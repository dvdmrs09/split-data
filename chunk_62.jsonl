{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the user_data of the given media descriptor.", "response": "def libvlc_media_set_user_data(p_md, p_new_user_data):\n    '''Sets media descriptor's user_data. user_data is specialized data\n    accessed by the host application, VLC.framework uses it as a pointer to\n    an native object that references a L{Media} pointer.\n    @param p_md: media descriptor object.\n    @param p_new_user_data: pointer to user data.\n    '''\n    f = _Cfunctions.get('libvlc_media_set_user_data', None) or \\\n        _Cfunction('libvlc_media_set_user_data', ((1,), (1,),), None,\n                    None, Media, ctypes.c_void_p)\n    return f(p_md, p_new_user_data)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting media descriptor s user_data.", "response": "def libvlc_media_get_user_data(p_md):\n    '''Get media descriptor's user_data. user_data is specialized data\n    accessed by the host application, VLC.framework uses it as a pointer to\n    an native object that references a L{Media} pointer.\n    @param p_md: media descriptor object.\n    '''\n    f = _Cfunctions.get('libvlc_media_get_user_data', None) or \\\n        _Cfunction('libvlc_media_get_user_data', ((1,),), None,\n                    ctypes.c_void_p, Media)\n    return f(p_md)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef libvlc_media_tracks_get(p_md, tracks):\n    '''Get media descriptor's elementary streams description\n    Note, you need to call L{libvlc_media_parse}() or play the media at least once\n    before calling this function.\n    Not doing this will result in an empty array.\n    @param p_md: media descriptor object.\n    @param tracks: address to store an allocated array of Elementary Streams descriptions (must be freed with L{libvlc_media_tracks_release}.\n    @return: the number of Elementary Streams (zero on error).\n    @version: LibVLC 2.1.0 and later.\n    '''\n    f = _Cfunctions.get('libvlc_media_tracks_get', None) or \\\n        _Cfunction('libvlc_media_tracks_get', ((1,), (1,),), None,\n                    ctypes.c_uint, Media, ctypes.POINTER(ctypes.POINTER(MediaTrack)))\n    return f(p_md, tracks)", "response": "Get media descriptor s elementary streams description\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef libvlc_media_get_codec_description(i_type, i_codec):\n    '''Get codec description from media elementary stream.\n    @param i_type: i_type from L{MediaTrack}.\n    @param i_codec: i_codec or i_original_fourcc from L{MediaTrack}.\n    @return: codec description.\n    @version: LibVLC 3.0.0 and later. See L{MediaTrack}.\n    '''\n    f = _Cfunctions.get('libvlc_media_get_codec_description', None) or \\\n        _Cfunction('libvlc_media_get_codec_description', ((1,), (1,),), None,\n                    ctypes.c_char_p, TrackType, ctypes.c_uint32)\n    return f(i_type, i_codec)", "response": "Get codec description from media elementary stream."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef libvlc_media_tracks_release(p_tracks, i_count):\n    '''Release media descriptor's elementary streams description array.\n    @param p_tracks: tracks info array to release.\n    @param i_count: number of elements in the array.\n    @version: LibVLC 2.1.0 and later.\n    '''\n    f = _Cfunctions.get('libvlc_media_tracks_release', None) or \\\n        _Cfunction('libvlc_media_tracks_release', ((1,), (1,),), None,\n                    None, ctypes.POINTER(MediaTrack), ctypes.c_uint)\n    return f(p_tracks, i_count)", "response": "Release media descriptor s elementary streams description array."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef libvlc_media_get_type(p_md):\n    '''Get the media type of the media descriptor object.\n    @param p_md: media descriptor object.\n    @return: media type.\n    @version: LibVLC 3.0.0 and later. See libvlc_media_type_t.\n    '''\n    f = _Cfunctions.get('libvlc_media_get_type', None) or \\\n        _Cfunction('libvlc_media_get_type', ((1,),), None,\n                    MediaType, Media)\n    return f(p_md)", "response": "Get the media type of the media descriptor object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef libvlc_media_discoverer_new(p_inst, psz_name):\n    '''Create a media discoverer object by name.\n    After this object is created, you should attach to events in order to be\n    notified of the discoverer state.\n    You should also attach to media_list events in order to be notified of new\n    items discovered.\n    You need to call L{libvlc_media_discoverer_start}() in order to start the\n    discovery.\n    See L{libvlc_media_discoverer_media_list}\n    See L{libvlc_media_discoverer_event_manager}\n    See L{libvlc_media_discoverer_start}.\n    @param p_inst: libvlc instance.\n    @param psz_name: service name.\n    @return: media discover object or NULL in case of error.\n    @version: LibVLC 3.0.0 or later.\n    '''\n    f = _Cfunctions.get('libvlc_media_discoverer_new', None) or \\\n        _Cfunction('libvlc_media_discoverer_new', ((1,), (1,),), class_result(MediaDiscoverer),\n                    ctypes.c_void_p, Instance, ctypes.c_char_p)\n    return f(p_inst, psz_name)", "response": "Create a new media discoverer object by name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef libvlc_media_discoverer_localized_name(p_mdis):\n    '''Get media service discover object its localized name.\n    @param p_mdis: media discover object.\n    @return: localized name.\n    '''\n    f = _Cfunctions.get('libvlc_media_discoverer_localized_name', None) or \\\n        _Cfunction('libvlc_media_discoverer_localized_name', ((1,),), string_result,\n                    ctypes.c_void_p, MediaDiscoverer)\n    return f(p_mdis)", "response": "Get media service discover object its localized name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget media service discover media list.", "response": "def libvlc_media_discoverer_media_list(p_mdis):\n    '''Get media service discover media list.\n    @param p_mdis: media service discover object.\n    @return: list of media items.\n    '''\n    f = _Cfunctions.get('libvlc_media_discoverer_media_list', None) or \\\n        _Cfunction('libvlc_media_discoverer_media_list', ((1,),), class_result(MediaList),\n                    ctypes.c_void_p, MediaDiscoverer)\n    return f(p_mdis)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef libvlc_media_discoverer_event_manager(p_mdis):\n    '''Get event manager from media service discover object.\n    @param p_mdis: media service discover object.\n    @return: event manager object.\n    '''\n    f = _Cfunctions.get('libvlc_media_discoverer_event_manager', None) or \\\n        _Cfunction('libvlc_media_discoverer_event_manager', ((1,),), class_result(EventManager),\n                    ctypes.c_void_p, MediaDiscoverer)\n    return f(p_mdis)", "response": "Get event manager from media service discover object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nquerying if media service discover object is running.", "response": "def libvlc_media_discoverer_is_running(p_mdis):\n    '''Query if media service discover object is running.\n    @param p_mdis: media service discover object.\n    @return: true if running, false if not \\libvlc_return_bool.\n    '''\n    f = _Cfunctions.get('libvlc_media_discoverer_is_running', None) or \\\n        _Cfunction('libvlc_media_discoverer_is_running', ((1,),), None,\n                    ctypes.c_int, MediaDiscoverer)\n    return f(p_mdis)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef libvlc_media_library_new(p_instance):\n    '''Create an new Media Library object.\n    @param p_instance: the libvlc instance.\n    @return: a new object or NULL on error.\n    '''\n    f = _Cfunctions.get('libvlc_media_library_new', None) or \\\n        _Cfunction('libvlc_media_library_new', ((1,),), class_result(MediaLibrary),\n                    ctypes.c_void_p, Instance)\n    return f(p_instance)", "response": "Create an empty Media Library object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading media library. @param p_mlib: media library object. @return: 0 on success, -1 on error.", "response": "def libvlc_media_library_load(p_mlib):\n    '''Load media library.\n    @param p_mlib: media library object.\n    @return: 0 on success, -1 on error.\n    '''\n    f = _Cfunctions.get('libvlc_media_library_load', None) or \\\n        _Cfunction('libvlc_media_library_load', ((1,),), None,\n                    ctypes.c_int, MediaLibrary)\n    return f(p_mlib)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef libvlc_media_library_media_list(p_mlib):\n    '''Get media library subitems.\n    @param p_mlib: media library object.\n    @return: media list subitems.\n    '''\n    f = _Cfunctions.get('libvlc_media_library_media_list', None) or \\\n        _Cfunction('libvlc_media_library_media_list', ((1,),), class_result(MediaList),\n                    ctypes.c_void_p, MediaLibrary)\n    return f(p_mlib)", "response": "Get media library subitems."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef libvlc_media_list_new(p_instance):\n    '''Create an empty media list.\n    @param p_instance: libvlc instance.\n    @return: empty media list, or NULL on error.\n    '''\n    f = _Cfunctions.get('libvlc_media_list_new', None) or \\\n        _Cfunction('libvlc_media_list_new', ((1,),), class_result(MediaList),\n                    ctypes.c_void_p, Instance)\n    return f(p_instance)", "response": "Create an empty media list."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nassociates media instance with this media list instance.", "response": "def libvlc_media_list_set_media(p_ml, p_md):\n    '''Associate media instance with this media list instance.\n    If another media instance was present it will be released.\n    The L{libvlc_media_list_lock} should NOT be held upon entering this function.\n    @param p_ml: a media list instance.\n    @param p_md: media instance to add.\n    '''\n    f = _Cfunctions.get('libvlc_media_list_set_media', None) or \\\n        _Cfunction('libvlc_media_list_set_media', ((1,), (1,),), None,\n                    None, MediaList, Media)\n    return f(p_ml, p_md)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets media instance from this media list instance.", "response": "def libvlc_media_list_media(p_ml):\n    '''Get media instance from this media list instance. This action will increase\n    the refcount on the media instance.\n    The L{libvlc_media_list_lock} should NOT be held upon entering this function.\n    @param p_ml: a media list instance.\n    @return: media instance.\n    '''\n    f = _Cfunctions.get('libvlc_media_list_media', None) or \\\n        _Cfunction('libvlc_media_list_media', ((1,),), class_result(Media),\n                    ctypes.c_void_p, MediaList)\n    return f(p_ml)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef libvlc_media_list_insert_media(p_ml, p_md, i_pos):\n    '''Insert media instance in media list on a position\n    The L{libvlc_media_list_lock} should be held upon entering this function.\n    @param p_ml: a media list instance.\n    @param p_md: a media instance.\n    @param i_pos: position in array where to insert.\n    @return: 0 on success, -1 if the media list is read-only.\n    '''\n    f = _Cfunctions.get('libvlc_media_list_insert_media', None) or \\\n        _Cfunction('libvlc_media_list_insert_media', ((1,), (1,), (1,),), None,\n                    ctypes.c_int, MediaList, Media, ctypes.c_int)\n    return f(p_ml, p_md, i_pos)", "response": "Insert a media instance in media list on a position\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove a media instance from a media list on a position.", "response": "def libvlc_media_list_remove_index(p_ml, i_pos):\n    '''Remove media instance from media list on a position\n    The L{libvlc_media_list_lock} should be held upon entering this function.\n    @param p_ml: a media list instance.\n    @param i_pos: position in array where to insert.\n    @return: 0 on success, -1 if the list is read-only or the item was not found.\n    '''\n    f = _Cfunctions.get('libvlc_media_list_remove_index', None) or \\\n        _Cfunction('libvlc_media_list_remove_index', ((1,), (1,),), None,\n                    ctypes.c_int, MediaList, ctypes.c_int)\n    return f(p_ml, i_pos)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef libvlc_media_list_count(p_ml):\n    '''Get count on media list items\n    The L{libvlc_media_list_lock} should be held upon entering this function.\n    @param p_ml: a media list instance.\n    @return: number of items in media list.\n    '''\n    f = _Cfunctions.get('libvlc_media_list_count', None) or \\\n        _Cfunction('libvlc_media_list_count', ((1,),), None,\n                    ctypes.c_int, MediaList)\n    return f(p_ml)", "response": "Get count on media list items\n    The L { libvlc_media_list_lock should be held upon entering this function."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef libvlc_media_list_item_at_index(p_ml, i_pos):\n    '''List media instance in media list at a position\n    The L{libvlc_media_list_lock} should be held upon entering this function.\n    @param p_ml: a media list instance.\n    @param i_pos: position in array where to insert.\n    @return: media instance at position i_pos, or NULL if not found. In case of success, L{libvlc_media_retain}() is called to increase the refcount on the media.\n    '''\n    f = _Cfunctions.get('libvlc_media_list_item_at_index', None) or \\\n        _Cfunction('libvlc_media_list_item_at_index', ((1,), (1,),), class_result(Media),\n                    ctypes.c_void_p, MediaList, ctypes.c_int)\n    return f(p_ml, i_pos)", "response": "Return the media instance at the given position in the media list."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef libvlc_media_list_index_of_item(p_ml, p_md):\n    '''Find index position of List media instance in media list.\n    Warning: the function will return the first matched position.\n    The L{libvlc_media_list_lock} should be held upon entering this function.\n    @param p_ml: a media list instance.\n    @param p_md: media instance.\n    @return: position of media instance or -1 if media not found.\n    '''\n    f = _Cfunctions.get('libvlc_media_list_index_of_item', None) or \\\n        _Cfunction('libvlc_media_list_index_of_item', ((1,), (1,),), None,\n                    ctypes.c_int, MediaList, Media)\n    return f(p_ml, p_md)", "response": "Find index of the first matched media in a list."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef libvlc_media_list_event_manager(p_ml):\n    '''Get libvlc_event_manager from this media list instance.\n    The p_event_manager is immutable, so you don't have to hold the lock.\n    @param p_ml: a media list instance.\n    @return: libvlc_event_manager.\n    '''\n    f = _Cfunctions.get('libvlc_media_list_event_manager', None) or \\\n        _Cfunction('libvlc_media_list_event_manager', ((1,),), class_result(EventManager),\n                    ctypes.c_void_p, MediaList)\n    return f(p_ml)", "response": "Get libvlc_event_manager from this media list instance."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef libvlc_media_list_player_new(p_instance):\n    '''Create new media_list_player.\n    @param p_instance: libvlc instance.\n    @return: media list player instance or NULL on error.\n    '''\n    f = _Cfunctions.get('libvlc_media_list_player_new', None) or \\\n        _Cfunction('libvlc_media_list_player_new', ((1,),), class_result(MediaListPlayer),\n                    ctypes.c_void_p, Instance)\n    return f(p_instance)", "response": "Create new media_list_player.\n    @param p_instance: libvlc instance.\n    @return: media list player instance or NULL on error."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the event manager of this media_list_player.", "response": "def libvlc_media_list_player_event_manager(p_mlp):\n    '''Return the event manager of this media_list_player.\n    @param p_mlp: media list player instance.\n    @return: the event manager.\n    '''\n    f = _Cfunctions.get('libvlc_media_list_player_event_manager', None) or \\\n        _Cfunction('libvlc_media_list_player_event_manager', ((1,),), class_result(EventManager),\n                    ctypes.c_void_p, MediaListPlayer)\n    return f(p_mlp)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreplacing media player in media_list_player with this instance.", "response": "def libvlc_media_list_player_set_media_player(p_mlp, p_mi):\n    '''Replace media player in media_list_player with this instance.\n    @param p_mlp: media list player instance.\n    @param p_mi: media player instance.\n    '''\n    f = _Cfunctions.get('libvlc_media_list_player_set_media_player', None) or \\\n        _Cfunction('libvlc_media_list_player_set_media_player', ((1,), (1,),), None,\n                    None, MediaListPlayer, MediaPlayer)\n    return f(p_mlp, p_mi)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef libvlc_media_list_player_set_media_list(p_mlp, p_mlist):\n    '''Set the media list associated with the player.\n    @param p_mlp: media list player instance.\n    @param p_mlist: list of media.\n    '''\n    f = _Cfunctions.get('libvlc_media_list_player_set_media_list', None) or \\\n        _Cfunction('libvlc_media_list_player_set_media_list', ((1,), (1,),), None,\n                    None, MediaListPlayer, MediaList)\n    return f(p_mlp, p_mlist)", "response": "Set the media list associated with the player."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nis media list playing?", "response": "def libvlc_media_list_player_is_playing(p_mlp):\n    '''Is media list playing?\n    @param p_mlp: media list player instance.\n    @return: true for playing and false for not playing \\libvlc_return_bool.\n    '''\n    f = _Cfunctions.get('libvlc_media_list_player_is_playing', None) or \\\n        _Cfunction('libvlc_media_list_player_is_playing', ((1,),), None,\n                    ctypes.c_int, MediaListPlayer)\n    return f(p_mlp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets current libvlc_state of media list player.", "response": "def libvlc_media_list_player_get_state(p_mlp):\n    '''Get current libvlc_state of media list player.\n    @param p_mlp: media list player instance.\n    @return: libvlc_state_t for media list player.\n    '''\n    f = _Cfunctions.get('libvlc_media_list_player_get_state', None) or \\\n        _Cfunction('libvlc_media_list_player_get_state', ((1,),), None,\n                    State, MediaListPlayer)\n    return f(p_mlp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef libvlc_media_list_player_play_item_at_index(p_mlp, i_index):\n    '''Play media list item at position index.\n    @param p_mlp: media list player instance.\n    @param i_index: index in media list to play.\n    @return: 0 upon success -1 if the item wasn't found.\n    '''\n    f = _Cfunctions.get('libvlc_media_list_player_play_item_at_index', None) or \\\n        _Cfunction('libvlc_media_list_player_play_item_at_index', ((1,), (1,),), None,\n                    ctypes.c_int, MediaListPlayer, ctypes.c_int)\n    return f(p_mlp, i_index)", "response": "Play media list item at position index."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nplaying the given media item.", "response": "def libvlc_media_list_player_play_item(p_mlp, p_md):\n    '''Play the given media item.\n    @param p_mlp: media list player instance.\n    @param p_md: the media instance.\n    @return: 0 upon success, -1 if the media is not part of the media list.\n    '''\n    f = _Cfunctions.get('libvlc_media_list_player_play_item', None) or \\\n        _Cfunction('libvlc_media_list_player_play_item', ((1,), (1,),), None,\n                    ctypes.c_int, MediaListPlayer, Media)\n    return f(p_mlp, p_md)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the playback mode for the playlist.", "response": "def libvlc_media_list_player_set_playback_mode(p_mlp, e_mode):\n    '''Sets the playback mode for the playlist.\n    @param p_mlp: media list player instance.\n    @param e_mode: playback mode specification.\n    '''\n    f = _Cfunctions.get('libvlc_media_list_player_set_playback_mode', None) or \\\n        _Cfunction('libvlc_media_list_player_set_playback_mode', ((1,), (1,),), None,\n                    None, MediaListPlayer, PlaybackMode)\n    return f(p_mlp, e_mode)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef libvlc_media_player_new(p_libvlc_instance):\n    '''Create an empty Media Player object.\n    @param p_libvlc_instance: the libvlc instance in which the Media Player should be created.\n    @return: a new media player object, or NULL on error.\n    '''\n    f = _Cfunctions.get('libvlc_media_player_new', None) or \\\n        _Cfunction('libvlc_media_player_new', ((1,),), class_result(MediaPlayer),\n                    ctypes.c_void_p, Instance)\n    return f(p_libvlc_instance)", "response": "Create an empty Media Player object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef libvlc_media_player_new_from_media(p_md):\n    '''Create a Media Player object from a Media.\n    @param p_md: the media. Afterwards the p_md can be safely destroyed.\n    @return: a new media player object, or NULL on error.\n    '''\n    f = _Cfunctions.get('libvlc_media_player_new_from_media', None) or \\\n        _Cfunction('libvlc_media_player_new_from_media', ((1,),), class_result(MediaPlayer),\n                    ctypes.c_void_p, Media)\n    return f(p_md)", "response": "Create a Media Player object from a Media."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the media that will be used by the media_player.", "response": "def libvlc_media_player_set_media(p_mi, p_md):\n    '''Set the media that will be used by the media_player. If any,\n    previous md will be released.\n    @param p_mi: the Media Player.\n    @param p_md: the Media. Afterwards the p_md can be safely destroyed.\n    '''\n    f = _Cfunctions.get('libvlc_media_player_set_media', None) or \\\n        _Cfunction('libvlc_media_player_set_media', ((1,), (1,),), None,\n                    None, MediaPlayer, Media)\n    return f(p_mi, p_md)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the media used by the media_player.", "response": "def libvlc_media_player_get_media(p_mi):\n    '''Get the media used by the media_player.\n    @param p_mi: the Media Player.\n    @return: the media associated with p_mi, or NULL if no media is associated.\n    '''\n    f = _Cfunctions.get('libvlc_media_player_get_media', None) or \\\n        _Cfunction('libvlc_media_player_get_media', ((1,),), class_result(Media),\n                    ctypes.c_void_p, MediaPlayer)\n    return f(p_mi)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the Event Manager from which the media player send event.", "response": "def libvlc_media_player_event_manager(p_mi):\n    '''Get the Event Manager from which the media player send event.\n    @param p_mi: the Media Player.\n    @return: the event manager associated with p_mi.\n    '''\n    f = _Cfunctions.get('libvlc_media_player_event_manager', None) or \\\n        _Cfunction('libvlc_media_player_event_manager', ((1,),), class_result(EventManager),\n                    ctypes.c_void_p, MediaPlayer)\n    return f(p_mi)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef libvlc_media_player_set_pause(mp, do_pause):\n    '''Pause or resume (no effect if there is no media).\n    @param mp: the Media Player.\n    @param do_pause: play/resume if zero, pause if non-zero.\n    @version: LibVLC 1.1.1 or later.\n    '''\n    f = _Cfunctions.get('libvlc_media_player_set_pause', None) or \\\n        _Cfunction('libvlc_media_player_set_pause', ((1,), (1,),), None,\n                    None, MediaPlayer, ctypes.c_int)\n    return f(mp, do_pause)", "response": "Pause or resume the media."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef libvlc_video_set_callbacks(mp, lock, unlock, display, opaque):\n    '''Set callbacks and private data to render decoded video to a custom area\n    in memory.\n    Use L{libvlc_video_set_format}() or L{libvlc_video_set_format_callbacks}()\n    to configure the decoded format.\n    @param mp: the media player.\n    @param lock: callback to lock video memory (must not be NULL).\n    @param unlock: callback to unlock video memory (or NULL if not needed).\n    @param display: callback to display video (or NULL if not needed).\n    @param opaque: private pointer for the three callbacks (as first parameter).\n    @version: LibVLC 1.1.1 or later.\n    '''\n    f = _Cfunctions.get('libvlc_video_set_callbacks', None) or \\\n        _Cfunction('libvlc_video_set_callbacks', ((1,), (1,), (1,), (1,), (1,),), None,\n                    None, MediaPlayer, VideoLockCb, VideoUnlockCb, VideoDisplayCb, ctypes.c_void_p)\n    return f(mp, lock, unlock, display, opaque)", "response": "Set callbacks and private data to render decoded video to a custom area\n    in memory."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting decoded video chroma and dimensions.", "response": "def libvlc_video_set_format(mp, chroma, width, height, pitch):\n    '''Set decoded video chroma and dimensions.\n    This only works in combination with L{libvlc_video_set_callbacks}(),\n    and is mutually exclusive with L{libvlc_video_set_format_callbacks}().\n    @param mp: the media player.\n    @param chroma: a four-characters string identifying the chroma (e.g. \"RV32\" or \"YUYV\").\n    @param width: pixel width.\n    @param height: pixel height.\n    @param pitch: line pitch (in bytes).\n    @version: LibVLC 1.1.1 or later.\n    @bug: All pixel planes are expected to have the same pitch. To use the YCbCr color space with chrominance subsampling, consider using L{libvlc_video_set_format_callbacks}() instead.\n    '''\n    f = _Cfunctions.get('libvlc_video_set_format', None) or \\\n        _Cfunction('libvlc_video_set_format', ((1,), (1,), (1,), (1,), (1,),), None,\n                    None, MediaPlayer, ctypes.c_char_p, ctypes.c_uint, ctypes.c_uint, ctypes.c_uint)\n    return f(mp, chroma, width, height, pitch)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef libvlc_video_set_format_callbacks(mp, setup, cleanup):\n    '''Set decoded video chroma and dimensions. This only works in combination with\n    L{libvlc_video_set_callbacks}().\n    @param mp: the media player.\n    @param setup: callback to select the video format (cannot be NULL).\n    @param cleanup: callback to release any allocated resources (or NULL).\n    @version: LibVLC 2.0.0 or later.\n    '''\n    f = _Cfunctions.get('libvlc_video_set_format_callbacks', None) or \\\n        _Cfunction('libvlc_video_set_format_callbacks', ((1,), (1,), (1,),), None,\n                    None, MediaPlayer, VideoFormatCb, VideoCleanupCb)\n    return f(mp, setup, cleanup)", "response": "Set decoded video chroma and dimensions. This only works in combination with\n    L{libvlc_video_set_callbacks().\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef libvlc_media_player_set_nsobject(p_mi, drawable):\n    '''Set the NSView handler where the media player should render its video output.\n    Use the vout called \"macosx\".\n    The drawable is an NSObject that follow the VLCOpenGLVideoViewEmbedding\n    protocol:\n    @begincode\n    \\@protocol VLCOpenGLVideoViewEmbedding <NSObject>\n    - (void)addVoutSubview:(NSView *)view;\n    - (void)removeVoutSubview:(NSView *)view;\n    \\@end\n    @endcode\n    Or it can be an NSView object.\n    If you want to use it along with Qt4 see the QMacCocoaViewContainer. Then\n    the following code should work:\n    @begincode\n    \n        NSView *video = [[NSView alloc] init];\n        QMacCocoaViewContainer *container = new QMacCocoaViewContainer(video, parent);\n        L{libvlc_media_player_set_nsobject}(mp, video);\n        [video release];\n    \n    @endcode\n    You can find a live example in VLCVideoView in VLCKit.framework.\n    @param p_mi: the Media Player.\n    @param drawable: the drawable that is either an NSView or an object following the VLCOpenGLVideoViewEmbedding protocol.\n    '''\n    f = _Cfunctions.get('libvlc_media_player_set_nsobject', None) or \\\n        _Cfunction('libvlc_media_player_set_nsobject', ((1,), (1,),), None,\n                    None, MediaPlayer, ctypes.c_void_p)\n    return f(p_mi, drawable)", "response": "Set the NSView handler where the media player should render its video output."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef libvlc_media_player_get_nsobject(p_mi):\n    '''Get the NSView handler previously set with L{libvlc_media_player_set_nsobject}().\n    @param p_mi: the Media Player.\n    @return: the NSView handler or 0 if none where set.\n    '''\n    f = _Cfunctions.get('libvlc_media_player_get_nsobject', None) or \\\n        _Cfunction('libvlc_media_player_get_nsobject', ((1,),), None,\n                    ctypes.c_void_p, MediaPlayer)\n    return f(p_mi)", "response": "Get the NSView handler previously set with LVLC_media_player_set_nsobject()."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef libvlc_media_player_set_agl(p_mi, drawable):\n    '''Set the agl handler where the media player should render its video output.\n    @param p_mi: the Media Player.\n    @param drawable: the agl handler.\n    '''\n    f = _Cfunctions.get('libvlc_media_player_set_agl', None) or \\\n        _Cfunction('libvlc_media_player_set_agl', ((1,), (1,),), None,\n                    None, MediaPlayer, ctypes.c_uint32)\n    return f(p_mi, drawable)", "response": "Set the agl handler where the media player should render its video output."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the agl handler previously set with LVLC_media_player_set_agl().", "response": "def libvlc_media_player_get_agl(p_mi):\n    '''Get the agl handler previously set with L{libvlc_media_player_set_agl}().\n    @param p_mi: the Media Player.\n    @return: the agl handler or 0 if none where set.\n    '''\n    f = _Cfunctions.get('libvlc_media_player_get_agl', None) or \\\n        _Cfunction('libvlc_media_player_get_agl', ((1,),), None,\n                    ctypes.c_uint32, MediaPlayer)\n    return f(p_mi)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting callbacks and private data for decoded audio.", "response": "def libvlc_audio_set_callbacks(mp, play, pause, resume, flush, drain, opaque):\n    '''Set callbacks and private data for decoded audio.\n    Use L{libvlc_audio_set_format}() or L{libvlc_audio_set_format_callbacks}()\n    to configure the decoded audio format.\n    @param mp: the media player.\n    @param play: callback to play audio samples (must not be NULL).\n    @param pause: callback to pause playback (or NULL to ignore).\n    @param resume: callback to resume playback (or NULL to ignore).\n    @param flush: callback to flush audio buffers (or NULL to ignore).\n    @param drain: callback to drain audio buffers (or NULL to ignore).\n    @param opaque: private pointer for the audio callbacks (as first parameter).\n    @version: LibVLC 2.0.0 or later.\n    '''\n    f = _Cfunctions.get('libvlc_audio_set_callbacks', None) or \\\n        _Cfunction('libvlc_audio_set_callbacks', ((1,), (1,), (1,), (1,), (1,), (1,), (1,),), None,\n                    None, MediaPlayer, AudioPlayCb, AudioPauseCb, AudioResumeCb, AudioFlushCb, AudioDrainCb, ctypes.c_void_p)\n    return f(mp, play, pause, resume, flush, drain, opaque)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset callbacks and private data for decoded audio.", "response": "def libvlc_audio_set_volume_callback(mp, set_volume):\n    '''Set callbacks and private data for decoded audio. This only works in\n    combination with L{libvlc_audio_set_callbacks}().\n    Use L{libvlc_audio_set_format}() or L{libvlc_audio_set_format_callbacks}()\n    to configure the decoded audio format.\n    @param mp: the media player.\n    @param set_volume: callback to apply audio volume, or NULL to apply volume in software.\n    @version: LibVLC 2.0.0 or later.\n    '''\n    f = _Cfunctions.get('libvlc_audio_set_volume_callback', None) or \\\n        _Cfunction('libvlc_audio_set_volume_callback', ((1,), (1,),), None,\n                    None, MediaPlayer, AudioSetVolumeCb)\n    return f(mp, set_volume)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef libvlc_audio_set_format_callbacks(mp, setup, cleanup):\n    '''Set decoded audio format. This only works in combination with\n    L{libvlc_audio_set_callbacks}().\n    @param mp: the media player.\n    @param setup: callback to select the audio format (cannot be NULL).\n    @param cleanup: callback to release any allocated resources (or NULL).\n    @version: LibVLC 2.0.0 or later.\n    '''\n    f = _Cfunctions.get('libvlc_audio_set_format_callbacks', None) or \\\n        _Cfunction('libvlc_audio_set_format_callbacks', ((1,), (1,), (1,),), None,\n                    None, MediaPlayer, AudioSetupCb, AudioCleanupCb)\n    return f(mp, setup, cleanup)", "response": "Set decoded audio format. This only works in combination with\n    L{libvlc_audio_set_callbacks().\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef libvlc_audio_set_format(mp, format, rate, channels):\n    '''Set decoded audio format.\n    This only works in combination with L{libvlc_audio_set_callbacks}(),\n    and is mutually exclusive with L{libvlc_audio_set_format_callbacks}().\n    @param mp: the media player.\n    @param format: a four-characters string identifying the sample format (e.g. \"S16N\" or \"FL32\").\n    @param rate: sample rate (expressed in Hz).\n    @param channels: channels count.\n    @version: LibVLC 2.0.0 or later.\n    '''\n    f = _Cfunctions.get('libvlc_audio_set_format', None) or \\\n        _Cfunction('libvlc_audio_set_format', ((1,), (1,), (1,), (1,),), None,\n                    None, MediaPlayer, ctypes.c_char_p, ctypes.c_uint, ctypes.c_uint)\n    return f(mp, format, rate, channels)", "response": "Set decoded audio format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the current movie length in ms.", "response": "def libvlc_media_player_get_length(p_mi):\n    '''Get the current movie length (in ms).\n    @param p_mi: the Media Player.\n    @return: the movie length (in ms), or -1 if there is no media.\n    '''\n    f = _Cfunctions.get('libvlc_media_player_get_length', None) or \\\n        _Cfunction('libvlc_media_player_get_length', ((1,),), None,\n                    ctypes.c_longlong, MediaPlayer)\n    return f(p_mi)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef libvlc_media_player_set_time(p_mi, i_time):\n    '''Set the movie time (in ms). This has no effect if no media is being played.\n    Not all formats and protocols support this.\n    @param p_mi: the Media Player.\n    @param i_time: the movie time (in ms).\n    '''\n    f = _Cfunctions.get('libvlc_media_player_set_time', None) or \\\n        _Cfunction('libvlc_media_player_set_time', ((1,), (1,),), None,\n                    None, MediaPlayer, ctypes.c_longlong)\n    return f(p_mi, i_time)", "response": "Set the movie time in ms."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef libvlc_media_player_set_position(p_mi, f_pos):\n    '''Set movie position as percentage between 0.0 and 1.0.\n    This has no effect if playback is not enabled.\n    This might not work depending on the underlying input format and protocol.\n    @param p_mi: the Media Player.\n    @param f_pos: the position.\n    '''\n    f = _Cfunctions.get('libvlc_media_player_set_position', None) or \\\n        _Cfunction('libvlc_media_player_set_position', ((1,), (1,),), None,\n                    None, MediaPlayer, ctypes.c_float)\n    return f(p_mi, f_pos)", "response": "Set movie position as percentage between 0. 0 and 1. 0."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef libvlc_media_player_set_chapter(p_mi, i_chapter):\n    '''Set movie chapter (if applicable).\n    @param p_mi: the Media Player.\n    @param i_chapter: chapter number to play.\n    '''\n    f = _Cfunctions.get('libvlc_media_player_set_chapter', None) or \\\n        _Cfunction('libvlc_media_player_set_chapter', ((1,), (1,),), None,\n                    None, MediaPlayer, ctypes.c_int)\n    return f(p_mi, i_chapter)", "response": "Set movie chapter (if applicable).\n    @param p_mi: the Media Player.\n    @param i_chapter: chapter number to play."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef libvlc_media_player_get_chapter_count_for_title(p_mi, i_title):\n    '''Get title chapter count.\n    @param p_mi: the Media Player.\n    @param i_title: title.\n    @return: number of chapters in title, or -1.\n    '''\n    f = _Cfunctions.get('libvlc_media_player_get_chapter_count_for_title', None) or \\\n        _Cfunction('libvlc_media_player_get_chapter_count_for_title', ((1,), (1,),), None,\n                    ctypes.c_int, MediaPlayer, ctypes.c_int)\n    return f(p_mi, i_title)", "response": "Get title chapter count."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef libvlc_media_player_set_rate(p_mi, rate):\n    '''Set movie play rate.\n    @param p_mi: the Media Player.\n    @param rate: movie play rate to set.\n    @return: -1 if an error was detected, 0 otherwise (but even then, it might not actually work depending on the underlying media protocol).\n    '''\n    f = _Cfunctions.get('libvlc_media_player_set_rate', None) or \\\n        _Cfunction('libvlc_media_player_set_rate', ((1,), (1,),), None,\n                    ctypes.c_int, MediaPlayer, ctypes.c_float)\n    return f(p_mi, rate)", "response": "Set movie play rate."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef libvlc_media_player_get_state(p_mi):\n    '''Get current movie state.\n    @param p_mi: the Media Player.\n    @return: the current state of the media player (playing, paused, ...) See libvlc_state_t.\n    '''\n    f = _Cfunctions.get('libvlc_media_player_get_state', None) or \\\n        _Cfunction('libvlc_media_player_get_state', ((1,),), None,\n                    State, MediaPlayer)\n    return f(p_mi)", "response": "Get current movie state."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef libvlc_media_player_get_fps(p_mi):\n    '''Get movie fps rate.\n    @param p_mi: the Media Player.\n    @return: frames per second (fps) for this playing movie, or 0 if unspecified.\n    '''\n    f = _Cfunctions.get('libvlc_media_player_get_fps', None) or \\\n        _Cfunction('libvlc_media_player_get_fps', ((1,),), None,\n                    ctypes.c_float, MediaPlayer)\n    return f(p_mi)", "response": "Get movie fps rate."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nnavigate through DVD Menu.", "response": "def libvlc_media_player_navigate(p_mi, navigate):\n    '''Navigate through DVD Menu.\n    @param p_mi: the Media Player.\n    @param navigate: the Navigation mode.\n    @version: libVLC 2.0.0 or later.\n    '''\n    f = _Cfunctions.get('libvlc_media_player_navigate', None) or \\\n        _Cfunction('libvlc_media_player_navigate', ((1,), (1,),), None,\n                    None, MediaPlayer, ctypes.c_uint)\n    return f(p_mi, navigate)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef libvlc_media_player_set_video_title_display(p_mi, position, timeout):\n    '''Set if, and how, the video title will be shown when media is played.\n    @param p_mi: the media player.\n    @param position: position at which to display the title, or libvlc_position_disable to prevent the title from being displayed.\n    @param timeout: title display timeout in milliseconds (ignored if libvlc_position_disable).\n    @version: libVLC 2.1.0 or later.\n    '''\n    f = _Cfunctions.get('libvlc_media_player_set_video_title_display', None) or \\\n        _Cfunction('libvlc_media_player_set_video_title_display', ((1,), (1,), (1,),), None,\n                    None, MediaPlayer, Position, ctypes.c_int)\n    return f(p_mi, position, timeout)", "response": "Set if and how the video title will be shown when media is played."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreleases the list of unallocated items in the given L { TrackDescription }.", "response": "def libvlc_track_description_list_release(p_track_description):\n    '''Release (free) L{TrackDescription}.\n    @param p_track_description: the structure to release.\n    '''\n    f = _Cfunctions.get('libvlc_track_description_list_release', None) or \\\n        _Cfunction('libvlc_track_description_list_release', ((1,),), None,\n                    None, ctypes.POINTER(TrackDescription))\n    return f(p_track_description)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nenabling or disable fullscreen mode.", "response": "def libvlc_set_fullscreen(p_mi, b_fullscreen):\n    '''Enable or disable fullscreen.\n    @warning: With most window managers, only a top-level windows can be in\n    full-screen mode. Hence, this function will not operate properly if\n    L{libvlc_media_player_set_xwindow}() was used to embed the video in a\n    non-top-level window. In that case, the embedding window must be reparented\n    to the root window B{before} fullscreen mode is enabled. You will want\n    to reparent it back to its normal parent when disabling fullscreen.\n    @param p_mi: the media player.\n    @param b_fullscreen: boolean for fullscreen status.\n    '''\n    f = _Cfunctions.get('libvlc_set_fullscreen', None) or \\\n        _Cfunction('libvlc_set_fullscreen', ((1,), (1,),), None,\n                    None, MediaPlayer, ctypes.c_int)\n    return f(p_mi, b_fullscreen)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef libvlc_video_set_key_input(p_mi, on):\n    '''Enable or disable key press events handling, according to the LibVLC hotkeys\n    configuration. By default and for historical reasons, keyboard events are\n    handled by the LibVLC video widget.\n    @note: On X11, there can be only one subscriber for key press and mouse\n    click events per window. If your application has subscribed to those events\n    for the X window ID of the video widget, then LibVLC will not be able to\n    handle key presses and mouse clicks in any case.\n    @warning: This function is only implemented for X11 and Win32 at the moment.\n    @param p_mi: the media player.\n    @param on: true to handle key press events, false to ignore them.\n    '''\n    f = _Cfunctions.get('libvlc_video_set_key_input', None) or \\\n        _Cfunction('libvlc_video_set_key_input', ((1,), (1,),), None,\n                    None, MediaPlayer, ctypes.c_uint)\n    return f(p_mi, on)", "response": "Enable or disable key press events handling according to the LibVLC hotkeys\n    configuration."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the pixel dimensions of a video.", "response": "def libvlc_video_get_size(p_mi, num):\n    '''Get the pixel dimensions of a video.\n    @param p_mi: media player.\n    @param num: number of the video (starting from, and most commonly 0).\n    @return: px pixel width, py pixel height.\n    '''\n    f = _Cfunctions.get('libvlc_video_get_size', None) or \\\n        _Cfunction('libvlc_video_get_size', ((1,), (1,), (2,), (2,),), None,\n                    ctypes.c_int, MediaPlayer, ctypes.c_uint, ctypes.POINTER(ctypes.c_uint), ctypes.POINTER(ctypes.c_uint))\n    return f(p_mi, num)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the video scaling factor. That is the ratio of the number of pixels on the original decoded video to the number of pixels in the original decoded video in each screen to the number of pixels in the original decoded video in each dimension. Zero is a special value.", "response": "def libvlc_video_set_scale(p_mi, f_factor):\n    '''Set the video scaling factor. That is the ratio of the number of pixels on\n    screen to the number of pixels in the original decoded video in each\n    dimension. Zero is a special value; it will adjust the video to the output\n    window/drawable (in windowed mode) or the entire screen.\n    Note that not all video outputs support scaling.\n    @param p_mi: the media player.\n    @param f_factor: the scaling factor, or zero.\n    '''\n    f = _Cfunctions.get('libvlc_video_set_scale', None) or \\\n        _Cfunction('libvlc_video_set_scale', ((1,), (1,),), None,\n                    None, MediaPlayer, ctypes.c_float)\n    return f(p_mi, f_factor)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef libvlc_video_get_aspect_ratio(p_mi):\n    '''Get current video aspect ratio.\n    @param p_mi: the media player.\n    @return: the video aspect ratio or NULL if unspecified (the result must be released with free() or L{libvlc_free}()).\n    '''\n    f = _Cfunctions.get('libvlc_video_get_aspect_ratio', None) or \\\n        _Cfunction('libvlc_video_get_aspect_ratio', ((1,),), string_result,\n                    ctypes.c_void_p, MediaPlayer)\n    return f(p_mi)", "response": "Get current video aspect ratio."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef libvlc_video_set_aspect_ratio(p_mi, psz_aspect):\n    '''Set new video aspect ratio.\n    @param p_mi: the media player.\n    @param psz_aspect: new video aspect-ratio or NULL to reset to default @note Invalid aspect ratios are ignored.\n    '''\n    f = _Cfunctions.get('libvlc_video_set_aspect_ratio', None) or \\\n        _Cfunction('libvlc_video_set_aspect_ratio', ((1,), (1,),), None,\n                    None, MediaPlayer, ctypes.c_char_p)\n    return f(p_mi, psz_aspect)", "response": "Set new video aspect ratio."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef libvlc_video_get_spu(p_mi):\n    '''Get current video subtitle.\n    @param p_mi: the media player.\n    @return: the video subtitle selected, or -1 if none.\n    '''\n    f = _Cfunctions.get('libvlc_video_get_spu', None) or \\\n        _Cfunction('libvlc_video_get_spu', ((1,),), None,\n                    ctypes.c_int, MediaPlayer)\n    return f(p_mi)", "response": "Get current video subtitle."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef libvlc_video_set_spu(p_mi, i_spu):\n    '''Set new video subtitle.\n    @param p_mi: the media player.\n    @param i_spu: video subtitle track to select (i_id from track description).\n    @return: 0 on success, -1 if out of range.\n    '''\n    f = _Cfunctions.get('libvlc_video_set_spu', None) or \\\n        _Cfunction('libvlc_video_set_spu', ((1,), (1,),), None,\n                    ctypes.c_int, MediaPlayer, ctypes.c_int)\n    return f(p_mi, i_spu)", "response": "Set new video subtitle."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset new video subtitle file.", "response": "def libvlc_video_set_subtitle_file(p_mi, psz_subtitle):\n    '''Set new video subtitle file.\n    @param p_mi: the media player.\n    @param psz_subtitle: new video subtitle file.\n    @return: the success status (boolean).\n    '''\n    f = _Cfunctions.get('libvlc_video_set_subtitle_file', None) or \\\n        _Cfunction('libvlc_video_set_subtitle_file', ((1,), (1,),), None,\n                    ctypes.c_int, MediaPlayer, ctypes.c_char_p)\n    return f(p_mi, psz_subtitle)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the subtitle delay. This affects the timing of when the subtitle will be displayed later.", "response": "def libvlc_video_set_spu_delay(p_mi, i_delay):\n    '''Set the subtitle delay. This affects the timing of when the subtitle will\n    be displayed. Positive values result in subtitles being displayed later,\n    while negative values will result in subtitles being displayed earlier.\n    The subtitle delay will be reset to zero each time the media changes.\n    @param p_mi: media player.\n    @param i_delay: time (in microseconds) the display of subtitles should be delayed.\n    @return: 0 on success, -1 on error.\n    @version: LibVLC 2.0.0 or later.\n    '''\n    f = _Cfunctions.get('libvlc_video_set_spu_delay', None) or \\\n        _Cfunction('libvlc_video_set_spu_delay', ((1,), (1,),), None,\n                    ctypes.c_int, MediaPlayer, ctypes.c_int64)\n    return f(p_mi, i_delay)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef libvlc_video_get_chapter_description(p_mi, i_title):\n    '''Get the description of available chapters for specific title.\n    @param p_mi: the media player.\n    @param i_title: selected title.\n    @return: list containing description of available chapter for title i_title.\n    '''\n    f = _Cfunctions.get('libvlc_video_get_chapter_description', None) or \\\n        _Cfunction('libvlc_video_get_chapter_description', ((1,), (1,),), None,\n                    ctypes.POINTER(TrackDescription), MediaPlayer, ctypes.c_int)\n    return f(p_mi, i_title)", "response": "Get the description of available chapters for specific title."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef libvlc_video_set_crop_geometry(p_mi, psz_geometry):\n    '''Set new crop filter geometry.\n    @param p_mi: the media player.\n    @param psz_geometry: new crop filter geometry (NULL to unset).\n    '''\n    f = _Cfunctions.get('libvlc_video_set_crop_geometry', None) or \\\n        _Cfunction('libvlc_video_set_crop_geometry', ((1,), (1,),), None,\n                    None, MediaPlayer, ctypes.c_char_p)\n    return f(p_mi, psz_geometry)", "response": "Set new crop filter geometry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef libvlc_video_set_teletext(p_mi, i_page):\n    '''Set new teletext page to retrieve.\n    @param p_mi: the media player.\n    @param i_page: teletex page number requested.\n    '''\n    f = _Cfunctions.get('libvlc_video_set_teletext', None) or \\\n        _Cfunction('libvlc_video_set_teletext', ((1,), (1,),), None,\n                    None, MediaPlayer, ctypes.c_int)\n    return f(p_mi, i_page)", "response": "Set new teletext page to retrieve."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef libvlc_video_get_track_description(p_mi):\n    '''Get the description of available video tracks.\n    @param p_mi: media player.\n    @return: list with description of available video tracks, or NULL on error.\n    '''\n    f = _Cfunctions.get('libvlc_video_get_track_description', None) or \\\n        _Cfunction('libvlc_video_get_track_description', ((1,),), None,\n                    ctypes.POINTER(TrackDescription), MediaPlayer)\n    return f(p_mi)", "response": "Get the description of available video tracks."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef libvlc_video_take_snapshot(p_mi, num, psz_filepath, i_width, i_height):\n    '''Take a snapshot of the current video window.\n    If i_width AND i_height is 0, original size is used.\n    If i_width XOR i_height is 0, original aspect-ratio is preserved.\n    @param p_mi: media player instance.\n    @param num: number of video output (typically 0 for the first/only one).\n    @param psz_filepath: the path where to save the screenshot to.\n    @param i_width: the snapshot's width.\n    @param i_height: the snapshot's height.\n    @return: 0 on success, -1 if the video was not found.\n    '''\n    f = _Cfunctions.get('libvlc_video_take_snapshot', None) or \\\n        _Cfunction('libvlc_video_take_snapshot', ((1,), (1,), (1,), (1,), (1,),), None,\n                    ctypes.c_int, MediaPlayer, ctypes.c_uint, ctypes.c_char_p, ctypes.c_int, ctypes.c_int)\n    return f(p_mi, num, psz_filepath, i_width, i_height)", "response": "Take a snapshot of the current video window."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nenabling or disable deinterlace filter.", "response": "def libvlc_video_set_deinterlace(p_mi, psz_mode):\n    '''Enable or disable deinterlace filter.\n    @param p_mi: libvlc media player.\n    @param psz_mode: type of deinterlace filter, NULL to disable.\n    '''\n    f = _Cfunctions.get('libvlc_video_set_deinterlace', None) or \\\n        _Cfunction('libvlc_video_set_deinterlace', ((1,), (1,),), None,\n                    None, MediaPlayer, ctypes.c_char_p)\n    return f(p_mi, psz_mode)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a string marquee option value.", "response": "def libvlc_video_get_marquee_string(p_mi, option):\n    '''Get a string marquee option value.\n    @param p_mi: libvlc media player.\n    @param option: marq option to get See libvlc_video_marquee_string_option_t.\n    '''\n    f = _Cfunctions.get('libvlc_video_get_marquee_string', None) or \\\n        _Cfunction('libvlc_video_get_marquee_string', ((1,), (1,),), string_result,\n                    ctypes.c_void_p, MediaPlayer, ctypes.c_uint)\n    return f(p_mi, option)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nenabling disable or set an integer marquee option.", "response": "def libvlc_video_set_marquee_int(p_mi, option, i_val):\n    '''Enable, disable or set an integer marquee option\n    Setting libvlc_marquee_Enable has the side effect of enabling (arg !0)\n    or disabling (arg 0) the marq filter.\n    @param p_mi: libvlc media player.\n    @param option: marq option to set See libvlc_video_marquee_int_option_t.\n    @param i_val: marq option value.\n    '''\n    f = _Cfunctions.get('libvlc_video_set_marquee_int', None) or \\\n        _Cfunction('libvlc_video_set_marquee_int', ((1,), (1,), (1,),), None,\n                    None, MediaPlayer, ctypes.c_uint, ctypes.c_int)\n    return f(p_mi, option, i_val)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef libvlc_video_set_marquee_string(p_mi, option, psz_text):\n    '''Set a marquee string option.\n    @param p_mi: libvlc media player.\n    @param option: marq option to set See libvlc_video_marquee_string_option_t.\n    @param psz_text: marq option value.\n    '''\n    f = _Cfunctions.get('libvlc_video_set_marquee_string', None) or \\\n        _Cfunction('libvlc_video_set_marquee_string', ((1,), (1,), (1,),), None,\n                    None, MediaPlayer, ctypes.c_uint, ctypes.c_char_p)\n    return f(p_mi, option, psz_text)", "response": "Set a marquee string option."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef libvlc_video_get_logo_int(p_mi, option):\n    '''Get integer logo option.\n    @param p_mi: libvlc media player instance.\n    @param option: logo option to get, values of libvlc_video_logo_option_t.\n    '''\n    f = _Cfunctions.get('libvlc_video_get_logo_int', None) or \\\n        _Cfunction('libvlc_video_get_logo_int', ((1,), (1,),), None,\n                    ctypes.c_int, MediaPlayer, ctypes.c_uint)\n    return f(p_mi, option)", "response": "Get integer logo option."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset logo option as integer.", "response": "def libvlc_video_set_logo_int(p_mi, option, value):\n    '''Set logo option as integer. Options that take a different type value\n    are ignored.\n    Passing libvlc_logo_enable as option value has the side effect of\n    starting (arg !0) or stopping (arg 0) the logo filter.\n    @param p_mi: libvlc media player instance.\n    @param option: logo option to set, values of libvlc_video_logo_option_t.\n    @param value: logo option value.\n    '''\n    f = _Cfunctions.get('libvlc_video_set_logo_int', None) or \\\n        _Cfunction('libvlc_video_set_logo_int', ((1,), (1,), (1,),), None,\n                    None, MediaPlayer, ctypes.c_uint, ctypes.c_int)\n    return f(p_mi, option, value)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting logo option as string.", "response": "def libvlc_video_set_logo_string(p_mi, option, psz_value):\n    '''Set logo option as string. Options that take a different type value\n    are ignored.\n    @param p_mi: libvlc media player instance.\n    @param option: logo option to set, values of libvlc_video_logo_option_t.\n    @param psz_value: logo option value.\n    '''\n    f = _Cfunctions.get('libvlc_video_set_logo_string', None) or \\\n        _Cfunction('libvlc_video_set_logo_string', ((1,), (1,), (1,),), None,\n                    None, MediaPlayer, ctypes.c_uint, ctypes.c_char_p)\n    return f(p_mi, option, psz_value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget float adjust option.", "response": "def libvlc_video_get_adjust_float(p_mi, option):\n    '''Get float adjust option.\n    @param p_mi: libvlc media player instance.\n    @param option: adjust option to get, values of libvlc_video_adjust_option_t.\n    @version: LibVLC 1.1.1 and later.\n    '''\n    f = _Cfunctions.get('libvlc_video_get_adjust_float', None) or \\\n        _Cfunction('libvlc_video_get_adjust_float', ((1,), (1,),), None,\n                    ctypes.c_float, MediaPlayer, ctypes.c_uint)\n    return f(p_mi, option)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef libvlc_video_set_adjust_float(p_mi, option, value):\n    '''Set adjust option as float. Options that take a different type value\n    are ignored.\n    @param p_mi: libvlc media player instance.\n    @param option: adust option to set, values of libvlc_video_adjust_option_t.\n    @param value: adjust option value.\n    @version: LibVLC 1.1.1 and later.\n    '''\n    f = _Cfunctions.get('libvlc_video_set_adjust_float', None) or \\\n        _Cfunction('libvlc_video_set_adjust_float', ((1,), (1,), (1,),), None,\n                    None, MediaPlayer, ctypes.c_uint, ctypes.c_float)\n    return f(p_mi, option, value)", "response": "Set adjust option as float."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef libvlc_audio_output_list_get(p_instance):\n    '''Gets the list of available audio output modules.\n    @param p_instance: libvlc instance.\n    @return: list of available audio outputs. It must be freed it with In case of error, NULL is returned.\n    '''\n    f = _Cfunctions.get('libvlc_audio_output_list_get', None) or \\\n        _Cfunction('libvlc_audio_output_list_get', ((1,),), None,\n                    ctypes.POINTER(AudioOutput), Instance)\n    return f(p_instance)", "response": "Gets the list of available audio output modules."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef libvlc_audio_output_list_release(p_list):\n    '''Frees the list of available audio output modules.\n    @param p_list: list with audio outputs for release.\n    '''\n    f = _Cfunctions.get('libvlc_audio_output_list_release', None) or \\\n        _Cfunction('libvlc_audio_output_list_release', ((1,),), None,\n                    None, ctypes.POINTER(AudioOutput))\n    return f(p_list)", "response": "Frees the list of available audio output modules."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef libvlc_audio_output_set(p_mi, psz_name):\n    '''Selects an audio output module.\n    @note: Any change will take be effect only after playback is stopped and\n    restarted. Audio output cannot be changed while playing.\n    @param p_mi: media player.\n    @param psz_name: name of audio output, use psz_name of See L{AudioOutput}.\n    @return: 0 if function succeded, -1 on error.\n    '''\n    f = _Cfunctions.get('libvlc_audio_output_set', None) or \\\n        _Cfunction('libvlc_audio_output_set', ((1,), (1,),), None,\n                    ctypes.c_int, MediaPlayer, ctypes.c_char_p)\n    return f(p_mi, psz_name)", "response": "Selects an audio output module."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef libvlc_audio_output_device_enum(mp):\n    '''Gets a list of potential audio output devices,\n    See L{libvlc_audio_output_device_set}().\n    @note: Not all audio outputs support enumerating devices.\n    The audio output may be functional even if the list is empty (NULL).\n    @note: The list may not be exhaustive.\n    @warning: Some audio output devices in the list might not actually work in\n    some circumstances. By default, it is recommended to not specify any\n    explicit audio device.\n    @param mp: media player.\n    @return: A NULL-terminated linked list of potential audio output devices. It must be freed it with L{libvlc_audio_output_device_list_release}().\n    @version: LibVLC 2.2.0 or later.\n    '''\n    f = _Cfunctions.get('libvlc_audio_output_device_enum', None) or \\\n        _Cfunction('libvlc_audio_output_device_enum', ((1,),), None,\n                    ctypes.POINTER(AudioOutputDevice), MediaPlayer)\n    return f(mp)", "response": "Get a list of potential audio output devices."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a list of audio output devices for a given audio output module.", "response": "def libvlc_audio_output_device_list_get(p_instance, aout):\n    '''Gets a list of audio output devices for a given audio output module,\n    See L{libvlc_audio_output_device_set}().\n    @note: Not all audio outputs support this. In particular, an empty (NULL)\n    list of devices does B{not} imply that the specified audio output does\n    not work.\n    @note: The list might not be exhaustive.\n    @warning: Some audio output devices in the list might not actually work in\n    some circumstances. By default, it is recommended to not specify any\n    explicit audio device.\n    @param p_instance: libvlc instance.\n    @param psz_aout: audio output name (as returned by L{libvlc_audio_output_list_get}()).\n    @return: A NULL-terminated linked list of potential audio output devices. It must be freed it with L{libvlc_audio_output_device_list_release}().\n    @version: LibVLC 2.1.0 or later.\n    '''\n    f = _Cfunctions.get('libvlc_audio_output_device_list_get', None) or \\\n        _Cfunction('libvlc_audio_output_device_list_get', ((1,), (1,),), None,\n                    ctypes.POINTER(AudioOutputDevice), Instance, ctypes.c_char_p)\n    return f(p_instance, aout)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfreeing a list of available audio output devices.", "response": "def libvlc_audio_output_device_list_release(p_list):\n    '''Frees a list of available audio output devices.\n    @param p_list: list with audio outputs for release.\n    @version: LibVLC 2.1.0 or later.\n    '''\n    f = _Cfunctions.get('libvlc_audio_output_device_list_release', None) or \\\n        _Cfunction('libvlc_audio_output_device_list_release', ((1,),), None,\n                    None, ctypes.POINTER(AudioOutputDevice))\n    return f(p_list)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef libvlc_audio_output_device_set(mp, module, device_id):\n    '''Configures an explicit audio output device.\n    If the module paramater is NULL, audio output will be moved to the device\n    specified by the device identifier string immediately. This is the\n    recommended usage.\n    A list of adequate potential device strings can be obtained with\n    L{libvlc_audio_output_device_enum}().\n    However passing NULL is supported in LibVLC version 2.2.0 and later only;\n    in earlier versions, this function would have no effects when the module\n    parameter was NULL.\n    If the module parameter is not NULL, the device parameter of the\n    corresponding audio output, if it exists, will be set to the specified\n    string. Note that some audio output modules do not have such a parameter\n    (notably MMDevice and PulseAudio).\n    A list of adequate potential device strings can be obtained with\n    L{libvlc_audio_output_device_list_get}().\n    @note: This function does not select the specified audio output plugin.\n    L{libvlc_audio_output_set}() is used for that purpose.\n    @warning: The syntax for the device parameter depends on the audio output.\n    Some audio output modules require further parameters (e.g. a channels map\n    in the case of ALSA).\n    @param mp: media player.\n    @param module: If NULL, current audio output module. if non-NULL, name of audio output module.\n    @param device_id: device identifier string.\n    @return: Nothing. Errors are ignored (this is a design bug).\n    '''\n    f = _Cfunctions.get('libvlc_audio_output_device_set', None) or \\\n        _Cfunction('libvlc_audio_output_device_set', ((1,), (1,), (1,),), None,\n                    None, MediaPlayer, ctypes.c_char_p, ctypes.c_char_p)\n    return f(mp, module, device_id)", "response": "Configures an explicit audio output device."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the current audio output device identifier.", "response": "def libvlc_audio_output_device_get(mp):\n    '''Get the current audio output device identifier.\n    This complements L{libvlc_audio_output_device_set}().\n    @warning: The initial value for the current audio output device identifier\n    may not be set or may be some unknown value. A LibVLC application should\n    compare this value against the known device identifiers (e.g. those that\n    were previously retrieved by a call to L{libvlc_audio_output_device_enum} or\n    L{libvlc_audio_output_device_list_get}) to find the current audio output device.\n    It is possible that the selected audio output device changes (an external\n    change) without a call to L{libvlc_audio_output_device_set}. That may make this\n    method unsuitable to use if a LibVLC application is attempting to track\n    dynamic audio device changes as they happen.\n    @param mp: media player.\n    @return: the current audio output device identifier NULL if no device is selected or in case of error (the result must be released with free() or L{libvlc_free}()).\n    @version: LibVLC 3.0.0 or later.\n    '''\n    f = _Cfunctions.get('libvlc_audio_output_device_get', None) or \\\n        _Cfunction('libvlc_audio_output_device_get', ((1,),), None,\n                    ctypes.c_char_p, MediaPlayer)\n    return f(mp)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef libvlc_audio_set_mute(p_mi, status):\n    '''Set mute status.\n    @param p_mi: media player.\n    @param status: If status is true then mute, otherwise unmute @warning This function does not always work. If there are no active audio playback stream, the mute status might not be available. If digital pass-through (S/PDIF, HDMI...) is in use, muting may be unapplicable. Also some audio output plugins do not support muting at all. @note To force silent playback, disable all audio tracks. This is more efficient and reliable than mute.\n    '''\n    f = _Cfunctions.get('libvlc_audio_set_mute', None) or \\\n        _Cfunction('libvlc_audio_set_mute', ((1,), (1,),), None,\n                    None, MediaPlayer, ctypes.c_int)\n    return f(p_mi, status)", "response": "Set mute status.\n    @param p_mi: media player.\n    @param status: If status is true then mute, otherwise unmute @warning This function does not always work. If there are no active audio playback stream, the mute status might not be available. If digital pass-through (S/PDIF, HDMI...) is in use, muting may be unapplicable. Also some audio output plugins do not support muting at all. @note To force silent playback, disable all audio tracks. This is more efficient and reliable than mute."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef libvlc_audio_set_volume(p_mi, i_volume):\n    '''Set current software audio volume.\n    @param p_mi: media player.\n    @param i_volume: the volume in percents (0 = mute, 100 = 0dB).\n    @return: 0 if the volume was set, -1 if it was out of range.\n    '''\n    f = _Cfunctions.get('libvlc_audio_set_volume', None) or \\\n        _Cfunction('libvlc_audio_set_volume', ((1,), (1,),), None,\n                    ctypes.c_int, MediaPlayer, ctypes.c_int)\n    return f(p_mi, i_volume)", "response": "Set current software audio volume."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset current audio track.", "response": "def libvlc_audio_set_track(p_mi, i_track):\n    '''Set current audio track.\n    @param p_mi: media player.\n    @param i_track: the track ID (i_id field from track description).\n    @return: 0 on success, -1 on error.\n    '''\n    f = _Cfunctions.get('libvlc_audio_set_track', None) or \\\n        _Cfunction('libvlc_audio_set_track', ((1,), (1,),), None,\n                    ctypes.c_int, MediaPlayer, ctypes.c_int)\n    return f(p_mi, i_track)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef libvlc_audio_set_channel(p_mi, channel):\n    '''Set current audio channel.\n    @param p_mi: media player.\n    @param channel: the audio channel, See libvlc_audio_output_channel_t.\n    @return: 0 on success, -1 on error.\n    '''\n    f = _Cfunctions.get('libvlc_audio_set_channel', None) or \\\n        _Cfunction('libvlc_audio_set_channel', ((1,), (1,),), None,\n                    ctypes.c_int, MediaPlayer, ctypes.c_int)\n    return f(p_mi, channel)", "response": "Set current audio channel."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef libvlc_audio_get_delay(p_mi):\n    '''Get current audio delay.\n    @param p_mi: media player.\n    @return: the audio delay (microseconds).\n    @version: LibVLC 1.1.1 or later.\n    '''\n    f = _Cfunctions.get('libvlc_audio_get_delay', None) or \\\n        _Cfunction('libvlc_audio_get_delay', ((1,),), None,\n                    ctypes.c_int64, MediaPlayer)\n    return f(p_mi)", "response": "Get current audio delay."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef libvlc_audio_equalizer_get_preset_name(u_index):\n    '''Get the name of a particular equalizer preset.\n    This name can be used, for example, to prepare a preset label or menu in a user\n    interface.\n    @param u_index: index of the preset, counting from zero.\n    @return: preset name, or NULL if there is no such preset.\n    @version: LibVLC 2.2.0 or later.\n    '''\n    f = _Cfunctions.get('libvlc_audio_equalizer_get_preset_name', None) or \\\n        _Cfunction('libvlc_audio_equalizer_get_preset_name', ((1,),), None,\n                    ctypes.c_char_p, ctypes.c_uint)\n    return f(u_index)", "response": "Get the name of a particular equalizer preset."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef libvlc_audio_equalizer_get_band_frequency(u_index):\n    '''Get a particular equalizer band frequency.\n    This value can be used, for example, to create a label for an equalizer band control\n    in a user interface.\n    @param u_index: index of the band, counting from zero.\n    @return: equalizer band frequency (Hz), or -1 if there is no such band.\n    @version: LibVLC 2.2.0 or later.\n    '''\n    f = _Cfunctions.get('libvlc_audio_equalizer_get_band_frequency', None) or \\\n        _Cfunction('libvlc_audio_equalizer_get_band_frequency', ((1,),), None,\n                    ctypes.c_float, ctypes.c_uint)\n    return f(u_index)", "response": "Get a particular equalizer band frequency."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new equalizer with initial frequency values copied from an existing preset.", "response": "def libvlc_audio_equalizer_new_from_preset(u_index):\n    '''Create a new equalizer, with initial frequency values copied from an existing\n    preset.\n    The new equalizer can subsequently be applied to a media player by invoking\n    L{libvlc_media_player_set_equalizer}().\n    The returned handle should be freed via L{libvlc_audio_equalizer_release}() when\n    it is no longer needed.\n    @param u_index: index of the preset, counting from zero.\n    @return: opaque equalizer handle, or NULL on error.\n    @version: LibVLC 2.2.0 or later.\n    '''\n    f = _Cfunctions.get('libvlc_audio_equalizer_new_from_preset', None) or \\\n        _Cfunction('libvlc_audio_equalizer_new_from_preset', ((1,),), None,\n                    ctypes.c_void_p, ctypes.c_uint)\n    return f(u_index)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrelease a previously created equalizer instance.", "response": "def libvlc_audio_equalizer_release(p_equalizer):\n    '''Release a previously created equalizer instance.\n    The equalizer was previously created by using L{libvlc_audio_equalizer_new}() or\n    L{libvlc_audio_equalizer_new_from_preset}().\n    It is safe to invoke this method with a NULL p_equalizer parameter for no effect.\n    @param p_equalizer: opaque equalizer handle, or NULL.\n    @version: LibVLC 2.2.0 or later.\n    '''\n    f = _Cfunctions.get('libvlc_audio_equalizer_release', None) or \\\n        _Cfunction('libvlc_audio_equalizer_release', ((1,),), None,\n                    None, ctypes.c_void_p)\n    return f(p_equalizer)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting a new pre - amplification value for an equalizer.", "response": "def libvlc_audio_equalizer_set_preamp(p_equalizer, f_preamp):\n    '''Set a new pre-amplification value for an equalizer.\n    The new equalizer settings are subsequently applied to a media player by invoking\n    L{libvlc_media_player_set_equalizer}().\n    The supplied amplification value will be clamped to the -20.0 to +20.0 range.\n    @param p_equalizer: valid equalizer handle, must not be NULL.\n    @param f_preamp: preamp value (-20.0 to 20.0 Hz).\n    @return: zero on success, -1 on error.\n    @version: LibVLC 2.2.0 or later.\n    '''\n    f = _Cfunctions.get('libvlc_audio_equalizer_set_preamp', None) or \\\n        _Cfunction('libvlc_audio_equalizer_set_preamp', ((1,), (1,),), None,\n                    ctypes.c_int, ctypes.c_void_p, ctypes.c_float)\n    return f(p_equalizer, f_preamp)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef libvlc_audio_equalizer_get_preamp(p_equalizer):\n    '''Get the current pre-amplification value from an equalizer.\n    @param p_equalizer: valid equalizer handle, must not be NULL.\n    @return: preamp value (Hz).\n    @version: LibVLC 2.2.0 or later.\n    '''\n    f = _Cfunctions.get('libvlc_audio_equalizer_get_preamp', None) or \\\n        _Cfunction('libvlc_audio_equalizer_get_preamp', ((1,),), None,\n                    ctypes.c_float, ctypes.c_void_p)\n    return f(p_equalizer)", "response": "Get the current pre - amplification value from an equalizer."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset a new amplification value for a particular equalizer frequency band.", "response": "def libvlc_audio_equalizer_set_amp_at_index(p_equalizer, f_amp, u_band):\n    '''Set a new amplification value for a particular equalizer frequency band.\n    The new equalizer settings are subsequently applied to a media player by invoking\n    L{libvlc_media_player_set_equalizer}().\n    The supplied amplification value will be clamped to the -20.0 to +20.0 range.\n    @param p_equalizer: valid equalizer handle, must not be NULL.\n    @param f_amp: amplification value (-20.0 to 20.0 Hz).\n    @param u_band: index, counting from zero, of the frequency band to set.\n    @return: zero on success, -1 on error.\n    @version: LibVLC 2.2.0 or later.\n    '''\n    f = _Cfunctions.get('libvlc_audio_equalizer_set_amp_at_index', None) or \\\n        _Cfunction('libvlc_audio_equalizer_set_amp_at_index', ((1,), (1,), (1,),), None,\n                    ctypes.c_int, ctypes.c_void_p, ctypes.c_float, ctypes.c_uint)\n    return f(p_equalizer, f_amp, u_band)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef libvlc_audio_equalizer_get_amp_at_index(p_equalizer, u_band):\n    '''Get the amplification value for a particular equalizer frequency band.\n    @param p_equalizer: valid equalizer handle, must not be NULL.\n    @param u_band: index, counting from zero, of the frequency band to get.\n    @return: amplification value (Hz); NaN if there is no such frequency band.\n    @version: LibVLC 2.2.0 or later.\n    '''\n    f = _Cfunctions.get('libvlc_audio_equalizer_get_amp_at_index', None) or \\\n        _Cfunction('libvlc_audio_equalizer_get_amp_at_index', ((1,), (1,),), None,\n                    ctypes.c_float, ctypes.c_void_p, ctypes.c_uint)\n    return f(p_equalizer, u_band)", "response": "Get the amplification value for a particular equalizer frequency band."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef libvlc_media_player_set_equalizer(p_mi, p_equalizer):\n    '''Apply new equalizer settings to a media player.\n    The equalizer is first created by invoking L{libvlc_audio_equalizer_new}() or\n    L{libvlc_audio_equalizer_new_from_preset}().\n    It is possible to apply new equalizer settings to a media player whether the media\n    player is currently playing media or not.\n    Invoking this method will immediately apply the new equalizer settings to the audio\n    output of the currently playing media if there is any.\n    If there is no currently playing media, the new equalizer settings will be applied\n    later if and when new media is played.\n    Equalizer settings will automatically be applied to subsequently played media.\n    To disable the equalizer for a media player invoke this method passing NULL for the\n    p_equalizer parameter.\n    The media player does not keep a reference to the supplied equalizer so it is safe\n    for an application to release the equalizer reference any time after this method\n    returns.\n    @param p_mi: opaque media player handle.\n    @param p_equalizer: opaque equalizer handle, or NULL to disable the equalizer for this media player.\n    @return: zero on success, -1 on error.\n    @version: LibVLC 2.2.0 or later.\n    '''\n    f = _Cfunctions.get('libvlc_media_player_set_equalizer', None) or \\\n        _Cfunction('libvlc_media_player_set_equalizer', ((1,), (1,),), None,\n                    ctypes.c_int, MediaPlayer, ctypes.c_void_p)\n    return f(p_mi, p_equalizer)", "response": "Set new equalizer settings for a media player."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef libvlc_vlm_add_broadcast(p_instance, psz_name, psz_input, psz_output, i_options, ppsz_options, b_enabled, b_loop):\n    '''Add a broadcast, with one input.\n    @param p_instance: the instance.\n    @param psz_name: the name of the new broadcast.\n    @param psz_input: the input MRL.\n    @param psz_output: the output MRL (the parameter to the \"sout\" variable).\n    @param i_options: number of additional options.\n    @param ppsz_options: additional options.\n    @param b_enabled: boolean for enabling the new broadcast.\n    @param b_loop: Should this broadcast be played in loop ?\n    @return: 0 on success, -1 on error.\n    '''\n    f = _Cfunctions.get('libvlc_vlm_add_broadcast', None) or \\\n        _Cfunction('libvlc_vlm_add_broadcast', ((1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,),), None,\n                    ctypes.c_int, Instance, ctypes.c_char_p, ctypes.c_char_p, ctypes.c_char_p, ctypes.c_int, ListPOINTER(ctypes.c_char_p), ctypes.c_int, ctypes.c_int)\n    return f(p_instance, psz_name, psz_input, psz_output, i_options, ppsz_options, b_enabled, b_loop)", "response": "Add a broadcast with one input."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a vod with one input.", "response": "def libvlc_vlm_add_vod(p_instance, psz_name, psz_input, i_options, ppsz_options, b_enabled, psz_mux):\n    '''Add a vod, with one input.\n    @param p_instance: the instance.\n    @param psz_name: the name of the new vod media.\n    @param psz_input: the input MRL.\n    @param i_options: number of additional options.\n    @param ppsz_options: additional options.\n    @param b_enabled: boolean for enabling the new vod.\n    @param psz_mux: the muxer of the vod media.\n    @return: 0 on success, -1 on error.\n    '''\n    f = _Cfunctions.get('libvlc_vlm_add_vod', None) or \\\n        _Cfunction('libvlc_vlm_add_vod', ((1,), (1,), (1,), (1,), (1,), (1,), (1,),), None,\n                    ctypes.c_int, Instance, ctypes.c_char_p, ctypes.c_char_p, ctypes.c_int, ListPOINTER(ctypes.c_char_p), ctypes.c_int, ctypes.c_char_p)\n    return f(p_instance, psz_name, psz_input, i_options, ppsz_options, b_enabled, psz_mux)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes a media from the vlm.", "response": "def libvlc_vlm_del_media(p_instance, psz_name):\n    '''Delete a media (VOD or broadcast).\n    @param p_instance: the instance.\n    @param psz_name: the media to delete.\n    @return: 0 on success, -1 on error.\n    '''\n    f = _Cfunctions.get('libvlc_vlm_del_media', None) or \\\n        _Cfunction('libvlc_vlm_del_media', ((1,), (1,),), None,\n                    ctypes.c_int, Instance, ctypes.c_char_p)\n    return f(p_instance, psz_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nenables or disable a media.", "response": "def libvlc_vlm_set_enabled(p_instance, psz_name, b_enabled):\n    '''Enable or disable a media (VOD or broadcast).\n    @param p_instance: the instance.\n    @param psz_name: the media to work on.\n    @param b_enabled: the new status.\n    @return: 0 on success, -1 on error.\n    '''\n    f = _Cfunctions.get('libvlc_vlm_set_enabled', None) or \\\n        _Cfunction('libvlc_vlm_set_enabled', ((1,), (1,), (1,),), None,\n                    ctypes.c_int, Instance, ctypes.c_char_p, ctypes.c_int)\n    return f(p_instance, psz_name, b_enabled)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef libvlc_vlm_set_output(p_instance, psz_name, psz_output):\n    '''Set the output for a media.\n    @param p_instance: the instance.\n    @param psz_name: the media to work on.\n    @param psz_output: the output MRL (the parameter to the \"sout\" variable).\n    @return: 0 on success, -1 on error.\n    '''\n    f = _Cfunctions.get('libvlc_vlm_set_output', None) or \\\n        _Cfunction('libvlc_vlm_set_output', ((1,), (1,), (1,),), None,\n                    ctypes.c_int, Instance, ctypes.c_char_p, ctypes.c_char_p)\n    return f(p_instance, psz_name, psz_output)", "response": "Set the output for a media."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef libvlc_vlm_set_input(p_instance, psz_name, psz_input):\n    '''Set a media's input MRL. This will delete all existing inputs and\n    add the specified one.\n    @param p_instance: the instance.\n    @param psz_name: the media to work on.\n    @param psz_input: the input MRL.\n    @return: 0 on success, -1 on error.\n    '''\n    f = _Cfunctions.get('libvlc_vlm_set_input', None) or \\\n        _Cfunction('libvlc_vlm_set_input', ((1,), (1,), (1,),), None,\n                    ctypes.c_int, Instance, ctypes.c_char_p, ctypes.c_char_p)\n    return f(p_instance, psz_name, psz_input)", "response": "Set a media s input MRL."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef libvlc_vlm_set_loop(p_instance, psz_name, b_loop):\n    '''Set a media's loop status.\n    @param p_instance: the instance.\n    @param psz_name: the media to work on.\n    @param b_loop: the new status.\n    @return: 0 on success, -1 on error.\n    '''\n    f = _Cfunctions.get('libvlc_vlm_set_loop', None) or \\\n        _Cfunction('libvlc_vlm_set_loop', ((1,), (1,), (1,),), None,\n                    ctypes.c_int, Instance, ctypes.c_char_p, ctypes.c_int)\n    return f(p_instance, psz_name, b_loop)", "response": "Set a media s loop status."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef libvlc_vlm_set_mux(p_instance, psz_name, psz_mux):\n    '''Set a media's vod muxer.\n    @param p_instance: the instance.\n    @param psz_name: the media to work on.\n    @param psz_mux: the new muxer.\n    @return: 0 on success, -1 on error.\n    '''\n    f = _Cfunctions.get('libvlc_vlm_set_mux', None) or \\\n        _Cfunction('libvlc_vlm_set_mux', ((1,), (1,), (1,),), None,\n                    ctypes.c_int, Instance, ctypes.c_char_p, ctypes.c_char_p)\n    return f(p_instance, psz_name, psz_mux)", "response": "Set a media s vod muxer."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nseek in the named broadcast.", "response": "def libvlc_vlm_seek_media(p_instance, psz_name, f_percentage):\n    '''Seek in the named broadcast.\n    @param p_instance: the instance.\n    @param psz_name: the name of the broadcast.\n    @param f_percentage: the percentage to seek to.\n    @return: 0 on success, -1 on error.\n    '''\n    f = _Cfunctions.get('libvlc_vlm_seek_media', None) or \\\n        _Cfunction('libvlc_vlm_seek_media', ((1,), (1,), (1,),), None,\n                    ctypes.c_int, Instance, ctypes.c_char_p, ctypes.c_float)\n    return f(p_instance, psz_name, f_percentage)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns information about the named media as a JSON string representation.", "response": "def libvlc_vlm_show_media(p_instance, psz_name):\n    '''Return information about the named media as a JSON\n    string representation.\n    This function is mainly intended for debugging use,\n    if you want programmatic access to the state of\n    a vlm_media_instance_t, please use the corresponding\n    libvlc_vlm_get_media_instance_xxx -functions.\n    Currently there are no such functions available for\n    vlm_media_t though.\n    @param p_instance: the instance.\n    @param psz_name: the name of the media, if the name is an empty string, all media is described.\n    @return: string with information about named media, or NULL on error.\n    '''\n    f = _Cfunctions.get('libvlc_vlm_show_media', None) or \\\n        _Cfunction('libvlc_vlm_show_media', ((1,), (1,),), string_result,\n                    ctypes.c_void_p, Instance, ctypes.c_char_p)\n    return f(p_instance, psz_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef libvlc_vlm_get_media_instance_position(p_instance, psz_name, i_instance):\n    '''Get vlm_media instance position by name or instance id.\n    @param p_instance: a libvlc instance.\n    @param psz_name: name of vlm media instance.\n    @param i_instance: instance id.\n    @return: position as float or -1. on error.\n    '''\n    f = _Cfunctions.get('libvlc_vlm_get_media_instance_position', None) or \\\n        _Cfunction('libvlc_vlm_get_media_instance_position', ((1,), (1,), (1,),), None,\n                    ctypes.c_float, Instance, ctypes.c_char_p, ctypes.c_int)\n    return f(p_instance, psz_name, i_instance)", "response": "Get vlm_media instance position by name or instance id."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets vlm_media instance time by name or instance id.", "response": "def libvlc_vlm_get_media_instance_time(p_instance, psz_name, i_instance):\n    '''Get vlm_media instance time by name or instance id.\n    @param p_instance: a libvlc instance.\n    @param psz_name: name of vlm media instance.\n    @param i_instance: instance id.\n    @return: time as integer or -1 on error.\n    '''\n    f = _Cfunctions.get('libvlc_vlm_get_media_instance_time', None) or \\\n        _Cfunction('libvlc_vlm_get_media_instance_time', ((1,), (1,), (1,),), None,\n                    ctypes.c_int, Instance, ctypes.c_char_p, ctypes.c_int)\n    return f(p_instance, psz_name, i_instance)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef libvlc_vlm_get_event_manager(p_instance):\n    '''Get libvlc_event_manager from a vlm media.\n    The p_event_manager is immutable, so you don't have to hold the lock.\n    @param p_instance: a libvlc instance.\n    @return: libvlc_event_manager.\n    '''\n    f = _Cfunctions.get('libvlc_vlm_get_event_manager', None) or \\\n        _Cfunction('libvlc_vlm_get_event_manager', ((1,),), class_result(EventManager),\n                    ctypes.c_void_p, Instance)\n    return f(p_instance)", "response": "Get libvlc_event_manager from a vlm media."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _dot2int(v):\n    '''(INTERNAL) Convert 'i.i.i[.i]' str to int.\n    '''\n    t = [int(i) for i in v.split('.')]\n    if len(t) == 3:\n        t.append(0)\n    elif len(t) != 4:\n        raise ValueError('\"i.i.i[.i]\": %r' % (v,))\n    if min(t) < 0 or max(t) > 255:\n        raise ValueError('[0..255]: %r' % (v,))\n    i = t.pop(0)\n    while t:\n        i = (i << 8) + t.pop(0)\n    return i", "response": "Convert a dot - separated string to int.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef debug_callback(event, *args, **kwds):\n    '''Example callback, useful for debugging.\n    '''\n    l = ['event %s' % (event.type,)]\n    if args:\n        l.extend(map(str, args))\n    if kwds:\n        l.extend(sorted('%s=%s' % t for t in kwds.items()))\n    print('Debug callback (%s)' % ', '.join(l))", "response": "Example callback useful for debugging.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nregister an event notification.", "response": "def event_attach(self, eventtype, callback, *args, **kwds):\n        \"\"\"Register an event notification.\n\n        @param eventtype: the desired event type to be notified about.\n        @param callback: the function to call when the event occurs.\n        @param args: optional positional arguments for the callback.\n        @param kwds: optional keyword arguments for the callback.\n        @return: 0 on success, ENOMEM on error.\n\n        @note: The callback function must have at least one argument,\n        an Event instance.  Any other, optional positional and keyword\n        arguments are in B{addition} to the first one.\n        \"\"\"\n        if not isinstance(eventtype, EventType):\n            raise VLCException(\"%s required: %r\" % ('EventType', eventtype))\n        if not hasattr(callback, '__call__'):  # callable()\n            raise VLCException(\"%s required: %r\" % ('callable', callback))\n         # check that the callback expects arguments\n        if not any(getargspec(callback)[:2]):  # list(...)\n            raise VLCException(\"%s required: %r\" % ('argument', callback))\n\n        if self._callback_handler is None:\n            _called_from_ctypes = ctypes.CFUNCTYPE(None, ctypes.POINTER(Event), ctypes.c_void_p)\n            @_called_from_ctypes\n            def _callback_handler(event, k):\n                \"\"\"(INTERNAL) handle callback call from ctypes.\n\n                @note: We cannot simply make this an EventManager\n                method since ctypes does not prepend self as the\n                first parameter, hence this closure.\n                \"\"\"\n                try: # retrieve Python callback and arguments\n                    call, args, kwds = self._callbacks[k]\n                     # deref event.contents to simplify callback code\n                    call(event.contents, *args, **kwds)\n                except KeyError:  # detached?\n                    pass\n            self._callback_handler = _callback_handler\n            self._callbacks = {}\n\n        k = eventtype.value\n        r = libvlc_event_attach(self, k, self._callback_handler, k)\n        if not r:\n            self._callbacks[k] = (callback, args, kwds)\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new MediaPlayer instance.", "response": "def media_player_new(self, uri=None):\n        \"\"\"Create a new MediaPlayer instance.\n\n        @param uri: an optional URI to play in the player.\n        \"\"\"\n        p = libvlc_media_player_new(self)\n        if uri:\n            p.set_media(self.media_new(uri))\n        p._instance = self\n        return p"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new Media instance.", "response": "def media_new(self, mrl, *options):\n        \"\"\"Create a new Media instance.\n\n        If mrl contains a colon (:) preceded by more than 1 letter, it\n        will be treated as a URL. Else, it will be considered as a\n        local path. If you need more control, directly use\n        media_new_location/media_new_path methods.\n\n        Options can be specified as supplementary string parameters,\n        but note that many options cannot be set at the media level,\n        and rather at the Instance level. For instance, the marquee\n        filter must be specified when creating the vlc.Instance or\n        vlc.MediaPlayer.\n\n        Alternatively, options can be added to the media using the\n        Media.add_options method (with the same limitation).\n\n        @param options: optional media option=value strings\n        \"\"\"\n        if ':' in mrl and mrl.index(':') > 1:\n            # Assume it is a URL\n            m = libvlc_media_new_location(self, str_to_bytes(mrl))\n        else:\n            # Else it should be a local path.\n            m = libvlc_media_new_path(self, str_to_bytes(os.path.normpath(mrl)))\n        for o in options:\n            libvlc_media_add_option(m, str_to_bytes(o))\n        m._instance = self\n        return m"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef media_list_new(self, mrls=None):\n        l = libvlc_media_list_new(self)\n        # We should take the lock, but since we did not leak the\n        # reference, nobody else can access it.\n        if mrls:\n            for m in mrls:\n                l.add_media(m)\n        l._instance = self\n        return l", "response": "Create a new MediaList instance."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nenumerating the defined audio output devices.", "response": "def audio_output_enumerate_devices(self):\n        \"\"\"Enumerate the defined audio output devices.\n\n        @return: list of dicts {name:, description:, devices:}\n        \"\"\"\n        r = []\n        head = libvlc_audio_output_list_get(self)\n        if head:\n            i = head\n            while i:\n                i = i.contents\n                d = [{'id':       libvlc_audio_output_device_id      (self, i.name, d),\n                      'longname': libvlc_audio_output_device_longname(self, i.name, d)}\n                   for d in range(libvlc_audio_output_device_count   (self, i.name))]\n                r.append({'name': i.name, 'description': i.description, 'devices': d})\n                i = i.next\n            libvlc_audio_output_list_release(head)\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset some meta - information about the application.", "response": "def set_app_id(self, id, version, icon):\n        '''Sets some meta-information about the application.\n        See also L{set_user_agent}().\n        @param id: Java-style application identifier, e.g. \"com.acme.foobar\".\n        @param version: application version numbers, e.g. \"1.2.3\".\n        @param icon: application icon name, e.g. \"foobar\".\n        @version: LibVLC 2.1.0 or later.\n        '''\n        return libvlc_set_app_id(self, str_to_bytes(id), str_to_bytes(version), str_to_bytes(icon))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef media_new_callbacks(self, open_cb, read_cb, seek_cb, close_cb, opaque):\n        '''Create a media with custom callbacks to read the data from.\n        @param open_cb: callback to open the custom bitstream input media.\n        @param read_cb: callback to read data (must not be NULL).\n        @param seek_cb: callback to seek, or NULL if seeking is not supported.\n        @param close_cb: callback to close the media, or NULL if unnecessary.\n        @param opaque: data pointer for the open callback.\n        @return: the newly created media or NULL on error @note If open_cb is NULL, the opaque pointer will be passed to read_cb, seek_cb and close_cb, and the stream size will be treated as unknown. @note The callbacks may be called asynchronously (from another thread). A single stream instance need not be reentrant. However the open_cb needs to be reentrant if the media is used by multiple player instances. @warning The callbacks may be used until all or any player instances that were supplied the media item are stopped. See L{media_release}.\n        @version: LibVLC 3.0.0 and later.\n        '''\n        return libvlc_media_new_callbacks(self, open_cb, read_cb, seek_cb, close_cb, opaque)", "response": "Create a media with custom callbacks to read the data from."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a broadcast with one input.", "response": "def vlm_add_broadcast(self, psz_name, psz_input, psz_output, i_options, ppsz_options, b_enabled, b_loop):\n        '''Add a broadcast, with one input.\n        @param psz_name: the name of the new broadcast.\n        @param psz_input: the input MRL.\n        @param psz_output: the output MRL (the parameter to the \"sout\" variable).\n        @param i_options: number of additional options.\n        @param ppsz_options: additional options.\n        @param b_enabled: boolean for enabling the new broadcast.\n        @param b_loop: Should this broadcast be played in loop ?\n        @return: 0 on success, -1 on error.\n        '''\n        return libvlc_vlm_add_broadcast(self, str_to_bytes(psz_name), str_to_bytes(psz_input), str_to_bytes(psz_output), i_options, ppsz_options, b_enabled, b_loop)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef vlm_add_vod(self, psz_name, psz_input, i_options, ppsz_options, b_enabled, psz_mux):\n        '''Add a vod, with one input.\n        @param psz_name: the name of the new vod media.\n        @param psz_input: the input MRL.\n        @param i_options: number of additional options.\n        @param ppsz_options: additional options.\n        @param b_enabled: boolean for enabling the new vod.\n        @param psz_mux: the muxer of the vod media.\n        @return: 0 on success, -1 on error.\n        '''\n        return libvlc_vlm_add_vod(self, str_to_bytes(psz_name), str_to_bytes(psz_input), i_options, ppsz_options, b_enabled, str_to_bytes(psz_mux))", "response": "Add a vod with one input."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef vlm_set_output(self, psz_name, psz_output):\n        '''Set the output for a media.\n        @param psz_name: the media to work on.\n        @param psz_output: the output MRL (the parameter to the \"sout\" variable).\n        @return: 0 on success, -1 on error.\n        '''\n        return libvlc_vlm_set_output(self, str_to_bytes(psz_name), str_to_bytes(psz_output))", "response": "Set the output for a media."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef vlm_set_input(self, psz_name, psz_input):\n        '''Set a media's input MRL. This will delete all existing inputs and\n        add the specified one.\n        @param psz_name: the media to work on.\n        @param psz_input: the input MRL.\n        @return: 0 on success, -1 on error.\n        '''\n        return libvlc_vlm_set_input(self, str_to_bytes(psz_name), str_to_bytes(psz_input))", "response": "Set a media s input MRL. This will delete all existing inputs and add the specified one."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a media s input MRL. This will add the specified one.", "response": "def vlm_add_input(self, psz_name, psz_input):\n        '''Add a media's input MRL. This will add the specified one.\n        @param psz_name: the media to work on.\n        @param psz_input: the input MRL.\n        @return: 0 on success, -1 on error.\n        '''\n        return libvlc_vlm_add_input(self, str_to_bytes(psz_name), str_to_bytes(psz_input))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef vlm_set_mux(self, psz_name, psz_mux):\n        '''Set a media's vod muxer.\n        @param psz_name: the media to work on.\n        @param psz_mux: the new muxer.\n        @return: 0 on success, -1 on error.\n        '''\n        return libvlc_vlm_set_mux(self, str_to_bytes(psz_name), str_to_bytes(psz_mux))", "response": "Set a media s vod muxer."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef vlm_change_media(self, psz_name, psz_input, psz_output, i_options, ppsz_options, b_enabled, b_loop):\n        '''Edit the parameters of a media. This will delete all existing inputs and\n        add the specified one.\n        @param psz_name: the name of the new broadcast.\n        @param psz_input: the input MRL.\n        @param psz_output: the output MRL (the parameter to the \"sout\" variable).\n        @param i_options: number of additional options.\n        @param ppsz_options: additional options.\n        @param b_enabled: boolean for enabling the new broadcast.\n        @param b_loop: Should this broadcast be played in loop ?\n        @return: 0 on success, -1 on error.\n        '''\n        return libvlc_vlm_change_media(self, str_to_bytes(psz_name), str_to_bytes(psz_input), str_to_bytes(psz_output), i_options, ppsz_options, b_enabled, b_loop)", "response": "Edit the parameters of a media. This will delete all existing inputs and add the specified one."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tracks_get(self):\n        mediaTrack_pp = ctypes.POINTER(MediaTrack)()\n        n = libvlc_media_tracks_get(self, byref(mediaTrack_pp))\n        info = cast(ctypes.mediaTrack_pp, ctypes.POINTER(ctypes.POINTER(MediaTrack) * n))\n        return info", "response": "Get the elementary streams description of the media."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a media instance to the media list.", "response": "def add_media(self, mrl):\n        \"\"\"Add media instance to media list.\n        \n        The L{lock} should be held upon entering this function.\n        @param mrl: a media instance or a MRL.\n        @return: 0 on success, -1 if the media list is read-only.\n        \"\"\"\n        if isinstance(mrl, basestring):\n            mrl = (self.get_instance() or get_default_instance()).media_new(mrl)\n        return libvlc_media_list_add_media(self, mrl)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the MRL to play.", "response": "def set_mrl(self, mrl, *options):\n        \"\"\"Set the MRL to play.\n\n        Warning: most audio and video options, such as text renderer,\n        have no effects on an individual media. These options must be\n        set at the vlc.Instance or vlc.MediaPlayer instanciation.\n\n        @param mrl: The MRL\n        @param options: optional media option=value strings\n        @return: the Media object\n        \"\"\"\n        m = self.get_instance().media_new(mrl, *options)\n        self.set_media(m)\n        return m"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the video size in pixels as 2 - tuple.", "response": "def video_get_size(self, num=0):\n        \"\"\"Get the video size in pixels as 2-tuple (width, height).\n\n        @param num: video number (default 0).\n        \"\"\"\n        r = libvlc_video_get_size(self, num)\n        if isinstance(r, tuple) and len(r) == 2:\n            return r\n        else:\n            raise VLCException('invalid video number (%s)' % (num,))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting a Win32 or Win64 API window handle.", "response": "def set_hwnd(self, drawable):\n        \"\"\"Set a Win32/Win64 API window handle (HWND).\n\n        Specify where the media player should render its video\n        output. If LibVLC was built without Win32/Win64 API output\n        support, then this has no effects.\n           \n        @param drawable: windows handle of the drawable.\n        \"\"\"\n        if not isinstance(drawable, ctypes.c_void_p):\n            drawable = ctypes.c_void_p(int(drawable))\n        libvlc_media_player_set_hwnd(self, drawable)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the mouse pointer coordinates over a video.", "response": "def video_get_cursor(self, num=0):\n        \"\"\"Get the mouse pointer coordinates over a video as 2-tuple (x, y).\n\n        Coordinates are expressed in terms of the decoded video resolution,\n        B{not} in terms of pixels on the screen/viewport.  To get the\n        latter, you must query your windowing system directly.\n\n        Either coordinate may be negative or larger than the corresponding\n        size of the video, if the cursor is outside the rendering area.\n\n        @warning: The coordinates may be out-of-date if the pointer is not\n        located on the video rendering area.  LibVLC does not track the\n        mouse pointer if the latter is outside the video widget.\n\n        @note: LibVLC does not support multiple mouse pointers (but does\n        support multiple input devices sharing the same pointer).\n\n        @param num: video number (default 0).\n        \"\"\"\n        r = libvlc_video_get_cursor(self, num)\n        if isinstance(r, tuple) and len(r) == 2:\n            return r\n        raise VLCException('invalid video number (%s)' % (num,))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef video_set_callbacks(self, lock, unlock, display, opaque):\n        '''Set callbacks and private data to render decoded video to a custom area\n        in memory.\n        Use L{video_set_format}() or L{video_set_format_callbacks}()\n        to configure the decoded format.\n        @param lock: callback to lock video memory (must not be NULL).\n        @param unlock: callback to unlock video memory (or NULL if not needed).\n        @param display: callback to display video (or NULL if not needed).\n        @param opaque: private pointer for the three callbacks (as first parameter).\n        @version: LibVLC 1.1.1 or later.\n        '''\n        return libvlc_video_set_callbacks(self, lock, unlock, display, opaque)", "response": "Set callbacks and private data to render decoded video to a custom area\n        in memory."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef video_set_format(self, chroma, width, height, pitch):\n        '''Set decoded video chroma and dimensions.\n        This only works in combination with L{video_set_callbacks}(),\n        and is mutually exclusive with L{video_set_format_callbacks}().\n        @param chroma: a four-characters string identifying the chroma (e.g. \"RV32\" or \"YUYV\").\n        @param width: pixel width.\n        @param height: pixel height.\n        @param pitch: line pitch (in bytes).\n        @version: LibVLC 1.1.1 or later.\n        @bug: All pixel planes are expected to have the same pitch. To use the YCbCr color space with chrominance subsampling, consider using L{video_set_format_callbacks}() instead.\n        '''\n        return libvlc_video_set_format(self, str_to_bytes(chroma), width, height, pitch)", "response": "Set decoded video chroma and dimensions."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets callbacks and private data for decoded audio.", "response": "def audio_set_callbacks(self, play, pause, resume, flush, drain, opaque):\n        '''Set callbacks and private data for decoded audio.\n        Use L{audio_set_format}() or L{audio_set_format_callbacks}()\n        to configure the decoded audio format.\n        @param play: callback to play audio samples (must not be NULL).\n        @param pause: callback to pause playback (or NULL to ignore).\n        @param resume: callback to resume playback (or NULL to ignore).\n        @param flush: callback to flush audio buffers (or NULL to ignore).\n        @param drain: callback to drain audio buffers (or NULL to ignore).\n        @param opaque: private pointer for the audio callbacks (as first parameter).\n        @version: LibVLC 2.0.0 or later.\n        '''\n        return libvlc_audio_set_callbacks(self, play, pause, resume, flush, drain, opaque)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef audio_set_format(self, format, rate, channels):\n        '''Set decoded audio format.\n        This only works in combination with L{audio_set_callbacks}(),\n        and is mutually exclusive with L{audio_set_format_callbacks}().\n        @param format: a four-characters string identifying the sample format (e.g. \"S16N\" or \"FL32\").\n        @param rate: sample rate (expressed in Hz).\n        @param channels: channels count.\n        @version: LibVLC 2.0.0 or later.\n        '''\n        return libvlc_audio_set_format(self, str_to_bytes(format), rate, channels)", "response": "Set decoded audio format."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntake a snapshot of the current video window.", "response": "def video_take_snapshot(self, num, psz_filepath, i_width, i_height):\n        '''Take a snapshot of the current video window.\n        If i_width AND i_height is 0, original size is used.\n        If i_width XOR i_height is 0, original aspect-ratio is preserved.\n        @param num: number of video output (typically 0 for the first/only one).\n        @param psz_filepath: the path where to save the screenshot to.\n        @param i_width: the snapshot's width.\n        @param i_height: the snapshot's height.\n        @return: 0 on success, -1 if the video was not found.\n        '''\n        return libvlc_video_take_snapshot(self, num, str_to_bytes(psz_filepath), i_width, i_height)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef audio_output_device_set(self, module, device_id):\n        '''Configures an explicit audio output device.\n        If the module paramater is NULL, audio output will be moved to the device\n        specified by the device identifier string immediately. This is the\n        recommended usage.\n        A list of adequate potential device strings can be obtained with\n        L{audio_output_device_enum}().\n        However passing NULL is supported in LibVLC version 2.2.0 and later only;\n        in earlier versions, this function would have no effects when the module\n        parameter was NULL.\n        If the module parameter is not NULL, the device parameter of the\n        corresponding audio output, if it exists, will be set to the specified\n        string. Note that some audio output modules do not have such a parameter\n        (notably MMDevice and PulseAudio).\n        A list of adequate potential device strings can be obtained with\n        L{audio_output_device_list_get}().\n        @note: This function does not select the specified audio output plugin.\n        L{audio_output_set}() is used for that purpose.\n        @warning: The syntax for the device parameter depends on the audio output.\n        Some audio output modules require further parameters (e.g. a channels map\n        in the case of ALSA).\n        @param module: If NULL, current audio output module. if non-NULL, name of audio output module.\n        @param device_id: device identifier string.\n        @return: Nothing. Errors are ignored (this is a design bug).\n        '''\n        return libvlc_audio_output_device_set(self, str_to_bytes(module), str_to_bytes(device_id))", "response": "Configures an explicit audio output device."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef undoable(generator):\r\n    ''' Decorator which creates a new undoable action type.\r\n\r\n    This decorator should be used on a generator of the following format::\r\n\r\n        @undoable\r\n        def operation(*args):\r\n            do_operation_code\r\n            yield 'descriptive text'\r\n            undo_operator_code\r\n    '''\r\n\r\n    def inner(*args, **kwargs):\r\n        action = _Action(generator, args, kwargs)\r\n        ret = action.do()\r\n        stack().append(action)\r\n        if isinstance(ret, tuple):\r\n            if len(ret) == 1:\r\n                return ret[0]\r\n            elif len(ret) == 0:\r\n                return None\r\n        return ret\r\n    return inner", "response": "Decorator which creates a new undoable action type."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndoes or redo the action", "response": "def do(self):\r\n        'Do or redo the action'\r\n        self._runner = self._generator(*self.args, **self.kwargs)\r\n        rets = next(self._runner)\r\n        if isinstance(rets, tuple):\r\n            self._text = rets[0]\r\n            return rets[1:]\r\n        elif rets is None:\r\n            self._text = ''\r\n            return None\r\n        else:\r\n            self._text = rets\r\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nredo the last undone action.", "response": "def redo(self):\r\n        ''' Redo the last undone action.\r\n\r\n        This is only possible if no other actions have occurred since the\r\n        last undo call.\r\n        '''\r\n        if self.canredo():\r\n            undoable = self._redos.pop()\r\n            with self._pausereceiver():\r\n                try:\r\n                    undoable.do()\r\n                except:\r\n                    self.clear()\r\n                    raise\r\n                else:\r\n                    self._undos.append(undoable)\r\n            self.docallback()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nundo the last action.", "response": "def undo(self):\r\n        ''' Undo the last action. '''\r\n        if self.canundo():\r\n            undoable = self._undos.pop()\r\n            with self._pausereceiver():\r\n                try:\r\n                    undoable.undo()\r\n                except:\r\n                    self.clear()\r\n                    raise\r\n                else:\r\n                    self._redos.append(undoable)\r\n            self.undocallback()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nclearing the undo list.", "response": "def clear(self):\r\n        ''' Clear the undo list. '''\r\n        self._undos.clear()\r\n        self._redos.clear()\r\n        self._savepoint = None\r\n        self._receiver = self._undos"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a undoable to the stack using receiver. append.", "response": "def append(self, action):\r\n        ''' Add a undoable to the stack, using ``receiver.append()``. '''\r\n        if self._receiver is not None:\r\n            self._receiver.append(action)\r\n        if self._receiver is self._undos:\r\n            self._redos.clear()\r\n            self.docallback()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_bbox(self):\n\n        x_min = self.x\n        x_max = x_min + self.width\n        y_min = self.y\n        y_max = self.y + self.height\n\n        return x_min, x_max, y_min, y_max", "response": "Returns the bounding box of the current image."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_bbox_not_intersecting(self, other):\n\n        self_x_min, self_x_max, self_y_min, self_y_max = self.get_bbox()\n        other_x_min, other_x_max, other_y_min, other_y_max = other.get_bbox()\n\n        return \\\n            self_x_min > other_x_max or \\\n            other_x_min > self_x_max or \\\n            self_y_min > other_y_max or \\\n            other_y_min > self_y_max", "response": "Returns True iif bounding boxed of self and other intersect"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_point_in_rect(self, pt_x, pt_y):\n\n        x_min, x_max, y_min, y_max = self.get_bbox()\n\n        return x_min <= pt_x <= x_max and y_min <= pt_y <= y_max", "response": "Returns True iif point is inside the rectangle"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_bbox(self):\n\n        width = self.width\n        height = self.height\n\n        cos_angle = cos(self.angle)\n        sin_angle = sin(self.angle)\n\n        x_diff = 0.5 * width\n        y_diff = 0.5 * height\n\n        # self rotates around (0, 0).\n        c_x_diff = cos_angle * x_diff\n        s_x_diff = sin_angle * x_diff\n\n        c_y_diff = cos_angle * y_diff\n        s_y_diff = sin_angle * y_diff\n\n        if cos_angle > 0:\n            if sin_angle > 0:\n                x_max = c_x_diff + s_y_diff\n                x_min = -x_max\n                y_max = c_y_diff + s_x_diff\n                y_min = -y_max\n            else:  # sin_angle <= 0.0\n                x_max = c_x_diff - s_y_diff\n                x_min = -x_max\n                y_max = c_y_diff - s_x_diff\n                y_min = -y_max\n\n        else:  # cos(angle) <= 0.0\n            if sin_angle > 0:\n                x_min = c_x_diff - s_y_diff\n                x_max = -x_min\n                y_min = c_y_diff - s_x_diff\n                y_max = -y_min\n            else:  # sin_angle <= 0.0\n                x_min = c_x_diff + s_y_diff\n                x_max = -x_min\n                y_min = c_y_diff + s_x_diff\n                y_max = -y_min\n\n        return x_min, x_max, y_min, y_max", "response": "Returns the bounding box of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if any edge excludes all vertices of other.", "response": "def is_edge_not_excluding_vertices(self, other):\n        \"\"\"Returns False iif any edge excludes all vertices of other.\"\"\"\n\n        c_a = cos(self.angle)\n        s_a = sin(self.angle)\n\n        # Get min and max of other.\n\n        other_x_min, other_x_max, other_y_min, other_y_max = other.get_bbox()\n\n        self_x_diff = 0.5 * self.width\n        self_y_diff = 0.5 * self.height\n\n        if c_a > 0:\n            if s_a > 0:\n                return \\\n                    c_a * other_x_max + s_a * other_y_max < -self_x_diff or \\\n                    c_a * other_x_min + s_a * other_y_min >  self_x_diff or \\\n                    c_a * other_y_max - s_a * other_x_min < -self_y_diff or \\\n                    c_a * other_y_min - s_a * other_x_max >  self_y_diff\n\n            else:  # s_a <= 0.0\n                return \\\n                    c_a * other_x_max + s_a * other_y_min < -self_x_diff or \\\n                    c_a * other_x_min + s_a * other_y_max >  self_x_diff or \\\n                    c_a * other_y_max - s_a * other_x_max < -self_y_diff or \\\n                    c_a * other_y_min - s_a * other_x_min >  self_y_diff\n\n        else:  # c_a <= 0.0\n            if s_a > 0:\n                return \\\n                    c_a * other_x_min + s_a * other_y_max < -self_x_diff or \\\n                    c_a * other_x_max + s_a * other_y_min >  self_x_diff or \\\n                    c_a * other_y_min - s_a * other_x_min < -self_y_diff or \\\n                    c_a * other_y_max - s_a * other_x_max >  self_y_diff\n\n            else:  # s_a <= 0.0\n                return \\\n                    c_a * other_x_min + s_a * other_y_min < -self_x_diff or \\\n                    c_a * other_x_max + s_a * other_y_max >  self_x_diff or \\\n                    c_a * other_y_min - s_a * other_x_max < -self_y_diff or \\\n                    c_a * other_y_max - s_a * other_x_min >  self_y_diff"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if this image collides with another image.", "response": "def collides(self, other):\n        \"\"\"Returns collision with axis aligned rect\"\"\"\n\n        angle = self.angle\n        width = self.width\n        height = self.height\n\n        if angle == 0:\n            return other.collides(Rect(-0.5 * width,\n                                       -0.5 * height, width, height))\n\n        # Phase 1\n        #\n        #  * Form bounding box on tilted rectangle P.\n        #  * Check whether bounding box and other intersect.\n        #  * If not, then self and other do not intersect.\n        #  * Otherwise proceed to Phase 2.\n\n        # Now perform the standard rectangle intersection test.\n\n        if self.is_bbox_not_intersecting(other):\n            return False\n\n        # Phase 2\n        #\n        # If we get here, check the edges of self to see\n        #  * if one of them excludes all vertices of other.\n        #  * If so, then self and other do not intersect.\n        #  * (If not, then self and other do intersect.)\n\n        return not self.is_edge_not_excluding_vertices(other)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn vector from left to right", "response": "def get_vec_lr(self):\n        \"\"\"Returns vector from left to right\"\"\"\n\n        return self.width * self.cos_a(), -self.width * self.sin_a()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns vector from top to bottom", "response": "def get_vec_tb(self):\n        \"\"\"Returns vector from top to bottom\"\"\"\n\n        return self.height * self.sin_a(), self.height * self.cos_a()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_edges(self):\n\n        lr_x, lr_y = self.get_vec_lr()\n        tb_x, tb_y = self.get_vec_tb()\n\n        top_left = self.x, self.y\n        top_right = self.x + lr_x, self.y + lr_y\n        bottom_left = self.x + tb_x, self.y + tb_y\n        bottom_right = self.x + lr_x + tb_x, self.y + lr_y + tb_y\n\n        return top_left, top_right, bottom_left, bottom_right", "response": "Returns 2 - tuples for each edge in the tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef collides_axisaligned_rect(self, other):\n\n        # Shift both rects so that self is centered at origin\n\n        self_shifted = RotoOriginRect(self.width, self.height, -self.angle)\n\n        s_a = self.sin_a()\n        c_a = self.cos_a()\n\n        center_x = self.x + self.width / 2.0 * c_a - self.height / 2.0 * s_a\n        center_y = self.y - self.height / 2.0 * c_a - self.width / 2.0 * s_a\n\n        other_shifted = Rect(other.x - center_x, other.y - center_y,\n                             other.width, other.height)\n\n        # Calculate collision\n\n        return self_shifted.collides(other_shifted)", "response": "Returns a collision with axis aligned other rect"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn tuple of theme icon action and toggle paths", "response": "def get_paths(self, theme, icon_size):\n        \"\"\"Returns tuple of theme, icon, action and toggle paths\"\"\"\n\n        _size_str = \"x\".join(map(str, icon_size))\n\n        theme_path = get_program_path() + \"share\" + os.sep + \"icons\" + os.sep\n        icon_path = theme_path + theme + os.sep + _size_str + os.sep\n        action_path = icon_path + \"actions\" + os.sep\n        toggle_path = icon_path + \"toggles\" + os.sep\n\n        return theme_path, icon_path, action_path, toggle_path"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef CreateBitmap(self, artid, client, size):\n\n        if artid in self.extra_icons:\n            return wx.Bitmap(self.extra_icons[artid], wx.BITMAP_TYPE_ANY)\n\n        else:\n            return wx.ArtProvider.GetBitmap(artid, client, size)", "response": "Creates a custom image from an artid"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_initial_state(self, kwargs):\n\n        self.main_window = kwargs.pop(\"main_window\")\n\n        try:\n            statustext = kwargs.pop(\"statustext\")\n\n        except KeyError:\n            statustext = \"\"\n\n        try:\n            self.total_lines = kwargs.pop(\"total_lines\")\n            self.statustext = statustext + \\\n                _(\"{nele} of {totalele} elements processed.\")\n\n        except KeyError:\n            self.total_lines = None\n            self.statustext = statustext + _(\"{nele} elements processed.\")\n\n        try:\n            self.freq = kwargs.pop(\"freq\")\n\n        except KeyError:\n            self.freq = 1000\n\n        # The aborted attribute makes next() to raise StopIteration\n        self.aborted = False\n\n        # Line counter\n        self.line = 0\n\n        # Bindings\n        self.main_window.Bind(wx.EVT_KEY_DOWN, self.on_key)", "response": "Sets the initial state of the class from kwargs attributes pops extra kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite that shows progress in statusbar for each frequency cell", "response": "def write(self, *args, **kwargs):\n        \"\"\"Write that shows progress in statusbar for each <freq> cells\"\"\"\n\n        self.progress_status()\n\n        # Check abortes state and raise StopIteration if aborted\n        if self.aborted:\n            statustext = _(\"File saving aborted.\")\n            post_command_event(self.main_window, self.main_window.StatusBarMsg,\n                               text=statustext)\n            return False\n\n        return self.parent_cls.write(self, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndisplays progress in statusbar", "response": "def progress_status(self):\n        \"\"\"Displays progress in statusbar\"\"\"\n\n        if self.line % self.freq == 0:\n            text = self.statustext.format(nele=self.line,\n                                          totalele=self.total_lines)\n\n            if self.main_window.grid.actions.pasting:\n                try:\n                    post_command_event(self.main_window,\n                                       self.main_window.StatusBarMsg,\n                                       text=text)\n                except TypeError:\n                    # The main window does not exist any more\n                    pass\n            else:\n                # Write directly to the status bar because the event queue\n                # is not emptied during file access\n\n                self.main_window.GetStatusBar().SetStatusText(text)\n\n            # Now wait for the statusbar update to be written on screen\n            if is_gtk():\n                try:\n                    wx.Yield()\n                except:\n                    pass\n\n        self.line += 1"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef on_key(self, event):\n\n        if self.main_window.grid.actions.pasting and \\\n           event.GetKeyCode() == wx.WXK_ESCAPE:\n            self.aborted = True\n\n        event.Skip()", "response": "Sets aborted state if escape is pressed"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns list of table nodes from ods object", "response": "def _get_tables(self, ods):\n        \"\"\"Returns list of table nodes from ods object\"\"\"\n\n        childnodes = ods.spreadsheet.childNodes\n        qname_childnodes = [(s.qname[1], s) for s in childnodes]\n        return [node for name, node in qname_childnodes if name == u\"table\"]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn rows from table", "response": "def _get_rows(self, table):\n        \"\"\"Returns rows from table\"\"\"\n\n        childnodes = table.childNodes\n        qname_childnodes = [(s.qname[1], s) for s in childnodes]\n        return [node for name, node in qname_childnodes\n                if name == u'table-row']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn rows from row", "response": "def _get_cells(self, row):\n        \"\"\"Returns rows from row\"\"\"\n\n        childnodes = row.childNodes\n        qname_childnodes = [(s.qname[1], s) for s in childnodes]\n        return [node for name, node in qname_childnodes\n                if name == u'table-cell']"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates code_array with the contents of the ODS file.", "response": "def _ods2code(self):\n        \"\"\"Updates code in code_array\"\"\"\n\n        ods = ODSReader(self.ods_file, clonespannedcolumns=True)\n        tables = ods.sheets\n        for tab_id, table in enumerate(tables):\n            for row_id in xrange(len(table)):\n                for col_id in xrange(len(table[row_id])):\n                    key = row_id, col_id, tab_id\n                    text = unicode(table[row_id][col_id])\n                    self.code_array[key] = text"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhold application main loop", "response": "def pyspread(S=None):\n    \"\"\"Holds application main loop\"\"\"\n\n    # Initialize main application\n    app = MainApplication(S=S, redirect=False)\n\n    app.MainLoop()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse(self):\n\n        options, args = self.parser.parse_args()\n\n        # If one dimension is 0 then the grid has no cells\n        if min(options.dimensions) < 1:\n            print(_(\"Cell dimension must be > 0.\"))\n            sys.exit()\n\n        # No MDI yet, pyspread can be started several times though\n        if len(args) > 1:\n            print(_(\"Only one file may be opened at a time.\"))\n            sys.exit()\n\n        filename = None\n        if len(args) == 1:\n            # A filename is provided and hence opened\n            filename = args[0]\n        else:\n            filename = None\n\n        return options, filename", "response": "Parse the command line options and filename."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef OnInit(self):\n\n        # Get command line options and arguments\n        cmdp = Commandlineparser()\n        options, filename = cmdp.parse()\n\n        kwargs = {\n            \"title\": \"pyspread\",\n            \"S\": self.S\n        }\n\n        # Store command line input in config if no file is provided\n        if filename is None:\n            kwargs[\"dimensions\"] = options.dimensions\n\n        # Main window creation\n        from src.gui._main_window import MainWindow\n\n        self.main_window = MainWindow(None, **kwargs)\n\n        # Initialize file loading via event\n\n        if gnupg is not None and options.new_gpgkey:\n            # Create GPG key if not present\n\n            try:\n                from src.lib.gpg import genkey\n                self.config[\"gpg_key_fingerprint\"] = repr(\"\")\n                genkey()\n\n            except ImportError:\n                pass\n\n            except ValueError:\n                # python-gnupg is installed but gnupg is not installed\n                pass\n\n        # Show application window\n        self.SetTopWindow(self.main_window)\n        self.main_window.Show()\n\n        # Load filename if provided\n        if filename is not None:\n            post_command_event(self.main_window, self.GridActionOpenMsg,\n                               attr={\"filepath\": filename})\n            self.main_window.filepath = filename\n\n        return True", "response": "Called by the main window when the application is initialized."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads a sheet in the sheet dictionary and stores each row in an array of arrays.", "response": "def readSheet(self, sheet):\n        \"\"\"Reads a sheet in the sheet dictionary\n\n        Stores each sheet as an array (rows) of arrays (columns)\n\n        \"\"\"\n\n        name = sheet.getAttribute(\"name\")\n        rows = sheet.getElementsByType(TableRow)\n        arrRows = []\n\n        # for each row\n        for row in rows:\n            row_comment = \"\"\n            arrCells = GrowingList()\n            cells = row.getElementsByType(TableCell)\n\n            # for each cell\n            count = 0\n            for cell in cells:\n                # repeated value?\n                repeat = cell.getAttribute(\"numbercolumnsrepeated\")\n                if(not repeat):\n                    repeat = 1\n                    spanned = \\\n                        int(cell.getAttribute('numbercolumnsspanned') or 0)\n                    # clone spanned cells\n                    if self.clonespannedcolumns is not None and spanned > 1:\n                        repeat = spanned\n\n                ps = cell.getElementsByType(P)\n                textContent = \"\"\n\n                # for each text/text:span node\n                for p in ps:\n                    for n in p.childNodes:\n                        if (n.nodeType == 1 and n.tagName == \"text:span\"):\n                            for c in n.childNodes:\n                                if (c.nodeType == 3):\n                                    textContent = u'{}{}'.format(textContent,\n                                                                 n.data)\n\n                        if (n.nodeType == 3):\n                            textContent = u'{}{}'.format(textContent, n.data)\n\n                if(textContent):\n                    if(textContent[0] != \"#\"):  # ignore comments cells\n                        for rr in xrange(int(repeat)):  # repeated?\n                            arrCells[count]=textContent\n                            count+=1\n                    else:\n                        row_comment = row_comment + textContent + \" \"\n                else:\n                    for rr in xrange(int(repeat)):\n                        count+=1\n\n            # if row contained something\n            if(len(arrCells)):\n                arrRows.append(arrCells)\n\n            #else:\n            #    print (\"Empty or commented row (\", row_comment, \")\")\n\n        self.sheets.append(arrRows)\n        self.sheet_names.append(name)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a tuple of dialect and header info from csvfilepath", "response": "def sniff(filepath):\n    \"\"\"\n    Sniffs CSV dialect and header info from csvfilepath\n\n    Returns a tuple of dialect and has_header\n\n    \"\"\"\n\n    with open(filepath, \"rb\") as csvfile:\n        sample = csvfile.read(config[\"sniff_size\"])\n\n    sniffer = csv.Sniffer()\n    dialect = sniffer.sniff(sample)()\n    has_header = sniffer.has_header(sample)\n\n    return dialect, has_header"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_first_line(filepath, dialect):\n\n    with open(filepath, \"rb\") as csvfile:\n        csvreader = csv.reader(csvfile, dialect=dialect)\n\n        for first_line in csvreader:\n            break\n\n    return first_line", "response": "Returns List of first line items of file filepath"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef digested_line(line, digest_types):\n\n    digested_line = []\n    for i, ele in enumerate(line):\n        try:\n            digest_key = digest_types[i]\n\n        except IndexError:\n            digest_key = digest_types[0]\n\n        digest = Digest(acceptable_types=[digest_key])\n\n        try:\n            digested_line.append(repr(digest(ele)))\n\n        except Exception:\n            digested_line.append(\"\")\n\n    return digested_line", "response": "Returns list of digested values in line"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef csv_digest_gen(filepath, dialect, has_header, digest_types):\n\n    with open(filepath, \"rb\") as csvfile:\n        csvreader = csv.reader(csvfile, dialect=dialect)\n\n        if has_header:\n            # Ignore first line\n            for line in csvreader:\n                break\n\n        for line in csvreader:\n            yield digested_line(line, digest_types)", "response": "Generator of digested values from csv file in filepath"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef encode_gen(line, encoding=\"utf-8\"):\n\n    for ele in line:\n        if isinstance(ele, types.UnicodeType):\n            yield ele.encode(encoding)\n        else:\n            yield ele", "response": "Encodes all Unicode strings in line to encoding encoding"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_csv_cells_gen(self, line):\n\n        digest_types = self.digest_types\n\n        for j, value in enumerate(line):\n            if self.first_line:\n                digest_key = None\n                digest = lambda x: x.decode(self.encoding)\n            else:\n                try:\n                    digest_key = digest_types[j]\n                except IndexError:\n                    digest_key = digest_types[0]\n\n                digest = Digest(acceptable_types=[digest_key],\n                                encoding=self.encoding)\n\n            try:\n                digest_res = digest(value)\n\n                if digest_res == \"\\b\":\n                    digest_res = None\n\n                elif digest_key is not types.CodeType:\n                    digest_res = repr(digest_res)\n\n            except Exception:\n                digest_res = \"\"\n\n            yield digest_res", "response": "Generator of values in a csv line"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite values from iterable into CSV file", "response": "def write(self, iterable):\n        \"\"\"Writes values from iterable into CSV file\"\"\"\n\n        io_error_text = _(\"Error writing to file {filepath}.\")\n        io_error_text = io_error_text.format(filepath=self.path)\n\n        try:\n\n            with open(self.path, \"wb\") as csvfile:\n                csv_writer = csv.writer(csvfile, self.dialect)\n\n                for line in iterable:\n                    csv_writer.writerow(\n                        list(encode_gen(line, encoding=self.encoding)))\n\n        except IOError:\n            txt = \\\n                _(\"Error opening file {filepath}.\").format(filepath=self.path)\n            try:\n                post_command_event(self.main_window, self.StatusBarMsg,\n                                   text=txt)\n            except TypeError:\n                # The main window does not exist any more\n                pass\n\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef color2idx(self, red, green, blue):\n\n        xlwt_colors = [\n            (0, 0, 0), (255, 255, 255), (255, 0, 0), (0, 255, 0), (0, 0, 255),\n            (255, 255, 0), (255, 0, 255), (0, 255, 255), (0, 0, 0),\n            (255, 255, 255), (255, 0, 0), (0, 255, 0), (0, 0, 255),\n            (255, 255, 0), (255, 0, 255), (0, 255, 255), (128, 0, 0),\n            (0, 128, 0), (0, 0, 128), (128, 128, 0), (128, 0, 128),\n            (0, 128, 128), (192, 192, 192), (128, 128, 128), (153, 153, 255),\n            (153, 51, 102), (255, 255, 204), (204, 255, 255), (102, 0, 102),\n            (255, 128, 128), (0, 102, 204), (204, 204, 255), (0, 0, 128),\n            (255, 0, 255), (255, 255, 0), (0, 255, 255), (128, 0, 128),\n            (128, 0, 0), (0, 128, 128), (0, 0, 255), (0, 204, 255),\n            (204, 255, 255), (204, 255, 204), (255, 255, 153), (153, 204, 255),\n            (255, 153, 204), (204, 153, 255), (255, 204, 153), (51, 102, 255),\n            (51, 204, 204), (153, 204, 0), (255, 204, 0), (255, 153, 0),\n            (255, 102, 0), (102, 102, 153), (150, 150, 150), (0, 51, 102),\n            (51, 153, 102), (0, 51, 0), (51, 51, 0), (153, 51, 0),\n            (153, 51, 102), (51, 51, 153), (51, 51, 51)\n        ]\n\n        distances = [abs(red - r) + abs(green - g) + abs(blue - b)\n                     for r, g, b in xlwt_colors]\n\n        min_dist_idx = distances.index(min(distances))\n\n        return min_dist_idx", "response": "Get an Excel index from the color tuple."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite shape to xls file", "response": "def _shape2xls(self, worksheets):\n        \"\"\"Writes shape to xls file\n\n        Format: <rows>\\t<cols>\\t<tabs>\\n\n\n        \"\"\"\n\n        __, __, tabs = self.code_array.shape\n\n        if tabs > self.xls_max_tabs:\n            tabs = self.xls_max_tabs\n\n        for tab in xrange(tabs):\n            worksheet = self.workbook.add_sheet(str(tab))\n            worksheets.append(worksheet)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates code_array. shape based on XLS file.", "response": "def _xls2shape(self):\n        \"\"\"Updates shape in code_array\"\"\"\n\n        sheets = self.workbook.sheets()\n        nrows = 1\n        ncols = 1\n        for sheet in sheets:\n            nrows = max(nrows, sheet.nrows)\n            ncols = max(ncols, sheet.ncols)\n        ntabs = len(sheets)\n\n        self.code_array.shape = nrows, ncols, ntabs"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites code to xls file.", "response": "def _code2xls(self, worksheets):\n        \"\"\"Writes code to xls file\n\n        Format: <row>\\t<col>\\t<tab>\\t<code>\\n\n\n        \"\"\"\n\n        code_array = self.code_array\n\n        xls_max_shape = self.xls_max_rows, self.xls_max_cols, self.xls_max_tabs\n\n        for key in code_array:\n            if all(kele < mele for kele, mele in zip(key, xls_max_shape)):\n                # Cell lies within Excel boundaries\n                row, col, tab = key\n                code_str = code_array(key)\n                if code_str is not None:\n                    style = self._get_xfstyle(worksheets, key)\n                    worksheets[tab].write(row, col, label=code_str,\n                                          style=style)\n\n        # Handle cell formatting in cells without code\n\n        # Get bboxes for all cell_attributes\n        max_shape = [min(xls_max_shape[0], code_array.shape[0]),\n                     min(xls_max_shape[1], code_array.shape[1])]\n\n        # Prevent systems from blocking\n        if max_shape[0] * max_shape[1] > 1024000:\n            # Ignore all cell attributes below row 3999\n            max_shape[0] = 4000\n\n        cell_attributes = code_array.dict_grid.cell_attributes\n        bboxes = []\n        for s, __tab, __ in cell_attributes:\n            if s:\n                bboxes.append((s.get_grid_bbox(code_array.shape), __tab))\n\n        # Get bbox_cell_set from bboxes\n        cells = []\n        for ((bb_top, bb_left), (bb_bottom, bb_right)), __tab in bboxes:\n            __bb_bottom = min(bb_bottom, max_shape[0])\n            __bb_right = min(bb_right, max_shape[1])\n            for __row, __col in product(xrange(bb_top, __bb_bottom + 1),\n                                        xrange(bb_left, __bb_right + 1)):\n                cells.append((__row, __col, __tab))\n\n        cell_set = set(cells)\n        # Loop over those with non-standard attributes\n        for key in cell_set:\n            if key not in code_array and all(ele >= 0 for ele in key):\n                row, col, tab = key\n                style = self._get_xfstyle(worksheets, key)\n                worksheets[tab].write(row, col, label=\"\", style=style)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _xls2code(self, worksheet, tab):\n\n        def xlrddate2datetime(xlrd_date):\n            \"\"\"Returns datetime from xlrd_date\"\"\"\n\n            try:\n                xldate_tuple = xlrd.xldate_as_tuple(xlrd_date,\n                                                    self.workbook.datemode)\n                return datetime(xldate_tuple)\n\n            except (ValueError, TypeError):\n                return ''\n\n        type2mapper = {\n            0: lambda x: None,  # Empty cell\n            1: lambda x: str(x),  # Text cell\n            2: lambda x: str(x),  # Number cell\n            3: xlrddate2datetime,  # Date\n            4: lambda x: str(bool(x)),  # Boolean cell\n            5: lambda x: str(x),  # Error cell\n            6: lambda x: None,  # Blank cell\n        }\n\n        rows, cols = worksheet.nrows, worksheet.ncols\n        for row, col in product(xrange(rows), xrange(cols)):\n            cell_type = worksheet.cell_type(row, col)\n            cell_value = worksheet.cell_value(row, col)\n\n            key = row, col, tab\n            mapper = type2mapper[cell_type]\n            self.code_array[key] = mapper(cell_value)", "response": "Updates code in xls code_array"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_font(self, pys_style):\n\n        # Return None if there is no font\n        if \"textfont\" not in pys_style:\n            return\n\n        font = xlwt.Font()\n\n        font.name = pys_style[\"textfont\"]\n\n        if \"pointsize\" in pys_style:\n            font.height = pys_style[\"pointsize\"] * 20.0\n\n        if \"fontweight\" in pys_style:\n            font.bold = (pys_style[\"fontweight\"] == wx.BOLD)\n\n        if \"fontstyle\" in pys_style:\n            font.italic = (pys_style[\"fontstyle\"] == wx.ITALIC)\n\n        if \"textcolor\" in pys_style:\n            textcolor = wx.Colour()\n            textcolor.SetRGB(pys_style[\"textcolor\"])\n            font.colour_index = self.color2idx(*textcolor.Get())\n\n        if \"underline\" in pys_style:\n            font.underline_type = pys_style[\"underline\"]\n\n        if \"strikethrough\" in pys_style:\n            font.struck_out = pys_style[\"strikethrough\"]\n\n        return font", "response": "Returns xlwt. Font for pyspread style"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_alignment(self, pys_style):\n\n        # Return None if there is no alignment\n        alignment_styles = [\"justification\", \"vertical_align\", \"angle\"]\n        if not any(astyle in pys_style for astyle in alignment_styles):\n            return\n\n        def angle2xfrotation(angle):\n            \"\"\"Returns angle from xlrotatation\"\"\"\n\n            # angle is counterclockwise\n            if 0 <= angle <= 90:\n                return angle\n\n            elif -90 <= angle < 0:\n                return 90 - angle\n\n            return 0\n\n        justification2xfalign = {\n            \"left\": 1,\n            \"center\": 2,\n            \"right\": 3,\n        }\n\n        vertical_align2xfalign = {\n            \"top\": 0,\n            \"middle\": 1,\n            \"bottom\": 2,\n        }\n\n        alignment = xlwt.Alignment()\n\n        try:\n            alignment.horz = justification2xfalign[pys_style[\"justification\"]]\n\n        except KeyError:\n            pass\n\n        try:\n            alignment.vert = \\\n                vertical_align2xfalign[pys_style[\"vertical_align\"]]\n\n        except KeyError:\n            pass\n\n        try:\n            alignment.rota = angle2xfrotation(pys_style[\"angle\"])\n\n        except KeyError:\n            pass\n\n        return alignment", "response": "Returns xlwt. Alignment for pyspread style"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_pattern(self, pys_style):\n\n        # Return None if there is no bgcolor\n        if \"bgcolor\" not in pys_style:\n            return\n\n        pattern = xlwt.Pattern()\n        pattern.pattern = xlwt.Pattern.SOLID_PATTERN\n\n        bgcolor = wx.Colour()\n        bgcolor.SetRGB(pys_style[\"bgcolor\"])\n        pattern.pattern_fore_colour = self.color2idx(*bgcolor.Get())\n\n        return pattern", "response": "Returns xlwt. pattern for pyspread style"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn xlwt. Borders object for pyspread style", "response": "def _get_borders(self, pys_style, pys_style_above, pys_style_left):\n        \"\"\"Returns xlwt.Borders for pyspread style\"\"\"\n\n        # Return None if there is no border key\n        border_keys = [\n            \"borderwidth_right\",\n            \"borderwidth_bottom\",\n            \"bordercolor_right\",\n            \"bordercolor_bottom\",\n        ]\n\n        if not any(border_key in pys_style for border_key in border_keys):\n            return\n\n        def width2border_line_style(width):\n            if width == 0:\n                return xlwt.Borders.NO_LINE\n\n            if 0 < width < 2:\n                return xlwt.Borders.THIN\n\n            if 2 <= width < 6:\n                return xlwt.Borders.MEDIUM\n\n            if width >= 6:\n                return xlwt.Borders.THICK\n\n            raise ValueError(\"Width {} unknown\".format(width))\n\n        DEFAULT_LINE_STYLE = xlwt.Borders.THIN\n        DEFAULT_COLOR_IDX = 0x16  # Tried out with gnumeric and LibreOffice\n\n        borders = xlwt.Borders()\n\n        # Width / style\n        # -------------\n\n        # Bottom width\n\n        try:\n            bottom_pys_style = pys_style[\"borderwidth_bottom\"]\n            bottom_line_style = width2border_line_style(bottom_pys_style)\n\n        except KeyError:\n            # No or unknown border width\n            bottom_line_style = DEFAULT_LINE_STYLE\n\n        finally:\n            borders.bottom = bottom_line_style\n\n        # Right width\n\n        try:\n            right_pys_style = pys_style[\"borderwidth_right\"]\n            right_line_style = width2border_line_style(right_pys_style)\n\n        except KeyError:\n            # No or unknown border width\n            right_line_style = DEFAULT_LINE_STYLE\n\n        finally:\n            borders.right = right_line_style\n\n        # Top width\n\n        try:\n            top_pys_style = pys_style_above[\"borderwidth_bottom\"]\n            top_line_style = width2border_line_style(top_pys_style)\n\n        except KeyError:\n            # No or unknown border width\n            top_line_style = DEFAULT_LINE_STYLE\n\n        finally:\n            borders.top = top_line_style\n\n        # Left width\n\n        try:\n            left_pys_style = pys_style_left[\"borderwidth_right\"]\n            left_line_style = width2border_line_style(left_pys_style)\n\n        except KeyError:\n            # No or unknown border width\n            left_line_style = DEFAULT_LINE_STYLE\n\n        finally:\n            borders.left = left_line_style\n\n        # Border colors\n        # -------------\n\n        # Bottom color\n\n        def _get_color_idx(color):\n            \"\"\"Converts wx.Colour to Excel color index\n\n            Differs from self.color2idx because it maps\n            the pyspread default grid color to the Excel default color\n\n            Parameters\n            ----------\n            color: wx.Colour\n            \\tColor to be converted\n\n            \"\"\"\n\n            if color == get_color(config[\"grid_color\"]):\n                return DEFAULT_COLOR_IDX\n            else:\n                return self.color2idx(*color.Get())\n\n        try:\n            bottom_color_pys_style = pys_style[\"bordercolor_bottom\"]\n            bcolor = wx.Colour()\n            bcolor.SetRGB(bottom_color_pys_style)\n            bottom_color_idx = _get_color_idx(bcolor)\n\n        except KeyError:\n            # No or unknown border color\n            bottom_color_idx = DEFAULT_COLOR_IDX\n\n        finally:\n            borders.bottom_colour = bottom_color_idx\n\n        # Right color\n\n        try:\n            right_color_pys_style = pys_style[\"bordercolor_right\"]\n            rcolor = wx.Colour()\n            rcolor.SetRGB(right_color_pys_style)\n            right_colour_idx = _get_color_idx(rcolor)\n\n        except KeyError:\n            # No or unknown border color\n            right_colour_idx = DEFAULT_COLOR_IDX\n\n        finally:\n            borders.right_colour = right_colour_idx\n\n        # Top color\n\n        try:\n            top_color_pys_style = pys_style_above[\"bordercolor_bottom\"]\n            tcolor = wx.Colour()\n            tcolor.SetRGB(top_color_pys_style)\n            top_color_idx = _get_color_idx(tcolor)\n\n        except KeyError:\n            # No or unknown border color\n            top_color_idx = DEFAULT_COLOR_IDX\n\n        finally:\n            borders.top_colour = top_color_idx\n\n        # Left color\n\n        try:\n            left_color_pys_style = pys_style_left[\"bordercolor_right\"]\n            lcolor = wx.Colour()\n            lcolor.SetRGB(left_color_pys_style)\n            left_colour_idx = _get_color_idx(lcolor)\n\n        except KeyError:\n            # No or unknown border color\n            left_colour_idx = DEFAULT_COLOR_IDX\n\n        finally:\n            borders.left_colour = left_colour_idx\n\n        return borders"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the XFStyle for the given cell key", "response": "def _get_xfstyle(self, worksheets, key):\n        \"\"\"Gets XFStyle for cell key\"\"\"\n\n        row, col, tab = key\n        dict_grid = self.code_array.dict_grid\n        dict_grid.cell_attributes._update_table_cache()\n\n        pys_style = dict_grid.cell_attributes[key]\n        pys_style_above = dict_grid.cell_attributes[row - 1, col, tab]\n        pys_style_left = dict_grid.cell_attributes[row, col - 1, tab]\n\n        xfstyle = xlwt.XFStyle()\n\n        # Font\n        # ----\n\n        font = self._get_font(pys_style)\n        if font is not None:\n            xfstyle.font = font\n\n        # Alignment\n        # ---------\n\n        alignment = self._get_alignment(pys_style)\n        if alignment is not None:\n            xfstyle.alignment = alignment\n\n        # Background / pattern\n        # --------------------\n\n        pattern = self._get_pattern(pys_style)\n        if pattern is not None:\n            xfstyle.pattern = pattern\n\n        # Border\n        # ------\n\n        borders = self._get_borders(pys_style, pys_style_above, pys_style_left)\n        if borders is not None:\n            xfstyle.borders = borders\n\n        return xfstyle"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _cell_attribute_append(self, selection, tab, attributes):\n\n        cell_attributes = self.code_array.cell_attributes\n\n        thick_bottom_cells = []\n        thick_right_cells = []\n\n        # Does any cell in selection.cells have a larger bottom border?\n\n        if \"borderwidth_bottom\" in attributes:\n            bwidth = attributes[\"borderwidth_bottom\"]\n            for row, col in selection.cells:\n                __bwidth = cell_attributes[row, col, tab][\"borderwidth_bottom\"]\n                if __bwidth > bwidth:\n                    thick_bottom_cells.append((row, col))\n\n        # Does any cell in selection.cells have a larger right border?\n        if \"borderwidth_right\" in attributes:\n            rwidth = attributes[\"borderwidth_right\"]\n            for row, col in selection.cells:\n                __rwidth = cell_attributes[row, col, tab][\"borderwidth_right\"]\n                if __rwidth > rwidth:\n                    thick_right_cells.append((row, col))\n\n        for thick_cell in thick_bottom_cells + thick_right_cells:\n            try:\n                selection.cells.remove(thick_cell)\n            except ValueError:\n                pass\n\n        cell_attributes.append((selection, tab, attributes))\n\n        if thick_bottom_cells:\n            bsel = copy(selection)\n            bsel.cells = thick_bottom_cells\n            battrs = copy(attributes)\n            battrs.pop(\"borderwidth_bottom\")\n            cell_attributes.append((bsel, tab, battrs))\n\n        if thick_right_cells:\n            rsel = copy(selection)\n            rsel.cells = thick_right_cells\n            rattrs = copy(attributes)\n            rattrs.pop(\"borderwidth_right\")\n            cell_attributes.append((rsel, tab, rattrs))", "response": "Appends to cell_attributes with checks."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _xls2attributes(self, worksheet, tab):\n\n        # Merged cells\n        for top, bottom, left, right in worksheet.merged_cells:\n            attrs = {\"merge_area\": (top, left, bottom - 1, right - 1)}\n            selection = Selection([(top, left)], [(bottom - 1, right - 1)],\n                                  [], [], [])\n            self.code_array.cell_attributes.append((selection, tab, attrs))\n\n        # Which cell comprise which format ids\n        xf2cell = dict((xfid, []) for xfid in xrange(self.workbook.xfcount))\n        rows, cols = worksheet.nrows, worksheet.ncols\n        for row, col in product(xrange(rows), xrange(cols)):\n            xfid = worksheet.cell_xf_index(row, col)\n            xf2cell[xfid].append((row, col))\n\n        for xfid, xf in enumerate(self.workbook.xf_list):\n            selection = Selection([], [], [], [], xf2cell[xfid])\n            selection_above = selection.shifted(-1, 0)\n            selection_left = selection.shifted(0, -1)\n\n            attributes = {}\n\n            # Alignment\n\n            xfalign2justification = {\n                0: \"left\",\n                1: \"left\",\n                2: \"center\",\n                3: \"right\",\n                4: \"left\",\n                5: \"left\",\n                6: \"center\",\n                7: \"left\",\n            }\n\n            xfalign2vertical_align = {\n                0: \"top\",\n                1: \"middle\",\n                2: \"bottom\",\n                3: \"middle\",\n                4: \"middle\",\n            }\n\n            def xfrotation2angle(xfrotation):\n                \"\"\"Returns angle from xlrotatation\"\"\"\n\n                # angle is counterclockwise\n                if 0 <= xfrotation <= 90:\n                    return xfrotation\n\n                elif 90 < xfrotation <= 180:\n                    return - (xfrotation - 90)\n\n                return 0\n\n            try:\n                attributes[\"justification\"] = \\\n                    xfalign2justification[xf.alignment.hor_align]\n\n                attributes[\"vertical_align\"] = \\\n                    xfalign2vertical_align[xf.alignment.vert_align]\n\n                attributes[\"angle\"] = \\\n                    xfrotation2angle(xf.alignment.rotation)\n\n            except AttributeError:\n                pass\n\n            # Background\n            if xf.background.fill_pattern == 1:\n                color_idx = xf.background.pattern_colour_index\n                color = self.idx2colour(color_idx)\n                attributes[\"bgcolor\"] = color.GetRGB()\n\n            # Border\n            __border_line_style2width = {\n                0: 1,\n                1: 1,\n                2: 4,\n                5: 7,\n            }\n\n            def constant_factory(value):\n                return repeat(value).next\n\n            border_line_style2width = defaultdict(constant_factory(1))\n            border_line_style2width.update(__border_line_style2width)\n\n            bottom_color_idx = xf.border.bottom_colour_index\n\n            if bottom_color_idx in self.workbook.colour_map and \\\n               self.workbook.colour_map[bottom_color_idx] is not None:\n                bottom_color = self.idx2colour(bottom_color_idx)\n                attributes[\"bordercolor_bottom\"] = bottom_color.GetRGB()\n\n            right_color_idx = xf.border.right_colour_index\n            if right_color_idx in self.workbook.colour_map and \\\n               self.workbook.colour_map[right_color_idx] is not None:\n                right_color = self.idx2colour(right_color_idx)\n                attributes[\"bordercolor_right\"] = right_color.GetRGB()\n\n            bottom_width = border_line_style2width[xf.border.bottom_line_style]\n            attributes[\"borderwidth_bottom\"] = bottom_width\n\n            right_width = border_line_style2width[xf.border.right_line_style]\n            attributes[\"borderwidth_right\"] = right_width\n\n            # Font\n\n            font = self.workbook.font_list[xf.font_index]\n\n            attributes[\"textfont\"] = font.name\n            attributes[\"pointsize\"] = font.height / 20.0\n\n            fontweight = wx.BOLD if font.weight == 700 else wx.NORMAL\n            attributes[\"fontweight\"] = fontweight\n\n            if font.italic:\n                attributes[\"fontstyle\"] = wx.ITALIC\n\n            if font.colour_index in self.workbook.colour_map and \\\n               self.workbook.colour_map[font.colour_index] is not None:\n                attributes[\"textcolor\"] = \\\n                    self.idx2colour(font.colour_index).GetRGB()\n\n            if font.underline_type:\n                attributes[\"underline\"] = True\n\n            if font.struck_out:\n                attributes[\"strikethrough\"] = True\n\n            # Handle top cells' top borders\n\n            attributes_above = {}\n            top_width = border_line_style2width[xf.border.top_line_style]\n            if top_width != 1:\n                attributes_above[\"borderwidth_bottom\"] = top_width\n            top_color_idx = xf.border.top_colour_index\n            if top_color_idx in self.workbook.colour_map and \\\n               self.workbook.colour_map[top_color_idx] is not None:\n                top_color = self.idx2colour(top_color_idx)\n                attributes_above[\"bordercolor_bottom\"] = top_color.GetRGB()\n\n            # Handle leftmost cells' left borders\n\n            attributes_left = {}\n            left_width = border_line_style2width[xf.border.left_line_style]\n            if left_width != 1:\n                attributes_left[\"borderwidth_right\"] = left_width\n            left_color_idx = xf.border.left_colour_index\n            if left_color_idx in self.workbook.colour_map and \\\n               self.workbook.colour_map[left_color_idx] is not None:\n                left_color = self.idx2colour(left_color_idx)\n                attributes_above[\"bordercolor_right\"] = left_color.GetRGB()\n\n            if attributes_above:\n                self._cell_attribute_append(selection_above, tab,\n                                            attributes_above)\n            if attributes_left:\n                self._cell_attribute_append(selection_left, tab,\n                                            attributes_left)\n            if attributes:\n                self._cell_attribute_append(selection, tab, attributes)", "response": "Updates the attributes of the code_array based on the extended cells and the cells in the worksheet."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _row_heights2xls(self, worksheets):\n\n        xls_max_rows, xls_max_tabs = self.xls_max_rows, self.xls_max_tabs\n\n        dict_grid = self.code_array.dict_grid\n\n        for row, tab in dict_grid.row_heights:\n            if row < xls_max_rows and tab < xls_max_tabs:\n                height_pixels = dict_grid.row_heights[(row, tab)]\n                height_inches = height_pixels / float(get_dpi()[1])\n                height_points = height_inches * 72.0\n\n                worksheets[tab].row(row).height_mismatch = True\n                worksheets[tab].row(row).height = int(height_points * 20.0)", "response": "Writes row_heights to xls file\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _xls2row_heights(self, worksheet, tab):\n\n        for row in xrange(worksheet.nrows):\n            try:\n                height_points = worksheet.rowinfo_map[row].height / 20.0\n                height_inches = height_points / 72.0\n                height_pixels = height_inches * get_dpi()[1]\n\n                self.code_array.row_heights[row, tab] = height_pixels\n\n            except KeyError:\n                pass", "response": "Updates row_heights in code_array"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn xls width from given pyspread width", "response": "def pys_width2xls_width(self, pys_width):\n        \"\"\"Returns xls width from given pyspread width\"\"\"\n\n        width_0 = get_default_text_extent(\"0\")[0]\n        # Scale relative to 12 point font instead of 10 point\n        width_0_char = pys_width * 1.2 / width_0\n        return int(width_0_char * 256.0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites col_widths to xls file.", "response": "def _col_widths2xls(self, worksheets):\n        \"\"\"Writes col_widths to xls file\n\n        Format: <col>\\t<tab>\\t<value>\\n\n\n        \"\"\"\n\n        xls_max_cols, xls_max_tabs = self.xls_max_cols, self.xls_max_tabs\n\n        dict_grid = self.code_array.dict_grid\n\n        for col, tab in dict_grid.col_widths:\n            if col < xls_max_cols and tab < xls_max_tabs:\n                pys_width = dict_grid.col_widths[(col, tab)]\n                xls_width = self.pys_width2xls_width(pys_width)\n                worksheets[tab].col(col).width = xls_width"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _xls2col_widths(self, worksheet, tab):\n\n        for col in xrange(worksheet.ncols):\n            try:\n                xls_width = worksheet.colinfo_map[col].width\n                pys_width = self.xls_width2pys_width(xls_width)\n                self.code_array.col_widths[col, tab] = pys_width\n\n            except KeyError:\n                pass", "response": "Updates col_widths in code_array."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_code_array(self):\n\n        worksheets = []\n        self._shape2xls(worksheets)\n\n        self._code2xls(worksheets)\n\n        self._row_heights2xls(worksheets)\n        self._col_widths2xls(worksheets)\n\n        return self.workbook", "response": "Returns xls workbook object with everything from code_array"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreplace everything in code_array from xls_file", "response": "def to_code_array(self):\n        \"\"\"Replaces everything in code_array from xls_file\"\"\"\n\n        self._xls2shape()\n\n        worksheets = self.workbook.sheet_names()\n\n        for tab, worksheet_name in enumerate(worksheets):\n            worksheet = self.workbook.sheet_by_name(worksheet_name)\n            self._xls2code(worksheet, tab)\n            self._xls2attributes(worksheet, tab)\n            self._xls2row_heights(worksheet, tab)\n            self._xls2col_widths(worksheet, tab)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _split_tidy(self, string, maxsplit=None):\n\n        if maxsplit is None:\n            return string.rstrip(\"\\n\").split(\"\\t\")\n        else:\n            return string.rstrip(\"\\n\").split(\"\\t\", maxsplit)", "response": "Rstrips string for \\ n and splits string for \\ t"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _pys_assert_version(self, line):\n\n        if float(line.strip()) > 1.0:\n            # Abort if file version not supported\n            msg = _(\"File version {version} unsupported (>1.0).\").format(\n                version=line.strip())\n            raise ValueError(msg)", "response": "Asserts pys file version"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _shape2pys(self):\n\n        shape_line = u\"\\t\".join(map(unicode, self.code_array.shape)) + u\"\\n\"\n        self.pys_file.write(shape_line)", "response": "Writes shape to pys file\n\n        Format is row col row"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _pys2shape(self, line):\n\n        self.code_array.shape = self._get_key(*self._split_tidy(line))", "response": "Updates code_array. shape with the shape of the given line"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _code2pys(self):\n\n        for key in self.code_array:\n            key_str = u\"\\t\".join(repr(ele) for ele in key)\n            code_str = self.code_array(key)\n            if code_str is not None:\n                out_str = key_str + u\"\\t\" + code_str + u\"\\n\"\n\n                self.pys_file.write(out_str.encode(\"utf-8\"))", "response": "Writes code to pys file\n\n           "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate code in pys code_array", "response": "def _pys2code(self, line):\n        \"\"\"Updates code in pys code_array\"\"\"\n\n        row, col, tab, code = self._split_tidy(line, maxsplit=3)\n        key = self._get_key(row, col, tab)\n\n        self.code_array.dict_grid[key] = unicode(code, encoding='utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites attributes to pys file", "response": "def _attributes2pys(self):\n        \"\"\"Writes attributes to pys file\n\n        Format:\n        <selection[0]>\\t[...]\\t<tab>\\t<key>\\t<value>\\t[...]\\n\n\n        \"\"\"\n\n        # Remove doublettes\n        purged_cell_attributes = []\n        purged_cell_attributes_keys = []\n        for selection, tab, attr_dict in self.code_array.cell_attributes:\n            if purged_cell_attributes_keys and \\\n               (selection, tab) == purged_cell_attributes_keys[-1]:\n                purged_cell_attributes[-1][2].update(attr_dict)\n            else:\n                purged_cell_attributes_keys.append((selection, tab))\n                purged_cell_attributes.append([selection, tab, attr_dict])\n\n        for selection, tab, attr_dict in purged_cell_attributes:\n            sel_list = [selection.block_tl, selection.block_br,\n                        selection.rows, selection.cols, selection.cells]\n\n            tab_list = [tab]\n\n            attr_dict_list = []\n            for key in attr_dict:\n                attr_dict_list.append(key)\n                attr_dict_list.append(attr_dict[key])\n\n                if config[\"font_save_enabled\"] and key == 'textfont':\n                    self.fonts_used.append(attr_dict[key])\n\n            line_list = map(repr, sel_list + tab_list + attr_dict_list)\n\n            self.pys_file.write(u\"\\t\".join(line_list) + u\"\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _pys2attributes(self, line):\n\n        splitline = self._split_tidy(line)\n\n        selection_data = map(ast.literal_eval, splitline[:5])\n        selection = Selection(*selection_data)\n\n        tab = int(splitline[5])\n\n        attrs = {}\n        for col, ele in enumerate(splitline[6:]):\n            if not (col % 2):\n                # Odd entries are keys\n                key = ast.literal_eval(ele)\n\n            else:\n                # Even cols are values\n                attrs[key] = ast.literal_eval(ele)\n\n        self.code_array.cell_attributes.append((selection, tab, attrs))", "response": "Updates the attributes in code_array based on the line of the Pys file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting row_heights to pys file", "response": "def _row_heights2pys(self):\n        \"\"\"Writes row_heights to pys file\n\n        Format: <row>\\t<tab>\\t<value>\\n\n\n        \"\"\"\n\n        for row, tab in self.code_array.dict_grid.row_heights:\n            if row < self.code_array.shape[0] and \\\n               tab < self.code_array.shape[2]:\n                height = self.code_array.dict_grid.row_heights[(row, tab)]\n                height_strings = map(repr, [row, tab, height])\n                self.pys_file.write(u\"\\t\".join(height_strings) + u\"\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate row_heights in code_array with row_heights.", "response": "def _pys2row_heights(self, line):\n        \"\"\"Updates row_heights in code_array\"\"\"\n\n        # Split with maxsplit 3\n        split_line = self._split_tidy(line)\n        key = row, tab = self._get_key(*split_line[:2])\n        height = float(split_line[2])\n\n        shape = self.code_array.shape\n\n        try:\n            if row < shape[0] and tab < shape[2]:\n                self.code_array.row_heights[key] = height\n\n        except ValueError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting col_widths to pys file", "response": "def _col_widths2pys(self):\n        \"\"\"Writes col_widths to pys file\n\n        Format: <col>\\t<tab>\\t<value>\\n\n\n        \"\"\"\n\n        for col, tab in self.code_array.dict_grid.col_widths:\n            if col < self.code_array.shape[1] and \\\n               tab < self.code_array.shape[2]:\n                width = self.code_array.dict_grid.col_widths[(col, tab)]\n                width_strings = map(repr, [col, tab, width])\n                self.pys_file.write(u\"\\t\".join(width_strings) + u\"\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _pys2col_widths(self, line):\n\n        # Split with maxsplit 3\n        split_line = self._split_tidy(line)\n        key = col, tab = self._get_key(*split_line[:2])\n        width = float(split_line[2])\n\n        shape = self.code_array.shape\n\n        try:\n            if col < shape[1] and tab < shape[2]:\n                self.code_array.col_widths[key] = width\n\n        except ValueError:\n            pass", "response": "Updates col_widths in code_array. col_widths."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite macros to pys file", "response": "def _macros2pys(self):\n        \"\"\"Writes macros to pys file\n\n        Format: <macro code line>\\n\n\n        \"\"\"\n\n        macros = self.code_array.dict_grid.macros\n        pys_macros = macros.encode(\"utf-8\")\n        self.pys_file.write(pys_macros)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates macros in code_array", "response": "def _pys2macros(self, line):\n        \"\"\"Updates macros in code_array\"\"\"\n\n        if self.code_array.dict_grid.macros and \\\n           self.code_array.dict_grid.macros[-1] != \"\\n\":\n            # The last macro line does not end with \\n\n            # Therefore, if not new line is inserted, the codeis broken\n            self.code_array.dict_grid.macros += \"\\n\"\n\n        self.code_array.dict_grid.macros += line.decode(\"utf-8\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _fonts2pys(self):\n\n        # Get mapping from fonts to fontfiles\n\n        system_fonts = font_manager.findSystemFonts()\n\n        font_name2font_file = {}\n        for sys_font in system_fonts:\n            font_name = font_manager.FontProperties(fname=sys_font).get_name()\n            if font_name in self.fonts_used:\n                font_name2font_file[font_name] = sys_font\n\n        # Only include fonts that have been used in the attributes\n        for font_name in font_name2font_file:\n            # Serialize font\n            with open(font_name2font_file[font_name]) as fontfile:\n                font_data = fontfile.read()\n                ascii_font_data = base64.b64encode(font_data)\n\n            # Store font in pys file\n            font_line_list = [font_name, ascii_font_data]\n            self.pys_file.write(u\"\\t\".join(font_line_list) + u\"\\n\")", "response": "Writes fonts to pys file"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _pys2fonts(self, line):\n\n        font_name, ascii_font_data = self._split_tidy(line)\n        font_data = base64.b64decode(ascii_font_data)\n\n        # Get system font names\n        system_fonts = font_manager.findSystemFonts()\n\n        system_font_names = []\n        for sys_font in system_fonts:\n            system_font_names.append(\n                font_manager.FontProperties(fname=sys_font).get_name()\n            )\n\n        # Use the system font if applicable\n        if font_name not in system_font_names:\n            self.code_array.custom_fonts[font_name] = font_data\n\n        with open(self.temp_fontdir + os.sep + font_name, \"wb\") as font_file:\n            font_file.write(font_data)\n\n        with tempfile.NamedTemporaryFile() as fontsconf_tmpfile:\n            fontsconf_tmpfile_name = fontsconf_tmpfile.name\n            fontsconf_tmpfile.write(self.temp_fontdir)\n\n        os.environ[\"FONTCONFIG_FILE\"] = fontsconf_tmpfile_name", "response": "Updates the custom font list with the data from the system font."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreplaces everything in pys_file from code_array", "response": "def from_code_array(self):\n        \"\"\"Replaces everything in pys_file from code_array\"\"\"\n\n        for key in self._section2writer:\n            self.pys_file.write(key)\n            self._section2writer[key]()\n\n            try:\n                if self.pys_file.aborted:\n                    break\n            except AttributeError:\n                # pys_file is not opened via fileio.BZAopen\n                pass\n\n        if config[\"font_save_enabled\"]:\n            # Clean up fonts used info\n            self.fonts_used = []"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreplace everything in code_array from pys_file", "response": "def to_code_array(self):\n        \"\"\"Replaces everything in code_array from pys_file\"\"\"\n\n        state = None\n\n        # Check if version section starts with first line\n        first_line = True\n\n        # Reset pys_file to start to enable multiple calls of this method\n        self.pys_file.seek(0)\n\n        for line in self.pys_file:\n            if first_line:\n                # If Version section does not start with first line then\n                # the file is invalid.\n                if line == \"[Pyspread save file version]\\n\":\n                    first_line = False\n                else:\n                    raise ValueError(_(\"File format unsupported.\"))\n\n            if line in self._section2reader:\n                state = line\n\n            elif state is not None:\n                self._section2reader[state](line)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfold all levels in the editor", "response": "def fold_all(self):\n        \"\"\"Folds/unfolds all levels in the editor\"\"\"\n\n        line_count = self.GetLineCount()\n        expanding = True\n\n        # find out if we are folding or unfolding\n        for line_num in range(line_count):\n            if self.GetFoldLevel(line_num) & stc.STC_FOLDLEVELHEADERFLAG:\n                expanding = not self.GetFoldExpanded(line_num)\n                break\n\n        line_num = 0\n\n        while line_num < line_count:\n            level = self.GetFoldLevel(line_num)\n            if level & stc.STC_FOLDLEVELHEADERFLAG and \\\n               (level & stc.STC_FOLDLEVELNUMBERMASK) == stc.STC_FOLDLEVELBASE:\n\n                if expanding:\n                    self.SetFoldExpanded(line_num, True)\n                    line_num = self.expand(line_num, True)\n                    line_num = line_num - 1\n                else:\n                    last_child = self.GetLastChild(line_num, -1)\n                    self.SetFoldExpanded(line_num, False)\n\n                    if last_child > line_num:\n                        self.HideLines(line_num + 1, last_child)\n\n            line_num = line_num + 1"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef expand(self, line, do_expand, force=False, vislevels=0, level=-1):\n\n        lastchild = self.GetLastChild(line, level)\n        line += 1\n\n        while line <= lastchild:\n            if force:\n                if vislevels > 0:\n                    self.ShowLines(line, line)\n                else:\n                    self.HideLines(line, line)\n            elif do_expand:\n                self.ShowLines(line, line)\n\n            if level == -1:\n                level = self.GetFoldLevel(line)\n\n            if level & stc.STC_FOLDLEVELHEADERFLAG:\n                if force:\n                    self.SetFoldExpanded(line, vislevels - 1)\n                    line = self.expand(line, do_expand, force, vislevels - 1)\n\n                else:\n                    expandsub = do_expand and self.GetFoldExpanded(line)\n                    line = self.expand(line, expandsub, force, vislevels - 1)\n            else:\n                line += 1\n\n        return line", "response": "Multi - purpose expand method from original STC class"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalling for drawing the background area of each item with the same color.", "response": "def OnDrawBackground(self, dc, rect, item, flags):\n        \"\"\"Called for drawing the background area of each item\n\n        Overridden from OwnerDrawnComboBox\n\n        \"\"\"\n\n        # If the item is selected, or its item is even,\n        # or if we are painting the combo control itself\n        # then use the default rendering.\n\n        if (item & 1 == 0 or flags & (wx.combo.ODCB_PAINTING_CONTROL |\n                                      wx.combo.ODCB_PAINTING_SELECTED)):\n            try:\n                wx.combo.OwnerDrawnComboBox.OnDrawBackground(self, dc,\n                                                             rect, item, flags)\n            finally:\n                return\n\n        # Otherwise, draw every other background with\n        # different color.\n\n        bg_color = get_color(config[\"label_color\"])\n        dc.SetBrush(wx.Brush(bg_color))\n        dc.SetPen(wx.Pen(bg_color))\n        dc.DrawRectangleRect(rect)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns code for given label string", "response": "def get_style_code(self, label):\n        \"\"\"Returns code for given label string\n\n        Inverse of get_code\n\n        Parameters\n        ----------\n        label: String\n        \\tLlabel string, field 0 of style tuple\n\n        \"\"\"\n\n        for style in self.styles:\n            if style[0] == label:\n                return style[1]\n\n        msg = _(\"Label {label} is invalid.\").format(label=label)\n        raise ValueError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn string label for given code string", "response": "def get_label(self, code):\n        \"\"\"Returns string label for given code string\n\n        Inverse of get_code\n\n        Parameters\n        ----------\n        code: String\n        \\tCode string, field 1 of style tuple\n\n        \"\"\"\n\n        for style in self.styles:\n            if style[1] == code:\n                return style[0]\n\n        msg = _(\"Code {code} is invalid.\").format(code=code)\n        raise ValueError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef OnMeasureItem(self, item):\n\n        item_name = self.GetItems()[item]\n        return icons[item_name].GetHeight()", "response": "Called when the user hits the MeasureItem event."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmeasures the width of the item in the popup", "response": "def OnMeasureItemWidth(self, item):\n        \"\"\"Returns the height of the items in the popup\"\"\"\n\n        item_name = self.GetItems()[item]\n        return icons[item_name].GetWidth()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef toggle(self, event):\n\n        if self.state < len(self.bitmap_list) - 1:\n            self.state += 1\n        else:\n            self.state = 0\n\n        self.SetBitmapLabel(self.bitmap_list[self.state])\n\n        try:\n            event.Skip()\n        except AttributeError:\n            pass\n\n        \"\"\"For compatibility with toggle buttons\"\"\"\n        setattr(self, \"GetToolState\", lambda x: self.state)", "response": "Toggles state to next bitmap"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntoggles button event handler", "response": "def OnToggle(self, event):\n        \"\"\"Toggle button event handler\"\"\"\n\n        if self.selection_toggle_button.GetValue():\n            self.entry_line.last_selection = self.entry_line.GetSelection()\n            self.entry_line.last_selection_string = \\\n                self.entry_line.GetStringSelection()\n            self.entry_line.last_table = self.main_window.grid.current_table\n            self.entry_line.Disable()\n            post_command_event(self, self.EnterSelectionModeMsg)\n\n        else:\n            self.entry_line.Enable()\n            post_command_event(self, self.GridActionTableSwitchMsg,\n                               newtable=self.entry_line.last_table)\n            post_command_event(self, self.ExitSelectionModeMsg)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef OnText(self, event):\n\n        if not self.ignore_changes:\n            post_command_event(self, self.CodeEntryMsg, code=event.GetString())\n\n        self.main_window.grid.grid_renderer.cell_cache.clear()\n\n        event.Skip()", "response": "Text event method evals the cell and updates the grid"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nhandles the char event for the current cell access code", "response": "def OnChar(self, event):\n        \"\"\"Key event method\n\n         * Forces grid update on <Enter> key\n         * Handles insertion of cell access code\n\n        \"\"\"\n\n        if not self.ignore_changes:\n\n            # Handle special keys\n            keycode = event.GetKeyCode()\n\n            if keycode == 13 and not self.GetStringSelection():\n                # <Enter> pressed and no selection --> Focus on grid\n                self.main_window.grid.SetFocus()\n\n                # Ignore <Ctrl> + <Enter> and Quote content\n                if event.ControlDown():\n                    self.SetValue(quote(self.GetValue()))\n\n                # Do not process <Enter>\n                return\n\n            elif keycode == 13 and self.GetStringSelection():\n                # <Enter> pressed and selection\n                # --> Place cursor at end of selection and clear selection\n                selection_start, selection_stop = self.Selection\n                self.SetSelection(selection_stop, selection_stop)\n\n                # Do not process <Enter>\n                return\n\n            elif keycode == 9 and jedi is None:\n                # Ignore the <Tab>\n                return\n\n            elif keycode == 9 and jedi is not None:\n                #  If auto completion library jedi is present\n                # <Tab> pressed --> show docstring tooltip\n\n                tiptext = \"\"\n\n                code = \"\".join(self.GetValue().split(\"\\n\"))\n                position = self.GetInsertionPoint()\n\n                # Get the docstring\n                code_array = self.parent.parent.parent.grid.code_array\n                env = code_array.get_globals()\n                try:\n                    script = jedi.Interpreter(code, [env], line=1,\n                                              column=position)\n                except ValueError:\n                    # Jedi has thrown an error\n                    event.Skip()\n                    return\n\n                completions = script.completions()\n                completes = [completion.complete for completion in completions]\n                complete = common_start(completes)\n\n                if complete and \\\n                   not self.GetSelection()[1] > self.GetSelection()[0]:\n                    # There is a non-empty completion\n                    insertion_point = self.GetInsertionPoint()\n                    self.write(complete)\n                    if len(completes) > 1:\n                        self.SetSelection(insertion_point,\n                                          insertion_point + len(complete))\n\n                words = [completion.name for completion in completions]\n\n                docs = []\n                for completion in completions:\n                    doc = completion.docstring(fast=False)\n                    if not doc and code:\n                        # Is the completion part of a module?\n                        code_segment = \\\n                            code[:position+1].split()[-1]\n                        module_name = code_segment.rsplit(\".\", 1)[0]\n                        try:\n                            module = env[module_name]\n                            doc = getattr(module, completion.name).__doc__\n                        except (KeyError, AttributeError):\n                            pass\n\n                    if not doc:\n                        name = completion.name\n                        try:\n                            # Is the completion a builtin?\n                            doc = getattr(__builtin__, name).__doc__\n                        except AttributeError:\n                            pass\n                    docs.append(doc)\n\n                try:\n                    dws = [\": \".join([w, d]) for w, d in zip(words, docs)]\n\n                    tiptext = \"\\n \\n\".join(dws)\n                except TypeError:\n                    pass\n\n                # Cut tiptext length because Tooltip fails for long strings\n\n                self.SetToolTip(wx.ToolTip(tiptext[:MAX_TOOLTIP_LENGTH]))\n\n                # Do not process <Tab>\n                return\n\n        event.Skip()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntabling changed event handler", "response": "def OnTableChanged(self, event):\n        \"\"\"Table changed event handler\"\"\"\n\n        if hasattr(event, 'updated_cell'):\n            # Event posted by cell edit widget.  Even more up to date\n            #  than the current cell's contents\n            self.ignore_changes = True\n            try:\n                self.SetValue(event.updated_cell)\n\n            except TypeError:\n                # None instead of string present\n                pass\n            self.ignore_changes = False\n\n        else:\n            current_cell = self.main_window.grid.actions.cursor\n            current_cell_code = self.main_window.grid.code_array(current_cell)\n\n            if current_cell_code is None:\n                self.SetValue(u\"\")\n            else:\n                self.SetValue(current_cell_code)\n\n        event.Skip()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef change_max(self, no_tabs):\n\n        self.no_tabs = no_tabs\n\n        if self.GetValue() >= no_tabs:\n            self.SetValue(no_tabs - 1)", "response": "Updates the number of tables in the current set to the new number of tables in the new set."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts the value of the control into the appropriate value.", "response": "def _fromGUI(self, value):\n        \"\"\"\n        Conversion function used in getting the value of the control.\n\n        \"\"\"\n\n        # One or more of the underlying text control implementations\n        # issue an intermediate EVT_TEXT when replacing the control's\n        # value, where the intermediate value is an empty string.\n        # So, to ensure consistency and to prevent spurious ValueErrors,\n        # we make the following test, and react accordingly:\n        #\n        if value == '':\n            if not self.IsNoneAllowed():\n                return 0\n            else:\n                return\n        else:\n            try:\n                return int(value)\n            except ValueError:\n                if self.IsLongAllowed():\n                    try:\n                        return long(value)\n                    except ValueError:\n                        wx.TextCtrl.SetValue(self, \"0\")\n                        return 0\n                else:\n                    raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef OnMouseWheel(self, event):\n\n        # Prevent lost IntCtrl changes\n        if self.switching:\n            time.sleep(0.1)\n            return\n\n        value = self.GetValue()\n\n        current_time = time.clock()\n        if current_time < self.last_change_s + 0.01:\n            return\n\n        if event.GetWheelRotation() >= event.GetWheelDelta():\n            self.SetValue(min(value+1, self.no_tabs-1))\n        elif event.GetWheelRotation() <= -event.GetWheelDelta():\n            self.SetValue(max(value-1, 0))", "response": "Mouse wheel event handler"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef OnTableChanged(self, event):\n\n        if hasattr(event, 'table'):\n            self.SetValue(event.table)\n\n        wx.TextCtrl.SetInsertionPoint(self, self.cursor_pos)\n\n        event.Skip()", "response": "Table changed event handler"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef OnResizeGrid(self, event):\n\n        shape = min(event.shape[2], 2**30)\n        self.SetItemCount(shape)\n        event.Skip()", "response": "event handler for grid resizing"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef OnTableChanged(self, event):\n\n        if hasattr(event, 'table'):\n            self.Select(event.table)\n            self.EnsureVisible(event.table)\n\n        event.Skip()", "response": "Table changed event handler"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef OnMouseUp(self, event):\n\n        if not self.IsInControl:  # 1. Outside the control : Do Nothing\n            self.IsDrag = False\n        elif self.IsDrag:\n            if not self.IsDrag:\n                # In control and is a drag event : Determine Location\n                self.hitIndex = self.HitTest(event.GetPosition())\n                self.dropIndex = self.hitIndex[0]\n                # Drop index indicates where the drop location is;\n                # what index number\n\n                # Determine dropIndex and its validity\n\n                # 2. On itself or below control : Do Nothing\n                if not (self.dropIndex == self.startIndex or\n                        self.dropIndex == -1):\n                    # Now that dropIndex has been established do 3 things\n                    # 1. gather item data\n                    # 2. delete item in list\n                    # 3. insert item & it's data into the list at the new index\n\n                    # dropList is a list of field values from the list control\n                    dropList = []\n\n                    thisItem = self.GetItem(self.startIndex)\n                    for x in xrange(self.GetColumnCount()):\n                        dropList.append(\n                            self.GetItem(self.startIndex, x).GetText())\n                    thisItem.SetId(self.dropIndex)\n                    self.DeleteItem(self.startIndex)\n                    self.InsertItem(thisItem)\n                    for x in range(self.GetColumnCount()):\n                        self.SetStringItem(self.dropIndex, x, dropList[x])\n            # If in control but not a drag event : Do Nothing\n\n        self.IsDrag = False\n        event.Skip()", "response": "Handles mouse up events for the item in the list."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nenables menu bar view item checkmarks", "response": "def _set_menu_toggles(self):\n        \"\"\"Enable menu bar view item checkmarks\"\"\"\n\n        toggles = [\n            (self.main_toolbar, \"main_window_toolbar\", _(\"Main toolbar\")),\n            (self.macro_toolbar, \"macro_toolbar\", _(\"Macro toolbar\")),\n            (self.macro_panel, \"macro_panel\", _(\"Macro panel\")),\n            (self.attributes_toolbar, \"attributes_toolbar\",\n             _(\"Format toolbar\")),\n            (self.find_toolbar, \"find_toolbar\", _(\"Find toolbar\")),\n            (self.widget_toolbar, \"widget_toolbar\", _(\"Widget toolbar\")),\n            (self.entry_line_panel, \"entry_line_panel\", _(\"Entry line\")),\n            (self.table_list_panel, \"table_list_panel\", _(\"Table list\")),\n        ]\n\n        for toolbar, pane_name, toggle_label in toggles:\n            # Get pane from aui manager\n            pane = self._mgr.GetPane(pane_name)\n\n            # Get menu item to toggle\n            toggle_id = self.menubar.FindMenuItem(_(\"View\"), toggle_label)\n            if toggle_id != -1:\n                # Check may fail if translation is incomplete\n                toggle_item = self.menubar.FindItemById(toggle_id)\n\n                # Adjust toggle to pane visibility\n                toggle_item.Check(pane.IsShown())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _do_layout(self):\n\n        # Set background color for the toolbar via the manager\n        ap = self._mgr.GetArtProvider()\n        ap.SetColour(aui.AUI_DOCKART_BACKGROUND_GRADIENT_COLOUR,\n                     get_color(config[\"background_color\"]))\n\n        # Add the toolbars to the manager\n\n        self._mgr.AddPane(self.main_toolbar, aui.AuiPaneInfo().\n                          Name(\"main_window_toolbar\").\n                          Caption(_(\"Main toolbar\")).\n                          ToolbarPane().Top().Row(0))\n\n        self._mgr.AddPane(self.find_toolbar, aui.AuiPaneInfo().\n                          Name(\"find_toolbar\").Caption(_(\"Find toolbar\")).\n                          ToolbarPane().Top().Row(0))\n\n        self._mgr.AddPane(self.attributes_toolbar, aui.AuiPaneInfo().\n                          Name(\"attributes_toolbar\").\n                          Caption(_(\"Format toolbar\")).\n                          ToolbarPane().Top().Row(1))\n\n        self._mgr.AddPane(self.macro_toolbar, aui.AuiPaneInfo().\n                          Name(\"macro_toolbar\").Caption(_(\"Macro toolbar\")).\n                          Gripper(True).ToolbarPane().Top().Row(1))\n\n        self._mgr.AddPane(self.widget_toolbar, aui.AuiPaneInfo().\n                          Name(\"widget_toolbar\").Caption(_(\"Widget toolbar\")).\n                          Gripper(True).ToolbarPane().Top().Row(1))\n\n        self._mgr.AddPane(self.entry_line_panel, aui.AuiPaneInfo().\n                          Name(\"entry_line_panel\").Caption(_(\"Entry line\")).\n                          Gripper(False).CenterPane().Top().Row(2).\n                          BestSize(400, 30).PaneBorder(False))\n\n        self._mgr.AddPane(self.table_list_panel, aui.AuiPaneInfo().\n                          Name(\"table_list_panel\").Caption(_(\"Table\")).\n                          CenterPane().Left().BestSize(50, 300))\n\n        self._mgr.AddPane(self.macro_panel, aui.AuiPaneInfo().\n                          Name(\"macro_panel\").Caption(_(\"Macro panel\")).\n                          Gripper(False).CenterPane().Right().\n                          BestSize(200, 200))\n\n        # Load perspective from config\n        window_layout = config[\"window_layout\"]\n\n        if window_layout:\n            self._mgr.LoadPerspective(window_layout)\n\n        # Add the main grid\n        self._mgr.AddPane(self.grid, aui.AuiPaneInfo().\n                          Name(\"grid\").Caption(_(\"Main grid\")).CentrePane())\n\n        # Tell the manager to 'commit' all the changes just made\n        self._mgr.Update()\n        self._mgr.GetPane(\"attributes_toolbar\")\n        self._mgr.Update()\n\n        self._set_menu_toggles()\n\n        # Set initial size to config value\n        self.SetInitialSize(config[\"window_size\"])\n        self.SetMinSize((10, 10))\n\n        # TODO: Set window position fix --> different positions for\n        # different window managers prevent this\n\n        self.SetPosition(config[\"window_position\"])", "response": "Adds widgets to the manager and controls the layout"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbind events to handlers", "response": "def _bind(self):\n        \"\"\"Bind events to handlers\"\"\"\n\n        handlers = self.handlers\n\n        # Main window events\n        self.Bind(wx.EVT_MOVE, handlers.OnMove)\n        self.Bind(wx.EVT_SIZE, handlers.OnSize)\n        self.Bind(self.EVT_CMD_FULLSCREEN, handlers.OnToggleFullscreen)\n\n        # Content changed event, adjusts title bar with star\n        self.Bind(self.EVT_CONTENT_CHANGED, handlers.OnContentChanged)\n\n        # Program state events\n\n        self.Bind(self.EVT_CMD_TITLE, handlers.OnTitle)\n        self.Bind(self.EVT_CMD_SAFE_MODE_ENTRY, handlers.OnSafeModeEntry)\n        self.Bind(self.EVT_CMD_SAFE_MODE_EXIT, handlers.OnSafeModeExit)\n        self.Bind(wx.EVT_CLOSE, handlers.OnClose)\n        self.Bind(self.EVT_CMD_CLOSE, handlers.OnClose)\n        self.Bind(self.EVT_SPELL_CHECK, handlers.OnSpellCheckToggle)\n\n        # Preferences events\n\n        self.Bind(self.EVT_CMD_PREFERENCES, handlers.OnPreferences)\n        self.Bind(self.EVT_CMD_NEW_GPG_KEY, handlers.OnNewGpgKey)\n\n        # Toolbar toggle events\n\n        self.Bind(self.EVT_CMD_MAINTOOLBAR_TOGGLE,\n                  handlers.OnMainToolbarToggle)\n        self.Bind(self.EVT_CMD_MACROTOOLBAR_TOGGLE,\n                  handlers.OnMacroToolbarToggle)\n        self.Bind(self.EVT_CMD_WIDGETTOOLBAR_TOGGLE,\n                  handlers.OnWidgetToolbarToggle)\n        self.Bind(self.EVT_CMD_ATTRIBUTESTOOLBAR_TOGGLE,\n                  handlers.OnAttributesToolbarToggle)\n        self.Bind(self.EVT_CMD_FIND_TOOLBAR_TOGGLE,\n                  handlers.OnFindToolbarToggle)\n        self.Bind(self.EVT_CMD_ENTRYLINE_TOGGLE,\n                  handlers.OnEntryLineToggle)\n        self.Bind(self.EVT_CMD_MACROPANEL_TOGGLE,\n                  handlers.OnMacroPanelToggle)\n        self.Bind(self.EVT_CMD_TABLELIST_TOGGLE,\n                  handlers.OnTableListToggle)\n        self.Bind(aui.EVT_AUI_PANE_CLOSE, handlers.OnPaneClose)\n\n        # File events\n\n        self.Bind(self.EVT_CMD_NEW, handlers.OnNew)\n        self.Bind(self.EVT_CMD_OPEN, handlers.OnOpen)\n        self.Bind(self.EVT_CMD_SAVE, handlers.OnSave)\n        self.Bind(self.EVT_CMD_SAVEAS, handlers.OnSaveAs)\n        self.Bind(self.EVT_CMD_IMPORT, handlers.OnImport)\n        self.Bind(self.EVT_CMD_EXPORT, handlers.OnExport)\n        self.Bind(self.EVT_CMD_EXPORT_PDF, handlers.OnExportPDF)\n        self.Bind(self.EVT_CMD_APPROVE, handlers.OnApprove)\n        self.Bind(self.EVT_CMD_CLEAR_GLOBALS, handlers.OnClearGlobals)\n\n        # Find events\n        self.Bind(self.EVT_CMD_FOCUSFIND, handlers.OnFocusFind)\n\n        # Format events\n        self.Bind(self.EVT_CMD_FONTDIALOG, handlers.OnFontDialog)\n        self.Bind(self.EVT_CMD_TEXTCOLORDIALOG, handlers.OnTextColorDialog)\n        self.Bind(self.EVT_CMD_BGCOLORDIALOG, handlers.OnBgColorDialog)\n\n        # Print events\n\n        self.Bind(self.EVT_CMD_PAGE_SETUP, handlers.OnPageSetup)\n        self.Bind(self.EVT_CMD_PRINT_PREVIEW, handlers.OnPrintPreview)\n        self.Bind(self.EVT_CMD_PRINT, handlers.OnPrint)\n\n        # Edit Events\n        self.Bind(self.EVT_CMD_SELECT_ALL, handlers.OnSelectAll)\n\n        # Clipboard events\n\n        self.Bind(self.EVT_CMD_CUT, handlers.OnCut)\n        self.Bind(self.EVT_CMD_COPY, handlers.OnCopy)\n        self.Bind(self.EVT_CMD_COPY_RESULT, handlers.OnCopyResult)\n        self.Bind(self.EVT_CMD_PASTE, handlers.OnPaste)\n        self.Bind(self.EVT_CMD_PASTE_AS, handlers.OnPasteAs)\n\n        # Help events\n\n        self.Bind(self.EVT_CMD_MANUAL, handlers.OnManual)\n        self.Bind(self.EVT_CMD_TUTORIAL, handlers.OnTutorial)\n        self.Bind(self.EVT_CMD_FAQ, handlers.OnFaq)\n        self.Bind(self.EVT_CMD_PYTHON_TURORIAL, handlers.OnPythonTutorial)\n        self.Bind(self.EVT_CMD_DEPENDENCIES, handlers.OnDependencies)\n        self.Bind(self.EVT_CMD_ABOUT, handlers.OnAbout)\n\n        self.Bind(self.EVT_CMD_MACROREPLACE, handlers.OnMacroReplace)\n        self.Bind(self.EVT_CMD_MACROEXECUTE, handlers.OnMacroExecute)\n        self.Bind(self.EVT_CMD_MACROLOAD, handlers.OnMacroListLoad)\n        self.Bind(self.EVT_CMD_MACROSAVE, handlers.OnMacroListSave)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets main window icon to given wx. Bitmap", "response": "def set_icon(self, bmp):\n        \"\"\"Sets main window icon to given wx.Bitmap\"\"\"\n\n        _icon = wx.EmptyIcon()\n        _icon.CopyFromBitmap(bmp)\n        self.SetIcon(_icon)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef OnMove(self, event):\n\n        # Store window position in config\n        position = self.main_window.GetScreenPositionTuple()\n\n        config[\"window_position\"] = repr(position)", "response": "Main window move event handler"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef OnSize(self, event):\n\n        # Store window size in config\n\n        size = event.GetSize()\n\n        config[\"window_size\"] = repr((size.width, size.height))", "response": "Main window move event handler"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsafes mode entry event handler", "response": "def OnSafeModeEntry(self, event):\n        \"\"\"Safe mode entry event handler\"\"\"\n\n        # Enable menu item for leaving safe mode\n\n        self.main_window.main_menu.enable_file_approve(True)\n\n        self.main_window.grid.Refresh()\n\n        event.Skip()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsafing mode exit event handler", "response": "def OnSafeModeExit(self, event):\n        \"\"\"Safe mode exit event handler\"\"\"\n\n        # Run macros\n\n        # self.MainGrid.model.pysgrid.sgrid.execute_macros(safe_mode=False)\n\n        # Disable menu item for leaving safe mode\n\n        self.main_window.main_menu.enable_file_approve(False)\n\n        self.main_window.grid.Refresh()\n\n        event.Skip()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef OnClose(self, event):\n\n        # If changes have taken place save of old grid\n\n        if undo.stack().haschanged():\n            save_choice = self.interfaces.get_save_request_from_user()\n\n            if save_choice is None:\n                # Cancelled close operation\n                return\n\n            elif save_choice:\n                # User wants to save content\n                post_command_event(self.main_window, self.main_window.SaveMsg)\n\n        # Save the AUI state\n\n        config[\"window_layout\"] = repr(self.main_window._mgr.SavePerspective())\n\n        # Uninit the AUI stuff\n\n        self.main_window._mgr.UnInit()\n\n        # Save config\n        config.save()\n\n        # Close main_window\n\n        self.main_window.Destroy()\n\n        # Set file mode to 600 to protect GPG passwd a bit\n        sp = wx.StandardPaths.Get()\n        pyspreadrc_path = sp.GetUserConfigDir() + \"/.\" + config.config_filename\n        try:\n            os.chmod(pyspreadrc_path, 0600)\n        except OSError:\n            dummyfile = open(pyspreadrc_path, \"w\")\n            dummyfile.close()\n            os.chmod(pyspreadrc_path, 0600)", "response": "Program exit event handler"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef OnSpellCheckToggle(self, event):\n\n        spelltoolid = self.main_window.main_toolbar.label2id[\"CheckSpelling\"]\n        self.main_window.main_toolbar.ToggleTool(spelltoolid,\n                                                 not config[\"check_spelling\"])\n\n        config[\"check_spelling\"] = repr(not config[\"check_spelling\"])\n\n        self.main_window.grid.grid_renderer.cell_cache.clear()\n        self.main_window.grid.ForceRefresh()", "response": "Spell checking toggle event handler"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef OnNewGpgKey(self, event):\n\n        if gnupg is None:\n            return\n\n        if genkey is None:\n            # gnupg is not present\n            self.interfaces.display_warning(\n                _(\"Python gnupg not found. No key selected.\"),\n                _(\"Key selection failed.\"))\n        else:\n            # gnupg is present\n            genkey()", "response": "Called when a new GPG key is selected."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _toggle_pane(self, pane):\n\n        if pane.IsShown():\n            pane.Hide()\n        else:\n            pane.Show()\n\n        self.main_window._mgr.Update()", "response": "Toggles visibility of given aui pane"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef OnMainToolbarToggle(self, event):\n\n        self.main_window.main_toolbar.SetGripperVisible(True)\n        main_toolbar_info = \\\n            self.main_window._mgr.GetPane(\"main_window_toolbar\")\n\n        self._toggle_pane(main_toolbar_info)\n\n        event.Skip()", "response": "Main window toolbar toggle event handler"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef OnAttributesToolbarToggle(self, event):\n\n        self.main_window.attributes_toolbar.SetGripperVisible(True)\n        attributes_toolbar_info = \\\n            self.main_window._mgr.GetPane(\"attributes_toolbar\")\n\n        self._toggle_pane(attributes_toolbar_info)\n\n        event.Skip()", "response": "Format toolbar toggle event handler"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsearches toolbar toggle event handler", "response": "def OnFindToolbarToggle(self, event):\n        \"\"\"Search toolbar toggle event handler\"\"\"\n\n        self.main_window.find_toolbar.SetGripperVisible(True)\n\n        find_toolbar_info = self.main_window._mgr.GetPane(\"find_toolbar\")\n\n        self._toggle_pane(find_toolbar_info)\n\n        event.Skip()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef OnTableListToggle(self, event):\n\n        table_list_panel_info = \\\n            self.main_window._mgr.GetPane(\"table_list_panel\")\n\n        self._toggle_pane(table_list_panel_info)\n\n        event.Skip()", "response": "Table list toggle event handler"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef OnPaneClose(self, event):\n\n        toggle_label = event.GetPane().caption\n\n        # Get menu item to toggle\n        menubar = self.main_window.menubar\n        toggle_id = menubar.FindMenuItem(_(\"View\"), toggle_label)\n        toggle_item = menubar.FindItemById(toggle_id)\n\n        # Adjust toggle to pane visibility\n        toggle_item.Check(False)\n\n        menubar.UpdateMenus()\n\n        self.main_window._mgr.Update()\n\n        event.Skip()", "response": "Pane close event handler"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfiling open event handler", "response": "def OnOpen(self, event):\n        \"\"\"File open event handler\"\"\"\n\n        # If changes have taken place save of old grid\n        if undo.stack().haschanged():\n            save_choice = self.interfaces.get_save_request_from_user()\n\n            if save_choice is None:\n                # Cancelled close operation\n                return\n\n            elif save_choice:\n                # User wants to save content\n                post_command_event(self.main_window, self.main_window.SaveMsg)\n\n        # Get filepath from user\n        f2w = get_filetypes2wildcards(\n            [\"pys\", \"pysu\", \"xls\", \"xlsx\", \"ods\", \"all\"])\n        filetypes = f2w.keys()\n        wildcards = f2w.values()\n        wildcard = \"|\".join(wildcards)\n\n        message = _(\"Choose file to open.\")\n        style = wx.OPEN\n\n        default_filetype = config[\"default_open_filetype\"]\n        try:\n            default_filterindex = filetypes.index(default_filetype)\n        except ValueError:\n            # Be graceful if the user has entered an unkown filetype\n            default_filterindex = 0\n\n        get_fp_fidx = self.interfaces.get_filepath_findex_from_user\n        filepath, filterindex = get_fp_fidx(wildcard, message, style,\n                                            filterindex=default_filterindex)\n\n        if filepath is None:\n            return\n\n        filetype = filetypes[filterindex]\n\n        # Change the main window filepath state\n\n        self.main_window.filepath = filepath\n\n        # Load file into grid\n        post_command_event(self.main_window,\n                           self.main_window.GridActionOpenMsg,\n                           attr={\"filepath\": filepath, \"filetype\": filetype})\n\n        # Set Window title to new filepath\n\n        title_text = filepath.split(\"/\")[-1] + \" - pyspread\"\n        post_command_event(self.main_window,\n                           self.main_window.TitleMsg, text=title_text)\n\n        self.main_window.grid.ForceRefresh()\n\n        if is_gtk():\n            try:\n                wx.Yield()\n            except:\n                pass\n\n        # Update savepoint and clear the undo stack\n        undo.stack().clear()\n        undo.stack().savepoint()\n\n        # Update content changed state\n        try:\n            post_command_event(self.main_window, self.ContentChangedMsg)\n        except TypeError:\n            # The main window does not exist any more\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfiles save event handler", "response": "def OnSave(self, event):\n        \"\"\"File save event handler\"\"\"\n\n        try:\n            filetype = event.attr[\"filetype\"]\n\n        except (KeyError, AttributeError):\n            filetype = None\n\n        filepath = self.main_window.filepath\n        if filepath is None:\n            filetype = config[\"default_save_filetype\"]\n\n        if filetype is None:\n\n            f2w = get_filetypes2wildcards([\"pys\", \"pysu\", \"xls\", \"all\"])\n            __filetypes = f2w.keys()\n\n            # Check if the file extension matches any valid save filetype\n            for __filetype in __filetypes:\n                if splitext(filepath)[-1][1:] == __filetype:\n                    filetype = __filetype\n                    break\n\n        # If there is no filepath or no filetype is found then jump to save as\n\n        if self.main_window.filepath is None or filetype is None:\n            post_command_event(self.main_window,\n                               self.main_window.SaveAsMsg)\n            return\n\n        # Save the grid\n\n        post_command_event(self.main_window,\n                           self.main_window.GridActionSaveMsg,\n                           attr={\"filepath\": self.main_window.filepath,\n                                 \"filetype\": filetype})\n\n        # Update undo stack savepoint\n        undo.stack().savepoint()\n\n        # Display file save in status bar\n\n        statustext = self.main_window.filepath.split(\"/\")[-1] + \" saved.\"\n        post_command_event(self.main_window,\n                           self.main_window.StatusBarMsg,\n                           text=statustext)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef OnSaveAs(self, event):\n\n        # Get filepath from user\n\n        f2w = get_filetypes2wildcards([\"pys\", \"pysu\", \"xls\", \"all\"])\n        filetypes = f2w.keys()\n        wildcards = f2w.values()\n\n        wildcard = \"|\".join(wildcards)\n\n        message = _(\"Choose filename for saving.\")\n        style = wx.SAVE\n\n        default_filetype = config[\"default_save_filetype\"]\n        try:\n            default_filterindex = filetypes.index(default_filetype)\n        except ValueError:\n            # Be graceful if the user has entered an unkown filetype\n            default_filterindex = 0\n\n        get_fp_fidx = self.interfaces.get_filepath_findex_from_user\n        filepath, filterindex = get_fp_fidx(wildcard, message, style,\n                                            filterindex=default_filterindex)\n\n        if filepath is None:\n            return 0\n\n        filetype = filetypes[filterindex]\n\n        # Look if path is already present\n        if os.path.exists(filepath):\n            if not os.path.isfile(filepath):\n                # There is a directory with the same path\n                statustext = _(\"Directory present. Save aborted.\")\n                post_command_event(self.main_window,\n                                   self.main_window.StatusBarMsg,\n                                   text=statustext)\n                return 0\n\n            # There is a file with the same path\n            message = \\\n                _(\"The file {filepath} is already present.\\nOverwrite?\")\\\n                .format(filepath=filepath)\n            short_msg = _(\"File collision\")\n\n            if not self.main_window.interfaces.get_warning_choice(message,\n                                                                  short_msg):\n\n                statustext = _(\"File present. Save aborted by user.\")\n                post_command_event(self.main_window,\n                                   self.main_window.StatusBarMsg,\n                                   text=statustext)\n                return 0\n\n        # Put pys suffix if wildcard choice is 0\n        if filterindex == 0 and filepath[-4:] != \".pys\":\n            filepath += \".pys\"\n\n        # Set the filepath state\n        self.main_window.filepath = filepath\n\n        # Set Window title to new filepath\n        title_text = filepath.split(\"/\")[-1] + \" - pyspread\"\n        post_command_event(self.main_window, self.main_window.TitleMsg,\n                           text=title_text)\n\n        # Now jump to save\n        post_command_event(self.main_window, self.main_window.SaveMsg,\n                           attr={\"filetype\": filetype})", "response": "File save as event handler"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfiles import event handler", "response": "def OnImport(self, event):\n        \"\"\"File import event handler\"\"\"\n\n        # Get filepath from user\n\n        wildcards = get_filetypes2wildcards([\"csv\", \"txt\"]).values()\n        wildcard = \"|\".join(wildcards)\n\n        message = _(\"Choose file to import.\")\n        style = wx.OPEN\n        filepath, filterindex = \\\n            self.interfaces.get_filepath_findex_from_user(wildcard, message,\n                                                          style)\n\n        if filepath is None:\n            return\n\n        # Get generator of import data\n        import_data = self.main_window.actions.import_file(filepath,\n                                                           filterindex)\n\n        if import_data is None:\n            return\n\n        # Paste import data to grid\n        grid = self.main_window.grid\n        tl_cell = grid.GetGridCursorRow(), grid.GetGridCursorCol()\n\n        grid.actions.paste(tl_cell, import_data)\n\n        self.main_window.grid.ForceRefresh()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfile export event handler", "response": "def OnExport(self, event):\n        \"\"\"File export event handler\n\n        Currently, only CSV export is supported\n\n        \"\"\"\n\n        code_array = self.main_window.grid.code_array\n        tab = self.main_window.grid.current_table\n\n        selection = self.main_window.grid.selection\n\n        # Check if no selection is present\n\n        selection_bbox = selection.get_bbox()\n\n        f2w = get_filetypes2wildcards([\"csv\", \"pdf\", \"svg\"])\n        filters = f2w.keys()\n        wildcards = f2w.values()\n\n        wildcard = \"|\".join(wildcards)\n\n        if selection_bbox is None:\n            # No selection --> Use smallest filled area for bottom right edge\n            maxrow, maxcol, __ = code_array.get_last_filled_cell(tab)\n\n            (top, left), (bottom, right) = (0, 0), (maxrow, maxcol)\n\n        else:\n            (top, left), (bottom, right) = selection_bbox\n\n        # Generator of row and column keys in correct order\n\n        __top = 0 if top is None else top\n        __bottom = code_array.shape[0] if bottom is None else bottom + 1\n        __left = 0 if left is None else left\n        __right = code_array.shape[1] if right is None else right + 1\n\n        def data_gen(top, bottom, left, right):\n            for row in xrange(top, bottom):\n                yield (code_array[row, col, tab]\n                       for col in xrange(left, right))\n\n        data = data_gen(__top, __bottom, __left, __right)\n        preview_data = data_gen(__top, __bottom, __left, __right)\n\n        # Get target filepath from user\n\n        # No selection --> Provide svg export of current cell\n        # if current cell is a matplotlib figure\n        if selection_bbox is None:\n            cursor = self.main_window.grid.actions.cursor\n            figure = code_array[cursor]\n            if Figure is not None and isinstance(figure, Figure):\n                wildcard += \\\n                    \"|\" + _(\"SVG of current cell\") + \" (*.svg)|*.svg\" + \\\n                    \"|\" + _(\"EPS of current cell\") + \" (*.eps)|*.eps\" + \\\n                    \"|\" + _(\"PS of current cell\") + \" (*.ps)|*.ps\" + \\\n                    \"|\" + _(\"PDF of current cell\") + \" (*.pdf)|*.pdf\" + \\\n                    \"|\" + _(\"PNG of current cell\") + \" (*.png)|*.png\"\n                filters.append(\"cell_svg\")\n                filters.append(\"cell_eps\")\n                filters.append(\"cell_ps\")\n                filters.append(\"cell_pdf\")\n                filters.append(\"cell_png\")\n\n        message = _(\"Choose filename for export.\")\n        style = wx.SAVE\n        path, filterindex = \\\n            self.interfaces.get_filepath_findex_from_user(wildcard, message,\n                                                          style)\n\n        if path is None:\n            return\n\n        # If an single cell is exported then the selection bbox\n        # has to be changed to the current cell\n        if filters[filterindex].startswith(\"cell_\"):\n            data = figure\n\n        # Export file\n        # -----------\n\n        self.main_window.actions.export_file(path, filters[filterindex], data,\n                                             preview_data)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexporting PDF event handler", "response": "def OnExportPDF(self, event):\n        \"\"\"Export PDF event handler\"\"\"\n\n        wildcards = get_filetypes2wildcards([\"pdf\"]).values()\n\n        if not wildcards:\n            return\n\n        wildcard = \"|\".join(wildcards)\n\n        # Get filepath from user\n        message = _(\"Choose file path for PDF export.\")\n\n        style = wx.SAVE\n        filepath, filterindex = \\\n            self.interfaces.get_filepath_findex_from_user(wildcard, message,\n                                                          style)\n\n        if filepath is None:\n            return\n\n        self.main_window.actions.export_cairo(filepath, \"pdf\")\n\n        event.Skip()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef OnApprove(self, event):\n\n        if not self.main_window.safe_mode:\n            return\n\n        msg = _(u\"You are going to approve and trust a file that\\n\"\n                u\"you have not created yourself.\\n\"\n                u\"After proceeding, the file is executed.\\n \\n\"\n                u\"It may harm your system as any program can.\\n\"\n                u\"Please check all cells thoroughly before\\nproceeding.\\n \\n\"\n                u\"Proceed and sign this file as trusted?\")\n\n        short_msg = _(\"Security warning\")\n\n        if self.main_window.interfaces.get_warning_choice(msg, short_msg):\n            # Leave safe mode\n            self.main_window.grid.actions.leave_safe_mode()\n\n            # Display safe mode end in status bar\n\n            statustext = _(\"Safe mode deactivated.\")\n            post_command_event(self.main_window, self.main_window.StatusBarMsg,\n                               text=statustext)", "response": "File approve event handler"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef OnClearGlobals(self, event):\n\n        msg = _(\"Deleting globals and reloading modules cannot be undone.\"\n                \" Proceed?\")\n        short_msg = _(\"Really delete globals and modules?\")\n\n        choice = self.main_window.interfaces.get_warning_choice(msg, short_msg)\n\n        if choice:\n            self.main_window.grid.actions.clear_globals_reload_modules()\n\n            statustext = _(\"Globals cleared and base modules reloaded.\")\n            post_command_event(self.main_window, self.main_window.StatusBarMsg,\n                               text=statustext)", "response": "Clear globals event handler"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef OnPageSetup(self, event):\n\n        print_data = self.main_window.print_data\n        new_print_data = \\\n            self.main_window.interfaces.get_print_setup(print_data)\n        self.main_window.print_data = new_print_data", "response": "Page setup event handler for printing framework"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning selection bounding box or visible area", "response": "def _get_print_area(self):\n        \"\"\"Returns selection bounding box or visible area\"\"\"\n\n        # Get print area from current selection\n        selection = self.main_window.grid.selection\n        print_area = selection.get_bbox()\n\n        # If there is no selection use the visible area on the screen\n        if print_area is None:\n            print_area = self.main_window.grid.actions.get_visible_area()\n\n        return print_area"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef OnPrintPreview(self, event):\n\n        print_area = self._get_print_area()\n        print_data = self.main_window.print_data\n\n        self.main_window.actions.print_preview(print_area, print_data)", "response": "Print preview event handler"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef OnPaste(self, event):\n\n        data = self.main_window.clipboard.get_clipboard()\n\n        focus = self.main_window.FindFocus()\n\n        if isinstance(focus, wx.TextCtrl):\n            # Paste into TextCtrl if in focus\n            focus.WriteText(data)\n\n        else:\n            # We got a grid selection\n            key = self.main_window.grid.actions.cursor\n\n            with undo.group(_(\"Paste\")):\n                self.main_window.actions.paste(key, data)\n\n        self.main_window.grid.ForceRefresh()\n\n        event.Skip()", "response": "Clipboard paste event handler"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef OnPasteAs(self, event):\n\n        data = self.main_window.clipboard.get_clipboard()\n        key = self.main_window.grid.actions.cursor\n\n        with undo.group(_(\"Paste As...\")):\n            self.main_window.actions.paste_as(key, data)\n\n        self.main_window.grid.ForceRefresh()\n\n        event.Skip()", "response": "Clipboard paste as event handler"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef OnSelectAll(self, event):\n\n        entry_line = \\\n            self.main_window.entry_line_panel.entry_line_panel.entry_line\n\n        if wx.Window.FindFocus() != entry_line:\n            self.main_window.grid.SelectAll()\n\n        else:\n            entry_line.SelectAll()", "response": "Select all cells event handler"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef OnMacroListSave(self, event):\n\n        # Get filepath from user\n\n        wildcards = get_filetypes2wildcards([\"py\", \"all\"]).values()\n\n        wildcard = \"|\".join(wildcards)\n\n        message = _(\"Choose macro file.\")\n\n        style = wx.SAVE\n        filepath, filterindex = \\\n            self.interfaces.get_filepath_findex_from_user(wildcard, message,\n                                                          style)\n\n        if filepath is None:\n            return\n\n        # Save macros to file\n\n        macros = self.main_window.grid.code_array.macros\n        self.main_window.actions.save_macros(filepath, macros)\n\n        event.Skip()", "response": "Macro list save event handler"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd items in data as a submenu to parent", "response": "def _add_submenu(self, parent, data):\n        \"\"\"Adds items in data as a submenu to parent\"\"\"\n\n        for item in data:\n            obj = item[0]\n            if obj == wx.Menu:\n                try:\n                    __, menuname, submenu, menu_id = item\n                except ValueError:\n                    __, menuname, submenu = item\n                    menu_id = -1\n\n                menu = obj()\n                self._add_submenu(menu, submenu)\n\n                if parent == self:\n                    self.menubar.Append(menu, menuname)\n                else:\n                    parent.AppendMenu(menu_id, menuname, menu)\n\n            elif obj == wx.MenuItem:\n                try:\n                    msgtype, shortcut, helptext, item_id = item[1]\n                except ValueError:\n                    msgtype, shortcut, helptext = item[1]\n                    item_id = wx.NewId()\n\n                try:\n                    style = item[2]\n                except IndexError:\n                    style = wx.ITEM_NORMAL\n\n                menuitem = obj(parent, item_id, shortcut, helptext, style)\n                self.shortcut2menuitem[shortcut] = menuitem\n                self.id2menuitem[item_id] = menuitem\n\n                parent.AppendItem(menuitem)\n\n                self.ids_msgs[item_id] = msgtype\n\n                self.parent.Bind(wx.EVT_MENU, self.OnMenu, id=item_id)\n\n            elif obj == \"Separator\":\n                parent.AppendSeparator()\n\n            else:\n                raise TypeError(_(\"Menu item unknown\"))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef enable_file_approve(self, enable=True):\n\n        approve_item = self.shortcut2menuitem[_(\"&Approve file\")]\n        approve_item.Enable(enable)", "response": "Enables or disables the approve file menu item."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_code(self, code):\n\n        # If string representations of False are in the code\n        # then it has to be converted explicitly\n\n        if code == \"False\" or code == \"0\":\n            code = False\n\n        self.SetValue(bool(code))", "response": "Sets the value of the flag from the given string representation of bool value."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbind events to handlers", "response": "def __bindings(self):\n        \"\"\"Binds events to handlers\"\"\"\n\n        self.textctrl.Bind(wx.EVT_TEXT, self.OnText)\n        self.fontbutton.Bind(wx.EVT_BUTTON, self.OnFont)\n        self.Bind(csel.EVT_COLOURSELECT, self.OnColor)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn kwargs dict for text", "response": "def get_kwargs(self):\n        \"\"\"Return kwargs dict for text\"\"\"\n\n        kwargs = {}\n\n        if self.font_face:\n            kwargs[\"fontname\"] = repr(self.font_face)\n        if self.font_size:\n            kwargs[\"fontsize\"] = repr(self.font_size)\n        if self.font_style in self.style_wx2mpl:\n            kwargs[\"fontstyle\"] = repr(self.style_wx2mpl[self.font_style])\n        if self.font_weight in self.weight_wx2mpl:\n            kwargs[\"fontweight\"] = repr(self.weight_wx2mpl[self.font_weight])\n\n        kwargs[\"color\"] = color2code(self.colorselect.GetValue())\n\n        code = \", \".join(repr(key) + \": \" + kwargs[key] for key in kwargs)\n\n        code = \"{\" + code + \"}\"\n\n        return code"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_kwargs(self, code):\n\n        kwargs = {}\n\n        kwarglist = list(parse_dict_strings(code[1:-1]))\n\n        for kwarg, val in zip(kwarglist[::2], kwarglist[1::2]):\n            kwargs[unquote_string(kwarg)] = val\n\n        for key in kwargs:\n            if key == \"color\":\n                color = code2color(kwargs[key])\n                self.colorselect.SetOwnForegroundColour(color)\n\n            elif key == \"fontname\":\n                self.font_face = unquote_string(kwargs[key])\n\n                if self.chosen_font is None:\n                    self.chosen_font = get_default_font()\n                self.chosen_font.SetFaceName(self.font_face)\n\n            elif key == \"fontsize\":\n                if kwargs[key]:\n                    self.font_size = int(kwargs[key])\n                else:\n                    self.font_size = get_default_font().GetPointSize()\n\n                if self.chosen_font is None:\n                    self.chosen_font = get_default_font()\n\n                self.chosen_font.SetPointSize(self.font_size)\n\n            elif key == \"fontstyle\":\n                self.font_style = \\\n                    self.style_mpl2wx[unquote_string(kwargs[key])]\n\n                if self.chosen_font is None:\n                    self.chosen_font = get_default_font()\n\n                self.chosen_font.SetStyle(self.font_style)\n\n            elif key == \"fontweight\":\n                self.font_weight = \\\n                    self.weight_mpl2wx[unquote_string(kwargs[key])]\n\n                if self.chosen_font is None:\n                    self.chosen_font = get_default_font()\n\n                self.chosen_font.SetWeight(self.font_weight)", "response": "Sets widget from kwargs string"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef OnFont(self, event):\n\n        font_data = wx.FontData()\n\n        # Disable color chooser on Windows\n        font_data.EnableEffects(False)\n\n        if self.chosen_font:\n            font_data.SetInitialFont(self.chosen_font)\n\n        dlg = wx.FontDialog(self, font_data)\n\n        if dlg.ShowModal() == wx.ID_OK:\n            font_data = dlg.GetFontData()\n\n            font = self.chosen_font = font_data.GetChosenFont()\n\n            self.font_face = font.GetFaceName()\n            self.font_size = font.GetPointSize()\n            self.font_style = font.GetStyle()\n            self.font_weight = font.GetWeight()\n\n        dlg.Destroy()\n\n        post_command_event(self, self.DrawChartMsg)", "response": "Check event handler for font dialog and update font properties"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __bindings(self):\n\n        self.direction_choicectrl.Bind(wx.EVT_CHOICE, self.OnDirectionChoice)\n        self.sec_checkboxctrl.Bind(wx.EVT_CHECKBOX, self.OnSecondaryCheckbox)\n        self.pad_intctrl.Bind(EVT_INT, self.OnPadIntCtrl)\n        self.labelsize_intctrl.Bind(EVT_INT, self.OnLabelSizeIntCtrl)", "response": "Binds events to handlers"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_kwargs(self):\n\n        kwargs = {}\n\n        for attr in self.attrs:\n            val = self.attrs[attr]\n            if val is not None:\n                kwargs[attr] = repr(val)\n\n        code = \", \".join(repr(key) + \": \" + kwargs[key] for key in kwargs)\n\n        code = \"{\" + code + \"}\"\n\n        return code", "response": "Return kwargs dict for text"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_kwargs(self, code):\n\n        kwargs = {}\n\n        kwarglist = list(parse_dict_strings(code[1:-1]))\n\n        for kwarg, val in zip(kwarglist[::2], kwarglist[1::2]):\n            kwargs[unquote_string(kwarg)] = val\n\n        for key in kwargs:\n            if key == \"direction\":\n                self.attrs[key] = unquote_string(kwargs[key])\n                label = self.choice_param2label[self.attrs[key]]\n                label_list = self.direction_choicectrl.Items\n                self.direction_choicectrl.SetSelection(label_list.index(label))\n\n            elif key == \"pad\":\n                self.attrs[key] = int(kwargs[key])\n                self.pad_intctrl.SetValue(self.attrs[key])\n\n            elif key in [\"top\", \"right\"]:\n                self.attrs[key] = (not kwargs[key] == \"False\")\n                if self.attrs[key]:\n                    self.sec_checkboxctrl.Set3StateValue(wx.CHK_CHECKED)\n                else:\n                    self.sec_checkboxctrl.Set3StateValue(wx.CHK_UNCHECKED)\n\n            elif key == \"labelsize\":\n                self.attrs[key] = int(kwargs[key])\n                self.labelsize_intctrl.SetValue(self.attrs[key])", "response": "Sets widget from kwargs string"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef OnSecondaryCheckbox(self, event):\n\n        self.attrs[\"top\"] = event.IsChecked()\n        self.attrs[\"right\"] = event.IsChecked()\n\n        post_command_event(self, self.DrawChartMsg)", "response": "Top Checkbox event handler"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef OnPadIntCtrl(self, event):\n\n        self.attrs[\"pad\"] = event.GetValue()\n\n        post_command_event(self, self.DrawChartMsg)", "response": "Pad IntCtrl event handler"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlabeling size IntCtrl event handler", "response": "def OnLabelSizeIntCtrl(self, event):\n        \"\"\"Label size IntCtrl event handler\"\"\"\n\n        self.attrs[\"labelsize\"] = event.GetValue()\n\n        post_command_event(self, self.DrawChartMsg)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_code(self):\n\n        selection = self.GetSelection()\n\n        if selection == wx.NOT_FOUND:\n            selection = 0\n\n        # Return code string\n        return self.styles[selection][1]", "response": "Returns code representation of value of widget"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the widget from code string", "response": "def set_code(self, code):\n        \"\"\"Sets widget from code string\n\n        Parameters\n        ----------\n        code: String\n        \\tCode representation of widget value\n\n        \"\"\"\n\n        for i, (_, style_code) in enumerate(self.styles):\n            if code == style_code:\n                self.SetSelection(i)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(self, series_data):\n\n        for key in series_data:\n            try:\n                data_list = list(self.data[key])\n                data_list[2] = str(series_data[key])\n                self.data[key] = tuple(data_list)\n            except KeyError:\n                pass", "response": "Updates self. data from series data"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns current plot panel", "response": "def get_plot_panel(self):\n        \"\"\"Returns current plot_panel\"\"\"\n\n        plot_type_no = self.chart_type_book.GetSelection()\n        return self.chart_type_book.GetPage(plot_type_no)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __bindings(self):\n\n        self.Bind(fnb.EVT_FLATNOTEBOOK_PAGE_CHANGED, self.OnSeriesChanged)\n        self.Bind(fnb.EVT_FLATNOTEBOOK_PAGE_CLOSING, self.OnSeriesDeleted)", "response": "Binds events to handlers"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update(self, series_list):\n\n        if not series_list:\n            self.series_notebook.AddPage(wx.Panel(self, -1), _(\"+\"))\n            return\n\n        self.updating = True\n\n        # Delete all tabs in the notebook\n        self.series_notebook.DeleteAllPages()\n\n        # Add as many tabs as there are series in code\n\n        for page, attrdict in enumerate(series_list):\n            series_panel = SeriesPanel(self.grid, attrdict)\n            name = \"Series\"\n\n            self.series_notebook.InsertPage(page, series_panel, name)\n\n        self.series_notebook.AddPage(wx.Panel(self, -1), _(\"+\"))\n\n        self.updating = False", "response": "Updates the content of the series_list widget with the contents of the series_list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef OnSeriesChanged(self, event):\n\n        selection = event.GetSelection()\n\n        if not self.updating and \\\n           selection == self.series_notebook.GetPageCount() - 1:\n            # Add new series\n            new_panel = SeriesPanel(self, {\"type\": \"plot\"})\n            self.series_notebook.InsertPage(selection, new_panel, _(\"Series\"))\n\n        event.Skip()", "response": "Event handler for series changed event handler"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the figure canvas and layout", "response": "def update(self, figure):\n        \"\"\"Updates figure on data change\n\n        Parameters\n        ----------\n        * figure: matplotlib.figure.Figure\n        \\tMatplotlib figure object that is displayed in self\n\n        \"\"\"\n\n        if hasattr(self, \"figure_canvas\"):\n            self.figure_canvas.Destroy()\n\n        self.figure_canvas = self._get_figure_canvas(figure)\n\n        self.figure_canvas.SetSize(self.GetSize())\n        figure.subplots_adjust()\n\n        self.main_sizer.Add(self.figure_canvas, 1,\n                            wx.EXPAND | wx.FIXED_MINSIZE, 0)\n\n        self.Layout()\n        self.figure_canvas.draw()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_figure(self, code):\n\n        # Caching for fast response if there are no changes\n        if code == self.figure_code_old and self.figure_cache:\n            return self.figure_cache\n\n        self.figure_code_old = code\n\n        # key is the current cursor cell of the grid\n        key = self.grid.actions.cursor\n        cell_result = self.grid.code_array._eval_cell(key, code)\n\n        # If cell_result is matplotlib figure\n        if isinstance(cell_result, matplotlib.pyplot.Figure):\n            # Return it\n            self.figure_cache = cell_result\n            return cell_result\n\n        else:\n            # Otherwise return empty figure\n            self.figure_cache = charts.ChartFigure()\n\n        return self.figure_cache", "response": "Returns a matplotlib figure instance from executing code in grid\n           "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_code(self, code):\n\n        # Get attributes from code\n\n        attributes = []\n        strip = lambda s: s.strip('u').strip(\"'\").strip('\"')\n        for attr_dict in parse_dict_strings(unicode(code).strip()[19:-1]):\n            attrs = list(strip(s) for s in parse_dict_strings(attr_dict[1:-1]))\n            attributes.append(dict(zip(attrs[::2], attrs[1::2])))\n\n        if not attributes:\n            return\n\n        # Set widgets from attributes\n        # ---------------------------\n\n        # Figure attributes\n        figure_attributes = attributes[0]\n\n        for key, widget in self.figure_attributes_panel:\n            try:\n                obj = figure_attributes[key]\n                kwargs_key = key + \"_kwargs\"\n                if kwargs_key in figure_attributes:\n                    widget.set_kwargs(figure_attributes[kwargs_key])\n\n            except KeyError:\n                obj = \"\"\n\n            widget.code = charts.object2code(key, obj)\n\n        # Series attributes\n        self.all_series_panel.update(attributes[1:])", "response": "Update widgets from code"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_code(self):\n\n        def dict2str(attr_dict):\n            \"\"\"Returns string with dict content with values as code\n\n            Code means that string identifiers are removed\n\n            \"\"\"\n\n            result = u\"{\"\n\n            for key in attr_dict:\n                code = attr_dict[key]\n\n                if key in self.string_keys:\n                    code = repr(code)\n\n                elif code and key in self.tuple_keys and \\\n                     not (code[0] in [\"[\", \"(\"] and code[-1] in [\"]\", \")\"]):\n\n                    code = \"(\" + code + \")\"\n\n                elif key in [\"xscale\", \"yscale\"]:\n                    if code:\n                        code = '\"log\"'\n                    else:\n                        code = '\"linear\"'\n\n                elif key in [\"legend\"]:\n                    if code:\n                        code = '1'\n                    else:\n                        code = '0'\n\n                elif key in [\"xtick_params\"]:\n                    code = '\"x\"'\n\n                elif key in [\"ytick_params\"]:\n                    code = '\"y\"'\n\n                if not code:\n                    if key in self.empty_none_keys:\n                        code = \"None\"\n                    else:\n                        code = 'u\"\"'\n\n                result += repr(key) + \": \" + code + \", \"\n\n            result = result[:-2] + u\"}\"\n\n            return result\n\n        # cls_name inludes full class name incl. charts\n        cls_name = \"charts.\" + charts.ChartFigure.__name__\n\n        attr_dicts = []\n\n        # Figure attributes\n        attr_dict = {}\n        # figure_attributes is a dict key2code\n        for key, widget in self.figure_attributes_panel:\n            if key == \"type\":\n                attr_dict[key] = widget\n            else:\n                attr_dict[key] = widget.code\n                try:\n                    attr_dict[key+\"_kwargs\"] = widget.get_kwargs()\n                except AttributeError:\n                    pass\n\n        attr_dicts.append(attr_dict)\n\n        # Series_attributes is a list of dicts key2code\n        for series_panel in self.all_series_panel:\n            attr_dict = {}\n            for key, widget in series_panel:\n                if key == \"type\":\n                    attr_dict[key] = widget\n                else:\n                    attr_dict[key] = widget.code\n\n            attr_dicts.append(attr_dict)\n\n        code = cls_name + \"(\"\n\n        for attr_dict in attr_dicts:\n            code += dict2str(attr_dict) + \", \"\n\n        code = code[:-2] + \")\"\n\n        return code", "response": "Returns code that generates figure from widgets"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef OnUpdateFigurePanel(self, event):\n\n        if self.updating:\n            return\n\n        self.updating = True\n        self.figure_panel.update(self.get_figure(self.code))\n        self.updating = False", "response": "Redraw event handler for the figure panel"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parameters(self):\n\n        return self.block_tl, self.block_br, self.rows, self.cols, self.cells", "response": "Returns tuple of selection parameters of self"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef insert(self, point, number, axis):\n\n        def build_tuple_list(source_list, point, number, axis):\n            \"\"\"Returns adjusted tuple list for single cells\"\"\"\n\n            target_list = []\n\n            for tl in source_list:\n                tl_list = list(tl)\n                if tl[axis] > point:\n                    tl_list[axis] += number\n                target_list.append(tuple(tl_list))\n\n            return target_list\n\n        self.block_tl = build_tuple_list(self.block_tl, point, number, axis)\n\n        self.block_br = build_tuple_list(self.block_br, point, number, axis)\n\n        if axis == 0:\n            self.rows = \\\n                [row + number if row > point else row for row in self.rows]\n        elif axis == 1:\n            self.cols = \\\n                [col + number if col > point else col for col in self.cols]\n        else:\n            raise ValueError(\"Axis not in [0, 1]\")\n\n        self.cells = build_tuple_list(self.cells, point, number, axis)", "response": "Inserts number of rows or cols into the selection at point on axis."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_bbox(self):\n\n        bb_top, bb_left, bb_bottom, bb_right = [None] * 4\n\n        # Block selections\n\n        for top_left, bottom_right in zip(self.block_tl, self.block_br):\n            top, left = top_left\n            bottom, right = bottom_right\n\n            if bb_top is None or bb_top > top:\n                bb_top = top\n            if bb_left is None or bb_left > left:\n                bb_left = left\n            if bb_bottom is None or bb_bottom < bottom:\n                bb_bottom = bottom\n            if bb_right is None or bb_right > right:\n                bb_right = right\n\n        # Row and column selections\n\n        for row in self.rows:\n            if bb_top is None or bb_top > row:\n                bb_top = row\n            if bb_bottom is None or bb_bottom < row:\n                bb_bottom = row\n\n        for col in self.cols:\n            if bb_left is None or bb_left > col:\n                bb_left = col\n            if bb_right is None or bb_right < col:\n                bb_right = col\n\n        # Cell selections\n\n        for cell in self.cells:\n            cell_row, cell_col = cell\n\n            if bb_top is None or bb_top > cell_row:\n                bb_top = cell_row\n            if bb_left is None or bb_left > cell_col:\n                bb_left = cell_col\n            if bb_bottom is None or bb_bottom < cell_row:\n                bb_bottom = cell_row\n            if bb_right is None or bb_right < cell_col:\n                bb_right = cell_col\n\n        if all(val is None for val in [bb_top, bb_left, bb_bottom, bb_right]):\n            return None\n\n        return ((bb_top, bb_left), (bb_bottom, bb_right))", "response": "Returns the top left bottom right of the bounding box of the table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_grid_bbox(self, shape):\n\n        (bb_top, bb_left), (bb_bottom, bb_right) = self.get_bbox()\n\n        if bb_top is None:\n            bb_top = 0\n        if bb_left is None:\n            bb_left = 0\n        if bb_bottom is None:\n            bb_bottom = shape[0]\n        if bb_right is None:\n            bb_right = shape[1]\n\n        return ((bb_top, bb_left), (bb_bottom, bb_right))", "response": "Returns the top left bottom right of the grid of the specified size."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_access_string(self, shape, table):\n\n        rows, columns, tables = shape\n\n        # Negative dimensions cannot be\n        assert all(dim > 0 for dim in shape)\n\n        # Current table has to be in dimensions\n        assert 0 <= table < tables\n\n        string_list = []\n\n        # Block selections\n        templ = \"[(r, c, {}) for r in xrange({}, {}) for c in xrange({}, {})]\"\n        for (top, left), (bottom, right) in izip(self.block_tl, self.block_br):\n            string_list += [templ.format(table, top, bottom + 1,\n                                         left, right + 1)]\n\n        # Fully selected rows\n        template = \"[({}, c, {}) for c in xrange({})]\"\n        for row in self.rows:\n            string_list += [template.format(row, table, columns)]\n\n        # Fully selected columns\n        template = \"[(r, {}, {}) for r in xrange({})]\"\n        for column in self.cols:\n            string_list += [template.format(column, table, rows)]\n\n        # Single cells\n        for row, column in self.cells:\n            string_list += [repr([(row, column, table)])]\n\n        key_string = \" + \".join(string_list)\n\n        if len(string_list) == 0:\n            return \"\"\n\n        elif len(self.cells) == 1 and len(string_list) == 1:\n            return \"S[{}]\".format(string_list[0][1:-1])\n\n        else:\n            template = \"[S[key] for key in {} if S[key] is not None]\"\n            return template.format(key_string)", "response": "Returns a string with which the selection can be accessed by the current table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef shifted(self, rows, cols):\n\n        shifted_block_tl = \\\n            [(row + rows, col + cols) for row, col in self.block_tl]\n        shifted_block_br = \\\n            [(row + rows, col + cols) for row, col in self.block_br]\n        shifted_rows = [row + rows for row in self.rows]\n        shifted_cols = [col + cols for col in self.cols]\n        shifted_cells = [(row + rows, col + cols) for row, col in self.cells]\n\n        return Selection(shifted_block_tl, shifted_block_br, shifted_rows,\n                         shifted_cols, shifted_cells)", "response": "Returns a new Selection that is shifted by rows and cols."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef grid_select(self, grid, clear_selection=True):\n\n        if clear_selection:\n            grid.ClearSelection()\n\n        for (tl, br) in zip(self.block_tl, self.block_br):\n            grid.SelectBlock(tl[0], tl[1], br[0], br[1], addToSelected=True)\n\n        for row in self.rows:\n            grid.SelectRow(row, addToSelected=True)\n\n        for col in self.cols:\n            grid.SelectCol(col, addToSelected=True)\n\n        for cell in self.cells:\n            grid.SelectBlock(cell[0], cell[1], cell[0], cell[1],\n                             addToSelected=True)", "response": "Selects cells of grid with selection content"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_user_codeframe(tb):\n    while tb is not None:\n        f = tb.tb_frame\n        co = f.f_code\n        filename = co.co_filename\n        if filename[0] == '<':\n            # This is a meta-descriptor\n            # (probably either \"<unknown>\" or \"<string>\")\n            # and is likely the user's code we're executing\n            return tb\n        else:\n            tb = tb.tb_next\n    # We could not find the user's frame.\n    return False", "response": "Return the traceback that contains the user s code frame."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef object2code(key, code):\n\n    if key in [\"xscale\", \"yscale\"]:\n        if code == \"log\":\n            code = True\n        else:\n            code = False\n\n    else:\n        code = unicode(code)\n\n    return code", "response": "Returns code for widget from dict object"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fig2bmp(figure, width, height, dpi, zoom):\n\n    dpi *= float(zoom)\n\n    figure.set_figwidth(width / dpi)\n    figure.set_figheight(height / dpi)\n    figure.subplots_adjust()\n\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n\n    try:\n        # The padding is too small for small sizes. This fixes it.\n        figure.tight_layout(pad=1.0/zoom)\n    except ValueError:\n        pass\n\n    figure.set_canvas(FigureCanvas(figure))\n    png_stream = StringIO()\n\n    figure.savefig(png_stream, format='png', dpi=(dpi))\n\n    png_stream.seek(0)\n    img = wx.ImageFromStream(png_stream, type=wx.BITMAP_TYPE_PNG)\n\n    return wx.BitmapFromImage(img)", "response": "Returns wx. Bitmap from matplotlib figure"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn svg from matplotlib chart", "response": "def fig2x(figure, format):\n    \"\"\"Returns svg from matplotlib chart\"\"\"\n\n    # Save svg to file like object svg_io\n    io = StringIO()\n    figure.savefig(io, format=format)\n\n    # Rewind the file like object\n    io.seek(0)\n\n    data = io.getvalue()\n    io.close()\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmakes x axis a date axis with auto format", "response": "def _xdate_setter(self, xdate_format='%Y-%m-%d'):\n        \"\"\"Makes x axis a date axis with auto format\n\n        Parameters\n        ----------\n\n        xdate_format: String\n        \\tSets date formatting\n\n        \"\"\"\n\n        if xdate_format:\n            # We have to validate xdate_format. If wrong then bail out.\n            try:\n                self.autofmt_xdate()\n                datetime.date(2000, 1, 1).strftime(xdate_format)\n\n            except ValueError:\n                self.autofmt_xdate()\n                return\n\n            self.__axes.xaxis_date()\n            formatter = dates.DateFormatter(xdate_format)\n            self.__axes.xaxis.set_major_formatter(formatter)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets up the axes for drawing chart", "response": "def _setup_axes(self, axes_data):\n        \"\"\"Sets up axes for drawing chart\"\"\"\n\n        self.__axes.clear()\n\n        key_setter = [\n            (\"title\", self.__axes.set_title),\n            (\"xlabel\", self.__axes.set_xlabel),\n            (\"ylabel\", self.__axes.set_ylabel),\n            (\"xscale\", self.__axes.set_xscale),\n            (\"yscale\", self.__axes.set_yscale),\n            (\"xticks\", self.__axes.set_xticks),\n            (\"xtick_labels\", self.__axes.set_xticklabels),\n            (\"xtick_params\", self.__axes.tick_params),\n            (\"yticks\", self.__axes.set_yticks),\n            (\"ytick_labels\", self.__axes.set_yticklabels),\n            (\"ytick_params\", self.__axes.tick_params),\n            (\"xlim\", self.__axes.set_xlim),\n            (\"ylim\", self.__axes.set_ylim),\n            (\"xgrid\", self.__axes.xaxis.grid),\n            (\"ygrid\", self.__axes.yaxis.grid),\n            (\"xdate_format\", self._xdate_setter),\n        ]\n\n        key2setter = OrderedDict(key_setter)\n\n        for key in key2setter:\n            if key in axes_data and axes_data[key]:\n                try:\n                    kwargs_key = key + \"_kwargs\"\n                    kwargs = axes_data[kwargs_key]\n\n                except KeyError:\n                    kwargs = {}\n\n                if key == \"title\":\n                    # Shift title up\n                    kwargs[\"y\"] = 1.08\n\n                key2setter[key](axes_data[key], **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nplot chart from self. attributes", "response": "def draw_chart(self):\n        \"\"\"Plots chart from self.attributes\"\"\"\n\n        if not hasattr(self, \"attributes\"):\n            return\n\n        # The first element is always axes data\n        self._setup_axes(self.attributes[0])\n\n        for attribute in self.attributes[1:]:\n\n            series = copy(attribute)\n            # Extract chart type\n            chart_type_string = series.pop(\"type\")\n\n            x_str, y_str = self.plot_type_xy_mapping[chart_type_string]\n            # Check xdata length\n            if x_str in series and \\\n               len(series[x_str]) != len(series[y_str]):\n                # Wrong length --> ignore xdata\n                series[x_str] = range(len(series[y_str]))\n            else:\n                # Solve the problem that the series data may contain utf-8 data\n                series_list = list(series[x_str])\n                series_unicode_list = []\n                for ele in series_list:\n                    if isinstance(ele, types.StringType):\n                        try:\n                            series_unicode_list.append(ele.decode('utf-8'))\n                        except Exception:\n                            series_unicode_list.append(ele)\n                    else:\n                        series_unicode_list.append(ele)\n                series[x_str] = tuple(series_unicode_list)\n\n            fixed_attrs = []\n            if chart_type_string in self.plot_type_fixed_attrs:\n                for attr in self.plot_type_fixed_attrs[chart_type_string]:\n                    # Remove attr if it is a fixed (non-kwd) attr\n                    # If a fixed attr is missing, insert a dummy\n                    try:\n                        fixed_attrs.append(tuple(series.pop(attr)))\n                    except KeyError:\n                        fixed_attrs.append(())\n\n            # Remove contour chart label info from series\n            cl_attrs = {}\n            for contour_label_attr in self.contour_label_attrs:\n                if contour_label_attr in series:\n                    cl_attrs[self.contour_label_attrs[contour_label_attr]] = \\\n                        series.pop(contour_label_attr)\n\n            # Remove contourf attributes from series\n            cf_attrs = {}\n            for contourf_attr in self.contourf_attrs:\n                if contourf_attr in series:\n                    cf_attrs[self.contourf_attrs[contourf_attr]] = \\\n                        series.pop(contourf_attr)\n\n            if not fixed_attrs or all(fixed_attrs):\n                # Draw series to axes\n\n                # Do we have a Sankey plot --> build it\n                if chart_type_string == \"Sankey\":\n                    Sankey(self.__axes, **series).finish()\n\n                else:\n                    chart_method = getattr(self.__axes, chart_type_string)\n                    plot = chart_method(*fixed_attrs, **series)\n\n                # Do we have a filled contour?\n                try:\n                    if cf_attrs.pop(\"contour_fill\"):\n                        cf_attrs.update(series)\n                        if \"linewidths\" in cf_attrs:\n                            cf_attrs.pop(\"linewidths\")\n                        if \"linestyles\" in cf_attrs:\n                            cf_attrs.pop(\"linestyles\")\n                        if not cf_attrs[\"hatches\"]:\n                            cf_attrs.pop(\"hatches\")\n                        self.__axes.contourf(plot, **cf_attrs)\n                except KeyError:\n                    pass\n\n                # Do we have a contour chart label?\n                try:\n                    if cl_attrs.pop(\"contour_labels\"):\n                        self.__axes.clabel(plot, **cl_attrs)\n                except KeyError:\n                    pass\n\n        # The legend has to be set up after all series are drawn\n        self._setup_legend(self.attributes[0])"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the source string of a cell", "response": "def GetSource(self, row, col, table=None):\n        \"\"\"Return the source string of a cell\"\"\"\n\n        if table is None:\n            table = self.grid.current_table\n\n        value = self.code_array((row, col, table))\n\n        if value is None:\n            return u\"\"\n        else:\n            return value"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef GetValue(self, row, col, table=None):\n\n        if table is None:\n            table = self.grid.current_table\n\n        try:\n            cell_code = self.code_array((row, col, table))\n        except IndexError:\n            cell_code = None\n\n        # Put EOLs into result if it is too long\n        maxlength = int(config[\"max_textctrl_length\"])\n\n        if cell_code is not None and len(cell_code) > maxlength:\n            chunk = 80\n            cell_code = \"\\n\".join(cell_code[i:i + chunk]\n                                  for i in xrange(0, len(cell_code), chunk))\n\n        return cell_code", "response": "Return the result value of a cell line split if too much data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef SetValue(self, row, col, value, refresh=True):\n\n        # Join code that has been split because of long line issue\n        value = \"\".join(value.split(\"\\n\"))\n\n        key = row, col, self.grid.current_table\n\n        old_code = self.grid.code_array(key)\n        if old_code is None:\n            old_code = \"\"\n\n        if value != old_code:\n            self.grid.actions.set_code(key, value)", "response": "Set the value of a cell"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef UpdateValues(self):\n\n        # This sends an event to the grid table\n        # to update all of the values\n\n        msg = wx.grid.GridTableMessage(self,\n                wx.grid.GRIDTABLE_REQUEST_VIEW_GET_VALUES)\n        self.grid.ProcessTableMessage(msg)", "response": "Update all displayed values"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreset the grid view.", "response": "def ResetView(self):\n        \"\"\"\n        (Grid) -> Reset the grid view.   Call this to\n        update the grid if rows and columns have been added or deleted\n\n        \"\"\"\n\n        grid = self.grid\n\n        current_rows = self.grid.GetNumberRows()\n        current_cols = self.grid.GetNumberCols()\n\n        grid.BeginBatch()\n\n        for current, new, delmsg, addmsg in [\n            (current_rows, self.GetNumberRows(),\n             wx.grid.GRIDTABLE_NOTIFY_ROWS_DELETED,\n             wx.grid.GRIDTABLE_NOTIFY_ROWS_APPENDED),\n            (current_cols, self.GetNumberCols(),\n             wx.grid.GRIDTABLE_NOTIFY_COLS_DELETED,\n             wx.grid.GRIDTABLE_NOTIFY_COLS_APPENDED)]:\n\n            if new < current:\n                msg = wx.grid.GridTableMessage(self, delmsg, new,\n                                               current - new)\n                grid.ProcessTableMessage(msg)\n            elif new > current:\n                msg = wx.grid.GridTableMessage(self, addmsg, new - current)\n                grid.ProcessTableMessage(msg)\n                self.UpdateValues()\n\n        grid.EndBatch()\n\n        # Reset cell sizes to standard cell size\n\n        grid.SetDefaultRowSize(grid.GetDefaultRowSize(),\n                               resizeExistingRows=True)\n        grid.SetDefaultColSize(grid.GetDefaultColSize(),\n                               resizeExistingCols=True)\n\n        # Adjust rows\n        row_heights = grid.code_array.row_heights\n        for key in row_heights:\n            if key[1] == grid.current_table and \\\n               key[0] < self.code_array.shape[0]:\n                row = key[0]\n                if row_heights[key] is None:\n                    # Default row size\n                    grid.SetRowSize(row, grid.GetDefaultRowSize())\n                else:\n                    grid.SetRowSize(row, row_heights[key])\n\n        # Adjust columns\n        col_widths = grid.code_array.col_widths\n        for key in col_widths:\n            if key[1] == grid.current_table and \\\n               key[0] < self.code_array.shape[1]:\n                col = key[0]\n                if col_widths[key] is None:\n                    # Default row size\n                    grid.SetColSize(col, grid.GetDefaultColSize())\n                else:\n                    grid.SetColSize(col, col_widths[key])\n\n        # update the scrollbars and the displayed part\n        # of the grid\n\n        grid.Freeze()\n        grid.AdjustScrollbars()\n        grid.Refresh()\n        grid.Thaw()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nposting command event to main window", "response": "def post_command_event(target, msg_cls, **kwargs):\n    \"\"\"Posts command event to main window\n\n    Command events propagate.\n\n    Parameters\n    ----------\n     * msg_cls: class\n    \\tMessage class from new_command_event()\n     * kwargs: dict\n    \\tMessage arguments\n\n    \"\"\"\n\n    msg = msg_cls(id=-1, **kwargs)\n    wx.PostEvent(target, msg)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _convert_clipboard(self, datastring=None, sep='\\t'):\n\n        if datastring is None:\n            datastring = self.get_clipboard()\n\n        data_it = ((ele for ele in line.split(sep))\n                            for line in datastring.splitlines())\n        return data_it", "response": "Converts the clipboard string to iterable."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_clipboard(self):\n\n        bmpdata = wx.BitmapDataObject()\n        textdata = wx.TextDataObject()\n\n        if self.clipboard.Open():\n            is_bmp_present = self.clipboard.GetData(bmpdata)\n            self.clipboard.GetData(textdata)\n            self.clipboard.Close()\n        else:\n            wx.MessageBox(_(\"Can't open the clipboard\"), _(\"Error\"))\n\n        if is_bmp_present:\n            return bmpdata.GetBitmap()\n        else:\n            return textdata.GetText()", "response": "Returns the clipboard content as a string."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites data to the clipboard", "response": "def set_clipboard(self, data, datatype=\"text\"):\n        \"\"\"Writes data to the clipboard\n\n        Parameters\n        ----------\n        data: Object\n        \\tData object for clipboard\n        datatype: String in [\"text\", \"bitmap\"]\n        \\tIdentifies datatype to be copied to the clipboard\n\n        \"\"\"\n\n        error_log = []\n\n        if datatype == \"text\":\n            clip_data = wx.TextDataObject(text=data)\n\n        elif datatype == \"bitmap\":\n            clip_data = wx.BitmapDataObject(bitmap=data)\n\n        else:\n            msg = _(\"Datatype {type} unknown\").format(type=datatype)\n            raise ValueError(msg)\n\n        if self.clipboard.Open():\n            self.clipboard.SetData(clip_data)\n            self.clipboard.Close()\n        else:\n            wx.MessageBox(_(\"Can't open the clipboard\"), _(\"Error\"))\n\n        return error_log"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _is_aborted(self, cycle, statustext, total_elements=None, freq=None):\n\n        if total_elements is None:\n            statustext += _(\"{nele} elements processed. Press <Esc> to abort.\")\n        else:\n            statustext += _(\"{nele} of {totalele} elements processed. \"\n                            \"Press <Esc> to abort.\")\n\n        if freq is None:\n            show_msg = False\n            freq = 1000\n        else:\n            show_msg = True\n\n        # Show progress in statusbar each freq (1000) cells\n        if cycle % freq == 0:\n            if show_msg:\n                text = statustext.format(nele=cycle, totalele=total_elements)\n                try:\n                    post_command_event(self.main_window, self.StatusBarMsg,\n                                       text=text)\n                except TypeError:\n                    # The main window does not exist any more\n                    pass\n\n            # Now wait for the statusbar update to be written on screen\n            if is_gtk():\n                try:\n                    wx.Yield()\n                except:\n                    pass\n\n            # Abort if we have to\n            if self.need_abort:\n                # We have to abort`\n                return True\n\n        # Continue\n        return False", "response": "Displays progress and returns True if aborted"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate_signature(self, filename):\n\n        if not GPG_PRESENT:\n            return False\n\n        sigfilename = filename + '.sig'\n\n        try:\n            with open(sigfilename):\n                pass\n\n        except IOError:\n            # Signature file does not exist\n            return False\n\n        # Check if the sig is valid for the sigfile\n        # TODO: Check for whitespace in filepaths\n        return verify(sigfilename, filename)", "response": "Returns True if a valid signature is present for filename"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting safe mode if signature missing of invalid", "response": "def approve(self, filepath):\n        \"\"\"Sets safe mode if signature missing of invalid\"\"\"\n\n        try:\n            signature_valid = self.validate_signature(filepath)\n\n        except ValueError:\n            # GPG is not installed\n            signature_valid = False\n\n        if signature_valid:\n            self.leave_safe_mode()\n            post_command_event(self.main_window, self.SafeModeExitMsg)\n\n            statustext = _(\"Valid signature found. File is trusted.\")\n            post_command_event(self.main_window, self.StatusBarMsg,\n                               text=statustext)\n\n        else:\n            self.enter_safe_mode()\n            post_command_event(self.main_window, self.SafeModeEntryMsg)\n\n            statustext = \\\n                _(\"File is not properly signed. Safe mode \"\n                  \"activated. Select File -> Approve to leave safe mode.\")\n            post_command_event(self.main_window, self.StatusBarMsg,\n                               text=statustext)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nclear globals and reloads modules", "response": "def clear_globals_reload_modules(self):\n        \"\"\"Clears globals and reloads modules\"\"\"\n\n        self.code_array.clear_globals()\n        self.code_array.reload_modules()\n\n        # Clear result cache\n        self.code_array.result_cache.clear()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns infile version string.", "response": "def _get_file_version(self, infile):\n        \"\"\"Returns infile version string.\"\"\"\n\n        # Determine file version\n        for line1 in infile:\n            if line1.strip() != \"[Pyspread save file version]\":\n                raise ValueError(_(\"File format unsupported.\"))\n            break\n\n        for line2 in infile:\n            return line2.strip()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clear(self, shape=None):\n\n        # Without setting this explicitly, the cursor is set too late\n        self.grid.actions.cursor = 0, 0, 0\n        self.grid.current_table = 0\n\n        post_command_event(self.main_window.grid, self.GotoCellMsg,\n                           key=(0, 0, 0))\n\n        # Clear cells\n        self.code_array.dict_grid.clear()\n\n        # Clear attributes\n        del self.code_array.dict_grid.cell_attributes[:]\n\n        if shape is not None:\n            # Set shape\n            self.code_array.shape = shape\n\n        # Clear row heights and column widths\n        self.code_array.row_heights.clear()\n        self.code_array.col_widths.clear()\n\n        # Clear macros\n        self.code_array.macros = \"\"\n\n        # Clear caches\n        self.code_array.result_cache.clear()\n\n        # Clear globals\n        self.code_array.clear_globals()\n        self.code_array.reload_modules()", "response": "Clears all cells row heights column widths and frozen states."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nopen a file that is specified in event. attr and returns a dict containing the related object that is used to load the file.", "response": "def open(self, event):\n        \"\"\"Opens a file that is specified in event.attr\n\n        Parameters\n        ----------\n        event.attr: Dict\n        \\tkey filepath contains file path of file to be loaded\n        \\tkey filetype contains file type of file to be loaded\n        \\tFiletypes can be pys, pysu, xls\n\n        \"\"\"\n\n        filepath = event.attr[\"filepath\"]\n        try:\n            filetype = event.attr[\"filetype\"]\n\n        except KeyError:\n            try:\n                file_ext = filepath.strip().split(\".\")[-1]\n            except:\n                file_ext = None\n\n            if file_ext in [\"pys\", \"pysu\", \"xls\", \"xlsx\", \"ods\"]:\n                filetype = file_ext\n            else:\n                filetype = \"pys\"\n\n        type2opener = {\n            \"pys\": (Bz2AOpen, [filepath, \"r\"], {\"main_window\":\n                                                self.main_window}),\n            \"pysu\": (AOpen, [filepath, \"r\"], {\"main_window\": self.main_window})\n        }\n\n        if xlrd is not None:\n            type2opener[\"xls\"] = \\\n                (xlrd.open_workbook, [filepath], {\"formatting_info\": True})\n\n            type2opener[\"xlsx\"] = \\\n                (xlrd.open_workbook, [filepath], {\"formatting_info\": False})\n\n        if odf is not None and Ods is not None:\n            type2opener[\"ods\"] = (open, [filepath, \"rb\"], {})\n\n        # Specify the interface that shall be used\n        opener, op_args, op_kwargs = type2opener[filetype]\n        Interface = self.type2interface[filetype]\n\n        # Set state for file open\n        self.opening = True\n\n        try:\n            with opener(*op_args, **op_kwargs) as infile:\n                # Make loading safe\n                self.approve(filepath)\n\n                if xlrd is None:\n                    interface_errors = (ValueError, )\n                else:\n                    interface_errors = (ValueError, xlrd.biffh.XLRDError)\n\n                try:\n                    wx.BeginBusyCursor()\n                    self.grid.Disable()\n                    self.clear()\n                    interface = Interface(self.grid.code_array, infile)\n                    interface.to_code_array()\n                    self.grid.main_window.macro_panel.codetext_ctrl.SetText(\n                        self.grid.code_array.macros)\n\n                except interface_errors, err:\n                    post_command_event(self.main_window, self.StatusBarMsg,\n                                       text=str(err))\n\n                finally:\n                    self.grid.GetTable().ResetView()\n                    post_command_event(self.main_window, self.ResizeGridMsg,\n                                       shape=self.grid.code_array.shape)\n                    self.grid.Enable()\n                    wx.EndBusyCursor()\n\n                # Execute macros\n                self.main_window.actions.execute_macros()\n\n                self.grid.GetTable().ResetView()\n                self.grid.ForceRefresh()\n\n                # File sucessfully opened. Approve again to show status.\n                self.approve(filepath)\n\n                # Change current directory to file directory\n                filedir = os.path.dirname(filepath)\n                os.chdir(filedir)\n\n        except IOError, err:\n            txt = _(\"Error opening file {filepath}:\").format(filepath=filepath)\n            txt += \" \" + str(err)\n            post_command_event(self.main_window, self.StatusBarMsg, text=txt)\n\n            return False\n\n        except EOFError:\n            # Normally on empty grids\n            pass\n\n        finally:\n            # Unset state for file open\n            self.opening = False"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsigns a file if possible", "response": "def sign_file(self, filepath):\n        \"\"\"Signs file if possible\"\"\"\n\n        if not GPG_PRESENT:\n            return\n\n        signed_data = sign(filepath)\n        signature = signed_data.data\n\n        if signature is None or not signature:\n            statustext = _('Error signing file. ') + signed_data.stderr\n            try:\n                post_command_event(self.main_window, self.StatusBarMsg,\n                                   text=statustext)\n            except TypeError:\n                # The main window does not exist any more\n                pass\n\n            return\n\n        with open(filepath + '.sig', 'wb') as signfile:\n            signfile.write(signature)\n\n        # Statustext differs if a save has occurred\n\n        if self.code_array.safe_mode:\n            statustext = _('File saved and signed')\n        else:\n            statustext = _('File signed')\n\n        try:\n            post_command_event(self.main_window, self.StatusBarMsg,\n                               text=statustext)\n        except TypeError:\n            # The main window does not exist any more\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_save_states(self):\n\n        wx.BeginBusyCursor()\n        self.saving = True\n        self.grid.Disable()", "response": "Sets application save states"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreleasing application save states", "response": "def _release_save_states(self):\n        \"\"\"Releases application save states\"\"\"\n\n        self.saving = False\n        self.grid.Enable()\n        wx.EndBusyCursor()\n\n        # Mark content as unchanged\n        try:\n            post_command_event(self.main_window, self.ContentChangedMsg)\n        except TypeError:\n            # The main window does not exist any more\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _move_tmp_file(self, tmpfilepath, filepath):\n\n        try:\n            shutil.move(tmpfilepath, filepath)\n\n        except OSError, err:\n            # No tmp file present\n            post_command_event(self.main_window, self.StatusBarMsg, text=err)", "response": "Moves tmpfile over file after saving is finished\n           "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _save_xls(self, filepath):\n\n        Interface = self.type2interface[\"xls\"]\n\n        workbook = xlwt.Workbook()\n        interface = Interface(self.grid.code_array, workbook)\n        interface.from_code_array()\n\n        try:\n            workbook.save(filepath)\n\n        except IOError, err:\n            try:\n                post_command_event(self.main_window, self.StatusBarMsg,\n                                   text=err)\n            except TypeError:\n                # The main window does not exist any more\n                pass", "response": "Saves file as xls workbook"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsave file as pys file and returns True if save success otherwise returns False", "response": "def _save_pys(self, filepath):\n        \"\"\"Saves file as pys file and returns True if save success\n\n        Parameters\n        ----------\n\n        filepath: String\n        \\tTarget file path for xls file\n\n        \"\"\"\n\n        try:\n            with Bz2AOpen(filepath, \"wb\",\n                          main_window=self.main_window) as outfile:\n                interface = Pys(self.grid.code_array, outfile)\n                interface.from_code_array()\n\n        except (IOError, ValueError), err:\n            try:\n                post_command_event(self.main_window, self.StatusBarMsg,\n                                   text=err)\n                return\n            except TypeError:\n                # The main window does not exist any more\n                pass\n\n        return not outfile.aborted"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsigns the new file and saves it to the main window", "response": "def _save_sign(self, filepath):\n        \"\"\"Sign so that the new file may be retrieved without safe mode\"\"\"\n\n        if self.code_array.safe_mode:\n            msg = _(\"File saved but not signed because it is unapproved.\")\n            try:\n                post_command_event(self.main_window, self.StatusBarMsg,\n                                   text=msg)\n            except TypeError:\n                # The main window does not exist any more\n                pass\n\n        else:\n            try:\n                self.sign_file(filepath)\n\n            except ValueError, err:\n                msg = \"Signing file failed. \" + unicode(err)\n                post_command_event(self.main_window, self.StatusBarMsg,\n                                   text=msg)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsave a file that is specified in event. attr and returns the unique ID of the file that was saved.", "response": "def save(self, event):\n        \"\"\"Saves a file that is specified in event.attr\n\n        Parameters\n        ----------\n        event.attr: Dict\n        \\tkey filepath contains file path of file to be saved\n\n        \"\"\"\n\n        filepath = event.attr[\"filepath\"]\n\n        try:\n            filetype = event.attr[\"filetype\"]\n        except KeyError:\n            filetype = \"pys\"\n\n        # If saving is already in progress abort\n        if self.saving:\n            return\n\n        # Use tmpfile to make sure that old save file does not get lost\n        # on abort save\n\n        __, tmpfilepath = tempfile.mkstemp()\n\n        if filetype == \"xls\":\n            self._set_save_states()\n            self._save_xls(tmpfilepath)\n            self._move_tmp_file(tmpfilepath, filepath)\n            self._release_save_states()\n\n        elif filetype == \"pys\" or filetype == \"all\":\n            self._set_save_states()\n            if self._save_pys(tmpfilepath):\n                # Writing was successful\n                self._move_tmp_file(tmpfilepath, filepath)\n                self._save_sign(filepath)\n            self._release_save_states()\n\n        elif filetype == \"pysu\":\n            self._set_save_states()\n            if self._save_pysu(tmpfilepath):\n                # Writing was successful\n                self._move_tmp_file(tmpfilepath, filepath)\n                self._save_sign(filepath)\n            self._release_save_states()\n\n        else:\n            os.remove(tmpfilepath)\n            msg = \"Filetype {filetype} unknown.\".format(filetype=filetype)\n            raise ValueError(msg)\n\n        try:\n            os.remove(tmpfilepath)\n        except OSError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset row height and marks grid as changed", "response": "def set_row_height(self, row, height):\n        \"\"\"Sets row height and marks grid as changed\"\"\"\n\n        # Mark content as changed\n        post_command_event(self.main_window, self.ContentChangedMsg)\n\n        tab = self.grid.current_table\n\n        self.code_array.set_row_height(row, tab, height)\n        self.grid.SetRowSize(row, height)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding no_rows rows before row", "response": "def insert_rows(self, row, no_rows=1):\n        \"\"\"Adds no_rows rows before row, appends if row > maxrows\n\n        and marks grid as changed\n\n        \"\"\"\n\n        # Mark content as changed\n        post_command_event(self.main_window, self.ContentChangedMsg)\n\n        tab = self.grid.current_table\n\n        self.code_array.insert(row, no_rows, axis=0, tab=tab)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes no_rows rows and marks grid as changed", "response": "def delete_rows(self, row, no_rows=1):\n        \"\"\"Deletes no_rows rows and marks grid as changed\"\"\"\n\n        # Mark content as changed\n        post_command_event(self.main_window, self.ContentChangedMsg)\n\n        tab = self.grid.current_table\n\n        try:\n            self.code_array.delete(row, no_rows, axis=0, tab=tab)\n\n        except ValueError, err:\n            post_command_event(self.main_window, self.StatusBarMsg,\n                               text=err.message)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_col_width(self, col, width):\n\n        # Mark content as changed\n        post_command_event(self.main_window, self.ContentChangedMsg)\n\n        tab = self.grid.current_table\n\n        self.code_array.set_col_width(col, tab, width)\n        self.grid.SetColSize(col, width)", "response": "Sets column width and marks grid as changed"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd no_cols columns before col", "response": "def insert_cols(self, col, no_cols=1):\n        \"\"\"Adds no_cols columns before col, appends if col > maxcols\n\n        and marks grid as changed\n\n        \"\"\"\n\n        # Mark content as changed\n        post_command_event(self.main_window, self.ContentChangedMsg)\n\n        tab = self.grid.current_table\n\n        self.code_array.insert(col, no_cols, axis=1, tab=tab)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes no_cols column and marks grid as changed", "response": "def delete_cols(self, col, no_cols=1):\n        \"\"\"Deletes no_cols column and marks grid as changed\"\"\"\n\n        # Mark content as changed\n        post_command_event(self.main_window, self.ContentChangedMsg)\n\n        tab = self.grid.current_table\n\n        try:\n            self.code_array.delete(col, no_cols, axis=1, tab=tab)\n\n        except ValueError, err:\n            post_command_event(self.main_window, self.StatusBarMsg,\n                               text=err.message)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding no_tabs tabs before table appends if tab > maxtabs", "response": "def insert_tabs(self, tab, no_tabs=1):\n        \"\"\"Adds no_tabs tabs before table, appends if tab > maxtabs\n\n        and marks grid as changed\n\n        \"\"\"\n\n        # Mark content as changed\n        post_command_event(self.main_window, self.ContentChangedMsg)\n\n        self.code_array.insert(tab, no_tabs, axis=2)\n\n        # Update TableChoiceIntCtrl\n        shape = self.grid.code_array.shape\n        post_command_event(self.main_window, self.ResizeGridMsg, shape=shape)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete no_tabs tabs and marks grid as changed", "response": "def delete_tabs(self, tab, no_tabs=1):\n        \"\"\"Deletes no_tabs tabs and marks grid as changed\"\"\"\n\n        # Mark content as changed\n        post_command_event(self.main_window, self.ContentChangedMsg)\n\n        try:\n            self.code_array.delete(tab, no_tabs, axis=2)\n\n            # Update TableChoiceIntCtrl\n            shape = self.grid.code_array.shape\n            post_command_event(self.main_window, self.ResizeGridMsg,\n                               shape=shape)\n\n        except ValueError, err:\n            post_command_event(self.main_window, self.StatusBarMsg,\n                               text=err.message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef on_key(self, event):\n\n        # If paste is running and Esc is pressed then we need to abort\n\n        if event.GetKeyCode() == wx.WXK_ESCAPE and \\\n           self.pasting or self.grid.actions.saving:\n            self.need_abort = True\n\n        event.Skip()", "response": "Sets abort if pasting and escape is pressed"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn full key even if table is omitted", "response": "def _get_full_key(self, key):\n        \"\"\"Returns full key even if table is omitted\"\"\"\n\n        length = len(key)\n\n        if length == 3:\n            return key\n\n        elif length == 2:\n            row, col = key\n            tab = self.grid.current_table\n            return row, col, tab\n\n        else:\n            msg = _(\"Key length {length}  not in (2, 3)\").format(length=length)\n            raise ValueError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndisplay overflow message after import in statusbar", "response": "def _show_final_overflow_message(self, row_overflow, col_overflow):\n        \"\"\"Displays overflow message after import in statusbar\"\"\"\n\n        if row_overflow and col_overflow:\n            overflow_cause = _(\"rows and columns\")\n        elif row_overflow:\n            overflow_cause = _(\"rows\")\n        elif col_overflow:\n            overflow_cause = _(\"columns\")\n        else:\n            raise AssertionError(_(\"Import cell overflow missing\"))\n\n        statustext = \\\n            _(\"The imported data did not fit into the grid {cause}. \"\n              \"It has been truncated. Use a larger grid for full import.\").\\\n            format(cause=overflow_cause)\n        post_command_event(self.main_window, self.StatusBarMsg,\n                           text=statustext)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _show_final_paste_message(self, tl_key, no_pasted_cells):\n\n        plural = \"\" if no_pasted_cells == 1 else _(\"s\")\n\n        statustext = _(\"{ncells} cell{plural} pasted at cell {topleft}\").\\\n            format(ncells=no_pasted_cells, plural=plural, topleft=tl_key)\n\n        post_command_event(self.main_window, self.StatusBarMsg,\n                           text=statustext)", "response": "Show actually pasted number of cells"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npastes data into grid from top left cell tl_key", "response": "def paste_to_current_cell(self, tl_key, data, freq=None):\n        \"\"\"Pastes data into grid from top left cell tl_key\n\n        Parameters\n        ----------\n\n        ul_key: Tuple\n        \\key of top left cell of paste area\n        data: iterable of iterables where inner iterable returns string\n        \\tThe outer iterable represents rows\n        freq: Integer, defaults to None\n        \\tStatus message frequency\n\n        \"\"\"\n\n        self.pasting = True\n\n        grid_rows, grid_cols, __ = self.grid.code_array.shape\n\n        self.need_abort = False\n\n        tl_row, tl_col, tl_tab = self._get_full_key(tl_key)\n\n        row_overflow = False\n        col_overflow = False\n\n        no_pasted_cells = 0\n\n        for src_row, row_data in enumerate(data):\n            target_row = tl_row + src_row\n\n            if self.grid.actions._is_aborted(src_row, _(\"Pasting cells... \"),\n                                             freq=freq):\n                self._abort_paste()\n                return False\n\n            # Check if rows fit into grid\n            if target_row >= grid_rows:\n                row_overflow = True\n                break\n\n            for src_col, cell_data in enumerate(row_data):\n                target_col = tl_col + src_col\n\n                if target_col >= grid_cols:\n                    col_overflow = True\n                    break\n\n                if cell_data is not None:\n                    # Is only None if pasting into selection\n                    key = target_row, target_col, tl_tab\n\n                    try:\n                        CellActions.set_code(self, key, cell_data)\n                        no_pasted_cells += 1\n                    except KeyError:\n                        pass\n\n        if row_overflow or col_overflow:\n            self._show_final_overflow_message(row_overflow, col_overflow)\n\n        else:\n            self._show_final_paste_message(tl_key, no_pasted_cells)\n\n        self.pasting = False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef selection_paste_data_gen(self, selection, data, freq=None):\n\n        (bb_top, bb_left), (bb_bottom, bb_right) = \\\n            selection.get_grid_bbox(self.grid.code_array.shape)\n        bbox_height = bb_bottom - bb_top + 1\n        bbox_width = bb_right - bb_left + 1\n\n        for row, row_data in enumerate(itertools.cycle(data)):\n            # Break if row is not in selection bbox\n            if row >= bbox_height:\n                break\n\n            # Duplicate row data if selection is wider than row data\n            row_data = list(row_data)\n            duplicated_row_data = row_data * (bbox_width // len(row_data) + 1)\n            duplicated_row_data = duplicated_row_data[:bbox_width]\n\n            for col in xrange(len(duplicated_row_data)):\n                if (bb_top, bb_left + col) not in selection:\n                    duplicated_row_data[col] = None\n\n            yield duplicated_row_data", "response": "Generator that yields data for selection paste"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npasting data into grid selection", "response": "def paste_to_selection(self, selection, data, freq=None):\n        \"\"\"Pastes data into grid selection\"\"\"\n\n        (bb_top, bb_left), (bb_bottom, bb_right) = \\\n            selection.get_grid_bbox(self.grid.code_array.shape)\n        adjusted_data = self.selection_paste_data_gen(selection, data)\n        self.paste_to_current_cell((bb_top, bb_left), adjusted_data, freq=freq)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npastes data into grid marks grid changed", "response": "def paste(self, tl_key, data, freq=None):\n        \"\"\"Pastes data into grid, marks grid changed\n\n        If no selection is present, data is pasted starting with current cell\n        If a selection is present, data is pasted fully if the selection is\n        smaller. If the selection is larger then data is duplicated.\n\n        Parameters\n        ----------\n\n        ul_key: Tuple\n        \\key of top left cell of paste area\n        data: iterable of iterables where inner iterable returns string\n        \\tThe outer iterable represents rows\n        freq: Integer, defaults to None\n        \\tStatus message frequency\n\n        \"\"\"\n\n        # Get selection bounding box\n\n        selection = self.get_selection()\n\n        # Mark content as changed\n        post_command_event(self.main_window, self.ContentChangedMsg)\n\n        if selection:\n            # There is a selection.  Paste into it\n            self.paste_to_selection(selection, data, freq=freq)\n        else:\n            # There is no selection.  Paste from top left cell.\n            self.paste_to_current_cell(tl_key, data, freq=freq)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreplacing cells in current selection so that they are sorted", "response": "def replace_cells(self, key, sorted_row_idxs):\n        \"\"\"Replaces cells in current selection so that they are sorted\"\"\"\n\n        row, col, tab = key\n\n        new_keys = {}\n        del_keys = []\n\n        selection = self.grid.actions.get_selection()\n\n        for __row, __col, __tab in self.grid.code_array:\n            if __tab == tab and \\\n               (not selection or (__row, __col) in selection):\n                new_row = sorted_row_idxs.index(__row)\n                if __row != new_row:\n                    new_keys[(new_row, __col, __tab)] = \\\n                        self.grid.code_array((__row, __col, __tab))\n                    del_keys.append((__row, __col, __tab))\n\n        for key in del_keys:\n            self.grid.code_array.pop(key)\n\n        for key in new_keys:\n            CellActions.set_code(self, key, new_keys[key])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sort_ascending(self, key):\n\n        row, col, tab = key\n\n        scells = self.grid.code_array[:, col, tab]\n\n        def sorter(i):\n            sorted_ele = scells[i]\n            return sorted_ele is None, sorted_ele\n\n        sorted_row_idxs = sorted(xrange(len(scells)), key=sorter)\n\n        self.replace_cells(key, sorted_row_idxs)\n\n        self.grid.ForceRefresh()", "response": "Sorts selection or grid if none corresponding to column of key"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sort_descending(self, key):\n\n        row, col, tab = key\n\n        scells = self.grid.code_array[:, col, tab]\n        sorted_row_idxs = sorted(xrange(len(scells)), key=scells.__getitem__)\n        sorted_row_idxs.reverse()\n\n        self.replace_cells(key, sorted_row_idxs)\n\n        self.grid.ForceRefresh()", "response": "Sorts inversely selection or grid if none"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef new(self, event):\n\n        # Grid table handles interaction to code_array\n\n        self.grid.actions.clear(event.shape)\n\n        _grid_table = GridTable(self.grid, self.grid.code_array)\n        self.grid.SetTable(_grid_table, True)\n\n        # Update toolbars\n        self.grid.update_entry_line()\n        self.grid.update_attribute_toolbar()", "response": "Creates a new spreadsheet. Expects code_array in event."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _zoom_labels(self, zoom):\n\n        labelfont = self.grid.GetLabelFont()\n        default_fontsize = get_default_font().GetPointSize()\n        labelfont.SetPointSize(max(1, int(round(default_fontsize * zoom))))\n        self.grid.SetLabelFont(labelfont)", "response": "Adjust grid label font to zoom factor"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nzoom to zoom factor", "response": "def zoom(self, zoom=None):\n        \"\"\"Zooms to zoom factor\"\"\"\n\n        status = True\n\n        if zoom is None:\n            zoom = self.grid.grid_renderer.zoom\n            status = False\n\n        # Zoom factor for grid content\n        self.grid.grid_renderer.zoom = zoom\n\n        # Zoom grid labels\n        self._zoom_labels(zoom)\n\n        # Zoom rows and columns\n        self._zoom_rows(zoom)\n        self._zoom_cols(zoom)\n\n        if self.main_window.IsFullScreen():\n            # Do not display labels in fullscreen mode\n            self.main_window.handlers.row_label_size = \\\n                self.grid.GetRowLabelSize()\n            self.main_window.handlers.col_label_size = \\\n                self.grid.GetColLabelSize()\n\n            self.grid.HideRowLabels()\n            self.grid.HideColLabels()\n\n        self.grid.ForceRefresh()\n\n        if status:\n            statustext = _(u\"Zoomed to {0:.2f}.\").format(zoom)\n\n            post_command_event(self.main_window, self.StatusBarMsg,\n                               text=statustext)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef zoom_in(self):\n\n        zoom = self.grid.grid_renderer.zoom\n\n        target_zoom = zoom * (1 + config[\"zoom_factor\"])\n\n        if target_zoom < config[\"maximum_zoom\"]:\n            self.zoom(target_zoom)", "response": "Zooms in by zoom factor"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef zoom_out(self):\n\n        zoom = self.grid.grid_renderer.zoom\n\n        target_zoom = zoom * (1 - config[\"zoom_factor\"])\n\n        if target_zoom > config[\"minimum_zoom\"]:\n            self.zoom(target_zoom)", "response": "Zooms out by zoom factor"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the total height of all grid rows", "response": "def _get_rows_height(self):\n        \"\"\"Returns the total height of all grid rows\"\"\"\n\n        tab = self.grid.current_table\n        no_rows = self.grid.code_array.shape[0]\n        default_row_height = self.grid.code_array.cell_attributes.\\\n            default_cell_attributes[\"row-height\"]\n\n        non_standard_row_heights = []\n        __row_heights = self.grid.code_array.row_heights\n        for __row, __tab in __row_heights:\n            if __tab == tab:\n                non_standard_row_heights.append(__row_heights[(__row, __tab)])\n\n        rows_height = sum(non_standard_row_heights)\n        rows_height += \\\n            (no_rows - len(non_standard_row_heights)) * default_row_height\n\n        return rows_height"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the total width of all grid cols", "response": "def _get_cols_width(self):\n        \"\"\"Returns the total width of all grid cols\"\"\"\n\n        tab = self.grid.current_table\n        no_cols = self.grid.code_array.shape[1]\n        default_col_width = self.grid.code_array.cell_attributes.\\\n            default_cell_attributes[\"column-width\"]\n\n        non_standard_col_widths = []\n        __col_widths = self.grid.code_array.col_widths\n        for __col, __tab in __col_widths:\n            if __tab == tab:\n                non_standard_col_widths.append(__col_widths[(__col, __tab)])\n\n        cols_width = sum(non_standard_col_widths)\n        cols_width += \\\n            (no_cols - len(non_standard_col_widths)) * default_col_width\n\n        return cols_width"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef zoom_fit(self):\n\n        zoom = self.grid.grid_renderer.zoom\n\n        grid_width, grid_height = self.grid.GetSize()\n\n        rows_height = self._get_rows_height() + \\\n            (float(self.grid.GetColLabelSize()) / zoom)\n        cols_width = self._get_cols_width() + \\\n            (float(self.grid.GetRowLabelSize()) / zoom)\n\n        # Check target zoom for rows\n        zoom_height = float(grid_height) / rows_height\n\n        # Check target zoom for columns\n        zoom_width = float(grid_width) / cols_width\n\n        # Use the minimum target zoom from rows and column target zooms\n        target_zoom = min(zoom_height, zoom_width)\n\n        # Zoom only if between min and max\n\n        if config[\"minimum_zoom\"] < target_zoom < config[\"maximum_zoom\"]:\n            self.zoom(target_zoom)", "response": "Zooms the rid to fit the window."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndisplaying the code of the cell key in status bar", "response": "def on_mouse_over(self, key):\n        \"\"\"Displays cell code of cell key in status bar\"\"\"\n\n        def split_lines(string, line_length=80):\n            \"\"\"Returns string that is split into lines of length line_length\"\"\"\n\n            result = u\"\"\n            line = 0\n\n            while len(string) > line_length * line:\n                line_start = line * line_length\n                result += string[line_start:line_start+line_length]\n                result += '\\n'\n                line += 1\n\n            return result[:-1]\n\n        row, col, tab = key\n\n        # If the cell is a button cell or a frozen cell then do nothing\n        cell_attributes = self.grid.code_array.cell_attributes\n        if cell_attributes[key][\"button_cell\"] or \\\n           cell_attributes[key][\"frozen\"]:\n            return\n\n        if (row, col) != self.prev_rowcol and row >= 0 and col >= 0:\n            self.prev_rowcol[:] = [row, col]\n\n            max_result_length = int(config[\"max_result_length\"])\n            table = self.grid.GetTable()\n            hinttext = table.GetSource(row, col, tab)[:max_result_length]\n\n            if hinttext is None:\n                hinttext = ''\n\n            post_command_event(self.main_window, self.StatusBarMsg,\n                               text=hinttext)\n\n            cell_res = self.grid.code_array[row, col, tab]\n\n            if cell_res is None:\n                self.grid.SetToolTip(None)\n                return\n\n            try:\n                cell_res_str = unicode(cell_res)\n            except UnicodeEncodeError:\n                cell_res_str = unicode(cell_res, encoding='utf-8')\n\n            if len(cell_res_str) > max_result_length:\n                cell_res_str = cell_res_str[:max_result_length] + ' [...]'\n\n            self.grid.SetToolTipString(split_lines(cell_res_str))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_visible_area(self):\n\n        grid = self.grid\n\n        top = grid.YToRow(grid.GetViewStart()[1] * grid.ScrollLineX)\n        left = grid.XToCol(grid.GetViewStart()[0] * grid.ScrollLineY)\n\n        # Now start at top left for determining the bottom right visible cell\n\n        bottom, right = top, left\n\n        while grid.IsVisible(bottom, left, wholeCellVisible=False):\n            bottom += 1\n\n        while grid.IsVisible(top, right, wholeCellVisible=False):\n            right += 1\n\n        # The derived lower right cell is *NOT* visible\n\n        bottom -= 1\n        right -= 1\n\n        return (top, left), (bottom, right)", "response": "Returns the area of the visible area of the current cell."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef switch_to_table(self, event):\n\n        newtable = event.newtable\n\n        no_tabs = self.grid.code_array.shape[2] - 1\n\n        if 0 <= newtable <= no_tabs:\n            self.grid.current_table = newtable\n\n            self.grid.SetToolTip(None)\n\n            # Delete renderer cache\n            self.grid.grid_renderer.cell_cache.clear()\n\n            # Delete video cells\n            video_cells = self.grid.grid_renderer.video_cells\n            for key in video_cells:\n                video_panel = video_cells[key]\n                video_panel.player.stop()\n                video_panel.player.release()\n                video_panel.Destroy()\n            video_cells.clear()\n\n            # Hide cell editor\n            cell_editor = self.grid.GetCellEditor(self.grid.GetGridCursorRow(),\n                                                  self.grid.GetGridCursorCol())\n\n            try:\n                cell_editor.Reset()\n            except AttributeError:\n                # No cell editor open\n                pass\n\n            self.grid.HideCellEditControl()\n\n            # Change value of entry_line and table choice\n            post_command_event(self.main_window, self.TableChangedMsg,\n                               table=newtable)\n\n            # Reset row heights and column widths by zooming\n\n            self.zoom()", "response": "Switches grid to a new table"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning current grid cursor cell row col tab", "response": "def get_cursor(self):\n        \"\"\"Returns current grid cursor cell (row, col, tab)\"\"\"\n\n        return self.grid.GetGridCursorRow(), self.grid.GetGridCursorCol(), \\\n            self.grid.current_table"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_cursor(self, value):\n\n        shape = self.grid.code_array.shape\n\n        if len(value) == 3:\n            self.grid._last_selected_cell = row, col, tab = value\n            if row < 0 or col < 0 or tab < 0 or \\\n               row >= shape[0] or col >= shape[1] or tab >= shape[2]:\n                raise ValueError(\"Cell {value} outside of {shape}\".format(\n                                 value=value, shape=shape))\n\n            if tab != self.cursor[2]:\n                post_command_event(self.main_window,\n                                   self.GridActionTableSwitchMsg, newtable=tab)\n                if is_gtk():\n                    try:\n                        wx.Yield()\n                    except:\n                        pass\n        else:\n            row, col = value\n            if row < 0 or col < 0 or row >= shape[0] or col >= shape[1]:\n                raise ValueError(\"Cell {value} outside of {shape}\".format(\n                                 value=value, shape=shape))\n\n            self.grid._last_selected_cell = row, col, self.grid.current_table\n\n        if not (row is None and col is None):\n            if not self.grid.IsVisible(row, col, wholeCellVisible=True):\n                self.grid.MakeCellVisible(row, col)\n            self.grid.SetGridCursor(row, col)", "response": "Changes the grid cursor cell."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the selected cells in grid as Selection object", "response": "def get_selection(self):\n        \"\"\"Returns selected cells in grid as Selection object\"\"\"\n\n        # GetSelectedCells: individual cells selected by ctrl-clicking\n        # GetSelectedRows: rows selected by clicking on the labels\n        # GetSelectedCols: cols selected by clicking on the labels\n        # GetSelectionBlockTopLeft\n        # GetSelectionBlockBottomRight: For blocks selected by dragging\n        # across the grid cells.\n\n        block_top_left = self.grid.GetSelectionBlockTopLeft()\n        block_bottom_right = self.grid.GetSelectionBlockBottomRight()\n        rows = self.grid.GetSelectedRows()\n        cols = self.grid.GetSelectedCols()\n        cells = self.grid.GetSelectedCells()\n\n        return Selection(block_top_left, block_bottom_right, rows, cols, cells)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nselect a single cell in the grid.", "response": "def select_cell(self, row, col, add_to_selected=False):\n        \"\"\"Selects a single cell\"\"\"\n\n        self.grid.SelectBlock(row, col, row, col,\n                              addToSelected=add_to_selected)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nselects a slice of cells in the grid.", "response": "def select_slice(self, row_slc, col_slc, add_to_selected=False):\n        \"\"\"Selects a slice of cells\n\n        Parameters\n        ----------\n         * row_slc: Integer or Slice\n        \\tRows to be selected\n         * col_slc: Integer or Slice\n        \\tColumns to be selected\n         * add_to_selected: Bool, defaults to False\n        \\tOld selections are cleared if False\n\n        \"\"\"\n\n        if not add_to_selected:\n            self.grid.ClearSelection()\n\n        if row_slc == row_slc == slice(None, None, None):\n            # The whole grid is selected\n            self.grid.SelectAll()\n\n        elif row_slc.stop is None and col_slc.stop is None:\n            # A block is selected:\n            self.grid.SelectBlock(row_slc.start, col_slc.start,\n                                  row_slc.stop - 1, col_slc.stop - 1)\n        else:\n            for row in xrange(row_slc.start, row_slc.stop, row_slc.step):\n                for col in xrange(col_slc.start, col_slc.stop, col_slc.step):\n                    self.select_cell(row, col, add_to_selected=True)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete_selection(self, selection=None):\n\n        # Mark content as changed\n        post_command_event(self.main_window, self.ContentChangedMsg)\n\n        if selection is None:\n            selection = self.get_selection()\n\n        current_table = self.grid.current_table\n\n        for row, col, tab in self.grid.code_array.dict_grid.keys():\n            if tab == current_table and (row, col) in selection:\n                self.grid.actions.delete_cell((row, col, tab))\n\n        self.grid.code_array.result_cache.clear()", "response": "Deletes selection marks content as changed\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes a selection if any else deletes the cursor cell at the cursor atom. Refreshes grid after deletion", "response": "def delete(self):\n        \"\"\"Deletes a selection if any else deletes the cursor cell\n\n        Refreshes grid after deletion\n\n        \"\"\"\n\n        if self.grid.IsSelection():\n            # Delete selection\n            self.grid.actions.delete_selection()\n\n        else:\n            # Delete cell at cursor\n            cursor = self.grid.actions.cursor\n            self.grid.actions.delete_cell(cursor)\n\n        # Update grid\n        self.grid.ForceRefresh()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef quote_selection(self):\n\n        selection = self.get_selection()\n        current_table = self.grid.current_table\n        for row, col, tab in self.grid.code_array.dict_grid.keys():\n            if tab == current_table and (row, col) in selection:\n                self.grid.actions.quote_code((row, col, tab))\n\n        self.grid.code_array.result_cache.clear()", "response": "Quotes selected cells marks content as changed"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncopy the selection access_string to the clipboard", "response": "def copy_selection_access_string(self):\n        \"\"\"Copys access_string to selection to the clipboard\n\n        An access string is Python code to reference the selection\n        If there is no selection then a reference to the current cell is copied\n\n        \"\"\"\n\n        selection = self.get_selection()\n        if not selection:\n            cursor = self.grid.actions.cursor\n            selection = Selection([], [], [], [], [tuple(cursor[:2])])\n        shape = self.grid.code_array.shape\n        tab = self.grid.current_table\n\n        access_string = selection.get_access_string(shape, tab)\n\n        # Copy access string to clipboard\n        self.grid.main_window.clipboard.set_clipboard(access_string)\n\n        # Display copy operation and access string in status bar\n        statustext = _(\"Cell reference copied to clipboard: {access_string}\")\n        statustext = statustext.format(access_string=access_string)\n\n        post_command_event(self.main_window, self.StatusBarMsg,\n                           text=statustext)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncopy the format of the selected cells to the Clipboard.", "response": "def copy_format(self):\n        \"\"\"Copies the format of the selected cells to the Clipboard\n\n        Cells are shifted so that the top left bbox corner is at 0,0\n\n        \"\"\"\n\n        row, col, tab = self.grid.actions.cursor\n        code_array = self.grid.code_array\n\n        # Cell attributes\n\n        new_cell_attributes = []\n        selection = self.get_selection()\n        if not selection:\n            # Current cell is chosen for selection\n            selection = Selection([], [], [], [], [(row, col)])\n\n        # Format content is shifted so that the top left corner is 0,0\n        ((top, left), (bottom, right)) = \\\n            selection.get_grid_bbox(self.grid.code_array.shape)\n\n        cell_attributes = code_array.cell_attributes\n        for __selection, table, attrs in cell_attributes:\n            if tab == table:\n                new_selection = selection & __selection\n                if new_selection:\n                    new_shifted_selection = new_selection.shifted(-top, -left)\n                    if \"merge_area\" not in attrs:\n                        selection_params = new_shifted_selection.parameters\n                        cellattribute = selection_params, table, attrs\n                        new_cell_attributes.append(cellattribute)\n\n        # Rows\n\n        shifted_new_row_heights = {}\n        for row, table in code_array.row_heights:\n            if tab == table and top <= row <= bottom:\n                shifted_new_row_heights[row-top, table] = \\\n                    code_array.row_heights[row, table]\n\n        # Columns\n\n        shifted_new_col_widths = {}\n        for col, table in code_array.col_widths:\n            if tab == table and left <= col <= right:\n                shifted_new_col_widths[col-left, table] = \\\n                    code_array.col_widths[col, table]\n\n        format_data = {\n            \"cell_attributes\": new_cell_attributes,\n            \"row_heights\": shifted_new_row_heights,\n            \"col_widths\": shifted_new_col_widths,\n        }\n\n        attr_string = repr(format_data)\n\n        self.grid.main_window.clipboard.set_clipboard(attr_string)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef paste_format(self):\n\n        row, col, tab = self.grid.actions.cursor\n\n        selection = self.get_selection()\n        if selection:\n            # Use selection rather than cursor for top left cell if present\n            row, col = [tl if tl is not None else 0\n                        for tl in selection.get_bbox()[0]]\n\n        cell_attributes = self.grid.code_array.cell_attributes\n\n        string_data = self.grid.main_window.clipboard.get_clipboard()\n        format_data = ast.literal_eval(string_data)\n\n        ca = format_data[\"cell_attributes\"]\n        rh = format_data[\"row_heights\"]\n        cw = format_data[\"col_widths\"]\n\n        assert isinstance(ca, types.ListType)\n        assert isinstance(rh, types.DictType)\n        assert isinstance(cw, types.DictType)\n\n        # Cell attributes\n\n        for selection_params, tab, attrs in ca:\n            base_selection = Selection(*selection_params)\n            shifted_selection = base_selection.shifted(row, col)\n            if \"merge_area\" not in attrs:\n                # Do not paste merge areas because this may have\n                # inintended consequences for existing merge areas\n                new_cell_attribute = shifted_selection, tab, attrs\n                cell_attributes.append(new_cell_attribute)\n\n        # Row heights\n        row_heights = self.grid.code_array.row_heights\n        for __row, __tab in rh:\n            row_heights[__row+row, tab] = rh[__row, __tab]\n\n        # Column widths\n        col_widths = self.grid.code_array.col_widths\n        for __col, __tab in cw:\n            col_widths[__col+col, tab] = cw[(__col, __tab)]", "response": "Pastes cell formats\n\n        Pasting starts at cursor or at top left bbox corner"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns list of all positions of event_find_string in MainGrid.", "response": "def find_all(self, find_string, flags):\n        \"\"\"Return list of all positions of event_find_string in MainGrid.\n\n        Only the code is searched. The result is not searched here.\n\n        Parameters:\n        -----------\n        gridpos: 3-tuple of Integer\n        \\tPosition at which the search starts\n        find_string: String\n        \\tString to find in grid\n        flags: List of strings\n        \\t Search flag out of\n        \\t [\"UP\" xor \"DOWN\", \"WHOLE_WORD\", \"MATCH_CASE\", \"REG_EXP\"]\n\n        \"\"\"\n\n        code_array = self.grid.code_array\n        string_match = code_array.string_match\n\n        find_keys = []\n\n        for key in code_array:\n            if string_match(code_array(key), find_string, flags) is not None:\n                find_keys.append(key)\n\n        return find_keys"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find(self, gridpos, find_string, flags, search_result=True):\n\n        findfunc = self.grid.code_array.findnextmatch\n\n        if \"DOWN\" in flags:\n            if gridpos[0] < self.grid.code_array.shape[0]:\n                gridpos[0] += 1\n            elif gridpos[1] < self.grid.code_array.shape[1]:\n                gridpos[1] += 1\n            elif gridpos[2] < self.grid.code_array.shape[2]:\n                gridpos[2] += 1\n            else:\n                gridpos = (0, 0, 0)\n        elif \"UP\" in flags:\n            if gridpos[0] > 0:\n                gridpos[0] -= 1\n            elif gridpos[1] > 0:\n                gridpos[1] -= 1\n            elif gridpos[2] > 0:\n                gridpos[2] -= 1\n            else:\n                gridpos = [dim - 1 for dim in self.grid.code_array.shape]\n\n        return findfunc(tuple(gridpos), find_string, flags, search_result)", "response": "This method returns the next position of event_find_string in MainGrid."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef replace_all(self, findpositions, find_string, replace_string):\n        # Mark content as changed\n        post_command_event(self.main_window, self.ContentChangedMsg)\n\n        for findpos in findpositions:\n            old_code = self.grid.code_array(findpos)\n            new_code = old_code.replace(find_string, replace_string)\n\n            self.grid.code_array[findpos] = new_code\n\n        statustext = _(\"Replaced {no_cells} cells.\")\n        statustext = statustext.format(no_cells=len(findpositions))\n\n        post_command_event(self.main_window, self.StatusBarMsg,\n                           text=statustext)\n\n        self.grid.ForceRefresh()", "response": "Replaces occurrences of find_string with replace_string at findpos\n        and marks content as changed"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef replace(self, findpos, find_string, replace_string):\n\n        # Mark content as changed\n        post_command_event(self.main_window, self.ContentChangedMsg)\n\n        old_code = self.grid.code_array(findpos)\n        new_code = old_code.replace(find_string, replace_string)\n\n        self.grid.code_array[findpos] = new_code\n        self.grid.actions.cursor = findpos\n\n        statustext = _(\"Replaced {old} with {new} in cell {key}.\")\n        statustext = statustext.format(old=old_code, new=new_code, key=findpos)\n\n        post_command_event(self.main_window, self.StatusBarMsg,\n                           text=statustext)\n\n        self.grid.ForceRefresh()", "response": "Replaces occurrences of find_string with replace_string at findpos in grid and marks content as changed"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _replace_bbox_none(self, bbox):\n\n        (bb_top, bb_left), (bb_bottom, bb_right) = bbox\n\n        if bb_top is None:\n            bb_top = 0\n\n        if bb_left is None:\n            bb_left = 0\n\n        if bb_bottom is None:\n            bb_bottom = self.code_array.shape[0] - 1\n\n        if bb_right is None:\n            bb_right = self.code_array.shape[1] - 1\n\n        return (bb_top, bb_left), (bb_bottom, bb_right)", "response": "Returns bbox in which None is replaced by grid boundaries"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_filetypes2wildcards(filetypes):\n\n    def is_available(filetype):\n        return filetype not in FILETYPE_AVAILABILITY or \\\n               FILETYPE_AVAILABILITY[filetype]\n\n    available_filetypes = filter(is_available, filetypes)\n\n    return OrderedDict((ft, FILETYPE2WILDCARD[ft])\n                       for ft in available_filetypes)", "response": "Returns OrderedDict of filetypes to wildcards"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_key_params_from_user(gpg_key_param_list):\n\n    params = [[_('Real name'), 'name_real']]\n\n    vals = [\"\"] * len(params)\n\n    while \"\" in vals:\n        dlg = GPGParamsDialog(None, -1, \"Enter GPG key parameters\", params)\n        dlg.CenterOnScreen()\n\n        for val, textctrl in zip(vals, dlg.textctrls):\n            textctrl.SetValue(val)\n\n        if dlg.ShowModal() != wx.ID_OK:\n            dlg.Destroy()\n            return\n\n        vals = [textctrl.Value for textctrl in dlg.textctrls]\n\n        dlg.Destroy()\n\n        if \"\" in vals:\n            msg = _(\"Please enter a value in each field.\")\n\n            dlg = GMD.GenericMessageDialog(None, msg, _(\"Missing value\"),\n                                           wx.OK | wx.ICON_ERROR)\n            dlg.ShowModal()\n            dlg.Destroy()\n\n    for (__, key), val in zip(params, vals):\n        gpg_key_param_list.insert(-2, (key, val))\n\n    return dict(gpg_key_param_list)", "response": "Displays parameter entry dialog and returns parameter dict"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_dimensions_from_user(self, no_dim):\n\n        # Grid dimension dialog\n\n        if no_dim != 3:\n            raise NotImplementedError(\n                _(\"Currently, only 3D grids are supported.\"))\n\n        dim_dialog = DimensionsEntryDialog(self.main_window)\n\n        if dim_dialog.ShowModal() != wx.ID_OK:\n            dim_dialog.Destroy()\n            return\n\n        dim = tuple(dim_dialog.dimensions)\n        dim_dialog.Destroy()\n\n        return dim", "response": "Queries grid dimensions in a model dialog and returns n - tuple"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_preferences_from_user(self):\n\n        dlg = PreferencesDialog(self.main_window)\n\n        change_choice = dlg.ShowModal()\n\n        preferences = {}\n\n        if change_choice == wx.ID_OK:\n            for (parameter, _), ctrl in zip(dlg.parameters, dlg.textctrls):\n                if isinstance(ctrl, wx.Choice):\n                    value = ctrl.GetStringSelection()\n                    if value:\n                        preferences[parameter] = repr(value)\n                else:\n                    preferences[parameter] = repr(ctrl.Value)\n\n        dlg.Destroy()\n\n        return preferences", "response": "Launches preferences dialog and returns dict with preferences"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nqueries user if grid should be saved", "response": "def get_save_request_from_user(self):\n        \"\"\"Queries user if grid should be saved\"\"\"\n\n        msg = _(\"There are unsaved changes.\\nDo you want to save?\")\n\n        dlg = GMD.GenericMessageDialog(\n            self.main_window, msg,\n            _(\"Unsaved changes\"), wx.YES_NO | wx.ICON_QUESTION | wx.CANCEL)\n\n        save_choice = dlg.ShowModal()\n\n        dlg.Destroy()\n\n        if save_choice == wx.ID_YES:\n            return True\n\n        elif save_choice == wx.ID_NO:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nopen a file dialog and returns filepath and filterindex", "response": "def get_filepath_findex_from_user(self, wildcard, message, style,\n                                      filterindex=0):\n        \"\"\"Opens a file dialog and returns filepath and filterindex\n\n        Parameters\n        ----------\n        wildcard: String\n        \\tWildcard string for file dialog\n        message: String\n        \\tMessage in the file dialog\n        style: Integer\n        \\tDialog style, e. g. wx.OPEN | wx.CHANGE_DIR\n        filterindex: Integer, defaults to 0\n        \\tDefault filterindex that is selected when the dialog is displayed\n\n        \"\"\"\n\n        dlg = wx.FileDialog(self.main_window, wildcard=wildcard,\n                            message=message, style=style,\n                            defaultDir=os.getcwd(), defaultFile=\"\")\n\n        # Set the initial filterindex\n        dlg.SetFilterIndex(filterindex)\n\n        filepath = None\n        filter_index = None\n\n        if dlg.ShowModal() == wx.ID_OK:\n            filepath = dlg.GetPath()\n            filter_index = dlg.GetFilterIndex()\n\n        dlg.Destroy()\n\n        return filepath, filter_index"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef display_warning(self, message, short_message,\n                        style=wx.OK | wx.ICON_WARNING):\n        \"\"\"Displays a warning message\"\"\"\n\n        dlg = GMD.GenericMessageDialog(self.main_window, message,\n                                       short_message, style)\n        dlg.ShowModal()\n        dlg.Destroy()", "response": "Displays a warning message"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_warning_choice(self, message, short_message,\n                           style=wx.YES_NO | wx.NO_DEFAULT | wx.ICON_WARNING):\n        \"\"\"Launches proceeding dialog and returns True if ok to proceed\"\"\"\n\n        dlg = GMD.GenericMessageDialog(self.main_window, message,\n                                       short_message, style)\n\n        choice = dlg.ShowModal()\n\n        dlg.Destroy()\n\n        return choice == wx.ID_YES", "response": "Launches a dialog and returns True if ok to proceed"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_print_setup(self, print_data):\n\n        psd = wx.PageSetupDialogData(print_data)\n        # psd.EnablePrinter(False)\n        psd.CalculatePaperSizeFromId()\n        dlg = wx.PageSetupDialog(self.main_window, psd)\n        dlg.ShowModal()\n\n        # this makes a copy of the wx.PrintData instead of just saving\n        # a reference to the one inside the PrintDialogData that will\n        # be destroyed when the dialog is destroyed\n        data = dlg.GetPageSetupData()\n        new_print_data = wx.PrintData(data.GetPrintData())\n        new_print_data.PaperId = data.PaperId\n        new_print_data.PaperSize = data.PaperSize\n\n        dlg.Destroy()\n\n        return new_print_data", "response": "Opens print setup dialog and returns print_data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_csv_import_info(self, path):\n\n        csvfilename = os.path.split(path)[1]\n\n        try:\n            filterdlg = CsvImportDialog(self.main_window, csvfilepath=path)\n\n        except csv.Error, err:\n            # Display modal warning dialog\n\n            msg = _(\"'{filepath}' does not seem to be a valid CSV file.\\n \\n\"\n                    \"Opening it yielded the error:\\n{error}\")\n            msg = msg.format(filepath=csvfilename, error=err)\n            short_msg = _('Error reading CSV file')\n\n            self.display_warning(msg, short_msg)\n\n            return\n\n        if filterdlg.ShowModal() == wx.ID_OK:\n            dialect, has_header = filterdlg.csvwidgets.get_dialect()\n            digest_types = filterdlg.grid.dtypes\n            encoding = filterdlg.csvwidgets.encoding\n\n        else:\n            filterdlg.Destroy()\n\n            return\n\n        filterdlg.Destroy()\n\n        return dialect, has_header, digest_types, encoding", "response": "Launches the csv dialog and returns csv_info\n           "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_csv_export_info(self, preview_data):\n\n        preview_rows = 100\n        preview_cols = 100\n\n        export_preview = list(list(islice(col, None, preview_cols))\n                              for col in islice(preview_data, None,\n                                                preview_rows))\n\n        filterdlg = CsvExportDialog(self.main_window, data=export_preview)\n\n        if filterdlg.ShowModal() == wx.ID_OK:\n            dialect, has_header = filterdlg.csvwidgets.get_dialect()\n            digest_types = [types.StringType]\n        else:\n            filterdlg.Destroy()\n            return\n\n        filterdlg.Destroy()\n\n        return dialect, has_header, digest_types", "response": "Shows csv export preview dialog and returns csv_info\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_cairo_export_info(self, filetype):\n\n        export_dlg = CairoExportDialog(self.main_window, filetype=filetype)\n\n        if export_dlg.ShowModal() == wx.ID_OK:\n            info = export_dlg.get_info()\n            export_dlg.Destroy()\n            return info\n\n        else:\n            export_dlg.Destroy()", "response": "Shows Cairo export dialog and returns info"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nopening an integer entry dialog and returns integer value", "response": "def get_int_from_user(self, title=\"Enter integer value\",\n                          cond_func=lambda i: i is not None):\n        \"\"\"Opens an integer entry dialog and returns integer\n\n        Parameters\n        ----------\n        title: String\n        \\tDialog title\n        cond_func: Function\n        \\tIf cond_func of int(<entry_value> then result is returned.\n        \\tOtherwise the dialog pops up again.\n\n        \"\"\"\n\n        is_integer = False\n\n        while not is_integer:\n            dlg = wx.TextEntryDialog(None, title, title)\n\n            if dlg.ShowModal() == wx.ID_OK:\n                result = dlg.GetValue()\n            else:\n                return None\n\n            dlg.Destroy()\n\n            try:\n                integer = int(result)\n\n                if cond_func(integer):\n                    is_integer = True\n\n            except ValueError:\n                pass\n\n        return integer"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_pasteas_parameters_from_user(self, obj):\n\n        dlg = PasteAsDialog(None, -1, obj)\n        dlg_choice = dlg.ShowModal()\n\n        if dlg_choice != wx.ID_OK:\n            dlg.Destroy()\n            return None\n\n        parameters = {}\n        parameters.update(dlg.parameters)\n        dlg.Destroy()\n\n        return parameters", "response": "Opens a PasteAsDialog and returns parameters dict"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef SetSize(self, rect):\n\n        grid = self.main_window.grid\n        key = grid.actions.cursor\n\n        drawn_rect = grid.grid_renderer._get_drawn_rect(grid, key, rect)\n\n        self._tc.SetDimensions(drawn_rect.x, drawn_rect.y,\n                               drawn_rect.width+2, drawn_rect.height+2,\n                               wx.SIZE_ALLOW_MINUS_ONE)\n        self._tc.Layout()", "response": "Called to position the edit control within the cell rectangle."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nshowing or hide the edit control.", "response": "def Show(self, show, attr):\n        \"\"\"\n        Show or hide the edit control.  You can use the attr (if not None)\n        to set colours or fonts for the control.\n\n        \"\"\"\n\n        super(GridCellEditor, self).Show(show, attr)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstart editing the current value of the cell at the specified location.", "response": "def BeginEdit(self, row, col, grid):\n        \"\"\"\n        Fetch the value from the table and prepare the edit control\n        to begin editing.  Set the focus to the edit control.\n        *Must Override*\n\n        \"\"\"\n\n        # Disable if cell is locked, enable if cell is not locked\n        grid = self.main_window.grid\n        key = grid.actions.cursor\n\n        locked = grid.code_array.cell_attributes[key][\"locked\"]or \\\n            grid.code_array.cell_attributes[key][\"button_cell\"]\n        self._tc.Enable(not locked)\n        self._tc.Show(not locked)\n\n        if locked:\n            grid.code_array.result_cache.clear()\n            self._execute_cell_code(row, col, grid)\n\n        # Mirror our changes onto the main_window's code bar\n        self._tc.Bind(wx.EVT_CHAR, self.OnChar)\n        self._tc.Bind(wx.EVT_KEY_UP, self.OnKeyUp)\n\n        # Save cell and grid info\n        self._row = row\n        self._col = [col, ]  # List of columns we are occupying\n        self._grid = grid\n\n        start_value = grid.GetTable().GetValue(*key)\n\n        try:\n            start_value_list = [start_value[i:i+self.max_char_width]\n                                for i in xrange(0, len(start_value),\n                                                self.max_char_width)]\n            startValue = \"\\n\".join(start_value_list)\n            self.startValue = startValue\n\n        except TypeError:\n            self.startValue = u\"\"\n\n        # Set up the textcontrol to look like this cell (TODO: Does not work)\n        try:\n            self._tc.SetValue(unicode(startValue))\n        except (TypeError, AttributeError, UnboundLocalError):\n            self._tc.SetValue(u\"\")\n\n        self._tc.SetFont(grid.GetCellFont(row, col))\n        self._tc.SetBackgroundColour(grid.GetCellBackgroundColour(row, col))\n        self._update_control_length()\n\n        self._tc.SetInsertionPointEnd()\n\n        h_scroll_pos = grid.GetScrollPos(wx.SB_HORIZONTAL)\n        v_scroll_pos = grid.GetScrollPos(wx.SB_VERTICAL)\n\n        self._tc.SetFocus()\n\n        # GTK Bugfix for jumping grid when focusing the textctrl\n        if grid.GetScrollPos(wx.SB_HORIZONTAL) != h_scroll_pos or \\\n           grid.GetScrollPos(wx.SB_VERTICAL) != v_scroll_pos:\n            wx.ScrolledWindow.Scroll(grid, (h_scroll_pos, v_scroll_pos))\n\n        # Select the text\n        self._tc.SetSelection(0, self._tc.GetLastPosition())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nending editing the cell.", "response": "def EndEdit(self, row, col, grid, oldVal=None):\n        \"\"\"\n        End editing the cell.  This function must check if the current\n        value of the editing control is valid and different from the\n        original value (available as oldval in its string form.)  If\n        it has not changed then simply return None, otherwise return\n        the value in its string form.\n        *Must Override*\n\n        \"\"\"\n\n        # Mirror our changes onto the main_window's code bar\n        self._tc.Unbind(wx.EVT_KEY_UP)\n\n        self.ApplyEdit(row, col, grid)\n\n        del self._col\n        del self._row\n        del self._grid"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ApplyEdit(self, row, col, grid):\n\n        val = self._tc.GetValue()\n        grid.GetTable().SetValue(row, col, val)  # update the table\n\n        self.startValue = ''\n        self._tc.SetValue('')", "response": "This function is called by the edit method to update the value of the current control in the specified grid."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nresetting the value in the control back to its starting value.", "response": "def Reset(self):\n        \"\"\"\n        Reset the value in the control back to its starting value.\n        *Must Override*\n        \"\"\"\n\n        try:\n            self._tc.SetValue(self.startValue)\n        except TypeError:\n            # Start value was None\n            pass\n        self._tc.SetInsertionPointEnd()\n        # Update the Entry Line\n        post_command_event(self.main_window, self.TableChangedMsg,\n                           updated_cell=self.startValue)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if the given key is accepted by the base class.", "response": "def IsAcceptedKey(self, evt):\n        \"\"\"\n        Return True to allow the given key to start editing: the base class\n        version only checks that the event has no modifiers.  F2 is special\n        and will always start the editor.\n\n        \"\"\"\n\n        ## We can ask the base class to do it\n        #return super(MyCellEditor, self).IsAcceptedKey(evt)\n\n        # or do it ourselves\n\n        accepted = super(GridCellEditor, self).IsAcceptedKey(evt)\n        accepted = accepted and not evt.ControlDown()\n        accepted = accepted and not evt.AltDown()\n        accepted = accepted and (evt.GetKeyCode() != wx.WXK_SHIFT)\n\n        return accepted"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef StartingKey(self, evt):\n\n        key = evt.GetKeyCode()\n        ch = None\n        if key in [\n                wx.WXK_NUMPAD0, wx.WXK_NUMPAD1, wx.WXK_NUMPAD2, wx.WXK_NUMPAD3,\n                wx.WXK_NUMPAD4, wx.WXK_NUMPAD5, wx.WXK_NUMPAD6, wx.WXK_NUMPAD7,\n                wx.WXK_NUMPAD8, wx.WXK_NUMPAD9]:\n\n            ch = ch = chr(ord('0') + key - wx.WXK_NUMPAD0)\n\n        elif key < 256 and key >= 0 and chr(key) in string.printable:\n            ch = chr(key)\n\n        if ch is not None and self._tc.IsEnabled():\n            # For this example, replace the text.  Normally we would append it.\n            #self._tc.AppendText(ch)\n            self._tc.SetValue(ch)\n            self._tc.SetInsertionPointEnd()\n        else:\n            evt.Skip()", "response": "This method is called when the user presses the Enter key."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef GetPageInfo(self):\n\n        return self.first_tab, self.last_tab, self.first_tab, self.last_tab", "response": "Returns page information\n\n        What is the page range available, and what is the selected page range."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the code if not already quoted and if possible", "response": "def quote(code):\n    \"\"\"Returns quoted code if not already quoted and if possible\n\n    Parameters\n    ----------\n\n    code: String\n    \\tCode thta is quoted\n\n    \"\"\"\n\n    try:\n        code = code.rstrip()\n\n    except AttributeError:\n        # code is not a string, may be None --> There is no code to quote\n        return code\n\n    if code and code[0] + code[-1] not in ('\"\"', \"''\", \"u'\", '\"') \\\n       and '\"' not in code:\n        return 'u\"' + code + '\"'\n    else:\n        return code"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _layout(self):\n\n        self.EnableGridLines(False)\n\n        # Standard row and col sizes for zooming\n        default_cell_attributes = \\\n            self.code_array.cell_attributes.default_cell_attributes\n\n        self.std_row_size = default_cell_attributes[\"row-height\"]\n        self.std_col_size = default_cell_attributes[\"column-width\"]\n\n        self.SetDefaultRowSize(self.std_row_size)\n        self.SetDefaultColSize(self.std_col_size)\n\n        # Standard row and col label sizes for zooming\n        self.col_label_size = self.GetColLabelSize()\n        self.row_label_size = self.GetRowLabelSize()\n\n        self.SetRowMinimalAcceptableHeight(1)\n        self.SetColMinimalAcceptableWidth(1)\n\n        self.SetCellHighlightPenWidth(0)", "response": "Set the layout of the code array to match the layout of the code array."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbinding events to handlers", "response": "def _bind(self):\n        \"\"\"Bind events to handlers\"\"\"\n\n        main_window = self.main_window\n\n        handlers = self.handlers\n        c_handlers = self.cell_handlers\n\n        # Non wx.Grid events\n\n        self.Bind(wx.EVT_MOUSEWHEEL, handlers.OnMouseWheel)\n        self.Bind(wx.EVT_KEY_DOWN, handlers.OnKey)\n\n        # Grid events\n\n        self.GetGridWindow().Bind(wx.EVT_MOTION, handlers.OnMouseMotion)\n        self.Bind(wx.grid.EVT_GRID_RANGE_SELECT, handlers.OnRangeSelected)\n\n        # Context menu\n\n        self.Bind(wx.grid.EVT_GRID_CELL_RIGHT_CLICK, handlers.OnContextMenu)\n\n        # Cell code events\n\n        main_window.Bind(self.EVT_CMD_CODE_ENTRY, c_handlers.OnCellText)\n\n        main_window.Bind(self.EVT_CMD_INSERT_BMP, c_handlers.OnInsertBitmap)\n        main_window.Bind(self.EVT_CMD_LINK_BMP, c_handlers.OnLinkBitmap)\n        main_window.Bind(self.EVT_CMD_VIDEO_CELL, c_handlers.OnLinkVLCVideo)\n        main_window.Bind(self.EVT_CMD_INSERT_CHART,\n                         c_handlers.OnInsertChartDialog)\n\n        # Cell attribute events\n\n        main_window.Bind(self.EVT_CMD_COPY_FORMAT, c_handlers.OnCopyFormat)\n        main_window.Bind(self.EVT_CMD_PASTE_FORMAT, c_handlers.OnPasteFormat)\n\n        main_window.Bind(self.EVT_CMD_FONT, c_handlers.OnCellFont)\n        main_window.Bind(self.EVT_CMD_FONTSIZE, c_handlers.OnCellFontSize)\n        main_window.Bind(self.EVT_CMD_FONTBOLD, c_handlers.OnCellFontBold)\n        main_window.Bind(self.EVT_CMD_FONTITALICS,\n                         c_handlers.OnCellFontItalics)\n        main_window.Bind(self.EVT_CMD_FONTUNDERLINE,\n                         c_handlers.OnCellFontUnderline)\n        main_window.Bind(self.EVT_CMD_FONTSTRIKETHROUGH,\n                         c_handlers.OnCellFontStrikethrough)\n        main_window.Bind(self.EVT_CMD_FROZEN, c_handlers.OnCellFrozen)\n        main_window.Bind(self.EVT_CMD_LOCK, c_handlers.OnCellLocked)\n        main_window.Bind(self.EVT_CMD_BUTTON_CELL, c_handlers.OnButtonCell)\n        main_window.Bind(self.EVT_CMD_MARKUP, c_handlers.OnCellMarkup)\n        main_window.Bind(self.EVT_CMD_MERGE, c_handlers.OnMerge)\n        main_window.Bind(self.EVT_CMD_JUSTIFICATION,\n                         c_handlers.OnCellJustification)\n        main_window.Bind(self.EVT_CMD_ALIGNMENT, c_handlers.OnCellAlignment)\n        main_window.Bind(self.EVT_CMD_BORDERWIDTH,\n                         c_handlers.OnCellBorderWidth)\n        main_window.Bind(self.EVT_CMD_BORDERCOLOR,\n                         c_handlers.OnCellBorderColor)\n        main_window.Bind(self.EVT_CMD_BACKGROUNDCOLOR,\n                         c_handlers.OnCellBackgroundColor)\n        main_window.Bind(self.EVT_CMD_TEXTCOLOR, c_handlers.OnCellTextColor)\n        main_window.Bind(self.EVT_CMD_ROTATION0,\n                         c_handlers.OnTextRotation0)\n        main_window.Bind(self.EVT_CMD_ROTATION90,\n                         c_handlers.OnTextRotation90)\n        main_window.Bind(self.EVT_CMD_ROTATION180,\n                         c_handlers.OnTextRotation180)\n        main_window.Bind(self.EVT_CMD_ROTATION270,\n                         c_handlers.OnTextRotation270)\n        main_window.Bind(self.EVT_CMD_TEXTROTATATION,\n                         c_handlers.OnCellTextRotation)\n\n        # Cell selection events\n\n        self.Bind(wx.grid.EVT_GRID_CMD_SELECT_CELL, c_handlers.OnCellSelected)\n\n        # Grid edit mode events\n\n        main_window.Bind(self.EVT_CMD_ENTER_SELECTION_MODE,\n                         handlers.OnEnterSelectionMode)\n        main_window.Bind(self.EVT_CMD_EXIT_SELECTION_MODE,\n                         handlers.OnExitSelectionMode)\n\n        # Grid view events\n\n        main_window.Bind(self.EVT_CMD_VIEW_FROZEN, handlers.OnViewFrozen)\n        main_window.Bind(self.EVT_CMD_REFRESH_SELECTION,\n                         handlers.OnRefreshSelectedCells)\n        main_window.Bind(self.EVT_CMD_TIMER_TOGGLE,\n                         handlers.OnTimerToggle)\n        self.Bind(wx.EVT_TIMER, handlers.OnTimer)\n        main_window.Bind(self.EVT_CMD_DISPLAY_GOTO_CELL_DIALOG,\n                         handlers.OnDisplayGoToCellDialog)\n        main_window.Bind(self.EVT_CMD_GOTO_CELL, handlers.OnGoToCell)\n        main_window.Bind(self.EVT_CMD_ZOOM_IN, handlers.OnZoomIn)\n        main_window.Bind(self.EVT_CMD_ZOOM_OUT, handlers.OnZoomOut)\n        main_window.Bind(self.EVT_CMD_ZOOM_STANDARD, handlers.OnZoomStandard)\n        main_window.Bind(self.EVT_CMD_ZOOM_FIT, handlers.OnZoomFit)\n\n        # Find events\n        main_window.Bind(self.EVT_CMD_FIND, handlers.OnFind)\n        main_window.Bind(self.EVT_CMD_REPLACE, handlers.OnShowFindReplace)\n        main_window.Bind(wx.EVT_FIND, handlers.OnReplaceFind)\n        main_window.Bind(wx.EVT_FIND_NEXT, handlers.OnReplaceFind)\n        main_window.Bind(wx.EVT_FIND_REPLACE, handlers.OnReplace)\n        main_window.Bind(wx.EVT_FIND_REPLACE_ALL, handlers.OnReplaceAll)\n        main_window.Bind(wx.EVT_FIND_CLOSE, handlers.OnCloseFindReplace)\n\n        # Grid change events\n\n        main_window.Bind(self.EVT_CMD_INSERT_ROWS, handlers.OnInsertRows)\n        main_window.Bind(self.EVT_CMD_INSERT_COLS, handlers.OnInsertCols)\n        main_window.Bind(self.EVT_CMD_INSERT_TABS, handlers.OnInsertTabs)\n\n        main_window.Bind(self.EVT_CMD_DELETE_ROWS, handlers.OnDeleteRows)\n        main_window.Bind(self.EVT_CMD_DELETE_COLS, handlers.OnDeleteCols)\n        main_window.Bind(self.EVT_CMD_DELETE_TABS, handlers.OnDeleteTabs)\n\n        main_window.Bind(self.EVT_CMD_SHOW_RESIZE_GRID_DIALOG,\n                         handlers.OnResizeGridDialog)\n        main_window.Bind(self.EVT_CMD_QUOTE, handlers.OnQuote)\n\n        main_window.Bind(wx.grid.EVT_GRID_ROW_SIZE, handlers.OnRowSize)\n        main_window.Bind(wx.grid.EVT_GRID_COL_SIZE, handlers.OnColSize)\n\n        main_window.Bind(self.EVT_CMD_SORT_ASCENDING, handlers.OnSortAscending)\n        main_window.Bind(self.EVT_CMD_SORT_DESCENDING,\n                         handlers.OnSortDescending)\n\n        # Undo/Redo events\n\n        main_window.Bind(self.EVT_CMD_UNDO, handlers.OnUndo)\n        main_window.Bind(self.EVT_CMD_REDO, handlers.OnRedo)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntrues if the key in merged area shall be drawn", "response": "def is_merged_cell_drawn(self, key):\n        \"\"\"True if key in merged area shall be drawn\n\n        This is the case if it is the top left most visible key of the merge\n        area on the screen.\n\n        \"\"\"\n\n        row, col, tab = key\n\n        # Is key not merged? --> False\n        cell_attributes = self.code_array.cell_attributes\n\n        top, left, __ = cell_attributes.get_merging_cell(key)\n\n        # Case 1: Top left cell of merge is visible\n        # --> Only top left cell returns True\n        top_left_drawn = \\\n            row == top and col == left and \\\n            self.IsVisible(row, col, wholeCellVisible=False)\n\n        # Case 2: Leftmost column is visible\n        # --> Only top visible leftmost cell returns True\n\n        left_drawn = \\\n            col == left and \\\n            self.IsVisible(row, col, wholeCellVisible=False) and \\\n            not self.IsVisible(row-1, col, wholeCellVisible=False)\n\n        # Case 3: Top row is visible\n        # --> Only left visible top cell returns True\n\n        top_drawn = \\\n            row == top and \\\n            self.IsVisible(row, col, wholeCellVisible=False) and \\\n            not self.IsVisible(row, col-1, wholeCellVisible=False)\n\n        # Case 4: Top row and leftmost column are invisible\n        # --> Only top left visible cell returns True\n\n        middle_drawn = \\\n            self.IsVisible(row, col, wholeCellVisible=False) and \\\n            not self.IsVisible(row-1, col, wholeCellVisible=False) and \\\n            not self.IsVisible(row, col-1, wholeCellVisible=False)\n\n        return top_left_drawn or left_drawn or top_drawn or middle_drawn"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_entry_line(self, key=None):\n\n        if key is None:\n            key = self.actions.cursor\n\n        cell_code = self.GetTable().GetValue(*key)\n\n        post_command_event(self, self.EntryLineMsg, text=cell_code)", "response": "Updates the entry line with the cell code corresponding to the given key"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the attribute toolbar", "response": "def update_attribute_toolbar(self, key=None):\n        \"\"\"Updates the attribute toolbar\n\n        Parameters\n        ----------\n        key: 3-tuple of Integer, defaults to current cell\n        \\tCell to which attributes the attributes toolbar is updated\n\n        \"\"\"\n\n        if key is None:\n            key = self.actions.cursor\n\n        post_command_event(self, self.ToolbarUpdateMsg, key=key,\n                           attr=self.code_array.cell_attributes[key])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating the panel cell attrutes of a panel cell", "response": "def _update_video_volume_cell_attributes(self, key):\n        \"\"\"Updates the panel cell attrutes of a panel cell\"\"\"\n\n        try:\n            video_cell_panel = self.grid_renderer.video_cells[key]\n        except KeyError:\n            return\n\n        old_video_volume = self.code_array.cell_attributes[key][\"video_volume\"]\n        new_video_volume = video_cell_panel.volume\n\n        if old_video_volume == new_video_volume:\n            return\n\n        selection = Selection([], [], [], [], [key])\n\n        self.actions.set_attr(\"video_volume\", new_video_volume, selection)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ForceRefresh(self, *args, **kwargs):\n\n        wx.grid.Grid.ForceRefresh(self, *args, **kwargs)\n\n        for video_cell_key in self.grid_renderer.video_cells:\n            if video_cell_key[2] == self.current_table:\n                video_cell = self.grid_renderer.video_cells[video_cell_key]\n                rect = self.CellToRect(video_cell_key[0], video_cell_key[1])\n                drawn_rect = self.grid_renderer._get_drawn_rect(self,\n                                                                video_cell_key,\n                                                                rect)\n                video_cell.SetClientRect(drawn_rect)\n                self._update_video_volume_cell_attributes(video_cell_key)", "response": "Force refresh hook for all video cells in the grid"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninserting bitmap event handler", "response": "def OnInsertBitmap(self, event):\n        \"\"\"Insert bitmap event handler\"\"\"\n\n        key = self.grid.actions.cursor\n        # Get file name\n\n        wildcard = _(\"Bitmap file\") + \" (*)|*\"\n        if rsvg is not None:\n            wildcard += \"|\" + _(\"SVG file\") + \" (*.svg)|*.svg\"\n\n        message = _(\"Select image for current cell\")\n        style = wx.OPEN | wx.CHANGE_DIR\n        filepath, index = \\\n            self.grid.interfaces.get_filepath_findex_from_user(wildcard,\n                                                               message, style)\n        if index == 0:\n            # Bitmap loaded\n            try:\n                img = wx.EmptyImage(1, 1)\n                img.LoadFile(filepath)\n            except TypeError:\n                return\n\n            if img.GetSize() == (-1, -1):\n                # Bitmap could not be read\n                return\n\n            code = self.grid.main_window.actions.img2code(key, img)\n\n        elif index == 1 and rsvg is not None:\n            # SVG loaded\n            with open(filepath) as infile:\n                try:\n                    code = infile.read()\n                except IOError:\n                    return\n                if is_svg(code):\n                    code = 'u\"\"\"' + code + '\"\"\"'\n                else:\n                    # Does not seem to be an svg file\n                    return\n\n        else:\n            code = None\n\n        if code:\n            self.grid.actions.set_code(key, code)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef OnLinkBitmap(self, event):\n\n        # Get file name\n        wildcard = \"*\"\n        message = _(\"Select bitmap for current cell\")\n        style = wx.OPEN | wx.CHANGE_DIR\n        filepath, __ = \\\n            self.grid.interfaces.get_filepath_findex_from_user(wildcard,\n                                                               message, style)\n        try:\n            bmp = wx.Bitmap(filepath)\n        except TypeError:\n            return\n\n        if bmp.Size == (-1, -1):\n            # Bitmap could not be read\n            return\n\n        code = \"wx.Bitmap(r'{filepath}')\".format(filepath=filepath)\n\n        key = self.grid.actions.cursor\n        self.grid.actions.set_code(key, code)", "response": "Link bitmap event handler"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef OnLinkVLCVideo(self, event):\n\n        key = self.grid.actions.cursor\n\n        if event.videofile:\n            try:\n                video_volume = \\\n                    self.grid.code_array.cell_attributes[key][\"video_volume\"]\n            except KeyError:\n                video_volume = None\n\n            self.grid.actions.set_attr(\"panel_cell\", True)\n\n            if video_volume is not None:\n                code = 'vlcpanel_factory(\"{}\", {})'.format(\n                    event.videofile, video_volume)\n            else:\n                code = 'vlcpanel_factory(\"{}\")'.format(event.videofile)\n\n            self.grid.actions.set_code(key, code)\n\n        else:\n            try:\n                video_panel = self.grid.grid_renderer.video_cells.pop(key)\n                video_panel.player.stop()\n                video_panel.player.release()\n                video_panel.Destroy()\n            except KeyError:\n                pass\n\n            self.grid.actions.set_code(key, u\"\")", "response": "Link VLC video event handler"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncharts dialog event handler", "response": "def OnInsertChartDialog(self, event):\n        \"\"\"Chart dialog event handler\"\"\"\n\n        key = self.grid.actions.cursor\n\n        cell_code = self.grid.code_array(key)\n\n        if cell_code is None:\n            cell_code = u\"\"\n\n        chart_dialog = ChartDialog(self.grid.main_window, key, cell_code)\n\n        if chart_dialog.ShowModal() == wx.ID_OK:\n            code = chart_dialog.get_code()\n            key = self.grid.actions.cursor\n            self.grid.actions.set_code(key, code)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npasting format event handler", "response": "def OnPasteFormat(self, event):\n        \"\"\"Paste format event handler\"\"\"\n\n        with undo.group(_(\"Paste format\")):\n            self.grid.actions.paste_format()\n\n        self.grid.ForceRefresh()\n        self.grid.update_attribute_toolbar()\n        self.grid.actions.zoom()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef OnCellFontSize(self, event):\n\n        with undo.group(_(\"Font size\")):\n            self.grid.actions.set_attr(\"pointsize\", event.size)\n\n        self.grid.ForceRefresh()\n\n        self.grid.update_attribute_toolbar()\n\n        event.Skip()", "response": "Cell font size event handler"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef OnCellFontUnderline(self, event):\n\n        with undo.group(_(\"Underline\")):\n            self.grid.actions.toggle_attr(\"underline\")\n\n        self.grid.ForceRefresh()\n\n        self.grid.update_attribute_toolbar()\n\n        event.Skip()", "response": "Cell font underline event handler"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef OnButtonCell(self, event):\n\n        # The button text\n        text = event.text\n\n        with undo.group(_(\"Button\")):\n            self.grid.actions.set_attr(\"button_cell\", text)\n\n        self.grid.ForceRefresh()\n\n        self.grid.update_attribute_toolbar()\n\n        event.Skip()", "response": "Button cell event handler"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmerge cells event handler", "response": "def OnMerge(self, event):\n        \"\"\"Merge cells event handler\"\"\"\n\n        with undo.group(_(\"Merge cells\")):\n            self.grid.actions.merge_selected_cells(self.grid.selection)\n\n        self.grid.ForceRefresh()\n\n        self.grid.update_attribute_toolbar()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef OnCellBackgroundColor(self, event):\n\n        with undo.group(_(\"Background color\")):\n            self.grid.actions.set_attr(\"bgcolor\", event.color)\n\n        self.grid.ForceRefresh()\n\n        self.grid.update_attribute_toolbar()\n\n        event.Skip()", "response": "Cell background color event handler"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef OnCellTextRotation(self, event):\n\n        with undo.group(_(\"Rotation\")):\n            self.grid.actions.toggle_attr(\"angle\")\n\n        self.grid.ForceRefresh()\n\n        self.grid.update_attribute_toolbar()\n\n        if is_gtk():\n            try:\n                wx.Yield()\n            except:\n                pass\n\n        event.Skip()", "response": "Cell text rotation event handler"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef OnMouseMotion(self, event):\n\n        grid = self.grid\n\n        pos_x, pos_y = grid.CalcUnscrolledPosition(event.GetPosition())\n\n        row = grid.YToRow(pos_y)\n        col = grid.XToCol(pos_x)\n        tab = grid.current_table\n\n        key = row, col, tab\n\n        merge_area = self.grid.code_array.cell_attributes[key][\"merge_area\"]\n        if merge_area is not None:\n            top, left, bottom, right = merge_area\n            row, col = top, left\n\n        grid.actions.on_mouse_over((row, col, tab))\n\n        event.Skip()", "response": "Mouse motion event handler"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhandles non - standard key events", "response": "def OnKey(self, event):\n        \"\"\"Handles non-standard shortcut events\"\"\"\n\n        def switch_to_next_table():\n            newtable = self.grid.current_table + 1\n            post_command_event(self.grid, self.GridActionTableSwitchMsg,\n                               newtable=newtable)\n\n        def switch_to_previous_table():\n            newtable = self.grid.current_table - 1\n            post_command_event(self.grid, self.GridActionTableSwitchMsg,\n                               newtable=newtable)\n\n        grid = self.grid\n        actions = grid.actions\n\n        shift, alt, ctrl = 1, 1 << 1, 1 << 2\n\n        # Shortcuts key tuple: (modifier, keycode)\n        # Modifier may be e. g. shift | ctrl\n\n        shortcuts = {\n            # <Esc> pressed\n            (0, 27): lambda: setattr(actions, \"need_abort\", True),\n            # <Del> pressed\n            (0, 127): actions.delete,\n            # <Home> pressed\n            (0, 313): lambda: actions.set_cursor((grid.GetGridCursorRow(), 0)),\n            # <Ctrl> + R pressed\n            (ctrl, 82): actions.copy_selection_access_string,\n            # <Ctrl> + + pressed\n            (ctrl, 388): actions.zoom_in,\n            # <Ctrl> + - pressed\n            (ctrl, 390): actions.zoom_out,\n            # <Shift> + <Space> pressed\n            (shift, 32): lambda: grid.SelectRow(grid.GetGridCursorRow()),\n            # <Ctrl> + <Space> pressed\n            (ctrl, 32): lambda: grid.SelectCol(grid.GetGridCursorCol()),\n            # <Shift> + <Ctrl> + <Space> pressed\n            (shift | ctrl, 32): grid.SelectAll,\n        }\n\n        if self.main_window.IsFullScreen():\n            # <Arrow up> pressed\n            shortcuts[(0, 315)] = switch_to_previous_table\n            # <Arrow down> pressed\n            shortcuts[(0, 317)] = switch_to_next_table\n            # <Space> pressed\n            shortcuts[(0, 32)] = switch_to_next_table\n\n        keycode = event.GetKeyCode()\n\n        modifier = shift * event.ShiftDown() | \\\n            alt * event.AltDown() | ctrl * event.ControlDown()\n\n        if (modifier, keycode) in shortcuts:\n            shortcuts[(modifier, keycode)]()\n\n        else:\n            event.Skip()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nshow cells as frozen status", "response": "def OnViewFrozen(self, event):\n        \"\"\"Show cells as frozen status\"\"\"\n\n        self.grid._view_frozen = not self.grid._view_frozen\n\n        self.grid.grid_renderer.cell_cache.clear()\n        self.grid.ForceRefresh()\n\n        event.Skip()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef OnGoToCell(self, event):\n\n        row, col, tab = event.key\n\n        try:\n            self.grid.actions.cursor = row, col, tab\n\n        except ValueError:\n            msg = _(\"Cell {key} outside grid shape {shape}\").format(\n                key=event.key, shape=self.grid.code_array.shape)\n            post_command_event(self.grid.main_window, self.grid.StatusBarMsg,\n                               text=msg)\n\n            event.Skip()\n            return\n\n        self.grid.MakeCellVisible(row, col)\n\n        event.Skip()", "response": "Shift a given cell into view"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhandling entering selection mode disables cell edits", "response": "def OnEnterSelectionMode(self, event):\n        \"\"\"Event handler for entering selection mode, disables cell edits\"\"\"\n\n        self.grid.sel_mode_cursor = list(self.grid.actions.cursor)\n        self.grid.EnableDragGridSize(False)\n        self.grid.EnableEditing(False)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef OnExitSelectionMode(self, event):\n\n        self.grid.sel_mode_cursor = None\n        self.grid.EnableDragGridSize(True)\n        self.grid.EnableEditing(True)", "response": "event handler for leaving selection mode enables cell edits"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef OnRefreshSelectedCells(self, event):\n\n        self.grid.actions.refresh_selected_frozen_cells()\n        self.grid.ForceRefresh()\n\n        event.Skip()", "response": "Event handler for refreshing the selected cells via menu"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntoggle the timer for updating frozen cells", "response": "def OnTimerToggle(self, event):\n        \"\"\"Toggles the timer for updating frozen cells\"\"\"\n\n        if self.grid.timer_running:\n            # Stop timer\n            self.grid.timer_running = False\n            self.grid.timer.Stop()\n            del self.grid.timer\n\n        else:\n            # Start timer\n            self.grid.timer_running = True\n            self.grid.timer = wx.Timer(self.grid)\n            self.grid.timer.Start(config[\"timer_interval\"])"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates all frozen cells because of timer call", "response": "def OnTimer(self, event):\n        \"\"\"Update all frozen cells because of timer call\"\"\"\n\n        self.timer_updating = True\n\n        shape = self.grid.code_array.shape[:2]\n        selection = Selection([(0, 0)], [(shape)], [], [], [])\n        self.grid.actions.refresh_selected_frozen_cells(selection)\n        self.grid.ForceRefresh()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef OnZoomStandard(self, event):\n\n        self.grid.actions.zoom(zoom=1.0)\n\n        event.Skip()", "response": "event handler for resetting grid zoom"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef OnMouseWheel(self, event):\n\n        if event.ControlDown():\n            if event.WheelRotation > 0:\n                post_command_event(self.grid, self.grid.ZoomInMsg)\n            else:\n                post_command_event(self.grid, self.grid.ZoomOutMsg)\n\n        elif self.main_window.IsFullScreen():\n            if event.WheelRotation > 0:\n                newtable = self.grid.current_table - 1\n            else:\n                newtable = self.grid.current_table + 1\n\n            post_command_event(self.grid, self.GridActionTableSwitchMsg,\n                               newtable=newtable)\n            return\n\n        else:\n            wheel_speed = config[\"mouse_wheel_speed_factor\"]\n            x, y = self.grid.GetViewStart()\n            direction = wheel_speed if event.GetWheelRotation() < 0 \\\n                else -wheel_speed\n            if event.ShiftDown():\n                # Scroll sideways if shift is pressed.\n                self.grid.Scroll(x + direction, y)\n            else:\n                self.grid.Scroll(x, y + direction)", "response": "Mouse wheel event handler for grid actions\n            Invokes zoom when Ctrl is also pressed \\"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind functionality called from toolbar returns find position", "response": "def OnFind(self, event):\n        \"\"\"Find functionality, called from toolbar, returns find position\"\"\"\n\n        # Search starts in next cell after the current one\n        gridpos = list(self.grid.actions.cursor)\n        text, flags = event.text, event.flags\n        findpos = self.grid.actions.find(gridpos, text, flags)\n\n        if findpos is None:\n            # If nothing is found mention it in the statusbar and return\n\n            statustext = _(\"'{text}' not found.\").format(text=text)\n\n        else:\n            # Otherwise select cell with next occurrence if successful\n            self.grid.actions.cursor = findpos\n\n            # Update statusbar\n            statustext = _(u\"Found '{text}' in cell {key}.\")\n            statustext = statustext.format(text=text, key=findpos)\n\n        post_command_event(self.grid.main_window, self.grid.StatusBarMsg,\n                           text=statustext)\n\n        event.Skip()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef OnShowFindReplace(self, event):\n\n        data = wx.FindReplaceData(wx.FR_DOWN)\n        dlg = wx.FindReplaceDialog(self.grid, data, \"Find & Replace\",\n                                   wx.FR_REPLACEDIALOG)\n        dlg.data = data  # save a reference to data\n        dlg.Show(True)", "response": "Calls the find - replace dialog"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef OnReplaceFind(self, event):\n\n        event.text = event.GetFindString()\n        event.flags = self._wxflag2flag(event.GetFlags())\n\n        self.OnFind(event)", "response": "Called when a find operation is started from F&R dialog"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef OnReplace(self, event):\n\n        find_string = event.GetFindString()\n        flags = self._wxflag2flag(event.GetFlags())\n        replace_string = event.GetReplaceString()\n\n        gridpos = list(self.grid.actions.cursor)\n\n        findpos = self.grid.actions.find(gridpos, find_string, flags,\n                                         search_result=False)\n\n        if findpos is None:\n            statustext = _(u\"'{find_string}' not found.\")\n            statustext = statustext.format(find_string=find_string)\n\n        else:\n            with undo.group(_(\"Replace\")):\n                self.grid.actions.replace(findpos, find_string, replace_string)\n            self.grid.actions.cursor = findpos\n\n            # Update statusbar\n            statustext = _(u\"Replaced '{find_string}' in cell {key} with \"\n                           u\"{replace_string}.\")\n            statustext = statustext.format(find_string=find_string,\n                                           key=findpos,\n                                           replace_string=replace_string)\n\n        post_command_event(self.grid.main_window, self.grid.StatusBarMsg,\n                           text=statustext)\n\n        event.Skip()", "response": "Called when a replace operation is started returns the find position"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef OnReplaceAll(self, event):\n\n        find_string = event.GetFindString()\n        flags = self._wxflag2flag(event.GetFlags())\n        replace_string = event.GetReplaceString()\n\n        findpositions = self.grid.actions.find_all(find_string, flags)\n\n        with undo.group(_(\"Replace all\")):\n            self.grid.actions.replace_all(findpositions, find_string,\n                                          replace_string)\n\n        event.Skip()", "response": "Called when a replace all operation is started"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn tuple of number of rows and cols from bbox", "response": "def _get_no_rowscols(self, bbox):\n        \"\"\"Returns tuple of number of rows and cols from bbox\"\"\"\n\n        if bbox is None:\n            return 1, 1\n        else:\n            (bb_top, bb_left), (bb_bottom, bb_right) = bbox\n            if bb_top is None:\n                bb_top = 0\n            if bb_left is None:\n                bb_left = 0\n            if bb_bottom is None:\n                bb_bottom = self.grid.code_array.shape[0] - 1\n            if bb_right is None:\n                bb_right = self.grid.code_array.shape[1] - 1\n\n            return bb_bottom - bb_top + 1, bb_right - bb_left + 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef OnInsertRows(self, event):\n\n        bbox = self.grid.selection.get_bbox()\n\n        if bbox is None or bbox[1][0] is None:\n            # Insert rows at cursor\n            ins_point = self.grid.actions.cursor[0] - 1\n            no_rows = 1\n        else:\n            # Insert at lower edge of bounding box\n            ins_point = bbox[0][0] - 1\n            no_rows = self._get_no_rowscols(bbox)[0]\n\n        with undo.group(_(\"Insert rows\")):\n            self.grid.actions.insert_rows(ins_point, no_rows)\n\n        self.grid.GetTable().ResetView()\n\n        # Update the default sized cell sizes\n        self.grid.actions.zoom()\n\n        event.Skip()", "response": "Insert the maximum of 1 and the number of selected rows"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef OnInsertCols(self, event):\n\n        bbox = self.grid.selection.get_bbox()\n\n        if bbox is None or bbox[1][1] is None:\n            # Insert rows at cursor\n            ins_point = self.grid.actions.cursor[1] - 1\n            no_cols = 1\n        else:\n            # Insert at right edge of bounding box\n            ins_point = bbox[0][1] - 1\n            no_cols = self._get_no_rowscols(bbox)[1]\n\n        with undo.group(_(\"Insert columns\")):\n            self.grid.actions.insert_cols(ins_point, no_cols)\n\n        self.grid.GetTable().ResetView()\n\n        # Update the default sized cell sizes\n        self.grid.actions.zoom()\n\n        event.Skip()", "response": "Inserts the maximum of 1 and the number of selected columns"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef OnInsertTabs(self, event):\n\n        with undo.group(_(\"Insert table\")):\n            self.grid.actions.insert_tabs(self.grid.current_table - 1, 1)\n\n        self.grid.GetTable().ResetView()\n        self.grid.actions.zoom()\n\n        event.Skip()", "response": "Insert one table into grid"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting rows from all tables of the grid", "response": "def OnDeleteRows(self, event):\n        \"\"\"Deletes rows from all tables of the grid\"\"\"\n\n        bbox = self.grid.selection.get_bbox()\n\n        if bbox is None or bbox[1][0] is None:\n            # Insert rows at cursor\n            del_point = self.grid.actions.cursor[0]\n            no_rows = 1\n        else:\n            # Insert at lower edge of bounding box\n            del_point = bbox[0][0]\n            no_rows = self._get_no_rowscols(bbox)[0]\n\n        with undo.group(_(\"Delete rows\")):\n            self.grid.actions.delete_rows(del_point, no_rows)\n\n        self.grid.GetTable().ResetView()\n\n        # Update the default sized cell sizes\n        self.grid.actions.zoom()\n\n        event.Skip()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting columns from all tables of the grid", "response": "def OnDeleteCols(self, event):\n        \"\"\"Deletes columns from all tables of the grid\"\"\"\n\n        bbox = self.grid.selection.get_bbox()\n\n        if bbox is None or bbox[1][1] is None:\n            # Insert rows at cursor\n            del_point = self.grid.actions.cursor[1]\n            no_cols = 1\n        else:\n            # Insert at right edge of bounding box\n            del_point = bbox[0][1]\n            no_cols = self._get_no_rowscols(bbox)[1]\n\n        with undo.group(_(\"Delete columns\")):\n            self.grid.actions.delete_cols(del_point, no_cols)\n\n        self.grid.GetTable().ResetView()\n\n        # Update the default sized cell sizes\n        self.grid.actions.zoom()\n\n        event.Skip()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndeleting tabs event handler", "response": "def OnDeleteTabs(self, event):\n        \"\"\"Deletes tables\"\"\"\n\n        with undo.group(_(\"Delete table\")):\n            self.grid.actions.delete_tabs(self.grid.current_table, 1)\n\n        self.grid.GetTable().ResetView()\n        self.grid.actions.zoom()\n\n        event.Skip()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nquote selection or none the current cell", "response": "def OnQuote(self, event):\n        \"\"\"Quotes selection or if none the current cell\"\"\"\n\n        grid = self.grid\n        grid.DisableCellEditControl()\n\n        with undo.group(_(\"Quote cell(s)\")):\n            # Is a selection present?\n            if self.grid.IsSelection():\n                # Enclose all selected cells\n                self.grid.actions.quote_selection()\n\n                # Update grid\n                self.grid.ForceRefresh()\n\n            else:\n                row = self.grid.GetGridCursorRow()\n                col = self.grid.GetGridCursorCol()\n                key = row, col, grid.current_table\n\n                self.grid.actions.quote_code(key)\n\n                grid.MoveCursorDown(False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef OnRowSize(self, event):\n\n        row = event.GetRowOrCol()\n        tab = self.grid.current_table\n        rowsize = self.grid.GetRowSize(row) / self.grid.grid_renderer.zoom\n\n        # Detect for resizing group of rows\n        rows = self.grid.GetSelectedRows()\n        if len(rows) == 0:\n            rows = [row, ]\n\n        # Detect for selection of rows spanning all columns\n        selection = self.grid.selection\n        num_cols = self.grid.code_array.shape[1]-1\n        for box in zip(selection.block_tl, selection.block_br):\n            leftmost_col = box[0][1]\n            rightmost_col = box[1][1]\n            if leftmost_col == 0 and rightmost_col == num_cols:\n                rows += range(box[0][0], box[1][0]+1)\n\n        # All row resizing is undone in one click\n        with undo.group(_(\"Resize Rows\")):\n            for row in rows:\n                self.grid.code_array.set_row_height(row, tab, rowsize)\n                zoomed_rowsize = rowsize * self.grid.grid_renderer.zoom\n                self.grid.SetRowSize(row, zoomed_rowsize)\n\n        # Mark content as changed\n        post_command_event(self.grid.main_window, self.grid.ContentChangedMsg)\n\n        event.Skip()\n        self.grid.ForceRefresh()", "response": "Row size event handler"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef OnColSize(self, event):\n\n        col = event.GetRowOrCol()\n        tab = self.grid.current_table\n        colsize = self.grid.GetColSize(col) / self.grid.grid_renderer.zoom\n\n        # Detect for resizing group of cols\n        cols = self.grid.GetSelectedCols()\n        if len(cols) == 0:\n            cols = [col, ]\n\n        # Detect for selection of rows spanning all columns\n        selection = self.grid.selection\n        num_rows = self.grid.code_array.shape[0]-1\n        for box in zip(selection.block_tl, selection.block_br):\n            top_row = box[0][0]\n            bottom_row = box[1][0]\n            if top_row == 0 and bottom_row == num_rows:\n                cols += range(box[0][1], box[1][1]+1)\n\n        # All column resizing is undone in one click\n        with undo.group(_(\"Resize Columns\")):\n            for col in cols:\n                self.grid.code_array.set_col_width(col, tab, colsize)\n                zoomed_colsize = colsize * self.grid.grid_renderer.zoom\n                self.grid.SetColSize(col, zoomed_colsize)\n\n        # Mark content as changed\n        post_command_event(self.grid.main_window, self.grid.ContentChangedMsg)\n\n        event.Skip()\n        self.grid.ForceRefresh()", "response": "Col size event handler"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef OnSortAscending(self, event):\n\n        try:\n            with undo.group(_(\"Sort ascending\")):\n                self.grid.actions.sort_ascending(self.grid.actions.cursor)\n            statustext = _(u\"Sorting complete.\")\n\n        except Exception, err:\n            statustext = _(u\"Sorting failed: {}\").format(err)\n\n        post_command_event(self.grid.main_window, self.grid.StatusBarMsg,\n                           text=statustext)", "response": "Sort ascending event handler"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncall the grid undo method", "response": "def OnUndo(self, event):\n        \"\"\"Calls the grid undo method\"\"\"\n\n        statustext = undo.stack().undotext()\n        undo.stack().undo()\n\n        # Update content changed state\n        try:\n            post_command_event(self.grid.main_window,\n                               self.grid.ContentChangedMsg)\n        except TypeError:\n            # The main window does not exist any more\n            pass\n\n        self.grid.code_array.result_cache.clear()\n\n        post_command_event(self.grid.main_window, self.grid.TableChangedMsg,\n                           updated_cell=True)\n\n        # Reset row heights and column widths by zooming\n        self.grid.actions.zoom()\n\n        # Change grid table dimensions\n        self.grid.GetTable().ResetView()\n\n        # Update TableChoiceIntCtrl\n        shape = self.grid.code_array.shape\n        post_command_event(self.main_window, self.grid.ResizeGridMsg,\n                           shape=shape)\n\n        # Update toolbars\n        self.grid.update_entry_line()\n        self.grid.update_attribute_toolbar()\n\n        post_command_event(self.grid.main_window, self.grid.StatusBarMsg,\n                           text=statustext)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rowcol_from_template(target_tab, template_tab=0):\n\n\tfor row, tab in S.row_heights.keys():\n\t\t# Delete all row heights in target table\n\t\tif tab == target_tab:\n\t\t\tS.row_heights.pop((row, tab))\n\n\t\tif tab == template_tab:\n\t\t\tS.row_heights[(row, target_tab)] = \\\n\t\t\t\tS.row_heights[(row, tab)]\n\n\tfor col, tab in S.col_widths.keys():\n\t\t# Delete all column widths in target table\n\t\tif tab == target_tab:\n\t\t\tS.col_widths.pop((col, tab))\n\n\t\tif tab == template_tab:\n\t\t\tS.col_widths[(col, target_tab)] = \\\n\t\t\t\t\tS.col_widths[(col, tab)]\n\n\treturn \"Table {tab} adjusted.\".format(tab=target_tab)", "response": "Adjusts row heights and column widths to match the template_tab"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadjusting cell paarmeters to match the template_tab", "response": "def cell_attributes_from_template(target_tab, template_tab=0):\n\t\"\"\"Adjusts cell paarmeters to match the template\n\n\tParameters\n\t----------\n\ttarget_tab: Integer\n\t\\tTable to be adjusted\n\ttemplate_tab: Integer, defaults to 0\n\t\\tTemplate table\n\n\t\"\"\"\n\n\tnew_cell_attributes = []\n\tfor attr in S.cell_attributes:\n\t\tif attr[1] == template_tab:\n\t\t\tnew_attr = (attr[0], target_tab, attr[2])\n\t\t\tnew_cell_attributes.append(new_attr)\n\tS.cell_attributes.extend(new_cell_attributes)\n\n\treturn \"Table {tab} adjusted.\".format(tab=target_tab)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns wx. Font from fontdata string", "response": "def get_font_from_data(fontdata):\n    \"\"\"Returns wx.Font from fontdata string\"\"\"\n\n    textfont = get_default_font()\n\n    if fontdata != \"\":\n        nativefontinfo = wx.NativeFontInfo()\n        nativefontinfo.FromString(fontdata)\n\n        # OS X does not like a PointSize of 0\n        # Therefore, it is explicitly set to the system default font point size\n\n        if not nativefontinfo.GetPointSize():\n            nativefontinfo.SetPointSize(get_default_font().GetPointSize())\n\n        textfont.SetNativeFontInfo(nativefontinfo)\n\n    return textfont"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_pen_from_data(pendata):\n\n    pen_color = wx.Colour()\n    pen_color.SetRGB(pendata[0])\n    pen = wx.Pen(pen_color, *pendata[1:])\n    pen.SetJoin(wx.JOIN_MITER)\n\n    return pen", "response": "Returns wx. Pen from pendata attribute list"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef code2color(color_string):\n\n    color_tuple = ast.literal_eval(color_string)\n    color_tuple_int = map(lambda x: int(x * 255.0), color_tuple)\n\n    return wx.Colour(*color_tuple_int)", "response": "Returns wx. Colour from a string of a 3 - tuple of floats in [ 0 1 )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef color_pack2rgb(packed):\n\n    r = packed & 255\n    g = (packed & (255 << 8)) >> 8\n    b = (packed & (255 << 16)) >> 16\n\n    return r, g, b", "response": "Returns r g b tuple from packed wx. ColourGetRGB value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a string from code that contains a repr of the string", "response": "def unquote_string(code):\n    \"\"\"Returns a string from code that contains a repr of the string\"\"\"\n\n    scode = code.strip()\n    assert scode[-1] in [\"'\", '\"']\n    assert scode[0] in [\"'\", '\"'] or scode[1] in [\"'\", '\"']\n\n    return ast.literal_eval(scode)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_dict_strings(code):\n\n    i = 0\n    level = 0\n    chunk_start = 0\n    curr_paren = None\n\n    for i, char in enumerate(code):\n        if char in [\"(\", \"[\", \"{\"] and curr_paren is None:\n            level += 1\n        elif char in [\")\", \"]\", \"}\"] and curr_paren is None:\n            level -= 1\n        elif char in ['\"', \"'\"]:\n            if curr_paren == char:\n                curr_paren = None\n            elif curr_paren is None:\n                curr_paren = char\n\n        if level == 0 and char in [':', ','] and curr_paren is None:\n            yield code[chunk_start: i].strip()\n            chunk_start = i + 1\n\n    yield code[chunk_start:i + 1].strip()", "response": "Generator of elements of a dict that is given in the code string"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn start sub - string that is common for all given strings", "response": "def common_start(strings):\n    \"\"\"Returns start sub-string that is common for all given strings\n\n    Parameters\n    ----------\n    strings: List of strings\n    \\tThese strings are evaluated for their largest common start string\n\n    \"\"\"\n\n    def gen_start_strings(string):\n        \"\"\"Generator that yield start sub-strings of length 1, 2, ...\"\"\"\n\n        for i in xrange(1, len(string) + 1):\n            yield string[:i]\n\n    # Empty strings list\n    if not strings:\n        return \"\"\n\n    start_string = \"\"\n\n    # Get sucessively start string of 1st string\n    for start_string in gen_start_strings(max(strings)):\n        if not all(string.startswith(start_string) for string in strings):\n            return start_string[:-1]\n\n    return start_string"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_svg(code):\n\n    if rsvg is None:\n        return\n\n    try:\n        rsvg.Handle(data=code)\n\n    except glib.GError:\n        return False\n\n    # The SVG file has to refer to its xmlns\n    # Hopefully, it does so wiyhin the first 1000 characters\n\n    if \"http://www.w3.org/2000/svg\" in code[:1000]:\n        return True\n\n    return False", "response": "Checks if code is an SVG image."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npages layout choice event handler", "response": "def on_page_layout_choice(self, event):\n        \"\"\"Page layout choice event handler\"\"\"\n\n        width, height = self.paper_sizes_points[event.GetString()]\n        self.page_width_text_ctrl.SetValue(str(width / 72.0))\n        self.page_height_text_ctrl.SetValue(str(height / 72.0))\n\n        event.Skip()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_info(self):\n\n        info = {}\n\n        info[\"top_row\"] = self.top_row_text_ctrl.GetValue()\n        info[\"bottom_row\"] = self.bottom_row_text_ctrl.GetValue()\n        info[\"left_col\"] = self.left_col_text_ctrl.GetValue()\n        info[\"right_col\"] = self.right_col_text_ctrl.GetValue()\n        info[\"first_tab\"] = self.first_tab_text_ctrl.GetValue()\n        info[\"last_tab\"] = self.last_tab_text_ctrl.GetValue()\n\n        if self.filetype != \"print\":\n            # If printing and not exporting then page info is\n            # gathered from printer dialog\n\n            info[\"paper_width\"] = float(\n                self.page_width_text_ctrl.GetValue()) * 72.0\n            info[\"paper_height\"] = float(\n                self.page_height_text_ctrl.GetValue()) * 72.0\n\n            if self.portrait_landscape_radio_box.GetSelection() == 0:\n                orientation = \"portrait\"\n            elif self.portrait_landscape_radio_box.GetSelection() == 1:\n                orientation = \"landscape\"\n            else:\n                raise ValueError(\"Orientation not in portrait or landscape\")\n\n            info[\"orientation\"] = orientation\n\n        return info", "response": "Returns a dict with the dialog PDF info."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the path in which pyspread is installed", "response": "def get_program_path():\n    \"\"\"Returns the path in which pyspread is installed\"\"\"\n\n    src_folder = os.path.dirname(__file__)\n    program_path = os.sep.join(src_folder.split(os.sep)[:-1]) + os.sep\n\n    return program_path"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_dpi():\n\n    def pxmm_2_dpi((pixels, length_mm)):\n        return pixels * 25.6 / length_mm\n\n    return map(pxmm_2_dpi, zip(wx.GetDisplaySize(), wx.GetDisplaySizeMM()))", "response": "Returns screen dpi resolution"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_font_list():\n\n    font_map = pangocairo.cairo_font_map_get_default()\n    font_list = [f.get_name() for f in font_map.list_families()]\n    font_list.sort()\n\n    return font_list", "response": "Returns a sorted list of all system font names"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of dicts which indicate installed dependencies", "response": "def get_dependencies():\n    \"\"\"Returns list of dicts which indicate installed dependencies\"\"\"\n\n    dependencies = []\n\n    # Numpy\n    dep_attrs = {\n        \"name\": \"numpy\",\n        \"min_version\": \"1.1.0\",\n        \"description\": \"required\",\n    }\n    try:\n        import numpy\n        dep_attrs[\"version\"] = numpy.version.version\n    except ImportError:\n        dep_attrs[\"version\"] = None\n    dependencies.append(dep_attrs)\n\n    # wxPython\n    dep_attrs = {\n        \"name\": \"wxPython\",\n        \"min_version\": \"2.8.10.1\",\n        \"description\": \"required\",\n    }\n    try:\n        import wx\n        dep_attrs[\"version\"] = wx.version()\n    except ImportError:\n        dep_attrs[\"version\"] = None\n    dependencies.append(dep_attrs)\n\n    # Matplotlib\n    dep_attrs = {\n        \"name\": \"matplotlib\",\n        \"min_version\": \"1.1.1\",\n        \"description\": \"required\",\n    }\n    try:\n        import matplotlib\n        dep_attrs[\"version\"] = matplotlib._version.get_versions()[\"version\"]\n    except ImportError:\n        dep_attrs[\"version\"] = None\n    except AttributeError:\n        # May happen in old matplotlib versions\n        dep_attrs[\"version\"] = matplotlib.__version__\n\n    dependencies.append(dep_attrs)\n\n    # Pycairo\n    dep_attrs = {\n        \"name\": \"pycairo\",\n        \"min_version\": \"1.8.8\",\n        \"description\": \"required\",\n    }\n    try:\n        import cairo\n        dep_attrs[\"version\"] = cairo.version\n    except ImportError:\n        dep_attrs[\"version\"] = None\n    dependencies.append(dep_attrs)\n\n    # Python GnuPG\n    dep_attrs = {\n        \"name\": \"python-gnupg\",\n        \"min_version\": \"0.3.0\",\n        \"description\": \"for opening own files without approval\",\n    }\n    try:\n        import gnupg\n        dep_attrs[\"version\"] = gnupg.__version__\n    except ImportError:\n        dep_attrs[\"version\"] = None\n    dependencies.append(dep_attrs)\n\n    # xlrd\n    dep_attrs = {\n        \"name\": \"xlrd\",\n        \"min_version\": \"0.9.2\",\n        \"description\": \"for loading Excel files\",\n    }\n    try:\n        import xlrd\n        dep_attrs[\"version\"] = xlrd.__VERSION__\n    except ImportError:\n        dep_attrs[\"version\"] = None\n    dependencies.append(dep_attrs)\n\n    # xlwt\n    dep_attrs = {\n        \"name\": \"xlwt\",\n        \"min_version\": \"0.7.2\",\n        \"description\": \"for saving Excel files\",\n    }\n    try:\n        import xlwt\n        dep_attrs[\"version\"] = xlwt.__VERSION__\n    except ImportError:\n        dep_attrs[\"version\"] = None\n    dependencies.append(dep_attrs)\n\n    # Jedi\n    dep_attrs = {\n        \"name\": \"jedi\",\n        \"min_version\": \"0.8.0\",\n        \"description\": \"for tab completion and context help in the entry line\",\n    }\n    try:\n        import jedi\n        dep_attrs[\"version\"] = jedi.__version__\n    except ImportError:\n        dep_attrs[\"version\"] = None\n    dependencies.append(dep_attrs)\n\n    # pyrsvg\n    dep_attrs = {\n        \"name\": \"pyrsvg\",\n        \"min_version\": \"2.32\",\n        \"description\": \"for displaying SVG files in cells\",\n    }\n    try:\n        import rsvg\n        dep_attrs[\"version\"] = True\n    except ImportError:\n        dep_attrs[\"version\"] = None\n    dependencies.append(dep_attrs)\n\n    # pyenchant\n    dep_attrs = {\n        \"name\": \"pyenchant\",\n        \"min_version\": \"1.6.6\",\n        \"description\": \"for spell checking\",\n    }\n    try:\n        import enchant\n        dep_attrs[\"version\"] = enchant.__version__\n    except ImportError:\n        dep_attrs[\"version\"] = None\n    dependencies.append(dep_attrs)\n\n    return dependencies"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_cell_rect(self, row, col, tab):\n\n        top_row = self.row_tb[0]\n        left_col = self.col_rl[0]\n\n        pos_x = self.x_offset\n        pos_y = self.y_offset\n\n        merge_area = self._get_merge_area((row, col, tab))\n\n        for __row in xrange(top_row, row):\n            __row_height = self.code_array.get_row_height(__row, tab)\n            pos_y += __row_height\n\n        for __col in xrange(left_col, col):\n            __col_width = self.code_array.get_col_width(__col, tab)\n            pos_x += __col_width\n\n        if merge_area is None:\n            height = self.code_array.get_row_height(row, tab)\n            width = self.code_array.get_col_width(col, tab)\n        else:\n            # We have a merged cell\n            top, left, bottom, right = merge_area\n            # Are we drawing the top left cell?\n            if top == row and left == col:\n                # Set rect to merge area\n                heights = (self.code_array.get_row_height(__row, tab)\n                           for __row in xrange(top, bottom+1))\n                widths = (self.code_array.get_col_width(__col, tab)\n                          for __col in xrange(left, right+1))\n                height = sum(heights)\n                width = sum(widths)\n            else:\n                # Do not draw the cell because it is hidden\n                return\n\n        return pos_x, pos_y, width, height", "response": "Returns rectangle of the cell on canvas"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef draw(self):\n\n        row_start, row_stop = self.row_tb\n        col_start, col_stop = self.col_rl\n        tab_start, tab_stop = self.tab_fl\n\n        for tab in xrange(tab_start, tab_stop):\n            # Scale context to page extent\n            # In order to keep the aspect ration intact use the maximum\n            first_key = row_start, col_start, tab\n            first_rect = self.get_cell_rect(*first_key)\n\n            # If we have a merged cell then use the top left cell rect\n            if first_rect is None:\n                top, left, __, __ = self._get_merge_area(first_key)\n                first_rect = self.get_cell_rect(top, left, tab)\n\n            last_key = row_stop - 1, col_stop - 1, tab\n            last_rect = self.get_cell_rect(*last_key)\n\n            # If we have a merged cell then use the top left cell rect\n            if last_rect is None:\n                top, left, __, __ = self._get_merge_area(last_key)\n                last_rect = self.get_cell_rect(top, left, tab)\n\n            x_extent = last_rect[0] + last_rect[2] - first_rect[0]\n            y_extent = last_rect[1] + last_rect[3] - first_rect[1]\n\n            scale_x = (self.width - 2 * self.x_offset) / float(x_extent)\n            scale_y = (self.height - 2 * self.y_offset) / float(y_extent)\n\n            self.context.save()\n            # Translate offset to o\n            self.context.translate(first_rect[0], first_rect[1])\n\n            # Scale to fit page, do not change aspect ratio\n            scale = min(scale_x, scale_y)\n            self.context.scale(scale, scale)\n\n            # Translate offset\n            self.context.translate(-self.x_offset, -self.y_offset)\n\n            # TODO: Center the grid on the page\n\n            # Render cells\n\n            for row in xrange(row_start, row_stop):\n                for col in xrange(col_start, col_stop):\n                    key = row, col, tab\n                    rect = self.get_cell_rect(row, col, tab)  # Rect\n                    if rect is not None:\n                        cell_renderer = GridCellCairoRenderer(\n                            self.context,\n                            self.code_array,\n                            key,  # (row, col, tab)\n                            rect,\n                            self.view_frozen\n                        )\n\n                        cell_renderer.draw()\n\n            # Undo scaling, translation, ...\n            self.context.restore()\n\n            self.context.show_page()", "response": "Draws slice to context"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef draw(self):\n\n        cell_background_renderer = GridCellBackgroundCairoRenderer(\n            self.context,\n            self.code_array,\n            self.key,\n            self.rect,\n            self.view_frozen)\n\n        cell_content_renderer = GridCellContentCairoRenderer(\n            self.context,\n            self.code_array,\n            self.key,\n            self.rect,\n            self.spell_check)\n\n        cell_border_renderer = GridCellBorderCairoRenderer(\n            self.context,\n            self.code_array,\n            self.key,\n            self.rect)\n\n        cell_background_renderer.draw()\n        cell_content_renderer.draw()\n        cell_border_renderer.draw()", "response": "Draws the cell to context"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning scale_x scale_y for bitmap display", "response": "def _get_scalexy(self, ims_width, ims_height):\n        \"\"\"Returns scale_x, scale_y for bitmap display\"\"\"\n\n        # Get cell attributes\n        cell_attributes = self.code_array.cell_attributes[self.key]\n        angle = cell_attributes[\"angle\"]\n\n        if abs(angle) == 90:\n            scale_x = self.rect[3] / float(ims_width)\n            scale_y = self.rect[2] / float(ims_height)\n\n        else:\n            # Normal case\n            scale_x = self.rect[2] / float(ims_width)\n            scale_y = self.rect[3] / float(ims_height)\n\n        return scale_x, scale_y"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn x and y for a bitmap translation", "response": "def _get_translation(self, ims_width, ims_height):\n        \"\"\"Returns x and y for a bitmap translation\"\"\"\n\n        # Get cell attributes\n        cell_attributes = self.code_array.cell_attributes[self.key]\n        justification = cell_attributes[\"justification\"]\n        vertical_align = cell_attributes[\"vertical_align\"]\n        angle = cell_attributes[\"angle\"]\n\n        scale_x, scale_y = self._get_scalexy(ims_width, ims_height)\n        scale = min(scale_x, scale_y)\n\n        if angle not in (90, 180, -90):\n            # Standard direction\n            x = -2  # Otherwise there is a white border\n            y = -2  # Otherwise there is a white border\n\n            if scale_x > scale_y:\n                if justification == \"center\":\n                    x += (self.rect[2] - ims_width * scale) / 2\n\n                elif justification == \"right\":\n                    x += self.rect[2] - ims_width * scale\n\n            else:\n                if vertical_align == \"middle\":\n                    y += (self.rect[3] - ims_height * scale) / 2\n\n                elif vertical_align == \"bottom\":\n                    y += self.rect[3] - ims_height * scale\n\n        if angle == 90:\n            x = -ims_width * scale + 2\n            y = -2\n\n            if scale_y > scale_x:\n                if justification == \"center\":\n                    y += (self.rect[2] - ims_height * scale) / 2\n\n                elif justification == \"right\":\n                    y += self.rect[2] - ims_height * scale\n\n            else:\n                if vertical_align == \"middle\":\n                    x -= (self.rect[3] - ims_width * scale) / 2\n\n                elif vertical_align == \"bottom\":\n                    x -= self.rect[3] - ims_width * scale\n\n        elif angle == 180:\n            x = -ims_width * scale + 2\n            y = -ims_height * scale + 2\n\n            if scale_x > scale_y:\n                if justification == \"center\":\n                    x -= (self.rect[2] - ims_width * scale) / 2\n\n                elif justification == \"right\":\n                    x -= self.rect[2] - ims_width * scale\n\n            else:\n                if vertical_align == \"middle\":\n                    y -= (self.rect[3] - ims_height * scale) / 2\n\n                elif vertical_align == \"bottom\":\n                    y -= self.rect[3] - ims_height * scale\n\n        elif angle == -90:\n            x = -2\n            y = -ims_height * scale + 2\n\n            if scale_y > scale_x:\n                if justification == \"center\":\n                    y -= (self.rect[2] - ims_height * scale) / 2\n\n                elif justification == \"right\":\n                    y -= self.rect[2] - ims_height * scale\n\n            else:\n                if vertical_align == \"middle\":\n                    x += (self.rect[3] - ims_width * scale) / 2\n\n                elif vertical_align == \"bottom\":\n                    x += self.rect[3] - ims_width * scale\n\n        return x, y"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef draw_bitmap(self, content):\n\n        if content.HasAlpha():\n            image = wx.ImageFromBitmap(content)\n            image.ConvertAlphaToMask()\n            image.SetMask(False)\n            content = wx.BitmapFromImage(image)\n\n        ims = wx.lib.wxcairo.ImageSurfaceFromBitmap(content)\n\n        ims_width = ims.get_width()\n        ims_height = ims.get_height()\n\n        transx, transy = self._get_translation(ims_width, ims_height)\n\n        scale_x, scale_y = self._get_scalexy(ims_width, ims_height)\n        scale = min(scale_x, scale_y)\n\n        angle = float(self.code_array.cell_attributes[self.key][\"angle\"])\n\n        self.context.save()\n        self.context.rotate(-angle / 360 * 2 * math.pi)\n        self.context.translate(transx, transy)\n        self.context.scale(scale, scale)\n        self.context.set_source_surface(ims, 0, 0)\n        self.context.paint()\n        self.context.restore()", "response": "Draws bitmap cell content to context"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef draw_svg(self, svg_str):\n\n        try:\n            import rsvg\n        except ImportError:\n            self.draw_text(svg_str)\n            return\n\n        svg = rsvg.Handle(data=svg_str)\n\n        svg_width, svg_height = svg.get_dimension_data()[:2]\n\n        transx, transy = self._get_translation(svg_width, svg_height)\n\n        scale_x, scale_y = self._get_scalexy(svg_width, svg_height)\n        scale = min(scale_x, scale_y)\n\n        angle = float(self.code_array.cell_attributes[self.key][\"angle\"])\n\n        self.context.save()\n        self.context.rotate(-angle / 360 * 2 * math.pi)\n        self.context.translate(transx, transy)\n        self.context.scale(scale, scale)\n        svg.render_cairo(self.context)\n        self.context.restore()", "response": "Draws svg string to cell"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndraw a matplotlib figure to context", "response": "def draw_matplotlib_figure(self, figure):\n        \"\"\"Draws matplotlib figure to context\"\"\"\n\n        class CustomRendererCairo(RendererCairo):\n            \"\"\"Workaround for older versins with limited draw path length\"\"\"\n\n            if sys.byteorder == 'little':\n                BYTE_FORMAT = 0  # BGRA\n            else:\n                BYTE_FORMAT = 1  # ARGB\n\n            def draw_path(self, gc, path, transform, rgbFace=None):\n                ctx = gc.ctx\n                transform = transform + Affine2D().scale(1.0, -1.0).\\\n                    translate(0, self.height)\n                ctx.new_path()\n                self.convert_path(ctx, path, transform)\n\n                try:\n                    self._fill_and_stroke(ctx, rgbFace, gc.get_alpha(),\n                                          gc.get_forced_alpha())\n                except AttributeError:\n                    # Workaround for some Windiws version of Cairo\n                    self._fill_and_stroke(ctx, rgbFace, gc.get_alpha())\n\n            def draw_image(self, gc, x, y, im):\n                # bbox - not currently used\n                rows, cols, buf = im.color_conv(self.BYTE_FORMAT)\n                surface = cairo.ImageSurface.create_for_data(\n                    buf, cairo.FORMAT_ARGB32, cols, rows, cols*4)\n                ctx = gc.ctx\n                y = self.height - y - rows\n                ctx.save()\n                ctx.set_source_surface(surface, x, y)\n                if gc.get_alpha() != 1.0:\n                    ctx.paint_with_alpha(gc.get_alpha())\n                else:\n                    ctx.paint()\n                ctx.restore()\n\n        if pyplot is None:\n            # Matplotlib is not installed\n            return\n\n        FigureCanvasCairo(figure)\n\n        dpi = float(figure.dpi)\n\n        # Set a border so that the figure is not cut off at the cell border\n        border_x = 200 / (self.rect[2] / dpi) ** 2\n        border_y = 200 / (self.rect[3] / dpi) ** 2\n\n        width = (self.rect[2] - 2 * border_x) / dpi\n        height = (self.rect[3] - 2 * border_y) / dpi\n\n        figure.set_figwidth(width)\n        figure.set_figheight(height)\n\n        renderer = CustomRendererCairo(dpi)\n        renderer.set_width_height(width, height)\n\n        renderer.gc.ctx = self.context\n        renderer.text_ctx = self.context\n\n        self.context.save()\n        self.context.translate(border_x, border_y + height * dpi)\n\n        figure.draw(renderer)\n\n        self.context.restore()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn text color rgb tuple of right line", "response": "def _get_text_color(self):\n        \"\"\"Returns text color rgb tuple of right line\"\"\"\n\n        color = self.code_array.cell_attributes[self.key][\"textcolor\"]\n        return tuple(c / 255.0 for c in color_pack2rgb(color))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_font(self, pango_layout):\n\n        wx2pango_weights = {\n            wx.FONTWEIGHT_BOLD: pango.WEIGHT_BOLD,\n            wx.FONTWEIGHT_LIGHT: pango.WEIGHT_LIGHT,\n            wx.FONTWEIGHT_NORMAL: None,  # Do not set a weight by default\n        }\n\n        wx2pango_styles = {\n            wx.FONTSTYLE_NORMAL: None,  # Do not set a style by default\n            wx.FONTSTYLE_SLANT: pango.STYLE_OBLIQUE,\n            wx.FONTSTYLE_ITALIC: pango.STYLE_ITALIC,\n        }\n\n        cell_attributes = self.code_array.cell_attributes[self.key]\n\n        # Text font attributes\n        textfont = cell_attributes[\"textfont\"]\n        pointsize = cell_attributes[\"pointsize\"]\n        fontweight = cell_attributes[\"fontweight\"]\n        fontstyle = cell_attributes[\"fontstyle\"]\n        underline = cell_attributes[\"underline\"]\n        strikethrough = cell_attributes[\"strikethrough\"]\n\n        # Now construct the pango font\n        font_description = pango.FontDescription(\n            \" \".join([textfont, str(pointsize)]))\n        pango_layout.set_font_description(font_description)\n\n        attrs = pango.AttrList()\n\n        # Underline\n        attrs.insert(pango.AttrUnderline(underline, 0, MAX_RESULT_LENGTH))\n\n        # Weight\n        weight = wx2pango_weights[fontweight]\n        if weight is not None:\n            attrs.insert(pango.AttrWeight(weight, 0, MAX_RESULT_LENGTH))\n\n        # Style\n        style = wx2pango_styles[fontstyle]\n        if style is not None:\n            attrs.insert(pango.AttrStyle(style, 0, MAX_RESULT_LENGTH))\n\n        # Strikethrough\n        attrs.insert(pango.AttrStrikethrough(strikethrough, 0,\n                                             MAX_RESULT_LENGTH))\n\n        pango_layout.set_attributes(attrs)", "response": "Sets the font for draw_text"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _rotate_cell(self, angle, rect, back=False):\n\n        if angle == 90 and not back:\n            self.context.rotate(-math.pi / 2.0)\n            self.context.translate(-rect[2] + 4, 0)\n\n        elif angle == 90 and back:\n            self.context.translate(rect[2] - 4, 0)\n            self.context.rotate(math.pi / 2.0)\n\n        elif angle == -90 and not back:\n            self.context.rotate(math.pi / 2.0)\n            self.context.translate(0, -rect[3] + 2)\n\n        elif angle == -90 and back:\n            self.context.translate(0, rect[3] - 2)\n            self.context.rotate(-math.pi / 2.0)\n\n        elif angle == 180 and not back:\n            self.context.rotate(math.pi)\n            self.context.translate(-rect[2] + 4, -rect[3] + 2)\n\n        elif angle == 180 and back:\n            self.context.translate(rect[2] - 4, rect[3] - 2)\n            self.context.rotate(-math.pi)", "response": "Rotates and translates cell if angle in [ - 90 - 180 )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndraws an error underline", "response": "def _draw_error_underline(self, ptx, pango_layout, start, stop):\n        \"\"\"Draws an error underline\"\"\"\n\n        self.context.save()\n        self.context.set_source_rgb(1.0, 0.0, 0.0)\n\n        pit = pango_layout.get_iter()\n\n        # Skip characters until start\n        for i in xrange(start):\n            pit.next_char()\n\n        extents_list = []\n\n        for char_no in xrange(start, stop):\n            char_extents = pit.get_char_extents()\n            underline_pixel_extents = [\n                char_extents[0] / pango.SCALE,\n                (char_extents[1] + char_extents[3]) / pango.SCALE - 2,\n                char_extents[2] / pango.SCALE,\n                4,\n            ]\n            if extents_list:\n                if extents_list[-1][1] == underline_pixel_extents[1]:\n                    # Same line\n                    extents_list[-1][2] = extents_list[-1][2] + \\\n                        underline_pixel_extents[2]\n                else:\n                    # Line break\n                    extents_list.append(underline_pixel_extents)\n            else:\n                extents_list.append(underline_pixel_extents)\n\n            pit.next_char()\n\n        for extent in extents_list:\n            pangocairo.show_error_underline(ptx, *extent)\n\n        self.context.restore()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of start stop tuples that have spelling errors", "response": "def _check_spelling(self, text, lang=\"en_US\"):\n        \"\"\"Returns a list of start stop tuples that have spelling errors\n\n        Parameters\n        ----------\n        text: Unicode or string\n        \\tThe text that is checked\n        lang: String, defaults to \"en_US\"\n        \\tName of spell checking dictionary\n\n        \"\"\"\n\n        chkr = SpellChecker(lang)\n\n        chkr.set_text(text)\n\n        word_starts_ends = []\n\n        for err in chkr:\n            start = err.wordpos\n            stop = err.wordpos + len(err.word) + 1\n            word_starts_ends.append((start, stop))\n\n        return word_starts_ends"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef draw_text(self, content):\n\n        wx2pango_alignment = {\n            \"left\": pango.ALIGN_LEFT,\n            \"center\": pango.ALIGN_CENTER,\n            \"right\": pango.ALIGN_RIGHT,\n        }\n\n        cell_attributes = self.code_array.cell_attributes[self.key]\n\n        angle = cell_attributes[\"angle\"]\n\n        if angle in [-90, 90]:\n            rect = self.rect[1], self.rect[0], self.rect[3], self.rect[2]\n        else:\n            rect = self.rect\n\n        # Text color attributes\n        self.context.set_source_rgb(*self._get_text_color())\n\n        ptx = pangocairo.CairoContext(self.context)\n        pango_layout = ptx.create_layout()\n        self.set_font(pango_layout)\n\n        pango_layout.set_wrap(pango.WRAP_WORD_CHAR)\n\n        pango_layout.set_width(int(round((rect[2] - 4.0) * pango.SCALE)))\n\n        try:\n            markup = cell_attributes[\"markup\"]\n        except KeyError:\n            # Old file\n            markup = False\n\n        if markup:\n            with warnings.catch_warnings(record=True) as warning_lines:\n                warnings.resetwarnings()\n                warnings.simplefilter(\"always\")\n                pango_layout.set_markup(unicode(content))\n\n                if warning_lines:\n                    w2unicode = lambda m: unicode(m.message)\n                    msg = u\"\\n\".join(map(w2unicode, warning_lines))\n                    pango_layout.set_text(msg)\n        else:\n            pango_layout.set_text(unicode(content))\n\n        alignment = cell_attributes[\"justification\"]\n        pango_layout.set_alignment(wx2pango_alignment[alignment])\n\n        # Shift text for vertical alignment\n        extents = pango_layout.get_pixel_extents()\n\n        downshift = 0\n\n        if cell_attributes[\"vertical_align\"] == \"bottom\":\n            downshift = rect[3] - extents[1][3] - 4\n\n        elif cell_attributes[\"vertical_align\"] == \"middle\":\n            downshift = int((rect[3] - extents[1][3]) / 2) - 2\n\n        self.context.save()\n\n        self._rotate_cell(angle, rect)\n        self.context.translate(0, downshift)\n\n        # Spell check underline drawing\n        if SpellChecker is not None and self.spell_check:\n            text = unicode(pango_layout.get_text())\n            lang = config[\"spell_lang\"]\n            for start, stop in self._check_spelling(text, lang=lang):\n                self._draw_error_underline(ptx, pango_layout, start, stop-1)\n\n        ptx.update_layout(pango_layout)\n        ptx.show_layout(pango_layout)\n\n        self.context.restore()", "response": "Draws text cell content to context"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef draw_roundedrect(self, x, y, w, h, r=10):\n        # A****BQ\n        # H     C\n        # *     *\n        # G     D\n        # F****E\n\n        context = self.context\n\n        context.save\n\n        context.move_to(x+r, y)  # Move to A\n        context.line_to(x+w-r, y)  # Straight line to B\n        context.curve_to(x+w, y, x+w, y, x+w, y+r)  # Curve to C\n        # Control points are both at Q\n        context.line_to(x+w, y+h-r)  # Move to D\n        context.curve_to(x+w, y+h, x+w, y+h, x+w-r, y+h)  # Curve to E\n        context.line_to(x+r, y+h)  # Line to F\n        context.curve_to(x, y+h, x, y+h, x, y+h-r)  # Curve to G\n        context.line_to(x, y+r)  # Line to H\n        context.curve_to(x, y, x, y, x+r, y)  # Curve to A\n\n        context.restore", "response": "Draws a rounded rectangle of the log entry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndrawing the content of the current cell into the context", "response": "def draw(self):\n        \"\"\"Draws cell content to context\"\"\"\n\n        # Content is only rendered within rect\n        self.context.save()\n        self.context.rectangle(*self.rect)\n        self.context.clip()\n\n        content = self.get_cell_content()\n\n        pos_x, pos_y = self.rect[:2]\n        self.context.translate(pos_x + 2, pos_y + 2)\n\n        cell_attributes = self.code_array.cell_attributes\n\n        # Do not draw cell content if cell is too small\n        # This allows blending out small cells by reducing height to 0\n\n        if self.rect[2] < cell_attributes[self.key][\"borderwidth_right\"] or \\\n           self.rect[3] < cell_attributes[self.key][\"borderwidth_bottom\"]:\n            self.context.restore()\n            return\n\n        if self.code_array.cell_attributes[self.key][\"button_cell\"]:\n            # Render a button instead of the cell\n            label = self.code_array.cell_attributes[self.key][\"button_cell\"]\n            self.draw_button(1, 1, self.rect[2]-5, self.rect[3]-5, label)\n\n        elif isinstance(content, wx._gdi.Bitmap):\n            # A bitmap is returned --> Draw it!\n            self.draw_bitmap(content)\n\n        elif pyplot is not None and isinstance(content, pyplot.Figure):\n            # A matplotlib figure is returned --> Draw it!\n            self.draw_matplotlib_figure(content)\n\n        elif isinstance(content, basestring) and is_svg(content):\n            # The content is a vaid SVG xml string\n            self.draw_svg(content)\n\n        elif content is not None:\n            self.draw_text(content)\n\n        self.context.translate(-pos_x - 2, -pos_y - 2)\n\n        # Remove clipping to rect\n        self.context.restore()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_background_color(self):\n\n        color = self.cell_attributes[self.key][\"bgcolor\"]\n        return tuple(c / 255.0 for c in color_pack2rgb(color))", "response": "Returns background color rgb tuple of right line"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndraw frozen pattern i. e. diagonal lines", "response": "def _draw_frozen_pattern(self):\n        \"\"\"Draws frozen pattern, i.e. diagonal lines\"\"\"\n\n        self.context.save()\n\n        x, y, w, h = self.rect\n        self.context.set_source_rgb(0, 0, 1)\n        self.context.set_line_width(0.25)\n        self.context.rectangle(*self.rect)\n        self.context.clip()\n\n        for __x in numpy.arange(x-h, x+w, 5):\n            self.context.move_to(__x, y + h)\n            self.context.line_to(__x + h, y)\n        self.context.stroke()\n\n        self.context.restore()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef draw(self):\n\n        self.context.set_source_rgb(*self._get_background_color())\n        self.context.rectangle(*self.rect)\n        self.context.fill()\n\n        # If show frozen is active, show frozen pattern\n        if self.view_frozen and self.cell_attributes[self.key][\"frozen\"]:\n            self._draw_frozen_pattern()", "response": "Draws cell background to context"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndraws this line to the Cairo context", "response": "def draw(self, context):\n        \"\"\"Draws self to Cairo context\"\"\"\n\n        context.set_line_width(self.width)\n        context.set_source_rgb(*self.color)\n\n        context.move_to(*self.start_point)\n        context.line_to(*self.end_point)\n        context.stroke()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_above_key_rect(self):\n\n        key_above = self.row - 1, self.col, self.tab\n\n        border_width_bottom = \\\n            float(self.cell_attributes[key_above][\"borderwidth_bottom\"]) / 2.0\n\n        rect_above = (self.x, self.y-border_width_bottom,\n                      self.width, border_width_bottom)\n        return key_above, rect_above", "response": "Returns tuple key rect of above cell"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_below_key_rect(self):\n\n        key_below = self.row + 1, self.col, self.tab\n\n        border_width_bottom = \\\n            float(self.cell_attributes[self.key][\"borderwidth_bottom\"]) / 2.0\n\n        rect_below = (self.x, self.y+self.height,\n                      self.width, border_width_bottom)\n        return key_below, rect_below", "response": "Returns tuple key rect of below cell"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_left_key_rect(self):\n\n        key_left = self.row, self.col - 1, self.tab\n\n        border_width_right = \\\n            float(self.cell_attributes[key_left][\"borderwidth_right\"]) / 2.0\n\n        rect_left = (self.x-border_width_right, self.y,\n                     border_width_right, self.height)\n        return key_left, rect_left", "response": "Returns tuple key rect of left cell"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns tuple key rect of right cell", "response": "def get_right_key_rect(self):\n        \"\"\"Returns tuple key rect of right cell\"\"\"\n\n        key_right = self.row, self.col + 1, self.tab\n\n        border_width_right = \\\n            float(self.cell_attributes[self.key][\"borderwidth_right\"]) / 2.0\n\n        rect_right = (self.x+self.width, self.y,\n                      border_width_right, self.height)\n        return key_right, rect_right"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_above_left_key_rect(self):\n\n        key_above_left = self.row - 1, self.col - 1, self.tab\n\n        border_width_right = \\\n            float(self.cell_attributes[key_above_left][\"borderwidth_right\"]) \\\n            / 2.0\n        border_width_bottom = \\\n            float(self.cell_attributes[key_above_left][\"borderwidth_bottom\"]) \\\n            / 2.0\n\n        rect_above_left = (self.x-border_width_right,\n                           self.y-border_width_bottom,\n                           border_width_right, border_width_bottom)\n        return key_above_left, rect_above_left", "response": "Returns tuple key rect of above left cell"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_above_right_key_rect(self):\n\n        key_above = self.row - 1, self.col, self.tab\n        key_above_right = self.row - 1, self.col + 1, self.tab\n\n        border_width_right = \\\n            float(self.cell_attributes[key_above][\"borderwidth_right\"]) / 2.0\n        border_width_bottom = \\\n            float(self.cell_attributes[key_above_right][\"borderwidth_bottom\"])\\\n            / 2.0\n\n        rect_above_right = (self.x+self.width, self.y-border_width_bottom,\n                            border_width_right, border_width_bottom)\n        return key_above_right, rect_above_right", "response": "Returns tuple key rect of above right cell"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_below_left_key_rect(self):\n\n        key_left = self.row, self.col - 1, self.tab\n        key_below_left = self.row + 1, self.col - 1, self.tab\n\n        border_width_right = \\\n            float(self.cell_attributes[key_below_left][\"borderwidth_right\"]) \\\n            / 2.0\n        border_width_bottom = \\\n            float(self.cell_attributes[key_left][\"borderwidth_bottom\"]) / 2.0\n\n        rect_below_left = (self.x-border_width_right, self.y-self.height,\n                           border_width_right, border_width_bottom)\n        return key_below_left, rect_below_left", "response": "Returns tuple key rect of below left cell"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn tuple key rect of below right cell", "response": "def get_below_right_key_rect(self):\n        \"\"\"Returns tuple key rect of below right cell\"\"\"\n\n        key_below_right = self.row + 1, self.col + 1, self.tab\n\n        border_width_right = \\\n            float(self.cell_attributes[self.key][\"borderwidth_right\"]) / 2.0\n        border_width_bottom = \\\n            float(self.cell_attributes[self.key][\"borderwidth_bottom\"]) / 2.0\n\n        rect_below_right = (self.x+self.width, self.y-self.height,\n                            border_width_right, border_width_bottom)\n        return key_below_right, rect_below_right"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns start and stop coordinates of bottom line", "response": "def _get_bottom_line_coordinates(self):\n        \"\"\"Returns start and stop coordinates of bottom line\"\"\"\n\n        rect_x, rect_y, rect_width, rect_height = self.rect\n\n        start_point = rect_x, rect_y + rect_height\n        end_point = rect_x + rect_width, rect_y + rect_height\n\n        return start_point, end_point"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_bottom_line_color(self):\n\n        color = self.cell_attributes[self.key][\"bordercolor_bottom\"]\n        return tuple(c / 255.0 for c in color_pack2rgb(color))", "response": "Returns color rgb tuple of bottom line"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn color rgb tuple of right line", "response": "def _get_right_line_color(self):\n        \"\"\"Returns color rgb tuple of right line\"\"\"\n\n        color = self.cell_attributes[self.key][\"bordercolor_right\"]\n        return tuple(c / 255.0 for c in color_pack2rgb(color))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the bottom border of the cell", "response": "def get_b(self):\n        \"\"\"Returns the bottom border of the cell\"\"\"\n\n        start_point, end_point = self._get_bottom_line_coordinates()\n        width = self._get_bottom_line_width()\n        color = self._get_bottom_line_color()\n\n        return CellBorder(start_point, end_point, width, color)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the right border of the cell", "response": "def get_r(self):\n        \"\"\"Returns the right border of the cell\"\"\"\n\n        start_point, end_point = self._get_right_line_coordinates()\n        width = self._get_right_line_width()\n        color = self._get_right_line_color()\n\n        return CellBorder(start_point, end_point, width, color)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the top border of the cell", "response": "def get_t(self):\n        \"\"\"Returns the top border of the cell\"\"\"\n\n        cell_above = CellBorders(self.cell_attributes,\n                                 *self.cell.get_above_key_rect())\n        return cell_above.get_b()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the left border of the cell", "response": "def get_l(self):\n        \"\"\"Returns the left border of the cell\"\"\"\n\n        cell_left = CellBorders(self.cell_attributes,\n                                *self.cell.get_left_key_rect())\n        return cell_left.get_r()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_tl(self):\n\n        cell_above_left = CellBorders(self.cell_attributes,\n                                      *self.cell.get_above_left_key_rect())\n        return cell_above_left.get_r()", "response": "Returns the top left border of the cell"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_tr(self):\n\n        cell_above = CellBorders(self.cell_attributes,\n                                 *self.cell.get_above_key_rect())\n        return cell_above.get_r()", "response": "Returns the top right border of the cell"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_rt(self):\n\n        cell_above_right = CellBorders(self.cell_attributes,\n                                       *self.cell.get_above_right_key_rect())\n        return cell_above_right.get_b()", "response": "Returns the right top border of the cell"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_rb(self):\n\n        cell_right = CellBorders(self.cell_attributes,\n                                 *self.cell.get_right_key_rect())\n        return cell_right.get_b()", "response": "Returns the right bottom border of the cell"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_br(self):\n\n        cell_below = CellBorders(self.cell_attributes,\n                                 *self.cell.get_below_key_rect())\n        return cell_below.get_r()", "response": "Returns the bottom right border of the cell"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the bottom left border of the cell", "response": "def get_bl(self):\n        \"\"\"Returns the bottom left border of the cell\"\"\"\n\n        cell_below_left = CellBorders(self.cell_attributes,\n                                      *self.cell.get_below_left_key_rect())\n        return cell_below_left.get_r()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the left bottom border of the cell", "response": "def get_lb(self):\n        \"\"\"Returns the left bottom border of the cell\"\"\"\n\n        cell_left = CellBorders(self.cell_attributes,\n                                *self.cell.get_left_key_rect())\n        return cell_left.get_b()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_lt(self):\n\n        cell_above_left = CellBorders(self.cell_attributes,\n                                      *self.cell.get_above_left_key_rect())\n        return cell_above_left.get_b()", "response": "Returns the left top border of the cell"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndraw cell borders to context", "response": "def draw(self):\n        \"\"\"Draws cell border to context\"\"\"\n\n        # Lines should have a square cap to avoid ugly edges\n        self.context.set_line_cap(cairo.LINE_CAP_SQUARE)\n\n        self.context.save()\n        self.context.rectangle(*self.rect)\n        self.context.clip()\n\n        cell_borders = CellBorders(self.cell_attributes, self.key, self.rect)\n        borders = list(cell_borders.gen_all())\n        borders.sort(key=attrgetter('width', 'color'))\n        for border in borders:\n            border.draw(self.context)\n\n        self.context.restore()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _draw_cursor(self, dc, grid, row, col,\n                     pen=None, brush=None):\n        \"\"\"Draws cursor as Rectangle in lower right corner\"\"\"\n\n        # If in full screen mode draw no cursor\n        if grid.main_window.IsFullScreen():\n            return\n\n        key = row, col, grid.current_table\n        rect = grid.CellToRect(row, col)\n        rect = self.get_merged_rect(grid, key, rect)\n\n        # Check if cell is invisible\n        if rect is None:\n            return\n\n        size = self.get_zoomed_size(1.0)\n\n        caret_length = int(min([rect.width, rect.height]) / 5.0)\n\n        color = get_color(config[\"text_color\"])\n        if pen is None:\n          pen = wx.Pen(color)\n        if brush is None:\n          brush = wx.Brush(color)\n\n        pen.SetWidth(size)\n\n        # Inner right and lower borders\n        border_left = rect.x + size - 1\n        border_right = rect.x + rect.width - size - 1\n        border_upper = rect.y + size - 1\n        border_lower = rect.y + rect.height - size - 1\n\n        points_lr = [\n            (border_right, border_lower - caret_length),\n            (border_right, border_lower),\n            (border_right - caret_length, border_lower),\n            (border_right, border_lower),\n        ]\n\n        points_ur = [\n            (border_right, border_upper + caret_length),\n            (border_right, border_upper),\n            (border_right - caret_length, border_upper),\n            (border_right, border_upper),\n        ]\n\n        points_ul = [\n            (border_left, border_upper + caret_length),\n            (border_left, border_upper),\n            (border_left + caret_length, border_upper),\n            (border_left, border_upper),\n        ]\n\n        points_ll = [\n            (border_left, border_lower - caret_length),\n            (border_left, border_lower),\n            (border_left + caret_length, border_lower),\n            (border_left, border_lower),\n        ]\n\n        point_list = [points_lr, points_ur, points_ul, points_ll]\n\n        dc.DrawPolygonList(point_list, pens=pen, brushes=brush)\n\n        self.old_cursor_row_col = row, col", "response": "Draws cursor as Rectangle in lower right corner of the current cell"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_cursor(self, dc, grid, row, col):\n\n        old_row, old_col = self.old_cursor_row_col\n\n        bgcolor = get_color(config[\"background_color\"])\n\n        self._draw_cursor(dc, grid, old_row, old_col,\n                          pen=wx.Pen(bgcolor), brush=wx.Brush(bgcolor))\n        self._draw_cursor(dc, grid, row, col)", "response": "Whites out the old cursor and draws the new one"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns rect for normal or merged cells and None for merged", "response": "def get_merged_rect(self, grid, key, rect):\n        \"\"\"Returns cell rect for normal or merged cells and None for merged\"\"\"\n\n        row, col, tab = key\n\n        # Check if cell is merged:\n        cell_attributes = grid.code_array.cell_attributes\n        merge_area = cell_attributes[(row, col, tab)][\"merge_area\"]\n\n        if merge_area is None:\n            return rect\n\n        else:\n            # We have a merged cell\n            top, left, bottom, right = merge_area\n\n            # Are we drawing the top left cell?\n            if top == row and left == col:\n                # Set rect to merge area\n                ul_rect = grid.CellToRect(row, col)\n                br_rect = grid.CellToRect(bottom, right)\n\n                width = br_rect.x - ul_rect.x + br_rect.width\n                height = br_rect.y - ul_rect.y + br_rect.height\n\n                rect = wx.Rect(ul_rect.x, ul_rect.y, width, height)\n\n                return rect"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreplacing drawn rect if the one provided by wx is incorrect This handles merged rects including those that are partly off screen.", "response": "def _get_drawn_rect(self, grid, key, rect):\n        \"\"\"Replaces drawn rect if the one provided by wx is incorrect\n\n        This handles merged rects including those that are partly off screen.\n\n        \"\"\"\n\n        rect = self.get_merged_rect(grid, key, rect)\n        if rect is None:\n            # Merged cell is drawn\n            if grid.is_merged_cell_drawn(key):\n                # Merging cell is outside view\n                row, col, __ = key = self.get_merging_cell(grid, key)\n                rect = grid.CellToRect(row, col)\n                rect = self.get_merged_rect(grid, key, rect)\n            else:\n                return\n\n        return rect"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_draw_cache_key(self, grid, key, drawn_rect, is_selected):\n\n        row, col, tab = key\n        cell_attributes = grid.code_array.cell_attributes\n\n        zoomed_width = drawn_rect.width / self.zoom\n        zoomed_height = drawn_rect.height / self.zoom\n\n        # Button cells shall not be executed for preview\n        if grid.code_array.cell_attributes[key][\"button_cell\"]:\n            cell_preview = repr(grid.code_array(key))[:100]\n            __id = id(grid.code_array(key))\n        else:\n            cell_preview = repr(grid.code_array[key])[:100]\n            __id = id(grid.code_array[key])\n\n        sorted_keys = sorted(grid.code_array.cell_attributes[key].iteritems())\n\n        key_above_left = row - 1, col - 1, tab\n        key_above = row - 1, col, tab\n        key_above_right = row - 1, col + 1, tab\n        key_left = row, col - 1, tab\n        key_right = row, col + 1, tab\n        key_below_left = row + 1, col - 1, tab\n        key_below = row + 1, col, tab\n\n        borders = []\n\n        for k in [key, key_above_left, key_above, key_above_right,\n                  key_left, key_right, key_below_left, key_below]:\n            borders.append(cell_attributes[k][\"borderwidth_bottom\"])\n            borders.append(cell_attributes[k][\"borderwidth_right\"])\n            borders.append(cell_attributes[k][\"bordercolor_bottom\"])\n            borders.append(cell_attributes[k][\"bordercolor_right\"])\n\n        return (zoomed_width, zoomed_height, is_selected, cell_preview, __id,\n                tuple(sorted_keys), tuple(borders))", "response": "Returns the key for the screen draw cache"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a wx. Bitmap of cell key in size rect", "response": "def _get_cairo_bmp(self, mdc, key, rect, is_selected, view_frozen):\n        \"\"\"Returns a wx.Bitmap of cell key in size rect\"\"\"\n\n        bmp = wx.EmptyBitmap(rect.width, rect.height)\n        mdc.SelectObject(bmp)\n        mdc.SetBackgroundMode(wx.SOLID)\n        mdc.SetBackground(wx.WHITE_BRUSH)\n        mdc.Clear()\n        mdc.SetDeviceOrigin(0, 0)\n\n        context = wx.lib.wxcairo.ContextFromDC(mdc)\n\n        context.save()\n\n        # Zoom context\n        zoom = self.zoom\n        context.scale(zoom, zoom)\n\n        # Set off cell renderer by 1/2 a pixel to avoid blurry lines\n        rect_tuple = \\\n            -0.5, -0.5, rect.width / zoom + 0.5, rect.height / zoom + 0.5\n        spell_check = config[\"check_spelling\"]\n        cell_renderer = GridCellCairoRenderer(context, self.data_array,\n                                              key, rect_tuple, view_frozen,\n                                              spell_check=spell_check)\n        # Draw cell\n        cell_renderer.draw()\n\n        # Draw selection if present\n        if is_selected:\n            context.set_source_rgba(*self.selection_color_tuple)\n            context.rectangle(*rect_tuple)\n            context.fill()\n\n        context.restore()\n\n        return bmp"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef Draw(self, grid, attr, dc, rect, row, col, isSelected):\n\n        key = row, col, grid.current_table\n\n        # If cell is merge draw the merging cell if invisibile\n        if grid.code_array.cell_attributes[key][\"merge_area\"]:\n            key = self.get_merging_cell(grid, key)\n\n        drawn_rect = self._get_drawn_rect(grid, key, rect)\n        if drawn_rect is None:\n            return\n\n        cell_cache_key = self._get_draw_cache_key(grid, key, drawn_rect,\n                                                  isSelected)\n\n        mdc = wx.MemoryDC()\n\n        if vlc is not None and key in self.video_cells and \\\n           grid.code_array.cell_attributes[key][\"panel_cell\"]:\n            # Update video position of previously created video panel\n            self.video_cells[key].SetClientRect(drawn_rect)\n\n        elif cell_cache_key in self.cell_cache:\n            mdc.SelectObject(self.cell_cache[cell_cache_key])\n\n        else:\n            code = grid.code_array(key)\n            if vlc is not None and code is not None and \\\n               grid.code_array.cell_attributes[key][\"panel_cell\"]:\n                try:\n                    # A panel is to be displayed\n                    panel_cls = grid.code_array[key]\n\n                    # Assert that we have a subclass of a wxPanel that we\n                    # can instantiate\n                    assert issubclass(panel_cls, wx.Panel)\n\n                    video_panel = panel_cls(grid)\n                    video_panel.SetClientRect(drawn_rect)\n                    # Register video cell\n                    self.video_cells[key] = video_panel\n\n                    return\n\n                except Exception, err:\n                    # Someting is wrong with the panel to be displayed\n                    post_command_event(grid.main_window, self.StatusBarMsg,\n                                       text=unicode(err))\n                    bmp = self._get_cairo_bmp(mdc, key, drawn_rect, isSelected,\n                                              grid._view_frozen)\n            else:\n                bmp = self._get_cairo_bmp(mdc, key, drawn_rect, isSelected,\n                                          grid._view_frozen)\n\n            # Put resulting bmp into cache\n            self.cell_cache[cell_cache_key] = bmp\n\n        dc.Blit(drawn_rect.x, drawn_rect.y,\n                drawn_rect.width, drawn_rect.height,\n                mdc, 0, 0, wx.COPY)\n\n        # Draw cursor\n        if grid.actions.cursor[:2] == (row, col):\n            self.update_cursor(dc, grid, row, col)", "response": "Draws the border and content using pycairo"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef choose_key(gpg_private_keys):\n\n    uid_strings_fp = []\n    uid_string_fp2key = {}\n\n    current_key_index = None\n\n    for i, key in enumerate(gpg_private_keys):\n        fingerprint = key['fingerprint']\n\n        if fingerprint == config[\"gpg_key_fingerprint\"]:\n            current_key_index = i\n\n        for uid_string in key['uids']:\n            uid_string_fp = '\"' + uid_string + ' (' + fingerprint + ')'\n            uid_strings_fp.append(uid_string_fp)\n            uid_string_fp2key[uid_string_fp] = key\n\n    msg = _('Choose a GPG key for signing pyspread save files.\\n'\n            'The GPG key must not have a passphrase set.')\n\n    dlg = wx.SingleChoiceDialog(None, msg, _('Choose key'), uid_strings_fp,\n                                wx.CHOICEDLG_STYLE)\n\n    childlist = list(dlg.GetChildren())\n    childlist[-3].SetLabel(_(\"Use chosen key\"))\n    childlist[-2].SetLabel(_(\"Create new key\"))\n\n    if current_key_index is not None:\n        # Set choice to current key\n        dlg.SetSelection(current_key_index)\n\n    if dlg.ShowModal() == wx.ID_OK:\n        uid_string_fp = dlg.GetStringSelection()\n        key = uid_string_fp2key[uid_string_fp]\n\n    else:\n        key = None\n\n    dlg.Destroy()\n\n    return key", "response": "Displays a single choice dialog and returns key"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _register_key(fingerprint, gpg):\n\n    for private_key in gpg.list_keys(True):\n        try:\n            if str(fingerprint) == private_key['fingerprint']:\n                config[\"gpg_key_fingerprint\"] = \\\n                    repr(private_key['fingerprint'])\n        except KeyError:\n            pass", "response": "Registers a key in config"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True iif gpg_secret_key has a password", "response": "def has_no_password(gpg_secret_keyid):\n    \"\"\"Returns True iif gpg_secret_key has a password\"\"\"\n\n    if gnupg is None:\n        return False\n\n    gpg = gnupg.GPG()\n    s = gpg.sign(\"\", keyid=gpg_secret_keyid, passphrase=\"\")\n\n    try:\n        return s.status == \"signature created\"\n    except AttributeError:\n        # This may happen on Windows\n        if hasattr(s, \"stderr\"):\n            return \"GOOD_PASSPHRASE\" in s.stderr"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef genkey(key_name=None):\n\n    if gnupg is None:\n        return\n\n    gpg_key_param_list = [\n        ('key_type', 'DSA'),\n        ('key_length', '2048'),\n        ('subkey_type', 'ELG-E'),\n        ('subkey_length', '2048'),\n        ('expire_date', '0'),\n    ]\n\n    gpg = gnupg.GPG()\n\n    gpg.encoding = 'utf-8'\n\n    # Check if standard key is already present\n\n    pyspread_key_fingerprint = config[\"gpg_key_fingerprint\"]\n    gpg_private_keys = [key for key in gpg.list_keys(secret=True)\n                        if has_no_password(key[\"keyid\"])]\n    gpg_private_fingerprints = \\\n        [key['fingerprint'] for key in gpg.list_keys(secret=True)\n         if has_no_password(key[\"keyid\"])]\n\n    pyspread_key = None\n\n    for private_key, fingerprint in zip(gpg_private_keys,\n                                        gpg_private_fingerprints):\n        if str(pyspread_key_fingerprint) == fingerprint:\n            pyspread_key = private_key\n\n    if gpg_private_keys:\n        # If GPG are available, choose one\n        pyspread_key = choose_key(gpg_private_keys)\n\n    if pyspread_key:\n        # A key has been chosen\n        config[\"gpg_key_fingerprint\"] = repr(pyspread_key['fingerprint'])\n\n    else:\n        # No key has been chosen --> Create new one\n        if key_name is None:\n            gpg_key_parameters = get_key_params_from_user(gpg_key_param_list)\n            if gpg_key_parameters is None:\n                # No name entered\n                return\n        else:\n            gpg_key_param_list.append(\n                ('name_real', '{key_name}'.format(key_name=key_name)))\n            gpg_key_parameters = dict(gpg_key_param_list)\n\n        input_data = gpg.gen_key_input(**gpg_key_parameters)\n\n        # Generate key\n        # ------------\n\n        if key_name is None:\n            # Show information dialog\n\n            style = wx.ICON_INFORMATION | wx.DIALOG_NO_PARENT | wx.OK | \\\n                wx.CANCEL\n            pyspread_key_uid = gpg_key_parameters[\"name_real\"]\n            short_message = _(\"New GPG key\").format(pyspread_key_uid)\n            message = _(\"After confirming this dialog, a new GPG key \") + \\\n                _(\"'{key}' will be generated.\").format(key=pyspread_key_uid) +\\\n                _(\" \\n \\nThis may take some time.\\nPlease wait.\")\n            dlg = wx.MessageDialog(None, message, short_message, style)\n            dlg.Centre()\n\n            if dlg.ShowModal() == wx.ID_OK:\n                dlg.Destroy()\n                gpg_key = gpg.gen_key(input_data)\n                _register_key(gpg_key, gpg)\n                fingerprint = gpg_key.fingerprint\n            else:\n                dlg.Destroy()\n                return\n\n        else:\n            gpg_key = gpg.gen_key(input_data)\n            _register_key(gpg_key, gpg)\n            fingerprint = gpg_key.fingerprint\n\n    return fingerprint", "response": "Creates a new GPG key and returns it"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fingerprint2keyid(fingerprint):\n\n    if gnupg is None:\n        return\n\n    gpg = gnupg.GPG()\n    private_keys = gpg.list_keys(True)\n\n    keyid = None\n    for private_key in private_keys:\n        if private_key['fingerprint'] == config[\"gpg_key_fingerprint\"]:\n            keyid = private_key['keyid']\n            break\n\n    return keyid", "response": "Returns keyid from fingerprint for private keys"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sign(filename):\n\n    if gnupg is None:\n        return\n\n    gpg = gnupg.GPG()\n\n    with open(filename, \"rb\") as signfile:\n        keyid = fingerprint2keyid(config[\"gpg_key_fingerprint\"])\n\n        if keyid is None:\n            msg = \"No private key for GPG fingerprint '{}'.\"\n            raise ValueError(msg.format(config[\"gpg_key_fingerprint\"]))\n\n        signed_data = gpg.sign_file(signfile, keyid=keyid, detach=True)\n\n    return signed_data", "response": "Returns detached signature for file"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nverifying a signature returns True if successful else False.", "response": "def verify(sigfilename, filefilename=None):\n    \"\"\"Verifies a signature, returns True if successful else False.\"\"\"\n\n    if gnupg is None:\n        return False\n\n    gpg = gnupg.GPG()\n\n    with open(sigfilename, \"rb\") as sigfile:\n        verified = gpg.verify_file(sigfile, filefilename)\n\n        pyspread_keyid = fingerprint2keyid(config[\"gpg_key_fingerprint\"])\n\n        if verified.valid and verified.key_id == pyspread_keyid:\n            return True\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _len_table_cache(self):\n\n        length = 0\n\n        for table in self._table_cache:\n            length += len(self._table_cache[table])\n\n        return length", "response": "Returns the length of the table cache"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nclear and updates the table cache to be in sync with self", "response": "def _update_table_cache(self):\n        \"\"\"Clears and updates the table cache to be in sync with self\"\"\"\n\n        self._table_cache.clear()\n        for sel, tab, val in self:\n            try:\n                self._table_cache[tab].append((sel, val))\n            except KeyError:\n                self._table_cache[tab] = [(sel, val)]\n\n        assert len(self) == self._len_table_cache()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_merging_cell(self, key):\n\n        row, col, tab = key\n\n        # Is cell merged\n        merge_area = self[key][\"merge_area\"]\n\n        if merge_area:\n            return merge_area[0], merge_area[1], tab", "response": "Returns the key of the cell that merges the cell key or None if no such cell exists"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn dict of data content.", "response": "def _get_data(self):\n        \"\"\"Returns dict of data content.\n\n        Keys\n        ----\n\n        shape: 3-tuple of Integer\n        \\tGrid shape\n        grid: Dict of 3-tuples to strings\n        \\tCell content\n        attributes: List of 3-tuples\n        \\tCell attributes\n        row_heights: Dict of 2-tuples to float\n        \\t(row, tab): row_height\n        col_widths: Dict of 2-tuples to float\n        \\t(col, tab): col_width\n        macros: String\n        \\tMacros from macro list\n\n        \"\"\"\n\n        data = {}\n\n        data[\"shape\"] = self.shape\n        data[\"grid\"] = {}.update(self.dict_grid)\n        data[\"attributes\"] = [ca for ca in self.cell_attributes]\n        data[\"row_heights\"] = self.row_heights\n        data[\"col_widths\"] = self.col_widths\n        data[\"macros\"] = self.macros\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting data from given parameters.", "response": "def _set_data(self, **kwargs):\n        \"\"\"Sets data from given parameters\n\n        Old values are deleted.\n        If a paremeter is not given, nothing is changed.\n\n        Parameters\n        ----------\n\n        shape: 3-tuple of Integer\n        \\tGrid shape\n        grid: Dict of 3-tuples to strings\n        \\tCell content\n        attributes: List of 3-tuples\n        \\tCell attributes\n        row_heights: Dict of 2-tuples to float\n        \\t(row, tab): row_height\n        col_widths: Dict of 2-tuples to float\n        \\t(col, tab): col_width\n        macros: String\n        \\tMacros from macro list\n\n        \"\"\"\n\n        if \"shape\" in kwargs:\n            self.shape = kwargs[\"shape\"]\n\n        if \"grid\" in kwargs:\n            self.dict_grid.clear()\n            self.dict_grid.update(kwargs[\"grid\"])\n\n        if \"attributes\" in kwargs:\n            self.attributes[:] = kwargs[\"attributes\"]\n\n        if \"row_heights\" in kwargs:\n            self.row_heights = kwargs[\"row_heights\"]\n\n        if \"col_widths\" in kwargs:\n            self.col_widths = kwargs[\"col_widths\"]\n\n        if \"macros\" in kwargs:\n            self.macros = kwargs[\"macros\"]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_col_width(self, col, tab):\n\n        try:\n            return self.col_widths[(col, tab)]\n\n        except KeyError:\n            return config[\"default_col_width\"]", "response": "Returns the column width for a given column and tab."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_shape(self, shape):\n\n        # Delete each cell that is beyond new borders\n\n        old_shape = self.shape\n        deleted_cells = {}\n\n        if any(new_axis < old_axis\n               for new_axis, old_axis in zip(shape, old_shape)):\n            for key in self.dict_grid.keys():\n                if any(key_ele >= new_axis\n                       for key_ele, new_axis in zip(key, shape)):\n                    deleted_cells[key] = self.pop(key)\n\n        # Set dict_grid shape attribute\n        self.dict_grid.shape = shape\n\n        self._adjust_rowcol(0, 0, 0)\n        self._adjust_cell_attributes(0, 0, 0)\n\n        # Undo actions\n\n        yield \"_set_shape\"\n\n        self.shape = old_shape\n\n        for key in deleted_cells:\n            self[key] = deleted_cells[key]", "response": "Sets the shape of the dictionary_grid and sets the shape attribute for the grid."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the key for the bottommost rightmost cell with content MimeType", "response": "def get_last_filled_cell(self, table=None):\n        \"\"\"Returns key for the bottommost rightmost cell with content\n\n        Parameters\n        ----------\n        table: Integer, defaults to None\n        \\tLimit search to this table\n\n        \"\"\"\n\n        maxrow = 0\n        maxcol = 0\n\n        for row, col, tab in self.dict_grid:\n            if table is None or tab == table:\n                maxrow = max(row, maxrow)\n                maxcol = max(col, maxcol)\n\n        return maxrow, maxcol, table"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cell_array_generator(self, key):\n\n        for i, key_ele in enumerate(key):\n\n            # Get first element of key that is a slice\n            if type(key_ele) is SliceType:\n                slc_keys = xrange(*key_ele.indices(self.dict_grid.shape[i]))\n                key_list = list(key)\n\n                key_list[i] = None\n\n                has_subslice = any(type(ele) is SliceType for ele in key_list)\n\n                for slc_key in slc_keys:\n                    key_list[i] = slc_key\n\n                    if has_subslice:\n                        # If there is a slice left yield generator\n                        yield self.cell_array_generator(key_list)\n\n                    else:\n                        # No slices? Yield value\n                        yield self[tuple(key_list)]\n\n                break", "response": "Generator traversing cells specified in key"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nshifts row and column sizes when a table is inserted or deleted", "response": "def _shift_rowcol(self, insertion_point, no_to_insert):\n        \"\"\"Shifts row and column sizes when a table is inserted or deleted\"\"\"\n\n        # Shift row heights\n\n        new_row_heights = {}\n        del_row_heights = []\n\n        for row, tab in self.row_heights:\n            if tab > insertion_point:\n                new_row_heights[(row, tab + no_to_insert)] = \\\n                    self.row_heights[(row, tab)]\n                del_row_heights.append((row, tab))\n\n        for row, tab in new_row_heights:\n            self.set_row_height(row, tab, new_row_heights[(row, tab)])\n\n        for row, tab in del_row_heights:\n            if (row, tab) not in new_row_heights:\n                self.set_row_height(row, tab, None)\n\n        # Shift column widths\n\n        new_col_widths = {}\n        del_col_widths = []\n\n        for col, tab in self.col_widths:\n            if tab > insertion_point:\n                new_col_widths[(col, tab + no_to_insert)] = \\\n                    self.col_widths[(col, tab)]\n                del_col_widths.append((col, tab))\n\n        for col, tab in new_col_widths:\n            self.set_col_width(col, tab, new_col_widths[(col, tab)])\n\n        for col, tab in del_col_widths:\n            if (col, tab) not in new_col_widths:\n                self.set_col_width(col, tab, None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadjusts row and column sizes on insertion and deletion.", "response": "def _adjust_rowcol(self, insertion_point, no_to_insert, axis, tab=None):\n        \"\"\"Adjusts row and column sizes on insertion/deletion\"\"\"\n\n        if axis == 2:\n            self._shift_rowcol(insertion_point, no_to_insert)\n            return\n\n        assert axis in (0, 1)\n\n        cell_sizes = self.col_widths if axis else self.row_heights\n        set_cell_size = self.set_col_width if axis else self.set_row_height\n\n        new_sizes = {}\n        del_sizes = []\n\n        for pos, table in cell_sizes:\n            if pos > insertion_point and (tab is None or tab == table):\n                if 0 <= pos + no_to_insert < self.shape[axis]:\n                    new_sizes[(pos + no_to_insert, table)] = \\\n                        cell_sizes[(pos, table)]\n                del_sizes.append((pos, table))\n\n        for pos, table in new_sizes:\n            set_cell_size(pos, table, new_sizes[(pos, table)])\n\n        for pos, table in del_sizes:\n            if (pos, table) not in new_sizes:\n                set_cell_size(pos, table, None)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the adjusted merge area for the specified cell attributes.", "response": "def _get_adjusted_merge_area(self, attrs, insertion_point, no_to_insert,\n                                 axis):\n        \"\"\"Returns updated merge area\n\n        Parameters\n        ----------\n        attrs: Dict\n        \\tCell attribute dictionary that shall be adjusted\n        insertion_point: Integer\n        \\tPont on axis, before which insertion takes place\n        no_to_insert: Integer >= 0\n        \\tNumber of rows/cols/tabs that shall be inserted\n        axis: Integer in range(2)\n        \\tSpecifies number of dimension, i.e. 0 == row, 1 == col\n\n        \"\"\"\n\n        assert axis in range(2)\n\n        if \"merge_area\" not in attrs or attrs[\"merge_area\"] is None:\n            return\n\n        top, left, bottom, right = attrs[\"merge_area\"]\n        selection = Selection([(top, left)], [(bottom, right)], [], [], [])\n\n        selection.insert(insertion_point, no_to_insert, axis)\n\n        __top, __left = selection.block_tl[0]\n        __bottom, __right = selection.block_br[0]\n\n        # Adjust merge area if it is beyond the grid shape\n        rows, cols, tabs = self.shape\n\n        if __top < 0 and __bottom < 0 or __top >= rows and __bottom >= rows or\\\n           __left < 0 and __right < 0 or __left >= cols and __right >= cols:\n            return\n\n        if __top < 0:\n            __top = 0\n\n        if __top >= rows:\n            __top = rows - 1\n\n        if __bottom < 0:\n            __bottom = 0\n\n        if __bottom >= rows:\n            __bottom = rows - 1\n\n        if __left < 0:\n            __left = 0\n\n        if __left >= cols:\n            __left = cols - 1\n\n        if __right < 0:\n            __right = 0\n\n        if __right >= cols:\n            __right = cols - 1\n\n        return __top, __left, __bottom, __right"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadjust the cell attributes on insertion and deletion on table and cell attributes.", "response": "def _adjust_cell_attributes(self, insertion_point, no_to_insert, axis,\n                                tab=None, cell_attrs=None):\n        \"\"\"Adjusts cell attributes on insertion/deletion\n\n        Parameters\n        ----------\n        insertion_point: Integer\n        \\tPont on axis, before which insertion takes place\n        no_to_insert: Integer >= 0\n        \\tNumber of rows/cols/tabs that shall be inserted\n        axis: Integer in range(3)\n        \\tSpecifies number of dimension, i.e. 0 == row, 1 == col, ...\n        tab: Integer, defaults to None\n        \\tIf given then insertion is limited to this tab for axis < 2\n        cell_attrs: List, defaults to []\n        \\tIf not empty then the given cell attributes replace the existing ones\n\n        \"\"\"\n\n        def replace_cell_attributes_table(index, new_table):\n            \"\"\"Replaces table in cell_attributes item\"\"\"\n\n            ca = list(list.__getitem__(self.cell_attributes, index))\n            ca[1] = new_table\n            self.cell_attributes.__setitem__(index, tuple(ca))\n\n        def get_ca_with_updated_ma(attrs, merge_area):\n            \"\"\"Returns cell attributes with updated merge area\"\"\"\n\n            new_attrs = copy(attrs)\n\n            if merge_area is None:\n                try:\n                    new_attrs.pop(\"merge_area\")\n                except KeyError:\n                    pass\n            else:\n                new_attrs[\"merge_area\"] = merge_area\n\n            return new_attrs\n\n        if axis not in range(3):\n            raise ValueError(\"Axis must be in [0, 1, 2]\")\n\n        assert tab is None or tab >= 0\n\n        if cell_attrs is None:\n            cell_attrs = []\n\n        if cell_attrs:\n            self.cell_attributes[:] = cell_attrs\n\n        elif axis < 2:\n            # Adjust selections on given table\n\n            ca_updates = {}\n            for i, (selection, table, attrs) in enumerate(\n                                                    self.cell_attributes):\n                selection = copy(selection)\n                if tab is None or tab == table:\n                    selection.insert(insertion_point, no_to_insert, axis)\n                    # Update merge area if present\n                    merge_area = self._get_adjusted_merge_area(attrs,\n                                                               insertion_point,\n                                                               no_to_insert,\n                                                               axis)\n                    new_attrs = get_ca_with_updated_ma(attrs, merge_area)\n\n                    ca_updates[i] = selection, table, new_attrs\n\n            for idx in ca_updates:\n                self.cell_attributes[idx] = ca_updates[idx]\n\n        elif axis == 2:\n            # Adjust tabs\n\n            pop_indices = []\n\n            for i, cell_attribute in enumerate(self.cell_attributes):\n                selection, table, value = cell_attribute\n\n                if no_to_insert < 0 and insertion_point <= table:\n                    if insertion_point > table + no_to_insert:\n                        # Delete later\n                        pop_indices.append(i)\n                    else:\n                        replace_cell_attributes_table(i, table + no_to_insert)\n\n                elif insertion_point < table:\n                    # Insert\n                    replace_cell_attributes_table(i, table + no_to_insert)\n\n            for i in pop_indices[::-1]:\n                self.cell_attributes.pop(i)\n\n        self.cell_attributes._attr_cache.clear()\n        self.cell_attributes._update_table_cache()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninsert no_to_insert rows and cols and tabs before insertion_point.", "response": "def insert(self, insertion_point, no_to_insert, axis, tab=None):\n        \"\"\"Inserts no_to_insert rows/cols/tabs/... before insertion_point\n\n        Parameters\n        ----------\n\n        insertion_point: Integer\n        \\tPont on axis, before which insertion takes place\n        no_to_insert: Integer >= 0\n        \\tNumber of rows/cols/tabs that shall be inserted\n        axis: Integer\n        \\tSpecifies number of dimension, i.e. 0 == row, 1 == col, ...\n        tab: Integer, defaults to None\n        \\tIf given then insertion is limited to this tab for axis < 2\n\n        \"\"\"\n\n        if not 0 <= axis <= len(self.shape):\n            raise ValueError(\"Axis not in grid dimensions\")\n\n        if insertion_point > self.shape[axis] or \\\n           insertion_point < -self.shape[axis]:\n            raise IndexError(\"Insertion point not in grid\")\n\n        new_keys = {}\n        del_keys = []\n\n        for key in self.dict_grid.keys():\n            if key[axis] > insertion_point and (tab is None or tab == key[2]):\n                new_key = list(key)\n                new_key[axis] += no_to_insert\n                if 0 <= new_key[axis] < self.shape[axis]:\n                    new_keys[tuple(new_key)] = self(key)\n                del_keys.append(key)\n\n        # Now re-insert moved keys\n\n        for key in del_keys:\n            if key not in new_keys and self(key) is not None:\n                self.pop(key)\n\n        self._adjust_rowcol(insertion_point, no_to_insert, axis, tab=tab)\n        self._adjust_cell_attributes(insertion_point, no_to_insert, axis, tab)\n\n        for key in new_keys:\n            self.__setitem__(key, new_keys[key])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete(self, deletion_point, no_to_delete, axis, tab=None):\n\n        if not 0 <= axis < len(self.shape):\n            raise ValueError(\"Axis not in grid dimensions\")\n\n        if no_to_delete < 0:\n            raise ValueError(\"Cannot delete negative number of rows/cols/...\")\n\n        elif no_to_delete >= self.shape[axis]:\n            raise ValueError(\"Last row/column/table must not be deleted\")\n\n        if deletion_point > self.shape[axis] or \\\n           deletion_point <= -self.shape[axis]:\n            raise IndexError(\"Deletion point not in grid\")\n\n        new_keys = {}\n        del_keys = []\n\n        # Note that the loop goes over a list that copies all dict keys\n        for key in self.dict_grid.keys():\n            if tab is None or tab == key[2]:\n                if deletion_point <= key[axis] < deletion_point + no_to_delete:\n                    del_keys.append(key)\n\n                elif key[axis] >= deletion_point + no_to_delete:\n                    new_key = list(key)\n                    new_key[axis] -= no_to_delete\n\n                    new_keys[tuple(new_key)] = self(key)\n                    del_keys.append(key)\n\n        # Now re-insert moved keys\n\n        for key in new_keys:\n            self.__setitem__(key, new_keys[key])\n\n        for key in del_keys:\n            if key not in new_keys and self(key) is not None:\n                self.pop(key)\n\n        self._adjust_rowcol(deletion_point, -no_to_delete, axis, tab=tab)\n        self._adjust_cell_attributes(deletion_point, -no_to_delete, axis)", "response": "Deletes no_to_delete rows and cols from the grid."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_row_height(self, row, tab, height):\n\n        try:\n            old_height = self.row_heights.pop((row, tab))\n\n        except KeyError:\n            old_height = None\n\n        if height is not None:\n            self.row_heights[(row, tab)] = float(height)", "response": "Sets the row height for a specific tab."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the column width.", "response": "def set_col_width(self, col, tab, width):\n        \"\"\"Sets column width\"\"\"\n\n        try:\n            old_width = self.col_widths.pop((col, tab))\n\n        except KeyError:\n            old_width = None\n\n        if width is not None:\n            self.col_widths[(col, tab)] = float(width)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmake nested list from generator for creating numpy. array", "response": "def _make_nested_list(self, gen):\n        \"\"\"Makes nested list from generator for creating numpy.array\"\"\"\n\n        res = []\n\n        for ele in gen:\n            if ele is None:\n                res.append(None)\n\n            elif not is_string_like(ele) and is_generator_like(ele):\n                # Nested generator\n                res.append(self._make_nested_list(ele))\n\n            else:\n                res.append(ele)\n\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the position of 1st char after an assignment traget.", "response": "def _get_assignment_target_end(self, ast_module):\n        \"\"\"Returns position of 1st char after assignment traget.\n\n        If there is no assignment, -1 is returned\n\n        If there are more than one of any ( expressions or assigments)\n        then a ValueError is raised.\n\n        \"\"\"\n\n        if len(ast_module.body) > 1:\n            raise ValueError(\"More than one expression or assignment.\")\n\n        elif len(ast_module.body) > 0 and \\\n                type(ast_module.body[0]) is ast.Assign:\n            if len(ast_module.body[0].targets) != 1:\n                raise ValueError(\"More than one assignment target.\")\n            else:\n                return len(ast_module.body[0].targets[0].id)\n\n        return -1"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a copy of the environment with the magic variable name updated with the given dict.", "response": "def _get_updated_environment(self, env_dict=None):\n        \"\"\"Returns globals environment with 'magic' variable\n\n        Parameters\n        ----------\n        env_dict: Dict, defaults to {'S': self}\n        \\tDict that maps global variable name to value\n\n        \"\"\"\n\n        if env_dict is None:\n            env_dict = {'S': self}\n\n        env = globals().copy()\n        env.update(env_dict)\n\n        return env"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nevaluate one cell and returns its result", "response": "def _eval_cell(self, key, code):\n        \"\"\"Evaluates one cell and returns its result\"\"\"\n\n        # Flatten helper function\n        def nn(val):\n            \"\"\"Returns flat numpy arraz without None values\"\"\"\n            try:\n                return numpy.array(filter(None, val.flat))\n\n            except AttributeError:\n                # Probably no numpy array\n                return numpy.array(filter(None, val))\n\n        # Set up environment for evaluation\n\n        env_dict = {'X': key[0], 'Y': key[1], 'Z': key[2], 'bz2': bz2,\n                    'base64': base64, 'charts': charts, 'nn': nn,\n                    'R': key[0], 'C': key[1], 'T': key[2], 'S': self,\n                    'vlcpanel_factory': vlcpanel_factory}\n        env = self._get_updated_environment(env_dict=env_dict)\n\n        #_old_code = self(key)\n\n        # Return cell value if in safe mode\n\n        if self.safe_mode:\n            return code\n\n        # If cell is not present return None\n\n        if code is None:\n            return\n\n        elif is_generator_like(code):\n            # We have a generator object\n\n            return numpy.array(self._make_nested_list(code), dtype=\"O\")\n\n        # If only 1 term in front of the \"=\" --> global\n\n        try:\n            assignment_target_error = None\n            module = ast.parse(code)\n            assignment_target_end = self._get_assignment_target_end(module)\n\n        except ValueError, err:\n            assignment_target_error = ValueError(err)\n\n        except AttributeError, err:\n            # Attribute Error includes RunTimeError\n            assignment_target_error = AttributeError(err)\n\n        except Exception, err:\n            assignment_target_error = Exception(err)\n\n        if assignment_target_error is None and assignment_target_end != -1:\n            glob_var = code[:assignment_target_end]\n            expression = code.split(\"=\", 1)[1]\n            expression = expression.strip()\n\n            # Delete result cache because assignment changes results\n            self.result_cache.clear()\n\n        else:\n            glob_var = None\n            expression = code\n\n        if assignment_target_error is not None:\n            result = assignment_target_error\n\n        else:\n\n            try:\n                import signal\n\n                signal.signal(signal.SIGALRM, self.handler)\n                signal.alarm(config[\"timeout\"])\n\n            except:\n                # No POSIX system\n                pass\n\n            try:\n                result = eval(expression, env, {})\n\n            except AttributeError, err:\n                # Attribute Error includes RunTimeError\n                result = AttributeError(err)\n\n            except RuntimeError, err:\n                result = RuntimeError(err)\n\n            except Exception, err:\n                result = Exception(err)\n\n            finally:\n                try:\n                    signal.alarm(0)\n                except:\n                    # No POSIX system\n                    pass\n\n        # Change back cell value for evaluation from other cells\n        #self.dict_grid[key] = _old_code\n\n        if glob_var is not None:\n            globals().update({glob_var: result})\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pop(self, key):\n\n        try:\n            self.result_cache.pop(repr(key))\n\n        except KeyError:\n            pass\n\n        return DataArray.pop(self, key)", "response": "Pops dict_grid with undo and redo support\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef reload_modules(self):\n\n        import src.lib.charts as charts\n        from src.gui.grid_panels import vlcpanel_factory\n        modules = [charts, bz2, base64, re, ast, sys, wx, numpy, datetime]\n\n        for module in modules:\n            reload(module)", "response": "Reloads modules that are available in cells"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nclear all newly assigned globals", "response": "def clear_globals(self):\n        \"\"\"Clears all newly assigned globals\"\"\"\n\n        base_keys = ['cStringIO', 'IntType', 'KeyValueStore', 'undoable',\n                     'is_generator_like', 'is_string_like', 'bz2', 'base64',\n                     '__package__', 're', 'config', '__doc__', 'SliceType',\n                     'CellAttributes', 'product', 'ast', '__builtins__',\n                     '__file__', 'charts', 'sys', 'is_slice_like', '__name__',\n                     'copy', 'imap', 'wx', 'ifilter', 'Selection', 'DictGrid',\n                     'numpy', 'CodeArray', 'DataArray', 'datetime',\n                     'vlcpanel_factory']\n\n        for key in globals().keys():\n            if key not in base_keys:\n                globals().pop(key)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexecuting all macros and returns result string", "response": "def execute_macros(self):\n        \"\"\"Executes all macros and returns result string\n\n        Executes macros only when not in safe_mode\n\n        \"\"\"\n\n        if self.safe_mode:\n            return '', \"Safe mode activated. Code not executed.\"\n\n        # Windows exec does not like Windows newline\n        self.macros = self.macros.replace('\\r\\n', '\\n')\n\n        # Set up environment for evaluation\n        globals().update(self._get_updated_environment())\n\n        # Create file-like string to capture output\n        code_out = cStringIO.StringIO()\n        code_err = cStringIO.StringIO()\n        err_msg = cStringIO.StringIO()\n\n        # Capture output and errors\n        sys.stdout = code_out\n        sys.stderr = code_err\n\n        try:\n            import signal\n\n            signal.signal(signal.SIGALRM, self.handler)\n            signal.alarm(config[\"timeout\"])\n\n        except:\n            # No POSIX system\n            pass\n\n        try:\n            exec(self.macros, globals())\n            try:\n                signal.alarm(0)\n            except:\n                # No POSIX system\n                pass\n\n        except Exception:\n            # Print exception\n            # (Because of how the globals are handled during execution\n            # we must import modules here)\n            from traceback import print_exception\n            from src.lib.exception_handling import get_user_codeframe\n            exc_info = sys.exc_info()\n            user_tb = get_user_codeframe(exc_info[2]) or exc_info[2]\n            print_exception(exc_info[0], exc_info[1], user_tb, None, err_msg)\n        # Restore stdout and stderr\n        sys.stdout = sys.__stdout__\n        sys.stderr = sys.__stderr__\n\n        results = code_out.getvalue()\n        errs = code_err.getvalue() + err_msg.getvalue()\n\n        code_out.close()\n        code_err.close()\n\n        # Reset result cache\n        self.result_cache.clear()\n\n        # Reset frozen cache\n        self.frozen_cache.clear()\n\n        return results, errs"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _sorted_keys(self, keys, startkey, reverse=False):\n\n        tuple_key = lambda t: t[::-1]\n        if reverse:\n            tuple_cmp = lambda t: t[::-1] > startkey[::-1]\n        else:\n            tuple_cmp = lambda t: t[::-1] < startkey[::-1]\n\n        searchkeys = sorted(keys, key=tuple_key, reverse=reverse)\n        searchpos = sum(1 for _ in ifilter(tuple_cmp, searchkeys))\n\n        searchkeys = searchkeys[searchpos:] + searchkeys[:searchpos]\n\n        for key in searchkeys:\n            yield key", "response": "Generator that yields sorted keys starting with startkey"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the position of findstring in datastring or None if not found.", "response": "def string_match(self, datastring, findstring, flags=None):\n        \"\"\"\n        Returns position of findstring in datastring or None if not found.\n        Flags is a list of strings. Supported strings are:\n         * \"MATCH_CASE\": The case has to match for valid find\n         * \"WHOLE_WORD\": The word has to be surrounded by whitespace characters\n                         if in the middle of the string\n         * \"REG_EXP\":    A regular expression is evaluated.\n\n        \"\"\"\n\n        if type(datastring) is IntType:  # Empty cell\n            return None\n\n        if flags is None:\n            flags = []\n\n        if \"REG_EXP\" in flags:\n            match = re.search(findstring, datastring)\n            if match is None:\n                pos = -1\n            else:\n                pos = match.start()\n        else:\n            if \"MATCH_CASE\" not in flags:\n                datastring = datastring.lower()\n                findstring = findstring.lower()\n\n            if \"WHOLE_WORD\" in flags:\n                pos = -1\n                matchstring = r'\\b' + findstring + r'+\\b'\n                for match in re.finditer(matchstring, datastring):\n                    pos = match.start()\n                    break  # find 1st occurrance\n            else:\n                pos = datastring.find(findstring)\n\n        if pos == -1:\n            return None\n        else:\n            return pos"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a tuple with the position of the next match of find_string. Returns None if string not found.", "response": "def findnextmatch(self, startkey, find_string, flags, search_result=True):\n        \"\"\" Returns a tuple with the position of the next match of find_string\n\n        Returns None if string not found.\n\n        Parameters:\n        -----------\n        startkey:   Start position of search\n        find_string:String to be searched for\n        flags:      List of strings, out of\n                    [\"UP\" xor \"DOWN\", \"WHOLE_WORD\", \"MATCH_CASE\", \"REG_EXP\"]\n        search_result: Bool, defaults to True\n        \\tIf True then the search includes the result string (slower)\n\n        \"\"\"\n\n        assert \"UP\" in flags or \"DOWN\" in flags\n        assert not (\"UP\" in flags and \"DOWN\" in flags)\n\n        if search_result:\n            def is_matching(key, find_string, flags):\n                code = self(key)\n                if self.string_match(code, find_string, flags) is not None:\n                    return True\n                else:\n                    res_str = unicode(self[key])\n                    return self.string_match(res_str, find_string, flags) \\\n                        is not None\n\n        else:\n            def is_matching(code, find_string, flags):\n                code = self(key)\n                return self.string_match(code, find_string, flags) is not None\n\n        # List of keys in sgrid in search order\n\n        reverse = \"UP\" in flags\n\n        for key in self._sorted_keys(self.keys(), startkey, reverse=reverse):\n            try:\n                if is_matching(key, find_string, flags):\n                    return key\n\n            except Exception:\n                # re errors are cryptical: sre_constants,...\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if Value in digits False otherwise", "response": "def Validate(self, win):\n        \"\"\"Returns True if Value in digits, False otherwise\"\"\"\n\n        val = self.GetWindow().GetValue()\n\n        for x in val:\n            if x not in string.digits:\n                return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\neats event for a character event", "response": "def OnChar(self, event):\n        \"\"\"Eats event if key not in digits\"\"\"\n\n        key = event.GetKeyCode()\n\n        if key < wx.WXK_SPACE or key == wx.WXK_DELETE or key > 255 or \\\n           chr(key) in string.digits:\n            event.Skip()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef Draw(self, grid, attr, dc, rect, row, col, is_selected):\n\n        render = wx.RendererNative.Get()\n\n        # clear the background\n        dc.SetBackgroundMode(wx.SOLID)\n\n        if is_selected:\n            dc.SetBrush(wx.Brush(wx.BLUE, wx.SOLID))\n            dc.SetPen(wx.Pen(wx.BLUE, 1, wx.SOLID))\n        else:\n            dc.SetBrush(wx.Brush(wx.WHITE, wx.SOLID))\n            dc.SetPen(wx.Pen(wx.WHITE, 1, wx.SOLID))\n        dc.DrawRectangleRect(rect)\n\n        cb_lbl = grid.GetCellValue(row, col)\n        string_x = rect.x + 2\n        string_y = rect.y + 2\n        dc.DrawText(cb_lbl, string_x, string_y)\n\n        button_x = rect.x + rect.width - self.iconwidth\n        button_y = rect.y\n        button_width = self.iconwidth\n        button_height = rect.height\n        button_size = button_x, button_y, button_width, button_height\n        render.DrawComboBoxDropButton(grid, dc, button_size,\n                                      wx.CONTROL_CURRENT)", "response": "Draws the text and the combobox icon"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _setup_param_widgets(self):\n\n        for parameter in self.csv_params:\n            pname, ptype, plabel, phelp = parameter\n\n            label = wx.StaticText(self.parent, -1, plabel)\n            widget = self.type2widget[ptype](self.parent)\n\n            # Append choicebox items and bind handler\n            if pname in self.choices:\n                widget.AppendItems(self.choices[pname])\n                widget.SetValue = widget.Select\n                widget.SetSelection(0)\n\n            # Bind event handler to widget\n            if ptype is types.StringType or ptype is types.UnicodeType:\n                event_type = wx.EVT_TEXT\n            elif ptype is types.BooleanType:\n                event_type = wx.EVT_CHECKBOX\n            else:\n                event_type = wx.EVT_CHOICE\n\n            handler = getattr(self, self.widget_handlers[pname])\n            self.parent.Bind(event_type, handler, widget)\n\n            # Tool tips\n            label.SetToolTipString(phelp)\n            widget.SetToolTipString(phelp)\n\n            label.__name__ = wx.StaticText.__name__.lower()\n            widget.__name__ = self.type2widget[ptype].__name__.lower()\n\n            self.param_labels.append(label)\n            self.param_widgets.append(widget)\n\n            self.__setattr__(\"_\".join([label.__name__, pname]), label)\n            self.__setattr__(\"_\".join([widget.__name__, pname]), widget)", "response": "Creates the parameter entry widgets and binds them to methods"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _update_settings(self, dialect):\n\n        # the first parameter is the dialect itself --> ignore\n        for parameter in self.csv_params[2:]:\n            pname, ptype, plabel, phelp = parameter\n\n            widget = self._widget_from_p(pname, ptype)\n\n            if ptype is types.TupleType:\n                ptype = types.ObjectType\n\n            digest = Digest(acceptable_types=[ptype])\n\n            if pname == 'self.has_header':\n                if self.has_header is not None:\n                    widget.SetValue(digest(self.has_header))\n            else:\n                value = getattr(dialect, pname)\n                widget.SetValue(digest(value))", "response": "Updates the widget settings to those of the chosen dialect"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _widget_from_p(self, pname, ptype):\n\n        widget_name = self.type2widget[ptype].__name__.lower()\n        widget_name = \"_\".join([widget_name, pname])\n        return getattr(self, widget_name)", "response": "Returns a widget from its ptype and pname"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef OnDialectChoice(self, event):\n\n        dialect_name = event.GetString()\n        value = list(self.choices['dialects']).index(dialect_name)\n\n        if dialect_name == 'sniffer':\n            if self.csvfilepath is None:\n                event.Skip()\n                return None\n            dialect, self.has_header = sniff(self.csvfilepath)\n        elif dialect_name == 'user':\n            event.Skip()\n            return None\n        else:\n            dialect = csv.get_dialect(dialect_name)\n\n        self._update_settings(dialect)\n\n        self.choice_dialects.SetValue(value)", "response": "Updates all param widgets confirming to the selected dialect"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef OnWidget(self, event):\n\n        self.choice_dialects.SetValue(len(self.choices['dialects']) - 1)\n        event.Skip()", "response": "Update the dialect widget to user"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_dialect(self):\n\n        parameters = {}\n\n        for parameter in self.csv_params[2:]:\n            pname, ptype, plabel, phelp = parameter\n\n            widget = self._widget_from_p(pname, ptype)\n\n            if ptype is types.StringType or ptype is types.UnicodeType:\n                parameters[pname] = str(widget.GetValue())\n            elif ptype is types.BooleanType:\n                parameters[pname] = widget.GetValue()\n            elif pname == 'quoting':\n                choice = self.choices['quoting'][widget.GetSelection()]\n                parameters[pname] = getattr(csv, choice)\n            else:\n                raise TypeError(_(\"{type} unknown.\").format(type=ptype))\n\n        has_header = parameters.pop(\"self.has_header\")\n\n        try:\n            csv.register_dialect('user', **parameters)\n\n        except TypeError, err:\n            msg = _(\"The dialect is invalid. \\n \"\n                    \"\\nError message:\\n{msg}\").format(msg=err)\n            dlg = wx.MessageDialog(self.parent, msg, style=wx.ID_CANCEL)\n            dlg.ShowModal()\n            dlg.Destroy()\n            raise TypeError(err)\n\n        return csv.get_dialect('user'), has_header", "response": "Returns a new dialect that implements the current selection"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreduce clicks to enter an edit control", "response": "def OnMouse(self, event):\n        \"\"\"Reduces clicks to enter an edit control\"\"\"\n\n        self.SetGridCursor(event.Row, event.Col)\n        self.EnableCellEditControl(True)\n        event.Skip()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef OnGridEditorCreated(self, event):\n\n        editor = event.GetControl()\n        editor.Bind(wx.EVT_KILL_FOCUS, self.OnGridEditorClosed)\n\n        event.Skip()", "response": "Used to capture Editor open events"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fill_cells(self, dialect, has_header, choices=True):\n\n        # Get columns from csv\n        first_line = get_first_line(self.csvfilepath, dialect)\n        self.shape[1] = no_cols = len(first_line)\n\n        if no_cols > self.GetNumberCols():\n            missing_cols = no_cols - self.GetNumberCols()\n            self.AppendCols(missing_cols)\n\n        elif no_cols < self.GetNumberCols():\n            obsolete_cols = self.GetNumberCols() - no_cols\n            self.DeleteCols(pos=no_cols - 1, numCols=obsolete_cols)\n\n        # Retrieve type choices\n        digest_keys = self.get_digest_keys()\n\n        # Is a header present? --> Import as strings in first line\n        if has_header:\n            for i, header in enumerate(first_line):\n                self.SetCellValue(0, i, header)\n\n        if choices:\n            # Add Choices\n            for col in xrange(self.shape[1]):\n                choice_renderer = ChoiceRenderer(self)\n                choice_editor = wx.grid.GridCellChoiceEditor(\n                    self.digest_types.keys(), False)\n                self.SetCellRenderer(has_header, col, choice_renderer)\n                self.SetCellEditor(has_header, col, choice_editor)\n                self.SetCellValue(has_header, col, digest_keys[col])\n\n        # Fill in the rest of the lines\n\n        self.dtypes = []\n        for key in self.get_digest_keys():\n            try:\n                self.dtypes.append(self.digest_types[key])\n            except KeyError:\n                self.dtypes.append(types.NoneType)\n\n        topleft = (has_header + 1, 0)\n\n        digest_gen = csv_digest_gen(self.csvfilepath, dialect, has_header,\n                                    self.dtypes)\n\n        for row, col, val in cell_key_val_gen(digest_gen, self.shape, topleft):\n            self.SetCellValue(row, col, val)\n\n        self.Refresh()", "response": "Fills the grid with the contents of the CSV file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_digest_keys(self):\n\n        digest_keys = []\n        for col in xrange(self.GetNumberCols()):\n            digest_key = self.GetCellValue(self.has_header, col)\n            if digest_key == \"\":\n                digest_key = self.digest_types.keys()[0]\n            digest_keys.append(digest_key)\n\n        return digest_keys", "response": "Returns a list of the type choices"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfills the grid with the preview of the data", "response": "def fill(self, data, dialect):\n        \"\"\"Fills the grid for preview of csv data\n\n        Parameters\n        ----------\n        data: 2-dim array of strings\n        \\tData that is written to preview TextCtrl\n        dialect: csv,dialect\n        \\tDialect used for csv reader\n\n        \"\"\"\n\n        csvfile = cStringIO.StringIO()\n        csvwriter = csv.writer(csvfile, dialect=dialect)\n\n        for i, line in enumerate(data):\n            csvwriter.writerow(list(encode_gen(line)))\n            if i >= self.preview_lines:\n                break\n\n        preview = csvfile.getvalue()\n        csvfile.close()\n        preview = preview.decode(\"utf-8\").replace(\"\\r\\n\", \"\\n\")\n        self.SetValue(preview)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_properties(self):\n\n        title = _(\"CSV Import: {filepath}\").format(filepath=self.csvfilename)\n        self.SetTitle(title)\n        self.SetSize((600, 600))\n\n        for button in [self.button_cancel, self.button_ok]:\n            button.SetMinSize((80, 28))", "response": "Sets dialog title size limitations of the widgets"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_properties(self):\n\n        self.SetTitle(\"CSV Export\")\n        self.SetSize((600, 600))\n\n        for button in [self.button_cancel, self.button_apply, self.button_ok]:\n            button.SetMinSize((80, 28))", "response": "Sets dialog title size limitations of the widgets"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _do_layout(self):\n\n        sizer_dialog = wx.FlexGridSizer(3, 1, 0, 0)\n\n        # Sub sizers\n        sizer_buttons = wx.FlexGridSizer(1, 3, 5, 5)\n\n        # Adding buttons to sizer_buttons\n        for button in [self.button_cancel, self.button_apply, self.button_ok]:\n            sizer_buttons.Add(button, 0, wx.ALL | wx.EXPAND, 5)\n\n        sizer_buttons.AddGrowableRow(0)\n        for col in xrange(3):\n            sizer_buttons.AddGrowableCol(col)\n\n        # Adding main components\n        sizer_dialog.Add(self.csvwidgets.sizer_csvoptions,\n                         0, wx.ALL | wx.EXPAND, 5)\n        sizer_dialog.Add(self.preview_textctrl,  1, wx.ALL | wx.EXPAND, 0)\n        sizer_dialog.Add(sizer_buttons,  0, wx.ALL | wx.EXPAND, 5)\n\n        self.SetSizer(sizer_dialog)\n\n        sizer_dialog.AddGrowableRow(1)\n        sizer_dialog.AddGrowableCol(0)\n\n        self.Layout()\n        self.Centre()", "response": "Layout the log file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the preview_textctrl with the data", "response": "def OnButtonApply(self, event):\n        \"\"\"Updates the preview_textctrl\"\"\"\n\n        try:\n            dialect, self.has_header = self.csvwidgets.get_dialect()\n        except TypeError:\n            event.Skip()\n            return 0\n\n        self.preview_textctrl.fill(data=self.data, dialect=dialect)\n\n        event.Skip()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _do_layout(self):\n\n        dialog_main_sizer = wx.BoxSizer(wx.HORIZONTAL)\n        upper_sizer = wx.BoxSizer(wx.HORIZONTAL)\n        lower_sizer = wx.FlexGridSizer(2, 1, 5, 0)\n        lower_sizer.AddGrowableRow(0)\n        lower_sizer.AddGrowableCol(0)\n        button_sizer = wx.BoxSizer(wx.HORIZONTAL)\n\n        upper_sizer.Add(self.codetext_ctrl, 1, wx.EXPAND, 0)\n        lower_sizer.Add(self.result_ctrl, 1, wx.EXPAND, 0)\n        lower_sizer.Add(button_sizer, 1, wx.EXPAND, 0)\n        button_sizer.Add(self.apply_button, 1, wx.EXPAND, 0)\n\n        self.upper_panel.SetSizer(upper_sizer)\n        self.lower_panel.SetSizer(lower_sizer)\n        sash_50 = int(round((config[\"window_size\"][1] - 100) * 0.5))\n\n        self.splitter.SplitHorizontally(self.upper_panel,\n                                        self.lower_panel, sash_50)\n        dialog_main_sizer.Add(self.splitter, 1, wx.EXPAND, 0)\n        self.SetSizer(dialog_main_sizer)\n        self.Layout()", "response": "Layouts the log file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_properties(self):\n\n        self.codetext_ctrl.SetToolTipString(_(\"Enter python code here.\"))\n        self.apply_button.SetToolTipString(_(\"Apply changes to current macro\"))\n        self.splitter.SetBackgroundStyle(wx.BG_STYLE_COLOUR)\n        self.result_ctrl.SetMinSize((10, 10))", "response": "Setup title size and tooltips"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef OnApply(self, event):\n\n        # See if we have valid python\n        try:\n            ast.parse(self.macros)\n        except:\n            # Grab the traceback and print it for the user\n            s = StringIO()\n            e = exc_info()\n            # usr_tb will more than likely be none because ast throws\n            #   SytnaxErrorsas occurring outside of the current\n            #   execution frame\n            usr_tb = get_user_codeframe(e[2]) or None\n            print_exception(e[0], e[1], usr_tb, None, s)\n            post_command_event(self.parent, self.MacroErrorMsg,\n                               err=s.getvalue())\n            success = False\n        else:\n            self.result_ctrl.SetValue('')\n            post_command_event(self.parent, self.MacroReplaceMsg,\n                               macros=self.macros)\n            post_command_event(self.parent, self.MacroExecuteMsg)\n            success = True\n\n        event.Skip()\n        return success", "response": "Event handler for Apply button"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_result_ctrl(self, event):\n\n        # Check to see if macro window still exists\n        if not self:\n            return\n\n        printLen = 0\n        self.result_ctrl.SetValue('')\n        if hasattr(event, 'msg'):\n            # Output of script (from print statements, for example)\n            self.result_ctrl.AppendText(event.msg)\n            printLen = len(event.msg)\n        if hasattr(event, 'err'):\n            # Error messages\n            errLen = len(event.err)\n            errStyle = wx.TextAttr(wx.RED)\n            self.result_ctrl.AppendText(event.err)\n            self.result_ctrl.SetStyle(printLen, printLen+errLen, errStyle)\n\n        if not hasattr(event, 'err') or event.err == '':\n            # No error passed.  Close dialog if user requested it.\n            if self._ok_pressed:\n                self.Destroy()\n        self._ok_pressed = False", "response": "Update event result following execution by main window"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting valuestring to int and assigns result to self. dim", "response": "def _ondim(self, dimension, valuestring):\n        \"\"\"Converts valuestring to int and assigns result to self.dim\n\n        If there is an error (such as an empty valuestring) or if\n        the value is < 1, the value 1 is assigned to self.dim\n\n        Parameters\n        ----------\n\n        dimension: int\n        \\tDimension that is to be updated. Must be in [1:4]\n        valuestring: string\n        \\t A string that can be converted to an int\n\n        \"\"\"\n\n        try:\n            self.dimensions[dimension] = int(valuestring)\n        except ValueError:\n            self.dimensions[dimension] = 1\n            self.textctrls[dimension].SetValue(str(1))\n\n        if self.dimensions[dimension] < 1:\n            self.dimensions[dimension] = 1\n            self.textctrls[dimension].SetValue(str(1))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nposts a command event that makes the grid show the entered cell", "response": "def OnOk(self, event):\n        \"\"\"Posts a command event that makes the grid show the entered cell\"\"\"\n\n        # Get key values from textctrls\n\n        key_strings = [self.row_textctrl.GetValue(),\n                       self.col_textctrl.GetValue(),\n                       self.tab_textctrl.GetValue()]\n\n        key = []\n\n        for key_string in key_strings:\n            try:\n                key.append(int(key_string))\n            except ValueError:\n                key.append(0)\n\n        # Post event\n\n        post_command_event(self.parent, self.GotoCellMsg, key=tuple(key))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn maximum dimensionality over which obj is iterable < = 2", "response": "def get_max_dim(self, obj):\n        \"\"\"Returns maximum dimensionality over which obj is iterable <= 2\"\"\"\n\n        try:\n            iter(obj)\n\n        except TypeError:\n            return 0\n\n        try:\n            for o in obj:\n                iter(o)\n                break\n\n        except TypeError:\n            return 1\n\n        return 2"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef query(self, req, timeout=None, metadata=None, credentials=None):\n        return self.stub.Query(req, timeout=timeout, metadata=metadata,\n                               credentials=credentials)", "response": "Runs a query operation."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mutate(self, mutation, timeout=None, metadata=None, credentials=None):\n        return self.stub.Mutate(mutation, timeout=timeout, metadata=metadata,\n                                credentials=credentials)", "response": "Runs a mutation operation."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrun commit or abort operation.", "response": "def commit_or_abort(self, ctx, timeout=None, metadata=None,\n                        credentials=None):\n        \"\"\"Runs commit or abort operation.\"\"\"\n        return self.stub.CommitOrAbort(ctx, timeout=timeout, metadata=metadata,\n                                       credentials=credentials)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the version of the Dgraph instance.", "response": "def check_version(self, check, timeout=None, metadata=None,\n                      credentials=None):\n        \"\"\"Returns the version of the Dgraph instance.\"\"\"\n        return self.stub.CheckVersion(check, timeout=timeout,\n                                      metadata=metadata,\n                                      credentials=credentials)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef alter(self, operation, timeout=None, metadata=None, credentials=None):\n        new_metadata = self.add_login_metadata(metadata)\n\n        try:\n            return self.any_client().alter(operation, timeout=timeout,\n                                           metadata=new_metadata,\n                                           credentials=credentials)\n        except Exception as error:\n            if util.is_jwt_expired(error):\n                self.retry_login()\n                new_metadata = self.add_login_metadata(metadata)\n                return self.any_client().alter(operation, timeout=timeout,\n                                               metadata=new_metadata,\n                                               credentials=credentials)\n            else:\n                raise error", "response": "Runs a modification via this client."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a query operation to the transaction.", "response": "def query(self, query, variables=None, timeout=None, metadata=None,\n              credentials=None):\n        \"\"\"Adds a query operation to the transaction.\"\"\"\n        new_metadata = self._dg.add_login_metadata(metadata)\n        req = self._common_query(query, variables=variables)\n        try:\n            res = self._dc.query(req, timeout=timeout,\n                                 metadata=new_metadata,\n                                 credentials=credentials)\n        except Exception as error:\n            if util.is_jwt_expired(error):\n                self._dg.retry_login()\n                new_metadata = self._dg.add_login_metadata(metadata)\n                res = self._dc.query(req, timeout=timeout,\n                                     metadata=new_metadata,\n                                     credentials=credentials)\n            else:\n                raise error\n\n        self.merge_context(res.txn)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mutate(self, mutation=None, set_obj=None, del_obj=None, set_nquads=None,\n               del_nquads=None, commit_now=None, ignore_index_conflict=None,\n               timeout=None, metadata=None, credentials=None):\n        \"\"\"Adds a mutate operation to the transaction.\"\"\"\n        mutation = self._common_mutate(\n            mutation=mutation, set_obj=set_obj, del_obj=del_obj,\n            set_nquads=set_nquads, del_nquads=del_nquads,\n            commit_now=commit_now, ignore_index_conflict=ignore_index_conflict)\n\n        new_metadata = self._dg.add_login_metadata(metadata)\n        mutate_error = None\n\n        try:\n            assigned = self._dc.mutate(mutation, timeout=timeout,\n                                       metadata=new_metadata,\n                                       credentials=credentials)\n        except Exception as error:\n            if util.is_jwt_expired(error):\n                self._dg.retry_login()\n                new_metadata = self._dg.add_login_metadata(metadata)\n                try:\n                    assigned = self._dc.mutate(mutation, timeout=timeout,\n                                               metadata=new_metadata,\n                                               credentials=credentials)\n                except Exception as error:\n                    mutate_error = error\n            else:\n                mutate_error = error\n\n        if mutate_error is not None:\n            try:\n                self.discard(timeout=timeout, metadata=metadata,\n                             credentials=credentials)\n            except:\n                # Ignore error - user should see the original error.\n                pass\n\n            self._common_except_mutate(mutate_error)\n\n        if mutation.commit_now:\n            self._finished = True\n\n        self.merge_context(assigned.context)\n        return assigned", "response": "Adds a mutate operation to the transaction."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmerges context from this instance with src.", "response": "def merge_context(self, src=None):\n        \"\"\"Merges context from this instance with src.\"\"\"\n        if src is None:\n            # This condition will be true only if the server doesn't return a\n            # txn context after a query or mutation.\n            return\n\n        if self._ctx.start_ts == 0:\n            self._ctx.start_ts = src.start_ts\n        elif self._ctx.start_ts != src.start_ts:\n            # This condition should never be true.\n            raise Exception('StartTs mismatch')\n\n        self._ctx.keys.extend(src.keys)\n        self._ctx.preds.extend(src.preds)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the token generator class based on the configuration in DJANGO_REST_PASSWORDRESET_TOKEN_CONFIG. CLASS and DJANGO_REST_PASSWORDRESET_TOKEN_CONFIG. OPTIONS.", "response": "def get_token_generator():\n    \"\"\"\n    Returns the token generator class based on the configuration in DJANGO_REST_PASSWORDRESET_TOKEN_CONFIG.CLASS and\n    DJANGO_REST_PASSWORDRESET_TOKEN_CONFIG.OPTIONS\n    :return:\n    \"\"\"\n    # by default, we are using the String Token Generator\n    token_class = RandomStringTokenGenerator\n    options = {}\n\n    # get the settings object\n    DJANGO_REST_PASSWORDRESET_TOKEN_CONFIG = getattr(settings, 'DJANGO_REST_PASSWORDRESET_TOKEN_CONFIG', None)\n\n    # check if something is in the settings object, and work with it\n    if DJANGO_REST_PASSWORDRESET_TOKEN_CONFIG:\n        if \"CLASS\" in DJANGO_REST_PASSWORDRESET_TOKEN_CONFIG:\n            class_path_name = DJANGO_REST_PASSWORDRESET_TOKEN_CONFIG[\"CLASS\"]\n            module_name, class_name = class_path_name.rsplit('.', 1)\n\n            mod = import_module(module_name)\n            token_class = getattr(mod, class_name)\n\n        if \"OPTIONS\" in DJANGO_REST_PASSWORDRESET_TOKEN_CONFIG:\n            options = DJANGO_REST_PASSWORDRESET_TOKEN_CONFIG[\"OPTIONS\"]\n\n    # initialize the token class and pass options\n    return token_class(**options)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate_token(self, *args, **kwargs):\n        # determine the length based on min_length and max_length\n        length = random.randint(self.min_length, self.max_length)\n\n        # generate the token using os.urandom and hexlify\n        return binascii.hexlify(\n            os.urandom(self.max_length)\n        ).decode()[0:length]", "response": "generates a pseudo random token using os. urandom and binascii. hexlify"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntrying to emit whatever text is in the node.", "response": "def get_text(self, node):\n        \"\"\"Try to emit whatever text is in the node.\"\"\"\n        try:\n            return node.children[0].content or \"\"\n        except (AttributeError, IndexError):\n            return node.content or \"\""}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nemit all the children of a node.", "response": "def emit_children(self, node):\n        \"\"\"Emit all the children of a node.\"\"\"\n        return \"\".join([self.emit_node(child) for child in node.children])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef emit_node(self, node):\n        emit = getattr(self, \"%s_emit\" % node.kind, self.default_emit)\n        return emit(node)", "response": "Emit a single node."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_system_lock(cls, redis, name, timeout):\n\n        pipeline = redis.pipeline()\n        pipeline.zadd(name, SYSTEM_LOCK_ID, time.time() + timeout)\n        pipeline.expire(name, timeout + 10)  # timeout plus buffer for troubleshooting\n        pipeline.execute()", "response": "Sets a system lock for the semaphore."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef acquire(self):\n\n        acquired, locks = self._semaphore(keys=[self.name],\n                                          args=[self.lock_id, self.max_locks,\n                                                self.timeout, time.time()])\n\n        # Convert Lua boolean returns to Python booleans\n        acquired = True if acquired == 1 else False\n\n        return acquired, locks", "response": "Obtain a semaphore lock. Returns True if the lock was acquired False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nacquire a shared distributed lock.", "response": "def acquire(self, blocking=True):\n        \"\"\"\n        Use Redis to hold a shared, distributed lock named ``name``.\n        Returns True once the lock is acquired.\n\n        If ``blocking`` is False, always return immediately. If the lock\n        was acquired, return True, otherwise return False.\n        \"\"\"\n        sleep = self.sleep\n        timeout = self.timeout\n        while 1:\n            unixtime = time.time()\n            if timeout:\n                timeout_at = unixtime + timeout\n            else:\n                timeout_at = Lock.LOCK_FOREVER\n            timeout_at = float(timeout_at)\n            if self.redis.setnx(self.name, timeout_at):\n                self.acquired_until = timeout_at\n                return True\n            # We want blocking, but didn't acquire the lock\n            # check to see if the current lock is expired\n            try:\n                existing = float(self.redis.get(self.name) or 1)\n            except ValueError:\n                existing = Lock.LOCK_FOREVER\n\n            if existing < unixtime:\n                # the previous lock is expired, attempt to overwrite it\n                try:\n                    existing = float(self.redis.getset(self.name, timeout_at) or 1)\n                except ValueError:\n                    existing = Lock.LOCK_FOREVER\n                if existing < unixtime:\n                    # we successfully acquired the lock\n                    self.acquired_until = timeout_at\n                    return True\n            if not blocking:\n                return False\n            time.sleep(sleep)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef release(self):\n        \"Releases the already acquired lock\"\n        if self.acquired_until is None:\n            raise ValueError(\"Cannot release an unlocked lock\")\n        existing = float(self.redis.get(self.name) or 1)\n        # if the lock time is in the future, delete the lock\n        if existing >= self.acquired_until:\n            self.redis.delete(self.name)\n        self.acquired_until = None", "response": "Releases the already acquired lock"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef renew(self, new_timeout):\n        if self.local.token is None:\n            raise LockError(\"Cannot extend an unlocked lock\")\n        if self.timeout is None:\n            raise LockError(\"Cannot extend a lock with no timeout\")\n        return self.do_renew(new_timeout)", "response": "Sets a new timeout for an already acquired lock.\n\n        ``new_timeout`` can be specified as an integer or a float, both\n        representing the number of seconds."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfunction decorator that defines the behavior of the function when it is used as a task. To use the default behavior, tasks don't need to be decorated. See README.rst for an explanation of the options.", "response": "def task(self, _fn=None, queue=None, hard_timeout=None, unique=None,\n             lock=None, lock_key=None, retry=None, retry_on=None,\n             retry_method=None, schedule=None, batch=False,\n             max_queue_size=None):\n        \"\"\"\n        Function decorator that defines the behavior of the function when it is\n        used as a task. To use the default behavior, tasks don't need to be\n        decorated.\n\n        See README.rst for an explanation of the options.\n        \"\"\"\n\n        def _delay(func):\n            def _delay_inner(*args, **kwargs):\n                return self.delay(func, args=args, kwargs=kwargs)\n            return _delay_inner\n\n        # Periodic tasks are unique.\n        if schedule is not None:\n            unique = True\n\n        def _wrap(func):\n            if hard_timeout is not None:\n                func._task_hard_timeout = hard_timeout\n            if queue is not None:\n                func._task_queue = queue\n            if unique is not None:\n                func._task_unique = unique\n            if lock is not None:\n                func._task_lock = lock\n            if lock_key is not None:\n                func._task_lock_key = lock_key\n            if retry is not None:\n                func._task_retry = retry\n            if retry_on is not None:\n                func._task_retry_on = retry_on\n            if retry_method is not None:\n                func._task_retry_method = retry_method\n            if batch is not None:\n                func._task_batch = batch\n            if schedule is not None:\n                func._task_schedule = schedule\n            if max_queue_size is not None:\n                func._task_max_queue_size = max_queue_size\n\n            func.delay = _delay(func)\n\n            if schedule is not None:\n                serialized_func = serialize_func_name(func)\n                assert serialized_func not in self.periodic_task_funcs, \\\n                    \"attempted duplicate registration of periodic task\"\n                self.periodic_task_funcs[serialized_func] = func\n\n            return func\n\n        return _wrap if _fn is None else _wrap(_fn)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nqueues a task. See README.rst for an explanation of the options.", "response": "def delay(self, func, args=None, kwargs=None, queue=None,\n              hard_timeout=None, unique=None, lock=None, lock_key=None,\n              when=None, retry=None, retry_on=None, retry_method=None,\n              max_queue_size=None):\n        \"\"\"\n        Queues a task. See README.rst for an explanation of the options.\n        \"\"\"\n\n        task = Task(self, func, args=args, kwargs=kwargs, queue=queue,\n                    hard_timeout=hard_timeout, unique=unique,\n                    lock=lock, lock_key=lock_key,\n                    retry=retry, retry_on=retry_on, retry_method=retry_method)\n\n        task.delay(when=when, max_queue_size=max_queue_size)\n\n        return task"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the number of tasks in each state. Returns a dict with the state of each state and the queue s size for the QUEUED SCHEDULED and ACTIVE structures.", "response": "def get_queue_sizes(self, queue):\n        \"\"\"\n        Get the queue's number of tasks in each state.\n\n        Returns dict with queue size for the QUEUED, SCHEDULED, and ACTIVE\n        states. Does not include size of error queue.\n        \"\"\"\n\n        states = [QUEUED, SCHEDULED, ACTIVE]\n        pipeline = self.connection.pipeline()\n        for state in states:\n            pipeline.zcard(self._key(state, queue))\n        results = pipeline.execute()\n        return dict(zip(states, results))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the system lock timeout for a queue", "response": "def get_queue_system_lock(self, queue):\n        \"\"\"\n        Get system lock timeout\n\n        Returns time system lock expires or None if lock does not exist\n        \"\"\"\n\n        key = self._key(LOCK_REDIS_KEY, queue)\n        return Semaphore.get_system_lock(self.connection, key)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_queue_system_lock(self, queue, timeout):\n\n        key = self._key(LOCK_REDIS_KEY, queue)\n        Semaphore.set_system_lock(self.connection, key, timeout)", "response": "Set the system lock on a queue."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_queue_stats(self):\n\n        states = (QUEUED, ACTIVE, SCHEDULED, ERROR)\n\n        pipeline = self.connection.pipeline()\n        for state in states:\n            pipeline.smembers(self._key(state))\n        queue_results = pipeline.execute()\n\n        pipeline = self.connection.pipeline()\n        for state, result in zip(states, queue_results):\n            for queue in result:\n                pipeline.zcard(self._key(state, queue))\n        card_results = pipeline.execute()\n\n        queue_stats = defaultdict(dict)\n        for state, result in zip(states, queue_results):\n            for queue in result:\n                queue_stats[queue][state] = card_results.pop(0)\n\n        return queue_stats", "response": "Returns a dictionary with stats about all the queues."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninstalls signal handlers for safely stopping the worker.", "response": "def _install_signal_handlers(self):\n        \"\"\"\n        Sets up signal handlers for safely stopping the worker.\n        \"\"\"\n        def request_stop(signum, frame):\n            self._stop_requested = True\n            self.log.info('stop requested, waiting for task to finish')\n        signal.signal(signal.SIGINT, request_stop)\n        signal.signal(signal.SIGTERM, request_stop)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _uninstall_signal_handlers(self):\n        signal.signal(signal.SIGINT, signal.SIG_DFL)\n        signal.signal(signal.SIGTERM, signal.SIG_DFL)", "response": "Uninstalls default signal handlers."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _filter_queues(self, queues):\n\n        def match(queue):\n            \"\"\"\n            Returns whether the given queue should be included by checking each\n            part of the queue name.\n            \"\"\"\n            for part in reversed_dotted_parts(queue):\n                if part in self.exclude_queues:\n                    return False\n                if part in self.only_queues:\n                    return True\n            return not self.only_queues\n\n        return [q for q in queues if match(q)]", "response": "Applies the filter to the given list of queues and returns the list of queues that match."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _wait_for_new_tasks(self, timeout=0, batch_timeout=0):\n\n        new_queue_found = False\n        start_time = batch_exit = time.time()\n        while True:\n            # Check to see if batch_exit has been updated\n            if batch_exit > start_time:\n                pubsub_sleep = batch_exit - time.time()\n            else:\n                pubsub_sleep = start_time + timeout - time.time()\n            message = self._pubsub.get_message(timeout=0 if pubsub_sleep < 0 or\n                                               self._did_work\n                                               else pubsub_sleep)\n\n            # Pull remaining messages off of channel\n            while message:\n                if message['type'] == 'message':\n                    new_queue_found, batch_exit = self._process_queue_message(\n                        message['data'], new_queue_found, batch_exit,\n                        start_time, timeout, batch_timeout\n                    )\n\n                message = self._pubsub.get_message()\n\n            if self._did_work:\n                break   # Exit immediately if we did work during the last\n                        # execution loop because there might be more work to do\n            elif time.time() >= batch_exit and new_queue_found:\n                break   # After finding a new queue we can wait until the\n                        # batch timeout expires\n            elif time.time() - start_time > timeout:\n                break", "response": "This method will check activity channel and wait as necessary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _worker_queue_expired_tasks(self):\n\n        # Note that we use the lock both to unnecessarily prevent multiple\n        # workers from requeueing expired tasks, as well as to space out\n        # this task (i.e. we don't release the lock unless we've exhausted our\n        # batch size, which will hopefully never happen)\n        lock = Lock(self.connection, self._key('lock', 'queue_expired_tasks'),\n                    timeout=self.config['REQUEUE_EXPIRED_TASKS_INTERVAL'])\n\n        acquired = lock.acquire(blocking=False)\n        if not acquired:\n            return\n\n        now = time.time()\n\n        # Get a batch of expired tasks.\n        task_data = self.scripts.get_expired_tasks(\n            self.config['REDIS_PREFIX'],\n            now - self.config['ACTIVE_TASK_UPDATE_TIMEOUT'],\n            self.config['REQUEUE_EXPIRED_TASKS_BATCH_SIZE']\n        )\n\n        for (queue, task_id) in task_data:\n            self.log.debug('expiring task', queue=queue, task_id=task_id)\n            self._did_work = True\n            try:\n                task = Task.from_id(self.tiger, queue, ACTIVE, task_id)\n                if task.should_retry_on(JobTimeoutException, logger=self.log):\n                    self.log.info('queueing expired task',\n                                  queue=queue, task_id=task_id)\n\n                    # Task is idempotent and can be requeued. If the task\n                    # already exists in the QUEUED queue, don't change its\n                    # time.\n                    task._move(from_state=ACTIVE,\n                               to_state=QUEUED,\n                               when=now,\n                               mode='nx')\n                else:\n                    self.log.error('failing expired task',\n                                   queue=queue, task_id=task_id)\n\n                    # Assume the task can't be retried and move it to the error\n                    # queue.\n                    task._move(from_state=ACTIVE, to_state=ERROR, when=now)\n            except TaskNotFound:\n                # Either the task was requeued by another worker, or we\n                # have a task without a task object.\n\n                # XXX: Ideally, the following block should be atomic.\n                if not self.connection.get(self._key('task', task_id)):\n                    self.log.error('not found', queue=queue, task_id=task_id)\n                    task = Task(self.tiger, queue=queue,\n                                _data={'id': task_id}, _state=ACTIVE)\n                    task._move()\n\n        # Release the lock immediately if we processed a full batch. This way,\n        # another process will be able to pick up another batch immediately\n        # without waiting for the lock to time out.\n        if len(task_data) == self.config['REQUEUE_EXPIRED_TASKS_BATCH_SIZE']:\n            lock.release()", "response": "This method takes expired tasks from the queue and puts them into the QUEUED queue."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _execute_forked(self, tasks, log):\n        success = False\n\n        execution = {}\n\n        assert len(tasks)\n        task_func = tasks[0].serialized_func\n        assert all([task_func == task.serialized_func for task in tasks[1:]])\n\n        execution['time_started'] = time.time()\n\n        exc = None\n        exc_info = None\n\n        try:\n            func = tasks[0].func\n\n            is_batch_func = getattr(func, '_task_batch', False)\n            g['current_task_is_batch'] = is_batch_func\n\n            if is_batch_func:\n                # Batch process if the task supports it.\n                params = [{\n                    'args': task.args,\n                    'kwargs': task.kwargs,\n                } for task in tasks]\n                task_timeouts = [task.hard_timeout for task in tasks if task.hard_timeout is not None]\n                hard_timeout = ((max(task_timeouts) if task_timeouts else None)\n                                or\n                                getattr(func, '_task_hard_timeout', None) or\n                                self.config['DEFAULT_HARD_TIMEOUT'])\n\n                g['current_tasks'] = tasks\n                with UnixSignalDeathPenalty(hard_timeout):\n                    func(params)\n\n            else:\n                # Process sequentially.\n                for task in tasks:\n                    hard_timeout = (task.hard_timeout or\n                                    getattr(func, '_task_hard_timeout', None) or\n                                    self.config['DEFAULT_HARD_TIMEOUT'])\n\n                    g['current_tasks'] = [task]\n                    with UnixSignalDeathPenalty(hard_timeout):\n                        func(*task.args, **task.kwargs)\n\n        except RetryException as exc:\n            execution['retry'] = True\n            if exc.method:\n                execution['retry_method'] = serialize_retry_method(exc.method)\n            execution['log_error'] = exc.log_error\n            execution['exception_name'] = serialize_func_name(exc.__class__)\n            exc_info = exc.exc_info or sys.exc_info()\n        except (JobTimeoutException, Exception) as exc:\n            execution['exception_name'] = serialize_func_name(exc.__class__)\n            exc_info = sys.exc_info()\n        else:\n            success = True\n\n        if not success:\n            execution['time_failed'] = time.time()\n            if self.store_tracebacks:\n                # Currently we only log failed task executions to Redis.\n                execution['traceback'] = \\\n                        ''.join(traceback.format_exception(*exc_info))\n            execution['success'] = success\n            execution['host'] = socket.gethostname()\n            serialized_execution = json.dumps(execution)\n            for task in tasks:\n                self.connection.rpush(self._key('task', task.id, 'executions'),\n                                      serialized_execution)\n\n        return success", "response": "Executes the tasks in the forked process."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_queue_batch_size(self, queue):\n\n        # Fetch one item unless this is a batch queue.\n        # XXX: It would be more efficient to loop in reverse order and break.\n        batch_queues = self.config['BATCH_QUEUES']\n        batch_size = 1\n        for part in dotted_parts(queue):\n            if part in batch_queues:\n                batch_size = batch_queues[part]\n\n        return batch_size", "response": "Get queue batch size."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_queue_lock(self, queue, log):\n        max_workers = self.max_workers_per_queue\n\n        # Check if this is single worker queue\n        for part in dotted_parts(queue):\n            if part in self.single_worker_queues:\n                log.debug('single worker queue')\n                max_workers = 1\n                break\n\n        # Max worker queues require us to get a queue lock before\n        # moving tasks\n        if max_workers:\n            queue_lock = Semaphore(self.connection,\n                                   self._key(LOCK_REDIS_KEY, queue),\n                                   self.id, max_locks=max_workers,\n                                   timeout=self.config['ACTIVE_TASK_UPDATE_TIMEOUT'])\n            acquired, locks = queue_lock.acquire()\n            if not acquired:\n                return None, True\n            log.debug('acquired queue lock', locks=locks)\n        else:\n            queue_lock = None\n\n        return queue_lock, False", "response": "Get the queue lock for max worker queues."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the heartbeat for the given task IDs.", "response": "def _heartbeat(self, queue, task_ids):\n        \"\"\"\n        Updates the heartbeat for the given task IDs to prevent them from\n        timing out and being requeued.\n        \"\"\"\n        now = time.time()\n        self.connection.zadd(self._key(ACTIVE, queue),\n                             **{task_id: now for task_id in task_ids})"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexecuting the given tasks.", "response": "def _execute(self, queue, tasks, log, locks, queue_lock, all_task_ids):\n        \"\"\"\n        Executes the given tasks. Returns a boolean indicating whether\n        the tasks were executed successfully.\n        \"\"\"\n\n        # The tasks must use the same function.\n        assert len(tasks)\n        task_func = tasks[0].serialized_func\n        assert all([task_func == task.serialized_func for task in tasks[1:]])\n\n        # Before executing periodic tasks, queue them for the next period.\n        if task_func in self.tiger.periodic_task_funcs:\n            tasks[0]._queue_for_next_period()\n\n        with g_fork_lock:\n            child_pid = os.fork()\n\n        if child_pid == 0:\n            # Child process\n            log = log.bind(child_pid=os.getpid())\n\n            # Disconnect the Redis connection inherited from the main process.\n            # Note that this doesn't disconnect the socket in the main process.\n            self.connection.connection_pool.disconnect()\n\n            random.seed()\n\n            # Ignore Ctrl+C in the child so we don't abort the job -- the main\n            # process already takes care of a graceful shutdown.\n            signal.signal(signal.SIGINT, signal.SIG_IGN)\n\n            with WorkerContextManagerStack(self.config['CHILD_CONTEXT_MANAGERS']):\n                success = self._execute_forked(tasks, log)\n\n            # Wait for any threads that might be running in the child, just\n            # like sys.exit() would. Note we don't call sys.exit() directly\n            # because it would perform additional cleanup (e.g. calling atexit\n            # handlers twice). See also: https://bugs.python.org/issue18966\n            threading._shutdown()\n\n            os._exit(int(not success))\n        else:\n            # Main process\n            log = log.bind(child_pid=child_pid)\n            for task in tasks:\n                log.info('processing', func=task_func, task_id=task.id,\n                         params={'args': task.args, 'kwargs': task.kwargs})\n\n            # Attach a signal handler to SIGCHLD (sent when the child process\n            # exits) so we can capture it.\n            signal.signal(signal.SIGCHLD, sigchld_handler)\n\n            # Since newer Python versions retry interrupted system calls we can't\n            # rely on the fact that select() is interrupted with EINTR. Instead,\n            # we'll set up a wake-up file descriptor below.\n\n            # Create a new pipe and apply the non-blocking flag (required for\n            # set_wakeup_fd).\n            pipe_r, pipe_w = os.pipe()\n            flags = fcntl.fcntl(pipe_w, fcntl.F_GETFL, 0)\n            flags = flags | os.O_NONBLOCK\n            fcntl.fcntl(pipe_w, fcntl.F_SETFL, flags)\n\n            # A byte will be written to pipe_w if a signal occurs (and can be\n            # read from pipe_r).\n            old_wakeup_fd = signal.set_wakeup_fd(pipe_w)\n\n            def check_child_exit():\n                \"\"\"\n                Do a non-blocking check to see if the child process exited.\n                Returns None if the process is still running, or the exit code\n                value of the child process.\n                \"\"\"\n                try:\n                    pid, return_code = os.waitpid(child_pid, os.WNOHANG)\n                    if pid != 0: # The child process is done.\n                        return return_code\n                except OSError as e:\n                    # Of course EINTR can happen if the child process exits\n                    # while we're checking whether it exited. In this case it\n                    # should be safe to retry.\n                    if e.errno == errno.EINTR:\n                        return check_child_exit()\n                    else:\n                        raise\n\n            # Wait for the child to exit and perform a periodic heartbeat.\n            # We check for the child twice in this loop so that we avoid\n            # unnecessary waiting if the child exited just before entering\n            # the while loop or while renewing heartbeat/locks.\n            while True:\n                return_code = check_child_exit()\n                if return_code is not None:\n                    break\n\n                # Wait until the timeout or a signal / child exit occurs.\n                try:\n                    select.select([pipe_r], [], [],\n                                  self.config['ACTIVE_TASK_UPDATE_TIMER'])\n                except select.error as e:\n                    if e.args[0] != errno.EINTR:\n                        raise\n\n                return_code = check_child_exit()\n                if return_code is not None:\n                    break\n\n                try:\n                    self._heartbeat(queue, all_task_ids)\n                    for lock in locks:\n                        lock.renew(self.config['ACTIVE_TASK_UPDATE_TIMEOUT'])\n                    if queue_lock:\n                        acquired, current_locks = queue_lock.renew()\n                        if not acquired:\n                            log.debug('queue lock renew failure')\n                except OSError as e:\n                    # EINTR happens if the task completed. Since we're just\n                    # renewing locks/heartbeat it's okay if we get interrupted.\n                    if e.errno != errno.EINTR:\n                        raise\n\n            # Restore signals / clean up\n            signal.signal(signal.SIGCHLD, signal.SIG_DFL)\n            signal.set_wakeup_fd(old_wakeup_fd)\n            os.close(pipe_r)\n            os.close(pipe_w)\n\n            success = (return_code == 0)\n            return success"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprocessing a queue message from activity channel.", "response": "def _process_queue_message(self, message_queue, new_queue_found, batch_exit,\n                               start_time, timeout, batch_timeout):\n        \"\"\"Process a queue message from activity channel.\"\"\"\n\n        for queue in self._filter_queues([message_queue]):\n            if queue not in self._queue_set:\n                if not new_queue_found:\n                    new_queue_found = True\n                    batch_exit = time.time() + batch_timeout\n                    # Limit batch_exit to max timeout\n                    if batch_exit > start_time + timeout:\n                        batch_exit = start_time + timeout\n                self._queue_set.add(queue)\n                self.log.debug('new queue', queue=queue)\n\n        return new_queue_found, batch_exit"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprocess the tasks in the queue.", "response": "def _process_queue_tasks(self, queue, queue_lock, task_ids, now, log):\n        \"\"\"Process tasks in queue.\"\"\"\n\n        processed_count = 0\n\n        # Get all tasks\n        serialized_tasks = self.connection.mget([\n            self._key('task', task_id) for task_id in task_ids\n        ])\n\n        # Parse tasks\n        tasks = []\n        for task_id, serialized_task in zip(task_ids, serialized_tasks):\n            if serialized_task:\n                task_data = json.loads(serialized_task)\n            else:\n                # In the rare case where we don't find the task which is\n                # queued (see ReliabilityTestCase.test_task_disappears),\n                # we log an error and remove the task below. We need to\n                # at least initialize the Task object with an ID so we can\n                # remove it.\n                task_data = {'id': task_id}\n\n            task = Task(self.tiger, queue=queue, _data=task_data,\n                        _state=ACTIVE, _ts=now)\n\n            if not serialized_task:\n                # Remove task as per comment above\n                log.error('not found', task_id=task_id)\n                task._move()\n            elif task.id != task_id:\n                log.error('task ID mismatch', task_id=task_id)\n                # Remove task\n                task._move()\n            else:\n                tasks.append(task)\n\n        # List of task IDs that exist and we will update the heartbeat on.\n        valid_task_ids = set(task.id for task in tasks)\n\n        # Group by task func\n        tasks_by_func = OrderedDict()\n        for task in tasks:\n            func = task.serialized_func\n            if func in tasks_by_func:\n                tasks_by_func[func].append(task)\n            else:\n                tasks_by_func[func] = [task]\n\n        # Execute tasks for each task func\n        for tasks in tasks_by_func.values():\n            success, processed_tasks = self._execute_task_group(queue,\n                    tasks, valid_task_ids, queue_lock)\n            processed_count = processed_count + len(processed_tasks)\n            log.debug('processed', attempted=len(tasks),\n                      processed=processed_count)\n            for task in processed_tasks:\n                self._finish_task_processing(queue, task, success)\n\n        return processed_count"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _process_from_queue(self, queue):\n        now = time.time()\n\n        log = self.log.bind(queue=queue)\n\n        batch_size = self._get_queue_batch_size(queue)\n\n        queue_lock, failed_to_acquire = self._get_queue_lock(queue, log)\n        if failed_to_acquire:\n            return [], -1\n\n        # Move an item to the active queue, if available.\n        # We need to be careful when moving unique tasks: We currently don't\n        # support concurrent processing of multiple unique tasks. If the task\n        # is already in the ACTIVE queue, we need to execute the queued task\n        # later, i.e. move it to the SCHEDULED queue (prefer the earliest\n        # time if it's already scheduled). We want to make sure that the last\n        # queued instance of the task always gets executed no earlier than it\n        # was queued.\n        later = time.time() + self.config['LOCK_RETRY']\n\n        task_ids = self.scripts.zpoppush(\n            self._key(QUEUED, queue),\n            self._key(ACTIVE, queue),\n            batch_size,\n            None,\n            now,\n            if_exists=('add', self._key(SCHEDULED, queue), later, 'min'),\n            on_success=('update_sets', queue, self._key(QUEUED),\n                        self._key(ACTIVE), self._key(SCHEDULED))\n        )\n        log.debug('moved tasks', src_queue=QUEUED, dest_queue=ACTIVE,\n                  qty=len(task_ids))\n\n        processed_count = 0\n        if task_ids:\n            processed_count = self._process_queue_tasks(queue, queue_lock,\n                                                        task_ids, now, log)\n\n        if queue_lock:\n            queue_lock.release()\n            log.debug('released swq lock')\n\n        return task_ids, processed_count", "response": "Internal method to process a task batch from the given queue."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _execute_task_group(self, queue, tasks, all_task_ids, queue_lock):\n        log = self.log.bind(queue=queue)\n\n        locks = []\n        # Keep track of the acquired locks: If two tasks in the list require\n        # the same lock we only acquire it once.\n        lock_ids = set()\n\n        ready_tasks = []\n        for task in tasks:\n            if task.lock:\n                if task.lock_key:\n                    kwargs = task.kwargs\n                    lock_id = gen_unique_id(\n                        task.serialized_func,\n                        None,\n                        {key: kwargs.get(key) for key in task.lock_key},\n                    )\n                else:\n                    lock_id = gen_unique_id(\n                        task.serialized_func,\n                        task.args,\n                        task.kwargs,\n                    )\n\n                if lock_id not in lock_ids:\n                    lock = Lock(self.connection, self._key('lock', lock_id), timeout=self.config['ACTIVE_TASK_UPDATE_TIMEOUT'])\n\n                    acquired = lock.acquire(blocking=False)\n                    if acquired:\n                        lock_ids.add(lock_id)\n                        locks.append(lock)\n                    else:\n                        log.info('could not acquire lock', task_id=task.id)\n\n                        # Reschedule the task (but if the task is already\n                        # scheduled in case of a unique task, don't prolong\n                        # the schedule date).\n                        when = time.time() + self.config['LOCK_RETRY']\n                        task._move(from_state=ACTIVE, to_state=SCHEDULED,\n                                   when=when, mode='min')\n                        # Make sure to remove it from this list so we don't\n                        # re-add to the ACTIVE queue by updating the heartbeat.\n                        all_task_ids.remove(task.id)\n                        continue\n\n            ready_tasks.append(task)\n\n        if not ready_tasks:\n            return True, []\n\n        if self.stats_thread:\n            self.stats_thread.report_task_start()\n        success = self._execute(queue, ready_tasks, log, locks, queue_lock, all_task_ids)\n        if self.stats_thread:\n            self.stats_thread.report_task_end()\n\n        for lock in locks:\n            lock.release()\n\n        return success, ready_tasks", "response": "Executes the given tasks in the queue."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _finish_task_processing(self, queue, task, success):\n        log = self.log.bind(queue=queue, task_id=task.id)\n\n        def _mark_done():\n            # Remove the task from active queue\n            task._move(from_state=ACTIVE)\n            log.info('done')\n\n        if success:\n            _mark_done()\n        else:\n            should_retry = False\n            should_log_error = True\n            # Get execution info (for logging and retry purposes)\n            execution = self.connection.lindex(\n                self._key('task', task.id, 'executions'), -1)\n\n            if execution:\n                execution = json.loads(execution)\n\n            if execution and execution.get('retry'):\n                if 'retry_method' in execution:\n                    retry_func, retry_args = execution['retry_method']\n                else:\n                    # We expect the serialized method here.\n                    retry_func, retry_args = serialize_retry_method( \\\n                            self.config['DEFAULT_RETRY_METHOD'])\n                should_log_error = execution['log_error']\n                should_retry = True\n\n            if task.retry_method and not should_retry:\n                retry_func, retry_args = task.retry_method\n                if task.retry_on:\n                    if execution:\n                        exception_name = execution.get('exception_name')\n                        try:\n                            exception_class = import_attribute(exception_name)\n                        except TaskImportError:\n                            log.error('could not import exception',\n                                      exception_name=exception_name)\n                        else:\n                            if task.should_retry_on(exception_class, logger=log):\n                                should_retry = True\n                else:\n                    should_retry = True\n\n            state = ERROR\n\n            when = time.time()\n\n            log_context = {\n                'func': task.serialized_func\n            }\n\n            if should_retry:\n                retry_num = task.n_executions()\n                log_context['retry_func'] = retry_func\n                log_context['retry_num'] = retry_num\n\n                try:\n                    func = import_attribute(retry_func)\n                except TaskImportError:\n                    log.error('could not import retry function',\n                              func=retry_func)\n                else:\n                    try:\n                        retry_delay = func(retry_num, *retry_args)\n                        log_context['retry_delay'] = retry_delay\n                        when += retry_delay\n                    except StopRetry:\n                        pass\n                    else:\n                        state = SCHEDULED\n\n            if execution:\n                if state == ERROR and should_log_error:\n                    log_func = log.error\n                else:\n                    log_func = log.warning\n\n                log_context.update({\n                    'time_failed': execution.get('time_failed'),\n                    'traceback': execution.get('traceback'),\n                    'exception_name': execution.get('exception_name'),\n                })\n\n                log_func('task error', **log_context)\n            else:\n                log.error('execution not found', **log_context)\n\n            # Move task to the scheduled queue for retry, or move to error\n            # queue if we don't want to retry.\n            if state == ERROR and not should_log_error:\n                _mark_done()\n            else:\n                task._move(from_state=ACTIVE, to_state=state, when=when)", "response": "This method is called when a task is executed."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nperforms one worker run: * Processes a set of messages from each queue and removes any empty queues from the working set. * Move any expired items from the active queue to the queued queue. * Move any scheduled items from the scheduled queue to the queued queue.", "response": "def _worker_run(self):\n        \"\"\"\n        Performs one worker run:\n        * Processes a set of messages from each queue and removes any empty\n          queues from the working set.\n        * Move any expired items from the active queue to the queued queue.\n        * Move any scheduled items from the scheduled queue to the queued\n          queue.\n        \"\"\"\n\n        queues = list(self._queue_set)\n        random.shuffle(queues)\n\n        for queue in queues:\n            task_ids, processed_count = self._process_from_queue(queue)\n            # Remove queue if queue was processed and was empty\n            if not task_ids and processed_count != -1:\n                self._queue_set.remove(queue)\n\n            if self._stop_requested:\n                break\n            if processed_count > 0:\n                self._did_work = True\n\n        if time.time() - self._last_task_check > self.config['SELECT_TIMEOUT'] and \\\n           not self._stop_requested:\n            self._worker_queue_scheduled_tasks()\n            self._worker_queue_expired_tasks()\n            self._last_task_check = time.time()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run(self, once=False, force_once=False):\n\n        self.log.info('ready', id=self.id,\n                               queues=sorted(self.only_queues),\n                               exclude_queues=sorted(self.exclude_queues),\n                               single_worker_queues=sorted(self.single_worker_queues),\n                               max_workers=self.max_workers_per_queue)\n\n        if not self.scripts.can_replicate_commands:\n            # Older Redis versions may create additional overhead when\n            # executing pipelines.\n            self.log.warn('using old Redis version')\n\n        if self.config['STATS_INTERVAL']:\n            self.stats_thread = StatsThread(self)\n            self.stats_thread.start()\n\n        # Queue any periodic tasks that are not queued yet.\n        self._queue_periodic_tasks()\n\n        # First scan all the available queues for new items until they're empty.\n        # Then, listen to the activity channel.\n        # XXX: This can get inefficient when having lots of queues.\n\n        self._pubsub = self.connection.pubsub()\n        self._pubsub.subscribe(self._key('activity'))\n\n        self._queue_set = set(self._filter_queues(\n                self.connection.smembers(self._key(QUEUED))))\n\n        try:\n            while True:\n                # Update the queue set on every iteration so we don't get stuck\n                # on processing a specific queue.\n                self._wait_for_new_tasks(timeout=self.config['SELECT_TIMEOUT'],\n                            batch_timeout=self.config['SELECT_BATCH_TIMEOUT'])\n\n                self._install_signal_handlers()\n                self._did_work = False\n                self._worker_run()\n                self._uninstall_signal_handlers()\n                if once and (not self._queue_set or force_once):\n                    break\n                if self._stop_requested:\n                    raise KeyboardInterrupt()\n        except KeyboardInterrupt:\n            pass\n\n        except Exception as e:\n            self.log.exception(event='exception')\n            raise\n\n        finally:\n            if self.stats_thread:\n                self.stats_thread.stop()\n                self.stats_thread = None\n\n            # Free up Redis connection\n            self._pubsub.reset()\n            self.log.info('done')", "response": "Main loop of the worker."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if Redis supports single command replication.", "response": "def can_replicate_commands(self):\n        \"\"\"\n        Whether Redis supports single command replication.\n        \"\"\"\n        if not hasattr(self, '_can_replicate_commands'):\n            info = self.redis.info('server')\n            version_info = info['redis_version'].split('.')\n            major, minor = int(version_info[0]), int(version_info[1])\n            result = major > 3 or major == 3 and minor >= 2\n            self._can_replicate_commands = result\n        return self._can_replicate_commands"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a new entry to the set with the given score and member.", "response": "def zadd(self, key, score, member, mode, client=None):\n        \"\"\"\n        Like ZADD, but supports different score update modes, in case the\n        member already exists in the ZSET:\n        - \"nx\": Don't update the score\n        - \"xx\": Only update elements that already exist. Never add elements.\n        - \"min\": Use the smaller of the given and existing score\n        - \"max\": Use the larger of the given and existing score\n        \"\"\"\n        if mode == 'nx':\n            f = self._zadd_noupdate\n        elif mode == 'xx':\n            f = self._zadd_update_existing\n        elif mode == 'min':\n            f = self._zadd_update_min\n        elif mode == 'max':\n            f = self._zadd_update_max\n        else:\n            raise NotImplementedError('mode \"%s\" unsupported' % mode)\n        return f(keys=[key], args=[score, member], client=client)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npops the first count members from the source ZSET and adds them to the destination ZSET with a score of new_score.", "response": "def zpoppush(self, source, destination, count, score, new_score,\n                 client=None, withscores=False, on_success=None,\n                 if_exists=None):\n        \"\"\"\n        Pops the first ``count`` members from the ZSET ``source`` and adds them\n        to the ZSET ``destination`` with a score of ``new_score``. If ``score``\n        is not None, only members up to a score of ``score`` are used. Returns\n        the members that were moved and, if ``withscores`` is True, their\n        original scores.\n\n        If items were moved, the action defined in ``on_success`` is executed.\n        The only implemented option is a tuple in the form ('update_sets',\n        ``set_value``, ``remove_from_set``, ``add_to_set``\n        [, ``add_to_set_if_exists``]).\n        If no items are left in the ``source`` ZSET, the ``set_value`` is\n        removed from ``remove_from_set``. If any items were moved to the\n        ``destination`` ZSET, the ``set_value`` is added to ``add_to_set``. If\n        any items were moved to the ``if_exists_key`` ZSET (see below), the\n        ``set_value`` is added to the ``add_to_set_if_exists`` set.\n\n        If ``if_exists`` is specified as a tuple ('add', if_exists_key,\n        if_exists_score, if_exists_mode), then members that are already in the\n        ``destination`` set will not be returned or updated, but they will be\n        added to a ZSET ``if_exists_key`` with a score of ``if_exists_score``\n        and the given behavior specified in ``if_exists_mode`` for members that\n        already exist in the ``if_exists_key`` ZSET. ``if_exists_mode`` can be\n        one of the following:\n        - \"nx\": Don't update the score\n        - \"min\": Use the smaller of the given and existing score\n        - \"max\": Use the larger of the given and existing score\n\n        If ``if_exists`` is specified as a tuple ('noupdate',), then no action\n        will be taken for members that are already in the ``destination`` ZSET\n        (their score will not be updated).\n        \"\"\"\n        if score is None:\n            score = '+inf' # Include all elements.\n        if withscores:\n            if on_success:\n                raise NotImplementedError()\n            return self._zpoppush_withscores(\n                keys=[source, destination],\n                args=[score, count, new_score],\n                client=client)\n        else:\n            if if_exists and if_exists[0] == 'add':\n                _, if_exists_key, if_exists_score, if_exists_mode = if_exists\n                if if_exists_mode != 'min':\n                    raise NotImplementedError()\n\n                if not on_success or on_success[0] != 'update_sets':\n                    raise NotImplementedError()\n                set_value, remove_from_set, add_to_set, add_to_set_if_exists \\\n                    = on_success[1:]\n\n                return self._zpoppush_exists_min_update_sets(\n                        keys=[source, destination, remove_from_set, add_to_set,\n                              add_to_set_if_exists, if_exists_key],\n                        args=[score, count, new_score, set_value, if_exists_score],\n                )\n            elif if_exists and if_exists[0] == 'noupdate':\n                if not on_success or on_success[0] != 'update_sets':\n                    raise NotImplementedError()\n                set_value, remove_from_set, add_to_set \\\n                    = on_success[1:]\n\n                return self._zpoppush_exists_ignore_update_sets(\n                        keys=[source, destination, remove_from_set, add_to_set],\n                        args=[score, count, new_score, set_value],\n                )\n\n            if on_success:\n                if on_success[0] != 'update_sets':\n                    raise NotImplementedError()\n                else:\n                    set_value, remove_from_set, add_to_set = on_success[1:]\n                    return self._zpoppush_update_sets(\n                        keys=[source, destination, remove_from_set, add_to_set],\n                        args=[score, count, new_score, set_value],\n                        client=client)\n            else:\n                return self._zpoppush(\n                    keys=[source, destination],\n                    args=[score, count, new_score],\n                    client=client)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef srem_if_not_exists(self, key, member, other_key, client=None):\n        return self._srem_if_not_exists(\n            keys=[key, other_key],\n            args=[member],\n            client=client)", "response": "Removes a member from the set if other_key does not exist."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove the specified key only if member is not member of any set in the set_list. Returns the number of removed elements.", "response": "def delete_if_not_in_zsets(self, key, member, set_list, client=None):\n        \"\"\"\n        Removes ``key`` only if ``member`` is not member of any sets in the\n        ``set_list``. Returns the number of removed elements (0 or 1).\n        \"\"\"\n        return self._delete_if_not_in_zsets(\n            keys=[key]+set_list,\n            args=[member],\n            client=client)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fail_if_not_in_zset(self, key, member, client=None):\n        self._fail_if_not_in_zset(keys=[key], args=[member], client=client)", "response": "Fail the job if the member is not in the ZSET."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_expired_tasks(self, key_prefix, time, batch_size, client=None):\n        result = self._get_expired_tasks(args=[key_prefix, time, batch_size],\n                                         client=client)\n\n        # [queue1, task1, queue2, task2] -> [(queue1, task1), (queue2, task2)]\n        return list(zip(result[::2], result[1::2]))", "response": "Returns a list of expired tasks in the specified time range."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef execute_pipeline(self, pipeline, client=None):\n\n        client = client or self.redis\n\n        executing_pipeline = None\n        try:\n\n            # Prepare args\n            stack = pipeline.command_stack\n            script_args = [int(self.can_replicate_commands), len(stack)]\n            for args, options in stack:\n                script_args += [len(args)-1] + list(args)\n\n            # Run the pipeline\n            if self.can_replicate_commands:  # Redis 3.2 or higher\n                # Make sure scripts exist\n                if pipeline.scripts:\n                    pipeline.load_scripts()\n\n                raw_results = self._execute_pipeline(args=script_args,\n                                                     client=client)\n            else:\n                executing_pipeline = client.pipeline()\n\n                # Always load scripts to avoid issues when Redis loads data\n                # from AOF file / when replicating.\n                for s in pipeline.scripts:\n                    executing_pipeline.script_load(s.script)\n\n                # Run actual pipeline lua script\n                self._execute_pipeline(args=script_args,\n                                       client=executing_pipeline)\n\n                # Always load all scripts and run actual pipeline lua script\n                raw_results = executing_pipeline.execute()[-1]\n\n            # Run response callbacks on results.\n            results = []\n            response_callbacks = pipeline.response_callbacks\n            for ((args, options), result) in zip(stack, raw_results):\n                command_name = args[0]\n                if command_name in response_callbacks:\n                    result = response_callbacks[command_name](result,\n                                                              **options)\n                results.append(result)\n\n            return results\n\n        finally:\n            if executing_pipeline:\n                executing_pipeline.reset()\n            pipeline.reset()", "response": "Executes the given Redis pipeline and returns a list of results."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef periodic(seconds=0, minutes=0, hours=0, days=0, weeks=0, start_date=None,\n             end_date=None):\n    \"\"\"\n    Periodic task schedule: Use to schedule a task to run periodically,\n    starting from start_date (or None to be active immediately) until end_date\n    (or None to repeat forever).\n\n    The period starts at the given start_date, or on Jan 1st 2000.\n\n    For more details, see README.\n    \"\"\"\n    period = seconds + minutes*60 + hours*3600 + days*86400 + weeks*604800\n    assert period > 0, \"Must specify a positive period.\"\n    if not start_date:\n        # Saturday at midnight\n        start_date = datetime.datetime(2000, 1, 1)\n    return (_periodic, (period, start_date, end_date))", "response": "Create a periodic task schedule for a given number of seconds minutes hours days and weeks."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning an attribute from a dotted path name ( e. g. path. to. func.", "response": "def import_attribute(name):\n    \"\"\"Return an attribute from a dotted path name (e.g. \"path.to.func\").\"\"\"\n    try:\n        sep = ':' if ':' in name else '.'  # For backwards compatibility\n        module_name, attribute = name.rsplit(sep, 1)\n        module = importlib.import_module(module_name)\n        return operator.attrgetter(attribute)(module)\n    except (ValueError, ImportError, AttributeError) as e:\n        raise TaskImportError(e)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates and returns a hex - encoded 256 - bit ID for the given task name and args. Used to generate unique IDs for tasks or locks.", "response": "def gen_unique_id(serialized_name, args, kwargs):\n    \"\"\"\n    Generates and returns a hex-encoded 256-bit ID for the given task name and\n    args. Used to generate IDs for unique tasks or for task locks.\n    \"\"\"\n    return hashlib.sha256(json.dumps({\n        'func': serialized_name,\n        'args': args,\n        'kwargs': kwargs,\n    }, sort_keys=True).encode('utf8')).hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef serialize_func_name(func):\n    if func.__module__ == '__main__':\n        raise ValueError('Functions from the __main__ module cannot be '\n                         'processed by workers.')\n    try:\n        # This will only work on Python 3.3 or above, but it will allow us to use static/classmethods\n        func_name = func.__qualname__\n    except AttributeError:\n        func_name = func.__name__\n    return ':'.join([func.__module__, func_name])", "response": "Returns the dotted serialized path to the passed function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nyield the dotted parts of a string.", "response": "def dotted_parts(s):\n    \"\"\"\n    For a string \"a.b.c\", yields \"a\", \"a.b\", \"a.b.c\".\n    \"\"\"\n    idx = -1\n    while s:\n        idx = s.find('.', idx+1)\n        if idx == -1:\n            yield s\n            break\n        yield s[:idx]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nyields the list of dotted parts of a string.", "response": "def reversed_dotted_parts(s):\n    \"\"\"\n    For a string \"a.b.c\", yields \"a.b.c\", \"a.b\", \"a\".\n    \"\"\"\n    idx = -1\n    if s:\n        yield s\n    while s:\n        idx = s.rfind('.', 0, idx)\n        if idx == -1:\n            break\n        yield s[:idx]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tasktiger_processor(logger, method_name, event_dict):\n\n    if g['current_tasks'] is not None and not g['current_task_is_batch']:\n        event_dict['task_id'] = g['current_tasks'][0].id\n\n    return event_dict", "response": "TaskTiger structlog processor.\n\n    Inject the current task id for non-batch tasks."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef should_retry_on(self, exception_class, logger=None):\n        for n in (self.retry_on or []):\n            try:\n                if issubclass(exception_class, import_attribute(n)):\n                    return True\n            except TaskImportError:\n                if logger:\n                    logger.error('should_retry_on could not import class',\n                                 exception_name=n)\n        return False", "response": "Returns True if this task should be retried when the given exception occurs."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _move(self, from_state=None, to_state=None, when=None, mode=None):\n\n        pipeline = self.tiger.connection.pipeline()\n        scripts = self.tiger.scripts\n        _key = self.tiger._key\n\n        from_state = from_state or self.state\n        queue = self.queue\n\n        assert from_state\n        assert queue\n\n        scripts.fail_if_not_in_zset(_key(from_state, queue), self.id,\n                                    client=pipeline)\n        if to_state:\n            if not when:\n                when = time.time()\n            if mode:\n                scripts.zadd(_key(to_state, queue), when, self.id,\n                                  mode, client=pipeline)\n            else:\n                pipeline.zadd(_key(to_state, queue), self.id, when)\n            pipeline.sadd(_key(to_state), queue)\n        pipeline.zrem(_key(from_state, queue), self.id)\n\n        if not to_state: # Remove the task if necessary\n            if self.unique:\n                # Only delete if it's not in any other queue\n                check_states = set([ACTIVE, QUEUED, ERROR, SCHEDULED])\n                check_states.remove(from_state)\n                # TODO: Do the following two in one call.\n                scripts.delete_if_not_in_zsets(_key('task', self.id, 'executions'),\n                                                    self.id, [\n                    _key(state, queue) for state in check_states\n                ], client=pipeline)\n                scripts.delete_if_not_in_zsets(_key('task', self.id),\n                                                    self.id, [\n                    _key(state, queue) for state in check_states\n                ], client=pipeline)\n            else:\n                # Safe to remove\n                pipeline.delete(_key('task', self.id, 'executions'))\n                pipeline.delete(_key('task', self.id))\n\n        scripts.srem_if_not_exists(_key(from_state), queue,\n                _key(from_state, queue), client=pipeline)\n\n        if to_state == QUEUED:\n            pipeline.publish(_key('activity'), queue)\n\n        try:\n            scripts.execute_pipeline(pipeline)\n        except redis.ResponseError as e:\n            if '<FAIL_IF_NOT_IN_ZSET>' in e.args[0]:\n                raise TaskNotFound('Task {} not found in queue \"{}\" in state \"{}\".'.format(\n                    self.id, queue, from_state\n                ))\n            raise\n        else:\n            self._state = to_state", "response": "Internal helper to move a task from one state to another."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_scheduled_time(self, when):\n        tiger = self.tiger\n\n        ts = get_timestamp(when)\n        assert ts\n\n        pipeline = tiger.connection.pipeline()\n        key = tiger._key(SCHEDULED, self.queue)\n        tiger.scripts.zadd(key, ts, self.id, mode='xx', client=pipeline)\n        pipeline.zscore(key, self.id)\n        _, score = pipeline.execute()\n        if not score:\n            raise TaskNotFound('Task {} not found in queue \"{}\" in state \"{}\".'.format(\n                self.id, self.queue, SCHEDULED\n            ))\n\n        self._ts = ts", "response": "Updates the scheduled time of the task."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload a task from the given queue in the given state.", "response": "def from_id(self, tiger, queue, state, task_id, load_executions=0):\n        \"\"\"\n        Loads a task with the given ID from the given queue in the given\n        state. An integer may be passed in the load_executions parameter\n        to indicate how many executions should be loaded (starting from the\n        latest). If the task doesn't exist, None is returned.\n        \"\"\"\n        if load_executions:\n            pipeline = tiger.connection.pipeline()\n            pipeline.get(tiger._key('task', task_id))\n            pipeline.lrange(tiger._key('task', task_id, 'executions'), -load_executions, -1)\n            serialized_data, serialized_executions = pipeline.execute()\n        else:\n            serialized_data = tiger.connection.get(tiger._key('task', task_id))\n            serialized_executions = []\n        # XXX: No timestamp for now\n        if serialized_data:\n            data = json.loads(serialized_data)\n            executions = [json.loads(e) for e in serialized_executions if e]\n            return Task(tiger, queue=queue, _data=data, _state=state,\n                        _executions=executions)\n        else:\n            raise TaskNotFound('Task {} not found.'.format(\n                task_id\n            ))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tasks_from_queue(self, tiger, queue, state, skip=0, limit=1000,\n                   load_executions=0):\n        \"\"\"\n        Returns a tuple with the following information:\n        * total items in the queue\n        * tasks from the given queue in the given state, latest first.\n\n        An integer may be passed in the load_executions parameter to indicate\n        how many executions should be loaded (starting from the latest).\n        \"\"\"\n\n        key = tiger._key(state, queue)\n        pipeline = tiger.connection.pipeline()\n        pipeline.zcard(key)\n        pipeline.zrange(key, -limit-skip, -1-skip, withscores=True)\n        n, items = pipeline.execute()\n\n        tasks = []\n\n        if items:\n            tss = [datetime.datetime.utcfromtimestamp(item[1]) for item in items]\n            if load_executions:\n                pipeline = tiger.connection.pipeline()\n                pipeline.mget([tiger._key('task', item[0]) for item in items])\n                for item in items:\n                    pipeline.lrange(tiger._key('task', item[0], 'executions'), -load_executions, -1)\n                results = pipeline.execute()\n\n                for serialized_data, serialized_executions, ts in zip(results[0], results[1:], tss):\n                    data = json.loads(serialized_data)\n                    executions = [json.loads(e) for e in serialized_executions if e]\n\n                    task = Task(tiger, queue=queue, _data=data, _state=state,\n                                _ts=ts, _executions=executions)\n\n                    tasks.append(task)\n            else:\n                data = tiger.connection.mget([tiger._key('task', item[0]) for item in items])\n                for serialized_data, ts in zip(data, tss):\n                    data = json.loads(serialized_data)\n                    task = Task(tiger, queue=queue, _data=data, _state=state,\n                                _ts=ts)\n                    tasks.append(task)\n\n        return n, tasks", "response": "Returns a list of tasks from the given queue in the given state."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nqueries and returns the number of past task executions.", "response": "def n_executions(self):\n        \"\"\"\n        Queries and returns the number of past task executions.\n        \"\"\"\n        pipeline = self.tiger.connection.pipeline()\n        pipeline.exists(self.tiger._key('task', self.id))\n        pipeline.llen(self.tiger._key('task', self.id, 'executions'))\n        exists, n_executions = pipeline.execute()\n        if not exists:\n            raise TaskNotFound('Task {} not found.'.format(\n                self.id\n            ))\n        return n_executions"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_input(self, nr=2, qd=1, b=0):\n        self.nr = nr\n        self.qd = qd\n        self.b = b", "response": "Set the inputs after initialization of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates the noise time series based on input parameters.", "response": "def generateNoise(self):\n        \"\"\" Generate noise time series based on input parameters\n\n        Returns\n        -------\n        time_series: np.array\n            Time series with colored noise.\n            len(time_series) == nr\n\n        \"\"\"\n        # Fill wfb array with white noise based on given discrete variance\n        wfb = np.zeros(self.nr*2)\n        wfb[:self.nr] = np.random.normal(0, np.sqrt(self.qd), self.nr)\n        # Generate the hfb coefficients based on the noise type\n        mhb = -self.b/2.0\n        hfb = np.zeros(self.nr*2)\n        hfb = np.zeros(self.nr*2)\n        hfb[0] = 1.0\n        indices = np.arange(self.nr-1)\n        hfb[1:self.nr] = (mhb+indices)/(indices+1.0)\n        hfb[:self.nr] = np.multiply.accumulate(hfb[:self.nr])\n        # Perform discrete Fourier transform of wfb and hfb time series\n        wfb_fft = np.fft.rfft(wfb)\n        hfb_fft = np.fft.rfft(hfb)\n        # Perform inverse Fourier transform of the product of wfb and hfb FFTs\n        time_series = np.fft.irfft(wfb_fft*hfb_fft)[:self.nr]\n        self.time_series = time_series"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn phase power spectral density coefficient g_b for noise - type defined by ( qd b tau0 )", "response": "def phase_psd_from_qd(self, tau0=1.0):\n        \"\"\" return phase power spectral density coefficient g_b\n            for noise-type defined by (qd, b, tau0)\n            where tau0 is the interval between data points\n\n            Colored noise generated with (qd, b, tau0) parameters will\n            show a phase power spectral density of\n            S_x(f) = Phase_PSD(f) = g_b * f^b\n\n            Kasdin & Walter eqn (39)\n        \"\"\"\n        return self.qd*2.0*pow(2.0*np.pi, self.b)*pow(tau0, self.b+1.0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef frequency_psd_from_qd(self, tau0=1.0):\n        a = self.b + 2.0\n        return self.qd*2.0*pow(2.0*np.pi, a)*pow(tau0, a-1.0)", "response": "return the frequency power spectral density coefficient h_a for the noise type defined by qd b tau0"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns predicted ADEV of noise - type at given tau0", "response": "def adev(self, tau0, tau):\n        \"\"\" return predicted ADEV of noise-type at given tau\n\n        \"\"\"\n        prefactor = self.adev_from_qd(tau0=tau0, tau=tau)\n        c = self.c_avar()\n        avar = pow(prefactor, 2)*pow(tau, c)\n        return np.sqrt(avar)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mdev(self, tau0, tau):\n        prefactor = self.mdev_from_qd(tau0=tau0, tau=tau)\n        c = self.c_mvar()\n        mvar = pow(prefactor, 2)*pow(tau, c)\n        return np.sqrt(mvar)", "response": "return predicted MDEV of noise - type at given tau0"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef c_avar(self):\n        if self.b == -4:\n            return 1.0\n        elif self.b == -3:\n            return 0.0\n        elif self.b == -2:\n            return -1.0\n        elif self.b == -1:\n            return -2.0\n        elif self.b == 0:\n            return -2.0", "response": "return the AVAR for noise type."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef c_mvar(self):\n        if self.b == -4:\n            return 1.0\n        elif self.b == -3:\n            return 0.0\n        elif self.b == -2:\n            return -1.0\n        elif self.b == -1:\n            return -2.0\n        elif self.b == 0:\n            return -3.0", "response": "return the m - variable for noise type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef adev_from_qd(self, tau0=1.0, tau=1.0):\n        g_b = self.phase_psd_from_qd(tau0)\n        f_h = 0.5/tau0\n        if self.b == 0:\n            coeff = 3.0*f_h / (4.0*pow(np.pi, 2)) # E, White PM, tau^-1\n        elif self.b == -1:\n            coeff = (1.038+3*np.log(2.0*np.pi*f_h*tau))/(4.0*pow(np.pi, 2))# D, Flicker PM, tau^-1\n        elif self.b == -2:\n            coeff = 0.5 # C, white FM,  1/sqrt(tau)\n        elif self.b == -3:\n            coeff = 2*np.log(2) # B, flicker FM,  constant ADEV\n        elif self.b == -4:\n            coeff = 2.0*pow(np.pi, 2)/3.0 #  A, RW FM, sqrt(tau)\n\n        return np.sqrt(coeff*g_b*pow(2.0*np.pi, 2))", "response": "prefactor for Allan deviation for noise\n            type defined by QD and tau0 parameters will show an Allan variance of the noise containing the Colored noise generated with QD and the Allan variance of the Colored noise containing the frequency PSD."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates power spectral density of input signal x", "response": "def numpy_psd(x, f_sample=1.0):\n    \"\"\" calculate power spectral density of input signal x\n        x = signal\n        f_sample = sampling frequency in Hz. i.e. 1/fs is the time-interval\n             in seconds between datapoints\n        scale fft so that output corresponds to 1-sided PSD\n        output has units of [X^2/Hz] where X is the unit of x\n    \"\"\"\n    psd_of_x = (2.0/ (float(len(x)) * f_sample)) * numpy.abs(numpy.fft.rfft(x))**2\n    f_axis = numpy.linspace(0, f_sample/2.0, len(psd_of_x)) # frequency axis\n    return f_axis, psd_of_x"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef white(num_points=1024, b0=1.0, fs=1.0):\n    return math.sqrt(b0*fs/2.0)*numpy.random.randn(num_points)", "response": "generate time series with white noise"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pink(N, depth=80):\n    a = []\n    s = iterpink(depth)\n    for n in range(N):\n        a.append(next(s))\n    return a", "response": "N - length vector with approximate pink noise has 1 / f PSD\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate a sequence of samples of pink noise.", "response": "def iterpink(depth=20):\n    \"\"\"Generate a sequence of samples of pink noise.\n\n    pink noise generator\n    from http://pydoc.net/Python/lmj.sound/0.1.1/lmj.sound.noise/\n\n    Based on the Voss-McCartney algorithm, discussion and code examples at\n    http://www.firstpr.com.au/dsp/pink-noise/\n\n    depth: Use this many samples of white noise to calculate the output. A\n      higher  number is slower to run, but renders low frequencies with more\n      correct power spectra.\n\n    Generates a never-ending sequence of floating-point values. Any continuous\n    set of these samples will tend to have a 1/f power spectrum.\n    \"\"\"\n    values = numpy.random.randn(depth)\n    smooth = numpy.random.randn(depth)\n    source = numpy.random.randn(depth)\n    sumvals = values.sum()\n    i = 0\n    while True:\n        yield sumvals + smooth[i]\n\n        # advance the index by 1. if the index wraps, generate noise to use in\n        # the calculations, but do not update any of the pink noise values.\n        i += 1\n        if i == depth:\n            i = 0\n            smooth = numpy.random.randn(depth)\n            source = numpy.random.randn(depth)\n            continue\n\n        # count trailing zeros in i\n        c = 0\n        while not (i >> c) & 1:\n            c += 1\n\n        # replace value c with a new source element\n        sumvals += source[i] - values[c]\n        values[c] = source[i]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef plotline(plt, alpha, taus, style,label=\"\"):\n    y = [pow(tt, alpha) for tt in taus]\n    plt.loglog(taus, y, style,label=label)", "response": "plot a line with the slope alpha"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nplots the data of the current object with the computed data", "response": "def plot(self, atDataset,\n             errorbars=False,\n             grid=False):\n        \"\"\" use matplotlib methods for plotting\n\n        Parameters\n        ----------\n        atDataset : allantools.Dataset()\n            a dataset with computed data\n        errorbars : boolean\n            Plot errorbars. Defaults to False\n        grid : boolean\n            Plot grid. Defaults to False\n        \"\"\"\n        if errorbars:\n            self.ax.errorbar(atDataset.out[\"taus\"],\n                             atDataset.out[\"stat\"],\n                             yerr=atDataset.out[\"stat_err\"],\n                             )\n        else:\n            self.ax.plot(atDataset.out[\"taus\"],\n                         atDataset.out[\"stat\"],\n                         )\n        self.ax.set_xlabel(\"Tau\")\n        self.ax.set_ylabel(atDataset.out[\"stat_id\"])\n        self.ax.grid(grid, which=\"minor\", ls=\"-\", color='0.65')\n        self.ax.grid(grid, which=\"major\", ls=\"-\", color='0.25')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef confidence_interval(dev, edf, ci=ONE_SIGMA_CI):\n    ci_l = min(np.abs(ci), np.abs((ci-1))) / 2\n    ci_h = 1 - ci_l\n\n    # function from scipy, works OK, but scipy is large and slow to build\n    chi2_l = scipy.stats.chi2.ppf(ci_l, edf)\n    chi2_h = scipy.stats.chi2.ppf(ci_h, edf)\n\n    variance = dev*dev\n    var_l = float(edf) * variance / chi2_h  # NIST SP1065 eqn (45)\n    var_h = float(edf) * variance / chi2_l\n    return (np.sqrt(var_l), np.sqrt(var_h))", "response": "returns the confidence interval for a given deviation dev equivalent degrees of freedom edf and degree of confidence ci"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef confidence_interval_noiseID(x, dev, af, dev_type=\"adev\", data_type=\"phase\", ci=ONE_SIGMA_CI):\n    # 1) noise ID\n    dmax = 2\n    if (dev_type is \"hdev\") or (dev_type is \"ohdev\"):\n        dmax = 3\n    alpha_int = autocorr_noise_id( x, int(af), data_type=data_type, dmin=0, dmax=dmax)[0]\n\n    # 2) EDF\n    if dev_type is \"adev\":\n        edf = edf_greenhall( alpha=alpha_int, d=2, m=af, N=len(x), overlapping = False, modified=False )\n    elif dev_type is \"oadev\":\n        edf = edf_greenhall( alpha=alpha_int, d=2, m=af, N=len(x), overlapping = True, modified=False  )\n    elif (dev_type is \"mdev\") or (dev_type is \"tdev\"):\n        edf = edf_greenhall( alpha=alpha_int, d=2, m=af, N=len(x), overlapping = True, modified=True  )\n    elif dev_type is \"hdev\":\n        edf = edf_greenhall( alpha=alpha_int, d=3, m=af, N=len(x), overlapping = False, modified=False  )\n    elif dev_type is \"ohdev\":\n        edf = edf_greenhall( alpha=alpha_int, d=3, m=af, N=len(x), overlapping = True, modified=False  )\n    else:\n        raise NotImplementedError\n\n    # 3) confidence interval\n    (low, high)  = confidence_interval(dev, edf, ci)\n    return (low, high)", "response": "returns the confidence interval for a given noise ID"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rn(x, af, rate):\n    (taus,devs,errs,ns) = at.adev(x,taus=[af*rate], data_type='phase', rate=rate) \n    oadev_x = devs[0]\n    (mtaus,mdevs,errs,ns) = at.mdev(x,taus=[af*rate], data_type='phase', rate=rate)\n    mdev_x = mdevs[0]\n    rn = pow(mdev_x/oadev_x,2)\n    return rn", "response": "R ( n ) ratio for noise identification of AVAR to MVAR"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rn_boundary(af, b_hi):\n    return np.sqrt( rn_theory(af, b)*rn_theory(af, b-1) )", "response": "R ( n ) ratio boundary for selecting between b_hi and b_hi - 1."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef b1_theory(N, mu):\n    \n    # see Table 3 of Howe 2000\n    if mu == 2:\n        return float(N)*(float(N)+1.0)/6.0\n        #up = N*(1.0-pow(N, mu))\n        #down = 2*(N-1.0)*(1-pow(2.0, mu))\n        #return up/down        \n    elif mu == 1:\n        return float(N)/2.0\n    elif mu == 0:\n        return N*np.log(N)/(2.0*(N-1.0)*np.log(2))\n    elif mu == -1:\n        return 1\n    elif mu == -2:\n        return (pow(N,2)-1.0)/(1.5*N*(N-1.0))\n    else:\n        up = N*(1.0-pow(N, mu))\n        down = 2*(N-1.0)*(1-pow(2.0, mu))\n        return up/down\n        \n    assert False", "response": "This function calculates the B1 ratio for given time - series length N and exponent mu."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate the B1 ratio boundary for selecting between b_hi and b_lo.", "response": "def b1_boundary(b_hi, N):\n    \"\"\"\n    B1 ratio boundary for selecting between [b_hi-1, b_hi]\n    alpha = b + 2\n    \n    \"\"\"\n    b_lo = b_hi-1\n    b1_lo = b1_theory(N, b_to_mu(b_lo))\n    b1_hi = b1_theory(N, b_to_mu(b_hi))\n    if b1_lo >= -4:\n        return np.sqrt(b1_lo*b1_hi) # geometric mean\n    else:\n        return 0.5*(b1_lo+b1_hi)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef lag1_acf(x, detrend_deg=1):\n    mu = np.mean(x)\n    a=0\n    b=0\n    for n in range(len(x)-1):\n        a = a + (x[n]-mu)*(x[n+1]-mu)\n    for n in range(len(x)):\n        b=b+pow( x[n]-mu , 2 )\n    return a/b", "response": "lag - 1 autocorrelation function for input time - series x"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef autocorr_noise_id(x, af, data_type=\"phase\", dmin=0, dmax=2):\n    d = 0 # number of differentiations\n    lag = 1\n    if data_type is \"phase\":\n        \n        if af>1:\n            #x = scipy.signal.decimate(x, af, n=1, ftype='fir')\n            x = x[0:len(x):af] # decimate by averaging factor\n        x = detrend(x, deg=2) # remove quadratic trend (frequency offset and drift)\n    elif data_type is \"freq\":\n        # average by averaging factor\n        y_cut = np.array(x[:len(x)-(len(x)%af)]) # cut to length\n        assert len(y_cut)%af == 0\n        y_shaped = y_cut.reshape((int(len(y_cut)/af), af))\n        x = np.average(y_shaped, axis=1) # average\n        x = detrend(x, deg=1) # remove frequency drift\n    \n    # require minimum length for time-series\n    if len(x)<30:\n        print(\"autocorr_noise_id() Don't know how to do noise-ID for time-series length= %d\"%len(x))\n        raise NotImplementedError\n    \n    while True:\n        r1 = lag1_acf(x)\n        rho = r1/(1.0+r1)\n        if d >= dmin and ( rho < 0.25 or d >= dmax ):\n            p = -2*(rho+d)\n            #print r1\n            #assert r1 < 0\n            #assert r1 > -1.0/2.0\n            phase_add2 = 0\n            if data_type is \"phase\":\n                phase_add2 = 2\n            alpha = p+phase_add2\n            alpha_int = int( -1.0*np.round(2*rho) - 2.0*d )+phase_add2 \n            #print \"d=\",d,\"alpha=\",p+2\n            return alpha_int, alpha, d, rho\n        else:\n            x = np.diff(x)\n            d = d + 1\n    assert False", "response": "This function is used to generate a new autocorrelation based noise id for a given time - series."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef detrend(x, deg=1):\n    t=range(len(x))\n    p = np.polyfit(t, x, deg)\n    residual = x - np.polyval(p, t)\n    return residual", "response": "detrend the polynomial from data."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef edf_greenhall_simple(alpha, d, m, S, F, N):\n    L = m/F+m*d # length of filter applied to phase samples\n    M = 1 + np.floor(S*(N-L) / m)\n    J = min(M, (d+1)*S)\n    inv_edf = (1.0/(pow(greenhall_sz(0, F, alpha, d), 2)*M))* \\\n               greenhall_BasicSum(J, M, S, F, alpha, d)\n    return 1.0/inv_edf", "response": "Eqn ( 13 ) from Greenhall2004"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the EDF of the current set of unmasked non - overlapping states for a given noise type d m and N.", "response": "def edf_greenhall(alpha, d, m, N, overlapping=False, modified=False, verbose=False):\n    \"\"\" returns Equivalent degrees of freedom\n        \n        Parameters\n        ----------\n        alpha: int\n            noise type, +2...-4\n        d: int\n            1 first-difference variance\n            2 Allan variance\n            3 Hadamard variance\n            require alpha+2*d>1\n        m: int\n            averaging factor\n            tau = m*tau0 = m*(1/rate)\n        N: int\n            number of phase observations (length of time-series)\n        overlapping: bool\n            True for oadev, ohdev\n        modified: bool\n            True for mdev, tdev\n        \n        Returns\n        -------\n        edf: float\n            Equivalent degrees of freedom\n        \n        Greenhall, Riley, 2004\n        https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20050061319.pdf\n        UNCERTAINTY OF STABILITY VARIANCES BASED ON FINITE DIFFERENCES\n        \n        Notes\n        -----\n        Used for the following deviations (see http://www.wriley.com/CI2.pdf page 8)\n        adev()\n        oadev()\n        mdev()\n        tdev()\n        hdev()\n        ohdev()\n    \"\"\"\n\n    if modified:\n        F = 1 # F filter factor, 1 modified variance, m unmodified variance\n    else:\n        F = int(m)\n    if overlapping:\n        S = int(m) # S stride factor, 1 nonoverlapped estimator, m overlapped estimator (estimator stride = tau/S )\n    else:\n        S = 1\n    assert(alpha+2*d > 1.0)\n    L = m/F+m*d # length of filter applied to phase samples\n    M = 1 + np.floor(S*(N-L) / m)\n    J = min(M, (d+1)*S)\n    J_max = 100\n    r = M/S\n    if int(F) == 1 and modified: # case 1, modified variances, all alpha\n        if J <= J_max:\n            inv_edf = (1.0/(pow(greenhall_sz(0, 1, alpha, d), 2)*M))* \\\n                       greenhall_BasicSum(J, M, S, 1, alpha, d)\n            if verbose:\n                print(\"case 1.1 edf= %3f\" % float(1.0/inv_edf))\n            return 1.0/inv_edf\n        elif r > d+1:\n            (a0, a1) = greenhall_table1(alpha, d)\n            inv_edf = (1.0/r)*(a0-a1/r)\n            if verbose:\n                print(\"case 1.2 edf= %3f\" % float(1.0/inv_edf))\n            return 1.0/inv_edf\n        else:\n            m_prime = J_max/r\n            inv_edf = (1.0/(pow(greenhall_sz(0, F, alpha, d), 2)*J_max))* \\\n                       greenhall_BasicSum(J_max, J_max, m_prime, 1, alpha, d)\n            if verbose:\n                print(\"case 1.3 edf= %3f\" % float(1.0/inv_edf))\n            return 1.0/inv_edf\n    elif int(F) == int(m) and int(alpha) <= 0 and not modified: \n        # case 2, unmodified variances, alpha <= 0\n        if J <= J_max:\n            if m*(d+1) <= J_max:\n                m_prime = m\n                variant = \"a\"\n            else:\n                m_prime = float('inf')\n                variant = \"b\"\n\n            inv_edf = (1.0/(pow(greenhall_sz(0, m_prime, alpha, d), 2)*M))* \\\n                       greenhall_BasicSum(J, M, S, m_prime, alpha, d)\n            if verbose:\n                print(\"case 2.1%s edf= %3f\" % (variant, float(1.0/inv_edf)))\n            return 1.0/inv_edf\n        elif r > d+1:\n            (a0, a1) = greenhall_table2(alpha, d)\n            inv_edf = (1.0/r)*(a0-a1/r)\n            if verbose:\n                print(\"case 2.2 edf= %3f\" % float(1.0/inv_edf))\n            return 1.0/inv_edf\n        else:\n            m_prime = J_max/r\n            inv_edf = (1.0/(pow(greenhall_sz(0, float('inf'), alpha, d), 2)*J_max))* \\\n                       greenhall_BasicSum(J_max, J_max, m_prime, float('inf'), alpha, d)\n            if verbose:\n                print(\"case 2.3 edf= %3f\" % float(1.0/inv_edf))\n            return 1.0/inv_edf\n    elif int(F) == int(m) and int(alpha) == 1 and not modified: \n        # case 3, unmodified variances, alpha=1\n        if J <= J_max:\n            inv_edf = (1.0/(pow(greenhall_sz(0, m, 1, d), 2)*M))* \\\n                       greenhall_BasicSum(J, M, S, m, 1, d) # note: m<1e6 to avoid roundoff\n            if verbose:\n                print(\"case 3.1 edf= %3f\" % float(1.0/inv_edf))\n            return 1.0/inv_edf\n        elif r > d+1:\n            (a0, a1) = greenhall_table2(alpha, d)\n            (b0, b1) = greenhall_table3(alpha, d)\n            inv_edf = (1.0/(pow(b0+b1*np.log(m), 2)*r))*(a0-a1/r)\n            if verbose:\n                print(\"case 3.2 edf= %3f\" % float(1.0/inv_edf))\n            return 1.0/inv_edf\n        else:\n            m_prime = J_max/r\n            (b0, b1) = greenhall_table3(alpha, d)\n            inv_edf = (1.0/(pow(b0+b1*np.log(m), 2)*J_max))* \\\n                       greenhall_BasicSum(J_max, J_max, m_prime, m_prime, 1, d)\n            if verbose:\n                print(\"case 3.3 edf= %3f\" % float(1.0/inv_edf))\n            return 1.0/inv_edf\n    elif int(F) == int(m) and int(alpha) == 2 and not modified: \n        # case 4, unmodified variances, alpha=2\n        K = np.ceil(r)\n        if K <= d:\n            raise NotImplementedError  # FIXME: add formula from the paper here!\n        else:\n            a0 = scipy.special.binom(4*d, 2*d) / pow(scipy.special.binom(2*d, d), 2)\n            a1 = d/2.0\n            inv_edf = (1.0/M)*(a0-a1/r)\n            if verbose:\n                print(\"case 4.2 edf= %3f\" % float(1.0/inv_edf))\n            return 1.0/inv_edf\n\n    print(\"greenhall_edf() no matching case!\")\n    raise NotImplementedError"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef greenhall_BasicSum(J, M, S, F, alpha, d):\n    first = pow(greenhall_sz(0, F, alpha, d), 2)\n    second = (1-float(J)/float(M))*pow(greenhall_sz(float(J)/float(S), F, alpha, d), 2)\n    third = 0\n    for j in range(1, int(J)):\n        third += 2*(1.0-float(j)/float(M))*pow(greenhall_sz(float(j)/float(S), F, alpha, d), 2)\n    return first+second+third", "response": "Eqn ( 10 ) from Greenhall2004"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef greenhall_sz(t, F, alpha, d):\n    if d == 1:\n        a = 2*greenhall_sx(t, F, alpha)\n        b = greenhall_sx(t-1.0, F, alpha)\n        c = greenhall_sx(t+1.0, F, alpha)\n        return a-b-c\n    elif d == 2:\n        a = 6*greenhall_sx(t, F, alpha)\n        b = 4*greenhall_sx(t-1.0, F, alpha)\n        c = 4*greenhall_sx(t+1.0, F, alpha)\n        dd = greenhall_sx(t-2.0, F, alpha)\n        e = greenhall_sx(t+2.0, F, alpha)\n        return a-b-c+dd+e\n    elif d == 3:\n        a = 20.0*greenhall_sx(t, F, alpha)\n        b = 15.0*greenhall_sx(t-1.0, F, alpha)\n        c = 15.0*greenhall_sx(t+1.0, F, alpha)\n        dd = 6.0*greenhall_sx(t-2.0, F, alpha)\n        e = 6.0*greenhall_sx(t+2.0, F, alpha)\n        f = greenhall_sx(t-3.0, F, alpha)\n        g = greenhall_sx(t+3.0, F, alpha)\n        return a-b-c+dd+e-f-g\n\n    assert(0)", "response": "Eqn ( 9 ) from Greenhall2004"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef greenhall_table2(alpha, d):\n    row_idx = int(-alpha+2) # map 2-> row0 and -4-> row6\n    assert(row_idx in [0, 1, 2, 3, 4, 5])\n    col_idx = int(d-1)\n    table2 = [[(3.0/2.0, 1.0/2.0), (35.0/18.0, 1.0), (231.0/100.0, 3.0/2.0)], # alpha=+2\n              [(78.6, 25.2), (790.0, 410.0), (9950.0, 6520.0)],\n              [(2.0/3.0, 1.0/6.0), (2.0/3.0, 1.0/3.0), (7.0/9.0, 1.0/2.0)], # alpha=0\n              [(-1, -1), (0.852, 0.375), (0.997, 0.617)], # -1\n              [(-1, -1), (1.079, 0.368), (1.033, 0.607)], #-2\n              [(-1, -1), (-1, -1), (1.053, 0.553)], #-3\n              [(-1, -1), (-1, -1), (1.302, 0.535)], # alpha=-4\n             ]\n    #print(\"table2 = \", table2[row_idx][col_idx])\n    return table2[row_idx][col_idx]", "response": "Greenhall 2004 Table 2 from Greenhall 2004"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntabling 1 from Greenhall 2004", "response": "def greenhall_table1(alpha, d):\n    \"\"\" Table 1 from Greenhall 2004 \"\"\"\n    row_idx = int(-alpha+2) # map 2-> row0 and -4-> row6\n    col_idx = int(d-1)\n    table1 = [[(2.0/3.0, 1.0/3.0), (7.0/9.0, 1.0/2.0), (22.0/25.0, 2.0/3.0)], # alpha=+2\n              [(0.840, 0.345), (0.997, 0.616), (1.141, 0.843)],\n              [(1.079, 0.368), (1.033, 0.607), (1.184, 0.848)],\n              [(-1, -1), (1.048, 0.534), (1.180, 0.816)], # -1\n              [(-1, -1), (1.302, 0.535), (1.175, 0.777)], #-2\n              [(-1, -1), (-1, -1), (1.194, 0.703)], #-3\n              [(-1, -1), (-1, -1), (1.489, 0.702)], # alpha=-4\n             ]\n    #print(\"table1 = \", table1[row_idx][col_idx])\n    return table1[row_idx][col_idx]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef example1():\n    N = 1000\n    f = 1\n    y = np.random.randn(1,N)[0,:]\n    x = [xx for xx in np.linspace(1,len(y),len(y))]\n    x_ax, y_ax, (err_l, err_h), ns = allan.gradev(y,data_type='phase',rate=f,taus=x)\n    plt.errorbar(x_ax, y_ax,yerr=[err_l,err_h],label='GRADEV, no gaps')\n    \n    \n    y[int(np.floor(0.4*N)):int(np.floor(0.6*N))] = np.NaN # Simulate missing data\n    x_ax, y_ax, (err_l, err_h) , ns = allan.gradev(y,data_type='phase',rate=f,taus=x)\n    plt.errorbar(x_ax, y_ax,yerr=[err_l,err_h], label='GRADEV, with gaps')\n    plt.xscale('log')\n    plt.yscale('log')\n    plt.grid()\n    plt.legend()\n    plt.xlabel('Tau / s')\n    plt.ylabel('Overlapping Allan deviation')\n    plt.show()", "response": "Compute the GRADEV of a white phase noise. Compares two different \n    scenarios. 1 ) The original data and 2 ) ADEV estimate with gap robust ADEV."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes the GRADEV of a nonstationary white phase noise.", "response": "def example2():\n    \"\"\"\n    Compute the GRADEV of a nonstationary white phase noise.\n    \"\"\"\n    N=1000 # number of samples\n    f = 1 # data samples per second\n    s=1+5/N*np.arange(0,N)\n    y=s*np.random.randn(1,N)[0,:]\n    x = [xx for xx in np.linspace(1,len(y),len(y))]\n    x_ax, y_ax, (err_l, err_h) , ns = allan.gradev(y,data_type='phase',rate=f,taus=x)\n    plt.loglog(x_ax, y_ax,'b.',label=\"No gaps\")\n    y[int(0.4*N):int(0.6*N,)] = np.NaN  # Simulate missing data\n    x_ax, y_ax, (err_l, err_h), ns = allan.gradev(y,data_type='phase',rate=f,taus=x)\n    plt.loglog(x_ax, y_ax,'g.',label=\"With gaps\")\n    plt.grid()\n    plt.legend()\n    plt.xlabel('Tau / s')\n    plt.ylabel('Overlapping Allan deviation')\n    plt.show()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tdev(data, rate=1.0, data_type=\"phase\", taus=None):\n    phase = input_to_phase(data, rate, data_type)\n    (taus, md, mde, ns) = mdev(phase, rate=rate, taus=taus)\n    td = taus * md / np.sqrt(3.0)\n    tde = td / np.sqrt(ns)\n    return taus, td, tde, ns", "response": "Time deviation of the current set of Tau values for each tau value."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmodifies Allan deviation. Used to distinguish between White and Flicker Phase Modulation. .. math:: \\\\sigma^2_{MDEV}(m\\\\tau_0) = { 1 \\\\over 2 (m \\\\tau_0 )^2 (N-3m+1) } \\\\sum_{j=1}^{N-3m+1} \\\\lbrace \\\\sum_{i=j}^{j+m-1} {x}_{i+2m} - 2x_{i+m} + x_{i} \\\\rbrace^2 Parameters ---------- data: np.array Input data. Provide either phase or frequency (fractional, adimensional). rate: float The sampling rate for data, in Hz. Defaults to 1.0 data_type: {'phase', 'freq'} Data type, i.e. phase or frequency. Defaults to \"phase\". taus: np.array Array of tau values, in seconds, for which to compute statistic. Optionally set taus=[\"all\"|\"octave\"|\"decade\"] for automatic tau-list generation. Returns ------- (taus2, md, mde, ns): tuple Tuple of values taus2: np.array Tau values for which td computed md: np.array Computed mdev for each tau value mde: np.array mdev errors ns: np.array Values of N used in each mdev calculation Notes ----- see http://www.leapsecond.com/tools/adev_lib.c NIST SP 1065 eqn (14) and (15), page 17", "response": "def mdev(data, rate=1.0, data_type=\"phase\", taus=None):\n    \"\"\"  Modified Allan deviation.\n         Used to distinguish between White and Flicker Phase Modulation.\n\n    .. math::\n\n        \\\\sigma^2_{MDEV}(m\\\\tau_0) = { 1 \\\\over 2 (m \\\\tau_0 )^2 (N-3m+1) }\n        \\\\sum_{j=1}^{N-3m+1} \\\\lbrace\n        \\\\sum_{i=j}^{j+m-1} {x}_{i+2m} - 2x_{i+m} + x_{i} \\\\rbrace^2\n\n    Parameters\n    ----------\n    data: np.array\n        Input data. Provide either phase or frequency (fractional,\n        adimensional).\n    rate: float\n        The sampling rate for data, in Hz. Defaults to 1.0\n    data_type: {'phase', 'freq'}\n        Data type, i.e. phase or frequency. Defaults to \"phase\".\n    taus: np.array\n        Array of tau values, in seconds, for which to compute statistic.\n        Optionally set taus=[\"all\"|\"octave\"|\"decade\"] for automatic\n        tau-list generation.\n\n    Returns\n    -------\n    (taus2, md, mde, ns): tuple\n          Tuple of values\n    taus2: np.array\n        Tau values for which td computed\n    md: np.array\n        Computed mdev for each tau value\n    mde: np.array\n        mdev errors\n    ns: np.array\n        Values of N used in each mdev calculation\n\n    Notes\n    -----\n\n    see http://www.leapsecond.com/tools/adev_lib.c\n\n    NIST SP 1065 eqn (14) and (15), page 17\n\n    \"\"\"\n    phase = input_to_phase(data, rate, data_type)\n    (phase, ms, taus_used) = tau_generator(phase, rate, taus=taus)\n    data, taus = np.array(phase), np.array(taus)\n\n    md = np.zeros_like(ms)\n    mderr = np.zeros_like(ms)\n    ns = np.zeros_like(ms)\n\n    # this is a 'loop-unrolled' algorithm following\n    # http://www.leapsecond.com/tools/adev_lib.c\n    for idx, m in enumerate(ms):\n        m = int(m) # without this we get: VisibleDeprecationWarning:\n                   # using a non-integer number instead of an integer\n                   # will result in an error in the future\n        tau = taus_used[idx]\n\n        # First loop sum\n        d0 = phase[0:m]\n        d1 = phase[m:2*m]\n        d2 = phase[2*m:3*m]\n        e = min(len(d0), len(d1), len(d2))\n        v = np.sum(d2[:e] - 2* d1[:e] + d0[:e])\n        s = v * v\n\n        # Second part of sum\n        d3 = phase[3*m:]\n        d2 = phase[2*m:]\n        d1 = phase[1*m:]\n        d0 = phase[0:]\n\n        e = min(len(d0), len(d1), len(d2), len(d3))\n        n = e + 1\n\n        v_arr = v + np.cumsum(d3[:e] - 3 * d2[:e] + 3 * d1[:e] - d0[:e])\n\n        s = s + np.sum(v_arr * v_arr)\n        s /= 2.0 * m * m * tau * tau * n\n        s = np.sqrt(s)\n\n        md[idx] = s\n        mderr[idx] = (s / np.sqrt(n))\n        ns[idx] = n\n\n    return remove_small_ns(taus_used, md, mderr, ns)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef adev(data, rate=1.0, data_type=\"phase\", taus=None):\n    phase = input_to_phase(data, rate, data_type)\n    (phase, m, taus_used) = tau_generator(phase, rate, taus)\n\n    ad = np.zeros_like(taus_used)\n    ade = np.zeros_like(taus_used)\n    adn = np.zeros_like(taus_used)\n\n    for idx, mj in enumerate(m):  # loop through each tau value m(j)\n        (ad[idx], ade[idx], adn[idx]) = calc_adev_phase(phase, rate, mj, mj)\n\n    return remove_small_ns(taus_used, ad, ade, adn)", "response": "Allan deviation of a set of time - series data."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute the Overlapping Hadamard deviation for a set of time - series of phase observations.", "response": "def ohdev(data, rate=1.0, data_type=\"phase\", taus=None):\n    \"\"\" Overlapping Hadamard deviation.\n        Better confidence than normal Hadamard.\n\n    .. math::\n\n        \\\\sigma^2_{OHDEV}(m\\\\tau_0) = { 1 \\\\over 6 (m \\\\tau_0 )^2 (N-3m) }\n        \\\\sum_{i=1}^{N-3m} ( {x}_{i+3m} - 3x_{i+2m} + 3x_{i+m} - x_{i} )^2\n\n    where :math:`x_i` is the time-series of phase observations, spaced\n    by the measurement interval :math:`\\\\tau_0`, and with length :math:`N`.\n\n    Parameters\n    ----------\n    data: np.array\n        Input data. Provide either phase or frequency (fractional,\n        adimensional).\n    rate: float\n        The sampling rate for data, in Hz. Defaults to 1.0\n    data_type: {'phase', 'freq'}\n        Data type, i.e. phase or frequency. Defaults to \"phase\".\n    taus: np.array\n        Array of tau values, in seconds, for which to compute statistic.\n        Optionally set taus=[\"all\"|\"octave\"|\"decade\"] for automatic\n        tau-list generation.\n\n    Returns\n    -------\n    (taus2, hd, hde, ns): tuple\n          Tuple of values\n    taus2: np.array\n        Tau values for which td computed\n    hd: np.array\n        Computed hdev for each tau value\n    hde: np.array\n        hdev errors\n    ns: np.array\n        Values of N used in each hdev calculation\n\n    \"\"\"\n    phase = input_to_phase(data, rate, data_type)\n    (phase, m, taus_used) = tau_generator(phase, rate, taus)\n    hdevs = np.zeros_like(taus_used)\n    hdeverrs = np.zeros_like(taus_used)\n    ns = np.zeros_like(taus_used)\n\n    for idx, mj in enumerate(m):\n        (hdevs[idx],\n         hdeverrs[idx],\n         ns[idx]) = calc_hdev_phase(phase, rate, mj, 1)\n\n    return remove_small_ns(taus_used, hdevs, hdeverrs, ns)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef calc_hdev_phase(phase, rate, mj, stride):\n\n    tau0 = 1.0 / float(rate)\n    mj = int(mj)\n    stride = int(stride)\n    d3 = phase[3 * mj::stride]\n    d2 = phase[2 * mj::stride]\n    d1 = phase[1 * mj::stride]\n    d0 = phase[::stride]\n\n    n = min(len(d0), len(d1), len(d2), len(d3))\n\n    v_arr = d3[:n] - 3 * d2[:n] + 3 * d1[:n] - d0[:n]\n\n    s = np.sum(v_arr * v_arr)\n\n    if n == 0:\n        n = 1\n\n    h = np.sqrt(s / 6.0 / float(n)) / float(tau0 * mj)\n    e = h / np.sqrt(n)\n    return h, e, n", "response": "main calculation fungtion for HDEV and OHDEV"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef totdev(data, rate=1.0, data_type=\"phase\", taus=None):\n    phase = input_to_phase(data, rate, data_type)\n    (phase, m, taus_used) = tau_generator(phase, rate, taus)\n    N = len(phase)\n\n    # totdev requires a new dataset\n    # Begin by adding reflected data before dataset\n    x1 = 2.0 * phase[0] * np.ones((N - 2,))\n    x1 = x1 - phase[1:-1]\n    x1 = x1[::-1]\n\n    # Reflected data at end of dataset\n    x2 = 2.0 * phase[-1] * np.ones((N - 2,))\n    x2 = x2 - phase[1:-1][::-1]\n\n    # check length of new dataset\n    assert len(x1)+len(phase)+len(x2) == 3*N - 4\n    # Combine into a single array\n    x = np.zeros((3*N - 4))\n    x[0:N-2] = x1\n    x[N-2:2*(N-2)+2] = phase # original data in the middle\n    x[2*(N-2)+2:] = x2\n\n    devs = np.zeros_like(taus_used)\n    deverrs = np.zeros_like(taus_used)\n    ns = np.zeros_like(taus_used)\n\n    mid = len(x1)\n\n    for idx, mj in enumerate(m):\n        mj = int(mj)\n        d0 = x[mid + 1:]\n        d1 = x[mid  + mj + 1:]\n        d1n = x[mid - mj + 1:]\n        e = min(len(d0), len(d1), len(d1n))\n\n        v_arr = d1n[:e] - 2.0 * d0[:e] + d1[:e]\n        dev = np.sum(v_arr[:mid] * v_arr[:mid])\n\n        dev /= float(2 * pow(mj / rate, 2) * (N - 2))\n        dev = np.sqrt(dev)\n        devs[idx] = dev\n        deverrs[idx] = dev / np.sqrt(mid)\n        ns[idx] = mid\n\n    return remove_small_ns(taus_used, devs, deverrs, ns)", "response": "This function calculates the total deviation of the characterization of the current language."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ttotdev(data, rate=1.0, data_type=\"phase\", taus=None):\n\n    (taus, mtotdevs, mde, ns) = mtotdev(data, data_type=data_type,\n                                        rate=rate, taus=taus)\n    td = taus*mtotdevs / np.sqrt(3.0)\n    tde = td / np.sqrt(ns)\n    return taus, td, tde, ns", "response": "Time Total Deviation\n        modified total variance scaled by tau^2"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a new Hadamard Total deviation for a set of data.", "response": "def htotdev(data, rate=1.0, data_type=\"phase\", taus=None):\n    \"\"\" PRELIMINARY - REQUIRES FURTHER TESTING.\n        Hadamard Total deviation.\n        Better confidence at long averages for Hadamard deviation\n\n        FIXME: bias corrections from http://www.wriley.com/CI2.pdf\n        W FM    0.995      alpha= 0\n        F FM    0.851      alpha=-1\n        RW FM   0.771      alpha=-2\n        FW FM   0.717      alpha=-3\n        RR FM   0.679      alpha=-4\n\n    Parameters\n    ----------\n    data: np.array\n        Input data. Provide either phase or frequency (fractional,\n        adimensional).\n    rate: float\n        The sampling rate for data, in Hz. Defaults to 1.0\n    data_type: {'phase', 'freq'}\n        Data type, i.e. phase or frequency. Defaults to \"phase\".\n    taus: np.array\n        Array of tau values, in seconds, for which to compute statistic.\n        Optionally set taus=[\"all\"|\"octave\"|\"decade\"] for automatic\n        tau-list generation.\n\n    \"\"\"\n    if data_type == \"phase\":\n        phase = data\n        freq = phase2frequency(phase, rate)\n    elif data_type == \"freq\":\n        phase = frequency2phase(data, rate)\n        freq = data\n    else:\n        raise Exception(\"unknown data_type: \" + data_type)\n\n    rate = float(rate)\n    (freq, ms, taus_used) = tau_generator(freq, rate, taus,\n                                          maximum_m=float(len(freq))/3.0)\n    phase = np.array(phase)\n    freq = np.array(freq)\n    devs = np.zeros_like(taus_used)\n    deverrs = np.zeros_like(taus_used)\n    ns = np.zeros_like(taus_used)\n\n    # NOTE at mj==1 we use ohdev(), based on comment from here:\n    # http://www.wriley.com/paper4ht.htm\n    # \"For best consistency, the overlapping Hadamard variance is used\n    # instead of the Hadamard total variance at m=1\"\n    # FIXME: this uses both freq and phase datasets, which uses double the memory really needed...\n    for idx, mj in enumerate(ms):\n        if int(mj) == 1:\n            (devs[idx],\n             deverrs[idx],\n             ns[idx]) = calc_hdev_phase(phase, rate, mj, 1)\n        else:\n            (devs[idx],\n             deverrs[idx],\n             ns[idx]) = calc_htotdev_freq(freq, mj)\n\n    return remove_small_ns(taus_used, devs, deverrs, ns)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef calc_htotdev_freq(freq, m):\n\n    N = int(len(freq)) # frequency data, N points\n    m = int(m)\n    n = 0    # number of terms in the sum, for error estimation\n    dev = 0.0 # the deviation we are computing\n    for i in range(0, N-3*int(m)+1):\n        # subsequence of length 3m, from the original phase data\n        xs = freq[i:i+3*m]\n        assert len(xs) == 3*m\n        # remove linear trend. by averaging first/last half,\n        # computing slope, and subtracting\n        half1_idx = int(np.floor(3*m/2.0))\n        half2_idx = int(np.ceil(3*m/2.0))\n        # m\n        # 1    0:1   2:2\n        mean1 = np.mean(xs[:half1_idx])\n        mean2 = np.mean(xs[half2_idx:])\n\n        if int(3*m)%2 == 1: # m is odd\n            # 3m = 2k+1 is odd, with the averages at both ends over k points\n            # the distance between the averages is then k+1 = (3m-1)/2 +1\n            slope = (mean2-mean1) / ((0.5*(3*m-1)+1))\n        else: # m is even\n            # 3m = 2k is even, so distance between averages is k=3m/2\n            slope = (mean2-mean1) / (0.5*3*m)\n\n        # remove the linear trend\n        x0 = [x - slope*(idx-np.floor(3*m/2)) for (idx, x) in enumerate(xs)]\n        x0_flip = x0[::-1] # left-right flipped version of array\n        # extended sequence of length 9m, by uninverted even reflection\n        xstar = np.concatenate((x0_flip, x0, x0_flip))\n        assert len(xstar) == 9*m\n\n        # now compute totdev on these 9m points\n        # 6m unique groups of m-point averages,\n        # all possible overlapping second differences\n        # one term in the 6m sum:  [ x_i - 2 x_i+m + x_i+2m ]^2\n        squaresum = 0.0\n        k = 0\n        for j in range(0, 6*int(m)): # summation of the 6m terms.\n            xmean1 = np.mean(xstar[j+0*m : j+1*m])\n            xmean2 = np.mean(xstar[j+1*m : j+2*m])\n            xmean3 = np.mean(xstar[j+2*m : j+3*m])\n            squaresum += pow(xmean1-2.0*xmean2+xmean3, 2)\n            k = k+1\n        assert k == 6*int(m)\n\n        squaresum = (1.0/(6.0*k)) * squaresum\n        dev += squaresum\n        n = n+1\n\n    # scaling in front of double-sum\n    assert n == N-3*int(m)+1 # sanity check on the number of terms n\n    dev = dev* 1.0/ (N-3*m+1)\n    dev = np.sqrt(dev)\n    error = dev / np.sqrt(n)\n    return (dev, error, n)", "response": "Calculates the hotdev of a frequency array for one averaging factor m."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tierms(data, rate=1.0, data_type=\"phase\", taus=None):\n    phase = input_to_phase(data, rate, data_type)\n    (data, m, taus_used) = tau_generator(phase, rate, taus)\n\n    count = len(phase)\n\n    devs = np.zeros_like(taus_used)\n    deverrs = np.zeros_like(taus_used)\n    ns = np.zeros_like(taus_used)\n\n    for idx, mj in enumerate(m):\n        mj = int(mj)\n\n        # This seems like an unusual way to\n        phases = np.column_stack((phase[:-mj], phase[mj:]))\n        p_max = np.max(phases, axis=1)\n        p_min = np.min(phases, axis=1)\n        phases = p_max - p_min\n        tie = np.sqrt(np.mean(phases * phases))\n\n        ncount = count - mj\n\n        devs[idx] = tie\n        deverrs[idx] = 0 / np.sqrt(ncount) # TODO! I THINK THIS IS WRONG!\n        ns[idx] = ncount\n\n    return remove_small_ns(taus_used, devs, deverrs, ns)", "response": "Time Interval Error RMS."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef mtie_rolling_window(a, window):\n    if window < 1:\n        raise ValueError(\"`window` must be at least 1.\")\n    if window > a.shape[-1]:\n        raise ValueError(\"`window` is too long.\")\n    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n    strides = a.strides + (a.strides[-1],)\n    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)", "response": "Returns an array_like a with a rolling window of the last dimension of the given size."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mtie_phase_fast(phase, rate=1.0, data_type=\"phase\", taus=None):\n    rate = float(rate)\n    phase = np.asarray(phase)\n    k_max = int(np.floor(np.log2(len(phase))))\n    phase = phase[0:pow(2, k_max)] # truncate data to 2**k_max datapoints\n    assert len(phase) == pow(2, k_max)\n    #k = 1\n    taus = [ pow(2,k) for k in range(k_max)]\n    #while k <= k_max:\n    #    tau = pow(2, k)\n    #    taus.append(tau)\n        #print tau\n    #    k += 1\n    print(\"taus N=\", len(taus), \" \",taus)\n    devs = np.zeros(len(taus))\n    deverrs = np.zeros(len(taus))\n    ns = np.zeros(len(taus))\n    taus_used = np.array(taus) # [(1.0/rate)*t for t in taus]\n    # matrices to store results\n    mtie_max = np.zeros((len(phase)-1, k_max))\n    mtie_min = np.zeros((len(phase)-1, k_max))\n    for kidx in range(k_max):\n        k = kidx+1\n        imax = len(phase)-pow(2, k)+1\n        #print k, imax\n        tie = np.zeros(imax)\n        ns[kidx]=imax\n        #print np.max( tie )\n        for i in range(imax):\n            if k == 1:\n                mtie_max[i, kidx] = max(phase[i], phase[i+1])\n                mtie_min[i, kidx] = min(phase[i], phase[i+1])\n            else:\n                p = int(pow(2, k-1))\n                mtie_max[i, kidx] = max(mtie_max[i, kidx-1],\n                                        mtie_max[i+p, kidx-1])\n                mtie_min[i, kidx] = min(mtie_min[i, kidx-1],\n                                        mtie_min[i+p, kidx-1])\n\n        #for i in range(imax):\n            tie[i] = mtie_max[i, kidx] - mtie_min[i, kidx]\n            #print tie[i]\n        devs[kidx] = np.amax(tie) # maximum along axis\n        #print \"maximum %2.4f\" % devs[kidx]\n        #print np.amax( tie )\n    #for tau in taus:\n    #for\n    devs = np.array(devs)\n    print(\"devs N=\",len(devs),\" \",devs)\n    print(\"taus N=\", len(taus_used), \" \",taus_used)\n    return remove_small_ns(taus_used, devs, deverrs, ns)", "response": "Fast binary decomposition of the TVAR and MTIE phase."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef gradev(data, rate=1.0, data_type=\"phase\", taus=None,\n           ci=0.9, noisetype='wp'):\n    \"\"\" gap resistant overlapping Allan deviation\n\n    Parameters\n    ----------\n    data: np.array\n        Input data. Provide either phase or frequency (fractional,\n        adimensional). Warning : phase data works better (frequency data is\n        first trantformed into phase using numpy.cumsum() function, which can\n        lead to poor results).\n    rate: float\n        The sampling rate for data, in Hz. Defaults to 1.0\n    data_type: {'phase', 'freq'}\n        Data type, i.e. phase or frequency. Defaults to \"phase\".\n    taus: np.array\n        Array of tau values, in seconds, for which to compute statistic.\n        Optionally set taus=[\"all\"|\"octave\"|\"decade\"] for automatic\n        tau-list generation.\n    ci: float\n        the total confidence interval desired, i.e. if ci = 0.9, the bounds\n        will be at 0.05 and 0.95.\n    noisetype: string\n        the type of noise desired:\n        'wp' returns white phase noise.\n        'wf' returns white frequency noise.\n        'fp' returns flicker phase noise.\n        'ff' returns flicker frequency noise.\n        'rf' returns random walk frequency noise.\n        If the input is not recognized, it defaults to idealized, uncorrelated\n        noise with (N-1) degrees of freedom.\n\n    Returns\n    -------\n    taus: np.array\n        list of tau vales in seconds\n    adev: np.array\n        deviations\n    [err_l, err_h] : list of len()==2, np.array\n        the upper and lower bounds of the confidence interval taken as\n        distances from the the estimated two sample variance.\n    ns: np.array\n        numper of terms n in the adev estimate.\n\n    \"\"\"\n    if (data_type == \"freq\"):\n        print(\"Warning : phase data is preferred as input to gradev()\")\n    phase = input_to_phase(data, rate, data_type)\n    (data, m, taus_used) = tau_generator(phase, rate, taus)\n\n    ad = np.zeros_like(taus_used)\n    ade_l = np.zeros_like(taus_used)\n    ade_h = np.zeros_like(taus_used)\n    adn = np.zeros_like(taus_used)\n\n    for idx, mj in enumerate(m):\n        (dev, deverr, n) = calc_gradev_phase(data,\n                                             rate,\n                                             mj,\n                                             1,\n                                             ci,\n                                             noisetype)\n        # stride=1 for overlapping ADEV\n        ad[idx] = dev\n        ade_l[idx] = deverr[0]\n        ade_h[idx] = deverr[1]\n        adn[idx] = n\n\n    # Note that errors are split in 2 arrays\n    return remove_small_ns(taus_used, ad, [ade_l, ade_h], adn)", "response": "Generate a gap resistant overlapping Allan deviation tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef input_to_phase(data, rate, data_type):\n    if data_type == \"phase\":\n        return data\n    elif data_type == \"freq\":\n        return frequency2phase(data, rate)\n    else:\n        raise Exception(\"unknown data_type: \" + data_type)", "response": "Take either phase or frequency as input and return phase\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tau_generator(data, rate, taus=None, v=False, even=False, maximum_m=-1):\n\n\n    if rate == 0:\n        raise RuntimeError(\"Warning! rate==0\")\n\n    if taus is None: # empty or no tau-list supplied\n        taus = \"octave\" # default to octave\n    elif isinstance(taus, list) and taus == []:\n        taus = \"octave\"\n\n    if taus is \"all\":\n        taus = (1.0/rate)*np.linspace(1.0, len(data), len(data))\n    elif taus is \"octave\":\n        maxn = np.floor(np.log2(len(data)))\n        taus = (1.0/rate)*np.logspace(0, maxn, maxn+1, base=2.0)\n    elif taus is \"decade\": # 1, 2, 4, 10, 20, 40, spacing similar to Stable32\n        maxn = np.floor(np.log10(len(data)))\n        taus = []\n        for k in range(int(maxn+1)):\n            taus.append(1.0*(1.0/rate)*pow(10.0, k))\n            taus.append(2.0*(1.0/rate)*pow(10.0, k))\n            taus.append(4.0*(1.0/rate)*pow(10.0, k))\n\n    data, taus = np.array(data), np.array(taus)\n    rate = float(rate)\n    m = [] # integer averaging factor. tau = m*tau0\n\n    if maximum_m == -1: # if no limit given\n        maximum_m = len(data)\n    # FIXME: should we use a \"stop-ratio\" like Stable32\n    # found in Table III, page 9 of \"Evolution of frequency stability analysis software\"\n    # max(AF) = len(phase)/stop_ratio, where \n    # function  stop_ratio\n    # adev      5\n    # oadev     4\n    # mdev      4\n    # tdev      4\n    # hdev      5\n    # ohdev     4\n    # totdev    2\n    # tierms    4\n    # htotdev   3\n    # mtie      2\n    # theo1     1\n    # theoH     1\n    # mtotdev   2\n    # ttotdev   2\n\n    taus_valid1 = taus < (1 / float(rate)) * float(len(data))\n    taus_valid2 = taus > 0\n    taus_valid3 = taus <= (1 / float(rate)) * float(maximum_m)\n    taus_valid = taus_valid1 & taus_valid2 & taus_valid3\n    m = np.floor(taus[taus_valid] * rate)\n    m = m[m != 0]       # m is tau in units of datapoints\n    m = np.unique(m)    # remove duplicates and sort\n\n    if v:\n        print(\"tau_generator: \", m)\n\n    if len(m) == 0:\n        print(\"Warning: sanity-check on tau failed!\")\n        print(\"   len(data)=\", len(data), \" rate=\", rate, \"taus= \", taus)\n\n    taus2 = m / float(rate)\n\n    if even: # used by Theo1\n        m_even_mask = ((m % 2) == 0)\n        m = m[m_even_mask]\n        taus2 = taus2[m_even_mask]\n\n    return data, m, taus2", "response": "Generate the tau - list for the current time interval."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tau_reduction(ms, rate, n_per_decade):\n    ms = np.int64(ms)\n    keep = np.bool8(np.rint(n_per_decade*np.log10(ms[1:])) -\n                    np.rint(n_per_decade*np.log10(ms[:-1])))\n    # Adjust ms size to fit above-defined mask\n    ms = ms[:-1]\n    assert len(ms) == len(keep)\n    ms = ms[keep]\n    taus = ms/float(rate)\n\n    return ms, taus", "response": "This function reduces the number of taus to maximum of n per decade."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove results with small number of samples.", "response": "def remove_small_ns(taus, devs, deverrs, ns):\n    \"\"\" Remove results with small number of samples.\n        If n is small (==1), reject the result\n\n    Parameters\n    ----------\n    taus: array\n        List of tau values for which deviation were computed\n    devs: array\n        List of deviations\n    deverrs: array or list of arrays\n        List of estimated errors (possibly a list containing two arrays :\n        upper and lower values)\n    ns: array\n        Number of samples for each point\n\n    Returns\n    -------\n    (taus, devs, deverrs, ns): tuple\n        Identical to input, except that values with low ns have been removed.\n\n    \"\"\"\n    ns_big_enough = ns > 1\n\n    o_taus = taus[ns_big_enough]\n    o_devs = devs[ns_big_enough]\n    o_ns = ns[ns_big_enough]\n    if isinstance(deverrs, list):\n        assert len(deverrs) < 3\n        o_deverrs = [deverrs[0][ns_big_enough], deverrs[1][ns_big_enough]]\n    else:\n        o_deverrs = deverrs[ns_big_enough]\n    if len(o_devs)==0:\n        print(\"remove_small_ns() nothing remains!?\")\n        raise UserWarning\n         \n    return o_taus, o_devs, o_deverrs, o_ns"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef trim_data(x):\n    # Find indices for first and last valid data\n    first = 0\n    while np.isnan(x[first]):\n        first += 1\n    last = len(x)\n    while np.isnan(x[last - 1]):\n        last -= 1\n    return x[first:last]", "response": "Trim leading and trailing NaNs from dataset\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef frequency2phase(freqdata, rate):\n    dt = 1.0 / float(rate)\n    # Protect against NaN values in input array (issue #60)\n    # Reintroduces data trimming as in commit 503cb82\n    freqdata = trim_data(freqdata)\n    phasedata = np.cumsum(freqdata) * dt\n    phasedata = np.insert(phasedata, 0, 0) # FIXME: why do we do this?\n    # so that phase starts at zero and len(phase)=len(freq)+1 ??\n    return phasedata", "response": "Integrate fractional frequency data and output phase data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef phase2radians(phasedata, v0):\n    fi = [2*np.pi*v0*xx for xx in phasedata]\n    return fi", "response": "Convert phase in seconds to phase in radians"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef frequency2fractional(frequency, mean_frequency=-1):\n    if mean_frequency == -1:\n        mu = np.mean(frequency)\n    else:\n        mu = mean_frequency\n    y = [(x-mu)/mu for x in frequency]\n    return y", "response": "Convert frequency in Hz to fractional frequency in Hz"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_input(self, data,\n                  rate=1.0, data_type=\"phase\", taus=None):\n        \"\"\" Optionnal method if you chose not to set inputs on init\n\n        Parameters\n        ----------\n        data: np.array\n            Input data. Provide either phase or frequency (fractional,\n            adimensional)\n        rate: float\n            The sampling rate for data, in Hz. Defaults to 1.0\n        data_type: {'phase', 'freq'}\n            Data type, i.e. phase or frequency. Defaults to \"phase\".\n        taus: np.array\n            Array of tau values, in seconds, for which to compute statistic.\n            Optionally set taus=[\"all\"|\"octave\"|\"decade\"] for automatic\n        \"\"\"\n        self.inp[\"data\"] = data\n        self.inp[\"rate\"] = rate\n        self.inp[\"data_type\"] = data_type\n        self.inp[\"taus\"] = taus", "response": "Set the input data for the current object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nevaluate the passed function with the supplied data and store the result in self. out.", "response": "def compute(self, function):\n        \"\"\"Evaluate the passed function with the supplied data.\n\n        Stores result in self.out.\n\n        Parameters\n        ----------\n        function: str\n            Name of the :mod:`allantools` function to evaluate\n\n        Returns\n        -------\n        result: dict\n            The results of the calculation.\n\n        \"\"\"\n        try:\n            func = getattr(allantools, function)\n        except AttributeError:\n            raise AttributeError(\"function must be defined in allantools\")\n\n        whitelisted = [\"theo1\", \"mtie\", \"tierms\"]\n\n        if function[-3:] != \"dev\" and function not in whitelisted:\n            # this should probably raise a custom exception type so\n            # it's easier to distinguish from other bad things\n            raise RuntimeError(\"function must be one of the 'dev' functions\")\n        result = func(self.inp[\"data\"], rate=self.inp[\"rate\"],\n                      data_type=self.inp[\"data_type\"], taus=self.inp[\"taus\"])\n        keys = [\"taus\", \"stat\", \"stat_err\", \"stat_n\"]\n        result = {key: result[i] for i, key in enumerate(keys)}\n        self.out = result.copy()\n        self.out[\"stat_id\"] = function\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes average of many PSDs", "response": "def many_psds(k=2,fs=1.0, b0=1.0, N=1024):\n    \"\"\" compute average of many PSDs \"\"\"\n    psd=[]\n    for j in range(k):\n        print j\n        x = noise.white(N=2*4096,b0=b0,fs=fs)\n        f, tmp = noise.numpy_psd(x,fs)\n        if j==0:\n            psd = tmp\n        else:\n            psd = psd + tmp\n    return f, psd/k"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlisting all the organizations that are the owner or as the member of the current identity.", "response": "def list_my(self):\n        \"\"\" Find organization that has the current identity as the owner or as the member \"\"\"\n        org_list = self.call_contract_command(\"Registry\", \"listOrganizations\", [])\n\n        rez_owner  = []\n        rez_member = []\n        for idx, org_id in enumerate(org_list):\n            (found, org_id, org_name, owner, members, serviceNames, repositoryNames) = self.call_contract_command(\"Registry\", \"getOrganizationById\", [org_id])\n            if (not found):\n                raise Exception(\"Organization was removed during this call. Please retry.\");\n            if self.ident.address == owner:\n                rez_owner.append((org_name, bytes32_to_str(org_id)))\n\n            if self.ident.address in members:\n                rez_member.append((org_name, bytes32_to_str(org_id)))\n\n        if (rez_owner):\n            self._printout(\"# Organizations you are the owner of\")\n            self._printout(\"# OrgName OrgId\")\n            for n,i in rez_owner:\n                self._printout(\"%s   %s\"%(n,i))\n\n        if (rez_member):\n            self._printout(\"# Organizations you are the member of\")\n            self._printout(\"# OrgName OrgId\")\n            for n,i in rez_member:\n                self._printout(\"%s   %s\"%(n,i))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a group to the cache", "response": "def add_group(self, group_name, payment_address):\n        \"\"\" Return new group_id in base64 \"\"\"\n        if (self.is_group_name_exists(group_name)):\n            raise Exception(\"the group \\\"%s\\\" is already present\"%str(group_name))\n        group_id_base64 = base64.b64encode(secrets.token_bytes(32))\n        self.m[\"groups\"] += [{\"group_name\"      : group_name ,\n                              \"group_id\"        : group_id_base64.decode(\"ascii\"),\n                              \"payment_address\" : payment_address}]\n        return group_id_base64"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if group with given name exists", "response": "def is_group_name_exists(self, group_name):\n        \"\"\" check if group with given name is already exists \"\"\"\n        groups = self.m[\"groups\"]\n        for g in groups:\n            if (g[\"group_name\"] == group_name):\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_group_by_group_id(self, group_id):\n        group_id_base64 = base64.b64encode(group_id).decode('ascii')\n        groups = self.m[\"groups\"]\n        for g in groups:\n            if (g[\"group_id\"] == group_id_base64):\n                return g\n        return None", "response": "return the group with given group_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_group_name_nonetrick(self, group_name = None):\n        groups = self.m[\"groups\"]\n        if (len(groups) == 0):\n            raise Exception(\"Cannot find any groups in metadata\")\n        if (not group_name):\n            if (len(groups) > 1):\n                raise Exception(\"We have more than one payment group in metadata, so group_name should be specified\")\n            return groups[0][\"group_name\"]\n        return group_name", "response": "Get the group name of the nonetrick payment group."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npublishing a tar from protodir and return base58 encoded ipfs hash", "response": "def publish_proto_in_ipfs(ipfs_client, protodir):\n    \"\"\"\n    make tar from protodir/*proto, and publish this tar in ipfs\n    return base58 encoded ipfs hash\n    \"\"\"\n    \n    if (not os.path.isdir(protodir)):\n        raise Exception(\"Directory %s doesn't exists\"%protodir)\n\n    files = glob.glob(os.path.join(protodir, \"*.proto\"))\n\n    if (len(files) == 0):\n        raise Exception(\"Cannot find any %s files\"%(os.path.join(protodir, \"*.proto\")) )\n\n    # We are sorting files before we add them to the .tar since an archive containing the same files in a different\n    # order will produce a different content hash;\n    files.sort()\n        \n    tarbytes  = io.BytesIO()        \n    tar       = tarfile.open(fileobj=tarbytes, mode=\"w\")\n    for f in files:\n        tar.add(f, os.path.basename(f))\n    tar.close()\n    return ipfs_client.add_bytes(tarbytes.getvalue())"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets file from ipfs and check the hash", "response": "def get_from_ipfs_and_checkhash(ipfs_client, ipfs_hash_base58, validate=True):\n    \"\"\"\n    Get file from ipfs\n    We must check the hash becasue we cannot believe that ipfs_client wasn't been compromise\n    \"\"\"\n    if validate:\n        from snet_cli.resources.proto.unixfs_pb2 import Data\n        from snet_cli.resources.proto.merckledag_pb2 import MerkleNode\n\n        # No nice Python library to parse ipfs blocks, so do it ourselves.\n        block_data = ipfs_client.block_get(ipfs_hash_base58)\n        mn = MerkleNode()\n        mn.ParseFromString(block_data)\n        unixfs_data = Data()\n        unixfs_data.ParseFromString(mn.Data)\n        assert unixfs_data.Type == unixfs_data.DataType.Value('File'), \"IPFS hash must be a file\"\n        data = unixfs_data.Data\n        \n        # multihash has a badly registered base58 codec, overwrite it...\n        multihash.CodecReg.register('base58', base58.b58encode, base58.b58decode)\n        # create a multihash object from our ipfs hash\n        mh = multihash.decode(ipfs_hash_base58.encode('ascii'), 'base58')\n        \n        # Convenience method lets us directly use a multihash to verify data\n        if not mh.verify(block_data):\n            raise Exception(\"IPFS hash mismatch with data\")\n    else:\n        data = ipfs_client.cat(ipfs_hash_base58)\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef hash_to_bytesuri(s):\n    # TODO: we should pad string with zeros till closest 32 bytes word because of a bug in processReceipt (in snet_cli.contract.process_receipt)\n    s = \"ipfs://\" + s\n    return s.encode(\"ascii\").ljust(32 * (len(s)//32 + 1), b\"\\0\")", "response": "Convert in and from bytes uri format used in Registry contract\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef safe_extract_proto_from_ipfs(ipfs_client, ipfs_hash, protodir):\n    spec_tar = get_from_ipfs_and_checkhash(ipfs_client, ipfs_hash)\n    with tarfile.open(fileobj=io.BytesIO(spec_tar)) as f:\n        for m in f.getmembers():\n            if (os.path.dirname(m.name) != \"\"):\n                raise Exception(\"tarball has directories. We do not support it.\")\n            if (not m.isfile()):\n                raise Exception(\"tarball contains %s which is not a files\"%m.name)\n            fullname = os.path.join(protodir, m.name)\n            if (os.path.exists(fullname)):\n                raise Exception(\"%s already exists.\"%fullname)\n        # now it is safe to call extractall\n        f.extractall(protodir)", "response": "Extract the protocol from the given ipfs_client and protodir."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_stub_and_request_classes(self, service_name):\n        # Compile protobuf if needed\n        codegen_dir = Path.home().joinpath(\".snet\", \"mpe_client\", \"control_service\")\n        proto_dir   = Path(__file__).absolute().parent.joinpath(\"resources\", \"proto\")\n        if (not codegen_dir.joinpath(\"control_service_pb2.py\").is_file()):\n            compile_proto(proto_dir, codegen_dir, proto_file = \"control_service.proto\")\n\n        stub_class, request_class, _ = import_protobuf_from_dir(codegen_dir, service_name)\n        return stub_class, request_class", "response": "Imports the protobuf and returns stub and request class for the given service name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nclaim all pending payments in progress and channels.", "response": "def _claim_in_progress_and_claim_channels(self, grpc_channel, channels):\n        \"\"\" Claim all 'pending' payments in progress and after we claim given channels \"\"\"\n        # first we get the list of all 'payments in progress' in case we 'lost' some payments.\n        payments = self._call_GetListInProgress(grpc_channel)\n        if (len(payments) > 0):\n            self._printout(\"There are %i payments in 'progress' (they haven't been claimed in blockchain). We will claim them.\"%len(payments))\n            self._blockchain_claim(payments)\n        payments = self._start_claim_channels(grpc_channel, channels)\n        self._blockchain_claim(payments)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_default_config(self):\n        # make config directory with the minimal possible permission\n        self._config_file.parent.mkdir(mode=0o700, exist_ok=True)\n        self[\"network.kovan\"]   = {\"default_eth_rpc_endpoint\": \"https://kovan.infura.io\",   \"default_gas_price\" : \"medium\"}\n        self[\"network.mainnet\"] = {\"default_eth_rpc_endpoint\": \"https://mainnet.infura.io\", \"default_gas_price\" : \"medium\"}\n        self[\"network.ropsten\"] = {\"default_eth_rpc_endpoint\": \"https://ropsten.infura.io\", \"default_gas_price\" : \"medium\"}\n        self[\"network.rinkeby\"] = {\"default_eth_rpc_endpoint\": \"https://rinkeby.infura.io\", \"default_gas_price\" : \"medium\"}\n        self[\"ipfs\"] = {\"default_ipfs_endpoint\": \"http://ipfs.singularitynet.io:80\"}\n        self[\"session\"] = {\n        \"network\": \"kovan\" }\n        self._persist()\n        print(\"We've created configuration file with default values in: %s\\n\"%str(self._config_file))", "response": "Create default configuration file if it does not exist"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nswitches the payload encoding to JSON for GRPC call", "response": "def switch_to_json_payload_encoding(call_fn, response_class):\n    \"\"\" Switch payload encoding to JSON for GRPC call \"\"\"\n    def json_serializer(*args, **kwargs):\n        return bytes(json_format.MessageToJson(args[0], True, preserving_proto_field_name=True), \"utf-8\")\n    def json_deserializer(*args, **kwargs):\n        resp = response_class()\n        json_format.Parse(args[0], resp, True)\n        return resp\n    call_fn._request_serializer    = json_serializer\n    call_fn._response_deserializer = json_deserializer"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntransform the call parameters into a dictionary of base64 - encoded and base64 - decoded ones.", "response": "def _transform_call_params(self, params):\n        \"\"\"\n        possible modifiers: file, b64encode, b64decode\n        format:             modifier1@modifier2@...modifierN@k_final\n        \"\"\"\n        rez = {}\n        for k, v in params.items():\n            if isinstance(v, dict):\n                v = self._transform_call_params(v)\n                k_final = k\n            else:\n                # k = modifier1@modifier2@...modifierN@k_final\n                k_split = k.split(\"@\")\n                k_final = k_split[-1]\n                k_mods  = k_split[:-1]\n                for m in k_mods:\n                    if (m == \"file\"):\n                        with open(v, 'rb') as f:\n                            v = f.read()\n                    elif (m == \"b64encode\"):\n                        v = base64.b64encode(v)\n                    elif (m == \"b64decode\"):\n                        v = base64.b64decode(v)\n                    else:\n                        raise Exception(\"Unknown modifier ('%s') in call parameters. Possible modifiers: file, b64encode, b64decode\"%m)\n            rez[k_final] = v\n        return rez"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_channel_state_statelessly(self, grpc_channel, channel_id):\n        server     = self._get_channel_state_from_server    (grpc_channel, channel_id)\n        blockchain = self._get_channel_state_from_blockchain(              channel_id)\n\n        if (server[\"current_nonce\"] == blockchain[\"nonce\"]):\n            unspent_amount = blockchain[\"value\"] - server[\"current_signed_amount\"]\n        else:\n            unspent_amount = None # in this case we cannot securely define unspent_amount yet\n\n        return (server[\"current_nonce\"], server[\"current_signed_amount\"], unspent_amount)", "response": "Get the state of the channel by securely combine the server and blockchain and return the result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef print_agi_and_mpe_balances(self):\n        if (self.args.account):\n            account = self.args.account\n        else:\n            account = self.ident.address\n        eth_wei  = self.w3.eth.getBalance(account)\n        agi_cogs = self.call_contract_command(\"SingularityNetToken\", \"balanceOf\", [account])\n        mpe_cogs = self.call_contract_command(\"MultiPartyEscrow\",    \"balances\",  [account])\n\n        # we cannot use _pprint here because it doesn't conserve order yet\n        self._printout(\"    account: %s\"%account)\n        self._printout(\"    ETH: %s\"%self.w3.fromWei(eth_wei, 'ether'))\n        self._printout(\"    AGI: %s\"%cogs2stragi(agi_cogs))\n        self._printout(\"    MPE: %s\"%cogs2stragi(mpe_cogs))", "response": "Print balance of ETH AGI and MPE wallet"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef publish_proto_in_ipfs(self):\n        ipfs_hash_base58 = utils_ipfs.publish_proto_in_ipfs(self._get_ipfs_client(), self.args.protodir)\n        self._printout(ipfs_hash_base58)", "response": "Publish proto files in ipfs and print hash"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef publish_proto_metadata_update(self):\n        metadata = load_mpe_service_metadata(self.args.metadata_file)\n        ipfs_hash_base58 = utils_ipfs.publish_proto_in_ipfs(self._get_ipfs_client(), self.args.protodir)\n        metadata.set_simple_field(\"model_ipfs_hash\", ipfs_hash_base58)\n        metadata.save_pretty(self.args.metadata_file)", "response": "Publish protobuf model in ipfs and update existing metadata file"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef metadata_add_endpoints(self):\n        metadata = load_mpe_service_metadata(self.args.metadata_file)\n        group_name = metadata.get_group_name_nonetrick(self.args.group_name)\n        for endpoint in self.args.endpoints:\n            metadata.add_endpoint(group_name, endpoint)\n        metadata.save_pretty(self.args.metadata_file)", "response": "Metadata add endpoints to the group"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef metadata_remove_all_endpoints(self):\n        metadata = load_mpe_service_metadata(self.args.metadata_file)\n        metadata.remove_all_endpoints()\n        metadata.save_pretty(self.args.metadata_file)", "response": "Remove all endpoints from all groups"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds description to metadata file", "response": "def metadata_add_description(self):\n        \"\"\" Metadata: add description \"\"\"\n        service_description = {}\n        if (self.args.json):\n            service_description = json.loads(self.args.json)\n        if (self.args.url):\n            if \"url\" in service_description:\n                raise Exception(\"json service description already contains url field\")\n            service_description[\"url\"] = self.args.url\n        if (self.args.description):\n            if \"description\" in service_description:\n                raise Exception(\"json service description already contains description field\")\n            service_description[\"description\"] = self.args.description\n        metadata = load_mpe_service_metadata(self.args.metadata_file)\n        # merge with old service_description if necessary\n        if (\"service_description\" in metadata):\n            service_description = {**metadata[\"service_description\"], **service_description}\n        metadata.set_simple_field(\"service_description\", service_description)\n        metadata.save_pretty(self.args.metadata_file)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets persistent storage for mpe", "response": "def _get_persistent_mpe_dir(self):\n        \"\"\" get persistent storage for mpe \"\"\"\n        mpe_address      = self.get_mpe_address().lower()\n        registry_address = self.get_registry_address().lower()\n        return Path.home().joinpath(\".snet\", \"mpe_client\", \"%s_%s\"%(mpe_address, registry_address))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_initialized_channels_dict_for_service(self, org_id, service_id):\n        '''return {channel_id: channel}'''\n        fn = self._get_channels_info_file(org_id, service_id)\n        if (os.path.isfile(fn)):\n            return pickle.load( open( fn, \"rb\" ) )\n        else:\n            return {}", "response": "Returns a dictionary of channel_id = > channel"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_initialized_channels_for_service(self, org_id, service_id):\n        '''return [channel]'''\n        channels_dict = self._get_initialized_channels_dict_for_service(org_id, service_id)\n        return list(channels_dict.values())", "response": "Returns a list of all channels that have been initialized for the given org_id and service_id."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks that MultiPartyEscrow address from metadata is correct", "response": "def _check_mpe_address_metadata(self, metadata):\n        \"\"\" we make sure that MultiPartyEscrow address from metadata is correct \"\"\"\n        mpe_address = self.get_mpe_address()\n        if (str(mpe_address).lower() != str(metadata[\"mpe_address\"]).lower()):\n            raise Exception(\"MultiPartyEscrow contract address from metadata %s do not correspond to current MultiPartyEscrow address %s\"%(metadata[\"mpe_address\"], mpe_address))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_expiration_from_args(self):\n        current_block = self.ident.w3.eth.blockNumber\n        s = self.args.expiration\n        if (s.startswith(\"+\") and s.endswith(\"days\")):\n            rez = current_block + int(s[1:-4]) * 4 * 60 * 24\n        elif (s.startswith(\"+\") and s.endswith(\"blocks\")):\n            rez = current_block + int(s[1:-6])\n        else:\n            rez = int(s)\n        if (rez > current_block + 1036800 and not self.args.force):\n            d = (rez - current_block) // (4 * 60 * 24)\n            raise Exception(\"You try to set expiration time too far in the future: approximately %i days. \"%d +\n                            \"Set --force parameter if your really want to do it.\")\n        return rez", "response": "read expiration time from args. expiration\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _smart_get_initialized_channel_for_service(self, metadata, filter_by, is_try_initailize = True):\n        '''\n         - filter_by can be sender or signer\n        '''\n        channels = self._get_initialized_channels_for_service(self.args.org_id, self.args.service_id)\n        group_id = metadata.get_group_id(self.args.group_name)\n        channels = [c for c in channels if c[filter_by].lower() == self.ident.address.lower() and c[\"groupId\"] == group_id]\n\n        if (len(channels) == 0 and is_try_initailize):\n           # this will work only in simple case where signer == sender\n           self._initialize_already_opened_channel(metadata, self.ident.address, self.ident.address)\n           return self._smart_get_initialized_channel_for_service(metadata, filter_by, is_try_initailize = False)\n\n        if (len(channels) == 0):\n            raise Exception(\"Cannot find initialized channel for service with org_id=%s service_id=%s and signer=%s\"%(self.args.org_id, self.args.service_id, self.ident.address))\n        if (self.args.channel_id is None):\n            if (len(channels) > 1):\n                channel_ids = [channel[\"channelId\"] for channel in channels]\n                raise Exception(\"We have several initialized channel: %s. You should use --channel-id to select one\"%str(channel_ids))\n            return channels[0]\n        for channel in channels:\n            if (channel[\"channelId\"] == self.args.channel_id):\n                return channel\n        raise Exception(\"Channel %i has not been initialized or your are not the sender/signer of it\"%self.args.channel_id)", "response": "Get the first initialized channel for a given service."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a dict of lists of all initialized channels.", "response": "def _get_all_initialized_channels(self):\n        \"\"\" return dict of lists  rez[(<org_id>, <service_id>)] = [(channel_id, channel_info)] \"\"\"\n        channels_dict = defaultdict(list)\n        for service_base_dir in self._get_persistent_mpe_dir().glob(\"*/*\"):\n            org_id     = service_base_dir.parent.name\n            service_id = service_base_dir.name\n            channels   = self._get_initialized_channels_for_service(org_id, service_id)\n            if (channels):\n                channels_dict[(org_id, service_id)] = channels\n        return channels_dict"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_all_filtered_channels(self, topics_without_signature):\n        mpe_address     = self.get_mpe_address()\n        event_signature = self.ident.w3.sha3(text=\"ChannelOpen(uint256,uint256,address,address,address,bytes32,uint256,uint256)\").hex()\n        topics = [event_signature] + topics_without_signature\n        logs = self.ident.w3.eth.getLogs({\"fromBlock\" : self.args.from_block, \"address\"   : mpe_address, \"topics\"    : topics})\n        abi           = get_contract_def(\"MultiPartyEscrow\")\n        event_abi     = abi_get_element_by_name(abi, \"ChannelOpen\")\n        channels_ids  = [get_event_data(event_abi, l)[\"args\"][\"channelId\"] for l in logs]\n        return channels_ids", "response": "get all filtered channels from blockchain logs"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_contract_address(cmd, contract_name, error_message = None):\n\n    # try to get from command line argument at or contractname_at\n    a = \"at\"\n    if (hasattr(cmd.args, a) and getattr(cmd.args, a)):\n        return cmd.w3.toChecksumAddress( getattr(cmd.args, a) )\n\n    # try to get from command line argument contractname_at\n    a = \"%s_at\"%contract_name.lower()\n    if (hasattr(cmd.args, a) and getattr(cmd.args, a)):\n        return cmd.w3.toChecksumAddress( getattr(cmd.args, a) )\n\n\n    # try to get from current session configuration\n    rez = cmd.config.get_session_field(\"current_%s_at\"%(contract_name.lower()), exception_if_not_found = False)\n    if rez:\n        return cmd.w3.toChecksumAddress(rez)\n\n    error_message = error_message or \"Fail to read %s address from \\\"networks\\\", you should specify address by yourself via --%s_at parameter\"%(contract_name, contract_name.lower())\n    # try to take address from networks\n    return read_default_contract_address(w3=cmd.w3, contract_name=contract_name)", "response": "Try to get a contract address from the different sources"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_field_from_args_or_session(config, args, field_name):\n    rez = getattr(args, field_name, None)\n    #type(rez) can be int in case of wallet-index, so we cannot make simply if(rez)\n    if (rez != None):\n        return rez\n    rez = config.get_session_field(\"default_%s\"%field_name, exception_if_not_found=False)\n    if (rez):\n        return rez\n    raise Exception(\"Fail to get default_%s from config, should specify %s via --%s parameter\"%(field_name, field_name, field_name.replace(\"_\",\"-\")))", "response": "Try to get field_name from args or session"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef abi_get_element_by_name(abi, name):\n    if (abi and \"abi\" in abi):\n        for a in abi[\"abi\"]:\n            if (\"name\" in a and a[\"name\"] == name):\n                return a\n    return None", "response": "Return element of a given abi by name"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_valid_endpoint(url):\n    try:\n        result = urlparse(url)\n        if result.port:\n            _port = int(result.port)\n        return (\n            all([result.scheme, result.netloc]) and\n            result.scheme in ['http', 'https']\n        )\n    except ValueError:\n        return False", "response": "Check if the url is a valid URL."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nopens a gRPC channel for the given endpoint.", "response": "def open_grpc_channel(endpoint):\n    \"\"\"\n       open grpc channel:\n           - for http://  we open insecure_channel\n           - for https:// we open secure_channel (with default credentials)\n           - without prefix we open insecure_channel\n    \"\"\"\n    if (endpoint.startswith(\"https://\")):\n        return grpc.secure_channel(remove_http_https_prefix(endpoint), grpc.ssl_channel_credentials())\n    return grpc.insecure_channel(remove_http_https_prefix(endpoint))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_repo(self, repo_name, description=None):\n        req = proto.CreateRepoRequest(repo=proto.Repo(name=repo_name), description=description)\n        self.stub.CreateRepo(req, metadata=self.metadata)", "response": "Creates a new Repo object in PFS with the given name and optional description."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn info about a specific Repo.", "response": "def inspect_repo(self, repo_name):\n        \"\"\"\n        Returns info about a specific Repo.\n        \n        Params:\n        * repo_name: Name of the repo.\n        \"\"\"\n        req = proto.InspectRepoRequest(repo=proto.Repo(name=repo_name))\n        res = self.stub.InspectRepo(req, metadata=self.metadata)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_repo(self):\n        req = proto.ListRepoRequest()\n        res = self.stub.ListRepo(req, metadata=self.metadata)\n        if hasattr(res, 'repo_info'):\n            return res.repo_info\n        return []", "response": "Returns info about all Repos."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes a repository and reclaims the storage space it was using.", "response": "def delete_repo(self, repo_name=None, force=False, all=False):\n        \"\"\"\n        Deletes a repo and reclaims the storage space it was using.\n\n        Params:\n        * repo_name: The name of the repo.\n        * force: If set to true, the repo will be removed regardless of\n        errors. This argument should be used with care.\n        * all: Delete all repos.\n        \"\"\"\n        if not all:\n            if repo_name:\n                req = proto.DeleteRepoRequest(repo=proto.Repo(name=repo_name), force=force)\n                self.stub.DeleteRepo(req, metadata=self.metadata)\n            else:\n                raise ValueError(\"Either a repo_name or all=True needs to be provided\")\n        else:\n            if not repo_name:\n                req = proto.DeleteRepoRequest(force=force, all=all)\n                self.stub.DeleteRepo(req, metadata=self.metadata)\n            else:\n                raise ValueError(\"Cannot specify a repo_name if all=True\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstart a commit on a Repo.", "response": "def start_commit(self, repo_name, branch=None, parent=None, description=None):\n        \"\"\"\n        Begins the process of committing data to a Repo. Once started you can\n        write to the Commit with PutFile and when all the data has been\n        written you must finish the Commit with FinishCommit. NOTE, data is\n        not persisted until FinishCommit is called. A Commit object is\n        returned.\n\n        Params:\n        * repo_name: The name of the repo.\n        * branch: A more convenient way to build linear chains of commits.\n        When a commit is started with a non-empty branch the value of branch\n        becomes an alias for the created Commit. This enables a more intuitive\n        access pattern. When the commit is started on a branch the previous\n        head of the branch is used as the parent of the commit.\n        * parent: Specifies the parent Commit, upon creation the new Commit\n        will appear identical to the parent Commit, data can safely be added\n        to the new commit without affecting the contents of the parent Commit.\n        You may pass \"\" as parentCommit in which case the new Commit will have\n        no parent and will initially appear empty.\n        * description: (optional) explanation of the commit for clarity.\n        \"\"\"\n        req = proto.StartCommitRequest(parent=proto.Commit(repo=proto.Repo(name=repo_name), id=parent), branch=branch,\n                                       description=description)\n        res = self.stub.StartCommit(req, metadata=self.metadata)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinishing the commit of the current object.", "response": "def finish_commit(self, commit):\n        \"\"\"\n        Ends the process of committing data to a Repo and persists the\n        Commit. Once a Commit is finished the data becomes immutable and\n        future attempts to write to it with PutFile will error.\n\n        Params:\n        * commit: A tuple, string, or Commit object representing the commit.\n        \"\"\"\n        req = proto.FinishCommitRequest(commit=commit_from(commit))\n        res = self.stub.FinishCommit(req, metadata=self.metadata)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef commit(self, repo_name, branch=None, parent=None, description=None):\n        commit = self.start_commit(repo_name, branch, parent, description)\n        try:\n            yield commit\n        except Exception as e:\n            print(\"An exception occurred during an open commit. \"\n                  \"Trying to finish it (Currently a commit can't be cancelled)\")\n            raise e\n        finally:\n            self.finish_commit(commit)", "response": "A context manager for doing stuff inside a commit."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning info about a specific Commit.", "response": "def inspect_commit(self, commit):\n        \"\"\"\n        Returns info about a specific Commit.\n\n        Params:\n        * commit: A tuple, string, or Commit object representing the commit.\n        \"\"\"\n        req = proto.InspectCommitRequest(commit=commit_from(commit))\n        return self.stub.InspectCommit(req, metadata=self.metadata)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of CommitInfo objects.", "response": "def list_commit(self, repo_name, to_commit=None, from_commit=None, number=0):\n        \"\"\"\n        Gets a list of CommitInfo objects.\n\n        Params:\n        * repo_name: If only `repo_name` is given, all commits in the repo are\n        returned.\n        * to_commit: Optional. Only the ancestors of `to`, including `to`\n        itself, are considered.\n        * from_commit: Optional. Only the descendants of `from`, including\n        `from` itself, are considered.\n        * number: Optional. Determines how many commits are returned.  If\n        `number` is 0, all commits that match the aforementioned criteria are\n        returned.\n        \"\"\"\n        req = proto.ListCommitRequest(repo=proto.Repo(name=repo_name), number=number)\n        if to_commit is not None:\n            req.to.CopyFrom(commit_from(to_commit))\n        if from_commit is not None:\n            getattr(req, 'from').CopyFrom(commit_from(from_commit))\n        res = self.stub.ListCommit(req, metadata=self.metadata)\n        if hasattr(res, 'commit_info'):\n            return res.commit_info\n        return []"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete_commit(self, commit):\n        req = proto.DeleteCommitRequest(commit=commit_from(commit))\n        self.stub.DeleteCommit(req, metadata=self.metadata)", "response": "Deletes a commit.\n\n        Params:\n        * commit: A tuple, string, or Commit object representing the commit."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef flush_commit(self, commits, repos=tuple()):\n        req = proto.FlushCommitRequest(commit=[commit_from(c) for c in commits],\n                                       to_repo=[proto.Repo(name=r) for r in repos])\n        res = self.stub.FlushCommit(req, metadata=self.metadata)\n        return res", "response": "Flushes the specified commits to the specified repos."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef subscribe_commit(self, repo_name, branch, from_commit_id=None):\n        repo = proto.Repo(name=repo_name)\n        req = proto.SubscribeCommitRequest(repo=repo, branch=branch)\n        if from_commit_id is not None:\n            getattr(req, 'from').CopyFrom(proto.Commit(repo=repo, id=from_commit_id))\n        res = self.stub.SubscribeCommit(req, metadata=self.metadata)\n        return res", "response": "SubscribeCommit is like ListCommit but it keeps listening for commits as\n        they come in. This returns an iterator Commit objects.\n\n        Params:\n        * repo_name: Name of the repo.\n        * branch: Branch to subscribe to.\n        * from_commit_id: Optional. Only commits created since this commit\n        are returned."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_branch(self, repo_name):\n        req = proto.ListBranchRequest(repo=proto.Repo(name=repo_name))\n        res = self.stub.ListBranch(req, metadata=self.metadata)\n        if hasattr(res, 'branch_info'):\n            return res.branch_info\n        return []", "response": "Returns a list of active Branch objects on a Repo."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_branch(self, commit, branch_name):\n        res = proto.SetBranchRequest(commit=commit_from(commit), branch=branch_name)\n        self.stub.SetBranch(res, metadata=self.metadata)", "response": "Sets a commit and its ancestors as a branch."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting a branch from the repository.", "response": "def delete_branch(self, repo_name, branch_name):\n        \"\"\"\n        Deletes a branch, but leaves the commits themselves intact. In other\n        words, those commits can still be accessed via commit IDs and other\n        branches they happen to be on.\n\n        Params:\n        * repo_name: The name of the repo.\n        * branch_name: The name of the branch to delete.\n        \"\"\"\n        res = proto.DeleteBranchRequest(repo=Repo(name=repo_name), branch=branch_name)\n        self.stub.DeleteBranch(res, metadata=self.metadata)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef put_file_bytes(self, commit, path, value, delimiter=proto.NONE,\n                       target_file_datums=0, target_file_bytes=0, overwrite_index=None):\n        \"\"\"\n        Uploads a binary bytes array as file(s) in a certain path.\n\n        Params:\n        * commit: A tuple, string, or Commit object representing the commit.\n        * path: Path in the repo the file(s) will be written to.\n        * value: The file contents as bytes, represented as a file-like\n        object, bytestring, or iterator of bytestrings.\n        * delimiter: Optional. causes data to be broken up into separate files\n        with `path` as a prefix.\n        * target_file_datums: Optional. Specifies the target number of datums\n        in each written file. It may be lower if data does not split evenly,\n        but will never be higher, unless the value is 0.\n        * target_file_bytes: Specifies the target number of bytes in each\n        written file, files may have more or fewer bytes than the target.\n        \"\"\"\n\n        overwrite_index_proto = proto.OverwriteIndex(index=overwrite_index) if overwrite_index is not None else None\n\n        if hasattr(value, \"read\"):\n            def wrap(value):\n                for i in itertools.count():\n                    chunk = value.read(BUFFER_SIZE)\n\n                    if len(chunk) == 0:\n                        return\n\n                    if i == 0:\n                        yield proto.PutFileRequest(\n                            file=proto.File(commit=commit_from(commit), path=path),\n                            value=chunk,\n                            delimiter=delimiter,\n                            target_file_datums=target_file_datums,\n                            target_file_bytes=target_file_bytes,\n                            overwrite_index=overwrite_index_proto\n                        )\n                    else:\n                        yield proto.PutFileRequest(value=chunk)\n        elif isinstance(value, collections.Iterable) and not isinstance(value, (six.string_types, six.binary_type)):\n            def wrap(value):\n                for i, chunk in enumerate(value):\n                    if i == 0:\n                        yield proto.PutFileRequest(\n                            file=proto.File(commit=commit_from(commit), path=path),\n                            value=chunk,\n                            delimiter=delimiter,\n                            target_file_datums=target_file_datums,\n                            target_file_bytes=target_file_bytes,\n                            overwrite_index=overwrite_index_proto\n                        )\n                    else:\n                        yield proto.PutFileRequest(value=chunk)\n        else:\n            def wrap(value):\n                yield proto.PutFileRequest(\n                    file=proto.File(commit=commit_from(commit), path=path),\n                    value=value[:BUFFER_SIZE],\n                    delimiter=delimiter,\n                    target_file_datums=target_file_datums,\n                    target_file_bytes=target_file_bytes,\n                    overwrite_index=overwrite_index_proto\n                )\n\n                for i in range(BUFFER_SIZE, len(value), BUFFER_SIZE):\n                    yield proto.PutFileRequest(\n                        value=value[i:i + BUFFER_SIZE],\n                        overwrite_index=overwrite_index_proto\n                    )\n\n        self.stub.PutFile(wrap(value), metadata=self.metadata)", "response": "Uploads a binary file in a certain path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef put_file_url(self, commit, path, url, recursive=False):\n        req = iter([\n            proto.PutFileRequest(\n                file=proto.File(commit=commit_from(commit), path=path),\n                url=url,\n                recursive=recursive\n            )\n        ])\n        self.stub.PutFile(req, metadata=self.metadata)", "response": "This method is used to put a file using the content found at a URL."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns an iterator of the contents of a file at a specific Commit.", "response": "def get_file(self, commit, path, offset_bytes=0, size_bytes=0, extract_value=True):\n        \"\"\"\n        Returns an iterator of the contents contents of a file at a specific Commit.\n\n        Params:\n        * commit: A tuple, string, or Commit object representing the commit.\n        * path: The path of the file.\n        * offset_bytes: Optional. specifies a number of bytes that should be\n        skipped in the beginning of the file.\n        * size_bytes: Optional. limits the total amount of data returned, note\n        you will get fewer bytes than size if you pass a value larger than the\n        size of the file. If size is set to 0 then all of the data will be\n        returned.\n        * extract_value: If True, then an ExtractValueIterator will be return,\n        which will iterate over the bytes of the file. If False, then the\n        protobuf response iterator will return.\n        \"\"\"\n        req = proto.GetFileRequest(\n            file=proto.File(commit=commit_from(commit), path=path),\n            offset_bytes=offset_bytes,\n            size_bytes=size_bytes\n        )\n        res = self.stub.GetFile(req, metadata=self.metadata)\n        if extract_value:\n            return ExtractValueIterator(res)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_files(self, commit, paths, recursive=False):\n        filtered_file_infos = []\n        for path in paths:\n            fi = self.inspect_file(commit, path)\n            if fi.file_type == proto.FILE:\n                filtered_file_infos.append(fi)\n            else:\n                filtered_file_infos += self.list_file(commit, path, recursive=recursive)\n\n        filtered_paths = [fi.file.path for fi in filtered_file_infos if fi.file_type == proto.FILE]\n\n        return {path: b''.join(self.get_file(commit, path)) for path in filtered_paths}", "response": "Returns the contents of a list of files at a specific Commit as a dictionary of file paths to data."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns info about a specific file.", "response": "def inspect_file(self, commit, path):\n        \"\"\"\n        Returns info about a specific file.\n\n        Params:\n        * commit: A tuple, string, or Commit object representing the commit.\n        * path: Path to file.\n        \"\"\"\n        req = proto.InspectFileRequest(file=proto.File(commit=commit_from(commit), path=path))\n        res = self.stub.InspectFile(req, metadata=self.metadata)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_file(self, commit, path, recursive=False):\n        req = proto.ListFileRequest(\n            file=proto.File(commit=commit_from(commit), path=path)\n        )\n        res = self.stub.ListFile(req, metadata=self.metadata)\n        file_infos = res.file_info\n\n        if recursive:\n            dirs = [f for f in file_infos if f.file_type == proto.DIR]\n            files = [f for f in file_infos if f.file_type == proto.FILE]\n            return sum([self.list_file(commit, d.file.path, recursive) for d in dirs], files)\n\n        return list(file_infos)", "response": "Returns a list of all files in a directory."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete a file from a Commit.", "response": "def delete_file(self, commit, path):\n        \"\"\"\n        Deletes a file from a Commit. DeleteFile leaves a tombstone in the\n        Commit, assuming the file isn't written to later attempting to get the\n        file from the finished commit will result in not found error. The file\n        will of course remain intact in the Commit's parent.\n\n        Params:\n        * commit: A tuple, string, or Commit object representing the commit.\n        * path: The path to the file.\n        \"\"\"\n        req = proto.DeleteFileRequest(file=proto.File(commit=commit_from(commit), path=path))\n        self.stub.DeleteFile(req, metadata=self.metadata)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhandling the response from an authentication request.", "response": "def handle_authn_response(self, context, internal_response):\n        \"\"\"\n        See super class method satosa.frontends.base.FrontendModule#handle_authn_response\n        :type context: satosa.context.Context\n        :type internal_response: satosa.internal.InternalData\n        :rtype satosa.response.Response\n        \"\"\"\n        return self._handle_authn_response(context, internal_response, self.idp)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef handle_authn_request(self, context, binding_in):\n        return self._handle_authn_request(context, binding_in, self.idp)", "response": "This method is bound to the starting endpoint of the authentication. It is used to handle the authentication request."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef register_endpoints(self, backend_names):\n        self.idp_config = self._build_idp_config_endpoints(\n            self.config[self.KEY_IDP_CONFIG], backend_names)\n        # Create the idp\n        idp_config = IdPConfig().load(copy.deepcopy(self.idp_config), metadata_construction=False)\n        self.idp = Server(config=idp_config)\n        return self._register_endpoints(backend_names)", "response": "Register the backend_names in the frontend module."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate the state data for the current context and the response arguments.", "response": "def _create_state_data(self, context, resp_args, relay_state):\n        \"\"\"\n        Returns a dict containing the state needed in the response flow.\n\n        :type context: satosa.context.Context\n        :type resp_args: dict[str, str | saml2.samlp.NameIDPolicy]\n        :type relay_state: str\n        :rtype: dict[str, dict[str, str] | str]\n\n        :param context: The current context\n        :param resp_args: Response arguments\n        :param relay_state: Request relay state\n        :return: A state as a dict\n        \"\"\"\n        if \"name_id_policy\" in resp_args and resp_args[\"name_id_policy\"] is not None:\n            resp_args[\"name_id_policy\"] = resp_args[\"name_id_policy\"].to_string().decode(\"utf-8\")\n        return {\"resp_args\": resp_args, \"relay_state\": relay_state}"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads a state from state.", "response": "def load_state(self, state):\n        \"\"\"\n        Loads a state from state\n        :type state: satosa.state.State\n        :rtype: dict[str, Any]\n        :param state: The current state\n        :return: The dictionary given by the save_state function\n        \"\"\"\n        state_data = state[self.name]\n        if isinstance(state_data[\"resp_args\"][\"name_id_policy\"], str):\n            state_data[\"resp_args\"][\"name_id_policy\"] = name_id_policy_from_string(\n                state_data[\"resp_args\"][\"name_id_policy\"])\n        return state_data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _validate_config(self, config):\n        required_keys = [\n            self.KEY_IDP_CONFIG,\n            self.KEY_ENDPOINTS,\n        ]\n\n        if not config:\n            raise ValueError(\"No configuration given\")\n\n        for key in required_keys:\n            try:\n                _val = config[key]\n            except KeyError as e:\n                raise ValueError(\"Missing configuration key: %s\" % key) from e", "response": "Validates some parts of the module config\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nhandling the SAML Request from the requester.", "response": "def _handle_authn_request(self, context, binding_in, idp):\n        \"\"\"\n        See doc for handle_authn_request method.\n\n        :type context: satosa.context.Context\n        :type binding_in: str\n        :type idp: saml.server.Server\n        :rtype: satosa.response.Response\n\n        :param context: The current context\n        :param binding_in: The pysaml binding type\n        :param idp: The saml frontend idp server\n        :return: response\n        \"\"\"\n        req_info = idp.parse_authn_request(context.request[\"SAMLRequest\"], binding_in)\n        authn_req = req_info.message\n        satosa_logging(logger, logging.DEBUG, \"%s\" % authn_req, context.state)\n\n        try:\n            resp_args = idp.response_args(authn_req)\n        except SAMLError as e:\n            satosa_logging(logger, logging.ERROR, \"Could not find necessary info about entity: %s\" % e, context.state)\n            return ServiceError(\"Incorrect request from requester: %s\" % e)\n\n        requester = resp_args[\"sp_entity_id\"]\n        context.state[self.name] = self._create_state_data(context, idp.response_args(authn_req),\n                                                           context.request.get(\"RelayState\"))\n\n        subject = authn_req.subject\n        name_id_value = subject.name_id.text if subject else None\n\n        nameid_formats = {\n            \"from_policy\": authn_req.name_id_policy and authn_req.name_id_policy.format,\n            \"from_response\": subject and subject.name_id and subject.name_id.format,\n            \"from_metadata\": (\n                idp.metadata[requester]\n                .get(\"spsso_descriptor\", [{}])[0]\n                .get(\"name_id_format\", [{}])[0]\n                .get(\"text\")\n            ),\n            \"default\": NAMEID_FORMAT_TRANSIENT,\n        }\n\n        name_id_format = (\n            nameid_formats[\"from_policy\"]\n            or (\n                nameid_formats[\"from_response\"] != NAMEID_FORMAT_UNSPECIFIED\n                and nameid_formats[\"from_response\"]\n            )\n            or nameid_formats[\"from_metadata\"]\n            or nameid_formats[\"from_response\"]\n            or nameid_formats[\"default\"]\n        )\n\n        requester_name = self._get_sp_display_name(idp, requester)\n        internal_req = InternalData(\n            subject_id=name_id_value,\n            subject_type=name_id_format,\n            requester=requester,\n            requester_name=requester_name,\n        )\n\n        idp_policy = idp.config.getattr(\"policy\", \"idp\")\n        if idp_policy:\n            internal_req.attributes = self._get_approved_attributes(\n                idp, idp_policy, requester, context.state\n            )\n\n        return self.auth_req_callback_func(context, internal_req)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_approved_attributes(self, idp, idp_policy, sp_entity_id, state):\n        name_format = idp_policy.get_name_form(sp_entity_id)\n        attrconvs = idp.config.attribute_converters\n        idp_policy.acs = attrconvs\n        attribute_filter = []\n        for aconv in attrconvs:\n            if aconv.name_format == name_format:\n                all_attributes = {v: None for v in aconv._fro.values()}\n                attribute_filter = list(idp_policy.restrict(all_attributes, sp_entity_id, idp.metadata).keys())\n                break\n        attribute_filter = self.converter.to_internal_filter(self.attribute_profile, attribute_filter)\n        satosa_logging(logger, logging.DEBUG, \"Filter: %s\" % attribute_filter, state)\n        return attribute_filter", "response": "Returns a list of approved attributes"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _handle_authn_response(self, context, internal_response, idp):\n        request_state = self.load_state(context.state)\n\n        resp_args = request_state[\"resp_args\"]\n        sp_entity_id = resp_args[\"sp_entity_id\"]\n        internal_response.attributes = self._filter_attributes(\n            idp, internal_response, context)\n        ava = self.converter.from_internal(\n            self.attribute_profile, internal_response.attributes)\n\n        auth_info = {}\n        if self.acr_mapping:\n            auth_info[\"class_ref\"] = self.acr_mapping.get(\n                internal_response.auth_info.issuer, self.acr_mapping[\"\"])\n        else:\n            auth_info[\"class_ref\"] = internal_response.auth_info.auth_class_ref\n\n        auth_info[\"authn_auth\"] = internal_response.auth_info.issuer\n\n        if self.custom_attribute_release:\n            custom_release = util.get_dict_defaults(\n                self.custom_attribute_release,\n                internal_response.auth_info.issuer,\n                sp_entity_id)\n            attributes_to_remove = custom_release.get(\"exclude\", [])\n            for k in attributes_to_remove:\n                ava.pop(k, None)\n\n        nameid_value = internal_response.subject_id\n        nameid_format = subject_type_to_saml_nameid_format(\n            internal_response.subject_type\n        )\n\n        # If the backend did not receive a SAML <NameID> and so\n        # name_id is set to None then do not create a NameID instance.\n        # Instead pass None as the name name_id to the IdP server\n        # instance and it will use its configured policy to construct\n        # a <NameID>, with the default to create a transient <NameID>.\n        name_id = None if not nameid_value else NameID(\n            text=nameid_value,\n            format=nameid_format,\n            sp_name_qualifier=None,\n            name_qualifier=None,\n        )\n\n        dbgmsg = \"returning attributes %s\" % json.dumps(ava)\n        satosa_logging(logger, logging.DEBUG, dbgmsg, context.state)\n\n        policies = self.idp_config.get(\n            'service', {}).get('idp', {}).get('policy', {})\n        sp_policy = policies.get('default', {})\n        sp_policy.update(policies.get(sp_entity_id, {}))\n\n        sign_assertion = sp_policy.get('sign_assertion', False)\n        sign_response = sp_policy.get('sign_response', True)\n        sign_alg = sp_policy.get('sign_alg', 'SIG_RSA_SHA256')\n        digest_alg = sp_policy.get('digest_alg', 'DIGEST_SHA256')\n\n        # Construct arguments for method create_authn_response\n        # on IdP Server instance\n        args = {\n            'identity'      : ava,\n            'name_id'       : name_id,\n            'authn'         : auth_info,\n            'sign_response' : sign_response,\n            'sign_assertion': sign_assertion,\n        }\n\n        # Add the SP details\n        args.update(**resp_args)\n\n        try:\n            args['sign_alg'] = getattr(xmldsig, sign_alg)\n        except AttributeError as e:\n            errmsg = \"Unsupported sign algorithm %s\" % sign_alg\n            satosa_logging(logger, logging.ERROR, errmsg, context.state)\n            raise Exception(errmsg) from e\n        else:\n            dbgmsg = \"signing with algorithm %s\" % args['sign_alg']\n            satosa_logging(logger, logging.DEBUG, dbgmsg, context.state)\n\n        try:\n            args['digest_alg'] = getattr(xmldsig, digest_alg)\n        except AttributeError as e:\n            errmsg = \"Unsupported digest algorithm %s\" % digest_alg\n            satosa_logging(logger, logging.ERROR, errmsg, context.state)\n            raise Exception(errmsg) from e\n        else:\n            dbgmsg = \"using digest algorithm %s\" % args['digest_alg']\n            satosa_logging(logger, logging.DEBUG, dbgmsg, context.state)\n\n        resp = idp.create_authn_response(**args)\n        http_args = idp.apply_binding(\n            resp_args[\"binding\"], str(resp), resp_args[\"destination\"],\n            request_state[\"relay_state\"], response=True)\n\n        # Set the common domain cookie _saml_idp if so configured.\n        if self.config.get('common_domain_cookie'):\n            self._set_common_domain_cookie(internal_response, http_args, context)\n\n        del context.state[self.name]\n        return make_saml_response(resp_args[\"binding\"], http_args)", "response": "Handles the AuthnResponse message."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _handle_backend_error(self, exception, idp):\n        loaded_state = self.load_state(exception.state)\n        relay_state = loaded_state[\"relay_state\"]\n        resp_args = loaded_state[\"resp_args\"]\n        error_resp = idp.create_error_response(resp_args[\"in_response_to\"],\n                                               resp_args[\"destination\"],\n                                               Exception(exception.message))\n        http_args = idp.apply_binding(resp_args[\"binding\"], str(error_resp), resp_args[\"destination\"], relay_state,\n                                      response=True)\n\n        satosa_logging(logger, logging.DEBUG, \"HTTPargs: %s\" % http_args, exception.state)\n        return make_saml_response(resp_args[\"binding\"], http_args)", "response": "Handle an error in the backend."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _register_endpoints(self, providers):\n        url_map = []\n\n        for endp_category in self.endpoints:\n            for binding, endp in self.endpoints[endp_category].items():\n                valid_providers = \"\"\n                for provider in providers:\n                    valid_providers = \"{}|^{}\".format(valid_providers, provider)\n                valid_providers = valid_providers.lstrip(\"|\")\n                parsed_endp = urlparse(endp)\n                url_map.append((\"(%s)/%s$\" % (valid_providers, parsed_endp.path),\n                                functools.partial(self.handle_authn_request, binding_in=binding)))\n\n        if self.expose_entityid_endpoint():\n            parsed_entity_id = urlparse(self.idp.config.entityid)\n            url_map.append((\"^{0}\".format(parsed_entity_id.path[1:]),\n                            self._metadata_endpoint))\n\n        return url_map", "response": "Register methods to endpoints\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds the final frontend module config with the endpoints for each provider.", "response": "def _build_idp_config_endpoints(self, config, providers):\n        \"\"\"\n        Builds the final frontend module config\n\n        :type config: dict[str, Any]\n        :type providers: list[str]\n        :rtype: dict[str, Any]\n\n        :param config: The module config\n        :param providers: A list of backend names\n        :return: The final config\n        \"\"\"\n        # Add an endpoint to each provider\n        idp_endpoints = []\n        for endp_category in self.endpoints:\n            for func, endpoint in self.endpoints[endp_category].items():\n                for provider in providers:\n                    _endpoint = \"{base}/{provider}/{endpoint}\".format(\n                        base=self.base_url, provider=provider, endpoint=endpoint)\n                    idp_endpoints.append((_endpoint, func))\n            config[\"service\"][\"idp\"][\"endpoints\"][endp_category] = idp_endpoints\n\n        return config"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _load_endpoints_to_config(self, provider, target_entity_id, config=None):\n        idp_conf = copy.deepcopy(config or self.idp_config)\n        for service, endpoint in self.endpoints.items():\n            idp_endpoints = []\n            for binding, path in endpoint.items():\n                url = \"{base}/{provider}/{target_id}/{path}\".format(\n                    base=self.base_url, provider=provider,\n                    target_id=target_entity_id, path=path)\n                idp_endpoints.append((url, binding))\n            idp_conf[\"service\"][\"idp\"][\"endpoints\"][service] = idp_endpoints\n        return idp_conf", "response": "Loads approved endpoints to the config."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload an idp server that accepts the target backend name in the endpoint url ex : / <backend_name >", "response": "def _load_idp_dynamic_endpoints(self, context):\n        \"\"\"\n        Loads an idp server that accepts the target backend name in the endpoint url\n         ex: /<backend_name>/sso/redirect\n\n        :type context: The current context\n        :rtype: saml.server.Server\n\n        :param context:\n        :return: An idp server\n        \"\"\"\n        target_entity_id = context.target_entity_id_from_path()\n        idp_conf_file = self._load_endpoints_to_config(context.target_backend, target_entity_id)\n        idp_config = IdPConfig().load(idp_conf_file, metadata_construction=False)\n        return Server(config=idp_config)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _load_idp_dynamic_entity_id(self, state):\n        # Change the idp entity id dynamically\n        idp_config_file = copy.deepcopy(self.idp_config)\n        idp_config_file[\"entityid\"] = \"{}/{}\".format(self.idp_config[\"entityid\"], state[self.name][\"target_entity_id\"])\n        idp_config = IdPConfig().load(idp_config_file, metadata_construction=False)\n        return Server(config=idp_config)", "response": "Loads an idp server with the entity id saved in state\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _create_state_data(self, context, resp_args, relay_state):\n        state = super()._create_state_data(context, resp_args, relay_state)\n        state[\"target_entity_id\"] = context.target_entity_id_from_path()\n        return state", "response": "Create the state data for the state object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef handle_backend_error(self, exception):\n        idp = self._load_idp_dynamic_entity_id(exception.state)\n        return self._handle_backend_error(exception, idp)", "response": "Handle an error in the frontend."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhandle the response from the authentication server.", "response": "def handle_authn_response(self, context, internal_response):\n        \"\"\"\n        See super class satosa.frontends.base.FrontendModule#handle_authn_response\n        :param context:\n        :param internal_response:\n        :return:\n        \"\"\"\n        idp = self._load_idp_dynamic_entity_id(context.state)\n        return self._handle_authn_response(context, internal_response, idp)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _register_endpoints(self, providers):\n        url_map = []\n\n        for endp_category in self.endpoints:\n            for binding, endp in self.endpoints[endp_category].items():\n                valid_providers = \"|^\".join(providers)\n                parsed_endp = urlparse(endp)\n                url_map.append((\"(^%s)/\\S+/%s\" % (valid_providers, parsed_endp.path),\n                                functools.partial(self.handle_authn_request, binding_in=binding)))\n\n        return url_map", "response": "Register the endpoints with the given providers."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates the state data for the state object.", "response": "def _create_state_data(self, context, resp_args, relay_state):\n        \"\"\"\n        Adds the CO name to state\n        See super class satosa.frontends.saml2.SAMLFrontend#save_state\n\n        :type context: satosa.context.Context\n        :type resp_args: dict[str, str | saml2.samlp.NameIDPolicy]\n        :type relay_state: str\n        :rtype: dict[str, dict[str, str] | str]\n        \"\"\"\n        state = super()._create_state_data(context, resp_args, relay_state)\n        state[self.KEY_CO_NAME] = context.get_decoration(self.KEY_CO_NAME)\n\n        return state"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_co_name_from_path(self, context):\n        url_encoded_co_name = context.path.split(\"/\")[1]\n        co_name = unquote_plus(url_encoded_co_name)\n\n        return co_name", "response": "Get the CO name from the path of the request."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the name of the current CO from the request state or from the request path.", "response": "def _get_co_name(self, context):\n        \"\"\"\n        Obtain the CO name previously saved in the request state, or if not set\n        use the request path obtained from the current context to determine\n        the target CO.\n\n        :type context: The current context\n        :rtype: string\n\n        :param context: The current context\n        :return: CO name\n        \"\"\"\n        try:\n            co_name = context.state[self.name][self.KEY_CO_NAME]\n            logger.debug(\"Found CO {} from state\".format(co_name))\n        except KeyError:\n            co_name = self._get_co_name_from_path(context)\n            logger.debug(\"Found CO {} from request path\".format(co_name))\n\n        return co_name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _add_endpoints_to_config(self, config, co_name, backend_name):\n\n        for service, endpoint in self.endpoints.items():\n            idp_endpoints = []\n            for binding, path in endpoint.items():\n                url = \"{base}/{backend}/{co_name}/{path}\".format(\n                      base=self.base_url,\n                      backend=backend_name,\n                      co_name=quote_plus(co_name),\n                      path=path)\n                mapping = (url, binding)\n                idp_endpoints.append(mapping)\n\n            # Overwrite the IdP config with the CO specific mappings between\n            # SAML binding and URL endpoints.\n            config[\"service\"][\"idp\"][\"endpoints\"][service] = idp_endpoints\n\n        return config", "response": "Add the endpoints to the config"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds the entity ID to the config dictionary", "response": "def _add_entity_id(self, config, co_name):\n        \"\"\"\n        Use the CO name to construct the entity ID for the virtual IdP\n        for the CO.\n\n        The entity ID has the form\n\n        {base_entity_id}/{co_name}\n\n        :type config: satosa.satosa_config.SATOSAConfig\n        :type co_name: str\n        :rtype: satosa.satosa_config.SATOSAConfig\n\n        :param config: satosa proxy config\n        :param co_name: CO name\n\n        :return: config with updated entity ID\n        \"\"\"\n        base_entity_id = config['entityid']\n        co_entity_id = \"{}/{}\".format(base_entity_id, quote_plus(co_name))\n        config['entityid'] = co_entity_id\n\n        return config"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _overlay_for_saml_metadata(self, config, co_name):\n        for co in self.config[self.KEY_CO]:\n            if co[self.KEY_ENCODEABLE_NAME] == co_name:\n                break\n\n        key = self.KEY_ORGANIZATION\n        if key in co:\n            if key not in config:\n                config[key] = {}\n            for org_key in self.KEY_ORGANIZATION_KEYS:\n                if org_key in co[key]:\n                    config[key][org_key] = co[key][org_key]\n\n        key = self.KEY_CONTACT_PERSON\n        if key in co:\n            config[key] = co[key]\n\n        return config", "response": "Overlay configuration details like organization and contact person\n        from the front end configuration onto the IdP configuration to support SAML metadata generation."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the configuration for the names of the COs for which to construct virtual IdPs.", "response": "def _co_names_from_config(self):\n        \"\"\"\n        Parse the configuration for the names of the COs for which to\n        construct virtual IdPs.\n\n        :rtype: [str]\n\n        :return: list of CO names\n        \"\"\"\n        co_names = [co[self.KEY_ENCODEABLE_NAME] for\n                    co in self.config[self.KEY_CO]]\n\n        return co_names"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a virtual IdP for the current CO.", "response": "def _create_co_virtual_idp(self, context):\n        \"\"\"\n        Create a virtual IdP to represent the CO.\n\n        :type context: The current context\n        :rtype: saml.server.Server\n\n        :param context:\n        :return: An idp server\n        \"\"\"\n        co_name = self._get_co_name(context)\n        context.decorate(self.KEY_CO_NAME, co_name)\n\n        # Verify that we are configured for this CO. If the CO was not\n        # configured most likely the endpoint used was not registered and\n        # SATOSA core code threw an exception before getting here, but we\n        # include this check in case later the regex used to register the\n        # endpoints is relaxed.\n        co_names = self._co_names_from_config()\n        if co_name not in co_names:\n            msg = \"CO {} not in configured list of COs {}\".format(co_name,\n                                                                  co_names)\n            satosa_logging(logger, logging.WARN, msg, context.state)\n            raise SATOSAError(msg)\n\n        # Make a copy of the general IdP config that we will then overwrite\n        # with mappings between SAML bindings and CO specific URL endpoints,\n        # and the entityID for the CO virtual IdP.\n        backend_name = context.target_backend\n        idp_config = copy.deepcopy(self.idp_config)\n        idp_config = self._add_endpoints_to_config(idp_config,\n                                                   co_name,\n                                                   backend_name)\n        idp_config = self._add_entity_id(idp_config, co_name)\n\n        # Use the overwritten IdP config to generate a pysaml2 config object\n        # and from it a server object.\n        pysaml2_idp_config = IdPConfig().load(idp_config,\n                                              metadata_construction=False)\n\n        server = Server(config=pysaml2_idp_config)\n\n        return server"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nregister the endpoints in the frontend module.", "response": "def _register_endpoints(self, backend_names):\n        \"\"\"\n        See super class satosa.frontends.base.FrontendModule#register_endpoints\n\n        Endpoints have the format\n\n        {base}/{backend}/{co_name}/{binding path}\n\n        For example the HTTP-Redirect binding request path will have the\n        format\n\n        {base}/{backend}/{co_name}/sso/redirect\n\n        :type providers: list[str]\n        :rtype list[(str, ((satosa.context.Context, Any) ->\n                    satosa.response.Response, Any))] |\n               list[(str, (satosa.context.Context) ->\n                    satosa.response.Response)]\n        :param backend_names: A list of backend names\n        :return: A list of url and endpoint function pairs\n        \"\"\"\n        # Create a regex pattern that will match any of the CO names. We\n        # escape special characters like '+' and '.' that are valid\n        # characters in an URL encoded string.\n        co_names = self._co_names_from_config()\n        url_encoded_co_names = [re.escape(quote_plus(name)) for name in\n                                co_names]\n        co_name_pattern = \"|\".join(url_encoded_co_names)\n\n        # Create a regex pattern that will match any of the backend names.\n        backend_url_pattern = \"|^\".join(backend_names)\n        logger.debug(\"Input backend names are {}\".format(backend_names))\n        logger.debug(\"Created backend regex '{}'\".format(backend_url_pattern))\n\n        # Hold a list of tuples containing URL regex patterns and the callables\n        # that handle them.\n        url_to_callable_mappings = []\n\n        # Loop over IdP endpoint categories, e.g., single_sign_on_service.\n        for endpoint_category in self.endpoints:\n            logger.debug(\"Examining endpoint category {}\".format(\n                                    endpoint_category))\n\n            # For each endpoint category loop of the bindings and their\n            # assigned endpoints.\n            for binding, endpoint in self.endpoints[endpoint_category].items():\n                logger.debug(\"Found binding {} and endpoint {}\".format(binding,\n                             endpoint))\n\n                # Parse out the path from the endpoint.\n                endpoint_path = urlparse(endpoint).path\n                logger.debug(\"Using path {}\".format(endpoint_path))\n\n                # Use the backend URL pattern and the endpoint path to create\n                # a regex that will match and that includes a pattern for\n                # matching the URL encoded CO name.\n                regex_pattern = \"(^{})/({})/{}\".format(\n                                backend_url_pattern,\n                                co_name_pattern,\n                                endpoint_path)\n                logger.debug(\"Created URL regex {}\".format(regex_pattern))\n\n                # Map the regex pattern to a callable.\n                the_callable = functools.partial(self.handle_authn_request,\n                                                 binding_in=binding)\n                logger.debug(\"Created callable {}\".format(the_callable))\n\n                mapping = (regex_pattern, the_callable)\n                url_to_callable_mappings.append(mapping)\n                logger.debug(\"Adding mapping {}\".format(mapping))\n\n        return url_to_callable_mappings"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef start_auth(self, context, internal_request, get_state=stateID):\n        request_args = dict(\n            client_id=self.config['client_config']['client_id'],\n            redirect_uri=self.redirect_url,\n            scope=' '.join(self.config['scope']), )\n        cis = self.consumer.construct_AuthorizationRequest(\n            request_args=request_args)\n        return Redirect(cis.request(self.consumer.authorization_endpoint))", "response": "Start the authentication process."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a MetadataDescription object for a configured OAuth backend.", "response": "def get_metadata_desc_for_oauth_backend(entity_id, config):\n    \"\"\"\n    Returns a SAML metadata entity (IdP) descriptor for a configured OAuth/OpenID Connect Backend.\n    :param entity_id: If entity_id is None, the id will be retrieved from the config\n    :type entity_id: str\n    :param config: The backend module config\n    :type config: dict[str, Any]\n    :return: metadata description\n    :rtype: satosa.metadata_creation.description.MetadataDescription\n    \"\"\"\n    metadata_description = []\n    entity_id = urlsafe_b64encode(entity_id.encode(\"utf-8\")).decode(\"utf-8\")\n    description = MetadataDescription(entity_id)\n\n    if \"entity_info\" in config:\n        entity_info = config[\"entity_info\"]\n\n        # Add contact person information\n        for contact_person in entity_info.get(\"contact_person\", []):\n            person = ContactPersonDesc()\n            if 'contact_type' in contact_person:\n                person.contact_type = contact_person['contact_type']\n            for address in contact_person.get('email_address', []):\n                person.add_email_address(address)\n            if 'given_name' in contact_person:\n                person.given_name = contact_person['given_name']\n            if 'sur_name' in contact_person:\n                person.sur_name = contact_person['sur_name']\n\n            description.add_contact_person(person)\n\n        # Add organization information\n        if \"organization\" in entity_info:\n            organization_info = entity_info[\"organization\"]\n            organization = OrganizationDesc()\n\n            for name_info in organization_info.get(\"organization_name\", []):\n                organization.add_name(name_info[0], name_info[1])\n            for display_name_info in organization_info.get(\"organization_display_name\", []):\n                organization.add_display_name(display_name_info[0], display_name_info[1])\n            for url_info in organization_info.get(\"organization_url\", []):\n                organization.add_url(url_info[0], url_info[1])\n\n            description.organization = organization\n\n        # Add ui information\n        if \"ui_info\" in entity_info:\n            ui_info = entity_info[\"ui_info\"]\n            ui_description = UIInfoDesc()\n            for desc in ui_info.get(\"description\", []):\n                ui_description.add_description(desc[0], desc[1])\n            for name in ui_info.get(\"display_name\", []):\n                ui_description.add_display_name(name[0], name[1])\n            for logo in ui_info.get(\"logo\", []):\n                ui_description.add_logo(logo[\"image\"], logo[\"width\"], logo[\"height\"], logo[\"lang\"])\n\n            description.ui_info = ui_description\n\n    metadata_description.append(description)\n    return metadata_description"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstarting the authentication process for the current application.", "response": "def start_auth(self, context, internal_request, get_state=stateID):\n        \"\"\"\n        See super class method satosa.backends.base#start_auth\n        :param get_state: Generates a state to be used in the authentication call.\n\n        :type get_state: Callable[[str, bytes], str]\n        :type context: satosa.context.Context\n        :type internal_request: satosa.internal.InternalData\n        :rtype satosa.response.Redirect\n        \"\"\"\n        oauth_state = get_state(self.config[\"base_url\"], rndstr().encode())\n\n        state_data = dict(state=oauth_state)\n        context.state[self.name] = state_data\n\n        request_args = {\"redirect_uri\": self.redirect_url, \"state\": oauth_state}\n        cis = self.consumer.construct_AuthorizationRequest(request_args=request_args)\n        return Redirect(cis.request(self.consumer.authorization_endpoint))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _verify_state(self, resp, state_data, state):\n        is_known_state = \"state\" in resp and \"state\" in state_data and resp[\"state\"] == state_data[\"state\"]\n        if not is_known_state:\n            received_state = resp.get(\"state\", \"\")\n            satosa_logging(logger, logging.DEBUG,\n                           \"Missing or invalid state [%s] in response!\" % received_state, state)\n            raise SATOSAAuthenticationError(state,\n                                            \"Missing or invalid state [%s] in response!\" %\n                                            received_state)", "response": "Verify the state of the state of the state_data."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhandle the authentication response from the AS.", "response": "def _authn_response(self, context):\n        \"\"\"\n        Handles the authentication response from the AS.\n\n        :type context: satosa.context.Context\n        :rtype: satosa.response.Response\n        :param context: The context in SATOSA\n        :return: A SATOSA response. This method is only responsible to call the callback function\n        which generates the Response object.\n        \"\"\"\n        state_data = context.state[self.name]\n        aresp = self.consumer.parse_response(AuthorizationResponse, info=json.dumps(context.request))\n        self._verify_state(aresp, state_data, context.state)\n\n        rargs = {\"code\": aresp[\"code\"], \"redirect_uri\": self.redirect_url,\n                 \"state\": state_data[\"state\"]}\n\n        atresp = self.consumer.do_access_token_request(request_args=rargs, state=aresp[\"state\"])\n        if \"verify_accesstoken_state\" not in self.config or self.config[\"verify_accesstoken_state\"]:\n            self._verify_state(atresp, state_data, context.state)\n\n        user_info = self.user_information(atresp[\"access_token\"])\n        internal_response = InternalData(auth_info=self.auth_info(context.request))\n        internal_response.attributes = self.converter.to_internal(self.external_type, user_info)\n        internal_response.subject_id = user_info[self.user_id_attr]\n        del context.state[self.name]\n        return self.auth_callback_func(context, internal_response)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef user_information(self, access_token):\n        payload = {'access_token': access_token}\n        url = \"https://graph.facebook.com/v2.5/me\"\n        if self.config[\"fields\"]:\n            payload[\"fields\"] = \",\".join(self.config[\"fields\"])\n        resp = requests.get(url, params=payload)\n        data = json.loads(resp.text)\n        try:\n            picture_url = data[\"picture\"][\"data\"][\"url\"]\n            data[\"picture\"] = picture_url\n        except KeyError as e:\n            pass\n        return data", "response": "Returns the user information for the authenticated user."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a SAML response.", "response": "def make_saml_response(binding, http_args):\n    \"\"\"\n    Creates a SAML response.\n    :param binding: SAML response binding\n    :param http_args: http arguments\n    :return: response.Response\n    \"\"\"\n    if binding == BINDING_HTTP_REDIRECT:\n        headers = dict(http_args[\"headers\"])\n        return SeeOther(str(headers[\"Location\"]))\n\n    return Response(http_args[\"data\"], headers=http_args[\"headers\"])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhash a value together with a salt with the given hash algorithm.", "response": "def hash_data(salt, value, hash_alg=None):\n    \"\"\"\n    Hashes a value together with a salt with the given hash algorithm.\n\n    :type salt: str\n    :type hash_alg: str\n    :type value: str\n    :param salt: hash salt\n    :param hash_alg: the hash algorithm to use (default: SHA512)\n    :param value: value to hash together with the salt\n    :return: hashed value\n    \"\"\"\n    hash_alg = hash_alg or 'sha512'\n    hasher = hashlib.new(hash_alg)\n    hasher.update(value.encode('utf-8'))\n    hasher.update(salt.encode('utf-8'))\n    value_hashed = hasher.hexdigest()\n    return value_hashed"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a random ascii string of the specified size.", "response": "def rndstr(size=16, alphabet=\"\"):\n    \"\"\"\n    Returns a string of random ascii characters or digits\n    :type size: int\n    :type alphabet: str\n    :param size: The length of the string\n    :param alphabet: A string with characters.\n    :return: string\n    \"\"\"\n    rng = random.SystemRandom()\n    if not alphabet:\n        alphabet = string.ascii_letters[0:52] + string.digits\n    return type(alphabet)().join(rng.choice(alphabet) for _ in range(size))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _construct_filter_value(self, candidate, data):\n        context = self.context\n\n        attributes = data.attributes\n        satosa_logging(logger, logging.DEBUG, \"Input attributes {}\".format(attributes), context.state)\n\n        # Get the values configured list of identifier names for this candidate\n        # and substitute None if there are no values for a configured identifier.\n        values = []\n        for identifier_name in candidate['attribute_names']:\n            v = attributes.get(identifier_name, None)\n            if isinstance(v, list):\n                v = v[0]\n            values.append(v)\n        satosa_logging(logger, logging.DEBUG, \"Found candidate values {}\".format(values), context.state)\n\n        # If one of the configured identifier names is name_id then if there is also a configured\n        # name_id_format add the value for the NameID of that format if it was asserted by the IdP\n        # or else add the value None.\n        if 'name_id' in candidate['attribute_names']:\n            candidate_nameid_value = None\n            candidate_name_id_format = candidate.get('name_id_format')\n            name_id_value = data.subject_id\n            name_id_format = data.subject_type\n            if (\n                name_id_value\n                and candidate_name_id_format\n                and candidate_name_id_format == name_id_format\n            ):\n                satosa_logging(logger, logging.DEBUG, \"IdP asserted NameID {}\".format(name_id_value), context.state)\n                candidate_nameid_value = name_id_value\n\n            # Only add the NameID value asserted by the IdP if it is not already\n            # in the list of values. This is necessary because some non-compliant IdPs\n            # have been known, for example, to assert the value of eduPersonPrincipalName\n            # in the value for SAML2 persistent NameID as well as asserting\n            # eduPersonPrincipalName.\n            if candidate_nameid_value not in values:\n                satosa_logging(logger, logging.DEBUG, \"Added NameID {} to candidate values\".format(candidate_nameid_value), context.state)\n                values.append(candidate_nameid_value)\n            else:\n                satosa_logging(logger, logging.WARN, \"NameID {} value also asserted as attribute value\".format(candidate_nameid_value), context.state)\n\n        # If no value was asserted by the IdP for one of the configured list of identifier names\n        # for this candidate then go onto the next candidate.\n        if None in values:\n            satosa_logging(logger, logging.DEBUG, \"Candidate is missing value so skipping\", context.state)\n            return None\n\n        # All values for the configured list of attribute names are present\n        # so we can create a value. Add a scope if configured\n        # to do so.\n        if 'add_scope' in candidate:\n            if candidate['add_scope'] == 'issuer_entityid':\n                scope = data.auth_info.issuer\n            else:\n                scope = candidate['add_scope']\n            satosa_logging(logger, logging.DEBUG, \"Added scope {} to values\".format(scope), context.state)\n            values.append(scope)\n\n        # Concatenate all values to create the filter value.\n        value = ''.join(values)\n\n        satosa_logging(logger, logging.DEBUG, \"Constructed filter value {}\".format(value), context.state)\n\n        return value", "response": "Construct and return a LDAP directory search filter value from the given candidate identifier."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfiltering sensitive details like passwords from a configuration dictionary.", "response": "def _filter_config(self, config, fields=None):\n        \"\"\"\n        Filter sensitive details like passwords from a configuration\n        dictionary.\n        \"\"\"\n        filter_fields_default = [\n            'bind_password',\n            'connection'\n            ]\n\n        filter_fields = fields or filter_fields_default\n        return dict(\n            map(\n                lambda key: (key, '<hidden>' if key in filter_fields else config[key]),\n                config.keys()\n                )\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _ldap_connection_factory(self, config):\n        ldap_url = config['ldap_url']\n        bind_dn = config['bind_dn']\n        bind_password = config['bind_password']\n\n        if not ldap_url:\n            raise LdapAttributeStoreError(\"ldap_url is not configured\")\n        if not bind_dn:\n            raise LdapAttributeStoreError(\"bind_dn is not configured\")\n        if not bind_password:\n            raise LdapAttributeStoreError(\"bind_password is not configured\")\n\n        pool_size = config['pool_size']\n        pool_keepalive = config['pool_keepalive']\n\n        server = ldap3.Server(config['ldap_url'])\n\n        satosa_logging(logger, logging.DEBUG, \"Creating a new LDAP connection\", None)\n        satosa_logging(logger, logging.DEBUG, \"Using LDAP URL {}\".format(ldap_url), None)\n        satosa_logging(logger, logging.DEBUG, \"Using bind DN {}\".format(bind_dn), None)\n        satosa_logging(logger, logging.DEBUG, \"Using pool size {}\".format(pool_size), None)\n        satosa_logging(logger, logging.DEBUG, \"Using pool keep alive {}\".format(pool_keepalive), None)\n\n        try:\n            connection = ldap3.Connection(\n                            server,\n                            bind_dn,\n                            bind_password,\n                            auto_bind=True,\n                            client_strategy=ldap3.REUSABLE,\n                            pool_size=pool_size,\n                            pool_keepalive=pool_keepalive\n                            )\n\n        except LDAPException as e:\n            msg = \"Caught exception when connecting to LDAP server: {}\".format(e)\n            satosa_logging(logger, logging.ERROR, msg, None)\n            raise LdapAttributeStoreError(msg)\n\n        satosa_logging(logger, logging.DEBUG, \"Successfully connected to LDAP server\", None)\n\n        return connection", "response": "Create a new LDAP connection object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _populate_attributes(self, config, record, context, data):\n        search_return_attributes = config['search_return_attributes']\n        for attr in search_return_attributes.keys():\n            if attr in record[\"attributes\"]:\n                if record[\"attributes\"][attr]:\n                    data.attributes[search_return_attributes[attr]] = record[\"attributes\"][attr]\n                    satosa_logging(\n                        logger,\n                        logging.DEBUG,\n                        \"Setting internal attribute {} with values {}\".format(\n                            search_return_attributes[attr],\n                            record[\"attributes\"][attr]\n                            ),\n                        context.state\n                        )\n                else:\n                    satosa_logging(\n                        logger,\n                        logging.DEBUG,\n                        \"Not setting internal attribute {} because value {} is null or empty\".format(\n                            search_return_attributes[attr],\n                            record[\"attributes\"][attr]\n                            ),\n                        context.state\n                        )", "response": "Populate the attributes of the data object with the values found in LDAP."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _populate_input_for_name_id(self, config, record, context, data):\n        user_id = \"\"\n        user_id_from_attrs = config['user_id_from_attrs']\n        for attr in user_id_from_attrs:\n            if attr in record[\"attributes\"]:\n                value = record[\"attributes\"][attr]\n                if isinstance(value, list):\n                    # Use a default sort to ensure some predictability since the\n                    # LDAP directory server may return multi-valued attributes\n                    # in any order.\n                    value.sort()\n                    user_id += \"\".join(value)\n                    satosa_logging(\n                        logger,\n                        logging.DEBUG,\n                        \"Added attribute {} with values {} to input for NameID\".format(attr, value),\n                        context.state\n                        )\n                else:\n                    user_id += value\n                    satosa_logging(\n                        logger,\n                        logging.DEBUG,\n                        \"Added attribute {} with value {} to input for NameID\".format(attr, value),\n                        context.state\n                        )\n        if not user_id:\n            satosa_logging(\n                logger,\n                logging.WARNING,\n                \"Input for NameID is empty so not overriding default\",\n                context.state\n                )\n        else:\n            data.subject_id = user_id\n            satosa_logging(\n                logger,\n                logging.DEBUG,\n                \"Input for NameID is {}\".format(data.subject_id),\n                context.state\n                )", "response": "Populate the input for NameID generation."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef process(self, context, data):\n        self.context = context\n\n        # Find the entityID for the SP that initiated the flow.\n        try:\n            sp_entity_id = context.state.state_dict['SATOSA_BASE']['requester']\n        except KeyError as err:\n            satosa_logging(logger, logging.ERROR, \"Unable to determine the entityID for the SP requester\", context.state)\n            return super().process(context, data)\n\n        satosa_logging(logger, logging.DEBUG, \"entityID for the SP requester is {}\".format(sp_entity_id), context.state)\n\n        # Get the configuration for the SP.\n        if sp_entity_id in self.config.keys():\n            config = self.config[sp_entity_id]\n        else:\n            config = self.config['default']\n\n        satosa_logging(logger, logging.DEBUG, \"Using config {}\".format(self._filter_config(config)), context.state)\n\n        # Ignore this SP entirely if so configured.\n        if config['ignore']:\n            satosa_logging(logger, logging.INFO, \"Ignoring SP {}\".format(sp_entity_id), None)\n            return super().process(context, data)\n\n        # The list of values for the LDAP search filters that will be tried in order to find the\n        # LDAP directory record for the user.\n        filter_values = []\n\n        # Loop over the configured list of identifiers from the IdP to consider and find\n        # asserted values to construct the ordered list of values for the LDAP search filters.\n        for candidate in config['ordered_identifier_candidates']:\n            value = self._construct_filter_value(candidate, data)\n\n            # If we have constructed a non empty value then add it as the next filter value\n            # to use when searching for the user record.\n            if value:\n                filter_values.append(value)\n                satosa_logging(logger, logging.DEBUG, \"Added search filter value {} to list of search filters\".format(value), context.state)\n\n        # Initialize an empty LDAP record. The first LDAP record found using the ordered\n        # list of search filter values will be the record used.\n        record = None\n\n        try:\n            connection = config['connection']\n\n            for filter_val in filter_values:\n                if record:\n                    break\n\n                search_filter = '({0}={1})'.format(config['ldap_identifier_attribute'], filter_val)\n                satosa_logging(logger, logging.DEBUG, \"Constructed search filter {}\".format(search_filter), context.state)\n\n                satosa_logging(logger, logging.DEBUG, \"Querying LDAP server...\", context.state)\n                message_id = connection.search(config['search_base'], search_filter, attributes=config['search_return_attributes'].keys())\n                responses = connection.get_response(message_id)[0]\n                satosa_logging(logger, logging.DEBUG, \"Done querying LDAP server\", context.state)\n                satosa_logging(logger, logging.DEBUG, \"LDAP server returned {} records\".format(len(responses)), context.state)\n\n                # for now consider only the first record found (if any)\n                if len(responses) > 0:\n                    if len(responses) > 1:\n                        satosa_logging(logger, logging.WARN, \"LDAP server returned {} records using search filter value {}\".format(len(responses), filter_val), context.state)\n                    record = responses[0]\n                    break\n        except LDAPException as err:\n            satosa_logging(logger, logging.ERROR, \"Caught LDAP exception: {}\".format(err), context.state)\n        except LdapAttributeStoreError as err:\n            satosa_logging(logger, logging.ERROR, \"Caught LDAP Attribute Store exception: {}\".format(err), context.state)\n        except Exception as err:\n            satosa_logging(logger, logging.ERROR, \"Caught unhandled exception: {}\".format(err), context.state)\n        else:\n            err = None\n        finally:\n            if err:\n                return super().process(context, data)\n\n        # Before using a found record, if any, to populate attributes\n        # clear any attributes incoming to this microservice if so configured.\n        if config['clear_input_attributes']:\n            satosa_logging(logger, logging.DEBUG, \"Clearing values for these input attributes: {}\".format(data.attributes), context.state)\n            data.attributes = {}\n\n        # Use a found record, if any, to populate attributes and input for NameID\n        if record:\n            satosa_logging(logger, logging.DEBUG, \"Using record with DN {}\".format(record[\"dn\"]), context.state)\n            satosa_logging(logger, logging.DEBUG, \"Record with DN {} has attributes {}\".format(record[\"dn\"], record[\"attributes\"]), context.state)\n\n            # Populate attributes as configured.\n            self._populate_attributes(config, record, context, data)\n\n            # Populate input for NameID if configured. SATOSA core does the hashing of input\n            # to create a persistent NameID.\n            self._populate_input_for_name_id(config, record, context, data)\n\n        else:\n            satosa_logging(logger, logging.WARN, \"No record found in LDAP so no attributes will be added\", context.state)\n            on_ldap_search_result_empty = config['on_ldap_search_result_empty']\n            if on_ldap_search_result_empty:\n                # Redirect to the configured URL with\n                # the entityIDs for the target SP and IdP used by the user\n                # as query string parameters (URL encoded).\n                encoded_sp_entity_id = urllib.parse.quote_plus(sp_entity_id)\n                encoded_idp_entity_id = urllib.parse.quote_plus(data.auth_info.issuer)\n                url = \"{}?sp={}&idp={}\".format(on_ldap_search_result_empty, encoded_sp_entity_id, encoded_idp_entity_id)\n                satosa_logging(logger, logging.INFO, \"Redirecting to {}\".format(url), context.state)\n                return Redirect(url)\n\n        satosa_logging(logger, logging.DEBUG, \"Returning data.attributes {}\".format(str(data.attributes)), context.state)\n        return super().process(context, data)", "response": "Process the input data for the microservices."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate an object from a dictionary representation of an AuthenticationInformation object.", "response": "def from_dict(cls, data):\n        \"\"\"\n        :type data: dict[str, str]\n        :rtype: satosa.internal.AuthenticationInformation\n        :param data: A dict representation of an AuthenticationInformation object\n        :return: An AuthenticationInformation object\n        \"\"\"\n        return cls(\n            auth_class_ref=data.get(\"auth_class_ref\"),\n            timestamp=data.get(\"timestamp\"),\n            issuer=data.get(\"issuer\"),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_dict(self):\n        data = {\n            \"auth_info\": self.auth_info.to_dict(),\n            \"requester\": self.requester,\n            \"requester_name\": self.requester_name,\n            \"attributes\": self.attributes,\n            \"subject_id\": self.subject_id,\n            \"subject_type\": self.subject_type,\n        }\n        data.update(\n            {\n                \"user_id\": self.subject_id,\n                \"hash_type\": self.subject_type,\n                \"name_id\": self.subject_id,\n                \"approved_attributes\": self.attributes,\n            }\n        )\n        return data", "response": "Converts an InternalData object to a dict representation of the object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_dict(cls, data):\n        auth_info = AuthenticationInformation.from_dict(\n            data.get(\"auth_info\", {})\n        )\n        instance = cls(\n            auth_info=auth_info,\n            requester=data.get(\"requester\"),\n            requester_name=data.get(\"requester_name\"),\n            subject_id=data.get(\"subject_id\"),\n            subject_type=data.get(\"subject_type\"),\n            attributes=data.get(\"attributes\"),\n            user_id=data.get(\"user_id\"),\n            user_id_hash_type=data.get(\"hash_type\"),\n            name_id=data.get(\"name_id\"),\n            approved_attributes=data.get(\"approved_attributes\"),\n        )\n        return instance", "response": "Creates an InternalData object from a dictionary representation of an InternalData object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nverify that the configuration contains all necessary keys.", "response": "def _verify_dict(self, conf):\n        \"\"\"\n        Check that the configuration contains all necessary keys.\n\n        :type conf: dict\n        :rtype: None\n        :raise SATOSAConfigurationError: if the configuration is incorrect\n\n        :param conf: config to verify\n        :return: None\n        \"\"\"\n        if not conf:\n            raise SATOSAConfigurationError(\"Missing configuration or unknown format\")\n\n        for key in SATOSAConfig.mandatory_dict_keys:\n            if key not in conf:\n                raise SATOSAConfigurationError(\"Missing key '%s' in config\" % key)\n\n        for key in SATOSAConfig.sensitive_dict_keys:\n            if key not in conf and \"SATOSA_{key}\".format(key=key) not in os.environ:\n                raise SATOSAConfigurationError(\"Missing key '%s' from config and ENVIRONMENT\" % key)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload config from yaml file or string", "response": "def _load_yaml(self, config_file):\n        \"\"\"\n        Load config from yaml file or string\n\n        :type config_file: str\n        :rtype: dict\n\n        :param config_file: config to load. Can be file path or yaml string\n        :return: Loaded config\n        \"\"\"\n        try:\n            with open(config_file) as f:\n                return yaml.safe_load(f.read())\n        except yaml.YAMLError as exc:\n            logger.error(\"Could not parse config as YAML: {}\", str(exc))\n            if hasattr(exc, 'problem_mark'):\n                mark = exc.problem_mark\n                logger.error(\"Error position: (%s:%s)\" % (mark.line + 1, mark.column + 1))\n        except IOError as e:\n            logger.debug(\"Could not open config file: {}\", str(e))\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlogging a message to the given logger.", "response": "def satosa_logging(logger, level, message, state, **kwargs):\n    \"\"\"\n    Adds a session ID to the message.\n\n    :type logger: logging\n    :type level: int\n    :type message: str\n    :type state: satosa.state.State\n\n    :param logger: Logger to use\n    :param level: Logger level (ex: logging.DEBUG/logging.WARN/...)\n    :param message: Message\n    :param state: The current state\n    :param kwargs: set exc_info=True to get an exception stack trace in the log\n    \"\"\"\n    if state is None:\n        session_id = \"UNKNOWN\"\n    else:\n        try:\n            session_id = state[LOGGER_STATE_KEY]\n        except KeyError:\n            session_id = uuid4().urn\n            state[LOGGER_STATE_KEY] = session_id\n    logger.log(level, \"[{id}] {msg}\".format(id=session_id, msg=message), **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process(self, context, data):\n        context.target_backend = self.requester_mapping[data.requester]\n        return super().process(context, data)", "response": "This method will modify the context. target_backend attribute based on the requester identifier."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhandle the response from a consent request.", "response": "def _handle_consent_response(self, context):\n        \"\"\"\n        Endpoint for handling consent service response\n        :type context: satosa.context.Context\n        :rtype: satosa.response.Response\n\n        :param context: response context\n        :return: response\n        \"\"\"\n        consent_state = context.state[STATE_KEY]\n        saved_resp = consent_state[\"internal_resp\"]\n        internal_response = InternalData.from_dict(saved_resp)\n\n        hash_id = self._get_consent_id(internal_response.requester, internal_response.subject_id,\n                                       internal_response.attributes)\n\n        try:\n            consent_attributes = self._verify_consent(hash_id)\n        except ConnectionError as e:\n            satosa_logging(logger, logging.ERROR,\n                           \"Consent service is not reachable, no consent given.\", context.state)\n            # Send an internal_response without any attributes\n            consent_attributes = None\n\n        if consent_attributes is None:\n            satosa_logging(logger, logging.INFO, \"Consent was NOT given\", context.state)\n            # If consent was not given, then don't send any attributes\n            consent_attributes = []\n        else:\n            satosa_logging(logger, logging.INFO, \"Consent was given\", context.state)\n\n        internal_response.attributes = self._filter_attributes(internal_response.attributes, consent_attributes)\n        return self._end_consent(context, internal_response)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprocessing the response from the consent service and send an internal_response to the user.", "response": "def process(self, context, internal_response):\n        \"\"\"\n        Manage consent and attribute filtering\n\n        :type context: satosa.context.Context\n        :type internal_response: satosa.internal.InternalData\n        :rtype: satosa.response.Response\n\n        :param context: response context\n        :param internal_response: the response\n        :return: response\n        \"\"\"\n        consent_state = context.state[STATE_KEY]\n\n        internal_response.attributes = self._filter_attributes(internal_response.attributes, consent_state[\"filter\"])\n        id_hash = self._get_consent_id(internal_response.requester, internal_response.subject_id,\n                                       internal_response.attributes)\n\n        try:\n            # Check if consent is already given\n            consent_attributes = self._verify_consent(id_hash)\n        except requests.exceptions.ConnectionError as e:\n            satosa_logging(logger, logging.ERROR,\n                           \"Consent service is not reachable, no consent given.\", context.state)\n            # Send an internal_response without any attributes\n            internal_response.attributes = {}\n            return self._end_consent(context, internal_response)\n\n        # Previous consent was given\n        if consent_attributes is not None:\n            satosa_logging(logger, logging.DEBUG, \"Previous consent was given\", context.state)\n            internal_response.attributes = self._filter_attributes(internal_response.attributes, consent_attributes)\n            return self._end_consent(context, internal_response)\n\n        # No previous consent, request consent by user\n        return self._approve_new_consent(context, internal_response, id_hash)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a hashed id based on requester user id and filtered attributes.", "response": "def _get_consent_id(self, requester, user_id, filtered_attr):\n        \"\"\"\n        Get a hashed id based on requester, user id and filtered attributes\n\n        :type requester: str\n        :type user_id: str\n        :type filtered_attr: dict[str, str]\n\n        :param requester: The calling requester\n        :param user_id: The authorized user id\n        :param filtered_attr: a list containing all attributes to be sent\n        :return: an id\n        \"\"\"\n\n        filtered_attr_key_list = sorted(filtered_attr.keys())\n        hash_str = \"\"\n        for key in filtered_attr_key_list:\n            _hash_value = \"\".join(sorted(filtered_attr[key]))\n            hash_str += key + _hash_value\n        id_string = \"%s%s%s\" % (requester, user_id, hash_str)\n        return urlsafe_b64encode(hashlib.sha512(id_string.encode(\"utf-8\")).hexdigest().encode(\"utf-8\")).decode(\"utf-8\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nregister a request at the consent service", "response": "def _consent_registration(self, consent_args):\n        \"\"\"\n        Register a request at the consent service\n\n        :type consent_args: dict\n        :rtype: str\n\n        :param consent_args: All necessary parameters for the consent request\n        :return: Ticket received from the consent service\n        \"\"\"\n        jws = JWS(json.dumps(consent_args), alg=self.signing_key.alg).sign_compact([self.signing_key])\n        request = \"{}/creq/{}\".format(self.api_url, jws)\n        res = requests.get(request)\n\n        if res.status_code != 200:\n            raise UnexpectedResponseError(\"Consent service error: %s %s\", res.status_code, res.text)\n\n        return res.text"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _verify_consent(self, consent_id):\n        request = \"{}/verify/{}\".format(self.api_url, consent_id)\n        res = requests.get(request)\n\n        if res.status_code == 200:\n            return json.loads(res.text)\n\n        return None", "response": "Connects to the consent service and checks if the user has given consent_id and returns the attributes that have been approved by the user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nclearing the state for consent and end the consent step", "response": "def _end_consent(self, context, internal_response):\n        \"\"\"\n        Clear the state for consent and end the consent step\n\n        :type context: satosa.context.Context\n        :type internal_response: satosa.internal.InternalData\n        :rtype: satosa.response.Response\n\n        :param context: response context\n        :param internal_response: the response\n        :return: response\n        \"\"\"\n        del context.state[STATE_KEY]\n        return super().process(context, internal_response)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconstruct and return a primary identifier value from the data asserted by the IdP using the ordered list of candidates.", "response": "def constructPrimaryIdentifier(self, data, ordered_identifier_candidates):\n        \"\"\"\n        Construct and return a primary identifier value from the\n        data asserted by the IdP using the ordered list of candidates\n        from the configuration.\n        \"\"\"\n        logprefix = PrimaryIdentifier.logprefix\n        context = self.context\n\n        attributes = data.attributes\n        satosa_logging(logger, logging.DEBUG, \"{} Input attributes {}\".format(logprefix, attributes), context.state)\n\n        value = None\n\n        for candidate in ordered_identifier_candidates:\n            satosa_logging(logger, logging.DEBUG, \"{} Considering candidate {}\".format(logprefix, candidate), context.state)\n\n            # Get the values asserted by the IdP for the configured list of attribute names for this candidate\n            # and substitute None if the IdP did not assert any value for a configured attribute.\n            values = [ attributes.get(attribute_name, [None])[0] for attribute_name in candidate['attribute_names'] ]\n            satosa_logging(logger, logging.DEBUG, \"{} Found candidate values {}\".format(logprefix, values), context.state)\n\n            # If one of the configured attribute names is name_id then if there is also a configured\n            # name_id_format add the value for the NameID of that format if it was asserted by the IdP\n            # or else add the value None.\n            if 'name_id' in candidate['attribute_names']:\n                candidate_nameid_value = None\n                candidate_nameid_value = None\n                candidate_name_id_format = candidate.get('name_id_format')\n                name_id_value = data.subject_id\n                name_id_format = data.subject_type\n                if (\n                    name_id_value\n                    and candidate_name_id_format\n                    and candidate_name_id_format == name_id_format\n                ):\n                    satosa_logging(logger, logging.DEBUG, \"{} IdP asserted NameID {}\".format(logprefix, name_id_value), context.state)\n                    candidate_nameid_value = name_id_value\n\n                # Only add the NameID value asserted by the IdP if it is not already\n                # in the list of values. This is necessary because some non-compliant IdPs\n                # have been known, for example, to assert the value of eduPersonPrincipalName\n                # in the value for SAML2 persistent NameID as well as asserting\n                # eduPersonPrincipalName.\n                if candidate_nameid_value not in values:\n                    satosa_logging(logger, logging.DEBUG, \"{} Added NameID {} to candidate values\".format(logprefix, candidate_nameid_value), context.state)\n                    values.append(candidate_nameid_value)\n                else:\n                    satosa_logging(logger, logging.WARN, \"{} NameID {} value also asserted as attribute value\".format(logprefix, candidate_nameid_value), context.state)\n\n            # If no value was asserted by the IdP for one of the configured list of attribute names\n            # for this candidate then go onto the next candidate.\n            if None in values:\n                satosa_logging(logger, logging.DEBUG, \"{} Candidate is missing value so skipping\".format(logprefix), context.state)\n                continue\n\n            # All values for the configured list of attribute names are present\n            # so we can create a primary identifer. Add a scope if configured\n            # to do so.\n            if 'add_scope' in candidate:\n                if candidate['add_scope'] == 'issuer_entityid':\n                    scope = data.auth_info.issuer\n                else:\n                    scope = candidate['add_scope']\n                satosa_logging(logger, logging.DEBUG, \"{} Added scope {} to values\".format(logprefix, scope), context.state)\n                values.append(scope)\n\n            # Concatenate all values to create the primary identifier.\n            value = ''.join(values)\n            break\n\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef state_to_cookie(state, name, path, encryption_key):\n\n    cookie_data = \"\" if state.delete else state.urlstate(encryption_key)\n    max_age = 0 if state.delete else STATE_COOKIE_MAX_AGE\n\n    satosa_logging(logger, logging.DEBUG,\n                   \"Saving state as cookie, secure: %s, max-age: %s, path: %s\" %\n                   (STATE_COOKIE_SECURE, STATE_COOKIE_MAX_AGE, path), state)\n    cookie = SimpleCookie()\n    cookie[name] = cookie_data\n    cookie[name][\"secure\"] = STATE_COOKIE_SECURE\n    cookie[name][\"path\"] = path\n    cookie[name][\"max-age\"] = max_age\n    return cookie", "response": "Save a state to a cookie"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cookie_to_state(cookie_str, name, encryption_key):\n    try:\n        cookie = SimpleCookie(cookie_str)\n        state = State(cookie[name].value, encryption_key)\n    except KeyError as e:\n        msg_tmpl = 'No cookie named {name} in {data}'\n        msg = msg_tmpl.format(name=name, data=cookie_str)\n        logger.exception(msg)\n        raise SATOSAStateError(msg) from e\n    except ValueError as e:\n        msg_tmpl = 'Failed to process {name} from {data}'\n        msg = msg_tmpl.format(name=name, data=cookie_str)\n        logger.exception(msg)\n        raise SATOSAStateError(msg) from e\n    else:\n        msg_tmpl = 'Loading state from cookie {data}'\n        msg = msg_tmpl.format(data=cookie_str)\n        satosa_logging(logger, logging.DEBUG, msg, state)\n        return state", "response": "Load a state from a cookie string"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef encrypt(self, raw):\n        raw = self._pad(raw)\n        iv = Random.new().read(AES.block_size)\n        cipher = AES.new(self.key, AES.MODE_CBC, iv)\n        return base64.urlsafe_b64encode(iv + cipher.encrypt(raw))", "response": "Encryptes the parameter raw."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npad the parameter b to be of the correct length for the encryption alg.", "response": "def _pad(self, b):\n        \"\"\"\n        Will padd the param to be of the correct length for the encryption alg.\n\n        :type b: bytes\n        :rtype: bytes\n        \"\"\"\n        return b + (self.bs - len(b) % self.bs) * chr(self.bs - len(b) % self.bs).encode(\"UTF-8\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef urlstate(self, encryption_key):\n        lzma = LZMACompressor()\n        urlstate_data = json.dumps(self._state_dict)\n        urlstate_data = lzma.compress(urlstate_data.encode(\"UTF-8\"))\n        urlstate_data += lzma.flush()\n        urlstate_data = _AESCipher(encryption_key).encrypt(urlstate_data)\n        lzma = LZMACompressor()\n        urlstate_data = lzma.compress(urlstate_data)\n        urlstate_data += lzma.flush()\n        urlstate_data = base64.urlsafe_b64encode(urlstate_data)\n        return urlstate_data.decode(\"utf-8\")", "response": "Returns a url safe representation of the state of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a deep copy of the state", "response": "def copy(self):\n        \"\"\"\n        Returns a deepcopy of the state\n\n        :rtype: satosa.state.State\n\n        :return: A copy of the state\n        \"\"\"\n        state_copy = State()\n        state_copy._state_dict = copy.deepcopy(self._state_dict)\n        return state_copy"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef saml_name_id_format_to_hash_type(name_format):\n    msg = \"saml_name_id_format_to_hash_type is deprecated and will be removed.\"\n    _warnings.warn(msg, DeprecationWarning)\n\n    name_id_format_to_hash_type = {\n        NAMEID_FORMAT_TRANSIENT: UserIdHashType.transient,\n        NAMEID_FORMAT_PERSISTENT: UserIdHashType.persistent,\n        NAMEID_FORMAT_EMAILADDRESS: UserIdHashType.emailaddress,\n        NAMEID_FORMAT_UNSPECIFIED: UserIdHashType.unspecified,\n    }\n\n    return name_id_format_to_hash_type.get(\n        name_format, UserIdHashType.transient\n    )", "response": "Translate pySAML2 name format to satosa format"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntranslate satosa format to pySAML2 name format", "response": "def hash_type_to_saml_name_id_format(hash_type):\n    \"\"\"\n    Translate satosa format to pySAML2 name format\n\n    :type hash_type: satosa.internal_data.UserIdHashType\n    :rtype: str\n    :param hash_type: satosa format\n    :return: pySAML2 name format\n    \"\"\"\n    msg = \"hash_type_to_saml_name_id_format is deprecated and will be removed.\"\n    _warnings.warn(msg, DeprecationWarning)\n\n    hash_type_to_name_id_format = {\n        UserIdHashType.transient: NAMEID_FORMAT_TRANSIENT,\n        UserIdHashType.persistent: NAMEID_FORMAT_PERSISTENT,\n        UserIdHashType.emailaddress: NAMEID_FORMAT_EMAILADDRESS,\n        UserIdHashType.unspecified: NAMEID_FORMAT_UNSPECIFIED,\n    }\n\n    return hash_type_to_name_id_format.get(hash_type, NAMEID_FORMAT_PERSISTENT)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate an InternalResponse object from a dictionary representation of an InternalResponse object.", "response": "def from_dict(cls, data):\n        \"\"\"\n        :type data: dict[str, dict[str, str] | str]\n        :rtype: satosa.internal_data.InternalResponse\n        :param data: A dict representation of an InternalResponse object\n        :return: An InternalResponse object\n        \"\"\"\n        auth_info = _AuthenticationInformation.from_dict(data.get(\"auth_info\"))\n        instance = cls(auth_info=auth_info)\n        instance.user_id_hash_type = data.get(\"hash_type\")\n        instance.attributes = data.get(\"attributes\", {})\n        instance.user_id = data.get(\"user_id\")\n        instance.requester = data.get(\"requester\")\n        return instance"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save_state(internal_request, state):\n        state_data = {\"hash_type\": internal_request.user_id_hash_type}\n        state[UserIdHasher.STATE_KEY] = state_data", "response": "Saves all necessary information needed by the UserIdHasher\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef hash_data(salt, value):\n        msg = \"UserIdHasher is deprecated; use satosa.util.hash_data instead.\"\n        _warnings.warn(msg, DeprecationWarning)\n        return util.hash_data(salt, value)", "response": "Hash a value together with a salt."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef hash_id(salt, user_id, requester, state):\n        hash_type_to_format = {\n            NAMEID_FORMAT_TRANSIENT: \"{id}{req}{time}\",\n            NAMEID_FORMAT_PERSISTENT: \"{id}{req}\",\n            \"pairwise\": \"{id}{req}\",\n            \"public\": \"{id}\",\n            NAMEID_FORMAT_EMAILADDRESS: \"{id}\",\n            NAMEID_FORMAT_UNSPECIFIED: \"{id}\",\n        }\n\n        format_args = {\n            \"id\": user_id,\n            \"req\": requester,\n            \"time\": datetime.datetime.utcnow().timestamp(),\n        }\n\n        hash_type = UserIdHasher.hash_type(state)\n        try:\n            fmt = hash_type_to_format[hash_type]\n        except KeyError as e:\n            raise ValueError(\"Unknown hash type: {}\".format(hash_type)) from e\n        else:\n            user_id = fmt.format(**format_args)\n\n        hasher = (\n            (lambda salt, value: value)\n            if hash_type\n            in [NAMEID_FORMAT_EMAILADDRESS, NAMEID_FORMAT_UNSPECIFIED]\n            else util.hash_data\n        )\n        return hasher(salt, user_id)", "response": "Hashes a user id to the internal_response containing the hashed user ID"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstarting the authentication process.", "response": "def start_auth(self, context, internal_request, get_state=stateID):\n        \"\"\"\n        :param get_state: Generates a state to be used in authentication call\n\n        :type get_state: Callable[[str, bytes], str]\n        :type context: satosa.context.Context\n        :type internal_request: satosa.internal.InternalData\n        :rtype satosa.response.Redirect\n        \"\"\"\n        oauth_state = get_state(self.config[\"base_url\"], rndstr().encode())\n        context.state[self.name] = dict(state=oauth_state)\n\n        request_args = dict(\n            client_id=self.config['client_config']['client_id'],\n            redirect_uri=self.redirect_url,\n            state=oauth_state,\n            allow_signup=self.config.get('allow_signup', False))\n        scope = ' '.join(self.config['scope'])\n        if scope:\n            request_args['scope'] = scope\n\n        cis = self.consumer.construct_AuthorizationRequest(\n            request_args=request_args)\n        return Redirect(cis.request(self.consumer.authorization_endpoint))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unpack_post(environ, content_length):\n    post_body = environ['wsgi.input'].read(content_length).decode(\"utf-8\")\n    data = None\n    if \"application/x-www-form-urlencoded\" in environ[\"CONTENT_TYPE\"]:\n        data = dict(parse_qsl(post_body))\n    elif \"application/json\" in environ[\"CONTENT_TYPE\"]:\n        data = json.loads(post_body)\n\n    logger.debug(\"unpack_post:: %s\", data)\n    return data", "response": "Unpacks a POST request query string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef unpack_request(environ, content_length=0):\n    data = None\n    if environ[\"REQUEST_METHOD\"] == \"GET\":\n        data = unpack_get(environ)\n    elif environ[\"REQUEST_METHOD\"] == \"POST\":\n        data = unpack_post(environ, content_length)\n\n    logger.debug(\"read request data: %s\", data)\n    return data", "response": "Unpacks a get or post request query string."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninsert a path to the context.", "response": "def path(self, p):\n        \"\"\"\n        Inserts a path to the context.\n        This path is striped by the base_url, so for example:\n            A path BASE_URL/ENDPOINT_URL, would be inserted as only ENDPOINT_URL\n            https://localhost:8092/sso/redirect -> sso/redirect\n\n        :type p: str\n\n        :param p: A path to an endpoint.\n        :return: None\n        \"\"\"\n        if not p:\n            raise ValueError(\"path can't be set to None\")\n        elif p.startswith('/'):\n            raise ValueError(\"path can't start with '/'\")\n        self._path = p"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_backends(config, callback, internal_attributes):\n    backend_modules = _load_plugins(config.get(\"CUSTOM_PLUGIN_MODULE_PATHS\"), config[\"BACKEND_MODULES\"], backend_filter,\n                                    config[\"BASE\"], internal_attributes, callback)\n    logger.info(\"Setup backends: %s\" % [backend.name for backend in backend_modules])\n    return backend_modules", "response": "Load all backend modules specified in the config"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_frontends(config, callback, internal_attributes):\n    frontend_modules = _load_plugins(config.get(\"CUSTOM_PLUGIN_MODULE_PATHS\"), config[\"FRONTEND_MODULES\"],\n                                     frontend_filter, config[\"BASE\"], internal_attributes, callback)\n    logger.info(\"Setup frontends: %s\" % [frontend.name for frontend in frontend_modules])\n    return frontend_modules", "response": "Load all frontend modules specified in the config and callback."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns true if the class is a subclass of MicroService.", "response": "def _micro_service_filter(cls):\n    \"\"\"\n    Will only give a find on classes that is a subclass of MicroService, with the exception that\n    the class is not allowed to be a direct ResponseMicroService or RequestMicroService.\n\n    :type cls: type\n    :rtype: bool\n\n    :param cls: A class object\n    :return: True if match, else false\n    \"\"\"\n    is_microservice_module = issubclass(cls, MicroService)\n    is_correct_subclass = cls != MicroService and cls != ResponseMicroService and cls != RequestMicroService\n    return is_microservice_module and is_correct_subclass"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload endpoint plugins from the given plugins list.", "response": "def _load_plugins(plugin_paths, plugins, plugin_filter, base_url, internal_attributes, callback):\n    \"\"\"\n    Loads endpoint plugins\n\n    :type plugin_paths: list[str]\n    :type plugins: list[str]\n    :type plugin_filter: (type | str) -> bool\n    :type internal_attributes: dict[string, dict[str, str | list[str]]]\n    :rtype list[satosa.plugin_base.endpoint.InterfaceModulePlugin]\n\n    :param plugin_paths: Path to the plugin directory\n    :param plugins: A list with the name of the plugin files\n    :param plugin_filter: Filter what to load from the module file\n    :param args: Arguments to the plugin\n    :return: A list with all the loaded plugins\n    \"\"\"\n    loaded_plugin_modules = []\n    with prepend_to_import_path(plugin_paths):\n        for plugin_config in plugins:\n            try:\n                module_class = _load_endpoint_module(plugin_config, plugin_filter)\n            except SATOSAConfigurationError as e:\n                raise SATOSAConfigurationError(\"Configuration error in {}\".format(json.dumps(plugin_config))) from e\n\n            if module_class:\n                module_config = _replace_variables_in_plugin_module_config(plugin_config[\"config\"], base_url,\n                                                                           plugin_config[\"name\"])\n                instance = module_class(callback, internal_attributes, module_config, base_url,\n                                        plugin_config[\"name\"])\n                loaded_plugin_modules.append(instance)\n    return loaded_plugin_modules"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload request micro services from the plugin directory.", "response": "def load_request_microservices(plugin_path, plugins, internal_attributes, base_url):\n    \"\"\"\n    Loads request micro services (handling incoming requests).\n\n    :type plugin_path: list[str]\n    :type plugins: list[str]\n    :type internal_attributes: dict[string, dict[str, str | list[str]]]\n    :type base_url: str\n    :rtype satosa.micro_service.service_base.RequestMicroService\n\n    :param plugin_path: Path to the plugin directory\n    :param plugins: A list with the name of the plugin files\n    :param: base_url: base url of the SATOSA server\n    :return: Request micro service\n    \"\"\"\n    request_services = _load_microservices(plugin_path, plugins, _request_micro_service_filter, internal_attributes,\n                                           base_url)\n    logger.info(\"Loaded request micro services: %s\" % [type(k).__name__ for k in request_services])\n    return request_services"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading response micro services.", "response": "def load_response_microservices(plugin_path, plugins, internal_attributes, base_url):\n    \"\"\"\n    Loads response micro services (handling outgoing responses).\n\n    :type plugin_path: list[str]\n    :type plugins: list[str]\n    :type internal_attributes: dict[string, dict[str, str | list[str]]]\n    :type base_url: str\n    :rtype satosa.micro_service.service_base.ResponseMicroService\n\n    :param plugin_path: Path to the plugin directory\n    :param plugins: A list with the name of the plugin files\n    :param: base_url: base url of the SATOSA server\n    :return: Response micro service\n    \"\"\"\n    response_services = _load_microservices(plugin_path, plugins, _response_micro_service_filter, internal_attributes,\n                                            base_url)\n    logger.info(\"Loaded response micro services: %s\" % [type(k).__name__ for k in response_services])\n    return response_services"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_and_write_saml_metadata(proxy_conf, key, cert, dir, valid, split_frontend_metadata=False,\n                                   split_backend_metadata=False):\n    \"\"\"\n    Generates SAML metadata for the given PROXY_CONF, signed with the given KEY and associated CERT.\n    \"\"\"\n    satosa_config = SATOSAConfig(proxy_conf)\n    secc = _get_security_context(key, cert)\n    frontend_entities, backend_entities = create_entity_descriptors(satosa_config)\n\n    output = []\n    if frontend_entities:\n        if split_frontend_metadata:\n            output.extend(_create_split_entity_descriptors(frontend_entities, secc, valid))\n        else:\n            output.extend(_create_merged_entities_descriptors(frontend_entities, secc, valid, \"frontend.xml\"))\n    if backend_entities:\n        if split_backend_metadata:\n            output.extend(_create_split_entity_descriptors(backend_entities, secc, valid))\n        else:\n            output.extend(_create_merged_entities_descriptors(backend_entities, secc, valid, \"backend.xml\"))\n\n    for metadata, filename in output:\n        path = os.path.join(dir, filename)\n        print(\"Writing metadata to '{}'\".format(path))\n        with open(path, \"w\") as f:\n            f.write(metadata)", "response": "Generates SAML metadata for the given PROXY_CONF signed with the given KEY and associated CERT."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef register_endpoints(self, backend_names):\n        url_map = [(\"^{}\".format(self.name), self.ping_endpoint)]\n\n        return url_map", "response": "Register the endpoints that should be used for the current frontend."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a pyoidc client instance.", "response": "def _create_client(provider_metadata, client_metadata, verify_ssl=True):\n    \"\"\"\n    Create a pyoidc client instance.\n    :param provider_metadata: provider configuration information\n    :type provider_metadata: Mapping[str, Union[str, Sequence[str]]]\n    :param client_metadata: client metadata\n    :type client_metadata: Mapping[str, Union[str, Sequence[str]]]\n    :return: client instance to use for communicating with the configured provider\n    :rtype: oic.oic.Client\n    \"\"\"\n    client = oic.Client(\n        client_authn_method=CLIENT_AUTHN_METHOD, verify_ssl=verify_ssl\n    )\n\n    # Provider configuration information\n    if \"authorization_endpoint\" in provider_metadata:\n        # no dynamic discovery necessary\n        client.handle_provider_config(ProviderConfigurationResponse(**provider_metadata),\n                                      provider_metadata[\"issuer\"])\n    else:\n        # do dynamic discovery\n        client.provider_config(provider_metadata[\"issuer\"])\n\n    # Client information\n    if \"client_id\" in client_metadata:\n        # static client info provided\n        client.store_registration_info(RegistrationRequest(**client_metadata))\n    else:\n        # do dynamic registration\n        client.register(client.provider_info['registration_endpoint'],\n                        **client_metadata)\n\n    client.subject_type = (client.registration_response.get(\"subject_type\") or\n                           client.provider_info[\"subject_types_supported\"][0])\n    return client"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstarting the authentication process.", "response": "def start_auth(self, context, request_info):\n        \"\"\"\n        See super class method satosa.backends.base#start_auth\n        :type context: satosa.context.Context\n        :type request_info: satosa.internal.InternalData\n        \"\"\"\n        oidc_nonce = rndstr()\n        oidc_state = rndstr()\n        state_data = {\n            NONCE_KEY: oidc_nonce,\n            STATE_KEY: oidc_state\n        }\n        context.state[self.name] = state_data\n\n        args = {\n            \"scope\": self.config[\"client\"][\"auth_req_params\"][\"scope\"],\n            \"response_type\": self.config[\"client\"][\"auth_req_params\"][\"response_type\"],\n            \"client_id\": self.client.client_id,\n            \"redirect_uri\": self.client.registration_response[\"redirect_uris\"][0],\n            \"state\": oidc_state,\n            \"nonce\": oidc_nonce\n        }\n        args.update(self.config[\"client\"][\"auth_req_params\"])\n        auth_req = self.client.construct_AuthorizationRequest(request_args=args)\n        login_url = auth_req.request(self.client.authorization_endpoint)\n        return Redirect(login_url)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef register_endpoints(self):\n        url_map = []\n        redirect_path = urlparse(self.config[\"client\"][\"client_metadata\"][\"redirect_uris\"][0]).path\n        if not redirect_path:\n            raise SATOSAError(\"Missing path in redirect uri\")\n\n        url_map.append((\"^%s$\" % redirect_path.lstrip(\"/\"), self.response_endpoint))\n        return url_map", "response": "Creates a list of all the endpoints that this backend module needs to listen to."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nverifies the received OIDC nonce from the ID Token.", "response": "def _verify_nonce(self, nonce, context):\n        \"\"\"\n        Verify the received OIDC 'nonce' from the ID Token.\n        :param nonce: OIDC nonce\n        :type nonce: str\n        :param context: current request context\n        :type context: satosa.context.Context\n        :raise SATOSAAuthenticationError: if the nonce is incorrect\n        \"\"\"\n        backend_state = context.state[self.name]\n        if nonce != backend_state[NONCE_KEY]:\n            satosa_logging(logger, logging.DEBUG,\n                           \"Missing or invalid nonce in authn response for state: %s\" %\n                           backend_state,\n                           context.state)\n            raise SATOSAAuthenticationError(context.state, \"Missing or invalid nonce in authn response\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_tokens(self, authn_response, context):\n        if \"code\" in authn_response:\n            # make token request\n            args = {\n                \"code\": authn_response[\"code\"],\n                \"redirect_uri\": self.client.registration_response['redirect_uris'][0],\n            }\n\n            token_resp = self.client.do_access_token_request(scope=\"openid\", state=authn_response[\"state\"],\n                                                             request_args=args,\n                                                             authn_method=self.client.registration_response[\n                                                                 \"token_endpoint_auth_method\"])\n\n            self._check_error_response(token_resp, context)\n            return token_resp[\"access_token\"], token_resp[\"id_token\"]\n\n        return authn_response.get(\"access_token\"), authn_response.get(\"id_token\")", "response": "Get the access token and ID Token claims from the authentication response."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if the response is an error response.", "response": "def _check_error_response(self, response, context):\n        \"\"\"\n        Check if the response is an OAuth error response.\n        :param response: the OIDC response\n        :type response: oic.oic.message\n        :raise SATOSAAuthenticationError: if the response is an OAuth error response\n        \"\"\"\n        if \"error\" in response:\n            satosa_logging(logger, logging.DEBUG, \"%s error: %s %s\" %\n                           (type(response).__name__, response[\"error\"], response.get(\"error_description\", \"\")),\n                           context.state)\n            raise SATOSAAuthenticationError(context.state, \"Access denied\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef response_endpoint(self, context, *args):\n        backend_state = context.state[self.name]\n        authn_resp = self.client.parse_response(AuthorizationResponse, info=context.request, sformat=\"dict\")\n        if backend_state[STATE_KEY] != authn_resp[\"state\"]:\n            satosa_logging(logger, logging.DEBUG,\n                           \"Missing or invalid state in authn response for state: %s\" %\n                           backend_state,\n                           context.state)\n            raise SATOSAAuthenticationError(context.state, \"Missing or invalid state in authn response\")\n\n        self._check_error_response(authn_resp, context)\n        access_token, id_token_claims = self._get_tokens(authn_resp, context)\n        if id_token_claims:\n            self._verify_nonce(id_token_claims[\"nonce\"], context)\n        else:\n            id_token_claims = {}\n\n        userinfo = {}\n        if access_token:\n            # make userinfo request\n            userinfo = self._get_userinfo(authn_resp[\"state\"], context)\n\n        if not id_token_claims and not userinfo:\n            satosa_logging(logger, logging.ERROR, \"No id_token or userinfo, nothing to do..\", context.state)\n            raise SATOSAAuthenticationError(context.state, \"No user info available.\")\n\n        all_user_claims = dict(list(userinfo.items()) + list(id_token_claims.items()))\n        satosa_logging(logger, logging.DEBUG, \"UserInfo: %s\" % all_user_claims, context.state)\n        del context.state[self.name]\n        internal_resp = self._translate_response(all_user_claims, self.client.authorization_endpoint)\n        return self.auth_callback_func(context, internal_resp)", "response": "Handles the response from the OP."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _translate_response(self, response, issuer):\n        auth_info = AuthenticationInformation(UNSPECIFIED, str(datetime.now()), issuer)\n        internal_resp = InternalData(auth_info=auth_info)\n        internal_resp.attributes = self.converter.to_internal(\"openid\", response)\n        internal_resp.subject_id = response[\"sub\"]\n        return internal_resp", "response": "Translate oidc response to internal response."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprocesses the response from the AL service.", "response": "def process(self, context, internal_response):\n        \"\"\"\n        Manage account linking and recovery\n\n        :type context: satosa.context.Context\n        :type internal_response: satosa.internal.InternalData\n        :rtype: satosa.response.Response\n\n        :param context:\n        :param internal_response:\n        :return: response\n        :\n        \"\"\"\n\n        status_code, message = self._get_uuid(context, internal_response.auth_info.issuer, internal_response.subject_id)\n\n        data = {\n            \"issuer\": internal_response.auth_info.issuer,\n            \"redirect_endpoint\": \"%s/account_linking%s\" % (self.base_url, self.endpoint)\n        }\n\n        # Store the issuer subject_id/sub because we'll need it in handle_al_response\n        internal_response.attributes['issuer_user_id'] = internal_response.subject_id\n        if status_code == 200:\n            satosa_logging(logger, logging.INFO, \"issuer/id pair is linked in AL service\",\n                           context.state)\n            internal_response.subject_id = message\n            data['user_id'] = message\n            if self.id_to_attr:\n                internal_response.attributes[self.id_to_attr] = [message]\n        else:\n            satosa_logging(logger, logging.INFO, \"issuer/id pair is not linked in AL service. Got a ticket\",\n                           context.state)\n            data['ticket'] = message\n        jws = JWS(json.dumps(data), alg=self.signing_key.alg).sign_compact([self.signing_key])\n        context.state[self.name] = internal_response.to_dict()\n        return Redirect(\"%s/%s\" % (self.redirect_url, jws))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_uuid(self, context, issuer, id):\n        data = {\n            \"idp\": issuer,\n            \"id\": id,\n            \"redirect_endpoint\": \"%s/account_linking%s\" % (self.base_url, self.endpoint)\n        }\n        jws = JWS(json.dumps(data), alg=self.signing_key.alg).sign_compact([self.signing_key])\n\n        try:\n            request = \"{}/get_id?jwt={}\".format(self.api_url, jws)\n            response = requests.get(request)\n        except Exception as con_exc:\n            msg = \"Could not connect to account linking service\"\n            satosa_logging(logger, logging.CRITICAL, msg, context.state, exc_info=True)\n            raise SATOSAAuthenticationError(context.state, msg) from con_exc\n\n        if response.status_code not in [200, 404]:\n            msg = \"Got status code '%s' from account linking service\" % (response.status_code)\n            satosa_logging(logger, logging.CRITICAL, msg, context.state)\n            raise SATOSAAuthenticationError(context.state, msg)\n\n        return response.status_code, response.text", "response": "Ask the account linking service for a uuid."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef backend_routing(self, context):\n        satosa_logging(logger, logging.DEBUG, \"Routing to backend: %s \" % context.target_backend, context.state)\n        backend = self.backends[context.target_backend][\"instance\"]\n        context.state[STATE_KEY] = context.target_frontend\n        return backend", "response": "Returns the targeted backend and an updated state\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the targeted frontend and original state", "response": "def frontend_routing(self, context):\n        \"\"\"\n        Returns the targeted frontend and original state\n\n        :type context: satosa.context.Context\n        :rtype satosa.frontends.base.FrontendModule\n\n        :param context: The response context\n        :return: frontend\n        \"\"\"\n\n        target_frontend = context.state[STATE_KEY]\n        satosa_logging(logger, logging.DEBUG, \"Routing to frontend: %s \" % target_frontend, context.state)\n        context.target_frontend = target_frontend\n        frontend = self.frontends[context.target_frontend][\"instance\"]\n        return frontend"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding and returns the endpoint function bound to the path", "response": "def endpoint_routing(self, context):\n        \"\"\"\n        Finds and returns the endpoint function bound to the path\n\n        :type context: satosa.context.Context\n        :rtype: ((satosa.context.Context, Any) -> Any, Any)\n\n        :param context: The request context\n        :return: registered endpoint and bound parameters\n        \"\"\"\n        if context.path is None:\n            satosa_logging(logger, logging.DEBUG, \"Context did not contain a path!\", context.state)\n            raise SATOSABadContextError(\"Context did not contain any path\")\n\n        satosa_logging(logger, logging.DEBUG, \"Routing path: %s\" % context.path, context.state)\n        path_split = context.path.split(\"/\")\n        backend = path_split[0]\n\n        if backend in self.backends:\n            context.target_backend = backend\n        else:\n            satosa_logging(logger, logging.DEBUG, \"Unknown backend %s\" % backend, context.state)\n\n        try:\n            name, frontend_endpoint = self._find_registered_endpoint(context, self.frontends)\n        except ModuleRouter.UnknownEndpoint as e:\n            pass\n        else:\n            context.target_frontend = name\n            return frontend_endpoint\n\n        try:\n            name, micro_service_endpoint = self._find_registered_endpoint(context, self.micro_services)\n        except ModuleRouter.UnknownEndpoint as e:\n            pass\n        else:\n            context.target_micro_service = name\n            return micro_service_endpoint\n\n        if backend in self.backends:\n            backend_endpoint = self._find_registered_backend_endpoint(context)\n            if backend_endpoint:\n                return backend_endpoint\n\n        raise SATOSANoBoundEndpointError(\"'{}' not bound to any function\".format(context.path))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _auth_resp_callback_func(self, context, internal_response):\n\n        context.request = None\n        internal_response.requester = context.state[STATE_KEY][\"requester\"]\n\n        # If configured construct the user id from attribute values.\n        if \"user_id_from_attrs\" in self.config[\"INTERNAL_ATTRIBUTES\"]:\n            subject_id = [\n                \"\".join(internal_response.attributes[attr]) for attr in\n                self.config[\"INTERNAL_ATTRIBUTES\"][\"user_id_from_attrs\"]\n            ]\n            internal_response.subject_id = \"\".join(subject_id)\n\n        if self.response_micro_services:\n            return self.response_micro_services[0].process(\n                context, internal_response)\n\n        return self._auth_resp_finish(context, internal_response)", "response": "This function is called by the backend module when the authentication is complete."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _handle_satosa_authentication_error(self, error):\n        context = Context()\n        context.state = error.state\n        frontend = self.module_router.frontend_routing(context)\n        return frontend.handle_backend_error(error)", "response": "Handle an error that occurred during the authentication process."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _load_state(self, context):\n        try:\n            state = cookie_to_state(\n                    context.cookie,\n                    self.config[\"COOKIE_STATE_NAME\"],\n                    self.config[\"STATE_ENCRYPTION_KEY\"])\n        except SATOSAStateError as e:\n            msg_tmpl = 'Failed to decrypt state {state} with {error}'\n            msg = msg_tmpl.format(state=context.cookie, error=str(e))\n            satosa_logging(logger, logging.WARNING, msg, None)\n            state = State()\n        finally:\n            context.state = state", "response": "Load state from cookie to the context"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _save_state(self, resp, context):\n\n        cookie = state_to_cookie(context.state, self.config[\"COOKIE_STATE_NAME\"], \"/\",\n                                 self.config[\"STATE_ENCRYPTION_KEY\"])\n        resp.headers.append(tuple(cookie.output().split(\": \", 1)))", "response": "Saves a state from context to cookie\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run(self, context):\n        try:\n            self._load_state(context)\n            spec = self.module_router.endpoint_routing(context)\n            resp = self._run_bound_endpoint(context, spec)\n            self._save_state(resp, context)\n        except SATOSANoBoundEndpointError:\n            raise\n        except SATOSAError:\n            satosa_logging(logger, logging.ERROR, \"Uncaught SATOSA error \", context.state,\n                           exc_info=True)\n            raise\n        except UnknownSystemEntity as err:\n            satosa_logging(logger, logging.ERROR,\n                           \"configuration error: unknown system entity \" + str(err),\n                           context.state, exc_info=False)\n            raise\n        except Exception as err:\n            satosa_logging(logger, logging.ERROR, \"Uncaught exception\", context.state,\n                           exc_info=True)\n            raise SATOSAUnknownError(\"Unknown error\") from err\n        return resp", "response": "Runs the satosa proxy with the given context."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates SAML metadata strings for the configured front - and backend plugins.", "response": "def create_entity_descriptors(satosa_config):\n    \"\"\"\n    Creates SAML metadata strings for the configured front- and backends.\n    :param satosa_config: configuration of the proxy\n    :return: a tuple of the frontend metadata (containing IdP entities) and the backend metadata (containing SP\n             entities).\n\n    :type satosa_config: satosa.satosa_config.SATOSAConfig\n    :rtype: Tuple[str, str]\n    \"\"\"\n    frontend_modules = load_frontends(satosa_config, None, satosa_config[\"INTERNAL_ATTRIBUTES\"])\n    backend_modules = load_backends(satosa_config, None, satosa_config[\"INTERNAL_ATTRIBUTES\"])\n    logger.info(\"Loaded frontend plugins: {}\".format([frontend.name for frontend in frontend_modules]))\n    logger.info(\"Loaded backend plugins: {}\".format([backend.name for backend in backend_modules]))\n\n    backend_metadata = _create_backend_metadata(backend_modules)\n    frontend_metadata = _create_frontend_metadata(frontend_modules, backend_modules)\n\n    return frontend_metadata, backend_metadata"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_signed_entities_descriptor(entity_descriptors, security_context, valid_for=None):\n    entities_desc, xmldoc = entities_descriptor(entity_descriptors, valid_for=valid_for, name=None, ident=None,\n                                                sign=True, secc=security_context)\n    if not valid_instance(entities_desc):\n        raise ValueError(\"Could not construct valid EntitiesDescriptor tag\")\n\n    return xmldoc", "response": "Creates a signed EntitiesDescriptor tag and returns it"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a signed XML document for the given entity descriptor.", "response": "def create_signed_entity_descriptor(entity_descriptor, security_context, valid_for=None):\n    \"\"\"\n    :param entity_descriptor: the entity descriptor to sign\n    :param security_context: security context for the signature\n    :param valid_for: number of hours the metadata should be valid\n    :return: the signed XML document\n\n    :type entity_descriptor: saml2.md.EntityDescriptor]\n    :type security_context: saml2.sigver.SecurityContext\n    :type valid_for: Optional[int]\n    \"\"\"\n    if valid_for:\n        entity_descriptor.valid_until = in_a_while(hours=valid_for)\n\n    entity_desc, xmldoc = sign_entity_descriptor(entity_descriptor, None, security_context)\n\n    if not valid_instance(entity_desc):\n        raise ValueError(\"Could not construct valid EntityDescriptor tag\")\n\n    return xmldoc"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef start_auth(self, context, internal_req):\n\n        target_entity_id = context.get_decoration(Context.KEY_TARGET_ENTITYID)\n        if target_entity_id:\n            entity_id = target_entity_id\n            return self.authn_request(context, entity_id)\n\n        # if there is only one IdP in the metadata, bypass the discovery service\n        idps = self.sp.metadata.identity_providers()\n        if len(idps) == 1 and \"mdq\" not in self.config[\"sp_config\"][\"metadata\"]:\n            entity_id = idps[0]\n            return self.authn_request(context, entity_id)\n\n        return self.disco_query()", "response": "Start the authentication process."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmake a request to the discovery server to get the current context and the request s metadata.", "response": "def disco_query(self):\n        \"\"\"\n        Makes a request to the discovery server\n\n        :type context: satosa.context.Context\n        :type internal_req: satosa.internal.InternalData\n        :rtype: satosa.response.SeeOther\n\n        :param context: The current context\n        :param internal_req: The request\n        :return: Response\n        \"\"\"\n        return_url = self.sp.config.getattr(\"endpoints\", \"sp\")[\"discovery_response\"][0][0]\n        loc = self.sp.create_discovery_service_request(self.discosrv, self.sp.config.entityid, **{\"return\": return_url})\n        return SeeOther(loc)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef authn_request(self, context, entity_id):\n\n        # If IDP blacklisting is enabled and the selected IDP is blacklisted,\n        # stop here\n        if self.idp_blacklist_file:\n            with open(self.idp_blacklist_file) as blacklist_file:\n                blacklist_array = json.load(blacklist_file)['blacklist']\n                if entity_id in blacklist_array:\n                    satosa_logging(logger, logging.DEBUG, \"IdP with EntityID {} is blacklisted\".format(entity_id), context.state, exc_info=False)\n                    raise SATOSAAuthenticationError(context.state, \"Selected IdP is blacklisted for this backend\")\n\n        kwargs = {}\n        authn_context = self.construct_requested_authn_context(entity_id)\n        if authn_context:\n            kwargs['requested_authn_context'] = authn_context\n\n        try:\n            binding, destination = self.sp.pick_binding(\n                \"single_sign_on_service\", None, \"idpsso\", entity_id=entity_id)\n            satosa_logging(logger, logging.DEBUG, \"binding: %s, destination: %s\" % (binding, destination),\n                           context.state)\n            acs_endp, response_binding = self.sp.config.getattr(\"endpoints\", \"sp\")[\"assertion_consumer_service\"][0]\n            req_id, req = self.sp.create_authn_request(\n                destination, binding=response_binding, **kwargs)\n            relay_state = util.rndstr()\n            ht_args = self.sp.apply_binding(binding, \"%s\" % req, destination, relay_state=relay_state)\n            satosa_logging(logger, logging.DEBUG, \"ht_args: %s\" % ht_args, context.state)\n        except Exception as exc:\n            satosa_logging(logger, logging.DEBUG, \"Failed to construct the AuthnRequest for state\", context.state,\n                           exc_info=True)\n            raise SATOSAAuthenticationError(context.state, \"Failed to construct the AuthnRequest\") from exc\n\n        if self.sp.config.getattr('allow_unsolicited', 'sp') is False:\n            if req_id in self.outstanding_queries:\n                errmsg = \"Request with duplicate id {}\".format(req_id)\n                satosa_logging(logger, logging.DEBUG, errmsg, context.state)\n                raise SATOSAAuthenticationError(context.state, errmsg)\n            self.outstanding_queries[req_id] = req\n\n        context.state[self.name] = {\"relay_state\": relay_state}\n        return make_saml_response(binding, ht_args)", "response": "Do an authentication request on the given entity id."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _translate_response(self, response, state):\n\n        # The response may have been encrypted by the IdP so if we have an\n        # encryption key, try it.\n        if self.encryption_keys:\n            response.parse_assertion(self.encryption_keys)\n\n        authn_info = response.authn_info()[0]\n        auth_class_ref = authn_info[0]\n        timestamp = response.assertion.authn_statement[0].authn_instant\n        issuer = response.response.issuer.text\n\n        auth_info = AuthenticationInformation(\n            auth_class_ref, timestamp, issuer,\n        )\n\n        # The SAML response may not include a NameID.\n        subject = response.get_subject()\n        name_id = subject.text if subject else None\n        name_id_format = subject.format if subject else None\n\n        attributes = self.converter.to_internal(\n            self.attribute_profile, response.ava,\n        )\n\n        internal_resp = InternalData(\n            auth_info=auth_info,\n            attributes=attributes,\n            subject_type=name_id_format,\n            subject_id=name_id,\n        )\n\n        satosa_logging(logger, logging.DEBUG,\n                       \"backend received attributes:\\n%s\" %\n                       json.dumps(response.ava, indent=4), state)\n        return internal_resp", "response": "Translate a SAML response to an internal response."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef register_endpoints(self):\n        url_map = []\n        sp_endpoints = self.sp.config.getattr(\"endpoints\", \"sp\")\n        for endp, binding in sp_endpoints[\"assertion_consumer_service\"]:\n            parsed_endp = urlparse(endp)\n            url_map.append((\"^%s$\" % parsed_endp.path[1:], functools.partial(self.authn_response, binding=binding)))\n\n        if self.discosrv:\n            for endp, binding in sp_endpoints[\"discovery_response\"]:\n                parsed_endp = urlparse(endp)\n                url_map.append(\n                    (\"^%s$\" % parsed_endp.path[1:], self.disco_response))\n\n        if self.expose_entityid_endpoint():\n            parsed_entity_id = urlparse(self.sp.config.entityid)\n            url_map.append((\"^{0}\".format(parsed_entity_id.path[1:]),\n                            self._metadata_endpoint))\n\n        return url_map", "response": "Register the endpoints that are available for the current context."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the metadata description for the current class.", "response": "def get_metadata_desc(self):\n        \"\"\"\n        See super class satosa.backends.backend_base.BackendModule#get_metadata_desc\n        :rtype: satosa.metadata_creation.description.MetadataDescription\n        \"\"\"\n        entity_descriptions = []\n\n        idp_entities = self.sp.metadata.with_descriptor(\"idpsso\")\n        for entity_id, entity in idp_entities.items():\n            description = MetadataDescription(urlsafe_b64encode(entity_id.encode(\"utf-8\")).decode(\"utf-8\"))\n\n            # Add organization info\n            try:\n                organization_info = entity[\"organization\"]\n            except KeyError:\n                pass\n            else:\n                organization = OrganizationDesc()\n                for name_info in organization_info.get(\"organization_name\", []):\n                    organization.add_name(name_info[\"text\"], name_info[\"lang\"])\n                for display_name_info in organization_info.get(\"organization_display_name\", []):\n                    organization.add_display_name(display_name_info[\"text\"], display_name_info[\"lang\"])\n                for url_info in organization_info.get(\"organization_url\", []):\n                    organization.add_url(url_info[\"text\"], url_info[\"lang\"])\n                description.organization = organization\n\n            # Add contact person info\n            try:\n                contact_persons = entity[\"contact_person\"]\n            except KeyError:\n                pass\n            else:\n                for person in contact_persons:\n                    person_desc = ContactPersonDesc()\n                    person_desc.contact_type = person.get(\"contact_type\")\n                    for address in person.get('email_address', []):\n                        person_desc.add_email_address(address[\"text\"])\n                    if \"given_name\" in person:\n                        person_desc.given_name = person[\"given_name\"][\"text\"]\n                    if \"sur_name\" in person:\n                        person_desc.sur_name = person[\"sur_name\"][\"text\"]\n\n                    description.add_contact_person(person_desc)\n\n            # Add UI info\n            ui_info = self.sp.metadata.extension(entity_id, \"idpsso_descriptor\", \"{}&UIInfo\".format(UI_NAMESPACE))\n            if ui_info:\n                ui_info = ui_info[0]\n                ui_info_desc = UIInfoDesc()\n                for desc in ui_info.get(\"description\", []):\n                    ui_info_desc.add_description(desc[\"text\"], desc[\"lang\"])\n                for name in ui_info.get(\"display_name\", []):\n                    ui_info_desc.add_display_name(name[\"text\"], name[\"lang\"])\n                for logo in ui_info.get(\"logo\", []):\n                    ui_info_desc.add_logo(logo[\"text\"], logo[\"width\"], logo[\"height\"], logo.get(\"lang\"))\n                description.ui_info = ui_info_desc\n\n            entity_descriptions.append(description)\n        return entity_descriptions"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a dictionary representation of the ContactPersonDesc.", "response": "def to_dict(self):\n        \"\"\"\n        Returns a dictionary representation of the ContactPersonDesc.\n        The format is the same as a pysaml2 configuration for a contact person.\n        :rtype: dict[str, str]\n        :return: A dictionary representation\n        \"\"\"\n        person = {}\n        if self.contact_type:\n            person[\"contact_type\"] = self.contact_type\n        if self._email_address:\n            person[\"email_address\"] = self._email_address\n        if self.given_name:\n            person[\"given_name\"] = self.given_name\n        if self.sur_name:\n            person[\"sur_name\"] = self.sur_name\n        return person"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a logo to the logo list", "response": "def add_logo(self, text, width, height, lang=None):\n        \"\"\"\n        Binds a logo to the given language\n        :type text: str\n        :type width: str\n        :type height: str\n        :type lang: Optional[str]\n\n        :param text: Path to logo\n        :param width: width of logo\n        :param height: height of logo\n        :param lang: language\n        \"\"\"\n\n        logo_entry ={\"text\": text, \"width\": width, \"height\": height}\n        if lang:\n            logo_entry[\"lang\"] = lang\n        self._logos.append(logo_entry)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a dictionary representation of the UIInfoDesc object.", "response": "def to_dict(self):\n        \"\"\"\n        Returns a dictionary representation of the UIInfoDesc object.\n        The format is the same as a pysaml2 configuration for ui info.\n        :rtype: dict[str, str]\n        :return: A dictionary representation\n        \"\"\"\n        ui_info = {}\n        if self._description:\n            ui_info[\"description\"] = self._description\n        if self._display_name:\n            ui_info[\"display_name\"] = self._display_name\n        if self._logos:\n            ui_info[\"logo\"] = self._logos\n        return {\"service\": {\"idp\": {\"ui_info\": ui_info}}} if ui_info else {}"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a dictionary representation of the OrganizationDesc object.", "response": "def to_dict(self):\n        \"\"\"\n        Returns a dictionary representation of the OrganizationDesc object.\n        The format is the same as a pysaml2 configuration for organization.\n        :rtype: dict[str, str]\n        :return: A dictionary representation\n        \"\"\"\n        org = {}\n        if self._display_name:\n            org[\"display_name\"] = self._display_name\n        if self._name:\n            org[\"name\"] = self._name\n        if self._url:\n            org[\"url\"] = self._url\n        return {\"organization\": org} if org else {}"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the organization to the description", "response": "def organization(self, organization):\n        \"\"\"\n        Set an organization to the description\n        :type organization: satosa.metadata_creation.description.OrganizationDesc\n        :param organization: Organization description\n        \"\"\"\n        if not isinstance(organization, OrganizationDesc):\n            raise TypeError(\"organization must be of type OrganizationDesc\")\n        self._organization = organization"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a contact person to the description", "response": "def add_contact_person(self, person):\n        \"\"\"\n        Adds a contact person to the description\n        :type person: satosa.metadata_creation.description.ContactPersonDesc\n        :param person: The contact person to be added\n        \"\"\"\n        if not isinstance(person, ContactPersonDesc):\n            raise TypeError(\"person must be of type ContactPersonDesc\")\n        self._contact_person.append(person)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ui_info(self, ui_info):\n        if not isinstance(ui_info, UIInfoDesc):\n            raise TypeError(\"ui_info must be of type UIInfoDesc\")\n        self._ui_info = ui_info", "response": "Set the ui info to the description\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a dictionary representation of the MetadataDescription object.", "response": "def to_dict(self):\n        \"\"\"\n        Returns a dictionary representation of the MetadataDescription object.\n        The format is the same as a pysaml2 configuration\n        :rtype: dict[str, Any]\n        :return: A dictionary representation\n        \"\"\"\n        description = {}\n        description[\"entityid\"] = self.entity_id\n        if self._organization:\n            description.update(self._organization.to_dict())\n        if self._contact_person:\n            description['contact_person'] = []\n            for person in self._contact_person:\n                description['contact_person'].append(person.to_dict())\n        if self._ui_info:\n            description.update(self._ui_info.to_dict())\n        return description"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhandles an OpenID response.", "response": "def handle_authn_response(self, context, internal_resp, extra_id_token_claims=None):\n        \"\"\"\n        See super class method satosa.frontends.base.FrontendModule#handle_authn_response\n        :type context: satosa.context.Context\n        :type internal_response: satosa.internal.InternalData\n        :rtype oic.utils.http_util.Response\n        \"\"\"\n\n        auth_req = self._get_authn_request_from_state(context.state)\n\n        attributes = self.converter.from_internal(\"openid\", internal_resp.attributes)\n        self.user_db[internal_resp.subject_id] = {k: v[0] for k, v in attributes.items()}\n        auth_resp = self.provider.authorize(\n            auth_req,\n            internal_resp.subject_id,\n            extra_id_token_claims=extra_id_token_claims,\n        )\n\n        del context.state[self.name]\n        http_response = auth_resp.request(auth_req[\"redirect_uri\"], should_fragment_encode(auth_req))\n        return SeeOther(http_response)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhandle an exception raised by the backend.", "response": "def handle_backend_error(self, exception):\n        \"\"\"\n        See super class satosa.frontends.base.FrontendModule\n        :type exception: satosa.exception.SATOSAError\n        :rtype: oic.utils.http_util.Response\n        \"\"\"\n        auth_req = self._get_authn_request_from_state(exception.state)\n        # If the client sent us a state parameter, we should reflect it back according to the spec\n        if 'state' in auth_req:\n            error_resp = AuthorizationErrorResponse(error=\"access_denied\",\n                                                    error_description=exception.message,\n                                                    state=auth_req['state'])\n        else:\n            error_resp = AuthorizationErrorResponse(error=\"access_denied\",\n                                                    error_description=exception.message)\n        satosa_logging(logger, logging.DEBUG, exception.message, exception.state)\n        return SeeOther(error_resp.request(auth_req[\"redirect_uri\"], should_fragment_encode(auth_req)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef register_endpoints(self, backend_names):\n        backend_name = None\n        if len(backend_names) != 1:\n            # only supports one backend since there currently is no way to publish multiple authorization endpoints\n            # in configuration information and there is no other standard way of authorization_endpoint discovery\n            # similar to SAML entity discovery\n            # this can be circumvented with a custom RequestMicroService which handles the routing based on something\n            # in the authentication request\n            logger.warn(\"More than one backend is configured, make sure to provide a custom routing micro service to \"\n                        \"determine which backend should be used per request.\")\n        else:\n            backend_name = backend_names[0]\n\n        endpoint_baseurl = \"{}/{}\".format(self.base_url, self.name)\n        self._create_provider(endpoint_baseurl)\n\n        provider_config = (\"^.well-known/openid-configuration$\", self.provider_config)\n        jwks_uri = (\"^{}/jwks$\".format(self.name), self.jwks)\n\n        if backend_name:\n            # if there is only one backend, include its name in the path so the default routing can work\n            auth_endpoint = \"{}/{}/{}/{}\".format(self.base_url, backend_name, self.name, AuthorizationEndpoint.url)\n            self.provider.configuration_information[\"authorization_endpoint\"] = auth_endpoint\n            auth_path = urlparse(auth_endpoint).path.lstrip(\"/\")\n        else:\n            auth_path = \"{}/{}\".format(self.name, AuthorizationEndpoint.url)\n        authentication = (\"^{}$\".format(auth_path), self.handle_authn_request)\n        url_map = [provider_config, jwks_uri, authentication]\n\n        if any(\"code\" in v for v in self.provider.configuration_information[\"response_types_supported\"]):\n            self.provider.configuration_information[\"token_endpoint\"] = \"{}/{}\".format(endpoint_baseurl,\n                                                                                       TokenEndpoint.url)\n            token_endpoint = (\"^{}/{}\".format(self.name, TokenEndpoint.url), self.token_endpoint)\n            url_map.append(token_endpoint)\n\n            self.provider.configuration_information[\"userinfo_endpoint\"] = \"{}/{}\".format(endpoint_baseurl,\n                                                                                          UserinfoEndpoint.url)\n            userinfo_endpoint = (\"^{}/{}\".format(self.name, UserinfoEndpoint.url), self.userinfo_endpoint)\n            url_map.append(userinfo_endpoint)\n        if \"registration_endpoint\" in self.provider.configuration_information:\n            client_registration = (\"^{}/{}\".format(self.name, RegistrationEndpoint.url), self.client_registration)\n            url_map.append(client_registration)\n\n        return url_map", "response": "Register the endpoints for the current backend."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nvalidating that all necessary config parameters are specified.", "response": "def _validate_config(self, config):\n        \"\"\"\n        Validates that all necessary config parameters are specified.\n        :type config: dict[str, dict[str, Any] | str]\n        :param config: the module config\n        \"\"\"\n        if config is None:\n            raise ValueError(\"OIDCFrontend conf can't be 'None'.\")\n\n        for k in {\"signing_key_path\", \"provider\"}:\n            if k not in config:\n                raise ValueError(\"Missing configuration parameter '{}' for OpenID Connect frontend.\".format(k))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef client_registration(self, context):\n        try:\n            resp = self.provider.handle_client_registration_request(json.dumps(context.request))\n            return Created(resp.to_json(), content=\"application/json\")\n        except InvalidClientRegistrationRequest as e:\n            return BadRequest(e.to_json(), content=\"application/json\")", "response": "Handle the OIDC dynamic client registration request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _handle_authn_request(self, context):\n        request = urlencode(context.request)\n        satosa_logging(logger, logging.DEBUG, \"Authn req from client: {}\".format(request),\n                       context.state)\n\n        try:\n            authn_req = self.provider.parse_authentication_request(request)\n        except InvalidAuthenticationRequest as e:\n            satosa_logging(logger, logging.ERROR, \"Error in authn req: {}\".format(str(e)),\n                           context.state)\n            error_url = e.to_error_url()\n\n            if error_url:\n                return SeeOther(error_url)\n            else:\n                return BadRequest(\"Something went wrong: {}\".format(str(e)))\n\n        client_id = authn_req[\"client_id\"]\n        context.state[self.name] = {\"oidc_request\": request}\n        subject_type = self.provider.clients[client_id].get(\"subject_type\", \"pairwise\")\n        client_name = self.provider.clients[client_id].get(\"client_name\")\n        if client_name:\n            # TODO should process client names for all languages, see OIDC Registration, Section 2.1\n            requester_name = [{\"lang\": \"en\", \"text\": client_name}]\n        else:\n            requester_name = None\n        internal_req = InternalData(\n            subject_type=subject_type,\n            requester=client_id,\n            requester_name=requester_name,\n        )\n\n        internal_req.attributes = self.converter.to_internal_filter(\n            \"openid\", self._get_approved_attributes(self.provider.configuration_information[\"claims_supported\"],\n                                                    authn_req))\n        return internal_req", "response": "Parse and verify the authentication request into an internal request."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef handle_authn_request(self, context):\n        internal_req = self._handle_authn_request(context)\n        if not isinstance(internal_req, InternalData):\n            return internal_req\n        return self.auth_req_callback_func(context, internal_req)", "response": "Handle an authentication request and pass it on to the client."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef jwks(self, context):\n        return Response(json.dumps(self.provider.jwks), content=\"application/json\")", "response": "Construct the JWKS document for the current context."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhandle token requests at token endpoint.", "response": "def token_endpoint(self, context):\n        \"\"\"\n        Handle token requests (served at /token).\n        :type context: satosa.context.Context\n        :rtype: oic.utils.http_util.Response\n\n        :param context: the current context\n        :return: HTTP response to the client\n        \"\"\"\n        headers = {\"Authorization\": context.request_authorization}\n        try:\n            response = self.provider.handle_token_request(urlencode(context.request), headers)\n            return Response(response.to_json(), content=\"application/json\")\n        except InvalidClientAuthentication as e:\n            logger.debug('invalid client authentication at token endpoint', exc_info=True)\n            error_resp = TokenErrorResponse(error='invalid_client', error_description=str(e))\n            response = Unauthorized(error_resp.to_json(), headers=[(\"WWW-Authenticate\", \"Basic\")],\n                                    content=\"application/json\")\n            return response\n        except OAuthError as e:\n            logger.debug('invalid request: %s', str(e), exc_info=True)\n            error_resp = TokenErrorResponse(error=e.oauth_error, error_description=str(e))\n            return BadRequest(error_resp.to_json(), content=\"application/json\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nextract the scope from a mako template", "response": "def scope(s):\n    \"\"\"\n    Mako filter: used to extract scope from attribute\n    :param s: string to extract scope from (filtered string in mako template)\n    :return: the scope\n    \"\"\"\n    if '@' not in s:\n        raise ValueError(\"Unscoped string\")\n    (local_part, _, domain_part) = s.partition('@')\n    return domain_part"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts attribute names from external type to internal format", "response": "def to_internal_filter(self, attribute_profile, external_attribute_names):\n        \"\"\"\n        Converts attribute names from external \"type\" to internal\n\n        :type attribute_profile: str\n        :type external_attribute_names: list[str]\n        :type case_insensitive: bool\n        :rtype: list[str]\n\n        :param attribute_profile: From which external type to convert (ex: oidc, saml, ...)\n        :param external_attribute_names: A list of attribute names\n        :param case_insensitive: Create a case insensitive filter\n        :return: A list of attribute names in the internal format\n        \"\"\"\n        try:\n            profile_mapping = self.to_internal_attributes[attribute_profile]\n        except KeyError:\n            logger.warn(\"no attribute mapping found for the given attribute profile '%s'\", attribute_profile)\n            # no attributes since the given profile is not configured\n            return []\n\n        internal_attribute_names = set()  # use set to ensure only unique values\n        for external_attribute_name in external_attribute_names:\n            try:\n                internal_attribute_name = profile_mapping[external_attribute_name]\n                internal_attribute_names.add(internal_attribute_name)\n            except KeyError:\n                pass\n\n        return list(internal_attribute_names)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_internal(self, attribute_profile, external_dict):\n        internal_dict = {}\n\n        for internal_attribute_name, mapping in self.from_internal_attributes.items():\n            if attribute_profile not in mapping:\n                logger.debug(\"no attribute mapping found for internal attribute '%s' the attribute profile '%s'\" % (\n                    internal_attribute_name, attribute_profile))\n                # skip this internal attribute if we have no mapping in the specified profile\n                continue\n\n            external_attribute_name = mapping[attribute_profile]\n            attribute_values = self._collate_attribute_values_by_priority_order(external_attribute_name,\n                                                                                external_dict)\n            if attribute_values:  # Only insert key if it has some values\n                logger.debug(\"backend attribute '%s' mapped to %s\" % (external_attribute_name,\n                                                            internal_attribute_name))\n                internal_dict[internal_attribute_name] = attribute_values\n            else:\n                logger.debug(\"skipped backend attribute '%s': no value found\", external_attribute_name)\n\n        internal_dict = self._handle_template_attributes(attribute_profile, internal_dict)\n        return internal_dict", "response": "Converts the external data from type to internal format."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting the internal data to the external data.", "response": "def from_internal(self, attribute_profile, internal_dict):\n        \"\"\"\n        Converts the internal data to \"type\"\n\n        :type attribute_profile: str\n        :type internal_dict: dict[str, str]\n        :rtype: dict[str, str]\n\n        :param attribute_profile: To which external type to convert (ex: oidc, saml, ...)\n        :param internal_dict: attributes to map\n        :return: attribute values and names in the specified \"profile\"\n        \"\"\"\n        external_dict = {}\n        for internal_attribute_name in internal_dict:\n            try:\n                attribute_mapping = self.from_internal_attributes[internal_attribute_name]\n            except KeyError:\n                logger.debug(\"no attribute mapping found for the internal attribute '%s'\", internal_attribute_name)\n                continue\n\n            if attribute_profile not in attribute_mapping:\n                # skip this internal attribute if we have no mapping in the specified profile\n                logger.debug(\"no mapping found for '%s' in attribute profile '%s'\" %\n                             (internal_attribute_name,\n                             attribute_profile))\n                continue\n\n            external_attribute_names = self.from_internal_attributes[internal_attribute_name][attribute_profile]\n            # select the first attribute name\n            external_attribute_name = external_attribute_names[0]\n            logger.debug(\"frontend attribute %s mapped from %s\" % (external_attribute_name,\n                                                                   internal_attribute_name))\n\n            if self.separator in external_attribute_name:\n                nested_attribute_names = external_attribute_name.split(self.separator)\n                nested_dict = self._create_nested_attribute_value(nested_attribute_names[1:],\n                                                                  internal_dict[internal_attribute_name])\n                external_dict[nested_attribute_names[0]] = nested_dict\n            else:\n                external_dict[external_attribute_name] = internal_dict[internal_attribute_name]\n\n        return external_dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _serialize(self, version, serialize_format, context, raise_if_incomplete=False):\n        values = context.copy()\n        for k in version:\n            values[k] = version[k]\n\n        # TODO dump complete context on debug level\n\n        try:\n            # test whether all parts required in the format have values\n            serialized = serialize_format.format(**values)\n\n        except KeyError as e:\n            missing_key = getattr(e, \"message\", e.args[0])\n            raise MissingValueForSerializationException(\n                \"Did not find key {} in {} when serializing version number\".format(\n                    repr(missing_key), repr(version)\n                )\n            )\n\n        keys_needing_representation = set()\n        found_required = False\n\n        for k in self.order():\n            v = values[k]\n\n            if not isinstance(v, VersionPart):\n                # values coming from environment variables don't need\n                # representation\n                continue\n\n            if not v.is_optional():\n                found_required = True\n                keys_needing_representation.add(k)\n            elif not found_required:\n                keys_needing_representation.add(k)\n\n        required_by_format = set(self._labels_for_format(serialize_format))\n\n        # try whether all parsed keys are represented\n        if raise_if_incomplete:\n            if not (keys_needing_representation <= required_by_format):\n                raise IncompleteVersionRepresentationException(\n                    \"Could not represent '{}' in format '{}'\".format(\n                        \"', '\".join(keys_needing_representation ^ required_by_format),\n                        serialize_format,\n                    )\n                )\n\n        return serialized", "response": "Serializes a version with the given serialization format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the text of the selected option in a ButtonGroup by its text value.", "response": "def value_text(self):\n        \"\"\"\n        Sets or returns the option selected in a ButtonGroup by its text value.\n        \"\"\"\n        search = self._selected.get() # a string containing the selected option\n        # This is a bit nasty - suggestions welcome\n        for item in self._rbuttons:\n            if item.value == search:\n                return item.text\n        return \"\""}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nappend a new option to the end of the ButtonGroup.", "response": "def append(self, option):\n        \"\"\"\n        Appends a new `option` to the end of the ButtonGroup.\n\n        :param string/List option:\n            The option to append to the ButtonGroup. If a 2D list is specified,\n            the first element is the text, the second is the value.\n        \"\"\"\n        self._options.append(self._parse_option(option))\n        self._refresh_options()\n        self.resize(self._width, self._height)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninserts a new option in the ButtonGroup at the specified index.", "response": "def insert(self, index, option):\n        \"\"\"\n        Insert a new `option` in the ButtonGroup at `index`.\n\n        :param int option:\n            The index of where to insert the option.\n\n        :param string/List option:\n            The option to append to the ButtonGroup. If a 2D list is specified,\n            the first element is the text, the second is the value.\n        \"\"\"\n        self._options.insert(index, self._parse_option(option))\n        self._refresh_options()\n        self.resize(self._width, self._height)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove the first option from the ButtonGroup.", "response": "def remove(self, option):\n        \"\"\"\n        Removes the first `option` from the ButtonGroup.\n\n        Returns `True` if an item was removed.\n\n        :param string option:\n            The value of the option to remove from the ButtonGroup.\n        \"\"\"\n        for existing_option in self._options:\n            if existing_option[1] == option:\n                self._options.remove(existing_option)\n                self._refresh_options()\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating the callback command which is called when the ButtonGroup changes.", "response": "def update_command(self, command, args=None):\n        \"\"\"\n        Updates the callback command which is called when the ButtonGroup\n        changes.\n\n        Setting to `None` stops the callback.\n\n        :param callback command:\n            The callback function to call.\n\n        :param callback args:\n            A list of arguments to pass to the widgets `command`, defaults to\n            `None`.\n        \"\"\"\n        if command is None:\n            self._command = lambda: None\n        else:\n            if args is None:\n                self._command = command\n            else:\n                self._command = utils.with_args(command, *args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nselects the default option of the current item in the combo box.", "response": "def select_default(self):\n        \"\"\"\n        Resets the combo box to the original \"selected\" value from the\n        constructor (or the first value if no selected value was specified).\n        \"\"\"\n        if self._default is None:\n            if not self._set_option_by_index(0):\n                utils.error_format(self.description + \"\\n\" +\n                \"Unable to select default option as the Combo is empty\")\n\n        else:\n            if not self._set_option(self._default):\n                utils.error_format( self.description + \"\\n\" +\n                \"Unable to select default option as it doesnt exist in the Combo\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninsert a new option into the Combo at the specified index.", "response": "def insert(self, index, option):\n        \"\"\"\n        Insert a new `option` in the Combo at `index`.\n\n        :param int option:\n            The index of where to insert the option.\n\n        :param string option:\n            The option to insert into to the Combo.\n        \"\"\"\n        option = str(option)\n        self._options.insert(index, option)\n        # if this is the first option, set it.\n        if len(self._options) == 1:\n            self.value = option\n\n        self._refresh_options()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove the first option from the Combo.", "response": "def remove(self, option):\n        \"\"\"\n        Removes the first `option` from the Combo.\n\n        Returns `True` if an item was removed.\n\n        :param string option:\n            The option to remove from the Combo.\n        \"\"\"\n        if option in self._options:\n            if len(self._options) == 1:\n                # this is the last option in the list so clear it\n                self.clear()\n            else:\n                self._options.remove(option)\n                self._refresh_options()\n                # have we just removed the selected option?\n                # if so set it to the first option\n                if option == self.value:\n                    self._set_option(self._options[0])\n            return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clear(self):\n        self._options = []\n        self._combo_menu.tk.delete(0, END)\n        self._selected.set(\"\")", "response": "Clears all the options in a Combo\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset a single option in the Combo returning True if it was able too.", "response": "def _set_option(self, value):\n        \"\"\"\n        Sets a single option in the Combo, returning True if it was able too.\n        \"\"\"\n        if len(self._options) > 0:\n            if value in self._options:\n                self._selected.set(value)\n                return True\n            else:\n                return False\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_option_by_index(self, index):\n        if index < len(self._options):\n            self._selected.set(self._options[index])\n            return True\n        else:\n            return False", "response": "Sets a single option in the Combo by its index returning True if it was able too."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncall function after time milliseconds.", "response": "def after(self, time, function, args = []):\n        \"\"\"Call `function` after `time` milliseconds.\"\"\"\n        callback_id = self.tk.after(time, self._call_wrapper, time, function, *args)\n        self._callback[function] = [callback_id, False]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef repeat(self, time, function, args = []):\n        callback_id = self.tk.after(time, self._call_wrapper, time, function, *args)\n        self._callback[function] = [callback_id, True]", "response": "Repeat function every time milliseconds."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncancels the scheduled function calls.", "response": "def cancel(self, function):\n        \"\"\"Cancel the scheduled `function` calls.\"\"\"\n        if function in self._callback.keys():\n            callback_id = self._callback[function][0]\n            self.tk.after_cancel(callback_id)\n            self._callback.pop(function)\n        else:\n            utils.error_format(\"Could not cancel function - it doesnt exist, it may have already run\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfire by tk. after gets the callback and either executes the function and cancels or repeats", "response": "def _call_wrapper(self, time, function, *args):\n        \"\"\"Fired by tk.after, gets the callback and either executes the function and cancels or repeats\"\"\"\n        # execute the function\n        function(*args)\n        if function in self._callback.keys():\n            repeat = self._callback[function][1]\n            if repeat:\n                # setup the call back again and update the id\n                callback_id = self.tk.after(time, self._call_wrapper, time, function, *args)\n                self._callback[function][0] = callback_id\n            else:\n                # remove it from the call back dictionary\n                self._callback.pop(function)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef convert_color(color):\n    if color is not None:\n\n        # is the color a string\n        if isinstance(color, str):\n            # strip the color of white space\n            color = color.strip()\n\n            # if it starts with a # check it is a valid color\n            if color[0] == \"#\":\n\n                # check its format\n                if len(color) != 7:\n                    raise ValueError(\"{} is not a valid # color, it must be in the format #ffffff.\".format(color))\n                else:\n                    # split the color into its hex values\n                    hex_colors = (color[1:3], color[3:5], color[5:7])\n\n                    # check hex values are between 00 and ff\n                    for hex_color in hex_colors:\n                        try:\n                            int_color = int(hex_color, 16)\n                        except:\n                            raise ValueError(\"{} is not a valid value, it must be hex 00 - ff\".format(hex_color))\n\n                        if not (0 <= int_color <= 255):\n                            raise ValueError(\"{} is not a valid color value, it must be 00 - ff\".format(hex_color))\n\n        # if the color is not a string, try and convert it\n        else:\n            # get the number of colors and check it is iterable\n            try:\n                no_of_colors = len(color)\n            except:\n                raise ValueError(\"A color must be a list or tuple of 3 values (red, green, blue)\")\n\n            if no_of_colors != 3:\n                raise ValueError(\"A color must contain 3 values (red, green, blue)\")\n\n            # check the color values are between 0 and 255\n            for c in color:\n                if not (0 <= c <= 255):\n                    raise ValueError(\"{} is not a valid color value, it must be 0 - 255\")\n\n            # convert to #ffffff format\n            color = \"#{:02x}{:02x}{:02x}\".format(color[0], color[1], color[2])\n\n    return color", "response": "Converts a color from color 255 or \"#ffffff into a color tk \n should understand."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset a callback for a reference", "response": "def set_callback(self, ref, callback):\n        \"\"\"\n        Sets a callback for a ref (reference), setting to None will remove it\n        \"\"\"\n        # if the callback already exists, remove it\n        self.remove_callback(ref)\n\n        # add it to the callbacks\n        if callback is not None:\n            self._callbacks[ref] = callback"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rebind(self, tks):\n        self._tks = tks\n        for tk in self._tks:\n            tk.unbind_all(self._tk_event)\n            func_id = tk.bind(self._tk_event, self._event_callback)\n            self._func_ids.append(func_id)", "response": "Rebinds the tk event to the callback function."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the event callback for a reference", "response": "def get_event(self, ref):\n        \"\"\"\n        Returns the event callback for a ref (reference)\n        \"\"\"\n        # is this reference one which has been setup?\n        if ref in self._refs:\n            return self._refs[ref].get_callback(ref)\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_event(self, ref, tk_event, callback):\n        # has an EventCallback been created for this tk event\n        if tk_event not in self._event_callbacks:\n            self._event_callbacks[tk_event] = EventCallback(self._widget, self._tks, tk_event)\n\n        # assign this ref to this event callback\n        self._refs[ref] = self._event_callbacks[tk_event]\n\n        # set up the callback\n        self._refs[ref].set_callback(ref, callback)", "response": "Sets a callback for this widget against a ref for the tk_event"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_event(self, ref):\n        # is this reference one which has been setup?\n        if ref in self._refs:\n            self._refs[ref].remove_callback(ref)", "response": "Removes an event for a ref."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrebind all the tk events in the current object to the given tk events.", "response": "def rebind_events(self, *tks):\n        \"\"\"\n        Rebinds all the tk events, only used if a tk widget has been destroyed\n        and recreated.\n        \"\"\"\n        for ref in self._refs:\n            self._refs[ref].rebind(tks)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the border thickness and color.", "response": "def set_border(self, thickness, color=\"black\"):\n        \"\"\"\n        Sets the border thickness and color.\n\n        :param int thickness:\n            The thickenss of the border.\n\n        :param str color:\n            The color of the border.\n        \"\"\"\n        self._set_tk_config(\"highlightthickness\", thickness)\n        self._set_tk_config(\"highlightbackground\", utils.convert_color(color))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef resize(self, width, height):\n        self._set_propagation(width, height)\n        \n        super(Box, self).resize(width, height)", "response": "Resizes the widget.\n\n        :param int width:\n            The width of the widget.\n\n        :param int height:\n            The height of the widget."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndestroy and close the App.", "response": "def destroy(self):\n        \"\"\"\n        Destroy and close the App.\n\n        :return:\n            None.\n\n         :note:\n            Once destroyed an App can no longer be used.\n        \"\"\"\n        # if this is the main_app - set the _main_app class variable to `None`.\n        if self == App._main_app:\n            App._main_app = None\n        self.tk.destroy()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef resize(self, width, height):\n        # set the internal listbox width to be 0 as otherwise it maintains a default\n        # size and you cant make the control smaller than that.\n        self._listbox._set_tk_config(\"width\", None if width is None else 0)\n        self._set_propagation(width, height)\n        super(ListBox, self).resize(width, height)", "response": "Resizes the widget.\n\n        :param int width:\n            The width of the widget.\n\n        :param int height:\n            The height of the widget."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndrawing a line between two points.", "response": "def line(self, x1, y1, x2, y2, color=\"black\", width=1):\n        \"\"\"\n        Draws a line between 2 points\n\n        :param int x1:\n            The x position of the starting point.\n\n        :param int y1:\n            The y position of the starting point.\n\n        :param int x2:\n            The x position of the end point.\n\n        :param int y2:\n            The y position of the end point.\n\n        :param str color:\n            The color of the line. Defaults to `\"black\"`.\n\n        :param int width:\n            The width of the line. Defaults to `1`.\n\n        :return:\n            The id of the line.\n        \"\"\"\n        return self.tk.create_line(\n            x1, y1, x2, y2, \n            width = width,\n            fill = \"\" if color is None else utils.convert_color(color)\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndraws an oval between two points.", "response": "def oval(self, x1, y1, x2, y2, color=\"black\", outline=False, outline_color=\"black\"):\n        \"\"\"\n        Draws an oval between 2 points\n\n        :param int x1:\n            The x position of the starting point.\n\n        :param int y1:\n            The y position of the starting point.\n\n        :param int x2:\n            The x position of the end point.\n\n        :param int y2:\n            The y position of the end point.\n\n        :param str color:\n            The color of the shape. Defaults to `\"black\"`.\n\n        :param int outline:\n            `0` or `False` is no outline. `True` or value > 1 sets an outline. Defaults to `False`.\n\n        :param str outline_color:\n            The color of the outline. Defaults to `\"black\"`.\n\n        :return:\n            The id of the shape.\n        \"\"\"\n        return self.tk.create_oval(\n            x1, y1, x2, y2, \n            outline = utils.convert_color(outline_color) if outline else \"\",\n            width = int(outline),\n            fill = \"\" if color is None else utils.convert_color(color)\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndraw a rectangle between two points.", "response": "def rectangle(self, x1, y1, x2, y2, color=\"black\", outline=False, outline_color=\"black\"):\n        \"\"\"\n        Draws a rectangle between 2 points\n\n        :param int x1:\n            The x position of the starting point.\n\n        :param int y1:\n            The y position of the starting point.\n\n        :param int x2:\n            The x position of the end point.\n\n        :param int y2:\n            The y position of the end point.\n\n        :param str color:\n            The color of the shape. Defaults to `\"black\"`.\n\n        :param int outline:\n            `0` or `False` is no outline. `True` or value > 1 sets an outline. Defaults to `False`.\n\n        :param str outline_color:\n            The color of the outline. Defaults to `\"black\"`.\n\n        :return:\n            The id of the shape.\n        \"\"\"\n        return self.tk.create_rectangle(\n            x1, y1, x2, y2, \n            outline = utils.convert_color(outline_color) if outline else \"\",\n            width = int(outline),\n            fill = \"\" if color is None else utils.convert_color(color)\n            )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndraw a polygon from a list of coordinates.", "response": "def polygon(self, *coords, color=\"black\", outline=False, outline_color=\"black\"):\n        \"\"\"\n        Draws a polygon from an list of co-ordinates\n\n        :param int *coords:\n            Pairs of x and y positions which make up the polygon.\n\n        :param str color:\n            The color of the shape. Defaults to `\"black\"`.\n\n        :param int outline:\n            `0` or `False` is no outline. `True` or value > 1 sets an outline. Defaults to `False`.\n\n        :param str outline_color:\n            The color of the outline. Defaults to `\"black\"`.\n\n        :return:\n            The id of the shape.\n        \"\"\"\n        return self.tk.create_polygon(\n            *coords, \n            outline = utils.convert_color(outline_color) if outline else \"\",\n            width = int(outline),\n            fill = \"\" if color is None else utils.convert_color(color)\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndraw a triangle between 3 points.", "response": "def triangle(self, x1, y1, x2, y2, x3, y3, color=\"black\", outline=False, outline_color=\"black\"):\n        \"\"\"\n        Draws a triangle between 3 points\n\n        :param int x1:\n            The x position of the starting point.\n\n        :param int y1:\n            The y position of the starting point.\n\n        :param int x2:\n            The x position of the middle point.\n\n        :param int y2:\n            The y position of the middle point.\n\n        :param int x3:\n            The x position of the end point.\n\n        :param int y3:\n            The y position of the end point.\n\n        :param str color:\n            The color of the shape. Defaults to `\"black\"`.\n\n        :param int outline:\n            `0` or `False` is no outline. `True` or value > 1 sets an outline. Defaults to `False`.\n\n        :param str outline_color:\n            The color of the outline. Defaults to `\"black\"`.\n\n        :return:\n            The id of the shape.\n        \"\"\"\n        return self.polygon(\n            x1, y1, x2, y2, x3, y3, \n            color=color, \n            outline=outline, \n            outline_color=outline_color)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef image(self, x, y, image, width=None, height=None):\n        # load the image and add to the dict (otherwise tk destroys the reference to them!)\n        _image = utils.GUIZeroImage(image, width, height)\n        id = self.tk.create_image(x, y, image=_image.tk_image, anchor=\"nw\")\n        self._images[id] = _image\n        return id", "response": "Insert an image into the drawing position by its top - left corner."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninserts text into the drawing position by its top - left corner.", "response": "def text(self, x, y, text, color=\"black\", font=None, size=None, max_width=None):\n        \"\"\"\n        Inserts text into the drawing, position by its top-left corner.\n        \n        :param int x:\n            The x position of the text.\n\n        :param int y:\n            The x position of the text.\n\n        :param str color:\n            The color of the text. Defaults to `\"black\"`.\n\n        :param str font:\n            The font to use. Defaults to `None` and will use the system\n            default font.\n\n        :param int size:\n            The size of the text. Defaults to `None` and will use the system\n            default font size.\n\n        :param int max_width:\n            Maximum line length. Lines longer than this value are wrapped. \n            Default is `None` (no wrapping).\n        \"\"\"\n        # create the font\n        if size is None:\n            f = Font(self.tk, family=font)\n        else:\n            f = Font(self.tk, family=font, size=size)\n        \n        return self.tk.create_text(\n            x, y, \n            text=text,\n            fill = \"\" if color is None else utils.convert_color(color),\n            font=f,\n            width=max_width,\n            anchor=\"nw\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndelete an object from the drawing.", "response": "def delete(self, id):\n        \"\"\"\n        Deletes an \"object\" (line, triangle, image, etc) from the drawing.\n\n        :param int id:\n            The id of the object.\n        \"\"\"\n        if id in self._images.keys():\n            del self._images[id]\n        self.tk.delete(id)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_tk_config(self, key, default=False):\n        if default:\n            return self._tk_defaults[key]\n        else:\n            return self.tk[key]", "response": "Get the config value for a specific key from the tk object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_tk_config(self, keys, value):\n\n        # if a single key is passed, convert to list\n        if isinstance(keys, str):\n            keys = [keys]\n\n        # loop through all the keys\n        for key in keys:\n            if key in self.tk.keys():\n                if value is None:\n                    # reset to default\n                    self.tk[key] = self._tk_defaults[key]\n                else:\n                    self.tk[key] = value", "response": "Sets the config value for the tk object"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef destroy(self):\n        # if this widget has a master remove the it from the master\n        if self.master is not None:\n            self.master._remove_child(self)\n\n        self.tk.destroy()", "response": "Destroy the tk widget."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a tk widget into a guizero container.", "response": "def add_tk_widget(self, tk_widget, grid=None, align=None, visible=True, enabled=None, width=None, height=None):\n        \"\"\"\n        Adds a tk widget into a guizero container.\n\n        :param tkinter.Widget tk_widget:\n            The Container (App, Box, etc) the tk widget will belong too.\n\n        :param List grid:\n            Grid co-ordinates for the widget, required if the master layout\n            is 'grid', defaults to `None`.\n\n        :param string align:\n            How to align the widget within the grid, defaults to None.\n\n        :param bool visible:\n            If the widget should be visible, defaults to `True`.\n\n        :param bool enabled:\n            If the widget should be enabled, defaults to `None`. If `None`\n            the value is inherited from the master.\n\n        :param int width:\n            The starting width of the widget. Defaults to `None` and will auto\n            size.\n\n        :param int height:\n            The starting height of the widget. Defaults to `None` and will auto\n            size.\n        \"\"\"\n        return Widget(self, tk_widget, \"tk widget\", grid, align, visible, enabled, width, height)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef display_widgets(self):\n        # All widgets are removed and then recreated to ensure the order they\n        # were created is the order they are displayed.\n\n        for child in self.children:\n\n            if child.displayable:\n\n                # forget the widget\n                if self.layout != \"grid\":\n                    child.tk.pack_forget()\n                else:\n                    child.tk.grid_forget()\n\n                # display the widget\n                if child.visible:\n                    if self.layout != \"grid\":\n                        self._pack_widget(child)\n                    else:\n                        self._grid_widget(child)", "response": "Displays all the widgets associated with this Container."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef disable(self):\n        self._enabled = False\n        for child in self.children:\n            if isinstance(child, (Container, Widget)):\n                child.disable()", "response": "Disable all the widgets in this container."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nenables all the widgets in this container.", "response": "def enable(self):\n        \"\"\"\n        Enable all the widgets in this container\n        \"\"\"\n        self._enabled = True\n        for child in self.children:\n            if isinstance(child, (Container, Widget)):\n                child.enable()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmakes this window full screen and bind the Escape key or given key.", "response": "def set_full_screen(self, keybind=\"<Escape>\"):\n        \"\"\"Make this window full screen and bind the Escape key (or given key) to exit full screen mode\"\"\"\n        self.tk.attributes(\"-fullscreen\", True)\n        self._full_screen = True\n        self.events.set_event(\"<FullScreen.Escape>\", keybind, self.exit_full_screen)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef exit_full_screen(self):\n        self.tk.attributes(\"-fullscreen\", False)\n        self._full_screen = False\n        self.events.remove_event(\"<FullScreen.Escape>\")", "response": "Exit full screen mode"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_propagation(self, width, height):\n        if width is None:\n            width = 0\n\n        if height is None:\n            height = 0\n\n        # set the propagate value\n        propagate_function = self.tk.pack_propagate\n        if self.layout == \"grid\":\n            propagate_function = self.tk.grid_propagate\n\n        propagate_value = True\n\n        # if height or width > 0 need to stop propagation\n        if isinstance(width, int):\n            if width > 0:\n                propagate_value = False\n        if isinstance(height, int):\n            if height > 0:\n                propagate_value = False\n\n        # if you specify a height or width you must specify they other\n        # (unless its a fill)\n        if isinstance(width, int) and isinstance(height, int):\n            if (width == 0 and height > 0) or (height == 0 and width > 0):\n                 utils.error_format(\"You must specify a width and a height for {}\".format(self.description))\n\n        propagate_function(propagate_value)", "response": "Set the propagation value of the tk widget dependent on the width and height of the tk widget."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload a value from memory into a VEX temporary register.", "response": "def load(self, addr, ty):\n        \"\"\"\n        Load a value from memory into a VEX temporary register.\n\n        :param addr: The VexValue containing the addr to load from.\n        :param ty: The Type of the resulting data\n        :return: a VexValue\n        \"\"\"\n        rdt = self.irsb_c.load(addr.rdt, ty)\n        return VexValue(self.irsb_c, rdt)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a constant VexValue from the given value and type.", "response": "def constant(self, val, ty):\n        \"\"\"\n        Creates a constant as a VexValue\n\n        :param val: The value, as an integer\n        :param ty: The type of the resulting VexValue\n        :return: a VexValue\n        \"\"\"\n        if isinstance(val, VexValue) and not isinstance(val, IRExpr):\n            raise Exception('Constant cannot be made from VexValue or IRExpr')\n        rdt = self.irsb_c.mkconst(val, ty)\n        return VexValue(self.irsb_c, rdt)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, reg, ty):\n        offset = self.lookup_register(self.irsb_c.irsb.arch, reg)\n        if offset == self.irsb_c.irsb.arch.ip_offset:\n            return self.constant(self.addr, ty)\n        rdt = self.irsb_c.rdreg(offset, ty)\n        return VexValue(self.irsb_c, rdt)", "response": "Load a value from a machine register into a VEX temporary register."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef put(self, val, reg):\n        offset = self.lookup_register(self.irsb_c.irsb.arch, reg)\n        self.irsb_c.put(val.rdt, offset)", "response": "Stores a VEX value into a machine register."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlike put except it checks a condition and put in the destination register.", "response": "def put_conditional(self, cond, valiftrue, valiffalse, reg):\n        \"\"\"\n        Like put, except it checks a condition\n        to decide what to put in the destination register.\n\n        :param cond: The VexValue representing the logical expression for the condition\n            (if your expression only has constants, don't use this method!)\n        :param valiftrue: the VexValue to put in reg if cond evals as true\n        :param validfalse: the VexValue to put in reg if cond evals as false\n        :param reg: The integer register number to store into, or register name\t\n        :return: None\n        \"\"\"\n\n        val = self.irsb_c.ite(cond.rdt , valiftrue.rdt, valiffalse.rdt)\n        offset = self.lookup_register(self.irsb_c.irsb.arch, reg)\n        self.irsb_c.put(val, offset)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef store(self, val, addr):\n        self.irsb_c.store(addr.rdt, val.rdt)", "response": "Stores a VexValue in memory at the specified loaction."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef jump(self, condition, to_addr, jumpkind=JumpKind.Boring, ip_offset=None):\n        to_addr_ty = None\n        if isinstance(to_addr, VexValue):\n            # Unpack a VV\n            to_addr_rdt = to_addr.rdt\n            to_addr_ty = to_addr.ty\n        elif isinstance(to_addr, int):\n            # Direct jump to an int, make an RdT and Ty\n            to_addr_ty = vex_int_class(self.irsb_c.irsb.arch.bits).type\n            to_addr = self.constant(to_addr, to_addr_ty) # TODO archinfo may be changing\n            to_addr_rdt = to_addr.rdt\n        elif isinstance(to_addr, RdTmp):\n            # An RdT; just get the Ty of the arch's pointer type\n            to_addr_ty = vex_int_class(self.irsb_c.irsb.arch.bits).type\n            to_addr_rdt = to_addr\n        else:\n            raise ValueError(\"Jump destination has unknown type: \" + repr(type(to_addr)))\n        if not condition:\n            # This is the default exit.\n            self.irsb_c.irsb.jumpkind = jumpkind\n            self.irsb_c.irsb.next = to_addr_rdt\n        else:\n            # add another exit\n            # EDG says: We should make sure folks set ArchXYZ.ip_offset like they're supposed to\n            if ip_offset is None:\n                ip_offset = self.arch.ip_offset\n            assert ip_offset is not None\n\n            negated_condition_rdt = self.ite(condition, self.constant(0, condition.ty), self.constant(1, condition.ty))\n            direct_exit_target = self.constant(self.addr + (self.bitwidth // 8), to_addr_ty)\n            self.irsb_c.add_exit(negated_condition_rdt, direct_exit_target.rdt, jumpkind, ip_offset)\n            self.irsb_c.irsb.jumpkind = jumpkind\n            self.irsb_c.irsb.next = to_addr_rdt", "response": "Jump to a specified destination under the specified condition."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a CCall operation.", "response": "def ccall(self, ret_type, func_obj, args):\n        \"\"\"\n        Creates a CCall operation.\n        A CCall is a procedure that calculates a value at *runtime*, not at lift-time.\n        You can use these for flags, unresolvable jump targets, etc.\n        We caution you to avoid using them when at all possible though.\n\n        For an example of how to write and use a CCall, see gymrat/bf/lift_bf.py\n\n        :param ret_type: The return type of the CCall\n        :param func_obj: The function object to eventually call.\n        :param args: List of arguments to the function\n        :return: A VexValue of the result.\n        \"\"\"\n        # HACK: FIXME: If you're reading this, I'm sorry. It's truly a crime against Python...\n\n        from angr.engines.vex import ccall\n\n        # Check the args to make sure they're the right type\n        list_args = list(args)\n        new_args = []\n        for arg in list_args:\n            if isinstance(arg, VexValue):\n                arg = arg.rdt\n            new_args.append(arg)\n        args = tuple(new_args)\n\n\n        # Support calling ccalls via string name\n        if isinstance(func_obj, str):\n            func_obj = getattr(ccall, func_obj)\n        else:\n            # ew, monkey-patch in the user-provided CCall\n            if not hasattr(ccall, func_obj.__name__):\n                setattr(ccall, func_obj.__name__, func_obj)\n        cc = self.irsb_c.op_ccall(ret_type, func_obj.__name__, args)\n        return VexValue(self.irsb_c, cc)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef lift(data, addr, arch, max_bytes=None, max_inst=None, bytes_offset=0, opt_level=1, traceflags=0,\n         strict_block_end=True, inner=False, skip_stmts=False, collect_data_refs=False):\n    \"\"\"\n    Recursively lifts blocks using the registered lifters and postprocessors. Tries each lifter in the order in\n    which they are registered on the data to lift.\n\n    If a lifter raises a LiftingException on the data, it is skipped.\n    If it succeeds and returns a block with a jumpkind of Ijk_NoDecode, all of the lifters are tried on the rest\n    of the data and if they work, their output is appended to the first block.\n\n    :param arch:            The arch to lift the data as.\n    :type arch:             :class:`archinfo.Arch`\n    :param addr:            The starting address of the block. Effects the IMarks.\n    :param data:            The bytes to lift as either a python string of bytes or a cffi buffer object.\n    :param max_bytes:       The maximum number of bytes to lift. If set to None, no byte limit is used.\n    :param max_inst:        The maximum number of instructions to lift. If set to None, no instruction limit is used.\n    :param bytes_offset:    The offset into `data` to start lifting at.\n    :param opt_level:       The level of optimization to apply to the IR, -1 through 2. -1 is the strictest\n                            unoptimized level, 0 is unoptimized but will perform some lookahead/lookbehind\n                            optimizations, 1 performs constant propogation, and 2 performs loop unrolling,\n                            which honestly doesn't make much sense in the context of pyvex. The default is 1.\n    :param traceflags:      The libVEX traceflags, controlling VEX debug prints.\n\n    .. note:: Explicitly specifying the number of instructions to lift (`max_inst`) may not always work\n              exactly as expected. For example, on MIPS, it is meaningless to lift a branch or jump\n              instruction without its delay slot. VEX attempts to Do The Right Thing by possibly decoding\n              fewer instructions than requested. Specifically, this means that lifting a branch or jump\n              on MIPS as a single instruction (`max_inst=1`) will result in an empty IRSB, and subsequent\n              attempts to run this block will raise `SimIRSBError('Empty IRSB passed to SimIRSB.')`.\n\n    .. note:: If no instruction and byte limit is used, pyvex will continue lifting the block until the block\n              ends properly or until it runs out of data to lift.\n    \"\"\"\n    if max_bytes is not None and max_bytes <= 0:\n        raise PyVEXError(\"Cannot lift block with no data (max_bytes <= 0)\")\n\n    if not data:\n        raise PyVEXError(\"Cannot lift block with no data (data is empty)\")\n\n    if isinstance(data, str):\n        raise TypeError(\"Cannot pass unicode string as data to lifter\")\n\n    if isinstance(data, bytes):\n        py_data = data\n        c_data = None\n        allow_arch_optimizations = False\n    else:\n        if max_bytes is None:\n            raise PyVEXError(\"Cannot lift block with ffi pointer and no size (max_bytes is None)\")\n        c_data = data\n        py_data = None\n        allow_arch_optimizations = True\n\n    # In order to attempt to preserve the property that\n    # VEX lifts the same bytes to the same IR at all times when optimizations are disabled\n    # we hack off all of VEX's non-IROpt optimizations when opt_level == -1.\n    # This is intended to enable comparisons of the lifted IR between code that happens to be\n    # found in different contexts.\n    if opt_level < 0:\n        allow_arch_optimizations = False\n        opt_level = 0\n\n    for lifter in lifters[arch.name]:\n        try:\n            u_data = data\n            if lifter.REQUIRE_DATA_C:\n                if c_data is None:\n                    u_data = ffi.new('unsigned char [%d]' % (len(py_data) + 8), py_data + b'\\0' * 8)\n                    max_bytes = min(len(py_data), max_bytes) if max_bytes is not None else len(py_data)\n                else:\n                    u_data = c_data\n            elif lifter.REQUIRE_DATA_PY:\n                if py_data is None:\n                    if max_bytes is None:\n                        l.debug('Cannot create py_data from c_data when no max length is given')\n                        continue\n                    u_data = ffi.buffer(c_data, max_bytes)[:]\n                else:\n                    u_data = py_data\n\n            try:\n                final_irsb = lifter(arch, addr)._lift(u_data, bytes_offset, max_bytes, max_inst, opt_level, traceflags,\n                                                      allow_arch_optimizations, strict_block_end, skip_stmts, collect_data_refs,\n                                                      )\n            except SkipStatementsError:\n                assert skip_stmts is True\n                final_irsb = lifter(arch, addr)._lift(u_data, bytes_offset, max_bytes, max_inst, opt_level, traceflags,\n                                                      allow_arch_optimizations, strict_block_end, skip_stmts=False,\n                                                      collect_data_refs=collect_data_refs,\n                                                      )\n            #l.debug('block lifted by %s' % str(lifter))\n            #l.debug(str(final_irsb))\n            break\n        except LiftingException as ex:\n            l.debug('Lifting Exception: %s', str(ex))\n            continue\n    else:\n        final_irsb = IRSB.empty_block(arch,\n                                      addr,\n                                      size=0,\n                                      nxt=Const(const.vex_int_class(arch.bits)(addr)),\n                                      jumpkind='Ijk_NoDecode',\n                                      )\n        final_irsb.invalidate_direct_next()\n        return final_irsb\n\n    if final_irsb.size > 0 and final_irsb.jumpkind == 'Ijk_NoDecode':\n        # We have decoded a few bytes before we hit an undecodeable instruction.\n\n        # Determine if this is an intentional NoDecode, like the ud2 instruction on AMD64\n        nodecode_addr_expr = final_irsb.next\n        if type(nodecode_addr_expr) is Const:\n            nodecode_addr = nodecode_addr_expr.con.value\n            next_irsb_start_addr = addr + final_irsb.size\n            if nodecode_addr != next_irsb_start_addr:\n                # The last instruction of the IRSB has a non-zero length. This is an intentional NoDecode.\n                # The very last instruction has been decoded\n                final_irsb.jumpkind = 'Ijk_NoDecode'\n                final_irsb.next = final_irsb.next\n                final_irsb.invalidate_direct_next()\n                return final_irsb\n\n        # Decode more bytes\n        if skip_stmts:\n            # When gymrat will be invoked, we will merge future basic blocks to the current basic block. In this case,\n            # statements are usually required.\n            # TODO: In the future, we may further optimize it to handle cases where getting statements in gymrat is not\n            # TODO: required.\n            return lift(data, addr, arch,\n                        max_bytes=max_bytes,\n                        max_inst=max_inst,\n                        bytes_offset=bytes_offset,\n                        opt_level=opt_level,\n                        traceflags=traceflags,\n                        strict_block_end=strict_block_end,\n                        skip_stmts=False,\n                        collect_data_refs=collect_data_refs,\n                        )\n\n        next_addr = addr + final_irsb.size\n        if max_bytes is not None:\n            max_bytes -= final_irsb.size\n        if isinstance(data, (str, bytes)):\n            data_left = data[final_irsb.size:]\n        else:\n            data_left = data + final_irsb.size\n        if max_inst is not None:\n            max_inst -= final_irsb.instructions\n        if (max_bytes is None or max_bytes > 0) and (max_inst is None or max_inst > 0) and data_left:\n            more_irsb = lift(data_left, next_addr, arch,\n                             max_bytes=max_bytes,\n                             max_inst=max_inst,\n                             bytes_offset=bytes_offset,\n                             opt_level=opt_level,\n                             traceflags=traceflags,\n                             strict_block_end=strict_block_end,\n                             inner=True,\n                             skip_stmts=False,\n                             collect_data_refs=collect_data_refs,\n                             )\n            if more_irsb.size:\n                # Successfully decoded more bytes\n                final_irsb.extend(more_irsb)\n        elif max_bytes == 0:\n            # We have no more bytes left. Mark the jumpkind of the IRSB as Ijk_Boring\n            if final_irsb.size > 0 and final_irsb.jumpkind == 'Ijk_NoDecode':\n                final_irsb.jumpkind = 'Ijk_Boring'\n                final_irsb.next = Const(vex_int_class(arch.bits)(final_irsb.addr + final_irsb.size))\n\n    if not inner:\n        for postprocessor in postprocessors[arch.name]:\n            try:\n                postprocessor(final_irsb).postprocess()\n            except NeedStatementsNotification:\n                # The post-processor cannot work without statements. Re-lift the current block with skip_stmts=False\n                if not skip_stmts:\n                    # sanity check\n                    # Why does the post-processor raise NeedStatementsNotification when skip_stmts is False?\n                    raise TypeError(\"Bad post-processor %s: \"\n                                    \"NeedStatementsNotification is raised when statements are available.\" %\n                                    postprocessor.__class__)\n\n                # Re-lift the current IRSB\n                return lift(data, addr, arch,\n                            max_bytes=max_bytes,\n                            max_inst=max_inst,\n                            bytes_offset=bytes_offset,\n                            opt_level=opt_level,\n                            traceflags=traceflags,\n                            strict_block_end=strict_block_end,\n                            inner=inner,\n                            skip_stmts=False,\n                            collect_data_refs=collect_data_refs,\n                            )\n            except LiftingException:\n                continue\n\n    return final_irsb", "response": "Recursively lifts a block of data into a single block of Ijk_NoDecode."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nregistering a Lifter or Postprocessor to be used by pyvex.", "response": "def register(lifter, arch_name):\n    \"\"\"\n    Registers a Lifter or Postprocessor to be used by pyvex. Lifters are are given priority based on the order\n    in which they are registered. Postprocessors will be run in registration order.\n\n    :param lifter:       The Lifter or Postprocessor to register\n    :vartype lifter:     :class:`Lifter` or :class:`Postprocessor`\n    \"\"\"\n    if issubclass(lifter, Lifter):\n        l.debug(\"Registering lifter %s for architecture %s.\", lifter.__name__, arch_name)\n        lifters[arch_name].append(lifter)\n    if issubclass(lifter, Postprocessor):\n        l.debug(\"Registering postprocessor %s for architecture %s.\", lifter.__name__, arch_name)\n        postprocessors[arch_name].append(lifter)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef child_expressions(self):\n        expressions = [ ]\n        for k in self.__slots__:\n            v = getattr(self, k)\n            if isinstance(v, IRExpr):\n                expressions.append(v)\n                expressions.extend(v.child_expressions)\n        return expressions", "response": "A list of all of the expressions that this expression ends up evaluating."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef constants(self):\n        constants = [ ]\n        for k in self.__slots__:\n            v = getattr(self, k)\n            if isinstance(v, IRExpr):\n                constants.extend(v.constants)\n            elif isinstance(v, IRConst):\n                constants.append(v)\n        return constants", "response": "A list of all of the constants that this expression ends up using."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef replace_expression(self, expr, replacement):\n\n        for k in self.__slots__:\n            v = getattr(self, k)\n            if v is expr:\n                setattr(self, k, replacement)\n            elif type(v) is list:\n                # Replace the instance in the list\n                for i, expr_ in enumerate(v):\n                    if expr_ is expr:\n                        v[i] = replacement\n            elif type(v) is tuple:\n                # Rebuild the tuple\n                _lst = [ ]\n                replaced = False\n                for i, expr_ in enumerate(v):\n                    if expr_ is expr:\n                        _lst.append(replacement)\n                        replaced = True\n                    else:\n                        _lst.append(expr_)\n                if replaced:\n                    setattr(self, k, tuple(_lst))\n            elif isinstance(v, IRExpr):\n                v.replace_expression(expr, replacement)", "response": "Replace the expression expr with replacement."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef extend(self, extendwith):\n        if self.stmts_used == 0:\n            self._from_py(extendwith)\n            return\n\n        conversion_dict = { }\n        invalid_vals = (0xffffffff, -1)\n\n        new_size = self.size + extendwith.size\n        new_instructions = self.instructions + extendwith.instructions\n        new_direct_next = extendwith.direct_next\n\n        def convert_tmp(tmp):\n            \"\"\"\n            Converts a tmp from the appended-block into one in the appended-to-block. Creates a new tmp if it does not\n            already exist. Prevents collisions in tmp numbers between the two blocks.\n            :param tmp:       The tmp number to convert\n            \"\"\"\n            if tmp not in conversion_dict:\n                tmp_type = extendwith.tyenv.lookup(tmp)\n                conversion_dict[tmp] = self.tyenv.add(tmp_type)\n            return conversion_dict[tmp]\n\n        def convert_expr(expr_):\n            \"\"\"\n            Converts a VEX expression to use tmps in the appended-block instead of the appended-to-block. Used to prevent\n            collisions in tmp numbers between the two blocks.\n            :param tmp:       The VEX expression to convert\n            :vartype expr:    :class:`IRExpr`\n            \"\"\"\n            if type(expr_) is RdTmp:\n                return RdTmp.get_instance(convert_tmp(expr_.tmp))\n            return expr_\n\n        for stmt_ in extendwith.statements:\n            stmttype = type(stmt_)\n            if stmttype is WrTmp:\n                stmt_.tmp = convert_tmp(stmt_.tmp)\n            elif stmttype is LoadG:\n                stmt_.dst = convert_tmp(stmt_.dst)\n            elif stmttype is LLSC:\n                stmt_.result = convert_tmp(stmt_.result)\n            elif stmttype is Dirty:\n                if stmt_.tmp not in invalid_vals:\n                    stmt_.tmp = convert_tmp(stmt_.tmp)\n                for e in stmt_.args:\n                    convert_expr(e)\n            elif stmttype is CAS:\n                if stmt_.oldLo not in invalid_vals: stmt_.oldLo = convert_tmp(stmt_.oldLo)\n                if stmt_.oldHi not in invalid_vals: stmt_.oldHi = convert_tmp(stmt_.oldHi)\n            # Convert all expressions\n            to_replace = { }\n            for expr_ in stmt_.expressions:\n                replacement = convert_expr(expr_)\n                if replacement is not expr_:\n                    to_replace[expr_] = replacement\n            for expr_, replacement in to_replace.items():\n                stmt_.replace_expression(expr_, replacement)\n            # Add the converted statement to self.statements\n            self.statements.append(stmt_)\n        extendwith.next = convert_expr(extendwith.next)\n        self.next = extendwith.next\n        self.jumpkind = extendwith.jumpkind\n        self._size = new_size\n        self._instructions = new_instructions\n        self._direct_next = new_direct_next", "response": "Extends the current irsb with the given IRSB."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef expressions(self):\n        for s in self.statements:\n            for expr_ in s.expressions:\n                yield expr_\n        yield self.next", "response": "Return an iterator of all expressions contained in the IRSB."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the number of instructions in this block.", "response": "def instructions(self):\n        \"\"\"\n        The number of instructions in this block\n        \"\"\"\n        if self._instructions is None:\n            if self.statements is None:\n                self._instructions = 0\n            else:\n                self._instructions = len([s for s in self.statements if type(s) is stmt.IMark])\n        return self._instructions"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef instruction_addresses(self):\n        if self._instruction_addresses is None:\n            if self.statements is None:\n                self._instruction_addresses = [ ]\n            else:\n                self._instruction_addresses = [ (s.addr + s.delta) for s in self.statements if type(s) is stmt.IMark ]\n        return self._instruction_addresses", "response": "Returns a list of addresses of instructions in this block."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef size(self):\n        if self._size is None:\n            self._size = sum(s.len for s in self.statements if type(s) is stmt.IMark)\n        return self._size", "response": "Returns the size of this block in bytes."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the list of constants in the IRSB as a list of pyvex. const. IRConst objects.", "response": "def constants(self):\n        \"\"\"\n        The constants (excluding updates of the program counter) in the IRSB as :class:`pyvex.const.IRConst`.\n        \"\"\"\n        return sum(\n            (s.constants for s in self.statements if not (type(s) is stmt.Put and s.offset == self.offsIP)), [])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef constant_jump_targets_and_jumpkinds(self):\n        exits = dict()\n\n        if self.exit_statements:\n            for _, _, stmt_ in self.exit_statements:\n                exits[stmt_.dst.value] = stmt_.jumpkind\n\n        default_target = self.default_exit_target\n        if default_target is not None:\n            exits[default_target] = self.jumpkind\n\n        return exits", "response": "A dict of the static jump targets of the basic block to their jumpkind."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _pp_str(self):\n        sa = []\n        sa.append(\"IRSB {\")\n        if self.statements is not None:\n            sa.append(\"   %s\" % self.tyenv)\n        sa.append(\"\")\n        if self.statements is not None:\n            for i, s in enumerate(self.statements):\n                if isinstance(s, stmt.Put):\n                    stmt_str = s.__str__(reg_name=self.arch.translate_register_name(s.offset, s.data.result_size(self.tyenv) // 8))\n                elif isinstance(s, stmt.WrTmp) and isinstance(s.data, expr.Get):\n                    stmt_str = s.__str__(reg_name=self.arch.translate_register_name(s.data.offset, s.data.result_size(self.tyenv) // 8))\n                elif isinstance(s, stmt.Exit):\n                    stmt_str = s.__str__(reg_name=self.arch.translate_register_name(s.offsIP, self.arch.bits // 8))\n                else:\n                    stmt_str = s.__str__()\n                sa.append(\"   %02d | %s\" % (i, stmt_str))\n        else:\n            sa.append(\"   Statements are omitted.\")\n        sa.append(\n            \"   NEXT: PUT(%s) = %s; %s\" % (self.arch.translate_register_name(self.offsIP), self.next, self.jumpkind))\n        sa.append(\"}\")\n        return '\\n'.join(sa)", "response": "Return the pretty - printed IRSB."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if the default exit of this IRSB is a direct jump or not.", "response": "def _is_defaultexit_direct_jump(self):\n        \"\"\"\n        Checks if the default of this IRSB a direct jump or not.\n        \"\"\"\n        if not (self.jumpkind == 'Ijk_InvalICache' or self.jumpkind == 'Ijk_Boring' or self.jumpkind == 'Ijk_Call'):\n            return False\n\n        target = self.default_exit_target\n        return target is not None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef lookup(self, tmp):\n        if tmp < 0 or tmp > self.types_used:\n            l.debug(\"Invalid temporary number %d\", tmp)\n            raise IndexError(tmp)\n        return self.types[tmp]", "response": "Returns the type of temporary variable tmp as an enum string"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the size of a VEX type specifier e. g. Ity_I16 -> 16", "response": "def get_type_size(ty):\n    \"\"\"\n    Returns the size, in BITS, of a VEX type specifier\n    e.g., Ity_I16 -> 16\n\n    :param ty:\n    :return:\n    \"\"\"\n    m = type_str_re.match(ty)\n    if m is None:\n        raise ValueError('Type %s does not have size' % ty)\n    return int(m.group('size'))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the width of a type specifier", "response": "def get_type_spec_size(ty):\n    \"\"\"\n    Get the width of a \"type specifier\"\n    like I16U\n    or F16\n    or just 16\n    (Yes, this really just takes the int out.  If we must special-case, do it here.\n    :param tyspec:\n    :return:\n    \"\"\"\n    m = type_tag_str_re.match(ty)\n    if m is None:\n        raise ValueError('Type specifier %s does not have size' % ty)\n    return int(m.group('size'))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrap around the libvex. _lift method that creates a new IRSB and stores it in self. data.", "response": "def _lift(self,\n              data,\n              bytes_offset=None,\n              max_bytes=None,\n              max_inst=None,\n              opt_level=1,\n              traceflags=None,\n              allow_arch_optimizations=None,\n              strict_block_end=None,\n              skip_stmts=False,\n              collect_data_refs=False):\n        \"\"\"\n        Wrapper around the `lift` method on Lifters. Should not be overridden in child classes.\n\n        :param data:                The bytes to lift as either a python string of bytes or a cffi buffer object.\n        :param bytes_offset:        The offset into `data` to start lifting at.\n        :param max_bytes:           The maximum number of bytes to lift. If set to None, no byte limit is used.\n        :param max_inst:            The maximum number of instructions to lift. If set to None, no instruction limit is used.\n        :param opt_level:           The level of optimization to apply to the IR, 0-2. Most likely will be ignored in any lifter\n                                    other then LibVEX.\n        :param traceflags:          The libVEX traceflags, controlling VEX debug prints. Most likely will be ignored in any\n                                    lifter other than LibVEX.\n        :param allow_arch_optimizations:   Should the LibVEX lifter be allowed to perform lift-time preprocessing optimizations\n                            (e.g., lookback ITSTATE optimization on THUMB)\n                            Most likely will be ignored in any lifter other than LibVEX.\n        :param strict_block_end:    Should the LibVEX arm-thumb split block at some instructions, for example CB{N}Z.\n        :param skip_stmts:          Should the lifter skip transferring IRStmts from C to Python.\n        :param collect_data_refs:   Should the LibVEX lifter collect data references in C.\n        \"\"\"\n        irsb = IRSB.empty_block(self.arch, self.addr)\n        self.data = data\n        self.bytes_offset = bytes_offset\n        self.opt_level = opt_level\n        self.traceflags = traceflags\n        self.allow_arch_optimizations = allow_arch_optimizations\n        self.strict_block_end = strict_block_end\n        self.collect_data_refs = collect_data_refs\n        self.max_inst = max_inst\n        self.max_bytes = max_bytes\n        self.skip_stmts = skip_stmts\n        self.irsb = irsb\n        self.lift()\n        return self.irsb"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a function which generates an op format for the given fmt_string", "response": "def make_format_op_generator(fmt_string):\n    \"\"\"\n    Return a function which generates an op format (just a string of the vex instruction)\n\n    Functions by formatting the fmt_string with the types of the arguments\n    \"\"\"\n    def gen(arg_types):\n        converted_arg_types = list(map(get_op_format_from_const_ty, arg_types))\n        op = fmt_string.format(arg_t=converted_arg_types)\n        return op\n    return gen"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_exit(self, guard, dst, jk, ip):\n        self.irsb.statements.append(Exit(guard, dst.con, jk, ip))", "response": "Add an exit to the middle of an IRSB."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a constant VexValue", "response": "def Constant(cls, irsb_c, val, ty):\n        \"\"\"\n        Creates a constant as a VexValue\n        :param irsb_c: The IRSBCustomizer to use\n        :param val: The value, as an integer\n        :param ty: The type of the resulting VexValue\n        :return: a VexValue\n        \"\"\"\n        assert not (isinstance(val, VexValue) or isinstance(val, IRExpr))\n        rdt = irsb_c.mkconst(val, ty)\n        return cls(irsb_c, rdt)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef replace_expression(self, expression, replacement):\n\n        for k in self.__slots__:\n            v = getattr(self, k)\n            if v is expression:\n                setattr(self, k, replacement)\n            elif isinstance(v, IRExpr):\n                v.replace_expression(expression, replacement)\n            elif type(v) is tuple:\n                # Rebuild the tuple\n                _lst = [ ]\n                replaced = False\n                for expr_ in v:\n                    if expr_ is expression:\n                        _lst.append(replacement)\n                        replaced = True\n                    else:\n                        _lst.append(expr_)\n                if replaced:\n                    setattr(self, k, tuple(_lst))", "response": "Replace child expressions in - place."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a random proxy from the available proxies.", "response": "def get_random(self):\n        \"\"\" Return a random available proxy (either good or unchecked) \"\"\"\n        available = list(self.unchecked | self.good)\n        if not available:\n            return None\n        return random.choice(available)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns complete proxy name associated with a hostport of a given proxy_address.", "response": "def get_proxy(self, proxy_address):\n        \"\"\"\n        Return complete proxy name associated with a hostport of a given\n        ``proxy_address``. If ``proxy_address`` is unkonwn or empty,\n        return None.\n        \"\"\"\n        if not proxy_address:\n            return None\n        hostport = extract_proxy_hostport(proxy_address)\n        return self.proxies_by_hostport.get(hostport, None)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmarking a proxy as dead.", "response": "def mark_dead(self, proxy, _time=None):\n        \"\"\" Mark a proxy as dead \"\"\"\n        if proxy not in self.proxies:\n            logger.warn(\"Proxy <%s> was not found in proxies list\" % proxy)\n            return\n\n        if proxy in self.good:\n            logger.debug(\"GOOD proxy became DEAD: <%s>\" % proxy)\n        else:\n            logger.debug(\"Proxy <%s> is DEAD\" % proxy)\n\n        self.unchecked.discard(proxy)\n        self.good.discard(proxy)\n        self.dead.add(proxy)\n\n        now = _time or time.time()\n        state = self.proxies[proxy]\n        state.backoff_time = self.backoff(state.failed_attempts)\n        state.next_check = now + state.backoff_time\n        state.failed_attempts += 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mark_good(self, proxy):\n        if proxy not in self.proxies:\n            logger.warn(\"Proxy <%s> was not found in proxies list\" % proxy)\n            return\n\n        if proxy not in self.good:\n            logger.debug(\"Proxy <%s> is GOOD\" % proxy)\n\n        self.unchecked.discard(proxy)\n        self.dead.discard(proxy)\n        self.good.add(proxy)\n        self.proxies[proxy].failed_attempts = 0", "response": "Mark a proxy as GOOD"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmoving dead proxies to unchecked if a backoff timeout passes.", "response": "def reanimate(self, _time=None):\n        \"\"\" Move dead proxies to unchecked if a backoff timeout passes \"\"\"\n        n_reanimated = 0\n        now = _time or time.time()\n        for proxy in list(self.dead):\n            state = self.proxies[proxy]\n            assert state.next_check is not None\n            if state.next_check <= now:\n                self.dead.remove(proxy)\n                self.unchecked.add(proxy)\n                n_reanimated += 1\n        return n_reanimated"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reset(self):\n        for proxy in list(self.dead):\n            self.dead.remove(proxy)\n            self.unchecked.add(proxy)", "response": "Mark all dead proxies as unchecked"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getQuotes(symbols):\n    '''\n    get real-time quotes (index, last trade price, last trade time, etc) for stocks, using google api: http://finance.google.com/finance/info?client=ig&q=symbols\n\n    Unlike python package 'yahoo-finance' (15 min delay), There is no delay for NYSE and NASDAQ stocks in 'googlefinance' package.\n\n    example:\n    quotes = getQuotes('AAPL')\n    return:\n    [{u'Index': u'NASDAQ', u'LastTradeWithCurrency': u'129.09', u'LastTradeDateTime': u'2015-03-02T16:04:29Z', u'LastTradePrice': u'129.09', u'Yield': u'1.46', u'LastTradeTime': u'4:04PM EST', u'LastTradeDateTimeLong': u'Mar 2, 4:04PM EST', u'Dividend': u'0.47', u'StockSymbol': u'AAPL', u'ID': u'22144'}]\n\n    quotes = getQuotes(['AAPL', 'GOOG'])\n    return:\n    [{u'Index': u'NASDAQ', u'LastTradeWithCurrency': u'129.09', u'LastTradeDateTime': u'2015-03-02T16:04:29Z', u'LastTradePrice': u'129.09', u'Yield': u'1.46', u'LastTradeTime': u'4:04PM EST', u'LastTradeDateTimeLong': u'Mar 2, 4:04PM EST', u'Dividend': u'0.47', u'StockSymbol': u'AAPL', u'ID': u'22144'}, {u'Index': u'NASDAQ', u'LastTradeWithCurrency': u'571.34', u'LastTradeDateTime': u'2015-03-02T16:04:29Z', u'LastTradePrice': u'571.34', u'Yield': u'', u'LastTradeTime': u'4:04PM EST', u'LastTradeDateTimeLong': u'Mar 2, 4:04PM EST', u'Dividend': u'', u'StockSymbol': u'GOOG', u'ID': u'304466804484872'}]\n\n    :param symbols: a single symbol or a list of stock symbols\n    :return: real-time quotes list\n    '''\n    if type(symbols) == type('str'):\n        symbols = [symbols]\n    content = json.loads(request(symbols))\n    return replaceKeys(content);", "response": "Returns a sequence of quotes for stocks in the order of market market."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add(self, name, monitor=True):\n\n        if os.path.isdir(name):\n            if (not os.path.basename(name).startswith(\".\")):\n                self.add_folder(name)\n\n        elif os.path.isfile(name):\n            if ((self._looks_like_resource_file(name)) or\n                (self._looks_like_libdoc_file(name)) or\n                (self._looks_like_library_file(name))):\n                self.add_file(name)\n        else:\n            # let's hope it's a library name!\n            self.add_library(name)", "response": "Add a file folder library or resource file to the database."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrespond to changes in the file system that have been saved in disk.", "response": "def on_change(self, path, event_type):\n        \"\"\"Respond to changes in the file system\n\n        This method will be given the path to a file that\n        has changed on disk. We need to reload the keywords\n        from that file\n        \"\"\"\n        # I can do all this work in a sql statement, but\n        # for debugging it's easier to do it in stages.\n        sql = \"\"\"SELECT collection_id\n                 FROM collection_table\n                 WHERE path == ?\n        \"\"\"\n        cursor = self._execute(sql, (path,))\n        results = cursor.fetchall()\n        # there should always be exactly one result, but\n        # there's no harm in using a loop to process the\n        # single result\n        for result in results:\n            collection_id = result[0]\n            # remove all keywords in this collection\n            sql = \"\"\"DELETE from keyword_table\n                     WHERE collection_id == ?\n            \"\"\"\n            cursor = self._execute(sql, (collection_id,))\n            self._load_keywords(collection_id, path=path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _load_keywords(self, collection_id, path=None, libdoc=None):\n        if libdoc is None and path is None:\n            raise(Exception(\"You must provide either a path or libdoc argument\"))\n\n        if libdoc is None:\n            libdoc = LibraryDocumentation(path)\n\n        if len(libdoc.keywords) > 0:\n            for keyword in libdoc.keywords:\n                self._add_keyword(collection_id, keyword.name, keyword.doc, keyword.args)", "response": "Load a collection of keywords from a LibraryDocumentation."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a resource file or library file to the database", "response": "def add_file(self, path):\n        \"\"\"Add a resource file or library file to the database\"\"\"\n        libdoc = LibraryDocumentation(path)\n        if len(libdoc.keywords) > 0:\n            if libdoc.doc.startswith(\"Documentation for resource file\"):\n                # bah! The file doesn't have an file-level documentation\n                # and libdoc substitutes some placeholder text.\n                libdoc.doc = \"\"\n\n            collection_id = self.add_collection(path, libdoc.name, libdoc.type,\n                                                libdoc.doc, libdoc.version,\n                                                libdoc.scope, libdoc.named_args,\n                                                libdoc.doc_format)\n            self._load_keywords(collection_id, libdoc=libdoc)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_library(self, name):\n        libdoc = LibraryDocumentation(name)\n        if len(libdoc.keywords) > 0:\n            # FIXME: figure out the path to the library file\n            collection_id = self.add_collection(None, libdoc.name, libdoc.type,\n                                                libdoc.doc, libdoc.version,\n                                                libdoc.scope, libdoc.named_args,\n                                                libdoc.doc_format)\n            self._load_keywords(collection_id, libdoc=libdoc)", "response": "Add a library to the database"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a new collection entry into the database.", "response": "def add_collection(self, path, c_name, c_type, c_doc, c_version=\"unknown\",\n                       c_scope=\"\", c_namedargs=\"yes\", c_doc_format=\"ROBOT\"):\n        \"\"\"Insert data into the collection table\"\"\"\n        if path is not None:\n            # We want to store the normalized form of the path in the\n            # database\n            path = os.path.abspath(path)\n\n        cursor = self.db.cursor()\n        cursor.execute(\"\"\"\n            INSERT INTO collection_table\n                (name, type, version, scope, namedargs, path, doc, doc_format)\n            VALUES\n                (?,?,?,?,?,?,?,?)\n        \"\"\", (c_name, c_type, c_version, c_scope, c_namedargs, path, c_doc, c_doc_format))\n        collection_id = cursor.lastrowid\n        return collection_id"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding any installed libraries that we can find .", "response": "def add_installed_libraries(self, extra_libs = [\"Selenium2Library\",\n                                                    \"SudsLibrary\",\n                                                    \"RequestsLibrary\"]):\n        \"\"\"Add any installed libraries that we can find\n\n        We do this by looking in the `libraries` folder where\n        robot is installed. If you have libraries installed\n        in a non-standard place, this won't pick them up.\n        \"\"\"\n\n        libdir = os.path.dirname(robot.libraries.__file__)\n        loaded = []\n        for filename in os.listdir(libdir):\n            if filename.endswith(\".py\") or filename.endswith(\".pyc\"):\n                libname, ext = os.path.splitext(filename)\n                if (libname.lower() not in loaded and\n                    not self._should_ignore(libname)):\n\n                    try:\n                        self.add(libname)\n                        loaded.append(libname.lower())\n                    except Exception as e:\n                        # need a better way to log this...\n                        self.log.debug(\"unable to add library: \" + str(e))\n\n        # I hate how I implemented this, but I don't think there's\n        # any way to find out which installed python packages are\n        # robot libraries.\n        for library in extra_libs:\n            if (library.lower() not in loaded and\n                not self._should_ignore(library)):\n                try:\n                    self.add(library)\n                    loaded.append(library.lower())\n                except Exception as e:\n                    self.log.debug(\"unable to add external library %s: %s\" % \\\n                                   (library, str(e)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_collection(self, collection_id):\n        sql = \"\"\"SELECT collection.collection_id, collection.type,\n                        collection.name, collection.path,\n                        collection.doc,\n                        collection.version, collection.scope,\n                        collection.namedargs,\n                        collection.doc_format\n                 FROM collection_table as collection\n                 WHERE collection_id == ? OR collection.name like ?\n        \"\"\"\n        cursor = self._execute(sql, (collection_id, collection_id))\n        # need to handle the case where we get more than one result...\n        sql_result = cursor.fetchone()\n        return {\n            \"collection_id\": sql_result[0],\n            \"type\": sql_result[1],\n            \"name\": sql_result[2],\n            \"path\": sql_result[3],\n            \"doc\":  sql_result[4],\n            \"version\": sql_result[5],\n            \"scope\":   sql_result[6],\n            \"namedargs\": sql_result[7],\n            \"doc_format\": sql_result[8]\n        }\n        return sql_result", "response": "Get a specific collection"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_collections(self, pattern=\"*\", libtype=\"*\"):\n\n        sql = \"\"\"SELECT collection.collection_id, collection.name, collection.doc,\n                        collection.type, collection.path\n                 FROM collection_table as collection\n                 WHERE name like ?\n                 AND type like ?\n                 ORDER BY collection.name\n              \"\"\"\n\n        cursor = self._execute(sql, (self._glob_to_sql(pattern),\n                                     self._glob_to_sql(libtype)))\n        sql_result = cursor.fetchall()\n\n        return [{\"collection_id\": result[0],\n                 \"name\": result[1],\n                 \"synopsis\": result[2].split(\"\\n\")[0],\n                 \"type\": result[3],\n                 \"path\": result[4]\n             } for result in sql_result]", "response": "Returns a list of collection name summary tuples"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a specific keyword from a library", "response": "def get_keyword(self, collection_id, name):\n        \"\"\"Get a specific keyword from a library\"\"\"\n        sql = \"\"\"SELECT keyword.name, keyword.args, keyword.doc\n                 FROM keyword_table as keyword\n                 WHERE keyword.collection_id == ?\n                 AND keyword.name like ?\n              \"\"\"\n        cursor = self._execute(sql, (collection_id,name))\n        # We're going to assume no library has duplicate keywords\n        # While that in theory _could_ happen, it never _should_,\n        # and you get what you deserve if it does.\n        row = cursor.fetchone()\n        if row is not None:\n            return {\"name\": row[0],\n                    \"args\": json.loads(row[1]),\n                    \"doc\": row[2],\n                    \"collection_id\": collection_id\n            }\n        return {}"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn all keywords that match a glob - style pattern.", "response": "def get_keyword_hierarchy(self, pattern=\"*\"):\n        \"\"\"Returns all keywords that match a glob-style pattern\n\n        The result is a list of dictionaries, sorted by collection\n        name.\n\n        The pattern matching is insensitive to case. The function\n        returns a list of (library_name, keyword_name,\n        keyword_synopsis tuples) sorted by keyword name\n\n        \"\"\"\n\n        sql = \"\"\"SELECT collection.collection_id, collection.name, collection.path,\n                 keyword.name, keyword.doc\n                 FROM collection_table as collection\n                 JOIN keyword_table as keyword\n                 WHERE collection.collection_id == keyword.collection_id\n                 AND keyword.name like ?\n                 ORDER by collection.name, collection.collection_id, keyword.name\n             \"\"\"\n        cursor = self._execute(sql, (self._glob_to_sql(pattern),))\n        libraries = []\n        current_library = None\n        for row in cursor.fetchall():\n            (c_id, c_name, c_path, k_name, k_doc) = row\n            if c_id != current_library:\n                current_library = c_id\n                libraries.append({\"name\": c_name, \"collection_id\": c_id, \"keywords\": [], \"path\": c_path})\n            libraries[-1][\"keywords\"].append({\"name\": k_name, \"doc\": k_doc})\n        return libraries"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nperforms a pattern - based search on keyword names and documentation.", "response": "def search(self, pattern=\"*\", mode=\"both\"):\n        \"\"\"Perform a pattern-based search on keyword names and documentation\n\n        The pattern matching is insensitive to case. The function\n        returns a list of tuples of the form library_id, library_name,\n        keyword_name, keyword_synopsis, sorted by library id,\n        library name, and then keyword name\n\n        If a pattern begins with \"name:\", only the keyword names will\n        be searched. Otherwise, the pattern is searched for in both\n        the name and keyword documentation.\n\n        You can limit the search to a single library by specifying\n        \"in:\" followed by the name of the library or resource\n        file. For example, \"screenshot in:Selenium2Library\" will only\n        search for the word 'screenshot' in the Selenium2Library.\n\n        \"\"\"\n        pattern = self._glob_to_sql(pattern)\n\n        COND = \"(keyword.name like ? OR keyword.doc like ?)\"\n        args = [pattern, pattern]\n        if mode == \"name\":\n            COND = \"(keyword.name like ?)\"\n            args = [pattern,]\n\n        sql = \"\"\"SELECT collection.collection_id, collection.name, keyword.name, keyword.doc\n                 FROM collection_table as collection\n                 JOIN keyword_table as keyword\n                 WHERE collection.collection_id == keyword.collection_id\n                 AND %s\n                 ORDER by collection.collection_id, collection.name, keyword.name\n             \"\"\" % COND\n\n        cursor = self._execute(sql, args)\n        result = [(row[0], row[1], row[2], row[3].strip().split(\"\\n\")[0])\n                  for row in cursor.fetchall()]\n        return list(set(result))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_keywords(self, pattern=\"*\"):\n\n        sql = \"\"\"SELECT collection.collection_id, collection.name,\n                        keyword.name, keyword.doc, keyword.args\n                 FROM collection_table as collection\n                 JOIN keyword_table as keyword\n                 WHERE collection.collection_id == keyword.collection_id\n                 AND keyword.name like ?\n                 ORDER by collection.name, keyword.name\n             \"\"\"\n        pattern = self._glob_to_sql(pattern)\n        cursor = self._execute(sql, (pattern,))\n        result = [(row[0], row[1], row[2], row[3], row[4])\n                  for row in cursor.fetchall()]\n        return list(set(result))", "response": "Returns all keywords that match a glob - style pattern"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _looks_like_libdoc_file(self, name):\n        # inefficient since we end up reading the file twice,\n        # but it's fast enough for our purposes, and prevents\n        # us from doing a full parse of files that are obviously\n        # not libdoc files\n        if name.lower().endswith(\".xml\"):\n            with open(name, \"r\") as f:\n                # read the first few lines; if we don't see\n                # what looks like libdoc data, return false\n                data = f.read(200)\n                index = data.lower().find(\"<keywordspec \")\n                if index > 0:\n                    return True\n        return False", "response": "Return true if an xml file looks like a libdoc file"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _looks_like_resource_file(self, name):\n        # inefficient since we end up reading the file twice,\n        # but it's fast enough for our purposes, and prevents\n        # us from doing a full parse of files that are obviously\n        # not robot files\n\n        if (re.search(r'__init__.(txt|robot|html|tsv)$', name)):\n            # These are initialize files, not resource files\n            return False\n\n        found_keyword_table = False\n        if (name.lower().endswith(\".robot\") or\n            name.lower().endswith(\".txt\") or\n            name.lower().endswith(\".tsv\")):\n\n            with open(name, \"r\") as f:\n                data = f.read()\n                for match in re.finditer(r'^\\*+\\s*(Test Cases?|(?:User )?Keywords?)',\n                                         data, re.MULTILINE|re.IGNORECASE):\n                    if (re.match(r'Test Cases?', match.group(1), re.IGNORECASE)):\n                        # if there's a test case table, it's not a keyword file\n                        return False\n\n                    if (not found_keyword_table and\n                        re.match(r'(User )?Keywords?', match.group(1), re.IGNORECASE)):\n                        found_keyword_table = True\n        return found_keyword_table", "response": "Return true if the file looks like a resource file and not a testcase table"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _should_ignore(self, name):\n        _name = name.lower()\n        return (_name.startswith(\"deprecated\") or\n                _name.startswith(\"_\") or\n                _name in (\"remote\", \"reserved\",\n                          \"dialogs_py\", \"dialogs_ipy\", \"dialogs_jy\"))", "response": "Return True if a given library name should be ignored"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _execute(self, *args):\n        cursor = self.db.cursor()\n        cursor.execute(*args)\n        return cursor", "response": "Execute an SQL query\n\n        This exists because I think it s tedious to get a cursor and use a cursor."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _add_keyword(self, collection_id, name, doc, args):\n        argstring = json.dumps(args)\n        self.db.execute(\"\"\"\n            INSERT INTO keyword_table\n                (collection_id, name, doc, args)\n            VALUES\n                (?,?,?,?)\n        \"\"\", (collection_id, name, doc, argstring))", "response": "Insert data into the keyword table\n           "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _glob_to_sql(self, string):\n\n        # What's with the chr(1) and chr(2) nonsense? It's a trick to\n        # hide \\* and \\? from the * and ? substitutions. This trick\n        # depends on the substitutiones being done in order.  chr(1)\n        # and chr(2) were picked because I know those characters\n        # almost certainly won't be in the input string\n        table = ((r'\\\\', chr(1)), (r'\\*', chr(2)), (r'\\?', chr(3)),\n                 (r'%', r'\\%'),   (r'?', '_'),     (r'*', '%'),\n                 (chr(1), r'\\\\'), (chr(2), r'\\*'), (chr(3), r'\\?'))\n\n        for (a, b) in table:\n            string = string.replace(a,b)\n\n        string = string[1:] if string.startswith(\"^\") else \"%\" + string\n        string = string[:-1] if string.endswith(\"$\") else string + \"%\"\n\n        return string", "response": "Convert glob - like wildcards to SQL wildcards"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef doc():\n    kwdb = current_app.kwdb\n\n    libraries = get_collections(kwdb, libtype=\"library\")\n    resource_files = get_collections(kwdb, libtype=\"resource\")\n    hierarchy = get_navpanel_data(kwdb)\n\n    return flask.render_template(\"home.html\",\n                                 data={\"libraries\": libraries,\n                                       \"version\": __version__,\n                                       \"libdoc\": None,\n                                       \"hierarchy\": hierarchy,\n                                       \"resource_files\": resource_files\n                                   })", "response": "Show a list of libraries along with the nav panel on the left"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nshow a list of available libraries and resource files", "response": "def index():\n    \"\"\"Show a list of available libraries, and resource files\"\"\"\n    kwdb = current_app.kwdb\n\n    libraries = get_collections(kwdb, libtype=\"library\")\n    resource_files = get_collections(kwdb, libtype=\"resource\")\n\n    return flask.render_template(\"libraryNames.html\",\n                                 data={\"libraries\": libraries,\n                                       \"version\": __version__,\n                                       \"resource_files\": resource_files\n                                   })"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nshowing all keywords that match a pattern", "response": "def search():\n    \"\"\"Show all keywords that match a pattern\"\"\"\n    pattern = flask.request.args.get('pattern', \"*\").strip().lower()\n\n    # if the pattern contains \"in:<collection>\" (eg: in:builtin),\n    # filter results to only that (or those) collections\n    # This was kind-of hacked together, but seems to work well enough\n    collections = [c[\"name\"].lower() for c in current_app.kwdb.get_collections()]\n    words = []\n    filters = []\n    if pattern.startswith(\"name:\"):\n        pattern = pattern[5:].strip()\n        mode = \"name\"\n    else:\n        mode=\"both\"\n\n    for word in pattern.split(\" \"):\n        if word.lower().startswith(\"in:\"):\n            filters.extend([name for name in collections if name.startswith(word[3:])])\n        else:\n            words.append(word)\n    pattern = \" \".join(words)\n\n    keywords = []\n    for keyword in current_app.kwdb.search(pattern, mode):\n        kw = list(keyword)\n        collection_id = kw[0]\n        collection_name = kw[1].lower()\n        if len(filters) == 0 or collection_name in filters:\n            url = flask.url_for(\".doc_for_library\", collection_id=kw[0], keyword=kw[2])\n            row_id = \"row-%s.%s\" % (keyword[1].lower(), keyword[2].lower().replace(\" \",\"-\"))\n            keywords.append({\"collection_id\": keyword[0],\n                             \"collection_name\": keyword[1],\n                             \"name\": keyword[2],\n                             \"synopsis\": keyword[3],\n                             \"version\": __version__,\n                             \"url\": url,\n                             \"row_id\": row_id\n                         })\n\n    keywords.sort(key=lambda kw: kw[\"name\"])\n    return flask.render_template(\"search.html\",\n                                 data={\"keywords\": keywords,\n                                       \"version\": __version__,\n                                       \"pattern\": pattern\n                                   })"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets list of collections from kwdb then add urls necessary for hyperlinks", "response": "def get_collections(kwdb, libtype=\"*\"):\n    \"\"\"Get list of collections from kwdb, then add urls necessary for hyperlinks\"\"\"\n    collections = kwdb.get_collections(libtype=libtype)\n    for result in collections:\n        url = flask.url_for(\".doc_for_library\", collection_id=result[\"collection_id\"])\n        result[\"url\"] = url\n\n    return collections"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets navpanel data from kwdb and add urls necessary for hyperlinks", "response": "def get_navpanel_data(kwdb):\n    \"\"\"Get navpanel data from kwdb, and add urls necessary for hyperlinks\"\"\"\n    data = kwdb.get_keyword_hierarchy()\n    for library in data:\n        library[\"url\"] = flask.url_for(\".doc_for_library\", collection_id=library[\"collection_id\"])\n        for keyword in library[\"keywords\"]:\n            url = flask.url_for(\".doc_for_library\",\n                                collection_id=library[\"collection_id\"],\n                                keyword=keyword[\"name\"])\n            keyword[\"url\"] = url\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef doc_to_html(doc, doc_format=\"ROBOT\"):\n    from robot.libdocpkg.htmlwriter import DocToHtml\n    return DocToHtml(doc_format)(doc)", "response": "Convert a documentation to HTML"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef coords(obj):\n    # Handle recursive case first\n    if 'features' in obj:\n        for f in obj['features']:\n            # For Python 2 compatibility\n            # See https://www.reddit.com/r/learnpython/comments/4rc15s/yield_from_and_python_27/ # noqa: E501\n            for c in coords(f):\n                yield c\n    else:\n        if isinstance(obj, (tuple, list)):\n            coordinates = obj\n        elif 'geometry' in obj:\n            coordinates = obj['geometry']['coordinates']\n        else:\n            coordinates = obj.get('coordinates', obj)\n        for e in coordinates:\n            if isinstance(e, (float, int)):\n                yield tuple(coordinates)\n                break\n            for f in coords(e):\n                yield f", "response": "Yields the coordinates from a geometry or feature."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the mapped coordinates from a Geometry after applying the provided function to each dimension in the tuple list.", "response": "def map_coords(func, obj):\n    \"\"\"\n    Returns the mapped coordinates from a Geometry after applying the provided\n    function to each dimension in tuples list (ie, linear scaling).\n\n    :param func: Function to apply to individual coordinate values\n    independently\n    :type func: function\n    :param obj: A geometry or feature to extract the coordinates from.\n    :type obj: Point, LineString, MultiPoint, MultiLineString, Polygon,\n    MultiPolygon\n    :return: The result of applying the function to each dimension in the\n    array.\n    :rtype: list\n    :raises ValueError: if the provided object is not GeoJSON.\n    \"\"\"\n\n    def tuple_func(coord):\n        return (func(coord[0]), func(coord[1]))\n\n    return map_tuples(tuple_func, obj)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the mapped coordinates from a Geometry after applying the provided function to each coordinate.", "response": "def map_tuples(func, obj):\n    \"\"\"\n    Returns the mapped coordinates from a Geometry after applying the provided\n    function to each coordinate.\n\n    :param func: Function to apply to tuples\n    :type func: function\n    :param obj: A geometry or feature to extract the coordinates from.\n    :type obj: Point, LineString, MultiPoint, MultiLineString, Polygon,\n    MultiPolygon\n    :return: The result of applying the function to each dimension in the\n    array.\n    :rtype: list\n    :raises ValueError: if the provided object is not GeoJSON.\n    \"\"\"\n\n    if obj['type'] == 'Point':\n        coordinates = tuple(func(obj['coordinates']))\n    elif obj['type'] in ['LineString', 'MultiPoint']:\n        coordinates = [tuple(func(c)) for c in obj['coordinates']]\n    elif obj['type'] in ['MultiLineString', 'Polygon']:\n        coordinates = [[\n            tuple(func(c)) for c in curve]\n            for curve in obj['coordinates']]\n    elif obj['type'] == 'MultiPolygon':\n        coordinates = [[[\n            tuple(func(c)) for c in curve]\n            for curve in part]\n            for part in obj['coordinates']]\n    elif obj['type'] in ['Feature', 'FeatureCollection', 'GeometryCollection']:\n        return map_geometries(lambda g: map_tuples(func, g), obj)\n    else:\n        raise ValueError(\"Invalid geometry object %s\" % repr(obj))\n    return {'type': obj['type'], 'coordinates': coordinates}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef map_geometries(func, obj):\n    simple_types = [\n        'Point',\n        'LineString',\n        'MultiPoint',\n        'MultiLineString',\n        'Polygon',\n        'MultiPolygon',\n    ]\n\n    if obj['type'] in simple_types:\n        return func(obj)\n    elif obj['type'] == 'GeometryCollection':\n        geoms = [func(geom) if geom else None for geom in obj['geometries']]\n        return {'type': obj['type'], 'geometries': geoms}\n    elif obj['type'] == 'Feature':\n        geom = func(obj['geometry']) if obj['geometry'] else None\n        return {\n            'type': obj['type'],\n            'geometry': geom,\n            'properties': obj['properties'],\n        }\n    elif obj['type'] == 'FeatureCollection':\n        feats = [map_geometries(func, feat) for feat in obj['features']]\n        return {'type': obj['type'], 'features': feats}\n    else:\n        raise ValueError(\"Invalid GeoJSON object %s\" % repr(obj))", "response": "Applies a function to each geometry in the given geojson object\n    Returns the result of applying the function to each geometry in the given geojson object\n    through func."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate_random(featureType, numberVertices=3,\n                    boundingBox=[-180.0, -90.0, 180.0, 90.0]):\n    \"\"\"\n    Generates random geojson features depending on the parameters\n    passed through.\n    The bounding box defaults to the world - [-180.0, -90.0, 180.0, 90.0].\n    The number of vertices defaults to 3.\n\n    :param featureType: A geometry type\n    :type featureType: Point, LineString, Polygon\n    :param numberVertices: The number vertices that a linestring or polygon\n    will have\n    :type numberVertices: int\n    :param boundingBox: A bounding box in which features will be restricted to\n    :type boundingBox: list\n    :return: The resulting random geojson object or geometry collection.\n    :rtype: object\n    :raises ValueError: if there is no featureType provided.\n    \"\"\"\n\n    from geojson import Point, LineString, Polygon\n    import random\n    import math\n\n    lonMin = boundingBox[0]\n    lonMax = boundingBox[2]\n\n    def randomLon():\n        return random.uniform(lonMin, lonMax)\n\n    latMin = boundingBox[1]\n    latMax = boundingBox[3]\n\n    def randomLat():\n        return random.uniform(latMin, latMax)\n\n    def createPoint():\n        return Point((randomLon(), randomLat()))\n\n    def createLine():\n        return LineString([createPoint() for unused in range(numberVertices)])\n\n    def createPoly():\n        aveRadius = 60\n        ctrX = 0.1\n        ctrY = 0.2\n        irregularity = clip(0.1, 0, 1) * 2 * math.pi / numberVertices\n        spikeyness = clip(0.5, 0, 1) * aveRadius\n\n        angleSteps = []\n        lower = (2 * math.pi / numberVertices) - irregularity\n        upper = (2 * math.pi / numberVertices) + irregularity\n        sum = 0\n        for i in range(numberVertices):\n            tmp = random.uniform(lower, upper)\n            angleSteps.append(tmp)\n            sum = sum + tmp\n\n        k = sum / (2 * math.pi)\n        for i in range(numberVertices):\n            angleSteps[i] = angleSteps[i] / k\n\n        points = []\n        angle = random.uniform(0, 2 * math.pi)\n\n        for i in range(numberVertices):\n            r_i = clip(random.gauss(aveRadius, spikeyness), 0, 2 * aveRadius)\n            x = ctrX + r_i * math.cos(angle)\n            y = ctrY + r_i * math.sin(angle)\n            points.append((int(x), int(y)))\n            angle = angle + angleSteps[i]\n\n        firstVal = points[0]\n        points.append(firstVal)\n        return Polygon([points])\n\n    def clip(x, min, max):\n        if(min > max):\n            return x\n        elif(x < min):\n            return min\n        elif(x > max):\n            return max\n        else:\n            return x\n\n    if featureType == 'Point':\n        return createPoint()\n\n    if featureType == 'LineString':\n        return createLine()\n\n    if featureType == 'Polygon':\n        return createPoly()", "response": "Generates a random geojson feature based on the parameters passed through."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_simple_web_feature(o):\n    try:\n        id = o['id']\n        g = o['geometry']\n        p = o['properties']\n        return SimpleWebFeature(str(id), {\n            'type': str(g.get('type')),\n            'coordinates': g.get('coordinates', [])},\n            title=p.get('title'),\n            summary=p.get('summary'),\n            link=str(p.get('link')))\n    except (KeyError, TypeError):\n        pass\n    return o", "response": "Create an instance of SimpleWebFeature from a dict."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_instance(cls, ob, default=None, strict=False):\n        if ob is None and default is not None:\n            instance = default()\n        elif isinstance(ob, GeoJSON):\n            instance = ob\n        else:\n            mapping = to_mapping(ob)\n            d = {}\n            for k in mapping:\n                d[k] = mapping[k]\n            try:\n                type_ = d.pop(\"type\")\n                try:\n                    type_ = str(type_)\n                except UnicodeEncodeError:\n                    # If the type contains non-ascii characters, we can assume\n                    # it's not a valid GeoJSON type\n                    raise AttributeError(\n                        \"{0} is not a GeoJSON type\").format(type_)\n                geojson_factory = getattr(geojson.factory, type_)\n                instance = geojson_factory(**d)\n            except (AttributeError, KeyError) as invalid:\n                if strict:\n                    msg = \"Cannot coerce %r into a valid GeoJSON structure: %s\"\n                    msg %= (ob, invalid)\n                    raise ValueError(msg)\n                instance = ob\n        return instance", "response": "Encode a GeoJSON dict into an instance of cls."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_list_errors(self, checkFunc, lst):\n        # check for errors on each subitem, filter only subitems with errors\n        results = (checkFunc(i) for i in lst)\n        return [err for err in results if err]", "response": "Check for errors on each item in list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _glob_escape(pathname):\n    drive, pathname = os.path.splitdrive(pathname)\n    pathname = _magic_check.sub(r'[\\1]', pathname)\n    return drive + pathname", "response": "Escape all special characters in pathname."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning a keyword only once in one of the parallel processes.", "response": "def run_only_once(self, keyword):\n        \"\"\"\n        Runs a keyword only once in one of the parallel processes.\n        As the keyword will be called\n        only in one process and the return value could basically be anything.\n        The \"Run Only Once\" can't return the actual return value.\n        If the keyword fails, \"Run Only Once\" fails.\n        Others executing \"Run Only Once\" wait before going through this\n        keyword before the actual command has been executed.\n        NOTE! This is a potential \"Shoot yourself in to knee\" keyword\n        Especially note that all the namespace changes are only visible\n        in the process that actually executed the keyword.\n        Also note that this might lead to odd situations if used inside\n        of other keywords.\n        Also at this point the keyword will be identified to be same\n        if it has the same name.\n        \"\"\"\n        lock_name = 'pabot_run_only_once_%s' % keyword\n        try:\n            self.acquire_lock(lock_name)\n            passed = self.get_parallel_value_for_key(lock_name)\n            if passed != '':\n                if passed == 'FAILED':\n                    raise AssertionError('Keyword failed in other process')\n                return\n            BuiltIn().run_keyword(keyword)\n            self.set_parallel_value_for_key(lock_name, 'PASSED')\n        except:\n            self.set_parallel_value_for_key(lock_name, 'FAILED')\n            raise\n        finally:\n            self.release_lock(lock_name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset a globally available key and value that can be accessed by all the pabot processes.", "response": "def set_parallel_value_for_key(self, key, value):\n        \"\"\"\n        Set a globally available key and value that can be accessed\n        from all the pabot processes.\n        \"\"\"\n        if self._remotelib:\n            self._remotelib.run_keyword('set_parallel_value_for_key',\n                                        [key, value], {})\n        else:\n            _PabotLib.set_parallel_value_for_key(self, key, value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_parallel_value_for_key(self, key):\n        if self._remotelib:\n            return self._remotelib.run_keyword('get_parallel_value_for_key',\n                                               [key], {})\n        return _PabotLib.get_parallel_value_for_key(self, key)", "response": "Get the value for a key."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwaiting for a lock with the given name.", "response": "def acquire_lock(self, name):\n        \"\"\"\n        Wait for a lock with name.\n        This will prevent other processes from acquiring the lock with\n        the name while it is held. Thus they will wait in the position\n        where they are acquiring the lock until the process that has it\n        releases it.\n        \"\"\"\n        if self._remotelib:\n            try:\n                while not self._remotelib.run_keyword('acquire_lock',\n                                                      [name, self._my_id], {}):\n                    time.sleep(0.1)\n                    logger.debug('waiting for lock to release')\n                return True\n            except RuntimeError:\n                logger.warn('no connection')\n                self.__remotelib = None\n        return _PabotLib.acquire_lock(self, name, self._my_id)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrelease a lock with name.", "response": "def release_lock(self, name):\n        \"\"\"\n        Release a lock with name.\n        This will enable others to acquire the lock.\n        \"\"\"\n        if self._remotelib:\n            self._remotelib.run_keyword('release_lock',\n                                        [name, self._my_id], {})\n        else:\n            _PabotLib.release_lock(self, name, self._my_id)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrelease all locks called by instance.", "response": "def release_locks(self):\n        \"\"\"\n        Release all locks called by instance.\n        \"\"\"\n        if self._remotelib:\n            self._remotelib.run_keyword('release_locks',\n                                        [self._my_id], {})\n        else:\n            _PabotLib.release_locks(self, self._my_id)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef acquire_value_set(self, *tags):\n        setname = self._acquire_value_set(*tags)\n        if setname is None:\n            raise ValueError(\"Could not aquire a value set\")\n        return setname", "response": "Acquires a value set for this execution."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_value_from_set(self, key):\n        #TODO: This should be done locally. \n        # We do not really need to call centralised server if the set is already\n        # reserved as the data there is immutable during execution\n        key = key.lower()\n        if self._remotelib:\n            while True:\n                value = self._remotelib.run_keyword('get_value_from_set',\n                                                    [key, self._my_id], {})\n                if value:\n                    return value\n                time.sleep(0.1)\n                logger.debug('waiting for a value')\n        else:\n            return _PabotLib.get_value_from_set(self, key, self._my_id)", "response": "Get a value from previously reserved value set."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreleases a reserved value set so that other executions can use it.", "response": "def release_value_set(self):\n        \"\"\"\n        Release a reserved value set so that other executions can use it also.\n        \"\"\"\n        if self._remotelib:\n            self._remotelib.run_keyword('release_value_set', [self._my_id], {})\n        else:\n            _PabotLib.release_value_set(self, self._my_id)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef install_all_patches():\n    from . import mysqldb\n    from . import psycopg2\n    from . import strict_redis\n    from . import sqlalchemy\n    from . import tornado_http\n    from . import urllib\n    from . import urllib2\n    from . import requests\n\n    mysqldb.install_patches()\n    psycopg2.install_patches()\n    strict_redis.install_patches()\n    sqlalchemy.install_patches()\n    tornado_http.install_patches()\n    urllib.install_patches()\n    urllib2.install_patches()\n    requests.install_patches()", "response": "A convenience method that installs all available hooks."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninstall the specified client hooks into the base base.", "response": "def install_patches(patchers='all'):\n    \"\"\"\n    Usually called from middleware to install client hooks\n    specified in the client_hooks section of the configuration.\n\n    :param patchers: a list of patchers to run. Acceptable values include:\n      * None - installs all client patches\n      * 'all' - installs all client patches\n      * empty list - does not install any patches\n      * list of function names - executes the functions\n    \"\"\"\n    if patchers is None or patchers == 'all':\n        install_all_patches()\n        return\n    if not _valid_args(patchers):\n        raise ValueError('patchers argument must be None, \"all\", or a list')\n\n    for patch_func_name in patchers:\n        logging.info('Loading client hook %s', patch_func_name)\n        patch_func = _load_symbol(patch_func_name)\n        logging.info('Applying client hook %s', patch_func_name)\n        patch_func()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef install_client_interceptors(client_interceptors=()):\n    if not _valid_args(client_interceptors):\n        raise ValueError('client_interceptors argument must be a list')\n\n    from ..http_client import ClientInterceptors\n\n    for client_interceptor in client_interceptors:\n        logging.info('Loading client interceptor %s', client_interceptor)\n        interceptor_class = _load_symbol(client_interceptor)\n        logging.info('Adding client interceptor %s', client_interceptor)\n        ClientInterceptors.append(interceptor_class())", "response": "Installs client interceptors for the patchers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading a symbol by name.", "response": "def _load_symbol(name):\n    \"\"\"Load a symbol by name.\n\n    :param str name: The name to load, specified by `module.attr`.\n    :returns: The attribute value. If the specified module does not contain\n              the requested attribute then `None` is returned.\n    \"\"\"\n    module_name, key = name.rsplit('.', 1)\n    try:\n        module = importlib.import_module(module_name)\n    except ImportError as err:\n        # it's possible the symbol is a class method\n        module_name, class_name = module_name.rsplit('.', 1)\n        module = importlib.import_module(module_name)\n        cls = getattr(module, class_name, None)\n        if cls:\n            attr = getattr(cls, key, None)\n        else:\n            raise err\n    else:\n        attr = getattr(module, key, None)\n    if not callable(attr):\n        raise ValueError('%s is not callable (was %r)' % (name, attr))\n    return attr"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the current span associated with the current request context.", "response": "def get_current_span():\n    \"\"\"\n    Access current request context and extract current Span from it.\n    :return:\n        Return current span associated with the current request context.\n        If no request context is present in thread local, or the context\n        has no span, return None.\n    \"\"\"\n    # Check against the old, ScopeManager-less implementation,\n    # for backwards compatibility.\n    context = RequestContextManager.current_context()\n    if context is not None:\n        return context.span\n\n    active = opentracing.tracer.scope_manager.active\n    return active.span if active else None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a WSGI tracing middleware that stores the given span in the thread - local request context.", "response": "def span_in_context(span):\n    \"\"\"\n    Create a context manager that stores the given span in the thread-local\n    request context. This function should only be used in single-threaded\n    applications like Flask / uWSGI.\n\n    ## Usage example in WSGI middleware:\n\n    .. code-block:: python\n        from opentracing_instrumentation.http_server import WSGIRequestWrapper\n        from opentracing_instrumentation.http_server import before_request\n        from opentracing_instrumentation import request_context\n\n        def create_wsgi_tracing_middleware(other_wsgi):\n\n            def wsgi_tracing_middleware(environ, start_response):\n                request = WSGIRequestWrapper.from_wsgi_environ(environ)\n                span = before_request(request=request, tracer=tracer)\n\n                # Wrapper around the real start_response object to log\n                # additional information to opentracing Span\n                def start_response_wrapper(status, response_headers,\n                                           exc_info=None):\n                    if exc_info is not None:\n                        span.log(event='exception', payload=exc_info)\n                    span.finish()\n\n                    return start_response(status, response_headers)\n\n                with request_context.span_in_context(span):\n                    return other_wsgi(environ, start_response_wrapper)\n\n            return wsgi_tracing_middleware\n\n    :param span: OpenTracing Span\n    :return:\n        Return context manager that wraps the request context.\n    \"\"\"\n\n    # Return a no-op Scope if None was specified.\n    if span is None:\n        return opentracing.Scope(None, None)\n\n    return opentracing.tracer.scope_manager.activate(span, False)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new Tornado s StackContext that stores the given span in the current thread - local request context.", "response": "def span_in_stack_context(span):\n    \"\"\"\n    Create Tornado's StackContext that stores the given span in the\n    thread-local request context. This function is intended for use\n    in Tornado applications based on IOLoop, although will work fine\n    in single-threaded apps like Flask, albeit with more overhead.\n\n    ## Usage example in Tornado application\n\n    Suppose you have a method `handle_request(request)` in the http server.\n    Instead of calling it directly, use a wrapper:\n\n    .. code-block:: python\n\n        from opentracing_instrumentation import request_context\n\n        @tornado.gen.coroutine\n        def handle_request_wrapper(request, actual_handler, *args, **kwargs)\n\n            request_wrapper = TornadoRequestWrapper(request=request)\n            span = http_server.before_request(request=request_wrapper)\n\n            with request_context.span_in_stack_context(span):\n                return actual_handler(*args, **kwargs)\n\n    :param span:\n    :return:\n        Return StackContext that wraps the request context.\n    \"\"\"\n\n    if not isinstance(opentracing.tracer.scope_manager, TornadoScopeManager):\n        raise RuntimeError('scope_manager is not TornadoScopeManager')\n\n    # Enter the newly created stack context so we have\n    # storage available for Span activation.\n    context = tracer_stack_context()\n    entered_context = _TracerEnteredStackContext(context)\n\n    if span is None:\n        return entered_context\n\n    opentracing.tracer.scope_manager.activate(span, False)\n    assert opentracing.tracer.active_span is not None\n    assert opentracing.tracer.active_span is span\n\n    return entered_context"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new span for execution of a function.", "response": "def func_span(func, tags=None, require_active_trace=False):\n    \"\"\"\n    Creates a new local span for execution of the given `func`.\n    The returned span is best used as a context manager, e.g.\n\n    .. code-block:: python\n\n        with func_span('my_function'):\n            return my_function(...)\n\n    At this time the func should be a string name. In the future this code\n    can be enhanced to accept a real function and derive its qualified name.\n\n    :param func: name of the function or method\n    :param tags: optional tags to add to the child span\n    :param require_active_trace: controls what to do when there is no active\n        trace. If require_active_trace=True, then no span is created.\n        If require_active_trace=False, a new trace is started.\n    :return: new child span, or a dummy context manager if there is no\n        active/current parent span\n    \"\"\"\n    current_span = get_current_span()\n\n    if current_span is None and require_active_trace:\n        @contextlib2.contextmanager\n        def empty_ctx_mgr():\n            yield None\n\n        return empty_ctx_mgr()\n\n    # TODO convert func to a proper name: module:class.func\n    operation_name = str(func)\n    return utils.start_child_span(\n        operation_name=operation_name, parent=current_span, tags=tags)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef traced_function(func=None, name=None, on_start=None,\n                    require_active_trace=False):\n    \"\"\"\n    A decorator that enables tracing of the wrapped function or\n    Tornado co-routine provided there is a parent span already established.\n\n    .. code-block:: python\n\n        @traced_function\n        def my_function1(arg1, arg2=None)\n            ...\n\n    :param func: decorated function or Tornado co-routine\n    :param name: optional name to use as the Span.operation_name.\n        If not provided, func.__name__ will be used.\n    :param on_start: an optional callback to be executed once the child span\n        is started, but before the decorated function is called. It can be\n        used to set any additional tags on the span, perhaps by inspecting\n        the decorated function arguments. The callback must have a signature\n        `(span, *args, *kwargs)`, where the last two collections are the\n        arguments passed to the actual decorated function.\n\n        .. code-block:: python\n\n            def extract_call_site_tag(span, *args, *kwargs)\n                if 'call_site_tag' in kwargs:\n                    span.set_tag('call_site_tag', kwargs['call_site_tag'])\n\n            @traced_function(on_start=extract_call_site_tag)\n            @tornado.get.coroutine\n            def my_function(arg1, arg2=None, call_site_tag=None)\n                ...\n\n    :param require_active_trace: controls what to do when there is no active\n        trace. If require_active_trace=True, then no span is created.\n        If require_active_trace=False, a new trace is started.\n    :return: returns a tracing decorator\n    \"\"\"\n\n    if func is None:\n        return functools.partial(traced_function, name=name,\n                                 on_start=on_start,\n                                 require_active_trace=require_active_trace)\n\n    if name:\n        operation_name = name\n    else:\n        operation_name = func.__name__\n\n    @functools.wraps(func)\n    def decorator(*args, **kwargs):\n        parent_span = get_current_span()\n        if parent_span is None and require_active_trace:\n            return func(*args, **kwargs)\n\n        span = utils.start_child_span(\n            operation_name=operation_name, parent=parent_span)\n        if callable(on_start):\n            on_start(span, *args, **kwargs)\n\n        # We explicitly invoke deactivation callback for the StackContext,\n        # because there are scenarios when it gets retained forever, for\n        # example when a Periodic Callback is scheduled lazily while in the\n        # scope of a tracing StackContext.\n        with span_in_stack_context(span) as deactivate_cb:\n            try:\n                res = func(*args, **kwargs)\n                # Tornado co-routines usually return futures, so we must wait\n                # until the future is completed, in order to accurately\n                # capture the function's execution time.\n                if tornado.concurrent.is_future(res):\n                    def done_callback(future):\n                        deactivate_cb()\n                        exception = future.exception()\n                        if exception is not None:\n                            span.log(event='exception', payload=exception)\n                            span.set_tag('error', 'true')\n                        span.finish()\n                    res.add_done_callback(done_callback)\n                else:\n                    deactivate_cb()\n                    span.finish()\n                return res\n            except Exception as e:\n                deactivate_cb()\n                span.log(event='exception', payload=e)\n                span.set_tag('error', 'true')\n                span.finish()\n                raise\n    return decorator", "response": "Decorator that enables tracing of a function or Tornado co - routine."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstart a new span as a child of parent_span.", "response": "def start_child_span(operation_name, tracer=None, parent=None, tags=None):\n    \"\"\"\n    Start a new span as a child of parent_span. If parent_span is None,\n    start a new root span.\n\n    :param operation_name: operation name\n    :param tracer: Tracer or None (defaults to opentracing.tracer)\n    :param parent: parent Span or None\n    :param tags: optional tags\n    :return: new span\n    \"\"\"\n    tracer = tracer or opentracing.tracer\n    return tracer.start_span(\n        operation_name=operation_name,\n        child_of=parent.context if parent else None,\n        tags=tags\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef before_request(request, tracer=None):\n    if tracer is None:  # pragma: no cover\n        tracer = opentracing.tracer\n\n    # we need to prepare tags upfront, mainly because RPC_SERVER tag must be\n    # set when starting the span, to support Zipkin's one-span-per-RPC model\n    tags_dict = {\n        tags.SPAN_KIND: tags.SPAN_KIND_RPC_SERVER,\n        tags.HTTP_URL: request.full_url,\n    }\n\n    remote_ip = request.remote_ip\n    if remote_ip:\n        tags_dict[tags.PEER_HOST_IPV4] = remote_ip\n\n    caller_name = request.caller_name\n    if caller_name:\n        tags_dict[tags.PEER_SERVICE] = caller_name\n\n    remote_port = request.remote_port\n    if remote_port:\n        tags_dict[tags.PEER_PORT] = remote_port\n\n    operation = request.operation\n    try:\n        carrier = {}\n        for key, value in six.iteritems(request.headers):\n            carrier[key] = value\n        parent_ctx = tracer.extract(\n            format=Format.HTTP_HEADERS, carrier=carrier\n        )\n    except Exception as e:\n        logging.exception('trace extract failed: %s' % e)\n        parent_ctx = None\n\n    span = tracer.start_span(\n        operation_name=operation,\n        child_of=parent_ctx,\n        tags=tags_dict)\n\n    return span", "response": "Attempts to extract a tracing span from incoming request."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parse_wsgi_headers(wsgi_environ):\n        prefix = 'HTTP_'\n        p_len = len(prefix)\n        # use .items() despite suspected memory pressure bc GC occasionally\n        # collects wsgi_environ.iteritems() during iteration.\n        headers = {\n            key[p_len:].replace('_', '-').lower():\n                val for (key, val) in wsgi_environ.items()\n            if key.startswith(prefix)}\n        return headers", "response": "This method parses the WSGI environment with HTTP_ prefix and returns a dictionary of headers."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef full_url(self):\n        environ = self.wsgi_environ\n        url = environ['wsgi.url_scheme'] + '://'\n\n        if environ.get('HTTP_HOST'):\n            url += environ['HTTP_HOST']\n        else:\n            url += environ['SERVER_NAME']\n\n            if environ['wsgi.url_scheme'] == 'https':\n                if environ['SERVER_PORT'] != '443':\n                    url += ':' + environ['SERVER_PORT']\n            else:\n                if environ['SERVER_PORT'] != '80':\n                    url += ':' + environ['SERVER_PORT']\n\n        url += urllib.parse.quote(environ.get('SCRIPT_NAME', ''))\n        url += urllib.parse.quote(environ.get('PATH_INFO', ''))\n        if environ.get('QUERY_STRING'):\n            url += '?' + environ['QUERY_STRING']\n        return url", "response": "Reconstructs the full URL from WSGI environment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding an interceptor to the end of the internal list.", "response": "def append(cls, interceptor):\n        \"\"\"\n        Add interceptor to the end of the internal list.\n\n        Note: Raises ``ValueError`` if interceptor\n              does not extend ``OpenTracingInterceptor``\n        \"\"\"\n        cls._check(interceptor)\n        cls._interceptors.append(interceptor)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef insert(cls, index, interceptor):\n        cls._check(interceptor)\n        cls._interceptors.insert(index, interceptor)", "response": "Adds an interceptor to the given index in the internal list."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef singleton(func):\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        if wrapper.__call_state__ == CALLED:\n            return\n        ret = func(*args, **kwargs)\n        wrapper.__call_state__ = CALLED\n        return ret\n\n    def reset():\n        wrapper.__call_state__ = NOT_CALLED\n\n    wrapper.reset = reset\n    reset()\n\n    # save original func to be able to patch and restore multiple times from\n    # unit tests\n    wrapper.__original_func = func\n    return wrapper", "response": "Decorator to make sure that a function is called only once and only once."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef before_http_request(request, current_span_extractor):\n\n    span = utils.start_child_span(\n        operation_name=request.operation,\n        parent=current_span_extractor()\n    )\n\n    span.set_tag(tags.SPAN_KIND, tags.SPAN_KIND_RPC_CLIENT)\n    span.set_tag(tags.HTTP_URL, request.full_url)\n\n    service_name = request.service_name\n    host, port = request.host_port\n    if service_name:\n        span.set_tag(tags.PEER_SERVICE, service_name)\n    if host:\n        span.set_tag(tags.PEER_HOST_IPV4, host)\n    if port:\n        span.set_tag(tags.PEER_PORT, port)\n\n    # fire interceptors\n    for interceptor in ClientInterceptors.get_interceptors():\n        interceptor.process(request=request, span=span)\n\n    try:\n        carrier = {}\n        opentracing.tracer.inject(span_context=span.context,\n                                  format=Format.HTTP_HEADERS,\n                                  carrier=carrier)\n        for key, value in six.iteritems(carrier):\n            request.add_header(key, value)\n    except opentracing.UnsupportedFormatException:\n        pass\n\n    return span", "response": "A hook to be executed before HTTP request is executed. It returns a Span object that can be used as a context manager around the current request and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsmooth an image ANTsImage object", "response": "def smooth_image(image, sigma, sigma_in_physical_coordinates=True, FWHM=False, max_kernel_width=32):\n    \"\"\"\n    Smooth an image\n\n    ANTsR function: `smoothImage`\n\n    Arguments\n    ---------\n    image   \n        Image to smooth\n    \n    sigma   \n        Smoothing factor. Can be scalar, in which case the same sigma is applied to each dimension, or a vector of length dim(inimage) to specify a unique smoothness for each dimension.\n    \n    sigma_in_physical_coordinates : boolean  \n        If true, the smoothing factor is in millimeters; if false, it is in pixels.\n    \n    FWHM : boolean    \n        If true, sigma is interpreted as the full-width-half-max (FWHM) of the filter, not the sigma of a Gaussian kernel.\n    \n    max_kernel_width : scalar    \n        Maximum kernel width\n    \n    Returns\n    -------\n    ANTsImage\n    \n    Example\n    -------\n    >>> import ants\n    >>> image = ants.image_read( ants.get_ants_data('r16'))\n    >>> simage = ants.smooth_image(image, (1.2,1.5))\n    \"\"\"\n    if image.components == 1:\n        return _smooth_image_helper(image, sigma, sigma_in_physical_coordinates, FWHM, max_kernel_width)\n    else:\n        imagelist = utils.split_channels(image)\n        newimages = []\n        for image in imagelist:\n            newimage = _smooth_image_helper(image, sigma, sigma_in_physical_coordinates, FWHM, max_kernel_width)\n            newimages.append(newimage)\n        return utils.merge_channels(newimages)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nestimating an optimal template from an input image_list ANTsR function: N/A Arguments --------- initial_template : ANTsImage initialization for the template building image_list : ANTsImages images from which to estimate template iterations : integer number of template building iterations gradient_step : scalar for shape update gradient kwargs : keyword args extra arguments passed to ants registration Returns ------- ANTsImage Example ------- >>> import ants >>> image = ants.image_read( ants.get_ants_data('r16') , 'float') >>> image2 = ants.image_read( ants.get_ants_data('r27') , 'float') >>> image3 = ants.image_read( ants.get_ants_data('r85') , 'float') >>> timage = ants.build_template( image_list = ( image, image2, image3 ) )", "response": "def build_template(\n    initial_template=None,\n    image_list=None,\n    iterations = 3,\n    gradient_step = 0.2,\n    **kwargs ):\n    \"\"\"\n    Estimate an optimal template from an input image_list\n\n    ANTsR function: N/A\n\n    Arguments\n    ---------\n    initial_template : ANTsImage\n        initialization for the template building\n\n    image_list : ANTsImages\n        images from which to estimate template\n\n    iterations : integer\n        number of template building iterations\n\n    gradient_step : scalar\n        for shape update gradient\n\n    kwargs : keyword args\n        extra arguments passed to ants registration\n\n    Returns\n    -------\n    ANTsImage\n\n    Example\n    -------\n    >>> import ants\n    >>> image = ants.image_read( ants.get_ants_data('r16') , 'float')\n    >>> image2 = ants.image_read( ants.get_ants_data('r27') , 'float')\n    >>> image3 = ants.image_read( ants.get_ants_data('r85') , 'float')\n    >>> timage = ants.build_template( image_list = ( image, image2, image3 ) )\n    \"\"\"\n    wt = 1.0 / len( image_list )\n    if initial_template is None:\n        initial_template = image_list[ 0 ] * 0\n        for i in range( len( image_list ) ):\n            initial_template = initial_template + image_list[ i ] * wt\n\n    xavg = initial_template.clone()\n    for i in range( iterations ):\n        for k in range( len( image_list ) ):\n            w1 = registration( xavg, image_list[k],\n              type_of_transform='SyN', **kwargs )\n            if k == 0:\n              wavg = iio.image_read( w1['fwdtransforms'][0] ) * wt\n              xavgNew = w1['warpedmovout'] * wt\n            else:\n              wavg = wavg + iio.image_read( w1['fwdtransforms'][0] ) * wt\n              xavgNew = xavgNew + w1['warpedmovout'] * wt\n        print( wavg.abs().mean() )\n        wscl = (-1.0) * gradient_step\n        wavg = wavg * wscl\n        wavgfn = mktemp(suffix='.nii.gz')\n        iio.image_write(wavg, wavgfn)\n        xavg = apply_transforms( xavg, xavg, wavgfn )\n\n    return xavg"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfitting the interface to the set of images and labels.", "response": "def fit(self, X, y=None):\n        \"\"\"\n        X : ANTsImage | string | list of ANTsImage types | list of strings\n            images to register to fixed image\n\n        y : string | list of strings\n            labels for images\n        \"\"\"\n        moving_images = X if isinstance(X, (list,tuple)) else [X]\n        moving_labels = y if y is not None else [i for i in range(len(moving_images))]\n        fixed_image = self.fixed_image\n\n        self.fwdtransforms_ = {}\n        self.invtransforms_ = {}\n        self.warpedmovout_ = {}\n        self.warpedfixout_ = {}\n        \n        for moving_image, moving_label in zip(moving_images, moving_labels):\n            fit_result = interface.registration(fixed_image,\n                                                moving_image,\n                                                type_of_transform=self.type_of_transform,\n                                                initial_transform=None,\n                                                outprefix='',\n                                                mask=None,\n                                                grad_step=0.2,\n                                                flow_sigma=3,\n                                                total_sigma=0,\n                                                aff_metric='mattes',\n                                                aff_sampling=32,\n                                                syn_metric='mattes',\n                                                syn_sampling=32,\n                                                reg_iterations=(40,20,0),\n                                                verbose=False)\n\n            self.fwdtransforms_[moving_label] = fit_result['fwdtransforms']\n            self.invtransforms_[moving_label] = fit_result['invtransforms']\n            self.warpedmovout_[moving_label]  = fit_result['warpedmovout']\n            self.warpedfixout_[moving_label]  = fit_result['warpedfixout']\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef joint_label_fusion(target_image, target_image_mask, atlas_list, beta=4, rad=2,\n                        label_list=None, rho=0.01, usecor=False, r_search=3,\n                        nonnegative=False, verbose=False):\n    \"\"\"\n    A multiple atlas voting scheme to customize labels for a new subject.\n    This function will also perform intensity fusion. It almost directly\n    calls the C++ in the ANTs executable so is much faster than other\n    variants in ANTsR.\n\n    One may want to normalize image intensities for each input image before\n    passing to this function. If no labels are passed, we do intensity fusion.\n    Note on computation time: the underlying C++ is multithreaded.\n    You can control the number of threads by setting the environment\n    variable ITK_GLOBAL_DEFAULT_NUMBER_OF_THREADS e.g. to use all or some\n    of your CPUs. This will improve performance substantially.\n    For instance, on a macbook pro from 2015, 8 cores improves speed by about 4x.\n\n    ANTsR function: `jointLabelFusion`\n\n    Arguments\n    ---------\n    target_image : ANTsImage\n        image to be approximated\n\n    target_image_mask : ANTsImage\n        mask with value 1\n\n    atlas_list : list of ANTsImage types\n        list containing intensity images\n\n    beta : scalar\n        weight sharpness, default to 2\n\n    rad : scalar\n        neighborhood radius, default to 2\n\n    label_list : list of ANTsImage types (optional)\n        list containing images with segmentation labels\n\n    rho : scalar\n        ridge penalty increases robustness to outliers but also makes image converge to average\n\n    usecor : boolean\n        employ correlation as local similarity\n\n    r_search : scalar\n        radius of search, default is 3\n\n    nonnegative : boolean\n        constrain weights to be non-negative\n\n    verbose : boolean\n        whether to show status updates\n\n    Returns\n    -------\n    dictionary w/ following key/value pairs:\n        `segmentation` : ANTsImage\n            segmentation image\n\n        `intensity` : ANTsImage\n            intensity image\n\n        `probabilityimages` : list of ANTsImage types\n            probability map image for each label\n\n    Example\n    -------\n    >>> import ants\n    >>> ref = ants.image_read( ants.get_ants_data('r16'))\n    >>> ref = ants.resample_image(ref, (50,50),1,0)\n    >>> ref = ants.iMath(ref,'Normalize')\n    >>> mi = ants.image_read( ants.get_ants_data('r27'))\n    >>> mi2 = ants.image_read( ants.get_ants_data('r30'))\n    >>> mi3 = ants.image_read( ants.get_ants_data('r62'))\n    >>> mi4 = ants.image_read( ants.get_ants_data('r64'))\n    >>> mi5 = ants.image_read( ants.get_ants_data('r85'))\n    >>> refmask = ants.get_mask(ref)\n    >>> refmask = ants.iMath(refmask,'ME',2) # just to speed things up\n    >>> ilist = [mi,mi2,mi3,mi4,mi5]\n    >>> seglist = [None]*len(ilist)\n    >>> for i in range(len(ilist)):\n    >>>     ilist[i] = ants.iMath(ilist[i],'Normalize')\n    >>>     mytx = ants.registration(fixed=ref , moving=ilist[i] ,\n    >>>         typeofTransform = ('Affine') )\n    >>>     mywarpedimage = ants.apply_transforms(fixed=ref,moving=ilist[i],\n    >>>             transformlist=mytx['fwdtransforms'])\n    >>>     ilist[i] = mywarpedimage\n    >>>     seg = ants.threshold_image(ilist[i],'Otsu', 3)\n    >>>     seglist[i] = ( seg ) + ants.threshold_image( seg, 1, 3 ).morphology( operation='dilate', radius=3 )\n    >>> r = 2\n    >>> pp = ants.joint_label_fusion(ref, refmask, ilist, r_search=2,\n    >>>                     label_list=seglist, rad=[r]*ref.dimension )\n    >>> pp = ants.joint_label_fusion(ref,refmask,ilist, r_search=2, rad=[r]*ref.dimension)\n    \"\"\"\n    segpixtype = 'unsigned int'\n    if (label_list is None) or (np.any([l is None for l in label_list])):\n        doJif = True\n    else:\n        doJif = False\n\n    if not doJif:\n        if len(label_list) != len(atlas_list):\n            raise ValueError('len(label_list) != len(atlas_list)')\n        inlabs = np.sort(np.unique(label_list[0][target_image_mask != 0 ]))\n        mymask = target_image_mask.clone()\n    else:\n        mymask = target_image_mask\n\n    osegfn = mktemp(prefix='antsr', suffix='myseg.nii.gz')\n    #segdir = osegfn.replace(os.path.basename(osegfn),'')\n\n    if os.path.exists(osegfn):\n        os.remove(osegfn)\n\n    probs = mktemp(prefix='antsr', suffix='prob%02d.nii.gz')\n    probsbase = os.path.basename(probs)\n    tdir = probs.replace(probsbase,'')\n    searchpattern = probsbase.replace('%02d', '*')\n\n    mydim = target_image_mask.dimension\n    if not doJif:\n        # not sure if these should be allocated or what their size should be\n        outimg = label_list[1].clone(segpixtype)\n        outimgi = target_image * 0\n\n        outimg_ptr = utils.get_pointer_string(outimg)\n        outimgi_ptr = utils.get_pointer_string(outimgi)\n        outs = '[%s,%s,%s]' % (outimg_ptr, outimgi_ptr, probs)\n    else:\n        outimgi = target_image * 0\n        outs = utils.get_pointer_string(outimgi)\n\n    mymask = mymask.clone(segpixtype)\n    if (not isinstance(rad, (tuple,list))) or (len(rad)==1):\n        myrad = [rad] * mydim\n    else:\n        myrad = rad\n\n    if len(myrad) != mydim:\n        raise ValueError('path radius dimensionality must equal image dimensionality')\n\n    myrad = 'x'.join([str(mr) for mr in myrad])\n    vnum = 1 if verbose else 0\n    nnum = 1 if nonnegative else 0\n\n    myargs = {\n        'd': mydim,\n        't': target_image,\n        'a': rho,\n        'b': beta,\n        'c': nnum,\n        'p': myrad,\n        'm': 'PC',\n        's': r_search,\n        'x': mymask,\n        'o': outs,\n        'v': vnum\n    }\n\n    kct = len(myargs.keys())\n    for k in range(len(atlas_list)):\n        kct += 1\n        myargs['g-MULTINAME-%i' % kct] = atlas_list[k]\n        if not doJif:\n            kct += 1\n            castseg = label_list[k].clone(segpixtype)\n            myargs['l-MULTINAME-%i' % kct] = castseg\n\n    myprocessedargs = utils._int_antsProcessArguments(myargs)\n\n    libfn = utils.get_lib_fn('antsJointFusion')\n    rval = libfn(myprocessedargs)\n    if rval != 0:\n        print('Warning: Non-zero return from antsJointFusion')\n\n    if doJif:\n        return outimgi\n\n    probsout = glob.glob(os.path.join(tdir,'*'+searchpattern ) )\n    probsout.sort()\n    probimgs = [iio2.image_read(probsout[0])]\n    for idx in range(1, len(probsout)):\n        probimgs.append(iio2.image_read(probsout[idx]))\n\n    segmat = iio2.images_to_matrix( probimgs, target_image_mask )\n    finalsegvec = segmat.argmax( axis = 0 )\n    finalsegvec2 = finalsegvec.copy()\n    # mapfinalsegvec to original labels\n    for i in range(finalsegvec.max()+1):\n        finalsegvec2[finalsegvec==i] = inlabs[i]\n    outimg = iio2.make_image( target_image_mask, finalsegvec2 )\n\n    return {\n        'segmentation': outimg,\n        'intensity': outimgi,\n        'probabilityimages': probimgs\n    }", "response": "This function is used to customize the label of a new subject by using the joint label Fusion function. It will also customize the label of a new subject by using the intensity fusion function."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a tiled mosaic of 2D slice images from a 3D ANTsImage. ANTsR function : N/A ANTs function : `createTiledMosaic` Arguments --------- image : ANTsImage base image to visualize rgb : ANTsImage optional overlay image to display on top of base image mask : ANTsImage optional mask image alpha : float alpha value for rgb/overlay image direction : integer or string which axis to visualize options: 0, 1, 2, 'x', 'y', 'z' pad_or_crop : list of 2-tuples padding or cropping values for each dimension and each side. - to crop the X dimension, use the following: pad_or_crop = [(10,10), 0, 0] - to pad the X dimension, use the following: pad_or_crop = [(-10,-10), 0, 0] slices : list/numpy.ndarray or integer or 3-tuple if list or numpy.ndarray: slices to use if integer: number of slices to incremenet if 3-tuple: (# slices to increment, min slice, max slice) flip_slice : 2-tuple of boolean (whether to flip X direction, whether to flip Y direction) permute_axes : boolean whether to permute axes output : string output filename where mosaic image will be saved. If not given, this function will save to a temp file, then return the image as a PIL.Image object ANTs ---- -i, --input-image inputImageFilename -r, --rgb-image rgbImageFilename -x, --mask-image maskImageFilename -a, --alpha value -e, --functional-overlay [rgbImageFileName,maskImageFileName,<alpha=1>] -o, --output tiledMosaicImage -t, --tile-geometry RxC -d, --direction 0/1/2/x/y/(z) -p, --pad-or-crop padVoxelWidth [padVoxelWidth,<constantValue=0>] [lowerPadding[0]xlowerPadding[1],upperPadding[0]xupperPadding[1],constantValue] -s, --slices Slice1xSlice2xSlice3... numberOfSlicesToIncrement [numberOfSlicesToIncrement,<minSlice=0>,<maxSlice=lastSlice>] -f, --flip-slice flipXxflipY -g, --permute-axes doPermute -h CreateTiledMosaic -i OAS1_0457_MR1_mpr_n3_anon_sbj_111BrainSegmentation0N4 . nii . gz \\ -r OAS1_0457_MR1_mpr_n3_anon_sbj_111CorticalThickness_hot . nii . gz \\ -x OAS1_0457_MR1_mpr_n3_anon_sbj_111CorticalThickness_mask . nii . gz \\ -o OAS1_0457_MR1_mpr_n3_anon_sbj_111_tiledMosaic . png \\ -a 1.0 -t -1 x8 -d 2 -p [ -15x -50 , -15x -30 ,0] -s [2 ,100 ,160] Example ------- >>> import ants >>> image = ants.image_read(ants.get_ants_data('ch2')) >>> plt = ants.create_tiled_mosaic(image)", "response": "def create_tiled_mosaic(image, rgb=None, mask=None, overlay=None,\n                        output=None, alpha=1., direction=0, \n                        pad_or_crop=None, slices=None,\n                        flip_slice=None, permute_axes=False):\n    \"\"\"\n    Create a tiled mosaic of 2D slice images from a 3D ANTsImage.\n    \n    ANTsR function : N/A\n    ANTs function  : `createTiledMosaic`\n\n    Arguments\n    ---------\n    image : ANTsImage\n        base image to visualize\n\n    rgb : ANTsImage\n        optional overlay image to display on top of base image\n\n    mask : ANTsImage\n        optional mask image\n\n    alpha : float\n        alpha value for rgb/overlay image\n\n    direction : integer or string\n        which axis to visualize\n        options: 0, 1, 2, 'x', 'y', 'z'\n\n    pad_or_crop : list of 2-tuples\n        padding or cropping values for each dimension and each side.\n        - to crop the X dimension, use the following:\n            pad_or_crop = [(10,10), 0, 0]\n        - to pad the X dimension, use the following:\n            pad_or_crop = [(-10,-10), 0, 0]\n\n    slices : list/numpy.ndarray or integer or 3-tuple\n        if list or numpy.ndarray:\n            slices to use\n        if integer:\n            number of slices to incremenet\n        if 3-tuple:\n            (# slices to increment, min slice, max slice)\n    \n    flip_slice : 2-tuple of boolean\n        (whether to flip X direction, whether to flip Y direction)\n    \n    permute_axes : boolean\n        whether to permute axes\n\n    output : string\n        output filename where mosaic image will be saved.\n        If not given, this function will save to a temp file,\n        then return the image as a PIL.Image object\n    \n    ANTs\n    ----\n     -i, --input-image inputImageFilename\n     -r, --rgb-image rgbImageFilename\n     -x, --mask-image maskImageFilename\n     -a, --alpha value\n     -e, --functional-overlay [rgbImageFileName,maskImageFileName,<alpha=1>]\n     -o, --output tiledMosaicImage\n     -t, --tile-geometry RxC\n     -d, --direction 0/1/2/x/y/(z)\n     -p, --pad-or-crop padVoxelWidth\n                       [padVoxelWidth,<constantValue=0>]\n                       [lowerPadding[0]xlowerPadding[1],upperPadding[0]xupperPadding[1],constantValue]\n     -s, --slices Slice1xSlice2xSlice3...\n                  numberOfSlicesToIncrement\n                  [numberOfSlicesToIncrement,<minSlice=0>,<maxSlice=lastSlice>]\n     -f, --flip-slice flipXxflipY\n     -g, --permute-axes doPermute\n     -h \n\n    CreateTiledMosaic -i OAS1_0457_MR1_mpr_n3_anon_sbj_111BrainSegmentation0N4 . nii . gz \\\n    -r OAS1_0457_MR1_mpr_n3_anon_sbj_111CorticalThickness_hot . nii . gz \\\n    -x OAS1_0457_MR1_mpr_n3_anon_sbj_111CorticalThickness_mask . nii . gz \\\n    -o OAS1_0457_MR1_mpr_n3_anon_sbj_111_tiledMosaic . png \\\n    -a 1.0 -t -1 x8 -d 2 -p [ -15x -50 , -15x -30 ,0] -s [2 ,100 ,160]\n\n    Example\n    -------\n    >>> import ants\n    >>> image = ants.image_read(ants.get_ants_data('ch2'))\n    >>> plt = ants.create_tiled_mosaic(image)\n    \"\"\"\n    # image needs to be unsigned char\n    if image.pixeltype != 'unsigned char':\n        # transform between 0 and 255.\n        image = (image - image.max()) / (image.max() - image.min())\n        image = image * 255.\n        image = image.clone('unsigned char')\n    \n    output_is_temp = False\n    if output is None:\n        output_is_temp = True\n        output = mktemp(suffix='.jpg')\n\n    if rgb is None:\n        rgb = image.clone()\n\n\n    imagepath = mktemp(suffix='.nii.gz')\n    iio2.image_write(image, imagepath)\n    rgbpath = mktemp(suffix='.nii.gz')\n    iio2.image_write(rgb, rgbpath)\n    args = {\n        'i': imagepath,\n        'r': rgbpath,\n        'o': output\n    }\n\n    processed_args = utils._int_antsProcessArguments(args)\n    libfn = utils.get_lib_fn('CreateTiledMosaic')\n    \n    libfn(processed_args)\n\n    outimage = Image.open(output)\n    if output_is_temp:\n        os.remove(output)\n    return outimage"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nimpute missing values on a numpy ndarray in a column - wise manner.", "response": "def impute(data, method='mean', value=None, nan_value=np.nan):\n    \"\"\"\n    Impute missing values on a numpy ndarray in a column-wise manner.\n    \n    ANTsR function: `antsrimpute`\n\n    Arguments\n    ---------\n    data : numpy.ndarray\n        data to impute\n\n    method : string or float\n        type of imputation method to use\n        Options:\n            mean\n            median\n            constant\n            KNN\n            BiScaler\n            NuclearNormMinimization\n            SoftImpute\n            IterativeSVD\n\n    value : scalar (optional)\n        optional arguments for different methods\n        if method == 'constant'\n            constant value\n        if method == 'KNN'\n            number of nearest neighbors to use\n\n    nan_value : scalar\n        value which is interpreted as a missing value\n\n    Returns\n    -------\n    ndarray if ndarray was given\n    OR\n    pd.DataFrame if pd.DataFrame was given\n\n    Example\n    -------\n    >>> import ants\n    >>> import numpy as np\n    >>> data = np.random.randn(4,10)\n    >>> data[2,3] = np.nan\n    >>> data[3,5] = np.nan\n    >>> data_imputed = ants.impute(data, 'mean')\n\n    Details\n    -------\n    KNN: Nearest neighbor imputations which weights samples using the mean squared \n            difference on features for which two rows both have observed data.\n\n    SoftImpute: Matrix completion by iterative soft thresholding of SVD \n                decompositions. Inspired by the softImpute package for R, which \n                is based on Spectral Regularization Algorithms for Learning \n                Large Incomplete Matrices by Mazumder et. al.\n\n    IterativeSVD: Matrix completion by iterative low-rank SVD decomposition.\n                    Should be similar to SVDimpute from Missing value estimation \n                    methods for DNA microarrays by Troyanskaya et. al.\n\n    MICE: Reimplementation of Multiple Imputation by Chained Equations.\n\n    MatrixFactorization: Direct factorization of the incomplete matrix into \n                        low-rank U and V, with an L1 sparsity penalty on the elements \n                        of U and an L2 penalty on the elements of V. \n                        Solved by gradient descent.\n\n    NuclearNormMinimization: Simple implementation of Exact Matrix Completion \n                            via Convex Optimization by Emmanuel Candes and Benjamin \n                            Recht using cvxpy. Too slow for large matrices.\n\n    BiScaler: Iterative estimation of row/column means and standard deviations \n                to get doubly normalized matrix. Not guaranteed to converge but \n                works well in practice. Taken from Matrix Completion and \n                Low-Rank SVD via Fast Alternating Least Squares.\n    \"\"\"\n    _fancyimpute_options = {'KNN', 'BiScaler', 'NuclearNormMinimization', 'SoftImpute', 'IterativeSVD'}\n    if (not has_fancyimpute) and (method in _fancyimpute_options):\n        raise ValueError('You must install `fancyimpute` (pip install fancyimpute) to use this method')\n\n    _base_options = {'mean', 'median', 'constant'}\n    if (method not in _base_options) and (method not in _fancyimpute_options) and (not isinstance(method, (int,float))):\n        raise ValueError('method not understood.. Use `mean`, `median`, a scalar, or an option from `fancyimpute`')\n\n    X_incomplete = data.copy()\n\n    if method == 'KNN':\n        if value is None:\n            value = 3\n        X_filled = KNN(k=value, verbose=False).complete(X_incomplete)\n\n    elif method == 'BiScaler':\n        X_filled = BiScaler(verbose=False).fit_transform(X_incomplete)\n\n    elif method == 'SoftImpute':\n        X_filled = SoftImpute(verbose=False).complete(X_incomplete)\n\n    elif method == 'IterativeSVD':\n        if value is None:\n            rank = min(10, X_incomplete.shape[0]-2)\n        else:\n            rank = value\n        X_filled = IterativeSVD(rank=rank, verbose=False).complete(X_incomplete)\n\n    elif method == 'mean':\n        col_means = np.nanmean(X_incomplete, axis=0)\n        for i in range(X_incomplete.shape[1]):\n            X_incomplete[:,i][np.isnan(X_incomplete[:,i])] = col_means[i]\n        X_filled = X_incomplete\n\n    elif method == 'median':\n        col_means = np.nanmean(X_incomplete, axis=0)\n        for i in range(X_incomplete.shape[1]):\n            X_incomplete[:,i][np.isnan(X_incomplete[:,i])] = col_means[i]\n        X_filled = X_incomplete\n\n    elif method == 'constant':\n        if value is None:\n            raise ValueError('Must give `value` argument if method == constant')\n        X_incomplete[np.isnan(X_incomplete)] = value\n        X_filled = X_incomplete\n\n    return X_filled"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef resample_image(image, resample_params, use_voxels=False, interp_type=1):\n    if image.components == 1:\n        inimage = image.clone('float')\n        outimage = image.clone('float')\n        rsampar = 'x'.join([str(rp) for rp in resample_params])\n\n        args = [image.dimension, inimage, outimage, rsampar, int(use_voxels), interp_type]\n        processed_args = utils._int_antsProcessArguments(args)\n        libfn = utils.get_lib_fn('ResampleImage')\n        libfn(processed_args)\n        outimage = outimage.clone(image.pixeltype)\n        return outimage\n    else:\n        raise ValueError('images with more than 1 component not currently supported')", "response": "Resample image by spacing or number of voxels with \n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef resample_image_to_target(image, target, interp_type='linear', imagetype=0, verbose=False, **kwargs):\n    fixed = target\n    moving = image\n    compose = None\n    transformlist = 'identity'\n    interpolator = interp_type\n\n    interpolator_oldoptions = (\"linear\", \"nearestNeighbor\", \"gaussian\", \"cosineWindowedSinc\", \"bSpline\")\n    if isinstance(interp_type, int):\n        interpolator = interpolator_oldoptions[interp_type]\n\n    accepted_interpolators = {\"linear\", \"nearestNeighbor\", \"multiLabel\", \"gaussian\",\n                        \"bSpline\", \"cosineWindowedSinc\", \"welchWindowedSinc\",\n                        \"hammingWindowedSinc\", \"lanczosWindowedSinc\", \"genericLabel\"}\n\n    if interpolator not in accepted_interpolators:\n        raise ValueError('interpolator not supported - see %s' % accepted_interpolators)\n\n    args = [fixed, moving, transformlist, interpolator]\n\n    if not isinstance(fixed, str):\n        if isinstance(fixed, iio.ANTsImage) and isinstance(moving, iio.ANTsImage):\n            inpixeltype = fixed.pixeltype\n            warpedmovout = moving.clone()\n            f = fixed\n            m = moving\n            if (moving.dimension == 4) and (fixed.dimension==3) and (imagetype==0):\n                raise ValueError('Set imagetype 3 to transform time series images.')\n\n            wmo = warpedmovout\n            mytx = ['-t', 'identity']\n            if compose is None:\n                args = ['-d', fixed.dimension, '-i', m, '-o', wmo, '-r', f, '-n', interpolator] + mytx\n\n            tfn = '%scomptx.nii.gz' % compose if compose is not None else 'NA'\n            if compose is not None:\n                mycompo = '[%s,1]' % tfn\n                args = ['-d', fixed.dimension, '-i', m, '-o', mycompo, '-r', f, '-n', interpolator] + mytx\n\n            myargs = utils._int_antsProcessArguments(args)\n\n            # NO CLUE WHAT THIS DOES OR WHY IT'S NEEDED\n            for jj in range(len(myargs)):\n                if myargs[jj] is not None:\n                    if myargs[jj] == '-':\n                        myargs2 = [None]*(len(myargs)-1)\n                        myargs2[:(jj-1)] = myargs[:(jj-1)]\n                        myargs2[jj:(len(myargs)-1)] = myargs[(jj+1):(len(myargs))]\n                        myargs = myargs2\n\n            myverb = int(verbose)\n\n            processed_args = myargs + ['-z', str(1), '-v', str(myverb), '--float', str(1), '-e', str(imagetype)]\n            libfn = utils.get_lib_fn('antsApplyTransforms')\n            libfn(processed_args)\n\n            if compose is None:\n                return warpedmovout.clone(inpixeltype)\n            else:\n                if os.path.exists(tfn):\n                    return tfn\n                else:\n                    return None\n        else:\n            return 1\n    else:\n        processed_args = myargs + ['-z', str(1), '--float', str(1), '-e', str(imagetype)]\n        libfn = utils.get_lib_fn('antsApplyTransforms')\n        libfn(processed_args)", "response": "Resample an image to another image."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef apply_ants_transform(transform, data, data_type=\"point\", reference=None, **kwargs):\n    return transform.apply(data, data_type, reference, **kwargs)", "response": "Apply ANTsTransform to data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\napplying an ants transform to an image", "response": "def apply_ants_transform_to_image(transform, image, reference, interpolation='linear'):\n    \"\"\"\n    Apply transform to an image\n\n    ANTsR function: `applyAntsrTransformToImage`\n\n    Arguments\n    ---------\n    image : ANTsImage\n        image to which the transform will be applied\n\n    reference : ANTsImage\n        reference image\n\n    interpolation : string\n        type of interpolation to use\n\n    Returns\n    -------\n    list : transformed vector\n\n    Example\n    -------\n    >>> import ants\n    >>> img = ants.image_read(ants.get_ants_data(\"r16\")).clone('float')\n    >>> tx = ants.new_ants_transform(dimension=2)\n    >>> tx.set_parameters((0.9,0,0,1.1,10,11))\n    >>> img2 = tx.apply_to_image(img, img)\n    \"\"\"\n    return transform.apply_to_image(image, reference, interpolation)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef compose_ants_transforms(transform_list):\n    precision = transform_list[0].precision\n    dimension = transform_list[0].dimension\n\n    for tx in transform_list:\n        if precision != tx.precision:\n            raise ValueError('All transforms must have the same precision')\n        if dimension != tx.dimension:\n            raise ValueError('All transforms must have the same dimension')\n\n    tx_ptr_list = list(reversed([tf.pointer for tf in transform_list]))\n    libfn = utils.get_lib_fn('composeTransforms%s' % (transform_list[0]._libsuffix))\n    itk_composed_tx = libfn(tx_ptr_list, precision, dimension)\n    return ANTsTransform(precision=precision, dimension=dimension,\n                        transform_type='CompositeTransform', pointer=itk_composed_tx)", "response": "Compose multiple ANTsTransform s together\n    ANTsR function"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a new ANTsImage with spatial point transformed from index of an image.", "response": "def transform_index_to_physical_point(image, index):\n    \"\"\"\n    Get spatial point from index of an image.\n\n    ANTsR function: `antsTransformIndexToPhysicalPoint`\n\n    Arguments\n    ---------\n    img : ANTsImage\n        image to get values from\n\n    index : list or tuple or numpy.ndarray\n        location in image\n\n    Returns\n    -------\n    tuple\n\n    Example\n    -------\n    >>> import ants\n    >>> import numpy as np\n    >>> img = ants.make_image((10,10),np.random.randn(100))\n    >>> pt = ants.transform_index_to_physical_point(img, (2,2))\n    \"\"\"\n    if not isinstance(image, iio.ANTsImage):\n        raise ValueError('image must be ANTsImage type')\n\n    if isinstance(index, np.ndarray):\n        index = index.tolist()\n\n    if not isinstance(index, (tuple,list)):\n        raise ValueError('index must be tuple or list')\n\n    if len(index) != image.dimension:\n        raise ValueError('len(index) != image.dimension')\n\n    index = [i+1 for i in index]\n    ndim = image.dimension\n    ptype = image.pixeltype\n    libfn = utils.get_lib_fn('TransformIndexToPhysicalPoint%s%i' % (utils.short_ptype(ptype), ndim))\n    point = libfn(image.pointer, [list(index)])\n\n    return np.array(point[0])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parameters(self):\n        libfn = utils.get_lib_fn('getTransformParameters%s'%self._libsuffix)\n        return np.asarray(libfn(self.pointer), order='F')", "response": "Get the parameters of the transform"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the parameters of the transform.", "response": "def set_parameters(self, parameters):\n        \"\"\" Set parameters of transform \"\"\"\n        if not isinstance(parameters, np.ndarray):\n            parameters = np.asarray(parameters)\n\n        # if in two dimensions, flatten with fortran ordering\n        if parameters.ndim > 1:\n            parameters = parameters.flatten(order='F')\n\n        libfn = utils.get_lib_fn('setTransformParameters%s'%self._libsuffix)\n        libfn(self.pointer, parameters.tolist())"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fixed_parameters(self):\n        libfn = utils.get_lib_fn('getTransformFixedParameters%s'%self._libsuffix)\n        return np.asarray(libfn(self.pointer))", "response": "Get the fixed parameters of the transform"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the fixed parameters of the transform", "response": "def set_fixed_parameters(self, parameters):\n        \"\"\" Set parameters of transform \"\"\"\n        if not isinstance(parameters, np.ndarray):\n            parameters = np.asarray(parameters)\n\n        libfn = utils.get_lib_fn('setTransformFixedParameters%s'%self._libsuffix)\n        libfn(self.pointer, parameters.tolist())"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\napplies transform to data", "response": "def apply(self, data, data_type='point', reference=None, **kwargs):\n        \"\"\"\n        Apply transform to data\n\n        \"\"\"\n        if data_type == 'point':\n            return self.apply_to_point(data)\n        elif data_type == 'vector':\n            return self.apply_to_vector(data)\n        elif data_type == 'image':\n            return self.apply_to_image(data, reference, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\napplying a transform to a point", "response": "def apply_to_point(self, point):\n        \"\"\"\n        Apply transform to a point\n\n        Arguments\n        ---------\n        point : list/tuple\n            point to which the transform will be applied\n\n        Returns\n        -------\n        list : transformed point\n\n        Example\n        -------\n        >>> import ants\n        >>> tx = ants.new_ants_transform()\n        >>> params = tx.parameters\n        >>> tx.set_parameters(params*2)\n        >>> pt2 = tx.apply_to_point((1,2,3)) # should be (2,4,6)\n        \"\"\"\n        libfn = utils.get_lib_fn('transformPoint%s' % (self._libsuffix))\n        return tuple(libfn(self.pointer, point))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef apply_to_vector(self, vector):\n        if isinstance(vector, np.ndarray):\n            vector = vector.tolist()\n\n        libfn = utils.get_lib_fn('transformVector%s' % (self._libsuffix))\n        return np.asarray(libfn(self.pointer, vector))", "response": "Applies a transform to a list of unique items"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef apply_to_image(self, image, reference=None, interpolation='linear'):\n        if reference is None:\n            reference = image.clone()\n\n        tform_fn = utils.get_lib_fn('transformImage%s%s' % (self._libsuffix, image._libsuffix))\n        reference = reference.clone(image.pixeltype)\n\n        img_ptr = tform_fn(self.pointer, image.pointer, reference.pointer, interpolation)\n        return iio.ANTsImage(pixeltype=image.pixeltype,\n                            dimension=image.dimension,\n                            components=image.components,\n                            pointer=img_ptr)", "response": "Applies the transform to an image and returns a list of transformed ANTsImage objects"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates and save a movie - mp4 gif etc - of the various ants image", "response": "def movie(image, filename=None, writer=None, fps=30):\n    \"\"\"\n    Create and save a movie - mp4, gif, etc - of the various\n    2D slices of a 3D ants image\n    \n    Try this:\n        conda install -c conda-forge ffmpeg\n\n    Example\n    -------\n    >>> import ants\n    >>> mni = ants.image_read(ants.get_data('mni'))\n    >>> ants.movie(mni, filename='~/desktop/movie.mp4')\n    \"\"\"\n\n    image = image.pad_image()\n    img_arr = image.numpy()\n\n    minidx = max(0, np.where(image > 0)[0][0] - 5)\n    maxidx = max(image.shape[0], np.where(image > 0)[0][-1] + 5)\n\n    # Creare your figure and axes\n    fig, ax = plt.subplots(1)\n\n    im = ax.imshow(img_arr[minidx,:,:], animated=True, \n        cmap='Greys_r', vmin=image.quantile(0.05), vmax=image.quantile(0.95))\n\n    ax.axis('off')\n\n    def init():\n        fig.axes('off')\n        return im,\n\n    def updatefig(frame):\n        im.set_array(img_arr[frame,:,:])\n        return im,\n\n    ani = animation.FuncAnimation(fig, updatefig, frames=np.arange(minidx,maxidx),\n                                  #init_func=init, \n                                  interval=50, blit=True)\n\n    if writer is None:\n        writer = animation.FFMpegWriter(fps=fps)\n\n    if filename is not None:\n        filename = os.path.expanduser(filename)\n        ani.save(filename, writer=writer)\n    else:\n        plt.show()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plot_hist(image, threshold=0., fit_line=False, normfreq=True,\n    ## plot label arguments\n    title=None, grid=True, xlabel=None, ylabel=None,\n    ## other plot arguments\n    facecolor='green', alpha=0.75):\n    \"\"\"\n    Plot a histogram from an ANTsImage\n\n    Arguments\n    ---------\n    image : ANTsImage\n        image from which histogram will be created\n    \"\"\"\n    img_arr = image.numpy().flatten()\n    img_arr = img_arr[np.abs(img_arr) > threshold]\n\n    if normfreq != False:\n        normfreq = 1. if normfreq == True else normfreq\n    n, bins, patches = plt.hist(img_arr, 50, normed=normfreq, facecolor=facecolor, alpha=alpha)\n\n    if fit_line:\n        # add a 'best fit' line\n        y = mlab.normpdf( bins, img_arr.mean(), img_arr.std())\n        l = plt.plot(bins, y, 'r--', linewidth=1)\n\n    if xlabel is not None:\n        plt.xlabel(xlabel)\n    if ylabel is not None:\n        plt.ylabel(ylabel)\n    if title is not None:\n        plt.title(title)\n\n    plt.grid(grid)\n    plt.show()", "response": "Plots a histogram from an ANTsImage object"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plot_grid(images, slices=None, axes=2, \n    # general figure arguments\n    figsize=1., rpad=0, cpad=0,\n    # title arguments\n    title=None, tfontsize=20, title_dx=0, title_dy=0,\n    # row arguments\n    rlabels=None, rfontsize=14, rfontcolor='white', rfacecolor='black', \n    # column arguments \n    clabels=None, cfontsize=14, cfontcolor='white', cfacecolor='black',\n    # save arguments\n    filename=None, dpi=400, transparent=True,\n    # other args\n    **kwargs):\n    \"\"\"\n    Plot a collection of images in an arbitrarily-defined grid\n    \n    Matplotlib named colors: https://matplotlib.org/examples/color/named_colors.html\n\n    Arguments\n    ---------\n    images : list of ANTsImage types\n        image(s) to plot.\n        if one image, this image will be used for all grid locations.\n        if multiple images, they should be arrange in a list the same\n        shape as the `gridsize` argument.\n\n    slices : integer or list of integers\n        slice indices to plot\n        if one integer, this slice index will be used for all images\n        if multiple integers, they should be arranged in a list the same\n        shape as the `gridsize` argument\n\n    axes : integer or list of integers\n        axis or axes along which to plot image slices\n        if one integer, this axis will be used for all images\n        if multiple integers, they should be arranged in a list the same\n        shape as the `gridsize` argument\n\n    Example\n    -------\n    >>> import ants\n    >>> import numpy as np\n    >>> mni1 = ants.image_read(ants.get_data('mni'))\n    >>> mni2 = mni1.smooth_image(1.)\n    >>> mni3 = mni1.smooth_image(2.)\n    >>> mni4 = mni1.smooth_image(3.)\n    >>> images = np.asarray([[mni1, mni2],\n    ...                      [mni3, mni4]])\n    >>> slices = np.asarray([[100, 100],\n    ...                      [100, 100]])\n    >>> #axes = np.asarray([[2,2],[2,2]])\n    >>> # standard plotting\n    >>> ants.plot_grid(images=images, slices=slices, title='2x2 Grid')\n    >>> ants.plot_grid(images.reshape(1,4), slices.reshape(1,4), title='1x4 Grid')\n    >>> ants.plot_grid(images.reshape(4,1), slices.reshape(4,1), title='4x1 Grid')\n\n    >>> # Padding between rows and/or columns\n    >>> ants.plot_grid(images, slices, cpad=0.02, title='Col Padding')\n    >>> ants.plot_grid(images, slices, rpad=0.02, title='Row Padding')\n    >>> ants.plot_grid(images, slices, rpad=0.02, cpad=0.02, title='Row and Col Padding')\n\n    >>> # Adding plain row and/or column labels \n    >>> ants.plot_grid(images, slices, title='Adding Row Labels', rlabels=['Row #1', 'Row #2'])\n    >>> ants.plot_grid(images, slices, title='Adding Col Labels', clabels=['Col #1', 'Col #2'])\n    >>> ants.plot_grid(images, slices, title='Row and Col Labels',\n                       rlabels=['Row 1', 'Row 2'], clabels=['Col 1', 'Col 2'])\n\n    >>> # Making a publication-quality image \n    >>> images = np.asarray([[mni1, mni2, mni2],\n    ...                      [mni3, mni4, mni4]])\n    >>> slices = np.asarray([[100, 100, 100],\n    ...                      [100, 100, 100]])\n    >>> axes = np.asarray([[0, 1, 2],\n                           [0, 1, 2]])\n    >>> ants.plot_grid(images, slices, axes, title='Publication Figures with ANTsPy',\n                       tfontsize=20, title_dy=0.03, title_dx=-0.04,\n                       rlabels=['Row 1', 'Row 2'], clabels=['Col 1', 'Col 2', 'Col 3'],\n                       rfontsize=16, cfontsize=16)\n    \"\"\"\n    def mirror_matrix(x):\n        return x[::-1,:]\n    def rotate270_matrix(x):\n        return mirror_matrix(x.T)\n    def rotate180_matrix(x):\n        return x[::-1,:]\n    def rotate90_matrix(x):\n        return mirror_matrix(x).T\n    def flip_matrix(x):\n        return mirror_matrix(rotate180_matrix(x))\n    def reorient_slice(x, axis):\n        if (axis != 1):\n            x = rotate90_matrix(x)\n        if (axis == 1):\n            x = rotate90_matrix(x)\n        x = mirror_matrix(x)\n        return x\n    def slice_image(img, axis, idx):\n        if axis == 0:\n            return img[idx,:,:]\n        elif axis == 1:\n            return img[:,idx,:]\n        elif axis == 2:\n            return img[:,:,idx]\n        elif axis == -1:\n            return img[:,:,idx]\n        elif axis == -2:\n            return img[:,idx,:]\n        elif axis == -3:\n            return img[idx,:,:]\n        else:\n            raise ValueError('axis %i not valid' % axis)\n\n    if isinstance(images, np.ndarray):\n        images = images.tolist()\n    if not isinstance(images, list):\n        raise ValueError('images argument must be of type list')\n    if not isinstance(images[0], list):\n        images = [images]\n\n    if isinstance(slices, int):\n        one_slice = True\n    if isinstance(slices, np.ndarray):\n        slices = slices.tolist()\n    if isinstance(slices, list):\n        one_slice = False\n        if not isinstance(slices[0], list):\n            slices = [slices]\n        nslicerow = len(slices)\n        nslicecol = len(slices[0])\n    \n    nrow = len(images)\n    ncol = len(images[0])\n\n    if rlabels is None:\n        rlabels = [None]*nrow\n    if clabels is None:\n        clabels = [None]*ncol\n\n    if (not one_slice):\n        if (nrow != nslicerow) or (ncol != nslicecol):\n            raise ValueError('`images` arg shape (%i,%i) must equal `slices` arg shape (%i,%i)!' % (nrow,ncol,nslicerow,nslicecol))\n\n    fig = plt.figure(figsize=((ncol+1)*2.5*figsize, (nrow+1)*2.5*figsize))\n\n    if title is not None:\n        basex = 0.5\n        basey = 0.9 if clabels[0] is None else 0.95\n        fig.suptitle(title, fontsize=tfontsize, x=basex+title_dx, y=basey+title_dy)\n\n    if (cpad > 0) and (rpad > 0):\n        bothgridpad = max(cpad, rpad)\n        cpad = 0\n        rpad = 0\n    else:\n        bothgridpad = 0.0\n\n    gs = gridspec.GridSpec(nrow, ncol, wspace=bothgridpad, hspace=0.0,\n                 top=1.-0.5/(nrow+1), bottom=0.5/(nrow+1) + cpad, \n                 left=0.5/(ncol+1) + rpad, right=1-0.5/(ncol+1))\n\n    for rowidx in range(nrow):\n        for colidx in range(ncol):\n            ax = plt.subplot(gs[rowidx, colidx])\n\n            if colidx == 0:\n                if rlabels[rowidx] is not None:\n                    bottom, height = .25, .5\n                    top = bottom + height\n                    # add label text\n                    ax.text(-0.07, 0.5*(bottom+top), rlabels[rowidx],\n                            horizontalalignment='right', verticalalignment='center',\n                            rotation='vertical', transform=ax.transAxes,\n                            color=rfontcolor, fontsize=rfontsize)\n\n                    # add label background\n                    extra = 0.3 if rowidx == 0 else 0.0\n\n                    rect = patches.Rectangle((-0.3, 0), 0.3, 1.0+extra, \n                        facecolor=rfacecolor,\n                        alpha=1., transform=ax.transAxes, clip_on=False)\n                    ax.add_patch(rect)\n\n            if rowidx == 0:\n                if clabels[colidx] is not None:\n                    bottom, height = .25, .5\n                    left, width = .25, .5\n                    right = left + width\n                    top = bottom + height\n                    ax.text(0.5*(left+right), 0.09+top+bottom, clabels[colidx],\n                            horizontalalignment='center', verticalalignment='center',\n                            rotation='horizontal', transform=ax.transAxes,\n                            color=cfontcolor, fontsize=cfontsize)\n\n                    # add label background\n                    rect = patches.Rectangle((0, 1.), 1.0, 0.3, \n                        facecolor=cfacecolor, \n                        alpha=1., transform=ax.transAxes, clip_on=False)\n                    ax.add_patch(rect)\n\n            tmpimg = images[rowidx][colidx]\n            if isinstance(axes, int):\n                tmpaxis = axes\n            else:\n                tmpaxis = axes[rowidx][colidx]\n            sliceidx = slices[rowidx][colidx] if not one_slice else slices\n            tmpslice = slice_image(tmpimg, tmpaxis, sliceidx)\n            tmpslice = reorient_slice(tmpslice, tmpaxis)\n            ax.imshow(tmpslice, cmap='Greys_r', aspect='auto')\n            ax.axis('off')\n\n    if filename is not None:\n        filename = os.path.expanduser(filename)\n        plt.savefig(filename, dpi=dpi, transparent=transparent, bbox_inches='tight')\n        plt.close(fig)\n    else:\n        plt.show()", "response": "Plots a collection of images in an arbitrarily - defined grid."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nplotting the orthographic stack of images.", "response": "def plot_ortho_stack(images, overlays=None, reorient=True,\n    # xyz arguments\n    xyz=None, xyz_lines=False, xyz_color='red', xyz_alpha=0.6, xyz_linewidth=2, xyz_pad=5,\n    # base image arguments\n    cmap='Greys_r', alpha=1,\n    # overlay arguments\n    overlay_cmap='jet', overlay_alpha=0.9, \n    # background arguments\n    black_bg=True, bg_thresh_quant=0.01, bg_val_quant=0.99, \n    # scale/crop/domain arguments\n    crop=False, scale=False, domain_image_map=None, \n    # title arguments\n    title=None, titlefontsize=24, title_dx=0, title_dy=0, \n    # 4th panel text arguemnts\n    text=None, textfontsize=24, textfontcolor='white', text_dx=0, text_dy=0,\n    # save & size arguments\n    filename=None, dpi=500, figsize=1., colpad=0, rowpad=0,\n    transpose=False, transparent=True):\n    \"\"\"\n    Example\n    -------\n    >>> import ants\n    >>> mni = ants.image_read(ants.get_data('mni'))\n    >>> ch2 = ants.image_read(ants.get_data('ch2'))\n    >>> ants.plot_ortho_stack([mni,mni,mni])\n    \"\"\"\n    def mirror_matrix(x):\n        return x[::-1,:]\n    def rotate270_matrix(x):\n        return mirror_matrix(x.T)\n    def reorient_slice(x, axis):\n        return rotate270_matrix(x)\n\n    # need this hack because of a weird NaN warning from matplotlib with overlays\n    warnings.simplefilter('ignore')\n\n    n_images = len(images)\n\n    # handle `image` argument\n    for i in range(n_images):\n        if isinstance(images[i], str):\n            images[i] = iio2.image_read(images[i])\n        if not isinstance(images[i], iio.ANTsImage):\n            raise ValueError('image argument must be an ANTsImage')\n        if images[i].dimension != 3:\n            raise ValueError('Input image must have 3 dimensions!')\n\n    if overlays is None:\n        overlays = [None]*n_images\n    # handle `overlay` argument\n    for i in range(n_images):\n        if overlays[i] is not None:\n            if isinstance(overlays[i], str):\n                overlays[i] = iio2.image_read(overlays[i])\n            if not isinstance(overlays[i], iio.ANTsImage):\n                raise ValueError('overlay argument must be an ANTsImage')\n            if overlays[i].dimension != 3:\n                raise ValueError('Overlay image must have 3 dimensions!')\n\n            if not iio.image_physical_space_consistency(images[i], overlays[i]):\n                overlays[i] = reg.resample_image_to_target(overlays[i], images[i], interp_type='linear')\n\n    for i in range(1,n_images):\n        if not iio.image_physical_space_consistency(images[0], images[i]):\n            images[i] = reg.resample_image_to_target(images[0], images[i], interp_type='linear')\n\n    # reorient images\n    if reorient != False:\n        if reorient == True:\n            reorient = 'RPI'\n        \n        for i in range(n_images):\n            images[i] = images[i].reorient_image2(reorient)\n        \n        if overlays[i] is not None:\n            overlays[i] = overlays[i].reorient_image2(reorient)\n\n    # handle `slices` argument\n    if xyz is None:\n        xyz = [int(s/2) for s in images[0].shape]\n    for i in range(3):\n        if xyz[i] is None:\n            xyz[i] = int(images[0].shape[i]/2)\n\n    # resample image if spacing is very unbalanced\n    spacing = [s for i,s in enumerate(images[0].spacing)]\n    if (max(spacing) / min(spacing)) > 3.:\n        new_spacing = (1,1,1)\n        for i in range(n_images):\n            images[i] = images[i].resample_image(tuple(new_spacing))\n        if overlays[i] is not None:\n            overlays[i] = overlays[i].resample_image(tuple(new_spacing))\n        xyz = [int(sl*(sold/snew)) for sl,sold,snew in zip(xyz,spacing,new_spacing)]\n\n    # potentially crop image\n    if crop:\n        for i in range(n_images):\n            plotmask = images[i].get_mask(cleanup=0)\n            if plotmask.max() == 0:\n                plotmask += 1\n            images[i] = images[i].crop_image(plotmask)\n            if overlays[i] is not None:\n                overlays[i] = overlays[i].crop_image(plotmask)\n                \n    # pad images\n    for i in range(n_images):\n        if i == 0:\n            images[i], lowpad, uppad = images[i].pad_image(return_padvals=True)\n        else:\n            images[i] = images[i].pad_image()\n        if overlays[i] is not None:\n            overlays[i] = overlays[i].pad_image()\n    xyz = [v+l for v,l in zip(xyz,lowpad)]\n\n    # handle `domain_image_map` argument\n    if domain_image_map is not None:\n        if isinstance(domain_image_map, iio.ANTsImage):\n            tx = tio2.new_ants_transform(precision='float', transform_type='AffineTransform',\n                                         dimension=3)\n            for i in range(n_images):\n                images[i] = tio.apply_ants_transform_to_image(tx, images[i], domain_image_map)\n            \n                if overlays[i] is not None:\n                    overlays[i] = tio.apply_ants_transform_to_image(tx, overlays[i], \n                                                            domain_image_map, \n                                                            interpolation='linear')       \n        elif isinstance(domain_image_map, (list, tuple)):\n            # expect an image and transformation\n            if len(domain_image_map) != 2:\n                raise ValueError('domain_image_map list or tuple must have length == 2')\n            \n            dimg = domain_image_map[0]\n            if not isinstance(dimg, iio.ANTsImage):\n                raise ValueError('domain_image_map first entry should be ANTsImage')\n\n            tx = domain_image_map[1]\n            for i in range(n_images):\n                images[i] = reg.apply_transforms(dimg, images[i], transform_list=tx)\n                if overlays[i] is not None:\n                    overlays[i] = reg.apply_transforms(dimg, overlays[i], transform_list=tx,\n                                                   interpolator='linear')\n\n    # potentially find dynamic range\n    if scale == True:\n        vmins = []\n        vmaxs = []\n        for i in range(n_images):\n            vmin, vmax = images[i].quantile((0.05,0.95))\n            vmins.append(vmin)\n            vmaxs.append(vmax)\n    elif isinstance(scale, (list,tuple)):\n        if len(scale) != 2:\n            raise ValueError('scale argument must be boolean or list/tuple with two values')\n        vmins = []\n        vmaxs = []\n        for i in range(n_images):\n            vmin, vmax = images[i].quantile(scale)\n            vmins.append(vmin)\n            vmaxs.append(vmax)\n    else:\n        vmin = None\n        vmax = None\n\n    if not transpose:\n        nrow = n_images\n        ncol = 3\n    else:\n        nrow = 3\n        ncol = n_images\n\n    fig = plt.figure(figsize=((ncol+1)*2.5*figsize, (nrow+1)*2.5*figsize))\n    if title is not None:\n        basey = 0.93\n        basex = 0.5\n        fig.suptitle(title, fontsize=titlefontsize, x=basex+title_dx, y=basey+title_dy)\n\n    if (colpad > 0) and (rowpad > 0):\n        bothgridpad = max(colpad, rowpad)\n        colpad = 0\n        rowpad = 0\n    else:\n        bothgridpad = 0.0\n\n    gs = gridspec.GridSpec(nrow, ncol, wspace=bothgridpad, hspace=0.0,\n                 top=1.-0.5/(nrow+1), bottom=0.5/(nrow+1) + colpad, \n                 left=0.5/(ncol+1) + rowpad, right=1-0.5/(ncol+1))\n\n    # pad image to have isotropic array dimensions\n    for i in range(n_images):\n        images[i] = images[i].numpy()\n        if overlays[i] is not None:\n            overlays[i] = overlays[i].numpy()\n            overlays[i][np.abs(overlays[i]) == 0] = np.nan\n\n    ####################\n    ####################\n    for i in range(n_images):\n        yz_slice = reorient_slice(images[i][xyz[0],:,:],0)\n        if not transpose:\n            ax = plt.subplot(gs[i,0])\n        else:\n            ax = plt.subplot(gs[0,i])\n        ax.imshow(yz_slice, cmap=cmap, vmin=vmin, vmax=vmax)\n        if overlays[i] is not None:\n            yz_overlay = reorient_slice(overlays[i][xyz[0],:,:],0)\n            ax.imshow(yz_overlay, alpha=overlay_alpha, cmap=overlay_cmap)\n        if xyz_lines:\n            # add lines\n            l = mlines.Line2D([yz_slice.shape[0]-xyz[1],yz_slice.shape[0]-xyz[1]], \n                              [xyz_pad,yz_slice.shape[0]-xyz_pad],\n                              color=xyz_color, alpha=xyz_alpha, linewidth=xyz_linewidth)\n            ax.add_line(l)\n            l = mlines.Line2D([xyz_pad,yz_slice.shape[1]-xyz_pad], \n                              [yz_slice.shape[1]-xyz[2],yz_slice.shape[1]-xyz[2]],\n                color=xyz_color, alpha=xyz_alpha, linewidth=xyz_linewidth)\n            ax.add_line(l)\n        ax.axis('off')\n        ####################\n        ####################\n\n        xz_slice = reorient_slice(images[i][:,xyz[1],:],1)\n        if not transpose:\n            ax = plt.subplot(gs[i,1])\n        else:\n            ax = plt.subplot(gs[1,i])\n        ax.imshow(xz_slice, cmap=cmap, vmin=vmin, vmax=vmax)\n        if overlays[i] is not None:\n            xz_overlay = reorient_slice(overlays[i][:,xyz[1],:],1)\n            ax.imshow(xz_overlay, alpha=overlay_alpha, cmap=overlay_cmap)\n        if xyz_lines:\n            # add lines\n            l = mlines.Line2D([xz_slice.shape[0]-xyz[0],xz_slice.shape[0]-xyz[0]], \n                              [xyz_pad,xz_slice.shape[0]-xyz_pad],\n                               color=xyz_color, alpha=xyz_alpha, linewidth=xyz_linewidth)\n            ax.add_line(l)\n            l = mlines.Line2D([xyz_pad,xz_slice.shape[1]-xyz_pad], \n                              [xz_slice.shape[1]-xyz[2],xz_slice.shape[1]-xyz[2]],\n                              color=xyz_color, alpha=xyz_alpha, linewidth=xyz_linewidth)\n            ax.add_line(l)\n        ax.axis('off')\n\n        ####################\n        ####################\n        xy_slice = reorient_slice(images[i][:,:,xyz[2]],2)\n        if not transpose:\n            ax = plt.subplot(gs[i,2])\n        else:\n            ax = plt.subplot(gs[2,i])\n        ax.imshow(xy_slice, cmap=cmap, vmin=vmin, vmax=vmax)\n        if overlays[i] is not None:\n            xy_overlay = reorient_slice(overlays[i][:,:,xyz[2]],2)\n            ax.imshow(xy_overlay, alpha=overlay_alpha, cmap=overlay_cmap)\n        if xyz_lines:\n            # add lines\n            l = mlines.Line2D([xy_slice.shape[0]-xyz[0],xy_slice.shape[0]-xyz[0]], \n                              [xyz_pad,xy_slice.shape[0]-xyz_pad],\n                              color=xyz_color, alpha=xyz_alpha, linewidth=xyz_linewidth)\n            ax.add_line(l)\n            l = mlines.Line2D([xyz_pad,xy_slice.shape[1]-xyz_pad], \n                              [xy_slice.shape[1]-xyz[1],xy_slice.shape[1]-xyz[1]],\n                              color=xyz_color, alpha=xyz_alpha, linewidth=xyz_linewidth)\n            ax.add_line(l)\n        ax.axis('off')\n\n    ####################\n    ####################\n\n    if filename is not None:\n        plt.savefig(filename, dpi=dpi, transparent=transparent)\n        plt.close(fig)\n    else:\n        plt.show()\n\n    # turn warnings back to default\n    warnings.simplefilter('default')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nplots an orthographic double image.", "response": "def plot_ortho_double(image, image2, overlay=None, overlay2=None, reorient=True,\n    # xyz arguments\n    xyz=None, xyz_lines=True, xyz_color='red', xyz_alpha=0.6, xyz_linewidth=2, xyz_pad=5,\n    # base image arguments\n    cmap='Greys_r', alpha=1, cmap2='Greys_r', alpha2=1,\n    # overlay arguments\n    overlay_cmap='jet', overlay_alpha=0.9, overlay_cmap2='jet', overlay_alpha2=0.9,  \n    # background arguments\n    black_bg=True, bg_thresh_quant=0.01, bg_val_quant=0.99, \n    # scale/crop/domain arguments\n    crop=False, scale=False, crop2=False, scale2=True, domain_image_map=None, \n    # title arguments\n    title=None, titlefontsize=24, title_dx=0, title_dy=0, \n    # 4th panel text arguemnts\n    text=None, textfontsize=24, textfontcolor='white', text_dx=0, text_dy=0,\n    # save & size arguments\n    filename=None, dpi=500, figsize=1., flat=True, transpose=False, transparent=True):\n    \"\"\"\n    Example\n    -------\n    >>> import ants\n    >>> mni = ants.image_read(ants.get_data('mni'))\n    >>> ch2 = ants.image_read(ants.get_data('ch2'))\n    >>> ants.plot_ortho_double(mni, ch2)\n    \"\"\"\n    def mirror_matrix(x):\n        return x[::-1,:]\n    def rotate270_matrix(x):\n        return mirror_matrix(x.T)\n    def reorient_slice(x, axis):\n        return rotate270_matrix(x)\n\n    # need this hack because of a weird NaN warning from matplotlib with overlays\n    warnings.simplefilter('ignore')\n\n    # handle `image` argument\n    if isinstance(image, str):\n        image = iio2.image_read(image)\n    if not isinstance(image, iio.ANTsImage):\n        raise ValueError('image argument must be an ANTsImage')\n    if image.dimension != 3:\n        raise ValueError('Input image must have 3 dimensions!')\n    \n    if isinstance(image2, str):\n        image2 = iio2.image_read(image2)\n    if not isinstance(image2, iio.ANTsImage):\n        raise ValueError('image2 argument must be an ANTsImage')\n    if image2.dimension != 3:\n        raise ValueError('Input image2 must have 3 dimensions!')\n\n    # handle `overlay` argument \n    if overlay is not None:\n        if isinstance(overlay, str):\n            overlay = iio2.image_read(overlay)\n        if not isinstance(overlay, iio.ANTsImage):\n            raise ValueError('overlay argument must be an ANTsImage')\n        if overlay.dimension != 3:\n            raise ValueError('Overlay image must have 3 dimensions!')\n\n        if not iio.image_physical_space_consistency(image, overlay):\n            overlay = reg.resample_image_to_target(overlay, image, interp_type='linear')\n    \n    if overlay2 is not None:\n        if isinstance(overlay2, str):\n            overlay2 = iio2.image_read(overlay2)\n        if not isinstance(overlay2, iio.ANTsImage):\n            raise ValueError('overlay2 argument must be an ANTsImage')\n        if overlay2.dimension != 3:\n            raise ValueError('Overlay2 image must have 3 dimensions!')\n\n        if not iio.image_physical_space_consistency(image2, overlay2):\n            overlay2 = reg.resample_image_to_target(overlay2, image2, interp_type='linear')\n\n    if not iio.image_physical_space_consistency(image, image2):\n        image2 = reg.resample_image_to_target(image2, image, interp_type='linear')\n\n    if image.pixeltype not in {'float', 'double'}:\n        scale = False # turn off scaling if image is discrete\n\n    if image2.pixeltype not in {'float', 'double'}:\n        scale2 = False # turn off scaling if image is discrete\n\n    # reorient images\n    if reorient != False:\n        if reorient == True:\n            reorient = 'RPI'\n        image = image.reorient_image2(reorient)\n        image2 = image2.reorient_image2(reorient)\n        if overlay is not None:\n            overlay = overlay.reorient_image2(reorient)\n        if overlay2 is not None:\n            overlay2 = overlay2.reorient_image2(reorient)\n\n    # handle `slices` argument\n    if xyz is None:\n        xyz = [int(s/2) for s in image.shape]\n    for i in range(3):\n        if xyz[i] is None:\n            xyz[i] = int(image.shape[i]/2)\n\n    # resample image if spacing is very unbalanced\n    spacing = [s for i,s in enumerate(image.spacing)]\n    if (max(spacing) / min(spacing)) > 3.:\n        new_spacing = (1,1,1)\n        image = image.resample_image(tuple(new_spacing))\n        image2 = image2.resample_image_to_target(tuple(new_spacing))\n        if overlay is not None:\n            overlay = overlay.resample_image(tuple(new_spacing))\n        if overlay2 is not None:\n            overlay2 = overlay2.resample_image(tuple(new_spacing))\n        xyz = [int(sl*(sold/snew)) for sl,sold,snew in zip(xyz,spacing,new_spacing)]\n\n    # pad images\n    image, lowpad, uppad = image.pad_image(return_padvals=True)\n    image2, lowpad2, uppad2 = image2.pad_image(return_padvals=True)\n    xyz = [v+l for v,l in zip(xyz,lowpad)]\n    if overlay is not None:\n        overlay = overlay.pad_image()\n    if overlay2 is not None:\n        overlay2 = overlay2.pad_image()\n\n    # handle `domain_image_map` argument\n    if domain_image_map is not None:\n        if isinstance(domain_image_map, iio.ANTsImage):\n            tx = tio2.new_ants_transform(precision='float', transform_type='AffineTransform',\n                                         dimension=image.dimension)\n            image = tio.apply_ants_transform_to_image(tx, image, domain_image_map)\n            image2 = tio.apply_ants_transform_to_image(tx, image2, domain_image_map)\n            if overlay is not None:\n                overlay = tio.apply_ants_transform_to_image(tx, overlay, \n                                                            domain_image_map, \n                                                            interpolation='linear')\n            if overlay2 is not None:\n                overlay2 = tio.apply_ants_transform_to_image(tx, overlay2, \n                                                            domain_image_map, \n                                                            interpolation='linear')          \n        elif isinstance(domain_image_map, (list, tuple)):\n            # expect an image and transformation\n            if len(domain_image_map) != 2:\n                raise ValueError('domain_image_map list or tuple must have length == 2')\n            \n            dimg = domain_image_map[0]\n            if not isinstance(dimg, iio.ANTsImage):\n                raise ValueError('domain_image_map first entry should be ANTsImage')\n\n            tx = domain_image_map[1]\n            image = reg.apply_transforms(dimg, image, transform_list=tx)\n            if overlay is not None:\n                overlay = reg.apply_transforms(dimg, overlay, transform_list=tx,\n                                               interpolator='linear')\n\n            image2 = reg.apply_transforms(dimg, image2, transform_list=tx)\n            if overlay2 is not None:\n                overlay2 = reg.apply_transforms(dimg, overlay2, transform_list=tx,\n                                               interpolator='linear')\n\n    ## single-channel images ##\n    if image.components == 1:\n        \n        # potentially crop image\n        if crop:\n            plotmask = image.get_mask(cleanup=0)\n            if plotmask.max() == 0:\n                plotmask += 1\n            image = image.crop_image(plotmask)\n            if overlay is not None:\n                overlay = overlay.crop_image(plotmask)\n        \n        if crop2:\n            plotmask2 = image2.get_mask(cleanup=0)\n            if plotmask2.max() == 0:\n                plotmask2 += 1\n            image2 = image2.crop_image(plotmask2)\n            if overlay2 is not None:\n                overlay2 = overlay2.crop_image(plotmask2)\n\n\n        # potentially find dynamic range\n        if scale == True:\n            vmin, vmax = image.quantile((0.05,0.95))\n        elif isinstance(scale, (list,tuple)):\n            if len(scale) != 2:\n                raise ValueError('scale argument must be boolean or list/tuple with two values')\n            vmin, vmax = image.quantile(scale)\n        else:\n            vmin = None\n            vmax = None\n\n        if scale2 == True:\n            vmin2, vmax2 = image2.quantile((0.05,0.95))\n        elif isinstance(scale2, (list,tuple)):\n            if len(scale2) != 2:\n                raise ValueError('scale2 argument must be boolean or list/tuple with two values')\n            vmin2, vmax2 = image2.quantile(scale2)\n        else:\n            vmin2 = None\n            vmax2 = None\n\n        if not flat:\n            nrow = 2\n            ncol = 4\n        else:\n            if not transpose:\n                nrow = 2\n                ncol = 3\n            else:\n                nrow = 3\n                ncol = 2\n\n        fig = plt.figure(figsize=((ncol+1)*2.5*figsize, (nrow+1)*2.5*figsize))\n        if title is not None:\n            basey = 0.88 if not flat else 0.66\n            basex = 0.5\n            fig.suptitle(title, fontsize=titlefontsize, x=basex+title_dx, y=basey+title_dy)\n\n        gs = gridspec.GridSpec(nrow, ncol,\n                 wspace=0.0, hspace=0.0, \n                 top=1.-0.5/(nrow+1), bottom=0.5/(nrow+1), \n                 left=0.5/(ncol+1), right=1-0.5/(ncol+1))\n\n        # pad image to have isotropic array dimensions\n        image = image.numpy()\n        if overlay is not None:\n            overlay = overlay.numpy()\n            overlay[np.abs(overlay) == 0] = np.nan\n\n        image2 = image2.numpy()\n        if overlay2 is not None:\n            overlay2 = overlay2.numpy()\n            overlay2[np.abs(overlay2) == 0] = np.nan\n\n        ####################\n        ####################\n        yz_slice = reorient_slice(image[xyz[0],:,:],0)\n        ax = plt.subplot(gs[0,0])\n        ax.imshow(yz_slice, cmap=cmap, vmin=vmin, vmax=vmax)\n        if overlay is not None:\n            yz_overlay = reorient_slice(overlay[xyz[0],:,:],0)\n            ax.imshow(yz_overlay, alpha=overlay_alpha, cmap=overlay_cmap)\n        if xyz_lines:\n            # add lines\n            l = mlines.Line2D([yz_slice.shape[0]-xyz[1],yz_slice.shape[0]-xyz[1]], \n                              [xyz_pad,yz_slice.shape[0]-xyz_pad],\n                              color=xyz_color, alpha=xyz_alpha, linewidth=xyz_linewidth)\n            ax.add_line(l)\n            l = mlines.Line2D([xyz_pad,yz_slice.shape[1]-xyz_pad], \n                              [yz_slice.shape[1]-xyz[2],yz_slice.shape[1]-xyz[2]],\n                color=xyz_color, alpha=xyz_alpha, linewidth=xyz_linewidth)\n            ax.add_line(l)\n        ax.axis('off')\n\n        #######\n        yz_slice2 = reorient_slice(image2[xyz[0],:,:],0)\n        if not flat:\n            ax = plt.subplot(gs[0,1])\n        else:\n            if not transpose:\n                ax = plt.subplot(gs[1,0])\n            else:\n                ax = plt.subplot(gs[0,1])\n        ax.imshow(yz_slice2, cmap=cmap2, vmin=vmin2, vmax=vmax2)\n        if overlay2 is not None:\n            yz_overlay2 = reorient_slice(overlay2[xyz[0],:,:],0)\n            ax.imshow(yz_overlay2, alpha=overlay_alpha2, cmap=overlay_cmap2)\n        if xyz_lines:\n            # add lines\n            l = mlines.Line2D([yz_slice2.shape[0]-xyz[1],yz_slice2.shape[0]-xyz[1]], \n                              [xyz_pad,yz_slice2.shape[0]-xyz_pad],\n                              color=xyz_color, alpha=xyz_alpha, linewidth=xyz_linewidth)\n            ax.add_line(l)\n            l = mlines.Line2D([xyz_pad,yz_slice2.shape[1]-xyz_pad], \n                              [yz_slice2.shape[1]-xyz[2],yz_slice2.shape[1]-xyz[2]],\n                color=xyz_color, alpha=xyz_alpha, linewidth=xyz_linewidth)\n            ax.add_line(l)\n        ax.axis('off')\n        ####################\n        ####################\n\n        xz_slice = reorient_slice(image[:,xyz[1],:],1)\n        if not flat:\n            ax = plt.subplot(gs[0,2])\n        else:\n            if not transpose:\n                ax = plt.subplot(gs[0,1])\n            else:\n                ax = plt.subplot(gs[1,0])\n        ax.imshow(xz_slice, cmap=cmap, vmin=vmin, vmax=vmax)\n        if overlay is not None:\n            xz_overlay = reorient_slice(overlay[:,xyz[1],:],1)\n            ax.imshow(xz_overlay, alpha=overlay_alpha, cmap=overlay_cmap)\n        if xyz_lines:\n            # add lines\n            l = mlines.Line2D([xz_slice.shape[0]-xyz[0],xz_slice.shape[0]-xyz[0]], \n                              [xyz_pad,xz_slice.shape[0]-xyz_pad],\n                               color=xyz_color, alpha=xyz_alpha, linewidth=xyz_linewidth)\n            ax.add_line(l)\n            l = mlines.Line2D([xyz_pad,xz_slice.shape[1]-xyz_pad], \n                              [xz_slice.shape[1]-xyz[2],xz_slice.shape[1]-xyz[2]],\n                              color=xyz_color, alpha=xyz_alpha, linewidth=xyz_linewidth)\n            ax.add_line(l)\n        ax.axis('off')\n\n        #######\n        xz_slice2 = reorient_slice(image2[:,xyz[1],:],1)\n        if not flat:\n            ax = plt.subplot(gs[0,3])\n        else:\n            ax = plt.subplot(gs[1,1])\n        ax.imshow(xz_slice2, cmap=cmap2, vmin=vmin2, vmax=vmax2)\n        if overlay is not None:\n            xz_overlay2 = reorient_slice(overlay2[:,xyz[1],:],1)\n            ax.imshow(xz_overlay2, alpha=overlay_alpha2, cmap=overlay_cmap2)\n        if xyz_lines:\n            # add lines\n            l = mlines.Line2D([xz_slice2.shape[0]-xyz[0],xz_slice2.shape[0]-xyz[0]], \n                              [xyz_pad,xz_slice2.shape[0]-xyz_pad],\n                               color=xyz_color, alpha=xyz_alpha, linewidth=xyz_linewidth)\n            ax.add_line(l)\n            l = mlines.Line2D([xyz_pad,xz_slice2.shape[1]-xyz_pad], \n                              [xz_slice2.shape[1]-xyz[2],xz_slice2.shape[1]-xyz[2]],\n                              color=xyz_color, alpha=xyz_alpha, linewidth=xyz_linewidth)\n            ax.add_line(l)\n        ax.axis('off')\n\n        ####################\n        ####################\n        xy_slice = reorient_slice(image[:,:,xyz[2]],2)\n        if not flat:\n            ax = plt.subplot(gs[1,2])\n        else:\n            if not transpose:\n                ax = plt.subplot(gs[0,2])\n            else:\n                ax = plt.subplot(gs[2,0])\n        ax.imshow(xy_slice, cmap=cmap, vmin=vmin, vmax=vmax)\n        if overlay is not None:\n            xy_overlay = reorient_slice(overlay[:,:,xyz[2]],2)\n            ax.imshow(xy_overlay, alpha=overlay_alpha, cmap=overlay_cmap)\n        if xyz_lines:\n            # add lines\n            l = mlines.Line2D([xy_slice.shape[0]-xyz[0],xy_slice.shape[0]-xyz[0]], \n                              [xyz_pad,xy_slice.shape[0]-xyz_pad],\n                              color=xyz_color, alpha=xyz_alpha, linewidth=xyz_linewidth)\n            ax.add_line(l)\n            l = mlines.Line2D([xyz_pad,xy_slice.shape[1]-xyz_pad], \n                              [xy_slice.shape[1]-xyz[1],xy_slice.shape[1]-xyz[1]],\n                              color=xyz_color, alpha=xyz_alpha, linewidth=xyz_linewidth)\n            ax.add_line(l)\n        ax.axis('off')\n\n        #######\n        xy_slice2 = reorient_slice(image2[:,:,xyz[2]],2)\n        if not flat:\n            ax = plt.subplot(gs[1,3])\n        else:\n            if not transpose:\n                ax = plt.subplot(gs[1,2])\n            else:\n                ax = plt.subplot(gs[2,1])\n        ax.imshow(xy_slice2, cmap=cmap2, vmin=vmin2, vmax=vmax2)\n        if overlay is not None:\n            xy_overlay2 = reorient_slice(overlay2[:,:,xyz[2]],2)\n            ax.imshow(xy_overlay2, alpha=overlay_alpha2, cmap=overlay_cmap2)\n        if xyz_lines:\n            # add lines\n            l = mlines.Line2D([xy_slice2.shape[0]-xyz[0],xy_slice2.shape[0]-xyz[0]], \n                              [xyz_pad,xy_slice2.shape[0]-xyz_pad],\n                              color=xyz_color, alpha=xyz_alpha, linewidth=xyz_linewidth)\n            ax.add_line(l)\n            l = mlines.Line2D([xyz_pad,xy_slice2.shape[1]-xyz_pad], \n                              [xy_slice2.shape[1]-xyz[1],xy_slice2.shape[1]-xyz[1]],\n                              color=xyz_color, alpha=xyz_alpha, linewidth=xyz_linewidth)\n            ax.add_line(l)\n        ax.axis('off')\n\n        ####################\n        ####################\n\n        if not flat:\n            # empty corner\n            ax = plt.subplot(gs[1,:2])\n            if text is not None:\n                # add text\n                left, width = .25, .5\n                bottom, height = .25, .5\n                right = left + width\n                top = bottom + height\n                ax.text(0.5*(left+right)+text_dx, 0.5*(bottom+top)+text_dy, text,\n                        horizontalalignment='center',\n                        verticalalignment='center',\n                        fontsize=textfontsize, color=textfontcolor,\n                        transform=ax.transAxes)\n            #ax.text(0.5, 0.5)\n            img_shape = list(image.shape[:-1])\n            img_shape[1] *= 2\n            ax.imshow(np.zeros(img_shape), cmap='Greys_r')\n            ax.axis('off')\n\n\n    ## multi-channel images ##\n    elif image.components > 1:\n        raise ValueError('Multi-channel images not currently supported!')\n\n    if filename is not None:\n        plt.savefig(filename, dpi=dpi, transparent=transparent)\n        plt.close(fig)\n    else:\n        plt.show()\n\n    # turn warnings back to default\n    warnings.simplefilter('default')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nplotting an orthographic view of an image.", "response": "def plot_ortho(image, overlay=None, reorient=True, blend=False,\n    # xyz arguments\n    xyz=None, xyz_lines=True, xyz_color='red', xyz_alpha=0.6, xyz_linewidth=2, xyz_pad=5,\n    orient_labels=True,\n    # base image arguments\n    alpha=1, cmap='Greys_r', \n    # overlay arguments\n    overlay_cmap='jet', overlay_alpha=0.9,   \n    # background arguments\n    black_bg=True, bg_thresh_quant=0.01, bg_val_quant=0.99, \n    # scale/crop/domain arguments\n    crop=False, scale=False, domain_image_map=None, \n    # title arguments\n    title=None, titlefontsize=24, title_dx=0, title_dy=0, \n    # 4th panel text arguemnts\n    text=None, textfontsize=24, textfontcolor='white', text_dx=0, text_dy=0,\n    # save & size arguments\n    filename=None, dpi=500, figsize=1., flat=False, transparent=True):\n    \"\"\"\n    Plot an orthographic view of a 3D image\n\n    TODO:\n        - add colorbar option\n    \n    ANTsR function: N/A\n\n    Arguments\n    ---------\n    image : ANTsImage\n        image to plot\n\n    overlay : ANTsImage\n        image to overlay on base image\n\n    slices : list or tuple of 3 integers\n        slice indices along each axis to plot\n        This can be absolute array indices (e.g. (80,100,120)), or\n        this can be relative array indices (e.g. (0.4,0.5,0.6)).\n        The default is to take the middle slice along each axis.\n    \n    xyz : list or tuple of 3 integers\n        if given, solid lines will be drawn to converge at this coordinate.\n        This is useful for pinpointing a specific location in the image.\n\n    flat : boolean\n        if true, the ortho image will be plot in one row\n        if false, the ortho image will be a 2x2 grid with the bottom\n            left corner blank\n\n    cmap : string\n        colormap to use for base image. See matplotlib.\n\n    overlay_cmap : string\n        colormap to use for overlay images, if applicable. See matplotlib.\n\n    overlay_alpha : float\n        level of transparency for any overlays. Smaller value means \n        the overlay is more transparent. See matplotlib.\n\n    axis : integer\n        which axis to plot along if image is 3D\n\n    black_bg : boolean\n        if True, the background of the image(s) will be black.\n        if False, the background of the image(s) will be determined by the\n            values `bg_thresh_quant` and `bg_val_quant`.\n\n    bg_thresh_quant : float \n        if white_bg=True, the background will be determined by thresholding\n        the image at the `bg_thresh` quantile value and setting the background\n        intensity to the `bg_val` quantile value. \n        This value should be in [0, 1] - somewhere around 0.01 is recommended.\n            - equal to 1 will threshold the entire image\n            - equal to 0 will threshold none of the image\n\n    bg_val_quant : float\n        if white_bg=True, the background will be determined by thresholding\n        the image at the `bg_thresh` quantile value and setting the background\n        intensity to the `bg_val` quantile value.\n        This value should be in [0, 1] \n            - equal to 1 is pure white\n            - equal to 0 is pure black\n            - somewhere in between is gray\n\n    domain_image_map : ANTsImage\n        this input ANTsImage or list of ANTsImage types contains a reference image\n        `domain_image` and optional reference mapping named `domainMap`.\n        If supplied, the image(s) to be plotted will be mapped to the domain\n        image space before plotting - useful for non-standard image orientations.\n\n    crop : boolean\n        if true, the image(s) will be cropped to their bounding boxes, resulting\n        in a potentially smaller image size.\n        if false, the image(s) will not be cropped\n\n    scale : boolean or 2-tuple\n        if true, nothing will happen to intensities of image(s) and overlay(s)\n        if false, dynamic range will be maximized when visualizing overlays\n        if 2-tuple, the image will be dynamically scaled between these quantiles\n\n    title : string \n        add a title to the plot\n\n    filename : string\n        if given, the resulting image will be saved to this file\n\n    dpi : integer\n        determines resolution of image if saved to file. Higher values\n        result in higher resolution images, but at a cost of having a \n        larger file size\n\n    Example\n    -------\n    >>> import ants\n    >>> mni = ants.image_read(ants.get_data('mni'))\n    >>> ants.plot_ortho(mni, xyz=(100,100,100))\n    >>> mni2 = mni.threshold_image(7000, mni.max())\n    >>> ants.plot_ortho(mni, overlay=mni2)\n    >>> ants.plot_ortho(mni, overlay=mni2, flat=True)\n    >>> ants.plot_ortho(mni, overlay=mni2, xyz=(110,110,110), xyz_lines=False,\n                        text='Lines Turned Off', textfontsize=22)\n    >>> ants.plot_ortho(mni, mni2, xyz=(120,100,100),\n                        text=' Example \\nOrtho Text', textfontsize=26, \n                        title='Example Ortho Title', titlefontsize=26)\n    \"\"\"\n    def mirror_matrix(x):\n        return x[::-1,:]\n    def rotate270_matrix(x):\n        return mirror_matrix(x.T)\n    def reorient_slice(x, axis):\n        return rotate270_matrix(x)\n\n    # need this hack because of a weird NaN warning from matplotlib with overlays\n    warnings.simplefilter('ignore')\n\n    # handle `image` argument\n    if isinstance(image, str):\n        image = iio2.image_read(image)\n    if not isinstance(image, iio.ANTsImage):\n        raise ValueError('image argument must be an ANTsImage')\n    if image.dimension != 3:\n        raise ValueError('Input image must have 3 dimensions!')\n\n    # handle `overlay` argument \n    if overlay is not None:\n        if isinstance(overlay, str):\n            overlay = iio2.image_read(overlay)\n        if not isinstance(overlay, iio.ANTsImage):\n            raise ValueError('overlay argument must be an ANTsImage')\n        if overlay.dimension != 3:\n            raise ValueError('Overlay image must have 3 dimensions!')\n\n        if not iio.image_physical_space_consistency(image, overlay):\n            overlay = reg.resample_image_to_target(overlay, image, interp_type='linear')\n\n    if blend:\n        if alpha == 1:\n            alpha = 0.5\n        image = image*alpha + overlay*(1-alpha)\n        overlay = None\n        alpha = 1.\n\n    if image.pixeltype not in {'float', 'double'}:\n        scale = False # turn off scaling if image is discrete\n\n    # reorient images\n    if reorient != False:\n        if reorient == True:\n            reorient = 'RPI'\n        image = image.reorient_image2('RPI')\n        if overlay is not None:\n            overlay = overlay.reorient_image2('RPI')\n\n    # handle `slices` argument\n    if xyz is None:\n        xyz = [int(s/2) for s in image.shape]\n    for i in range(3):\n        if xyz[i] is None:\n            xyz[i] = int(image.shape[i]/2)\n\n    # resample image if spacing is very unbalanced\n    spacing = [s for i,s in enumerate(image.spacing)]\n    if (max(spacing) / min(spacing)) > 3.:\n        new_spacing = (1,1,1)\n        image = image.resample_image(tuple(new_spacing))\n        if overlay is not None:\n            overlay = overlay.resample_image(tuple(new_spacing))\n        xyz = [int(sl*(sold/snew)) for sl,sold,snew in zip(xyz,spacing,new_spacing)]\n\n    # potentially crop image\n    if crop:\n        plotmask = image.get_mask(cleanup=0)\n        if plotmask.max() == 0:\n            plotmask += 1\n        image = image.crop_image(plotmask)\n        if overlay is not None:\n            overlay = overlay.crop_image(plotmask)\n\n    # pad images\n    image, lowpad, uppad = image.pad_image(return_padvals=True)\n    xyz = [v+l for v,l in zip(xyz,lowpad)]\n    if overlay is not None:\n        overlay = overlay.pad_image()\n\n    # handle `domain_image_map` argument\n    if domain_image_map is not None:\n        if isinstance(domain_image_map, iio.ANTsImage):\n            tx = tio2.new_ants_transform(precision='float', transform_type='AffineTransform',\n                                         dimension=image.dimension)\n            image = tio.apply_ants_transform_to_image(tx, image, domain_image_map)\n            if overlay is not None:\n                overlay = tio.apply_ants_transform_to_image(tx, overlay, \n                                                            domain_image_map, \n                                                            interpolation='linear')\n        elif isinstance(domain_image_map, (list, tuple)):\n            # expect an image and transformation\n            if len(domain_image_map) != 2:\n                raise ValueError('domain_image_map list or tuple must have length == 2')\n            \n            dimg = domain_image_map[0]\n            if not isinstance(dimg, iio.ANTsImage):\n                raise ValueError('domain_image_map first entry should be ANTsImage')\n\n            tx = domain_image_map[1]\n            image = reg.apply_transforms(dimg, image, transform_list=tx)\n            if overlay is not None:\n                overlay = reg.apply_transforms(dimg, overlay, transform_list=tx,\n                                               interpolator='linear')\n\n    ## single-channel images ##\n    if image.components == 1:\n\n        # potentially find dynamic range\n        if scale == True:\n            vmin, vmax = image.quantile((0.05,0.95))\n        elif isinstance(scale, (list,tuple)):\n            if len(scale) != 2:\n                raise ValueError('scale argument must be boolean or list/tuple with two values')\n            vmin, vmax = image.quantile(scale)\n        else:\n            vmin = None\n            vmax = None\n\n        if not flat:\n            nrow = 2\n            ncol = 2\n        else:\n            nrow = 1\n            ncol = 3\n\n        fig = plt.figure(figsize=(9*figsize,9*figsize))\n        if title is not None:\n            basey = 0.88 if not flat else 0.66\n            basex = 0.5\n            fig.suptitle(title, fontsize=titlefontsize, x=basex+title_dx, y=basey+title_dy)\n\n        gs = gridspec.GridSpec(nrow, ncol,\n                 wspace=0.0, hspace=0.0, \n                 top=1.-0.5/(nrow+1), bottom=0.5/(nrow+1), \n                 left=0.5/(ncol+1), right=1-0.5/(ncol+1))\n\n        # pad image to have isotropic array dimensions\n        image = image.numpy()\n        if overlay is not None:\n            overlay = overlay.numpy()\n            overlay[np.abs(overlay) == 0] = np.nan\n\n        yz_slice = reorient_slice(image[xyz[0],:,:],0)\n        ax = plt.subplot(gs[0,0])\n        ax.imshow(yz_slice, cmap=cmap, vmin=vmin, vmax=vmax)\n        if overlay is not None:\n            yz_overlay = reorient_slice(overlay[xyz[0],:,:],0)\n            ax.imshow(yz_overlay, alpha=overlay_alpha, cmap=overlay_cmap)\n        if xyz_lines:\n            # add lines\n            l = mlines.Line2D([yz_slice.shape[0]-xyz[1],yz_slice.shape[0]-xyz[1]], \n                              [xyz_pad,yz_slice.shape[0]-xyz_pad],\n                              color=xyz_color, alpha=xyz_alpha, linewidth=xyz_linewidth)\n            ax.add_line(l)\n            l = mlines.Line2D([xyz_pad,yz_slice.shape[1]-xyz_pad], \n                              [yz_slice.shape[1]-xyz[2],yz_slice.shape[1]-xyz[2]],\n                color=xyz_color, alpha=xyz_alpha, linewidth=xyz_linewidth)\n            ax.add_line(l)\n        if orient_labels:\n            ax.text(0.5,0.98, 'S',\n                    horizontalalignment='center',\n                    verticalalignment='top',\n                    fontsize=20*figsize, color=textfontcolor,\n                    transform=ax.transAxes)\n            ax.text(0.5,0.02, 'I',\n                    horizontalalignment='center',\n                    verticalalignment='bottom',\n                    fontsize=20*figsize, color=textfontcolor,\n                    transform=ax.transAxes)\n            ax.text(0.98,0.5, 'A',\n                    horizontalalignment='right',\n                    verticalalignment='center',\n                    fontsize=20*figsize, color=textfontcolor,\n                    transform=ax.transAxes)\n            ax.text(0.02,0.5, 'P',\n                    horizontalalignment='left',\n                    verticalalignment='center',\n                    fontsize=20*figsize, color=textfontcolor,\n                    transform=ax.transAxes)\n        ax.axis('off')\n\n        xz_slice = reorient_slice(image[:,xyz[1],:],1)\n        ax = plt.subplot(gs[0,1])\n        ax.imshow(xz_slice, cmap=cmap, vmin=vmin, vmax=vmax)\n        if overlay is not None:\n            xz_overlay = reorient_slice(overlay[:,xyz[1],:],1)\n            ax.imshow(xz_overlay, alpha=overlay_alpha, cmap=overlay_cmap)\n        if xyz_lines:\n            # add lines\n            l = mlines.Line2D([xz_slice.shape[0]-xyz[0],xz_slice.shape[0]-xyz[0]], \n                              [xyz_pad,xz_slice.shape[0]-xyz_pad],\n                               color=xyz_color, alpha=xyz_alpha, linewidth=xyz_linewidth)\n            ax.add_line(l)\n            l = mlines.Line2D([xyz_pad,xz_slice.shape[1]-xyz_pad], \n                              [xz_slice.shape[1]-xyz[2],xz_slice.shape[1]-xyz[2]],\n                              color=xyz_color, alpha=xyz_alpha, linewidth=xyz_linewidth)\n            ax.add_line(l)\n        if orient_labels:\n            ax.text(0.5,0.98, 'S',\n                    horizontalalignment='center',\n                    verticalalignment='top',\n                    fontsize=20*figsize, color=textfontcolor,\n                    transform=ax.transAxes)\n            ax.text(0.5,0.02, 'I',\n                    horizontalalignment='center',\n                    verticalalignment='bottom',\n                    fontsize=20*figsize, color=textfontcolor,\n                    transform=ax.transAxes)\n            ax.text(0.98,0.5, 'R',\n                    horizontalalignment='right',\n                    verticalalignment='center',\n                    fontsize=20*figsize, color=textfontcolor,\n                    transform=ax.transAxes)\n            ax.text(0.02,0.5, 'L',\n                    horizontalalignment='left',\n                    verticalalignment='center',\n                    fontsize=20*figsize, color=textfontcolor,\n                    transform=ax.transAxes)\n        ax.axis('off')\n\n        xy_slice = reorient_slice(image[:,:,xyz[2]],2)\n        if not flat:\n            ax = plt.subplot(gs[1,1])\n        else:\n            ax = plt.subplot(gs[0,2])\n        ax.imshow(xy_slice, cmap=cmap, vmin=vmin, vmax=vmax)\n        if overlay is not None:\n            xy_overlay = reorient_slice(overlay[:,:,xyz[2]],2)\n            ax.imshow(xy_overlay, alpha=overlay_alpha, cmap=overlay_cmap)\n        if xyz_lines:\n            # add lines\n            l = mlines.Line2D([xy_slice.shape[0]-xyz[0],xy_slice.shape[0]-xyz[0]], \n                              [xyz_pad,xy_slice.shape[0]-xyz_pad],\n                              color=xyz_color, alpha=xyz_alpha, linewidth=xyz_linewidth)\n            ax.add_line(l)\n            l = mlines.Line2D([xyz_pad,xy_slice.shape[1]-xyz_pad], \n                              [xy_slice.shape[1]-xyz[1],xy_slice.shape[1]-xyz[1]],\n                              color=xyz_color, alpha=xyz_alpha, linewidth=xyz_linewidth)\n            ax.add_line(l)\n        if orient_labels:\n            ax.text(0.5,0.98, 'A',\n                    horizontalalignment='center',\n                    verticalalignment='top',\n                    fontsize=20*figsize, color=textfontcolor,\n                    transform=ax.transAxes)\n            ax.text(0.5,0.02, 'P',\n                    horizontalalignment='center',\n                    verticalalignment='bottom',\n                    fontsize=20*figsize, color=textfontcolor,\n                    transform=ax.transAxes)\n            ax.text(0.98,0.5, 'R',\n                    horizontalalignment='right',\n                    verticalalignment='center',\n                    fontsize=20*figsize, color=textfontcolor,\n                    transform=ax.transAxes)\n            ax.text(0.02,0.5, 'L',\n                    horizontalalignment='left',\n                    verticalalignment='center',\n                    fontsize=20*figsize, color=textfontcolor,\n                    transform=ax.transAxes)\n        ax.axis('off')\n\n        if not flat:\n            # empty corner\n            ax = plt.subplot(gs[1,0])\n            if text is not None:\n                # add text\n                left, width = .25, .5\n                bottom, height = .25, .5\n                right = left + width\n                top = bottom + height\n                ax.text(0.5*(left+right)+text_dx, 0.5*(bottom+top)+text_dy, text,\n                        horizontalalignment='center',\n                        verticalalignment='center',\n                        fontsize=textfontsize, color=textfontcolor,\n                        transform=ax.transAxes)\n            #ax.text(0.5, 0.5)\n            ax.imshow(np.zeros(image.shape[:-1]), cmap='Greys_r')\n            ax.axis('off')\n            \n    ## multi-channel images ##\n    elif image.components > 1:\n        raise ValueError('Multi-channel images not currently supported!')\n\n    if filename is not None:\n        plt.savefig(filename, dpi=dpi, transparent=transparent)\n        plt.close(fig)\n    else:\n        plt.show()\n\n    # turn warnings back to default\n    warnings.simplefilter('default')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nplot an ANTsImage. By default, images will be reoriented to 'LAI' orientation before plotting. So, if axis == 0, the images will be ordered from the left side of the brain to the right side of the brain. If axis == 1, the images will be ordered from the anterior (front) of the brain to the posterior (back) of the brain. And if axis == 2, the images will be ordered from the inferior (bottom) of the brain to the superior (top) of the brain. ANTsR function: `plot.antsImage` Arguments --------- image : ANTsImage image to plot overlay : ANTsImage image to overlay on base image cmap : string colormap to use for base image. See matplotlib. overlay_cmap : string colormap to use for overlay images, if applicable. See matplotlib. overlay_alpha : float level of transparency for any overlays. Smaller value means the overlay is more transparent. See matplotlib. axis : integer which axis to plot along if image is 3D nslices : integer number of slices to plot if image is 3D slices : list or tuple of integers specific slice indices to plot if image is 3D. If given, this will override `nslices`. This can be absolute array indices (e.g. (80,100,120)), or this can be relative array indices (e.g. (0.4,0.5,0.6)) ncol : integer Number of columns to have on the plot if image is 3D. slice_buffer : integer how many slices to buffer when finding the non-zero slices of a 3D images. So, if slice_buffer = 10, then the first slice in a 3D image will be the first non-zero slice index plus 10 more slices. black_bg : boolean if True, the background of the image(s) will be black. if False, the background of the image(s) will be determined by the values `bg_thresh_quant` and `bg_val_quant`. bg_thresh_quant : float if white_bg=True, the background will be determined by thresholding the image at the `bg_thresh` quantile value and setting the background intensity to the `bg_val` quantile value. This value should be in [0, 1] - somewhere around 0.01 is recommended. - equal to 1 will threshold the entire image - equal to 0 will threshold none of the image bg_val_quant : float if white_bg=True, the background will be determined by thresholding the image at the `bg_thresh` quantile value and setting the background intensity to the `bg_val` quantile value. This value should be in [0, 1] - equal to 1 is pure white - equal to 0 is pure black - somewhere in between is gray domain_image_map : ANTsImage this input ANTsImage or list of ANTsImage types contains a reference image `domain_image` and optional reference mapping named `domainMap`. If supplied, the image(s) to be plotted will be mapped to the domain image space before plotting - useful for non-standard image orientations. crop : boolean if true, the image(s) will be cropped to their bounding boxes, resulting in a potentially smaller image size. if false, the image(s) will not be cropped scale : boolean or 2-tuple if true, nothing will happen to intensities of image(s) and overlay(s) if false, dynamic range will be maximized when visualizing overlays if 2-tuple, the image will be dynamically scaled between these quantiles reverse : boolean if true, the order in which the slices are plotted will be reversed. This is useful if you want to plot from the front of the brain first to the back of the brain, or vice-versa title : string add a title to the plot filename : string if given, the resulting image will be saved to this file dpi : integer determines resolution of image if saved to file. Higher values result in higher resolution images, but at a cost of having a larger file size Example ------- >>> import ants >>> import numpy as np >>> img = ants.image_read(ants.get_data('r16')) >>> segs = img.kmeans_segmentation(k=3)['segmentation'] >>> ants.plot(img, segs*(segs==1), crop=True) >>> ants.plot(img, segs*(segs==1), crop=False) >>> mni = ants.image_read(ants.get_data('mni')) >>> segs = mni.kmeans_segmentation(k=3)['segmentation'] >>> ants.plot(mni, segs*(segs==1), crop=False)", "response": "def plot(image, overlay=None,  blend=False,\n    alpha=1, cmap='Greys_r', overlay_cmap='jet', overlay_alpha=0.9, \n    cbar=False, cbar_length=0.8, cbar_dx=0., cbar_vertical=True,\n    axis=0, nslices=12, slices=None, ncol=None, slice_buffer=None, black_bg=True,\n    bg_thresh_quant=0.01, bg_val_quant=0.99, domain_image_map=None, crop=False, scale=False,\n    reverse=False, title=None, title_fontsize=20, title_dx=0., title_dy=0.,\n    filename=None, dpi=500, figsize=1.5, reorient=True):\n    \"\"\"\n    Plot an ANTsImage. \n\n    By default, images will be reoriented to 'LAI' orientation before plotting. \n    So, if axis == 0, the images will be ordered from the\n    left side of the brain to the right side of the brain. If axis == 1,\n    the images will be ordered from the anterior (front) of the brain to\n    the posterior (back) of the brain. And if axis == 2, the images will\n    be ordered from the inferior (bottom) of the brain to the superior (top)\n    of the brain.\n    \n    ANTsR function: `plot.antsImage`\n\n    Arguments\n    ---------\n    image : ANTsImage\n        image to plot\n\n    overlay : ANTsImage\n        image to overlay on base image\n\n    cmap : string\n        colormap to use for base image. See matplotlib.\n\n    overlay_cmap : string\n        colormap to use for overlay images, if applicable. See matplotlib.\n\n    overlay_alpha : float\n        level of transparency for any overlays. Smaller value means \n        the overlay is more transparent. See matplotlib.\n\n    axis : integer\n        which axis to plot along if image is 3D\n\n    nslices : integer\n        number of slices to plot if image is 3D\n\n    slices : list or tuple of integers\n        specific slice indices to plot if image is 3D. \n        If given, this will override `nslices`.\n        This can be absolute array indices (e.g. (80,100,120)), or\n        this can be relative array indices (e.g. (0.4,0.5,0.6))\n\n    ncol : integer\n        Number of columns to have on the plot if image is 3D.\n\n    slice_buffer : integer\n        how many slices to buffer when finding the non-zero slices of\n        a 3D images. So, if slice_buffer = 10, then the first slice\n        in a 3D image will be the first non-zero slice index plus 10 more\n        slices.\n\n    black_bg : boolean\n        if True, the background of the image(s) will be black.\n        if False, the background of the image(s) will be determined by the\n            values `bg_thresh_quant` and `bg_val_quant`.\n\n    bg_thresh_quant : float \n        if white_bg=True, the background will be determined by thresholding\n        the image at the `bg_thresh` quantile value and setting the background\n        intensity to the `bg_val` quantile value. \n        This value should be in [0, 1] - somewhere around 0.01 is recommended.\n            - equal to 1 will threshold the entire image\n            - equal to 0 will threshold none of the image\n\n    bg_val_quant : float\n        if white_bg=True, the background will be determined by thresholding\n        the image at the `bg_thresh` quantile value and setting the background\n        intensity to the `bg_val` quantile value.\n        This value should be in [0, 1] \n            - equal to 1 is pure white\n            - equal to 0 is pure black\n            - somewhere in between is gray\n\n    domain_image_map : ANTsImage\n        this input ANTsImage or list of ANTsImage types contains a reference image\n        `domain_image` and optional reference mapping named `domainMap`.\n        If supplied, the image(s) to be plotted will be mapped to the domain\n        image space before plotting - useful for non-standard image orientations.\n\n    crop : boolean\n        if true, the image(s) will be cropped to their bounding boxes, resulting\n        in a potentially smaller image size.\n        if false, the image(s) will not be cropped\n\n    scale : boolean or 2-tuple\n        if true, nothing will happen to intensities of image(s) and overlay(s)\n        if false, dynamic range will be maximized when visualizing overlays\n        if 2-tuple, the image will be dynamically scaled between these quantiles\n    \n    reverse : boolean\n        if true, the order in which the slices are plotted will be reversed.\n        This is useful if you want to plot from the front of the brain first \n        to the back of the brain, or vice-versa\n\n    title : string \n        add a title to the plot\n\n    filename : string\n        if given, the resulting image will be saved to this file\n\n    dpi : integer\n        determines resolution of image if saved to file. Higher values\n        result in higher resolution images, but at a cost of having a \n        larger file size\n\n    Example\n    -------\n    >>> import ants\n    >>> import numpy as np\n    >>> img = ants.image_read(ants.get_data('r16'))\n    >>> segs = img.kmeans_segmentation(k=3)['segmentation']\n    >>> ants.plot(img, segs*(segs==1), crop=True)\n    >>> ants.plot(img, segs*(segs==1), crop=False)\n    >>> mni = ants.image_read(ants.get_data('mni'))\n    >>> segs = mni.kmeans_segmentation(k=3)['segmentation']\n    >>> ants.plot(mni, segs*(segs==1), crop=False)\n    \"\"\"\n    if (axis == 'x') or (axis == 'saggittal'):\n        axis = 0\n    if (axis == 'y') or (axis == 'coronal'):\n        axis = 1\n    if (axis == 'z') or (axis == 'axial'):\n        axis = 2\n\n    def mirror_matrix(x):\n        return x[::-1,:]\n    def rotate270_matrix(x):\n        return mirror_matrix(x.T)\n    def rotate180_matrix(x):\n        return x[::-1,:]\n    def rotate90_matrix(x):\n        return x.T\n    def flip_matrix(x):\n        return mirror_matrix(rotate180_matrix(x))\n    def reorient_slice(x, axis):\n        if (axis != 2):\n            x = rotate90_matrix(x)\n        if (axis == 2):\n            x = rotate270_matrix(x)\n        x = mirror_matrix(x)\n        return x\n    # need this hack because of a weird NaN warning from matplotlib with overlays\n    warnings.simplefilter('ignore')\n\n    # handle `image` argument\n    if isinstance(image, str):\n        image = iio2.image_read(image)\n    if not isinstance(image, iio.ANTsImage):\n        raise ValueError('image argument must be an ANTsImage')\n    \n    if (image.pixeltype not in {'float', 'double'}) or (image.is_rgb):\n        scale = False # turn off scaling if image is discrete\n\n    # handle `overlay` argument\n    if overlay is not None:\n        if isinstance(overlay, str):\n            overlay = iio2.image_read(overlay)\n        if not isinstance(overlay, iio.ANTsImage):\n            raise ValueError('overlay argument must be an ANTsImage')\n\n        if not iio.image_physical_space_consistency(image, overlay):\n            overlay = reg.resample_image_to_target(overlay, image, interp_type='linear')\n\n        if blend:\n            if alpha == 1:\n                alpha = 0.5\n            image = image*alpha + overlay*(1-alpha)\n            overlay = None\n            alpha = 1.\n\n    # handle `domain_image_map` argument\n    if domain_image_map is not None:\n        if isinstance(domain_image_map, iio.ANTsImage):\n            tx = tio2.new_ants_transform(precision='float', transform_type='AffineTransform',\n                                         dimension=image.dimension)\n            image = tio.apply_ants_transform_to_image(tx, image, domain_image_map)\n            if overlay is not None:\n                overlay = tio.apply_ants_transform_to_image(tx, overlay, \n                                                            domain_image_map, \n                                                            interpolation='linear')\n        elif isinstance(domain_image_map, (list, tuple)):\n            # expect an image and transformation\n            if len(domain_image_map) != 2:\n                raise ValueError('domain_image_map list or tuple must have length == 2')\n            \n            dimg = domain_image_map[0]\n            if not isinstance(dimg, iio.ANTsImage):\n                raise ValueError('domain_image_map first entry should be ANTsImage')\n\n            tx = domain_image_map[1]\n            image = reg.apply_transforms(dimg, image, transform_list=tx)\n            if overlay is not None:\n                overlay = reg.apply_transforms(dimg, overlay, transform_list=tx,\n                                               interpolator='linear')\n\n    ## single-channel images ##\n    if image.components == 1:\n        \n        # potentially crop image\n        if crop:\n            plotmask = image.get_mask(cleanup=0)\n            if plotmask.max() == 0:\n                plotmask += 1\n            image = image.crop_image(plotmask)\n            if overlay is not None:\n                overlay = overlay.crop_image(plotmask)\n\n        # potentially find dynamic range\n        if scale == True:\n            vmin, vmax = image.quantile((0.05,0.95))\n        elif isinstance(scale, (list,tuple)):\n            if len(scale) != 2:\n                raise ValueError('scale argument must be boolean or list/tuple with two values')\n            vmin, vmax = image.quantile(scale)\n        else:\n            vmin = None\n            vmax = None\n\n        # Plot 2D image\n        if image.dimension == 2:\n\n            img_arr = image.numpy()\n            img_arr = rotate90_matrix(img_arr)\n\n            if not black_bg:\n                img_arr[img_arr<image.quantile(bg_thresh_quant)] = image.quantile(bg_val_quant)\n\n            if overlay is not None:\n                ov_arr = overlay.numpy()\n                ov_arr = rotate90_matrix(ov_arr)\n                ov_arr[np.abs(ov_arr) == 0] = np.nan\n\n            fig = plt.figure()\n            if title is not None:\n                fig.suptitle(title, fontsize=title_fontsize, x=0.5+title_dx, y=0.95+title_dy)\n\n            ax = plt.subplot(111)\n\n            # plot main image\n            im = ax.imshow(img_arr, cmap=cmap,\n                      alpha=alpha, \n                      vmin=vmin, vmax=vmax)\n\n            if overlay is not None:\n                im = ax.imshow(ov_arr, \n                               alpha=overlay_alpha, \n                               cmap=overlay_cmap)\n\n            if cbar:\n                cbar_orient = 'vertical' if cbar_vertical else 'horizontal'\n                fig.colorbar(im, orientation=cbar_orient)\n\n            plt.axis('off')\n\n        # Plot 3D image\n        elif image.dimension == 3:\n            # resample image if spacing is very unbalanced\n            spacing = [s for i,s in enumerate(image.spacing) if i != axis]\n            was_resampled = False\n            if (max(spacing) / min(spacing)) > 3.:\n                was_resampled = True\n                new_spacing = (1,1,1)\n                image = image.resample_image(tuple(new_spacing))\n                if overlay is not None:\n                    overlay = overlay.resample_image(tuple(new_spacing))\n\n            if reorient:\n                image = image.reorient_image2('LAI')\n            img_arr = image.numpy()\n            # reorder dims so that chosen axis is first\n            img_arr = np.rollaxis(img_arr, axis)\n\n            if overlay is not None:\n                if reorient:\n                    overlay = overlay.reorient_image2('LAI')\n                ov_arr = overlay.numpy()\n                ov_arr[np.abs(ov_arr) == 0] = np.nan\n                ov_arr = np.rollaxis(ov_arr, axis)\n\n            if slices is None:\n                if not isinstance(slice_buffer, (list, tuple)):\n                    if slice_buffer is None:\n                        slice_buffer = (int(img_arr.shape[1]*0.1), int(img_arr.shape[2]*0.1))\n                    else:\n                        slice_buffer = (slice_buffer, slice_buffer)\n                nonzero = np.where(img_arr.sum(axis=(1,2)) > 0.01)[0]\n                min_idx = nonzero[0] + slice_buffer[0]\n                max_idx = nonzero[-1] - slice_buffer[1]\n                slice_idxs = np.linspace(min_idx, max_idx, nslices).astype('int')\n                if reverse:\n                    slice_idxs = np.array(list(reversed(slice_idxs)))\n            else:\n                if isinstance(slices, (int,float)):\n                    slices = [slices]\n                # if all slices are less than 1, infer that they are relative slices\n                if sum([s > 1 for s in slices]) == 0:\n                    slices = [int(s*img_arr.shape[0]) for s in slices]\n                slice_idxs = slices\n                nslices = len(slices)\n\n            if was_resampled:\n                # re-calculate slices to account for new image shape\n                slice_idxs = np.unique(np.array([int(s*(image.shape[axis]/img_arr.shape[0])) for s in slice_idxs]))\n\n            # only have one row if nslices <= 6 and user didnt specify ncol\n            if ncol is None:\n                if (nslices <= 6):\n                    ncol = nslices\n                else:\n                    ncol = int(round(math.sqrt(nslices)))\n\n            # calculate grid size\n            nrow = math.ceil(nslices / ncol)\n            xdim = img_arr.shape[2]\n            ydim = img_arr.shape[1]\n\n            dim_ratio = ydim/xdim\n            fig = plt.figure(figsize=((ncol+1)*figsize*dim_ratio, (nrow+1)*figsize))\n            if title is not None:\n                fig.suptitle(title, fontsize=title_fontsize, x=0.5+title_dx, y=0.95+title_dy)\n\n            gs = gridspec.GridSpec(nrow, ncol,\n                     wspace=0.0, hspace=0.0, \n                     top=1.-0.5/(nrow+1), bottom=0.5/(nrow+1), \n                     left=0.5/(ncol+1), right=1-0.5/(ncol+1))\n\n            slice_idx_idx = 0\n            for i in range(nrow):\n                for j in range(ncol):\n                    if slice_idx_idx < len(slice_idxs):\n                        imslice = img_arr[slice_idxs[slice_idx_idx]]\n                        imslice = reorient_slice(imslice, axis)\n                        if not black_bg:\n                            imslice[imslice<image.quantile(bg_thresh_quant)] = image.quantile(bg_val_quant)\n                    else:\n                        imslice = np.zeros_like(img_arr[0])\n                        imslice = reorient_slice(imslice, axis)\n\n                    ax = plt.subplot(gs[i,j])\n                    im = ax.imshow(imslice, cmap=cmap,\n                              vmin=vmin, vmax=vmax)\n\n                    if overlay is not None:\n                        if slice_idx_idx < len(slice_idxs):\n                            ovslice = ov_arr[slice_idxs[slice_idx_idx]]\n                            ovslice = reorient_slice(ovslice, axis)\n                            im = ax.imshow(ovslice, alpha=overlay_alpha, cmap=overlay_cmap)\n                    ax.axis('off')\n                    slice_idx_idx += 1\n\n            if cbar:\n                cbar_start = (1-cbar_length) / 2\n                if cbar_vertical:\n                    cax = fig.add_axes([0.9+cbar_dx, cbar_start, 0.03, cbar_length])\n                    cbar_orient = 'vertical'\n                else:\n                    cax = fig.add_axes([cbar_start, 0.08+cbar_dx, cbar_length, 0.03])\n                    cbar_orient = 'horizontal'\n                fig.colorbar(im, cax=cax, orientation=cbar_orient)\n    \n    ## multi-channel images ##\n    elif image.components > 1:\n        if not image.is_rgb:\n            raise ValueError('Multi-component images only supported if they are RGB')\n        \n        img_arr = image.numpy()\n        img_arr = np.stack([rotate90_matrix(img_arr[:,:,i]) for i in range(3)], axis=-1)\n\n        fig = plt.figure()\n        ax = plt.subplot(111)\n\n        # plot main image\n        ax.imshow(img_arr, alpha=alpha)\n\n        plt.axis('off')\n\n    if filename is not None:\n        filename = os.path.expanduser(filename)\n        plt.savefig(filename, dpi=dpi, transparent=True, bbox_inches='tight')\n        plt.close(fig)\n    else:\n        plt.show()\n\n    # turn warnings back to default\n    warnings.simplefilter('default')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating and save an ANTsPy plot for every image in a directory.", "response": "def plot_directory(directory, recursive=False, regex='*', \n    save_prefix='', save_suffix='', axis=None, **kwargs):\n    \"\"\"\n    Create and save an ANTsPy plot for every image matching a given regular\n    expression in a directory, optionally recursively. This is a good function\n    for quick visualize exploration of all of images in a directory \n    \n    ANTsR function: N/A\n\n    Arguments\n    ---------\n    directory : string\n        directory in which to search for images and plot them\n\n    recursive : boolean\n        If true, this function will search through all directories under \n        the given directory recursively to make plots.\n        If false, this function will only create plots for images in the\n        given directory\n\n    regex : string\n        regular expression used to filter out certain filenames or suffixes\n\n    save_prefix : string\n        sub-string that will be appended to the beginning of all saved plot filenames. \n        Default is to add nothing.\n\n    save_suffix : string\n        sub-string that will be appended to the end of all saved plot filenames. \n        Default is add nothing.\n\n    kwargs : keyword arguments\n        any additional arguments to pass onto the `ants.plot` function.\n        e.g. overlay, alpha, cmap, etc. See `ants.plot` for more options.\n\n    Example\n    -------\n    >>> import ants\n    >>> ants.plot_directory(directory='~/desktop/testdir',\n                            recursive=False, regex='*')\n    \"\"\"\n    def has_acceptable_suffix(fname):\n        suffixes = {'.nii.gz'}\n        return sum([fname.endswith(sx) for sx in suffixes]) > 0\n\n    if directory.startswith('~'):\n        directory = os.path.expanduser(directory)\n\n    if not os.path.isdir(directory):\n        raise ValueError('directory %s does not exist!' % directory)\n\n    for root, dirnames, fnames in os.walk(directory):\n        for fname in fnames:\n            if fnmatch.fnmatch(fname, regex) and has_acceptable_suffix(fname):\n                load_fname = os.path.join(root, fname)\n                fname = fname.replace('.'.join(fname.split('.')[1:]), 'png')\n                fname = fname.replace('.png', '%s.png' % save_suffix)\n                fname = '%s%s' % (save_prefix, fname)\n                save_fname = os.path.join(root, fname)\n                img = iio2.image_read(load_fname)\n\n                if axis is None:\n                    axis_range = [i for i in range(img.dimension)]\n                else:\n                    axis_range = axis if isinstance(axis,(list,tuple)) else [axis]\n\n                if img.dimension > 2:\n                    for axis_idx in axis_range:\n                        filename = save_fname.replace('.png', '_axis%i.png' % axis_idx)\n                        ncol = int(math.sqrt(img.shape[axis_idx]))\n                        plot(img, axis=axis_idx, nslices=img.shape[axis_idx], ncol=ncol,\n                             filename=filename, **kwargs)\n                else:\n                    filename = save_fname\n                    plot(img, filename=filename, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nregister a pair of images either through the full or simplified interface to the ANTs registration method. ANTsR function: `antsRegistration` Arguments --------- fixed : ANTsImage fixed image to which we register the moving image. moving : ANTsImage moving image to be mapped to fixed space. type_of_transform : string A linear or non-linear registration type. Mutual information metric by default. See Notes below for more. initial_transform : list of strings (optional) transforms to prepend outprefix : string output will be named with this prefix. mask : ANTsImage (optional) mask the registration. grad_step : scalar gradient step size (not for all tx) flow_sigma : scalar smoothing for update field total_sigma : scalar smoothing for total field aff_metric : string the metric for the affine part (GC, mattes, meansquares) aff_sampling : scalar the nbins or radius parameter for the syn metric syn_metric : string the metric for the syn part (CC, mattes, meansquares, demons) syn_sampling : scalar the nbins or radius parameter for the syn metric reg_iterations : list/tuple of integers vector of iterations for syn. we will set the smoothing and multi-resolution parameters based on the length of this vector. write_composite_transform : boolean Boolean specifying whether or not the composite transform (and its inverse, if it exists) should be written to an hdf5 composite file. This is false by default so that only the transform for each stage is written to file. verbose : boolean request verbose output (useful for debugging) multivariate_extras : additional metrics for multi-metric registration list of additional images and metrics which will trigger the use of multiple metrics in the registration process in the deformable stage. Each multivariate metric needs 5 entries: name of metric, fixed, moving, weight, samplingParam. the list of lists should be of the form ( ( \"nameOfMetric2\", img, img, weight, metricParam ) ). Another example would be ( ( \"MeanSquares\", f2, m2, 0.5, 0 ), ( \"CC\", f2, m2, 0.5, 2 ) ) . This is only compatible with the SyNOnly transformation. kwargs : keyword args extra arguments Returns ------- dict containing follow key/value pairs: `warpedmovout`: Moving image warped to space of fixed image. `warpedfixout`: Fixed image warped to space of moving image. `fwdtransforms`: Transforms to move from moving to fixed image. `invtransforms`: Transforms to move from fixed to moving image. Notes ----- typeofTransform can be one of: - \"Translation\": Translation transformation. - \"Rigid\": Rigid transformation: Only rotation and translation. - \"Similarity\": Similarity transformation: scaling, rotation and translation. - \"QuickRigid\": Rigid transformation: Only rotation and translation. May be useful for quick visualization fixes.' - \"DenseRigid\": Rigid transformation: Only rotation and translation. Employs dense sampling during metric estimation.' - \"BOLDRigid\": Rigid transformation: Parameters typical for BOLD to BOLD intrasubject registration'.' - \"Affine\": Affine transformation: Rigid + scaling. - \"AffineFast\": Fast version of Affine. - \"BOLDAffine\": Affine transformation: Parameters typical for BOLD to BOLD intrasubject registration'.' - \"TRSAA\": translation, rigid, similarity, affine (twice). please set regIterations if using this option. this would be used in cases where you want a really high quality affine mapping (perhaps with mask). - \"ElasticSyN\": Symmetric normalization: Affine + deformable transformation, with mutual information as optimization metric and elastic regularization. - \"SyN\": Symmetric normalization: Affine + deformable transformation, with mutual information as optimization metric. - \"SyNRA\": Symmetric normalization: Rigid + Affine + deformable transformation, with mutual information as optimization metric. - \"SyNOnly\": Symmetric normalization: no initial transformation, with mutual information as optimization metric. Assumes images are aligned by an inital transformation. Can be useful if you want to run an unmasked affine followed by masked deformable registration. - \"SyNCC\": SyN, but with cross-correlation as the metric. - \"SyNabp\": SyN optimized for abpBrainExtraction. - \"SyNBold\": SyN, but optimized for registrations between BOLD and T1 images. - \"SyNBoldAff\": SyN, but optimized for registrations between BOLD and T1 images, with additional affine step. - \"SyNAggro\": SyN, but with more aggressive registration (fine-scale matching and more deformation). Takes more time than SyN. - \"TVMSQ\": time-varying diffeomorphism with mean square metric - \"TVMSQC\": time-varying diffeomorphism with mean square metric for very large deformation Example ------- >>> import ants >>> fi = ants.image_read(ants.get_ants_data('r16')) >>> mi = ants.image_read(ants.get_ants_data('r64')) >>> fi = ants.resample_image(fi, (60,60), 1, 0) >>> mi = ants.resample_image(mi, (60,60), 1, 0) >>> mytx = ants.registration(fixed=fi, moving=mi, type_of_transform = 'SyN' )", "response": "def registration(fixed,\n                 moving,\n                 type_of_transform='SyN',\n                 initial_transform=None,\n                 outprefix='',\n                 mask=None,\n                 grad_step=0.2,\n                 flow_sigma=3,\n                 total_sigma=0,\n                 aff_metric='mattes',\n                 aff_sampling=32,\n                 syn_metric='mattes',\n                 syn_sampling=32,\n                 reg_iterations=(40,20,0),\n                 write_composite_transform=False,\n                 verbose=False,\n                 multivariate_extras=None,\n                 **kwargs):\n    \"\"\"\n    Register a pair of images either through the full or simplified\n    interface to the ANTs registration method.\n\n    ANTsR function: `antsRegistration`\n\n    Arguments\n    ---------\n    fixed : ANTsImage\n        fixed image to which we register the moving image.\n\n    moving : ANTsImage\n        moving image to be mapped to fixed space.\n\n    type_of_transform : string\n        A linear or non-linear registration type. Mutual information metric by default.\n        See Notes below for more.\n\n    initial_transform : list of strings (optional)\n        transforms to prepend\n\n    outprefix : string\n        output will be named with this prefix.\n\n    mask : ANTsImage (optional)\n        mask the registration.\n\n    grad_step : scalar\n        gradient step size (not for all tx)\n\n    flow_sigma : scalar\n        smoothing for update field\n\n    total_sigma : scalar\n        smoothing for total field\n\n    aff_metric : string\n        the metric for the affine part (GC, mattes, meansquares)\n\n    aff_sampling : scalar\n        the nbins or radius parameter for the syn metric\n\n    syn_metric : string\n        the metric for the syn part (CC, mattes, meansquares, demons)\n\n    syn_sampling : scalar\n        the nbins or radius parameter for the syn metric\n\n    reg_iterations : list/tuple of integers\n        vector of iterations for syn. we will set the smoothing and multi-resolution parameters based on the length of this vector.\n\n    write_composite_transform : boolean\n        Boolean specifying whether or not the composite transform (and its inverse, if it exists) should be written to an hdf5 composite file. This is false by default so that only the transform for each stage is written to file.\n\n    verbose : boolean\n        request verbose output (useful for debugging)\n\n    multivariate_extras : additional metrics for multi-metric registration\n        list of additional images and metrics which will\n        trigger the use of multiple metrics in the registration\n        process in the deformable stage. Each multivariate metric needs 5\n        entries: name of metric, fixed, moving, weight,\n        samplingParam. the list of lists should be of the form ( (\n        \"nameOfMetric2\", img, img, weight, metricParam ) ). Another\n        example would be  ( ( \"MeanSquares\", f2, m2, 0.5, 0\n          ), ( \"CC\", f2, m2, 0.5, 2 ) ) .  This is only compatible\n        with the SyNOnly transformation.\n\n\n    kwargs : keyword args\n        extra arguments\n\n    Returns\n    -------\n    dict containing follow key/value pairs:\n        `warpedmovout`: Moving image warped to space of fixed image.\n        `warpedfixout`: Fixed image warped to space of moving image.\n        `fwdtransforms`: Transforms to move from moving to fixed image.\n        `invtransforms`: Transforms to move from fixed to moving image.\n\n    Notes\n    -----\n    typeofTransform can be one of:\n        - \"Translation\": Translation transformation.\n        - \"Rigid\": Rigid transformation: Only rotation and translation.\n        - \"Similarity\": Similarity transformation: scaling, rotation and translation.\n        - \"QuickRigid\": Rigid transformation: Only rotation and translation.\n                        May be useful for quick visualization fixes.'\n        - \"DenseRigid\": Rigid transformation: Only rotation and translation.\n                        Employs dense sampling during metric estimation.'\n        - \"BOLDRigid\": Rigid transformation: Parameters typical for BOLD to\n                        BOLD intrasubject registration'.'\n        - \"Affine\": Affine transformation: Rigid + scaling.\n        - \"AffineFast\": Fast version of Affine.\n        - \"BOLDAffine\": Affine transformation: Parameters typical for BOLD to\n                        BOLD intrasubject registration'.'\n        - \"TRSAA\": translation, rigid, similarity, affine (twice). please set\n                    regIterations if using this option. this would be used in\n                    cases where you want a really high quality affine mapping\n                    (perhaps with mask).\n        - \"ElasticSyN\": Symmetric normalization: Affine + deformable\n                        transformation, with mutual information as optimization\n                        metric and elastic regularization.\n        - \"SyN\": Symmetric normalization: Affine + deformable transformation,\n                    with mutual information as optimization metric.\n        - \"SyNRA\": Symmetric normalization: Rigid + Affine + deformable\n                    transformation, with mutual information as optimization metric.\n        - \"SyNOnly\": Symmetric normalization: no initial transformation,\n                    with mutual information as optimization metric. Assumes\n                    images are aligned by an inital transformation. Can be\n                    useful if you want to run an unmasked affine followed by\n                    masked deformable registration.\n        - \"SyNCC\": SyN, but with cross-correlation as the metric.\n        - \"SyNabp\": SyN optimized for abpBrainExtraction.\n        - \"SyNBold\": SyN, but optimized for registrations between BOLD and T1 images.\n        - \"SyNBoldAff\": SyN, but optimized for registrations between BOLD\n                        and T1 images, with additional affine step.\n        - \"SyNAggro\": SyN, but with more aggressive registration\n                        (fine-scale matching and more deformation).\n                        Takes more time than SyN.\n        - \"TVMSQ\": time-varying diffeomorphism with mean square metric\n        - \"TVMSQC\": time-varying diffeomorphism with mean square metric for very large deformation\n\n    Example\n    -------\n    >>> import ants\n    >>> fi = ants.image_read(ants.get_ants_data('r16'))\n    >>> mi = ants.image_read(ants.get_ants_data('r64'))\n    >>> fi = ants.resample_image(fi, (60,60), 1, 0)\n    >>> mi = ants.resample_image(mi, (60,60), 1, 0)\n    >>> mytx = ants.registration(fixed=fi, moving=mi, type_of_transform = 'SyN' )\n    \"\"\"\n    if isinstance(fixed, list) and (moving is None):\n        processed_args = utils._int_antsProcessArguments(fixed)\n        libfn = utils.get_lib_fn('antsRegistration')\n        libfn(processed_args)\n        return 0\n\n    if type_of_transform == '':\n        type_of_transform = 'SyN'\n\n    if isinstance(type_of_transform, (tuple,list)) and (len(type_of_transform) == 1):\n        type_of_transform = type_of_transform[0]\n\n    if (outprefix == '') or len(outprefix) == 0:\n        outprefix = mktemp()\n\n    if (np.sum(np.isnan(fixed.numpy())) > 0):\n        raise ValueError('fixed image has NaNs - replace these')\n    if (np.sum(np.isnan(moving.numpy())) > 0):\n        raise ValueError('moving image has NaNs - replace these')\n    #----------------------------\n\n    args = [fixed, moving, type_of_transform, outprefix]\n    myl = 0\n    myf_aff = '6x4x2x1'\n    mys_aff = '3x2x1x0'\n    metsam = 0.2\n\n    myiterations = '2100x1200x1200x10'\n    if (type_of_transform == 'AffineFast'):\n        type_of_transform = 'Affine'\n        myiterations = '2100x1200x0x0'\n    if (type_of_transform == 'BOLDAffine'):\n        type_of_transform = 'Affine'\n        myf_aff='2x1'\n        mys_aff='1x0'\n        myiterations = '100x20'\n        myl=1\n    if (type_of_transform == 'QuickRigid'):\n        type_of_transform = 'Rigid'\n        myiterations = '20x20x0x0'\n    if (type_of_transform == 'DenseRigid'):\n        type_of_transform = 'Rigid'\n        metsam = 0.8\n    if (type_of_transform == 'BOLDRigid'):\n        type_of_transform = 'Rigid'\n        myf_aff='2x1'\n        mys_aff='1x0'\n        myiterations = '100x20'\n        myl=1\n\n    mysyn = 'SyN[%f,%f,%f]' % (grad_step, flow_sigma, total_sigma)\n    itlen = len(reg_iterations)# NEED TO CHECK THIS\n    if itlen == 0:\n        smoothingsigmas = 0\n        shrinkfactors = 1\n        synits = reg_iterations\n    else:\n        smoothingsigmas = np.arange(0, itlen)[::-1].astype('float32') # NEED TO CHECK THIS\n        shrinkfactors = 2**smoothingsigmas\n        shrinkfactors = shrinkfactors.astype('int')\n        smoothingsigmas = 'x'.join([str(ss)[0] for ss in smoothingsigmas])\n        shrinkfactors = 'x'.join([str(ss) for ss in shrinkfactors])\n        synits = 'x'.join([str(ri) for ri in reg_iterations])\n\n    if not isinstance(fixed, str):\n        if isinstance(fixed, iio.ANTsImage) and isinstance(moving, iio.ANTsImage):\n            inpixeltype = fixed.pixeltype\n            ttexists = False\n            allowable_tx =  {'SyNBold','SyNBoldAff', 'ElasticSyN','SyN','SyNRA',\n                            'SyNOnly','SyNAggro','SyNCC','TRSAA','SyNabp','SyNLessAggro',\n                            'TVMSQ','TVMSQC','Rigid','Similarity','Translation','Affine',\n                            'AffineFast','BOLDAffine','QuickRigid','DenseRigid','BOLDRigid'}\n            ttexists = type_of_transform in allowable_tx\n            if not ttexists:\n                raise ValueError('`type_of_transform` does not exist')\n\n            if ttexists:\n                initx = initial_transform\n                #if isinstance(initx, ANTsTransform):\n                    #tempTXfilename = tempfile( fileext = '.mat' )\n                    #initx = invertAntsrTransform( initialTransform )\n                    #initx = invertAntsrTransform( initx )\n                    #writeAntsrTransform( initx, tempTXfilename )\n                    #initx = tempTXfilename\n                moving = moving.clone('float')\n                fixed = fixed.clone('float')\n                warpedfixout = moving.clone()\n                warpedmovout = fixed.clone()\n                f = utils.get_pointer_string(fixed)\n                m = utils.get_pointer_string(moving)\n                wfo = utils.get_pointer_string(warpedfixout)\n                wmo = utils.get_pointer_string(warpedmovout)\n                if mask is not None:\n                    mask_scale = mask - mask.min()\n                    mask_scale = mask_scale / mask_scale.max() * 255.\n                    charmask = mask_scale.clone('unsigned char')\n                    maskopt = '[%s,NA]' % (utils.get_pointer_string(charmask))\n                else:\n                    maskopt = None\n                if initx is None:\n                    initx = '[%s,%s,1]' % (f, m)\n                # ------------------------------------------------------------\n                if type_of_transform == 'SyNBold':\n                    args = ['-d', str(fixed.dimension),\n                        '-r', initx,\n                        '-m', '%s[%s,%s,1,%s,regular,0.2]' % (aff_metric, f, m, aff_sampling),\n                        '-t', 'Rigid[0.25]',\n                        '-c', '[1200x1200x100,1e-6,5]',\n                        '-s', '2x1x0',\n                        '-f', '4x2x1',\n                        '-x', '[NA,NA]',\n                        '-m', '%s[%s,%s,1,%s]' % (syn_metric, f, m, syn_sampling),\n                        '-t', mysyn,\n                        '-c', '[%s,1e-7,8]' % synits,\n                        '-s', smoothingsigmas,\n                        '-f', shrinkfactors,\n                        '-u', '1',\n                        '-z', '1',\n                        '-l', myl,\n                        '-o', '[%s,%s,%s]' % (outprefix, wmo, wfo)]\n                    if maskopt is not None:\n                        args.append('-x')\n                        args.append(maskopt)\n                    else:\n                        args.append('-x')\n                        args.append('[NA,NA]')\n                # ------------------------------------------------------------\n                elif type_of_transform == 'SyNBoldAff':\n                    args = ['-d', str(fixed.dimension),\n                        '-r', initx,\n                        '-m', '%s[%s,%s,1,%s,regular,0.2]' % (aff_metric, f, m, aff_sampling),\n                        '-t', 'Rigid[0.25]',\n                        '-c', '[1200x1200x100,1e-6,5]',\n                        '-s', '2x1x0',\n                        '-f', '4x2x1',\n                        '-x', '[NA,NA]',\n                        '-m', '%s[%s,%s,1,%s,regular,0.2]' % (aff_metric, f, m, aff_sampling),\n                        '-t', 'Affine[0.25]',\n                        '-c', '[200x20,1e-6,5]',\n                        '-s', '1x0',\n                        '-f', '2x1',\n                        '-x', '[NA,NA]',\n                        '-m', '%s[%s,%s,1,%s]' % (syn_metric, f, m, syn_sampling),\n                        '-t', mysyn,\n                        '-c', '[%s,1e-7,8]' % (synits),\n                        '-s', smoothingsigmas,\n                        '-f', shrinkfactors,\n                        '-u', '1',\n                        '-z', '1',\n                        '-l', myl,\n                        '-o', '[%s,%s,%s]' % (outprefix, wmo, wfo)]\n                    if maskopt is not None:\n                        args.append('-x')\n                        args.append(maskopt)\n                    else:\n                        args.append('-x')\n                        args.append('[NA,NA]')\n                # ------------------------------------------------------------\n                elif type_of_transform == 'ElasticSyN':\n                    args = ['-d', str(fixed.dimension),\n                        '-r', initx,\n                        '-m', '%s[%s,%s,1,%s,regular,0.2]' % (aff_metric, f, m, aff_sampling),\n                        '-t', 'Affine[0.25]',\n                        '-c', '2100x1200x200x0',\n                        '-s', '3x2x1x0',\n                        '-f', '4x2x2x1',\n                        '-x', '[NA,NA]',\n                        '-m', '%s[%s,%s,1,%s]' % (syn_metric, f, m, syn_sampling),\n                        '-t', mysyn,\n                        '-c', '[%s,1e-7,8]' % (synits),\n                        '-s', smoothingsigmas,\n                        '-f', shrinkfactors,\n                        '-u', '1',\n                        '-z', '1',\n                        '-l', myl,\n                        '-o', '[%s,%s,%s]' % (outprefix, wmo, wfo)]\n                    if maskopt is not None:\n                        args.append('-x')\n                        args.append(maskopt)\n                    else:\n                        args.append('-x')\n                        args.append('[NA,NA]')\n                # ------------------------------------------------------------\n                elif type_of_transform == 'SyN':\n                    args = ['-d', str(fixed.dimension),\n                        '-r', initx,\n                        '-m', '%s[%s,%s,1,%s,regular,0.2]' % (aff_metric, f, m, aff_sampling),\n                        '-t', 'Affine[0.25]',\n                        '-c', '2100x1200x1200x0',\n                        '-s', '3x2x1x0',\n                        '-f', '4x2x2x1',\n                        '-x', '[NA,NA]',\n                        '-m', '%s[%s,%s,1,%s]' % (syn_metric, f, m, syn_sampling),\n                        '-t', mysyn,\n                        '-c', '[%s,1e-7,8]' % synits,\n                        '-s', smoothingsigmas,\n                        '-f', shrinkfactors,\n                        '-u', '1',\n                        '-z', '1',\n                        '-l', myl,\n                        '-o', '[%s,%s,%s]' % (outprefix, wmo, wfo)]\n                    if maskopt is not None:\n                        args.append('-x')\n                        args.append(maskopt)\n                    else:\n                        args.append('-x')\n                        args.append('[NA,NA]')\n                # ------------------------------------------------------------\n                elif type_of_transform == 'SyNRA':\n                    args = ['-d', str(fixed.dimension),\n                            '-r', initx,\n                            '-m', '%s[%s,%s,1,%s,regular,0.2]' % (aff_metric, f, m, aff_sampling),\n                            '-t', 'Rigid[0.25]',\n                            '-c', '2100x1200x1200x0',\n                            '-s', '3x2x1x0',\n                            '-f', '4x2x2x1',\n                            '-x', '[NA,NA]',\n                            '-m', '%s[%s,%s,1,%s,regular,0.2]' % (aff_metric, f, m, aff_sampling),\n                            '-t', 'Affine[0.25]',\n                            '-c', '2100x1200x1200x0',\n                            '-s', '3x2x1x0',\n                            '-f', '4x2x2x1',\n                            '-x', '[NA,NA]',\n                            '-m', '%s[%s,%s,1,%s]' % (syn_metric, f, m, syn_sampling),\n                            '-t', mysyn,\n                            '-c', '[%s,1e-7,8]' % synits,\n                            '-s', smoothingsigmas,\n                            '-f', shrinkfactors,\n                            '-u', '1',\n                            '-z', '1',\n                            '-l', myl,\n                            '-o', '[%s,%s,%s]' % (outprefix, wmo, wfo)]\n                    if maskopt is not None:\n                        args.append('-x')\n                        args.append(maskopt)\n                    else:\n                        args.append('-x')\n                        args.append('[NA,NA]')\n                # ------------------------------------------------------------\n                elif type_of_transform == 'SyNOnly':\n                    args = ['-d', str(fixed.dimension),\n                            '-r', initx,\n                            '-m', '%s[%s,%s,1,%s]' % (syn_metric, f, m, syn_sampling),\n                            '-t', mysyn,\n                            '-c', '[%s,1e-7,8]' % synits,\n                            '-s', smoothingsigmas,\n                            '-f', shrinkfactors,\n                            '-u', '1',\n                            '-z', '1',\n                            '-l', myl,\n                            '-o', '[%s,%s,%s]' % (outprefix, wmo, wfo)]\n                    if multivariate_extras is not None:\n                        metrics = [ ]\n                        for kk in range( len( multivariate_extras ) ):\n                            metrics.append( '-m' )\n                            metricname = multivariate_extras[kk][0]\n                            metricfixed = utils.get_pointer_string(multivariate_extras[kk][1])\n                            metricmov = utils.get_pointer_string(multivariate_extras[kk][2])\n                            metricWeight = multivariate_extras[kk][3]\n                            metricSampling = multivariate_extras[kk][4]\n                            metricString = \"%s[%s,%s,%s,%s]\" %  (metricname,metricfixed,metricmov,metricWeight,metricSampling)\n                            metrics.append( metricString )\n                        args = ['-d', str(fixed.dimension),\n                                 '-r', initx,\n                                 '-m', '%s[%s,%s,1,%s]' % (syn_metric, f, m, syn_sampling) ]\n                        args1= ['-t', mysyn,\n                                '-c', '[%s,1e-7,8]' % synits,\n                                '-s', smoothingsigmas,\n                                '-f', shrinkfactors,\n                                '-u', '1',\n                                '-z', '1',\n                                '-l', myl,\n                                '-o', '[%s,%s,%s]' % (outprefix, wmo, wfo)]\n                        for kk in range( len( metrics ) ):\n                            args.append( metrics[kk] )\n                        for kk in range( len( args1 ) ):\n                            args.append( args1[kk] )\n                    if maskopt is not None:\n                        args.append('-x')\n                        args.append(maskopt)\n                    else:\n                        args.append('-x')\n                        args.append('[NA,NA]')\n                # ------------------------------------------------------------\n                elif type_of_transform == 'SyNAggro':\n                    args = ['-d', str(fixed.dimension),\n                            '-r', initx,\n                            '-m', '%s[%s,%s,1,%s,regular,0.2]' % (aff_metric, f, m, aff_sampling),\n                            '-t', 'Affine[0.25]',\n                            '-c', '2100x1200x1200x100',\n                            '-s', '3x2x1x0',\n                            '-f', '4x2x2x1',\n                            '-x', '[NA,NA]',\n                            '-m', '%s[%s,%s,1,%s]' % (syn_metric, f, m, syn_sampling),\n                            '-t', mysyn,\n                            '-c', '[%s,1e-7,8]' % synits,\n                            '-s', smoothingsigmas,\n                            '-f', shrinkfactors,\n                            '-u', '1',\n                            '-z', '1',\n                            '-l', myl,\n                            '-o', '[%s,%s,%s]' % (outprefix, wmo, wfo)]\n                    if maskopt is not None:\n                        args.append('-x')\n                        args.append(maskopt)\n                    else:\n                        args.append('-x')\n                        args.append('[NA,NA]')\n                # ------------------------------------------------------------\n                elif type_of_transform == 'SyNCC':\n                    syn_metric = 'CC'\n                    syn_sampling = 4\n                    synits = '2100x1200x1200x20'\n                    smoothingsigmas = '3x2x1x0'\n                    shrinkfactors = '4x3x2x1'\n                    mysyn = 'SyN[0.15,3,0]'\n\n                    args = ['-d', str(fixed.dimension),\n                            '-r', initx,\n                            '-m', '%s[%s,%s,1,%s,regular,0.2]' % (aff_metric, f, m, aff_sampling),\n                            '-t', 'Rigid[1]',\n                            '-c', '2100x1200x1200x0',\n                            '-s', '3x2x1x0',\n                            '-f', '4x4x2x1',\n                            '-x', '[NA,NA]',\n                            '-m', '%s[%s,%s,1,%s,regular,0.2]' % (aff_metric, f, m, aff_sampling),\n                            '-t', 'Affine[1]',\n                            '-c', '1200x1200x100',\n                            '-s', '2x1x0',\n                            '-f', '4x2x1',\n                            '-x', '[NA,NA]',\n                            '-m', '%s[%s,%s,1,%s]' % (syn_metric, f, m, syn_sampling),\n                            '-t', mysyn,\n                            '-c', '[%s,1e-7,8]' % synits,\n                            '-s', smoothingsigmas,\n                            '-f', shrinkfactors,\n                            '-u', '1',\n                            '-z', '1',\n                            '-l', myl,\n                            '-o', '[%s,%s,%s]' % (outprefix, wmo, wfo)]\n                    if maskopt is not None:\n                        args.append('-x')\n                        args.append(maskopt)\n                    else:\n                        args.append('-x')\n                        args.append('[NA,NA]')\n                # ------------------------------------------------------------\n                elif type_of_transform == 'TRSAA':\n                    itlen = len( reg_iterations )\n                    itlenlow = round( itlen/2 + 0.0001 )\n                    dlen = itlen - itlenlow\n                    _myconvlow = [2000]*itlenlow + [0]*dlen\n                    myconvlow = 'x'.join([str(mc) for mc in _myconvlow])\n                    myconvhi = 'x'.join([str(r) for r in reg_iterations])\n                    myconvhi = '[%s,1.e-7,10]' % myconvhi\n                    args = ['-d', str(fixed.dimension),\n                            '-r', initx,\n                            '-m', '%s[%s,%s,1,%s,regular,0.3]' % (aff_metric, f, m, aff_sampling),\n                            '-t', 'Translation[1]',\n                            '-c', myconvlow,\n                            '-s', smoothingsigmas,\n                            '-f', shrinkfactors,\n                            '-x', '[NA,NA]',\n                            '-m', '%s[%s,%s,1,%s,regular,0.3]' % (aff_metric, f, m, aff_sampling),\n                            '-t', 'Rigid[1]',\n                            '-c', myconvlow,\n                            '-s', smoothingsigmas,\n                            '-f', shrinkfactors,\n                            '-x', '[NA,NA]',\n                            '-m', '%s[%s,%s,1,%s,regular,0.3]' % (aff_metric, f, m, aff_sampling),\n                            '-t', 'Similarity[1]',\n                            '-c', myconvlow,\n                            '-s', smoothingsigmas,\n                            '-f', shrinkfactors,\n                            '-x', '[NA,NA]',\n                            '-m', '%s[%s,%s,1,%s,regular,0.3]' % (aff_metric, f, m, aff_sampling),\n                            '-t', 'Affine[1]',\n                            '-c', myconvhi,\n                            '-s', smoothingsigmas,\n                            '-f', shrinkfactors,\n                            '-x', '[NA,NA]',\n                            '-m', '%s[%s,%s,1,%s,regular,0.3]' % (aff_metric, f, m, aff_sampling),\n                            '-t', 'Affine[1]',\n                            '-c', myconvhi,\n                            '-s', smoothingsigmas,\n                            '-f', shrinkfactors,\n                            '-u', '1',\n                            '-z', '1',\n                            '-l', myl,\n                            '-o', '[%s,%s,%s]' % (outprefix, wmo, wfo)]\n                    if maskopt is not None:\n                        args.append('-x')\n                        args.append(maskopt)\n                    else:\n                        args.append('-x')\n                        args.append('[NA,NA]')\n                # ------------------------------------------------------------s\n                elif type_of_transform == 'SyNabp':\n                    args = ['-d', str(fixed.dimension),\n                            '-r', initx,\n                            '-m', 'mattes[%s,%s,1,32,regular,0.25]' % (f, m),\n                            '-t', 'Rigid[0.1]',\n                            '-c', '1000x500x250x100',\n                            '-s', '4x2x1x0',\n                            '-f', '8x4x2x1',\n                            '-x', '[NA,NA]',\n                            '-m', 'mattes[%s,%s,1,32,regular,0.25]' % (f, m),\n                            '-t', 'Affine[0.1]',\n                            '-c', '1000x500x250x100',\n                            '-s', '4x2x1x0',\n                            '-f', '8x4x2x1',\n                            '-x', '[NA,NA]',\n                            '-m', 'CC[%s,%s,0.5,4]' % (f,m),\n                            '-t', 'SyN[0.1,3,0]',\n                            '-c', '50x10x0',\n                            '-s', '2x1x0',\n                            '-f', '4x2x1',\n                            '-u', '1',\n                            '-z', '1',\n                            '-l', myl,\n                            '-o', '[%s,%s,%s]' % (outprefix, wmo, wfo)]\n                    if maskopt is not None:\n                        args.append('-x')\n                        args.append(maskopt)\n                    else:\n                        args.append('-x')\n                        args.append('[NA,NA]')\n                # ------------------------------------------------------------\n                elif type_of_transform == 'SyNLessAggro':\n                    args = ['-d', str(fixed.dimension),\n                            '-r', initx,\n                            '-m', '%s[%s,%s,1,%s,regular,0.2]' % (aff_metric, f, m, aff_sampling),\n                            '-t', 'Affine[0.25]',\n                            '-c', '2100x1200x1200x100',\n                            '-s', '3x2x1x0',\n                            '-f', '4x2x2x1',\n                            '-x', '[NA,NA]',\n                            '-m', '%s[%s,%s,1,%s]' % (syn_metric, f, m, syn_sampling),\n                            '-t', mysyn,\n                            '-c', '[%s,1e-7,8]' % synits,\n                            '-s', smoothingsigmas,\n                            '-f', shrinkfactors,\n                            '-u', '1',\n                            '-z', '1',\n                            '-l', myl,\n                            '-o', '[%s,%s,%s]' % (outprefix, wmo, wfo)]\n                    if maskopt is not None:\n                        args.append('-x')\n                        args.append(maskopt)\n                    else:\n                        args.append('-x')\n                        args.append('[NA,NA]')\n                # ------------------------------------------------------------\n                elif type_of_transform == 'TVMSQ':\n                    if grad_step is None:\n                        grad_step = 1.0\n\n                    tvtx = 'TimeVaryingVelocityField[%s, 4, 0.0,0.0, 0.5,0 ]' % str(grad_step)\n                    args = ['-d', str(fixed.dimension),\n                            # '-r', initx,\n                            '-m', '%s[%s,%s,1,%s]' % (syn_metric, f, m, syn_sampling),\n                            '-t', tvtx,\n                            '-c', '[%s,1e-7,8]' % synits,\n                            '-s', smoothingsigmas,\n                            '-f', shrinkfactors,\n                            '-u', '1',\n                            '-z', '1',\n                            '-l', myl,\n                            '-o', '[%s,%s,%s]' % (outprefix, wmo, wfo)]\n                    if maskopt is not None:\n                        args.append('-x')\n                        args.append(maskopt)\n                    else:\n                        args.append('-x')\n                        args.append('[NA,NA]')\n                # ------------------------------------------------------------\n                elif type_of_transform == 'TVMSQC':\n                    if grad_step is None:\n                        grad_step = 2.0\n\n                    tvtx = 'TimeVaryingVelocityField[%s, 8, 1.0,0.0, 0.05,0 ]' % str(grad_step)\n                    args = ['-d', str(fixed.dimension),\n                            # '-r', initx,\n                            '-m', 'demons[%s,%s,0.5,0]' % (f, m),\n                            '-m', 'meansquares[%s,%s,1,0]' % (f, m),\n                            '-t', tvtx,\n                            '-c', '[1200x1200x100x20x0,0,5]',\n                            '-s', '8x6x4x2x1vox',\n                            '-f', '8x6x4x2x1',\n                            '-u', '1',\n                            '-z', '1',\n                            '-l', myl,\n                            '-o', '[%s,%s,%s]' % (outprefix, wmo, wfo)]\n                    if maskopt is not None:\n                        args.append('-x')\n                        args.append(maskopt)\n                    else:\n                        args.append('-x')\n                        args.append('[NA,NA]')\n                # ------------------------------------------------------------\n                elif (type_of_transform == 'Rigid') or (type_of_transform == 'Similarity') or \\\n                     (type_of_transform == 'Translation') or (type_of_transform == 'Affine'):\n                    args = ['-d', str(fixed.dimension),\n                            '-r', initx,\n                            '-m', '%s[%s,%s,1,%s,regular,%s]' % (aff_metric, f, m, aff_sampling, metsam),\n                            '-t', '%s[0.25]' % type_of_transform,\n                            '-c', myiterations,\n                            '-s', mys_aff,\n                            '-f', myf_aff,\n                            '-u', '1',\n                            '-z', '1',\n                            '-l', myl,\n                            '-o', '[%s,%s,%s]' % (outprefix, wmo, wfo)]\n                    if maskopt is not None:\n                        args.append('-x')\n                        args.append(maskopt)\n                    else:\n                        args.append('-x')\n                        args.append('[NA,NA]')\n                # ------------------------------------------------------------\n                args.append('--float')\n                args.append('1')\n                args.append('--write-composite-transform')\n                args.append( write_composite_transform * 1 )\n                if verbose:\n                    args.append('-v')\n                    args.append('1')\n\n                processed_args = utils._int_antsProcessArguments(args)\n                libfn = utils.get_lib_fn('antsRegistration')\n                libfn(processed_args)\n                afffns = glob.glob(outprefix+'*'+'[0-9]GenericAffine.mat')\n                fwarpfns = glob.glob(outprefix+'*'+'[0-9]Warp.nii.gz')\n                iwarpfns = glob.glob(outprefix+'*'+'[0-9]InverseWarp.nii.gz')\n                #print(afffns, fwarpfns, iwarpfns)\n                if len(afffns) == 0:\n                    afffns = ''\n                if len(fwarpfns) == 0:\n                    fwarpfns = ''\n                if len(iwarpfns) == 0:\n                    iwarpfns = ''\n\n                alltx = sorted(glob.glob(outprefix+'*'+'[0-9]*'))\n                findinv = np.where([re.search('[0-9]InverseWarp.nii.gz',ff) for ff in alltx])[0]\n                findfwd = np.where([re.search('[0-9]Warp.nii.gz', ff) for ff in alltx])[0]\n                if len(findinv) > 0:\n                    fwdtransforms = list(reversed([ff for idx,ff in enumerate(alltx) if idx !=findinv[0]]))\n                    invtransforms = [ff for idx,ff in enumerate(alltx) if idx!=findfwd[0]]\n                else:\n                    fwdtransforms = list(reversed(alltx))\n                    invtransforms = alltx\n\n                if write_composite_transform:\n                    fwdtransforms = outprefix + 'Composite.h5'\n                    invtransforms = outprefix + 'InverseComposite.h5'\n\n                return {\n                    'warpedmovout': warpedmovout.clone(inpixeltype),\n                    'warpedfixout': warpedfixout.clone(inpixeltype),\n                    'fwdtransforms': fwdtransforms,\n                    'invtransforms': invtransforms\n                }\n    else:\n        args.append('--float')\n        args.append('1')\n        args.append('--write-composite-transform')\n        args.append( write_composite_transform * 1 )\n        if verbose:\n            args.append('-v')\n            args.append('1')\n            processed_args = utils._int_antsProcessArguments(args)\n            libfn = utils.get_lib_fn('antsRegistration')\n            libfn(processed_args)\n            return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef motion_correction(\n                 image,\n                 fixed=None,\n                 type_of_transform=\"Rigid\",\n                 mask=None,\n                 fdOffset = 50,\n                 verbose = False,\n                 **kwargs):\n    \"\"\"\n    Correct time-series data for motion.\n\n    ANTsR function: `antsrMotionCalculation`\n\n    Arguments\n    ---------\n        image: antsImage, usually ND where D=4.\n\n        fixed: Fixed image to register all timepoints to.  If not provided,\n            mean image is used.\n\n        type_of_transform : string\n            A linear or non-linear registration type. Mutual information metric and rigid transformation by default.\n            See ants registration for details.\n\n        mask: mask for image (ND-1).  If not provided, estimated from data.\n\n        fdOffset: offset value to use in framewise displacement calculation\n\n        verbose: boolean\n\n        kwargs: keyword args\n            extra arguments - these extra arguments will control the details of registration that is performed. see ants registration for more.\n\n    Returns\n    -------\n    dict containing follow key/value pairs:\n        `motion_corrected`: Moving image warped to space of fixed image.\n        `motion_parameters`: transforms for each image in the time series.\n        `FD`: Framewise displacement generalized for arbitrary transformations.\n\n    Notes\n    -----\n    Control extra arguments via kwargs. see ants.registration for details.\n\n    Example\n    -------\n    >>> import ants\n    >>> fi = ants.image_read(ants.get_ants_data('ch2'))\n    >>> mytx = ants.motion_correction( fi )\n    \"\"\"\n    idim = image.dimension\n    ishape = image.shape\n    nTimePoints = ishape[ idim - 1 ]\n    if fixed is None:\n        wt = 1.0 / nTimePoints\n        fixed = utils.slice_image( image, axis = idim - 1, idx = 0) * 0\n        for k in range( nTimePoints ):\n            temp = utils.slice_image( image, axis = idim - 1, idx = k )\n            fixed = fixed + temp * wt\n    if mask is None:\n        mask = utils.get_mask( fixed )\n    FD = np.zeros( nTimePoints )\n    motion_parameters = list()\n    motion_corrected = list()\n    centerOfMass = mask.get_center_of_mass( )\n    npts = pow( 2, idim - 1 )\n    pointOffsets = np.zeros( ( npts, idim - 1 ) )\n    myrad = np.ones( idim - 1 ).astype(int).tolist()\n    mask1vals = np.zeros( int( mask.sum() ) )\n    mask1vals[ round( len(mask1vals)/2 ) ] = 1\n    mask1 = core.make_image( mask, mask1vals )\n    myoffsets = utils.get_neighborhood_in_mask(\n      mask1, mask1, radius=myrad, spatial_info=True )['offsets']\n\n    mycols = list('xy')\n    if ( idim-1 == 3 ):\n        mycols = list('xyz')\n    useinds = list()\n    for k in range( myoffsets.shape[0] ):\n        if ( abs(myoffsets[k,:]).sum() == ( idim - 2 ) ):\n            useinds.append( k )\n        myoffsets[k,:] = myoffsets[k,:] * fdOffset / 2.0 + centerOfMass\n    fdpts = pd.DataFrame(data=myoffsets[useinds,:],columns=mycols)\n    if verbose:\n        print( \"Progress:\" )\n    counter = 0\n    for k in range( nTimePoints ):\n        mycount = round( k / nTimePoints * 100 )\n        if verbose and mycount == counter:\n            counter = counter + 10\n            print( mycount, end = \"%.\", flush=True )\n        temp = utils.slice_image( image, axis = idim - 1, idx = k )\n        if ( temp.numpy().var() > 0 ):\n            myreg = registration( fixed, temp,\n              type_of_transform = type_of_transform,\n              mask = mask,\n              **kwargs )\n            fdptsTxI = apply_transforms_to_points( idim - 1, fdpts, myreg[ 'fwdtransforms' ] )\n            if k > 0 and motion_parameters[ k - 1 ] != \"NA\":\n                fdptsTxIminus1 = apply_transforms_to_points( idim - 1, fdpts, motion_parameters[ k - 1 ] )\n            else:\n                fdptsTxIminus1 = fdptsTxI\n            # take the absolute value, then the mean across columns, then the sum\n            FD[ k ] = (fdptsTxIminus1-fdptsTxI).abs().mean().sum()\n            motion_parameters.append( myreg[ 'fwdtransforms' ] )\n            motion_corrected.append( myreg[ 'warpedmovout' ] )\n        else:\n            motion_parameters.append( \"NA\" )\n            motion_corrected.append( temp )\n\n    if verbose:\n        print(\"Done\")\n    return {\n        'motion_corrected': utils.list_to_ndimage( image, motion_corrected ),\n        'motion_parameters': motion_parameters,\n        'FD': FD\n        }", "response": "Calculate motion correction for an image."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget neighborhoods for voxels within mask. This converts a scalar image to a matrix with rows that contain neighbors around a center voxel ANTsR function: `getNeighborhoodInMask` Arguments --------- image : ANTsImage image to get values from mask : ANTsImage image indicating which voxels to examine. Each voxel > 0 will be used as the center of a neighborhood radius : tuple/list array of values for neighborhood radius (in voxels) physical_coordinates : boolean whether voxel indices and offsets should be in voxel or physical coordinates boundary_condition : string (optional) how to handle voxels in a neighborhood, but not in the mask. None : fill values with `NaN` `image` : use image value, even if not in mask `mean` : use mean of all non-NaN values for that neighborhood spatial_info : boolean whether voxel locations and neighborhood offsets should be returned along with pixel values. get_gradient : boolean whether a matrix of gradients (at the center voxel) should be returned in addition to the value matrix (WIP) Returns ------- if spatial_info is False: if get_gradient is False: ndarray an array of pixel values where the number of rows is the size of the neighborhood and there is a column for each voxel else if get_gradient is True: dictionary w/ following key-value pairs: values : ndarray array of pixel values where the number of rows is the size of the neighborhood and there is a column for each voxel. gradients : ndarray array providing the gradients at the center voxel of each neighborhood else if spatial_info is True: dictionary w/ following key-value pairs: values : ndarray array of pixel values where the number of rows is the size of the neighborhood and there is a column for each voxel. indices : ndarray array provinding the center coordinates for each neighborhood offsets : ndarray array providing the offsets from center for each voxel in a neighborhood Example ------- >>> import ants >>> r16 = ants.image_read(ants.get_ants_data('r16')) >>> mask = ants.get_mask(r16) >>> mat = ants.get_neighborhood_in_mask(r16, mask, radius=(2,2))", "response": "def get_neighborhood_in_mask(image, mask, radius, physical_coordinates=False,\n                            boundary_condition=None, spatial_info=False, get_gradient=False):\n    \"\"\"\n    Get neighborhoods for voxels within mask.\n    \n    This converts a scalar image to a matrix with rows that contain neighbors \n    around a center voxel\n    \n    ANTsR function: `getNeighborhoodInMask`\n\n    Arguments\n    ---------\n    image : ANTsImage\n        image to get values from\n    \n    mask : ANTsImage\n        image indicating which voxels to examine. Each voxel > 0 will be used as the \n        center of a neighborhood\n    \n    radius : tuple/list\n        array of values for neighborhood radius (in voxels)\n    \n    physical_coordinates : boolean\n        whether voxel indices and offsets should be in voxel or physical coordinates\n    \n    boundary_condition : string (optional)\n        how to handle voxels in a neighborhood, but not in the mask.\n            None : fill values with `NaN`\n            `image` : use image value, even if not in mask\n            `mean` : use mean of all non-NaN values for that neighborhood\n    \n    spatial_info : boolean\n        whether voxel locations and neighborhood offsets should be returned along with pixel values.\n    \n    get_gradient : boolean\n        whether a matrix of gradients (at the center voxel) should be returned in \n        addition to the value matrix (WIP)\n\n    Returns\n    -------\n    if spatial_info is False:\n        if get_gradient is False:\n            ndarray\n                an array of pixel values where the number of rows is the size of the \n                neighborhood and there is a column for each voxel\n\n        else if get_gradient is True:\n            dictionary w/ following key-value pairs:\n                values : ndarray\n                    array of pixel values where the number of rows is the size of the \n                    neighborhood and there is a column for each voxel.\n\n                gradients : ndarray\n                    array providing the gradients at the center voxel of each \n                    neighborhood\n        \n    else if spatial_info is True:\n        dictionary w/ following key-value pairs:\n            values : ndarray\n                array of pixel values where the number of rows is the size of the \n                neighborhood and there is a column for each voxel.\n\n            indices : ndarray\n                array provinding the center coordinates for each neighborhood\n\n            offsets : ndarray\n                array providing the offsets from center for each voxel in a neighborhood\n\n    Example\n    -------\n    >>> import ants\n    >>> r16 = ants.image_read(ants.get_ants_data('r16'))\n    >>> mask = ants.get_mask(r16)\n    >>> mat = ants.get_neighborhood_in_mask(r16, mask, radius=(2,2))\n    \"\"\"\n    if not isinstance(image, iio.ANTsImage):\n        raise ValueError('image must be ANTsImage type')\n    if not isinstance(mask, iio.ANTsImage):\n        raise ValueError('mask must be ANTsImage type')\n    if isinstance(radius, (int, float)):\n        radius = [radius]*image.dimension\n    if (not isinstance(radius, (tuple,list))) or (len(radius) != image.dimension):\n        raise ValueError('radius must be tuple or list with length == image.dimension')\n\n    boundary = 0\n    if boundary_condition == 'image':\n        boundary = 1\n    elif boundary_condition == 'mean':\n        boundary = 2\n    \n    libfn = utils.get_lib_fn('getNeighborhoodMatrix%s' % image._libsuffix)\n    retvals = libfn(image.pointer, \n                    mask.pointer, \n                    list(radius),\n                    int(physical_coordinates), \n                    int(boundary),\n                    int(spatial_info),\n                    int(get_gradient))\n\n    if not spatial_info:\n        if get_gradient:\n            retvals['values'] = np.asarray(retvals['values'])\n            retvals['gradients'] = np.asarray(retvals['gradients'])\n        else:\n            retvals = np.asarray(retvals['matrix'])\n    else:\n        retvals['values'] = np.asarray(retvals['values'])\n        retvals['indices'] = np.asarray(retvals['indices'])\n        retvals['offsets'] = np.asarray(retvals['offsets'])\n\n    return retvals"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a hypercube neighborhood at a voxel.", "response": "def get_neighborhood_at_voxel(image, center, kernel, physical_coordinates=False):\n    \"\"\"\n    Get a hypercube neighborhood at a voxel. Get the values in a local \n    neighborhood of an image.\n    \n    ANTsR function: `getNeighborhoodAtVoxel`\n\n    Arguments\n    ---------\n    image : ANTsImage\n        image to get values from.\n    \n    center : tuple/list\n        indices for neighborhood center\n    \n    kernel : tuple/list\n        either a collection of values for neighborhood radius (in voxels) or \n        a binary collection of the same dimension as the image, specifying the shape of the neighborhood to extract\n    \n    physical_coordinates : boolean\n        whether voxel indices and offsets should be in voxel \n        or physical coordinates\n\n    Returns\n    -------\n    dictionary w/ following key-value pairs:\n        values : ndarray\n            array of neighborhood values at the voxel\n\n        indices : ndarray\n            matrix providing the coordinates for each value\n\n    Example\n    -------\n    >>> import ants\n    >>> img = ants.image_read(ants.get_ants_data('r16'))\n    >>> center = (2,2)\n    >>> radius = (3,3)\n    >>> retval = ants.get_neighborhood_at_voxel(img, center, radius)\n    \"\"\"\n    if not isinstance(image, iio.ANTsImage):\n        raise ValueError('image must be ANTsImage type')\n\n    if (not isinstance(center, (tuple,list))) or (len(center) != image.dimension):\n        raise ValueError('center must be tuple or list with length == image.dimension')\n\n    if (not isinstance(kernel, (tuple,list))) or (len(kernel) != image.dimension):\n        raise ValueError('kernel must be tuple or list with length == image.dimension')\n\n    radius = [int((k-1)/2) for k in kernel]\n\n    libfn = utils.get_lib_fn('getNeighborhood%s' % image._libsuffix)\n    retvals = libfn(image.pointer, \n                    list(center), \n                    list(kernel), \n                    list(radius), \n                    int(physical_coordinates))\n    for k in retvals.keys():\n        retvals[k] = np.asarray(retvals[k])\n    return retvals"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_centroids(image, clustparam=0):\n    imagedim = image.dimension\n    if clustparam > 0:\n        mypoints = label_clusters(image, clustparam, max_thresh=1e15)\n    if clustparam == 0:\n        mypoints = image.clone()\n    mypoints = label_stats(mypoints, mypoints)\n    mypoints = mypoints.iloc[1:,:]\n    x = mypoints.x\n    y = mypoints.y\n    \n    if imagedim == 3:\n        z = mypoints.y\n    else:\n        z = np.zeros(mypoints.shape[0])\n\n    if imagedim == 4:\n        t = mypoints.t\n    else:\n        t = np.zeros(mypoints.shape[0])\n\n    centroids = np.stack([x,y,z,t]).T\n    return centroids", "response": "Reduces a variate image to a set of centroids \n    describing the center of each stand - alone non - zero component in the image."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef denoise_image(image, mask=None, shrink_factor=1, p=1, r=3, noise_model='Rician', v=0 ):\n    inpixeltype = image.pixeltype\n    outimage = image.clone('float')\n\n    mydim = image.dimension\n\n    if mask is None:\n        myargs = {\n            'd': mydim,\n            'i': image,\n            'n': noise_model,\n            's': int(shrink_factor),\n            'p': p,\n            'r': r,\n            'o': outimage,\n            'v': v\n        }\n    else :\n        myargs = {\n            'd': mydim,\n            'i': image,\n            'n': noise_model,\n            'x': mask.clone('unsigned char'),\n            's': int(shrink_factor),\n            'p': p,\n            'r': r,\n            'o': outimage,\n            'v': v\n        }\n\n    processed_args = pargs._int_antsProcessArguments(myargs)\n    libfn = utils.get_lib_fn('DenoiseImage')\n    libfn(processed_args)\n    return outimage.clone(inpixeltype)", "response": "This function denoises an image using a spatially adaptive filter originally described in the ANTsR file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfunctions to apply morphological operations to an image ANTsImage ANTs", "response": "def morphology(image, operation, radius, mtype='binary', value=1,\n               shape='ball', radius_is_parametric=False, thickness=1,\n               lines=3, include_center=False):\n    \"\"\"\n    Apply morphological operations to an image\n\n    ANTsR function: `morphology`\n\n    Arguments\n    ---------\n    input : ANTsImage\n        input image\n\n    operation : string\n        operation to apply\n            \"close\" Morpholgical closing\n            \"dilate\" Morpholgical dilation\n            \"erode\" Morpholgical erosion\n            \"open\" Morpholgical opening\n\n    radius : scalar\n        radius of structuring element\n\n    mtype : string\n        type of morphology\n            \"binary\" Binary operation on a single value\n            \"grayscale\" Grayscale operations\n\n    value : scalar\n        value to operation on (type='binary' only)\n\n    shape : string\n        shape of the structuring element ( type='binary' only )\n            \"ball\" spherical structuring element\n            \"box\" box shaped structuring element\n            \"cross\" cross shaped structuring element\n            \"annulus\" annulus shaped structuring element\n            \"polygon\" polygon structuring element\n\n    radius_is_parametric : boolean\n        used parametric radius boolean (shape='ball' and shape='annulus' only)\n\n    thickness : scalar\n        thickness (shape='annulus' only)\n\n    lines : integer\n        number of lines in polygon (shape='polygon' only)\n\n    include_center : boolean\n        include center of annulus boolean (shape='annulus' only)\n\n    Returns\n    -------\n    ANTsImage\n\n    Example\n    -------\n    >>> import ants\n    >>> fi = ants.image_read( ants.get_ants_data('r16') , 2 )\n    >>> mask = ants.get_mask( fi )\n    >>> dilated_ball = ants.morphology( mask, operation='dilate', radius=3, mtype='binary', shape='ball')\n    >>> eroded_box = ants.morphology( mask, operation='erode', radius=3, mtype='binary', shape='box')\n    >>> opened_annulus = ants.morphology( mask, operation='open', radius=5, mtype='binary', shape='annulus', thickness=2)\n    \"\"\"\n    if image.components > 1:\n        raise ValueError('multichannel images not yet supported')\n\n    _sflag_dict = {'ball': 1, 'box': 2, 'cross': 3, 'annulus': 4, 'polygon': 5}\n    sFlag = _sflag_dict.get(shape, 0)\n\n    if sFlag == 0:\n        raise ValueError('invalid element shape')\n\n    radius_is_parametric = radius_is_parametric * 1\n    include_center = include_center * 1\n    if (mtype == 'binary'):\n        if (operation == 'dilate'):\n            if (sFlag == 5):\n                ret = iMath(image, 'MD', radius, value, sFlag, lines)\n            else:\n                ret = iMath(image, 'MD', radius, value, sFlag, radius_is_parametric, thickness, include_center)\n        elif (operation == 'erode'):\n            if (sFlag == 5):\n                ret = iMath(image, 'ME', radius, value, sFlag, lines)\n            else:\n                ret = iMath(image, 'ME', radius, value, sFlag, radius_is_parametric, thickness, include_center)\n        elif (operation == 'open'):\n            if (sFlag == 5):\n                ret = iMath(image, 'MO', radius, value, sFlag, lines)\n            else:\n                ret = iMath(image, 'MO', radius, value, sFlag, radius_is_parametric, thickness, include_center)\n        elif (operation == 'close'):\n            if (sFlag == 5):\n                ret = iMath(image, 'MC', radius, value, sFlag, lines)\n            else:\n                ret = iMath(image, 'MC', radius, value, sFlag, radius_is_parametric, thickness, include_center)\n        else:\n            raise ValueError('Invalid morphology operation')\n    elif (mtype == 'grayscale'):\n        if (operation == 'dilate'):\n            ret = iMath(image, 'GD', radius)\n        elif (operation == 'erode'):\n            ret = iMath(image, 'GE', radius)\n        elif (operation == 'open'):\n            ret = iMath(image, 'GO', radius)\n        elif (operation == 'close'):\n            ret = iMath(image, 'GC', radius)\n        else:\n            raise ValueError('Invalid morphology operation')\n    else:\n        raise ValueError('Invalid morphology type')\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a scalar image to RGB.", "response": "def scalar_to_rgb(image, mask=None, filename=None, cmap='red', custom_colormap_file=None, \n                  min_input=None, max_input=None, min_rgb_output=None, max_rgb_output=None,\n                  vtk_lookup_table=None):\n    \"\"\"\n    Usage: ConvertScalarImageToRGB imageDimension inputImage outputImage mask colormap \n    [customColormapFile] [minimumInput] [maximumInput] [minimumRGBOutput=0] \n    [maximumRGBOutput=255] <vtkLookupTable>\n    Possible colormaps: grey, red, green, blue, copper, jet, hsv, spring, summer, autumn, winter, hot, cool, overunder, custom\n    \n    Example\n    -------\n    >>> import ants\n    >>> img = ants.image_read(ants.get_data('r16'))\n    >>> img_color = img.scalar_to_rgb(cmap='jet')\n    \"\"\"\n\n    if filename is None:\n        file_is_temp = True\n        filename = mktemp(suffix='.png')\n    else:\n        file_is_temp = False\n\n    args = 'imageDimension inputImage outputImage mask colormap'.split(' ')\n    args[0] = image.dimension\n\n    if isinstance(image, iio.ANTsImage):\n        tmpimgfile = mktemp(suffix='.nii.gz')\n        image.to_file(tmpimgfile)\n    elif isinstance(image, str):\n        tmpimgfile = image\n    args[1] = tmpimgfile\n    args[2] = filename\n    args[3] = mask if mask is not None else image.new_image_like(np.ones(image.shape))\n    args[4] = cmap\n    if custom_colormap_file is not None:\n        args.append('customColormapFile=%s' % custom_colormap_file)\n    if min_input is not None:\n        args.append('minimumInput=%f' % min_input)\n    if max_input is not None:\n        args.append('maximumInput=%f' % max_input)\n    if min_rgb_output is not None:\n        args.append('minRGBOutput=%f' % min_rgb_output)\n    if max_rgb_output is not None:\n        args.append('maxRGBOutput=%f' % min_rgb_output)\n    if vtk_lookup_table is not None:\n        vtk_lookup_table = mktemp(suffix='.csv')\n        args.append('vtkLookupTable=%s' % vtk_lookup_table)\n    \n    processed_args = utils._int_antsProcessArguments(args)\n    libfn = utils.get_lib_fn('ConvertScalarImageToRGB')\n    libfn(processed_args)\n\n    if file_is_temp:\n        outimg = iio2.image_read(filename, pixeltype=None)\n        # clean up temp files\n        os.remove(filename)\n        os.remove(tmpimgfile)\n\n        return outimg\n    else:\n        os.remove(tmpimgfile)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts an RGB ANTsImage to a Vector ANTsImage", "response": "def rgb_to_vector(image):\n    \"\"\"\n    Convert an RGB ANTsImage to a Vector ANTsImage\n\n    Arguments\n    ---------\n    image : ANTsImage\n        RGB image to be converted\n\n    Returns\n    -------\n    ANTsImage\n\n    Example\n    -------\n    >>> import ants\n    >>> mni = ants.image_read(ants.get_data('mni'))\n    >>> mni_rgb = mni.scalar_to_rgb()\n    >>> mni_vector = mni.rgb_to_vector()\n    >>> mni_rgb2 = mni.vector_to_rgb()\n    \"\"\"\n    if image.pixeltype != 'unsigned char':\n        image = image.clone('unsigned char')\n    idim = image.dimension\n    libfn = utils.get_lib_fn('RgbToVector%i' % idim)\n    new_ptr = libfn(image.pointer)\n    new_img = iio.ANTsImage(pixeltype=image.pixeltype, dimension=image.dimension, \n                            components=3, pointer=new_ptr, is_rgb=False)\n    return new_img"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting an Vector ANTsImage to a RGB ANTsImage", "response": "def vector_to_rgb(image):\n    \"\"\"\n    Convert an Vector ANTsImage to a RGB ANTsImage\n\n    Arguments\n    ---------\n    image : ANTsImage\n        RGB image to be converted\n\n    Returns\n    -------\n    ANTsImage\n\n    Example\n    -------\n    >>> import ants\n    >>> img = ants.image_read(ants.get_data('r16'), pixeltype='unsigned char')\n    >>> img_rgb = img.clone().scalar_to_rgb()\n    >>> img_vec = img_rgb.rgb_to_vector()\n    >>> img_rgb2 = img_vec.vector_to_rgb()\n    \"\"\"\n    if image.pixeltype != 'unsigned char':\n        image = image.clone('unsigned char')\n    idim = image.dimension\n    libfn = utils.get_lib_fn('VectorToRgb%i' % idim)\n    new_ptr = libfn(image.pointer)\n    new_img = iio.ANTsImage(pixeltype=image.pixeltype, dimension=image.dimension, \n                            components=3, pointer=new_ptr, is_rgb=True)\n    return new_img"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef multi_label_morphology(image, operation, radius, dilation_mask=None, label_list=None, force=False):\n    if (label_list is None) or (len(label_list) == 1):\n        label_list = np.sort(np.unique(image[image > 0]))\n        if (len(label_list) > 200) and (not force):\n            raise ValueError('More than 200 labels... Make sure the image is discrete'\n                             ' and call this function again with `force=True` if you'\n                             ' really want to do this.')\n\n    image_binary = image.clone()\n    image_binary[image_binary > 1] = 1\n\n    # Erosion / opening is simply a case of looping over the input labels\n    if (operation == 'ME') or (operation == 'MO'):\n        output = image.clone()\n\n        for current_label in label_list:\n            output = output.iMath(operation, radius, current_label)\n\n        return output\n\n    if dilation_mask is not None:\n        if int(dilation_mask.max()) != 1:\n            raise ValueError('Mask is either empty or not binary')\n\n    output = image.clone()\n    for current_label in label_list:\n        current_label_region = image.threshold_image(current_label, current_label)\n        other_labels = output - current_label_region\n        clab_binary_morphed = current_label_region.iMath(operation, radius, 1)\n\n        if (operation == 'MD') and (dilation_mask is not None):\n            clab_binary_morphed_nooverlap = current_label_region + dilation_mask * clab_binary_morphed - other_labels\n            clab_binary_morphed_nooverlap = clab_binary_morphed_nooverlap.threshold_image(1, 2)\n        else:\n            clab_binary_morphed_nooverlap = clab_binary_morphed - other_labels\n            clab_binary_morphed_nooverlap = clab_binary_morphed_nooverlap.threshold_image(1, 1)\n\n        output = output + clab_binary_morphed_nooverlap * current_label\n\n    return output", "response": "Returns the binary morphology for the given image operation and radius."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ilr( data_frame, voxmats, ilr_formula, verbose = False ):\n\n    nvoxmats = len( voxmats )\n    if nvoxmats < 1 :\n        raise ValueError('Pass at least one matrix to voxmats list')\n    keylist = list(voxmats.keys())\n    firstmat = keylist[0]\n    voxshape = voxmats[firstmat].shape\n    nvox = voxshape[1]\n    nmats = len( keylist )\n    for k in keylist:\n        if voxmats[firstmat].shape != voxmats[k].shape:\n            raise ValueError('Matrices must have same number of rows (samples)')\n\n    # test voxel\n    vox = 0\n    nrows = data_frame.shape[0]\n    data_frame_vox = data_frame.copy()\n    for k in range( nmats ):\n        data = {keylist[k]: np.random.normal(0,1,nrows) }\n        temp = pd.DataFrame( data )\n        data_frame_vox = pd.concat([data_frame_vox.reset_index(drop=True),temp], axis=1 )\n    mod = smf.ols(formula=ilr_formula, data=data_frame_vox )\n    res = mod.fit()\n    modelNames = res.model.exog_names\n    if verbose:\n        print( data_frame_vox )\n        print(res.summary())\n    nOutcomes = len( modelNames )\n    tValsOut = list()\n    pValsOut = list()\n    bValsOut = list()\n    for k in range( len( modelNames ) ):\n        bValsOut.append( np.zeros( nvox ) )\n        pValsOut.append( np.zeros( nvox ) )\n        tValsOut.append( np.zeros( nvox ) )\n\n    data_frame_vox = data_frame.copy()\n    for v in range( nmats ):\n        data = {keylist[v]: voxmats[keylist[v]][:,k] }\n        temp = pd.DataFrame( data )\n        data_frame_vox = pd.concat([data_frame_vox.reset_index(drop=True),temp], axis=1 )\n    for k in range( nvox ):\n        # first get the correct data frame\n        for v in range( nmats ):\n            data_frame_vox[ keylist[v] ] = voxmats[keylist[v]][:,k]\n        # then get the local model results\n        mod = smf.ols(formula=ilr_formula, data=data_frame_vox )\n        res = mod.fit()\n        tvals = res.tvalues\n        pvals = res.pvalues\n        bvals = res.params\n        for v in range( len( modelNames ) ):\n            bValsOut[v][k] = bvals[v]\n            pValsOut[v][k] = pvals[v]\n            tValsOut[v][k] = tvals[v]\n\n    bValsOutDict = { }\n    tValsOutDict = { }\n    pValsOutDict = { }\n    for v in range( len( modelNames ) ):\n        bValsOutDict[ 'coef_' + modelNames[v] ] = bValsOut[v]\n        tValsOutDict[ 'tval_' + modelNames[v] ] = tValsOut[v]\n        pValsOutDict[ 'pval_' + modelNames[v] ] = pValsOut[v]\n\n    return {\n        'modelNames': modelNames,\n        'coefficientValues': bValsOutDict,\n        'pValues': pValsOutDict,\n        'tValues': tValsOutDict }", "response": "This function simplifies calculating p - values from linear regression models."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the quantile values from an ANTsImage", "response": "def quantile(image, q, nonzero=True):\n    \"\"\"\n    Get the quantile values from an ANTsImage\n    \"\"\"\n    img_arr = image.numpy()\n    if isinstance(q, (list,tuple)):\n        q = [qq*100. if qq <= 1. else qq for qq in q]\n        if nonzero:\n            img_arr = img_arr[img_arr>0]\n        vals = [np.percentile(img_arr, qq) for qq in q]\n        return tuple(vals)\n    elif isinstance(q, (float,int)):\n        if q <= 1.:\n            q = q*100.\n        if nonzero:\n            img_arr = img_arr[img_arr>0]\n        return np.percentile(img_arr[img_arr>0], q)\n    else:\n        raise ValueError('q argument must be list/tuple or float/int')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nregressing a polynomial of data into a new design matrix.", "response": "def regress_poly(degree, data, remove_mean=True, axis=-1):\n    \"\"\"\n    Returns data with degree polynomial regressed out.\n    :param bool remove_mean: whether or not demean data (i.e. degree 0),\n    :param int axis: numpy array axes along which regression is performed\n    \"\"\"\n    timepoints = data.shape[0]\n    # Generate design matrix\n    X = np.ones((timepoints, 1))  # quick way to calc degree 0\n    for i in range(degree):\n        polynomial_func = Legendre.basis(i + 1)\n        value_array = np.linspace(-1, 1, timepoints)\n        X = np.hstack((X, polynomial_func(value_array)[:, np.newaxis]))\n    non_constant_regressors = X[:, :-1] if X.shape[1] > 1 else np.array([])\n    betas = np.linalg.pinv(X).dot(data)\n    if remove_mean:\n        datahat = X.dot(betas)\n    else:  # disregard the first layer of X, which is degree 0\n        datahat = X[:, 1:].dot(betas[1:, ...])\n    regressed_data = data - datahat\n    return regressed_data, non_constant_regressors"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef regress_components( data, components, remove_mean=True ):\n    timepoints = data.shape[0]\n    betas = np.linalg.pinv(components).dot(data)\n    if remove_mean:\n        datahat = components.dot(betas)\n    else:  # disregard the first layer of X, which is degree 0\n        datahat = components[:, 1:].dot(betas[1:, ...])\n    regressed_data = data - datahat\n    return regressed_data", "response": "Regress components in data to the timepoints of the timepoints of the timepoints of the first layer of X."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\naverage the timeseries into a dimension - 1 image.", "response": "def get_average_of_timeseries( image, idx=None ):\n    \"\"\"Average the timeseries into a dimension-1 image.\n    image: input time series image\n    idx:  indices over which to average\n    \"\"\"\n    imagedim = image.dimension\n    if idx is None:\n        idx = range( image.shape[ imagedim - 1 ] )\n    i0 = utils.slice_image( image, axis=image.dimension-1, idx=idx[0] ) * 0\n    wt = 1.0 / len( idx )\n    for k in idx:\n        i0 = i0 + utils.slice_image( image, axis=image.dimension-1, idx=k ) * wt\n    return( i0 )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef compcor( boldImage, ncompcor=4, quantile=0.975, mask=None, filter_type=False, degree=2 ):\n\n    def compute_tSTD(M, quantile, x=0, axis=0):\n        stdM = np.std(M, axis=axis)\n        # set bad values to x\n        stdM[stdM == 0] = x\n        stdM[np.isnan(stdM)] = x\n        tt = round( quantile*100 )\n        threshold_std = np.percentile( stdM, tt )\n    #    threshold_std = quantile( stdM, quantile )\n        return { 'tSTD': stdM, 'threshold_std': threshold_std}\n    if mask is None:\n        temp = utils.slice_image( boldImage, axis=boldImage.dimension-1, idx=0 )\n        mask = utils.get_mask( temp )\n    imagematrix = core.timeseries_to_matrix( boldImage, mask )\n    temp = compute_tSTD( imagematrix, quantile, 0 )\n    tsnrmask = core.make_image( mask,  temp['tSTD'] )\n    tsnrmask = utils.threshold_image( tsnrmask, temp['threshold_std'], temp['tSTD'].max() )\n    M = core.timeseries_to_matrix( boldImage, tsnrmask )\n    components = None\n    basis = np.array([])\n    if filter_type in ('polynomial', False):\n        M, basis = regress_poly(degree, M)\n#    M = M / compute_tSTD(M, 1.)['tSTD']\n    # \"The covariance matrix C = MMT was constructed and decomposed into its\n    # principal components using a singular value decomposition.\"\n    u, _, _ = linalg.svd(M, full_matrices=False)\n    if components is None:\n        components = u[:, :ncompcor]\n    else:\n        components = np.hstack((components, u[:, :ncompcor]))\n    if components is None and ncompcor > 0:\n        raise ValueError('No components found')\n    return { 'components': components, 'basis': basis }", "response": "This function computes the noise components from the input time series image and returns the corresponding dictionary of noise components."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mask_image(image, mask, level=1, binarize=False):\n    leveluse = level\n    if type(leveluse) is np.ndarray:\n        leveluse = level.tolist()\n    image_out = image.clone() * 0\n    for mylevel in leveluse:\n        temp = threshold_image( mask, mylevel, mylevel )\n        if binarize:\n            image_out = image_out + temp\n        else:\n            image_out = image_out + temp * image\n    return image_out", "response": "Mask an input image by a mask image."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef n4_bias_field_correction(image, mask=None, shrink_factor=4,\n                             convergence={'iters':[50,50,50,50], 'tol':1e-07},\n                             spline_param=200, verbose=False, weight_mask=None):\n    \"\"\"\n    N4 Bias Field Correction\n\n    ANTsR function: `n4BiasFieldCorrection`\n\n    Arguments\n    ---------\n    image : ANTsImage\n        image to bias correct\n\n    mask : ANTsImage\n        input mask, if one is not passed one will be made\n\n    shrink_factor : scalar\n        Shrink factor for multi-resolution correction, typically integer less than 4\n\n    convergence : dict w/ keys `iters` and `tol`\n        iters : vector of maximum number of iterations for each shrinkage factor\n        tol : the convergence tolerance.\n\n    spline_param : integer\n        Parameter controlling number of control points in spline. Either single value, indicating how many control points, or vector with one entry per dimension of image, indicating the spacing in each direction.\n\n    verbose : boolean\n        enables verbose output.\n\n    weight_mask : ANTsImage (optional)\n        antsImage of weight mask\n\n    Returns\n    -------\n    ANTsImage\n\n    Example\n    -------\n    >>> image = ants.image_read( ants.get_ants_data('r16') )\n    >>> image_n4 = ants.n4_bias_field_correction(image)\n    \"\"\"\n    if image.pixeltype != 'float':\n        image = image.clone('float')\n    iters = convergence['iters']\n    tol = convergence['tol']\n    if mask is None:\n        mask = get_mask(image)\n\n    N4_CONVERGENCE_1 = '[%s, %.10f]' % ('x'.join([str(it) for it in iters]), tol)\n    N4_SHRINK_FACTOR_1 = str(shrink_factor)\n    if (not isinstance(spline_param, (list,tuple))) or (len(spline_param) == 1):\n        N4_BSPLINE_PARAMS = '[%i]' % spline_param\n    elif (isinstance(spline_param, (list,tuple))) and (len(spline_param) == image.dimension):\n        N4_BSPLINE_PARAMS = '[%s]' % ('x'.join([str(sp) for sp in spline_param]))\n    else:\n        raise ValueError('Length of splineParam must either be 1 or dimensionality of image')\n\n    if weight_mask is not None:\n        if not isinstance(weight_mask, iio.ANTsImage):\n            raise ValueError('Weight Image must be an antsImage')\n\n    outimage = image.clone()\n    kwargs = {\n        'd': outimage.dimension,\n        'i': image,\n        'w': weight_mask,\n        's': N4_SHRINK_FACTOR_1,\n        'c': N4_CONVERGENCE_1,\n        'b': N4_BSPLINE_PARAMS,\n        'x': mask,\n        'o': outimage,\n        'v': int(verbose)\n    }\n\n    processed_args = pargs._int_antsProcessArguments(kwargs)\n    libfn = utils.get_lib_fn('N4BiasFieldCorrection')\n    libfn(processed_args)\n    return outimage", "response": "N4 Bias Field Correction ANTsR function."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef abp_n4(image, intensity_truncation=(0.025,0.975,256), mask=None, usen3=False):\n    if (not isinstance(intensity_truncation, (list,tuple))) or (len(intensity_truncation) != 3):\n        raise ValueError('intensity_truncation must be list/tuple with 3 values')\n    outimage = iMath(image, 'TruncateIntensity',\n            intensity_truncation[0], intensity_truncation[1], intensity_truncation[2])\n    if usen3 == True:\n        outimage = n3_bias_field_correction(outimage, 4)\n        outimage = n3_bias_field_correction(outimage, 2)\n        return outimage\n    else:\n        outimage = n4_bias_field_correction(outimage, mask)\n        return outimage", "response": "This function will truncate outlier intensities and bias correct with the N4 algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a binary mask image from the given image after thresholding it.", "response": "def get_mask(image, low_thresh=None, high_thresh=None, cleanup=2):\n    \"\"\"\n    Get a binary mask image from the given image after thresholding\n\n    ANTsR function: `getMask`\n\n    Arguments\n    ---------\n    image : ANTsImage\n        image from which mask will be computed. Can be an antsImage of 2, 3 or 4 dimensions.\n\n    low_thresh : scalar (optional)\n        An inclusive lower threshold for voxels to be included in the mask.\n        If not given, defaults to image mean.\n\n    high_thresh : scalar (optional)\n        An inclusive upper threshold for voxels to be included in the mask.\n        If not given, defaults to image max\n\n    cleanup : integer\n        If > 0, morphological operations will be applied to clean up the mask by eroding away small or weakly-connected areas, and closing holes.\n        If cleanup is >0, the following steps are applied\n            1. Erosion with radius 2 voxels\n            2. Retain largest component\n            3. Dilation with radius 1 voxel\n            4. Morphological closing\n\n    Returns\n    -------\n    ANTsImage\n\n    Example\n    -------\n    >>> import ants\n    >>> image = ants.image_read( ants.get_ants_data('r16') )\n    >>> mask = ants.get_mask(image)\n    \"\"\"\n    cleanup = int(cleanup)\n    if isinstance(image, iio.ANTsImage):\n        if image.pixeltype != 'float':\n            image = image.clone('float')\n\n    if low_thresh is None:\n        low_thresh = image.mean()\n    if high_thresh is None:\n        high_thresh = image.max()\n\n    mask_image = threshold_image(image, low_thresh, high_thresh)\n    if cleanup > 0:\n        mask_image = iMath(mask_image, 'ME', cleanup)\n        mask_image = iMath(mask_image, 'GetLargestComponent')\n        mask_image = iMath(mask_image, 'MD', cleanup)\n        mask_image = iMath(mask_image, 'FillHoles').threshold_image( 1, 2 )\n        while ((mask_image.min() == mask_image.max()) and (cleanup > 0)):\n            cleanup = cleanup - 1\n            mask_image = threshold_image(image, low_thresh, high_thresh)\n            if cleanup > 0:\n                mask_image = iMath(mask_image, 'ME', cleanup)\n                mask_image = iMath(mask_image, 'MD', cleanup)\n                mask_image = iMath(mask_image, 'FillHoles').threshold_image( 1, 2 )\n\n            #if cleanup == 0:\n            #    clustlab = label_clusters(mask_image, 1)\n            #    mask_image = threshold_image(clustlab, 1, 1)\n\n    return mask_image"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef label_image_centroids(image, physical=False, convex=True, verbose=False):\n    d = image.shape\n    if len(d) != 3:\n        raise ValueError('image must be 3 dimensions')\n\n    xcoords = np.asarray(np.arange(d[0]).tolist()*(d[1]*d[2]))\n    ycoords = np.asarray(np.repeat(np.arange(d[1]),d[0]).tolist()*d[2])\n    zcoords = np.asarray(np.repeat(np.arange(d[1]), d[0]*d[2]))\n\n    labels = image.numpy()\n    mylabels = np.sort(np.unique(labels[labels > 0])).astype('int')\n    n_labels = len(mylabels)\n    xc = np.zeros(n_labels)\n    yc = np.zeros(n_labels)\n    zc = np.zeros(n_labels)\n\n    if convex:\n        for i in mylabels:\n            idx = (labels == i).flatten()\n            xc[i-1] = np.mean(xcoords[idx])\n            yc[i-1] = np.mean(ycoords[idx])\n            zc[i-1] = np.mean(zcoords[idx])\n    else:\n        for i in mylabels:\n            idx = (labels == i).flatten()\n            xci = xcoords[idx]\n            yci = ycoords[idx]\n            zci = zcoords[idx]\n            dist = np.zeros(len(xci))\n\n            for j in range(len(xci)):\n                dist[j] = np.mean(np.sqrt((xci[j] - xci)**2 + (yci[j] - yci)**2 + (zci[j] - zci)**2))\n\n            mid = np.where(dist==np.min(dist))\n            xc[i-1] = xci[mid]\n            yc[i-1] = yci[mid]\n            zc[i-1] = zci[mid]\n\n    centroids = np.vstack([xc,yc,zc]).T\n\n    #if physical:\n    #    centroids = tio.transform_index_to_physical_point(image, centroids)\n\n    return {\n        'labels': mylabels,\n        'vertices': centroids\n    }", "response": "Returns a dictionary of all the image centroids of the image."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef transform(self, X, y=None):\n        insuffix = X._libsuffix\n        multires_fn = utils.get_lib_fn('multiResolutionAntsImage%s' % (insuffix))\n        casted_ptrs = multires_fn(X.pointer, self.levels)\n        \n        imgs = []\n        for casted_ptr in casted_ptrs:\n            img = iio.ANTsImage(pixeltype=X.pixeltype, dimension=X.dimension,\n                                components=X.components, pointer=casted_ptr)\n            if self.keep_shape:\n                img = img.resample_image_to_target(X)\n            imgs.append(img)\n\n        return imgs", "response": "Generate a set of multi - resolution ANTsImage types for the given ANTsImage X and y."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntransforms an ants image to a new image.", "response": "def transform(self, X, y=None):\n        \"\"\"\n        Example\n        -------\n        >>> import ants\n        >>> translater = ants.contrib.TranslateImage((40,0))\n        >>> img2d = ants.image_read(ants.get_data('r16'))\n        >>> img2d_r = translater.transform(img2d)\n        >>> ants.plot(img2d, img2d_r)\n        >>> translater = ants.contrib.TranslateImage((40,0,0))\n        >>> img3d = ants.image_read(ants.get_data('mni'))\n        >>> img3d_r = translater.transform(img3d)\n        >>> ants.plot(img3d, img3d_r, axis=2)\n        \"\"\"\n        if X.pixeltype != 'float':\n            raise ValueError('image.pixeltype must be float ... use TypeCast transform or clone to float')\n\n        if len(self.translation) != X.dimension:\n            raise ValueError('must give a translation value for each image dimension')\n\n        if self.reference is None:\n            reference = X\n        else:\n            reference = self.reference\n\n        insuffix = X._libsuffix\n        cast_fn = utils.get_lib_fn('translateAntsImage%s_%s' % (insuffix, self.interp))\n        casted_ptr = cast_fn(X.pointer, reference.pointer, self.translation)\n        return iio.ANTsImage(pixeltype=X.pixeltype, dimension=X.dimension,\n                             components=X.components, pointer=casted_ptr)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_warped_grid(image, grid_step=10, grid_width=2, grid_directions=(True, True),\n                       fixed_reference_image=None, transform=None, foreground=1, background=0):\n    \"\"\"\n    Deforming a grid is a helpful way to visualize a deformation field. \n    This function enables a user to define the grid parameters \n    and apply a deformable map to that grid.\n\n    ANTsR function: `createWarpedGrid`\n    \n    Arguments\n    ---------\n    image : ANTsImage\n        input image\n    \n    grid_step : scalar   \n        width of grid blocks\n    \n    grid_width : scalar\n        width of grid lines\n    \n    grid_directions : tuple of booleans \n        directions in which to draw grid lines, boolean vector\n    \n    fixed_reference_image : ANTsImage (optional)\n        reference image space\n    \n    transform : list/tuple of strings (optional)\n        vector of transforms\n    \n    foreground : scalar\n        intensity value for grid blocks\n    \n    background : scalar\n        intensity value for grid lines\n\n    Returns\n    -------\n    ANTsImage\n\n    Example\n    -------\n    >>> import ants\n    >>> fi = ants.image_read( ants.get_ants_data( 'r16' ) )\n    >>> mi = ants.image_read( ants.get_ants_data( 'r64' ) )\n    >>> mygr = ants.create_warped_grid( mi )\n    >>> mytx = ants.registration(fixed=fi, moving=mi, type_of_transform = ('SyN') )\n    >>> mywarpedgrid = ants.create_warped_grid( mi, grid_directions=(False,True),\n                            transform=mytx['fwdtransforms'], fixed_reference_image=fi )\n    \"\"\"\n    if isinstance(image, iio.ANTsImage):\n        if len(grid_directions) != image.dimension:\n            grid_directions = [True]*image.dimension\n        garr = image.numpy() * 0 + foreground\n    else:\n        if not isinstance(image, (list, tuple)):\n            raise ValueError('image arg must be ANTsImage or list or tuple')\n        if len(grid_directions) != len(image):\n            grid_directions = [True]*len(image)\n        garr = np.zeros(image) + foreground\n        image = iio2.from_numpy(garr)\n\n    idim = garr.ndim\n    gridw = grid_width\n\n    for d in range(idim):\n        togrid = np.arange(-1, garr.shape[d]-1, step=grid_step)\n        for i in range(len(togrid)):\n            if (d == 0) & (idim == 3) & (grid_directions[d]):\n                garr[togrid[i]:(togrid[i]+gridw),...] = background\n                garr[0,...] = background\n                garr[-1,...] = background\n            if (d == 1) & (idim == 3) & (grid_directions[d]):\n                garr[:,togrid[i]:(togrid[i]+gridw),:] = background\n                garr[:,0,:] = background\n                garr[:,-1,:] = background\n            if (d == 2) & (idim == 3) & (grid_directions[d]):\n                garr[...,togrid[i]:(togrid[i]+gridw)] = background\n                garr[...,0] = background\n                garr[...,-1] = background\n            if (d == 0) & (idim == 2) & (grid_directions[d]):\n                garr[togrid[i]:(togrid[i]+gridw),:] = background\n                garr[0,:] = background\n                garr[-1,:] = background\n            if (d == 1) & (idim == 2) & (grid_directions[d]):\n                garr[:,togrid[i]:(togrid[i]+gridw)] = background\n                garr[:,0] = background\n                garr[:,-1] = background\n\n\n    gimage = image.new_image_like(garr)\n\n    if (transform is not None) and (fixed_reference_image is not None):\n        return apply_transforms( fixed=fixed_reference_image, moving=gimage,\n                               transformlist=transform ) \n    else:\n        return gimage", "response": "This function creates a warped grid for an image."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfunction to retrieve the test data for a single ANTsPy test image tag.", "response": "def get_data(name=None):\n    \"\"\"\n    Get ANTsPy test data filename\n\n    ANTsR function: `getANTsRData`\n    \n    Arguments\n    ---------\n    name : string\n        name of test image tag to retrieve\n        Options:\n            - 'r16'\n            - 'r27'\n            - 'r64'\n            - 'r85'\n            - 'ch2'\n            - 'mni'\n            - 'surf'\n    Returns\n    -------\n    string\n        filepath of test image\n\n    Example\n    -------\n    >>> import ants\n    >>> mnipath = ants.get_ants_data('mni')\n    \"\"\"\n    if name is None:\n        files = []\n        for fname in os.listdir(data_path):\n            if (fname.endswith('.nii.gz')) or (fname.endswith('.jpg') or (fname.endswith('.csv'))):\n                fname = os.path.join(data_path, fname)\n                files.append(fname)\n        return files\n    else:\n        datapath = None\n        for fname in os.listdir(data_path):\n            if (name == fname.split('.')[0]) or ((name+'slice') == fname.split('.')[0]):\n                datapath = os.path.join(data_path, fname)\n\n        if datapath is None:\n            raise ValueError('File doesnt exist. Options: ' , os.listdir(data_path))\n        return datapath"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef invariant_image_similarity(image1, image2, \n                                local_search_iterations=0, metric='MI', \n                                thetas=np.linspace(0,360,5),\n                                thetas2=np.linspace(0,360,5),\n                                thetas3=np.linspace(0,360,5),  \n                                scale_image=1, do_reflection=False,\n                                txfn=None, transform='Affine'):\n    \"\"\"\n    Similarity metrics between two images as a function of geometry\n\n    Compute similarity metric between two images as image is rotated about its\n    center w/ or w/o optimization\n\n    ANTsR function: `invariantImageSimilarity`\n\n    Arguments\n    ---------\n    image1 : ANTsImage\n        reference image\n    \n    image2 : ANTsImage\n        moving image\n    \n    local_search_iterations : integer\n        integer controlling local search in multistart\n    \n    metric : string\n        which metric to use\n            MI\n            GC\n    thetas : 1D-ndarray/list/tuple\n        numeric vector of search angles in degrees\n    \n    thetas2 : 1D-ndarray/list/tuple\n        numeric vector of search angles in degrees around principal axis 2 (3D)\n    \n    thetas3 : 1D-ndarray/list/tuple\n        numeric vector of search angles in degrees around principal axis 3 (3D)\n    \n    scale_image : scalar\n        global scale\n    \n    do_reflection : boolean\n        whether to reflect image about principal axis\n    \n    txfn : string (optional)\n        if present, write optimal tx to .mat file\n    \n    transform : string\n        type of transform to use\n            Rigid\n            Similarity\n            Affine \n\n    Returns\n    -------\n    pd.DataFrame\n        dataframe with metric values and transformation parameters\n\n    Example\n    -------\n    >>> import ants\n    >>> img1 = ants.image_read(ants.get_ants_data('r16'))\n    >>> img2 = ants.image_read(ants.get_ants_data('r64'))\n    >>> metric = ants.invariant_image_similarity(img1,img2)\n    \"\"\"\n    if transform not in {'Rigid', 'Similarity', 'Affine'}:\n        raise ValueError('transform must be one of Rigid/Similarity/Affine')\n\n    if image1.pixeltype != 'float':\n        image1 = image1.clone('float')\n    if image2.pixeltype != 'float':\n        image2 = image2.clone('float')\n\n    if txfn is None:\n        txfn = mktemp(suffix='.mat')\n\n    # convert thetas to radians\n    thetain = (thetas * math.pi) / 180.\n    thetain2 = (thetas2 * math.pi) / 180.\n    thetain3 = (thetas3 * math.pi) / 180.\n\n    image1 = utils.iMath(image1, 'Normalize')\n    image2 = utils.iMath(image2, 'Normalize')\n\n    idim = image1.dimension\n    fpname = ['FixedParam%i'%i for i in range(1,idim+1)]\n\n    if not do_reflection:\n        libfn = utils.get_lib_fn('invariantImageSimilarity_%s%iD' % (transform, idim))\n        r1 = libfn(image1.pointer, \n                    image2.pointer,\n                    list(thetain), \n                    list(thetain2), \n                    list(thetain3),\n                    local_search_iterations, \n                    metric,\n                    scale_image, \n                    int(do_reflection),\n                    txfn)\n        r1 = np.asarray(r1)\n\n        pnames = ['Param%i'%i for i in range(1,r1.shape[1])]\n        pnames[(len(pnames)-idim):len(pnames)] = fpname\n\n        r1 = pd.DataFrame(r1, columns=['MetricValue']+pnames)\n        return r1, txfn\n    else:\n        txfn1 = mktemp(suffix='.mat')\n        txfn2 = mktemp(suffix='.mat')\n        txfn3 = mktemp(suffix='.mat')\n        txfn4 = mktemp(suffix='.mat')\n\n        libfn = utils.get_lib_fn('invariantImageSimilarity_%s%iD' % (transform, idim))\n        ## R1 ##\n        r1 = libfn(image1.pointer,\n                    image2.pointer,\n                    list(thetain), \n                    list(thetain2), \n                    list(thetain3),\n                    local_search_iterations, \n                    metric,\n                    scale_image, \n                    0,\n                    txfn1)\n        r1 = np.asarray(r1)\n        pnames = ['Param%i'%i for i in range(1,r1.shape[1])]\n        pnames[(len(pnames)-idim):len(pnames)] = fpname\n        r1 = pd.DataFrame(r1, columns=['MetricValue']+pnames)\n\n        ## R2 ##\n        r2 = libfn(image1.pointer,\n                    image2.pointer,\n                    list(thetain), \n                    list(thetain2), \n                    list(thetain3),\n                    local_search_iterations, \n                    metric,\n                    scale_image, \n                    1,\n                    txfn2)\n        r2 = np.asarray(r2)\n        r2 = pd.DataFrame(r2, columns=['MetricValue']+pnames)\n\n        ## R3 ##\n        r3 = libfn(image1.pointer,\n                    image2.pointer,\n                    list(thetain), \n                    list(thetain2), \n                    list(thetain3),\n                    local_search_iterations, \n                    metric,\n                    scale_image, \n                    2,\n                    txfn3)\n        r3 = np.asarray(r3)\n        r3 = pd.DataFrame(r3, columns=['MetricValue']+pnames)\n\n        ## R4 ##\n        r4 = libfn(image1.pointer,\n                    image2.pointer,\n                    list(thetain), \n                    list(thetain2), \n                    list(thetain3),\n                    local_search_iterations, \n                    metric,\n                    scale_image, \n                    3,\n                    txfn4)\n        r4 = np.asarray(r4)\n        r4 = pd.DataFrame(r4, columns=['MetricValue']+pnames)\n\n        rmins = [np.min(r1.iloc[:,0]), np.min(r2.iloc[:,0]), np.min(r3.iloc[:,0]), np.min(r4.iloc[:,0])]\n        ww = np.argmin(rmins)\n\n        if ww == 0:\n            return r1, txfn1\n        elif ww == 1:\n            return r2, txfn2\n        elif ww == 2:\n            return r3, txfn3\n        elif ww == 3:\n            return r4, txfn4", "response": "Function that computes the similarity between two ANTsImage objects and returns a dataframe of the result of the invariant image similarity function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmerge list of multiple scalar ANTsImage types of dimension into one ANTsImage of dimension plus one ANTsImage", "response": "def list_to_ndimage( image, image_list ):\n    \"\"\"\n    Merge list of multiple scalar ANTsImage types of dimension into one\n    ANTsImage of dimension plus one\n\n    ANTsR function: `mergeListToNDImage`\n\n    Arguments\n    ---------\n    image : target image space\n    image_list : list/tuple of ANTsImage types\n        scalar images to merge into target image space\n\n    Returns\n    -------\n    ANTsImage\n\n    Example\n    -------\n    >>> import ants\n    >>> image = ants.image_read(ants.get_ants_data('r16'))\n    >>> image2 = ants.image_read(ants.get_ants_data('r16'))\n    >>> imageTar = ants.make_image( ( *image2.shape, 2 ) )\n    >>> image3 = ants.list_to_ndimage( imageTar, [image,image2])\n    >>> image3.dimension == 3\n    \"\"\"\n    inpixeltype = image_list[0].pixeltype\n    dimension = image_list[0].dimension\n    components = len(image_list)\n\n    for imageL in image_list:\n        if not isinstance(imageL, iio.ANTsImage):\n            raise ValueError('list may only contain ANTsImage objects')\n        if image.pixeltype != inpixeltype:\n            raise ValueError('all images must have the same pixeltype')\n\n    dimensionout = ( *image_list[0].shape, len( image_list )  )\n    newImage = iio2.make_image(\n      dimensionout,\n      spacing = iio.get_spacing( image ),\n      origin = iio.get_origin( image ),\n      direction = iio.get_direction( image ),\n      pixeltype = inpixeltype\n      )\n    # FIXME - should implement paste image filter from ITK\n    for x in range( len( image_list ) ):\n        if dimension == 2:\n            newImage[:,:,x] = image_list[x][:,:]\n        if dimension == 3:\n            newImage[:,:,:,x] = image_list[x][:,:,:]\n    return newImage"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ndimage_to_list(image):\n    inpixeltype = image.pixeltype\n    dimension = image.dimension\n    components = 1\n    imageShape = image.shape\n    nSections = imageShape[ dimension - 1 ]\n    subdimension = dimension - 1\n    suborigin = iio.get_origin( image )[0:subdimension]\n    subspacing = iio.get_spacing( image )[0:subdimension]\n    subdirection = np.eye( subdimension )\n    for i in range( subdimension ):\n        subdirection[i,:] = iio.get_direction( image )[i,0:subdimension]\n    subdim = image.shape[ 0:subdimension ]\n    imagelist = []\n    for i in range( nSections ):\n        img = utils.slice_image( image, axis = subdimension, idx = i )\n        iio.set_spacing( img, subspacing )\n        iio.set_origin( img, suborigin )\n        iio.set_direction( img, subdirection )\n        imagelist.append( img )\n\n    return imagelist", "response": "Split an n - dimensional ANTsImage into a list of n - dimensional ANTsImages"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprocesses the arguments passed to an ants.", "response": "def _int_antsProcessArguments(args):\n    \"\"\"\n    Needs to be better validated.\n    \"\"\"\n    p_args = []\n    if isinstance(args, dict):\n        for argname, argval in args.items():\n            if '-MULTINAME-' in argname:\n                # have this little hack because python doesnt support\n                # multiple dict entries w/ the same key like R lists\n                argname = argname[:argname.find('-MULTINAME-')]\n            if argval is not None:\n                if len(argname) > 1:\n                    p_args.append('--%s' % argname)\n                else:\n                    p_args.append('-%s' % argname)\n\n                if isinstance(argval, iio.ANTsImage):\n                    p_args.append(_ptrstr(argval.pointer))\n                elif isinstance(argval, list):\n                    for av in argval:\n                        if isinstance(av, iio.ANTsImage):\n                            av = _ptrstr(av.pointer)\n                        p_args.append(av)\n                else:\n                    p_args.append(str(argval))\n\n    elif isinstance(args, list):\n        for arg in args:\n            if isinstance(arg, iio.ANTsImage):\n                pointer_string = _ptrstr(arg.pointer)\n                p_arg = pointer_string\n            elif arg is None:\n                pass\n            else:\n                p_arg = str(arg)\n            p_args.append(p_arg)\n    return p_args"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef surf_fold(image, outfile,\n    # processing args\n    dilation=0, inflation=10, alpha=1.,\n    # overlay args\n    overlay=None, overlay_mask=None, overlay_cmap='jet', overlay_scale=False,\n    overlay_alpha=1.,\n    # display args\n    rotation=None, cut_idx=None, cut_side='left',\n    grayscale=0.7, bg_grayscale=0.9,\n    verbose=False, cleanup=True):\n    \"\"\"\n    Generate a cortical folding surface of the gray matter of a brain image. \n    \n    rotation : 3-tuple | string | 2-tuple of string & 3-tuple\n        if 3-tuple, this will be the rotation from RPI about x-y-z axis\n        if string, this should be a canonical view (see : ants.get_canonical_views())\n        if 2-tuple, the first value should be a string canonical view, and the second\n                    value should be a 3-tuple representing a delta change in each\n                    axis from the canonical view (useful for apply slight changes\n                    to canonical views)\n        NOTE:\n            rotation=(0,0,0) will be a view of the top of the brain with the \n                       front of the brain facing the bottom of the image\n        NOTE:\n            1st value : controls rotation about x axis (anterior/posterior tilt)\n                note : the x axis extends to the side of you\n            2nd value : controls rotation about y axis (inferior/superior tilt)\n                note : the y axis extends in front and behind you\n            3rd value : controls rotation about z axis (left/right tilt) \n                note : thte z axis extends up and down\n\n    Example\n    -------\n    >>> import ants\n    >>> mni = ants.image_read(ants.get_data('mni'))\n    >>> seg = mni.otsu_segmentation(k=3)\n    >>> wm_img = seg.threshold_image(3,3)\n    >>> ants.surf_fold(wm_img, outfile='~/desktop/surf_fold.png')\n    >>> # with overlay\n    >>> overlay = ants.weingarten_image_curvature( mni, 1.5  ).smooth_image( 1 )\n    >>> ants.surf_fold(image=wm_img, overlay=overlay, outfile='~/desktop/surf_fold2.png')\n    \"\"\"\n    if not isinstance(rotation, list):\n        rotation = [rotation]\n    if not isinstance(rotation[0], list):\n        rotation = [rotation]\n\n    nrow = len(rotation)\n    ncol = len(rotation[0])\n\n    #image = image.reorient_image2('RPI')\n    #if overlay is not None:\n    #    overlay = overlay.reorient_image2('RPI')\n    \n    # preprocess outfile arg\n    outfile = os.path.expanduser(outfile)\n    if not outfile.endswith('.png'):\n        outfile = outfile.split('.')[0] + '.png'\n\n    # create all of the individual filenames by appending to outfile\n    rotation_filenames = []\n    for rowidx in range(nrow):\n        rotation_filenames.append([])\n        for colidx in range(ncol):\n            if rotation[rowidx][colidx] is not None:\n                ij_filename = outfile.replace('.png','_%i%i.png' % (rowidx,colidx))\n            else:\n                ij_filename = None\n            rotation_filenames[rowidx].append(ij_filename)\n\n    # create each individual surface image\n    for rowidx in range(nrow):\n        for colidx in range(ncol):\n            ij_filename = rotation_filenames[rowidx][colidx]\n            if ij_filename is not None:\n                ij_rotation = rotation[rowidx][colidx]\n                _surf_fold_single(image=image, outfile=ij_filename, dilation=dilation, inflation=inflation, alpha=alpha,\n                                  overlay=overlay, overlay_mask=overlay_mask, overlay_cmap=overlay_cmap, \n                                  overlay_scale=overlay_scale,overlay_alpha=overlay_alpha,rotation=ij_rotation, \n                                  cut_idx=cut_idx,cut_side=cut_side,grayscale=grayscale, \n                                  bg_grayscale=bg_grayscale,verbose=verbose)\n            rotation_filenames[rowidx][colidx] = ij_filename\n\n    # if only one view just rename the file, otherwise stitch images together according\n    # to the `rotation` list structure\n    if (nrow==1) and (ncol==1):\n        os.rename(rotation_filenames[0][0], outfile)\n    else:\n        if verbose:\n            print('Stitching images together..')\n        # read first image to calculate shape of stitched image\n        first_actual_file = None\n        for rowidx in range(nrow):\n            for colidx in range(ncol):\n                if rotation_filenames[rowidx][colidx] is not None:\n                    first_actual_file = rotation_filenames[rowidx][colidx]\n                    break\n\n        if first_actual_file is None:\n            raise ValueError('No images were created... check your rotation argument')\n\n        mypngimg = scipy.misc.imread(first_actual_file)\n        img_shape = mypngimg.shape\n        array_shape = (mypngimg.shape[0]*nrow, mypngimg.shape[1]*ncol, mypngimg.shape[-1])\n        mypngarray = np.zeros(array_shape).astype('uint8')\n\n        # read each individual image and place it in the larger stitch\n        for rowidx in range(nrow):\n            for colidx in range(ncol):\n                ij_filename = rotation_filenames[rowidx][colidx]\n                if ij_filename is not None:\n                    mypngimg = scipy.misc.imread(ij_filename)\n                else:\n                    mypngimg = np.zeros(img_shape) + int(255*bg_grayscale)\n                \n                row_start = rowidx*img_shape[0]\n                row_end   = (rowidx+1)*img_shape[0]\n                col_start = colidx*img_shape[1]\n                col_end   = (colidx+1)*img_shape[1]\n                \n                mypngarray[row_start:row_end,col_start:col_end:] = mypngimg\n\n        # save the stitch to the outfile\n        scipy.misc.imsave(outfile, mypngarray)\n\n        # delete all of the individual images if cleanup arg is True\n        if cleanup:\n            for rowidx in range(nrow):\n                for colidx in range(ncol):\n                    ij_filename = rotation_filenames[rowidx][colidx]\n                    if ij_filename is not None:\n                        os.remove(ij_filename)", "response": "This function generates a cortical folding surface of the image."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _surf_smooth_single(image,outfile,dilation,smooth,threshold,inflation,alpha,\n    cut_idx,cut_side,overlay,overlay_mask,overlay_cmap,overlay_scale, \n    overlay_alpha,rotation,grayscale,bg_grayscale,verbose):\n    \"\"\"\n    Generate a surface of the smooth white matter of a brain image. \n\n    This is great for displaying functional activations as are typically seen\n    in the neuroimaging literature.\n\n    Arguments\n    ---------\n    image : ANTsImage\n        A binary segmentation of the white matter surface.\n        If you don't have a white matter segmentation, you can use\n        `kmeans_segmentation` or `atropos` on a full-brain image.\n    \n    inflation : integer\n        how much to inflate the final surface\n\n    rotation : 3-tuple | string | list of 3-tuples | list of string\n        if tuple, this is rotation of X, Y, Z \n        if string, this is a canonical view..\n            Options: 'left', 'right', 'inner_left', 'inner_right', \n            'anterior', 'posterior', 'inferior', 'superior'\n        if list of tuples or strings, the surface images will be arranged\n        in a grid according to the shape of the list.\n        \n        e.g. rotation=[['left', 'inner_left' ],\n                       ['right','inner_right']] \n        will result in a 2x2 grid of the above 4 canonical views\n    \n    grayscale : float\n        value between 0 and 1 representing how light to make the base image.\n        grayscale = 1 will make the base image completely white and \n        grayscale = 0 will make the base image completely black\n\n    background : float\n        value between 0 and 1 representing how light to make the base image.\n        see `grayscale` arg.\n\n    outfile : string\n        filepath to which the surface plot will be saved\n\n    Example\n    -------\n    >>> import ants\n    >>> mni = ants.image_read(ants.get_data('mni'))\n    >>> seg = mni.otsu_segmentation(k=3)\n    >>> wm_img = seg.threshold_image(3,3)\n    >>> #ants.surf_smooth(wm_img, outfile='~/desktop/surf_smooth.png')\n    >>> ants.surf_smooth(wm_img, rotation='inner_right', outfile='~/desktop/surf_smooth_innerright.png')\n    >>> # with overlay\n    >>> overlay = ants.weingarten_image_curvature( mni, 1.5  ).smooth_image( 1 ).iMath_GD(3)\n    >>> ants.surf_smooth(image=wm_img, overlay=overlay, outfile='~/desktop/surf_smooth2.png')\n    \"\"\"\n\n    # handle rotation argument\n    if rotation is None:\n        rotation = (270,0,270)\n    if not isinstance(rotation, (str, tuple)):\n        raise ValueError('rotation must be a 3-tuple or string')\n    if isinstance(rotation, str):\n        if 'inner' in rotation:\n            cut_idx = int(image.shape[2]/2)\n            cut_side = rotation.replace('inner_','')\n        rotation = _view_map[rotation.lower()]\n\n\n    # handle filename argument\n    if outfile is None:\n        outfile = mktemp(suffix='.png')\n    else:\n        outfile = os.path.expanduser(outfile)\n\n    # handle overlay argument\n    if overlay is not None:\n        if overlay_mask is None:\n            overlay_mask = image.iMath_MD(3)\n\n    # PROCESSING IMAGE\n    image = image.reorient_image2('RPI')\n    image = image.iMath_fill_holes().iMath_get_largest_component()\n    if dilation > 0:\n        image = image.iMath_MD(dilation)\n    if smooth > 0:\n        image = image.smooth_image(smooth)\n    if threshold > 0:\n        image = image.threshold_image(threshold)\n    if cut_idx is not None:\n        if cut_side == 'left':\n            image = image.crop_indices((0,0,0),(cut_idx,image.shape[1],image.shape[2]))\n        elif cut_side == 'right':\n            image = image.crop_indices((cut_idx,0,0),image.shape)\n        else:\n            raise ValueError('not valid cut_side argument')\n\n    # surface arg\n    # save base image to temp file\n    image_tmp_file = mktemp(suffix='.nii.gz')\n    image.to_file(image_tmp_file)\n    # build image color\n    grayscale = int(grayscale*255)\n    alpha = 1.\n    image_color = '%sx%.1f' % ('x'.join([str(grayscale)]*3),\n                               alpha)\n    cmd = '-s [%s,%s] ' % (image_tmp_file, image_color)\n\n    # anti-alias arg\n    tolerance = 0.01\n    cmd += '-a %.3f ' % tolerance\n\n    # inflation arg\n    cmd += '-i %i ' % inflation\n\n    # display arg\n    bg_grayscale = int(bg_grayscale*255)\n    cmd += '-d %s[%s,%s]' % (outfile,\n                              'x'.join([str(s) for s in rotation]),\n                              'x'.join([str(bg_grayscale)]*3))\n\n    # overlay arg\n    if overlay is not None:\n        overlay = overlay.reorient_image2('RPI')\n        if overlay_scale == True:\n            min_overlay, max_overlay = overlay.quantile((0.05,0.95))\n            overlay[overlay<min_overlay] = min_overlay\n            overlay[overlay>max_overlay] = max_overlay\n        elif isinstance(overlay_scale, tuple):\n            min_overlay, max_overlay = overlay.quantile((overlay_scale[0], overlay_scale[1]))\n            overlay[overlay<min_overlay] = min_overlay\n            overlay[overlay>max_overlay] = max_overlay\n\n        # make tempfile for overlay\n        overlay_tmp_file = mktemp(suffix='.nii.gz')\n        # convert overlay image to RGB\n        overlay.scalar_to_rgb(mask=overlay_mask, cmap=overlay_cmap,\n                              filename=overlay_tmp_file)\n        # make tempfile for overlay mask\n        overlay_mask_tmp_file = mktemp(suffix='.nii.gz')\n        overlay_mask.to_file(overlay_mask_tmp_file)\n\n        cmd += ' -f [%s,%s,%.2f]' % (overlay_tmp_file, overlay_mask_tmp_file, overlay_alpha)\n\n    if verbose:\n        print(cmd)\n        time.sleep(1)\n\n    cmd = cmd.split(' ')\n    libfn = utils.get_lib_fn('antsSurf')\n    retval = libfn(cmd)\n    if retval != 0:\n        print('ERROR: Non-Zero Return Value!')\n\n    # cleanup temp file\n    os.remove(image_tmp_file)", "response": "This function generates a single segmented surface of the given image."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef surf(x, y=None, z=None,\n         quantlimits=(0.1,0.9),\n         colormap='jet',\n         grayscale=0.7,\n         bg_grayscale=0.9,\n         alpha=None,\n         inflation_factor=0,\n         tol=0.03,\n         smoothing_sigma=0.0,\n         rotation_params=(90,0,270),\n         overlay_limits=None,\n         filename=None,\n         verbose=False):\n    \"\"\"\n    Render a function onto a surface.\n\n    ANTsR function: `antsrSurf`\n        NOTE: the ANTsPy version of this function does NOT make a function call\n        to ANTs, unlike the ANTsR version, so you don't have to worry about paths.\n\n    Arguments\n    ---------\n    x : ANTsImage   \n        input image defining the surface on which to render\n    \n    y : ANTsImage\n        input image list defining the function to render on the surface. \n        these image(s) should be in the same space as x.\n    \n    z : ANTsImage\n        input image list mask for each y function to render on the surface. \n        these image(s) should be in the same space as y.\n    \n    quantlimits : tuple/list\n        lower and upper quantile limits for overlay\n    \n    colormap : string\n        one of: grey, red, green, blue, copper, jet, hsv, spring, summer, \n        autumn, winter, hot, cool, overunder, custom\n    \n    alpha : scalar  \n        transparency vector for underlay and each overlay, default zero\n    \n    inflation_factor : integer\n        number of inflation iterations to run\n\n    tol : float\n        error tolerance for surface reconstruction. Smaller values will\n        lead to better surfaces, at the cost of taking longer.\n        Try decreasing this value if your surfaces look very block-y.\n    \n    smoothing_sigma : scalar\n        gaussian smooth the overlay by this sigma\n    \n    rotation_params : tuple/list/ndarray \n        3 Rotation angles expressed in degrees or a matrix of rotation \n        parameters that will be applied in sequence.\n    \n    overlay_limits : tuple (optional)\n        absolute lower and upper limits for functional overlay. this parameter \n        will override quantlimits. Currently, this will set levels above \n        overlayLimits[2] to overlayLimits[1]. Can be a list of length of y.\n    \n    filename : string\n        prefix filename for output pngs\n    \n    verbose : boolean\n        prints the command used to call antsSurf\n    \n    Returns\n    -------\n    N/A\n\n    Example\n    -------\n    >>> import ants\n    >>> ch2i = ants.image_read( ants.get_ants_data(\"ch2\") )\n    >>> ch2seg = ants.threshold_image( ch2i, \"Otsu\", 3 )\n    >>> wm   = ants.threshold_image( ch2seg, 3, 3 )\n    >>> wm2 = wm.smooth_image( 1 ).threshold_image( 0.5, 1e15 )\n    >>> kimg = ants.weingarten_image_curvature( ch2i, 1.5  ).smooth_image( 1 )\n    >>> wmz = wm2.iMath(\"MD\",3)\n    >>> rp = [(90,180,90), (90,180,270), (90,180,180)]\n    >>> ants.surf( x=wm2, y=[kimg], z=[wmz],\n                inflation_factor=255, overlay_limits=(-0.3,0.3), verbose = True,\n                rotation_params = rp, filename='/users/ncullen/desktop/surface.png')\n\n    \"\"\"\n    TEMPFILES = []\n    len_x = len(x) if isinstance(x, (tuple,list)) else 1\n    len_y = len(y) if isinstance(y, (tuple,list)) else 1\n    len_z = len(z) if isinstance(z, (tuple,list)) else 1\n\n    if alpha is None:\n        alpha = [1] * (len_x+len_y)\n\n    if len_z != len_y:\n        raise ValueError('each y must have a mask in z')\n\n    if (overlay_limits is not None) and not isinstance(overlay_limits, (tuple, list)):\n        overlay_limits = [overlay_limits]\n\n    # not supported right now\n    domain_image_map = None\n    if domain_image_map is not None:\n        pass\n\n    if filename is None:\n        filename = mktemp()\n        #TEMPFILES.append(filename)\n    else:\n        filename = os.path.expanduser(filename)\n        if filename.endswith('.png'):\n            filename = filename.replace('.png','')\n\n    if not isinstance(rotation_params, np.ndarray):\n        if isinstance(rotation_params, (tuple, list)):\n            rotation_params = np.hstack(rotation_params)\n        rotation_params = np.array(rotation_params)\n    rotation_params = np.array(rotation_params).reshape(-1,3)\n\n    if (not isinstance(y, (tuple,list))) and (y is not None):\n        y = [y]\n    if (not isinstance(z, (tuple,list))) and (z is not None):\n        z = [z]\n\n    xfn = mktemp(suffix='.nii.gz')\n    TEMPFILES.append(xfn)\n    core.image_write(x, xfn)\n\n    pngs = []\n    gs = int(grayscale*255)\n    background_color = '%ix%ix%ix%s' % (gs,gs,gs,str(alpha[0]))\n\n    for myrot in range(rotation_params.shape[0]):\n        surfcmd = ['-s', '[%s,%s]' %(xfn,background_color)]\n\n        if y is not None:\n            ct = 0\n            if len(colormap) != len(y):\n                colormap = [colormap] * len(y)\n\n            for overlay in y:\n                ct = ct + 1\n                wms = utils.smooth_image(overlay, smoothing_sigma)\n                myquants = np.percentile(wms[np.abs(wms.numpy())>0], [q*100 for q in quantlimits])\n\n                if overlay_limits is not None or (isinstance(overlay_limits, list) and \\\n                    (np.sum([o is not None for o in overlay_limits])>0)):\n                    myquants = overlay_limits\n\n                kblobfn = mktemp(suffix='.nii.gz')\n                TEMPFILES.append(kblobfn)\n                core.image_write(z[ct-1], kblobfn)\n                overlayfn = mktemp(suffix='.nii.gz')\n                TEMPFILES.append(overlayfn)\n                core.image_write(wms, overlayfn)\n                csvlutfn = mktemp(suffix='.csv')\n                TEMPFILES.append(csvlutfn)\n                overlayrgbfn = mktemp(suffix='.nii.gz')\n                TEMPFILES.append(overlayrgbfn)\n                iio.scalar_to_rgb(dimension=3, img=overlayfn, outimg=overlayrgbfn, \n                    mask=kblobfn, colormap=colormap[ct-1], custom_colormap_file=None, \n                    min_input=myquants[0], max_input=myquants[1],\n                    min_rgb_output=0, max_rgb_output=255, vtk_lookup_table=csvlutfn)\n                alphaloc = alpha[min(ct, len(alpha)-1)]\n\n                surfcmd = surfcmd + ['-f', '[%s,%s,%s]' % (overlayrgbfn, kblobfn,str(alphaloc))]\n\n        rparamstring = 'x'.join([str(rp) for rp in rotation_params[myrot,:]])\n        pngext = myrot\n        if myrot < 10:\n            pngext = '0%s' % pngext\n        if myrot < 100:\n            pngext = '0%s' % pngext\n\n        pngfnloc = '%s%s.png' % (filename, pngext)\n        try:\n            os.remove(pngfnloc)\n        except:\n            pass\n\n        gs2 = int(bg_grayscale * 255.)\n        surfcmd += ['-d', '%s[%s,%ix%ix%i]'%(pngfnloc,rparamstring,gs2,gs2,gs2)]\n        surfcmd += ['-a', '%f' % tol]\n        surfcmd += ['-i', '%i' % inflation_factor]\n\n        libfn = utils.get_lib_fn('antsSurf')\n        libfn(surfcmd)\n\n        if rotation_params.shape[0] > 1:\n            pngs.append(pngfnloc)\n\n    # CLEANUP TEMP FILES\n    for tfile in TEMPFILES:\n        try:\n            os.remove(tfile)\n        except:\n            pass", "response": "Render a function onto a surface."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sparse_decom2(inmatrix,\n                    inmask=(None, None),\n                    sparseness=(0.01, 0.01),\n                    nvecs=3,\n                    its=20,\n                    cthresh=(0,0),\n                    statdir=None,\n                    perms=0,\n                    uselong=0,\n                    z=0,\n                    smooth=0,\n                    robust=0,\n                    mycoption=0,\n                    initialization_list=[],\n                    initialization_list2=[],\n                    ell1=10,\n                    prior_weight=0,\n                    verbose=False,\n                    rejector=0,\n                    max_based=False,\n                    version=1):\n    \"\"\"\n    Decomposes two matrices into paired sparse eigenevectors to\n    maximize canonical correlation - aka Sparse CCA.\n    Note: we do not scale the matrices internally. We leave\n    scaling choices to the user.\n\n    ANTsR function: `sparseDecom2`\n\n    Arguments\n    ---------\n    inmatrix : 2-tuple of ndarrays\n        input as inmatrix=(mat1,mat2). n by p input matrix and n by q input matrix , spatial variable lies along columns.\n\n    inmask : 2-tuple of ANTsImage types (optional - one or both)\n        optional pair of image masks\n\n    sparseness : tuple\n        a pair of float values e.g c(0.01,0.1) enforces an unsigned 99 percent and 90 percent sparse solution for each respective view\n\n    nvecs : integer\n        number of eigenvector pairs\n\n    its : integer\n        number of iterations, 10 or 20 usually sufficient\n\n    cthresh : 2-tuple\n        cluster threshold pair\n\n    statdir : string (optional)\n        temporary directory if you want to look at full output\n\n    perms : integer\n        number of permutations. settings permutations greater than 0 will estimate significance per vector empirically. For small datasets, these may be conservative. p-values depend on how one scales the input matrices.\n\n    uselong : boolean\n        enforce solutions of both views to be the same - requires matrices to be the same size\n\n    z : float\n        subject space (low-dimensional space) sparseness value\n\n    smooth : float\n        smooth the data (only available when mask is used)\n\n    robust : boolean\n        rank transform input matrices\n\n    mycoption : integer\n        enforce 1 - spatial orthogonality, 2 - low-dimensional orthogonality or 0 - both\n\n    initialization_list : list\n        initialization for first view\n\n    initialization_list2 : list\n        initialization for 2nd view\n\n    ell1 : float\n        gradient descent parameter, if negative then l0 otherwise use l1\n\n    prior_weight : scalar\n        Scalar value weight on prior between 0 (prior is weak) and 1 (prior is strong). Only engaged if initialization is used\n\n    verbose : boolean\n        activates verbose output to screen\n\n    rejector : scalar\n        rejects small correlation solutions\n\n    max_based : boolean\n        whether to choose max-based thresholding\n\n    Returns\n    -------\n    dict w/ following key/value pairs:\n\n        `projections` : ndarray\n            X projections\n\n        `projections2` : ndarray\n            Y projections\n\n        `eig1` : ndarray\n            X components\n\n        `eig2` : ndarray\n            Y components\n\n        `summary` : pd.DataFrame\n            first column is canonical correlations,\n            second column is p-values (these are `None` if perms > 0)\n\n    Example\n    -------\n    >>> import numpy as np\n    >>> import ants\n    >>> mat = np.random.randn(20, 100)\n    >>> mat2 = np.random.randn(20, 90)\n    >>> mydecom = ants.sparse_decom2(inmatrix = (mat,mat2),\n                                    sparseness=(0.1,0.3), nvecs=3,\n                                    its=3, perms=0)\n\n    \"\"\"\n    if inmatrix[0].shape[0] != inmatrix[1].shape[0]:\n        raise ValueError('Matrices must have same number of rows (samples)')\n\n    idim = 3\n\n    if isinstance(inmask[0], iio.ANTsImage):\n        maskx = inmask[0].clone('float')\n        idim = inmask[0].dimension\n        hasmaskx = 1\n    elif isinstance(inmask[0], np.ndarray):\n        maskx = core.from_numpy(inmask[0], pixeltype='float')\n        idim = inmask[0].ndim\n        hasmaskx = 1\n    else:\n        maskx = core.make_image([1]*idim, pixeltype='float')\n        hasmaskx = -1\n\n    if isinstance(inmask[1], iio.ANTsImage):\n        masky = inmask[1].clone('float')\n        idim = inmask[1].dimension\n        hasmasky = 1\n    elif isinstance(inmask[1], np.ndarray):\n        masky = core.from_numpy(inmask[1], pixeltype='float')\n        idim = inmask[1].ndim\n        hasmasky = 1\n    else:\n        masky = core.make_image([1]*idim, pixeltype='float')\n        hasmasky = -1\n\n    inmask = [maskx, masky]\n\n    if robust > 0:\n        raise NotImplementedError('robust > 0 not currently implemented')\n    else:\n        input_matrices = inmatrix\n\n    if idim == 2:\n        if version == 1:\n            sccancpp_fn = utils.get_lib_fn('sccanCpp2D')\n        elif version == 2:\n            sccancpp_fn = utils.get_lib_fn('sccanCpp2DV2')\n            input_matrices = (input_matrices[0].tolist(), input_matrices[1].tolist())\n    elif idim ==3:\n        if version == 1:\n            sccancpp_fn = utils.get_lib_fn('sccanCpp3D')\n        elif version == 2:\n            sccancpp_fn = utils.get_lib_fn('sccanCpp3DV2')\n            input_matrices = (input_matrices[0].tolist(), input_matrices[1].tolist())\n\n    outval = sccancpp_fn(input_matrices[0], input_matrices[1],\n                        inmask[0].pointer, inmask[1].pointer,\n                        hasmaskx, hasmasky,\n                        sparseness[0], sparseness[1],\n                        nvecs, its,\n                        cthresh[0], cthresh[1],\n                        z, smooth,\n                        initialization_list, initialization_list2,\n                        ell1, verbose,\n                        prior_weight, mycoption, max_based)\n\n\n    p1 = np.dot(input_matrices[0], outval['eig1'].T)\n    p2 = np.dot(input_matrices[1], outval['eig2'].T)\n    outcorrs = np.array([pearsonr(p1[:,i],p2[:,i])[0] for i in range(p1.shape[1])])\n    if prior_weight < 1e-10:\n        myord = np.argsort(np.abs(outcorrs))[::-1]\n        outcorrs = outcorrs[myord]\n        p1 = p1[:, myord]\n        p2 = p2[:, myord]\n        outval['eig1'] = outval['eig1'][myord,:]\n        outval['eig2'] = outval['eig2'][myord,:]\n\n    cca_summary = np.vstack((outcorrs,[None]*len(outcorrs))).T\n\n    if perms > 0:\n        cca_summary[:,1] = 0\n\n        nsubs = input_matrices[0].shape[0]\n        for permer in range(perms):\n            m1 = input_matrices[0][np.random.permutation(nsubs),:]\n            m2 = input_matrices[1][np.random.permutation(nsubs),:]\n            outvalperm = sccancpp_fn(m1, m2,\n                                inmask[0].pointer, inmask[1].pointer,\n                                hasmaskx, hasmasky,\n                                sparseness[0], sparseness[1],\n                                nvecs, its,\n                                cthresh[0], cthresh[1],\n                                z, smooth,\n                                initialization_list, initialization_list2,\n                                ell1, verbose,\n                                prior_weight, mycoption, max_based)\n            p1perm = np.dot(m1, outvalperm['eig1'].T)\n            p2perm = np.dot(m2, outvalperm['eig2'].T)\n            outcorrsperm = np.array([pearsonr(p1perm[:,i],p2perm[:,i])[0] for i in range(p1perm.shape[1])])\n            if prior_weight < 1e-10:\n                myord = np.argsort(np.abs(outcorrsperm))[::-1]\n                outcorrsperm = outcorrsperm[myord]\n            counter = np.abs(cca_summary[:,0]) < np.abs(outcorrsperm)\n            counter = counter.astype('int')\n            cca_summary[:,1] = cca_summary[:,1] + counter\n\n        cca_summary[:,1] = cca_summary[:,1] / float(perms)\n\n    return {'projections': p1,\n            'projections2': p2,\n            'eig1': outval['eig1'].T,\n            'eig2': outval['eig2'].T,\n            'summary': pd.DataFrame(cca_summary,columns=['corrs','pvalues'])}", "response": "This function is used to decompose two sparse ANTsImage matrices into paired sparse eigenvector vectors."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef eig_seg(mask, img_list, apply_segmentation_to_images=False, cthresh=0, smooth=1):\n    maskvox = mask > 0\n    maskseg = mask.clone()\n    maskseg[maskvox] = 0\n    if isinstance(img_list, np.ndarray):\n        mydata = img_list\n    elif isinstance(img_list, (tuple, list)):\n        mydata = core.image_list_to_matrix(img_list, mask)\n\n    if (smooth > 0):\n        for i in range(mydata.shape[0]):\n            temp_img = core.make_image(mask, mydata[i,:], pixeltype='float')\n            temp_img = utils.smooth_image(temp_img, smooth, sigma_in_physical_coordinates=True)\n            mydata[i,:] = temp_img[mask >= 0.5]\n\n    segids = np.argmax(np.abs(mydata), axis=0)+1\n    segmax = np.max(np.abs(mydata), axis=0)\n    maskseg[maskvox] = (segids * (segmax > 1e-09))\n\n    if cthresh > 0:\n        for kk in range(int(maskseg.max())):\n            timg = utils.threshold_image(maskseg, kk, kk)\n            timg = utils.label_clusters(timg, cthresh)\n            timg = utils.threshold_image(timg, 1, 1e15) * float(kk)\n            maskseg[maskseg == kk] = timg[maskseg == kk]\n\n    if (apply_segmentation_to_images) and (not isinstance(img_list, np.ndarray)):\n        for i in range(len(img_list)):\n            img = img_list[i]\n            img[maskseg != float(i)] = 0\n            img_list[i] = img\n\n    return maskseg", "response": "Segment a mask into regions based on the max value in an image list."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfunctioning to calculate label statistics from image and label", "response": "def label_stats(image, label_image):\n    \"\"\"\n    Get label statistics from image\n\n    ANTsR function: `labelStats`\n    \n    Arguments\n    ---------\n    image : ANTsImage \n        Image from which statistics will be calculated\n    \n    label_image : ANTsImage\n        Label image\n\n    Returns\n    -------\n    ndarray ?\n    \n    Example\n    -------\n    >>> import ants\n    >>> image = ants.image_read( ants.get_ants_data('r16') , 2 )\n    >>> image = ants.resample_image( image, (64,64), 1, 0 )\n    >>> mask = ants.get_mask(image)\n    >>> segs1 = ants.kmeans_segmentation( image, 3 )\n    >>> stats = ants.label_stats(image, segs1['segmentation'])\n    \"\"\"\n    image_float = image.clone('float')\n    label_image_int = label_image.clone('unsigned int')\n\n    libfn = utils.get_lib_fn('labelStats%iD' % image.dimension)\n    df = libfn(image_float.pointer, label_image_int.pointer)\n    #df = df[order(df$LabelValue), ]\n    return pd.DataFrame(df)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef labels_to_matrix(image, mask, target_labels=None, missing_val=np.nan):\n    if (not isinstance(image, iio.ANTsImage)) or (not isinstance(mask, iio.ANTsImage)):\n        raise ValueError('image and mask must be ANTsImage types')\n\n    vec = image[mask > 0]\n    \n    if target_labels is not None:\n        the_labels = target_labels\n    else:\n        the_labels = np.sort(np.unique(vec))\n\n    n_labels = len(the_labels)\n    labels = np.zeros((n_labels, len(vec)))\n\n    for i in range(n_labels):\n        lab = float(the_labels[i])\n        filler = (vec == lab).astype('float')\n        if np.sum(filler) == 0:\n            filler = np.asarray([np.nan]*len(vec))\n        labels[i,:] = filler\n    return labels", "response": "Convert a labeled image to an n x m matrix where n x m = number of voxels and m = number of labels in the image."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncopy origin direction and spacing from one antsImage to another ANTsImage", "response": "def copy_image_info(reference, target):\n    \"\"\"\n    Copy origin, direction, and spacing from one antsImage to another\n    \n    ANTsR function: `antsCopyImageInfo`\n\n    Arguments\n    ---------   \n    reference : ANTsImage\n        Image to get values from.\n    target  : ANTsImAGE\n        Image to copy values to\n\n    Returns\n    -------\n    ANTsImage\n        Target image with reference header information\n    \"\"\"\n    target.set_origin(reference.origin)\n    target.set_direction(reference.direction)\n    target.set_spacing(reference.spacing)\n    return target"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef image_physical_space_consistency(image1, image2, tolerance=1e-2, datatype=False):\n    images = [image1, image2]\n\n    img1 = images[0]\n    for img2 in images[1:]:\n        if (not isinstance(img1, ANTsImage)) or (not isinstance(img2, ANTsImage)):\n            raise ValueError('Both images must be of class `AntsImage`')\n\n        # image dimension check\n        if img1.dimension != img2.dimension:\n            return False\n\n        # image spacing check\n        space_diffs = sum([abs(s1-s2)>tolerance for s1, s2 in zip(img1.spacing, img2.spacing)])\n        if space_diffs > 0:\n            return False\n\n        # image origin check\n        origin_diffs = sum([abs(s1-s2)>tolerance for s1, s2 in zip(img1.origin, img2.origin)])\n        if origin_diffs > 0:\n            return False\n\n        # image direction check\n        origin_diff = np.allclose(img1.direction, img2.direction, atol=tolerance)\n        if not origin_diff:\n            return False\n\n        # data type\n        if datatype == True:\n            if img1.pixeltype != img2.pixeltype:\n                return False\n\n            if img1.components != img2.components:\n                return False\n\n    return True", "response": "Check if two ANTsImage objects occupy the same physical space."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of ANTsImages containing images of the highest pixeltype present in the list or all images of the highest pixeltype present in the list . pixeltype can be None to use unsigned char pixeltype", "response": "def image_type_cast(image_list, pixeltype=None):\n    \"\"\"\n    Cast a list of images to the highest pixeltype present in the list\n    or all to a specified type\n    \n    ANTsR function: `antsImageTypeCast`\n\n    Arguments\n    ---------\n    image_list : list/tuple\n        images to cast\n\n    pixeltype : string (optional)\n        pixeltype to cast to. If None, images will be cast to the highest\n        precision pixeltype found in image_list\n\n    Returns\n    -------\n    list of ANTsImages\n        given images casted to new type\n    \"\"\"\n    if not isinstance(image_list, (list,tuple)):\n        raise ValueError('image_list must be list of ANTsImage types')\n\n    pixtypes = []\n    for img in image_list:\n        pixtypes.append(img.pixeltype)\n\n    if pixeltype is None:\n        pixeltype = 'unsigned char'\n        for p in pixtypes:\n            if p == 'double':\n                pixeltype = 'double'\n            elif (p=='float') and (pixeltype!='double'):\n                pixeltype = 'float'\n            elif (p=='unsigned int') and (pixeltype!='float') and (pixeltype!='double'):\n                pixeltype = 'unsigned int'\n\n    out_images = []\n    for img in image_list:\n        if img.pixeltype == pixeltype:\n            out_images.append(img)\n        else:\n            out_images.append(img.clone(pixeltype))\n\n    return out_images"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the image spacing as a tuple.", "response": "def spacing(self):\n        \"\"\"\n        Get image spacing\n\n        Returns\n        -------\n        tuple\n        \"\"\"\n        libfn = utils.get_lib_fn('getSpacing%s'%self._libsuffix)\n        return libfn(self.pointer)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset image spacing for the current image.", "response": "def set_spacing(self, new_spacing):\n        \"\"\"\n        Set image spacing\n\n        Arguments\n        ---------\n        new_spacing : tuple or list\n            updated spacing for the image.\n            should have one value for each dimension\n\n        Returns\n        -------\n        None\n        \"\"\"\n        if not isinstance(new_spacing, (tuple, list)):\n            raise ValueError('arg must be tuple or list')\n        if len(new_spacing) != self.dimension:\n            raise ValueError('must give a spacing value for each dimension (%i)' % self.dimension)\n\n        libfn = utils.get_lib_fn('setSpacing%s'%self._libsuffix)\n        libfn(self.pointer, new_spacing)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef origin(self):\n        libfn = utils.get_lib_fn('getOrigin%s'%self._libsuffix)\n        return libfn(self.pointer)", "response": "Returns the image origin"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the image origin for this object.", "response": "def set_origin(self, new_origin):\n        \"\"\"\n        Set image origin\n\n        Arguments\n        ---------\n        new_origin : tuple or list\n            updated origin for the image.\n            should have one value for each dimension\n\n        Returns\n        -------\n        None\n        \"\"\"\n        if not isinstance(new_origin, (tuple, list)):\n            raise ValueError('arg must be tuple or list')\n        if len(new_origin) != self.dimension:\n            raise ValueError('must give a origin value for each dimension (%i)' % self.dimension)\n\n        libfn = utils.get_lib_fn('setOrigin%s'%self._libsuffix)\n        libfn(self.pointer, new_origin)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef direction(self):\n        libfn = utils.get_lib_fn('getDirection%s'%self._libsuffix)\n        return libfn(self.pointer)", "response": "Get image direction Returns ------- tuple\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_direction(self, new_direction):\n        if isinstance(new_direction, (tuple,list)):\n            new_direction = np.asarray(new_direction)\n\n        if not isinstance(new_direction, np.ndarray):\n            raise ValueError('arg must be np.ndarray or tuple or list')\n        if len(new_direction) != self.dimension:\n            raise ValueError('must give a origin value for each dimension (%i)' % self.dimension)\n\n        libfn = utils.get_lib_fn('setDirection%s'%self._libsuffix)\n        libfn(self.pointer, new_direction)", "response": "Set image direction\n\n        Arguments\n        ---------\n        new_direction : numpy.ndarray or tuple or list\n            updated direction for the image.\n            should have one value for each dimension\n\n        Returns\n        -------\n        None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef numpy(self, single_components=False):\n        array = np.array(self.view(single_components=single_components), copy=True, dtype=self.dtype)\n        if self.has_components or (single_components == True):\n            array = np.rollaxis(array, 0, self.dimension+1)\n        return array", "response": "Returns a numpy array representation of the underlying image data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef clone(self, pixeltype=None):\n        if pixeltype is None:\n            pixeltype = self.pixeltype\n\n        if pixeltype not in _supported_ptypes:\n            raise ValueError('Pixeltype %s not supported. Supported types are %s' % (pixeltype, _supported_ptypes))\n\n        if self.has_components and (not self.is_rgb):\n            comp_imgs = utils.split_channels(self)\n            comp_imgs_cloned = [comp_img.clone(pixeltype) for comp_img in comp_imgs]\n            return utils.merge_channels(comp_imgs_cloned)\n        else:\n            p1_short = utils.short_ptype(self.pixeltype)\n            p2_short = utils.short_ptype(pixeltype)\n            ndim = self.dimension\n            fn_suffix = '%s%i%s%i' % (p1_short,ndim,p2_short,ndim)\n            libfn = utils.get_lib_fn('antsImageClone%s'%fn_suffix)\n            pointer_cloned = libfn(self.pointer)\n            return ANTsImage(pixeltype=pixeltype, \n                            dimension=self.dimension, \n                            components=self.components, \n                            is_rgb=self.is_rgb,\n                            pointer=pointer_cloned)", "response": "Create a copy of this ANTsImage with the same data and info possibly with a different data type for the image."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncasting an ANTsImage to a given numpy datatype.", "response": "def astype(self, dtype):\n        \"\"\"\n        Cast & clone an ANTsImage to a given numpy datatype.\n\n        Map:\n            uint8   : unsigned char\n            uint32  : unsigned int\n            float32 : float\n            float64 : double\n        \"\"\"\n        if dtype not in _supported_dtypes:\n            raise ValueError('Datatype %s not supported. Supported types are %s' % (dtype, _supported_dtypes))\n\n        pixeltype = _npy_to_itk_map[dtype]\n        return self.clone(pixeltype)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new ANTsImage with the same header information but with a new array.", "response": "def new_image_like(self, data):\n        \"\"\"\n        Create a new ANTsImage with the same header information, but with \n        a new image array.\n\n        Arguments\n        ---------\n        data : ndarray or py::capsule\n            New array or pointer for the image. \n            It must have the same shape as the current\n            image data.\n\n        Returns\n        -------\n        ANTsImage\n        \"\"\"\n        if not isinstance(data, np.ndarray):\n            raise ValueError('data must be a numpy array')\n        if not self.has_components:\n            if data.shape != self.shape:\n                raise ValueError('given array shape (%s) and image array shape (%s) do not match' % (data.shape, self.shape))\n        else:\n            if (data.shape[-1] != self.components) or (data.shape[:-1] != self.shape):\n                raise ValueError('given array shape (%s) and image array shape (%s) do not match' % (data.shape[1:], self.shape))\n\n        return iio2.from_numpy(data, origin=self.origin, \n            spacing=self.spacing, direction=self.direction, \n            has_components=self.has_components)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites the ANTsImage to file", "response": "def to_file(self, filename):\n        \"\"\"\n        Write the ANTsImage to file\n\n        Args\n        ----\n        filename : string\n            filepath to which the image will be written\n        \"\"\"\n        filename = os.path.expanduser(filename)\n        libfn = utils.get_lib_fn('toFile%s'%self._libsuffix)\n        libfn(self.pointer, filename)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef apply(self, fn):\n        this_array = self.numpy()\n        new_array = fn(this_array)\n        return self.new_image_like(new_array)", "response": "Apply an arbitrary function to ANTsImage.\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sum(self, axis=None, keepdims=False):\n        return self.numpy().sum(axis=axis, keepdims=keepdims)", "response": "Return sum along specified axis"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef range(self, axis=None):\n        return (self.min(axis=axis), self.max(axis=axis))", "response": "Return tuple along specified axis"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the indices of the elements along specified axis", "response": "def argrange(self, axis=None):\n        \"\"\" Return argrange along specified axis \"\"\"\n        amin = self.argmin(axis=axis)\n        amax = self.argmax(axis=axis)\n        if axis is None:\n            return (amin, amax)\n        else:\n            return np.stack([amin, amax]).T"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning unique set of values in image", "response": "def unique(self, sort=False):\n        \"\"\" Return unique set of values in image \"\"\"\n        unique_vals = np.unique(self.numpy())\n        if sort:\n            unique_vals = np.sort(unique_vals)\n        return unique_vals"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef uniquekeys(self, metakey=None):\n        if metakey is None:\n            return self._uniquekeys\n        else:\n            if metakey not in self.metakeys():\n                raise ValueError('metakey %s does not exist' % metakey)\n            return self._uniquekeys[metakey]", "response": "Get unique keys for a given metakey"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef label_clusters(image, min_cluster_size=50, min_thresh=1e-6, max_thresh=1, fully_connected=False):\n    dim = image.dimension\n    clust = threshold_image(image, min_thresh, max_thresh)\n    temp = int(fully_connected)\n    args = [dim, clust, clust, min_cluster_size, temp]\n    processed_args = _int_antsProcessArguments(args)\n    libfn = utils.get_lib_fn('LabelClustersUniquely')\n    libfn(processed_args)\n    return clust", "response": "This function labels the nodes of the image in the ANTsImage by using the threshold image function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfunction to create a label image from a set of points.", "response": "def make_points_image(pts, mask, radius=5):\n    \"\"\"\n    Create label image from physical space points\n\n    Creates spherical points in the coordinate space of the target image based\n    on the n-dimensional matrix of points that the user supplies. The image\n    defines the dimensionality of the data so if the input image is 3D then\n    the input points should be 2D or 3D.\n\n    ANTsR function: `makePointsImage`\n\n    Arguments\n    ---------\n    pts : numpy.ndarray\n        input powers points\n\n    mask : ANTsImage\n        mask defining target space\n\n    radius : integer\n        radius for the points\n\n    Returns\n    -------\n    ANTsImage\n\n    Example\n    -------\n    >>> import ants\n    >>> import pandas as pd\n    >>> mni = ants.image_read(ants.get_data('mni')).get_mask()\n    >>> powers_pts = pd.read_csv(ants.get_data('powers_mni_itk'))\n    >>> powers_labels = ants.make_points_image(powers_pts.iloc[:,:3].values, mni, radius=3)\n    \"\"\"\n    powers_lblimg = mask * 0\n    npts = len(pts)\n    dim = mask.dimension\n    if pts.shape[1] != dim:\n        raise ValueError('points dimensionality should match that of images')\n\n    for r in range(npts):\n        pt = pts[r,:]\n        idx = tio.transform_physical_point_to_index(mask, pt.tolist() ).astype(int)\n        in_image = (np.prod(idx <= mask.shape)==1) and (len(np.where(idx<0)[0])==0)\n        if ( in_image == True ):\n            if (dim == 3):\n                powers_lblimg[idx[0],idx[1],idx[2]] = r + 1\n            elif (dim == 2):\n                powers_lblimg[idx[0],idx[1]] = r + 1\n    return utils.morphology( powers_lblimg, 'dilate', radius, 'grayscale' )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef weingarten_image_curvature(image, sigma=1.0, opt='mean'):\n    if image.dimension not in {2,3}:\n        raise ValueError('image must be 2D or 3D')\n\n    if image.dimension == 2:\n        d = image.shape\n        temp = np.zeros(list(d)+[10])\n        for k in range(1,7):\n            voxvals = image[:d[0],:d[1]]\n            temp[:d[0],:d[1],k] = voxvals\n        temp = core.from_numpy(temp)\n        myspc = image.spacing\n        myspc = list(myspc) + [min(myspc)]\n        temp.set_spacing(myspc)\n        temp = temp.clone('float')\n    else:\n        temp = image.clone('float')\n\n    optnum = 0\n    if opt == 'gaussian': \n        optnum = 6\n    if opt == 'characterize':\n        optnum = 5\n\n    libfn = utils.get_lib_fn('weingartenImageCurvature')\n    mykout = libfn(temp.pointer, sigma, optnum)\n    mykout = iio.ANTsImage(pixeltype=image.pixeltype, dimension=3,\n                            components=image.components, pointer=mykout)\n    if image.dimension == 3:\n        return mykout\n    elif image.dimension == 2:\n        subarr = core.from_numpy(mykout.numpy()[:,:,4])\n        return core.copy_image_info(image, subarr)", "response": "Returns ANTsImage object for curvature estimate of image from which curvature is calculated."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfunction to create an ants. ANTsImage object that computes the jacobian of the determinant from a transformation file.", "response": "def create_jacobian_determinant_image(domain_image, tx, do_log=False, geom=False):\n    \"\"\"\n    Compute the jacobian determinant from a transformation file\n   \n    ANTsR function: `createJacobianDeterminantImage`\n\n    Arguments\n    ---------\n    domain_image : ANTsImage\n        image that defines transformation domain\n    \n    tx : string\n        deformation transformation file name\n    \n    do_log : boolean\n        return the log jacobian\n    \n    geom : bolean\n        use the geometric jacobian calculation (boolean)\n    \n    Returns\n    -------\n    ANTsImage\n\n    Example\n    -------\n    >>> import ants\n    >>> fi = ants.image_read( ants.get_ants_data('r16'))\n    >>> mi = ants.image_read( ants.get_ants_data('r64'))\n    >>> fi = ants.resample_image(fi,(128,128),1,0)\n    >>> mi = ants.resample_image(mi,(128,128),1,0)\n    >>> mytx = ants.registration(fixed=fi , moving=mi, type_of_transform = ('SyN') )\n    >>> jac = ants.create_jacobian_determinant_image(fi,mytx['fwdtransforms'][0],1)\n    \"\"\"\n    dim = domain_image.dimension\n    if isinstance(tx, iio.ANTsImage):\n        txuse = mktemp(suffix='.nii.gz')\n        iio2.image_write(tx, txuse)\n    else:\n        txuse = tx\n    #args = [dim, txuse, do_log]\n    dimage = domain_image.clone('double')\n    args2 = [dim, txuse, dimage, int(do_log), int(geom)]\n    processed_args = utils._int_antsProcessArguments(args2)\n    libfn = utils.get_lib_fn('CreateJacobianDeterminantImage')\n    libfn(processed_args)\n    jimage = args2[2].clone('float')\n    \n    return jimage"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating an ANTsImage object from a numpy array", "response": "def from_numpy(data, origin=None, spacing=None, direction=None, has_components=False, is_rgb=False):\n    \"\"\"\n    Create an ANTsImage object from a numpy array\n\n    ANTsR function: `as.antsImage`\n\n    Arguments\n    ---------\n    data : ndarray\n        image data array\n\n    origin : tuple/list\n        image origin\n\n    spacing : tuple/list\n        image spacing\n\n    direction : list/ndarray\n        image direction\n\n    has_components : boolean\n        whether the image has components\n\n    Returns\n    -------\n    ANTsImage\n        image with given data and any given information\n    \"\"\"\n    data = data.astype('float32') if data.dtype.name == 'float64' else data\n    img = _from_numpy(data.T.copy(), origin, spacing, direction, has_components, is_rgb)\n    return img"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _from_numpy(data, origin=None, spacing=None, direction=None, has_components=False, is_rgb=False):\n    if is_rgb: has_components = True\n    ndim = data.ndim\n    if has_components:\n        ndim -= 1\n    dtype = data.dtype.name\n    ptype = _npy_to_itk_map[dtype]\n\n    data = np.array(data)\n\n    if origin is None: origin = tuple([0.]*ndim)\n    if spacing is None: spacing = tuple([1.]*ndim)\n    if direction is None: direction = np.eye(ndim)\n\n    libfn = utils.get_lib_fn('fromNumpy%s%i' % (_ntype_type_map[dtype], ndim))\n\n    if not has_components:\n        itk_image = libfn(data, data.shape[::-1])\n        ants_image = iio.ANTsImage(pixeltype=ptype, dimension=ndim, components=1, pointer=itk_image)\n        ants_image.set_origin(origin)\n        ants_image.set_spacing(spacing)\n        ants_image.set_direction(direction)\n        ants_image._ndarr = data\n    else:\n        arrays = [data[i,...].copy() for i in range(data.shape[0])]\n        data_shape = arrays[0].shape\n        ants_images = []\n        for i in range(len(arrays)):\n            tmp_ptr = libfn(arrays[i], data_shape[::-1])\n            tmp_img = iio.ANTsImage(pixeltype=ptype,\n                                    dimension=ndim,\n                                    components=1,\n                                    pointer=tmp_ptr)\n            tmp_img.set_origin(origin)\n            tmp_img.set_spacing(spacing)\n            tmp_img.set_direction(direction)\n            tmp_img._ndarr = arrays[i]\n            ants_images.append(tmp_img)\n        ants_image = utils.merge_channels(ants_images)\n        if is_rgb: ants_image = ants_image.vector_to_rgb()\n    return ants_image", "response": "Internal function for creating an ANTsImage object from numpy array."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfunctioning to make an image with given size and voxel value or given a mask and vector.", "response": "def make_image(imagesize, voxval=0, spacing=None, origin=None, direction=None, has_components=False, pixeltype='float'):\n    \"\"\"\n    Make an image with given size and voxel value or given a mask and vector\n\n    ANTsR function: `makeImage`\n\n    Arguments\n    ---------\n    shape : tuple/ANTsImage\n        input image size or mask\n\n    voxval : scalar\n        input image value or vector, size of mask\n\n    spacing : tuple/list\n        image spatial resolution\n\n    origin  : tuple/list\n        image spatial origin\n\n    direction : list/ndarray\n        direction matrix to convert from index to physical space\n\n    components : boolean\n        whether there are components per pixel or not\n\n    pixeltype : float\n        data type of image values\n\n    Returns\n    -------\n    ANTsImage\n    \"\"\"\n    if isinstance(imagesize, iio.ANTsImage):\n        img = imagesize.clone()\n        sel = imagesize > 0\n        if voxval.ndim > 1:\n                voxval = voxval.flatten()\n        if (len(voxval) == int((sel>0).sum())) or (len(voxval) == 0):\n            img[sel] = voxval\n        else:\n            raise ValueError('Num given voxels %i not same as num positive values %i in `imagesize`' % (len(voxval), int((sel>0).sum())))\n        return img\n    else:\n        if isinstance(voxval, (tuple,list,np.ndarray)):\n            array = np.asarray(voxval).astype('float32').reshape(imagesize)\n        else:\n            array = np.full(imagesize,voxval,dtype='float32')\n        image = from_numpy(array, origin=origin, spacing=spacing,\n                            direction=direction, has_components=has_components)\n        return image.clone(pixeltype)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nunmasking rows of a matrix and writes as images ANTsR function: `matrixToImages` Arguments --------- data_matrix : numpy.ndarray each row corresponds to an image array should have number of columns equal to non-zero voxels in the mask mask : ANTsImage image containing a binary mask. Rows of the matrix are unmasked and written as images. The mask defines the output image space Returns ------- list of ANTsImage types", "response": "def matrix_to_images(data_matrix, mask):\n    \"\"\"\n    Unmasks rows of a matrix and writes as images\n\n    ANTsR function: `matrixToImages`\n\n    Arguments\n    ---------\n    data_matrix : numpy.ndarray\n        each row corresponds to an image\n        array should have number of columns equal to non-zero voxels in the mask\n\n    mask : ANTsImage\n        image containing a binary mask. Rows of the matrix are\n        unmasked and written as images. The mask defines the output image space\n\n    Returns\n    -------\n    list of ANTsImage types\n    \"\"\"\n\n    if data_matrix.ndim > 2:\n        data_matrix = data_matrix.reshape(data_matrix.shape[0], -1)\n\n    numimages = len(data_matrix)\n    numVoxelsInMatrix = data_matrix.shape[1]\n    numVoxelsInMask = (mask >= 0.5).sum()\n    if numVoxelsInMask != numVoxelsInMatrix:\n        raise ValueError('Num masked voxels %i must match data matrix %i' % (numVoxelsInMask, numVoxelsInMatrix))\n\n    imagelist = []\n    for i in range(numimages):\n        img = mask.clone()\n        img[mask >= 0.5] = data_matrix[i,:]\n        imagelist.append(img)\n    return imagelist"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads images into rows of a matrix.", "response": "def images_to_matrix(image_list, mask=None, sigma=None, epsilon=0.5 ):\n    \"\"\"\n    Read images into rows of a matrix, given a mask - much faster for\n    large datasets as it is based on C++ implementations.\n\n    ANTsR function: `imagesToMatrix`\n\n    Arguments\n    ---------\n    image_list : list of ANTsImage types\n        images to convert to ndarray\n\n    mask : ANTsImage (optional)\n        image containing binary mask. voxels in the mask are placed in the matrix\n\n    sigma : scaler (optional)\n        smoothing factor\n\n    epsilon : scalar\n        threshold for mask\n\n    Returns\n    -------\n    ndarray\n        array with a row for each image\n        shape = (N_IMAGES, N_VOXELS)\n\n    Example\n    -------\n    >>> import ants\n    >>> img = ants.image_read(ants.get_ants_data('r16'))\n    >>> img2 = ants.image_read(ants.get_ants_data('r16'))\n    >>> img3 = ants.image_read(ants.get_ants_data('r16'))\n    >>> mat = ants.image_list_to_matrix([img,img2,img3])\n    \"\"\"\n    def listfunc(x):\n        if np.sum(np.array(x.shape) - np.array(mask.shape)) != 0:\n            x = reg.resample_image_to_target(x, mask, 2)\n        return x[mask]\n\n    if mask is None:\n        mask = utils.get_mask(image_list[0])\n\n    num_images = len(image_list)\n    mask_arr = mask.numpy() >= epsilon\n    num_voxels = np.sum(mask_arr)\n\n    data_matrix = np.empty((num_images, num_voxels))\n    do_smooth = sigma is not None\n    for i,img in enumerate(image_list):\n        if do_smooth:\n            data_matrix[i, :] = listfunc(utils.smooth_image(img, sigma, sigma_in_physical_coordinates=True))\n        else:\n            data_matrix[i,:] = listfunc(img)\n    return data_matrix"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef timeseries_to_matrix( image, mask=None ):\n    temp = utils.ndimage_to_list( image )\n    if mask is None:\n        mask = temp[0]*0 + 1\n    return image_list_to_matrix( temp, mask )", "response": "Convert a timeseries image into a matrix."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef matrix_to_timeseries( image, matrix, mask=None ):\n\n    if mask is None:\n        mask = temp[0]*0 + 1\n    temp = matrix_to_images( matrix, mask )\n    newImage = utils.list_to_ndimage( image, temp)\n    iio.copy_image_info( image, newImage)\n    return(newImage)", "response": "Function to convert a matrix to a ND image."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef image_header_info(filename):\n    if not os.path.exists(filename):\n        raise Exception('filename does not exist')\n\n    libfn = utils.get_lib_fn('antsImageHeaderInfo')\n    retval = libfn(filename)\n    retval['dimensions'] = tuple(retval['dimensions'])\n    retval['origin'] = tuple([round(o,4) for o in retval['origin']])\n    retval['spacing'] = tuple([round(s,4) for s in retval['spacing']])\n    retval['direction'] = np.round(retval['direction'],4)\n    return retval", "response": "Reads file info from image header file ANTsR function"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef image_read(filename, dimension=None, pixeltype='float', reorient=False):\n    if filename.endswith('.npy'):\n        filename = os.path.expanduser(filename)\n        img_array = np.load(filename)\n        if os.path.exists(filename.replace('.npy', '.json')):\n            with open(filename.replace('.npy', '.json')) as json_data:\n                img_header = json.load(json_data)\n            ants_image = from_numpy(img_array,\n                                    origin=img_header.get('origin', None),\n                                    spacing=img_header.get('spacing', None),\n                                    direction=np.asarray(img_header.get('direction',None)),\n                                    has_components=img_header.get('components',1)>1)\n        else:\n            img_header = {}\n            ants_image = from_numpy(img_array)\n\n    else:\n        filename = os.path.expanduser(filename)\n        if not os.path.exists(filename):\n            raise ValueError('File %s does not exist!' % filename)\n\n        hinfo = image_header_info(filename)\n        ptype = hinfo['pixeltype']\n        pclass = hinfo['pixelclass']\n        ndim = hinfo['nDimensions']\n        ncomp = hinfo['nComponents']\n        is_rgb = True if pclass == 'rgb' else False\n        if dimension is not None:\n            ndim = dimension\n\n        # error handling on pixelclass\n        if pclass not in _supported_pclasses:\n            raise ValueError('Pixel class %s not supported!' % pclass)\n\n        # error handling on pixeltype\n        if ptype in _unsupported_ptypes:\n            ptype = _unsupported_ptype_map.get(ptype, 'unsupported')\n            if ptype == 'unsupported':\n                raise ValueError('Pixeltype %s not supported' % ptype)\n\n        # error handling on dimension\n        if (ndim < 2) or (ndim > 4):\n            raise ValueError('Found %i-dimensional image - not supported!' % ndim)\n\n        libfn = utils.get_lib_fn(_image_read_dict[pclass][ptype][ndim])\n        itk_pointer = libfn(filename)\n\n        ants_image = iio.ANTsImage(pixeltype=ptype, dimension=ndim, components=ncomp,\n            pointer=itk_pointer, is_rgb=is_rgb)\n\n        if pixeltype is not None:\n            ants_image = ants_image.clone(pixeltype)\n\n    if (reorient != False) and (ants_image.dimension == 3):\n        if reorient == True:\n            ants_image = ants_image.reorient_image2('RPI')\n        elif isinstance(reorient, str):\n            ants_image = ants_image.reorient_image2(reorient)\n\n    return ants_image", "response": "Function to read an image from file and return ANTsImage object"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads a set of dicom files in a directory into a single ANTsImage.", "response": "def dicom_read(directory, pixeltype='float'):\n    \"\"\"\n    Read a set of dicom files in a directory into a single ANTsImage.\n    The origin of the resulting 3D image will be the origin of the\n    first dicom image read.\n\n    Arguments\n    ---------\n    directory : string\n        folder in which all the dicom images exist\n\n    Returns\n    -------\n    ANTsImage\n\n    Example\n    -------\n    >>> import ants\n    >>> img = ants.dicom_read('~/desktop/dicom-subject/')\n    \"\"\"\n    slices = []\n    imgidx = 0\n    for imgpath in os.listdir(directory):\n        if imgpath.endswith('.dcm'):\n            if imgidx == 0:\n                tmp = image_read(os.path.join(directory,imgpath), dimension=3, pixeltype=pixeltype)\n                origin = tmp.origin\n                spacing = tmp.spacing\n                direction = tmp.direction\n                tmp = tmp.numpy()[:,:,0]\n            else:\n                tmp = image_read(os.path.join(directory,imgpath), dimension=2, pixeltype=pixeltype).numpy()\n\n            slices.append(tmp)\n            imgidx += 1\n\n    slices = np.stack(slices, axis=-1)\n    return from_numpy(slices, origin=origin, spacing=spacing, direction=direction)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef image_write(image, filename, ri=False):\n    if filename.endswith('.npy'):\n        img_array = image.numpy()\n        img_header = {'origin': image.origin,'spacing': image.spacing,\n                        'direction': image.direction.tolist(), 'components': image.components}\n\n        np.save(filename, img_array)\n        with open(filename.replace('.npy','.json'), 'w') as outfile:\n            json.dump(img_header, outfile)\n    else:\n        image.to_file(filename)\n\n    if ri:\n        return image", "response": "An image write function that saves ANTsImage to file"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef otsu_segmentation(image, k, mask=None):\n    if mask is not None:\n        image = image.mask_image(mask)\n\n    seg = image.threshold_image('Otsu', k)\n    return seg", "response": "A very fast ANTsR segmentation algorithm good for quick explortation of image."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef affine_initializer(fixed_image, moving_image, search_factor=20,\n                        radian_fraction=0.1, use_principal_axis=False, \n                        local_search_iterations=10, mask=None, txfn=None ):\n    \"\"\"\n    A multi-start optimizer for affine registration\n    Searches over the sphere to find a good initialization for further\n    registration refinement, if needed.  This is a arapper for the ANTs\n    function antsAffineInitializer.\n    \n    ANTsR function: `affineInitializer`\n\n    Arguments\n    ---------\n    fixed_image : ANTsImage\n        the fixed reference image\n    moving_image : ANTsImage \n        the moving image to be mapped to the fixed space\n    search_factor : scalar\n        degree of increments on the sphere to search\n    radian_fraction : scalar\n        between zero and one, defines the arc to search over\n    use_principal_axis : boolean\n        boolean to initialize by principal axis\n    local_search_iterations : scalar\n        gradient descent iterations\n    mask : ANTsImage (optional)\n        optional mask to restrict registration\n    txfn : string (optional)\n        filename for the transformation\n\n    Returns\n    -------\n    ndarray\n        transformation matrix\n    \n    Example\n    -------\n    >>> import ants\n    >>> fi = ants.image_read(ants.get_ants_data('r16'))\n    >>> mi = ants.image_read(ants.get_ants_data('r27'))\n    >>> txfile = ants.affine_initializer( fi, mi )\n    >>> tx = ants.read_transform(txfile, dimension=2)\n    \"\"\"\n\n    if txfn is None:\n        txfn = mktemp(suffix='.mat')\n\n    veccer = [fixed_image.dimension, fixed_image, moving_image, txfn,\n                search_factor, radian_fraction, int(use_principal_axis),\n                local_search_iterations]\n    if mask is not None:\n        veccer.append(mask)\n\n    xxx = utils._int_antsProcessArguments(veccer)\n    libfn = utils.get_lib_fn('antsAffineInitializer')\n    retval = libfn(xxx)\n\n    if retval != 0:\n        warnings.warn('ERROR: Non-zero exit status!')\n    \n    return txfn", "response": "A multi - start optimizer for antAllergy initialization for the ANTsAffine model."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef crop_image(image, label_image=None, label=1):\n    inpixeltype = image.pixeltype\n    ndim = image.dimension\n    if image.pixeltype != 'float':\n        image = image.clone('float')\n\n    if label_image is None:\n        label_image = get_mask(image)\n\n    if label_image.pixeltype != 'float':\n        label_image = label_image.clone('float')\n\n    libfn = utils.get_lib_fn('cropImageF%i' % ndim)\n    itkimage = libfn(image.pointer, label_image.pointer, label, 0, [], [])\n    return iio.ANTsImage(pixeltype='float', dimension=ndim, \n                        components=image.components, pointer=itkimage).clone(inpixeltype)", "response": "This function crops an image from within a larger ANTsImage"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a proper ANTsImage sub - image by indexing the image with indices.", "response": "def crop_indices(image, lowerind, upperind):\n    \"\"\"\n    Create a proper ANTsImage sub-image by indexing the image with indices. \n    This is similar to but different from array sub-setting in that \n    the resulting sub-image can be decropped back into its place without \n    having to store its original index locations explicitly.\n    \n    ANTsR function: `cropIndices`\n\n    Arguments\n    ---------\n    image : ANTsImage  \n        image to crop\n    \n    lowerind : list/tuple of integers  \n        vector of lower index, should be length image dimensionality\n    \n    upperind : list/tuple of integers\n        vector of upper index, should be length image dimensionality\n    \n    Returns\n    -------\n    ANTsImage\n\n    Example\n    -------\n    >>> import ants\n    >>> fi = ants.image_read( ants.get_ants_data(\"r16\"))\n    >>> cropped = ants.crop_indices( fi, (10,10), (100,100) )\n    >>> cropped = ants.smooth_image( cropped, 5 )\n    >>> decropped = ants.decrop_image( cropped, fi )\n    \"\"\"\n    inpixeltype = 'float'\n    if image.pixeltype != 'float':\n        inpixeltype = image.pixeltype\n        image = image.clone('float')\n\n    if (image.dimension != len(lowerind)) or (image.dimension != len(upperind)):\n        raise ValueError('image dimensionality and index length must match')\n\n    libfn = utils.get_lib_fn('cropImageF%i' % image.dimension)\n    itkimage = libfn(image.pointer, image.pointer, 1, 2, lowerind, upperind)\n    ants_image = iio.ANTsImage(pixeltype='float', dimension=image.dimension,\n                        components=image.components, pointer=itkimage)\n    if inpixeltype != 'float':\n        ants_image = ants_image.clone(inpixeltype)\n    return ants_image"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef reorient_image2(image, orientation='RAS'):\n    if image.dimension != 3:\n        raise ValueError('image must have 3 dimensions')\n\n    inpixeltype = image.pixeltype\n    ndim = image.dimension\n    if image.pixeltype != 'float':\n        image = image.clone('float')\n\n    libfn = utils.get_lib_fn('reorientImage2')\n    itkimage = libfn(image.pointer, orientation)\n\n    new_img = iio.ANTsImage(pixeltype='float', dimension=ndim, \n                         components=image.components, pointer=itkimage)#.clone(inpixeltype)\n    if inpixeltype != 'float':\n        new_img = new_img.clone(inpixeltype)\n    return new_img", "response": "Reorient an image to a new image."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\naligns image along a specified axis ANTsR function: `reorientImage` Arguments --------- image : ANTsImage image to reorient axis1 : list/tuple of integers vector of size dim, might need to play w/axis sign axis2 : list/tuple of integers vector of size dim for 3D doreflection : boolean whether to reflect doscale : scalar value 1 allows automated estimate of scaling txfn : string file name for transformation Returns ------- ANTsImage Example ------- >>> import ants >>> image = ants.image_read(ants.get_ants_data('r16')) >>> ants.reorient_image(image, (1,0))", "response": "def reorient_image(image, axis1, axis2=None, doreflection=False, doscale=0, txfn=None):\n    \"\"\"\n    Align image along a specified axis\n\n    ANTsR function: `reorientImage`\n    \n    Arguments\n    ---------\n    image : ANTsImage\n        image to reorient\n    \n    axis1 : list/tuple of integers\n        vector of size dim, might need to play w/axis sign\n    \n    axis2 : list/tuple of integers\n        vector of size dim for 3D\n    \n    doreflection : boolean\n        whether to reflect\n    \n    doscale : scalar value\n         1 allows automated estimate of scaling\n    \n    txfn : string\n        file name for transformation\n    \n    Returns\n    -------\n    ANTsImage\n\n    Example\n    -------\n    >>> import ants\n    >>> image = ants.image_read(ants.get_ants_data('r16'))\n    >>> ants.reorient_image(image, (1,0))\n    \"\"\"\n    inpixeltype = image.pixeltype\n    if image.pixeltype != 'float':\n        image = image.clone('float')\n\n    axis_was_none = False\n    if axis2 is None:\n        axis_was_none = True\n        axis2 = [0]*image.dimension\n\n    axis1 = np.array(axis1)\n    axis2 = np.array(axis2)\n\n    axis1 = axis1 / np.sqrt(np.sum(axis1*axis1)) * (-1)\n    axis1 = axis1.astype('int')\n\n    if not axis_was_none:\n        axis2 = axis2 / np.sqrt(np.sum(axis2*axis2)) * (-1)\n        axis2 = axis2.astype('int')\n    else:\n        axis2 = np.array([0]*image.dimension).astype('int')\n\n    if txfn is None:\n        txfn = mktemp(suffix='.mat')\n\n    if isinstance(doreflection, tuple):\n        doreflection = list(doreflection)\n    if not isinstance(doreflection, list):\n        doreflection = [doreflection]\n\n    if isinstance(doscale, tuple):\n        doscale = list(doscale)\n    if not isinstance(doscale, list):\n        doscale = [doscale]\n\n    if len(doreflection) == 1:\n        doreflection = [doreflection[0]]*image.dimension\n    if len(doscale) == 1:\n        doscale = [doscale[0]]*image.dimension\n\n    libfn = utils.get_lib_fn('reorientImage%s' % image._libsuffix)\n    libfn(image.pointer, txfn, axis1.tolist(), axis2.tolist(), doreflection, doscale)\n    image2 = apply_transforms(image, image, transformlist=[txfn])\n\n    if image.pixeltype != inpixeltype:\n        image2 = image2.clone(inpixeltype)\n\n    return {'reoimage':image2,\n            'txfn':txfn}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_center_of_mass(image):\n    if image.pixeltype != 'float':\n        image = image.clone('float')\n\n    libfn = utils.get_lib_fn('centerOfMass%s' % image._libsuffix)\n    com = libfn(image.pointer)\n\n    return tuple(com)", "response": "Function to compute the center of mass in physical space which is defined \n    as the mean of the intensity weighted voxel coordinate system."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert an ANTsImage to a Nibabel image", "response": "def to_nibabel(image):\n    \"\"\"\n    Convert an ANTsImage to a Nibabel image\n    \"\"\"\n    if image.dimension != 3:\n        raise ValueError('Only 3D images currently supported')\n\n    import nibabel as nib\n    array_data = image.numpy()\n    affine = np.hstack([image.direction*np.diag(image.spacing),np.array(image.origin).reshape(3,1)])\n    affine = np.vstack([affine, np.array([0,0,0,1.])])\n    affine[:2,:] *= -1\n    new_img = nib.Nifti1Image(array_data, affine)\n    return new_img"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a nibabel image to ANTsImage", "response": "def from_nibabel(nib_image):\n    \"\"\"\n    Convert a nibabel image to an ANTsImage\n    \"\"\"\n    tmpfile = mktemp(suffix='.nii.gz')\n    nib_image.to_filename(tmpfile)\n    new_img = iio2.image_read(tmpfile)\n    os.remove(tmpfile)\n    return new_img"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef transform(self, X=None, y=None):\n        # random draw in shear range\n        shear_x = random.gauss(self.shear_range[0], self.shear_range[1])\n        shear_y = random.gauss(self.shear_range[0], self.shear_range[1])\n        shear_z = random.gauss(self.shear_range[0], self.shear_range[1])\n        self.params = (shear_x, shear_y, shear_z)\n\n        tx = Shear3D((shear_x, shear_y, shear_z),\n                     reference=self.reference,\n                     lazy=self.lazy)\n\n        return tx.transform(X,y)", "response": "Transform an image using an Affine transform with shear parameters randomly generated from the user - specified range."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntransforming an image using an Affine transform with the given rotation parameters.", "response": "def transform(self, X=None, y=None):\n        \"\"\"\n        Transform an image using an Affine transform with the given\n        rotation parameters.  Return the transform if X=None.\n\n        Arguments\n        ---------\n        X : ANTsImage\n            Image to transform\n\n        y : ANTsImage (optional)\n            Another image to transform\n\n        Returns\n        -------\n        ANTsImage if y is None, else a tuple of ANTsImage types\n\n        Examples\n        --------\n        >>> import ants\n        >>> img = ants.image_read(ants.get_data('ch2'))\n        >>> tx = ants.contrib.Rotate3D(rotation=(10,-5,12))\n        >>> img2 = tx.transform(img)\n        \"\"\"\n        # unpack zoom range\n        rotation_x, rotation_y, rotation_z = self.rotation\n\n        # Rotation about X axis\n        theta_x = math.pi / 180 * rotation_x\n        rotate_matrix_x = np.array([[1, 0,                  0,                 0],\n                                    [0, math.cos(theta_x), -math.sin(theta_x), 0],\n                                    [0, math.sin(theta_x),  math.cos(theta_x), 0],\n                                    [0,0,0,1]])\n\n        # Rotation about Y axis\n        theta_y = math.pi / 180 * rotation_y\n        rotate_matrix_y = np.array([[math.cos(theta_y),  0, math.sin(theta_y), 0],\n                                    [0,                  1, 0,                 0],\n                                    [-math.sin(theta_y), 0, math.cos(theta_y), 0],\n                                    [0,0,0,1]])\n\n        # Rotation about Z axis\n        theta_z = math.pi / 180 * rotation_z\n        rotate_matrix_z = np.array([[math.cos(theta_z), -math.sin(theta_z), 0, 0],\n                                    [math.sin(theta_z),  math.cos(theta_z), 0, 0],\n                                    [0,                0,                   1, 0],\n                                    [0,0,0,1]])\n        rotate_matrix = rotate_matrix_x.dot(rotate_matrix_y).dot(rotate_matrix_z)[:3,:]\n\n        self.tx.set_parameters(rotate_matrix)\n        if self.lazy or X is None:\n            return self.tx\n        else:\n            return self.tx.apply_to_image(X, reference=self.reference)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntransform an image using an Affine transform with the specified parameters randomly generated from the user - specified rotation range.", "response": "def transform(self, X=None, y=None):\n        \"\"\"\n        Transform an image using an Affine transform with\n        rotation parameters randomly generated from the user-specified\n        range.  Return the transform if X=None.\n\n        Arguments\n        ---------\n        X : ANTsImage\n            Image to transform\n\n        y : ANTsImage (optional)\n            Another image to transform\n\n        Returns\n        -------\n        ANTsImage if y is None, else a tuple of ANTsImage types\n\n        Examples\n        --------\n        >>> import ants\n        >>> img = ants.image_read(ants.get_data('ch2'))\n        >>> tx = ants.contrib.RandomRotate3D(rotation_range=(-10,10))\n        >>> img2 = tx.transform(img)\n        \"\"\"\n        # random draw in rotation range\n        rotation_x = random.gauss(self.rotation_range[0], self.rotation_range[1])\n        rotation_y = random.gauss(self.rotation_range[0], self.rotation_range[1])\n        rotation_z = random.gauss(self.rotation_range[0], self.rotation_range[1])\n        self.params = (rotation_x, rotation_y, rotation_z)\n\n        tx = Rotate3D((rotation_x, rotation_y, rotation_z),\n                    reference=self.reference,\n                    lazy=self.lazy)\n\n        return tx.transform(X,y)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntransforming an image using an Affine transform with the specified zoom parameters randomly generated from the user - specified range.", "response": "def transform(self, X=None, y=None):\n        \"\"\"\n        Transform an image using an Affine transform with\n        zoom parameters randomly generated from the user-specified\n        range.  Return the transform if X=None.\n\n        Arguments\n        ---------\n        X : ANTsImage\n            Image to transform\n\n        y : ANTsImage (optional)\n            Another image to transform\n\n        Returns\n        -------\n        ANTsImage if y is None, else a tuple of ANTsImage types\n\n        Examples\n        --------\n        >>> import ants\n        >>> img = ants.image_read(ants.get_data('ch2'))\n        >>> tx = ants.contrib.RandomZoom3D(zoom_range=(0.8,0.9))\n        >>> img2 = tx.transform(img)\n        \"\"\"\n        # random draw in zoom range\n        zoom_x = np.exp( random.gauss(\n          np.log( self.zoom_range[0] ),\n          np.log( self.zoom_range[1] ) ) )\n        zoom_y = np.exp( random.gauss(\n          np.log( self.zoom_range[0] ),\n          np.log( self.zoom_range[1] ) ) )\n        zoom_z = np.exp( random.gauss(\n          np.log( self.zoom_range[0] ),\n          np.log( self.zoom_range[1] ) ) )\n        self.params = (zoom_x, zoom_y, zoom_z)\n\n        tx = Zoom3D((zoom_x,zoom_y,zoom_z),\n                    reference=self.reference,\n                    lazy=self.lazy)\n\n        return tx.transform(X,y)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntransform an image using an Affine transform with the given translation parameters. Return the transform if X = None.", "response": "def transform(self, X=None, y=None):\n        \"\"\"\n        Transform an image using an Affine transform with the given\n        translation parameters.  Return the transform if X=None.\n\n        Arguments\n        ---------\n        X : ANTsImage\n            Image to transform\n\n        y : ANTsImage (optional)\n            Another image to transform\n\n        Returns\n        -------\n        ANTsImage if y is None, else a tuple of ANTsImage types\n\n        Examples\n        --------\n        >>> import ants\n        >>> img = ants.image_read(ants.get_data('r16'))\n        >>> tx = ants.contrib.Translate2D(translation=(10,0))\n        >>> img2_x = tx.transform(img)\n        >>> tx = ants.contrib.Translate2D(translation=(-10,0)) # other direction\n        >>> img2_x = tx.transform(img)\n        >>> tx = ants.contrib.Translate2D(translation=(0,10))\n        >>> img2_z = tx.transform(img)\n        >>> tx = ants.contrib.Translate2D(translation=(10,10))\n        >>> img2 = tx.transform(img)\n        \"\"\"\n        # convert to radians and unpack\n        translation_x, translation_y = self.translation\n\n        translation_matrix = np.array([[1, 0, translation_x],\n                                       [0, 1, translation_y]])\n        self.tx.set_parameters(translation_matrix)\n        if self.lazy or X is None:\n            return self.tx\n        else:\n            return self.tx.apply_to_image(X, reference=self.reference)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntransform an image using an Affine transform with translation parameters randomly generated from the user - specified translation_range. Returns the transform if X = None.", "response": "def transform(self, X=None, y=None):\n        \"\"\"\n        Transform an image using an Affine transform with\n        translation parameters randomly generated from the user-specified\n        range.   Return the transform if X=None.\n\n        Arguments\n        ---------\n        X : ANTsImage\n            Image to transform\n\n        y : ANTsImage (optional)\n            Another image to transform\n\n        Returns\n        -------\n        ANTsImage if y is None, else a tuple of ANTsImage types\n\n        Examples\n        --------\n        >>> import ants\n        >>> img = ants.image_read(ants.get_data('r16'))\n        >>> tx = ants.contrib.RandomShear2D(translation_range=(-10,10))\n        >>> img2 = tx.transform(img)\n        \"\"\"\n        # random draw in translation range\n        translation_x = random.gauss(self.translation_range[0], self.translation_range[1])\n        translation_y = random.gauss(self.translation_range[0], self.translation_range[1])\n        self.params = (translation_x, translation_y)\n\n        tx = Translate2D((translation_x, translation_y),\n                          reference=self.reference,\n                          lazy=self.lazy)\n\n        return tx.transform(X,y)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef transform(self, X=None, y=None):\n        # random draw in rotation range\n        rotation = random.gauss(self.rotation_range[0], self.rotation_range[1])\n        self.params = rotation\n\n        tx = Rotate2D(rotation,\n                    reference=self.reference,\n                    lazy=self.lazy)\n\n        return tx.transform(X,y)", "response": "Transform an image using an Affine transform with the specified rotation parameters randomly generated from the user - specified rotation_range. Returns the transform if X = None."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef kelly_kapowski(s, g, w, its=50, r=0.025, m=1.5, **kwargs):\n    if isinstance(s, iio.ANTsImage):\n        s = s.clone('unsigned int')\n\n    d = s.dimension\n    outimg = g.clone()\n    kellargs = {'d': d,\n                's': s,\n                'g': g,\n                'w': w,\n                'c': its,\n                'r': r,\n                'm': m,\n                'o': outimg}\n    for k, v in kwargs.items():\n        kellargs[k] = v\n\n    processed_kellargs = utils._int_antsProcessArguments(kellargs)\n\n    libfn = utils.get_lib_fn('KellyKapowski')\n    libfn(processed_kellargs)\n    return outimg", "response": "Compute cortical thickness using the Kelly - Kapowski algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef new_ants_transform(precision='float', dimension=3, transform_type='AffineTransform', parameters=None):\n    libfn = utils.get_lib_fn('newAntsTransform%s%i' % (utils.short_ptype(precision), dimension))\n    itk_tx = libfn(precision, dimension, transform_type)\n    ants_tx = tio.ANTsTransform(precision=precision, dimension=dimension, \n                                transform_type=transform_type, pointer=itk_tx)\n\n    if parameters is not None:\n        ants_tx.set_parameters(parameters)\n\n    return ants_tx", "response": "Create a new ANTsTransform object"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates an ANTsTransform object for an arbitrary set of types.", "response": "def create_ants_transform(transform_type='AffineTransform',\n                          precision='float', \n                          dimension=3,\n                          matrix=None,\n                          offset=None, \n                          center=None, \n                          translation=None, \n                          parameters=None, \n                          fixed_parameters=None, \n                          displacement_field=None,\n                          supported_types=False):\n    \"\"\"\n    Create and initialize an ANTsTransform\n\n    ANTsR function: `createAntsrTransform`\n\n    Arguments\n    ---------\n    transform_type : string   \n        type of transform(s)\n    \n    precision : string\n        numerical precision\n    \n    dimension : integer\n        spatial dimension of transform\n    \n    matrix : ndarray\n        matrix for linear transforms\n    \n    offset : tuple/list\n        offset for linear transforms\n    \n    center : tuple/list\n        center for linear transforms\n    \n    translation : tuple/list\n        translation for linear transforms\n    \n    parameters : ndarray/list\n        array of parameters\n    \n    fixed_parameters : ndarray/list   \n        array of fixed parameters\n    \n    displacement_field : ANTsImage\n        multichannel ANTsImage for non-linear transform\n    \n    supported_types : boolean\n        flag that returns array of possible transforms types\n\n    Returns\n    -------\n    ANTsTransform or list of ANTsTransform types\n\n    Example\n    -------\n    >>> import ants\n    >>> translation = (3,4,5)\n    >>> tx = ants.create_ants_transform( type='Euler3DTransform', translation=translation )\n    \"\"\"\n    def _check_arg(arg, dim=1):\n        if arg is None:\n            if dim == 1:\n                return []\n            elif dim == 2:\n                return [[]]\n        elif isinstance(arg, np.ndarray):\n            return arg.tolist()\n        elif isinstance(arg, (tuple, list)):\n            return list(arg)\n        else:\n            raise ValueError('Incompatible input argument')\n\n    matrix = _check_arg(matrix, dim=2)\n    offset = _check_arg(offset)\n    center = _check_arg(center)\n    translation = _check_arg(translation)\n    parameters = _check_arg(parameters)\n    fixed_parameters = _check_arg(fixed_parameters)\n\n    matrix_offset_types = {'AffineTransform', 'CenteredAffineTransform', \n                         'Euler2DTransform', 'Euler3DTransform', 'Rigid3DTransform',\n                         'Rigid2DTransform', 'QuaternionRigidTransform', \n                         'Similarity2DTransform', 'CenteredSimilarity2DTransform',\n                         'Similarity3DTransform', 'CenteredRigid2DTransform', \n                         'CenteredEuler3DTransform'}\n\n    #user_matrix_types = {'Affine','CenteredAffine', \n    #                     'Euler', 'CenteredEuler',\n    #                     'Rigid', 'CenteredRigid', 'QuaternionRigid',\n    #                     'Similarity', 'CenteredSimilarity'}\n\n    if supported_types:\n      return set(list(matrix_offset_types) + ['DisplacementFieldTransform'])\n\n    # Check for valid dimension\n    if (dimension < 2) or (dimension > 4):\n        raise ValueError('Unsupported dimension: %i' % dimension)\n\n    # Check for valid precision\n    precision_types = ('float', 'double')\n    if precision not in precision_types:\n        raise ValueError('Unsupported Precision %s' % str(precision))\n\n    # Check for supported transform type\n    if (transform_type not in matrix_offset_types) and (transform_type != 'DisplacementFieldTransform'):\n        raise ValueError('Unsupported type %s' % str(transform_type)) \n\n    # Check parameters with type\n    if (transform_type=='Euler3DTransform'):\n        dimension = 3\n    elif (transform_type=='Euler2DTransform'):\n        dimension = 2\n    elif (transform_type=='Rigid3DTransform'):\n        dimension = 3\n    elif (transform_type=='QuaternionRigidTransform'):\n        dimension = 3\n    elif (transform_type=='Rigid2DTransform'):\n        dimension = 2\n    elif (transform_type=='CenteredRigid2DTransform'):\n        dimension = 2\n    elif (transform_type=='CenteredEuler3DTransform'):\n        dimension = 3\n    elif (transform_type=='Similarity3DTransform'):\n        dimension = 3\n    elif (transform_type=='Similarity2DTransform'):\n        dimension = 2\n    elif (transform_type=='CenteredSimilarity2DTransform'):\n        dimension = 2\n\n    # If displacement field\n    if displacement_field is not None:\n        raise ValueError('Displacement field transform not currently supported')\n    #    itk_tx = transform_from_displacement_field(displacement_field)\n    #    return tio.ants_transform(itk_tx)\n\n    # Transforms that derive from itk::MatrixOffsetTransformBase\n    libfn = utils.get_lib_fn('matrixOffset%s%i' % (utils.short_ptype(precision), dimension))\n    itk_tx = libfn(transform_type,\n                    precision,\n                    dimension,\n                    matrix,\n                    offset,\n                    center,\n                    translation,\n                    parameters,\n                    fixed_parameters)\n    return tio.ANTsTransform(precision=precision, dimension=dimension,\n                            transform_type=transform_type, pointer=itk_tx)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a displacement field to ANTsTransform", "response": "def transform_from_displacement_field(field):\n    \"\"\"\n    Convert deformation field (multiChannel image) to ANTsTransform\n\n    ANTsR function: `antsrTransformFromDisplacementField`\n\n    Arguments\n    ---------\n    field : ANTsImage\n        deformation field as multi-channel ANTsImage\n\n    Returns\n    -------\n    ANTsImage\n\n    Example\n    -------\n    >>> import ants\n    >>> fi = ants.image_read(ants.get_ants_data('r16') )\n    >>> mi = ants.image_read(ants.get_ants_data('r64') )\n    >>> fi = ants.resample_image(fi,(60,60),1,0)\n    >>> mi = ants.resample_image(mi,(60,60),1,0) # speed up\n    >>> mytx = ants.registration(fixed=fi, moving=mi, type_of_transform = ('SyN') )\n    >>> compfield = ants.compose_transforms_to_field( fi, mytx['fwd'] )\n    >>> atx = ants.transform_from_displacement_field( compfield )\n    \"\"\"\n    if not isinstance(field, iio.ANTsImage):\n        raise ValueError('field must be ANTsImage type')\n    libfn = utils.get_lib_fn('antsTransformFromDisplacementFieldF%i'%field.dimension)\n    field = field.clone('float')\n    txptr = libfn(field.pointer)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading a transform from file and return ANTsTransform object", "response": "def read_transform(filename, dimension=2, precision='float'):\n    \"\"\"\n    Read a transform from file\n\n    ANTsR function: `readAntsrTransform`\n\n    Arguments\n    ---------\n    filename : string\n        filename of transform\n\n    dimension : integer\n        spatial dimension of transform\n\n    precision : string\n        numerical precision of transform\n    \n    Returns\n    -------\n    ANTsTransform\n\n    Example\n    -------\n    >>> import ants\n    >>> tx = ants.new_ants_transform(dimension=2)\n    >>> tx.set_parameters((0.9,0,0,1.1,10,11))\n    >>> ants.write_transform(tx, '~/desktop/tx.mat')\n    >>> tx2 = ants.read_transform('~/desktop/tx.mat')\n    \"\"\"\n    filename = os.path.expanduser(filename)\n    if not os.path.exists(filename):\n        raise ValueError('filename does not exist!')\n\n    libfn1 = utils.get_lib_fn('getTransformDimensionFromFile')\n    dimension = libfn1(filename)\n\n    libfn2 = utils.get_lib_fn('getTransformNameFromFile')\n    transform_type = libfn2(filename)\n\n    libfn3 = utils.get_lib_fn('readTransform%s%i' % (utils.short_ptype(precision), dimension))\n    itk_tx = libfn3(filename, dimension, precision)\n\n    return tio.ANTsTransform(precision=precision, dimension=dimension, \n                            transform_type=transform_type, pointer=itk_tx)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite ANTsTransform to file ANTsR function", "response": "def write_transform(transform, filename):\n    \"\"\"\n    Write ANTsTransform to file\n\n    ANTsR function: `writeAntsrTransform`\n\n    Arguments\n    ---------\n    transform : ANTsTransform\n        transform to save\n\n    filename : string\n        filename of transform (file extension is \".mat\" for affine transforms)\n    \n    Returns\n    -------\n    N/A\n\n    Example\n    -------\n    >>> import ants\n    >>> tx = ants.new_ants_transform(dimension=2)\n    >>> tx.set_parameters((0.9,0,0,1.1,10,11))\n    >>> ants.write_transform(tx, '~/desktop/tx.mat')\n    >>> tx2 = ants.read_transform('~/desktop/tx.mat')\n    \"\"\"\n    filename = os.path.expanduser(filename)\n    libfn = utils.get_lib_fn('writeTransform%s' % (transform._libsuffix))\n    libfn(transform.pointer, filename)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts an FSL linear transform to an antsrTransform", "response": "def fsl2antstransform(matrix, reference, moving):\n    \"\"\"\n    Convert an FSL linear transform to an antsrTransform\n    \n    ANTsR function: `fsl2antsrtransform`\n\n    Arguments\n    ---------\n    matrix : ndarray/list\n        4x4 matrix of transform parameters\n\n    reference : ANTsImage\n        target image\n\n    moving : ANTsImage\n        moving image\n\n    Returns\n    -------\n    ANTsTransform\n\n    Examples\n    --------\n    >>> import ants\n    >>> import numpy as np\n    >>> fslmat = np.zeros((4,4))\n    >>> np.fill_diagonal(fslmat, 1)\n    >>> img = ants.image_read(ants.get_ants_data('ch2'))\n    >>> tx = ants.fsl2antstransform(fslmat, img, img)\n    \"\"\"\n    if reference.dimension != 3:\n        raise ValueError('reference image must be 3 dimensions')\n\n    if reference.pixeltype != 'float':\n        reference = reference.clone('float')\n    if moving.pixeltype != 'float':\n        moving = moving.clone('float')\n\n    libfn = utils.get_lib_fn('fsl2antstransformF3')\n    tx_ptr = libfn(list(matrix), \n                    reference.pointer,\n                    moving.pointer,\n                    1)\n\n    return tio.ANTsTransform(precision='float', dimension=reference.dimension, \n                             transform_type='AffineTransform', pointer=tx_ptr)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreflecting an image along an axis ANTsR function", "response": "def reflect_image(image, axis=None, tx=None, metric='mattes'):\n    \"\"\"\n    Reflect an image along an axis\n\n    ANTsR function: `reflectImage`\n\n    Arguments\n    ---------\n    image : ANTsImage\n        image to reflect\n    \n    axis : integer (optional)\n        which dimension to reflect across, numbered from 0 to imageDimension-1\n    \n    tx : string (optional)\n        transformation type to estimate after reflection\n    \n    metric : string  \n        similarity metric for image registration. see antsRegistration.\n    \n    Returns\n    -------\n    ANTsImage\n\n    Example\n    -------\n    >>> import ants\n    >>> fi = ants.image_read( ants.get_ants_data('r16'), 'float' )\n    >>> axis = 2\n    >>> asym = ants.reflect_image(fi, axis, 'Affine')['warpedmovout']\n    >>> asym = asym - fi\n    \"\"\"\n    if axis is None:\n        axis = image.dimension - 1\n\n    if (axis > image.dimension) or (axis < 0):\n        axis = image.dimension - 1\n\n    rflct = mktemp(suffix='.mat')\n\n    libfn = utils.get_lib_fn('reflectionMatrix%s'%image._libsuffix)\n    libfn(image.pointer, axis, rflct)\n\n    if tx is not None:\n        rfi = registration(image, image, type_of_transform=tx,\n                            syn_metric=metric, outprefix=mktemp(),\n                            initial_transform=rflct)\n        return rfi\n    else:\n        return apply_transforms(image, image, rflct)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a BIDSSampler that can be used to generate infinite augmented samples.", "response": "def create_sampler(self, inputs, targets, input_reader=None, target_reader=None, \n        input_transform=None, target_transform=None, co_transform=None,\n        input_return_processor=None, target_return_processor=None, co_return_processor=None):\n        \"\"\"\n        Create a BIDSSampler that can be used to generate infinite augmented samples\n        \"\"\"\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef iMath(image, operation, *args):\n    if operation not in _iMathOps:\n        raise ValueError('Operation not recognized')\n\n    imagedim = image.dimension\n    outimage = image.clone()\n    args = [imagedim, outimage, operation, image] + [a for a in args]\n    processed_args = _int_antsProcessArguments(args)\n\n    libfn = utils.get_lib_fn('iMath')\n    libfn(processed_args)\n    return outimage", "response": "This function is used to perform various mathematical operations on the input image and return the result as ANTsImage objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef iMath_propagate_labels_through_mask(image, labels, stopping_value=100, propagation_method=0):\n    return iMath(image, 'PropagateLabelsThroughMask', labels, stopping_value, propagation_method)", "response": "Propagate labels through a mask."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntruncating intensity of an image.", "response": "def iMath_truncate_intensity(image, lower_q, upper_q, n_bins=64):\n    \"\"\"\n    >>> import ants\n    >>> img = ants.image_read(ants.get_ants_data('r16'))\n    >>> ants.iMath_truncate_intensity( img, 0.2, 0.8 )\n    \"\"\"\n    return iMath(image, 'TruncateIntensity', lower_q, upper_q, n_bins )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nslice an image. Example ------- >>> import ants >>> mni = ants.image_read(ants.get_data('mni')) >>> mni2 = ants.slice_image(mni, axis=1, idx=100)", "response": "def slice_image(image, axis=None, idx=None):\n    \"\"\"\n    Slice an image.\n\n    Example\n    -------\n    >>> import ants\n    >>> mni = ants.image_read(ants.get_data('mni'))\n    >>> mni2 = ants.slice_image(mni, axis=1, idx=100)\n    \"\"\"\n    if image.dimension < 3:\n        raise ValueError('image must have at least 3 dimensions')\n\n    inpixeltype = image.pixeltype\n    ndim = image.dimension\n    if image.pixeltype != 'float':\n        image = image.clone('float')\n\n    libfn = utils.get_lib_fn('sliceImageF%i' % ndim)\n    itkimage = libfn(image.pointer, axis, idx)\n\n    return iio.ANTsImage(pixeltype='float', dimension=ndim-1, \n                         components=image.components, pointer=itkimage).clone(inpixeltype)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npadding an image to have the given shape or to be isotropic.", "response": "def pad_image(image, shape=None, pad_width=None, value=0.0, return_padvals=False):\n    \"\"\"\n    Pad an image to have the given shape or to be isotropic.\n\n    Arguments\n    ---------\n    image : ANTsImage\n        image to pad\n\n    shape : tuple\n        - if shape is given, the image will be padded in each dimension\n          until it has this shape\n        - if shape is not given, the image will be padded along each\n          dimension to match the largest existing dimension so that it\n          has isotropic dimension\n\n    pad_width : list of \n\n    pad_value : scalar\n        value with which image will be padded\n\n    Example\n    -------\n    >>> import ants\n    >>> img = ants.image_read(ants.get_data('r16'))\n    >>> img2 = ants.pad_image(img, shape=(300,300))\n    >>> mni = ants.image_read(ants.get_data('mni'))\n    >>> mni2 = ants.pad_image(mni)\n    >>> mni3 = ants.pad_image(mni, pad_width=[(0,4),(0,4),(0,4)])\n    >>> mni4 = ants.pad_image(mni, pad_width=(4,4,4))\n    \"\"\"\n    inpixeltype = image.pixeltype\n    ndim = image.dimension\n    if image.pixeltype != 'float':\n        image = image.clone('float')\n\n    if pad_width is None:\n        if shape is None:\n            shape = [max(image.shape)] * image.dimension\n        lower_pad_vals = [math.floor(max(ns-os,0)/2) for os,ns in zip(image.shape, shape)]\n        upper_pad_vals = [math.ceil(max(ns-os,0)/2) for os,ns in zip(image.shape, shape)]\n    else:\n        if shape is not None:\n            raise ValueError('Cannot give both `shape` and `pad_width`. Pick one!')\n        if len(pad_width) != image.dimension:\n            raise ValueError('Must give pad width for each image dimension')\n\n        lower_pad_vals = []\n        upper_pad_vals = []\n        for p in pad_width:\n            if isinstance(p, (list, tuple)):\n                lower_pad_vals.append(p[0])\n                upper_pad_vals.append(p[1])\n            else:\n                lower_pad_vals.append(math.floor(p/2))\n                upper_pad_vals.append(math.ceil(p/2))\n\n    libfn = utils.get_lib_fn('padImageF%i' % ndim)\n    itkimage = libfn(image.pointer, lower_pad_vals, upper_pad_vals, value)\n\n    new_image = iio.ANTsImage(pixeltype='float', dimension=ndim, \n                         components=image.components, pointer=itkimage).clone(inpixeltype)\n    if return_padvals:\n        return new_image, lower_pad_vals, upper_pad_vals\n    else:\n        return new_image"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrender an image as a base surface and an optional collection of other images.", "response": "def render_surface_function(surfimg, funcimg=None, alphasurf=0.2, alphafunc=1.0, \n                            isosurf=0.5, isofunc=0.5, smoothsurf=None, smoothfunc=None,\n                            cmapsurf='grey', cmapfunc='red', filename=None, notebook=False,\n                            auto_open=False):\n    \"\"\"\n    Render an image as a base surface and an optional collection of other image.\n\n    ANTsR function: `renderSurfaceFunction`\n        NOTE: The ANTsPy version of this function is actually completely different\n        than the ANTsR version, although they should produce similar results.\n\n    Arguments\n    ---------\n    surfimg : ANTsImage\n        Input image to use as rendering substrate.\n    \n    funcimg : ANTsImage\n        Input list of images to use as functional overlays.\n    \n    alphasurf : scalar\n        alpha for the surface contour\n    \n    alphafunc : scalar\n        alpha value for functional blobs\n\n    isosurf : scalar\n        intensity level that defines lower threshold for surface image\n    \n    isofunc : scalar\n        intensity level that defines lower threshold for functional image\n    \n    smoothsurf  : scalar (optional)\n        smoothing for the surface image\n    \n    smoothfunc : scalar (optional)\n        smoothing for the functional image\n    \n    cmapsurf : string\n        color map for surface image\n    \n    cmapfunc : string   \n        color map for functional image\n    \n    filename : string   \n        where to save rendering. if None, will plot interactively\n    \n    notebook : boolean\n        whether you're in a jupyter notebook.\n    \n    Returns\n    -------\n    N/A\n\n    Example\n    -------\n    >>> import ants\n    >>> mni = ants.image_read(ants.get_ants_data('mni'))\n    >>> mnia = ants.image_read(ants.get_ants_data('mnia'))\n    >>> ants.render_surface_function(mni, mnia, alphasurf=0.1, filename='/users/ncullen/desktop/surffnc.png')\n    \"\"\"\n    cmap_dict = {\n        'grey': 'Greys',\n        'gray': 'Greys',\n        'red': 'Reds',\n        'green': 'Greens',\n        'jet': 'Jet'\n    }\n    if surfimg.dimension != 3:\n        raise ValueError('surfimg must be 3D')\n\n    #if (filename is None) and (not notebook_render):\n    #    raise Exception('Must either 1) give filename, 2) set `html_render`=True or 3) set `notebook_render`=True')\n    \n    if notebook:\n        init_notebook_mode(connected=True)\n\n    fig_list = []\n    fig_data_list = []\n\n    surfimg = resample_image(surfimg, (3,3,3))\n    surfimg_arr = surfimg.numpy()\n    surfverts, surffaces,_,_ = skimage.measure.marching_cubes_lewiner(surfimg_arr, isosurf, spacing=(1,1,1))\n\n    surffig = FF.create_trisurf(x=surfverts[:,0],\n                                y=surfverts[:,1],\n                                z=surfverts[:,2],\n                                colormap=cmap_dict.get(cmapsurf, cmapsurf),\n                                plot_edges=False,\n                                simplices=surffaces)\n\n    surffig['data'][0].update(opacity=alphasurf)\n\n    fig_list.append(surffig)\n    fig_data_list.append(surffig.data[0])\n\n    if funcimg is not None:\n        if not isinstance(funcimg, (tuple,list)):\n            funcimg = [funcimg]\n        if not isinstance(alphafunc, (tuple,list)):\n            alphafunc = [alphafunc]*len(funcimg)\n        if not isinstance(isofunc, (tuple,list)):\n            isofunc = [isofunc]*len(funcimg)\n        if not isinstance(cmapfunc, (tuple,list)):\n            cmapfunc = [cmapfunc]*len(funcimg)\n            #cmapfunc = [cmap_dict.get(c,c) for c in cmapfunc]\n        \n        for i in range(len(cmapfunc)):\n            cmapfunc[i] = 'rgb%s' % str(wc.name_to_rgb(cmapfunc[i]))\n            cmapfunc[i] = [cmapfunc[i]]*2\n\n        for func_idx, fimg in enumerate(funcimg):\n            if fimg.dimension != 3:\n                raise ValueError('all funcimgs must be 3D')\n\n            fimg = resample_image(fimg, (3,3,3))\n            funcimg_arr = fimg.numpy()\n            funcverts, funcfaces,_,_ = skimage.measure.marching_cubes_lewiner(funcimg_arr, \n                                            isofunc[func_idx], spacing=(1,1,1))\n            funcfig = FF.create_trisurf(x=funcverts[:,0],\n                                        y=funcverts[:,1],\n                                        z=funcverts[:,2],\n                                        plot_edges=False,\n                                        simplices=funcfaces,\n                                        colormap=cmapfunc[func_idx])\n            funcfig['data'][0].update(opacity=alphafunc[func_idx])\n            fig_list.append(funcfig)\n            fig_data_list.append(funcfig.data[0])\n\n    if filename is not None:\n        save_file = 'png'\n        image_filename = filename\n        filename = image_filename.split('.')[0] + '.html'\n    else:\n        image_filename = 'ants_plot'\n        filename = 'ants_plot.html'\n        save_file = None\n\n    try:\n        plot(fig_data_list, image=save_file, filename=filename, image_filename=image_filename, auto_open=auto_open)\n    except PermissionError:\n        print('PermissionError caught - are you running jupyter console? Try launching it with sudo privledges (e.g. `sudo jupyter-console`)')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef image_similarity(fixed_image, moving_image, metric_type='MeanSquares', \n                    fixed_mask=None, moving_mask=None, \n                    sampling_strategy='regular', sampling_percentage=1.):\n    \"\"\"\n    Measure similarity between two images\n    \n    ANTsR function: `imageSimilarity`\n\n    Arguments\n    ---------\n    fixed : ANTsImage\n        the fixed image\n    \n    moving : ANTsImage\n        the moving image\n    \n    metric_type : string\n        image metric to calculate\n            MeanSquares\n            Correlation\n            ANTSNeighborhoodCorrelation\n            MattesMutualInformation\n            JointHistogramMutualInformation\n            Demons\n    \n    fixed_mask : ANTsImage (optional)\n        mask for the fixed image\n    \n    moving_mask : ANTsImage (optional)\n        mask for the moving image\n    \n    sampling_strategy : string (optional)\n        sampling strategy, default is full sampling\n            None (Full sampling)\n            random\n            regular\n    \n    sampling_percentage : scalar \n        percentage of data to sample when calculating metric\n        Must be between 0 and 1\n\n    Returns\n    -------\n    scalar\n\n    Example\n    -------\n    >>> import ants\n    >>> x = ants.image_read(ants.get_ants_data('r16'))\n    >>> y = ants.image_read(ants.get_ants_data('r30'))\n    >>> metric = ants.image_similarity(x,y,metric_type='MeanSquares')\n    \"\"\"\n    metric = mio2.create_ants_metric(fixed_image, moving_image, metric_type, fixed_mask,\n                        moving_mask, sampling_strategy, sampling_percentage)\n    return metric.get_value()", "response": "Function to calculate the image similarity between two ANTsImages"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _vol_fold_single(image, outfile, magnification, dilation, inflation, alpha, overlay, overlay_mask, \n    overlay_cmap, overlay_scale, overlay_alpha, rotation,\n    cut_idx, cut_side, grayscale, bg_grayscale, verbose):\n    \"\"\"\n    Helper function for making a single surface fold image.\n    \"\"\"\n    if rotation is None:\n        rotation = (270,0,270)\n    if not isinstance(rotation, (str, tuple)):\n        raise ValueError('rotation must be a tuple or string')\n    if isinstance(rotation, tuple):\n        if isinstance(rotation[0], str):\n            rotation_dx = rotation[1]\n            rotation = rotation[0]\n            if 'inner' in rotation:\n                if rotation.count('_') == 2:\n                    rsplit = rotation.split('_')\n                    rotation = '_'.join(rsplit[:-1])\n                    cut_idx = int(rsplit[-1])\n                else:\n                    cut_idx = 0\n                centroid = int(-1*image.origin[0] + image.get_center_of_mass()[0])\n                cut_idx = centroid + cut_idx\n                cut_side = rotation.replace('inner_','')\n            else:\n                cut_idx = int(image.get_centroids()[0][0])\n            rotation_string = rotation\n            rotation = _view_map[rotation.lower()]\n            rotation = (r+rd for r,rd in zip(rotation,rotation_dx))\n\n    elif isinstance(rotation, str):\n        if 'inner' in rotation:\n            if rotation.count('_') == 2:\n                rsplit = rotation.split('_')\n                rotation = '_'.join(rsplit[:-1])\n                cut_idx = int(rsplit[-1])\n            else:\n                cut_idx = 0\n            centroid = int(-1*image.origin[0] + image.get_center_of_mass()[0])\n            if verbose:\n                print('Found centroid at %i index' % centroid)\n            cut_idx = centroid + cut_idx\n            cut_side = rotation.replace('inner_','')\n            if verbose:\n                print('Cutting image on %s side at %i index' % (cut_side,cut_idx))\n        else:\n            cut_idx = int(image.get_centroids()[0][0])\n        rotation_string = rotation\n        rotation = _view_map[rotation.lower()]\n\n    # handle filename argument\n    outfile = os.path.expanduser(outfile)\n\n    # handle overlay argument\n    if overlay is not None:\n        if not iio.image_physical_space_consistency(image, overlay):\n            overlay = overlay.resample_image_to_target(image)\n            if verbose:\n                print('Resampled overlay to base image space')\n\n        if overlay_mask is None:\n            overlay_mask = image.iMath_MD(3)\n\n    ## PROCESSING ##\n    if dilation > 0:\n        image = image.iMath_MD(dilation)\n        \n    thal = image\n    wm = image\n    #wm = wm + thal\n    wm = wm.iMath_fill_holes().iMath_get_largest_component().iMath_MD()\n    wms = wm.smooth_image(0.5)\n    wmt_label = wms.iMath_propagate_labels_through_mask(thal, 500, 0 )\n    image = wmt_label.threshold_image(1,1)\n    if cut_idx is not None:\n        if cut_idx > image.shape[0]:\n            raise ValueError('cut_idx (%i) must be less than image X dimension (%i)' % (cut_idx, image.shape[0]))\n        cut_mask = image*0 + 1.\n        if 'inner' in rotation_string:\n            if cut_side == 'left':\n                cut_mask[cut_idx:,:,:] = 0\n            elif cut_side == 'right':\n                cut_mask[:cut_idx,:,:] = 0\n            else:\n                raise ValueError('cut_side argument must be `left` or `right`')\n        else:\n            if 'left' in rotation:\n                cut_mask[cut_idx:,:,:] = 0\n            elif 'right' in rotation:\n                cut_mask[:cut_idx,:,:] = 0\n        image = image * cut_mask\n    ##\n\n    # surface arg\n    # save base image to temp file\n    image_tmp_file = mktemp(suffix='.nii.gz')\n    image.to_file(image_tmp_file)\n    # build image color\n    grayscale = int(grayscale*255)\n    #image_color = '%sx%.1f' % ('x'.join([str(grayscale)]*3), alpha)\n    cmd = '-i [%s,0.0x1.0] ' % (image_tmp_file)\n\n    # add mask\n    #mask = image.clone() > 0.01\n    #cm\n\n    # display arg\n    bg_grayscale = int(bg_grayscale*255)\n    cmd += '-d %s[%.2f,%s,%s]' % (outfile,\n                                  magnification,\n                                  'x'.join([str(s) for s in rotation]),\n                                  'x'.join([str(bg_grayscale)]*3))\n\n    # overlay arg\n    if overlay is not None:\n        #-f [rgbImageFileName,maskImageFileName,<alpha=1>]\n        if overlay_scale == True:\n            min_overlay, max_overlay = overlay.quantile((0.05,0.95))\n            overlay[overlay<min_overlay] = min_overlay\n            overlay[overlay>max_overlay] = max_overlay\n        elif isinstance(overlay_scale, tuple):\n            min_overlay, max_overlay = overlay.quantile((overlay_scale[0], overlay_scale[1]))\n            overlay[overlay<min_overlay] = min_overlay\n            overlay[overlay>max_overlay] = max_overlay\n\n        # make tempfile for overlay\n        overlay_tmp_file = mktemp(suffix='.nii.gz')\n        # convert overlay image to RGB\n        overlay.scalar_to_rgb(mask=overlay_mask, cmap=overlay_cmap,\n                              filename=overlay_tmp_file)\n        # make tempfile for overlay mask\n        overlay_mask_tmp_file = mktemp(suffix='.nii.gz')\n        overlay_mask.to_file(overlay_mask_tmp_file)\n\n        cmd += ' -f [%s,%s]' % (overlay_tmp_file, overlay_mask_tmp_file)\n\n    if verbose:\n        print(cmd)\n        time.sleep(1)\n\n    cmd = cmd.split(' ')\n    libfn = utils.get_lib_fn('antsVol')\n    retval = libfn(cmd)\n    if retval != 0:\n        print('ERROR: Non-Zero Return Value!')\n\n    # cleanup temp file\n    os.remove(image_tmp_file)\n    if overlay is not None:\n        os.remove(overlay_tmp_file)\n        os.remove(overlay_mask_tmp_file)", "response": "This function is used to make a single surface fold image."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convert_scalar_image_to_rgb(dimension, img, outimg, mask, colormap='red', custom_colormap_file=None, \n                                min_input=None, max_input=None, min_rgb_output=None, max_rgb_output=None,\n                                vtk_lookup_table=None):\n    \"\"\"\n    Usage: ConvertScalarImageToRGB imageDimension inputImage outputImage mask colormap [customColormapFile] [minimumInput] [maximumInput] [minimumRGBOutput=0] [maximumRGBOutput=255] <vtkLookupTable>\n    Possible colormaps: grey, red, green, blue, copper, jet, hsv, spring, summer, autumn, winter, hot, cool, overunder, custom\n    \"\"\"\n    if custom_colormap_file is None:\n        custom_colormap_file = 'none'\n\n    args = [dimension, img, outimg, mask, colormap, custom_colormap_file,\n            min_input, max_input, min_rgb_output, max_rgb_output, vtk_lookup_table]\n    processed_args = utils._int_antsProcessArguments(args)\n    libfn = utils.get_lib_fn('ConvertScalarImageToRGB')\n    libfn(processed_args)", "response": "Convert a scalar image to RGB."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrenders an ANTsImage as a volume", "response": "def vol(volume, overlays=None,\n        quantlimits=(0.1,0.9),\n        colormap='jet',\n        rotation_params=(90,0,270),\n        overlay_limits=None,\n        magnification_factor=1.0,\n        intensity_truncation=(0.0,1.0),\n        filename=None,\n        verbose=False):\n    \"\"\"\n    Render an ANTsImage as a volume with optional ANTsImage functional overlay.\n    This function is beautiful, and runs very fast. It requires VTK.\n    \n    ANTsR function: `antsrVol`\n        NOTE: the ANTsPy version of this function does NOT make a function call\n        to ANTs, unlike the ANTsR version, so you don't have to worry about paths.\n\n    Arguments\n    ---------\n    volume : ANTsImage\n        base volume to render\n    \n    overlay : list of ANTsImages\n        functional overlay to render on the volume image. \n        These images should be in the same space\n\n    colormap : string\n        possible values:\n            grey, red, green, blue, copper, jet, \n            hsv, spring, summer, autumn, winter, \n            hot, cool, overunder, custom\n\n    rotation_params: tuple or collection of tuples or np.ndarray w/ shape (N,3)\n        rotation parameters to render. The final image will be a stitch of each image\n        from the given rotation params.\n        e.g. if rotation_params = [(90,90,90),(180,180,180)], then the final\n             stiched image will have 2 brain renderings at those angles\n\n    overlay_limts\n\n    magnification_factor : float\n        how much to zoom in on the image before rendering. If the stitched images\n        are too far apart, try increasing this value. If the brain volume gets\n        cut off in the image, try decreasing this value\n\n    intensity_truncation : 2-tuple of float\n        percentile to truncate intensity of overlay\n\n    filename : string\n        final filename to which the final rendered volume stitch image will be saved\n        this will always be a .png file\n\n    verbose : boolean\n        whether to print updates during rendering\n    \n    Returns\n    -------\n    - a numpy array representing the final stitched image.\n    \n    Effects\n    -------\n    - saves a few png files to disk\n\n    Example\n    -------\n    >>> import ants\n    >>> ch2i = ants.image_read( ants.get_ants_data(\"mni\") )\n    >>> ch2seg = ants.threshold_image( ch2i, \"Otsu\", 3 )\n    >>> wm   = ants.threshold_image( ch2seg, 2, 2 )\n    >>> kimg = ants.weingarten_image_curvature( ch2i, 1.5  ).smooth_image( 1 )\n    >>> rp = [(90,180,90), (90,180,270), (90,180,180)]\n    >>> result = ants.vol( wm, [kimg], quantlimits=(0.01,0.99), filename='/users/ncullen/desktop/voltest.png')\n    \"\"\"\n    if (overlays is not None) and not isinstance(overlays, (list,iio.ANTsImage)):\n        raise ValueError('overlay must be ANTsImage..')\n    \n\n    if not isinstance(colormap, list):\n        colormap = [colormap]\n\n    xfn = mktemp(suffix='.nii.gz')\n    xmod = volume.clone()\n    if (intensity_truncation[0] > 0) or (intensity_truncation[1] < 1):\n        xmod = utils.iMath(volume, 'TruncateIntensity',\n                           intensity_truncation[0], intensity_truncation[1])\n    core.image_write(xmod, xfn)\n    \n    if filename is None:\n        filename = mktemp()\n    else:\n        filename = os.path.expanduser(filename)\n        if filename.endswith('.png'):\n            filename = filename.replace('.png','')\n\n    if not isinstance(rotation_params, np.ndarray):\n        if isinstance(rotation_params, (tuple, list)):\n            rotation_params = np.hstack(rotation_params)\n        rotation_params = np.array(rotation_params)\n    rotation_params = np.array(rotation_params).reshape(-1,3)\n\n    pngs = []\n    for myrot in range(rotation_params.shape[0]):\n        volcmd = ['-i', xfn]\n        if overlays is not None:\n            if not isinstance(overlays, (tuple, list)):\n                overlays = [overlays]\n            ct = 0\n            if len(colormap) != len(overlays):\n                colormap = [colormap] * len(overlays)\n            for overlay in overlays:\n                ct = ct + 1\n                wms = utils.smooth_image(overlay, 1.0)\n                myquants = np.percentile(overlay[np.abs(overlay.numpy())>0], [q*100 for q in quantlimits])\n                if overlay_limits is not None or (isinstance(overlay_limits, list) and (np.sum([o is not None for o in overlay_limits])>0)):\n                    myquants = overlay_limits\n                    overlay[overlay < myquants[0]] = 0\n                    overlay[overlay > myquants[1]] = myquants[1]\n                    if verbose: \n                        print(myquants)\n\n                kblob = utils.threshold_image(wms, myquants[0], 1e15)\n                kblobfn = mktemp(suffix='.nii.gz')\n                core.image_write(kblob, kblobfn)\n                overlayfn = mktemp(suffix='.nii.gz')\n                core.image_write(overlay, overlayfn)\n\n                csvlutfn = mktemp(suffix='.csv')\n                overlayrgbfn = mktemp(suffix='.nii.gz')\n\n                convert_scalar_image_to_rgb(dimension=3, img=overlayfn, outimg=overlayrgbfn, mask=kblobfn, colormap=colormap[ct-1],\n                                    custom_colormap_file=None, min_input=myquants[0], max_input=myquants[1],\n                                    min_rgb_output=0, max_rgb_output=255, vtk_lookup_table=csvlutfn)\n\n                volcmd = volcmd + ['-f', ' [%s,%s]' % (overlayrgbfn, kblobfn)]\n        \n        if filename is None:\n            volcmd = volcmd + [' -d [%s,%s]' % (magnification_factor, 'x'.join([str(r) for r in rotation_params[myrot,:]]))]            \n        else:\n            pngext = myrot\n            if myrot < 10: pngext = '0%s' % pngext\n            if myrot < 100: pngext = '0%s' % pngext\n            pngfnloc = '%s%s.png' % (filename, pngext)\n            try:\n                os.remove(pngfnloc)\n            except:\n                pass\n            rparamstring = 'x'.join([str(r) for r in rotation_params[myrot,:]])\n            volcmd = volcmd + ['-d', '%s[%s,%s,255x255x255]' % (pngfnloc, magnification_factor, rparamstring)]\n\n        ## C++ LIBRARY FUNCTION CALL ##\n        libfn = utils.get_lib_fn('antsVol')\n        retval = libfn(volcmd)\n\n        if retval != 0:\n            raise Exception('antsVol c++ function call failed for unknown reason')\n\n        #if rotation_params.shape[0] > 1:\n        pngs.append(pngfnloc)\n\n\n    #if rotation_params.shape[0] > 1:\n    mypngimg = scipy.misc.imread(pngs[0])\n    img_shape = mypngimg.shape\n    array_shape = (mypngimg.shape[0], mypngimg.shape[1]*len(pngs), mypngimg.shape[-1])\n    mypngarray = np.zeros(array_shape).astype('uint8')\n    for i in range(len(pngs)):\n        mypngimg = scipy.misc.imread(pngs[i])\n        mypngarray[:,(i*img_shape[1]):((i+1)*img_shape[1]),:] = mypngimg\n\n    scipy.misc.imsave('%s.png' % filename, mypngarray)\n\n    return mypngarray"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\napply a transform list to map an image from one domain to another. In image registration, one computes mappings between (usually) pairs of images. These transforms are often a sequence of increasingly complex maps, e.g. from translation, to rigid, to affine to deformation. The list of such transforms is passed to this function to interpolate one image domain into the next image domain, as below. The order matters strongly and the user is advised to familiarize with the standards established in examples. ANTsR function: `antsApplyTransforms` Arguments --------- fixed : ANTsImage fixed image defining domain into which the moving image is transformed. moving : AntsImage moving image to be mapped to fixed space. transformlist : list of strings list of transforms generated by ants.registration where each transform is a filename. interpolator : string Choice of interpolator. Supports partial matching. linear nearestNeighbor multiLabel for label images but genericlabel is preferred gaussian bSpline cosineWindowedSinc welchWindowedSinc hammingWindowedSinc lanczosWindowedSinc genericLabel use this for label images imagetype : integer choose 0/1/2/3 mapping to scalar/vector/tensor/time-series whichtoinvert : list of booleans (optional) Must be same length as transformlist. whichtoinvert[i] is True if transformlist[i] is a matrix, and the matrix should be inverted. If transformlist[i] is a warp field, whichtoinvert[i] must be False. If the transform list is a matrix followed by a warp field, whichtoinvert defaults to (True,False). Otherwise it defaults to [False]*len(transformlist)). compose : string (optional) if it is a string pointing to a valid file location, this will force the function to return a composite transformation filename. verbose : boolean print command and run verbose application of transform. kwargs : keyword arguments extra parameters Returns ------- ANTsImage or string (transformation filename) Example ------- >>> import ants >>> fixed = ants.image_read( ants.get_ants_data('r16') ) >>> moving = ants.image_read( ants.get_ants_data('r64') ) >>> fixed = ants.resample_image(fixed, (64,64), 1, 0) >>> moving = ants.resample_image(moving, (64,64), 1, 0) >>> mytx = ants.registration(fixed=fixed , moving=moving , type_of_transform = 'SyN' ) >>> mywarpedimage = ants.apply_transforms( fixed=fixed, moving=moving, transformlist=mytx['fwdtransforms'] )", "response": "def apply_transforms(fixed, moving, transformlist,\n                     interpolator='linear', imagetype=0,\n                     whichtoinvert=None, compose=None, verbose=False,\n                     **kwargs):\n    \"\"\"\n    Apply a transform list to map an image from one domain to another.\n    In image registration, one computes mappings between (usually) pairs\n    of images. These transforms are often a sequence of increasingly\n    complex maps, e.g. from translation, to rigid, to affine to deformation.\n    The list of such transforms is passed to this function to interpolate one\n    image domain into the next image domain, as below. The order matters\n    strongly and the user is advised to familiarize with the standards\n    established in examples.\n\n    ANTsR function: `antsApplyTransforms`\n\n    Arguments\n    ---------\n    fixed : ANTsImage\n        fixed image defining domain into which the moving image is transformed.\n\n    moving : AntsImage\n        moving image to be mapped to fixed space.\n\n    transformlist : list of strings\n        list of transforms generated by ants.registration where each transform is a filename.\n\n    interpolator : string\n        Choice of interpolator. Supports partial matching.\n            linear\n            nearestNeighbor\n            multiLabel for label images but genericlabel is preferred\n            gaussian\n            bSpline\n            cosineWindowedSinc\n            welchWindowedSinc\n            hammingWindowedSinc\n            lanczosWindowedSinc\n            genericLabel use this for label images\n\n    imagetype : integer\n        choose 0/1/2/3 mapping to scalar/vector/tensor/time-series\n\n    whichtoinvert : list of booleans (optional)\n        Must be same length as transformlist.\n        whichtoinvert[i] is True if transformlist[i] is a matrix,\n        and the matrix should be inverted. If transformlist[i] is a\n        warp field, whichtoinvert[i] must be False.\n        If the transform list is a matrix followed by a warp field,\n        whichtoinvert defaults to (True,False). Otherwise it defaults\n        to [False]*len(transformlist)).\n\n    compose : string (optional)\n        if it is a string pointing to a valid file location,\n        this will force the function to return a composite transformation filename.\n\n    verbose : boolean\n        print command and run verbose application of transform.\n\n    kwargs : keyword arguments\n        extra parameters\n\n    Returns\n    -------\n    ANTsImage or string (transformation filename)\n\n    Example\n    -------\n    >>> import ants\n    >>> fixed = ants.image_read( ants.get_ants_data('r16') )\n    >>> moving = ants.image_read( ants.get_ants_data('r64') )\n    >>> fixed = ants.resample_image(fixed, (64,64), 1, 0)\n    >>> moving = ants.resample_image(moving, (64,64), 1, 0)\n    >>> mytx = ants.registration(fixed=fixed , moving=moving ,\n                                 type_of_transform = 'SyN' )\n    >>> mywarpedimage = ants.apply_transforms( fixed=fixed, moving=moving,\n                                               transformlist=mytx['fwdtransforms'] )\n    \"\"\"\n\n    if not isinstance(transformlist, (tuple, list)) and (transformlist is not None):\n        transformlist = [transformlist]\n\n    accepted_interpolators = {\"linear\", \"nearestNeighbor\", \"multiLabel\", \"gaussian\",\n                        \"bSpline\", \"cosineWindowedSinc\", \"welchWindowedSinc\",\n                        \"hammingWindowedSinc\", \"lanczosWindowedSinc\", \"genericLabel\"}\n\n    if interpolator not in accepted_interpolators:\n        raise ValueError('interpolator not supported - see %s' % accepted_interpolators)\n\n    args = [fixed, moving, transformlist, interpolator]\n\n    if not isinstance(fixed, str):\n        if isinstance(fixed, iio.ANTsImage) and isinstance(moving, iio.ANTsImage):\n            for tl_path in transformlist:\n                if not os.path.exists(tl_path):\n                    raise Exception('Transform %s does not exist' % tl_path)\n\n            inpixeltype = fixed.pixeltype\n            fixed = fixed.clone('float')\n            moving = moving.clone('float')\n            warpedmovout = moving.clone()\n            f = fixed\n            m = moving\n            if (moving.dimension == 4) and (fixed.dimension == 3) and (imagetype == 0):\n                raise Exception('Set imagetype 3 to transform time series images.')\n\n            wmo = warpedmovout\n            mytx = []\n            if whichtoinvert is None or (isinstance(whichtoinvert, (tuple,list)) and (sum([w is not None for w in whichtoinvert])==0)):\n                if (len(transformlist) == 2) and ('.mat' in transformlist[0]) and ('.mat' not in transformlist[1]):\n                    whichtoinvert = (True, False)\n                else:\n                    whichtoinvert = tuple([False]*len(transformlist))\n\n            if len(whichtoinvert) != len(transformlist):\n                raise ValueError('Transform list and inversion list must be the same length')\n\n            for i in range(len(transformlist)):\n                ismat = False\n                if '.mat' in transformlist[i]:\n                    ismat = True\n                if whichtoinvert[i] and (not ismat):\n                    raise ValueError('Cannot invert transform %i (%s) because it is not a matrix' % (i, transformlist[i]))\n                if whichtoinvert[i]:\n                    mytx = mytx + ['-t', '[%s,1]' % (transformlist[i])]\n                else:\n                    mytx = mytx + ['-t', transformlist[i]]\n\n            if compose is None:\n                args = ['-d', fixed.dimension,\n                        '-i', m,\n                        '-o', wmo,\n                        '-r', f,\n                        '-n', interpolator]\n                args = args + mytx\n            tfn = '%scomptx.nii.gz' % compose if compose is not None else 'NA'\n            if compose is not None:\n                mycompo = '[%s,1]' % tfn\n                args = ['-d', fixed.dimension,\n                        '-i', m,\n                        '-o', mycompo,\n                        '-r', f,\n                        '-n', interpolator]\n                args = args + mytx\n\n            myargs = utils._int_antsProcessArguments(args)\n\n            # NO CLUE WHAT THIS DOES OR WHY IT'S NEEDED\n            for jj in range(len(myargs)):\n                if myargs[jj] is not None:\n                    if myargs[jj] == '-':\n                        myargs2 = [None]*(len(myargs)-1)\n                        myargs2[:(jj-1)] = myargs[:(jj-1)]\n                        myargs2[jj:(len(myargs)-1)] = myargs[(jj+1):(len(myargs))]\n                        myargs = myargs2\n\n            myverb = int(verbose)\n            if verbose:\n                print(myargs)\n\n            processed_args = myargs + ['-z', str(1), '-v', str(myverb), '--float', str(1), '-e', str(imagetype)]\n            libfn = utils.get_lib_fn('antsApplyTransforms')\n            libfn(processed_args)\n\n            if compose is None:\n                return warpedmovout.clone(inpixeltype)\n            else:\n                if os.path.exists(tfn):\n                    return tfn\n                else:\n                    return None\n\n        else:\n            return 1\n    else:\n        args = args + ['-z', 1, '--float', 1, '-e', imagetype]\n        processed_args = utils._int_antsProcessArguments(args)\n        libfn = utils.get_lib_fn('antsApplyTransforms')\n        libfn(processed_args)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef apply_transforms_to_points( dim, points, transformlist,\n                     whichtoinvert=None, verbose=False ):\n    \"\"\"\n     Apply a transform list to map a pointset from one domain to\n     another. In registration, one computes mappings between pairs of\n     domains. These transforms are often a sequence of increasingly\n     complex maps, e.g. from translation, to rigid, to affine to\n     deformation.  The list of such transforms is passed to this\n     function to interpolate one image domain into the next image\n     domain, as below.  The order matters strongly and the user is\n     advised to familiarize with the standards established in examples.\n     Importantly, point mapping goes the opposite direction of image\n     mapping, for both reasons of convention and engineering.\n\n    ANTsR function: `antsApplyTransformsToPoints`\n\n    Arguments\n    ---------\n    dim: integer\n         dimensionality of the transformation.\n\n    points: data frame\n          moving point set with n-points in rows of at least dim\n          columns - we maintain extra information in additional\n          columns. this should be a data frame with columns names x, y, z, t.\n\n    transformlist : list of strings\n        list of transforms generated by ants.registration where each transform is a filename.\n\n    whichtoinvert : list of booleans (optional)\n        Must be same length as transformlist.\n        whichtoinvert[i] is True if transformlist[i] is a matrix,\n        and the matrix should be inverted. If transformlist[i] is a\n        warp field, whichtoinvert[i] must be False.\n        If the transform list is a matrix followed by a warp field,\n        whichtoinvert defaults to (True,False). Otherwise it defaults\n        to [False]*len(transformlist)).\n\n    verbose : boolean\n\n    Returns\n    -------\n    data frame of transformed points\n\n    Example\n    -------\n    >>> import ants\n    >>> fixed = ants.image_read( ants.get_ants_data('r16') )\n    >>> moving = ants.image_read( ants.get_ants_data('r27') )\n    >>> reg = ants.registration( fixed, moving, 'Affine' )\n    >>> d = {'x': [128, 127], 'y': [101, 111]}\n    >>> pts = pd.DataFrame(data=d)\n    >>> ptsw = ants.apply_transforms_to_points( 2, pts, reg['fwdtransforms'])\n    \"\"\"\n\n    if not isinstance(transformlist, (tuple, list)) and (transformlist is not None):\n        transformlist = [transformlist]\n\n    args = [dim, points, transformlist, whichtoinvert]\n\n    for tl_path in transformlist:\n        if not os.path.exists(tl_path):\n            raise Exception('Transform %s does not exist' % tl_path)\n\n    mytx = []\n\n    if whichtoinvert is None or (isinstance(whichtoinvert, (tuple,list)) and (sum([w is not None for w in whichtoinvert])==0)):\n        if (len(transformlist) == 2) and ('.mat' in transformlist[0]) and ('.mat' not in transformlist[1]):\n            whichtoinvert = (True, False)\n        else:\n            whichtoinvert = tuple([False]*len(transformlist))\n\n    if len(whichtoinvert) != len(transformlist):\n        raise ValueError('Transform list and inversion list must be the same length')\n\n    for i in range(len(transformlist)):\n        ismat = False\n        if '.mat' in transformlist[i]:\n            ismat = True\n        if whichtoinvert[i] and (not ismat):\n            raise ValueError('Cannot invert transform %i (%s) because it is not a matrix' % (i, transformlist[i]))\n        if whichtoinvert[i]:\n            mytx = mytx + ['-t', '[%s,1]' % (transformlist[i])]\n        else:\n            mytx = mytx + ['-t', transformlist[i]]\n    if dim == 2:\n        pointsSub = points[['x','y']]\n    if dim == 3:\n        pointsSub = points[['x','y','z']]\n    if dim == 4:\n        pointsSub = points[['x','y','z','t']]\n    pointImage = core.make_image( pointsSub.shape, pointsSub.values.flatten())\n    pointsOut = pointImage.clone()\n    args = ['-d', dim,\n            '-i', pointImage,\n            '-o', pointsOut ]\n    args = args + mytx\n    myargs = utils._int_antsProcessArguments(args)\n\n    myverb = int(verbose)\n    if verbose:\n        print(myargs)\n\n    processed_args = myargs + [ '-f', str(1), '--precision', str(0)]\n    libfn = utils.get_lib_fn('antsApplyTransformsToPoints')\n    libfn(processed_args)\n    mynp = pointsOut.numpy()\n    pointsOutDF = points.copy()\n    pointsOutDF['x'] = mynp[:,0]\n    if dim >= 2:\n        pointsOutDF['y'] = mynp[:,1]\n    if dim >= 3:\n        pointsOutDF['z'] = mynp[:,2]\n    if dim >= 4:\n        pointsOutDF['t'] = mynp[:,3]\n    return pointsOutDF", "response": "This function applies a list of transforms to a set of points."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\napplies Anti-Alias filter to a binary image ANTsR function: N/A Arguments --------- image : ANTsImage binary image to which anti-aliasing will be applied Returns ------- ANTsImage Example ------- >>> import ants >>> img = ants.image_read(ants.get_data('r16')) >>> mask = ants.get_mask(img) >>> mask_aa = ants.anti_alias(mask) >>> ants.plot(mask) >>> ants.plot(mask_aa)", "response": "def anti_alias(image):\n    \"\"\"\n    Apply Anti-Alias filter to a binary image\n    \n    ANTsR function: N/A\n\n    Arguments\n    ---------\n    image : ANTsImage\n        binary image to which anti-aliasing will be applied\n\n    Returns\n    -------\n    ANTsImage\n\n    Example\n    -------\n    >>> import ants\n    >>> img = ants.image_read(ants.get_data('r16'))\n    >>> mask = ants.get_mask(img)\n    >>> mask_aa = ants.anti_alias(mask)\n    >>> ants.plot(mask)\n    >>> ants.plot(mask_aa)\n    \"\"\"\n    if image.pixeltype != 'unsigned char':\n        if image.max() > 255.:\n            image = (image - image.max()) / (image.max() - image.min())\n        image = image.clone('unsigned char')\n\n    libfn = utils.get_lib_fn('antiAlias%s' % image._libsuffix)\n    new_ptr = libfn(image.pointer)\n    return iio.ANTsImage(pixeltype='float', dimension=image.dimension, \n                         components=image.components, pointer=new_ptr)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef merge_channels(image_list):\n    inpixeltype = image_list[0].pixeltype\n    dimension = image_list[0].dimension\n    components = len(image_list)\n\n    for image in image_list:\n        if not isinstance(image, iio.ANTsImage):\n            raise ValueError('list may only contain ANTsImage objects')\n        if image.pixeltype != inpixeltype:\n            raise ValueError('all images must have the same pixeltype')\n\n    libfn = utils.get_lib_fn('mergeChannels%s' % image_list[0]._libsuffix)\n    image_ptr = libfn([image.pointer for image in image_list])\n    \n    return iio.ANTsImage(pixeltype=inpixeltype,\n                         dimension=dimension,\n                         components=components,\n                         pointer=image_ptr)", "response": "Function to merge multiple scalar ANTsImage types into one \n    ANTsR function"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsplitting a multi - channel ANTsImage into a collection of scalar ANTsImage types", "response": "def split_channels(image):\n    \"\"\"\n    Split channels of a multi-channel ANTsImage into a collection\n    of scalar ANTsImage types\n    \n    Arguments\n    ---------\n    image : ANTsImage\n        multi-channel image to split\n\n    Returns\n    -------\n    list of ANTsImage types\n\n    Example\n    -------\n    >>> import ants\n    >>> image = ants.image_read(ants.get_ants_data('r16'), 'float')\n    >>> image2 = ants.image_read(ants.get_ants_data('r16'), 'float')\n    >>> imagemerge = ants.merge_channels([image,image2])\n    >>> imagemerge.components == 2\n    >>> images_unmerged = ants.split_channels(imagemerge)\n    >>> len(images_unmerged) == 2\n    >>> images_unmerged[0].components == 1\n    \"\"\"\n    inpixeltype = image.pixeltype\n    dimension = image.dimension\n    components = 1\n\n    libfn = utils.get_lib_fn('splitChannels%s' % image._libsuffix)\n    itkimages = libfn(image.pointer)\n    antsimages = [iio.ANTsImage(pixeltype=inpixeltype, dimension=dimension, \n                              components=components, pointer=itkimage) for itkimage in itkimages]\n    return antsimages"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_fixed_image(self, image):\n        if not isinstance(image, iio.ANTsImage):\n            raise ValueError('image must be ANTsImage type')\n\n        if image.dimension != self.dimension:\n            raise ValueError('image dim (%i) does not match metric dim (%i)' % (image.dimension, self.dimension))\n\n        self._metric.setFixedImage(image.pointer, False)\n        self.fixed_image = image", "response": "Sets the fixed ANTsImage for this metric."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the fixed ANTsImage Mask for this metric.", "response": "def set_fixed_mask(self, image):\n        \"\"\"\n        Set Fixed ANTsImage Mask for metric\n        \"\"\"\n        if not isinstance(image, iio.ANTsImage):\n            raise ValueError('image must be ANTsImage type')\n\n        if image.dimension != self.dimension:\n            raise ValueError('image dim (%i) does not match metric dim (%i)' % (image.dimension, self.dimension))\n\n        self._metric.setFixedImage(image.pointer, True)\n        self.fixed_mask = image"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_moving_image(self, image):\n        if not isinstance(image, iio.ANTsImage):\n            raise ValueError('image must be ANTsImage type')\n\n        if image.dimension != self.dimension:\n            raise ValueError('image dim (%i) does not match metric dim (%i)' % (image.dimension, self.dimension))\n\n        self._metric.setMovingImage(image.pointer, False)\n        self.moving_image = image", "response": "Sets the Moving ANTsImage for this metric."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the fixed ANTsImage Mask for metric.", "response": "def set_moving_mask(self, image):\n        \"\"\"\n        Set Fixed ANTsImage Mask for metric\n        \"\"\"\n        if not isinstance(image, iio.ANTsImage):\n            raise ValueError('image must be ANTsImage type')\n\n        if image.dimension != self.dimension:\n            raise ValueError('image dim (%i) does not match metric dim (%i)' % (image.dimension, self.dimension))\n\n        self._metric.setMovingImage(image.pointer, True)\n        self.moving_mask = image"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef image_to_cluster_images(image, min_cluster_size=50, min_thresh=1e-06, max_thresh=1):\n    if not isinstance(image, iio.ANTsImage):\n        raise ValueError('image must be ANTsImage type')\n\n    clust = label_clusters(image, min_cluster_size, min_thresh, max_thresh)\n    labs = np.unique(clust[clust > 0])\n\n    clustlist = []\n    for i in range(len(labs)):\n        labimage = image.clone()\n        labimage[clust != labs[i]] = 0\n        clustlist.append(labimage)\n    return clustlist", "response": "This function converts an image to several independent images. It returns a list of unique image for each connected \n    component 1 through N of size > = min_cluster_size and N of size > max_thresh"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef threshold_image(image, low_thresh=None, high_thresh=None, inval=1, outval=0, binary=True):\n    if high_thresh is None:\n        high_thresh = image.max() + 0.01\n    if low_thresh is None:\n        low_thresh = image.min() - 0.01\n    dim = image.dimension\n    outimage = image.clone()\n    args = [dim, image, outimage, low_thresh, high_thresh, inval, outval]\n    processed_args = _int_antsProcessArguments(args)\n    libfn = utils.get_lib_fn('ThresholdImage')\n    libfn(processed_args)\n    if binary:\n        return outimage\n    else:\n        return outimage*image", "response": "This function takes a scalar image and returns a ANTsImage object that is binary and thresholding operations."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nusing registration and reflection to make an image symmetric ANTsR function: N/A Arguments --------- image : ANTsImage image to make symmetric Returns ------- ANTsImage Example ------- >>> import ants >>> image = ants.image_read( ants.get_ants_data('r16') , 'float') >>> simage = ants.symimage(image)", "response": "def symmetrize_image(image):\n    \"\"\"\n    Use registration and reflection to make an image symmetric\n\n    ANTsR function: N/A\n\n    Arguments\n    ---------\n    image : ANTsImage\n        image to make symmetric\n\n    Returns\n    -------\n    ANTsImage\n\n    Example\n    -------\n    >>> import ants\n    >>> image = ants.image_read( ants.get_ants_data('r16') , 'float')\n    >>> simage = ants.symimage(image)\n    \"\"\"\n    imager = reflect_image(image, axis=0)\n    imageavg = imager * 0.5 + image\n    for i in range(5):\n        w1 = registration(imageavg, image, type_of_transform='SyN')\n        w2 = registration(imageavg, imager, type_of_transform='SyN')\n        \n        xavg = w1['warpedmovout']*0.5 + w2['warpedmovout']*0.5\n        nada1 = apply_transforms(image, image, w1['fwdtransforms'], compose=w1['fwdtransforms'][0])\n        nada2 = apply_transforms(image, image, w2['fwdtransforms'], compose=w2['fwdtransforms'][0])\n\n        wavg = (iio.image_read(nada1) + iio.image_read(nada2)) * (-0.5)\n        wavgfn = mktemp(suffix='.nii.gz')\n        iio.image_write(wavg, wavgfn)\n        xavg = apply_transforms(image, imageavg, wavgfn)\n\n    return xavg"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates an ants metric for the given fixed and moving image.", "response": "def create_ants_metric(fixed, \n                        moving,\n                        metric_type='MeanSquares',\n                        fixed_mask=None,\n                        moving_mask=None,\n                        sampling_strategy='regular',\n                        sampling_percentage=1):\n    \"\"\"\n    Arguments\n    ---------\n    metric_type : string\n        which metric to use\n        options:\n            MeanSquares\n            MattesMutualInformation\n            ANTsNeighborhoodCorrelation\n            Correlation\n            Demons\n            JointHistogramMutualInformation\n\n    Example\n    -------\n    >>> import ants\n    >>> fixed = ants.image_read(ants.get_ants_data('r16'))\n    >>> moving = ants.image_read(ants.get_ants_data('r64'))\n    >>> metric_type = 'Correlation'\n    >>> metric = ants.create_ants_metric(fixed, moving, metric_type)\n    \"\"\"\n    dimension = fixed.dimension\n    pixeltype = fixed.pixeltype\n    is_vector = False # For now, no multichannel images\n\n    if metric_type not in _supported_metrics:\n        raise ValueError('metric_type must be one of %s' % _supported_metrics)\n    \n    if (dimension < 2) or (dimension > 4):\n        raise ValueError('unsupported dimension %i' % dimension)\n\n    if not isinstance(moving, iio.ANTsImage):\n        raise ValueError('invalid moving image')\n    \n    if moving.dimension != dimension:\n        raise ValueError('Fixed and Moving images must have same dimension')\n\n    if not isinstance(fixed, iio.ANTsImage):\n        raise ValueError('invalid fixed image')\n\n    fixed = fixed.clone('float')\n    moving = moving.clone('float') \n\n    libfn = utils.get_lib_fn('create_ants_metricF%i' % dimension)\n    metric = libfn(pixeltype, dimension, metric_type, is_vector, fixed.pointer, moving.pointer)\n\n    ants_metric = mio.ANTsImageToImageMetric(metric)\n    ants_metric.set_fixed_image(fixed)\n    ants_metric.set_moving_image(moving)\n\n    if isinstance(fixed_mask, iio.ANTsImage):\n        ants_metric.set_fixed_mask(fixed_mask)\n\n    if isinstance(moving_mask, iio.ANTsImage):\n        ants_metric.set_moving_mask(moving_mask)\n\n    ants_metric.set_sampling(sampling_strategy, sampling_percentage)\n    ants_metric.initialize()\n\n    return ants_metric"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef label_geometry_measures(label_image, intensity_image=None):\n    if intensity_image is None:\n        intensity_image = label_image.clone()\n\n    outcsv = mktemp(suffix='.csv')\n\n    veccer = [label_image.dimension, label_image, intensity_image, outcsv]\n    veccer_processed = utils._int_antsProcessArguments(veccer)\n    libfn = utils.get_lib_fn('LabelGeometryMeasures')\n    pp = libfn(veccer_processed)\n    pp = pd.read_csv(outcsv)\n    pp['Label'] = np.sort(np.unique(label_image[label_image>0])).astype('int')\n    pp_cols = pp.columns.values\n    pp_cols[1] = 'VolumeInMillimeters'\n    pp.columns = pp_cols\n    spc = np.prod(label_image.spacing)\n    pp['VolumeInMillimeters'] = pp['VolumeInMillimeters']*spc\n    return pp", "response": "Function to compute the geometry of a set of label_image and intensity_image."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_date(string, force_datetime=False):\n    matches = DATE.match(string)\n    if not matches:\n        return None\n\n    values = dict([\n        (\n            k,\n            v if v[0] in '+-' else int(v)\n        ) for k,v in matches.groupdict().items() if v and int(v)\n    ])\n\n    if 'timestamp' in values:\n        value = datetime.datetime.utcfromtimestamp(0) + datetime.timedelta(\n            hours=int(values.get('offset_h', 0)),\n            minutes=int(values.get('offset_m', 0)),\n            seconds=int(values['timestamp']) / 1000.0\n        )\n        return value\n\n    # I've made an assumption here, that a DateTime value will not\n    # ever be YYYY-MM-DDT00:00:00, which is probably bad. I'm not\n    # really sure how to handle this, other than to hard-code the\n    # names of the field that are actually Date rather than DateTime.\n    if len(values) > 3 or force_datetime:\n        return datetime.datetime(**values)\n\n    # Sometimes Xero returns Date(0+0000), so we end up with no\n    # values. Return None for this case\n    if not values:\n        return None\n\n    return datetime.date(**values)", "response": "Takes a Xero formatted date e. g. / Date 1426849200000 + 1300"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhooks for json. parse to parse Xero date formats.", "response": "def json_load_object_hook(dct):\n    \"\"\" Hook for json.parse(...) to parse Xero date formats.\n    \"\"\"\n    for key, value in dct.items():\n        if isinstance(value, six.string_types):\n            value = parse_date(value)\n            if value:\n                dct[key] = value\n\n    return dct"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve a list of attachments associated with this Xero object.", "response": "def _get_attachments(self, id):\n        \"\"\"Retrieve a list of attachments associated with this Xero object.\"\"\"\n        uri = '/'.join([self.base_url, self.name, id, 'Attachments']) + '/'\n        return uri, {}, 'get', None, None, False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_attachment_data(self, id, filename):\n        uri = '/'.join([self.base_url, self.name, id, 'Attachments', filename])\n        return uri, {}, 'get', None, None, False", "response": "Retrieve the contents of a specific attachment."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_attachment(self, id, filename, file):\n        data = self.get_attachment_data(id, filename)\n        file.write(data)\n        return len(data)", "response": "Retrieve the contents of a specific attachment identified by filename. Returns the length of data written."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupload an attachment to the Xero object.", "response": "def _put_attachment_data(self, id, filename, data, content_type, include_online=False):\n        \"\"\"Upload an attachment to the Xero object.\"\"\"\n        uri = '/'.join([self.base_url, self.name, id, 'Attachments', filename])\n        params = {'IncludeOnline': 'true'} if include_online else {}\n        headers = {'Content-Type': content_type, 'Content-Length': str(len(data))}\n        return uri, params, 'put', data, headers, False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef put_attachment(self, id, filename, file, content_type, include_online=False):\n        return self.put_attachment_data(id, filename, file.read(), content_type, include_online=include_online)", "response": "Upload an attachment to the Xero object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef page_response(self, title='', body=''):\n        f = StringIO()\n        f.write('<!DOCTYPE html>\\n')\n        f.write('<html>\\n')\n        f.write('<head><title>{}</title><head>\\n'.format(title))\n        f.write('<body>\\n<h2>{}</h2>\\n'.format(title))\n        f.write('<div class=\"content\">{}</div>\\n'.format(body))\n        f.write('</body>\\n</html>\\n')\n        length = f.tell()\n        f.seek(0)\n        self.send_response(200)\n        encoding = sys.getfilesystemencoding()\n        self.send_header(\"Content-type\", \"text/html; charset=%s\" % encoding)\n        self.send_header(\"Content-Length\", str(length))\n        self.end_headers()\n        self.copyfile(f, self.wfile)\n        f.close()", "response": "Helper to render an html page with dynamic content"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndepend on the state passed in get self. _oauth up and running", "response": "def _init_credentials(self, oauth_token, oauth_token_secret):\n        \"Depending on the state passed in, get self._oauth up and running\"\n        if oauth_token and oauth_token_secret:\n            if self.verified:\n                # If provided, this is a fully verified set of\n                # credentials. Store the oauth_token and secret\n                # and initialize OAuth around those\n                self._init_oauth(oauth_token, oauth_token_secret)\n\n            else:\n                # If provided, we are reconstructing an initalized\n                # (but non-verified) set of public credentials.\n                self.oauth_token = oauth_token\n                self.oauth_token_secret = oauth_token_secret\n\n        else:\n            # This is a brand new set of credentials - we need to generate\n            # an oauth token so it's available for the url property.\n            oauth = OAuth1(\n                self.consumer_key,\n                client_secret=self.consumer_secret,\n                callback_uri=self.callback_uri,\n                rsa_key=self.rsa_key,\n                signature_method=self._signature_method\n            )\n\n            url = self.base_url + REQUEST_TOKEN_URL\n            headers = {'User-Agent': self.user_agent}\n            response = requests.post(url=url, headers=headers, auth=oauth)\n            self._process_oauth_response(response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _init_oauth(self, oauth_token, oauth_token_secret):\n        \"Store and initialize a verified set of OAuth credentials\"\n        self.oauth_token = oauth_token\n        self.oauth_token_secret = oauth_token_secret\n\n        self._oauth = OAuth1(\n            self.consumer_key,\n            client_secret=self.consumer_secret,\n            resource_owner_key=self.oauth_token,\n            resource_owner_secret=self.oauth_token_secret,\n            rsa_key=self.rsa_key,\n            signature_method=self._signature_method\n        )", "response": "Store and initialize a verified set of OAuth credentials"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _process_oauth_response(self, response):\n        \"Extracts the fields from an oauth response\"\n        if response.status_code == 200:\n            credentials = parse_qs(response.text)\n\n            # Initialize the oauth credentials\n            self._init_oauth(\n                credentials.get('oauth_token')[0],\n                credentials.get('oauth_token_secret')[0]\n            )\n\n            # If tokens are refreshable, we'll get a session handle\n            self.oauth_session_handle = credentials.get(\n                    'oauth_session_handle', [None])[0]\n\n            # Calculate token/auth expiry\n            oauth_expires_in = credentials.get(\n                    'oauth_expires_in',\n                    [OAUTH_EXPIRY_SECONDS])[0]\n            oauth_authorisation_expires_in = credentials.get(\n                    'oauth_authorization_expires_in',\n                    [OAUTH_EXPIRY_SECONDS])[0]\n\n            self.oauth_expires_at = datetime.datetime.now() + \\\n                                    datetime.timedelta(seconds=int(\n                                        oauth_expires_in))\n            self.oauth_authorization_expires_at = \\\n                                    datetime.datetime.now() + \\\n                                    datetime.timedelta(seconds=int(\n                                        oauth_authorisation_expires_in))\n        else:\n            self._handle_error_response(response)", "response": "Extracts the fields from an oauth response"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nobtains the useful state of this credentials object so that it can reconstruct it independently.", "response": "def state(self):\n        \"\"\"Obtain the useful state of this credentials object so that\n        we can reconstruct it independently.\n        \"\"\"\n        return dict(\n            (attr, getattr(self, attr))\n            for attr in (\n                'consumer_key', 'consumer_secret', 'callback_uri',\n                'verified', 'oauth_token', 'oauth_token_secret',\n                'oauth_session_handle', 'oauth_expires_at',\n                'oauth_authorization_expires_at', 'scope'\n            )\n            if getattr(self, attr) is not None\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nverifying an OAuth token", "response": "def verify(self, verifier):\n        \"Verify an OAuth token\"\n\n        # Construct the credentials for the verification request\n        oauth = OAuth1(\n            self.consumer_key,\n            client_secret=self.consumer_secret,\n            resource_owner_key=self.oauth_token,\n            resource_owner_secret=self.oauth_token_secret,\n            verifier=verifier,\n            rsa_key=self.rsa_key,\n            signature_method=self._signature_method\n        )\n\n        # Make the verification request, gettiung back an access token\n        url = self.base_url + ACCESS_TOKEN_URL\n        headers = {'User-Agent': self.user_agent}\n        response = requests.post(url=url, headers=headers, auth=oauth)\n        self._process_oauth_response(response)\n        self.verified = True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the URL that can be visited to obtain a verifier code", "response": "def url(self):\n        \"Returns the URL that can be visited to obtain a verifier code\"\n        # The authorize url is always api.xero.com\n        query_string = {'oauth_token': self.oauth_token}\n\n        if self.scope:\n            query_string['scope'] = self.scope\n\n        url = XERO_BASE_URL + AUTHORIZE_URL + '?' + \\\n              urlencode(query_string)\n        return url"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef refresh(self):\n        \"Refresh an expired token\"\n\n        # Construct the credentials for the verification request\n        oauth = OAuth1(\n            self.consumer_key,\n            client_secret=self.consumer_secret,\n            resource_owner_key=self.oauth_token,\n            resource_owner_secret=self.oauth_token_secret,\n            rsa_key=self.rsa_key,\n            signature_method=self._signature_method\n        )\n\n        # Make the verification request, getting back an access token\n        headers = {'User-Agent': self.user_agent}\n        params = {'oauth_session_handle': self.oauth_session_handle}\n        response = requests.post(url=self.base_url + ACCESS_TOKEN_URL,\n                params=params, headers=headers, auth=oauth)\n        self._process_oauth_response(response)", "response": "Refresh an expired token"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving the list of files contained in a folder", "response": "def _get_files(self, folderId):\n        \"\"\"Retrieve the list of files contained in a folder\"\"\"\n        uri = '/'.join([self.base_url, self.name, folderId, 'Files'])\n        return uri, {}, 'get', None, None, False, None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhandle the cluster command.", "response": "def handle_cluster_request(self, tsn, command_id, args):\n        \"\"\"Handle the cluster command.\"\"\"\n        if command_id == 0:\n            if self._timer_handle:\n                self._timer_handle.cancel()\n            loop = asyncio.get_event_loop()\n            self._timer_handle = loop.call_later(30, self._turn_off)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parse_attributes(self, value):\n        from zigpy.zcl import foundation as f\n        attributes = {}\n        attribute_names = {\n            1: BATTERY_VOLTAGE_MV,\n            3: TEMPERATURE,\n            4: XIAOMI_ATTR_4,\n            5: XIAOMI_ATTR_5,\n            6: XIAOMI_ATTR_6,\n            10: PATH\n        }\n        result = {}\n        while value:\n            skey = int(value[0])\n            svalue, value = f.TypeValue.deserialize(value[1:])\n            result[skey] = svalue.value\n        for item, value in result.items():\n            key = attribute_names[item] \\\n                if item in attribute_names else \"0xff01-\" + str(item)\n            attributes[key] = value\n        if BATTERY_VOLTAGE_MV in attributes:\n            attributes[BATTERY_LEVEL] = int(\n                self._calculate_remaining_battery_percentage(\n                    attributes[BATTERY_VOLTAGE_MV]\n                )\n            )\n        return attributes", "response": "Parse non standard atrributes."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncalculate percentage of battery remaining.", "response": "def _calculate_remaining_battery_percentage(self, voltage):\n        \"\"\"Calculate percentage.\"\"\"\n        min_voltage = 2500\n        max_voltage = 3000\n        percent = (voltage - min_voltage) / (max_voltage - min_voltage) * 200\n        return min(200, percent)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef battery_reported(self, voltage, rawVoltage):\n        self._update_attribute(BATTERY_PERCENTAGE_REMAINING, voltage)\n        self._update_attribute(self.BATTERY_VOLTAGE_ATTR,\n                               int(rawVoltage / 100))", "response": "Updates the battery percentage reported."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the object removing the device group if inherited from the root folder", "response": "def update(self, **kwargs):\n        '''Update the object, removing device group if inherited\n\n        If inheritedDevicegroup is the string \"true\" we need to remove\n        deviceGroup from the args before we update or we get the\n        following error:\n\n        The floating traffic-group: /Common/traffic-group-1 can only be set on\n        /testfolder if its device-group is inherited from the root folder\n        '''\n        inherit_device_group = self.__dict__.get('inheritedDevicegroup', False)\n        if inherit_device_group == 'true':\n            self.__dict__.pop('deviceGroup')\n        return self._update(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef exists(self, **kwargs):\n\n        requests_params = self._handle_requests_params(kwargs)\n        self._check_load_parameters(**kwargs)\n        load_uri = self._create_subpath_uri(kwargs)\n        session = self._meta_data['bigip']._meta_data['icr_session']\n        kwargs.update(requests_params)\n        try:\n            session.get(load_uri, **kwargs)\n        except HTTPError as err:\n            logger.debug(err.response.text)\n            if err.response.status_code == 404:\n                return False\n            else:\n                raise\n        return True", "response": "Checks if the named object exists on the BIG - IP."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading the application resource.", "response": "def _load_11_6(self, **kwargs):\n        \"\"\"Must check if rule actually exists before proceeding with load.\"\"\"\n        if self._check_existence_by_collection(self._meta_data['container'],\n                                               kwargs['name']):\n            return super(Protocol_Dns, self)._load(**kwargs)\n        msg = 'The application resource named, {}, does not exist on the ' \\\n              'device.'.format(kwargs['name'])\n        raise NonExtantApplication(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrap method that synchronizes configuration to device - group.", "response": "def sync_to(self):\n        \"\"\"Wrapper method that synchronizes configuration to DG.\n\n\n        Executes the containing object's cm :meth:`~f5.bigip.cm.Cm.exec_cmd`\n        method to sync the configuration TO the device-group.\n\n        :note:: Both sync_to, and sync_from methods are convenience\n                methods which usually are not what this SDK offers.\n                It is best to execute config-sync with the use of\n                exec_cmd() method on the cm endpoint.\n        \"\"\"\n        device_group_collection = self._meta_data['container']\n        cm = device_group_collection._meta_data['container']\n        sync_cmd = 'config-sync to-group %s' % self.name\n        cm.exec_cmd('run', utilCmdArgs=sync_cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate service on device and create accompanying Python object.", "response": "def _create(self, **kwargs):\n        '''Create service on device and create accompanying Python object.\n\n        :params kwargs: keyword arguments passed in from create call\n        :raises: HTTPError\n        :returns: Python Service object\n        '''\n\n        try:\n            return super(Service, self)._create(**kwargs)\n        except HTTPError as ex:\n            if \"The configuration was updated successfully but could not be \" \\\n                    \"retrieved\" not in ex.response.text:\n                raise\n\n            # BIG-IP\u00ae will create in Common partition if none is given.\n            # In order to create the uri properly in this class's load,\n            # drop in Common as the partition in kwargs.\n            if 'partition' not in kwargs:\n                kwargs['partition'] = 'Common'\n            # Pop all but the necessary load kwargs from the kwargs given to\n            # create. Otherwise, load may fail.\n            kwargs_copy = kwargs.copy()\n            for key in kwargs_copy:\n                if key not in self._meta_data['required_load_parameters']:\n                    kwargs.pop(key)\n            # If response was created successfully, do a local_update.\n            # If not, call to overridden _load method via load\n            return self.load(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads python Service object with response JSON from BIG - IP\u00ae.", "response": "def _load(self, **kwargs):\n        '''Load python Service object with response JSON from BIG-IP\u00ae.\n\n        :params kwargs: keyword arguments for talking to the device\n        :returns: populated Service object\n        '''\n        # Some kwargs should be popped before we do a load\n        for key in self._meta_data['disallowed_load_parameters']:\n            if key in kwargs:\n                kwargs.pop(key)\n\n        self._check_load_parameters(**kwargs)\n        name = kwargs.pop('name', '')\n        partition = kwargs.pop('partition', '')\n        read_session = self._meta_data['icr_session']\n        base_uri = self._meta_data['container']._meta_data['uri']\n\n        load_uri = self._build_service_uri(base_uri, partition, name)\n        response = read_session.get(load_uri, uri_as_parts=False, **kwargs)\n        return self._produce_instance(response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _build_service_uri(self, base_uri, partition, name):\n        '''Build the proper uri for a service resource.\n\n        This follows the scheme:\n            <base_uri>/~<partition>~<<name>.app>~<name>\n\n        :param base_uri: str -- base uri for container\n        :param partition: str -- partition for this service\n        :param name: str -- name of the service\n        :returns: str -- uri to access this service\n        '''\n        name = name.replace('/', '~')\n        return '%s~%s~%s.app~%s' % (base_uri, partition, name, name)", "response": "Build the proper uri for a service resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef exists(self, **kwargs):\n        '''Check for the existence of the named object on the BIG-IP\n\n        Override of resource.Resource exists() to build proper URI unique to\n        service resources.\n\n        Sends an HTTP GET to the URI of the named object and if it fails with\n        a :exc:~requests.HTTPError` exception it checks the exception for\n        status code of 404 and returns :obj:`False` in that case.\n\n        If the GET is successful it returns :obj:`True`.\n\n        For any other errors are raised as-is.\n\n        :param kwargs: Keyword arguments required to get objects\n        NOTE: If kwargs has a 'requests_params' key the corresponding dict will\n        be passed to the underlying requests.session.get method where it will\n        be handled according to that API. THIS IS HOW TO PASS QUERY-ARGS!\n        :returns: bool -- The objects exists on BIG-IP\u00ae or not.\n        :raises: :exc:`requests.HTTPError`, Any HTTP error that was not status\n                 code 404.\n        '''\n\n        requests_params = self._handle_requests_params(kwargs)\n        self._check_load_parameters(**kwargs)\n        kwargs['uri_as_parts'] = False\n        session = self._meta_data['bigip']._meta_data['icr_session']\n        base_uri = self._meta_data['container']._meta_data['uri']\n        partition = kwargs.pop('partition')\n        name = kwargs.pop('name')\n\n        exists_uri = self._build_service_uri(base_uri, partition, name)\n        kwargs.update(requests_params)\n        try:\n            session.get(exists_uri, **kwargs)\n        except HTTPError as err:\n            if err.response.status_code == 404:\n                return False\n            else:\n                raise\n        return True", "response": "Check for the existence of the named object on the BIG - IP."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete(self, **kwargs):\n        if 'id' not in kwargs:\n            # BIG-IQ requires that you provide the ID of the members to revoke\n            # a license from. This ID is already part of the deletion URL though.\n            # Therefore, if you do not provide it, we enumerate it for you.\n            delete_uri = self._meta_data['uri']\n            if delete_uri.endswith('/'):\n                delete_uri = delete_uri[0:-1]\n                kwargs['id'] = os.path.basename(delete_uri)\n            uid = uuid.UUID(kwargs['id'], version=4)\n            if uid.hex != kwargs['id'].replace('-', ''):\n                raise F5SDKError(\n                    \"The specified ID is invalid\"\n                )\n\n        requests_params = self._handle_requests_params(kwargs)\n        kwargs = self._check_for_python_keywords(kwargs)\n        kwargs = self._prepare_request_json(kwargs)\n\n        delete_uri = self._meta_data['uri']\n        session = self._meta_data['bigip']._meta_data['icr_session']\n\n        # Check the generation for match before delete\n        force = self._check_force_arg(kwargs.pop('force', True))\n        if not force:\n            self._check_generation()\n\n        response = session.delete(delete_uri, json=kwargs, **requests_params)\n        if response.status_code == 200:\n            self.__dict__ = {'deleted': True}\n\n        # This sleep is necessary to prevent BIG-IQ from being able to remove\n        # a license. It happens in certain cases that assignments can be revoked\n        # (and license deletion started) too quickly. Therefore, we must introduce\n        # an artificial delay here to prevent revoking from returning before\n        # BIG-IQ would be ready to remove the license.\n        time.sleep(1)", "response": "Deletes a member from a license pool."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting attributes for instance in one place", "response": "def _set_attributes(self, **kwargs):\n        '''Set attributes for instance in one place\n\n        :param kwargs: dict -- dictionary of keyword arguments\n        '''\n\n        self.devices = kwargs['devices'][:]\n        self.partition = kwargs['partition']\n        self.device_group_name = 'device_trust_group'\n        self.device_group_type = 'sync-only'"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate(self):\n        '''Validate that devices are each trusted by one another\n\n        :param kwargs: dict -- keyword args for devices and partition\n        :raises: DeviceNotTrusted\n        '''\n\n        self._populate_domain()\n        missing = []\n        for domain_device in self.domain:\n            for truster, trustees in iteritems(self.domain):\n                if domain_device not in trustees:\n                    missing.append((domain_device, truster, trustees))\n\n        if missing:\n            msg = ''\n            for item in missing:\n                msg += '\\n%r is not trusted by %r, which trusts: %r' % \\\n                    (item[0], item[1], item[2])\n            raise DeviceNotTrusted(msg)\n        self.device_group = DeviceGroup(\n            devices=self.devices,\n            device_group_name=self.device_group_name,\n            device_group_type=self.device_group_type,\n            device_group_partition=self.partition\n        )", "response": "Validate that devices are each trusted by one another."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _populate_domain(self):\n        '''Populate TrustDomain's domain attribute.\n\n        This entails an inspection of each device's certificate-authority\n        devices in its trust domain and recording them. After which, we\n        get a dictionary of who trusts who in the domain.\n        '''\n\n        self.domain = {}\n        for device in self.devices:\n            device_name = get_device_info(device).name\n            ca_devices = \\\n                device.tm.cm.trust_domains.trust_domain.load(\n                    name='Root'\n                ).caDevices\n            self.domain[device_name] = [\n                d.replace('/%s/' % self.partition, '') for d in ca_devices\n            ]", "response": "Populate TrustDomain s domain attribute."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new trust object.", "response": "def create(self, **kwargs):\n        '''Add trusted peers to the root bigip device.\n\n        When adding a trusted device to a device, the trust is reflexive. That\n        is, the truster trusts the trustee and the trustee trusts the truster.\n        So we only need to add the trusted devices to one device.\n\n        :param kwargs: dict -- devices and partition\n        '''\n\n        self._set_attributes(**kwargs)\n        for device in self.devices[1:]:\n            self._add_trustee(device)\n        pollster(self.validate)()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef teardown(self):\n        '''Teardown trust domain by removing trusted devices.'''\n\n        for device in self.devices:\n            self._remove_trustee(device)\n            self._populate_domain()\n        self.domain = {}", "response": "Teardown trust domain by removing trusted devices."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _add_trustee(self, device):\n        '''Add a single trusted device to the trust domain.\n\n        :param device: ManagementRoot object -- device to add to trust domain\n        '''\n\n        device_name = get_device_info(device).name\n        if device_name in self.domain:\n            msg = 'Device: %r is already in this trust domain.' % device_name\n            raise DeviceAlreadyInTrustDomain(msg)\n        self._modify_trust(self.devices[0], self._get_add_trustee_cmd, device)", "response": "Add a single trusted device to the trust domain."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _remove_trustee(self, device):\n        '''Remove a trustee from the trust domain.\n\n        :param device: MangementRoot object -- device to remove\n        '''\n\n        trustee_name = get_device_info(device).name\n        name_object_map = get_device_names_to_objects(self.devices)\n        delete_func = self._get_delete_trustee_cmd\n\n        for truster in self.domain:\n            if trustee_name in self.domain[truster] and \\\n                    truster != trustee_name:\n                truster_obj = name_object_map[truster]\n                self._modify_trust(truster_obj, delete_func, trustee_name)\n            self._populate_domain()\n\n        for trustee in self.domain[trustee_name]:\n            if trustee_name != trustee:\n                self._modify_trust(device, delete_func, trustee)\n\n        self.devices.remove(name_object_map[trustee_name])", "response": "Remove a trustee from the trust domain."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmodifies a trusted peer device by deploying an iapp.", "response": "def _modify_trust(self, truster, mod_peer_func, trustee):\n        '''Modify a trusted peer device by deploying an iapp.\n\n\n        :param truster: ManagementRoot object -- device on which to perform\n                        commands\n        :param mod_peer_func: function -- function to call to modify peer\n        :param trustee: ManagementRoot object or str -- device to modify\n        '''\n\n        iapp_name = 'trusted_device'\n        mod_peer_cmd = mod_peer_func(trustee)\n        iapp_actions = self.iapp_actions.copy()\n        iapp_actions['definition']['implementation'] = mod_peer_cmd\n        self._deploy_iapp(iapp_name, iapp_actions, truster)\n        self._delete_iapp(iapp_name, truster)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _delete_iapp(self, iapp_name, deploying_device):\n        '''Delete an iapp service and template on the root device.\n\n        :param iapp_name: str -- name of iapp\n        :param deploying_device: ManagementRoot object -- device where the\n                                 iapp will be deleted\n        '''\n\n        iapp = deploying_device.tm.sys.application\n        iapp_serv = iapp.services.service.load(\n            name=iapp_name, partition=self.partition\n        )\n        iapp_serv.delete()\n        iapp_tmpl = iapp.templates.template.load(\n            name=iapp_name, partition=self.partition\n        )\n        iapp_tmpl.delete()", "response": "Delete an iapp service and template on the root device."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _deploy_iapp(self, iapp_name, actions, deploying_device):\n        '''Deploy iapp to add trusted device\n\n        :param iapp_name: str -- name of iapp\n        :param actions: dict -- actions definition of iapp sections\n        :param deploying_device: ManagementRoot object -- device where the\n                                 iapp will be created\n        '''\n\n        tmpl = deploying_device.tm.sys.application.templates.template\n        serv = deploying_device.tm.sys.application.services.service\n        tmpl.create(name=iapp_name, partition=self.partition, actions=actions)\n        pollster(deploying_device.tm.sys.application.templates.template.load)(\n            name=iapp_name, partition=self.partition\n        )\n        serv.create(\n            name=iapp_name,\n            partition=self.partition,\n            template='/%s/%s' % (self.partition, iapp_name)\n        )", "response": "Deploy iapp to add trusted device\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_add_trustee_cmd(self, trustee):\n        '''Get tmsh command to add a trusted device.\n\n        :param trustee: ManagementRoot object -- device to add as trusted\n        :returns: str -- tmsh command to add trustee\n        '''\n\n        trustee_info = pollster(get_device_info)(trustee)\n        username = trustee._meta_data['username']\n        password = trustee._meta_data['password']\n        return 'tmsh::modify cm trust-domain Root ca-devices add ' \\\n            '\\\\{ %s \\\\} name %s username %s password %s' % \\\n            (trustee_info.managementIp, trustee_info.name, username, password)", "response": "Get tmsh command to add a trusted device."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef construct_cfgs(**kargs):\n    docker_dir = _check_args(**kargs)\n    if not docker_dir or not os.path.isdir(docker_dir):\n        print(\"Unable to determine the %s/%s combo under supported versioning\"\n              % (kargs['operating_system'], kargs['version']))\n        exit_cleanly(error_number=errno.ENOSYS)\n    if kargs['operating_system'] == 'redhat':\n        _build_setup_cfg(kargs['working_directory'])\n    elif kargs['operating_system'] == 'ubuntu':\n        _build_stdeb_cfg(kargs['working_directory'])\n    else:\n        print(\"Unsure of what to do... operating_system(%s) is not recognized!\"\n              % kargs['operating_system'])", "response": "Construct the configuration files for the current version of the current operating system."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_args():\n    expected = ['working_directory', 'operating_system', 'version']\n    possible = ['json'].extend(expected)\n    try:\n        opts, args = getopt.getopt(sys.argv[1:], '', map(lambda x: ('%s=' % x),\n                                   possible))\n    except getopt.GetoptError as err:\n        print(str(err))\n        exit_cleanly(error_number=errno.EINVAL)\n    arguments = dict()\n    for o, a in opts:\n        option = re.sub('^-*', '', o)\n        if 'json' in option:\n            arguments = _load_json(a)\n            break\n        if option in expected:\n            arguments[option] = a\n    error = 0\n    for item in expected:\n        if item not in arguments:\n            print(\"Missing: %s from arguments\" % item)\n            error = errno.EINVAL\n    if error:\n        exit_cleanly(error_number=error)\n    return arguments", "response": "get_args\nTaxonomy function extracts the script arguments within the arguments variable and extracts their meaning before returning such content."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main():\n    try:\n        args = get_args()\n        if 'setup_cfg' in args and 'stdeb_cfg' in args:\n            _construct_cfgs_from_json(args)\n        else:\n            construct_cfgs(**args)\n    except Exception as Error:\n        print(str(Error))\n        print(\"Exiting cleanly...\")\n        exit_cleanly()\n    exit_cleanly(error_number=0)", "response": "This function is called by the main function in a cleanly fashon. It will handle any runtime\nerrors and exceptions in a cleanly fashon."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads a given resource and returns the vCMP resource object.", "response": "def load(self, **kwargs):\n        \"\"\"Loads a given resource\n\n        Loads a given resource provided a 'name' and an optional 'slot'\n        parameter. The 'slot' parameter is not a required load parameter\n        because it is provided as an optional way of constructing the\n        correct 'name' of the vCMP resource.\n\n        :param kwargs:\n        :return:\n        \"\"\"\n        kwargs['transform_name'] = True\n        kwargs = self._mutate_name(kwargs)\n        return self._load(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _check_load_parameters(self, **kwargs):\n\n        if 'partition' in kwargs:\n            msg = \"'partition' is not allowed as a load parameter. Vcmp \" \\\n                \"guests are accessed by name.\"\n            raise DisallowedReadParameter(msg)\n        super(Virtual_Disk, self)._check_load_parameters(**kwargs)", "response": "Override method for one in resource. py to check partition\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _check_create_parameters(self, **kwargs):\n\n        if 'partition' in kwargs:\n            msg = \"'partition' is not allowed as a create parameter. Vcmp \" \\\n                \"guests are created with the 'name' at least.\"\n            raise DisallowedCreationParameter(msg)\n        super(Virtual_Disk, self)._check_create_parameters(**kwargs)", "response": "Override method for one in resource. py to check partition\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the end of a section s content.", "response": "def _get_section_end_index(self, section, section_start):\n        '''Get end of section's content.\n\n        In the loop to match braces, we must not count curly braces that are\n        within a doubly quoted string.\n\n        :param section: string name of section\n        :param section_start: integer index of section's beginning\n        :return: integer index of section's end\n        :raises: CurlyBraceMismatchException\n        '''\n\n        brace_count = 0\n        in_quote = False\n        in_escape = False\n\n        for index, char in enumerate(self.template_str[section_start:]):\n            # This check is to look for items inside of an escape sequence.\n            #\n            # For example, in the iApp team's iApps, there is a proc called\n            # \"iapp_get_items\" which has a line that looks like this.\n            #\n            #     set val [string map {\\\" \"\"} $val]\n            #\n            # This will cause this parser to fail because of the unbalanced\n            # quotes. Therefore, this conditional takes this into consideration\n            #\n            if char == '\\\\' and not in_escape:\n                in_escape = True\n            elif char == '\\\\' and in_escape:\n                in_escape = False\n\n            if not in_escape:\n                if char == '\"' and not in_quote:\n                    in_quote = True\n                elif char == '\"' and in_quote:\n                    in_quote = False\n\n            if char == '{' and not in_quote:\n                brace_count += 1\n            elif char == '}' and not in_quote:\n                brace_count -= 1\n\n            if brace_count is 0:\n                return index + section_start\n\n        if brace_count is not 0:\n            raise CurlyBraceMismatchException(\n                'Curly braces mismatch in section %s.' % section\n                )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_section_start_index(self, section):\n        '''Get start of a section's content.\n\n        :param section: string name of section\n        :return: integer index of section's beginning\n        :raises: NonextantSectionException\n        '''\n\n        sec_start_re = r'%s\\s*\\{' % section\n\n        found = re.search(sec_start_re, self.template_str)\n        if found:\n            return found.end() - 1\n\n        raise NonextantSectionException(\n            'Section %s not found in template' % section\n            )", "response": "Get start of a section s content."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds template name. :returns: string of template name :raises: NonextantTemplateNameException", "response": "def _get_template_name(self):\n        '''Find template name.\n\n        :returns: string of template name\n        :raises: NonextantTemplateNameException\n        '''\n\n        start_pattern = r\"sys application template\\s+\" \\\n                        r\"(\\/[\\w\\.\\-]+\\/)?\" \\\n                        r\"(?P<name>[\\w\\.\\-]+)\\s*\\{\"\n\n        template_start = re.search(start_pattern, self.template_str)\n        if template_start:\n            return template_start.group('name')\n\n        raise NonextantTemplateNameException('Template name not found.')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_template_attr(self, attr):\n        '''Find the attribute value for a specific attribute.\n\n        :param attr: string of attribute name\n        :returns: string of attribute value\n        '''\n\n        attr_re = r'{0}\\s+.*'.format(attr)\n\n        attr_found = re.search(attr_re, self.template_str)\n        if attr_found:\n            attr_value = attr_found.group(0).replace(attr, '', 1)\n            return attr_value.strip()", "response": "Find the attribute value for a specific attribute."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _add_sections(self):\n        '''Add the found and required sections to the templ_dict.'''\n        for section in self.template_sections:\n            try:\n                sec_start = self._get_section_start_index(section)\n            except NonextantSectionException:\n                if section in self.sections_not_required:\n                    continue\n                raise\n            sec_end = self._get_section_end_index(section, sec_start)\n            section_value = self.template_str[sec_start+1:sec_end].strip()\n            section, section_value = self._transform_key_value(\n                section,\n                section_value,\n                self.section_map\n            )\n            self.templ_dict['actions']['definition'][section] = section_value\n            self.template_str = self.template_str[:sec_start+1] + \\\n                self.template_str[sec_end:]", "response": "Add the found and required sections to the templ_dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _add_cli_scripts(self):\n        '''Add the found external sections to the templ_dict.'''\n\n        pattern = r\"cli script\\s+\" \\\n                  r\"(\\/[\\w\\.\\-]+\\/)?\" \\\n                  r\"(?P<name>[\\w\\.\\-]+)\\s*\\{\"\n        sections = re.finditer(pattern, self.template_str)\n\n        for section in sections:\n            if 'scripts' not in self.templ_dict:\n                self.templ_dict['scripts'] = []\n\n            try:\n                sec_start = self._get_section_start_index(\n                    section.group('name')\n                )\n            except NonextantSectionException:\n                continue\n\n            sec_end = self._get_section_end_index(\n                section.group('name'), sec_start\n            )\n            section_value = self.template_str[sec_start+1:sec_end].strip()\n\n            self.templ_dict['scripts'].append(dict(\n                name=section.group('name'),\n                script=section_value\n            ))\n\n            self.template_str = self.template_str[:sec_start+1] + \\\n                self.template_str[sec_end:]", "response": "Add the found external sections to the templ_dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds the found and required attrs to the templ_dict.", "response": "def _add_attrs(self):\n        '''Add the found and required attrs to the templ_dict.'''\n        for attr in self.template_attrs:\n            attr_value = self._get_template_attr(attr)\n\n            if not attr_value:\n                continue\n\n            attr, attr_value = self._transform_key_value(\n                attr,\n                attr_value,\n                self.attr_map\n            )\n            self.templ_dict[attr] = attr_value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nturning a string representation of a TCL list into a Python list.", "response": "def _parse_tcl_list(self, attr, list_str):\n        '''Turns a string representation of a TCL list into a Python list.\n\n        :param attr: string name of attribute\n        :param list_str: string representation of a list\n        :returns: Python list\n        '''\n\n        list_str = list_str.strip()\n\n        if not list_str:\n            return []\n\n        if list_str[0] != '{' and list_str[-1] != '}':\n            if list_str.find('none') >= 0:\n                return list_str\n\n        if not re.search(self.tcl_list_patterns[attr], list_str):\n            raise MalformedTCLListException(\n                'TCL list for \"%s\" is malformed. ' % attr\n            )\n\n        list_str = list_str.strip('{').strip('}')\n        list_str = list_str.strip()\n        return list_str.split()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmassage keys and values for iapp dict to look like JSON.", "response": "def _transform_key_value(self, key, value, map_dict):\n        '''Massage keys and values for iapp dict to look like JSON.\n\n        :param key: string dictionary key\n        :param value: string dictionary value\n        :param map_dict: dictionary to map key names\n        '''\n\n        if key in self.tcl_list_patterns:\n            value = self._parse_tcl_list(key, value)\n\n        if key in map_dict:\n            key = map_dict[key]\n\n        return key, value"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the template string into a dictionary.", "response": "def parse_template(self):\n        '''Parse the template string into a dict.\n\n        Find the (large) inner sections first, save them, and remove them from\n        a modified string. Then find the template attributes in the modified\n        string.\n\n        :returns: dictionary of parsed template\n        '''\n\n        self.templ_dict = {'actions': {'definition': {}}}\n\n        self.templ_dict['name'] = self._get_template_name()\n\n        self._add_cli_scripts()\n        self._add_sections()\n        self._add_attrs()\n\n        return self.templ_dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncall this to change the configuration of the service on the device. This method uses HTTP PUT alter the service state on the device. The attributes of the instance will be packaged as a dictionary. That dictionary will be updated with kwargs. It is then submitted as JSON to the device. Various edge cases are handled: * read-only attributes that are unchangeable are removed * If ``fqdn`` is in the kwargs or set as an attribute, removes the ``autopopulate`` and ``addressFamily`` keys from it if there. :param kwargs: keys and associated values to alter on the device", "response": "def update(self, **kwargs):\n        \"\"\"Call this to change the configuration of the service on the device.\n\n        This method uses HTTP PUT alter the service state on the device.\n\n        The attributes of the instance will be packaged as a dictionary.  That\n        dictionary will be updated with kwargs.  It is then submitted as JSON\n        to the device.  Various edge cases are handled:\n\n        * read-only attributes that are unchangeable are removed\n        * If ``fqdn`` is in the kwargs or set as an attribute, removes the\n          ``autopopulate`` and ``addressFamily`` keys from it if there.\n\n        :param kwargs: keys and associated values to alter on the device\n\n        \"\"\"\n        checked = self._check_node_parameters(**kwargs)\n        return self._update(**checked)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if the node parameters are valid.", "response": "def _check_node_parameters(self, **kwargs):\n        \"\"\"See discussion in issue #840.\"\"\"\n        if 'fqdn' in kwargs:\n            kwargs['fqdn'].pop('autopopulate', '')\n            kwargs['fqdn'].pop('addressFamily', '')\n        if 'fqdn' in self.__dict__:\n            self.__dict__['fqdn'].pop('autopopulate', '')\n            self.__dict__['fqdn'].pop('addressFamily', '')\n        if 'state' in kwargs:\n            if kwargs['state'] != 'user-up' and kwargs['state'] != \\\n                    'user-down':\n                kwargs.pop('state')\n        if 'state' in self.__dict__:\n            if self.__dict__['state'] != 'user-up' and self.__dict__['state'] \\\n                    != 'user-down':\n                self.__dict__.pop('state')\n        if 'session' in kwargs:\n            if kwargs['session'] != 'user-enabled' and kwargs['session'] != \\\n                    'user-disabled':\n                kwargs.pop('session')\n        if 'session' in self.__dict__:\n            if self.__dict__['session'] != 'user-enabled' and \\\n                    self.__dict__['session'] != 'user-disabled':\n                self.__dict__.pop('session')\n        # Until we implement sanity checks for __dict__ this needs to stay here\n        self.__dict__.pop('ephemeral', '')\n        self.__dict__.pop('address', '')\n        return kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _modify(self, **patch):\n        if 'state' in patch:\n            if patch['state'] not in ['user-up', 'user-down', 'unchecked', 'fqdn-up']:\n                msg = \"The node resource does not support a modify with the \" \\\n                      \"value of the 'state' attribute as %s. The accepted \" \\\n                      \"values are 'user-up', 'user-down', 'unchecked', or 'fqdn-up'\" \\\n                      % patch['state']\n                raise NodeStateModifyUnsupported(msg)\n        if 'session' in patch:\n            if patch['session'] not in ['user-enabled', 'user-disabled']:\n                msg = \"The node resource does not support a modify with the \" \\\n                      \"value of the 'session' attribute as %s. \" \\\n                      \"The accepted values are 'user-enabled' or \" \\\n                      \"'user-disabled'\" % patch['session']\n                raise NodeStateModifyUnsupported(msg)\n        super(Node, self)._modify(**patch)", "response": "Override modify to check kwargs before request sent to device."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new resource associated with the BIG - IP.", "response": "def create(self, **kwargs):\n        \"\"\"Create the resource on the BIG-IP\u00ae.\n\n        Uses HTTP POST to the `collection` URI to create a resource associated\n        with a new unique URI on the device.\n\n        ..\n            If you do a create with inheritedTrafficGroup set to 'false' you\n            must also have a trafficGroup.  This pattern generalizes like so:\n            If the presence of a param implies an additional required param,\n            then simply\n            self._meta_data['required_creation_params'].update(IMPLIED),\n            before the call to self._create(**kwargs), wherein req params are\n            checked.\n\n            We refer to this property as \"implied-required parameters\" because\n            the presence of one parameter, or parameter value (e.g.\n            inheritedTrafficGroup), implies that another parameter is required.\n\n        .. note::\n            If you are creating with ``inheritedTrafficGroup` set to\n            :obj:`False` you just also have a `trafficGroup`.\n\n        :param kwargs: All the key-values needed to create the resource\n        :returns: ``self`` - A python object that represents the object's\n                  configuration and state on the BIG-IP\u00ae.\n\n        \"\"\"\n        itg = kwargs.get('inheritedTrafficGroup', None)\n        if itg and itg == 'false':\n            self._meta_data['required_creation_parameters'].\\\n                update(('trafficGroup',))\n            try:\n                if not kwargs['trafficGroup']:\n                    raise MissingRequiredCreationParameter(\n                        \"trafficGroup must not be falsey but it's: %r\"\n                        % kwargs['trafficGroup'])\n            except KeyError:\n                pass\n        new_instance = self._create(**kwargs)\n        return new_instance"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef terminal(cmd, log=None, args=[], want_result=True, multi_stmt=False):\n    Error = None\n    succeeded = False\n    if log and isinstance(log, str) and os.access(log, os.W_OK):\n        fh = open(log, 'w')\n    else:\n        fh = Hold()\n    if args and isinstance(cmd, str):\n        cmd = [cmd]\n        cmd.extend(args)\n    try:\n        proc = subprocess.Popen(cmd, shell=multi_stmt, stdout=subprocess.PIPE,\n                                stderr=subprocess.PIPE)\n        # fh.write(subprocess.check_output(cmd, shell=multi_stmt))\n        out, err = proc.communicate()\n        fh.write('Out:\\n' + str(out))\n        fh.write('Err:\\n' + str(err))\n        succeeded = True if proc.returncode == 0 else False\n    except OSError as Error:\n        fh.write(str(Error))\n    except subprocess.CalledProcessError as Error:\n        fh.write(str(Error))\n\n    try:\n        fh.close()\n        result = Result(succeeded, None, Error)\n    except Exception:\n        if want_result:\n            result = Result(succeeded, fh.get_held(), Error)\n        elif not want_result:\n            result = Result(succeeded, None, Error)\n            fh.output()\n    return result", "response": "Terminal function that returns a named tuple containing the command and arguments."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create(self, **kwargs):\n        self._check_create_parameters(**kwargs)\n        if kwargs['extractFromAllItems'] is False:\n            self._meta_data['minimum_additional_parameters'] = {\n                'extractFromRegularExpression', 'extractUrlReferences',\n                'extractFiletypeReferences'\n            }\n        return self._create(**kwargs)", "response": "Custom create method to accommodate different endpoint behavior."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _create(self, **kwargs):\n        if 'uri' in self._meta_data:\n            error = \"There was an attempt to assign a new uri to this \"\\\n                    \"resource, the _meta_data['uri'] is %s and it should\"\\\n                    \" not be changed.\" % (self._meta_data['uri'])\n            raise URICreationCollision(error)\n        self._check_exclusive_parameters(**kwargs)\n        requests_params = self._handle_requests_params(kwargs)\n        self._minimum_one_is_missing(**kwargs)\n        self._check_create_parameters(**kwargs)\n        kwargs = self._check_for_python_keywords(kwargs)\n\n        # Reduce boolean pairs as specified by the meta_data entry below\n        for key1, key2 in self._meta_data['reduction_forcing_pairs']:\n            kwargs = self._reduce_boolean_pair(kwargs, key1, key2)\n\n        # Make convenience variable with short names for this method.\n        _create_uri = self._meta_data['container']._meta_data['uri']\n        session = self._meta_data['bigip']._meta_data['icr_session']\n\n        kwargs = self._prepare_request_json(kwargs)\n\n        # Invoke the REST operation on the device.\n        response = session.post(_create_uri, json=kwargs, **requests_params)\n\n        # Make new instance of self\n        result = self._produce_instance(response)\n        return result", "response": "wrapped by create override that by customize"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\noverride method for one in resource. py to check partition", "response": "def _check_load_parameters(self, **kwargs):\n        \"\"\"Override method for one in resource.py to check partition\n\n        The partition cannot be included as a parameter to load a guest.\n        Raise an exception if a consumer gives the partition parameter.\n\n        :raises: DisallowedReadParameter\n        \"\"\"\n\n        if 'partition' in kwargs:\n            msg = \"'partition' is not allowed as a load parameter. Vcmp \" \\\n                \"guests are accessed by name.\"\n            raise DisallowedReadParameter(msg)\n        super(Guest, self)._check_load_parameters(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\noverrides method for one in resource. py to check partition", "response": "def _check_create_parameters(self, **kwargs):\n        \"\"\"Override method for one in resource.py to check partition\n\n        The partition cannot be included as a parameter to create a guest.\n        Raise an exception if a consumer gives the partition parameter.\n\n        :raises: DisallowedCreationParameter\n        \"\"\"\n\n        if 'partition' in kwargs:\n            msg = \"'partition' is not allowed as a create parameter. Vcmp \" \\\n                \"guests are created with the 'name' at least.\"\n            raise DisallowedCreationParameter(msg)\n        super(Guest, self)._check_create_parameters(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a vcmp fixture", "response": "def vcmp_host(opt_vcmp_host, opt_username, opt_password, opt_port):\n    '''vcmp fixture'''\n    m = ManagementRoot(\n        opt_vcmp_host, opt_username, opt_password, port=opt_port)\n    return m"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if a record exists.", "response": "def exists(self, **kwargs):\n        \"\"\"Providing a partition is not necessary on topology; causes errors\"\"\"\n        kwargs.pop('partition', None)\n        kwargs['transform_name'] = True\n        return self._exists(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update(self, **kwargs):\n        self.__dict__.pop('tmCommand', '')\n        self.__dict__.pop('agent', '')\n        self.__dict__.pop('method', '')\n        super(Real_Server, self).update(**kwargs)", "response": "Update the configuration of the resource on the device."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate the configuration of the resource on the device.", "response": "def update(self, **kwargs):\n        \"\"\"Change the configuration of the resource on the device.\n\n        This method uses Http PUT alter the service state on the device.\n\n        The attributes of the instance will be packaged as a dictionary.  That\n        dictionary will be updated with kwargs.  It is then submitted as JSON\n        to the device.  Various edge cases are handled:\n\n        * read-only attributes that are unchangeable are removed\n        * ``agent`` attribute removed prior to PUT\n        * ``post`` attribute removed prior to PUT\n        * ``method`` attribute removed prior to PUT\n\n        :param kwargs: keys and associated values to alter on the device\n\n        \"\"\"\n        self.__dict__.pop('agent', '')\n        self.__dict__.pop('post', '')\n        self.__dict__.pop('method', '')\n        super(Wmi, self).update(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreplacing fullstops in returned keynames", "response": "def _key_dot_replace(self, rdict):\n        \"\"\"Replace fullstops in returned keynames\"\"\"\n        temp_dict = {}\n        for key, value in iteritems(rdict):\n            if isinstance(value, dict):\n                value = self._key_dot_replace(value)\n            temp_dict[key.replace('.', '_')] = value\n        return temp_dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrefresh stats attached to an object", "response": "def refresh(self, **kwargs):\n        \"\"\"Refreshes stats attached to an object\"\"\"\n        self.resource.refresh(**kwargs)\n        self.rdict = self.resource.entries\n        self._update_stats()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the rule with the new values.", "response": "def update(self, **kwargs):\n        \"\"\"We need to implement the custom exclusive parameter check.\"\"\"\n        self._check_exclusive_parameters(**kwargs)\n        return super(Rule, self)._update(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\noverrides the default modify method to implement custom exclusive parameter check.", "response": "def modify(self, **kwargs):\n        \"\"\"We need to implement the custom exclusive parameter check.\"\"\"\n        self._check_exclusive_parameters(**kwargs)\n        return super(Rule, self)._modify(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _load_11_6(self, **kwargs):\n        if self._check_existence_by_collection(self._meta_data['container'],\n                                               kwargs['name']):\n            return super(Rule, self)._load(**kwargs)\n        msg = 'The application resource named, {}, does not exist on the ' \\\n              'device.'.format(kwargs['name'])\n        raise NonExtantFirewallRule(msg)", "response": "Load the application resource."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npoll with a given callable for a specified number of times.", "response": "def poll_for_exceptionless_callable(callable, attempts, interval):\n    '''Poll with a given callable for a specified number of times.\n\n    :param callable: callable to invoke in loop -- if no exception is raised\n                    the call is considered succeeded\n    :param attempts: number of iterations to attempt\n    :param interval: seconds to wait before next attempt\n    '''\n\n    @wraps(callable)\n    def poll(*args, **kwargs):\n        for attempt in range(attempts):\n            try:\n                return callable(*args, **kwargs)\n            except Exception as ex:\n                if attempt == attempts-1:\n                    raise MaximumAttemptsReached(ex)\n                time.sleep(interval)\n                continue\n    return poll"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexiting the runtime cleanly.", "response": "def exit_cleanly(errnum=None):\n    \"\"\"exit_cleanly\n\nExits the runtime cleanly using SystemExit.  This is the official, handling\nexception here as this is mostly meant to be a standalone script.\n    \"\"\"\n    default = \"An Unknown Error has Occurred!\"\n    cases = {errno.EINVAL: \"Improper or invalid input value\",\n             errno.ESPIPE: \"Could not complete action due to a broken\" +\n             \" dependency\",\n             errno.ENOSYS: \"Could not complete action due to unexpected setup\",\n             errno.EIO: \"Could not access an expected file\",\n             errno.EPERM: \"Could not access an item due to permissions issues\",\n             -1: default}\n    help_stmt = \"\"\"\n%s [--opt [option]]\n    With opts:\n        working_directory - ONLY use this if you're overwriting `pwd`!\n    \"\"\" % (sys.argv[0])\n    if not errnum:\n        errnum = 0\n    elif not isinstance(errnum, int) and hasattr(errno, errnum):\n        errnum = getattr(errno, errnum)\n    try:\n        errnum = int(errnum)\n    except TypeError:\n        errnum = -1\n    if errnum == 0:\n        help_stmt = ''\n        stmt = \"Successful in configuration!\"\n    elif errnum in cases:\n        stmt = cases[errnum]\n    else:\n        stmt = default\n    print(\"%s\\n\\n%s\" % (stmt, help_stmt))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_env(working_directory=None):\n    working = working_directory if working_directory else os.getcwd()\n    dist_dirs = glob.glob(working + \"/f5-*-dist\")\n    print(dist_dirs)\n    dist_dir_re = re.compile('/([^/]+)-dist/?')\n    if dist_dirs:\n        dist_dir = dist_dirs[0]\n        match = dist_dir_re.search(dist_dir)\n        if match:\n            project_name = match.group(1)\n        else:\n            print(\"Unrecognized run location:\\n\" + working)\n            exit_cleanly(errnum=errno.EIO)\n    elif '-dist/scripts' in working:\n        match = dist_dir_re.search(working)\n        if match:\n            project_name = match.group(1)\n    else:\n        print(\"Unable to determine the *-dist directory from \" + working)\n        exit_cleanly(errnum=errno.ENOSYS)\n    stdeb_cfg = dist_dir + \"/deb_dist/stdeb.cfg\"\n    setup_cfg = working + \"/setup.cfg\"\n    stp_reqs = working + \"/setup_requirements.txt\"\n    scripts = dist_dir + \"/scripts\"\n    env = {'working': working, 'dist_dir': dist_dir, 'stdeb_cfg': stdeb_cfg,\n           'setup_requirements': stp_reqs, 'setup_cfg': setup_cfg,\n           'scripts': scripts, 'project': project_name}\n    return env", "response": "This function grabs the environment variables for the the\nconfig. JSON file and assigns them to the environment variables."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef export_to_json(env):\n    json_fl = env['scripts'] + \"/config.JSON\"\n    with open(json_fl, 'w') as fh:\n        fh.write(json.dumps(env, sort_keys=True, indent=4,\n                            separators=(',', ': ')))", "response": "export_to_json\nThis function takes in a dictionary and stores it within the config. JSON\nfile."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_config(filename):\n    config = None\n    if os.path.isfile(filename) and os.access(filename, os.R_OK):\n        with open(filename, 'r') as fh:\n            config = json.loads(fh.read())\n    return config", "response": "Load the configuration from a file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef exists(self, **kwargs):\n\n        if LooseVersion(self.tmos_ver) == LooseVersion('11.6.0'):\n            return self._exists_11_6(**kwargs)\n        else:\n            return super(Network, self)._exists(**kwargs)", "response": "Check if the object exists in the database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading the application resource.", "response": "def _load_11_6(self, **kwargs):\n        \"\"\"Must check if rule actually exists before proceeding with load.\"\"\"\n        if self._check_existence_by_collection(self._meta_data['container'], kwargs['name']):\n            return super(Protocol_Sip, self)._load(**kwargs)\n        msg = 'The application resource named, {}, does not exist on the device.'.format(kwargs['name'])\n        resp = Response()\n        resp.status_code = 404\n        ex = HTTPError(msg, response=resp)\n        raise ex"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload the config. JSON file system object s contents and translate it into a Python object.", "response": "def load_json():\n    \"\"\"load_json\n\nLoads the config.JSON file system object's contents and translate it into a\nPython object.  This python object is then returned.\n    \"\"\"\n    try:\n        env = configure.get_env()\n        configure.export_to_json(env)\n    except SystemExit:\n        raise BuildError(msg=\"configure failed!  Could not build targets!\",\n                         frame=gfi(cf()), errno=errno.ENOSYS)\n    json_fl = os.path.dirname(sys.argv[0]) + \"/scripts/config.JSON\"\n    data = _load_json(json_fl)\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef build_debian(config, os_versions, os_type='ubuntu'):\n    def build_pkg(config, os_type, os_version):\n        result = _build_package(config, os_type, os_version)\n        if not result.succeeded:\n            print(result.cli)\n            raise DebianError(result, os_type, os_version, frame=gfi(cf()))\n\n    error = 0\n    if isinstance(os_versions, str):\n        os_version = os_versions\n        try:\n            build_pkg(config, os_type, os_version)\n        except DebianError as error:\n            error.print_msg()\n    else:\n        for os_version in os_versions:\n            try:\n                build_pkg(config, os_type, os_version)\n            except DebianError as error:\n                error.print_msg()\n    return error", "response": "build_debian\n\nBuilds for a specific debian operating system with os version\nspecified."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build_packages(config):\n    error = 0\n    print(\"Building packages...\")\n    for operation in expected_operations:\n        if operation.os_category == 'redhat':\n            print(\"For Redhat...\")\n            function = build_redhat\n        elif operation.os_category == 'debian':\n            print(\"For Debian...\")\n            function = build_debian\n        else:\n            # can overwrite a previous error statement, but this does need to\n            # be preserved...\n            error = BuildError(operation, msg=\"Unexpected operation specified\",\n                               frame=gfi(cf()))\n            function = Error.print_msg\n        # preserve a previous iteration's error, if needed\n        for os_version in operation.versions:\n            error = function(config, os_version) if not error else error\n            if error:\n                break\n        if error:\n            print(\"A Failure occurred...\", str(error))\n            break\n    if not error:\n        print(\"Completed package builds...\")\n    return error", "response": "Build the packages for the expected_operations OperationSettings entries."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef store_json(obj, destination):\n    with open(destination, 'r+') as FH:\n        fcntl.lockf(FH, fcntl.LOCK_EX)\n        json_in = json.loads(FH.read())\n        json_in.update(obj)  # obj overwrites items in json_in...\n        FH.seek(0)\n        FH.write(json.dumps(json_in, sort_keys=True, indent=4,\n                            separators=(',', ': ')))", "response": "Stores a json - portable object into a filesystem - based destination."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if the given command is allowed on a given endpoint.", "response": "def _is_allowed_command(self, command):\n        \"\"\"Checking if the given command is allowed on a given endpoint.\"\"\"\n        cmds = self._meta_data['allowed_commands']\n        if command not in self._meta_data['allowed_commands']:\n            error_message = \"The command value {0} does not exist. \" \\\n                            \"Valid commands are {1}\".format(command, cmds)\n            raise InvalidCommand(error_message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _check_command_result(self):\n        if self.commandResult.startswith('/bin/bash'):\n            raise UtilError('%s' % self.commandResult.split(' ', 1)[1])\n        if self.commandResult.startswith('/bin/mv'):\n            raise UtilError('%s' % self.commandResult.split(' ', 1)[1])\n        if self.commandResult.startswith('/bin/ls'):\n            raise UtilError('%s' % self.commandResult.split(' ', 1)[1])\n        if self.commandResult.startswith('/bin/rm'):\n            raise UtilError('%s' % self.commandResult.split(' ', 1)[1])\n        if 'invalid option' in self.commandResult:\n            raise UtilError('%s' % self.commandResult)\n        if 'Invalid option' in self.commandResult:\n            raise UtilError('%s' % self.commandResult)\n        if 'usage: /usr/bin/get_dossier' in self.commandResult:\n            raise UtilError('%s' % self.commandResult)", "response": "Check if command result exists run these checks."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef exec_cmd(self, command, **kwargs):\n        self._is_allowed_command(command)\n        self._check_command_parameters(**kwargs)\n        return self._exec_cmd(command, **kwargs)", "response": "Wrapper method that can be changed in the inheriting classes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new method as command has specific requirements.", "response": "def _exec_cmd(self, command, **kwargs):\n        \"\"\"Create a new method as command has specific requirements.\n\n        There is a handful of the TMSH global commands supported,\n        so this method requires them as a parameter.\n\n        :raises: InvalidCommand\n        \"\"\"\n\n        kwargs['command'] = command\n        self._check_exclusive_parameters(**kwargs)\n        requests_params = self._handle_requests_params(kwargs)\n        session = self._meta_data['bigip']._meta_data['icr_session']\n        response = session.post(\n            self._meta_data['uri'], json=kwargs, **requests_params)\n        new_instance = self._stamp_out_core()\n        new_instance._local_update(response.json())\n        if 'commandResult' in new_instance.__dict__:\n            new_instance._check_command_result()\n\n        return new_instance"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget device information about a specific BigIP device.", "response": "def get_device_info(self, bigip):\n        '''Get device information about a specific BigIP device.\n\n        :param bigip: bigip object --- device to inspect\n        :returns: bigip object\n        '''\n\n        coll = bigip.tm.cm.devices.get_collection()\n        device = [device for device in coll if device.selfDevice == 'true']\n        assert len(device) == 1\n        return device[0]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _check_existence_by_collection(self, container, item_name):\n        '''Check existnce of item based on get collection call.\n\n        :param collection: container object -- capable of get_collection()\n        :param item_name: str -- name of item to search for in collection\n        '''\n\n        coll = container.get_collection()\n        for item in coll:\n            if item.name == item_name:\n                return True\n        return False", "response": "Check if the item exists in the collection"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _return_object(self, container, item_name):\n        coll = container.get_collection()\n        for item in coll:\n            if item.name == item_name:\n                return item", "response": "Helper method to retrieve the object from the container"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexecutes a command on the local cache", "response": "def exec_cmd(self, command, **kwargs):\n        \"\"\"Normal save and load only need the command.\n\n        To merge, just supply the merge and file arguments as kwargs like so:\n        exec_cmd('load', merge=True, file='/path/to/file.txt')\n        \"\"\"\n\n        if command == 'load':\n            if kwargs:\n                kwargs = dict(options=[kwargs])\n        return self._exec_cmd(command, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update(self, **kwargs):\n        tmos_version = self._meta_data['bigip'].tmos_version\n        if LooseVersion(tmos_version) > LooseVersion('12.0.0'):\n            msg = \"Update() is unsupported for User on version %s. \" \\\n                  \"Utilize Modify() method instead\" % tmos_version\n            raise UnsupportedOperation(msg)\n        else:\n            self._update(**kwargs)", "response": "Update the object with the new data."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _process_config_with_kind(self, raw_conf):\n        '''Use this to decide which format is called for by the kind.\n\n        NOTE, order matters since subsequent conditions are not evaluated is an\n        earlier condition is met.  In the some cases, e.g. a kind contains both\n        \"stats\" and \"state\", this will become an issue.\n        '''\n        kind = raw_conf[u\"kind\"]\n        org_match = re.match(self.OC_pattern, kind)\n        if org_match:\n            return self._format_org_collection(org_match, kind, raw_conf)\n        elif 'collectionstate' in kind:\n            return self._format_collection(kind, raw_conf)\n        elif kind.endswith('stats'):\n            return self._format_stats(kind, raw_conf)\n        elif kind.endswith('state'):\n            return self._format_resource(kind, raw_conf)", "response": "Process the raw configuration dictionary with the kind."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _missing_required_parameters(rqset, **kwargs):\n    key_set = set(list(iterkeys(kwargs)))\n    required_minus_received = rqset - key_set\n    if required_minus_received != set():\n        return list(required_minus_received)", "response": "Helper function to do operations on sets.\n    Returns non - empty list if any missing parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _format_collection_name(self):\n        base_uri = self._format_resource_name()\n        if base_uri[-2:] == '_s':\n            endind = 2\n        else:\n            endind = 1\n        return base_uri[:-endind]", "response": "Formats a name from Collection"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking that the parameters given to exec_cmd satisfy required params.", "response": "def _check_command_parameters(self, **kwargs):\n        \"\"\"Params given to exec_cmd should satisfy required params.\n\n        :params: kwargs\n        :raises: MissingRequiredCommandParameter\n        \"\"\"\n        rset = self._meta_data['required_command_parameters']\n        check = _missing_required_parameters(rset, **kwargs)\n        if check:\n            error_message = 'Missing required params: %s' % check\n            raise MissingRequiredCommandParameter(error_message)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _check_generation(self):\n        session = self._meta_data['bigip']._meta_data['icr_session']\n        response = session.get(self._meta_data['uri'])\n        current_gen = response.json().get('generation', None)\n        if current_gen is not None and current_gen != self.generation:\n            error_message = (\"The generation of the object on the BigIP \"\n                             + \"(\" + str(current_gen) + \")\"\n                             + \" does not match the current object\"\n                             + \"(\" + str(self.generation) + \")\")\n            raise GenerationMismatch(error_message)", "response": "Check that the generation of the object currently has matches the current object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _handle_requests_params(self, kwargs):\n        requests_params = kwargs.pop('requests_params', {})\n        for param in requests_params:\n            if param in kwargs:\n                error_message = 'Requests Parameter %r collides with a load'\\\n                    ' parameter of the same name.' % param\n                raise RequestParamKwargCollision(error_message)\n        # If we have an icontrol version we need to add 'ver' to params\n        if self._meta_data['icontrol_version']:\n            params = requests_params.pop('params', {})\n            params.update({'ver': self._meta_data['icontrol_version']})\n            requests_params.update({'params': params})\n        return requests_params", "response": "Validate the parameters that will be passed to the requests verbs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if mutually exclusive attributes are present in kwargs. Raises ExclusiveAttributesPresent", "response": "def _check_exclusive_parameters(self, **kwargs):\n        \"\"\"Check for mutually exclusive attributes in kwargs.\n\n        :raises ExclusiveAttributesPresent\n        \"\"\"\n        if len(self._meta_data['exclusive_attributes']) > 0:\n            attr_set = set(list(iterkeys(kwargs)))\n            ex_set = set(self._meta_data['exclusive_attributes'][0])\n            common_set = sorted(attr_set.intersection(ex_set))\n            if len(common_set) > 1:\n                cset = ', '.join(common_set)\n                error = 'Mutually exclusive arguments submitted. ' \\\n                        'The following arguments cannot be set ' \\\n                        'together: \"%s\".' % cset\n                raise ExclusiveAttributesPresent(error)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwraps with modify override in a subclass to customize.", "response": "def _modify(self, **patch):\n        \"\"\"Wrapped with modify, override in a subclass to customize.\"\"\"\n\n        requests_params, patch_uri, session, read_only = \\\n            self._prepare_put_or_patch(patch)\n        self._check_for_boolean_pair_reduction(patch)\n        read_only_mutations = []\n        for attr in read_only:\n            if attr in patch:\n                read_only_mutations.append(attr)\n        if read_only_mutations:\n            msg = 'Attempted to mutate read-only attribute(s): %s' \\\n                % read_only_mutations\n            raise AttemptedMutationOfReadOnly(msg)\n\n        patch = self._prepare_request_json(patch)\n        response = session.patch(patch_uri, json=patch, **requests_params)\n        self._local_update(response.json())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _check_for_boolean_pair_reduction(self, kwargs):\n\n        if 'reduction_forcing_pairs' in self._meta_data:\n            for key1, key2 in self._meta_data['reduction_forcing_pairs']:\n                kwargs = self._reduce_boolean_pair(kwargs, key1, key2)\n        return kwargs", "response": "Check if boolean pairs should be reduced in this resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _prepare_put_or_patch(self, kwargs):\n\n        requests_params = self._handle_requests_params(kwargs)\n        update_uri = self._meta_data['uri']\n        session = self._meta_data['bigip']._meta_data['icr_session']\n        read_only = self._meta_data.get('read_only_attributes', [])\n        return requests_params, update_uri, session, read_only", "response": "Retrieve the appropriate request items for put or patch calls."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _prepare_request_json(self, kwargs):\n\n        # Check for python keywords in dict\n        kwargs = self._check_for_python_keywords(kwargs)\n\n        # Check for the key 'check' in kwargs\n        if 'check' in kwargs:\n            od = OrderedDict()\n            od['check'] = kwargs['check']\n            kwargs.pop('check')\n            od.update(kwargs)\n            return od\n        return kwargs", "response": "Prepare request args for sending to device as JSON."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _iter_list_for_dicts(self, check_list):\n\n        list_copy = copy.deepcopy(check_list)\n        for index, elem in enumerate(check_list):\n            if isinstance(elem, dict):\n                list_copy[index] = self._check_for_python_keywords(elem)\n            elif isinstance(elem, list):\n                list_copy[index] = self._iter_list_for_dicts(elem)\n            else:\n                list_copy[index] = elem\n        return list_copy", "response": "Iterate over list to find dicts and check for python keywords."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _check_for_python_keywords(self, kwargs):\n\n        kwargs_copy = copy.deepcopy(kwargs)\n        for key, val in iteritems(kwargs):\n            if isinstance(val, dict):\n                kwargs_copy[key] = self._check_for_python_keywords(val)\n            elif isinstance(val, list):\n                kwargs_copy[key] = self._iter_list_for_dicts(val)\n            else:\n                if key.endswith('_'):\n                    strip_key = key.rstrip('_')\n                    if keyword.iskeyword(strip_key):\n                        kwargs_copy[strip_key] = val\n                        kwargs_copy.pop(key)\n        return kwargs_copy", "response": "When Python keywords seen mutate to remove trailing underscore."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if the keys in the response are not public.", "response": "def _check_keys(self, rdict):\n        \"\"\"Call this from _local_update to validate response keys\n\n        disallowed server-response json keys:\n        1. The string-literal '_meta_data'\n        2. strings that are not valid Python 2.7 identifiers\n        3. strings beginning with '__'.\n\n        :param rdict: from response.json()\n        :raises: DeviceProvidesIncompatibleKey\n        :returns: checked response rdict\n        \"\"\"\n        if '_meta_data' in rdict:\n            error_message = \"Response contains key '_meta_data' which is \"\\\n                \"incompatible with this API!!\\n Response json: %r\" % rdict\n            raise DeviceProvidesIncompatibleKey(error_message)\n        for x in rdict:\n            if not re.match(tokenize.Name, x):\n                error_message = \"Device provided %r which is disallowed\"\\\n                    \" because it's not a valid Python 2.7 identifier.\" % x\n                raise DeviceProvidesIncompatibleKey(error_message)\n            elif keyword.iskeyword(x):\n                # If attribute is keyword, append underscore to attribute name\n                rdict[x + '_'] = rdict[x]\n                rdict.pop(x)\n            elif x.startswith('__'):\n                error_message = \"Device provided %r which is disallowed\"\\\n                    \", it mangles into a Python non-public attribute.\" % x\n                raise DeviceProvidesIncompatibleKey(error_message)\n        return rdict"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _local_update(self, rdict):\n        sanitized = self._check_keys(rdict)\n        temp_meta = self._meta_data\n        self.__dict__ = sanitized\n        self._meta_data = temp_meta", "response": "Call this with a response dictionary to update instance attrs."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _update(self, **kwargs):\n\n        requests_params, update_uri, session, read_only = \\\n            self._prepare_put_or_patch(kwargs)\n\n        read_only_mutations = []\n        for attr in read_only:\n            if attr in kwargs:\n                read_only_mutations.append(attr)\n        if read_only_mutations:\n            msg = 'Attempted to mutate read-only attribute(s): %s' \\\n                  % read_only_mutations\n            raise AttemptedMutationOfReadOnly(msg)\n\n        # Get the current state of the object on BIG-IP\u00ae and check the\n        # generation Use pop here because we don't want force in the data_dict\n        force = self._check_force_arg(kwargs.pop('force', True))\n        if not force:\n            # generation has a known server-side error\n            self._check_generation()\n\n        kwargs = self._check_for_boolean_pair_reduction(kwargs)\n\n        # Save the meta data so we can add it back into self after we\n        # load the new object.\n        temp_meta = self.__dict__.pop('_meta_data')\n\n        # Need to remove any of the Collection objects from self.__dict__\n        # because these are subCollections and _meta_data and\n        # other non-BIG-IP\u00ae attrs are not removed from the subCollections\n        # See issue #146 for details\n        tmp = dict()\n        for key, value in iteritems(self.__dict__):\n            # In Python2 versions we were changing a dictionary in place,\n            # but this cannot be done with an iterator as an error is raised.\n            # So instead we create a temporary holder for the modified dict\n            # and then re-assign it afterwards.\n            if isinstance(value, Collection):\n                pass\n            else:\n                tmp[key] = value\n        self.__dict__ = tmp\n        data_dict = self.to_dict()\n\n        # Remove any read-only attributes from our data_dict before we update\n        # the data dict with the attributes.  If they pass in read-only attrs\n        # in the method call we are going to let BIG-IP\u00ae let them know about it\n        # when it fails\n        for attr in read_only:\n            data_dict.pop(attr, '')\n\n        data_dict.update(kwargs)\n        data_dict = self._prepare_request_json(data_dict)\n\n        # Handles ConnectionAborted errors\n        #\n        # @see https://github.com/F5Networks/f5-ansible/issues/317\n        # @see https://github.com/requests/requests/issues/2364\n        for _ in range(0, 30):\n            try:\n                response = session.put(update_uri, json=data_dict, **requests_params)\n                self._meta_data = temp_meta\n                self._local_update(response.json())\n                break\n            except iControlUnexpectedHTTPError:\n                response = session.get(update_uri, **requests_params)\n                self._meta_data = temp_meta\n                self._local_update(response.json())\n                raise\n            except ConnectionError as ex:\n                if 'Connection aborted' in str(ex):\n                    time.sleep(1)\n                    continue\n                else:\n                    raise", "response": "wrapped with update override that in a subclass to customize"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _refresh(self, **kwargs):\n        requests_params = self._handle_requests_params(kwargs)\n        refresh_session = self._meta_data['bigip']._meta_data['icr_session']\n\n        if self._meta_data['uri'].endswith('/stats/'):\n            # Slicing off the trailing slash here for Stats enpoints because\n            # iWorkflow doesn't consider those `stats` URLs valid if they\n            # include the trailing slash.\n            #\n            # Other than that, functionality does not change\n            uri = self._meta_data['uri'][0:-1]\n        else:\n            uri = self._meta_data['uri']\n\n        response = refresh_session.get(uri, **requests_params)\n        self._local_update(response.json())", "response": "wrapped by refresh override that in a subclass to customize"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _produce_instance(self, response):\n        '''Generate a new self, which is an instance of the self.'''\n        new_instance = self._stamp_out_core()\n        # Post-process the response\n        new_instance._local_update(response.json())\n\n        # Allow for example files, which are KindTypeMismatches\n        if hasattr(new_instance, 'selfLink'):\n            if new_instance.kind != new_instance._meta_data[\n                'required_json_kind'] \\\n                    and new_instance.kind != \"tm:transaction:commandsstate\" \\\n                    and 'example' not in new_instance.selfLink.split('/')[-1]:\n                error_message = \"For instances of type '%r' the corresponding\" \\\n                                \" kind must be '%r' but creation returned JSON with kind: %r\" \\\n                                % (new_instance.__class__.__name__,\n                                   new_instance._meta_data[\n                                       'required_json_kind'],\n                                   new_instance.kind)\n                raise KindTypeMismatch(error_message)\n        else:\n            if new_instance.kind != new_instance._meta_data[\n                'required_json_kind'] \\\n                    and new_instance.kind != \"tm:transaction:commandsstate\":\n                error_message = \"For instances of type '%r' the corresponding\" \\\n                                \" kind must be '%r' but creation returned JSON with kind: %r\" \\\n                                % (new_instance.__class__.__name__,\n                                   new_instance._meta_data[\n                                       'required_json_kind'],\n                                   new_instance.kind)\n                raise KindTypeMismatch(error_message)\n\n        # Update the object to have the correct functional uri.\n        new_instance._activate_URI(new_instance.selfLink)\n        return new_instance", "response": "Generate a new self which is an instance of the self."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _reduce_boolean_pair(self, config_dict, key1, key2):\n\n        if key1 in config_dict and key2 in config_dict \\\n                and config_dict[key1] == config_dict[key2]:\n            msg = 'Boolean pair, %s and %s, have same value: %s. If both ' \\\n                'are given to this method, they cannot be the same, as this ' \\\n                'method cannot decide which one should be True.' \\\n                % (key1, key2, config_dict[key1])\n            raise BooleansToReduceHaveSameValue(msg)\n        elif key1 in config_dict and not config_dict[key1]:\n            config_dict[key2] = True\n            config_dict.pop(key1)\n        elif key2 in config_dict and not config_dict[key2]:\n            config_dict[key1] = True\n            config_dict.pop(key2)\n        return config_dict", "response": "Reduce the boolean value of a key with a boolean value."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_collection(self, **kwargs):\n        list_of_contents = []\n        self.refresh(**kwargs)\n        if 'items' in self.__dict__:\n            for item in self.items:\n                # It's possible to have non-\"kind\" JSON returned. We just\n                # append the corresponding dict. PostProcessing is the caller's\n                # responsibility.\n                if 'kind' not in item:\n                    list_of_contents.append(item)\n                    continue\n                kind = item['kind']\n                if kind in self._meta_data['attribute_registry']:\n                    # If it has a kind, it must be registered.\n                    instance = self._meta_data['attribute_registry'][kind](self)\n                    instance._local_update(item)\n                    instance._activate_URI(instance.selfLink)\n                    list_of_contents.append(instance)\n                else:\n                    error_message = '%r is not registered!' % kind\n                    raise UnregisteredKind(error_message)\n        return list_of_contents", "response": "Get an iterator of Pythonic Resource objects that represent URIs."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _delete_collection(self, **kwargs):\n        error_message = \"The request must include \\\"requests_params\\\": {\\\"params\\\": \\\"options=<glob pattern>\\\"} as kwarg\"\n        try:\n            if kwargs['requests_params']['params'].split('=')[0] != 'options':\n                raise MissingRequiredRequestsParameter(error_message)\n        except KeyError:\n            raise\n\n        requests_params = self._handle_requests_params(kwargs)\n        delete_uri = self._meta_data['uri']\n        session = self._meta_data['bigip']._meta_data['icr_session']\n\n        session.delete(delete_uri, **requests_params)", "response": "wrapped with delete_collection override that in a sublcass to customize"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nactivate the new URI in the cache.", "response": "def _activate_URI(self, selfLinkuri):\n        \"\"\"Call this with a selfLink, after it's returned in _create or _load.\n\n        Each instance is tightly bound to a particular service URI.  When that\n        service is created by this library, or loaded from the device, the URI\n        is set to self._meta_data['uri'].   This operation can only occur once,\n        any subsequent attempt to manipulate self._meta_data['uri'] is\n        probably a mistake.\n\n        self.selfLink references a value that is returned as a JSON value from\n        the device.  This value contains \"localhost\" as the domain or the uri.\n        \"localhost\" is only conceivably useful if the client library is run on\n        the device itself, so it is replaced with the domain this API used to\n        communicate with the device.\n\n        self.selfLink correctly contains a complete uri, that is only _now_\n        (post create or load) available to self.\n\n        Now that the complete URI is available to self, it is now possible to\n        reference subcollections, as attributes of self!\n        e.g. a resource with a uri path like:\n        \"/mgmt/tm/ltm/pool/~Common~pool_collection1/members\"\n        The mechanism used to enable this change is to set\n        the `allowed_lazy_attributes` _meta_data key to hold values of the\n        `attribute_registry` _meta_data key.\n\n        Finally we stash the corrected `uri`, returned hash_fragment, query\n        args, and of course allowed_lazy_attributes in _meta_data.\n\n        :param selfLinkuri: the server provided selfLink (contains localhost)\n        :raises: URICreationCollision\n        \"\"\"\n\n        # netloc local alias\n        uri = urlparse.urlsplit(str(self._meta_data['bigip']._meta_data['uri']))\n\n        # attrs local alias\n        attribute_reg = self._meta_data.get('attribute_registry', {})\n        attrs = list(itervalues(attribute_reg))\n        attrs = self._assign_stats(attrs)\n\n        (scheme, domain, path, qarg, frag) = urlparse.urlsplit(selfLinkuri)\n        path_uri = urlparse.urlunsplit((scheme, uri.netloc, path, '', ''))\n        if not path_uri.endswith('/'):\n            path_uri = path_uri + '/'\n        qargs = urlparse.parse_qs(qarg)\n        self._meta_data.update({'uri': path_uri,\n                                'creation_uri_qargs': qargs,\n                                'creation_uri_frag': frag,\n                                'allowed_lazy_attributes': attrs})"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks that the params given to create are satisfy required params.", "response": "def _check_create_parameters(self, **kwargs):\n        \"\"\"Params given to create should satisfy required params.\n\n        :params: kwargs\n        :raises: MissingRequiredCreateParameter\n        \"\"\"\n        rset = self._meta_data['required_creation_parameters']\n        check = _missing_required_parameters(rset, **kwargs)\n        if check:\n            error_message = 'Missing required params: %s' % check\n            raise MissingRequiredCreationParameter(error_message)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _minimum_one_is_missing(self, **kwargs):\n        rqset = self._meta_data['minimum_additional_parameters']\n        if rqset:\n            kwarg_set = set(iterkeys(kwargs))\n            if kwarg_set.isdisjoint(rqset):\n                args = sorted(rqset)\n                error_message = 'This resource requires at least one of the ' \\\n                                'mandatory additional ' \\\n                                'parameters to be provided: %s' % ', '.join(args)\n                raise MissingRequiredCreationParameter(error_message)", "response": "Helper function to verify if at least one of the elements\n        is present in kwargs."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking that the required parameters are present in the load.", "response": "def _check_load_parameters(self, **kwargs):\n        \"\"\"Params given to load should at least satisfy required params.\n\n        :params: kwargs\n        :raises: MissingRequiredReadParameter\n        \"\"\"\n        rset = self._meta_data['required_load_parameters']\n        check = _missing_required_parameters(rset, **kwargs)\n        if check:\n            check.sort()\n            error_message = 'Missing required params: %s' % check\n            raise MissingRequiredReadParameter(error_message)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _load(self, **kwargs):\n        if 'uri' in self._meta_data:\n            error = \"There was an attempt to assign a new uri to this \"\\\n                    \"resource, the _meta_data['uri'] is %s and it should\"\\\n                    \" not be changed.\" % (self._meta_data['uri'])\n            raise URICreationCollision(error)\n        requests_params = self._handle_requests_params(kwargs)\n        self._check_load_parameters(**kwargs)\n        kwargs['uri_as_parts'] = True\n        refresh_session = self._meta_data['bigip']._meta_data['icr_session']\n        base_uri = self._meta_data['container']._meta_data['uri']\n        kwargs.update(requests_params)\n        for key1, key2 in self._meta_data['reduction_forcing_pairs']:\n            kwargs = self._reduce_boolean_pair(kwargs, key1, key2)\n        kwargs = self._check_for_python_keywords(kwargs)\n        response = refresh_session.get(base_uri, **kwargs)\n        # Make new instance of self\n        return self._produce_instance(response)", "response": "wrapped with load override that in a subclass to customize"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _delete(self, **kwargs):\n        requests_params = self._handle_requests_params(kwargs)\n\n        delete_uri = self._meta_data['uri']\n        session = self._meta_data['bigip']._meta_data['icr_session']\n\n        # Check the generation for match before delete\n        force = self._check_force_arg(kwargs.pop('force', True))\n        if not force:\n            self._check_generation()\n\n        response = session.delete(delete_uri, **requests_params)\n        if response.status_code == 200:\n            self.__dict__ = {'deleted': True}", "response": "wrapped with delete override that in a subclass to customize"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _delete(self, **kwargs):\n        requests_params = self._handle_requests_params(kwargs)\n\n        delete_uri = self._meta_data['uri']\n        session = self._meta_data['bigip']._meta_data['icr_session']\n        response = session.delete(delete_uri, **requests_params)\n        if response.status_code == 200 or 201:\n            self.__dict__ = {'deleted': True}", "response": "Wrapped with delete override that in a subclass to customize"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwrapping by fetch override that by customize", "response": "def _fetch(self):\n        \"\"\"wrapped by `fetch` override that in subclasses to customize\"\"\"\n        if 'uri' in self._meta_data:\n            error = \"There was an attempt to assign a new uri to this \"\\\n                    \"resource, the _meta_data['uri'] is %s and it should\"\\\n                    \" not be changed.\" % (self._meta_data['uri'])\n            raise URICreationCollision(error)\n        # Make convenience variable with short names for this method.\n        _create_uri = self._meta_data['container']._meta_data['uri']\n        session = self._meta_data['bigip']._meta_data['icr_session']\n        # Invoke the REST operation on the device.\n        response = session.post(_create_uri, json={})\n        # Make new instance of self\n        return self._produce_instance(response)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _check_device_number(self, devices):\n        '''Check if number of devices is between 2 and 4\n\n        :param kwargs: dict -- keyword args in dict\n        '''\n\n        if len(devices) < 2 or len(devices) > 4:\n            msg = 'The number of devices to cluster is not supported.'\n            raise ClusterNotSupported(msg)", "response": "Check if number of devices is between 2 and 4."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmanaging an existing cluster with the same attributes.", "response": "def manage_extant(self, **kwargs):\n        '''Manage an existing cluster\n\n        :param kwargs: dict -- keyword args in dict\n        '''\n\n        self._check_device_number(kwargs['devices'])\n        self.trust_domain = TrustDomain(\n            devices=kwargs['devices'],\n            partition=kwargs['device_group_partition']\n        )\n        self.device_group = DeviceGroup(**kwargs)\n        self.cluster = Cluster(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create(self, **kwargs):\n        '''Create a cluster of BIG-IP\u00ae devices.\n\n        :param kwargs: dict -- keyword arguments for cluster manager\n        '''\n\n        try:\n            cluster = getattr(self, \"cluster\", None)\n        except NoClusterToManage:\n            cluster = None\n        if cluster is not None:\n            msg = 'The ClusterManager is already managing a cluster.'\n            raise AlreadyManagingCluster(msg)\n\n        self._check_device_number(kwargs['devices'])\n        self.trust_domain.create(\n            devices=kwargs['devices'],\n            partition=kwargs['device_group_partition']\n        )\n        self.device_group.create(**kwargs)\n        self.cluster = Cluster(**kwargs)", "response": "Create a cluster of BIG - IP\u00ae devices."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfilter version - specific optional parameters in v12. 1. 0 and greater.", "response": "def _filter_version_specific_options(self, tmos_ver, **kwargs):\n        '''Filter version-specific optional parameters\n\n        Some optional parameters only exist in v12.1.0 and greater,\n        filter these out for earlier versions to allow backward comatibility.\n        '''\n\n        if LooseVersion(tmos_ver) < LooseVersion('12.1.0'):\n            for k, parms in self._meta_data['optional_parameters'].items():\n                for r in kwargs.get(k, []):\n                    for parm in parms:\n                        value = r.pop(parm, None)\n                        if value is not None:\n                            logger.info(\n                                \"Policy parameter %s:%s is invalid for v%s\",\n                                k, parm, tmos_ver)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _create(self, **kwargs):\n        '''Allow creation of draft policy and ability to publish a draft\n\n        Draft policies only exist in 12.1.0 and greater versions of TMOS.\n        But there must be a method to create a draft, then publish it.\n\n        :raises: MissingRequiredCreationParameter\n        '''\n\n        tmos_ver = self._meta_data['bigip']._meta_data['tmos_version']\n        legacy = kwargs.pop('legacy', False)\n        publish = kwargs.pop('publish', False)\n        self._filter_version_specific_options(tmos_ver, **kwargs)\n        if LooseVersion(tmos_ver) < LooseVersion('12.1.0'):\n            return super(Policy, self)._create(**kwargs)\n        else:\n            if legacy:\n                return super(Policy, self)._create(legacy=True, **kwargs)\n            else:\n                if 'subPath' not in kwargs:\n                    msg = \"The keyword 'subPath' must be specified when \" \\\n                        \"creating draft policy in TMOS versions >= 12.1.0. \" \\\n                        \"Try and specify subPath as 'Drafts'.\"\n                    raise MissingRequiredCreationParameter(msg)\n                self = super(Policy, self)._create(**kwargs)\n                if publish:\n                    self.publish()\n                return self", "response": "Allow creation of draft policies and ability to publish a draft."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _modify(self, **patch):\n        '''Modify only draft or legacy policies\n\n        Published policies cannot be modified\n        :raises: OperationNotSupportedOnPublishedPolicy\n        '''\n\n        legacy = patch.pop('legacy', False)\n        tmos_ver = self._meta_data['bigip']._meta_data['tmos_version']\n        self._filter_version_specific_options(tmos_ver, **patch)\n        if 'Drafts' not in self._meta_data['uri'] and \\\n                LooseVersion(tmos_ver) >= LooseVersion('12.1.0') and \\\n                not legacy:\n            msg = 'Modify operation not allowed on a published policy.'\n            raise OperationNotSupportedOnPublishedPolicy(msg)\n        super(Policy, self)._modify(**patch)", "response": "Modify only draft or legacy policies can be modified\n        :raises OperationNotSupportedOnPublishedPolicy\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _update(self, **kwargs):\n        '''Update only draft or legacy policies\n\n        Published policies cannot be updated\n        :raises: OperationNotSupportedOnPublishedPolicy\n        '''\n\n        legacy = kwargs.pop('legacy', False)\n        tmos_ver = self._meta_data['bigip']._meta_data['tmos_version']\n        self._filter_version_specific_options(tmos_ver, **kwargs)\n        if 'Drafts' not in self._meta_data['uri'] and \\\n                LooseVersion(tmos_ver) >= LooseVersion('12.1.0') and \\\n                not legacy:\n            msg = 'Update operation not allowed on a published policy.'\n            raise OperationNotSupportedOnPublishedPolicy(msg)\n        super(Policy, self)._update(**kwargs)", "response": "Update only draft or legacy policies\n        Published policies cannot be updated\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef publish(self, **kwargs):\n        '''Publishing a draft policy is only applicable in TMOS 12.1 and up.\n\n        This operation updates the meta_data['uri'] of the existing object\n        and effectively moves a draft into a published state on the device.\n        The self object is also updated with the response from a GET to the\n        device.\n\n        :raises: PolicyNotDraft\n        '''\n\n        assert 'Drafts' in self._meta_data['uri']\n        assert self.status.lower() == 'draft'\n        base_uri = self._meta_data['container']._meta_data['uri']\n        requests_params = self._handle_requests_params(kwargs)\n        session = self._meta_data['bigip']._meta_data['icr_session']\n        if 'command' not in kwargs:\n            kwargs['command'] = 'publish'\n        if 'Drafts' not in self.name:\n            kwargs['name'] = self.fullPath\n        session.post(base_uri, json=kwargs, **requests_params)\n        get_kwargs = {\n            'name': self.name, 'partition': self.partition,\n            'uri_as_parts': True\n        }\n        response = session.get(base_uri, **get_kwargs)\n        json_data = response.json()\n        self._local_update(json_data)\n        self._activate_URI(json_data['selfLink'])", "response": "Publishes a draft policy on the device."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nallows for easily re - drafting a policy by creating a draft for the user with existing published policies. This method is used to re - draft the existing policy.", "response": "def draft(self, **kwargs):\n        '''Allows for easily re-drafting a policy\n\n        After a policy has been created, it was not previously possible\n        to re-draft the published policy. This method makes it possible\n        for a user with existing, published, policies to create drafts\n        from them so that they are modifiable.\n        See https://github.com/F5Networks/f5-common-python/pull/1099\n\n        :param kwargs:\n        :return:\n        '''\n        tmos_ver = self._meta_data['bigip']._meta_data['tmos_version']\n        legacy = kwargs.pop('legacy', False)\n        if LooseVersion(tmos_ver) < LooseVersion('12.1.0') or legacy:\n            raise DraftPolicyNotSupportedInTMOSVersion(\n                \"Drafting on this version of BIG-IP is not supported\"\n            )\n        kwargs = dict(\n            createDraft=True\n        )\n        super(Policy, self)._modify(**kwargs)\n\n        get_kwargs = {\n            'name': self.name,\n            'partition': self.partition,\n            'uri_as_parts': True,\n            'subPath': 'Drafts'\n        }\n        base_uri = self._meta_data['container']._meta_data['uri']\n        session = self._meta_data['bigip']._meta_data['icr_session']\n        response = session.get(base_uri, **get_kwargs)\n        json_data = response.json()\n        self._local_update(json_data)\n        self._activate_URI(json_data['selfLink'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _load(self, **kwargs):\n\n        if self._check_existence_by_collection(\n                self._meta_data['container'], kwargs['name']):\n            return super(Rules, self)._load(**kwargs)\n        msg = 'The rule named, {}, does not exist on the device.'.format(\n            kwargs['name'])\n        raise NonExtantPolicyRule(msg)", "response": "Load the rule from the device."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete(self, **kwargs):\n        if 'uuid' not in kwargs:\n            kwargs['uuid'] = str(self.uuid)\n\n        requests_params = self._handle_requests_params(kwargs)\n        kwargs = self._check_for_python_keywords(kwargs)\n        kwargs = self._prepare_request_json(kwargs)\n\n        delete_uri = self._meta_data['uri']\n        session = self._meta_data['bigip']._meta_data['icr_session']\n\n        # Check the generation for match before delete\n        force = self._check_force_arg(kwargs.pop('force', True))\n        if not force:\n            self._check_generation()\n\n        response = session.delete(delete_uri, json=kwargs, **requests_params)\n        if response.status_code == 200:\n            self.__dict__ = {'deleted': True}", "response": "Deletes a member from an unmanaged license pool."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndefines custom method to append 'exclusive_attributes'. WARNING: Some parameters are hyphenated therefore the function will need to utilize variable keyword argument syntax. This only applies when utilCmdArgs method is not in use. eg. param_set ={'standby':True 'traffic-group': 'traffic-group-1'} bigip.tm.sys.failover.exec_cmd('run', **param_set The 'standby' attribute cannot be present with either 'offline' or 'online' attribute, whichever is present. Additionally we check for existence of same attribute values in 'offline' and 'online' if both present. note:: There is also another way of using failover endpoint, by the means of 'utilCmdArgs' attribute, here the syntax will resemble more that of the 'tmsh run sys failover...' command. eg. exec_cmd('run', utilCmdArgs='standby traffic-group traffic-group-1') :: raises InvalidParameterValue", "response": "def exec_cmd(self, command, **kwargs):\n        \"\"\"Defining custom method to append 'exclusive_attributes'.\n\n        WARNING: Some parameters are hyphenated therefore the function\n                 will need to utilize variable keyword argument syntax.\n                 This only applies when utilCmdArgs method is not in use.\n\n                 eg.\n\n                 param_set ={'standby':True 'traffic-group': 'traffic-group-1'}\n                 bigip.tm.sys.failover.exec_cmd('run', **param_set\n\n        The 'standby' attribute cannot be present with either 'offline'\n        or 'online' attribute, whichever is present. Additionally\n        we check for existence of same attribute values in\n        'offline' and 'online' if both present.\n\n\n        note:: There is also another way of using failover endpoint,\n               by the means of 'utilCmdArgs' attribute, here the syntax\n               will resemble more that of the 'tmsh run sys failover...'\n               command.\n                    eg. exec_cmd('run', utilCmdArgs='standby traffic-group\n                    traffic-group-1')\n\n        :: raises InvalidParameterValue\n        \"\"\"\n\n        kwargs = self._reduce_boolean_pair(kwargs, 'online', 'offline')\n        if 'offline' in kwargs:\n            self._meta_data['exclusive_attributes'].append(\n                ('offline', 'standby'))\n\n        if 'online' in kwargs:\n            self._meta_data['exclusive_attributes'].append(\n                ('online', 'standby'))\n        self._is_allowed_command(command)\n        self._check_command_parameters(**kwargs)\n        return self._exec_cmd(command, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef toggle_standby(self, **kwargs):\n\n        trafficgroup = kwargs.pop('trafficgroup')\n        state = kwargs.pop('state')\n        if kwargs:\n            raise TypeError('Unexpected **kwargs: %r' % kwargs)\n        arguments = {'standby': state, 'traffic-group': trafficgroup}\n        return self.exec_cmd('run', **arguments)", "response": "Toggle the standby status of a traffic group."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a Route on the BIG - IP\u00ae and the associated python object.", "response": "def create(self, **kwargs):\n        '''Create a Route on the BIG-IP\u00ae and the associated python object.\n\n        One of the following gateways is required when creating the route\n        objects: ``blackhole``, ``gw``, ``tmInterface``, ``pool``.\n\n        :params kwargs: keyword arguments passed in from create call\n        :raises: KindTypeMismatch\n        :raises: MissingRequiredCreationParameter\n        :raises: HTTPError\n        :returns: Python Route object\n        '''\n        # We need to check that we have one of the available gateways set\n        # when we create.  This isn't exactly the same as\n        # required_creation_parameters because it needs to be one of the\n        # gateways in the list.\n        gateways = ['blackhole', 'gw', 'tmInterface', 'pool']\n        kwkeys = list(iterkeys(kwargs))\n        if not [k for k in kwkeys if k in gateways]:\n            raise MissingRequiredCreationParameter(\n                \"One of %s gateways is required.\" % gateways\n            )\n        return self._create(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create(self, **kwargs):\n        if kwargs['useProxyServer'] == 'enabled':\n            tup_par = ('proxyServerPool', 'trustedCa', 'useProxyServer')\n        else:\n            tup_par = ('dnsResolver', 'trustedCa', 'useProxyServer')\n\n        self._meta_data['required_creation_parameters'].update(tup_par)\n        return self._create(**kwargs)", "response": "Create the resource on the BIG - IP\u00ae."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating the object with the specified parameters.", "response": "def update(self, **kwargs):\n        \"\"\"When setting useProxyServer to enable we need to supply\n\n            proxyServerPool value as well\n        \"\"\"\n        if 'useProxyServer' in kwargs and kwargs['useProxyServer'] == 'enabled':\n            if 'proxyServerPool' not in kwargs:\n                error = 'Missing proxyServerPool parameter value.'\n                raise MissingUpdateParameter(error)\n        if hasattr(self, 'useProxyServer'):\n            if getattr(self, 'useProxyServer') == 'enabled' and 'proxyServerPool' not in self.__dict__:\n                error = 'Missing proxyServerPool parameter value.'\n                raise MissingUpdateParameter(error)\n\n        self._update(**kwargs)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _check_tagmode_and_tmos_version(self, **kwargs):\n        '''Raise an exception if tagMode in kwargs and tmos version < 11.6.0\n\n        :param kwargs: dict -- keyword arguments for request\n        :raises: TagModeDisallowedForTMOSVersion\n        '''\n\n        tmos_version = self._meta_data['bigip']._meta_data['tmos_version']\n        if LooseVersion(tmos_version) < LooseVersion('11.6.0'):\n            msg = \"The parameter, 'tagMode', is not allowed against the \" \\\n                \"following version of TMOS: %s\" % (tmos_version)\n            if 'tagMode' in kwargs or hasattr(self, 'tagMode'):\n                raise TagModeDisallowedForTMOSVersion(msg)", "response": "Raise an exception if tagMode is not allowed against the TMOS version of the current instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load(self, **kwargs):\n        tmos_v = self._meta_data['bigip']._meta_data['tmos_version']\n        if self._check_existence_by_collection(\n                self._meta_data['container'], kwargs['name']):\n            if LooseVersion(tmos_v) == LooseVersion('11.5.4'):\n                return self._load_11_5_4(**kwargs)\n            else:\n                return self._load(**kwargs)\n        msg = 'The Policy named, {}, does not exist on the device.'.format(\n            kwargs['name'])\n        raise NonExtantVirtualPolicy(msg)", "response": "Override load to retrieve object based on exists above."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _load_11_5_4(self, **kwargs):\n        if 'uri' in self._meta_data:\n            error = \"There was an attempt to assign a new uri to this \" \\\n                    \"resource, the _meta_data['uri'] is %s and it should\" \\\n                    \" not be changed.\" % (self._meta_data['uri'])\n            raise URICreationCollision(error)\n        requests_params = self._handle_requests_params(kwargs)\n        self._check_load_parameters(**kwargs)\n        kwargs['uri_as_parts'] = True\n        refresh_session = self._meta_data['bigip']._meta_data[\n            'icr_session']\n        base_uri = self._meta_data['container']._meta_data['uri']\n        kwargs.update(requests_params)\n        for key1, key2 in self._meta_data['reduction_forcing_pairs']:\n            kwargs = self._reduce_boolean_pair(kwargs, key1, key2)\n        kwargs = self._check_for_python_keywords(kwargs)\n        try:\n            response = refresh_session.get(base_uri, **kwargs)\n        except HTTPError as err:\n            if err.response.status_code != 404:\n                raise\n            if err.response.status_code == 404:\n                return self._return_object(self._meta_data['container'],\n                                           kwargs['name'])\n        # Make new instance of self\n        return self._produce_instance(response)", "response": "Custom _load method to accommodate for issue in 11. 5. 4."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_collection(self, **kwargs):\n        list_of_contents = []\n        self.refresh(**kwargs)\n        if 'items' in self.__dict__:\n            for item in self.items:\n                # It's possible to have non-\"kind\" JSON returned. We just\n                # append the corresponding dict. PostProcessing is the caller's\n                # responsibility.\n                if 'kind' not in item:\n                    list_of_contents.append(item)\n                    continue\n                kind = item['kind']\n                if kind in self._meta_data['attribute_registry']:\n                    # If it has a kind, it must be registered.\n                    instance =\\\n                        self._meta_data['attribute_registry'][kind](self)\n                    instance._local_update(item)\n                    instance._activate_URI(instance.selfLink)\n                    list_of_contents.append(instance)\n                else:\n                    error_message = '%r is not registered!' % kind\n                    raise UnregisteredKind(error_message)\n\n        if 'policiesReference' in self.__dict__ and 'items' not in \\\n                self.__dict__:\n            for item in self.policiesReference['items']:\n                kind = item['kind']\n                if kind in self._meta_data['attribute_registry']:\n                    # If it has a kind, it must be registered.\n                    instance = \\\n                        self._meta_data['attribute_registry'][kind](self)\n                    instance._local_update(item)\n                    instance._activate_URI(instance.selfLink)\n                    list_of_contents.append(instance)\n                else:\n                    error_message = '%r is not registered!' % kind\n                    raise UnregisteredKind(error_message)\n\n        return list_of_contents", "response": "This method is used to get a list of objects that are nested under the policiesReference key."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncall this to create a new snat on the BIG-IP\u00ae. Uses HTTP POST to 'containing' URI to create a service associated with a new URI on the device. Note this is the one of two fundamental Resource operations that returns a different uri (in the returned object) than the uri the operation was called on. The returned uri can be accessed as Object.selfLink, the actual uri used by REST operations on the object is Object._meta_data['uri']. The _meta_data['uri'] is the same as Object.selfLink with the substring 'localhost' replaced with the value of Object._meta_data['BIG-IP']._meta_data['hostname'], and without query args, or hash fragments. The following is done prior to the POST * Ensures that one of ``automap``, ``snatpool``, ``translation`` parameter is passed in. :param kwargs: All the key-values needed to create the resource :returns: An instance of the Python object that represents the device's uri-published resource. The uri of the resource is part of the object's _meta_data.", "response": "def create(self, **kwargs):\n        \"\"\"Call this to create a new snat on the BIG-IP\u00ae.\n\n        Uses HTTP POST to 'containing' URI to create a service associated with\n        a new URI on the device.\n\n        Note this is the one of two fundamental Resource operations that\n        returns a different uri (in the returned object) than the uri the\n        operation was called on.  The returned uri can be accessed as\n        Object.selfLink, the actual uri used by REST operations on the object\n        is Object._meta_data['uri'].  The _meta_data['uri'] is the same as\n        Object.selfLink with the substring 'localhost' replaced with the value\n        of Object._meta_data['BIG-IP']._meta_data['hostname'], and without\n        query args, or hash fragments.\n\n        The following is done prior to the POST\n        * Ensures that one of ``automap``, ``snatpool``, ``translation``\n          parameter is passed in.\n\n        :param kwargs: All the key-values needed to create the resource\n        :returns: An instance of the Python object that represents the device's\n        uri-published resource.  The uri of the resource is part of the\n        object's _meta_data.\n        \"\"\"\n        required_one_of = ['automap', 'snatpool', 'translation']\n        has_any = [x for x in iterkeys(kwargs) if x in required_one_of]\n\n        # The rules for SNAT is that you must provide one, and only one,\n        # of the `required_one_of` values above.\n        if len(has_any) == 1:\n            return self._create(**kwargs)\n\n        raise RequireOneOf(\n            \"Creation requires one of the provided {0}\".format(\n                ', '.join(required_one_of)\n            )\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmaps a list of devices to their hostnames.", "response": "def get_device_names_to_objects(devices):\n    '''Map a list of devices to their hostnames.\n\n    :param devices: list -- list of ManagementRoot objects\n    :returns: dict -- mapping of hostnames to ManagementRoot objects\n    '''\n\n    name_to_object = {}\n    for device in devices:\n        device_name = get_device_info(device).name\n        name_to_object[device_name] = device\n    return name_to_object"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _format_monitor_parameter(param):\n        if '{' in param and '}':\n            tmp = param.strip('}').split('{')\n            monitor = ''.join(tmp).rstrip()\n            return monitor\n        else:\n            return param", "response": "This is a workaround for a known issue ID645289, which affects\n\n        all versions of TMOS at this time."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef modify(self, **patch):\n        if 'monitor' in patch:\n            value = self._format_monitor_parameter(patch['monitor'])\n            patch['monitor'] = value\n        return super(Pool, self)._modify(**patch)", "response": "Custom modify method to implement monitor parameter formatting."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _check_member_parameters(self, **kwargs):\n        if 'fqdn' in kwargs:\n            kwargs['fqdn'].pop('autopopulate', '')\n            kwargs['fqdn'].pop('addressFamily', '')\n        if 'fqdn' in self.__dict__:\n            self.__dict__['fqdn'].pop('autopopulate', '')\n            self.__dict__['fqdn'].pop('addressFamily', '')\n        if 'state' in kwargs:\n            if kwargs['state'] != 'user-up' and kwargs['state'] != \\\n                    'user-down':\n                kwargs.pop('state')\n        if 'state' in self.__dict__:\n            if self.__dict__['state'] != 'user-up' and self.__dict__['state'] \\\n                    != 'user-down':\n                self.__dict__.pop('state')\n        if 'session' in kwargs:\n            if kwargs['session'] != 'user-enabled' and kwargs['session'] != \\\n                    'user-disabled':\n                kwargs.pop('session')\n        if 'session' in self.__dict__:\n            if self.__dict__['session'] != 'user-enabled' and \\\n                    self.__dict__['session'] != 'user-disabled':\n                self.__dict__.pop('session')\n        # Until we implement sanity checks for __dict__ this needs to stay here\n        self.__dict__.pop('ephemeral', '')\n        self.__dict__.pop('address', '')\n        return kwargs", "response": "Check if the parameters of the user are in the correct order."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate the configuration of the service on the device.", "response": "def update(self, **kwargs):\n        \"\"\"Call this to change the configuration of the service on the device.\n\n        This method uses HTTP PUT to alter the service state on the device.\n\n        The attributes of the instance will be packaged as a dictionary.  That\n        dictionary will be updated with kwargs.  It is then submitted as JSON\n        to the device.  Various edge cases are handled:\n\n        * read-only attributes that are unchangeable are removed\n        * If ``fqdn`` is in the kwargs or set as an attribute, removes the\n          ``autopopulate`` and ``addressFamily`` keys from it.\n\n        :param kwargs: keys and associated values to alter on the device\n        \"\"\"\n        checked = self._check_member_parameters(**kwargs)\n        return super(Members, self)._update(**checked)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if the named object exists on the BigIP.", "response": "def exists(self, **kwargs):\n        \"\"\"Check for the existence of the named object on the BigIP\n\n        Sends an HTTP GET to the URI of the named object and if it fails with\n        a :exc:~requests.HTTPError` exception it checks the exception for\n        status code of 404 and returns :obj:`False` in that case.\n\n        If the GET is successful it must then check the contents of the json\n        contained in the response, this is because the \"pool/... /members\"\n        resource provided by the server returns a status code of 200 for\n        queries that do not correspond to an existing configuration.  Therefore\n        this method checks for the presence of the \"address\" key in the\n        response JSON...  of course, this means that exists depends on an\n        unexpected idiosyncrancy of the server, and might break with version\n        updates, edge cases, or other unpredictable changes.\n\n        :param kwargs: Keyword arguments required to get objects, \"partition\"\n        and \"name\" are required\n\n        NOTE: If kwargs has a 'requests_params' key the corresponding dict will\n        be passed to the underlying requests.session.get method where it will\n        be handled according to that API. THIS IS HOW TO PASS QUERY-ARGS!\n        :returns: bool -- The objects exists on BigIP or not.\n        :raises: :exc:`requests.HTTPError`, Any HTTP error that was not status\n                 code 404.\n        \"\"\"\n        requests_params = self._handle_requests_params(kwargs)\n        self._check_load_parameters(**kwargs)\n        kwargs['uri_as_parts'] = True\n        session = self._meta_data['bigip']._meta_data['icr_session']\n        base_uri = self._meta_data['container']._meta_data['uri']\n        kwargs.update(requests_params)\n        try:\n            response = session.get(base_uri, **kwargs)\n        except HTTPError as err:\n            if err.response.status_code == 404:\n                return False\n            else:\n                raise\n        rdict = response.json()\n        if \"address\" not in rdict:\n            # We can add 'or' conditions to be more restrictive.\n            return False\n        # Only after all conditions are met...\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\noverriding modify to check kwargs before request sent to device.", "response": "def _modify(self, **patch):\n        \"\"\"Override modify to check kwargs before request sent to device.\"\"\"\n        if 'state' in patch:\n            if patch['state'] != 'user-up' and patch['state'] != 'user-down':\n                msg = \"The members resource does not support a modify with \" \\\n                      \"the value of the 'state' attribute as %s. \" \\\n                      \"The accepted values are 'user-up' or \" \\\n                      \"'user-down'\" % patch['state']\n                raise MemberStateModifyUnsupported(msg)\n        if 'session' in patch:\n            if patch['session'] != 'user-enabled' and patch['session'] != \\\n                    'user-disabled':\n                msg = \"The members resource does not support a modify with \" \\\n                      \"the value of the 'session' attribute as %s. \" \\\n                      \"The accepted values are 'user-enabled' or \" \\\n                      \"'user-disabled'\" % patch['session']\n                raise MemberStateModifyUnsupported(msg)\n        super(Members, self)._modify(**patch)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef exec_cmd(self, command, **kwargs):\n        self._is_allowed_command(command)\n        self._check_command_parameters(**kwargs)\n\n        if command == 'load':\n            kwargs['command'] = command\n            self._check_exclusive_parameters(**kwargs)\n            requests_params = self._handle_requests_params(kwargs)\n            session = self._meta_data['bigip']._meta_data['icr_session']\n            try:\n\n                session.post(\n                    self._meta_data['uri'], json=kwargs, **requests_params)\n\n            except HTTPError as err:\n                if err.response.status_code != 502:\n                    raise\n                return\n\n        else:\n            return self._exec_cmd(command, **kwargs)", "response": "Execute a command on the ID476518."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_attributes(self, **kwargs):\n        '''Set instance attributes based on kwargs\n\n        :param kwargs: dict -- kwargs to set as attributes\n        '''\n\n        try:\n            self.devices = kwargs['devices'][:]\n            self.name = kwargs['device_group_name']\n            self.type = kwargs['device_group_type']\n            self.partition = kwargs['device_group_partition']\n        except KeyError as ex:\n            raise MissingRequiredDeviceGroupParameter(ex)", "response": "Set instance attributes based on kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate(self, **kwargs):\n        '''Validate device group state among given devices.\n\n        :param kwargs: dict -- keyword args of device group information\n        :raises: UnexpectedDeviceGroupType, UnexpectedDeviceGroupDevices\n        '''\n\n        self._set_attributes(**kwargs)\n        self._check_type()\n        self.dev_group_uri_res = self._get_device_group(self.devices[0])\n        if self.dev_group_uri_res.type != self.type:\n            msg = 'Device group type found: %r does not match expected ' \\\n                'device group type: %r' % (\n                    self.dev_group_uri_res.type, self.type\n                )\n            raise UnexpectedDeviceGroupType(msg)\n        queried_device_names = self._get_device_names_in_group()\n        given_device_names = []\n        for device in self.devices:\n            device_name = get_device_info(device).name\n            given_device_names.append(device_name)\n        if sorted(queried_device_names) != sorted(given_device_names):\n            msg = 'Given devices does not match queried devices.'\n            raise UnexpectedDeviceGroupDevices(msg)\n        self.ensure_all_devices_in_sync()", "response": "Validate the state of the current state of the current state of the device group."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck that the device group type is correct.", "response": "def _check_type(self):\n        '''Check that the device group type is correct.\n\n        :raises: DeviceGroupOperationNotSupported, DeviceGroupNotSupported\n        '''\n\n        if self.type not in self.available_types:\n            msg = 'Unsupported cluster type was given: %s' % self.type\n            raise DeviceGroupNotSupported(msg)\n        elif self.type == 'sync-only' and self.name != 'device_trust_group':\n            msg = \"Management of sync-only device groups only supported for \" \\\n                \"built-in device group named 'device_trust_group'\"\n            raise DeviceGroupNotSupported(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates the device service cluster group and add devices to it.", "response": "def create(self, **kwargs):\n        '''Create the device service cluster group and add devices to it.'''\n\n        self._set_attributes(**kwargs)\n        self._check_type()\n        pollster(self._check_all_devices_in_sync)()\n        dg = self.devices[0].tm.cm.device_groups.device_group\n        dg.create(name=self.name, partition=self.partition, type=self.type)\n        for device in self.devices:\n            self._add_device_to_device_group(device)\n            device.tm.sys.config.exec_cmd('save')\n        self.ensure_all_devices_in_sync()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef teardown(self):\n        '''Teardown device service cluster group.'''\n\n        self.ensure_all_devices_in_sync()\n        for device in self.devices:\n            self._delete_device_from_device_group(device)\n            self._sync_to_group(device)\n            pollster(self._ensure_device_active)(device)\n            self.ensure_all_devices_in_sync()\n        dg = pollster(self._get_device_group)(self.devices[0])\n        dg.delete()\n        pollster(self._check_devices_active_licensed)()\n        pollster(self._check_all_devices_in_sync)()", "response": "Teardown device service cluster group."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_device_names_in_group(self):\n        '''_get_device_names_in_group\n\n        :returns: list -- list of device names in group\n        '''\n\n        device_names = []\n        dg = pollster(self._get_device_group)(self.devices[0])\n        members = dg.devices_s.get_collection()\n        for member in members:\n            member_name = member.name.replace('/%s/' % self.partition, '')\n            device_names.append(member_name)\n        return device_names", "response": "_get_device_names_in_group\n        - returns list of device names in group\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_device_group(self, device):\n        '''Get the device group through a device.\n\n        :param device: bigip object -- device\n        :returns: tm.cm.device_groups.device_group object\n        '''\n\n        return device.tm.cm.device_groups.device_group.load(\n            name=self.name, partition=self.partition\n        )", "response": "Get the device group through a device."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking that all devices are in an active or licensed state.", "response": "def _check_devices_active_licensed(self):\n        '''All devices should be in an active/licensed state.\n\n        :raises: UnexpectedClusterState\n        '''\n\n        if len(self._get_devices_by_activation_state('active')) != \\\n                len(self.devices):\n            msg = \"One or more devices not in 'Active' and licensed state.\"\n            raise UnexpectedDeviceGroupState(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _add_device_to_device_group(self, device):\n        '''Add device to device service cluster group.\n\n        :param device: bigip object -- device to add to group\n        '''\n\n        device_name = get_device_info(device).name\n        dg = pollster(self._get_device_group)(device)\n        dg.devices_s.devices.create(name=device_name, partition=self.partition)\n        pollster(self._check_device_exists_in_device_group)(device_name)", "response": "Add device to device service cluster group."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _check_device_exists_in_device_group(self, device_name):\n        '''Check whether a device exists in the device group\n\n        :param device: ManagementRoot object -- device to look for\n        '''\n\n        dg = self._get_device_group(self.devices[0])\n        dg.devices_s.devices.load(name=device_name, partition=self.partition)", "response": "Check whether a device exists in the device group"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _delete_device_from_device_group(self, device):\n        '''Remove device from device service cluster group.\n\n        :param device: ManagementRoot object -- device to delete from group\n        '''\n\n        device_name = get_device_info(device).name\n        dg = pollster(self._get_device_group)(device)\n        device_to_remove = dg.devices_s.devices.load(\n            name=device_name, partition=self.partition\n        )\n        device_to_remove.delete()", "response": "Remove device from device service cluster group."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nensures a single device is in an active state.", "response": "def _ensure_device_active(self, device):\n        '''Ensure a single device is in an active state\n\n        :param device: ManagementRoot object -- device to inspect\n        :raises: UnexpectedClusterState\n        '''\n\n        act = device.tm.cm.devices.device.load(\n            name=get_device_info(device).name,\n            partition=self.partition\n        )\n        if act.failoverState != 'active':\n            msg = \"A device in the cluster was not in the 'Active' state.\"\n            raise UnexpectedDeviceGroupState(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _check_all_devices_in_sync(self):\n        '''Wait until all devices have failover status of 'In Sync'.\n\n        :raises: UnexpectedClusterState\n        '''\n\n        if len(self._get_devices_by_failover_status('In Sync')) != \\\n                len(self.devices):\n            msg = \"Expected all devices in group to have 'In Sync' status.\"\n            raise UnexpectedDeviceGroupState(msg)", "response": "Wait until all devices have failover status of In Sync."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_devices_by_failover_status(self, status):\n        '''Get a list of bigips by failover status.\n\n        :param status: str -- status to filter the returned list of devices\n        :returns: list -- list of devices that have the given status\n        '''\n\n        devices_with_status = []\n        for device in self.devices:\n            if (self._check_device_failover_status(device, status)):\n                devices_with_status.append(device)\n        return devices_with_status", "response": "Get a list of bigips by failover status."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _check_device_failover_status(self, device, status):\n        '''Determine if a device has a specific failover status.\n\n        :param status: str -- status to check against\n        :returns: bool -- True is it has status, False otherwise\n        '''\n\n        sync_status = device.tm.cm.sync_status\n        sync_status.refresh()\n        current_status = (sync_status.entries[self.sync_status_entry]\n                          ['nestedStats']['entries']['status']\n                          ['description'])\n        if status == current_status:\n            return True\n        return False", "response": "Check if a device has a specific failover status."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_devices_by_activation_state(self, state):\n        '''Get a list of bigips by activation statue.\n\n        :param state: str -- state to filter the returned list of devices\n        :returns: list -- list of devices that are in the given state\n        '''\n\n        devices_with_state = []\n        for device in self.devices:\n            act = device.tm.cm.devices.device.load(\n                name=get_device_info(device).name,\n                partition=self.partition\n            )\n            if act.failoverState == state:\n                devices_with_state.append(device)\n        return devices_with_state", "response": "Get a list of bigips by activation state."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef reset(self):\n\n\t\t\"\"\"\n\t\tReinitializes data to original inputs, and drops any estimated\n\t\tresults.\n\t\t\"\"\"\n\n\t\tY, D, X = self.old_data['Y'], self.old_data['D'], self.old_data['X']\n\t\tself.raw_data = Data(Y, D, X)\n\t\tself.summary_stats = Summary(self.raw_data)\n\t\tself.propensity = None\n\t\tself.cutoff = None\n\t\tself.blocks = None\n\t\tself.strata = None\n\t\tself.estimates = Estimators()", "response": "Resets the internal state of the object to its original state."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef est_propensity(self, lin='all', qua=None):\n\n\t\t\"\"\"\n\t\tEstimates the propensity scores given list of covariates to\n\t\tinclude linearly or quadratically.\n\n\t\tThe propensity score is the conditional probability of\n\t\treceiving the treatment given the observed covariates.\n\t\tEstimation is done via a logistic regression.\n\n\t\tParameters\n\t\t----------\n\t\tlin: string or list, optional\n\t\t\tColumn numbers (zero-based) of variables of\n\t\t\tthe original covariate matrix X to include\n\t\t\tlinearly. Defaults to the string 'all', which\n\t\t\tuses whole covariate matrix.\n\t\tqua: list, optional\n\t\t\tTuples indicating which columns of the original\n\t\t\tcovariate matrix to multiply and include. E.g.,\n\t\t\t[(1,1), (2,3)] indicates squaring the 2nd column\n\t\t\tand including the product of the 3rd and 4th\n\t\t\tcolumns. Default is to not include any\n\t\t\tquadratic terms.\n\t\t\"\"\"\n\n\t\tlin_terms = parse_lin_terms(self.raw_data['K'], lin)\n\t\tqua_terms = parse_qua_terms(self.raw_data['K'], qua)\n\n\t\tself.propensity = Propensity(self.raw_data, lin_terms, qua_terms)\n\t\tself.raw_data._dict['pscore'] = self.propensity['fitted']\n\t\tself._post_pscore_init()", "response": "Estimates the propensity scores given the observed covariates to include linearly or quadraticly."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef est_propensity_s(self, lin_B=None, C_lin=1, C_qua=2.71):\n\t\n\t\t\"\"\"\n\t\tEstimates the propensity score with covariates selected using\n\t\tthe algorithm suggested by [1]_.\n\n\t\tThe propensity score is the conditional probability of\n\t\treceiving the treatment given the observed covariates.\n\t\tEstimation is done via a logistic regression.\n\n\t\tThe covariate selection algorithm is based on a sequence\n\t\tof likelihood ratio tests.\n\n\t\tParameters\n\t\t----------\n\t\tlin_B: list, optional\n\t\t\tColumn numbers (zero-based) of variables of\n\t\t\tthe original covariate matrix X to include\n\t\t\tlinearly. Defaults to empty list, meaning\n\t\t\tevery column of X is subjected to the\n\t\t\tselection algorithm.\n\t\tC_lin: scalar, optional\n\t\t\tCritical value used in likelihood ratio tests\n\t\t\tto decide whether candidate linear terms should\n\t\t\tbe included. Defaults to 1 as in [1]_.\n\t\tC_qua: scalar, optional\n\t\t\tCritical value used in likelihood ratio tests\n\t\t\tto decide whether candidate quadratic terms\n\t\t\tshould be included. Defaults to 2.71 as in\n\t\t\t[1]_.\n\n\t\tReferences\n\t\t----------\n\t\t.. [1] Imbens, G. & Rubin, D. (2015). Causal Inference in\n\t\t\tStatistics, Social, and Biomedical Sciences: An\n\t\t\tIntroduction.\n\t\t\"\"\"\n\n\t\tlin_basic = parse_lin_terms(self.raw_data['K'], lin_B)\n\n\t\tself.propensity = PropensitySelect(self.raw_data, lin_basic,\n\t\t                                   C_lin, C_qua)\n\t\tself.raw_data._dict['pscore'] = self.propensity['fitted']\n\t\tself._post_pscore_init()", "response": "Estimates the propensity score with covariates selected using the given covariates."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef trim(self):\n\n\t\t\"\"\"\n\t\tTrims data based on propensity score to create a subsample with\n\t\tbetter covariate balance.\n\t\t\n\t\tThe default cutoff value is set to 0.1. To set a custom cutoff\n\t\tvalue, modify the object attribute named cutoff directly.\n\n\t\tThis method should only be executed after the propensity score\n\t\thas been estimated.\n\t\t\"\"\"\n\n\t\tif 0 < self.cutoff <= 0.5:\n\t\t\tpscore = self.raw_data['pscore']\n\t\t\tkeep = (pscore >= self.cutoff) & (pscore <= 1-self.cutoff)\n\t\t\tY_trimmed = self.raw_data['Y'][keep]\n\t\t\tD_trimmed = self.raw_data['D'][keep]\n\t\t\tX_trimmed = self.raw_data['X'][keep]\n\t\t\tself.raw_data = Data(Y_trimmed, D_trimmed, X_trimmed)\n\t\t\tself.raw_data._dict['pscore'] = pscore[keep]\n\t\t\tself.summary_stats = Summary(self.raw_data)\n\t\t\tself.strata = None\n\t\t\tself.estimates = Estimators()\n\t\telif self.cutoff == 0:\n\t\t\tpass\n\t\telse:\n\t\t\traise ValueError('Invalid cutoff.')", "response": "This method trims the data based on the propensity score and creates a subsample with the same data."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef trim_s(self):\n\n\t\t\"\"\"\n\t\tTrims data based on propensity score using the cutoff\n\t\tselection algorithm suggested by [1]_.\n\t\t\n\t\tThis method should only be executed after the propensity score\n\t\thas been estimated.\n\n\t\tReferences\n\t\t----------\n\t\t.. [1] Crump, R., Hotz, V., Imbens, G., & Mitnik, O. (2009).\n\t\t\tDealing with Limited Overlap in Estimation of\n\t\t\tAverage Treatment Effects. Biometrika, 96, 187-199.\n\t\t\"\"\"\n\n\t\tpscore = self.raw_data['pscore']\n\t\tg = 1.0/(pscore*(1-pscore))  # 1 over Bernoulli variance\n\n\t\tself.cutoff = select_cutoff(g)\n\t\tself.trim()", "response": "trims the data based on the propensity score using the cutoff\n\tselection algorithm suggested by [ 1 ] _."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stratify(self):\n\n\t\t\"\"\"\n\t\tStratifies the sample based on propensity score.\n\t\t\n\t\tBy default the sample is divided into five equal-sized bins.\n\t\tThe number of bins can be set by modifying the object\n\t\tattribute named blocks. Alternatively, custom-sized bins can\n\t\tbe created by setting blocks equal to a sorted list of numbers\n\t\tbetween 0 and 1 indicating the bin boundaries.\n\n\t\tThis method should only be executed after the propensity score\n\t\thas been estimated.\n\t\t\"\"\"\n\n\t\tY, D, X = self.raw_data['Y'], self.raw_data['D'], self.raw_data['X']\n\t\tpscore = self.raw_data['pscore']\n\n\t\tif isinstance(self.blocks, int):\n\t\t\tblocks = split_equal_bins(pscore, self.blocks)\n\t\telse:\n\t\t\tblocks = self.blocks[:]  # make a copy; should be sorted\n\t\t\tblocks[0] = 0  # avoids always dropping 1st unit\n\n\t\tdef subset(p_low, p_high):\n\t\t\treturn (p_low < pscore) & (pscore <= p_high)\n\t\tsubsets = [subset(*ps) for ps in zip(blocks, blocks[1:])]\n\t\tstrata = [CausalModel(Y[s], D[s], X[s]) for s in subsets]\n\t\tself.strata = Strata(strata, subsets, pscore)", "response": "Stratifies the sample based on propensity score."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef stratify_s(self):\n\n\t\t\"\"\"\n\t\tStratifies the sample based on propensity score using the\n\t\tbin selection procedure suggested by [1]_.\n\n\t\tThe bin selection algorithm is based on a sequence of\n\t\ttwo-sample t tests performed on the log-odds ratio.\n\n\t\tThis method should only be executed after the propensity score\n\t\thas been estimated.\n\n\t\tReferences\n\t\t----------\n\t\t.. [1] Imbens, G. & Rubin, D. (2015). Causal Inference in\n\t\t\tStatistics, Social, and Biomedical Sciences: An\n\t\t\tIntroduction.\n\t\t\"\"\"\n\n\t\tpscore_order = self.raw_data['pscore'].argsort()\n\t\tpscore = self.raw_data['pscore'][pscore_order]\n\t\tD = self.raw_data['D'][pscore_order]\n\t\tlogodds = np.log(pscore / (1-pscore))\n\t\tK = self.raw_data['K']\n\n\t\tblocks_uniq = set(select_blocks(pscore, logodds, D, K, 0, 1))\n\t\tself.blocks = sorted(blocks_uniq)\n\t\tself.stratify()", "response": "Stratifies the sample based on the propensity score using the bin selection procedure suggested by [ 1 ] _."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef est_via_matching(self, weights='inv', matches=1, bias_adj=False):\n\n\t\t\"\"\"\n\t\tEstimates average treatment effects using nearest-\n\t\tneighborhood matching.\n\n\t\tMatching is done with replacement. Method supports multiple\n\t\tmatching. Correcting bias that arise due to imperfect matches\n\t\tis also supported. For details on methodology, see [1]_.\n\n\t\tParameters\n\t\t----------\n\t\tweights: str or positive definite square matrix\n\t\t\tSpecifies weighting matrix used in computing\n\t\t\tdistance measures. Defaults to string 'inv',\n\t\t\twhich does inverse variance weighting. String\n\t\t\t'maha' gives the weighting matrix used in the\n\t\t\tMahalanobis metric.\n\t\tmatches: int\n\t\t\tNumber of matches to use for each subject.\n\t\tbias_adj: bool\n\t\t\tSpecifies whether bias adjustments should be\n\t\t\tattempted.\n\n\t\tReferences\n\t\t----------\n\t\t.. [1] Imbens, G. & Rubin, D. (2015). Causal Inference in\n\t\t\tStatistics, Social, and Biomedical Sciences: An\n\t\t\tIntroduction.\n\t\t\"\"\"\n\n\t\tX, K = self.raw_data['X'], self.raw_data['K']\n\t\tX_c, X_t = self.raw_data['X_c'], self.raw_data['X_t']\n\n\t\tif weights == 'inv':\n\t\t\tW = 1/X.var(0)\n\t\telif weights == 'maha':\n\t\t\tV_c = np.cov(X_c, rowvar=False, ddof=0)\n\t\t\tV_t = np.cov(X_t, rowvar=False, ddof=0)\n\t\t\tif K == 1:\n\t\t\t\tW = 1/np.array([[(V_c+V_t)/2]])  # matrix form\n\t\t\telse:\n\t\t\t\tW = np.linalg.inv((V_c+V_t)/2)\n\t\telse:\n\t\t\tW = weights\n\n\t\tself.estimates['matching'] = Matching(self.raw_data, W,\n\t\t                                      matches, bias_adj)", "response": "Estimates average treatment effects using nearest - neighborhood matching."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef random_data(N=5000, K=3, unobservables=False, **kwargs):\n\n\t\"\"\"\n\tFunction that generates data according to one of two simple models that\n\tsatisfies the unconfoundedness assumption.\n\n\tThe covariates and error terms are generated according to\n\t\tX ~ N(mu, Sigma), epsilon ~ N(0, Gamma).\n\n\tThe counterfactual outcomes are generated by\n\t\tY0 = X*beta + epsilon_0,\n\t\tY1 = delta + X*(beta+theta) + epsilon_1.\n\n\tSelection is done according to the following propensity score function:\n\t\tP(D=1|X) = Lambda(X*beta).\n\n\tHere Lambda is the standard logistic CDF.\n\n\tParameters\n\t----------\n\tN: int\n\t\tNumber of units to draw. Defaults to 5000.\n\tK: int\n\t\tNumber of covariates. Defaults to 3.\n\tunobservables: bool\n\t\tReturns potential outcomes and true propensity score\n\t\tin addition to observed outcome and covariates if True.\n\t\tDefaults to False.\n\tmu, Sigma, Gamma, beta, delta, theta: NumPy ndarrays, optional\n\t\tParameter values appearing in data generating process.\n\n\tReturns\n\t-------\n\ttuple\n\t\tA tuple in the form of (Y, D, X) or (Y, D, X, Y0, Y1) of\n\t\tobserved outcomes, treatment indicators, covariate matrix,\n\t\tand potential outomces.\n\t\"\"\"\n\n\tmu = kwargs.get('mu', np.zeros(K))\n\tbeta = kwargs.get('beta', np.ones(K))\n\ttheta = kwargs.get('theta', np.ones(K))\n\tdelta = kwargs.get('delta', 3)\n\tSigma = kwargs.get('Sigma', np.identity(K))\n\tGamma = kwargs.get('Gamma', np.identity(2))\n\n\tX = np.random.multivariate_normal(mean=mu, cov=Sigma, size=N)\n\tXbeta = X.dot(beta)\n\tpscore = logistic.cdf(Xbeta)\n\tD = np.array([np.random.binomial(1, p, size=1) for p in pscore]).flatten()\n\n\tepsilon = np.random.multivariate_normal(mean=np.zeros(2), cov=Gamma, size=N)\n\tY0 = Xbeta + epsilon[:,0]\n\tY1 = delta + X.dot(beta+theta) + epsilon[:,1]\n\tY = (1-D)*Y0 + D*Y1\n\n\tif unobservables:\n\t\treturn Y, D, X, Y0, Y1, pscore\n\telse:\n\t\treturn Y, D, X", "response": "Function that generates random data according to the model that satisfies the unconfoundedness assumption."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalls by Strata class during initialization.", "response": "def _summarize_pscore(self, pscore_c, pscore_t):\n\n\t\t\"\"\"\n\t\tCalled by Strata class during initialization.\n\t\t\"\"\"\n\n\t\tself._dict['p_min'] = min(pscore_c.min(), pscore_t.min())\n\t\tself._dict['p_max'] = max(pscore_c.max(), pscore_t.max())\n\t\tself._dict['p_c_mean'] = pscore_c.mean()\n\t\tself._dict['p_t_mean'] = pscore_t.mean()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef lookup_bulk(self, ResponseGroup=\"Large\", **kwargs):\n        response = self.api.ItemLookup(ResponseGroup=ResponseGroup, **kwargs)\n        root = objectify.fromstring(response)\n        if not hasattr(root.Items, 'Item'):\n            return []\n        return list(\n            AmazonProduct(\n                item,\n                self.aws_associate_tag,\n                self,\n                region=self.region) for item in root.Items.Item\n        )", "response": "Lookup Amazon Products in bulk."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef similarity_lookup(self, ResponseGroup=\"Large\", **kwargs):\n        response = self.api.SimilarityLookup(\n            ResponseGroup=ResponseGroup, **kwargs)\n        root = objectify.fromstring(response)\n        if root.Items.Request.IsValid == 'False':\n            code = root.Items.Request.Errors.Error.Code\n            msg = root.Items.Request.Errors.Error.Message\n            raise SimilartyLookupException(\n                \"Amazon Similarty Lookup Error: '{0}', '{1}'\".format(\n                    code, msg))\n        return [\n            AmazonProduct(\n                item,\n                self.aws_associate_tag,\n                self.api,\n                region=self.region\n            )\n            for item in getattr(root.Items, 'Item', [])\n        ]", "response": "Returns up to ten products that are similar to all items\n            specified in the request."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbrowse Node Lookup. Returns the specified browse node's name, children, and ancestors. Example: >>> api.browse_node_lookup(BrowseNodeId='163357')", "response": "def browse_node_lookup(self, ResponseGroup=\"BrowseNodeInfo\", **kwargs):\n        \"\"\"Browse Node Lookup.\n\n        Returns the specified browse node's name, children, and ancestors.\n        Example:\n            >>> api.browse_node_lookup(BrowseNodeId='163357')\n        \"\"\"\n        response = self.api.BrowseNodeLookup(\n            ResponseGroup=ResponseGroup, **kwargs)\n        root = objectify.fromstring(response)\n        if root.BrowseNodes.Request.IsValid == 'False':\n            code = root.BrowseNodes.Request.Errors.Error.Code\n            msg = root.BrowseNodes.Request.Errors.Error.Message\n            raise BrowseNodeLookupException(\n                \"Amazon BrowseNode Lookup Error: '{0}', '{1}'\".format(\n                    code, msg))\n        return [AmazonBrowseNode(node.BrowseNode) for node in root.BrowseNodes]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsearches for the related resources.", "response": "def search(self, **kwargs):\n        \"\"\"Search.\n\n        :return:\n            An :class:`~.AmazonSearch` iterable.\n        \"\"\"\n        region = kwargs.get('region', self.region)\n        kwargs.update({'region': region})\n        return AmazonSearch(self.api, self.aws_associate_tag, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef search_n(self, n, **kwargs):\n        region = kwargs.get('region', self.region)\n        kwargs.update({'region': region})\n        items = AmazonSearch(self.api, self.aws_associate_tag, **kwargs)\n        return list(islice(items, n))", "response": "Search and return first N results.."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cart_create(self, items, **kwargs):\n\n        if isinstance(items, dict):\n            items = [items]\n\n        if len(items) > 10:\n            raise CartException(\"You can't add more than 10 items at once\")\n\n        offer_id_key_template = 'Item.{0}.OfferListingId'\n        quantity_key_template = 'Item.{0}.Quantity'\n\n        for i, item in enumerate(items):\n            kwargs[offer_id_key_template.format(i)] = item['offer_id']\n            kwargs[quantity_key_template.format(i)] = item['quantity']\n\n        response = self.api.CartCreate(**kwargs)\n        root = objectify.fromstring(response)\n\n        return AmazonCart(root)", "response": "This method creates a new AmazonCart object with the given items."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cart_add(self, items, CartId=None, HMAC=None, **kwargs):\n        if not CartId or not HMAC:\n            raise CartException('CartId and HMAC required for CartAdd call')\n\n        if isinstance(items, dict):\n            items = [items]\n\n        if len(items) > 10:\n            raise CartException(\"You can't add more than 10 items at once\")\n\n        offer_id_key_template = 'Item.{0}.OfferListingId'\n        quantity_key_template = 'Item.{0}.Quantity'\n\n        for i, item in enumerate(items):\n            kwargs[offer_id_key_template.format(i)] = item['offer_id']\n            kwargs[quantity_key_template.format(i)] = item['quantity']\n\n        response = self.api.CartAdd(CartId=CartId, HMAC=HMAC, **kwargs)\n        root = objectify.fromstring(response)\n\n        new_cart = AmazonCart(root)\n        self._check_for_cart_error(new_cart)\n\n        return new_cart", "response": "This method adds items to the cart."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cart_clear(self, CartId=None, HMAC=None, **kwargs):\n        if not CartId or not HMAC:\n            raise CartException('CartId required for CartClear call')\n        response = self.api.CartClear(CartId=CartId, HMAC=HMAC, **kwargs)\n        root = objectify.fromstring(response)\n\n        new_cart = AmazonCart(root)\n        self._check_for_cart_error(new_cart)\n\n        return new_cart", "response": "This method removes all items from the cart."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cart_get(self, CartId=None, HMAC=None, **kwargs):\n        if not CartId or not HMAC:\n            raise CartException('CartId required for CartGet call')\n        response = self.api.CartGet(CartId=CartId, HMAC=HMAC, **kwargs)\n        root = objectify.fromstring(response)\n\n        cart = AmazonCart(root)\n        self._check_for_cart_error(cart)\n\n        return cart", "response": "Gets an existing cart with the given ID and HMAC"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cart_modify(self, items, CartId=None, HMAC=None, **kwargs):\n        if not CartId or not HMAC:\n            raise CartException('CartId required for CartModify call')\n\n        if isinstance(items, dict):\n            items = [items]\n\n        if len(items) > 10:\n            raise CartException(\"You can't add more than 10 items at once\")\n\n        cart_item_id_key_template = 'Item.{0}.CartItemId'\n        quantity_key_template = 'Item.{0}.Quantity'\n\n        for i, item in enumerate(items):\n            kwargs[cart_item_id_key_template.format(i)] = item['cart_item_id']\n            kwargs[quantity_key_template.format(i)] = item['quantity']\n\n        response = self.api.CartModify(CartId=CartId, HMAC=HMAC, **kwargs)\n        root = objectify.fromstring(response)\n\n        new_cart = AmazonCart(root)\n        self._check_for_cart_error(new_cart)\n\n        return new_cart", "response": "This method allows you to modify the items in the cart."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsafing get element as datetime. date or None.", "response": "def _safe_get_element_date(self, path, root=None):\n        \"\"\"Safe get elemnent date.\n\n        Get element as datetime.date or None,\n        :param root:\n            Lxml element.\n        :param path:\n            String path (i.e. 'Items.Item.Offers.Offer').\n        :return:\n            datetime.date or None.\n        \"\"\"\n        value = self._safe_get_element_text(path=path, root=root)\n        if value is not None:\n            try:\n                value = dateutil.parser.parse(value)\n                if value:\n                    value = value.date()\n            except ValueError:\n                value = None\n\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef iterate_pages(self):\n        try:\n            while not self.is_last_page:\n                self.current_page += 1\n                yield self._query(ItemPage=self.current_page, **self.kwargs)\n        except NoMorePages:\n            pass", "response": "Iterate over all pages."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nquery Amazon Search and check for errors.", "response": "def _query(self, ResponseGroup=\"Large\", **kwargs):\n        \"\"\"Query.\n\n        Query Amazon search and check for errors.\n\n        :return:\n            An lxml root element.\n        \"\"\"\n        response = self.api.ItemSearch(ResponseGroup=ResponseGroup, **kwargs)\n        root = objectify.fromstring(response)\n        if (hasattr(root.Items.Request, 'Errors') and\n                not hasattr(root.Items, 'Item')):\n            code = root.Items.Request.Errors.Error.Code\n            msg = root.Items.Request.Errors.Error.Message\n            if code == 'AWS.ParameterOutOfRange':\n                raise NoMorePages(msg)\n            elif code == 'HTTP Error 503':\n                raise RequestThrottled(\n                    \"Request Throttled Error: '{0}', '{1}'\".format(code, msg))\n            else:\n                raise SearchException(\n                    \"Amazon Search Error: '{0}', '{1}'\".format(code, msg))\n        if hasattr(root.Items, 'TotalPages'):\n            if root.Items.TotalPages == self.current_page:\n                self.is_last_page = True\n        return root"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ancestor(self):\n        ancestors = getattr(self.parsed_response, 'Ancestors', None)\n        if hasattr(ancestors, 'BrowseNode'):\n            return AmazonBrowseNode(ancestors['BrowseNode'])\n        return None", "response": "This browse node s immediate ancestor in the browse node tree."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ancestors(self):\n        ancestors = []\n        node = self.ancestor\n        while node is not None:\n            ancestors.append(node)\n            node = node.ancestor\n        return ancestors", "response": "A list of this browse node s ancestors in the browse node tree."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef children(self):\n        children = []\n        child_nodes = getattr(self.parsed_response, 'Children')\n        for child in getattr(child_nodes, 'BrowseNode', []):\n            children.append(AmazonBrowseNode(child))\n        return children", "response": "This browse node s children in the browse node tree."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef price_and_currency(self):\n        price = self._safe_get_element_text(\n            'Offers.Offer.OfferListing.SalePrice.Amount')\n        if price:\n            currency = self._safe_get_element_text(\n                'Offers.Offer.OfferListing.SalePrice.CurrencyCode')\n        else:\n            price = self._safe_get_element_text(\n                'Offers.Offer.OfferListing.Price.Amount')\n            if price:\n                currency = self._safe_get_element_text(\n                    'Offers.Offer.OfferListing.Price.CurrencyCode')\n            else:\n                price = self._safe_get_element_text(\n                    'OfferSummary.LowestNewPrice.Amount')\n                currency = self._safe_get_element_text(\n                    'OfferSummary.LowestNewPrice.CurrencyCode')\n        if price:\n            dprice = Decimal(\n                price) / 100 if 'JP' not in self.region else Decimal(price)\n            return dprice, currency\n        else:\n            return None, None", "response": "Get the offer price and currency."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the URL for the Offer.", "response": "def offer_url(self):\n        \"\"\"Offer URL\n\n        :return:\n            Offer URL (string).\n        \"\"\"\n        return \"{0}{1}/?tag={2}\".format(\n            AMAZON_ASSOCIATES_BASE_URL.format(domain=DOMAINS[self.region]),\n            self.asin,\n            self.aws_associate_tag)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef authors(self):\n        result = []\n        authors = self._safe_get_element('ItemAttributes.Author')\n        if authors is not None:\n            for author in authors:\n                result.append(author.text)\n        return result", "response": "Get a list of authors"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef creators(self):\n        # return tuples of name and role\n        result = []\n        creators = self._safe_get_element('ItemAttributes.Creator')\n        if creators is not None:\n            for creator in creators:\n                role = creator.attrib['Role'] if \\\n                    'Role' in creator.attrib else None\n                result.append((creator.text, role))\n        return result", "response": "Returns a list of tuples containing the name and role of the creators."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ean(self):\n        ean = self._safe_get_element_text('ItemAttributes.EAN')\n        if ean is None:\n            ean_list = self._safe_get_element_text('ItemAttributes.EANList')\n            if ean_list:\n                ean = self._safe_get_element_text(\n                    'EANListElement', root=ean_list[0])\n        return ean", "response": "Return the EAN of the item."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef upc(self):\n        upc = self._safe_get_element_text('ItemAttributes.UPC')\n        if upc is None:\n            upc_list = self._safe_get_element_text('ItemAttributes.UPCList')\n            if upc_list:\n                upc = self._safe_get_element_text(\n                    'UPCListElement', root=upc_list[0])\n        return upc", "response": "Return the UPC for the current item."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of all Editorial Review.", "response": "def editorial_reviews(self):\n        \"\"\"Editorial Review.\n\n        Returns a list of all editorial reviews.\n\n        :return:\n            A list containing:\n\n                Editorial Review (string)\n        \"\"\"\n        result = []\n        reviews_node = self._safe_get_element('EditorialReviews')\n\n        if reviews_node is not None:\n            for review_node in reviews_node.iterchildren():\n                content_node = getattr(review_node, 'Content')\n                if content_node is not None:\n                    result.append(content_node.text)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a set of languages in lower - case.", "response": "def languages(self):\n        \"\"\"Languages.\n\n        Returns a set of languages in lower-case.\n\n        :return:\n            Returns a set of languages in lower-case (strings).\n        \"\"\"\n        result = set()\n        languages = self._safe_get_element('ItemAttributes.Languages')\n        if languages is not None:\n            for language in languages.iterchildren():\n                text = self._safe_get_element_text('Name', language)\n                if text:\n                    result.add(text.lower())\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef features(self):\n        result = []\n        features = self._safe_get_element('ItemAttributes.Feature')\n        if features is not None:\n            for feature in features:\n                result.append(feature.text)\n        return result", "response": "Returns a list of feature descriptions."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_price(self):\n        price = self._safe_get_element_text('ItemAttributes.ListPrice.Amount')\n        currency = self._safe_get_element_text(\n            'ItemAttributes.ListPrice.CurrencyCode')\n        if price:\n            dprice = Decimal(\n                price) / 100 if 'JP' not in self.region else Decimal(price)\n            return dprice, currency\n        else:\n            return None, None", "response": "Returns a tuple containing the Decimal representation of price."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_attributes(self, name_list):\n        properties = {}\n        for name in name_list:\n            value = self.get_attribute(name)\n            if value is not None:\n                properties[name] = value\n        return properties", "response": "Get a list of attributes as a name - value dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_parent(self):\n        if not self.parent:\n            parent = self._safe_get_element('ParentASIN')\n            if parent:\n                self.parent = self.api.lookup(ItemId=parent)\n        return self.parent", "response": "Get parent product if it exists."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbrowses Nodes. :return: A list of :class:`~.AmazonBrowseNode` objects.", "response": "def browse_nodes(self):\n        \"\"\"Browse Nodes.\n\n        :return:\n            A list of :class:`~.AmazonBrowseNode` objects.\n        \"\"\"\n        root = self._safe_get_element('BrowseNodes')\n        if root is None:\n            return []\n\n        return [AmazonBrowseNode(child) for child in root.iterchildren()]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of images for a response.", "response": "def images(self):\n        \"\"\"List of images for a response.\n        When using lookup with RespnoseGroup 'Images', you'll get a\n        list of images. Parse them so they are returned in an easily\n        used list format.\n\n        :return:\n            A list of `ObjectifiedElement` images\n        \"\"\"\n        try:\n            images = [image for image in self._safe_get_element(\n                'ImageSets.ImageSet')]\n        except TypeError:  # No images in this ResponseGroup\n            images = []\n        return images"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef directors(self):\n        result = []\n        directors = self._safe_get_element('ItemAttributes.Director') or []\n        for director in directors:\n            result.append(director.text)\n        return result", "response": "Movie Directors.\n        - Gets the names of the directors of a movie."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _find_from_file(full_doc, from_file_keyword):\n    path = None\n\n    for line in full_doc.splitlines():\n        if from_file_keyword in line:\n            parts = line.strip().split(':')\n            if len(parts) == 2 and parts[0].strip() == from_file_keyword:\n                path = parts[1].strip()\n                break\n\n    return path", "response": "Find a line in the full_doc like\n\n        from_file_keyword and return path"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _extract_definitions(alist, level=None):\n\n    def _extract_array_defs(source):\n        # extract any definitions that are within arrays\n        # this occurs recursively\n        ret = []\n        items = source.get('items')\n        if items is not None and 'schema' in items:\n            ret += _extract_definitions([items], level+1)\n        return ret\n\n    # for tracking level of recursion\n    if level is None:\n        level = 0\n\n    defs = list()\n    if alist is not None:\n        for item in alist:\n            schema = item.get(\"schema\")\n            if schema is not None:\n                schema_id = schema.get(\"id\")\n                if schema_id is not None:\n                    defs.append(schema)\n                    ref = {\"$ref\": \"#/definitions/{}\".format(schema_id)}\n\n                    # only add the reference as a schema if we are in a response or\n                    # a parameter i.e. at the top level\n                    # directly ref if a definition is used within another definition\n                    if level == 0:\n                        item['schema'] = ref\n                    else:\n                        item.update(ref)\n                        del item['schema']\n\n                # extract any definitions that are within properties\n                # this occurs recursively\n                properties = schema.get('properties')\n                if properties is not None:\n                    defs += _extract_definitions(properties.values(), level+1)\n\n                defs += _extract_array_defs(schema)\n\n            defs += _extract_array_defs(item)\n\n    return defs", "response": "Extract the list of definitions from the given list of items and properties."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef swagger(app, prefix=None, process_doc=_sanitize,\n            from_file_keyword=None, template=None):\n    \"\"\"\n    Call this from an @app.route method like this\n    @app.route('/spec.json')\n    def spec():\n       return jsonify(swagger(app))\n\n    We go through all endpoints of the app searching for swagger endpoints\n    We provide the minimum required data according to swagger specs\n    Callers can and should add and override at will\n\n    Arguments:\n    app -- the flask app to inspect\n\n    Keyword arguments:\n    process_doc -- text sanitization method, the default simply replaces \\n with <br>\n    from_file_keyword -- how to specify a file to load doc from\n    template -- The spec to start with and update as flask-swagger finds paths.\n    \"\"\"\n    output = {\n        \"swagger\": \"2.0\",\n        \"info\": {\n            \"version\": \"0.0.0\",\n            \"title\": \"Cool product name\",\n        }\n    }\n    paths = defaultdict(dict)\n    definitions = defaultdict(dict)\n    if template is not None:\n        output.update(template)\n        # check for template provided paths and definitions\n        for k, v in output.get('paths', {}).items():\n            paths[k] = v\n        for k, v in output.get('definitions', {}).items():\n            definitions[k] = v\n    output[\"paths\"] = paths\n    output[\"definitions\"] = definitions\n\n    ignore_verbs = {\"HEAD\", \"OPTIONS\"}\n    # technically only responses is non-optional\n    optional_fields = ['tags', 'consumes', 'produces', 'schemes', 'security',\n                       'deprecated', 'operationId', 'externalDocs']\n\n    for rule in app.url_map.iter_rules():\n        if prefix and rule.rule[:len(prefix)] != prefix:\n            continue\n        endpoint = app.view_functions[rule.endpoint]\n        methods = dict()\n        for verb in rule.methods.difference(ignore_verbs):\n            verb = verb.lower()\n            if hasattr(endpoint, 'methods') \\\n                    and verb in map(lambda m: m.lower(), endpoint.methods) \\\n                    and hasattr(endpoint.view_class, verb):\n                methods[verb] = getattr(endpoint.view_class, verb)\n            else:\n                methods[verb] = endpoint\n        operations = dict()\n        for verb, method in methods.items():\n            summary, description, swag = _parse_docstring(method, process_doc,\n                                                          from_file_keyword)\n            if swag is not None:  # we only add endpoints with swagger data in the docstrings\n                defs = swag.get('definitions', [])\n                defs = _extract_definitions(defs)\n                params = swag.get('parameters', [])\n                defs += _extract_definitions(params)\n                responses = swag.get('responses', {})\n                responses = {\n                    str(key): value\n                    for key, value in responses.items()\n                }\n                if responses is not None:\n                    defs = defs + _extract_definitions(responses.values())\n                for definition in defs:\n                    def_id = definition.pop('id')\n                    if def_id is not None:\n                        definitions[def_id].update(definition)\n                operation = dict(\n                    summary=summary,\n                    description=description,\n                    responses=responses\n                )\n                # parameters - swagger ui dislikes empty parameter lists\n                if len(params) > 0:\n                    operation['parameters'] = params\n                # other optionals\n                for key in optional_fields:\n                    if key in swag:\n                        operation[key] = swag.get(key)\n                operations[verb] = operation\n\n        if len(operations):\n            rule = str(rule)\n            for arg in re.findall('(<([^<>]*:)?([^<>]*)>)', rule):\n                rule = rule.replace(arg[0], '{%s}' % arg[2])\n            paths[rule].update(operations)\n    return output", "response": "Return a dictionary that contains all the swagger - related information for the application."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the MIB symbol of the current object.", "response": "def getMibSymbol(self):\n        \"\"\"Returns MIB variable symbolic identification.\n\n        Returns\n        -------\n        str\n             MIB module name\n        str\n             MIB variable symbolic name\n        : :py:class:`~pysnmp.proto.rfc1902.ObjectName`\n             class instance representing MIB variable instance index.\n\n        Raises\n        ------\n        SmiError\n            If MIB variable conversion has not been performed.\n\n        Examples\n        --------\n        >>> objectIdentity = ObjectIdentity('1.3.6.1.2.1.1.1.0')\n        >>> objectIdentity.resolveWithMib(mibViewController)\n        >>> objectIdentity.getMibSymbol()\n        ('SNMPv2-MIB', 'sysDescr', (0,))\n        >>>\n        \"\"\"\n        if self._state & self.ST_CLEAN:\n            return self._modName, self._symName, self._indices\n\n        else:\n            raise SmiError(\n                '%s object not fully initialized' % self.__class__.__name__)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the OID identifying MIB variable including possible index part part.", "response": "def getOid(self):\n        \"\"\"Returns OID identifying MIB variable.\n\n        Returns\n        -------\n        : :py:class:`~pysnmp.proto.rfc1902.ObjectName`\n            full OID identifying MIB variable including possible index part.\n\n        Raises\n        ------\n        SmiError\n           If MIB variable conversion has not been performed.\n\n        Examples\n        --------\n        >>> objectIdentity = ObjectIdentity('SNMPv2-MIB', 'sysDescr', 0)\n        >>> objectIdentity.resolveWithMib(mibViewController)\n        >>> objectIdentity.getOid()\n        ObjectName('1.3.6.1.2.1.1.1.0')\n        >>>\n        \"\"\"\n        if self._state & self.ST_CLEAN:\n            return self._oid\n\n        else:\n            raise SmiError(\n                '%s object not fully initialized' % self.__class__.__name__)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a symbolic path to this MIB variable.", "response": "def getLabel(self):\n        \"\"\"Returns symbolic path to this MIB variable.\n\n        Meaning a sequence of symbolic identifications for each of parent\n        MIB objects in MIB tree.\n\n        Returns\n        -------\n        tuple\n            sequence of names of nodes in a MIB tree from the top of the tree\n            towards this MIB variable.\n\n        Raises\n        ------\n        SmiError\n           If MIB variable conversion has not been performed.\n\n        Notes\n        -----\n        Returned sequence may not contain full path to this MIB variable\n        if some symbols are now known at the moment of MIB look up.\n\n        Examples\n        --------\n        >>> objectIdentity = ObjectIdentity('SNMPv2-MIB', 'sysDescr', 0)\n        >>> objectIdentity.resolveWithMib(mibViewController)\n        >>> objectIdentity.getOid()\n        ('iso', 'org', 'dod', 'internet', 'mgmt', 'mib-2', 'system', 'sysDescr')\n        >>>\n        \"\"\"\n        if self._state & self.ST_CLEAN:\n            return self._label\n\n        else:\n            raise SmiError(\n                '%s object not fully initialized' % self.__class__.__name__)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding path to a repository to search ASN. 1 MIB files.", "response": "def addAsn1MibSource(self, *asn1Sources, **kwargs):\n        \"\"\"Adds path to a repository to search ASN.1 MIB files.\n\n        Parameters\n        ----------\n        *asn1Sources :\n            one or more URL in form of :py:obj:`str` identifying local or\n            remote ASN.1 MIB repositories. Path must include the *@mib@*\n            component which will be replaced with MIB module name at the\n            time of search.\n\n        Returns\n        -------\n        : :py:class:`~pysnmp.smi.rfc1902.ObjectIdentity`\n            reference to itself\n\n        Notes\n        -----\n        Please refer to :py:class:`~pysmi.reader.localfile.FileReader`,\n        :py:class:`~pysmi.reader.httpclient.HttpReader` and\n        :py:class:`~pysmi.reader.ftpclient.FtpReader` classes for\n        in-depth information on ASN.1 MIB lookup.\n\n        Examples\n        --------\n        >>> ObjectIdentity('SNMPv2-MIB', 'sysDescr').addAsn1Source('http://mibs.snmplabs.com/asn1/@mib@')\n        ObjectIdentity('SNMPv2-MIB', 'sysDescr')\n        >>>\n        \"\"\"\n        if self._asn1SourcesToAdd is None:\n            self._asn1SourcesToAdd = asn1Sources\n\n        else:\n            self._asn1SourcesToAdd += asn1Sources\n\n        if self._asn1SourcesOptions:\n            self._asn1SourcesOptions.update(kwargs)\n\n        else:\n            self._asn1SourcesOptions = kwargs\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd path to repository to search PySNMP MIB files.", "response": "def addMibSource(self, *mibSources):\n        \"\"\"Adds path to repository to search PySNMP MIB files.\n\n        Parameters\n        ----------\n        *mibSources :\n            one or more paths to search or Python package names to import\n            and search for PySNMP MIB modules.\n\n        Returns\n        -------\n        : :py:class:`~pysnmp.smi.rfc1902.ObjectIdentity`\n            reference to itself\n\n        Notes\n        -----\n        Normally, ASN.1-to-Python MIB modules conversion is performed\n        automatically through PySNMP/PySMI interaction. ASN1 MIB modules\n        could also be manually compiled into Python via the\n        `mibdump.py <http://snmplabs.com/pysmi/mibdump.html>`_\n        tool.\n\n        Examples\n        --------\n        >>> ObjectIdentity('SNMPv2-MIB', 'sysDescr').addMibSource('/opt/pysnmp/mibs', 'pysnmp_mibs')\n        ObjectIdentity('SNMPv2-MIB', 'sysDescr')\n        >>>\n        \"\"\"\n        if self._mibSourcesToAdd is None:\n            self._mibSourcesToAdd = mibSources\n\n        else:\n            self._mibSourcesToAdd += mibSources\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef loadMibs(self, *modNames):\n        if self._modNamesToLoad is None:\n            self._modNamesToLoad = modNames\n\n        else:\n            self._modNamesToLoad += modNames\n\n        return self", "response": "Schedules search and load of given MIB modules."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nperform MIB variable ID conversion.", "response": "def resolveWithMib(self, mibViewController):\n        \"\"\"Perform MIB variable ID conversion.\n\n        Parameters\n        ----------\n        mibViewController : :py:class:`~pysnmp.smi.view.MibViewController`\n            class instance representing MIB browsing functionality.\n\n        Returns\n        -------\n        : :py:class:`~pysnmp.smi.rfc1902.ObjectIdentity`\n            reference to itself\n\n        Raises\n        ------\n        SmiError\n           In case of fatal MIB hanling errora\n\n        Notes\n        -----\n        Calling this method might cause the following sequence of\n        events (exact details depends on many factors):\n\n        * ASN.1 MIB file downloaded and handed over to\n          :py:class:`~pysmi.compiler.MibCompiler` for conversion into\n          Python MIB module (based on pysnmp classes)\n        * Python MIB module is imported by SNMP engine, internal indices\n          created\n        * :py:class:`~pysnmp.smi.view.MibViewController` looks up the\n          rest of MIB identification information based on whatever information\n          is already available, :py:class:`~pysnmp.smi.rfc1902.ObjectIdentity`\n          class instance\n          gets updated and ready for further use.\n\n        Examples\n        --------\n        >>> objectIdentity = ObjectIdentity('SNMPv2-MIB', 'sysDescr')\n        >>> objectIdentity.resolveWithMib(mibViewController)\n        ObjectIdentity('SNMPv2-MIB', 'sysDescr')\n        >>>\n        \"\"\"\n        if self._mibSourcesToAdd is not None:\n            debug.logger & debug.FLAG_MIB and debug.logger(\n                'adding MIB sources %s' % ', '.join(self._mibSourcesToAdd))\n\n            mibViewController.mibBuilder.addMibSources(\n                *[ZipMibSource(x) for x in self._mibSourcesToAdd])\n\n            self._mibSourcesToAdd = None\n\n        if self._asn1SourcesToAdd is None:\n            addMibCompiler(\n                mibViewController.mibBuilder,\n                ifAvailable=True, ifNotAdded=True)\n\n        else:\n            debug.logger & debug.FLAG_MIB and debug.logger(\n                'adding MIB compiler with source paths '\n                '%s' % ', '.join(self._asn1SourcesToAdd))\n\n            addMibCompiler(\n                mibViewController.mibBuilder,\n                sources=self._asn1SourcesToAdd,\n                searchers=self._asn1SourcesOptions.get('searchers'),\n                borrowers=self._asn1SourcesOptions.get('borrowers'),\n                destination=self._asn1SourcesOptions.get('destination'),\n                ifAvailable=self._asn1SourcesOptions.get('ifAvailable'),\n                ifNotAdded=self._asn1SourcesOptions.get('ifNotAdded')\n            )\n\n            self._asn1SourcesToAdd = self._asn1SourcesOptions = None\n\n        if self._modNamesToLoad is not None:\n            debug.logger & debug.FLAG_MIB and debug.logger(\n                'loading MIB modules %s' % ', '.join(self._modNamesToLoad))\n\n            mibViewController.mibBuilder.loadModules(*self._modNamesToLoad)\n\n            self._modNamesToLoad = None\n\n        if self._state & self.ST_CLEAN:\n            return self\n\n        MibScalar, MibTableColumn = mibViewController.mibBuilder.importSymbols(\n            'SNMPv2-SMI', 'MibScalar', 'MibTableColumn')\n\n        self._indices = ()\n\n        if isinstance(self._args[0], ObjectIdentity):\n            self._args[0].resolveWithMib(mibViewController)\n\n        if len(self._args) == 1:  # OID or label or MIB module\n            debug.logger & debug.FLAG_MIB and debug.logger(\n                'resolving %s as OID or label' % self._args)\n\n            try:\n                # pyasn1 ObjectIdentifier or sequence of ints or string OID\n                self._oid = rfc1902.ObjectName(self._args[0])  # OID\n\n            except PyAsn1Error:\n                # sequence of sub-OIDs and labels\n                if isinstance(self._args[0], (list, tuple)):\n                    prefix, label, suffix = mibViewController.getNodeName(\n                        self._args[0])\n\n                # string label\n                elif '.' in self._args[0]:\n                    prefix, label, suffix = mibViewController.getNodeNameByOid(\n                        tuple(self._args[0].split('.')))\n\n                # MIB module name\n                else:\n                    modName = self._args[0]\n\n                    mibViewController.mibBuilder.loadModules(modName)\n\n                    if self._kwargs.get('last'):\n                        (prefix, label,\n                         suffix) = mibViewController.getLastNodeName(modName)\n\n                    else:\n                        (prefix, label,\n                         suffix) = mibViewController.getFirstNodeName(modName)\n\n                if suffix:\n                    try:\n                        suffix = tuple(int(x) for x in suffix)\n\n                    except ValueError:\n                        raise SmiError(\n                            'Unknown object name component %r' % (suffix,))\n\n                self._oid = rfc1902.ObjectName(prefix + suffix)\n\n            else:\n                prefix, label, suffix = mibViewController.getNodeNameByOid(\n                    self._oid)\n\n            debug.logger & debug.FLAG_MIB and debug.logger(\n                'resolved %r into prefix %r and suffix '\n                '%r' % (self._args, prefix, suffix))\n\n            modName, symName, _ = mibViewController.getNodeLocation(prefix)\n\n            self._modName = modName\n            self._symName = symName\n\n            self._label = label\n\n            mibNode, = mibViewController.mibBuilder.importSymbols(\n                modName, symName)\n\n            self._mibNode = mibNode\n\n            debug.logger & debug.FLAG_MIB and debug.logger(\n                'resolved prefix %r into MIB node %r' % (prefix, mibNode))\n\n            if isinstance(mibNode, MibTableColumn):  # table column\n                if suffix:\n                    rowModName, rowSymName, _ = mibViewController.getNodeLocation(\n                        mibNode.name[:-1]\n                    )\n\n                    rowNode, = mibViewController.mibBuilder.importSymbols(\n                        rowModName, rowSymName\n                    )\n\n                    self._indices = rowNode.getIndicesFromInstId(suffix)\n\n            elif isinstance(mibNode, MibScalar):  # scalar\n                if suffix:\n                    self._indices = (rfc1902.ObjectName(suffix),)\n\n            else:\n                if suffix:\n                    self._indices = (rfc1902.ObjectName(suffix),)\n\n            self._state |= self.ST_CLEAN\n\n            debug.logger & debug.FLAG_MIB and debug.logger(\n                'resolved indices are %r' % (self._indices,))\n\n            return self\n\n        elif len(self._args) > 1:  # MIB, symbol[, index, index ...]\n            # MIB, symbol, index, index\n            if self._args[0] and self._args[1]:\n                self._modName = self._args[0]\n                self._symName = self._args[1]\n\n            # MIB, ''\n            elif self._args[0]:\n                mibViewController.mibBuilder.loadModules(self._args[0])\n\n                if self._kwargs.get('last'):\n                    (prefix, label,\n                     suffix) = mibViewController.getLastNodeName(self._args[0])\n\n                else:\n                    (prefix, label,\n                     suffix) = mibViewController.getFirstNodeName(self._args[0])\n\n                (self._modName,\n                 self._symName, _) = mibViewController.getNodeLocation(prefix)\n\n            # '', symbol, index, index\n            else:\n                (prefix, label,\n                 suffix) = mibViewController.getNodeName(self._args[1:])\n\n                (self._modName,\n                 self._symName, _) = mibViewController.getNodeLocation(prefix)\n\n            mibNode, = mibViewController.mibBuilder.importSymbols(\n                self._modName, self._symName)\n\n            self._mibNode = mibNode\n\n            self._oid = rfc1902.ObjectName(mibNode.getName())\n\n            (prefix, label,\n             suffix) = mibViewController.getNodeNameByOid(\n                self._oid)\n\n            self._label = label\n\n            debug.logger & debug.FLAG_MIB and debug.logger(\n                'resolved %r into prefix %r and suffix '\n                '%r' % (self._args, prefix, suffix))\n\n            if isinstance(mibNode, MibTableColumn):  # table\n                rowModName, rowSymName, _ = mibViewController.getNodeLocation(\n                    mibNode.name[:-1])\n\n                rowNode, = mibViewController.mibBuilder.importSymbols(\n                    rowModName, rowSymName)\n\n                if self._args[2:]:\n                    try:\n                        instIds = rowNode.getInstIdFromIndices(*self._args[2:])\n                        self._oid += instIds\n                        self._indices = rowNode.getIndicesFromInstId(instIds)\n\n                    except PyAsn1Error as exc:\n                        raise SmiError(\n                            'Instance index %r to OID conversion failure '\n                            'at object %r: '\n                            '%s' % (self._args[2:], mibNode.getLabel(), exc))\n\n            elif self._args[2:]:  # any other kind of MIB node with indices\n                if self._args[2:]:\n                    instId = rfc1902.ObjectName(\n                        '.'.join(str(x) for x in self._args[2:]))\n\n                    self._oid += instId\n\n                    self._indices = (instId,)\n\n            self._state |= self.ST_CLEAN\n\n            debug.logger & debug.FLAG_MIB and debug.logger(\n                'resolved indices are %r' % (self._indices,))\n\n            return self\n\n        else:\n            raise SmiError('Non-OID, label or MIB symbol')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds path to a repository to search ASN. 1 MIB files.", "response": "def addAsn1MibSource(self, *asn1Sources, **kwargs):\n        \"\"\"Adds path to a repository to search ASN.1 MIB files.\n\n        Parameters\n        ----------\n        *asn1Sources :\n            one or more URL in form of :py:obj:`str` identifying local or\n            remote ASN.1 MIB repositories. Path must include the *@mib@*\n            component which will be replaced with MIB module name at the\n            time of search.\n\n        Returns\n        -------\n        : :py:class:`~pysnmp.smi.rfc1902.ObjectType`\n            reference to itself\n\n        Notes\n        -----\n        Please refer to :py:class:`~pysmi.reader.localfile.FileReader`,\n        :py:class:`~pysmi.reader.httpclient.HttpReader` and\n        :py:class:`~pysmi.reader.ftpclient.FtpReader` classes for\n        in-depth information on ASN.1 MIB lookup.\n\n        Examples\n        --------\n        >>> ObjectType(ObjectIdentity('SNMPv2-MIB', 'sysDescr')).addAsn1Source('http://mibs.snmplabs.com/asn1/@mib@')\n        ObjectType(ObjectIdentity('SNMPv2-MIB', 'sysDescr'))\n        >>>\n\n        \"\"\"\n        self._args[0].addAsn1MibSource(*asn1Sources, **kwargs)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nperform MIB variable ID and associated value conversion.", "response": "def resolveWithMib(self, mibViewController):\n        \"\"\"Perform MIB variable ID and associated value conversion.\n\n        Parameters\n        ----------\n        mibViewController : :py:class:`~pysnmp.smi.view.MibViewController`\n            class instance representing MIB browsing functionality.\n\n        Returns\n        -------\n        : :py:class:`~pysnmp.smi.rfc1902.ObjectType`\n            reference to itself\n\n        Raises\n        ------\n        SmiError\n           In case of fatal MIB hanling errora\n\n        Notes\n        -----\n        Calling this method involves\n        :py:meth:`~pysnmp.smi.rfc1902.ObjectIdentity.resolveWithMib`\n        method invocation.\n\n        Examples\n        --------\n        >>> from pysmi.hlapi import varbinds\n        >>> mibViewController = varbinds.AbstractVarBinds.getMibViewController( engine )\n        >>> objectType = ObjectType(ObjectIdentity('SNMPv2-MIB', 'sysDescr'), 'Linux i386')\n        >>> objectType.resolveWithMib(mibViewController)\n        ObjectType(ObjectIdentity('SNMPv2-MIB', 'sysDescr'), DisplayString('Linux i386'))\n        >>> str(objectType)\n        'SNMPv2-MIB::sysDescr.\"0\" = Linux i386'\n        >>>\n\n        \"\"\"\n        if self._state & self.ST_CLEAM:\n            return self\n\n        self._args[0].resolveWithMib(mibViewController)\n\n        MibScalar, MibTableColumn = mibViewController.mibBuilder.importSymbols(\n            'SNMPv2-SMI', 'MibScalar', 'MibTableColumn')\n\n        if not isinstance(self._args[0].getMibNode(),\n                          (MibScalar, MibTableColumn)):\n            if not isinstance(self._args[1], AbstractSimpleAsn1Item):\n                raise SmiError('MIB object %r is not OBJECT-TYPE '\n                               '(MIB not loaded?)' % (self._args[0],))\n\n            self._state |= self.ST_CLEAM\n\n            return self\n\n        if isinstance(self._args[1], (rfc1905.UnSpecified,\n                                      rfc1905.NoSuchObject,\n                                      rfc1905.NoSuchInstance,\n                                      rfc1905.EndOfMibView)):\n            self._state |= self.ST_CLEAM\n            return self\n\n        syntax = self._args[0].getMibNode().getSyntax()\n\n        try:\n            self._args[1] = syntax.clone(self._args[1])\n\n        except PyAsn1Error as exc:\n            raise SmiError(\n                'MIB object %r having type %r failed to cast value '\n                '%r: %s' % (self._args[0].prettyPrint(),\n                            syntax.__class__.__name__, self._args[1], exc))\n\n        if rfc1902.ObjectIdentifier().isSuperTypeOf(\n                self._args[1], matchConstraints=False):\n            self._args[1] = ObjectIdentity(\n                self._args[1]).resolveWithMib(mibViewController)\n\n        self._state |= self.ST_CLEAM\n\n        debug.logger & debug.FLAG_MIB and debug.logger(\n            'resolved %r syntax is %r' % (self._args[0], self._args[1]))\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nappends variable - binding to the current object.", "response": "def addVarBinds(self, *varBinds):\n        \"\"\"Appends variable-binding to notification.\n\n        Parameters\n        ----------\n        *varBinds : :py:class:`~pysnmp.smi.rfc1902.ObjectType`\n            One or more :py:class:`~pysnmp.smi.rfc1902.ObjectType` class\n            instances.\n\n        Returns\n        -------\n        : :py:class:`~pysnmp.smi.rfc1902.NotificationType`\n            reference to itself\n\n        Notes\n        -----\n        This method can be used to add custom variable-bindings to\n        notification message in addition to MIB variables specified\n        in NOTIFICATION-TYPE->OBJECTS clause.\n\n        Examples\n        --------\n        >>> nt = NotificationType(ObjectIdentity('IP-MIB', 'linkDown'))\n        >>> nt.addVarBinds(ObjectType(ObjectIdentity('SNMPv2-MIB', 'sysDescr', 0)))\n        NotificationType(ObjectIdentity('IP-MIB', 'linkDown'), (), {})\n        >>>\n        \"\"\"\n        debug.logger & debug.FLAG_MIB and debug.logger(\n            'additional var-binds: %r' % (varBinds,))\n\n        if self._state & self.ST_CLEAN:\n            raise SmiError(\n                '%s object is already sealed' % self.__class__.__name__)\n\n        else:\n            self._additionalVarBinds.extend(varBinds)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds path to a repository to search ASN. 1 MIB files.", "response": "def addAsn1MibSource(self, *asn1Sources, **kwargs):\n        \"\"\"Adds path to a repository to search ASN.1 MIB files.\n\n        Parameters\n        ----------\n        *asn1Sources :\n            one or more URL in form of :py:obj:`str` identifying local or\n            remote ASN.1 MIB repositories. Path must include the *@mib@*\n            component which will be replaced with MIB module name at the\n            time of search.\n\n        Returns\n        -------\n        : :py:class:`~pysnmp.smi.rfc1902.NotificationType`\n            reference to itself\n\n        Notes\n        -----\n        Please refer to :py:class:`~pysmi.reader.localfile.FileReader`,\n        :py:class:`~pysmi.reader.httpclient.HttpReader` and\n        :py:class:`~pysmi.reader.ftpclient.FtpReader` classes for\n        in-depth information on ASN.1 MIB lookup.\n\n        Examples\n        --------\n        >>> NotificationType(ObjectIdentity('IF-MIB', 'linkDown'), (), {}).addAsn1Source('http://mibs.snmplabs.com/asn1/@mib@')\n        NotificationType(ObjectIdentity('IF-MIB', 'linkDown'), (), {})\n        >>>\n        \"\"\"\n        self._objectIdentity.addAsn1MibSource(*asn1Sources, **kwargs)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef resolveWithMib(self, mibViewController):\n        if self._state & self.ST_CLEAN:\n            return self\n\n        self._objectIdentity.resolveWithMib(mibViewController)\n\n        self._varBinds.append(\n            ObjectType(ObjectIdentity(v2c.apiTrapPDU.snmpTrapOID),\n                       self._objectIdentity).resolveWithMib(mibViewController))\n\n        SmiNotificationType, = mibViewController.mibBuilder.importSymbols(\n            'SNMPv2-SMI', 'NotificationType')\n\n        mibNode = self._objectIdentity.getMibNode()\n\n        varBindsLocation = {}\n\n        if isinstance(mibNode, SmiNotificationType):\n\n            for notificationObject in mibNode.getObjects():\n                objectIdentity = ObjectIdentity(\n                    *notificationObject + self._instanceIndex)\n\n                objectIdentity.resolveWithMib(mibViewController)\n\n                objectType = ObjectType(\n                    objectIdentity, self._objects.get(\n                        notificationObject, rfc1905.unSpecified))\n\n                objectType.resolveWithMib(mibViewController)\n\n                self._varBinds.append(objectType)\n\n                varBindsLocation[objectIdentity] = len(self._varBinds) - 1\n\n        else:\n            debug.logger & debug.FLAG_MIB and debug.logger(\n                'WARNING: MIB object %r is not NOTIFICATION-TYPE (MIB not '\n                'loaded?)' % (self._objectIdentity,))\n\n        for varBinds in self._additionalVarBinds:\n            if not isinstance(varBinds, ObjectType):\n                varBinds = ObjectType(ObjectIdentity(varBinds[0]), varBinds[1])\n\n            varBinds.resolveWithMib(mibViewController)\n\n            if varBinds[0] in varBindsLocation:\n                self._varBinds[varBindsLocation[varBinds[0]]] = varBinds\n\n            else:\n                self._varBinds.append(varBinds)\n\n        self._additionalVarBinds = []\n\n        self._state |= self.ST_CLEAN\n\n        debug.logger & debug.FLAG_MIB and debug.logger(\n            'resolved %r into %r' % (self._objectIdentity, self._varBinds))\n\n        return self", "response": "Perform MIB variable ID conversion and notification objects expansion."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef withValues(cls, *values):\n\n        class X(cls):\n            subtypeSpec = cls.subtypeSpec + constraint.SingleValueConstraint(\n                *values)\n\n        X.__name__ = cls.__name__\n        return X", "response": "Creates a subclass with discreet values constraint.\n            is a subclass of the base class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef withRange(cls, minimum, maximum):\n\n        class X(cls):\n            subtypeSpec = cls.subtypeSpec + constraint.ValueRangeConstraint(\n                minimum, maximum)\n\n        X.__name__ = cls.__name__\n        return X", "response": "Creates a subclass with value range constraint."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a subclass with discreet named values constraint.", "response": "def withNamedValues(cls, **values):\n        \"\"\"Create a subclass with discreet named values constraint.\n\n        Reduce fully duplicate enumerations along the way.\n        \"\"\"\n        enums = set(cls.namedValues.items())\n        enums.update(values.items())\n\n        class X(cls):\n            namedValues = namedval.NamedValues(*enums)\n            subtypeSpec = cls.subtypeSpec + constraint.SingleValueConstraint(\n                *values.values())\n\n        X.__name__ = cls.__name__\n\n        return X"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef withSize(cls, minimum, maximum):\n\n        class X(cls):\n            subtypeSpec = cls.subtypeSpec + constraint.ValueSizeConstraint(\n                minimum, maximum)\n\n        X.__name__ = cls.__name__\n        return X", "response": "Creates a subclass with value size constraint."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef withNamedBits(cls, **values):\n        enums = set(cls.namedValues.items())\n        enums.update(values.items())\n\n        class X(cls):\n            namedValues = namedval.NamedValues(*enums)\n\n        X.__name__ = cls.__name__\n        return X", "response": "Creates a subclass with discreet named bits constraint."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends a new notification to the specified context.", "response": "def sendNotification(snmpEngine, authData, transportTarget, contextData,\n                     notifyType, *varBinds, **options):\n    \"\"\"Send SNMP notification.\n\n    Based on passed parameters, prepares SNMP TRAP or INFORM\n    notification (:RFC:`1905#section-4.2.6`) and schedules its\n    transmission by I/O framework at a later point of time.\n\n    Parameters\n    ----------\n    snmpEngine : :py:class:`~pysnmp.hlapi.SnmpEngine`\n        Class instance representing SNMP engine.\n\n    authData : :py:class:`~pysnmp.hlapi.CommunityData` or :py:class:`~pysnmp.hlapi.UsmUserData`\n        Class instance representing SNMP credentials.\n\n    transportTarget : :py:class:`~pysnmp.hlapi.asyncore.UdpTransportTarget` or :py:class:`~pysnmp.hlapi.asyncore.Udp6TransportTarget`\n        Class instance representing transport type along with SNMP peer\n        address.\n\n    contextData : :py:class:`~pysnmp.hlapi.ContextData`\n        Class instance representing SNMP ContextEngineId and ContextName\n        values.\n\n    notifyType : str\n        Indicates type of notification to be sent. Recognized literal\n        values are *trap* or *inform*.\n\n    \\*varBinds: :class:`tuple` of OID-value pairs or :py:class:`~pysnmp.smi.rfc1902.ObjectType` or :py:class:`~pysnmp.smi.rfc1902.NotificationType`\n        One or more objects representing MIB variables to place\n        into SNMP notification. It could be tuples of OID-values\n        or :py:class:`~pysnmp.smi.rfc1902.ObjectType` class instances\n        of :py:class:`~pysnmp.smi.rfc1902.NotificationType` objects.\n\n        SNMP Notification PDU includes some housekeeping items that\n        are required for SNMP to function.\n\n        Agent information:\n\n        * SNMPv2-MIB::sysUpTime.0 = <agent uptime>\n        * SNMPv2-SMI::snmpTrapOID.0 = {SNMPv2-MIB::coldStart, ...}\n\n        Applicable to SNMP v1 TRAP:\n\n        * SNMP-COMMUNITY-MIB::snmpTrapAddress.0 = <agent-IP>\n        * SNMP-COMMUNITY-MIB::snmpTrapCommunity.0 = <snmp-community-name>\n        * SNMP-COMMUNITY-MIB::snmpTrapEnterprise.0 = <enterprise-OID>\n\n        .. note::\n\n           Unless user passes some of these variable-bindings, `.sendNotification()`\n           call will fill in the missing items.\n\n        User variable-bindings:\n\n        * SNMPv2-SMI::NOTIFICATION-TYPE\n        * SNMPv2-SMI::OBJECT-TYPE\n\n        .. note::\n\n           The :py:class:`~pysnmp.smi.rfc1902.NotificationType` object ensures\n           properly formed SNMP notification (to comply MIB definition). If you\n           build notification PDU out of :py:class:`~pysnmp.smi.rfc1902.ObjectType`\n           objects or simple tuples of OID-value objects, it is your responsibility\n           to provide well-formed notification payload.\n\n    Other Parameters\n    ----------------\n    \\*\\*options:\n\n        * lookupMib: bool\n            `lookupMib` - load MIB and resolve response MIB variables at\n            the cost of slightly reduced performance. Default is `True`.\n        * cbFun: callable\n            user-supplied callable that is invoked to pass SNMP response\n            to *INFORM* notification or error to user at a later point of\n            time. The `cbFun` callable is never invoked for *TRAP* notifications.\n        * cbCtx: object\n            user-supplied object passing additional parameters to/from\n            `cbFun`\n\n    Notes\n    -----\n    User-supplied `cbFun` callable must have the following call\n    signature:\n\n    * snmpEngine (:py:class:`~pysnmp.hlapi.SnmpEngine`):\n      Class instance representing SNMP engine.\n    * sendRequestHandle (int): Unique request identifier. Can be used\n      for matching multiple ongoing *INFORM* notifications with received\n      responses.\n    * errorIndication (str): True value indicates SNMP engine error.\n    * errorStatus (str): True value indicates SNMP PDU error.\n    * errorIndex (int): Non-zero value refers to `varBinds[errorIndex-1]`\n    * varBinds (tuple): A sequence of\n      :py:class:`~pysnmp.smi.rfc1902.ObjectType` class instances\n      representing MIB variables returned in SNMP response in exactly\n      the same order as `varBinds` in request.\n    * `cbCtx` : Original user-supplied object.\n\n    Returns\n    -------\n    sendRequestHandle : int\n        Unique request identifier. Can be used for matching received\n        responses with ongoing *INFORM* requests. Returns `None` for\n        *TRAP* notifications.\n\n    Raises\n    ------\n    PySnmpError\n        Or its derivative indicating that an error occurred while\n        performing SNMP operation.\n\n    Examples\n    --------\n    >>> from pysnmp.hlapi.asyncore import *\n    >>>\n    >>> snmpEngine = SnmpEngine()\n    >>> sendNotification(\n    ...     snmpEngine,\n    ...     CommunityData('public'),\n    ...     UdpTransportTarget(('demo.snmplabs.com', 162)),\n    ...     ContextData(),\n    ...     'trap',\n    ...     NotificationType(ObjectIdentity('SNMPv2-MIB', 'coldStart')),\n    ... )\n    >>> snmpEngine.transportDispatcher.runDispatcher()\n    >>>\n\n    \"\"\"\n\n    # noinspection PyShadowingNames\n    def __cbFun(snmpEngine, sendRequestHandle, errorIndication,\n                errorStatus, errorIndex, varBinds, cbCtx):\n\n        lookupMib, cbFun, cbCtx = cbCtx\n\n        varBinds = VB_PROCESSOR.unmakeVarBinds(\n            snmpEngine.cache, varBinds, lookupMib)\n\n        return cbFun and cbFun(\n            snmpEngine, sendRequestHandle, errorIndication,\n            errorStatus, errorIndex, varBinds, cbCtx)\n\n    notifyName = LCD.configure(snmpEngine, authData, transportTarget,\n                               notifyType, contextData.contextName)\n\n    varBinds = VB_PROCESSOR.makeVarBinds(snmpEngine.cache, varBinds)\n\n    return ntforg.NotificationOriginator().sendVarBinds(\n        snmpEngine, notifyName,\n        contextData.contextEngineId, contextData.contextName,\n        varBinds, __cbFun, (options.get('lookupMib', True),\n                            options.get('cbFun'), options.get('cbCtx')))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getCmd(snmpDispatcher, authData, transportTarget,\n           *varBinds, **options):\n    \"\"\"Creates a generator to perform SNMP GET query.\n\n    When iterator gets advanced by :py:mod:`asyncio` main loop,\n    SNMP GET request is sent (:RFC:`1905#section-4.2.1`).\n    The iterator yields :py:class:`asyncio.Future` which gets done whenever\n    response arrives or error occurs.\n\n    Parameters\n    ----------\n    snmpDispatcher: :py:class:`~pysnmp.hlapi.v1arch.asyncore.SnmpDispatcher`\n        Class instance representing asynio-based asynchronous event loop and\n        associated state information.\n\n    authData: :py:class:`~pysnmp.hlapi.v1arch.CommunityData`\n        Class instance representing SNMPv1/v2c credentials.\n\n    transportTarget: :py:class:`~pysnmp.hlapi.v1arch.asyncio.UdpTransportTarget` or\n        :py:class:`~pysnmp.hlapi.v1arch.asyncio.Udp6TransportTarget` Class instance representing\n        transport type along with SNMP peer address.\n\n    \\*varBinds: :class:`tuple` of OID-value pairs or :py:class:`~pysnmp.smi.rfc1902.ObjectType`\n        One or more class instances representing MIB variables to place\n        into SNMP request.\n\n    Note\n    ----\n    The `SnmpDispatcher` object may be expensive to create, therefore it is\n    advised to maintain it for the lifecycle of the application/thread for\n    as long as possible.\n\n    Other Parameters\n    ----------------\n    \\*\\*options :\n        Request options:\n\n        * `lookupMib` - load MIB and resolve response MIB variables at\n          the cost of slightly reduced performance. Default is `False`,\n          unless :py:class:`~pysnmp.smi.rfc1902.ObjectType` is present\n          among `varBinds` in which case `lookupMib` gets automatically\n          enabled.\n\n    Yields\n    ------\n    errorIndication: str\n        True value indicates SNMP engine error.\n    errorStatus: str\n        True value indicates SNMP PDU error.\n    errorIndex: int\n        Non-zero value refers to `varBinds[errorIndex-1]`\n    varBinds: tuple\n        A sequence of OID-value pairs in form of base SNMP types (if\n        `lookupMib` is `False`) or :py:class:`~pysnmp.smi.rfc1902.ObjectType`\n        class instances (if `lookupMib` is `True`) representing MIB variables\n        returned in SNMP response.\n\n    Raises\n    ------\n    PySnmpError\n        Or its derivative indicating that an error occurred while\n        performing SNMP operation.\n\n    Examples\n    --------\n    >>> import asyncio\n    >>> from pysnmp.hlapi.v1arch.asyncio import *\n    >>>\n    >>> @asyncio.coroutine\n    ... def run():\n    ...     errorIndication, errorStatus, errorIndex, varBinds = yield from getCmd(\n    ...         SnmpDispatcher(),\n    ...         CommunityData('public'),\n    ...         UdpTransportTarget(('demo.snmplabs.com', 161)),\n    ...         ObjectType(ObjectIdentity('SNMPv2-MIB', 'sysDescr', 0))\n    ...     )\n    ...     print(errorIndication, errorStatus, errorIndex, varBinds)\n    >>>\n    >>> asyncio.get_event_loop().run_until_complete(run())\n    (None, 0, 0, [ObjectType(ObjectIdentity(ObjectName('1.3.6.1.2.1.1.1.0')), DisplayString('SunOS zeus.snmplabs.com 4.1.3_U1 1 sun4m'))])\n    >>>\n    \"\"\"\n\n    def _cbFun(snmpDispatcher, stateHandle, errorIndication, rspPdu, _cbCtx):\n        if future.cancelled():\n            return\n\n        errorStatus = pMod.apiPDU.getErrorStatus(rspPdu)\n        errorIndex = pMod.apiPDU.getErrorIndex(rspPdu)\n\n        varBinds = pMod.apiPDU.getVarBinds(rspPdu)\n\n        if lookupMib:\n            try:\n                varBinds = VB_PROCESSOR.unmakeVarBinds(\n                    snmpDispatcher.cache, varBinds, lookupMib)\n\n            except Exception as e:\n                future.set_exception(e)\n                return\n\n        future.set_result(\n            (errorIndication, errorStatus, errorIndex, varBinds)\n        )\n\n    lookupMib = options.get('lookupMib')\n\n    if not lookupMib and any(isinstance(x, ObjectType) for x in varBinds):\n        lookupMib = True\n\n    if lookupMib:\n        varBinds = VB_PROCESSOR.makeVarBinds(snmpDispatcher.cache, varBinds)\n\n    pMod = api.PROTOCOL_MODULES[authData.mpModel]\n\n    reqPdu = pMod.GetRequestPDU()\n    pMod.apiPDU.setDefaults(reqPdu)\n    pMod.apiPDU.setVarBinds(reqPdu, varBinds)\n\n    future = asyncio.Future()\n\n    snmpDispatcher.sendPdu(authData, transportTarget, reqPdu, cbFun=_cbFun)\n\n    return future", "response": "Returns a generator that yields a single object representing the current state of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef loadModule(self, modName, **userCtx):\n        for mibSource in self._mibSources:\n            debug.logger & debug.FLAG_BLD and debug.logger(\n                'loadModule: trying %s at %s' % (modName, mibSource))\n\n            try:\n                codeObj, sfx = mibSource.read(modName)\n\n            except IOError as exc:\n                debug.logger & debug.FLAG_BLD and debug.logger(\n                    'loadModule: read %s from %s failed: '\n                    '%s' % (modName, mibSource, exc))\n                continue\n\n            modPath = mibSource.fullPath(modName, sfx)\n\n            if modPath in self._modPathsSeen:\n                debug.logger & debug.FLAG_BLD and debug.logger(\n                    'loadModule: seen %s' % modPath)\n                break\n\n            else:\n                self._modPathsSeen.add(modPath)\n\n            debug.logger & debug.FLAG_BLD and debug.logger(\n                'loadModule: evaluating %s' % modPath)\n\n            g = {'mibBuilder': self,\n                 'userCtx': userCtx}\n\n            try:\n                exec(codeObj, g)\n\n            except Exception:\n                self._modPathsSeen.remove(modPath)\n                raise error.MibLoadError(\n                    'MIB module \"%s\" load error: '\n                    '%s' % (modPath, traceback.format_exception(*sys.exc_info())))\n\n            self._modSeen[modName] = modPath\n\n            debug.logger & debug.FLAG_BLD and debug.logger(\n                'loadModule: loaded %s' % modPath)\n\n            break\n\n        if modName not in self._modSeen:\n            raise error.MibNotFoundError(\n                'MIB file \"%s\" not found in search path '\n                '(%s)' % (modName and modName + \".py[co]\", ', '.join(\n                    [str(x) for x in self._mibSources])))\n\n        return self", "response": "Load and execute MIB modules as Python code"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads pysnmp MIB modules", "response": "def loadModules(self, *modNames, **userCtx):\n        \"\"\"Load (optionally, compiling) pysnmp MIB modules\"\"\"\n        # Build a list of available modules\n        if not modNames:\n            modNames = {}\n\n            for mibSource in self._mibSources:\n                for modName in mibSource.listdir():\n                    modNames[modName] = None\n\n            modNames = list(modNames)\n\n        if not modNames:\n            raise error.MibNotFoundError(\n                'No MIB module to load at %s' % (self,))\n\n        for modName in modNames:\n            try:\n                self.loadModule(modName, **userCtx)\n\n            except error.MibNotFoundError:\n                if not self._mibCompiler:\n                    raise\n\n                debug.logger & debug.FLAG_BLD and debug.logger(\n                    'loadModules: calling MIB compiler for %s' % modName)\n\n                status = self._mibCompiler.compile(modName, genTexts=self.loadTexts)\n\n                errs = '; '.join(\n                    hasattr(x, 'error') and str(x.error) or x\n                    for x in status.values()\n                    if x in ('failed', 'missing'))\n\n                if errs:\n                    raise error.MibNotFoundError(\n                        '%s compilation error(s): %s' % (modName, errs))\n\n                # compilation succeeded, MIB might load now\n                self.loadModule(modName, **userCtx)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sendNotification(snmpEngine, authData, transportTarget, contextData,\n                     notifyType, *varBinds, **options):\n    \"\"\"Creates a generator to send one or more SNMP notifications.\n\n    On each iteration, new SNMP TRAP or INFORM notification is send\n    (:RFC:`1905#section-4,2,6`). The iterator blocks waiting for\n    INFORM acknowledgement to arrive or error to occur.\n\n    Parameters\n    ----------\n    snmpEngine: :py:class:`~pysnmp.hlapi.SnmpEngine`\n        Class instance representing SNMP engine.\n\n    authData: :py:class:`~pysnmp.hlapi.CommunityData` or :py:class:`~pysnmp.hlapi.UsmUserData`\n        Class instance representing SNMP credentials.\n\n    transportTarget: :py:class:`~pysnmp.hlapi.asyncore.UdpTransportTarget` or :py:class:`~pysnmp.hlapi.asyncore.Udp6TransportTarget`\n        Class instance representing transport type along with SNMP peer address.\n\n    contextData: :py:class:`~pysnmp.hlapi.ContextData`\n        Class instance representing SNMP ContextEngineId and ContextName values.\n\n    notifyType: str\n        Indicates type of notification to be sent. Recognized literal\n        values are *trap* or *inform*.\n\n    \\*varBinds: :class:`tuple` of OID-value pairs or :py:class:`~pysnmp.smi.rfc1902.ObjectType` or :py:class:`~pysnmp.smi.rfc1902.NotificationType`\n        One or more objects representing MIB variables to place\n        into SNMP notification. It could be tuples of OID-values\n        or :py:class:`~pysnmp.smi.rfc1902.ObjectType` class instances\n        of :py:class:`~pysnmp.smi.rfc1902.NotificationType` objects.\n\n        SNMP Notification PDU includes some housekeeping items that\n        are required for SNMP to function.\n\n        Agent information:\n\n        * SNMPv2-MIB::sysUpTime.0 = <agent uptime>\n        * SNMPv2-SMI::snmpTrapOID.0 = {SNMPv2-MIB::coldStart, ...}\n\n        Applicable to SNMP v1 TRAP:\n\n        * SNMP-COMMUNITY-MIB::snmpTrapAddress.0 = <agent-IP>\n        * SNMP-COMMUNITY-MIB::snmpTrapCommunity.0 = <snmp-community-name>\n        * SNMP-COMMUNITY-MIB::snmpTrapEnterprise.0 = <enterprise-OID>\n\n        .. note::\n\n           Unless user passes some of these variable-bindings, `.sendNotification()`\n           call will fill in the missing items.\n\n        User variable-bindings:\n\n        * SNMPv2-SMI::NOTIFICATION-TYPE\n        * SNMPv2-SMI::OBJECT-TYPE\n\n        .. note::\n\n           The :py:class:`~pysnmp.smi.rfc1902.NotificationType` object ensures\n           properly formed SNMP notification (to comply MIB definition). If you\n           build notification PDU out of :py:class:`~pysnmp.smi.rfc1902.ObjectType`\n           objects or simple tuples of OID-value objects, it is your responsibility\n           to provide well-formed notification payload.\n\n    Other Parameters\n    ----------------\n    \\*\\*options:\n        * `lookupMib` - load MIB and resolve response MIB variables at\n          the cost of slightly reduced performance. Default is `True`.\n\n    Yields\n    ------\n    errorIndication: str\n        True value indicates SNMP engine error.\n    errorStatus: str\n        True value indicates SNMP PDU error.\n    errorIndex: int\n        Non-zero value refers to `varBinds[errorIndex-1]`\n    varBinds: tuple\n        A sequence of :py:class:`~pysnmp.smi.rfc1902.ObjectType` class\n        instances representing MIB variables returned in SNMP response.\n\n    Raises\n    ------\n    PySnmpError\n        Or its derivative indicating that an error occurred while\n        performing SNMP operation.\n\n    Notes\n    -----\n    The `sendNotification` generator will be exhausted immediately unless\n    an instance of :py:class:`~pysnmp.smi.rfc1902.NotificationType` class\n    or a sequence of :py:class:`~pysnmp.smi.rfc1902.ObjectType` `varBinds`\n    are send back into running generator (supported since Python 2.6).\n\n    Examples\n    --------\n    >>> from pysnmp.hlapi import *\n    >>> g = sendNotification(SnmpEngine(),\n    ...                      CommunityData('public'),\n    ...                      UdpTransportTarget(('demo.snmplabs.com', 162)),\n    ...                      ContextData(),\n    ...                      'trap',\n    ...                      NotificationType(ObjectIdentity('IF-MIB', 'linkDown')))\n    >>> next(g)\n    (None, 0, 0, [])\n    >>>\n\n    \"\"\"\n\n    # noinspection PyShadowingNames\n    def cbFun(snmpEngine, sendRequestHandle,\n              errorIndication, errorStatus, errorIndex,\n              varBinds, cbCtx):\n        cbCtx['errorIndication'] = errorIndication\n        cbCtx['errorStatus'] = errorStatus\n        cbCtx['errorIndex'] = errorIndex\n        cbCtx['varBinds'] = varBinds\n\n    cbCtx = {}\n\n    while True:\n        if varBinds:\n            ntforg.sendNotification(snmpEngine, authData, transportTarget,\n                                    contextData, notifyType, *varBinds,\n                                    cbFun=cbFun, cbCtx=cbCtx,\n                                    lookupMib=options.get('lookupMib', True))\n\n            snmpEngine.transportDispatcher.runDispatcher()\n\n            errorIndication = cbCtx.get('errorIndication')\n            errorStatus = cbCtx.get('errorStatus')\n            errorIndex = cbCtx.get('errorIndex')\n            varBinds = cbCtx.get('varBinds', [])\n\n        else:\n            errorIndication = errorStatus = errorIndex = None\n            varBinds = []\n\n        varBinds = (yield errorIndication, errorStatus, errorIndex, varBinds)\n\n        if not varBinds:\n            break", "response": "Sends one or more SNMP notifications to the peer."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getCmd(snmpDispatcher, authData, transportTarget,\n           *varBinds, **options):\n    \"\"\"Creates a generator to perform one or more SNMP GET queries.\n\n    On each iteration, new SNMP GET request is send (:RFC:`1905#section-4.2.1`).\n    The iterator blocks waiting for response to arrive or error to occur.\n\n    Parameters\n    ----------\n    snmpDispatcher: :py:class:`~pysnmp.hlapi.v1arch.asyncore.SnmpDispatcher`\n        Class instance representing asyncore-based asynchronous event loop and\n        associated state information.\n\n    authData: :py:class:`~pysnmp.hlapi.CommunityData` or :py:class:`~pysnmp.hlapi.UsmUserData`\n        Class instance representing SNMP credentials.\n\n    transportTarget: :py:class:`~pysnmp.hlapi.asyncore.UdpTransportTarget` or :py:class:`~pysnmp.hlapi.asyncore.Udp6TransportTarget`\n        Class instance representing transport type along with SNMP peer address.\n\n    \\*varBinds: :py:class:`~pysnmp.smi.rfc1902.ObjectType`\n        One or more class instances representing MIB variables to place\n        into SNMP request.\n\n    Other Parameters\n    ----------------\n    \\*\\*options:\n        Request options:\n\n            * `lookupMib` - load MIB and resolve response MIB variables at\n              the cost of slightly reduced performance. Default is `False`.\n\n    Yields\n    ------\n    errorIndication: str\n        True value indicates local SNMP error.\n    errorStatus: str\n        True value indicates SNMP PDU error reported by remote.\n    errorIndex: int\n        Non-zero value refers to `varBinds[errorIndex-1]`\n    varBinds: tuple\n        A sequence of :py:class:`~pysnmp.smi.rfc1902.ObjectType` class\n        instances representing MIB variables returned in SNMP response.\n\n    Raises\n    ------\n    PySnmpError\n        Or its derivative indicating that an error occurred while\n        performing SNMP operation.\n\n    Notes\n    -----\n    The `getCmd` generator will be exhausted immediately unless\n    a new sequence of `varBinds` are send back into running generator\n    (supported since Python 2.6).\n\n    Examples\n    --------\n    >>> from pysnmp.hlapi.v1arch import *\n    >>>\n    >>> g = getCmd(snmpDispatcher(),\n    >>>            CommunityData('public'),\n    >>>            UdpTransportTarget(('demo.snmplabs.com', 161)),\n    >>>            ObjectType(ObjectIdentity('SNMPv2-MIB', 'sysDescr', 0)))\n    >>>\n    >>> next(g)\n    (None, 0, 0, [ObjectType(ObjectIdentity(ObjectName('1.3.6.1.2.1.1.1.0')),\n                  DisplayString('SunOS zeus.snmplabs.com 4.1.3_U1 1 sun4m'))])\n    \"\"\"\n\n    def cbFun(*args, **kwargs):\n        response[:] = args\n\n    options['cbFun'] = cbFun\n\n    errorIndication, errorStatus, errorIndex = None, 0, 0\n    response = []\n\n    while True:\n        if varBinds:\n            cmdgen.getCmd(snmpDispatcher, authData, transportTarget,\n                          *varBinds, **options)\n\n            snmpDispatcher.transportDispatcher.runDispatcher()\n\n            errorIndication, errorStatus, errorIndex, varBinds = response\n\n        varBinds = (yield errorIndication, errorStatus, errorIndex, varBinds)\n\n        if not varBinds:\n            break", "response": "Returns a generator that yields one or more SNMP GET requests."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a generator to perform one or more SNMP GETNEXT queries. On each iteration, new SNMP GETNEXT request is send (:RFC:`1905#section-4.2.2`). The iterator blocks waiting for response to arrive or error to occur. Parameters ---------- snmpDispatcher : :py:class:`~pysnmp.hlapi.snmpDispatcher` Class instance representing SNMP engine. authData : :py:class:`~pysnmp.hlapi.CommunityData` or :py:class:`~pysnmp.hlapi.UsmUserData` Class instance representing SNMP credentials. transportTarget : :py:class:`~pysnmp.hlapi.asyncore.UdpTransportTarget` or :py:class:`~pysnmp.hlapi.asyncore.Udp6TransportTarget` Class instance representing transport type along with SNMP peer address. \\*varBinds : :py:class:`~pysnmp.smi.rfc1902.ObjectType` One or more class instances representing MIB variables to place into SNMP request. Other Parameters ---------------- \\*\\*options : Request options: * `lookupMib` - load MIB and resolve response MIB variables at the cost of slightly reduced performance. Default is `True`. Default is `True`. * `lexicographicMode` - walk SNMP agent's MIB till the end (if `True`), otherwise (if `False`) stop iteration when all response MIB variables leave the scope of initial MIB variables in `varBinds`. Default is `True`. * `ignoreNonIncreasingOid` - continue iteration even if response MIB variables (OIDs) are not greater then request MIB variables. Be aware that setting it to `True` may cause infinite loop between SNMP management and agent applications. Default is `False`. * `maxRows` - stop iteration once this generator instance processed `maxRows` of SNMP conceptual table. Default is `0` (no limit). * `maxCalls` - stop iteration once this generator instance processed `maxCalls` responses. Default is 0 (no limit). Yields ------ errorIndication: str True value indicates SNMP engine error. errorStatus: str True value indicates SNMP PDU error. errorIndex: int Non-zero value refers to `varBinds[errorIndex-1]` varBindTable: tuple A 2-dimensional array of :py:class:`~pysnmp.smi.rfc1902.ObjectType` class instances representing a table of MIB variables returned in SNMP response. Raises ------ PySnmpError Or its derivative indicating that an error occurred while performing SNMP operation. Notes ----- The `nextCmd` generator will be exhausted on any of the following conditions: * SNMP engine error occurs thus `errorIndication` is `True` * SNMP PDU `errorStatus` is reported as `True` * SNMP :py:class:`~pysnmp.proto.rfc1905.EndOfMibView` values (also known as *SNMP exception values*) are reported for all MIB variables in `varBinds` * *lexicographicMode* option is `True` and SNMP agent reports end-of-mib or *lexicographicMode* is `False` and all response MIB variables leave the scope of `varBinds` At any moment a new sequence of `varBinds` could be send back into running generator (supported since Python 2.6). Examples -------- >>> from pysnmp.hlapi.v1arch import * >>> >>> g = nextCmd(snmpDispatcher(), >>> CommunityData('public'), >>> UdpTransportTarget(('demo.snmplabs.com', 161)), >>> ObjectType(ObjectIdentity('SNMPv2-MIB', 'sysDescr'))) >>> next(g) (None, 0, 0, [[ObjectType(ObjectIdentity(ObjectName('1.3.6.1.2.1.1.1.0')), DisplayString('SunOS zeus.snmplabs.com 4.1.3_U1 1 sun4m'))]]) >>> g.send([ObjectType(ObjectIdentity('IF-MIB', 'ifInOctets'))]) (None, 0, 0, [(ObjectName('1.3.6.1.2.1.2.2.1.10.1'), Counter32(284817787))])", "response": "def nextCmd(snmpDispatcher, authData, transportTarget,\n            *varBinds, **options):\n    \"\"\"Create a generator to perform one or more SNMP GETNEXT queries.\n\n    On each iteration, new SNMP GETNEXT request is send\n    (:RFC:`1905#section-4.2.2`). The iterator blocks waiting for response\n    to arrive or error to occur.\n\n    Parameters\n    ----------\n    snmpDispatcher : :py:class:`~pysnmp.hlapi.snmpDispatcher`\n        Class instance representing SNMP engine.\n\n    authData : :py:class:`~pysnmp.hlapi.CommunityData` or :py:class:`~pysnmp.hlapi.UsmUserData`\n        Class instance representing SNMP credentials.\n\n    transportTarget : :py:class:`~pysnmp.hlapi.asyncore.UdpTransportTarget` or :py:class:`~pysnmp.hlapi.asyncore.Udp6TransportTarget`\n        Class instance representing transport type along with SNMP peer address.\n\n    \\*varBinds : :py:class:`~pysnmp.smi.rfc1902.ObjectType`\n        One or more class instances representing MIB variables to place\n        into SNMP request.\n\n    Other Parameters\n    ----------------\n    \\*\\*options :\n        Request options:\n\n            * `lookupMib` - load MIB and resolve response MIB variables at\n              the cost of slightly reduced performance. Default is `True`.\n              Default is `True`.\n            * `lexicographicMode` - walk SNMP agent's MIB till the end (if `True`),\n              otherwise (if `False`) stop iteration when all response MIB\n              variables leave the scope of initial MIB variables in\n              `varBinds`. Default is `True`.\n            * `ignoreNonIncreasingOid` - continue iteration even if response\n              MIB variables (OIDs) are not greater then request MIB variables.\n              Be aware that setting it to `True` may cause infinite loop between\n              SNMP management and agent applications. Default is `False`.\n            * `maxRows` - stop iteration once this generator instance processed\n              `maxRows` of SNMP conceptual table. Default is `0` (no limit).\n            * `maxCalls` - stop iteration once this generator instance processed\n              `maxCalls` responses. Default is 0 (no limit).\n\n    Yields\n    ------\n    errorIndication: str\n        True value indicates SNMP engine error.\n    errorStatus: str\n        True value indicates SNMP PDU error.\n    errorIndex: int\n        Non-zero value refers to `varBinds[errorIndex-1]`\n    varBindTable: tuple\n        A 2-dimensional array of :py:class:`~pysnmp.smi.rfc1902.ObjectType` class\n        instances representing a table of MIB variables returned in SNMP response.\n\n    Raises\n    ------\n    PySnmpError\n        Or its derivative indicating that an error occurred while\n        performing SNMP operation.\n\n    Notes\n    -----\n    The `nextCmd` generator will be exhausted on any of the following\n    conditions:\n\n    * SNMP engine error occurs thus `errorIndication` is `True`\n    * SNMP PDU `errorStatus` is reported as `True`\n    * SNMP :py:class:`~pysnmp.proto.rfc1905.EndOfMibView` values\n      (also known as *SNMP exception values*) are reported for all\n      MIB variables in `varBinds`\n    * *lexicographicMode* option is `True` and SNMP agent reports\n      end-of-mib or *lexicographicMode* is `False` and all\n      response MIB variables leave the scope of `varBinds`\n\n    At any moment a new sequence of `varBinds` could be send back into\n    running generator (supported since Python 2.6).\n\n    Examples\n    --------\n    >>> from pysnmp.hlapi.v1arch import *\n    >>>\n    >>> g = nextCmd(snmpDispatcher(),\n    >>>             CommunityData('public'),\n    >>>             UdpTransportTarget(('demo.snmplabs.com', 161)),\n    >>>             ObjectType(ObjectIdentity('SNMPv2-MIB', 'sysDescr')))\n    >>> next(g)\n    (None, 0, 0, [[ObjectType(ObjectIdentity(ObjectName('1.3.6.1.2.1.1.1.0')), DisplayString('SunOS zeus.snmplabs.com 4.1.3_U1 1 sun4m'))]])\n    >>> g.send([ObjectType(ObjectIdentity('IF-MIB', 'ifInOctets'))])\n    (None, 0, 0, [(ObjectName('1.3.6.1.2.1.2.2.1.10.1'), Counter32(284817787))])\n    \"\"\"\n\n    def cbFun(*args, **kwargs):\n        response[:] = args + (kwargs.get('nextVarBinds', ()),)\n\n    options['cbFun'] = cbFun\n\n    lexicographicMode = options.pop('lexicographicMode', True)\n    maxRows = options.pop('maxRows', 0)\n    maxCalls = options.pop('maxCalls', 0)\n\n    initialVarBinds = VB_PROCESSOR.makeVarBinds(snmpDispatcher.cache, varBinds)\n\n    totalRows = totalCalls = 0\n\n    errorIndication, errorStatus, errorIndex, varBindTable = None, 0, 0, ()\n    response = []\n\n    while True:\n        if not varBinds:\n            yield (errorIndication, errorStatus, errorIndex,\n                   varBindTable and varBindTable[0] or [])\n            return\n\n        cmdgen.nextCmd(snmpDispatcher, authData, transportTarget,\n                       *[(x[0], Null('')) for x in varBinds], **options)\n\n        snmpDispatcher.transportDispatcher.runDispatcher()\n\n        errorIndication, errorStatus, errorIndex, varBindTable, varBinds = response\n\n        if errorIndication:\n            yield (errorIndication, errorStatus, errorIndex,\n                   varBindTable and varBindTable[0] or [])\n            return\n\n        elif errorStatus:\n            if errorStatus == 2:\n                # Hide SNMPv1 noSuchName error which leaks in here\n                # from SNMPv1 Agent through internal pysnmp proxy.\n                errorStatus = errorStatus.clone(0)\n                errorIndex = errorIndex.clone(0)\n            yield (errorIndication, errorStatus, errorIndex,\n                   varBindTable and varBindTable[0] or [])\n            return\n\n        else:\n            varBindRow = varBindTable and varBindTable[-1]\n\n            if not lexicographicMode:\n                for idx, varBind in enumerate(varBindRow):\n                    name, val = varBind\n                    if not isinstance(val, Null):\n                        if initialVarBinds[idx][0].isPrefixOf(name):\n                            break\n                else:\n                    return\n\n            for varBindRow in varBindTable:\n                nextVarBinds = (yield errorIndication, errorStatus, errorIndex, varBindRow)\n\n                if nextVarBinds:\n                    initialVarBinds = varBinds = VB_PROCESSOR.makeVarBinds(snmpDispatcher.cache, nextVarBinds)\n\n                totalRows += 1\n                totalCalls += 1\n\n                if maxRows and totalRows >= maxRows:\n                    return\n\n                if maxCalls and totalCalls >= maxCalls:\n                    return"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef bulkCmd(snmpDispatcher, authData, transportTarget,\n            nonRepeaters, maxRepetitions, *varBinds, **options):\n    \"\"\"Creates a generator to perform one or more SNMP GETBULK queries.\n\n    On each iteration, new SNMP GETBULK request is send\n    (:RFC:`1905#section-4.2.3`). The iterator blocks waiting for response\n    to arrive or error to occur.\n\n    Parameters\n    ----------\n    snmpDispatcher : :py:class:`~pysnmp.hlapi.snmpDispatcher`\n        Class instance representing SNMP engine.\n\n    authData : :py:class:`~pysnmp.hlapi.CommunityData` or :py:class:`~pysnmp.hlapi.UsmUserData`\n        Class instance representing SNMP credentials.\n\n    transportTarget : :py:class:`~pysnmp.hlapi.asyncore.UdpTransportTarget` or :py:class:`~pysnmp.hlapi.asyncore.Udp6TransportTarget`\n        Class instance representing transport type along with SNMP peer address.\n\n    nonRepeaters : int\n        One MIB variable is requested in response for the first\n        `nonRepeaters` MIB variables in request.\n\n    maxRepetitions : int\n        `maxRepetitions` MIB variables are requested in response for each\n        of the remaining MIB variables in the request (e.g. excluding\n        `nonRepeaters`). Remote SNMP engine may choose lesser value than\n        requested.\n\n    \\*varBinds : :py:class:`~pysnmp.smi.rfc1902.ObjectType`\n        One or more class instances representing MIB variables to place\n        into SNMP request.\n\n    Other Parameters\n    ----------------\n    \\*\\*options :\n        Request options:\n\n            * `lookupMib` - load MIB and resolve response MIB variables at\n              the cost of slightly reduced performance. Default is `True`.\n              Default is `True`.\n            * `lexicographicMode` - walk SNMP agent's MIB till the end (if `True`),\n              otherwise (if `False`) stop iteration when all response MIB\n              variables leave the scope of initial MIB variables in\n              `varBinds`. Default is `True`.\n            * `ignoreNonIncreasingOid` - continue iteration even if response\n              MIB variables (OIDs) are not greater then request MIB variables.\n              Be aware that setting it to `True` may cause infinite loop between\n              SNMP management and agent applications. Default is `False`.\n            * `maxRows` - stop iteration once this generator instance processed\n              `maxRows` of SNMP conceptual table. Default is `0` (no limit).\n            * `maxCalls` - stop iteration once this generator instance processed\n              `maxCalls` responses. Default is 0 (no limit).\n\n    Yields\n    ------\n    errorIndication : str\n        True value indicates SNMP engine error.\n    errorStatus : str\n        True value indicates SNMP PDU error.\n    errorIndex : int\n        Non-zero value refers to \\*varBinds[errorIndex-1]\n    varBinds: tuple\n        A sequence of :py:class:`~pysnmp.smi.rfc1902.ObjectType` class\n        instances representing MIB variables returned in SNMP response.\n\n    Raises\n    ------\n    PySnmpError\n        Or its derivative indicating that an error occurred while\n        performing SNMP operation.\n\n    Notes\n    -----\n    The `bulkCmd` generator will be exhausted on any of the following\n    conditions:\n\n    * SNMP engine error occurs thus `errorIndication` is `True`\n    * SNMP PDU `errorStatus` is reported as `True`\n    * SNMP :py:class:`~pysnmp.proto.rfc1905.EndOfMibView` values\n      (also known as *SNMP exception values*) are reported for all\n      MIB variables in `varBinds`\n    * *lexicographicMode* option is `True` and SNMP agent reports\n      end-of-mib or *lexicographicMode* is `False` and all\n      response MIB variables leave the scope of `varBinds`\n\n    At any moment a new sequence of `varBinds` could be send back into\n    running generator (supported since Python 2.6).\n\n    Setting `maxRepetitions` value to 15..50 might significantly improve\n    system performance, as many MIB variables get packed into a single\n    response message at once.\n\n    Examples\n    --------\n    >>> from pysnmp.hlapi.v1arch import *\n    >>>\n    >>> g = bulkCmd(snmpDispatcher(),\n    >>>             CommunityData('public'),\n    >>>             UdpTransportTarget(('demo.snmplabs.com', 161)),\n    >>>             0, 25,\n    >>>             ObjectType(ObjectIdentity('SNMPv2-MIB', 'sysDescr')))\n    >>> next(g)\n    (None, 0, 0, [[ObjectType(ObjectIdentity(ObjectName('1.3.6.1.2.1.1.1.0')), DisplayString('SunOS zeus.snmplabs.com 4.1.3_U1 1 sun4m'))]])\n    >>> g.send([ObjectType(ObjectIdentity('IF-MIB', 'ifInOctets'))])\n    (None, 0, 0, [[(ObjectName('1.3.6.1.2.1.2.2.1.10.1'), Counter32(284817787))]])\n    \"\"\"\n\n    def cbFun(*args, **kwargs):\n        response[:] = args + (kwargs.get('nextVarBinds', ()),)\n\n    options['cbFun'] = cbFun\n\n    lexicographicMode = options.pop('lexicographicMode', True)\n    maxRows = options.pop('maxRows', 0)\n    maxCalls = options.pop('maxCalls', 0)\n\n    initialVarBinds = VB_PROCESSOR.makeVarBinds(snmpDispatcher.cache, varBinds)\n\n    nullVarBinds = [False] * len(initialVarBinds)\n\n    totalRows = totalCalls = 0\n\n    errorIndication, errorStatus, errorIndex, varBindTable = None, 0, 0, ()\n    response = []\n\n    stopFlag = False\n\n    while not stopFlag:\n        if not varBinds:\n            yield (errorIndication, errorStatus, errorIndex, varBinds)\n            return\n\n        if maxRows and totalRows < maxRows:\n            maxRepetitions = min(maxRepetitions, maxRows - totalRows)\n\n        cmdgen.bulkCmd(snmpDispatcher, authData, transportTarget,\n                       nonRepeaters, maxRepetitions,\n                       *[(x[0], Null('')) for x in varBinds], **options)\n\n        snmpDispatcher.transportDispatcher.runDispatcher()\n\n        errorIndication, errorStatus, errorIndex, varBindTable, varBinds = response\n\n        if errorIndication:\n            yield (errorIndication, errorStatus, errorIndex, ())\n            return\n\n        elif errorStatus:\n            if errorStatus == 2:\n                # Hide SNMPv1 noSuchName error which leaks in here\n                # from SNMPv1 Agent through internal pysnmp proxy.\n                errorStatus = errorStatus.clone(0)\n                errorIndex = errorIndex.clone(0)\n            yield (errorIndication, errorStatus, errorIndex, varBindTable and varBindTable[0] or [])\n            return\n\n        else:\n            for rowIdx, varBindRow in enumerate(varBindTable):\n                stopFlag = True\n                if len(varBindRow) != len(initialVarBinds):\n                    varBindTable = rowIdx and varBindTable[:rowIdx - 1] or []\n                    break\n\n                for colIdx, varBind in enumerate(varBindRow):\n                    name, val = varBind\n                    if nullVarBinds[colIdx]:\n                        varBindRow[colIdx] = name, endOfMibView\n                        continue\n\n                    stopFlag = False\n\n                    if isinstance(val, Null):\n                        nullVarBinds[colIdx] = True\n\n                    elif not lexicographicMode and not initialVarBinds[colIdx][0].isPrefixOf(name):\n                        varBindRow[colIdx] = name, endOfMibView\n                        nullVarBinds[colIdx] = True\n\n                if stopFlag:\n                    varBindTable = rowIdx and varBindTable[:rowIdx - 1] or []\n                    break\n\n            totalRows += len(varBindTable)\n            totalCalls += 1\n\n            if maxRows and totalRows >= maxRows:\n                if totalRows > maxRows:\n                    varBindTable = varBindTable[:-(totalRows - maxRows)]\n                stopFlag = True\n\n            if maxCalls and totalCalls >= maxCalls:\n                stopFlag = True\n\n            for varBindRow in varBindTable:\n                nextVarBinds = (yield errorIndication, errorStatus, errorIndex, varBindRow)\n\n                if nextVarBinds:\n                    initialVarBinds = varBinds = VB_PROCESSOR.makeVarBinds(snmpDispatcher.cache, nextVarBinds)", "response": "This function is used to perform one or more SNMP GETBULK queries."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sendNotification(snmpDispatcher, authData, transportTarget,\n                     notifyType, *varBinds, **options):\n    \"\"\"Creates a generator to send SNMP notification.\n\n    When iterator gets advanced by :py:mod:`asyncio` main loop,\n    SNMP TRAP or INFORM notification is send (:RFC:`1905#section-4.2.6`).\n    The iterator yields :py:class:`asyncio.Future` which gets done whenever\n    response arrives or error occurs.\n\n    Parameters\n    ----------\n    snmpDispatcher: :py:class:`~pysnmp.hlapi.v1arch.asyncore.SnmpDispatcher`\n        Class instance representing asynio-based asynchronous event loop and\n        associated state information.\n\n    authData: :py:class:`~pysnmp.hlapi.v1arch.CommunityData`\n        Class instance representing SNMPv1/v2c credentials.\n\n    transportTarget: :py:class:`~pysnmp.hlapi.v1arch.asyncio.UdpTransportTarget` or\n        :py:class:`~pysnmp.hlapi.v1arch.asyncio.Udp6TransportTarget` Class instance representing\n        transport type along with SNMP peer address.\n\n    notifyType : str\n        Indicates type of notification to be sent. Recognized literal\n        values are *trap* or *inform*.\n\n    \\*varBinds: :class:`tuple` of OID-value pairs or :py:class:`~pysnmp.smi.rfc1902.ObjectType` or :py:class:`~pysnmp.smi.rfc1902.NotificationType`\n        One or more objects representing MIB variables to place\n        into SNMP notification. It could be tuples of OID-values\n        or :py:class:`~pysnmp.smi.rfc1902.ObjectType` class instances\n        of :py:class:`~pysnmp.smi.rfc1902.NotificationType` objects.\n\n        Besides user variable-bindings, SNMP Notification PDU requires at\n        least two variable-bindings to be present:\n\n        0. SNMPv2-MIB::sysUpTime.0 = <agent uptime>\n        1. SNMPv2-SMI::snmpTrapOID.0 = <notification ID>\n\n        When sending SNMPv1 TRAP, more variable-bindings could be present:\n\n        2. SNMP-COMMUNITY-MIB::snmpTrapAddress.0 = <agent-IP>\n        3. SNMP-COMMUNITY-MIB::snmpTrapCommunity.0 = <snmp-community-name>\n        4. SNMP-COMMUNITY-MIB::snmpTrapEnterprise.0 = <enterprise-OID>\n\n        If user does not supply some or any of the above variable-bindings or\n        if they are at the wrong positions, the system will add/reorder the\n        missing ones automatically.\n\n        On top of that, some notification types imply including some additional\n        variable-bindings providing additional details on the event being\n        reported. Therefore it is generally easier to use\n        :py:class:`~pysnmp.smi.rfc1902.NotificationType` object which will\n        help adding relevant variable-bindings.\n\n    Other Parameters\n    ----------------\n    \\*\\*options :\n        Request options:\n\n        * `lookupMib` - load MIB and resolve response MIB variables at\n          the cost of slightly reduced performance. Default is `False`,\n          unless :py:class:`~pysnmp.smi.rfc1902.ObjectType` or\n          :py:class:`~pysnmp.smi.rfc1902.NotificationType` is present\n          among `varBinds` in which case `lookupMib` gets automatically\n          enabled.\n\n    Yields\n    ------\n    errorIndication: str\n        True value indicates SNMP engine error.\n    errorStatus: str\n        True value indicates SNMP PDU error.\n    errorIndex: int\n        Non-zero value refers to `varBinds[errorIndex-1]`\n    varBinds: tuple\n        A sequence of OID-value pairs in form of base SNMP types (if\n        `lookupMib` is `False`) or :py:class:`~pysnmp.smi.rfc1902.ObjectType`\n        class instances (if `lookupMib` is `True`) representing MIB variables\n        returned in SNMP response.\n\n    Raises\n    ------\n    PySnmpError\n        Or its derivative indicating that an error occurred while\n        performing SNMP operation.\n\n    Examples\n    --------\n    >>> import asyncio\n    >>> from pysnmp.hlapi.asyncio import *\n    >>>\n    >>> @asyncio.coroutine\n    ... def run():\n    ...     errorIndication, errorStatus, errorIndex, varBinds = yield from sendNotification(\n    ...         SnmpDispatcher(),\n    ...         CommunityData('public'),\n    ...         UdpTransportTarget(('demo.snmplabs.com', 162)),\n    ...         'trap',\n    ...         NotificationType(ObjectIdentity('IF-MIB', 'linkDown')))\n    ...     print(errorIndication, errorStatus, errorIndex, varBinds)\n    ...\n    >>> asyncio.get_event_loop().run_until_complete(run())\n    (None, 0, 0, [])\n    >>>\n    \"\"\"\n\n    sysUpTime = v2c.apiTrapPDU.sysUpTime\n    snmpTrapOID = v2c.apiTrapPDU.snmpTrapOID\n\n    def _ensureVarBinds(varBinds):\n        # Add sysUpTime if not present already\n        if not varBinds or varBinds[0][0] != sysUpTime:\n            varBinds.insert(0, (v2c.ObjectIdentifier(sysUpTime), v2c.TimeTicks(0)))\n\n        # Search for and reposition sysUpTime if it's elsewhere\n        for idx, varBind in enumerate(varBinds[1:]):\n            if varBind[0] == sysUpTime:\n                varBinds[0] = varBind\n                del varBinds[idx + 1]\n                break\n\n        if len(varBinds) < 2:\n            raise error.PySnmpError('SNMP notification PDU requires '\n                                    'SNMPv2-MIB::snmpTrapOID.0 to be present')\n\n        # Search for and reposition snmpTrapOID if it's elsewhere\n        for idx, varBind in enumerate(varBinds[2:]):\n            if varBind[0] == snmpTrapOID:\n                del varBinds[idx + 2]\n                if varBinds[1][0] == snmpTrapOID:\n                    varBinds[1] = varBind\n                else:\n                    varBinds.insert(1, varBind)\n                break\n\n        # Fail on missing snmpTrapOID\n        if varBinds[1][0] != snmpTrapOID:\n            raise error.PySnmpError('SNMP notification PDU requires '\n                                    'SNMPv2-MIB::snmpTrapOID.0 to be present')\n\n        return varBinds\n\n    def _cbFun(snmpDispatcher, stateHandle, errorIndication, rspPdu, _cbCtx):\n        if future.cancelled():\n            return\n\n        errorStatus = v2c.apiTrapPDU.getErrorStatus(rspPdu)\n        errorIndex = v2c.apiTrapPDU.getErrorIndex(rspPdu)\n\n        varBinds = v2c.apiTrapPDU.getVarBinds(rspPdu)\n\n        try:\n            varBindsUnmade = VB_PROCESSOR.unmakeVarBinds(snmpDispatcher.cache, varBinds,\n                                                         lookupMib)\n        except Exception as e:\n            future.set_exception(e)\n\n        else:\n            future.set_result(\n                (errorIndication, errorStatus, errorIndex, varBindsUnmade)\n            )\n\n    lookupMib = options.get('lookupMib')\n\n    if not lookupMib and any(isinstance(x, (NotificationType, ObjectType))\n                             for x in varBinds):\n        lookupMib = True\n\n    if lookupMib:\n        varBinds = VB_PROCESSOR.makeVarBinds(snmpDispatcher.cache, varBinds)\n\n    if notifyType == 'trap':\n        reqPdu = v2c.TrapPDU()\n    else:\n        reqPdu = v2c.InformRequestPDU()\n\n    v2c.apiTrapPDU.setDefaults(reqPdu)\n    v2c.apiTrapPDU.setVarBinds(reqPdu, varBinds)\n\n    varBinds = v2c.apiTrapPDU.getVarBinds(reqPdu)\n\n    v2c.apiTrapPDU.setVarBinds(reqPdu, _ensureVarBinds(varBinds))\n\n    if authData.mpModel == 0:\n        reqPdu = rfc2576.v2ToV1(reqPdu)\n\n    future = asyncio.Future()\n\n    snmpDispatcher.sendPdu(authData, transportTarget, reqPdu, cbFun=_cbFun)\n\n    if notifyType == 'trap':\n        def __trapFun(future):\n            if future.cancelled():\n                return\n            future.set_result((None, 0, 0, []))\n\n        loop = asyncio.get_event_loop()\n        loop.call_soon(__trapFun, future)\n\n    return future", "response": "Sends a new notification to the given node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef registerContextEngineId(self, contextEngineId, pduTypes, processPdu):\n        # 4.3.2 -> no-op\n\n        # 4.3.3\n        for pduType in pduTypes:\n            k = contextEngineId, pduType\n            if k in self._appsRegistration:\n                raise error.ProtocolError(\n                    'Duplicate registration %r/%s' % (contextEngineId, pduType))\n\n            # 4.3.4\n            self._appsRegistration[k] = processPdu\n\n        debug.logger & debug.FLAG_DSP and debug.logger(\n            'registerContextEngineId: contextEngineId %r pduTypes '\n            '%s' % (contextEngineId, pduTypes))", "response": "Register application with dispatcher"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmessaging dispatcher -- de-serialize message into PDU", "response": "def receiveMessage(self, snmpEngine, transportDomain,\n                       transportAddress, wholeMsg):\n        \"\"\"Message dispatcher -- de-serialize message into PDU\"\"\"\n        mibBuilder = self.mibInstrumController.mibBuilder\n\n        # 4.2.1.1\n        snmpInPkts, = mibBuilder.importSymbols(\n            '__SNMPv2-MIB', 'snmpInPkts')\n        snmpInPkts.syntax += 1\n\n        restOfWholeMsg = null  # XXX fix decoder non-recursive return\n\n        # 4.2.1.2\n        try:\n            msgVersion = verdec.decodeMessageVersion(wholeMsg)\n\n        except error.ProtocolError:\n            snmpInASNParseErrs, = mibBuilder.importSymbols(\n                '__SNMPv2-MIB', 'snmpInASNParseErrs')\n            snmpInASNParseErrs.syntax += 1\n\n            return null  # n.b the whole buffer gets dropped\n\n        debug.logger & debug.FLAG_DSP and debug.logger(\n            'receiveMessage: msgVersion %s, msg decoded' % msgVersion)\n\n        messageProcessingModel = msgVersion\n\n        try:\n            mpHandler = snmpEngine.messageProcessingSubsystems[\n                int(messageProcessingModel)]\n\n        except KeyError:\n            snmpInBadVersions, = mibBuilder.importSymbols(\n                '__SNMPv2-MIB', 'snmpInBadVersions')\n            snmpInBadVersions.syntax += 1\n\n            return restOfWholeMsg\n\n        # 4.2.1.3 -- no-op\n\n        # 4.2.1.4\n        try:\n            (messageProcessingModel,\n             securityModel,\n             securityName,\n             securityLevel,\n             contextEngineId,\n             contextName,\n             pduVersion,\n             PDU,\n             pduType,\n             sendPduHandle,\n             maxSizeResponseScopedPDU,\n             statusInformation,\n             stateReference) = mpHandler.prepareDataElements(\n                snmpEngine, transportDomain, transportAddress, wholeMsg)\n\n            debug.logger & debug.FLAG_DSP and debug.logger(\n                'receiveMessage: MP succeded')\n\n        except error.StatusInformation as exc:\n            statusInformation = exc\n\n            if 'sendPduHandle' in statusInformation:\n                # Dropped REPORT -- re-run pending reqs queue as some\n                # of them may be waiting for this REPORT\n                debug.logger & debug.FLAG_DSP and debug.logger(\n                    'receiveMessage: MP failed, statusInformation %s, '\n                    'forcing retry' % statusInformation)\n\n                self.__expireRequest(\n                    statusInformation['sendPduHandle'],\n                    self._cache.pop(statusInformation['sendPduHandle']),\n                    snmpEngine,\n                    statusInformation)\n\n            return restOfWholeMsg\n\n        except PyAsn1Error as exc:\n            debug.logger & debug.FLAG_MP and debug.logger(\n                'receiveMessage: %s' % exc)\n            snmpInASNParseErrs, = mibBuilder.importSymbols(\n                '__SNMPv2-MIB', 'snmpInASNParseErrs')\n            snmpInASNParseErrs.syntax += 1\n\n            return restOfWholeMsg\n\n        debug.logger & debug.FLAG_DSP and debug.logger(\n            'receiveMessage: PDU %s' % PDU.prettyPrint())\n\n        # 4.2.2\n        if sendPduHandle is None:\n            # 4.2.2.1 (request or notification)\n\n            debug.logger & debug.FLAG_DSP and debug.logger(\n                'receiveMessage: pduType %s' % pduType)\n\n            # 4.2.2.1.1\n            processPdu = self.getRegisteredApp(contextEngineId, pduType)\n\n            # 4.2.2.1.2\n            if processPdu is None:\n                # 4.2.2.1.2.a\n                snmpUnknownPDUHandlers, = importSymbols(\n                    '__SNMP-MPD-MIB', 'snmpUnknownPDUHandlers')\n                snmpUnknownPDUHandlers.syntax += 1\n\n                # 4.2.2.1.2.b\n                statusInformation = {\n                    'errorIndication': errind.unknownPDUHandler,\n                    'oid': snmpUnknownPDUHandlers.name,\n                    'val': snmpUnknownPDUHandlers.syntax\n                }\n\n                debug.logger & debug.FLAG_DSP and debug.logger(\n                    'receiveMessage: unhandled PDU type')\n\n                # 4.2.2.1.2.c\n                try:\n                    (destTransportDomain,\n                     destTransportAddress,\n                     outgoingMessage) = mpHandler.prepareResponseMessage(\n                        snmpEngine, messageProcessingModel,\n                        securityModel, securityName, securityLevel,\n                        contextEngineId, contextName, pduVersion,\n                        PDU, maxSizeResponseScopedPDU, stateReference,\n                        statusInformation)\n\n                    snmpEngine.transportDispatcher.sendMessage(\n                        outgoingMessage, destTransportDomain,\n                        destTransportAddress)\n\n                except PySnmpError as exc:\n                    debug.logger & debug.FLAG_DSP and debug.logger(\n                        'receiveMessage: report failed, statusInformation %s' % exc)\n\n                else:\n                    debug.logger & debug.FLAG_DSP and debug.logger(\n                        'receiveMessage: reporting succeeded')\n\n                # 4.2.2.1.2.d\n                return restOfWholeMsg\n\n            else:\n                snmpEngine.observer.storeExecutionContext(\n                    snmpEngine, 'rfc3412.receiveMessage:request',\n                    dict(transportDomain=transportDomain,\n                         transportAddress=transportAddress,\n                         wholeMsg=wholeMsg,\n                         messageProcessingModel=messageProcessingModel,\n                         securityModel=securityModel,\n                         securityName=securityName,\n                         securityLevel=securityLevel,\n                         contextEngineId=contextEngineId,\n                         contextName=contextName,\n                         pdu=PDU))\n\n                # pass transport info to app (legacy)\n                if stateReference is not None:\n                    self._transportInfo[stateReference] = (\n                        transportDomain, transportAddress)\n\n                # 4.2.2.1.3 (asynchronous function)\n                processPdu(\n                    snmpEngine, messageProcessingModel, securityModel,\n                    securityName, securityLevel, contextEngineId,\n                    contextName, pduVersion, PDU, maxSizeResponseScopedPDU,\n                    stateReference)\n\n                snmpEngine.observer.clearExecutionContext(\n                    snmpEngine, 'rfc3412.receiveMessage:request')\n\n                # legacy\n                if stateReference is not None:\n                    del self._transportInfo[stateReference]\n\n                debug.logger & debug.FLAG_DSP and debug.logger(\n                    'receiveMessage: processPdu initiated')\n\n                return restOfWholeMsg\n\n        else:\n            # 4.2.2.2 (response)\n\n            # 4.2.2.2.1\n            cachedParams = self._cache.pop(sendPduHandle)\n\n            # 4.2.2.2.2\n            if cachedParams is None:\n                snmpUnknownPDUHandlers, = mibBuilder.importSymbols(\n                    '__SNMP-MPD-MIB', 'snmpUnknownPDUHandlers')\n                snmpUnknownPDUHandlers.syntax += 1\n\n                return restOfWholeMsg\n\n            debug.logger & debug.FLAG_DSP and debug.logger(\n                'receiveMessage: cache read by sendPduHandle %s' % sendPduHandle)\n\n            # 4.2.2.2.3\n            # no-op ? XXX\n\n            snmpEngine.observer.storeExecutionContext(\n                snmpEngine, 'rfc3412.receiveMessage:response',\n                dict(transportDomain=transportDomain,\n                     transportAddress=transportAddress,\n                     wholeMsg=wholeMsg,\n                     messageProcessingModel=messageProcessingModel,\n                     securityModel=securityModel,\n                     securityName=securityName,\n                     securityLevel=securityLevel,\n                     contextEngineId=contextEngineId,\n                     contextName=contextName,\n                     pdu=PDU))\n\n            # 4.2.2.2.4\n            processResponsePdu = cachedParams['cbFun']\n\n            processResponsePdu(\n                snmpEngine, messageProcessingModel, securityModel,\n                securityName, securityLevel, contextEngineId, contextName,\n                pduVersion, PDU, statusInformation,\n                cachedParams['sendPduHandle'],\n                cachedParams['cbCtx'])\n\n            snmpEngine.observer.clearExecutionContext(\n                snmpEngine, 'rfc3412.receiveMessage:response')\n\n            debug.logger & debug.FLAG_DSP and debug.logger(\n                'receiveMessage: processResponsePdu succeeded')\n\n            return restOfWholeMsg"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sendNotification(snmpEngine, authData, transportTarget, contextData,\n                     notifyType, *varBinds, **options):\n    \"\"\"Sends SNMP notification.\n\n    Based on passed parameters, prepares SNMP TRAP or INFORM message\n    (:RFC:`1905#section-4.2.6`) and schedules its transmission by\n    :mod:`twisted` I/O framework at a later point of time.\n\n    Parameters\n    ----------\n    snmpEngine: :py:class:`~pysnmp.hlapi.SnmpEngine`\n        Class instance representing SNMP engine.\n\n    authData: :py:class:`~pysnmp.hlapi.CommunityData` or :py:class:`~pysnmp.hlapi.UsmUserData`\n        Class instance representing SNMP credentials.\n\n    transportTarget : :py:class:`~pysnmp.hlapi.twisted.UdpTransportTarget` or :py:class:`~pysnmp.hlapi.twisted.Udp6TransportTarget`\n        Class instance representing transport type along with SNMP peer address.\n\n    contextData: :py:class:`~pysnmp.hlapi.ContextData`\n        Class instance representing SNMP ContextEngineId and ContextName values.\n\n    notifyType: str\n        Indicates type of notification to be sent. Recognized literal\n        values are *trap* or *inform*.\n\n    \\*varBinds: :class:`tuple` of OID-value pairs or :py:class:`~pysnmp.smi.rfc1902.ObjectType` or :py:class:`~pysnmp.smi.rfc1902.NotificationType`\n        One or more objects representing MIB variables to place\n        into SNMP notification. It could be tuples of OID-values\n        or :py:class:`~pysnmp.smi.rfc1902.ObjectType` class instances\n        of :py:class:`~pysnmp.smi.rfc1902.NotificationType` objects.\n\n        SNMP Notification PDU includes some housekeeping items that\n        are required for SNMP to function.\n\n        Agent information:\n\n        * SNMPv2-MIB::sysUpTime.0 = <agent uptime>\n        * SNMPv2-SMI::snmpTrapOID.0 = {SNMPv2-MIB::coldStart, ...}\n\n        Applicable to SNMP v1 TRAP:\n\n        * SNMP-COMMUNITY-MIB::snmpTrapAddress.0 = <agent-IP>\n        * SNMP-COMMUNITY-MIB::snmpTrapCommunity.0 = <snmp-community-name>\n        * SNMP-COMMUNITY-MIB::snmpTrapEnterprise.0 = <enterprise-OID>\n\n        .. note::\n\n           Unless user passes some of these variable-bindings, `.sendNotification()`\n           call will fill in the missing items.\n\n        User variable-bindings:\n\n        * SNMPv2-SMI::NOTIFICATION-TYPE\n        * SNMPv2-SMI::OBJECT-TYPE\n\n        .. note::\n\n           The :py:class:`~pysnmp.smi.rfc1902.NotificationType` object ensures\n           properly formed SNMP notification (to comply MIB definition). If you\n           build notification PDU out of :py:class:`~pysnmp.smi.rfc1902.ObjectType`\n           objects or simple tuples of OID-value objects, it is your responsibility\n           to provide well-formed notification payload.\n\n    Other Parameters\n    ----------------\n    \\*\\*options :\n        Request options:\n\n            * `lookupMib` - load MIB and resolve response MIB variables at\n              the cost of slightly reduced performance. Default is `True`.\n\n    Returns\n    -------\n    deferred : :class:`~twisted.internet.defer.Deferred`\n        Twisted Deferred object representing work-in-progress. User\n        is expected to attach his own `success` and `error` callback\n        functions to the Deferred object though\n        :meth:`~twisted.internet.defer.Deferred.addCallbacks` method.\n\n    Raises\n    ------\n    PySnmpError\n        Or its derivative indicating that an error occurred while\n        performing SNMP operation.\n\n    Notes\n    -----\n    User `success` callback is called with the following tuple as\n    its first argument:\n\n    * errorStatus (str) : True value indicates SNMP PDU error.\n    * errorIndex (int) : Non-zero value refers to `varBinds[errorIndex-1]`\n    * varBinds (tuple) : A sequence of\n      :class:`~pysnmp.smi.rfc1902.ObjectType` class instances representing\n      MIB variables returned in SNMP response.\n\n    User `error` callback is called with `errorIndication` object wrapped\n    in :class:`~twisted.python.failure.Failure` object.\n\n    Examples\n    --------\n    >>> from twisted.internet.task import react\n    >>> from pysnmp.hlapi.twisted import *\n    >>>\n    >>> def success(args):\n    ...     (errorStatus, errorIndex, varBinds) = args\n    ...     print(errorStatus, errorIndex, varBind)\n    ...\n    >>> def failure(errorIndication):\n    ...     print(errorIndication)\n    ...\n    >>> def run(reactor):\n    ...     d = sendNotification(SnmpEngine(),\n    ...                          CommunityData('public'),\n    ...                          UdpTransportTarget(('demo.snmplabs.com', 162)),\n    ...                          ContextData(),\n    ...                          'trap',\n    ...                          NotificationType(ObjectIdentity('IF-MIB', 'linkDown')))\n    ...     d.addCallback(success).addErrback(failure)\n    ...     return d\n    ...\n    >>> react(run)\n    (0, 0, [])\n    \"\"\"\n    def __cbFun(snmpEngine, sendRequestHandle,\n                errorIndication, errorStatus, errorIndex,\n                varBinds, cbCtx):\n\n        lookupMib, deferred = cbCtx\n\n        if errorIndication:\n            deferred.errback(Failure(errorIndication))\n\n        else:\n            try:\n                varBinds = VB_PROCESSOR.unmakeVarBinds(\n                    snmpEngine.cache, varBinds, lookupMib)\n\n            except Exception as e:\n                deferred.errback(Failure(e))\n\n            else:\n                deferred.callback((errorStatus, errorIndex, varBinds))\n\n    notifyName = LCD.configure(snmpEngine, authData, transportTarget,\n                               notifyType, contextData.contextName)\n\n    def __trapFun(deferred):\n        deferred.callback((0, 0, []))\n\n    varBinds = VB_PROCESSOR.makeVarBinds(snmpEngine.cache, varBinds)\n\n    deferred = Deferred()\n\n    ntforg.NotificationOriginator().sendVarBinds(\n        snmpEngine, notifyName, contextData.contextEngineId,\n        contextData.contextName, varBinds, __cbFun,\n        (options.get('lookupMib', True), deferred)\n    )\n\n    if notifyType == 'trap':\n        reactor.callLater(0, __trapFun, deferred)\n\n    return deferred", "response": "Sends a new notification to the given context."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sendNotification(snmpDispatcher, authData, transportTarget,\n                     notifyType, *varBinds, **options):\n    \"\"\"Creates a generator to send one or more SNMP notifications.\n\n    On each iteration, new SNMP TRAP or INFORM notification is send\n    (:RFC:`1905#section-4,2,6`). The iterator blocks waiting for\n    INFORM acknowledgement to arrive or error to occur.\n\n    Parameters\n    ----------\n    snmpDispatcher: :py:class:`~pysnmp.hlapi.v1arch.asyncore.SnmpDispatcher`\n        Class instance representing asyncore-based asynchronous event loop and\n        associated state information.\n\n    authData: :py:class:`~pysnmp.hlapi.CommunityData` or :py:class:`~pysnmp.hlapi.UsmUserData`\n        Class instance representing SNMP credentials.\n\n    transportTarget: :py:class:`~pysnmp.hlapi.asyncore.UdpTransportTarget` or\n        :py:class:`~pysnmp.hlapi.asyncore.Udp6TransportTarget`\n        Class instance representing transport type along with SNMP peer address.\n\n    notifyType: str\n        Indicates type of notification to be sent. Recognized literal\n        values are *trap* or *inform*.\n\n    \\*varBinds: :class:`tuple` of OID-value pairs or :py:class:`~pysnmp.smi.rfc1902.ObjectType` or :py:class:`~pysnmp.smi.rfc1902.NotificationType`\n        One or more objects representing MIB variables to place\n        into SNMP notification. It could be tuples of OID-values\n        or :py:class:`~pysnmp.smi.rfc1902.ObjectType` class instances\n        of :py:class:`~pysnmp.smi.rfc1902.NotificationType` objects.\n\n        Besides user variable-bindings, SNMP Notification PDU requires at\n        least two variable-bindings to be present:\n\n        0. SNMPv2-MIB::sysUpTime.0 = <agent uptime>\n        1. SNMPv2-SMI::snmpTrapOID.0 = <notification ID>\n\n        When sending SNMPv1 TRAP, more variable-bindings could be present:\n\n        2. SNMP-COMMUNITY-MIB::snmpTrapAddress.0 = <agent-IP>\n        3. SNMP-COMMUNITY-MIB::snmpTrapCommunity.0 = <snmp-community-name>\n        4. SNMP-COMMUNITY-MIB::snmpTrapEnterprise.0 = <enterprise-OID>\n\n        If user does not supply some or any of the above variable-bindings or\n        if they are at the wrong positions, the system will add/reorder the\n        missing ones automatically.\n\n        On top of that, some notification types imply including some additional\n        variable-bindings providing additional details on the event being\n        reported. Therefore it is generally easier to use\n        :py:class:`~pysnmp.smi.rfc1902.NotificationType` object which will\n        help adding relevant variable-bindings.\n\n    Other Parameters\n    ----------------\n    \\*\\*options :\n        Request options:\n\n            * `lookupMib` - load MIB and resolve response MIB variables at\n              the cost of slightly reduced performance. Default is `False`.\n\n    Yields\n    ------\n    errorIndication: str\n        True value indicates local SNMP error.\n    errorStatus: str\n        True value indicates SNMP PDU error reported by remote.\n    errorIndex: int\n        Non-zero value refers to `varBinds[errorIndex-1]`\n    varBinds: tuple\n        A sequence of :py:class:`~pysnmp.smi.rfc1902.ObjectType` class\n        instances representing MIB variables returned in SNMP response.\n\n    Raises\n    ------\n    PySnmpError\n        Or its derivative indicating that an error occurred while\n        performing SNMP operation.\n\n    Notes\n    -----\n    The `sendNotification` generator will be exhausted immediately unless\n    an instance of :py:class:`~pysnmp.smi.rfc1902.NotificationType` class\n    or a sequence of :py:class:`~pysnmp.smi.rfc1902.ObjectType` `varBinds`\n    are send back into running generator (supported since Python 2.6).\n\n    Examples\n    --------\n    >>> from pysnmp.hlapi.v1arch import *\n    >>>\n    >>> g = sendNotification(SnmpDispatcher(),\n    >>>                      CommunityData('public'),\n    >>>                      UdpTransportTarget(('demo.snmplabs.com', 162)),\n    >>>                      'trap',\n    >>>                      NotificationType(ObjectIdentity('IF-MIB', 'linkDown')))\n    >>> next(g)\n    (None, 0, 0, [])\n    \"\"\"\n\n    def cbFun(*args, **kwargs):\n        response[:] = args\n\n    options['cbFun'] = cbFun\n\n    errorIndication, errorStatus, errorIndex = None, 0, 0\n\n    response = [None, 0, 0, []]\n\n    while True:\n        if varBinds:\n            ntforg.sendNotification(snmpDispatcher, authData, transportTarget,\n                                    notifyType, *varBinds, **options)\n\n            snmpDispatcher.transportDispatcher.runDispatcher()\n\n            errorIndication, errorStatus, errorIndex, varBinds = response\n\n        varBinds = (yield errorIndication, errorStatus, errorIndex, varBinds)\n\n        if not varBinds:\n            break", "response": "Sends one or more SNMP notifications to the given target."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nperforms SNMP GET query. Based on passed parameters, prepares SNMP GET packet (:RFC:`1905#section-4.2.1`) and schedules its transmission by :mod:`twisted` I/O framework at a later point of time. Parameters ---------- snmpEngine : :class:`~pysnmp.hlapi.SnmpEngine` Class instance representing SNMP engine. authData : :class:`~pysnmp.hlapi.CommunityData` or :class:`~pysnmp.hlapi.UsmUserData` Class instance representing SNMP credentials. transportTarget : :class:`~pysnmp.hlapi.twisted.UdpTransportTarget` or :class:`~pysnmp.hlapi.twisted.Udp6TransportTarget` Class instance representing transport type along with SNMP peer address. contextData : :class:`~pysnmp.hlapi.ContextData` Class instance representing SNMP ContextEngineId and ContextName values. \\*varBinds : :class:`~pysnmp.smi.rfc1902.ObjectType` One or more class instances representing MIB variables to place into SNMP request. Other Parameters ---------------- \\*\\*options : Request options: * `lookupMib` - load MIB and resolve response MIB variables at the cost of slightly reduced performance. Default is `True`. Returns ------- deferred : :class:`~twisted.internet.defer.Deferred` Twisted Deferred object representing work-in-progress. User is expected to attach his own `success` and `error` callback functions to the Deferred object though :meth:`~twisted.internet.defer.Deferred.addCallbacks` method. Raises ------ PySnmpError Or its derivative indicating that an error occurred while performing SNMP operation. Notes ----- User `success` callback is called with the following tuple as its first argument: * errorStatus (str) : True value indicates SNMP PDU error. * errorIndex (int) : Non-zero value refers to `varBinds[errorIndex-1]` * varBinds (tuple) : A sequence of :class:`~pysnmp.smi.rfc1902.ObjectType` class instances representing MIB variables returned in SNMP response. User `error` callback is called with `errorIndication` object wrapped in :class:`~twisted.python.failure.Failure` object. Examples -------- >>> from twisted.internet.task import react >>> from pysnmp.hlapi.twisted import * >>> >>> def success(args): ... (errorStatus, errorIndex, varBinds) = args ... print(errorStatus, errorIndex, varBind) ... >>> def failure(errorIndication): ... print(errorIndication) ... >>> def run(reactor): ... d = getCmd(SnmpEngine(), ... CommunityData('public'), ... UdpTransportTarget(('demo.snmplabs.com', 161)), ... ContextData(), ... ObjectType(ObjectIdentity('SNMPv2-MIB', 'sysDescr', 0))) ... d.addCallback(success).addErrback(failure) ... return d ... >>> react(run) (0, 0, [ObjectType(ObjectIdentity(ObjectName('1.3.6.1.2.1.1.1.0')), DisplayString('SunOS zeus.snmplabs.com 4.1.3_U1 1 sun4m'))])", "response": "def getCmd(snmpEngine, authData, transportTarget, contextData,\n           *varBinds, **options):\n    \"\"\"Performs SNMP GET query.\n\n    Based on passed parameters, prepares SNMP GET packet\n    (:RFC:`1905#section-4.2.1`) and schedules its transmission by\n    :mod:`twisted` I/O framework at a later point of time.\n\n    Parameters\n    ----------\n    snmpEngine : :class:`~pysnmp.hlapi.SnmpEngine`\n        Class instance representing SNMP engine.\n\n    authData : :class:`~pysnmp.hlapi.CommunityData` or :class:`~pysnmp.hlapi.UsmUserData`\n        Class instance representing SNMP credentials.\n\n    transportTarget : :class:`~pysnmp.hlapi.twisted.UdpTransportTarget` or :class:`~pysnmp.hlapi.twisted.Udp6TransportTarget`\n        Class instance representing transport type along with SNMP peer address.\n\n    contextData : :class:`~pysnmp.hlapi.ContextData`\n        Class instance representing SNMP ContextEngineId and ContextName values.\n\n    \\*varBinds : :class:`~pysnmp.smi.rfc1902.ObjectType`\n        One or more class instances representing MIB variables to place\n        into SNMP request.\n\n    Other Parameters\n    ----------------\n    \\*\\*options :\n        Request options:\n\n            * `lookupMib` - load MIB and resolve response MIB variables at\n              the cost of slightly reduced performance. Default is `True`.\n\n    Returns\n    -------\n    deferred : :class:`~twisted.internet.defer.Deferred`\n        Twisted Deferred object representing work-in-progress. User\n        is expected to attach his own `success` and `error` callback\n        functions to the Deferred object though\n        :meth:`~twisted.internet.defer.Deferred.addCallbacks` method.\n\n    Raises\n    ------\n    PySnmpError\n        Or its derivative indicating that an error occurred while\n        performing SNMP operation.\n\n    Notes\n    -----\n    User `success` callback is called with the following tuple as\n    its first argument:\n\n    * errorStatus (str) : True value indicates SNMP PDU error.\n    * errorIndex (int) : Non-zero value refers to `varBinds[errorIndex-1]`\n    * varBinds (tuple) : A sequence of\n      :class:`~pysnmp.smi.rfc1902.ObjectType` class instances representing\n      MIB variables returned in SNMP response.\n\n    User `error` callback is called with `errorIndication` object wrapped\n    in :class:`~twisted.python.failure.Failure` object.\n\n    Examples\n    --------\n    >>> from twisted.internet.task import react\n    >>> from pysnmp.hlapi.twisted import *\n    >>>\n    >>> def success(args):\n    ...     (errorStatus, errorIndex, varBinds) = args\n    ...     print(errorStatus, errorIndex, varBind)\n    ...\n    >>> def failure(errorIndication):\n    ...     print(errorIndication)\n    ...\n    >>> def run(reactor):\n    ...     d = getCmd(SnmpEngine(),\n    ...                CommunityData('public'),\n    ...                UdpTransportTarget(('demo.snmplabs.com', 161)),\n    ...                ContextData(),\n    ...                ObjectType(ObjectIdentity('SNMPv2-MIB', 'sysDescr', 0)))\n    ...     d.addCallback(success).addErrback(failure)\n    ...     return d\n    ...\n    >>> react(run)\n    (0, 0, [ObjectType(ObjectIdentity(ObjectName('1.3.6.1.2.1.1.1.0')), DisplayString('SunOS zeus.snmplabs.com 4.1.3_U1 1 sun4m'))])\n    \"\"\"\n    def __cbFun(snmpEngine, sendRequestHandle,\n                errorIndication, errorStatus, errorIndex,\n                varBinds, cbCtx):\n\n        lookupMib, deferred = cbCtx\n\n        if errorIndication:\n            deferred.errback(Failure(errorIndication))\n\n        else:\n            try:\n                varBinds = VB_PROCESSOR.unmakeVarBinds(snmpEngine.cache, varBinds, lookupMib)\n\n            except Exception as e:\n                deferred.errback(Failure(e))\n\n            else:\n                deferred.callback((errorStatus, errorIndex, varBinds))\n\n    addrName, paramsName = LCD.configure(\n        snmpEngine, authData, transportTarget, contextData.contextName)\n\n    varBinds = VB_PROCESSOR.makeVarBinds(snmpEngine.cache, varBinds)\n\n    deferred = Deferred()\n\n    cmdgen.GetCommandGenerator().sendVarBinds(\n        snmpEngine, addrName, contextData.contextEngineId,\n        contextData.contextName, varBinds, __cbFun,\n        (options.get('lookupMib', True), deferred))\n\n    return deferred"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef nextCmd(snmpEngine, authData, transportTarget, contextData,\n            *varBinds, **options):\n    \"\"\"Performs SNMP GETNEXT query.\n\n    Based on passed parameters, prepares SNMP GETNEXT packet\n    (:RFC:`1905#section-4.2.2`) and schedules its transmission by\n    :mod:`twisted` I/O framework at a later point of time.\n\n    Parameters\n    ----------\n    snmpEngine : :class:`~pysnmp.hlapi.SnmpEngine`\n        Class instance representing SNMP engine.\n\n    authData : :class:`~pysnmp.hlapi.CommunityData` or :class:`~pysnmp.hlapi.UsmUserData`\n        Class instance representing SNMP credentials.\n\n    transportTarget : :class:`~pysnmp.hlapi.twisted.UdpTransportTarget` or :class:`~pysnmp.hlapi.twisted.Udp6TransportTarget`\n        Class instance representing transport type along with SNMP peer address.\n\n    contextData : :class:`~pysnmp.hlapi.ContextData`\n        Class instance representing SNMP ContextEngineId and ContextName values.\n\n    \\*varBinds : :class:`~pysnmp.smi.rfc1902.ObjectType`\n        One or more class instances representing MIB variables to place\n        into SNMP request.\n\n    Other Parameters\n    ----------------\n    \\*\\*options :\n        Request options:\n\n            * `lookupMib` - load MIB and resolve response MIB variables at\n              the cost of slightly reduced performance. Default is `True`.\n            * `ignoreNonIncreasingOid` - continue iteration even if response\n              MIB variables (OIDs) are not greater then request MIB variables.\n              Be aware that setting it to `True` may cause infinite loop between\n              SNMP management and agent applications. Default is `False`.\n\n    Returns\n    -------\n    deferred : :class:`~twisted.internet.defer.Deferred`\n        Twisted Deferred object representing work-in-progress. User\n        is expected to attach his own `success` and `error` callback\n        functions to the Deferred object though\n        :meth:`~twisted.internet.defer.Deferred.addCallbacks` method.\n\n    Raises\n    ------\n    PySnmpError\n        Or its derivative indicating that an error occurred while\n        performing SNMP operation.\n\n    Notes\n    -----\n    User `success` callback is called with the following tuple as\n    its first argument:\n\n    * errorStatus (str) : True value indicates SNMP PDU error.\n    * errorIndex (int) : Non-zero value refers to `varBinds[errorIndex-1]`\n    * varBinds (tuple) :\n        A sequence of sequences (e.g. 2-D array) of\n        :py:class:`~pysnmp.smi.rfc1902.ObjectType` class instances\n        representing a table of MIB variables returned in SNMP response.\n        Inner sequences represent table rows and ordered exactly the same\n        as `varBinds` in request. Response to GETNEXT always contain\n        a single row.\n\n    User `error` callback is called with `errorIndication` object wrapped\n    in :class:`~twisted.python.failure.Failure` object.\n\n    Examples\n    --------\n    >>> from twisted.internet.task import react\n    >>> from pysnmp.hlapi.twisted import *\n    >>>\n    >>> def success(args):\n    ...     (errorStatus, errorIndex, varBindTable) = args\n    ...     print(errorStatus, errorIndex, varBindTable)\n    ...\n    >>> def failure(errorIndication):\n    ...     print(errorIndication)\n    ...\n    >>> def run(reactor):\n    ...     d = nextCmd(SnmpEngine(),\n    ...                 CommunityData('public'),\n    ...                 UdpTransportTarget(('demo.snmplabs.com', 161)),\n    ...                 ContextData(),\n    ...                 ObjectType(ObjectIdentity('SNMPv2-MIB', 'system'))\n    ...     d.addCallback(success).addErrback(failure)\n    ...     return d\n    ...\n    >>> react(run)\n    (0, 0, [[ObjectType(ObjectIdentity(ObjectName('1.3.6.1.2.1.1.1.0')), DisplayString('SunOS zeus.snmplabs.com 4.1.3_U1 1 sun4m'))]])\n    \"\"\"\n    def __cbFun(snmpEngine, sendRequestHandle,\n                errorIndication, errorStatus, errorIndex,\n                varBindTable, cbCtx):\n\n        lookupMib, deferred = cbCtx\n\n        if (options.get('ignoreNonIncreasingOid', False) and errorIndication\n                and isinstance(errorIndication, errind.OidNotIncreasing)):\n            errorIndication = None\n\n        if errorIndication:\n            deferred.errback(Failure(errorIndication))\n\n        else:\n            try:\n                varBindTable = [\n                    VB_PROCESSOR.unmakeVarBinds(snmpEngine.cache,\n                                                varBindTableRow, lookupMib)\n                    for varBindTableRow in varBindTable\n                ]\n\n            except Exception as e:\n                deferred.errback(Failure(e))\n\n            else:\n                deferred.callback((errorStatus, errorIndex, varBindTable))\n\n    addrName, paramsName = LCD.configure(\n        snmpEngine, authData, transportTarget, contextData.contextName)\n\n    varBinds = VB_PROCESSOR.makeVarBinds(snmpEngine.cache, varBinds)\n\n    deferred = Deferred()\n\n    cmdgen.NextCommandGenerator().sendVarBinds(\n        snmpEngine, addrName, contextData.contextEngineId,\n        contextData.contextName, varBinds, __cbFun,\n        (options.get('lookupMib', True), deferred))\n\n    return deferred", "response": "This function prepares and schedules the next command for the next segment of the current segment."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getBranch(self, name, **context):\n        for keyLen in self._vars.getKeysLens():\n            subName = name[:keyLen]\n            if subName in self._vars:\n                return self._vars[subName]\n\n        raise error.NoSuchObjectError(name=name, idx=context.get('idx'))", "response": "Return a branch of this tree where the name OID may reside"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns tree node found by name", "response": "def getNode(self, name, **context):\n        \"\"\"Return tree node found by name\"\"\"\n        if name == self.name:\n            return self\n        else:\n            return self.getBranch(name, **context).getNode(name, **context)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns tree node next to name", "response": "def getNextNode(self, name, **context):\n        \"\"\"Return tree node next to name\"\"\"\n        try:\n            nextNode = self.getBranch(name, **context)\n        except (error.NoSuchInstanceError, error.NoSuchObjectError):\n            return self.getNextBranch(name, **context)\n        else:\n            try:\n                return nextNode.getNextNode(name, **context)\n            except (error.NoSuchInstanceError, error.NoSuchObjectError):\n                try:\n                    return self._vars[self._vars.nextKey(nextNode.name)]\n                except KeyError:\n                    raise error.NoSuchObjectError(name=name, idx=context.get('idx'))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncommitting new value of the Managed Object Instance. Implements the second of the multi-step workflow of the SNMP SET command processing (:RFC:`1905#section-4.2.5`). The goal of the second phase is to actually modify the requested Managed Object Instance. When multiple Managed Objects Instances are modified at once (likely coming all in one SNMP PDU), each of them has to run through the second (*commit*) phase successfully for the system to transition to the third (*cleanup*) phase. If any single *commit* step fails, the system transitions into the *undo* state for each of Managed Objects Instances being processed at once. The role of this object in the MIB tree is non-terminal. It does not access the actual Managed Object Instance, but just traverses one level down the MIB tree and hands off the query to the underlying objects. Parameters ---------- varBind: :py:class:`~pysnmp.smi.rfc1902.ObjectType` object representing new Managed Object Instance value to set Other Parameters ---------------- \\*\\*context: Query parameters: * `cbFun` (callable) - user-supplied callable that is invoked to pass the new value of the Managed Object Instance or an error. Notes ----- The callback functions (e.g. `cbFun`) have the same signature as this method where `varBind` contains the new Managed Object Instance value. In case of an error, the `error` key in the `context` dict will contain an exception object.", "response": "def writeCommit(self, varBind, **context):\n        \"\"\"Commit new value of the Managed Object Instance.\n\n        Implements the second of the multi-step workflow of the SNMP SET\n        command processing (:RFC:`1905#section-4.2.5`).\n\n        The goal of the second phase is to actually modify the requested Managed\n        Object Instance. When multiple Managed Objects Instances are modified at\n        once (likely coming all in one SNMP PDU), each of them has to run through\n        the second (*commit*) phase successfully for the system to transition to\n        the third (*cleanup*) phase. If any single *commit* step fails, the system\n        transitions into the *undo* state for each of Managed Objects Instances\n        being processed at once.\n\n        The role of this object in the MIB tree is non-terminal. It does not\n        access the actual Managed Object Instance, but just traverses one level\n        down the MIB tree and hands off the query to the underlying objects.\n\n        Parameters\n        ----------\n        varBind: :py:class:`~pysnmp.smi.rfc1902.ObjectType` object representing\n            new Managed Object Instance value to set\n\n        Other Parameters\n        ----------------\n        \\*\\*context:\n\n            Query parameters:\n\n            * `cbFun` (callable) - user-supplied callable that is invoked to\n              pass the new value of the Managed Object Instance or an error.\n\n        Notes\n        -----\n        The callback functions (e.g. `cbFun`) have the same signature as this\n        method where `varBind` contains the new Managed Object Instance value.\n\n        In case of an error, the `error` key in the `context` dict will contain\n        an exception object.\n        \"\"\"\n        name, val = varBind\n\n        (debug.logger & debug.FLAG_INS and\n         debug.logger('%s: writeCommit(%s, %r)' % (self, name, val)))\n\n        cbFun = context['cbFun']\n\n        instances = context['instances'].setdefault(self.name, {self.ST_CREATE: {}, self.ST_DESTROY: {}})\n        idx = context['idx']\n\n        if idx in instances[self.ST_CREATE]:\n            self.createCommit(varBind, **context)\n            return\n \n        if idx in instances[self.ST_DESTROY]:\n            self.destroyCommit(varBind, **context)\n            return\n\n        try:\n            node = self.getBranch(name, **context)\n\n        except (error.NoSuchInstanceError, error.NoSuchObjectError) as exc:\n            cbFun(varBind, **dict(context, error=exc))\n\n        else:\n            node.writeCommit(varBind, **context)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinalizes Managed Object Instance modification.", "response": "def writeCleanup(self, varBind, **context):\n        \"\"\"Finalize Managed Object Instance modification.\n\n        Implements the successful third step of the multi-step workflow of the\n        SNMP SET command processing (:RFC:`1905#section-4.2.5`).\n\n        The goal of the third (successful) phase is to seal the new state of the\n        requested Managed Object Instance. Once the system transition into the\n        *cleanup* state, no roll back to the previous Managed Object Instance\n        state is possible.\n\n        The role of this object in the MIB tree is non-terminal. It does not\n        access the actual Managed Object Instance, but just traverses one level\n        down the MIB tree and hands off the query to the underlying objects.\n\n        Parameters\n        ----------\n        varBind: :py:class:`~pysnmp.smi.rfc1902.ObjectType` object representing\n            new Managed Object Instance value to set\n\n        Other Parameters\n        ----------------\n        \\*\\*context:\n\n            Query parameters:\n\n            * `cbFun` (callable) - user-supplied callable that is invoked to\n              pass the new value of the Managed Object Instance or an error.\n\n        Notes\n        -----\n        The callback functions (e.g. `cbFun`) have the same signature as this\n        method where `varBind` contains the new Managed Object Instance value.\n\n        In case of an error, the `error` key in the `context` dict will contain\n        an exception object.\n        \"\"\"\n        name, val = varBind\n\n        (debug.logger & debug.FLAG_INS and\n         debug.logger('%s: writeCleanup(%s, %r)' % (self, name, val)))\n\n        cbFun = context['cbFun']\n\n        self.branchVersionId += 1\n\n        instances = context['instances'].setdefault(self.name, {self.ST_CREATE: {}, self.ST_DESTROY: {}})\n        idx = context['idx']\n\n        if idx in instances[self.ST_CREATE]:\n            self.createCleanup(varBind, **context)\n            return\n\n        if idx in instances[self.ST_DESTROY]:\n            self.destroyCleanup(varBind, **context)\n            return\n\n        try:\n            node = self.getBranch(name, **context)\n\n        except (error.NoSuchInstanceError, error.NoSuchObjectError) as exc:\n            cbFun(varBind, **dict(context, error=exc))\n\n        else:\n            node.writeCleanup(varBind, **context)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef writeUndo(self, varBind, **context):\n        name, val = varBind\n\n        (debug.logger & debug.FLAG_INS and\n         debug.logger('%s: writeUndo(%s, %r)' % (self, name, val)))\n\n        cbFun = context['cbFun']\n\n        instances = context['instances'].setdefault(self.name, {self.ST_CREATE: {}, self.ST_DESTROY: {}})\n        idx = context['idx']\n\n        if idx in instances[self.ST_CREATE]:\n            self.createUndo(varBind, **context)\n            return\n\n        if idx in instances[self.ST_DESTROY]:\n            self.destroyUndo(varBind, **context)\n            return\n\n        try:\n            node = self.getBranch(name, **context)\n\n        except (error.NoSuchInstanceError, error.NoSuchObjectError) as exc:\n            cbFun(varBind, **dict(context, error=exc))\n\n        else:\n            node.writeUndo(varBind, **context)", "response": "Finalize Managed Object Instance modification. This method is used to finalize the Managed Object Instance modification."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads Managed Object Instance. Implements the second of the two phases of the SNMP GET command processing (:RFC:`1905#section-4.2.1`). The goal of the second phase is to actually read the requested Managed Object Instance. When multiple Managed Objects Instances are read at once (likely coming all in one SNMP PDU), each of them has to run through the first (*test*) and second (*read) phases successfully for the whole read operation to succeed. The role of this object in the MIB tree is non-terminal. It does not access the actual Managed Object Instance, but just traverses one level down the MIB tree and hands off the query to the underlying objects. Beyond that, this object imposes access control logic towards the underlying :class:`MibScalarInstance` objects by invoking the `acFun` callable. Parameters ---------- varBind: :py:class:`~pysnmp.smi.rfc1902.ObjectType` object representing Managed Object Instance to read Other Parameters ---------------- \\*\\*context: Query parameters: * `cbFun` (callable) - user-supplied callable that is invoked to pass read Managed Object Instance or an error. * `acFun` (callable) - user-supplied callable that is invoked to authorize access to the requested Managed Object Instance. If not supplied, no access control will be performed. Notes ----- The callback functions (e.g. `cbFun`, `acFun`) has the same signature as this method where `varBind` contains read Managed Object Instance value. In case of an error, the `error` key in the `context` dict will contain an exception object.", "response": "def readGet(self, varBind, **context):\n        \"\"\"Read Managed Object Instance.\n\n        Implements the second of the two phases of the SNMP GET command\n        processing (:RFC:`1905#section-4.2.1`).\n\n        The goal of the second phase is to actually read the requested Managed\n        Object Instance. When multiple Managed Objects Instances are read at\n        once (likely coming all in one SNMP PDU), each of them has to run through\n        the first (*test*) and second (*read) phases successfully for the whole\n        read operation to succeed.\n\n        The role of this object in the MIB tree is non-terminal. It does not\n        access the actual Managed Object Instance, but just traverses one level\n        down the MIB tree and hands off the query to the underlying objects.\n\n        Beyond that, this object imposes access control logic towards the\n        underlying :class:`MibScalarInstance` objects by invoking the `acFun`\n        callable.\n\n        Parameters\n        ----------\n        varBind: :py:class:`~pysnmp.smi.rfc1902.ObjectType` object representing\n            Managed Object Instance to read\n\n        Other Parameters\n        ----------------\n        \\*\\*context:\n\n            Query parameters:\n\n            * `cbFun` (callable) - user-supplied callable that is invoked to\n              pass read Managed Object Instance or an error.\n\n            * `acFun` (callable) - user-supplied callable that is invoked to\n               authorize access to the requested Managed Object Instance. If\n               not supplied, no access control will be performed.\n\n        Notes\n        -----\n        The callback functions (e.g. `cbFun`, `acFun`) has the same signature as\n        this method where `varBind` contains read Managed Object Instance value.\n\n        In case of an error, the `error` key in the `context` dict will contain\n        an exception object.\n        \"\"\"\n        name, val = varBind\n\n        (debug.logger & debug.FLAG_INS and\n         debug.logger('%s: readGet(%s, %r)' % (self, name, val)))\n\n        cbFun = context['cbFun']\n\n        if name == self.name:\n            cbFun((name, exval.noSuchInstance), **context)\n            return\n\n        acFun = context.get('acFun')\n        if acFun:\n            if (self.maxAccess not in ('readonly', 'readwrite', 'readcreate') or\n                    acFun('read', (name, self.syntax), **context)):\n                cbFun((name, exval.noSuchInstance), **context)\n                return\n\n        ManagedMibObject.readGet(self, varBind, **context)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads the next Managed Object Instance. Implements the second of the two phases of the SNMP GETNEXT command processing (:RFC:`1905#section-4.2.2`). The goal of the second phase is to actually read the Managed Object Instance which is next in the MIB tree to the one being requested. When multiple Managed Objects Instances are read at once (likely coming all in one SNMP PDU), each of them has to run through the first (*testnext*) and second (*getnext*) phases successfully for the whole read operation to succeed. The role of this object in the MIB tree is non-terminal. It does not access the actual Managed Object Instance, but just traverses one level down the MIB tree and hands off the query to the underlying objects. Beyond that, this object imposes access control logic towards the underlying :class:`MibScalarInstance` objects by invoking the `acFun` callable. Parameters ---------- varBind: :py:class:`~pysnmp.smi.rfc1902.ObjectType` object representing Managed Object Instance to read Other Parameters ---------------- \\*\\*context: Query parameters: * `cbFun` (callable) - user-supplied callable that is invoked to pass read Managed Object Instance (the *next* one in the MIB tree relative to the one being requested) or an error. * `acFun` (callable) - user-supplied callable that is invoked to authorize access to the Managed Object Instance which is *next* to the one being requested. If not supplied, no access control will be performed. Notes ----- The callback functions (e.g. `cbFun`, `acFun`) have the same signature as this method where `varBind` contains read Managed Object Instance value. In case of an error, the `error` key in the `context` dict will contain an exception object.", "response": "def readGetNext(self, varBind, **context):\n        \"\"\"Read the next Managed Object Instance.\n\n        Implements the second of the two phases of the SNMP GETNEXT command\n        processing (:RFC:`1905#section-4.2.2`).\n\n        The goal of the second phase is to actually read the Managed Object\n        Instance which is next in the MIB tree to the one being requested.\n        When multiple Managed Objects Instances are read at once (likely coming\n        all in one SNMP PDU), each of them has to run through the first\n        (*testnext*) and second (*getnext*) phases successfully for the whole\n        read operation to succeed.\n\n        The role of this object in the MIB tree is non-terminal. It does not\n        access the actual Managed Object Instance, but just traverses one level\n        down the MIB tree and hands off the query to the underlying objects.\n\n        Beyond that, this object imposes access control logic towards the\n        underlying :class:`MibScalarInstance` objects by invoking the `acFun`\n        callable.\n\n        Parameters\n        ----------\n        varBind: :py:class:`~pysnmp.smi.rfc1902.ObjectType` object representing\n            Managed Object Instance to read\n\n        Other Parameters\n        ----------------\n        \\*\\*context:\n\n            Query parameters:\n\n            * `cbFun` (callable) - user-supplied callable that is invoked to\n              pass read Managed Object Instance (the *next* one in the MIB tree\n              relative to the one being requested) or an error.\n\n            * `acFun` (callable) - user-supplied callable that is invoked to\n               authorize access to the Managed Object Instance which is *next*\n               to the one being requested. If not supplied, no access control\n               will be performed.\n\n        Notes\n        -----\n        The callback functions (e.g. `cbFun`, `acFun`) have the same signature\n        as this method where `varBind` contains read Managed Object Instance\n        value.\n\n        In case of an error, the `error` key in the `context` dict will contain\n        an exception object.\n        \"\"\"\n        name, val = varBind\n\n        (debug.logger & debug.FLAG_INS and\n         debug.logger('%s: readGetNext(%s, %r)' % (self, name, val)))\n\n        acFun = context.get('acFun')\n        if acFun:\n            if (self.maxAccess not in ('readonly', 'readwrite', 'readcreate') or\n                    acFun('read', (name, self.syntax), **context)):\n                nextName = context.get('nextName')\n                if nextName:\n                    varBind = nextName, exval.noSuchInstance\n                else:\n                    varBind = name, exval.endOfMibView\n\n                cbFun = context['cbFun']\n                cbFun(varBind, **context)\n                return\n\n        ManagedMibObject.readGetNext(self, varBind, **context)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate Managed Object Instance. Implements the second of the multi-step workflow similar to the SNMP SET command processing (:RFC:`1905#section-4.2.5`). The goal of the second phase is to actually create requested Managed Object Instance. When multiple Managed Objects Instances are created/modified at once (likely coming all in one SNMP PDU), each of them has to run through the second (*commit*) phase successfully for the system to transition to the third (*cleanup*) phase. If any single *commit* step fails, the system transitions into the *undo* state for each of Managed Objects Instances being processed at once. The role of this object in the MIB tree is non-terminal. It does not access the actual Managed Object Instance, but just traverses one level down the MIB tree and hands off the query to the underlying objects. Parameters ---------- varBind: :py:class:`~pysnmp.smi.rfc1902.ObjectType` object representing new Managed Object Instance value to create Other Parameters ---------------- \\*\\*context: Query parameters: * `cbFun` (callable) - user-supplied callable that is invoked to pass the new value of the Managed Object Instance or an error. * `instances` (dict): user-supplied dict for temporarily holding Managed Objects Instances being created. Notes ----- The callback functions (e.g. `cbFun`) have the same signature as this method where `varBind` contains the new Managed Object Instance value. In case of an error, the `error` key in the `context` dict will contain an exception object.", "response": "def createCommit(self, varBind, **context):\n        \"\"\"Create Managed Object Instance.\n\n        Implements the second of the multi-step workflow similar to the SNMP SET\n        command processing (:RFC:`1905#section-4.2.5`).\n\n        The goal of the second phase is to actually create requested Managed\n        Object Instance. When multiple Managed Objects Instances are created/modified\n        at once (likely coming all in one SNMP PDU), each of them has to run through\n        the second (*commit*) phase successfully for the system to transition to\n        the third (*cleanup*) phase. If any single *commit* step fails, the system\n        transitions into the *undo* state for each of Managed Objects Instances\n        being processed at once.\n\n        The role of this object in the MIB tree is non-terminal. It does not\n        access the actual Managed Object Instance, but just traverses one level\n        down the MIB tree and hands off the query to the underlying objects.\n\n        Parameters\n        ----------\n        varBind: :py:class:`~pysnmp.smi.rfc1902.ObjectType` object representing\n            new Managed Object Instance value to create\n\n        Other Parameters\n        ----------------\n        \\*\\*context:\n\n            Query parameters:\n\n            * `cbFun` (callable) - user-supplied callable that is invoked to\n              pass the new value of the Managed Object Instance or an error.\n\n            * `instances` (dict): user-supplied dict for temporarily holding\n              Managed Objects Instances being created.\n\n        Notes\n        -----\n        The callback functions (e.g. `cbFun`) have the same signature as this\n        method where `varBind` contains the new Managed Object Instance value.\n\n        In case of an error, the `error` key in the `context` dict will contain\n        an exception object.\n        \"\"\"\n        name, val = varBind\n\n        (debug.logger & debug.FLAG_INS and\n         debug.logger('%s: writeCommit(%s, %r)' % (self, name, val)))\n\n        cbFun = context['cbFun']\n\n        instances = context['instances'].setdefault(self.name, {self.ST_CREATE: {}, self.ST_DESTROY: {}})\n        idx = context['idx']\n\n        if name in self._vars:\n            cbFun(varBind, **context)\n            return\n\n        # NOTE: multiple names are possible in a single PDU, that could collide\n        # Therefore let's keep old object indexed by (negative) var-bind index\n        self._vars[name], instances[self.ST_CREATE][-idx - 1] = instances[self.ST_CREATE][idx], self._vars.get(name)\n\n        instances[self.ST_CREATE][idx].writeCommit(varBind, **context)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinalizing Managed Object Instance creation.", "response": "def createCleanup(self, varBind, **context):\n        \"\"\"Finalize Managed Object Instance creation.\n\n        Implements the successful third step of the multi-step workflow similar to\n        the SNMP SET command processing (:RFC:`1905#section-4.2.5`).\n\n        The goal of the third (successful) phase is to seal the new Managed Object\n        Instance. Once the system transitions into the *cleanup* state, no roll back\n        to the previous Managed Object Instance state is possible.\n\n        The role of this object in the MIB tree is non-terminal. It does not\n        access the actual Managed Object Instance, but just traverses one level\n        down the MIB tree and hands off the query to the underlying objects.\n\n        Parameters\n        ----------\n        varBind: :py:class:`~pysnmp.smi.rfc1902.ObjectType` object representing\n            new Managed Object Instance value to create\n\n        Other Parameters\n        ----------------\n        \\*\\*context:\n\n            Query parameters:\n\n            * `cbFun` (callable) - user-supplied callable that is invoked to\n              pass the new value of the Managed Object Instance or an error.\n\n            * `instances` (dict): user-supplied dict for temporarily holding\n              Managed Objects Instances being created.\n\n        Notes\n        -----\n        The callback functions (e.g. `cbFun`) have the same signature as this\n        method where `varBind` contains the new Managed Object Instance value.\n\n        In case of an error, the `error` key in the `context` dict will contain\n        an exception object.\n        \"\"\"\n        name, val = varBind\n\n        (debug.logger & debug.FLAG_INS and\n         debug.logger('%s: createCleanup(%s, %r)' % (self, name, val)))\n\n        instances = context['instances'].setdefault(self.name, {self.ST_CREATE: {}, self.ST_DESTROY: {}})\n        idx = context['idx']\n\n        self.branchVersionId += 1\n\n        instances[self.ST_CREATE].pop(-idx - 1, None)\n\n        self._vars[name].writeCleanup(varBind, **context)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef destroyCommit(self, varBind, **context):\n        name, val = varBind\n\n        (debug.logger & debug.FLAG_INS and\n         debug.logger('%s: destroyCommit(%s, %r)' % (self, name, val)))\n\n        instances = context['instances'].setdefault(self.name, {self.ST_CREATE: {}, self.ST_DESTROY: {}})\n        idx = context['idx']\n\n        # NOTE: multiple names are possible in a single PDU, that could collide\n        # Therefore let's keep old object indexed by (negative) var-bind index\n        try:\n            instances[self.ST_DESTROY][-idx - 1] = self._vars.pop(name)\n\n        except KeyError:\n            pass\n\n        cbFun = context['cbFun']\n        cbFun(varBind, **context)", "response": "This method is used to destroy Managed Object Instance values from the MIB tree. It is used to remove Managed Object Instance values from the MIB tree and destroy the Managed Object Instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef oidToValue(self, syntax, identifier, impliedFlag=False, parentIndices=None):\n        if not identifier:\n            raise error.SmiError('Short OID for index %r' % (syntax,))\n\n        if hasattr(syntax, 'cloneFromName'):\n            return syntax.cloneFromName(\n                identifier, impliedFlag, parentRow=self, parentIndices=parentIndices)\n\n        baseTag = syntax.getTagSet().getBaseTag()\n        if baseTag == Integer.tagSet.getBaseTag():\n            return syntax.clone(identifier[0]), identifier[1:]\n\n        elif IpAddress.tagSet.isSuperTagSetOf(syntax.getTagSet()):\n            return syntax.clone(\n                '.'.join([str(x) for x in identifier[:4]])), identifier[4:]\n\n        elif baseTag == OctetString.tagSet.getBaseTag():\n            # rfc1902, 7.7\n            if impliedFlag:\n                return syntax.clone(tuple(identifier)), ()\n\n            elif syntax.isFixedLength():\n                l = syntax.getFixedLength()\n                return syntax.clone(tuple(identifier[:l])), identifier[l:]\n\n            else:\n                return syntax.clone(\n                    tuple(identifier[1:identifier[0] + 1])), identifier[identifier[0] + 1:]\n\n        elif baseTag == ObjectIdentifier.tagSet.getBaseTag():\n            if impliedFlag:\n                return syntax.clone(identifier), ()\n\n            else:\n                return syntax.clone(\n                    identifier[1:identifier[0] + 1]), identifier[identifier[0] + 1:]\n\n        # rfc2578, 7.1\n        elif baseTag == Bits.tagSet.getBaseTag():\n            return syntax.clone(\n                tuple(identifier[1:identifier[0] + 1])), identifier[identifier[0] + 1:]\n\n        else:\n            raise error.SmiError('Unknown value type for index %r' % (syntax,))", "response": "Turn an object identifier into a value object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef valueToOid(self, value, impliedFlag=False, parentIndices=None):\n        if hasattr(value, 'cloneAsName'):\n            return value.cloneAsName(impliedFlag, parentRow=self, parentIndices=parentIndices)\n\n        baseTag = value.getTagSet().getBaseTag()\n        if baseTag == Integer.tagSet.getBaseTag():\n            return int(value),\n\n        elif IpAddress.tagSet.isSuperTagSetOf(value.getTagSet()):\n            return value.asNumbers()\n\n        elif baseTag == OctetString.tagSet.getBaseTag():\n            if impliedFlag or value.isFixedLength():\n                initial = ()\n            else:\n                initial = (len(value),)\n            return initial + value.asNumbers()\n\n        elif baseTag == ObjectIdentifier.tagSet.getBaseTag():\n            if impliedFlag:\n                return tuple(value)\n            else:\n                return (len(value),) + tuple(value)\n\n        # rfc2578, 7.1\n        elif baseTag == Bits.tagSet.getBaseTag():\n            return (len(value),) + value.asNumbers()\n\n        else:\n            raise error.SmiError('Unknown value type for index %r' % (value,))", "response": "Converts an arbitrary value object into an SMI table instance identifier."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nannouncing the state of a managed object instance.", "response": "def announceManagementEvent(self, action, varBind, **context):\n        \"\"\"Announce mass operation on parent table's row.\n\n        SNMP SMI provides a way to extend already existing SMI table with\n        another table. Whenever a mass operation on parent table's column\n        is performed (e.g. row creation or destruction), this operation\n        has to be propagated over all the extending tables.\n\n        This method gets invoked on parent :py:class:`MibTableRow` whenever\n        row modification is performed on the parent table.\n\n        Parameters\n        ----------\n        action: :py:class:`str` any of :py:class:`MibInstrumController`'s states\n            being applied on the parent table's row.\n\n        varBind: :py:class:`~pysnmp.smi.rfc1902.ObjectType` object representing\n            new :py:class:`RowStatus`  Managed Object Instance value being set\n            on parent table row\n\n        Other Parameters\n        ----------------\n        \\*\\*context:\n\n            Query parameters:\n\n            * `cbFun` (callable) - user-supplied callable that is invoked once\n                all the consumers of this notifications finished with their stuff\n                or an error occurs\n\n        Notes\n        -----\n        The callback functions (e.g. `cbFun`) expects two parameters: `varBind`\n        and `**context`.\n\n        In case of an error, the `error` key in the `context` dict will contain\n        an exception object.\n        \"\"\"\n        name, val = varBind\n\n        cbFun = context['cbFun']\n\n        if not self._augmentingRows:\n            cbFun(varBind, **context)\n            return\n\n        # Convert OID suffix into index values\n        instId = name[len(self.name) + 1:]\n        baseIndices = []\n        indices = []\n        for impliedFlag, modName, symName in self._indexNames:\n            mibObj, = mibBuilder.importSymbols(modName, symName)\n            syntax, instId = self.oidToValue(mibObj.syntax, instId,\n                                             impliedFlag, indices)\n\n            if self.name == mibObj.name[:-1]:\n                baseIndices.append((mibObj.name, syntax))\n\n            indices.append(syntax)\n\n        if instId:\n            exc = error.SmiError('Excessive instance identifier sub-OIDs left at %s: %s' % (self, instId))\n            cbFun(varBind, **dict(context, error=exc))\n            return\n\n        if not baseIndices:\n            cbFun(varBind, **context)\n            return\n\n        count = [len(self._augmentingRows)]\n\n        def _cbFun(varBind, **context):\n            count[0] -= 1\n\n            if not count[0]:\n                cbFun(varBind, **context)\n\n        for modName, mibSym in self._augmentingRows:\n            mibObj, = mibBuilder.importSymbols(modName, mibSym)\n            mibObj.receiveManagementEvent(action, (baseIndices, val), **dict(context, cbFun=_cbFun))\n\n            debug.logger & debug.FLAG_INS and debug.logger('announceManagementEvent %s to %s' % (action, mibObj))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef receiveManagementEvent(self, action, varBind, **context):\n        baseIndices, val = varBind\n\n        # The default implementation supports one-to-one rows dependency\n        instId = ()\n\n        # Resolve indices intersection\n        for impliedFlag, modName, symName in self._indexNames:\n            mibObj, = mibBuilder.importSymbols(modName, symName)\n            parentIndices = []\n            for name, syntax in baseIndices:\n                if name == mibObj.name:\n                    instId += self.valueToOid(syntax, impliedFlag, parentIndices)\n                parentIndices.append(syntax)\n\n        if instId:\n            debug.logger & debug.FLAG_INS and debug.logger(\n                'receiveManagementEvent %s for suffix %s' % (action, instId))\n\n            self._manageColumns(action, (self.name + (0,) + instId, val), **context)", "response": "This method is called by the management event handler to set the current value of the managed object instance of the current row. This method is called by the management event handler when the action is applied on the current table and the varBind dict contains the value of the new Managed Object Instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef registerAugmentation(self, *names):\n        for name in names:\n            if name in self._augmentingRows:\n                raise error.SmiError(\n                    'Row %s already augmented by %s::%s' % (self.name, name[0], name[1])\n                )\n\n            self._augmentingRows.add(name)\n\n        return self", "response": "Register an augmentation of the current table with another table."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\napplies a management action on all columns and return a new rowStatus object.", "response": "def _manageColumns(self, action, varBind, **context):\n        \"\"\"Apply a management action on all columns\n\n        Parameters\n        ----------\n        action: :py:class:`str` any of :py:class:`MibInstrumController`'s states\n            to apply on all columns but the one passed in `varBind`\n\n        varBind: :py:class:`~pysnmp.smi.rfc1902.ObjectType` object representing\n            new :py:class:`RowStatus`  Managed Object Instance value being set\n            on table row\n\n        Other Parameters\n        ----------------\n        \\*\\*context:\n\n            Query parameters:\n\n            * `cbFun` (callable) - user-supplied callable that is invoked once\n              all columns have been processed or an error occurs\n\n        Notes\n        -----\n        The callback functions (e.g. `cbFun`) expects two parameters: `varBind`\n        and `**context`.\n\n        In case of an error, the `error` key in the `context` dict will contain\n        an exception object.\n\n        Assumes that row consistency check has been triggered by RowStatus\n        columnar object transition into `active` state.\n        \"\"\"\n        name, val = varBind\n\n        (debug.logger & debug.FLAG_INS and\n         debug.logger('%s: _manageColumns(%s, %s, %r)' % (self, action, name, val)))\n\n        cbFun = context['cbFun']\n\n        colLen = len(self.name) + 1\n\n        # Build a map of index names and values for automatic initialization\n        indexVals = {}\n\n        instId = name[colLen:]\n        indices = []\n\n        for impliedFlag, modName, symName in self._indexNames:\n            mibObj, = mibBuilder.importSymbols(modName, symName)\n            syntax, instId = self.oidToValue(mibObj.syntax, instId, impliedFlag, indices)\n            indexVals[mibObj.name] = syntax\n            indices.append(syntax)\n\n        count = [len(self._vars)]\n\n        if name[:colLen] in self._vars:\n            count[0] -= 1\n\n        def _cbFun(varBind, **context):\n            count[0] -= 1\n\n            if not count[0]:\n                cbFun(varBind, **context)\n\n        for colName, colObj in self._vars.items():\n            acFun = context.get('acFun')\n\n            if colName in indexVals:\n                colInstanceValue = indexVals[colName]\n                # Index column is usually read-only\n                acFun = None\n\n            elif name[:colLen] == colName:\n                # status column is following `write` path\n                continue\n\n            else:\n                colInstanceValue = None\n\n            actionFun = getattr(colObj, action)\n\n            colInstanceName = colName + name[colLen:]\n\n            actionFun((colInstanceName, colInstanceValue),\n                      **dict(context, acFun=acFun, cbFun=_cbFun))\n\n            debug.logger & debug.FLAG_INS and debug.logger(\n                '_manageColumns: action %s name %s instance %s %svalue %r' % (\n                    action, name, instId, name in indexVals and \"index \" or \"\", indexVals.get(name, val)))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _checkColumns(self, varBind, **context):\n        name, val = varBind\n\n        (debug.logger & debug.FLAG_INS and\n         debug.logger('%s: _checkColumns(%s, %r)' % (self, name, val)))\n\n        cbFun = context['cbFun']\n\n        # RowStatus != active\n        if val != 1:\n            cbFun(varBind, **context)\n            return\n\n        count = [len(self._vars)]\n\n        def _cbFun(varBind, **context):\n            count[0] -= 1\n\n            name, val = varBind\n\n            if count[0] >= 0:\n                exc = context.get('error')\n                if exc or not val.hasValue():\n                    count[0] = -1  # ignore the rest of callbacks\n                    exc = error.InconsistentValueError(msg='Inconsistent column %s: %s' % (name, exc))\n                    cbFun(varBind, **dict(context, error=exc))\n                    return\n\n            if not count[0]:\n                cbFun(varBind, **context)\n                return\n\n        colLen = len(self.name) + 1\n\n        for colName, colObj in self._vars.items():\n            instName = colName + name[colLen:]\n\n            colObj.readGet((instName, None), **dict(context, cbFun=_cbFun))\n\n            debug.logger & debug.FLAG_INS and debug.logger(\n                '%s: _checkColumns: checking instance %s' % (self, instName))", "response": "Check the consistency of all columns."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getIndicesFromInstId(self, instId):\n        if instId in self._idToIdxCache:\n            return self._idToIdxCache[instId]\n\n        indices = []\n        for impliedFlag, modName, symName in self._indexNames:\n            mibObj, = mibBuilder.importSymbols(modName, symName)\n            try:\n                syntax, instId = self.oidToValue(mibObj.syntax, instId, impliedFlag, indices)\n            except PyAsn1Error as exc:\n                debug.logger & debug.FLAG_INS and debug.logger(\n                    'error resolving table indices at %s, %s: %s' % (self.__class__.__name__, instId, exc))\n                indices = [instId]\n                instId = ()\n                break\n\n            indices.append(syntax)  # to avoid cyclic refs\n\n        if instId:\n            raise error.SmiError(\n                'Excessive instance identifier sub-OIDs left at %s: %s' %\n                (self, instId)\n            )\n\n        indices = tuple(indices)\n        self._idToIdxCache[instId] = indices\n\n        return indices", "response": "Return index values for instance identification"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getInstIdFromIndices(self, *indices):\n        try:\n            return self._idxToIdCache[indices]\n        except TypeError:\n            cacheable = False\n        except KeyError:\n            cacheable = True\n        idx = 0\n        instId = ()\n        parentIndices = []\n        for impliedFlag, modName, symName in self._indexNames:\n            if idx >= len(indices):\n                break\n            mibObj, = mibBuilder.importSymbols(modName, symName)\n            syntax = mibObj.syntax.clone(indices[idx])\n            instId += self.valueToOid(syntax, impliedFlag, parentIndices)\n            parentIndices.append(syntax)\n            idx += 1\n        if cacheable:\n            self._idxToIdCache[indices] = instId\n        return instId", "response": "Return column instance identification from indices"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild column instance name from components", "response": "def getInstNameByIndex(self, colId, *indices):\n        \"\"\"Build column instance name from components\"\"\"\n        return self.name + (colId,) + self.getInstIdFromIndices(*indices)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getInstNamesByIndex(self, *indices):\n        instNames = []\n        for columnName in self._vars.keys():\n            instNames.append(\n                self.getInstNameByIndex(*(columnName[-1],) + indices)\n            )\n\n        return tuple(instNames)", "response": "Build column instance names from indices"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef prettyOut(self, value):  # override asn1 type method\n        if self.displayHint and (self.__integer.isSuperTypeOf(self, matchConstraints=False) and not self.getNamedValues() or\n                                 self.__unsigned32.isSuperTypeOf(self, matchConstraints=False) or\n                                 self.__timeticks.isSuperTypeOf(self, matchConstraints=False)):\n            _ = lambda t, f=0: (t, f)\n            displayHintType, decimalPrecision = _(*self.displayHint.split('-'))\n            if displayHintType == 'x':\n                return '0x%x' % value\n            elif displayHintType == 'd':\n                try:\n                    return '%.*f' % (int(decimalPrecision), float(value) / pow(10, int(decimalPrecision)))\n                except Exception as exc:\n                    raise SmiError(\n                        'float evaluation error: %s' % exc\n                    )\n            elif displayHintType == 'o':\n                return '0%o' % value\n            elif displayHintType == 'b':\n                runningValue = value\n                outputValue = ['B']\n                while runningValue:\n                    outputValue.insert(0, '%d' % (runningValue & 0x01))\n                    runningValue >>= 1\n                return ''.join(outputValue)\n            else:\n                raise SmiError(\n                    'Unsupported numeric type spec \"%s\" at %s' % (displayHintType, self.__class__.__name__)\n                )\n        elif self.displayHint and self.__octetString.isSuperTypeOf(self, matchConstraints=False):\n            outputValue = ''\n            runningValue = OctetString(value).asOctets()\n            displayHint = self.displayHint\n            while runningValue and displayHint:\n                # 1\n                if displayHint[0] == '*':\n                    repeatIndicator = repeatCount = octets.oct2int(runningValue[0])\n                    displayHint = displayHint[1:]\n                    runningValue = runningValue[1:]\n                else:\n                    repeatCount = 1\n                    repeatIndicator = None\n\n                # 2\n                octetLength = ''\n                while displayHint and displayHint[0] in string.digits:\n                    octetLength += displayHint[0]\n                    displayHint = displayHint[1:]\n\n                # length is manatory, but people ignore that\n                if not octetLength:\n                    octetLength = len(runningValue)\n\n                try:\n                    octetLength = int(octetLength)\n                except Exception:\n                    raise SmiError(\n                        'Bad octet length: %s' % octetLength\n                    )\n\n                if not displayHint:\n                    raise SmiError(\n                        'Short octet length: %s' % self.displayHint\n                    )\n\n                # 3\n                displayFormat = displayHint[0]\n                displayHint = displayHint[1:]\n\n                # 4\n                if displayHint and displayHint[0] not in string.digits and displayHint[0] != '*':\n                    displaySep = displayHint[0]\n                    displayHint = displayHint[1:]\n                else:\n                    displaySep = ''\n\n                # 5\n                if displayHint and displaySep and repeatIndicator is not None:\n                    repeatTerminator = displayHint[0]\n                    displaySep = ''\n                    displayHint = displayHint[1:]\n                else:\n                    repeatTerminator = None\n\n                while repeatCount:\n                    repeatCount -= 1\n                    if displayFormat == 'a':\n                        outputValue += runningValue[:octetLength].decode('ascii', 'ignore')\n                    elif displayFormat == 't':\n                        outputValue += runningValue[:octetLength].decode('utf-8', 'ignore')\n                    elif displayFormat in ('x', 'd', 'o'):\n                        number = 0\n                        numberString = runningValue[:octetLength]\n                        while numberString:\n                            number <<= 8\n                            try:\n                                number |= octets.oct2int(numberString[0])\n                                numberString = numberString[1:]\n                            except Exception as exc:\n                                raise SmiError(\n                                    'Display format eval failure: %s: %s'\n                                    % (numberString, exc)\n                                )\n                        if displayFormat == 'x':\n                            outputValue += '%02x' % number\n                        elif displayFormat == 'o':\n                            outputValue += '%03o' % number\n                        else:\n                            outputValue += '%d' % number\n                    else:\n                        raise SmiError(\n                            'Unsupported display format char: %s' %\n                            displayFormat\n                        )\n                    if runningValue and repeatTerminator:\n                        outputValue += repeatTerminator\n                    runningValue = runningValue[octetLength:]\n                if runningValue and displaySep:\n                    outputValue += displaySep\n                if not displayHint:\n                    displayHint = self.displayHint\n\n            return outputValue\n\n        for base in inspect.getmro(self.__class__):\n            if not issubclass(base, TextualConvention) and issubclass(base, Asn1Item):\n                return base.prettyOut(self, value)\n\n        raise SmiError('TEXTUAL-CONVENTION has no underlying SNMP base type')", "response": "Returns a string representation of the value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef prettyIn(self, value):  # override asn1 type method\n        for base in inspect.getmro(self.__class__):\n            if not issubclass(base, TextualConvention) and issubclass(base, Asn1Item):\n                break\n        else:\n            raise SmiError('TEXTUAL-CONVENTION has no underlying SNMP base type')\n\n        if self.displayHint and (self.__integer.isSuperTypeOf(self, matchConstraints=False) and\n                                 self.getNamedValues() or\n                                 self.__unsigned32.isSuperTypeOf(self, matchConstraints=False) or\n                                 self.__timeticks.isSuperTypeOf(self, matchConstraints=False)):\n            value = str(value)\n\n            _ = lambda t, f=0: (t, f)\n            displayHintType, decimalPrecision = _(*self.displayHint.split('-'))\n            if displayHintType == 'x' and (value.startswith('0x') or value.startswith('-0x')):\n                try:\n                    if value.startswith('-'):\n                        return base.prettyIn(self, -int(value[3:], 16))\n                    else:\n                        return base.prettyIn(self, int(value[2:], 16))\n                except Exception as exc:\n                    raise SmiError(\n                        'integer evaluation error: %s' % exc\n                    )\n            elif displayHintType == 'd':\n                try:\n                    return base.prettyIn(self, int(float(value) * 10**int(decimalPrecision)))\n                except Exception as exc:\n                    raise SmiError(\n                        'float evaluation error: %s' % exc\n                    )\n            elif displayHintType == 'o' and (value.startswith('0') or value.startswith('-0')):\n                try:\n                    return base.prettyIn(self, int(value, 8))\n                except Exception as exc:\n                    raise SmiError(\n                        'octal evaluation error: %s' % exc\n                    )\n            elif displayHintType == 'b' and (value.startswith('B') or value.startswith('-B')):\n                negative = value.startswith('-')\n                if negative:\n                    value = value[2:]\n                else:\n                    value = value[1:]\n                value = [x != '0' and 1 or 0 for x in value]\n                binValue = 0\n                while value:\n                    binValue <<= value[0]\n                    del value[0]\n                return base.prettyIn(self, binValue)\n            else:\n                raise SmiError(\n                    'Unsupported numeric type spec \"%s\" at %s' % (displayHintType, self.__class__.__name__)\n                )\n\n        elif self.displayHint and self.__octetString.isSuperTypeOf(self, matchConstraints=False):\n            numBase = {\n                'x': 16,\n                'd': 10,\n                'o': 8\n            }\n            numDigits = {\n                'x': octets.str2octs(string.hexdigits),\n                'o': octets.str2octs(string.octdigits),\n                'd': octets.str2octs(string.digits)\n            }\n\n            # how do we know if object is initialized with display-hint\n            # formatted text? based on \"text\" input maybe?\n            # That boils down to `str` object on Py3 or `unicode` on Py2.\n            if octets.isStringType(value) and not octets.isOctetsType(value):\n                value = base.prettyIn(self, value)\n            else:\n                return base.prettyIn(self, value)\n\n            outputValue = octets.str2octs('')\n            runningValue = value\n            displayHint = self.displayHint\n\n            while runningValue and displayHint:\n                # 1 this information is totally lost, just fail explicitly\n                if displayHint[0] == '*':\n                    raise SmiError(\n                        'Can\\'t parse \"*\" in DISPLAY-HINT (%s)' % self.__class__.__name__\n                    )\n\n                # 2 this becomes ambiguous when it comes to rendered value\n                octetLength = ''\n                while displayHint and displayHint[0] in string.digits:\n                    octetLength += displayHint[0]\n                    displayHint = displayHint[1:]\n\n                # length is mandatory but people ignore that\n                if not octetLength:\n                    octetLength = len(runningValue)\n\n                try:\n                    octetLength = int(octetLength)\n                except Exception:\n                    raise SmiError(\n                        'Bad octet length: %s' % octetLength\n                    )\n\n                if not displayHint:\n                    raise SmiError(\n                        'Short octet length: %s' % self.displayHint\n                    )\n\n                # 3\n                displayFormat = displayHint[0]\n                displayHint = displayHint[1:]\n\n                # 4 this is the lifesaver -- we could use it as an anchor\n                if displayHint and displayHint[0] not in string.digits and displayHint[0] != '*':\n                    displaySep = displayHint[0]\n                    displayHint = displayHint[1:]\n                else:\n                    displaySep = ''\n\n                # 5 is probably impossible to support\n\n                if displayFormat in ('a', 't'):\n                    outputValue += runningValue[:octetLength]\n                elif displayFormat in numBase:\n                    if displaySep:\n                        guessedOctetLength = runningValue.find(octets.str2octs(displaySep))\n                        if guessedOctetLength == -1:\n                            guessedOctetLength = len(runningValue)\n                    else:\n                        for idx in range(len(runningValue)):\n                            if runningValue[idx] not in numDigits[displayFormat]:\n                                guessedOctetLength = idx\n                                break\n                        else:\n                            guessedOctetLength = len(runningValue)\n\n                    try:\n                        num = int(octets.octs2str(runningValue[:guessedOctetLength]), numBase[displayFormat])\n                    except Exception as exc:\n                        raise SmiError(\n                            'Display format eval failure: %s: %s'\n                            % (runningValue[:guessedOctetLength], exc)\n                        )\n\n                    num_as_bytes = []\n                    if num:\n                        while num:\n                            num_as_bytes.append(num & 0xFF)\n                            num >>= 8\n                    else:\n                        num_as_bytes = [0]\n\n                    while len(num_as_bytes) < octetLength:\n                        num_as_bytes.append(0)\n\n                    num_as_bytes.reverse()\n\n                    outputValue += octets.ints2octs(num_as_bytes)\n\n                    if displaySep:\n                        guessedOctetLength += 1\n\n                    octetLength = guessedOctetLength\n                else:\n                    raise SmiError(\n                        'Unsupported display format char: %s' %\n                        displayFormat\n                    )\n\n                runningValue = runningValue[octetLength:]\n\n                if not displayHint:\n                    displayHint = self.displayHint\n\n            return base.prettyIn(self, outputValue)\n\n        else:\n            return base.prettyIn(self, value)", "response": "Implements display - hint parsing into base SNMP value."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sendNotification(snmpEngine, authData, transportTarget, contextData,\n                     notifyType, *varBinds, **options):\n    \"\"\"Creates a generator to send SNMP notification.\n\n    When iterator gets advanced by :py:mod:`asyncio` main loop,\n    SNMP TRAP or INFORM notification is send (:RFC:`1905#section-4.2.6`).\n    The iterator yields :py:class:`asyncio.Future` which gets done whenever\n    response arrives or error occurs.\n\n    Parameters\n    ----------\n    snmpEngine : :py:class:`~pysnmp.hlapi.SnmpEngine`\n        Class instance representing SNMP engine.\n\n    authData : :py:class:`~pysnmp.hlapi.CommunityData` or :py:class:`~pysnmp.hlapi.UsmUserData`\n        Class instance representing SNMP credentials.\n\n    transportTarget : :py:class:`~pysnmp.hlapi.asyncio.UdpTransportTarget` or :py:class:`~pysnmp.hlapi.asyncio.Udp6TransportTarget`\n        Class instance representing transport type along with SNMP peer address.\n\n    contextData : :py:class:`~pysnmp.hlapi.ContextData`\n        Class instance representing SNMP ContextEngineId and ContextName values.\n\n    notifyType : str\n        Indicates type of notification to be sent. Recognized literal\n        values are *trap* or *inform*.\n\n    \\*varBinds: :class:`tuple` of OID-value pairs or :py:class:`~pysnmp.smi.rfc1902.ObjectType` or :py:class:`~pysnmp.smi.rfc1902.NotificationType`\n        One or more objects representing MIB variables to place\n        into SNMP notification. It could be tuples of OID-values\n        or :py:class:`~pysnmp.smi.rfc1902.ObjectType` class instances\n        of :py:class:`~pysnmp.smi.rfc1902.NotificationType` objects.\n\n        SNMP Notification PDU places rigid requirement on the ordering of\n        the variable-bindings.\n\n        Mandatory variable-bindings:\n\n        0. SNMPv2-MIB::sysUpTime.0 = <agent uptime>\n        1. SNMPv2-SMI::snmpTrapOID.0 = {SNMPv2-MIB::coldStart, ...}\n\n        Optional variable-bindings (applicable to SNMP v1 TRAP):\n\n        2. SNMP-COMMUNITY-MIB::snmpTrapAddress.0 = <agent-IP>\n        3. SNMP-COMMUNITY-MIB::snmpTrapCommunity.0 = <snmp-community-name>\n        4. SNMP-COMMUNITY-MIB::snmpTrapEnterprise.0 = <enterprise-OID>\n\n        Informational variable-bindings:\n\n        * SNMPv2-SMI::NOTIFICATION-TYPE\n        * SNMPv2-SMI::OBJECT-TYPE\n\n    Other Parameters\n    ----------------\n    \\*\\*options :\n        Request options:\n\n            * `lookupMib` - load MIB and resolve response MIB variables at\n              the cost of slightly reduced performance. Default is `True`.\n\n    Yields\n    ------\n    errorIndication : str\n        True value indicates SNMP engine error.\n    errorStatus : str\n        True value indicates SNMP PDU error.\n    errorIndex : int\n        Non-zero value refers to `varBinds[errorIndex-1]`\n    varBinds : tuple\n        A sequence of :py:class:`~pysnmp.smi.rfc1902.ObjectType` class\n        instances representing MIB variables returned in SNMP response.\n\n    Raises\n    ------\n    PySnmpError\n        Or its derivative indicating that an error occurred while\n        performing SNMP operation.\n\n    Examples\n    --------\n    >>> import asyncio\n    >>> from pysnmp.hlapi.asyncio import *\n    >>>\n    >>> @asyncio.coroutine\n    ... def run():\n    ...     errorIndication, errorStatus, errorIndex, varBinds = yield from sendNotification(\n    ...         SnmpEngine(),\n    ...         CommunityData('public'),\n    ...         UdpTransportTarget(('demo.snmplabs.com', 162)),\n    ...         ContextData(),\n    ...         'trap',\n    ...         NotificationType(ObjectIdentity('IF-MIB', 'linkDown')))\n    ...     print(errorIndication, errorStatus, errorIndex, varBinds)\n    ...\n    >>> asyncio.get_event_loop().run_until_complete(run())\n    (None, 0, 0, [])\n    >>>\n\n    \"\"\"\n\n    def __cbFun(snmpEngine, sendRequestHandle,\n                errorIndication, errorStatus, errorIndex,\n                varBinds, cbCtx):\n        lookupMib, future = cbCtx\n        if future.cancelled():\n            return\n        try:\n            varBindsUnmade = VB_PROCESSOR.unmakeVarBinds(snmpEngine.cache, varBinds,\n                                                         lookupMib)\n        except Exception as e:\n            future.set_exception(e)\n        else:\n            future.set_result(\n                    (errorIndication, errorStatus, errorIndex, varBindsUnmade)\n            )\n\n    notifyName = LCD.configure(\n        snmpEngine, authData, transportTarget, notifyType,\n        contextData.contextName)\n\n    future = asyncio.Future()\n\n    ntforg.NotificationOriginator().sendVarBinds(\n        snmpEngine,\n        notifyName,\n        contextData.contextEngineId,\n        contextData.contextName,\n        VB_PROCESSOR.makeVarBinds(snmpEngine.cache, varBinds),\n        __cbFun,\n        (options.get('lookupMib', True), future)\n    )\n\n    if notifyType == 'trap':\n        def __trapFun(future):\n            if future.cancelled():\n                return\n            future.set_result((None, 0, 0, []))\n\n        loop = asyncio.get_event_loop()\n        loop.call_soon(__trapFun, future)\n\n    return future", "response": "Sends a new notification to the given context."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a generator that yields one or more SNMP GET requests.", "response": "def getCmd(snmpEngine, authData, transportTarget, contextData,\n           *varBinds, **options):\n    \"\"\"Creates a generator to perform one or more SNMP GET queries.\n\n    On each iteration, new SNMP GET request is send (:RFC:`1905#section-4.2.1`).\n    The iterator blocks waiting for response to arrive or error to occur.\n\n    Parameters\n    ----------\n    snmpEngine : :py:class:`~pysnmp.hlapi.SnmpEngine`\n        Class instance representing SNMP engine.\n\n    authData : :py:class:`~pysnmp.hlapi.CommunityData` or :py:class:`~pysnmp.hlapi.UsmUserData`\n        Class instance representing SNMP credentials.\n\n    transportTarget : :py:class:`~pysnmp.hlapi.asyncore.UdpTransportTarget` or :py:class:`~pysnmp.hlapi.asyncore.Udp6TransportTarget`\n        Class instance representing transport type along with SNMP peer address.\n\n    contextData : :py:class:`~pysnmp.hlapi.ContextData`\n        Class instance representing SNMP ContextEngineId and ContextName values.\n\n    \\*varBinds : :py:class:`~pysnmp.smi.rfc1902.ObjectType`\n        One or more class instances representing MIB variables to place\n        into SNMP request.\n\n    Other Parameters\n    ----------------\n    \\*\\*options :\n        Request options:\n\n            * `lookupMib` - load MIB and resolve response MIB variables at\n              the cost of slightly reduced performance. Default is `True`.\n\n    Yields\n    ------\n    errorIndication : str\n        True value indicates SNMP engine error.\n    errorStatus : str\n        True value indicates SNMP PDU error.\n    errorIndex : int\n        Non-zero value refers to `varBinds[errorIndex-1]`\n    varBinds : tuple\n        A sequence of :py:class:`~pysnmp.smi.rfc1902.ObjectType` class\n        instances representing MIB variables returned in SNMP response.\n\n    Raises\n    ------\n    PySnmpError\n        Or its derivative indicating that an error occurred while\n        performing SNMP operation.\n\n    Notes\n    -----\n    The `getCmd` generator will be exhausted immediately unless\n    a new sequence of `varBinds` are send back into running generator\n    (supported since Python 2.6).\n\n    Examples\n    --------\n    >>> from pysnmp.hlapi import *\n    >>> g = getCmd(SnmpEngine(),\n    ...            CommunityData('public'),\n    ...            UdpTransportTarget(('demo.snmplabs.com', 161)),\n    ...            ContextData(),\n    ...            ObjectType(ObjectIdentity('SNMPv2-MIB', 'sysDescr', 0)))\n    >>> next(g)\n    (None, 0, 0, [ObjectType(ObjectIdentity(ObjectName('1.3.6.1.2.1.1.1.0')), DisplayString('SunOS zeus.snmplabs.com 4.1.3_U1 1 sun4m'))])\n    >>>\n\n    \"\"\"\n\n    # noinspection PyShadowingNames\n    def cbFun(snmpEngine, sendRequestHandle,\n              errorIndication, errorStatus, errorIndex,\n              varBinds, cbCtx):\n        cbCtx['errorIndication'] = errorIndication\n        cbCtx['errorStatus'] = errorStatus\n        cbCtx['errorIndex'] = errorIndex\n        cbCtx['varBinds'] = varBinds\n\n    cbCtx = {}\n\n    while True:\n        if varBinds:\n            cmdgen.getCmd(snmpEngine, authData, transportTarget,\n                          contextData, *varBinds,\n                          cbFun=cbFun, cbCtx=cbCtx,\n                          lookupMib=options.get('lookupMib', True))\n\n            snmpEngine.transportDispatcher.runDispatcher()\n\n            errorIndication = cbCtx['errorIndication']\n            errorStatus = cbCtx['errorStatus']\n            errorIndex = cbCtx['errorIndex']\n            varBinds = cbCtx['varBinds']\n\n        else:\n            errorIndication = errorStatus = errorIndex = None\n            varBinds = []\n\n        varBinds = (yield errorIndication, errorStatus, errorIndex, varBinds)\n\n        if not varBinds:\n            break"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef nextCmd(snmpEngine, authData, transportTarget, contextData,\n            *varBinds, **options):\n    \"\"\"Creates a generator to perform one or more SNMP GETNEXT queries.\n\n    On each iteration, new SNMP GETNEXT request is send\n    (:RFC:`1905#section-4.2.2`). The iterator blocks waiting for response\n    to arrive or error to occur.\n\n    Parameters\n    ----------\n    snmpEngine : :py:class:`~pysnmp.hlapi.SnmpEngine`\n        Class instance representing SNMP engine.\n\n    authData : :py:class:`~pysnmp.hlapi.CommunityData` or :py:class:`~pysnmp.hlapi.UsmUserData`\n        Class instance representing SNMP credentials.\n\n    transportTarget : :py:class:`~pysnmp.hlapi.asyncore.UdpTransportTarget` or :py:class:`~pysnmp.hlapi.asyncore.Udp6TransportTarget`\n        Class instance representing transport type along with SNMP peer address.\n\n    contextData : :py:class:`~pysnmp.hlapi.ContextData`\n        Class instance representing SNMP ContextEngineId and ContextName values.\n\n    \\*varBinds : :py:class:`~pysnmp.smi.rfc1902.ObjectType`\n        One or more class instances representing MIB variables to place\n        into SNMP request.\n\n    Other Parameters\n    ----------------\n    \\*\\*options :\n        Request options:\n\n            * `lookupMib` - load MIB and resolve response MIB variables at\n              the cost of slightly reduced performance. Default is `True`.\n              Default is `True`.\n            * `lexicographicMode` - walk SNMP agent's MIB till the end (if `True`),\n              otherwise (if `False`) stop iteration when all response MIB\n              variables leave the scope of initial MIB variables in\n              `varBinds`. Default is `True`.\n            * `ignoreNonIncreasingOid` - continue iteration even if response\n              MIB variables (OIDs) are not greater then request MIB variables.\n              Be aware that setting it to `True` may cause infinite loop between\n              SNMP management and agent applications. Default is `False`.\n            * `maxRows` - stop iteration once this generator instance processed\n              `maxRows` of SNMP conceptual table. Default is `0` (no limit).\n            * `maxCalls` - stop iteration once this generator instance processed\n              `maxCalls` responses. Default is 0 (no limit).\n\n    Yields\n    ------\n    errorIndication : str\n        True value indicates SNMP engine error.\n    errorStatus : str\n        True value indicates SNMP PDU error.\n    errorIndex : int\n        Non-zero value refers to `varBinds[errorIndex-1]`\n    varBinds : tuple\n        A sequence of :py:class:`~pysnmp.smi.rfc1902.ObjectType` class\n        instances representing MIB variables returned in SNMP response.\n\n    Raises\n    ------\n    PySnmpError\n        Or its derivative indicating that an error occurred while\n        performing SNMP operation.\n\n    Notes\n    -----\n    The `nextCmd` generator will be exhausted on any of the following\n    conditions:\n\n    * SNMP engine error occurs thus `errorIndication` is `True`\n    * SNMP PDU `errorStatus` is reported as `True`\n    * SNMP :py:class:`~pysnmp.proto.rfc1905.EndOfMibView` values\n      (also known as *SNMP exception values*) are reported for all\n      MIB variables in `varBinds`\n    * *lexicographicMode* option is `True` and SNMP agent reports\n      end-of-mib or *lexicographicMode* is `False` and all\n      response MIB variables leave the scope of `varBinds`\n\n    At any moment a new sequence of `varBinds` could be send back into\n    running generator (supported since Python 2.6).\n\n    Examples\n    --------\n    >>> from pysnmp.hlapi import *\n    >>> g = nextCmd(SnmpEngine(),\n    ...             CommunityData('public'),\n    ...             UdpTransportTarget(('demo.snmplabs.com', 161)),\n    ...             ContextData(),\n    ...             ObjectType(ObjectIdentity('SNMPv2-MIB', 'sysDescr')))\n    >>> next(g)\n    (None, 0, 0, [ObjectType(ObjectIdentity(ObjectName('1.3.6.1.2.1.1.1.0')), DisplayString('SunOS zeus.snmplabs.com 4.1.3_U1 1 sun4m'))])\n    >>> g.send( [ ObjectType(ObjectIdentity('IF-MIB', 'ifInOctets')) ] )\n    (None, 0, 0, [(ObjectName('1.3.6.1.2.1.2.2.1.10.1'), Counter32(284817787))])\n    \"\"\"\n\n    # noinspection PyShadowingNames\n    def cbFun(snmpEngine, sendRequestHandle,\n              errorIndication, errorStatus, errorIndex,\n              varBindTable, cbCtx):\n        cbCtx['errorIndication'] = errorIndication\n        cbCtx['errorStatus'] = errorStatus\n        cbCtx['errorIndex'] = errorIndex\n        cbCtx['varBindTable'] = varBindTable\n\n    lexicographicMode = options.get('lexicographicMode', True)\n    ignoreNonIncreasingOid = options.get('ignoreNonIncreasingOid', False)\n    maxRows = options.get('maxRows', 0)\n    maxCalls = options.get('maxCalls', 0)\n\n    cbCtx = {}\n\n    vbProcessor = CommandGeneratorVarBinds()\n\n    initialVars = [x[0] for x in vbProcessor.makeVarBinds(snmpEngine.cache, varBinds)]\n\n    totalRows = totalCalls = 0\n\n    while True:\n        previousVarBinds = varBinds\n\n        if varBinds:\n            cmdgen.nextCmd(snmpEngine, authData, transportTarget, contextData,\n                           *[(x[0], Null('')) for x in varBinds],\n                           cbFun=cbFun, cbCtx=cbCtx,\n                           lookupMib=options.get('lookupMib', True))\n\n            snmpEngine.transportDispatcher.runDispatcher()\n\n            errorIndication = cbCtx['errorIndication']\n            errorStatus = cbCtx['errorStatus']\n            errorIndex = cbCtx['errorIndex']\n\n            if ignoreNonIncreasingOid and errorIndication and isinstance(errorIndication, errind.OidNotIncreasing):\n                errorIndication = None\n\n            if errorIndication:\n                yield (errorIndication, errorStatus, errorIndex, varBinds)\n                return\n\n            elif errorStatus:\n                if errorStatus == 2:\n                    # Hide SNMPv1 noSuchName error which leaks in here\n                    # from SNMPv1 Agent through internal pysnmp proxy.\n                    errorStatus = errorStatus.clone(0)\n                    errorIndex = errorIndex.clone(0)\n                yield (errorIndication, errorStatus, errorIndex, varBinds)\n                return\n\n            else:\n                stopFlag = True\n\n                varBinds = cbCtx['varBindTable'] and cbCtx['varBindTable'][0]\n\n                for col, varBind in enumerate(varBinds):\n                    name, val = varBind\n                    if isinstance(val, Null):\n                        varBinds[col] = previousVarBinds[col][0], endOfMibView\n\n                    if not lexicographicMode and not initialVars[col].isPrefixOf(name):\n                        varBinds[col] = previousVarBinds[col][0], endOfMibView\n\n                    if stopFlag and varBinds[col][1] is not endOfMibView:\n                        stopFlag = False\n\n                if stopFlag:\n                    return\n\n                totalRows += 1\n                totalCalls += 1\n        else:\n            errorIndication = errorStatus = errorIndex = None\n            varBinds = []\n\n        initialVarBinds = (yield errorIndication, errorStatus, errorIndex, varBinds)\n\n        if initialVarBinds:\n            varBinds = initialVarBinds\n            initialVars = [x[0] for x in vbProcessor.makeVarBinds(snmpEngine.cache, varBinds)]\n\n        if maxRows and totalRows >= maxRows:\n            return\n\n        if maxCalls and totalCalls >= maxCalls:\n            return", "response": "This function returns a generator that yields one or more SNMP GETNEXT requests."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef bulkCmd(snmpEngine, authData, transportTarget, contextData,\n            nonRepeaters, maxRepetitions, *varBinds, **options):\n    \"\"\"Creates a generator to perform one or more SNMP GETBULK queries.\n\n    On each iteration, new SNMP GETBULK request is send\n    (:RFC:`1905#section-4.2.3`). The iterator blocks waiting for response\n    to arrive or error to occur.\n\n    Parameters\n    ----------\n    snmpEngine : :py:class:`~pysnmp.hlapi.SnmpEngine`\n        Class instance representing SNMP engine.\n\n    authData : :py:class:`~pysnmp.hlapi.CommunityData` or :py:class:`~pysnmp.hlapi.UsmUserData`\n        Class instance representing SNMP credentials.\n\n    transportTarget : :py:class:`~pysnmp.hlapi.asyncore.UdpTransportTarget` or :py:class:`~pysnmp.hlapi.asyncore.Udp6TransportTarget`\n        Class instance representing transport type along with SNMP peer address.\n\n    contextData : :py:class:`~pysnmp.hlapi.ContextData`\n        Class instance representing SNMP ContextEngineId and ContextName values.\n\n    nonRepeaters : int\n        One MIB variable is requested in response for the first\n        `nonRepeaters` MIB variables in request.\n\n    maxRepetitions : int\n        `maxRepetitions` MIB variables are requested in response for each\n        of the remaining MIB variables in the request (e.g. excluding\n        `nonRepeaters`). Remote SNMP engine may choose lesser value than\n        requested.\n\n    \\*varBinds : :py:class:`~pysnmp.smi.rfc1902.ObjectType`\n        One or more class instances representing MIB variables to place\n        into SNMP request.\n\n    Other Parameters\n    ----------------\n    \\*\\*options :\n        Request options:\n\n            * `lookupMib` - load MIB and resolve response MIB variables at\n              the cost of slightly reduced performance. Default is `True`.\n              Default is `True`.\n            * `lexicographicMode` - walk SNMP agent's MIB till the end (if `True`),\n              otherwise (if `False`) stop iteration when all response MIB\n              variables leave the scope of initial MIB variables in\n              `varBinds`. Default is `True`.\n            * `ignoreNonIncreasingOid` - continue iteration even if response\n              MIB variables (OIDs) are not greater then request MIB variables.\n              Be aware that setting it to `True` may cause infinite loop between\n              SNMP management and agent applications. Default is `False`.\n            * `maxRows` - stop iteration once this generator instance processed\n              `maxRows` of SNMP conceptual table. Default is `0` (no limit).\n            * `maxCalls` - stop iteration once this generator instance processed\n              `maxCalls` responses. Default is 0 (no limit).\n\n    Yields\n    ------\n    errorIndication : str\n        True value indicates SNMP engine error.\n    errorStatus : str\n        True value indicates SNMP PDU error.\n    errorIndex : int\n        Non-zero value refers to \\*varBinds[errorIndex-1]\n    varBinds : tuple\n        A sequence of :py:class:`~pysnmp.smi.rfc1902.ObjectType` class\n        instances representing MIB variables returned in SNMP response.\n\n    Raises\n    ------\n    PySnmpError\n        Or its derivative indicating that an error occurred while\n        performing SNMP operation.\n\n    Notes\n    -----\n    The `bulkCmd` generator will be exhausted on any of the following\n    conditions:\n\n    * SNMP engine error occurs thus `errorIndication` is `True`\n    * SNMP PDU `errorStatus` is reported as `True`\n    * SNMP :py:class:`~pysnmp.proto.rfc1905.EndOfMibView` values\n      (also known as *SNMP exception values*) are reported for all\n      MIB variables in `varBinds`\n    * *lexicographicMode* option is `True` and SNMP agent reports\n      end-of-mib or *lexicographicMode* is `False` and all\n      response MIB variables leave the scope of `varBinds`\n\n    At any moment a new sequence of `varBinds` could be send back into\n    running generator (supported since Python 2.6).\n\n    Setting `maxRepetitions` value to 15..50 might significantly improve\n    system performance, as many MIB variables get packed into a single\n    response message at once.\n\n    Examples\n    --------\n    >>> from pysnmp.hlapi import *\n    >>> g = bulkCmd(SnmpEngine(),\n    ...             CommunityData('public'),\n    ...             UdpTransportTarget(('demo.snmplabs.com', 161)),\n    ...             ContextData(),\n    ...             0, 25,\n    ...             ObjectType(ObjectIdentity('SNMPv2-MIB', 'sysDescr')))\n    >>> next(g)\n    (None, 0, 0, [ObjectType(ObjectIdentity(ObjectName('1.3.6.1.2.1.1.1.0')), DisplayString('SunOS zeus.snmplabs.com 4.1.3_U1 1 sun4m'))])\n    >>> g.send( [ ObjectType(ObjectIdentity('IF-MIB', 'ifInOctets')) ] )\n    (None, 0, 0, [(ObjectName('1.3.6.1.2.1.2.2.1.10.1'), Counter32(284817787))])\n    \"\"\"\n\n    # noinspection PyShadowingNames\n    def cbFun(snmpEngine, sendRequestHandle,\n              errorIndication, errorStatus, errorIndex,\n              varBindTable, cbCtx):\n        cbCtx['errorIndication'] = errorIndication\n        cbCtx['errorStatus'] = errorStatus\n        cbCtx['errorIndex'] = errorIndex\n        cbCtx['varBindTable'] = varBindTable\n\n    lexicographicMode = options.get('lexicographicMode', True)\n    ignoreNonIncreasingOid = options.get('ignoreNonIncreasingOid', False)\n    maxRows = options.get('maxRows', 0)\n    maxCalls = options.get('maxCalls', 0)\n\n    cbCtx = {}\n\n    vbProcessor = CommandGeneratorVarBinds()\n\n    initialVars = [x[0] for x in vbProcessor.makeVarBinds(snmpEngine.cache, varBinds)]\n    nullVarBinds = [False] * len(initialVars)\n\n    totalRows = totalCalls = 0\n    stopFlag = False\n\n    while not stopFlag:\n        if maxRows and totalRows < maxRows:\n            maxRepetitions = min(maxRepetitions, maxRows - totalRows)\n\n        previousVarBinds = varBinds\n\n        cmdgen.bulkCmd(snmpEngine, authData, transportTarget, contextData,\n                       nonRepeaters, maxRepetitions,\n                       *[(x[0], Null('')) for x in varBinds],\n                       cbFun=cbFun, cbCtx=cbCtx,\n                       lookupMib=options.get('lookupMib', True))\n\n        snmpEngine.transportDispatcher.runDispatcher()\n\n        errorIndication = cbCtx['errorIndication']\n        errorStatus = cbCtx['errorStatus']\n        errorIndex = cbCtx['errorIndex']\n        varBindTable = cbCtx['varBindTable']\n\n        if ignoreNonIncreasingOid and errorIndication and \\\n                isinstance(errorIndication, errind.OidNotIncreasing):\n            errorIndication = None\n\n        if errorIndication:\n            yield (errorIndication, errorStatus, errorIndex,\n                   varBindTable and varBindTable[0] or [])\n\n            if errorIndication != errind.requestTimedOut:\n                return\n\n        elif errorStatus:\n            if errorStatus == 2:\n                # Hide SNMPv1 noSuchName error which leaks in here\n                # from SNMPv1 Agent through internal pysnmp proxy.\n                errorStatus = errorStatus.clone(0)\n                errorIndex = errorIndex.clone(0)\n            yield (errorIndication, errorStatus, errorIndex, varBindTable and varBindTable[0] or [])\n            return\n\n        else:\n            for row in range(len(varBindTable)):\n                stopFlag = True\n\n                if len(varBindTable[row]) != len(initialVars):\n                    varBindTable = row and varBindTable[:row - 1] or []\n                    break\n\n                for col in range(len(varBindTable[row])):\n                    name, val = varBindTable[row][col]\n\n                    if row:\n                        previousVarBinds = varBindTable[row - 1]\n\n                    if nullVarBinds[col]:\n                        varBindTable[row][col] = previousVarBinds[col][0], endOfMibView\n                        continue\n\n                    stopFlag = False\n\n                    if isinstance(val, Null):\n                        varBindTable[row][col] = previousVarBinds[col][0], endOfMibView\n                        nullVarBinds[col] = True\n\n                    if not lexicographicMode and not initialVars[col].isPrefixOf(name):\n                        varBindTable[row][col] = previousVarBinds[col][0], endOfMibView\n                        nullVarBinds[col] = True\n\n                if stopFlag:\n                    varBindTable = row and varBindTable[:row - 1] or []\n                    break\n\n            totalRows += len(varBindTable)\n            totalCalls += 1\n\n            if maxRows and totalRows >= maxRows:\n                if totalRows > maxRows:\n                    varBindTable = varBindTable[:-(totalRows - maxRows)]\n                stopFlag = True\n\n            if maxCalls and totalCalls >= maxCalls:\n                stopFlag = True\n\n            varBinds = varBindTable and varBindTable[-1] or []\n\n            for varBindRow in varBindTable:\n                initialVarBinds = (yield errorIndication, errorStatus, errorIndex, varBindRow)\n\n                if initialVarBinds:\n                    varBinds = initialVarBinds\n                    initialVars = [x[0] for x in vbProcessor.makeVarBinds(snmpEngine, varBinds)]\n                    nullVarBinds = [False] * len(initialVars)", "response": "This function is used to perform one or more SNMP GETBULK queries."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _storeAccessContext(snmpEngine):\n        execCtx = snmpEngine.observer.getExecutionContext('rfc3412.receiveMessage:request')\n\n        return {\n            'securityModel': execCtx['securityModel'],\n            'securityName': execCtx['securityName'],\n            'securityLevel': execCtx['securityLevel'],\n            'contextName': execCtx['contextName'],\n            'pduType': execCtx['pdu'].getTagSet()\n        }", "response": "Copy received message metadata while it lasts"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _getManagedObjectsInstances(self, varBinds, **context):\n        rspVarBinds = context['rspVarBinds']\n        varBindsMap = context['varBindsMap']\n\n        rtrVarBinds = []\n\n        for idx, varBind in enumerate(varBinds):\n            name, val = varBind\n            if (exval.noSuchObject.isSameTypeWith(val) or\n                    exval.noSuchInstance.isSameTypeWith(val)):\n                varBindsMap[len(rtrVarBinds)] = varBindsMap.pop(idx, idx)\n                rtrVarBinds.append(varBind)\n\n            else:\n                rspVarBinds[varBindsMap.pop(idx, idx)] = varBind\n\n        if rtrVarBinds:\n            snmpEngine = context['snmpEngine']\n\n            # Need to unwind stack, can't recurse any more\n            def callLater(*args):\n                snmpEngine.transportDispatcher.unregisterTimerCbFun(callLater)\n                mgmtFun = context['mgmtFun']\n                mgmtFun(*varBinds, **context)\n\n            snmpEngine.transportDispatcher.registerTimerCbFun(callLater, 0.01)\n\n        else:\n            return rspVarBinds", "response": "Iterate over Managed Objects fulfilling SNMP query."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a generator that yields Future objects for the SNMP GET request.", "response": "def getCmd(snmpEngine, authData, transportTarget, contextData,\n           *varBinds, **options):\n    \"\"\"Creates a generator to perform SNMP GET query.\n\n    When iterator gets advanced by :py:mod:`asyncio` main loop,\n    SNMP GET request is send (:RFC:`1905#section-4.2.1`).\n    The iterator yields :py:class:`asyncio.Future` which gets done whenever\n    response arrives or error occurs.\n\n    Parameters\n    ----------\n    snmpEngine : :py:class:`~pysnmp.hlapi.SnmpEngine`\n        Class instance representing SNMP engine.\n\n    authData : :py:class:`~pysnmp.hlapi.CommunityData` or :py:class:`~pysnmp.hlapi.UsmUserData`\n        Class instance representing SNMP credentials.\n\n    transportTarget : :py:class:`~pysnmp.hlapi.asyncio.UdpTransportTarget` or :py:class:`~pysnmp.hlapi.asyncio.Udp6TransportTarget`\n        Class instance representing transport type along with SNMP peer address.\n\n    contextData : :py:class:`~pysnmp.hlapi.ContextData`\n        Class instance representing SNMP ContextEngineId and ContextName values.\n\n    \\*varBinds : :py:class:`~pysnmp.smi.rfc1902.ObjectType`\n        One or more class instances representing MIB variables to place\n        into SNMP request.\n\n    Other Parameters\n    ----------------\n    \\*\\*options :\n        Request options:\n\n            * `lookupMib` - load MIB and resolve response MIB variables at\n              the cost of slightly reduced performance. Default is `True`.\n\n    Yields\n    ------\n    errorIndication : str\n        True value indicates SNMP engine error.\n    errorStatus : str\n        True value indicates SNMP PDU error.\n    errorIndex : int\n        Non-zero value refers to `varBinds[errorIndex-1]`\n    varBinds : tuple\n        A sequence of :py:class:`~pysnmp.smi.rfc1902.ObjectType` class\n        instances representing MIB variables returned in SNMP response.\n\n    Raises\n    ------\n    PySnmpError\n        Or its derivative indicating that an error occurred while\n        performing SNMP operation.\n\n    Examples\n    --------\n    >>> import asyncio\n    >>> from pysnmp.hlapi.asyncio import *\n    >>>\n    >>> @asyncio.coroutine\n    ... def run():\n    ...     errorIndication, errorStatus, errorIndex, varBinds = yield from getCmd(\n    ...         SnmpEngine(),\n    ...         CommunityData('public'),\n    ...         UdpTransportTarget(('demo.snmplabs.com', 161)),\n    ...         ContextData(),\n    ...         ObjectType(ObjectIdentity('SNMPv2-MIB', 'sysDescr', 0))\n    ...     )\n    ...     print(errorIndication, errorStatus, errorIndex, varBinds)\n    >>>\n    >>> asyncio.get_event_loop().run_until_complete(run())\n    (None, 0, 0, [ObjectType(ObjectIdentity(ObjectName('1.3.6.1.2.1.1.1.0')), DisplayString('SunOS zeus.snmplabs.com 4.1.3_U1 1 sun4m'))])\n    >>>\n\n    \"\"\"\n\n    def __cbFun(snmpEngine, sendRequestHandle,\n                errorIndication, errorStatus, errorIndex,\n                varBinds, cbCtx):\n        lookupMib, future = cbCtx\n\n        if future.cancelled():\n            return\n\n        try:\n            varBindsUnmade = VB_PROCESSOR.unmakeVarBinds(\n                snmpEngine.cache, varBinds, lookupMib)\n\n        except Exception as e:\n            future.set_exception(e)\n\n        else:\n            future.set_result(\n                (errorIndication, errorStatus, errorIndex, varBindsUnmade))\n\n    addrName, paramsName = LCD.configure(\n        snmpEngine, authData, transportTarget, contextData.contextName)\n\n    future = asyncio.Future()\n\n    cmdgen.GetCommandGenerator().sendVarBinds(\n        snmpEngine, addrName, contextData.contextEngineId,\n        contextData.contextName,\n        VB_PROCESSOR.makeVarBinds(snmpEngine.cache, varBinds), __cbFun,\n        (options.get('lookupMib', True), future)\n    )\n\n    return future"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend a new notification to the given node.", "response": "def sendNotification(snmpDispatcher, authData, transportTarget,\n                     notifyType, *varBinds, **options):\n    \"\"\"Send SNMP notification.\n\n    Based on passed parameters, prepares SNMP TRAP or INFORM\n    notification (:RFC:`1905#section-4.2.6`) and schedules its\n    transmission by I/O framework at a later point of time.\n\n    Parameters\n    ----------\n    snmpDispatcher: :py:class:`~pysnmp.hlapi.v1arch.asyncore.SnmpDispatcher`\n        Class instance representing asyncore-based asynchronous event loop and\n        associated state information.\n\n    authData: :py:class:`~pysnmp.hlapi.CommunityData` or :py:class:`~pysnmp.hlapi.UsmUserData`\n        Class instance representing SNMP credentials.\n\n    transportTarget: :py:class:`~pysnmp.hlapi.asyncore.UdpTransportTarget` or\n        :py:class:`~pysnmp.hlapi.asyncore.Udp6TransportTarget`\n        Class instance representing transport type along with SNMP peer address.\n\n    notifyType: str\n        Indicates type of notification to be sent. Recognized literal\n        values are *trap* or *inform*.\n\n    \\*varBinds: :class:`tuple` of OID-value pairs or :py:class:`~pysnmp.smi.rfc1902.ObjectType` or :py:class:`~pysnmp.smi.rfc1902.NotificationType`\n        One or more objects representing MIB variables to place\n        into SNMP notification. It could be tuples of OID-values\n        or :py:class:`~pysnmp.smi.rfc1902.ObjectType` class instances\n        of :py:class:`~pysnmp.smi.rfc1902.NotificationType` objects.\n\n        Besides user variable-bindings, SNMP Notification PDU requires at\n        least two variable-bindings to be present:\n\n        0. SNMPv2-MIB::sysUpTime.0 = <agent uptime>\n        1. SNMPv2-SMI::snmpTrapOID.0 = <notification ID>\n\n        When sending SNMPv1 TRAP, more variable-bindings could be present:\n\n        2. SNMP-COMMUNITY-MIB::snmpTrapAddress.0 = <agent-IP>\n        3. SNMP-COMMUNITY-MIB::snmpTrapCommunity.0 = <snmp-community-name>\n        4. SNMP-COMMUNITY-MIB::snmpTrapEnterprise.0 = <enterprise-OID>\n\n        If user does not supply some or any of the above variable-bindings or\n        if they are at the wrong positions, the system will add/reorder the\n        missing ones automatically.\n\n        On top of that, some notification types imply including some additional\n        variable-bindings providing additional details on the event being\n        reported. Therefore it is generally easier to use\n        :py:class:`~pysnmp.smi.rfc1902.NotificationType` object which will\n        help adding relevant variable-bindings.\n\n    Other Parameters\n    ----------------\n    \\*\\*options :\n        Request options:\n\n        * `lookupMib` - load MIB and resolve response MIB variables at\n          the cost of slightly reduced performance. Default is `False`.\n        * `cbFun` (callable) - user-supplied callable that is invoked\n          to pass SNMP response data or error to user at a later point\n          of time. Default is `None`.\n        * `cbCtx` (object) - user-supplied object passing additional\n          parameters to/from `cbFun`. Default is `None`.\n\n    Note\n    ----\n    The `SnmpDispatcher` object may be expensive to create, therefore it is\n    advised to maintain it for the lifecycle of the application/thread for\n    as long as possible.\n\n    Returns\n    -------\n    sendRequestHandle: int\n        Unique request identifier. Can be used for matching received\n        responses with ongoing *INFORM* requests. Returns `None` for\n        *TRAP* notifications.\n\n    Raises\n    ------\n    PySnmpError\n        Or its derivative indicating that an error occurred while\n        performing SNMP operation.\n\n    Examples\n    --------\n    >>> from pysnmp.hlapi.v1arch.asyncore import *\n    >>>\n    >>> snmpDispatcher = SnmpDispatcher()\n    >>>\n    >>> sendNotification(\n    >>>     snmpDispatcher,\n    >>>     CommunityData('public'),\n    >>>     UdpTransportTarget(('demo.snmplabs.com', 162)),\n    >>>     'trap',\n    >>>     NotificationType(ObjectIdentity('SNMPv2-MIB', 'coldStart')),\n    >>>     lookupMib=True\n    >>> )\n    >>> snmpDispatcher.transportDispatcher.runDispatcher()\n    \"\"\"\n\n    sysUpTime = v2c.apiTrapPDU.sysUpTime\n    snmpTrapOID = v2c.apiTrapPDU.snmpTrapOID\n\n    def _ensureVarBinds(varBinds):\n        # Add sysUpTime if not present already\n        if not varBinds or varBinds[0][0] != sysUpTime:\n            varBinds.insert(0, (v2c.ObjectIdentifier(sysUpTime), v2c.TimeTicks(0)))\n\n        # Search for and reposition sysUpTime if it's elsewhere\n        for idx, varBind in enumerate(varBinds[1:]):\n            if varBind[0] == sysUpTime:\n                varBinds[0] = varBind\n                del varBinds[idx + 1]\n                break\n\n        if len(varBinds) < 2:\n            raise error.PySnmpError('SNMP notification PDU requires '\n                                    'SNMPv2-MIB::snmpTrapOID.0 to be present')\n\n        # Search for and reposition snmpTrapOID if it's elsewhere\n        for idx, varBind in enumerate(varBinds[2:]):\n            if varBind[0] == snmpTrapOID:\n                del varBinds[idx + 2]\n                if varBinds[1][0] == snmpTrapOID:\n                    varBinds[1] = varBind\n                else:\n                    varBinds.insert(1, varBind)\n                break\n\n        # Fail on missing snmpTrapOID\n        if varBinds[1][0] != snmpTrapOID:\n            raise error.PySnmpError('SNMP notification PDU requires '\n                                    'SNMPv2-MIB::snmpTrapOID.0 to be present')\n\n        return varBinds\n\n    def _cbFun(snmpDispatcher, stateHandle, errorIndication, rspPdu, _cbCtx):\n        if not cbFun:\n            return\n\n        if errorIndication:\n            cbFun(errorIndication, v2c.Integer(0), v2c.Integer(0), None,\n                  cbCtx=cbCtx, snmpDispatcher=snmpDispatcher, stateHandle=stateHandle)\n            return\n\n        errorStatus = v2c.apiTrapPDU.getErrorStatus(rspPdu)\n        errorIndex = v2c.apiTrapPDU.getErrorIndex(rspPdu)\n\n        varBinds = v2c.apiTrapPDU.getVarBinds(rspPdu)\n\n        if lookupMib:\n            varBinds = VB_PROCESSOR.unmakeVarBinds(snmpDispatcher.cache, varBinds)\n\n        nextStateHandle = v2c.getNextRequestID()\n\n        nextVarBinds = cbFun(errorIndication, errorStatus, errorIndex, varBinds,\n                             cbCtx=cbCtx,\n                             snmpDispatcher=snmpDispatcher,\n                             stateHandle=stateHandle,\n                             nextStateHandle=nextStateHandle)\n\n        if not nextVarBinds:\n            return\n\n        v2c.apiTrapPDU.setRequestID(reqPdu, nextStateHandle)\n        v2c.apiTrapPDU.setVarBinds(reqPdu, _ensureVarBinds(nextVarBinds))\n\n        return snmpDispatcher.sendPdu(authData, transportTarget, reqPdu, cbFun=_cbFun)\n\n    lookupMib, cbFun, cbCtx = [options.get(x) for x in ('lookupMib', 'cbFun', 'cbCtx')]\n\n    if lookupMib:\n        varBinds = VB_PROCESSOR.makeVarBinds(snmpDispatcher.cache, varBinds)\n\n    if notifyType == 'trap':\n        reqPdu = v2c.TrapPDU()\n    else:\n        reqPdu = v2c.InformRequestPDU()\n\n    v2c.apiTrapPDU.setDefaults(reqPdu)\n    v2c.apiTrapPDU.setVarBinds(reqPdu, varBinds)\n\n    varBinds = v2c.apiTrapPDU.getVarBinds(reqPdu)\n\n    v2c.apiTrapPDU.setVarBinds(reqPdu, _ensureVarBinds(varBinds))\n\n    if authData.mpModel == 0:\n        reqPdu = rfc2576.v2ToV1(reqPdu)\n\n    return snmpDispatcher.sendPdu(authData, transportTarget, reqPdu, cbFun=_cbFun)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nclones this instance. If *value* is specified, use its tag as the component type selector, and itself as the component value. :param value: (Optional) the component value. :type value: :py:obj:`pyasn1.type.base.Asn1ItemBase` :return: the cloned instance. :rtype: :py:obj:`pysnmp.proto.rfc1155.NetworkAddress` :raise: :py:obj:`pysnmp.smi.error.SmiError`: if the type of *value* is not allowed for this Choice instance.", "response": "def clone(self, value=univ.noValue, **kwargs):\n        \"\"\"Clone this instance.\n\n        If *value* is specified, use its tag as the component type selector,\n        and itself as the component value.\n\n        :param value: (Optional) the component value.\n        :type value: :py:obj:`pyasn1.type.base.Asn1ItemBase`\n        :return: the cloned instance.\n        :rtype: :py:obj:`pysnmp.proto.rfc1155.NetworkAddress`\n        :raise: :py:obj:`pysnmp.smi.error.SmiError`:\n            if the type of *value* is not allowed for this Choice instance.\n        \"\"\"\n        cloned = univ.Choice.clone(self, **kwargs)\n\n        if value is not univ.noValue:\n            if isinstance(value, NetworkAddress):\n                value = value.getComponent()\n\n            elif not isinstance(value, IpAddress):\n                # IpAddress is the only supported type, perhaps forever because\n                # this is SNMPv1.\n                value = IpAddress(value)\n\n            try:\n                tagSet = value.tagSet\n\n            except AttributeError:\n                raise PyAsn1Error('component value %r has no tag set' % (value,))\n\n            cloned.setComponentByType(tagSet, value)\n\n        return cloned"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrebuild a tree from all Managed Objects and Instances and MIBs in the current modules.", "response": "def _indexMib(self):\n        \"\"\"Rebuild a tree from MIB objects found at currently loaded modules.\n\n        If currently existing tree is out of date, walk over all Managed Objects\n        and Instances to structure Management Instrumentation objects into a tree\n        of the following layout:\n\n        MibTree\n          |\n          +----MibScalar\n          |        |\n          |        +-----MibScalarInstance\n          |\n          +----MibTable\n          |\n          +----MibTableRow\n                   |\n                   +-------MibTableColumn\n                                 |\n                                 +------MibScalarInstance(s)\n\n        Notes\n        -----\n        Only Managed Objects (i.e. `OBJECT-TYPE`) get indexed here, various MIB\n        definitions and constants can't be SNMP managed so we drop them.\n        \"\"\"\n        if self.lastBuildId == self.mibBuilder.lastBuildId:\n            return\n\n        (MibScalarInstance, MibScalar,\n         MibTableColumn, MibTableRow,\n         MibTable) = self.mibBuilder.importSymbols(\n            'SNMPv2-SMI', 'MibScalarInstance', 'MibScalar',\n            'MibTableColumn', 'MibTableRow', 'MibTable'\n        )\n\n        mibTree, = self.mibBuilder.importSymbols('SNMPv2-SMI', 'iso')\n\n        scalars = {}\n        instances = {}\n        tables = {}\n        rows = {}\n        cols = {}\n\n        # Sort by module name to give user a chance to slip-in\n        # custom MIB modules (that would be sorted out first)\n        mibSymbols = list(self.mibBuilder.mibSymbols.items())\n        mibSymbols.sort(key=lambda x: x[0], reverse=True)\n\n        for modName, mibMod in mibSymbols:\n\n            for symObj in mibMod.values():\n\n                if isinstance(symObj, MibTable):\n                    tables[symObj.name] = symObj\n\n                elif isinstance(symObj, MibTableRow):\n                    rows[symObj.name] = symObj\n\n                elif isinstance(symObj, MibTableColumn):\n                    cols[symObj.name] = symObj\n\n                elif isinstance(symObj, MibScalarInstance):\n                    instances[symObj.name] = symObj\n\n                elif isinstance(symObj, MibScalar):\n                    scalars[symObj.name] = symObj\n\n        # Detach items from each other\n        for symName, parentName in self.lastBuildSyms.items():\n\n            if parentName in scalars:\n                scalars[parentName].unregisterSubtrees(symName)\n\n            elif parentName in cols:\n                cols[parentName].unregisterSubtrees(symName)\n\n            elif parentName in rows:\n                rows[parentName].unregisterSubtrees(symName)\n\n            else:\n                mibTree.unregisterSubtrees(symName)\n\n        lastBuildSyms = {}\n\n        # Attach Managed Objects Instances to Managed Objects\n        for inst in instances.values():\n            if inst.typeName in scalars:\n                scalars[inst.typeName].registerSubtrees(inst)\n\n            elif inst.typeName in cols:\n                cols[inst.typeName].registerSubtrees(inst)\n\n            else:\n                raise error.SmiError(\n                    'Orphan MIB scalar instance %r at '\n                    '%r' % (inst, self))\n\n            lastBuildSyms[inst.name] = inst.typeName\n\n        # Attach Table Columns to Table Rows\n        for col in cols.values():\n            rowName = col.name[:-1]  # XXX\n\n            if rowName in rows:\n                rows[rowName].registerSubtrees(col)\n\n            else:\n                raise error.SmiError(\n                    'Orphan MIB table column %r at '\n                    '%r' % (col, self))\n\n            lastBuildSyms[col.name] = rowName\n\n        # Attach Table Rows to MIB tree\n        for row in rows.values():\n            mibTree.registerSubtrees(row)\n            lastBuildSyms[row.name] = mibTree.name\n\n        # Attach Tables to MIB tree\n        for table in tables.values():\n            mibTree.registerSubtrees(table)\n            lastBuildSyms[table.name] = mibTree.name\n\n        # Attach Scalars to MIB tree\n        for scalar in scalars.values():\n            mibTree.registerSubtrees(scalar)\n            lastBuildSyms[scalar.name] = mibTree.name\n\n        self.lastBuildSyms = lastBuildSyms\n\n        self.lastBuildId = self.mibBuilder.lastBuildId\n\n        debug.logger & debug.FLAG_INS and debug.logger('_indexMib: rebuilt')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef flipFlopFsm(self, fsmTable, *varBinds, **context):\n        count = [0]\n\n        cbFun = context.get('cbFun')\n\n        def _cbFun(varBind, **context):\n            idx = context.pop('idx', None)\n\n            err = context.pop('error', None)\n            if err:\n                # Move other errors into the errors sequence\n                errors = context['errors']\n\n                errors.append(\n                    {'error': err,\n                     'idx': idx,\n                     'varbind': varBind,\n                     'state': context['state']})\n\n                context['status'] = self.STATUS_ERROR\n\n            if idx is None:\n                if cbFun:\n                    cbFun((), **context)\n                return\n\n            _varBinds = context['varBinds']\n\n            _varBinds[idx] = varBind\n\n            count[0] += 1\n\n            debug.logger & debug.FLAG_INS and debug.logger(\n                '_cbFun: var-bind %d, processed %d, expected '\n                '%d' % (idx, count[0], len(varBinds)))\n\n            if count[0] < len(varBinds):\n                return\n\n            debug.logger & debug.FLAG_INS and debug.logger(\n                '_cbFun: finished, output var-binds %r' % (_varBinds,))\n\n            self.flipFlopFsm(fsmTable, *varBinds, **dict(context, cbFun=cbFun))\n\n        debug.logger & debug.FLAG_INS and debug.logger(\n            'flipFlopFsm: input var-binds %r' % (varBinds,))\n\n        mibTree, = self.mibBuilder.importSymbols('SNMPv2-SMI', 'iso')\n\n        try:\n            state = context['state']\n            status = context['status']\n            instances = context['instances']\n            errors = context['errors']\n            _varBinds = context['varBinds']\n\n        except KeyError:\n            state, status = self.STATE_START, self.STATUS_OK\n            instances = {}\n            errors = []\n            _varBinds = list(varBinds)\n\n            self._indexMib()\n\n        debug.logger & debug.FLAG_INS and debug.logger(\n            'flipFlopFsm: current state %s, status %s' % (state, status))\n\n        try:\n            newState = fsmTable[(state, status)]\n\n        except KeyError:\n            try:\n                newState = fsmTable[(self.STATE_ANY, status)]\n\n            except KeyError:\n                raise error.SmiError(\n                    'Unresolved FSM state %s, %s' % (state, status))\n\n        debug.logger & debug.FLAG_INS and debug.logger(\n            'flipFlopFsm: state %s status %s -> transitioned into state '\n            '%s' % (state, status, newState))\n\n        state = newState\n\n        if state == self.STATE_STOP:\n            context.pop('state', None)\n            context.pop('status', None)\n            context.pop('instances', None)\n            context.pop('varBinds', None)\n\n            if cbFun:\n                cbFun(_varBinds, **context)\n\n            return\n\n        # the case of no var-binds\n        if not varBinds:\n            _cbFun(None, **context)\n            return\n\n        actionFun = getattr(mibTree, state, None)\n        if not actionFun:\n            raise error.SmiError(\n                'Unsupported state handler %s at '\n                '%s' % (state, self))\n\n        for idx, varBind in enumerate(varBinds):\n            actionFun(\n                varBind,\n                **dict(context, cbFun=_cbFun, state=state, status=status,\n                       idx=idx, total=len(varBinds), instances=instances,\n                       errors=errors, varBinds=_varBinds, nextName=None))\n\n            debug.logger & debug.FLAG_INS and debug.logger(\n                'flipFlopFsm: func %s initiated for %r' % (actionFun, varBind))", "response": "Read modify create or remove Managed Objects Instances."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _defaultErrorHandler(varBinds, **context):\n        errors = context.get('errors')\n\n        if errors:\n            err = errors[-1]\n            raise err['error']", "response": "Raise exception on any error if user callback is missing"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef readMibObjects(self, *varBinds, **context):\n        if 'cbFun' not in context:\n            context['cbFun'] = self._defaultErrorHandler\n\n        self.flipFlopFsm(self.FSM_READ_VAR, *varBinds, **context)", "response": "Reads Managed Objects Instances from the specified set of variable names."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread the next Managed Object Instance from the given set of objects.", "response": "def readNextMibObjects(self, *varBinds, **context):\n        \"\"\"Read Managed Objects Instances next to the given ones.\n\n        Given one or more py:class:`~pysnmp.smi.rfc1902.ObjectType` objects, read\n        all or none of the Managed Objects Instances next to the referenced ones.\n\n        Parameters\n        ----------\n        varBinds: :py:class:`tuple` of :py:class:`~pysnmp.smi.rfc1902.ObjectType` objects\n            representing Managed Objects Instances to read next to.\n\n        Other Parameters\n        ----------------\n        \\*\\*context:\n\n            Query parameters:\n\n            * `cbFun` (callable) - user-supplied callable that is invoked to\n                pass the new value of the Managed Object Instance or an error.\n                If not provided, default function will raise exception in case\n                of an error.\n\n            * `acFun` (callable) - user-supplied callable that is invoked to\n                authorize access to the requested Managed Object Instance. If\n                not supplied, no access control will be performed.\n\n        Notes\n        -----\n        The signature of the callback functions (e.g. `cbFun`, `acFun`) is this:\n\n        .. code-block: python\n\n            def cbFun(varBinds, **context):\n                errors = context.get(errors)\n                if errors:\n                    print(errors[0].error)\n\n                else:\n                    print(', '.join('%s = %s' % varBind for varBind in varBinds))\n\n        In case of errors, the `errors` key in the `context` dict will contain\n        a sequence of `dict` objects describing one or more errors that occur.\n\n        If a non-existing Managed Object is referenced, no error will be\n        reported, but the values returned in the `varBinds` would be one of:\n        :py:class:`NoSuchObject` (indicating non-existent Managed Object) or\n        :py:class:`NoSuchInstance` (if Managed Object exists, but is not\n        instantiated) or :py:class:`EndOfMibView` (when the last Managed Object\n        Instance has been read).\n\n        When :py:class:`NoSuchObject` or :py:class:`NoSuchInstance` values are\n        returned, the caller is expected to repeat the same call with some\n        or all `varBinds` returned to progress towards the end of the\n        implemented MIB.\n        \"\"\"\n        if 'cbFun' not in context:\n            context['cbFun'] = self._defaultErrorHandler\n\n        self.flipFlopFsm(self.FSM_READ_NEXT_VAR, *varBinds, **context)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef writeMibObjects(self, *varBinds, **context):\n        if 'cbFun' not in context:\n            context['cbFun'] = self._defaultErrorHandler\n\n        self.flipFlopFsm(self.FSM_WRITE_VAR, *varBinds, **context)", "response": "This method writes Managed Object Instances to the specified set of variables."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninitiating a new SNMP GET packet and return the base class instance of the base class.", "response": "def getCmd(snmpDispatcher, authData, transportTarget, *varBinds, **options):\n    \"\"\"Initiate SNMP GET query over SNMPv1/v2c.\n\n    Based on passed parameters, prepares SNMP GET packet\n    (:RFC:`1905#section-4.2.1`) and schedules its transmission by\n    I/O framework at a later point of time.\n\n    Parameters\n    ----------\n    snmpDispatcher: :py:class:`~pysnmp.hlapi.v1arch.asyncore.SnmpDispatcher`\n        Class instance representing asyncore-based asynchronous event loop and\n        associated state information.\n\n    authData: :py:class:`~pysnmp.hlapi.v1arch.CommunityData`\n        Class instance representing SNMPv1/v2c credentials.\n\n    transportTarget: :py:class:`~pysnmp.hlapi.v1arch.asyncore.UdpTransportTarget` or\n        :py:class:`~pysnmp.hlapi.v1arch.asyncore.Udp6TransportTarget` Class instance representing\n        transport type along with SNMP peer address.\n\n    \\*varBinds: :class:`tuple` of OID-value pairs or :py:class:`~pysnmp.smi.rfc1902.ObjectType`\n        One or more class instances representing MIB variables to place\n        into SNMP request.\n\n    Other Parameters\n    ----------------\n    \\*\\*options:\n        Request options:\n\n        * `lookupMib` - load MIB and resolve response MIB variables at\n          the cost of slightly reduced performance. Default is `False`.\n        * `cbFun` (callable) - user-supplied callable that is invoked\n          to pass SNMP response data or error to user at a later point\n          of time. Default is `None`.\n        * `cbCtx` (object) - user-supplied object passing additional\n          parameters to/from `cbFun`. Default is `None`.\n\n    Note\n    ----\n    The `SnmpDispatcher` object may be expensive to create, therefore it is\n    advised to maintain it for the lifecycle of the application/thread for\n    as long as possible.\n\n    Note\n    ----\n    User-supplied `cbFun` callable must have the following call\n    signature:\n\n    * snmpDispatcher: :py:class:`~pysnmp.hlapi.v1arch.asyncore.SnmpDispatcher`\n      Class instance representing asyncore-based asynchronous event loop and\n      associated state information.\n    * stateHandle (int): Unique request identifier. Can be used\n      for matching multiple ongoing requests with received responses.\n    * errorIndication (str): evaluates to `True` to indicate SNMP dispatcher\n      error.\n    * errorStatus (int): evaluates to `True` to indicate SNMP PDU error.\n    * errorIndex (int): Non-zero value refers to `varBinds[errorIndex-1]`\n    * varBinds (tuple): A sequence of\n      :py:class:`~pysnmp.smi.rfc1902.ObjectType` class instances\n      representing MIB variables returned in SNMP response in exactly\n      the same order as `varBinds` in request.\n    * `cbCtx` (object): Original user-supplied object.\n\n    Returns\n    -------\n    stateHandle: int\n        Unique request identifier. Can be used for matching received\n        responses with ongoing requests.\n\n    Raises\n    ------\n    PySnmpError\n        Or its derivative indicating that an error occurred while\n        performing SNMP operation.\n\n    Examples\n    --------\n    >>> from pysnmp.hlapi.v1arch.asyncore import *\n    >>>\n    >>> def cbFun(snmpDispatcher, stateHandle, errorIndication,\n    >>>           errorStatus, errorIndex, varBinds, cbCtx):\n    >>>     print(errorIndication, errorStatus, errorIndex, varBinds)\n    >>>\n    >>> snmpDispatcher = SnmpDispatcher()\n    >>>\n    >>> stateHandle = getCmd(\n    >>>     snmpDispatcher,\n    >>>     CommunityData('public'),\n    >>>     UdpTransportTarget(('demo.snmplabs.com', 161)),\n    >>>     ObjectType(ObjectIdentity('SNMPv2-MIB', 'sysDescr', 0)),\n    >>>     cbFun=cbFun\n    >>> )\n    >>>\n    >>> snmpDispatcher.transportDispatcher.runDispatcher()\n    \"\"\"\n\n    def _cbFun(snmpDispatcher, stateHandle, errorIndication, rspPdu, _cbCtx):\n        if not cbFun:\n            return\n\n        if errorIndication:\n            cbFun(errorIndication, pMod.Integer(0), pMod.Integer(0), None,\n                  cbCtx=cbCtx, snmpDispatcher=snmpDispatcher, stateHandle=stateHandle)\n            return\n\n        errorStatus = pMod.apiPDU.getErrorStatus(rspPdu)\n        errorIndex = pMod.apiPDU.getErrorIndex(rspPdu)\n\n        varBinds = pMod.apiPDU.getVarBinds(rspPdu)\n\n        if lookupMib:\n            varBinds = VB_PROCESSOR.unmakeVarBinds(snmpDispatcher.cache, varBinds)\n\n        nextStateHandle = pMod.getNextRequestID()\n\n        nextVarBinds = cbFun(errorIndication, errorStatus, errorIndex, varBinds,\n                             cbCtx=cbCtx,\n                             snmpDispatcher=snmpDispatcher,\n                             stateHandle=stateHandle,\n                             nextStateHandle=nextStateHandle)\n\n        if not nextVarBinds:\n            return\n\n        pMod.apiPDU.setRequestID(reqPdu, nextStateHandle)\n        pMod.apiPDU.setVarBinds(reqPdu, nextVarBinds)\n\n        return snmpDispatcher.sendPdu(authData, transportTarget, reqPdu, cbFun=_cbFun)\n\n    lookupMib, cbFun, cbCtx = [options.get(x) for x in ('lookupMib', 'cbFun', 'cbCtx')]\n\n    if lookupMib:\n        varBinds = VB_PROCESSOR.makeVarBinds(snmpDispatcher.cache, varBinds)\n\n    pMod = api.PROTOCOL_MODULES[authData.mpModel]\n\n    reqPdu = pMod.GetRequestPDU()\n    pMod.apiPDU.setDefaults(reqPdu)\n    pMod.apiPDU.setVarBinds(reqPdu, varBinds)\n\n    return snmpDispatcher.sendPdu(authData, transportTarget, reqPdu, cbFun=_cbFun)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninitiate SNMP GETBULK query over SNMPv2c. Based on passed parameters, prepares SNMP GETBULK packet (:RFC:`1905#section-4.2.3`) and schedules its transmission by I/O framework at a later point of time. Parameters ---------- snmpDispatcher: :py:class:`~pysnmp.hlapi.v1arch.asyncore.SnmpDispatcher` Class instance representing SNMP dispatcher. authData: :py:class:`~pysnmp.hlapi.v1arch.CommunityData` or :py:class:`~pysnmp.hlapi.v1arch.UsmUserData` Class instance representing SNMP credentials. transportTarget: :py:class:`~pysnmp.hlapi.v1arch.asyncore.UdpTransportTarget` or :py:class:`~pysnmp.hlapi.v1arch.asyncore.Udp6TransportTarget` Class instance representing transport type along with SNMP peer address. nonRepeaters: int One MIB variable is requested in response for the first `nonRepeaters` MIB variables in request. maxRepetitions: int `maxRepetitions` MIB variables are requested in response for each of the remaining MIB variables in the request (e.g. excluding `nonRepeaters`). Remote SNMP dispatcher may choose lesser value than requested. \\*varBinds: :py:class:`~pysnmp.smi.rfc1902.ObjectType` One or more class instances representing MIB variables to place into SNMP request. Other Parameters ---------------- \\*\\*options : Request options: * `lookupMib` - load MIB and resolve response MIB variables at the cost of slightly reduced performance. Default is `True`. * `cbFun` (callable) - user-supplied callable that is invoked to pass SNMP response data or error to user at a later point of time. Default is `None`. * `cbCtx` (object) - user-supplied object passing additional parameters to/from `cbFun`. Default is `None`. Notes ----- User-supplied `cbFun` callable must have the following call signature: * snmpDispatcher (:py:class:`~pysnmp.hlapi.v1arch.snmpDispatcher`): Class instance representing SNMP dispatcher. * stateHandle (int): Unique request identifier. Can be used for matching multiple ongoing requests with received responses. * errorIndication (str): True value indicates SNMP dispatcher error. * errorStatus (str): True value indicates SNMP PDU error. * errorIndex (int): Non-zero value refers to `varBinds[errorIndex-1]` * varBindTable (tuple): A sequence of sequences (e.g. 2-D array) of variable-bindings represented as :class:`tuple` or :py:class:`~pysnmp.smi.rfc1902.ObjectType` class instances representing a table of MIB variables returned in SNMP response, with up to ``maxRepetitions`` rows, i.e. ``len(varBindTable) <= maxRepetitions``. For ``0 <= i < len(varBindTable)`` and ``0 <= j < len(varBinds)``, ``varBindTable[i][j]`` represents: - For non-repeaters (``j < nonRepeaters``), the first lexicographic successor of ``varBinds[j]``, regardless the value of ``i``, or an :py:class:`~pysnmp.smi.rfc1902.ObjectType` instance with the :py:obj:`~pysnmp.proto.rfc1905.endOfMibView` value if no such successor exists; - For repeaters (``j >= nonRepeaters``), the ``i``-th lexicographic successor of ``varBinds[j]``, or an :py:class:`~pysnmp.smi.rfc1902.ObjectType` instance with the :py:obj:`~pysnmp.proto.rfc1905.endOfMibView` value if no such successor exists. See :rfc:`3416#section-4.2.3` for details on the underlying ``GetBulkRequest-PDU`` and the associated ``GetResponse-PDU``, such as specific conditions under which the server may truncate the response, causing ``varBindTable`` to have less than ``maxRepetitions`` rows. * `cbCtx` (object): Original user-supplied object. Returns ------- stateHandle : int Unique request identifier. Can be used for matching received responses with ongoing requests. Raises ------ PySnmpError Or its derivative indicating that an error occurred while performing SNMP operation. Examples -------- >>> from pysnmp.hlapi.v1arch.asyncore import * >>> >>> def cbFun(snmpDispatcher, stateHandle, errorIndication, >>> errorStatus, errorIndex, varBinds, cbCtx): >>> print(errorIndication, errorStatus, errorIndex, varBinds) >>> >>> snmpDispatcher = snmpDispatcher() >>> >>> stateHandle = bulkCmd( >>> snmpDispatcher, >>> CommunityData('public'), >>> UdpTransportTarget(('demo.snmplabs.com', 161)), >>> 0, 2, >>> ('1.3.6.1.2.1.1', None), >>> cbFun=cbFun >>> ) >>> >>> snmpDispatcher.transportDispatcher.runDispatcher()", "response": "def bulkCmd(snmpDispatcher, authData, transportTarget,\n            nonRepeaters, maxRepetitions, *varBinds, **options):\n    \"\"\"Initiate SNMP GETBULK query over SNMPv2c.\n\n    Based on passed parameters, prepares SNMP GETBULK packet\n    (:RFC:`1905#section-4.2.3`) and schedules its transmission by\n    I/O framework at a later point of time.\n\n    Parameters\n    ----------\n    snmpDispatcher: :py:class:`~pysnmp.hlapi.v1arch.asyncore.SnmpDispatcher`\n        Class instance representing SNMP dispatcher.\n\n    authData: :py:class:`~pysnmp.hlapi.v1arch.CommunityData` or :py:class:`~pysnmp.hlapi.v1arch.UsmUserData`\n        Class instance representing SNMP credentials.\n\n    transportTarget: :py:class:`~pysnmp.hlapi.v1arch.asyncore.UdpTransportTarget` or :py:class:`~pysnmp.hlapi.v1arch.asyncore.Udp6TransportTarget`\n        Class instance representing transport type along with SNMP peer\n        address.\n\n    nonRepeaters: int\n        One MIB variable is requested in response for the first\n        `nonRepeaters` MIB variables in request.\n\n    maxRepetitions: int\n        `maxRepetitions` MIB variables are requested in response for each\n        of the remaining MIB variables in the request (e.g. excluding\n        `nonRepeaters`). Remote SNMP dispatcher may choose lesser value than\n        requested.\n\n    \\*varBinds: :py:class:`~pysnmp.smi.rfc1902.ObjectType`\n        One or more class instances representing MIB variables to place\n        into SNMP request.\n\n    Other Parameters\n    ----------------\n    \\*\\*options :\n        Request options:\n\n            * `lookupMib` - load MIB and resolve response MIB variables at\n              the cost of slightly reduced performance. Default is `True`.\n            * `cbFun` (callable) - user-supplied callable that is invoked\n               to pass SNMP response data or error to user at a later point\n               of time. Default is `None`.\n            * `cbCtx` (object) - user-supplied object passing additional\n               parameters to/from `cbFun`. Default is `None`.\n\n    Notes\n    -----\n    User-supplied `cbFun` callable must have the following call\n    signature:\n\n    * snmpDispatcher (:py:class:`~pysnmp.hlapi.v1arch.snmpDispatcher`):\n      Class instance representing SNMP dispatcher.\n    * stateHandle (int): Unique request identifier. Can be used\n      for matching multiple ongoing requests with received responses.\n    * errorIndication (str): True value indicates SNMP dispatcher error.\n    * errorStatus (str): True value indicates SNMP PDU error.\n    * errorIndex (int): Non-zero value refers to `varBinds[errorIndex-1]`\n    * varBindTable (tuple): A sequence of sequences (e.g. 2-D array) of\n      variable-bindings represented as :class:`tuple` or\n      :py:class:`~pysnmp.smi.rfc1902.ObjectType` class instances\n      representing a table of MIB variables returned in SNMP response, with\n      up to ``maxRepetitions`` rows, i.e. ``len(varBindTable) <= maxRepetitions``.\n\n      For ``0 <= i < len(varBindTable)`` and ``0 <= j < len(varBinds)``,\n      ``varBindTable[i][j]`` represents:\n\n      - For non-repeaters (``j < nonRepeaters``), the first lexicographic\n        successor of ``varBinds[j]``, regardless the value of ``i``, or an\n        :py:class:`~pysnmp.smi.rfc1902.ObjectType` instance with the\n        :py:obj:`~pysnmp.proto.rfc1905.endOfMibView` value if no such successor\n        exists;\n      - For repeaters (``j >= nonRepeaters``), the ``i``-th lexicographic\n        successor of ``varBinds[j]``, or an\n        :py:class:`~pysnmp.smi.rfc1902.ObjectType` instance with the\n        :py:obj:`~pysnmp.proto.rfc1905.endOfMibView` value if no such successor\n        exists.\n\n      See :rfc:`3416#section-4.2.3` for details on the underlying\n      ``GetBulkRequest-PDU`` and the associated ``GetResponse-PDU``, such as\n      specific conditions under which the server may truncate the response,\n      causing ``varBindTable`` to have less than ``maxRepetitions`` rows.\n    * `cbCtx` (object): Original user-supplied object.\n\n    Returns\n    -------\n    stateHandle : int\n        Unique request identifier. Can be used for matching received\n        responses with ongoing requests.\n\n    Raises\n    ------\n    PySnmpError\n        Or its derivative indicating that an error occurred while\n        performing SNMP operation.\n\n    Examples\n    --------\n    >>> from pysnmp.hlapi.v1arch.asyncore import *\n    >>>\n    >>> def cbFun(snmpDispatcher, stateHandle, errorIndication,\n    >>>           errorStatus, errorIndex, varBinds, cbCtx):\n    >>>     print(errorIndication, errorStatus, errorIndex, varBinds)\n    >>>\n    >>> snmpDispatcher = snmpDispatcher()\n    >>>\n    >>> stateHandle = bulkCmd(\n    >>>     snmpDispatcher,\n    >>>     CommunityData('public'),\n    >>>     UdpTransportTarget(('demo.snmplabs.com', 161)),\n    >>>     0, 2,\n    >>>     ('1.3.6.1.2.1.1', None),\n    >>>     cbFun=cbFun\n    >>> )\n    >>>\n    >>> snmpDispatcher.transportDispatcher.runDispatcher()\n    \"\"\"\n\n    def _cbFun(snmpDispatcher, stateHandle, errorIndication, rspPdu, _cbCtx):\n        if not cbFun:\n            return\n\n        if errorIndication:\n            cbFun(errorIndication, pMod.Integer(0), pMod.Integer(0), None,\n                  cbCtx=cbCtx, snmpDispatcher=snmpDispatcher, stateHandle=stateHandle)\n            return\n\n        errorStatus = pMod.apiBulkPDU.getErrorStatus(rspPdu)\n        errorIndex = pMod.apiBulkPDU.getErrorIndex(rspPdu)\n\n        varBindTable = pMod.apiBulkPDU.getVarBindTable(reqPdu, rspPdu)\n\n        errorIndication, nextVarBinds = pMod.apiBulkPDU.getNextVarBinds(\n            varBindTable[-1], errorIndex=errorIndex\n        )\n\n        if options.get('lookupMib'):\n            varBindTable = [\n                VB_PROCESSOR.unmakeVarBinds(snmpDispatcher.cache, vbs) for vbs in varBindTable\n            ]\n\n        nextStateHandle = pMod.getNextRequestID()\n\n        nextVarBinds = cbFun(errorIndication, errorStatus, errorIndex, varBindTable,\n                             cbCtx=cbCtx,\n                             snmpDispatcher=snmpDispatcher,\n                             stateHandle=stateHandle,\n                             nextStateHandle=nextStateHandle,\n                             nextVarBinds=nextVarBinds)\n\n        if not nextVarBinds:\n            return\n\n        pMod.apiBulkPDU.setRequestID(reqPdu, nextStateHandle)\n        pMod.apiBulkPDU.setVarBinds(reqPdu, nextVarBinds)\n\n        return snmpDispatcher.sendPdu(authData, transportTarget, reqPdu, cbFun=_cbFun)\n\n    if authData.mpModel < 1:\n        raise error.PySnmpError('GETBULK PDU is only supported in SNMPv2c and SNMPv3')\n\n    lookupMib, cbFun, cbCtx = [options.get(x) for x in ('lookupMib', 'cbFun', 'cbCtx')]\n\n    if lookupMib:\n        varBinds = VB_PROCESSOR.makeVarBinds(snmpDispatcher.cache, varBinds)\n\n    pMod = api.PROTOCOL_MODULES[authData.mpModel]\n\n    reqPdu = pMod.GetBulkRequestPDU()\n    pMod.apiBulkPDU.setDefaults(reqPdu)\n    pMod.apiBulkPDU.setNonRepeaters(reqPdu, nonRepeaters)\n    pMod.apiBulkPDU.setMaxRepetitions(reqPdu, maxRepetitions)\n    pMod.apiBulkPDU.setVarBinds(reqPdu, varBinds)\n\n    return snmpDispatcher.sendPdu(authData, transportTarget, reqPdu, cbFun=_cbFun)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a new object which is created by the function that is invoked by the callbackFun and cbCtx methods of the next request.", "response": "def getCmd(snmpEngine, authData, transportTarget, contextData,\n           *varBinds, **options):\n    \"\"\"Performs SNMP GET query.\n\n    Based on passed parameters, prepares SNMP GET packet\n    (:RFC:`1905#section-4.2.1`) and schedules its transmission by\n    I/O framework at a later point of time.\n\n    Parameters\n    ----------\n    snmpEngine : :py:class:`~pysnmp.hlapi.SnmpEngine`\n        Class instance representing SNMP engine.\n\n    authData : :py:class:`~pysnmp.hlapi.CommunityData` or :py:class:`~pysnmp.hlapi.UsmUserData`\n        Class instance representing SNMP credentials.\n\n    transportTarget : :py:class:`~pysnmp.hlapi.asyncore.UdpTransportTarget` or :py:class:`~pysnmp.hlapi.asyncore.Udp6TransportTarget`\n        Class instance representing transport type along with SNMP peer\n        address.\n\n    contextData : :py:class:`~pysnmp.hlapi.ContextData`\n        Class instance representing SNMP ContextEngineId and ContextName\n        values.\n\n    \\*varBinds : :py:class:`~pysnmp.smi.rfc1902.ObjectType`\n        One or more class instances representing MIB variables to place\n        into SNMP request.\n\n    Other Parameters\n    ----------------\n    \\*\\*options :\n\n        * `lookupMib` (bool) - load MIB and resolve response MIB variables at\n          the cost of slightly reduced performance. Default is `True`.\n        * `cbFun` (callable) - user-supplied callable that is invoked\n           to pass SNMP response data or error to user at a later point\n           of time. Default is `None`\n        * `cbCtx` (object) - user-supplied object passing additional\n           parameters to/from `cbFun`. Default is `None`.\n\n    Notes\n    -----\n    User-supplied `cbFun` callable must have the following call\n    signature:\n\n    * snmpEngine (:py:class:`~pysnmp.hlapi.SnmpEngine`):\n      Class instance representing SNMP engine.\n    * sendRequestHandle (int): Unique request identifier. Can be used\n      for matching multiple ongoing requests with received responses.\n    * errorIndication (str): True value indicates SNMP engine error.\n    * errorStatus (str): True value indicates SNMP PDU error.\n    * errorIndex (int): Non-zero value refers to `varBinds[errorIndex-1]`\n    * varBinds (tuple): A sequence of\n      :py:class:`~pysnmp.smi.rfc1902.ObjectType` class instances\n      representing MIB variables returned in SNMP response in exactly\n      the same order as `varBinds` in request.\n    * `cbCtx` : Original user-supplied object.\n\n    Returns\n    -------\n    sendRequestHandle : int\n        Unique request identifier. Can be used for matching received\n        responses with ongoing requests.\n\n    Raises\n    ------\n    PySnmpError\n        Or its derivative indicating that an error occurred while\n        performing SNMP operation.\n\n    Examples\n    --------\n    >>> from pysnmp.hlapi.asyncore import *\n    >>> def cbFun(snmpEngine, sendRequestHandle, errorIndication, errorStatus, errorIndex, varBinds, cbCtx):\n    ...     print(errorIndication, errorStatus, errorIndex, varBinds)\n    >>>\n    >>> snmpEngine = SnmpEngine()\n    >>> getCmd(snmpEngine,\n    ...        CommunityData('public'),\n    ...        UdpTransportTarget(('demo.snmplabs.com', 161)),\n    ...        ContextData(),\n    ...        ObjectType(ObjectIdentity('SNMPv2-MIB', 'sysDescr', 0)),\n    ...        cbFun=cbFun)\n    >>> snmpEngine.transportDispatcher.runDispatcher()\n    (None, 0, 0, [ObjectType(ObjectIdentity(ObjectName('1.3.6.1.2.1.1.1.0')), DisplayString('SunOS zeus.snmplabs.com 4.1.3_U1 1 sun4m'))])\n    >>>\n\n    \"\"\"\n\n    def __cbFun(snmpEngine, sendRequestHandle,\n                errorIndication, errorStatus, errorIndex,\n                varBinds, cbCtx):\n\n        lookupMib, cbFun, cbCtx = cbCtx\n\n        if cbFun:\n            varBinds = VB_PROCESSOR.unmakeVarBinds(\n                snmpEngine.cache, varBinds, lookupMib)\n\n            return cbFun(snmpEngine, sendRequestHandle, errorIndication,\n                         errorStatus, errorIndex, varBinds, cbCtx)\n\n    addrName, paramsName = LCD.configure(\n        snmpEngine, authData, transportTarget, contextData.contextName)\n\n    varBinds = VB_PROCESSOR.makeVarBinds(snmpEngine.cache, varBinds)\n\n    return cmdgen.GetCommandGenerator().sendVarBinds(\n        snmpEngine, addrName, contextData.contextEngineId,\n        contextData.contextName, varBinds, __cbFun,\n        (options.get('lookupMib', True),\n         options.get('cbFun'), options.get('cbCtx')))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite current changes to disk and flushes modified objects in the AAFObjectManager", "response": "def save(self):\n        \"\"\"\n        Writes current changes to disk and flushes modified objects in the\n        AAFObjectManager\n        \"\"\"\n        if self.mode in (\"wb+\", 'rb+'):\n            if not self.is_open:\n                raise IOError(\"file closed\")\n            self.write_reference_properties()\n            self.manager.write_objects()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncloses the file. A closed file cannot be read or written any more.", "response": "def close(self):\n        \"\"\"\n        Close the file. A closed file cannot be read or written any more.\n        \"\"\"\n        self.save()\n        self.manager.remove_temp()\n        self.cfb.close()\n        self.is_open = False\n        self.f.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run_apidoc(_):\n    import os\n    dirname = os.path.dirname(__file__)\n    ignore_paths = [os.path.join(dirname, '../../aaf2/model'),]\n    # https://github.com/sphinx-doc/sphinx/blob/master/sphinx/ext/apidoc.py\n    argv = [\n        '--force',\n        '--no-toc',\n        '--separate',\n        '--module-first',\n        '--output-dir',\n        os.path.join(dirname, 'api'),\n        os.path.join(dirname, '../../aaf2'),\n     ] + ignore_paths\n\n    from sphinx.ext import apidoc\n    apidoc.main(argv)", "response": "This method is required by the setup method below."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninitialize a new object from a dictionary.", "response": "def from_dict(self, d):\n        \"\"\"\n        Set MobID from a dict\n        \"\"\"\n        self.length = d.get(\"length\", 0)\n        self.instanceHigh = d.get(\"instanceHigh\", 0)\n        self.instanceMid = d.get(\"instanceMid\", 0)\n        self.instanceLow = d.get(\"instanceLow\", 0)\n\n        material = d.get(\"material\", {'Data1':0, 'Data2':0, 'Data3':0, 'Data4': [0 for i in range(8)]})\n\n        self.Data1 = material.get('Data1', 0)\n        self.Data2 = material.get('Data2', 0)\n        self.Data3 = material.get('Data3', 0)\n\n        self.Data4 = material.get(\"Data4\", [0 for i in range(8)])\n        self.SMPTELabel = d.get(\"SMPTELabel\", [0 for i in range(12)])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the MobID representation as a dict.", "response": "def to_dict(self):\n        \"\"\"\n        MobID representation as dict\n        \"\"\"\n\n        material = {'Data1': self.Data1,\n                    'Data2': self.Data2,\n                    'Data3': self.Data3,\n                    'Data4': list(self.Data4)\n                    }\n\n        return {'material':material,\n                'length': self.length,\n                'instanceHigh': self.instanceHigh,\n                'instanceMid': self.instanceMid,\n                'instanceLow': self.instanceLow,\n                'SMPTELabel': list(self.SMPTELabel)\n                }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the Urn of the current state of the object.", "response": "def urn(self):\n        \"\"\"\n        MobID Uniform Resource Name representation.\n        https://en.wikipedia.org/wiki/Uniform_Resource_Name\n        \"\"\"\n\n        SMPTELabel = self.SMPTELabel\n        Data4 = self.Data4\n\n        # handle case UMIDs where the material number is half swapped\n        if (SMPTELabel[11] == 0x00 and\n            Data4[0] == 0x06 and Data4[1] == 0x0E and\n            Data4[2] == 0x2B and Data4[3] == 0x34 and\n            Data4[4] == 0x7F and Data4[5] == 0x7F):\n\n            # print(\"case 1\")\n            f = \"urn:smpte:umid:%02x%02x%02x%02x.%02x%02x%02x%02x.%02x%02x%02x%02x.\" + \\\n             \"%02x\"  + \\\n             \"%02x%02x%02x.\" + \\\n             \"%02x%02x%02x%02x.%02x%02x%02x%02x.%08x.%04x%04x\"\n\n            return f % (\n                 SMPTELabel[0], SMPTELabel[1], SMPTELabel[2],  SMPTELabel[3],\n                 SMPTELabel[4], SMPTELabel[5], SMPTELabel[6],  SMPTELabel[7],\n                 SMPTELabel[8], SMPTELabel[9], SMPTELabel[10], SMPTELabel[11],\n                 self.length,\n                 self.instanceHigh, self.instanceMid, self.instanceLow,\n                 Data4[0], Data4[1], Data4[2], Data4[3],\n                 Data4[4], Data4[5], Data4[6], Data4[7],\n                 self.Data1, self.Data2, self.Data3)\n        else:\n            # print(\"case 2\")\n            f = \"urn:smpte:umid:%02x%02x%02x%02x.%02x%02x%02x%02x.%02x%02x%02x%02x.\" + \\\n             \"%02x\"  + \\\n             \"%02x%02x%02x.\" + \\\n             \"%08x.%04x%04x.%02x%02x%02x%02x.%02x%02x%02x%02x\"\n\n            return f % (\n                 SMPTELabel[0], SMPTELabel[1], SMPTELabel[2],  SMPTELabel[3],\n                 SMPTELabel[4], SMPTELabel[5], SMPTELabel[6],  SMPTELabel[7],\n                 SMPTELabel[8], SMPTELabel[9], SMPTELabel[10], SMPTELabel[11],\n                 self.length,\n                 self.instanceHigh, self.instanceMid, self.instanceLow,\n                 self.Data1, self.Data2, self.Data3,\n                 Data4[0], Data4[1], Data4[2], Data4[3],\n                 Data4[4], Data4[5], Data4[6], Data4[7])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wave_infochunk(path):\n    with open(path,'rb') as file:\n        if file.read(4) != b\"RIFF\":\n            return None\n        data_size = file.read(4) # container size\n        if file.read(4) != b\"WAVE\":\n            return None\n        while True:\n            chunkid = file.read(4)\n            sizebuf = file.read(4)\n            if len(sizebuf) < 4 or len(chunkid) < 4:\n                return None\n            size    = struct.unpack(b'<L', sizebuf )[0]\n            if chunkid[0:3] != b\"fmt\":\n                if size % 2 == 1:\n                    seek = size + 1\n                else:\n                    seek = size\n                file.seek(size,1)\n            else:\n                return bytearray(b\"RIFF\" + data_size + b\"WAVE\" + chunkid + sizebuf + file.read(size))", "response": "Returns a bytearray of the WAVE RIFF header and fmt\nracket chunk for a WAVEDescriptor and Summary"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_wav_link(f, metadata):\n    path       = metadata['format']['filename']\n    master_mob = f.create.MasterMob()\n    source_mob = f.create.SourceMob()\n    tape_mob   = f.create.SourceMob()\n\n    edit_rate  = metadata['streams'][0]['sample_rate']\n    length     = metadata['streams'][0]['duration_ts']\n\n    master_mob.name = os.path.basename(path)\n    source_mob.name = os.path.basename(path) + \" Source MOB\"\n    tape_mob.name   = os.path.basename(path) + \" Tape MOB\"\n    container_guid  = AUID(\"3711d3cc-62d0-49d7-b0ae-c118101d1a16\") # WAVE/AIFF\n\n    f.content.mobs.append(master_mob)\n    f.content.mobs.append(source_mob)\n    f.content.mobs.append(tape_mob)\n\n    tape_mob.descriptor = f.create.TapeDescriptor()\n    tape_mob.descriptor[\"VideoSignal\"].value = \"VideoSignalNull\"\n\n    # Tape timecode\n\n    t = tape_mob.create_empty_sequence_slot(edit_rate, media_kind='timecode')\n    tc = f.create.Timecode(int(float(edit_rate)+0.5), drop=False)\n    tc.length = int(length)\n    if 'tags' not in metadata['format'].keys() or \\\n            'time_reference' not in metadata['format']['tags']:\n        tc.start = 0\n    else:\n        tc.start = metadata['format']['tags']['time_reference'] or 0\n\n    t.segment.length = int(length)\n    t.segment.components.append(tc)\n\n    descriptor = create_wav_descriptor(f, source_mob, path, metadata['streams'][0])\n    source_mob.descriptor = descriptor\n\n    for channel_index in range(metadata['streams'][0]['channels']):\n        tape_slot = tape_mob.create_empty_sequence_slot(edit_rate, media_kind='sound')\n        tape_slot.segment.length = length\n        nul_ref = f.create.SourceClip(media_kind='sound')\n        nul_ref.length = length\n        tape_slot.segment.components.append(nul_ref)\n\n        tape_clip = tape_mob.create_source_clip(tape_slot.slot_id)\n        tape_clip.length = length\n        tape_clip.media_kind = 'sound'\n\n        src_slot = source_mob.create_empty_sequence_slot(edit_rate, media_kind='sound')\n        src_slot.segment.length = length\n        src_slot.segment.components.append(tape_clip)\n        src_slot['PhysicalTrackNumber'].value = channel_index + 1\n\n        clip = source_mob.create_source_clip(src_slot.slot_id)\n        clip.length = length\n        clip.media_kind = 'sound'\n\n        master_slot = master_mob.create_empty_sequence_slot(edit_rate, media_kind='sound')\n        master_slot.segment.components.append(clip)\n        master_slot.segment.length = length\n\n        master_slot['PhysicalTrackNumber'].value = channel_index + 1\n\n    return master_mob, source_mob, tape_mob", "response": "This function creates a WAVE link for the given file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves self from binary search tree", "response": "def pop(self):\n        \"\"\"\n        remove self from binary search tree\n        \"\"\"\n        entry = self\n        parent = self.parent\n\n        root = parent.child()\n\n        dir_per_sector = self.storage.sector_size // 128\n        max_dirs_entries = self.storage.dir_sector_count * dir_per_sector\n        count = 0\n\n        if root.dir_id == entry.dir_id:\n            parent.child_id = None\n        else:\n            # find dir entry pointing to self\n            while True:\n                if count > max_dirs_entries:\n                    raise CompoundFileBinaryError(\"max dir entries limit reached\")\n\n                if entry < root:\n                    if root.left_id == entry.dir_id:\n                        root.left_id = None\n                        break\n                    root = root.left()\n                else:\n                    if root.right_id == entry.dir_id:\n                        # root right is pointing to self\n                        root.right_id = None\n                        break\n                    root = root.right()\n\n                count += 1\n\n\n        left = entry.left()\n        right = entry.right()\n\n        # clear from cache\n        if parent.dir_id in self.storage.children_cache:\n            del self.storage.children_cache[parent.dir_id][entry.name]\n            if left:\n                del self.storage.children_cache[parent.dir_id][left.name]\n            if right:\n                del self.storage.children_cache[parent.dir_id][right.name]\n\n        if left is not None:\n            parent.add_child(left)\n        if right is not None:\n            parent.add_child(right)\n\n        # clear parent and left and right\n        self.left_id = None\n        self.right_id = None\n        self.parent = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove(self, path):\n\n        entry = self.find(path)\n\n        if not entry:\n            raise ValueError(\"%s does not exists\" % path)\n\n        if entry.type == 'root storage':\n            raise ValueError(\"can no remove root entry\")\n\n        if entry.type == \"storage\" and not entry.child_id is None:\n            raise ValueError(\"storage contains children\")\n\n        entry.pop()\n\n        # remove stream data\n        if entry.type == \"stream\":\n            self.free_fat_chain(entry.sector_id, entry.byte_size < self.min_stream_max_size)\n\n        self.free_dir_entry(entry)", "response": "Removes both streams and storage types from file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves the directory structure of the file at the given path.", "response": "def rmtree(self, path):\n        \"\"\"\n        Removes directory structure, similar to shutil.rmtree.\n        \"\"\"\n        for root, storage, streams in self.walk(path, topdown=False):\n\n            for item in streams:\n                self.free_fat_chain(item.sector_id, item.byte_size < self.min_stream_max_size)\n                self.free_dir_entry(item)\n\n            for item in storage:\n                self.free_dir_entry(item)\n\n            root.child_id = None\n\n        # remove root item\n        self.remove(path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef listdir_dict(self, path = None):\n\n        if path is None:\n            path = self.root\n\n        root = self.find(path)\n        if root is None:\n            raise ValueError(\"unable to find dir: %s\" % str(path))\n\n        if not root.isdir():\n            raise ValueError(\"can only list storage types\")\n\n        children = self.children_cache.get(root.dir_id, None)\n        if children is not None:\n            return children\n\n        child = root.child()\n\n        result = {}\n        if not child:\n            self.children_cache[root.dir_id] = result\n            return result\n\n        dir_per_sector = self.sector_size // 128\n        max_dirs_entries = self.dir_sector_count * dir_per_sector\n\n        stack =  deque([child])\n        count = 0\n\n        while stack:\n            current = stack.pop()\n            result[current.name] = current\n            count += 1\n\n            if count > max_dirs_entries:\n                raise CompoundFileBinaryError(\"corrupt folder structure\")\n\n            left = current.left()\n            if left:\n                stack.append(left)\n            right =  current.right()\n            if right:\n                stack.append(right)\n\n        self.children_cache[root.dir_id] = result\n        return result", "response": "Return a dict containing the DirEntry objects in the directory with the given path as key."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find(self, path):\n\n        if isinstance(path, DirEntry):\n            return path\n\n        if path == \"/\":\n            return self.root\n\n        split_path = path.lstrip('/').split(\"/\")\n\n        i = 0\n        root = self.root\n\n        while True:\n\n            children = self.listdir_dict(root)\n            match = children.get(split_path[i], None)\n\n            if match:\n                if i == len(split_path) - 1:\n                    return match\n                root = match\n                i += 1\n            else:\n                return None", "response": "Find a DirEntry located at path. Returns None if no such DirEntry is found."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef walk(self, path = None, topdown=True):\n\n        if path is None:\n            path = self.root\n\n        root = self.find(path)\n\n        if not root.isdir():\n            raise ValueError(\"can only walk storage types\")\n\n        if not root.child_id:\n            return\n\n        if topdown:\n            storage_items = []\n            stream_items = []\n\n            for item in self.listdir(root):\n                if item.isdir():\n                    storage_items.append(item)\n                else:\n                    stream_items.append(item)\n\n            yield root, storage_items, stream_items\n\n            for item in storage_items:\n                for root, storage_items, stream_items in self.walk(item):\n                    yield root, storage_items, stream_items\n        else:\n\n            def topdown_visit_node(root):\n                storage_items = []\n                stream_items = []\n                for item in self.listdir(root):\n                    if item.isdir():\n                        for sub_root, sub_storage, sub_stream in topdown_visit_node(item):\n                            yield sub_root, sub_storage, sub_stream\n\n                        storage_items.append(item)\n                    else:\n                        stream_items.append(item)\n\n                yield root, storage_items, stream_items\n\n            for root_item, storage, stream in topdown_visit_node(root):\n                yield root_item, storage, stream", "response": "A generator function that walks the storage types tree and returns a list of storage types and streams."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a storage DirEntry name path", "response": "def makedir(self, path, class_id=None):\n        \"\"\"\n        Create a storage DirEntry name path\n        \"\"\"\n        return self.create_dir_entry(path, dir_type='storage', class_id=class_id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef makedirs(self, path):\n        root = \"\"\n\n        assert path.startswith('/')\n        p = path.strip('/')\n        for item in p.split('/'):\n            root += \"/\" + item\n            if not self.exists(root):\n                self.makedir(root)\n\n        return self.find(path)", "response": "Recursive storage DirEntry creation function."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef move(self, src, dst):\n        src_entry = self.find(src)\n        if src_entry is None:\n            raise ValueError(\"src path does not exist: %s\" % src)\n\n        if dst.endswith('/'):\n            dst += src_entry.name\n\n        if self.exists(dst):\n            raise ValueError(\"dst path already exist: %s\" % dst)\n\n        if dst == '/' or src == '/':\n            raise ValueError(\"cannot overwrite root dir\")\n\n        split_path = dst.strip('/').split('/')\n        dst_basename = split_path[-1]\n        dst_dirname = '/' + '/'.join(split_path[:-1])\n\n        # print(dst)\n        # print(dst_basename, dst_dirname)\n\n        dst_entry = self.find(dst_dirname)\n        if dst_entry is None:\n            raise ValueError(\"src path does not exist: %s\" % dst_dirname)\n\n        if not dst_entry.isdir():\n            raise ValueError(\"dst dirname cannot be stream: %s\" % dst_dirname)\n\n        # src_entry.parent.remove_child(src_entry)\n\n        src_entry.pop()\n\n        src_entry.parent = None\n        src_entry.name = dst_basename\n        dst_entry.add_child(src_entry)\n\n        self.children_cache[dst_entry.dir_id][src_entry.name] = src_entry\n\n        return src_entry", "response": "Moves src to dst."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nopen a stream at the given path.", "response": "def open(self, path, mode='r'):\n        \"\"\"Open stream, returning ``Stream`` object\"\"\"\n\n        entry = self.find(path)\n        if entry is None:\n            if mode == 'r':\n                raise ValueError(\"stream does not exists: %s\" % path)\n            entry = self.create_dir_entry(path, 'stream', None)\n\n        else:\n            if not entry.isfile():\n                raise ValueError(\"can only open stream type DirEntry's\")\n\n            if mode == 'w':\n                logging.debug(\"stream: %s exists, overwriting\" % path)\n                self.free_fat_chain(entry.sector_id, entry.byte_size < self.min_stream_max_size)\n                entry.sector_id = None\n                entry.byte_size = 0\n                entry.class_id = None\n            elif mode == 'rw':\n                pass\n\n        s = Stream(self, entry, mode)\n        return s"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add2set(self, pid, key, value):\n    prop = self.property_entries[pid]\n\n    current = prop.objects.get(key, None)\n    current_local_key = prop.references.get(key, None)\n\n    if current and current is not value:\n        current.detach()\n\n    if current_local_key is None:\n        prop.references[key] = prop.next_free_key\n        prop.next_free_key += 1\n\n    prop.objects[key] = value\n\n    if prop.parent.dir:\n        ref = prop.index_ref_name(key)\n        dir_entry = prop.parent.dir.get(ref)\n        if dir_entry is None:\n            dir_entry = prop.parent.dir.makedir(ref)\n        if value.dir != dir_entry:\n            value.attach(dir_entry)\n        prop.mark_modified()", "response": "low level add to StrongRefSetProperty"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _create_opt_rule(self, rulename):\n        optname = rulename + '_opt'\n\n        def optrule(self, p):\n            p[0] = p[1]\n\n        optrule.__doc__ = '%s : empty\\n| %s' % (optname, rulename)\n        optrule.__name__ = 'p_%s' % optname\n        setattr(self.__class__, optrule.__name__, optrule)", "response": "Creates an optional rule for the given rule name."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef p_definitions(self, p):\n        'definitions : definitions definition'\n        p[0] = p[1] + (p[2],)\n        p.set_lineno(0, p.lineno(1))", "response": "\\ x1b [ 1mNAME \\ x1b [ 0m definitions - > definitions definition"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_pragma_assign(self, p):\n        'pragma : LPAREN TIMES ID EQUALS expression TIMES RPAREN'\n        p[0] = Pragma(PragmaEntry(p[3], p[5], lineno=p.lineno(1)),\n                      lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "pragma : LPAREN TIMES ID EQUALS expression TIMES RPAREN"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_pragma(self, p):\n        'pragma : LPAREN TIMES ID TIMES RPAREN'\n        p[0] = Pragma(PragmaEntry(p[3], lineno=p.lineno(1)),\n                      lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "P_pragma is a bit of a hack to make a new pragma."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_paramlist(self, p):\n        'paramlist : DELAY LPAREN params RPAREN'\n        p[0] = Paramlist(params=p[3], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "paramlist : DELAY LPAREN params RPAREN"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_params_begin(self, p):\n        'params_begin : params_begin param'\n        p[0] = p[1] + (p[2],)\n        p.set_lineno(0, p.lineno(1))", "response": "params_begin : params_begin param"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_param(self, p):\n        'param : PARAMETER param_substitution_list COMMA'\n        paramlist = [Parameter(rname, rvalue, lineno=p.lineno(2))\n                     for rname, rvalue in p[2]]\n        p[0] = Decl(tuple(paramlist), lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "param : PARAMETER param_substitution_list COMMA"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_param_signed(self, p):\n        'param : PARAMETER SIGNED param_substitution_list COMMA'\n        paramlist = [Parameter(rname, rvalue, signed=True, lineno=p.lineno(2))\n                     for rname, rvalue in p[3]]\n        p[0] = Decl(tuple(paramlist), lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "param : PARAMETER SIGNED param_substitution_list COMMA"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_portlist(self, p):\n        'portlist : LPAREN ports RPAREN SEMICOLON'\n        p[0] = Portlist(ports=p[2], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "portlist : LPAREN ports RPAREN SEMICOLON"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_portlist_io(self, p):\n        'portlist : LPAREN ioports RPAREN SEMICOLON'\n        p[0] = Portlist(ports=p[2], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "portlist : LPAREN ioports RPAREN SEMICOLON"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_portlist_paren_empty(self, p):\n        'portlist : LPAREN RPAREN SEMICOLON'\n        p[0] = Portlist(ports=(), lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "portlist : LPAREN RPAREN SEMICOLON"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_ports(self, p):\n        'ports : ports COMMA portname'\n        wid = None\n        port = Port(name=p[3], width=wid, type=None, lineno=p.lineno(1))\n        p[0] = p[1] + (port,)\n        p.set_lineno(0, p.lineno(1))", "response": "ports : ports COMMA portname"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_ioport_width(self, p):\n        'ioport : sigtypes width portname'\n        p[0] = self.create_ioport(p[1], p[3], width=p[2], lineno=p.lineno(3))\n        p.set_lineno(0, p.lineno(1))", "response": "ioport : sigtypes width portname"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_length(self, p):\n        'length : LBRACKET expression COLON expression RBRACKET'\n        p[0] = Length(p[2], p[4], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "length : LBRACKET expression COLON expression RBRACKET"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_decl(self, p):\n        'decl : sigtypes declnamelist SEMICOLON'\n        decllist = []\n        for rname, rlength in p[2]:\n            decllist.extend(self.create_decl(p[1], rname, length=rlength,\n                                             lineno=p.lineno(2)))\n        p[0] = Decl(tuple(decllist), lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "decl : sigtypes declnamelist SEMICOLON"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_declnamelist(self, p):\n        'declnamelist : declnamelist COMMA declname'\n        p[0] = p[1] + (p[3],)\n        p.set_lineno(0, p.lineno(1))", "response": "declnamelist : declnamelist COMMA declname"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_declarray(self, p):\n        'declname : ID length'\n        p[0] = (p[1], p[2])\n        p.set_lineno(0, p.lineno(1))", "response": "declname : ID length"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_declassign(self, p):\n        'declassign : sigtypes declassign_element SEMICOLON'\n        decllist = self.create_declassign(\n            p[1], p[2][0], p[2][1], lineno=p.lineno(2))\n        p[0] = Decl(decllist, lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "declassign : sigtypes declassign_element SEMICOLON"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_declassign_width(self, p):\n        'declassign : sigtypes width declassign_element SEMICOLON'\n        decllist = self.create_declassign(\n            p[1], p[3][0], p[3][1], width=p[2], lineno=p.lineno(3))\n        p[0] = Decl(tuple(decllist), lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "declassign : sigtypes width declassign_element SEMICOLON"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_integernamelist(self, p):\n        'integernamelist : integernamelist COMMA integername'\n        p[0] = p[1] + (p[3],)\n        p.set_lineno(0, p.lineno(1))", "response": "integernamelist : integernamelist COMMA integername"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing REAL realnamelist SEMICOLON", "response": "def p_realdecl(self, p):\n        'realdecl : REAL realnamelist SEMICOLON'\n        reallist = [Real(p[1],\n                         Width(msb=IntConst('31', lineno=p.lineno(2)),\n                               lsb=IntConst('0', lineno=p.lineno(2)),\n                               lineno=p.lineno(2)),\n                         lineno=p.lineno(2)) for r in p[2]]\n        p[0] = Decl(tuple(reallist), lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_assignment_delay(self, p):\n        'assignment : ASSIGN delays lvalue EQUALS delays rvalue SEMICOLON'\n        p[0] = Assign(p[3], p[6], p[2], p[5], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "assignment : ASSIGN delays lvalue EQUALS delays rvalue SEMICOLON"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_lpartselect_lpointer_minus(self, p):\n        'lpartselect : pointer LBRACKET expression MINUSCOLON expression RBRACKET'\n        p[0] = Partselect(p[1], p[3], Minus(p[3], p[5]), lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "lpartselect : pointer LBRACKET expression MINUSCOLON expression RBRACKET"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_lpartselect(self, p):\n        'lpartselect : identifier LBRACKET expression COLON expression RBRACKET'\n        p[0] = Partselect(p[1], p[3], p[5], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "lpartselect : identifier LBRACKET expression COLON expression RBRACKET"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_lpartselect_plus(self, p):\n        'lpartselect : identifier LBRACKET expression PLUSCOLON expression RBRACKET'\n        p[0] = Partselect(p[1], p[3], Plus(p[3], p[5]), lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "lpartselect : identifier LBRACKET expression PLUSCOLON expression RBRACKET"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_lconcat(self, p):\n        'lconcat : LBRACE lconcatlist RBRACE'\n        p[0] = LConcat(p[2], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "lconcat list | LConcat | LConcat | LConcat | LConcat | RConcat | LConcat | LConcat | LConcat | LConcat | RConcat | LConcat | LConcat | LConcat | LConcat | LConcat | LConcat | LConcat | LConcat | LConcat | LConcat | LConcat | LConcat | LConcat | LConcat | LConcat | LConcat | LConcat | LConcat | LConcat | LConcat | LConcat | LConcat | |"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef p_expression_uminus(self, p):\n        'expression : MINUS expression %prec UMINUS'\n        p[0] = Uminus(p[2], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "expression : MINUS expression %prec UMINUS"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_expression_ulnot(self, p):\n        'expression : LNOT expression %prec ULNOT'\n        p[0] = Ulnot(p[2], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "expression : LNOT expression %prec ULNOT"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_expression_unot(self, p):\n        'expression : NOT expression %prec UNOT'\n        p[0] = Unot(p[2], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "expression : NOT expression %prec UNOT"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_expression_uor(self, p):\n        'expression : OR expression %prec UOR'\n        p[0] = Uor(p[2], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "expression %prec UOR expression %prec UOR"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_expression_div(self, p):\n        'expression : expression DIVIDE expression'\n        p[0] = Divide(p[1], p[3], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "expression : expression DIVIDE expression"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_expression_plus(self, p):\n        'expression : expression PLUS expression'\n        p[0] = Plus(p[1], p[3], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "expression : expression PLUS expression"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_expression_sla(self, p):\n        'expression : expression LSHIFTA expression'\n        p[0] = Sll(p[1], p[3], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "expression : expression LSHIFTA expression"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_expression_sra(self, p):\n        'expression : expression RSHIFTA expression'\n        p[0] = Sra(p[1], p[3], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "expression : expression RSHIFTA expression"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_expression_greaterthan(self, p):\n        'expression : expression GT expression'\n        p[0] = GreaterThan(p[1], p[3], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "expression : expression GT expression"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_expression_lesseq(self, p):\n        'expression : expression LE expression'\n        p[0] = LessEq(p[1], p[3], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "expression : expression LE expression"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_expression_eql(self, p):\n        'expression : expression EQL expression'\n        p[0] = Eql(p[1], p[3], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "expression : expression EQL expression"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_expression_And(self, p):\n        'expression : expression AND expression'\n        p[0] = And(p[1], p[3], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "expression : expression AND expression"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_expression_Xnor(self, p):\n        'expression : expression XNOR expression'\n        p[0] = Xnor(p[1], p[3], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "expression : expression XNOR expression"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_expression_lor(self, p):\n        'expression : expression LOR expression'\n        p[0] = Lor(p[1], p[3], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "expression : expression LOR expression"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_expression_cond(self, p):\n        'expression : expression COND expression COLON expression'\n        p[0] = Cond(p[1], p[3], p[5], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "expression COND expression COLON expression"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_concat(self, p):\n        'concat : LBRACE concatlist RBRACE'\n        p[0] = Concat(p[2], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "concatlist LBRACE concatlist RBRACE"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_concatlist(self, p):\n        'concatlist : concatlist COMMA expression'\n        p[0] = p[1] + (p[3],)\n        p.set_lineno(0, p.lineno(1))", "response": "concatlist : concatlist COMMA expression"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrepeat : LBRACE expression concat RBRACE", "response": "def p_repeat(self, p):\n        'repeat : LBRACE expression concat RBRACE'\n        p[0] = Repeat(p[3], p[2], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_partselect_plus(self, p):\n        'partselect : identifier LBRACKET expression PLUSCOLON expression RBRACKET'\n        p[0] = Partselect(p[1], p[3], Plus(\n            p[3], p[5], lineno=p.lineno(1)), lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "partselect : identifier LBRACKET expression PLUSCOLON expression RBRACKET"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_partselect_minus(self, p):\n        'partselect : identifier LBRACKET expression MINUSCOLON expression RBRACKET'\n        p[0] = Partselect(p[1], p[3], Minus(\n            p[3], p[5], lineno=p.lineno(1)), lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "partselect : identifier LBRACKET expression MINUSCOLON expression RBRACKET"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_partselect_pointer(self, p):\n        'partselect : pointer LBRACKET expression COLON expression RBRACKET'\n        p[0] = Partselect(p[1], p[3], p[5], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "Partselect pointer LBRACKET expression COLON expression RBRACKET"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_partselect_pointer_minus(self, p):\n        'partselect : pointer LBRACKET expression MINUSCOLON expression RBRACKET'\n        p[0] = Partselect(p[1], p[3], Minus(\n            p[3], p[5], lineno=p.lineno(1)), lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "partselect : pointer LBRACKET expression MINUSCOLON expression RBRACKET"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_pointer(self, p):\n        'pointer : identifier LBRACKET expression RBRACKET'\n        p[0] = Pointer(p[1], p[3], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "parse a resource table pointer"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef p_pointer_pointer(self, p):\n        'pointer : pointer LBRACKET expression RBRACKET'\n        p[0] = Pointer(p[1], p[3], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "parse LBRACKET expression RBRACKET pointer LBRACKET expression RBRACKET"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_always_comb(self, p):\n        'always_comb : ALWAYS_COMB senslist always_statement'\n        p[0] = AlwaysComb(p[2], p[3], lineno=p.lineno(1))", "response": "A always_comb is a senslist always_statement"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_sens_egde_paren(self, p):\n        'senslist : AT LPAREN edgesigs RPAREN'\n        p[0] = SensList(p[3], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "Sens list | AT LPAREN edgesigs RPAREN"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_posedgesig(self, p):\n        'edgesig : POSEDGE edgesig_base'\n        p[0] = Sens(p[2], 'posedge', lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "edgesig : POSEDGE edgesig_base"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_edgesigs(self, p):\n        'edgesigs : edgesigs SENS_OR edgesig'\n        p[0] = p[1] + (p[3],)\n        p.set_lineno(0, p.lineno(1))", "response": "edgesigs : edgesigs SENS_OR edgesig"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_sens_level(self, p):\n        'senslist : AT levelsig'\n        p[0] = SensList((p[2],), lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "SensList : AT levelsig"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_sens_level_paren(self, p):\n        'senslist : AT LPAREN levelsigs RPAREN'\n        p[0] = SensList(p[3], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "SensList | levelsigs | levelsigs | levelsigs | levelsigs | levelsigs | levelsigs | levelsigs | levelsigs | levelsigs | levelsigs | levelsigs | levelsigs | levelsigs | levelsigs | levelsigs | levelsigs | levelsigs | levelsigs | levelsigs | levelsigs | levelsigs | levelsigs | levelsigs | levelsigs | levelsigs|"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_levelsigs(self, p):\n        'levelsigs : levelsigs SENS_OR levelsig'\n        p[0] = p[1] + (p[3],)\n        p.set_lineno(0, p.lineno(1))", "response": "levelsigs : levelsigs SENS_OR levelsig"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_levelsigs_comma(self, p):\n        'levelsigs : levelsigs COMMA levelsig'\n        p[0] = p[1] + (p[3],)\n        p.set_lineno(0, p.lineno(1))", "response": "levelsigs : levelsigs COMMA levelsig"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_sens_all(self, p):\n        'senslist : AT TIMES'\n        p[0] = SensList(\n            (Sens(None, 'all', lineno=p.lineno(1)),), lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "SensList : AT TIMES"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_sens_all_paren(self, p):\n        'senslist : AT LPAREN TIMES RPAREN'\n        p[0] = SensList(\n            (Sens(None, 'all', lineno=p.lineno(1)),), lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "SensList : AT LPAREN TIMES RPAREN"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_blocking_substitution(self, p):\n        'blocking_substitution : delays lvalue EQUALS delays rvalue SEMICOLON'\n        p[0] = BlockingSubstitution(p[2], p[5], p[1], p[4], lineno=p.lineno(2))\n        p.set_lineno(0, p.lineno(2))", "response": "\\ x1b [ 1mNAME \\ x1b [ 0m blocking_substitution - Adds a blocking substitution to the beginning of the line."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_blocking_substitution_base(self, p):\n        'blocking_substitution_base : delays lvalue EQUALS delays rvalue'\n        p[0] = BlockingSubstitution(p[2], p[5], p[1], p[4], lineno=p.lineno(2))\n        p.set_lineno(0, p.lineno(2))", "response": "blocking_substitution_base : delays lvalue EQUALS delays rvalue"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_delays(self, p):\n        'delays : DELAY LPAREN expression RPAREN'\n        p[0] = DelayStatement(p[3], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "P - DELAY LPAREN expression RPAREN"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelay : DELAY identifier", "response": "def p_delays_identifier(self, p):\n        'delays : DELAY identifier'\n        p[0] = DelayStatement(p[2], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndelaying : DELAY intnumber", "response": "def p_delays_intnumber(self, p):\n        'delays : DELAY intnumber'\n        p[0] = DelayStatement(\n            IntConst(p[2], lineno=p.lineno(1)), lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_delays_floatnumber(self, p):\n        'delays : DELAY floatnumber'\n        p[0] = DelayStatement(FloatConst(\n            p[2], lineno=p.lineno(1)), lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "delays : DELAY floatnumber"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_block(self, p):\n        'block : BEGIN block_statements END'\n        p[0] = Block(p[2], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "block : BEGIN block_statements END"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nblocking : BEGIN END", "response": "def p_block_empty(self, p):\n        'block : BEGIN END'\n        p[0] = Block((), lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_block_statements(self, p):\n        'block_statements : block_statements block_statement'\n        p[0] = p[1] + (p[2],)\n        p.set_lineno(0, p.lineno(1))", "response": "block_statements : block_statements block_statement"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_namedblock_empty(self, p):\n        'namedblock : BEGIN COLON ID END'\n        p[0] = Block((), p[3], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "BEGIN COLON ID END namedblock"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_namedblock_statement(self, p):\n        if isinstance(p[1], Decl):\n            for r in p[1].list:\n                if (not isinstance(r, Reg) and not isinstance(r, Wire)\n                    and not isinstance(r, Integer) and not isinstance(r, Real)\n                        and not isinstance(r, Parameter) and not isinstance(r, Localparam)):\n                    raise ParseError(\"Syntax Error\")\n        p[0] = p[1]\n        p.set_lineno(0, p.lineno(1))", "response": "Parse a namedblock statement."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_parallelblock(self, p):\n        'parallelblock : FORK block_statements JOIN'\n        p[0] = ParallelBlock(p[2], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "parallelblock : FORK block_statements JOIN"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_if_statement(self, p):\n        'if_statement : IF LPAREN cond RPAREN true_statement ELSE else_statement'\n        p[0] = IfStatement(p[3], p[5], p[7], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "if_statement : IF LPAREN cond RPAREN true_statement ELSE else_statement"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_if_statement_woelse(self, p):\n        'if_statement : IF LPAREN cond RPAREN true_statement'\n        p[0] = IfStatement(p[3], p[5], None, lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "if_statement : IF LPAREN cond RPAREN true_statement"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_if_statement_delay(self, p):\n        'if_statement : delays IF LPAREN cond RPAREN true_statement ELSE else_statement'\n        p[0] = IfStatement(p[4], p[6], p[8], lineno=p.lineno(2))\n        p.set_lineno(0, p.lineno(2))", "response": "if_statement delays IF LPAREN cond RPAREN true_statement ELSE else_statement"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef p_if_statement_woelse_delay(self, p):\n        'if_statement : delays IF LPAREN cond RPAREN true_statement'\n        p[0] = IfStatement(p[4], p[6], None, lineno=p.lineno(2))\n        p.set_lineno(0, p.lineno(2))", "response": "if_statement : delays IF LPAREN cond RPAREN true_statement"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_while_statement(self, p):\n        'while_statement : WHILE LPAREN cond RPAREN whilecontent_statement'\n        p[0] = WhileStatement(p[3], p[5], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "while_statement : WHILE LPAREN cond RPAREN whilecontent_statement"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_case_statement(self, p):\n        'case_statement : CASE LPAREN case_comp RPAREN casecontent_statements ENDCASE'\n        p[0] = CaseStatement(p[3], p[5], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "CASE LPAREN case_comp RPAREN casecontent_statements ENDCASE"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing UNIQUE CASE LPAREN case_comp RPAREN casecontent_statements ENDCASE", "response": "def p_unique_case_statement(self, p):\n        'unique_case_statement : UNIQUE CASE LPAREN case_comp RPAREN casecontent_statements ENDCASE'\n        p[0] = UniqueCaseStatement(p[3], p[5], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_casecontent_statement(self, p):\n        'casecontent_statement : casecontent_condition COLON basic_statement'\n        p[0] = Case(p[1], p[3], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "CASE content_statement : casecontent_condition COLON basic_statement"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_casecontent_statement_default(self, p):\n        'casecontent_statement : DEFAULT COLON basic_statement'\n        p[0] = Case(None, p[3], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "CASE content_statement : DEFAULT COLON basic_statement"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_initial(self, p):\n        'initial : INITIAL initial_statement'\n        p[0] = Initial(p[2], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "initial : INITIAL initial_statement"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_event_statement(self, p):\n        'event_statement : senslist SEMICOLON'\n        p[0] = EventStatement(p[1], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "event_statement : senslist SEMICOLON"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef p_wait_statement(self, p):\n        'wait_statement : WAIT LPAREN cond RPAREN waitcontent_statement'\n        p[0] = WaitStatement(p[3], p[5], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "parse WAIT LPAREN cond RPAREN waitcontent_statement"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_forever_statement(self, p):\n        'forever_statement : FOREVER basic_statement'\n        p[0] = ForeverStatement(p[2], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "forever_statement : FOREVER basic_statement"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninstances : SENS_OR parameterlist instance_bodylist SEMICOLON", "response": "def p_instance_or(self, p):\n        'instance : SENS_OR parameterlist instance_bodylist SEMICOLON'\n        instancelist = []\n        for instance_name, instance_ports, instance_array in p[3]:\n            instancelist.append(Instance(p[1], instance_name, instance_ports,\n                                         p[2], instance_array, lineno=p.lineno(1)))\n        p[0] = InstanceList(p[1], p[2], tuple(\n            instancelist), lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_instance_body(self, p):\n        'instance_body : ID LPAREN instance_ports RPAREN'\n        p[0] = (p[1], p[3], None)\n        p.set_lineno(0, p.lineno(1))", "response": "instance_body : ID LPAREN instance_ports RPAREN"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef p_param_args(self, p):\n        'param_args : param_args COMMA param_arg'\n        p[0] = p[1] + (p[3],)\n        p.set_lineno(0, p.lineno(1))", "response": "param_args : param_args COMMA param_arg"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_instance_ports_arg(self, p):\n        'instance_ports_arg : instance_ports_arg COMMA instance_port_arg'\n        p[0] = p[1] + (p[3],)\n        p.set_lineno(0, p.lineno(1))", "response": "instance_ports_arg : instance_ports_arg COMMA instance_port_arg"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_instance_port_arg_none(self, p):\n        'instance_port_arg : DOT ID LPAREN RPAREN'\n        p[0] = PortArg(p[2], None, lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "instance_port_arg | instance_port_arg | instance_port_arg | instance_port_arg | None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse the genvarlist COMMA genvar", "response": "def p_genvarlist(self, p):\n        'genvarlist : genvarlist COMMA genvar'\n        p[0] = p[1] + (p[3],)\n        p.set_lineno(0, p.lineno(1))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate : GENERATE generate_items ENDGENERATE", "response": "def p_generate(self, p):\n        'generate : GENERATE generate_items ENDGENERATE'\n        p[0] = GenerateStatement(p[2], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_generate_if_woelse(self, p):\n        'generate_if : IF LPAREN cond RPAREN gif_true_item'\n        p[0] = IfStatement(p[3], p[5], None, lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "generate_if : IF LPAREN cond RPAREN gif_true_item"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_generate_for(self, p):\n        'generate_for : FOR LPAREN forpre forcond forpost RPAREN generate_forcontent'\n        p[0] = ForStatement(p[3], p[4], p[5], p[7], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "\\ x1b [ 1mNAME \\ x1b [ 0m generate_for - Creates a ForStatement object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef p_systemcall_noargs(self, p):\n        'systemcall : DOLLER ID'\n        p[0] = SystemCall(p[2], (), lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "systemcall : DOLLER ID"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_systemcall(self, p):\n        'systemcall : DOLLER ID LPAREN sysargs RPAREN'\n        p[0] = SystemCall(p[2], p[4], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "SystemCall | SystemCall sysargs | SystemCall | SystemCall sysargs RPAREN | SystemCall sysargs LPAREN sysargs RPAREN"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef p_systemcall_signed(self, p):  # for $signed system task\n        'systemcall : DOLLER SIGNED LPAREN sysargs RPAREN'\n        p[0] = SystemCall(p[2], p[4], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "DOLLER SIGNED LPAREN sysargs RPAREN"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_sysargs(self, p):\n        'sysargs : sysargs COMMA sysarg'\n        p[0] = p[1] + (p[3],)\n        p.set_lineno(0, p.lineno(1))", "response": "sysargs : sysargs COMMA sysarg"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_function(self, p):\n        'function : FUNCTION width ID SEMICOLON function_statement ENDFUNCTION'\n        p[0] = Function(p[3], p[2], p[5], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "FUNCTION width ID SEMICOLON function_statement ENDFUNCTION"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfunctioning : FUNCTION ID SEMICOLON function_statement ENDFUNCTION", "response": "def p_function_nowidth(self, p):\n        'function : FUNCTION ID SEMICOLON function_statement ENDFUNCTION'\n        p[0] = Function(p[2],\n                        Width(IntConst('0', lineno=p.lineno(1)),\n                              IntConst('0', lineno=p.lineno(1)),\n                              lineno=p.lineno(1)),\n                        p[4], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_function_statement(self, p):\n        'function_statement : funcvardecls function_calc'\n        p[0] = p[1] + (p[2],)\n        p.set_lineno(0, p.lineno(1))", "response": "function_statement : funcvardecls function_calc"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_funcvardecls(self, p):\n        'funcvardecls : funcvardecls funcvardecl'\n        p[0] = p[1] + (p[2],)\n        p.set_lineno(0, p.lineno(1))", "response": "funcvardecls : funcvardecls funcvardecl"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_funcvardecl(self, p):\n        if isinstance(p[1], Decl):\n            for r in p[1].list:\n                if (not isinstance(r, Input) and not isinstance(r, Reg)\n                        and not isinstance(r, Integer)):\n                    raise ParseError(\"Syntax Error\")\n        p[0] = p[1]\n        p.set_lineno(0, p.lineno(1))", "response": "funcvardecl : decl\n        | integerdecl"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_functioncall(self, p):\n        'functioncall : identifier LPAREN func_args RPAREN'\n        p[0] = FunctionCall(p[1], p[3], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "functioncall : identifier LPAREN func_args RPAREN"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_func_args(self, p):\n        'func_args : func_args COMMA expression'\n        p[0] = p[1] + (p[3],)\n        p.set_lineno(0, p.lineno(1))", "response": "func_args : func_args COMMA expression"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntasking : TASK ID SEMICOLON task_statement ENDTASK", "response": "def p_task(self, p):\n        'task : TASK ID SEMICOLON task_statement ENDTASK'\n        p[0] = Task(p[2], p[4], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_taskvardecls(self, p):\n        'taskvardecls : taskvardecls taskvardecl'\n        p[0] = p[1] + (p[2],)\n        p.set_lineno(0, p.lineno(1))", "response": "taskvardecls : taskvardecls taskvardecl"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nidentifies | identifier | identifier | identifier | identifier | identifier | identifier | identifier | identifier | identifier | identifier | identifier | lineno | identifier | identifier | identifier | identifier | identifier | identifier | identifier | identifier | identifier | identifier |", "response": "def p_identifier(self, p):\n        'identifier : ID'\n        p[0] = Identifier(p[1], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_scope_identifier(self, p):\n        'identifier : scope ID'\n        p[0] = Identifier(p[2], p[1], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "Identifier | scope ID | identifier | lineno | scope ID"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_scope(self, p):\n        'scope : identifier DOT'\n        scope = () if p[1].scope is None else p[1].scope.labellist\n        p[0] = IdentifierScope(\n            scope + (IdentifierScopeLabel(p[1].name, lineno=p.lineno(1)),), lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "scope : identifier DOT"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_scope_pointer(self, p):\n        'scope : pointer DOT'\n        scope = () if p[1].var.scope is None else p[1].var.scope.labellist\n        p[0] = IdentifierScope(scope + (IdentifierScopeLabel(p[1].var.name,\n                                                             p[1].ptr, lineno=p.lineno(1)),), lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "scope : pointer DOT"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_disable(self, p):\n        'disable : DISABLE ID'\n        p[0] = Disable(p[2], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "disable : DISABLE ID"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_single_statement_systemcall(self, p):\n        'single_statement : systemcall SEMICOLON'\n        p[0] = SingleStatement(p[1], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "Systemcall SEMICOLON | |"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_single_statement_disable(self, p):\n        'single_statement : disable SEMICOLON'\n        p[0] = SingleStatement(p[1], lineno=p.lineno(1))\n        p.set_lineno(0, p.lineno(1))", "response": "single_statement : disable SEMICOLON"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn extra information about histogram", "response": "def histogram_info(self) -> dict:\n        \"\"\" Return extra information about histogram \"\"\"\n        return {\n            'support_atoms': self.support_atoms,\n            'atom_delta': self.atom_delta,\n            'vmin': self.vmin,\n            'vmax': self.vmax,\n            'num_atoms': self.atoms\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsamples from a greedy strategy with given q - value histogram", "response": "def sample(self, histogram_logits):\n        \"\"\" Sample from a greedy strategy with given q-value histogram \"\"\"\n        histogram_probs = histogram_logits.exp()  # Batch size * actions * atoms\n        atoms = self.support_atoms.view(1, 1, self.atoms)  # Need to introduce two new dimensions\n        return (histogram_probs * atoms).sum(dim=-1).argmax(dim=1)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create(input_width, input_height, input_channels=1, output_dim=512, initial_std_dev=0.4, factorized_noise=True):\n    def instantiate(**_):\n        return DoubleNoisyNatureCnn(\n            input_width=input_width, input_height=input_height, input_channels=input_channels,\n            output_dim=output_dim, initial_std_dev=initial_std_dev, factorized_noise=factorized_noise\n        )\n\n    return ModelFactory.generic(instantiate)", "response": "Create a new double noisy nature cnn."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef value(self):\n        if self.buffer:\n            return np.quantile(self.buffer, self.quantile)\n        else:\n            return 0.0", "response": "Return the current value for the metric"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the current value for the metric", "response": "def value(self):\n        \"\"\" Return current value for the metric \"\"\"\n        if self.buffer:\n            return np.mean([ep['l'] for ep in self.buffer])\n        else:\n            return 0"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sample_forward_transitions(self, batch_size, batch_info, forward_steps: int,\n                                   discount_factor: float) -> Transitions:\n        \"\"\"\n        Sample transitions from replay buffer with _forward steps_.\n        That is, instead of getting a transition s_t -> s_t+1 with reward r,\n        get a transition s_t -> s_t+n with sum of intermediate rewards.\n\n        Used in a variant of Deep Q-Learning\n        \"\"\"\n        raise NotImplementedError", "response": "Sample the forward transitions from the replay buffer with _forward steps _."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create(model_config, url, local_dir, sequence_length=64, batch_size=64, train_val_split=0.8):\n    if not os.path.isabs(local_dir):\n        local_dir = model_config.project_data_dir(local_dir)\n\n    return TextUrlSource(\n        url,\n        absolute_data_path=local_dir,\n        sequence_length=sequence_length,\n        batch_size=batch_size,\n        train_val_split=train_val_split,\n    )", "response": "Create a new base class for the current language."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndownloading the data file and store it in the processed_path.", "response": "def download(self):\n        \"\"\" Make sure data file is downloaded and stored properly \"\"\"\n        if not os.path.exists(self.data_path):\n            # Create if it doesn't exist\n            pathlib.Path(self.data_path).mkdir(parents=True, exist_ok=True)\n\n        if not os.path.exists(self.text_path):\n            http = urllib3.PoolManager(cert_reqs='CERT_REQUIRED', ca_certs=certifi.where())\n\n            with open(self.text_path, 'wt') as fp:\n                request = http.request('GET', self.url)\n                content = request.data.decode('utf8')\n                fp.write(content)\n\n        if not os.path.exists(self.processed_path):\n            with open(self.text_path, 'rt') as fp:\n                content = fp.read()\n\n            alphabet = sorted(set(content))\n\n            index_to_character = {idx: c for idx, c in enumerate(alphabet, 1)}\n            character_to_index = {c: idx for idx, c in enumerate(alphabet, 1)}\n\n            content_encoded = np.array([character_to_index[c] for c in content], dtype=np.uint8)\n\n            data_dict = {\n                'alphabet': alphabet,\n                'index_to_character': index_to_character,\n                'character_to_index': character_to_index,\n                'content_encoded': content_encoded\n            }\n\n            with open(self.processed_path, 'wb') as fp:\n                torch.save(data_dict, fp)\n        else:\n            with open(self.processed_path, 'rb') as fp:\n                data_dict = torch.load(fp)\n\n        return data_dict"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating how much variance in returns do the values explain", "response": "def explained_variance(returns, values):\n    \"\"\" Calculate how much variance in returns do the values explain \"\"\"\n    exp_var = 1 - torch.var(returns - values) / torch.var(returns)\n    return exp_var.item()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates an ImageDirSource with supplied arguments", "response": "def create(model_config, path, num_workers, batch_size, augmentations=None, tta=None):\n    \"\"\" Create an ImageDirSource with supplied arguments \"\"\"\n    if not os.path.isabs(path):\n        path = model_config.project_top_dir(path)\n\n    train_path = os.path.join(path, 'train')\n    valid_path = os.path.join(path, 'valid')\n\n    train_ds = ImageDirSource(train_path)\n    val_ds = ImageDirSource(valid_path)\n\n    return TrainingData(\n        train_ds,\n        val_ds,\n        num_workers=num_workers,\n        batch_size=batch_size,\n        augmentations=augmentations,\n        # test_time_augmentation=tta\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a multilayer rnn sequence classification model.", "response": "def create(input_block: ModelFactory, rnn_type: str, output_dim: int,\n           rnn_layers: typing.List[int], rnn_dropout: float=0.0, bidirectional: bool=False,\n           linear_layers: typing.List[int]=None, linear_dropout: float=0.0):\n    \"\"\" Vel factory function \"\"\"\n    if linear_layers is None:\n        linear_layers = []\n\n    def instantiate(**_):\n        return MultilayerRnnSequenceClassification(\n            input_block=input_block.instantiate(), rnn_type=rnn_type, output_dim=output_dim,\n            rnn_layers=rnn_layers, rnn_dropout=rnn_dropout, bidirectional=bidirectional,\n            linear_layers=linear_layers, linear_dropout=linear_dropout\n        )\n\n    return ModelFactory.generic(instantiate)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef forward(self, sequence):\n        data = self.input_block(sequence)\n\n        for idx in range(len(self.rnn_layers)):\n            data, _ = self.rnn_layers[idx](data)\n\n            if self.rnn_dropout_layers:\n                data = self.rnn_dropout_layers[idx](data)\n\n        # We are interested only in the last element of the sequence\n        if self.bidirectional:\n            last_hidden_size = self.rnn_layers_sizes[-1]\n            data = torch.cat([data[:, -1, :last_hidden_size], data[:, 0, last_hidden_size:]], dim=1)\n        else:\n            data = data[:, -1]\n\n        for idx in range(len(self.linear_layers_sizes)):\n            data = F.relu(self.linear_layers[idx](data))\n\n            if self.linear_dropout_layers:\n                data = self.linear_dropout_layers[idx](data)\n\n        data = self.output_layer(data)\n\n        return self.output_activation(data)", "response": "Forward propagate batch of sequences through the network without accounting for the state"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create(backbone: ModelFactory, input_block: typing.Optional[ModelFactory]=None):\n    if input_block is None:\n        input_block = IdentityFactory()\n\n    return QModelFactory(input_block=input_block, backbone=backbone)", "response": "Create a new QModelFactory instance"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef model_action_q(self):\n        q = self.get('model:q')\n        actions = self.get('rollout:actions')\n        return q.gather(1, actions.unsqueeze(1)).squeeze(1)", "response": "Get the model action values for selected actions in the rollout"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninitializing weights to reasonable defaults", "response": "def reset_weights(self):\n        \"\"\" Initialize weights to reasonable defaults \"\"\"\n        self.input_block.reset_weights()\n        self.backbone.reset_weights()\n        self.q_head.reset_weights()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_params(img, output_size):\n        w, h, *_ = img.shape\n\n        th, tw = output_size\n        if w == tw and h == th:\n            return 0, 0, h, w\n\n        i = random.randint(0, h - th)\n        j = random.randint(0, w - tw)\n        return i, j, th, tw", "response": "Get parameters for a random crop."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef resolve_parameters(self, func, extra_env=None):\n        parameter_list = [\n            (k, v.default == inspect.Parameter.empty) for k, v in inspect.signature(func).parameters.items()\n        ]\n        extra_env = extra_env if extra_env is not None else {}\n        kwargs = {}\n\n        for parameter_name, is_required in parameter_list:\n            # extra_env is a 'local' object data defined in-place\n            if parameter_name in extra_env:\n                kwargs[parameter_name] = self.instantiate_from_data(extra_env[parameter_name])\n                continue\n\n            if parameter_name in self.instances:\n                kwargs[parameter_name] = self.instances[parameter_name]\n                continue\n\n            if parameter_name in self.environment:\n                kwargs[parameter_name] = self.instantiate_by_name(parameter_name)\n                continue\n\n            if is_required:\n                funcname = f\"{inspect.getmodule(func).__name__}.{func.__name__}\"\n                raise RuntimeError(\"Required argument '{}' cannot be resolved for function '{}'\".format(\n                    parameter_name, funcname\n                ))\n\n        return kwargs", "response": "Resolve parameter dictionary for the supplied function"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef resolve_and_call(self, func, extra_env=None):\n        kwargs = self.resolve_parameters(func, extra_env=extra_env)\n        return func(**kwargs)", "response": "Resolve function arguments and call them possibily filling from the environment"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrenders variables in configuration object but don t instantiate anything", "response": "def render_configuration(self, configuration=None):\n        \"\"\" Render variables in configuration object but don't instantiate anything \"\"\"\n        if configuration is None:\n            configuration = self.environment\n\n        if isinstance(configuration, dict):\n            return {k: self.render_configuration(v) for k, v in configuration.items()}\n        elif isinstance(configuration, list):\n            return [self.render_configuration(x) for x in configuration]\n        elif isinstance(configuration, Variable):\n            return configuration.resolve(self.parameters)\n        else:\n            return configuration"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new nature cnn.", "response": "def create(input_width, input_height, input_channels=1, output_dim=512):\n    \"\"\" Vel factory function \"\"\"\n    def instantiate(**_):\n        return NatureCnn(\n            input_width=input_width, input_height=input_height, input_channels=input_channels,\n            output_dim=output_dim\n        )\n\n    return ModelFactory.generic(instantiate)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a new MLP object.", "response": "def create(input_length, hidden_layers, activation='tanh', normalization=None):\n    \"\"\" Vel factory function \"\"\"\n    def instantiate(**_):\n        return MLP(\n            input_length=input_length,\n            hidden_layers=hidden_layers,\n            activation=activation,\n            normalization=normalization\n        )\n\n    return ModelFactory.generic(instantiate)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new PPOPolicyGradient object.", "response": "def create(entropy_coefficient, value_coefficient, cliprange, max_grad_norm, discount_factor,\n           normalize_advantage=True, gae_lambda=1.0):\n    \"\"\" Vel factory function \"\"\"\n    return PpoPolicyGradient(\n        entropy_coefficient, value_coefficient, cliprange, max_grad_norm,\n        discount_factor=discount_factor,\n        normalize_advantage=normalize_advantage,\n        gae_lambda=gae_lambda\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef calculate_gradient(self, batch_info, device, model, rollout):\n        evaluator = model.evaluate(rollout)\n\n        # Part 0.0 - Rollout values\n        advantages = evaluator.get('rollout:advantages')\n        rollout_values = evaluator.get('rollout:values')\n        rollout_action_logprobs = evaluator.get('rollout:action:logprobs')\n        returns = evaluator.get('rollout:returns')\n\n        # PART 0.1 - Model evaluation\n        entropy = evaluator.get('model:entropy')\n        model_values = evaluator.get('model:values')\n        model_action_logprobs = evaluator.get('model:action:logprobs')\n\n        # Select the cliprange\n        current_cliprange = self.cliprange.value(batch_info['progress'])\n\n        # Normalize the advantages?\n        if self.normalize_advantage:\n            advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)\n\n        # PART 1 - policy entropy\n        policy_entropy = torch.mean(entropy)\n\n        # PART 2 - value function\n        value_output_clipped = rollout_values + torch.clamp(\n            model_values - rollout_values, -current_cliprange, current_cliprange\n        )\n        value_loss_part1 = (model_values - returns).pow(2)\n        value_loss_part2 = (value_output_clipped - returns).pow(2)\n        value_loss = 0.5 * torch.mean(torch.max(value_loss_part1, value_loss_part2))\n\n        # PART 3 - policy gradient loss\n        ratio = torch.exp(model_action_logprobs - rollout_action_logprobs)\n\n        pg_loss_part1 = -advantages * ratio\n        pg_loss_part2 = -advantages * torch.clamp(ratio, 1.0 - current_cliprange, 1.0 + current_cliprange)\n        policy_loss = torch.mean(torch.max(pg_loss_part1, pg_loss_part2))\n\n        loss_value = (\n            policy_loss - self.entropy_coefficient * policy_entropy + self.value_coefficient * value_loss\n        )\n\n        loss_value.backward()\n\n        with torch.no_grad():\n            approx_kl_divergence = 0.5 * torch.mean((model_action_logprobs - rollout_action_logprobs).pow(2))\n            clip_fraction = torch.mean((torch.abs(ratio - 1.0) > current_cliprange).to(dtype=torch.float))\n\n        return {\n            'policy_loss': policy_loss.item(),\n            'value_loss': value_loss.item(),\n            'policy_entropy': policy_entropy.item(),\n            'approx_kl_divergence': approx_kl_divergence.item(),\n            'clip_fraction': clip_fraction.item(),\n            'advantage_norm': torch.norm(advantages).item(),\n            'explained_variance': explained_variance(returns, rollout_values)\n        }", "response": "Calculate the gradient of the given rollout"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of metrics that can be used to track this learning process.", "response": "def metrics(self) -> list:\n        \"\"\" List of metrics to track for this learning process \"\"\"\n        return [\n            AveragingNamedMetric(\"policy_loss\"),\n            AveragingNamedMetric(\"value_loss\"),\n            AveragingNamedMetric(\"policy_entropy\"),\n            AveragingNamedMetric(\"approx_kl_divergence\"),\n            AveragingNamedMetric(\"clip_fraction\"),\n            AveragingNamedMetric(\"grad_norm\"),\n            AveragingNamedMetric(\"advantage_norm\"),\n            AveragingNamedMetric(\"explained_variance\")\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create(img_rows, img_cols, img_channels, num_classes):\n    def instantiate(**_):\n        return Net(img_rows, img_cols, img_channels, num_classes)\n    return ModelFactory.generic(instantiate)", "response": "Create a vel factory function"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if evaluator provides given value", "response": "def is_provided(self, name):\n        \"\"\" Capability check if evaluator provides given value \"\"\"\n        if name in self._storage:\n            return True\n        elif name in self._providers:\n            return True\n        elif name.startswith('rollout:'):\n            rollout_name = name[8:]\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(self, name):\n        if name in self._storage:\n            return self._storage[name]\n        elif name in self._providers:\n            value = self._storage[name] = self._providers[name](self)\n            return value\n        elif name.startswith('rollout:'):\n            rollout_name = name[8:]\n            value = self._storage[name] = self.rollout.batch_tensor(rollout_name)\n            return value\n        else:\n            raise RuntimeError(f\"Key {name} is not provided by this evaluator\")", "response": "Get a value from this evaluator."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a double nature cnn.", "response": "def create(input_width, input_height, input_channels=1):\n    \"\"\" Vel factory function \"\"\"\n    def instantiate(**_):\n        return DoubleNatureCnn(input_width=input_width, input_height=input_height, input_channels=input_channels)\n\n    return ModelFactory.generic(instantiate)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create(model_config, batch_size, normalize=True, num_workers=0, augmentations=None):\n    path = model_config.data_dir('mnist')\n\n    train_dataset = datasets.MNIST(path, train=True, download=True)\n    test_dataset = datasets.MNIST(path, train=False, download=True)\n\n    augmentations = [ToArray()] + (augmentations if augmentations is not None else [])\n\n    if normalize:\n        train_data = train_dataset.train_data\n        mean_value = (train_data.double() / 255).mean().item()\n        std_value = (train_data.double() / 255).std().item()\n\n        augmentations.append(Normalize(mean=mean_value, std=std_value, tags=['train', 'val']))\n\n    augmentations.append(ToTensor())\n\n    return TrainingData(\n        train_dataset,\n        test_dataset,\n        num_workers=num_workers,\n        batch_size=batch_size,\n        augmentations=augmentations\n    )", "response": "Create a TrainingData object with the given model config."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a new QStochasticPolicyModelFactory instance.", "response": "def create(backbone: ModelFactory, input_block: typing.Optional[ModelFactory]=None):\n    \"\"\" Vel factory function \"\"\"\n    if input_block is None:\n        input_block = IdentityFactory()\n\n    return QStochasticPolicyModelFactory(input_block=input_block, backbone=backbone)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef step(self, observation, argmax_sampling=False):\n        policy_params, q = self(observation)\n        actions = self.action_head.sample(policy_params, argmax_sampling=argmax_sampling)\n\n        # log probability - we can do that, because we support only discrete action spaces\n        logprobs = self.action_head.logprob(actions, policy_params)\n\n        return {\n            'actions': actions,\n            'q': q,\n            'logprobs': policy_params,\n            'action:logprobs': logprobs\n        }", "response": "Select actions based on model s output"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating only value head for given state", "response": "def value(self, observation):\n        \"\"\" Calculate only value head for given state \"\"\"\n        policy_params, q = self(observation)\n\n        # Expectation of Q value with respect to action\n        return (torch.exp(policy_params) * q).sum(dim=1)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new ClassicStorage object.", "response": "def create(model_config, backend, checkpoint_strategy, streaming=None):\n    \"\"\" Vel factory function \"\"\"\n    return ClassicStorage(\n        model_config=model_config,\n        backend=backend,\n        checkpoint_strategy=checkpoint_strategy,\n        streaming=streaming\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreset the current configuration and store it in the backend.", "response": "def reset(self, configuration: dict) -> None:\n        \"\"\"\n        Whenever there was anything stored in the database or not, purge previous state and start\n        new training process from scratch.\n        \"\"\"\n        self.clean(0)\n        self.backend.store_config(configuration)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nresuming learning process and return loaded model state dictionary and hidden state dictionary", "response": "def load(self, train_info: TrainingInfo) -> (dict, dict):\n        \"\"\"\n        Resume learning process and return loaded hidden state dictionary\n        \"\"\"\n        last_epoch = train_info.start_epoch_idx\n\n        model_state = torch.load(self.checkpoint_filename(last_epoch))\n        hidden_state = torch.load(self.checkpoint_hidden_filename(last_epoch))\n\n        self.checkpoint_strategy.restore(hidden_state)\n        train_info.restore(hidden_state)\n\n        return model_state, hidden_state"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _persisted_last_epoch(self) -> int:\n        epoch_number = 0\n        self._make_sure_dir_exists()\n\n        for x in os.listdir(self.model_config.checkpoint_dir()):\n            match = re.match('checkpoint_(\\\\d+)\\\\.data', x)\n            if match:\n                idx = int(match[1])\n\n                if idx > epoch_number:\n                    epoch_number = idx\n\n        return epoch_number", "response": "Return number of last epoch already calculated"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _make_sure_dir_exists(self):\n        filename = self.model_config.checkpoint_dir()\n        pathlib.Path(filename).mkdir(parents=True, exist_ok=True)", "response": "Make sure the checkpoint directory exists"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nclipping gradients to a given maximum length", "response": "def clip_gradients(batch_result, model, max_grad_norm):\n    \"\"\" Clip gradients to a given maximum length \"\"\"\n    if max_grad_norm is not None:\n        grad_norm = torch.nn.utils.clip_grad_norm_(\n            filter(lambda p: p.requires_grad, model.parameters()),\n            max_norm=max_grad_norm\n        )\n    else:\n        grad_norm = 0.0\n\n    batch_result['grad_norm'] = grad_norm"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsingling optimization step for a model", "response": "def optimizer_step(self, batch_info, device, model, rollout):\n        \"\"\" Single optimization step for a model \"\"\"\n        batch_info.optimizer.zero_grad()\n\n        batch_result = self.calculate_gradient(batch_info=batch_info, device=device, model=model, rollout=rollout)\n\n        clip_gradients(batch_result, model, self.max_grad_norm)\n\n        batch_info.optimizer.step(closure=None)\n\n        self.post_optimization_step(batch_info, device, model, rollout)\n\n        return batch_result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new CircularReplayBufferFactory object.", "response": "def create(buffer_capacity: int, buffer_initial_size: int, frame_stack_compensation: bool = False,\n           frame_history: int = 1):\n    \"\"\" Vel factory function \"\"\"\n    return CircularReplayBufferFactory(\n        buffer_capacity=buffer_capacity,\n        buffer_initial_size=buffer_initial_size,\n        frame_stack_compensation=frame_stack_compensation,\n        frame_history=frame_history\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a batch of transition tensors with given indexes", "response": "def _get_transitions(self, indexes):\n        \"\"\" Return batch with given indexes \"\"\"\n        transition_tensors = self.backend.get_transitions(indexes)\n\n        return Trajectories(\n            num_steps=indexes.shape[0],\n            num_envs=indexes.shape[1],\n            environment_information=None,\n            transition_tensors=transition_tensors,\n            rollout_tensors={}\n        ).to_transitions()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sample_trajectories(self, rollout_length, batch_info) -> Trajectories:\n        indexes = self.backend.sample_batch_trajectories(rollout_length)\n        transition_tensors = self.backend.get_trajectories(indexes, rollout_length)\n\n        return Trajectories(\n            num_steps=rollout_length,\n            num_envs=self.backend.num_envs,\n            environment_information=None,\n            transition_tensors={k: torch.from_numpy(v) for k, v in transition_tensors.items()},\n            rollout_tensors={}\n        )", "response": "Sample a batch of trajectories and return them"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sample_transitions(self, batch_size, batch_info, discount_factor=None) -> Transitions:\n        indexes = self.backend.sample_batch_transitions(batch_size)\n        transition_tensors = self.backend.get_transitions(indexes)\n\n        return Trajectories(\n            num_steps=batch_size,\n            num_envs=self.backend.num_envs,\n            environment_information=None,\n            transition_tensors={k: torch.from_numpy(v) for k, v in transition_tensors.items()},\n            rollout_tensors={}\n        ).to_transitions()", "response": "Sample batch of transitions and return them"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sample_forward_transitions(self, batch_size, batch_info, forward_steps: int,\n                                   discount_factor: float) -> Transitions:\n        \"\"\"\n        Sample transitions from replay buffer with _forward steps_.\n        That is, instead of getting a transition s_t -> s_t+1 with reward r,\n        get a transition s_t -> s_t+n with sum of intermediate rewards.\n\n        Used in a variant of Deep Q-Learning\n        \"\"\"\n        indexes = self.backend.sample_batch_transitions(batch_size, forward_steps=forward_steps)\n        transition_tensors = self.backend.get_transitions_forward_steps(\n            indexes, forward_steps=forward_steps, discount_factor=discount_factor\n        )\n\n        return Trajectories(\n            num_steps=batch_size,\n            num_envs=self.backend.num_envs,\n            environment_information=None,\n            transition_tensors={k: torch.from_numpy(v) for k, v in transition_tensors.items()},\n            rollout_tensors={},\n            extra_data={\n                'forward_steps': forward_steps\n            }\n        ).to_transitions()", "response": "Sample the forward steps of the current state of the current state of the current state of the current state of the current state."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef store_transition(self, frame, action, reward, done, extra_info=None):\n        self.backend.store_transition(frame=frame, action=action, reward=reward, done=done, extra_info=extra_info)", "response": "Store given transition in the backend"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create(model_config, model, vec_env, storage, fps=30.0, sample_args=None):\n    return EnjoyCommand(\n        model_config, model, vec_env, storage, float(fps), sample_args\n    )", "response": "Create a new enjoy command."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef optimizer_step(self, batch_info, device, model, rollout):\n        rollout = rollout.to_transitions()\n\n        # This algorithm makes quote strong assumptions about how does the model look\n        # so it does not make that much sense to switch to the evaluator interface\n        # As it would be more of a problem than actual benefit\n\n        observations = rollout.batch_tensor('observations')\n        returns = rollout.batch_tensor('returns')\n\n        # Evaluate model on the observations\n        policy_params = model.policy(observations)\n        policy_entropy = torch.mean(model.entropy(policy_params))\n\n        policy_loss = self.calc_policy_loss(model, policy_params, policy_entropy, rollout)\n        policy_grad = p2v(autograd.grad(policy_loss, model.policy_parameters(), retain_graph=True)).detach()\n\n        # Calculate gradient of KL divergence of model with fixed version of itself\n        # Value of kl_divergence will be 0, but what we need is the gradient, actually the 2nd derivarive\n        kl_divergence = torch.mean(model.kl_divergence(policy_params.detach(), policy_params))\n        kl_divergence_gradient = p2v(torch.autograd.grad(kl_divergence, model.policy_parameters(), create_graph=True))\n\n        step_direction = conjugate_gradient_method(\n            matrix_vector_operator=lambda x: self.fisher_vector_product(x, kl_divergence_gradient, model),\n            # Because we want to decrease the loss, we want to go into the direction of -gradient\n            loss_gradient=-policy_grad,\n            nsteps=self.cg_iters\n        )\n\n        shs = 0.5 * step_direction @ self.fisher_vector_product(step_direction, kl_divergence_gradient, model)\n        lm = torch.sqrt(shs / self.mak_kl)\n        full_step = step_direction / lm\n\n        # Because we want to decrease the loss, we want to go into the direction of -gradient\n        expected_improvement = (-policy_grad) @ full_step\n        original_parameter_vec = p2v(model.policy_parameters()).detach_()\n\n        policy_optimization_success, ratio, policy_loss_improvement, new_policy_loss, kl_divergence_step = self.line_search(\n            model, rollout, policy_loss, policy_params, original_parameter_vec, full_step, expected_improvement\n        )\n\n        gradient_norms = []\n\n        for i in range(self.vf_iters):\n            batch_info.optimizer.zero_grad()\n            value_loss = self.value_loss(model, observations, returns)\n\n            value_loss.backward()\n\n            # Gradient clipping\n            if self.max_grad_norm is not None:\n                grad_norm = torch.nn.utils.clip_grad_norm_(\n                    filter(lambda p: p.requires_grad, model.parameters()),\n                    max_norm=self.max_grad_norm\n                )\n\n                gradient_norms.append(grad_norm)\n\n            batch_info.optimizer.step(closure=None)\n\n        if gradient_norms:\n            gradient_norm = np.mean(gradient_norms)\n        else:\n            gradient_norm = 0.0\n\n        # noinspection PyUnboundLocalVariable\n        return {\n            'new_policy_loss': new_policy_loss.item(),\n            'policy_entropy': policy_entropy.item(),\n            'value_loss': value_loss.item(),\n            'policy_optimization_success': float(policy_optimization_success),\n            'policy_improvement_ratio': ratio.item(),\n            'kl_divergence_step': kl_divergence_step.item(),\n            'policy_loss_improvement': policy_loss_improvement.item(),\n            'grad_norm': gradient_norm,\n            'advantage_norm': torch.norm(rollout.batch_tensor('advantages')).item(),\n            'explained_variance': explained_variance(returns, rollout.batch_tensor('values'))\n        }", "response": "This function is called by the optimizer to calculate the model and the model s model parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds the right stepsize to make sure policy improves", "response": "def line_search(self, model, rollout, original_policy_loss, original_policy_params, original_parameter_vec,\n                    full_step, expected_improvement_full):\n        \"\"\" Find the right stepsize to make sure policy improves \"\"\"\n        current_parameter_vec = original_parameter_vec.clone()\n\n        for idx in range(self.line_search_iters):\n            stepsize = 0.5 ** idx\n\n            new_parameter_vec = current_parameter_vec + stepsize * full_step\n\n            # Update model parameters\n            v2p(new_parameter_vec, model.policy_parameters())\n\n            # Calculate new loss\n            with torch.no_grad():\n                policy_params = model.policy(rollout.batch_tensor('observations'))\n                policy_entropy = torch.mean(model.entropy(policy_params))\n                kl_divergence = torch.mean(model.kl_divergence(original_policy_params, policy_params))\n\n                new_loss = self.calc_policy_loss(model, policy_params, policy_entropy, rollout)\n\n                actual_improvement = original_policy_loss - new_loss\n                expected_improvement = expected_improvement_full * stepsize\n\n                ratio = actual_improvement / expected_improvement\n\n            if kl_divergence.item() > self.mak_kl * 1.5:\n                # KL divergence bound exceeded\n                continue\n            elif ratio < expected_improvement:\n                # Not enough loss improvement\n                continue\n            else:\n                # Optimization successful\n                return True, ratio, actual_improvement, new_loss, kl_divergence\n\n        # Optimization failed, revert to initial parameters\n        v2p(original_parameter_vec, model.policy_parameters())\n        return False, torch.tensor(0.0), torch.tensor(0.0), torch.tensor(0.0), torch.tensor(0.0)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fisher_vector_product(self, vector, kl_divergence_gradient, model):\n        assert not vector.requires_grad, \"Vector must not propagate gradient\"\n        dot_product = vector @ kl_divergence_gradient\n\n        # at least one dimension spans across two contiguous subspaces\n        double_gradient = torch.autograd.grad(dot_product, model.policy_parameters(), retain_graph=True)\n        fvp = p2v(x.contiguous() for x in double_gradient)\n\n        return fvp + vector * self.cg_damping", "response": "Calculate product Hessian for a given vector and gradient"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates the policy gradient loss for the current cluster.", "response": "def calc_policy_loss(self, model, policy_params, policy_entropy, rollout):\n        \"\"\"\n        Policy gradient loss - calculate from probability distribution\n\n        Calculate surrogate loss - advantage * policy_probability / fixed_initial_policy_probability\n\n        Because we operate with logarithm of -probability (neglogp) we do\n        - advantage * exp(fixed_neglogps - model_neglogps)\n        \"\"\"\n        actions = rollout.batch_tensor('actions')\n        advantages = rollout.batch_tensor('advantages')\n        fixed_logprobs = rollout.batch_tensor('action:logprobs')\n\n        model_logprobs = model.logprob(actions, policy_params)\n\n        # Normalize advantages\n        advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)\n\n        # We put - in front because we want to maximize the surrogate objective\n        policy_loss = -advantages * torch.exp(model_logprobs - fixed_logprobs)\n\n        return policy_loss.mean() - policy_entropy * self.entropy_coef"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create(model_config, model, vec_env, storage, takes, parallel_envs, action_noise=None, sample_args=None):\n    return EvaluateEnvCommand(\n        model_config=model_config,\n        model_factory=model,\n        env_factory=vec_env,\n        parallel_envs=parallel_envs,\n        action_noise=action_noise,\n        storage=storage,\n        takes=takes,\n        sample_args=sample_args\n    )", "response": "Create a new EvalEnvCommand instance."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef shuffled_batches(self, batch_size):\n        if batch_size >= self.size:\n            yield self\n        else:\n            batch_splits = math_util.divide_ceiling(self.size, batch_size)\n            indices = list(range(self.size))\n            np.random.shuffle(indices)\n\n            for sub_indices in np.array_split(indices, batch_splits):\n                yield Transitions(\n                    size=len(sub_indices),\n                    environment_information=None,\n                    # Dont use it in batches for a moment, can be uncommented later if needed\n                    # environment_information=[info[sub_indices.tolist()] for info in self.environment_information]\n                    transition_tensors={k: v[sub_indices] for k, v in self.transition_tensors.items()}\n                    # extra_data does not go into batches\n                )", "response": "Generates randomized batches of data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmoving a rollout to a selected device", "response": "def to_device(self, device, non_blocking=True):\n        \"\"\" Move a rollout to a selected device \"\"\"\n        return Transitions(\n            size=self.size,\n            environment_information=self.environment_information,\n            transition_tensors={k: v.to(device, non_blocking=non_blocking) for k, v in self.transition_tensors.items()},\n            extra_data=self.extra_data\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert the given rollout to a list of Transitions.", "response": "def to_transitions(self) -> 'Transitions':\n        \"\"\" Convert given rollout to Transitions \"\"\"\n        # No need to propagate 'rollout_tensors' as they won't mean anything\n        return Transitions(\n            size=self.num_steps * self.num_envs,\n            environment_information=\n                [ei for l in self.environment_information for ei in l]\n                if self.environment_information is not None else None,\n            transition_tensors={\n                name: tensor_util.merge_first_two_dims(t) for name, t in self.transition_tensors.items()\n            },\n            extra_data=self.extra_data\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef shuffled_batches(self, batch_size):\n        if batch_size >= self.num_envs * self.num_steps:\n            yield self\n        else:\n            rollouts_in_batch = batch_size // self.num_steps\n\n            batch_splits = math_util.divide_ceiling(self.num_envs, rollouts_in_batch)\n\n            indices = list(range(self.num_envs))\n            np.random.shuffle(indices)\n\n            for sub_indices in np.array_split(indices, batch_splits):\n                yield Trajectories(\n                    num_steps=self.num_steps,\n                    num_envs=len(sub_indices),\n                    # Dont use it in batches for a moment, can be uncommented later if needed\n                    # environment_information=[x[sub_indices.tolist()] for x in self.environment_information],\n                    environment_information=None,\n                    transition_tensors={k: x[:, sub_indices] for k, x in self.transition_tensors.items()},\n                    rollout_tensors={k: x[sub_indices] for k, x in self.rollout_tensors.items()},\n                    # extra_data does not go into batches\n                )", "response": "Generates randomized batches of data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef batch_tensor(self, name):\n        if name in self.transition_tensors:\n            return tensor_util.merge_first_two_dims(self.transition_tensors[name])\n        else:\n            return self.rollout_tensors[name]", "response": "A batch tensor of a given name in a flat format."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef episode_information(self):\n        return [\n            info.get('episode') for infolist in self.environment_information for info in infolist if 'episode' in info\n        ]", "response": "Return a list of information about finished episodes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmoving a rollout to a selected device", "response": "def to_device(self, device, non_blocking=True):\n        \"\"\" Move a rollout to a selected device \"\"\"\n        return Trajectories(\n            num_steps=self.num_steps,\n            num_envs=self.num_envs,\n            environment_information=self.environment_information,\n            transition_tensors={k: v.to(device, non_blocking=non_blocking) for k, v in self.transition_tensors.items()},\n            rollout_tensors={k: v.to(device, non_blocking=non_blocking) for k, v in self.rollout_tensors.items()},\n            extra_data=self.extra_data\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a multilayer rnn sequence model.", "response": "def create(input_block: ModelFactory, rnn_type: str, hidden_layers: typing.List[int],\n           output_dim: int, dropout=0.0):\n    \"\"\" Vel factory function \"\"\"\n    def instantiate(**_):\n        return MultilayerRnnSequenceModel(\n            input_block.instantiate(), rnn_type=rnn_type, hidden_layers=hidden_layers, output_dim=output_dim, dropout=dropout\n        )\n\n    return ModelFactory.generic(instantiate)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef forward(self, sequence):\n        data = self.input_block(sequence)\n\n        for idx in range(len(self.recurrent_layers)):\n            data, _ = self.recurrent_layers[idx](data)\n\n            if self.dropout_layers:\n                data = self.dropout_layers[idx](data)\n\n        data = self.output_layer(data)\n\n        return self.output_activation(data)", "response": "Forward propagate batch of sequences through the network without accounting for the state of the state"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nforwarding propagate a sequence through the network accounting for the state", "response": "def forward_state(self, sequence, state=None):\n        \"\"\" Forward propagate a sequence through the network accounting for the state \"\"\"\n        if state is None:\n            state = self.zero_state(sequence.size(0))\n\n        data = self.input_block(sequence)\n\n        state_outputs = []\n\n        # for layer_length, layer in zip(self.hidden_layers, self.recurrent_layers):\n        for idx in range(len(self.recurrent_layers)):\n            layer_length = self.recurrent_layers[idx].state_dim\n\n            # Partition hidden state, for each layer we have layer_length of h state and layer_length of c state\n            current_state = state[:, :, :layer_length]\n            state = state[:, :, layer_length:]\n\n            # Propagate through the GRU state\n            data, new_h = self.recurrent_layers[idx](data, current_state)\n\n            if self.dropout_layers:\n                data = self.dropout_layers[idx](data)\n\n            state_outputs.append(new_h)\n\n        output_data = self.output_activation(self.output_layer(data))\n\n        concatenated_hidden_output = torch.cat(state_outputs, dim=2)\n\n        return output_data, concatenated_hidden_output"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate a value of loss function", "response": "def loss_value(self, x_data, y_true, y_pred):\n        \"\"\" Calculate a value of loss function \"\"\"\n        y_pred = y_pred.view(-1, y_pred.size(2))\n        y_true = y_true.view(-1).to(torch.long)\n        return F.nll_loss(y_pred, y_true)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run_epoch(self, epoch_info: EpochInfo, source: 'vel.api.Source'):\n        epoch_info.on_epoch_begin()\n\n        lr = epoch_info.optimizer.param_groups[-1]['lr']\n        print(\"|-------- Epoch {:06} Lr={:.6f} ----------|\".format(epoch_info.global_epoch_idx, lr))\n\n        self.train_epoch(epoch_info, source)\n        epoch_info.result_accumulator.freeze_results('train')\n\n        self.validation_epoch(epoch_info, source)\n        epoch_info.result_accumulator.freeze_results('val')\n\n        epoch_info.on_epoch_end()", "response": "Run full epoch of learning"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef train_epoch(self, epoch_info, source: 'vel.api.Source', interactive=True):\n        self.train()\n\n        if interactive:\n            iterator = tqdm.tqdm(source.train_loader(), desc=\"Training\", unit=\"iter\", file=sys.stdout)\n        else:\n            iterator = source.train_loader()\n\n        for batch_idx, (data, target) in enumerate(iterator):\n            batch_info = BatchInfo(epoch_info, batch_idx)\n\n            batch_info.on_batch_begin()\n            self.train_batch(batch_info, data, target)\n            batch_info.on_batch_end()\n\n            iterator.set_postfix(loss=epoch_info.result_accumulator.intermediate_value('loss'))", "response": "Run a single training epoch"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrun a single evaluation epoch", "response": "def validation_epoch(self, epoch_info, source: 'vel.api.Source'):\n        \"\"\" Run a single evaluation epoch \"\"\"\n        self.eval()\n\n        iterator = tqdm.tqdm(source.val_loader(), desc=\"Validation\", unit=\"iter\", file=sys.stdout)\n\n        with torch.no_grad():\n            for batch_idx, (data, target) in enumerate(iterator):\n                batch_info = BatchInfo(epoch_info, batch_idx)\n\n                batch_info.on_validation_batch_begin()\n                self.feed_batch(batch_info, data, target)\n                batch_info.on_validation_batch_end()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrun a single batch of data and store the results in batch_info.", "response": "def feed_batch(self, batch_info, data, target):\n        \"\"\" Run single batch of data \"\"\"\n        data, target = data.to(self.device), target.to(self.device)\n        output, loss = self.model.loss(data, target)\n\n        # Store extra batch information for calculation of the statistics\n        batch_info['data'] = data\n        batch_info['target'] = target\n        batch_info['output'] = output\n        batch_info['loss'] = loss\n\n        return loss"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef train_batch(self, batch_info, data, target):\n        batch_info.optimizer.zero_grad()\n        loss = self.feed_batch(batch_info, data, target)\n        loss.backward()\n\n        if self.max_grad_norm is not None:\n            batch_info['grad_norm'] = torch.nn.utils.clip_grad_norm_(\n                filter(lambda p: p.requires_grad, self.model.parameters()),\n                max_norm=self.max_grad_norm\n            )\n\n        batch_info.optimizer.step()", "response": "Train a single batch of data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef divide_ceiling(numerator, denominator):\n    split_val = numerator // denominator\n    rest = numerator % denominator\n\n    if rest > 0:\n        return split_val + 1\n    else:\n        return split_val", "response": "Divide a number by a denominator"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef calculate(self, batch_info):\n        value = self._value_function(batch_info['data'], batch_info['target'], batch_info['output'])\n        self.storage.append(value)", "response": "Calculate the value of a metric"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef process_environment_settings(default_dictionary: dict, settings: typing.Optional[dict]=None,\n                                 presets: typing.Optional[dict]=None):\n    \"\"\" Process a dictionary of env settings \"\"\"\n    settings = settings if settings is not None else {}\n    presets = presets if presets is not None else {}\n\n    env_keys = sorted(set(default_dictionary.keys()) | set(presets.keys()))\n\n    result_dict = {}\n\n    for key in env_keys:\n        if key in default_dictionary:\n            new_dict = default_dictionary[key].copy()\n        else:\n            new_dict = {}\n\n        new_dict.update(settings)\n\n        if key in presets:\n            new_dict.update(presets[key])\n\n        result_dict[key] = new_dict\n\n    return result_dict", "response": "Process a dictionary of env settings"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create(model_config, vec_env, model, algo, env_roller, parallel_envs: int,\n           rollout_steps: int, training_steps: int, training_rounds: int=1):\n    \"\"\" Vel factory function \"\"\"\n    settings = BufferedOffPolicyIterationReinforcerSettings(\n        rollout_steps=rollout_steps,\n        training_steps=training_steps,\n        training_rounds=training_rounds\n    )\n\n    return BufferedOffPolicyIterationReinforcerFactory(\n        settings=settings,\n        env_factory=vec_env,\n        model_factory=model,\n        algo=algo,\n        env_roller_factory=env_roller,\n        parallel_envs=parallel_envs,\n        seed=model_config.seed\n    )", "response": "Create a new BufferedOffPolicyIterationReinforcerFactory instance."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of metrics to track for this learning process.", "response": "def metrics(self) -> list:\n        \"\"\" List of metrics to track for this learning process \"\"\"\n        my_metrics = [\n            FramesMetric(\"frames\"),\n            FPSMetric(\"fps\"),\n            EpisodeRewardMetric('PMM:episode_rewards'),\n            EpisodeRewardMetricQuantile('P09:episode_rewards', quantile=0.9),\n            EpisodeRewardMetricQuantile('P01:episode_rewards', quantile=0.1),\n            EpisodeLengthMetric(\"episode_length\")\n        ]\n\n        return my_metrics + self.algo.metrics() + self.env_roller.metrics()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef train_batch(self, batch_info: BatchInfo) -> None:\n        # For each reinforcer batch:\n\n        # 1. Roll out environment and store out experience in the buffer\n        self.roll_out_and_store(batch_info)\n\n        # 2. Sample the buffer and train the algo on sample batch\n        self.train_on_replay_memory(batch_info)", "response": "Train the reinforforcer on the given batch."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrolling out environment and store result in the replay buffer", "response": "def roll_out_and_store(self, batch_info):\n        \"\"\" Roll out environment and store result in the replay buffer \"\"\"\n        self.model.train()\n\n        if self.env_roller.is_ready_for_sampling():\n            rollout = self.env_roller.rollout(batch_info, self.model, self.settings.rollout_steps).to_device(self.device)\n\n            # Store some information about the rollout, no training phase\n            batch_info['frames'] = rollout.frames()\n            batch_info['episode_infos'] = rollout.episode_information()\n        else:\n            frames = 0\n            episode_infos = []\n\n            with tqdm.tqdm(desc=\"Populating memory\", total=self.env_roller.initial_memory_size_hint()) as pbar:\n                while not self.env_roller.is_ready_for_sampling():\n                    rollout = self.env_roller.rollout(batch_info, self.model, self.settings.rollout_steps).to_device(self.device)\n\n                    new_frames = rollout.frames()\n                    frames += new_frames\n                    episode_infos.extend(rollout.episode_information())\n\n                    pbar.update(new_frames)\n\n            # Store some information about the rollout, no training phase\n            batch_info['frames'] = frames\n            batch_info['episode_infos'] = episode_infos"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntrain agent on a replay buffer.", "response": "def train_on_replay_memory(self, batch_info):\n        \"\"\" Train agent on a memory gotten from replay buffer \"\"\"\n        self.model.train()\n\n        # Algo will aggregate data into this list:\n        batch_info['sub_batch_data'] = []\n\n        for i in range(self.settings.training_rounds):\n            sampled_rollout = self.env_roller.sample(batch_info, self.model, self.settings.training_steps)\n\n            batch_result = self.algo.optimizer_step(\n                batch_info=batch_info,\n                device=self.device,\n                model=self.model,\n                rollout=sampled_rollout.to_device(self.device)\n            )\n\n            self.env_roller.update(rollout=sampled_rollout, batch_info=batch_result)\n\n            batch_info['sub_batch_data'].append(batch_result)\n\n        batch_info.aggregate_key('sub_batch_data')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef conv3x3(in_channels, out_channels, stride=1):\n    return nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)", "response": "3x3 convolution with padding.\n    Original code has had bias turned off, because Batch Norm would remove the bias either way"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create(backbone: ModelFactory, vmin: float, vmax: float, atoms: int,\n           input_block: typing.Optional[ModelFactory]=None):\n    \"\"\" Vel factory function \"\"\"\n    if input_block is None:\n        input_block = IdentityFactory()\n\n    return QDistributionalModelFactory(\n        input_block=input_block, backbone=backbone,\n        vmin=vmin,\n        vmax=vmax,\n        atoms=atoms\n    )", "response": "Create a new QDistributionalModelFactory object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef model_action_q_dist(self):\n        q = self.get('model:q_dist')\n        actions = self.get('rollout:actions')\n        return q[range(q.size(0)), actions]", "response": "Get the Q - Dist of selected actions in the rollout"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsampling an action from an action space for given state", "response": "def step(self, observations):\n        \"\"\" Sample action from an action space for given state \"\"\"\n        log_histogram = self(observations)\n        actions = self.q_head.sample(log_histogram)\n\n        return {\n            'actions': actions,\n            'log_histogram': log_histogram\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a QDistributionalModelFactory object", "response": "def create(backbone: ModelFactory, vmin: float, vmax: float, atoms: int, initial_std_dev: float = 0.4,\n           factorized_noise: bool = True, input_block: typing.Optional[ModelFactory] = None):\n    \"\"\" Vel factory function \"\"\"\n    if input_block is None:\n        input_block = IdentityFactory()\n\n    return QDistributionalModelFactory(\n        input_block=input_block, backbone=backbone,\n        vmin=vmin,\n        vmax=vmax,\n        atoms=atoms,\n        initial_std_dev=initial_std_dev,\n        factorized_noise=factorized_noise\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading a ModelConfig from a file.", "response": "def load(config_path, run_number=0, device='cuda:0'):\n    \"\"\" Load a ModelConfig from filename \"\"\"\n    model_config = ModelConfig.from_file(config_path, run_number, device=device)\n\n    return model_config"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the environment rollout", "response": "def rollout(self, batch_info: BatchInfo, model: RlModel, number_of_steps: int) -> Rollout:\n        \"\"\" Calculate env rollout \"\"\"\n        assert not model.is_recurrent, \"Replay env roller does not support recurrent models\"\n\n        accumulator = TensorAccumulator()\n        episode_information = []  # List of dictionaries with episode information\n\n        for step_idx in range(number_of_steps):\n            step = model.step(self.last_observation)\n\n            replay_extra_information = {}\n\n            accumulator.add('observations', self.last_observation_cpu)\n\n            # Add step to the tensor accumulator\n            for name, tensor in step.items():\n                tensor_cpu = tensor.cpu()\n                accumulator.add(name, tensor_cpu)\n\n                if name != 'actions':\n                    replay_extra_information[name] = tensor_cpu.numpy()\n\n            actions_numpy = step['actions'].detach().cpu().numpy()\n            new_obs, new_rewards, new_dones, new_infos = self.environment.step(actions_numpy)\n\n            # Store rollout in the experience replay buffer\n            self.replay_buffer.store_transition(\n                frame=self.last_observation_cpu.numpy(),\n                action=actions_numpy,\n                reward=new_rewards,\n                done=new_dones,\n                extra_info=replay_extra_information\n            )\n\n            # Done is flagged true when the episode has ended AND the frame we see is already a first frame from the\n            # next episode\n\n            dones_tensor = torch.from_numpy(new_dones.astype(np.float32)).clone()\n            accumulator.add('dones', dones_tensor)\n\n            self.last_observation_cpu = torch.from_numpy(new_obs).clone()\n            self.last_observation = self.last_observation_cpu.to(self.device)\n            accumulator.add('rewards', torch.from_numpy(new_rewards.astype(np.float32)).clone())\n\n            episode_information.append(new_infos)\n\n        accumulated_tensors = accumulator.result()\n\n        return Trajectories(\n            num_steps=accumulated_tensors['observations'].size(0),\n            num_envs=accumulated_tensors['observations'].size(1),\n            environment_information=episode_information,\n            transition_tensors=accumulated_tensors,\n            rollout_tensors={\n                'final_values': model.value(self.last_observation).cpu()\n            }\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsample an experience from the replay buffer and return a batch", "response": "def sample(self, batch_info: BatchInfo, model: RlModel, number_of_steps: int) -> Rollout:\n        \"\"\" Sample experience from replay buffer and return a batch \"\"\"\n        # Sample trajectories\n        rollout = self.replay_buffer.sample_trajectories(rollout_length=number_of_steps, batch_info=batch_info)\n\n        last_observations = rollout.transition_tensors['observations_next'][-1].to(self.device)\n        final_values = model.value(last_observations).cpu()\n\n        # Add 'final_values' to the rollout\n        rollout.rollout_tensors['final_values'] = final_values\n\n        return rollout"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rollout(self, batch_info: BatchInfo, model: Model, number_of_steps: int) -> Rollout:\n        accumulator = TensorAccumulator()\n        episode_information = []  # List of dictionaries with episode information\n\n        if self.hidden_state is None and model.is_recurrent:\n            self.hidden_state = model.zero_state(self.last_observation.size(0)).to(self.device)\n\n        # Remember rollout initial state, we'll use that for training as well\n        initial_hidden_state = self.hidden_state\n\n        for step_idx in range(number_of_steps):\n            if model.is_recurrent:\n                step = model.step(self.last_observation.to(self.device), state=self.hidden_state)\n                self.hidden_state = step['state']\n            else:\n                step = model.step(self.last_observation.to(self.device))\n\n            # Add step to the tensor accumulator\n            for name, tensor in step.items():\n                accumulator.add(name, tensor.cpu())\n\n            accumulator.add('observations', self.last_observation)\n\n            actions_numpy = step['actions'].detach().cpu().numpy()\n            new_obs, new_rewards, new_dones, new_infos = self.environment.step(actions_numpy)\n\n            # Done is flagged true when the episode has ended AND the frame we see is already a first frame from the\n            # next episode\n            dones_tensor = torch.from_numpy(new_dones.astype(np.float32)).clone()\n            accumulator.add('dones', dones_tensor)\n\n            self.last_observation = torch.from_numpy(new_obs).clone()\n\n            if model.is_recurrent:\n                # Zero out state in environments that have finished\n                self.hidden_state = self.hidden_state * (1.0 - dones_tensor.unsqueeze(-1)).to(self.device)\n\n            accumulator.add('rewards', torch.from_numpy(new_rewards.astype(np.float32)).clone())\n\n            episode_information.append(new_infos)\n\n        if model.is_recurrent:\n            final_values = model.value(self.last_observation.to(self.device), state=self.hidden_state).cpu()\n        else:\n            final_values = model.value(self.last_observation.to(self.device)).cpu()\n\n        accumulated_tensors = accumulator.result()\n\n        return Trajectories(\n            num_steps=accumulated_tensors['observations'].size(0),\n            num_envs=accumulated_tensors['observations'].size(1),\n            environment_information=episode_information,\n            transition_tensors=accumulated_tensors,\n            rollout_tensors={\n                'initial_hidden_state': initial_hidden_state.cpu() if initial_hidden_state is not None else None,\n                'final_values': final_values\n            }\n        )", "response": "Calculate the env rollout for the current episode."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef restore(self, hidden_state):\n        for callback in self.callbacks:\n            callback.load_state_dict(self, hidden_state)\n\n        if 'optimizer' in hidden_state:\n            self.optimizer_initial_state = hidden_state['optimizer']", "response": "Restore any state from checkpoint"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an intermediate value of a metric", "response": "def intermediate_value(self, metric):\n        \"\"\" Return an intermediate (inter-epoch) value of a metric \"\"\"\n        if ':' in metric:\n            metric_name = metric.split(':')[-1]\n        else:\n            metric_name = metric\n\n        return self.metrics_by_name[metric_name].value()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef result(self):\n        final_result = {'epoch_idx': self.global_epoch_idx}\n\n        for key, value in self.frozen_results.items():\n            final_result[key] = value\n\n        return final_result", "response": "Return the epoch result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef state_dict(self) -> dict:\n        hidden_state = {}\n\n        if self.optimizer is not None:\n            hidden_state['optimizer'] = self.optimizer.state_dict()\n\n        for callback in self.callbacks:\n            callback.write_state_dict(self.training_info, hidden_state)\n\n        return hidden_state", "response": "Calculate hidden state dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef aggregate_key(self, aggregate_key):\n        aggregation = self.data_dict[aggregate_key]  # List of dictionaries of numpy arrays/scalars\n\n        # Aggregate sub batch data\n        data_dict_keys = {y for x in aggregation for y in x.keys()}\n\n        for key in data_dict_keys:\n            # Just average all the statistics from the loss function\n            stacked = np.stack([d[key] for d in aggregation], axis=0)\n            self.data_dict[key] = np.mean(stacked, axis=0)", "response": "Aggregate values from key and put them into the top - level dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new one - hot encoding input.", "response": "def create(alphabet_size: int):\n    \"\"\" Vel factory function \"\"\"\n    def instantiate(**_):\n        return OneHotEncodingInput(alphabet_size)\n\n    return ModelFactory.generic(instantiate)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new RlTrainCommand object.", "response": "def create(model_config, reinforcer, optimizer, storage, total_frames, batches_per_epoch,\n           callbacks=None, scheduler=None, openai_logging=False):\n    \"\"\" Vel factory function \"\"\"\n    from vel.openai.baselines import logger\n    logger.configure(dir=model_config.openai_dir())\n\n    return RlTrainCommand(\n        model_config=model_config,\n        reinforcer=reinforcer,\n        optimizer_factory=optimizer,\n        scheduler_factory=scheduler,\n        storage=storage,\n        callbacks=callbacks,\n        total_frames=int(float(total_frames)),\n        batches_per_epoch=int(batches_per_epoch),\n        openai_logging=openai_logging\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrun the reinforcement learning algorithm.", "response": "def run(self):\n        \"\"\" Run reinforcement learning algorithm \"\"\"\n        device = self.model_config.torch_device()\n\n        # Reinforcer is the learner for the reinforcement learning model\n        reinforcer = self.reinforcer.instantiate(device)\n        optimizer = self.optimizer_factory.instantiate(reinforcer.model)\n\n        # All callbacks used for learning\n        callbacks = self.gather_callbacks(optimizer)\n        # Metrics to track through this training\n        metrics = reinforcer.metrics()\n\n        training_info = self.resume_training(reinforcer, callbacks, metrics)\n\n        reinforcer.initialize_training(training_info)\n        training_info.on_train_begin()\n\n        if training_info.optimizer_initial_state:\n            optimizer.load_state_dict(training_info.optimizer_initial_state)\n\n        global_epoch_idx = training_info.start_epoch_idx + 1\n\n        while training_info['frames'] < self.total_frames:\n            epoch_info = EpochInfo(\n                training_info,\n                global_epoch_idx=global_epoch_idx,\n                batches_per_epoch=self.batches_per_epoch,\n                optimizer=optimizer,\n            )\n\n            reinforcer.train_epoch(epoch_info)\n\n            if self.openai_logging:\n                self._openai_logging(epoch_info.result)\n\n            self.storage.checkpoint(epoch_info, reinforcer.model)\n\n            global_epoch_idx += 1\n\n        training_info.on_train_end()\n\n        return training_info"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngathers all the callbacks used in this training run.", "response": "def gather_callbacks(self, optimizer) -> list:\n        \"\"\" Gather all the callbacks to be used in this training run \"\"\"\n        callbacks = [FrameTracker(self.total_frames), TimeTracker()]\n\n        if self.scheduler_factory is not None:\n            callbacks.append(self.scheduler_factory.instantiate(optimizer))\n\n        callbacks.extend(self.callbacks)\n        callbacks.extend(self.storage.streaming_callbacks())\n\n        return callbacks"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef resume_training(self, reinforcer, callbacks, metrics) -> TrainingInfo:\n        if self.model_config.continue_training:\n            start_epoch = self.storage.last_epoch_idx()\n        else:\n            start_epoch = 0\n\n        training_info = TrainingInfo(\n            start_epoch_idx=start_epoch,\n            run_name=self.model_config.run_name,\n            metrics=metrics, callbacks=callbacks\n        )\n\n        if start_epoch == 0:\n            self.storage.reset(self.model_config.render_configuration())\n            training_info.initialize()\n            reinforcer.initialize_training(training_info)\n        else:\n            model_state, hidden_state = self.storage.load(training_info)\n            reinforcer.initialize_training(training_info, model_state, hidden_state)\n\n        return training_info", "response": "Resume training from a saved state from the storage."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nuses OpenAI logging facilities for the same type of logging", "response": "def _openai_logging(self, epoch_result):\n        \"\"\" Use OpenAI logging facilities for the same type of logging \"\"\"\n        for key in sorted(epoch_result.keys()):\n            if key == 'fps':\n                # Not super elegant, but I like nicer display of FPS\n                openai_logger.record_tabular(key, int(epoch_result[key]))\n            else:\n                openai_logger.record_tabular(key, epoch_result[key])\n\n        openai_logger.dump_tabular()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalling given function in all submodules with given parameters", "response": "def module_broadcast(m, broadcast_fn, *args, **kwargs):\n    \"\"\" Call given function in all submodules with given parameters \"\"\"\n    apply_leaf(m, lambda x: module_apply_broadcast(x, broadcast_fn, args, kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef trainable_params_(m):\n    if isinstance(m, collections.Sequence):\n        return [p for p in m if p.requires_grad]\n    else:\n        return [p for p in m.parameters() if p.requires_grad]", "response": "Returns a list of trainable parameters in the model m."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create(backbone: ModelFactory, input_block: typing.Optional[ModelFactory]=None, initial_std_dev=0.4,\n           factorized_noise=True):\n    \"\"\" Vel factory function \"\"\"\n    if input_block is None:\n        input_block = IdentityFactory()\n\n    return NoisyQModelFactory(\n        input_block=input_block, backbone=backbone, initial_std_dev=initial_std_dev, factorized_noise=factorized_noise\n    )", "response": "Create a NoisyQModelFactory object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create(model_config, model, source, storage, phases, callbacks=None, restart=True):\n    return PhaseTrainCommand(\n        model_config=model_config,\n        model_factory=model,\n        source=source,\n        storage=storage,\n        phases=phases,\n        callbacks=callbacks,\n        restart=restart\n    )", "response": "Create a new PhaseTrainCommand object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nselecting the first phase that is not done after the given epoch number.", "response": "def _select_phase_left_bound(self, epoch_number):\n        \"\"\"\n        Return number of current phase.\n        Return index of first phase not done after all up to epoch_number were done.\n        \"\"\"\n        idx = bisect.bisect_left(self.ladder, epoch_number)\n\n        if idx >= len(self.ladder):\n            return len(self.ladder) - 1\n        elif self.ladder[idx] > epoch_number:\n            return idx - 1\n        else:\n            return idx"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning the command with supplied configuration", "response": "def run(self):\n        \"\"\" Run the command with supplied configuration \"\"\"\n        device = self.model_config.torch_device()\n        learner = Learner(device, self.model_factory.instantiate())\n\n        # All callbacks useful for learning\n        callbacks = self.gather_callbacks()\n\n        # Metrics to track through this training\n        metrics = learner.metrics()\n\n        # Check if training was already started and potentially continue where we left off\n        training_info, hidden_state = self.resume_training(learner, callbacks, metrics)\n\n        # Prepare current training phase\n        current_phase_idx = self._select_phase_left_bound(training_info.start_epoch_idx)\n        current_phase = self.phases[current_phase_idx]\n        local_idx = training_info.start_epoch_idx - self.ladder[current_phase_idx]\n\n        current_phase.set_up_phase(training_info, learner.model, self.source)\n        print(current_phase.banner())\n\n        if training_info.start_epoch_idx > 0:\n            current_phase.restore(training_info, local_idx, learner.model, hidden_state)\n\n        training_info.on_train_begin()\n\n        for global_epoch_idx in range(training_info.start_epoch_idx + 1, self.full_number_of_epochs + 1):\n            iteration_phase_idx = self._select_phase_right_bound(global_epoch_idx-1)\n            local_idx = global_epoch_idx - self.ladder[iteration_phase_idx]\n\n            # Phase preparations\n            while current_phase_idx != iteration_phase_idx:\n                current_phase.tear_down_phase(training_info, learner.model)\n\n                current_phase_idx += 1\n                current_phase = self.phases[current_phase_idx]\n\n                current_phase.set_up_phase(training_info, learner.model, self.source)\n                print(current_phase.banner())\n\n            # Create epoch info\n            epoch_info = current_phase.epoch_info(training_info, global_epoch_idx, local_idx)\n\n            # Execute learning\n            current_phase.execute_epoch(epoch_info, learner)\n\n            # Epoch checkpoint\n            self.storage.checkpoint(epoch_info, learner.model)\n\n        # Tear down the last phase\n        if current_phase is not None:\n            current_phase.tear_down_phase(training_info, learner.model)\n\n        training_info.on_train_end()\n\n        return training_info"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngather all the callbacks that are used in this training run.", "response": "def gather_callbacks(self) -> list:\n        \"\"\" Gather all the callbacks to be used in this training run \"\"\"\n        callbacks = []\n\n        callbacks.extend(self.callbacks)\n        callbacks.extend(self.storage.streaming_callbacks())\n\n        return callbacks"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites the sequence of args to the console and output files.", "response": "def log(*args, level=INFO):\n    \"\"\"\n    Write the sequence of args, with no separators, to the console and output files (if you've configured an output file).\n    \"\"\"\n    Logger.CURRENT.log(*args, level=level)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read_tb(path):\n    import pandas\n    import numpy as np\n    from glob import glob\n    from collections import defaultdict\n    import tensorflow as tf\n    if osp.isdir(path):\n        fnames = glob(osp.join(path, \"events.*\"))\n    elif osp.basename(path).startswith(\"events.\"):\n        fnames = [path]\n    else:\n        raise NotImplementedError(\"Expected tensorboard file or directory containing them. Got %s\"%path)\n    tag2pairs = defaultdict(list)\n    maxstep = 0\n    for fname in fnames:\n        for summary in tf.train.summary_iterator(fname):\n            if summary.step > 0:\n                for v in summary.summary.value:\n                    pair = (summary.step, v.simple_value)\n                    tag2pairs[v.tag].append(pair)\n                maxstep = max(summary.step, maxstep)\n    data = np.empty((maxstep, len(tag2pairs)))\n    data[:] = np.nan\n    tags = sorted(tag2pairs.keys())\n    for (colidx,tag) in enumerate(tags):\n        pairs = tag2pairs[tag]\n        for (step, value) in pairs:\n            data[step-1, colidx] = value\n    return pandas.DataFrame(data, columns=tags)", "response": "Reads a TB file or directory and returns a pandas. DataFrame with the TB tags as columns."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a relatively raw atari environment", "response": "def env_maker(environment_id):\n    \"\"\" Create a relatively raw atari environment \"\"\"\n    env = gym.make(environment_id)\n    assert 'NoFrameskip' in env.spec.id\n\n    # Wait for between 1 and 30 rounds doing nothing on start\n    env = NoopResetEnv(env, noop_max=30)\n\n    # Do the same action for k steps. Return max of last 2 frames. Return sum of rewards\n    env = MaxAndSkipEnv(env, skip=4)\n\n    return env"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate an environment that can be used to learn RL algorithms.", "response": "def wrapped_env_maker(environment_id, seed, serial_id, disable_reward_clipping=False, disable_episodic_life=False,\n                      monitor=False, allow_early_resets=False, scale_float_frames=False,\n                      max_episode_frames=10000, frame_stack=None):\n    \"\"\" Wrap atari environment so that it's nicer to learn RL algorithms \"\"\"\n    env = env_maker(environment_id)\n    env.seed(seed + serial_id)\n\n    if max_episode_frames is not None:\n        env = ClipEpisodeLengthWrapper(env, max_episode_length=max_episode_frames)\n\n    # Monitoring the env\n    if monitor:\n        logdir = logger.get_dir() and os.path.join(logger.get_dir(), str(serial_id))\n    else:\n        logdir = None\n\n    env = Monitor(env, logdir, allow_early_resets=allow_early_resets)\n\n    if not disable_episodic_life:\n        # Make end-of-life == end-of-episode, but only reset on true game over.\n        # Done by DeepMind for the DQN and co. since it helps value estimation.\n        env = EpisodicLifeEnv(env)\n\n    if 'FIRE' in env.unwrapped.get_action_meanings():\n        # Take action on reset for environments that are fixed until firing.\n        if disable_episodic_life:\n            env = FireEpisodicLifeEnv(env)\n        else:\n            env = FireResetEnv(env)\n\n    # Warp frames to 84x84 as done in the Nature paper and later work.\n    env = WarpFrame(env)\n\n    if scale_float_frames:\n        env = ScaledFloatFrame(env)\n\n    if not disable_reward_clipping:\n        # Bin reward to {+1, 0, -1} by its sign.\n        env = ClipRewardEnv(env)\n\n    if frame_stack is not None:\n        env = FrameStack(env, frame_stack)\n\n    return env"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmaking a single environment compatible with the experiments", "response": "def instantiate(self, seed=0, serial_id=0, preset='default', extra_args=None) -> gym.Env:\n        \"\"\" Make a single environment compatible with the experiments \"\"\"\n        settings = self.get_preset(preset)\n        return wrapped_env_maker(self.envname, seed, serial_id, **settings)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create(model_config, model, source, optimizer, start_lr=1e-5, end_lr=10, iterations=100, freeze=False,\n           interpolation='logscale', stop_dv=True, divergence_threshold=4.0, metric='loss'):\n    \"\"\" Vel factory function \"\"\"\n    return LrFindCommand(\n        model_config=model_config,\n        model=model,\n        source=source,\n        optimizer_factory=optimizer,\n        start_lr=start_lr,\n        end_lr=end_lr,\n        num_it=iterations,\n        interpolation=interpolation,\n        freeze=freeze,\n        stop_dv=stop_dv,\n        divergence_threshold=divergence_threshold,\n        metric=metric\n    )", "response": "Create a new LrFindCommand object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run(self):\n        device = self.model_config.torch_device()\n        learner = Learner(device, self.model.instantiate())\n\n        lr_schedule = interp.interpolate_series(self.start_lr, self.end_lr, self.num_it, self.interpolation)\n\n        if self.freeze:\n            learner.model.freeze()\n\n        # Optimizer shoudl be created after freeze\n        optimizer = self.optimizer_factory.instantiate(learner.model)\n\n        iterator = iter(self.source.train_loader())\n\n        # Metrics to track through this training\n        metrics = learner.metrics() + [AveragingNamedMetric(\"lr\")]\n\n        learner.train()\n\n        best_value = None\n\n        training_info = TrainingInfo(start_epoch_idx=0, metrics=metrics)\n\n        # Treat it all as one epoch\n        epoch_info = EpochInfo(\n            training_info, global_epoch_idx=1, batches_per_epoch=1, optimizer=optimizer\n        )\n\n        for iteration_idx, lr in enumerate(tqdm.tqdm(lr_schedule)):\n            batch_info = BatchInfo(epoch_info, iteration_idx)\n\n            # First, set the learning rate, the same for each parameter group\n            for param_group in optimizer.param_groups:\n                param_group['lr'] = lr\n\n            try:\n                data, target = next(iterator)\n            except StopIteration:\n                iterator = iter(self.source.train_loader())\n                data, target = next(iterator)\n\n            learner.train_batch(batch_info, data, target)\n\n            batch_info['lr'] = lr\n\n            # METRIC RECORDING PART\n            epoch_info.result_accumulator.calculate(batch_info)\n\n            current_value = epoch_info.result_accumulator.intermediate_value(self.metric)\n\n            final_metrics = {'epoch_idx': iteration_idx, self.metric: current_value, 'lr': lr}\n\n            if best_value is None or current_value < best_value:\n                best_value = current_value\n\n            # Stop on divergence\n            if self.stop_dv and (np.isnan(current_value) or current_value > best_value * self.divergence_threshold):\n                break\n\n            training_info.history.add(final_metrics)\n\n        frame = training_info.history.frame()\n\n        fig, ax = plt.subplots(1, 2)\n\n        ax[0].plot(frame.index, frame.lr)\n        ax[0].set_title(\"LR Schedule\")\n        ax[0].set_xlabel(\"Num iterations\")\n        ax[0].set_ylabel(\"Learning rate\")\n\n        if self.interpolation == 'logscale':\n            ax[0].set_yscale(\"log\", nonposy='clip')\n\n        ax[1].plot(frame.lr, frame[self.metric], label=self.metric)\n        # ax[1].plot(frame.lr, frame[self.metric].ewm(com=20).mean(), label=self.metric + ' smooth')\n        ax[1].set_title(self.metric)\n        ax[1].set_xlabel(\"Learning rate\")\n        ax[1].set_ylabel(self.metric)\n        # ax[1].legend()\n\n        if self.interpolation == 'logscale':\n            ax[1].set_xscale(\"log\", nonposx='clip')\n\n        plt.show()", "response": "Runs the command with supplied configuration"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend metrics to the visdom", "response": "def visdom_send_metrics(vis, metrics, update='replace'):\n    \"\"\" Send set of metrics to visdom \"\"\"\n    visited = {}\n\n    sorted_metrics = sorted(metrics.columns, key=_column_original_name)\n    for metric_basename, metric_list in it.groupby(sorted_metrics, key=_column_original_name):\n        metric_list = list(metric_list)\n\n        for metric in metric_list:\n            if vis.win_exists(metric_basename) and (not visited.get(metric, False)):\n                update = update\n            elif not vis.win_exists(metric_basename):\n                update = None\n            else:\n                update = 'append'\n\n            vis.line(\n                metrics[metric].values,\n                metrics.index.values,\n                win=metric_basename,\n                name=metric,\n                opts={\n                    'title': metric_basename,\n                    'showlegend': True\n                },\n                update=update\n            )\n\n            if metric_basename != metric and len(metric_list) > 1:\n                if vis.win_exists(metric):\n                    update = update\n                else:\n                    update = None\n\n                vis.line(\n                    metrics[metric].values,\n                    metrics.index.values,\n                    win=metric,\n                    name=metric,\n                    opts={\n                        'title': metric,\n                        'showlegend': True\n                    },\n                    update=update\n                )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrestore learning from intermediate state.", "response": "def restore(self, training_info: TrainingInfo, local_batch_idx: int, model: Model, hidden_state: dict):\n        \"\"\"\n        Restore learning from intermediate state.\n        \"\"\"\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef store_transition(self, frame, action, reward, done, extra_info=None):\n        self.current_idx = (self.current_idx + 1) % self.buffer_capacity\n\n        self.state_buffer[self.current_idx] = frame\n        self.action_buffer[self.current_idx] = action\n        self.reward_buffer[self.current_idx] = reward\n        self.dones_buffer[self.current_idx] = done\n\n        for name in self.extra_data:\n            self.extra_data[name][self.current_idx] = extra_info[name]\n\n        if self.current_size < self.buffer_capacity:\n            self.current_size += 1\n\n        return self.current_idx", "response": "Store a transition in the backend."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the frame from the buffer.", "response": "def get_frame(self, idx, history_length=1):\n        \"\"\" Return frame from the buffer \"\"\"\n        if idx >= self.current_size:\n            raise VelException(\"Requested frame beyond the size of the buffer\")\n\n        if history_length > 1:\n            assert self.state_buffer.shape[-1] == 1, \\\n                \"State buffer must have last dimension of 1 if we want frame history\"\n\n        accumulator = []\n\n        last_frame = self.state_buffer[idx]\n        accumulator.append(last_frame)\n\n        for i in range(history_length - 1):\n            prev_idx = (idx - 1) % self.buffer_capacity\n\n            if prev_idx == self.current_idx:\n                raise VelException(\"Cannot provide enough history for the frame\")\n            elif self.dones_buffer[prev_idx]:\n                # If previous frame was done - just append zeroes\n                accumulator.append(np.zeros_like(last_frame))\n            else:\n                idx = prev_idx\n                accumulator.append(self.state_buffer[idx])\n\n        # We're pushing the elements in reverse order\n        return np.concatenate(accumulator[::-1], axis=-1)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_frame_with_future(self, frame_idx, history_length=1):\n        if frame_idx == self.current_idx:\n            raise VelException(\"Cannot provide enough future for the frame\")\n\n        past_frame = self.get_frame(frame_idx, history_length)\n\n        if history_length > 1:\n            assert self.state_buffer.shape[-1] == 1, \\\n                \"State buffer must have last dimension of 1 if we want frame history\"\n\n        if not self.dones_buffer[frame_idx]:\n            next_idx = (frame_idx + 1) % self.buffer_capacity\n            next_frame = self.state_buffer[next_idx]\n        else:\n            next_idx = (frame_idx + 1) % self.buffer_capacity\n            next_frame = np.zeros_like(self.state_buffer[next_idx])\n\n        if history_length > 1:\n            future_frame = np.concatenate([\n                past_frame.take(indices=np.arange(1, past_frame.shape[-1]), axis=-1), next_frame\n            ], axis=-1)\n        else:\n            future_frame = next_frame\n\n        return past_frame, future_frame", "response": "Return frame from the buffer together with the next frame"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_transitions(self, indexes, history_length=1):\n        frame_batch_shape = (\n                [indexes.shape[0]]\n                + list(self.state_buffer.shape[1:-1])\n                + [self.state_buffer.shape[-1] * history_length]\n        )\n\n        past_frame_buffer = np.zeros(frame_batch_shape, dtype=self.state_buffer.dtype)\n        future_frame_buffer = np.zeros(frame_batch_shape, dtype=self.state_buffer.dtype)\n\n        for buffer_idx, frame_idx in enumerate(indexes):\n            past_frame_buffer[buffer_idx], future_frame_buffer[buffer_idx] = self.get_frame_with_future(\n                frame_idx, history_length\n            )\n\n        actions = self.action_buffer[indexes]\n        rewards = self.reward_buffer[indexes]\n        dones = self.dones_buffer[indexes]\n\n        data_dict = {\n            'observations': past_frame_buffer,\n            'actions': actions,\n            'rewards': rewards,\n            'observations_next': future_frame_buffer,\n            'dones': dones,\n        }\n\n        for name in self.extra_data:\n            data_dict[name] = self.extra_data[name][indexes]\n\n        return data_dict", "response": "Return a dictionary of state data for given indexes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a batch consisting of consecutive transitions", "response": "def get_trajectories(self, index, rollout_length, history_length):\n        \"\"\" Return batch consisting of *consecutive* transitions \"\"\"\n        indexes = np.arange(index - rollout_length + 1, index + 1, dtype=int)\n        return self.get_transitions(indexes, history_length)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sample_batch_transitions(self, batch_size, history_length):\n        # Sample from up to total size\n        if self.current_size < self.buffer_capacity:\n            # -1 because we cannot take the last one\n            return np.random.choice(self.current_size - 1, batch_size, replace=False)\n        else:\n            candidate = np.random.choice(self.buffer_capacity, batch_size, replace=False)\n\n            forbidden_ones = (\n                    np.arange(self.current_idx, self.current_idx + history_length)\n                    % self.buffer_capacity\n            )\n\n            # Exclude these frames for learning as they may have some part of history overwritten\n            while any(x in candidate for x in forbidden_ones):\n                candidate = np.random.choice(self.buffer_capacity, batch_size, replace=False)\n\n            return candidate", "response": "Sample from up to total size and return the indexes of next batch transition."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsamples from the buffer and return the next batch trajectories", "response": "def sample_batch_trajectories(self, rollout_length, history_length):\n        \"\"\" Return indexes of next sample \"\"\"\n        # Sample from up to total size\n        if self.current_size < self.buffer_capacity:\n            if rollout_length + 1 > self.current_size:\n                raise VelException(\"Not enough elements in the buffer to sample the rollout\")\n\n            # -1 because we cannot take the last one\n            return np.random.choice(self.current_size - rollout_length) + rollout_length - 1\n        else:\n            if rollout_length + history_length > self.current_size:\n                raise VelException(\"Not enough elements in the buffer to sample the rollout\")\n\n            candidate = np.random.choice(self.buffer_capacity)\n\n            # These are the elements we cannot draw, as then we don't have enough history\n            forbidden_ones = (\n                    np.arange(self.current_idx, self.current_idx + history_length + rollout_length - 1)\n                    % self.buffer_capacity\n            )\n\n            # Exclude these frames for learning as they may have some part of history overwritten\n            while candidate in forbidden_ones:\n                candidate = np.random.choice(self.buffer_capacity)\n\n            return candidate"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstores given transition in the backend.", "response": "def store_transition(self, frame, action, reward, done, extra_info=None):\n        \"\"\" Store given transition in the backend \"\"\"\n        self.deque.store_transition(frame, action, reward, done, extra_info=extra_info)\n\n        # We add element with max priority to all the trees\n        for segment_tree in self.segment_trees:\n            segment_tree.append(segment_tree.max)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the list of transition data for the given indexes and the given forward_steps.", "response": "def get_transitions_forward_steps(self, indexes, forward_steps, discount_factor):\n        \"\"\" Get dictionary of transition data \"\"\"\n        return self.deque.get_transitions_forward_steps(indexes, forward_steps, discount_factor)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the probability of the next sample of the next batch of transitions.", "response": "def sample_batch_transitions(self, batch_size, forward_steps=1):\n        \"\"\" Return indexes of next sample\"\"\"\n        batches = [\n            self._sample_batch_prioritized(\n                segment_tree, batch_size, self.deque.frame_history, forward_steps=forward_steps\n            )\n            for segment_tree in self.segment_trees\n        ]\n\n        probs, idxs, tree_idxs = zip(*batches)\n\n        return np.stack(probs, axis=1).astype(float), np.stack(idxs, axis=1), np.stack(tree_idxs, axis=1)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_priority(self, tree_idx_list, priority_list):\n        for tree_idx, priority, segment_tree in zip(tree_idx_list, priority_list, self.segment_trees):\n            segment_tree.update(tree_idx, priority)", "response": "Update the priorities of the elements in the tree."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the next batch of samples from the prioritized distribution.", "response": "def _sample_batch_prioritized(self, segment_tree, batch_size, history, forward_steps=1):\n        \"\"\" Return indexes of the next sample in from prioritized distribution \"\"\"\n        p_total = segment_tree.total()\n        segment = p_total / batch_size\n\n        # Get batch of valid samples\n        batch = [\n            self._get_sample_from_segment(segment_tree, segment, i, history, forward_steps)\n            for i in range(batch_size)\n        ]\n\n        probs, idxs, tree_idxs = zip(*batch)\n        return np.array(probs), np.array(idxs), np.array(tree_idxs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstores a given transition in the backend.", "response": "def store_transition(self, frame, action, reward, done, extra_info=None):\n        \"\"\" Store given transition in the backend \"\"\"\n        self.current_idx = (self.current_idx + 1) % self.buffer_capacity\n\n        if self.frame_stack_compensation:\n            # Compensate for frame stack built into the environment\n            idx_range = np.arange(-frame.shape[-1] // self.frame_history, 0)\n            frame = np.take(frame, indices=idx_range, axis=-1)\n\n        self.state_buffer[self.current_idx] = frame\n\n        self.action_buffer[self.current_idx] = action\n        self.reward_buffer[self.current_idx] = reward\n        self.dones_buffer[self.current_idx] = done\n\n        if extra_info is not None:\n            for name in extra_info:\n                if name not in self.extra_data:\n                    assert self.current_size == 0, f\"New data {name} encountered in the middle of the training\"\n                    array = extra_info[name]\n\n                    self.extra_data[name] = np.zeros([self.buffer_capacity] + list(array.shape), dtype=array.dtype)\n\n                self.extra_data[name][self.current_idx] = extra_info[name]\n\n        if self.current_size < self.buffer_capacity:\n            self.current_size += 1\n\n        return self.current_idx"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_frame_with_future(self, frame_idx, env_idx):\n        if frame_idx == self.current_idx:\n            raise VelException(\"Cannot provide enough future for the frame\")\n\n        past_frame = self.get_frame(frame_idx, env_idx)\n\n        if not self.dones_buffer[frame_idx, env_idx]:\n            # We're not done\n            next_idx = (frame_idx + 1) % self.buffer_capacity\n            next_frame = self.state_buffer[next_idx, env_idx]\n\n            if self.frame_history > 1:\n                future_frame = np.concatenate([\n                    past_frame.take(indices=np.arange(1, past_frame.shape[-1]), axis=-1), next_frame\n                ], axis=-1)\n            else:\n                future_frame = next_frame\n        else:\n            # We are done\n            future_frame = np.zeros_like(past_frame)\n\n        return past_frame, future_frame", "response": "Return frame from the buffer together with the next frame"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the frame from the buffer together with the next frame.", "response": "def get_frame_with_future_forward_steps(self, frame_idx, env_idx, forward_steps, discount_factor):\n        \"\"\" Return frame from the buffer together with the next frame \"\"\"\n        index_array = np.arange(frame_idx, frame_idx+forward_steps) % self.current_size\n\n        if self.current_idx in index_array:\n            raise VelException(\"Cannot provide enough future for the frame\")\n\n        past_frame = self.get_frame(frame_idx, env_idx)\n        dones_array = self.dones_buffer[index_array, env_idx]\n\n        rewards_array = self.reward_buffer[index_array, env_idx]\n        discounted_rewards_array = rewards_array * (discount_factor ** np.arange(forward_steps))\n\n        if dones_array.any():\n            # Are we done between current frame and frame + n\n            done = True\n\n            dones_shifted = np.zeros_like(dones_array)\n            dones_shifted[1:] = dones_array[:-1]\n            reward = discounted_rewards_array[~np.logical_or.accumulate(dones_shifted)].sum()\n            future_frame = np.zeros_like(past_frame)\n        else:\n            done = False\n            reward = discounted_rewards_array.sum()\n\n            if forward_steps >= self.frame_history:\n                frame_indices = (index_array[:self.frame_history] + 1) % self.buffer_capacity\n                future_frame = np.moveaxis(self.state_buffer[frame_indices, env_idx], 0, -2).reshape(past_frame.shape)\n            else:\n                frame_candidate = np.moveaxis(\n                    self.state_buffer[(index_array + 1) % self.buffer_capacity, env_idx], 0, -2\n                )\n                frame_candidate_target_shape = (\n                    list(frame_candidate.shape[:-2]) + [frame_candidate.shape[-2] * frame_candidate.shape[-1]]\n                )\n\n                future_frame = np.concatenate([\n                    past_frame[..., (frame_candidate_target_shape[-1] - past_frame.shape[-1]):],\n                    frame_candidate.reshape(frame_candidate_target_shape)\n                ], -1)\n\n        return past_frame, future_frame, reward, done"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_frame(self, frame_idx, env_idx):\n        if frame_idx >= self.current_size:\n            raise VelException(\"Requested frame beyond the size of the buffer\")\n\n        accumulator = []\n\n        last_frame = self.state_buffer[frame_idx, env_idx]\n\n        accumulator.append(last_frame)\n\n        for i in range(self.frame_history - 1):\n            prev_idx = (frame_idx - 1) % self.buffer_capacity\n\n            if prev_idx == self.current_idx:\n                raise VelException(\"Cannot provide enough history for the frame\")\n            elif self.dones_buffer[prev_idx, env_idx]:\n                # If previous frame was done - just append zeroes\n                accumulator.append(np.zeros_like(last_frame))\n            else:\n                frame_idx = prev_idx\n                accumulator.append(self.state_buffer[frame_idx, env_idx])\n\n        # We're pushing the elements in reverse order\n        return np.concatenate(accumulator[::-1], axis=-1)", "response": "Return the frame from the buffer"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a dictionary of data for a single transition with given index.", "response": "def get_transition(self, frame_idx, env_idx):\n        \"\"\" Single transition with given index \"\"\"\n        past_frame, future_frame = self.get_frame_with_future(frame_idx, env_idx)\n\n        data_dict = {\n            'observations': past_frame,\n            'observations_next': future_frame,\n            'actions': self.action_buffer[frame_idx, env_idx],\n            'rewards': self.reward_buffer[frame_idx, env_idx],\n            'dones': self.dones_buffer[frame_idx, env_idx],\n        }\n\n        for name in self.extra_data:\n            data_dict[name] = self.extra_data[name][frame_idx, env_idx]\n\n        return data_dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a dictionary of transition data for each environment.", "response": "def get_transitions(self, indexes):\n        \"\"\" Get dictionary of transition data \"\"\"\n        assert indexes.shape[1] == self.state_buffer.shape[1], \\\n            \"Must have the same number of indexes as there are environments\"\n\n        frame_batch_shape = (\n                [indexes.shape[0], indexes.shape[1]]\n                + list(self.state_buffer.shape[2:-1])\n                + [self.state_buffer.shape[-1] * self.frame_history]\n        )\n\n        past_frame_buffer = np.zeros(frame_batch_shape, dtype=self.state_buffer.dtype)\n        future_frame_buffer = np.zeros(frame_batch_shape, dtype=self.state_buffer.dtype)\n\n        for buffer_idx, frame_row in enumerate(indexes):\n            for env_idx, frame_idx in enumerate(frame_row):\n                past_frame_buffer[buffer_idx, env_idx], future_frame_buffer[buffer_idx, env_idx] = (\n                    self.get_frame_with_future(frame_idx, env_idx)\n                )\n\n        actions = take_along_axis(self.action_buffer, indexes)\n        rewards = take_along_axis(self.reward_buffer, indexes)\n        dones = take_along_axis(self.dones_buffer, indexes)\n\n        transition_tensors = {\n            'observations': past_frame_buffer,\n            'actions': actions,\n            'rewards': rewards,\n            'observations_next': future_frame_buffer,\n            'dones': dones.astype(np.float32),\n        }\n\n        for name in self.extra_data:\n            transition_tensors[name] = take_along_axis(self.extra_data[name], indexes)\n\n        return transition_tensors"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a dictionary of a transition data where the target of a transition is forward along the trajectory.", "response": "def get_transitions_forward_steps(self, indexes, forward_steps, discount_factor):\n        \"\"\"\n        Get dictionary of a transition data - where the target of a transition is\n        n steps forward along the trajectory. Rewards are properly aggregated according to the discount factor,\n        and the process stops when trajectory is done.\n        \"\"\"\n        frame_batch_shape = (\n                [indexes.shape[0], indexes.shape[1]]\n                + list(self.state_buffer.shape[2:-1])\n                + [self.state_buffer.shape[-1] * self.frame_history]\n        )\n\n        simple_batch_shape = [indexes.shape[0], indexes.shape[1]]\n\n        past_frame_buffer = np.zeros(frame_batch_shape, dtype=self.state_buffer.dtype)\n        future_frame_buffer = np.zeros(frame_batch_shape, dtype=self.state_buffer.dtype)\n\n        reward_buffer = np.zeros(simple_batch_shape, dtype=np.float32)\n        dones_buffer = np.zeros(simple_batch_shape, dtype=bool)\n\n        for buffer_idx, frame_row in enumerate(indexes):\n            for env_idx, frame_idx in enumerate(frame_row):\n                past_frame, future_frame, reward, done = self.get_frame_with_future_forward_steps(\n                    frame_idx, env_idx, forward_steps=forward_steps, discount_factor=discount_factor\n                )\n\n                past_frame_buffer[buffer_idx, env_idx] = past_frame\n                future_frame_buffer[buffer_idx, env_idx] = future_frame\n                reward_buffer[buffer_idx, env_idx] = reward\n                dones_buffer[buffer_idx, env_idx] = done\n\n        actions = take_along_axis(self.action_buffer, indexes)\n\n        transition_tensors = {\n            'observations': past_frame_buffer,\n            'actions': actions,\n            'rewards': reward_buffer,\n            'observations_next': future_frame_buffer,\n            'dones': dones_buffer.astype(np.float32),\n        }\n\n        for name in self.extra_data:\n            transition_tensors[name] = take_along_axis(self.extra_data[name], indexes)\n\n        return transition_tensors"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_trajectories(self, indexes, rollout_length):\n        # assert indexes.shape[0] > 1, \"There must be multiple indexes supplied\"\n        assert rollout_length > 1, \"Rollout length must be greater than 1\"\n\n        batch_indexes = (\n                indexes.reshape(1, indexes.shape[0]) - np.arange(rollout_length - 1, -1, -1).reshape(rollout_length, 1)\n        )\n\n        return self.get_transitions(batch_indexes)", "response": "Get the trajectories for the given indexes and rollout_length."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sample_batch_transitions(self, batch_size, forward_steps=1):\n        results = []\n\n        for i in range(self.num_envs):\n            results.append(self.sample_frame_single_env(batch_size, forward_steps=forward_steps))\n\n        return np.stack(results, axis=-1)", "response": "Sample the next batch of transitions from the current environments."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sample_batch_trajectories(self, rollout_length):\n        results = []\n\n        for i in range(self.num_envs):\n            results.append(self.sample_rollout_single_env(rollout_length))\n\n        return np.stack(results, axis=-1)", "response": "Return the batch trajectories of the given length"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sample_rollout_single_env(self, rollout_length):\n        # Sample from up to total size\n        if self.current_size < self.buffer_capacity:\n            if rollout_length + 1 > self.current_size:\n                raise VelException(\"Not enough elements in the buffer to sample the rollout\")\n\n            # -1 because we cannot take the last one\n            return np.random.choice(self.current_size - rollout_length) + rollout_length - 1\n        else:\n            if rollout_length + self.frame_history > self.current_size:\n                raise VelException(\"Not enough elements in the buffer to sample the rollout\")\n\n            candidate = np.random.choice(self.buffer_capacity)\n\n            # These are the elements we cannot draw, as then we don't have enough history\n            forbidden_ones = (\n                    np.arange(self.current_idx, self.current_idx + self.frame_history + rollout_length - 1)\n                    % self.buffer_capacity\n            )\n\n            # Exclude these frames for learning as they may have some part of history overwritten\n            while candidate in forbidden_ones:\n                candidate = np.random.choice(self.buffer_capacity)\n\n            return candidate", "response": "Sample from the buffer and return the next one in the given rollout length"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sample_frame_single_env(self, batch_size, forward_steps=1):\n        # Whole idea of this function is to make sure that sample we take is far away from the point which we are\n        # currently writing to the buffer, which is 'discontinuous'\n\n        if self.current_size < self.buffer_capacity:\n            # Sample from up to total size of the buffer\n            # -1 because we cannot take the last one\n            return np.random.choice(self.current_size - forward_steps, batch_size, replace=False)\n        else:\n            candidate = np.random.choice(self.buffer_capacity, batch_size, replace=False)\n\n            forbidden_ones = (\n                np.arange(self.current_idx - forward_steps + 1, self.current_idx + self.frame_history)\n                % self.buffer_capacity\n            )\n\n            # Exclude these frames for learning as they may have some part of history overwritten\n            while any(x in candidate for x in forbidden_ones):\n                candidate = np.random.choice(self.buffer_capacity, batch_size, replace=False)\n\n            return candidate", "response": "Sample a set of frames from a single environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new record movie command object.", "response": "def create(model_config, model, vec_env, storage, takes, videoname, fps=30, sample_args=None):\n    \"\"\" Vel factory function \"\"\"\n    return RecordMovieCommand(\n        model_config=model_config,\n        model_factory=model,\n        env_factory=vec_env,\n        storage=storage,\n        videoname=videoname,\n        takes=takes,\n        fps=fps,\n        sample_args=sample_args\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef record_take(self, model, env_instance, device, take_number):\n        frames = []\n\n        observation = env_instance.reset()\n\n        if model.is_recurrent:\n            hidden_state = model.zero_state(1).to(device)\n\n        frames.append(env_instance.render('rgb_array'))\n\n        print(\"Evaluating environment...\")\n\n        while True:\n            observation_array = np.expand_dims(np.array(observation), axis=0)\n            observation_tensor = torch.from_numpy(observation_array).to(device)\n\n            if model.is_recurrent:\n                output = model.step(observation_tensor, hidden_state, **self.sample_args)\n                hidden_state = output['state']\n                actions = output['actions']\n            else:\n                actions = model.step(observation_tensor, **self.sample_args)['actions']\n\n            actions = actions.detach().cpu().numpy()\n\n            observation, reward, done, epinfo = env_instance.step(actions[0])\n\n            frames.append(env_instance.render('rgb_array'))\n\n            if 'episode' in epinfo:\n                # End of an episode\n                break\n\n        takename = self.model_config.output_dir('videos', self.model_config.run_name, self.videoname.format(take_number))\n        pathlib.Path(os.path.dirname(takename)).mkdir(parents=True, exist_ok=True)\n\n        fourcc = cv2.VideoWriter_fourcc('M', 'J', 'P', 'G')\n        video = cv2.VideoWriter(takename, fourcc, self.fps, (frames[0].shape[1], frames[0].shape[0]))\n\n        for i in tqdm.trange(len(frames), file=sys.stdout):\n            video.write(cv2.cvtColor(frames[i], cv2.COLOR_RGB2BGR))\n\n        video.release()\n        print(\"Written {}\".format(takename))", "response": "Record a single movie and store it on hard drive"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new vel factory function", "response": "def create(input_shape):\n    \"\"\" Vel factory function \"\"\"\n    if isinstance(input_shape, numbers.Number):\n        input_shape = (input_shape,)\n    elif not isinstance(input_shape, tuple):\n        input_shape = tuple(input_shape)\n\n    def instantiate(**_):\n        return NormalizeObservations(input_shape)\n\n    return ModelFactory.generic(instantiate)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nresetting training state after training episode is finished.", "response": "def reset_training_state(self, dones, batch_info):\n        \"\"\" A hook for a model to react when during training episode is finished \"\"\"\n        for idx, done in enumerate(dones):\n            if done > 0.5:\n                self.processes[idx].reset()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef forward(self, actions, batch_info):\n        while len(self.processes) < actions.shape[0]:\n            len_action_space = self.action_space.shape[-1]\n\n            self.processes.append(\n                OrnsteinUhlenbeckNoiseProcess(\n                    np.zeros(len_action_space), float(self.std_dev) * np.ones(len_action_space)\n                )\n            )\n\n        noise = torch.from_numpy(np.stack([x() for x in self.processes])).float().to(actions.device)\n\n        return torch.min(torch.max(actions + noise, self.low_tensor), self.high_tensor)", "response": "Return model step after applying noise"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef interpolate_logscale(start, end, steps):\n    if start <= 0.0:\n        warnings.warn(\"Start of logscale interpolation must be positive!\")\n        start = 1e-5\n\n    return np.logspace(np.log10(float(start)), np.log10(float(end)), steps)", "response": "Interpolate series between start and end in given number of steps - logscale interpolation"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef interpolate_cosine_single(start, end, coefficient):\n    cos_out = (np.cos(np.pi*coefficient) + 1) / 2.0\n    return end + (start - end) * cos_out", "response": "Cosine interpolation for single segment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef interpolate_logscale_single(start, end, coefficient):\n    return np.exp(np.log(start) + (np.log(end) - np.log(start)) * coefficient)", "response": "Cosine interpolation for a single log - scale."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef interpolate_series(start, end, steps, how='linear'):\n    return INTERP_DICT[how](start, end, steps)", "response": "Interpolate a series between start and end in given number of steps."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninterpolating a single value between start and end in given number of steps", "response": "def interpolate_single(start, end, coefficient, how='linear'):\n    \"\"\" Interpolate single value between start and end in given number of steps \"\"\"\n    return INTERP_SINGLE_DICT[how](start, end, coefficient)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create(epsilon: typing.Union[Schedule, float]):\n    return GenericFactory(EpsGreedy, arguments={'epsilon': epsilon})", "response": "Create a new vel factory function"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create(lr, alpha, momentum=0, weight_decay=0, epsilon=1e-8):\n    return RMSpropTFFactory(lr=lr, alpha=alpha, momentum=momentum, weight_decay=weight_decay, eps=float(epsilon))", "response": "Create a new RMSpropTFFactory object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nperforms a single optimization step.", "response": "def step(self, closure=None):\n        \"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"\n        loss = None\n        if closure is not None:\n            loss = closure()\n\n        for group in self.param_groups:\n            for p in group['params']:\n                if p.grad is None:\n                    continue\n                grad = p.grad.data\n                if grad.is_sparse:\n                    raise RuntimeError('RMSprop does not support sparse gradients')\n                state = self.state[p]\n\n                # State initialization\n                if len(state) == 0:\n                    state['step'] = 0\n                    # ANOTHER LINE I'VE CHANGED\n                    state['square_avg'] = torch.ones_like(p.data)\n\n                    if group['momentum'] > 0:\n                        state['momentum_buffer'] = torch.zeros_like(p.data)\n\n                    if group['centered']:\n                        state['grad_avg'] = torch.zeros_like(p.data)\n\n                square_avg = state['square_avg']\n                alpha = group['alpha']\n\n                state['step'] += 1\n\n                if group['weight_decay'] != 0:\n                    grad = grad.add(group['weight_decay'], p.data)\n\n                square_avg.mul_(alpha).addcmul_(1 - alpha, grad, grad)\n\n                if group['centered']:\n                    grad_avg = state['grad_avg']\n                    grad_avg.mul_(alpha).add_(1 - alpha, grad)\n                    # THIS LINE IS EVERYTHING THAT I CHANGED IN THIS OPTIMIZER\n                    # avg = square_avg.addcmul(-1, grad_avg, grad_avg).sqrt().add_(group['eps'])\n                    avg = square_avg.addcmul(-1, grad_avg, grad_avg).add(group['eps']).sqrt()\n                else:\n                    # THIS LINE IS EVERYTHING THAT I CHANGED IN THIS OPTIMIZER\n                    # avg = square_avg.sqrt().add_(group['eps'])\n                    avg = square_avg.add(group['eps']).sqrt()\n\n                if group['momentum'] > 0:\n                    buf = state['momentum_buffer']\n                    buf.mul_(group['momentum']).addcdiv_(grad, avg)\n                    p.data.add_(-group['lr'], buf)\n                else:\n                    p.data.addcdiv_(-group['lr'], grad, avg)\n\n        return loss"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninitializes policy gradient from reinforcer settings", "response": "def initialize(self, training_info, model, environment, device):\n        \"\"\" Initialize policy gradient from reinforcer settings \"\"\"\n        self.target_model = self.model_factory.instantiate(action_space=environment.action_space).to(device)\n        self.target_model.load_state_dict(model.state_dict())\n        self.target_model.eval()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef calculate_gradient(self, batch_info, device, model, rollout):\n        evaluator = model.evaluate(rollout)\n\n        dones_tensor = evaluator.get('rollout:dones')\n        rewards_tensor = evaluator.get('rollout:rewards')\n\n        assert dones_tensor.dtype == torch.float32\n\n        with torch.no_grad():\n            target_evaluator = self.target_model.evaluate(rollout)\n\n            if self.double_dqn:\n                # DOUBLE DQN\n                target_q = target_evaluator.get('model:q_next')\n                model_q = evaluator.get('model:q_next')\n                # Select largest 'target' value based on action that 'model' selects\n                values = target_q.gather(1, model_q.argmax(dim=1, keepdim=True)).squeeze(1)\n            else:\n                # REGULAR DQN\n                # [0] is because in pytorch .max(...) returns tuple (max values, argmax)\n                values = target_evaluator.get('model:q_next').max(dim=1)[0]\n\n            forward_steps = rollout.extra_data.get('forward_steps', 1)\n            estimated_return = rewards_tensor + (self.discount_factor ** forward_steps) * values * (1 - dones_tensor)\n\n        q_selected = evaluator.get('model:action:q')\n\n        if evaluator.is_provided('rollout:weights'):\n            weights = evaluator.get('rollout:weights')\n        else:\n            weights = torch.ones_like(rewards_tensor)\n\n        original_losses = F.smooth_l1_loss(q_selected, estimated_return, reduction='none')\n\n        loss_value = torch.mean(weights * original_losses)\n        loss_value.backward()\n\n        return {\n            'loss': loss_value.item(),\n            # We need it to update priorities in the replay buffer:\n            'errors': original_losses.detach().cpu().numpy(),\n            'average_q_selected': torch.mean(q_selected).item(),\n            'average_q_target': torch.mean(estimated_return).item()\n        }", "response": "Calculate the gradient of the given rollout"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef post_optimization_step(self, batch_info, device, model, rollout):\n        if batch_info.aggregate_batch_number % self.target_update_frequency == 0:\n            self.target_model.load_state_dict(model.state_dict())\n            self.target_model.eval()", "response": "This method is called when the optimization step is done."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new on - policy iteration reinforcer.", "response": "def create(model_config, model, vec_env, algo, env_roller, parallel_envs, number_of_steps,\n           batch_size=256, experience_replay=1, stochastic_experience_replay=False, shuffle_transitions=True):\n    \"\"\" Vel factory function \"\"\"\n    settings = OnPolicyIterationReinforcerSettings(\n        number_of_steps=number_of_steps,\n        batch_size=batch_size,\n        experience_replay=experience_replay,\n        stochastic_experience_replay=stochastic_experience_replay,\n        shuffle_transitions=shuffle_transitions\n    )\n\n    return OnPolicyIterationReinforcerFactory(\n        settings=settings,\n        parallel_envs=parallel_envs,\n        env_factory=vec_env,\n        model_factory=model,\n        algo=algo,\n        env_roller_factory=env_roller,\n        seed=model_config.seed\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninitialize the training model and algo for training", "response": "def initialize_training(self, training_info: TrainingInfo, model_state=None, hidden_state=None):\n        \"\"\" Prepare models for training \"\"\"\n        if model_state is not None:\n            self.model.load_state_dict(model_state)\n        else:\n            self.model.reset_weights()\n\n        self.algo.initialize(\n            training_info=training_info, model=self.model, environment=self.env_roller.environment, device=self.device\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef train_batch(self, batch_info: BatchInfo) -> None:\n        # Calculate environment rollout on the evaluation version of the model\n        self.model.train()\n\n        rollout = self.env_roller.rollout(batch_info, self.model, self.settings.number_of_steps)\n\n        # Process rollout by the 'algo' (e.g. perform the advantage estimation)\n        rollout = self.algo.process_rollout(batch_info, rollout)\n\n        # Perform the training step\n        # Algo will aggregate data into this list:\n        batch_info['sub_batch_data'] = []\n\n        if self.settings.shuffle_transitions:\n            rollout = rollout.to_transitions()\n\n        if self.settings.stochastic_experience_replay:\n            # Always play experience at least once\n            experience_replay_count = max(np.random.poisson(self.settings.experience_replay), 1)\n        else:\n            experience_replay_count = self.settings.experience_replay\n\n        # Repeat the experience N times\n        for i in range(experience_replay_count):\n            # We may potentially need to split rollout into multiple batches\n            if self.settings.batch_size >= rollout.frames():\n                batch_result = self.algo.optimizer_step(\n                    batch_info=batch_info,\n                    device=self.device,\n                    model=self.model,\n                    rollout=rollout.to_device(self.device)\n                )\n\n                batch_info['sub_batch_data'].append(batch_result)\n            else:\n                # Rollout too big, need to split in batches\n                for batch_rollout in rollout.shuffled_batches(self.settings.batch_size):\n                    batch_result = self.algo.optimizer_step(\n                        batch_info=batch_info,\n                        device=self.device,\n                        model=self.model,\n                        rollout=batch_rollout.to_device(self.device)\n                    )\n\n                    batch_info['sub_batch_data'].append(batch_result)\n\n        batch_info['frames'] = rollout.frames()\n        batch_info['episode_infos'] = rollout.episode_information()\n\n        # Even with all the experience replay, we count the single rollout as a single batch\n        batch_info.aggregate_key('sub_batch_data')", "response": "Train the policy using the current environment and the model."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convolutional_layer_series(initial_size, layer_sequence):\n    size = initial_size\n\n    for filter_size, padding, stride in layer_sequence:\n        size = convolution_size_equation(size, filter_size, padding, stride)\n\n    return size", "response": "Execute a series of convolutional layer transformations to the size number"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new embedding model.", "response": "def create(alphabet_size: int, output_dim: int, pretrained: bool=False, frozen: bool=False, source: TextData=None):\n    \"\"\" Vel factory function \"\"\"\n    def instantiate(**_):\n        return EmbeddingInput(alphabet_size, output_dim, pretrained=pretrained, frozen=frozen, source=source)\n\n    return ModelFactory.generic(instantiate)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef process_rollout(self, batch_info, rollout: Rollout):\n        assert isinstance(rollout, Trajectories), \"A2C requires trajectory rollouts\"\n\n        advantages = discount_bootstrap_gae(\n            rewards_buffer=rollout.transition_tensors['rewards'],\n            dones_buffer=rollout.transition_tensors['dones'],\n            values_buffer=rollout.transition_tensors['values'],\n            final_values=rollout.rollout_tensors['final_values'],\n            discount_factor=self.discount_factor,\n            gae_lambda=self.gae_lambda,\n            number_of_steps=rollout.num_steps\n        )\n\n        returns = advantages + rollout.transition_tensors['values']\n\n        rollout.transition_tensors['advantages'] = advantages\n        rollout.transition_tensors['returns'] = returns\n\n        return rollout", "response": "Process the given rollout for ALGO before any chunking or shuffling"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef calculate_gradient(self, batch_info, device, model, rollout):\n        evaluator = model.evaluate(rollout)\n\n        # Use evaluator interface to get the what we are interested in from the model\n        advantages = evaluator.get('rollout:advantages')\n        returns = evaluator.get('rollout:returns')\n        rollout_values = evaluator.get('rollout:values')\n\n        logprobs = evaluator.get('model:action:logprobs')\n        values = evaluator.get('model:values')\n        entropy = evaluator.get('model:entropy')\n\n        # Actual calculations. Pretty trivial\n        policy_loss = -torch.mean(advantages * logprobs)\n        value_loss = 0.5 * F.mse_loss(values, returns)\n        policy_entropy = torch.mean(entropy)\n\n        loss_value = (\n            policy_loss - self.entropy_coefficient * policy_entropy + self.value_coefficient * value_loss\n        )\n\n        loss_value.backward()\n\n        return {\n            'policy_loss': policy_loss.item(),\n            'value_loss': value_loss.item(),\n            'policy_entropy': policy_entropy.item(),\n            'advantage_norm': torch.norm(advantages).item(),\n            'explained_variance': explained_variance(returns, rollout_values)\n        }", "response": "Calculate the gradient of the given rollout"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\napply sequence of actions to sequence of environments actions -> ( observations rewards news infos", "response": "def step(self, action):\n        \"\"\"\n        Apply sequence of actions to sequence of environments\n        actions -> (observations, rewards, news)\n\n        where 'news' is a boolean vector indicating whether each element is new.\n        \"\"\"\n        obs, rews, news, infos = self.env.step(action)\n\n        self.ret = self.ret * self.gamma + rews\n\n        obs = self._filter_observation(obs)\n\n        if self.ret_rms:\n            self.ret_rms.update(np.array([self.ret]))\n            rews = np.clip(rews / np.sqrt(self.ret_rms.var + self.epsilon), -self.cliprew, self.cliprew)\n\n        return obs, rews, news, infos"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate an AdamFactory object", "response": "def create(lr, betas=(0.9, 0.999), weight_decay=0, epsilon=1e-8, layer_groups=False):\n    \"\"\" Vel factory function \"\"\"\n    return AdamFactory(lr=lr, betas=betas, weight_decay=weight_decay, eps=epsilon, layer_groups=layer_groups)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the module in training mode.", "response": "def train(self, mode=True):\n        r\"\"\"\n        Sets the module in training mode.\n\n        This has any effect only on certain modules. See documentations of\n        particular modules for details of their behaviors in training/evaluation\n        mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n        etc.\n\n        Returns:\n            Module: self\n        \"\"\"\n        super().train(mode)\n\n        if mode:\n            mu.apply_leaf(self, mu.set_train_mode)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef summary(self, input_size=None, hashsummary=False):\n\n        if input_size is None:\n            print(self)\n            print(\"-\" * 120)\n            number = sum(p.numel() for p in self.model.parameters())\n            print(\"Number of model parameters: {:,}\".format(number))\n            print(\"-\" * 120)\n        else:\n            summary(self, input_size)\n\n        if hashsummary:\n            for idx, hashvalue in enumerate(self.hashsummary()):\n                print(f\"{idx}: {hashvalue}\")", "response": "Print a model summary"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprints a model summary - checksums of each layer parameters", "response": "def hashsummary(self):\n        \"\"\" Print a model summary - checksums of each layer parameters \"\"\"\n        children = list(self.children())\n\n        result = []\n\n        for child in children:\n            result.extend(hashlib.sha256(x.detach().cpu().numpy().tobytes()).hexdigest() for x in child.parameters())\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef zero_state(self, batch_size):\n        return torch.zeros(batch_size, self.state_dim, dtype=torch.float32)", "response": "Returns a new state of the network with the given batch size."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef loss(self, x_data, y_true):\n        y_pred = self(x_data)\n        return y_pred, self.loss_value(x_data, y_true, y_pred)", "response": "Forward propagate network and return a value of loss function"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef value(self, progress_indicator):\n        return interpolate.interpolate_linear_single(self.initial_value, self.final_value, progress_indicator)", "response": "Interpolate linearly between start and end values."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a new deep - deterministic policy gradient.", "response": "def create(model, discount_factor: float, tau: float, max_grad_norm: float=None):\n    \"\"\" Vel factory function \"\"\"\n    return DeepDeterministicPolicyGradient(\n        tau=tau,\n        discount_factor=discount_factor,\n        model_factory=model,\n        max_grad_norm=max_grad_norm\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncalculate the gradients of the current model and rollout", "response": "def calculate_gradient(self, batch_info, device, model, rollout):\n        \"\"\" Calculate loss of the supplied rollout \"\"\"\n        rollout = rollout.to_transitions()\n\n        dones = rollout.batch_tensor('dones')\n        rewards = rollout.batch_tensor('rewards')\n        observations_next = rollout.batch_tensor('observations_next')\n        actions = rollout.batch_tensor('actions')\n        observations = rollout.batch_tensor('observations')\n\n        # Calculate value loss - or critic loss\n        with torch.no_grad():\n            target_next_value = self.target_model.value(observations_next)\n            target_value = rewards + (1.0 - dones) * self.discount_factor * target_next_value\n\n        # Value estimation error vs the target network\n        model_value = model.value(observations, actions)\n        value_loss = F.mse_loss(model_value, target_value)\n\n        # It may seem a bit tricky what I'm doing here, but the underlying idea is simple\n        # All other implementations I found keep two separate optimizers for actor and critic\n        # and update them separately\n        # What I'm trying to do is to optimize them both with a single optimizer\n        # but I need to make sure gradients flow correctly\n        # From critic loss to critic network only and from actor loss to actor network only\n\n        # Backpropagate value loss to critic only\n        value_loss.backward()\n\n        model_action = model.action(observations)\n        model_action_value = model.value(observations, model_action)\n\n        policy_loss = -model_action_value.mean()\n\n        model_action_grad = torch.autograd.grad(policy_loss, model_action)[0]\n\n        # Backpropagate actor loss to actor only\n        model_action.backward(gradient=model_action_grad)\n\n        return {\n            'policy_loss': policy_loss.item(),\n            'value_loss': value_loss.item(),\n        }"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef post_optimization_step(self, batch_info, device, model, rollout):\n        # Update target model\n        for model_param, target_param in zip(model.parameters(), self.target_model.parameters()):\n            # EWMA average model update\n            target_param.data.mul_(1 - self.tau).add_(model_param.data * self.tau)", "response": "Update the target model with the new model parameters."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a DeterministicPolicyModelFactory object.", "response": "def create(policy_backbone: ModelFactory, value_backbone: ModelFactory,\n           input_block: typing.Optional[ModelFactory]=None):\n    \"\"\" Vel factory function \"\"\"\n    if input_block is None:\n        input_block = IdentityFactory()\n\n    return DeterministicPolicyModelFactory(\n        input_block=input_block, policy_backbone=policy_backbone, value_backbone=value_backbone\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef model_estimated_values_next(self):\n        observations = self.get('rollout:observations_next')\n        action, value = self.model(observations)\n        return value", "response": "Estimate state - value of the transition next state"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef model_actions(self):\n        observations = self.get('rollout:observations')\n        model_action = self.model.action(observations)\n        return model_action", "response": "Return the model actions for this rollout"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reset_weights(self):\n        self.input_block.reset_weights()\n        self.policy_backbone.reset_weights()\n        self.value_backbone.reset_weights()\n        self.action_head.reset_weights()\n        self.critic_head.reset_weights()", "response": "Initialize properly model weights"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef policy_parameters(self):\n        return it.chain(self.policy_backbone.parameters(), self.action_head.parameters())", "response": "Returns a generator of all the parameters of the policy."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef value_parameters(self):\n        return it.chain(self.value_backbone.parameters(), self.critic_head.parameters())", "response": "Returns a generator of all the value parameters of the current set of attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_layer_groups(self):\n        return [\n            [self.policy_backbone, self.action_head],\n            [self.value_backbone, [y for (x, y) in self.critic_head.named_parameters() if x.endswith('bias')]],\n            # OpenAI regularizes only weight on the last layer. I'm just replicating that\n            [[y for (x, y) in self.critic_head.named_parameters() if x.endswith('weight')]]\n        ]", "response": "Return layers grouped by backbone action head and weight."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the value for the given observation", "response": "def value(self, observation, input_actions=None):\n        \"\"\" Calculate value for given state \"\"\"\n        action, value = self(observation, input_actions)\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef action(self, observations):\n        observations = self.input_block(observations)\n        policy_hidden = self.policy_backbone(observations)\n        action = self.action_head(policy_hidden)\n        return action", "response": "Calculate the action value for given state"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new instance of the transition_replay_env_roller_factory.", "response": "def create(replay_buffer, discount_factor: typing.Optional[float]=None, normalize_returns: bool=False,\n           forward_steps: int=1, action_noise: typing.Optional[ModelFactory]=None):\n    \"\"\" Vel factory function \"\"\"\n    return TransitionReplayEnvRollerFactory(\n        replay_buffer_factory=replay_buffer,\n        discount_factor=discount_factor,\n        forward_steps=forward_steps,\n        normalize_returns=normalize_returns,\n        action_noise=action_noise\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates the environment rollout", "response": "def rollout(self, batch_info: BatchInfo, model: RlModel, number_of_steps: int) -> Rollout:\n        \"\"\" Calculate env rollout \"\"\"\n        assert not model.is_recurrent, \"Replay env roller does not support recurrent models\"\n\n        accumulator = TensorAccumulator()\n        episode_information = []  # List of dictionaries with episode information\n\n        for step_idx in range(number_of_steps):\n            step = model.step(self.last_observation)\n\n            if self.action_noise is not None:\n                step['actions'] = self.action_noise(step['actions'], batch_info=batch_info)\n\n            replay_extra_information = {}\n\n            accumulator.add('observations', self.last_observation_cpu)\n\n            # Add step to the tensor accumulator\n            for name, tensor in step.items():\n                tensor_cpu = tensor.cpu()\n                accumulator.add(name, tensor_cpu)\n\n                if name != 'actions':\n                    replay_extra_information[name] = tensor_cpu.numpy()\n\n            actions_numpy = step['actions'].detach().cpu().numpy()\n            new_obs, new_rewards, new_dones, new_infos = self.environment.step(actions_numpy)\n\n            # Store rollout in the experience replay buffer\n            self.replay_buffer.store_transition(\n                frame=self.last_observation_cpu.numpy(),\n                action=actions_numpy,\n                reward=new_rewards,\n                done=new_dones,\n                extra_info=replay_extra_information\n            )\n\n            if self.ret_rms is not None:\n                self.accumulated_returns = new_rewards + self.discount_factor * self.accumulated_returns\n                self.ret_rms.update(self.accumulated_returns)\n\n            # Done is flagged true when the episode has ended AND the frame we see is already a first frame from the\n            # next episode\n            dones_tensor = torch.from_numpy(new_dones.astype(np.float32)).clone()\n            accumulator.add('dones', dones_tensor)\n\n            if self.action_noise is not None:\n                self.action_noise.reset_training_state(dones_tensor, batch_info=batch_info)\n\n            self.accumulated_returns = self.accumulated_returns * (1.0 - new_dones.astype(np.float32))\n\n            self.last_observation_cpu = torch.from_numpy(new_obs).clone()\n            self.last_observation = self.last_observation_cpu.to(self.device)\n\n            if self.ret_rms is not None:\n                new_rewards = np.clip(new_rewards / np.sqrt(self.ret_rms.var + 1e-8), -self.clip_obs, self.clip_obs)\n\n            accumulator.add('rewards', torch.from_numpy(new_rewards.astype(np.float32)).clone())\n\n            episode_information.append(new_infos)\n\n        accumulated_tensors = accumulator.result()\n\n        return Trajectories(\n            num_steps=accumulated_tensors['observations'].size(0),\n            num_envs=accumulated_tensors['observations'].size(1),\n            environment_information=episode_information,\n            transition_tensors=accumulated_tensors,\n            rollout_tensors={}\n        ).to_transitions()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sample(self, batch_info: BatchInfo, model: RlModel, number_of_steps: int) -> Rollout:\n        if self.forward_steps > 1:\n            transitions = self.replay_buffer.sample_forward_transitions(\n                batch_size=number_of_steps, batch_info=batch_info, forward_steps=self.forward_steps,\n                discount_factor=self.discount_factor\n            )\n        else:\n            transitions = self.replay_buffer.sample_transitions(batch_size=number_of_steps, batch_info=batch_info)\n\n        if self.ret_rms is not None:\n            rewards = transitions.transition_tensors['rewards']\n            new_rewards = torch.clamp(rewards / np.sqrt(self.ret_rms.var + 1e-8), -self.clip_obs, self.clip_obs)\n            transitions.transition_tensors['rewards'] = new_rewards\n\n        return transitions", "response": "Sample an experience from the replay buffer and return a batch"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new vel factory function", "response": "def create(blocks, mode='basic', inplanes=16, divisor=4, num_classes=1000):\n    \"\"\" Vel factory function \"\"\"\n    block_dict = {\n        'basic': BasicBlock,\n        'bottleneck': Bottleneck\n    }\n\n    def instantiate(**_):\n        return ResNetV2(block_dict[mode], blocks, inplanes=inplanes, divisor=divisor, num_classes=num_classes)\n\n    return ModelFactory.generic(instantiate)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef metrics(self):\n        from vel.metrics.loss_metric import Loss\n        from vel.metrics.accuracy import Accuracy\n        return [Loss(), Accuracy()]", "response": "Returns a list of metrics for this model"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncrop image into a square of size sz", "response": "def crop_square(im, r, c, sz):\n    '''\n    crop image into a square of size sz,\n    '''\n    return im[r:r+sz, c:c+sz]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef crop(im, r, c, sz_h, sz_w):\n    '''\n    crop image into a square of size sz,\n    '''\n    return im[r:r+sz_h, c:c+sz_w]", "response": "crop image into a square of size sz"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrotates an image by deg degrees", "response": "def rotate_img(im, deg, mode=cv2.BORDER_CONSTANT, interpolation=cv2.INTER_AREA):\n    \"\"\" Rotates an image by deg degrees\n\n    Arguments:\n        deg (float): degree to rotate.\n    \"\"\"\n    r,c,*_ = im.shape\n    M = cv2.getRotationMatrix2D((c//2,r//2),deg,1)\n    return cv2.warpAffine(im,M,(c,r), borderMode=mode, flags=cv2.WARP_FILL_OUTLIERS+interpolation)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef one_hot_encoding(input_tensor, num_labels):\n    xview = input_tensor.view(-1, 1).to(torch.long)\n\n    onehot = torch.zeros(xview.size(0), num_labels, device=input_tensor.device, dtype=torch.float)\n    onehot.scatter_(1, xview, 1)\n    return onehot.view(list(input_tensor.shape) + [-1])", "response": "One - hot encode labels from input tensor"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef merge_first_two_dims(tensor):\n    shape = tensor.shape\n    batch_size = shape[0] * shape[1]\n    new_shape = tuple([batch_size] + list(shape[2:]))\n    return tensor.view(new_shape)", "response": "Reshape tensor to merge first two dimensions"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new nature cnn rnn backbone.", "response": "def create(input_width, input_height, input_channels=1, rnn_type='lstm', cnn_output_dim=512, hidden_units=128):\n    \"\"\" Vel factory function \"\"\"\n    def instantiate(**_):\n        return NatureCnnRnnBackbone(\n            input_width=input_width, input_height=input_height, input_channels=input_channels,\n            rnn_type=rnn_type, cnn_output_dim=cnn_output_dim, hidden_units=hidden_units\n        )\n\n    return ModelFactory.generic(instantiate)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new SgdFactory object.", "response": "def create(lr, weight_decay=0, momentum=0, layer_groups=False):\n    \"\"\" Vel factory function \"\"\"\n    return SgdFactory(lr=lr, weight_decay=weight_decay, momentum=momentum, layer_groups=layer_groups)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create(blocks, mode='basic', inplanes=64, cardinality=4, image_features=64, divisor=4, num_classes=1000):\n    block_dict = {\n        # 'basic': BasicBlock,\n        'bottleneck': ResNeXtBottleneck\n    }\n\n    def instantiate(**_):\n        return ResNeXt(block_dict[mode], blocks, inplanes=inplanes, image_features=image_features, cardinality=cardinality, divisor=divisor, num_classes=num_classes)\n\n    return ModelFactory.generic(instantiate)", "response": "Create a new virtual tree structure."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef instantiate_single(self, seed=0, preset='default'):\n        env = self.env.instantiate(seed=seed, serial_id=0, preset=preset)\n\n        if self.frame_history is not None:\n            env = FrameStack(env, self.frame_history)\n\n        return env", "response": "Create a new Env instance - single"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a proper closure around supplied values", "response": "def _creation_function(self, idx, seed, preset):\n        \"\"\" Helper function to create a proper closure around supplied values \"\"\"\n        return lambda: self.env.instantiate(seed=seed, serial_id=idx, preset=preset)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a StochasticPolicyModelFactory instance", "response": "def create(backbone: ModelFactory, input_block: typing.Optional[ModelFactory]=None):\n    \"\"\" Vel factory function \"\"\"\n    if input_block is None:\n        input_block = IdentityFactory()\n\n    return StochasticPolicyModelFactory(input_block=input_block, backbone=backbone)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reset_weights(self):\n        self.input_block.reset_weights()\n        self.backbone.reset_weights()\n        self.action_head.reset_weights()\n        self.value_head.reset_weights()", "response": "Initialize properly model weights"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nselect actions based on model s output", "response": "def step(self, observation, argmax_sampling=False):\n        \"\"\" Select actions based on model's output \"\"\"\n        action_pd_params, value_output = self(observation)\n        actions = self.action_head.sample(action_pd_params, argmax_sampling=argmax_sampling)\n\n        # log likelihood of selected action\n        logprobs = self.action_head.logprob(actions, action_pd_params)\n\n        return {\n            'actions': actions,\n            'values': value_output,\n            'action:logprobs': logprobs\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new generator command.", "response": "def create(model_config, model, source, storage, start_letter, length, temperature):\n    \"\"\" Vel factory function \"\"\"\n    return GenerateTextCommand(model_config, model, source, storage, start_letter, length, temperature)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef factorized_gaussian_noise(in_features, out_features, device):\n    in_noise = scaled_noise(in_features, device=device)\n    out_noise = scaled_noise(out_features, device=device)\n\n    return out_noise.ger(in_noise), out_noise", "response": "Factorised ( cheaper ) gaussian noise from Noisy Networks for Exploration"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef gaussian_noise(in_features, out_features, device):\n    return torch.randn((in_features, out_features), device=device), torch.randn(out_features, device=device)", "response": "Normal gaussian N noise"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reset_weights(self):\n        self.input_block.reset_weights()\n\n        self.policy_backbone.reset_weights()\n        self.value_backbone.reset_weights()\n\n        self.action_head.reset_weights()\n        self.value_head.reset_weights()", "response": "Initialize properly model weights"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef value(self, observations):\n        input_data = self.input_block(observations)\n        base_output = self.value_backbone(input_data)\n        value_output = self.value_head(base_output)\n        return value_output", "response": "Calculate only value head for given state"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef policy(self, observations):\n        input_data = self.input_block(observations)\n        policy_base_output = self.policy_backbone(input_data)\n        policy_params = self.action_head(policy_base_output)\n        return policy_params", "response": "Calculate only action head for given state"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new CyclePhase object.", "response": "def create(optimizer, max_lr, min_lr, cycles, cycle_len=1, cycle_mult=1, interpolate='linear', init_lr=0, init_iter=0):\n    \"\"\" Vel factory function \"\"\"\n    return CyclePhase(\n        max_lr=max_lr,\n        min_lr=min_lr,\n        cycles=cycles,\n        cycle_len=cycle_len,\n        cycle_mult=cycle_mult,\n        interpolate=interpolate,\n        optimizer_factory=optimizer,\n        init_lr=init_lr,\n        init_iter=init_iter,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _init_cycle_dict(self):\n        dict_arr = np.zeros(self.epochs, dtype=int)\n        length_arr = np.zeros(self.epochs, dtype=int)\n        start_arr = np.zeros(self.epochs, dtype=int)\n\n        c_len = self.cycle_len\n        idx = 0\n\n        for i in range(self.cycles):\n            current_start = idx\n            for j in range(c_len):\n                dict_arr[idx] = i\n                length_arr[idx] = c_len\n                start_arr[idx] = current_start\n                idx += 1\n\n            c_len *= self.cycle_mult\n\n        return dict_arr, length_arr, start_arr", "response": "Populate a cycle dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef on_batch_begin(self, batch_info: BatchInfo):\n        cycle_length = self.cycle_lengths[batch_info.local_epoch_number - 1]\n        cycle_start = self.cycle_starts[batch_info.local_epoch_number - 1]\n\n        numerator = (batch_info.local_epoch_number - cycle_start - 1) * batch_info.batches_per_epoch + batch_info.batch_number\n        denominator = cycle_length * batch_info.batches_per_epoch\n\n        interpolation_number = numerator / denominator\n\n        if cycle_start == 0 and numerator < self.init_iter:\n            lr = self.init_lr\n        else:\n            if isinstance(self.max_lr, list):\n                lr = [interp.interpolate_single(max_lr, min_lr, interpolation_number, how=self.interpolate) for max_lr, min_lr in zip(self.max_lr, self.min_lr)]\n            else:\n                lr = interp.interpolate_single(self.max_lr, self.min_lr, interpolation_number, how=self.interpolate)\n\n        self.set_lr(lr)", "response": "Set proper learning rate for the current batch."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_lr(self, lr):\n        if isinstance(lr, list):\n            for group_lr, param_group in zip(lr, self.optimizer.param_groups):\n                param_group['lr'] = group_lr\n        else:\n            for param_group in self.optimizer.param_groups:\n                param_group['lr'] = lr", "response": "Set a learning rate for the optimizer"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_up_phase(self, training_info, model, source):\n        # To parameter groups handles properly filtering parameters that don't require gradient\n        self._optimizer_instance = self.optimizer_factory.instantiate(model)\n        self._source = source\n\n        self.special_callback = CycleCallback(\n            self._optimizer_instance,\n            max_lr=self.max_lr, min_lr=self.min_lr, cycles=self.cycles,\n            cycle_len=self.cycle_len, cycle_mult=self.cycle_mult, interpolate=self.interpolate,\n            init_iter=self.init_iter, init_lr=self.init_lr\n        )\n\n        return self._optimizer_instance", "response": "Prepare the phase for learning"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new train command", "response": "def create(model_config, epochs, optimizer, model, source, storage, scheduler=None, callbacks=None, max_grad_norm=None):\n    \"\"\" Vel factory function \"\"\"\n    return SimpleTrainCommand(\n        epochs=epochs,\n        model_config=model_config,\n        model_factory=model,\n        optimizer_factory=optimizer,\n        scheduler_factory=scheduler,\n        source=source,\n        storage=storage,\n        callbacks=callbacks,\n        max_grad_norm=max_grad_norm\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run(self):\n        device = self.model_config.torch_device()\n\n        learner = api.Learner(device, self.model_factory.instantiate(), self.max_grad_norm)\n        optimizer = self.optimizer_factory.instantiate(learner.model)\n\n        # All callbacks used for learning\n        callbacks = self.gather_callbacks(optimizer)\n\n        # Metrics to track through this training\n        metrics = learner.metrics()\n\n        # Check if training was already started and potentially continue where we left off\n        training_info = self.resume_training(learner, callbacks, metrics)\n\n        training_info.on_train_begin()\n\n        if training_info.optimizer_initial_state:\n            optimizer.load_state_dict(training_info.optimizer_initial_state)\n\n        for global_epoch_idx in range(training_info.start_epoch_idx + 1, self.epochs + 1):\n            epoch_info = api.EpochInfo(\n                training_info=training_info,\n                global_epoch_idx=global_epoch_idx,\n                batches_per_epoch=self.source.train_iterations_per_epoch(),\n                optimizer=optimizer\n            )\n\n            # Execute learning\n            learner.run_epoch(epoch_info, self.source)\n\n            self.storage.checkpoint(epoch_info, learner.model)\n\n        training_info.on_train_end()\n\n        return training_info", "response": "Runs the command with supplied configuration"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new virtual hierarchy.", "response": "def create(lr, epochs, optimizer):\n    \"\"\" Vel factory function \"\"\"\n    return GenericPhase(\n        lr=lr,\n        epochs=epochs,\n        optimizer_factory=optimizer,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npreparing the phase for learning", "response": "def set_up_phase(self, training_info, model, source: Source):\n        \"\"\" Prepare the phase for learning \"\"\"\n        self._optimizer_instance = self.optimizer_factory.instantiate(model)\n        self._source = source"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprepares the phase for learning", "response": "def execute_epoch(self, epoch_info, learner):\n        \"\"\" Prepare the phase for learning \"\"\"\n        for param_group in epoch_info.optimizer.param_groups:\n            param_group['lr'] = self.lr\n\n        epoch_result = learner.run_epoch(epoch_info, self._source)\n\n        return epoch_result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parameter_constructor(cls, loader, node):\n        value = loader.construct_scalar(node)\n\n        if isinstance(value, str):\n            if '=' in value:\n                (varname, varvalue) = Parser.parse_equality(value)\n                return cls(varname, varvalue)\n            else:\n                return cls(value)\n        else:\n            return cls(value)", "response": "Construct a new instance of the class from a yaml node."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nregister variable handling in YAML", "response": "def register(cls):\n        \"\"\" Register variable handling in YAML \"\"\"\n        if not cls.IS_LOADED:\n            cls.IS_LOADED = True\n\n            yaml.add_constructor('!param', Parameter.parameter_constructor, Loader=yaml.SafeLoader)\n            yaml.add_constructor('!env', EnvironmentVariable.parameter_constructor, Loader=yaml.SafeLoader)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_equality(cls, equality_string):\n        cls.register()\n        assert '=' in equality_string, \"There must be an '=' sign in the equality\"\n        [left_side, right_side] = equality_string.split('=', 1)\n\n        left_side_value = yaml.safe_load(left_side.strip())\n        right_side_value = yaml.safe_load(right_side.strip())\n\n        assert isinstance(left_side_value, str), \"Left side of equality must be a string\"\n\n        return left_side_value, right_side_value", "response": "Parse the simple equality statement"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving entries from database that would get overwritten", "response": "def clean(self, initial_epoch):\n        \"\"\" Remove entries from database that would get overwritten \"\"\"\n        self.db.metrics.delete_many({'run_name': self.model_config.run_name, 'epoch_idx': {'$gt': initial_epoch}})"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef store_config(self, configuration):\n        run_name = self.model_config.run_name\n\n        self.db.configs.delete_many({'run_name': self.model_config.run_name})\n\n        configuration = configuration.copy()\n        configuration['run_name'] = run_name\n\n        self.db.configs.insert_one(configuration)", "response": "Store the model parameters in the database"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_frame(self):\n        metric_items = list(self.db.metrics.find({'run_name': self.model_config.run_name}).sort('epoch_idx'))\n        if len(metric_items) == 0:\n            return pd.DataFrame(columns=['run_name'])\n        else:\n            return pd.DataFrame(metric_items).drop(['_id', 'model_name'], axis=1).set_index('epoch_idx')", "response": "Get a dataframe of metrics from this storage"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_transitions(self, probs, indexes, tree_idxs, batch_info, forward_steps=1, discount_factor=1.0):\n        if forward_steps > 1:\n            transition_arrays = self.backend.get_transitions_forward_steps(indexes, forward_steps, discount_factor)\n        else:\n            transition_arrays = self.backend.get_transitions(indexes)\n\n        priority_weight = self.priority_weight.value(batch_info['progress'])\n\n        # Normalize by sum of all probs\n        probs = probs / np.array([s.total() for s in self.backend.segment_trees], dtype=float).reshape(1, -1)\n        capacity = self.backend.current_size\n        weights = (capacity * probs) ** (-priority_weight)\n        weights = weights / weights.max(axis=0, keepdims=True)\n\n        transition_arrays['weights'] = weights\n        transition_tensors = {k: torch.from_numpy(v) for k, v in transition_arrays.items()}\n\n        transitions = Trajectories(\n            num_steps=indexes.shape[0],\n            num_envs=indexes.shape[1],\n            environment_information=None,\n            transition_tensors=transition_tensors,\n            rollout_tensors={},\n            extra_data={\n                'tree_idxs': tree_idxs\n            }\n        )\n\n        return transitions.to_transitions()", "response": "Return a batch of frames for given indexes"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sample_transitions(self, batch_size, batch_info) -> Transitions:\n        probs, indexes, tree_idxs = self.backend.sample_batch_transitions(batch_size)\n\n        return self._get_transitions(probs, indexes, tree_idxs, batch_info)", "response": "Sample a batch of transitions and return them"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sample_forward_transitions(self, batch_size, batch_info,\n                                   forward_steps: int, discount_factor: float) -> Transitions:\n        \"\"\"\n        Sample transitions from replay buffer with _forward steps_.\n        That is, instead of getting a transition s_t -> s_t+1 with reward r,\n        get a transition s_t -> s_t+n with sum of intermediate rewards.\n\n        Used in a variant of Deep Q-Learning\n        \"\"\"\n        probs, indexes, tree_idxs = self.backend.sample_batch_transitions(batch_size, forward_steps)\n\n        return self._get_transitions(\n            probs, indexes, tree_idxs, batch_info\n        )", "response": "Sample the forward_steps transitions from the replay buffer with _forward steps."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef summary(model, input_size):\n    def register_hook(module):\n        def hook(module, input, output):\n            class_name = str(module.__class__).split('.')[-1].split(\"'\")[0]\n            module_idx = len(summary)\n\n            m_key = '%s-%i' % (class_name, module_idx + 1)\n            summary[m_key] = OrderedDict()\n            summary[m_key]['input_shape'] = list(input[0].size())\n            summary[m_key]['input_shape'][0] = -1\n            if isinstance(output, (list, tuple)):\n                summary[m_key]['output_shape'] = [[-1] + list(o.size())[1:] for o in output]\n            else:\n                summary[m_key]['output_shape'] = list(output.size())\n                summary[m_key]['output_shape'][0] = -1\n\n            params = 0\n            if hasattr(module, 'weight') and hasattr(module.weight, 'size'):\n                params += torch.prod(torch.LongTensor(list(module.weight.size())))\n                summary[m_key]['trainable'] = module.weight.requires_grad\n            if hasattr(module, 'bias') and hasattr(module.bias, 'size'):\n                params += torch.prod(torch.LongTensor(list(module.bias.size())))\n            summary[m_key]['nb_params'] = params\n\n        if (not isinstance(module, nn.Sequential) and\n                not isinstance(module, nn.ModuleList) and\n                not (module == model)):\n            hooks.append(module.register_forward_hook(hook))\n\n    if torch.cuda.is_available():\n        dtype = torch.cuda.FloatTensor\n        model = model.cuda()\n    else:\n        dtype = torch.FloatTensor\n        model = model.cpu()\n\n    # check if there are multiple inputs to the network\n    if isinstance(input_size[0], (list, tuple)):\n        x = [Variable(torch.rand(2, *in_size)).type(dtype) for in_size in input_size]\n    else:\n        x = Variable(torch.rand(2, *input_size)).type(dtype)\n\n    # print(type(x[0]))\n    # create properties\n    summary = OrderedDict()\n    hooks = []\n    # register hook\n    model.apply(register_hook)\n    # make a forward pass\n    # print(x.shape)\n    model(x)\n    # remove these hooks\n    for h in hooks:\n        h.remove()\n\n    print('----------------------------------------------------------------')\n    line_new = '{:>20}  {:>25} {:>15}'.format('Layer (type)', 'Output Shape', 'Param #')\n    print(line_new)\n    print('================================================================')\n    total_params = 0\n    trainable_params = 0\n    for layer in summary:\n        # input_shape, output_shape, trainable, nb_params\n        line_new = '{:>20}  {:>25} {:>15}'.format(layer, str(summary[layer]['output_shape']),\n                                                  '{0:,}'.format(summary[layer]['nb_params']))\n        total_params += summary[layer]['nb_params']\n        if 'trainable' in summary[layer]:\n            if summary[layer]['trainable'] == True:\n                trainable_params += summary[layer]['nb_params']\n        print(line_new)\n    print('================================================================')\n    print('Total params: {0:,}'.format(total_params))\n    print('Trainable params: {0:,}'.format(trainable_params))\n    print('Non-trainable params: {0:,}'.format(total_params - trainable_params))\n    print('----------------------------------------------------------------')", "response": "Print summary of the network."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new QDuelingModelFactory instance.", "response": "def create(backbone: ModelFactory, input_block: typing.Optional[ModelFactory]=None):\n    \"\"\" Vel factory function \"\"\"\n    if input_block is None:\n        input_block = IdentityFactory()\n\n    return QDuelingModelFactory(input_block=input_block, backbone=backbone)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef step(self, observations):\n        q_values = self(observations)\n\n        return {\n            'actions': self.q_head.sample(q_values),\n            'q': q_values\n        }", "response": "Sample action from an action space for given state"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nroll - out the environment and return it", "response": "def rollout(self, batch_info: BatchInfo, model: Model, number_of_steps: int) -> Rollout:\n        \"\"\" Roll-out the environment and return it \"\"\"\n        raise NotImplementedError"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new object of type BufferedMixedPolicyIterationReinforcerFactory.", "response": "def create(model_config, model, vec_env, algo, env_roller,\n           parallel_envs, number_of_steps,\n           experience_replay=1, stochastic_experience_replay=True):\n    \"\"\" Vel factory function \"\"\"\n    settings = BufferedMixedPolicyIterationReinforcerSettings(\n        experience_replay=experience_replay,\n        stochastic_experience_replay=stochastic_experience_replay,\n        number_of_steps=number_of_steps\n    )\n\n    return BufferedMixedPolicyIterationReinforcerFactory(\n        settings,\n        env_factory=vec_env,\n        model_factory=model,\n        parallel_envs=parallel_envs,\n        env_roller_factory=env_roller,\n        algo=algo,\n        seed=model_config.seed\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntrain model on an epoch of a fixed number of batch updates", "response": "def train_epoch(self, epoch_info: EpochInfo, interactive=True):\n        \"\"\" Train model on an epoch of a fixed number of batch updates \"\"\"\n        epoch_info.on_epoch_begin()\n\n        if interactive:\n            iterator = tqdm.trange(epoch_info.batches_per_epoch, file=sys.stdout, desc=\"Training\", unit=\"batch\")\n        else:\n            iterator = range(epoch_info.batches_per_epoch)\n\n        for batch_idx in iterator:\n            batch_info = BatchInfo(epoch_info, batch_idx)\n\n            batch_info.on_batch_begin()\n            self.train_batch(batch_info)\n            batch_info.on_batch_end()\n\n        epoch_info.result_accumulator.freeze_results()\n        epoch_info.on_epoch_end()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntrains the policy for a single batch.", "response": "def train_batch(self, batch_info: BatchInfo):\n        \"\"\" Single, most atomic 'step' of learning this reinforcer can perform \"\"\"\n        batch_info['sub_batch_data'] = []\n\n        self.on_policy_train_batch(batch_info)\n\n        if self.settings.experience_replay > 0 and self.env_roller.is_ready_for_sampling():\n            if self.settings.stochastic_experience_replay:\n                experience_replay_count = np.random.poisson(self.settings.experience_replay)\n            else:\n                experience_replay_count = self.settings.experience_replay\n\n            for i in range(experience_replay_count):\n                self.off_policy_train_batch(batch_info)\n\n        # Even with all the experience replay, we count the single rollout as a single batch\n        batch_info.aggregate_key('sub_batch_data')"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nperform an on - policy training step of evaluating an env and a single backpropagation step", "response": "def on_policy_train_batch(self, batch_info: BatchInfo):\n        \"\"\" Perform an 'on-policy' training step of evaluating an env and a single backpropagation step \"\"\"\n        self.model.train()\n\n        rollout = self.env_roller.rollout(batch_info, self.model, self.settings.number_of_steps).to_device(self.device)\n\n        batch_result = self.algo.optimizer_step(\n            batch_info=batch_info,\n            device=self.device,\n            model=self.model,\n            rollout=rollout\n        )\n\n        batch_info['sub_batch_data'].append(batch_result)\n        batch_info['frames'] = rollout.frames()\n        batch_info['episode_infos'] = rollout.episode_information()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nperform an off - policy training step of sampling the replay buffer and gradient descent", "response": "def off_policy_train_batch(self, batch_info: BatchInfo):\n        \"\"\" Perform an 'off-policy' training step of sampling the replay buffer and gradient descent \"\"\"\n        self.model.train()\n\n        rollout = self.env_roller.sample(batch_info, self.model, self.settings.number_of_steps).to_device(self.device)\n\n        batch_result = self.algo.optimizer_step(\n            batch_info=batch_info,\n            device=self.device,\n            model=self.model,\n            rollout=rollout\n        )\n\n        batch_info['sub_batch_data'].append(batch_result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create(mean, std, mode='x', tags=None):\n    return Normalize(mean=mean, std=std, mode=mode, tags=tags)", "response": "Create a new virtual element."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new ClassicCheckpointStrategy instance.", "response": "def create(checkpoint_frequency=0, metric=None, metric_mode='min', store_best=False):\n    \"\"\" Vel factory function \"\"\"\n    return ClassicCheckpointStrategy(\n        checkpoint_frequency=checkpoint_frequency,\n        metric=metric,\n        metric_mode=metric_mode,\n        store_best=store_best\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if we should store the current checkpoint as the best", "response": "def should_store_best_checkpoint(self, epoch_idx, metrics) -> bool:\n        \"\"\" Should we store current checkpoint as the best \"\"\"\n        if not self.store_best:\n            return False\n\n        metric = metrics[self.metric]\n\n        if better(self._current_best_metric_value, metric, self.metric_mode):\n            self._current_best_metric_value = metric\n            return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create(model_config, batch_size, vectors=None):\n    path = model_config.data_dir('imdb')\n\n    text_field = data.Field(lower=True, tokenize='spacy', batch_first=True)\n    label_field = data.LabelField(is_target=True)\n\n    train_source, test_source = IMDBCached.splits(\n        root=path,\n        text_field=text_field,\n        label_field=label_field\n    )\n\n    text_field.build_vocab(train_source, max_size=25_000, vectors=vectors)\n    label_field.build_vocab(train_source)\n\n    train_iterator, test_iterator = data.BucketIterator.splits(\n        (train_source, test_source),\n        batch_size=batch_size,\n        device=model_config.torch_device(),\n        shuffle=True\n    )\n\n    return TextData(\n        train_source, test_source, train_iterator, test_iterator, text_field, label_field\n    )", "response": "Create an IMDB dataset"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a classic control environment with basic set of wrappers.", "response": "def env_maker(environment_id, seed, serial_id, monitor=False, allow_early_resets=False):\n    \"\"\" Create a classic control environment with basic set of wrappers \"\"\"\n    env = gym.make(environment_id)\n    env.seed(seed + serial_id)\n\n    # Monitoring the env\n    if monitor:\n        logdir = logger.get_dir() and os.path.join(logger.get_dir(), str(serial_id))\n    else:\n        logdir = None\n\n    env = Monitor(env, logdir, allow_early_resets=allow_early_resets)\n\n    return env"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create(game, settings=None, presets=None):\n    return ClassicControlEnv(\n        envname=game,\n        settings=settings,\n        presets=presets\n    )", "response": "Create a new instance of the ClassicControlEnv class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create(fc_layers=None, dropout=None, pretrained=True):\n    def instantiate(**_):\n        return Resnet34(fc_layers, dropout, pretrained)\n\n    return ModelFactory.generic(instantiate)", "response": "Create a new vel model."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfreezing given number of layers in the model.", "response": "def freeze(self, number=None):\n        \"\"\" Freeze given number of layers in the model \"\"\"\n        if number is None:\n            number = self.head_layers\n\n        for idx, child in enumerate(self.model.children()):\n            if idx < number:\n                mu.freeze_layer(child)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_layer_groups(self):\n        g1 = list(self.model[:self.group_cut_layers[0]])\n        g2 = list(self.model[self.group_cut_layers[0]:self.group_cut_layers[1]])\n        g3 = list(self.model[self.group_cut_layers[1]:])\n        return [g1, g2, g3]", "response": "Return layers grouped by group"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a new policy gradient RNN model factory function", "response": "def create(backbone: ModelFactory, input_block: typing.Optional[ModelFactory]=None):\n    \"\"\" Vel factory function \"\"\"\n    if input_block is None:\n        input_block = IdentityFactory()\n\n    return PolicyGradientRnnModelFactory(\n        input_block=input_block,\n        backbone=backbone\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nselects actions based on model s output", "response": "def step(self, observations, state, argmax_sampling=False):\n        \"\"\" Select actions based on model's output \"\"\"\n        action_pd_params, value_output, new_state = self(observations, state)\n        actions = self.action_head.sample(action_pd_params, argmax_sampling=argmax_sampling)\n\n        # log likelihood of selected action\n        logprobs = self.action_head.logprob(actions, action_pd_params)\n\n        return {\n            'actions': actions,\n            'values': value_output,\n            'logprobs': logprobs,\n            'state': new_state\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new AcerPolicyGradient object", "response": "def create(model, trust_region, entropy_coefficient, q_coefficient, max_grad_norm, discount_factor,\n           rho_cap=10.0, retrace_rho_cap=1.0, average_model_alpha=0.99, trust_region_delta=1.0):\n    \"\"\" Vel factory function \"\"\"\n    return AcerPolicyGradient(\n        trust_region=trust_region,\n        model_factory=model,\n        entropy_coefficient=entropy_coefficient,\n        q_coefficient=q_coefficient,\n        rho_cap=rho_cap,\n        retrace_rho_cap=retrace_rho_cap,\n        max_grad_norm=max_grad_norm,\n        discount_factor=discount_factor,\n        average_model_alpha=average_model_alpha,\n        trust_region_delta=trust_region_delta\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef initialize(self, training_info, model, environment, device):\n        if self.trust_region:\n            self.average_model = self.model_factory.instantiate(action_space=environment.action_space).to(device)\n            self.average_model.load_state_dict(model.state_dict())", "response": "Initialize policy gradient from reinforcer settings."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_average_model(self, model):\n        for model_param, average_param in zip(model.parameters(), self.average_model.parameters()):\n            # EWMA average model update\n            average_param.data.mul_(self.average_model_alpha).add_(model_param.data * (1 - self.average_model_alpha))", "response": "Update weights of the average model with new model observation"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef calculate_gradient(self, batch_info, device, model, rollout):\n        assert isinstance(rollout, Trajectories), \"ACER algorithm requires trajectory input\"\n\n        local_epsilon = 1e-6\n\n        evaluator = model.evaluate(rollout)\n\n        actions = evaluator.get('rollout:actions')\n        rollout_probabilities = torch.exp(evaluator.get('rollout:logprobs'))\n\n        # We calculate the trust-region update with respect to the average model\n        if self.trust_region:\n            self.update_average_model(model)\n\n        logprobs = evaluator.get('model:logprobs')\n        q = evaluator.get('model:q')\n\n        # Selected action values\n        action_logprobs = select_indices(logprobs, actions)\n        action_q = select_indices(q, actions)\n\n        # We only want to propagate gradients through specific variables\n        with torch.no_grad():\n            model_probabilities = torch.exp(logprobs)\n\n            # Importance sampling correction - we must find the quotient of probabilities\n            rho = model_probabilities / (rollout_probabilities + local_epsilon)\n\n            # Probability quotient only for selected actions\n            actions_rho = select_indices(rho, actions)\n\n            # Calculate policy state values\n            model_state_values = (model_probabilities * q).sum(dim=1)\n\n            trajectory_rewards = rollout.transition_tensors['rewards']\n            trajectory_dones = rollout.transition_tensors['dones']\n\n            q_retraced = self.retrace(\n                trajectory_rewards,\n                trajectory_dones,\n                action_q.reshape(trajectory_rewards.size()),\n                model_state_values.reshape(trajectory_rewards.size()),\n                actions_rho.reshape(trajectory_rewards.size()),\n                rollout.rollout_tensors['final_values']\n            ).flatten()\n\n            advantages = q_retraced - model_state_values\n            importance_sampling_coefficient = torch.min(actions_rho, self.rho_cap * torch.ones_like(actions_rho))\n\n            explained_variance = 1 - torch.var(q_retraced - action_q) / torch.var(q_retraced)\n\n        # Entropy of the policy distribution\n        policy_entropy = torch.mean(model.entropy(logprobs))\n        policy_gradient_loss = -torch.mean(advantages * importance_sampling_coefficient * action_logprobs)\n\n        # Policy gradient bias correction\n        with torch.no_grad():\n            advantages_bias_correction = q - model_state_values.view(model_probabilities.size(0), 1)\n            bias_correction_coefficient = F.relu(1.0 - self.rho_cap / (rho + local_epsilon))\n\n        # This sum is an expectation with respect to action probabilities according to model policy\n        policy_gradient_bias_correction_gain = torch.sum(\n            logprobs * bias_correction_coefficient * advantages_bias_correction * model_probabilities,\n            dim=1\n        )\n\n        policy_gradient_bias_correction_loss = - torch.mean(policy_gradient_bias_correction_gain)\n\n        policy_loss = policy_gradient_loss + policy_gradient_bias_correction_loss\n\n        q_function_loss = 0.5 * F.mse_loss(action_q, q_retraced)\n\n        if self.trust_region:\n            with torch.no_grad():\n                average_evaluator = self.average_model.evaluate(rollout)\n                average_action_logits = average_evaluator.get('model:logprobs')\n\n            actor_loss = policy_loss - self.entropy_coefficient * policy_entropy\n            q_loss = self.q_coefficient * q_function_loss\n\n            actor_gradient = torch.autograd.grad(-actor_loss, logprobs, retain_graph=True)[0]\n\n            # kl_divergence = model.kl_divergence(average_action_logits, action_logits).mean()\n            # kl_divergence_grad = torch.autograd.grad(kl_divergence, action_logits, retain_graph=True)\n\n            # Analytically calculated derivative of KL divergence on logits\n            # That makes it hardcoded for discrete action spaces\n            kl_divergence_grad_symbolic = - torch.exp(average_action_logits) / logprobs.size(0)\n\n            k_dot_g = (actor_gradient * kl_divergence_grad_symbolic).sum(dim=-1)\n            k_dot_k = (kl_divergence_grad_symbolic ** 2).sum(dim=-1)\n\n            adjustment = (k_dot_g - self.trust_region_delta) / k_dot_k\n            adjustment_clipped = adjustment.clamp(min=0.0)\n\n            actor_gradient_updated = actor_gradient - adjustment_clipped.view(adjustment_clipped.size(0), 1)\n\n            # Populate gradient from the newly updated fn\n            logprobs.backward(gradient=-actor_gradient_updated, retain_graph=True)\n            q_loss.backward(retain_graph=True)\n        else:\n            # Just populate gradient from the loss\n            loss = policy_loss + self.q_coefficient * q_function_loss - self.entropy_coefficient * policy_entropy\n\n            loss.backward()\n\n        return {\n            'policy_loss': policy_loss.item(),\n            'policy_gradient_loss': policy_gradient_loss.item(),\n            'policy_gradient_bias_correction': policy_gradient_bias_correction_loss.item(),\n            'avg_q_selected': action_q.mean().item(),\n            'avg_q_retraced': q_retraced.mean().item(),\n            'q_loss': q_function_loss.item(),\n            'policy_entropy': policy_entropy.item(),\n            'advantage_norm': torch.norm(advantages).item(),\n            'explained_variance': explained_variance.item(),\n            'model_prob_std': model_probabilities.std().item(),\n            'rollout_prob_std': rollout_probabilities.std().item()\n        }", "response": "Calculates the gradients of the given rollout"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef retrace(self, rewards, dones, q_values, state_values, rho, final_values):\n        rho_bar = torch.min(torch.ones_like(rho) * self.retrace_rho_cap, rho)\n\n        q_retraced_buffer = torch.zeros_like(rewards)\n\n        next_value = final_values\n\n        for i in reversed(range(rewards.size(0))):\n            q_retraced = rewards[i] + self.discount_factor * next_value * (1.0 - dones[i])\n\n            # Next iteration\n            next_value = rho_bar[i] * (q_retraced - q_values[i]) + state_values[i]\n\n            q_retraced_buffer[i] = q_retraced\n\n        return q_retraced_buffer", "response": "Calculate Q retraced targets"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the value of a metric", "response": "def calculate(self, batch_info):\n        \"\"\" Calculate value of a metric \"\"\"\n        value = self._value_function(batch_info)\n        self.buffer += value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsampling from a probability space of all actions", "response": "def sample(self, params, argmax_sampling=False):\n        \"\"\" Sample from a probability space of all actions \"\"\"\n        means = params[:, :, 0]\n        log_std = params[:, :, 1]\n\n        if argmax_sampling:\n            return means\n        else:\n            return torch.randn_like(means) * torch.exp(log_std) + means"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef logprob(self, action_sample, pd_params):\n        means = pd_params[:, :, 0]\n        log_std = pd_params[:, :, 1]\n\n        std = torch.exp(log_std)\n\n        z_score = (action_sample - means) / std\n\n        return - (0.5 * ((z_score**2 + self.LOG2PI).sum(dim=-1)) + log_std.sum(dim=-1))", "response": "Log - likelihood of the action sample."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef entropy(self, params):\n        log_std = params[:, :, 1]\n        return (log_std + 0.5 * (self.LOG2PI + 1)).sum(dim=-1)", "response": "Calculate the entropy of a set of classes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating the KL divergence of a Categorical distribution.", "response": "def kl_divergence(self, params_q, params_p):\n        \"\"\"\n        Categorical distribution KL divergence calculation\n        KL(Q || P) = sum Q_i log (Q_i / P_i)\n\n        Formula is:\n        log(sigma_p) - log(sigma_q) + (sigma_q^2 + (mu_q - mu_p)^2))/(2 * sigma_p^2)\n        \"\"\"\n        means_q = params_q[:, :, 0]\n        log_std_q = params_q[:, :, 1]\n\n        means_p = params_p[:, :, 0]\n        log_std_p = params_p[:, :, 1]\n\n        std_q = torch.exp(log_std_q)\n        std_p = torch.exp(log_std_p)\n\n        kl_div = log_std_p - log_std_q + (std_q ** 2 + (means_q - means_p) ** 2) / (2.0 * std_p ** 2) - 0.5\n\n        return kl_div.sum(dim=-1)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef logprob(self, actions, action_logits):\n        neg_log_prob = F.nll_loss(action_logits, actions, reduction='none')\n        return -neg_log_prob", "response": "Logarithm of probability of given sample"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsample from a probability space of all actions", "response": "def sample(self, logits, argmax_sampling=False):\n        \"\"\" Sample from a probability space of all actions \"\"\"\n        if argmax_sampling:\n            return torch.argmax(logits, dim=-1)\n        else:\n            u = torch.rand_like(logits)\n            return torch.argmax(logits - torch.log(-torch.log(u)), dim=-1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the KL divergence of the categories.", "response": "def kl_divergence(self, logits_q, logits_p):\n        \"\"\"\n        Categorical distribution KL divergence calculation\n        KL(Q || P) = sum Q_i log (Q_i / P_i)\n        When talking about logits this is:\n        sum exp(Q_i) * (Q_i - P_i)\n        \"\"\"\n        return (torch.exp(logits_q) * (logits_q - logits_p)).sum(1, keepdim=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _value_function(self, x_input, y_true, y_pred):\n        if len(y_true.shape) == 1:\n            return y_pred.argmax(1).eq(y_true).double().mean().item()\n        else:\n            raise NotImplementedError", "response": "Return classification accuracy of input"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate data in visdom on push", "response": "def on_epoch_end(self, epoch_info):\n        \"\"\" Update data in visdom on push \"\"\"\n        metrics_df = pd.DataFrame([epoch_info.result]).set_index('epoch_idx')\n\n        visdom_append_metrics(\n            self.vis,\n            metrics_df,\n            first_epoch=epoch_info.global_epoch_idx == 1\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef on_batch_end(self, batch_info):\n        if self.settings.stream_lr:\n            iteration_idx = (\n                    float(batch_info.epoch_number) +\n                    float(batch_info.batch_number) / batch_info.batches_per_epoch\n            )\n            \n            lr = batch_info.optimizer.param_groups[-1]['lr']\n\n            metrics_df = pd.DataFrame([lr], index=[iteration_idx], columns=['lr'])\n\n            visdom_append_metrics(\n                self.vis,\n                metrics_df,\n                first_epoch=(batch_info.epoch_number == 1) and (batch_info.batch_number == 0)\n            )", "response": "Stream LR to visdom"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef value(self, progress_indicator):\n        if progress_indicator <= self.end_of_interpolation:\n            return interpolate.interpolate_linear_single(\n                self.initial_value, self.final_value, progress_indicator/self.end_of_interpolation\n            )\n        else:\n            return self.final_value", "response": "Interpolate linearly between start and end of the calendar."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_seed(seed: int):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.random.manual_seed(seed)", "response": "Set random seed for python numpy and pytorch RNGs"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create(model: ModelFactory, discount_factor: float, target_update_frequency: int,\n           max_grad_norm: float, double_dqn: bool = False):\n    \"\"\" Vel factory function \"\"\"\n    return DistributionalDeepQLearning(\n        model_factory=model,\n        discount_factor=discount_factor,\n        double_dqn=double_dqn,\n        target_update_frequency=target_update_frequency,\n        max_grad_norm=max_grad_norm\n    )", "response": "Create a new DistributionalDeepQLearning object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninitializing the policy gradient from reinforcer settings", "response": "def initialize(self, training_info, model, environment, device):\n        \"\"\" Initialize policy gradient from reinforcer settings \"\"\"\n        self.target_model = self.model_factory.instantiate(action_space=environment.action_space).to(device)\n        self.target_model.load_state_dict(model.state_dict())\n        self.target_model.eval()\n\n        histogram_info = model.histogram_info()\n\n        self.vmin = histogram_info['vmin']\n        self.vmax = histogram_info['vmax']\n\n        self.num_atoms = histogram_info['num_atoms']\n\n        self.support_atoms = histogram_info['support_atoms']\n        self.atom_delta = histogram_info['atom_delta']"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the gradient of the given rollout", "response": "def calculate_gradient(self, batch_info, device, model, rollout):\n        \"\"\" Calculate loss of the supplied rollout \"\"\"\n        evaluator = model.evaluate(rollout)\n        batch_size = rollout.frames()\n\n        dones_tensor = evaluator.get('rollout:dones')\n        rewards_tensor = evaluator.get('rollout:rewards')\n\n        assert dones_tensor.dtype == torch.float32\n\n        with torch.no_grad():\n            target_evaluator = self.target_model.evaluate(rollout)\n\n            if self.double_dqn:\n                # DOUBLE DQN\n                # Histogram gets returned as logits initially, we need to exp it before projection\n                target_value_histogram_for_all_actions = target_evaluator.get('model:q_dist_next').exp()\n                model_value_histogram_for_all_actions = evaluator.get('model:q_dist_next').exp()\n\n                atoms_aligned = self.support_atoms.view(1, 1, self.num_atoms)\n\n                selected_action_indices = (\n                    (atoms_aligned * model_value_histogram_for_all_actions).sum(dim=-1).argmax(dim=1)\n                )\n\n                # Select largest 'target' value based on action that 'model' selects\n                next_value_histograms = (\n                    target_value_histogram_for_all_actions[range(batch_size), selected_action_indices]\n                )\n            else:\n                # REGULAR DQN\n                # Histogram gets returned as logits initially, we need to exp it before projection\n                target_value_histogram_for_all_actions = target_evaluator.get('model:q_dist_next').exp()\n\n                atoms_aligned = self.support_atoms.view(1, 1, self.num_atoms)\n\n                selected_action_indices = (\n                    (atoms_aligned * target_value_histogram_for_all_actions).sum(dim=-1).argmax(dim=1)\n                )\n\n                next_value_histograms = (\n                    target_value_histogram_for_all_actions[range(batch_size), selected_action_indices]\n                )\n\n            # HISTOGRAM PROJECTION CODE\n            forward_steps = rollout.extra_data.get('forward_steps', 1)\n\n            atoms_projected = (\n                rewards_tensor.unsqueeze(1) +\n                (self.discount_factor ** forward_steps) *\n                (1 - dones_tensor).unsqueeze(1) * self.support_atoms.unsqueeze(0)\n            )\n\n            atoms_projected = atoms_projected.clamp(min=self.vmin, max=self.vmax)\n            projection_indices = (atoms_projected - self.vmin) / self.atom_delta\n\n            index_floor = projection_indices.floor().long()\n            index_ceil = projection_indices.ceil().long()\n\n            # Fix corner case when index_floor == index_ceil\n            index_floor[(index_ceil > 0) * (index_floor == index_ceil)] -= 1\n            index_ceil[(index_floor < (self.num_atoms - 1)) * (index_floor == index_ceil)] += 1\n\n            value_histogram_projected = torch.zeros_like(next_value_histograms)\n\n            # Following part will be a bit convoluted, in an effort to fully vectorize projection operation\n\n            # Special offset index tensor\n            offsets = (\n                torch.arange(0, batch_size * self.num_atoms, self.num_atoms)\n                .unsqueeze(1)\n                .expand(batch_size, self.num_atoms)\n                .contiguous().view(-1).to(device)\n            )\n\n            # Linearize all the buffers\n            value_histogram_projected = value_histogram_projected.view(-1)\n            index_ceil = index_ceil.view(-1)\n            index_floor = index_floor.view(-1)\n            projection_indices = projection_indices.view(-1)\n\n            value_histogram_projected.index_add_(\n                0,\n                index_floor+offsets,\n                (next_value_histograms.view(-1) * (index_ceil.float() - projection_indices))\n            )\n\n            value_histogram_projected.index_add_(\n                0,\n                index_ceil+offsets,\n                (next_value_histograms.view(-1) * (projection_indices - index_floor.float()))\n            )\n\n            value_histogram_projected = value_histogram_projected.reshape(next_value_histograms.shape)\n\n        q_log_histogram_selected = evaluator.get('model:action:q_dist')\n\n        # Cross-entropy loss as usual\n        original_losses = -(value_histogram_projected * q_log_histogram_selected).sum(dim=1)\n\n        if evaluator.is_provided('rollout:weights'):\n            weights = evaluator.get('rollout:weights')\n        else:\n            weights = torch.ones_like(rewards_tensor)\n\n        loss_value = torch.mean(weights * original_losses)\n        loss_value.backward()\n\n        with torch.no_grad():\n            mean_q_model = (self.support_atoms.unsqueeze(0) * torch.exp(q_log_histogram_selected)).sum(dim=1).mean()\n            mean_q_target = (self.support_atoms.unsqueeze(0) * value_histogram_projected).sum(dim=1).mean()\n\n        return {\n            'loss': loss_value.item(),\n            # We need it to update priorities in the replay buffer:\n            'errors': original_losses.detach().cpu().numpy(),\n            'average_q_selected': mean_q_model.item(),\n            'average_q_target': mean_q_target.item()\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if new value is better than the old value", "response": "def better(old_value, new_value, mode):\n    \"\"\" Check if new value is better than the old value\"\"\"\n    if (old_value is None or np.isnan(old_value)) and (new_value is not None and not np.isnan(new_value)):\n        return True\n\n    if mode == 'min':\n        return new_value < old_value\n    elif mode == 'max':\n        return new_value > old_value\n    else:\n        raise RuntimeError(f\"Mode '{mode}' value is not supported\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreset weights to sane defaults", "response": "def reset_weights(self):\n        \"\"\" Initialize weights to sane defaults \"\"\"\n        init.uniform_(self.linear.weight, -3e-3, 3e-3)\n        init.zeros_(self.linear.bias)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef discount_bootstrap(rewards_buffer, dones_buffer, final_values, discount_factor, number_of_steps):\n    true_value_buffer = torch.zeros_like(rewards_buffer)\n\n    # discount/bootstrap off value fn\n    current_value = final_values\n\n    for i in reversed(range(number_of_steps)):\n        current_value = rewards_buffer[i] + discount_factor * current_value * (1.0 - dones_buffer[i])\n        true_value_buffer[i] = current_value\n\n    return true_value_buffer", "response": "Calculate the state values bootstrapping off the following state values"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef discount_bootstrap_gae(rewards_buffer, dones_buffer, values_buffer, final_values, discount_factor, gae_lambda,\n                           number_of_steps):\n    \"\"\"\n    Calculate state values bootstrapping off the following state values - Generalized Advantage Estimation\n    https://arxiv.org/abs/1506.02438\n    \"\"\"\n    advantage_buffer = torch.zeros_like(rewards_buffer)\n\n    # Accmulate sums\n    sum_accumulator = 0\n\n    for i in reversed(range(number_of_steps)):\n        if i == number_of_steps - 1:\n            next_value = final_values\n        else:\n            next_value = values_buffer[i + 1]\n\n        bellman_delta = (\n                rewards_buffer[i] + discount_factor * next_value * (1.0 - dones_buffer[i]) - values_buffer[i]\n        )\n\n        advantage_buffer[i] = sum_accumulator = (\n                bellman_delta + discount_factor * gae_lambda * sum_accumulator * (1.0 - dones_buffer[i])\n        )\n\n    return advantage_buffer", "response": "Calculates the bootstrapped state values for a single site."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a relatively raw atari environment.", "response": "def env_maker(environment_id, seed, serial_id, monitor=False, allow_early_resets=False, normalize_observations=False,\n              normalize_returns=False, normalize_gamma=0.99):\n    \"\"\" Create a relatively raw atari environment \"\"\"\n    env = gym.make(environment_id)\n    env.seed(seed + serial_id)\n\n    # Monitoring the env\n    if monitor:\n        logdir = logger.get_dir() and os.path.join(logger.get_dir(), str(serial_id))\n    else:\n        logdir = None\n\n    env = Monitor(env, logdir, allow_early_resets=allow_early_resets)\n\n    if normalize_observations or normalize_returns:\n        env = EnvNormalize(\n            env,\n            normalize_observations=normalize_observations,\n            normalize_returns=normalize_returns,\n            gamma=normalize_gamma\n        )\n\n    return env"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create(game, normalize_returns=False, settings=None, presets=None):\n    return MujocoEnv(\n        envname=game,\n        normalize_returns=normalize_returns,\n        settings=settings,\n        presets=presets\n    )", "response": "Create a new MujocoEnv object"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlocating top - level project directory.", "response": "def find_project_directory(start_path) -> str:\n        \"\"\" Locate top-level project directory  \"\"\"\n        start_path = os.path.realpath(start_path)\n        possible_name = os.path.join(start_path, ModelConfig.PROJECT_FILE_NAME)\n\n        if os.path.exists(possible_name):\n            return start_path\n        else:\n            up_path = os.path.realpath(os.path.join(start_path, '..'))\n            if os.path.realpath(start_path) == up_path:\n                raise RuntimeError(f\"Couldn't find project file starting from {start_path}\")\n            else:\n                return ModelConfig.find_project_directory(up_path)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a new model config from a file.", "response": "def from_file(cls, filename: str, run_number: int, continue_training: bool = False, seed: int = None,\n                  device: str = 'cuda', params=None):\n        \"\"\" Create model config from file \"\"\"\n        with open(filename, 'r') as fp:\n            model_config_contents = Parser.parse(fp)\n\n        project_config_path = ModelConfig.find_project_directory(os.path.dirname(os.path.abspath(filename)))\n\n        with open(os.path.join(project_config_path, cls.PROJECT_FILE_NAME), 'r') as fp:\n            project_config_contents = Parser.parse(fp)\n\n        aggregate_dictionary = {\n            **project_config_contents,\n            **model_config_contents\n        }\n\n        return ModelConfig(\n            filename=filename,\n            configuration=aggregate_dictionary,\n            run_number=run_number,\n            project_dir=project_config_path,\n            continue_training=continue_training,\n            seed=seed,\n            device=device,\n            parameters=params\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new model config from supplied data.", "response": "def from_memory(cls, model_data: dict, run_number: int, project_dir: str,\n                    continue_training=False, seed: int = None, device: str = 'cuda', params=None):\n        \"\"\" Create model config from supplied data \"\"\"\n        return ModelConfig(\n            filename=\"[memory]\",\n            configuration=model_data,\n            run_number=run_number,\n            project_dir=project_dir,\n            continue_training=continue_training,\n            seed=seed,\n            device=device,\n            parameters=params\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the path where to store the data for the current project.", "response": "def project_data_dir(self, *args) -> str:\n        \"\"\" Directory where to store data \"\"\"\n        return os.path.normpath(os.path.join(self.project_dir, 'data', *args))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the path where to store the log files", "response": "def output_dir(self, *args) -> str:\n        \"\"\" Directory where to store output \"\"\"\n        return os.path.join(self.project_dir, 'output', *args)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the path to the project top - level directory.", "response": "def project_top_dir(self, *args) -> str:\n        \"\"\" Project top-level directory \"\"\"\n        return os.path.join(self.project_dir, *args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a dependency - injected instance by name with default value.", "response": "def provide_with_default(self, name, default=None):\n        \"\"\" Return a dependency-injected instance \"\"\"\n        return self.provider.instantiate_by_name_with_default(name, default_value=default)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef banner(self, command_name) -> None:\n        import torch\n        device = self.torch_device()\n\n        print(\"=\" * 80)\n        print(f\"Pytorch version: {torch.__version__} cuda version {torch.version.cuda} cudnn version {torch.backends.cudnn.version()}\")\n        print(\"Running model {}, run {} -- command {} -- device {}\".format(self._model_name, self.run_number, command_name, self.device))\n        if device.type == 'cuda':\n            device_idx = 0 if device.index is None else device.index\n            print(f\"CUDA Device name {torch.cuda.get_device_name(device_idx)}\")\n        print(dtm.datetime.now().strftime(\"%Y/%m/%d - %H:%M:%S\"))\n        print(\"=\" * 80)", "response": "Print a banner for running the system"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef quit_banner(self) -> None:\n        print(\"=\" * 80)\n        print(\"Done.\")\n        print(dtm.datetime.now().strftime(\"%Y/%m/%d - %H:%M:%S\"))\n        print(\"=\" * 80)", "response": "Print a banner for running the system"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef benchmark_method(f):\n    \"decorator to turn f into a factory of benchmarks\"\n    @wraps(f)\n    def inner(name, *args, **kwargs):\n        return Benchmark(name, f, args, kwargs)\n    return inner", "response": "decorator to turn f into a factory of benchmarks"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbenchmark the get method for each of the participants", "response": "def bench(participants=participants, benchmarks=benchmarks,\n          bench_time=BENCH_TIME):\n    \"\"\"Do you even lift?\"\"\"\n\n    mcs = [p.factory() for p in participants]\n    means = [[] for p in participants]\n    stddevs = [[] for p in participants]\n\n    # Have each lifter do one benchmark each\n    last_fn = None\n    for benchmark_name, fn, args, kwargs in benchmarks:\n        logger.info('')\n        logger.info('%s', benchmark_name)\n\n        for i, (participant, mc) in enumerate(zip(participants, mcs)):\n\n            # FIXME: set before bench for get\n            if 'get' in fn.__name__:\n                last_fn(mc, *args, **kwargs)\n\n            sw = Stopwatch()\n            while sw.total() < bench_time:\n                with sw.timing():\n                    fn(mc, *args, **kwargs)\n\n            means[i].append(sw.mean())\n            stddevs[i].append(sw.stddev())\n\n            logger.info(u'%76s: %s', participant.name, sw)\n        last_fn = fn\n\n    return means, stddevs"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef streaming_market_filter(market_ids=None, bsp_market=None, betting_types=None, event_type_ids=None, event_ids=None,\n                            turn_in_play_enabled=None, market_types=None, venues=None, country_codes=None,\n                            race_types=None):\n    \"\"\"\n    :param list market_ids: filter market data to data pertaining to specific marketIds.\n    :param list event_type_ids: filter market data to data pertaining to specific event_type ids.\n    :param list event_ids: filter market data to data pertaining to specific event ids.\n    :param bool turn_in_play_enabled: restriction on whether market will turn in play or not, not supplied returns all.\n    :param list venues: restrict markets by venue (only horse racing has venue at the moment)\n    :param bool bsp_market: restriction on bsp, not supplied will return all.\n    :param list betting_types: filter on betting types\n    :param list market_types: filter market data by market types.\n    :param list country_codes: filter based on country codes\n    :param list race_types: filter race types\n\n    :return: dict\n    \"\"\"\n    args = locals()\n    return {\n        to_camel_case(k): v for k, v in args.items() if v is not None\n    }", "response": "filter out market data by market id event type id betting types country codes and race types"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfilters out non - None values from the given fields.", "response": "def streaming_market_data_filter(fields=None, ladder_levels=None):\n    \"\"\"\n    :param list fields: EX_BEST_OFFERS_DISP, EX_BEST_OFFERS, EX_ALL_OFFERS, EX_TRADED,\n    EX_TRADED_VOL, EX_LTP, EX_MARKET_DEF, SP_TRADED, SP_PROJECTED\n    :param int ladder_levels: 1->10\n\n    :return: dict\n    \"\"\"\n    args = locals()\n    return {\n        to_camel_case(k): v for k, v in args.items() if v is not None\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef streaming_order_filter(include_overall_position=None, customer_strategy_refs=None,\n                           partition_matched_by_strategy_ref=None):\n    \"\"\"\n    :param bool include_overall_position: Returns overall / net position (OrderRunnerChange.mb / OrderRunnerChange.ml)\n    :param list customer_strategy_refs: Restricts to specified customerStrategyRefs; this will filter orders and\n    StrategyMatchChanges accordingly (Note: overall postition is not filtered)\n    :param bool partition_matched_by_strategy_ref: Returns strategy positions (OrderRunnerChange.smc=\n    Map<customerStrategyRef, StrategyMatchChange>) - these are sent in delta format as per overall position.\n\n    :return: dict\n    \"\"\"\n    args = locals()\n    return {\n        to_camel_case(k): v for k, v in args.items() if v is not None\n    }", "response": "Filter out order items that are not present in the order queue."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts datetime to datetime", "response": "def time_range(from_=None, to=None):  # todo datetime conversion\n    \"\"\"\n    :param str from_:\n    :param str to:\n\n    :return: dict\n    \"\"\"\n    args = locals()\n    return {\n        k.replace('_', ''): v for k, v in args.items()\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfilters market data by text associated with it e. g. event type competition market ids and market ids.", "response": "def market_filter(text_query=None, event_type_ids=None, event_ids=None, competition_ids=None, market_ids=None,\n                  venues=None, bsp_only=None, turn_in_play_enabled=None, in_play_only=None, market_betting_types=None,\n                  market_countries=None, market_type_codes=None, market_start_time=None, with_orders=None,\n                  race_types=None):\n    \"\"\"\n    :param str text_query: restrict markets by text associated with it, e.g name, event, comp.\n    :param list event_type_ids: filter market data to data pertaining to specific event_type ids.\n    :param list event_ids: filter market data to data pertaining to specific event ids.\n    :param list competition_ids: filter market data to data pertaining to specific competition ids.\n    :param list market_ids: filter market data to data pertaining to specific marketIds.\n    :param list venues: restrict markets by venue (only horse racing has venue at the moment)\n    :param bool bsp_only: restriction on bsp, not supplied will return all.\n    :param bool turn_in_play_enabled: restriction on whether market will turn in play or not, not supplied returns all.\n    :param bool in_play_only: restriction to currently inplay, not supplied returns all.\n    :param list market_betting_types: filter market data by market betting types.\n    :param list market_countries: filter market data by country codes.\n    :param list market_type_codes: filter market data to match the type of market e.g. MATCH_ODDS.\n    :param dict market_start_time: filter market data by time at which it starts.\n    :param str with_orders: filter market data by specified order status.\n    :param list race_types: filter race types.\n\n    :return: dict\n    \"\"\"\n    args = locals()\n    return {\n        to_camel_case(k): v for k, v in args.items() if v is not None\n    }"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a price data filter list from all args passed as True.", "response": "def price_data(sp_available=False, sp_traded=False, ex_best_offers=False, ex_all_offers=False, ex_traded=False):\n    \"\"\"\n    Create PriceData filter list from all args passed as True.\n    :param bool sp_available: Amount available for the BSP auction.\n    :param bool sp_traded: Amount traded in the BSP auction.\n    :param bool ex_best_offers: Only the best prices available for each runner, to requested price depth.\n    :param bool ex_all_offers: trumps EX_BEST_OFFERS if both settings are present\n    :param bool ex_traded: Amount traded on the exchange.\n\n    :returns: string values of all args specified as True.\n    :rtype: list\n    \"\"\"\n    args = locals()\n    return [\n        k.upper() for k, v in args.items() if v is True\n    ]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ex_best_offers_overrides(best_prices_depth=None, rollup_model=None, rollup_limit=None,\n                             rollup_liability_threshold=None, rollup_liability_factor=None):\n    \"\"\"\n    Create filter to specify whether to accumulate market volume info, how deep a book to return and rollup methods if\n    accumulation is selected.\n    :param int best_prices_depth: The maximum number of prices to return on each side for each runner.\n    :param str rollup_model: method to use to accumulate market orders.\n    :param int rollup_limit: The volume limit to use when rolling up returned sizes. The exact definition of the limit\n    depends on the rollupModel.\n                        If no limit is provided it will use minimum stake\n    :param float rollup_liability_threshold: Only applicable when rollupModel is MANAGED_LIABILITY. The rollup model\n    switches from being stake based to liability based at the smallest lay price which is >= rollupLiabilityThreshold\n    :param int rollup_liability_factor: Only applicable when rollupModel is MANAGED_LIABILITY. (rollupLiabilityFactor *\n    rollupLimit) is the minimum liabilty the user is deemed to be comfortable with. After the rollupLiabilityThreshold\n    price subsequent volumes will be rolled up to minimum value such that the liability >= the minimum liability.\n\n    :returns: parameters for inclusion in market data requests.\n    :rtype: dict\n    \"\"\"\n\n    args = locals()\n    return {\n        to_camel_case(k): v for k, v in args.items() if v is not None\n    }", "response": "This filter is used to accumulate market volume info for each runner and rollup orders for each market volume."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a selection criteria for market data.", "response": "def price_projection(price_data=price_data(), ex_best_offers_overrides=ex_best_offers_overrides(), virtualise=True,\n                     rollover_stakes=False):\n    \"\"\"\n    Selection criteria of the returning price data.\n    :param list price_data: PriceData filter to specify what market data we wish to receive.\n    :param dict ex_best_offers_overrides: define order book depth, rollup method.\n    :param bool virtualise: whether to receive virtualised prices also.\n    :param bool rollover_stakes: whether to accumulate volume at each price as sum of volume at that price and all better\n    prices.\n\n    :returns: price data criteria for market data.\n    :rtype: dict\n    \"\"\"\n    args = locals()\n    return {\n        to_camel_case(k): v for k, v in args.items() if v is not None\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a dictionary of order instructions to place an order at exchange.", "response": "def place_instruction(order_type, selection_id, side, handicap=None, limit_order=None, limit_on_close_order=None,\n                      market_on_close_order=None, customer_order_ref=None):\n    \"\"\"\n    Create order instructions to place an order at exchange.\n    :param str order_type: define type of order to place.\n    :param int selection_id: selection on which to place order\n    :param float handicap: handicap if placing order on asianhandicap type market\n    :param str side: side of order\n    :param resources.LimitOrder limit_order: if orderType is a limitOrder structure details of the order.\n    :param resources.LimitOnCloseOrder limit_on_close_order: if orderType is a\n    limitOnCloseOrder structure details of the order.\n    :param resources.MarketOnCloseOrder market_on_close_order: if orderType is\n    a marketOnCloseOrder structure details of the order.\n    :param str customer_order_ref: an optional reference customers can set to identify instructions..\n\n    :return: orders to place.\n    :rtype: dict\n    \"\"\"\n\n    args = locals()\n    return {\n        to_camel_case(k): v for k, v in args.items() if v is not None\n    }"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef limit_order(price, persistence_type=None, size=None, time_in_force=None, min_fill_size=None, bet_target_type=None,\n                bet_target_size=None):\n    \"\"\"\n    Create a limit order to send to exchange.\n    :param float size: amount in account currency to be sent.\n    :param float price: price at which the order is to be sent.\n    :param str persistence_type: what happens to order at turn in play.\n    :param str time_in_force: specify if it is FillOrKill/FillAndKill. This value takes precedence over any\n    PersistenceType value chosen.\n    :param float min_fill_size: the minimum amount to be filled for FillAndKill.\n    :param str bet_target_type: Specify the type of Target, bet to certain backer profit or certain payout value.\n                          Used to adjust to lower stakes if filled at better levels.\n    :param float bet_target_size: Size of payout of profit to bet.\n\n    :returns: Order information to place a limit order.\n    :rtype: dict\n    \"\"\"\n    args = locals()\n    return {\n        to_camel_case(k): v for k, v in args.items() if v is not None\n    }", "response": "Create a limit order for the given amount of amount in account currency."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreplaces an order with a new price.", "response": "def replace_instruction(bet_id, new_price):\n    \"\"\"\n    Instruction to replace a LIMIT or LIMIT_ON_CLOSE order at a new price.\n    Original order will be cancelled and a new order placed at the new price for the remaining stake.\n    :param str bet_id: Unique identifier for the bet\n    :param float new_price: The price to replace the bet at\n\n    :returns: replace report detailing status, replace requested and actual replace details.\n    :rtype: dict\n    \"\"\"\n    args = locals()\n    return {\n        to_camel_case(k): v for k, v in args.items() if v is not None\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_instruction(bet_id, new_persistence_type):\n    args = locals()\n    return {\n        to_camel_case(k): v for k, v in args.items() if v is not None\n    }", "response": "Returns a dict of bet s persistence of an order that do not affect exposure\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting value to datetime if string or int. is a string or int. is an integer.", "response": "def strip_datetime(value):\n        \"\"\"\n        Converts value to datetime if string or int.\n        \"\"\"\n        if isinstance(value, basestring):\n            try:\n                return parse_datetime(value)\n            except ValueError:\n                return\n        elif isinstance(value, integer_types):\n            try:\n                return datetime.datetime.utcfromtimestamp(value / 1e3)\n            except (ValueError, OverflowError, OSError):\n                return"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the session token and new login time.", "response": "def set_session_token(self, session_token):\n        \"\"\"\n        Sets session token and new login time.\n\n        :param str session_token: Session token from request.\n        \"\"\"\n        self.session_token = session_token\n        self._login_time = datetime.datetime.now()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the password for the user.", "response": "def get_password(self):\n        \"\"\"\n        If password is not provided will look in environment variables\n        for username+'password'.\n        \"\"\"\n        if self.password is None:\n            if os.environ.get(self.username+'password'):\n                self.password = os.environ.get(self.username+'password')\n            else:\n                raise PasswordError(self.username)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_app_key(self):\n        if self.app_key is None:\n            if os.environ.get(self.username):\n                self.app_key = os.environ.get(self.username)\n            else:\n                raise AppKeyError(self.username)", "response": "Get the app key for the user."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if session has expired.", "response": "def session_expired(self):\n        \"\"\"\n        Returns True if login_time not set or seconds since\n        login time is greater than 200 mins.\n        \"\"\"\n        if not self._login_time or (datetime.datetime.now()-self._login_time).total_seconds() > 12000:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the path of the certificates in the betfair certificates in the ssl directory.", "response": "def cert(self):\n        \"\"\"\n        The betfair certificates, by default it looks for the\n        certificates in /certs/.\n\n        :return: Path of cert files\n        :rtype: str\n        \"\"\"\n        if self.cert_files is not None:\n            return self.cert_files\n\n        certs = self.certs or '/certs/'\n        ssl_path = os.path.join(os.pardir, certs)\n        try:\n            cert_path = os.listdir(ssl_path)\n        except FileNotFoundError:\n            raise CertsError(certs)\n        except OSError:   # Python 2 compatability\n            raise CertsError(certs)\n\n        cert = None\n        key = None\n        for file in cert_path:\n            ext = os.path.splitext(file)[-1]\n            if ext in ['.crt', '.cert']:\n                cert = os.path.join(ssl_path, file)\n            elif ext == '.key':\n                key = os.path.join(ssl_path, file)\n        if cert is None or key is None:\n            raise CertsError(certs)\n        return [cert, key]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget available to bet amount.", "response": "def get_account_funds(self, wallet=None, session=None, lightweight=None):\n        \"\"\"\n        Get available to bet amount.\n\n        :param str wallet: Name of the wallet in question\n        :param requests.session session: Requests session object\n        :param bool lightweight: If True will return dict not a resource\n\n        :rtype: resources.AccountFunds\n        \"\"\"\n        params = clean_locals(locals())\n        method = '%s%s' % (self.URI, 'getAccountFunds')\n        (response, elapsed_time) = self.request(method, params, session)\n        return self.process_response(response, resources.AccountFunds, elapsed_time, lightweight)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_account_details(self, session=None, lightweight=None):\n        params = clean_locals(locals())\n        method = '%s%s' % (self.URI, 'getAccountDetails')\n        (response, elapsed_time) = self.request(method, params, session)\n        return self.process_response(response, resources.AccountDetails, elapsed_time, lightweight)", "response": "Returns the details related to your account including your discount\n        rate and Betfair point balance."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_account_statement(self, locale=None, from_record=None, record_count=None, item_date_range=time_range(),\n                              include_item=None, wallet=None, session=None, lightweight=None):\n        \"\"\"\n        Get account statement.\n\n        :param str locale: The language to be used where applicable.\n        :param int from_record: Specifies the first record that will be returned\n        :param int record_count: Specifies the maximum number of records to be returned.\n        :param dict item_date_range: Return items with an itemDate within this date range.\n        :param str include_item: Which items to include, if not specified then defaults to ALL.\n        :param str wallet: Which wallet to return statementItems for.\n        :param requests.session session: Requests session object\n        :param bool lightweight: If True will return dict not a resource\n\n        :rtype: resources.AccountStatementResult\n        \"\"\"\n        params = clean_locals(locals())\n        method = '%s%s' % (self.URI, 'getAccountStatement')\n        (response, elapsed_time) = self.request(method, params, session)\n        return self.process_response(response, resources.AccountStatementResult, elapsed_time, lightweight)", "response": "Returns a dict of items for the account statement for the specified locale from_record record_count and include_item. If lightweight is True the response will be a resource object with the same value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_currency_rates(self, from_currency=None, session=None, lightweight=None):\n        params = clean_locals(locals())\n        method = '%s%s' % (self.URI, 'listCurrencyRates')\n        (response, elapsed_time) = self.request(method, params, session)\n        return self.process_response(response, resources.CurrencyRate, elapsed_time, lightweight)", "response": "Returns a list of currency rates based on given currency"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks response. status_code is in codes.", "response": "def check_status_code(response, codes=None):\n    \"\"\"\n    Checks response.status_code is in codes.\n\n    :param requests.request response: Requests response\n    :param list codes: List of accepted codes or callable\n    :raises: StatusCodeError if code invalid\n    \"\"\"\n    codes = codes or [200]\n    if response.status_code not in codes:\n        raise StatusCodeError(response.status_code)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncleans up locals dict remove empty and self session params params and convert to camelCase.", "response": "def clean_locals(data):\n    \"\"\"\n    Clean up locals dict, remove empty and self/session/params params\n    and convert to camelCase.\n\n    :param {} data: locals dicts from a function.\n    :returns: dict\n    \"\"\"\n    if data.get('params') is not None:\n        return data.get('params')\n    else:\n        return {\n            to_camel_case(k): v for k, v in data.items() if v is not None and k not in\n            ['self', 'session', 'params', 'lightweight']\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of Event Types associated with the markets .", "response": "def list_event_types(self, filter=market_filter(), locale=None, session=None, lightweight=None):\n        \"\"\"\n        Returns a list of Event Types (i.e. Sports) associated with the markets\n        selected by the MarketFilter.\n\n        :param dict filter: The filter to select desired markets\n        :param str locale: The language used for the response\n        :param requests.session session: Requests session object\n        :param bool lightweight: If True will return dict not a resource\n\n        :rtype: list[resources.EventTypeResult]\n        \"\"\"\n        params = clean_locals(locals())\n        method = '%s%s' % (self.URI, 'listEventTypes')\n        (response, elapsed_time) = self.request(method, params, session)\n        return self.process_response(response, resources.EventTypeResult, elapsed_time, lightweight)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_time_ranges(self, filter=market_filter(), granularity='DAYS', session=None, lightweight=None):\n        params = clean_locals(locals())\n        method = '%s%s' % (self.URI, 'listTimeRanges')\n        (response, elapsed_time) = self.request(method, params, session)\n        return self.process_response(response, resources.TimeRangeResult, elapsed_time, lightweight)", "response": "Returns a list of time ranges associated with the given markets."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_market_catalogue(self, filter=market_filter(), market_projection=None, sort=None, max_results=1,\n                              locale=None, session=None, lightweight=None):\n        \"\"\"\n        Returns a list of information about published (ACTIVE/SUSPENDED) markets\n        that does not change (or changes very rarely).\n\n        :param dict filter: The filter to select desired markets\n        :param list market_projection: The type and amount of data returned about the market\n        :param str sort: The order of the results\n        :param int max_results: Limit on the total number of results returned, must be greater\n        than 0 and less than or equal to 10000\n        :param str locale: The language used for the response\n        :param requests.session session: Requests session object\n        :param bool lightweight: If True will return dict not a resource\n\n        :rtype: list[resources.MarketCatalogue]\n        \"\"\"\n        params = clean_locals(locals())\n        method = '%s%s' % (self.URI, 'listMarketCatalogue')\n        (response, elapsed_time) = self.request(method, params, session)\n        return self.process_response(response, resources.MarketCatalogue, elapsed_time, lightweight)", "response": "Returns a list of published markets with the specified filter and optional sort and locale."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_runner_book(self, market_id, selection_id, handicap=None, price_projection=None, order_projection=None,\n                         match_projection=None, include_overall_position=None, partition_matched_by_strategy_ref=None,\n                         customer_strategy_refs=None, currency_code=None, matched_since=None, bet_ids=None, locale=None,\n                         session=None, lightweight=None):\n        \"\"\"\n        Returns a list of dynamic data about a market and a specified runner. \n        Dynamic data includes prices, the status of the market, the status of selections, \n        the traded volume, and the status of any orders you have placed in the market\n\n        :param unicode market_id: The unique id for the market\n        :param int selection_id: The unique id for the selection in the market\n        :param double handicap: The projection of price data you want to receive in the response\n        :param dict price_projection: The projection of price data you want to receive in the response\n        :param str order_projection: The orders you want to receive in the response\n        :param str match_projection: If you ask for orders, specifies the representation of matches\n        :param bool include_overall_position: If you ask for orders, returns matches for each selection\n        :param bool partition_matched_by_strategy_ref: If you ask for orders, returns the breakdown of matches\n        by strategy for each selection\n        :param list customer_strategy_refs: If you ask for orders, restricts the results to orders matching\n        any of the specified set of customer defined strategies\n        :param str currency_code: A Betfair standard currency code\n        :param str matched_since: If you ask for orders, restricts the results to orders that have at\n        least one fragment matched since the specified date\n        :param list bet_ids: If you ask for orders, restricts the results to orders with the specified bet IDs\n        :param str locale: The language used for the response\n        :param requests.session session: Requests session object\n        :param bool lightweight: If True will return dict not a resource\n\n        :rtype: list[resources.MarketBook]\n        \"\"\"\n        params = clean_locals(locals())\n        method = '%s%s' % (self.URI, 'listRunnerBook')\n        (response, elapsed_time) = self.request(method, params, session)\n        return self.process_response(response, resources.MarketBook, elapsed_time, lightweight)", "response": "Returns a list of dynamic data about a market and a specified runner."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_current_orders(self, bet_ids=None, market_ids=None, order_projection=None, customer_order_refs=None,\n                            customer_strategy_refs=None, date_range=time_range(), order_by=None, sort_dir=None,\n                            from_record=None, record_count=None, session=None, lightweight=None):\n        \"\"\"\n        Returns a list of your current orders.\n\n        :param list bet_ids: If you ask for orders, restricts the results to orders with the specified bet IDs\n        :param list market_ids: One or more market ids\n        :param str order_projection: Optionally restricts the results to the specified order status\n        :param list customer_order_refs: Optionally restricts the results to the specified customer order references\n        :param list customer_strategy_refs: Optionally restricts the results to the specified customer strategy\n        references\n        :param dict date_range: Optionally restricts the results to be from/to the specified date, these dates\n        are contextual to the orders being returned and therefore the dates used to filter on will change\n        to placed, matched, voided or settled dates depending on the orderBy\n        :param str order_by: Specifies how the results will be ordered. If no value is passed in, it defaults to BY_BET\n        :param str sort_dir: Specifies the direction the results will be sorted in\n        :param int from_record: Specifies the first record that will be returned\n        :param int record_count: Specifies how many records will be returned from the index position 'fromRecord'\n        :param requests.session session: Requests session object\n        :param bool lightweight: If True will return dict not a resource\n\n        :rtype: resources.CurrentOrders\n        \"\"\"\n        params = clean_locals(locals())\n        method = '%s%s' % (self.URI, 'listCurrentOrders')\n        (response, elapsed_time) = self.request(method, params, session)\n        return self.process_response(response, resources.CurrentOrders, elapsed_time, lightweight)", "response": "Returns a list of your current orders."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_cleared_orders(self, bet_status='SETTLED', event_type_ids=None, event_ids=None, market_ids=None,\n                            runner_ids=None, bet_ids=None, customer_order_refs=None, customer_strategy_refs=None,\n                            side=None, settled_date_range=time_range(), group_by=None, include_item_description=None,\n                            locale=None, from_record=None, record_count=None, session=None, lightweight=None):\n        \"\"\"\n        Returns a list of settled bets based on the bet status,\n        ordered by settled date.\n\n        :param str bet_status: Restricts the results to the specified status\n        :param list event_type_ids: Optionally restricts the results to the specified Event Type IDs\n        :param list event_ids: Optionally restricts the results to the specified Event IDs\n        :param list market_ids: Optionally restricts the results to the specified market IDs\n        :param list runner_ids: Optionally restricts the results to the specified Runners\n        :param list bet_ids: If you ask for orders, restricts the results to orders with the specified bet IDs\n        :param list customer_order_refs: Optionally restricts the results to the specified customer order references\n        :param list customer_strategy_refs: Optionally restricts the results to the specified customer strategy\n        references\n        :param str side: Optionally restricts the results to the specified side\n        :param dict settled_date_range: Optionally restricts the results to be from/to the specified settled date\n        :param str group_by: How to aggregate the lines, if not supplied then the lowest level is returned\n        :param bool include_item_description: If true then an ItemDescription object is included in the response\n        :param str locale: The language used for the response\n        :param int from_record: Specifies the first record that will be returned\n        :param int record_count: Specifies how many records will be returned from the index position 'fromRecord'\n        :param requests.session session: Requests session object\n        :param bool lightweight: If True will return dict not a resource\n\n        :rtype: resources.ClearedOrders\n        \"\"\"\n        params = clean_locals(locals())\n        method = '%s%s' % (self.URI, 'listClearedOrders')\n        (response, elapsed_time) = self.request(method, params, session)\n        return self.process_response(response, resources.ClearedOrders, elapsed_time, lightweight)", "response": "Returns a list of settled bets based on the bet status event type market strategy and side."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn profit and loss for a given list of markets.", "response": "def list_market_profit_and_loss(self, market_ids, include_settled_bets=None, include_bsp_bets=None,\n                                    net_of_commission=None, session=None, lightweight=None):\n        \"\"\"\n        Retrieve profit and loss for a given list of OPEN markets.\n\n        :param list market_ids: List of markets to calculate profit and loss\n        :param bool include_settled_bets: Option to include settled bets (partially settled markets only)\n        :param bool include_bsp_bets: Option to include BSP bets\n        :param bool net_of_commission: Option to return profit and loss net of users current commission\n        rate for this market including any special tariffs\n        :param requests.session session: Requests session object\n        :param bool lightweight: If True will return dict not a resource\n\n        :rtype: list[resources.MarketProfitLoss]\n        \"\"\"\n        params = clean_locals(locals())\n        method = '%s%s' % (self.URI, 'listMarketProfitAndLoss')\n        (response, elapsed_time) = self.request(method, params, session)\n        return self.process_response(response, resources.MarketProfitLoss, elapsed_time, lightweight)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef place_orders(self, market_id, instructions, customer_ref=None, market_version=None,\n                     customer_strategy_ref=None, async_=None, session=None, lightweight=None):\n        \"\"\"\n        Place new orders into market.\n\n        :param str market_id: The market id these orders are to be placed on\n        :param list instructions: The number of place instructions\n        :param str customer_ref: Optional parameter allowing the client to pass a unique string\n        (up to 32 chars) that is used to de-dupe mistaken re-submissions\n        :param dict market_version: Optional parameter allowing the client to specify which\n        version of the market the orders should be placed on, e.g. \"{'version': 123456}\"\n        :param str customer_strategy_ref: An optional reference customers can use to specify\n        which strategy has sent the order\n        :param bool async_: An optional flag (not setting equates to false) which specifies if\n        the orders should be placed asynchronously\n        :param requests.session session: Requests session object\n        :param bool lightweight: If True will return dict not a resource\n\n        :rtype: resources.PlaceOrders\n        \"\"\"\n        params = clean_locals(locals())\n        method = '%s%s' % (self.URI, 'placeOrders')\n        (response, elapsed_time) = self.request(method, params, session)\n        return self.process_response(response, resources.PlaceOrders, elapsed_time, lightweight)", "response": "Place new orders into market."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncancels all bets or partially or partially - identified orders on a market.", "response": "def cancel_orders(self, market_id=None, instructions=None, customer_ref=None, session=None, lightweight=None):\n        \"\"\"\n        Cancel all bets OR cancel all bets on a market OR fully or partially\n        cancel particular orders on a market.\n\n        :param str market_id: If marketId and betId aren't supplied all bets are cancelled\n        :param list instructions: All instructions need to be on the same market\n        :param str customer_ref: Optional parameter allowing the client to pass a unique\n        string (up to 32 chars) that is used to de-dupe mistaken re-submissions\n        :param requests.session session: Requests session object\n        :param bool lightweight: If True will return dict not a resource\n\n        :rtype: resources.CancelOrders\n        \"\"\"\n        params = clean_locals(locals())\n        method = '%s%s' % (self.URI, 'cancelOrders')\n        (response, elapsed_time) = self.request(method, params, session)\n        return self.process_response(response, resources.CancelOrders, elapsed_time, lightweight)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef replace_orders(self, market_id, instructions, customer_ref=None, market_version=None,\n                       async_=None, session=None, lightweight=None):\n        \"\"\"\n        This operation is logically a bulk cancel followed by a bulk place.\n        The cancel is completed first then the new orders are placed.\n\n        :param str market_id: The market id these orders are to be placed on\n        :param list instructions: The number of replace instructions.  The limit\n        of replace instructions per request is 60\n        :param str customer_ref: Optional parameter allowing the client to pass a unique\n        string (up to 32 chars) that is used to de-dupe mistaken re-submissions\n        :param dict market_version: Optional parameter allowing the client to specify\n        which version of the market the orders should be placed on, e.g. \"{'version': 123456}\"\n        :param bool async_: An optional flag (not setting equates to false) which specifies\n        if the orders should be replaced asynchronously\n        :param requests.session session: Requests session object\n        :param bool lightweight: If True will return dict not a resource\n\n        :rtype: resources.ReplaceOrders\n        \"\"\"\n        params = clean_locals(locals())\n        method = '%s%s' % (self.URI, 'replaceOrders')\n        (response, elapsed_time) = self.request(method, params, session)\n        return self.process_response(response, resources.ReplaceOrders, elapsed_time, lightweight)", "response": "This operation replaces the orders in the specified market with the given instructions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate the traded list.", "response": "def update_traded(self, traded_update):\n        \"\"\":param traded_update: [price, size]\n        \"\"\"\n        if not traded_update:\n            self.traded.clear()\n        else:\n            self.traded.update(traded_update)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef serialise(self):\n        return {\n            'marketId': self.market_id,\n            'totalAvailable': None,\n            'isMarketDataDelayed': None,\n            'lastMatchTime': None,\n            'betDelay': self.market_definition.get('betDelay'),\n            'version': self.market_definition.get('version'),\n            'complete': self.market_definition.get('complete'),\n            'runnersVoidable': self.market_definition.get('runnersVoidable'),\n            'totalMatched': self.total_matched,\n            'status': self.market_definition.get('status'),\n            'bspReconciled': self.market_definition.get('bspReconciled'),\n            'crossMatching': self.market_definition.get('crossMatching'),\n            'inplay': self.market_definition.get('inPlay'),\n            'numberOfWinners': self.market_definition.get('numberOfWinners'),\n            'numberOfRunners': len(self.market_definition.get('runners')),\n            'numberOfActiveRunners': self.market_definition.get('numberOfActiveRunners'),\n            'runners': [\n                runner.serialise(\n                    self.market_definition_runner_dict[(runner.selection_id, runner.handicap)]\n                ) for runner in self.runners\n            ],\n            'publishTime': self.publish_time,\n            'priceLadderDefinition': self.market_definition.get('priceLadderDefinition'),\n            'keyLineDescription': self.market_definition.get('keyLineDefinition'),\n            'marketDefinition': self.market_definition,  # used in lightweight\n        }", "response": "Serialises the market book json response"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsearch for races to get their details.", "response": "def list_race_details(self, meeting_ids=None, race_ids=None, session=None, lightweight=None):\n        \"\"\"\n        Search for races to get their details.\n\n        :param dict meeting_ids: Optionally restricts the results to the specified meeting IDs.\n        The unique Id for the meeting equivalent to the eventId for that specific race as\n        returned by listEvents\n        :param str race_ids: Optionally restricts the results to the specified race IDs. The\n        unique Id for the race in the format meetingid.raceTime (hhmm). raceTime is in GMT\n        :param requests.session session: Requests session object\n        :param bool lightweight: If True will return dict not a resource\n\n        :rtype: list[resources.RaceDetail]\n        \"\"\"\n        params = clean_locals(locals())\n        method = '%s%s' % (self.URI, 'listRaceDetails')\n        (response, elapsed_time) = self.request(method, params, session)\n        return self.process_response(response, resources.RaceDetails, elapsed_time, lightweight)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of available events.", "response": "def list_available_events(self, event_ids=None, event_type_ids=None, event_status=None, session=None,\n                              lightweight=None):\n        \"\"\"\n        Search for events that have live score data available.\n\n        :param list event_ids: Optionally restricts the results to the specified event IDs\n        :param list event_type_ids: Optionally restricts the results to the specified event type IDs\n        :param list event_status: Optionally restricts the results to the specified event status\n        :param requests.session session: Requests session object\n        :param bool lightweight: If True will return dict not a resource\n\n        :rtype: list[resources.AvailableEvent]\n        \"\"\"\n        params = clean_locals(locals())\n        method = '%s%s' % (self.URI, 'listAvailableEvents')\n        (response, elapsed_time) = self.request(method, params, session)\n        return self.process_response(response, resources.AvailableEvent, elapsed_time, lightweight)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_scores(self, update_keys, session=None, lightweight=None):\n        params = clean_locals(locals())\n        method = '%s%s' % (self.URI, 'listScores')\n        (response, elapsed_time) = self.request(method, params, session)\n        return self.process_response(response, resources.Score, elapsed_time, lightweight)", "response": "Returns a list of scores for the given events."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_incidents(self, update_keys, session=None, lightweight=None):\n        params = clean_locals(locals())\n        method = '%s%s' % (self.URI, 'listIncidents')\n        (response, elapsed_time) = self.request(method, params, session)\n        return self.process_response(response, resources.Incidents, elapsed_time, lightweight)", "response": "Returns a list of incidents for the given events."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget event timeline for event id provided.", "response": "def get_event_timeline(self, event_id, session=None, lightweight=None):\n        \"\"\"\n        Returns event timeline for event id provided.\n\n        :param int event_id: Event id to return\n        :param requests.session session: Requests session object\n        :param bool lightweight: If True will return dict not a resource\n\n        :rtype: resources.EventTimeline\n        \"\"\"\n        url = '%s%s' % (self.url, 'eventTimeline')\n        params = {\n            'eventId': event_id,\n            'alt': 'json',\n            'regionCode': 'UK',\n            'locale': 'en_GB'\n        }\n        (response, elapsed_time) = self.request(params=params, session=session, url=url)\n        return self.process_response(response, resources.EventTimeline, elapsed_time, lightweight)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_event_timelines(self, event_ids, session=None, lightweight=None):\n        url = '%s%s' % (self.url, 'eventTimelines')\n        params = {\n            'eventIds': ','.join(str(x) for x in event_ids),\n            'alt': 'json',\n            'regionCode': 'UK',\n            'locale': 'en_GB'\n        }\n        (response, elapsed_time) = self.request(params=params, session=session, url=url)\n        return self.process_response(response, resources.EventTimeline, elapsed_time, lightweight)", "response": "Returns a list of event timelines based on event id s."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of scores based on event id s.", "response": "def get_scores(self, event_ids, session=None, lightweight=None):\n        \"\"\"\n        Returns a list of scores based on event id's\n        supplied.\n\n        :param list event_ids: List of event id's to return\n        :param requests.session session: Requests session object\n        :param bool lightweight: If True will return dict not a resource\n\n        :rtype: list[resources.Scores]\n        \"\"\"\n        url = '%s%s' % (self.url, 'scores')\n        params = {\n            'eventIds': ','.join(str(x) for x in event_ids),\n            'alt': 'json',\n            'regionCode': 'UK',\n            'locale': 'en_GB'\n        }\n        (response, elapsed_time) = self.request(params=params, session=session, url=url)\n        return self.process_response(response, resources.Scores, elapsed_time, lightweight)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_stream(self, unique_id=0, listener=None, timeout=11, buffer_size=1024, description='BetfairSocket',\n                      host=None):\n        \"\"\"\n        Creates BetfairStream.\n\n        :param dict unique_id: Id used to start unique id's of the stream (+1 before every request)\n        :param resources.Listener listener:  Listener class to use\n        :param float timeout: Socket timeout\n        :param int buffer_size: Socket buffer size\n        :param str description: Betfair stream description\n        :param str host: Host endpoint (prod (default) or integration)\n\n        :rtype: BetfairStream\n        \"\"\"\n        listener = listener if listener else BaseListener()\n        return BetfairStream(\n            unique_id,\n            listener,\n            app_key=self.client.app_key,\n            session_token=self.client.session_token,\n            timeout=timeout,\n            buffer_size=buffer_size,\n            description=description,\n            host=host,\n        )", "response": "Creates a new BetfairStream object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_historical_stream(directory, listener=None):\n        listener = listener if listener else BaseListener()\n        listener.register_stream('HISTORICAL', 'marketSubscription')\n        return HistoricalStream(directory, listener)", "response": "Create a new stream for reading betfair data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_my_data(self, session=None):\n        params = clean_locals(locals())\n        method = 'GetMyData'\n        (response, elapsed_time) = self.request(method, params, session)\n        return response", "response": "Returns a list of data descriptions for data which has been purchased by the signed in user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the size of the data for a specific sport plan from_day to_month to_year.", "response": "def get_data_size(self, sport, plan, from_day, from_month, from_year, to_day, to_month, to_year, event_id=None,\n                      event_name=None, market_types_collection=None, countries_collection=None,\n                      file_type_collection=None, session=None):\n        \"\"\"\n        Returns a dictionary of file count and combines size files.\n\n        :param sport: sport to filter data for.\n        :param plan: plan type to filter for, Basic Plan, Advanced Plan or Pro Plan.\n        :param from_day: day of month to start data from.\n        :param from_month: month to start data from.\n        :param from_year: year to start data from.\n        :param to_day: day of month to end data at.\n        :param to_month: month to end data at.\n        :param to_year: year to end data at.\n        :param event_id: id of a specific event to get data for.\n        :param event_name: name of a specific event to get data for.\n        :param market_types_collection: list of specific marketTypes to filter for.\n        :param countries_collection: list of countries to filter for.\n        :param file_type_collection: list of file types.\n        :param requests.session session: Requests session object\n\n        :rtype: dict\n        \"\"\"\n        params = clean_locals(locals())\n        method = 'GetAdvBasketDataSize'\n        (response, elapsed_time) = self.request(method, params, session)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndownloads a file from betfair historical and store in given directory or current directory.", "response": "def download_file(self, file_path, store_directory=None):\n        \"\"\"\n        Download a file from betfair historical and store in given directory or current directory.\n        \n        :param file_path: the file path as given by get_file_list method.\n        :param store_directory: directory path to store data files in.\n        :return: name of file.\n        \"\"\"\n        local_filename = file_path.split('/')[-1]\n        if store_directory:\n            local_filename = os.path.join(store_directory, local_filename)\n        r = requests.get(\n            '%s%s' % (self.url, 'DownloadFile'),\n            params={'filePath': file_path},\n            headers=self.headers,\n            stream=True,\n        )\n        with open(local_filename, 'wb') as f:\n            for chunk in r.iter_content(chunk_size=1024):\n                if chunk:\n                    f.write(chunk)\n        return local_filename"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlogin to betfair exchange site.", "response": "def login(self, session=None):\n        \"\"\"\n        Parses app key from betfair exchange site.\n\n        :param requests.session session: Requests session object\n        \"\"\"\n        session = session or self.client.session\n        try:\n            response = session.get(self.login_url)\n        except ConnectionError:\n            raise APIError(None, self.login_url, None, 'ConnectionError')\n        except Exception as e:\n            raise APIError(None, self.login_url, None, e)\n        app_key = re.findall(r'''\"appKey\":\\s\"(.*?)\"''', response.text)\n        if app_key:\n            self.app_key = app_key[0]\n        else:\n            raise RaceCardError(\"Unable to find appKey\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_race_card(self, market_ids, data_entries=None, session=None, lightweight=None):\n        if not self.app_key:\n            raise RaceCardError(\"You need to login before requesting a race_card\\n\"\n                                \"APIClient.race_card.login()\")\n        params = self.create_race_card_req(market_ids, data_entries)\n        (response, elapsed_time) = self.request(params=params, session=session)\n        return self.process_response(response, resources.RaceCard, elapsed_time, lightweight)", "response": "Returns a list of resources. RaceCard objects based on market ids provided."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalling when raw data is received from the connection.", "response": "def on_data(self, raw_data):\n        \"\"\"Called when raw data is received from connection.\n        Override this method if you wish to manually handle\n        the stream data\n\n        :param raw_data: Received raw data\n        :return: Return False to stop stream and close connection\n        \"\"\"\n        try:\n            data = json.loads(raw_data)\n        except ValueError:\n            logger.error('value error: %s' % raw_data)\n            return\n\n        unique_id = data.get('id')\n\n        if self._error_handler(data, unique_id):\n            return False\n\n        operation = data['op']\n        if operation == 'connection':\n            self._on_connection(data, unique_id)\n        elif operation == 'status':\n            self._on_status(data, unique_id)\n        elif operation in ['mcm', 'ocm']:\n            # historic data does not contain unique_id\n            if self.stream_unique_id not in [unique_id, 'HISTORICAL']:\n                logger.warning('Unwanted data received from uniqueId: %s, expecting: %s' %\n                               (unique_id, self.stream_unique_id))\n                return\n            self._on_change_message(data, unique_id)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _on_connection(self, data, unique_id):\n        if unique_id is None:\n            unique_id = self.stream_unique_id\n        self.connection_id = data.get('connectionId')\n        logger.info('[Connect: %s]: connection_id: %s' % (unique_id, self.connection_id))", "response": "Called when a connection is received from the server"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalls when the status of the resource is received", "response": "def _on_status(data, unique_id):\n        \"\"\"Called on status operation\n\n        :param data: Received data\n        \"\"\"\n        status_code = data.get('statusCode')\n        logger.info('[Subscription: %s]: %s' % (unique_id, status_code))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _error_handler(data, unique_id):\n        if data.get('statusCode') == 'FAILURE':\n            logger.error('[Subscription: %s] %s: %s' % (unique_id, data.get('errorCode'), data.get('errorMessage')))\n            if data.get('connectionClosed'):\n                return True\n        if data.get('status'):\n            # Clients shouldn't disconnect if status 503 is returned; when the stream\n            # recovers updates will be sent containing the latest data\n            logger.warning('[Subscription: %s] status: %s' % (unique_id, data['status']))", "response": "Called when data first received from the server returns False if error present\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstart the read loop if not already running.", "response": "def start(self, async_=False):\n        \"\"\"Starts read loop, new thread if async and\n        connects/authenticates if not already running.\n\n        :param async_: If True new thread is started\n        \"\"\"\n        if not self._running:\n            self._connect()\n            self.authenticate()\n        if async_:\n            t = threading.Thread(name=self.description, target=self._read_loop)\n            t.daemon = False\n            t.start()\n        else:\n            self._read_loop()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef stop(self):\n        self._running = False\n\n        if self._socket is None:\n            return\n        try:\n            self._socket.shutdown(socket.SHUT_RDWR)\n            self._socket.close()\n        except socket.error:\n            pass\n        self._socket = None", "response": "Stops read loop and closes socket if it has been created."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef heartbeat(self):\n        unique_id = self.new_unique_id()\n        message = {\n            'op': 'heartbeat',\n            'id': unique_id,\n        }\n        self._send(message)\n        return unique_id", "response": "Heartbeat request to keep session alive."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef subscribe_to_markets(self, market_filter, market_data_filter, initial_clk=None, clk=None,\n                             conflate_ms=None, heartbeat_ms=None, segmentation_enabled=True):\n        \"\"\"\n        Market subscription request.\n\n        :param dict market_filter: Market filter\n        :param dict market_data_filter: Market data filter\n        :param str initial_clk: Sequence token for reconnect\n        :param str clk: Sequence token for reconnect\n        :param int conflate_ms: conflation rate (bounds are 0 to 120000)\n        :param int heartbeat_ms: heartbeat rate (500 to 5000)\n        :param bool segmentation_enabled: allow the server to send large sets of data\n        in segments, instead of a single block\n        \"\"\"\n        unique_id = self.new_unique_id()\n        message = {\n            'op': 'marketSubscription',\n            'id': unique_id,\n            'marketFilter': market_filter,\n            'marketDataFilter': market_data_filter,\n            'initialClk': initial_clk,\n            'clk': clk,\n            'conflateMs': conflate_ms,\n            'heartbeatMs': heartbeat_ms,\n            'segmentationEnabled': segmentation_enabled,\n        }\n        if initial_clk and clk:\n            # if resubscribe only update unique_id\n            self.listener.stream_unique_id = unique_id\n        else:\n            self.listener.register_stream(unique_id, 'marketSubscription')\n        self._send(message)\n        return unique_id", "response": "Subscribe to a set of market data segments."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef subscribe_to_orders(self, order_filter=None, initial_clk=None, clk=None, conflate_ms=None,\n                            heartbeat_ms=None, segmentation_enabled=True):\n        \"\"\"\n        Order subscription request.\n\n        :param dict order_filter: Order filter to be applied\n        :param str initial_clk: Sequence token for reconnect\n        :param str clk: Sequence token for reconnect\n        :param int conflate_ms: conflation rate (bounds are 0 to 120000)\n        :param int heartbeat_ms: heartbeat rate (500 to 5000)\n        :param bool segmentation_enabled: allow the server to send large sets of data\n        in segments, instead of a single block\n        \"\"\"\n        unique_id = self.new_unique_id()\n        message = {\n            'op': 'orderSubscription',\n            'id': unique_id,\n            'orderFilter': order_filter,\n            'initialClk': initial_clk,\n            'clk': clk,\n            'conflateMs': conflate_ms,\n            'heartbeatMs': heartbeat_ms,\n            'segmentationEnabled': segmentation_enabled,\n        }\n        if initial_clk and clk:\n            # if resubscribe only update unique_id\n            self.listener.stream_unique_id = unique_id\n        else:\n            self.listener.register_stream(unique_id, 'orderSubscription')\n        self._send(message)\n        return unique_id", "response": "Subscribe to the order."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates ssl socket connects to stream api and sets timeout.", "response": "def _create_socket(self):\n        \"\"\"Creates ssl socket, connects to stream api and\n        sets timeout.\n        \"\"\"\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        s = ssl.wrap_socket(s)\n        s.connect((self.host, self.__port))\n        s.settimeout(self.timeout)\n        return s"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _read_loop(self):\n        while self._running:\n            received_data_raw = self._receive_all()\n            if self._running:\n                self.receive_count += 1\n                self.datetime_last_received = datetime.datetime.utcnow()\n                received_data_split = received_data_raw.split(self.__CRLF)\n                for received_data in received_data_split:\n                    if received_data:\n                        self._data(received_data)", "response": "Read loop splits by CRLF and pushes received data to _data."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _receive_all(self):\n        (data, part) = ('', '')\n        if is_py3:\n            crlf_bytes = bytes(self.__CRLF, encoding=self.__encoding)\n        else:\n            crlf_bytes = self.__CRLF\n\n        while self._running and part[-2:] != crlf_bytes:\n            try:\n                part = self._socket.recv(self.buffer_size)\n            except (socket.timeout, socket.error) as e:\n                if self._running:\n                    self.stop()\n                    raise SocketError('[Connect: %s]: Socket %s' % (self._unique_id, e))\n                else:\n                    return  # 133, prevents error if stop is called mid recv\n\n            # an empty string indicates the server shutdown the socket\n            if len(part) == 0:\n                self.stop()\n                raise SocketError('Connection closed by server')\n\n            data += part.decode(self.__encoding)\n        return data", "response": "Receive all data from socket till CRLF is detected."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _data(self, received_data):\n        if self.listener.on_data(received_data) is False:\n            self.stop()\n            raise ListenerError(self.listener.connection_id, received_data)", "response": "Sends data to listener if False is returned ; socket\n        is closed."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend a message to the Betfair server.", "response": "def _send(self, message):\n        \"\"\"If not running connects socket and\n        authenticates. Adds CRLF and sends message\n        to Betfair.\n\n        :param message: Data to be sent to Betfair.\n        \"\"\"\n        if not self._running:\n            self._connect()\n            self.authenticate()\n        message_dumped = json.dumps(message) + self.__CRLF\n        try:\n            self._socket.send(message_dumped.encode())\n        except (socket.timeout, socket.error) as e:\n            self.stop()\n            raise SocketError('[Connect: %s]: Socket %s' % (self._unique_id, e))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsending a request to the API.", "response": "def request(self, method, params, session):\n        \"\"\"\n        :param str method: Betfair api-ng method to be used.\n        :param dict params: Params to be used in request\n        :param Session session: Requests session to be used, reduces latency.\n        \"\"\"\n        session = session or self.client.session\n        request = self.create_req(method, params)\n        date_time_sent = datetime.datetime.utcnow()\n        try:\n            response = session.post(\n                self.url,\n                data=request,\n                headers=self.client.request_headers,\n                timeout=(self.connect_timeout, self.read_timeout)\n            )\n        except ConnectionError:\n            raise APIError(None, method, params, 'ConnectionError')\n        except Exception as e:\n            raise APIError(None, method, params, e)\n        elapsed_time = (datetime.datetime.utcnow()-date_time_sent).total_seconds()\n\n        check_status_code(response)\n        try:\n            response_data = response.json()\n        except ValueError:\n            raise InvalidResponse(response.text)\n\n        if self._error_handler:\n            self._error_handler(response_data, method, params)\n        return response_data, elapsed_time"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef process_response(self, response_json, resource, elapsed_time, lightweight):\n        if isinstance(response_json, list):\n            result = response_json\n        else:\n            result = response_json.get('result', response_json)\n\n        if lightweight:\n            return result\n        elif self.client.lightweight and lightweight is not False:\n            return result\n        elif isinstance(result, list):\n            try:\n                return [resource(elapsed_time=elapsed_time, **x) for x in result]\n            except TypeError:\n                raise InvalidResponse(response=result)\n        else:\n            try:\n                return resource(elapsed_time=elapsed_time, **result)\n            except TypeError:\n                raise InvalidResponse(response=result)", "response": "Process the response from the API and return the resource data structure."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfitting the model to the data X and y.", "response": "def fit(self, X, y=None, **fit_params):\n        \"\"\"\n        Fit the model\n\n        Fit all the transforms one after the other and transform the\n        data, then fit the transformed data using the final estimator.\n\n        Parameters\n        ----------\n        X : iterable\n            Training data. Must fulfill input requirements of first step of the\n            pipeline.\n        y : iterable, default=None\n            Training targets. Must fulfill label requirements for all steps of\n            the pipeline.\n        **fit_params : dict of string -> object\n            Parameters passed to the ``fit`` method of each step, where\n            each parameter name is prefixed such that parameter ``p`` for step\n            ``s`` has key ``s__p``.\n\n        Returns\n        -------\n        self : Pipeline\n            This estimator\n        \"\"\"\n        Xt, yt, fit_params = self._fit(X, y, **fit_params)\n\n        self.N_train = len(yt)\n\n        if self._final_estimator is not None:\n            fitres = self._final_estimator.fit(Xt, yt, **fit_params)\n            if hasattr(fitres, 'history'):\n                self.history = fitres\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\napply transforms and transform with the final estimator.", "response": "def transform(self, X, y=None):\n        \"\"\"\n        Apply transforms, and transform with the final estimator\n        This also works where final estimator is ``None``: all prior\n        transformations are applied.\n\n        Parameters\n        ----------\n        X : iterable\n            Data to transform. Must fulfill input requirements of first step\n            of the pipeline.\n        y : array-like\n            Target\n\n        Returns\n        -------\n        Xt : array-like, shape = [n_samples, n_transformed_features]\n            Transformed data\n        yt : array-like, shape = [n_samples]\n            Transformed target\n        \"\"\"\n        Xt, yt, _ = self._transform(X, y)\n\n        if isinstance(self._final_estimator, XyTransformerMixin):\n            Xt, yt, _ = self._final_estimator.transform(Xt, yt)\n        else:\n            Xt = self._final_estimator.transform(Xt)\n\n        return Xt, yt"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfit the model and transform with the final estimator.", "response": "def fit_transform(self, X, y=None, **fit_params):\n        \"\"\"\n        Fit the model and transform with the final estimator\n        Fits all the transforms one after the other and transforms the\n        data, then uses fit_transform on transformed data with the final\n        estimator.\n\n        Parameters\n        ----------\n        X : iterable\n            Training data. Must fulfill input requirements of first step of the\n            pipeline.\n        y : iterable, default=None\n            Training targets. Must fulfill label requirements for all steps of\n            the pipeline.\n        **fit_params : dict of string -> object\n            Parameters passed to the ``fit`` method of each step, where\n            each parameter name is prefixed such that parameter ``p`` for step\n            ``s`` has key ``s__p``.\n\n        Returns\n        -------\n        Xt : array-like, shape = [n_samples, n_transformed_features]\n            Transformed samples\n        yt : array-like, shape = [n_samples]\n            Transformed target\n        \"\"\"\n\n        Xt, yt, fit_params = self._fit(X, y, **fit_params)\n\n        if isinstance(self._final_estimator, XyTransformerMixin):\n            Xt, yt, _ = self._final_estimator.fit_transform(Xt, yt)\n        else:\n            if hasattr(self._final_estimator, 'fit_transform'):\n                Xt = self._final_estimator.fit_transform(Xt, yt)\n            else:\n                self._final_estimator.fit(Xt, yt)\n                Xt = self._final_estimator.transform(Xt)\n\n        self.N_fit = len(yt)\n\n        return Xt, yt"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npredicting the target of the target with the final estimator.", "response": "def predict(self, X):\n        \"\"\"\n        Apply transforms to the data, and predict with the final estimator\n\n        Parameters\n        ----------\n        X : iterable\n            Data to predict on. Must fulfill input requirements of first step\n            of the pipeline.\n\n        Returns\n        -------\n        yp : array-like\n            Predicted transformed target\n        \"\"\"\n        Xt, _, _ = self._transform(X)\n        return self._final_estimator.predict(Xt)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef transform_predict(self, X, y):\n        Xt, yt, _ = self._transform(X, y)\n        yp = self._final_estimator.predict(Xt)\n        return yt, yp", "response": "Apply transforms to the data and predict with the final estimator."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\napplies transforms and score with the final estimator and returns the score.", "response": "def score(self, X, y=None, sample_weight=None):\n        \"\"\"\n        Apply transforms, and score with the final estimator\n\n        Parameters\n        ----------\n        X : iterable\n            Data to predict on. Must fulfill input requirements of first step\n            of the pipeline.\n        y : iterable, default=None\n            Targets used for scoring. Must fulfill label requirements for all\n            steps of the pipeline.\n        sample_weight : array-like, default=None\n            If not None, this argument is passed as ``sample_weight`` keyword\n            argument to the ``score`` method of the final estimator.\n\n        Returns\n        -------\n        score : float\n        \"\"\"\n\n        Xt, yt, swt = self._transform(X, y, sample_weight)\n\n        self.N_test = len(yt)\n\n        score_params = {}\n        if swt is not None:\n            score_params['sample_weight'] = swt\n\n        if self.scorer is None:\n            return self._final_estimator.score(Xt, yt, **score_params)\n\n        return self.scorer(self._final_estimator, Xt, yt, **score_params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\napplies transforms and predict_proba of the final estimator and returns the predicted probability of each class in X.", "response": "def predict_proba(self, X):\n        \"\"\"\n        Apply transforms, and predict_proba of the final estimator\n\n        Parameters\n        ----------\n        X : iterable\n            Data to predict on. Must fulfill input requirements of first step\n            of the pipeline.\n\n        Returns\n        -------\n        y_proba : array-like, shape = [n_samples, n_classes]\n            Predicted probability of each class\n        \"\"\"\n        Xt, _, _ = self._transform(X)\n        return self._final_estimator.predict_proba(Xt)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\napplies transforms and decision_function of the final estimator and return the decision_function.", "response": "def decision_function(self, X):\n        \"\"\"\n        Apply transforms, and decision_function of the final estimator\n\n        Parameters\n        ----------\n        X : iterable\n            Data to predict on. Must fulfill input requirements of first step\n            of the pipeline.\n\n        Returns\n        -------\n        y_score : array-like, shape = [n_samples, n_classes]\n        \"\"\"\n        Xt, _, _ = self._transform(X)\n        return self._final_estimator.decision_function(Xt)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the parameters of this estimator.", "response": "def set_params(self, **params):\n        \"\"\"\n        Set the parameters of this estimator.\n        Valid parameter keys can be listed with ``get_params()``.\n\n        Returns\n        -------\n        self\n        \"\"\"\n        items = self.steps\n        names, _ = zip(*items)\n\n        keys = list(six.iterkeys(params))\n\n        for name in keys:\n            if '__' not in name and name in names:\n                # replace an estimator\n                self._replace_estimator('steps', name, params.pop(name))\n\n            if callable(params[name]):\n                # use a callable or function to set parameters\n                params[name] = params[name](params)\n\n            elif params[name] in keys:\n                # set one arg from another\n                params[name] = params[params[name]]\n\n        BaseEstimator.set_params(self, **params)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef base_features():\n    ''' Returns dictionary of some basic features that can be calculated for segmented time\n    series data '''\n    features = {'mean': mean,\n                'median': median,\n                'abs_energy': abs_energy,\n                'std': std,\n                'var': var,\n                'min': minimum,\n                'max': maximum,\n                'skew': skew,\n                'kurt': kurt,\n                'mse': mse,\n                'mnx': mean_crossings}\n    return features", "response": "Returns a dictionary of basic features that can be calculated for segmented time\n    series data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a dictionary of all features in the module .", "response": "def all_features():\n    ''' Returns dictionary of all features in the module\n\n    .. note:: Some of the features (hist4, corr) are relatively expensive to compute\n    '''\n    features = {'mean': mean,\n                'median': median,\n                'gmean': gmean,\n                'hmean': hmean,\n                'vec_sum': vec_sum,\n                'abs_sum': abs_sum,\n                'abs_energy': abs_energy,\n                'std': std,\n                'var': var,\n                'variation': variation,\n                'min': minimum,\n                'max': maximum,\n                'skew': skew,\n                'kurt': kurt,\n                'mean_diff': mean_diff,\n                'mean_abs_diff': means_abs_diff,\n                'mse': mse,\n                'mnx': mean_crossings,\n                'hist4': hist(),\n                'corr': corr2,\n                'mean_abs_value': mean_abs,\n                'zero_crossings': zero_crossing(),\n                'slope_sign_changes': slope_sign_changes(),\n                'waveform_length': waveform_length,\n                'emg_var': emg_var,\n                'root_mean_square': root_mean_square,\n                'willison_amplitude': willison_amplitude()}\n    return features"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef emg_features(threshold=0):\n    '''Return a dictionary of popular features used for EMG time series classification.'''\n    return {\n        'mean_abs_value': mean_abs,\n        'zero_crossings': zero_crossing(threshold),\n        'slope_sign_changes': slope_sign_changes(threshold),\n        'waveform_length': waveform_length,\n        'integrated_emg': abs_sum,\n        'emg_var': emg_var,\n        'simple square integral': abs_energy,\n        'root_mean_square': root_mean_square,\n        'willison_amplitude': willison_amplitude(threshold),\n    }", "response": "Return a dictionary of popular features used for EMG time series classification."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef means_abs_diff(X):\n    ''' mean absolute temporal derivative '''\n    return np.mean(np.abs(np.diff(X, axis=1)), axis=1)", "response": "mean absolute temporal derivative"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes mean spectral energy for each variable in a segmented time series", "response": "def mse(X):\n    ''' computes mean spectral energy for each variable in a segmented time series '''\n    return np.mean(np.square(np.abs(np.fft.fft(X, axis=1))), axis=1)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mean_crossings(X):\n    ''' Computes number of mean crossings for each variable in a segmented time series '''\n    X = np.atleast_3d(X)\n    N = X.shape[0]\n    D = X.shape[2]\n    mnx = np.zeros((N, D))\n    for i in range(D):\n        pos = X[:, :, i] > 0\n        npos = ~pos\n        c = (pos[:, :-1] & npos[:, 1:]) | (npos[:, :-1] & pos[:, 1:])\n        mnx[:, i] = np.count_nonzero(c, axis=1)\n    return mnx", "response": "Computes the number of mean crossings for each variable in a segmented time series"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes the correlations between all variable pairs in a segmented time series", "response": "def corr2(X):\n    ''' computes correlations between all variable pairs in a segmented time series\n\n    .. note:: this feature is expensive to compute with the current implementation, and cannot be\n    used with univariate time series\n    '''\n    X = np.atleast_3d(X)\n    N = X.shape[0]\n    D = X.shape[2]\n\n    if D == 1:\n        return np.zeros(N, dtype=np.float)\n\n    trii = np.triu_indices(D, k=1)\n    DD = len(trii[0])\n    r = np.zeros((N, DD))\n    for i in np.arange(N):\n        rmat = np.corrcoef(X[i])  # get the ith window from each signal, result will be DxD\n        r[i] = rmat[trii]\n    return r"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrooting mean square for each variable in the segmented time series", "response": "def root_mean_square(X):\n    ''' root mean square for each variable in the segmented time series '''\n    segment_width = X.shape[1]\n    return np.sqrt(np.sum(X * X, axis=1) / segment_width)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef temporal_split(X, y, test_size=0.25):\n    '''\n    Split time series or sequence data along the time axis.\n    Test data is drawn from the end of each series / sequence\n\n    Parameters\n    ----------\n    X : array-like, shape [n_series, ...]\n       Time series data and (optionally) contextual data\n    y : array-like shape [n_series, ]\n        target vector\n    test_size : float\n        between 0 and 1, amount to allocate to test\n\n    Returns\n    -------\n    X_train : array-like, shape [n_series, ]\n    X_test : array-like, shape [n_series, ]\n    y_train :  array-like, shape [n_series, ]\n    y_test :  array-like, shape [n_series, ]\n\n    '''\n\n    if test_size <= 0. or test_size >= 1.:\n        raise ValueError(\"temporal_split: test_size must be >= 0.0 and <= 1.0\"\n                         \" (was %.1f)\" %test_size)\n\n    Ns = len(y)  # number of series\n    check_ts_data(X, y)\n    Xt, Xc = get_ts_data_parts(X)\n\n    train_size = 1. - test_size\n\n    train_ind = [np.arange(0, int(train_size * len(Xt[i]))) for i in range(Ns)]\n    test_ind = [np.arange(len(train_ind[i]), len(Xt[i])) for i in range(Ns)]\n\n    X_train = [Xt[i][train_ind[i]] for i in range(Ns)]\n    X_test = [Xt[i][test_ind[i]] for i in range(Ns)]\n\n    if Xc is not None:\n        X_train = TS_Data(X_train, Xc)\n        X_test = TS_Data(X_test, Xc)\n\n    if len(np.atleast_1d(y[0])) == len(Xt[0]):\n        # y is a time series\n        y_train = [y[i][train_ind[i]] for i in range(Ns)]\n        y_test = [y[i][test_ind[i]] for i in range(Ns)]\n    else:\n        # y is contextual\n        y_train = y\n        y_test = y\n\n    return X_train, X_test, y_train, y_test", "response": "Split time series or sequence data along the time axis."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsplitting the time series data and target arrays and generates splitting indices", "response": "def split(self, X, y):\n        '''\n        Splits time series data and target arrays, and generates splitting indices\n\n        Parameters\n        ----------\n        X : array-like, shape [n_series, ...]\n           Time series data and (optionally) contextual data\n        y : array-like shape [n_series, ]\n            target vector\n\n        Returns\n        -------\n        X : array-like, shape [n_series * n_splits, ]\n            Split time series data and contextual data\n        y : array-like, shape [n_series * n_splits]\n            Split target data\n        cv : list, shape [2, n_splits]\n            Splitting indices\n        '''\n\n        check_ts_data(X, y)\n        Xt, Xc = get_ts_data_parts(X)\n        Ns = len(Xt)\n        Xt_new, y_new = self._ts_slice(Xt, y)\n\n        if Xc is not None:\n            Xc_new = np.concatenate([Xc] * self.n_splits)\n            X_new = TS_Data(Xt_new, Xc_new)\n        else:\n            X_new = np.array(Xt_new)\n\n        cv = self._make_indices(Ns)\n\n        return X_new, y_new, cv"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntakes time series data and splits each series into temporal folds", "response": "def _ts_slice(self, Xt, y):\n        ''' takes time series data, and splits each series into temporal folds '''\n        Ns = len(Xt)\n        Xt_new = []\n        for i in range(self.n_splits):\n            for j in range(Ns):\n                Njs = int(len(Xt[j]) / self.n_splits)\n                Xt_new.append(Xt[j][(Njs * i):(Njs * (i + 1))])\n        Xt_new = np.array(Xt_new)\n\n        if len(np.atleast_1d(y[0])) == len(Xt[0]):\n            # y is a time series\n            y_new = []\n            for i in range(self.n_splits):\n                for j in range(Ns):\n                    Njs = int(len(y[j]) / self.n_splits)\n                    y_new.append(y[j][(Njs * i):(Njs * (i + 1))])\n            y_new = np.array(y_new)\n        else:\n            # y is contextual to each series\n            y_new = np.concatenate([y for i in range(self.n_splits)])\n\n        return Xt_new, y_new"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmaking indices for cross validation", "response": "def _make_indices(self, Ns):\n        ''' makes indices for cross validation '''\n        N_new = int(Ns * self.n_splits)\n\n        test = [np.full(N_new, False) for i in range(self.n_splits)]\n        for i in range(self.n_splits):\n            test[i][np.arange(Ns * i, Ns * (i + 1))] = True\n        train = [np.logical_not(test[i]) for i in range(self.n_splits)]\n\n        test = [np.arange(N_new)[test[i]] for i in range(self.n_splits)]\n        train = [np.arange(N_new)[train[i]] for i in range(self.n_splits)]\n\n        cv = list(zip(train, test))\n        return cv"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef transform(self, X, y, sample_weight=None):\n        '''\n        Transforms the time series data with run length encoding of the target variable\n        Note this transformation changes the number of samples in the data\n        If sample_weight is provided, it is transformed to align to the new target encoding\n\n\n        Parameters\n        ----------\n        X : array-like, shape [n_series, ...]\n           Time series data and (optionally) contextual data\n        y : array-like shape [n_series, ...]\n            target variable encoded as a time series\n        sample_weight : array-like shape [n_series], default = None\n            sample weights\n\n        Returns\n        -------\n        Xt : array-like, shape [n_rle_series, ]\n            transformed time series data\n        yt : array-like, shape [n_rle_series]\n            target values for each series\n        sample_weight_new : array-like shape [n_rle_series]\n            sample weights\n        '''\n        check_ts_data_with_ts_target(X, y)\n\n        Xt, Xc = get_ts_data_parts(X)\n        N = len(Xt)  # number of time series\n\n        # transformed data\n        yt = []\n        Xtt = []\n        swt = sample_weight\n        Nt = []\n\n        for i in range(N):\n            Xi, yi = self._transform(Xt[i], y[i])\n            yt+=yi\n            Xtt+=Xi\n            Nt.append(len(yi)) # number of contiguous class instances\n\n        if Xc is not None:\n            Xct = expand_variables_to_segments(Xc, Nt)\n            Xtt = TS_Data(Xtt, Xct)\n\n        if sample_weight is not None:\n            swt = expand_variables_to_segments(sample_weight, Nt)\n\n        return Xtt, yt, swt", "response": "Transforms the time series data with run length encoding of the target variable X and y."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _rle(self, a):\n        '''\n        rle implementation credit to Thomas Browne from his SOF post Sept 2015\n\n        Parameters\n        ----------\n        a : array, shape[n,]\n            input vector\n\n        Returns\n        -------\n        z : array, shape[nt,]\n            run lengths\n        p : array, shape[nt,]\n            start positions of each run\n        ar : array, shape[nt,]\n            values for each run\n        '''\n        ia = np.asarray(a)\n        n = len(ia)\n        y = np.array(ia[1:] != ia[:-1])  # pairwise unequal (string safe)\n        i = np.append(np.where(y), n - 1)  # must include last element posi\n        z = np.diff(np.append(-1, i))  # run lengths\n        p = np.cumsum(np.append(0, z))[:-1]  # positions\n        return (z, p, ia[i])", "response": "rle implementation credit to Thomas Browne from his SOF post Sept 2015"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntransforming single series to single - level array", "response": "def _transform(self, X, y):\n        '''\n        Transforms single series\n        '''\n        z, p, y_rle = self._rle(y)\n        p = np.append(p, len(y))\n        big_enough = p[1:] - p[:-1] >= self.min_length\n        Xt = []\n\n        for i in range(len(y_rle)):\n            if (big_enough[i]):\n                Xt.append(X[p[i]:p[i+1]])\n\n        yt = y_rle[big_enough].tolist()\n        return Xt, yt"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the time series data and context data parts of a single object.", "response": "def get_ts_data_parts(X):\n    '''\n    Separates time series data object into time series variables and contextual variables\n\n    Parameters\n    ----------\n    X : array-like, shape [n_series, ...]\n       Time series data and (optionally) contextual data\n\n    Returns\n    -------\n    Xt : array-like, shape [n_series, ]\n        Time series data\n    Xs : array-like, shape [n_series, n_contextd = np.colum _variables]\n        contextual variables\n\n    '''\n    if not isinstance(X, TS_Data):\n        return X, None\n    return X.ts_data, X.context_data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks time series data with time series target is good. If not raises value error.", "response": "def check_ts_data_with_ts_target(X, y=None):\n    '''\n    Checks time series data with time series target is good. If not raises value error.\n\n    Parameters\n    ----------\n    X : array-like, shape [n_series, ...]\n       Time series data and (optionally) contextual data\n    y : array-like, shape [n_series, ...]\n        target data\n    '''\n    if y is not None:\n        Nx = len(X)\n        Ny = len(y)\n\n        if Nx != Ny:\n            raise ValueError(\"Number of time series different in X (%d) and y (%d)\"\n                             % (Nx, Ny))\n\n        Xt, _ = get_ts_data_parts(X)\n        Ntx = np.array([len(Xt[i]) for i in np.arange(Nx)])\n        Nty = np.array([len(np.atleast_1d(y[i])) for i in np.arange(Nx)])\n\n        if np.count_nonzero(Nty == Ntx) == Nx:\n            return\n        else:\n            raise ValueError(\"Invalid time series lengths.\\n\"\n                             \"Ns: \", Nx,\n                             \"Ntx: \", Ntx,\n                             \"Nty: \", Nty)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating some helpful statistics about the time series data Xt and y.", "response": "def ts_stats(Xt, y, fs=1.0, class_labels=None):\n    '''\n    Generates some helpful statistics about the data X\n\n    Parameters\n    ----------\n    X : array-like, shape [n_series, ...]\n       Time series data and (optionally) contextual data\n    y : array-like, shape [n_series]\n        target data\n    fs : float\n        sampling frequency\n    class_labels : list of strings, default None\n        List of target class names\n\n\n    Returns\n    -------\n    results : dict\n        | Dictionary of relevant statistics for the time series data\n        | results['total'] has stats for the whole data set\n        | results['by_class'] has stats segragated by target class\n\n    '''\n    check_ts_data(Xt)\n    Xt, Xs = get_ts_data_parts(Xt)\n\n    if Xs is not None:\n        S = len(np.atleast_1d(Xs[0]))\n    else:\n        S = 0\n\n    C = np.max(y) + 1  # number of classes\n    if class_labels is None:\n        class_labels = np.arange(C)\n\n    N = len(Xt)\n    if Xt[0].ndim > 1:\n        D = Xt[0].shape[1]\n    else:\n        D = 1\n\n    Ti = np.array([Xt[i].shape[0] for i in range(N)], dtype=np.float64) / fs\n    ic = np.array([y == i for i in range(C)])\n    Tic = [Ti[ic[i]] for i in range(C)]\n\n    T = np.sum(Ti)\n\n    total = {\"n_series\": N, \"n_classes\": C, \"n_TS_vars\": D, \"n_context_vars\": S, \"Total_Time\": T,\n             \"Series_Time_Mean\": np.mean(Ti),\n             \"Series_Time_Std\": np.std(Ti),\n             \"Series_Time_Range\": (np.min(Ti), np.max(Ti))}\n\n    by_class = {\"Class_labels\": class_labels,\n                \"n_series\": np.array([len(Tic[i]) for i in range(C)]),\n                \"Total_Time\": np.array([np.sum(Tic[i]) for i in range(C)]),\n                \"Series_Time_Mean\": np.array([np.mean(Tic[i]) for i in range(C)]),\n                \"Series_Time_Std\": np.array([np.std(Tic[i]) for i in range(C)]),\n                \"Series_Time_Min\": np.array([np.min(Tic[i]) for i in range(C)]),\n                \"Series_Time_Max\": np.array([np.max(Tic[i]) for i in range(C)])}\n\n    results = {'total': total,\n               'by_class': by_class}\n\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload some of the 6 - axis inertial sensor data from my smartwatch project.", "response": "def load_watch():\n    '''\n    Loads some of the 6-axis inertial sensor data from my smartwatch project. The sensor data was\n    recorded as study subjects performed sets of 20 shoulder exercise repetitions while wearing a\n    smartwatch. It is a multivariate time series.\n\n    The study can be found here: https://arxiv.org/abs/1802.01489\n\n    Returns\n    -------\n    data : dict\n        data['X'] : list, length 140\n            | inertial sensor data, each element with shape [n_samples, 6]\n            | sampled at 50 Hz\n        data['y'] : array, length 140\n            target vector (exercise type)\n        data['side'] : array, length 140\n            the extremity side, 1 = right, 0 = left\n        data['subject'] : array, length 140\n            the subject (participant) number\n        data['X_labels'] : str list, length 6\n            ordered labels for the sensor data variables\n        data['y_labels'] :str list, length 7\n            ordered labels for the target (exercise type)\n\n    Examples\n    --------\n    >>> from seglearn.datasets import load_watch\n    >>> data = load_watch()\n    >>> print(data.keys())\n    '''\n    module_path = dirname(__file__)\n    data = np.load(module_path + \"/data/watch_dataset.npy\").item()\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nshuffles indices X y and sample_weight together", "response": "def shuffle_data(X, y=None, sample_weight=None):\n    ''' Shuffles indices X, y, and sample_weight together'''\n    if len(X) > 1:\n        ind = np.arange(len(X), dtype=np.int)\n        np.random.shuffle(ind)\n        Xt = X[ind]\n        yt = y\n        swt = sample_weight\n\n        if yt is not None:\n            yt = yt[ind]\n        if swt is not None:\n            swt = swt[ind]\n\n        return Xt, yt, swt\n    else:\n        return X, y, sample_weight"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexpand contextual variables v by repeating each instance as specified in Nt", "response": "def expand_variables_to_segments(v, Nt):\n    ''' expands contextual variables v, by repeating each instance as specified in Nt '''\n    N_v = len(np.atleast_1d(v[0]))\n    return np.concatenate([np.full((Nt[i], N_v), v[i]) for i in np.arange(len(v))])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sliding_window(time_series, width, step, order='F'):\n    '''\n    Segments univariate time series with sliding window\n\n    Parameters\n    ----------\n    time_series : array like shape [n_samples]\n        time series or sequence\n    width : int > 0\n        segment width in samples\n    step : int > 0\n        stepsize for sliding in samples\n\n    Returns\n    -------\n    w : array like shape [n_segments, width]\n        resampled time series segments\n    '''\n    w = np.hstack([time_series[i:1 + i - width or None:step] for i in range(0, width)])\n    result = w.reshape((int(len(w) / width), width), order='F')\n    if order == 'F':\n        return result\n    else:\n        return np.ascontiguousarray(result)", "response": "Returns univariate time series with sliding window"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sliding_tensor(mv_time_series, width, step, order='F'):\n    '''\n    segments multivariate time series with sliding window\n\n    Parameters\n    ----------\n    mv_time_series : array like shape [n_samples, n_variables]\n        multivariate time series or sequence\n    width : int > 0\n        segment width in samples\n    step : int > 0\n        stepsize for sliding in samples\n\n    Returns\n    -------\n    data : array like shape [n_segments, width, n_variables]\n        segmented multivariate time series data\n    '''\n    D = mv_time_series.shape[1]\n    data = [sliding_window(mv_time_series[:, j], width, step, order) for j in range(D)]\n    return np.stack(data, axis=2)", "response": "Returns a tensor that is a sliding window of the given time series."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntransforms the time series data into segments (temporal tensor) Note this transformation changes the number of samples in the data If y and sample_weight are provided, they are transformed to align to the new samples Parameters ---------- X : array-like, shape [n_series, ...] Time series data and (optionally) contextual data y : array-like shape [n_series], default = None target vector sample_weight : array-like shape [n_series], default = None sample weights Returns ------- Xt : array-like, shape [n_segments, ] transformed time series data yt : array-like, shape [n_segments] expanded target vector sample_weight_new : array-like shape [n_segments] expanded sample weights", "response": "def transform(self, X, y=None, sample_weight=None):\n        '''\n        Transforms the time series data into segments (temporal tensor)\n        Note this transformation changes the number of samples in the data\n        If y and sample_weight are provided, they are transformed to align to the new samples\n\n\n        Parameters\n        ----------\n        X : array-like, shape [n_series, ...]\n           Time series data and (optionally) contextual data\n        y : array-like shape [n_series], default = None\n            target vector\n        sample_weight : array-like shape [n_series], default = None\n            sample weights\n\n        Returns\n        -------\n        Xt : array-like, shape [n_segments, ]\n            transformed time series data\n        yt : array-like, shape [n_segments]\n            expanded target vector\n        sample_weight_new : array-like shape [n_segments]\n            expanded sample weights\n        '''\n        check_ts_data(X, y)\n        Xt, Xc = get_ts_data_parts(X)\n        yt = y\n        swt = sample_weight\n\n        N = len(Xt)  # number of time series\n\n        if Xt[0].ndim > 1:\n            Xt = np.array([sliding_tensor(Xt[i], self.width, self._step, self.order)\n                           for i in np.arange(N)])\n        else:\n            Xt = np.array([sliding_window(Xt[i], self.width, self._step, self.order)\n                           for i in np.arange(N)])\n\n        Nt = [len(Xt[i]) for i in np.arange(len(Xt))]\n        Xt = np.concatenate(Xt)\n\n        if yt is not None:\n            yt = expand_variables_to_segments(yt, Nt).ravel()\n\n        if swt is not None:\n            swt = expand_variables_to_segments(swt, Nt).ravel()\n\n        if Xc is not None:\n            Xc = expand_variables_to_segments(Xc, Nt)\n            Xt = TS_Data(Xt, Xc)\n\n        if self.shuffle is True:\n            check_random_state(self.random_state)\n            return shuffle_data(Xt, yt, swt)\n\n        return Xt, yt, swt"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef transform(self, X, y=None, sample_weight=None):\n        '''\n        Transforms the time series data into segments\n        Note this transformation changes the number of samples in the data\n        If y is provided, it is segmented and transformed to align to the new samples as per\n        ``y_func``\n        Currently sample weights always returned as None\n\n        Parameters\n        ----------\n        X : array-like, shape [n_series, ...]\n           Time series data and (optionally) contextual data\n        y : array-like shape [n_series], default = None\n            target vector\n        sample_weight : array-like shape [n_series], default = None\n            sample weights\n\n        Returns\n        -------\n        Xt : array-like, shape [n_segments, ]\n            transformed time series data\n        yt : array-like, shape [n_segments]\n            expanded target vector\n        sample_weight_new : None\n\n        '''\n        check_ts_data(X, y)\n        Xt, Xc = get_ts_data_parts(X)\n        yt = y\n\n        N = len(Xt)  # number of time series\n\n        if Xt[0].ndim > 1:\n            Xt = np.array([sliding_tensor(Xt[i], self.width, self._step, self.order)\n                           for i in np.arange(N)])\n        else:\n            Xt = np.array([sliding_window(Xt[i], self.width, self._step, self.order)\n                           for i in np.arange(N)])\n\n        Nt = [len(Xt[i]) for i in np.arange(len(Xt))]\n        Xt = np.concatenate(Xt)\n\n        if Xc is not None:\n            Xc = expand_variables_to_segments(Xc, Nt)\n            Xt = TS_Data(Xt, Xc)\n\n        if yt is not None:\n            yt = np.array([sliding_window(yt[i], self.width, self._step, self.order)\n                           for i in np.arange(N)])\n            yt = np.concatenate(yt)\n            yt = self.y_func(yt)\n\n        if self.shuffle is True:\n            check_random_state(self.random_state)\n            Xt, yt, _ = shuffle_data(Xt, yt)\n\n        return Xt, yt, None", "response": "This function transforms the time series data into segments and returns the new time series data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef transform(self, X, y=None, sample_weight=None):\n        '''\n        Transforms the time series data into fixed length segments using padding and or truncation\n        If y is a time series and passed, it will be transformed as well\n\n        Parameters\n        ----------\n        X : array-like, shape [n_series, ...]\n           Time series data and (optionally) contextual data\n        y : array-like shape [n_series], default = None\n            target vector\n        sample_weight : array-like shape [n_series], default = None\n            sample weights\n\n        Returns\n        -------\n        X_new : array-like, shape [n_series, ]\n            transformed time series data\n        y_new : array-like, shape [n_series]\n            expanded target vector\n        sample_weight_new : None\n\n        '''\n        check_ts_data(X, y)\n        Xt, Xc = get_ts_data_parts(X)\n        yt = y\n        swt = sample_weight\n\n        Xt = self._mv_resize(Xt)\n\n        if Xc is not None:\n            Xt = TS_Data(Xt, Xc)\n\n        if yt is not None and len(np.atleast_1d(yt[0])) > 1:\n            # y is a time series\n            yt = self._mv_resize(yt)\n            swt = None\n        elif yt is not None:\n            # todo: is this needed?\n            yt = np.array(yt)\n\n        return Xt, yt, swt", "response": "Transforms the time series data into fixed length segments using padding and or truncation."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfit the transform. Does nothing for compatibility with sklearn API.", "response": "def fit(self, X, y=None):\n        '''\n        Fit the transform. Does nothing, for compatibility with sklearn API.\n\n        Parameters\n        ----------\n        X : array-like, shape [n_series, ...]\n            Time series data and (optionally) contextual data\n        y : None\n            There is no need of a target in a transformer, yet the pipeline API requires this\n            parameter.\n\n        Returns\n        -------\n        self : object\n            Returns self.\n        '''\n        check_ts_data(X, y)\n        if not X[0].ndim > 1:\n            raise ValueError(\"X variable must have more than 1 channel\")\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntransform the time series data with linear direct value interpolation If y is a time series and passed, it will be transformed as well The time dimension is removed from the data Parameters ---------- X : array-like, shape [n_series, ...] Time series data and (optionally) contextual data y : array-like shape [n_series], default = None target vector sample_weight : array-like shape [n_series], default = None sample weights Returns ------- X_new : array-like, shape [n_series, ] transformed time series data y_new : array-like, shape [n_series] expanded target vector sample_weight_new : array-like or None None is returned if target is changed. Otherwise it is returned unchanged.", "response": "def transform(self, X, y=None, sample_weight=None):\n        '''\n        Transforms the time series data with linear direct value interpolation\n        If y is a time series and passed, it will be transformed as well\n        The time dimension is removed from the data\n\n        Parameters\n        ----------\n        X : array-like, shape [n_series, ...]\n           Time series data and (optionally) contextual data\n        y : array-like shape [n_series], default = None\n            target vector\n        sample_weight : array-like shape [n_series], default = None\n            sample weights\n\n        Returns\n        -------\n        X_new : array-like, shape [n_series, ]\n            transformed time series data\n        y_new : array-like, shape [n_series]\n            expanded target vector\n        sample_weight_new : array-like or None\n            None is returned if target is changed. Otherwise it is returned unchanged.\n        '''\n        check_ts_data(X, y)\n        Xt, Xc = get_ts_data_parts(X)\n        yt = y\n        swt = sample_weight\n\n        N = len(Xt)  # number of series\n        D = Xt[0].shape[1] - 1  # number of data channels\n\n        # 1st channel is time\n        t = [Xt[i][:, 0] for i in np.arange(N)]\n        t_lin = [np.arange(Xt[i][0, 0], Xt[i][-1, 0], self.sample_period) for i in np.arange(N)]\n\n        if D == 1:\n            Xt = [self._interp(t_lin[i], t[i], Xt[i][:, 1], kind=self.kind) for i in np.arange(N)]\n        elif D > 1:\n            Xt = [np.column_stack([self._interp(t_lin[i], t[i], Xt[i][:, j], kind=self.kind)\n                                   for j in range(1, D + 1)]) for i in np.arange(N)]\n        if Xc is not None:\n            Xt = TS_Data(Xt, Xc)\n\n        if yt is not None and len(np.atleast_1d(yt[0])) > 1:\n            # y is a time series\n            swt = None\n            if self.categorical_target is True:\n                yt = [self._interp(t_lin[i], t[i], yt[i], kind='nearest') for i in np.arange(N)]\n            else:\n                yt = [self._interp(t_lin[i], t[i], yt[i], kind=self.kind) for i in np.arange(N)]\n        else:\n            # y is static - leave y alone\n            pass\n\n        return Xt, yt, swt"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fit(self, X, y=None):\n        '''\n        Fit the transform. Does nothing, for compatibility with sklearn API.\n\n        Parameters\n        ----------\n        X : array-like, shape [n_series, ...]\n            Time series data and (optionally) contextual data\n        y : None\n            There is no need of a target in a transformer, yet the pipeline API requires this\n            parameter.\n\n        Returns\n        -------\n        self : object\n            Returns self.\n        '''\n        self._check_data(X)\n        if not X[0].ndim >= 2:\n            raise ValueError(\"X input must be 2 dim array or greater\")\n        return self", "response": "Fit the transform. Does nothing for compatibility with sklearn API."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _check_data(self, X):\n        '''\n        Checks that unique identifiers vaf_types are consistent between time series.\n\n        Parameters\n        ----------\n        X : array-like, shape [n_series, ...]\n            Time series data and (optionally) contextual data\n        '''\n\n        if len(X) > 1:\n            sval = np.unique(X[0][:, 1])\n            if np.all([np.all(np.unique(X[i][:, 1]) == sval) for i in range(1, len(X))]):\n                pass\n            else:\n                raise ValueError(\"Unique identifier var_types not consistent between time series\")", "response": "Checks that unique identifiers vaf_types are consistent between time series data and contextual data."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntransform the time series data with linear direct value interpolation.", "response": "def transform(self, X, y=None, sample_weight=None):\n        '''\n        Transforms the time series data with linear direct value interpolation\n        If y is a time series and passed, it will be transformed as well\n        The time dimension is removed from the data\n\n        Parameters\n        ----------\n        X : array-like, shape [n_series, ...]\n           Time series data and (optionally) contextual data\n        y : array-like shape [n_series], default = None\n            target vector\n        sample_weight : array-like shape [n_series], default = None\n            sample weights\n\n        Returns\n        -------\n        X_new : array-like, shape [n_series, ]\n            transformed time series data\n        y_new : array-like, shape [n_series]\n            expanded target vector\n        sample_weight_new : array-like or None\n            None is returned if target is changed. Otherwise it is returned unchanged.\n        '''\n        check_ts_data(X, y)\n        xt, xc = get_ts_data_parts(X)\n        yt = y\n        swt = sample_weight\n\n        # number of data channels\n        d = xt[0][0].shape[0] - 2\n        # number of series\n        N = len(xt)\n\n        # retrieve the unique identifiers\n        s = np.unique(xt[0][:, 1])\n\n        x_new = []\n        t_lin = []\n\n        # transform x\n        for i in np.arange(N):\n\n            # splits series into a list for each variable\n            xs = [xt[i][xt[i][:, 1] == s[j]] for j in np.arange(len(s))]\n\n            # find latest/earliest sample time for each identifier's first/last time sample time\n            t_min = np.max([np.min(xs[j][:, 0]) for j in np.arange(len(s))])\n            t_max = np.min([np.max(xs[j][:, 0]) for j in np.arange(len(s))])\n\n            # Generate a regular series of timestamps starting at tStart and tEnd for sample_period\n            t_lin.append(np.arange(t_min, t_max, self.sample_period))\n\n            # Interpolate for the new regular sample times\n            if d == 1:\n                x_new.append(\n                    np.column_stack(\n                        [self._interp(t_lin[i], xs[j][:, 0], xs[j][:, 2], kind=self.kind)\n                         for j in np.arange(len(s))]))\n            elif d > 1:\n                xd = []\n                for j in np.arange(len(s)):\n                    # stack the columns of each variable by dimension d after interpolation to new regular sample times\n                    temp = np.column_stack(\n                        [(self._interp(t_lin[i], xs[j][:, 0], xs[j][:, k], kind=self.kind))\n                         for k in np.arange(2, 2 + d)])\n                    xd.append(temp)\n                # column stack each of the sensors s -- resulting in s*d columns\n                x_new.append(np.column_stack(xd))\n\n        # transform y\n        if yt is not None and len(np.atleast_1d(yt[0])) > 1:\n            # y is a time series\n            swt = None\n            if self.categorical_target is True:\n                yt = [self._interp(t_lin[i], xt[i][:, 0], yt[i], kind='nearest') for i in\n                      np.arange(N)]\n            else:\n                yt = [self._interp(t_lin[i], xt[i][:, 0], yt[i], kind=self.kind) for i in\n                      np.arange(N)]\n        else:\n            # y is static - leave y alone\n            pass\n\n        if xc is not None:\n            x_new = TS_Data(x_new, xc)\n\n        return x_new, yt, swt"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fit(self, X, y=None):\n        '''\n        Fit the transform\n\n        Parameters\n        ----------\n        X : array-like, shape [n_series, ...]\n            Segmented time series data and (optionally) contextual data\n        y : None\n            There is no need of a target in a transformer, yet the pipeline API requires this\n            parameter.\n\n        Returns\n        -------\n        self : object\n            Returns self.\n        '''\n        check_ts_data(X, y)\n        self._reset()\n        if self.verbose:\n            print(\"X Shape: \", X.shape)\n        self.f_labels = self._generate_feature_labels(X)\n        return self", "response": "Fit the transform to the object X."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntransforms the segmented time series data into feature data.", "response": "def transform(self, X):\n        '''\n        Transform the segmented time series data into feature data.\n        If contextual data is included in X, it is returned with the feature data.\n\n        Parameters\n        ----------\n        X : array-like, shape [n_series, ...]\n            Segmented time series data and (optionally) contextual data\n\n        Returns\n        -------\n        X_new : array shape [n_series, ...]\n            Feature representation of segmented time series data and contextual data\n\n        '''\n        self._check_if_fitted()\n        Xt, Xc = get_ts_data_parts(X)\n        check_array(Xt, dtype='numeric', ensure_2d=False, allow_nd=True)\n\n        fts = np.column_stack([self.features[f](Xt) for f in self.features])\n        if Xc is not None:\n            fts = np.column_stack([fts, Xc])\n        return fts"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntesting output of each feature against a segmented time series Xti.", "response": "def _check_features(self, features, Xti):\n        '''\n        tests output of each feature against a segmented time series X\n\n        Parameters\n        ----------\n        features : dict\n            feature function dictionary\n        Xti : array-like, shape [n_samples, segment_width, n_variables]\n            segmented time series (instance)\n\n        Returns\n        -------\n            ftr_sizes : dict\n                number of features output by each feature function\n        '''\n        N = Xti.shape[0]\n        N_fts = len(features)\n        fshapes = np.zeros((N_fts, 2), dtype=np.int)\n        keys = [key for key in features]\n        for i in np.arange(N_fts):\n            fshapes[i] = np.row_stack(features[keys[i]](Xti)).shape\n\n        # make sure each feature returns an array shape [N, ]\n        if not np.all(fshapes[:, 0] == N):\n            raise ValueError(\"feature function returned array with invalid length, \",\n                             np.array(features.keys())[fshapes[:, 0] != N])\n\n        return {keys[i]: fshapes[i, 1] for i in range(N_fts)}"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates string feature labels", "response": "def _generate_feature_labels(self, X):\n        '''\n        Generates string feature labels\n        '''\n        Xt, Xc = get_ts_data_parts(X)\n\n        ftr_sizes = self._check_features(self.features, Xt[0:3])\n        f_labels = []\n\n        # calculated features\n        for key in ftr_sizes:\n            for i in range(ftr_sizes[key]):\n                f_labels += [key + '_' + str(i)]\n\n        # contextual features\n        if Xc is not None:\n            Ns = len(np.atleast_1d(Xc[0]))\n            s_labels = [\"context_\" + str(i) for i in range(Ns)]\n            f_labels += s_labels\n\n        return f_labels"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretrieve a list of indices corresponding to the provided column specification.", "response": "def _retrieve_indices(cols):\n        '''\n        Retrieve a list of indices corresponding to the provided column specification.\n        '''\n        if isinstance(cols, int):\n            return [cols]\n        elif isinstance(cols, slice):\n            start = cols.start if cols.start else 0\n            stop = cols.stop\n            step = cols.step if cols.step else 1\n            return list(range(start, stop, step))\n        elif isinstance(cols, list) and cols:\n            if isinstance(cols[0], bool):\n                return np.flatnonzero(np.asarray(cols))\n            elif isinstance(cols[0], int):\n                return cols\n        else:\n            raise TypeError('No valid column specifier. Only a scalar, list or slice of all'\n                            'integers or a boolean mask are allowed.')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfitting the transform to the object X and y.", "response": "def fit(self, X, y=None):\n        '''\n        Fit the transform\n\n        Parameters\n        ----------\n        X : array-like, shape [n_series, ...]\n            Segmented time series data and (optionally) contextual data\n        y : None\n            There is no need of a target in a transformer, yet the pipeline API requires this\n            parameter.\n\n        Returns\n        -------\n        self : object\n            Returns self.\n        '''\n        Xt, Xc = get_ts_data_parts(X)\n        self.f_labels = []\n\n        # calculated features (prefix with the FeatureRep name and correct the index)\n        for name, trans, cols in self.transformers:\n            indices = self._retrieve_indices(cols)\n            trans.fit(self._select(Xt, cols))\n            for label, index in zip(trans.f_labels, indices):\n                self.f_labels.append(name + '_' + label.rsplit('_', 1)[0] + '_' + str(index))\n\n        # contextual features\n        if Xc is not None:\n            Ns = len(np.atleast_1d(Xc[0]))\n            self.f_labels += ['context_' + str(i) for i in range(Ns)]\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef transform(self, X):\n        '''\n        Transform the segmented time series data into feature data.\n        If contextual data is included in X, it is returned with the feature data.\n\n        Parameters\n        ----------\n        X : array-like, shape [n_series, ...]\n            Segmented time series data and (optionally) contextual data\n\n        Returns\n        -------\n        X_new : array shape [n_series, ...]\n            Feature representation of segmented time series data and contextual data\n\n        '''\n        self._validate()\n\n        Xt, Xc = get_ts_data_parts(X)\n        check_array(Xt, dtype='numeric', ensure_2d=False, allow_nd=True)\n\n        # calculated features\n        fts = np.column_stack([trans.transform(self._select(Xt, cols))\n                               for _, trans, cols in self.transformers])\n        # contextual features\n        if Xc is not None:\n            fts = np.column_stack([fts, Xc])\n\n        return fts", "response": "Transform the segmented time series data into feature data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef transform(self, X):\n        '''\n        Transforms the time series data based on the provided function. Note this transformation\n        must not change the number of samples in the data.\n\n        Parameters\n        ----------\n        X : array-like, shape [n_samples, ...]\n            time series data and (optionally) contextual data\n\n        Returns\n        -------\n        Xt : array-like, shape [n_samples, ...]\n            transformed time series data\n\n        '''\n        if self.func is None:\n            return X\n        else:\n            Xt, Xc = get_ts_data_parts(X)\n            n_samples = len(Xt)\n            Xt = self.func(Xt, **self.func_kwargs)\n            if len(Xt) != n_samples:\n                raise ValueError(\"FunctionTransformer changes sample number (not supported).\")\n            if Xc is not None:\n                Xt = TS_Data(Xt, Xc)\n            return Xt", "response": "Transforms the time series data based on the function provided."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_ini(ini_file, section=None):\n    if not os.path.exists(ini_file):\n        raise RuntimeError('Could not find ini file %s' % ini_file)\n    cp = configparser.ConfigParser()\n    cp.read(ini_file)\n    if not cp.sections():\n        raise RuntimeError('Could not find any section in ini file %s' % ini_file)\n    if section:\n        sec_list = [section]\n    elif len(cp.sections()) == 1:\n        # no section specified - check if there is a single/unique section in the ini file:\n        sec_list = cp.sections()\n    else:\n        # ini_file has more than one section, so try some default names:\n        sec_list = ['hana', 'pytest']\n\n    for sec in sec_list:\n        try:\n            param_values = cp.items(sec)\n        except configparser.NoSectionError:\n            continue\n        params = dict(param_values)\n        break\n    else:\n        raise RuntimeError('Could not guess which section to use for hana credentials from %s' % ini_file)\n\n    # Parameters can be named like 'hana_user' (e.g. pytest.ini) or just 'user' (other ini's).\n    # Remove the 'hana_' prefix so that parameter names match the arguments of the pyhdb.connect() function.\n    # Also remove invalid keys from clean_params (like 'hostname' etc).\n\n    def rm_prefix(param):\n        return param[5:] if param.startswith('hana_') else param\n\n    valid_keys = ('host', 'port', 'user', 'password')\n    clean_params = {'%s' % rm_prefix(key): val for key, val in params.items() if rm_prefix(key) in valid_keys}\n\n    # make actual connection:\n    return connect(**clean_params)", "response": "Read connection parameters from an ini file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send_request(self, message):\n        payload = message.pack()  # obtain BytesIO instance\n        return self.__send_message_recv_reply(payload.getvalue())", "response": "Send a request to HANA db and return reply message"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild the payload of all parts and writes them into the payload buffer", "response": "def build_payload(self, payload):\n        \"\"\"Build payload of all parts and write them into the payload buffer\"\"\"\n        remaining_size = self.MAX_SEGMENT_PAYLOAD_SIZE\n\n        for part in self.parts:\n            part_payload = part.pack(remaining_size)\n            payload.write(part_payload)\n            remaining_size -= len(part_payload)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef escape(value):\n\n    if isinstance(value, (tuple, list)):\n        return \"(\" + \", \".join([escape(arg) for arg in value]) + \")\"\n    else:\n        typ = by_python_type.get(value.__class__)\n        if typ is None:\n            raise InterfaceError(\n                \"Unsupported python input: %s (%s)\" % (value, value.__class__)\n            )\n\n        return typ.to_sql(value)", "response": "Escape a single value."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef escape_values(values):\n    if isinstance(values, (tuple, list)):\n        return tuple([escape(value) for value in values])\n    elif isinstance(values, dict):\n        return dict([\n            (key, escape(value)) for (key, value) in values.items()\n        ])\n    else:\n        raise InterfaceError(\"escape_values expects list, tuple or dict\")", "response": "Escape multiple values from a list tuple or dict."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prepare(cls, value):\n        pfield = struct.pack('b', cls.type_code)\n        if isinstance(value, string_types):\n            value = datetime.datetime.strptime(value, \"%Y-%m-%d\")\n        year = value.year | 0x8000  # for some unknown reasons year has to be bit-or'ed with 0x8000\n        month = value.month - 1     # for some unknown reasons HANA counts months starting from zero\n        pfield += cls._struct.pack(year, month, value.day)\n        return pfield", "response": "Pack datetime value into proper binary format"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_daydate(cls, *argv):\n        argc = len(argv)\n        if argc == 3:\n            year, month, day = argv\n        elif argc == 1:\n            dval = argv[0]\n            try:\n                year = dval.year\n                month = dval.month\n                day = dval.day\n            except AttributeError:\n                raise InterfaceError(\"Unsupported python date input: %s (%s)\" % (str(dval), dval.__class__))\n        else:\n            raise InterfaceError(\"Date.to_datetime does not support %d arguments.\" % argc)\n\n        TURN_OF_ERAS = 1721424\n\n        if month < 3:\n            year -= 1\n            month += 12\n\n        if ((year > 1582) or\n                (year == 1582 and month > 10) or\n                (year == 1582 and month == 10 and day >= 15)):\n            A = int(year / 100)\n            B = int(A / 4)\n            C = 2 - A + B\n        else:\n            C = 0\n\n        E = int(365.25 * (year + 4716))\n        F = int(30.6001 * (month + 1))\n        Z = C + day + E + F - 1524\n        return Z + 1 - TURN_OF_ERAS", "response": "Convert date to Julian day."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prepare(cls, value):\n        pfield = struct.pack('b', cls.type_code)\n        if isinstance(value, string_types):\n            if \".\" in value:\n                value = datetime.datetime.strptime(value, \"%H:%M:%S.%f\")\n            else:\n                value = datetime.datetime.strptime(value, \"%H:%M:%S\")\n        millisecond = value.second * 1000 + value.microsecond // 1000\n        hour = value.hour | 0x80    # for some unknown reasons hour has to be bit-or'ed with 0x80\n        pfield += cls._struct.pack(hour, value.minute, millisecond)\n        return pfield", "response": "Pack time value into proper binary format"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprepares the lob header.", "response": "def prepare(cls, value, length=0, position=0, is_last_data=True):\n        \"\"\"Prepare Lob header.\n        Note that the actual lob data is NOT written here but appended after the parameter block for each row!\n        \"\"\"\n        hstruct = WriteLobHeader.header_struct\n        lob_option_dataincluded = WriteLobHeader.LOB_OPTION_DATAINCLUDED if length > 0 else 0\n        lob_option_lastdata = WriteLobHeader.LOB_OPTION_LASTDATA if is_last_data else 0\n        options = lob_option_dataincluded | lob_option_lastdata\n        pfield = hstruct.pack(cls.type_code, options, length, position)\n        return pfield"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_payload(type_code, payload, connection):\n    lob_header = ReadLobHeader(payload)\n    if lob_header.isnull():\n        lob = None\n    else:\n        data = payload.read(lob_header.chunk_length)\n        _LobClass = LOB_TYPE_CODE_MAP[type_code]\n        lob = _LobClass.from_payload(data, lob_header, connection)\n        logger.debug('Lob Header %r' % lob)\n    return lob", "response": "Generator function to create a lob from a payload."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef seek(self, offset, whence=SEEK_SET):\n        # A nice trick is to (ab)use BytesIO.seek() to go to the desired position for easier calculation.\n        # This will not add any data to the buffer however - very convenient!\n        self.data.seek(offset, whence)\n        new_pos = self.data.tell()\n        missing_bytes_to_read = new_pos - self._current_lob_length\n        if missing_bytes_to_read > 0:\n            # Trying to seek beyond currently available LOB data, so need to load some more first.\n\n            # We are smart here: (at least trying...):\n            #         If a user sets a certain file position s/he probably wants to read data from\n            #         there. So already read some extra data to avoid yet another immediate\n            #         reading step. Try with EXTRA_NUM_ITEMS_TO_READ_AFTER_SEEK additional items (bytes/chars).\n\n            # jump to the end of the current buffer and read the new data:\n            self.data.seek(0, SEEK_END)\n            self.read(missing_bytes_to_read + self.EXTRA_NUM_ITEMS_TO_READ_AFTER_SEEK)\n            # reposition file pointer a originally desired position:\n            self.data.seek(new_pos)\n        return new_pos", "response": "Seek in lob data buffer to requested position."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads up to n items from the lob and return them.", "response": "def read(self, n=-1):\n        \"\"\"Read up to n items (bytes/chars) from the lob and return them.\n        If n is -1 then all available data is returned.\n        Might trigger further loading of data from the database if the number of items requested for\n        reading is larger than what is currently buffered.\n        \"\"\"\n        pos = self.tell()\n        num_items_to_read = n if n != -1 else self.length - pos\n        # calculate the position of the file pointer after data was read:\n        new_pos = min(pos + num_items_to_read, self.length)\n\n        if new_pos > self._current_lob_length:\n            missing_num_items_to_read = new_pos - self._current_lob_length\n            self._read_missing_lob_data_from_db(self._current_lob_length, missing_num_items_to_read)\n        # reposition file pointer to original position as reading in IO buffer might have changed it\n        self.seek(pos, SEEK_SET)\n        return self.data.read(n)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads LOB request part from database and store it in self. data.", "response": "def _read_missing_lob_data_from_db(self, readoffset, readlength):\n        \"\"\"Read LOB request part from database\"\"\"\n        logger.debug('Reading missing lob data from db. Offset: %d, readlength: %d' % (readoffset, readlength))\n        lob_data = self._make_read_lob_request(readoffset, readlength)\n\n        # make sure we really got as many items (not bytes!) as requested:\n        enc_lob_data = self._decode_lob_data(lob_data)\n        assert readlength == len(enc_lob_data), 'expected: %d, received; %d' % (readlength, len(enc_lob_data))\n\n        # jump to end of data, and append new and properly decoded data to it:\n        # import pdb;pdb.set_trace()\n        self.data.seek(0, SEEK_END)\n        self.data.write(enc_lob_data)\n        self._current_lob_length = len(self.data.getvalue())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmake a READLOBREQUEST message and return the LOB container.", "response": "def _make_read_lob_request(self, readoffset, readlength):\n        \"\"\"Make low level request to HANA database (READLOBREQUEST).\n        Compose request message with proper parameters and read lob data from second part object of reply.\n        \"\"\"\n        self._connection._check_closed()\n\n        request = RequestMessage.new(\n            self._connection,\n            RequestSegment(\n                message_types.READLOB,\n                (ReadLobRequest(self._lob_header.locator_id, readoffset, readlength),)\n            )\n        )\n        response = self._connection.send_request(request)\n\n        # The segment of the message contains two parts.\n        # 1) StatementContext -> ignored for now\n        # 2) ReadLobReply -> contains some header information and actual LOB data\n        data_part = response.segments[0].parts[1]\n        # return actual lob container (BytesIO/TextIO):\n        return data_part.data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _init_io_container(self, init_value):\n        if isinstance(init_value, CLOB_STRING_IO_CLASSES):\n            # already a valid StringIO instance, just use it as it is\n            v = init_value\n        else:\n            # works for strings and unicodes. However unicodes must only contain valid ascii chars!\n            if PY3:\n                # a io.StringIO also accepts any unicode characters, but we must be sure that only\n                # ascii chars are contained. In PY2 we use a cStringIO class which complains by itself\n                # if it catches this case, so in PY2 no extra check needs to be performed here.\n                init_value.encode('ascii')  # this is just a check, result not needed!\n            v = CLOB_STRING_IO(init_value)\n        return v", "response": "Initialize the lob data container."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nattribute sql parameters with meta data for one sql statement at a time.", "response": "def prepare_parameters(self, multi_row_parameters):\n        \"\"\" Attribute sql parameters with meta data for a prepared statement.\n        Make some basic checks that at least the number of parameters is correct.\n        :param multi_row_parameters: A list/tuple containing list/tuples of parameters (for multiple rows)\n        :returns: A generator producing parameters attributed with meta data for one sql statement (a row) at a time\n        \"\"\"\n        self._multi_row_parameters = multi_row_parameters\n        self._num_rows = len(multi_row_parameters)\n        self._iter_row_count = 0\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprepares a SQL statement in HANA and cache it.", "response": "def prepare(self, statement):\n        \"\"\"Prepare SQL statement in HANA and cache it\n        :param statement; a valid SQL statement\n        :returns: statement_id (of prepared and cached statement)\n        \"\"\"\n        self._check_closed()\n        self._column_types = None\n        statement_id = params_metadata = result_metadata_part = None\n\n        request = RequestMessage.new(\n            self.connection,\n            RequestSegment(\n                message_types.PREPARE,\n                Command(statement)\n            )\n        )\n        response = self.connection.send_request(request)\n\n        for part in response.segments[0].parts:\n            if part.kind == part_kinds.STATEMENTID:\n                statement_id = part.statement_id\n            elif part.kind == part_kinds.PARAMETERMETADATA:\n                params_metadata = part.values\n            elif part.kind == part_kinds.RESULTSETMETADATA:\n                result_metadata_part = part\n\n        # Check that both variables have been set in previous loop, we need them:\n        assert statement_id is not None\n        assert params_metadata is not None\n        # cache statement:\n        self._prepared_statements[statement_id] = PreparedStatement(self.connection, statement_id,\n                                                                    params_metadata, result_metadata_part)\n        return statement_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef execute_prepared(self, prepared_statement, multi_row_parameters):\n        self._check_closed()\n\n        # Convert parameters into a generator producing lists with parameters as named tuples (incl. some meta data):\n        parameters = prepared_statement.prepare_parameters(multi_row_parameters)\n\n        while parameters:\n            request = RequestMessage.new(\n                self.connection,\n                RequestSegment(\n                    message_types.EXECUTE,\n                    (StatementId(prepared_statement.statement_id),\n                     Parameters(parameters))\n                )\n            )\n            reply = self.connection.send_request(request)\n\n            parts = reply.segments[0].parts\n            function_code = reply.segments[0].function_code\n            if function_code == function_codes.SELECT:\n                self._handle_select(parts, prepared_statement.result_metadata_part)\n            elif function_code in function_codes.DML:\n                self._handle_upsert(parts, request.segments[0].parts[1].unwritten_lobs)\n            elif function_code == function_codes.DDL:\n                # No additional handling is required\n                pass\n            elif function_code in (function_codes.DBPROCEDURECALL, function_codes.DBPROCEDURECALLWITHRESULT):\n                self._handle_dbproc_call(parts, prepared_statement._params_metadata) # resultset metadata set in prepare\n            else:\n                raise InterfaceError(\"Invalid or unsupported function code received: %d\" % function_code)", "response": "Executes a prepared statement and returns a generator of result sets."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexecute a direct statement.", "response": "def _execute_direct(self, operation):\n        \"\"\"Execute statements which are not going through 'prepare_statement' (aka 'direct execution').\n        Either their have no parameters, or Python's string expansion has been applied to the SQL statement.\n        :param operation:\n        \"\"\"\n        request = RequestMessage.new(\n            self.connection,\n            RequestSegment(\n                message_types.EXECUTEDIRECT,\n                Command(operation)\n            )\n        )\n        reply = self.connection.send_request(request)\n\n        parts = reply.segments[0].parts\n        function_code = reply.segments[0].function_code\n        if function_code == function_codes.SELECT:\n            self._handle_select(parts)\n        elif function_code in function_codes.DML:\n            self._handle_upsert(parts)\n        elif function_code == function_codes.DDL:\n            # No additional handling is required\n            pass\n        elif function_code in (function_codes.DBPROCEDURECALL, function_codes.DBPROCEDURECALLWITHRESULT):\n            self._handle_dbproc_call(parts, None)\n        else:\n            raise InterfaceError(\"Invalid or unsupported function code received: %d\" % function_code)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef execute(self, statement, parameters=None):\n        self._check_closed()\n\n        if not parameters:\n            # Directly execute the statement, nothing else to prepare:\n            self._execute_direct(statement)\n        else:\n            self.executemany(statement, parameters=[parameters])\n        return self", "response": "Executes a statement on the database returning a cursor object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef executemany(self, statement, parameters):\n        # First try safer hana-style parameter expansion:\n        try:\n            statement_id = self.prepare(statement)\n        except DatabaseError as msg:\n            # Hana expansion failed, check message to be sure of reason:\n            if 'incorrect syntax near \"%\"' not in str(msg):\n                # Probably some other error than related to string expansion -> raise an error\n                raise\n            # Statement contained percentage char, so perform Python style parameter expansion:\n            for row_params in parameters:\n                operation = format_operation(statement, row_params)\n                self._execute_direct(operation)\n        else:\n            # Continue with Hana style statement execution:\n            prepared_statement = self.get_prepared_statement(statement_id)\n            self.execute_prepared(prepared_statement, parameters)\n        # Return cursor object:\n        return self", "response": "Executes a statement on the database with multiple rows to be inserted or updated."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _handle_upsert(self, parts, unwritten_lobs=()):\n        self.description = None\n        self._received_last_resultset_part = True  # set to 'True' so that cursor.fetch*() returns just empty list\n\n        for part in parts:\n            if part.kind == part_kinds.ROWSAFFECTED:\n                self.rowcount = part.values[0]\n            elif part.kind in (part_kinds.TRANSACTIONFLAGS, part_kinds.STATEMENTCONTEXT, part_kinds.PARAMETERMETADATA):\n                pass\n            elif part.kind == part_kinds.WRITELOBREPLY:\n                # This part occurrs after lobs have been submitted not at all or only partially during an insert.\n                # In this case the parameter part of the Request message contains a list called 'unwritten_lobs'\n                # with LobBuffer instances.\n                # Those instances are in the same order as 'locator_ids' received in the reply message. These IDs\n                # are then used to deliver the missing LOB data to the server via WRITE_LOB_REQUESTs.\n                for lob_buffer, lob_locator_id in izip(unwritten_lobs, part.locator_ids):\n                    # store locator_id in every lob buffer instance for later reference:\n                    lob_buffer.locator_id = lob_locator_id\n                self._perform_lob_write_requests(unwritten_lobs)\n            else:\n                raise InterfaceError(\"Prepared insert statement response, unexpected part kind %d.\" % part.kind)\n        self._executed = True", "response": "Handle reply messages from INSERT or UPDATE statements."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _perform_lob_write_requests(self, unwritten_lobs):\n        while unwritten_lobs:\n            request = RequestMessage.new(\n                self.connection,\n                RequestSegment(\n                    message_types.WRITELOB,\n                    WriteLobRequest(unwritten_lobs)\n                )\n            )\n            self.connection.send_request(request)", "response": "This method sends LOBWRITE requests to the server."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhandles reply messages from SELECT statements.", "response": "def _handle_select(self, parts, result_metadata=None):\n        \"\"\"Handle reply messages from SELECT statements\"\"\"\n        self.rowcount = -1\n        if result_metadata is not None:\n            # Select was prepared and we can use the already received metadata\n            self.description, self._column_types = self._handle_result_metadata(result_metadata)\n\n        for part in parts:\n            if part.kind == part_kinds.RESULTSETID:\n                self._resultset_id = part.value\n            elif part.kind == part_kinds.RESULTSETMETADATA:\n                self.description, self._column_types = self._handle_result_metadata(part)\n            elif part.kind == part_kinds.RESULTSET:\n                self._buffer = part.unpack_rows(self._column_types, self.connection)\n                self._received_last_resultset_part = part.attribute & 1\n                self._executed = True\n            elif part.kind in (part_kinds.STATEMENTCONTEXT, part_kinds.TRANSACTIONFLAGS, part_kinds.PARAMETERMETADATA):\n                pass\n            else:\n                raise InterfaceError(\"Prepared select statement response, unexpected part kind %d.\" % part.kind)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _handle_dbproc_call(self, parts, parameters_metadata):\n        for part in parts:\n            if part.kind == part_kinds.ROWSAFFECTED:\n                self.rowcount = part.values[0]\n            elif part.kind == part_kinds.TRANSACTIONFLAGS:\n                pass\n            elif part.kind == part_kinds.STATEMENTCONTEXT:\n                pass\n            elif part.kind == part_kinds.OUTPUTPARAMETERS:\n                self._buffer = part.unpack_rows(parameters_metadata, self.connection)\n                self._received_last_resultset_part = True\n                self._executed = True\n            elif part.kind == part_kinds.RESULTSETMETADATA:\n                self.description, self._column_types = self._handle_result_metadata(part)\n            elif part.kind == part_kinds.RESULTSETID:\n                self._resultset_id = part.value\n            elif part.kind == part_kinds.RESULTSET:\n                self._buffer = part.unpack_rows(self._column_types, self.connection)\n                self._received_last_resultset_part = part.attribute & 1\n                self._executed = True\n            else:\n                raise InterfaceError(\"Stored procedure call, unexpected part kind %d.\" % part.kind)\n        self._executed = True", "response": "Handle reply messages from STORED PROCEDURE statements."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfetching many rows from the select result set.", "response": "def fetchmany(self, size=None):\n        \"\"\"Fetch many rows from select result set.\n        :param size: Number of rows to return.\n        :returns: list of row records (tuples)\n        \"\"\"\n        self._check_closed()\n        if not self._executed:\n            raise ProgrammingError(\"Require execute() first\")\n        if size is None:\n            size = self.arraysize\n\n        result = []\n        cnt = 0\n        while cnt != size:\n            try:\n                result.append(next(self._buffer))\n                cnt += 1\n            except StopIteration:\n                break\n\n        if cnt == size or self._received_last_resultset_part:\n            # No rows are missing or there are no additional rows\n            return result\n\n        request = RequestMessage.new(\n            self.connection,\n            RequestSegment(\n                message_types.FETCHNEXT,\n                (ResultSetId(self._resultset_id), FetchSize(size - cnt))\n            )\n        )\n        response = self.connection.send_request(request)\n\n        resultset_part = response.segments[0].parts[1]\n        if resultset_part.attribute & 1:\n            self._received_last_resultset_part = True\n        result.extend(resultset_part.unpack_rows(self._column_types, self.connection))\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfetching all available rows from select result set.", "response": "def fetchall(self):\n        \"\"\"Fetch all available rows from select result set.\n        :returns: list of row tuples\n        \"\"\"\n        result = r = self.fetchmany(size=self.FETCHALL_BLOCKSIZE)\n        while len(r) == self.FETCHALL_BLOCKSIZE or not self._received_last_resultset_part:\n            r = self.fetchmany(size=self.FETCHALL_BLOCKSIZE)\n            result.extend(r)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef allhexlify(data):\n    hx = binascii.hexlify(data)\n    return b''.join([b'\\\\x' + o for o in re.findall(b'..', hx)])", "response": "Hexlify given data into a string representation with hex values for all chars in the tree tree"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npacks data of part into binary format", "response": "def pack(self, remaining_size):\n        \"\"\"Pack data of part into binary format\"\"\"\n        arguments_count, payload = self.pack_data(remaining_size - self.header_size)\n        payload_length = len(payload)\n\n        # align payload length to multiple of 8\n        if payload_length % 8 != 0:\n            payload += b\"\\x00\" * (8 - payload_length % 8)\n\n        self.header = PartHeader(self.kind, self.attribute, arguments_count, self.bigargumentcount,\n                                 payload_length, remaining_size)\n        hdr = self.header_struct.pack(*self.header)\n        if pyhdb.tracing:\n            self.trace_header = humanhexlify(hdr, 30)\n            self.trace_payload = humanhexlify(payload, 30)\n        return hdr + payload"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nunpack parts from payload", "response": "def unpack_from(cls, payload, expected_parts):\n        \"\"\"Unpack parts from payload\"\"\"\n\n        for num_part in iter_range(expected_parts):\n            hdr = payload.read(cls.header_size)\n            try:\n                part_header = PartHeader(*cls.header_struct.unpack(hdr))\n            except struct.error:\n                raise InterfaceError(\"No valid part header\")\n\n            if part_header.payload_size % 8 != 0:\n                part_payload_size = part_header.payload_size + 8 - (part_header.payload_size % 8)\n            else:\n                part_payload_size = part_header.payload_size\n            pl = payload.read(part_payload_size)\n            part_payload = io.BytesIO(pl)\n            try:\n                _PartClass = PART_MAPPING[part_header.part_kind]\n            except KeyError:\n                raise InterfaceError(\"Unknown part kind %s\" % part_header.part_kind)\n\n            debug('%s (%d/%d): %s', _PartClass.__name__, num_part+1, expected_parts, str(part_header))\n            debug('Read %d bytes payload for part %d', part_payload_size, num_part + 1)\n\n            init_arguments = _PartClass.unpack_data(part_header.argument_count, part_payload)\n            debug('Part data: %s', init_arguments)\n            part = _PartClass(*init_arguments)\n            part.header = part_header\n            part.attribute = part_header.part_attributes\n            part.source = 'server'\n            if pyhdb.tracing:\n                part.trace_header = humanhexlify(hdr[:part_header.payload_size])\n                part.trace_payload = humanhexlify(pl, 30)\n            yield part"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef unpack_rows(self, column_types, connection):\n        for _ in iter_range(self.num_rows):\n            yield tuple(typ.from_resultset(self.payload, connection) for typ in column_types)", "response": "Unpack rows for data from a select statement and yield a single row at a time."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unpack_rows(self, parameters_metadata, connection):\n        values = []\n        for param in parameters_metadata:\n            # Unpack OUT or INOUT parameters' values\n            if param.iotype != parameter_direction.IN:\n                values.append( by_type_code[param.datatype].from_resultset(self.payload) )\n        yield tuple(values)", "response": "Unpack output or input or output parameters from the stored procedure call result\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pack_data(self, remaining_size):\n        payload = self.part_struct.pack(self.locator_id, self.readoffset + 1, self.readlength, b'    ')\n        return 4, payload", "response": "Pack data. readoffset has to be increased by one, seems like HANA starts from 1, not zero."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nunpack payload by splitting up the raw payload into list of locator_ids", "response": "def unpack_data(cls, argument_count, payload):\n        \"\"\"Unpack payload by splitting up the raw payload into list of locator_ids\n        :param argument_count: number of locator_ids in payload is equal to argument_count\n        :param payload: BytesIO instance with list of concatenated locator_ids, where each locator_id is 8 bytes long\n        \"\"\"\n        pl = payload.read()\n        locator_ids = [pl[start:start+8] for start in range(0, len(pl), 8)]\n        return locator_ids,"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npack the lob data into the payload.", "response": "def pack_lob_data(remaining_size, payload, row_header_start_pos, row_lobs):\n        \"\"\"\n        After parameter row has been written, append the lobs and update the corresponding lob headers\n        with lob position and lob size:\n        :param payload: payload object (io.BytesIO instance)\n        :param row_header_start_pos: absolute position of start position of row within payload\n        :param row_lobs: list of row buffer instance (containing binary encoded lob data, header position and DataType)\n        \"\"\"\n        unwritten_lobs = collections.deque()\n        for lob_buffer in row_lobs:\n            # Calculate relative position of lob within the binary packed parameter row.\n            # Add +1, Hana counts from 1, not 0!\n            rel_lob_pos = payload.tell() - row_header_start_pos + 1\n\n            # Calculate how much space is left in message for lob data:\n            max_data_to_write = min(lob_buffer.encoded_lob_size, remaining_size - payload.tell())\n            payload.write(lob_buffer.encoded_data.read(max_data_to_write))\n            is_last_data = max_data_to_write == lob_buffer.encoded_lob_size\n            if not is_last_data:\n                # lob has not been written (partially or entirely) into message -> register for further write requests\n                unwritten_lobs.append(lob_buffer)\n\n            # Write position and size of lob data into lob header block:\n            payload.seek(lob_buffer.lob_header_pos)\n            payload.write(lob_buffer.DataType.prepare(None, length=max_data_to_write,\n                                                      position=rel_lob_pos, is_last_data=is_last_data))\n            # Set pointer back to end for further writing\n            payload.seek(0, io.SEEK_END)\n        return unwritten_lobs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding the payload of the message.", "response": "def build_payload(self, payload):\n        \"\"\" Build payload of message. \"\"\"\n        for segment in self.segments:\n            segment.pack(payload, commit=self.autocommit)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pack(self):\n        payload = io.BytesIO()\n        # Advance num bytes equal to header size - the header is written later\n        # after the payload of all segments and parts has been written:\n        payload.seek(self.header_size, io.SEEK_CUR)\n\n        # Write out payload of segments and parts:\n        self.build_payload(payload)\n\n        packet_length = len(payload.getvalue()) - self.header_size\n        self.header = MessageHeader(self.session_id, self.packet_count, packet_length, constants.MAX_SEGMENT_SIZE,\n                                    num_segments=len(self.segments), packet_options=0)\n        packed_header = self.header_struct.pack(*self.header)\n\n        # Go back to begining of payload for writing message header:\n        payload.seek(0)\n        payload.write(packed_header)\n        payload.seek(0, io.SEEK_END)\n\n        trace(self)\n\n        return payload", "response": "Pack the message into binary stream."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a new RequestMessage instance - extracts required data from connection object", "response": "def new(cls, connection, segments=()):\n        \"\"\"Return a new request message instance - extracts required data from connection object\n        :param connection: connection object\n        :param segments: a single segment instance, or a list/tuple of segment instances\n        :returns: RequestMessage instance\n        \"\"\"\n        return cls(connection.session_id, connection.get_next_packet_count(), segments,\n                   autocommit=connection.autocommit)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef unpack_reply(cls, header, payload):\n        reply = cls(\n            header.session_id, header.packet_count,\n            segments=tuple(ReplySegment.unpack_from(payload, expected_segments=header.num_segments)),\n            header=header\n        )\n        trace(reply)\n        return reply", "response": "Take already unpacked header and binary payload of received request reply and creates a new message instance containing it."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nunpack binary message header data obtained as a reply from HANA", "response": "def header_from_raw_header_data(cls, raw_header):\n        \"\"\"Unpack binary message header data obtained as a reply from HANA\n        :param raw_header: binary string containing message header data\n        :returns: named tuple for easy access of header data\n        \"\"\"\n        try:\n            header = MessageHeader(*cls.header_struct.unpack(raw_header))\n        except struct.error:\n            raise Exception(\"Invalid message header received\")\n        return header"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprint recursive trace of given network protocol object", "response": "def trace(trace_obj):\n    \"\"\"Print recursive trace of given network protocol object\n    :param trace_obj: either a message, segement, or kind object\n    \"\"\"\n    if pyhdb.tracing:\n        t = TraceLogger()\n        tr = t.trace(trace_obj)\n        print(tr)\n        return tr"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef trace(self, trace_obj):\n        tracer = self\n        tracer.writeln(u'%s = ' % trace_obj.__class__.__name__)\n        tracer.incr('{')\n        for attr_name in trace_obj.__tracing_attrs__:\n            attr = getattr(trace_obj, attr_name)\n            if isinstance(attr, tuple) and hasattr(attr, '_fields'):\n                # probably a namedtuple instance\n                tracer.writeln(u'%s = ' % (attr_name,))\n                tracer.incr('[')\n                for k, v in attr._asdict().items():\n                    # _asdict() creates an OrderedDict, so elements are still in order\n                    tracer.writeln(u'%s = %s' % (k, v))\n                tracer.decr(']')\n            elif isinstance(attr, (list, tuple)):\n                if attr:\n                    tracer.writeln(u'%s = ' % (attr_name,))\n                    tracer.incr('[')\n                    for elem in attr:\n                        if hasattr(elem, '__tracing_attrs__'):\n                            self.trace(elem)\n                        else:\n                            # some other plain list element, just print it as it is:\n                            tracer.writeln(u'%s' % repr(elem))\n                    tracer.decr(']')\n                else:\n                    tracer.writeln(u'%s = []' % (attr_name,))\n            else:\n                # a plain attribute object, just print it as it is\n                tracer.writeln(u'%s = %s' % (attr_name, repr(attr)))\n        tracer.decr('}')\n        return self.getvalue()", "response": "Trace given trace_obj recursively."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_root_object(models):\n    root = napalm_yang.base.Root()\n\n    for model in models:\n        current = napalm_yang\n        for p in model.split(\".\"):\n            current = getattr(current, p)\n        root.add_model(current)\n\n    return root", "response": "Read list of models and returns a Root object with the proper models added."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fetchEntries(self):\n        if not self.date:\n            # Fetch latest chart\n            url = 'http://www.billboard.com/charts/%s' % (self.name)\n        else:\n            url = 'http://www.billboard.com/charts/%s/%s' % (\n                self.name, self.date)\n\n        req = requests.get(url, headers=HEADERS, timeout=self._timeout)\n        if req.status_code == 404:\n            message = \"Chart not found (perhaps the name is misspelled?)\"\n            raise BillboardNotFoundException(message)\n        req.raise_for_status()\n\n        soup = BeautifulSoup(req.text, 'html.parser')\n\n        dateElement = soup.select_one(_DATE_ELEMENT_SELECTOR)\n        if dateElement:\n            dateText = dateElement.text.strip()\n            self.date = datetime.datetime.strptime(dateText, '%B %d, %Y').strftime('%Y-%m-%d')\n\n        prevWeek = soup.select_one(_PREVIOUS_DATE_SELECTOR)\n        nextWeek = soup.select_one(_NEXT_DATE_SELECTOR)\n        if prevWeek and prevWeek.parent.get('href'):\n            self.previousDate = prevWeek.parent.get('href').split('/')[-1]\n        if nextWeek and nextWeek.parent.get('href'):\n            self.nextDate = nextWeek.parent.get('href').split('/')[-1]\n\n        for entrySoup in soup.select(_ENTRY_LIST_SELECTOR):\n            try:\n                title = entrySoup[_ENTRY_TITLE_ATTR].strip()\n            except:\n                message = \"Failed to parse title\"\n                raise BillboardParseException(message)\n\n            try:\n                artist = entrySoup[_ENTRY_ARTIST_ATTR].strip() or ''\n            except:\n                message = \"Failed to parse artist\"\n                raise BillboardParseException(message)\n\n            if artist == '':\n                title, artist = artist, title\n\n            try:\n                rank = int(entrySoup[_ENTRY_RANK_ATTR].strip())\n            except:\n                message = \"Failed to parse rank\"\n                raise BillboardParseException(message)\n\n            def getPositionRowValue(rowName):\n                try:\n                    selector = _ROW_SELECTOR_FORMAT % rowName\n                    selected = entrySoup.select_one(selector)\n                    if selected is None or selected.string == '-':\n                        return 0\n                    else:\n                        return int(selected.string.strip())\n                except:\n                    message = \"Failed to parse row value: %s\" % rowName\n                    raise BillboardParseException(message)\n\n            if self.date:\n                peakPos = getPositionRowValue(_PEAK_POS_FORMAT)\n                peakPos = rank if peakPos == 0 else peakPos\n                lastPos = getPositionRowValue(_LAST_POS_FORMAT)\n                weeks = getPositionRowValue(_WEEKS_ON_CHART_FORMAT)\n                weeks = weeks if weeks != 0 else 1\n                isNew = True if weeks == 1 else False\n            else:\n                peakPos = lastPos = weeks = None\n                isNew = False\n\n            entry = ChartEntry(title, artist, peakPos, lastPos, weeks, rank, isNew)\n            self.entries.append(entry)", "response": "Fetches the corresponding chart data from Billboard. com and parses it into a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_specs(specs, renamings, types):\n    '''\n    Does nothing but raising PythranSyntaxError if specs\n    are incompatible with the actual code\n    '''\n    from pythran.types.tog import unify, clone, tr\n    from pythran.types.tog import Function, TypeVariable, InferenceError\n\n    functions = {renamings.get(k, k): v for k, v in specs.functions.items()}\n    for fname, signatures in functions.items():\n        ftype = types[fname]\n        for signature in signatures:\n            sig_type = Function([tr(p) for p in signature], TypeVariable())\n            try:\n                unify(clone(sig_type), clone(ftype))\n            except InferenceError:\n                raise PythranSyntaxError(\n                    \"Specification for `{}` does not match inferred type:\\n\"\n                    \"expected `{}`\\n\"\n                    \"got `Callable[[{}], ...]`\".format(\n                        fname,\n                        ftype,\n                        \", \".join(map(str, sig_type.types[:-1])))\n                )", "response": "Does nothing but raising PythranSyntaxError if specs are incompatible with the actual code\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_exports(mod, specs, renamings):\n    '''\n    Does nothing but raising PythranSyntaxError if specs\n    references an undefined global\n    '''\n    functions = {renamings.get(k, k): v for k, v in specs.functions.items()}\n\n    mod_functions = {node.name: node for node in mod.body\n                     if isinstance(node, ast.FunctionDef)}\n\n    for fname, signatures in functions.items():\n        try:\n            fnode = mod_functions[fname]\n        except KeyError:\n            raise PythranSyntaxError(\n                \"Invalid spec: exporting undefined function `{}`\"\n                .format(fname))\n        for signature in signatures:\n            args_count = len(fnode.args.args)\n            if len(signature) > args_count:\n                raise PythranSyntaxError(\n                    \"Too many arguments when exporting `{}`\"\n                    .format(fname))\n            elif len(signature) < args_count - len(fnode.args.defaults):\n                raise PythranSyntaxError(\n                    \"Not enough arguments when exporting `{}`\"\n                    .format(fname))", "response": "Does nothing but raising PythranSyntaxError if specs\n                     references an undefined global\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if imported module exists in MODULES.", "response": "def visit_Import(self, node):\n        \"\"\" Check if imported module exists in MODULES. \"\"\"\n        for alias in node.names:\n            current_module = MODULES\n            # Recursive check for submodules\n            for path in alias.name.split('.'):\n                if path not in current_module:\n                    raise PythranSyntaxError(\n                        \"Module '{0}' unknown.\".format(alias.name),\n                        node)\n                else:\n                    current_module = current_module[path]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef visit_ImportFrom(self, node):\n        if node.level:\n            raise PythranSyntaxError(\"Relative import not supported\", node)\n        if not node.module:\n            raise PythranSyntaxError(\"import from without module\", node)\n        module = node.module\n        current_module = MODULES\n        # Check if module exists\n        for path in module.split('.'):\n            if path not in current_module:\n                raise PythranSyntaxError(\n                    \"Module '{0}' unknown.\".format(module),\n                    node)\n            else:\n                current_module = current_module[path]\n\n        # Check if imported functions exist\n        for alias in node.names:\n            if alias.name == '*':\n                continue\n            elif alias.name not in current_module:\n                raise PythranSyntaxError(\n                    \"identifier '{0}' not found in module '{1}'\".format(\n                        alias.name,\n                        module),\n                    node)", "response": "Check validity of imported functions."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef uncamel(name):\n    s1 = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', name)\n    return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', s1).lower()", "response": "Transform CamelCase naming convention into C -ish convention."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef verify_dependencies(self):\n\n        for i in range(1, len(self.deps)):\n            assert(not (isinstance(self.deps[i], Transformation) and\n                   isinstance(self.deps[i - 1], Analysis))\n                   ), \"invalid dep order for %s\" % self", "response": "Checks that all dependencies are valid and that the analysis is not called before a transformation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef prepare(self, node):\n        '''Gather analysis result required by this analysis'''\n        if isinstance(node, ast.Module):\n            self.ctx.module = node\n        elif isinstance(node, ast.FunctionDef):\n            self.ctx.function = node\n\n        for D in self.deps:\n            d = D()\n            d.attach(self.passmanager, self.ctx)\n            result = d.run(node)\n            setattr(self, uncamel(D.__name__), result)", "response": "Gather analysis result required by this analysis"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run(self, node):\n        n = super(Transformation, self).run(node)\n        if self.update:\n            ast.fix_missing_locations(n)\n            self.passmanager._cache.clear()\n        return n", "response": "Apply transformation and dependencies and fix new node location."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef apply(self, node):\n        new_node = self.run(node)\n        return self.update, new_node", "response": "Apply transformation and return if an update happened."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef gather(self, analysis, node):\n        \"High-level function to call an `analysis' on a `node'\"\n        assert issubclass(analysis, Analysis)\n        a = analysis()\n        a.attach(self)\n        return a.run(node)", "response": "High - level function to call an analysis on a node"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dump(self, backend, node):\n        '''High-level function to call a `backend' on a `node' to generate\n        code for module `module_name'.'''\n        assert issubclass(backend, Backend)\n        b = backend()\n        b.attach(self)\n        return b.run(node)", "response": "High - level function to call a backend on a node to generate\n        code for module module_name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pytype_to_ctype(t):\n    if isinstance(t, List):\n        return 'pythonic::types::list<{0}>'.format(\n            pytype_to_ctype(t.__args__[0])\n        )\n    elif isinstance(t, Set):\n        return 'pythonic::types::set<{0}>'.format(\n            pytype_to_ctype(t.__args__[0])\n        )\n    elif isinstance(t, Dict):\n        tkey, tvalue = t.__args__\n        return 'pythonic::types::dict<{0},{1}>'.format(pytype_to_ctype(tkey),\n                                                       pytype_to_ctype(tvalue))\n    elif isinstance(t, Tuple):\n        return 'decltype(pythonic::types::make_tuple({0}))'.format(\n            \", \".join('std::declval<{}>()'.format(pytype_to_ctype(p))\n                      for p in t.__args__)\n        )\n    elif isinstance(t, NDArray):\n        dtype = pytype_to_ctype(t.__args__[0])\n        ndim = len(t.__args__) - 1\n        shapes = ','.join(('long'\n                           if s.stop == -1 or s.stop is None\n                           else 'std::integral_constant<long, {}>'.format(\n                               s.stop)\n                           ) for s in t.__args__[1:])\n        pshape = 'pythonic::types::pshape<{0}>'.format(shapes)\n        arr = 'pythonic::types::ndarray<{0},{1}>'.format(\n                    dtype, pshape)\n        if t.__args__[1].start == -1:\n            return 'pythonic::types::numpy_texpr<{0}>'.format(arr)\n        elif any(s.step is not None and s.step < 0 for s in t.__args__[1:]):\n            slices = \", \".join(['pythonic::types::normalized_slice'] * ndim)\n            return 'pythonic::types::numpy_gexpr<{0},{1}>'.format(arr, slices)\n        else:\n            return arr\n    elif isinstance(t, Pointer):\n        return 'pythonic::types::pointer<{0}>'.format(\n            pytype_to_ctype(t.__args__[0])\n        )\n    elif isinstance(t, Fun):\n        return 'pythonic::types::cfun<{0}({1})>'.format(\n            pytype_to_ctype(t.__args__[-1]),\n            \", \".join(pytype_to_ctype(arg) for arg in t.__args__[:-1]),\n        )\n    elif t in PYTYPE_TO_CTYPE_TABLE:\n        return PYTYPE_TO_CTYPE_TABLE[t]\n    else:\n        raise NotImplementedError(\"{0}:{1}\".format(type(t), t))", "response": "Python -> pythonic type binding."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pytype_to_pretty_type(t):\n    if isinstance(t, List):\n        return '{0} list'.format(pytype_to_pretty_type(t.__args__[0]))\n    elif isinstance(t, Set):\n        return '{0} set'.format(pytype_to_pretty_type(t.__args__[0]))\n    elif isinstance(t, Dict):\n        tkey, tvalue = t.__args__\n        return '{0}:{1} dict'.format(pytype_to_pretty_type(tkey),\n                                     pytype_to_pretty_type(tvalue))\n    elif isinstance(t, Tuple):\n        return '({0})'.format(\n            \", \".join(pytype_to_pretty_type(p) for p in t.__args__)\n        )\n    elif isinstance(t, NDArray):\n        dtype = pytype_to_pretty_type(t.__args__[0])\n        ndim = len(t.__args__) - 1\n        arr = '{0}[{1}]'.format(\n            dtype,\n            ','.join(':' if s.stop in (-1, None) else str(s.stop)\n                     for s in t.__args__[1:]))\n        # it's a transpose!\n        if t.__args__[1].start == -1:\n            return '{} order(F)'.format(arr)\n        elif any(s.step is not None and s.step < 0 for s in t.__args__[1:]):\n            return '{0}[{1}]'.format(dtype, ','.join(['::'] * ndim))\n        else:\n            return arr\n    elif isinstance(t, Pointer):\n        dtype = pytype_to_pretty_type(t.__args__[0])\n        return '{}*'.format(dtype)\n    elif isinstance(t, Fun):\n        rtype = pytype_to_pretty_type(t.__args__[-1])\n        argtypes = [pytype_to_pretty_type(arg) for arg in t.__args__[:-1]]\n        return '{}({})'.format(rtype, \", \".join(argtypes))\n    elif t in PYTYPE_TO_CTYPE_TABLE:\n        return t.__name__\n    else:\n        raise NotImplementedError(\"{0}:{1}\".format(type(t), t))", "response": "Python type to pretty type."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_builtin_module(module_name):\n    module_name = module_name.split(\".\")[0]\n    return (module_name in MODULES or\n            (module_name in cxx_keywords and module_name + \"_\" in MODULES))", "response": "Test if a module is a builtin module."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef interleave(inter, f, seq):\n    seq = iter(seq)\n    try:\n        f(next(seq))\n    except StopIteration:\n        pass\n    else:\n        for x in seq:\n            inter()\n            f(x)", "response": "Call f on each item in seq calling inter in between."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fill(self, text=\"\"):\n        \"Indent a piece of text, according to the current indentation level\"\n        self.f.write(self.line_marker + \"    \" * self._indent + text)\n        self.line_marker = \"\\n\"", "response": "Indent a piece of text according to the current indentation level"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dispatch(self, tree):\n        # display omp directive in python dump\n        for omp in metadata.get(tree, openmp.OMPDirective):\n            deps = list()\n            for dep in omp.deps:\n                old_file = self.f\n                self.f = io.StringIO()\n                self.dispatch(dep)\n                deps.append(self.f.getvalue())\n                self.f = old_file\n            directive = omp.s.format(*deps)\n            self._Expr(ast.Expr(ast.Str(s=directive)))\n\n        if isinstance(tree, list):\n            for t in tree:\n                self.dispatch(t)\n            return\n        meth = getattr(self, \"_\" + tree.__class__.__name__)\n        meth(tree)", "response": "Dispatches a tree type T to method _T."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef analyse(node, env, non_generic=None):\n\n    if non_generic is None:\n        non_generic = set()\n\n    # expr\n    if isinstance(node, gast.Name):\n        if isinstance(node.ctx, (gast.Store)):\n            new_type = TypeVariable()\n            non_generic.add(new_type)\n            env[node.id] = new_type\n        return get_type(node.id, env, non_generic)\n    elif isinstance(node, gast.Num):\n        if isinstance(node.n, int):\n            return Integer()\n        elif isinstance(node.n, float):\n            return Float()\n        elif isinstance(node.n, complex):\n            return Complex()\n        else:\n            raise NotImplementedError\n    elif isinstance(node, gast.Str):\n        return Str()\n    elif isinstance(node, gast.Compare):\n        left_type = analyse(node.left, env, non_generic)\n        comparators_type = [analyse(comparator, env, non_generic)\n                            for comparator in node.comparators]\n        ops_type = [analyse(op, env, non_generic)\n                    for op in node.ops]\n        prev_type = left_type\n        result_type = TypeVariable()\n        for op_type, comparator_type in zip(ops_type, comparators_type):\n            try:\n                unify(Function([prev_type, comparator_type], result_type),\n                      op_type)\n                prev_type = comparator_type\n            except InferenceError:\n                raise PythranTypeError(\n                    \"Invalid comparison, between `{}` and `{}`\".format(\n                        prev_type,\n                        comparator_type\n                    ),\n                    node)\n        return result_type\n    elif isinstance(node, gast.Call):\n        if is_getattr(node):\n            self_type = analyse(node.args[0], env, non_generic)\n            attr_name = node.args[1].s\n            _, attr_signature = attributes[attr_name]\n            attr_type = tr(attr_signature)\n            result_type = TypeVariable()\n            try:\n                unify(Function([self_type], result_type), attr_type)\n            except InferenceError:\n                if isinstance(prune(attr_type), MultiType):\n                    msg = 'no attribute found, tried:\\n{}'.format(attr_type)\n                else:\n                    msg = 'tried {}'.format(attr_type)\n                raise PythranTypeError(\n                    \"Invalid attribute for getattr call with self\"\n                    \"of type `{}`, {}\".format(self_type, msg), node)\n\n        else:\n            fun_type = analyse(node.func, env, non_generic)\n            arg_types = [analyse(arg, env, non_generic) for arg in node.args]\n            result_type = TypeVariable()\n            try:\n                unify(Function(arg_types, result_type), fun_type)\n            except InferenceError:\n                # recover original type\n                fun_type = analyse(node.func, env, non_generic)\n                if isinstance(prune(fun_type), MultiType):\n                    msg = 'no overload found, tried:\\n{}'.format(fun_type)\n                else:\n                    msg = 'tried {}'.format(fun_type)\n                raise PythranTypeError(\n                    \"Invalid argument type for function call to \"\n                    \"`Callable[[{}], ...]`, {}\"\n                    .format(', '.join('{}'.format(at) for at in arg_types),\n                            msg),\n                    node)\n        return result_type\n\n    elif isinstance(node, gast.IfExp):\n        test_type = analyse(node.test, env, non_generic)\n        unify(Function([test_type], Bool()),\n              tr(MODULES['__builtin__']['bool_']))\n\n        if is_test_is_none(node.test):\n            none_id = node.test.left.id\n            body_env = env.copy()\n            body_env[none_id] = NoneType\n        else:\n            none_id = None\n            body_env = env\n\n        body_type = analyse(node.body, body_env, non_generic)\n\n        if none_id:\n            orelse_env = env.copy()\n            if is_option_type(env[none_id]):\n                orelse_env[none_id] = prune(env[none_id]).types[0]\n            else:\n                orelse_env[none_id] = TypeVariable()\n        else:\n            orelse_env = env\n\n        orelse_type = analyse(node.orelse, orelse_env, non_generic)\n\n        try:\n            return merge_unify(body_type, orelse_type)\n        except InferenceError:\n            raise PythranTypeError(\n                \"Incompatible types from different branches:\"\n                \"`{}` and `{}`\".format(\n                    body_type,\n                    orelse_type\n                ),\n                node\n            )\n    elif isinstance(node, gast.UnaryOp):\n        operand_type = analyse(node.operand, env, non_generic)\n        op_type = analyse(node.op, env, non_generic)\n        result_type = TypeVariable()\n        try:\n            unify(Function([operand_type], result_type), op_type)\n            return result_type\n        except InferenceError:\n            raise PythranTypeError(\n                \"Invalid operand for `{}`: `{}`\".format(\n                    symbol_of[type(node.op)],\n                    operand_type\n                ),\n                node\n            )\n    elif isinstance(node, gast.BinOp):\n        left_type = analyse(node.left, env, non_generic)\n        op_type = analyse(node.op, env, non_generic)\n        right_type = analyse(node.right, env, non_generic)\n        result_type = TypeVariable()\n        try:\n            unify(Function([left_type, right_type], result_type), op_type)\n        except InferenceError:\n            raise PythranTypeError(\n                \"Invalid operand for `{}`: `{}` and `{}`\".format(\n                    symbol_of[type(node.op)],\n                    left_type,\n                    right_type),\n                node\n            )\n        return result_type\n    elif isinstance(node, gast.Pow):\n        return tr(MODULES['numpy']['power'])\n    elif isinstance(node, gast.Sub):\n        return tr(MODULES['operator_']['sub'])\n    elif isinstance(node, (gast.USub, gast.UAdd)):\n        return tr(MODULES['operator_']['pos'])\n    elif isinstance(node, (gast.Eq, gast.NotEq, gast.Lt, gast.LtE, gast.Gt,\n                           gast.GtE, gast.Is, gast.IsNot)):\n        return tr(MODULES['operator_']['eq'])\n    elif isinstance(node, (gast.In, gast.NotIn)):\n        contains_sig = tr(MODULES['operator_']['contains'])\n        contains_sig.types[:-1] = reversed(contains_sig.types[:-1])\n        return contains_sig\n    elif isinstance(node, gast.Add):\n        return tr(MODULES['operator_']['add'])\n    elif isinstance(node, gast.Mult):\n        return tr(MODULES['operator_']['mul'])\n    elif isinstance(node, gast.MatMult):\n        return tr(MODULES['operator_']['matmul'])\n    elif isinstance(node, (gast.Div, gast.FloorDiv)):\n        return tr(MODULES['operator_']['floordiv'])\n    elif isinstance(node, gast.Mod):\n        return tr(MODULES['operator_']['mod'])\n    elif isinstance(node, (gast.LShift, gast.RShift)):\n        return tr(MODULES['operator_']['lshift'])\n    elif isinstance(node, (gast.BitXor, gast.BitAnd, gast.BitOr)):\n        return tr(MODULES['operator_']['lshift'])\n    elif isinstance(node, gast.List):\n        new_type = TypeVariable()\n        for elt in node.elts:\n            elt_type = analyse(elt, env, non_generic)\n            try:\n                unify(new_type, elt_type)\n            except InferenceError:\n                raise PythranTypeError(\n                    \"Incompatible list element type `{}` and `{}`\".format(\n                        new_type, elt_type),\n                    node\n                )\n        return List(new_type)\n    elif isinstance(node, gast.Set):\n        new_type = TypeVariable()\n        for elt in node.elts:\n            elt_type = analyse(elt, env, non_generic)\n            try:\n                unify(new_type, elt_type)\n            except InferenceError:\n                raise PythranTypeError(\n                    \"Incompatible set element type `{}` and `{}`\".format(\n                        new_type, elt_type),\n                    node\n                )\n        return Set(new_type)\n    elif isinstance(node, gast.Dict):\n        new_key_type = TypeVariable()\n        for key in node.keys:\n            key_type = analyse(key, env, non_generic)\n            try:\n                unify(new_key_type, key_type)\n            except InferenceError:\n                raise PythranTypeError(\n                    \"Incompatible dict key type `{}` and `{}`\".format(\n                        new_key_type, key_type),\n                    node\n                )\n        new_value_type = TypeVariable()\n        for value in node.values:\n            value_type = analyse(value, env, non_generic)\n            try:\n                unify(new_value_type, value_type)\n            except InferenceError:\n                raise PythranTypeError(\n                    \"Incompatible dict value type `{}` and `{}`\".format(\n                        new_value_type, value_type),\n                    node\n                )\n        return Dict(new_key_type, new_value_type)\n    elif isinstance(node, gast.Tuple):\n        return Tuple([analyse(elt, env, non_generic) for elt in node.elts])\n    elif isinstance(node, gast.Index):\n        return analyse(node.value, env, non_generic)\n    elif isinstance(node, gast.Slice):\n        def unify_int_or_none(t, name):\n            try:\n                unify(t, Integer())\n            except InferenceError:\n                try:\n                    unify(t, NoneType)\n                except InferenceError:\n                    raise PythranTypeError(\n                        \"Invalid slice {} type `{}`, expecting int or None\"\n                        .format(name, t)\n                    )\n        if node.lower:\n            lower_type = analyse(node.lower, env, non_generic)\n            unify_int_or_none(lower_type, 'lower bound')\n        else:\n            lower_type = Integer()\n        if node.upper:\n            upper_type = analyse(node.upper, env, non_generic)\n            unify_int_or_none(upper_type, 'upper bound')\n        else:\n            upper_type = Integer()\n        if node.step:\n            step_type = analyse(node.step, env, non_generic)\n            unify_int_or_none(step_type, 'step')\n        else:\n            step_type = Integer()\n        return Slice\n    elif isinstance(node, gast.ExtSlice):\n        return [analyse(dim, env, non_generic) for dim in node.dims]\n    elif isinstance(node, gast.NameConstant):\n        if node.value is None:\n            return env['None']\n    elif isinstance(node, gast.Subscript):\n        new_type = TypeVariable()\n        value_type = prune(analyse(node.value, env, non_generic))\n        try:\n            slice_type = prune(analyse(node.slice, env, non_generic))\n        except PythranTypeError as e:\n            raise PythranTypeError(e.msg, node)\n\n        if isinstance(node.slice, gast.ExtSlice):\n            nbslice = len(node.slice.dims)\n            dtype = TypeVariable()\n            try:\n                unify(Array(dtype, nbslice), clone(value_type))\n            except InferenceError:\n                raise PythranTypeError(\n                    \"Dimension mismatch when slicing `{}`\".format(value_type),\n                    node)\n            return TypeVariable()  # FIXME\n        elif isinstance(node.slice, gast.Index):\n            # handle tuples in a special way\n            isnum = isinstance(node.slice.value, gast.Num)\n            if isnum and is_tuple_type(value_type):\n                try:\n                    unify(prune(prune(value_type.types[0]).types[0])\n                          .types[node.slice.value.n],\n                          new_type)\n                    return new_type\n                except IndexError:\n                    raise PythranTypeError(\n                        \"Invalid tuple indexing, \"\n                        \"out-of-bound index `{}` for type `{}`\".format(\n                            node.slice.value.n,\n                            value_type),\n                        node)\n        try:\n            unify(tr(MODULES['operator_']['getitem']),\n                  Function([value_type, slice_type], new_type))\n        except InferenceError:\n            raise PythranTypeError(\n                \"Invalid subscripting of `{}` by `{}`\".format(\n                    value_type,\n                    slice_type),\n                node)\n        return new_type\n        return new_type\n    elif isinstance(node, gast.Attribute):\n        from pythran.utils import attr_to_path\n        obj, path = attr_to_path(node)\n        if obj.signature is typing.Any:\n            return TypeVariable()\n        else:\n            return tr(obj)\n\n    # stmt\n    elif isinstance(node, gast.Import):\n        for alias in node.names:\n            if alias.name not in MODULES:\n                raise NotImplementedError(\"unknown module: %s \" % alias.name)\n            if alias.asname is None:\n                target = alias.name\n            else:\n                target = alias.asname\n            env[target] = tr(MODULES[alias.name])\n        return env\n    elif isinstance(node, gast.ImportFrom):\n        if node.module not in MODULES:\n            raise NotImplementedError(\"unknown module: %s\" % node.module)\n        for alias in node.names:\n            if alias.name not in MODULES[node.module]:\n                raise NotImplementedError(\n                    \"unknown function: %s in %s\" % (alias.name, node.module))\n            if alias.asname is None:\n                target = alias.name\n            else:\n                target = alias.asname\n            env[target] = tr(MODULES[node.module][alias.name])\n        return env\n    elif isinstance(node, gast.FunctionDef):\n        ftypes = []\n        for i in range(1 + len(node.args.defaults)):\n            new_env = env.copy()\n            new_non_generic = non_generic.copy()\n\n            # reset return special variables\n            new_env.pop('@ret', None)\n            new_env.pop('@gen', None)\n\n            hy = HasYield()\n            for stmt in node.body:\n                hy.visit(stmt)\n            new_env['@gen'] = hy.has_yield\n\n            arg_types = []\n            istop = len(node.args.args) - i\n            for arg in node.args.args[:istop]:\n                arg_type = TypeVariable()\n                new_env[arg.id] = arg_type\n                new_non_generic.add(arg_type)\n                arg_types.append(arg_type)\n            for arg, expr in zip(node.args.args[istop:],\n                                 node.args.defaults[-i:]):\n                arg_type = analyse(expr, new_env, new_non_generic)\n                new_env[arg.id] = arg_type\n\n            analyse_body(node.body, new_env, new_non_generic)\n\n            result_type = new_env.get('@ret', NoneType)\n\n            if new_env['@gen']:\n                result_type = Generator(result_type)\n\n            ftype = Function(arg_types, result_type)\n            ftypes.append(ftype)\n        if len(ftypes) == 1:\n            ftype = ftypes[0]\n            env[node.name] = ftype\n        else:\n            env[node.name] = MultiType(ftypes)\n        return env\n    elif isinstance(node, gast.Module):\n        analyse_body(node.body, env, non_generic)\n        return env\n    elif isinstance(node, (gast.Pass, gast.Break, gast.Continue)):\n        return env\n    elif isinstance(node, gast.Expr):\n        analyse(node.value, env, non_generic)\n        return env\n    elif isinstance(node, gast.Delete):\n        for target in node.targets:\n            if isinstance(target, gast.Name):\n                if target.id in env:\n                    del env[target.id]\n                else:\n                    raise PythranTypeError(\n                        \"Invalid del: unbound identifier `{}`\".format(\n                            target.id),\n                        node)\n            else:\n                analyse(target, env, non_generic)\n        return env\n    elif isinstance(node, gast.Print):\n        if node.dest is not None:\n            analyse(node.dest, env, non_generic)\n        for value in node.values:\n            analyse(value, env, non_generic)\n        return env\n    elif isinstance(node, gast.Assign):\n        defn_type = analyse(node.value, env, non_generic)\n        for target in node.targets:\n            target_type = analyse(target, env, non_generic)\n            try:\n                unify(target_type, defn_type)\n            except InferenceError:\n                raise PythranTypeError(\n                    \"Invalid assignment from type `{}` to type `{}`\".format(\n                        target_type,\n                        defn_type),\n                    node)\n        return env\n    elif isinstance(node, gast.AugAssign):\n        # FIMXE: not optimal: evaluates type of node.value twice\n        fake_target = deepcopy(node.target)\n        fake_target.ctx = gast.Load()\n        fake_op = gast.BinOp(fake_target, node.op, node.value)\n        gast.copy_location(fake_op, node)\n        res_type = analyse(fake_op, env, non_generic)\n        target_type = analyse(node.target, env, non_generic)\n\n        try:\n            unify(target_type, res_type)\n        except InferenceError:\n            raise PythranTypeError(\n                \"Invalid update operand for `{}`: `{}` and `{}`\".format(\n                    symbol_of[type(node.op)],\n                    res_type,\n                    target_type\n                ),\n                node\n            )\n        return env\n    elif isinstance(node, gast.Raise):\n        return env  # TODO\n    elif isinstance(node, gast.Return):\n        if env['@gen']:\n            return env\n\n        if node.value is None:\n            ret_type = NoneType\n        else:\n            ret_type = analyse(node.value, env, non_generic)\n        if '@ret' in env:\n            try:\n                ret_type = merge_unify(env['@ret'], ret_type)\n            except InferenceError:\n                raise PythranTypeError(\n                    \"function may returns with incompatible types \"\n                    \"`{}` and `{}`\".format(env['@ret'], ret_type),\n                    node\n                )\n\n        env['@ret'] = ret_type\n        return env\n    elif isinstance(node, gast.Yield):\n        assert env['@gen']\n        assert node.value is not None\n\n        if node.value is None:\n            ret_type = NoneType\n        else:\n            ret_type = analyse(node.value, env, non_generic)\n        if '@ret' in env:\n            try:\n                ret_type = merge_unify(env['@ret'], ret_type)\n            except InferenceError:\n                raise PythranTypeError(\n                    \"function may yields incompatible types \"\n                    \"`{}` and `{}`\".format(env['@ret'], ret_type),\n                    node\n                )\n\n        env['@ret'] = ret_type\n        return env\n    elif isinstance(node, gast.For):\n        iter_type = analyse(node.iter, env, non_generic)\n        target_type = analyse(node.target, env, non_generic)\n        unify(Collection(TypeVariable(), TypeVariable(), TypeVariable(),\n                         target_type),\n              iter_type)\n        analyse_body(node.body, env, non_generic)\n        analyse_body(node.orelse, env, non_generic)\n        return env\n    elif isinstance(node, gast.If):\n        test_type = analyse(node.test, env, non_generic)\n        unify(Function([test_type], Bool()),\n              tr(MODULES['__builtin__']['bool_']))\n\n        body_env = env.copy()\n        body_non_generic = non_generic.copy()\n\n        if is_test_is_none(node.test):\n            none_id = node.test.left.id\n            body_env[none_id] = NoneType\n        else:\n            none_id = None\n\n        analyse_body(node.body, body_env, body_non_generic)\n\n        orelse_env = env.copy()\n        orelse_non_generic = non_generic.copy()\n\n        if none_id:\n            if is_option_type(env[none_id]):\n                orelse_env[none_id] = prune(env[none_id]).types[0]\n            else:\n                orelse_env[none_id] = TypeVariable()\n        analyse_body(node.orelse, orelse_env, orelse_non_generic)\n\n        for var in body_env:\n            if var not in env:\n                if var in orelse_env:\n                    try:\n                        new_type = merge_unify(body_env[var], orelse_env[var])\n                    except InferenceError:\n                        raise PythranTypeError(\n                            \"Incompatible types from different branches for \"\n                            \"`{}`: `{}` and `{}`\".format(\n                                var,\n                                body_env[var],\n                                orelse_env[var]\n                            ),\n                            node\n                        )\n                else:\n                    new_type = body_env[var]\n                env[var] = new_type\n\n        for var in orelse_env:\n            if var not in env:\n                # may not be unified by the prev loop if a del occured\n                if var in body_env:\n                    new_type = merge_unify(orelse_env[var], body_env[var])\n                else:\n                    new_type = orelse_env[var]\n                env[var] = new_type\n\n        if none_id:\n            try:\n                new_type = merge_unify(body_env[none_id], orelse_env[none_id])\n            except InferenceError:\n                msg = (\"Inconsistent types while merging values of `{}` from \"\n                       \"conditional branches: `{}` and `{}`\")\n                err = msg.format(none_id,\n                                 body_env[none_id],\n                                 orelse_env[none_id])\n                raise PythranTypeError(err, node)\n            env[none_id] = new_type\n\n        return env\n    elif isinstance(node, gast.While):\n        test_type = analyse(node.test, env, non_generic)\n        unify(Function([test_type], Bool()),\n              tr(MODULES['__builtin__']['bool_']))\n\n        analyse_body(node.body, env, non_generic)\n        analyse_body(node.orelse, env, non_generic)\n        return env\n    elif isinstance(node, gast.Try):\n        analyse_body(node.body, env, non_generic)\n        for handler in node.handlers:\n            analyse(handler, env, non_generic)\n        analyse_body(node.orelse, env, non_generic)\n        analyse_body(node.finalbody, env, non_generic)\n        return env\n    elif isinstance(node, gast.ExceptHandler):\n        if(node.name):\n            new_type = ExceptionType\n            non_generic.add(new_type)\n            if node.name.id in env:\n                unify(env[node.name.id], new_type)\n            else:\n                env[node.name.id] = new_type\n        analyse_body(node.body, env, non_generic)\n        return env\n    elif isinstance(node, gast.Assert):\n        if node.msg:\n            analyse(node.msg, env, non_generic)\n        analyse(node.test, env, non_generic)\n        return env\n    elif isinstance(node, gast.UnaryOp):\n        operand_type = analyse(node.operand, env, non_generic)\n        return_type = TypeVariable()\n        op_type = analyse(node.op, env, non_generic)\n        unify(Function([operand_type], return_type), op_type)\n        return return_type\n    elif isinstance(node, gast.Invert):\n        return MultiType([Function([Bool()], Integer()),\n                          Function([Integer()], Integer())])\n    elif isinstance(node, gast.Not):\n        return tr(MODULES['__builtin__']['bool_'])\n    elif isinstance(node, gast.BoolOp):\n        op_type = analyse(node.op, env, non_generic)\n        value_types = [analyse(value, env, non_generic)\n                       for value in node.values]\n\n        for value_type in value_types:\n            unify(Function([value_type], Bool()),\n                  tr(MODULES['__builtin__']['bool_']))\n\n        return_type = TypeVariable()\n        prev_type = value_types[0]\n        for value_type in value_types[1:]:\n            unify(Function([prev_type, value_type], return_type), op_type)\n            prev_type = value_type\n        return return_type\n    elif isinstance(node, (gast.And, gast.Or)):\n        x_type = TypeVariable()\n        return MultiType([\n            Function([x_type, x_type], x_type),\n            Function([TypeVariable(), TypeVariable()], TypeVariable()),\n        ])\n\n    raise RuntimeError(\"Unhandled syntax node {0}\".format(type(node)))", "response": "Analyse the abstract syntax tree node and returns the type of the expression."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_type(name, env, non_generic):\n    if name in env:\n        if isinstance(env[name], MultiType):\n            return clone(env[name])\n        return fresh(env[name], non_generic)\n    else:\n        print(\"W: Undefined symbol {0}\".format(name))\n        return TypeVariable()", "response": "Get the type of identifier name from the type environment env."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmakes a copy of a type expression.", "response": "def fresh(t, non_generic):\n    \"\"\"Makes a copy of a type expression.\n\n    The type t is copied. The generic variables are duplicated and the\n    non_generic variables are shared.\n\n    Args:\n        t: A type to be copied.\n        non_generic: A set of non-generic TypeVariables\n    \"\"\"\n\n    mappings = {}  # A mapping of TypeVariables to TypeVariables\n\n    def freshrec(tp):\n        p = prune(tp)\n        if isinstance(p, TypeVariable):\n            if is_generic(p, non_generic):\n                if p not in mappings:\n                    mappings[p] = TypeVariable()\n                return mappings[p]\n            else:\n                return p\n        elif isinstance(p, dict):\n            return p  # module\n        elif isinstance(p, Collection):\n            return Collection(*[freshrec(x) for x in p.types])\n        elif isinstance(p, Scalar):\n            return Scalar([freshrec(x) for x in p.types])\n        elif isinstance(p, TypeOperator):\n            return TypeOperator(p.name, [freshrec(x) for x in p.types])\n        elif isinstance(p, MultiType):\n            return MultiType([freshrec(x) for x in p.types])\n        else:\n            assert False, \"missing freshrec case {}\".format(type(p))\n\n    return freshrec(t)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef unify(t1, t2):\n\n    a = prune(t1)\n    b = prune(t2)\n    if isinstance(a, TypeVariable):\n        if a != b:\n            if occurs_in_type(a, b):\n                raise InferenceError(\"recursive unification\")\n            a.instance = b\n    elif isinstance(b, TypeVariable):\n        unify(b, a)\n    elif isinstance(a, TypeOperator) and a.name == 'any':\n            return\n    elif isinstance(b, TypeOperator) and b.name == 'any':\n            return\n    elif isinstance(a, TypeOperator) and isinstance(b, TypeOperator):\n        if len(a.types) != len(b.types):\n            raise InferenceError(\"Type length differ\")\n        else:\n            if a.name != b.name:\n                raise InferenceError(\"Type name differ\")\n        try:\n            for p, q in zip(a.types, b.types):\n                unify(p, q)\n        except InferenceError:\n            raise\n    elif isinstance(a, MultiType) and isinstance(b, MultiType):\n        if len(a.types) != len(b.types):\n            raise InferenceError(\"Type lenght differ\")\n        for p, q in zip(a.types, b.types):\n            unify(p, q)\n    elif isinstance(b, MultiType):\n        return unify(b, a)\n    elif isinstance(a, MultiType):\n        types = []\n        for t in a.types:\n            try:\n                t_clone = fresh(t, {})\n                b_clone = fresh(b, {})\n                unify(t_clone, b_clone)\n                types.append(t)\n            except InferenceError:\n                pass\n        if types:\n            if len(types) == 1:\n                unify(clone(types[0]), b)\n            else:\n                # too many overloads are found,\n                # so extract as many information as we can,\n                # and leave the remaining over-approximated\n                def try_unify(t, ts):\n                    if isinstance(t, TypeVariable):\n                        return\n                    if any(isinstance(tp, TypeVariable) for tp in ts):\n                        return\n                    if any(len(tp.types) != len(t.types) for tp in ts):\n                        return\n                    for i, tt in enumerate(t.types):\n                        its = [prune(tp.types[i]) for tp in ts]\n                        if any(isinstance(it, TypeVariable) for it in its):\n                            continue\n                        it0 = its[0]\n                        it0ntypes = len(it0.types)\n                        if all(((it.name == it0.name) and\n                                (len(it.types) == it0ntypes))\n                               for it in its):\n                            ntypes = [TypeVariable() for _ in range(it0ntypes)]\n                            new_tt = TypeOperator(it0.name, ntypes)\n                            new_tt.__class__ = it0.__class__\n                            unify(tt, new_tt)\n                            try_unify(prune(tt), [prune(it) for it in its])\n                try_unify(b, types)\n        else:\n            raise InferenceError(\"No overload\")\n    else:\n        raise RuntimeError(\"Not unified {} and {}\".format(type(a), type(b)))", "response": "Unifies the two types t1 and t2 and returns the equivalent version of the types t1 and t2."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prune(t):\n    if isinstance(t, TypeVariable):\n        if t.instance is not None:\n            t.instance = prune(t.instance)\n            return t.instance\n    return t", "response": "Returns the currently defining instance of t."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef occurs_in_type(v, type2):\n    pruned_type2 = prune(type2)\n    if pruned_type2 == v:\n        return True\n    elif isinstance(pruned_type2, TypeOperator):\n        return occurs_in(v, pruned_type2.types)\n    return False", "response": "Checks whether a type variable occurs in a type expression."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nvisits the whole module and add all import at the top level.", "response": "def visit_Module(self, node):\n        \"\"\"\n        Visit the whole module and add all import at the top level.\n\n        >> import numpy.linalg\n\n        Becomes\n\n        >> import numpy\n\n        \"\"\"\n        node.body = [k for k in (self.visit(n) for n in node.body) if k]\n        imports = [ast.Import([ast.alias(i, mangle(i))]) for i in self.imports]\n        node.body = imports + node.body\n        ast.fix_missing_locations(node)\n        return node"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nregisters imported modules and usage symbols.", "response": "def visit_Import(self, node):\n        \"\"\" Register imported modules and usage symbols.  \"\"\"\n        for alias in node.names:\n            alias_name = tuple(alias.name.split('.'))\n            self.imports.add(alias_name[0])\n            if alias.asname:\n                self.symbols[alias.asname] = alias_name\n            else:\n                self.symbols[alias_name[0]] = alias_name[:1]\n            self.update = True\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nregisters imported modules and usage symbols.", "response": "def visit_ImportFrom(self, node):\n        \"\"\" Register imported modules and usage symbols.  \"\"\"\n        module_path = tuple(node.module.split('.'))\n        self.imports.add(module_path[0])\n        for alias in node.names:\n            path = module_path + (alias.name,)\n            self.symbols[alias.asname or alias.name] = path\n        self.update = True\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate import context using overwriting name information.", "response": "def visit_FunctionDef(self, node):\n        \"\"\"\n        Update import context using overwriting name information.\n\n        Examples\n        --------\n        >> import foo\n        >> import bar\n        >> def foo(bar):\n        >>     print(bar)\n\n        In this case, neither bar nor foo can be used in the foo function and\n        in future function, foo will not be usable.\n        \"\"\"\n        self.symbols.pop(node.name, None)\n        gsymbols = self.symbols.copy()\n        [self.symbols.pop(arg.id, None) for arg in node.args.args]\n        self.generic_visit(node)\n        self.symbols = gsymbols\n        return node"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef visit_Assign(self, node):\n        if isinstance(node.value, ast.Name) and node.value.id in self.symbols:\n            symbol = path_to_node(self.symbols[node.value.id])\n            if not getattr(symbol, 'isliteral', lambda: False)():\n                for target in node.targets:\n                    if not isinstance(target, ast.Name):\n                        err = \"Unsupported module aliasing\"\n                        raise PythranSyntaxError(err, target)\n                    self.symbols[target.id] = self.symbols[node.value.id]\n                return None  # this assignment is no longer needed\n        new_node = self.generic_visit(node)\n        # no problem if targets contains a subscript, it is not a new assign.\n        [self.symbols.pop(t.id, None)\n         for t in new_node.targets if isinstance(t, ast.Name)]\n        return new_node", "response": "Update import context using overwriting name information."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef visit_Name(self, node):\n        if node.id in self.symbols:\n            symbol = path_to_node(self.symbols[node.id])\n            if not getattr(symbol, 'isliteral', lambda: False)():\n                parent = self.ancestors[node][-1]\n                blacklist = (ast.Tuple,\n                             ast.List,\n                             ast.Set,\n                             ast.Return)\n                if isinstance(parent, blacklist):\n                    raise PythranSyntaxError(\n                        \"Unsupported module identifier manipulation\",\n                        node)\n            new_node = path_to_attr(self.symbols[node.id])\n            new_node.ctx = node.ctx\n            ast.copy_location(new_node, node)\n            return new_node\n        return node", "response": "Replace name with full expanded name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef prepare(self, node):\n        super(ArgumentEffects, self).prepare(node)\n        for n in self.global_declarations.values():\n            fe = FunctionEffects(n)\n            self.node_to_functioneffect[n] = fe\n            self.result.add_node(fe)", "response": "Prepare the node for argument effects."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef process_locals(self, node, node_visited, *skipped):\n        local_vars = self.scope[node].difference(skipped)\n        local_vars = local_vars.difference(self.openmp_deps)\n        if not local_vars:\n            return node_visited  # no processing\n\n        locals_visited = []\n        for varname in local_vars:\n            vartype = self.typeof(varname)\n            decl = Statement(\"{} {}\".format(vartype, varname))\n            locals_visited.append(decl)\n        self.ldecls.difference_update(local_vars)\n        return Block(locals_visited + [node_visited])", "response": "Declare variable local to node and insert declaration before.\n\n        Not possible for function yielding values."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds OpenMP pragma on the correct stmt in the correct order. stmt may be a list. On this case, index have to be specify to add OpenMP on the correct statement.", "response": "def process_omp_attachements(self, node, stmt, index=None):\n        \"\"\"\n        Add OpenMP pragma on the correct stmt in the correct order.\n\n        stmt may be a list. On this case, index have to be specify to add\n        OpenMP on the correct statement.\n        \"\"\"\n        omp_directives = metadata.get(node, OMPDirective)\n        if omp_directives:\n            directives = list()\n            for directive in omp_directives:\n                directive.deps = [self.visit(dep) for dep in directive.deps]\n                directives.append(directive)\n            if index is None:\n                stmt = AnnotatedStatement(stmt, directives)\n            else:\n                stmt[index] = AnnotatedStatement(stmt[index], directives)\n        return stmt"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating Assign node for final Cxx representation.", "response": "def visit_Assign(self, node):\n        \"\"\"\n        Create Assign node for final Cxx representation.\n\n        It tries to handle multi assignment like:\n\n        >> a = b = c = 2\n\n        If only one local variable is assigned, typing is added:\n\n        >> int a = 2;\n\n        TODO: Handle case of multi-assignement for some local variables.\n\n        Finally, process OpenMP clause like #pragma omp atomic\n        \"\"\"\n        if not all(isinstance(n, (ast.Name, ast.Subscript))\n                   for n in node.targets):\n            raise PythranSyntaxError(\n                \"Must assign to an identifier or a subscript\",\n                node)\n        value = self.visit(node.value)\n        targets = [self.visit(t) for t in node.targets]\n        alltargets = \"= \".join(targets)\n        islocal = (len(targets) == 1 and\n                   isinstance(node.targets[0], ast.Name) and\n                   node.targets[0].id in self.scope[node] and\n                   node.targets[0].id not in self.openmp_deps)\n        if islocal:\n            # remove this decls from local decls\n            self.ldecls.difference_update(t.id for t in node.targets)\n            # add a local declaration\n            if self.types[node.targets[0]].iscombined():\n                alltargets = '{} {}'.format(self.typeof(node.targets[0]),\n                                            alltargets)\n            elif isinstance(self.types[node.targets[0]],\n                            self.types.builder.Assignable):\n                alltargets = '{} {}'.format(\n                    self.types.builder.Assignable(\n                        self.types.builder.NamedType(\n                            'decltype({})'.format(value))),\n                    alltargets)\n            else:\n                assert isinstance(self.types[node.targets[0]],\n                                  self.types.builder.Lazy)\n                alltargets = '{} {}'.format(\n                    self.types.builder.Lazy(\n                        self.types.builder.NamedType(\n                            'decltype({})'.format(value))),\n                    alltargets)\n        stmt = Assign(alltargets, value)\n        return self.process_omp_attachements(node, stmt)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef gen_for(self, node, target, local_iter, local_iter_decl, loop_body):\n        # Choose target variable for iterator (which is iterator type)\n        local_target = \"__target{0}\".format(id(node))\n        local_target_decl = self.types.builder.IteratorOfType(local_iter_decl)\n\n        # If variable is local to the for body it's a ref to the iterator value\n        # type\n        if node.target.id in self.scope[node] and not hasattr(self, 'yields'):\n            local_type = \"auto&&\"\n        else:\n            local_type = \"\"\n\n        # Assign iterable value\n        loop_body_prelude = Statement(\"{} {}= *{}\".format(local_type,\n                                                          target,\n                                                          local_target))\n\n        # Create the loop\n        assign = self.make_assign(local_target_decl, local_target, local_iter)\n        loop = For(\"{}.begin()\".format(assign),\n                   \"{0} < {1}.end()\".format(local_target, local_iter),\n                   \"++{0}\".format(local_target),\n                   Block([loop_body_prelude, loop_body]))\n        return [self.process_omp_attachements(node, loop)]", "response": "Generate for loop body for given target variable and iterator type."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nhandle comparison for real loops.", "response": "def handle_real_loop_comparison(self, args, target, upper_bound):\n        \"\"\"\n        Handle comparison for real loops.\n\n        Add the correct comparison operator if possible.\n        \"\"\"\n        # order is 1 for increasing loop, -1 for decreasing loop and 0 if it is\n        # not known at compile time\n        if len(args) <= 2:\n            order = 1\n        elif isinstance(args[2], ast.Num):\n            order = -1 + 2 * (int(args[2].n) > 0)\n        elif isinstance(args[1], ast.Num) and isinstance(args[0], ast.Num):\n            order = -1 + 2 * (int(args[1].n) > int(args[0].n))\n        else:\n            order = 0\n\n        comparison = \"{} < {}\" if order == 1 else \"{} > {}\"\n        comparison = comparison.format(target, upper_bound)\n        return comparison"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate a C for representation for the given node.", "response": "def gen_c_for(self, node, local_iter, loop_body):\n        \"\"\"\n        Create C For representation for Cxx generation.\n\n        Examples\n        --------\n        >> for i in xrange(10):\n        >>     ... do things ...\n\n        Becomes\n\n        >> for(long i = 0, __targetX = 10; i < __targetX; i += 1)\n        >>     ... do things ...\n\n        Or\n\n        >> for i in xrange(10, 0, -1):\n        >>     ... do things ...\n\n        Becomes\n\n        >> for(long i = 10, __targetX = 0; i > __targetX; i += -1)\n        >>     ... do things ...\n\n\n        It the case of not local variable, typing for `i` disappear\n        \"\"\"\n        args = node.iter.args\n        step = \"1L\" if len(args) <= 2 else self.visit(args[2])\n        if len(args) == 1:\n            lower_bound = \"0L\"\n            upper_arg = 0\n        else:\n            lower_bound = self.visit(args[0])\n            upper_arg = 1\n\n\n        upper_type = iter_type = \"long \"\n        upper_value = self.visit(args[upper_arg])\n        if is_simple_expr(args[upper_arg]):\n            upper_bound = upper_value  # compatible with collapse\n        else:\n            upper_bound = \"__target{0}\".format(id(node))\n\n        # If variable is local to the for body keep it local...\n        if node.target.id in self.scope[node] and not hasattr(self, 'yields'):\n            loop = list()\n        else:\n            # For yield function, upper_bound is globals.\n            iter_type = \"\"\n            # Back one step to keep Python behavior (except for break)\n            loop = [If(\"{} == {}\".format(local_iter, upper_bound),\n                    Statement(\"{} -= {}\".format(local_iter, step)))]\n\n        comparison = self.handle_real_loop_comparison(args, local_iter,\n                                                      upper_bound)\n\n        forloop = For(\"{0} {1}={2}\".format(iter_type, local_iter, lower_bound),\n                      comparison,\n                      \"{0} += {1}\".format(local_iter, step),\n                      loop_body)\n\n        loop.insert(0, self.process_omp_attachements(node, forloop))\n\n        # Store upper bound value if needed\n        if upper_bound is upper_value:\n            header = []\n        else:\n            assgnt = self.make_assign(upper_type, upper_bound, upper_value)\n            header = [Statement(assgnt)]\n        return header, loop"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef handle_omp_for(self, node, local_iter):\n        for directive in metadata.get(node, OMPDirective):\n            if any(key in directive.s for key in (' parallel ', ' task ')):\n                # Eventually add local_iter in a shared clause as iterable is\n                # shared in the for loop (for every clause with datasharing)\n                directive.s += ' shared({})'\n                directive.deps.append(ast.Name(local_iter, ast.Load(), None))\n                directive.shared_deps.append(directive.deps[-1])\n\n            target = node.target\n            assert isinstance(target, ast.Name)\n            hasfor = 'for' in directive.s\n            nodefault = 'default' not in directive.s\n            noindexref = all(isinstance(x, ast.Name) and\n                             x.id != target.id for x in directive.deps)\n            if (hasfor and nodefault and noindexref and\n                    target.id not in self.scope[node]):\n                # Target is private by default in omp but iterator use may\n                # introduce an extra variable\n                directive.s += ' private({})'\n                directive.deps.append(ast.Name(target.id, ast.Load(), None))\n                directive.private_deps.append(directive.deps[-1])", "response": "Handle OpenMP directives on For loops."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef can_use_autofor(self, node):\n        auto_for = (isinstance(node.target, ast.Name) and\n                    node.target.id in self.scope[node] and\n                    node.target.id not in self.openmp_deps)\n        auto_for &= not metadata.get(node, OMPDirective)\n        auto_for &= node.target.id not in self.openmp_deps\n        return auto_for", "response": "Check if given for Node can use autoFor syntax."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if a for loop can use classic C syntax.", "response": "def can_use_c_for(self, node):\n        \"\"\"\n        Check if a for loop can use classic C syntax.\n\n        To use C syntax:\n            - target should not be assign in the loop\n            - xrange should be use as iterator\n            - order have to be known at compile time\n        \"\"\"\n        assert isinstance(node.target, ast.Name)\n        if sys.version_info.major == 3:\n            range_name = 'range'\n        else:\n            range_name = 'xrange'\n        pattern_range = ast.Call(func=ast.Attribute(\n            value=ast.Name(id='__builtin__',\n                           ctx=ast.Load(),\n                           annotation=None),\n            attr=range_name, ctx=ast.Load()),\n            args=AST_any(), keywords=[])\n        is_assigned = {node.target.id: False}\n        [is_assigned.update(self.gather(IsAssigned, stmt))\n         for stmt in node.body]\n\n        nodes = ASTMatcher(pattern_range).search(node.iter)\n        if (node.iter not in nodes or is_assigned[node.target.id]):\n            return False\n\n        args = node.iter.args\n        if len(args) < 3:\n            return True\n        if isinstance(args[2], ast.Num):\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef visit_For(self, node):\n        if not isinstance(node.target, ast.Name):\n            raise PythranSyntaxError(\n                \"Using something other than an identifier as loop target\",\n                node.target)\n        target = self.visit(node.target)\n\n        # Handle the body of the for loop\n        loop_body = Block([self.visit(stmt) for stmt in node.body])\n\n        # Declare local variables at the top of the loop body\n        loop_body = self.process_locals(node, loop_body, node.target.id)\n        iterable = self.visit(node.iter)\n\n        if self.can_use_c_for(node):\n            header, loop = self.gen_c_for(node, target, loop_body)\n        else:\n\n            if self.can_use_autofor(node):\n                header = []\n                self.ldecls.remove(node.target.id)\n                autofor = AutoFor(target, iterable, loop_body)\n                loop = [self.process_omp_attachements(node, autofor)]\n            else:\n                # Iterator declaration\n                local_iter = \"__iter{0}\".format(id(node))\n                local_iter_decl = self.types.builder.Assignable(\n                    self.types[node.iter])\n\n                self.handle_omp_for(node, local_iter)\n\n                # Assign iterable\n                # For C loop, it avoids issues\n                # if the upper bound is assigned in the loop\n                asgnt = self.make_assign(local_iter_decl, local_iter, iterable)\n                header = [Statement(asgnt)]\n                loop = self.gen_for(node, target, local_iter, local_iter_decl,\n                                    loop_body)\n\n        # For xxxComprehension, it is replaced by a for loop. In this case,\n        # pre-allocate size of container.\n        for comp in metadata.get(node, metadata.Comprehension):\n            header.append(Statement(\"pythonic::utils::reserve({0},{1})\".format(\n                comp.target,\n                iterable)))\n\n        return Block(header + loop)", "response": "Handles For loops and returns a new for representation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate While node for Cxx generation.", "response": "def visit_While(self, node):\n        \"\"\"\n        Create While node for Cxx generation.\n\n        It is a cxx_loop to handle else clause.\n        \"\"\"\n        test = self.visit(node.test)\n        body = [self.visit(n) for n in node.body]\n        stmt = While(test, Block(body))\n        return self.process_omp_attachements(node, stmt)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef visit_Break(self, _):\n        if self.break_handlers and self.break_handlers[-1]:\n            return Statement(\"goto {0}\".format(self.break_handlers[-1]))\n        else:\n            return Statement(\"break\")", "response": "Generate break statement in most case and goto for orelse clause."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef visit_Module(self, node):\n        # build all types\n        deps = sorted(self.dependencies)\n        headers = [Include(os.path.join(\"pythonic\", \"include\",  *t) + \".hpp\")\n                   for t in deps]\n        headers += [Include(os.path.join(\"pythonic\", *t) + \".hpp\")\n                    for t in deps]\n\n        decls_n_defns = [self.visit(stmt) for stmt in node.body]\n        decls, defns = zip(*[s for s in decls_n_defns if s])\n\n        nsbody = [s for ls in decls + defns for s in ls]\n        ns = Namespace(pythran_ward + self.passmanager.module_name, nsbody)\n        self.result = CompilationUnit(headers + [ns])", "response": "Build a compilation unit for the module."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef refine(pm, node, optimizations):\n    # Sanitize input\n    pm.apply(ExpandGlobals, node)\n    pm.apply(ExpandImportAll, node)\n    pm.apply(NormalizeTuples, node)\n    pm.apply(ExpandBuiltins, node)\n    pm.apply(ExpandImports, node)\n    pm.apply(NormalizeMethodCalls, node)\n    pm.apply(NormalizeIsNone, node)\n    pm.apply(SplitStaticExpression, node)\n    pm.apply(NormalizeStaticIf, node)\n    pm.apply(NormalizeTuples, node)\n    pm.apply(NormalizeException, node)\n    pm.apply(NormalizeMethodCalls, node)\n\n    # Some early optimizations\n    pm.apply(ComprehensionPatterns, node)\n\n    pm.apply(RemoveLambdas, node)\n    pm.apply(RemoveNestedFunctions, node)\n    pm.apply(NormalizeCompare, node)\n\n    pm.gather(ExtendedSyntaxCheck, node)\n\n    pm.apply(ListCompToGenexp, node)\n    pm.apply(RemoveComprehension, node)\n    pm.apply(RemoveNamedArguments, node)\n\n    # sanitize input\n    pm.apply(NormalizeReturn, node)\n    pm.apply(UnshadowParameters, node)\n    pm.apply(FalsePolymorphism, node)\n\n    # some extra optimizations\n    apply_optimisation = True\n    while apply_optimisation:\n        apply_optimisation = False\n        for optimization in optimizations:\n            apply_optimisation |= pm.apply(optimization, node)[0]", "response": "Refine a node in place until it matches pythran s expectations."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef prepare(self, node):\n        super(GlobalEffects, self).prepare(node)\n\n        def register_node(module):\n            \"\"\" Recursively save globals effect for all functions. \"\"\"\n            for v in module.values():\n                if isinstance(v, dict):  # Submodule case\n                    register_node(v)\n                else:\n                    fe = GlobalEffects.FunctionEffect(v)\n                    self.node_to_functioneffect[v] = fe\n                    self.result.add_node(fe)\n                    if isinstance(v, intrinsic.Class):\n                        register_node(v.fields)\n\n        register_node(self.global_declarations)\n        for module in MODULES.values():\n            register_node(module)\n        self.node_to_functioneffect[intrinsic.UnboundValue] = \\\n            GlobalEffects.FunctionEffect(intrinsic.UnboundValue)", "response": "Prepare for Pythonic functions and default values set for Pythonic functions and default values set for Pythonic functions and default values set for Pythonic functions."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprepare the types for the given node.", "response": "def prepare(self, node):\n        \"\"\"\n        Initialise values to prepare typing computation.\n\n        Reorder functions to avoid dependencies issues and prepare typing\n        computation setting typing values for Pythonic functions.\n        \"\"\"\n\n        def register(name, module):\n            \"\"\" Recursively save function typing and combiners for Pythonic.\"\"\"\n            for fname, function in module.items():\n                if isinstance(function, dict):\n                    register(name + \"::\" + fname, function)\n                else:\n                    tname = 'pythonic::{0}::functor::{1}'.format(name, fname)\n                    self.result[function] = self.builder.NamedType(tname)\n                    self.combiners[function] = function\n                    if isinstance(function, Class):\n                        register(name + \"::\" + fname, function.fields)\n\n        for mname, module in MODULES.items():\n            register(mname, module)\n        super(Types, self).prepare(node)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nregisters ptype as a local typedef", "response": "def register(self, ptype):\n        \"\"\"register ptype as a local typedef\"\"\"\n        # Too many of them leads to memory burst\n        if len(self.typedefs) < cfg.getint('typing', 'max_combiner'):\n            self.typedefs.append(ptype)\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks whether node aliases to a parameter.", "response": "def isargument(self, node):\n        \"\"\" checks whether node aliases to a parameter.\"\"\"\n        try:\n            node_id, _ = self.node_to_id(node)\n            return (node_id in self.name_to_nodes and\n                    any([isinstance(n, ast.Name) and\n                         isinstance(n.ctx, ast.Param)\n                         for n in self.name_to_nodes[node_id]]))\n        except UnboundableRValue:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncombines two node and othernode.", "response": "def combine(self, node, othernode, op=None, unary_op=None, register=False,\n                aliasing_type=False):\n        \"\"\"\n        Change `node` typing with combination of `node` and `othernode`.\n\n        Parameters\n        ----------\n        aliasing_type : bool\n            All node aliasing to `node` have to be updated too.\n        \"\"\"\n        if self.result[othernode] is self.builder.UnknownType:\n            if node not in self.result:\n                self.result[node] = self.builder.UnknownType\n            return\n\n        if aliasing_type:\n            self.combine_(node, othernode, op or operator.add,\n                          unary_op or (lambda x: x), register)\n            for a in self.strict_aliases[node]:\n                self.combine_(a, othernode, op or operator.add,\n                              unary_op or (lambda x: x), register)\n        else:\n            self.combine_(node, othernode, op or operator.add,\n                          unary_op or (lambda x: x), register)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef visit_Return(self, node):\n        self.generic_visit(node)\n        # No merge are done if the function is a generator.\n        if not self.yield_points:\n            assert node.value, \"Values were added in each return statement.\"\n            self.combine(self.current, node.value)", "response": "Compute return type and merges with others possible return type."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes yield type and merges it with others yield type.", "response": "def visit_Yield(self, node):\n        \"\"\" Compute yield type and merges it with others yield type. \"\"\"\n        self.generic_visit(node)\n        self.combine(self.current, node.value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef visit_BoolOp(self, node):\n        # Visit subnodes\n        self.generic_visit(node)\n        # Merge all operands types.\n        [self.combine(node, value) for value in node.values]", "response": "Merge all operands types."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset type for number.", "response": "def visit_Num(self, node):\n        \"\"\"\n        Set type for number.\n\n        It could be int, long or float so we use the default python to pythonic\n        type converter.\n        \"\"\"\n        ty = type(node.n)\n        sty = pytype_to_ctype(ty)\n        if node in self.immediates:\n            sty = \"std::integral_constant<%s, %s>\" % (sty, node.n)\n\n        self.result[node] = self.builder.NamedType(sty)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef visit_Str(self, node):\n        self.result[node] = self.builder.NamedType(pytype_to_ctype(str))", "response": "Set the pythonic string type."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef visit_Attribute(self, node):\n        obj, path = attr_to_path(node)\n        # If no type is given, use a decltype\n        if obj.isliteral():\n            typename = pytype_to_ctype(obj.signature)\n            self.result[node] = self.builder.NamedType(typename)\n        else:\n            self.result[node] = self.builder.DeclType('::'.join(path) + '{}')", "response": "Compute typing for an attribute node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef visit_Slice(self, node):\n        self.generic_visit(node)\n        if node.step is None or (isinstance(node.step, ast.Num) and\n                                 node.step.n == 1):\n            self.result[node] = self.builder.NamedType(\n                'pythonic::types::contiguous_slice')\n        else:\n            self.result[node] = self.builder.NamedType(\n                'pythonic::types::slice')", "response": "Set slicing type using continuous information if provided."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndefine list type from all elements type.", "response": "def visit_List(self, node):\n        \"\"\" Define list type from all elements type (or empty_list type). \"\"\"\n        self.generic_visit(node)\n        if node.elts:\n            for elt in node.elts:\n                self.combine(node, elt, unary_op=self.builder.ListType)\n        else:\n            self.result[node] = self.builder.NamedType(\n                \"pythonic::types::empty_list\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef visit_Set(self, node):\n        self.generic_visit(node)\n        if node.elts:\n            for elt in node.elts:\n                self.combine(node, elt, unary_op=self.builder.SetType)\n        else:\n            self.result[node] = self.builder.NamedType(\n                \"pythonic::types::empty_set\")", "response": "Define set type from all elements type."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef visit_Dict(self, node):\n        self.generic_visit(node)\n        if node.keys:\n            for key, value in zip(node.keys, node.values):\n                value_type = self.result[value]\n                self.combine(node, key,\n                             unary_op=partial(self.builder.DictType,\n                                              of_val=value_type))\n        else:\n            self.result[node] = self.builder.NamedType(\n                \"pythonic::types::empty_dict\")", "response": "Define set type from all elements type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef init_not_msvc(self):\n        # find_library() does not search automatically LD_LIBRARY_PATH\n        paths = os.environ.get('LD_LIBRARY_PATH', '').split(':')\n        for gomp in ('libgomp.so', 'libgomp.dylib'):\n            if cxx is None:\n                continue\n            cmd = [cxx, '-print-file-name=' + gomp]\n            # the subprocess can fail in various ways\n            # in that case just give up that path\n            try:\n                path = os.path.dirname(check_output(cmd).strip())\n                if path:\n                    paths.append(path)\n            except OSError:\n                pass\n\n        # Try to load find libgomp shared library using loader search dirs\n        libgomp_path = find_library(\"gomp\")\n\n        # Try to use custom paths if lookup failed\n        for path in paths:\n            if libgomp_path:\n                break\n            path = path.strip()\n            if os.path.isdir(path):\n                libgomp_path = find_library(os.path.join(str(path), \"libgomp\"))\n\n        if not libgomp_path:\n            raise ImportError(\"I can't find a shared library for libgomp,\"\n                              \" you may need to install it or adjust the \"\n                              \"LD_LIBRARY_PATH environment variable.\")\n        else:\n            # Load the library (shouldn't fail with an absolute path right?)\n            self.libomp = ctypes.CDLL(libgomp_path)\n            self.version = 45", "response": "Try to load the library and check if it is using ctype interface."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetermine this function definition can be inlined.", "response": "def visit_FunctionDef(self, node):\n        \"\"\" Determine this function definition can be inlined. \"\"\"\n        if (len(node.body) == 1 and\n                isinstance(node.body[0], (ast.Call, ast.Return))):\n            ids = self.gather(Identifiers, node.body[0])\n            # FIXME : It mark \"not inlinable\" def foo(foo): return foo\n            if node.name not in ids:\n                self.result[node.name] = copy.deepcopy(node)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prepare(self, node):\n        super(TypeDependencies, self).prepare(node)\n        for v in self.global_declarations.values():\n            self.result.add_node(v)\n        self.result.add_node(TypeDependencies.NoDeps)", "response": "Add nodes for each global declaration in the result graph."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef visit_any_conditionnal(self, node1, node2):\n\n        true_naming = false_naming = None\n\n        try:\n            tmp = self.naming.copy()\n            for expr in node1:\n                self.visit(expr)\n            true_naming = self.naming\n            self.naming = tmp\n        except KeyError:\n            pass\n\n        try:\n            tmp = self.naming.copy()\n            for expr in node2:\n                self.visit(expr)\n            false_naming = self.naming\n            self.naming = tmp\n        except KeyError:\n            pass\n\n        if true_naming and not false_naming:\n            self.naming = true_naming\n\n        elif false_naming and not true_naming:\n            self.naming = false_naming\n\n        elif true_naming and false_naming:\n            self.naming = false_naming\n            for k, v in true_naming.items():\n                if k not in self.naming:\n                    self.naming[k] = v\n                else:\n                    for dep in v:\n                        if dep not in self.naming[k]:\n                            self.naming[k].append(dep)", "response": "Visit any conditionnal nodes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvisit a function definition node.", "response": "def visit_FunctionDef(self, node):\n        \"\"\"\n        Initialize variable for the current function to add edges from calls.\n\n        We compute variable to call dependencies and add edges when returns\n        are reach.\n        \"\"\"\n        # Ensure there are no nested functions.\n        assert self.current_function is None\n        self.current_function = node\n        self.naming = dict()\n        self.in_cond = False  # True when we are in a if, while or for\n        self.generic_visit(node)\n        self.current_function = None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef visit_Return(self, node):\n        if not node.value:\n            # Yielding function can't return values\n            return\n        for dep_set in self.visit(node.value):\n            if dep_set:\n                for dep in dep_set:\n                    self.result.add_edge(dep, self.current_function)\n            else:\n                self.result.add_edge(TypeDependencies.NoDeps,\n                                     self.current_function)", "response": "Visit a Return node and add edges from all possible callee to current function."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef visit_Assign(self, node):\n        value_deps = self.visit(node.value)\n        for target in node.targets:\n            name = get_variable(target)\n            if isinstance(name, ast.Name):\n                self.naming[name.id] = value_deps", "response": "Visit the Assign node and add type dependencies."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nhandles iterator variable in for loops. Iterate variable may be the correct one at the end of the loop.", "response": "def visit_For(self, node):\n        \"\"\"\n        Handle iterator variable in for loops.\n\n        Iterate variable may be the correct one at the end of the loop.\n        \"\"\"\n        body = node.body\n        if node.target.id in self.naming:\n            body = [ast.Assign(targets=[node.target], value=node.iter)] + body\n            self.visit_any_conditionnal(body, node.orelse)\n        else:\n            iter_dep = self.visit(node.iter)\n            self.naming[node.target.id] = iter_dep\n            self.visit_any_conditionnal(body, body + node.orelse)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef visit_BoolOp(self, node):\n        return sum((self.visit(value) for value in node.values), [])", "response": "Return type may come from any boolop operand."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef visit_BinOp(self, node):\n        args = [self.visit(arg) for arg in (node.left, node.right)]\n        return list({frozenset.union(*x) for x in itertools.product(*args)})", "response": "Return type depend from both operands of the binary operation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef visit_Call(self, node):\n        args = [self.visit(arg) for arg in node.args]\n        func = self.visit(node.func)\n        params = args + [func or []]\n        return list({frozenset.union(*p) for p in itertools.product(*params)})", "response": "Return a list of all function call depend on all function use in the call."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns dependencies for given variable.", "response": "def visit_Name(self, node):\n        \"\"\"\n        Return dependencies for given variable.\n\n        It have to be register first.\n        \"\"\"\n        if node.id in self.naming:\n            return self.naming[node.id]\n        elif node.id in self.global_declarations:\n            return [frozenset([self.global_declarations[node.id]])]\n        elif isinstance(node.ctx, ast.Param):\n            deps = [frozenset()]\n            self.naming[node.id] = deps\n            return deps\n        else:\n            raise PythranInternalError(\"Variable '{}' use before assignment\"\n                                       \"\".format(node.id))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of all elements that depend on each element type dependency.", "response": "def visit_List(self, node):\n        \"\"\" List construction depend on each elements type dependency. \"\"\"\n        if node.elts:\n            return list(set(sum([self.visit(elt) for elt in node.elts], [])))\n        else:\n            return [frozenset()]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef visit_ExceptHandler(self, node):\n        if node.name:\n            self.naming[node.name.id] = [frozenset()]\n        for stmt in node.body:\n            self.visit(stmt)", "response": "A handler is an exception variable."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef arc_distance(theta_1, phi_1,\n                       theta_2, phi_2):\n    \"\"\"\n    Calculates the pairwise arc distance between all points in vector a and b.\n    \"\"\"\n    temp = np.sin((theta_2-theta_1)/2)**2+np.cos(theta_1)*np.cos(theta_2)*np.sin((phi_2-phi_1)/2)**2\n    distance_matrix = 2 * (np.arctan2(np.sqrt(temp),np.sqrt(1-temp)))\n    return distance_matrix", "response": "Calculates the pairwise arc distance between two points in vector a and b."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef visit_Module(self, node):\n        module_body = list()\n        symbols = set()\n        # Gather top level assigned variables.\n        for stmt in node.body:\n            if isinstance(stmt, (ast.Import, ast.ImportFrom)):\n                for alias in stmt.names:\n                    name = alias.asname or alias.name\n                    symbols.add(name)  # no warning here\n            elif isinstance(stmt, ast.FunctionDef):\n                if stmt.name in symbols:\n                    raise PythranSyntaxError(\n                        \"Multiple top-level definition of %s.\" % stmt.name,\n                        stmt)\n                else:\n                    symbols.add(stmt.name)\n\n            if not isinstance(stmt, ast.Assign):\n                continue\n\n            for target in stmt.targets:\n                if not isinstance(target, ast.Name):\n                    raise PythranSyntaxError(\n                        \"Top-level assignment to an expression.\",\n                        target)\n                if target.id in self.to_expand:\n                    raise PythranSyntaxError(\n                        \"Multiple top-level definition of %s.\" % target.id,\n                        target)\n                if isinstance(stmt.value, ast.Name):\n                    if stmt.value.id in symbols:\n                        continue  # create aliasing between top level symbols\n                self.to_expand.add(target.id)\n\n        for stmt in node.body:\n            if isinstance(stmt, ast.Assign):\n                # that's not a global var, but a module/function aliasing\n                if all(isinstance(t, ast.Name) and t.id not in self.to_expand\n                       for t in stmt.targets):\n                    module_body.append(stmt)\n                    continue\n\n                self.local_decl = set()\n                cst_value = self.visit(stmt.value)\n                for target in stmt.targets:\n                    assert isinstance(target, ast.Name)\n                    module_body.append(\n                        ast.FunctionDef(target.id,\n                                        ast.arguments([], None,\n                                                      [], [], None, []),\n                                        [ast.Return(value=cst_value)],\n                                        [], None))\n                    metadata.add(module_body[-1].body[0],\n                                 metadata.StaticReturn())\n            else:\n                self.local_decl = self.gather(\n                    LocalNameDeclarations, stmt)\n                module_body.append(self.visit(stmt))\n\n        self.update |= bool(self.to_expand)\n\n        node.body = module_body\n        return node", "response": "Turn globals assignment to functionDef and visit function defs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if the node is a name from an assignment or a function call.", "response": "def visit_Name(self, node):\n        \"\"\"\n        Turn global variable used not shadows to function call.\n\n        We check it is a name from an assignment as import or functions use\n        should not be turn into call.\n        \"\"\"\n        if (isinstance(node.ctx, ast.Load) and\n                node.id not in self.local_decl and\n                node.id in self.to_expand):\n            self.update = True\n            return ast.Call(func=node,\n                            args=[], keywords=[])\n        return node"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef visit_Module(self, node):\n        self.skip_functions = True\n        self.generic_visit(node)\n        self.skip_functions = False\n        self.generic_visit(node)\n        new_imports = self.to_import - self.globals\n        imports = [ast.Import(names=[ast.alias(name=mod[17:], asname=mod)])\n                   for mod in new_imports]\n        node.body = imports + node.body\n        self.update |= bool(imports)\n        return node", "response": "Add correct import for module."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef renamer(v, cur_module):\n        mname = demangle(v)\n\n        name = v + '_'\n        if name in cur_module:\n            return name, mname\n        else:\n            return v, mname", "response": "Rename function path to fit Pythonic naming."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef visit_Call(self, node):\n        node = self.generic_visit(node)\n        # Only attributes function can be Pythonic and should be normalized\n        if isinstance(node.func, ast.Attribute):\n            if node.func.attr in methods:\n                # Get object targeted by methods\n                obj = lhs = node.func.value\n                # Get the most left identifier to check if it is not an\n                # imported module\n                while isinstance(obj, ast.Attribute):\n                    obj = obj.value\n                is_not_module = (not isinstance(obj, ast.Name) or\n                                 obj.id not in self.imports)\n\n                if is_not_module:\n                    self.update = True\n                    # As it was a methods call, push targeted object as first\n                    # arguments and add correct module prefix\n                    node.args.insert(0, lhs)\n                    mod = methods[node.func.attr][0]\n                    # Submodules import full module\n                    self.to_import.add(mangle(mod[0]))\n                    node.func = reduce(\n                        lambda v, o: ast.Attribute(v, o, ast.Load()),\n                        mod[1:] + (node.func.attr,),\n                        ast.Name(mangle(mod[0]), ast.Load(), None)\n                        )\n                # else methods have been called using function syntax\n            if node.func.attr in methods or node.func.attr in functions:\n                # Now, methods and function have both function syntax\n                def rec(path, cur_module):\n                    \"\"\"\n                    Recursively rename path content looking in matching module.\n\n                    Prefers __module__ to module if it exists.\n                    This recursion is done as modules are visited top->bottom\n                    while attributes have to be visited bottom->top.\n                    \"\"\"\n                    err = \"Function path is chained attributes and name\"\n                    assert isinstance(path, (ast.Name, ast.Attribute)), err\n                    if isinstance(path, ast.Attribute):\n                        new_node, cur_module = rec(path.value, cur_module)\n                        new_id, mname = self.renamer(path.attr, cur_module)\n                        return (ast.Attribute(new_node, new_id, ast.Load()),\n                                cur_module[mname])\n                    else:\n                        new_id, mname = self.renamer(path.id, cur_module)\n                        if mname not in cur_module:\n                            raise PythranSyntaxError(\n                                \"Unbound identifier '{}'\".format(mname), node)\n\n                        return (ast.Name(new_id, ast.Load(), None),\n                                cur_module[mname])\n\n                # Rename module path to avoid naming issue.\n                node.func.value, _ = rec(node.func.value, MODULES)\n                self.update = True\n\n        return node", "response": "Transform call site to have normal function call."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting paths to config files for a single node.", "response": "def get_paths_cfg(\n    sys_file='pythran.cfg',\n    platform_file='pythran-{}.cfg'.format(sys.platform),\n    user_file='.pythranrc'\n):\n    \"\"\"\n    >>> os.environ['HOME'] = '/tmp/test'\n    >>> get_paths_cfg()['user']\n    '/tmp/test/.pythranrc'\n    >>> os.environ['HOME'] = '/tmp/test'\n    >>> os.environ['XDG_CONFIG_HOME'] = '/tmp/test2'\n    >>> get_paths_cfg()['user']\n    '/tmp/test2/.pythranrc'\n    >>> os.environ['HOME'] = '/tmp/test'\n    >>> os.environ['XDG_CONFIG_HOME'] = '/tmp/test2'\n    >>> os.environ['PYTHRANRC'] = '/tmp/test3/pythranrc'\n    >>> get_paths_cfg()['user']\n    '/tmp/test3/pythranrc'\n    \"\"\"\n    sys_config_dir = os.path.dirname(__file__)\n    sys_config_path = os.path.join(sys_config_dir, sys_file)\n\n    platform_config_path = os.path.join(sys_config_dir, platform_file)\n\n    user_config_path = os.environ.get('PYTHRANRC', None)\n    if not user_config_path:\n        user_config_dir = os.environ.get('XDG_CONFIG_HOME', '~')\n        user_config_path = os.path.expanduser(\n            os.path.join(user_config_dir, user_file))\n    return {\"sys\": sys_config_path, \"platform\": platform_config_path, \"user\": user_config_path}"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compiler():\n    cfg_cxx = str(cfg.get('compiler', 'CXX'))\n    if not cfg_cxx:\n        cfg_cxx = None\n    return os.environ.get('CXX', cfg_cxx) or None", "response": "Get the compiler to use for C ++ binary process."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run():\n    '''\n    Dump on stdout the config flags required to compile pythran-generated code.\n    '''\n    import argparse\n    import distutils.sysconfig\n    import pythran\n    import numpy\n\n    parser = argparse.ArgumentParser(\n        prog='pythran-config',\n        description='output build options for pythran-generated code',\n        epilog=\"It's a megablast!\"\n    )\n\n    parser.add_argument('--compiler', action='store_true',\n                        help='print default compiler')\n\n    parser.add_argument('--cflags', action='store_true',\n                        help='print compilation flags')\n\n    parser.add_argument('--libs', action='store_true',\n                        help='print linker flags')\n\n    parser.add_argument('--no-python', action='store_true',\n                        help='do not include Python-related flags')\n\n    parser.add_argument('--verbose', '-v', action='count', default=0,\n                        help=(\n                            'verbose mode: [-v] prints warnings if pythranrc '\n                            'has an invalid configuration; use '\n                            '[-vv] for more information')\n                        )\n\n    args = parser.parse_args(sys.argv[1:])\n\n    args.python = not args.no_python\n\n    output = []\n\n    extension = pythran.config.make_extension(python=args.python)\n\n    if args.verbose >= 1:\n        if args.verbose == 1:\n            logger.setLevel(logging.WARNING)\n        else:\n            logger.setLevel(logging.INFO)\n\n        lint_cfg(cfg)\n\n    if args.compiler or args.verbose >= 2:\n        cxx = compiler() or 'c++'\n        logger.info('CXX = '.rjust(10) + cxx)\n        if args.compiler:\n            output.append(cxx)\n\n    if args.cflags or args.verbose>=2:\n        def fmt_define(define):\n            name, value = define\n            if value is None:\n                return '-D' + name\n            else:\n                return '-D' + name + '=' + value\n\n        cflags = []\n        cflags.extend(fmt_define(define)\n                      for define in extension['define_macros'])\n        cflags.extend(('-I' + include)\n                      for include in extension['include_dirs'])\n        if args.python:\n            cflags.append('-I' + numpy.get_include())\n            cflags.append('-I' + distutils.sysconfig.get_python_inc())\n\n        logger.info('CFLAGS = '.rjust(10) + ' '.join(cflags))\n        if args.cflags:\n            output.extend(cflags)\n\n    if args.libs or args.verbose>=2:\n        ldflags = []\n        ldflags.extend(('-L' + include)\n                       for include in extension['library_dirs'])\n        ldflags.extend(('-l' + include)\n                       for include in extension['libraries'])\n\n        if args.python:\n            ldflags.append('-L' + distutils.sysconfig.get_config_var('LIBPL'))\n            ldflags.extend(distutils.sysconfig.get_config_var('LIBS').split())\n            ldflags.append('-lpython'\n                           + distutils.sysconfig.get_config_var('VERSION'))\n\n        logger.info('LDFLAGS = '.rjust(10) + ' '.join(ldflags))\n        if args.libs:\n            output.extend(ldflags)\n\n    if output:\n        print(' '.join(output))", "response": "This function is run by command line. It will print out the config flags required to compile pythran - generated code."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nextracts types dependencies from specs for each exported signature.", "response": "def _extract_specs_dependencies(specs):\n    \"\"\" Extract types dependencies from specs for each exported signature. \"\"\"\n    deps = set()\n    # for each function\n    for signatures in specs.functions.values():\n        # for each signature\n        for signature in signatures:\n            # for each argument\n            for t in signature:\n                deps.update(pytype_to_deps(t))\n    # and each capsule\n    for signature in specs.capsules.values():\n        # for each argument\n        for t in signature:\n            deps.update(pytype_to_deps(t))\n    # Keep \"include\" first\n    return sorted(deps, key=lambda x: \"include\" not in x)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nturn an optimization of the form my_optim into the associated symbol", "response": "def _parse_optimization(optimization):\n    '''Turns an optimization of the form\n        my_optim\n        my_package.my_optim\n        into the associated symbol'''\n    splitted = optimization.split('.')\n    if len(splitted) == 1:\n        splitted = ['pythran', 'optimizations'] + splitted\n    return reduce(getattr, splitted[1:], __import__(splitted[0]))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _write_temp(content, suffix):\n    '''write `content` to a temporary XXX`suffix` file and return the filename.\n       It is user's responsibility to delete when done.'''\n    with NamedTemporaryFile(mode='w', suffix=suffix, delete=False) as out:\n        out.write(content)\n        return out.name", "response": "write content to a temporary XXX suffix file and return the filename."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef front_middle_end(module_name, code, optimizations=None, module_dir=None):\n    pm = PassManager(module_name, module_dir)\n\n    # front end\n    ir, renamings, docstrings = frontend.parse(pm, code)\n\n    # middle-end\n    if optimizations is None:\n        optimizations = cfg.get('pythran', 'optimizations').split()\n    optimizations = [_parse_optimization(opt) for opt in optimizations]\n    refine(pm, ir, optimizations)\n\n    return pm, ir, renamings, docstrings", "response": "Front - end and middle - end compilation steps"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate_py(module_name, code, optimizations=None, module_dir=None):\n    '''python + pythran spec -> py code\n\n    Prints and returns the optimized python code.\n\n    '''\n\n    pm, ir, _, _ = front_middle_end(module_name, code, optimizations,\n                                    module_dir)\n\n    return pm.dump(Python, ir)", "response": "Generate a python code from a code block."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate_cxx(module_name, code, specs=None, optimizations=None,\n                 module_dir=None):\n    '''python + pythran spec -> c++ code\n    returns a PythonModule object and an error checker\n\n    the error checker can be used to print more detailed info on the origin of\n    a compile error (e.g. due to bad typing)\n\n    '''\n\n    pm, ir, renamings, docstrings = front_middle_end(module_name, code,\n                                                     optimizations, module_dir)\n\n    # back-end\n    content = pm.dump(Cxx, ir)\n\n    # instantiate the meta program\n    if specs is None:\n\n        class Generable(object):\n            def __init__(self, content):\n                self.content = content\n\n            def __str__(self):\n                return str(self.content)\n\n            generate = __str__\n\n        mod = Generable(content)\n\n        def error_checker():\n            tog.typecheck(ir)\n\n    else:\n\n        # uniform typing\n        if isinstance(specs, dict):\n            specs = Spec(specs, {})\n\n        def error_checker():\n            types = tog.typecheck(ir)\n            check_specs(specs, renamings, types)\n\n        specs.to_docstrings(docstrings)\n        check_exports(ir, specs, renamings)\n\n        if isinstance(code, bytes):\n            code_bytes = code\n        else:\n            code_bytes = code.encode('ascii', 'ignore')\n        metainfo = {'hash': hashlib.sha256(code_bytes).hexdigest(),\n                    'version': __version__,\n                    'date': datetime.now()}\n\n        mod = PythonModule(module_name, docstrings, metainfo)\n        mod.add_to_includes(\n            Include(\"pythonic/core.hpp\"),\n            Include(\"pythonic/python/core.hpp\"),\n            # FIXME: only include these when needed\n            Include(\"pythonic/types/bool.hpp\"),\n            Include(\"pythonic/types/int.hpp\"),\n            Line(\"#ifdef _OPENMP\\n#include <omp.h>\\n#endif\")\n        )\n        mod.add_to_includes(*[Include(inc) for inc in\n                              _extract_specs_dependencies(specs)])\n        mod.add_to_includes(*content.body)\n        mod.add_to_includes(\n            Include(\"pythonic/python/exception_handler.hpp\"),\n        )\n\n        def warded(module_name, internal_name):\n            return pythran_ward + '{0}::{1}'.format(module_name, internal_name)\n\n        for function_name, signatures in specs.functions.items():\n            internal_func_name = renamings.get(function_name,\n                                               function_name)\n            # global variables are functions with no signatures :-)\n            if not signatures:\n                mod.add_global_var(function_name,\n                                   \"{}()()\".format(warded(module_name,\n                                                          internal_func_name)))\n\n            for sigid, signature in enumerate(signatures):\n                numbered_function_name = \"{0}{1}\".format(internal_func_name,\n                                                         sigid)\n                arguments_types = [pytype_to_ctype(t) for t in signature]\n                arguments_names = HasArgument(internal_func_name).visit(ir)\n                arguments = [n for n, _ in\n                             zip(arguments_names, arguments_types)]\n                name_fmt = pythran_ward + \"{0}::{1}::type{2}\"\n                args_list = \", \".join(arguments_types)\n                specialized_fname = name_fmt.format(module_name,\n                                                    internal_func_name,\n                                                    \"<{0}>\".format(args_list)\n                                                    if arguments_names else \"\")\n                result_type = \"typename %s::result_type\" % specialized_fname\n                mod.add_pyfunction(\n                    FunctionBody(\n                        FunctionDeclaration(\n                            Value(\n                                result_type,\n                                numbered_function_name),\n                            [Value(t + '&&', a)\n                             for t, a in zip(arguments_types, arguments)]),\n                        Block([Statement(\"\"\"\n                            PyThreadState *_save = PyEval_SaveThread();\n                            try {{\n                                auto res = {0}()({1});\n                                PyEval_RestoreThread(_save);\n                                return res;\n                            }}\n                            catch(...) {{\n                                PyEval_RestoreThread(_save);\n                                throw;\n                            }}\n                            \"\"\".format(warded(module_name,\n                                              internal_func_name),\n                                       ', '.join(arguments)))])\n                    ),\n                    function_name,\n                    arguments_types,\n                    signature\n                )\n\n        for function_name, signature in specs.capsules.items():\n            internal_func_name = renamings.get(function_name,\n                                               function_name)\n\n            arguments_types = [pytype_to_ctype(t) for t in signature]\n            arguments_names = HasArgument(internal_func_name).visit(ir)\n            arguments = [n for n, _ in\n                         zip(arguments_names, arguments_types)]\n            name_fmt = pythran_ward + \"{0}::{1}::type{2}\"\n            args_list = \", \".join(arguments_types)\n            specialized_fname = name_fmt.format(module_name,\n                                                internal_func_name,\n                                                \"<{0}>\".format(args_list)\n                                                if arguments_names else \"\")\n            result_type = \"typename %s::result_type\" % specialized_fname\n            docstring = spec_to_string(function_name, signature)\n            mod.add_capsule(\n                FunctionBody(\n                    FunctionDeclaration(\n                        Value(result_type, function_name),\n                        [Value(t, a)\n                         for t, a in zip(arguments_types, arguments)]),\n                    Block([ReturnStatement(\"{0}()({1})\".format(\n                        warded(module_name, internal_func_name),\n                        ', '.join(arguments)))])\n                ),\n                function_name,\n                docstring\n            )\n\n    return mod, error_checker", "response": "Generate a c ++ file for a single item in the order of the code."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef compile_cxxfile(module_name, cxxfile, output_binary=None, **kwargs):\n    '''c++ file -> native module\n    Return the filename of the produced shared library\n    Raises CompileError on failure\n\n    '''\n\n    builddir = mkdtemp()\n    buildtmp = mkdtemp()\n\n    extension_args = make_extension(python=True, **kwargs)\n\n    extension = PythranExtension(module_name,\n                                 [cxxfile],\n                                 **extension_args)\n\n    try:\n        setup(name=module_name,\n              ext_modules=[extension],\n              cmdclass={\"build_ext\": PythranBuildExt},\n              # fake CLI call\n              script_name='setup.py',\n              script_args=['--verbose'\n                           if logger.isEnabledFor(logging.INFO)\n                           else '--quiet',\n                           'build_ext',\n                           '--build-lib', builddir,\n                           '--build-temp', buildtmp]\n              )\n    except SystemExit as e:\n        raise CompileError(str(e))\n\n    def copy(src_file, dest_file):\n        # not using shutil.copy because it fails to copy stat across devices\n        with open(src_file, 'rb') as src:\n            with open(dest_file, 'wb') as dest:\n                dest.write(src.read())\n\n    ext = sysconfig.get_config_var('SO')\n    # Copy all generated files including the module name prefix (.pdb, ...)\n    for f in glob.glob(os.path.join(builddir, module_name + \"*\")):\n        if f.endswith(ext):\n            if not output_binary:\n                output_binary = os.path.join(os.getcwd(), module_name + ext)\n            copy(f, output_binary)\n        else:\n            if not output_binary:\n                output_directory = os.getcwd()\n            else:\n                output_directory = os.path.dirname(output_binary)\n            copy(f, os.path.join(output_directory, os.path.basename(f)))\n    shutil.rmtree(builddir)\n    shutil.rmtree(buildtmp)\n\n    logger.info(\"Generated module: \" + module_name)\n    logger.info(\"Output: \" + output_binary)\n\n    return output_binary", "response": "Compile a C ++ file into a shared library."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompile a C ++ code into a native module.", "response": "def compile_cxxcode(module_name, cxxcode, output_binary=None, keep_temp=False,\n                    **kwargs):\n    '''c++ code (string) -> temporary file -> native module.\n    Returns the generated .so.\n\n    '''\n\n    # Get a temporary C++ file to compile\n    fdpath = _write_temp(cxxcode, '.cpp')\n    output_binary = compile_cxxfile(module_name, fdpath,\n                                    output_binary, **kwargs)\n    if not keep_temp:\n        # remove tempfile\n        os.remove(fdpath)\n    else:\n        logger.warn(\"Keeping temporary generated file:\" + fdpath)\n\n    return output_binary"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncompiles a Python code and return a native module containing the code.", "response": "def compile_pythrancode(module_name, pythrancode, specs=None,\n                        opts=None, cpponly=False, pyonly=False,\n                        output_file=None, module_dir=None, **kwargs):\n    '''Pythran code (string) -> c++ code -> native module\n\n    if `cpponly` is set to true, return the generated C++ filename\n    if `pyonly` is set to true, prints the generated Python filename,\n       unless `output_file` is set\n    otherwise, return the generated native library filename\n    '''\n\n    if pyonly:\n        # Only generate the optimized python code\n        content = generate_py(module_name, pythrancode, opts, module_dir)\n        if output_file is None:\n            print(content)\n            return None\n        else:\n            return _write_temp(content, '.py')\n\n    # Autodetect the Pythran spec if not given as parameter\n    from pythran.spec import spec_parser\n    if specs is None:\n        specs = spec_parser(pythrancode)\n\n    # Generate C++, get a PythonModule object\n    module, error_checker = generate_cxx(module_name, pythrancode, specs, opts,\n                                         module_dir)\n\n    if 'ENABLE_PYTHON_MODULE' in kwargs.get('undef_macros', []):\n        module.preamble.insert(0, Line('#undef ENABLE_PYTHON_MODULE'))\n        module.preamble.insert(0, Line('#define PY_MAJOR_VERSION {}'.\n                                       format(sys.version_info.major)))\n\n    if cpponly:\n        # User wants only the C++ code\n        tmp_file = _write_temp(str(module), '.cpp')\n        if not output_file:\n            output_file = module_name + \".cpp\"\n        shutil.move(tmp_file, output_file)\n        logger.info(\"Generated C++ source file: \" + output_file)\n    else:\n        # Compile to binary\n        try:\n            output_file = compile_cxxcode(module_name,\n                                          str(module),\n                                          output_binary=output_file,\n                                          **kwargs)\n        except CompileError:\n            logger.warn(\"Compilation error, trying hard to find its origin...\")\n            error_checker()\n            logger.warn(\"Nop, I'm going to flood you with C++ errors!\")\n            raise\n\n    return output_file"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncompiles a Python file into a Python module.", "response": "def compile_pythranfile(file_path, output_file=None, module_name=None,\n                        cpponly=False, pyonly=False, **kwargs):\n    \"\"\"\n    Pythran file -> c++ file -> native module.\n\n    Returns the generated .so (or .cpp if `cpponly` is set to true).\n\n    Usage without an existing spec file\n\n    >>> with open('pythran_test.py', 'w') as fd:\n    ...    _ = fd.write('def foo(i): return i ** 2')\n    >>> cpp_path = compile_pythranfile('pythran_test.py', cpponly=True)\n\n    Usage with an existing spec file:\n\n    >>> with open('pythran_test.pythran', 'w') as fd:\n    ...    _ = fd.write('export foo(int)')\n    >>> so_path = compile_pythranfile('pythran_test.py')\n\n    Specify the output file:\n\n    >>> import sysconfig\n    >>> ext = sysconfig.get_config_vars()[\"SO\"]\n    >>> so_path = compile_pythranfile('pythran_test.py', output_file='foo'+ext)\n    \"\"\"\n    if not output_file:\n        # derive module name from input file name\n        _, basename = os.path.split(file_path)\n        module_name = module_name or os.path.splitext(basename)[0]\n\n    else:\n        # derive module name from destination output_file name\n        _, basename = os.path.split(output_file)\n        module_name = module_name or basename.split(\".\", 1)[0]\n\n    module_dir = os.path.dirname(file_path)\n\n    # Look for an extra spec file\n    spec_file = os.path.splitext(file_path)[0] + '.pythran'\n    if os.path.isfile(spec_file):\n        specs = load_specfile(open(spec_file).read())\n        kwargs.setdefault('specs', specs)\n\n    output_file = compile_pythrancode(module_name, open(file_path).read(),\n                                      output_file=output_file,\n                                      cpponly=cpponly, pyonly=pyonly,\n                                      module_dir=module_dir,\n                                      **kwargs)\n\n    return output_file"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pairwise(X):\n    M = X.shape[0]\n    N = X.shape[1]\n    D = numpy.zeros((M,N))\n    \"omp parallel for private(i,j,d,k,tmp)\"\n    for i in xrange(M):\n        for j in xrange(M):\n            d = 0.0\n            for k in xrange(N):\n                tmp = X[i,k] - X[j,k]\n                d += tmp * tmp\n            D[i,j] = math.sqrt(d)\n    return D", "response": "omp parallel for private i j d k tmp"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef nest_reducer(x, g):\n        def wrap_in_ifs(node, ifs):\n            \"\"\"\n            Wrap comprehension content in all possibles if clauses.\n\n            Examples\n            --------\n            >> [i for i in xrange(2) if i < 3 if 0 < i]\n\n            Becomes\n\n            >> for i in xrange(2):\n            >>    if i < 3:\n            >>        if 0 < i:\n            >>            ... the code from `node` ...\n\n            Note the nested ifs clauses.\n            \"\"\"\n            return reduce(lambda n, if_: ast.If(if_, [n], []), ifs, node)\n        return ast.For(g.target, g.iter, [wrap_in_ifs(x, g.ifs)], [])", "response": "Create a ast. For node from a comprehension and another node."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef matrix_multiply(m0, m1):\n    new_matrix = numpy.zeros((m0.shape[0],m1.shape[1]))\n    \"omp parallel for private(i,j,k,r)\"\n    for i in xrange(m0.shape[0]):\n        for j in xrange(m1.shape[1]):\n            r=0\n            for k in xrange(m1.shape[0]):\n                r += m0[i,k]*m1[k,j]\n            new_matrix[i,j]=r\n    return new_matrix", "response": "multiply matrix by matrix multiplication"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef inline(self):\n        tp_lines, tp_decl = self.get_decl_pair()\n        tp_lines = \" \".join(tp_lines)\n        if tp_decl is None:\n            return tp_lines\n        else:\n            return \"%s %s\" % (tp_lines, tp_decl)", "response": "Return the declarator as a single line."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a generator that yields the declination and the structure.", "response": "def get_decl_pair(self):\n        \"\"\" See Declarator.get_decl_pair.\"\"\"\n        def get_tp():\n            \"\"\" Iterator generating lines for struct definition. \"\"\"\n            decl = \"struct \"\n            if self.tpname is not None:\n                decl += self.tpname\n                if self.inherit is not None:\n                    decl += \" : \" + self.inherit\n            yield decl\n            yield \"{\"\n            for f in self.fields:\n                for f_line in f.generate():\n                    yield \"  \" + f_line\n            yield \"} \"\n        return get_tp(), \"\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_function_to(self, to, func, name, ctypes, signature):\n        to.append(func)\n\n        args_unboxing = []  # turns PyObject to c++ object\n        args_checks = []  # check if the above conversion is valid\n        wrapper_name = pythran_ward + 'wrap_' + func.fdecl.name\n\n        for i, t in enumerate(ctypes):\n            args_unboxing.append('from_python<{}>(args_obj[{}])'.format(t, i))\n            args_checks.append('is_convertible<{}>(args_obj[{}])'.format(t, i))\n        if ctypes:\n            arg_decls = func.fdecl.arg_decls[:len(ctypes)]\n            keywords = \",\".join('\"{}\"'.format(arg.name) for arg in arg_decls)\n            wrapper = dedent('''\n                static PyObject *\n                {wname}(PyObject *self, PyObject *args, PyObject *kw)\n                {{\n                    PyObject* args_obj[{size}+1];\n                    char const* keywords[] = {{{keywords}, nullptr}};\n                    if(! PyArg_ParseTupleAndKeywords(args, kw, \"{fmt}\",\n                                                     (char**)keywords, {objs}))\n                        return nullptr;\n                    if({checks})\n                        return to_python({name}({args}));\n                    else {{\n                        return nullptr;\n                    }}\n                }}''')\n        else:\n            keywords = ''\n            wrapper = dedent('''\n                static PyObject *\n                {wname}(PyObject *self, PyObject *args, PyObject *kw)\n                {{\n                    return to_python({name}({args}));\n                }}''')\n\n        self.wrappers.append(\n            wrapper.format(name=func.fdecl.name,\n                           size=len(ctypes),\n                           fmt=\"O\" * len(ctypes),\n                           objs=', '.join('&args_obj[%d]' % i\n                                          for i in range(len(ctypes))),\n                           args=', '.join(args_unboxing),\n                           checks=' && '.join(args_checks),\n                           wname=wrapper_name,\n                           keywords=keywords,\n                           )\n        )\n\n        func_descriptor = wrapper_name, ctypes, signature\n        self.functions.setdefault(name, []).append(func_descriptor)", "response": "Adds a function to the list to be exported."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fbcorr(imgs, filters):\n    n_imgs, n_rows, n_cols, n_channels = imgs.shape\n    n_filters, height, width, n_ch2 = filters.shape\n    output = numpy.zeros((n_imgs, n_filters, (n_rows - height + 1),(n_cols - width + 1)))\n    \"omp parallel for private(rr,cc,hh,ww,jj,ff,imgval, filterval)\"\n    for ii in xrange(n_imgs):\n        for rr in xrange(n_rows - height + 1):\n            for cc in xrange(n_cols - width + 1):\n                for hh in xrange(height):\n                    for ww in xrange(width):\n                        for jj in xrange(n_channels):\n                            for ff in xrange(n_filters):\n                                imgval = imgs[ii,rr + hh,cc + ww,jj]\n                                filterval = filters[ff,hh,ww,jj]\n                                output[ii,ff,rr,cc] += imgval * filterval\n    return output", "response": "Compute the FB correlation matrix for a private page."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef visit_Subscript(self, node):\n        self.generic_visit(node)\n        if not isinstance(node.value, ast.Subscript):\n            return node\n        if not isinstance(node.value.slice, ast.Slice):\n            return node\n        if not isinstance(node.slice, ast.Index):\n            return node\n\n        if not isinstance(node.slice.value, ast.Num):\n            return node\n\n        slice_ = node.value.slice\n        index = node.slice\n        node = node.value\n\n        node.slice = index\n        lower = slice_.lower or ast.Num(0)\n        step = slice_.step or ast.Num(1)\n        node.slice.value = ast.BinOp(lower,\n                                     ast.Add(),\n                                     ast.BinOp(index.value,\n                                               ast.Mult(),\n                                               step))\n        self.update = True\n        return node", "response": "Visit a SUBSCRIPT node and return the corresponding object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating the statements in charge of gathering control flow information for the static_if result and executes the expected control flow information for the static_if result.", "response": "def make_control_flow_handlers(self, cont_n, status_n, expected_return,\n                                   has_cont, has_break):\n        '''\n        Create the statements in charge of gathering control flow information\n        for the static_if result, and executes the expected control flow\n        instruction\n        '''\n        if expected_return:\n            assign = cont_ass = [ast.Assign(\n                [ast.Tuple(expected_return, ast.Store())],\n                ast.Name(cont_n, ast.Load(), None))]\n        else:\n            assign = cont_ass = []\n\n        if has_cont:\n            cmpr = ast.Compare(ast.Name(status_n, ast.Load(), None),\n                               [ast.Eq()], [ast.Num(LOOP_CONT)])\n            cont_ass = [ast.If(cmpr,\n                               deepcopy(assign) + [ast.Continue()],\n                               cont_ass)]\n        if has_break:\n            cmpr = ast.Compare(ast.Name(status_n, ast.Load(), None),\n                               [ast.Eq()], [ast.Num(LOOP_BREAK)])\n            cont_ass = [ast.If(cmpr,\n                               deepcopy(assign) + [ast.Break()],\n                               cont_ass)]\n        return cont_ass"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreplace the placeholder if it is one or continue.", "response": "def visit(self, node):\n        \"\"\" Replace the placeholder if it is one or continue. \"\"\"\n        if isinstance(node, Placeholder):\n            return self.placeholders[node.id]\n        else:\n            return super(PlaceholderReplace, self).visit(node)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef visit(self, node):\n        for pattern, replace in know_pattern:\n            check = Check(node, dict())\n            if check.visit(pattern):\n                node = PlaceholderReplace(check.placeholders).visit(replace())\n                self.update = True\n        return super(PatternTransform, self).visit(node)", "response": "Try to replace if node match the given pattern or keep going."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef visit_Name(self, node):\n        if isinstance(node.ctx, (ast.Store, ast.Param)):\n            self.result.add(node.id)", "response": "Any node with Store or Param context is a new identifier."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nvisits the function definition node.", "response": "def visit_FunctionDef(self, node):\n        \"\"\" Function name is a possible identifier. \"\"\"\n        self.result.add(node.name)\n        self.generic_visit(node)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nvisit the For statement and return the result.", "response": "def visit_For(self, node):\n        \"\"\"\n        OUT = (node,) + last body statements\n        RAISES = body's that are not break or continue\n        \"\"\"\n        currs = (node,)\n        break_currs = tuple()\n        raises = ()\n        # handle body\n        for n in node.body:\n            self.result.add_node(n)\n            for curr in currs:\n                self.result.add_edge(curr, n)\n            currs, nraises = self.visit(n)\n            for nraise in nraises:\n                if isinstance(nraise, ast.Break):\n                    break_currs += (nraise,)\n                elif isinstance(nraise, ast.Continue):\n                    self.result.add_edge(nraise, node)\n                else:\n                    raises += (nraise,)\n        # add the backward loop\n        for curr in currs:\n            self.result.add_edge(curr, node)\n        # the else statement if needed\n        if node.orelse:\n            for n in node.orelse:\n                self.result.add_node(n)\n                for curr in currs:\n                    self.result.add_edge(curr, n)\n                currs, nraises = self.visit(n)\n        # while only\n        if hasattr(node, 'test') and is_true_predicate(node.test):\n            return break_currs, raises\n\n        return break_currs + currs, raises"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nvisit the If node and return the result.", "response": "def visit_If(self, node):\n        \"\"\"\n        OUT = true branch U false branch\n        RAISES = true branch U false branch\n        \"\"\"\n        currs = (node,)\n        raises = ()\n\n        # true branch\n        for n in node.body:\n            self.result.add_node(n)\n            for curr in currs:\n                self.result.add_edge(curr, n)\n            currs, nraises = self.visit(n)\n            raises += nraises\n        if is_true_predicate(node.test):\n            return currs, raises\n\n        # false branch\n        tcurrs = currs\n        currs = (node,)\n        for n in node.orelse:\n            self.result.add_node(n)\n            for curr in currs:\n                self.result.add_edge(curr, n)\n            currs, nraises = self.visit(n)\n            raises += nraises\n        return tcurrs + currs, raises"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nvisits a Try node and return the currs and raises nodes.", "response": "def visit_Try(self, node):\n        \"\"\"\n        OUT = body's U handler's\n        RAISES = handler's\n        this equation is not has good has it could be...\n        but we need type information to be more accurate\n        \"\"\"\n        currs = (node,)\n        raises = ()\n        for handler in node.handlers:\n            self.result.add_node(handler)\n        for n in node.body:\n            self.result.add_node(n)\n            for curr in currs:\n                self.result.add_edge(curr, n)\n            currs, nraises = self.visit(n)\n            for nraise in nraises:\n                if isinstance(nraise, ast.Raise):\n                    for handler in node.handlers:\n                        self.result.add_edge(nraise, handler)\n                else:\n                    raises += (nraise,)\n        for handler in node.handlers:\n            ncurrs, nraises = self.visit(handler)\n            currs += ncurrs\n            raises += nraises\n        return currs, raises"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef visit_ExceptHandler(self, node):\n        currs = (node,)\n        raises = ()\n        for n in node.body:\n            self.result.add_node(n)\n            for curr in currs:\n                self.result.add_edge(curr, n)\n            currs, nraises = self.visit(n)\n            raises += nraises\n        return currs, raises", "response": "Visit the except handler node and return the currs and raises nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstores variable have new value.", "response": "def visit_Name(self, node):\n        \"\"\" Stored variable have new value. \"\"\"\n        if isinstance(node.ctx, ast.Store):\n            self.result[node.id] = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add(self, variable, range_):\n        if variable not in self.result:\n            self.result[variable] = range_\n        else:\n            self.result[variable] = self.result[variable].union(range_)\n        return self.result[variable]", "response": "Adds a new low and high bound for a variable."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef visit_Assign(self, node):\n        assigned_range = self.visit(node.value)\n        for target in node.targets:\n            if isinstance(target, ast.Name):\n                # Make sure all Interval doesn't alias for multiple variables.\n                self.add(target.id, assigned_range)\n            else:\n                self.visit(target)", "response": "Set range value for assigned variable."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates augassigned variable range value.", "response": "def visit_AugAssign(self, node):\n        \"\"\" Update range value for augassigned variables.\n\n        >>> import gast as ast\n        >>> from pythran import passmanager, backend\n        >>> node = ast.parse(\"def foo(): a = 2; a -= 1\")\n        >>> pm = passmanager.PassManager(\"test\")\n        >>> res = pm.gather(RangeValues, node)\n        >>> res['a']\n        Interval(low=1, high=2)\n        \"\"\"\n        self.generic_visit(node)\n        if isinstance(node.target, ast.Name):\n            name = node.target.id\n            res = combine(node.op,\n                          self.result[name],\n                          self.result[node.value])\n            self.result[name] = self.result[name].union(res)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef visit_For(self, node):\n        assert isinstance(node.target, ast.Name), \"For apply on variables.\"\n        self.visit(node.iter)\n        if isinstance(node.iter, ast.Call):\n            for alias in self.aliases[node.iter.func]:\n                if isinstance(alias, Intrinsic):\n                    self.add(node.target.id,\n                             alias.return_range_content(\n                                 [self.visit(n) for n in node.iter.args]))\n\n        self.visit_loop(node)", "response": "Handle iterate variable in for loops."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhandles incremented variables in loop body.", "response": "def visit_loop(self, node, cond=None):\n        \"\"\" Handle incremented variables in loop body.\n\n        >>> import gast as ast\n        >>> from pythran import passmanager, backend\n        >>> node = ast.parse('''\n        ... def foo():\n        ...     a = b = c = 2\n        ...     while a > 0:\n        ...         a -= 1\n        ...         b += 1''')\n        >>> pm = passmanager.PassManager(\"test\")\n        >>> res = pm.gather(RangeValues, node)\n        >>> res['a']\n        Interval(low=-inf, high=2)\n        >>> res['b']\n        Interval(low=2, high=inf)\n        >>> res['c']\n        Interval(low=2, high=2)\n        \"\"\"\n        # visit once to gather newly declared vars\n        for stmt in node.body:\n            self.visit(stmt)\n\n        # freeze current state\n        old_range = self.result.copy()\n\n        # extra round\n        for stmt in node.body:\n            self.visit(stmt)\n\n        # widen any change\n        for expr, range_ in old_range.items():\n            self.result[expr] = self.result[expr].widen(range_)\n\n        # propagate  the new informations\n        cond and self.visit(cond)\n        for stmt in node.body:\n            self.visit(stmt)\n\n        for stmt in node.orelse:\n            self.visit(stmt)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmerges right and left operands ranges.", "response": "def visit_BoolOp(self, node):\n        \"\"\" Merge right and left operands ranges.\n\n        TODO : We could exclude some operand with this range information...\n\n        >>> import gast as ast\n        >>> from pythran import passmanager, backend\n        >>> node = ast.parse('''\n        ... def foo():\n        ...     a = 2\n        ...     c = 3\n        ...     d = a or c''')\n        >>> pm = passmanager.PassManager(\"test\")\n        >>> res = pm.gather(RangeValues, node)\n        >>> res['d']\n        Interval(low=2, high=3)\n        \"\"\"\n        res = list(zip(*[self.visit(elt).bounds() for elt in node.values]))\n        return self.add(node, Interval(min(res[0]), max(res[1])))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef visit_BinOp(self, node):\n        res = combine(node.op, self.visit(node.left), self.visit(node.right))\n        return self.add(node, res)", "response": "Combine operands ranges for given binary operator."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating the range with given unary operation.", "response": "def visit_UnaryOp(self, node):\n        \"\"\" Update range with given unary operation.\n\n        >>> import gast as ast\n        >>> from pythran import passmanager, backend\n        >>> node = ast.parse('''\n        ... def foo():\n        ...     a = 2\n        ...     c = -a\n        ...     d = ~a\n        ...     f = +a\n        ...     e = not a''')\n        >>> pm = passmanager.PassManager(\"test\")\n        >>> res = pm.gather(RangeValues, node)\n        >>> res['f']\n        Interval(low=2, high=2)\n        >>> res['c']\n        Interval(low=-2, high=-2)\n        >>> res['d']\n        Interval(low=-3, high=-3)\n        >>> res['e']\n        Interval(low=0, high=1)\n        \"\"\"\n        res = self.visit(node.operand)\n        if isinstance(node.op, ast.Not):\n            res = Interval(0, 1)\n        elif(isinstance(node.op, ast.Invert) and\n             isinstance(res.high, int) and\n             isinstance(res.low, int)):\n            res = Interval(~res.high, ~res.low)\n        elif isinstance(node.op, ast.UAdd):\n            pass\n        elif isinstance(node.op, ast.USub):\n            res = Interval(-res.high, -res.low)\n        else:\n            res = UNKNOWN_RANGE\n        return self.add(node, res)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nhandle iterate variable across branches", "response": "def visit_If(self, node):\n        \"\"\" Handle iterate variable across branches\n\n        >>> import gast as ast\n        >>> from pythran import passmanager, backend\n        >>> node = ast.parse('''\n        ... def foo(a):\n        ...     if a > 1: b = 1\n        ...     else: b = 3''')\n\n        >>> pm = passmanager.PassManager(\"test\")\n        >>> res = pm.gather(RangeValues, node)\n        >>> res['b']\n        Interval(low=1, high=3)\n        \"\"\"\n        self.visit(node.test)\n        old_range = self.result\n\n        self.result = old_range.copy()\n        for stmt in node.body:\n            self.visit(stmt)\n        body_range = self.result\n\n        self.result = old_range.copy()\n        for stmt in node.orelse:\n            self.visit(stmt)\n        orelse_range = self.result\n\n        self.result = body_range\n        for k, v in orelse_range.items():\n            if k in self.result:\n                self.result[k] = self.result[k].union(v)\n            else:\n                self.result[k] = v"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvisit the IfExp node and add it to the result set.", "response": "def visit_IfExp(self, node):\n        \"\"\" Use worst case for both possible values.\n\n        >>> import gast as ast\n        >>> from pythran import passmanager, backend\n        >>> node = ast.parse('''\n        ... def foo():\n        ...     a = 2 or 3\n        ...     b = 4 or 5\n        ...     c = a if a else b''')\n        >>> pm = passmanager.PassManager(\"test\")\n        >>> res = pm.gather(RangeValues, node)\n        >>> res['c']\n        Interval(low=2, high=5)\n        \"\"\"\n        self.visit(node.test)\n        body_res = self.visit(node.body)\n        orelse_res = self.visit(node.orelse)\n        return self.add(node, orelse_res.union(body_res))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nvisits the function call and return the result.", "response": "def visit_Call(self, node):\n        \"\"\" Function calls are not handled for now.\n\n        >>> import gast as ast\n        >>> from pythran import passmanager, backend\n        >>> node = ast.parse('''\n        ... def foo():\n        ...     a = __builtin__.range(10)''')\n        >>> pm = passmanager.PassManager(\"test\")\n        >>> res = pm.gather(RangeValues, node)\n        >>> res['a']\n        Interval(low=-inf, high=inf)\n        \"\"\"\n        for alias in self.aliases[node.func]:\n            if alias is MODULES['__builtin__']['getattr']:\n                attr_name = node.args[-1].s\n                attribute = attributes[attr_name][-1]\n                self.add(node, attribute.return_range(None))\n            elif isinstance(alias, Intrinsic):\n                alias_range = alias.return_range(\n                    [self.visit(n) for n in node.args])\n                self.add(node, alias_range)\n            else:\n                return self.generic_visit(node)\n        return self.result[node]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nhandles literals integers values.", "response": "def visit_Num(self, node):\n        \"\"\" Handle literals integers values. \"\"\"\n        if isinstance(node.n, int):\n            return self.add(node, Interval(node.n, node.n))\n        return UNKNOWN_RANGE"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef visit_Name(self, node):\n        return self.add(node, self.result[node.id])", "response": "Get range for parameters or false branching."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd unknown range value to the set.", "response": "def generic_visit(self, node):\n        \"\"\" Other nodes are not known and range value neither. \"\"\"\n        super(RangeValues, self).generic_visit(node)\n        return self.add(node, UNKNOWN_RANGE)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbuilds a dictionnary with an entry for cppflags ldflags and cxxflags.", "response": "def compile_flags(args):\n    \"\"\"\n    Build a dictionnary with an entry for cppflags, ldflags, and cxxflags.\n\n    These options are filled according to the command line defined options\n\n    \"\"\"\n\n    compiler_options = {\n        'define_macros': args.defines,\n        'undef_macros': args.undefs,\n        'include_dirs': args.include_dirs,\n        'extra_compile_args': args.extra_flags,\n        'library_dirs': args.libraries_dir,\n        'extra_link_args': args.extra_flags,\n    }\n    for param in ('opts', ):\n        val = getattr(args, param, None)\n        if val:\n            compiler_options[param] = val\n\n    return compiler_options"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind the builtin keyword that matches the given node.", "response": "def find_matching_builtin(self, node):\n        \"\"\"\n        Return matched keyword.\n\n        If the node alias on a correct keyword (and only it), it matches.\n        \"\"\"\n        for path in EQUIVALENT_ITERATORS.keys():\n            correct_alias = {path_to_node(path)}\n            if self.aliases[node.func] == correct_alias:\n                return path"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds itertools. izip or izip iterator to the node body.", "response": "def visit_Module(self, node):\n        \"\"\"Add itertools import for imap, izip or ifilter iterator.\"\"\"\n        self.generic_visit(node)\n        import_alias = ast.alias(name='itertools', asname=mangle('itertools'))\n        if self.use_itertools:\n            importIt = ast.Import(names=[import_alias])\n            node.body.insert(0, importIt)\n        return node"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreplaces function call by its correct iterator if it is possible.", "response": "def visit_Call(self, node):\n        \"\"\"Replace function call by its correct iterator if it is possible.\"\"\"\n        if node in self.potential_iterator:\n            matched_path = self.find_matching_builtin(node)\n            if matched_path is None:\n                return self.generic_visit(node)\n\n            # Special handling for map which can't be turn to imap with None as\n            # a parameter as map(None, [1, 2]) == [1, 2] while\n            # list(imap(None, [1, 2])) == [(1,), (2,)]\n            if (matched_path[1] == \"map\" and\n                    MODULES[\"__builtin__\"][\"None\"] in\n                    self.aliases[node.args[0]]):\n                return self.generic_visit(node)\n\n            # if a dtype conversion is implied\n            if matched_path[1] in ('array', 'asarray') and len(node.args) != 1:\n                return self.generic_visit(node)\n\n            path = EQUIVALENT_ITERATORS[matched_path]\n            if path:\n                node.func = path_to_attr(path)\n                self.use_itertools |= path[0] == 'itertools'\n            else:\n                node = node.args[0]\n\n            self.update = True\n        return self.generic_visit(node)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef range_values(args):\n    if len(args) == 1:\n        return Interval(0, args[0].high)\n    elif len(args) == 2:\n        return Interval(args[0].low, args[1].high)\n    elif len(args) == 3:\n        is_neg = args[2].low < 0\n        is_pos = args[2].high > 0\n        if is_neg and is_pos:\n            return UNKNOWN_RANGE\n        elif is_neg:\n            return Interval(args[1].low, args[0].high)\n        else:\n            return Interval(args[0].low, args[1].high)", "response": "Function used to compute returned range value of [ x ]range function."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns possible range for max function.", "response": "def max_values(args):\n    \"\"\" Return possible range for max function. \"\"\"\n    return Interval(max(x.low for x in args), max(x.high for x in args))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef min_values(args):\n    return Interval(min(x.low for x in args), min(x.high for x in args))", "response": "Return possible range for min function."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef union(self, other):\n        return Interval(min(self.low, other.low), max(self.high, other.high))", "response": "Intersect current range with other."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexports : | PYTHRAN EXPORT export_list opt_craps exports | PYTHRAN EXPORT CAPSULE export_list opt_craps exports", "response": "def p_exports(self, p):\n        '''exports :\n                   | PYTHRAN EXPORT export_list opt_craps exports\n                   | PYTHRAN EXPORT CAPSULE export_list opt_craps exports'''\n        if len(p) > 1:\n            target = self.exports if len(p) == 6 else self.native_exports\n            for key, val in p[len(p)-3]:\n                target[key] += val"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_export(self, p):\n        '''export : IDENTIFIER LPAREN opt_param_types RPAREN\n                  | IDENTIFIER\n                  | EXPORT LPAREN opt_param_types RPAREN\n                  | ORDER LPAREN opt_param_types RPAREN'''\n        # unlikely case: the IDENTIFIER is an otherwise reserved name\n        if len(p) > 2:\n            sigs = p[3] or ((),)\n        else:\n            sigs = ()\n        p[0] = p[1], sigs", "response": "export | EXPORT LPAREN opt_param_types RPAREN | ORDER LPAREN opt_param_types RPAREN | EXPORT LPAREN opt_param_types RPAREN | EXPORT LPAREN opt_param_types RPAREN | ORDER LPAREN opt_param_types RPAREN | EXPORT LPAREN opt_param_types RPAREN | EXPORT LPAREN opt_param_types RPAREN | ORDER LPAREN opt_param_types RPAREN | EXPORT LPAREN opt_param_types R"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntypes | types COMMA types", "response": "def p_types(self, p):\n        '''types : type\n                 | type COMMA types'''\n        if len(p) == 2:\n            p[0] = tuple((t,) for t in p[1])\n        else:\n            p[0] = tuple((t,) + ts for t in p[1] for ts in p[3])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_type(self, p):\n        '''type : term\n                | array_type opt_order\n                | pointer_type\n                | type LIST\n                | type SET\n                | type LPAREN opt_types RPAREN\n                | type COLUMN type DICT\n                | LPAREN types RPAREN\n                | LARRAY type RARRAY\n                | type OR type\n                '''\n        if len(p) == 2:\n            p[0] = p[1],\n        elif len(p) == 3 and p[2] == 'list':\n            p[0] = tuple(List[t] for t in p[1])\n        elif len(p) == 3 and p[2] == 'set':\n            p[0] = tuple(Set[t] for t in p[1])\n        elif len(p) == 3:\n            if p[2] is None:\n                expanded = []\n                for nd in p[1]:\n                    expanded.append(nd)\n                    if isinstance(nd, NDArray) and len(nd.__args__) == 3:\n                        expanded.append(NDArray[nd.__args__[0], -1::, -1::])\n                p[0] = tuple(expanded)\n            elif p[2] == \"F\":\n                for nd in p[1]:\n                    if len(nd.__args__) != 3:\n                        raise PythranSyntaxError(\"Invalid Pythran spec. \"\n                                                 \"F order is only valid for 2D arrays\")\n                p[0] = tuple(NDArray[nd.__args__[0], -1::, -1::] for nd in p[1])\n            else:\n                p[0] = p[1]\n        elif len(p) == 5 and p[4] == ')':\n            p[0] = tuple(Fun[args, r]\n                         for r in p[1]\n                         for args in (product(*p[3])\n                                      if len(p[3]) > 1 else p[3]))\n        elif len(p) == 5:\n            p[0] = tuple(Dict[k, v] for k in p[1] for v in p[3])\n        elif len(p) == 4 and p[2] == 'or':\n            p[0] = p[1] + p[3]\n        elif len(p) == 4 and p[3] == ')':\n            p[0] = tuple(Tuple[t] for t in p[2])\n        elif len(p) == 4 and p[3] == ']':\n            p[0] = p[2]\n        else:\n            raise PythranSyntaxError(\"Invalid Pythran spec. \"\n                                     \"Unknown text '{0}'\".format(p.value))", "response": "type of the term in the database"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_opt_order(self, p):\n        '''opt_order :\n                     | ORDER LPAREN IDENTIFIER RPAREN'''\n        if len(p) > 1:\n            if p[3] not in 'CF':\n                raise PythranSyntaxError(\"Invalid Pythran spec. \"\n                                         \"Unknown order '{}'\".format(p[3]))\n            p[0] = p[3]\n        else:\n            p[0] = None", "response": "opt_order :\n                     | ORDER LPAREN IDENTIFIER RPAREN"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_array_indices(self, p):\n        '''array_indices : array_index\n                         | array_index COMMA array_indices'''\n        if len(p) == 2:\n            p[0] = p[1],\n        else:\n            p[0] = (p[1],) + p[3]", "response": "array_indices | array_index COMMA array_indices"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nterming is a term type", "response": "def p_term(self, p):\n        '''term : STR\n                | NONE\n                | dtype'''\n        if p[1] == 'str':\n            p[0] = str\n        elif p[1] == 'None':\n            p[0] = type(None)\n        else:\n            p[0] = p[1][0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates u from the private structure", "response": "def calculate_u(dt, dx, dy, u, um, k):\n    up = numpy.zeros((u.shape[0], u.shape[1]))\n    \"omp parallel for private(i,j)\"\n    for i in xrange(1, u.shape[0]-1):\n        for j in xrange(1, u.shape[1]-1):\n            up[i,j] = 2*u[i,j] - um[i,j] + \\\n                (dt/dx)**2*(\n                        (0.5*(k[i+1,j] + k[i,j])*(u[i+1,j] - u[i,j]) -\n                            0.5*(k[i,j] + k[i-1,j])*(u[i,j] - u[i-1,j]))) + \\\n                        (dt/dy)**2*(\n                                (0.5*(k[i,j+1] + k[i,j])*(u[i,j+1] - u[i,j]) -\n                                    0.5*(k[i,j] + k[i,j-1])*(u[i,j] - u[i,j-1])))\n    return up"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngathers keywords to positional argument information COOKIES Assumes the named parameter exist raises a KeyError otherwise", "response": "def handle_keywords(self, func, node, offset=0):\n        '''\n        Gather keywords to positional argument information\n\n        Assumes the named parameter exist, raises a KeyError otherwise\n        '''\n        func_argument_names = {}\n        for i, arg in enumerate(func.args.args[offset:]):\n            assert isinstance(arg, ast.Name)\n            func_argument_names[arg.id] = i\n\n        nargs = len(func.args.args) - offset\n        defaults = func.args.defaults\n        keywords = {func_argument_names[kw.arg]: kw.value\n                    for kw in node.keywords}\n        node.args.extend([None] * (1 + max(keywords.keys()) - len(node.args)))\n\n        replacements = {}\n        for index, arg in enumerate(node.args):\n            if arg is None:\n                if index in keywords:\n                    replacements[index] = deepcopy(keywords[index])\n                else:  # must be a default value\n                    replacements[index] = deepcopy(defaults[index - nargs])\n        return replacements"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncombining the arguments of a function into a list of node_args_k.", "response": "def update_effects(self, node):\n    \"\"\"\n    Combiner when we update the first argument of a function.\n\n    It turn type of first parameter in combination of all others\n    parameters types.\n    \"\"\"\n    return [self.combine(node.args[0], node_args_k, register=True,\n                         aliasing_type=True)\n            for node_args_k in node.args[1:]]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fill_constants_types(module_name, elements):\n    for elem, intrinsic in elements.items():\n        if isinstance(intrinsic, dict):  # Submodule case\n            fill_constants_types(module_name + (elem,), intrinsic)\n        elif isinstance(intrinsic, ConstantIntr):\n            # use introspection to get the Python constants types\n            cst = getattr(__import__(\".\".join(module_name)), elem)\n            intrinsic.signature = type(cst)", "response": "Recursively save the types of the constants in the specified module."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save_function(elements, module_path):\n    for elem, signature in elements.items():\n        if isinstance(signature, dict):  # Submodule case\n            save_function(signature, module_path + (elem,))\n        elif signature.isstaticfunction():\n            functions.setdefault(elem, []).append((module_path, signature,))\n        elif isinstance(signature, Class):\n            save_function(signature.fields, module_path + (elem,))", "response": "Recursively save functions with module name and signature."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save_attribute(elements, module_path):\n    for elem, signature in elements.items():\n        if isinstance(signature, dict):  # Submodule case\n            save_attribute(signature, module_path + (elem,))\n        elif signature.isattribute():\n            assert elem not in attributes  # we need unicity\n            attributes[elem] = (module_path, signature,)\n        elif isinstance(signature, Class):\n            save_attribute(signature.fields, module_path + (elem,))", "response": "Recursively save attributes with module name and signature."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pi_estimate(DARTS):\n    hits = 0\n    \"omp parallel for private(i,x,y,dist), reduction(+:hits)\"\n    for i in xrange (0, DARTS):\n    \tx = random()\n    \ty = random()\n    \tdist = sqrt(pow(x, 2) + pow(y, 2))\n    \tif dist <= 1.0:\n            hits += 1.0\n    # hits / throws = 1/4 Pi\n    pi = 4 * (hits / DARTS)\n    return pi", "response": "estimate pi for private i x y dist"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreplaces list calls by static_list calls when possible is set to 0", "response": "def visit_Assign(self, node):\n        \"\"\"\n        Replace list calls by static_list calls when possible\n\n        >>> import gast as ast\n        >>> from pythran import passmanager, backend\n        >>> node = ast.parse(\"def foo(n): x = __builtin__.list(n); x[0] = 0; return __builtin__.tuple(x)\")\n        >>> pm = passmanager.PassManager(\"test\")\n        >>> _, node = pm.apply(ListToTuple, node)\n        >>> print(pm.dump(backend.Python, node))\n        def foo(n):\n            x = __builtin__.pythran.static_list(n)\n            x[0] = 0\n            return __builtin__.tuple(x)\n\n        >>> node = ast.parse(\"def foo(n): x = __builtin__.list(n); x[0] = 0; return x\")\n        >>> pm = passmanager.PassManager(\"test\")\n        >>> _, node = pm.apply(ListToTuple, node)\n        >>> print(pm.dump(backend.Python, node))\n        def foo(n):\n            x = __builtin__.list(n)\n            x[0] = 0\n            return x\n        \"\"\"\n        self.generic_visit(node)\n        if node.value not in self.fixed_size_list:\n            return node\n\n        node.value = self.convert(node.value)\n        return node"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninstalls boost deps from the third_party directory", "response": "def copy_pkg(self, pkg, src_only=False):\n        \"Install boost deps from the third_party directory\"\n\n        if getattr(self, 'no_' + pkg) is None:\n            print('Copying boost dependencies')\n            to_copy = pkg,\n        else:\n            return\n\n        src = os.path.join('third_party', *to_copy)\n\n        # copy to the build tree\n        if not src_only:\n            target = os.path.join(self.build_lib, 'pythran', *to_copy)\n            shutil.rmtree(target, True)\n            shutil.copytree(src, target)\n\n        # copy them to the source tree too, needed for sdist\n        target = os.path.join('pythran', *to_copy)\n        shutil.rmtree(target, True)\n        shutil.copytree(src, target)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if list of node elements are equal.", "response": "def check_list(self, node_list, pattern_list):\n        \"\"\" Check if list of node are equal. \"\"\"\n        if len(node_list) != len(pattern_list):\n            return False\n        else:\n            return all(Check(node_elt,\n                             self.placeholders).visit(pattern_list[i])\n                       for i, node_elt in enumerate(node_list))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef visit_Placeholder(self, pattern):\n        if (pattern.id in self.placeholders and\n                not Check(self.node, self.placeholders).visit(\n                    self.placeholders[pattern.id])):\n            return False\n        else:\n            self.placeholders[pattern.id] = self.node\n            return True", "response": "Save matching node or compare it with the existing one."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmatching if any of the or content match with the other node.", "response": "def visit_AST_or(self, pattern):\n        \"\"\" Match if any of the or content match with the other node. \"\"\"\n        return any(self.field_match(self.node, value_or)\n                   for value_or in pattern.args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if the pattern has unordered values.", "response": "def visit_Set(self, pattern):\n        \"\"\" Set have unordered values. \"\"\"\n        if len(pattern.elts) > MAX_UNORDERED_LENGTH:\n            raise DamnTooLongPattern(\"Pattern for Set is too long\")\n        return (isinstance(self.node, Set) and\n                any(self.check_list(self.node.elts, pattern_elts)\n                    for pattern_elts in permutations(pattern.elts)))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if Dict matches with unordered values.", "response": "def visit_Dict(self, pattern):\n        \"\"\" Dict can match with unordered values. \"\"\"\n        if not isinstance(self.node, Dict):\n            return False\n        if len(pattern.keys) > MAX_UNORDERED_LENGTH:\n            raise DamnTooLongPattern(\"Pattern for Dict is too long\")\n        for permutation in permutations(range(len(self.node.keys))):\n            for i, value in enumerate(permutation):\n                if not self.field_match(self.node.keys[i],\n                                        pattern.keys[value]):\n                    break\n            else:\n                pattern_values = [pattern.values[i] for i in permutation]\n                return self.check_list(self.node.values, pattern_values)\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef field_match(self, node_field, pattern_field):\n        is_good_list = (isinstance(pattern_field, list) and\n                        self.check_list(node_field, pattern_field))\n        is_good_node = (isinstance(pattern_field, AST) and\n                        Check(node_field,\n                              self.placeholders).visit(pattern_field))\n\n        def strict_eq(f0, f1):\n            try:\n                return f0 == f1 or (isnan(f0) and isnan(f1))\n            except TypeError:\n                return f0 == f1\n\n        is_same = strict_eq(pattern_field, node_field)\n        return is_good_list or is_good_node or is_same", "response": "Check if two fields match."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if the pattern match with the checked node.", "response": "def generic_visit(self, pattern):\n        \"\"\"\n        Check if the pattern match with the checked node.\n\n        a node match if:\n            - type match\n            - all field match\n        \"\"\"\n        return (isinstance(pattern, type(self.node)) and\n                all(self.field_match(value, getattr(pattern, field))\n                    for field, value in iter_fields(self.node)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef visit(self, node):\n        if Check(node, dict()).visit(self.pattern):\n            self.result.add(node)\n        self.generic_visit(node)", "response": "Visitor looking for matching between current node and pattern."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef visit_Call(self, node):\n        md.visit(self, node)\n        for arg in node.args:\n            self.visit(arg)\n        self.func_args_lazyness(node.func, node.args, node)\n        self.visit(node.func)", "response": "Visit the arguments and call the function name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef visit_Stmt(self, node):\n        save_defs, self.defs = self.defs or list(), list()\n        self.generic_visit(node)\n        new_defs, self.defs = self.defs, save_defs\n        return new_defs + [node]", "response": "Add new variable definition before the Statement."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef visit_Call(self, node):\n        func_aliases = self.aliases[node.func]\n        if len(func_aliases) == 1:\n            function_def = next(iter(func_aliases))\n            if (isinstance(function_def, ast.FunctionDef) and\n                    function_def.name in self.inlinable):\n                self.update = True\n                to_inline = copy.deepcopy(self.inlinable[function_def.name])\n                arg_to_value = dict()\n                values = node.args\n                values += to_inline.args.defaults[len(node.args) -\n                                                  len(to_inline.args.args):]\n                for arg_fun, arg_call in zip(to_inline.args.args, values):\n                    v_name = \"__pythran_inline{}{}{}\".format(function_def.name,\n                                                             arg_fun.id,\n                                                             self.call_count)\n                    new_var = ast.Name(id=v_name,\n                                       ctx=ast.Store(),\n                                       annotation=None)\n                    self.defs.append(ast.Assign(targets=[new_var],\n                                                value=arg_call))\n                    arg_to_value[arg_fun.id] = ast.Name(id=v_name,\n                                                        ctx=ast.Load(),\n                                                        annotation=None)\n                self.call_count += 1\n                return Inliner(arg_to_value).visit(to_inline.body[0])\n        return node", "response": "Replace function call by inlined function s body."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting value to ast expression for sized container.", "response": "def size_container_folding(value):\n    \"\"\"\n    Convert value to ast expression if size is not too big.\n\n    Converter for sized container.\n    \"\"\"\n    if len(value) < MAX_LEN:\n        if isinstance(value, list):\n            return ast.List([to_ast(elt) for elt in value], ast.Load())\n        elif isinstance(value, tuple):\n            return ast.Tuple([to_ast(elt) for elt in value], ast.Load())\n        elif isinstance(value, set):\n            return ast.Set([to_ast(elt) for elt in value])\n        elif isinstance(value, dict):\n            keys = [to_ast(elt) for elt in value.keys()]\n            values = [to_ast(elt) for elt in value.values()]\n            return ast.Dict(keys, values)\n        elif isinstance(value, np.ndarray):\n            return ast.Call(func=ast.Attribute(\n                ast.Name(mangle('numpy'), ast.Load(), None),\n                'array',\n                ast.Load()),\n                args=[to_ast(totuple(value.tolist())),\n                      ast.Attribute(\n                          ast.Name(mangle('numpy'), ast.Load(), None),\n                          value.dtype.name,\n                          ast.Load())],\n                keywords=[])\n        else:\n            raise ConversionError()\n    else:\n        raise ToNotEval()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert builtin function to ast expression.", "response": "def builtin_folding(value):\n    \"\"\" Convert builtin function to ast expression. \"\"\"\n    if isinstance(value, (type(None), bool)):\n        name = str(value)\n    elif value.__name__ in (\"bool\", \"float\", \"int\"):\n        name = value.__name__ + \"_\"\n    else:\n        name = value.__name__\n    return ast.Attribute(ast.Name('__builtin__', ast.Load(), None),\n                         name, ast.Load())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nturning a value into an ast expression.", "response": "def to_ast(value):\n    \"\"\"\n    Turn a value into ast expression.\n\n    >>> a = 1\n    >>> print(ast.dump(to_ast(a)))\n    Num(n=1)\n    >>> a = [1, 2, 3]\n    >>> print(ast.dump(to_ast(a)))\n    List(elts=[Num(n=1), Num(n=2), Num(n=3)], ctx=Load())\n    \"\"\"\n\n    if isinstance(value, (type(None), bool)):\n        return builtin_folding(value)\n    if sys.version_info[0] == 2 and isinstance(value, long):\n        from pythran.syntax import PythranSyntaxError\n        raise PythranSyntaxError(\"constant folding results in big int\")\n    if any(value is t for t in (bool, int, float)):\n        iinfo = np.iinfo(int)\n        if isinstance(value, int) and not (iinfo.min <= value <= iinfo.max):\n            from pythran.syntax import PythranSyntaxError\n            raise PythranSyntaxError(\"constant folding results in big int\")\n        return builtin_folding(value)\n    elif isinstance(value, np.generic):\n        return to_ast(np.asscalar(value))\n    elif isinstance(value, numbers.Number):\n        return ast.Num(value)\n    elif isinstance(value, str):\n        return ast.Str(value)\n    elif isinstance(value, (list, tuple, set, dict, np.ndarray)):\n        return size_container_folding(value)\n    elif hasattr(value, \"__module__\") and value.__module__ == \"__builtin__\":\n        # TODO Can be done the same way for others modules\n        return builtin_folding(value)\n    # only meaningful for python3\n    elif sys.version_info.major == 3:\n        if isinstance(value, (filter, map, zip)):\n            return to_ast(list(value))\n    raise ToNotEval()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nimporting module define a new variable name.", "response": "def visit_Module(self, node):\n        \"\"\" Import module define a new variable name. \"\"\"\n        duc = SilentDefUseChains()\n        duc.visit(node)\n        for d in duc.locals[node]:\n            self.result[d.name()] = d.node"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute the path and final object for an attribute node.", "response": "def attr_to_path(node):\n    \"\"\" Compute path and final object for an attribute node \"\"\"\n\n    def get_intrinsic_path(modules, attr):\n        \"\"\" Get function path and intrinsic from an ast.Attribute.  \"\"\"\n        if isinstance(attr, ast.Name):\n            return modules[demangle(attr.id)], (demangle(attr.id),)\n        elif isinstance(attr, ast.Attribute):\n            module, path = get_intrinsic_path(modules, attr.value)\n            return module[attr.attr], path + (attr.attr,)\n    obj, path = get_intrinsic_path(MODULES, node)\n    if not obj.isliteral():\n        path = path[:-1] + ('functor', path[-1])\n    return obj, ('pythonic', ) + path"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef path_to_attr(path):\n    return reduce(lambda hpath, last: ast.Attribute(hpath, last, ast.Load()),\n                  path[1:], ast.Name(mangle(path[0]), ast.Load(), None))", "response": "Transform a path to ast. Attribute.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_variable(assignable):\n    msg = \"Only name and subscript can be assigned.\"\n    assert isinstance(assignable, (ast.Name, ast.Subscript)), msg\n    while isinstance(assignable, ast.Subscript) or isattr(assignable):\n        if isattr(assignable):\n            assignable = assignable.args[0]\n        else:\n            assignable = assignable.value\n    return assignable", "response": "Return modified variable name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nformatting type dependencies information to use if reordering.", "response": "def prepare(self, node):\n        \"\"\" Format type dependencies information to use if for reordering. \"\"\"\n        super(Reorder, self).prepare(node)\n        candidates = self.type_dependencies.successors(\n            TypeDependencies.NoDeps)\n        # We first select function which may have a result without calling any\n        # others functions.\n        # Then we check if no loops type dependencies exists. If it exists, we\n        # can safely remove the dependency as it could be compute without this\n        # information.\n        # As we can compute type for this function, successors can potentially\n        # be computed\n        # FIXME: This is false in some cases\n        #\n        # def bar(i):\n        #   if i > 0:\n        #     return foo(i)\n        #   else:\n        #     return []\n        #\n        # def foo(i):\n        #   return [len(bar(i-1)) + len(bar(i - 2))]\n        #\n        # If we check for function without deps first, we will pick bar and say\n        # it returns empty list\n        while candidates:\n            new_candidates = list()\n            for n in candidates:\n                # remove edges that imply a circular dependency\n                for p in list(self.type_dependencies.predecessors(n)):\n                    if nx.has_path(self.type_dependencies, n, p):\n                        self.type_dependencies.remove_edge(p, n)\n                if n not in self.type_dependencies.successors(n):\n                    new_candidates.extend(self.type_dependencies.successors(n))\n            candidates = new_candidates"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nkeeping everything but function definition then add sorted functions.", "response": "def visit_Module(self, node):\n        \"\"\"\n        Keep everything but function definition then add sorted functions.\n\n        Most of the time, many function sort work so we use function calldepth\n        as a \"sort hint\" to simplify typing.\n        \"\"\"\n        newbody = list()\n        olddef = list()\n        for stmt in node.body:\n            if isinstance(stmt, ast.FunctionDef):\n                olddef.append(stmt)\n            else:\n                newbody.append(stmt)\n        try:\n            newdef = topological_sort(\n                self.type_dependencies,\n                self.ordered_global_declarations)\n            newdef = [f for f in newdef if isinstance(f, ast.FunctionDef)]\n        except nx.exception.NetworkXUnfeasible:\n            raise PythranSyntaxError(\"Infinite function recursion\")\n\n        assert set(newdef) == set(olddef), \"A function have been lost...\"\n        node.body = newbody + newdef\n        self.update = True\n        return node"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding dead code elimination OMPDirective from the old node to the new one.", "response": "def visit(self, node):\n        \"\"\" Add OMPDirective from the old node to the new one. \"\"\"\n        old_omp = metadata.get(node, OMPDirective)\n        node = super(DeadCodeElimination, self).visit(node)\n        if not metadata.get(node, OMPDirective):\n            for omp_directive in old_omp:\n                metadata.add(node, omp_directive)\n        return node"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef visit_BoolOp(self, node):\n        '''\n        Resulting node may alias to either operands:\n\n        >>> from pythran import passmanager\n        >>> pm = passmanager.PassManager('demo')\n        >>> module = ast.parse('def foo(a, b): return a or b')\n        >>> result = pm.gather(Aliases, module)\n        >>> Aliases.dump(result, filter=ast.BoolOp)\n        (a or b) => ['a', 'b']\n\n        Note that a literal does not create any alias\n\n        >>> module = ast.parse('def foo(a, b): return a or 0')\n        >>> result = pm.gather(Aliases, module)\n        >>> Aliases.dump(result, filter=ast.BoolOp)\n        (a or 0) => ['<unbound-value>', 'a']\n        '''\n        return self.add(node, set.union(*[self.visit(n) for n in node.values]))", "response": "Visit a BoolOp node and add it to the set of identifiers that are used by the passmanager."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef visit_IfExp(self, node):\n        '''\n        Resulting node alias to either branch\n\n        >>> from pythran import passmanager\n        >>> pm = passmanager.PassManager('demo')\n        >>> module = ast.parse('def foo(a, b, c): return a if c else b')\n        >>> result = pm.gather(Aliases, module)\n        >>> Aliases.dump(result, filter=ast.IfExp)\n        (a if c else b) => ['a', 'b']\n        '''\n        self.visit(node.test)\n        rec = [self.visit(n) for n in (node.body, node.orelse)]\n        return self.add(node, set.union(*rec))", "response": "Visit the IfExp node and return the result."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nvisiting a Return node and update the return_alias field of the current function.", "response": "def visit_Return(self, node):\n        '''\n        A side effect of computing aliases on a Return is that it updates the\n        ``return_alias`` field of current function\n\n        >>> from pythran import passmanager\n        >>> pm = passmanager.PassManager('demo')\n        >>> module = ast.parse('def foo(a, b): return a')\n        >>> result = pm.gather(Aliases, module)\n        >>> module.body[0].return_alias # doctest: +ELLIPSIS\n        <function ...merge_return_aliases at...>\n\n        This field is a function that takes as many nodes as the function\n        argument count as input and returns an expression based on\n        these arguments if the function happens to create aliasing\n        between its input and output. In our case:\n\n        >>> f = module.body[0].return_alias\n        >>> Aliases.dump(f([ast.Name('A', ast.Load(), None), ast.Num(1)]))\n        ['A']\n\n        This also works if the relationship between input and output\n        is more complex:\n\n        >>> module = ast.parse('def foo(a, b): return a or b[0]')\n        >>> result = pm.gather(Aliases, module)\n        >>> f = module.body[0].return_alias\n        >>> List = ast.List([ast.Name('L0', ast.Load(), None)], ast.Load())\n        >>> Aliases.dump(f([ast.Name('B', ast.Load(), None), List]))\n        ['B', '[L0][0]']\n\n        Which actually means that when called with two arguments ``B`` and\n        the single-element list ``[L[0]]``, ``foo`` may returns either the\n        first argument, or the first element of the second argument.\n        '''\n        if not node.value:\n            return\n        ret_aliases = self.visit(node.value)\n        if Aliases.RetId in self.aliases:\n            ret_aliases = ret_aliases.union(self.aliases[Aliases.RetId])\n        self.aliases[Aliases.RetId] = ret_aliases"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nvisits a call node and return the node alias to the return_alias of called function.", "response": "def visit_Call(self, node):\n        '''\n        Resulting node alias to the return_alias of called function,\n        if the function is already known by Pythran (i.e. it's an Intrinsic)\n        or if Pythran already computed it's ``return_alias`` behavior.\n\n        >>> from pythran import passmanager\n        >>> pm = passmanager.PassManager('demo')\n        >>> fun = \"\"\"\n        ... def f(a): return a\n        ... def foo(b): c = f(b)\"\"\"\n        >>> module = ast.parse(fun)\n\n        The ``f`` function create aliasing between\n        the returned value and its first argument.\n\n        >>> result = pm.gather(Aliases, module)\n        >>> Aliases.dump(result, filter=ast.Call)\n        f(b) => ['b']\n\n        This also works with intrinsics, e.g ``dict.setdefault`` which\n        may create alias between its third argument and the return value.\n\n        >>> fun = 'def foo(a, d): __builtin__.dict.setdefault(d, 0, a)'\n        >>> module = ast.parse(fun)\n        >>> result = pm.gather(Aliases, module)\n        >>> Aliases.dump(result, filter=ast.Call)\n        __builtin__.dict.setdefault(d, 0, a) => ['<unbound-value>', 'a']\n\n        Note that complex cases can arise, when one of the formal parameter\n        is already known to alias to various values:\n\n        >>> fun = \"\"\"\n        ... def f(a, b): return a and b\n        ... def foo(A, B, C, D): return f(A or B, C or D)\"\"\"\n        >>> module = ast.parse(fun)\n        >>> result = pm.gather(Aliases, module)\n        >>> Aliases.dump(result, filter=ast.Call)\n        f((A or B), (C or D)) => ['A', 'B', 'C', 'D']\n        '''\n        self.generic_visit(node)\n        f = node.func\n        # special handler for bind functions\n        if isinstance(f, ast.Attribute) and f.attr == \"partial\":\n            return self.add(node, {node})\n        else:\n            return_alias = self.call_return_alias(node)\n            # expand collected aliases\n            all_aliases = set()\n            for value in return_alias:\n                # no translation\n                if isinstance(value, (ContainerOf, ast.FunctionDef,\n                                      Intrinsic)):\n                    all_aliases.add(value)\n                elif value in self.result:\n                    all_aliases.update(self.result[value])\n                else:\n                    try:\n                        ap = Aliases.access_path(value)\n                        all_aliases.update(self.aliases.get(ap, ()))\n                    except NotImplementedError:\n                        # should we do something better here?\n                        all_aliases.add(value)\n            return self.add(node, all_aliases)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef visit_Subscript(self, node):\n        '''\n        Resulting node alias stores the subscript relationship if we don't know\n        anything about the subscripted node.\n\n        >>> from pythran import passmanager\n        >>> pm = passmanager.PassManager('demo')\n        >>> module = ast.parse('def foo(a): return a[0]')\n        >>> result = pm.gather(Aliases, module)\n        >>> Aliases.dump(result, filter=ast.Subscript)\n        a[0] => ['a[0]']\n\n        If we know something about the container, e.g. in case of a list, we\n        can use this information to get more accurate informations:\n\n        >>> module = ast.parse('def foo(a, b, c): return [a, b][c]')\n        >>> result = pm.gather(Aliases, module)\n        >>> Aliases.dump(result, filter=ast.Subscript)\n        [a, b][c] => ['a', 'b']\n\n        Moreover, in case of a tuple indexed by a constant value, we can\n        further refine the aliasing information:\n\n        >>> fun = \"\"\"\n        ... def f(a, b): return a, b\n        ... def foo(a, b): return f(a, b)[0]\"\"\"\n        >>> module = ast.parse(fun)\n        >>> result = pm.gather(Aliases, module)\n        >>> Aliases.dump(result, filter=ast.Subscript)\n        f(a, b)[0] => ['a']\n\n        Nothing is done for slices, even if the indices are known :-/\n\n        >>> module = ast.parse('def foo(a, b, c): return [a, b, c][1:]')\n        >>> result = pm.gather(Aliases, module)\n        >>> Aliases.dump(result, filter=ast.Subscript)\n        [a, b, c][1:] => ['<unbound-value>']\n        '''\n        if isinstance(node.slice, ast.Index):\n            aliases = set()\n            self.visit(node.slice)\n            value_aliases = self.visit(node.value)\n            for alias in value_aliases:\n                if isinstance(alias, ContainerOf):\n                    if isinstance(node.slice.value, ast.Slice):\n                        continue\n                    if isinstance(node.slice.value, ast.Num):\n                        if node.slice.value.n != alias.index:\n                            continue\n                    # FIXME: what if the index is a slice variable...\n                    aliases.add(alias.containee)\n                elif isinstance(getattr(alias, 'ctx', None), ast.Param):\n                    aliases.add(ast.Subscript(alias, node.slice, node.ctx))\n        else:\n            # could be enhanced through better handling of containers\n            aliases = None\n            self.generic_visit(node)\n        return self.add(node, aliases)", "response": "Visit the subscripted node and store the result in the aliasing table."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nvisits the function definition node and add aliasing values for the current function.", "response": "def visit_FunctionDef(self, node):\n        '''\n        Initialise aliasing default value before visiting.\n\n        Add aliasing values for :\n            - Pythonic\n            - globals declarations\n            - current function arguments\n        '''\n        self.aliases = IntrinsicAliases.copy()\n\n        self.aliases.update((f.name, {f})\n                            for f in self.global_declarations.values())\n\n        self.aliases.update((arg.id, {arg})\n                            for arg in node.args.args)\n\n        self.generic_visit(node)\n        if Aliases.RetId in self.aliases:\n            # parametrize the expression\n            def parametrize(exp):\n                # constant(?) or global -> no change\n                if isinstance(exp, (ast.Index, Intrinsic, ast.FunctionDef)):\n                    return lambda _: {exp}\n                elif isinstance(exp, ContainerOf):\n                    pcontainee = parametrize(exp.containee)\n                    index = exp.index\n                    return lambda args: {\n                        ContainerOf(pc, index)\n                        for pc in pcontainee(args)\n                    }\n                elif isinstance(exp, ast.Name):\n                    try:\n                        w = node.args.args.index(exp)\n\n                        def return_alias(args):\n                            if w < len(args):\n                                return {args[w]}\n                            else:\n                                return {node.args.defaults[w - len(args)]}\n                        return return_alias\n                    except ValueError:\n                        return lambda _: self.get_unbound_value_set()\n                elif isinstance(exp, ast.Subscript):\n                    values = parametrize(exp.value)\n                    slices = parametrize(exp.slice)\n                    return lambda args: {\n                        ast.Subscript(value, slice, ast.Load())\n                        for value in values(args)\n                        for slice in slices(args)}\n                else:\n                    return lambda _: self.get_unbound_value_set()\n\n            # this is a little tricky: for each returned alias,\n            # parametrize builds a function that, given a list of args,\n            # returns the alias\n            # then as we may have multiple returned alias, we compute the union\n            # of these returned aliases\n            return_aliases = [parametrize(ret_alias)\n                              for ret_alias\n                              in self.aliases[Aliases.RetId]]\n\n            def merge_return_aliases(args):\n                merged_return_aliases = set()\n                for return_alias in return_aliases:\n                    merged_return_aliases.update(return_alias(args))\n                return merged_return_aliases\n\n            node.return_alias = merge_return_aliases"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef visit_For(self, node):\n        '''\n        For loop creates aliasing between the target\n        and the content of the iterator\n\n        >>> from pythran import passmanager\n        >>> pm = passmanager.PassManager('demo')\n        >>> module = ast.parse(\"\"\"\n        ... def foo(a):\n        ...     for i in a:\n        ...         {i}\"\"\")\n        >>> result = pm.gather(Aliases, module)\n        >>> Aliases.dump(result, filter=ast.Set)\n        {i} => ['|i|']\n\n        Not very useful, unless we know something about the iterated container\n\n        >>> module = ast.parse(\"\"\"\n        ... def foo(a, b):\n        ...     for i in [a, b]:\n        ...         {i}\"\"\")\n        >>> result = pm.gather(Aliases, module)\n        >>> Aliases.dump(result, filter=ast.Set)\n        {i} => ['|a|', '|b|']\n        '''\n\n        iter_aliases = self.visit(node.iter)\n        if all(isinstance(x, ContainerOf) for x in iter_aliases):\n            target_aliases = set()\n            for iter_alias in iter_aliases:\n                target_aliases.add(iter_alias.containee)\n        else:\n            target_aliases = {node.target}\n\n        self.add(node.target, target_aliases)\n        self.aliases[node.target.id] = self.result[node.target]\n\n        self.generic_visit(node)\n        self.generic_visit(node)", "response": "Create aliasing between the target and the content of the iterator."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef visit_If(self, node):\n        '''\n        After an if statement, the values from both branches are merged,\n        potentially creating more aliasing:\n\n        >>> from pythran import passmanager\n        >>> pm = passmanager.PassManager('demo')\n        >>> fun = \"\"\"\n        ... def foo(a, b):\n        ...     if a: c=a\n        ...     else: c=b\n        ...     return {c}\"\"\"\n        >>> module = ast.parse(fun)\n        >>> result = pm.gather(Aliases, module)\n        >>> Aliases.dump(result, filter=ast.Set)\n        {c} => ['|a|', '|b|']\n        '''\n\n        md.visit(self, node)\n        self.visit(node.test)\n        true_aliases = false_aliases = None\n\n        # first try the true branch\n        try:\n            tmp = self.aliases.copy()\n            for stmt in node.body:\n                self.visit(stmt)\n            true_aliases = self.aliases\n            self.aliases = tmp\n        except PythranSyntaxError:\n            pass\n\n        # then try the false branch\n        try:\n            for stmt in node.orelse:\n                self.visit(stmt)\n            false_aliases = self.aliases\n        except PythranSyntaxError:\n            pass\n\n        if true_aliases and not false_aliases:\n            self.aliases = true_aliases\n            try:\n                for stmt in node.orelse:\n                    self.visit(stmt)\n                false_aliases = self.aliases\n            except PythranSyntaxError:\n                pass\n\n        if false_aliases and not true_aliases:\n            self.aliases = false_aliases\n            try:\n                for stmt in node.body:\n                    self.visit(stmt)\n                true_aliases = self.aliases\n            except PythranSyntaxError:\n                pass\n\n        # merge the results from true and false branches\n        if false_aliases and true_aliases:\n            for k, v in true_aliases.items():\n                if k in self.aliases:\n                    self.aliases[k] = self.aliases[k].union(v)\n                else:\n                    assert isinstance(v, (frozenset, set))\n                    self.aliases[k] = v\n        elif true_aliases:\n            self.aliases = true_aliases", "response": "Visit the node and create the set of aliases that are used to associate the values of the two branches."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef prepare(self, node):\n        super(ArgumentReadOnce, self).prepare(node)\n        # global functions init\n        for n in self.global_declarations.values():\n            fe = ArgumentReadOnce.FunctionEffects(n)\n            self.node_to_functioneffect[n] = fe\n            self.result.add(fe)\n\n        # Pythonic functions init\n        def save_effect(module):\n            \"\"\" Recursively save read once effect for Pythonic functions. \"\"\"\n            for intr in module.values():\n                if isinstance(intr, dict):  # Submodule case\n                    save_effect(intr)\n                else:\n                    fe = ArgumentReadOnce.FunctionEffects(intr)\n                    self.node_to_functioneffect[intr] = fe\n                    self.result.add(fe)\n                    if isinstance(intr, intrinsic.Class):  # Class case\n                        save_effect(intr.fields)\n\n        for module in MODULES.values():\n            save_effect(module)", "response": "Prepare for the argument read once analysis."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a list of ~regions. Region objects to DS9 region string.", "response": "def ds9_objects_to_string(regions, coordsys='fk5', fmt='.6f', radunit='deg'):\n    \"\"\"\n    Converts a `list` of `~regions.Region` to DS9 region string.\n\n    Parameters\n    ----------\n    regions : `list`\n        List of `~regions.Region` objects\n    coordsys : `str`, optional\n        This overrides the coordinate system frame for all regions.\n        Default is 'fk5'.\n    fmt : `str`, optional\n        A python string format defining the output precision. Default is .6f,\n        which is accurate to 0.0036 arcseconds.\n    radunit : `str`, optional\n        This denotes the unit of the radius. Default is 'deg'(degrees)\n\n    Returns\n    -------\n    region_string : `str`\n        DS9 region string\n\n    Examples\n    --------\n    >>> from astropy import units as u\n    >>> from astropy.coordinates import SkyCoord\n    >>> from regions import CircleSkyRegion, ds9_objects_to_string\n    >>> reg_sky = CircleSkyRegion(SkyCoord(1 * u.deg, 2 * u.deg), 5 * u.deg)\n    >>> print(ds9_objects_to_string([reg_sky]))\n    # Region file format: DS9 astropy/regions\n    fk5\n    circle(1.000007,2.000002,5.000000)\n    \"\"\"\n    shapelist = to_shape_list(regions, coordsys)\n    return shapelist.to_ds9(coordsys, fmt, radunit)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwriting a list of ~regions. Region objects to DS9 string and write to file.", "response": "def write_ds9(regions, filename, coordsys='fk5', fmt='.6f', radunit='deg'):\n    \"\"\"\n    Converts a `list` of `~regions.Region` to DS9 string and write to file.\n\n    Parameters\n    ----------\n    regions : `list`\n        List of `regions.Region` objects\n    filename : `str`\n        Filename in which the string is to be written.\n    coordsys : `str`, optional #TODO\n        Coordinate system that overrides the coordinate frames of all regions.\n        Default is 'fk5'.\n    fmt : `str`, optional\n        A python string format defining the output precision. Default is .6f,\n        which is accurate to 0.0036 arcseconds.\n    radunit : `str`, optional\n        This denotes the unit of the radius. Default is deg (degrees)\n\n    Examples\n    --------\n    >>> from astropy import units as u\n    >>> from astropy.coordinates import SkyCoord\n    >>> from regions import CircleSkyRegion, write_ds9\n    >>> reg_sky = CircleSkyRegion(SkyCoord(1 * u.deg, 2 * u.deg), 5 * u.deg)\n    >>> write_ds9([reg_sky], 'test_write.reg')\n    >>> with open('test_write.reg') as f:\n    ...      print(f.read())\n    # Region file format: DS9 astropy/regions\n    fk5\n    circle(1.000007,2.000002,5.000000)\n    \"\"\"\n    output = ds9_objects_to_string(regions, coordsys, fmt, radunit)\n    with open(filename, 'w') as fh:\n        fh.write(output)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a list of ~regions. Region objects to a CRTF region string.", "response": "def crtf_objects_to_string(regions, coordsys='fk5', fmt='.6f', radunit='deg'):\n    \"\"\"\n    Converts a `list` of `~regions.Region` to CRTF region string.\n\n    Parameters\n    ----------\n    regions : `list`\n        List of `~regions.Region` objects\n    coordsys : `str`, optional\n        Astropy Coordinate system that overrides the coordinate system frame for\n        all regions. Default is 'fk5'.\n    fmt : `str`, optional\n        A python string format defining the output precision. Default is .6f,\n        which is accurate to 0.0036 arcseconds.\n    radunit : `str`, optional\n        This denotes the unit of the radius. Default is deg (degrees)\n\n    Returns\n    -------\n    region_string : `str`\n        CRTF region string\n\n    Examples\n    --------\n    >>> from astropy import units as u\n    >>> from astropy.coordinates import SkyCoord\n    >>> from regions import CircleSkyRegion, crtf_objects_to_string\n    >>> reg_sky = CircleSkyRegion(SkyCoord(1 * u.deg, 2 * u.deg), 5 * u.deg)\n    >>> print(crtf_objects_to_string([reg_sky]))\n    #CRTF\n    global coord=fk5\n    +circle[[1.000007deg, 2.000002deg], 5.000000deg]\n\n    \"\"\"\n\n    shapelist = to_shape_list(regions, coordsys)\n    return shapelist.to_crtf(coordsys, fmt, radunit)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write_crtf(regions, filename, coordsys='fk5', fmt='.6f', radunit='deg'):\n\n    output = crtf_objects_to_string(regions, coordsys, fmt, radunit)\n    with open(filename, 'w') as fh:\n        fh.write(output)", "response": "Writes a list of ~regions. Region objects to CRTF string and writes to file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bounding_box(self):\n        xmin = self.center.x - self.radius\n        xmax = self.center.x + self.radius\n        ymin = self.center.y - self.radius\n        ymax = self.center.y + self.radius\n\n        return BoundingBox.from_float(xmin, xmax, ymin, ymax)", "response": "Returns the bounding box of the current region."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef as_artist(self, origin=(0, 0), **kwargs):\n        from matplotlib.patches import Circle\n        xy = self.center.x - origin[0], self.center.y - origin[1]\n        radius = self.radius\n\n        mpl_params = self.mpl_properties_default('patch')\n        mpl_params.update(kwargs)\n\n        return Circle(xy=xy, radius=radius, **mpl_params)", "response": "Return a Matplotlib circle object for this region."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bounding_box(self):\n\n        w2 = self.width / 2.\n        h2 = self.height / 2.\n        cos_angle = np.cos(self.angle)    # self.angle is a Quantity\n        sin_angle = np.sin(self.angle)    # self.angle is a Quantity\n        dx1 = abs(w2 * cos_angle - h2 * sin_angle)\n        dy1 = abs(w2 * sin_angle + h2 * cos_angle)\n        dx2 = abs(w2 * cos_angle + h2 * sin_angle)\n        dy2 = abs(w2 * sin_angle - h2 * cos_angle)\n        dx = max(dx1, dx2)\n        dy = max(dy1, dy2)\n\n        xmin = self.center.x - dx\n        xmax = self.center.x + dx\n        ymin = self.center.y - dy\n        ymax = self.center.y + dy\n\n        return BoundingBox.from_float(xmin, xmax, ymin, ymax)", "response": "Returns the minimal bounding box that contains the exact rectangular region."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef as_artist(self, origin=(0, 0), **kwargs):\n        from matplotlib.patches import Rectangle\n        xy = self._lower_left_xy()\n        xy = xy[0] - origin[0], xy[1] - origin[1]\n        width = self.width\n        height = self.height\n        # From the docstring: MPL expects \"rotation in degrees (anti-clockwise)\"\n        angle = self.angle.to('deg').value\n\n        mpl_params = self.mpl_properties_default('patch')\n        mpl_params.update(kwargs)\n\n        return Rectangle(xy=xy, width=width, height=height,\n                         angle=angle, **mpl_params)", "response": "Return a Matplotlib circle object that represents this region."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the x y coordinates that define the corners", "response": "def corners(self):\n        \"\"\"\n        Return the x, y coordinate pairs that define the corners\n        \"\"\"\n\n        corners = [(-self.width/2, -self.height/2),\n                   ( self.width/2, -self.height/2),\n                   ( self.width/2,  self.height/2),\n                   (-self.width/2,  self.height/2),\n                  ]\n        rotmat = [[np.cos(self.angle), np.sin(self.angle)],\n                  [-np.sin(self.angle), np.cos(self.angle)]]\n\n        return np.dot(corners, rotmat) + np.array([self.center.x,\n                                                   self.center.y])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_polygon(self):\n        x,y = self.corners.T\n        vertices = PixCoord(x=x, y=y)\n        return PolygonPixelRegion(vertices=vertices, meta=self.meta,\n                                  visual=self.visual)", "response": "Return a 4 - cornered polygon equivalent to this rectangle."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _lower_left_xy(self):\n        hw = self.width / 2.\n        hh = self.height / 2.\n        sint = np.sin(self.angle)\n        cost = np.cos(self.angle)\n        dx = (hh * sint) - (hw * cost)\n        dy = -(hh * cost) - (hw * sint)\n        x = self.center.x + dx\n        y = self.center.y + dy\n        return x, y", "response": "Compute lower left xy position."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bounding_box(self):\n\n        # We use the solution described in http://stackoverflow.com/a/88020\n        # which is to use the parametric equation of an ellipse and to find\n        # when dx/dt or dy/dt=0.\n\n        cos_angle = np.cos(self.angle)\n        sin_angle = np.sin(self.angle)\n        tan_angle = np.tan(self.angle)\n\n        t1 = np.arctan(-self.height * tan_angle / self.width)\n        t2 = t1 + np.pi * u.rad\n\n        dx1 = 0.5 * self.width * cos_angle * np.cos(t1) - 0.5 * self.height * sin_angle * np.sin(t1)\n        dx2 = 0.5 * self.width * cos_angle * np.cos(t2) - 0.5 * self.height * sin_angle * np.sin(t2)\n\n        if dx1 > dx2:\n            dx1, dx2 = dx2, dx1\n\n        t1 = np.arctan(self.height / tan_angle / self.width)\n        t2 = t1 + np.pi * u.rad\n\n        dy1 = 0.5 * self.height * cos_angle * np.sin(t1) + 0.5 * self.width * sin_angle * np.cos(t1)\n        dy2 = 0.5 * self.height * cos_angle * np.sin(t2) + 0.5 * self.width * sin_angle * np.cos(t2)\n\n        if dy1 > dy2:\n            dy1, dy2 = dy2, dy1\n\n        xmin = self.center.x + dx1\n        xmax = self.center.x + dx2\n        ymin = self.center.y + dy1\n        ymax = self.center.y + dy2\n\n        return BoundingBox.from_float(xmin, xmax, ymin, ymax)", "response": "Returns the minimal bounding box that contains the exact elliptical region."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a Matplotlib ellipse object for this region.", "response": "def as_artist(self, origin=(0, 0), **kwargs):\n        \"\"\"\n        Matplotlib patch object for this region (`matplotlib.patches.Ellipse`).\n\n        Parameters:\n        -----------\n        origin : array_like, optional\n            The ``(x, y)`` pixel position of the origin of the displayed image.\n            Default is (0, 0).\n        kwargs : `dict`\n            All keywords that a `~matplotlib.patches.Ellipse` object accepts\n\n        Returns\n        -------\n        patch : `~matplotlib.patches.Ellipse`\n            Matplotlib ellipse patch\n\n        \"\"\"\n        from matplotlib.patches import Ellipse\n        xy = self.center.x - origin[0], self.center.y - origin[1]\n        width = self.width\n        height = self.height\n        # From the docstring: MPL expects \"rotation in degrees (anti-clockwise)\"\n        angle = self.angle.to('deg').value\n\n        mpl_params = self.mpl_properties_default('patch')\n        mpl_params.update(kwargs)\n\n        return Ellipse(xy=xy, width=width, height=height, angle=angle,\n                       **mpl_params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _make_annulus_path(patch_inner, patch_outer):\n\n        import matplotlib.path as mpath\n\n        path_inner = patch_inner.get_path()\n        transform_inner = patch_inner.get_transform()\n        path_inner = transform_inner.transform_path(path_inner)\n\n        path_outer = patch_outer.get_path()\n        transform_outer = patch_outer.get_transform()\n        path_outer = transform_outer.transform_path(path_outer)\n\n        verts_inner = path_inner.vertices[:-1][::-1]\n        verts_inner = np.concatenate((verts_inner, [verts_inner[-1]]))\n\n        verts = np.vstack((path_outer.vertices, verts_inner))\n        codes = np.hstack((path_outer.codes, path_inner.codes))\n\n        return mpath.Path(verts, codes)", "response": "Creates a matplotlib annulus path from two patches."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a Matplotlib patch object for this object.", "response": "def as_artist(self, origin=(0, 0), **kwargs):\n        \"\"\"\n        Matplotlib patch object for annulus region (`matplotlib.patches.PathPatch`).\n\n        Parameters\n        ----------\n        origin : array_like, optional\n            The ``(x, y)`` pixel position of the origin of the displayed image.\n            Default is (0, 0).\n        kwargs : `dict`\n            All keywords that a `~matplotlib.patches.PathPatch` object accepts\n\n        Returns\n        -------\n        patch : `~matplotlib.patches.PathPatch`\n            Matplotlib patch object\n        \"\"\"\n\n        if self.region1.center == self.region2.center and self.operator == op.xor:\n            import matplotlib.patches as mpatches\n\n            patch_inner = self.region1.as_artist(origin=origin)\n            patch_outer = self.region2.as_artist(origin=origin)\n            path = self._make_annulus_path(patch_inner, patch_outer)\n            patch = mpatches.PathPatch(path, **kwargs)\n            return patch\n        else:\n            raise NotImplementedError"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a Matplotlib Text object for this region.", "response": "def as_artist(self, origin=(0, 0), **kwargs):\n        \"\"\"\n        Matplotlib Text object for this region (`matplotlib.text.Text`).\n\n        Parameters\n        ----------\n        origin : array_like, optional\n            The ``(x, y)`` pixel position of the origin of the displayed image.\n            Default is (0, 0).\n        kwargs : `dict`\n            All keywords that a `~matplotlib.text.Text` object accepts\n\n        Returns\n        -------\n        text : `~matplotlib.text.Text`\n            Matplotlib Text object.\n        \"\"\"\n        from matplotlib.text import Text\n\n        mpl_params = self.mpl_properties_default('text')\n        mpl_params.update(kwargs)\n        text = Text(self.center.x - origin[0], self.center.y - origin[1],\n                    self.text, **mpl_params)\n\n        return text"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngiving a polygon with vertices defined by ( lon lat ) rotate the polygon so that the North pole is now at ( lon0 lat0 ).", "response": "def rotate_polygon(lon, lat, lon0, lat0):\n    \"\"\"\n    Given a polygon with vertices defined by (lon, lat), rotate the polygon\n    such that the North pole of the spherical coordinates is now at (lon0,\n    lat0). Therefore, to end up with a polygon centered on (lon0, lat0), the\n    polygon should initially be drawn around the North pole.\n    \"\"\"\n\n    # Create a representation object\n    polygon = UnitSphericalRepresentation(lon=lon, lat=lat)\n\n    # Determine rotation matrix to make it so that the circle is centered\n    # on the correct longitude/latitude.\n    m1 = rotation_matrix(-(0.5 * np.pi * u.radian - lat0), axis='y')\n    m2 = rotation_matrix(-lon0, axis='z')\n    transform_matrix = m2 * m1\n\n    # Apply 3D rotation\n    polygon = polygon.to_cartesian()\n    polygon = polygon.transform(transform_matrix)\n    polygon = UnitSphericalRepresentation.from_cartesian(polygon)\n\n    return polygon.lon, polygon.lat"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef as_artist(self, origin=(0, 0), **kwargs):\n\n        from matplotlib.lines import Line2D\n\n        mpl_params = self.mpl_properties_default('LINE2D')\n        mpl_params.update(kwargs)\n\n        point = Line2D([self.center.x - origin[0]], [self.center.y - origin[1]],\n                       **mpl_params)\n\n        return point", "response": "Return a Matplotlib Line2D object for this region."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_fits_region(filename, errors='strict'):\n    regions = []\n\n    hdul = fits.open(filename)\n\n    for hdu in hdul:\n        if hdu.name == 'REGION':\n            table = Table.read(hdu)\n            wcs = WCS(hdu.header, keysel=['image', 'binary', 'pixel'])\n            regions_list = FITSRegionParser(table, errors).shapes.to_regions()\n            for reg in regions_list:\n                regions.append(reg.to_sky(wcs))\n\n    return regions", "response": "Reads a FITS region file and scans for any fits regions table and converts them into a list of SkyRegion objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a list of regions into a list of shapes.", "response": "def to_shape_list(region_list, coordinate_system='fk5'):\n    \"\"\"\n    Converts a list of regions into a `regions.ShapeList` object.\n\n    Parameters\n    ----------\n    region_list: python list\n        Lists of `regions.Region` objects\n    format_type: str ('DS9' or 'CRTF')\n        The format type of the Shape object. Default is 'DS9'.\n    coordinate_system: str\n        The astropy coordinate system frame in which all the coordinates present\n        in the `region_list` will be converted. Default is 'fk5'.\n\n    Returns\n    -------\n    shape_list: `regions.ShapeList` object\n        list of `regions.Shape` objects.\n    \"\"\"\n\n    shape_list = ShapeList()\n\n    for region in region_list:\n\n        coord = []\n        if isinstance(region, SkyRegion):\n            reg_type = region.__class__.__name__[:-9].lower()\n        else:\n            reg_type = region.__class__.__name__[:-11].lower()\n\n        for val in regions_attributes[reg_type]:\n            coord.append(getattr(region, val))\n\n        if reg_type == 'polygon':\n            coord = [x for x in region.vertices]\n\n        if coordinate_system:\n            coordsys = coordinate_system\n        else:\n            if isinstance(region, SkyRegion):\n                coordsys = coord[0].name\n            else:\n                coordsys = 'image'\n\n        frame = coordinates.frame_transform_graph.lookup_name(coordsys)\n\n        new_coord = []\n        for val in coord:\n            if isinstance(val, Angle) or isinstance(val, u.Quantity) or isinstance(val, numbers.Number):\n                new_coord.append(val)\n            elif isinstance(val, PixCoord):\n                new_coord.append(u.Quantity(val.x, u.dimensionless_unscaled))\n                new_coord.append(u.Quantity(val.y, u.dimensionless_unscaled))\n            else:\n                new_coord.append(Angle(val.transform_to(frame).spherical.lon))\n                new_coord.append(Angle(val.transform_to(frame).spherical.lat))\n\n        meta = dict(region.meta)\n        meta.update(region.visual)\n\n        if reg_type == 'text':\n            meta['text'] = meta.get('text', meta.pop('label', ''))\n\n        include = region.meta.pop('include', True)\n\n        shape_list.append(Shape(coordsys, reg_type, new_coord, meta, False,\n                                include))\n\n    return shape_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the meta data DS9 compatible by filtering and mapping the valid keys in DS9.", "response": "def to_ds9_meta(shape_meta):\n    \"\"\"\n    Makes the meta data DS9 compatible by filtering and mapping the valid keys\n\n    Parameters\n    ----------\n    shape_meta: dict\n        meta attribute of a `regions.Shape` object\n\n    Returns\n    -------\n    meta : dict\n        DS9 compatible meta dictionary\n    \"\"\"\n\n    # meta keys allowed in DS9.\n    valid_keys = ['symbol', 'include', 'tag', 'line', 'comment',\n                  'name', 'select', 'highlite', 'fixed', 'label', 'text',\n                  'edit', 'move', 'rotate', 'delete', 'source', 'background']\n\n    # visual keys allowed in DS9\n    valid_keys += ['color', 'dash', 'linewidth', 'font', 'dashlist',\n                   'fill', 'textangle', 'symsize']\n\n    # mapped to actual names in DS9\n    key_mappings = {'symbol': 'point', 'linewidth': 'width', 'label': 'text'}\n\n    meta = _to_io_meta(shape_meta, valid_keys, key_mappings)\n\n    if 'font' in meta:\n        meta['font'] += \" {0} {1} {2}\".format(shape_meta.get('fontsize', 12),\n                                              shape_meta.get('fontstyle', 'normal'),\n                                              shape_meta.get('fontweight', 'roman'))\n\n    return meta"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_crtf(self,  coordsys='fk5', fmt='.6f', radunit='deg'):\n\n        crtf_strings = {\n            'circle': '{0}circle[[{1:FMT}deg, {2:FMT}deg], {3:FMT}RAD]',\n            'circleannulus': '{0}annulus[[{1:FMT}deg, {2:FMT}deg], [{3:FMT}RAD, {4:FMT}RAD]]',\n            'ellipse': '{0}ellipse[[{1:FMT}deg, {2:FMT}deg], [{3:FMT}RAD, {4:FMT}RAD], {5:FMT}deg]',\n            'rectangle': '{0}rotbox[[{1:FMT}deg, {2:FMT}deg], [{3:FMT}RAD, {4:FMT}RAD], {5:FMT}deg]',\n            'polygon': '{0}poly[{1}]',\n            'point': '{0}point[[{1:FMT}deg, {2:FMT}deg]]',\n            'symbol': '{0}symbol[[{1:FMT}deg, {2:FMT}deg], {symbol}]',\n            'text': '{0}text[[{1:FMT}deg, {2:FMT}deg], \\'{text}\\']',\n            'line': '{0}line[[{1:FMT}deg, {2:FMT}deg], [{3:FMT}deg, {4:FMT}deg]]'\n                        }\n\n        output = '#CRTF\\n'\n\n        if radunit == 'arcsec':\n            # what's this for?\n            if coordsys in coordsys_mapping['CRTF'].values():\n                radunitstr = '\"'\n            else:\n                raise ValueError(\n                    'Radius unit arcsec not valid for coordsys {}'.format(\n                        coordsys))\n        else:\n            radunitstr = radunit\n\n        for key, val in crtf_strings.items():\n            crtf_strings[key] = val.replace(\"FMT\", fmt).replace(\"RAD\",\n                                                                radunitstr)\n\n        # CASA does not support global coordinate specification, even though the\n        # documentation for the specification explicitly states that it does.\n        # output += 'global coord={}\\n'.format(coordsys)\n\n        for shape in self:\n\n            shape.check_crtf()\n            shape.meta = to_crtf_meta(shape.meta)\n\n            # if unspecified, include is True.\n            # Despite the specification, CASA does *not* support a preceding\n            # \"+\".  If you want a region included, leave the opening character\n            # blank.\n            include = \"-\" if shape.include in (False, '-') else \"\"\n            include += \"ann \" if shape.meta.get('type', 'reg') == 'ann' else \"\"\n\n            if shape.meta.get('label', \"\") != \"\":\n                shape.meta['label'] = \"'{}'\".format(shape.meta['label'])\n            meta_str = \", \".join(\"{0}={1}\".format(key, val) for key, val in\n                                shape.meta.items() if\n                                key not in ('include', 'comment', 'symbol',\n                                            'coord', 'text', 'range', 'corr',\n                                            'type'))\n\n            # the first item should be the coordinates, since CASA cannot\n            # recognize a region without an inline coordinate specification\n            # It can be, but does not need to be, comma-separated at the start\n            meta_str = \"coord={0}, \".format(coordsys.upper()) + meta_str\n\n            if 'comment' in shape.meta:\n                meta_str += \", \" + shape.meta['comment']\n            if 'range' in shape.meta:\n                shape.meta['range'] = [str(str(x).replace(\" \", \"\")) for x in\n                                       shape.meta['range']]\n                meta_str += \", range={}\".format(shape.meta['range']).replace(\"'\", \"\")\n            if 'corr' in shape.meta:\n                meta_str += \", corr={}\".format(shape.meta['corr']).replace(\"'\", \"\")\n\n            coord = []\n            if coordsys not in ['image', 'physical']:\n                for val in shape.coord:\n                    if isinstance(val, Angle):\n                        coord.append(float(val.value))\n                    else:\n                        if radunit == '' or None:\n                            coord.append(float(val.value))\n                        else:\n                            coord.append(float(val.to(radunit).value))\n            else:\n                for val in shape.coord:\n                    if isinstance(val, u.Quantity):\n                        coord.append(float(val.value))\n                    else:\n                        coord.append(float(val))\n\n            if shape.region_type in ['ellipse', 'rectangle'] and len(shape.coord) % 2 == 1:\n                coord[-1] = float(shape.coord[-1].to('deg').value)\n\n            if shape.region_type == 'polygon':\n                val = '[{0:' + fmt + '}deg, {1:' + fmt + '}deg]'\n                temp = [val.format(x, y) for x, y in zip(coord[::2], coord[1::2])]\n                coord = \", \".join(temp)\n                line = crtf_strings['polygon'].format(include, coord)\n            elif shape.region_type == 'point':\n                if 'symbol' in shape.meta:\n                    line = crtf_strings['symbol'].format(include, *coord,\n                                                         symbol=shape.meta['symbol'])\n                else:\n                    line = crtf_strings['point'].format(include, *coord)\n            elif shape.region_type == 'ellipse':\n                coord[2:] = [x / 2 for x in coord[2:]]\n                if len(coord) % 2 == 1:\n                    coord[-1] *= 2\n                line = crtf_strings['ellipse'].format(include, *coord)\n            elif shape.region_type == 'text':\n                line = crtf_strings['text'].format(include, *coord, text=shape.meta['text'])\n            else:\n                line = crtf_strings[shape.region_type].format(include, *coord)\n\n            if meta_str.strip():\n                output += \"{0}, {1}\\n\".format(line, meta_str)\n            else:\n                output += \"{0}\\n\".format(line)\n\n        return output", "response": "Converts a list of regions. Shape objects to crtf region strings."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a list of regions. Shape objects to DS9 region strings.", "response": "def to_ds9(self, coordsys='fk5', fmt='.6f', radunit='deg'):\n        \"\"\"\n        Converts a list of ``regions.Shape`` objects to ds9 region strings.\n\n        Parameters\n        ----------\n        coordsys : str\n            This overrides the coordinate system frame for all regions.\n        fmt : str\n            A python string format defining the output precision.\n            Default is .6f, which is accurate to 0.0036 arcseconds.\n        radunit : str\n            This denotes the unit of the radius.\n\n        Returns\n        -------\n        region_string : str\n            ds9 region string\n\n        Examples\n        --------\n        TODO\n        \"\"\"\n        valid_symbols_reverse = {y: x for x, y in valid_symbols_ds9.items()}\n\n        ds9_strings = {\n            'circle': '{0}circle({1:FMT},{2:FMT},{3:FMT}RAD)',\n            'circleannulus': '{0}annulus({1:FMT},{2:FMT},{3:FMT}RAD,{4:FMT}RAD)',\n            'ellipse': '{0}ellipse({1:FMT},{2:FMT},{3:FMT}RAD,{4:FMT}RAD,{5:FMT})',\n            'rectangle': '{0}box({1:FMT},{2:FMT},{3:FMT}RAD,{4:FMT}RAD,{5:FMT})',\n            'polygon': '{0}polygon({1})',\n            'point': '{0}point({1:FMT},{2:FMT})',\n            'line': '{0}line({1:FMT},{2:FMT},{3:FMT},{4:FMT})',\n            'text': '{0}text({1:FMT},{2:FMT})'\n                      }\n\n        output = '# Region file format: DS9 astropy/regions\\n'\n\n        if radunit == 'arcsec':\n            # what's this for?\n            if coordsys in coordsys_mapping['DS9'].values():\n                radunitstr = '\"'\n            else:\n                raise ValueError('Radius unit arcsec not valid for coordsys {}'.format(coordsys))\n        else:\n            radunitstr = ''\n\n        for key, val in ds9_strings.items():\n            ds9_strings[key] = val.replace(\"FMT\", fmt).replace(\"RAD\", radunitstr)\n\n        output += '{}\\n'.format(coordsys)\n\n        for shape in self:\n\n            shape.check_ds9()\n            shape.meta = to_ds9_meta(shape.meta)\n\n            # if unspecified, include is True.\n            include = \"-\" if shape.include in (False, '-') else \"\"\n\n            if 'point' in shape.meta:\n                shape.meta['point'] = valid_symbols_reverse[shape.meta['point']]\n\n            if 'symsize' in shape.meta:\n                shape.meta['point'] += \" {}\".format(shape.meta.pop('symsize'))\n\n            meta_str = \" \".join(\"{0}={1}\".format(key, val) for key, val in\n                                shape.meta.items() if key not in ('include', 'tag', 'comment', 'font', 'text'))\n            if 'tag' in shape.meta:\n                meta_str += \" \" + \" \".join([\"tag={0}\".format(tag) for tag in shape.meta['tag']])\n            if 'font' in shape.meta:\n                meta_str += \" \" + 'font=\"{0}\"'.format(shape.meta['font'])\n            if shape.meta.get('text', '') != '':\n                meta_str += \" \" + 'text={' + shape.meta['text'] + '}'\n            if 'comment' in shape.meta:\n                meta_str += \" \" + shape.meta['comment']\n\n            coord = []\n\n            if coordsys not in ['image', 'physical']:\n                for val in shape.coord:\n                    if isinstance(val, Angle):\n                        coord.append(float(val.value))\n                    else:\n                        if radunit == '' or None:\n                            coord.append(float(val.value))\n                        else:\n                            coord.append(float(val.to(radunit).value))\n                if shape.region_type in ['ellipse', 'rectangle'] and len(shape.coord) % 2 == 1:\n                    coord[-1] = float(shape.coord[-1].to('deg').value)\n            else:\n                for val in shape.coord:\n                    if isinstance(val, u.Quantity):\n                        coord.append(float(val.value))\n                    else:\n                        coord.append(float(val))\n                if shape.region_type in ['polygon', 'line']:\n                    coord = [x+1 for x in coord]\n                else:\n                    coord[0] += 1\n                    coord[1] += 1\n\n            if shape.region_type == 'polygon':\n                val = \"{0:\" + fmt + \"}\"\n                temp = [val.format(x) for x in coord]\n                coord = \",\".join(temp)\n                line = ds9_strings['polygon'].format(include, coord)\n            elif shape.region_type == 'ellipse':\n                coord[2:] = [x / 2 for x in coord[2:]]\n                if len(coord) % 2 == 1:\n                    coord[-1] *= 2\n                line = ds9_strings['ellipse'].format(include, *coord)\n            else:\n                line = ds9_strings[shape.region_type].format(include, *coord)\n\n            if meta_str.strip():\n                output += \"{0} # {1}\\n\".format(line, meta_str)\n            else:\n                output += \"{0}\\n\".format(line)\n\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a ~regions. ShapeList to a ~astropy. table. Table object.", "response": "def to_fits(self):\n        \"\"\"\n        Converts a `~regions.ShapeList` to a `~astropy.table.Table` object.\n        \"\"\"\n\n        max_length_coord = 1\n        coord_x = []\n        coord_y = []\n        shapes = []\n        radius = []\n        rotangle_deg = []\n        components = []\n\n        reg_reverse_mapping = {value: key for key, value in\n                               reg_mapping['FITS_REGION'].items()}\n        reg_reverse_mapping['rectangle'] = 'ROTBOX'\n        reg_reverse_mapping['circleannulus'] = 'ANNULUS'\n        reg_reverse_mapping['ellipseannulus'] = 'ELLIPTANNULUS'\n\n        for num, shape in enumerate(self):\n            shapes.append(reg_reverse_mapping[shape.region_type])\n            if shape.region_type == 'polygon':\n                max_length_coord = max(len(shape.coord)/2, max_length_coord)\n                coord = [x.value for x in shape.coord]\n                coord_x.append(coord[::2])\n                coord_y.append(coord[1::2])\n                radius.append(0)\n                rotangle_deg.append(0)\n            else:\n                coord_x.append(shape.coord[0].value)\n                coord_y.append(shape.coord[1].value)\n                if shape.region_type in ['circle', 'circleannulus', 'point']:\n                    radius.append([float(val) for val in shape.coord[2:]])\n                    rotangle_deg.append(0)\n                else:\n                    radius.append([float(x) for x in shape.coord[2:-1]])\n                    rotangle_deg.append(shape.coord[-1].to('deg').value)\n\n            tag = shape.meta.get('tag', '')\n            if tag.isdigit():\n                components.append(int(tag))\n            else:\n                components.append(num + 1)\n\n        # padding every value with zeros at the end to make sure that all values\n        # in the column have same length.\n        for i in range(len(self)):\n            if np.isscalar(coord_x[i]):\n                coord_x[i] = np.array([coord_x[i]])\n            if np.isscalar(coord_y[i]):\n                coord_y[i] = np.array([coord_y[i]])\n            if np.isscalar(radius[i]):\n                radius[i] = np.array([radius[i]])\n\n            coord_x[i] = np.pad(coord_x[i], (0, int(max_length_coord - len(coord_x[i]))),\n                                'constant', constant_values=(0, 0))\n            coord_y[i] = np.pad(coord_y[i], (0, int(max_length_coord - len(coord_y[i]))),\n                                'constant', constant_values=(0, 0))\n            radius[i] = np.pad(radius[i], (0, 4 - len(radius[i])), 'constant',\n                               constant_values=(0, 0))\n\n        table = Table([coord_x, coord_y, shapes, radius, rotangle_deg, components],\n                       names=('X', 'Y', 'SHAPE', 'R', 'ROTANG', 'COMPONENT'))\n        table['X'].unit = 'pix'\n        table['Y'].unit = 'pix'\n        table['R'].unit = 'pix'\n        table['ROTANG'].unit = 'deg'\n\n        return table"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting coordinates in the list of coordinates and return a list of SkyCoord or PixCoord objects.", "response": "def convert_coords(self):\n        \"\"\"\n        Process list of coordinates\n\n        This mainly searches for tuple of coordinates in the coordinate list and\n        creates a SkyCoord or PixCoord object from them if appropriate for a\n        given region type. This involves again some coordinate transformation,\n        so this step could be moved to the parsing process\n        \"\"\"\n        if self.coordsys in ['image', 'physical']:\n            coords = self._convert_pix_coords()\n        else:\n            coords = self._convert_sky_coords()\n\n        if self.region_type == 'line':\n            coords = [coords[0][0], coords[0][1]]\n\n        if self.region_type == 'text':\n            coords.append(self.meta['text'])\n\n        return coords"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _convert_sky_coords(self):\n        parsed_angles = [(x, y)\n                         for x, y in zip(self.coord[:-1:2], self.coord[1::2])\n                         if (isinstance(x, coordinates.Angle) and isinstance(y, coordinates.Angle))\n                         ]\n        frame = coordinates.frame_transform_graph.lookup_name(self.coordsys)\n\n        lon, lat = zip(*parsed_angles)\n        if hasattr(lon, '__len__') and hasattr(lat, '__len__') and len(lon) == 1 and len(lat) == 1:\n            # force entries to be scalar if they are length-1\n            lon, lat = u.Quantity(lon[0]), u.Quantity(lat[0])\n        else:\n            # otherwise, they are vector quantities\n            lon, lat = u.Quantity(lon), u.Quantity(lat)\n        sphcoords = coordinates.UnitSphericalRepresentation(lon, lat)\n        coords = [SkyCoord(frame(sphcoords))]\n\n        if self.region_type != 'polygon':\n            coords += self.coord[len(coords * 2):]\n\n        return coords", "response": "Convert to sky coordinates"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _convert_pix_coords(self):\n        if self.region_type in ['polygon', 'line']:\n            # have to special-case polygon in the phys coord case\n            # b/c can't typecheck when iterating as in sky coord case\n            coords = [PixCoord(self.coord[0::2], self.coord[1::2])]\n        else:\n            temp = [_.value for _ in self.coord]\n            coord = PixCoord(temp[0], temp[1])\n            coords = [coord] + temp[2:]\n\n        # The angle remains as a quantity object.\n        # Modulus check makes sure that it works for ellipse/rectangle annulus\n        if self.region_type in ['ellipse', 'rectangle'] and len(coords) % 2 == 0:\n            coords[-1] = self.coord[-1]\n\n        return coords", "response": "Convert to pixel coordinates"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_region(self):\n\n        coords = self.convert_coords()\n        log.debug(coords)\n        viz_keywords = ['color', 'dash', 'dashlist', 'width', 'font', 'symsize',\n                        'symbol', 'symsize', 'fontsize', 'fontstyle', 'usetex',\n                        'labelpos', 'labeloff', 'linewidth', 'linestyle',\n                        'point', 'textangle', 'fontweight']\n\n        if isinstance(coords[0], SkyCoord):\n            reg = self.shape_to_sky_region[self.region_type](*coords)\n        elif isinstance(coords[0], PixCoord):\n            reg = self.shape_to_pixel_region[self.region_type](*coords)\n        else:\n            self._raise_error(\"No central coordinate\")\n\n        reg.visual = RegionVisual()\n        reg.meta = RegionMeta()\n\n        # both 'text' and 'label' should be set to the same value, where we\n        # default to the 'text' value since that is the one used by ds9 regions\n        label = self.meta.get('text',\n                              self.meta.get('label', \"\"))\n        if label != '':\n            reg.meta['label'] = label\n        for key in self.meta:\n            if key in viz_keywords:\n                reg.visual[key] = self.meta[key]\n            else:\n                reg.meta[key] = self.meta[key]\n        reg.meta['include'] = self.include\n        return reg", "response": "Converts the object to a region object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_crtf(self):\n        if self.region_type not in regions_attributes:\n            raise ValueError(\"'{0}' is not a valid region type in this package\"\n                             \"supported by CRTF\".format(self.region_type))\n\n        if self.coordsys not in valid_coordsys['CRTF']:\n            raise ValueError(\"'{0}' is not a valid coordinate reference frame in \"\n                             \"astropy supported by CRTF\".format(self.coordsys))", "response": "Checks for CRTF compatibility."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_ds9(self):\n        if self.region_type not in regions_attributes:\n            raise ValueError(\"'{0}' is not a valid region type in this package\"\n                             \"supported by DS9\".format(self.region_type))\n\n        if self.coordsys not in valid_coordsys['DS9']:\n            raise ValueError(\"'{0}' is not a valid coordinate reference frame \"\n                             \"in astropy supported by DS9\".format(self.coordsys))", "response": "Checks for DS9 compatibility."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _validate(self):\n        if self.region_type not in regions_attributes:\n            raise ValueError(\"'{0}' is not a valid region type in this package\"\n                             .format(self.region_type))\n\n        if self.coordsys not in valid_coordsys['DS9'] + valid_coordsys['CRTF']:\n            raise ValueError(\"'{0}' is not a valid coordinate reference frame \"\n                             \"in astropy\".format(self.coordsys))", "response": "Checks whether all the attributes of this object are valid."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread a CRTF file and returns a list of regions.", "response": "def read_crtf(filename, errors='strict'):\n    \"\"\"\n    Reads a CRTF region file and returns a list of region objects.\n\n    Parameters\n    ----------\n    filename : `str`\n        The file path\n    errors : ``warn``, ``ignore``, ``strict``, optional\n      The error handling scheme to use for handling parsing errors.\n      The default is 'strict', which will raise a `~regions.CRTFRegionParserError`.\n      ``warn`` will raise a `~regions.CRTFRegionParserWarning`, and ``ignore`` will do nothing\n      (i.e., be silent).\n\n    Returns\n    -------\n    regions : `list`\n        Python `list` of `~regions.Region` objects.\n\n    Examples\n    --------\n    >>> from regions import read_crtf\n    >>> from astropy.utils.data import get_pkg_data_filename\n    >>> file = get_pkg_data_filename('data/CRTFgeneral.crtf', package='regions.io.crtf.tests')\n    >>> regs = read_crtf(file, errors='warn')\n    >>> print(regs[0])\n    Region: CircleSkyRegion\n    center: <SkyCoord (FK4: equinox=B1950.000, obstime=B1950.000): (ra, dec) in deg\n    (273.1, -23.18333333)>\n    radius: 2.3 arcsec\n    >>> print(regs[0].meta)\n    {'frame': 'BARY', 'corr': ['I', 'Q'], 'include': True, 'type': 'ann'}\n    >>> print(regs[0].visual)\n    {'color': 'blue'}\n\n    \"\"\"\n    with open(filename) as fh:\n        if regex_begin.search(fh.readline()):\n            region_string = fh.read()\n            parser = CRTFParser(region_string, errors)\n            return parser.shapes.to_regions()\n        else:\n            raise CRTFRegionParserError('Every CRTF Region must start with \"#CRTF\" ')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_line(self, line):\n\n        # Skip blanks\n        if line == '':\n            return\n\n        # Skip comments\n        if regex_comment.search(line):\n            return\n\n        # Special case / header: parse global parameters into metadata\n        global_parameters = regex_global.search(line)\n        if global_parameters:\n            self.parse_global_meta(global_parameters.group('parameters'))\n            return\n\n        # Tries to check the validity of the line.\n        crtf_line = regex_line.search(line)\n        if crtf_line:\n            # Tries to parse the line.\n\n            # Finds info about the region.\n            region = regex_region.search(crtf_line.group('region'))\n            type_ = region.group('type') or 'reg'\n            include = region.group('include') or '+'\n            region_type = region.group('regiontype').lower()\n            if region_type in self.valid_definition:\n                helper = CRTFRegionParser(self.global_meta, include, type_, region_type,\n                                          *crtf_line.group('region', 'parameters'))\n                self.shapes.append(helper.shape)\n            else:\n                self._raise_error(\"Not a valid CRTF Region type: '{0}'.\".format(region_type))\n\n        else:\n            self._raise_error(\"Not a valid CRTF line: '{0}'.\".format(line))\n            return", "response": "Parses a single line of CRTF into a dictionary of metadata."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the line starting with global to extract all the valid meta key value pairs.", "response": "def parse_global_meta(self, global_meta_str):\n        \"\"\"\n        Parses the line starting with global to extract all the valid meta key/value pair.\n        \"\"\"\n\n        if global_meta_str:\n            global_meta_str = regex_meta.findall(global_meta_str + ',')\n        if global_meta_str:\n            for par in global_meta_str:\n                if par[0] is not '':\n                    val1 = par[0].lower()\n                    val2 = par[1]\n                else:\n                    val1 = par[2].lower()\n                    val2 = par[3]\n                val1 = val1.strip()\n                val2 = val2.strip()\n                if val1 in self.valid_global_keys :\n                    if val1 in ('range', 'corr', 'labeloff'):\n                        val2 = val2.split(\",\")\n                        val2 = [x.strip() for x in val2 if x]\n                    self.global_meta[val1] = val2\n                else:\n                    self._raise_error(\"'{0}' is not a valid global meta key\".format(val1))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the CRTF region string.", "response": "def parse(self):\n        \"\"\"\n        Starting point to parse the CRTF region string.\n        \"\"\"\n\n        self.convert_meta()\n        self.coordsys = self.meta.get('coord', 'image').lower()\n        self.set_coordsys()\n        self.convert_coordinates()\n        self.make_shape()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the astropy s coordinate system name for this object.", "response": "def set_coordsys(self):\n        \"\"\"\n        Mapping to astropy's coordinate system name\n\n        # TODO: needs expert attention (Most reference systems are not mapped)\n        \"\"\"\n        if self.coordsys.lower() in self.coordsys_mapping:\n            self.coordsys = self.coordsys_mapping[self.coordsys.lower()]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convert_coordinates(self):\n        coord_list_str = regex_coordinate.findall(self.reg_str) + regex_length.findall(self.reg_str)\n        coord_list = []\n\n        if self.region_type == 'poly':\n            if len(coord_list_str) < 4:\n                self._raise_error('Not in proper format: {} polygon should have > 4 coordinates'.format(self.reg_str))\n            if coord_list_str[0] != coord_list_str[-1]:\n                self._raise_error(\"Not in proper format: '{0}', \"\n                                  \"In polygon, the last and first coordinates should be same\".format(self.reg_str))\n        else:\n            if len(coord_list_str) != len(self.language_spec[self.region_type]):\n                self._raise_error(\"Not in proper format: '{0}', \"\n                                  \"Does not contain expected number of parameters for the region '{1}'\"\n                                  .format(self.reg_str, self.region_type))\n\n        for attr_spec, val_str in zip(self.language_spec[self.region_type], coord_list_str):\n\n            if attr_spec == 'c':\n                if len(val_str) == 2 and val_str[1] != '':\n                    coord_list.append(CoordinateParser.parse_coordinate(val_str[0]))\n                    coord_list.append(CoordinateParser.parse_coordinate(val_str[1]))\n                else:\n                    self._raise_error(\"Not in proper format: {0} should be a coordinate\".format(val_str))\n            if attr_spec == 'pl':\n                if len(val_str) == 2 and val_str[1] != '':\n                    coord_list.append(CoordinateParser.parse_angular_length_quantity(val_str[0]))\n                    coord_list.append(CoordinateParser.parse_angular_length_quantity(val_str[1]))\n                else:\n                    self._raise_error(\"Not in proper format: {0} should be a pair of length\".format(val_str))\n            if attr_spec == 'l':\n                if isinstance(val_str, six.string_types):\n                    coord_list.append(CoordinateParser.parse_angular_length_quantity(val_str))\n                else:\n                    self._raise_error(\"Not in proper format: {0} should be a single length\".format(val_str))\n            if attr_spec == 's':\n                if self.region_type == 'symbol':\n                    if val_str in valid_symbols:\n                        self.meta['symbol'] = val_str\n                    else:\n                        self._raise_error(\"Not in proper format: '{0}' should be a symbol\".format(val_str))\n                elif self.region_type == 'text':\n                    self.meta['text'] = val_str[1:-1]\n\n        self.coord = coord_list", "response": "Convert the coordinates string to an array of ~astropy. coordinates. Angle or ~astropy. units. quantity. Quantity objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef convert_meta(self):\n        if self.meta_str:\n            self.meta_str = regex_meta.findall(self.meta_str + ',')\n        if self.meta_str:\n            for par in self.meta_str:\n                if par[0] is not '':\n                    val1 = par[0]\n                    val2 = par[1]\n                else:\n                    val1 = par[2]\n                    val2 = par[3]\n                val1 = val1.strip()\n                val2 = val2.strip()\n                if val1 in CRTFParser.valid_global_keys or val1 == 'label':\n                    if val1 in ('range', 'corr', 'labeloff'):\n                        val2 = val2.split(',')\n                        val2 = [x.strip() for x in val2]\n                    self.meta[val1] = val2\n                else:\n                    self._raise_error(\"'{0}' is not a valid meta key\".format(val1))\n\n        self.meta['include'] = self.include != '-'\n        self.include = self.meta['include']\n\n        if 'range' in self.meta:\n            self.meta['range'] = [u.Quantity(x) for x in self.meta['range']]\n\n        self.meta['type'] = self.type_", "response": "Parses the meta_str and stores in meta attribute."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmakes shape object for the current region.", "response": "def make_shape(self):\n        \"\"\"\n        Make shape object\n        \"\"\"\n        if self.region_type == 'ellipse':\n            self.coord[2:] = [x * 2 for x in self.coord[2:]]\n            if len(self.coord) % 2 == 1:  # This checks if the angle is present.\n                self.coord[-1] /= 2\n\n        if self.region_type == 'box':\n            x = (self.coord[0] + self.coord[2]) / 2\n            y = (self.coord[1] + self.coord[3]) / 2\n            w = u.Quantity(self.coord[0] - self.coord[2])\n            h = u.Quantity(self.coord[1] - self.coord[3])\n            self.coord = [x, y, abs(w), abs(h)]\n\n        self.meta.pop('coord', None)\n\n        self.shape = Shape(coordsys=self.coordsys,\n                           region_type=reg_mapping['CRTF'][self.region_type],\n                           coord=self.coord,\n                           meta=self.meta,\n                           composite=False,\n                           include=self.include\n                           )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses a single coordinate representation into a u. Quantity or u. Angle object.", "response": "def parse_coordinate(string_rep):\n        \"\"\"\n        Parse a single coordinate\n        \"\"\"\n\n        # Any CRTF coordinate representation (sexagesimal or degrees)\n        if 'pix' in string_rep:\n            return u.Quantity(string_rep[:-3], u.dimensionless_unscaled)\n        if 'h' in string_rep or 'rad' in string_rep:\n            return coordinates.Angle(string_rep)\n        if len(string_rep.split('.')) >= 3:\n            string_rep = string_rep.replace('.', ':', 2)\n\n        return coordinates.Angle(string_rep, u.deg)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_angular_length_quantity(string_rep):\n        unit_mapping = {\n            'deg': u.deg,\n            'rad': u.rad,\n            'arcmin': u.arcmin,\n            'arcsec': u.arcsec,\n            'pix': u.dimensionless_unscaled,\n            '\"': u.arcsec,\n            \"'\": u.arcmin,\n        }\n        regex_str = re.compile(r'([0-9+,-.]*)(.*)')\n        str = regex_str.search(string_rep)\n        unit = str.group(2)\n        if unit:\n            if unit in unit_mapping:\n                return u.Quantity(str.group(1), unit=unit_mapping[unit])\n            return u.Quantity(str.group(1))\n        else:\n            raise CRTFRegionParserError('Units must be specified for {0} '.format(string_rep))", "response": "Parse a string that is a number and a unit return a u. Quantity"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fits_region_objects_to_table(regions):\n    for reg in regions:\n        if isinstance(reg, SkyRegion):\n            raise TypeError('Every region must be a pixel region'.format(reg))\n\n    shape_list = to_shape_list(regions, coordinate_system='image')\n    return shape_list.to_fits()", "response": "Converts list of regions to FITS region table."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write_fits_region(filename, regions, header=None):\n    output = fits_region_objects_to_table(regions)\n\n    bin_table = fits.BinTableHDU(data=output, header=header)\n    bin_table.writeto(filename)", "response": "Converts list of regions to FITS region table and write to a file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_example_dataset(data='simulated', config=None):\n    if data == 'simulated':\n        return ExampleDatasetSimulated(config=config)\n    elif data == 'fermi':\n        return ExampleDatasetFermi(config=config)\n    else:\n        raise ValueError('Invalid selection data: {}'.format(data))", "response": "Make an example dataset."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert ~astropy. table. Table to astropy. io. fits. BinTable.", "response": "def _table_to_bintable(table):\n    \"\"\"Convert `~astropy.table.Table` to `astropy.io.fits.BinTable`.\"\"\"\n    data = table.as_array()\n    header = fits.Header()\n    header.update(table.meta)\n    name = table.meta.pop('name', None)\n    return fits.BinTableHDU(data, header, name=name)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef wcs(self):\n        wcs = WCS(naxis=2)\n        wcs.wcs.crval = self.config['crval']\n        wcs.wcs.crpix = self.config['crpix']\n        wcs.wcs.cdelt = self.config['cdelt']\n        wcs.wcs.ctype = self.config['ctype']\n\n        return wcs", "response": "Return WCS object for this instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef hdu_list(self):\n        hdu_list = fits.HDUList()\n\n        hdu = _table_to_bintable(self.source_table)\n        hdu.name = 'sources'\n        hdu_list.append(hdu)\n\n        hdu = _table_to_bintable(self.event_table)\n        hdu.name = 'events'\n        hdu_list.append(hdu)\n\n        hdu = self.image\n        hdu.name = 'image'\n        hdu_list.append(hdu)\n\n        return hdu_list", "response": "A list of HDUs that are identical pieces collected together in a HDU list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef source_table(self):\n        table = Table()\n        table['GLON'] = np.array([0, 45, 45], dtype='float32')\n        table['GLAT'] = np.array([0, 0, 45], dtype='float32')\n        table['COUNTS'] = np.array([100, 100, 100], dtype='int32')\n        return table", "response": "Return a new source table with the keys GLON GLAT COUNTS"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef event_table(self):\n        # Create event list table for each source\n        tables = []\n        for source in self.source_table:\n            lon = source['GLON'] * np.ones(source['COUNTS'])\n            lat = source['GLAT'] * np.ones(source['COUNTS'])\n            coord = SkyCoord(lon, lat, unit='deg', frame='galactic')\n\n            # TODO: scatter positions assuming Gaussian PSF on the sky\n            # using SkyOffsetFrame.\n\n            table = Table()\n            table['GLON'] = lon\n            table['GLAT'] = lat\n            table['SOURCE_IDX'] = source.index\n\n            tables.append(table)\n\n        # Stack all tables together\n        table = table_vstack(tables)\n\n        return table", "response": "Return an event table for each source in the event list."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a source table.", "response": "def source_table(self):\n        \"\"\"Source table  (`~astropy.table.Table`).\n\n        Columns: GLON, GLAT, COUNTS\n        \"\"\"\n        url = 'https://github.com/gammapy/gammapy-extra/raw/master/datasets/fermi_2fhl/gll_psch_v08.fit.gz'\n        table = Table.read(url, hdu='2FHL Source Catalog')\n        table.rename_column('Npred', 'COUNTS')\n        table.keep_columns(['GLON', 'GLAT', 'COUNTS'])\n        table.meta.clear()\n        return table"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread a DS9 region file into a list of ~regions. Region objects.", "response": "def read_ds9(filename, errors='strict'):\n    \"\"\"\n    Read a DS9 region file in as a `list` of `~regions.Region` objects.\n\n    Parameters\n    ----------\n    filename : `str`\n        The file path\n    errors : ``warn``, ``ignore``, ``strict``, optional\n      The error handling scheme to use for handling parsing errors.\n      The default is 'strict', which will raise a `~regions.DS9RegionParserError`.\n      ``warn`` will raise a `~regions.DS9RegionParserWarning`, and\n      ``ignore`` will do nothing (i.e., be silent).\n\n    Returns\n    -------\n    regions : `list`\n        Python list of `~regions.Region` objects.\n\n    Examples\n    --------\n    >>> from regions import read_ds9\n    >>> from astropy.utils.data import get_pkg_data_filename\n    >>> file = get_pkg_data_filename('data/physical_reference.reg', package='regions.io.ds9.tests')\n    >>> regs = read_ds9(file, errors='warn')\n    >>> print(regs[0])\n    Region: CirclePixelRegion\n    center: PixCoord(x=330.0, y=1090.0)\n    radius: 40.0\n    >>> print(regs[0].meta)\n    {'label': 'Circle', 'select': '1', 'highlite': '1', 'fixed': '0', 'edit': '1', 'move': '1', 'delete': '1', 'source': '1', 'tag': ['{foo}', '{foo bar}'], 'include': True}\n    >>> print(regs[0].visual)\n    {'dashlist': '8 3', 'dash': '0', 'color': 'pink', 'linewidth': '3', 'font': 'times', 'fontsize': '10', 'fontstyle': 'normal', 'fontweight': 'roman'}\n\n    \"\"\"\n    with open(filename) as fh:\n        region_string = fh.read()\n\n    parser = DS9Parser(region_string, errors=errors)\n    return parser.shapes.to_regions()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse a single coordinate string into a u. Quantity object.", "response": "def parse_coordinate(string_rep, unit):\n        \"\"\"\n        Parse a single coordinate\n        \"\"\"\n        # explicit radian ('r') value\n        if string_rep[-1] == 'r':\n            return coordinates.Angle(string_rep[:-1], unit=u.rad)\n        # explicit image ('i') and physical ('p') pixels\n        elif string_rep[-1] in ['i', 'p']:\n            return u.Quantity(string_rep[:-1]) - 1\n        # Any ds9 coordinate representation (sexagesimal or degrees)\n        elif 'd' in string_rep or 'h' in string_rep:\n            return coordinates.Angle(string_rep)\n        elif unit is 'hour_or_deg':\n            if ':' in string_rep:\n                spl = tuple([float(x) for x in string_rep.split(\":\")])\n                return coordinates.Angle(spl, u.hourangle)\n            else:\n                ang = float(string_rep)\n                return coordinates.Angle(ang, u.deg)\n        elif unit.is_equivalent(u.deg):\n            # return coordinates.Angle(string_rep, unit=unit)\n            if ':' in string_rep:\n                ang = tuple([float(x) for x in string_rep.split(\":\")])\n            else:\n                ang = float(string_rep)\n            return coordinates.Angle(ang, u.deg)\n        elif unit.is_equivalent(u.dimensionless_unscaled):\n            return u.Quantity(float(string_rep), unit) - 1\n        else:\n            return u.Quantity(float(string_rep), unit)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse a string that is either a number or a unit and return a u. Quantity object.", "response": "def parse_angular_length_quantity(string_rep, unit=u.deg):\n        \"\"\"\n        Given a string that is either a number or a number and a unit, return a\n        Quantity of that string.  e.g.:\n\n            23.9 -> 23.9*u.deg\n            50\" -> 50*u.arcsec\n        \"\"\"\n        unit_mapping = {\n            '\"': u.arcsec,\n            \"'\": u.arcmin,\n            'd': u.deg,\n            'r': u.rad,\n            'i': u.dimensionless_unscaled,\n            'p': u.dimensionless_unscaled\n        }\n        has_unit = string_rep[-1] not in string.digits\n        if has_unit:\n            unit = unit_mapping[string_rep[-1]]\n            return u.Quantity(float(string_rep[:-1]), unit=unit)\n        else:\n            return u.Quantity(float(string_rep), unit=unit)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_coordsys(self, coordsys):\n        if coordsys in self.coordsys_mapping:\n            self.coordsys = self.coordsys_mapping[coordsys]\n        else:\n            self.coordsys = coordsys", "response": "Set the coordinatesys of the object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrun all steps in the global state", "response": "def run(self):\n        \"\"\"\n        Run all steps\n        \"\"\"\n        for line_ in self.region_string.split('\\n'):\n            for line in line_.split(\";\"):\n                self.parse_line(line)\n                log.debug('Global state: {}'.format(self))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_line(self, line):\n        log.debug('Parsing {}'.format(line))\n\n        # Skip blanks\n        if line == '':\n            return\n\n        # Skip comments\n        if line[0] == '#':\n            return\n\n        # Special case / header: parse global parameters into metadata\n        if line.lstrip()[:6] == 'global':\n            self.global_meta = self.parse_meta(line)\n            # global_meta can specify \"include=1\"; never seen other options\n            # used but presumably =0 means false\n            self.global_meta['include'] = (False if\n                                           self.global_meta.get('include') in\n                                           ('0', 'False', False) else True)\n            return\n\n        # Try to parse the line\n        region_type_search = regex_global.search(line)\n        if region_type_search:\n            include = region_type_search.groups()[0]\n            region_type = region_type_search.groups()[1]\n        else:\n            self._raise_error(\"No region type found for line '{0}'.\".format(line))\n            return\n\n        if region_type in self.coordinate_systems:\n            # Found coord system definition\n            self.set_coordsys(region_type)\n            return\n        if region_type not in DS9RegionParser.language_spec:\n            self._raise_error(\"Region type '{0}' was identified, but it is not one of \"\n                              \"the known region types.\".format(region_type))\n            return\n        else:\n            # Found region specification,\n            region_end = region_type_search.span()[1]\n            self.parse_region(include, region_type, region_end, line)", "response": "Parses one line into a dictionary of metadata and other information."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_meta(meta_str):\n        keys_vals = [(x, y) for x, _, y in regex_meta.findall(meta_str.strip())]\n        extra_text = regex_meta.split(meta_str.strip())[-1]\n        result = OrderedDict()\n        for key, val in keys_vals:\n            # regex can include trailing whitespace or inverted commas\n            # remove it\n            val = val.strip().strip(\"'\").strip('\"')\n            if key == 'text':\n                val = val.lstrip(\"{\").rstrip(\"}\")\n            if key in result:\n                if key == 'tag':\n                    result[key].append(val)\n                else:\n                    raise ValueError(\"Duplicate key {0} found\".format(key))\n            else:\n                if key == 'tag':\n                    result[key] = [val]\n                else:\n                    result[key] = val\n        if extra_text:\n            result['comment'] = extra_text\n\n        return result", "response": "Parses the metadata string and returns a dictionary containing the metadata for a single ds9 region."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_region(self, include, region_type, region_end, line):\n        if self.coordsys is None:\n            raise DS9RegionParserError(\"No coordinate system specified and a\"\n                                       \" region has been found.\")\n        else:\n            helper = DS9RegionParser(coordsys=self.coordsys,\n                                     include=include,\n                                     region_type=region_type,\n                                     region_end=region_end,\n                                     global_meta=self.global_meta,\n                                     line=line)\n            helper.parse()\n            self.shapes.append(helper.shape)", "response": "Extract a Shape from a region string"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse(self):\n        log.debug(self)\n\n        self.parse_composite()\n        self.split_line()\n        self.convert_coordinates()\n        self.convert_meta()\n        self.make_shape()\n        log.debug(self)", "response": "Parse the ISO - 8601 string into a set of attributes."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef split_line(self):\n        # coordinate of the # symbol or end of the line (-1) if not found\n        hash_or_end = self.line.find(\"#\")\n        temp = self.line[self.region_end:hash_or_end].strip(\" |\")\n        self.coord_str = regex_paren.sub(\"\", temp)\n\n        # don't want any meta_str if there is no metadata found\n        if hash_or_end >= 0:\n            self.meta_str = self.line[hash_or_end:]\n        else:\n            self.meta_str = \"\"", "response": "Split line into coordinates and meta string"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef convert_coordinates(self):\n        coord_list = []\n        # strip out \"null\" elements, i.e. ''.  It might be possible to eliminate\n        # these some other way, i.e. with regex directly, but I don't know how.\n        # We need to copy in order not to burn up the iterators\n        elements = [x for x in regex_splitter.split(self.coord_str) if x]\n        element_parsers = self.language_spec[self.region_type]\n        for ii, (element, element_parser) in enumerate(zip(elements,\n                                                           element_parsers)):\n            if element_parser is coordinate:\n                unit = self.coordinate_units[self.coordsys][ii % 2]\n                coord_list.append(element_parser(element, unit))\n            elif self.coordinate_units[self.coordsys][0] is u.dimensionless_unscaled:\n                    coord_list.append(element_parser(element, unit=u.dimensionless_unscaled))\n            else:\n                coord_list.append(element_parser(element))\n\n        if self.region_type in ['ellipse', 'box'] and len(coord_list) % 2 == 1:\n                coord_list[-1] = CoordinateParser.parse_angular_length_quantity(elements[len(coord_list)-1])\n\n        # Reset iterator for ellipse and annulus\n        # Note that this cannot be done with copy.deepcopy on python2\n        if self.region_type in ['ellipse', 'annulus']:\n            self.language_spec[self.region_type] = itertools.chain(\n                (coordinate, coordinate), itertools.cycle((radius,)))\n\n        self.coord = coord_list", "response": "Convert coordinate string to objects"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef convert_meta(self):\n        meta_ = DS9Parser.parse_meta(self.meta_str)\n        self.meta = copy.deepcopy(self.global_meta)\n        self.meta.update(meta_)\n        # the 'include' is not part of the metadata string;\n        # it is pre-parsed as part of the shape type and should always\n        # override the global one\n        self.include = self.meta.get('include', True) if self.include == '' else self.include != '-'\n        self.meta['include'] = self.include", "response": "Convert meta string to dict"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_shape(self):\n        # In DS9, ellipse can also represents an elliptical annulus\n        # For elliptical annulus angle is optional.\n        if self.region_type == 'ellipse':\n            self.coord[2:] = [x * 2 for x in self.coord[2:]]\n            if len(self.coord) % 2 == 1:  # This checks if angle is present\n                self.coord[-1] /= 2\n\n        if 'point' in self.meta:\n            point = self.meta['point'].split(\" \")\n            if len(point) > 1:\n                self.meta['symsize'] = point[1]\n            self.meta['point'] = valid_symbols_ds9[point[0]]\n\n        if 'font' in self.meta:\n            fonts = self.meta['font'].split(\" \")\n            keys = ['font', 'fontsize', 'fontstyle', 'fontweight']\n            for i, val in enumerate(fonts):\n                self.meta[keys[i]] = val\n\n        self.meta.pop('coord', None)\n\n        self.shape = Shape(coordsys=self.coordsys,\n                           region_type=reg_mapping['DS9'][self.region_type],\n                           coord=self.coord,\n                           meta=self.meta,\n                           composite=self.composite,\n                           include=self.include,\n                          )", "response": "Make shape object for the current object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _validate(val, name, expected='any'):\n        if not isinstance(val, PixCoord):\n            raise TypeError('{} must be a PixCoord'.format(name))\n\n        if expected == 'any':\n            pass\n        elif expected == 'scalar':\n            if not val.isscalar:\n                raise ValueError('{} must be a scalar PixCoord'.format(name))\n        elif expected == 'not scalar':\n            if val.isscalar:\n                raise ValueError('{} must be a non-scalar PixCoord'.format(name))\n        else:\n            raise ValueError('Invalid argument for `expected`: {}'.format(expected))\n\n        return val", "response": "Validate that a given object is an appropriate PixCoord."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_sky(self, wcs, origin=_DEFAULT_WCS_ORIGIN, mode=_DEFAULT_WCS_MODE):\n        return SkyCoord.from_pixel(\n            xp=self.x, yp=self.y, wcs=wcs,\n            origin=origin, mode=mode,\n        )", "response": "Convert this PixCoord to SkyCoord."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_sky(cls, skycoord, wcs, origin=_DEFAULT_WCS_ORIGIN, mode=_DEFAULT_WCS_MODE):\n        x, y = skycoord.to_pixel(wcs=wcs, origin=origin, mode=mode)\n        return cls(x=x, y=y)", "response": "Create a new image from a SkyCoord object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef separation(self, other):\n        dx = other.x - self.x\n        dy = other.y - self.y\n        return np.hypot(dx, dy)", "response": "This is the two - dimensional cartesian separation of this pixel coordinate to another pixel coordinate."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef as_artist(self, origin=(0, 0), **kwargs):\n        from matplotlib.patches import Polygon\n        xy = np.vstack([self.vertices.x - origin[0],\n                        self.vertices.y - origin[1]]).transpose()\n\n        mpl_params = self.mpl_properties_default('patch')\n        mpl_params.update(kwargs)\n\n        return Polygon(xy=xy, **mpl_params)", "response": "Returns a Matplotlib polygon object for this region."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef skycoord_to_pixel_scale_angle(skycoord, wcs, small_offset=1 * u.arcsec):\n\n    # Convert to pixel coordinates\n    x, y = skycoord_to_pixel(skycoord, wcs, mode=skycoord_to_pixel_mode)\n    pixcoord = PixCoord(x=x, y=y)\n\n    # We take a point directly 'above' (in latitude) the position requested\n    # and convert it to pixel coordinates, then we use that to figure out the\n    # scale and position angle of the coordinate system at the location of\n    # the points.\n\n    # Find the coordinates as a representation object\n    r_old = skycoord.represent_as('unitspherical')\n\n    # Add a a small perturbation in the latitude direction (since longitude\n    # is more difficult because it is not directly an angle).\n    dlat = small_offset\n    r_new = UnitSphericalRepresentation(r_old.lon, r_old.lat + dlat)\n    coords_offset = skycoord.realize_frame(r_new)\n\n    # Find pixel coordinates of offset coordinates\n    x_offset, y_offset = skycoord_to_pixel(coords_offset, wcs,\n                                           mode=skycoord_to_pixel_mode)\n\n    # Find vector\n    dx = x_offset - x\n    dy = y_offset - y\n\n    # Find the length of the vector\n    scale = np.hypot(dx, dy) / dlat.to('degree').value\n\n    # Find the position angle\n    angle = np.arctan2(dy, dx) * u.radian\n\n    return pixcoord, scale, angle", "response": "Convert a set of SkyCoord coordinates into pixel coordinates pixel scales and position angles."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking that the given quantity is an angular units.", "response": "def assert_angle(name, q):\n    \"\"\"\n    Check that ``q`` is an angular `~astropy.units.Quantity`.\n    \"\"\"\n    if isinstance(q, u.Quantity):\n        if q.unit.physical_type == 'angle':\n            pass\n        else:\n            raise ValueError(\"{0} should have angular units\".format(name))\n    else:\n        raise TypeError(\"{0} should be a Quantity instance\".format(name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _silence():\n\n    old_stdout = sys.stdout\n    old_stderr = sys.stderr\n    sys.stdout = _DummyFile()\n    sys.stderr = _DummyFile()\n    exception_occurred = False\n    try:\n        yield\n    except:\n        exception_occurred = True\n        # Go ahead and clean up so that exception handling can work normally\n        sys.stdout = old_stdout\n        sys.stderr = old_stderr\n        raise\n\n    if not exception_occurred:\n        sys.stdout = old_stdout\n        sys.stderr = old_stderr", "response": "A context manager that silences sys. stdout and sys. stderr."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a new astropy_helpers module that can be imported from PyPI.", "response": "def use_astropy_helpers(**kwargs):\n    \"\"\"\n    Ensure that the `astropy_helpers` module is available and is importable.\n    This supports automatic submodule initialization if astropy_helpers is\n    included in a project as a git submodule, or will download it from PyPI if\n    necessary.\n\n    Parameters\n    ----------\n\n    path : str or None, optional\n        A filesystem path relative to the root of the project's source code\n        that should be added to `sys.path` so that `astropy_helpers` can be\n        imported from that path.\n\n        If the path is a git submodule it will automatically be initialized\n        and/or updated.\n\n        The path may also be to a ``.tar.gz`` archive of the astropy_helpers\n        source distribution.  In this case the archive is automatically\n        unpacked and made temporarily available on `sys.path` as a ``.egg``\n        archive.\n\n        If `None` skip straight to downloading.\n\n    download_if_needed : bool, optional\n        If the provided filesystem path is not found an attempt will be made to\n        download astropy_helpers from PyPI.  It will then be made temporarily\n        available on `sys.path` as a ``.egg`` archive (using the\n        ``setup_requires`` feature of setuptools.  If the ``--offline`` option\n        is given at the command line the value of this argument is overridden\n        to `False`.\n\n    index_url : str, optional\n        If provided, use a different URL for the Python package index than the\n        main PyPI server.\n\n    use_git : bool, optional\n        If `False` no git commands will be used--this effectively disables\n        support for git submodules. If the ``--no-git`` option is given at the\n        command line the value of this argument is overridden to `False`.\n\n    auto_upgrade : bool, optional\n        By default, when installing a package from a non-development source\n        distribution ah_boostrap will try to automatically check for patch\n        releases to astropy-helpers on PyPI and use the patched version over\n        any bundled versions.  Setting this to `False` will disable that\n        functionality. If the ``--offline`` option is given at the command line\n        the value of this argument is overridden to `False`.\n\n    offline : bool, optional\n        If `False` disable all actions that require an internet connection,\n        including downloading packages from the package index and fetching\n        updates to any git submodule.  Defaults to `True`.\n    \"\"\"\n\n    global BOOTSTRAPPER\n\n    config = BOOTSTRAPPER.config\n    config.update(**kwargs)\n\n    # Create a new bootstrapper with the updated configuration and run it\n    BOOTSTRAPPER = _Bootstrapper(**config)\n    BOOTSTRAPPER.run()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef config(self):\n\n        return dict((optname, getattr(self, optname))\n                    for optname, _ in CFG_OPTIONS if hasattr(self, optname))", "response": "A dict containing the options that this _Bootstrapper was configured with."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the local directory distribution that is available on PyPI.", "response": "def get_local_directory_dist(self):\n        \"\"\"\n        Handle importing a vendored package from a subdirectory of the source\n        distribution.\n        \"\"\"\n\n        if not os.path.isdir(self.path):\n            return\n\n        log.info('Attempting to import astropy_helpers from {0} {1!r}'.format(\n                 'submodule' if self.is_submodule else 'directory',\n                 self.path))\n\n        dist = self._directory_import()\n\n        if dist is None:\n            log.warn(\n                'The requested path {0!r} for importing {1} does not '\n                'exist, or does not contain a copy of the {1} '\n                'package.'.format(self.path, PACKAGE_NAME))\n        elif self.auto_upgrade and not self.is_submodule:\n            # A version of astropy-helpers was found on the available path, but\n            # check to see if a bugfix release is available on PyPI\n            upgrade = self._do_upgrade(dist)\n            if upgrade is not None:\n                dist = upgrade\n\n        return dist"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the local file distribution for the current version of astropy - helpers.", "response": "def get_local_file_dist(self):\n        \"\"\"\n        Handle importing from a source archive; this also uses setup_requires\n        but points easy_install directly to the source archive.\n        \"\"\"\n\n        if not os.path.isfile(self.path):\n            return\n\n        log.info('Attempting to unpack and import astropy_helpers from '\n                 '{0!r}'.format(self.path))\n\n        try:\n            dist = self._do_download(find_links=[self.path])\n        except Exception as e:\n            if DEBUG:\n                raise\n\n            log.warn(\n                'Failed to import {0} from the specified archive {1!r}: '\n                '{2}'.format(PACKAGE_NAME, self.path, str(e)))\n            dist = None\n\n        if dist is not None and self.auto_upgrade:\n            # A version of astropy-helpers was found on the available path, but\n            # check to see if a bugfix release is available on PyPI\n            upgrade = self._do_upgrade(dist)\n            if upgrade is not None:\n                dist = upgrade\n\n        return dist"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nimport astropy_helpers from the given path and return the dist - info directory.", "response": "def _directory_import(self):\n        \"\"\"\n        Import astropy_helpers from the given path, which will be added to\n        sys.path.\n\n        Must return True if the import succeeded, and False otherwise.\n        \"\"\"\n\n        # Return True on success, False on failure but download is allowed, and\n        # otherwise raise SystemExit\n        path = os.path.abspath(self.path)\n\n        # Use an empty WorkingSet rather than the man\n        # pkg_resources.working_set, since on older versions of setuptools this\n        # will invoke a VersionConflict when trying to install an upgrade\n        ws = pkg_resources.WorkingSet([])\n        ws.add_entry(path)\n        dist = ws.by_key.get(DIST_NAME)\n\n        if dist is None:\n            # We didn't find an egg-info/dist-info in the given path, but if a\n            # setup.py exists we can generate it\n            setup_py = os.path.join(path, 'setup.py')\n            if os.path.isfile(setup_py):\n                # We use subprocess instead of run_setup from setuptools to\n                # avoid segmentation faults - see the following for more details:\n                # https://github.com/cython/cython/issues/2104\n                sp.check_output([sys.executable, 'setup.py', 'egg_info'], cwd=path)\n\n                for dist in pkg_resources.find_distributions(path, True):\n                    # There should be only one...\n                    return dist\n\n        return dist"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if the given path is a git submodule.", "response": "def _check_submodule(self):\n        \"\"\"\n        Check if the given path is a git submodule.\n\n        See the docstrings for ``_check_submodule_using_git`` and\n        ``_check_submodule_no_git`` for further details.\n        \"\"\"\n\n        if (self.path is None or\n                (os.path.exists(self.path) and not os.path.isdir(self.path))):\n            return False\n\n        if self.use_git:\n            return self._check_submodule_using_git()\n        else:\n            return self._check_submodule_no_git()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if the given path is a git submodule and if so attempt to initialize it if needed.", "response": "def _check_submodule_using_git(self):\n        \"\"\"\n        Check if the given path is a git submodule.  If so, attempt to initialize\n        and/or update the submodule if needed.\n\n        This function makes calls to the ``git`` command in subprocesses.  The\n        ``_check_submodule_no_git`` option uses pure Python to check if the given\n        path looks like a git submodule, but it cannot perform updates.\n        \"\"\"\n\n        cmd = ['git', 'submodule', 'status', '--', self.path]\n\n        try:\n            log.info('Running `{0}`; use the --no-git option to disable git '\n                     'commands'.format(' '.join(cmd)))\n            returncode, stdout, stderr = run_cmd(cmd)\n        except _CommandNotFound:\n            # The git command simply wasn't found; this is most likely the\n            # case on user systems that don't have git and are simply\n            # trying to install the package from PyPI or a source\n            # distribution.  Silently ignore this case and simply don't try\n            # to use submodules\n            return False\n\n        stderr = stderr.strip()\n\n        if returncode != 0 and stderr:\n            # Unfortunately the return code alone cannot be relied on, as\n            # earlier versions of git returned 0 even if the requested submodule\n            # does not exist\n\n            # This is a warning that occurs in perl (from running git submodule)\n            # which only occurs with a malformatted locale setting which can\n            # happen sometimes on OSX.  See again\n            # https://github.com/astropy/astropy/issues/2749\n            perl_warning = ('perl: warning: Falling back to the standard locale '\n                            '(\"C\").')\n            if not stderr.strip().endswith(perl_warning):\n                # Some other unknown error condition occurred\n                log.warn('git submodule command failed '\n                         'unexpectedly:\\n{0}'.format(stderr))\n                return False\n\n        # Output of `git submodule status` is as follows:\n        #\n        # 1: Status indicator: '-' for submodule is uninitialized, '+' if\n        # submodule is initialized but is not at the commit currently indicated\n        # in .gitmodules (and thus needs to be updated), or 'U' if the\n        # submodule is in an unstable state (i.e. has merge conflicts)\n        #\n        # 2. SHA-1 hash of the current commit of the submodule (we don't really\n        # need this information but it's useful for checking that the output is\n        # correct)\n        #\n        # 3. The output of `git describe` for the submodule's current commit\n        # hash (this includes for example what branches the commit is on) but\n        # only if the submodule is initialized.  We ignore this information for\n        # now\n        _git_submodule_status_re = re.compile(\n            r'^(?P<status>[+-U ])(?P<commit>[0-9a-f]{40}) '\n            r'(?P<submodule>\\S+)( .*)?$')\n\n        # The stdout should only contain one line--the status of the\n        # requested submodule\n        m = _git_submodule_status_re.match(stdout)\n        if m:\n            # Yes, the path *is* a git submodule\n            self._update_submodule(m.group('submodule'), m.group('status'))\n            return True\n        else:\n            log.warn(\n                'Unexpected output from `git submodule status`:\\n{0}\\n'\n                'Will attempt import from {1!r} regardless.'.format(\n                    stdout, self.path))\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nliking ``_check_submodule_using_git``, but simply parses the .gitmodules file to determine if the supplied path is a git submodule, and does not exec any subprocesses. This can only determine if a path is a submodule--it does not perform updates, etc. This function may need to be updated if the format of the .gitmodules file is changed between git versions.", "response": "def _check_submodule_no_git(self):\n        \"\"\"\n        Like ``_check_submodule_using_git``, but simply parses the .gitmodules file\n        to determine if the supplied path is a git submodule, and does not exec any\n        subprocesses.\n\n        This can only determine if a path is a submodule--it does not perform\n        updates, etc.  This function may need to be updated if the format of the\n        .gitmodules file is changed between git versions.\n        \"\"\"\n\n        gitmodules_path = os.path.abspath('.gitmodules')\n\n        if not os.path.isfile(gitmodules_path):\n            return False\n\n        # This is a minimal reader for gitconfig-style files.  It handles a few of\n        # the quirks that make gitconfig files incompatible with ConfigParser-style\n        # files, but does not support the full gitconfig syntax (just enough\n        # needed to read a .gitmodules file).\n        gitmodules_fileobj = io.StringIO()\n\n        # Must use io.open for cross-Python-compatible behavior wrt unicode\n        with io.open(gitmodules_path) as f:\n            for line in f:\n                # gitconfig files are more flexible with leading whitespace; just\n                # go ahead and remove it\n                line = line.lstrip()\n\n                # comments can start with either # or ;\n                if line and line[0] in (':', ';'):\n                    continue\n\n                gitmodules_fileobj.write(line)\n\n        gitmodules_fileobj.seek(0)\n\n        cfg = RawConfigParser()\n\n        try:\n            cfg.readfp(gitmodules_fileobj)\n        except Exception as exc:\n            log.warn('Malformatted .gitmodules file: {0}\\n'\n                     '{1} cannot be assumed to be a git submodule.'.format(\n                         exc, self.path))\n            return False\n\n        for section in cfg.sections():\n            if not cfg.has_option(section, 'path'):\n                continue\n\n            submodule_path = cfg.get(section, 'path').rstrip(os.sep)\n\n            if submodule_path == self.path.rstrip(os.sep):\n                return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef multidot_old(ten,mats):\n    '''\n    Implements tensor operation : tensor-times-matrices.\n    If last dimensions of ten represent multilinear operations of the type : [X1,...,Xk]->B[X1,...,Xk]\n    and mats contains matrices or vectors [A1,...Ak] the function returns an array representing operators :\n    [X1,...,Xk]->B[A1 X1,...,Ak Xk]\n    '''\n    resp = ten\n    n_d = ten.ndim\n    n_m = len(mats)\n    for i in range(n_m):\n        #resp = np.tensordot( resp, mats[i], (n_d-n_m+i-1,0) )\n        resp = np.tensordot( resp, mats[i], (n_d-n_m,0) )\n    return resp", "response": "This function is used to create a multidot operation for a single - dimensional tree tree."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sdot( U, V ):\n    '''\n    Computes the tensorproduct reducing last dimensoin of U with first dimension of V.\n    For matrices, it is equal to regular matrix product.\n    '''\n    nu = U.ndim\n    #nv = V.ndim\n    return np.tensordot( U, V, axes=(nu-1,0) )", "response": "Computes the tensorproduct of U and V."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef deprecated(func):\n    '''This is a decorator which can be used to mark functions\n    as deprecated. It will result in a warning being emitted\n    when the function is used.'''\n\n    import warnings\n\n    @functools.wraps(func)\n    def new_func(*args, **kwargs):\n        if is_python_3:\n            code = func.__code__\n        else:\n            code = func.func_code\n        warnings.warn_explicit(\n            \"Call to deprecated function {}.\".format(func.__name__),\n            category=Warning,\n            filename=code.co_filename,\n            lineno=code.co_firstlineno + 1\n        )\n        return func(*args, **kwargs)\n    return new_func", "response": "A decorator which marks functions\n    as deprecated. It will result in a warning being emitted\nAttributeNames when the function is used."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef decode_complementarity(comp, control):\n\n    '''\n    # comp can be either:\n    - None\n    - \"a<=expr\" where a is a controls\n    - \"expr<=a\" where a is a control\n    - \"expr1<=a<=expr2\"\n    '''\n\n    try:\n        res = regex.match(comp).groups()\n    except:\n        raise Exception(\"Unable to parse complementarity condition '{}'\".format(comp))\n    res = [r.strip() for r in res]\n    if res[1] != control:\n        msg = \"Complementarity condition '{}' incorrect. Expected {} instead of {}.\".format(comp, control, res[1])\n        raise Exception(msg)\n    return [res[0], res[2]]", "response": "Decode a complementarity condition into a sequence of two - element tuples."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef time_iteration(model, initial_guess=None, dprocess=None, with_complementarities=True,\n                        verbose=True, grid={},\n                        maxit=1000, inner_maxit=10, tol=1e-6, hook=None, details=False):\n\n    '''\n    Finds a global solution for ``model`` using backward time-iteration.\n\n    This algorithm iterates on the residuals of the arbitrage equations\n\n    Parameters\n    ----------\n    model : Model\n        model to be solved\n    verbose : boolean\n        if True, display iterations\n    initial_guess : decision rule\n        initial guess for the decision rule\n    dprocess : DiscretizedProcess (model.exogenous.discretize())\n        discretized process to be used\n    with_complementarities : boolean (True)\n        if False, complementarity conditions are ignored\n    grid: grid options\n        overload the values set in `options:grid` section\n    maxit: maximum number of iterations\n    inner_maxit: maximum number of iteration for inner solver\n    tol: tolerance criterium for successive approximations\n    hook: Callable\n        function to be called within each iteration, useful for debugging purposes\n\n\n    Returns\n    -------\n    decision rule :\n        approximated solution\n    '''\n\n    from dolo import dprint\n    def vprint(t):\n        if verbose:\n            print(t)\n\n    if dprocess is None:\n        dprocess = model.exogenous.discretize()\n\n    n_ms = dprocess.n_nodes() # number of exogenous states\n    n_mv = dprocess.n_inodes(0) # this assume number of integration nodes is constant\n\n    x0 = model.calibration['controls']\n    parms = model.calibration['parameters']\n    n_x = len(x0)\n    n_s = len(model.symbols['states'])\n\n    endo_grid = model.get_grid(**grid)\n\n    exo_grid = dprocess.grid\n\n    mdr = DecisionRule(exo_grid, endo_grid)\n\n    grid = mdr.endo_grid.nodes()\n    N = grid.shape[0]\n\n    controls_0 = numpy.zeros((n_ms, N, n_x))\n    if initial_guess is None:\n        controls_0[:, :, :] = x0[None,None,:]\n    else:\n        if isinstance(initial_guess, AlgoResult):\n            initial_guess = initial_guess.dr\n        try:\n            for i_m in range(n_ms):\n                controls_0[i_m, :, :] = initial_guess(i_m, grid)\n        except Exception:\n            for i_m in range(n_ms):\n                m = dprocess.node(i_m)\n                controls_0[i_m, :, :] = initial_guess(m, grid)\n\n    f = model.functions['arbitrage']\n    g = model.functions['transition']\n\n    if 'controls_lb' in model.functions and with_complementarities==True:\n        lb_fun = model.functions['controls_lb']\n        ub_fun = model.functions['controls_ub']\n        lb = numpy.zeros_like(controls_0)*numpy.nan\n        ub = numpy.zeros_like(controls_0)*numpy.nan\n        for i_m in range(n_ms):\n            m = dprocess.node(i_m)[None,:]\n            p = parms[None,:]\n            m = numpy.repeat(m, N, axis=0)\n            p = numpy.repeat(p, N, axis=0)\n\n            lb[i_m,:,:] = lb_fun(m, grid, p)\n            ub[i_m,:,:] = ub_fun(m, grid, p)\n\n    else:\n        with_complementarities = False\n\n    sh_c = controls_0.shape\n\n    controls_0 = controls_0.reshape( (-1,n_x) )\n\n    from dolo.numeric.optimize.newton import newton, SerialDifferentiableFunction\n    from dolo.numeric.optimize.ncpsolve import ncpsolve\n\n    err = 10\n    it = 0\n\n    if with_complementarities:\n        vprint(\"Solving WITH complementarities.\")\n        lb = lb.reshape((-1,n_x))\n        ub = ub.reshape((-1,n_x))\n\n\n    if verbose:\n        headline = '|{0:^4} | {1:10} | {2:8} | {3:8} | {4:3} |'.format( 'N',' Error', 'Gain','Time',  'nit' )\n        stars = '-'*len(headline)\n        print(stars)\n        print(headline)\n        print(stars)\n\n    import time\n    t1 = time.time()\n\n    err_0 = numpy.nan\n\n    verbit = (verbose == 'full')\n\n    while err>tol and it<maxit:\n\n        it += 1\n\n        t_start = time.time()\n\n        mdr.set_values(controls_0.reshape(sh_c))\n\n        fn = lambda x: residuals_simple(f, g, grid, x.reshape(sh_c), mdr, dprocess, parms).reshape((-1,n_x))\n        dfn = SerialDifferentiableFunction(fn)\n\n        res = fn(controls_0)\n\n        if hook:\n            hook()\n\n        if with_complementarities:\n            [controls,nit] = ncpsolve(dfn, lb, ub, controls_0, verbose=verbit, maxit=inner_maxit)\n        else:\n            [controls, nit] = newton(dfn, controls_0, verbose=verbit, maxit=inner_maxit)\n\n        err = abs(controls-controls_0).max()\n\n        err_SA = err/err_0\n        err_0 = err\n\n        controls_0 = controls\n\n        t_finish = time.time()\n        elapsed = t_finish - t_start\n\n        if verbose:\n            print('|{0:4} | {1:10.3e} | {2:8.3f} | {3:8.3f} | {4:3} |'.format( it, err, err_SA, elapsed, nit  ))\n\n    controls_0 = controls.reshape(sh_c)\n\n    t2 = time.time()\n\n    if verbose:\n        print(stars)\n        print(\"Elapsed: {} seconds.\".format(t2-t1))\n        print(stars)\n\n    if not details:\n        return mdr\n\n    return TimeIterationResult(\n        mdr,\n        it,\n        with_complementarities,\n        dprocess,\n        err<tol, # x_converged: bool\n        tol, # x_tol\n        err, #: float\n        None,  # log: object # TimeIterationLog\n        None   # trace: object #{Nothing,IterationTrace}\n    )", "response": "This function finds a global solution for a model using backward time - iteration."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating self. theta parameter. No returns values", "response": "def set_values(self,x):\n        \"\"\" Updates self.theta parameter. No returns values\"\"\"\n\n        x = numpy.atleast_2d(x)\n\n        x = x.real # ahem\n\n        C_inv = self.__C_inv__\n        theta = numpy.dot( x, C_inv )\n        self.theta = theta\n\n        return theta"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tauchen(N, mu, rho, sigma, m=2):\n    Z     = np.zeros((N,1))\n    Zprob = np.zeros((N,N))\n    a     = (1-rho)*mu\n\n    Z[-1]  = m * math.sqrt(sigma**2 / (1 - (rho**2)))\n    Z[0]  = -1 * Z[-1]\n    zstep = (Z[-1] - Z[0]) / (N - 1)\n\n    for i in range(1,N):\n        Z[i] = Z[0] + zstep * (i)\n\n    Z = Z + a / (1-rho)\n\n    for j in range(0,N):\n        for k in range(0,N):\n            if k == 0:\n                Zprob[j,k] = sp.stats.norm.cdf((Z[0] - a - rho * Z[j] + zstep / 2) / sigma)\n            elif k == (N-1):\n                Zprob[j,k] = 1 - sp.stats.norm.cdf((Z[-1] - a - rho * Z[j] - zstep / 2) / sigma)\n            else:\n                up = sp.stats.norm.cdf((Z[k] - a - rho * Z[j] + zstep / 2) / sigma)\n                down = sp.stats.norm.cdf( (Z[k] - a - rho * Z[j] - zstep / 2) / sigma)\n                Zprob[j,k] = up - down\n\n    return( (Z, Zprob) )", "response": "This function calculates the transition probabilities of an AR1 process by a finite markov chain using Tauchen s method."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\napproximate an AR1 process by a finite markov chain using Rouwenhorst s method.", "response": "def rouwenhorst(rho, sigma, N):\n    \"\"\"\n    Approximate an AR1 process by a finite markov chain using Rouwenhorst's method.\n\n    :param rho: autocorrelation of the AR1 process\n    :param sigma: conditional standard deviation of the AR1 process\n    :param N: number of states\n    :return [nodes, P]: equally spaced nodes and transition matrix\n    \"\"\"\n\n    from numpy import sqrt, linspace, array,zeros\n\n    sigma = float(sigma)\n\n    if N == 1:\n      nodes = array([0.0])\n      transitions = array([[1.0]])\n      return [nodes, transitions]\n\n    p = (rho+1)/2\n    q = p\n    nu = sqrt( (N-1)/(1-rho**2) )*sigma\n\n    nodes = linspace( -nu, nu, N)\n    sig_a = sigma\n    n = 1\n    #    mat0 = array( [[1]] )\n    mat0 = array([[p,1-p],[1-q,q]])\n    if N == 2:\n        return [nodes,mat0]\n    for n in range(3,N+1):\n        mat = zeros( (n,n) )\n        mat_A = mat.copy()\n        mat_B = mat.copy()\n        mat_C = mat.copy()\n        mat_D = mat.copy()\n        mat_A[:-1,:-1] = mat0\n        mat_B[:-1,1:] = mat0\n        mat_C[1:,:-1] = mat0\n        mat_D[1:,1:] = mat0\n\n        mat0 = p*mat_A + (1-p)*mat_B + (1-q)*mat_C + q*mat_D\n        mat0[1:-1,:] = mat0[1:-1,:]/2\n    P = mat0\n    return [nodes, P]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef multidimensional_discretization(rho, sigma, N=3, method='rouwenhorst', m=2):\n\n    # rho is assumed to be a scalar\n    # sigma is a positive symmetric matrix\n    # N number of points in each non-degenerate dimension\n    # m : standard deviations to approximate\n\n    import scipy.linalg\n    from itertools import product\n\n    d = sigma.shape[1]\n\n    sigma = sigma.copy()\n\n    zero_columns = np.where(sigma.sum(axis=0)==0)[0]\n    for i in zero_columns:\n        sigma[i,i] = 1\n\n    L = scipy.linalg.cholesky(sigma)\n\n    N = int(N)\n\n    if method=='tauchen':\n        [nodes_1d, probas_1d] = tauchen(N, 0, rho, 1, m=m)\n    elif method=='rouwenhorst':\n        [nodes_1d, probas_1d] = rouwenhorst(rho, 1, N)\n\n    markov_nodes = np.array( list( product( *([nodes_1d]*d))) ).T\n    markov_indices = np.array( list( product( *([range(N)]*d)  )  ) ).T\n\n    markov_nodes = np.dot(L, markov_nodes)\n\n\n    transition_matrix = 1\n    for i in range(d):\n        transition_matrix = np.kron(transition_matrix, probas_1d)\n\n    markov_nodes = np.ascontiguousarray(markov_nodes.T)\n\n    for i in zero_columns:\n        markov_nodes[:,i] = 0\n\n    return [markov_nodes, transition_matrix]", "response": "Discretizes an VAR into a markov chain."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes the product of two independent markov chains.", "response": "def tensor_markov( *args ):\n    \"\"\"Computes the product of two independent markov chains.\n\n    :param m1: a tuple containing the nodes and the transition matrix of the first chain\n    :param m2: a tuple containing the nodes and the transition matrix of the second chain\n    :return: a tuple containing the nodes and the transition matrix of the product chain\n    \"\"\"\n    if len(args) > 2:\n\n        m1 = args[0]\n        m2 = args[1]\n        tail = args[2:]\n        prod = tensor_markov(m1,m2)\n        return tensor_markov( prod, tail )\n\n    elif len(args) == 2:\n\n        m1,m2 = args\n        n1, t1 = m1\n        n2, t2 = m2\n\n        n1 = np.array(n1, dtype=float)\n        n2 = np.array(n2, dtype=float)\n        t1 = np.array(t1, dtype=float)\n        t2 = np.array(t2, dtype=float)\n\n        assert(n1.shape[0] == t1.shape[0] == t1.shape[1])\n        assert(n2.shape[0] == t2.shape[0] == t2.shape[1])\n\n        t = np.kron(t1, t2)\n\n        p = t1.shape[0]\n        q = t2.shape[0]\n\n        np.tile( n2, (1,p))\n        # n = np.row_stack([\n        #     np.repeat(n1, q, axis=1),\n        #     np.tile( n2, (1,p))\n        # ])\n        n = np.column_stack([\n            np.repeat(n1, q, axis=0),\n            np.tile( n2, (p,1))\n        ])\n        return [n,t]\n\n    else:\n        raise Exception(\"Incorrect number of arguments. Expected at least 2. Found {}.\".format(len(args)))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing the text of a modfile into a modfile structure", "response": "def parse_dynare_text(txt,add_model=True,full_output=False, debug=False):\n    '''\n    Imports the content of a modfile into the current interpreter scope\n    '''\n    # here we call \"instruction group\", a string finishing by a semicolon\n    # an \"instruction group\" can have several lines\n    # a line can be\n    # - a comment //...\n    # - an old-style tag //$...\n    # - a new-style tag [key1='value1',..]\n    # - macro-instruction @#...\n    # A Modfile contains several blocks (in this order) :\n    # - an initblock defining variables, exovariables, parameters, initialization\n    #   inside the initblock the order of declaration doesn't matter\n    # - a model block with two special lines (model; end;)\n    # - optional blocks (like endval, shocks)\n    #    seperated by free matlab instructions in any order;\n    # - all other instructions are ignored\n\n    otxt = txt\n    otxt = otxt.replace(\"\\r\\n\",\"\\n\")\n    otxt = otxt.replace(\"^\",\"**\")\n\n    # first, we remove end-of-line comments : they are definitely lost\n    regex = re.compile(\"(.+)//[^#](.*)\")\n    def remove_end_comment(line):\n        res = regex.search(line)\n        if res:\n            l = res.groups(1)[0]\n            return(l)\n        else:\n            return line\n    txt = str.join(\"\\n\",map(remove_end_comment,otxt.split(\"\\n\")))\n\n    name_regex = re.compile(\"//\\s*fname\\s*=\\s*'(.*)'\")\n    m = name_regex.search(txt)\n    if m:\n        fname = m.group(1)\n    else:\n        fname = None\n\n\n    instruction_groups = [Instruction_group(s) for s in txt.split(\";\")]\n\n    instructions = [ig.instruction for ig in instruction_groups]\n\n    if debug:\n        print('Elementary instructions')\n        for i in instruction_groups:\n            print(i)\n\n    try:\n        imodel = [re.compile('model(\\(.*\\)|)').match(e) is not None for e in instructions]\n        imodel = imodel.index(True)\n        #imodel = instructions.index(\"model\") #this doesn't work for \"MODEL\"\n        iend = instructions.index(\"end\")\n        model_block = instruction_groups[imodel:(iend+1)]\n        init_block = instruction_groups[0:imodel]\n    except:\n        raise Exception('Model block could not be found.')\n\n    next_instructions = instructions[(iend+1):]\n    next_instruction_groups = instruction_groups[(iend+1):]\n\n    if 'initval' in next_instructions:\n        iinitval = next_instructions.index('initval')\n        iend = next_instructions.index('end',iinitval)\n        matlab_block_1 = next_instruction_groups[0:iinitval]\n        initval_block = next_instruction_groups[iinitval:(iend+1)]\n        next_instruction_groups = next_instruction_groups[(iend+1):]\n        next_instructions = next_instructions[(iend+1):]\n    else:\n        initval_block = None\n        matlab_block_1 = None\n\n    if 'endval' in next_instructions:\n        iendval = next_instructions.index('endval')\n        iend = next_instructions.index('end',iendval)\n        matlab_block_2 = next_instruction_groups[0:iendval]\n        endval_block = next_instruction_groups[iendval:(iend+1)]\n        next_instruction_groups = next_instruction_groups[(iend+1):]\n        next_instructions = next_instructions[(iend+1):]\n    else:\n        endval_block = None\n        matlab_block_2 = None\n\n    # TODO : currently shocks block needs to follow initval, this restriction should be removed\n    if 'shocks' in next_instructions:\n        ishocks = next_instructions.index('shocks')\n        iend = next_instructions.index('end',ishocks)\n        matlab_block_3 = next_instruction_groups[0:ishocks]\n        shocks_block = next_instruction_groups[ishocks:(iend+1)]\n        next_instruction_groups = next_instruction_groups[(iend+1):]\n        next_instructions = next_instructions[(iend+1):]\n    else:\n        shocks_block = None\n        matlab_block_3 = None\n\n    try:\n        init_regex = re.compile(\"(parameters |var |varexo |)(.*)\")\n        var_names = []\n        varexo_names = []\n        parameters_names = []\n        declarations = {}\n        for ig in init_block:\n            if ig.instruction != '':\n                m = init_regex.match(ig.instruction)\n                if not m:\n                    raise Exception(\"Unexpected instruction in init block : \" + str(ig.instruction))\n                if m.group(1) == '':\n                    [lhs,rhs] = m.group(2).split(\"=\")\n                    lhs = lhs.strip()\n                    rhs = rhs.strip()\n                    declarations[lhs] = rhs\n                else:\n                    arg = m.group(2).replace(\",\",\" \")\n                    names = [vn.strip() for vn in arg.split()]\n                    if m.group(1).strip() == 'var':\n                        dest = var_names\n                    elif m.group(1).strip() == 'varexo':\n                        dest = varexo_names\n                    elif m.group(1).strip() == 'parameters':\n                        dest = parameters_names\n                    for n in names:\n                        if not n in dest:\n                            dest.append(n)\n                        else:\n                            raise Exception(\"symbol %s has already been defined\".format(n))\n    except Exception as e:\n        raise Exception('Init block could not be read : ' + str(e) )\n    # the following instruction set the variables \"variables\",\"shocks\",\"parameters\"\n\n\n    variables = []\n    for vn in var_names:\n        v = Variable(vn)\n        variables.append(v)\n\n    shocks = []\n    for vn in varexo_names:\n        s = Shock(vn)\n        shocks.append(s)\n\n    parameters = []\n    for vn in parameters_names:\n        p = Parameter(vn)\n        parameters.append(p)\n\n    parse_dict = dict()\n    for v in variables + shocks + parameters:\n        parse_dict[v.name] = v\n\n    special_symbols = [sympy.exp,sympy.log,sympy.sin,sympy.cos, sympy.atan, sympy.tan]\n    for s in special_symbols:\n        parse_dict[str(s)] = s\n    parse_dict['sqrt'] = sympy.sqrt\n\n\n    # Read parameters values\n    parameters_values = {}\n    for p in declarations:\n        try:\n            rhs = eval(declarations[p], parse_dict)\n        except Exception as e:\n            Exception(\"Impossible to evaluate parameter value : \" + str(e))\n        try:\n            lhs = eval(p,parse_dict)\n        except Exception as e:\n            # here we could declare p\n            raise e\n        parameters_values[lhs] = rhs\n\n\n    # Now we read the model block\n    model_tags = model_block[0].tags\n    equations = []\n    for ig in model_block[1:-1]:\n        if ig.instruction != '':\n            teq = ig.instruction.replace('^',\"**\")\n            if '=' in teq:\n                teqlhs,teqrhs = teq.split(\"=\")\n            else:\n                teqlhs = teq\n                teqrhs = '0'\n            eqlhs = eval(teqlhs, parse_dict)\n            eqrhs = eval(teqrhs, parse_dict)\n            eq = Equation(eqlhs,eqrhs)\n            eq.tags.update(ig.tags)\n    #        if eq.tags.has_key('name'):\n    #            eq.tags[] = ig.tags['name']\n            equations.append(eq)\n\n    # Now we read the initval block\n    init_values = {}\n    if initval_block != None:\n        for ig in initval_block[1:-1]:\n            if len(ig.instruction.strip()) >0:\n                try:\n                    [lhs,rhs] = ig.instruction.split(\"=\")\n                except Exception as e:\n                    print(ig.instruction)\n                    raise e\n                init_values[eval(lhs,parse_dict)] = eval(rhs,parse_dict)\n\n    # Now we read the endval block\n    # I don't really care about the endval block !\n\n    end_values = {}\n    if endval_block != None:\n        for ig in endval_block[1:-1]:\n            [lhs,rhs] = ig.instruction.split(\"=\")\n            end_values[eval(lhs)] = eval(rhs)\n\n    # Now we read the shocks block\n    covariances = None\n    if shocks_block != None:\n        covariances = sympy.zeros(len(shocks))\n        regex1 = re.compile(\"var (.*?),(.*?)=(.*)|var (.*?)=(.*)\")\n        for ig in shocks_block[1:-1]:\n            m = regex1.match(ig.instruction)\n            if not m:\n                raise Exception(\"unrecognized instruction in block shocks : \" + str(ig.instruction))\n            if m.group(1) != None:\n                varname1 = m.group(1).strip()\n                varname2 = m.group(2).strip()\n                value = m.group(3).strip().replace(\"^\",\"**\")\n            elif m.group(4) != None:\n                varname1 = m.group(4).strip()\n                varname2 = varname1\n                value = m.group(5).strip().replace(\"^\",\"**\")\n            i = varexo_names.index(varname1)\n            j = varexo_names.index(varname2)\n            covariances[i,j] = eval(value,parse_dict)\n            covariances[j,i] = eval(value,parse_dict)\n\n    calibration = {}\n    calibration.update(parameters_values)\n    calibration.update(init_values)\n    symbols = {'variables': variables, 'shocks': shocks, 'parameters': parameters}\n\n    from trash.dolo.symbolic.model import SModel\n    model = SModel({'dynare_block': equations}, symbols, calibration, covariances)\n    return model"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dynare_import(filename,full_output=False, debug=False):\n    '''Imports model defined in specified file'''\n    import os\n    basename = os.path.basename(filename)\n    fname = re.compile('(.*)\\.(.*)').match(basename).group(1)\n    f = open(filename)\n    txt = f.read()\n    model = parse_dynare_text(txt,full_output=full_output, debug=debug)\n    model.name = fname\n    return model", "response": "Imports model defined in specified file"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef loadUiType(uiFile):\r\n\t\tparsed = xml.parse(uiFile)\r\n\t\twidget_class = parsed.find('widget').get('class')\r\n\t\tform_class = parsed.find('class').text\r\n\t\r\n\t\twith open(uiFile, 'r') as f:\r\n\t\t\to = StringIO()\r\n\t\t\tframe = {}\r\n\t\t\t\r\n\t\t\tpysideuic.compileUi(f, o, indent=0)\r\n\t\t\tpyc = compile(o.getvalue(), '<string>', 'exec')\r\n\t\t\texec pyc in frame\r\n\t\t\t\r\n\t\t\t#Fetch the base_class and form class based on their type in the xml from designer\r\n\t\t\tform_class = frame['Ui_%s'%form_class]\r\n\t\t\tbase_class = eval('QtGui.%s'%widget_class)\r\n\t\treturn form_class, base_class", "response": "Load the type of the UI file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsolves many independent systems f(x)=0 simultaneously using a simple gradient descent. :param f: objective function to be solved with values p x N . The second output argument represents the derivative with values in (p x p x N) :param x0: initial value ( p x N ) :return: solution x such that f(x) = 0", "response": "def simple_newton(f, x0, lb=None, ub=None, infos=False, verbose=False, maxit=50, tol=1e-8, eps=1e-8, numdiff=True):\n    '''Solves many independent systems f(x)=0 simultaneously using a simple gradient descent.\n    :param f: objective function to be solved with values p x N . The second output argument represents the derivative with\n    values in (p x p x N)\n    :param x0: initial value ( p x N )\n    :return: solution x such that f(x) = 0\n    '''\n\n    precision = x0.dtype   # default tolerance should depend on precision\n\n    from numpy.linalg import solve\n\n    err = 1\n\n    it = 0\n    while err > tol and it <= maxit:\n\n        if not numdiff:\n            [res,dres] = f(x0)\n        else:\n            res = f(x0)\n            dres = numpy.zeros( (res.shape[0], x0.shape[0]), dtype=precision )\n            for i in range(x0.shape[0]):\n                xi = x0.copy()\n                xi[i] += eps\n                resi = f(xi)\n                dres[:,i] = (resi - res)/eps\n\n        dx = - solve(dres,res)\n\n        x = x0 + dx\n\n        print('x0 : {}'.format(x0))\n        err = abs(res).max()\n        print('iteration {} {}'.format(it, err))\n\n        x0 = x\n        it += 1\n\n    if not infos:\n        return x\n    else:\n        return [x, it]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsolves many independent systems f = 0 simultaneously using a simple gradient descent.", "response": "def newton_solver(f, x0, lb=None, ub=None, infos=False, verbose=False, maxit=50, tol=1e-8, eps=1e-5, numdiff=False):\n    '''Solves many independent systems f(x)=0 simultaneously using a simple gradient descent.\n    :param f: objective function to be solved with values p x N . The second output argument represents the derivative with\n    values in (p x p x N)\n    :param x0: initial value ( p x N )\n    :return: solution x such that f(x) = 0\n    '''\n\n    precision = x0.dtype   # default tolerance should depend on precision\n\n    from dolo.numeric.serial_operations import serial_multiplication as stv, serial_solve\n    err = 1\n\n    it = 0\n    while err > tol and it <= maxit:\n        if not numdiff:\n            [res,dres] = f(x0)\n        else:\n            res = f(x0)\n            dres = numpy.zeros( (res.shape[0], x0.shape[0], x0.shape[1]), dtype=precision )\n            for i in range(x0.shape[0]):\n                xi = x0.copy()\n                xi[i,:] += eps\n                resi = f(xi)\n                dres[:,i,:] = (resi - res)/eps\n\n        try:\n            dx = - serial_solve(dres,res)\n        except:\n            dx = - serial_solve(dres,res, debug=True)\n        x = x0 + dx\n\n        err = abs(res).max()\n\n        x0 = x\n        it += 1\n\n    if not infos:\n        return x\n    else:\n        return [x, it]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef newton_solver_comp(f, x0, lb, ub, infos=False, backsteps=10, maxit=50, numdiff=False):\n    '''Solves many independent systems f(x)=0 simultaneously using a simple gradient descent.\n    :param f: objective function to be solved with values p x N . The second output argument represents the derivative with\n    values in (p x p x N)\n    :param x0: initial value ( p x N )\n    :param lb: bounds for first variable\n    :param ub: bounds for second variable\n    :return: solution x such that f(x) = 0\n    '''\n\n    from numpy import row_stack\n\n    ind = x0.shape[0] - 1\n\n    def fun_lc(xx):\n        x = row_stack([xx, lb])\n        res = f(x)\n        return res[:ind,:]\n\n    def fun_uc(xx):\n        x = row_stack([xx, ub])\n        res = f(x)\n        return res[:ind,:]\n\n    [sol_nc, nit0] = newton_solver(f, x0, numdiff=True, infos=True)\n    lower_constrained = sol_nc[ind,:] < lb\n    upper_constrained = sol_nc[ind,:] > ub\n    not_constrained =  - ( lower_constrained + upper_constrained )\n\n\n    sol = sol_nc.copy()\n\n#    sol[ind,:] = lb * lower_constrained + ub * upper_constrained + sol_nc[ind,:] * not_constrained\n#    nit = nit0\n\n\n    [sol_lc, nit1] = newton_solver(fun_lc, x0[:-1,:], numdiff=True, infos=True)\n    [sol_uc, nit2] = newton_solver(fun_uc, x0[:-1,:], numdiff=True, infos=True)\n#\n    nit = nit0 + nit1 + nit2\n#\n    sol_lc = row_stack([sol_lc, lb])\n    sol_uc = row_stack([sol_uc, ub])\n#\n    lower_constrained = sol_nc[-1,:] < lb\n    upper_constrained = sol_nc[-1,:] > ub\n    not_constrained =  - ( lower_constrained + upper_constrained )\n#\n    sol = sol_lc * lower_constrained + sol_uc * upper_constrained + sol_nc * not_constrained\n\n    return [sol,nit]", "response": "Solves many independent systems f = 0 simultaneously using a simple gradient descent."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef approximate_controls(model, verbose=False, steady_state=None, eigmax=1.0-1e-6,\n                         solve_steady_state=False, order=1):\n    \"\"\"Compute first order approximation of optimal controls\n\n    Parameters:\n    -----------\n\n    model: NumericModel\n        Model to be solved\n\n    verbose: boolean\n        If True: displays number of contracting eigenvalues\n\n    steady_state: ndarray\n        Use supplied steady-state value to compute the approximation.\n        The routine doesn't check whether it is really a solution or not.\n\n    solve_steady_state: boolean\n        Use nonlinear solver to find the steady-state\n\n    orders: {1}\n        Approximation order. (Currently, only first order is supported).\n\n    Returns:\n    --------\n\n    TaylorExpansion:\n        Decision Rule for the optimal controls around the steady-state.\n\n    \"\"\"\n\n    if order > 1:\n        raise Exception(\"Not implemented.\")\n\n    f = model.functions['arbitrage']\n    g = model.functions['transition']\n\n    if steady_state is not None:\n        calib = steady_state\n    else:\n        calib = model.calibration\n\n    if solve_steady_state:\n        calib = find_deterministic_equilibrium(model)\n\n    p = calib['parameters']\n    s = calib['states']\n    x = calib['controls']\n    e = calib['shocks']\n\n    distrib = model.get_distribution()\n    sigma = distrib.sigma\n\n    l = g(s, x, e, p, diff=True)\n    [junk, g_s, g_x, g_e] = l[:4]  # [el[0,...] for el in l[:4]]\n\n    l = f(s, x, e, s, x, p, diff=True)\n    [res, f_s, f_x, f_e, f_S, f_X] = l  # [el[0,...] for el in l[:6]]\n\n    n_s = g_s.shape[0]           # number of controls\n    n_x = g_x.shape[1]   # number of states\n    n_e = g_e.shape[1]\n    n_v = n_s + n_x\n\n    A = row_stack([\n        column_stack([eye(n_s), zeros((n_s, n_x))]),\n        column_stack([-f_S    , -f_X             ])\n    ])\n\n    B = row_stack([\n        column_stack([g_s, g_x]),\n        column_stack([f_s, f_x])\n    ])\n\n\n    [S, T, Q, Z, eigval] = qzordered(A, B, 1.0-1e-8)\n\n    Q = Q.real  # is it really necessary ?\n    Z = Z.real\n\n    diag_S = np.diag(S)\n    diag_T = np.diag(T)\n\n    tol_geneigvals = 1e-10\n\n    try:\n        ok = sum((abs(diag_S) < tol_geneigvals) *\n                 (abs(diag_T) < tol_geneigvals)) == 0\n        assert(ok)\n    except Exception as e:\n        raise GeneralizedEigenvaluesError(diag_S=diag_S, diag_T=diag_T)\n\n    if max(eigval[:n_s]) >= 1 and min(eigval[n_s:]) < 1:\n        # BK conditions are met\n        pass\n    else:\n        eigval_s = sorted(eigval, reverse=True)\n        ev_a = eigval_s[n_s-1]\n        ev_b = eigval_s[n_s]\n        cutoff = (ev_a - ev_b)/2\n        if not ev_a > ev_b:\n            raise GeneralizedEigenvaluesSelectionError(\n                    A=A, B=B, eigval=eigval, cutoff=cutoff,\n                    diag_S=diag_S, diag_T=diag_T, n_states=n_s\n                )\n        import warnings\n        if cutoff > 1:\n            warnings.warn(\"Solution is not convergent.\")\n        else:\n            warnings.warn(\"There are multiple convergent solutions. The one with the smaller eigenvalues was selected.\")\n        [S, T, Q, Z, eigval] = qzordered(A, B, cutoff)\n\n    Z11 = Z[:n_s, :n_s]\n    # Z12 = Z[:n_s, n_s:]\n    Z21 = Z[n_s:, :n_s]\n    # Z22 = Z[n_s:, n_s:]\n    # S11 = S[:n_s, :n_s]\n    # T11 = T[:n_s, :n_s]\n\n    # first order solution\n    # P = (solve(S11.T, Z11.T).T @ solve(Z11.T, T11.T).T)\n    C = solve(Z11.T, Z21.T).T\n    Q = g_e\n\n    s = s.ravel()\n    x = x.ravel()\n\n    A = g_s + g_x @ C\n    B = g_e\n\n    dr = CDR([s, x, C])\n    dr.A = A\n    dr.B = B\n    dr.sigma = sigma\n\n    return dr", "response": "Compute the first order approximation of optimal controls."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef deterministic_solve(\n        model,\n        shocks=None,\n        s1=None,\n        T=100,\n        ignore_constraints=False,\n        maxit=100,\n        initial_guess=None,\n        verbose=True,\n        solver='ncpsolve',\n        tol=1e-6):\n    \"\"\"\n    Computes a perfect foresight simulation using a stacked-time algorithm.\n\n    The initial state is specified either by providing a series of exogenous\n    shocks and assuming the model is initially in equilibrium with the first\n    value of the shock, or by specifying an initial value for the states.\n\n    Parameters\n    ----------\n    model : Model\n        Model to be solved\n    shocks : array-like, dict, or pandas.DataFrame\n        A specification of the shocks to the model. Can be any of the\n        following (note by \"declaration order\" below we mean the order\n        of `model.symbols[\"shocks\"]`):\n\n        - A 1d numpy array-like specifying a time series for a single\n          shock, or all shocks stacked into a single array.\n        - A 2d numpy array where each column specifies the time series\n          for one of the shocks in declaration order. This must be an\n          `N` by number of shocks 2d array.\n        - A dict where keys are strings found in\n          `model.symbols[\"shocks\"]` and values are a time series of\n          values for that shock. For model shocks that do not appear in\n          this dict, the shock is set to the calibrated value. Note\n          that this interface is the most flexible as it allows the user\n          to pass values for only a subset of the model shocks and it\n          allows the passed time series to be of different lengths.\n        - A DataFrame where columns map shock names into time series.\n          The same assumptions and behavior that are used in the dict\n          case apply here\n\n        If nothing is given here, `shocks` is set equal to the\n        calibrated values found in `model.calibration[\"shocks\"]` for\n        all periods.\n\n        If the length of any time-series in shocks is less than `T`\n        (see below) it is assumed that that particular shock will\n        remain at the final given value for the duration of the\n        simulaiton.\n    s1 : ndarray or dict\n        a vector with the value of initial states\n    T : int\n        horizon for the perfect foresight simulation\n    maxit : int\n        maximum number of iteration for the nonlinear solver\n    verbose : boolean\n        if True, the solver displays iterations\n    tol : float\n        stopping criterium for the nonlinear solver\n    ignore_constraints : bool\n        if True, complementarity constraints are ignored.\n\n    Returns\n    -------\n    pandas dataframe\n        a dataframe with T+1 observations of the model variables along the\n        simulation (states, controls, auxiliaries). The first observation is\n        the steady-state corresponding to the first value of the shocks. The\n        simulation should return to a steady-state corresponding to the last\n        value of the exogenous shocks.\n\n    \"\"\"\n\n    # definitions\n    n_s = len(model.calibration['states'])\n    n_x = len(model.calibration['controls'])\n    p = model.calibration['parameters']\n\n    epsilons = _shocks_to_epsilons(model, shocks, T)\n\n    m0 = epsilons[0, :]\n\n    # get initial steady-state\n    from dolo.algos.steady_state import find_steady_state\n    # TODO: use initial_guess for steady_state\n    # TODO:\n\n    if s1 is None:\n        start_state = find_steady_state(model, m=m0)\n        s0 = start_state['states']\n        x0 = start_state['controls']\n        m1 = epsilons[1,:]\n        s1 = model.functions['transition'](m0, s0, x0, m1, p)\n    else:\n        s0 = model.calibration['states']*np.nan\n        x0 = model.calibration['controls']*np.nan\n        s1 = np.array(s1)\n\n    x1_g = model.calibration['controls']  # we can do better here\n    sT_g = model.calibration['states']  # we can do better here\n    xT_g = model.calibration['controls']  # we can do better here\n\n\n    if initial_guess is None:\n        start = np.concatenate([s1, x1_g])\n        final = np.concatenate([sT_g, xT_g])\n        initial_guess = np.row_stack(\n            [start * (1 - l) + final * l for l in linspace(0.0, 1.0, T)])\n\n    else:\n        if isinstance(initial_guess, pd.DataFrame):\n            initial_guess = np.array(initial_guess[model.symbols['states']+model.symbols['controls']])\n        initial_guess = initial_guess[1:,:]\n        initial_guess = initial_guess[:, :n_s + n_x]\n\n    sh = initial_guess.shape\n\n\n    if model.x_bounds and not ignore_constraints:\n        initial_states = initial_guess[:, :n_s]\n        [lb, ub] = [u(epsilons[1:,:], initial_states, p) for u in model.x_bounds]\n        lower_bound = initial_guess * 0 - np.inf\n        lower_bound[:, n_s:] = lb\n        upper_bound = initial_guess * 0 + np.inf\n        upper_bound[:, n_s:] = ub\n        test1 = max(lb.max(axis=0) - lb.min(axis=0))\n        test2 = max(ub.max(axis=0) - ub.min(axis=0))\n        if test1 > 0.00000001 or test2 > 0.00000001:\n            msg = \"Not implemented: perfect foresight solution requires that \"\n            msg += \"controls have constant bounds.\"\n            raise Exception(msg)\n    else:\n        ignore_constraints = True\n        lower_bound = None\n        upper_bound = None\n\n    if not ignore_constraints:\n\n        def ff(vec):\n            return det_residual(\n                model, vec.reshape(sh), s1, xT_g, epsilons[1:, :], jactype='sparse')\n\n        v0 = initial_guess.ravel()\n        if solver=='ncpsolve':\n            sol, nit = ncpsolve(\n                ff,\n                lower_bound.ravel(),\n                upper_bound.ravel(),\n                initial_guess.ravel(),\n                verbose=verbose,\n                maxit=maxit,\n                tol=tol,\n                jactype='sparse')\n        else:\n            from dolo.numeric.extern.lmmcp import lmmcp\n            sol = lmmcp(\n                lambda u: ff(u)[0],\n                lambda u: ff(u)[1].todense(),\n                lower_bound.ravel(),\n                upper_bound.ravel(),\n                initial_guess.ravel(),\n                verbose=verbose)\n            nit = -1\n\n        sol = sol.reshape(sh)\n\n    else:\n\n        def ff(vec):\n            ll = det_residual(\n                model, vec.reshape(sh), s1, xT_g, epsilons[1:, :],\n                diff=True)\n            return(ll)\n\n        v0 = initial_guess.ravel()\n        # from scipy.optimize import root\n        # sol = root(ff, v0, jac=True)\n        # sol = sol.x.reshape(sh)\n        from dolo.numeric.optimize.newton import newton\n        sol, nit = newton(ff, v0, jactype='sparse')\n        sol = sol.reshape(sh)\n\n    sx = np.concatenate([s0, x0])\n    # sol = sol[:-1, :]\n\n    sol = np.concatenate([sx[None, :], sol], axis=0)\n    # epsilons = np.concatenate([epsilons[:1,:], epsilons], axis=0)\n\n    if 'auxiliary' in model.functions:\n        colnames = (model.symbols['states'] + model.symbols['controls'] +\n                    model.symbols['auxiliaries'])\n        # compute auxiliaries\n        y = model.functions['auxiliary'](epsilons, sol[:, :n_s], sol[:, n_s:],\n                                         p)\n        sol = np.column_stack([sol, y])\n    else:\n        colnames = model.symbols['states'] + model.symbols['controls']\n\n    sol = np.column_stack([sol, epsilons])\n    colnames = colnames + model.symbols['exogenous']\n\n    ts = pd.DataFrame(sol, columns=colnames)\n    return ts", "response": "Solve a perfect foresight simulation using a stacked - time algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes the residuals, the derivatives of the stacked-time system. :param model: an fga model :param guess: the guess for the simulated values. An `(n_s.n_x) x N` array, where n_s is the number of states, n_x the number of controls, and `N` the length of the simulation. :param start: initial boundary condition (initial value of the states) :param final: final boundary condition (last value of the controls) :param shocks: values for the exogenous shocks :param diff: if True, the derivatives are computes :return: a list with two elements: - an `(n_s.n_x) x N` array with the residuals of the system - a `(n_s.n_x) x N x (n_s.n_x) x N` array representing the jacobian of the system", "response": "def det_residual(model,\n                 guess,\n                 start,\n                 final,\n                 shocks,\n                 diff=True,\n                 jactype='sparse'):\n    '''\n    Computes the residuals, the derivatives of the stacked-time system.\n    :param model: an fga model\n    :param guess: the guess for the simulated values. An `(n_s.n_x) x N` array,\n                  where n_s is the number of states,\n    n_x the number of controls, and `N` the length of the simulation.\n    :param start: initial boundary condition (initial value of the states)\n    :param final: final boundary condition (last value of the controls)\n    :param shocks: values for the exogenous shocks\n    :param diff: if True, the derivatives are computes\n    :return: a list with two elements:\n        - an `(n_s.n_x) x N` array with the residuals of the system\n        - a `(n_s.n_x) x N x (n_s.n_x) x N` array representing the jacobian of\n             the system\n    '''\n\n    # TODO: compute a sparse derivative and ensure the solvers can deal with it\n\n    n_s = len(model.symbols['states'])\n    n_x = len(model.symbols['controls'])\n\n    # n_e = len(model.symbols['shocks'])\n    N = guess.shape[0]\n\n    p = model.calibration['parameters']\n\n    f = model.functions['arbitrage']\n    g = model.functions['transition']\n\n    vec = guess[:-1, :]\n    vec_f = guess[1:, :]\n\n    s = vec[:, :n_s]\n    x = vec[:, n_s:]\n    S = vec_f[:, :n_s]\n    X = vec_f[:, n_s:]\n\n    m = shocks[:-1, :]\n    M = shocks[1:, :]\n\n    if diff:\n        SS, SS_m, SS_s, SS_x, SS_M = g(m, s, x, M, p, diff=True)\n        R, R_m, R_s, R_x, R_M, R_S, R_X = f(m, s, x, M, S, X, p, diff=True)\n    else:\n        SS = g(m, s, x, M, p)\n        R = f(m, s, x, M, S, X, p)\n\n    res_s = SS - S\n    res_x = R\n\n    res = np.zeros((N, n_s + n_x))\n\n    res[1:, :n_s] = res_s\n    res[:-1, n_s:] = res_x\n\n    res[0, :n_s] = -(guess[0, :n_s] - start)\n    res[-1, n_s:] = -(guess[-1, n_s:] - guess[-2, n_s:])\n\n    if not diff:\n        return res\n    else:\n\n        sparse_jac = False\n        if not sparse_jac:\n\n            # we compute the derivative matrix\n            res_s_s = SS_s\n            res_s_x = SS_x\n\n            # next block is probably very inefficient\n            jac = np.zeros((N, n_s + n_x, N, n_s + n_x))\n            for i in range(N - 1):\n                jac[i, n_s:, i, :n_s] = R_s[i, :, :]\n                jac[i, n_s:, i, n_s:] = R_x[i, :, :]\n                jac[i, n_s:, i + 1, :n_s] = R_S[i, :, :]\n                jac[i, n_s:, i + 1, n_s:] = R_X[i, :, :]\n                jac[i + 1, :n_s, i, :n_s] = SS_s[i, :, :]\n                jac[i + 1, :n_s, i, n_s:] = SS_x[i, :, :]\n                jac[i + 1, :n_s, i + 1, :n_s] = -np.eye(n_s)\n                # jac[i,n_s:,i,:n_s] = R_s[i,:,:]\n                # jac[i,n_s:,i,n_s:] = R_x[i,:,:]\n                # jac[i+1,n_s:,i,:n_s] = R_S[i,:,:]\n                # jac[i+1,n_s:,i,n_s:] = R_X[i,:,:]\n                # jac[i,:n_s,i+1,:n_s] = SS_s[i,:,:]\n                # jac[i,:n_s,i+1,n_s:] = SS_x[i,:,:]\n                # jac[i+1,:n_s,i+1,:n_s] = -np.eye(n_s)\n            jac[0, :n_s, 0, :n_s] = -np.eye(n_s)\n            jac[-1, n_s:, -1, n_s:] = -np.eye(n_x)\n            jac[-1, n_s:, -2, n_s:] = +np.eye(n_x)\n            nn = jac.shape[0] * jac.shape[1]\n            res = res.ravel()\n            jac = jac.reshape((nn, nn))\n\n        if jactype == 'sparse':\n            from scipy.sparse import csc_matrix, csr_matrix\n            jac = csc_matrix(jac)\n            # scipy bug ? I don't get the same with csr\n\n        return [res, jac]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of all the variables in the current object.", "response": "def def_variables(s):\n    \"\"\"\n    blabla\n    \"\"\"\n\n    frame = inspect.currentframe().f_back\n    try:\n        if isinstance(s,str):\n            s = re.split('\\s|,', s)\n        res = []\n        for t in s:\n            # skip empty stringG\n            if not t:\n                continue\n            if t.count(\"@\") > 0:\n                sym = IndexedSymbol(t,Variable)\n                t = t.strip('@')\n            else:\n                sym = Variable(t)\n            frame.f_globals[t] = sym\n            res.append(sym)\n        if frame.f_globals.get('variables_order'):\n            # we should avoid to declare symbols twice !\n            frame.f_globals['variables_order'].extend(res)\n        else:\n            frame.f_globals['variables_order'] = res\n        return res\n    finally:\n        del frame"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clear_all():\n\n    frame = inspect.currentframe().f_back\n    try:\n        if frame.f_globals.get('variables_order'):\n            # we should avoid to declare symbols twice !\n            del frame.f_globals['variables_order']\n        if frame.f_globals.get('parameters_order'):\n            # we should avoid to declare symbols twice !\n            del frame.f_globals['parameters_order']\n    finally:\n        del frame", "response": "Clears all parameters variables and shocks defined previously\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef simulate(model, dr, N=1, T=40, s0=None, i0=None, m0=None,\n        driving_process=None, seed=42, stochastic=True):\n    '''\n    Simulate a model using the specified decision rule.\n\n    Parameters\n    ----------\n\n    model: NumericModel\n\n    dr: decision rule\n\n    s0: ndarray\n        initial state where all simulations start\n\n    driving_process: ndarray\n        realization of exogenous driving process (drawn randomly if None)\n\n    N: int\n        number of simulations\n    T: int\n        horizon for the simulations\n    seed: int\n        used to initialize the random number generator. Use it to replicate\n        exact same results among simulations\n    discard: boolean (False)\n        if True, then all simulations containing at least one non finite value\n        are discarded\n\n    Returns\n    -------\n    xarray.DataArray:\n        returns a ``T x N x n_v`` array where ``n_v``\n           is the number of variables.\n    '''\n\n    if isinstance(dr, AlgoResult):\n        dr = dr.dr\n\n    calib = model.calibration\n    parms = numpy.array(calib['parameters'])\n\n    if s0 is None:\n        s0 = calib['states']\n\n    n_x = len(model.symbols[\"controls\"])\n    n_s = len(model.symbols[\"states\"])\n\n    s_simul = numpy.zeros((T, N, n_s))\n    x_simul = numpy.zeros((T, N, n_x))\n\n    s_simul[0, :, :] = s0[None, :]\n\n    # are we simulating a markov chain or a continuous process ?\n    if driving_process is not None:\n        m_simul = driving_process\n        sim_type = 'continuous'\n        m0 = m_simul[0,:,:]\n        x_simul[0,:,:] = dr.eval_ms(m0, s0)\n    else:\n        if isinstance(dr.exo_grid, UnstructuredGrid):\n            if i0 is None:\n                i0 = 0\n            dp = model.exogenous.discretize() ## TODO (nothing guarantee the processes match)\n            m_simul = dp.simulate(N, T, i0=i0, stochastic=stochastic)\n            i_simul = find_index(m_simul, dp.values)\n            sim_type = 'discrete'\n            m0 = dp.node(i0)\n            x0 = dr.eval_is(i0, s0)\n\n        else:\n            process = model.exogenous ## TODO (nothing guarantee the processes match)\n            m_simul = process.simulate(N, T, m0=m0, stochastic=stochastic)\n            sim_type = 'continuous'\n            if m0 is None:\n                m0 = model.calibration[\"exogenous\"]\n            x0 = dr.eval_ms(m0, s0)\n            x_simul[0, :, :] = x0[None, :]\n\n    fun = model.functions\n    f = model.functions['arbitrage']\n    g = model.functions['transition']\n\n    numpy.random.seed(seed)\n    from dolo.misc.dprint import dprint\n    mp = m0\n    for i in range(T):\n        m = m_simul[i,:,:]\n        s = s_simul[i,:,:]\n        if sim_type=='discrete':\n            i_m = i_simul[i,:]\n            xx = [dr.eval_is(i_m[ii], s[ii,:]) for ii in range(s.shape[0])]\n            x = np.row_stack(xx)\n        else:\n            x = dr.eval_ms(m, s)\n\n        x_simul[i,:,:] = x\n        ss = g(mp, s, x, m, parms)\n        if i < T-1:\n            s_simul[i + 1, :, :] = ss\n        mp = m\n\n    if 'auxiliary' not in fun:  # TODO: find a better test than this\n        l = [s_simul, x_simul]\n        varnames = model.symbols['states'] + model.symbols['controls']\n    else:\n        aux = fun['auxiliary']\n        a_simul = aux(\n            m_simul.reshape((N * T, -1)),\n            s_simul.reshape((N * T, -1)),\n            x_simul.reshape((N * T, -1)), parms)\n        a_simul = a_simul.reshape(T, N, -1)\n        l = [m_simul, s_simul, x_simul, a_simul]\n        varnames = model.symbols['exogenous'] + model.symbols['states'] + model.symbols[\n            'controls'] + model.symbols['auxiliaries']\n\n    simul = numpy.concatenate(l, axis=2)\n\n    import xarray as xr\n    data = xr.DataArray(\n            simul,\n            dims=['T','N','V'],\n            coords={'T': range(T), 'N': range(N), 'V': varnames}\n        )\n\n    return data", "response": "Simulate a model using the specified decision rule."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds a global solution for a model by solving one large system of equations with a simple newton algorithm.", "response": "def nonlinear_system(model, initial_dr=None, maxit=10, tol=1e-8,  grid={}, distribution={}, verbose=True):\n\n    '''\n    Finds a global solution for ``model`` by solving one large system of equations\n    using a simple newton algorithm.\n\n    Parameters\n    ----------\n    model: NumericModel\n        \"dtcscc\" model to be solved\n    verbose: boolean\n        if True, display iterations\n    initial_dr: decision rule\n        initial guess for the decision rule\n    maxit:  int\n        maximum number of iterationsd\n    tol: tolerance criterium for successive approximations\n    grid: grid options\n    distribution: distribution options\n\n    Returns\n    -------\n    decision rule :\n        approximated solution\n    '''\n\n\n    if verbose:\n        headline = '|{0:^4} | {1:10} | {2:8} |'\n        headline = headline.format('N', ' Error', 'Time')\n        stars = '-'*len(headline)\n        print(stars)\n        print(headline)\n        print(stars)\n        # format string for within loop\n        fmt_str = '|{0:4} | {1:10.3e} | {2:8.3f} |'\n\n    f = model.functions['arbitrage']\n    g = model.functions['transition']\n    p = model.calibration['parameters']\n\n    distrib = model.get_distribution(**distribution)\n    nodes, weights = distrib.discretize()\n\n    approx = model.get_grid(**grid)\n    ms = create_interpolator(approx, approx.interpolation)\n\n    grid = ms.grid\n\n    if initial_dr is None:\n        dr = approximate_controls(model)\n    else:\n        dr = initial_dr\n\n    ms.set_values(dr(grid))\n\n    x = dr(grid)\n    x0 = x.copy()\n\n    it = 0\n    err = 10\n\n\n    a0 = x0.copy().reshape((x0.shape[0]*x0.shape[1],))\n    a = a0.copy()\n\n    while err > tol and it < maxit:\n\n        it += 1\n        t1 = time.time()\n\n        r, da = residuals(f, g, grid, a.reshape(x0.shape), ms, nodes, weights, p, diff=True)[:2]\n        r = r.flatten()\n\n        err = abs(r).max()\n\n        t2 = time.time()\n\n        if verbose:\n            print(fmt_str.format(it, err, t2-t1))\n\n        if err > tol:\n            a -= scipy.sparse.linalg.spsolve(da, r)\n\n    if verbose:\n        print(stars)\n\n    return ms"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the nodes and weights for a Gauss - Hermite quadrature.", "response": "def gauss_hermite_nodes(orders, sigma, mu=None):\n    '''\n    Computes the weights and nodes for Gauss Hermite quadrature.\n\n    Parameters\n    ----------\n    orders : int, list, array\n        The order of integration used in the quadrature routine\n    sigma : array-like\n        If one dimensional, the variance of the normal distribution being\n        approximated. If multidimensional, the variance-covariance matrix of\n        the multivariate normal process being approximated.\n\n    Returns\n    -------\n    x : array\n        Quadrature nodes\n    w : array\n        Quadrature weights\n    '''\n    if isinstance(orders, int):\n        orders = [orders]\n\n    import numpy\n\n\n    if mu is None:\n        mu = numpy.array( [0]*sigma.shape[0] )\n\n\n    herms = [hermgauss(i) for i in orders]\n\n    points = [ h[0]*numpy.sqrt(2) for h in herms]\n    weights = [ h[1]/numpy.sqrt( numpy.pi) for h in herms]\n\n    if len(orders) == 1:\n        # Note: if sigma is 2D, x will always be 2D, even if sigma is only 1x1.\n        # print(points.shape)\n        x = numpy.array(points[0])*numpy.sqrt(float(sigma))\n        if sigma.ndim==2:\n            x = x[:,None]\n        w = weights[0]\n        return [x,w]\n\n    else:\n        x = cartesian( points).T\n\n        from functools import reduce\n        w = reduce( numpy.kron, weights)\n\n        zero_columns = numpy.where(sigma.sum(axis=0)==0)[0]\n        for i in zero_columns:\n            sigma[i,i] = 1.0\n\n        C = numpy.linalg.cholesky(sigma)\n\n        x = numpy.dot(C, x) + mu[:,numpy.newaxis]\n\n        x = numpy.ascontiguousarray(x.T)\n\n        for i in zero_columns:\n            x[:,i] =0\n\n        return [x,w]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parameterized_expectations(model, verbose=False, initial_dr=None,\n                               pert_order=1, with_complementarities=True,\n                               grid={}, distribution={},\n                               maxit=100, tol=1e-8, inner_maxit=100,\n                               direct=False):\n\n    '''\n    Find global solution for ``model`` via parameterized expectations.\n    Controls must be expressed as a direct function of equilibrium objects.\n    Algorithm iterates over the expectations function in the arbitrage equation.\n\n    Parameters:\n    ----------\n\n    model : NumericModel\n        ``dtcscc`` model to be solved\n\n    verbose : boolean\n        if True, display iterations\n\n    initial_dr : decision rule\n        initial guess for the decision rule\n\n    pert_order : {1}\n        if no initial guess is supplied, the perturbation solution at order\n        ``pert_order`` is used as initial guess\n\n    grid : grid options\n\n    distribution : distribution options\n\n    maxit : maximum number of iterations\n\n    tol : tolerance criterium for successive approximations\n\n    inner_maxit : maximum number of iteration for inner solver\n\n    direct : if True, solve with direct method. If false, solve indirectly\n\n    Returns\n    -------\n\n    decision rule :\n        approximated solution\n\n    '''\n\n    def vprint(t):\n        if verbose:\n            print(t)\n\n    g = model.functions['transition']\n    h = model.functions['expectation']\n    f = model.functions['arbitrage_exp']  # f(s, x, z, p, out)\n    parms = model.calibration['parameters']\n    if direct is True:\n        d = model.functions['direct_response']\n\n    approx = model.get_grid(**grid)\n    grid = approx.grid\n    interp_type = approx.interpolation\n    dr = create_interpolator(approx, interp_type)     # Interp for control\n    expect = create_interpolator(approx, interp_type)  # Interp for expectation\n\n    distrib = model.get_distribution(**distribution)\n    nodes, weights = distrib.discretize()\n\n    N = grid.shape[0]\n\n    if initial_dr is None:\n        if pert_order == 1:\n            initial_dr = approximate_controls(model)\n\n        if pert_order > 1:\n            raise Exception(\"Perturbation order > 1 not supported (yet).\")\n\n    # Use initial decision rule to find initial expectation function\n    x_0 = initial_dr(grid)\n    x_0 = x_0.real  # just in case ...\n\n    z_0 = np.zeros((N, len(model.symbols['expectations'])))\n    z_new = np.zeros((N, len(model.symbols['expectations'])))\n\n    xxnext = np.zeros((x_0.shape[0], x_0.shape[1], weights.shape[0]))\n    for i in range(weights.shape[0]):\n        e = nodes[i, :]\n        ssnext = g(grid, x_0, e, parms)\n        xxnext[:, :, i] = initial_dr(ssnext)\n        z_0 += weights[i]*h(ssnext, xxnext[:, :, i], parms)\n\n    t1 = time.time()\n    it = 0\n    err = 10\n    err_0 = 10\n\n    verbit = True if verbose == 'full' else False\n\n    if with_complementarities is True:\n        lbfun = model.functions['controls_lb']\n        ubfun = model.functions['controls_ub']\n        lb = lbfun(grid, parms)\n        ub = ubfun(grid, parms)\n    else:\n        lb = None\n        ub = None\n\n    if verbose:\n        headline = '|{0:^4} | {1:10} | {2:8} | {3:8} |'\n        headline = headline.format('N', ' Error', 'Gain', 'Time')\n        stars = '-'*len(headline)\n        print(stars)\n        print(headline)\n        print(stars)\n\n        # format string for within loop\n        fmt_str = '|{0:4} | {1:10.3e} | {2:8.3f} | {3:8.3f} |'\n\n    while err > tol and it <= maxit:\n\n        it += 1\n        t_start = time.time()\n\n        # update interpolation object with current guess for expectation\n        expect.set_values(z_0)\n\n        xxnext[...] = 0\n        if direct is True:\n            # Use control as direct function of arbitrage equation\n            xx = d(grid, expect(grid), parms)\n            for i in range(weights.shape[0]):\n                e = nodes[i, :]\n                ssnext = g(grid, xx, e, parms)\n                xxnext[:, :, i] = d(ssnext, expect(ssnext), parms)\n\n            if with_complementarities is True:\n                xx = np.minimum(xx, ub)\n                xx = np.maximum(xx, lb)\n                for i in range(weights.shape[0]):\n                    xxnext[:, :, i] = np.minimum(xxnext[:, :, i], ub)\n                    xxnext[:, :, i] = np.maximum(xxnext[:, :, i], lb)\n        else:\n            # Find control by solving arbitrage equation\n            def fun(x): return f(grid, x, expect(grid), parms)\n            sdfun = SerialDifferentiableFunction(fun)\n\n            if with_complementarities is True:\n                [xx, nit] = ncpsolve(sdfun, lb, ub, x_0, verbose=verbit,\n                                     maxit=inner_maxit)\n                dr.set_values(xx)  # Update decision rule object\n                for i in range(weights.shape[0]):\n                    e = nodes[i, :]\n                    ssnext = g(grid, xx, e, parms)\n                    xxnext[:, :, i] = dr(ssnext)\n\n                    # Make sure x_t+1 is within bounds\n                    xxnext[:, :, i] = np.minimum(xxnext[:, :, i], ub)\n                    xxnext[:, :, i] = np.maximum(xxnext[:, :, i], lb)\n            else:\n                [xx, nit] = serial_newton(sdfun, x_0, verbose=verbit)\n                dr.set_values(xx)  # Update decision rule object\n                for i in range(weights.shape[0]):\n                    e = nodes[i, :]\n                    ssnext = g(grid, xx, e, parms)\n                    xxnext[:, :, i] = dr(ssnext)\n\n        # Compute the new expectation function\n        z_new[...] = 0\n        for i in range(weights.shape[0]):\n            e = nodes[i, :]\n            ssnext = g(grid, xx, e, parms)\n            z_new += weights[i]*h(ssnext, xxnext[:, :, i], parms)\n\n        # update error\n        err = (abs(z_new - z_0).max())\n\n        # Update guess for expectations function and the decision rule\n        z_0 = z_new.copy()\n        x_0 = xx\n\n        # print error infomation if `verbose`\n        err_SA = err/err_0\n        err_0 = err\n        t_finish = time.time()\n        elapsed = t_finish - t_start\n        if verbose:\n            print(fmt_str.format(it, err, err_SA, elapsed))\n\n    if it == maxit:\n        import warnings\n        warnings.warn(UserWarning(\"Maximum number of iterations reached\"))\n\n    # compute final fime and do final printout if `verbose`\n    t2 = time.time()\n    if verbose:\n        print(stars)\n        print('Elapsed: {} seconds.'.format(t2 - t1))\n        print(stars)\n\n    # Interpolation for the decision rule\n    dr.set_values(x_0)\n\n    return dr", "response": "Returns a new object that is solved via parameterized expectations."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef newton(f, x, verbose=False, tol=1e-6, maxit=5, jactype='serial'):\n\n\n    \"\"\"Solve nonlinear system using safeguarded Newton iterations\n\n\n    Parameters\n    ----------\n\n    Return\n    ------\n    \"\"\"\n    if verbose:\n        print = lambda txt: old_print(txt)\n    else:\n        print = lambda txt: None\n\n    it = 0\n    error = 10\n    converged = False\n    maxbacksteps = 30\n\n    x0 = x\n\n    if jactype == 'sparse':\n        from scipy.sparse.linalg import spsolve as solve\n    elif jactype == 'full':\n        from numpy.linalg import solve\n    else:\n        solve = serial_solve\n\n    while it<maxit and not converged:\n\n        [v,dv] = f(x)\n\n        # TODO: rewrite starting here\n\n#        print(\"Time to evaluate {}\".format(ss-tt)0)\n\n        error_0 = abs(v).max()\n\n        if error_0 < tol:\n\n            if verbose:\n                print(\"> System was solved after iteration {}. Residual={}\".format(it,error_0))\n            converged = True\n\n        else:\n\n            it += 1\n\n            dx = solve(dv, v)\n\n            # norm_dx = abs(dx).max()\n\n            for bck in range(maxbacksteps):\n                xx = x - dx*(2**(-bck))\n                vm = f(xx)[0]\n                err = abs(vm).max()\n                if err < error_0:\n                    break\n\n            x = xx\n\n            if verbose:\n                print(\"\\t> {} | {} | {}\".format(it, err, bck))\n\n    if not converged:\n        import warnings\n        warnings.warn(\"Did not converge\")\n    return [x, it]", "response": "Solve a nonlinear system using safeguarded Newton iterations"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cartesian(arrays, out=None):\n\n    arrays = [np.asarray(x) for x in arrays]\n    dtype = arrays[0].dtype\n\n    n = np.prod([x.size for x in arrays])\n    if out is None:\n        out = np.zeros([n, len(arrays)], dtype=dtype)\n\n    m = n // arrays[0].size\n    out[:,0] = np.repeat(arrays[0], m)\n    if arrays[1:]:\n        cartesian(arrays[1:], out=out[0:m,1:])\n        for j in range(1, arrays[0].size):\n            out[j*m:(j+1)*m,1:] = out[0:m,1:]\n    return out", "response": "Generates a cartesian product of the input arrays."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef state_perturb(f_fun, g_fun, sigma, sigma2_correction=None, verbose=True):\n\n    import numpy as np\n    from numpy.linalg import solve\n\n    approx_order = len(f_fun) - 1 # order of approximation\n\n    [f0,f1] = f_fun[:2]\n\n    [g0,g1] = g_fun[:2]\n    n_x = f1.shape[0]           # number of controls\n    n_s = f1.shape[1]/2 - n_x   # number of states\n    n_e = g1.shape[1] - n_x - n_s\n    n_v = n_s + n_x\n\n    f_s = f1[:,:n_s]\n    f_x = f1[:,n_s:n_s+n_x]\n    f_snext = f1[:,n_v:n_v+n_s]\n    f_xnext = f1[:,n_v+n_s:]\n\n    g_s = g1[:,:n_s]\n    g_x = g1[:,n_s:n_s+n_x]\n    g_e = g1[:,n_v:]\n\n    A = np.row_stack([\n        np.column_stack( [ np.eye(n_s), np.zeros((n_s,n_x)) ] ),\n        np.column_stack( [ -f_snext    , -f_xnext             ] )\n    ])\n    B = np.row_stack([\n        np.column_stack( [ g_s, g_x ] ),\n        np.column_stack( [ f_s, f_x ] )\n    ])\n\n\n\n    from dolo.numeric.extern.qz import qzordered\n    [S,T,Q,Z,eigval] = qzordered(A,B,n_s)\n\n    # Check Blanchard=Kahn conditions\n    n_big_one = sum(eigval>1.0)\n    n_expected = n_x\n    if verbose:\n        print( \"There are {} eigenvalues greater than 1. Expected: {}.\".format( n_big_one, n_x ) )\n\n    if n_big_one != n_expected:\n        raise Exception(\"There should be exactly {} eigenvalues greater than one. Not {}.\".format(n_x, n_big_one))\n\n    Q = Q.real # is it really necessary ?\n    Z = Z.real\n\n    Z11 = Z[:n_s,:n_s]\n    Z12 = Z[:n_s,n_s:]\n    Z21 = Z[n_s:,:n_s]\n    Z22 = Z[n_s:,n_s:]\n    S11 = S[:n_s,:n_s]\n    T11 = T[:n_s,:n_s]\n\n    # first order solution\n    C = solve(Z11.T, Z21.T).T\n    P = np.dot(solve(S11.T, Z11.T).T , solve(Z11.T, T11.T).T )\n    Q = g_e\n\n    if False:\n        from numpy import dot\n        test = f_s + dot(f_x,C) + dot( f_snext, g_s + dot(g_x,C) ) + dot(f_xnext, dot( C, g_s + dot(g_x,C) ) )\n        print('Error: ' + str(abs(test).max()))\n\n    if approx_order == 1:\n        return [C]\n\n    # second order solution\n    from dolo.numeric.tensor import sdot, mdot\n    from numpy import dot\n    from dolo.numeric.matrix_equations import solve_sylvester\n\n    f2 = f_fun[2]\n    g2 = g_fun[2]\n    g_ss = g2[:,:n_s,:n_s]\n    g_sx = g2[:,:n_s,n_s:n_v]\n    g_xx = g2[:,n_s:n_v,n_s:n_v]\n\n    X_s = C\n\n\n\n    V1_3 = g_s + dot(g_x,X_s)\n    V1 = np.row_stack([\n        np.eye(n_s),\n        X_s,\n        V1_3,\n        dot( X_s, V1_3 )\n    ])\n\n    K2 = g_ss + 2 * sdot(g_sx,X_s) + mdot(g_xx,[X_s,X_s])\n    #L2 =\n    A = f_x + dot( f_snext + dot(f_xnext,X_s), g_x)\n    B = f_xnext\n    C = V1_3\n    D = mdot(f2,[V1,V1]) + sdot(f_snext + dot(f_xnext,X_s),K2)\n    \n    X_ss = solve_sylvester(A,B,C,D)\n\n#    test = sdot( A, X_ss ) + sdot( B,  mdot(X_ss,[V1_3,V1_3]) ) + D\n\n    \n    if not sigma == None:\n        g_ee = g2[:,n_v:,n_v:]\n\n        v = np.row_stack([\n            g_e,\n            dot(X_s,g_e)\n        ])\n\n        K_tt = mdot( f2[:,n_v:,n_v:], [v,v] )\n        K_tt += sdot( f_snext + dot(f_xnext,X_s) , g_ee )\n        K_tt += mdot( sdot( f_xnext, X_ss), [g_e, g_e] )\n        K_tt = np.tensordot( K_tt, sigma, axes=((1,2),(0,1)))\n\n        if sigma2_correction is not None:\n            K_tt += sdot( f_snext + dot(f_xnext,X_s) , sigma2_correction[0] )\n\n        L_tt = f_x  + dot(f_snext, g_x) + dot(f_xnext, dot(X_s, g_x) + np.eye(n_x) )\n        X_tt = solve( L_tt, - K_tt)\n\n    if approx_order == 2:\n        if sigma == None:\n            return [X_s,X_ss]  # here, we don't approximate the law of motion of the states\n        else:\n            return [[X_s,X_ss],[X_tt]]  # here, we don't approximate the law of motion of the states\n\n    # third order solution\n\n    f3 = f_fun[3]\n    g3 = g_fun[3]\n    g_sss = g3[:,:n_s,:n_s,:n_s]\n    g_ssx = g3[:,:n_s,:n_s,n_s:n_v]\n    g_sxx = g3[:,:n_s,n_s:n_v,n_s:n_v]\n    g_xxx = g3[:,n_s:n_v,n_s:n_v,n_s:n_v]\n\n    V2_3 = K2 + sdot(g_x,X_ss)\n    V2 = np.row_stack([\n        np.zeros( (n_s,n_s,n_s) ),\n        X_ss,\n        V2_3,\n        dot( X_s, V2_3 ) + mdot(X_ss,[V1_3,V1_3])\n    ])\n\n    K3 = g_sss + 3*sdot(g_ssx,X_s) + 3*mdot(g_sxx,[X_s,X_s]) + 2*sdot(g_sx,X_ss)\n    K3 += 3*mdot( g_xx,[X_ss,X_s] ) + mdot(g_xxx,[X_s,X_s,X_s])\n    L3 = 3*mdot(X_ss,[V1_3,V2_3])\n\n    # A = f_x + dot( f_snext + dot(f_xnext,X_s), g_x) # same as before\n    # B = f_xnext # same\n    # C = V1_3 # same\n    D = mdot(f3,[V1,V1,V1]) + 3*mdot(f2,[ V2,V1 ]) + sdot(f_snext + dot(f_xnext,X_s),K3)\n    D += sdot( f_xnext, L3 )\n\n    X_sss = solve_sylvester(A,B,C,D)\n\n    # now doing sigma correction with sigma replaced by l in the subscripts\n\n    if not sigma is None:\n        g_se= g2[:,:n_s,n_v:]\n        g_xe= g2[:,n_s:n_v,n_v:]\n\n        g_see= g3[:,:n_s,n_v:,n_v:]\n        g_xee= g3[:,n_s:n_v,n_v:,n_v:]\n\n\n        W_l = np.row_stack([\n            g_e,\n            dot(X_s,g_e)\n        ])\n\n        I_e = np.eye(n_e)\n\n        V_sl = g_se + mdot( g_xe, [X_s, np.eye(n_e)])\n\n        W_sl = np.row_stack([\n            V_sl,\n            mdot( X_ss, [ V1_3, g_e ] ) + sdot( X_s, V_sl)\n        ])\n\n        K_ee = mdot(f3[:,:,n_v:,n_v:], [V1, W_l, W_l ])\n        K_ee += 2 * mdot( f2[:,n_v:,n_v:], [W_sl, W_l])\n\n        # stochastic part of W_ll\n\n        SW_ll = np.row_stack([\n            g_ee,\n            mdot(X_ss, [g_e, g_e]) + sdot(X_s, g_ee)\n        ])\n\n        DW_ll = np.concatenate([\n            X_tt,\n            dot(g_x, X_tt),\n            dot(X_s, sdot(g_x,X_tt )) + X_tt\n        ])\n\n        K_ee += mdot( f2[:,:,n_v:], [V1, SW_ll])\n\n        K_ = np.tensordot(K_ee, sigma, axes=((2,3),(0,1)))\n\n        K_ += mdot(f2[:,:,n_s:], [V1, DW_ll])\n\n        def E(vec):\n            n = len(vec.shape)\n            return np.tensordot(vec,sigma,axes=((n-2,n-1),(0,1)))\n\n        L = sdot(g_sx,X_tt) + mdot(g_xx,[X_s,X_tt])\n\n        L += E(g_see + mdot(g_xee,[X_s,I_e,I_e]) )\n\n        M = E( mdot(X_sss,[V1_3, g_e, g_e]) + 2*mdot(X_ss, [V_sl,g_e]) )\n        M += mdot( X_ss, [V1_3, E( g_ee ) + sdot(g_x, X_tt)] )\n\n\n        A = f_x + dot( f_snext + dot(f_xnext,X_s), g_x) # same as before\n        B = f_xnext # same\n        C = V1_3 # same\n        D = K_ + dot( f_snext + dot(f_xnext,X_s), L) + dot( f_xnext, M )\n\n        if sigma2_correction is not None:\n            g_sl = sigma2_correction[1][:,:n_s]\n            g_xl = sigma2_correction[1][:,n_s:(n_s+n_x)]\n            D += dot( f_snext + dot(f_xnext,X_s), g_sl + dot(g_xl,X_s) )   # constant\n\n        X_stt = solve_sylvester(A,B,C,D)\n\n    if approx_order == 3:\n        if sigma is None:\n            return [X_s,X_ss,X_sss]\n        else:\n            return [[X_s,X_ss,X_sss],[X_tt, X_stt]]", "response": "Computes a Taylor approximation of decision rules given the supplied derivatives."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef qzordered(A,B,crit=1.0):\n    \"Eigenvalues bigger than crit are sorted in the top-left.\"\n\n    TOL = 1e-10\n\n    def select(alpha, beta):\n        return alpha**2>crit*beta**2\n\n    [S,T,alpha,beta,U,V] = ordqz(A,B,output='real',sort=select)\n\n    eigval = abs(numpy.diag(S)/numpy.diag(T))\n\n    return [S,T,U,V,eigval]", "response": "Eigenvalues bigger than crit are sorted in the top - left."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the QZ decomposition of two real matrices with reordering.", "response": "def ordqz(A, B, sort='lhp', output='real', overwrite_a=False,\n          overwrite_b=False, check_finite=True):\n    \"\"\"\n    QZ decomposition for a pair of matrices with reordering.\n\n    .. versionadded:: 0.17.0\n\n    Parameters\n    ----------\n    A : (N, N) array_like\n        2d array to decompose\n    B : (N, N) array_like\n        2d array to decompose\n    sort : {callable, 'lhp', 'rhp', 'iuc', 'ouc'}, optional\n        Specifies whether the upper eigenvalues should be sorted.  A callable\n        may be passed that, given a eigenvalue, returns a boolean denoting\n        whether the eigenvalue should be sorted to the top-left (True). For\n        real matrix pairs, the sort function takes three real arguments\n        (alphar, alphai, beta). The eigenvalue\n        ``x = (alphar + alphai*1j)/beta``.  For complex matrix pairs or\n        output='complex', the sort function takes two complex arguments\n        (alpha, beta). The eigenvalue ``x = (alpha/beta)``.\n        Alternatively, string parameters may be used:\n\n            - 'lhp'   Left-hand plane (x.real < 0.0)\n            - 'rhp'   Right-hand plane (x.real > 0.0)\n            - 'iuc'   Inside the unit circle (x*x.conjugate() < 1.0)\n            - 'ouc'   Outside the unit circle (x*x.conjugate() > 1.0)\n\n    output : str {'real','complex'}, optional\n        Construct the real or complex QZ decomposition for real matrices.\n        Default is 'real'.\n    overwrite_a : bool, optional\n        If True, the contents of A are overwritten.\n    overwrite_b : bool, optional\n        If True, the contents of B are overwritten.\n    check_finite : bool, optional\n        If true checks the elements of `A` and `B` are finite numbers. If\n        false does no checking and passes matrix through to\n        underlying algorithm.\n\n    Returns\n    -------\n    AA : (N, N) ndarray\n        Generalized Schur form of A.\n    BB : (N, N) ndarray\n        Generalized Schur form of B.\n    alpha : (N,) ndarray\n        alpha = alphar + alphai * 1j. See notes.\n    beta : (N,) ndarray\n        See notes.\n    Q : (N, N) ndarray\n        The left Schur vectors.\n    Z : (N, N) ndarray\n        The right Schur vectors.\n\n    Notes\n    -----\n    On exit, ``(ALPHAR(j) + ALPHAI(j)*i)/BETA(j), j=1,...,N``, will be the\n    generalized eigenvalues.  ``ALPHAR(j) + ALPHAI(j)*i`` and\n    ``BETA(j),j=1,...,N`` are the diagonals of the complex Schur form (S,T)\n    that would result if the 2-by-2 diagonal blocks of the real generalized\n    Schur form of (A,B) were further reduced to triangular form using complex\n    unitary transformations. If ALPHAI(j) is zero, then the j-th eigenvalue is\n    real; if positive, then the ``j``-th and ``(j+1)``-st eigenvalues are a complex\n    conjugate pair, with ``ALPHAI(j+1)`` negative.\n\n    See also\n    --------\n    qz\n    \"\"\"\n\n\n    import warnings\n\n    import numpy as np\n    from numpy import asarray_chkfinite\n\n    from scipy.linalg.misc import LinAlgError, _datacopied\n    from scipy.linalg.lapack import get_lapack_funcs\n\n    from scipy._lib.six import callable\n\n    from scipy.linalg._decomp_qz import _qz, _select_function\n\n    #NOTE: should users be able to set these?\n    lwork = None\n    result, typ = _qz(A, B, output=output, lwork=lwork, sort=None,\n                      overwrite_a=overwrite_a, overwrite_b=overwrite_b,\n                      check_finite=check_finite)\n    AA, BB, Q, Z = result[0], result[1], result[-4], result[-3]\n    if typ not in 'cz':\n        alpha, beta = result[3] + result[4]*1.j, result[5]\n    else:\n        alpha, beta = result[3], result[4]\n\n    sfunction = _select_function(sort)\n    select = sfunction(alpha, beta)\n\n    tgsen, = get_lapack_funcs(('tgsen',), (AA, BB))\n\n    if lwork is None or lwork == -1:\n        result = tgsen(select, AA, BB, Q, Z, lwork=-1)\n        lwork = result[-3][0].real.astype(np.int)\n        # looks like wrong value passed to ZTGSYL if not\n        lwork += 1\n\n    liwork = None\n    if liwork is None or liwork == -1:\n        result = tgsen(select, AA, BB, Q, Z, liwork=-1)\n        liwork = result[-2][0]\n\n    result = tgsen(select, AA, BB, Q, Z, lwork=lwork, liwork=liwork)\n\n    info = result[-1]\n    if info < 0:\n        raise ValueError(\"Illegal value in argument %d of tgsen\" % -info)\n    elif info == 1:\n        raise ValueError(\"Reordering of (A, B) failed because the transformed\"\n                         \" matrix pair (A, B) would be too far from \"\n                         \"generalized Schur form; the problem is very \"\n                         \"ill-conditioned. (A, B) may have been partially \"\n                         \"reorded. If requested, 0 is returned in DIF(*), \"\n                         \"PL, and PR.\")\n\n    # for real results has a, b, alphar, alphai, beta, q, z, m, pl, pr, dif,\n    # work, iwork, info\n    if typ in ['f', 'd']:\n        alpha = result[2] + result[3] * 1.j\n        return (result[0], result[1], alpha, result[4], result[5], result[6])\n    # for complex results has a, b, alpha, beta, q, z, m, pl, pr, dif, work,\n    # iwork, info\n    else:\n        return result[0], result[1], result[2], result[3], result[4], result[5]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parameterized_expectations(model, verbose=False, initial_dr=None,\n                               pert_order=1, with_complementarities=True,\n                               grid={}, distribution={},\n                               maxit=100, tol=1e-8, inner_maxit=10,\n                               direct=False):\n\n    '''\n    Find global solution for ``model`` via parameterized expectations.\n    Controls must be expressed as a direct function of equilibrium objects.\n    Algorithm iterates over the expectations function in the arbitrage equation.\n\n    Parameters:\n    ----------\n\n    model : NumericModel\n        ``dtcscc`` model to be solved\n\n    verbose : boolean\n        if True, display iterations\n\n    initial_dr : decision rule\n        initial guess for the decision rule\n\n    pert_order : {1}\n        if no initial guess is supplied, the perturbation solution at order\n        ``pert_order`` is used as initial guess\n\n    grid : grid options\n\n    distribution : distribution options\n\n    maxit : maximum number of iterations\n\n    tol : tolerance criterium for successive approximations\n\n    inner_maxit : maximum number of iteration for inner solver\n\n    direct : if True, solve with direct method. If false, solve indirectly\n\n    Returns\n    -------\n\n    decision rule :\n        approximated solution\n\n    '''\n\n    t1 = time.time()\n\n    g = model.functions['transition']\n    h = model.functions['expectation']\n    d = model.functions['direct_response']\n    f = model.functions['arbitrage_exp']  # f(s, x, z, p, out)\n    parms = model.calibration['parameters']\n\n    if initial_dr is None:\n        if pert_order == 1:\n            initial_dr = approximate_controls(model)\n\n        if pert_order > 1:\n            raise Exception(\"Perturbation order > 1 not supported (yet).\")\n\n    approx = model.get_grid(**grid)\n    grid = approx.grid\n    interp_type = approx.interpolation\n    dr = create_interpolator(approx, interp_type)\n    expect = create_interpolator(approx, interp_type)\n\n    distrib = model.get_distribution(**distribution)\n    nodes, weights = distrib.discretize()\n\n    N = grid.shape[0]\n    z = np.zeros((N, len(model.symbols['expectations'])))\n\n    x_0 = initial_dr(grid)\n    x_0 = x_0.real  # just in case ...\n    h_0 = h(grid, x_0, parms)\n\n    it = 0\n    err = 10\n    err_0 = 10\n\n    verbit = True if verbose == 'full' else False\n\n    if with_complementarities is True:\n        lbfun = model.functions['controls_lb']\n        ubfun = model.functions['controls_ub']\n        lb = lbfun(grid, parms)\n        ub = ubfun(grid, parms)\n    else:\n        lb = None\n        ub = None\n\n    if verbose:\n        headline = '|{0:^4} | {1:10} | {2:8} | {3:8} |'\n        headline = headline.format('N', ' Error', 'Gain', 'Time')\n        stars = '-'*len(headline)\n        print(stars)\n        print(headline)\n        print(stars)\n\n        # format string for within loop\n        fmt_str = '|{0:4} | {1:10.3e} | {2:8.3f} | {3:8.3f} |'\n\n    while err > tol and it <= maxit:\n\n        it += 1\n        t_start = time.time()\n\n        # dr.set_values(x_0)\n        expect.set_values(h_0)\n\n        # evaluate expectation over the future state\n        z[...] = 0\n        for i in range(weights.shape[0]):\n            e = nodes[i, :]\n            S = g(grid, x_0, e, parms)\n            z += weights[i]*expect(S)\n\n        if direct is True:\n            # Use control as direct function of arbitrage equation\n            new_x = d(grid, z, parms)\n            if with_complementarities is True:\n                new_x = np.minimum(new_x, ub)\n                new_x = np.maximum(new_x, lb)\n        else:\n            # Find control by solving arbitrage equation\n            def fun(x): return f(grid, x, z, parms)\n            sdfun = SerialDifferentiableFunction(fun)\n\n            if with_complementarities is True:\n                [new_x, nit] = ncpsolve(sdfun, lb, ub, x_0, verbose=verbit,\n                                        maxit=inner_maxit)\n            else:\n                [new_x, nit] = serial_newton(sdfun, x_0, verbose=verbit)\n\n        new_h = h(grid, new_x, parms)\n\n        # update error\n        err = (abs(new_h - h_0).max())\n\n        # Update guess for decision rule and expectations function\n        x_0 = new_x\n        h_0 = new_h\n\n        # print error infomation if `verbose`\n        err_SA = err/err_0\n        err_0 = err\n        t_finish = time.time()\n        elapsed = t_finish - t_start\n        if verbose:\n            print(fmt_str.format(it, err, err_SA, elapsed))\n\n    if it == maxit:\n        import warnings\n        warnings.warn(UserWarning(\"Maximum number of iterations reached\"))\n\n    # compute final fime and do final printout if `verbose`\n    t2 = time.time()\n    if verbose:\n        print(stars)\n        print('Elapsed: {} seconds.'.format(t2 - t1))\n        print(stars)\n\n    # Interpolation for the decision rule\n    dr.set_values(x_0)\n\n    return dr", "response": "Find global solution for model via parameterized expectations."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parameterized_expectations_direct(model, verbose=False, initial_dr=None,\n                                      pert_order=1, grid={}, distribution={},\n                                      maxit=100, tol=1e-8):\n    '''\n    Finds a global solution for ``model`` using parameterized expectations\n    function. Requires the model to be written with controls as a direct\n    function of the model objects.\n\n    The algorithm iterates on the expectations function in the arbitrage\n    equation. It follows the discussion in section 9.9 of Miranda and\n    Fackler (2002).\n\n    Parameters\n    ----------\n    model : NumericModel\n        \"dtcscc\" model to be solved\n    verbose : boolean\n        if True, display iterations\n    initial_dr : decision rule\n        initial guess for the decision rule\n    pert_order : {1}\n        if no initial guess is supplied, the perturbation solution at order\n        ``pert_order`` is used as initial guess\n    grid: grid options\n    distribution: distribution options\n    maxit: maximum number of iterations\n    tol: tolerance criterium for successive approximations\n\n    Returns\n    -------\n    decision rule :\n        approximated solution\n    '''\n\n    t1 = time.time()\n    g = model.functions['transition']\n    d = model.functions['direct_response']\n    h = model.functions['expectation']\n    parms = model.calibration['parameters']\n\n    if initial_dr is None:\n        if pert_order == 1:\n            initial_dr = approximate_controls(model)\n\n        if pert_order > 1:\n            raise Exception(\"Perturbation order > 1 not supported (yet).\")\n\n    approx = model.get_grid(**grid)\n    grid = approx.grid\n    interp_type = approx.interpolation\n    dr = create_interpolator(approx, interp_type)\n    expect = create_interpolator(approx, interp_type)\n\n    distrib = model.get_distribution(**distribution)\n    nodes, weights = distrib.discretize()\n\n    N = grid.shape[0]\n    z = np.zeros((N, len(model.symbols['expectations'])))\n\n    x_0 = initial_dr(grid)\n    x_0 = x_0.real  # just in case ...\n    h_0 = h(grid, x_0, parms)\n\n    it = 0\n    err = 10\n    err_0 = 10\n\n    if verbose:\n        headline = '|{0:^4} | {1:10} | {2:8} | {3:8} |'\n        headline = headline.format('N', ' Error', 'Gain', 'Time')\n        stars = '-'*len(headline)\n        print(stars)\n        print(headline)\n        print(stars)\n\n        # format string for within loop\n        fmt_str = '|{0:4} | {1:10.3e} | {2:8.3f} | {3:8.3f} |'\n\n    while err > tol and it <= maxit:\n\n        it += 1\n        t_start = time.time()\n\n        # dr.set_values(x_0)\n        expect.set_values(h_0)\n\n        z[...] = 0\n        for i in range(weights.shape[0]):\n            e = nodes[i, :]\n            S = g(grid, x_0, e, parms)\n            # evaluate expectation over the future state\n            z += weights[i]*expect(S)\n\n        # TODO: check that control is admissible\n        new_x = d(grid, z, parms)\n        new_h = h(grid, new_x, parms)\n\n        # update error\n        err = (abs(new_h - h_0).max())\n\n        # Update guess for decision rule and expectations function\n        x_0 = new_x\n        h_0 = new_h\n\n        # print error information if `verbose`\n        err_SA = err/err_0\n        err_0 = err\n        t_finish = time.time()\n        elapsed = t_finish - t_start\n        if verbose:\n            print(fmt_str.format(it, err, err_SA, elapsed))\n\n    if it == maxit:\n        import warnings\n        warnings.warn(UserWarning(\"Maximum number of iterations reached\"))\n\n    # compute final fime and do final printout if `verbose`\n    t2 = time.time()\n    if verbose:\n        print(stars)\n        print('Elapsed: {} seconds.'.format(t2 - t1))\n        print(stars)\n\n    # Interpolation for the decision rule\n    dr.set_values(x_0)\n\n    return dr", "response": "Returns a global solution for a model using parameterized expectations."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprinting s with additional debugging informations", "response": "def dprint(s):\n    '''Prints `s` with additional debugging informations'''\n\n    import inspect\n\n    frameinfo = inspect.stack()[1]\n    callerframe = frameinfo.frame\n    d = callerframe.f_locals\n\n    if (isinstance(s,str)):\n        val = eval(s, d)\n    else:\n        val = s\n        cc = frameinfo.code_context[0]\n        import re\n        regex = re.compile(\"dprint\\((.*)\\)\")\n        res = regex.search(cc)\n        s = res.group(1)\n\n    text = ''\n    text += bcolors.OKBLUE + \"At <{}>\\n\".format(str(frameinfo)) + bcolors.ENDC\n    text += bcolors.WARNING + \"{}:  \".format(s) + bcolors.ENDC\n    text += str(val)\n    text += str()\n\n    print(text)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef numdiff2(f, x0, dv=1e-8):\n    '''Returns the derivative of f w.r.t. to multidimensional vector x0\nIf x0 is of dimension R1 x ... x Rd dimension of f is assumed to be\nin the form S1 x ... x Sf x Rn. The last dimension corresponds to various\nobservations. The value returned is of dimension :\nS1 x ... x Sf x R1 x ... x Rd x Rn\n    '''\n\n    dd = x0.shape\n    f0 = f(x0)\n    nobs = f0.shape[-1]\n    f_shape = f0.shape[:-1]\n\n    out_shape = f_shape + dd + (nobs,)\n    ret = np.zeros(out_shape)\n\n\n    for ind in product( *[range(i) for i in dd] ):\n        x = x0.copy()\n        x[ind] += dv\n        x2 = x0.copy()\n        x2[ind] -= dv\n        df = (f(x) - f(x2))/dv/2.0\n        obj = [ Ellipsis] +  list(ind) + [slice(None, None, None)]\n        #obj = tuple(obj)\n        ret[obj] = df\n\n    return ret", "response": "Returns the derivative of f w. r. t. to multidimensional vector x0"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef perturb(model, verbose=False, steady_state=None, eigmax=1.0-1e-6,\n                         solve_steady_state=False, order=1, details=True):\n    \"\"\"Compute first order approximation of optimal controls\n\n    Parameters:\n    -----------\n\n    model: NumericModel\n        Model to be solved\n\n    verbose: boolean\n        If True: displays number of contracting eigenvalues\n\n    steady_state: ndarray\n        Use supplied steady-state value to compute the approximation.\n        The routine doesn't check whether it is really a solution or not.\n\n    solve_steady_state: boolean\n        Use nonlinear solver to find the steady-state\n\n    orders: {1}\n        Approximation order. (Currently, only first order is supported).\n\n    Returns:\n    --------\n\n    TaylorExpansion:\n        Decision Rule for the optimal controls around the steady-state.\n\n    \"\"\"\n\n    if order > 1:\n        raise Exception(\"Not implemented.\")\n\n    if steady_state is None:\n        steady_state = model.calibration\n\n    G_s, G_x, G_e, F_s, F_x, F_S, F_X = get_derivatives(model, steady_state=steady_state)\n\n    C, eigvals = approximate_1st_order(G_s, G_x, G_e, F_s, F_x, F_S, F_X)\n\n    m = steady_state['exogenous']\n    s = steady_state['states']\n    x = steady_state['controls']\n\n    from dolo.numeric.processes import VAR1\n    from dolo.numeric.processes import MvNormal\n\n    process = model.exogenous\n\n    if isinstance(process, VAR1):\n        C_m = C[:,:len(m)]\n        C_s = C[:,len(m):]\n    elif isinstance(process, MvNormal):\n        C_m = None\n        C_s = C\n    dr = BivariateTaylor(m,s,x,C_m,C_s)\n    if not details:\n        return dr\n    else:\n        return PerturbationResult(\n            dr,\n            eigvals,\n            True, # otherwise an Exception should have been raised already\n            True, # otherwise an Exception should have been raised already\n            True  # otherwise an Exception should have been raised already\n        )", "response": "Computes the first order approximation of optimal controls around the current state."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef deterministic_solve(model, shocks=None, start_states=None, T=100,\n                        ignore_constraints=False, maxit=100,\n                        initial_guess=None, verbose=False, tol=1e-6):\n    \"\"\"\n    Computes a perfect foresight simulation using a stacked-time algorithm.\n\n    The initial state is specified either by providing a series of exogenous\n    shocks and assuming the model is initially in equilibrium with the first\n    value of the shock, or by specifying an initial value for the states.\n\n    Parameters\n    ----------\n    model : NumericModel\n        \"dtcscc\" model to be solved\n    shocks : array-like, dict, or pandas.DataFrame\n        A specification of the shocks to the model. Can be any of the\n        following (note by \"declaration order\" below we mean the order\n        of `model.symbols[\"shocks\"]`):\n\n        - A 1d numpy array-like specifying a time series for a single\n          shock, or all shocks stacked into a single array.\n        - A 2d numpy array where each column specifies the time series\n          for one of the shocks in declaration order. This must be an\n          `N` by number of shocks 2d array.\n        - A dict where keys are strings found in\n          `model.symbols[\"shocks\"]` and values are a time series of\n          values for that shock. For model shocks that do not appear in\n          this dict, the shock is set to the calibrated value. Note\n          that this interface is the most flexible as it allows the user\n          to pass values for only a subset of the model shocks and it\n          allows the passed time series to be of different lengths.\n        - A DataFrame where columns map shock names into time series.\n          The same assumptions and behavior that are used in the dict\n          case apply here\n\n        If nothing is given here, `shocks` is set equal to the\n        calibrated values found in `model.calibration[\"shocks\"]` for\n        all periods.\n\n        If the length of any time-series in shocks is less than `T`\n        (see below) it is assumed that that particular shock will\n        remain at the final given value for the duration of the\n        simulaiton.\n    start_states : ndarray or dict\n        a vector with the value of initial states, or a calibration\n        dictionary with the initial values of states and controls\n    T : int\n        horizon for the perfect foresight simulation\n    maxit : int\n        maximum number of iteration for the nonlinear solver\n    verbose : boolean\n        if True, the solver displays iterations\n    tol : float\n        stopping criterium for the nonlinear solver\n    ignore_constraints : bool\n        if True, complementarity constraints are ignored.\n\n    Returns\n    -------\n    pandas dataframe\n        a dataframe with T+1 observations of the model variables along the\n        simulation (states, controls, auxiliaries). The first observation is\n        the steady-state corresponding to the first value of the shocks. The\n        simulation should return to a steady-state corresponding to the last\n        value of the exogenous shocks.\n\n    \"\"\"\n\n    # TODO:\n\n    # if model.model_spec == 'fga':\n    #     from dolo.compiler.converter import GModel_fg_from_fga\n    #     model = GModel_fg_from_fga(model)\n\n    # definitions\n    n_s = len(model.calibration['states'])\n    n_x = len(model.calibration['controls'])\n\n    epsilons = _shocks_to_epsilons(model, shocks, T)\n\n    # final initial and final steady-states consistent with exogenous shocks\n    if start_states is None:\n        start_states = model.calibration\n\n    if isinstance(start_states, dict):\n        # at least that part is clear\n        start_equilibrium = start_states\n        start_s = start_equilibrium['states']\n        start_x = start_equilibrium['controls']\n        final_s = start_equilibrium['states']\n        final_x = start_equilibrium['controls']\n    elif isinstance(start_states, np.ndarray):\n        start_s = start_states\n        start_x = model.calibration['controls']\n        final_s = model.calibration['states']\n        final_x = model.calibration['controls']\n\n    # if start_constraints:\n    #     # we ignore start_constraints\n    #     start_dict.update(start_constraints)\n    #     final_equilibrium = start_constraints.copy()\n    # else:\n    #     final_eqm = find_deterministic_equilibrium(model,\n    #                                                constraints=final_dict)\n    # final_s = final_eqm['states']\n    # final_x = final_eqm['controls']\n    #\n    # start_s = start_states\n    # start_x = final_x\n\n    # TODO: for start_x, it should be possible to use first order guess\n\n    final = np.concatenate([final_s, final_x])\n    start = np.concatenate([start_s, start_x])\n\n    if verbose is True:\n        print(\"Initial states : {}\".format(start_s))\n        print(\"Final controls : {}\".format(final_x))\n\n    p = model.calibration['parameters']\n\n    if initial_guess is None:\n        initial_guess = np.row_stack([start*(1-l) + final*l\n                                         for l in linspace(0.0, 1.0, T+1)])\n\n    else:\n        if isinstance(initial_guess, pd.DataFrame):\n            initial_guess = np.array(initial_guess).T.copy()\n        initial_guess = initial_guess[:, :n_s+n_x]\n        initial_guess[0, :n_s] = start_s\n        initial_guess[-1, n_s:] = final_x\n\n    sh = initial_guess.shape\n\n    if model.x_bounds and not ignore_constraints:\n        initial_states = initial_guess[:, :n_s]\n        [lb, ub] = [u(initial_states, p) for u in model.x_bounds]\n        lower_bound = initial_guess*0 - np.inf\n        lower_bound[:, n_s:] = lb\n        upper_bound = initial_guess*0 + np.inf\n        upper_bound[:, n_s:] = ub\n        test1 = max(lb.max(axis=0) - lb.min(axis=0))\n        test2 = max(ub.max(axis=0) - ub.min(axis=0))\n        if test1 > 0.00000001 or test2 > 0.00000001:\n            msg = \"Not implemented: perfect foresight solution requires that \"\n            msg += \"controls have constant bounds.\"\n            raise Exception(msg)\n    else:\n        ignore_constraints = True\n        lower_bound = None\n        upper_bound = None\n\n    nn = sh[0]*sh[1]\n\n    def fobj(vec):\n        o = det_residual(model, vec.reshape(sh), start_s, final_x, epsilons)[0]\n        return o.ravel()\n\n    if not ignore_constraints:\n        def ff(vec):\n            return det_residual(model, vec.reshape(sh), start_s, final_x,\n                                epsilons, jactype='sparse')\n\n        x0 = initial_guess.ravel()\n        sol, nit = ncpsolve(ff, lower_bound.ravel(), upper_bound.ravel(),\n                            initial_guess.ravel(), verbose=verbose,\n                            maxit=maxit, tol=tol, jactype='sparse')\n\n        sol = sol.reshape(sh)\n\n    else:\n\n        def ff(vec):\n            return det_residual(model, vec.reshape(sh), start_s, final_x,\n                                epsilons, diff=False).ravel()\n\n        x0 = initial_guess.ravel()\n        sol = root(ff, x0, jac=False)\n        res = ff(sol.x)\n        sol = sol.x.reshape(sh)\n\n    if 'auxiliary' in model.functions:\n        colnames = (model.symbols['states'] + model.symbols['controls'] +\n                    model.symbols['auxiliaries'])\n        # compute auxiliaries\n        y = model.functions['auxiliary'](sol[:, :n_s], sol[:, n_s:], p)\n        sol = np.column_stack([sol, y])\n    else:\n        colnames = model.symbols['states'] + model.symbols['controls']\n\n    sol = np.column_stack([sol, epsilons])\n    colnames = colnames + model.symbols['shocks']\n\n    ts = pd.DataFrame(sol, columns=colnames)\n    return ts", "response": "Solve a deterministic foresight simulation using a stacked - time algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting an AST expression to a sympy expression ( STUPID )", "response": "def ast_to_sympy(expr):\n    '''Converts an AST expression to a sympy expression (STUPID)'''\n    from dolang import to_source\n    s = to_source(expr)\n    not_to_be_treated_as_functions = ['alpha','beta', 'gamma','zeta', 'Chi']\n    d = {v: sympy.Symbol(v) for v in not_to_be_treated_as_functions}\n    return sympy.sympify(s, locals=d)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlists all combinations of 0... n - 1 in increasing order", "response": "def non_decreasing_series(n, size):\n    '''Lists all combinations of 0,...,n-1 in increasing order'''\n\n    if size == 1:\n        return [[a] for a in range(n)]\n    else:\n        lc = non_decreasing_series(n, size-1)\n        ll = []\n        for l in lc:\n            last = l[-1]\n            for i in range(last, n):\n                e = l + [i]\n                ll.append(e)\n        return ll"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef higher_order_diff(eqs, syms, order=2):\n    '''Takes higher order derivatives of a list of equations w.r.t a list of paramters'''\n\n    import numpy\n\n    eqs = list([sympy.sympify(eq) for eq in eqs])\n    syms = list([sympy.sympify(s) for s in syms])\n\n    neq = len(eqs)\n    p = len(syms)\n\n    D = [numpy.array(eqs)]\n    orders = []\n\n    for i in range(1,order+1):\n\n        par = D[i-1]\n        mat = numpy.empty([neq] + [p]*i, dtype=object)   #.append( numpy.zeros(orders))\n        for ind in non_decreasing_series(p,i):\n\n            ind_parent = ind[:-1]\n            k = ind[-1]\n\n            for line in range(neq):\n\n                ii = [line] + ind\n                iid = [line] + ind_parent\n                eeq = par[ tuple(iid) ]\n                mat[tuple(ii)] = eeq.diff(syms[k])\n\n        D.append(mat)\n\n    return D", "response": "Takes higher order derivatives of a list of equations w. r. t a list of paramters"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef eval_formula(expr: str, dataframe=None, context=None):\n    '''\n    expr: string\n        Symbolic expression to evaluate.\n        Example: `k(1)-delta*k(0)-i`\n    table: (optional) pandas dataframe\n        Each column is a time series, which can be indexed with dolo notations.\n    context: dict or CalibrationDict\n    '''\n\n    if context is None:\n        dd = {}  # context dictionary\n    elif isinstance(context, CalibrationDict):\n        dd = context.flat.copy()\n    else:\n        dd = context.copy()\n\n    # compat since normalize form for parameters doesn't match calib dict.\n    for k in [*dd.keys()]:\n        dd[stringify_symbol(k)] = dd[k]\n\n    expr_ast = parse_string(expr).value\n    variables = list_variables(expr_ast)\n    nexpr = stringify(expr_ast)\n\n\n    dd['log'] = log\n    dd['exp'] = exp\n\n    if dataframe is not None:\n\n        import pandas as pd\n        for (k, t) in variables:\n            dd[stringify_symbol((k, t))] = dataframe[k].shift(t)\n        dd['t_'] = pd.Series(dataframe.index, index=dataframe.index)\n\n    expr = to_source(nexpr)\n\n    res = eval(expr, dd)\n\n    return res", "response": "Evaluate a symbolic expression."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef value_iteration(model,\n                    grid={},\n                    tol=1e-6,\n                    maxit=500,\n                    maxit_howard=20,\n                    verbose=False,\n                    details=True):\n    \"\"\"\n    Solve for the value function and associated Markov decision rule by iterating over\n    the value function.\n\n    Parameters:\n    -----------\n    model :\n        \"dtmscc\" model. Must contain a 'felicity' function.\n    grid :\n        grid options\n    dr :\n        decision rule to evaluate\n\n    Returns:\n    --------\n    mdr : Markov decision rule\n        The solved decision rule/policy function\n    mdrv: decision rule\n        The solved value function\n    \"\"\"\n\n    transition = model.functions['transition']\n    felicity = model.functions['felicity']\n    controls_lb = model.functions['controls_lb']\n    controls_ub = model.functions['controls_ub']\n\n    parms = model.calibration['parameters']\n    discount = model.calibration['beta']\n\n    x0 = model.calibration['controls']\n    m0 = model.calibration['exogenous']\n    s0 = model.calibration['states']\n    r0 = felicity(m0, s0, x0, parms)\n\n    process = model.exogenous\n    dprocess = process.discretize()\n\n    n_ms = dprocess.n_nodes()  # number of exogenous states\n    n_mv = dprocess.n_inodes(\n        0)  # this assume number of integration nodes is constant\n\n    endo_grid = model.get_grid(**grid)\n\n    exo_grid = dprocess.grid\n\n    mdrv = DecisionRule(exo_grid, endo_grid)\n\n    grid = mdrv.endo_grid.nodes()\n    N = grid.shape[0]\n    n_x = len(x0)\n\n    mdr = constant_policy(model)\n    \n    controls_0 = np.zeros((n_ms, N, n_x))\n    for i_ms in range(n_ms):\n        controls_0[i_ms, :, :] = mdr.eval_is(i_ms, grid)\n\n    values_0 = np.zeros((n_ms, N, 1))\n    # for i_ms in range(n_ms):\n    #     values_0[i_ms, :, :] = mdrv(i_ms, grid)\n\n    mdr = DecisionRule(exo_grid, endo_grid)\n    # mdr.set_values(controls_0)\n\n    # THIRD: value function iterations until convergence\n    it = 0\n    err_v = 100\n    err_v_0 = 0\n    gain_v = 0.0\n    err_x = 100\n    err_x_0 = 0\n    tol_x = 1e-5\n    tol_v = 1e-7\n\n    itprint = IterationsPrinter(\n        ('N', int), ('Error_V', float), ('Gain_V', float), ('Error_x', float),\n        ('Gain_x', float), ('Eval_n', int), ('Time', float),\n        verbose=verbose)\n    itprint.print_header('Start value function iterations.')\n\n    while (it < maxit) and (err_v > tol or err_x > tol_x):\n\n        t_start = time.time()\n        it += 1\n\n        mdr.set_values(controls_0)\n        if it > 2:\n            ev = evaluate_policy(\n                model, mdr, initial_guess=mdrv, verbose=False, details=True)\n        else:\n            ev = evaluate_policy(model, mdr, verbose=False, details=True)\n\n        mdrv = ev.solution\n        for i_ms in range(n_ms):\n            values_0[i_ms, :, :] = mdrv.eval_is(i_ms, grid)\n\n        values = values_0.copy()\n        controls = controls_0.copy()\n\n        for i_m in range(n_ms):\n            m = dprocess.node(i_m)\n            for n in range(N):\n                s = grid[n, :]\n                x = controls[i_m, n, :]\n                lb = controls_lb(m, s, parms)\n                ub = controls_ub(m, s, parms)\n                bnds = [e for e in zip(lb, ub)]\n\n                def valfun(xx):\n                    return -choice_value(transition, felicity, i_m, s, xx,\n                                         mdrv, dprocess, parms, discount)[0]\n\n                res = scipy.optimize.minimize(valfun, x, bounds=bnds)\n                controls[i_m, n, :] = res.x\n                values[i_m, n, 0] = -valfun(x)\n\n        # compute error, update value and dr\n        err_x = abs(controls - controls_0).max()\n        err_v = abs(values - values_0).max()\n        t_end = time.time()\n        elapsed = t_end - t_start\n\n        values_0 = values\n        controls_0 = controls\n\n        gain_x = err_x / err_x_0\n        gain_v = err_v / err_v_0\n\n        err_x_0 = err_x\n        err_v_0 = err_v\n\n        itprint.print_iteration(\n            N=it,\n            Error_V=err_v,\n            Gain_V=gain_v,\n            Error_x=err_x,\n            Gain_x=gain_x,\n            Eval_n=ev.iterations,\n            Time=elapsed)\n\n    itprint.print_finished()\n\n    mdr = DecisionRule(exo_grid, endo_grid)\n    mdr.set_values(controls)\n    mdrv.set_values(values_0)\n\n    if not details:\n        return mdr, mdrv\n    else:\n        return ValueIterationResult(\n            mdr,             #:AbstractDecisionRule\n            mdrv,            #:AbstractDecisionRule\n            it,              #:Int\n            dprocess,        #:AbstractDiscretizedProcess\n            err_x<tol_x,     #:Bool\n            tol_x,           #:Float64\n            err_x,           #:Float64\n            err_v<tol_v,     #:Bool\n            tol_v,           #:Float64\n            err_v,           #:Float64\n            None,            #log:     #:ValueIterationLog\n            None             #trace:   #:Union{Nothing,IterationTrace\n        )", "response": "This function solves the value function and associated Markov decision rule by iterating over the value function and associated Markov decision rule by evaluating the value function."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef evaluate_policy(model,\n                    mdr,\n                    tol=1e-8,\n                    maxit=2000,\n                    grid={},\n                    verbose=True,\n                    initial_guess=None,\n                    hook=None,\n                    integration_orders=None,\n                    details=False,\n                    interp_type='cubic'):\n    \"\"\"Compute value function corresponding to policy ``dr``\n\n    Parameters:\n    -----------\n\n    model:\n        \"dtcscc\" model. Must contain a 'value' function.\n\n    mdr:\n        decision rule to evaluate\n\n    Returns:\n    --------\n\n    decision rule:\n        value function (a function of the space similar to a decision rule\n        object)\n\n    \"\"\"\n\n    process = model.exogenous\n    dprocess = process.discretize()\n\n    n_ms = dprocess.n_nodes()  # number of exogenous states\n    n_mv = dprocess.n_inodes(\n        0)  # this assume number of integration nodes is constant\n\n    x0 = model.calibration['controls']\n    v0 = model.calibration['values']\n    parms = model.calibration['parameters']\n    n_x = len(x0)\n    n_v = len(v0)\n    n_s = len(model.symbols['states'])\n\n    endo_grid = model.get_grid(**grid)\n    exo_grid = dprocess.grid\n\n    if initial_guess is not None:\n        mdrv = initial_guess\n    else:\n        mdrv = DecisionRule(exo_grid, endo_grid, interp_type=interp_type)\n\n    grid = mdrv.endo_grid.nodes()\n    N = grid.shape[0]\n\n    if isinstance(mdr, np.ndarray):\n        controls = mdr\n    else:\n        controls = np.zeros((n_ms, N, n_x))\n        for i_m in range(n_ms):\n            controls[i_m, :, :] = mdr.eval_is(i_m, grid)\n\n    values_0 = np.zeros((n_ms, N, n_v))\n    if initial_guess is None:\n        for i_m in range(n_ms):\n            values_0[i_m, :, :] = v0[None, :]\n    else:\n        for i_m in range(n_ms):\n            values_0[i_m, :, :] = initial_guess.eval_is(i_m, grid)\n\n    val = model.functions['value']\n    g = model.functions['transition']\n\n    sh_v = values_0.shape\n\n    err = 10\n    inner_maxit = 50\n    it = 0\n\n    if verbose:\n        headline = '|{0:^4} | {1:10} | {2:8} | {3:8} |'.format(\n            'N', ' Error', 'Gain', 'Time')\n        stars = '-' * len(headline)\n        print(stars)\n        print(headline)\n        print(stars)\n\n    t1 = time.time()\n\n    err_0 = np.nan\n\n    verbit = (verbose == 'full')\n\n    while err > tol and it < maxit:\n\n        it += 1\n\n        t_start = time.time()\n\n        mdrv.set_values(values_0.reshape(sh_v))\n        values = update_value(val, g, grid, controls, values_0, mdr, mdrv,\n                              dprocess, parms).reshape((-1, n_v))\n        err = abs(values.reshape(sh_v) - values_0).max()\n\n        err_SA = err / err_0\n        err_0 = err\n\n        values_0 = values.reshape(sh_v)\n\n        t_finish = time.time()\n        elapsed = t_finish - t_start\n\n        if verbose:\n            print('|{0:4} | {1:10.3e} | {2:8.3f} | {3:8.3f} |'.format(\n                it, err, err_SA, elapsed))\n\n    # values_0 = values.reshape(sh_v)\n\n    t2 = time.time()\n\n    if verbose:\n        print(stars)\n        print(\"Elapsed: {} seconds.\".format(t2 - t1))\n        print(stars)\n\n    if not details:\n        return mdrv\n    else:\n        return EvaluationResult(mdrv, it, tol, err)", "response": "Evaluate the policy dr"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a new random state tree from a model.", "response": "def gssa(model, maxit=100, tol=1e-8, initial_dr=None, verbose=False,\n         n_sim=10000, deg=3, damp=0.1, seed=42):\n    \"\"\"\n    Sketch of algorithm:\n\n    0. Choose levels for the initial states and the simulation length (n_sim)\n    1. Obtain an initial decision rule -- here using first order perturbation\n    2. Draw a sequence of innovations epsilon\n    3. Iterate on the following steps:\n        - Use the epsilons, initial states, and proposed decision rule to\n          simulate model forward. Will leave us with time series of states and\n          controls\n        - Evaluate expectations using quadrature\n        - Use direct response to get alternative proposal for controls\n        - Regress updated controls on the simulated states to get proposal\n          coefficients. New coefficients are convex combination of previous\n          coefficients and proposal coefficients. Weights controlled by damp,\n          where damp is the weight on the old coefficients. This should be\n          fairly low to increase chances of convergence.\n        - Check difference between the simulated series of controls and the\n          direct response version of controls\n\n    \"\"\"\n    # verify input arguments\n    if deg < 0 or deg > 5:\n        raise ValueError(\"deg must be in [1, 5]\")\n\n    if damp < 0 or damp > 1:\n        raise ValueError(\"damp must be in [0, 1]\")\n\n    t1 = time.time()\n\n    # extract model functions and parameters\n    g = model.__original_functions__['transition']\n    g_gu = model.__original_gufunctions__['transition']\n    h_gu = model.__original_gufunctions__['expectation']\n    d_gu = model.__original_gufunctions__['direct_response']\n    p = model.calibration['parameters']\n    n_s = len(model.symbols[\"states\"])\n    n_x = len(model.symbols[\"controls\"])\n    n_z = len(model.symbols[\"expectations\"])\n    n_eps = len(model.symbols[\"shocks\"])\n    s0 = model.calibration[\"states\"]\n    x0 = model.calibration[\"controls\"]\n\n    # construct initial decision rule if not supplied\n    if initial_dr is None:\n        drp = approximate_controls(model)\n    else:\n        drp = initial_dr\n\n    # set up quadrature weights and nodes\n    distrib = model.get_distribution()\n    nodes, weights = distrib.discretize()\n\n    # draw sequence of innovations\n    np.random.seed(seed)\n    distrib = model.get_distribution()\n    sigma = distrib.sigma\n    epsilon = np.random.multivariate_normal(np.zeros(n_eps), sigma, n_sim)\n\n    # simulate initial decision rule and do initial regression for coefs\n    init_sim = simulate(model, drp, horizon=n_sim, return_array=True,\n                        forcing_shocks=epsilon)\n    s_sim = init_sim[:, 0, 0:n_s]\n    x_sim = init_sim[:, 0, n_s:n_s + n_x]\n    Phi_sim = complete_polynomial(s_sim.T, deg).T\n    coefs = np.ascontiguousarray(lstsq(Phi_sim, x_sim)[0])\n\n    # NOTE: the ascontiguousarray above was needed for numba to compile the\n    #       `np.dot` in the simulation function in no python mode. Appearantly\n    #       the array returned from lstsq is not C-contiguous\n\n    # allocate for simulated series of expectations and next period states\n    z_sim = np.empty((n_sim, n_z))\n    S = np.empty_like(s_sim)\n    X = np.empty_like(x_sim)\n    H = np.empty_like(z_sim)\n    new_x = np.empty_like(x_sim)\n\n    # set initial states and controls\n    s_sim[0, :] = s0\n    x_sim[0, :] = x0\n\n    Phi_t = np.empty(n_complete(n_s, deg))  # buffer array for simulation\n\n    # create jitted function that will simulate states and controls, using\n    # the epsilon shocks from above (define here as closure over all data\n    # above).\n    @jit(nopython=True)\n    def simulate_states_controls(s, x, Phi_t, coefs):\n        for t in range(1, n_sim):\n            g(s[t - 1, :], x[t - 1, :], epsilon[t, :], p, s[t, :])\n\n            # fill Phi_t with new complete poly version of s[t, :]\n            _complete_poly_impl_vec(s[t, :], deg, Phi_t)\n\n            # do inner product to get new controls\n            x[t, :] = Phi_t @coefs\n\n    it = 0\n    err = 10.0\n    err_0 = 10\n\n    if verbose:\n        headline = '|{0:^4} | {1:10} | {2:8} | {3:8} |'\n        headline = headline.format('N', ' Error', 'Gain', 'Time')\n        stars = '-' * len(headline)\n        print(stars)\n        print(headline)\n        print(stars)\n\n        # format string for within loop\n        fmt_str = '|{0:4} | {1:10.3e} | {2:8.3f} | {3:8.3f} |'\n\n    while err > tol and it <= maxit:\n        t_start = time.time()\n\n        # simulate with new coefficients\n        simulate_states_controls(s_sim, x_sim, Phi_t, coefs)\n\n        # update expectations of z\n        # update_expectations(s_sim, x_sim, z_sim, Phi_sim)\n        z_sim[:, :] = 0.0\n        for i in range(weights.shape[0]):\n            e = nodes[i, :]  # extract nodes\n            # evaluate future states at each node (stores in S)\n            g_gu(s_sim, x_sim, e, p, S)\n\n            # evaluate future controls at each future state\n            _complete_poly_impl(S.T, deg, Phi_sim.T)\n            np.dot(Phi_sim, coefs, out=X)\n\n            # compute expectation (stores in H)\n            h_gu(S, X, p, H)\n            z_sim += weights[i] * H\n\n        # get controls on the simulated points from direct_resposne\n        # (stores in new_x)\n        d_gu(s_sim, z_sim, p, new_x)\n\n        # update basis matrix and do regression of new_x on s_sim to get\n        # updated coefficients\n        _complete_poly_impl(s_sim.T, deg, Phi_sim.T)\n        new_coefs = np.ascontiguousarray(lstsq(Phi_sim, new_x)[0])\n\n        # check whether they differ from the preceding guess\n        err = (abs(new_x - x_sim).max())\n\n        # update the series of controls and coefficients\n        x_sim[:, :] = new_x\n        coefs = (1 - damp) * new_coefs + damp * coefs\n\n        if verbose:\n            # update error and print if `verbose`\n            err_SA = err / err_0\n            err_0 = err\n            t_finish = time.time()\n            elapsed = t_finish - t_start\n            if verbose:\n                print(fmt_str.format(it, err, err_SA, elapsed))\n\n        it += 1\n\n    if it == maxit:\n        warnings.warn(UserWarning(\"Maximum number of iterations reached\"))\n\n    # compute final fime and do final printout if `verbose`\n    t2 = time.time()\n    if verbose:\n        print(stars)\n        print('Elapsed: {} seconds.'.format(t2 - t1))\n        print(stars)\n\n    cp = CompletePolynomial(deg, len(s0))\n    cp.fit_values(s_sim, x_sim)\n    return cp"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchanges current directory to the root of the project.", "response": "def groot(path=''):\n    \"Changes current directory to the root of the project (looks for README.md).\"\n\n    def check_filelist(l):\n        if ('README.md' in l) or ('README' in l):\n            return True\n        else:\n            return False\n\n    import os, copy\n    cwd = os.getcwd()  # initial dir\n    cwd0 = copy.copy(cwd)\n    cwd_init = copy.copy(cwd)\n\n    found = False\n    sysroot = False\n\n    while not found and not sysroot:\n        found = check_filelist(os.listdir())\n        if not found:\n            os.chdir(os.path.join(cwd, os.pardir))\n            cwd = os.getcwd()\n            if cwd == cwd0:\n                sysroot = True\n            else:\n                cwd0 = cwd\n        else:\n            os.chdir(os.path.join(cwd0, path))\n\n    if sysroot:\n        os.chdir(cwd_init)\n        raise Exception(\"Root directory not found.\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing a Taylor approximation of decision rules given the supplied derivatives of the state of the problem.", "response": "def state_perturb(problem: PerturbationProblem, verbose=True):\n    \"\"\"Computes a Taylor approximation of decision rules, given the supplied derivatives.\n\n    The original system is assumed to be in the the form:\n\n    .. math::\n\n        E_t f(s_t,x_t,s_{t+1},x_{t+1})\n\n        s_t = g(s_{t-1},x_{t-1}, \\\\lambda \\\\epsilon_t)\n\n    where :math:`\\\\lambda` is a scalar scaling down the risk.  the solution is a function :math:`\\\\varphi` such that:\n\n    .. math::\n\n        x_t = \\\\varphi ( s_t, \\\\sigma )\n\n    The user supplies, a list of derivatives of f and g.\n\n    :param f_fun: list of derivatives of f [order0, order1, order2, ...]\n    :param g_fun: list of derivatives of g [order0, order1, order2, ...]\n    :param sigma: covariance matrix of :math:`\\\\epsilon_t`\n\n\n    Assuming :math:`s_t` ,  :math:`x_t` and :math:`\\\\epsilon_t` are vectors of size\n    :math:`n_s`, :math:`n_x`  and :math:`n_x`  respectively.\n    In general the derivative of order :math:`i` of :math:`f`  is a multimensional array of size :math:`n_x \\\\times (N, ..., N)`\n    with :math:`N=2(n_s+n_x)` repeated :math:`i` times (possibly 0).\n    Similarly the derivative of order :math:`i` of :math:`g`  is a multidimensional array of size :math:`n_s \\\\times (M, ..., M)`\n    with :math:`M=n_s+n_x+n_2` repeated :math:`i` times (possibly 0).\n    \"\"\"\n\n    import numpy as np\n    from numpy.linalg import solve\n\n    approx_order = problem.order  # order of approximation\n\n    [f0, f1] = problem.f[:2]\n    [g0, g1] = problem.g[:2]\n    sigma = problem.sigma\n\n    n_x = f1.shape[0]           # number of controls\n    n_s = f1.shape[1]//2 - n_x   # number of states\n    n_e = g1.shape[1] - n_x - n_s\n    n_v = n_s + n_x\n\n    f_s = f1[:, :n_s]\n    f_x = f1[:, n_s:n_s+n_x]\n    f_snext = f1[:, n_v:n_v+n_s]\n    f_xnext = f1[:, n_v+n_s:]\n\n    g_s = g1[:, :n_s]\n    g_x = g1[:, n_s:n_s+n_x]\n    g_e = g1[:, n_v:]\n\n    A = np.row_stack([\n        np.column_stack([np.eye(n_s), np.zeros((n_s, n_x))]),\n        np.column_stack([-f_snext    , -f_xnext           ])\n    ])\n    B = np.row_stack([\n        np.column_stack([g_s, g_x]),\n        np.column_stack([f_s, f_x])\n    ])\n\n    [S, T, Q, Z, eigval] = qzordered(A, B, 1.0-1e-8)\n\n    Q = Q.real  # is it really necessary ?\n    Z = Z.real\n\n    diag_S = np.diag(S)\n    diag_T = np.diag(T)\n\n    tol_geneigvals = 1e-10\n\n    try:\n        ok = sum((abs(diag_S) < tol_geneigvals) *\n                 (abs(diag_T) < tol_geneigvals)) == 0\n        assert(ok)\n    except Exception as e:\n        raise GeneralizedEigenvaluesError(diag_S=diag_S, diag_T=diag_T)\n\n    if max(eigval[:n_s]) >= 1 and min(eigval[n_s:]) < 1:\n        # BK conditions are met\n        pass\n    else:\n        eigval_s = sorted(eigval, reverse=True)\n        ev_a = eigval_s[n_s-1]\n        ev_b = eigval_s[n_s]\n        cutoff = (ev_a - ev_b)/2\n        if not ev_a > ev_b:\n            raise GeneralizedEigenvaluesSelectionError(\n                    A=A, B=B, eigval=eigval, cutoff=cutoff,\n                    diag_S=diag_S, diag_T=diag_T, n_states=n_s\n                )\n        import warnings\n        if cutoff > 1:\n            warnings.warn(\"Solution is not convergent.\")\n        else:\n            warnings.warn(\"There are multiple convergent solutions. The one with the smaller eigenvalues was selected.\")\n        [S, T, Q, Z, eigval] = qzordered(A, B, cutoff)\n\n    Z11 = Z[:n_s, :n_s]\n    # Z12 = Z[:n_s, n_s:]\n    Z21 = Z[n_s:, :n_s]\n    # Z22 = Z[n_s:, n_s:]\n    S11 = S[:n_s, :n_s]\n    T11 = T[:n_s, :n_s]\n\n    # first order solution\n    C = solve(Z11.T, Z21.T).T\n    P = np.dot(solve(S11.T, Z11.T).T, solve(Z11.T, T11.T).T)\n    Q = g_e\n\n    # if False:\n    #     from numpy import dot\n    #     test = f_s + f_x @ C + f_snext @ (g_s + g_x @ C) + f_xnext @ C @ (g_s + g_x @ C)\n    #     print('Error: ' + str(abs(test).max()))\n\n    if approx_order == 1:\n        return [C]\n\n    # second order solution\n    from dolo.numeric.tensor import sdot, mdot\n    from numpy import dot\n    from dolo.numeric.matrix_equations import solve_sylvester\n\n    f2 = problem.f[2]\n    g2 = problem.g[2]\n    g_ss = g2[:, :n_s, :n_s]\n    g_sx = g2[:, :n_s, n_s:n_v]\n    g_xx = g2[:, n_s:n_v, n_s:n_v]\n\n    X_s = C\n\n    V1_3 = g_s + dot(g_x, X_s)\n    V1 = np.row_stack([\n        np.eye(n_s),\n        X_s,\n        V1_3,\n        X_s @ V1_3\n    ])\n\n    K2 = g_ss + 2 * sdot(g_sx, X_s) + mdot(g_xx, X_s, X_s)\n    A = f_x + dot(f_snext + dot(f_xnext, X_s), g_x)\n    B = f_xnext\n    C = V1_3\n    D = mdot(f2, V1, V1) + sdot(f_snext + dot(f_xnext, X_s), K2)\n\n    X_ss = solve_sylvester(A, B, C, D)\n\n#    test = sdot( A, X_ss ) + sdot( B,  mdot(X_ss,V1_3,V1_3) ) + D\n\n    g_ee = g2[:, n_v:, n_v:]\n\n    v = np.row_stack([\n        g_e,\n        dot(X_s, g_e)\n    ])\n\n    K_tt = mdot(f2[:, n_v:, n_v:], v, v)\n    K_tt += sdot(f_snext + dot(f_xnext, X_s), g_ee)\n    K_tt += mdot(sdot(f_xnext, X_ss), g_e, g_e)\n    K_tt = np.tensordot(K_tt, sigma, axes=((1, 2), (0, 1)))\n\n    L_tt = f_x + dot(f_snext, g_x) + dot(f_xnext, dot(X_s, g_x) + np.eye(n_x))\n    X_tt = solve(L_tt, - K_tt)\n\n    if approx_order == 2:\n        return [[X_s, X_ss], [X_tt]]\n\n    # third order solution\n\n    f3 = problem.f[3]\n    g3 = problem.g[3]\n    g_sss = g3[:, :n_s, :n_s, :n_s]\n    g_ssx = g3[:, :n_s, :n_s, n_s:n_v]\n    g_sxx = g3[:, :n_s, n_s:n_v, n_s:n_v]\n    g_xxx = g3[:, n_s:n_v, n_s:n_v, n_s:n_v]\n\n    V2_3 = K2 + sdot(g_x, X_ss)\n    V2 = np.row_stack([\n        np.zeros((n_s, n_s, n_s)),\n        X_ss,\n        V2_3,\n        dot(X_s, V2_3) + mdot(X_ss, V1_3, V1_3)\n    ])\n\n    K3 = g_sss + 3*sdot(g_ssx, X_s) + 3*mdot(g_sxx, X_s, X_s) + 2*sdot(g_sx, X_ss)\n    K3 += 3*mdot(g_xx, X_ss, X_s) + mdot(g_xxx, X_s, X_s, X_s)\n    L3 = 3*mdot(X_ss, V1_3, V2_3)\n\n    # A = f_x + dot( f_snext + dot(f_xnext,X_s), g_x) # same as before\n    # B = f_xnext # same\n    # C = V1_3 # same\n    D = mdot(f3, V1, V1, V1) + 3*mdot(f2, V2, V1) + sdot(f_snext + dot(f_xnext, X_s), K3)\n    D += sdot(f_xnext, L3)\n\n    X_sss = solve_sylvester(A, B, C, D)\n\n    # now doing sigma correction with sigma replaced by l in the subscripts\n\n    g_se = g2[:, :n_s, n_v:]\n    g_xe = g2[:, n_s:n_v, n_v:]\n\n    g_see = g3[:, :n_s, n_v:, n_v:]\n    g_xee = g3[:, n_s:n_v, n_v:, n_v:]\n\n    W_l = np.row_stack([\n        g_e,\n        dot(X_s, g_e)\n    ])\n\n    I_e = np.eye(n_e)\n\n    V_sl = g_se + mdot(g_xe, X_s, np.eye(n_e))\n\n    W_sl = np.row_stack([\n        V_sl,\n        mdot(X_ss, V1_3, g_e) + sdot(X_s, V_sl)\n    ])\n\n    K_ee = mdot(f3[:, :, n_v:, n_v:], V1, W_l, W_l)\n    K_ee += 2 * mdot(f2[:, n_v:, n_v:], W_sl, W_l)\n\n    # stochastic part of W_ll\n\n    SW_ll = np.row_stack([\n        g_ee,\n        mdot(X_ss, g_e, g_e) + sdot(X_s, g_ee)\n    ])\n\n    DW_ll = np.concatenate([\n        X_tt,\n        dot(g_x, X_tt),\n        dot(X_s, sdot(g_x, X_tt)) + X_tt\n    ])\n\n    K_ee += mdot(f2[:, :, n_v:], V1, SW_ll)\n\n    K_ = np.tensordot(K_ee, sigma, axes=((2,3), (0,1)))\n\n    K_ += mdot(f2[:, :, n_s:], V1, DW_ll)\n\n    def E(vec):\n        n = len(vec.shape)\n        return np.tensordot(vec, sigma, axes=((n-2, n-1), (0, 1)))\n\n    L = sdot(g_sx, X_tt) + mdot(g_xx, X_s, X_tt)\n\n    L += E(g_see + mdot(g_xee, X_s, I_e, I_e))\n\n    M = E(mdot(X_sss, V1_3, g_e, g_e) + 2*mdot(X_ss, V_sl, g_e))\n    M += mdot(X_ss, V1_3, E(g_ee) + sdot(g_x, X_tt))\n\n    A = f_x + dot(f_snext + dot(f_xnext, X_s), g_x)  # same as before\n    B = f_xnext  # same\n    C = V1_3     # same\n    D = K_ + dot(f_snext + dot(f_xnext, X_s), L) + dot(f_xnext, M)\n\n    X_stt = solve_sylvester(A, B, C, D)\n\n    if approx_order == 3:\n        # if sigma is None:\n        #     return [X_s,X_ss,X_sss]\n        # else:\n        #     return [[X_s,X_ss,X_sss],[X_tt, X_stt]]\n        return [[X_s, X_ss, X_sss], [X_tt, X_stt]]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the list of the first 100 ranked players.", "response": "def get_ranked_players():\n    \"\"\"Get the list of the first 100 ranked players.\"\"\"\n\n    rankings_page = requests.get(RANKINGS_URL)\n    root = etree.HTML(rankings_page.text)\n    player_rows = root.xpath('//div[@id=\"ranked\"]//tr')\n\n    for row in player_rows[1:]:\n        player_row = row.xpath('td[@class!=\"country\"]//text()')\n        yield _Player(\n            name=player_row[1],\n            country=row[1][0].get('title'),\n            triple_crowns=player_row[3],\n            monthly_win=player_row[4],\n            biggest_cash=player_row[5],\n            plb_score=player_row[6],\n            biggest_score=player_row[7],\n            average_score=player_row[8],\n            previous_rank=player_row[9],\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntell the numerical difference between two ranks.", "response": "def difference(cls, first, second):\n        \"\"\"Tells the numerical difference between two ranks.\"\"\"\n\n        # so we always get a Rank instance even if string were passed in\n        first, second = cls(first), cls(second)\n        rank_list = list(cls)\n        return abs(rank_list.index(first) - rank_list.index(second))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_random(cls):\n        self = object.__new__(cls)\n        self.rank = Rank.make_random()\n        self.suit = Suit.make_random()\n        return self", "response": "Returns a random Card instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef range_(range, no_border, html):\n    from .hand import Range\n\n    border = not no_border\n    result = Range(range).to_html() if html else Range(range).to_ascii(border)\n    click.echo(result)", "response": "Prints the given range in a formatted table either in a plain ASCII or HTML."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets profile information about a Two plus Two Forum member given the username.", "response": "def twoplustwo_player(username):\n    \"\"\"Get profile information about a Two plus Two Forum member given the username.\"\"\"\n\n    from .website.twoplustwo import ForumMember, AmbiguousUserNameError, UserNotFoundError\n\n    try:\n        member = ForumMember(username)\n    except UserNotFoundError:\n        raise click.ClickException('User \"%s\" not found!' % username)\n    except AmbiguousUserNameError as e:\n        click.echo('Got multiple users with similar names!', err=True)\n\n        for ind, user in enumerate(e.users):\n            click.echo('{}. {}'.format(ind + 1, user.name), err=True)\n\n        number = click.prompt('Which would you like to see [{}-{}]'.format(1, len(e.users)),\n                              prompt_suffix='? ', type=click.IntRange(1, len(e.users)), err=True)\n\n        userid = e.users[int(number) - 1].id\n        member = ForumMember.from_userid(userid)\n\n        click.echo(err=True)  # empty line after input\n\n    _print_header('Two plus two forum member')\n    _print_values(\n        ('Username', member.username),\n        ('Forum id', member.id),\n        ('Location', member.location),\n        ('Total posts', member.total_posts),\n        ('Posts per day', member.posts_per_day),\n        ('Rank', member.rank),\n        ('Last activity', member.last_activity),\n        ('Join date', member.join_date),\n        ('Usergroups', member.public_usergroups),\n        ('Profile picture', member.profile_picture),\n        ('Avatar', member.avatar),\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p5list(num):\n\n    from .website.pocketfives import get_ranked_players\n\n    format_str = '{:>4.4}   {!s:<15.13}{!s:<18.15}{!s:<9.6}{!s:<10.7}'\\\n                 '{!s:<14.11}{!s:<12.9}{!s:<12.9}{!s:<12.9}{!s:<4.4}'\n\n    click.echo(format_str.format(\n        'Rank' , 'Player name', 'Country', 'Triple', 'Monthly', 'Biggest cash',\n        'PLB score', 'Biggest s', 'Average s', 'Prev'\n    ))\n    # just generate the appropriate number of underlines and cut them with format_str\n    underlines = ['-' * 20] * 10\n    click.echo(format_str.format(*underlines))\n\n    for ind, player in enumerate(get_ranked_players()):\n        click.echo(format_str.format(str(ind + 1) + '.', *player))\n        if ind == num - 1:\n            break", "response": "List pocketfives ranked players max 100 if no NUM if specified."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef psstatus():\n    from .website.pokerstars import get_status\n\n    _print_header('PokerStars status')\n\n    status = get_status()\n    _print_values(\n        ('Info updated', status.updated),\n        ('Tables', status.tables),\n        ('Players', status.players),\n        ('Active tournaments', status.active_tournaments),\n        ('Total tournaments', status.total_tournaments),\n        ('Clubs', status.clubs),\n        ('Club members', status.club_members),\n    )\n\n    site_format_str = '{0.id:<12}  {0.tables:<7,}  {0.players:<8,}  {0.active_tournaments:,}'\n    click.echo('\\nSite          Tables   Players   Tournaments')\n    click.echo('-----------   ------   -------   -----------')\n\n    for site in status.sites:\n        click.echo(site_format_str.format(site))", "response": "Shows PokerStars status such as number of players active tournaments clubs members and total tournaments."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_note(self, player, text, label=None, update=None):\n        if label is not None and (label not in self.label_names):\n            raise LabelNotFoundError('Invalid label: {}'.format(label))\n        if update is None:\n            update = datetime.utcnow()\n        # converted to timestamp, rounded to ones\n        update = update.strftime('%s')\n        label_id = self._get_label_id(label)\n        new_note = etree.Element('note', player=player, label=label_id, update=update)\n        new_note.text = text\n        self.root.append(new_note)", "response": "Add a note to the xml."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nappends text to an already existing note.", "response": "def append_note(self, player, text):\n        \"\"\"Append text to an already existing note.\"\"\"\n        note = self._find_note(player)\n        note.text += text"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreplacing note text with text.", "response": "def replace_note(self, player, text):\n        \"\"\"Replace note text with text. (Overwrites previous note!)\"\"\"\n        note = self._find_note(player)\n        note.text = text"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding the label by name.", "response": "def get_label(self, name):\n        \"\"\"Find the label by name.\"\"\"\n        label_tag = self._find_label(name)\n        return _Label(label_tag.get('id'), label_tag.get('color'), label_tag.text)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a new label. It s id will automatically be calculated.", "response": "def add_label(self, name, color):\n        \"\"\"Add a new label. It's id will automatically be calculated.\"\"\"\n        color_upper = color.upper()\n        if not self._color_re.match(color_upper):\n            raise ValueError('Invalid color: {}'.format(color))\n\n        labels_tag = self.root[0]\n        last_id = int(labels_tag[-1].get('id'))\n        new_id = str(last_id + 1)\n\n        new_label = etree.Element('label', id=new_id, color=color_upper)\n        new_label.text = name\n\n        labels_tag.append(new_label)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef del_label(self, name):\n        labels_tag = self.root[0]\n        labels_tag.remove(self._find_label(name))", "response": "Delete a label by name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save(self, filename):\n        with open(filename, 'w') as fp:\n            fp.write(str(self))", "response": "Save the note XML to a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef board(self):\n        board = []\n        if self.flop:\n            board.extend(self.flop.cards)\n            if self.turn:\n                board.append(self.turn)\n                if self.river:\n                    board.append(self.river)\n        return tuple(board) if board else None", "response": "Calculates board from flop turn and river."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parse_date(self, date_string):\n        date = datetime.strptime(date_string, self._DATE_FORMAT)\n        self.date = self._TZ.localize(date).astimezone(pytz.UTC)", "response": "Parse the date_string and return a datetime object as UTC."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _split_raw(self):\n\n        self._splitted = self._split_re.split(self.raw)\n        # search split locations (basically empty strings)\n        self._sections = [ind for ind, elem in enumerate(self._splitted) if not elem]", "response": "Split hand history by sections."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_timezone(self, root):\n        tz_str = root.xpath('//div[@class=\"smallfont\" and @align=\"center\"]')[0].text\n        hours = int(self._tz_re.search(tz_str).group(1))\n        return tzoffset(tz_str, hours * 60)", "response": "Find timezone informatation on bottom of the page."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_current_tournaments():\n\n    schedule_page = requests.get(TOURNAMENTS_XML_URL)\n    root = etree.XML(schedule_page.content)\n\n    for tour in root.iter('{*}tournament'):\n        yield _Tournament(\n            start_date=tour.findtext('{*}start_date'),\n            name=tour.findtext('{*}name'),\n            game=tour.findtext('{*}game'),\n            buyin=tour.findtext('{*}buy_in_fee'),\n            players=tour.get('players')\n        )", "response": "Get the next 200 tournaments from pokerstars."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_status():\n\n    res = requests.get(STATUS_URL)\n    status = res.json()['tournaments']['summary']\n\n    # move all sites under sites attribute, including play money\n    sites = status.pop('site')\n    play_money = status.pop('play_money')\n    play_money['id'] = 'Play Money'\n    sites.append(play_money)\n    sites = tuple(_SiteStatus(**site) for site in sites)\n\n    return _Status(sites=sites, updated=status.pop('updated'), **status)", "response": "Get pokerstars status: players online, number of tables, etc."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _filter_file(src, dest, subst):\n    substre = re.compile(r'\\$(%s)' % '|'.join(subst.keys()))\n    def repl(m):\n        return subst[m.group(1)]\n    with open(src, \"rt\") as sf, open(dest, \"wt\") as df:\n        while True:\n            l = sf.readline()\n            if not l:\n                break\n            df.write(re.sub(substre, repl, l))", "response": "Copy src to dest doing substitutions on the fly."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlogs a json. JSONDecodeError and convert it to a GraphQL - compliant dict with keys data and errors.", "response": "def _log_json_error(self, body, exc):\n        '''Log a :exc:`json.JSONDecodeError`, converting to\n        GraphQL's ``{\"data\": null, \"errors\": [{\"message\": str(exc)...}]}``\n\n        :param body: the string with JSON document.\n        :type body: str\n\n        :param exc: the :exc:`json.JSONDecodeError`\n        :type exc: :exc:`json.JSONDecodeError`\n\n        :return: GraphQL-compliant dict with keys ``data`` and ``errors``.\n        :rtype: dict\n        '''\n        self.logger.error('could not decode JSON response: %s', exc)\n        return {'data': None, 'errors': [{\n            'message': str(exc),\n            'exception': exc,\n            'body': body,\n        }]}"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _fixup_graphql_error(self, data):\n        '''Given a possible GraphQL error payload, make sure it's in shape.\n\n        This will ensure the given ``data`` is in the shape:\n\n        .. code-block:: json\n\n           {\"errors\": [{\"message\": \"some string\"}]}\n\n        If ``errors`` is not an array, it will be made into a single element\n        array, with the object in that format, with its string representation\n        being the message.\n\n        If an element of the ``errors`` array is not in the format, then\n        it's converted to the format, with its string representation being\n        the message.\n\n        The input object is not changed, a copy is made if needed.\n\n        :return: the given ``data`` formatted to the correct shape, a copy\n                 is made and returned if any fix up was needed.\n        :rtype: dict\n        '''\n        original_data = data\n        errors = data.get('errors')\n        original_errors = errors\n        if not isinstance(errors, list):\n            self.logger.warning('data[\"errors\"] is not a list! Fix up data=%r',\n                                data)\n            data = data.copy()\n            data['errors'] = [{'message': str(errors)}]\n            return data\n\n        for i, error in enumerate(errors):\n            if not isinstance(error, dict):\n                self.logger.warning('Error #%d: is not a dict: %r. Fix up!',\n                                    i, error)\n                if data is original_data:\n                    data = data.copy()\n                if errors is original_errors:\n                    errors = errors.copy()\n                    data['errors'] = errors\n\n                errors[i] = {'message': str(error)}\n                continue\n\n            message = error.get('message')\n            if not isinstance(message, str):\n                if data is original_data:\n                    data = data.copy()\n                if errors is original_errors:\n                    errors = errors.copy()\n                    data['errors'] = errors\n\n                message = str(error) if message is None else str(message)\n                error = error.copy()\n                error['message'] = message\n                errors[i] = error\n\n        return data", "response": "Given a possible GraphQL error payload make sure it s in the correct shape."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _log_graphql_error(self, query, data):\n        '''Log a ``{\"errors\": [...]}`` GraphQL return and return itself.\n\n        :param query: the GraphQL query that triggered the result.\n        :type query: str\n\n        :param data: the decoded JSON object.\n        :type data: dict\n\n        :return: the input ``data``\n        :rtype: dict\n        '''\n        if isinstance(query, bytes):  # pragma: no cover\n            query = query.decode('utf-8')\n        elif not isinstance(query, str):  # pragma: no cover\n            # allows sgqlc.operation.Operation to be passed\n            # and generate compact representation of the queries\n            query = bytes(query).decode('utf-8')\n\n        data = self._fixup_graphql_error(data)\n        errors = data['errors']\n        self.logger.error('GraphQL query failed with %s errors', len(errors))\n        for i, error in enumerate(errors):\n            paths = error.get('path')\n            if paths:\n                paths = ' ' + '/'.join(str(path) for path in paths)\n            else:\n                paths = ''\n            self.logger.info('Error #{}{}:'.format(i, paths))\n            for ln in error.get('message', '').split('\\n'):\n                self.logger.info('   | {}'.format(ln))\n\n            s = self.snippet(query, error.get('locations'))\n            if s:\n                self.logger.info('   -')\n                self.logger.info('   | Locations:')\n                for ln in s:\n                    self.logger.info('   | {}'.format(ln))\n        return data", "response": "Log a GraphQL error and return itself."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngives a code and a list of locations convert to snippet lines.", "response": "def snippet(code, locations, sep=' | ', colmark=('-', '^'), context=5):\n        '''Given a code and list of locations, convert to snippet lines.\n\n        return will include line number, a separator (``sep``), then\n        line contents.\n\n        At most ``context`` lines are shown before each location line.\n\n        After each location line, the column is marked using\n        ``colmark``. The first character is repeated up to column, the\n        second character is used only once.\n\n        :return: list of lines of sources or column markups.\n        :rtype: list\n        '''\n        if not locations:\n            return []\n        lines = code.split('\\n')\n        offset = int(len(lines) / 10) + 1\n        linenofmt = '%{}d'.format(offset)\n        s = []\n        for loc in locations:\n            line = max(0, loc.get('line', 1) - 1)\n            column = max(0, loc.get('column', 1) - 1)\n            start_line = max(0, line - context)\n            for i, ln in enumerate(lines[start_line:line + 1], start_line):\n                s.append('{}{}{}'.format(linenofmt % i, sep, ln))\n            s.append('{}{}{}'.format(' ' * (offset + len(sep)),\n                                     colmark[0] * column,\n                                     colmark[1]))\n        return s"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates type wrapper for non - null of given type", "response": "def _create_non_null_wrapper(name, t):\n    'creates type wrapper for non-null of given type'\n    def __new__(cls, json_data, selection_list=None):\n        if json_data is None:\n            raise ValueError(name + ' received null value')\n        return t(json_data, selection_list)\n\n    def __to_graphql_input__(value, indent=0, indent_string='  '):\n        return t.__to_graphql_input__(value, indent, indent_string)\n\n    return type(name, (t,), {\n        '__new__': __new__,\n        '_%s__auto_register' % name: False,\n        '__to_graphql_input__': __to_graphql_input__,\n    })"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _create_list_of_wrapper(name, t):\n    'creates type wrapper for list of given type'\n    def __new__(cls, json_data, selection_list=None):\n        if json_data is None:\n            return None\n        return [t(v, selection_list) for v in json_data]\n\n    def __to_graphql_input__(value, indent=0, indent_string='  '):\n        r = []\n        for v in value:\n            r.append(t.__to_graphql_input__(v, indent, indent_string))\n        return '[' + ', '.join(r) + ']'\n\n    def __to_json_value__(value):\n        if value is None:\n            return None\n        return [t.__to_json_value__(v) for v in value]\n\n    return type(name, (t,), {\n        '__new__': __new__,\n        '_%s__auto_register' % name: False,\n        '__to_graphql_input__': __to_graphql_input__,\n        '__to_json_value__': __to_json_value__,\n    })", "response": "creates type wrapper for list of given type"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates a non - null type with the given value.", "response": "def non_null(t):\n    '''Generates non-null type (t!)\n\n    >>> class TypeWithNonNullFields(Type):\n    ...     a_int = non_null(int)\n    ...     a_float = non_null(Float)\n    ...     a_string = Field(non_null(String))\n    ...\n    >>> TypeWithNonNullFields\n    type TypeWithNonNullFields {\n      aInt: Int!\n      aFloat: Float!\n      aString: String!\n    }\n\n    Giving proper JSON data:\n\n    >>> json_data = {'aInt': 1, 'aFloat': 2.1, 'aString': 'hello'}\n    >>> obj = TypeWithNonNullFields(json_data)\n    >>> obj\n    TypeWithNonNullFields(a_int=1, a_float=2.1, a_string='hello')\n\n    Giving incorrect JSON data:\n\n    >>> json_data = {'aInt': None, 'aFloat': 2.1, 'aString': 'hello'}\n    >>> obj = TypeWithNonNullFields(json_data)  # doctest: +ELLIPSIS\n    Traceback (most recent call last):\n      ...\n    ValueError: TypeWithNonNullFields selection 'a_int': ...\n    >>> json_data = {'aInt': 1, 'aFloat': None, 'aString': 'hello'}\n    >>> obj = TypeWithNonNullFields(json_data)  # doctest: +ELLIPSIS\n    Traceback (most recent call last):\n      ...\n    ValueError: TypeWithNonNullFields selection 'a_float': ...\n    >>> json_data = {'aInt': 1, 'aFloat': 2.1, 'aString': None}\n    >>> obj = TypeWithNonNullFields(json_data)  # doctest: +ELLIPSIS\n    Traceback (most recent call last):\n      ...\n    ValueError: TypeWithNonNullFields selection 'a_string': ...\n\n    .. note::\n\n       Note that **missing** keys in JSON data are not considered\n       ``None``, and they won't show in ``iter(obj)``, ``__str__()``\n       or ``__repr__()``\n\n       >>> json_data = {'aInt': 1, 'aFloat': 2.1}\n       >>> obj = TypeWithNonNullFields(json_data)\n       >>> obj # repr()\n       TypeWithNonNullFields(a_int=1, a_float=2.1)\n       >>> for field_name in obj:\n       ...     print(field_name, repr(obj[field_name]))\n       ...\n       a_int 1\n       a_float 2.1\n\n    '''\n    if isinstance(t, str):\n        return Lazy(t, t + '!', non_null)\n    elif isinstance(t, Lazy):\n        return Lazy(t.target_name, t.target_name + '!', non_null, t)\n\n    t = BaseType.__ensure__(t)\n    name = t.__name__ + '!'\n    try:\n        return t.__schema__.__cache__[name]\n    except KeyError:\n        pass\n\n    wrapper = _create_non_null_wrapper(name, t)\n    t.__schema__.__cache__[name] = wrapper\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a list of types", "response": "def list_of(t):\n    '''Generates list of types ([t])\n\n    The example below highlights the usage including its usage with\n    lists:\n\n    - ``non_null_list_of_int`` means it must be a list, not ``None``,\n      however list elements may be ``None``, ie: ``[None, 1, None, 2]``;\n\n    - ``list_of_non_null_int`` means it may be ``None`` or be a list,\n      however list elements must not be ``None``, ie: ``None`` or\n      ``[1, 2]``;\n\n    - ``non_null_list_of_non_null_int`` means it must be a list, not\n      ``None`` **and** the list elements must not be ``Non``, ie:\n      ``[1, 2]``.\n\n    >>> class TypeWithListFields(Type):\n    ...     list_of_int = list_of(int)\n    ...     list_of_float = list_of(Float)\n    ...     list_of_string = Field(list_of(String))\n    ...     non_null_list_of_int = non_null(list_of(int))\n    ...     list_of_non_null_int = list_of(non_null(int))\n    ...     non_null_list_of_non_null_int = non_null(list_of(non_null(int)))\n    ...\n    >>> TypeWithListFields\n    type TypeWithListFields {\n      listOfInt: [Int]\n      listOfFloat: [Float]\n      listOfString: [String]\n      nonNullListOfInt: [Int]!\n      listOfNonNullInt: [Int!]\n      nonNullListOfNonNullInt: [Int!]!\n    }\n\n    It takes care to enforce proper type, including non-null checking\n    on its elements when creating instances. Giving proper JSON data:\n\n    >>> json_data = {\n    ...     'listOfInt': [1, 2],\n    ...     'listOfFloat': [1.1, 2.1],\n    ...     'listOfString': ['hello', 'world'],\n    ...     'nonNullListOfInt': [None, 1, None, 2],\n    ...     'listOfNonNullInt': [1, 2, 3],\n    ...     'nonNullListOfNonNullInt': [1, 2, 3, 4],\n    ... }\n    >>> obj = TypeWithListFields(json_data)\n    >>> for field_name in obj:\n    ...     print(field_name, repr(obj[field_name]))\n    ...\n    list_of_int [1, 2]\n    list_of_float [1.1, 2.1]\n    list_of_string ['hello', 'world']\n    non_null_list_of_int [None, 1, None, 2]\n    list_of_non_null_int [1, 2, 3]\n    non_null_list_of_non_null_int [1, 2, 3, 4]\n\n    Note that lists that are **not** enclosed in ``non_null()`` can be\n    ``None``:\n\n    >>> json_data = {\n    ...     'listOfInt': None,\n    ...     'listOfFloat': None,\n    ...     'listOfString': None,\n    ...     'nonNullListOfInt': [None, 1, None, 2],\n    ...     'listOfNonNullInt': None,\n    ...     'nonNullListOfNonNullInt': [1, 2, 3],\n    ... }\n    >>> obj = TypeWithListFields(json_data)\n    >>> for field_name in obj:\n    ...     print(field_name, repr(obj[field_name]))\n    ...\n    list_of_int None\n    list_of_float None\n    list_of_string None\n    non_null_list_of_int [None, 1, None, 2]\n    list_of_non_null_int None\n    non_null_list_of_non_null_int [1, 2, 3]\n\n    Types will be converted, so although not usual (since GraphQL\n    gives you the proper JSON type), this can be done:\n\n    >>> json_data = {\n    ...     'listOfInt': ['1', '2'],\n    ...     'listOfFloat': [1, '2.1'],\n    ...     'listOfString': ['hello', 2],\n    ...     'nonNullListOfInt': [None, '1', None, 2.1],\n    ...     'listOfNonNullInt': ['1', 2.1, 3],\n    ...     'nonNullListOfNonNullInt': ['1', 2.1, 3, 4],\n    ... }\n    >>> obj = TypeWithListFields(json_data)\n    >>> for field_name in obj:\n    ...     print(field_name, repr(obj[field_name]))\n    ...\n    list_of_int [1, 2]\n    list_of_float [1.0, 2.1]\n    list_of_string ['hello', '2']\n    non_null_list_of_int [None, 1, None, 2]\n    list_of_non_null_int [1, 2, 3]\n    non_null_list_of_non_null_int [1, 2, 3, 4]\n\n    Giving incorrect (nonconvertible) JSON data will raise exceptions:\n\n    >>> json_data = { 'listOfInt': 1 }\n    >>> obj = TypeWithListFields(json_data)  # doctest: +ELLIPSIS\n    Traceback (most recent call last):\n       ...\n    ValueError: TypeWithListFields selection 'list_of_int': ...\n\n    >>> json_data = { 'listOfInt': ['x'] }\n    >>> obj = TypeWithListFields(json_data)  # doctest: +ELLIPSIS\n    Traceback (most recent call last):\n       ...\n    ValueError: TypeWithListFields selection 'list_of_int': ...\n\n    >>> json_data = { 'listOfNonNullInt': [1, None] }\n    >>> obj = TypeWithListFields(json_data)  # doctest: +ELLIPSIS\n    Traceback (most recent call last):\n       ...\n    ValueError: TypeWithListFields selection 'list_of_non_null_int': ...\n\n\n    Lists are usable as input types as well:\n\n    >>> class TypeWithListInput(Type):\n    ...     a = Field(str, args={'values': Arg(list_of(int), default=[1, 2])})\n    ...     b = Field(str, args={'values': Arg(list_of(int))})\n    ...\n    >>> TypeWithListInput\n    type TypeWithListInput {\n      a(values: [Int] = [1, 2]): String\n      b(values: [Int]): String\n    }\n\n    >>> print(json.dumps(list_of(int).__to_json_value__([1, 2])))\n    [1, 2]\n    >>> print(json.dumps(list_of(int).__to_json_value__(None)))\n    null\n\n    '''\n    if isinstance(t, str):\n        return Lazy(t, '[' + t + ']', list_of)\n    elif isinstance(t, Lazy):\n        return Lazy(t.target_name, '[' + t.target_name + ']', list_of, t)\n\n    t = BaseType.__ensure__(t)\n    name = '[' + t.__name__ + ']'\n    try:\n        return t.__schema__.__cache__[name]\n    except KeyError:\n        pass\n\n    wrapper = _create_list_of_wrapper(name, t)\n    t.__schema__.__cache__[name] = wrapper\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _to_graphql_name(name):\n        '''Converts a Python name, ``a_name`` to GraphQL: ``aName``.\n        '''\n        parts = name.split('_')\n        return ''.join(parts[:1] + [p.title() for p in parts[1:]])", "response": "Converts a Python name a_name to GraphQL name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_query_to_url(url, extra_query):\n    '''Adds an extra query to URL, returning the new URL.\n\n    Extra query may be a dict or a list as returned by\n    :func:`urllib.parse.parse_qsl()` and :func:`urllib.parse.parse_qs()`.\n\n    '''\n    split = urllib.parse.urlsplit(url)\n    merged_query = urllib.parse.parse_qsl(split.query)\n    if isinstance(extra_query, dict):\n        for k, v in extra_query.items():\n            if not isinstance(v, (tuple, list)):\n                merged_query.append((k, v))\n            else:\n                for cv in v:\n                    merged_query.append((k, cv))\n    else:\n        merged_query.extend(extra_query)\n\n    merged_split = urllib.parse.SplitResult(\n        split.scheme,\n        split.netloc,\n        split.path,\n        urllib.parse.urlencode(merged_query),\n        split.fragment,\n    )\n    return merged_split.geturl()", "response": "Adds an extra query to a URL returning the new URL."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlog an HTTP error and return a dict with keys data and errors.", "response": "def _log_http_error(self, query, req, exc):\n        '''Log :exc:`urllib.error.HTTPError`, converting to\n        GraphQL's ``{\"data\": null, \"errors\": [{\"message\": str(exc)...}]}``\n\n        :param query: the GraphQL query that triggered the result.\n        :type query: str\n\n        :param req: :class:`urllib.request.Request` instance that was opened.\n        :type req: :class:`urllib.request.Request`\n\n        :param exc: :exc:`urllib.error.HTTPError` instance\n        :type exc: :exc:`urllib.error.HTTPError`\n\n        :return: GraphQL-compliant dict with keys ``data`` and ``errors``.\n        :rtype: dict\n        '''\n        self.logger.error('%s: %s', req.get_full_url(), exc)\n        for h in sorted(exc.headers):\n            self.logger.info('Response header: %s: %s', h, exc.headers[h])\n\n        body = exc.read().decode('utf-8')\n        content_type = exc.headers.get('Content-Type', '')\n        self.logger.info('Response [%s]:\\n%s', content_type, body)\n        if not content_type.startswith('application/json'):\n            return {'data': None, 'errors': [{\n                'message': str(exc),\n                'exception': exc,\n                'status': exc.code,\n                'headers': exc.headers,\n                'body': body,\n            }]}\n        else:\n            # GraphQL servers return 400 and {'errors': [...]}\n            # if only errors was returned, no {'data': ...}\n            try:\n                data = json.loads(body)\n            except json.JSONDecodeError as exc:\n                return self._log_json_error(body, exc)\n\n            if isinstance(data, dict) and data.get('errors'):\n                data.update({\n                    'exception': exc,\n                    'status': exc.code,\n                    'headers': exc.headers,\n                })\n                return self._log_graphql_error(query, data)\n            return {'data': None, 'errors': [{\n                'message': str(exc),\n                'exception': exc,\n                'status': exc.code,\n                'headers': exc.headers,\n                'body': body,\n            }]}"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef connection_args(*lst, **mapping):\n    '''Returns the default parameters for connection.\n\n    Extra parameters may be given as argument, both as iterable,\n    positional tuples or mapping.\n\n    By default, provides:\n\n     - ``after: String``\n     - ``before: String``\n     - ``first: Int``\n     - ``last: Int``\n    '''\n    pd = ArgDict(*lst, **mapping)\n    pd.setdefault('after', String)\n    pd.setdefault('before', String)\n    pd.setdefault('first', Int)\n    pd.setdefault('last', Int)\n    return pd", "response": "Returns the default parameters for a connection."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmeans squared jumping distance.", "response": "def msjd(theta):\n    \"\"\"Mean squared jumping distance.\n    \"\"\"\n    s = 0. \n    for p in theta.dtype.names:\n        s += np.sum(np.diff(theta[p], axis=0) ** 2)\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the list l that contains all distinct elements of idx.", "response": "def all_distinct(l, idx):\n    \"\"\"\n    Returns the list [l[i] for i in idx]\u00a0\n    When needed, objects l[i] are replaced by a copy, to make sure that\n    the elements of the list are all distinct\n\n    Parameters\n    ---------\n    l: iterable\n    idx: iterable that generates ints (e.g. ndarray of ints)\n\n    Returns\n    -------\n    a list \n    \"\"\"\n    out = []\n    deja_vu = [False for _ in l]\n    for i in idx:\n        to_add = cp.deepcopy(l[i]) if deja_vu[i] else l[i]\n        out.append(to_add)\n        deja_vu[i] = True\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef as_2d_array(theta):\n    v = theta.view(np.float)\n    N = theta.shape[0]\n    v.shape = (N, - 1)\n    # raise an error if v cannot be reshaped without creating a copy\n    return v", "response": "returns a view to record array theta which behaves\n    like a ( N d ) float array\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlogs - likelihood at given parameter values.", "response": "def loglik(self, theta, t=None):\n        \"\"\" log-likelihood at given parameter values. \n\n        Parameters\n        ----------\n        theta: dict-like\n            theta['par'] is a ndarray containing the N values for parameter par\n        t: int \n            time (if set to None, the full log-likelihood is returned)\n\n        Returns\n        -------\n        l: float numpy.ndarray\n            the N log-likelihood values \n        \"\"\"\n        if t is None:\n            t = self.T - 1\n        l = np.zeros(shape=theta.shape[0])\n        for s in range(t + 1):\n            l += self.logpyt(theta, s)\n        return l"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef logpost(self, theta, t=None):\n        return self.prior.logpdf(theta) + self.loglik(theta, t)", "response": "Posterior log - density at given parameter values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef copyto(self, src, where=None):\n        for n, _ in enumerate(self.l):\n            if where[n]:\n                self.l[n] = src.l[n]", "response": "Copy the contents of src to self."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a copy of the object.", "response": "def copy(self):\n        \"\"\"Returns a copy of the object.\"\"\"\n        attrs = {k: self.__dict__[k].copy() for k in self.containers}\n        attrs.update({k: cp.deepcopy(self.__dict__[k]) for k in self.shared})\n        return self.__class__(**attrs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef copyto(self, src, where=None):\n        for k in self.containers:\n            v = self.__dict__[k]\n            if isinstance(v, np.ndarray):\n                np.copyto(v, src.__dict__[k], where=where)\n            else:\n                v.copyto(src.__dict__[k], where=where)", "response": "Emulates function copyto in NumPy."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncopy the object at a given location.", "response": "def copyto_at(self, n, src, m):\n        \"\"\"Copy to at a given location. \n\n        Parameters\n        ----------\n        n: int \n            index where to copy \n        src: `ThetaParticles` object\n            source\n        m: int\n            index of the element to be copied\n\n        Note\n        ----\n        Basically, does self[n] <- src[m]\n        \"\"\"\n        for k in self.containers:\n            self.__dict__[k][n] = src.__dict__[k][m]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef Metropolis(self, compute_target, mh_options):\n        opts = mh_options.copy()\n        nsteps = opts.pop('nsteps', 0)\n        delta_dist = opts.pop('delta_dist', 0.1)\n        proposal = self.choose_proposal(**opts)\n        xout = self.copy()\n        xp = self.__class__(theta=np.empty_like(self.theta))\n        step_ars = []\n        for _ in self.mcmc_iterate(nsteps, self.arr, xout.arr, delta_dist):\n            xp.arr[:, :], delta_lp = proposal.step(xout.arr)\n            compute_target(xp)\n            lp_acc = xp.lpost - xout.lpost + delta_lp\n            accept = (np.log(stats.uniform.rvs(size=self.N)) < lp_acc)\n            xout.copyto(xp, where=accept)\n            step_ars.append(np.mean(accept))\n        xout.acc_rates = self.acc_rates + [step_ars]\n        return xout", "response": "Performs a certain number of Metropolis steps."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsample N trajectories from the posterior.", "response": "def sample(self, N=1):\n        \"\"\"Sample N trajectories from the posterior. \n        \n        Note\n        ----\n        Performs the forward step in case it has not been performed. \n\n        \"\"\"\n        if not self.filt:\n            self.forward()\n        paths = np.empty((len(self.filt), N), np.int)\n        paths[-1, :] = rs.multinomial(self.filt[-1], M=N)\n        log_trans = np.log(self.hmm.trans_mat)\n        for t, f in reversed(list(enumerate(self.filt[:-1]))):\n            for n in range(N):\n                probs = rs.exp_and_normalise(log_trans[:, paths[t + 1, n]] + np.log(f))\n                paths[t, n] = rs.multinomial_once(probs)\n        return paths"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfilter the object at a given time", "response": "def filter_step(G, covY, pred, yt):\n    \"\"\"Filtering step of Kalman filter.\n\n    Parameters\n    ----------\n    G:  (dy, dx) numpy array\n        mean of Y_t | X_t is G * X_t\n    covX: (dx, dx) numpy array \n        covariance of Y_t | X_t\n    pred: MeanAndCov object\n        predictive distribution at time t\n\n    Returns\n    -------\n    pred: MeanAndCov object\n        filtering distribution at time t\n    logpyt: float\n        log density of Y_t | Y_{0:t-1}\n    \"\"\"\n    # data prediction\n    data_pred_mean = np.matmul(pred.mean, G.T)\n    data_pred_cov = dotdot(G, pred.cov, G.T) + covY\n    if covY.shape[0] == 1:\n        logpyt = dists.Normal(loc=data_pred_mean,\n                              scale=np.sqrt(data_pred_cov)).logpdf(yt)\n    else:\n        logpyt = dists.MvNormal(loc=data_pred_mean,\n                                cov=data_pred_cov).logpdf(yt)\n    # filter\n    residual = yt - data_pred_mean\n    gain = dotdot(pred.cov, G.T, inv(data_pred_cov))\n    filt_mean = pred.mean + np.matmul(residual, gain.T)\n    filt_cov = pred.cov - dotdot(gain, G, pred.cov)\n    return MeanAndCov(mean=filt_mean, cov=filt_cov), logpyt"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef filter_step_asarray(G, covY, pred, yt):\n    pm = pred.mean[:, np.newaxis] if pred.mean.ndim == 1 else pred.mean\n    new_pred = MeanAndCov(mean=pm, cov=pred.cov)\n    filt, logpyt = filter_step(G, covY, new_pred, yt)\n    if pred.mean.ndim == 1:\n        filt.mean.squeeze()\n    return filt, logpyt", "response": "Filter a Kalman filter step of Kalman filter."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef smoother_step(F, filt, next_pred, next_smth):\n    J = dotdot(filt.cov, F.T, inv(next_pred.cov))\n    smth_cov = filt.cov + dotdot(J, next_smth.cov - next_pred.cov, J.T)\n    smth_mean = filt.mean + np.matmul(next_smth.mean - next_pred.mean, J.T)\n    return MeanAndCov(mean=smth_mean, cov=smth_cov)", "response": "Smoothing step of Kalman filter / smoother."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck all dimensions are correct.", "response": "def check_shapes(self):\n        \"\"\"\n        Check all dimensions are correct.\n        \"\"\"\n        assert self.covX.shape == (self.dx, self.dx), error_msg\n        assert self.covY.shape == (self.dy, self.dy), error_msg\n        assert self.F.shape == (self.dx, self.dx), error_msg\n        assert self.G.shape == (self.dy, self.dx), error_msg\n        assert self.mu0.shape == (self.dx,), error_msg\n        assert self.cov0.shape == (self.dx, self.dx), error_msg"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef smoother(self):\n        if not self.filt:\n            self.filter()\n        self.smth = [self.filt[-1]]\n        for t, f in reversed(list(enumerate(self.filt[:-1]))):\n            self.smth += [smoother_step(self.ssm.F, f, self.pred[t + 1], \n                                        self.smth[t + 1])]\n        self.smth.reverse()", "response": "Backward recursion : compute mean / variance of marginal smoother."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef psit(t, x, xf):\n    if t == 0:\n        return psi0(x) + psit(1, x, xf)\n    else:\n        return -0.5 / sigma0**2 + (0.5 / sigma0**4) * ((xf - mu0) - \n                                                       phi0 * (x - mu0))**2", "response": "A function of t X_t and X_t and X_t"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sobol(N, dim, scrambled=1):\n    while(True):\n        seed = np.random.randint(2**32)\n        out = lowdiscrepancy.sobol(N, dim, scrambled, seed, 1, 0)\n        if (scrambled == 0) or ((out < 1.).all() and (out > 0.).all()):\n            # no need to test if scrambled==0\n            return out", "response": "Sobol sequence. \n\n    Parameters\n    ----------\n    N : int\n        length of sequence\n    dim: int\n        dimension\n    scrambled: int\n        which scrambling method to use: \n\n            + 0: no scrambling\n            + 1: Owen's scrambling\n            + 2: Faure-Tezuka\n            + 3: Owen + Faure-Tezuka\n\n    Returns\n    -------\n    (N, dim) numpy array. \n\n\n    Notes \n    -----\n    For scrambling, seed is set randomly. \n\n    Fun fact: this venerable but playful piece of Fortran code occasionally\n    returns numbers above 1. (i.e. for a very small number of seeds); when this\n    happen we just start over (since the seed is randomly generated)."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef smoothing_worker(method=None, N=100, seed=None, fk=None, fk_info=None,\n                     add_func=None, log_gamma=None):\n    \"\"\"Generic worker for off-line smoothing algorithms.\n\n    This worker may be used in conjunction with utils.multiplexer in order to \n    run in parallel (and eventually compare) off-line smoothing algorithms.\n    \n    Parameters\n    ----------\n    method: string\n         ['FFBS_ON', 'FFBS_ON2', 'FFBS_QMC', \n           'two-filter_ON', 'two-filter_ON_prop', 'two-filter_ON2']\n    N: int\n        number of particles \n    seed: int\n        random generator seed; if None, generator is not seeded\n    fk: Feynman-Kac object\n        The Feynman-Kac model for the forward filter\n    fk_info: Feynman-Kac object (default=None)\n        the Feynman-Kac model for the information filter; if None, \n        set to the same Feynman-Kac model as fk, with data in reverse\n    add_func: function, with signature (t, x, xf) \n        additive function, at time t, for particles x=x_t and xf=x_{t+1}\n    log_gamma: function\n        log of function gamma (see book)\n\n    Returns\n    -------\n    a dict with fields:\n        est: a ndarray of length T\n        cpu_time \n    \"\"\"\n    T = fk.T  \n    if fk_info is None: \n        fk_info = fk.__class__(ssm=fk.ssm, data=fk.data[::-1])\n    if seed:\n        random.seed(seed)\n    est = np.zeros(T - 1)\n    if method=='FFBS_QMC':\n        pf = particles.SQMC(fk=fk, N=N, store_history=True)\n    else:\n        pf = particles.SMC(fk=fk, N=N, store_history=True)\n    tic = time.clock()\n    pf.run()\n    if method in ['FFBS_ON', 'FFBS_ON2', 'FFBS_QMC']:\n        if method.startswith('FFBS_ON'): \n            z = pf.hist.backward_sampling(N, linear_cost=(method == 'FFBS_ON'))\n        else:\n            z = pf.hist.backward_sampling_qmc(N)\n        for t in range(T - 1):\n            est[t] = np.mean(add_func(t, z[t], z[t + 1]))\n    elif method in ['two-filter_ON2', 'two-filter_ON', 'two-filter_ON_prop']:\n        infopf = particles.SMC(fk=fk_info, N=N, store_history=True)\n        infopf.run()\n        for t in range(T - 1):\n            psi = lambda x, xf: add_func(t, x, xf)\n            if method == 'two-filter_ON2':\n                est[t] = pf.hist.twofilter_smoothing(t, infopf, psi, log_gamma)\n            else:\n                ti = T - 2 - t  # t+1 for info filter\n                if method == 'two-filter_ON_prop':\n                    modif_fwd = stats.norm.logpdf(pf.hist.X[t],\n                                          loc=np.mean(infopf.hist.X[ti + 1]),\n                                          scale=np.std(infopf.hist.X[ti + 1]))\n                    modif_info = stats.norm.logpdf(infopf.hist.X[ti],\n                                           loc=np.mean(pf.hist.X[t + 1]),\n                                           scale=np.std(pf.hist.X[t + 1]))\n                else:\n                    modif_fwd, modif_info = None, None\n                est[t] = pf.hist.twofilter_smoothing(t, infopf, psi, log_gamma,\n                                                     linear_cost=True,\n                                                     modif_forward=modif_fwd,\n                                                     modif_info=modif_info)\n    else:\n        print('no such method?')\n    cpu_time = time.clock() - tic\n    print(method + ' took %.2f s for N=%i' % (cpu_time, N))\n    return {'est': est, 'cpu': cpu_time}", "response": "A worker for off - line smoothing algorithms."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save(self, X=None, w=None, A=None):\n        self.X.append(X)\n        self.wgt.append(w)\n        self.A.append(A)", "response": "Save one page of history at a given time."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef extract_one_trajectory(self):\n        traj = []\n        for t in reversed(range(self.T)):\n            if t == self.T - 1:\n                n = rs.multinomial_once(self.wgt[-1].W)\n            else:\n                n = self.A[t + 1][n]\n            traj.append(self.X[t][n])\n        return traj[::-1]", "response": "Extract a single trajectory from the particle history."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef compute_trajectories(self):\n        self.B = np.empty((self.T, self.N), 'int')\n        self.B[-1, :] = self.A[-1]\n        for t in reversed(range(self.T - 1)):\n            self.B[t, :] = self.A[t + 1][self.B[t + 1]]", "response": "Compute the N trajectories that constitute the current genealogy."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates trajectories using the FFBS forward filtering backward sampling algorithm.", "response": "def backward_sampling(self, M, linear_cost=False, return_ar=False):\n        \"\"\"Generate trajectories using the FFBS (forward filtering backward\n        sampling) algorithm. \n\n        Arguments\n        ---------\n        M: int\n            number of trajectories we want to generate\n        linear_cost: bool \n            if set to True, the O(N) version is used, see below. \n\n        return_ar: bool (default=False)\n            if set to True, change the output, see below. \n        \n        Returns\n        -------\n        paths: a list of ndarrays\n            paths[t][n] is component t of trajectory m. \n        ar: float\n            the overall acceptance rate of the rejection procedure\n\n        Notes\n        -----\n\n        1. if ``linear_cost=False``, complexity is O(TMN); i.e. O(TN^2) for M=N;\n           if ``linear_cost=True``, complexity is O(T(M+N)), i.e. O(TN) for M=N.\n           This requires that model has method `upper_bound_trans`, which\n           provides the log of a constant C_t such that\n           :math:`p_t(x_t|x_{t-1}) \\leq C_t`. \n\n        2. main output is ``paths``, a list of T arrays such that\n           ``paths[t][m]`` is component t of trajectory m.\n\n        3. if ``linear_cost=True`` and ``return_ar=True``, output is tuple\n           ``(paths, ar)``, where ``paths`` is as above, and ``ar`` is the overall \n           acceptance rate (of the rejection steps that choose the ancestors);\n           otherwise output is simply ``paths``.\n        \"\"\"\n        idx = np.empty((self.T, M), dtype=int)\n        idx[-1, :] = rs.multinomial(self.wgt[-1].W, M=M)\n        if linear_cost:\n            ar = self._backward_sampling_ON(M, idx)\n        else:\n            self._backward_sampling_ON2(M, idx)\n        # When M=1, we want a list of states, not a list of arrays containing \n        # one state\n        if M == 1:\n            idx = idx.squeeze(axis=1)\n        paths = [self.X[t][idx[t]] for t in range(self.T)]\n        if linear_cost and return_ar:\n            return (paths, ar)\n        else:\n            return paths"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef backward_sampling_qmc(self, M):\n        self._check_h_orders()\n        u = qmc.sobol(M, self.T)\n        # the final particles have not been sorted\n        hT = hilbert.hilbert_sort(self.X[-1])\n        # searchsorted to avoid having to sort in place u according to u[:,T-1]\n        idx = np.searchsorted(np.cumsum(self.wgt[-1].W[hT]), u[:, -1])\n        paths = [self.X[-1][hT][idx], ]\n        for t in reversed(range(self.T - 1)):\n            idx = np.empty(M, 'int')\n            for m, xn in enumerate(paths[-1]):\n                lwm = self.wgt[t].lw + self.model.logpt(t + 1, self.X[t], xn)\n                # use ordered version here\n                cw = np.cumsum(rs.exp_and_normalise(lwm[self.h_orders[t]]))\n                idx[m] = np.searchsorted(cw, u[m, t])\n            paths.append(self.X[t][self.h_orders[t]][idx])\n        paths.reverse()\n        return paths", "response": "This function calculates the QMC version of backward sampling."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _twofilter_smoothing_ON2(self, t, ti, info, phi, lwinfo):\n        sp, sw = 0., 0.\n        upb = lwinfo.max() + self.wgt[t].lw.max()\n        if hasattr(self.model, 'upper_bound_trans'):\n            upb += self.model.upper_bound_trans(t + 1)\n        # Loop over n, to avoid having in memory a NxN matrix\n        for n in range(self.N):\n            omegan = np.exp(lwinfo + self.wgt[t].lw[n] - upb\n                            + self.model.logpt(t + 1, self.X[t][n],\n                                               info.hist.X[ti]))\n            sp += np.sum(omegan * phi(self.X[t][n], info.hist.X[ti]))\n            sw += np.sum(omegan)\n        return sp / sw", "response": "O ( N^2 version of two - filter smoothing. \n"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _twofilter_smoothing_ON(self, t, ti, info, phi, lwinfo, return_ess,\n                               modif_forward, modif_info):\n        \"\"\"O(N) version of two-filter smoothing.\n\n        This method should not be called directly, see twofilter_smoothing.\n        \"\"\"\n        if modif_info is not None:\n            lwinfo += modif_info\n        Winfo = rs.exp_and_normalise(lwinfo)\n        I = rs.multinomial(Winfo)\n        if modif_forward is not None:\n            lw = self.wgt[t].lw + modif_forward\n            W = rs.exp_and_normalise(lw)\n        else:\n            W = self.wgt[t].W\n        J = rs.multinomial(W)\n        log_omega = self.model.logpt(t + 1, self.X[t][J], info.hist.X[ti][I])\n        if modif_forward is not None:\n            log_omega -= modif_forward[J]\n        if modif_info is not None:\n            log_omega -= modif_info[I]\n        Om = rs.exp_and_normalise(log_omega)\n        est = np.average(phi(self.X[t][J], info.hist.X[ti][I]), axis=0,\n                         weights=Om)\n        if return_ess:\n            return (est, 1. / np.sum(Om**2))\n        else:\n            return est", "response": "O ( N ) version of two - filter smoothing."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning multiple SMC algorithms in parallel using multiple CPU cores.", "response": "def multiSMC(nruns=10, nprocs=0, out_func=None, **args):\n    \"\"\"Run SMC algorithms in parallel, for different combinations of parameters.\n\n\n    `multiSMC` relies on the `multiplexer` utility, and obeys the same logic. \n    A basic usage is:: \n\n        results = multiSMC(fk=my_fk_model, N=100, nruns=20, nprocs=0)\n\n    This runs the same SMC algorithm 20 times, using all available CPU cores. \n    The output, ``results``, is a list of 20 dictionaries; a given dict corresponds \n    to a single run, and contains the following (key, value) pairs:\n        + ``'run'``: a run identifier (a number between 0 and nruns-1)\n        + ``'output'``: the corresponding SMC object (once method run was completed)\n\n    Since a `SMC` object may take a lot of space in memory (especially when\n    the option ``store_history`` is set to True), it is possible to require\n    `multiSMC` to store only some chosen summary of the SMC runs, using option \n    `out_func`. For instance, if we only want to store the estimate \n    of the log-likelihood of the model obtained from each particle filter:: \n\n        of = lambda pf: pf.logLt\n        results = multiSMC(fk=my_fk_model, N=100, nruns=20, out_func=of)\n\n    It is also possible to vary the parameters. Say:: \n\n        results = multiSMC(fk=my_fk_model, N=[100, 500, 1000])\n\n    will run the same SMC algorithm 30 times: 10 times for N=100, 10 times for\n    N=500, and 10 times for N=1000. The number 10 comes from the fact that we\n    did not specify nruns, and its default value is 10. The 30 dictionaries\n    obtained in results will then contain an extra (key, value) pair that will\n    give the value of N for which the run was performed. \n\n    It is possible to vary several arguments. Each time a list must be\n    provided. The end result will amount to take a *cartesian product* of the\n    arguments:: \n\n        results = multiSMC(fk=my_fk_model, N=[100, 1000], resampling=['multinomial',\n                             'residual'], nruns=20)\n\n    In that case we run our algorithm 80 times: 20 times with N=100 and\n    resampling set to multinomial, 20 times with N=100 and resampling set to\n    residual and so on. \n\n    Parameters\n    ----------\n    * nruns: int, optional\n        number of runs (default is 10)\n    * nprocs: int, optional \n        number of processors to use; if negative, number of cores not to use.\n        Default value is 1 (no multiprocessing)\n    * out_func: callable, optional \n        function to transform the output of each SMC run. (If not given, output\n        will be the complete SMC object). \n    * args: dict\n        arguments passed to SMC class \n\n    Returns\n    -------\n    A list of dicts \n\n    See also\n    --------\n    `utils.multiplexer`: for more details on the syntax. \n    \"\"\"\n    def f(**args):\n        pf = SMC(**args) \n        pf.run()\n        return out_func(pf)\n\n    if out_func is None:\n        out_func = lambda x: x\n    return utils.multiplexer(f=f, nruns=nruns, nprocs=nprocs, seeding=True, \n                             **args)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlogging - density of X_t given X_t given X_x.", "response": "def logpt(self, t, xp, x):\n        \"\"\"Log-density of X_t given X_{t-1}.\n        \"\"\"\n        raise NotImplementedError(err_msg_missing_trans %\n                                  self.__class__.__name__)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nresetting weights after a resampling step.", "response": "def reset_weights(self):\n        \"\"\"Reset weights after a resampling step. \n        \"\"\"\n        if self.fk.isAPF:\n            lw = (rs.log_mean_exp(self.logetat, W=self.W)\n                  - self.logetat[self.A])\n            self.wgts = rs.Weights(lw=lw)\n        else:\n            self.wgts = rs.Weights()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef setup_auxiliary_weights(self):\n        if self.fk.isAPF:\n            self.logetat = self.fk.logeta(self.t - 1, self.X)\n            self.aux = self.wgts.add(self.logetat)\n        else:\n            self.aux = self.wgts", "response": "Compute auxiliary weights for APF. \n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlogging of the sum of the exp of the arguments.", "response": "def log_sum_exp(v):\n    \"\"\"Log of the sum of the exp of the arguments. \n\n    Parameters\n    ----------\n    v: ndarray\n\n    Returns\n    -------\n    l: float \n        l = log(sum(exp(v)))\n\n    Note\n    ----\n    use the log_sum_exp trick to avoid overflow: i.e. we remove the max of v\n    before exponentiating, then we add it back\n\n    See also\n    --------\n    log_mean_exp\n\n    \"\"\"\n    m = v.max()\n    return m + np.log(np.sum(np.exp(v - m)))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef log_mean_exp(v, W=None):\n    m = v.max()\n    V = np.exp(v - m)\n    if W is None:\n        return m + np.log(np.mean(V))\n    else:\n        return m + np.log(np.average(V, weights=W))", "response": "Returns log of weighted mean of exp of vector v."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef wmean_and_var(W, x):\n    m = np.average(x, weights=W, axis=0)\n    m2 = np.average(x**2, weights=W, axis=0)\n    v = m2 - m**2\n    return {'mean': m, 'var': v}", "response": "Component - wise weighted mean and variance."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nweight mean and variance of each component of a structured array.", "response": "def wmean_and_var_str_array(W, x): \n    \"\"\"Weighted mean and variance of each component of a structured array.\n\n    Parameters\n    ----------\n    W: (N,) ndarray\n        normalised weights (must be >=0 and sum to one). \n    x: (N,) structured array\n        data \n\n    Returns\n    -------\n    dictionary \n        {'mean':weighted_means, 'var':weighted_variances}\n    \"\"\"\n    m = np.empty(shape=x.shape[1:], dtype=x.dtype)\n    v = np.empty_like(m)\n    for p in x.dtype.names:\n        m[p], v[p] = wmean_and_var(W, x[p]).values()\n    return {'mean': m, 'var': v}"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef wquantiles(W, x, alphas=(0.25, 0.50, 0.75)):\n    if len(x.shape) == 1:\n        return _wquantiles(W, x, alphas=alphas)\n    elif len(x.shape) == 2: \n        return np.array([_wquantiles(W, x[:, i], alphas=alphas) \n                         for i in range(x.shape[1])])", "response": "Quantiles for weighted data."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef wquantiles_str_array(W, x, alphas=(0.25, 0.50, 0,75)):\n    return {p: wquantiles(W, x[p], alphas) for p in x.dtype.names}", "response": "quantiles for weighted data stored in a structured array."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef resampling_scheme(func):\n\n    @functools.wraps(func)\n    def modif_func(W, M=None):\n        M = W.shape[0] if M is None else M\n        return func(W, M)\n\n    rs_funcs[func.__name__] = modif_func\n    modif_func.__doc__ = rs_doc % func.__name__.capitalize()\n    return modif_func", "response": "Decorator for resampling schemes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef inverse_cdf(su, W):\n    j = 0\n    s = W[0]\n    M = su.shape[0]\n    A = np.empty(M, 'int')\n    for n in range(M):\n        while su[n] > s:\n            j += 1\n            s += W[j]\n        A[n] = j\n    return A", "response": "Inverse CDF algorithm for a finite distribution."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef uniform_spacings(N):\n    z = np.cumsum(-np.log(random.rand(N + 1)))\n    return z[:-1] / z[-1]", "response": "Generate ordered uniform variates in O ( N time."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add(self, delta):\n        if self.lw is None:\n            return Weights(lw=delta)\n        else:\n            return Weights(lw=self.lw + delta)", "response": "Increment weights for a set of log entries."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dequeue(self, k):\n        if self.j + k <= self.M:\n            out = self.A[self.j:(self.j + k)]\n            self.j += k\n        elif k <= self.M:\n            out = np.empty(k, 'int')\n            nextra = self.j + k - self.M\n            out[:(k - nextra)] = self.A[self.j:]\n            self.enqueue()\n            out[(k - nextra):] = self.A[:nextra]\n            self.j = nextra\n        else:\n            raise ValueError('MultinomialQueue: k must be <= M (the max \\\n                             capacity of the queue)')\n        return out", "response": "Outputs *k* draws from the multinomial distribution."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute Hilbert indices. Parameters ---------- xint: (N, d) int numpy.ndarray Returns ------- h: (N,) int numpy.ndarray Hilbert indices", "response": "def hilbert_array(xint):\n    \"\"\"Compute Hilbert indices. \n\n    Parameters\n    ----------\n    xint: (N, d) int numpy.ndarray\n\n    Returns\n    -------\n    h: (N,) int numpy.ndarray\n        Hilbert indices \n    \"\"\"\n    N, d = xint.shape\n    h = np.zeros(N, int64)\n    for n in range(N):\n        h[n] = Hilbert_to_int(xint[n, :])\n    return h"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef hilbert_sort(x):\n    d = 1 if x.ndim == 1 else x.shape[1]\n    if d == 1:\n        return np.argsort(x, axis=0)\n    xs = invlogit((x - np.mean(x, axis=0)) / np.std(x, axis=0))\n    maxint = np.floor(2**(62 / d))\n    xint = np.floor(xs * maxint).astype('int')\n    return np.argsort(hilbert_array(xint))", "response": "Hilbert sort of vectors according to their Hilbert index."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmeaning squared jumping distance estimated from chain.", "response": "def mean_sq_jump_dist(self, discard_frac=0.1):\n        \"\"\"Mean squared jumping distance estimated from chain. \n\n        Parameters\n        ----------\n        discard_frac: float\n            fraction of iterations to discard at the beginning (as a burn-in)\n\n        Returns\n        -------\n        float\n        \"\"\"\n        discard = int(self.niter * discard_frac)\n        return msjd(self.chain.theta[discard:])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd point v to the log - likelihood.", "response": "def update(self, v):\n        \"\"\"Adds point v\"\"\"\n        self.t += 1\n        g = self.gamma()\n        self.mu = (1. - g) * self.mu + g * v\n        mv = v - self.mu\n        self.Sigma = ((1. - g) * self.Sigma\n                      + g * np.dot(mv[:, np.newaxis], mv[np.newaxis, :]))\n        try:\n            self.L = cholesky(self.Sigma, lower=True)\n        except LinAlgError:\n            self.L = self.L0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntake a dict of lists into a list of dicts that represents the cartesian product of the initial lists", "response": "def cartesian_lists(d):\n    \"\"\"\n    turns a dict of lists into a list of dicts that represents\n    the cartesian product of the initial lists\n\n    Example\n    -------\n    cartesian_lists({'a':[0, 2], 'b':[3, 4, 5]}\n    returns\n    [ {'a':0, 'b':3}, {'a':0, 'b':4}, ... {'a':2, 'b':5} ]\n\n    \"\"\"\n    return [{k: v for k, v in zip(d.keys(), args)}\n            for args in itertools.product(*d.values())]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes a list of inputs and outputs for a function with kw arguments.", "response": "def cartesian_args(args, listargs, dictargs):\n    \"\"\" Compute a list of inputs and outputs for a function\n    with kw arguments.\n\n    args: dict\n      fixed arguments, e.g. {'x': 3}, then x=3 for all inputs\n    listargs: dict\n        arguments specified as a list; then the inputs\n        should be the Cartesian products of these lists\n    dictargs: dict\n        same as above, except the key will be used in the output\n        (see module doc for more explanation)\n\n    \"\"\"\n    ils = {k: [v, ] for k, v in args.items()}\n    ils.update(listargs)\n    ils.update({k: v.values() for k, v in dictargs.items()})\n    ols = listargs.copy()\n    ols.update({k: v.keys() for k, v in dictargs.items()})\n    return cartesian_lists(ils), cartesian_lists(ols)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef worker(qin, qout, f):\n    while not qin.empty():\n        i, args = qin.get()\n        qout.put((i, f(**args)))", "response": "A worker for multiplying a set of arguments in the input queue and computes \n    f for this set of arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef distribute_work(f, inputs, outputs=None, nprocs=1, out_key='output'):\n    if outputs is None:\n        outputs = [ip.copy() for ip in inputs]\n    if nprocs <= 0:\n        nprocs += multiprocessing.cpu_count()\n\n    #\u00a0no multiprocessing\n    if nprocs <= 1:\n        return [add_to_dict(op, f(**ip), key=out_key)\n                for ip, op in zip(inputs, outputs)]\n\n    # multiprocessing\n    queue_in = multiprocessing.Queue()\n    queue_out = multiprocessing.Queue()\n    procs = [multiprocessing.Process(target=worker,\n                                     args=(queue_in, queue_out, f))\n             for _ in range(nprocs)]\n    sent = [queue_in.put((i, args)) for i, args in enumerate(inputs)]\n    [p.start() for p in procs]\n    results = [queue_out.get() for _ in sent]\n    for i, r in results:\n        add_to_dict(outputs[i], r)\n    [p.join() for p in procs]\n\n    return outputs", "response": "Distribute work from inputs to outputs using multiprocessing"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning k distinct seeds for random number generation", "response": "def distinct_seeds(k):\n    \"\"\" returns k distinct seeds for random number generation\n    \"\"\"\n    seeds = []\n    for _ in range(k):\n        while True:\n            s = random.randint(2**32 - 1)\n            if s not in seeds:\n                break\n        seeds.append(s)\n    return seeds"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef multiplexer(f=None, nruns=1, nprocs=1, seeding=None, **args):\n    if not callable(f):\n        raise ValueError('multiplexer: function f missing, or not callable')\n    if seeding is None:\n        seeding = (nruns > 1)\n    # extra arguments (meant to be arguments for f)\n    fixedargs, listargs, dictargs = {}, {}, {}\n    listargs['run'] = list(range(nruns))\n    for k, v in args.items():\n        if isinstance(v, list):\n            listargs[k] = v\n        elif isinstance(v, dict):\n            dictargs[k] = v\n        else:\n            fixedargs[k] = v\n    # cartesian product\n    inputs, outputs = cartesian_args(fixedargs, listargs, dictargs)\n    for ip in inputs:\n        ip.pop('run')  # run is not an argument of f, just an id for output\n    # distributing different seeds\n    if seeding:\n        seeds = distinct_seeds(len(inputs))\n        for ip, op, s in zip(inputs, outputs, seeds):\n            ip['seed'] = s\n            op['seed'] = s\n    # the actual work happens here\n    return distribute_work(f, inputs, outputs, nprocs=nprocs)", "response": "Evaluate a function f for different parameters optionally in parallel."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrejecting an arbitrary number of SV times a given sample from N m s^2 times a given SV likelihood.", "response": "def reject_sv(m, s, y):\n    \"\"\" Sample from N(m, s^2) times SV likelihood using rejection. \n\n    SV likelihood (in x) corresponds to y ~ N(0, exp(x)).\n    \"\"\"\n    mp = m + 0.5 * s**2 * (-1. + y**2 * np.exp(-m))\n    ntries = 0\n    while True:\n        ntries += 1\n        x = stats.norm.rvs(loc=mp, scale=s)\n        u = stats.uniform.rvs()\n        if np.log(u) < - 0.5 * y**2 * (np.exp(-x) - np.exp(-m) * (1. + m - x)):\n            break\n        if ntries > 1000:\n            print('1000 failed attempt, m,s,y=%f, %f, %f' % (m, s, y))\n            break\n    return x"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef predmean(self, xp): \n        out = np.empty_like(xp)\n        for i in range(3):\n            out[:, i] = xp[:, i] + self.delta * xp[:, i+3]  # position\n            out[:, i+3] = xp[:, i+3]                      # velocity \n        return out", "response": "Expectation of X_t given X_t = xp\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef diff_ft(self, xt, yt):\n        a, b = self.a, self.b \n        ex = np.exp(a + np.matmul(b, xt))  # shape = (dy,)\n        grad = (-np.sum(ex[:, np.newaxis] * b, axis=0)\n                + np.sum(yt.flatten()[:, np.newaxis] * b, axis=0)) #TODO flatten\n        hess = np.zeros((self.dx, self.dx))\n        for k in range(self.dy):\n            hess -= ex[k] * np.outer(b[k,:], b[k,:]) \n        return grad, hess", "response": "First and second derivatives of log - density of Y_t = xt and Y_t = yt"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef approx_post(self, xp, yt):\n        xmax, Q = self.approx_likelihood(yt)\n        G = np.eye(self.dx)\n        covY = linalg.inv(Q)\n        pred = kalman.MeanAndCov(mean=self.predmean(xp), cov=self.SigX)\n        return kalman.filter_step(G, covY, pred, xmax)", "response": "approximates the law of X_t | Y_t returns a tuple of size 3 loc cov logpyt\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsimulating state and observation processes.", "response": "def simulate(self, T):\n        \"\"\"Simulate state and observation processes. \n\n        Parameters\n        ----------\n        T: int\n            processes are simulated from time 0 to time T-1\n\n        Returns\n        -------\n        x, y: lists\n            lists of length T\n        \"\"\"\n        x = []\n        for t in range(T):\n            law_x = self.PX0() if t == 0 else self.PX(t, x[-1])\n            x.append(law_x.rvs(size=1))\n        y = self.simulate_given_x(x)\n        return x, y"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef logpt(self, t, xp, x):\n        return self.ssm.PX(t, xp).logpdf(x)", "response": "PDF of X_t = xp logpdf of X_t = x"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes E [ x_t|x_t - 1 ]", "response": "def EXt(self, xp):\n        \"\"\"compute E[x_t|x_{t-1}]\"\"\"\n        return (1. - self.rho) * self.mu + self.rho * xp"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef posterior(self, x, sigma=1.):\n        pr0 = 1. / self.scale**2  # prior precision\n        prd = x.size / sigma**2  # data precision\n        varp = 1. / (pr0 + prd)  # posterior variance\n        mu = varp * (pr0 * self.loc + prd * x.mean())\n        return Normal(loc=mu, scale=np.sqrt(varp))", "response": "Model is X_1... X_n ~ N ( theta sigma^2 ) theta ~ self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the posterior of the model.", "response": "def posterior(self, x):\n        \"\"\"Model is X_1,...,X_n ~ N(0, 1/theta), theta ~\u00a0Gamma(a, b)\"\"\"\n        return Gamma(a=self.a + 0.5 * x.size,\n                     b=self.b + 0.5 * np.sum(x**2))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef posterior(self, x, s=1.):\n        pr0 = 1. / self.sigma**2  # prior precision\n        prd = x.size / s**2  # data precision\n        varp = 1. / (pr0 + prd)  # posterior variance\n        mu = varp * (pr0 * self.mu + prd * x.mean())\n        return TruncNormal(mu=mu, sigma=np.sqrt(varp), a=self.a, b=self.b)", "response": "Model is X_1... X_n ~ N ( theta s^2 ) theta ~ self s fixed"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nnoting if dim(u) < self.dim, the remaining columns are filled with 0 Useful in case the distribution is partly degenerate", "response": "def ppf(self, u):\n        \"\"\"\n        Note: if dim(u) < self.dim, the remaining columns are filled with 0\n        Useful in case the distribution is partly degenerate\n        \"\"\"\n        N, du = u.shape\n        if du < self.dim:\n            z = np.zeros((N, self.dim))\n            z[:, :du] = stats.norm.ppf(u)\n        else:\n            z = stats.norm.ppf(u)\n        return self.linear_transform(z)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef posterior(self, x, Sigma=None):\n        n = x.shape[0]\n        Sigma = np.eye(self.dim) if Sigma is None else Sigma\n        Siginv = inv(Sigma)\n        Qpost = inv(self.cov) + n * Siginv\n        Sigpost = inv(Qpost)\n        mupost = (np.matmul(Siginv, self.mean) + \n                  np.matmu(Siginv, np.sum(x, axis=0)))\n        return MvNormal(loc=mupost, cov=Sigpost)", "response": "Posterior for model X1... Xn ~ N ( theta Sigma."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nscore of the model at a given log - likelihood at a given time.", "response": "def psit(t, xp, x):\n    \"\"\" score of the model (gradient of log-likelihood at theta=theta_0)\n    \"\"\"\n    if t == 0:\n        return -0.5 / sigma0**2 + \\\n            (0.5 * (1. - phi0**2) / sigma0**4) * (x - mu0)**2\n    else:\n        return -0.5 / sigma0**2 + (0.5 / sigma0**4) * \\\n            ((x - mu0) - phi0 * (xp - mu0))**2"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the average n + one", "response": "def avg_n_nplusone(x):\n    \"\"\" returns x[0]/2, (x[0]+x[1])/2, ... (x[-2]+x[-1])/2, x[-1]/2 \n    \"\"\"\n\n    y = np.zeros(1 + x.shape[0])\n    hx = 0.5 * x \n    y[:-1] = hx\n    y[1:] += hx \n    return y"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef interpoled_resampling(W, x):\n    N = W.shape[0] \n    idx = np.argsort(x)\n    xs = x[idx] \n    ws = W[idx]\n    cs = np.cumsum(avg_n_nplusone(ws)) \n    u = random.rand(N)\n    xrs = np.empty(N)\n    where = np.searchsorted(cs, u)\n    # costs O(N log(N)) but algorithm has O(N log(N)) complexity anyway\n    for n in range(N): \n        m = where[n]\n        if m==0:\n            xrs[n] = xs[0]\n        elif m==N:\n            xrs[n] = xs[-1]\n        else:\n            xrs[n] = interpol(cs[m-1], cs[m], xs[m-1], xs[m], u[n])\n    return xrs", "response": "Resampling based on an interpolated CDF."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses a variable declaration and returns a tuple of type kind length derived - type attributes.", "response": "def parse_type(string,capture_strings,settings):\n    \"\"\"\n    Gets variable type, kind, length, and/or derived-type attributes from a\n    variable declaration.\n    \"\"\"\n    typestr = ''\n    for vtype in settings['extra_vartypes']:\n        typestr = typestr + '|' + vtype\n    var_type_re = re.compile(VAR_TYPE_STRING + typestr,re.IGNORECASE)\n    match = var_type_re.match(string)\n    if not match: raise Exception(\"Invalid variable declaration: {}\".format(string))\n\n    vartype = match.group().lower()\n    if DOUBLE_PREC_RE.match(vartype): vartype = \"double precision\"\n    rest = string[match.end():].strip()\n    kindstr = ford.utils.get_parens(rest)\n    rest = rest[len(kindstr):].strip()\n\n    if len(kindstr) < 3 and vartype != \"type\" and vartype != \"class\" and not kindstr.startswith('*'):\n        return (vartype, None, None, None, rest)\n    match = VARKIND_RE.search(kindstr)\n    if match:\n        if match.group(1):\n            star = False\n            args = match.group(1).strip()\n        else:\n            star = True\n            args = match.group(2).strip()\n            if args.startswith('('):\n                args = args[1:-1].strip()\n\n        args = re.sub(\"\\s\",\"\",args)\n        if vartype == \"type\" or vartype == \"class\" or vartype == \"procedure\":\n            PROTO_RE = re.compile(\"(\\*|\\w+)\\s*(?:\\((.*)\\))?\")\n            try:\n                proto = list(PROTO_RE.match(args).groups())\n                if not proto[1]: proto[1] = ''\n            except:\n                raise Exception(\"Bad type, class, or procedure prototype specification: {}\".format(args))\n            return (vartype, None, None, proto, rest)\n        elif vartype == \"character\":\n            if star:\n                return (vartype, None, args, None, rest)\n            else:\n                kind = None\n                length = None\n                if KIND_RE.search(args):\n                    kind = KIND_RE.sub(\"\",args)\n                    try:\n                        match = QUOTES_RE.search(kind)\n                        num = int(match.group()[1:-1])\n                        kind = QUOTES_RE.sub(captured_strings[num],kind)\n                    except:\n                        pass\n                elif LEN_RE.search(args):\n                    length = LEN_RE.sub(\"\",args)\n                else:\n                    length = args\n                return (vartype, kind, length, None, rest)\n        else:\n            kind = KIND_RE.sub(\"\",args)\n            return (vartype, kind, None, None, rest)\n\n    raise Exception(\"Bad declaration of variable type {}: {}\".format(vartype,string))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sort_items(self,items,args=False):\n    if self.settings['sort'].lower() == 'src': return\n    def alpha(i):\n        return i.name\n    def permission(i):\n        if args:\n            if i.intent == 'in': return 'b'\n            if i.intent == 'inout': return 'c'\n            if i.intent == 'out': return 'd'\n            if i.intent == '': return 'e'\n        perm = getattr(i, 'permission', '')\n        if perm == 'public': return 'b'\n        if perm == 'protected': return 'c'\n        if perm == 'private': return 'd'\n        return 'a'\n    def permission_alpha(i):\n        return permission(i) + '-' + i.name\n    def itype(i):\n        if i.obj == 'variable':\n            retstr = i.vartype\n            if retstr == 'class': retstr = 'type'\n            if i.kind: retstr = retstr + '-' + str(i.kind)\n            if i.strlen: retstr = retstr + '-' + str(i.strlen)\n            if i.proto:\n                retstr = retstr + '-' + i.proto[0]\n            return retstr\n        elif i.obj == 'proc':\n            if i.proctype != 'Function':\n                return i.proctype.lower()\n            else:\n                return i.proctype.lower() + '-' + itype(i.retvar)\n        else:\n            return i.obj\n    def itype_alpha(i):\n        return itype(i) + '-' + i.name\n\n    if self.settings['sort'].lower() == 'alpha':\n        items.sort(key=alpha)\n    elif self.settings['sort'].lower() == 'permission':\n        items.sort(key=permission)\n    elif self.settings['sort'].lower() == 'permission-alpha':\n        items.sort(key=permission_alpha)\n    elif self.settings['sort'].lower() == 'type':\n        items.sort(key=itype)\n    elif self.settings['sort'].lower() == 'type-alpha':\n        items.sort(key=itype_alpha)", "response": "Sort the items in the list as contained in the self s contents as contained in the list items as specified in the self s meta - data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef contents_size(self):\n        '''\n        Returns the number of different categories to be shown in the\n        contents side-bar in the HTML documentation.\n        '''\n        count = 0\n        if hasattr(self,'variables'): count += 1\n        if hasattr(self,'types'): count += 1\n        if hasattr(self,'modules'): count += 1\n        if hasattr(self,'submodules'): count += 1\n        if hasattr(self,'subroutines'): count += 1\n        if hasattr(self,'modprocedures'): count += 1\n        if hasattr(self,'functions'): count += 1\n        if hasattr(self,'interfaces'): count += 1\n        if hasattr(self,'absinterfaces'): count += 1\n        if hasattr(self,'programs'): count += 1\n        if hasattr(self,'boundprocs'): count += 1\n        if hasattr(self,'finalprocs'): count += 1\n        if hasattr(self,'enums'): count += 1\n        if hasattr(self,'procedure'): count += 1\n        if hasattr(self,'constructor'): count += 1\n        if hasattr(self,'modfunctions'): count += 1\n        if hasattr(self,'modsubroutines'): count += 1\n        if hasattr(self,'modprocs'): count += 1\n        if getattr(self,'src',None): count += 1\n        return count", "response": "Returns the size of the contents side - bar in the HTML documentation."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef markdown(self,md,project):\n        if len(self.doc) > 0:\n            if len(self.doc) == 1 and ':' in self.doc[0]:\n                words = self.doc[0].split(':')[0].strip()\n                if words.lower() not in ['author','date','license','version','category','summary','deprecated','display','graph']:\n                    self.doc.insert(0,'')\n                self.doc.append('')\n            self.doc = '\\n'.join(self.doc)\n            self.doc = md.convert(self.doc)\n            self.meta = md.Meta\n            md.reset()\n            md.Meta = {}\n        else:\n            if self.settings['warn'].lower() == 'true' and self.obj != 'sourcefile' and self.obj != 'genericsource':\n                #TODO: Add ability to print line number where this item is in file\n                print('Warning: Undocumented {} {} in file {}'.format(self.obj, self.name, self.hierarchy[0].name))\n            self.doc = \"\"\n            self.meta = {}\n\n        if self.parent:\n            self.display = self.parent.display\n\n        #~ print (self.meta)\n        for key in self.meta:\n            #~ print(key, self.meta[key])\n            if key == 'display':\n                tmp = [ item.lower() for item in self.meta[key] ]\n                if type(self) == FortranSourceFile:\n                    while 'none' in tmp:\n                        tmp.remove('none')\n                if len(tmp) == 0:\n                    pass\n                elif 'none' in tmp:\n                    self.display = []\n                elif 'public' not in tmp and 'private' not in tmp and 'protected' not in tmp:\n                    pass\n                else:\n                    self.display = tmp\n            elif len(self.meta[key]) == 1:\n                self.meta[key] = self.meta[key][0]\n            elif key == 'summary':\n                self.meta[key] = '\\n'.join(self.meta[key])\n        if hasattr(self,'num_lines'): self.meta['num_lines'] = self.num_lines\n\n        self.doc = ford.utils.sub_macros(ford.utils.sub_notes(self.doc),self.base_url)\n\n        if 'summary' in self.meta:\n            self.meta['summary'] = md.convert(self.meta['summary'])\n            self.meta['summary'] = ford.utils.sub_macros(ford.utils.sub_notes(self.meta['summary']),self.base_url)\n        elif PARA_CAPTURE_RE.search(self.doc):\n            if self.get_url() == None:\n                # There is no stand-alone webpage for this item (e.g.,\n                # an internal routine in a routine, so make the whole\n                # doc blob appear, without the link to \"more...\"\n                self.meta['summary'] = self.doc\n            else:\n                self.meta['summary'] = PARA_CAPTURE_RE.search(self.doc).group()\n        else:\n            self.meta['summary'] = ''\n        if self.meta['summary'].strip() != self.doc.strip():\n            self.meta['summary'] += '<a href=\"{}\" class=\"pull-right\"><emph>Read more&hellip;</emph></a>'.format(self.get_url())\n        if 'graph' not in self.meta:\n            self.meta['graph'] = self.settings['graph']\n        else:\n            self.meta['graph'] = self.meta['graph'].lower()\n        if 'graph_maxdepth' not in self.meta:\n            self.meta['graph_maxdepth'] = self.settings['graph_maxdepth']\n        if 'graph_maxnodes' not in self.meta:\n            self.meta['graph_maxnodes'] = self.settings['graph_maxnodes']\n\n        if self.obj == 'proc' or self.obj == 'type' or self.obj == 'program':\n            if 'source' not in self.meta:\n                self.meta['source'] = self.settings['source'].lower()\n            else:\n                self.meta['source'] = self.meta['source'].lower()\n            if self.meta['source'] == 'true':\n                if self.obj == 'proc':\n                    obj = self.proctype.lower()\n                else:\n                    obj = self.obj\n                regex = re.compile(self.SRC_CAPTURE_STR.format(obj,self.name), re.IGNORECASE|re.DOTALL|re.MULTILINE)\n                match = regex.search(self.hierarchy[0].raw_src)\n                if match:\n                    self.src = highlight(match.group(),FortranLexer(),HtmlFormatter())\n                else:\n                    self.src = ''\n                    if self.settings['warn'].lower() == 'true':\n                        print('Warning: Could not extract source code for {} {} in file {}'.format(self.obj, self.name, self.hierarchy[0].name))\n\n        if self.obj == 'proc':\n            if 'proc_internals' not in self.meta:\n                self.meta['proc_internals'] = self.settings['proc_internals'].lower()\n            else:\n                self.meta['proc_internals'] = self.meta['proc_internals'].lower()\n\n        # Create Markdown\n        for item in self.iterator('variables', 'modules', 'submodules', 'common',\n                                   'subroutines', 'modprocedures', 'functions',\n                                   'interfaces', 'absinterfaces', 'types',\n                                   'programs', 'blockdata', 'boundprocs',\n                                   'finalprocs', 'args', 'enums'):\n            if isinstance(item, FortranBase):\n                item.markdown(md, project)\n        if hasattr(self,'retvar'):\n            if self.retvar:\n                if isinstance(self.retvar, FortranBase):\n                    self.retvar.markdown(md, project)\n        if hasattr(self,'procedure'):\n            if isinstance(self.procedure, FortranBase):\n                self.procedure.markdown(md, project)\n        return", "response": "Process the documentation with Markdown to produce HTML."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsorts the components of the object.", "response": "def sort(self):\n        '''\n        Sorts components of the object.\n        '''\n        if hasattr(self,'variables'):\n            sort_items(self,self.variables)\n        if hasattr(self,'modules'):\n            sort_items(self,self.modules)\n        if hasattr(self,'submodules'):\n            sort_items(self,self.submodules)\n        if hasattr(self,'common'):\n            sort_items(self,self.common)\n        if hasattr(self,'subroutines'):\n            sort_items(self,self.subroutines)\n        if hasattr(self,'modprocedures'):\n            sort_items(self,self.modprocedures)\n        if hasattr(self,'functions'):\n            sort_items(self,self.functions)\n        if hasattr(self,'interfaces'):\n            sort_items(self,self.interfaces)\n        if hasattr(self,'absinterfaces'):\n            sort_items(self,self.absinterfaces)\n        if hasattr(self,'types'):\n            sort_items(self,self.types)\n        if hasattr(self,'programs'):\n            sort_items(self,self.programs)\n        if hasattr(self,'blockdata'):\n            sort_items(self,self.blockdata)\n        if hasattr(self,'boundprocs'):\n            sort_items(self,self.boundprocs)\n        if hasattr(self,'finalprocs'):\n            sort_items(self,self.finalprocs)\n        if hasattr(self,'args'):\n            #sort_items(self.args,args=True)\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprocess intra - site links to other parts of the program.", "response": "def make_links(self, project):\n        \"\"\"\n        Process intra-site links to documentation of other parts of the program.\n        \"\"\"\n        self.doc = ford.utils.sub_links(self.doc,project)\n        if 'summary' in self.meta:\n            self.meta['summary'] = ford.utils.sub_links(self.meta['summary'],project)\n\n        # Create links in the project\n        for item in self.iterator('variables', 'types', 'enums', 'modules',\n                                   'submodules', 'subroutines', 'functions',\n                                   'interfaces', 'absinterfaces', 'programs',\n                                   'boundprocs', 'args', 'bindings'):\n            if isinstance(item, FortranBase):\n                item.make_links(project)\n        if hasattr(self, 'retvar'):\n            if self.retvar:\n                if isinstance(self.retvar, FortranBase):\n                    self.retvar.make_links(project)\n        if hasattr(self, 'procedure'):\n            if isinstance(self.procedure, FortranBase):\n                self.procedure.make_links(project)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove anything which shouldn t be displayed.", "response": "def prune(self):\n        \"\"\"\n        Remove anything which shouldn't be displayed.\n        \"\"\"\n        def to_include(obj):\n            inc = obj.permission in self.display\n            if self.settings['hide_undoc'].lower() == 'true' and not obj.doc:\n                inc = False\n            return inc\n\n        if self.obj == 'proc' and self.meta['proc_internals'] == 'false':\n            self.functions = []\n            self.subroutines = []\n            self.types = []\n            self.interfaces = []\n            self.absinterfaces = []\n            self.variables = []\n        else:\n            self.functions = [obj for obj in self.functions if to_include(obj)]\n            self.subroutines = [obj for obj in self.subroutines if to_include(obj)]\n            self.types = [obj for obj in self.types if to_include(obj)]\n            self.interfaces = [obj for obj in self.interfaces if to_include(obj)]\n            self.absinterfaces = [obj for obj in self.absinterfaces if to_include(obj)]\n            self.variables = [obj for obj in self.variables if to_include(obj)]\n            if hasattr(self,'modprocedures'):\n                self.modprocedures = [obj for obj in self.modprocedures if to_include(obj)]\n            if hasattr(self,'modsubroutines'):\n                self.modsubroutines = [obj for obj in self.modsubroutines if to_include(obj)]\n            if hasattr(self,'modfunctions'):\n                self.modfunctions = [obj for obj in self.modfunctions if to_include(obj)]\n        # Recurse\n        for obj in self.absinterfaces:\n            obj.visible = True\n        for obj in self.iterator('functions', 'subroutines', 'types', 'interfaces', 'modprocedures', 'modfunctions', 'modsubroutines'):\n            obj.visible = True\n        for obj in self.iterator('functions', 'subroutines', 'types', 'modprocedures', 'modfunctions', 'modsubroutines'):\n            obj.prune()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_used_entities(self,use_specs):\n        if len(use_specs.strip()) == 0:\n            return (self.pub_procs, self.pub_absints, self.pub_types, self.pub_vars)\n        only = bool(self.ONLY_RE.match(use_specs))\n        use_specs = self.ONLY_RE.sub('',use_specs)\n        ulist = self.SPLIT_RE.split(use_specs)\n        ulist[-1] = ulist[-1].strip()\n        uspecs = {}\n        for item in ulist:\n            match = self.RENAME_RE.search(item)\n            if match:\n                uspecs[match.group(1).lower()] = match.group(2)\n            else:\n                uspecs[item.lower()] = item\n        ret_procs = {}\n        ret_absints = {}\n        ret_types = {}\n        ret_vars = {}\n        for name, obj in self.pub_procs.items():\n            name = name.lower()\n            if only:\n                if name in uspecs:\n                    ret_procs[name] = obj\n            else:\n                ret_procs[name] = obj\n        for name, obj in self.pub_absints.items():\n            name = name.lower()\n            if only:\n                if name in uspecs:\n                    ret_absints[name] = obj\n            else:\n                ret_absints[name] = obj\n        for name, obj in self.pub_types.items():\n            name = name.lower()\n            if only:\n                if name in uspecs:\n                    ret_types[name] = obj\n            else:\n                ret_types[name] = obj\n        for name, obj in self.pub_vars.items():\n            name = name.lower()\n            if only:\n                if name in uspecs:\n                    ret_vars[name] = obj\n            else:\n                ret_vars[name] = obj\n        return (ret_procs,ret_absints,ret_types,ret_vars)", "response": "Returns the entities which are used by a use statement. These are contained in dicts."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove anything which shouldn t be displayed.", "response": "def prune(self):\n        \"\"\"\n        Remove anything which shouldn't be displayed.\n        \"\"\"\n        self.boundprocs = [ obj for obj in self.boundprocs if obj.permission in self.display ]\n        self.variables = [ obj for obj in self.variables if obj.permission in self.display ]\n        for obj in self.boundprocs + self.variables:\n            obj.visible = True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the name for this item registered with this NameSelector.", "response": "def get_name(self,item):\n        \"\"\"\n        Return the name for this item registered with this NameSelector.\n        If no name has previously been registered, then generate a new\n        one.\n        \"\"\"\n        if not isinstance(item,ford.sourceform.FortranBase):\n            raise Exception('{} is not of a type derived from FortranBase'.format(str(item)))\n\n        if item in self._items:\n            return self._items[item]\n        else:\n            if item.get_dir() not in self._counts:\n                self._counts[item.get_dir()] = {}\n            if item.name in self._counts[item.get_dir()]:\n                num = self._counts[item.get_dir()][item.name] + 1\n            else:\n                num = 1\n            self._counts[item.get_dir()][item.name] = num\n            name = item.name.lower().replace('<','lt')\n            # name is already lower\n            name = name.replace('>','gt')\n            name = name.replace('/','SLASH')\n            if name == '': name = '__unnamed__'\n            if num > 1:\n                name = name + '~' + str(num)\n            self._items[item] = name\n            return name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninitialize the global documentation for a project.", "response": "def initialize():\n    \"\"\"\n    Method to parse and check configurations of FORD, get the project's \n    global documentation, and create the Markdown reader.\n    \"\"\"\n    try:\n        import multiprocessing\n        ncpus = '{0}'.format(multiprocessing.cpu_count())\n    except (ImportError, NotImplementedError):\n        ncpus = '0'\n\n    # Setup the command-line options and parse them.\n    parser = argparse.ArgumentParser(description=\"Document a program or library written in modern Fortran. Any command-line options over-ride those specified in the project file.\")\n    parser.add_argument(\"project_file\",help=\"file containing the description and settings for the project\",\n                        type=argparse.FileType('r'))\n    parser.add_argument(\"-d\",\"--src_dir\",action=\"append\",help='directories containing all source files for the project')\n    parser.add_argument(\"-p\",\"--page_dir\",help=\"directory containing the optional page tree describing the project\")\n    parser.add_argument(\"-o\",\"--output_dir\",help=\"directory in which to place output files\")\n    parser.add_argument(\"-s\",\"--css\",help=\"custom style-sheet for the output\")\n    parser.add_argument(\"-r\",\"--revision\",dest=\"revision\",help=\"Source code revision the project to document\")\n    parser.add_argument(\"--exclude\",action=\"append\",help=\"any files which should not be included in the documentation\")\n    parser.add_argument(\"--exclude_dir\",action=\"append\",help=\"any directories whose contents should not be included in the documentation\")\n    parser.add_argument(\"-e\",\"--extensions\",action=\"append\",help=\"extensions which should be scanned for documentation (default: f90, f95, f03, f08)\")\n    parser.add_argument(\"-m\",\"--macro\",action=\"append\",help=\"preprocessor macro (and, optionally, its value) to be applied to files in need of preprocessing.\")\n    parser.add_argument(\"-w\",\"--warn\",dest='warn',action='store_true',\n                        help=\"display warnings for undocumented items\")\n    parser.add_argument(\"--no-search\",dest='search',action='store_false',\n                        help=\"don't process documentation to produce a search feature\")\n    parser.add_argument(\"-q\",\"--quiet\",dest='quiet',action='store_true',\n                        help=\"do not print any description of progress\")\n    parser.add_argument(\"-V\", \"--version\", action=\"version\",\n                        version=\"{}, version {}\".format(__appname__,__version__))\n    parser.add_argument(\"--debug\",dest=\"dbg\",action=\"store_true\",\n                        help=\"display traceback if fatal exception occurs\")\n    parser.add_argument(\"-I\",\"--include\",action=\"append\",\n                        help=\"any directories which should be searched for include files\")\n    # Get options from command-line\n    args = parser.parse_args()\n    # Set up Markdown reader\n    md_ext = ['markdown.extensions.meta','markdown.extensions.codehilite',\n              'markdown.extensions.extra',MathExtension(),'md_environ.environ']\n    md = markdown.Markdown(extensions=md_ext, output_format=\"html5\",\n    extension_configs={})\n    # Read in the project-file. This will contain global documentation (which\n    # will appear on the homepage) as well as any information about the project\n    # and settings for generating the documentation.\n    proj_docs = args.project_file.read()\n    md.convert(proj_docs)\n    # Remake the Markdown object with settings parsed from the project_file\n    if 'md_base_dir' in md.Meta: md_base = md.Meta['md_base_dir'][0] \n    else: md_base = os.path.dirname(args.project_file.name)\n    md_ext.append('markdown_include.include')\n    if 'md_extensions' in md.Meta: md_ext.extend(md.Meta['md_extensions'])\n    md = markdown.Markdown(extensions=md_ext, output_format=\"html5\",\n            extension_configs={'markdown_include.include': {'base_path': md_base}})\n    md.reset()\n    # Re-read the project file\n    proj_docs = md.convert(proj_docs)\n    proj_data = md.Meta\n    md.reset()\n    # Get the default options, and any over-rides, straightened out\n    options = ['src_dir','extensions','fpp_extensions','fixed_extensions',\n               'output_dir','css','exclude',\n               'project','author','author_description','author_pic',\n               'summary','github','bitbucket','facebook','twitter',\n               'google_plus','linkedin','email','website','project_github',\n               'project_bitbucket','project_website','project_download',\n               'project_sourceforge','project_url','display','hide_undoc','version',\n               'year','docmark','predocmark','docmark_alt','predocmark_alt',\n               'media_dir','favicon','warn','extra_vartypes','page_dir',\n               'incl_src',\n               'source','exclude_dir','macro','include','preprocess','quiet',\n               'search','lower','sort','extra_mods','dbg','graph',\n               'graph_maxdepth', 'graph_maxnodes',\n               'license','extra_filetypes','preprocessor','creation_date',\n               'print_creation_date','proc_internals','coloured_edges',\n               'graph_dir','gitter_sidecar','mathjax_config','parallel',\n               'revision', 'fixed_length_limit']\n    defaults = {'src_dir':             ['./src'],\n                'extensions':          ['f90','f95','f03','f08','f15'],\n                'fpp_extensions':      ['F90','F95','F03','F08','F15','F','FOR'],\n                'fixed_extensions':    ['f','for','F','FOR'],\n                'output_dir':          './doc',\n                'project':             'Fortran Program',\n                'project_url':         '',\n                'display':             ['public','protected'],\n                'hide_undoc':          'false',\n                'year':                date.today().year,\n                'exclude':             [],\n                'exclude_dir':         [],\n                'docmark':             '!',\n                'docmark_alt':         '*',\n                'predocmark':          '>',\n                'predocmark_alt':      '|',\n                'favicon':             'default-icon',\n                'extra_vartypes':      [],\n                'incl_src':            'true',\n                'source':              'false',\n                'macro':               [],\n                'include':             [],\n                'preprocess':          'true',\n                'preprocessor':        '',\n                'proc_internals':      'false',\n                'warn':                'false',\n                'quiet':               'false',\n                'search':              'true',\n                'lower':               'false',\n                'sort':                'src',\n                'extra_mods':          [],\n                'dbg':                 True,\n                'graph':               'false',\n                'graph_maxdepth':      '10000',\n                'graph_maxnodes':      '1000000000',\n                'license':             '',\n                'extra_filetypes':     [],\n                'creation_date':       '%Y-%m-%dT%H:%M:%S.%f%z',\n                'print_creation_date': False,\n                'coloured_edges':      'false',\n                'parallel':            ncpus,\n                'fixed_length_limit':  'true',\n               }\n    listopts = ['extensions','fpp_extensions','fixed_extensions','display',\n                'extra_vartypes','src_dir','exclude','exclude_dir',\n                'macro','include','extra_mods','extra_filetypes']\n    # Evaluate paths relative to project file location\n    if args.warn:\n        args.warn = 'true'\n    else:\n        del args.warn\n    if args.quiet:\n        args.quiet = 'true'\n    else:\n        del args.quiet\n    if not args.search:\n        args.search = 'false'\n    else:\n        del args.search\n    for option in options:\n        if hasattr(args,option) and getattr(args,option):\n            proj_data[option] = getattr(args,option)\n        elif option in proj_data:\n            # Think if there is a safe  way to evaluate any expressions found in this list\n            #proj_data[option] = proj_data[option]\n            if option not in listopts:\n                proj_data[option] = '\\n'.join(proj_data[option])\n        elif option in defaults:\n           proj_data[option] = defaults[option]\n    base_dir = os.path.abspath(os.path.dirname(args.project_file.name))\n    proj_data['base_dir'] = base_dir\n    for var in ['src_dir','exclude_dir','include']:\n        if var in proj_data:\n            proj_data[var] = [os.path.normpath(os.path.join(base_dir,os.path.expanduser(os.path.expandvars(p)))) for p in proj_data[var]]\n    for var in ['page_dir','output_dir','graph_dir','media_dir','css','mathjax_config']:\n        if var in proj_data:\n            proj_data[var] = os.path.normpath(os.path.join(base_dir,os.path.expanduser(os.path.expandvars(proj_data[var]))))\n    if proj_data['favicon'].strip() != defaults['favicon']:\n        proj_data['favicon'] = os.path.normpath(os.path.join(base_dir,os.path.expanduser(os.path.expandvars(proj_data['favicon']))))\n    proj_data['display'] = [ item.lower() for item in proj_data['display'] ]\n    proj_data['incl_src'] = proj_data['incl_src'].lower()\n    proj_data['creation_date'] = datetime.now().strftime(proj_data['creation_date'])\n    relative = (proj_data['project_url'] == '')\n    proj_data['relative'] = relative\n    proj_data['extensions'] += [ext for ext in proj_data['fpp_extensions'] if ext not in proj_data['extensions']]\n    # Parse file extensions and comment characters for extra filetypes\n    extdict = {}\n    for ext in proj_data['extra_filetypes']:\n        sp = ext.split()\n        if len(sp) < 2: continue\n        if (len(sp)==2):\n            extdict[sp[0]] = (sp[1])        # (comment_char) only\n        else:\n            extdict[sp[0]] = (sp[1],sp[2])  # (comment_char and lexer_str)\n    proj_data['extra_filetypes'] = extdict\n    # Make sure no src_dir is contained within output_dir\n    for projdir in proj_data['src_dir']:\n        proj_path = ford.utils.split_path(projdir)\n        out_path  = ford.utils.split_path(proj_data['output_dir'])\n        for directory in out_path:\n            if len(proj_path) == 0:\n                break\n            if directory == proj_path[0]:\n                proj_path.remove(directory)\n            else:\n                break\n        else:\n            print('Error: directory containing source-code {} a subdirectory of output directory {}.'.format(proj_data['output_dir'],projdir))\n            sys.exit(1)\n    # Check that none of the docmarks are the same\n    if proj_data['docmark'] == proj_data['predocmark'] != '':\n        print('Error: docmark and predocmark are the same.')\n        sys.exit(1)\n    if proj_data['docmark'] == proj_data['docmark_alt'] != '':\n        print('Error: docmark and docmark_alt are the same.')\n        sys.exit(1)\n    if proj_data['docmark'] == proj_data['predocmark_alt'] != '':\n        print('Error: docmark and predocmark_alt are the same.')\n        sys.exit(1)\n    if proj_data['docmark_alt'] == proj_data['predocmark'] != '':\n        print('Error: docmark_alt and predocmark are the same.')\n        sys.exit(1)\n    if proj_data['docmark_alt'] == proj_data['predocmark_alt'] != '':\n        print('Error: docmark_alt and predocmark_alt are the same.')\n        sys.exit(1)\n    if proj_data['predocmark'] == proj_data['predocmark_alt'] != '':\n        print('Error: predocmark and predocmark_alt are the same.')\n        sys.exit(1)\n    # Add gitter sidecar if specified in metadata\n    if 'gitter_sidecar' in proj_data:\n        proj_docs += '''\n        <script>\n            ((window.gitter = {{}}).chat = {{}}).options = {{\n            room: '{}'\n            }};\n        </script>\n        <script src=\"https://sidecar.gitter.im/dist/sidecar.v1.js\" async defer></script>\n        '''.format(proj_data['gitter_sidecar'].strip())\n    # Handle preprocessor:\n    if proj_data['preprocess'].lower() == 'true':\n        if proj_data['preprocessor']:\n            preprocessor = proj_data['preprocessor'].split()\n        else:\n            preprocessor = ['cpp','-traditional-cpp','-E', '-D__GFORTRAN__']\n\n        # Check whether preprocessor works (reading nothing from stdin)\n        try:\n            devnull = open(os.devnull)\n            subprocess.Popen(preprocessor, stdin=devnull, stdout=devnull,\n                             stderr=devnull).communicate()\n        except OSError as ex:\n            print('Warning: Testing preprocessor failed')\n            print('  Preprocessor command: {}'.format(preprocessor))\n            print('  Exception: {}'.format(ex))\n            print('  -> Preprocessing turned off')\n            proj_data['preprocess'] = 'false'\n        else:\n            proj_data['preprocess'] = 'true'\n            proj_data['preprocessor'] = preprocessor\n    \n    # Get correct license\n    try:\n        proj_data['license'] = LICENSES[proj_data['license'].lower()]\n    except KeyError:\n        print('Warning: license \"{}\" not recognized.'.format(proj_data['license']))\n        proj_data['license'] = ''\n    # Return project data, docs, and the Markdown reader\n    md.reset()\n    md.Meta = {}\n    return (proj_data, proj_docs, md)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a stream from fixed source form to free source form.", "response": "def convertToFree(stream, length_limit=True):\n    \"\"\"Convert stream from fixed source form to free source form.\"\"\"\n    linestack = []\n        \n    for line in stream:\n        convline = FortranLine(line, length_limit)\n        \n        if convline.is_regular:\n            if convline.isContinuation and linestack: \n                linestack[0].continueLine()\n            for l in linestack:\n                yield str(l)\n            linestack = []\n            \n        linestack.append(convline)\n        \n    for l in linestack:\n        yield str(l)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef continueLine(self):\n\n        if not (self.isLong and self.is_regular):\n            self.line_conv = self.line_conv.rstrip() + \" &\\n\"\n        else:\n            temp = self.line_conv[:72].rstrip() + \" &\"\n            self.line_conv = temp.ljust(72) + self.excess_line", "response": "Insert line continuation symbol at end of line."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef id_mods(obj,modlist,intrinsic_mods={},submodlist=[]):\n    for i in range(len(obj.uses)):\n        for candidate in modlist:\n            if obj.uses[i][0].lower() == candidate.name.lower():\n                obj.uses[i] = [candidate, obj.uses[i][1]]\n                break\n        else:\n            if obj.uses[i][0].lower() in intrinsic_mods:\n                obj.uses[i] = [intrinsic_mods[obj.uses[i][0].lower()], obj.uses[i][1]]\n                continue\n    if getattr(obj,'ancestor',None):\n        for submod in submodlist:\n            if obj.ancestor.lower() == submod.name.lower():\n                obj.ancestor = submod\n                break\n    if hasattr(obj,'ancestor_mod'):\n        for mod in modlist:\n            if obj.ancestor_mod.lower() == mod.name.lower():\n                obj.ancestor_mod = mod\n                break\n    for modproc in getattr(obj,'modprocedures',[]):\n        id_mods(modproc,modlist,intrinsic_mods)\n    for func in getattr(obj,'functions',[]):\n        id_mods(func,modlist,intrinsic_mods)\n    for subroutine in getattr(obj,'subroutines',[]):\n        id_mods(subroutine,modlist,intrinsic_mods)", "response": "Match USE statements up with the right modules\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef allfiles(self):\n        for f in self.files:\n            yield f\n        for f in self.extra_files:\n            yield f", "response": "Yield all files in the archive."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nassociating various constructs with each other.", "response": "def correlate(self):\n        \"\"\"\n        Associates various constructs with each other.\n        \"\"\"\n\n        print(\"Correlating information from different parts of your project...\")\n                        \n        non_local_mods = INTRINSIC_MODS        \n        for item in self.settings['extra_mods']:\n            i = item.index(':')\n            if i < 0:\n                print('Warning: could not parse extra modules \"\"'.format(item))\n                continue\n            name = item[:i].strip()\n            url = item[i+1:].strip()\n            non_local_mods[name.lower()] = '<a href=\"{}\">{}</a>'.format(url,name)\n        \n        # Match USE statements up with the right modules\n        for s in self.modules:\n            id_mods(s, self.modules, non_local_mods, self.submodules)\n        for s in self.procedures:\n            id_mods(s, self.modules, non_local_mods, self.submodules)\n        for s in self.programs:\n            id_mods(s, self.modules, non_local_mods, self.submodules)\n        for s in self.submodules:\n            id_mods(s, self.modules, non_local_mods, self.submodules)\n        for s in self.blockdata:\n            id_mods(s, self.modules, non_local_mods, self.submodules)\n            \n        # Get the order to process other correlations with\n        deplist = {}\n        \n        def get_deps(item):\n            uselist = [m[0] for m in item.uses]\n            for proc in getattr(item,'subroutines',[]):\n                uselist.extend(get_deps(proc))\n            for proc in getattr(item,'functions',[]):\n                uselist.extend(get_deps(proc))\n            for proc in getattr(item,'modprocedures',[]):\n                uselist.extend(get_deps(proc))\n            return uselist\n        \n        for mod in self.modules:\n            uselist = get_deps(mod)\n            uselist = [m for m in uselist if type(m) == ford.sourceform.FortranModule]\n            deplist[mod] = set(uselist)\n            mod.deplist = uselist\n        for mod in self.submodules:\n            if type(mod.ancestor_mod) is ford.sourceform.FortranModule:\n                uselist = get_deps(mod)\n                uselist = [m for m in uselist if type(m) == ford.sourceform.FortranModule]\n                if mod.ancestor:\n                    if type(mod.ancestor) is ford.sourceform.FortranSubmodule:\n                        uselist.insert(0,mod.ancestor)\n                    elif self.settings['warn'].lower() == 'true':\n                        print('Warning: could not identify parent SUBMODULE of SUBMODULE ' + mod.name)\n                else:\n                    uselist.insert(0,mod.ancestor_mod)\n                mod.deplist = uselist\n                deplist[mod] = set(uselist)\n            elif self.settings['warn'].lower() == 'true':\n                print('Warning: could not identify parent MODULE of SUBMODULE ' + mod.name)\n        # Get dependencies for programs and top-level procedures as well,\n        # if dependency graphs are to be produced\n        if self.settings['graph'].lower() == 'true':\n            for proc in self.procedures:\n                proc.deplist = set([m for m in get_deps(proc) if type(m) == ford.sourceform.FortranModule])\n            for prog in self.programs:\n                prog.deplist = set([m for m in get_deps(prog) if type(m) == ford.sourceform.FortranModule])\n            for block in self.blockdata:\n                block.deplist = set([m for m in get_deps(block) if type(m) == ford.sourceform.FortranModule])\n        ranklist = toposort.toposort_flatten(deplist)\n        for proc in self.procedures:\n            if proc.parobj == 'sourcefile': ranklist.append(proc)\n        ranklist.extend(self.programs)\n        ranklist.extend(self.blockdata)\n\n        # Perform remaining correlations for the project\n        for container in ranklist:\n            if type(container) != str: container.correlate(self)\n        for container in ranklist:\n            if type(container) != str: container.prune()\n\n        if self.settings['project_url'] == '.':\n            url = '..'\n        else:\n            url = self.settings['project_url']\n\n        for sfile in self.files:\n            for module in sfile.modules:\n                for function in module.functions:\n                    self.procedures.append(function)\n                for subroutine in module.subroutines:\n                    self.procedures.append(subroutine)\n                for interface in module.interfaces:\n                    self.procedures.append(interface)\n                for absint in module.absinterfaces:\n                    self.absinterfaces.append(absint)\n                for dtype in module.types:\n                    self.types.append(dtype)\n\n            for module in sfile.submodules:\n                for function in module.functions:\n                    self.procedures.append(function)\n                for subroutine in module.subroutines:\n                    self.procedures.append(subroutine)\n                for function in module.modfunctions:\n                    self.submodprocedures.append(function)\n                for subroutine in module.modsubroutines:\n                    self.submodprocedures.append(subroutine)\n                for modproc in module.modprocedures:\n                    self.submodprocedures.append(modproc)\n                for interface in module.interfaces:\n                    self.procedures.append(interface)\n                for absint in module.absinterfaces:\n                    self.absinterfaces.append(absint)\n                for dtype in module.types:\n                    self.types.append(dtype)\n\n            for program in sfile.programs:\n                for function in program.functions:\n                    self.procedures.append(function)\n                for subroutine in program.subroutines:\n                    self.procedures.append(subroutine)\n                for interface in program.interfaces:\n                    self.procedures.append(interface)\n                for absint in program.absinterfaces:\n                    self.absinterfaces.append(absint)\n                for dtype in program.types:\n                    self.types.append(dtype)\n\n            for block in sfile.blockdata:\n                for dtype in block.types:\n                    self.types.append(dtype)\n\n        def sum_lines(*argv, **kwargs):\n            \"\"\" Wrapper for minimizing memory consumption \"\"\"\n            routine = kwargs.get('func', 'num_lines')\n            n = 0\n            for arg in argv:\n                for item in arg:\n                    n += getattr(item, routine)\n            return n\n        self.mod_lines = sum_lines(self.modules, self.submodules)\n        self.proc_lines = sum_lines(self.procedures)\n        self.file_lines = sum_lines(self.files)\n        self.type_lines = sum_lines(self.types)\n        self.type_lines_all = sum_lines(self.types, func='num_lines_all')\n        self.absint_lines = sum_lines(self.absinterfaces)\n        self.prog_lines = sum_lines(self.programs)\n        self.block_lines = sum_lines(self.blockdata)\n        print()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef markdown(self,md,base_url='..'):\n        print(\"\\nProcessing documentation comments...\")\n        ford.sourceform.set_base_url(base_url)        \n        if self.settings['warn'].lower() == 'true': print()\n        for src in self.allfiles:\n            src.markdown(md, self)", "response": "Process the documentation with Markdown to produce HTML."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_links(self,base_url='..'):\n        ford.sourceform.set_base_url(base_url)        \n        for src in self.allfiles:\n            src.make_links(self)", "response": "Substitute intrasite links to documentation for other parts of \n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_srcdir_list(self,exclude_dirs):\n        srcdir_list = []\n        for topdir in self.topdirs:\n            srcdir_list.append(topdir)\n            srcdir_list += self.recursive_dir_list(topdir,exclude_dirs)\n        return srcdir_list", "response": "Recursively walks the directory tree and returns a list of all the source directories that are not in exclude_dirs."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sub_notes(docs):\n    def substitute(match):\n        ret = \"</p><div class=\\\"alert alert-{}\\\" role=\\\"alert\\\"><h4>{}</h4>\" \\\n              \"<p>{}</p></div>\".format(NOTE_TYPE[match.group(1).lower()],\n                                       match.group(1).capitalize(), match.group(2))\n        if len(match.groups()) >= 4 and not match.group(4): ret += '\\n<p>'\n        return ret\n    for regex in NOTE_RE:\n        docs = regex.sub(substitute,docs)\n    return docs", "response": "Substitute special controls for notes warnings todos and bugs with\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_parens(line,retlevel=0,retblevel=0):\n    if len(line) == 0: return line\n    parenstr = ''\n    level = 0\n    blevel = 0\n    for char in line:\n        if char == '(':\n            level += 1\n        elif char == ')':\n            level -= 1\n        elif char == '[':\n            blevel += 1\n        elif char == ']':\n            blevel -= 1\n        elif (char.isalpha() or char == '_' or char == ':' or char == ',' \n          or char == ' ') and level == retlevel and blevel == retblevel:\n            return parenstr\n        parenstr = parenstr + char\n    \n    if level == retlevel and blevel == retblevel: return parenstr    \n    raise Exception(\"Couldn't parse parentheses: {}\".format(line))", "response": "Given a string and a level of open and close parenthesis returns the portion of the string starting with the corresponding open parenthesis and returns the portion of the string going to the corresponding close parenthesis."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef paren_split(sep,string):\n    if len(sep) != 1: raise Exception(\"Separation string must be one character long\")\n    retlist = []\n    level = 0\n    blevel = 0\n    left = 0\n    for i in range(len(string)):\n        if string[i] == \"(\": level += 1\n        elif string[i] == \")\": level -= 1\n        elif string[i] == \"[\": blevel += 1\n        elif string[i] == \"]\": blevel -= 1\n        elif string[i] == sep and level == 0 and blevel == 0:\n            retlist.append(string[left:i])\n            left = i+1\n    retlist.append(string[left:])\n    return retlist", "response": "Splits the string into pieces divided by sep when sep is outside of parentheses."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef quote_split(sep,string):\n    if len(sep) != 1: raise Exception(\"Separation string must be one character long\")\n    retlist = []\n    squote = False\n    dquote = False\n    left = 0\n    i = 0\n    while i < len(string):\n        if string[i] == '\"' and not dquote:\n            if not squote:\n                squote = True\n            elif (i+1) < len(string) and string[i+1] == '\"':\n                i += 1\n            else:\n                squote = False\n        elif string[i] == \"'\" and not squote:\n            if not dquote:\n                dquote = True\n            elif (i+1) < len(string) and string[i+1] == \"'\":\n                i += 1\n            else:\n                dquote = False            \n        elif string[i] == sep and not dquote and not squote:\n            retlist.append(string[left:i])\n            left = i + 1\n        i += 1\n    retlist.append(string[left:])\n    return retlist", "response": "Splits the string into pieces divided by sep when sep in not inside quotes."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef split_path(path):\n    '''\n    Splits the argument into its constituent directories and returns them as\n    a list.\n    '''\n    def recurse_path(path,retlist):\n        if len(retlist) > 100:\n            fullpath = os.path.join(*([ path, ] + retlist))\n            print(\"Directory '{}' contains too many levels\".format(fullpath))\n            exit(1)\n        head, tail = os.path.split(path)\n        if len(tail) > 0:\n            retlist.insert(0,tail)\n            recurse_path(head,retlist)\n        elif len(head) > 1:\n            recurse_path(head,retlist)\n        else:\n            return\n\n    retlist = []\n    path = os.path.realpath(os.path.normpath(path))\n    drive, path = os.path.splitdrive(path)\n    if len(drive) > 0: retlist.append(drive)\n    recurse_path(path,retlist)\n    return retlist", "response": "Splits the argument into its constituent directories and returns them as\n    a list."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreplace links to different parts of the program with the appropriate URL.", "response": "def sub_links(string,project):\n    '''\n    Replace links to different parts of the program, formatted as\n    [[name]] or [[name(object-type)]] with the appropriate URL. Can also\n    link to an item's entry in another's page with the syntax\n    [[parent-name:name]]. The object type can be placed in parentheses\n    for either or both of these parts.\n    '''\n    LINK_TYPES    = { 'module': 'modules',\n                      'type': 'types',\n                      'procedure': 'procedures',\n                      'subroutine': 'procedures',\n                      'function': 'procedures',\n                      'proc': 'procedures',\n                      'file': 'allfiles',\n                      'interface': 'absinterfaces',\n                      'absinterface': 'absinterfaces',\n                      'program': 'programs',\n                      'block': 'blockdata' }\n        \n    SUBLINK_TYPES = { 'variable': 'variables',\n                      'type': 'types',\n                      'constructor': 'constructor',\n                      'interface': 'interfaces',\n                      'absinterface': 'absinterfaces',\n                      'subroutine': 'subroutines',\n                      'function': 'functions',\n                      'final': 'finalprocs',\n                      'bound': 'boundprocs',\n                      'modproc': 'modprocs',\n                      'common': 'common' }\n        \n    \n    def convert_link(match):\n        ERR = 'Warning: Could not substitute link {}. {}'\n        url = ''\n        name = ''\n        found = False\n        searchlist = []\n        item = None\n        \n        #[name,obj,subname,subobj]\n        if not match.group(2):\n            for key, val in LINK_TYPES.items():\n                searchlist.extend(getattr(project,val))\n        else:\n            if match.group(2).lower() in LINK_TYPES:\n                searchlist.extend(getattr(project,LINK_TYPES[match.group(2).lower()]))\n            else:\n                print(ERR.format(match.group(),'Unrecognized classification \"{}\".'.format(match.group(2))))\n                return match.group()\n        \n        for obj in searchlist:\n            if match.group(1).lower() == obj.name.lower():\n                url = obj.get_url()\n                name = obj.name\n                found = True\n                item = obj\n                break\n        else:\n            print(ERR.format(match.group(),'\"{}\" not found.'.format(match.group(1))))\n            url = ''\n            name = match.group(1)\n        \n        if found and match.group(3):\n            searchlist = []\n            if not match.group(4):\n                for key, val in SUBLINK_TYPES.items():\n                    if val == 'constructor':\n                        if getattr(item,'constructor', False):\n                            searchlist.append(item.constructor)\n                        else:\n                            continue\n                    else:\n                        searchlist.extend(getattr(item,val,[]))\n            else:\n                if match.group(4).lower() in SUBLINK_TYPES:\n                    if hasattr(item,SUBLINK_TYPES[match.group(4).lower()]):\n                        if match.group(4).lower == 'constructor':\n                            if item.constructor:\n                                searchlist.append(item.constructor)\n                        else:\n                            searchlist.extend(getattr(item,SUBLINK_TYPES[match.group(4).lower()]))\n                    else:\n                        print(ERR.format(match.group(),'\"{}\" can not be contained in \"{}\"'.format(match.group(4),item.obj)))\n                        return match.group()\n                else:\n                    print(ERR.format(match.group(),'Unrecognized classification \"{}\".'.format(match.group(2))))\n                    return match.group()\n            \n            for obj in searchlist:\n                if match.group(3).lower() == obj.name.lower():\n                    url = url + '#' + obj.anchor\n                    name = obj.name\n                    item = obj\n                    break\n            else:\n                print(ERR.format(match.group(),'\"{0}\" not found in \"{1}\", linking to page for \"{1}\" instead.'.format(match.group(3),name)))\n\n        if found:\n            return '<a href=\"{}\">{}</a>'.format(url,name)\n        else:\n            return '<a>{}</a>'.format(name)\n\n    # Get information from links (need to build an RE)\n    string = LINK_RE.sub(convert_link,string)\n    return string"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sub_macros(string,base_url):\n    '''\n    Replaces macros in documentation with their appropriate values. These macros\n    are used for things like providing URLs.\n    '''\n    macros = { '|url|': base_url,\n               '|media|': os.path.join(base_url,'media'),\n               '|page|': os.path.join(base_url,'page')\n             }\n    for key, val in macros.items():\n        string = string.replace(key,val)\n    return string", "response": "Replaces macros in documentation with their appropriate values."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreplacing shutil. copytree to avoid problems on certain file systems.", "response": "def copytree(src, dst):\n    \"\"\"Replaces shutil.copytree to avoid problems on certain file systems.\n\n    shutil.copytree() and shutil.copystat() invoke os.setxattr(), which seems\n    to fail when called for directories on at least one NFS file system.\n    The current routine is a simple replacement, which should be good enough for\n    Ford.\n    \"\"\"\n    def touch(path):\n        now = time.time()\n        try:\n            # assume it's there\n            os.utime(path, (now, now))\n        except os.error:\n            # if it isn't, try creating the directory,\n            # a file with that name\n            os.makedirs(os.path.dirname(path))\n            open(path, \"w\").close()\n            os.utime(path, (now, now))\n\n    for root, dirs, files in os.walk(src):\n        relsrcdir = os.path.relpath(root, src)\n        dstdir = os.path.join(dst, relsrcdir)\n        if not os.path.exists(dstdir):\n            try:\n                os.makedirs(dstdir)\n            except OSError as ex:\n                if ex.errno != errno.EEXIST:\n                    raise\n        for ff in files:\n            shutil.copy(os.path.join(root, ff), os.path.join(dstdir, ff))\n            touch(os.path.join(dstdir, ff))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntruncate the string to the specified length.", "response": "def truncate(string, width):\n    \"\"\"\n    Truncates/pads the string to be the the specified length,\n    including ellipsis dots if truncation occurs.\n    \"\"\"\n    if len(string) > width:\n        return string[:width-3] + '...'\n    else:\n        return string.ljust(width)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef html(self):\n        return self.render(self.data, self.proj, self.obj)", "response": "Returns the HTML representation of the object"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a FortranObject to the appropriate list if not already present.", "response": "def register(self,obj,cls=type(None),hist={}):\n        \"\"\"\n        Takes a FortranObject and adds it to the appropriate list, if\n        not already present.\n        \"\"\"\n        #~ ident = getattr(obj,'ident',obj)\n        if is_submodule(obj,cls):\n            if obj not in self.submodules: self.submodules[obj] = SubmodNode(obj,self)\n        elif is_module(obj,cls):\n            if obj not in self.modules: self.modules[obj] = ModNode(obj,self)\n        elif is_type(obj,cls):\n            if obj not in self.types: self.types[obj] = TypeNode(obj,self,hist)\n        elif is_proc(obj,cls):\n            if obj not in self.procedures: self.procedures[obj] = ProcNode(obj,self,hist)\n        elif is_program(obj,cls):\n            if obj not in self.programs: self.programs[obj] = ProgNode(obj,self)\n        elif is_sourcefile(obj,cls):\n            if obj not in self.sourcefiles: self.sourcefiles[obj] = FileNode(obj,self)\n        elif is_blockdata(obj,cls):\n            if obj not in self.blockdata: self.blockdata[obj] = BlockNode(obj,self)\n        else:\n            raise BadType(\"Object type {} not recognized by GraphData\".format(type(obj).__name__))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_node(self,obj,cls=type(None),hist={}):\n        #~ ident = getattr(obj,'ident',obj)\n        if obj in self.modules and is_module(obj,cls):\n            return self.modules[obj]\n        elif obj in self.submodules and is_submodule(obj,cls):\n            return self.submodules[obj]\n        elif obj in self.types and is_type(obj,cls):\n            return self.types[obj]\n        elif obj in self.procedures and is_proc(obj,cls):\n            return self.procedures[obj]\n        elif obj in self.programs and is_program(obj,cls):\n            return self.programs[obj]\n        elif obj in self.sourcefiles and is_sourcefile(obj,cls):\n            return self.sourcefiles[obj]\n        elif obj in self.blockdata and is_blockdata(obj,cls):\n            return self.blockdata[obj]\n        else:\n            self.register(obj,cls,hist)\n            return self.get_node(obj,cls,hist)", "response": "Returns the node corresponding to obj. If the node does not exist it will create it."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_to_graph(self, nodes, edges, nesting):\n        if (len(nodes) + len(self.added)) > self.max_nodes:\n            if nesting < 2:\n                self.hopNodes = nodes\n                self.hopEdges = edges\n            self.truncated = nesting\n            return False\n        else:\n            for n in nodes:\n                self.dot.node(n.ident, **n.attribs)\n            for e in edges:\n                if len(e) == 5:\n                    self.dot.edge(e[0].ident, e[1].ident, style=e[2],\n                                  color=e[3], label=e[4])\n                else:\n                    self.dot.edge(e[0].ident, e[1].ident, style=e[2],\n                                  color=e[3])\n            self.added.update(nodes)\n            return True", "response": "Adds nodes and edges to the graph as long as the maximum number of nodes is not exceeded. Returns True if the graph was extended False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_nodes(self, nodes, nesting=1):\n        hopNodes = set()  # nodes in this hop\n        hopEdges = []     # edges in this hop\n        # get nodes and edges for this hop\n        for i, n in zip(range(len(nodes)), nodes):\n            r, g, b = rainbowcolour(i, len(nodes))\n            colour = '#%02X%02X%02X' % (r, g, b)\n            for nu in n.uses:\n                if nu not in self.added:\n                    hopNodes.add(nu)\n                hopEdges.append((n, nu, 'dashed', colour))\n            if hasattr(n, 'ancestor'):\n                if n.ancestor not in self.added:\n                    hopNodes.add(n.ancestor)\n                hopEdges.append((n, n.ancestor, 'solid', colour))\n        # add nodes, edges and attributes to the graph if maximum number of\n        # nodes is not exceeded\n        if self.add_to_graph(hopNodes, hopEdges, nesting):\n            self.dot.attr('graph', size='11.875,1000.0')", "response": "Adds nodes and edges for generating the relationship between modules and submodules listed in nodes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd nodes and edges showing dependencies between source files listed in the nodes.", "response": "def add_nodes(self, nodes, nesting=1):\n        \"\"\"\n        Adds edges showing dependencies between source files listed in\n        the nodes.\n        \"\"\"\n        hopNodes = set()  # nodes in this hop\n        hopEdges = []     # edges in this hop\n        # get nodes and edges for this hop\n        for i, n in zip(range(len(nodes)), nodes):\n            r, g, b = rainbowcolour(i, len(nodes))\n            colour = '#%02X%02X%02X' % (r, g, b)\n            for ne in n.efferent:\n                if ne not in self.added:\n                    hopNodes.add(ne)\n                hopEdges.append((ne, n, 'solid', colour))\n        # add nodes and edges to the graph if maximum number of nodes is not\n        # exceeded\n        self.add_to_graph(hopNodes, hopEdges, nesting)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds edges indicating the call - tree for the procedures listed in and the nodes in the node list.", "response": "def add_nodes(self, nodes, nesting=1):\n        \"\"\"\n        Adds edges indicating the call-tree for the procedures listed in\n        the nodes.\n        \"\"\"\n        hopNodes = set()  # nodes in this hop\n        hopEdges = []     # edges in this hop\n        # get nodes and edges for this hop\n        for i, n in zip(range(len(nodes)), nodes):\n            r, g, b = rainbowcolour(i, len(nodes))\n            colour = '#%02X%02X%02X' % (r, g, b)\n            for p in n.calls:\n                if p not in hopNodes:\n                    hopNodes.add(p)\n                hopEdges.append((n, p, 'solid', colour))\n            for p in getattr(n, 'interfaces', []):\n                if p not in hopNodes:\n                    hopNodes.add(p)\n                hopEdges.append((n, p, 'dashed', colour))\n        # add nodes, edges and attributes to the graph if maximum number of\n        # nodes is not exceeded\n        if self.add_to_graph(hopNodes, hopEdges, nesting):\n            self.dot.attr('graph', size='11.875,1000.0')\n            self.dot.attr('graph', concentrate='false')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef exception(self, url, exception):\n        '''What to return when there's an exception.'''\n        return (time.time() + self.ttl, self.factory(url))", "response": "What to return when there s an exception."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a timestamp for the provided datestring described by RFC 7231.", "response": "def parse_date(string):\n    '''Return a timestamp for the provided datestring, described by RFC 7231.'''\n    parsed = email.utils.parsedate_tz(string)\n    if parsed is None:\n        raise ValueError(\"Invalid time.\")\n    parsed = list(parsed)\n    # Default time zone is GMT/UTC\n    parsed[9] = 0 if parsed[9] is None else parsed[9]\n    return email.utils.mktime_tz(parsed)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ttl(self, response):\n        '''Get the ttl from headers.'''\n        # If max-age is specified in Cache-Control, use it and ignore any\n        # Expires header, as per RFC2616 Sec. 13.2.4.\n        cache_control = response.headers.get('cache-control')\n        if cache_control is not None:\n            for directive in cache_control.split(','):\n                name, _, value = directive.lower().partition('=')\n                name = name.strip()\n                if name in ('no-store', 'must-revalidate', 'no-cache'):\n                    return max(self.minimum, 0)\n                elif name in ('s-maxage', 'max-age'):\n                    try:\n                        return max(self.minimum, int(value.strip()))\n                    except ValueError:\n                        logger.warn(\n                            'Could not parse %s=%s', name, value, exc_info=1)\n\n        # Check the Expires header\n        expires = response.headers.get('expires')\n        if expires is not None:\n            # Evaluate the expiration relative to the server-provided date\n            date = response.headers.get('date')\n            if date is not None:\n                try:\n                    date = parse_date(date)\n                except ValueError:\n                    logger.warn(\n                        'Could not parse date string %s', date, exc_info=1)\n                    date = time.time()\n            else:\n                date = time.time()\n\n            try:\n                return max(self.minimum, parse_date(expires) - date)\n            except ValueError:\n                logger.warn(\n                    'Could not parse date string %s', expires, exc_info=1)\n\n        return self.default", "response": "Get the ttl from headers."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(self):\n        '''Get the wrapped object.'''\n        if (self.obj is None) or (time.time() >= self.expires):\n            with self.lock:\n                self.expires, self.obj = self.factory()\n                if isinstance(self.obj, BaseException):\n                    self.exception = self.obj\n                else:\n                    self.exception = None\n\n        if self.exception:\n            raise self.exception\n        else:\n            return self.obj", "response": "Get the wrapped object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, url):\n        '''Get the entity that corresponds to URL.'''\n        robots_url = Robots.robots_url(url)\n        if robots_url not in self.cache:\n            self.cache[robots_url] = ExpiringObject(partial(self.factory, robots_url))\n        return self.cache[robots_url].get()", "response": "Get the entity that corresponds to URL."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the expiration and obj corresponding to provided url exercising the cache_policy as necessary.", "response": "def factory(self, url):\n        '''\n        Return (expiration, obj) corresponding to provided url, exercising the\n        cache_policy as necessary.\n        '''\n        try:\n            return self.fetch(url)\n        except BaseException as exc:\n            logger.exception('Reppy cache fetch error on %s' % url)\n            return self.cache_policy.exception(url, exc)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef allowed(self, url, agent):\n        '''Return true if the provided URL is allowed to agent.'''\n        return self.get(url).allowed(url, agent)", "response": "Return true if the provided URL is allowed to agent."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns ( expiration Agent ) for the robots. txt at the provided URL.", "response": "def fetch(self, url):\n        '''Return (expiration, Agent) for the robots.txt at the provided URL.'''\n        robots = Robots.fetch(\n            url, ttl_policy=self.ttl_policy, *self.args, **self.kwargs)\n        return (robots.expires, robots.agent(self.agent))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd command line arguments for the behave management command.", "response": "def add_command_arguments(parser):\n    \"\"\"\n    Additional command line arguments for the behave management command\n    \"\"\"\n    parser.add_argument(\n        '--noinput',\n        '--no-input',\n        action='store_const',\n        const=False,\n        dest='interactive',\n        help='Tells Django to NOT prompt the user for input of any kind.',\n    )\n    parser.add_argument(\n        '--failfast', action='store_const', const=True, dest='failfast',\n        help=('Tells Django to stop running the '\n              'test suite after first failed test.'),\n    )\n    parser.add_argument(\n        '-r', '--reverse', action='store_const', const=True, dest='reverse',\n        help='Reverses test cases order.',\n    )\n    parser.add_argument(\n        '--use-existing-database',\n        action='store_true',\n        default=False,\n        help=\"Don't create a test database. USE AT YOUR OWN RISK!\",\n    )\n    parser.add_argument(\n        '-k', '--keepdb',\n        action='store_const',\n        const=True,\n        help=\"Preserves the test DB between runs.\",\n    )\n    parser.add_argument(\n        '-S', '--simple',\n        action='store_true',\n        default=False,\n        help=\"Use simple test runner that supports Django's\"\n        \" testing client only (no web browser automation)\"\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding behave command line arguments to the parser.", "response": "def add_behave_arguments(parser):  # noqa\n    \"\"\"\n    Additional command line arguments extracted directly from behave\n    \"\"\"\n\n    # Option strings that conflict with Django\n    conflicts = [\n        '--no-color',\n        '--version',\n        '-c',\n        '-k',\n        '-v',\n        '-S',\n        '--simple',\n    ]\n\n    parser.add_argument(\n        'paths',\n        action='store',\n        nargs='*',\n        help=\"Feature directory, file or file location (FILE:LINE).\"\n    )\n\n    for fixed, keywords in behave_options:\n        keywords = keywords.copy()\n\n        # Configfile only entries are ignored\n        if not fixed:\n            continue\n\n        # Build option strings\n        option_strings = []\n        for option in fixed:\n            # Prefix conflicting option strings with `--behave`\n            if option in conflicts:\n                prefix = '--' if option.startswith('--') else '-'\n                option = option.replace(prefix, '--behave-', 1)\n\n            option_strings.append(option)\n\n        # config_help isn't a valid keyword for add_argument\n        if 'config_help' in keywords:\n            keywords['help'] = keywords['config_help']\n            del keywords['config_help']\n\n        parser.add_argument(*option_strings, **keywords)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_arguments(self, parser):\n        parser.usage = \"%(prog)s [options] [ [DIR|FILE|FILE:LINE] ]+\"\n        parser.description = \"\"\"\\\n        Run a number of feature tests with behave.\"\"\"\n\n        add_command_arguments(parser)\n        add_behave_arguments(parser)", "response": "Add command line arguments to the parser"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a list of those command line arguments that are meant as arguments for running behave.", "response": "def get_behave_args(self, argv=sys.argv):\n        \"\"\"\n        Get a list of those command line arguments specified with the\n        management command that are meant as arguments for running behave.\n        \"\"\"\n        parser = BehaveArgsHelper().create_parser('manage.py', 'behave')\n        args, unknown = parser.parse_known_args(argv[2:])\n\n        behave_args = []\n        for option in unknown:\n            # Remove behave prefix\n            if option.startswith('--behave-'):\n                option = option.replace('--behave-', '', 1)\n                prefix = '-' if len(option) == 1 else '--'\n                option = prefix + option\n\n            behave_args.append(option)\n\n        return behave_args"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_registered_fixtures(context):\n    # -- SELECT STEP REGISTRY:\n    # HINT: Newer behave versions use runner.step_registry\n    # to be able to support multiple runners, each with its own step_registry.\n    runner = context._runner    # pylint: disable=protected-access\n    step_registry = getattr(runner, 'step_registry', None)\n    if not step_registry:\n        # -- BACKWARD-COMPATIBLE: Use module_step_registry\n        step_registry = module_step_registry.registry\n\n    # -- SETUP SCENARIO FIXTURES:\n    for step in context.scenario.all_steps:\n        match = step_registry.find_match(step)\n        if match and hasattr(match.func, 'registered_fixtures'):\n            if not context.test.fixtures:\n                context.test.fixtures = []\n            context.test.fixtures.extend(match.func.registered_fixtures)", "response": "Load the registered fixtures for the current scenario."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef monkey_patch_behave(django_test_runner):\n    behave_run_hook = ModelRunner.run_hook\n\n    def run_hook(self, name, context, *args):\n        if name == 'before_all':\n            django_test_runner.patch_context(context)\n\n        behave_run_hook(self, name, context, *args)\n\n        if name == 'before_scenario':\n            django_test_runner.setup_testclass(context)\n            django_test_runner.setup_fixtures(context)\n            django_test_runner.setup_test(context)\n            behave_run_hook(self, 'django_ready', context)\n\n        if name == 'after_scenario':\n            django_test_runner.teardown_test(context)\n\n    ModelRunner.run_hook = run_hook", "response": "Monkey patch behave_django in behave via before and after scenarios hooks\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npatch the context to add utility functions Sets up base_url and get_url utility functions", "response": "def patch_context(self, context):\n        \"\"\"\n        Patches the context to add utility functions\n\n        Sets up the base_url, and the get_url() utility function.\n        \"\"\"\n        context.__class__ = PatchedContext\n        # Simply setting __class__ directly doesn't work\n        # because behave.runner.Context.__setattr__ is implemented wrongly.\n        object.__setattr__(context, '__class__', PatchedContext)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset up fixtures for the current test.", "response": "def setup_fixtures(self, context):\n        \"\"\"\n        Sets up fixtures\n        \"\"\"\n        if getattr(context, 'fixtures', None):\n            context.test.fixtures = copy(context.fixtures)\n\n        if getattr(context, 'reset_sequences', None):\n            context.test.reset_sequences = context.reset_sequences\n\n        if getattr(context, 'multi_db', None):\n            context.test.__class__.multi_db = context.multi_db\n\n        if hasattr(context, 'scenario'):\n            load_registered_fixtures(context)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexecuting an AppCommand. xml end point.", "response": "def exec_appcommand_post(self, attribute_list):\n        \"\"\"\n        Prepare and execute a HTTP POST call to AppCommand.xml end point.\n\n        Returns XML ElementTree on success and None on fail.\n        \"\"\"\n        # Prepare POST XML body for AppCommand.xml\n        post_root = ET.Element(\"tx\")\n\n        for attribute in attribute_list:\n            # Append tags for each attribute\n            item = ET.Element(\"cmd\")\n            item.set(\"id\", \"1\")\n            item.text = attribute\n            post_root.append(item)\n\n        # Buffer XML body as binary IO\n        body = BytesIO()\n        post_tree = ET.ElementTree(post_root)\n        post_tree.write(body, encoding=\"utf-8\", xml_declaration=True)\n\n        # Query receivers AppCommand.xml\n        try:\n            res = self.send_post_command(\n                self._urls.appcommand, body.getvalue())\n        except requests.exceptions.RequestException:\n            _LOGGER.error(\"No connection to %s end point on host %s\",\n                          self._urls.appcommand, self._host)\n            body.close()\n        else:\n            # Buffered XML not needed anymore: close\n            body.close()\n\n            try:\n                # Return XML ElementTree\n                root = ET.fromstring(res)\n            except (ET.ParseError, TypeError):\n                _LOGGER.error(\n                    \"End point %s on host %s returned malformed XML.\",\n                    self._urls.appcommand, self._host)\n            else:\n                return root"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_status_xml(self, command, suppress_errors=False):\n        # Get XML structure via HTTP get\n        res = requests.get(\"http://{host}:{port}{command}\".format(\n            host=self._host, port=self._receiver_port, command=command),\n                           timeout=self.timeout)\n        # Continue with XML processing only if HTTP status code = 200\n        if res.status_code == 200:\n            try:\n                # Return XML ElementTree\n                return ET.fromstring(res.text)\n            except ET.ParseError as err:\n                if not suppress_errors:\n                    _LOGGER.error(\n                        \"Host %s returned malformed XML for end point %s\",\n                        self._host, command)\n                    _LOGGER.error(err)\n                raise ValueError\n        else:\n            if not suppress_errors:\n                _LOGGER.error((\n                    \"Host %s returned HTTP status code %s to GET request at \"\n                    \"end point %s\"), self._host, res.status_code, command)\n            raise ValueError", "response": "Get status XML via HTTP and return it as XML ElementTree."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend command to receiver.", "response": "def send_get_command(self, command):\n        \"\"\"Send command via HTTP get to receiver.\"\"\"\n        # Send commands via HTTP get\n        res = requests.get(\"http://{host}:{port}{command}\".format(\n            host=self._host, port=self._receiver_port, command=command),\n                           timeout=self.timeout)\n        if res.status_code == 200:\n            return True\n        else:\n            _LOGGER.error((\n                \"Host %s returned HTTP status code %s to GET command at \"\n                \"end point %s\"), self._host, res.status_code, command)\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send_post_command(self, command, body):\n        # Send commands via HTTP post\n        res = requests.post(\"http://{host}:{port}{command}\".format(\n            host=self._host, port=self._receiver_port, command=command),\n                            data=body, timeout=self.timeout)\n        if res.status_code == 200:\n            return res.text\n        else:\n            _LOGGER.error((\n                \"Host %s returned HTTP status code %s to POST command at \"\n                \"end point %s\"), self._host, res.status_code, command)\n            return False", "response": "Send command via HTTP post to receiver."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_zones(self, add_zones):\n        for zone, zname in add_zones.items():\n            # Name either set explicitly or name of Main Zone with suffix\n            zonename = \"{} {}\".format(self._name, zone) if (\n                zname is None) else zname\n            zone_inst = DenonAVRZones(self, zone, zonename)\n            self._zones[zone] = zone_inst", "response": "Create instances of additional zones for the receiver."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the status of the current receiver type.", "response": "def update(self):\n        \"\"\"\n        Get the latest status information from device.\n\n        Method executes the update method for the current receiver type.\n        \"\"\"\n        if self._receiver_type == AVR_X_2016.type:\n            return self._update_avr_2016()\n        else:\n            return self._update_avr()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the latest status information from device. Method queries device via HTTP and updates instance attributes. Returns \"True\" on success and \"False\" on fail. This method is for pre 2016 AVR(-X) devices", "response": "def _update_avr(self):\n        \"\"\"\n        Get the latest status information from device.\n\n        Method queries device via HTTP and updates instance attributes.\n        Returns \"True\" on success and \"False\" on fail.\n        This method is for pre 2016 AVR(-X) devices\n        \"\"\"\n        # Set all tags to be evaluated\n        relevant_tags = {\"Power\": None, \"InputFuncSelect\": None, \"Mute\": None,\n                         \"MasterVolume\": None}\n\n        # Sound mode information only available in main zone\n        if self._zone == \"Main\" and self._support_sound_mode:\n            relevant_tags[\"selectSurround\"] = None\n            relevant_tags[\"SurrMode\"] = None\n\n        # Get status XML from Denon receiver via HTTP\n        try:\n            root = self.get_status_xml(self._urls.status)\n        except ValueError:\n            pass\n        except requests.exceptions.RequestException:\n            # On timeout and connection error, the device is probably off\n            self._power = POWER_OFF\n        else:\n            # Get the tags from this XML\n            relevant_tags = self._get_status_from_xml_tags(root, relevant_tags)\n\n        # Second option to update variables from different source\n        if relevant_tags and self._power != POWER_OFF:\n            try:\n                root = self.get_status_xml(self._urls.mainzone)\n            except (ValueError,\n                    requests.exceptions.RequestException):\n                pass\n            else:\n                # Get the tags from this XML\n                relevant_tags = self._get_status_from_xml_tags(root,\n                                                               relevant_tags)\n\n        # Error message if still some variables are not updated yet\n        if relevant_tags and self._power != POWER_OFF:\n            _LOGGER.error(\"Missing status information from XML of %s for: %s\",\n                          self._zone, \", \".join(relevant_tags.keys()))\n\n        # Set state and media image URL based on current source\n        # and power status\n        if (self._power == POWER_ON) and (\n                self._input_func in self._playing_func_list):\n            if self._update_media_data():\n                pass\n            else:\n                _LOGGER.error(\n                    \"Update of media data for source %s in %s failed\",\n                    self._input_func, self._zone)\n        elif self._power == POWER_ON:\n            self._state = STATE_ON\n            self._title = None\n            self._artist = None\n            self._album = None\n            self._band = None\n            self._frequency = None\n            self._station = None\n            self._image_url = None\n        else:\n            self._state = STATE_OFF\n            self._title = None\n            self._artist = None\n            self._album = None\n            self._band = None\n            self._frequency = None\n            self._station = None\n\n        # Get/update sources list if current source is not known yet\n        if (self._input_func not in self._input_func_list and\n                self._input_func is not None):\n            if self._update_input_func_list():\n                _LOGGER.info(\"List of input functions refreshed.\")\n                # If input function is still not known, create new entry.\n                if (self._input_func not in self._input_func_list and\n                        self._input_func is not None):\n                    inputfunc = self._input_func\n                    self._input_func_list_rev[inputfunc] = inputfunc\n                    self._input_func_list[inputfunc] = inputfunc\n            else:\n                _LOGGER.error((\n                    \"Input function list for Denon receiver at host %s \"\n                    \"could not be updated.\"), self._host)\n\n        # Finished\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _update_avr_2016(self):\n        # Collect tags for AppCommand.xml call\n        tags = [\"GetAllZonePowerStatus\", \"GetAllZoneSource\",\n                \"GetAllZoneVolume\", \"GetAllZoneMuteStatus\",\n                \"GetSurroundModeStatus\"]\n        # Execute call\n        root = self.exec_appcommand_post(tags)\n        # Check result\n        if root is None:\n            _LOGGER.error(\"Update failed.\")\n            return False\n\n        # Extract relevant information\n        zone = self._get_own_zone()\n\n        try:\n            self._power = root[0].find(zone).text\n        except (AttributeError, IndexError):\n            _LOGGER.error(\"No PowerStatus found for zone %s\", self.zone)\n\n        try:\n            self._mute = root[3].find(zone).text\n        except (AttributeError, IndexError):\n            _LOGGER.error(\"No MuteStatus found for zone %s\", self.zone)\n\n        try:\n            self._volume = root.find(\n                \"./cmd/{zone}/volume\".format(zone=zone)).text\n        except AttributeError:\n            _LOGGER.error(\"No VolumeStatus found for zone %s\", self.zone)\n\n        try:\n            inputfunc = root.find(\n                \"./cmd/{zone}/source\".format(zone=zone)).text\n        except AttributeError:\n            _LOGGER.error(\"No Source found for zone %s\", self.zone)\n        else:\n            try:\n                self._input_func = self._input_func_list_rev[inputfunc]\n            except KeyError:\n                _LOGGER.info(\"No mapping for source %s found\", inputfunc)\n                self._input_func = inputfunc\n                # Get/update sources list if current source is not known yet\n                if self._update_input_func_list():\n                    _LOGGER.info(\"List of input functions refreshed.\")\n                    # If input function is still not known, create new entry.\n                    if (inputfunc not in self._input_func_list and\n                            inputfunc is not None):\n                        self._input_func_list_rev[inputfunc] = inputfunc\n                        self._input_func_list[inputfunc] = inputfunc\n                else:\n                    _LOGGER.error((\n                        \"Input function list for Denon receiver at host %s \"\n                        \"could not be updated.\"), self._host)\n        try:\n            self._sound_mode_raw = root[4][0].text.rstrip()\n        except (AttributeError, IndexError):\n            _LOGGER.error(\"No SoundMode found for the main zone %s\", self.zone)\n\n        # Now playing information is not implemented for 2016+ models, because\n        # a HEOS API query needed. So only sync the power state for now.\n        if self._power == POWER_ON:\n            self._state = STATE_ON\n        else:\n            self._state = STATE_OFF\n\n        return True", "response": "Update the current AVR - X status information from device."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _update_input_func_list(self):\n        # Get all sources and renaming information from receiver\n        # For structural information of the variables please see the methods\n        receiver_sources = self._get_receiver_sources()\n\n        if not receiver_sources:\n            _LOGGER.error(\"Receiver sources list empty. \"\n                          \"Please check if device is powered on.\")\n            return False\n\n        # First input_func_list determination of AVR-X receivers\n        if self._receiver_type in [AVR_X.type, AVR_X_2016.type]:\n            renamed_sources, deleted_sources, status_success = (\n                self._get_renamed_deleted_sourcesapp())\n\n            # Backup if previous try with AppCommand was not successful\n            if not status_success:\n                renamed_sources, deleted_sources = (\n                    self._get_renamed_deleted_sources())\n\n            # Remove all deleted sources\n            if self._show_all_inputs is False:\n                for deleted_source in deleted_sources.items():\n                    if deleted_source[1] == \"DEL\":\n                        receiver_sources.pop(deleted_source[0], None)\n\n            # Clear and rebuild the sources lists\n            self._input_func_list.clear()\n            self._input_func_list_rev.clear()\n            self._netaudio_func_list.clear()\n            self._playing_func_list.clear()\n\n            for item in receiver_sources.items():\n                # Mapping of item[0] because some func names are inconsistant\n                # at AVR-X receivers\n\n                m_item_0 = SOURCE_MAPPING.get(item[0], item[0])\n\n                # For renamed sources use those names and save the default name\n                # for a later mapping\n                if item[0] in renamed_sources:\n                    self._input_func_list[renamed_sources[item[0]]] = m_item_0\n                    self._input_func_list_rev[\n                        m_item_0] = renamed_sources[item[0]]\n                    # If the source is a netaudio source, save its renamed name\n                    if item[0] in NETAUDIO_SOURCES:\n                        self._netaudio_func_list.append(\n                            renamed_sources[item[0]])\n                    # If the source is a playing source, save its renamed name\n                    if item[0] in PLAYING_SOURCES:\n                        self._playing_func_list.append(\n                            renamed_sources[item[0]])\n                # Otherwise the default names are used\n                else:\n                    self._input_func_list[item[1]] = m_item_0\n                    self._input_func_list_rev[m_item_0] = item[1]\n                    # If the source is a netaudio source, save its name\n                    if item[1] in NETAUDIO_SOURCES:\n                        self._netaudio_func_list.append(item[1])\n                    # If the source is a playing source, save its name\n                    if item[1] in PLAYING_SOURCES:\n                        self._playing_func_list.append(item[1])\n\n        # Determination of input_func_list for non AVR-nonX receivers\n        elif self._receiver_type == AVR.type:\n            # Clear and rebuild the sources lists\n            self._input_func_list.clear()\n            self._input_func_list_rev.clear()\n            self._netaudio_func_list.clear()\n            self._playing_func_list.clear()\n            for item in receiver_sources.items():\n                self._input_func_list[item[1]] = item[0]\n                self._input_func_list_rev[item[0]] = item[1]\n                # If the source is a netaudio source, save its name\n                if item[0] in NETAUDIO_SOURCES:\n                    self._netaudio_func_list.append(item[1])\n                # If the source is a playing source, save its name\n                if item[0] in PLAYING_SOURCES:\n                    self._playing_func_list.append(item[1])\n        else:\n            _LOGGER.error('Receiver type not set yet.')\n            return False\n\n        # Finished\n        return True", "response": "Internal method which updates the input_func_list of AVR - X receivers and sources list of receiver."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_receiver_name(self):\n        # If name is not set yet, get it from Main Zone URL\n        if self._name is None and self._urls.mainzone is not None:\n            name_tag = {\"FriendlyName\": None}\n            try:\n                root = self.get_status_xml(self._urls.mainzone)\n            except (ValueError,\n                    requests.exceptions.RequestException):\n                _LOGGER.warning(\"Receiver name could not be determined. \"\n                                \"Using standard name: Denon AVR.\")\n                self._name = \"Denon AVR\"\n            else:\n                # Get the tags from this XML\n                name_tag = self._get_status_from_xml_tags(root, name_tag)\n                if name_tag:\n                    _LOGGER.warning(\"Receiver name could not be determined. \"\n                                    \"Using standard name: Denon AVR.\")\n                    self._name = \"Denon AVR\"", "response": "Get name of receiver from web interface if not set."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget receivers zone name.", "response": "def _get_zone_name(self):\n        \"\"\"Get receivers zone name if not set yet.\"\"\"\n        if self._name is None:\n            # Collect tags for AppCommand.xml call\n            tags = [\"GetZoneName\"]\n            # Execute call\n            root = self.exec_appcommand_post(tags)\n            # Check result\n            if root is None:\n                _LOGGER.error(\"Getting ZoneName failed.\")\n            else:\n                zone = self._get_own_zone()\n\n                try:\n                    name = root.find(\n                        \"./cmd/{zone}\".format(zone=zone)).text\n                except AttributeError:\n                    _LOGGER.error(\"No ZoneName found for zone %s\", self.zone)\n                else:\n                    self._name = name.strip()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_support_sound_mode(self):\n        if self._receiver_type == AVR_X_2016.type:\n            return self._get_support_sound_mode_avr_2016()\n        else:\n            return self._get_support_sound_mode_avr()", "response": "Method executes the method for getting the current sound mode."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_support_sound_mode_avr(self):\n        # Set sound mode tags to be checked if available\n        relevant_tags = {\"selectSurround\": None, \"SurrMode\": None}\n\n        # Get status XML from Denon receiver via HTTP\n        try:\n            root = self.get_status_xml(self._urls.status)\n        except (ValueError, requests.exceptions.RequestException):\n            pass\n        else:\n            # Process the tags from this XML\n            relevant_tags = self._get_status_from_xml_tags(root, relevant_tags)\n\n        # Second option to update variables from different source\n        if relevant_tags:\n            try:\n                root = self.get_status_xml(self._urls.mainzone)\n            except (ValueError,\n                    requests.exceptions.RequestException):\n                pass\n            else:\n                # Get the tags from this XML\n                relevant_tags = self._get_status_from_xml_tags(root,\n                                                               relevant_tags)\n\n        # if sound mode not found in the status XML, return False\n        if relevant_tags:\n            self._support_sound_mode = False\n            return False\n        # if sound mode found, the relevant_tags are empty: return True.\n        self._support_sound_mode = True\n        return True", "response": "Method checks if sound mode is supported from device via HTTP."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget renamed and deleted sources lists from receiver . Internal method which queries device via HTTP to get names of renamed input sources.", "response": "def _get_renamed_deleted_sources(self):\n        \"\"\"\n        Get renamed and deleted sources lists from receiver .\n\n        Internal method which queries device via HTTP to get names of renamed\n        input sources.\n        \"\"\"\n        # renamed_sources and deleted_sources are dicts with \"source\" as key\n        # and \"renamed_source\" or deletion flag as value.\n        renamed_sources = {}\n        deleted_sources = {}\n        xml_inputfunclist = []\n        xml_renamesource = []\n        xml_deletesource = []\n\n        # This XML is needed to get names of eventually renamed sources\n        try:\n            # AVR-X and AVR-nonX using different XMLs to provide info about\n            # deleted sources\n            if self._receiver_type == AVR_X.type:\n                root = self.get_status_xml(self._urls.status)\n            # URL only available for Main Zone.\n            elif (self._receiver_type == AVR.type and\n                  self._urls.mainzone is not None):\n                root = self.get_status_xml(self._urls.mainzone)\n            else:\n                return (renamed_sources, deleted_sources)\n        except (ValueError, requests.exceptions.RequestException):\n            return (renamed_sources, deleted_sources)\n\n        # Get the relevant tags from XML structure\n        for child in root:\n            # Default names of the sources\n            if child.tag == \"InputFuncList\":\n                for value in child:\n                    xml_inputfunclist.append(value.text)\n            # Renamed sources\n            if child.tag == \"RenameSource\":\n                for value in child:\n                    # Two different kinds of source structure types exist\n                    # 1. <RenameSource><Value>...\n                    if value.text is not None:\n                        xml_renamesource.append(value.text.strip())\n                    # 2. <RenameSource><Value><Value>\n                    else:\n                        try:\n                            xml_renamesource.append(value[0].text.strip())\n                        # Exception covers empty tags and appends empty line\n                        # in this case, to ensure that sources and\n                        # renamed_sources lists have always the same length\n                        except IndexError:\n                            xml_renamesource.append(None)\n            # Deleted sources\n            if child.tag == \"SourceDelete\":\n                for value in child:\n                    xml_deletesource.append(value.text)\n\n        # Renamed and deleted sources are in the same row as the default ones\n        # Only values which are not None are considered. Otherwise translation\n        # is not valid and original name is taken\n        for i, item in enumerate(xml_inputfunclist):\n            try:\n                if xml_renamesource[i] is not None:\n                    renamed_sources[item] = xml_renamesource[i]\n                else:\n                    renamed_sources[item] = item\n            except IndexError:\n                _LOGGER.error(\n                    \"List of renamed sources incomplete, continuing anyway\")\n            try:\n                deleted_sources[item] = xml_deletesource[i]\n            except IndexError:\n                _LOGGER.error(\n                    \"List of deleted sources incomplete, continuing anyway\")\n\n        return (renamed_sources, deleted_sources)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget renamed and deleted sources lists from receiver.", "response": "def _get_renamed_deleted_sourcesapp(self):\n        \"\"\"\n        Get renamed and deleted sources lists from receiver .\n\n        Internal method which queries device via HTTP to get names of renamed\n        input sources. In this method AppCommand.xml is used.\n        \"\"\"\n        # renamed_sources and deleted_sources are dicts with \"source\" as key\n        # and \"renamed_source\" or deletion flag as value.\n        renamed_sources = {}\n        deleted_sources = {}\n\n        # Collect tags for AppCommand.xml call\n        tags = [\"GetRenameSource\", \"GetDeletedSource\"]\n        # Execute call\n        root = self.exec_appcommand_post(tags)\n        # Check result\n        if root is None:\n            _LOGGER.error(\"Getting renamed and deleted sources failed.\")\n            return (renamed_sources, deleted_sources, False)\n\n        # Detect \"Document Error: Data follows\" title if URL does not exist\n        document_error = root.find(\"./head/title\")\n        if document_error is not None:\n            if document_error.text == \"Document Error: Data follows\":\n                return (renamed_sources, deleted_sources, False)\n\n        for child in root.findall(\"./cmd/functionrename/list\"):\n            try:\n                renamed_sources[child.find(\"name\").text.strip()] = (\n                    child.find(\"rename\").text.strip())\n            except AttributeError:\n                continue\n\n        for child in root.findall(\"./cmd/functiondelete/list\"):\n            try:\n                deleted_sources[child.find(\"FuncName\").text.strip(\n                )] = \"DEL\" if (\n                    child.find(\"use\").text.strip() == \"0\") else None\n            except AttributeError:\n                continue\n\n        return (renamed_sources, deleted_sources, True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget sources list from receiver.", "response": "def _get_receiver_sources(self):\n        \"\"\"\n        Get sources list from receiver.\n\n        Internal method which queries device via HTTP to get the receiver's\n        input sources.\n        This method also determines the type of the receiver\n        (avr, avr-x, avr-x-2016).\n        \"\"\"\n        # Test if receiver is a AVR-X with port 80 for pre 2016 devices and\n        # port 8080 devices 2016 and later\n        r_types = [AVR_X, AVR_X_2016]\n        for r_type, port in r_types:\n            self._receiver_port = port\n\n            # This XML is needed to get the sources of the receiver\n            try:\n                root = self.get_status_xml(self._urls.deviceinfo,\n                                           suppress_errors=True)\n            except (ValueError, requests.exceptions.RequestException):\n                self._receiver_type = None\n            else:\n                # First test by CommApiVers\n                try:\n                    if bool(DEVICEINFO_COMMAPI_PATTERN.search(\n                            root.find(\"CommApiVers\").text) is not None):\n                        self._receiver_type = r_type\n                        # receiver found break the loop\n                        break\n                except AttributeError:\n                    # AttributeError occurs when ModelName tag is not found.\n                    # In this case there is no AVR-X device\n                    self._receiver_type = None\n\n                # if first test did not find AVR-X device, check by model name\n                if self._receiver_type is None:\n                    try:\n                        if bool(DEVICEINFO_AVR_X_PATTERN.search(\n                                root.find(\"ModelName\").text) is not None):\n                            self._receiver_type = r_type\n                            # receiver found break the loop\n                            break\n                    except AttributeError:\n                        # AttributeError occurs when ModelName tag is not found\n                        # In this case there is no AVR-X device\n                        self._receiver_type = None\n\n        # Set ports and update method\n        if self._receiver_type is None:\n            self._receiver_type = AVR.type\n            self._receiver_port = AVR.port\n        elif self._receiver_type == AVR_X_2016.type:\n            self._receiver_port = AVR_X_2016.port\n        else:\n            self._receiver_port = AVR_X.port\n\n        _LOGGER.info(\"Identified receiver type: '%s' on port: '%s'\",\n                     self._receiver_type, self._receiver_port)\n\n        # Not an AVR-X device, start determination of sources\n        if self._receiver_type == AVR.type:\n            # Sources list is equal to list of renamed sources.\n            non_x_sources, deleted_non_x_sources, status_success = (\n                self._get_renamed_deleted_sourcesapp())\n\n            # Backup if previous try with AppCommand was not successful\n            if not status_success:\n                non_x_sources, deleted_non_x_sources = (\n                    self._get_renamed_deleted_sources())\n\n            # Remove all deleted sources\n            if self._show_all_inputs is False:\n                for deleted_source in deleted_non_x_sources.items():\n                    if deleted_source[1] == \"DEL\":\n                        non_x_sources.pop(deleted_source[0], None)\n            # Invalid source \"SOURCE\" needs to be deleted\n            non_x_sources.pop(\"SOURCE\", None)\n            return non_x_sources\n\n        # Following source determination of AVR-X receivers\n        else:\n            # receiver_sources is of type dict with \"FuncName\" as key and\n            # \"DefaultName\" as value.\n            receiver_sources = {}\n            # Source determination from XML\n            favorites = root.find(\".//FavoriteStation\")\n            if favorites:\n                for child in favorites:\n                    if not child.tag.startswith(\"Favorite\"):\n                        continue\n                    func_name = child.tag.upper()\n                    self._favorite_func_list.append(func_name)\n                    receiver_sources[func_name] = child.find(\"Name\").text\n            for xml_zonecapa in root.findall(\"DeviceZoneCapabilities\"):\n                # Currently only Main Zone (No=0) supported\n                if xml_zonecapa.find(\"./Zone/No\").text == \"0\":\n                    # Get list of all input sources of receiver\n                    xml_list = xml_zonecapa.find(\"./InputSource/List\")\n                    for xml_source in xml_list.findall(\"Source\"):\n                        receiver_sources[\n                            xml_source.find(\n                                \"FuncName\").text] = xml_source.find(\n                                    \"DefaultName\").text\n\n            return receiver_sources"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate media data for playing devices. Internal method which queries device via HTTP to update media information (title, artist, etc.) and URL of cover image.", "response": "def _update_media_data(self):\n        \"\"\"\n        Update media data for playing devices.\n\n        Internal method which queries device via HTTP to update media\n        information (title, artist, etc.) and URL of cover image.\n        \"\"\"\n        # Use different query URL based on selected source\n        if self._input_func in self._netaudio_func_list:\n            try:\n                root = self.get_status_xml(self._urls.netaudiostatus)\n            except (ValueError, requests.exceptions.RequestException):\n                return False\n\n            # Get the relevant tags from XML structure\n            for child in root:\n                if child.tag == \"szLine\":\n                    if (self._title != html.unescape(child[1].text) if (\n                            child[1].text is not None) else None or\n                            self._artist != html.unescape(child[2].text) if (\n                                child[2].text is not None) else None or\n                            self._album != html.unescape(child[4].text) if (\n                                child[4].text is not None) else None):\n                        # Refresh cover with a new time stamp for media URL\n                        # when track is changing\n                        self._image_url = (ALBUM_COVERS_URL.format(\n                            host=self._host, port=self._receiver_port,\n                            time=int(time.time())))\n                        # On track change assume device is PLAYING\n                        self._state = STATE_PLAYING\n                    self._title = html.unescape(child[1].text) if (\n                        child[1].text is not None) else None\n                    self._artist = html.unescape(child[2].text) if (\n                        child[2].text is not None) else None\n                    self._album = html.unescape(child[4].text)if (\n                        child[4].text is not None) else None\n                    self._band = None\n                    self._frequency = None\n                    self._station = None\n\n        elif self._input_func == \"Tuner\" or self._input_func == \"TUNER\":\n            try:\n                root = self.get_status_xml(self._urls.tunerstatus)\n            except (ValueError, requests.exceptions.RequestException):\n                return False\n\n            # Get the relevant tags from XML structure\n            for child in root:\n                if child.tag == \"Band\":\n                    self._band = child[0].text\n                elif child.tag == \"Frequency\":\n                    self._frequency = child[0].text\n\n            self._title = None\n            self._artist = None\n            self._album = None\n            self._station = None\n\n            # Assume Tuner is always PLAYING\n            self._state = STATE_PLAYING\n\n            # No special cover, using a static one\n            self._image_url = (\n                STATIC_ALBUM_URL.format(\n                    host=self._host, port=self._receiver_port))\n\n        elif self._input_func == \"HD Radio\" or self._input_func == \"HDRADIO\":\n            try:\n                root = self.get_status_xml(self._urls.hdtunerstatus)\n            except (ValueError, requests.exceptions.RequestException):\n                return False\n\n            # Get the relevant tags from XML structure\n            for child in root:\n                if child.tag == \"Artist\":\n                    self._artist = html.unescape(child[0].text) if (\n                        child[0].text is not None) else None\n                elif child.tag == \"Title\":\n                    self._title = html.unescape(child[0].text) if (\n                        child[0].text is not None) else None\n                elif child.tag == \"Album\":\n                    self._album = html.unescape(child[0].text) if (\n                        child[0].text is not None) else None\n                elif child.tag == \"Band\":\n                    self._band = html.unescape(child[0].text) if (\n                        child[0].text is not None) else None\n                elif child.tag == \"Frequency\":\n                    self._frequency = html.unescape(child[0].text) if (\n                        child[0].text is not None) else None\n                elif child.tag == \"StationNameSh\":\n                    self._station = html.unescape(child[0].text) if (\n                        child[0].text is not None) else None\n\n            # Assume Tuner is always PLAYING\n            self._state = STATE_PLAYING\n\n            # No special cover, using a static one\n            self._image_url = (\n                STATIC_ALBUM_URL.format(\n                    host=self._host, port=self._receiver_port))\n\n        # No behavior implemented, so reset all variables for that source\n        else:\n            self._band = None\n            self._frequency = None\n            self._title = None\n            self._artist = None\n            self._album = None\n            self._station = None\n            # Assume PLAYING_DEVICE is always PLAYING\n            self._state = STATE_PLAYING\n            # No special cover, using a static one\n            self._image_url = (\n                STATIC_ALBUM_URL.format(\n                    host=self._host, port=self._receiver_port))\n\n        # Test if image URL is accessable\n        if self._image_available is None and self._image_url is not None:\n            try:\n                imgres = requests.get(self._image_url, timeout=self.timeout)\n            except requests.exceptions.RequestException:\n                # No result set image URL to None\n                self._image_url = None\n            else:\n                if imgres.status_code == 200:\n                    self._image_available = True\n                else:\n                    _LOGGER.info('No album art available for your receiver')\n                    # No image available. Save this status.\n                    self._image_available = False\n                    #  Set image URL to None.\n                    self._image_url = None\n        # Already tested that image URL is not accessible\n        elif self._image_available is False:\n            self._image_url = None\n\n        # Finished\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets relevant status tags from XML structure with this internal method.", "response": "def _get_status_from_xml_tags(self, root, relevant_tags):\n        \"\"\"\n        Get relevant status tags from XML structure with this internal method.\n\n        Status is saved to internal attributes.\n        Return dictionary of tags not found in XML.\n        \"\"\"\n        for child in root:\n            if child.tag not in relevant_tags.keys():\n                continue\n            elif child.tag == \"Power\":\n                self._power = child[0].text\n                relevant_tags.pop(child.tag, None)\n            elif child.tag == \"InputFuncSelect\":\n                inputfunc = child[0].text\n                if inputfunc is not None:\n                    try:\n                        self._input_func = self._input_func_list_rev[inputfunc]\n                    except KeyError:\n                        _LOGGER.info(\n                            \"No mapping for source %s found\", inputfunc)\n                        self._input_func = inputfunc\n                    finally:\n                        relevant_tags.pop(child.tag, None)\n            elif child.tag == \"MasterVolume\":\n                self._volume = child[0].text\n                relevant_tags.pop(child.tag, None)\n            elif child.tag == \"Mute\":\n                self._mute = child[0].text\n                relevant_tags.pop(child.tag, None)\n            elif child.tag == \"FriendlyName\" and self._name is None:\n                self._name = child[0].text\n                relevant_tags.pop(child.tag, None)\n            elif child.tag == \"selectSurround\" or child.tag == \"SurrMode\":\n                self._sound_mode_raw = child[0].text.rstrip()\n                relevant_tags.pop(\"selectSurround\", None)\n                relevant_tags.pop(\"SurrMode\", None)\n\n        return relevant_tags"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting input_func of device.", "response": "def set_input_func(self, input_func):\n        \"\"\"\n        Set input_func of device.\n\n        Valid values depend on the device and should be taken from\n        \"input_func_list\".\n        Return \"True\" on success and \"False\" on fail.\n        \"\"\"\n        # For selection of sources other names then at receiving sources\n        # have to be used\n        # AVR-X receiver needs source mapping to set input_func\n        if self._receiver_type in [AVR_X.type, AVR_X_2016.type]:\n            direct_mapping = False\n            try:\n                linp = CHANGE_INPUT_MAPPING[self._input_func_list[input_func]]\n            except KeyError:\n                direct_mapping = True\n        else:\n            direct_mapping = True\n        # AVR-nonX receiver and if no mapping was found get parameter for\n        # setting input_func directly\n        if direct_mapping is True:\n            try:\n                linp = self._input_func_list[input_func]\n            except KeyError:\n                _LOGGER.error(\"No mapping for input source %s\", input_func)\n                return False\n        # Create command URL and send command via HTTP GET\n        try:\n            if linp in self._favorite_func_list:\n                command_url = self._urls.command_fav_src + linp\n            else:\n                command_url = self._urls.command_sel_src + linp\n\n            if self.send_get_command(command_url):\n                self._input_func = input_func\n                return True\n            else:\n                return False\n        except requests.exceptions.RequestException:\n            _LOGGER.error(\"Connection error: input function %s not set.\",\n                          input_func)\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_all_zone_stereo(self, zst_on):\n        command_url = self._urls.command_set_all_zone_stereo\n        if zst_on:\n            command_url += \"ZST ON\"\n        else:\n            command_url += \"ZST OFF\"\n\n        try:\n            return self.send_get_command(command_url)\n        except requests.exceptions.RequestException:\n            _LOGGER.error(\n                \"Connection error: unable to set All Zone Stereo to %s\",\n                zst_on)\n            return False", "response": "Send command to set All Zone Stereo option on the device."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset sound mode of the current language.", "response": "def set_sound_mode(self, sound_mode):\n        \"\"\"\n        Set sound_mode of device.\n\n        Valid values depend on the device and should be taken from\n        \"sound_mode_list\".\n        Return \"True\" on success and \"False\" on fail.\n        \"\"\"\n        if sound_mode == ALL_ZONE_STEREO:\n            if self._set_all_zone_stereo(True):\n                self._sound_mode_raw = ALL_ZONE_STEREO\n                return True\n            else:\n                return False\n        if self._sound_mode_raw == ALL_ZONE_STEREO:\n            if not self._set_all_zone_stereo(False):\n                return False\n        # For selection of sound mode other names then at receiving sound modes\n        # have to be used\n        # Therefore source mapping is needed to get sound_mode\n        # Create command URL and send command via HTTP GET\n        command_url = self._urls.command_sel_sound_mode + sound_mode\n        # sent command\n        try:\n            if self.send_get_command(command_url):\n                self._sound_mode_raw = self._sound_mode_dict[sound_mode][0]\n                return True\n            else:\n                return False\n        except requests.exceptions.RequestException:\n            _LOGGER.error(\"Connection error: sound mode function %s not set.\",\n                          sound_mode)\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_sound_mode_dict(self, sound_mode_dict):\n        error_msg = (\"Syntax of sound mode dictionary not valid, \"\n                     \"use: OrderedDict([('COMMAND', ['VALUE1','VALUE2'])])\")\n        if isinstance(sound_mode_dict, dict):\n            mode_list = list(sound_mode_dict.values())\n            for sublist in mode_list:\n                if isinstance(sublist, list):\n                    for element in sublist:\n                        if not isinstance(element, str):\n                            _LOGGER.error(error_msg)\n                            return False\n                else:\n                    _LOGGER.error(error_msg)\n                    return False\n        else:\n            _LOGGER.error(error_msg)\n            return False\n        self._sound_mode_dict = sound_mode_dict\n        self._sm_match_dict = self.construct_sm_match_dict()\n        return True", "response": "Set the matching dictionary used to match the raw sound mode."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconstructing the sm_match_dict for the sound_mode_dict.", "response": "def construct_sm_match_dict(self):\n        \"\"\"\n        Construct the sm_match_dict.\n\n        Reverse the key value structure. The sm_match_dict is bigger,\n        but allows for direct matching using a dictionary key access.\n        The sound_mode_dict is uses externally to set this dictionary\n        because that has a nicer syntax.\n        \"\"\"\n        mode_dict = list(self._sound_mode_dict.items())\n        match_mode_dict = {}\n        for matched_mode, sublist in mode_dict:\n            for raw_mode in sublist:\n                match_mode_dict[raw_mode.upper()] = matched_mode\n        return match_mode_dict"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmatch the raw_sound_mode to its corresponding sound_mode.", "response": "def match_sound_mode(self, sound_mode_raw):\n        \"\"\"Match the raw_sound_mode to its corresponding sound_mode.\"\"\"\n        try:\n            sound_mode = self._sm_match_dict[sound_mode_raw.upper()]\n            return sound_mode\n        except KeyError:\n            smr_up = sound_mode_raw.upper()\n            self._sound_mode_dict[smr_up] = [smr_up]\n            self._sm_match_dict = self.construct_sm_match_dict()\n            _LOGGER.warning(\"Not able to match sound mode: '%s', \"\n                            \"returning raw sound mode.\", sound_mode_raw)\n        return sound_mode_raw"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntoggle play pause media player.", "response": "def toggle_play_pause(self):\n        \"\"\"Toggle play pause media player.\"\"\"\n        # Use Play/Pause button only for sources which support NETAUDIO\n        if (self._state == STATE_PLAYING and\n                self._input_func in self._netaudio_func_list):\n            return self._pause()\n        elif self._input_func in self._netaudio_func_list:\n            return self._play()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _play(self):\n        # Use pause command only for sources which support NETAUDIO\n        if self._input_func in self._netaudio_func_list:\n            body = {\"cmd0\": \"PutNetAudioCommand/CurEnter\",\n                    \"cmd1\": \"aspMainZone_WebUpdateStatus/\",\n                    \"ZoneName\": \"MAIN ZONE\"}\n            try:\n                if self.send_post_command(\n                        self._urls.command_netaudio_post, body):\n                    self._state = STATE_PLAYING\n                    return True\n                else:\n                    return False\n            except requests.exceptions.RequestException:\n                _LOGGER.error(\"Connection error: play command not sent.\")\n                return False", "response": "Send play command to receiver command via HTTP post."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend pause command to receiver command via HTTP post.", "response": "def _pause(self):\n        \"\"\"Send pause command to receiver command via HTTP post.\"\"\"\n        # Use pause command only for sources which support NETAUDIO\n        if self._input_func in self._netaudio_func_list:\n            body = {\"cmd0\": \"PutNetAudioCommand/CurEnter\",\n                    \"cmd1\": \"aspMainZone_WebUpdateStatus/\",\n                    \"ZoneName\": \"MAIN ZONE\"}\n            try:\n                if self.send_post_command(\n                        self._urls.command_netaudio_post, body):\n                    self._state = STATE_PAUSED\n                    return True\n                else:\n                    return False\n            except requests.exceptions.RequestException:\n                _LOGGER.error(\"Connection error: pause command not sent.\")\n                return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef previous_track(self):\n        # Use previous track button only for sources which support NETAUDIO\n        if self._input_func in self._netaudio_func_list:\n            body = {\"cmd0\": \"PutNetAudioCommand/CurUp\",\n                    \"cmd1\": \"aspMainZone_WebUpdateStatus/\",\n                    \"ZoneName\": \"MAIN ZONE\"}\n            try:\n                return bool(self.send_post_command(\n                    self._urls.command_netaudio_post, body))\n            except requests.exceptions.RequestException:\n                _LOGGER.error(\n                    \"Connection error: previous track command not sent.\")\n                return False", "response": "Send previous track command to receiver command via HTTP post."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nturning on receiver via HTTP get command.", "response": "def power_on(self):\n        \"\"\"Turn off receiver via HTTP get command.\"\"\"\n        try:\n            if self.send_get_command(self._urls.command_power_on):\n                self._power = POWER_ON\n                self._state = STATE_ON\n                return True\n            else:\n                return False\n        except requests.exceptions.RequestException:\n            _LOGGER.error(\"Connection error: power on command not sent.\")\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nturns off receiver via HTTP get command.", "response": "def power_off(self):\n        \"\"\"Turn off receiver via HTTP get command.\"\"\"\n        try:\n            if self.send_get_command(self._urls.command_power_standby):\n                self._power = POWER_STANDBY\n                self._state = STATE_OFF\n                return True\n            else:\n                return False\n        except requests.exceptions.RequestException:\n            _LOGGER.error(\"Connection error: power off command not sent.\")\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nvolumes up receiver via HTTP get command.", "response": "def volume_up(self):\n        \"\"\"Volume up receiver via HTTP get command.\"\"\"\n        try:\n            return bool(self.send_get_command(self._urls.command_volume_up))\n        except requests.exceptions.RequestException:\n            _LOGGER.error(\"Connection error: volume up command not sent.\")\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nvolumes down receiver via HTTP get command.", "response": "def volume_down(self):\n        \"\"\"Volume down receiver via HTTP get command.\"\"\"\n        try:\n            return bool(self.send_get_command(self._urls.command_volume_down))\n        except requests.exceptions.RequestException:\n            _LOGGER.error(\"Connection error: volume down command not sent.\")\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_volume(self, volume):\n        if volume < -80 or volume > 18:\n            raise ValueError(\"Invalid volume\")\n\n        try:\n            return bool(self.send_get_command(\n                self._urls.command_set_volume % volume))\n        except requests.exceptions.RequestException:\n            _LOGGER.error(\"Connection error: set volume command not sent.\")\n            return False", "response": "Set receiver volume via HTTP get command."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmute receiver via HTTP get command.", "response": "def mute(self, mute):\n        \"\"\"Mute receiver via HTTP get command.\"\"\"\n        try:\n            if mute:\n                if self.send_get_command(self._urls.command_mute_on):\n                    self._mute = STATE_ON\n                    return True\n                else:\n                    return False\n            else:\n                if self.send_get_command(self._urls.command_mute_off):\n                    self._mute = STATE_OFF\n                    return True\n                else:\n                    return False\n        except requests.exceptions.RequestException:\n            _LOGGER.error(\"Connection error: mute command not sent.\")\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sound_mode(self):\n        sound_mode_matched = self._parent_avr.match_sound_mode(\n            self._parent_avr.sound_mode_raw)\n        return sound_mode_matched", "response": "Return the matched current sound mode as a string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef identify_denonavr_receivers():\n    # Sending SSDP broadcast message to get devices\n    devices = send_ssdp_broadcast()\n\n    # Check which responding device is a DenonAVR device and prepare output\n    receivers = []\n    for device in devices:\n        try:\n            receiver = evaluate_scpd_xml(device[\"URL\"])\n        except ConnectionError:\n            continue\n        if receiver:\n            receivers.append(receiver)\n\n    return receivers", "response": "Identify DenonAVR using SSDP and SCPD queries."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send_ssdp_broadcast():\n    # Send up to three different broadcast messages\n    for i, ssdp_query in enumerate(SSDP_QUERIES):\n        # Prepare SSDP broadcast message\n        sock = socket.socket(\n            socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP)\n        sock.settimeout(2)\n        sock.sendto(ssdp_query.encode(), (SSDP_ADDR, SSDP_PORT))\n\n        # Collect all responses within the timeout period\n        res = []\n        try:\n            while True:\n                res.append(sock.recvfrom(10240))\n        except socket.timeout:\n            sock.close()\n\n        if res:\n            _LOGGER.debug(\"Got results after %s SSDP queries\", i + 1)\n            sock.close()\n            break\n\n    # Prepare output of responding devices\n    devices = {}\n    device = {}\n\n    for entry in res:\n        device[\"address\"] = entry[1]\n        # Some string operations to get the receivers URL\n        # which could be found between LOCATION and end of line of the response\n        en_decoded = entry[0].decode(\"utf-8\")\n        # If location is not found, skip the entry\n        try:\n            device[\"URL\"] = (\n                en_decoded[\n                    en_decoded.lower().index(\n                        \"location:\") + 10:en_decoded.index(\n                            \"\\r\\n\", en_decoded.lower().index(\"location:\"))]\n            )\n        except ValueError:\n            continue\n        devices[device[\"address\"]] = device.copy()\n\n    _LOGGER.debug(\"Following devices found: %s\", list(devices.values()))\n    return list(devices.values())", "response": "Send SSDP broadcast message to discover UPnP devices."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nevaluating SCPD XML to identified URLs.", "response": "def evaluate_scpd_xml(url):\n    \"\"\"\n    Get and evaluate SCPD XML to identified URLs.\n\n    Returns dictionary with keys \"host\", \"modelName\", \"friendlyName\" and\n    \"presentationURL\" if a Denon AVR device was found and \"False\" if not.\n    \"\"\"\n    # Get SCPD XML via HTTP GET\n    try:\n        res = requests.get(url, timeout=2)\n    except requests.exceptions.RequestException as err:\n        _LOGGER.error(\n            \"When trying to request %s the following error occurred: %s\",\n            url, err)\n        raise ConnectionError\n\n    if res.status_code == 200:\n        try:\n            root = ET.fromstring(res.text)\n            # Look for manufacturer \"Denon\" in response.\n            # Using \"try\" in case tags are not available in XML\n            _LOGGER.debug(\"Device %s has manufacturer %s\", url,\n                          root.find(SCPD_DEVICE).find(SCPD_MANUFACTURER).text)\n            if (root.find(SCPD_DEVICE).find(\n                    SCPD_MANUFACTURER).text in SUPPORTED_MANUFACTURERS and\n                    root.find(SCPD_DEVICE).find(\n                        SCPD_DEVICETYPE).text == DEVICETYPE_DENON):\n                device = {}\n                device[\"host\"] = urlparse(\n                    root.find(SCPD_DEVICE).find(\n                        SCPD_PRESENTATIONURL).text).hostname\n                device[\"presentationURL\"] = (\n                    root.find(SCPD_DEVICE).find(SCPD_PRESENTATIONURL).text)\n                device[\"modelName\"] = (\n                    root.find(SCPD_DEVICE).find(SCPD_MODELNAME).text)\n                device[\"friendlyName\"] = (\n                    root.find(SCPD_DEVICE).find(SCPD_FRIENDLYNAME).text)\n                return device\n            else:\n                return False\n        except (AttributeError, ValueError, ET.ParseError) as err:\n            _LOGGER.error(\n                \"Error occurred during evaluation of SCPD XML: %s\", err)\n            return False\n    else:\n        _LOGGER.error(\"Host returned HTTP status %s when connecting to %s\",\n                      res.status_code, url)\n        raise ConnectionError"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef init_all_receivers():\n    receivers = discover()\n\n    init_receivers = []\n    for receiver in receivers:\n        init_receiver = DenonAVR(receiver[\"host\"])\n        init_receivers.append(init_receiver)\n    return init_receivers", "response": "Initialize all discovered Denon AVR receivers in LAN zone."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse a text string and returns a list of timestamps for words and lines of text", "response": "def parse_auto_sub(text):\n    '''\n    Parses webvtt and returns timestamps for words and lines\n    Tested on automatically generated subtitles from YouTube\n    '''\n\n    pat = r'<(\\d\\d:\\d\\d:\\d\\d(\\.\\d+)?)>'\n    out = []\n\n    lines = []\n    data = text.split('\\n')\n    data = [d for d in data if re.search(r'\\d\\d:\\d\\d:\\d\\d', d) is not None]\n    for i, d in enumerate(data):\n        if re.search(pat, d):\n            lines.append((data[i-1], d))\n\n    if len(lines) > 0:\n        out = parse_cued(lines)\n    else:\n        out = parse_uncued(text)\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting the given timecode to frames", "response": "def tc_to_frames(self, timecode):\n        \"\"\"Converts the given timecode to frames\n        \"\"\"\n        hours, minutes, seconds, frames = map(int, timecode.split(':'))\n\n        ffps = float(self._framerate)\n\n        if self.drop_frame:\n            # Number of drop frames is 6% of framerate rounded to nearest\n            # integer\n            drop_frames = int(round(ffps * .066666))\n        else:\n            drop_frames = 0\n\n        # We don't need the exact framerate anymore, we just need it rounded to\n        # nearest integer\n        ifps = self._int_framerate\n\n        # Number of frames per hour (non-drop)\n        hour_frames = ifps * 60 * 60\n\n        # Number of frames per minute (non-drop)\n        minute_frames = ifps * 60\n\n        # Total number of minutes\n        total_minutes = (60 * hours) + minutes\n\n        frame_number = \\\n            ((hour_frames * hours) + (minute_frames * minutes) +\n             (ifps * seconds) + frames) - \\\n            (drop_frames * (total_minutes - (total_minutes // 10)))\n\n        frames = frame_number + 1\n\n        return frames"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef frames_to_tc(self, frames):\n\n        if frames == 0:\n            return 0, 0, 0, 0\n\n        ffps = float(self._framerate)\n\n        if self.drop_frame:\n            # Number of frames to drop on the minute marks is the nearest\n            # integer to 6% of the framerate\n            drop_frames = int(round(ffps * .066666))\n        else:\n            drop_frames = 0\n\n        # Number of frames in an hour\n        frames_per_hour = int(round(ffps * 60 * 60))\n        # Number of frames in a day - timecode rolls over after 24 hours\n        frames_per_24_hours = frames_per_hour * 24\n        # Number of frames per ten minutes\n        frames_per_10_minutes = int(round(ffps * 60 * 10))\n        # Number of frames per minute is the round of the framerate * 60 minus\n        # the number of dropped frames\n        frames_per_minute = int(round(ffps)*60) - drop_frames\n\n        frame_number = frames - 1\n\n        if frame_number < 0:\n            # Negative time. Add 24 hours.\n            frame_number += frames_per_24_hours\n\n        # If frame_number is greater than 24 hrs, next operation will rollover\n        # clock\n        frame_number %= frames_per_24_hours\n\n        if self.drop_frame:\n            d = frame_number // frames_per_10_minutes\n            m = frame_number % frames_per_10_minutes\n            if m > drop_frames:\n                frame_number += (drop_frames * 9 * d) + \\\n                    drop_frames * ((m - drop_frames) // frames_per_minute)\n            else:\n                frame_number += drop_frames * 9 * d\n\n        ifps = self._int_framerate\n        frs = frame_number % ifps\n        secs = (frame_number // ifps) % 60\n        mins = ((frame_number // ifps) // 60) % 60\n        hrs = (((frame_number // ifps) // 60) // 60)\n\n        return hrs, mins, secs, frs", "response": "Converts frames back to timecode."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_timecode(cls, timecode):\n        bfr = timecode.replace(';', ':').replace('.', ':').split(':')\n        hrs = int(bfr[0])\n        mins = int(bfr[1])\n        secs = int(bfr[2])\n        frs = int(bfr[3])\n        return hrs, mins, secs, frs", "response": "parses a timecode string into a tuple of hours minutes seconds and seconds"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_ngrams(inputfile, n=1, use_transcript=False, use_vtt=False):\n    '''\n    Get ngrams from a text\n    Sourced from:\n    https://gist.github.com/dannguyen/93c2c43f4e65328b85af\n    '''\n\n    words = []\n    if use_transcript:\n        for s in audiogrep.convert_timestamps(inputfile):\n            for w in s['words']:\n                words.append(w[0])\n    elif use_vtt:\n        vtts = get_vtt_files(inputfile)\n        for vtt in vtts:\n            with open(vtt['vtt'], 'r') as infile:\n                sentences = parse_auto_sub(infile.read())\n            for s in sentences:\n                for w in s['words']:\n                    words.append(w['word'])\n    else:\n        text = ''\n        srts = get_subtitle_files(inputfile)\n        for srt in srts:\n            lines = clean_srt(srt)\n            if lines:\n                for timespan in lines.keys():\n                    line = lines[timespan].strip()\n                    text += line + ' '\n\n        words = re.split(r'[.?!,:\\\"]+\\s*|\\s+', text)\n\n    ngrams = zip(*[words[i:] for i in range(n)])\n    return ngrams", "response": "Get ngrams from a text file"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts an array of ordered timestamps into an EDL string", "response": "def make_edl(timestamps, name):\n    '''Converts an array of ordered timestamps into an EDL string'''\n\n    fpses = {}\n\n    out = \"TITLE: {}\\nFCM: NON-DROP FRAME\\n\\n\".format(name)\n\n    rec_in = 0\n\n    for index, timestamp in enumerate(timestamps):\n        if timestamp['file'] not in fpses:\n            fpses[timestamp['file']] = get_fps(timestamp['file'])\n\n        fps = fpses[timestamp['file']]\n\n        n = str(index + 1).zfill(4)\n\n        time_in = timestamp['start']\n        time_out = timestamp['end']\n        duration = time_out - time_in\n\n        rec_out = rec_in + duration\n\n        full_name = 'reel_{}'.format(n)\n\n        filename = timestamp['file']\n\n        out += make_edl_segment(n, time_in, time_out, rec_in, rec_out, full_name, filename, fps=fps)\n\n        rec_in = rec_out\n\n    with open(name, 'w') as outfile:\n        outfile.write(out)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert an srt timespan into a start and end timestamp.", "response": "def convert_timespan(timespan):\n    \"\"\"Convert an srt timespan into a start and end timestamp.\"\"\"\n    start, end = timespan.split('-->')\n    start = convert_timestamp(start)\n    end = convert_timestamp(end)\n    return start, end"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert an srt timestamp into seconds.", "response": "def convert_timestamp(timestamp):\n    \"\"\"Convert an srt timestamp into seconds.\"\"\"\n    timestamp = timestamp.strip()\n    chunk, millis = timestamp.split(',')\n    hours, minutes, seconds = chunk.split(':')\n    hours = int(hours)\n    minutes = int(minutes)\n    seconds = int(seconds)\n    seconds = seconds + hours * 60 * 60 + minutes * 60 + float(millis) / 1000\n    return seconds"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving damaging line breaks and numbers from srt files and return a OrderedDict.", "response": "def clean_srt(srt):\n    \"\"\"Remove damaging line breaks and numbers from srt files and return a\n    dictionary.\n    \"\"\"\n    with open(srt, 'r') as f:\n        text = f.read()\n    text = re.sub(r'^\\d+[\\n\\r]', '', text, flags=re.MULTILINE)\n    lines = text.splitlines()\n    output = OrderedDict()\n    key = ''\n\n    for line in lines:\n        line = line.strip()\n        if line.find('-->') > -1:\n            key = line\n            output[key] = ''\n        else:\n            if key != '':\n                output[key] += line + ' '\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsearches for and remove temp log files found in the output directory.", "response": "def cleanup_log_files(outputfile):\n    \"\"\"Search for and remove temp log files found in the output directory.\"\"\"\n    d = os.path.dirname(os.path.abspath(outputfile))\n    logfiles = [f for f in os.listdir(d) if f.endswith('ogg.log')]\n    for f in logfiles:\n        os.remove(f)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef demo_supercut(composition, padding):\n    for i, c in enumerate(composition):\n        line = c['line']\n        start = c['start']\n        end = c['end']\n        if i > 0 and composition[i - 1]['file'] == c['file'] and start < composition[i - 1]['end']:\n            start = start + padding\n        print(\"{1} to {2}:\\t{0}\".format(line, start, end))", "response": "Print out timespans to be cut followed by the line number in the srt."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_supercut(composition, outputfile, padding):\n    print(\"[+] Creating clips.\")\n    demo_supercut(composition, padding)\n\n    # add padding when necessary\n    for (clip, nextclip) in zip(composition, composition[1:]):\n        if ((nextclip['file'] == clip['file']) and (nextclip['start'] < clip['end'])):\n            nextclip['start'] += padding\n\n    # put all clips together:\n    all_filenames = set([c['file'] for c in composition])\n    videofileclips = dict([(f, VideoFileClip(f)) for f in all_filenames])\n    cut_clips = [videofileclips[c['file']].subclip(c['start'], c['end']) for c in composition]\n\n    print(\"[+] Concatenating clips.\")\n    final_clip = concatenate(cut_clips)\n\n    print(\"[+] Writing ouput file.\")\n    final_clip.to_videofile(outputfile, codec=\"libx264\", temp_audiofile='temp-audio.m4a', remove_temp=True, audio_codec='aac')", "response": "Create a supercut of the video file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating & concatenate video clips in batches of size BATCH_SIZE and output finished video file to output directory.", "response": "def create_supercut_in_batches(composition, outputfile, padding):\n    \"\"\"Create & concatenate video clips in groups of size BATCH_SIZE and output\n    finished video file to output directory.\n    \"\"\"\n    total_clips = len(composition)\n    start_index = 0\n    end_index = BATCH_SIZE\n    batch_comp = []\n    while start_index < total_clips:\n        filename = outputfile + '.tmp' + str(start_index) + '.mp4'\n        try:\n            create_supercut(composition[start_index:end_index], filename, padding)\n            batch_comp.append(filename)\n            gc.collect()\n            start_index += BATCH_SIZE\n            end_index += BATCH_SIZE\n        except:\n            start_index += BATCH_SIZE\n            end_index += BATCH_SIZE\n            next\n\n    clips = [VideoFileClip(filename) for filename in batch_comp]\n    video = concatenate(clips)\n    video.to_videofile(outputfile, codec=\"libx264\", temp_audiofile='temp-audio.m4a', remove_temp=True, audio_codec='aac')\n\n\n    # remove partial video files\n    for filename in batch_comp:\n        os.remove(filename)\n\n    cleanup_log_files(outputfile)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsearches a line in a given search term.", "response": "def search_line(line, search, searchtype):\n    \"\"\"Return True if search term is found in given line, False otherwise.\"\"\"\n    if searchtype == 're' or searchtype == 'word':\n        return re.search(search, line)  #, re.IGNORECASE)\n    elif searchtype == 'pos':\n        return searcher.search_out(line, search)\n    elif searchtype == 'hyper':\n        return searcher.hypernym_search(line, search)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of subtitle files.", "response": "def get_subtitle_files(inputfile):\n    \"\"\"Return a list of subtitle files.\"\"\"\n    srts = []\n\n    for f in inputfile:\n        filename = f.split('.')\n        filename[-1] = 'srt'\n        srt = '.'.join(filename)\n        if os.path.isfile(srt):\n            srts.append(srt)\n\n    if len(srts) == 0:\n        print(\"[!] No subtitle files were found.\")\n        return False\n\n    return srts"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of vtt files.", "response": "def get_vtt_files(inputfile):\n    \"\"\"Return a list of vtt files.\"\"\"\n    vtts = []\n\n    for f in inputfile:\n        filename = f.split('.')\n        filename = '.'.join(filename[0:-1])\n        vtt = glob(filename + '*.vtt')\n        if len(vtt) > 0:\n            vtts.append({'vtt': vtt[0], 'video': f})\n\n    if len(vtts) == 0:\n        print(\"[!] No vtt files were found.\")\n        return False\n\n    return vtts"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compose_from_srts(srts, search, searchtype):\n    composition = []\n    foundSearchTerm = False\n\n    # Iterate over each subtitles file.\n    for srt in srts:\n\n        print(srt)\n        lines = clean_srt(srt)\n\n        videofile = \"\"\n        foundVideoFile = False\n\n        print(\"[+] Searching for video file corresponding to '\" + srt + \"'.\")\n        for ext in usable_extensions:\n            tempVideoFile = srt.replace('.srt', '.' + ext)\n            if os.path.isfile(tempVideoFile):\n                videofile = tempVideoFile\n                foundVideoFile = True\n                print(\"[+] Found '\" + tempVideoFile + \"'.\")\n\n        # If a correspndong video file was found for this subtitles file...\n        if foundVideoFile:\n\n            # Check that the subtitles file contains subtitles.\n            if lines:\n\n                # Iterate over each line in the current subtitles file.\n                for timespan in lines.keys():\n                    line = lines[timespan].strip()\n\n                    # If this line contains the search term\n                    if search_line(line, search, searchtype):\n\n                        foundSearchTerm = True\n\n                        # Extract the timespan for this subtitle.\n                        start, end = convert_timespan(timespan)\n\n                        # Record this occurance of the search term.\n                        composition.append({'file': videofile, 'time': timespan, 'start': start, 'end': end, 'line': line})\n\n                # If the search was unsuccessful.\n                if foundSearchTerm is False:\n                    print(\"[!] Search term '\" + search + \"'\" + \" was not found is subtitle file '\" + srt + \"'.\")\n\n            # If no subtitles were found in the current file.\n            else:\n                print(\"[!] Subtitle file '\" + srt + \"' is empty.\")\n\n        # If no video file was found...\n        else:\n            print(\"[!] No video file was found which corresponds to subtitle file '\" + srt + \"'.\")\n            print(\"[!] The following video formats are currently supported:\")\n            extList = \"\"\n            for ext in usable_extensions:\n                extList += ext + \", \"\n            print(extList)\n\n    return composition", "response": "Takes a list of subtitle filenames search term and search type and returns a list of timestamps for composition."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntake a list of transcripts created by audiogrep a search and a search type and returns a list of timestamps for creating a supercut", "response": "def compose_from_transcript(files, search, searchtype):\n    \"\"\"Takes transcripts created by audiogrep/pocketsphinx, a search and search type\n    and returns a list of timestamps for creating a supercut\"\"\"\n\n    final_segments = []\n\n    if searchtype in ['re', 'word', 'franken', 'fragment']:\n        if searchtype == 're':\n            searchtype = 'sentence'\n\n        segments = audiogrep.search(search, files, mode=searchtype, regex=True)\n        for seg in segments:\n            seg['file'] = seg['file'].replace('.transcription.txt', '')\n            seg['line'] = seg['words']\n            final_segments.append(seg)\n\n    elif searchtype in ['hyper', 'pos']:\n        for s in audiogrep.convert_timestamps(files):\n            for w in s['words']:\n                if search_line(w[0], search, searchtype):\n                    seg = {\n                        'file': s['file'].replace('.transcription.txt',''),\n                        'line': w[0],\n                        'start': float(w[1]),\n                        'end': float(w[2])\n                    }\n                    final_segments.append(seg)\n\n    return final_segments"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef videogrep(inputfile, outputfile, search, searchtype, maxclips=0, padding=0, test=False, randomize=False, sync=0, use_transcript=False, use_vtt=False, export_clips=False):\n\n    padding = padding / 1000.0\n    sync = sync / 1000.0\n    composition = []\n    foundSearchTerm = False\n\n    if use_transcript:\n        composition = compose_from_transcript(inputfile, search, searchtype)\n    elif use_vtt:\n        vtts = get_vtt_files(inputfile)\n        composition = compose_from_vtt(vtts, search, searchtype)\n    else:\n        srts = get_subtitle_files(inputfile)\n        composition = compose_from_srts(srts, search, searchtype)\n\n\n    # If the search term was not found in any subtitle file...\n    if len(composition) == 0:\n        print(\"[!] Search term '\" + search + \"'\" + \" was not found in any file.\")\n        exit(1)\n\n    else:\n        print(\"[+] Search term '\" + search + \"'\" + \" was found in \" + str(len(composition)) + \" places.\")\n\n        # apply padding and sync\n        for c in composition:\n            c['start'] = c['start'] + sync - padding\n            c['end'] = c['end'] + sync + padding\n\n        if maxclips > 0:\n            composition = composition[:maxclips]\n\n        if randomize is True:\n            random.shuffle(composition)\n\n        if test is True:\n            demo_supercut(composition, padding)\n        else:\n            if os.path.splitext(outputfile)[1].lower() == '.edl':\n                make_edl(composition, outputfile)\n            elif export_clips:\n                split_clips(composition, outputfile)\n            else:\n                if len(composition) > BATCH_SIZE:\n                    print(\"[+} Starting batch job.\")\n                    create_supercut_in_batches(composition, outputfile, padding)\n                else:\n                    create_supercut(composition, outputfile, padding)", "response": "Search through and find all instances of the search term in an srt or transcript and output a new video file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _parseXml(self,cc):\n        htmlpar = HTMLParser.HTMLParser()\n        cc = cc.split(\"</text>\") # ['<text start=\"2997.929\">So, it will\\nhas time', '<text start=\"3000.929\">blah', ..]\n        captions = []\n        for line in cc:\n            if re.search('text', line):\n                time = re.search(r'start=\"(\\d+)(?:\\.(\\d+)){0,1}', line).groups() # ('2997','929')\n                time = ( int(time[0]), int(0 if not time[1] else time[1]) )\n                    #convert seconds and millisec to int\n                text = re.search(r'\">(.*)', line, re.DOTALL).group(1) # extract text i.e. 'So, it will\\nhas time'\n                textlines = [ htmlpar.unescape(htmlpar.unescape( unicode(lineunparsed,\"utf-8\") )) for lineunparsed in text.split('\\n') ] \n                    #unscape chars like &amp; or &#39;\n                ntime = {'hours':time[0]/3600,\"min\":time[0]%3600/60,\"sec\":time[0]%3600%60,\"msec\":time[1]}\n                captions.append({'time':ntime,'textlines':textlines})\n        return captions", "response": "This function parses the XML file with captions and returns a list of dictionaries with the keys time and textlines."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating a string that contains the srt of the captions.", "response": "def _generateSrt(self,captions):\n        \"\"\" INPUT: array with captions, i.e.\n                [{'texlines': [u\"So, I'm going to rewrite this\", 'in a more concise form as'],\n                'time': {'hours':'1', 'min':'2','sec':44,'msec':232} }]\n            OUTPUT: srtformated string\n        \"\"\"\n        caption_number = 0\n        srt_output = []\n        for caption in captions:\n            caption_number += 1\n            #CAPTION NUMBER\n            srt_output.append(str(caption_number))\n            #TIME\n            time_from = ( caption['time']['hours'], caption['time']['min'], caption['time']['sec'], caption['time']['msec'] ) \n            if len(captions)>caption_number:\n                #display caption until next one\n                next_caption_time = captions[caption_number]['time']\n                time_to = ( next_caption_time['hours'], next_caption_time['min'], next_caption_time['sec'], next_caption_time['msec'] )\n            else:\n                #display caption for 2 seconds\n                time_to = (time_from[0],time_from[1]+2,time_from[2],time_from[3]) \n            srt_output.append( (\":\").join([str(i) for i in time_from[0:-1]])+\",\"+str(time_from[-1])+\" --> \"+(\":\").join([str(i) for i in time_to[0:-1]])+\",\"+str(time_to[-1]))\n            #CAPTIONS\n            for caption_line in caption['textlines']:\n                srt_output.append(caption_line)\n            #Add two empty lines to serarate every caption showed\n            srt_output.append(\"\")\n            srt_output.append(\"\")\n        return srt_output"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef change_volume(self, increment):\n        if increment == 1:\n            self.volume += 5\n        else:\n            self.volume -= 5\n        self.volume = max(min(self.volume, 100), 0)", "response": "change the volume of the current object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating the internal state of the internal state of the object", "response": "def updown(self, increment):\n        \"\"\"\n        \u5c4f\u5e55\u4e0a\u4e0b\u6eda\u52a8\n\n        :params incrment: 1 \u5411\u4e0b\u6eda\u52a8\n                          -1 \u5411\u4e0a\u6eda\u52a8\n        \"\"\"\n        scroll_line_num = self.screen_height - 4\n        # paging\n        if increment == -1 and self.markline == 0 and self.topline != 0:\n            self.topline -= 1\n        elif increment == 1 and self.markline + self.topline != len(self._lines) - 1 and self.markline == scroll_line_num:\n            self.topline += 1\n        # scroll\n        if increment == -1 and self.markline != 0:\n            self.markline -= 1\n        elif increment == 1 and self.markline != scroll_line_num and self.markline < len(self._lines) - 1:\n            self.markline += 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns number of center characters in string", "response": "def center_num(self, string):\n        \"\"\"\n        \u8fd4\u56de\u603b\u5b57\u7b26\u6570(\u8003\u8651\u82f1\u6587\u548c\u4e2d\u6587\u5728\u7ec8\u7aef\u6240\u5360\u5b57\u5757)\n\n        return: int\n        \"\"\"\n        l = 0\n        for i in string:\n            l += 2 if self.is_cn_char(i) else 1\n        return l"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _watchdog_key(self):\n        while True:\n            k = getch.getch()\n            self.key_queue.put(k)", "response": "get a key from the watchdog queue and put it in the queue"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_line(self):\n        for now_time in reversed(range(self.data.time)):\n            locate = [index for index, i in enumerate(self._sort_lrc_dict)\n                      if i[0] == now_time]  # \u67e5\u627e\u6b4c\u8bcd\u5728self.sort_lrc_dict\u4e2d\u7684\u4f4d\u7f6e\n            if locate:\n                return locate[0] + self.lrc_offset\n        return 0", "response": "find the line in the sort_lrc_dict"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_display_lines(self):\n        self.screen_height, self.screen_width = self.linesnum()  # \u5c4f\u5e55\u663e\u793a\u884c\u6570\n\n        display_lines = ['']\n        display_lines.append(self._title + '\\r')\n        display_lines.append('')\n\n        scroll_line_num = self.screen_height - 6\n        for linenum in range(scroll_line_num):\n            if scroll_line_num//2 - linenum > self.markline - self.topline or \\\n                    linenum - scroll_line_num//2 >= len(self._lines) - self.markline:\n                display_lines.append('\\r')\n            else:\n                line = self._lines[self.markline - (scroll_line_num//2 - linenum)]\n                line = line.strip('\\n')\n                l = self.center_num(line)\n                flag_num = (self.screen_width - l) // 2\n                if linenum == scroll_line_num//2:\n                    i = color_func(self.c['LRC']['highlight'])(line)\n                    display_lines.append(' ' * flag_num + i + '\\r')\n                else:\n                    line = color_func(self.c['LRC']['line'])(line)\n                    display_lines.append(' ' * flag_num + line + '\\r')\n\n        display_lines.append('')  # \u7a7a\u884c\n        display_lines.append(self.center_suffix_selected() + '\\r')  # \u6b4c\u8bcd\u9875\u9762\u6807\u9898\n\n        self.display_lines = display_lines", "response": "Make the display lines for the screen."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef basic_color(code):\n    def inner(text, rl=False):\n        \"\"\" Every raw_input with color sequences should be called with\n        rl=True to avoid readline messed up the length calculation\n        \"\"\"\n        c = code\n        if rl:\n            return \"\\001\\033[%sm\\002%s\\001\\033[0m\\002\" % (c, text)\n        else:\n            return \"\\033[%sm%s\\033[0m\" % (c, text)\n    return inner", "response": "Basic color function for the base class"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef term_color(code):\n    def inner(text, rl=False):\n        \"\"\"\n        Every raw_input with color sequences should be called with\n        rl=True to avoid readline messed up the length calculation\n        \"\"\"\n        c = code\n        if rl:\n            return \"\\001\\033[38;5;%sm\\002%s\\001\\033[0m\\002\" % (c, text)\n        else:\n            return \"\\033[38;5;%sm%s\\033[0m\" % (c, text)\n    return inner", "response": "Color color function for the current term."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncall color function base on name", "response": "def color_func(func_name):\n    \"\"\"\n    Call color function base on name\n    \"\"\"\n    if str(func_name).isdigit():\n        return term_color(int(func_name))\n    return globals()[func_name]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _decode_list(data):\n    if six.PY3:\n        return data\n    rv = []\n    for item in data:\n        if not isinstance(item, text_type):\n            item = item.encode('utf-8')\n        elif isinstance(item, list):\n            item = _decode_list(item)\n        rv.append(item)\n    return rv", "response": "Convert list to list"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndecodes dict to unicode", "response": "def decode_dict(data):\n    \"\"\"\n    \u89e3\u6790json\u5b57\u5178,\u8f6c\u6362\u6210utf-8\n    \"\"\"\n    if six.PY3:\n        return data\n    rv = {}\n    for key, value in iteritems(data):\n        if isinstance(key, text_type):\n            key = key.encode('utf-8')\n\n        if isinstance(value, text_type):\n            value = value.encode('utf-8')\n        elif isinstance(value, list):\n            value = _decode_list(value)\n        # no need to recurse into dict, json library will do that\n        rv[key] = value\n    return rv"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets login data from pickle file.", "response": "def get_login_data(self):\n        \"\"\"\n        \u63d0\u4f9b\u767b\u9646\u7684\u8ba4\u8bc1\n\n        \u8fd9\u91cc\u987a\u5e26\u589e\u52a0\u4e86 volume, channel, theme_id , netease, run_times\u7684\u9ed8\u8ba4\u503c\n        \"\"\"\n        login_data = None\n        try:\n            if os.path.exists(PATH_TOKEN):\n                # \u4f7f\u7528\u4e0a\u6b21\u767b\u5f55\u4fdd\u5b58\u7684token\n                with open(PATH_TOKEN, 'rb') as f:\n                    login_data = pickle.load(f)\n                if 'cookies' not in login_data:\n                    login_data = request_token()\n        except Exception:\n            pass\n        if not login_data:\n            # \u672a\u767b\u9646\n            login_data = request_token()\n\n        self.get_default_set(login_data)\n        self.get_user_states(login_data)\n        self.get_is_latest_version(login_data)\n        Thread(target=self.check_version).start()  # \u8fd9\u91cc\u6bcf\u6b21\u5f02\u6b65\u68c0\u6d4b, \u4e0b\u6b21\u6253\u5f00\u65f6\u8fdb\u884c\u63d0\u793a\n\n        return login_data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_default_set(self, login_data):\n        self.cookies = login_data.get('cookies', '')\n        self.user_name = login_data.get('user_name', '')\n        print('\\033[31m\u2665\\033[0m Get local token - Username: \\033[33m%s\\033[0m' %\\\n              login_data['user_name'])\n\n        self.channel = login_data.get('channel', 0)\n        print('\\033[31m\u2665\\033[0m Get channel [\\033[32m OK \\033[0m]')\n\n        self.volume = login_data.get('volume', 50)\n        print('\\033[31m\u2665\\033[0m Get volume [\\033[32m OK \\033[0m]')\n\n        self.theme_id = login_data.get('theme_id', 0)\n        print('\\033[31m\u2665\\033[0m Get theme [\\033[32m OK \\033[0m]')\n\n        self.netease = login_data.get('netease', False)\n        self.keys = self.get_keys()", "response": "Get the default set of cookies and keys"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget user states from login data", "response": "def get_user_states(self, login_data):\n        \"\"\"\n        \u7edf\u8ba1\u7528\u6237\u4fe1\u606f\n        \"\"\"\n        self.run_times = login_data.get('run_times', 0)\n        self.total_time = login_data.get('total_time', 0)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the keys from the config file", "response": "def get_keys(self):\n        '''\n        \u83b7\u53d6\u914d\u7f6e\u5e76\u68c0\u67e5\u662f\u5426\u66f4\u6539\n        '''\n        if not os.path.exists(PATH_CONFIG):\n            with open(PATH_CONFIG, 'w') as F:\n                F.write(CONFIG)\n        else:\n            config = ConfigParser.ConfigParser()\n            with open(PATH_CONFIG, 'r') as cfgfile:\n                config.readfp(cfgfile)\n                options = config.options('key')\n                for option in options:\n                    option = option.upper()\n                    if option in KEYS:\n                        KEYS[option] = config.get('key', option)\n        return KEYS"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save_config(self, volume, channel, theme, netease):\n        self.login_data['cookies'] = self.cookies\n        self.login_data['volume'] = volume\n        self.login_data['channel'] = channel\n        self.login_data['theme_id'] = theme\n        self.login_data['netease'] = netease\n        self.login_data['run_times'] = self.run_times + 1\n        self.login_data['last_time'] = self.last_time\n        self.login_data['total_time'] = self.total_time +\\\n            time.time() - self.last_time\n        self.login_data['is_latest'] = self.is_latest\n        with open(PATH_TOKEN, 'wb') as f:\n            pickle.dump(self.login_data, f)", "response": "Save the config to disk."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_channels(self):\n        self._channel_list = [\n            # {'name': '\u7ea2\u5fc3\u5146\u8d6b', 'channel_id': -3},\n            {'name': '\u6211\u7684\u79c1\u4eba\u5146\u8d6b', 'channel_id': 0},\n            {'name': '\u6bcf\u65e5\u79c1\u4eba\u6b4c\u5355', 'channel_id': -2},\n            {'name': '\u8c46\u74e3\u7cbe\u9009\u5146\u8d6b', 'channel_id': -10},\n            # \u5fc3\u60c5 / \u573a\u666f\n            {'name': '\u5de5\u4f5c\u5b66\u4e60', 'channel_id': 153},\n            {'name': '\u6237\u5916', 'channel_id': 151},\n            {'name': '\u4f11\u606f', 'channel_id': 152},\n            {'name': '\u4ea2\u594b', 'channel_id': 154},\n            {'name': '\u8212\u7f13', 'channel_id': 155},\n            {'name': 'Easy', 'channel_id': 77},\n            {'name': '\u5496\u5561', 'channel_id': 32},\n            {'name': '\u8fd0\u52a8', 'channel_id': 257},\n            # \u8bed\u8a00 / \u5e74\u4ee3\n            {'name': '\u534e\u8bed', 'channel_id': 1},\n            {'name': '\u6b27\u7f8e', 'channel_id': 2},\n            {'name': '\u4e03\u96f6', 'channel_id': 3},\n            {'name': '\u516b\u96f6', 'channel_id': 4},\n            {'name': '\u4e5d\u96f6', 'channel_id': 5},\n            {'name': '\u7ca4\u8bed', 'channel_id': 6},\n            {'name': '\u65e5\u8bed', 'channel_id': 17},\n            {'name': '\u97e9\u8bed', 'channel_id': 18},\n            {'name': '\u6cd5\u8bed', 'channel_id': 22},\n            {'name': '\u65b0\u6b4c', 'channel_id': 61},\n            # \u98ce\u683c / \u6d41\u6d3e\n            {'name': '\u6d41\u884c', 'channel_id': 194},\n            {'name': '\u6447\u6eda', 'channel_id': 7},\n            {'name': '\u6c11\u8c23', 'channel_id': 8},\n            {'name': '\u8f7b\u97f3\u4e50', 'channel_id': 9},\n            {'name': '\u7535\u5f71\u539f\u58f0', 'channel_id': 10},\n            {'name': '\u7235\u58eb', 'channel_id': 13},\n            {'name': '\u7535\u5b50', 'channel_id': 14},\n            {'name': '\u8bf4\u5531', 'channel_id': 15},\n            {'name': 'R&B', 'channel_id': 16},\n            {'name': '\u53e4\u5178', 'channel_id': 27},\n            {'name': '\u52a8\u6f2b', 'channel_id': 28},\n            {'name': '\u4e16\u754c\u97f3\u4e50', 'channel_id': 187},\n            {'name': '\u5e03\u9c81\u65af', 'channel_id': 188},\n            {'name': '\u62c9\u4e01', 'channel_id': 189},\n            {'name': '\u96f7\u9b3c', 'channel_id': 190},\n            {'name': '\u5c0f\u6e05\u65b0', 'channel_id': 76}\n        ]", "response": "get the list of channels"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef requests_url(self, ptype, **data):\n        options = {\n            'type': ptype,\n            'pt': '3.1',\n            'channel': self._channel_id,\n            'pb': '320',\n            'from': 'mainsite',\n            'r': '',\n            'kbps': '320',\n            'app_name': 'radio_website',\n            'client': 's:mainsite|y:3.0',\n            'version': '100'\n        }\n        if 'sid' in data:\n            options['sid'] = data['sid']\n        url = 'https://douban.fm/j/v2/playlist'\n        while True:\n            try:\n                s = requests.get(url, params=options,\n                                 cookies=self._cookies, headers=HEADERS)\n                req_json = s.json()\n                if req_json['r'] == 0:\n                    if 'song' not in req_json or not req_json['song']:\n                        break\n                    return req_json['song'][0]\n            except Exception as err:\n                raise APIError(err)\n                break\n        return None", "response": "Get a url from the douban API"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_lrc(self, playingsong):\n        try:\n            url = \"https://douban.fm/j/v2/lyric\"\n            postdata = {\n                'sid': playingsong['sid'],\n                'ssid': playingsong['ssid'],\n            }\n            s = requests.session()\n            response = s.get(url, params=postdata, headers=HEADERS)\n\n            # \u628a\u6b4c\u8bcd\u89e3\u6790\u6210\u5b57\u5178\n            lyric = json.loads(response.text, object_hook=decode_dict)\n            logger.info(lyric)\n            if lyric.get('code', None) == 1998:\n                logger.info('lrc API access rate limit has been exceeded')\n                return {}\n            elif lyric.get('code', None) == 107:\n                logger.info('lrc API invalid_request_uri')\n                return {}\n            lrc_dic = lrc2dict(lyric['lyric'])\n\n            # \u539f\u6b4c\u8bcd\u7528\u7684unicode,\u4e3a\u4e86\u517c\u5bb9\n            for key, value in iteritems(lrc_dic):\n                # lrc_dic[key] = value.decode('utf-8')\n                lrc_dic[key] = value\n            if lrc_dic:\n                logger.debug('Get lyric success!')\n            return lrc_dic\n        except requests.exceptions.RequestException:\n            logger.error('Get lyric failed!')\n            return {}", "response": "Get a specific language from a specific language."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _run_player(self, extra_cmd):\n        # Force quit old process\n        if self.is_alive:\n            self.quit()\n        args = self._args + extra_cmd\n        logger.debug(\"Exec: \" + ' '.join(args))\n        self.sub_proc = subprocess.Popen(\n            args,\n            stdin=subprocess.PIPE,\n            stdout=subprocess.PIPE,\n            stderr=self._null_file,\n            preexec_fn=os.setsid\n        )\n        # Set up NONBLOCKING flag for the pipe\n        flags = fcntl.fcntl(self.sub_proc.stdout, fcntl.F_GETFL)\n        flags |= os.O_NONBLOCK\n        fcntl.fcntl(self.sub_proc.stdout, fcntl.F_SETFL, flags)\n        # Start watchdog\n        Thread(target=self._watchdog).start()", "response": "\u8fd0\u884c\u64ad\u653e\u5668\uff08\u82e5\u5f53\u524d\u5df2\u6709\u6b63\u5728\u8fd0\u884c\u7684\uff0c\u5f3a\u5236\u63a8\u51fa\uff09\n\n        extra_cmd: \u989d\u5916\u7684\u53c2\u6570 (list)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwatch the process for new data and set the exit event.", "response": "def _watchdog(self):\n        \"\"\"\n        \u76d1\u63a7\u6b63\u5728\u8fd0\u884c\u7684\u64ad\u653e\u5668\uff08\u72ec\u7acb\u7ebf\u7a0b\uff09\n\n        \u64ad\u653e\u5668\u9000\u51fa\u540e\u5c06\u4f1a\u8bbe\u7f6e _exit_event\n        \"\"\"\n        if not self.is_alive:\n            logger.debug(\"Player has already terminated.\")\n            self._exit_event.set()\n            return\n        logger.debug(\"Watching %s[%d]\",\n                     self._player_command, self.sub_proc.pid)\n        returncode = self.sub_proc.wait()\n        logger.debug(\"%s[%d] exit with code %d\",\n                     self._player_command, self.sub_proc.pid, returncode)\n        self._exit_event.set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pause(self):\n        self._pause = False if self._pause else True\n        self._send_command('pause')", "response": "pause - pause the current process"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _send_command(self, cmd, expect=None):\n        if not self.is_alive:\n            raise NotPlayingError()\n        logger.debug(\"Send command to mplayer: \" + cmd)\n        cmd = cmd + \"\\n\"\n        # In Py3k, TypeErrors will be raised because cmd is a string but stdin\n        # expects bytes. In Python 2.x on the other hand, UnicodeEncodeErrors\n        # will be raised if cmd is unicode. In both cases, encoding the string\n        # will fix the problem.\n        try:\n            self.sub_proc.stdin.write(cmd)\n        except (TypeError, UnicodeEncodeError):\n            self.sub_proc.stdin.write(cmd.encode('utf-8', 'ignore'))\n        time.sleep(0.1)     # wait for mplayer (better idea?)\n        # Expect a response for 'get_property' only\n        if not expect:\n            return\n        while True:\n            try:\n                output = self.sub_proc.stdout.readline().rstrip()\n                output = output.decode('utf-8')\n            except IOError:\n                return None\n            # print output\n            split_output = output.split('=')\n            # print(split_output)\n            if len(split_output) == 2 and split_output[0].strip() == expect:\n                # We found it\n                value = split_output[1]\n                return value.strip()", "response": "Send a command to the MPlayer."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef lock(func):\n        @functools.wraps(func)\n        def _func(*args, **kwargs):\n            mutex.acquire()\n            try:\n                return func(*args, **kwargs)\n            finally:\n                mutex.release()\n        return _func", "response": "A decorator that locks the current user s identity table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_lrc(self):\n        if self._playingsong != self._pre_playingsong:\n            self._lrc = douban.get_lrc(self._playingsong)\n            self._pre_playingsong = self._playingsong\n        return self._lrc", "response": "get_lrc - Get the LRC from the current player"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_channel(self, channel_num):\n        douban.set_channel(channel_num)\n        self.empty()\n        if channel_num != 2:\n            self._get_first_song()", "response": "set_channel - Set the channel number of the current douban"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a song from the cache", "response": "def get_song(self, netease=False):\n        \"\"\"\n        \u83b7\u53d6\u6b4c\u66f2, \u5bf9\u5916\u7edf\u4e00\u63a5\u53e3\n        \"\"\"\n        song = self._playlist.get(True)\n        self.hash_sid[song['sid']] = True  # \u53bb\u91cd\n        self.get_netease_song(song, netease)  # \u5224\u65ad\u662f\u5426\u7f51\u6613320k\n        self._playingsong = song\n\n        return song"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate the display lines for the current page.", "response": "def make_display_lines(self):\n        \"\"\"\n        \u751f\u6210\u8f93\u51fa\u884c\n\n        \u6ce8\u610f: \u591a\u7ebf\u7a0b\u7ec8\u7aef\u540c\u65f6\u8f93\u51fa\u4f1a\u6709bug, \u5bfc\u81f4\u8d77\u59cb\u4f4d\u7f6e\u504f\u79fb, \u9700\u8981\u5728\u6bcf\u884c\u52a0\\r\n        \"\"\"\n        self.screen_height, self.screen_width = self.linesnum()  # \u5c4f\u5e55\u663e\u793a\u884c\u6570\n\n        display_lines = ['\\r']\n        display_lines.append(self._title + '\\r')\n\n        top = self.topline\n        bottom = self.topline + self.screen_height - 3\n\n        for index, i in enumerate(self._lines[top:bottom]):\n            # \u7bad\u5934\u6307\u5411\n            if index == self.markline:\n                prefix = self._prefix_selected\n                i = color_func(self.c['LINE']['highlight'])(i)\n            else:\n                prefix = self._prefix_deselected\n            # \u9009\u62e9\u9891\u9053\n            if index + self.topline == self.displayline:\n                suffix = self._suffix_selected\n            else:\n                suffix = self._suffix_deselected\n            line = '%s %s %s' % (prefix, i, suffix)\n            line = color_func(self.c['LINE']['line'])(line)\n\n            display_lines.append(line + '\\r')\n\n        return_num = self.screen_height - 3 - len(self._lines)\n        for _ in range(return_num):\n            display_lines.append('\\r')\n        self.display_lines = display_lines"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend a notification to the user.", "response": "def send_notification(title=\"Douban.fm\", content=\"\", cover_file=None):\n    '''\u53d1\u9001\u684c\u9762\u901a\u77e5'''\n    if PLATFORM == 'Linux':\n        send_Linux_notify(title, content, cover_file)\n    elif PLATFORM == 'Darwin':\n        send_OS_X_notify(title, content, cover_file)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send_OS_X_notify(title, content, img_path):\n    '''\u53d1\u9001Mac\u684c\u9762\u901a\u77e5'''\n    try:\n        from Foundation import (\n            NSDate, NSUserNotification, NSUserNotificationCenter)\n        from AppKit import NSImage\n        import objc\n    except ImportError:\n        logger.info('failed to init OSX notify!')\n        return\n\n    def swizzle(cls, SEL, func):\n        old_IMP = getattr(cls, SEL, None)\n\n        if old_IMP is None:\n            old_IMP = cls.instanceMethodForSelector_(SEL)\n\n        def wrapper(self, *args, **kwargs):\n            return func(self, old_IMP, *args, **kwargs)\n        new_IMP = objc.selector(wrapper, selector=old_IMP.selector,\n                                signature=old_IMP.signature)\n        objc.classAddMethod(cls, SEL.encode(), new_IMP)\n\n    def swizzled_bundleIdentifier(self, original):\n        # Use iTunes icon for notification\n        return 'com.apple.itunes'\n\n    swizzle(objc.lookUpClass('NSBundle'),\n            'bundleIdentifier',\n            swizzled_bundleIdentifier)\n    notification = NSUserNotification.alloc().init()\n\n    notification.setTitle_(title)\n    notification.setSubtitle_(content)\n    notification.setInformativeText_('')\n    notification.setUserInfo_({})\n    if img_path is not None:\n        image = NSImage.alloc().initWithContentsOfFile_(img_path)\n        # notification.setContentImage_(image)\n        notification.set_identityImage_(image)\n    notification.setDeliveryDate_(\n        NSDate.dateWithTimeInterval_sinceDate_(0, NSDate.date())\n    )\n    NSUserNotificationCenter.defaultUserNotificationCenter().\\\n        scheduleNotification_(notification)\n    logger.info('send notify success!')", "response": "Send OS X notification to the server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_pic(self, playingsong, tempfile_path):\n        '''\u83b7\u53d6\u4e13\u8f91\u5c01\u9762'''\n        url = playingsong['picture'].replace('\\\\', '')\n        for _ in range(3):\n            try:\n                urllib.urlretrieve(url, tempfile_path)\n                logger.debug('Get cover art success!')\n                return True\n            except (IOError, urllib.ContentTooShortError):\n                pass\n        logger.error('Get cover art failed!')\n        return False", "response": "Get the picture from the playing song and save it to a temporary file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef init_notification(self, playingsong):\n        '''\u7b2c\u4e00\u6b21\u684c\u9762\u901a\u77e5\u65f6\u52a0\u5165\u56fe\u7247'''\n\n        logger.debug('init_notification')\n\n        old_title = playingsong['title']\n        self.cover_file = tempfile.NamedTemporaryFile(\n            suffix='.jpg', dir=self._tempdir)\n        if not self.get_pic(playingsong, self.cover_file.name):\n            return\n        title = playingsong['title']\n        if old_title != title:\n            # \u5df2\u5207\u6362\u81f3\u4e0b\u4e00\u9996\u6b4c\n            return\n        self.has_cover = True\n        content = playingsong['artist'] + ' - ' + playingsong['albumtitle']\n        send_notification(title.decode('utf-8'),\n                          content.decode('utf-8'),\n                          self.cover_file.name)", "response": "init_notification - inits the cover file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsending a notification to the user.", "response": "def send_notify(self, playingsong, content=''):\n        '''\u9700\u8981\u89e3\u7801\u4e00\u4e0b,\u901a\u77e5\u9700\u8981unicode\u7f16\u7801'''\n        title = playingsong['title'].decode('utf-8')\n        content = content.decode('utf-8')\n        if title == self.title:\n            if self.has_cover:\n                send_notification(self.title, content, self.cover_file.name)\n            else:\n                send_notification(self.title, content)\n        else:\n            self.init_notification(playingsong)\n            self.title = title"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_time(self, time):\n        rest_time = int(self.song_total_time) - self.time - 1\n        minute = int(rest_time) / 60\n        sec = int(rest_time) % 60\n\n        return str(minute).zfill(2) + ':' + str(sec).zfill(2)", "response": "set time to the current time"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlogin to the win", "response": "def win_login():\n    \"\"\"\u767b\u9646\u754c\u9762\"\"\"\n    email = input(EMAIL_INFO)\n    password = getpass.getpass(PASS_INFO)\n    captcha_id = get_captcha_id()\n    get_capthca_pic(captcha_id)\n    file = '/tmp/captcha_pic.jpg'\n    try:\n        from subprocess import call\n        from os.path import expanduser\n        call([expanduser('~') + '/.iterm2/imgcat', file])\n    except:\n        import webbrowser\n        webbrowser.open('file://' + file)\n    captcha_solution = input(CAPTCHA_INFO)\n    return email, password, captcha_solution, captcha_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef request_token():\n    while True:\n        email, password, captcha_solution, captcha_id = win_login()\n        options = {\n            'source': 'radio',\n            'alias': email,\n            'form_password': password,\n            'captcha_solution': captcha_solution,\n            'captcha_id': captcha_id,\n            'task': 'sync_channel_list'\n        }\n        r = requests.post('https://douban.fm/j/login', data=options, headers=HEADERS)\n        req_json = json.loads(r.text, object_hook=decode_dict)\n        # req_json = json.loads(r.text)\n        if req_json['r'] == 0:\n            post_data = {\n                # will not save\n                'liked': req_json['user_info']['play_record']['liked'],\n                'banned': req_json['user_info']['play_record']['banned'],\n                'played': req_json['user_info']['play_record']['played'],\n                'is_pro': req_json['user_info']['is_pro'],\n                'user_name': req_json['user_info']['name'],\n\n                # to save\n                'cookies': r.cookies,\n                'valume': 50,\n                'channel': 0,\n                'theme_id': 0\n            }\n            return post_data\n\n        print(req_json['err_msg'])\n        print(ERROR + req_json['err_msg'])", "response": "Request a token from Douban."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_song(self):\n        if self.playingsong:\n            playingsong = copy.deepcopy(self.playingsong)\n            rate_times = self.rate_times\n            logger.info(playingsong['title'])\n            self.after_play(playingsong, rate_times)\n        self.playingsong = self.data.get_song()\n        self.rate_times = 0\n        return self.playingsong", "response": "get_song - Get a new Song object"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_url(self):\n        '''\u6253\u5f00\u8c46\u74e3\u7f51\u9875'''\n        import webbrowser\n        url = \"http://music.douban.com\" + \\\n            self.data.playingsong['album'].replace('\\/', '/')\n        webbrowser.open(url)", "response": "set url to play"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsearch the Music Day of Alerting", "response": "def search(self, song_title, limit=1):\n        \"\"\"\n        \u6839\u636e\u6b4c\u66f2\u540d\u641c\u7d22\u6b4c\u66f2\n\n        : params : song_title: \u6b4c\u66f2\u540d\n                   limit: \u641c\u7d22\u6570\u91cf\n        \"\"\"\n        url = \"http://music.163.com/api/search/pc\"\n        headers = {'Cookie': 'appver=1.5.2',\n                   'Referer': 'http://music.163.com'}\n        payload = {'s': song_title,\n                   'limit': limit,\n                   'type': 1}\n\n        r = requests.post(url, params=payload, headers=headers)\n        data = json.loads(r.text)\n\n        if data['code'] == 200:\n            return data['result']['songs'][0]\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_url_and_bitrate(self, song_title):\n        song_id, bitrate = self.get_song_id(song_title)\n        url = 'http://m1.music.126.net/'\n        if song_id:\n            url += self.encrypted_id(song_id) + '/' + str(song_id) + '.mp3'\n            bitrate = str(bitrate/1000)\n            return url, bitrate\n        else:\n            return None, None", "response": "Get url and bitrate from song title"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run(self):\n        '''\u754c\u9762\u6267\u884c\u7a0b\u5e8f'''\n        while True:\n            self.display()\n            c = getch.getch()\n            if c == self.KEYS['UP'] or c == 'A' and self.markline != 1:\n                self.updown(-1)\n            elif c == self.KEYS['DOWN'] or c == 'B':\n                self.updown(1)\n            elif c == self.KEYS['QUIT']:\n                self.win.state = 0\n                break\n            elif c == ' ':\n                self.playsong()\n            elif c == self.KEYS['TOP']:      # g\u952e\u8fd4\u56de\u9876\u90e8\n                self.markline = 1\n                self.topline = 0\n            elif c == self.KEYS['BOTTOM']:   # G\u952e\u8fd4\u56de\u5e95\u90e8\n                if len(self.lines) < self.screen_height:\n                    self.markline = len(self.lines) - 1\n                else:\n                    self.markline = self.screen_height\n                    self.topline = len(self.lines) - self.screen_height - 1\n            elif c == 'h' or c == 'D':\n                self.state -= 1 if self.state != 0 else -2\n                self.get_lines()\n            elif c == 'l' or c == 'C':\n                self.state += 1 if self.state != 2 else -2\n                self.get_lines()", "response": "A thread that runs the main loop of the main loop."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_dict(data, ctx):\n\n        data = data.copy()\n\n        if data.get('price') is not None:\n            data['price'] = ctx.convert_decimal_number(\n                data.get('price')\n            )\n\n        if data.get('initialUnits') is not None:\n            data['initialUnits'] = ctx.convert_decimal_number(\n                data.get('initialUnits')\n            )\n\n        if data.get('initialMarginRequired') is not None:\n            data['initialMarginRequired'] = ctx.convert_decimal_number(\n                data.get('initialMarginRequired')\n            )\n\n        if data.get('currentUnits') is not None:\n            data['currentUnits'] = ctx.convert_decimal_number(\n                data.get('currentUnits')\n            )\n\n        if data.get('realizedPL') is not None:\n            data['realizedPL'] = ctx.convert_decimal_number(\n                data.get('realizedPL')\n            )\n\n        if data.get('unrealizedPL') is not None:\n            data['unrealizedPL'] = ctx.convert_decimal_number(\n                data.get('unrealizedPL')\n            )\n\n        if data.get('marginUsed') is not None:\n            data['marginUsed'] = ctx.convert_decimal_number(\n                data.get('marginUsed')\n            )\n\n        if data.get('averageClosePrice') is not None:\n            data['averageClosePrice'] = ctx.convert_decimal_number(\n                data.get('averageClosePrice')\n            )\n\n\n        if data.get('financing') is not None:\n            data['financing'] = ctx.convert_decimal_number(\n                data.get('financing')\n            )\n\n        if data.get('clientExtensions') is not None:\n            data['clientExtensions'] = \\\n                ctx.transaction.ClientExtensions.from_dict(\n                    data['clientExtensions'], ctx\n                )\n\n        if data.get('takeProfitOrder') is not None:\n            data['takeProfitOrder'] = \\\n                ctx.order.TakeProfitOrder.from_dict(\n                    data['takeProfitOrder'], ctx\n                )\n\n        if data.get('stopLossOrder') is not None:\n            data['stopLossOrder'] = \\\n                ctx.order.StopLossOrder.from_dict(\n                    data['stopLossOrder'], ctx\n                )\n\n        if data.get('trailingStopLossOrder') is not None:\n            data['trailingStopLossOrder'] = \\\n                ctx.order.TrailingStopLossOrder.from_dict(\n                    data['trailingStopLossOrder'], ctx\n                )\n\n        return Trade(**data)", "response": "Instantiate a new Trade from a dict."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate replace and cancel a Trade s dependent Orders through the Account", "response": "def set_dependent_orders(\n        self,\n        accountID,\n        tradeSpecifier,\n        **kwargs\n    ):\n        \"\"\"\n        Create, replace and cancel a Trade's dependent Orders (Take Profit,\n        Stop Loss and Trailing Stop Loss) through the Trade itself\n\n        Args:\n            accountID:\n                Account Identifier\n            tradeSpecifier:\n                Specifier for the Trade\n            takeProfit:\n                The specification of the Take Profit to create/modify/cancel.\n                If takeProfit is set to null, the Take Profit Order will be\n                cancelled if it exists. If takeProfit is not provided, the\n                exisiting Take Profit Order will not be modified. If a sub-\n                field of takeProfit is not specified, that field will be set to\n                a default value on create, and be inherited by the replacing\n                order on modify.\n            stopLoss:\n                The specification of the Stop Loss to create/modify/cancel. If\n                stopLoss is set to null, the Stop Loss Order will be cancelled\n                if it exists. If stopLoss is not provided, the exisiting Stop\n                Loss Order will not be modified. If a sub-field of stopLoss is\n                not specified, that field will be set to a default value on\n                create, and be inherited by the replacing order on modify.\n            trailingStopLoss:\n                The specification of the Trailing Stop Loss to\n                create/modify/cancel. If trailingStopLoss is set to null, the\n                Trailing Stop Loss Order will be cancelled if it exists. If\n                trailingStopLoss is not provided, the exisiting Trailing Stop\n                Loss Order will not be modified. If a sub-field of\n                trailngStopLoss is not specified, that field will be set to a\n                default value on create, and be inherited by the replacing\n                order on modify.\n\n        Returns:\n            v20.response.Response containing the results from submitting the\n            request\n        \"\"\"\n\n        request = Request(\n            'PUT',\n            '/v3/accounts/{accountID}/trades/{tradeSpecifier}/orders'\n        )\n\n        request.set_path_param(\n            'accountID',\n            accountID\n        )\n\n        request.set_path_param(\n            'tradeSpecifier',\n            tradeSpecifier\n        )\n\n        body = EntityDict()\n\n        if 'takeProfit' in kwargs:\n            body.set('takeProfit', kwargs['takeProfit'])\n\n        if 'stopLoss' in kwargs:\n            body.set('stopLoss', kwargs['stopLoss'])\n\n        if 'trailingStopLoss' in kwargs:\n            body.set('trailingStopLoss', kwargs['trailingStopLoss'])\n\n        request.set_body_dict(body.dict)\n\n        response = self.ctx.request(request)\n\n\n        if response.content_type is None:\n            return response\n\n        if not response.content_type.startswith(\"application/json\"):\n            return response\n\n        jbody = json.loads(response.raw_body)\n\n        parsed_body = {}\n\n        #\n        # Parse responses as defined by the API specification\n        #\n        if str(response.status) == \"200\":\n            if jbody.get('takeProfitOrderCancelTransaction') is not None:\n                parsed_body['takeProfitOrderCancelTransaction'] = \\\n                    self.ctx.transaction.OrderCancelTransaction.from_dict(\n                        jbody['takeProfitOrderCancelTransaction'],\n                        self.ctx\n                    )\n\n            if jbody.get('takeProfitOrderTransaction') is not None:\n                parsed_body['takeProfitOrderTransaction'] = \\\n                    self.ctx.transaction.TakeProfitOrderTransaction.from_dict(\n                        jbody['takeProfitOrderTransaction'],\n                        self.ctx\n                    )\n\n            if jbody.get('takeProfitOrderFillTransaction') is not None:\n                parsed_body['takeProfitOrderFillTransaction'] = \\\n                    self.ctx.transaction.OrderFillTransaction.from_dict(\n                        jbody['takeProfitOrderFillTransaction'],\n                        self.ctx\n                    )\n\n            if jbody.get('takeProfitOrderCreatedCancelTransaction') is not None:\n                parsed_body['takeProfitOrderCreatedCancelTransaction'] = \\\n                    self.ctx.transaction.OrderCancelTransaction.from_dict(\n                        jbody['takeProfitOrderCreatedCancelTransaction'],\n                        self.ctx\n                    )\n\n            if jbody.get('stopLossOrderCancelTransaction') is not None:\n                parsed_body['stopLossOrderCancelTransaction'] = \\\n                    self.ctx.transaction.OrderCancelTransaction.from_dict(\n                        jbody['stopLossOrderCancelTransaction'],\n                        self.ctx\n                    )\n\n            if jbody.get('stopLossOrderTransaction') is not None:\n                parsed_body['stopLossOrderTransaction'] = \\\n                    self.ctx.transaction.StopLossOrderTransaction.from_dict(\n                        jbody['stopLossOrderTransaction'],\n                        self.ctx\n                    )\n\n            if jbody.get('stopLossOrderFillTransaction') is not None:\n                parsed_body['stopLossOrderFillTransaction'] = \\\n                    self.ctx.transaction.OrderFillTransaction.from_dict(\n                        jbody['stopLossOrderFillTransaction'],\n                        self.ctx\n                    )\n\n            if jbody.get('stopLossOrderCreatedCancelTransaction') is not None:\n                parsed_body['stopLossOrderCreatedCancelTransaction'] = \\\n                    self.ctx.transaction.OrderCancelTransaction.from_dict(\n                        jbody['stopLossOrderCreatedCancelTransaction'],\n                        self.ctx\n                    )\n\n            if jbody.get('trailingStopLossOrderCancelTransaction') is not None:\n                parsed_body['trailingStopLossOrderCancelTransaction'] = \\\n                    self.ctx.transaction.OrderCancelTransaction.from_dict(\n                        jbody['trailingStopLossOrderCancelTransaction'],\n                        self.ctx\n                    )\n\n            if jbody.get('trailingStopLossOrderTransaction') is not None:\n                parsed_body['trailingStopLossOrderTransaction'] = \\\n                    self.ctx.transaction.TrailingStopLossOrderTransaction.from_dict(\n                        jbody['trailingStopLossOrderTransaction'],\n                        self.ctx\n                    )\n\n            if jbody.get('relatedTransactionIDs') is not None:\n                parsed_body['relatedTransactionIDs'] = \\\n                    jbody.get('relatedTransactionIDs')\n\n            if jbody.get('lastTransactionID') is not None:\n                parsed_body['lastTransactionID'] = \\\n                    jbody.get('lastTransactionID')\n\n        elif str(response.status) == \"400\":\n            if jbody.get('takeProfitOrderCancelRejectTransaction') is not None:\n                parsed_body['takeProfitOrderCancelRejectTransaction'] = \\\n                    self.ctx.transaction.OrderCancelRejectTransaction.from_dict(\n                        jbody['takeProfitOrderCancelRejectTransaction'],\n                        self.ctx\n                    )\n\n            if jbody.get('takeProfitOrderRejectTransaction') is not None:\n                parsed_body['takeProfitOrderRejectTransaction'] = \\\n                    self.ctx.transaction.TakeProfitOrderRejectTransaction.from_dict(\n                        jbody['takeProfitOrderRejectTransaction'],\n                        self.ctx\n                    )\n\n            if jbody.get('stopLossOrderCancelRejectTransaction') is not None:\n                parsed_body['stopLossOrderCancelRejectTransaction'] = \\\n                    self.ctx.transaction.OrderCancelRejectTransaction.from_dict(\n                        jbody['stopLossOrderCancelRejectTransaction'],\n                        self.ctx\n                    )\n\n            if jbody.get('stopLossOrderRejectTransaction') is not None:\n                parsed_body['stopLossOrderRejectTransaction'] = \\\n                    self.ctx.transaction.StopLossOrderRejectTransaction.from_dict(\n                        jbody['stopLossOrderRejectTransaction'],\n                        self.ctx\n                    )\n\n            if jbody.get('trailingStopLossOrderCancelRejectTransaction') is not None:\n                parsed_body['trailingStopLossOrderCancelRejectTransaction'] = \\\n                    self.ctx.transaction.OrderCancelRejectTransaction.from_dict(\n                        jbody['trailingStopLossOrderCancelRejectTransaction'],\n                        self.ctx\n                    )\n\n            if jbody.get('trailingStopLossOrderRejectTransaction') is not None:\n                parsed_body['trailingStopLossOrderRejectTransaction'] = \\\n                    self.ctx.transaction.TrailingStopLossOrderRejectTransaction.from_dict(\n                        jbody['trailingStopLossOrderRejectTransaction'],\n                        self.ctx\n                    )\n\n            if jbody.get('lastTransactionID') is not None:\n                parsed_body['lastTransactionID'] = \\\n                    jbody.get('lastTransactionID')\n\n            if jbody.get('relatedTransactionIDs') is not None:\n                parsed_body['relatedTransactionIDs'] = \\\n                    jbody.get('relatedTransactionIDs')\n\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        elif str(response.status) == \"401\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        elif str(response.status) == \"404\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        elif str(response.status) == \"405\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        #\n        # Unexpected response status\n        #\n        else:\n            parsed_body = jbody\n\n        response.body = parsed_body\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_dict(data, ctx):\n\n        data = data.copy()\n\n        if data.get('marginRate') is not None:\n            data['marginRate'] = ctx.convert_decimal_number(\n                data.get('marginRate')\n            )\n\n        return ClientConfigureTransaction(**data)", "response": "Instantiate a new ClientConfigureTransaction from a dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_dict(data, ctx):\n\n        data = data.copy()\n\n        if data.get('amount') is not None:\n            data['amount'] = ctx.convert_decimal_number(\n                data.get('amount')\n            )\n\n        if data.get('accountBalance') is not None:\n            data['accountBalance'] = ctx.convert_decimal_number(\n                data.get('accountBalance')\n            )\n\n        return TransferFundsTransaction(**data)", "response": "Instantiate a TransferFundsTransaction from a dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_dict(data, ctx):\n\n        data = data.copy()\n\n        if data.get('amount') is not None:\n            data['amount'] = ctx.convert_decimal_number(\n                data.get('amount')\n            )\n\n        return TransferFundsRejectTransaction(**data)", "response": "Instantiate a TransferFundsRejectTransaction from a dict."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_dict(data, ctx):\n\n        data = data.copy()\n\n        if data.get('units') is not None:\n            data['units'] = ctx.convert_decimal_number(\n                data.get('units')\n            )\n\n        if data.get('gainQuoteHomeConversionFactor') is not None:\n            data['gainQuoteHomeConversionFactor'] = ctx.convert_decimal_number(\n                data.get('gainQuoteHomeConversionFactor')\n            )\n\n        if data.get('lossQuoteHomeConversionFactor') is not None:\n            data['lossQuoteHomeConversionFactor'] = ctx.convert_decimal_number(\n                data.get('lossQuoteHomeConversionFactor')\n            )\n\n        if data.get('price') is not None:\n            data['price'] = ctx.convert_decimal_number(\n                data.get('price')\n            )\n\n        if data.get('fullVWAP') is not None:\n            data['fullVWAP'] = ctx.convert_decimal_number(\n                data.get('fullVWAP')\n            )\n\n        if data.get('fullPrice') is not None:\n            data['fullPrice'] = \\\n                ctx.pricing.ClientPrice.from_dict(\n                    data['fullPrice'], ctx\n                )\n\n        if data.get('pl') is not None:\n            data['pl'] = ctx.convert_decimal_number(\n                data.get('pl')\n            )\n\n        if data.get('financing') is not None:\n            data['financing'] = ctx.convert_decimal_number(\n                data.get('financing')\n            )\n\n        if data.get('commission') is not None:\n            data['commission'] = ctx.convert_decimal_number(\n                data.get('commission')\n            )\n\n        if data.get('guaranteedExecutionFee') is not None:\n            data['guaranteedExecutionFee'] = ctx.convert_decimal_number(\n                data.get('guaranteedExecutionFee')\n            )\n\n        if data.get('accountBalance') is not None:\n            data['accountBalance'] = ctx.convert_decimal_number(\n                data.get('accountBalance')\n            )\n\n        if data.get('tradeOpened') is not None:\n            data['tradeOpened'] = \\\n                ctx.transaction.TradeOpen.from_dict(\n                    data['tradeOpened'], ctx\n                )\n\n        if data.get('tradesClosed') is not None:\n            data['tradesClosed'] = [\n                ctx.transaction.TradeReduce.from_dict(d, ctx)\n                for d in data.get('tradesClosed')\n            ]\n\n        if data.get('tradeReduced') is not None:\n            data['tradeReduced'] = \\\n                ctx.transaction.TradeReduce.from_dict(\n                    data['tradeReduced'], ctx\n                )\n\n        if data.get('halfSpreadCost') is not None:\n            data['halfSpreadCost'] = ctx.convert_decimal_number(\n                data.get('halfSpreadCost')\n            )\n\n        return OrderFillTransaction(**data)", "response": "Instantiate a new OrderFillTransaction from a dict."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_dict(data, ctx):\n\n        data = data.copy()\n\n        if data.get('clientExtensionsModify') is not None:\n            data['clientExtensionsModify'] = \\\n                ctx.transaction.ClientExtensions.from_dict(\n                    data['clientExtensionsModify'], ctx\n                )\n\n        if data.get('tradeClientExtensionsModify') is not None:\n            data['tradeClientExtensionsModify'] = \\\n                ctx.transaction.ClientExtensions.from_dict(\n                    data['tradeClientExtensionsModify'], ctx\n                )\n\n        return OrderClientExtensionsModifyRejectTransaction(**data)", "response": "Instantiate a new OrderClientExtensionsModifyRejectTransaction from a dict."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_dict(data, ctx):\n\n        data = data.copy()\n\n        if data.get('tradeClientExtensionsModify') is not None:\n            data['tradeClientExtensionsModify'] = \\\n                ctx.transaction.ClientExtensions.from_dict(\n                    data['tradeClientExtensionsModify'], ctx\n                )\n\n        return TradeClientExtensionsModifyTransaction(**data)", "response": "Instantiate a TradeClientExtensionsModifyTransaction from a dict."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_dict(data, ctx):\n\n        data = data.copy()\n\n        if data.get('units') is not None:\n            data['units'] = ctx.convert_decimal_number(\n                data.get('units')\n            )\n\n        if data.get('price') is not None:\n            data['price'] = ctx.convert_decimal_number(\n                data.get('price')\n            )\n\n        if data.get('guaranteedExecutionFee') is not None:\n            data['guaranteedExecutionFee'] = ctx.convert_decimal_number(\n                data.get('guaranteedExecutionFee')\n            )\n\n        if data.get('clientExtensions') is not None:\n            data['clientExtensions'] = \\\n                ctx.transaction.ClientExtensions.from_dict(\n                    data['clientExtensions'], ctx\n                )\n\n        if data.get('halfSpreadCost') is not None:\n            data['halfSpreadCost'] = ctx.convert_decimal_number(\n                data.get('halfSpreadCost')\n            )\n\n        if data.get('initialMarginRequired') is not None:\n            data['initialMarginRequired'] = ctx.convert_decimal_number(\n                data.get('initialMarginRequired')\n            )\n\n        return TradeOpen(**data)", "response": "Instantiate a TradeOpen from a dict."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_dict(data, ctx):\n\n        data = data.copy()\n\n        if data.get('units') is not None:\n            data['units'] = ctx.convert_decimal_number(\n                data.get('units')\n            )\n\n        if data.get('price') is not None:\n            data['price'] = ctx.convert_decimal_number(\n                data.get('price')\n            )\n\n        if data.get('realizedPL') is not None:\n            data['realizedPL'] = ctx.convert_decimal_number(\n                data.get('realizedPL')\n            )\n\n        if data.get('financing') is not None:\n            data['financing'] = ctx.convert_decimal_number(\n                data.get('financing')\n            )\n\n        if data.get('guaranteedExecutionFee') is not None:\n            data['guaranteedExecutionFee'] = ctx.convert_decimal_number(\n                data.get('guaranteedExecutionFee')\n            )\n\n        if data.get('halfSpreadCost') is not None:\n            data['halfSpreadCost'] = ctx.convert_decimal_number(\n                data.get('halfSpreadCost')\n            )\n\n        return TradeReduce(**data)", "response": "Instantiate a new TradeReduce from a dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_dict(data, ctx):\n\n        data = data.copy()\n\n        if data.get('bidLiquidityUsed') is not None:\n            data['bidLiquidityUsed'] = ctx.convert_decimal_number(\n                data.get('bidLiquidityUsed')\n            )\n\n        if data.get('askLiquidityUsed') is not None:\n            data['askLiquidityUsed'] = ctx.convert_decimal_number(\n                data.get('askLiquidityUsed')\n            )\n\n        return LiquidityRegenerationScheduleStep(**data)", "response": "Instantiate a LiquidityRegenerationScheduleStep from a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_dict(data, ctx):\n\n        data = data.copy()\n\n        if data.get('financing') is not None:\n            data['financing'] = ctx.convert_decimal_number(\n                data.get('financing')\n            )\n\n        return OpenTradeFinancing(**data)", "response": "Instantiate an OpenTradeFinancing object from a dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_dict(data, ctx):\n\n        data = data.copy()\n\n        if data.get('financing') is not None:\n            data['financing'] = ctx.convert_decimal_number(\n                data.get('financing')\n            )\n\n        if data.get('openTradeFinancings') is not None:\n            data['openTradeFinancings'] = [\n                ctx.transaction.OpenTradeFinancing.from_dict(d, ctx)\n                for d in data.get('openTradeFinancings')\n            ]\n\n        return PositionFinancing(**data)", "response": "Instantiate a new PositionFinancing object from a dict."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a list of Transactions pages that satisfy a time-based Transaction query. Args: accountID: Account Identifier fromTime: The starting time (inclusive) of the time range for the Transactions being queried. toTime: The ending time (inclusive) of the time range for the Transactions being queried. pageSize: The number of Transactions to include in each page of the results. type: A filter for restricting the types of Transactions to retreive. Returns: v20.response.Response containing the results from submitting the request", "response": "def list(\n        self,\n        accountID,\n        **kwargs\n    ):\n        \"\"\"\n        Get a list of Transactions pages that satisfy a time-based Transaction\n        query.\n\n        Args:\n            accountID:\n                Account Identifier\n            fromTime:\n                The starting time (inclusive) of the time range for the\n                Transactions being queried.\n            toTime:\n                The ending time (inclusive) of the time range for the\n                Transactions being queried.\n            pageSize:\n                The number of Transactions to include in each page of the\n                results.\n            type:\n                A filter for restricting the types of Transactions to retreive.\n\n        Returns:\n            v20.response.Response containing the results from submitting the\n            request\n        \"\"\"\n\n        request = Request(\n            'GET',\n            '/v3/accounts/{accountID}/transactions'\n        )\n\n        request.set_path_param(\n            'accountID',\n            accountID\n        )\n\n        request.set_param(\n            'from',\n            kwargs.get('fromTime')\n        )\n\n        request.set_param(\n            'to',\n            kwargs.get('toTime')\n        )\n\n        request.set_param(\n            'pageSize',\n            kwargs.get('pageSize')\n        )\n\n        request.set_param(\n            'type',\n            kwargs.get('type')\n        )\n\n        response = self.ctx.request(request)\n\n\n        if response.content_type is None:\n            return response\n\n        if not response.content_type.startswith(\"application/json\"):\n            return response\n\n        jbody = json.loads(response.raw_body)\n\n        parsed_body = {}\n\n        #\n        # Parse responses as defined by the API specification\n        #\n        if str(response.status) == \"200\":\n            if jbody.get('from') is not None:\n                parsed_body['from'] = \\\n                    jbody.get('from')\n\n            if jbody.get('to') is not None:\n                parsed_body['to'] = \\\n                    jbody.get('to')\n\n            if jbody.get('pageSize') is not None:\n                parsed_body['pageSize'] = \\\n                    jbody.get('pageSize')\n\n            if jbody.get('type') is not None:\n                parsed_body['type'] = \\\n                    jbody.get('type')\n\n            if jbody.get('count') is not None:\n                parsed_body['count'] = \\\n                    jbody.get('count')\n\n            if jbody.get('pages') is not None:\n                parsed_body['pages'] = \\\n                    jbody.get('pages')\n\n            if jbody.get('lastTransactionID') is not None:\n                parsed_body['lastTransactionID'] = \\\n                    jbody.get('lastTransactionID')\n\n        elif str(response.status) == \"400\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        elif str(response.status) == \"401\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        elif str(response.status) == \"403\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        elif str(response.status) == \"404\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        elif str(response.status) == \"405\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        elif str(response.status) == \"416\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        #\n        # Unexpected response status\n        #\n        else:\n            parsed_body = jbody\n\n        response.body = parsed_body\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stream(\n        self,\n        accountID,\n        **kwargs\n    ):\n        \"\"\"\n        Get a stream of Transactions for an Account starting from when the\n        request is made.\n\n        Args:\n            accountID:\n                Account Identifier\n\n        Returns:\n            v20.response.Response containing the results from submitting the\n            request\n        \"\"\"\n\n        request = Request(\n            'GET',\n            '/v3/accounts/{accountID}/transactions/stream'\n        )\n\n        request.set_path_param(\n            'accountID',\n            accountID\n        )\n\n        request.set_stream(True)\n\n        class Parser():\n            def __init__(self, ctx):\n                self.ctx = ctx\n\n            def __call__(self, line):\n                j = json.loads(line.decode('utf-8'))\n\n                type = j.get(\"type\")\n\n                if type is None:\n                    return (\"unknown\", j)\n                elif type == \"HEARTBEAT\":\n                    return (\n                        \"transaction.TransactionHeartbeat\",\n                        self.ctx.transaction.TransactionHeartbeat.from_dict(\n                            j,\n                            self.ctx\n                        )\n                    )\n\n                transaction = self.ctx.transaction.Transaction.from_dict(\n                    j, self.ctx\n                )\n\n                return (\n                    \"transaction.Transaction\",\n                    transaction\n                )\n\n                \n        request.set_line_parser(\n            Parser(self.ctx)\n        )\n\n        response = self.ctx.request(request)\n\n\n        return response", "response": "Returns a stream of Transactions for an Account starting from when the request is made."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_dict(data, ctx):\n\n        data = data.copy()\n\n        if data.get('price') is not None:\n            data['price'] = ctx.convert_decimal_number(\n                data.get('price')\n            )\n\n        return PriceBucket(**data)", "response": "Instantiate a PriceBucket from a dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_dict(data, ctx):\n\n        data = data.copy()\n\n        if data.get('baseBid') is not None:\n            data['baseBid'] = ctx.convert_decimal_number(\n                data.get('baseBid')\n            )\n\n        if data.get('baseAsk') is not None:\n            data['baseAsk'] = ctx.convert_decimal_number(\n                data.get('baseAsk')\n            )\n\n        if data.get('bids') is not None:\n            data['bids'] = [\n                ctx.pricing_common.PriceBucket.from_dict(d, ctx)\n                for d in data.get('bids')\n            ]\n\n        if data.get('asks') is not None:\n            data['asks'] = [\n                ctx.pricing_common.PriceBucket.from_dict(d, ctx)\n                for d in data.get('asks')\n            ]\n\n        if data.get('closeoutBid') is not None:\n            data['closeoutBid'] = ctx.convert_decimal_number(\n                data.get('closeoutBid')\n            )\n\n        if data.get('closeoutAsk') is not None:\n            data['closeoutAsk'] = ctx.convert_decimal_number(\n                data.get('closeoutAsk')\n            )\n\n        return Price(**data)", "response": "Instantiate a new Price from a dict."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_dict(data, ctx):\n\n        data = data.copy()\n\n        if data.get('price') is not None:\n            data['price'] = ctx.convert_decimal_number(\n                data.get('price')\n            )\n\n        if data.get('bucketWidth') is not None:\n            data['bucketWidth'] = ctx.convert_decimal_number(\n                data.get('bucketWidth')\n            )\n\n        if data.get('buckets') is not None:\n            data['buckets'] = [\n                ctx.instrument.OrderBookBucket.from_dict(d, ctx)\n                for d in data.get('buckets')\n            ]\n\n        return OrderBook(**data)", "response": "Instantiate a new OrderBook from a dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_dict(data, ctx):\n\n        data = data.copy()\n\n        if data.get('price') is not None:\n            data['price'] = ctx.convert_decimal_number(\n                data.get('price')\n            )\n\n        if data.get('longCountPercent') is not None:\n            data['longCountPercent'] = ctx.convert_decimal_number(\n                data.get('longCountPercent')\n            )\n\n        if data.get('shortCountPercent') is not None:\n            data['shortCountPercent'] = ctx.convert_decimal_number(\n                data.get('shortCountPercent')\n            )\n\n        return OrderBookBucket(**data)", "response": "Instantiate a new OrderBookBucket from a dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_dict(data, ctx):\n\n        data = data.copy()\n\n        if data.get('price') is not None:\n            data['price'] = ctx.convert_decimal_number(\n                data.get('price')\n            )\n\n        if data.get('bucketWidth') is not None:\n            data['bucketWidth'] = ctx.convert_decimal_number(\n                data.get('bucketWidth')\n            )\n\n        if data.get('buckets') is not None:\n            data['buckets'] = [\n                ctx.instrument.PositionBookBucket.from_dict(d, ctx)\n                for d in data.get('buckets')\n            ]\n\n        return PositionBook(**data)", "response": "Instantiate a new PositionBook from a dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfetches candlestick data for an instrument. Args: instrument: Name of the Instrument price: The Price component(s) to get candlestick data for. Can contain any combination of the characters \"M\" (midpoint candles) \"B\" (bid candles) and \"A\" (ask candles). granularity: The granularity of the candlesticks to fetch count: The number of candlesticks to return in the reponse. Count should not be specified if both the start and end parameters are provided, as the time range combined with the graularity will determine the number of candlesticks to return. fromTime: The start of the time range to fetch candlesticks for. toTime: The end of the time range to fetch candlesticks for. smooth: A flag that controls whether the candlestick is \"smoothed\" or not. A smoothed candlestick uses the previous candle's close price as its open price, while an unsmoothed candlestick uses the first price from its time range as its open price. includeFirst: A flag that controls whether the candlestick that is covered by the from time should be included in the results. This flag enables clients to use the timestamp of the last completed candlestick received to poll for future candlesticks but avoid receiving the previous candlestick repeatedly. dailyAlignment: The hour of the day (in the specified timezone) to use for granularities that have daily alignments. alignmentTimezone: The timezone to use for the dailyAlignment parameter. Candlesticks with daily alignment will be aligned to the dailyAlignment hour within the alignmentTimezone. Note that the returned times will still be represented in UTC. weeklyAlignment: The day of the week used for granularities that have weekly alignment. Returns: v20.response.Response containing the results from submitting the request", "response": "def candles(\n        self,\n        instrument,\n        **kwargs\n    ):\n        \"\"\"\n        Fetch candlestick data for an instrument.\n\n        Args:\n            instrument:\n                Name of the Instrument\n            price:\n                The Price component(s) to get candlestick data for. Can contain\n                any combination of the characters \"M\" (midpoint candles) \"B\"\n                (bid candles) and \"A\" (ask candles).\n            granularity:\n                The granularity of the candlesticks to fetch\n            count:\n                The number of candlesticks to return in the reponse. Count\n                should not be specified if both the start and end parameters\n                are provided, as the time range combined with the graularity\n                will determine the number of candlesticks to return.\n            fromTime:\n                The start of the time range to fetch candlesticks for.\n            toTime:\n                The end of the time range to fetch candlesticks for.\n            smooth:\n                A flag that controls whether the candlestick is \"smoothed\" or\n                not.  A smoothed candlestick uses the previous candle's close\n                price as its open price, while an unsmoothed candlestick uses\n                the first price from its time range as its open price.\n            includeFirst:\n                A flag that controls whether the candlestick that is covered by\n                the from time should be included in the results. This flag\n                enables clients to use the timestamp of the last completed\n                candlestick received to poll for future candlesticks but avoid\n                receiving the previous candlestick repeatedly.\n            dailyAlignment:\n                The hour of the day (in the specified timezone) to use for\n                granularities that have daily alignments.\n            alignmentTimezone:\n                The timezone to use for the dailyAlignment parameter.\n                Candlesticks with daily alignment will be aligned to the\n                dailyAlignment hour within the alignmentTimezone.  Note that\n                the returned times will still be represented in UTC.\n            weeklyAlignment:\n                The day of the week used for granularities that have weekly\n                alignment.\n\n        Returns:\n            v20.response.Response containing the results from submitting the\n            request\n        \"\"\"\n\n        request = Request(\n            'GET',\n            '/v3/instruments/{instrument}/candles'\n        )\n\n        request.set_path_param(\n            'instrument',\n            instrument\n        )\n\n        request.set_param(\n            'price',\n            kwargs.get('price')\n        )\n\n        request.set_param(\n            'granularity',\n            kwargs.get('granularity')\n        )\n\n        request.set_param(\n            'count',\n            kwargs.get('count')\n        )\n\n        request.set_param(\n            'from',\n            kwargs.get('fromTime')\n        )\n\n        request.set_param(\n            'to',\n            kwargs.get('toTime')\n        )\n\n        request.set_param(\n            'smooth',\n            kwargs.get('smooth')\n        )\n\n        request.set_param(\n            'includeFirst',\n            kwargs.get('includeFirst')\n        )\n\n        request.set_param(\n            'dailyAlignment',\n            kwargs.get('dailyAlignment')\n        )\n\n        request.set_param(\n            'alignmentTimezone',\n            kwargs.get('alignmentTimezone')\n        )\n\n        request.set_param(\n            'weeklyAlignment',\n            kwargs.get('weeklyAlignment')\n        )\n\n        response = self.ctx.request(request)\n\n\n        if response.content_type is None:\n            return response\n\n        if not response.content_type.startswith(\"application/json\"):\n            return response\n\n        jbody = json.loads(response.raw_body)\n\n        parsed_body = {}\n\n        #\n        # Parse responses as defined by the API specification\n        #\n        if str(response.status) == \"200\":\n            if jbody.get('instrument') is not None:\n                parsed_body['instrument'] = \\\n                    jbody.get('instrument')\n\n            if jbody.get('granularity') is not None:\n                parsed_body['granularity'] = \\\n                    jbody.get('granularity')\n\n            if jbody.get('candles') is not None:\n                parsed_body['candles'] = [\n                    self.ctx.instrument.Candlestick.from_dict(d, self.ctx)\n                    for d in jbody.get('candles')\n                ]\n\n        elif str(response.status) == \"400\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        elif str(response.status) == \"401\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        elif str(response.status) == \"404\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        elif str(response.status) == \"405\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        #\n        # Unexpected response status\n        #\n        else:\n            parsed_body = jbody\n\n        response.body = parsed_body\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfetches a price for an instrument and time.", "response": "def price(\n        self,\n        instrument,\n        **kwargs\n    ):\n        \"\"\"\n        Fetch a price for an instrument. Accounts are not associated in any way\n        with this endpoint.\n\n        Args:\n            instrument:\n                Name of the Instrument\n            time:\n                The time at which the desired price is in effect. The current\n                price is returned if no time is provided.\n\n        Returns:\n            v20.response.Response containing the results from submitting the\n            request\n        \"\"\"\n\n        request = Request(\n            'GET',\n            '/v3/instruments/{instrument}/price'\n        )\n\n        request.set_path_param(\n            'instrument',\n            instrument\n        )\n\n        request.set_param(\n            'time',\n            kwargs.get('time')\n        )\n\n        response = self.ctx.request(request)\n\n\n        if response.content_type is None:\n            return response\n\n        if not response.content_type.startswith(\"application/json\"):\n            return response\n\n        jbody = json.loads(response.raw_body)\n\n        parsed_body = {}\n\n        #\n        # Parse responses as defined by the API specification\n        #\n        if str(response.status) == \"200\":\n            if jbody.get('price') is not None:\n                parsed_body['price'] = \\\n                    self.ctx.pricing_common.Price.from_dict(\n                        jbody['price'],\n                        self.ctx\n                    )\n\n        elif str(response.status) == \"400\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        elif str(response.status) == \"401\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        elif str(response.status) == \"404\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        elif str(response.status) == \"405\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        #\n        # Unexpected response status\n        #\n        else:\n            parsed_body = jbody\n\n        response.body = parsed_body\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_dict(data, ctx):\n\n        data = data.copy()\n\n        if data.get('units') is not None:\n            data['units'] = ctx.convert_decimal_number(\n                data.get('units')\n            )\n\n        if data.get('averagePrice') is not None:\n            data['averagePrice'] = ctx.convert_decimal_number(\n                data.get('averagePrice')\n            )\n\n\n        if data.get('pl') is not None:\n            data['pl'] = ctx.convert_decimal_number(\n                data.get('pl')\n            )\n\n        if data.get('unrealizedPL') is not None:\n            data['unrealizedPL'] = ctx.convert_decimal_number(\n                data.get('unrealizedPL')\n            )\n\n        if data.get('resettablePL') is not None:\n            data['resettablePL'] = ctx.convert_decimal_number(\n                data.get('resettablePL')\n            )\n\n        if data.get('financing') is not None:\n            data['financing'] = ctx.convert_decimal_number(\n                data.get('financing')\n            )\n\n        if data.get('guaranteedExecutionFees') is not None:\n            data['guaranteedExecutionFees'] = ctx.convert_decimal_number(\n                data.get('guaranteedExecutionFees')\n            )\n\n        return PositionSide(**data)", "response": "Instantiate a new PositionSide from a dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_dict(data, ctx):\n\n        data = data.copy()\n\n        if data.get('netUnrealizedPL') is not None:\n            data['netUnrealizedPL'] = ctx.convert_decimal_number(\n                data.get('netUnrealizedPL')\n            )\n\n        if data.get('longUnrealizedPL') is not None:\n            data['longUnrealizedPL'] = ctx.convert_decimal_number(\n                data.get('longUnrealizedPL')\n            )\n\n        if data.get('shortUnrealizedPL') is not None:\n            data['shortUnrealizedPL'] = ctx.convert_decimal_number(\n                data.get('shortUnrealizedPL')\n            )\n\n        if data.get('marginUsed') is not None:\n            data['marginUsed'] = ctx.convert_decimal_number(\n                data.get('marginUsed')\n            )\n\n        return CalculatedPositionState(**data)", "response": "Instantiate a new CalculatedPositionState from a dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_dict(data, ctx):\n\n        data = data.copy()\n\n        if data.get('trailingStopValue') is not None:\n            data['trailingStopValue'] = ctx.convert_decimal_number(\n                data.get('trailingStopValue')\n            )\n\n        if data.get('triggerDistance') is not None:\n            data['triggerDistance'] = ctx.convert_decimal_number(\n                data.get('triggerDistance')\n            )\n\n        return DynamicOrderState(**data)", "response": "Instantiate a DynamicOrderState from a dict."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_dict(data, ctx):\n\n        data = data.copy()\n\n        if data.get('price') is not None:\n            data['price'] = ctx.convert_decimal_number(\n                data.get('price')\n            )\n\n        if data.get('clientExtensions') is not None:\n            data['clientExtensions'] = \\\n                ctx.transaction.ClientExtensions.from_dict(\n                    data['clientExtensions'], ctx\n                )\n\n        return TakeProfitOrderRequest(**data)", "response": "Instantiate a TakeProfitOrderRequest from a dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a list of Orders for an Account", "response": "def list(\n        self,\n        accountID,\n        **kwargs\n    ):\n        \"\"\"\n        Get a list of Orders for an Account\n\n        Args:\n            accountID:\n                Account Identifier\n            ids:\n                List of Order IDs to retrieve\n            state:\n                The state to filter the requested Orders by\n            instrument:\n                The instrument to filter the requested orders by\n            count:\n                The maximum number of Orders to return\n            beforeID:\n                The maximum Order ID to return. If not provided the most recent\n                Orders in the Account are returned\n\n        Returns:\n            v20.response.Response containing the results from submitting the\n            request\n        \"\"\"\n\n        request = Request(\n            'GET',\n            '/v3/accounts/{accountID}/orders'\n        )\n\n        request.set_path_param(\n            'accountID',\n            accountID\n        )\n\n        request.set_param(\n            'ids',\n            kwargs.get('ids')\n        )\n\n        request.set_param(\n            'state',\n            kwargs.get('state')\n        )\n\n        request.set_param(\n            'instrument',\n            kwargs.get('instrument')\n        )\n\n        request.set_param(\n            'count',\n            kwargs.get('count')\n        )\n\n        request.set_param(\n            'beforeID',\n            kwargs.get('beforeID')\n        )\n\n        response = self.ctx.request(request)\n\n\n        if response.content_type is None:\n            return response\n\n        if not response.content_type.startswith(\"application/json\"):\n            return response\n\n        jbody = json.loads(response.raw_body)\n\n        parsed_body = {}\n\n        #\n        # Parse responses as defined by the API specification\n        #\n        if str(response.status) == \"200\":\n            if jbody.get('orders') is not None:\n                parsed_body['orders'] = [\n                    self.ctx.order.Order.from_dict(d, self.ctx)\n                    for d in jbody.get('orders')\n                ]\n\n            if jbody.get('lastTransactionID') is not None:\n                parsed_body['lastTransactionID'] = \\\n                    jbody.get('lastTransactionID')\n\n        elif str(response.status) == \"400\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        elif str(response.status) == \"404\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        elif str(response.status) == \"405\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        #\n        # Unexpected response status\n        #\n        else:\n            parsed_body = jbody\n\n        response.body = parsed_body\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreplaces an Order in an Account by simultaneously cancelling it and creating a replacement Order Args: accountID: Account Identifier orderSpecifier: The Order Specifier order: Specification of the replacing Order Returns: v20.response.Response containing the results from submitting the request", "response": "def replace(\n        self,\n        accountID,\n        orderSpecifier,\n        **kwargs\n    ):\n        \"\"\"\n        Replace an Order in an Account by simultaneously cancelling it and\n        creating a replacement Order\n\n        Args:\n            accountID:\n                Account Identifier\n            orderSpecifier:\n                The Order Specifier\n            order:\n                Specification of the replacing Order\n\n        Returns:\n            v20.response.Response containing the results from submitting the\n            request\n        \"\"\"\n\n        request = Request(\n            'PUT',\n            '/v3/accounts/{accountID}/orders/{orderSpecifier}'\n        )\n\n        request.set_path_param(\n            'accountID',\n            accountID\n        )\n\n        request.set_path_param(\n            'orderSpecifier',\n            orderSpecifier\n        )\n\n        body = EntityDict()\n\n        if 'order' in kwargs:\n            body.set('order', kwargs['order'])\n\n        request.set_body_dict(body.dict)\n\n        response = self.ctx.request(request)\n\n\n        if response.content_type is None:\n            return response\n\n        if not response.content_type.startswith(\"application/json\"):\n            return response\n\n        jbody = json.loads(response.raw_body)\n\n        parsed_body = {}\n\n        #\n        # Parse responses as defined by the API specification\n        #\n        if str(response.status) == \"201\":\n            if jbody.get('orderCancelTransaction') is not None:\n                parsed_body['orderCancelTransaction'] = \\\n                    self.ctx.transaction.OrderCancelTransaction.from_dict(\n                        jbody['orderCancelTransaction'],\n                        self.ctx\n                    )\n\n            if jbody.get('orderCreateTransaction') is not None:\n                parsed_body['orderCreateTransaction'] = \\\n                    self.ctx.transaction.Transaction.from_dict(\n                        jbody['orderCreateTransaction'],\n                        self.ctx\n                    )\n\n            if jbody.get('orderFillTransaction') is not None:\n                parsed_body['orderFillTransaction'] = \\\n                    self.ctx.transaction.OrderFillTransaction.from_dict(\n                        jbody['orderFillTransaction'],\n                        self.ctx\n                    )\n\n            if jbody.get('orderReissueTransaction') is not None:\n                parsed_body['orderReissueTransaction'] = \\\n                    self.ctx.transaction.Transaction.from_dict(\n                        jbody['orderReissueTransaction'],\n                        self.ctx\n                    )\n\n            if jbody.get('orderReissueRejectTransaction') is not None:\n                parsed_body['orderReissueRejectTransaction'] = \\\n                    self.ctx.transaction.Transaction.from_dict(\n                        jbody['orderReissueRejectTransaction'],\n                        self.ctx\n                    )\n\n            if jbody.get('replacingOrderCancelTransaction') is not None:\n                parsed_body['replacingOrderCancelTransaction'] = \\\n                    self.ctx.transaction.OrderCancelTransaction.from_dict(\n                        jbody['replacingOrderCancelTransaction'],\n                        self.ctx\n                    )\n\n            if jbody.get('relatedTransactionIDs') is not None:\n                parsed_body['relatedTransactionIDs'] = \\\n                    jbody.get('relatedTransactionIDs')\n\n            if jbody.get('lastTransactionID') is not None:\n                parsed_body['lastTransactionID'] = \\\n                    jbody.get('lastTransactionID')\n\n        elif str(response.status) == \"400\":\n            if jbody.get('orderRejectTransaction') is not None:\n                parsed_body['orderRejectTransaction'] = \\\n                    self.ctx.transaction.Transaction.from_dict(\n                        jbody['orderRejectTransaction'],\n                        self.ctx\n                    )\n\n            if jbody.get('relatedTransactionIDs') is not None:\n                parsed_body['relatedTransactionIDs'] = \\\n                    jbody.get('relatedTransactionIDs')\n\n            if jbody.get('lastTransactionID') is not None:\n                parsed_body['lastTransactionID'] = \\\n                    jbody.get('lastTransactionID')\n\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        elif str(response.status) == \"401\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        elif str(response.status) == \"404\":\n            if jbody.get('orderCancelRejectTransaction') is not None:\n                parsed_body['orderCancelRejectTransaction'] = \\\n                    self.ctx.transaction.Transaction.from_dict(\n                        jbody['orderCancelRejectTransaction'],\n                        self.ctx\n                    )\n\n            if jbody.get('relatedTransactionIDs') is not None:\n                parsed_body['relatedTransactionIDs'] = \\\n                    jbody.get('relatedTransactionIDs')\n\n            if jbody.get('lastTransactionID') is not None:\n                parsed_body['lastTransactionID'] = \\\n                    jbody.get('lastTransactionID')\n\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        elif str(response.status) == \"405\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        #\n        # Unexpected response status\n        #\n        else:\n            parsed_body = jbody\n\n        response.body = parsed_body\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncancel a pending order in an Account", "response": "def cancel(\n        self,\n        accountID,\n        orderSpecifier,\n        **kwargs\n    ):\n        \"\"\"\n        Cancel a pending Order in an Account\n\n        Args:\n            accountID:\n                Account Identifier\n            orderSpecifier:\n                The Order Specifier\n\n        Returns:\n            v20.response.Response containing the results from submitting the\n            request\n        \"\"\"\n\n        request = Request(\n            'PUT',\n            '/v3/accounts/{accountID}/orders/{orderSpecifier}/cancel'\n        )\n\n        request.set_path_param(\n            'accountID',\n            accountID\n        )\n\n        request.set_path_param(\n            'orderSpecifier',\n            orderSpecifier\n        )\n\n        response = self.ctx.request(request)\n\n\n        if response.content_type is None:\n            return response\n\n        if not response.content_type.startswith(\"application/json\"):\n            return response\n\n        jbody = json.loads(response.raw_body)\n\n        parsed_body = {}\n\n        #\n        # Parse responses as defined by the API specification\n        #\n        if str(response.status) == \"200\":\n            if jbody.get('orderCancelTransaction') is not None:\n                parsed_body['orderCancelTransaction'] = \\\n                    self.ctx.transaction.OrderCancelTransaction.from_dict(\n                        jbody['orderCancelTransaction'],\n                        self.ctx\n                    )\n\n            if jbody.get('relatedTransactionIDs') is not None:\n                parsed_body['relatedTransactionIDs'] = \\\n                    jbody.get('relatedTransactionIDs')\n\n            if jbody.get('lastTransactionID') is not None:\n                parsed_body['lastTransactionID'] = \\\n                    jbody.get('lastTransactionID')\n\n        elif str(response.status) == \"401\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        elif str(response.status) == \"404\":\n            if jbody.get('orderCancelRejectTransaction') is not None:\n                parsed_body['orderCancelRejectTransaction'] = \\\n                    self.ctx.transaction.OrderCancelRejectTransaction.from_dict(\n                        jbody['orderCancelRejectTransaction'],\n                        self.ctx\n                    )\n\n            if jbody.get('relatedTransactionIDs') is not None:\n                parsed_body['relatedTransactionIDs'] = \\\n                    jbody.get('relatedTransactionIDs')\n\n            if jbody.get('lastTransactionID') is not None:\n                parsed_body['lastTransactionID'] = \\\n                    jbody.get('lastTransactionID')\n\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        elif str(response.status) == \"405\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        #\n        # Unexpected response status\n        #\n        else:\n            parsed_body = jbody\n\n        response.body = parsed_body\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate the Client Extensions for an Order in an Account. Do not set, modify, or delete clientExtensions if your account is associated with MT4. Args: accountID: Account Identifier orderSpecifier: The Order Specifier clientExtensions: The Client Extensions to update for the Order. Do not set, modify, or delete clientExtensions if your account is associated with MT4. tradeClientExtensions: The Client Extensions to update for the Trade created when the Order is filled. Do not set, modify, or delete clientExtensions if your account is associated with MT4. Returns: v20.response.Response containing the results from submitting the request", "response": "def set_client_extensions(\n        self,\n        accountID,\n        orderSpecifier,\n        **kwargs\n    ):\n        \"\"\"\n        Update the Client Extensions for an Order in an Account. Do not set,\n        modify, or delete clientExtensions if your account is associated with\n        MT4.\n\n        Args:\n            accountID:\n                Account Identifier\n            orderSpecifier:\n                The Order Specifier\n            clientExtensions:\n                The Client Extensions to update for the Order. Do not set,\n                modify, or delete clientExtensions if your account is\n                associated with MT4.\n            tradeClientExtensions:\n                The Client Extensions to update for the Trade created when the\n                Order is filled. Do not set, modify, or delete clientExtensions\n                if your account is associated with MT4.\n\n        Returns:\n            v20.response.Response containing the results from submitting the\n            request\n        \"\"\"\n\n        request = Request(\n            'PUT',\n            '/v3/accounts/{accountID}/orders/{orderSpecifier}/clientExtensions'\n        )\n\n        request.set_path_param(\n            'accountID',\n            accountID\n        )\n\n        request.set_path_param(\n            'orderSpecifier',\n            orderSpecifier\n        )\n\n        body = EntityDict()\n\n        if 'clientExtensions' in kwargs:\n            body.set('clientExtensions', kwargs['clientExtensions'])\n\n        if 'tradeClientExtensions' in kwargs:\n            body.set('tradeClientExtensions', kwargs['tradeClientExtensions'])\n\n        request.set_body_dict(body.dict)\n\n        response = self.ctx.request(request)\n\n\n        if response.content_type is None:\n            return response\n\n        if not response.content_type.startswith(\"application/json\"):\n            return response\n\n        jbody = json.loads(response.raw_body)\n\n        parsed_body = {}\n\n        #\n        # Parse responses as defined by the API specification\n        #\n        if str(response.status) == \"200\":\n            if jbody.get('orderClientExtensionsModifyTransaction') is not None:\n                parsed_body['orderClientExtensionsModifyTransaction'] = \\\n                    self.ctx.transaction.OrderClientExtensionsModifyTransaction.from_dict(\n                        jbody['orderClientExtensionsModifyTransaction'],\n                        self.ctx\n                    )\n\n            if jbody.get('lastTransactionID') is not None:\n                parsed_body['lastTransactionID'] = \\\n                    jbody.get('lastTransactionID')\n\n            if jbody.get('relatedTransactionIDs') is not None:\n                parsed_body['relatedTransactionIDs'] = \\\n                    jbody.get('relatedTransactionIDs')\n\n        elif str(response.status) == \"400\":\n            if jbody.get('orderClientExtensionsModifyRejectTransaction') is not None:\n                parsed_body['orderClientExtensionsModifyRejectTransaction'] = \\\n                    self.ctx.transaction.OrderClientExtensionsModifyRejectTransaction.from_dict(\n                        jbody['orderClientExtensionsModifyRejectTransaction'],\n                        self.ctx\n                    )\n\n            if jbody.get('lastTransactionID') is not None:\n                parsed_body['lastTransactionID'] = \\\n                    jbody.get('lastTransactionID')\n\n            if jbody.get('relatedTransactionIDs') is not None:\n                parsed_body['relatedTransactionIDs'] = \\\n                    jbody.get('relatedTransactionIDs')\n\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        elif str(response.status) == \"401\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        elif str(response.status) == \"404\":\n            if jbody.get('orderClientExtensionsModifyRejectTransaction') is not None:\n                parsed_body['orderClientExtensionsModifyRejectTransaction'] = \\\n                    self.ctx.transaction.OrderClientExtensionsModifyRejectTransaction.from_dict(\n                        jbody['orderClientExtensionsModifyRejectTransaction'],\n                        self.ctx\n                    )\n\n            if jbody.get('lastTransactionID') is not None:\n                parsed_body['lastTransactionID'] = \\\n                    jbody.get('lastTransactionID')\n\n            if jbody.get('relatedTransactionIDs') is not None:\n                parsed_body['relatedTransactionIDs'] = \\\n                    jbody.get('relatedTransactionIDs')\n\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        elif str(response.status) == \"405\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        #\n        # Unexpected response status\n        #\n        else:\n            parsed_body = jbody\n\n        response.body = parsed_body\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef limit_replace(self, accountID, orderID, **kwargs):\n        return self.replace(\n            accountID,\n            orderID,\n            order=LimitOrderRequest(**kwargs)\n        )", "response": "This is a shortcut to replace a pending Limit Order in an Account and Limit Order in an Account"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef take_profit(self, accountID, **kwargs):\n        return self.create(\n            accountID,\n            order=TakeProfitOrderRequest(**kwargs)\n        )", "response": "Shortcut to create a Take Profit Order in an Account\n           "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef take_profit_replace(self, accountID, orderID, **kwargs):\n        return self.replace(\n            accountID,\n            orderID,\n            order=TakeProfitOrderRequest(**kwargs)\n        )", "response": "This is a shortcut to replace a pending Take Profit Order in an Account and Take Profit Order in an Account"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stop_loss(self, accountID, **kwargs):\n        return self.create(\n            accountID,\n            order=StopLossOrderRequest(**kwargs)\n        )", "response": "Shortcut to create a Stop Loss Order in an Account\n           "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef trailing_stop_loss_replace(self, accountID, orderID, **kwargs):\n        return self.replace(\n            accountID,\n            orderID,\n            order=TrailingStopLossOrderRequest(**kwargs)\n        )", "response": "Shortcut to replace a pending Trailing Stop Loss Order in an Account and Order in an Account"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_token(self, token):\n\n        self.token = token\n\n        self.set_header(\n            'Authorization',\n            \"Bearer {}\".format(token)\n        )", "response": "Set the token for the v20 context"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_datetime_format(self, format):\n        if not format in [\"UNIX\", \"RFC3339\"]:\n            return\n\n        self.datetime_format = format\n\n        self.set_header(\"Accept-Datetime-Format\", self.datetime_format)", "response": "Set the Accept - Datetime - Format header to an acceptable\n        value"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef request(self, request):\n\n        url = \"{}{}\".format(self._base_url, request.path)\n\n        timeout = self.poll_timeout\n\n        if request.stream is True:\n            timeout = self.stream_timeout\n\n        try:\n            http_response = self._session.request(\n                request.method,\n                url,\n                headers=self._headers,\n                params=request.params,\n                data=request.body,\n                stream=request.stream,\n                timeout=timeout\n            )\n        except requests.exceptions.ConnectionError:\n            raise V20ConnectionError(url)\n        except requests.exceptions.ConnectTimeout:\n            raise V20Timeout(url, \"connect\")\n        except requests.exceptions.ReadTimeout:\n            raise V20Timeout(url, \"read\")\n\n        request.headers = http_response.request.headers\n\n        response = Response(\n            request,\n            request.method,\n            http_response.url,\n            http_response.status_code,\n            http_response.reason,\n            http_response.headers\n        )\n\n        if request.stream:\n            response.set_line_parser(\n                request.line_parser\n            )\n\n            response.set_lines(\n                http_response.iter_lines(\n                    self.stream_chunk_size\n                )\n            )\n        else:\n            response.set_raw_body(http_response.text)\n\n        return response", "response": "Perform an HTTP request through the context of the context."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_dict(data, ctx):\n\n        data = data.copy()\n\n        if data.get('balance') is not None:\n            data['balance'] = ctx.convert_decimal_number(\n                data.get('balance')\n            )\n\n        if data.get('pl') is not None:\n            data['pl'] = ctx.convert_decimal_number(\n                data.get('pl')\n            )\n\n        if data.get('resettablePL') is not None:\n            data['resettablePL'] = ctx.convert_decimal_number(\n                data.get('resettablePL')\n            )\n\n        if data.get('financing') is not None:\n            data['financing'] = ctx.convert_decimal_number(\n                data.get('financing')\n            )\n\n        if data.get('commission') is not None:\n            data['commission'] = ctx.convert_decimal_number(\n                data.get('commission')\n            )\n\n        if data.get('guaranteedExecutionFees') is not None:\n            data['guaranteedExecutionFees'] = ctx.convert_decimal_number(\n                data.get('guaranteedExecutionFees')\n            )\n\n        if data.get('marginRate') is not None:\n            data['marginRate'] = ctx.convert_decimal_number(\n                data.get('marginRate')\n            )\n\n        if data.get('unrealizedPL') is not None:\n            data['unrealizedPL'] = ctx.convert_decimal_number(\n                data.get('unrealizedPL')\n            )\n\n        if data.get('NAV') is not None:\n            data['NAV'] = ctx.convert_decimal_number(\n                data.get('NAV')\n            )\n\n        if data.get('marginUsed') is not None:\n            data['marginUsed'] = ctx.convert_decimal_number(\n                data.get('marginUsed')\n            )\n\n        if data.get('marginAvailable') is not None:\n            data['marginAvailable'] = ctx.convert_decimal_number(\n                data.get('marginAvailable')\n            )\n\n        if data.get('positionValue') is not None:\n            data['positionValue'] = ctx.convert_decimal_number(\n                data.get('positionValue')\n            )\n\n        if data.get('marginCloseoutUnrealizedPL') is not None:\n            data['marginCloseoutUnrealizedPL'] = ctx.convert_decimal_number(\n                data.get('marginCloseoutUnrealizedPL')\n            )\n\n        if data.get('marginCloseoutNAV') is not None:\n            data['marginCloseoutNAV'] = ctx.convert_decimal_number(\n                data.get('marginCloseoutNAV')\n            )\n\n        if data.get('marginCloseoutMarginUsed') is not None:\n            data['marginCloseoutMarginUsed'] = ctx.convert_decimal_number(\n                data.get('marginCloseoutMarginUsed')\n            )\n\n        if data.get('marginCloseoutPercent') is not None:\n            data['marginCloseoutPercent'] = ctx.convert_decimal_number(\n                data.get('marginCloseoutPercent')\n            )\n\n        if data.get('marginCloseoutPositionValue') is not None:\n            data['marginCloseoutPositionValue'] = ctx.convert_decimal_number(\n                data.get('marginCloseoutPositionValue')\n            )\n\n        if data.get('withdrawalLimit') is not None:\n            data['withdrawalLimit'] = ctx.convert_decimal_number(\n                data.get('withdrawalLimit')\n            )\n\n        if data.get('marginCallMarginUsed') is not None:\n            data['marginCallMarginUsed'] = ctx.convert_decimal_number(\n                data.get('marginCallMarginUsed')\n            )\n\n        if data.get('marginCallPercent') is not None:\n            data['marginCallPercent'] = ctx.convert_decimal_number(\n                data.get('marginCallPercent')\n            )\n\n        return AccountSummary(**data)", "response": "Instantiate an AccountSummary object from a dict."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a list of all Accounts authorized for the provided token.", "response": "def list(\n        self,\n        **kwargs\n    ):\n        \"\"\"\n        Get a list of all Accounts authorized for the provided token.\n\n        Args:\n\n        Returns:\n            v20.response.Response containing the results from submitting the\n            request\n        \"\"\"\n\n        request = Request(\n            'GET',\n            '/v3/accounts'\n        )\n\n        response = self.ctx.request(request)\n\n\n        if response.content_type is None:\n            return response\n\n        if not response.content_type.startswith(\"application/json\"):\n            return response\n\n        jbody = json.loads(response.raw_body)\n\n        parsed_body = {}\n\n        #\n        # Parse responses as defined by the API specification\n        #\n        if str(response.status) == \"200\":\n            if jbody.get('accounts') is not None:\n                parsed_body['accounts'] = [\n                    self.ctx.account.AccountProperties.from_dict(d, self.ctx)\n                    for d in jbody.get('accounts')\n                ]\n\n        elif str(response.status) == \"401\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        elif str(response.status) == \"405\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        #\n        # Unexpected response status\n        #\n        else:\n            parsed_body = jbody\n\n        response.body = parsed_body\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the list of tradeable instruments for the given Account.", "response": "def instruments(\n        self,\n        accountID,\n        **kwargs\n    ):\n        \"\"\"\n        Get the list of tradeable instruments for the given Account. The list\n        of tradeable instruments is dependent on the regulatory division that\n        the Account is located in, thus should be the same for all Accounts\n        owned by a single user.\n\n        Args:\n            accountID:\n                Account Identifier\n            instruments:\n                List of instruments to query specifically.\n\n        Returns:\n            v20.response.Response containing the results from submitting the\n            request\n        \"\"\"\n\n        request = Request(\n            'GET',\n            '/v3/accounts/{accountID}/instruments'\n        )\n\n        request.set_path_param(\n            'accountID',\n            accountID\n        )\n\n        request.set_param(\n            'instruments',\n            kwargs.get('instruments')\n        )\n\n        response = self.ctx.request(request)\n\n\n        if response.content_type is None:\n            return response\n\n        if not response.content_type.startswith(\"application/json\"):\n            return response\n\n        jbody = json.loads(response.raw_body)\n\n        parsed_body = {}\n\n        #\n        # Parse responses as defined by the API specification\n        #\n        if str(response.status) == \"200\":\n            if jbody.get('instruments') is not None:\n                parsed_body['instruments'] = [\n                    self.ctx.primitives.Instrument.from_dict(d, self.ctx)\n                    for d in jbody.get('instruments')\n                ]\n\n            if jbody.get('lastTransactionID') is not None:\n                parsed_body['lastTransactionID'] = \\\n                    jbody.get('lastTransactionID')\n\n        elif str(response.status) == \"400\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        elif str(response.status) == \"401\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        elif str(response.status) == \"405\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        #\n        # Unexpected response status\n        #\n        else:\n            parsed_body = jbody\n\n        response.body = parsed_body\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef configure(\n        self,\n        accountID,\n        **kwargs\n    ):\n        \"\"\"\n        Set the client-configurable portions of an Account.\n\n        Args:\n            accountID:\n                Account Identifier\n            alias:\n                Client-defined alias (name) for the Account\n            marginRate:\n                The string representation of a decimal number.\n\n        Returns:\n            v20.response.Response containing the results from submitting the\n            request\n        \"\"\"\n\n        request = Request(\n            'PATCH',\n            '/v3/accounts/{accountID}/configuration'\n        )\n\n        request.set_path_param(\n            'accountID',\n            accountID\n        )\n\n        body = EntityDict()\n\n        if 'alias' in kwargs:\n            body.set('alias', kwargs['alias'])\n\n        if 'marginRate' in kwargs:\n            body.set('marginRate', kwargs['marginRate'])\n\n        request.set_body_dict(body.dict)\n\n        response = self.ctx.request(request)\n\n\n        if response.content_type is None:\n            return response\n\n        if not response.content_type.startswith(\"application/json\"):\n            return response\n\n        jbody = json.loads(response.raw_body)\n\n        parsed_body = {}\n\n        #\n        # Parse responses as defined by the API specification\n        #\n        if str(response.status) == \"200\":\n            if jbody.get('clientConfigureTransaction') is not None:\n                parsed_body['clientConfigureTransaction'] = \\\n                    self.ctx.transaction.ClientConfigureTransaction.from_dict(\n                        jbody['clientConfigureTransaction'],\n                        self.ctx\n                    )\n\n            if jbody.get('lastTransactionID') is not None:\n                parsed_body['lastTransactionID'] = \\\n                    jbody.get('lastTransactionID')\n\n        elif str(response.status) == \"400\":\n            if jbody.get('clientConfigureRejectTransaction') is not None:\n                parsed_body['clientConfigureRejectTransaction'] = \\\n                    self.ctx.transaction.ClientConfigureRejectTransaction.from_dict(\n                        jbody['clientConfigureRejectTransaction'],\n                        self.ctx\n                    )\n\n            if jbody.get('lastTransactionID') is not None:\n                parsed_body['lastTransactionID'] = \\\n                    jbody.get('lastTransactionID')\n\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        elif str(response.status) == \"403\":\n            if jbody.get('clientConfigureRejectTransaction') is not None:\n                parsed_body['clientConfigureRejectTransaction'] = \\\n                    self.ctx.transaction.ClientConfigureRejectTransaction.from_dict(\n                        jbody['clientConfigureRejectTransaction'],\n                        self.ctx\n                    )\n\n            if jbody.get('lastTransactionID') is not None:\n                parsed_body['lastTransactionID'] = \\\n                    jbody.get('lastTransactionID')\n\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        elif str(response.status) == \"401\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        elif str(response.status) == \"404\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        elif str(response.status) == \"405\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        #\n        # Unexpected response status\n        #\n        else:\n            parsed_body = jbody\n\n        response.body = parsed_body\n\n        return response", "response": "This method is used to configure the client - defined portions of an Account."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_info(\n        self,\n        userSpecifier,\n        **kwargs\n    ):\n        \"\"\"\n        Fetch the user information for the specified user. This endpoint is\n        intended to be used by the user themself to obtain their own\n        information.\n\n        Args:\n            userSpecifier:\n                The User Specifier\n\n        Returns:\n            v20.response.Response containing the results from submitting the\n            request\n        \"\"\"\n\n        request = Request(\n            'GET',\n            '/v3/users/{userSpecifier}'\n        )\n\n        request.set_path_param(\n            'userSpecifier',\n            userSpecifier\n        )\n\n        response = self.ctx.request(request)\n\n\n        if response.content_type is None:\n            return response\n\n        if not response.content_type.startswith(\"application/json\"):\n            return response\n\n        jbody = json.loads(response.raw_body)\n\n        parsed_body = {}\n\n        #\n        # Parse responses as defined by the API specification\n        #\n        if str(response.status) == \"200\":\n            if jbody.get('userInfo') is not None:\n                parsed_body['userInfo'] = \\\n                    self.ctx.user.UserInfo.from_dict(\n                        jbody['userInfo'],\n                        self.ctx\n                    )\n\n        elif str(response.status) == \"401\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        elif str(response.status) == \"403\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        elif str(response.status) == \"405\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        #\n        # Unexpected response status\n        #\n        else:\n            parsed_body = jbody\n\n        response.body = parsed_body\n\n        return response", "response": "This endpoint returns the user information for the specified user."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_dict(data, ctx):\n\n        data = data.copy()\n\n        if data.get('bids') is not None:\n            data['bids'] = [\n                ctx.pricing_common.PriceBucket.from_dict(d, ctx)\n                for d in data.get('bids')\n            ]\n\n        if data.get('asks') is not None:\n            data['asks'] = [\n                ctx.pricing_common.PriceBucket.from_dict(d, ctx)\n                for d in data.get('asks')\n            ]\n\n        if data.get('closeoutBid') is not None:\n            data['closeoutBid'] = ctx.convert_decimal_number(\n                data.get('closeoutBid')\n            )\n\n        if data.get('closeoutAsk') is not None:\n            data['closeoutAsk'] = ctx.convert_decimal_number(\n                data.get('closeoutAsk')\n            )\n\n        if data.get('quoteHomeConversionFactors') is not None:\n            data['quoteHomeConversionFactors'] = \\\n                ctx.pricing.QuoteHomeConversionFactors.from_dict(\n                    data['quoteHomeConversionFactors'], ctx\n                )\n\n        if data.get('unitsAvailable') is not None:\n            data['unitsAvailable'] = \\\n                ctx.order.UnitsAvailable.from_dict(\n                    data['unitsAvailable'], ctx\n                )\n\n        return ClientPrice(**data)", "response": "Instantiate a new ClientPrice from a dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_dict(data, ctx):\n\n        data = data.copy()\n\n        if data.get('positiveUnits') is not None:\n            data['positiveUnits'] = ctx.convert_decimal_number(\n                data.get('positiveUnits')\n            )\n\n        if data.get('negativeUnits') is not None:\n            data['negativeUnits'] = ctx.convert_decimal_number(\n                data.get('negativeUnits')\n            )\n\n        return QuoteHomeConversionFactors(**data)", "response": "Instantiate a new QuoteHomeConversionFactors object from a dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(\n        self,\n        accountID,\n        **kwargs\n    ):\n        \"\"\"\n        Get pricing information for a specified list of Instruments within an\n        Account.\n\n        Args:\n            accountID:\n                Account Identifier\n            instruments:\n                List of Instruments to get pricing for.\n            since:\n                Date/Time filter to apply to the response. Only prices and home\n                conversions (if requested) with a time later than this filter\n                (i.e. the price has changed after the since time) will be\n                provided, and are filtered independently.\n            includeUnitsAvailable:\n                Flag that enables the inclusion of the unitsAvailable field in\n                the returned Price objects.\n            includeHomeConversions:\n                Flag that enables the inclusion of the homeConversions field in\n                the returned response. An entry will be returned for each\n                currency in the set of all base and quote currencies present in\n                the requested instruments list.\n\n        Returns:\n            v20.response.Response containing the results from submitting the\n            request\n        \"\"\"\n\n        request = Request(\n            'GET',\n            '/v3/accounts/{accountID}/pricing'\n        )\n\n        request.set_path_param(\n            'accountID',\n            accountID\n        )\n\n        request.set_param(\n            'instruments',\n            kwargs.get('instruments')\n        )\n\n        request.set_param(\n            'since',\n            kwargs.get('since')\n        )\n\n        request.set_param(\n            'includeUnitsAvailable',\n            kwargs.get('includeUnitsAvailable')\n        )\n\n        request.set_param(\n            'includeHomeConversions',\n            kwargs.get('includeHomeConversions')\n        )\n\n        response = self.ctx.request(request)\n\n\n        if response.content_type is None:\n            return response\n\n        if not response.content_type.startswith(\"application/json\"):\n            return response\n\n        jbody = json.loads(response.raw_body)\n\n        parsed_body = {}\n\n        #\n        # Parse responses as defined by the API specification\n        #\n        if str(response.status) == \"200\":\n            if jbody.get('prices') is not None:\n                parsed_body['prices'] = [\n                    self.ctx.pricing.ClientPrice.from_dict(d, self.ctx)\n                    for d in jbody.get('prices')\n                ]\n\n            if jbody.get('homeConversions') is not None:\n                parsed_body['homeConversions'] = [\n                    self.ctx.pricing.HomeConversions.from_dict(d, self.ctx)\n                    for d in jbody.get('homeConversions')\n                ]\n\n            if jbody.get('time') is not None:\n                parsed_body['time'] = \\\n                    jbody.get('time')\n\n        elif str(response.status) == \"400\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        elif str(response.status) == \"401\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        elif str(response.status) == \"404\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        elif str(response.status) == \"405\":\n            if jbody.get('errorCode') is not None:\n                parsed_body['errorCode'] = \\\n                    jbody.get('errorCode')\n\n            if jbody.get('errorMessage') is not None:\n                parsed_body['errorMessage'] = \\\n                    jbody.get('errorMessage')\n\n        #\n        # Unexpected response status\n        #\n        else:\n            parsed_body = jbody\n\n        response.body = parsed_body\n\n        return response", "response": "This method returns the pricing information for a specified list of Instruments within an Account."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a stream of Account Prices for the given Account.", "response": "def stream(\n        self,\n        accountID,\n        **kwargs\n    ):\n        \"\"\"\n        Get a stream of Account Prices starting from when the request is made.\n        This pricing stream does not include every single price created for the\n        Account, but instead will provide at most 4 prices per second (every\n        250 milliseconds) for each instrument being requested. If more than one\n        price is created for an instrument during the 250 millisecond window,\n        only the price in effect at the end of the window is sent. This means\n        that during periods of rapid price movement, subscribers to this stream\n        will not be sent every price. Pricing windows for different connections\n        to the price stream are not all aligned in the same way (i.e. they are\n        not all aligned to the top of the second). This means that during\n        periods of rapid price movement, different subscribers may observe\n        different prices depending on their alignment.\n\n        Args:\n            accountID:\n                Account Identifier\n            instruments:\n                List of Instruments to stream Prices for.\n            snapshot:\n                Flag that enables/disables the sending of a pricing snapshot\n                when initially connecting to the stream.\n\n        Returns:\n            v20.response.Response containing the results from submitting the\n            request\n        \"\"\"\n\n        request = Request(\n            'GET',\n            '/v3/accounts/{accountID}/pricing/stream'\n        )\n\n        request.set_path_param(\n            'accountID',\n            accountID\n        )\n\n        request.set_param(\n            'instruments',\n            kwargs.get('instruments')\n        )\n\n        request.set_param(\n            'snapshot',\n            kwargs.get('snapshot')\n        )\n\n        request.set_stream(True)\n\n        class Parser():\n            def __init__(self, ctx):\n                self.ctx = ctx\n\n            def __call__(self, line):\n                j = json.loads(line.decode('utf-8'))\n\n                type = j.get(\"type\")\n\n                if type is None:\n                    return (\n                        \"pricing.ClientPrice\",\n                        self.ctx.pricing.ClientPrice.from_dict(j, self.ctx)\n                    )\n                elif type == \"HEARTBEAT\":\n                    return (\n                        \"pricing.PricingHeartbeat\",\n                        self.ctx.pricing.PricingHeartbeat.from_dict(j, self.ctx)\n                    )\n\n                return (\n                    \"pricing.ClientPrice\",\n                    self.ctx.pricing.ClientPrice.from_dict(j, self.ctx)\n                )\n\n                \n        request.set_line_parser(\n            Parser(self.ctx)\n        )\n\n        response = self.ctx.request(request)\n\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nnormalizes a string to be used as a base64 - encoded version of the ISO.", "response": "def normalize_str(string):\n    \"\"\"\n    Remove special characters and strip spaces\n    \"\"\"\n    if string:\n        if not isinstance(string, str):\n            string = str(string, 'utf-8', 'replace')\n\n        string = string.encode('utf-8')\n        return normalize(\n            'NFKD', string.decode('utf-8')).encode('ASCII', 'ignore').decode()\n    return ''"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nformats datetime to be used in log file", "response": "def format_datetime(value):\n    \"\"\"\n    Format datetime\n    \"\"\"\n    dt_format = '%Y-%m-%dT%H:%M:%I'\n    if isinstance(value, datetime):\n        return value.strftime(dt_format)\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef format_date(value):\n    dt_format = '%Y-%m-%d'\n    if isinstance(value, date):\n        return value.strftime(dt_format)\n    return value", "response": "Format date to be used in log file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a list of program files from a executable.", "response": "def _program_files_from_executable(self, executable, required_paths, parent_dir=False):\n        \"\"\"\n        Get a list of program files by expanding a list of path patterns\n        and interpreting it as relative to the executable.\n        This method can be used as helper for implementing the method program_files().\n        Contrary to the default implementation of program_files(), this method does not explicitly\n        add the executable to the list of returned files, it assumes that required_paths\n        contains a path that covers the executable.\n        @param executable: the path to the executable of the tool (typically the result of executable())\n        @param required_paths: a list of required path patterns\n        @param parent_dir: whether required_paths are relative to the directory of executable or the parent directory\n        @return a list of paths as strings, suitable for result of program_files()\n        \"\"\"\n        base_dir = os.path.dirname(executable)\n        if parent_dir:\n            base_dir = os.path.join(base_dir, os.path.pardir)\n        return util.flatten(\n            util.expand_filename_pattern(path, base_dir) for path in required_paths)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _version_from_tool(self, executable, arg='--version', use_stderr=False, ignore_stderr=False):\n        try:\n            process = subprocess.Popen([executable, arg],\n                                       stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n            (stdout, stderr) = process.communicate()\n        except OSError as e:\n            logging.warning('Cannot run {0} to determine version: {1}'.\n                            format(executable, e.strerror))\n            return ''\n        if stderr and not use_stderr and not ignore_stderr:\n            logging.warning('Cannot determine {0} version, error output: {1}'.\n                            format(executable, util.decode_to_string(stderr)))\n            return ''\n        if process.returncode:\n            logging.warning('Cannot determine {0} version, exit code {1}'.\n                            format(executable, process.returncode))\n            return ''\n        return util.decode_to_string(stderr if use_stderr else stdout).strip()", "response": "Get version of a tool by executing it with argument \"--version\" and returning stdout."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the error message for the current instance of the class.", "response": "def set_error(self, msg, runSet=None):\n        \"\"\"\n        Mark the benchmark as erroneous, e.g., because the benchmarking tool crashed.\n        The message is intended as explanation for the user.\n        \"\"\"\n        self.xml_header.set('error', msg if msg else 'unknown error')\n        if runSet:\n            runSet.xml.set('error', msg if msg else 'unknown error')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef output_before_run_set(self, runSet):\n        xml_file_name = self.get_filename(runSet.name, \"xml\")\n\n        identifier_names = [run.identifier for run in runSet.runs]\n\n        # common prefix of file names\n        runSet.common_prefix = util.common_base_dir(identifier_names)\n        if runSet.common_prefix:\n            runSet.common_prefix += os.path.sep\n\n        # length of the first column in terminal\n        runSet.max_length_of_filename = max(len(file) for file in identifier_names) if identifier_names else 20\n        runSet.max_length_of_filename = max(20, runSet.max_length_of_filename - len(runSet.common_prefix))\n\n        # write run set name to terminal\n        numberOfFiles = len(runSet.runs)\n        numberOfFilesStr = (\"     (1 file)\" if numberOfFiles == 1\n                        else \"     ({0} files)\".format(numberOfFiles))\n        util.printOut(\"\\nexecuting run set\"\n            + (\" '\" + runSet.name + \"'\" if runSet.name else \"\")\n            + numberOfFilesStr\n            + TERMINAL_TITLE.format(runSet.full_name))\n\n        # write information about the run set into txt_file\n        self.writeRunSetInfoToLog(runSet)\n\n        # prepare information for text output\n        for run in runSet.runs:\n            run.resultline = self.format_sourcefile_name(run.identifier, runSet)\n\n            if run.sourcefiles:\n                adjusted_identifier = util.relative_path(run.identifier, xml_file_name)\n            else:\n                # If no source files exist the task doesn't point to any file that could be downloaded.\n                # In this case, the name doesn't have to be adjusted because it's no path.\n                adjusted_identifier = run.identifier\n\n        # prepare XML structure for each run and runSet\n            run_attributes = {'name': adjusted_identifier}\n            if run.sourcefiles:\n                adjusted_sourcefiles = [util.relative_path(s, xml_file_name) for s in run.sourcefiles]\n                run_attributes['files'] = '[' + ', '.join(adjusted_sourcefiles) + ']'\n            run.xml = ET.Element(\"run\", run_attributes)\n            if run.specific_options:\n                run.xml.set(\"options\", \" \".join(run.specific_options))\n            if run.properties:\n                all_properties = [prop_name for prop in run.properties for prop_name in prop.names]\n                run.xml.set(\"properties\", \" \".join(sorted(all_properties)))\n            run.xml.extend(self.xml_dummy_elements)\n\n        block_name = runSet.blocks[0].name if len(runSet.blocks) == 1 else None\n        runSet.xml = self.runs_to_xml(runSet, runSet.runs, block_name)\n\n        # write (empty) results to txt_file and XML\n        self.txt_file.append(self.run_set_to_text(runSet), False)\n        runSet.xml_file_name = xml_file_name\n        self._write_rough_result_xml_to_file(runSet.xml, runSet.xml_file_name)\n        runSet.xml_file_last_modified_time = util.read_monotonic_time()\n        self.all_created_files.add(runSet.xml_file_name)\n        self.xml_file_names.append(runSet.xml_file_name)", "response": "This method writes the run set information to the terminal and stores the information about the run set in txt_file_name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef output_for_skipping_run_set(self, runSet, reason=None):\n        '''\n        This function writes a simple message to terminal and logfile,\n        when a run set is skipped.\n        There is no message about skipping a run set in the xml-file.\n        '''\n\n        # print to terminal\n        util.printOut(\"\\nSkipping run set\" +\n               (\" '\" + runSet.name + \"'\" if runSet.name else \"\") +\n               (\" \" + reason if reason else \"\")\n              )\n\n        # write into txt_file\n        runSetInfo = \"\\n\\n\"\n        if runSet.name:\n            runSetInfo += runSet.name + \"\\n\"\n        runSetInfo += \"Run set {0} of {1}: skipped {2}\\n\".format(\n                runSet.index, len(self.benchmark.run_sets), reason or \"\")\n        self.txt_file.append(runSetInfo)", "response": "This function writes a simple message to terminal and logfile the run set that is skipped."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef writeRunSetInfoToLog(self, runSet):\n\n        runSetInfo = \"\\n\\n\"\n        if runSet.name:\n            runSetInfo += runSet.name + \"\\n\"\n        runSetInfo += \"Run set {0} of {1} with options '{2}' and propertyfile '{3}'\\n\\n\".format(\n                runSet.index, len(self.benchmark.run_sets),\n                \" \".join(runSet.options),\n                runSet.propertyfile)\n\n        titleLine = self.create_output_line(runSet, \"inputfile\", \"status\", \"cpu time\",\n                            \"wall time\", \"host\", self.benchmark.columns, True)\n\n        runSet.simpleLine = \"-\" * (len(titleLine))\n\n        runSetInfo += titleLine + \"\\n\" + runSet.simpleLine + \"\\n\"\n\n        # write into txt_file\n        self.txt_file.append(runSetInfo)", "response": "This method writes the information about a run set into the txt_file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef output_before_run(self, run):\n        # output in terminal\n        runSet = run.runSet\n        try:\n            OutputHandler.print_lock.acquire()\n\n            try:\n                runSet.started_runs += 1\n            except AttributeError:\n                runSet.started_runs = 1\n\n            timeStr = time.strftime(\"%H:%M:%S\", time.localtime()) + \"   \"\n            progressIndicator = \" ({0}/{1})\".format(runSet.started_runs, len(runSet.runs))\n            terminalTitle = TERMINAL_TITLE.format(runSet.full_name + progressIndicator)\n            if self.benchmark.num_of_threads == 1:\n                util.printOut(terminalTitle + timeStr + self.format_sourcefile_name(run.identifier, runSet), '')\n            else:\n                util.printOut(terminalTitle + timeStr + \"starting   \" + self.format_sourcefile_name(run.identifier, runSet))\n        finally:\n            OutputHandler.print_lock.release()", "response": "This method prints the name of a file to terminal. It returns the name of the logfile."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef output_after_run(self, run):\n\n        # format times, type is changed from float to string!\n        cputime_str = util.format_number(run.cputime, TIME_PRECISION)\n        walltime_str = util.format_number(run.walltime, TIME_PRECISION)\n\n        # format numbers, number_of_digits is optional, so it can be None\n        for column in run.columns:\n            if column.number_of_digits is not None:\n\n                # if the number ends with \"s\" or another letter, remove it\n                if (not column.value.isdigit()) and column.value[-2:-1].isdigit():\n                    column.value = column.value[:-1]\n\n                try:\n                    floatValue = float(column.value)\n                    column.value = util.format_number(floatValue, column.number_of_digits)\n                except ValueError: # if value is no float, don't format it\n                    pass\n\n        # store information in run\n        run.resultline = self.create_output_line(run.runSet, run.identifier, run.status,\n                cputime_str, walltime_str, run.values.get('host'),\n                run.columns)\n        self.add_values_to_run_xml(run)\n\n        # output in terminal/console\n        statusStr = COLOR_DIC[run.category].format(run.status.ljust(LEN_OF_STATUS))\n\n        try:\n            OutputHandler.print_lock.acquire()\n\n            valueStr = statusStr + cputime_str.rjust(8) + walltime_str.rjust(8)\n            if self.benchmark.num_of_threads == 1:\n                util.printOut(valueStr)\n            else:\n                timeStr = time.strftime(\"%H:%M:%S\", time.localtime()) + \" \"*14\n                util.printOut(timeStr + self.format_sourcefile_name(run.identifier, run.runSet) + valueStr)\n\n            # write result in txt_file and XML\n            self.txt_file.append(self.run_set_to_text(run.runSet), False)\n            self.statistics.add_result(run)\n\n            # we don't want to write this file to often, it can slow down the whole script,\n            # so we wait at least 10 seconds between two write-actions\n            currentTime = util.read_monotonic_time()\n            if currentTime - run.runSet.xml_file_last_modified_time > 60:\n                self._write_rough_result_xml_to_file(run.runSet.xml, run.runSet.xml_file_name)\n                run.runSet.xml_file_last_modified_time = util.read_monotonic_time()\n\n        finally:\n            OutputHandler.print_lock.release()\n\n        if self.compress_results:\n            log_file_path = os.path.relpath(run.log_file, os.path.join(self.benchmark.log_folder, os.pardir))\n            with self.log_zip_lock:\n                self.log_zip.write(run.log_file, log_file_path)\n            os.remove(run.log_file)\n        else:\n            self.all_created_files.add(run.log_file)\n\n        if os.path.isdir(run.result_files_folder):\n            self.all_created_files.add(run.result_files_folder)", "response": "This method prints the filename result time and status of a run to terminal and stores all data in XML\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef runs_to_xml(self, runSet, runs, blockname=None):\n        # copy benchmarkinfo, limits, columntitles, systeminfo from xml_header\n        runsElem = util.copy_of_xml_element(self.xml_header)\n        runsElem.set(\"options\", \" \".join(runSet.options))\n        if blockname is not None:\n            runsElem.set(\"block\", blockname)\n            runsElem.set(\"name\", ((runSet.real_name + \".\") if runSet.real_name else \"\") + blockname)\n        elif runSet.real_name:\n            runsElem.set(\"name\", runSet.real_name)\n\n        # collect XMLelements from all runs\n        for run in runs:\n            runsElem.append(run.xml)\n\n        return runsElem", "response": "This function creates the XML structure for a list of runs."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_filename(self, runSetName, fileExtension):\n        '''\n        This function returns the name of the file for a run set\n        with an extension (\"txt\", \"xml\").\n        '''\n\n        fileName = self.benchmark.output_base_name + \".results.\"\n\n        if runSetName:\n            fileName += runSetName + \".\"\n\n        return fileName + fileExtension", "response": "This function returns the name of the file for a run set and a file extension."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nformat the file name for printing on console.", "response": "def format_sourcefile_name(self, fileName, runSet):\n        '''\n        Formats the file name of a program for printing on console.\n        '''\n        if fileName.startswith(runSet.common_prefix):\n            fileName = fileName[len(runSet.common_prefix):]\n        return fileName.ljust(runSet.max_length_of_filename + 4)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite a rough string version of the XML to a file.", "response": "def _write_rough_result_xml_to_file(self, xml, filename):\n        \"\"\"Write a rough string version of the XML (for temporary files).\"\"\"\n        # Write content to temp file first\n        error = xml.get('error', None)\n        xml.set('error', 'incomplete') # Mark result file as incomplete\n        temp_filename = filename + \".tmp\"\n        with open(temp_filename, 'wb') as file:\n            ET.ElementTree(xml).write(file, encoding='utf-8', xml_declaration=True)\n        os.rename(temp_filename, filename)\n        if error is not None:\n            xml.set('error', error)\n        else:\n            del xml.attrib['error']"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _write_pretty_result_xml_to_file(self, xml, filename):\n        if self.compress_results:\n            actual_filename = filename + \".bz2\"\n            # Use BZ2File directly or our hack for Python 3.2\n            open_func = bz2.BZ2File if hasattr(bz2.BZ2File, 'writable') else util.BZ2FileHack\n        else:\n            # write content to temp file first to prevent loosing data\n            # in existing file if writing fails\n            actual_filename = filename + \".tmp\"\n            open_func = open\n\n        with io.TextIOWrapper(open_func(actual_filename, 'wb'), encoding='utf-8') as file:\n            rough_string = ET.tostring(xml, encoding='unicode')\n            reparsed = minidom.parseString(rough_string)\n            doctype = minidom.DOMImplementation().createDocumentType(\n                    'result', RESULT_XML_PUBLIC_ID, RESULT_XML_SYSTEM_ID)\n            reparsed.insertBefore(doctype, reparsed.documentElement)\n            reparsed.writexml(file, indent=\"\", addindent=\"  \", newl=\"\\n\", encoding=\"utf-8\")\n\n        if self.compress_results:\n            # try to delete uncompressed file (would have been overwritten in no-compress-mode)\n            try:\n                os.remove(filename)\n            except OSError:\n                pass\n            self.all_created_files.discard(filename)\n            self.all_created_files.add(actual_filename)\n        else:\n            os.rename(actual_filename, filename)\n            self.all_created_files.add(filename)\n\n        return filename", "response": "Writes a nicely formatted XML file with DOCTYPE and compressed if necessary."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a function that extracts the value for a column.", "response": "def get_extract_value_function(column_identifier):\n    \"\"\"\n    returns a function that extracts the value for a column.\n    \"\"\"\n    def extract_value(run_result):\n        pos = None\n        for i, column in enumerate(run_result.columns):\n            if column.title == column_identifier:\n                pos = i\n                break\n        if pos is None:\n            sys.exit('CPU time missing for task {0}.'.format(run_result.task_id[0]))\n        return Util.to_decimal(run_result.values[pos])\n    return extract_value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate an assignment of the available CPU cores to a number of parallel benchmark executions such that each run gets its own cores without overlapping of cores between runs. In case the machine has hyper-threading, this method tries to avoid putting two different runs on the same physical core (but it does not guarantee this if the number of parallel runs is too high to avoid it). In case the machine has multiple CPUs, this method avoids splitting a run across multiple CPUs if the number of cores per run is lower than the number of cores per CPU (splitting a run over multiple CPUs provides worse performance). It will also try to split the runs evenly across all available CPUs. A few theoretically-possible cases are not implemented, for example assigning three 10-core runs on a machine with two 16-core CPUs (this would have unfair core assignment and thus undesirable performance characteristics anyway). The list of available cores is read from the cgroup file system, such that the assigned cores are a subset of the cores that the current process is allowed to use. This script does currently not support situations where the available cores are asymmetrically split over CPUs, e.g. 3 cores on one CPU and 5 on another. @param coreLimit: the number of cores for each run @param num_of_threads: the number of parallel benchmark executions @param coreSet: the list of CPU cores identifiers provided by a user, None makes benchexec using all cores @return a list of lists, where each inner list contains the cores for one run", "response": "def get_cpu_cores_per_run(coreLimit, num_of_threads, my_cgroups, coreSet=None):\n    \"\"\"\n    Calculate an assignment of the available CPU cores to a number\n    of parallel benchmark executions such that each run gets its own cores\n    without overlapping of cores between runs.\n    In case the machine has hyper-threading, this method tries to avoid\n    putting two different runs on the same physical core\n    (but it does not guarantee this if the number of parallel runs is too high to avoid it).\n    In case the machine has multiple CPUs, this method avoids\n    splitting a run across multiple CPUs if the number of cores per run\n    is lower than the number of cores per CPU\n    (splitting a run over multiple CPUs provides worse performance).\n    It will also try to split the runs evenly across all available CPUs.\n\n    A few theoretically-possible cases are not implemented,\n    for example assigning three 10-core runs on a machine\n    with two 16-core CPUs (this would have unfair core assignment\n    and thus undesirable performance characteristics anyway).\n\n    The list of available cores is read from the cgroup file system,\n    such that the assigned cores are a subset of the cores\n    that the current process is allowed to use.\n    This script does currently not support situations\n    where the available cores are asymmetrically split over CPUs,\n    e.g. 3 cores on one CPU and 5 on another.\n\n    @param coreLimit: the number of cores for each run\n    @param num_of_threads: the number of parallel benchmark executions\n    @param coreSet: the list of CPU cores identifiers provided by a user, None makes benchexec using all cores\n    @return a list of lists, where each inner list contains the cores for one run\n    \"\"\"\n    try:\n        # read list of available CPU cores\n        allCpus = util.parse_int_list(my_cgroups.get_value(cgroups.CPUSET, 'cpus'))\n\n        # Filter CPU cores according to the list of identifiers provided by a user\n        if coreSet:\n            invalid_cores = sorted(set(coreSet).difference(set(allCpus)))\n            if len(invalid_cores) > 0:\n                raise ValueError(\"The following provided CPU cores are not available: {}\".format(', '.join(map(str, invalid_cores))))\n            allCpus = [core for core in allCpus if core in coreSet]\n\n        logging.debug(\"List of available CPU cores is %s.\", allCpus)\n\n        # read mapping of core to CPU (\"physical package\")\n        physical_packages = [get_cpu_package_for_core(core) for core in allCpus]\n        cores_of_package = collections.defaultdict(list)\n        for core, package in zip(allCpus, physical_packages):\n            cores_of_package[package].append(core)\n        logging.debug(\"Physical packages of cores are %s.\", cores_of_package)\n\n        # read hyper-threading information (sibling cores sharing the same physical core)\n        siblings_of_core = {}\n        for core in allCpus:\n            siblings = util.parse_int_list(util.read_file('/sys/devices/system/cpu/cpu{0}/topology/thread_siblings_list'.format(core)))\n            siblings_of_core[core] = siblings\n        logging.debug(\"Siblings of cores are %s.\", siblings_of_core)\n    except ValueError as e:\n        sys.exit(\"Could not read CPU information from kernel: {0}\".format(e))\n\n    return _get_cpu_cores_per_run0(coreLimit, num_of_threads, allCpus, cores_of_package, siblings_of_core)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets an assignment of memory banks to runs that fits to the given coreAssignment.", "response": "def get_memory_banks_per_run(coreAssignment, cgroups):\n    \"\"\"Get an assignment of memory banks to runs that fits to the given coreAssignment,\n    i.e., no run is allowed to use memory that is not local (on the same NUMA node)\n    to one of its CPU cores.\"\"\"\n    try:\n        # read list of available memory banks\n        allMems = set(cgroups.read_allowed_memory_banks())\n\n        result = []\n        for cores in coreAssignment:\n            mems = set()\n            for core in cores:\n                coreDir = '/sys/devices/system/cpu/cpu{0}/'.format(core)\n                mems.update(_get_memory_banks_listed_in_dir(coreDir))\n            allowedMems = sorted(mems.intersection(allMems))\n            logging.debug(\"Memory banks for cores %s are %s, of which we can use %s.\", cores, list(mems), allowedMems)\n\n            result.append(allowedMems)\n\n        assert len(result) == len(coreAssignment)\n\n        if any(result) and os.path.isdir('/sys/devices/system/node/'):\n            return result\n        else:\n            # All runs get the empty list of memory regions\n            # because this system has no NUMA support\n            return None\n    except ValueError as e:\n        sys.exit(\"Could not read memory information from kernel: {0}\".format(e))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget all memory banks the kernel lists in a given directory.", "response": "def _get_memory_banks_listed_in_dir(path):\n    \"\"\"Get all memory banks the kernel lists in a given directory.\n    Such a directory can be /sys/devices/system/node/ (contains all memory banks)\n    or /sys/devices/system/cpu/cpu*/ (contains all memory banks on the same NUMA node as that core).\"\"\"\n    # Such directories contain entries named \"node<id>\" for each memory bank\n    return [int(entry[4:]) for entry in os.listdir(path) if entry.startswith('node')]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking whether the desired amount of parallel benchmarks fits in the memory.", "response": "def check_memory_size(memLimit, num_of_threads, memoryAssignment, my_cgroups):\n    \"\"\"Check whether the desired amount of parallel benchmarks fits in the memory.\n    Implemented are checks for memory limits via cgroup controller \"memory\" and\n    memory bank restrictions via cgroup controller \"cpuset\",\n    as well as whether the system actually has enough memory installed.\n    @param memLimit: the memory limit in bytes per run\n    @param num_of_threads: the number of parallel benchmark executions\n    @param memoryAssignment: the allocation of memory banks to runs (if not present, all banks are assigned to all runs)\n    \"\"\"\n    try:\n        # Check amount of memory allowed via cgroups.\n        def check_limit(actualLimit):\n            if actualLimit < memLimit:\n                sys.exit(\"Cgroups allow only {} bytes of memory to be used, cannot execute runs with {} bytes of memory.\".format(actualLimit, memLimit))\n            elif actualLimit < memLimit * num_of_threads:\n                sys.exit(\"Cgroups allow only {} bytes of memory to be used, not enough for {} benchmarks with {} bytes each. Please reduce the number of threads\".format(actualLimit, num_of_threads, memLimit))\n\n        if not os.path.isdir('/sys/devices/system/node/'):\n            logging.debug(\"System without NUMA support in Linux kernel, ignoring memory assignment.\")\n            return\n\n        if cgroups.MEMORY in my_cgroups:\n            # We use the entries hierarchical_*_limit in memory.stat and not memory.*limit_in_bytes\n            # because the former may be lower if memory.use_hierarchy is enabled.\n            for key, value in my_cgroups.get_key_value_pairs(cgroups.MEMORY, 'stat'):\n                if key == 'hierarchical_memory_limit' or key == 'hierarchical_memsw_limit':\n                    check_limit(int(value))\n\n        # Get list of all memory banks, either from memory assignment or from system.\n        if not memoryAssignment:\n            if cgroups.CPUSET in my_cgroups:\n                allMems = my_cgroups.read_allowed_memory_banks()\n            else:\n                allMems = _get_memory_banks_listed_in_dir('/sys/devices/system/node/')\n            memoryAssignment = [allMems] * num_of_threads # \"fake\" memory assignment: all threads on all banks\n        else:\n            allMems = set(itertools.chain(*memoryAssignment))\n\n        memSizes = dict((mem, _get_memory_bank_size(mem)) for mem in allMems)\n    except ValueError as e:\n        sys.exit(\"Could not read memory information from kernel: {0}\".format(e))\n\n    # Check whether enough memory is allocatable on the assigned memory banks.\n    # As the sum of the sizes of the memory banks is at most the total size of memory in the system,\n    # and we do this check always even if the banks are not restricted,\n    # this also checks whether the system has actually enough memory installed.\n    usedMem = collections.Counter()\n    for mems_of_run in memoryAssignment:\n        totalSize = sum(memSizes[mem] for mem in mems_of_run)\n        if totalSize < memLimit:\n            sys.exit(\"Memory banks {} do not have enough memory for one run, only {} bytes available.\".format(mems_of_run, totalSize))\n        usedMem[tuple(mems_of_run)] += memLimit\n        if usedMem[tuple(mems_of_run)] > totalSize:\n            sys.exit(\"Memory banks {} do not have enough memory for all runs, only {} bytes available. Please reduce the number of threads.\".format(mems_of_run, totalSize))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the size of a memory bank in bytes.", "response": "def _get_memory_bank_size(memBank):\n    \"\"\"Get the size of a memory bank in bytes.\"\"\"\n    fileName = '/sys/devices/system/node/node{0}/meminfo'.format(memBank)\n    size = None\n    with open(fileName) as f:\n        for line in f:\n            if 'MemTotal' in line:\n                size = line.split(':')[1].strip()\n                if size[-3:] != ' kB':\n                    raise ValueError('\"{}\" in file {} is not a memory size.'.format(size, fileName))\n                size = int(size[:-3]) * 1024 # kernel uses KiB but names them kB, convert to Byte\n                logging.debug(\"Memory bank %s has size %s bytes.\", memBank, size)\n                return size\n    raise ValueError('Failed to read total memory from {}.'.format(fileName))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef determine_result(self, returncode, returnsignal, output, isTimeout):\n        splitout = \"\\n\".join(output)\n        if 'SMACK found no errors' in splitout:\n          return result.RESULT_TRUE_PROP\n        errmsg = re.search(r'SMACK found an error(:\\s+([^\\.]+))?\\.', splitout)\n        if errmsg:\n          errtype = errmsg.group(2)\n          if errtype:\n            if 'invalid pointer dereference' == errtype:\n              return result.RESULT_FALSE_DEREF\n            elif 'invalid memory deallocation' == errtype:\n              return result.RESULT_FALSE_FREE\n            elif 'memory leak' == errtype:\n              return result.RESULT_FALSE_MEMTRACK\n            elif 'memory cleanup' == errtype:\n              return result.RESULT_FALSE_MEMCLEANUP\n            elif 'integer overflow' == errtype:\n              return result.RESULT_FALSE_OVERFLOW\n          else:\n            return result.RESULT_FALSE_REACH\n        return result.RESULT_UNKNOWN", "response": "Determine the result of a BenchExec command."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef determine_result(self, returncode, returnsignal, output, isTimeout):\n\n        if not output:\n            return 'ERROR - no output'\n\n        last = output[-1]\n\n        if isTimeout:\n            return 'TIMEOUT'\n\n        if returncode != 0:\n            return 'ERROR - {0}'.format( last )\n\n        if 'result:' in last:\n            res = last.split(':', maxsplit=1)[1].strip()\n            return self.RESMAP.get( res, result.RESULT_UNKNOWN );\n        else:\n            return 'UNKNOWN ERROR'", "response": "This method is used to determine the verification result of a specific user."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhandles the options specified by add_basic_container_args.", "response": "def handle_basic_container_args(options, parser=None):\n    \"\"\"Handle the options specified by add_basic_container_args().\n    @return: a dict that can be used as kwargs for the ContainerExecutor constructor\n    \"\"\"\n    dir_modes = {}\n    error_fn = parser.error if parser else sys.exit\n\n    def handle_dir_mode(path, mode):\n        path = os.path.abspath(path)\n        if not os.path.isdir(path):\n            error_fn(\n                \"Cannot specify directory mode for '{}' because it does not exist or is no directory.\"\n                .format(path))\n        if path in dir_modes:\n            error_fn(\"Cannot specify multiple directory modes for '{}'.\".format(path))\n        dir_modes[path] = mode\n\n    for path in options.hidden_dir:\n        handle_dir_mode(path, DIR_HIDDEN)\n    for path in options.read_only_dir:\n        handle_dir_mode(path, DIR_READ_ONLY)\n    for path in options.overlay_dir:\n        handle_dir_mode(path, DIR_OVERLAY)\n    for path in options.full_access_dir:\n        handle_dir_mode(path, DIR_FULL_ACCESS)\n\n    if options.keep_tmp:\n        if \"/tmp\" in dir_modes and not dir_modes[\"/tmp\"] == DIR_FULL_ACCESS:\n            error_fn(\"Cannot specify both --keep-tmp and --hidden-dir /tmp.\")\n        dir_modes[\"/tmp\"] = DIR_FULL_ACCESS\n    elif not \"/tmp\" in dir_modes:\n        dir_modes[\"/tmp\"] = DIR_HIDDEN\n\n    if not \"/\" in dir_modes:\n        dir_modes[\"/\"] = DIR_OVERLAY\n    if not \"/run\" in dir_modes:\n        dir_modes[\"/run\"] = DIR_HIDDEN\n\n    if options.container_system_config:\n        if options.network_access:\n            logging.warning(\"The container configuration disables DNS, \"\n                \"host lookups will fail despite --network-access. \"\n                \"Consider using --keep-system-config.\")\n    else:\n        # /etc/resolv.conf is necessary for DNS lookups and on many systems is a symlink\n        # to either /run/resolvconf/resolv.conf or /run/systemd/resolve/sub-resolve.conf,\n        # so we keep that directory accessible as well.\n        if not \"/run/resolvconf\" in dir_modes and os.path.isdir(\"/run/resolvconf\"):\n            dir_modes[\"/run/resolvconf\"] = DIR_READ_ONLY\n        if not \"/run/systemd/resolve\" in dir_modes and os.path.isdir(\"/run/systemd/resolve\"):\n            dir_modes[\"/run/systemd/resolve\"] = DIR_READ_ONLY\n\n    return {\n        'network_access': options.network_access,\n        'container_tmpfs': options.tmpfs,\n        'container_system_config': options.container_system_config,\n        'dir_modes': dir_modes,\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndefines command - line arguments for output of a container.", "response": "def add_container_output_args(argument_parser):\n    \"\"\"Define command-line arguments for output of a container (result files).\n    @param argument_parser: an argparse parser instance\n    \"\"\"\n    argument_parser.add_argument(\"--output-directory\", metavar=\"DIR\", default=\"output.files\",\n        help=\"target directory for result files (default: './output.files')\")\n    argument_parser.add_argument(\"--result-files\", metavar=\"PATTERN\", action=\"append\", default=[],\n        help=\"pattern for specifying which result files should be copied to the output directory \"\n            \"(default: '.')\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef handle_container_output_args(options, parser):\n    if options.result_files:\n        result_files_patterns = [os.path.normpath(p) for p in options.result_files if p]\n        for pattern in result_files_patterns:\n            if pattern.startswith(\"..\"):\n                parser.error(\"Invalid relative result-files pattern '{}'.\".format(pattern))\n    else:\n        result_files_patterns = [\".\"]\n\n    output_dir = options.output_directory\n    if os.path.exists(output_dir) and not os.path.isdir(output_dir):\n        parser.error(\"Output directory '{}' must not refer to an existing file.\".format(output_dir))\n    return {\n        'output_dir': output_dir,\n        'result_files_patterns': result_files_patterns,\n        }", "response": "Handle the options specified by add_container_output_args().\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef main(argv=None):\n    if argv is None:\n        argv = sys.argv\n\n    # parse options\n    parser = argparse.ArgumentParser(\n        fromfile_prefix_chars='@',\n        description=\n        \"\"\"Execute a command inside a simple container, i.e., partially isolated from the host.\n           Command-line parameters can additionally be read from a file if file name prefixed with '@' is given as argument.\n           Part of BenchExec: https://github.com/sosy-lab/benchexec/\"\"\")\n    parser.add_argument(\"--dir\", metavar=\"DIR\",\n                        help=\"working directory for executing the command (default is current directory)\")\n    parser.add_argument(\"--root\", action=\"store_true\",\n                        help=\"use UID 0 and GID 0 (i.e., fake root account) within container\")\n    parser.add_argument(\"--uid\", metavar=\"UID\", type=int, default=None,\n                        help=\"use given UID within container (default: current UID)\")\n    parser.add_argument(\"--gid\", metavar=\"GID\", type=int, default=None,\n                        help=\"use given GID within container (default: current UID)\")\n    add_basic_container_args(parser)\n    add_container_output_args(parser)\n    baseexecutor.add_basic_executor_options(parser)\n\n    options = parser.parse_args(argv[1:])\n    baseexecutor.handle_basic_executor_options(options, parser)\n    container_options = handle_basic_container_args(options, parser)\n    container_output_options = handle_container_output_args(options, parser)\n\n    if options.root:\n        if options.uid is not None or options.gid is not None:\n            parser.error(\"Cannot combine option --root with --uid/--gid\")\n        options.uid = 0\n        options.gid = 0\n\n    formatted_args = \" \".join(map(util.escape_string_shell, options.args))\n    logging.info('Starting command %s', formatted_args)\n\n    executor = ContainerExecutor(uid=options.uid, gid=options.gid, **container_options)\n\n    # ensure that process gets killed on interrupt/kill signal\n    def signal_handler_kill(signum, frame):\n        executor.stop()\n    signal.signal(signal.SIGTERM, signal_handler_kill)\n    signal.signal(signal.SIGINT,  signal_handler_kill)\n\n    # actual run execution\n    try:\n        result = executor.execute_run(options.args, workingDir=options.dir,\n                                      **container_output_options)\n    except (BenchExecException, OSError) as e:\n        if options.debug:\n            logging.exception(e)\n        sys.exit(\"Cannot execute {0}: {1}.\".format(util.escape_string_shell(options.args[0]), e))\n    return result.signal or result.value", "response": "A simple command - line interface for the containerexecutor module of BenchExec."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives the temp directory that is created for each run return the path to the directory where files created by the tool are stored.", "response": "def _get_result_files_base(self, temp_dir):\n        \"\"\"Given the temp directory that is created for each run, return the path to the directory\n        where files created by the tool are stored.\"\"\"\n        if not self._use_namespaces:\n            return super(ContainerExecutor, self)._get_result_files_base(temp_dir)\n        else:\n            return os.path.join(temp_dir, \"temp\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexecuting the given command and measure its resource usage in a container.", "response": "def _start_execution_in_container(\n            self, args, stdin, stdout, stderr, env, root_dir, cwd, temp_dir,\n            memlimit, memory_nodes,\n            cgroups, output_dir, result_files_patterns, parent_setup_fn,\n            child_setup_fn, parent_cleanup_fn):\n        \"\"\"Execute the given command and measure its resource usage similarly to super()._start_execution(),\n        but inside a container implemented using Linux namespaces.\n        The command has no network access (only loopback),\n        a fresh directory as /tmp and no write access outside of this,\n        and it does not see other processes except itself.\n        \"\"\"\n        assert self._use_namespaces\n\n        if root_dir is None:\n            env.update(self._env_override)\n\n        args = self._build_cmdline(args, env=env)\n\n        # We have three processes involved:\n        # parent: the current Python process in which RunExecutor is executing\n        # child: child process in new namespace (PID 1 in inner namespace),\n        #        configures inner namespace, serves as dummy init,\n        #        collects result of grandchild and passes it to parent\n        # grandchild: child of child process (PID 2 in inner namespace), exec()s tool\n\n        # We need the following communication steps between these proceses:\n        # 1a) grandchild tells parent its PID (in outer namespace).\n        # 1b) grandchild tells parent that it is ready and measurement should begin.\n        # 2) parent tells grandchild that measurement has begun and tool should\n        #    be exec()ed.\n        # 3) child tells parent about return value and resource consumption of grandchild.\n        # 1a and 1b are done together by sending the PID through a pipe.\n        # 2 is done by sending a null byte through a pipe.\n        # 3 is done by sending a pickled object through the same pipe as #2.\n        # We cannot use the same pipe for both directions, because otherwise a sender might\n        # read the bytes it has sent itself.\n\n        # Error codes from child to parent\n        CHILD_OSERROR = 128\n        CHILD_UNKNOWN_ERROR = 129\n\n        from_parent, to_grandchild = os.pipe() # \"downstream\" pipe parent->grandchild\n        from_grandchild, to_parent = os.pipe() # \"upstream\" pipe grandchild/child->parent\n\n        # The protocol for these pipes is that first the parent sends the marker for user mappings,\n        # then the grand child sends its outer PID back,\n        # and finally the parent sends its completion marker.\n        # After the run, the child sends the result of the grand child and then waits\n        # until the pipes are closed, before it terminates.\n        MARKER_USER_MAPPING_COMPLETED = b'A'\n        MARKER_PARENT_COMPLETED = b'B'\n\n        # If the current directory is within one of the bind mounts we create,\n        # we need to cd into this directory again, otherwise we would not see the bind mount,\n        # but the directory behind it. Thus we always set cwd to force a change of directory.\n        if root_dir is None:\n            cwd = os.path.abspath(cwd or os.curdir)\n        else:\n            root_dir = os.path.abspath(root_dir)\n            cwd = os.path.abspath(cwd)\n\n        def grandchild():\n            \"\"\"Setup everything inside the process that finally exec()s the tool.\"\"\"\n            try:\n                # We know that this process has PID 2 in the inner namespace,\n                # but we actually need to know its PID in the outer namespace\n                # such that parent can put us into the correct cgroups.\n                # According to http://man7.org/linux/man-pages/man7/pid_namespaces.7.html,\n                # there are two ways to achieve this: sending a message with the PID\n                # via a socket (but Python < 3.3 lacks a convenient API for sendmsg),\n                # and reading /proc/self in the outer procfs instance (that's what we do).\n                my_outer_pid = container.get_my_pid_from_procfs()\n\n                container.mount_proc()\n                container.drop_capabilities()\n                container.reset_signal_handling()\n                child_setup_fn() # Do some other setup the caller wants.\n\n                # Signal readiness to parent by sending our PID and wait until parent is also ready\n                os.write(to_parent, str(my_outer_pid).encode())\n                received = os.read(from_parent, 1)\n                assert received == MARKER_PARENT_COMPLETED, received\n            finally:\n                # close remaining ends of pipe\n                os.close(from_parent)\n                os.close(to_parent)\n            # here Python will exec() the tool for us\n\n        def child():\n            \"\"\"Setup everything inside the container, start the tool, and wait for result.\"\"\"\n            try:\n                logging.debug(\"Child: child process of RunExecutor with PID %d started\",\n                              container.get_my_pid_from_procfs())\n\n                # Put all received signals on hold until we handle them later.\n                container.block_all_signals()\n\n                # We want to avoid leaking file descriptors to the executed child.\n                # It is also nice if the child has only the minimal necessary file descriptors,\n                # to avoid keeping other pipes and files open, e.g., those that the parent\n                # uses to communicate with other containers (if containers are started in parallel).\n                # Thus we do not use the close_fds feature of subprocess.Popen,\n                # but do the same here manually.\n                # We keep the relevant ends of our pipes, and stdin/out/err of child and grandchild.\n                necessary_fds = {sys.stdin, sys.stdout, sys.stderr,\n                    to_parent, from_parent, stdin, stdout, stderr} - {None}\n                container.close_open_fds(keep_files=necessary_fds)\n\n                try:\n                    if self._container_system_config:\n                        # A standard hostname increases reproducibility.\n                        libc.sethostname(container.CONTAINER_HOSTNAME)\n\n                    if not self._allow_network:\n                        container.activate_network_interface(\"lo\")\n\n                    # Wait until user mapping is finished, this is necessary for filesystem writes\n                    received = os.read(from_parent, len(MARKER_USER_MAPPING_COMPLETED))\n                    assert received == MARKER_USER_MAPPING_COMPLETED, received\n\n                    if root_dir is not None:\n                        self._setup_root_filesystem(root_dir)\n                    else:\n                        self._setup_container_filesystem(\n                            temp_dir,\n                            output_dir if result_files_patterns else None,\n                            memlimit,\n                            memory_nodes)\n                except EnvironmentError as e:\n                    logging.critical(\"Failed to configure container: %s\", e)\n                    return CHILD_OSERROR\n\n                try:\n                    os.chdir(cwd)\n                except EnvironmentError as e:\n                    logging.critical(\n                        \"Cannot change into working directory inside container: %s\", e)\n                    return CHILD_OSERROR\n\n                try:\n                    grandchild_proc = subprocess.Popen(args,\n                                        stdin=stdin,\n                                        stdout=stdout, stderr=stderr,\n                                        env=env,\n                                        close_fds=False,\n                                        preexec_fn=grandchild)\n                except (EnvironmentError, RuntimeError) as e:\n                    logging.critical(\"Cannot start process: %s\", e)\n                    return CHILD_OSERROR\n\n                # keep capability for unmount if necessary later\n                necessary_capabilities = [libc.CAP_SYS_ADMIN] if result_files_patterns else []\n                container.drop_capabilities(keep=necessary_capabilities)\n\n                # Close other fds that were still necessary above.\n                container.close_open_fds(keep_files={sys.stdout, sys.stderr, to_parent, from_parent})\n\n                # Set up signal handlers to forward signals to grandchild\n                # (because we are PID 1, there is a special signal handling otherwise).\n                # cf. dumb-init project: https://github.com/Yelp/dumb-init\n                # Also wait for grandchild and return its result.\n                if _HAS_SIGWAIT:\n                    grandchild_result = container.wait_for_child_and_forward_all_signals(\n                        grandchild_proc.pid, args[0])\n                else:\n                    container.forward_all_signals_async(grandchild_proc.pid, args[0])\n                    grandchild_result = self._wait_for_process(grandchild_proc.pid, args[0])\n\n                logging.debug(\"Child: process %s terminated with exit code %d.\",\n                              args[0], grandchild_result[0])\n\n                if result_files_patterns:\n                    # Remove the bind mount that _setup_container_filesystem added\n                    # such that the parent can access the result files.\n                    libc.umount(temp_dir.encode())\n\n                os.write(to_parent, pickle.dumps(grandchild_result))\n                os.close(to_parent)\n\n                # Now the parent copies the output files, we need to wait until this is finished.\n                # If the child terminates, the container file system and its tmpfs go away.\n                os.read(from_parent, 1)\n                os.close(from_parent)\n\n                return 0\n            except EnvironmentError as e:\n                logging.exception(\"Error in child process of RunExecutor\")\n                return CHILD_OSERROR\n            except:\n                # Need to catch everything because this method always needs to return a int\n                # (we are inside a C callback that requires returning int).\n                logging.exception(\"Error in child process of RunExecutor\")\n                return CHILD_UNKNOWN_ERROR\n\n        try: # parent\n            try:\n                child_pid = container.execute_in_namespace(child, use_network_ns=not self._allow_network)\n            except OSError as e:\n                raise BenchExecException(\n                    \"Creating namespace for container mode failed: \" + os.strerror(e.errno))\n            logging.debug(\"Parent: child process of RunExecutor with PID %d started.\", child_pid)\n\n            def check_child_exit_code():\n                \"\"\"Check if the child process terminated cleanly and raise an error otherwise.\"\"\"\n                child_exitcode, unused_child_rusage = self._wait_for_process(child_pid, args[0])\n                child_exitcode = util.ProcessExitCode.from_raw(child_exitcode)\n                logging.debug(\"Parent: child process of RunExecutor with PID %d terminated with %s.\",\n                              child_pid, child_exitcode)\n\n                if child_exitcode:\n                    if child_exitcode.value:\n                        if child_exitcode.value == CHILD_OSERROR:\n                            # This was an OSError in the child, details were already logged\n                            raise BenchExecException(\"execution in container failed, check log for details\")\n                        elif child_exitcode.value == CHILD_UNKNOWN_ERROR:\n                            raise BenchExecException(\"unexpected error in container\")\n                        raise OSError(child_exitcode.value, os.strerror(child_exitcode.value))\n                    raise OSError(0, \"Child process of RunExecutor terminated with \" + str(child_exitcode))\n\n            # Close unnecessary ends of pipes such that read() does not block forever\n            # if all other processes have terminated.\n            os.close(from_parent)\n            os.close(to_parent)\n\n            container.setup_user_mapping(child_pid, uid=self._uid, gid=self._gid)\n            os.write(to_grandchild, MARKER_USER_MAPPING_COMPLETED) # signal child to continue\n\n            try:\n                grandchild_pid = int(os.read(from_grandchild, 10)) # 10 bytes is enough for 32bit int\n            except ValueError:\n                # probably empty read, i.e., pipe closed, i.e., child or grandchild failed\n                check_child_exit_code()\n                assert False, \"Child process of RunExecutor terminated cleanly but did not send expected data.\"\n\n            logging.debug(\"Parent: executing %s in grand child with PID %d via child with PID %d.\",\n                          args[0], grandchild_pid, child_pid)\n\n            # start measurements\n            cgroups.add_task(grandchild_pid)\n            parent_setup = parent_setup_fn()\n\n            # Signal grandchild that setup is finished\n            os.write(to_grandchild, MARKER_PARENT_COMPLETED)\n\n            # Copy file descriptor, otherwise we could not close from_grandchild in finally block\n            # and would leak a file descriptor in case of exception.\n            from_grandchild_copy = os.dup(from_grandchild)\n            to_grandchild_copy = os.dup(to_grandchild)\n        finally:\n            os.close(from_grandchild)\n            os.close(to_grandchild)\n\n        def wait_for_grandchild():\n            # 1024 bytes ought to be enough for everyone^Wour pickled result\n            try:\n                received = os.read(from_grandchild_copy, 1024)\n            except OSError as e:\n                if self.PROCESS_KILLED and e.errno == errno.EINTR:\n                    # Read was interrupted because of Ctrl+C, we just try again\n                    received = os.read(from_grandchild_copy, 1024)\n                else:\n                    raise e\n            exitcode, ru_child = pickle.loads(received)\n\n            base_path = \"/proc/{}/root\".format(child_pid)\n            parent_cleanup = parent_cleanup_fn(\n                parent_setup, util.ProcessExitCode.from_raw(exitcode), base_path)\n\n            if result_files_patterns:\n                # As long as the child process exists we can access the container file system here\n                self._transfer_output_files(\n                    base_path + temp_dir,\n                    cwd,\n                    output_dir,\n                    result_files_patterns)\n\n            os.close(from_grandchild_copy)\n            os.close(to_grandchild_copy) # signal child that it can terminate\n            check_child_exit_code()\n\n            return exitcode, ru_child, parent_cleanup\n\n        return grandchild_pid, wait_for_grandchild"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _setup_container_filesystem(self, temp_dir, output_dir, memlimit, memory_nodes):\n        # All strings here are bytes to avoid issues if existing mountpoints are invalid UTF-8.\n        temp_base = self._get_result_files_base(temp_dir).encode() # directory with files created by tool\n        temp_dir = temp_dir.encode()\n\n        tmpfs_opts = [\"size=\" + str(memlimit or \"100%\")]\n        if memory_nodes:\n            tmpfs_opts.append(\"mpol=bind:\" + \",\".join(map(str, memory_nodes)))\n        tmpfs_opts = (\",\".join(tmpfs_opts)).encode()\n        if self._container_tmpfs:\n            libc.mount(None, temp_dir, b\"tmpfs\", 0, tmpfs_opts)\n\n        mount_base = os.path.join(temp_dir, b\"mount\") # base dir for container mounts\n        os.mkdir(mount_base)\n        os.mkdir(temp_base)\n\n        def _is_below(path, target_path):\n            # compare with trailing slashes for cases like /foo and /foobar\n            path = os.path.join(path, b\"\")\n            target_path = os.path.join(target_path, b\"\")\n            return path.startswith(target_path)\n\n        def find_mode_for_dir(path, fstype=None):\n            if (path == b\"/proc\"):\n                # /proc is necessary for the grandchild to read PID, will be replaced later.\n                return DIR_READ_ONLY\n            if _is_below(path, b\"/proc\"):\n                # Irrelevant.\n                return None\n\n            parent_mode = None\n            result_mode = None\n            for special_dir, mode in self._dir_modes.items():\n                if _is_below(path, special_dir):\n                    if path != special_dir:\n                        parent_mode = mode\n                    result_mode = mode\n            assert result_mode is not None\n\n            if result_mode == DIR_OVERLAY and (\n                    _is_below(path, b\"/dev\") or\n                    _is_below(path, b\"/sys\") or\n                    fstype == b\"cgroup\"):\n                # Overlay does not make sense for /dev, /sys, and all cgroups.\n                return DIR_READ_ONLY\n\n            if result_mode == DIR_OVERLAY and (\n                    fstype == b\"autofs\" or\n                    fstype == b\"vfat\" or\n                    fstype == b\"ntfs\"):\n                # Overlayfs does not support these as underlying file systems.\n                logging.debug(\"Cannot use overlay mode for %s because it has file system %s. \"\n                              \"Using read-only mode instead.\",\n                              path.decode(), fstype.decode())\n                return DIR_READ_ONLY\n\n            if result_mode == DIR_HIDDEN and parent_mode == DIR_HIDDEN:\n                # No need to recursively recreate mountpoints in hidden dirs.\n                return None\n            return result_mode\n\n        # Overlayfs needs its own additional temporary directory (\"work\" directory).\n        # temp_base will be the \"upper\" layer, the host FS the \"lower\" layer,\n        # and mount_base the mount target.\n        work_base = os.path.join(temp_dir, b\"overlayfs\")\n        os.mkdir(work_base)\n\n        # Create a copy of host's mountpoints.\n        # Setting MS_PRIVATE flag discouples our mount namespace from the hosts's,\n        # i.e., mounts we do are not seen by the host, and any (un)mounts the host does afterward\n        # are not seen by us. The latter is desired such that new mounts (e.g.,\n        # USB sticks being plugged in) do not appear in the container.\n        # Blocking host-side unmounts from being propagated has the disadvantage\n        # that any unmounts done by the sysadmin won't really unmount the device\n        # because it stays mounted in the container and thus keep the device busy\n        # (cf. https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=739593#85).\n        # We could allow unmounts being propated with MS_SLAVE instead of MS_PRIVATE,\n        # but we prefer to have the mount namespace of the container being\n        # unchanged during run execution.\n        container.make_bind_mount(b\"/\", mount_base, recursive=True, private=True)\n\n        # Ensure each special dir is a mountpoint such that the next loop covers it.\n        for special_dir in self._dir_modes.keys():\n            mount_path = mount_base + special_dir\n            temp_path = temp_base + special_dir\n            try:\n                container.make_bind_mount(mount_path, mount_path)\n            except OSError as e:\n                # on btrfs, non-recursive bind mounts faitl\n                if e.errno == errno.EINVAL:\n                    try:\n                        container.make_bind_mount(mount_path, mount_path, recursive=True)\n                    except OSError as e2:\n                        logging.debug(\"Failed to make %s a (recursive) bind mount: %s\", mount_path, e2)\n                else:\n                    logging.debug(\"Failed to make %s a bind mount: %s\", mount_path, e)\n            if not os.path.exists(temp_path):\n                os.makedirs(temp_path)\n\n        # Set desired access mode for each mountpoint.\n        for unused_source, full_mountpoint, fstype, options in list(container.get_mount_points()):\n            if not _is_below(full_mountpoint, mount_base):\n                continue\n            mountpoint = full_mountpoint[len(mount_base):] or b\"/\"\n            mode = find_mode_for_dir(mountpoint, fstype)\n            if not mode:\n                continue\n\n            if not os.access(os.path.dirname(mountpoint), os.X_OK):\n                # If parent is not accessible we cannot mount something on mountpoint.\n                # We mark the inaccessible directory as hidden because otherwise the mountpoint\n                # could become accessible (directly!) if the permissions on the parent\n                # are relaxed during container execution.\n                original_mountpoint = mountpoint\n                parent = os.path.dirname(mountpoint)\n                while not os.access(parent, os.X_OK):\n                    mountpoint = parent\n                    parent = os.path.dirname(mountpoint)\n                mode = DIR_HIDDEN\n                logging.debug(\n                    \"Marking inaccessible directory '%s' as hidden \"\n                    \"because it contains a mountpoint at '%s'\",\n                    mountpoint.decode(), original_mountpoint.decode())\n            else:\n                logging.debug(\"Mounting '%s' as %s\", mountpoint.decode(), mode)\n\n            mount_path = mount_base + mountpoint\n            temp_path = temp_base + mountpoint\n            work_path = work_base + mountpoint\n\n            if mode == DIR_OVERLAY:\n                if not os.path.exists(temp_path):\n                    os.makedirs(temp_path)\n                if not os.path.exists(work_path):\n                    os.makedirs(work_path)\n                try:\n                    # Previous mount in this place not needed if replaced with overlay dir.\n                    libc.umount(mount_path)\n                except OSError as e:\n                    logging.debug(e)\n                try:\n                    container.make_overlay_mount(mount_path, mountpoint, temp_path, work_path)\n                except OSError as e:\n                    raise OSError(e.errno,\n                        \"Creating overlay mount for '{}' failed: {}. \"\n                        \"Please use other directory modes.\"\n                            .format(mountpoint.decode(), os.strerror(e.errno)))\n\n            elif mode == DIR_HIDDEN:\n                if not os.path.exists(temp_path):\n                    os.makedirs(temp_path)\n                try:\n                    # Previous mount in this place not needed if replaced with hidden dir.\n                    libc.umount(mount_path)\n                except OSError as e:\n                    logging.debug(e)\n                container.make_bind_mount(temp_path, mount_path)\n\n            elif mode == DIR_READ_ONLY:\n                try:\n                    container.remount_with_additional_flags(mount_path, options, libc.MS_RDONLY)\n                except OSError as e:\n                    if e.errno == errno.EACCES:\n                        logging.warning(\n                            \"Cannot mount '%s', directory may be missing from container.\",\n                            mountpoint.decode())\n                    else:\n                        # If this mountpoint is below an overlay/hidden dir re-create mountpoint.\n                        # Linux does not support making read-only bind mounts in one step:\n                        # https://lwn.net/Articles/281157/ http://man7.org/linux/man-pages/man8/mount.8.html\n                        container.make_bind_mount(\n                            mountpoint, mount_path, recursive=True, private=True)\n                        container.remount_with_additional_flags(mount_path, options, libc.MS_RDONLY)\n\n            elif mode == DIR_FULL_ACCESS:\n                try:\n                    # Ensure directory is still a mountpoint by attempting to remount.\n                    container.remount_with_additional_flags(mount_path, options, 0)\n                except OSError as e:\n                    if e.errno == errno.EACCES:\n                        logging.warning(\n                            \"Cannot mount '%s', directory may be missing from container.\",\n                            mountpoint.decode())\n                    else:\n                        # If this mountpoint is below an overlay/hidden dir re-create mountpoint.\n                        container.make_bind_mount(\n                            mountpoint, mount_path, recursive=True, private=True)\n\n            else:\n                assert False\n\n        # Now configure some special hard-coded cases\n\n        def make_tmpfs_dir(path):\n            \"\"\"Ensure that a tmpfs is mounted on path, if the path exists\"\"\"\n            if path in self._dir_modes:\n                return # explicitly configured by user\n            mount_tmpfs = mount_base + path\n            temp_tmpfs = temp_base + path\n            util.makedirs(temp_tmpfs, exist_ok=True)\n            if os.path.isdir(mount_tmpfs):\n                # If we already have a tmpfs, we can just bind mount it, otherwise we need one\n                if self._container_tmpfs:\n                    container.make_bind_mount(temp_tmpfs, mount_tmpfs)\n                else:\n                    libc.mount(None, mount_tmpfs, b\"tmpfs\", 0, tmpfs_opts)\n\n        # The following directories should be writable RAM disks for Posix shared memory.\n        # For example, the Python multiprocessing module explicitly checks for a tmpfs instance.\n        make_tmpfs_dir(b\"/dev/shm\")\n        make_tmpfs_dir(b\"/run/shm\")\n\n        if self._container_system_config:\n            # If overlayfs is not used for /etc, we need additional bind mounts\n            # for files in /etc that we want to override, like /etc/passwd\n            config_mount_base = mount_base if find_mode_for_dir(b\"/etc\") != DIR_OVERLAY else None\n            container.setup_container_system_config(temp_base, config_mount_base )\n\n        if output_dir:\n            # We need a way to see temp_base in the container in order to be able to copy result\n            # files out of it, so we need a directory that is guaranteed to exist in order to use\n            # it as mountpoint for a bind mount to temp_base.\n            # Of course, the tool inside the container should not have access to temp_base,\n            # so we will add another bind mount with an empty directory on top\n            # (equivalent to --hidden-dir). After the tool terminates we can unmount\n            # the top-level bind mount and then access temp_base. However, this works only\n            # if there is no other mount point below that directory, and the user can force us\n            # to create mount points at arbitrary directory if a directory mode is specified.\n            # So we need an existing directory with no mount points below, and luckily temp_dir\n            # fulfills all requirements (because we have just created it as fresh drectory ourselves).\n            # So we mount temp_base outside of the container to temp_dir inside.\n            util.makedirs(mount_base + temp_dir, exist_ok=True)\n            container.make_bind_mount(temp_base, mount_base + temp_dir, read_only=True)\n            # And the following if branch will automatically hide the bind\n            # mount below an empty directory.\n\n        # If necessary, (i.e., if /tmp is not already hidden),\n        # hide the directory where we store our files from processes in the container\n        # by mounting an empty directory over it.\n        if os.path.exists(mount_base + temp_dir):\n            util.makedirs(temp_base + temp_dir, exist_ok=True)\n            container.make_bind_mount(temp_base + temp_dir, mount_base + temp_dir)\n\n        os.chroot(mount_base)", "response": "Setup the filesystem layout in the container."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _setup_root_filesystem(self, root_dir):\n        root_dir = root_dir.encode()\n\n        # Create an empty proc folder into the root dir. The grandchild still needs a view of\n        # the old /proc, therefore we do not mount a fresh /proc here.\n        proc_base = os.path.join(root_dir, b\"proc\")\n        util.makedirs(proc_base, exist_ok=True)\n\n        dev_base = os.path.join(root_dir, b\"dev\")\n        util.makedirs(dev_base, exist_ok=True)\n\n        # Create a copy of the host's dev- and proc-mountpoints.\n        # They are marked as private in order to not being changed\n        # by existing mounts during run execution.\n        container.make_bind_mount(b\"/dev/\", dev_base, recursive=True, private=True)\n        container.make_bind_mount(b\"/proc/\", proc_base, recursive=True, private=True)\n\n        os.chroot(root_dir)", "response": "Setup the filesystem layout in the given root directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntransfers files created by the tool in the container to the output directory.", "response": "def _transfer_output_files(self, tool_output_dir, working_dir, output_dir, patterns):\n        \"\"\"Transfer files created by the tool in the container to the output directory.\n        @param tool_output_dir: The directory under which all tool output files are created.\n        @param working_dir: The absolute working directory of the tool in the container.\n        @param output_dir: the directory where to write result files\n        @param patterns: a list of patterns of files to retrieve as result files\n        \"\"\"\n        assert output_dir and patterns\n        if any(os.path.isabs(pattern) for pattern in patterns):\n            base_dir = tool_output_dir\n        else:\n            base_dir = tool_output_dir + working_dir\n\n        def transfer_file(abs_file):\n            assert abs_file.startswith(base_dir)\n\n            # We ignore (empty) directories, because we create them for hidden dirs etc.\n            # We ignore device nodes, because overlayfs creates them.\n            # We also ignore all other files (symlinks, fifos etc.),\n            # because they are probably irrelevant, and just handle regular files.\n            file = os.path.join(\"/\", os.path.relpath(abs_file, base_dir))\n            if (os.path.isfile(abs_file) and not os.path.islink(abs_file) and\n                    not container.is_container_system_config_file(file)):\n                target = output_dir + file\n                logging.debug(\"Transferring output file %s to %s\", abs_file, target)\n                try:\n                    os.makedirs(os.path.dirname(target))\n                except EnvironmentError:\n                    pass # exist_ok=True not supported on Python 2\n                try:\n                    # move is more efficient than copy in case both abs_file and target\n                    # are on the same filesystem, and it avoids matching the file again\n                    # with the next pattern.\n                    shutil.move(abs_file, target)\n                except EnvironmentError as e:\n                    logging.warning(\"Could not retrieve output file '%s': %s\", file, e)\n\n        for pattern in patterns:\n            if os.path.isabs(pattern):\n                pattern = tool_output_dir + pattern\n            else:\n                pattern = tool_output_dir + os.path.join(working_dir, pattern)\n            # normalize pattern for preventing directory traversal attacks:\n            for abs_file in util.maybe_recursive_iglob(os.path.normpath(pattern), recursive=True):\n                # Recursive matching is only supported starting with Python 3.5,\n                # so we allow the user to match directories and transfer them recursively.\n                if os.path.isdir(abs_file):\n                    for root, unused_dirs, files in os.walk(abs_file):\n                        for file in files:\n                            transfer_file(os.path.join(root, file))\n                else:\n                    transfer_file(abs_file)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread an parse the XML of a table - definition file. Read an XML of a table - definition file. Read an XML of a table - definition file. is the XML of the table - definition file. is the XML of the table - definition file. is the XML of the table - definition file.", "response": "def parse_table_definition_file(file):\n    '''\n    Read an parse the XML of a table-definition file.\n    @return: an ElementTree object for the table definition\n    '''\n    logging.info(\"Reading table definition from '%s'...\", file)\n    if not os.path.isfile(file):\n        logging.error(\"File '%s' does not exist.\", file)\n        exit(1)\n\n    try:\n        tableGenFile = ElementTree.ElementTree().parse(file)\n    except IOError as e:\n        logging.error('Could not read result file %s: %s', file, e)\n        exit(1)\n    except ElementTree.ParseError as e:\n        logging.error('Table file %s is invalid: %s', file, e)\n        exit(1)\n    if 'table' != tableGenFile.tag:\n        logging.error(\"Table file %s is invalid: It's root element is not named 'table'.\", file)\n        exit(1)\n    return tableGenFile"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_results_from_table_definition(table_definition, table_definition_file, options):\n    default_columns = extract_columns_from_table_definition_file(table_definition, table_definition_file)\n    columns_relevant_for_diff = _get_columns_relevant_for_diff(default_columns)\n\n    results = []\n    for tag in table_definition:\n        if tag.tag == 'result':\n            columns = extract_columns_from_table_definition_file(tag, table_definition_file) or default_columns\n            run_set_id = tag.get('id')\n            for resultsFile in get_file_list_from_result_tag(tag, table_definition_file):\n                results.append(parallel.submit(\n                    load_result, resultsFile, options, run_set_id, columns, columns_relevant_for_diff))\n\n        elif tag.tag == 'union':\n            results.append(parallel.submit(\n                handle_union_tag, tag, table_definition_file, options, default_columns, columns_relevant_for_diff))\n\n    return [future.result() for future in results]", "response": "Load all results in files that are listed in the given table - definition file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload results from given files with column definitions taken from a table - definition file.", "response": "def load_results_with_table_definition(result_files, table_definition, table_definition_file, options):\n    \"\"\"\n    Load results from given files with column definitions taken from a table-definition file.\n    @return: a list of RunSetResult objects\n    \"\"\"\n    columns = extract_columns_from_table_definition_file(table_definition, table_definition_file)\n    columns_relevant_for_diff = _get_columns_relevant_for_diff(columns)\n\n    return load_results(\n        result_files,\n        options=options,\n        columns=columns,\n        columns_relevant_for_diff=columns_relevant_for_diff)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef extract_columns_from_table_definition_file(xmltag, table_definition_file):\n    def handle_path(path):\n        \"\"\"Convert path from a path relative to table-definition file.\"\"\"\n        if not path or path.startswith(\"http://\") or path.startswith(\"https://\"):\n            return path\n        return os.path.join(os.path.dirname(table_definition_file), path)\n\n    columns = list()\n    for c in xmltag.findall('column'):\n        scale_factor = c.get(\"scaleFactor\")\n        display_unit = c.get(\"displayUnit\")\n        source_unit = c.get(\"sourceUnit\")\n\n        new_column = Column(c.get(\"title\"), c.text, c.get(\"numberOfDigits\"),\n                   handle_path(c.get(\"href\")), None, display_unit, source_unit,\n                   scale_factor, c.get(\"relevantForDiff\"), c.get(\"displayTitle\"))\n        columns.append(new_column)\n\n    return columns", "response": "Extract all columns mentioned in the result tag of a table definition file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_columns_relevant_for_diff(columns_to_show):\n    cols = set([col.title for col in columns_to_show if col.relevant_for_diff])\n    if len(cols) == 0:\n        return set(\n            [col.title for col in columns_to_show if col.title == \"status\"])\n    else:\n        return cols", "response": "Extract columns that are relevant for the diff table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a unique identifier for a given task.", "response": "def get_task_id(task, base_path_or_url):\n    \"\"\"\n    Return a unique identifier for a given task.\n    @param task: the XML element that represents a task\n    @return a tuple with filename of task as first element\n    \"\"\"\n    name = task.get('name')\n    if base_path_or_url:\n        if Util.is_url(base_path_or_url):\n            name = urllib.parse.urljoin(base_path_or_url, name)\n        else:\n            name = os.path.normpath(os.path.join(os.path.dirname(base_path_or_url), name))\n    task_id = [name,\n               task.get('properties'),\n               task.get('runset'),\n               ]\n    return tuple(task_id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_tool(result):\n    def load_tool_module(tool_module):\n        if not tool_module:\n            logging.warning('Cannot extract values from log files for benchmark results %s '\n                            '(missing attribute \"toolmodule\" on tag \"result\").',\n                            Util.prettylist(result.attributes['name']))\n            return None\n        try:\n            logging.debug('Loading %s', tool_module)\n            return __import__(tool_module, fromlist=['Tool']).Tool()\n        except ImportError as ie:\n            logging.warning(\n                'Missing module \"%s\", cannot extract values from log files (ImportError: %s).',\n                tool_module, ie)\n        except AttributeError:\n            logging.warning(\n                'The module \"%s\" does not define the necessary class Tool, '\n                'cannot extract values from log files.',\n                tool_module)\n        return None\n\n    tool_module = result.attributes['toolmodule'][0] if 'toolmodule' in result.attributes else None\n    if tool_module in loaded_tools:\n        return loaded_tools[tool_module]\n    else:\n        result = load_tool_module(tool_module)\n        loaded_tools[tool_module] = result\n        return result", "response": "Load the module with the tool - specific code."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_results(result_files, options, run_set_id=None, columns=None,\n                 columns_relevant_for_diff=set()):\n    \"\"\"Version of load_result for multiple input files that will be loaded concurrently.\"\"\"\n    return parallel.map(\n        load_result,\n        result_files,\n        itertools.repeat(options),\n        itertools.repeat(run_set_id),\n        itertools.repeat(columns),\n        itertools.repeat(columns_relevant_for_diff))", "response": "Version of load_result for multiple input files that will be loaded concurrently."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload a single result file into a RunSetResult instance.", "response": "def load_result(result_file, options, run_set_id=None, columns=None,\n                columns_relevant_for_diff=set()):\n    \"\"\"\n    Completely handle loading a single result file.\n    @param result_file the file to parse\n    @param options additional options\n    @param run_set_id the identifier of the run set\n    @param columns the list of columns\n    @param columns_relevant_for_diff a set of columns that is relevant for\n                                     the diff table\n    @return a fully ready RunSetResult instance or None\n    \"\"\"\n    xml = parse_results_file(result_file, run_set_id=run_set_id, ignore_errors=options.ignore_errors)\n    if xml is None:\n        return None\n\n    result = RunSetResult.create_from_xml(\n        result_file, xml, columns=columns, all_columns=options.all_columns,\n        columns_relevant_for_diff=columns_relevant_for_diff)\n    result.collect_data(options.correct_only)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef merge_task_lists(runset_results, tasks):\n    for runset in runset_results:\n        # create mapping from id to RunResult object\n        # Use reversed list such that the first instance of equal tasks end up in dic\n        dic = dict([(run_result.task_id, run_result) for run_result in reversed(runset.results)])\n        runset.results = [] # clear and repopulate results\n        for task in tasks:\n            run_result = dic.get(task)\n            if run_result is None:\n                logging.info(\"    No result for task '%s' in '%s'.\",\n                             task[0], Util.prettylist(runset.attributes['filename']))\n                # create an empty dummy element\n                run_result = RunResult(task, None, result.CATEGORY_MISSING, None, None,\n                                       runset.columns, [None]*len(runset.columns))\n            runset.results.append(run_result)", "response": "Merge all the tasks in the runset_results list into a single runset."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_rows(runSetResults):\n    rows = []\n    for task_results in zip(*[runset.results for runset in runSetResults]):\n        rows.append(Row(task_results))\n\n    return rows", "response": "Create list of rows with all data. Each row consists of several RunResults."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef filter_rows_with_differences(rows):\n    if not rows:\n        # empty table\n        return []\n    if len(rows[0].results) == 1:\n        # table with single column\n        return []\n\n\n    def get_index_of_column(name, cols):\n        for i in range(0, len(cols)):\n            if cols[i].title == name:\n                return i\n        return -1\n\n\n    def all_equal_result(listOfResults):\n        relevant_columns = set()\n        for res in listOfResults:\n            for relevant_column in res.columns_relevant_for_diff:\n                relevant_columns.add(relevant_column)\n        if len(relevant_columns) == 0:\n            relevant_columns.add(\"status\")\n\n        status = []\n        for col in relevant_columns:\n            # It's necessary to search for the index of a column every time\n            # because they can differ between results\n            status.append(\n                set(\n                    res.values[get_index_of_column(col, res.columns)]\n                    for res in listOfResults))\n\n        return reduce(lambda x, y: x and (len(y) <= 1), status, True)\n\n\n    rowsDiff = [row for row in rows if not all_equal_result(row.results)]\n\n    if len(rowsDiff) == 0:\n        logging.info(\"---> NO DIFFERENCE FOUND IN SELECTED COLUMNS\")\n    elif len(rowsDiff) == len(rows):\n        logging.info(\"---> DIFFERENCES FOUND IN ALL ROWS, NO NEED TO CREATE DIFFERENCE TABLE\")\n        return []\n\n    return rowsDiff", "response": "Filter the rows with differences in the status column."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef select_relevant_id_columns(rows):\n    relevant_id_columns = [True] # first column (file name) is always relevant\n    if rows:\n        prototype_id = rows[0].id\n        for column in range(1, len(prototype_id)):\n            def id_equal_to_prototype(row):\n                return row.id[column] == prototype_id[column]\n\n            relevant_id_columns.append(not all(map(id_equal_to_prototype, rows)))\n    return relevant_id_columns", "response": "Select relevant id columns for a given list of rows."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_stats_of_rows(rows):\n    count_true = count_false = max_score = 0\n    for row in rows:\n        if not row.properties:\n            logging.info('Missing property for %s.', row.filename)\n            continue\n        if len(row.properties) > 1:\n            # multiple properties not yet supported\n            count_true = count_false = max_score = 0\n            break\n        expected_result = row.expected_results.get(row.properties[0].name)\n        if not expected_result:\n            continue\n        if expected_result.result is True:\n            count_true += 1\n        elif expected_result.result is False:\n            count_false += 1\n        for prop in row.properties:\n            max_score += prop.max_score(expected_result)\n\n    return max_score, count_true, count_false", "response": "Calculate number of true / false tasks and maximum achievable score."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_stats_of_run_set(runResults, correct_only):\n\n    # convert:\n    # [['TRUE', 0,1], ['FALSE', 0,2]] -->  [['TRUE', 'FALSE'], [0,1, 0,2]]\n    # in python2 this is a list, in python3 this is the iterator of the list\n    # this works, because we iterate over the list some lines below\n    listsOfValues = zip(*[runResult.values for runResult in runResults])\n\n    columns = runResults[0].columns\n    main_status_list = [(runResult.category, runResult.status) for runResult in runResults]\n\n    # collect some statistics\n    totalRow = []\n    correctRow = []\n    correctTrueRow = []\n    correctFalseRow = []\n    correctUnconfirmedRow = []\n    correctUnconfirmedTrueRow = []\n    correctUnconfirmedFalseRow = []\n    incorrectRow = []\n    wrongTrueRow = []\n    wrongFalseRow = []\n    scoreRow = []\n\n    status_col_index = 0  # index of 'status' column\n    for index, (column, values) in enumerate(zip(columns, listsOfValues)):\n        col_type = column.type.type\n        if col_type != ColumnType.text:\n            if col_type == ColumnType.main_status or col_type == ColumnType.status:\n                if col_type == ColumnType.main_status:\n                    status_col_index = index\n                    score = StatValue(sum(run_result.score or 0 for run_result in runResults))\n                else:\n                    score = None\n\n                total   = StatValue(len([runResult.values[index] for runResult in runResults if runResult.status]))\n\n                curr_status_list = [(runResult.category, runResult.values[index]) for runResult in runResults]\n\n                counts = collections.Counter((category, result.get_result_classification(status))\n                                             for category, status in curr_status_list)\n                countCorrectTrue             = counts[result.CATEGORY_CORRECT,             result.RESULT_CLASS_TRUE]\n                countCorrectFalse            = counts[result.CATEGORY_CORRECT,             result.RESULT_CLASS_FALSE]\n                countCorrectUnconfirmedTrue  = counts[result.CATEGORY_CORRECT_UNCONFIRMED, result.RESULT_CLASS_TRUE]\n                countCorrectUnconfirmedFalse = counts[result.CATEGORY_CORRECT_UNCONFIRMED, result.RESULT_CLASS_FALSE]\n                countWrongTrue               = counts[result.CATEGORY_WRONG,               result.RESULT_CLASS_TRUE]\n                countWrongFalse              = counts[result.CATEGORY_WRONG,               result.RESULT_CLASS_FALSE]\n\n                correct                 = StatValue(countCorrectTrue + countCorrectFalse)\n                correctTrue             = StatValue(countCorrectTrue)\n                correctFalse            = StatValue(countCorrectFalse)\n                correctUnconfirmed      = StatValue(countCorrectUnconfirmedTrue + countCorrectUnconfirmedFalse)\n                correctUnconfirmedTrue  = StatValue(countCorrectUnconfirmedTrue)\n                correctUnconfirmedFalse = StatValue(countCorrectUnconfirmedFalse)\n                incorrect               = StatValue(countWrongTrue + countWrongFalse)\n                wrongTrue               = StatValue(countWrongTrue)\n                wrongFalse              = StatValue(countWrongFalse)\n\n            else:\n                assert column.is_numeric()\n                total, correct, correctTrue, correctFalse,\\\n                       correctUnconfirmed, correctUnconfirmedTrue, correctUnconfirmedFalse,\\\n                       incorrect, wrongTrue, wrongFalse =\\\n                    get_stats_of_number_column(values, main_status_list, column.title, correct_only)\n\n                score = None\n\n        else:\n            total, correct, correctTrue, correctFalse,\\\n                   correctUnconfirmed, correctUnconfirmedTrue, correctUnconfirmedFalse,\\\n                   incorrect, wrongTrue, wrongFalse =\\\n                (None, None, None, None, None, None, None, None, None, None)\n            score = None\n\n        totalRow.append(total)\n        correctRow.append(correct)\n        correctTrueRow.append(correctTrue)\n        correctFalseRow.append(correctFalse)\n        correctUnconfirmedRow.append(correctUnconfirmed)\n        correctUnconfirmedTrueRow.append(correctUnconfirmedTrue)\n        correctUnconfirmedFalseRow.append(correctUnconfirmedFalse)\n        incorrectRow.append(incorrect)\n        wrongTrueRow.append(wrongTrue)\n        wrongFalseRow.append(wrongFalse)\n        scoreRow.append(score)\n\n    def replace_irrelevant(row):\n        if not row:\n            return\n        count = row[status_col_index]\n        if not count or not count.sum:\n            for i in range(1, len(row)):\n                row[i] = None\n\n    replace_irrelevant(totalRow)\n    replace_irrelevant(correctRow)\n    replace_irrelevant(correctTrueRow)\n    replace_irrelevant(correctFalseRow)\n    replace_irrelevant(correctUnconfirmedRow)\n    replace_irrelevant(correctUnconfirmedTrueRow)\n    replace_irrelevant(correctUnconfirmedFalseRow)\n    replace_irrelevant(incorrectRow)\n    replace_irrelevant(wrongTrueRow)\n    replace_irrelevant(wrongFalseRow)\n    replace_irrelevant(scoreRow)\n\n    stats = (totalRow, correctRow, correctTrueRow, correctFalseRow,\\\n                       correctUnconfirmedRow, correctUnconfirmedTrueRow, correctUnconfirmedFalseRow,\\\n                       incorrectRow, wrongTrueRow, wrongFalseRow,\\\n             scoreRow)\n    return stats", "response": "This function returns the numbers of the statistics of the run set."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_regression_count(rows, ignoreFlappingTimeouts): # for options.dump_counts\n\n    def status_is(run_result, status):\n        # startswith is used because status can be \"TIMEOUT (TRUE)\" etc., which count as \"TIMEOUT\"\n        return run_result.status and run_result.status.startswith(status)\n\n    def any_status_is(run_results, status):\n        for run_result in run_results:\n            if status_is(run_result, status):\n                return True\n        return False\n\n    regressions = 0\n    for row in rows:\n        if len(row.results) < 2:\n            return 0 # no regressions at all with only one run\n\n        # \"new\" and \"old\" are the latest two results\n        new = row.results[-1]\n        old = row.results[-2]\n\n        if new.category == result.CATEGORY_CORRECT:\n            continue # no regression if result is correct\n\n        if new.status == old.status:\n            continue # no regression if result is the same as before\n        if status_is(new, 'TIMEOUT') and status_is(old, 'TIMEOUT'):\n            continue # no regression if both are some form of timeout\n        if status_is(new, 'OUT OF MEMORY') and status_is(old, 'OUT OF MEMORY'):\n            continue # same for OOM\n\n        if (ignoreFlappingTimeouts and\n                status_is(new, 'TIMEOUT') and any_status_is(row.results[:-2], 'TIMEOUT')):\n            continue # flapping timeout because any of the older results is also a timeout\n\n        regressions += 1\n\n    return regressions", "response": "Count the number of regressions at all of the results in the rows."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating tables and write them to files.", "response": "def create_tables(name, runSetResults, rows, rowsDiff, outputPath, outputFilePattern, options):\n    '''\n    Create tables and write them to files.\n    @return a list of futures to allow waiting for completion\n    '''\n\n    # get common folder of sourcefiles\n    common_prefix = os.path.commonprefix([r.filename for r in rows]) # maybe with parts of filename\n    common_prefix = common_prefix[: common_prefix.rfind('/') + 1] # only foldername\n    for row in rows:\n        Row.set_relative_path(row, common_prefix, outputPath)\n\n    # compute nice name of each run set for displaying\n    firstBenchmarkName = Util.prettylist(runSetResults[0].attributes['benchmarkname'])\n    allBenchmarkNamesEqual = all(Util.prettylist(r.attributes['benchmarkname']) == firstBenchmarkName for r in runSetResults)\n    for r in runSetResults:\n        if not r.attributes['name']:\n            r.attributes['niceName'] = r.attributes['benchmarkname']\n        elif allBenchmarkNamesEqual:\n            r.attributes['niceName'] = r.attributes['name']\n        else:\n            r.attributes['niceName'] = [Util.prettylist(r.attributes['benchmarkname']) + '.' + Util.prettylist(r.attributes['name'])]\n\n    template_values = lambda: None # dummy object as dict replacement for simpler syntax\n    template_values.head = get_table_head(runSetResults, common_prefix)\n    template_values.run_sets = [runSetResult.attributes for runSetResult in runSetResults]\n    template_values.columns = [[column for column in runSet.columns] for runSet in runSetResults]\n    template_values.columnTitles =\\\n        [[column.format_title() for column in runSet.columns] for runSet in runSetResults]\n\n    template_values.relevant_id_columns = select_relevant_id_columns(rows)\n    template_values.count_id_columns = template_values.relevant_id_columns.count(True)\n\n    template_values.lib_url = options.lib_url\n    template_values.base_dir = outputPath\n    template_values.href_base = os.path.dirname(options.xmltablefile) if options.xmltablefile else None\n    template_values.version = __version__\n\n    futures = []\n\n    def write_table(table_type, title, rows, use_local_summary):\n        # calculate statistics if necessary\n        if not options.format == ['csv']:\n            local_summary = get_summary(runSetResults) if use_local_summary else None\n            stats, stats_columns = get_stats(rows, local_summary, options.correct_only)\n        else:\n            stats = stats_columns = None\n\n        for template_format in (options.format or TEMPLATE_FORMATS):\n            if outputFilePattern == '-':\n                outfile = None\n                logging.info('Writing %s to stdout...', template_format.upper().ljust(4))\n            else:\n                outfile = os.path.join(outputPath, outputFilePattern.format(name=name, type=table_type, ext=template_format))\n                logging.info('Writing %s into %s ...', template_format.upper().ljust(4), outfile)\n\n            this_template_values = dict(title=title, body=rows, foot=stats, foot_columns=stats_columns)\n            this_template_values.update(template_values.__dict__)\n\n            futures.append(parallel.submit(\n                write_table_in_format,\n                template_format, outfile, this_template_values,\n                options.show_table and template_format == 'html',\n                ))\n\n    # write normal tables\n    write_table(\"table\", name, rows,\n                use_local_summary=(not options.correct_only and not options.common))\n\n    # write difference tables\n    if rowsDiff:\n        write_table(\"diff\", name + \" differences\", rowsDiff, use_local_summary=False)\n\n    return futures"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef append(self, resultFile, resultElem, all_columns=False):\n        self._xml_results += [(result, resultFile) for result in _get_run_tags_from_xml(resultElem)]\n        for attrib, values in RunSetResult._extract_attributes_from_result(resultFile, resultElem).items():\n            self.attributes[attrib].extend(values)\n\n        if not self.columns:\n            self.columns = RunSetResult._extract_existing_columns_from_result(resultFile, resultElem, all_columns)", "response": "Append the result for one run to the run set."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncollect the actual result values from the XML file and the log files.", "response": "def collect_data(self, correct_only):\n        \"\"\"\n        Load the actual result values from the XML file and the log files.\n        This may take some time if many log files have to be opened and parsed.\n        \"\"\"\n        self.results = []\n\n        def get_value_from_logfile(lines, identifier):\n            \"\"\"\n            This method searches for values in lines of the content.\n            It uses a tool-specific method to so.\n            \"\"\"\n            return load_tool(self).get_value_from_output(lines, identifier)\n\n        # Opening the ZIP archive with the logs for every run is too slow, we cache it.\n        log_zip_cache = {}\n        try:\n            for xml_result, result_file in self._xml_results:\n                self.results.append(RunResult.create_from_xml(\n                    xml_result, get_value_from_logfile, self.columns,\n                    correct_only, log_zip_cache, self.columns_relevant_for_diff, result_file))\n        finally:\n            for file in log_zip_cache.values():\n                file.close()\n\n        for column in self.columns:\n            column_values = (run_result.values[run_result.columns.index(column)] for run_result in self.results)\n            column.type, column.unit, column.source_unit, column.scale_factor = get_column_type(column, column_values)\n\n\n        del self._xml_results"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_from_xml(resultFile, resultElem, columns=None,\n                        all_columns=False, columns_relevant_for_diff=set()):\n        '''\n        This function extracts everything necessary for creating a RunSetResult object\n        from the \"result\" XML tag of a benchmark result file.\n        It returns a RunSetResult object, which is not yet fully initialized.\n        To finish initializing the object, call collect_data()\n        before using it for anything else\n        (this is to separate the possibly costly collect_data() call from object instantiation).\n        '''\n        attributes = RunSetResult._extract_attributes_from_result(resultFile, resultElem)\n\n        if not columns:\n            columns = RunSetResult._extract_existing_columns_from_result(resultFile, resultElem, all_columns)\n\n        summary = RunSetResult._extract_summary_from_result(resultElem, columns)\n\n        return RunSetResult([(result, resultFile) for result in _get_run_tags_from_xml(resultElem)],\n                attributes, columns, summary, columns_relevant_for_diff)", "response": "This function extracts all required information from the result XML tag of a benchmark result file and creates a RunSetResult object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the relative path of the file to be used for the log file.", "response": "def set_relative_path(self, common_prefix, base_dir):\n        \"\"\"\n        generate output representation of rows\n        \"\"\"\n        self.short_filename = self.filename.replace(common_prefix, '', 1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the path to the executable file that will get executed.", "response": "def executable(self):\n        \"\"\"\n        Find the path to the executable file that will get executed.\n        This method always needs to be overridden,\n        and most implementations will look similar to this one.\n        The path returned should be relative to the current directory.\n        \"\"\"\n        exe = util.find_executable('bin/symbiotic', exitOnError=False)\n        if exe:\n            return exe\n        else:\n            # this may be the old version of Symbiotic\n            return OldSymbiotic.executable(self)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndetermining whether the version of the current module is newer than some given version.", "response": "def _version_newer_than(self, vers):\n        \"\"\"\n        Determine whether the version is greater than some given version\n        \"\"\"\n        v = self.version(self.executable())\n        vers_num = v[:v.index('-')]\n        if not vers_num[0].isdigit():\n            # this is the old version which is \"older\" than any given version\n            return False\n\n        v1 = list(map(int, vers_num.split('.')))\n        v2 = list(map(int, vers.split('.')))\n        assert len(v1) == 3\n        assert len(v2) == 3\n\n        if v1[0] > v2[0]:\n            return True\n        elif v1[0] == v2[0]:\n            if v1[1] == v2[1]:\n                return v1[2] >= v2[2]\n            elif v1[1] > v2[1]:\n                return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef determine_result(self, returncode, returnsignal, output, isTimeout):\n        for line in output:\n            if line.startswith('KLEE: ERROR: '):\n                if line.find('ASSERTION FAIL:')!=-1:\n                    return result.RESULT_FALSE_REACH\n                elif line.find('memory error: out of bound pointer')!=-1:\n                    return result.RESULT_FALSE_DEREF\n                elif line.find('overflow')!=-1:\n                    return result.RESULT_FALSE_OVERFLOW\n                else:\n                    return \"ERROR ({0})\".format(returncode)\n            if line.startswith('KLEE: done'):\n                return result.RESULT_DONE\n        return result.RESULT_UNKNOWN", "response": "Parse the output of the tool and return the result."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the user account info from the passwd database. Only works on Linux.", "response": "def _get_user_account_info(user):\n    \"\"\"Get the user account info from the passwd database. Only works on Linux.\n    @param user The name of a user account or a numeric uid prefixed with '#'\n    @return a tuple that corresponds to the members of the passwd structure\n    @raise KeyError: If user account is unknown\n    @raise ValueError: If uid is not a valid number\n    \"\"\"\n    import pwd # Import here to avoid problems on other platforms\n    if user[0] == '#':\n        return pwd.getpwuid(int(user[1:]))\n    else:\n        return pwd.getpwnam(user)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_debug_output_after_crash(output_filename, base_path):\n    logging.debug(\"Analysing output for crash info.\")\n    foundDumpFile = False\n    try:\n        with open(output_filename, 'r+') as outputFile:\n            for line in outputFile:\n                if foundDumpFile:\n                    dumpFileName = base_path + line.strip(' #\\n')\n                    outputFile.seek(0, os.SEEK_END) # jump to end of log file\n                    try:\n                        with open(dumpFileName, 'r') as dumpFile:\n                            util.copy_all_lines_from_to(dumpFile, outputFile)\n                        os.remove(dumpFileName)\n                    except IOError as e:\n                        logging.warning('Could not append additional segmentation fault information '\n                                        'from %s (%s)',\n                                        dumpFileName, e.strerror)\n                    break\n                try:\n                    if util.decode_to_string(line).startswith('# An error report file with more information is saved as:'):\n                        logging.debug('Going to append error report file')\n                        foundDumpFile = True\n                except UnicodeDecodeError:\n                    pass\n                    # ignore invalid chars from logfile\n    except IOError as e:\n        logging.warning('Could not analyze tool output for crash information (%s)', e.strerror)", "response": "Get the debug output after a crash."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _try_join_cancelled_thread(thread):\n    thread.join(10)\n    if thread.is_alive():\n        logging.warning(\"Thread %s did not terminate within grace period after cancellation\",\n                        thread.name)", "response": "Join a thread but ignore it if it doesn t terminate within grace period."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding the command line for executing the given command.", "response": "def _build_cmdline(self, args, env={}):\n        \"\"\"\n        Build the final command line for executing the given command,\n        using sudo if necessary.\n        \"\"\"\n        if self._user is None:\n            return super(RunExecutor, self)._build_cmdline(args, env)\n        result = _SUDO_ARGS + [self._user]\n        for var, value in env.items():\n            result.append(var + '=' + value)\n        return result + ['--'] + args"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsending a signal to a process.", "response": "def _kill_process(self, pid, cgroups=None, sig=signal.SIGKILL):\n        \"\"\"\n        Try to send signal to given process, either directly of with sudo.\n        Because we cannot send signals to the sudo process itself,\n        this method checks whether the target is the sudo process\n        and redirects the signal to sudo's child in this case.\n        \"\"\"\n        if self._user is not None:\n            if not cgroups:\n                cgroups = find_cgroups_of_process(pid)\n            # In case we started a tool with sudo, we cannot kill the started\n            # process itself, because sudo always runs as root.\n            # So if we are asked to kill the started process itself (the first\n            # process in the cgroup), we instead kill the child of sudo\n            # (the second process in the cgroup).\n            pids = cgroups.get_all_tasks(FREEZER)\n            try:\n                if pid == next(pids):\n                    pid = next(pids)\n            except StopIteration:\n                # pids seems to not have enough values\n                pass\n            finally:\n                pids.close()\n        self._kill_process0(pid, sig)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend a signal to a process with sudo.", "response": "def _kill_process0(self, pid, sig=signal.SIGKILL):\n        \"\"\"\n        Send signal to given process, either directly or with sudo.\n        If the target is the sudo process itself, the signal will be lost,\n        because we do not have the rights to send signals to sudo.\n        Use _kill_process() because of this.\n        \"\"\"\n        if self._user is None:\n            super(RunExecutor, self)._kill_process(pid, sig)\n        else:\n            logging.debug('Sending signal %s to %s with sudo.', sig, pid)\n            try:\n                # Cast sig to int, under Python 3.5 the signal.SIG* constants are nums, not ints.\n                subprocess.check_call(args=self._build_cmdline(['kill', '-'+str(int(sig)), str(pid)]))\n            except subprocess.CalledProcessError as e:\n                # may happen for example if process no longer exists\n                logging.debug(e)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _listdir(self, path):\n        if self._user is None:\n            return os.listdir(path)\n        else:\n            args = self._build_cmdline(['/bin/ls', '-1A', path])\n            return subprocess.check_output(args, stderr=DEVNULL).decode('utf-8', errors='ignore').split('\\n')", "response": "Return the list of files in a directory assuming that our user can read it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _create_temp_dir(self):\n        if self._user is None:\n            base_dir = tempfile.mkdtemp(prefix=\"BenchExec_run_\")\n        else:\n            create_temp_dir = self._build_cmdline([\n                'python', '-c',\n                'import tempfile;'\n                'print(tempfile.mkdtemp(prefix=\"BenchExec_run_\"))'\n                ])\n            base_dir = subprocess.check_output(create_temp_dir).decode().strip()\n        return base_dir", "response": "Create a temporary directory for the run."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _cleanup_temp_dir(self, base_dir):\n        if self._should_cleanup_temp_dir:\n            logging.debug('Cleaning up temporary directory %s.', base_dir)\n            if self._user is None:\n                util.rmtree(base_dir, onerror=util.log_rmtree_error)\n            else:\n                rm = subprocess.Popen(self._build_cmdline(['rm', '-rf', '--', base_dir]),\n                                      stderr=subprocess.PIPE)\n                rm_output = rm.stderr.read().decode()\n                rm.stderr.close()\n                if rm.wait() != 0 or rm_output:\n                    logging.warning(\"Failed to clean up temp directory %s: %s.\",\n                                    base_dir, rm_output)\n        else:\n            logging.info(\"Skipping cleanup of temporary directory %s.\", base_dir)", "response": "Delete given temporary directory and all its contents."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _setup_environment(self, environments):\n        # If keepEnv is set or sudo is used, start from a fresh environment,\n        # otherwise with the current one.\n        # keepEnv specifies variables to copy from the current environment,\n        # newEnv specifies variables to set to a new value,\n        # additionalEnv specifies variables where some value should be appended, and\n        # clearEnv specifies variables to delete.\n        if self._user is not None or environments.get(\"keepEnv\", None) is not None:\n            run_environment = {}\n        else:\n            run_environment = os.environ.copy()\n        for key, value in environments.get(\"keepEnv\", {}).items():\n            if key in os.environ:\n                run_environment[key] = os.environ[key]\n        for key, value in environments.get(\"newEnv\", {}).items():\n            run_environment[key] = value\n        for key, value in environments.get(\"additionalEnv\", {}).items():\n            run_environment[key] = os.environ.get(key, \"\") + value\n        for key in environments.get(\"clearEnv\", {}).items():\n            run_environment.pop(key, None)\n\n        logging.debug(\"Using additional environment %s.\", environments)\n        return run_environment", "response": "Setup the environment variables for the run."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _setup_output_file(self, output_filename, args, write_header=True):\n        # write command line into outputFile\n        # (without environment variables, they are documented by benchexec)\n        try:\n            output_file = open(output_filename, 'w') # override existing file\n        except IOError as e:\n            sys.exit(e)\n\n        if write_header:\n            output_file.write(' '.join(map(util.escape_string_shell, self._build_cmdline(args)))\n                              + '\\n\\n\\n' + '-' * 80 + '\\n\\n\\n')\n            output_file.flush()\n\n        return output_file", "response": "Open and prepare output file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstarting time - limit handler.", "response": "def _setup_cgroup_time_limit(self, hardtimelimit, softtimelimit, walltimelimit,\n                                 cgroups, cores, pid_to_kill):\n        \"\"\"Start time-limit handler.\n        @return None or the time-limit handler for calling cancel()\n        \"\"\"\n        # hard time limit with cgroups is optional (additionally enforce by ulimit)\n        cgroup_hardtimelimit = hardtimelimit if CPUACCT in cgroups else None\n\n        if any([cgroup_hardtimelimit, softtimelimit, walltimelimit]):\n            # Start a timer to periodically check timelimit\n            timelimitThread = _TimelimitThread(cgroups=cgroups,\n                                               hardtimelimit=cgroup_hardtimelimit,\n                                               softtimelimit=softtimelimit,\n                                               walltimelimit=walltimelimit,\n                                               pid_to_kill=pid_to_kill,\n                                               cores=cores,\n                                               callbackFn=self._set_termination_reason,\n                                               kill_process_fn=self._kill_process)\n            timelimitThread.start()\n            return timelimitThread\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstart memory - limit handler.", "response": "def _setup_cgroup_memory_limit(self, memlimit, cgroups, pid_to_kill):\n        \"\"\"Start memory-limit handler.\n        @return None or the memory-limit handler for calling cancel()\n        \"\"\"\n        if memlimit is not None:\n            try:\n                oomThread = oomhandler.KillProcessOnOomThread(\n                    cgroups=cgroups, pid_to_kill=pid_to_kill,\n                    callbackFn=self._set_termination_reason,\n                    kill_process_fn=self._kill_process)\n                oomThread.start()\n                return oomThread\n            except OSError as e:\n                logging.critical(\"OSError %s during setup of OomEventListenerThread: %s.\",\n                                 e.errno, e.strerror)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _setup_ulimit_time_limit(self, hardtimelimit, cgroups):\n        if hardtimelimit is not None:\n            # Also use ulimit for CPU time limit as a fallback if cgroups don't work.\n            if CPUACCT in cgroups:\n                # Use a slightly higher limit to ensure cgroups get used\n                # (otherwise we cannot detect the timeout properly).\n                ulimit = hardtimelimit + _ULIMIT_DEFAULT_OVERHEAD\n            else:\n                ulimit = hardtimelimit\n            resource.setrlimit(resource.RLIMIT_CPU, (ulimit, ulimit))", "response": "Setup time limit with ulimit for the current process."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _setup_file_hierarchy_limit(\n            self, files_count_limit, files_size_limit, temp_dir, cgroups, pid_to_kill):\n        \"\"\"Start thread that enforces any file-hiearchy limits.\"\"\"\n        if files_count_limit is not None or files_size_limit is not None:\n            file_hierarchy_limit_thread = FileHierarchyLimitThread(\n                self._get_result_files_base(temp_dir),\n                files_count_limit=files_count_limit,\n                files_size_limit=files_size_limit,\n                cgroups=cgroups,\n                pid_to_kill=pid_to_kill,\n                callbackFn=self._set_termination_reason,\n                kill_process_fn=self._kill_process)\n            file_hierarchy_limit_thread.start()\n            return file_hierarchy_limit_thread\n        return None", "response": "Start thread that enforces any file - hiearchy limits."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef execute_run(self, args, output_filename, stdin=None,\n                    hardtimelimit=None, softtimelimit=None, walltimelimit=None,\n                   cores=None, memlimit=None, memory_nodes=None,\n                   environments={}, workingDir=None, maxLogfileSize=None,\n                   cgroupValues={},\n                   files_count_limit=None, files_size_limit=None,\n                   error_filename=None, write_header=True,\n                   **kwargs):\n        \"\"\"\n        This function executes a given command with resource limits,\n        and writes the output to a file.\n        @param args: the command line to run\n        @param output_filename: the file where the output should be written to\n        @param stdin: What to uses as stdin for the process (None: /dev/null, a file descriptor, or a file object)\n        @param hardtimelimit: None or the CPU time in seconds after which the tool is forcefully killed.\n        @param softtimelimit: None or the CPU time in seconds after which the tool is sent a kill signal.\n        @param walltimelimit: None or the wall time in seconds after which the tool is forcefully killed (default: hardtimelimit + a few seconds)\n        @param cores: None or a list of the CPU cores to use\n        @param memlimit: None or memory limit in bytes\n        @param memory_nodes: None or a list of memory nodes in a NUMA system to use\n        @param environments: special environments for running the command\n        @param workingDir: None or a directory which the execution should use as working directory\n        @param maxLogfileSize: None or a number of bytes to which the output of the tool should be truncated approximately if there is too much output.\n        @param cgroupValues: dict of additional cgroup values to set (key is tuple of subsystem and option, respective subsystem needs to be enabled in RunExecutor; cannot be used to override values set by BenchExec)\n        @param files_count_limit: None or maximum number of files that may be written.\n        @param files_size_limit: None or maximum size of files that may be written.\n        @param error_filename: the file where the error output should be written to (default: same as output_filename)\n        @param write_headers: Write informational headers to the output and the error file if separate (default: True)\n        @param **kwargs: further arguments for ContainerExecutor.execute_run()\n        @return: dict with result of run (measurement results and process exitcode)\n        \"\"\"\n        # Check argument values and call the actual method _execute()\n\n        if stdin == subprocess.PIPE:\n            sys.exit('Illegal value subprocess.PIPE for stdin')\n        elif stdin is None:\n            stdin = DEVNULL\n\n        if hardtimelimit is not None:\n            if hardtimelimit <= 0:\n                sys.exit(\"Invalid time limit {0}.\".format(hardtimelimit))\n        if softtimelimit is not None:\n            if softtimelimit <= 0:\n                sys.exit(\"Invalid soft time limit {0}.\".format(softtimelimit))\n            if hardtimelimit and (softtimelimit > hardtimelimit):\n                sys.exit(\"Soft time limit cannot be larger than the hard time limit.\")\n            if not CPUACCT in self.cgroups:\n                sys.exit(\"Soft time limit cannot be specified without cpuacct cgroup.\")\n\n        if walltimelimit is None:\n            if hardtimelimit is not None:\n                walltimelimit = hardtimelimit + _WALLTIME_LIMIT_DEFAULT_OVERHEAD\n            elif softtimelimit is not None:\n                walltimelimit = softtimelimit + _WALLTIME_LIMIT_DEFAULT_OVERHEAD\n        else:\n            if walltimelimit <= 0:\n                sys.exit(\"Invalid wall time limit {0}.\".format(walltimelimit))\n\n        if cores is not None:\n            if self.cpus is None:\n                sys.exit(\"Cannot limit CPU cores without cpuset cgroup.\")\n            if not cores:\n                sys.exit(\"Cannot execute run without any CPU core.\")\n            if not set(cores).issubset(self.cpus):\n                sys.exit(\"Cores {0} are not allowed to be used\".format(list(set(cores).difference(self.cpus))))\n\n        if memlimit is not None:\n            if memlimit <= 0:\n                sys.exit(\"Invalid memory limit {0}.\".format(memlimit))\n            if not MEMORY in self.cgroups:\n                sys.exit(\"Memory limit specified, but cannot be implemented without cgroup support.\")\n\n        if memory_nodes is not None:\n            if self.memory_nodes is None:\n                sys.exit(\"Cannot restrict memory nodes without cpuset cgroup.\")\n            if len(memory_nodes) == 0:\n                sys.exit(\"Cannot execute run without any memory node.\")\n            if not set(memory_nodes).issubset(self.memory_nodes):\n                sys.exit(\"Memory nodes {0} are not allowed to be used\".format(list(set(memory_nodes).difference(self.memory_nodes))))\n\n        if workingDir:\n            if not os.path.exists(workingDir):\n                sys.exit(\"Working directory {0} does not exist.\".format(workingDir))\n            if not os.path.isdir(workingDir):\n                sys.exit(\"Working directory {0} is not a directory.\".format(workingDir))\n            if not os.access(workingDir, os.X_OK):\n                sys.exit(\"Permission denied for working directory {0}.\".format(workingDir))\n\n        for ((subsystem, option), _) in cgroupValues.items():\n            if not subsystem in self._cgroup_subsystems:\n                sys.exit('Cannot set option \"{option}\" for subsystem \"{subsystem}\" that is not enabled. '\n                         'Please specify \"--require-cgroup-subsystem {subsystem}\".'.format(\n                            option=option, subsystem=subsystem))\n            if not self.cgroups.has_value(subsystem, option):\n                sys.exit('Cannot set option \"{option}\" for subsystem \"{subsystem}\", it does not exist.'\n                         .format(option=option, subsystem=subsystem))\n\n        if files_count_limit is not None:\n            if files_count_limit < 0:\n                sys.exit(\"Invalid files-count limit {0}.\".format(files_count_limit))\n        if files_size_limit is not None:\n            if files_size_limit < 0:\n                sys.exit(\"Invalid files-size limit {0}.\".format(files_size_limit))\n\n        try:\n            return self._execute(args, output_filename, error_filename, stdin, write_header,\n                                 hardtimelimit, softtimelimit, walltimelimit, memlimit,\n                                 cores, memory_nodes,\n                                 cgroupValues,\n                                 environments, workingDir, maxLogfileSize,\n                                 files_count_limit, files_size_limit,\n                                 **kwargs)\n\n        except BenchExecException as e:\n            logging.critical(\"Cannot execute '%s': %s.\",\n                util.escape_string_shell(args[0]), e)\n            return {'terminationreason': 'failed', 'exitcode': 0,\n                    'cputime': 0, 'walltime': 0}\n        except OSError as e:\n            logging.critical(\"OSError %s while starting '%s' in '%s': %s.\",\n                e.errno, util.escape_string_shell(args[0]), workingDir or '.', e.strerror)\n            return {'terminationreason': 'failed', 'exitcode': 0,\n                    'cputime': 0, 'walltime': 0}", "response": "This function executes a given command line and writes the output to a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _execute(self, args, output_filename, error_filename, stdin, write_header,\n                 hardtimelimit, softtimelimit, walltimelimit, memlimit,\n                 cores, memory_nodes,\n                 cgroup_values,\n                 environments, workingDir, max_output_size,\n                 files_count_limit, files_size_limit,\n                 **kwargs):\n        \"\"\"\n        This method executes the command line and waits for the termination of it,\n        handling all setup and cleanup, but does not check whether arguments are valid.\n        \"\"\"\n\n        if self._energy_measurement is not None:\n            # Calculate which packages we should use for energy measurements\n            if cores is None:\n                packages = True # We use all cores and thus all packages\n            else:\n                all_siblings = set(util.flatten(\n                    resources.get_cores_of_same_package_as(core) for core in cores))\n                if all_siblings == set(cores):\n                    packages = set(resources.get_cpu_package_for_core(core) for core in cores)\n                else:\n                    # Disable energy measurements because we use only parts of a CPU\n                    packages = None\n\n        def preParent():\n            \"\"\"Setup that is executed in the parent process immediately before the actual tool is started.\"\"\"\n            # start measurements\n            if self._energy_measurement is not None and packages:\n                self._energy_measurement.start()\n            walltime_before = util.read_monotonic_time()\n            return walltime_before\n\n        def postParent(preParent_result, exit_code, base_path):\n            \"\"\"Cleanup that is executed in the parent process immediately after the actual tool terminated.\"\"\"\n            # finish measurements\n            walltime_before = preParent_result\n            walltime = util.read_monotonic_time() - walltime_before\n            energy = self._energy_measurement.stop() if self._energy_measurement else None\n\n            if exit_code.value not in [0, 1]:\n                _get_debug_output_after_crash(output_filename, base_path)\n\n            return (walltime, energy)\n\n        def preSubprocess():\n            \"\"\"Setup that is executed in the forked process before the actual tool is started.\"\"\"\n            os.setpgrp() # make subprocess to group-leader\n            os.nice(5) # increase niceness of subprocess\n            self._setup_ulimit_time_limit(hardtimelimit, cgroups)\n\n        # preparations that are not time critical\n        cgroups = self._setup_cgroups(cores, memlimit, memory_nodes, cgroup_values)\n        temp_dir = self._create_temp_dir()\n        run_environment = self._setup_environment(environments)\n        outputFile = self._setup_output_file(output_filename, args, write_header=write_header)\n        if error_filename is None:\n            errorFile = outputFile\n        else:\n            errorFile = self._setup_output_file(error_filename, args, write_header=write_header)\n\n        timelimitThread = None\n        oomThread = None\n        file_hierarchy_limit_thread = None\n        pid = None\n        returnvalue = 0\n        ru_child = None\n        self._termination_reason = None\n        result = collections.OrderedDict()\n\n        throttle_check = systeminfo.CPUThrottleCheck(cores)\n        swap_check = systeminfo.SwapCheck()\n\n        logging.debug('Starting process.')\n\n        try:\n            pid, result_fn = self._start_execution(args=args,\n                stdin=stdin, stdout=outputFile, stderr=errorFile,\n                env=run_environment, cwd=workingDir, temp_dir=temp_dir,\n                memlimit=memlimit, memory_nodes=memory_nodes,\n                cgroups=cgroups,\n                parent_setup_fn=preParent, child_setup_fn=preSubprocess,\n                parent_cleanup_fn=postParent,\n                **kwargs)\n\n            with self.SUB_PROCESS_PIDS_LOCK:\n                self.SUB_PROCESS_PIDS.add(pid)\n\n            timelimitThread = self._setup_cgroup_time_limit(\n                hardtimelimit, softtimelimit, walltimelimit, cgroups, cores, pid)\n            oomThread = self._setup_cgroup_memory_limit(memlimit, cgroups, pid)\n            file_hierarchy_limit_thread = self._setup_file_hierarchy_limit(\n                files_count_limit, files_size_limit, temp_dir, cgroups, pid)\n\n            returnvalue, ru_child, (walltime, energy) = result_fn() # blocks until process has terminated\n            result['walltime'] = walltime\n        finally:\n            # cleanup steps that need to get executed even in case of failure\n            logging.debug('Process terminated, exit code %s.', returnvalue)\n\n            with self.SUB_PROCESS_PIDS_LOCK:\n                self.SUB_PROCESS_PIDS.discard(pid)\n\n            if timelimitThread:\n                timelimitThread.cancel()\n\n            if oomThread:\n                oomThread.cancel()\n\n            if file_hierarchy_limit_thread:\n                file_hierarchy_limit_thread.cancel()\n\n            # Kill all remaining processes (needs to come early to avoid accumulating more CPU time)\n            cgroups.kill_all_tasks(self._kill_process0)\n\n            # normally subprocess closes file, we do this again after all tasks terminated\n            outputFile.close()\n            if errorFile is not outputFile:\n                errorFile.close()\n\n            # measurements are not relevant in case of failure, but need to come before cgroup cleanup\n            self._get_cgroup_measurements(cgroups, ru_child, result)\n            logging.debug(\"Cleaning up cgroups.\")\n            cgroups.remove()\n\n            self._cleanup_temp_dir(temp_dir)\n\n            if timelimitThread:\n                _try_join_cancelled_thread(timelimitThread)\n            if oomThread:\n                _try_join_cancelled_thread(oomThread)\n            if file_hierarchy_limit_thread:\n                _try_join_cancelled_thread(file_hierarchy_limit_thread)\n\n            if self._energy_measurement:\n                self._energy_measurement.stop()\n\n        # cleanup steps that are only relevant in case of success\n        if throttle_check.has_throttled():\n            logging.warning('CPU throttled itself during benchmarking due to overheating. '\n                            'Benchmark results are unreliable!')\n        if swap_check.has_swapped():\n            logging.warning('System has swapped during benchmarking. '\n                            'Benchmark results are unreliable!')\n\n        if error_filename is not None:\n            _reduce_file_size_if_necessary(error_filename, max_output_size)\n\n        _reduce_file_size_if_necessary(output_filename, max_output_size)\n\n        result['exitcode'] = returnvalue\n        if energy:\n            if packages == True:\n                result['cpuenergy'] = energy\n            else:\n                result['cpuenergy'] = {pkg: energy[pkg] for pkg in energy if pkg in packages}\n        if self._termination_reason:\n            result['terminationreason'] = self._termination_reason\n        elif memlimit and 'memory' in result and result['memory'] >= memlimit:\n            # The kernel does not always issue OOM notifications and thus the OOMHandler\n            # does not always run even in case of OOM. We detect this there and report OOM.\n            result['terminationreason'] = 'memory'\n\n        return result", "response": "This method executes the command line and returns the output of the command line."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_for_new_files_in_home(self):\n        if not self._user:\n            return None\n        try:\n            created_files = set(self._listdir(self._home_dir)).difference(self._home_dir_content)\n        except (subprocess.CalledProcessError, IOError):\n            # Probably home directory does not exist\n            created_files = []\n        if created_files:\n            logging.warning('The tool created the following files in %s, '\n                            'this may influence later runs:\\n\\t%s',\n                            self._home_dir, '\\n\\t'.join(created_files))\n        return created_files", "response": "Check that the user s home directory now does not contain more files than\n        when this instance was created and warn if it was not."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the host name of the machine.", "response": "def sethostname(name):\n    \"\"\"Set the host name of the machine.\"\"\"\n    # TODO: replace with socket.sethostname, which is available from Python 3.3\n    name = name.encode()\n    _libc.sethostname(name, len(name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_cgroup_availability_in_thread(options):\n    thread = _CheckCgroupsThread(options)\n    thread.start()\n    thread.join()\n    if thread.error:\n        raise thread.error", "response": "Run check_cgroup_availability in a separate thread to detect if cgroups are available in the main thread."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef main(argv=None):\n    if argv is None:\n        argv = sys.argv\n\n    parser = argparse.ArgumentParser(\n        fromfile_prefix_chars='@',\n        description=\n        \"\"\"Check whether cgroups are available and can be used for BenchExec.\n           Part of BenchExec: https://github.com/sosy-lab/benchexec/\"\"\")\n    parser.add_argument(\"--wait\", type=int, default=1, metavar=\"SECONDS\",\n                        help='wait some time to ensure no process interferes with cgroups in the meantime (default: 1s)')\n    parser.add_argument(\"--no-thread\", action=\"store_true\",\n                        help='run check on the main thread instead of a separate thread'\n                            + '(behavior of cgrulesengd differs depending on this)')\n\n    options = parser.parse_args(argv[1:])\n\n    if options.no_thread:\n        check_cgroup_availability(options.wait)\n    else:\n        check_cgroup_availability_in_thread(options)", "response": "A simple command - line interface for the cgroups check of BenchExec."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef allInText(self, words, text):\n        index = 0\n        for word in words:\n            index = text[index:].find(word)\n            if index == -1:\n                return False\n        return True", "response": "This function checks if all the words appear in the given order in the given text."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a single child tag from an XML element.", "response": "def get_single_child_from_xml(elem, tag):\n    \"\"\"\n    Get a single child tag from an XML element.\n    Similar to \"elem.find(tag)\", but warns if there are multiple child tags with the given name.\n    \"\"\"\n    children = elem.findall(tag)\n    if not children:\n        return None\n    if len(children) > 1:\n        logging.warning('Tag \"%s\" has more than one child tags with name \"%s\" in input file, '\n                        'ignoring all but the first.',\n                        elem.tag, tag)\n    return children[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef copy_of_xml_element(elem):\n\n    copyElem = ElementTree.Element(elem.tag, elem.attrib)\n    for child in elem:\n        copyElem.append(child)\n    return copyElem", "response": "Returns a shallow copy of an XML - Element."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_int_list(s):\n    result = []\n    for item in s.split(','):\n        item = item.strip().split('-')\n        if len(item) == 1:\n            result.append(int(item[0]))\n        elif len(item) == 2:\n            start, end = item\n            result.extend(range(int(start), int(end)+1))\n        else:\n            raise ValueError(\"invalid range: '{0}'\".format(s))\n    return result", "response": "Parse a comma - separated list of strings."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse a string that consists of a integer number and an optional unit.", "response": "def split_number_and_unit(s):\n    \"\"\"Parse a string that consists of a integer number and an optional unit.\n    @param s a non-empty string that starts with an int and is followed by some letters\n    @return a triple of the number (as int) and the unit\n    \"\"\"\n    if not s:\n        raise ValueError('empty value')\n    s = s.strip()\n    pos = len(s)\n    while pos and not s[pos-1].isdigit():\n        pos -= 1\n    number = int(s[:pos])\n    unit = s[pos:].strip()\n    return (number, unit)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse a string that contains a number of bytes optionally with a unit like MB.", "response": "def parse_memory_value(s):\n    \"\"\"Parse a string that contains a number of bytes, optionally with a unit like MB.\n    @return the number of bytes encoded by the string\n    \"\"\"\n    number, unit = split_number_and_unit(s)\n    if not unit or unit == 'B':\n        return number\n    elif unit == 'kB':\n        return number * _BYTE_FACTOR\n    elif unit == 'MB':\n        return number * _BYTE_FACTOR * _BYTE_FACTOR\n    elif unit == 'GB':\n        return number * _BYTE_FACTOR * _BYTE_FACTOR * _BYTE_FACTOR\n    elif unit == 'TB':\n        return number * _BYTE_FACTOR * _BYTE_FACTOR * _BYTE_FACTOR * _BYTE_FACTOR\n    else:\n        raise ValueError('unknown unit: {} (allowed are B, kB, MB, GB, and TB)'.format(unit))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_timespan_value(s):\n    number, unit = split_number_and_unit(s)\n    if not unit or unit == \"s\":\n        return number\n    elif unit == \"min\":\n        return number * 60\n    elif unit == \"h\":\n        return number * 60 * 60\n    elif unit == \"d\":\n        return number * 24 * 60 * 60\n    else:\n        raise ValueError('unknown unit: {} (allowed are s, min, h, and d)'.format(unit))", "response": "Parse a string that contains a time span optionally with a unit like s.\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef expand_filename_pattern(pattern, base_dir):\n    # 'join' ignores base_dir, if expandedPattern is absolute.\n    # 'normpath' replaces 'A/foo/../B' with 'A/B', for pretty printing only\n    pattern = os.path.normpath(os.path.join(base_dir, pattern))\n\n    # expand tilde and variables\n    pattern = os.path.expandvars(os.path.expanduser(pattern))\n\n    # expand wildcards\n    fileList = glob.glob(pattern)\n\n    return fileList", "response": "Expand a file name pattern containing wildcards environment variables etc."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef substitute_vars(template, replacements):\n    result = template\n    for (key, value) in replacements:\n        result = result.replace('${' + key + '}' , value)\n    if '${' in result:\n        logging.warning(\"A variable was not replaced in '%s'.\", result)\n    return result", "response": "Replace certain keys with respective values in a string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef log_rmtree_error(func, arg, exc_info):\n    logging.warning(\"Failure during '%s(%s)': %s\", func.__name__, arg, exc_info[1])", "response": "Suited as onerror handler for ( sh ) util. rmtree"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncopying all lines from an input file object to an output file object.", "response": "def copy_all_lines_from_to(inputFile, outputFile):\n    \"\"\"Copy all lines from an input file object to an output file object.\"\"\"\n    currentLine = inputFile.readline()\n    while currentLine:\n        outputFile.write(currentLine)\n        currentLine = inputFile.readline()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_file(content, *path):\n    with open(os.path.join(*path), \"w\") as file:\n        return file.write(content)", "response": "Write some content to a file overriding the file if necessary."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef shrink_text_file(filename, max_size, removal_marker=None):\n    file_size = os.path.getsize(filename)\n    assert file_size > max_size\n\n    # We partition the file into 3 parts:\n    # A) start: maxSize/2 bytes we want to keep\n    # B) middle: part we want to remove\n    # C) end: maxSize/2 bytes we want to keep\n\n    # Trick taken from StackOverflow:\n    # https://stackoverflow.com/questions/2329417/fastest-way-to-delete-a-line-from-large-file-in-python\n    # We open the file twice at the same time, once for reading (input_file) and once for writing (output_file).\n    # We position output_file at the beginning of part B\n    # and input_file at the beginning of part C.\n    # Then we copy the content of C into B, overwriting what is there.\n    # Afterwards we truncate the file after A+C.\n\n    with open(filename, 'r+b') as output_file:\n        with open(filename, 'rb') as input_file:\n            # Position outputFile between A and B\n            output_file.seek(max_size // 2)\n            output_file.readline() # jump to end of current line so that we truncate at line boundaries\n            if output_file.tell() == file_size:\n                # readline jumped to end of file because of a long line\n                return\n\n            if removal_marker:\n                output_file.write(removal_marker.encode())\n\n            # Position inputFile between B and C\n            input_file.seek(-max_size // 2, os.SEEK_END) # jump to beginning of second part we want to keep from end of file\n            input_file.readline() # jump to end of current line so that we truncate at line boundaries\n\n            # Copy C over B\n            copy_all_lines_from_to(input_file, output_file)\n\n            output_file.truncate()", "response": "Shrink a text file to approximately maxSize bytes\n            by removing lines from the middle of the file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_file(*path):\n    with open(os.path.join(*path)) as f:\n        return f.read().strip()", "response": "Read the full content of a file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read_key_value_pairs_from_file(*path):\n    with open(os.path.join(*path)) as f:\n        for line in f:\n            yield line.split(' ', 1)", "response": "Reads key value pairs from a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds and commit all files given in a list into a git repository.", "response": "def add_files_to_git_repository(base_dir, files, description):\n    \"\"\"\n    Add and commit all files given in a list into a git repository in the\n    base_dir directory. Nothing is done if the git repository has\n    local changes.\n\n    @param files: the files to commit\n    @param description: the commit message\n    \"\"\"\n    if not os.path.isdir(base_dir):\n        printOut('Output path is not a directory, cannot add files to git repository.')\n        return\n\n    # find out root directory of repository\n    gitRoot = subprocess.Popen(['git', 'rev-parse', '--show-toplevel'],\n                               cwd=base_dir,\n                               stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    stdout = gitRoot.communicate()[0]\n    if gitRoot.returncode != 0:\n        printOut('Cannot commit results to repository: git rev-parse failed, perhaps output path is not a git directory?')\n        return\n    gitRootDir = decode_to_string(stdout).splitlines()[0]\n\n    # check whether repository is clean\n    gitStatus = subprocess.Popen(['git','status','--porcelain', '--untracked-files=no'],\n                                 cwd=gitRootDir,\n                                 stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    (stdout, stderr) = gitStatus.communicate()\n    if gitStatus.returncode != 0:\n        printOut('Git status failed! Output was:\\n' + decode_to_string(stderr))\n        return\n\n    if stdout:\n        printOut('Git repository has local changes, not commiting results.')\n        return\n\n    # add files to staging area\n    files = [os.path.realpath(file) for file in files]\n    # Use --force to add all files in result-files directory even if .gitignore excludes them\n    gitAdd = subprocess.Popen(['git', 'add', '--force', '--'] + files,\n                               cwd=gitRootDir)\n    if gitAdd.wait() != 0:\n        printOut('Git add failed, will not commit results!')\n        return\n\n    # commit files\n    printOut('Committing results files to git repository in ' + gitRootDir)\n    gitCommit = subprocess.Popen(['git', 'commit', '--file=-', '--quiet'],\n                                 cwd=gitRootDir,\n                                 stdin=subprocess.PIPE)\n    gitCommit.communicate(description.encode('UTF-8'))\n    if gitCommit.returncode != 0:\n        printOut('Git commit failed!')\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef setup_logging(format=\"%(asctime)s - %(levelname)s - %(message)s\", level='INFO'):\n    try:\n        import coloredlogs\n        coloredlogs.install(fmt=format, level=level)\n    except ImportError:\n        logging.basicConfig(format=format, level=level)", "response": "Setup the logging framework with a basic configuration"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninterrupt running process and provide a python prompt for interactive debugging.", "response": "def _debug_current_process(sig, current_frame):\n    \"\"\"Interrupt running process, and provide a python prompt for interactive debugging.\n    This code is based on http://stackoverflow.com/a/133384/396730\n    \"\"\"\n    # Import modules only if necessary, readline is for shell history support.\n    import code, traceback, readline, threading  # @UnresolvedImport @UnusedImport\n\n    d={'_frame':current_frame}         # Allow access to frame object.\n    d.update(current_frame.f_globals)  # Unless shadowed by global\n    d.update(current_frame.f_locals)\n\n    i = code.InteractiveConsole(d)\n    message  = \"Signal received : entering python shell.\\n\"\n\n    threads = dict((thread.ident, thread) for thread in threading.enumerate())\n    current_thread = threading.current_thread()\n    for thread_id, frame in sys._current_frames().items():\n        if current_thread.ident != thread_id:\n            message += \"\\nTraceback of thread {}:\\n\".format(threads[thread_id])\n            message += ''.join(traceback.format_stack(frame))\n    message += \"\\nTraceback of current thread {}:\\n\".format(current_thread)\n    message += ''.join(traceback.format_stack(current_frame))\n    i.interact(message)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the output of the tool and extract the verification result. This method always needs to be overridden. If the tool gave a result, this method needs to return one of the benchexec.result.RESULT_* strings. Otherwise an arbitrary string can be returned that will be shown to the user and should give some indication of the failure reason (e.g., \"CRASH\", \"OUT_OF_MEMORY\", etc.).", "response": "def determine_result(self, returncode, returnsignal, output, isTimeout):\n        \"\"\"\n        Parse the output of the tool and extract the verification result.\n        This method always needs to be overridden.\n        If the tool gave a result, this method needs to return one of the\n        benchexec.result.RESULT_* strings.\n        Otherwise an arbitrary string can be returned that will be shown to the user\n        and should give some indication of the failure reason\n        (e.g., \"CRASH\", \"OUT_OF_MEMORY\", etc.).\n        \"\"\"\n        for line in reversed(output):\n            if line.startswith('ERROR:'):\n                if 'timeout' in line.lower():\n                    return \"TIMEOUT\"\n                else:\n                    return \"ERROR ({0})\".format(returncode)\n            elif line.startswith('TBF') and 'FALSE' in line:\n                return result.RESULT_FALSE_REACH\n            elif line.startswith('TBF') and 'TRUE' in line:\n                return result.RESULT_TRUE_PROP\n            elif line.startswith('TBF') and 'DONE' in line:\n                return result.RESULT_DONE\n        return result.RESULT_UNKNOWN"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks whether Turbo Boost is enabled on this system.", "response": "def is_turbo_boost_enabled():\n    \"\"\"\n    Check whether Turbo Boost (scaling CPU frequency beyond nominal frequency)\n    is active on this system.\n    @return: A bool, or None if Turbo Boost is not supported.\n    \"\"\"\n    try:\n        if os.path.exists(_TURBO_BOOST_FILE):\n            boost_enabled = int(util.read_file(_TURBO_BOOST_FILE))\n            if not (0 <= boost_enabled <= 1):\n                raise ValueError('Invalid value {} for turbo boost activation'.format(boost_enabled))\n            return boost_enabled != 0\n        if os.path.exists(_TURBO_BOOST_FILE_PSTATE):\n            boost_disabled = int(util.read_file(_TURBO_BOOST_FILE_PSTATE))\n            if not (0 <= boost_disabled <= 1):\n                raise ValueError('Invalid value {} for turbo boost activation'.format(boost_enabled))\n            return boost_disabled != 1\n    except ValueError as e:\n        sys.exit(\"Could not read turbo-boost information from kernel: {0}\".format(e))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef has_throttled(self):\n        for file, value in self.cpu_throttle_count.items():\n            try:\n                new_value = int(util.read_file(file))\n                if new_value > value:\n                    return True\n            except Exception as e:\n                logging.warning('Cannot read throttling count of CPU from kernel: %s', e)\n        return False", "response": "Check whether any of the CPU cores monitored by this instance has throttled since this instance was created."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef has_swapped(self):\n        new_values = self._read_swap_count()\n        for key, new_value in new_values.items():\n            old_value = self.swap_count.get(key, 0)\n            if new_value > old_value:\n                return True\n        return False", "response": "Check whether any swapping occured on this system since this instance was created."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds some basic options for an executor to an argparse argument_parser.", "response": "def add_basic_executor_options(argument_parser):\n    \"\"\"Add some basic options for an executor to an argparse argument_parser.\"\"\"\n    argument_parser.add_argument(\"args\", nargs=\"+\", metavar=\"ARG\",\n        help='command line to run (prefix with \"--\" to ensure all arguments are treated correctly)')\n    argument_parser.add_argument(\"--version\", action=\"version\", version=\"%(prog)s \" + __version__)\n\n    verbosity = argument_parser.add_mutually_exclusive_group()\n    verbosity.add_argument(\"--debug\", action=\"store_true\",\n                           help=\"show debug output\")\n    verbosity.add_argument(\"--quiet\", action=\"store_true\",\n                           help=\"show only warnings\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhandle the options specified by add_basic_executor_options.", "response": "def handle_basic_executor_options(options, parser):\n    \"\"\"Handle the options specified by add_basic_executor_options().\"\"\"\n    # setup logging\n    logLevel = logging.INFO\n    if options.debug:\n        logLevel = logging.DEBUG\n    elif options.quiet:\n        logLevel = logging.WARNING\n    util.setup_logging(level=logLevel)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntries to send signal to given process.", "response": "def _kill_process(self, pid, sig=signal.SIGKILL):\n        \"\"\"Try to send signal to given process.\"\"\"\n        try:\n            os.kill(pid, sig)\n        except OSError as e:\n            if e.errno == errno.ESRCH: # process itself returned and exited before killing\n                logging.debug(\"Failure %s while killing process %s with signal %s: %s\",\n                              e.errno, pid, sig, e.strerror)\n            else:\n                logging.warning(\"Failure %s while killing process %s with signal %s: %s\",\n                                e.errno, pid, sig, e.strerror)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstart the execution of the tool and the measurements.", "response": "def _start_execution(self, args, stdin, stdout, stderr, env, cwd, temp_dir, cgroups,\n                         parent_setup_fn, child_setup_fn, parent_cleanup_fn):\n        \"\"\"Actually start the tool and the measurements.\n        @param parent_setup_fn a function without parameters that is called in the parent process\n            immediately before the tool is started\n        @param child_setup_fn a function without parameters that is called in the child process\n            before the tool is started\n        @param parent_cleanup_fn a function that is called in the parent process\n            immediately after the tool terminated, with three parameters:\n            the result of parent_setup_fn, the result of the executed process as ProcessExitCode,\n            and the base path for looking up files as parameter values\n        @return: a tuple of PID of process and a blocking function, which waits for the process\n            and a triple of the exit code and the resource usage of the process\n            and the result of parent_cleanup_fn (do not use os.wait)\n        \"\"\"\n        def pre_subprocess():\n            # Do some other setup the caller wants.\n            child_setup_fn()\n\n            # put us into the cgroup(s)\n            pid = os.getpid()\n            cgroups.add_task(pid)\n\n        # Set HOME and TMPDIR to fresh directories.\n        tmp_dir = os.path.join(temp_dir, \"tmp\")\n        home_dir = os.path.join(temp_dir, \"home\")\n        self._create_dirs_in_temp_dir(tmp_dir, home_dir)\n        env[\"HOME\"] = home_dir\n        env[\"TMPDIR\"] = tmp_dir\n        env[\"TMP\"] = tmp_dir\n        env[\"TEMPDIR\"] = tmp_dir\n        env[\"TEMP\"] = tmp_dir\n        logging.debug(\"Executing run with $HOME and $TMPDIR below %s.\", temp_dir)\n\n        args = self._build_cmdline(args, env=env)\n\n        parent_setup = parent_setup_fn()\n\n        p = subprocess.Popen(args,\n                     stdin=stdin,\n                     stdout=stdout, stderr=stderr,\n                     env=env, cwd=cwd,\n                     close_fds=True,\n                     preexec_fn=pre_subprocess)\n\n        def wait_and_get_result():\n            exitcode, ru_child = self._wait_for_process(p.pid, args[0])\n\n            parent_cleanup = parent_cleanup_fn(\n                parent_setup, util.ProcessExitCode.from_raw(exitcode), \"\")\n            return exitcode, ru_child, parent_cleanup\n\n        return p.pid, wait_and_get_result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _wait_for_process(self, pid, name):\n        try:\n            logging.debug(\"Waiting for process %s with pid %s\", name, pid)\n            unused_pid, exitcode, ru_child = os.wait4(pid, 0)\n            return exitcode, ru_child\n        except OSError as e:\n            if self.PROCESS_KILLED and e.errno == errno.EINTR:\n                # Interrupted system call seems always to happen\n                # if we killed the process ourselves after Ctrl+C was pressed\n                # We can try again to get exitcode and resource usage.\n                logging.debug(\"OSError %s while waiting for termination of %s (%s): %s.\",\n                              e.errno, name, pid, e.strerror)\n                try:\n                    unused_pid, exitcode, ru_child = os.wait4(pid, 0)\n                    return exitcode, ru_child\n                except OSError:\n                    pass # original error will be handled and this ignored\n\n            logging.critical(\"OSError %s while waiting for termination of %s (%s): %s.\",\n                             e.errno, name, pid, e.strerror)\n            return (0, None)", "response": "Wait for a process to terminate."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a pretty - printed XML string for the Element.", "response": "def xml_to_string(elem, qualified_name=None, public_id=None, system_id=None):\n    \"\"\"\n    Return a pretty-printed XML string for the Element.\n    Also allows setting a document type.\n    \"\"\"\n    from xml.dom import minidom\n    rough_string = ET.tostring(elem, 'utf-8')\n    reparsed = minidom.parseString(rough_string)\n    if qualified_name:\n        doctype = minidom.DOMImplementation().createDocumentType(\n                qualified_name, public_id, system_id)\n        reparsed.insertBefore(doctype, reparsed.documentElement)\n    return reparsed.toprettyxml(indent=\"  \")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndetermining the file paths to be adopted by the user.", "response": "def program_files(self, executable):\n        \"\"\"\n        Determine the file paths to be adopted\n        \"\"\"\n        if self._get_version() == 6:\n            paths = self.REQUIRED_PATHS_6\n        elif self._get_version() > 6:\n            paths = self.REQUIRED_PATHS_7_1\n\n        return paths"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef substitute_vars(oldList, runSet=None, sourcefile=None):\n    keyValueList = []\n    if runSet:\n        benchmark = runSet.benchmark\n\n        # list with tuples (key, value): 'key' is replaced by 'value'\n        keyValueList = [\n            ('benchmark_name',     benchmark.name),\n            ('benchmark_date',     benchmark.instance),\n            ('benchmark_path',     benchmark.base_dir or '.'),\n            ('benchmark_path_abs', os.path.abspath(benchmark.base_dir)),\n            ('benchmark_file',     os.path.basename(benchmark.benchmark_file)),\n            ('benchmark_file_abs', os.path.abspath(os.path.basename(benchmark.benchmark_file))),\n            ('logfile_path',       os.path.dirname(runSet.log_folder) or '.'),\n            ('logfile_path_abs',   os.path.abspath(runSet.log_folder)),\n            ('rundefinition_name', runSet.real_name if runSet.real_name else ''),\n            ('test_name',          runSet.real_name if runSet.real_name else ''),\n        ]\n\n    if sourcefile:\n        keyValueList.append(('inputfile_name', os.path.basename(sourcefile)))\n        keyValueList.append(('inputfile_path', os.path.dirname(sourcefile) or '.'))\n        keyValueList.append(('inputfile_path_abs', os.path.dirname(os.path.abspath(sourcefile))))\n        # The following are deprecated: do not use anymore.\n        keyValueList.append(('sourcefile_name', os.path.basename(sourcefile)))\n        keyValueList.append(('sourcefile_path', os.path.dirname(sourcefile) or '.'))\n        keyValueList.append(('sourcefile_path_abs', os.path.dirname(os.path.abspath(sourcefile))))\n    if sourcefile and sourcefile.endswith(\".yml\"):\n        keyValueList.append(('taskdef_name', os.path.basename(sourcefile)))\n        keyValueList.append(('taskdef_path', os.path.dirname(sourcefile) or '.'))\n        keyValueList.append(('taskdef_path_abs', os.path.dirname(os.path.abspath(sourcefile))))\n\n    # do not use keys twice\n    assert len(set((key for (key, value) in keyValueList))) == len(keyValueList)\n\n    return [util.substitute_vars(s, keyValueList) for s in oldList]", "response": "This method replaces special substrings from a list of string\n    and return a new list."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nopens and parse a task - definition file in YAML format.", "response": "def load_task_definition_file(task_def_file):\n    \"\"\"Open and parse a task-definition file in YAML format.\"\"\"\n    try:\n        with open(task_def_file) as f:\n            task_def = yaml.safe_load(f)\n    except OSError as e:\n        raise BenchExecException(\"Cannot open task-definition file: \" + str(e))\n    except yaml.YAMLError as e:\n        raise BenchExecException(\"Invalid task definition: \" + str(e))\n\n    if str(task_def.get(\"format_version\")) not in [\"0.1\", \"1.0\"]:\n        raise BenchExecException(\n            \"Task-definition file {} specifies invalid format_version '{}'.\"\n            .format(task_def_file, task_def.get(\"format_version\")))\n\n    return task_def"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_tool_info(tool_name):\n    tool_module = tool_name if '.' in tool_name else (\"benchexec.tools.\" + tool_name)\n    try:\n        tool = __import__(tool_module, fromlist=['Tool']).Tool()\n    except ImportError as ie:\n        sys.exit('Unsupported tool \"{0}\" specified. ImportError: {1}'.format(tool_name, ie))\n    except AttributeError:\n        sys.exit('The module \"{0}\" does not define the necessary class \"Tool\", '\n                 'it cannot be used as tool info for BenchExec.'.format(tool_module))\n    return (tool_module, tool)", "response": "Load the tool - info module and return the full name of the tool - info module and the tool class."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef extract_runs_from_xml(self, sourcefilesTagList, global_required_files_pattern):\n        '''\n        This function builds a list of SourcefileSets (containing filename with options).\n        The files and their options are taken from the list of sourcefilesTags.\n        '''\n        base_dir = self.benchmark.base_dir\n        # runs are structured as sourcefile sets, one set represents one sourcefiles tag\n        blocks = []\n\n        for index, sourcefilesTag in enumerate(sourcefilesTagList):\n            sourcefileSetName = sourcefilesTag.get(\"name\")\n            matchName = sourcefileSetName or str(index)\n            if self.benchmark.config.selected_sourcefile_sets \\\n                and not any(util.wildcard_match(matchName, sourcefile_set) for sourcefile_set in self.benchmark.config.selected_sourcefile_sets):\n                    continue\n\n            required_files_pattern = global_required_files_pattern.union(\n                set(tag.text for tag in sourcefilesTag.findall('requiredfiles')))\n\n            # get lists of filenames\n            task_def_files = self.get_task_def_files_from_xml(sourcefilesTag, base_dir)\n\n            # get file-specific options for filenames\n            fileOptions = util.get_list_from_xml(sourcefilesTag)\n            propertyfile = util.text_or_none(util.get_single_child_from_xml(sourcefilesTag, PROPERTY_TAG))\n\n            # some runs need more than one sourcefile,\n            # the first sourcefile is a normal 'include'-file, we use its name as identifier\n            # for logfile and result-category all other files are 'append'ed.\n            appendFileTags = sourcefilesTag.findall(\"append\")\n\n            currentRuns = []\n            for identifier in task_def_files:\n                if identifier.endswith('.yml'):\n                    if appendFileTags:\n                        raise BenchExecException(\n                            \"Cannot combine <append> and task-definition files in the same <tasks> tag.\")\n                    run = self.create_run_from_task_definition(\n                        identifier, fileOptions, propertyfile, required_files_pattern)\n                else:\n                    run = self.create_run_for_input_file(\n                        identifier, fileOptions, propertyfile, required_files_pattern, appendFileTags)\n                if run:\n                    currentRuns.append(run)\n\n            # add runs for cases without source files\n            for run in sourcefilesTag.findall(\"withoutfile\"):\n                currentRuns.append(Run(run.text, [], fileOptions, self, propertyfile, required_files_pattern))\n\n            blocks.append(SourcefileSet(sourcefileSetName, index, currentRuns))\n\n        if self.benchmark.config.selected_sourcefile_sets:\n            for selected in self.benchmark.config.selected_sourcefile_sets:\n                if not any(util.wildcard_match(sourcefile_set.real_name, selected) for sourcefile_set in blocks):\n                    logging.warning(\n                        'The selected tasks \"%s\" are not present in the input file, '\n                        'skipping them.',\n                        selected)\n        return blocks", "response": "This function extracts runs from the XML file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_task_def_files_from_xml(self, sourcefilesTag, base_dir):\n        sourcefiles = []\n\n        # get included sourcefiles\n        for includedFiles in sourcefilesTag.findall(\"include\"):\n            sourcefiles += self.expand_filename_pattern(includedFiles.text, base_dir)\n\n        # get sourcefiles from list in file\n        for includesFilesFile in sourcefilesTag.findall(\"includesfile\"):\n\n            for file in self.expand_filename_pattern(includesFilesFile.text, base_dir):\n\n                # check for code (if somebody confuses 'include' and 'includesfile')\n                if util.is_code(file):\n                    logging.error(\n                        \"'%s' seems to contain code instead of a set of source file names.\\n\"\n                        \"Please check your benchmark definition file \"\n                        \"or remove bracket '{' from this file.\",\n                        file)\n                    sys.exit()\n\n                # read files from list\n                fileWithList = open(file, 'rt')\n                for line in fileWithList:\n\n                    # strip() removes 'newline' behind the line\n                    line = line.strip()\n\n                    # ignore comments and empty lines\n                    if not util.is_comment(line):\n                        sourcefiles += self.expand_filename_pattern(line, os.path.dirname(file))\n\n                fileWithList.close()\n\n        # remove excluded sourcefiles\n        for excludedFiles in sourcefilesTag.findall(\"exclude\"):\n            excludedFilesList = self.expand_filename_pattern(excludedFiles.text, base_dir)\n            for excludedFile in excludedFilesList:\n                sourcefiles = util.remove_all(sourcefiles, excludedFile)\n\n        for excludesFilesFile in sourcefilesTag.findall(\"excludesfile\"):\n            for file in self.expand_filename_pattern(excludesFilesFile.text, base_dir):\n                # read files from list\n                fileWithList = open(file, 'rt')\n                for line in fileWithList:\n\n                    # strip() removes 'newline' behind the line\n                    line = line.strip()\n\n                    # ignore comments and empty lines\n                    if not util.is_comment(line):\n                        excludedFilesList = self.expand_filename_pattern(line, os.path.dirname(file))\n                        for excludedFile in excludedFilesList:\n                            sourcefiles = util.remove_all(sourcefiles, excludedFile)\n\n                fileWithList.close()\n\n        return sourcefiles", "response": "Get the task - definition files from the XML definition."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_run_for_input_file(\n            self, input_file, options, property_file, required_files_pattern, append_file_tags):\n        \"\"\"Create a Run from a direct definition of the main input file (without task definition)\"\"\"\n        input_files = [input_file]\n        base_dir = os.path.dirname(input_file)\n        for append_file in append_file_tags:\n            input_files.extend(\n                self.expand_filename_pattern(append_file.text, base_dir, sourcefile=input_file))\n\n        run = Run(\n            input_file,\n            util.get_files(input_files), # expand directories to get their sub-files\n            options,\n            self,\n            property_file,\n            required_files_pattern)\n\n        if not run.propertyfile:\n            return run\n\n        prop = result.Property.create(run.propertyfile, allow_unknown=False)\n        run.properties = [prop]\n        expected_results = result.expected_results_of_file(input_file)\n        if prop.name in expected_results:\n            run.expected_results[prop.filename] = expected_results[prop.name]\n        # We do not check here if there is an expected result for the given propertyfile\n        # like we do in create_run_from_task_definition, to keep backwards compatibility.\n        return run", "response": "Create a Run from a direct definition of the main input file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_run_from_task_definition(\n            self, task_def_file, options, propertyfile, required_files_pattern):\n        \"\"\"Create a Run from a task definition in yaml format\"\"\"\n        task_def = load_task_definition_file(task_def_file)\n\n        def expand_patterns_from_tag(tag):\n            result = []\n            patterns = task_def.get(tag, [])\n            if isinstance(patterns, str) or not isinstance(patterns, collections.Iterable):\n                # accept single string in addition to list of strings\n                patterns = [patterns]\n            for pattern in patterns:\n                expanded = util.expand_filename_pattern(\n                    str(pattern), os.path.dirname(task_def_file))\n                if not expanded:\n                    raise BenchExecException(\n                        \"Pattern '{}' in task-definition file {} did not match any paths.\"\n                        .format(pattern, task_def_file))\n                expanded.sort()\n                result.extend(expanded)\n            return result\n\n        input_files = expand_patterns_from_tag(\"input_files\")\n        if not input_files:\n            raise BenchExecException(\n                \"Task-definition file {} does not define any input files.\".format(task_def_file))\n        required_files = expand_patterns_from_tag(\"required_files\")\n\n        run = Run(\n            task_def_file,\n            input_files,\n            options,\n            self,\n            propertyfile,\n            required_files_pattern,\n            required_files)\n\n        # run.propertyfile of Run is fully determined only after Run is created,\n        # thus we handle it and the expected results here.\n        if not run.propertyfile:\n            return run\n\n        # TODO: support \"property_name\" attribute in yaml\n        prop = result.Property.create(run.propertyfile, allow_unknown=True)\n        run.properties = [prop]\n\n        for prop_dict in task_def.get(\"properties\", []):\n            if not isinstance(prop_dict, dict) or \"property_file\" not in prop_dict:\n                raise BenchExecException(\n                    \"Missing property file for property in task-definition file {}.\"\n                    .format(task_def_file))\n            expanded = util.expand_filename_pattern(\n                prop_dict[\"property_file\"], os.path.dirname(task_def_file))\n            if len(expanded) != 1:\n                raise BenchExecException(\n                    \"Property pattern '{}' in task-definition file {} does not refer to exactly one file.\"\n                    .format(prop_dict[\"property_file\"], task_def_file))\n\n            # TODO We could reduce I/O by checking absolute paths and using os.path.samestat\n            # with cached stat calls.\n            if prop.filename == expanded[0] or os.path.samefile(prop.filename, expanded[0]):\n                expected_result = prop_dict.get(\"expected_verdict\")\n                if expected_result is not None and not isinstance(expected_result, bool):\n                    raise BenchExecException(\n                        \"Invalid expected result '{}' for property {} in task-definition file {}.\"\n                        .format(expected_result, prop_dict[\"property_file\"], task_def_file))\n                run.expected_results[prop.filename] = \\\n                    result.ExpectedResult(expected_result, prop_dict.get(\"subproperty\"))\n\n        if not run.expected_results:\n            logging.debug(\n                \"Ignoring run '%s' because it does not have the property from %s.\",\n                run.identifier, run.propertyfile)\n            return None\n        elif len(run.expected_results) > 1:\n            raise BenchExecException(\n                \"Property '{}' specified multiple times in task-definition file {}.\"\n                .format(prop.filename, task_def_file))\n        else:\n            return run", "response": "Create a Run from a task - definition file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the result of this run.", "response": "def set_result(self, values, visible_columns={}):\n        \"\"\"Set the result of this run.\n        Use this method instead of manually setting the run attributes and calling after_execution(),\n        this method handles all this by itself.\n        @param values: a dictionary with result values as returned by RunExecutor.execute_run(),\n            may also contain arbitrary additional values\n        @param visible_columns: a set of keys of values that should be visible by default\n            (i.e., not marked as hidden), apart from those that BenchExec shows by default anyway\n        \"\"\"\n        exitcode = values.pop('exitcode', None)\n        if exitcode is not None:\n            self.values['@exitcode'] = exitcode\n            exitcode = util.ProcessExitCode.from_raw(exitcode)\n            if exitcode.signal:\n                self.values['@exitsignal'] = exitcode.signal\n            else:\n                self.values['@returnvalue'] = exitcode.value\n\n        for key, value in values.items():\n            if key == 'walltime':\n                self.walltime = value\n            elif key == 'cputime':\n                self.cputime = value\n            elif key == 'memory':\n                self.values['memUsage'] = value\n            elif key == 'cpuenergy' and not isinstance(value, (str, bytes)):\n                energy = intel_cpu_energy.format_energy_results(value)\n                for energy_key, energy_value in energy.items():\n                    if energy_key != 'cpuenergy':\n                        energy_key = '@' + energy_key\n                    self.values[energy_key] = energy_value\n            elif key == 'cpuenergy':\n                self.values[key] = value\n            elif key in visible_columns:\n                self.values[key] = value\n            else:\n                self.values['@' + key] = value\n\n        self.after_execution(exitcode, termination_reason=values.get('terminationreason'))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn status according to result and output of tool.", "response": "def _analyze_result(self, exitcode, output, isTimeout, termination_reason):\n        \"\"\"Return status according to result and output of tool.\"\"\"\n\n        # Ask tool info.\n        tool_status = None\n        if exitcode is not None:\n            logging.debug(\"My subprocess returned %s.\", exitcode)\n            tool_status = self.runSet.benchmark.tool.determine_result(\n                exitcode.value or 0, exitcode.signal or 0, output, isTimeout)\n\n            if tool_status in result.RESULT_LIST_OTHER:\n                # for unspecific results provide some more information if possible\n                if exitcode.signal == 6:\n                    tool_status = 'ABORTED'\n                elif exitcode.signal == 11:\n                    tool_status = 'SEGMENTATION FAULT'\n                elif exitcode.signal == 15:\n                    tool_status = 'KILLED'\n                elif exitcode.signal:\n                    tool_status = 'KILLED BY SIGNAL '+str(exitcode.signal)\n\n                elif exitcode.value:\n                    tool_status = '{} ({})'.format(result.RESULT_ERROR, exitcode.value)\n\n        # Tools sometimes produce a result even after violating a resource limit.\n        # This should not be counted, so we overwrite the result with TIMEOUT/OOM\n        # here, if this is the case.\n        # However, we don't want to forget more specific results like SEGFAULT,\n        # so we do this only if the result is a \"normal\" one like TRUE/FALSE\n        # or an unspecific one like UNKNOWN/ERROR.\n        status = None\n        if isTimeout:\n            status = \"TIMEOUT\"\n        elif termination_reason:\n            status = _ERROR_RESULTS_FOR_TERMINATION_REASON.get(termination_reason, termination_reason)\n\n        if not status:\n            # regular termination\n            status = tool_status\n        elif tool_status and tool_status not in (\n                result.RESULT_LIST_OTHER + [status, 'KILLED', 'KILLED BY SIGNAL 9']):\n            # timeout/OOM but tool still returned some result\n            status = '{} ({})'.format(status, tool_status)\n\n        return status"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _is_timeout(self):\n        ''' try to find out whether the tool terminated because of a timeout '''\n        if self.cputime is None:\n            is_cpulimit = False\n        else:\n            rlimits = self.runSet.benchmark.rlimits\n            if SOFTTIMELIMIT in rlimits:\n                limit = rlimits[SOFTTIMELIMIT]\n            elif TIMELIMIT in rlimits:\n                limit = rlimits[TIMELIMIT]\n            else:\n                limit = float('inf')\n            is_cpulimit = self.cputime > limit\n\n        if self.walltime is None:\n            is_walllimit = False\n        else:\n            rlimits = self.runSet.benchmark.rlimits\n            if WALLTIMELIMIT in rlimits:\n                limit = rlimits[WALLTIMELIMIT]\n            else:\n                limit = float('inf')\n            is_walllimit = self.walltime > limit\n\n        return is_cpulimit or is_walllimit", "response": "check if the tool terminated because of a timeout"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a dict of property - > ExpectedResult from information encoded in a filename.", "response": "def expected_results_of_file(filename):\n    \"\"\"Create a dict of property->ExpectedResult from information encoded in a filename.\"\"\"\n    results = {}\n    for (filename_part, (expected_result, for_properties)) in _FILE_RESULTS.items():\n        if filename_part in filename:\n            expected_result_class = get_result_classification(expected_result)\n            assert expected_result_class in {RESULT_CLASS_TRUE, RESULT_CLASS_FALSE}\n            expected_result = (expected_result_class == RESULT_CLASS_TRUE)\n            subproperty = None\n            if len(for_properties) > 1:\n                assert for_properties == _MEMSAFETY_SUBPROPERTIES and expected_result\n                property = _PROP_MEMSAFETY\n            else:\n                property = next(iter(for_properties))\n                if property in _MEMSAFETY_SUBPROPERTIES and not expected_result:\n                    subproperty = property\n                    property = _PROP_MEMSAFETY\n            if property in results:\n                raise BenchExecException(\n                    \"Duplicate property {} in filename {}\".format(property, filename))\n            results[property] = ExpectedResult(expected_result, subproperty)\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the achieved score of a task according to the SV - COMP scoring scheme.", "response": "def _svcomp_score(category, result):\n    \"\"\"\n    Return the achieved score of a task according to the SV-COMP scoring scheme.\n    @param category: result category as determined by get_result_category\n    @param result: the result given by the tool\n    \"\"\"\n    assert result is not None\n    result_class = get_result_classification(result)\n\n    if category == CATEGORY_CORRECT_UNCONFIRMED:\n        if result_class == RESULT_CLASS_TRUE:\n            return _SCORE_CORRECT_UNCONFIRMED_TRUE\n        elif result_class == RESULT_CLASS_FALSE:\n            return _SCORE_CORRECT_UNCONFIRMED_FALSE\n        else:\n            assert False\n\n    elif category == CATEGORY_CORRECT:\n        if result_class == RESULT_CLASS_TRUE:\n            return _SCORE_CORRECT_TRUE\n        elif result_class == RESULT_CLASS_FALSE:\n            return _SCORE_CORRECT_FALSE\n        else:\n            assert False, result\n\n    elif category == CATEGORY_WRONG:\n        if result_class == RESULT_CLASS_TRUE:\n            return _SCORE_WRONG_TRUE\n        elif result_class == RESULT_CLASS_FALSE:\n            return _SCORE_WRONG_FALSE\n        else:\n            assert False\n\n    else:\n        return _SCORE_UNKNOWN"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the score of the task based on whether the result is correct or not.", "response": "def score_for_task(properties, category, result):\n    \"\"\"\n    Return the possible score of task, depending on whether the result is correct or not.\n    \"\"\"\n    assert result is not None\n    if properties and Property.create_from_names(properties).is_svcomp:\n        return _svcomp_score(category, result)\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nclassifying the given result into true false unknown and error.", "response": "def get_result_classification(result):\n    '''\n    Classify the given result into \"true\" (property holds),\n    \"false\" (property does not hold), \"unknown\", and \"error\".\n    @param result: The result given by the tool (needs to be one of the RESULT_* strings to be recognized).\n    @return One of RESULT_CLASS_* strings\n    '''\n    if result not in RESULT_LIST:\n        if result and result.startswith(RESULT_FALSE_PROP + \"(\") and result.endswith(\")\"):\n            return RESULT_CLASS_FALSE\n        return RESULT_CLASS_OTHER\n\n    if result == RESULT_TRUE_PROP or result == RESULT_SAT:\n        return RESULT_CLASS_TRUE\n    else:\n        return RESULT_CLASS_FALSE"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a new instance of the class from a given property file.", "response": "def create(cls, propertyfile, allow_unknown):\n        \"\"\"\n        Create a Property instance by attempting to parse the given property file.\n        @param propertyfile: A file name of a property file\n        @param allow_unknown: Whether to accept unknown properties\n        \"\"\"\n        with open(propertyfile) as f:\n            content = f.read().strip()\n\n        # parse content for known properties\n        is_svcomp = False\n        known_properties = []\n        only_known_svcomp_property = True\n\n        if content == 'OBSERVER AUTOMATON' or content == 'SATISFIABLE':\n            known_properties = [_PROPERTY_NAMES[content]]\n\n        elif content.startswith('CHECK'):\n            is_svcomp = True\n            for line in filter(None, content.splitlines()):\n                if content.startswith('CHECK'):\n                    # SV-COMP property, either a well-known one or a new one\n                    props_in_line = [\n                        prop for (substring, prop) in _PROPERTY_NAMES.items() if substring in line]\n                    if len(props_in_line) == 1:\n                        known_properties.append(props_in_line[0])\n                    else:\n                        only_known_svcomp_property = False\n                else:\n                    # not actually an SV-COMP property file\n                    is_svcomp = False\n                    known_properties = []\n                    break\n\n        # check if some known property content was found\n        subproperties = None\n        if only_known_svcomp_property and len(known_properties) == 1:\n            is_well_known = True\n            name = known_properties[0]\n\n        elif only_known_svcomp_property and set(known_properties) == _MEMSAFETY_SUBPROPERTIES:\n            is_well_known = True\n            name = _PROP_MEMSAFETY\n            subproperties = list(known_properties)\n\n        else:\n            if not allow_unknown:\n                raise BenchExecException(\n                    'File \"{0}\" does not contain a known property.'.format(propertyfile))\n            is_well_known = False\n            name = os.path.splitext(os.path.basename(propertyfile))[0]\n\n        return cls(propertyfile, is_well_known, is_svcomp, name, subproperties)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a Property instance from a list of well - known property names.", "response": "def create_from_names(cls, property_names):\n        \"\"\"\n        Create a Property instance from a list of well-known property names\n        @param property_names: a non-empty list of property names\n        \"\"\"\n        assert property_names\n\n        if len(property_names) == 1:\n            name = property_names[0]\n            subproperties = None\n        else:\n            name = (_PROP_MEMSAFETY if set(property_names) == _MEMSAFETY_SUBPROPERTIES\n                    else \"unknown property\")\n            subproperties = list(property_names)\n\n        is_well_known = name in _VALID_RESULTS_PER_PROPERTY.keys()\n        is_svcomp = is_well_known and (_PROP_SAT not in property_names)\n\n        return cls(None, is_well_known, is_svcomp, name, subproperties)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_file_list(shortFile):\n    if \"://\" in shortFile: # seems to be a URL\n        return [shortFile]\n\n    # expand tilde and variables\n    expandedFile = os.path.expandvars(os.path.expanduser(shortFile))\n\n    # expand wildcards\n    fileList = glob.glob(expandedFile)\n\n    # sort alphabetical,\n    # if list is emtpy, sorting returns None, so better do not sort\n    if len(fileList) != 0:\n        fileList.sort()\n    else:\n        logging.warning(\"No file matches '%s'.\", shortFile)\n\n    return fileList", "response": "This function expands a short filename to a sorted list\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nopening a URL and ensure that the result is seekable.", "response": "def open_url_seekable(path_url, mode='rt'):\n    \"\"\"Open a URL and ensure that the result is seekable,\n    copying it into a buffer if necessary.\"\"\"\n\n    logging.debug(\"Making request to '%s'\", path_url)\n    response = urllib.request.urlopen(path_url)\n    logging.debug(\"Got response %s\", response.info())\n\n    try:\n        response.seek(0)\n    except (IOError, AttributeError):\n        # Copy into buffer to allow seeking.\n        response = io.BytesIO(response.read())\n    if \"b\" in mode:\n        return response\n    else:\n        return io.TextIOWrapper(response)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef split_string_at_suffix(s, numbers_into_suffix=False):\n    if not s:\n        return (s, '')\n    pos = len(s)\n    while pos and numbers_into_suffix == s[pos-1].isdigit():\n        pos -= 1\n    return (s[:pos], s[pos:])", "response": "Splits a string into two parts a prefix and a suffix."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef collapse_equal_values(values, counts):\n    assert len(values) == len(counts)\n    previousValue = values[0]\n    previousCount = 0\n\n    for value, count in zip(values, counts):\n        if value != previousValue:\n            yield (previousValue, previousCount)\n            previousCount = 0\n            previousValue = value\n        previousCount += count\n\n    yield (previousValue, previousCount)", "response": "Given a tuple of values and counts yield the values that are equal."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of entries with common prefixes.", "response": "def merge_entries_with_common_prefixes(list_, number_of_needed_commons=6):\n    \"\"\"\n    Returns a list where sequences of post-fixed entries are shortened to their common prefix.\n    This might be useful in cases of several similar values,\n    where the prefix is identical for several entries.\n    If less than 'number_of_needed_commons' are identically prefixed, they are kept unchanged.\n    Example: ['test', 'pc1', 'pc2', 'pc3', ... , 'pc10'] -> ['test', 'pc*']\n    \"\"\"\n    # first find common entry-sequences\n    prefix = None\n    lists_to_merge = []\n    for entry in list_:\n        newPrefix,number = split_string_at_suffix(entry, numbers_into_suffix=True)\n        if entry == newPrefix or prefix != newPrefix:\n            lists_to_merge.append([])\n            prefix = newPrefix\n        lists_to_merge[-1].append((entry,newPrefix,number))\n\n    # then merge them\n    returnvalue = []\n    for common_entries in lists_to_merge:\n        common_prefix = common_entries[0][1]\n        assert all(common_prefix == prefix for entry,prefix,number in common_entries)\n        if len(common_entries) <= number_of_needed_commons:\n            returnvalue.extend((entry for entry,prefix,number in common_entries))\n        else:\n            # we use '*' to indicate several entries,\n            # it would also be possible to use '[min,max]' from '(n for e,p,n in common_entries)'\n            returnvalue.append(common_prefix + '*')\n\n    return returnvalue"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef prettylist(list_):\n    if not list_:\n        return ''\n\n    values = set()\n    uniqueList = []\n\n    for entry in list_:\n        if not entry in values:\n            values.add(entry)\n            uniqueList.append(entry)\n\n    return uniqueList[0] if len(uniqueList) == 1 \\\n        else '[' + '; '.join(uniqueList) + ']'", "response": "Returns a pretty list of duplicate entries."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _format_number(number, initial_value_sig_digits, number_of_significant_digits, max_digits_after_decimal, isToAlign,\n                   format_target):\n    \"\"\"\n    If the value is a number (or number followed by a unit),\n    this function returns a string-representation of the number\n    with the specified number of significant digits,\n    optionally aligned at the decimal point.\n    \"\"\"\n    assert format_target in POSSIBLE_FORMAT_TARGETS, \"Invalid format \" + format_target\n\n    # Round to the given amount of significant digits\n    intended_digits = min(initial_value_sig_digits, number_of_significant_digits)\n    if number == 0:\n        formatted_value = '0'\n        if max_digits_after_decimal > 0 and initial_value_sig_digits > 0:\n            formatted_value += '.' + '0' * min(max_digits_after_decimal, initial_value_sig_digits)\n\n    else:\n        float_value = round(number, - int(floor(log10(abs(number)))) + (number_of_significant_digits - 1))\n\n        if not format_target.startswith('tooltip'):\n            max_digits_to_display = max_digits_after_decimal\n        else:\n            max_digits_to_display = len(\n                str(float_value))  # This value may be too big, but extra digits will be cut below\n        formatted_value = \"{0:.{1}f}\".format(float_value, max_digits_to_display)\n\n        # Get the number of intended significant digits and the number of current significant digits.\n        # If we have not enough digits due to rounding, 0's have to be re-added.\n        # If we have too many digits due to conversion of integers to float (e.g. 1234.0), the decimals have to be cut\n        current_sig_digits = _get_significant_digits(formatted_value)\n\n        digits_to_add = intended_digits - current_sig_digits\n\n        if digits_to_add > 0:\n            if '.' not in formatted_value:\n                raise AssertionError(\n                    \"Unexpected string '{}' after rounding '{}' to '{}' with {} significant digits and {} decimal digits for format '{}'\"\n                        .format(formatted_value, number, float_value, intended_digits, max_digits_to_display,\n                                format_target))\n            formatted_value += \"\".join(['0'] * digits_to_add)\n        elif digits_to_add < 0:\n            if '.' in formatted_value[:digits_to_add]:\n                formatted_value = formatted_value[:digits_to_add]\n            else:\n                formatted_value = str(round(float_value))\n\n            if formatted_value.endswith('.'):\n                formatted_value = formatted_value[:-1]\n\n    # Cut the 0 in front of the decimal point for values < 1.\n    # Example: 0.002 => .002\n    if _is_to_cut(formatted_value, format_target, isToAlign):\n        assert formatted_value[0] == '0'\n        formatted_value = formatted_value[1:]\n\n    # Alignment\n    if isToAlign:\n        formatted_value = _format_number_align(formatted_value, max_digits_after_decimal, format_target)\n    return formatted_value", "response": "Formats a number according to the given format target."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the type of the given column based on its row values on the given RunSetResult.", "response": "def get_column_type(column, column_values):\n    \"\"\"\n    Returns the type of the given column based on its row values on the given RunSetResult.\n    @param column: the column to return the correct ColumnType for\n    @param column_values: the column values to consider\n    @return: a tuple of a type object describing the column - the concrete ColumnType is stored in the attribute 'type',\n        the display unit of the column, which may be None,\n        the source unit of the column, which may be None,\n        and the scale factor to convert from the source unit to the display unit.\n        If no scaling is necessary for conversion, this value is 1.\n    \"\"\"\n\n    try:\n        return _get_column_type_heur(column, column_values)\n    except util.TableDefinitionError as e:\n        logging.error(\"Column type couldn't be determined: {}\".format(e.message))\n        return ColumnType.text, None, None, 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the amount of decimal digits of the given regex match considering the number of significant digits for the given column.", "response": "def _get_decimal_digits(decimal_number_match, number_of_significant_digits):\n    \"\"\"\n    Returns the amount of decimal digits of the given regex match, considering the number of significant\n    digits for the provided column.\n\n    @param decimal_number_match: a regex match of a decimal number, resulting from REGEX_MEASURE.match(x).\n    @param number_of_significant_digits: the number of significant digits required\n    @return: the number of decimal digits of the given decimal number match's representation, after expanding\n        the number to the required amount of significant digits\n    \"\"\"\n\n    assert 'e' not in decimal_number_match.group()  # check that only decimal notation is used\n\n    try:\n        num_of_digits = int(number_of_significant_digits)\n    except TypeError:\n        num_of_digits = DEFAULT_NUMBER_OF_SIGNIFICANT_DIGITS\n\n    if not decimal_number_match.group(GROUP_DEC_PART):\n        return 0\n\n    # If 1 > value > 0, only look at the decimal digits.\n    # In the second condition, we have to remove the first character from the decimal part group because the\n    # first character always is '.'\n    if int(decimal_number_match.group(GROUP_INT_PART)) == 0 \\\n            and int(decimal_number_match.group(GROUP_DEC_PART)[1:]) != 0:\n\n        max_num_of_digits = len(decimal_number_match.group(GROUP_SIG_DEC_PART))\n        num_of_digits = min(num_of_digits, max_num_of_digits)\n        # number of needed decimal digits = number of zeroes after decimal point + significant digits\n        curr_dec_digits = len(decimal_number_match.group(GROUP_ZEROES)) + int(num_of_digits)\n\n    else:\n        max_num_of_digits = \\\n            len(decimal_number_match.group(GROUP_INT_PART)) + len(decimal_number_match.group(GROUP_DEC_PART))\n        num_of_digits = min(num_of_digits, max_num_of_digits)\n        # number of needed decimal digits = significant digits - number of digits in front of decimal point\n        curr_dec_digits = int(num_of_digits) - len(decimal_number_match.group(GROUP_INT_PART))\n\n    return curr_dec_digits"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef format_value(self, value, isToAlign=False, format_target=\"html\"):\n        # Only format counts and measures\n        if self.type.type != ColumnType.count and self.type.type != ColumnType.measure:\n            return value\n\n        if format_target not in POSSIBLE_FORMAT_TARGETS:\n            raise ValueError('Unknown format target')\n\n        if value is None or value == '':\n            return ''\n\n        # If the number ends with \"s\" or another unit, remove it.\n        # Units should not occur in table cells, but in the table head.\n        number_str = util.remove_unit(str(value).strip())\n        number = float(number_str)\n\n        if isnan(number):\n            return 'NaN'\n        elif number == inf:\n            return 'Inf'\n        elif number == -inf:\n            return '-Inf'\n\n        # Apply the scale factor to the value\n        if self.scale_factor is not None:\n            number *= self.scale_factor\n\n        number_of_significant_digits = self.number_of_significant_digits\n        max_dec_digits = 0\n        if number_of_significant_digits is None and format_target is \"tooltip_stochastic\":\n            return str(round(number, DEFAULT_TOOLTIP_PRECISION))\n\n        elif self.type.type == ColumnType.measure:\n            if number_of_significant_digits is None and format_target is not \"csv\":\n                number_of_significant_digits = DEFAULT_TIME_PRECISION\n            max_dec_digits = self.type.max_decimal_digits\n\n        if number_of_significant_digits is not None:\n            current_significant_digits = _get_significant_digits(number_str)\n            return _format_number(number, current_significant_digits, number_of_significant_digits, max_dec_digits,\n                                  isToAlign, format_target)\n        else:\n            if number == float(number_str) or isnan(number) or isinf(number):\n                # TODO remove as soon as scaled values are handled correctly\n                return number_str\n            if int(number) == number:\n                number = int(number)\n            return str(number)", "response": "Format a value nicely for human - readable output."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef executable(self):\n        return util.find_executable(self.BINS[0], os.path.join(\"bin\", self.BINS[0]) )", "response": "Find the path to the executable file that will get executed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing the output of the tool and extract the verification result. This method always needs to be overridden. If the tool gave a result, this method needs to return one of the benchexec.result.RESULT_* strings. Otherwise an arbitrary string can be returned that will be shown to the user and should give some indication of the failure reason (e.g., \"CRASH\", \"OUT_OF_MEMORY\", etc.).", "response": "def determine_result(self, returncode, returnsignal, output, isTimeout):\n        \"\"\"\n        Parse the output of the tool and extract the verification result.\n        This method always needs to be overridden.\n        If the tool gave a result, this method needs to return one of the\n        benchexec.result.RESULT_* strings.\n        Otherwise an arbitrary string can be returned that will be shown to the user\n        and should give some indication of the failure reason\n        (e.g., \"CRASH\", \"OUT_OF_MEMORY\", etc.).\n        \"\"\"\n\n        if not output:\n            return 'ERROR - no output'\n\n        last = output[-1]\n\n        if isTimeout:\n            return 'TIMEOUT'\n\n        if returncode != 0:\n            return 'ERROR - Pre-run'\n\n        if last is None:\n            return 'ERROR - no output'\n        elif 'result: true' in last:\n            return result.RESULT_TRUE_PROP\n        elif 'result: false' in last:\n            return result.RESULT_FALSE_REACH\n        else:\n            return result.RESULT_UNKNOWN"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef program_files(self, executable):\n        directory = os.path.dirname(executable)\n        return ([os.path.join('.', directory, x) for x in self.BINS] +\n                [os.path.join('.', directory, \"..\", \"lib\", x) for x in self.LIBS])", "response": "Returns a list of files or directories that need to be run for the given executable."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_my_cgroups(cgroup_paths=None):\n    logging.debug('Analyzing /proc/mounts and /proc/self/cgroup for determining cgroups.')\n    if cgroup_paths is None:\n        my_cgroups = dict(_find_own_cgroups())\n    else:\n        my_cgroups = dict(_parse_proc_pid_cgroup(cgroup_paths))\n\n    cgroupsParents = {}\n    for subsystem, mount in _find_cgroup_mounts():\n        # Ignore mount points where we do not have any access,\n        # e.g. because a parent directory has insufficient permissions\n        # (lxcfs mounts cgroups under /run/lxcfs in such a way).\n        if os.access(mount, os.F_OK):\n            cgroupPath = os.path.join(mount, my_cgroups[subsystem])\n            if (not os.access(cgroupPath, os.W_OK) and\n                    os.access(os.path.join(cgroupPath, CGROUP_FALLBACK_PATH), os.W_OK)):\n                cgroupPath = os.path.join(cgroupPath, CGROUP_FALLBACK_PATH)\n            cgroupsParents[subsystem] = cgroupPath\n\n    return Cgroup(cgroupsParents)", "response": "Find all cgroups that are available for the current process."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the information which subsystems are mounted where.", "response": "def _find_cgroup_mounts():\n    \"\"\"\n    Return the information which subsystems are mounted where.\n    @return a generator of tuples (subsystem, mountpoint)\n    \"\"\"\n    try:\n        with open('/proc/mounts', 'rt') as mountsFile:\n            for mount in mountsFile:\n                mount = mount.split(' ')\n                if mount[2] == 'cgroup':\n                    mountpoint = mount[1]\n                    options = mount[3]\n                    for option in options.split(','):\n                        if option in ALL_KNOWN_SUBSYSTEMS:\n                            yield (option, mountpoint)\n    except IOError:\n        logging.exception('Cannot read /proc/mounts')"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind the cgroups that this process is in.", "response": "def _find_own_cgroups():\n    \"\"\"\n    For all subsystems, return the information in which (sub-)cgroup this process is in.\n    (Each process is in exactly cgroup in each hierarchy.)\n    @return a generator of tuples (subsystem, cgroup)\n    \"\"\"\n    try:\n        with open('/proc/self/cgroup', 'rt') as ownCgroupsFile:\n            for cgroup in _parse_proc_pid_cgroup(ownCgroupsFile):\n                yield cgroup\n    except IOError:\n        logging.exception('Cannot read /proc/self/cgroup')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse a proc - pid cgroup file into tuples of subsystem and cgroup.", "response": "def _parse_proc_pid_cgroup(content):\n    \"\"\"\n    Parse a /proc/*/cgroup file into tuples of (subsystem,cgroup).\n    @param content: An iterable over the lines of the file.\n    @return: a generator of tuples\n    \"\"\"\n    for ownCgroup in content:\n        #each line is \"id:subsystem,subsystem:path\"\n        ownCgroup = ownCgroup.strip().split(':')\n        try:\n            path = ownCgroup[2][1:] # remove leading /\n        except IndexError:\n            raise IndexError(\"index out of range for \" + str(ownCgroup))\n        for subsystem in ownCgroup[1].split(','):\n            yield (subsystem, path)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _register_process_with_cgrulesengd(pid):\n    # Logging/printing from inside preexec_fn would end up in the output file,\n    # not in the correct logger, thus it is disabled here.\n    from ctypes import cdll\n    try:\n        libcgroup = cdll.LoadLibrary('libcgroup.so.1')\n        failure = libcgroup.cgroup_init()\n        if failure:\n            pass\n            #print('Could not initialize libcgroup, error {}'.format(success))\n        else:\n            CGROUP_DAEMON_UNCHANGE_CHILDREN = 0x1\n            failure = libcgroup.cgroup_register_unchanged_process(pid, CGROUP_DAEMON_UNCHANGE_CHILDREN)\n            if failure:\n                pass\n                #print('Could not register process to cgrulesndg, error {}. '\n                #      'Probably the daemon will mess up our cgroups.'.format(success))\n    except OSError:\n        pass", "response": "This function is used to register a process with cgrulesengd daemon."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck whether the given subsystem is writable and creates a fresh child cgroup if it does not exist. Returns True if it is False otherwise.", "response": "def require_subsystem(self, subsystem, log_method=logging.warning):\n        \"\"\"\n        Check whether the given subsystem is enabled and is writable\n        (i.e., new cgroups can be created for it).\n        Produces a log message for the user if one of the conditions is not fulfilled.\n        If the subsystem is enabled but not writable, it will be removed from\n        this instance such that further checks with \"in\" will return \"False\".\n        @return A boolean value.\n        \"\"\"\n        if not subsystem in self:\n            log_method(\n                'Cgroup subsystem %s is not enabled. '\n                'Please enable it with \"sudo mount -t cgroup none /sys/fs/cgroup\".',\n                subsystem)\n            return False\n\n        try:\n            test_cgroup = self.create_fresh_child_cgroup(subsystem)\n            test_cgroup.remove()\n        except OSError as e:\n            self.paths = set(self.per_subsystem.values())\n            log_method(\n                'Cannot use cgroup hierarchy mounted at {0} for subsystem {1}, reason: {2}. '\n                'If permissions are wrong, please run \"sudo chmod o+wt \\'{0}\\'\".'\n                .format(self.per_subsystem[subsystem], subsystem, e.strerror))\n            del self.per_subsystem[subsystem]\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a fresh child cgroup for the current cgroup for at least the given subsystems.", "response": "def create_fresh_child_cgroup(self, *subsystems):\n        \"\"\"\n        Create child cgroups of the current cgroup for at least the given subsystems.\n        @return: A Cgroup instance representing the new child cgroup(s).\n        \"\"\"\n        assert set(subsystems).issubset(self.per_subsystem.keys())\n        createdCgroupsPerSubsystem = {}\n        createdCgroupsPerParent = {}\n        for subsystem in subsystems:\n            parentCgroup = self.per_subsystem[subsystem]\n            if parentCgroup in createdCgroupsPerParent:\n                # reuse already created cgroup\n                createdCgroupsPerSubsystem[subsystem] = createdCgroupsPerParent[parentCgroup]\n                continue\n\n            cgroup = tempfile.mkdtemp(prefix=CGROUP_NAME_PREFIX, dir=parentCgroup)\n            createdCgroupsPerSubsystem[subsystem] = cgroup\n            createdCgroupsPerParent[parentCgroup] = cgroup\n\n            # add allowed cpus and memory to cgroup if necessary\n            # (otherwise we can't add any tasks)\n            def copy_parent_to_child(name):\n                shutil.copyfile(os.path.join(parentCgroup, name), os.path.join(cgroup, name))\n            try:\n                copy_parent_to_child('cpuset.cpus')\n                copy_parent_to_child('cpuset.mems')\n            except IOError:\n                # expected to fail if cpuset subsystem is not enabled in this hierarchy\n                pass\n\n        return Cgroup(createdCgroupsPerSubsystem)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a process to the cgroups represented by this instance.", "response": "def add_task(self, pid):\n        \"\"\"\n        Add a process to the cgroups represented by this instance.\n        \"\"\"\n        _register_process_with_cgrulesengd(pid)\n        for cgroup in self.paths:\n            with open(os.path.join(cgroup, 'tasks'), 'w') as tasksFile:\n                tasksFile.write(str(pid))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a generator of all the PIDs currently in this cgroup for the given subsystem.", "response": "def get_all_tasks(self, subsystem):\n        \"\"\"\n        Return a generator of all PIDs currently in this cgroup for the given subsystem.\n        \"\"\"\n        with open(os.path.join(self.per_subsystem[subsystem], 'tasks'), 'r') as tasksFile:\n            for line in tasksFile:\n                yield int(line)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef kill_all_tasks_recursively(self, kill_process_fn):\n        def kill_all_tasks_in_cgroup_recursively(cgroup):\n            files = [os.path.join(cgroup,f) for f in os.listdir(cgroup)]\n            subdirs = filter(os.path.isdir, files)\n\n            for subCgroup in subdirs:\n                kill_all_tasks_in_cgroup_recursively(subCgroup)\n                remove_cgroup(subCgroup)\n\n            kill_all_tasks_in_cgroup(cgroup, kill_process_fn)\n\n        for cgroup in self.paths:\n            kill_all_tasks_in_cgroup_recursively(cgroup)", "response": "Kill all tasks in this cgroup and all its children forcefully."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck whether the given value exists in the given subsystem.", "response": "def has_value(self, subsystem, option):\n        \"\"\"\n        Check whether the given value exists in the given subsystem.\n        Does not make a difference whether the value is readable, writable, or both.\n        Do not include the subsystem name in the option name.\n        Only call this method if the given subsystem is available.\n        \"\"\"\n        assert subsystem in self\n        return os.path.isfile(os.path.join(self.per_subsystem[subsystem], subsystem + '.' + option))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_value(self, subsystem, option):\n        assert subsystem in self, 'Subsystem {} is missing'.format(subsystem)\n        return util.read_file(self.per_subsystem[subsystem], subsystem + '.' + option)", "response": "Read the given value from the given subsystem."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_file_lines(self, subsystem, option):\n        assert subsystem in self\n        with open(os.path.join(self.per_subsystem[subsystem], subsystem + '.' + option)) as f:\n            for line in f:\n                yield line", "response": "Read the lines of the given file from the given subsystem and option name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_key_value_pairs(self, subsystem, filename):\n        assert subsystem in self\n        return util.read_key_value_pairs_from_file(self.per_subsystem[subsystem], subsystem + '.' + filename)", "response": "Read the lines of the given file from the given subsystem and return a list of key - value pairs."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites the given value for the given subsystem and option.", "response": "def set_value(self, subsystem, option, value):\n        \"\"\"\n        Write the given value for the given subsystem.\n        Do not include the subsystem name in the option name.\n        Only call this method if the given subsystem is available.\n        \"\"\"\n        assert subsystem in self\n        util.write_file(str(value), self.per_subsystem[subsystem], subsystem + '.' + option)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef remove(self):\n        for cgroup in self.paths:\n            remove_cgroup(cgroup)\n\n        del self.paths\n        del self.per_subsystem", "response": "Remove all cgroups from the system."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses a time stamp in the year - month - day hour - minute format.", "response": "def parse_time_arg(s):\n    \"\"\"\n    Parse a time stamp in the \"year-month-day hour-minute\" format.\n    \"\"\"\n    try:\n        return time.strptime(s, \"%Y-%m-%d %H:%M\")\n    except ValueError as e:\n        raise argparse.ArgumentTypeError(e)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef main(benchexec=None, argv=None):\n    if sys.version_info < (3,):\n        sys.exit('benchexec needs Python 3 to run.')\n    # ignore SIGTERM\n    signal.signal(signal.SIGTERM, signal_handler_ignore)\n    try:\n        if not benchexec:\n            benchexec = BenchExec()\n        sys.exit(benchexec.start(argv or sys.argv))\n    except BenchExecException as e:\n        sys.exit('Error: ' + str(e))\n    except KeyboardInterrupt: # this block is reached, when interrupt is thrown before or after a run set execution\n        benchexec.stop()\n        util.printOut(\"\\n\\nScript was interrupted by user, some runs may not be done.\")", "response": "This is the main method of the benchmarks script. It is called by benchexec. start and benchexec. stop."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef start(self, argv):\n        parser = self.create_argument_parser()\n        self.config = parser.parse_args(argv[1:])\n\n        for arg in self.config.files:\n            if not os.path.exists(arg) or not os.path.isfile(arg):\n                parser.error(\"File {0} does not exist.\".format(repr(arg)))\n\n        if os.path.isdir(self.config.output_path):\n            self.config.output_path = os.path.normpath(self.config.output_path) + os.sep\n\n        self.setup_logging()\n\n        self.executor = self.load_executor()\n\n        returnCode = 0\n        for arg in self.config.files:\n            if self.stopped_by_interrupt:\n                break\n            logging.debug(\"Benchmark %r is started.\", arg)\n            rc = self.execute_benchmark(arg)\n            returnCode = returnCode or rc\n            logging.debug(\"Benchmark %r is done.\", arg)\n\n        logging.debug(\"I think my job is done. Have a nice day!\")\n        return returnCode", "response": "Start BenchExec.\n        @param argv: command-line options for BenchExec"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate an argument parser for the command - line options.", "response": "def create_argument_parser(self):\n        \"\"\"\n        Create a parser for the command-line options.\n        May be overwritten for adding more configuration options.\n        @return: an argparse.ArgumentParser instance\n        \"\"\"\n        parser = argparse.ArgumentParser(\n            fromfile_prefix_chars='@',\n            description=\n            \"\"\"Execute benchmarks for a given tool with a set of input files.\n               Benchmarks are defined in an XML file given as input.\n               Command-line parameters can additionally be read from a file if file name prefixed with '@' is given as argument.\n               The tool table-generator can be used to create tables for the results.\n               Part of BenchExec: https://github.com/sosy-lab/benchexec/\"\"\")\n\n        parser.add_argument(\"files\", nargs='+', metavar=\"FILE\",\n                          help=\"XML file with benchmark definition\")\n        parser.add_argument(\"-d\", \"--debug\",\n                          action=\"store_true\",\n                          help=\"Enable debug output and a debugging helper on signal USR1\")\n\n        parser.add_argument(\"-r\", \"--rundefinition\", dest=\"selected_run_definitions\",\n                          action=\"append\",\n                          help=\"Run only the specified RUN_DEFINITION from the benchmark definition file. \"\n                                + \"This option can be specified several times and can contain wildcards.\",\n                          metavar=\"RUN_DEFINITION\")\n\n        parser.add_argument(\"-t\", \"--tasks\", dest=\"selected_sourcefile_sets\",\n                          action=\"append\",\n                          help=\"Run only the tasks from the tasks tag with TASKS as name. \"\n                                + \"This option can be specified several times and can contain wildcards.\",\n                          metavar=\"TASKS\")\n\n        parser.add_argument(\"-n\", \"--name\",\n                          dest=\"name\", default=None,\n                          help=\"Set name of benchmark execution to NAME\",\n                          metavar=\"NAME\")\n\n        parser.add_argument(\"-o\", \"--outputpath\",\n                          dest=\"output_path\", type=str,\n                          default=self.DEFAULT_OUTPUT_PATH,\n                          help=\"Output prefix for the generated results. \"\n                                + \"If the path is a folder files are put into it,\"\n                                + \"otherwise it is used as a prefix for the resulting files.\")\n\n        parser.add_argument(\"-T\", \"--timelimit\",\n                          dest=\"timelimit\", default=None,\n                          help='Time limit for each run, e.g. \"90s\" '\n                               '(overwrites time limit and hard time limit from XML file, '\n                               'use \"-1\" to disable time limits completely)',\n                          metavar=\"SECONDS\")\n\n        parser.add_argument(\"-W\", \"--walltimelimit\",\n                            dest=\"walltimelimit\", default=None,\n                            help='Wall time limit for each run, e.g. \"90s\" '\n                                 '(overwrites wall time limit from XML file, '\n                                 'use \"-1\" to use CPU time limit plus a few seconds, such value is also used by default)',\n                            metavar=\"SECONDS\")\n\n        parser.add_argument(\"-M\", \"--memorylimit\",\n                          dest=\"memorylimit\", default=None,\n                          help=\"Memory limit, if no unit is given MB are assumed (-1 to disable)\",\n                          metavar=\"BYTES\")\n\n        parser.add_argument(\"-N\", \"--numOfThreads\",\n                          dest=\"num_of_threads\", default=None, type=int,\n                          help=\"Run n benchmarks in parallel\",\n                          metavar=\"n\")\n\n        parser.add_argument(\"-c\", \"--limitCores\", dest=\"corelimit\",\n                          default=None,\n                          metavar=\"N\",\n                          help=\"Limit each run of the tool to N CPU cores (-1 to disable).\")\n\n        parser.add_argument(\"--allowedCores\",\n                          dest=\"coreset\", default=None, type=util.parse_int_list,\n                          help=\"Limit the set of cores BenchExec will use for all runs \"\n                               \"(Applied only if the number of CPU cores is limited).\",\n                          metavar=\"N,M-K\",)\n\n        parser.add_argument(\"--user\",\n                            dest=\"users\",\n                            action=\"append\",\n                            metavar=\"USER\",\n                            help=\"Execute benchmarks under given user account(s) (needs password-less sudo setup).\")\n\n        parser.add_argument(\"--no-compress-results\",\n                            dest=\"compress_results\", action=\"store_false\",\n                            help=\"Do not compress result files.\")\n\n        def parse_filesize_value(value):\n            try:\n                value = int(value)\n                if value == -1:\n                    return None\n                logging.warning(\n                    'Value \"%s\" for logfile size interpreted as MB for backwards compatibility, '\n                    'specify a unit to make this unambiguous.',\n                    value)\n                value = value * _BYTE_FACTOR * _BYTE_FACTOR\n            except ValueError:\n                value = util.parse_memory_value(value)\n            return value\n\n        parser.add_argument(\"--maxLogfileSize\", dest=\"maxLogfileSize\",\n                            type=parse_filesize_value, default=20*_BYTE_FACTOR*_BYTE_FACTOR,\n                            metavar=\"SIZE\",\n                            help=\"Shrink logfiles to given size if they are too big. \"\n                                 \"(-1 to disable, default value: 20 MB).\")\n\n        parser.add_argument(\"--filesCountLimit\", type=int, metavar=\"COUNT\",\n            help=\"maximum number of files the tool may write to (checked periodically, counts only files written in container mode or to temporary directories)\")\n        parser.add_argument(\"--filesSizeLimit\", type=util.parse_memory_value, metavar=\"BYTES\",\n            help=\"maximum size of files the tool may write (checked periodically, counts only files written in container mode or to temporary directories)\")\n\n        parser.add_argument(\"--commit\", dest=\"commit\",\n                          action=\"store_true\",\n                          help=\"If the output path is a git repository without local changes, \"\n                                + \"add and commit the result files.\")\n\n        parser.add_argument(\"--message\",\n                          dest=\"commit_message\", type=str,\n                          default=\"Results for benchmark run\",\n                          help=\"Commit message if --commit is used.\")\n\n        parser.add_argument(\"--startTime\",\n                          dest=\"start_time\",\n                          type=parse_time_arg,\n                          default=None,\n                          metavar=\"'YYYY-MM-DD hh:mm'\",\n                          help='Set the given date and time as the start time of the benchmark.')\n\n        parser.add_argument(\"--version\",\n                            action=\"version\",\n                            version=\"%(prog)s \" + __version__)\n\n        try:\n            from benchexec import containerexecutor\n        except Exception:\n            # This fails e.g. on MacOS X because of missing libc.\n            # We want to keep BenchExec usable for cases where the\n            # localexecutor is replaced by something else.\n            logging.debug(\"Could not import container feature:\", exc_info=1)\n        else:\n            container_args = parser.add_argument_group(\"optional arguments for run container\")\n            container_on_args = container_args.add_mutually_exclusive_group()\n            container_on_args.add_argument(\"--container\", action='store_true',\n                help=\"force isolation of run in container (future default starting with BenchExec 2.0)\")\n            container_on_args.add_argument(\"--no-container\", action='store_true',\n                help=\"disable use of containers for isolation of runs (current default)\")\n            containerexecutor.add_basic_container_args(container_args)\n\n        return parser"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setup_logging(self):\n        if self.config.debug:\n            util.setup_logging(level=logging.DEBUG)\n            util.activate_debug_shell_on_signal()\n        else:\n            util.setup_logging(level=logging.INFO)", "response": "Configure the logging framework."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexecutes a single benchmark as defined in a file.", "response": "def execute_benchmark(self, benchmark_file):\n        \"\"\"\n        Execute a single benchmark as defined in a file.\n        If called directly, ensure that config and executor attributes are set up.\n        @param benchmark_file: the name of a benchmark-definition XML file\n        @return: a result value from the executor module\n        \"\"\"\n        benchmark = Benchmark(benchmark_file, self.config,\n                              self.config.start_time or time.localtime())\n        self.check_existing_results(benchmark)\n\n        self.executor.init(self.config, benchmark)\n        output_handler = OutputHandler(benchmark, self.executor.get_system_info(),\n                                       self.config.compress_results)\n\n        logging.debug(\"I'm benchmarking %r consisting of %s run sets.\",\n                      benchmark_file, len(benchmark.run_sets))\n\n        try:\n            result = self.executor.execute_benchmark(benchmark, output_handler)\n        finally:\n            output_handler.close()\n            # remove useless log folder if it is empty\n            try:\n                os.rmdir(benchmark.log_folder)\n            except:\n                pass\n\n        if self.config.commit and not self.stopped_by_interrupt:\n            try:\n                util.add_files_to_git_repository(self.config.output_path,\n                        output_handler.all_created_files,\n                        self.config.commit_message + '\\n\\n'\n                            + output_handler.description + '\\n\\n'\n                            + str(output_handler.statistics))\n            except OSError as e:\n                logging.warning('Could not add files to git repository: %s', e)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_existing_results(self, benchmark):\n        if os.path.exists(benchmark.log_folder):\n            sys.exit('Output directory {0} already exists, will not overwrite existing results.'.format(benchmark.log_folder))\n        if os.path.exists(benchmark.log_zip):\n            sys.exit('Output archive {0} already exists, will not overwrite existing results.'.format(benchmark.log_zip))", "response": "Check and abort if the target directory for the benchmark results\n        already exists in order to avoid overwriting results."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stop(self):\n        self.stopped_by_interrupt = True\n\n        if self.executor:\n            self.executor.stop()", "response": "Stop execution of a benchmark."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef allocate_stack(size=DEFAULT_STACK_SIZE):\n    # Allocate memory with appropriate flags for a stack as in https://blog.fefe.de/?ts=a85c8ba7\n    base = libc.mmap(\n        None,\n        size + GUARD_PAGE_SIZE,\n        libc.PROT_READ | libc.PROT_WRITE,\n        libc.MAP_PRIVATE | libc.MAP_ANONYMOUS | libc.MAP_GROWSDOWN | libc.MAP_STACK,\n        -1, 0)\n\n    try:\n        # create a guard page that crashes the application when it is written to (on stack overflow)\n        libc.mprotect(base, GUARD_PAGE_SIZE, libc.PROT_NONE)\n\n        yield ctypes.c_void_p(base + size + GUARD_PAGE_SIZE)\n    finally:\n        libc.munmap(base, size + GUARD_PAGE_SIZE)", "response": "Allocate some memory that can be used as a stack."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef execute_in_namespace(func, use_network_ns=True):\n    flags = (signal.SIGCHLD |\n        libc.CLONE_NEWNS | libc.CLONE_NEWUTS | libc.CLONE_NEWIPC | libc.CLONE_NEWUSER |\n        libc.CLONE_NEWPID)\n    if use_network_ns:\n        flags |= libc.CLONE_NEWNET\n\n    # We use the syscall clone() here, which is similar to fork().\n    # Calling it without letting Python know about it is dangerous (especially because\n    # we want to execute Python code in the child, too), but so far it seems to work.\n    # Basically we attempt to do (almost) the same that os.fork() does (cf. function os_fork_impl\n    # in https://github.com/python/cpython/blob/master/Modules/posixmodule.c).\n    # We currently do not take the import lock os.lock() does because it is only available\n    # via an internal API, and because the child should never import anything anyway\n    # (inside the container, modules might not be visible).\n    # It is very important, however, that we have the GIL during clone(),\n    # otherwise the child will often deadlock when trying to execute Python code.\n    # Luckily, the ctypes module allows us to hold the GIL while executing the\n    # function by using ctypes.PyDLL as library access instead of ctypes.CLL.\n\n    def child_func():\n        # This is necessary for correcting the Python interpreter state after a\n        # fork-like operation. For example, it resets the GIL and fixes state of\n        # several modules like threading and signal.\n        ctypes.pythonapi.PyOS_AfterFork()\n\n        return func()\n\n    with allocate_stack() as stack:\n        pid = libc.clone(ctypes.CFUNCTYPE(ctypes.c_int)(child_func), stack, flags, None)\n    return pid", "response": "Execute a function in a child process in separate namespaces."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setup_user_mapping(pid, uid=os.getuid(), gid=os.getgid()):\n    proc_child = os.path.join(\"/proc\", str(pid))\n    try:\n        uid_map = \"{0} {1} 1\".format(uid, os.getuid()) # map uid internally to our uid externally\n        util.write_file(uid_map, proc_child, \"uid_map\")\n    except IOError as e:\n        logging.warning(\"Creating UID mapping into container failed: %s\", e)\n\n    try:\n        util.write_file(\"deny\", proc_child, \"setgroups\")\n    except IOError as e:\n        # Not all systems have this file (depends on the kernel version),\n        # but if it does not exist, we do not need to write to it.\n        if e.errno != errno.ENOENT:\n            logging.warning(\"Could not write to setgroups file in /proc: %s\", e)\n\n    try:\n        gid_map = \"{0} {1} 1\".format(gid, os.getgid()) # map gid internally to our gid externally\n        util.write_file(gid_map, proc_child, \"gid_map\")\n    except IOError as e:\n        logging.warning(\"Creating GID mapping into container failed: %s\", e)", "response": "Create a user mapping for the process with the given PID."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef activate_network_interface(iface):\n    iface = iface.encode()\n\n    SIOCGIFFLAGS = 0x8913 # /usr/include/bits/ioctls.h\n    SIOCSIFFLAGS = 0x8914 # /usr/include/bits/ioctls.h\n    IFF_UP = 0x1 # /usr/include/net/if.h\n\n    # We need to use instances of \"struct ifreq\" for communicating with the kernel.\n    # This struct is complex with a big contained union, we define here only the few necessary\n    # fields for the two cases we need.\n    # The layout is given in the format used by the struct module:\n    STRUCT_IFREQ_LAYOUT_IFADDR_SAFAMILY = b\"16sH14s\" # ifr_name, ifr_addr.sa_family, padding\n    STRUCT_IFREQ_LAYOUT_IFFLAGS = b\"16sH14s\" # ifr_name, ifr_flags, padding\n\n    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_IP)\n    try:\n        # Get current interface flags from kernel\n        ifreq = struct.pack(STRUCT_IFREQ_LAYOUT_IFADDR_SAFAMILY, iface, socket.AF_INET, b'0' * 14)\n        ifreq = fcntl.ioctl(sock, SIOCGIFFLAGS, ifreq)\n        if_flags = struct.unpack(STRUCT_IFREQ_LAYOUT_IFFLAGS, ifreq)[1]\n\n        # Set new flags\n        ifreq = struct.pack(STRUCT_IFREQ_LAYOUT_IFFLAGS, iface, if_flags | IFF_UP, b'0' * 14)\n        fcntl.ioctl(sock, SIOCSIFFLAGS, ifreq)\n    finally:\n        sock.close()", "response": "Activate the given network interface."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget all current mount points of the system.", "response": "def get_mount_points():\n    \"\"\"Get all current mount points of the system.\n    Changes to the mount points during iteration may be reflected in the result.\n    @return a generator of (source, target, fstype, options),\n    where options is a list of bytes instances, and the others are bytes instances\n    (this avoids encoding problems with mount points with problematic characters).\n    \"\"\"\n    def decode_path(path):\n        # Replace tab, space, newline, and backslash escapes with actual characters.\n        # According to man 5 fstab, only tab and space escaped, but Linux escapes more:\n        # https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/fs/proc_namespace.c?id=12a54b150fb5b6c2f3da932dc0e665355f8a5a48#n85\n        return path.replace(br\"\\011\", b\"\\011\").replace(br\"\\040\", b\"\\040\").replace(br\"\\012\", b\"\\012\").replace(br\"\\134\", b\"\\134\")\n\n    with open(\"/proc/self/mounts\", \"rb\") as mounts:\n        # The format of this file is the same as of /etc/fstab (cf. man 5 fstab)\n        for mount in mounts:\n            source, target, fstype, options, unused1, unused2 = mount.split(b\" \")\n            options = set(options.split(b\",\"))\n            yield (decode_path(source), decode_path(target), fstype, options)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remount_with_additional_flags(mountpoint, existing_options, mountflags):\n    mountflags |= libc.MS_REMOUNT|libc.MS_BIND\n    for option, flag in libc.MOUNT_FLAGS.items():\n        if option in existing_options:\n            mountflags |= flag\n\n    libc.mount(None, mountpoint, None, mountflags, None)", "response": "Remount an existing mount point with additional flags."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_bind_mount(source, target, recursive=False, private=False, read_only=False):\n    flags = libc.MS_BIND\n    if recursive:\n        flags |= libc.MS_REC\n    if private:\n        flags |= libc.MS_PRIVATE\n    if read_only:\n        flags |= libc.MS_RDONLY\n    libc.mount(source, target, None, flags, None)", "response": "Make a bind mount."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef drop_capabilities(keep=[]):\n    capdata = (libc.CapData * 2)()\n    for cap in keep:\n        capdata[0].effective |= (1 << cap)\n        capdata[0].permitted |= (1 << cap)\n    libc.capset(ctypes.byref(libc.CapHeader(version=libc.LINUX_CAPABILITY_VERSION_3, pid=0)),\n                ctypes.byref(capdata))", "response": "Drop all capabilities that are not in the given list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninstalling all signal handler that forwards all signals to the given process.", "response": "def forward_all_signals_async(target_pid, process_name):\n    \"\"\"Install all signal handler that forwards all signals to the given process.\"\"\"\n    def forwarding_signal_handler(signum):\n        _forward_signal(signum, process_name, forwarding_signal_handler.target_pid)\n\n    # Somehow we get a Python SystemError sometimes if we access target_pid directly from inside function.\n    forwarding_signal_handler.target_pid = target_pid\n\n    for signum in _FORWARDABLE_SIGNALS:\n        # Need to directly access libc function,\n        # the state of the signal module is incorrect due to the clone()\n        # (it may think we are in a different thread than the main thread).\n        libc.signal(signum, forwarding_signal_handler)\n\n    # Reactivate delivery of signals such that our handler gets called.\n    reset_signal_handling()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwaiting for a child to terminate and in the meantime forward all signals.", "response": "def wait_for_child_and_forward_all_signals(child_pid, process_name):\n    \"\"\"Wait for a child to terminate and in the meantime forward all signals the current process\n    receives to this child.\n    @return a tuple of exit code and resource usage of the child as given by os.waitpid\n    \"\"\"\n    assert _HAS_SIGWAIT\n    block_all_signals()\n\n    while True:\n        logging.debug(\"Waiting for signals\")\n        signum = signal.sigwait(_ALL_SIGNALS)\n        if signum == signal.SIGCHLD:\n            pid, exitcode, ru_child = os.wait4(-1, os.WNOHANG)\n            while pid != 0:\n                if pid == child_pid:\n                    return exitcode, ru_child\n                else:\n                    logging.debug(\"Received unexpected SIGCHLD for PID %s\", pid)\n                pid, exitcode, ru_child = os.wait4(-1, os.WNOHANG)\n\n        else:\n            _forward_signal(signum, child_pid, process_name)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef close_open_fds(keep_files=[]):\n    keep_fds = set()\n    for file in keep_files:\n        if isinstance(file, int):\n            keep_fds.add(file)\n        else:\n            try:\n                keep_fds.add(file.fileno())\n            except Exception:\n                pass\n\n    for fd in os.listdir(\"/proc/self/fd\"):\n        fd = int(fd)\n        if fd not in keep_fds:\n            try:\n                os.close(fd)\n            except OSError:\n                # irrelevant and expected\n                # (the fd that was used by os.listdir() of course always fails)\n                pass", "response": "Close all open file descriptors except those in a given set."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a minimal system configuration for use in a container.", "response": "def setup_container_system_config(basedir, mountdir=None):\n    \"\"\"Create a minimal system configuration for use in a container.\n    @param basedir: The directory where the configuration files should be placed as bytes.\n    @param mountdir: If present, bind mounts to the configuration files will be added below\n        this path (given as bytes).\n    \"\"\"\n    etc = os.path.join(basedir, b\"etc\")\n    if not os.path.exists(etc):\n        os.mkdir(etc)\n\n    for file, content in CONTAINER_ETC_FILE_OVERRIDE.items():\n        # Create \"basedir/etc/file\"\n        util.write_file(content, etc, file)\n        if mountdir:\n            # Create bind mount to \"mountdir/etc/file\"\n            make_bind_mount(\n                os.path.join(etc, file), os.path.join(mountdir, b\"etc\", file), private=True)\n\n    os.symlink(b\"/proc/self/mounts\", os.path.join(etc, b\"mtab\"))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndetermines whether a given file is one of the files created by setup_container_system_config.", "response": "def is_container_system_config_file(file):\n    \"\"\"Determine whether a given file is one of the files created by setup_container_system_config().\n    @param file: Absolute file path as string.\n    \"\"\"\n    if not file.startswith(\"/etc/\"):\n        return False\n    return file in [os.path.join(\"/etc\", f.decode()) for f in CONTAINER_ETC_FILE_OVERRIDE]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the command line for the current working directory.", "response": "def cmdline(self, executable, options, tasks, propertyfile=None, rlimits={}):\n        \"\"\"\n        Compose the command line to execute from the name of the executable,\n        the user-specified options, and the inputfile to analyze.\n        This method can get overridden, if, for example, some options should\n        be enabled or if the order of arguments must be changed.\n\n        All paths passed to this method (executable, tasks, and propertyfile)\n        are either absolute or have been made relative to the designated working directory.\n\n        @param executable: the path to the executable of the tool (typically the result of executable())\n        @param options: a list of options, in the same order as given in the XML-file.\n        @param tasks: a list of tasks, that should be analysed with the tool in one run.\n                            In most cases we we have only _one_ inputfile.\n        @param propertyfile: contains a specification for the verifier.\n        @param rlimits: This dictionary contains resource-limits for a run,\n                        for example: time-limit, soft-time-limit, hard-time-limit, memory-limit, cpu-core-limit.\n                        All entries in rlimits are optional, so check for existence before usage!\n        \"\"\"\n        directory = os.path.dirname(executable)\n\n        # Ignore propertyfile since we run only reachability\n        return [os.path.join('.', directory, self.BINS[1]), directory] + options + tasks"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing the output of the tool and extract the verification result. This method always needs to be overridden. If the tool gave a result, this method needs to return one of the benchexec.result.RESULT_* strings. Otherwise an arbitrary string can be returned that will be shown to the user and should give some indication of the failure reason (e.g., \"CRASH\", \"OUT_OF_MEMORY\", etc.).", "response": "def determine_result(self, returncode, returnsignal, output, isTimeout):\n        \"\"\"\n        Parse the output of the tool and extract the verification result.\n        This method always needs to be overridden.\n        If the tool gave a result, this method needs to return one of the\n        benchexec.result.RESULT_* strings.\n        Otherwise an arbitrary string can be returned that will be shown to the user\n        and should give some indication of the failure reason\n        (e.g., \"CRASH\", \"OUT_OF_MEMORY\", etc.).\n        \"\"\"\n\n        join_output = '\\n'.join(output)\n\n        if isTimeout:\n            return 'TIMEOUT'\n\n        if returncode == 2:\n            return 'ERROR - Pre-run'\n\n        if join_output is None:\n            return 'ERROR - no output'\n        elif 'Safe.'in join_output:\n            return result.RESULT_TRUE_PROP\n        elif 'Error state' in join_output:\n            return result.RESULT_FALSE_REACH\n        else:\n            return result.RESULT_UNKNOWN"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of files or directories that need to be run for the given executable.", "response": "def program_files(self, executable):\n        \"\"\"\n        OPTIONAL, this method is only necessary for situations when the benchmark environment\n        needs to know all files belonging to a tool\n        (to transport them to a cloud service, for example).\n        Returns a list of files or directories that are necessary to run the tool.\n        \"\"\"\n        directory = os.path.dirname(executable)\n        return [os.path.join('.', directory, f) for f in self.BINS]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nappending a new content to the represented file.", "response": "def append(self, newContent, keep=True):\n        \"\"\"\n        Add content to the represented file.\n        If keep is False, the new content will be forgotten during the next call\n        to this method.\n        \"\"\"\n        content = self.__content + newContent\n        if keep:\n            self.__content = content\n\n        if self.__needsRewrite:\n            \"\"\"\n            Replace the content of the file.\n            A temporary file is used to avoid loss of data through an interrupt.\n            \"\"\"\n            tmpFilename = self.filename + \".tmp\"\n\n            util.write_file(content, tmpFilename)\n\n            os.rename(tmpFilename, self.filename)\n        else:\n            with open(self.filename, \"a\") as file:\n                file.write(newContent)\n\n        self.__needsRewrite = not keep"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntaking the result of an energy measurement and return a flat dictionary that contains all values.", "response": "def format_energy_results(energy):\n    \"\"\"Take the result of an energy measurement and return a flat dictionary that contains all values.\"\"\"\n    if not energy:\n        return {}\n    result = {}\n    cpuenergy = Decimal(0)\n    for pkg, domains in energy.items():\n        for domain, value in domains.items():\n            if domain == DOMAIN_PACKAGE:\n                cpuenergy += value\n                result['cpuenergy-pkg{}'.format(pkg)] = value\n            else:\n                result['cpuenergy-pkg{}-{}'.format(pkg, domain)] = value\n    result['cpuenergy'] = cpuenergy\n    result = collections.OrderedDict(sorted(result.items()))\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstarting the external measurement program.", "response": "def start(self):\n        \"\"\"Starts the external measurement program.\"\"\"\n        assert not self.is_running(), 'Attempted to start an energy measurement while one was already running.'\n\n        self._measurement_process = subprocess.Popen(\n            [self._executable, '-r'],\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            bufsize=10000,\n            preexec_fn=os.setpgrp, # Prevent delivery of Ctrl+C to subprocess\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstops the external measurement program and returns the measurement result if the measurement was running.", "response": "def stop(self):\n        \"\"\"Stops the external measurement program and returns the measurement result,\n        if the measurement was running.\"\"\"\n        consumed_energy = collections.defaultdict(dict)\n        if not self.is_running():\n            return None\n        # cpu-energy-meter expects SIGINT to stop and report its result\n        self._measurement_process.send_signal(signal.SIGINT)\n        (out, err) = self._measurement_process.communicate()\n        assert self._measurement_process.returncode is not None\n        if self._measurement_process.returncode:\n            logging.debug(\n                \"Energy measurement terminated with return code %s\",\n                self._measurement_process.returncode)\n        self._measurement_process = None\n        for line in err.splitlines():\n            logging.debug(\"energy measurement stderr: %s\", line)\n        for line in out.splitlines():\n            line = line.decode('ASCII')\n            logging.debug(\"energy measurement output: %s\", line)\n            match = re.match(r'cpu(\\d+)_([a-z]+)_joules=(\\d+\\.?\\d*)', line)\n            if not match:\n                continue\n\n            cpu, domain, energy = match.groups()\n            cpu = int(cpu)\n            energy = Decimal(energy)\n\n            consumed_energy[cpu][domain] = energy\n        return consumed_energy"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef determine_result(self, returncode, returnsignal, output, isTimeout):\n        for line in output:\n            if \"All test cases time out or crash, giving up!\" in line:\n                return \"Couldn't run: all seeds time out or crash\"\n            if \"ERROR: couldn't run FairFuzz\" in line:\n                return \"Couldn't run FairFuzz\"\n            if \"CRASHES FOUND\" in line:\n                return result.RESULT_FALSE_REACH\n            if \"DONE RUNNING\" in line:\n                return result.RESULT_DONE\n        return result.RESULT_UNKNOWN", "response": "This method parses the output of the tool and returns the result of the tool."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef document(self):\n        request = self._py_object.request\n        resp = request.environ.get('pylons.original_response')\n        content = literal(resp.body) or cgi.escape(request.GET.get('message', ''))\n\n        page = \"\"\"<!DOCTYPE html>\n<html lang=\"en\">\n    <head>\n        <title>NIPAP error</title>\n        <meta charset=\"utf-8\">\n        <link rel=\"stylesheet\" href=\"/nipap.css\">\n    </head>\n    <body>\n        <div class=\"top_menu\">\n            <div class=\"menu_entry\" style=\"line-height: 0px\">\n                <div class=\"menu_entry\" style=\"font-size: 10pt; color: #CCCCCC; padding-top: 11px; font-weight: bold;\">\n                NIPAP ERROR\n                </div>\n            </div>\n        </div>\n        <div class=\"content_outer\">\n            <div class=\"content_inner\">\n                <p>%s</p>\n                <p>Relevant information has been forwarded to the system administrator.</p>\n            </div>\n\t\t\t<div style=\"height: 500px;\"> &nbsp; </div>\n        </div>\n    </body>\n</html>\"\"\" % content\n\n        # If the error was raised from the XhrController, return HTML-less response\n        if type(request.environ['pylons.original_request'].environ.get('pylons.controller')) == XhrController:\n            return content\n        else:\n            return page", "response": "Render the error document"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _serve_file(self, path):\n        request = self._py_object.request\n        request.environ['PATH_INFO'] = '/%s' % path\n        return PkgResourcesParser('pylons', 'pylons')(request.environ, self.start_response)", "response": "Serve the file at the specified path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nextract prefix attributes from arbitary dict.", "response": "def extract_prefix_attr(cls, req):\n        \"\"\" Extract prefix attributes from arbitary dict.\n        \"\"\"\n\n        # TODO: add more?\n        attr = {}\n        if 'id' in req:\n            attr['id'] = int(req['id'])\n        if 'prefix' in req:\n            attr['prefix'] = req['prefix']\n        if 'pool' in req:\n            attr['pool_id'] = int(req['pool'])\n        if 'node' in req:\n            attr['node'] = req['node']\n        if 'type' in req:\n            attr['type'] = req['type']\n        if 'country' in req:\n            attr['country'] = req['country']\n        if 'indent' in req:\n            attr['indent'] = req['indent']\n\n        return attr"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extract_pool_attr(cls, req):\n\n        attr = {}\n        if 'id' in req:\n            attr['id'] = int(req['id'])\n        if 'name' in req:\n            attr['name'] = req['name']\n        if 'description' in req:\n            attr['description'] = req['description']\n        if 'default_type' in req:\n            attr['default_type'] = req['default_type']\n        if 'ipv4_default_prefix_length' in req:\n            attr['ipv4_default_prefix_length'] = int(req['ipv4_default_prefix_length'])\n        if 'ipv6_default_prefix_length' in req:\n            attr['ipv6_default_prefix_length'] = int(req['ipv6_default_prefix_length'])\n\n        return attr", "response": "Extract pool attributes from arbitary dict."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_vrf(self):\n\n        try:\n            vrfs = VRF.list()\n        except NipapError, e:\n            return json.dumps({'error': 1, 'message': e.args, 'type': type(e).__name__})\n\n        return json.dumps(vrfs, cls=NipapJSONEncoder)", "response": "List VRFs and return JSON encoded result."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nperforming a smart VRF search.", "response": "def smart_search_vrf(self):\n        \"\"\" Perform a smart VRF search.\n\n            The \"smart\" search function tries extract a query from\n            a text string. This query is then passed to the search_vrf\n            function, which performs the search.\n        \"\"\"\n\n        search_options = {}\n        extra_query = None\n\n        if 'query_id' in request.json:\n            search_options['query_id'] = request.json['query_id']\n\n        if 'max_result' in request.json:\n            search_options['max_result'] = request.json['max_result']\n\n        if 'offset' in request.json:\n            search_options['offset'] = request.json['offset']\n\n        if 'vrf_id' in request.json:\n            extra_query = {\n                    'val1': 'id',\n                    'operator': 'equals',\n                    'val2': request.json['vrf_id']\n                }\n\n        try:\n            result = VRF.smart_search(request.json['query_string'],\n                search_options, extra_query\n                )\n            # Remove error key in result from backend as it interferes with the\n            # error handling of the web interface.\n            # TODO: Reevaluate how to deal with different types of errors; soft\n            # errors like query string parser errors and hard errors like lost\n            # database.\n            del result['error']\n        except NipapError, e:\n            return json.dumps({'error': 1, 'message': e.args, 'type': type(e).__name__})\n\n        return json.dumps(result, cls=NipapJSONEncoder)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_vrf(self):\n\n        v = VRF()\n        if 'rt' in request.json:\n            v.rt = validate_string(request.json, 'rt')\n        if 'name' in request.json:\n            v.name = validate_string(request.json, 'name')\n        if 'description' in request.json:\n            v.description = validate_string(request.json, 'description')\n        if 'tags' in request.json:\n            v.tags = request.json['tags']\n        if 'avps' in request.json:\n            v.avps = request.json['avps']\n\n        try:\n            v.save()\n        except NipapError, e:\n            return json.dumps({'error': 1, 'message': e.args, 'type': type(e).__name__})\n\n        return json.dumps(v, cls=NipapJSONEncoder)", "response": "Add a new VRF to NIPAP and return its data."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist pools and return JSON encoded result.", "response": "def list_pool(self):\n        \"\"\" List pools and return JSON encoded result.\n        \"\"\"\n\n        # fetch attributes from request.json\n        attr = XhrController.extract_pool_attr(request.json)\n\n        try:\n            pools = Pool.list(attr)\n        except NipapError, e:\n            return json.dumps({'error': 1, 'message': e.args, 'type': type(e).__name__})\n\n        return json.dumps(pools, cls=NipapJSONEncoder)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef smart_search_pool(self):\n\n        search_options = {}\n\n        if 'query_id' in request.json:\n            search_options['query_id'] = request.json['query_id']\n\n        if 'max_result' in request.json:\n            search_options['max_result'] = request.json['max_result']\n        if 'offset' in request.json:\n            search_options['offset'] = request.json['offset']\n\n        try:\n            result = Pool.smart_search(request.json['query_string'],\n                search_options\n                )\n            # Remove error key in result from backend as it interferes with the\n            # error handling of the web interface.\n            # TODO: Reevaluate how to deal with different types of errors; soft\n            # errors like query string parser errors and hard errors like lost\n            # database.\n            del result['error']\n        except NipapError, e:\n            return json.dumps({'error': 1, 'message': e.args, 'type': type(e).__name__})\n\n        return json.dumps(result, cls=NipapJSONEncoder)", "response": "Perform a smart pool search."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_prefix(self):\n\n        # fetch attributes from request.json\n        attr = XhrController.extract_prefix_attr(request.json)\n\n        try:\n            prefixes = Prefix.list(attr)\n        except NipapError, e:\n            return json.dumps({'error': 1, 'message': e.args, 'type': type(e).__name__})\n\n        return json.dumps(prefixes, cls=NipapJSONEncoder)", "response": "List prefixes and return JSON encoded result."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsearches the prefix for a specific node.", "response": "def search_prefix(self):\n        \"\"\" Search prefixes. Does not yet incorporate all the functions of the\n            search_prefix API function due to difficulties with transferring\n            a complete 'dict-to-sql' encoded data structure.\n\n            Instead, a list of prefix attributes can be given which will be\n            matched with the 'equals' operator if notheing else is specified. If\n            multiple attributes are given, they will be combined with the 'and'\n            operator. Currently, it is not possible to specify different\n            operators for different attributes.\n        \"\"\"\n\n        # extract operator\n        if 'operator' in request.json:\n            operator = request.json['operator']\n        else:\n            operator = 'equals'\n\n        # fetch attributes from request.json\n        attr = XhrController.extract_prefix_attr(request.json)\n\n        # build query dict\n        n = 0\n        q = {}\n        for key, val in attr.items():\n            if n == 0:\n                q = {\n                    'operator': operator,\n                    'val1': key,\n                    'val2': val\n                }\n            else:\n                q = {\n                    'operator': 'and',\n                    'val1': {\n                        'operator': operator,\n                        'val1': key,\n                        'val2': val\n                    },\n                    'val2': q\n                }\n            n += 1\n\n        # extract search options\n        search_opts = {}\n        if 'children_depth' in request.json:\n            search_opts['children_depth'] = request.json['children_depth']\n        if 'parents_depth' in request.json:\n            search_opts['parents_depth'] = request.json['parents_depth']\n        if 'include_neighbors' in request.json:\n            search_opts['include_neighbors'] = request.json['include_neighbors']\n        if 'max_result' in request.json:\n            search_opts['max_result'] = request.json['max_result']\n        if 'offset' in request.json:\n            search_opts['offset'] = request.json['offset']\n\n        try:\n            result = Prefix.search(q, search_opts)\n        except NipapError, e:\n            return json.dumps({'error': 1, 'message': e.args, 'type': type(e).__name__})\n\n        return json.dumps(result, cls=NipapJSONEncoder)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef smart_search_prefix(self):\n\n        search_options = {}\n        extra_query = None\n        vrf_filter = None\n\n        if 'query_id' in request.json:\n            search_options['query_id'] = request.json['query_id']\n\n        if 'include_all_parents' in request.json:\n            if request.json['include_all_parents'] == 'true':\n                search_options['include_all_parents'] = True\n            else:\n                search_options['include_all_parents'] = False\n\n        if 'include_all_children' in request.json:\n            if request.json['include_all_children'] == 'true':\n                search_options['include_all_children'] = True\n            else:\n                search_options['include_all_children'] = False\n\n        if 'parents_depth' in request.json:\n            search_options['parents_depth'] = request.json['parents_depth']\n        if 'children_depth' in request.json:\n            search_options['children_depth'] = request.json['children_depth']\n        if 'include_neighbors' in request.json:\n            if request.json['include_neighbors'] == 'true':\n                search_options['include_neighbors'] = True\n            else:\n                search_options['include_neighbors'] = False\n        if 'max_result' in request.json:\n            if request.json['max_result'] == 'false':\n                search_options['max_result'] = False\n            else:\n                search_options['max_result'] = request.json['max_result']\n        if 'offset' in request.json:\n            search_options['offset'] = request.json['offset']\n        if 'parent_prefix' in request.json:\n            search_options['parent_prefix'] = request.json['parent_prefix']\n        if 'vrf_filter' in request.json:\n            vrf_filter_parts = []\n\n            # Fetch VRF IDs from search query and build extra query dict for\n            # smart_search_prefix.\n            vrfs = request.json['vrf_filter']\n\n            if len(vrfs) > 0:\n                vrf = vrfs[0]\n                vrf_filter = {\n                    'operator': 'equals',\n                    'val1': 'vrf_id',\n                    'val2': vrf if vrf != 'null' else None\n                }\n\n                for vrf in vrfs[1:]:\n                    vrf_filter = {\n                        'operator': 'or',\n                        'val1': vrf_filter,\n                        'val2': {\n                            'operator': 'equals',\n                            'val1': 'vrf_id',\n                            'val2': vrf if vrf != 'null' else None\n                        }\n                    }\n\n        if vrf_filter:\n            extra_query = vrf_filter\n\n        if 'indent' in request.json:\n            if extra_query:\n                extra_query = {\n                        'operator': 'and',\n                        'val1': extra_query,\n                        'val2': {\n                            'operator': 'equals',\n                            'val1': 'indent',\n                            'val2': request.json['indent']\n                        }\n                    }\n            else:\n                extra_query = {\n                    'operator': 'equals',\n                    'val1': 'indent',\n                    'val2': request.json['indent']\n                    }\n\n        try:\n            result = Prefix.smart_search(request.json['query_string'],\n                search_options, extra_query)\n            # Remove error key in result from backend as it interferes with the\n            # error handling of the web interface.\n            # TODO: Reevaluate how to deal with different types of errors; soft\n            # errors like query string parser errors and hard errors like lost\n            # database.\n            del result['error']\n        except NipapError, e:\n            return json.dumps({'error': 1, 'message': e.args, 'type': type(e).__name__})\n\n        return json.dumps(result, cls=NipapJSONEncoder)", "response": "Perform a smart search on the resource with the specified prefix."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a prefix to the current object.", "response": "def add_prefix(self):\n        \"\"\" Add prefix according to the specification.\n\n            The following keys can be used:\n\n            vrf             ID of VRF to place the prefix in\n            prefix          the prefix to add if already known\n            family          address family (4 or 6)\n            description     A short description\n            expires         Expiry time of assignment\n            comment         Longer comment\n            node            Hostname of node\n            type            Type of prefix; reservation, assignment, host\n            status          Status of prefix; assigned, reserved, quarantine\n            pool            ID of pool\n            country         Country where the prefix is used\n            order_id        Order identifier\n            customer_id     Customer identifier\n            vlan            VLAN ID\n            alarm_priority  Alarm priority of prefix\n            monitor         If the prefix should be monitored or not\n\n            from-prefix     A prefix the prefix is to be allocated from\n            from-pool       A pool (ID) the prefix is to be allocated from\n            prefix_length   Prefix length of allocated prefix\n        \"\"\"\n\n        p = Prefix()\n\n        # Sanitize input parameters\n        if 'vrf' in request.json:\n            try:\n                if request.json['vrf'] is None or len(unicode(request.json['vrf'])) == 0:\n                    p.vrf = None\n                else:\n                    p.vrf = VRF.get(int(request.json['vrf']))\n            except ValueError:\n                return json.dumps({'error': 1, 'message': \"Invalid VRF ID '%s'\" % request.json['vrf']})\n            except NipapError, e:\n                return json.dumps({'error': 1, 'message': e.args, 'type': type(e).__name__})\n\n        if 'description' in request.json:\n            p.description = validate_string(request.json, 'description')\n        if 'expires' in request.json:\n            p.expires = validate_string(request.json, 'expires')\n        if 'comment' in request.json:\n            p.comment = validate_string(request.json, 'comment')\n        if 'node' in request.json:\n            p.node = validate_string(request.json, 'node')\n        if 'status' in request.json:\n            p.status = validate_string(request.json, 'status')\n        if 'type' in request.json:\n            p.type = validate_string(request.json, 'type')\n\n        if 'pool' in request.json:\n            if request.json['pool'] is not None:\n                try:\n                    p.pool = Pool.get(int(request.json['pool']))\n                except NipapError, e:\n                    return json.dumps({'error': 1, 'message': e.args, 'type': type(e).__name__})\n\n        if 'country' in request.json:\n            p.country = validate_string(request.json, 'country')\n        if 'order_id' in request.json:\n            p.order_id = validate_string(request.json, 'order_id')\n        if 'customer_id' in request.json:\n            p.customer_id = validate_string(request.json, 'customer_id')\n        if 'alarm_priority' in request.json:\n            p.alarm_priority = validate_string(request.json, 'alarm_priority')\n        if 'monitor' in request.json:\n            p.monitor = request.json['monitor']\n\n        if 'vlan' in request.json:\n            p.vlan = request.json['vlan']\n        if 'tags' in request.json:\n            p.tags = request.json['tags']\n        if 'avps' in request.json:\n            p.avps = request.json['avps']\n\n        # arguments\n        args = {}\n        if 'from_prefix' in request.json:\n            args['from-prefix'] = request.json['from_prefix']\n        if 'from_pool' in request.json:\n            try:\n                args['from-pool'] = Pool.get(int(request.json['from_pool']))\n            except NipapError, e:\n                return json.dumps({'error': 1, 'message': e.args, 'type': type(e).__name__})\n        if 'family' in request.json:\n            args['family'] = request.json['family']\n        if 'prefix_length' in request.json:\n            args['prefix_length'] = request.json['prefix_length']\n\n        # manual allocation?\n        if args == {}:\n            if 'prefix' in request.json:\n                p.prefix = request.json['prefix']\n\n        try:\n            p.save(args)\n        except NipapError, e:\n            return json.dumps({'error': 1, 'message': e.args, 'type': type(e).__name__})\n\n        return json.dumps(p, cls=NipapJSONEncoder)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_current_vrf(self):\n\n        vrf_id = request.json['vrf_id']\n\n        if vrf_id is not None:\n\n            if vrf_id == 'null':\n                vrf = VRF()\n            else:\n                vrf_id = int(vrf_id)\n                vrf = VRF.get(vrf_id)\n\n            session['current_vrfs'][vrf_id] = { 'id': vrf.id, 'rt': vrf.rt,\n                    'name': vrf.name, 'description': vrf.description }\n            session.save()\n\n        return json.dumps(session.get('current_vrfs', {}))", "response": "Add VRF to filter list session variable\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove VRF from filter list session variable", "response": "def del_current_vrf(self):\n        \"\"\" Remove VRF to filter list session variable\n        \"\"\"\n\n        vrf_id = int(request.json['vrf_id'])\n        if vrf_id in session['current_vrfs']:\n            del session['current_vrfs'][vrf_id]\n\n            session.save()\n\n        return json.dumps(session.get('current_vrfs', {}))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_current_vrfs(self):\n\n        # Verify that all currently selected VRFs still exists\n        cur_vrfs = session.get('current_vrfs', {}).items()\n        if len(cur_vrfs) > 0:\n            q = {\n                'operator': 'equals',\n                'val1': 'id',\n                'val2': cur_vrfs[0][0]\n            }\n\n            if len(cur_vrfs) > 1:\n                for vrf_id, vrf in cur_vrfs[1:]:\n                    q = {\n                        'operator': 'or',\n                        'val1': q,\n                        'val2': {\n                            'operator': 'equals',\n                            'val1': 'id',\n                            'val2': vrf_id\n                        }\n                    }\n\n            res = VRF.search(q)\n\n            session['current_vrfs'] = {}\n            for vrf in res['result']:\n                session['current_vrfs'][vrf.id] = { 'id': vrf.id, 'rt': vrf.rt,\n                    'name': vrf.name, 'description': vrf.description }\n\n            session.save()\n\n        return json.dumps(session.get('current_vrfs', {}))", "response": "Return the list of currently selected VRFs in the session variable"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_tags(self):\n\n        try:\n            tags = Tags.list()\n        except NipapError, e:\n            return json.dumps({'error': 1, 'message': e.args, 'type': type(e).__name__})\n\n        return json.dumps(tags, cls=NipapJSONEncoder)", "response": "List Tags and return JSON encoded result."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_file(self):\n\n        # don't try to parse config file if we don't have one set\n        if not self._cfg_path:\n            return\n\n        try:\n            cfg_fp = open(self._cfg_path, 'r')\n            self.readfp(cfg_fp)\n        except IOError as exc:\n            raise NipapConfigError(str(exc))", "response": "Read the configuration file and return the set of set items."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndisplaying NIPAP version info", "response": "def index(self):\n        \"\"\" Display NIPAP version info\n        \"\"\"\n        c.pynipap_version = pynipap.__version__\n        try:\n            c.nipapd_version = pynipap.nipapd_version()\n        except:\n            c.nipapd_version = 'unknown'\n\n        c.nipap_db_version = pynipap.nipap_db_version()\n\n        return render('/version.html')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning an authentication object for the given username and password.", "response": "def get_auth(self, username, password, authoritative_source, auth_options=None):\n        \"\"\" Returns an authentication object.\n    \n            Examines the auth backend given after the '@' in the username and\n            returns a suitable instance of a subclass of the BaseAuth class.\n\n            * `username` [string]\n                Username to authenticate as.\n            * `password` [string]\n                Password to authenticate with.\n            * `authoritative_source` [string]\n                Authoritative source of the query.\n            * `auth_options` [dict]\n                A dict which, if authenticated as a trusted user, can override\n                `username` and `authoritative_source`.\n        \"\"\"\n\n        if auth_options is None:\n            auth_options = {}\n\n        # validate arguments\n        if (authoritative_source is None):\n            raise AuthError(\"Missing authoritative_source.\")\n\n        # remove invalid cache entries\n        rem = list()\n        for key in self._auth_cache:\n            if self._auth_cache[key]['valid_until'] < datetime.utcnow():\n                rem.append(key)\n        for key in rem:\n            del(self._auth_cache[key])\n\n        user_authbackend = username.rsplit('@', 1)\n    \n        # Find out what auth backend to use.\n        # If no auth backend was specified in username, use default\n        backend = \"\"\n        if len(user_authbackend) == 1:\n            backend = self._config.get('auth', 'default_backend')\n            self._logger.debug(\"Using default auth backend %s\" % backend)\n        else:\n            backend = user_authbackend[1]\n    \n        # do we have a cached instance?\n        auth_str = ( str(username) + str(password) + str(authoritative_source)\n            + str(auth_options) )\n        if auth_str in self._auth_cache:\n            self._logger.debug('found cached auth object for user %s' % username)\n            return self._auth_cache[auth_str]['auth_object']\n\n        # Create auth object\n        try:\n            auth = self._backends[backend](backend, user_authbackend[0], password, authoritative_source, auth_options)\n        except KeyError:\n            raise AuthError(\"Invalid auth backend '%s' specified\" %\n                str(backend))\n\n        # save auth object to cache\n        self._auth_cache[auth_str] = {\n            'valid_until': datetime.utcnow() + timedelta(seconds=self._config.getint('auth', 'auth_cache_timeout')),\n            'auth_object': auth\n        }\n\n        return auth"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nverify authentication. Returns True/False dependant on whether the authentication succeeded or not.", "response": "def authenticate(self):\n        \"\"\" Verify authentication.\n\n            Returns True/False dependant on whether the authentication\n            succeeded or not.\n        \"\"\"\n\n        # if authentication has been performed, return last result\n        if self._authenticated is not None:\n            return self._authenticated\n\n        try:\n            self._ldap_conn.simple_bind_s(self._ldap_binddn_fmt.format(ldap.dn.escape_dn_chars(self.username)), self.password)\n        except ldap.SERVER_DOWN as exc:\n            raise AuthError('Could not connect to LDAP server')\n        except (ldap.INVALID_CREDENTIALS, ldap.INVALID_DN_SYNTAX,\n                ldap.UNWILLING_TO_PERFORM) as exc:\n            # Auth failed\n            self._logger.debug('erroneous password for user %s' % self.username)\n            self._authenticated = False\n            return self._authenticated\n\n\n        # auth succeeded\n        self.authenticated_as = self.username\n        self.trusted = False\n        self.readonly = False\n\n        try:\n            # Create separate connection for search?\n            if self._ldap_search_conn is not None:\n                self._ldap_search_conn.simple_bind(self._ldap_search_binddn, self._ldap_search_password)\n                search_conn = self._ldap_search_conn\n            else:\n                search_conn = self._ldap_conn\n\n            res = search_conn.search_s(self._ldap_basedn, ldap.SCOPE_SUBTREE, self._ldap_search.format(ldap.dn.escape_dn_chars(self.username)), ['cn','memberOf'])\n            if res[0][1]['cn'][0] is not None:\n                self.full_name = res[0][1]['cn'][0].decode('utf-8')\n            # check for ro_group membership if ro_group is configured\n            if self._ldap_ro_group:\n                if self._ldap_ro_group in res[0][1].get('memberOf', []):\n                    self.readonly = True\n            # check for rw_group membership if rw_group is configured\n            if self._ldap_rw_group:\n                if self._ldap_rw_group in res[0][1].get('memberOf', []):\n                    self.readonly = False\n                else:\n                    # if ro_group is configured, and the user is a member of\n                    # neither the ro_group nor the rw_group, fail authentication.\n                    if self._ldap_ro_group:\n                        if self._ldap_ro_group not in res[0][1].get('memberOf', []):\n                            self._authenticated = False\n                            return self._authenticated\n                    else:\n                        self.readonly = True\n\n        except ldap.LDAPError as exc:\n            raise AuthError(exc)\n        except KeyError:\n            raise AuthError('LDAP attribute missing')\n        except IndexError:\n            self.full_name = ''\n            # authentication fails if either ro_group or rw_group are configured\n            # and the user is not found.\n            if self._ldap_rw_group or self._ldap_ro_group:\n                self._authenticated = False\n                return self._authenticated\n\n        self._authenticated = True\n\n        self._logger.debug('successfully authenticated as %s, username %s, full_name %s, readonly %s' % (self.authenticated_as, self.username, self.full_name, str(self.readonly)))\n        return self._authenticated"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _create_database(self):\n\n        self._logger.info('creating user database')\n        sql = '''CREATE TABLE IF NOT EXISTS user (\n            username NOT NULL PRIMARY KEY,\n            pwd_salt NOT NULL,\n            pwd_hash NOT NULL,\n            full_name,\n            trusted NOT NULL DEFAULT 0,\n            readonly NOT NULL DEFAULT 0\n        )'''\n        self._db_curs.execute(sql)\n        self._db_conn.commit()", "response": "Create the database for the user."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nverify authentication. Returns True/False dependant on whether the authentication succeeded or not.", "response": "def authenticate(self):\n        \"\"\" Verify authentication.\n\n            Returns True/False dependant on whether the authentication\n            succeeded or not.\n        \"\"\"\n\n        # if authentication has been performed, return last result\n        if self._authenticated is not None:\n            return self._authenticated\n\n        self._logger.debug('Trying to authenticate as user \\'%s\\'' % self.username)\n\n        user = self.get_user(self.username)\n        # Was user found?\n        if user is None:\n            self._logger.debug('unknown user %s' % self.username)\n            self._authenticated = False\n            return self._authenticated\n\n        # verify password\n        if self._gen_hash(self.password, user['pwd_salt']) != user['pwd_hash']:\n            # Auth failed\n            self._logger.debug('erroneous password for user %s' % self.username)\n            self._authenticated = False\n            return self._authenticated\n\n        # auth succeeded\n        self.authenticated_as = self.username\n        self._authenticated = True\n        self.trusted = bool(user['trusted'])\n        self.readonly = bool(user['readonly'])\n\n        if self.trusted:\n            # user can impersonate other users\n            # this also means that a system and full_name can be specified\n            if 'username' in self._auth_options:\n                self.username = self._auth_options['username']\n\n            # TODO: b0rk out if full_name is supplied and username not?\n            if 'full_name' in self._auth_options:\n                self.full_name = self._auth_options['full_name']\n\n            if 'authoritative_source' in self._auth_options:\n                self.authoritative_source = self._auth_options['authoritative_source']\n\n            if 'readonly' in self._auth_options:\n                self.readonly = self._auth_options['readonly']\n\n        else:\n            self.full_name = user['full_name']\n\n        self._logger.debug('successfully authenticated as %s, username %s, full_name %s, readonly %s' % (self.authenticated_as, self.username, self.full_name, str(self.readonly)))\n        return self._authenticated"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfetching the user from the database", "response": "def get_user(self, username):\n        \"\"\" Fetch the user from the database\n\n            The function will return None if the user is not found\n        \"\"\"\n\n        sql = '''SELECT * FROM user WHERE username = ?'''\n        self._db_curs.execute(sql, (username, ))\n        user = self._db_curs.fetchone()\n        return user"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding user to the database.", "response": "def add_user(self, username, password, full_name=None, trusted=False, readonly=False):\n        \"\"\" Add user to SQLite database.\n\n            * `username` [string]\n                Username of new user.\n            * `password` [string]\n                Password of new user.\n            * `full_name` [string]\n                Full name of new user.\n            * `trusted` [boolean]\n                Whether the new user should be trusted or not.\n            * `readonly` [boolean]\n                Whether the new user can only read or not\n        \"\"\"\n\n        # generate salt\n        char_set = string.ascii_letters + string.digits\n        salt = ''.join(random.choice(char_set) for x in range(8))\n\n\n        sql = '''INSERT INTO user\n            (username, pwd_salt, pwd_hash, full_name, trusted, readonly)\n            VALUES\n            (?, ?, ?, ?, ?, ?)'''\n        try:\n            self._db_curs.execute(sql, (username, salt,\n                self._gen_hash(password, salt), full_name, trusted or False,\n                                        readonly or False))\n            self._db_conn.commit()\n        except (sqlite3.OperationalError, sqlite3.IntegrityError) as error:\n            raise AuthError(error)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove user from the SQLite database.", "response": "def remove_user(self, username):\n        \"\"\" Remove user from the SQLite database.\n\n            * `username` [string]\n                Username of user to remove.\n        \"\"\"\n\n        sql = '''DELETE FROM user WHERE username = ?'''\n        try:\n            self._db_curs.execute(sql, (username, ))\n            self._db_conn.commit()\n        except (sqlite3.OperationalError, sqlite3.IntegrityError) as error:\n            raise AuthError(error)\n        return self._db_curs.rowcount"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef modify_user(self, username, data):\n        if 'password' in data:\n            # generate salt\n            char_set = string.ascii_letters + string.digits\n            data['pwd_salt'] = ''.join(random.choice(char_set) for x in range(8))\n            data['pwd_hash'] = self._gen_hash(data['password'], data['pwd_salt'])\n            del(data['password'])\n\n        sql = \"UPDATE user SET \"\n        sql += ', '.join(\"%s = ?\" % k for k in sorted(data))\n        sql += \" WHERE username = ?\"\n\n        vals = []\n        for k in sorted(data):\n            vals.append(data[k])\n        vals.append(username)\n\n        try:\n            self._db_curs.execute(sql, vals)\n            self._db_conn.commit()\n        except (sqlite3.OperationalError, sqlite3.IntegrityError) as error:\n            raise AuthError(error)", "response": "Modify user in SQLite database."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef requires_rw(f):\n    @wraps(f)\n\n    def decorated(*args, **kwargs):\n        auth = args[1]\n        if auth.readonly:\n            logger = logging.getLogger()\n            logger.info(\"read-only user '%s' is not authorized to run function '%s'\" % (auth.username, f.__name__))\n            raise authlib.AuthorizationFailed(\"read-only user '%s' is not authorized to run function '%s'\" % (auth.username, f.__name__))\n        return f(*args, **kwargs)\n\n    return decorated", "response": "Decorator to check if the user is a read - only user and reject the request."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _parse_expires(expires):\n    # none is used to signify positive infinity\n    if expires is None or expires in ('never', 'infinity'):\n        return 'infinity'\n\n    try:\n        return dateutil.parser.parse(unicode(expires))\n    except ValueError as exc:\n        pass\n\n    try:\n        # use parsedatetime for \"human readable\" time specs\n        exp = pdt.parse(expires)[0]\n        # and convert to datetime\n        return datetime.datetime.fromtimestamp(time.mktime(exp))\n    except ValueError as exc:\n        pass\n\n    raise NipapValueError(\"Invalid date specification for expires\")", "response": "Parse the expires attribute and return a datetime object"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _register_inet(self, oid=None, conn_or_curs=None):\n        from psycopg2 import extensions as _ext\n        if not oid:\n            oid = 869\n        _ext.INET = _ext.new_type((oid, ), \"INET\",\n                lambda data, cursor: data and Inet(data) or None)\n        _ext.register_type(_ext.INET, self._con_pg)\n        return _ext.INET", "response": "Create the INET type and an Inet adapter."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _is_ipv4(self, ip):\n        try:\n            p = IPy.IP(ip)\n        except ValueError:\n            return False\n\n        if p.version() == 4:\n            return True\n        return False", "response": "Return True if given arg is a valid IPv4 address"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_afi(self, ip):\n\n        parts = unicode(ip).split(\"/\")\n        if len(parts) == 1:\n            # just an address\n            if self._is_ipv4(ip):\n                return 4\n            elif self._is_ipv6(ip):\n                return 6\n            else:\n                return None\n        elif len(parts) == 2:\n            # a prefix!\n            try:\n                pl = int(parts[1])\n            except ValueError:\n                # if casting parts[1] to int failes, this is not a prefix..\n                return None\n\n            if self._is_ipv4(parts[0]):\n                if pl >= 0 and pl <= 32:\n                    # prefix mask must be between 0 and 32\n                    return 4\n                # otherwise error\n                return None\n            elif self._is_ipv6(parts[0]):\n                if pl >= 0 and pl <= 128:\n                    # prefix mask must be between 0 and 128\n                    return 6\n                # otherwise error\n                return None\n            else:\n                return None\n        else:\n            # more than two parts.. this is neither an address or a prefix\n            return None", "response": "Returns the address - family 4 or 6 for the given IP or None if invalid address - family"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nopen database connection and create tables.", "response": "def _connect_db(self):\n        \"\"\" Open database connection\n        \"\"\"\n\n        # Get database configuration\n        db_args = {}\n        db_args['host'] = self._cfg.get('nipapd', 'db_host')\n        db_args['database'] = self._cfg.get('nipapd', 'db_name')\n        db_args['user'] = self._cfg.get('nipapd', 'db_user')\n        db_args['password'] = self._cfg.get('nipapd', 'db_pass')\n        db_args['sslmode'] = self._cfg.get('nipapd', 'db_sslmode')\n        db_args['port'] = self._cfg.get('nipapd', 'db_port')\n        # delete keys that are None, for example if we want to connect over a\n        # UNIX socket, the 'host' argument should not be passed into the DSN\n        if db_args['host'] is not None and db_args['host'] == '':\n            db_args['host'] = None\n        for key in db_args.copy():\n            if db_args[key] is None:\n                del(db_args[key])\n\n        # Create database connection\n        while True:\n            try:\n                self._con_pg = psycopg2.connect(**db_args)\n                self._con_pg.set_isolation_level(psycopg2.extensions.ISOLATION_LEVEL_AUTOCOMMIT)\n                self._curs_pg = self._con_pg.cursor(cursor_factory=psycopg2.extras.DictCursor)\n                self._register_inet()\n                psycopg2.extras.register_hstore(self._con_pg, globally=True, unicode=True)\n            except psycopg2.Error as exc:\n                if re.search(\"database.*does not exist\", unicode(exc)):\n                    raise NipapDatabaseNonExistentError(\"Database '%s' does not exist\" % db_args['database'])\n                # no hstore extension, assume empty db (it wouldn't work\n                # otherwise) and do auto upgrade?\n                if re.search(\"hstore type not found in the database\", unicode(exc)):\n                    # automatically install if auto-install is enabled\n                    if self._auto_install_db:\n                        self._db_install(db_args['database'])\n                        continue\n                    raise NipapDatabaseMissingExtensionError(\"hstore extension not found in the database\")\n\n                self._logger.error(\"pgsql: %s\" % exc)\n                raise NipapError(\"Backend unable to connect to database\")\n            except psycopg2.Warning as warn:\n                self._logger.warning('pgsql: %s' % warn)\n\n            # check db version\n            try:\n                current_db_version = self._get_db_version()\n            except NipapDatabaseNoVersionError as exc:\n                # if there's no db schema version we assume the database is\n                # empty...\n                if self._auto_install_db:\n                    # automatically install schema?\n                    self._db_install(db_args['database'])\n                    continue\n                raise exc\n            except NipapError as exc:\n                self._logger.error(unicode(exc))\n                raise exc\n\n            if current_db_version != nipap.__db_version__:\n                if self._auto_upgrade_db:\n                    self._db_upgrade(db_args['database'])\n                    continue\n                raise NipapDatabaseWrongVersionError(\"NIPAP PostgreSQL database is outdated. Schema version %s is required to run but you are using %s\" % (nipap.__db_version__, current_db_version))\n\n            # if we reach this we should be fine and done\n            break"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexecute a query and return the result as a dict.", "response": "def _execute(self, sql, opt=None, callno = 0):\n        \"\"\" Execute query, catch and log errors.\n        \"\"\"\n\n        self._logger.debug(\"SQL: \" + sql + \"  params: \" + unicode(opt))\n        try:\n            self._curs_pg.execute(sql, opt)\n        except psycopg2.InternalError as exc:\n            self._con_pg.rollback()\n\n            # NOTE: psycopg2 is unable to differentiate between exceptions\n            # thrown by stored procedures and certain other database internal\n            # exceptions, thus we do not know if the exception in question is\n            # raised from our stored procedure or from some other error. In\n            # addition, postgresql is unable to pass any error code for the\n            # exception and so the only thing which we can look at is the actual\n            # text string.\n            #\n            # Exceptions raised by our stored procedures will all start with an\n            # error code followed by a colon, which separates the error code\n            # from the text string that follows next. If the error text does not\n            # follow this format it is likely not one of \"our\" exceptions and so\n            # we throw (and log) a more general exception.\n\n            # determine if it's \"one of our\" exceptions or something else\n            if len(unicode(exc).split(\":\")) < 2:\n                raise NipapError(exc)\n            code = unicode(exc).split(\":\", 1)[0]\n            try:\n                int(code)\n            except:\n                raise NipapError(exc)\n\n            text = unicode(exc).splitlines()[0].split(\":\", 1)[1]\n\n            if code == '1200':\n                raise NipapValueError(text)\n\n            estr = \"Internal database error: %s\" % exc\n            self._logger.error(estr)\n            raise NipapError(unicode(exc))\n\n        except psycopg2.IntegrityError as exc:\n            self._con_pg.rollback()\n\n            # this is a duplicate key error\n            if exc.pgcode == \"23505\":\n                # figure out which column it is and retrieve the database\n                # description for that column\n                m = re.match(r'.*\"([^\"]+)\"', exc.pgerror)\n                if m is None:\n                    raise NipapDuplicateError(\"Objects primary keys already exist\")\n                cursor = self._con_pg.cursor()\n                cursor.execute(\"\"\"  SELECT\n                                        obj_description(oid)\n                                    FROM pg_class\n                                    WHERE relname = %(relname)s\"\"\",\n                                { 'relname': m.group(1) })\n                column_desc = '<unknown>'\n                for desc in cursor:\n                    column_desc = unicode(desc[0])\n\n                # figure out the value for the duplicate value\n                column_value = None\n                try:\n                    m = re.match(r'.*=\\(([^)]+)\\) already exists.', exc.pgerror.splitlines()[1])\n                    if m is not None:\n                        column_value = m.group(1)\n                except:\n                    pass\n                else:\n                    raise NipapDuplicateError(\"Duplicate value for '\" +\n                        unicode(column_desc) + \"', the value '\" +\n                        unicode(column_value) + \"' is already in use.\")\n\n                raise NipapDuplicateError(\"Duplicate value for '\" +\n                    unicode(column_desc) +\n                    \"', the value you have inputted is already in use.\")\n\n            self._logger.exception(\"Unhandled database IntegrityError:\")\n            raise NipapError(\"Unhandled integrity error.\")\n\n        except psycopg2.DataError as exc:\n            self._con_pg.rollback()\n\n            m = re.search('invalid cidr value: \"([^\"]+)\"', exc.pgerror)\n            if m is not None:\n                strict_prefix = unicode(IPy.IP(m.group(1), make_net = True))\n                estr = \"Invalid prefix (%s); bits set to right of mask. Network address for current mask: %s\" % (m.group(1), strict_prefix)\n                raise NipapValueError(estr)\n\n            m = re.search('invalid input syntax for(?: type)? (\\w+): \"([^\"]+)\"', exc.pgerror)\n            if m is not None:\n                if m.group(1) in [\"cidr\", \"inet\"]:\n                    estr = \"Invalid syntax for prefix (%s)\" % m.group(2)\n                else:\n                    estr = \"Invalid syntax for %s (%s)\" % (m.group(1), m.group(2))\n                raise NipapValueError(estr)\n\n            self._logger.exception(\"Unhandled database DataError:\")\n            raise NipapError(\"Unhandled data error.\")\n\n        except psycopg2.Error as exc:\n            try:\n                self._con_pg.rollback()\n            except psycopg2.Error:\n                pass\n\n            estr = \"Unable to execute query: %s\" % exc\n            self._logger.error(estr)\n\n            # abort if we've already tried to reconnect\n            if callno > 0:\n                self._logger.error(estr)\n                raise NipapError(estr)\n\n            # reconnect to database and retry query\n            self._logger.info(\"Reconnecting to database...\")\n            self._connect_db()\n\n            return self._execute(sql, opt, callno + 1)\n\n        except psycopg2.Warning as warn:\n            self._logger.warning(unicode(warn))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexpanding a dict so it fits in an INSERT clause.", "response": "def _sql_expand_insert(self, spec, key_prefix = '', col_prefix = ''):\n        \"\"\" Expand a dict so it fits in a INSERT clause\n        \"\"\"\n        col = list(spec)\n        sql = '('\n        sql += ', '.join(col_prefix + key for key in col)\n        sql += ') VALUES ('\n        sql += ', '.join('%(' + key_prefix + key + ')s' for key in col)\n        sql += ')'\n        params = {}\n        for key in spec:\n            params[key_prefix + key] = spec[key]\n\n        return sql, params"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _sql_expand_update(self, spec, key_prefix = '', col_prefix = ''):\n        sql = ', '.join(col_prefix + key + ' = %(' + key_prefix + key + ')s' for key in spec)\n        params = {}\n        for key in spec:\n            params[key_prefix + key] = spec[key]\n\n        return sql, params", "response": "Expand a dict so it fits in an UPDATE clause"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets rows updated by last update query_* function", "response": "def _get_updated_rows(self, auth, function):\n        \"\"\" Get rows updated by last update query\n\n            * `function` [function]\n                Function to use for searching (one of the search_* functions).\n\n            Helper function used to fetch all rows which was updated by the\n            latest UPDATE ... RETURNING id query.\n        \"\"\"\n\n        # Get dicts for all rows which were edited by building a query for\n        # search_*. Each row returned from UPDATE ... RETURNING id gives us one\n        # query part (qp) which then are combined to one big query for the\n        # search_* API call.\n        qps = []\n        for row in self._curs_pg:\n            qps.append(\n                {\n                    'operator': 'equals',\n                    'val1': 'id',\n                    'val2': row['id']\n                }\n            )\n\n        # if we didn't update anything return empty list\n        if len(qps) == 0:\n            return []\n\n        # fetch list of objects based on IDs\n        q = qps[0]\n\n        for qp in qps[1:]:\n            q = {\n                'operator': 'or',\n                'val1': q,\n                'val2': qp\n            }\n\n        updated = function(auth, q, { 'max_result': 10000 })['result']\n\n        return updated"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsplitting a query string into its parts", "response": "def _get_query_parts(self, query_str, search_options=None):\n        \"\"\" Split a query string into its parts\n        \"\"\"\n\n        if search_options is None:\n            search_options = {}\n\n        if query_str is None:\n            raise NipapValueError(\"'query_string' must not be None\")\n\n        # find query parts\n        query_str_parts = []\n        try:\n            for part in shlex.split(query_str.encode('utf-8')):\n                query_str_parts.append({ 'string': part.decode('utf-8') })\n        except ValueError as exc:\n            if unicode(exc) == 'No closing quotation':\n                raise NipapValueError(unicode(exc))\n            raise exc\n\n        # Handle empty search.\n        # We need something to iterate over, but shlex.split() returns\n        # zero-element list for an empty string, so we have to append one\n        # manually\n        if len(query_str_parts) == 0:\n            query_str_parts.append({ 'string': '' })\n\n        return query_str_parts"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the schema version of the nipap psql db.", "response": "def _get_db_version(self):\n        \"\"\" Get the schema version of the nipap psql db.\n        \"\"\"\n\n        dbname = self._cfg.get('nipapd', 'db_name')\n        self._execute(\"SELECT description FROM pg_shdescription JOIN pg_database ON objoid = pg_database.oid WHERE datname = '%s'\" % dbname)\n        comment = self._curs_pg.fetchone()\n        if comment is None:\n            raise NipapDatabaseNoVersionError(\"Could not find comment of psql database %s\" % dbname)\n\n        db_version = None\n        m = re.match('NIPAP database - schema version: ([0-9]+)', comment[0])\n        if m:\n            db_version = int(m.group(1))\n        else:\n            raise NipapError(\"Could not match schema version database comment\")\n\n        return db_version"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _db_install(self, db_name):\n        self._logger.info(\"Installing NIPAP database schemas into db\")\n        self._execute(db_schema.ip_net % (db_name))\n        self._execute(db_schema.functions)\n        self._execute(db_schema.triggers)", "response": "Install nipap database schemas into db"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _db_upgrade(self, db_name):\n        current_db_version = self._get_db_version()\n        self._execute(db_schema.functions)\n        for i in range(current_db_version, nipap.__db_version__):\n            self._logger.info(\"Upgrading DB schema:\", i, \"to\", i+1)\n            upgrade_sql = db_schema.upgrade[i-1] # 0 count on array\n            self._execute(upgrade_sql % (db_name))\n        self._execute(db_schema.triggers)", "response": "Upgrade nipap database schema"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexpands VRF specification to SQL.", "response": "def _expand_vrf_spec(self, spec):\n        \"\"\" Expand VRF specification to SQL.\n\n            id [integer]\n                internal database id of VRF\n\n            name [string]\n                name of VRF\n\n            A VRF is referenced either by its internal database id or by its\n            name. Both are used for exact matching and so no wildcard or\n            regular expressions are allowed. Only one key may be used and an\n            error will be thrown if both id and name is specified.\n        \"\"\"\n\n        if type(spec) is not dict:\n            raise NipapInputError(\"vrf specification must be a dict\")\n\n        allowed_values = ['id', 'name', 'rt']\n        for a in spec:\n            if a not in allowed_values:\n                raise NipapExtraneousInputError(\"extraneous specification key %s\" % a)\n\n        if 'id' in spec:\n            if type(spec['id']) not in (int, long):\n                raise NipapValueError(\"VRF specification key 'id' must be an integer.\")\n        elif 'rt' in spec:\n            if type(spec['rt']) != type(''):\n                raise NipapValueError(\"VRF specification key 'rt' must be a string.\")\n        elif 'name' in spec:\n            if type(spec['name']) != type(''):\n                raise NipapValueError(\"VRF specification key 'name' must be a string.\")\n        if len(spec) > 1:\n            raise NipapExtraneousInputError(\"VRF specification contains too many keys, specify VRF id, vrf or name.\")\n\n        where, params = self._sql_expand_where(spec, 'spec_')\n\n        return where, params"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_vrf(self, auth, attr):\n\n        self._logger.debug(\"add_vrf called; attr: %s\" % unicode(attr))\n\n        # sanity check - do we have all attributes?\n        req_attr = [ 'rt', 'name' ]\n        self._check_attr(attr, req_attr, _vrf_attrs)\n\n        insert, params = self._sql_expand_insert(attr)\n        sql = \"INSERT INTO ip_net_vrf \" + insert\n\n        self._execute(sql, params)\n        vrf_id = self._lastrowid()\n        vrf = self.list_vrf(auth, { 'id': vrf_id })[0]\n\n        # write to audit table\n        audit_params = {\n            'vrf_id': vrf['id'],\n            'vrf_rt': vrf['rt'],\n            'vrf_name': vrf['name'],\n            'username': auth.username,\n            'authenticated_as': auth.authenticated_as,\n            'full_name': auth.full_name,\n            'authoritative_source': auth.authoritative_source,\n            'description': 'Added VRF %s with attr: %s' % (vrf['rt'], unicode(vrf))\n        }\n\n        sql, params = self._sql_expand_insert(audit_params)\n        self._execute('INSERT INTO ip_net_log %s' % sql, params)\n\n        return vrf", "response": "Add a new VRF to the database."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving a VRF from the database.", "response": "def remove_vrf(self, auth, spec):\n        \"\"\" Remove a VRF.\n\n            * `auth` [BaseAuth]\n                AAA options.\n            * `spec` [vrf_spec]\n                A VRF specification.\n\n            Remove VRF matching the `spec` argument.\n\n            This is the documentation of the internal backend function. It's\n            exposed over XML-RPC, please also see the XML-RPC documentation for\n            :py:func:`nipap.xmlrpc.NipapXMLRPC.remove_vrf` for full\n            understanding.\n        \"\"\"\n\n        self._logger.debug(\"remove_vrf called; spec: %s\" % unicode(spec))\n\n        # get list of VRFs to remove before removing them\n        vrfs = self.list_vrf(auth, spec)\n\n        # remove prefixes in VRFs\n        for vrf in vrfs:\n            v4spec = {\n                'prefix': '0.0.0.0/0',\n                'vrf_id': vrf['id']\n            }\n            v6spec = {\n                'prefix': '::/0',\n                'vrf_id': vrf['id']\n            }\n            self.remove_prefix(auth, spec = v4spec, recursive = True)\n            self.remove_prefix(auth, spec = v6spec, recursive = True)\n\n        where, params = self._expand_vrf_spec(spec)\n        sql = \"DELETE FROM ip_net_vrf WHERE %s\" % where\n        self._execute(sql, params)\n\n        # write to audit table\n        for v in vrfs:\n            audit_params = {\n                'vrf_id': v['id'],\n                'vrf_rt': v['rt'],\n                'vrf_name': v['name'],\n                'username': auth.username,\n                'authenticated_as': auth.authenticated_as,\n                'full_name': auth.full_name,\n                'authoritative_source': auth.authoritative_source,\n                'description': 'Removed vrf %s' % v['rt']\n            }\n            sql, params = self._sql_expand_insert(audit_params)\n            self._execute('INSERT INTO ip_net_log %s' % sql, params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_vrf(self, auth, spec=None):\n\n        if spec is None:\n            spec = {}\n\n        self._logger.debug(\"list_vrf called; spec: %s\" % unicode(spec))\n\n        sql = \"SELECT * FROM ip_net_vrf\"\n\n        params = list()\n        # no spec lists all VRFs\n        if spec is not None and not {}:\n            where, params = self._expand_vrf_spec(spec)\n        if len(params) > 0:\n            sql += \" WHERE \" + where\n\n        sql += \" ORDER BY vrf_rt_order(rt) NULLS FIRST\"\n\n        self._execute(sql, params)\n\n        res = list()\n        for row in self._curs_pg:\n            res.append(dict(row))\n\n        return res", "response": "Return a list of VRFs matching spec."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a VRF based on prefix spec", "response": "def _get_vrf(self, auth, spec, prefix = 'vrf_'):\n        \"\"\" Get a VRF based on prefix spec\n\n            Shorthand function to reduce code in the functions below, since\n            more or less all of them needs to perform the actions that are\n            specified here.\n\n            The major difference to :func:`list_vrf` is that we always return\n            results - empty results if no VRF is specified in prefix spec.\n        \"\"\"\n\n        # find VRF from attributes vrf, vrf_id or vrf_name\n        vrf = []\n        if prefix + 'id' in spec:\n            # if None, mangle it to being 0, ie our default VRF\n            if spec[prefix + 'id'] is None:\n                spec[prefix + 'id'] = 0\n            vrf = self.list_vrf(auth, { 'id': spec[prefix + 'id'] })\n        elif prefix + 'rt' in spec:\n            vrf = self.list_vrf(auth, { 'rt': spec[prefix + 'rt'] })\n        elif prefix + 'name' in spec:\n            vrf = self.list_vrf(auth, { 'name': spec[prefix + 'name'] })\n        else:\n            # no VRF specified - return VRF \"default\"\n            vrf = self.list_vrf(auth, { 'id': 0 })\n\n        if len(vrf) > 0:\n            return vrf[0]\n\n        raise NipapNonExistentError('No matching VRF found.')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef edit_vrf(self, auth, spec, attr):\n\n        self._logger.debug(\"edit_vrf called; spec: %s attr: %s\" %\n                (unicode(spec), unicode(attr)))\n\n        # sanity check - do we have all attributes?\n        self._check_attr(attr, [], _vrf_attrs)\n\n        # get list of VRFs which will be changed before changing them\n        vrfs = self.list_vrf(auth, spec)\n\n        where, params1 = self._expand_vrf_spec(spec)\n        update, params2 = self._sql_expand_update(attr)\n        params = dict(params2.items() + params1.items())\n\n        if len(attr) == 0:\n            raise NipapInputError(\"'attr' must not be empty.\")\n\n        sql = \"UPDATE ip_net_vrf SET \" + update\n        sql += \" WHERE \" + where\n        sql += \" RETURNING id\"\n\n        self._execute(sql, params)\n        updated_vrfs = self._get_updated_rows(auth, self.search_vrf)\n\n        # write to audit table\n        for v in vrfs:\n            audit_params = {\n                'vrf_id': v['id'],\n                'vrf_rt': v['rt'],\n                'vrf_name': v['name'],\n                'username': auth.username,\n                'authenticated_as': auth.authenticated_as,\n                'full_name': auth.full_name,\n                'authoritative_source': auth.authoritative_source,\n                'description': 'Edited VRF %s attr: %s' % (v['rt'], unicode(attr))\n            }\n            sql, params = self._sql_expand_insert(audit_params)\n            self._execute('INSERT INTO ip_net_log %s' % sql, params)\n\n        return updated_vrfs", "response": "Edit the VRF matching spec with attributes attr."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nperform a smart search on the VRF list.", "response": "def smart_search_vrf(self, auth, query_str, search_options=None, extra_query=None):\n        \"\"\" Perform a smart search on VRF list.\n\n            * `auth` [BaseAuth]\n                AAA options.\n            * `query_str` [string]\n                Search string\n            * `search_options` [options_dict]\n                Search options. See :func:`search_vrf`.\n            * `extra_query` [dict_to_sql]\n                Extra search terms, will be AND:ed together with what is\n                extracted from the query string.\n\n            Return a dict with three elements:\n                * :attr:`interpretation` - How the query string was interpreted.\n                * :attr:`search_options` - Various search_options.\n                * :attr:`result` - The search result.\n\n                The :attr:`interpretation` is given as a list of dicts, each\n                explaining how a part of the search key was interpreted (ie. what\n                VRF attribute the search operation was performed on).\n\n                The :attr:`result` is a list of dicts containing the search result.\n\n            The smart search function tries to convert the query from a text\n            string to a `query` dict which is passed to the\n            :func:`search_vrf` function.  If multiple search keys are\n            detected, they are combined with a logical AND.\n\n            It will basically just take each search term and try to match it\n            against the name or description column with regex match or the VRF\n            column with an exact match.\n\n            See the :func:`search_vrf` function for an explanation of the\n            `search_options` argument.\n\n            This is the documentation of the internal backend function. It's\n            exposed over XML-RPC, please also see the XML-RPC documentation for\n            :py:func:`nipap.xmlrpc.NipapXMLRPC.smart_search_vrf` for full\n            understanding.\n        \"\"\"\n\n        if search_options is None:\n            search_options = {}\n\n        self._logger.debug(\"smart_search_vrf query string: %s\" % query_str)\n\n        success, query = self._parse_vrf_query(query_str)\n        if not success:\n            return {\n                'interpretation': query,\n                'search_options': search_options,\n                'result': [],\n                'error': True,\n                'error_message': 'query interpretation failed'\n            }\n\n        if extra_query is not None:\n            query = {\n                'operator': 'and',\n                'val1': query,\n                'val2': extra_query\n            }\n\n        self._logger.debug(\"smart_search_vrf; query expanded to: %s\" % unicode(query))\n\n        search_result = self.search_vrf(auth, query, search_options)\n        search_result['interpretation'] = query\n        search_result['error'] = False\n\n        return search_result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing a smart search query for VRFs", "response": "def _parse_vrf_query(self, query_str):\n        \"\"\" Parse a smart search query for VRFs\n\n            This is a helper function to smart_search_vrf for easier unit\n            testing of the parser.\n        \"\"\"\n        sp = smart_parsing.VrfSmartParser()\n        query = sp.parse(query_str)\n        return query"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a pool according to attr.", "response": "def add_pool(self, auth, attr):\n        \"\"\" Create a pool according to `attr`.\n\n            * `auth` [BaseAuth]\n                AAA options.\n            * `attr` [pool_attr]\n                A dict containing the attributes the new pool should have.\n\n            Returns a dict describing the pool which was added.\n\n            This is the documentation of the internal backend function. It's\n            exposed over XML-RPC, please also see the XML-RPC documentation for\n            :py:func:`nipap.xmlrpc.NipapXMLRPC.add_pool` for full\n            understanding.\n        \"\"\"\n\n        self._logger.debug(\"add_pool called; attrs: %s\" % unicode(attr))\n\n        # sanity check - do we have all attributes?\n        req_attr = ['name', 'description', 'default_type']\n        self._check_pool_attr(attr, req_attr)\n\n        insert, params = self._sql_expand_insert(attr)\n        sql = \"INSERT INTO ip_net_pool \" + insert\n\n        self._execute(sql, params)\n        pool_id = self._lastrowid()\n        pool = self.list_pool(auth, { 'id': pool_id })[0]\n\n        # write to audit table\n        audit_params = {\n            'pool_id': pool['id'],\n            'pool_name': pool['name'],\n            'username': auth.username,\n            'authenticated_as': auth.authenticated_as,\n            'full_name': auth.full_name,\n            'authoritative_source': auth.authoritative_source,\n            'description': 'Added pool %s with attr: %s' % (pool['name'], unicode(attr))\n        }\n        sql, params = self._sql_expand_insert(audit_params)\n        self._execute('INSERT INTO ip_net_log %s' % sql, params)\n\n        return pool"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_pool(self, auth, spec):\n\n        self._logger.debug(\"remove_pool called; spec: %s\" % unicode(spec))\n\n        # fetch list of pools to remove before they are removed\n        pools = self.list_pool(auth, spec)\n\n        where, params = self._expand_pool_spec(spec)\n        sql = \"DELETE FROM ip_net_pool AS po WHERE %s\" % where\n        self._execute(sql, params)\n\n        # write to audit table\n        audit_params = {\n            'username': auth.username,\n            'authenticated_as': auth.authenticated_as,\n            'full_name': auth.full_name,\n            'authoritative_source': auth.authoritative_source,\n        }\n        for p in pools:\n            audit_params['pool_id'] = p['id'],\n            audit_params['pool_name'] = p['name'],\n            audit_params['description'] = 'Removed pool %s' % p['name']\n\n            sql, params = self._sql_expand_insert(audit_params)\n            self._execute('INSERT INTO ip_net_log %s' % sql, params)", "response": "Removes a pool from the database."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_pool(self, auth, spec=None):\n\n        if spec is None:\n            spec = {}\n\n        self._logger.debug(\"list_pool called; spec: %s\" % unicode(spec))\n\n        sql = \"\"\"SELECT DISTINCT (po.id),\n                        po.id,\n                        po.name,\n                        po.description,\n                        po.default_type,\n                        po.ipv4_default_prefix_length,\n                        po.ipv6_default_prefix_length,\n                        po.member_prefixes_v4,\n                        po.member_prefixes_v6,\n                        po.used_prefixes_v4,\n                        po.used_prefixes_v6,\n                        po.free_prefixes_v4,\n                        po.free_prefixes_v6,\n                        po.total_prefixes_v4,\n                        po.total_prefixes_v6,\n                        po.total_addresses_v4,\n                        po.total_addresses_v6,\n                        po.used_addresses_v4,\n                        po.used_addresses_v6,\n                        po.free_addresses_v4,\n                        po.free_addresses_v6,\n                        po.tags,\n                        po.avps,\n                        vrf.id AS vrf_id,\n                        vrf.rt AS vrf_rt,\n                        vrf.name AS vrf_name,\n                        (SELECT array_agg(prefix::text) FROM (SELECT prefix FROM ip_net_plan WHERE pool_id=po.id ORDER BY prefix) AS a) AS prefixes\n                FROM ip_net_pool AS po\n                LEFT OUTER JOIN ip_net_plan AS inp ON (inp.pool_id = po.id)\n                LEFT OUTER JOIN ip_net_vrf AS vrf ON (vrf.id = inp.vrf_id)\"\"\"\n        params = list()\n\n        # expand spec\n        where, params = self._expand_pool_spec(spec)\n        if len(where) > 0:\n            sql += \" WHERE \" + where\n\n        sql += \" ORDER BY name\"\n\n        self._execute(sql, params)\n\n        res = list()\n        for row in self._curs_pg:\n            p = dict(row)\n\n            # Make sure that prefixes is a list, even if there are no prefixes\n            if p['prefixes'] is None:\n                p['prefixes'] = []\n            res.append(p)\n\n        return res", "response": "List all the pools in the specified base auth."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a pool. Shorthand function to reduce code in the functions below, since more or less all of them needs to perform the actions that are specified here. The major difference to :func:`list_pool` is that an exception is raised if no pool matching the spec is found.", "response": "def _get_pool(self, auth, spec):\n        \"\"\" Get a pool.\n\n            Shorthand function to reduce code in the functions below, since\n            more or less all of them needs to perform the actions that are\n            specified here.\n\n            The major difference to :func:`list_pool` is that an exception\n            is raised if no pool matching the spec is found.\n        \"\"\"\n\n        pool = self.list_pool(auth, spec)\n        if len(pool) == 0:\n            raise NipapInputError(\"non-existing pool specified\")\n        return pool[0]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef edit_pool(self, auth, spec, attr):\n\n        self._logger.debug(\"edit_pool called; spec: %s attr: %s\" %\n                (unicode(spec), unicode(attr)))\n\n        if ('id' not in spec and 'name' not in spec) or ( 'id' in spec and 'name' in spec ):\n            raise NipapMissingInputError('''pool spec must contain either 'id' or 'name' ''')\n\n        self._check_pool_attr(attr)\n\n        where, params1 = self._expand_pool_spec(spec)\n        update, params2 = self._sql_expand_update(attr)\n        params = dict(params2.items() + params1.items())\n\n        pools = self.list_pool(auth, spec)\n\n        sql = \"UPDATE ip_net_pool SET \" + update\n        sql += \" FROM ip_net_pool AS po WHERE ip_net_pool.id = po.id AND \" + where\n        sql += \" RETURNING po.id AS id\"\n\n        self._execute(sql, params)\n\n        updated_pools = self._get_updated_rows(auth, self.search_pool)\n\n        # write to audit table\n        audit_params = {\n            'username': auth.username,\n            'authenticated_as': auth.authenticated_as,\n            'full_name': auth.full_name,\n            'authoritative_source': auth.authoritative_source\n        }\n        for p in pools:\n            audit_params['pool_id'] = p['id']\n            audit_params['pool_name'] = p['name']\n            audit_params['description'] = 'Edited pool %s attr: %s' % (p['name'], unicode(attr))\n\n            sql, params = self._sql_expand_insert(audit_params)\n            self._execute('INSERT INTO ip_net_log %s' % sql, params)\n\n        return updated_pools", "response": "Edit the pool given by spec with attributes attr."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef smart_search_pool(self, auth, query_str, search_options=None, extra_query=None):\n\n        if search_options is None:\n            search_options = {}\n\n        self._logger.debug(\"smart_search_pool query string: %s\" % query_str)\n\n        success, query = self._parse_pool_query(query_str)\n        if not success:\n            return {\n                'interpretation': query,\n                'search_options': search_options,\n                'result': [],\n                'error': True,\n                'error_message': 'query interpretation failed'\n        }\n\n        if extra_query is not None:\n            query = {\n                'operator': 'and',\n                'val1': query,\n                'val2': extra_query\n            }\n\n        self._logger.debug(\"smart_search_pool; query expanded to: %s\" % unicode(query))\n\n        search_result = self.search_pool(auth, query, search_options)\n        search_result['interpretation'] = query\n        search_result['error'] = False\n\n        return search_result", "response": "Perform a smart search on the pool list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing a smart search query for pools", "response": "def _parse_pool_query(self, query_str):\n        \"\"\" Parse a smart search query for pools\n\n            This is a helper function to smart_search_pool for easier unit\n            testing of the parser.\n        \"\"\"\n        sp = smart_parsing.PoolSmartParser()\n        query = sp.parse(query_str)\n        return query"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexpanding prefix specification to SQL.", "response": "def _expand_prefix_spec(self, spec, prefix = ''):\n        \"\"\" Expand prefix specification to SQL.\n        \"\"\"\n\n        # sanity checks\n        if type(spec) is not dict:\n            raise NipapInputError('invalid prefix specification')\n\n        for key in spec.keys():\n            if key not in _prefix_spec:\n                raise NipapExtraneousInputError(\"Key '\" + key + \"' not allowed in prefix spec.\")\n\n        where = \"\"\n        params = {}\n\n        # if we have id, no other input is needed\n        if 'id' in spec:\n            if spec != {'id': spec['id']}:\n                raise NipapExtraneousInputError(\"If 'id' specified, no other keys are allowed.\")\n\n        family = None\n        if 'family' in spec:\n            family = spec['family']\n            del(spec['family'])\n\n        # rename prefix columns\n        spec2 = {}\n        for k in spec:\n            spec2[prefix + k] = spec[k]\n        spec = spec2\n\n        # handle keys which refer to external keys\n        if prefix + 'vrf_id' in spec:\n            # \"translate\" vrf id None to id = 0\n            if spec[prefix + 'vrf_id'] is None:\n                spec[prefix + 'vrf_id'] = 0\n\n        if prefix + 'vrf_name' in spec:\n            spec['vrf.name'] = spec[prefix + 'vrf_name']\n            del(spec[prefix + 'vrf_name'])\n\n        if prefix + 'vrf_rt' in spec:\n            spec['vrf.rt'] = spec[prefix + 'vrf_rt']\n            del(spec[prefix + 'vrf_rt'])\n\n        if prefix + 'pool_name' in spec:\n            spec['pool.name'] = spec[prefix + 'pool_name']\n            del(spec[prefix + 'pool_name'])\n\n        where, params = self._sql_expand_where(spec)\n\n        # prefix family needs to be handled separately as it's not stored\n        # explicitly in the database\n        if family:\n            if len(params) == 0:\n                where = \"family(\" + prefix + \"prefix) = %(family)s\"\n            else:\n                where += \" AND family(\" + prefix + \"prefix) = %(family)s\"\n            params['family'] = family\n\n        self._logger.debug(\"_expand_prefix_spec; where: %s params: %s\" % (where, unicode(params)))\n        return where, params"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexpanding a prefix query dict into a WHERE - clause.", "response": "def _expand_prefix_query(self, query, table_name = None):\n        \"\"\" Expand prefix query dict into a WHERE-clause.\n\n            If you need to prefix each column reference with a table\n            name, that can be supplied via the table_name argument.\n        \"\"\"\n\n        where = unicode()\n        opt = list()\n\n        # handle table name, can be None\n        if table_name is None:\n            col_prefix = \"\"\n        else:\n            col_prefix = table_name + \".\"\n\n        if 'val1' not in query:\n            raise NipapMissingInputError(\"'val1' must be specified\")\n        if 'val2' not in query:\n            raise NipapMissingInputError(\"'val2' must be specified\")\n\n        if type(query['val1']) == dict and type(query['val2']) == dict:\n            # Sub expression, recurse! This is used for boolean operators: AND OR\n            # add parantheses\n\n            sub_where1, opt1 = self._expand_prefix_query(query['val1'], table_name)\n            sub_where2, opt2 = self._expand_prefix_query(query['val2'], table_name)\n            try:\n                where += unicode(\" (%s %s %s) \" % (sub_where1, _operation_map[query['operator']], sub_where2) )\n            except KeyError:\n                raise NipapNoSuchOperatorError(\"No such operator %s\" % unicode(query['operator']))\n\n            opt += opt1\n            opt += opt2\n\n        else:\n\n            # TODO: raise exception if someone passes one dict and one \"something else\"?\n\n            # val1 is key, val2 is value.\n\n            if query['val1'] not in _prefix_spec:\n                raise NipapInputError('Search variable \\'%s\\' unknown' % unicode(query['val1']))\n\n            # build where clause\n            if query['operator'] not in _operation_map:\n                raise NipapNoSuchOperatorError(\"No such operator %s\" % query['operator'])\n\n            if query['val1'] == 'vrf_id' and query['val2'] is None:\n                query['val2'] = 0\n\n            # workaround for handling equal matches of NULL-values\n            if query['operator'] == 'equals' and query['val2'] is None:\n                query['operator'] = 'is'\n            elif query['operator'] == 'not_equals' and query['val2'] is None:\n                query['operator'] = 'is_not'\n\n            if query['operator'] in (\n                    'contains',\n                    'contains_equals',\n                    'contained_within',\n                    'contained_within_equals'):\n\n                where = \" iprange(prefix) %(operator)s %%s \" % {\n                        'col_prefix': col_prefix,\n                        'operator': _operation_map[query['operator']]\n                        }\n\n            elif query['operator'] in ('equals_any',):\n                where = unicode(\" %%s = ANY (%s%s::citext[]) \" %\n                        ( col_prefix, _prefix_spec[query['val1']]['column'])\n                        )\n\n            elif query['operator'] in (\n                    'like',\n                    'regex_match',\n                    'regex_not_match'):\n                # we COALESCE column with '' to allow for example a regexp\n                # search on '.*' to match columns which are NULL in the\n                # database\n                where = unicode(\" COALESCE(%s%s, '') %s %%s \" %\n                        ( col_prefix, _prefix_spec[query['val1']]['column'],\n                        _operation_map[query['operator']] )\n                        )\n\n            else:\n                where = unicode(\" %s%s %s %%s \" %\n                        ( col_prefix, _prefix_spec[query['val1']]['column'],\n                        _operation_map[query['operator']] )\n                        )\n\n            opt.append(query['val2'])\n\n        return where, opt"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_prefix(self, auth, attr, args=None):\n\n        if args is None:\n            args = {}\n\n        self._logger.debug(\"add_prefix called; attr: %s; args: %s\" % (unicode(attr), unicode(args)))\n\n        # args defined?\n        if args is None:\n            args = {}\n\n        # attr must be a dict!\n        if type(attr) != dict:\n            raise NipapInputError(\"'attr' must be a dict\")\n\n        # handle pool attributes - find correct one and remove bad pool keys\n        # note how this is not related to from-pool but is merely the pool\n        # attributes if this prefix is to be part of a pool\n        if 'pool_id' in attr or 'pool_name' in attr:\n            if 'pool_id' in attr:\n                if attr['pool_id'] is None:\n                    pool = {\n                        'id': None,\n                        'name': None\n                    }\n                else:\n                    pool = self._get_pool(auth, { 'id': attr['pool_id'] })\n\n            else:\n                if attr['pool_name'] is None:\n                    pool = {\n                        'id': None,\n                        'name': None\n                    }\n                else:\n                    # resolve pool name to pool id\n                    pool = self._get_pool(auth, { 'name': attr['pool_name'] })\n\n                # and delete the pool_name attr\n                del(attr['pool_name'])\n\n            attr['pool_id'] = pool['id']\n\n        else:\n            pool = {\n                'id': None,\n                'name': None\n            }\n\n        attr['authoritative_source'] = auth.authoritative_source\n\n        # sanity checks for manual prefix vs from-pool vs from-prefix\n        if 'prefix' in attr:\n            if 'from-pool' in args or 'from-prefix' in args:\n                raise NipapExtraneousInputError(\"specify 'prefix' or 'from-prefix' or 'from-pool'\")\n\n        else:\n            if ('from-pool' not in args and 'from-prefix' not in args) or ('from-pool' in args and 'from-prefix' in args):\n                raise NipapExtraneousInputError(\"specify 'prefix' or 'from-prefix' or 'from-pool'\")\n\n        # VRF handling for manually specified prefix\n        if 'prefix' in attr:\n            # handle VRF - find the correct one and remove bad VRF keys\n            vrf = self._get_vrf(auth, attr)\n            if 'vrf_rt' in attr:\n                del(attr['vrf_rt'])\n            if 'vrf_name' in attr:\n                del(attr['vrf_name'])\n            attr['vrf_id'] = vrf['id']\n\n        # VRF handling for allocation from pool or parent prefix\n        if 'from-pool' in args or 'from-prefix' in args:\n            # did we get a VRF from the client?\n            if 'vrf_id' in attr or 'vrf_rt' in attr or 'vrf_name' in attr:\n                # handle VRF - find the correct one and remove bad VRF keys\n                vrf = self._get_vrf(auth, attr)\n                if 'vrf_rt' in attr:\n                    del(attr['vrf_rt'])\n                if 'vrf_name' in attr:\n                    del(attr['vrf_name'])\n                attr['vrf_id'] = vrf['id']\n\n            if 'from-pool' in args:\n                from_pool = self._get_pool(auth, args['from-pool'])\n\n                # make sure there are prefixes in pool, if any prefix is present\n                # than the implied-vrf is set, otherwise the pool is empty\n                if from_pool['vrf_id'] is None:\n                    raise NipapInputError('No prefixes in pool')\n\n                # set default type from pool if missing\n                if 'type' not in attr:\n                    attr['type'] = from_pool['default_type']\n\n                # set implied VRF of pool if missing\n                if 'vrf_id' not in attr:\n                    attr['vrf_id'] = from_pool['vrf_id']\n\n                # make sure VRF aligns with pool implied VRF\n                if attr['vrf_id'] != from_pool['vrf_id']:\n                    raise NipapInputError(\"VRF must be the same as the pools implied VRF\")\n\n                vrf = self._get_vrf(auth, attr)\n\n            if 'from-prefix' in args:\n                # handle VRF - find the correct one and remove bad VRF keys\n                vrf = self._get_vrf(auth, attr)\n                if 'vrf_rt' in attr:\n                    del(attr['vrf_rt'])\n                if 'vrf_name' in attr:\n                    del(attr['vrf_name'])\n                attr['vrf_id'] = vrf['id']\n\n            # VRF fiddling\n            ffp_vrf = self._get_vrf(auth, attr)\n\n            # get a new prefix\n            res = self.find_free_prefix(auth, ffp_vrf, args)\n            if res != []:\n                attr['prefix'] = res[0]\n            else:\n                # TODO: Raise other exception?\n                raise NipapNonExistentError(\"no free prefix found\")\n\n        # do we have all attributes?\n        req_attr = [ 'prefix', 'authoritative_source' ]\n        self._check_attr(attr, req_attr, _prefix_attrs)\n        if ('description' not in attr) and ('node' not in attr):\n            raise NipapMissingInputError('Either description or node must be specified.')\n\n        if 'expires' in attr:\n            attr['expires'] = _parse_expires(attr['expires'])\n\n        insert, params = self._sql_expand_insert(attr)\n        sql = \"INSERT INTO ip_net_plan \" + insert\n\n        self._execute(sql, params)\n        prefix_id = self._lastrowid()\n        prefix = self.list_prefix(auth, { 'id': prefix_id })[0]\n\n        # write to audit table\n        audit_params = {\n            'vrf_id': prefix['vrf_id'],\n            'vrf_rt': prefix['vrf_rt'],\n            'vrf_name': prefix['vrf_name'],\n            'prefix_id': prefix['id'],\n            'prefix_prefix': prefix['prefix'],\n            'username': auth.username,\n            'authenticated_as': auth.authenticated_as,\n            'full_name': auth.full_name,\n            'authoritative_source': auth.authoritative_source,\n            'description': 'Added prefix %s with attr: %s' % (prefix['prefix'], unicode(attr))\n        }\n        sql, params = self._sql_expand_insert(audit_params)\n        self._execute('INSERT INTO ip_net_log %s' % sql, params)\n\n        if pool['id'] is not None:\n            audit_params['pool_id'] = pool['id']\n            audit_params['pool_name'] = pool['name']\n            audit_params['description'] = 'Pool %s expanded with prefix %s in VRF %s' % (pool['name'], prefix['prefix'], unicode(prefix['vrf_rt']))\n\n            sql, params = self._sql_expand_insert(audit_params)\n            self._execute('INSERT INTO ip_net_log %s' % sql, params)\n\n        return prefix", "response": "Add a prefix and return its ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nedits the type of a prefix matching spec with attributes attr.", "response": "def edit_prefix(self, auth, spec, attr):\n        \"\"\" Update prefix matching `spec` with attributes `attr`.\n\n            * `auth` [BaseAuth]\n                AAA options.\n            * `spec` [prefix_spec]\n                Specifies the prefix to edit.\n            * `attr` [prefix_attr]\n                Prefix attributes.\n\n            Note that there are restrictions on when and how a prefix's type\n            can be changed; reservations can be changed to assignments and vice\n            versa, but only if they contain no child prefixes.\n\n            This is the documentation of the internal backend function. It's\n            exposed over XML-RPC, please also see the XML-RPC documentation for\n            :py:func:`nipap.xmlrpc.NipapXMLRPC.edit_prefix` for full\n            understanding.\n        \"\"\"\n\n        self._logger.debug(\"edit_prefix called; spec: %s attr: %s\" %\n                (unicode(spec), unicode(attr)))\n\n        # Handle Pool - find correct one and remove bad pool keys\n        pool = None\n        if 'pool_id' in attr or 'pool_name' in attr:\n            if 'pool_id' in attr:\n                if attr['pool_id'] is None:\n                    pool = {\n                        'id': None,\n                        'name': None\n                    }\n                else:\n                    pool = self._get_pool(auth, { 'id': attr['pool_id'] })\n\n            else:\n                if attr['pool_name'] is None:\n                    pool = {\n                        'id': None,\n                        'name': None\n                    }\n                else:\n                    # resolve pool name to pool id\n                    pool = self._get_pool(auth, { 'name': attr['pool_name'] })\n                # and delete the pool_name attr\n                del(attr['pool_name'])\n\n            attr['pool_id'] = pool['id']\n\n        else:\n            pool = {\n                'id': None,\n                'name': None\n            }\n\n        # Handle VRF - find the correct one and remove bad VRF keys.\n        vrf = self._get_vrf(auth, attr)\n        if 'vrf_rt' in attr:\n            del(attr['vrf_rt'])\n        if 'vrf_name' in attr:\n            del(attr['vrf_name'])\n        attr['vrf_id'] = vrf['id']\n\n        self._check_attr(attr, [], _prefix_attrs)\n\n        if 'expires' in attr:\n            attr['expires'] = _parse_expires(attr['expires'])\n\n        prefixes = self.list_prefix(auth, spec)\n        where, params1 = self._expand_prefix_spec(spec.copy())\n\n        update, params2 = self._sql_expand_update(attr)\n        params = dict(params2.items() + params1.items())\n\n        sql = \"UPDATE ip_net_plan SET \" + update + \" WHERE \" + where\n        sql += \" RETURNING id\"\n\n        self._execute(sql, params)\n        updated_prefixes = self._get_updated_rows(auth, self.search_prefix)\n\n        # write to audit table\n        audit_params = {\n            'username': auth.username,\n            'authenticated_as': auth.authenticated_as,\n            'full_name': auth.full_name,\n            'authoritative_source': auth.authoritative_source,\n            'vrf_id': vrf['id'],\n            'vrf_rt': vrf['rt'],\n            'vrf_name': vrf['name']\n        }\n\n        for p in prefixes:\n            audit_params['vrf_id'] = p['vrf_id']\n            audit_params['vrf_rt'] = p['vrf_rt']\n            audit_params['vrf_name'] = p['vrf_name']\n            audit_params['prefix_id'] = p['id']\n            audit_params['prefix_prefix'] = p['prefix']\n            audit_params['description'] = 'Edited prefix %s attr: %s' % (p['prefix'], unicode(attr))\n            sql, params = self._sql_expand_insert(audit_params)\n            self._execute('INSERT INTO ip_net_log %s' % sql, params)\n\n            # Only add to log if something was changed\n            if p['pool_id'] != pool['id']:\n\n                audit_params2 = {\n                    'prefix_id': p['id'],\n                    'prefix_prefix': p['prefix'],\n                    'vrf_id': p['vrf_id'],\n                    'vrf_rt': p['vrf_rt'],\n                    'vrf_name': p['vrf_name'],\n                    'username': auth.username,\n                    'authenticated_as': auth.authenticated_as,\n                    'full_name': auth.full_name,\n                    'authoritative_source': auth.authoritative_source,\n                }\n\n                # If pool ID set, pool was expanded\n                if pool['id'] is not None:\n\n                    audit_params2['pool_id'] = pool['id']\n                    audit_params2['pool_name'] = pool['name']\n                    audit_params2['description'] = 'Expanded pool %s with prefix %s' % (pool['name'], p['prefix'])\n\n                    sql, params = self._sql_expand_insert(audit_params2)\n                    self._execute('INSERT INTO ip_net_log %s' % sql, params)\n\n                # if prefix had pool set previously, prefix was removed from that pool\n                if p['pool_id'] is not None:\n\n                    pool2 = self._get_pool(auth, { 'id': p['pool_id'] })\n\n                    audit_params2['pool_id'] = pool2['id']\n                    audit_params2['pool_name'] = pool2['name']\n                    audit_params2['description'] = 'Removed prefix %s from pool %s' % (p['prefix'], pool2['name'])\n\n                    sql, params = self._sql_expand_insert(audit_params2)\n                    self._execute('INSERT INTO ip_net_log %s' % sql, params)\n\n        return updated_prefixes"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_free_prefix(self, auth, vrf, args):\n\n        # input sanity\n        if type(args) is not dict:\n            raise NipapInputError(\"invalid input, please provide dict as args\")\n\n        # TODO: find good default value for max_num\n        # TODO: let max_num be configurable from configuration file\n        max_count = 1000\n        if 'count' in args:\n            if int(args['count']) > max_count:\n                raise NipapValueError(\"count over the maximum result size\")\n        else:\n            args['count'] = 1\n\n        if 'from-pool' in args:\n            if 'from-prefix' in args:\n                raise NipapInputError(\"specify 'from-pool' OR 'from-prefix'\")\n            if 'family' not in args:\n                raise NipapMissingInputError(\"'family' must be specified with 'from-pool' mode\")\n            try:\n                assert int(args['family']) in [ 4, 6 ]\n            except (TypeError, AssertionError):\n                raise NipapValueError(\"incorrect family specified, must be 4 or 6\")\n\n        elif 'from-prefix' in args:\n            if type(args['from-prefix']) is not list:\n                raise NipapInputError(\"from-prefix should be a list\")\n            if 'from-pool' in args:\n                raise NipapInputError(\"specify 'from-pool' OR 'from-prefix'\")\n            if 'prefix_length' not in args:\n                raise NipapMissingInputError(\"'prefix_length' must be specified with 'from-prefix'\")\n            if 'family' in args:\n                raise NipapExtraneousInputError(\"'family' is superfluous when in 'from-prefix' mode\")\n\n        # determine prefixes\n        prefixes = []\n        wpl = 0\n        if 'from-pool' in args:\n            # extract prefixes from\n            pool_result = self.list_pool(auth, args['from-pool'])\n            self._logger.debug(args)\n            if pool_result == []:\n                raise NipapNonExistentError(\"Non-existent pool specified\")\n            for p in pool_result[0]['prefixes']:\n                if self._get_afi(p) == int(args['family']):\n                    prefixes.append(p)\n            if len(prefixes) == 0:\n                raise NipapInputError('No prefixes of family %s in pool' % unicode(args['family']))\n            if 'prefix_length' not in args:\n                if int(args['family']) == 4:\n                    wpl = pool_result[0]['ipv4_default_prefix_length']\n                else:\n                    wpl = pool_result[0]['ipv6_default_prefix_length']\n\n        afi = None\n        if 'from-prefix' in args:\n            for prefix in args['from-prefix']:\n                prefix_afi = self._get_afi(prefix)\n                if afi is None:\n                    afi = prefix_afi\n                elif afi != prefix_afi:\n                    raise NipapInputError(\"mixing of address-family is not allowed for 'from-prefix' arg\")\n                prefixes.append(prefix)\n\n        if 'prefix_length' in args:\n            try:\n                wpl = int(args['prefix_length'])\n            except ValueError:\n                raise NipapValueError(\"prefix length must be integer\")\n\n        # sanity check the wanted prefix length\n        if afi == 4:\n            if wpl < 0 or wpl > 32:\n                raise NipapValueError(\"the specified wanted prefix length argument must be between 0 and 32 for ipv4\")\n        elif afi == 6:\n            if wpl < 0 or wpl > 128:\n                raise NipapValueError(\"the specified wanted prefix length argument must be between 0 and 128 for ipv6\")\n\n        # build SQL\n        params = {}\n        # TODO: this makes me want to piss my pants\n        #       we should really write a patch to psycopg2 or something to\n        #       properly adapt an python list of texts with values looking\n        #       like prefixes to a postgresql array of inets\n        sql_prefix = ' UNION '.join('SELECT %(prefix' + unicode(prefixes.index(p)) + ')s AS prefix' for p in prefixes)\n        for p in prefixes:\n            params['prefix' + unicode(prefixes.index(p))] = unicode(p)\n\n        damp = 'SELECT array_agg((prefix::text)::inet) FROM (' + sql_prefix + ') AS a'\n\n        sql = \"\"\"SELECT * FROM find_free_prefix(%(vrf_id)s, (\"\"\" + damp + \"\"\"), %(prefix_length)s, %(max_result)s) AS prefix\"\"\"\n\n        v = self._get_vrf(auth, vrf or {}, '')\n\n        params['vrf_id'] = v['id']\n        params['prefixes'] = prefixes\n        params['prefix_length'] = wpl\n        params['max_result'] = args['count']\n\n        self._execute(sql, params)\n\n        res = list()\n        for row in self._curs_pg:\n            res.append(unicode(row['prefix']))\n\n        return res", "response": "This method finds free prefixes in the given sources."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlisting the prefixes in the specified auth.", "response": "def list_prefix(self, auth, spec = None):\n        \"\"\" List prefixes matching the `spec`.\n\n            * `auth` [BaseAuth]\n                AAA options.\n            * `spec` [prefix_spec]\n                Specifies prefixes to list. If omitted, all will be listed.\n\n            Returns a list of dicts.\n\n            This is a quite blunt tool for finding prefixes, mostly useful for\n            fetching data about a single prefix. For more capable alternatives,\n            see the :func:`search_prefix` or :func:`smart_search_prefix` functions.\n\n            This is the documentation of the internal backend function. It's\n            exposed over XML-RPC, please also see the XML-RPC documentation for\n            :py:func:`nipap.xmlrpc.NipapXMLRPC.list_prefix` for full\n            understanding.\n        \"\"\"\n\n        self._logger.debug(\"list_prefix called; spec: %s\" % unicode(spec))\n\n\n        if type(spec) is dict:\n            where, params = self._expand_prefix_spec(spec.copy(), 'inp.')\n        else:\n            raise NipapError(\"invalid prefix specification\")\n\n        if where != '':\n            where = ' WHERE ' + where\n\n        sql = \"\"\"SELECT\n            inp.id,\n            vrf.id AS vrf_id,\n            vrf.rt AS vrf_rt,\n            vrf.name AS vrf_name,\n            family(prefix) AS family,\n            inp.prefix,\n            inp.display_prefix,\n            inp.description,\n            COALESCE(inp.inherited_tags, '{}') AS inherited_tags,\n            COALESCE(inp.tags, '{}') AS tags,\n            inp.node,\n            inp.comment,\n            pool.id AS pool_id,\n            pool.name AS pool_name,\n            inp.type,\n            inp.indent,\n            inp.country,\n            inp.order_id,\n            inp.customer_id,\n            inp.external_key,\n            inp.authoritative_source,\n            inp.alarm_priority,\n            inp.monitor,\n            inp.vlan,\n            inp.added,\n            inp.last_modified,\n            inp.total_addresses,\n            inp.used_addresses,\n            inp.free_addresses,\n            inp.status,\n            inp.avps,\n            inp.expires\n            FROM ip_net_plan inp\n            JOIN ip_net_vrf vrf ON (inp.vrf_id = vrf.id)\n            LEFT JOIN ip_net_pool pool ON (inp.pool_id = pool.id) %s\n            ORDER BY vrf.rt NULLS FIRST, prefix\"\"\" % where\n\n        self._execute(sql, params)\n\n        res = list()\n        for row in self._curs_pg:\n            pref = dict(row)\n            pref['display_prefix'] = unicode(pref['display_prefix'])\n            res.append(pref)\n\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving a prefix from the database.", "response": "def _db_remove_prefix(self, spec, recursive = False):\n        \"\"\" Do the underlying database operations to delete a prefix\n        \"\"\"\n        if recursive:\n            prefix = spec['prefix']\n            del spec['prefix']\n            where, params = self._expand_prefix_spec(spec)\n            spec['prefix'] = prefix\n            params['prefix'] = prefix\n            where = 'prefix <<= %(prefix)s AND ' + where\n        else:\n            where, params = self._expand_prefix_spec(spec)\n\n        sql = \"DELETE FROM ip_net_plan AS p WHERE %s\" % where\n        self._execute(sql, params)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove a prefix matching spec.", "response": "def remove_prefix(self, auth, spec, recursive = False):\n        \"\"\" Remove prefix matching `spec`.\n\n            * `auth` [BaseAuth]\n                AAA options.\n            * `spec` [prefix_spec]\n                Specifies prefixe to remove.\n            * `recursive` [bool]\n                When set to True, also remove child prefixes.\n\n            This is the documentation of the internal backend function. It's\n            exposed over XML-RPC, please also see the XML-RPC documentation for\n            :py:func:`nipap.xmlrpc.NipapXMLRPC.remove_prefix` for full\n            understanding.\n        \"\"\"\n\n        self._logger.debug(\"remove_prefix called; spec: %s\" % unicode(spec))\n\n        # sanity check - do we have all attributes?\n        if 'id' in spec:\n            # recursive requires a prefix, so translate id to prefix\n            p = self.list_prefix(auth, spec)[0]\n            del spec['id']\n            spec['prefix'] = p['prefix']\n            spec['vrf_id'] = p['vrf_id']\n        elif 'prefix' in spec:\n            pass\n        else:\n            raise NipapMissingInputError('missing prefix or id of prefix')\n\n        prefixes = self.list_prefix(auth, spec)\n\n        if recursive:\n            spec['type'] = 'host'\n            self._db_remove_prefix(spec, recursive)\n            del spec['type']\n            self._db_remove_prefix(spec, recursive)\n        else:\n            self._db_remove_prefix(spec)\n\n        # write to audit table\n        audit_params = {\n            'username': auth.username,\n            'authenticated_as': auth.authenticated_as,\n            'full_name': auth.full_name,\n            'authoritative_source': auth.authoritative_source\n        }\n        for p in prefixes:\n            audit_params['prefix_id'] = p['id']\n            audit_params['prefix_prefix'] = p['prefix']\n            audit_params['description'] = 'Removed prefix %s' % p['prefix']\n            audit_params['vrf_id'] = p['vrf_id']\n            audit_params['vrf_rt'] = p['vrf_rt']\n            audit_params['vrf_name'] = p['vrf_name']\n            sql, params = self._sql_expand_insert(audit_params)\n            self._execute('INSERT INTO ip_net_log %s' % sql, params)\n\n            if p['pool_id'] is not None:\n                pool = self._get_pool(auth, { 'id': p['pool_id'] })\n                audit_params2 = {\n                    'pool_id': pool['id'],\n                    'pool_name': pool['name'],\n                    'prefix_id': p['id'],\n                    'prefix_prefix': p['prefix'],\n                    'description': 'Prefix %s removed from pool %s' % (p['prefix'], pool['name']),\n                    'username': auth.username,\n                    'authenticated_as': auth.authenticated_as,\n                    'full_name': auth.full_name,\n                    'authoritative_source': auth.authoritative_source\n                }\n                sql, params = self._sql_expand_insert(audit_params2)\n                self._execute('INSERT INTO ip_net_log %s' % sql, params)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef search_prefix(self, auth, query, search_options=None):\n\n        if search_options is None:\n            search_options = {}\n\n        #\n        # sanitize search options and set default if option missing\n        #\n\n        # include_parents\n        if 'include_all_parents' not in search_options:\n            search_options['include_all_parents'] = False\n        else:\n            if search_options['include_all_parents'] not in (True, False):\n                raise NipapValueError('Invalid value for option ' +\n                    \"'include_all_parents'. Only true and false valid. Supplied value :'%s'\" % unicode(search_options['include_all_parents']))\n\n        # include_children\n        if 'include_all_children' not in search_options:\n            search_options['include_all_children'] = False\n        else:\n            if search_options['include_all_children'] not in (True, False):\n                raise NipapValueError('Invalid value for option ' +\n                    \"'include_all_children'. Only true and false valid. Supplied value: '%s'\" % unicode(search_options['include_all_children']))\n\n        # parents_depth\n        if 'parents_depth' not in search_options:\n            search_options['parents_depth'] = 0\n        else:\n            try:\n                search_options['parents_depth'] = int(search_options['parents_depth'])\n            except (ValueError, TypeError):\n                raise NipapValueError('Invalid value for option' +\n                    ''' 'parent_depth'. Only integer values allowed.''')\n\n        # children_depth\n        if 'children_depth' not in search_options:\n            search_options['children_depth'] = 0\n        else:\n            try:\n                search_options['children_depth'] = int(search_options['children_depth'])\n            except (ValueError, TypeError):\n                raise NipapValueError('Invalid value for option' +\n                    ''' 'children_depth'. Only integer values allowed.''')\n\n        # include_neighbors\n        if 'include_neighbors' not in search_options:\n            search_options['include_neighbors'] = False\n        else:\n            if search_options['include_neighbors'] not in (True, False):\n                raise NipapValueError('Invalid value for option ' +\n                    \"'include_neighbors'. Only true and false valid. Supplied value: '%s'\" % unicode(search_options['include_neighbors']))\n\n        # max_result\n        if 'max_result' not in search_options:\n            search_options['max_result'] = 50\n        else:\n            if search_options['max_result'] in (False, None):\n                search_options['max_result'] = None\n            else:\n                try:\n                    search_options['max_result'] = int(search_options['max_result'])\n                except (ValueError, TypeError):\n                    raise NipapValueError('Invalid value for option' +\n                        ''' 'max_result'. Only integer values allowed.''')\n\n        # offset\n        if 'offset' not in search_options:\n            search_options['offset'] = 0\n        else:\n            try:\n                search_options['offset'] = int(search_options['offset'])\n            except (ValueError, TypeError):\n                raise NipapValueError('Invalid value for option' +\n                    ''' 'offset'. Only integer values allowed.''')\n\n        # parent_prefix\n        if ('parent_prefix' not in search_options or\n                search_options['parent_prefix'] is None):\n            search_options['parent_prefix'] = None\n        else:\n            try:\n                _ = int(search_options['parent_prefix'])\n            except ValueError:\n                raise NipapValueError(\n                    \"Invalid value '%s' for option 'parent_prefix'. Must be the ID of a prefix.\"\n                        % search_options['parent_prefix'])\n            try:\n                parent_prefix = self.list_prefix(auth, { 'id': search_options['parent_prefix'] })[0]\n            except IndexError:\n                raise NipapNonExistentError(\"Parent prefix %s can not be found\" % search_options['parent_prefix'])\n\n        self._logger.debug('search_prefix search_options: %s' % unicode(search_options))\n\n        # translate search options to SQL\n\n        if search_options['include_all_parents'] or search_options['parents_depth'] == -1:\n            where_parents = ''\n        elif search_options['parents_depth'] >= 0:\n            where_parents = 'AND p1.indent BETWEEN p2.indent - %d AND p1.indent' % search_options['parents_depth']\n        else:\n            raise NipapValueError(\"Invalid value for option 'parents_depth'. Only integer values > -1 allowed.\")\n\n        if search_options['include_all_children'] or search_options['children_depth'] == -1:\n            where_children = ''\n        elif search_options['children_depth'] >= 0:\n            where_children = 'AND p1.indent BETWEEN p2.indent AND p2.indent + %d' % search_options['children_depth']\n        else:\n            raise NipapValueError(\"Invalid value for option 'children_depth'. Only integer values > -1 allowed.\")\n\n        if search_options['include_neighbors']:\n            include_neighbors = 'true'\n        else:\n            include_neighbors = 'false'\n\n        if search_options['parent_prefix']:\n            vrf_id = 0\n            if parent_prefix['vrf_id']:\n                vrf_id = parent_prefix['vrf_id']\n            where_parent_prefix = \" WHERE (p1.vrf_id = %s AND iprange(p1.prefix) <<= iprange('%s') AND p1.indent <= %s) \" % (vrf_id, parent_prefix['prefix'], parent_prefix['indent'] + 1)\n            left_join = 'LEFT OUTER'\n        else:\n            where_parent_prefix = ''\n            left_join = ''\n\n        if search_options['max_result'] is None:\n            limit_string = \"\"\n        else:\n            limit_string = \"LIMIT %d\" % (search_options['max_result'] + search_options['offset'])\n\n        display = '(p1.prefix << p2.display_prefix OR p2.prefix <<= p1.prefix %s) OR (p2.prefix >>= p1.prefix %s)' % (where_parents, where_children)\n\n        where, opt = self._expand_prefix_query(query)\n        sql = \"\"\"\n    SELECT\n        id,\n        vrf_id,\n        vrf_rt,\n        vrf_name,\n        family,\n        display,\n        match,\n        prefix,\n        prefix_length,\n        display_prefix::text AS display_prefix,\n        description,\n        comment,\n        inherited_tags,\n        tags,\n        node,\n        pool_id,\n        pool_name,\n        type,\n        status,\n        indent,\n        country,\n        order_id,\n        customer_id,\n        external_key,\n        authoritative_source,\n        alarm_priority,\n        monitor,\n        vlan,\n        added,\n        last_modified,\n        children,\n        total_addresses,\n        used_addresses,\n        free_addresses,\n        avps,\n        expires\n    FROM (\n        SELECT DISTINCT ON(vrf_rt_order(vrf.rt), p1.prefix) p1.id,\n            p1.prefix,\n            p1.display_prefix,\n            p1.description,\n            p1.comment,\n            COALESCE(p1.inherited_tags, '{}') AS inherited_tags,\n            COALESCE(p1.tags, '{}') AS tags,\n            p1.node,\n            pool.id AS pool_id,\n            pool.name AS pool_name,\n            p1.type,\n            p1.indent,\n            p1.country,\n            p1.order_id,\n            p1.customer_id,\n            p1.external_key,\n            p1.authoritative_source,\n            p1.alarm_priority,\n            p1.monitor,\n            p1.vlan,\n            p1.added,\n            p1.last_modified,\n            p1.children,\n            p1.total_addresses,\n            p1.used_addresses,\n            p1.free_addresses,\n            p1.status,\n            p1.avps,\n            p1.expires,\n            vrf.id AS vrf_id,\n            vrf.rt AS vrf_rt,\n            vrf.name AS vrf_name,\n            masklen(p1.prefix) AS prefix_length,\n            family(p1.prefix) AS family,\n            (\"\"\" + display + \"\"\") AS display,\n            CASE WHEN p1.prefix = p2.prefix THEN true ELSE false END AS match\n            FROM ip_net_plan AS p1\n            -- possible set LEFT OUTER JOIN, if we are doing a parent_prefix operation\n            \"\"\" + left_join + \"\"\" JOIN ip_net_plan AS p2 ON\n            (\n                (\n                    (p1.vrf_id = p2.vrf_id)\n                    AND\n                    (\n                        -- Join in the parents (p1) of matching prefixes (p2)\n                        (iprange(p1.prefix) >>= iprange(p2.prefix) \"\"\" + where_parents + \"\"\")\n                        OR\n                        -- Join in the children (p1) of matching prefixes (p2)\n                        (iprange(p1.prefix) << iprange(p2.prefix) \"\"\" + where_children + \"\"\")\n                        OR\n                        -- Join in all neighbors (p1) of matching prefixes (p2)\n                        (true = \"\"\" + include_neighbors + \"\"\" AND iprange(p1.prefix) << iprange(p2.display_prefix::cidr) AND p1.indent = p2.indent)\n                    )\n                )\n                -- set match conditions for p2\n                AND p2.id IN (\n                    SELECT inp.id FROM ip_net_plan AS inp JOIN ip_net_vrf AS vrf ON inp.vrf_id = vrf.id LEFT JOIN ip_net_pool AS pool ON inp.pool_id = pool.id\n                        WHERE \"\"\" + where + \"\"\"\n                    ORDER BY vrf_rt_order(vrf.rt) NULLS FIRST, prefix\n                    \"\"\" + limit_string + \"\"\"\n                )\n            )\n            JOIN ip_net_vrf AS vrf ON (p1.vrf_id = vrf.id)\n            LEFT JOIN ip_net_pool AS pool ON (p1.pool_id = pool.id)\n            -- possible set where conditions, if we are doing a parent_prefix operation\n            \"\"\" + where_parent_prefix + \"\"\"\n            ORDER BY vrf_rt_order(vrf.rt) NULLS FIRST, p1.prefix, CASE WHEN p1.prefix = p2.prefix THEN 0 ELSE 1 END OFFSET \"\"\"  + unicode(search_options['offset']) + \") AS a ORDER BY vrf_rt_order(vrf_rt) NULLS FIRST, prefix\"\n\n\n        self._execute(sql, opt)\n\n        result = list()\n        for row in self._curs_pg:\n            result.append(dict(row))\n            # This is a SQL LIMIT clause implemented in Python. It is performed\n            # here to avoid a silly planner missestimate in PostgreSQL. For too\n            # low values of LIMIT, the planner will prefer plans with very low\n            # startup costs which will in turn lead to the slow plan. We avoid\n            # the low value (or any value really) of LIMIT by performing the\n            # LIMIT in Python. There is still a LIMIT on the inner query which\n            # together with the OFFSET, which is still performed in PostgreSQL,\n            # yields a rather small result set and thus high speed.\n            if search_options['max_result'] not in (False, None):\n                if len(result) >= int(search_options['max_result']):\n                    break\n\n        return { 'search_options': search_options, 'result': result }", "response": "Search the AAA database for prefixes matching query."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef smart_search_prefix(self, auth, query_str, search_options=None, extra_query=None):\n\n        if search_options is None:\n            search_options = {}\n\n        self._logger.debug(\"smart_search_prefix query string: %s\" % query_str)\n\n        success, query = self._parse_prefix_query(query_str)\n        if not success:\n            return {\n                'interpretation': query,\n                'search_options': search_options,\n                'result': [],\n                'error': True,\n                'error_message': 'query interpretation failed'\n            }\n\n        if extra_query is not None:\n            query = {\n                'operator': 'and',\n                'val1': query,\n                'val2': extra_query\n            }\n\n        self._logger.debug(\"smart_search_prefix: query expanded to: %s\" % unicode(query))\n\n        search_result = self.search_prefix(auth, query, search_options)\n        search_result['interpretation'] = query\n        search_result['error'] = False\n\n        return search_result", "response": "Perform a smart search on the prefix list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing a smart search query for prefixes", "response": "def _parse_prefix_query(self, query_str):\n        \"\"\" Parse a smart search query for prefixes\n\n            This is a helper function to smart_search_prefix for easier unit\n            testing of the parser.\n        \"\"\"\n        sp = smart_parsing.PrefixSmartParser()\n        query = sp.parse(query_str)\n        return query"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_asn(self, auth, asn=None):\n\n        if asn is None:\n            asn = {}\n\n        self._logger.debug(\"list_asn called; asn: %s\" % unicode(asn))\n\n        sql = \"SELECT * FROM ip_net_asn\"\n        params = list()\n\n        where, params = self._expand_asn_spec(asn)\n        if len(params) > 0:\n            sql += \" WHERE \" + where\n\n        sql += \" ORDER BY asn ASC\"\n\n        self._execute(sql, params)\n\n        res = list()\n        for row in self._curs_pg:\n            res.append(dict(row))\n\n        return res", "response": "List AS numbers matching spec."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a ASN number to the NIPAP.", "response": "def add_asn(self, auth, attr):\n        \"\"\" Add AS number to NIPAP.\n\n            * `auth` [BaseAuth]\n                AAA options.\n            * `attr` [asn_attr]\n                ASN attributes.\n\n            Returns a dict describing the ASN which was added.\n\n            This is the documentation of the internal backend function. It's\n            exposed over XML-RPC, please also see the XML-RPC documentation for\n            :py:func:`nipap.xmlrpc.NipapXMLRPC.add_asn` for full\n            understanding.\n        \"\"\"\n\n        self._logger.debug(\"add_asn called; attr: %s\" % unicode(attr))\n\n        # sanity check - do we have all attributes?\n        req_attr = [ 'asn', ]\n        allowed_attr = [ 'asn', 'name' ]\n        self._check_attr(attr, req_attr, allowed_attr)\n\n        insert, params = self._sql_expand_insert(attr)\n        sql = \"INSERT INTO ip_net_asn \" + insert\n        self._execute(sql, params)\n\n        asn = self.list_asn(auth, { 'asn': attr['asn'] })[0]\n\n        # write to audit table\n        audit_params = {\n            'username': auth.username,\n            'authenticated_as': auth.authenticated_as,\n            'full_name': auth.full_name,\n            'authoritative_source': auth.authoritative_source,\n            'description': 'Added ASN %s with attr: %s' % (attr['asn'], unicode(attr))\n        }\n\n        sql, params = self._sql_expand_insert(audit_params)\n        self._execute('INSERT INTO ip_net_log %s' % sql, params)\n\n        return asn"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef edit_asn(self, auth, asn, attr):\n\n        self._logger.debug(\"edit_asn called; asn: %s attr: %s\" %\n                (unicode(asn), unicode(attr)))\n\n        # sanity check - do we have all attributes?\n        req_attr = [ ]\n        allowed_attr = [ 'name', ]\n        self._check_attr(attr, req_attr, allowed_attr)\n\n        asns = self.list_asn(auth, asn)\n\n        where, params1 = self._expand_asn_spec(asn)\n        update, params2 = self._sql_expand_update(attr)\n        params = dict(params2.items() + params1.items())\n\n        sql = \"UPDATE ip_net_asn SET \" + update + \" WHERE \" + where\n        sql += \" RETURNING *\"\n\n        self._execute(sql, params)\n        updated_asns = []\n        for row in self._curs_pg:\n            updated_asns.append(dict(row))\n\n        # write to audit table\n        for a in asns:\n            audit_params = {\n                'username': auth.username,\n                'authenticated_as': auth.authenticated_as,\n                'full_name': auth.full_name,\n                'authoritative_source': auth.authoritative_source\n            }\n            audit_params['description'] = 'Edited ASN %s attr: %s' % (unicode(a['asn']), unicode(attr))\n\n            sql, params = self._sql_expand_insert(audit_params)\n            self._execute('INSERT INTO ip_net_log %s' % sql, params)\n\n        return updated_asns", "response": "Edit the AS number and attributes of the current AAA."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove_asn(self, auth, asn):\n\n        self._logger.debug(\"remove_asn called; asn: %s\" % unicode(asn))\n\n        # get list of ASNs to remove before removing them\n        asns = self.list_asn(auth, asn)\n\n        # remove\n        where, params = self._expand_asn_spec(asn)\n        sql = \"DELETE FROM ip_net_asn WHERE \" + where\n        self._execute(sql, params)\n\n        # write to audit table\n        for a in asns:\n            audit_params = {\n                'username': auth.username,\n                'authenticated_as': auth.authenticated_as,\n                'full_name': auth.full_name,\n                'authoritative_source': auth.authoritative_source,\n                'description': 'Removed ASN %s' % unicode(a['asn'])\n            }\n            sql, params = self._sql_expand_insert(audit_params)\n            self._execute('INSERT INTO ip_net_log %s' % sql, params)", "response": "Remove an AS number from the cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsearching ASNs for entries matching query.", "response": "def search_asn(self, auth, query, search_options=None):\n        \"\"\" Search ASNs for entries matching 'query'\n\n            * `auth` [BaseAuth]\n                AAA options.\n            * `query` [dict_to_sql]\n                How the search should be performed.\n            * `search_options` [options_dict]\n                Search options, see below.\n\n            Returns a list of dicts.\n\n            The `query` argument passed to this function is designed to be\n            able to specify how quite advanced search operations should be\n            performed in a generic format. It is internally expanded to a SQL\n            WHERE-clause.\n\n            The `query` is a dict with three elements, where one specifies the\n            operation to perform and the two other specifies its arguments. The\n            arguments can themselves be `query` dicts, to build more complex\n            queries.\n\n            The :attr:`operator` key specifies what operator should be used for the\n            comparison. Currently the following operators are supported:\n\n            * :data:`and` - Logical AND\n            * :data:`or` - Logical OR\n            * :data:`equals` - Equality; =\n            * :data:`not_equals` - Inequality; !=\n            * :data:`like` - SQL LIKE\n            * :data:`regex_match` - Regular expression match\n            * :data:`regex_not_match` - Regular expression not match\n\n            The :attr:`val1` and :attr:`val2` keys specifies the values which are subjected\n            to the comparison. :attr:`val1` can be either any prefix attribute or an\n            entire query dict. :attr:`val2` can be either the value you want to\n            compare the prefix attribute to, or an entire `query` dict.\n\n            The search options can also be used to limit the number of rows\n            returned or set an offset for the result.\n\n            The following options are available:\n                * :attr:`max_result` - The maximum number of prefixes to return (default :data:`50`).\n                * :attr:`offset` - Offset the result list this many prefixes (default :data:`0`).\n\n            This is the documentation of the internal backend function. It's\n            exposed over XML-RPC, please also see the XML-RPC documentation for\n            :py:func:`nipap.xmlrpc.NipapXMLRPC.search_tag` for full\n            understanding.\n        \"\"\"\n\n        if search_options is None:\n            search_options = {}\n\n        #\n        # sanitize search options and set default if option missing\n        #\n\n        # max_result\n        if 'max_result' not in search_options:\n            search_options['max_result'] = 50\n        else:\n            try:\n                search_options['max_result'] = int(search_options['max_result'])\n            except (ValueError, TypeError):\n                raise NipapValueError('Invalid value for option' +\n                    ''' 'max_result'. Only integer values allowed.''')\n\n        # offset\n        if 'offset' not in search_options:\n            search_options['offset'] = 0\n        else:\n            try:\n                search_options['offset'] = int(search_options['offset'])\n            except (ValueError, TypeError):\n                raise NipapValueError('Invalid value for option' +\n                    ''' 'offset'. Only integer values allowed.''')\n\n        self._logger.debug('search_asn search_options: %s' % unicode(search_options))\n\n        opt = None\n        sql = \"\"\" SELECT * FROM ip_net_asn \"\"\"\n\n        # add where clause if we have any search terms\n        if query != {}:\n\n            where, opt = self._expand_asn_query(query)\n            sql += \" WHERE \" + where\n\n        sql += \" ORDER BY asn LIMIT \" + unicode(search_options['max_result'])\n        self._execute(sql, opt)\n\n        result = list()\n        for row in self._curs_pg:\n            result.append(dict(row))\n\n        return { 'search_options': search_options, 'result': result }"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nperforms a smart search of the ASN attribute of the current AAA.", "response": "def smart_search_asn(self, auth, query_str, search_options=None, extra_query=None):\n        \"\"\" Perform a smart search operation among AS numbers\n\n            * `auth` [BaseAuth]\n                AAA options.\n            * `query_str` [string]\n                Search string\n            * `search_options` [options_dict]\n                Search options. See :func:`search_asn`.\n            * `extra_query` [dict_to_sql]\n                Extra search terms, will be AND:ed together with what is\n                extracted from the query string.\n\n            Return a dict with three elements:\n                * :attr:`interpretation` - How the query string was interpreted.\n                * :attr:`search_options` - Various search_options.\n                * :attr:`result` - The search result.\n\n                The :attr:`interpretation` is given as a list of dicts, each\n                explaining how a part of the search key was interpreted (ie. what\n                ASN attribute the search operation was performed on).\n\n                The :attr:`result` is a list of dicts containing the search result.\n\n            The smart search function tries to convert the query from a text\n            string to a `query` dict which is passed to the\n            :func:`search_asn` function.  If multiple search keys are\n            detected, they are combined with a logical AND.\n\n            See the :func:`search_asn` function for an explanation of the\n            `search_options` argument.\n\n            This is the documentation of the internal backend function. It's\n            exposed over XML-RPC, please also see the XML-RPC documentation for\n            :py:func:`nipap.xmlrpc.NipapXMLRPC.smart_search_asn` for full\n            understanding.\n        \"\"\"\n\n        if search_options is None:\n            search_options = {}\n\n        self._logger.debug(\"smart_search_asn called; query_str: %s\" % query_str)\n\n        success, query = self._parse_asn_query(query_str)\n        if not success:\n            return {\n                    'interpretation': query,\n                    'search_options': search_options,\n                    'result': [],\n                    'error': True,\n                    'error_message': 'query interpretaion failed'\n            }\n\n        if extra_query is not None:\n            query = {\n                'operator': 'and',\n                'val1': query,\n                'val2': extra_query\n            }\n\n        self._logger.debug(\"smart_search_asn; query expanded to: %s\" % unicode(query))\n\n        search_result = self.search_asn(auth, query, search_options)\n        search_result['interpretation'] = query\n        search_result['error'] = False\n\n        return search_result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses a smart search query for ASNs", "response": "def _parse_asn_query(self, query_str):\n        \"\"\" Parse a smart search query for ASNs\n\n            This is a helper function to smart_search_asn for easier unit\n            testing of the parser.\n        \"\"\"\n        # find query parts\n        query_str_parts = self._get_query_parts(query_str)\n\n        # go through parts and add to query_parts list\n        query_parts = list()\n        for query_str_part in query_str_parts:\n\n            is_int = True\n            try:\n                int(query_str_part['string'])\n            except ValueError:\n                is_int = False\n\n            if is_int:\n                self._logger.debug(\"Query part '\" + query_str_part['string'] + \"' interpreted as integer (ASN)\")\n                query_parts.append({\n                    'interpretation': {\n                        'string': query_str_part['string'],\n                        'interpretation': 'asn',\n                        'attribute': 'asn',\n                        'operator': 'equals',\n                    },\n                    'operator': 'equals',\n                    'val1': 'asn',\n                    'val2': query_str_part['string']\n                })\n\n            else:\n                self._logger.debug(\"Query part '\" + query_str_part['string'] + \"' interpreted as text\")\n                query_parts.append({\n                    'interpretation': {\n                        'string': query_str_part['string'],\n                        'interpretation': 'text',\n                        'attribute': 'name',\n                        'operator': 'regex',\n                    },\n                    'operator': 'regex_match',\n                    'val1': 'name',\n                    'val2': query_str_part['string']\n                })\n\n        # Sum all query parts to one query\n        query = {}\n        if len(query_parts) > 0:\n            query = query_parts[0]\n\n        if len(query_parts) > 1:\n            for query_part in query_parts[1:]:\n                query = {\n                    'interpretation': {\n                        'interpretation': 'and',\n                        'operator': 'and',\n                    },\n                    'operator': 'and',\n                    'val1': query_part,\n                    'val2': query\n                }\n\n        return True, query"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _expand_tag_query(self, query, table_name = None):\n\n        where = unicode()\n        opt = list()\n\n        # handle table name, can be None\n        if table_name is None:\n            col_prefix = \"\"\n        else:\n            col_prefix = table_name + \".\"\n\n        if type(query['val1']) == dict and type(query['val2']) == dict:\n            # Sub expression, recurse! This is used for boolean operators: AND OR\n            # add parantheses\n\n            sub_where1, opt1 = self._expand_tag_query(query['val1'], table_name)\n            sub_where2, opt2 = self._expand_tag_query(query['val2'], table_name)\n            try:\n                where += unicode(\" (%s %s %s) \" % (sub_where1, _operation_map[query['operator']], sub_where2) )\n            except KeyError:\n                raise NipapNoSuchOperatorError(\"No such operator %s\" % unicode(query['operator']))\n\n            opt += opt1\n            opt += opt2\n\n        else:\n\n            # TODO: raise exception if someone passes one dict and one \"something else\"?\n\n            # val1 is variable, val2 is string.\n            tag_attr = dict()\n            tag_attr['name'] = 'name'\n\n            if query['val1'] not in tag_attr:\n                raise NipapInputError('Search variable \\'%s\\' unknown' % unicode(query['val1']))\n\n            # workaround for handling equal matches of NULL-values\n            if query['operator'] == 'equals' and query['val2'] is None:\n                query['operator'] = 'is'\n            elif query['operator'] == 'not_equals' and query['val2'] is None:\n                query['operator'] = 'is_not'\n\n            # build where clause\n            if query['operator'] not in _operation_map:\n                raise NipapNoSuchOperatorError(\"No such operator %s\" % query['operator'])\n\n            where = unicode(\" %s%s %s %%s \" %\n                ( col_prefix, tag_attr[query['val1']],\n                _operation_map[query['operator']] )\n            )\n\n            opt.append(query['val2'])\n\n        return where, opt", "response": "Expand a query dict into a WHERE - clause."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate configure and return the routes Mapper", "response": "def make_map(config):\n    \"\"\"Create, configure and return the routes Mapper\"\"\"\n    map = Mapper(directory=config['pylons.paths']['controllers'],\n                 always_scan=config['debug'])\n    map.minimization = False\n    map.explicit = False\n\n    # The ErrorController route (handles 404/500 error pages); it should\n    # likely stay at the top, ensuring it can always be resolved\n    map.connect('/error/{action}', controller='error')\n    map.connect('/error/{action}/{id}', controller='error')\n\n    # CUSTOM ROUTES HERE\n    map.connect('/{controller}')\n    map.connect('/{controller}/{action}')\n    map.connect('/{controller}/{action}/{id}')\n\n    map.connect('/', controller='prefix', action='index')\n\n    return map"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setup_connection():\n\n    # get connection parameters, first from environment variables if they are\n    # defined, otherwise from .nipaprc\n    try:\n        con_params = {\n            'username': os.getenv('NIPAP_USERNAME') or cfg.get('global', 'username'),\n            'password': os.getenv('NIPAP_PASSWORD') or cfg.get('global', 'password'),\n            'hostname': os.getenv('NIPAP_HOST') or cfg.get('global', 'hostname'),\n            'port'    : os.getenv('NIPAP_PORT') or cfg.get('global', 'port')\n        }\n    except (configparser.NoOptionError, configparser.NoSectionError) as exc:\n        print(\"ERROR:\", str(exc), file=sys.stderr)\n        print(\"HINT: Please define the username, password, hostname and port in your .nipaprc under the section 'global' or provide them through the environment variables NIPAP_HOST, NIPAP_PORT, NIPAP_USERNAME and NIPAP_PASSWORD.\", file=sys.stderr)\n        sys.exit(1)\n\n    # if we haven't got a password (from env var or config) we interactively\n    # prompt for one\n    if con_params['password'] is None:\n        import getpass\n        con_params['password'] = getpass.getpass()\n\n    # build XML-RPC URI\n    pynipap.xmlrpc_uri = \"http://%(username)s:%(password)s@%(hostname)s:%(port)s\" % con_params\n\n    ao = pynipap.AuthOptions({\n        'authoritative_source': 'nipap',\n        'username': os.getenv('NIPAP_IMPERSONATE_USERNAME') or con_params['username'],\n        'full_name': os.getenv('NIPAP_IMPERSONATE_FULL_NAME'),\n        })", "response": "Setup the global pynipap connection object for one item from the global config file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_pool(arg = None, opts = None, abort = False):\n    # yep, global variables are evil\n    global pool\n\n    try:\n        pool = Pool.list({ 'name': arg })[0]\n    except IndexError:\n        if abort:\n            print(\"Pool '%s' not found.\" % str(arg), file=sys.stderr)\n            sys.exit(1)\n        else:\n            pool = None\n\n    return pool", "response": "Returns a pynipap. Pool object representing the pool we are working with."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a pynipap. VRF object representing the VRF we are working in. If there is no VRF set return this. If there is no VRF set return the default_vrf_rt.", "response": "def get_vrf(arg = None, default_var = 'default_vrf_rt', abort = False):\n    \"\"\" Returns VRF to work in\n\n        Returns a pynipap.VRF object representing the VRF we are working\n        in. If there is a VRF set globally, return this. If not, fetch the\n        VRF named 'arg'. If 'arg' is None, fetch the default_vrf\n        attribute from the config file and return this VRF.\n    \"\"\"\n\n    # yep, global variables are evil\n    global vrf\n\n    # if there is a VRF set, return it\n    if vrf is not None:\n        return vrf\n\n    if arg is None:\n        # fetch default vrf\n        try:\n            vrf_rt = cfg.get('global', default_var)\n        except configparser.NoOptionError:\n            # default to all VRFs\n            vrf_rt = 'all'\n    else:\n        vrf_rt = arg\n\n    if vrf_rt.lower() == 'all':\n        vrf = VRF()\n        vrf.rt = 'all'\n    else:\n        if vrf_rt.lower() in ('-', 'none'):\n            vrf_rt = None\n\n        try:\n            vrf = VRF.search({ 'val1': 'rt',\n                'operator': 'equals',\n                'val2': vrf_rt\n                })['result'][0]\n        except (KeyError, IndexError):\n            if abort:\n                print(\"VRF with [RT: %s] not found.\" % str(vrf_rt), file=sys.stderr)\n                sys.exit(1)\n            else:\n                vrf = False\n\n    return vrf"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_pool(arg, opts, shell_opts):\n\n    search_string = ''\n    if type(arg) == list or type(arg) == tuple:\n        search_string = ' '.join(arg)\n\n    v = get_vrf(opts.get('vrf_rt'), default_var='default_list_vrf_rt', abort=True)\n\n    if v.rt == 'all':\n        vrf_q = None\n    else:\n        vrf_q = {\n            'operator': 'equals',\n            'val1': 'vrf_rt',\n            'val2': v.rt\n        }\n\n    offset = 0\n    limit = 100\n    while True:\n        res = Pool.smart_search(search_string, { 'offset': offset, 'max_result': limit }, vrf_q)\n        if offset == 0: # first time in loop?\n            if shell_opts.show_interpretation:\n                print(\"Query interpretation:\")\n                _parse_interp_pool(res['interpretation'])\n\n            if res['error']:\n                print(\"Query failed: %s\" % res['error_message'])\n                return\n\n            if len(res['result']) == 0:\n                print(\"No matching pools found\")\n                return\n\n            print(\"%-19s %-2s %-39s %-13s  %-8s %s\" % (\n                \"Name\", \"#\", \"Description\", \"Default type\", \"4 / 6\", \"Implied VRF\"\n                ))\n            print(\"------------------------------------------------------------------------------------------------\")\n\n        for p in res['result']:\n            if len(str(p.description)) > 38:\n                desc = p.description[0:34] + \"...\"\n            else:\n                desc = p.description\n\n            vrf_rt = '-'\n            vrf_name = '-'\n            if p.vrf is not None:\n                vrf_rt = p.vrf.rt or '-'\n                vrf_name = p.vrf.name\n\n            tags = '-'\n            if len(p.tags) > 0:\n                tags = \"#%d\" % (len(p.tags))\n\n            print(\"%-19s %-2s %-39s %-13s %-2s / %-3s  [RT: %s] %s\" % (\n                p.name, tags, desc, p.default_type,\n                str(p.ipv4_default_prefix_length or '-'),\n                str(p.ipv6_default_prefix_length or '-'),\n                vrf_rt, vrf_name\n            ))\n        if len(res['result']) < limit:\n            break\n        offset += limit", "response": "List all pools matching a search criteria"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlists VRFs matching a search criteria", "response": "def list_vrf(arg, opts, shell_opts):\n    \"\"\" List VRFs matching a search criteria\n    \"\"\"\n\n    search_string = ''\n    if type(arg) == list or type(arg) == tuple:\n        search_string = ' '.join(arg)\n\n    offset = 0\n    limit = 100\n    while True:\n        res = VRF.smart_search(search_string, { 'offset': offset, 'max_result': limit })\n        if offset == 0:\n            if shell_opts.show_interpretation:\n                print(\"Query interpretation:\")\n                _parse_interp_vrf(res['interpretation'])\n\n            if res['error']:\n                print(\"Query failed: %s\" % res['error_message'])\n                return\n\n            if len(res['result']) == 0:\n                print(\"No VRFs matching '%s' found.\" % search_string)\n                return\n\n            print(\"%-16s %-22s %-2s %-40s\" % (\"VRF RT\", \"Name\", \"#\", \"Description\"))\n            print(\"--------------------------------------------------------------------------------\")\n\n        for v in res['result']:\n            tags = '-'\n            if len(v.tags) > 0:\n                tags = '#%d' % len(v.tags)\n            if len(str(v.description)) > 100:\n                desc = v.description[0:97] + \"...\"\n            else:\n                desc = v.description\n            print(\"%-16s %-22s %-2s %-40s\" % (v.rt or '-', v.name, tags, desc))\n\n        if len(res['result']) < limit:\n            break\n        offset += limit"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_prefix(arg, opts, shell_opts):\n\n    search_string = ''\n    if type(arg) == list or type(arg) == tuple:\n        search_string = ' '.join(arg)\n\n    v = get_vrf(opts.get('vrf_rt'), default_var='default_list_vrf_rt', abort=True)\n\n    if v.rt == 'all':\n        vrf_text = 'any VRF'\n        vrf_q = None\n    else:\n        vrf_text = vrf_format(v)\n        vrf_q = {\n            'operator': 'equals',\n            'val1': 'vrf_rt',\n            'val2': v.rt\n        }\n    print(\"Searching for prefixes in %s...\" % vrf_text)\n\n    col_def = {\n            'added': { 'title': 'Added' },\n            'alarm_priority': { 'title': 'Alarm Prio' },\n            'authoritative_source': { 'title': 'Auth source' },\n            'children': { 'title': 'Children' },\n            'comment': { 'title': 'Comment' },\n            'customer_id': { 'title': 'Customer ID' },\n            'description': { 'title': 'Description' },\n            'expires': { 'title': 'Expires' },\n            'free_addresses': { 'title': 'Free addresses' },\n            'monitor': { 'title': 'Monitor' },\n            'last_modified': { 'title': 'Last mod' },\n            'node': { 'title': 'Node' },\n            'order_id': { 'title': 'Order ID' },\n            'pool_name': { 'title': 'Pool name' },\n            'prefix': { 'title': 'Prefix' },\n            'status': { 'title': 'Status' },\n            'tags': { 'title': '#' },\n            'total_addresses': { 'title': 'Total addresses' },\n            'type': { 'title': '' },\n            'used_addresses': { 'title': 'Used addresses' },\n            'vlan': { 'title': 'VLAN' },\n            'vrf_rt': { 'title': 'VRF RT' },\n            }\n    # default columns\n    columns = [ 'vrf_rt', 'prefix', 'type', 'tags', 'node', 'order_id', 'customer_id', 'description' ]\n\n    # custom columns? prefer shell opts, then look in config file\n    custom_columns = None\n    if shell_opts.columns and len(shell_opts.columns) > 0:\n        custom_columns = shell_opts.columns\n    elif cfg.get('global', 'prefix_list_columns'):\n        custom_columns = cfg.get('global', 'prefix_list_columns')\n\n    # parse custom columns\n    if custom_columns:\n        # Clear out default columns, unless user whishes to append\n        if custom_columns[0] != '+':\n            columns = []\n\n        # read in custom columns\n        for col in list(csv.reader([custom_columns.lstrip('+') or ''], escapechar='\\\\'))[0]:\n            col = col.strip()\n            if col not in col_def:\n                print(\"Invalid column:\", col, file=sys.stderr)\n                sys.exit(1)\n            columns.append(col)\n\n    offset = 0\n    # small initial limit for \"instant\" result\n    limit = 50\n    prefix_str = \"\"\n    while True:\n        res = Prefix.smart_search(search_string, { 'parents_depth': -1,\n            'include_neighbors': True, 'offset': offset, 'max_result': limit },\n            vrf_q)\n\n        if offset == 0: # first time in loop?\n            if shell_opts.show_interpretation:\n                print(\"Query interpretation:\")\n                _parse_interp_prefix(res['interpretation'])\n\n            if res['error']:\n                print(\"Query failed: %s\" % res['error_message'])\n                return\n\n            if len(res['result']) == 0:\n                print(\"No addresses matching '%s' found.\" % search_string)\n                return\n\n            # guess column width by looking at the initial result set\n            for p in res['result']:\n                for colname, col in col_def.items():\n                    val = getattr(p, colname, '')\n                    col['width'] = max(len(colname), col.get('width', 0),\n                                       len(str(val)))\n\n                # special handling of a few columns\n                col_def['vrf_rt']['width'] = max(col_def['vrf_rt'].get('width', 8),\n                                                 len(str(p.vrf.rt)))\n                col_def['prefix']['width'] = max(col_def['prefix'].get('width', 0)-12,\n                                                 p.indent * 2 + len(p.prefix)) + 12\n                try:\n                    col_def['pool_name']['width'] = max(col_def['pool_name'].get('width', 8),\n                                                        len(str(p.pool.name)))\n                except:\n                    pass\n            # override certain column widths\n            col_def['type']['width'] = 1\n            col_def['tags']['width'] = 2\n\n            col_header_data = {}\n            # build prefix formatting string\n            for colname, col in [(k, col_def[k]) for k in columns]:\n                prefix_str += \"{%s:<%d}  \" % (colname, col['width'])\n                col_header_data[colname] = col['title']\n\n            column_header = prefix_str.format(**col_header_data)\n            print(column_header)\n            print(\"\".join(\"=\" for i in range(len(column_header))))\n\n        for p in res['result']:\n            if p.display == False:\n                continue\n\n            col_data = {}\n            try:\n                for colname, col in col_def.items():\n                    col_data[colname] = str(getattr(p, colname, None))\n\n                # overwrite some columns due to special handling\n                col_data['tags'] = '-'\n                if len(p.tags) > 0:\n                    col_data['tags'] = '#%d' % len(p.tags)\n\n                try: \n                    col_data['pool_name'] = p.pool.name\n                except:\n                    pass\n\n                col_data['prefix'] = \"\".join(\"  \" for i in range(p.indent)) + p.display_prefix\n                col_data['type'] = p.type[0].upper()\n                col_data['vrf_rt'] = p.vrf.rt or '-'\n\n                print(prefix_str.format(**col_data))\n\n            except UnicodeEncodeError as e:\n                print(\"\\nCrazy encoding for prefix %s\\n\" % p.prefix, file=sys.stderr)\n\n        if len(res['result']) < limit:\n            break\n        offset += limit\n\n        # let consecutive limit be higher to tax the XML-RPC backend less\n        limit = 200", "response": "List prefixes matching arg"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _prefix_from_opts(opts):\n    p = Prefix()\n    p.prefix = opts.get('prefix')\n    p.type = opts.get('type')\n    p.description = opts.get('description')\n    p.node = opts.get('node')\n    p.country = opts.get('country')\n    p.order_id = opts.get('order_id')\n    p.customer_id = opts.get('customer_id')\n    p.alarm_priority = opts.get('alarm_priority')\n    p.comment = opts.get('comment')\n    p.monitor = _str_to_bool(opts.get('monitor'))\n    p.vlan = opts.get('vlan')\n    p.status = opts.get('status') or 'assigned' # default to assigned\n    p.tags = list(csv.reader([opts.get('tags', '')], escapechar='\\\\'))[0]\n    p.expires = opts.get('expires')\n    return p", "response": "Return a Prefix object based on options passed from command line\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_prefix(arg, opts, shell_opts):\n\n    # sanity checks\n    if 'from-pool' not in opts and 'from-prefix' not in opts and 'prefix' not in opts:\n        print(\"ERROR: 'prefix', 'from-pool' or 'from-prefix' must be specified.\", file=sys.stderr)\n        sys.exit(1)\n\n    if len([opt for opt in opts if opt in ['from-pool', 'from-prefix', 'prefix']]) > 1:\n        print(\"ERROR: Use either assignment 'from-pool', 'from-prefix' or manual mode (using 'prefix')\", file=sys.stderr)\n        sys.exit(1)\n\n    if 'from-pool' in opts:\n        return add_prefix_from_pool(arg, opts)\n\n    args = {}\n    p = _prefix_from_opts(opts)\n    p.vrf = get_vrf(opts.get('vrf_rt'), abort=True)\n\n    for avp in opts.get('extra-attribute', []):\n        try:\n            key, value = avp.split('=', 1)\n        except ValueError:\n            print(\"ERROR: Incorrect extra-attribute: %s. Accepted form: 'key=value'\\n\" % avp, file=sys.stderr)\n            return\n        p.avps[key] = value\n\n    if 'from-prefix' in opts:\n        args['from-prefix'] = [ opts['from-prefix'], ]\n\n    if 'prefix_length' in opts:\n        args['prefix_length'] = int(opts['prefix_length'])\n\n    if 'family' in opts:\n        if opts['family'] == 'ipv4':\n            family = 4\n        elif opts['family'] == 'ipv6':\n            family = 6\n        elif opts['family'] == 'dual-stack':\n            print(\"ERROR: dual-stack mode only valid for from-pool assignments\", file=sys.stderr)\n            sys.exit(1)\n\n        args['family'] = family\n\n    # try to automatically figure out type for new prefix when not\n    # allocating from a pool\n\n    # get a list of prefixes that contain this prefix\n    vrf_id = 0\n    if p.vrf:\n        vrf_id = p.vrf.id\n\n    if 'from-prefix' in args:\n        parent_prefix = args['from-prefix'][0]\n        parent_op = 'equals'\n    else:\n        # If no prefix length is specified it is assumed to be a host and we do\n        # a search for prefixes that contains the specified prefix. The last\n        # entry will be the parent of the new prefix and we can look at it to\n        # determine type.\n        # If prefix length is specified (i.e. CIDR format) we check if prefix\n        # length equals max length in which case we assume a host prefix,\n        # otherwise we search for the network using an equal match and by\n        # zeroing out bits in the host part.\n        if len(opts.get('prefix').split(\"/\")) == 2:\n            ip = IPy.IP(opts.get('prefix').split(\"/\")[0])\n            plen = int(opts.get('prefix').split(\"/\")[1])\n            if ip.version() == 4 and plen == 32 or ip.version() == 6 and plen == 128:\n                parent_prefix = str(ip)\n                parent_op = 'contains'\n            else:\n                parent_prefix = str(IPy.IP(opts.get('prefix'), make_net=True))\n                parent_op = 'equals'\n        else:\n            parent_prefix = opts.get('prefix')\n            parent_op = 'contains'\n\n    auto_type_query = {\n            'val1': {\n                'val1'      : 'prefix',\n                'operator'  : parent_op,\n                'val2'      : parent_prefix\n                },\n            'operator': 'and',\n            'val2': {\n                'val1'      : 'vrf_id',\n                'operator'  : 'equals',\n                'val2'      : vrf_id\n                }\n        }\n    res = Prefix.search(auto_type_query, { })\n\n    # no results, ie the requested prefix is a top level prefix\n    if len(res['result']) == 0:\n        if p.type is None:\n            print(\"ERROR: Type of prefix must be specified ('assignment' or 'reservation').\", file=sys.stderr)\n            sys.exit(1)\n    else:\n        # last prefix in list will be the parent of the new prefix\n        parent = res['result'][-1]\n\n        # if the parent is an assignment, we can assume the new prefix to be\n        # a host and act accordingly\n        if parent.type == 'assignment':\n            # automatically set type\n            if p.type is None:\n                print(\"WARNING: Parent prefix is of type 'assignment'. Automatically setting type 'host' for new prefix.\", file=sys.stderr)\n            elif p.type == 'host':\n                pass\n            else:\n                print(\"WARNING: Parent prefix is of type 'assignment'. Automatically overriding specified type '%s' with type 'host' for new prefix.\" % p.type, file=sys.stderr)\n            p.type = 'host'\n\n            # if it's a manually specified prefix\n            if 'prefix' in opts:\n                # fiddle prefix length to all bits set\n                if parent.family == 4:\n                    p.prefix = p.prefix.split('/')[0] + '/32'\n                else:\n                    p.prefix = p.prefix.split('/')[0] + '/128'\n\n            # for from-prefix, we set prefix_length to host length\n            elif 'from-prefix' in opts:\n                if parent.family == 4:\n                    args['prefix_length'] = 32\n                else:\n                    args['prefix_length'] = 128\n\n    try:\n        p.save(args)\n    except NipapError as exc:\n        print(\"Could not add prefix to NIPAP: %s\" % str(exc), file=sys.stderr)\n        sys.exit(1)\n\n    if p.type == 'host':\n        print(\"Host %s added to %s: %s\" % (p.display_prefix,\n                vrf_format(p.vrf), p.node or p.description))\n    else:\n        print(\"Network %s added to %s: %s\" % (p.display_prefix,\n                vrf_format(p.vrf), p.description))\n\n    if opts.get('add-hosts') is not None:\n        if p.type != 'assignment':\n            print(\"ERROR: Not possible to add hosts to non-assignment\", file=sys.stderr)\n            sys.exit(1)\n\n        for host in opts.get('add-hosts').split(','):\n            h_opts = {\n                    'from-prefix': p.prefix,\n                    'vrf_rt': p.vrf.rt,\n                    'type': 'host',\n                    'node': host\n                    }\n            add_prefix({}, h_opts, {})", "response": "Add a prefix to the NIPAP\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a prefix using from - pool to NIPAP alues", "response": "def add_prefix_from_pool(arg, opts):\n    \"\"\" Add prefix using from-pool to NIPAP\n    \"\"\"\n\n    args = {}\n\n    # sanity checking\n    if 'from-pool' in opts:\n        res = Pool.list({ 'name': opts['from-pool'] })\n        if len(res) == 0:\n            print(\"No pool named '%s' found.\" % opts['from-pool'], file=sys.stderr)\n            sys.exit(1)\n\n        args['from-pool'] = res[0]\n\n    if 'family' not in opts:\n        print(\"ERROR: You have to specify the address family.\", file=sys.stderr)\n        sys.exit(1)\n\n    if opts['family'] == 'ipv4':\n        afis = [4]\n    elif opts['family'] == 'ipv6':\n        afis = [6]\n    elif opts['family'] == 'dual-stack':\n        afis = [4, 6]\n        if 'prefix_length' in opts:\n            print(\"ERROR: 'prefix_length' can not be specified for 'dual-stack' assignment\", file=sys.stderr)\n            sys.exit(1)\n    else:\n        print(\"ERROR: 'family' must be one of: %s\" % \" \".join(valid_families), file=sys.stderr)\n        sys.exit(1)\n\n    if 'prefix_length' in opts:\n        args['prefix_length'] = int(opts['prefix_length'])\n\n    for afi in afis:\n        p = _prefix_from_opts(opts)\n\n        if opts.get('vrf_rt') is None:\n            # if no VRF is specified use the pools implied VRF\n            p.vrf = args['from-pool'].vrf\n        else:\n            # use the specified VRF\n            p.vrf = get_vrf(opts.get('vrf_rt'), abort=True)\n\n        # set type to default type of pool unless already set\n        if p.type is None:\n            if args['from-pool'].default_type is None:\n                print(\"ERROR: Type not specified and no default-type specified for pool: %s\" % opts['from-pool'], file=sys.stderr)\n            p.type = args['from-pool'].default_type\n\n        for avp in opts.get('extra-attribute', []):\n            try:\n                key, value = avp.split('=', 1)\n            except ValueError:\n                print(\"ERROR: Incorrect extra-attribute: %s. Accepted form: 'key=value'\\n\" % avp, file=sys.stderr)\n                return\n            p.avps[key] = value\n\n\n        args['family'] = afi\n\n        try:\n            p.save(args)\n        except NipapError as exc:\n            print(\"Could not add prefix to NIPAP: %s\" % str(exc), file=sys.stderr)\n            sys.exit(1)\n\n        if p.type == 'host':\n            print(\"Host %s added to %s: %s\" % (p.display_prefix,\n                    vrf_format(p.vrf), p.node or p.description))\n        else:\n            print(\"Network %s added to %s: %s\" % (p.display_prefix,\n                    vrf_format(p.vrf), p.description))\n\n        if opts.get('add-hosts') is not None:\n            if p.type != 'assignment':\n                print(\"ERROR: Not possible to add hosts to non-assignment\", file=sys.stderr)\n                sys.exit(1)\n\n            for host in opts.get('add-hosts').split(','):\n                h_opts = {\n                        'from-prefix': p.prefix,\n                        'vrf_rt': p.vrf.rt,\n                        'type': 'host',\n                        'node': host\n                        }\n                add_prefix({}, h_opts, {})"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_vrf(arg, opts, shell_opts):\n\n    v = VRF()\n    v.rt = opts.get('rt')\n    v.name = opts.get('name')\n    v.description = opts.get('description')\n    v.tags = list(csv.reader([opts.get('tags', '')], escapechar='\\\\'))[0]\n\n    for avp in opts.get('extra-attribute', []):\n        try:\n            key, value = avp.split('=', 1)\n        except ValueError:\n            print(\"ERROR: Incorrect extra-attribute: %s. Accepted form: 'key=value'\\n\" % avp, file=sys.stderr)\n            return\n        v.avps[key] = value\n\n    try:\n        v.save()\n    except pynipap.NipapError as exc:\n        print(\"Could not add VRF to NIPAP: %s\" % str(exc), file=sys.stderr)\n        sys.exit(1)\n\n    print(\"Added %s\" % (vrf_format(v)))", "response": "Add VRF to NIPAP"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a pool to NIPAP.", "response": "def add_pool(arg, opts, shell_opts):\n    \"\"\" Add a pool.\n    \"\"\"\n\n    p = Pool()\n    p.name = opts.get('name')\n    p.description = opts.get('description')\n    p.default_type = opts.get('default-type')\n    p.ipv4_default_prefix_length = opts.get('ipv4_default_prefix_length')\n    p.ipv6_default_prefix_length = opts.get('ipv6_default_prefix_length')\n\n    if 'tags' in opts:\n        tags = list(csv.reader([opts.get('tags', '')], escapechar='\\\\'))[0]\n        p.tags = {}\n        for tag_name in tags:\n            tag = Tag()\n            tag.name = tag_name\n            p.tags[tag_name] = tag\n\n    for avp in opts.get('extra-attribute', []):\n        try:\n            key, value = avp.split('=', 1)\n        except ValueError:\n            print(\"ERROR: Incorrect extra-attribute: %s. Accepted form: 'key=value'\\n\" % avp, file=sys.stderr)\n            return\n        p.avps[key] = value\n\n    try:\n        p.save()\n    except pynipap.NipapError as exc:\n        print(\"Could not add pool to NIPAP: %s\" % str(exc), file=sys.stderr)\n        sys.exit(1)\n\n    print(\"Pool '%s' created.\" % (p.name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef view_vrf(arg, opts, shell_opts):\n\n    if arg is None:\n        print(\"ERROR: Please specify the RT of the VRF to view.\", file=sys.stderr)\n        sys.exit(1)\n\n    # interpret as default VRF (ie, RT = None)\n    if arg.lower() in ('-', 'none'):\n        arg = None\n\n    try:\n        v = VRF.search({\n            'val1': 'rt',\n            'operator': 'equals',\n            'val2': arg }\n            )['result'][0]\n    except (KeyError, IndexError):\n        print(\"VRF with [RT: %s] not found.\" % str(arg), file=sys.stderr)\n        sys.exit(1)\n\n    print(\"-- VRF\")\n    print(\"  %-26s : %d\" % (\"ID\", v.id))\n    print(\"  %-26s : %s\" % (\"RT\", v.rt))\n    print(\"  %-26s : %s\" % (\"Name\", v.name))\n    print(\"  %-26s : %s\" % (\"Description\", v.description))\n\n    print(\"-- Extra Attributes\")\n    if v.avps is not None:\n        for key in sorted(v.avps, key=lambda s: s.lower()):\n            print(\"  %-26s : %s\" % (key, v.avps[key]))\n\n    print(\"-- Tags\")\n    for tag_name in sorted(v.tags, key=lambda s: s.lower()):\n        print(\"  %s\" % tag_name)\n    # statistics\n    if v.total_addresses_v4 == 0:\n        used_percent_v4 = 0\n    else:\n        used_percent_v4 = (float(v.used_addresses_v4)/v.total_addresses_v4)*100\n    if v.total_addresses_v6 == 0:\n        used_percent_v6 = 0\n    else:\n        used_percent_v6 = (float(v.used_addresses_v6)/v.total_addresses_v6)*100\n    print(\"-- Statistics\")\n    print(\"  %-26s : %s\" % (\"IPv4 prefixes\", v.num_prefixes_v4))\n    print(\"  %-26s : %.0f / %.0f (%.2f%% of %.0f)\" % (\"IPv4 addresses Used / Free\",\n            v.used_addresses_v4, v.free_addresses_v4, used_percent_v4,\n            v.total_addresses_v4))\n    print(\"  %-26s : %s\" % (\"IPv6 prefixes\", v.num_prefixes_v6))\n    print(\"  %-26s : %.4e / %.4e (%.2f%% of %.4e)\" % (\"IPv6 addresses Used / Free\",\n            v.used_addresses_v6, v.free_addresses_v6, used_percent_v6,\n            v.total_addresses_v6))", "response": "View a single VRF in a single process."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nviews a single pool in a new language.", "response": "def view_pool(arg, opts, shell_opts):\n    \"\"\" View a single pool\n    \"\"\"\n\n    res = Pool.list({ 'name': arg })\n\n    if len(res) == 0:\n        print(\"No pool with name '%s' found.\" % arg)\n        return\n\n    p = res[0]\n\n    vrf_rt = None\n    vrf_name = None\n    if p.vrf:\n        vrf_rt = p.vrf.rt\n        vrf_name = p.vrf.name\n\n    print(\"-- Pool \")\n    print(\"  %-26s : %d\" % (\"ID\", p.id))\n    print(\"  %-26s : %s\" % (\"Name\", p.name))\n    print(\"  %-26s : %s\" % (\"Description\", p.description))\n    print(\"  %-26s : %s\" % (\"Default type\", p.default_type))\n    print(\"  %-26s : %s / %s\" % (\"Implied VRF RT / name\", vrf_rt, vrf_name))\n    print(\"  %-26s : %s / %s\" % (\"Preflen (v4/v6)\", str(p.ipv4_default_prefix_length), str(p.ipv6_default_prefix_length)))\n\n    print(\"-- Extra Attributes\")\n    if p.avps is not None:\n        for key in sorted(p.avps, key=lambda s: s.lower()):\n            print(\"  %-26s : %s\" % (key, p.avps[key]))\n\n    print(\"-- Tags\")\n    for tag_name in sorted(p.tags, key=lambda s: s.lower()):\n        print(\"  %s\" % tag_name)\n\n    # statistics\n    print(\"-- Statistics\")\n\n    # IPv4 total / used / free prefixes\n    if p.member_prefixes_v4 == 0:\n        print(\"  IPv4 prefixes Used / Free  : N/A (No IPv4 member prefixes)\")\n    elif p.ipv4_default_prefix_length is None:\n        print(\"  IPv4 prefixes Used / Free  : N/A (IPv4 default prefix length is not set)\")\n    else:\n        if p.total_prefixes_v4 == 0:\n            used_percent_v4 = 0\n        else:\n            used_percent_v4 = (float(p.used_prefixes_v4)/p.total_prefixes_v4)*100\n\n        print(\"  %-26s : %.0f / %.0f (%.2f%% of %.0f)\" % (\"IPv4 prefixes Used / Free\",\n                p.used_prefixes_v4, p.free_prefixes_v4, used_percent_v4,\n                p.total_prefixes_v4))\n\n    # IPv6 total / used / free prefixes\n    if p.member_prefixes_v6 == 0:\n        print(\"  IPv6 prefixes Used / Free  : N/A (No IPv6 member prefixes)\")\n    elif p.ipv6_default_prefix_length is None:\n        print(\"  IPv6 prefixes Used / Free  : N/A (IPv6 default prefix length is not set)\")\n    else:\n        if p.total_prefixes_v6 == 0:\n            used_percent_v6 = 0\n        else:\n            used_percent_v6 = (float(p.used_prefixes_v6)/p.total_prefixes_v6)*100\n        print(\"  %-26s : %.4e / %.4e (%.2f%% of %.4e)\" % (\"IPv6 prefixes Used / Free\",\n                p.used_prefixes_v6, p.free_prefixes_v6, used_percent_v6,\n                p.total_prefixes_v6))\n\n\n    # IPv4 total / used / free addresses\n    if p.member_prefixes_v4 == 0:\n        print(\"  IPv4 addresses Used / Free  : N/A (No IPv4 member prefixes)\")\n    elif p.ipv4_default_prefix_length is None:\n        print(\"  IPv4 addresses Used / Free  : N/A (IPv4 default prefix length is not set)\")\n    else:\n        if p.total_addresses_v4 == 0:\n            used_percent_v4 = 0\n        else:\n            used_percent_v4 = (float(p.used_addresses_v4)/p.total_addresses_v4)*100\n\n        print(\"  %-26s : %.0f / %.0f (%.2f%% of %.0f)\" % (\"IPv4 addresses Used / Free\",\n                p.used_addresses_v4, p.free_addresses_v4, used_percent_v4,\n                p.total_addresses_v4))\n\n    # IPv6 total / used / free addresses\n    if p.member_prefixes_v6 == 0:\n        print(\"  IPv6 addresses Used / Free  : N/A (No IPv6 member prefixes)\")\n    elif p.ipv6_default_prefix_length is None:\n        print(\"  IPv6 addresses Used / Free  : N/A (IPv6 default prefix length is not set)\")\n    else:\n        if p.total_addresses_v6 == 0:\n            used_percent_v6 = 0\n        else:\n            used_percent_v6 = (float(p.used_addresses_v6)/p.total_addresses_v6)*100\n        print(\"  %-26s : %.4e / %.4e (%.2f%% of %.4e)\" % (\"IPv6 addresses Used / Free\",\n                p.used_addresses_v6, p.free_addresses_v6, used_percent_v6,\n                p.total_addresses_v6))\n\n    print(\"\\n-- Prefixes in pool - v4: %d  v6: %d\" % (p.member_prefixes_v4,\n            p.member_prefixes_v6))\n\n    res = Prefix.list({ 'pool_id': p.id})\n    for pref in res:\n        print(\"  %s\" % pref.display_prefix)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef view_prefix(arg, opts, shell_opts):\n    # Internally, this function searches in the prefix column which means that\n    # hosts have a prefix length of 32/128 while they are normally displayed\n    # with the prefix length of the network they are in. To allow the user to\n    # input either, e.g. 1.0.0.1 or 1.0.0.1/31 we strip the prefix length bits\n    # to assume /32 if the address is not a network address. If it is the\n    # network address we always search using the specified mask. In certain\n    # cases there is a host with the network address, typically when /31 or /127\n    # prefix lengths are used, for example 1.0.0.0/31 and 1.0.0.0/32 (first host\n    # in /31 network) in which case it becomes necessary to distinguish between\n    # the two using the mask.\n    try:\n        # this fails if bits are set on right side of mask\n        ip = IPy.IP(arg)\n    except ValueError:\n        arg = arg.split('/')[0]\n\n    q = { 'prefix': arg }\n\n    v = get_vrf(opts.get('vrf_rt'), abort=True)\n    if v.rt != 'all':\n        q['vrf_rt'] = v.rt\n\n    res = Prefix.list(q)\n\n    if len(res) == 0:\n        vrf_text = 'any VRF'\n        if v.rt != 'all':\n            vrf_text = vrf_format(v)\n        print(\"Address %s not found in %s.\" % (arg, vrf_text), file=sys.stderr)\n        sys.exit(1)\n\n    p = res[0]\n    vrf = p.vrf.rt\n\n    print(\"-- Address \")\n    print(\"  %-26s : %s\" % (\"Prefix\", p.prefix))\n    print(\"  %-26s : %s\" % (\"Display prefix\", p.display_prefix))\n    print(\"  %-26s : %s\" % (\"Type\", p.type))\n    print(\"  %-26s : %s\" % (\"Status\", p.status))\n    print(\"  %-26s : IPv%s\" % (\"Family\", p.family))\n    print(\"  %-26s : %s\" % (\"VRF\", vrf))\n    print(\"  %-26s : %s\" % (\"Description\", p.description))\n    print(\"  %-26s : %s\" % (\"Node\", p.node))\n    print(\"  %-26s : %s\" % (\"Country\", p.country))\n    print(\"  %-26s : %s\" % (\"Order\", p.order_id))\n    print(\"  %-26s : %s\" % (\"Customer\", p.customer_id))\n    print(\"  %-26s : %s\" % (\"VLAN\", p.vlan))\n    print(\"  %-26s : %s\" % (\"Alarm priority\", p.alarm_priority))\n    print(\"  %-26s : %s\" % (\"Monitor\", p.monitor))\n    print(\"  %-26s : %s\" % (\"Added\", p.added))\n    print(\"  %-26s : %s\" % (\"Last modified\", p.last_modified))\n    print(\"  %-26s : %s\" % (\"Expires\", p.expires or '-'))\n    if p.family == 4:\n        print(\"  %-26s : %s / %s (%.2f%% of %s)\" % (\"Addresses Used / Free\", p.used_addresses,\n                p.free_addresses, (float(p.used_addresses)/p.total_addresses)*100,\n                p.total_addresses))\n    else:\n        print(\"  %-26s : %.4e / %.4e (%.2f%% of %.4e)\" % (\"Addresses Used / Free\", p.used_addresses,\n                p.free_addresses, (float(p.used_addresses)/p.total_addresses)*100,\n                p.total_addresses))\n    print(\"-- Extra Attributes\")\n    if p.avps is not None:\n        for key in sorted(p.avps, key=lambda s: s.lower()):\n            print(\"  %-26s : %s\" % (key, p.avps[key]))\n    print(\"-- Tags\")\n    for tag_name in sorted(p.tags, key=lambda s: s.lower()):\n        print(\"  %s\" % tag_name)\n    print(\"-- Inherited Tags\")\n    for tag_name in sorted(p.inherited_tags, key=lambda s: s.lower()):\n        print(\"  %s\" % tag_name)\n    print(\"-- Comment\")\n    print(p.comment or '')", "response": "View a single prefix in a single column."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove_vrf(arg, opts, shell_opts):\n\n    remove_confirmed = shell_opts.force\n\n    res = VRF.list({ 'rt': arg })\n    if len(res) < 1:\n        print(\"VRF with [RT: %s] not found.\" % arg, file=sys.stderr)\n        sys.exit(1)\n\n    v = res[0]\n\n    if not remove_confirmed:\n        print(\"RT: %s\\nName: %s\\nDescription: %s\" % (v.rt, v.name, v.description))\n        print(\"\\nWARNING: THIS WILL REMOVE THE VRF INCLUDING ALL ITS ADDRESSES\")\n        res = input(\"Do you really want to remove %s? [y/N]: \" % vrf_format(v))\n\n        if res == 'y':\n            remove_confirmed = True\n        else:\n            print(\"Operation canceled.\")\n\n    if remove_confirmed:\n        v.remove()\n        print(\"%s removed.\" % vrf_format(v))", "response": "Remove VRF with RT arg"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves a prefix from the base NIPAP", "response": "def remove_prefix(arg, opts, shell_opts):\n    \"\"\" Remove prefix\n    \"\"\"\n\n    # set up some basic variables\n    remove_confirmed = shell_opts.force\n    auth_src = set()\n    recursive = False\n\n    if opts.get('recursive') is True:\n        recursive = True\n\n    spec = { 'prefix': arg }\n    v = get_vrf(opts.get('vrf_rt'), abort=True)\n    if v.rt != 'all':\n        spec['vrf_rt'] = v.rt\n\n    res = Prefix.list(spec)\n\n    if len(res) < 1:\n        vrf_text = 'any VRF'\n        if v.rt != 'all':\n            vrf_text = vrf_format(v)\n        print(\"Prefix %s not found in %s.\" % (arg, vrf_text), file=sys.stderr)\n        sys.exit(1)\n\n    p = res[0]\n\n    if p.authoritative_source != 'nipap':\n        auth_src.add(p.authoritative_source)\n\n    if recursive is True or p.type == 'assignment':\n        # recursive delete\n\n        # get affected prefixes\n        query = {\n                'val1': 'prefix',\n                'operator': 'contained_within_equals',\n                'val2': p.prefix\n        }\n\n        # add VRF to query if we have one\n        if 'vrf_rt' in spec:\n            vrf_q = {\n                'val1': 'vrf_rt',\n                'operator': 'equals',\n                'val2': spec['vrf_rt']\n            }\n            query = {\n                'val1': query,\n                'operator': 'and',\n                'val2': vrf_q\n            }\n        pres = Prefix.search(query, { 'parents_depth': 0, 'max_result': 1200 })\n\n    if not remove_confirmed:\n\n        # if recursive is False, this delete will fail, ask user to do recursive\n        # delete instead\n        if p.type == 'assignment':\n            if len(pres['result']) > 1:\n                print(\"WARNING: %s in %s contains %s hosts.\" % (p.prefix, vrf_format(p.vrf), len(pres['result'])))\n                res = input(\"Would you like to recursively delete %s and all hosts? [y/N]: \" % (p.prefix))\n                if res.lower() in [ 'y', 'yes' ]:\n                    recursive = True\n                else:\n                    print(\"ERROR: Removal of assignment containing hosts is prohibited. Aborting removal of %s in %s.\" % (p.prefix, vrf_format(p.vrf)), file=sys.stderr)\n                    sys.exit(1)\n\n        if recursive is True:\n            if len(pres['result']) <= 1:\n                res = input(\"Do you really want to remove the prefix %s in %s? [y/N]: \" % (p.prefix, vrf_format(p.vrf)))\n\n                if res.lower() in [ 'y', 'yes' ]:\n                    remove_confirmed = True\n\n            else:\n                print(\"Recursively deleting %s in %s will delete the following prefixes:\" % (p.prefix, vrf_format(p.vrf)))\n\n                # Iterate prefixes to print a few of them and check the prefixes'\n                # authoritative source\n                i = 0\n                for rp in pres['result']:\n                    if i <= 10:\n                        print(\"%-29s %-2s %-19s %-14s %-14s %-40s\" % (\"\".join(\"  \" for i in\n                            range(rp.indent)) + rp.display_prefix,\n                            rp.type[0].upper(), rp.node, rp.order_id,\n                            rp.customer_id, rp.description))\n\n                    if i == 10:\n                        print(\".. and %s other prefixes\" % (len(pres['result']) - 10))\n\n                    if rp.authoritative_source != 'nipap':\n                        auth_src.add(rp.authoritative_source)\n\n                    i += 1\n\n                if len(auth_src) == 0:\n                    # Simple case; all prefixes were added from NIPAP\n                    res = input(\"Do you really want to recursively remove %s prefixes in %s? [y/N]: \" % (len(pres['result']),\n                                vrf_format(vrf)))\n\n                    if res.lower() in [ 'y', 'yes' ]:\n                        remove_confirmed = True\n\n                else:\n                    # we have prefixes with authoritative source != nipap\n                    auth_src = list(auth_src)\n                    plural = \"\"\n\n                    # format prompt depending on how many different sources we have\n                    if len(auth_src) == 1:\n                        systems = \"'%s'\" % auth_src[0]\n                        prompt = \"Enter the name of the managing system to continue or anything else to abort: \"\n\n                    else:\n                        systems = \", \".join(\"'%s'\" % x for x in auth_src[1:]) + \" and '%s'\" % auth_src[0]\n                        plural = \"s\"\n                        prompt = \"Enter the name of the last managing system to continue or anything else to abort: \"\n\n                    print((\"Prefix %s in %s contains prefixes managed by the system%s %s. \" +\n                        \"Are you sure you want to remove them? \") % (p.prefix,\n                                vrf_format(p.vrf), plural, systems))\n                    res = input(prompt)\n\n                    # Did the user provide the correct answer?\n                    if res.lower() == auth_src[0].lower():\n                        remove_confirmed = True\n                    else:\n                        print(\"System names did not match.\", file=sys.stderr)\n                        sys.exit(1)\n\n        else:\n            # non recursive delete\n            if len(auth_src) > 0:\n                auth_src = list(auth_src)\n                print((\"Prefix %s in %s is managed by the system '%s'. \" +\n                    \"Are you sure you want to remove it? \") % (p.prefix,\n                            vrf_format(p.vrf), auth_src[0]))\n                res = input(\"Enter the name of the managing system to continue or anything else to abort: \")\n\n                if res.lower() == auth_src[0].lower():\n                    remove_confirmed = True\n\n                else:\n                    print(\"System names did not match.\", file=sys.stderr)\n                    sys.exit(1)\n\n            else:\n                res = input(\"Do you really want to remove the prefix %s in %s? [y/N]: \" % (p.prefix, vrf_format(p.vrf)))\n                if res.lower() in [ 'y', 'yes' ]:\n                    remove_confirmed = True\n\n    if remove_confirmed is True:\n        p.remove(recursive = recursive)\n        if recursive is True:\n            print(\"Prefix %s and %s other prefixes in %s removed.\" % (p.prefix,\n                    (len(pres['result']) - 1), vrf_format(p.vrf)))\n        else:\n            print(\"Prefix %s in %s removed.\" % (p.prefix, vrf_format(p.vrf)))\n\n    else:\n        print(\"Operation canceled.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmodifies a VRF with the options set in opts", "response": "def modify_vrf(arg, opts, shell_opts):\n    \"\"\" Modify a VRF with the options set in opts\n    \"\"\"\n\n    res = VRF.list({ 'rt': arg })\n    if len(res) < 1:\n        print(\"VRF with [RT: %s] not found.\" % arg, file=sys.stderr)\n        sys.exit(1)\n\n    v = res[0]\n\n    if 'rt' in opts:\n        v.rt = opts['rt']\n    if 'name' in opts:\n        v.name = opts['name']\n    if 'description' in opts:\n        v.description = opts['description']\n    if 'tags' in opts:\n        tags = list(csv.reader([opts.get('tags', '')], escapechar='\\\\'))[0]\n        v.tags = {}\n        for tag_name in tags:\n            tag = Tag()\n            tag.name = tag_name\n            v.tags[tag_name] = tag\n\n    for avp in opts.get('extra-attribute', []):\n        try:\n            key, value = avp.split('=', 1)\n        except ValueError:\n            print(\"ERROR: Incorrect extra-attribute: %s. Accepted form: 'key=value'\\n\" % avp, file=sys.stderr)\n            return\n        v.avps[key] = value\n\n    v.save()\n\n    print(\"%s saved.\" % vrf_format(v))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmodify a pool with the options set in opts", "response": "def modify_pool(arg, opts, shell_opts):\n    \"\"\" Modify a pool with the options set in opts\n    \"\"\"\n\n    res = Pool.list({ 'name': arg })\n    if len(res) < 1:\n        print(\"No pool with name '%s' found.\" % arg, file=sys.stderr)\n        sys.exit(1)\n\n    p = res[0]\n\n    if 'name' in opts:\n        p.name = opts['name']\n    if 'description' in opts:\n        p.description = opts['description']\n    if 'default-type' in opts:\n        p.default_type = opts['default-type']\n    if 'ipv4_default_prefix_length' in opts:\n        p.ipv4_default_prefix_length = opts['ipv4_default_prefix_length']\n    if 'ipv6_default_prefix_length' in opts:\n        p.ipv6_default_prefix_length = opts['ipv6_default_prefix_length']\n    if 'tags' in opts:\n        tags = list(csv.reader([opts.get('tags', '')], escapechar='\\\\'))[0]\n        p.tags = {}\n        for tag_name in tags:\n            tag = Tag()\n            tag.name = tag_name\n            p.tags[tag_name] = tag\n\n    for avp in opts.get('extra-attribute', []):\n        try:\n            key, value = avp.split('=', 1)\n        except ValueError:\n            print(\"ERROR: Incorrect extra-attribute: %s. Accepted form: 'key=value'\\n\" % avp, file=sys.stderr)\n            return\n        p.avps[key] = value\n\n\n    p.save()\n\n    print(\"Pool '%s' saved.\" % p.name)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef grow_pool(arg, opts, shell_opts):\n    if not pool:\n        print(\"No pool with name '%s' found.\" % arg, file=sys.stderr)\n        sys.exit(1)\n\n    if not 'add' in opts:\n        print(\"Please supply a prefix to add to pool '%s'\" % pool.name, file=sys.stderr)\n        sys.exit(1)\n\n    # Figure out VRF.\n    # If pool already has a member prefix, implied_vrf will be set. Look for new\n    # prefix to add in the same vrf as implied_vrf.\n    # If pool has no members, then use get_vrf() to get vrf to search in for\n    # prefix to add.\n    if pool.vrf is not None:\n        v = pool.vrf\n    else:\n        v = get_vrf(opts.get('vrf_rt'), abort=True)\n\n    q = { 'prefix': opts['add'] }\n    if v.rt != 'all':\n        q['vrf_rt'] = v.rt\n\n    res = Prefix.list(q)\n\n    if len(res) == 0:\n        print(\"No prefix found matching %s in %s.\" % (opts['add'], vrf_format(v)), file=sys.stderr)\n        sys.exit(1)\n    elif res[0].pool:\n        if res[0].pool == pool:\n            print(\"Prefix %s in %s is already assigned to that pool.\" % (opts['add'], vrf_format(v)), file=sys.stderr)\n        else:\n            print(\"Prefix %s in %s is already assigned to a different pool ('%s').\" % (opts['add'], vrf_format(v), res[0].pool.name), file=sys.stderr)\n        sys.exit(1)\n\n    res[0].pool = pool\n    res[0].save()\n    print(\"Prefix %s in %s added to pool '%s'.\" % (res[0].prefix, vrf_format(v), pool.name))", "response": "Expand a pool with the ranges set in opts\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nshrink a pool by removing the ranges in opts from it", "response": "def shrink_pool(arg, opts, shell_opts):\n    \"\"\" Shrink a pool by removing the ranges in opts from it\n    \"\"\"\n    if not pool:\n        print(\"No pool with name '%s' found.\" % arg, file=sys.stderr)\n        sys.exit(1)\n\n    if 'remove' in opts:\n        res = Prefix.list({'prefix': opts['remove'], 'pool_id': pool.id})\n\n        if len(res) == 0:\n            print(\"Pool '%s' does not contain %s.\" % (pool.name,\n                opts['remove']), file=sys.stderr)\n            sys.exit(1)\n\n        res[0].pool = None\n        res[0].save()\n        print(\"Prefix %s removed from pool '%s'.\" % (res[0].prefix, pool.name))\n    else:\n        print(\"Please supply a prefix to add or remove to '%s':\" % (\n            pool.name), file=sys.stderr)\n        for pref in Prefix.list({'pool_id': pool.id}):\n            print(\"  %s\" % pref.prefix)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmodifies the prefix arg with the options opts", "response": "def modify_prefix(arg, opts, shell_opts):\n    \"\"\" Modify the prefix 'arg' with the options 'opts'\n    \"\"\"\n\n    modify_confirmed = shell_opts.force\n\n    spec = { 'prefix': arg }\n    v = get_vrf(opts.get('vrf_rt'), abort=True)\n    spec['vrf_rt'] = v.rt\n\n    res = Prefix.list(spec)\n    if len(res) == 0:\n        print(\"Prefix %s not found in %s.\" % (arg, vrf_format(v)), file=sys.stderr)\n        return\n\n    p = res[0]\n\n    if 'prefix' in opts:\n        p.prefix = opts['prefix']\n    if 'description' in opts:\n        p.description = opts['description']\n    if 'comment' in opts:\n        p.comment = opts['comment']\n    if 'tags' in opts:\n        tags = list(csv.reader([opts.get('tags', '')], escapechar='\\\\'))[0]\n        p.tags = {}\n        for tag_name in tags:\n            tag = Tag()\n            tag.name = tag_name\n            p.tags[tag_name] = tag\n    if 'node' in opts:\n        p.node = opts['node']\n    if 'type' in opts:\n        p.type = opts['type']\n    if 'status' in opts:\n        p.status = opts['status']\n    if 'country' in opts:\n        p.country = opts['country']\n    if 'order_id' in opts:\n        p.order_id = opts['order_id']\n    if 'customer_id' in opts:\n        p.customer_id = opts['customer_id']\n    if 'vlan' in opts:\n        p.vlan = opts['vlan']\n    if 'alarm_priority' in opts:\n        p.alarm_priority = opts['alarm_priority']\n    if 'monitor' in opts:\n        p.monitor = _str_to_bool(opts['monitor'])\n    if 'expires' in opts:\n        p.expires = opts['expires']\n\n    for avp in opts.get('extra-attribute', []):\n        try:\n            key, value = avp.split('=', 1)\n        except ValueError:\n            print(\"ERROR: Incorrect extra-attribute: %s. Accepted form: 'key=value'\\n\" % avp, file=sys.stderr)\n            return\n        p.avps[key] = value\n\n\n    # Promt user if prefix has authoritative source != nipap\n    if not modify_confirmed and p.authoritative_source.lower() != 'nipap':\n\n        res = input(\"Prefix %s in %s is managed by system '%s'. Are you sure you want to modify it? [y/n]: \" %\n            (p.prefix, vrf_format(p.vrf), p.authoritative_source))\n\n        # If the user declines, short-circuit...\n        if res.lower() not in [ 'y', 'yes' ]:\n            print(\"Operation aborted.\")\n            return\n\n    try:\n        p.save()\n    except NipapError as exc:\n        print(\"Could not save prefix changes: %s\" % str(exc), file=sys.stderr)\n        sys.exit(1)\n\n    print(\"Prefix %s in %s saved.\" % (p.display_prefix, vrf_format(p.vrf)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef prefix_attr_add(arg, opts, shell_opts):\n\n    spec = { 'prefix': arg }\n    v = get_vrf(opts.get('vrf_rt'), abort=True)\n    spec['vrf_rt'] = v.rt\n\n    res = Prefix.list(spec)\n    if len(res) == 0:\n        print(\"Prefix %s not found in %s.\" % (arg, vrf_format(v)), file=sys.stderr)\n        return\n\n    p = res[0]\n\n    for avp in opts.get('extra-attribute', []):\n        try:\n            key, value = avp.split('=', 1)\n        except ValueError:\n            print(\"ERROR: Incorrect extra-attribute: %s. Accepted form: 'key=value'\\n\" % avp, file=sys.stderr)\n            sys.exit(1)\n\n        if key in p.avps:\n            print(\"Unable to add extra-attribute: '%s' already exists.\" % key, file=sys.stderr)\n            sys.exit(1)\n\n        p.avps[key] = value\n\n    try:\n        p.save()\n    except NipapError as exc:\n        print(\"Could not save prefix changes: %s\" % str(exc), file=sys.stderr)\n        sys.exit(1)\n\n    print(\"Prefix %s in %s saved.\" % (p.display_prefix, vrf_format(p.vrf)))", "response": "Add attributes to a prefix\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd attributes to a VRF.", "response": "def vrf_attr_add(arg, opts, shell_opts):\n    \"\"\" Add attributes to a VRF\n    \"\"\"\n\n    if arg is None:\n        print(\"ERROR: Please specify the RT of the VRF to view.\", file=sys.stderr)\n        sys.exit(1)\n\n    # interpret as default VRF (ie, RT = None)\n    if arg.lower() in ('-', 'none'):\n        arg = None\n\n    try:\n        v = VRF.search({\n            'val1': 'rt',\n            'operator': 'equals',\n            'val2': arg }\n            )['result'][0]\n    except (KeyError, IndexError):\n        print(\"VRF with [RT: %s] not found.\" % str(arg), file=sys.stderr)\n        sys.exit(1)\n\n    for avp in opts.get('extra-attribute', []):\n        try:\n            key, value = avp.split('=', 1)\n        except ValueError:\n            print(\"ERROR: Incorrect extra-attribute: %s. Accepted form: 'key=value'\\n\" % avp, file=sys.stderr)\n            sys.exit(1)\n\n        if key in v.avps:\n            print(\"Unable to add extra-attribute: '%s' already exists.\" % key, file=sys.stderr)\n            sys.exit(1)\n\n        v.avps[key] = value\n\n    try:\n        v.save()\n    except NipapError as exc:\n        print(\"Could not save VRF changes: %s\" % str(exc), file=sys.stderr)\n        sys.exit(1)\n\n    print(\"%s saved.\" % vrf_format(v))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef vrf_attr_remove(arg, opts, shell_opts):\n\n    if arg is None:\n        print(\"ERROR: Please specify the RT of the VRF to view.\", file=sys.stderr)\n        sys.exit(1)\n\n    # interpret as default VRF (ie, RT = None)\n    if arg.lower() in ('-', 'none'):\n        arg = None\n\n    try:\n        v = VRF.search({\n            'val1': 'rt',\n            'operator': 'equals',\n            'val2': arg }\n            )['result'][0]\n    except (KeyError, IndexError):\n        print(\"VRF with [RT: %s] not found.\" % str(arg), file=sys.stderr)\n        sys.exit(1)\n\n    for key in opts.get('extra-attribute', []):\n        if key not in v.avps:\n            print(\"Unable to remove extra-attribute: '%s' does not exist.\" % key, file=sys.stderr)\n            sys.exit(1)\n\n        del v.avps[key]\n\n    try:\n        v.save()\n    except NipapError as exc:\n        print(\"Could not save VRF changes: %s\" % str(exc), file=sys.stderr)\n        sys.exit(1)\n\n    print(\"%s saved.\" % vrf_format(v))", "response": "Remove attributes from a prefix VRF"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pool_attr_add(arg, opts, shell_opts):\n\n    res = Pool.list({ 'name': arg })\n    if len(res) < 1:\n        print(\"No pool with name '%s' found.\" % arg, file=sys.stderr)\n        sys.exit(1)\n\n    p = res[0]\n\n    for avp in opts.get('extra-attribute', []):\n        try:\n            key, value = avp.split('=', 1)\n        except ValueError:\n            print(\"ERROR: Incorrect extra-attribute: %s. Accepted form: 'key=value'\\n\" % avp, file=sys.stderr)\n            sys.exit(1)\n\n        if key in p.avps:\n            print(\"Unable to add extra-attribute: '%s' already exists.\" % key, file=sys.stderr)\n            sys.exit(1)\n\n        p.avps[key] = value\n\n    try:\n        p.save()\n    except NipapError as exc:\n        print(\"Could not save pool changes: %s\" % str(exc), file=sys.stderr)\n        sys.exit(1)\n\n    print(\"Pool '%s' saved.\" % p.name)", "response": "Add attributes to a pool"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pool_attr_remove(arg, opts, shell_opts):\n\n    res = Pool.list({ 'name': arg })\n    if len(res) < 1:\n        print(\"No pool with name '%s' found.\" % arg, file=sys.stderr)\n        sys.exit(1)\n\n    p = res[0]\n\n    for key in opts.get('extra-attribute', []):\n        if key not in p.avps:\n            print(\"Unable to remove extra-attribute: '%s' does not exist.\" % key, file=sys.stderr)\n            sys.exit(1)\n\n        del p.avps[key]\n\n    try:\n        p.save()\n    except NipapError as exc:\n        print(\"Could not save pool changes: %s\" % str(exc), file=sys.stderr)\n        sys.exit(1)\n\n    print(\"Pool '%s' saved.\" % p.name)", "response": "Remove attributes from a prefix\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _complete_string(key, haystack):\n\n    if len(key) == 0:\n        return haystack\n\n    match = []\n    for straw in haystack:\n        if string.find(straw, key) == 0:\n            match.append(straw)\n    return match", "response": "Returns valid string completions\n        Takes the string key and compares it to each of the strings in haystack."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncompletes NIPAP prefix type", "response": "def complete_tags(arg):\n    \"\"\" Complete NIPAP prefix type\n    \"\"\"\n    search_string = '^'\n    if arg is not None:\n        search_string += arg\n\n    res = Tag.search({\n        'operator': 'regex_match',\n        'val1': 'name',\n        'val2': search_string\n    })\n\n    ret = []\n    for t in res['result']:\n        ret.append(t.name)\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncompleting member prefixes of pool", "response": "def complete_pool_members(arg):\n    \"\"\" Complete member prefixes of pool\n    \"\"\"\n    # pool should already be globally set\n    res = []\n    for member in Prefix.list({ 'pool_id': pool.id }):\n        res.append(member.prefix)\n\n    return _complete_string(arg, res)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef complete_node(arg):\n\n    # get complete command from config\n    try:\n        cmd = cfg.get('global', 'complete_node_cmd')\n    except configparser.NoOptionError:\n        return [ '', ]\n\n    cmd = re.sub('%search_string%', pipes.quote(arg), cmd)\n\n    args = shlex.split(cmd)\n    p = subprocess.Popen(args, stdout=subprocess.PIPE)\n    res, err = p.communicate()\n\n    nodes = res.split('\\n')\n    return nodes", "response": "Complete a node hostname"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn list of matching pool names", "response": "def complete_pool_name(arg):\n    \"\"\" Returns list of matching pool names\n    \"\"\"\n\n    search_string = '^'\n    if arg is not None:\n        search_string += arg\n\n    res = Pool.search({\n        'operator': 'regex_match',\n        'val1': 'name',\n        'val2': search_string\n    })\n\n    ret = []\n    for p in res['result']:\n        ret.append(p.name)\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning list of VRFs that match the given argument", "response": "def complete_vrf(arg):\n    \"\"\" Returns list of matching VRFs\n    \"\"\"\n\n    search_string = ''\n    if arg is not None:\n        search_string = '^%s' % arg\n\n    res = VRF.search({\n        'operator': 'regex_match',\n        'val1': 'rt',\n        'val2':  search_string\n        }, { 'max_result': 100000 } )\n\n    ret = []\n\n    for v in res['result']:\n        ret.append(v.rt)\n    if re.match(search_string, 'none'):\n        ret.append('none')\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef complete_vrf_virtual(arg):\n\n    ret = complete_vrf(arg)\n\n    search_string = ''\n    if arg is not None:\n        search_string = '^%s' % arg\n\n    if re.match(search_string, 'all'):\n        ret.append('all')\n\n    return ret", "response": "Returns list of VRFs that are used in search\n        operations"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _string_to_ast(self, input_string):\n\n        # simple words\n        # we need to use a regex to match on words because the regular\n        # Word(alphanums) will only match on American ASCII alphanums and since\n        # we try to be Unicode / internationally friendly we need to match much\n        # much more. Trying to expand a word class to catch it all seems futile\n        # so we match on everything *except* a few things, like our operators\n        comp_word = Regex(\"[^*\\s=><~!]+\")\n        word = Regex(\"[^*\\s=><~!]+\").setResultsName('word')\n        # numbers\n        comp_number = Word(nums)\n        number = Word(nums).setResultsName('number')\n\n        # IPv4 address\n        ipv4_oct = Regex(\"((2(5[0-5]|[0-4][0-9])|[01]?[0-9][0-9]?))\")\n        comp_ipv4_address = Combine(ipv4_oct + ('.' + ipv4_oct*3))\n        ipv4_address = Combine(ipv4_oct + ('.' + ipv4_oct*3)).setResultsName('ipv4_address')\n\n        # IPv6 address\n        ipv6_address = Regex(\"((([0-9A-Fa-f]{1,4}:){7}([0-9A-Fa-f]{1,4}|:))|(([0-9A-Fa-f]{1,4}:){6}(:[0-9A-Fa-f]{1,4}|((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(\\.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3})|:))|(([0-9A-Fa-f]{1,4}:){5}(((:[0-9A-Fa-f]{1,4}){1,2})|:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(\\.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3})|:))|(([0-9A-Fa-f]{1,4}:){4}(((:[0-9A-Fa-f]{1,4}){1,3})|((:[0-9A-Fa-f]{1,4})?:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(\\.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){3}(((:[0-9A-Fa-f]{1,4}){1,4})|((:[0-9A-Fa-f]{1,4}){0,2}:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(\\.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){2}(((:[0-9A-Fa-f]{1,4}){1,5})|((:[0-9A-Fa-f]{1,4}){0,3}:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(\\.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){1}(((:[0-9A-Fa-f]{1,4}){1,6})|((:[0-9A-Fa-f]{1,4}){0,4}:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(\\.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:))|(:(((:[0-9A-Fa-f]{1,4}){1,7})|((:[0-9A-Fa-f]{1,4}){0,5}:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(\\.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:)))(%.+)?\").setResultsName('ipv6_address')\n        ipv6_prefix = Combine(ipv6_address + Regex(\"/(12[0-8]|1[01][0-9]|[0-9][0-9]?)\")).setResultsName('ipv6_prefix')\n\n        # VRF RTs of the form number:number\n        vrf_rt = Combine((comp_ipv4_address | comp_number) + Literal(':') + comp_number).setResultsName('vrf_rt')\n\n        # tags\n        tags = Combine( Literal('#') + comp_word).setResultsName('tag')\n\n        # operators for matching\n        match_op = oneOf(' '.join(self.match_operators)).setResultsName('operator')\n        boolean_op = oneOf(' '.join(self.boolean_operators)).setResultsName('boolean')\n        # quoted string\n        d_quoted_string = QuotedString('\"', unquoteResults=True, escChar='\\\\')\n        s_quoted_string = QuotedString('\\'', unquoteResults=True, escChar='\\\\')\n        quoted_string = (s_quoted_string | d_quoted_string).setResultsName('quoted_string')\n        # expression to match a certain value for an attribute\n        expression = Group(word + match_op + (quoted_string | vrf_rt | word | number)).setResultsName('expression')\n        # we work on atoms, which are single quoted strings, match expressions,\n        # tags, VRF RT or simple words.\n        # NOTE: Place them in order of most exact match first!\n        atom = Group(ipv6_prefix | ipv6_address | quoted_string | expression | tags | vrf_rt | boolean_op | word)\n\n        enclosed = Forward()\n        parens = nestedExpr('(', ')', content=enclosed)\n        enclosed << (\n                parens | atom\n                ).setResultsName('nested')\n\n        content = Forward()\n        content << (\n                ZeroOrMore(enclosed)\n                )\n\n        res = content.parseString(input_string)\n        return res", "response": "Parse a smart search string and return an AST representation of the string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing a matching expression in form key <op > value", "response": "def _parse_expr(self, part):\n        \"\"\" Parse matching expression in form key <op> value\n\n            For example;\n                vlan > 1\n                node = FOO-BAR\n        \"\"\"\n        self._logger.debug(\"parsing expression: \" + unicode(part))\n        key, op, val = part\n\n        success = True\n        dictsql = {\n                'operator': op,\n                'val1': key,\n                'val2': unicode(val),\n                'interpretation': {\n                    'string': key + op + val,\n                    'interpretation': 'expression',\n                    'attribute': key,\n                    'operator': op,\n                    'error': False\n                }\n            }\n\n        if key in self.attributes:\n            if type(self.attributes[key]) is list:\n                if val not in self.attributes[key]:\n                    dictsql['interpretation']['error'] = True\n                    dictsql['interpretation']['error_message'] = 'invalid value'\n                    success = False\n\n        else:\n            dictsql['interpretation']['error'] = True\n            dictsql['interpretation']['error_message'] = 'unknown attribute'\n            success = False\n\n        return success, dictsql"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a single word or quoted string into a dictionary of values.", "response": "def _string_to_dictsql(self, part):\n        \"\"\" Do magic matching of single words or quoted string\n        \"\"\"\n        self._logger.debug(\"parsing string: \" + unicode(part[0]) + \" of type: \" + part.getName())\n\n        if part.getName() == 'tag':\n            self._logger.debug(\"Query part '\" + part[0] + \"' interpreted as tag\")\n            dictsql = {\n                    'interpretation': {\n                        'string': part[0],\n                        'interpretation': 'tag',\n                        'attribute': 'tag',\n                        'operator': 'equals_any',\n                        'error': False\n                        },\n                    'operator': 'equals_any',\n                    'val1': 'tags',\n                    'val2': part[0][1:]\n                    }\n\n        elif part.getName() == 'vrf_rt':\n            self._logger.debug(\"Query part '\" + part.vrf_rt + \"' interpreted as VRF RT\")\n            # TODO: enable this, our fancy new interpretation\n            dictsql = {\n                    'interpretation': {\n                        'attribute': 'VRF RT',\n                        'interpretation': 'vrf_rt',\n                        'operator': 'equals',\n                        'string': part.vrf_rt,\n                        'error': False\n                        },\n                    'operator': 'equals',\n                    'val1': 'vrf_rt',\n                    'val2': part.vrf_rt\n                    }\n            # using old interpretation for the time being to make sure we align\n            # with old smart search interpreter\n            dictsql = {\n                    'interpretation': {\n                        'attribute': 'name or description',\n                        'interpretation': 'text',\n                        'operator': 'regex',\n                        'string': part.vrf_rt,\n                        'error': False\n                        },\n                    'operator': 'or',\n                    'val1': {\n                        'operator': 'regex_match',\n                        'val1': 'name',\n                        'val2': part.vrf_rt\n                        },\n                    'val2': {\n                        'operator': 'regex_match',\n                        'val1': 'description',\n                        'val2': part.vrf_rt\n                        }\n                    }\n\n        else:\n            self._logger.debug(\"Query part '\" + part[0] + \"' interpreted as text\")\n            dictsql = {\n                    'interpretation': {\n                        'attribute': 'name or description',\n                        'interpretation': 'text',\n                        'operator': 'regex',\n                        'string': part[0],\n                        'error': False\n                        },\n                    'operator': 'or',\n                    'val1': {\n                        'operator': 'regex_match',\n                        'val1': 'name',\n                        'val2': part[0]\n                        },\n                    'val2': {\n                        'operator': 'regex_match',\n                        'val1': 'description',\n                        'val2': part[0]\n                        }\n                    }\n\n        return dictsql"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _string_to_dictsql(self, part):\n        self._logger.debug(\"parsing string: \" + unicode(part[0]) + \" of type: \" + part.getName())\n\n        if part.getName() == 'tag':\n            self._logger.debug(\"Query part '\" + part[0] + \"' interpreted as tag\")\n            dictsql = {\n                    'interpretation': {\n                        'string': part[0],\n                        'interpretation': '(inherited) tag',\n                        'attribute': 'tag',\n                        'operator': 'equals_any',\n                        'error': False\n                    },\n                    'operator': 'or',\n                    'val1': {\n                        'operator': 'equals_any',\n                        'val1': 'tags',\n                        'val2': part[0][1:]\n                    },\n                    'val2': {\n                        'operator': 'equals_any',\n                        'val1': 'inherited_tags',\n                        'val2': part[0][1:]\n                    }\n            }\n\n        elif part.getName() == 'vrf_rt':\n            self._logger.debug(\"Query part '\" + part.vrf_rt + \"' interpreted as VRF RT\")\n            dictsql = {\n                    'interpretation': {\n                        'attribute': 'VRF RT',\n                        'interpretation': 'vrf_rt',\n                        'operator': 'equals',\n                        'string': part.vrf_rt,\n                        'error': False\n                        },\n                    'operator': 'equals',\n                    'val1': 'vrf_rt',\n                    'val2': part.vrf_rt\n                    }\n\n        elif part.getName() == 'ipv6_address':\n            self._logger.debug(\"Query part '\" + part.ipv6_address + \"' interpreted as IPv6 address\")\n            dictsql = {\n                'interpretation': {\n                    'string': part.ipv6_address,\n                    'interpretation': 'IPv6 address',\n                    'attribute': 'prefix',\n                    'operator': 'contains_equals',\n                    'error': False\n                },\n                'operator': 'contains_equals',\n                'val1': 'prefix',\n                'val2': part.ipv6_address\n            }\n\n        elif part.getName() == 'ipv6_prefix':\n            self._logger.debug(\"Query part '\" + part.ipv6_prefix[0] + \"' interpreted as IPv6 prefix\")\n\n            strict_prefix = unicode(IPy.IP(part.ipv6_prefix[0], make_net=True))\n            interp = {\n                    'string': part.ipv6_prefix[0],\n                    'interpretation': 'IPv6 prefix',\n                    'attribute': 'prefix',\n                    'operator': 'contained_within_equals',\n                    'error': False\n                }\n            if part.ipv6_prefix[0] != strict_prefix:\n                interp['strict_prefix'] = strict_prefix\n\n            dictsql = {\n                'interpretation': interp,\n                'operator': 'contained_within_equals',\n                'val1': 'prefix',\n                'val2': strict_prefix\n            }\n\n        else:\n            # since it's difficult to parse shortened IPv4 addresses (like 10/8)\n            # using pyparsing we do a bit of good ol parsing here\n\n            if self._get_afi(part[0]) == 4 and len(part[0].split('/')) == 2:\n                self._logger.debug(\"Query part '\" + part[0] + \"' interpreted as prefix\")\n                address, prefix_length = part[0].split('/')\n\n                # complete a prefix to it's fully expanded form\n                # 10/8 will be expanded into 10.0.0.0/8 which PostgreSQL can\n                # parse correctly\n                while len(address.split('.')) < 4:\n                    address += '.0'\n\n                prefix = address + '/' + prefix_length\n                strict_prefix = unicode(IPy.IP(part[0], make_net=True))\n\n                interp = {\n                        'string': part[0],\n                        'interpretation': 'IPv4 prefix',\n                        'attribute': 'prefix',\n                        'operator': 'contained_within_equals',\n                        'error': False\n                    }\n\n                if prefix != part[0]:\n                    interp['expanded'] = prefix\n\n                if prefix != strict_prefix:\n                    interp['strict_prefix'] = strict_prefix\n\n                dictsql = {\n                    'interpretation': interp,\n                    'operator': 'contained_within_equals',\n                    'val1': 'prefix',\n                    'val2': strict_prefix\n                }\n\n            # IPv4 address\n            # split on dot to make sure we have all four octets before we do a\n            # search\n            elif self._get_afi(part[0]) == 4 and len(part[0].split('.')) == 4:\n                self._logger.debug(\"Query part '\" + part[0] + \"' interpreted as prefix\")\n                address = unicode(IPy.IP(part[0]))\n                dictsql = {\n                    'interpretation': {\n                        'string': address,\n                        'interpretation': 'IPv4 address',\n                        'attribute': 'prefix',\n                        'operator': 'contains_equals',\n                        'error': False\n                    },\n                    'operator': 'contains_equals',\n                    'val1': 'prefix',\n                    'val2': address\n                }\n\n            else:\n                # Description or comment\n                self._logger.debug(\"Query part '\" + part[0] + \"' interpreted as text\")\n                dictsql = {\n                        'interpretation': {\n                            'string': part[0],\n                            'interpretation': 'text',\n                            'attribute': 'description or comment or node or order_id or customer_id',\n                            'operator': 'regex',\n                            'error': False\n                        },\n                        'operator': 'or',\n                        'val1': {\n                            'operator': 'or',\n                            'val1': {\n                                'operator': 'or',\n                                'val1': {\n                                    'operator': 'or',\n                                    'val1': {\n                                        'operator': 'regex_match',\n                                        'val1': 'comment',\n                                        'val2': part[0]\n                                        },\n                                    'val2': {\n                                        'operator': 'regex_match',\n                                        'val1': 'description',\n                                        'val2': part[0]\n                                        }\n                                    },\n                                'val2': {\n                                    'operator': 'regex_match',\n                                    'val1': 'node',\n                                    'val2': part[0]\n                                    }\n                                },\n                            'val2': {\n                                'operator': 'regex_match',\n                                'val1': 'order_id',\n                                'val2': part[0]\n                                },\n                            },\n                        'val2': {\n                            'operator': 'regex_match',\n                            'val1': 'customer_id',\n                            'val2': part[0]\n                            }\n                        }\n\n        return dictsql", "response": "Return a dictionary of the keys and values of a single word or quoted string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _examine_key(self, key_name, key_val, p, i, option_parsing):\n\n        # if the element we reached has an executable registered, save it!\n        if 'exec' in key_val:\n            self.exe = key_val['exec']\n\n        # simple bool options, save value\n        if 'type' in key_val and key_val['type'] == 'bool':\n            self.exe_options[key_name] = True\n\n        # Elements wich takes arguments need special attention\n        if 'argument' in key_val:\n\n            # is there an argument (the next element)?\n            if len(self.inp_cmd) > i+1:\n\n                self.key = { 'argument': key_val['argument'] }\n\n                # there is - save it\n                if key_val['type'] == 'option':\n                    # if argument is of type multiple, store result in a list\n                    if 'multiple' in key_val and key_val['multiple'] == True:\n                        if key_name not in self.exe_options:\n                            self.exe_options[key_name] = []\n                        self.exe_options[key_name].append(self.inp_cmd[i+1])\n                    else:\n                        self.exe_options[key_name] = self.inp_cmd[i+1]\n                else:\n                    self.arg = self.inp_cmd[i+1]\n\n                # Validate the argument if possible\n                if 'validator' in key_val['argument']:\n                    self.key_complete = key_val['argument']['validator'](self.inp_cmd[i+1])\n                else:\n                    self.key_complete = True\n\n                # if there are sub parameters, add them\n                if 'children' in key_val:\n                    self.children = key_val['children']\n\n                # If we reached a command without parameters (which\n                # should be the end of the command), unset the children\n                # dict.\n                elif key_val['type'] == 'command':\n                    self.children = None\n\n                # if the command is finished (there is an element after the argument) and\n                # there is an exec_immediately-function, execute it now\n                if 'exec_immediately' in key_val and len(self.inp_cmd) > i+2:\n                    key_val['exec_immediately'](self.inp_cmd[i+1], self.exe_options)\n                    # clear exe_options as these were options for exec_immediately\n                    self.exe_options = {}\n\n                i += 1\n\n            else:\n                # if there is no next element, let key_complete be true\n                # and set children to the option argument\n                self.children = { 'argument': key_val['argument'] }\n\n            # remove option from further tab completion as it has been filled in,\n            # unless it has the 'multiple' key set, which means it can be filled\n            # in multiple types and will return a list of all values\n            if option_parsing and p == key_name and key_name in self.children:\n                # if multiple, then pass\n                if 'multiple' in self.children[key_name] and self.children[key_name]['multiple'] == True:\n                    pass\n                else:\n                    del self.children[key_name]\n\n\n        # otherwise we are handling a command without arguments\n        else:\n\n            # Rest arguments?\n            if 'rest_argument' in key_val:\n\n                self._scoop_rest_arguments = True\n                self.arg = []\n\n            self.children = key_val.get('children')\n            if self.exe is not None:\n                option_parsing = True\n\n        return i, option_parsing", "response": "Examine the current matching key and extract information from the current matching key."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_cmd(self, tree, inp_cmd = None):\n\n        # reset state from previous execution\n        self.exe = None\n        self.arg = None\n        self.exe_options = {}\n\n        self.children = tree['children']\n        self.key = tree['children']\n        option_parsing = False\n        self._scoop_rest_arguments = False\n\n        if inp_cmd is not None:\n            self.inp_cmd = inp_cmd\n\n        # iterate the list of inputted commands\n        i = 0\n        while i < len(self.inp_cmd):\n            p = self.inp_cmd[i]\n            self.key = {}\n\n            # Find which of the valid commands matches the current element of inp_cmd\n            if self.children is not None:\n                self.key_complete = False\n                match = False\n                for param, content in self.children.items():\n\n                    # match string to command\n                    if param.find(p) == 0:\n                        self.key[param] = content\n                        match = True\n\n                        # If we have an exact match, make sure that\n                        # is the only element in self.key\n                        if p == param and len(self.inp_cmd) > i+1:\n                            self.key_complete = True\n                            self.key = { param: content }\n                            break\n\n                # if we are in scoop-rest-mode, place elements not matching\n                # anything in argument-array\n                if not match:\n                    if self._scoop_rest_arguments:\n                        self.arg.append(p)\n                    else:\n                        raise InvalidCommand(\"Invalid argument: \" + p)\n\n            else:\n                raise InvalidCommand('ran out of parameters; command too long')\n\n            # Note that there are two reasons self.key can contain entries:\n            # 1) The current string (p) contained something and matched a param\n            # 2) The current string (p) is empty and matches all children\n            # If p is empty we don't really have a match but still need to\n            # have data in self.key to show all possible completions at this\n            # level. Therefore, we skip the command matching stuff when\n            # len(p) == 0\n\n            if len(p) != 0 and len(self.key) == 1:\n                key, val = list(self.key.items())[0]\n                i, option_parsing = self._examine_key(key, val, p, i, option_parsing)\n\n            i += 1", "response": "Parse the command and options from the inputted command."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns list of valid completions on the current level in the theCOOKIE tree.", "response": "def complete(self):\n        \"\"\" Return list of valid completions\n\n            Returns a list of valid completions on the current level in the\n            tree. If an element of type 'value' is found, its complete callback\n            function is called (if set).\n        \"\"\"\n\n        comp = []\n        for k, v in self.key.items():\n\n            # if we have reached a value, try to fetch valid completions\n            if v['type'] == 'value':\n                if 'complete' in v:\n                    comp += v['complete'](self.inp_cmd[-1])\n\n            # otherwise, k is our valid completion\n            else:\n                comp.append(k)\n\n        return comp"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning list of valid next values", "response": "def next_values(self):\n        \"\"\" Return list of valid next values\n        \"\"\"\n\n        nval = []\n\n        for k, v in self.children.items():\n\n            # if we have reached a value, try to fetch valid completions\n            if v['type'] == 'value':\n                if 'complete' in v:\n                    nval += v['complete']('')\n\n            # otherwise, k is our valid completion\n            else:\n                nval.append(k)\n\n        return nval"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a new NIPAP to the NIPAP.", "response": "def add(self):\n        \"\"\" Add a pool.\n        \"\"\"\n\n        # Adding to NIPAP\n        if request.method == 'POST':\n            p = Pool()\n            p.name = request.params.get('name')\n            p.description = request.params.get('description')\n            p.default_type = request.params.get('default_type')\n\n            if request.params['ipv4_default_prefix_length'].strip() != '':\n                p.ipv4_default_prefix_length = request.params['ipv4_default_prefix_length']\n\n            if request.params['ipv6_default_prefix_length'].strip() != '':\n                p.ipv6_default_prefix_length = request.params['ipv6_default_prefix_length']\n\n            p.save()\n            redirect(url(controller = 'pool', action = 'list'))\n\n        return render(\"/pool_add.html\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove a specific resource from the pool.", "response": "def remove(self, id):\n        \"\"\" Remove pool.\n        \"\"\"\n\n        p = Pool.get(int(id))\n        p.remove()\n        redirect(url(controller = 'pool', action = 'list'))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove_prefix(self, id):\n\n        if 'prefix' not in request.params:\n            abort(400, 'Missing prefix.')\n        prefix = Prefix.get(int(request.params['prefix']))\n        prefix.pool = None\n        prefix.save()\n\n        redirect(url(controller = 'pool', action = 'edit', id = id))", "response": "Remove a prefix from pool id."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_ip_to_net(networks, host):\n    for network in networks:\n        if host['ipaddr'] in network['network']:\n            network['hosts'].append(host)\n            return", "response": "Add hosts from ipplan to network object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_networks(base_file, ipaddr_file):\n    networks = []\n\n    base = open(base_file, 'r')\n\n    csv_reader = csv.reader(base, delimiter='\\t')\n\n    buffer = \"\"\n    for row in csv_reader:\n\n        # Fixes quotation bug in ipplan exporter for base.txt\n        if len(networks) > 0 and len(buffer) > 0:\n            networks[-1]['comment'] += \" \".join(buffer)\n            buffer = \"\"\n        if len(row) < 3:\n            buffer = row\n        else:\n\n            network = {\n                'network': ipaddress.ip_network(\"{}/{}\".format(row[0], row[2])),\n                'description': row[1],\n                'hosts': [],\n                'comment': \"\"\n            }\n\n            if len(row) > 3:\n                network['additional'] = \" \".join(row[3:])\n\n            networks.append(network)\n\n    base.close()\n\n    ipaddr = open(ipaddr_file, 'r')\n\n    csv_reader = csv.reader(ipaddr, delimiter='\\t')\n    for row in csv_reader:\n\n        host = {\n            'ipaddr': ipaddress.ip_address(row[0]),\n            'user': row[1],\n            'location': row[2],\n            'description': row[3],\n            'fqdn': row[4],\n            'phone': row[5],\n            'mac': row[6]\n        }\n\n        if len(row) > 7:\n            host['additional'] = \" \".join(row[7:])\n\n        add_ip_to_net(networks, host)\n\n    ipaddr.close()\n\n    return networks", "response": "Gather network and host information from ipplan export files."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding your network information to the prefix object.", "response": "def add_prefix(network):\n    \"\"\" Put your network information in the prefix object. \"\"\"\n    p = new_prefix()\n    p.prefix = str(network['network'])\n    p.type = \"assignment\"\n    p.description = network['description']\n    p.tags = ['ipplan-import']\n    p.comment = \"\"\n\n    if 'additional' in network:\n        p.comment += network['additional']\n    if len(network['comment']) > 0:\n        p.comment += network['comment']\n    return p"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds host information to the prefix object.", "response": "def add_host(host):\n    \"\"\" Put your host information in the prefix object. \"\"\"\n    p = new_prefix()\n    p.prefix = str(host['ipaddr'])\n    p.type = \"host\"\n    p.description = host['description']\n    p.node = host['fqdn']\n    p.avps = {}\n\n    # Use remaining data from ipplan to populate comment field.\n    if 'additional' in host:\n        p.comment = host['additional']\n\n    # Use specific info to create extra attributes.\n    if len(host['location']) > 0:\n        p.avps['location'] = host['location']\n\n    if len(host['mac']) > 0:\n        p.avps['mac'] = host['mac']\n\n    if len(host['phone']) > 0:\n        p.avps['phone'] = host['phone']\n\n    if len(host['user']) > 0:\n        p.avps['user'] = host['user']\n\n    return p"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef nipapd_version():\n\n    xmlrpc = XMLRPCConnection()\n    try:\n        return xmlrpc.connection.version(\n            {\n                'auth': AuthOptions().options\n            })\n    except xmlrpclib.Fault as xml_fault:\n        raise _fault_to_exception(xml_fault)", "response": "Get version of nipapd we re connected to."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef nipap_db_version():\n\n    xmlrpc = XMLRPCConnection()\n    try:\n        return xmlrpc.connection.db_version(\n            {\n                'auth': AuthOptions().options\n            })\n    except xmlrpclib.Fault as xml_fault:\n        raise _fault_to_exception(xml_fault)", "response": "Get schema version of database we re connected to."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert an XML - RPC Fault object to a Pynipap - exceptions.", "response": "def _fault_to_exception(f):\n    \"\"\" Converts XML-RPC Fault objects to Pynipap-exceptions.\n\n        TODO: Is this one neccesary? Can be done inline...\n    \"\"\"\n\n    e = _fault_to_exception_map.get(f.faultCode)\n    if e is None:\n        e = NipapError\n    return e(f.faultString)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_dict(cls, tag=None):\n\n        if tag is None:\n            tag = {}\n\n        l = Tag()\n        l.name = tag['name']\n        return l", "response": "Create a Tag object from a dict."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsearch tags. For more information, see the backend function :py:func:`nipap.backend.Nipap.search_tag`.", "response": "def search(cls, query, search_opts=None):\n        \"\"\" Search tags.\n\n            For more information, see the backend function\n            :py:func:`nipap.backend.Nipap.search_tag`.\n        \"\"\"\n\n        if search_opts is None:\n            search_opts = {}\n\n        xmlrpc = XMLRPCConnection()\n        try:\n            search_result = xmlrpc.connection.search_tag(\n                {\n                    'query': query,\n                    'search_options': search_opts,\n                    'auth': AuthOptions().options\n                })\n        except xmlrpclib.Fault as xml_fault:\n            raise _fault_to_exception(xml_fault)\n\n        result = dict()\n        result['result'] = []\n        result['search_options'] = search_result['search_options']\n        for xml_tag in search_result['result']:\n            result['result'].append(Tag.from_dict(xml_tag))\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list(cls, vrf=None):\n\n        if vrf is None:\n            vrf = {}\n\n        xmlrpc = XMLRPCConnection()\n        try:\n            vrf_list = xmlrpc.connection.list_vrf(\n                {\n                    'vrf': vrf,\n                    'auth': AuthOptions().options\n                })\n        except xmlrpclib.Fault as xml_fault:\n            raise _fault_to_exception(xml_fault)\n\n        res = list()\n        for v in vrf_list:\n            res.append(VRF.from_dict(v))\n\n        return res", "response": "List VRFs.\n\n            Maps to the function :py:func:`nipap.backend.Nipap.list_vrf` in the\n            backend. Please see the documentation for the backend function for\n            information regarding input arguments and return values."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a VRF object from a dictionary.", "response": "def from_dict(cls, parm, vrf = None):\n        \"\"\" Create new VRF-object from dict.\n\n            Suitable for creating objects from XML-RPC data.\n            All available keys must exist.\n        \"\"\"\n\n        if vrf is None:\n            vrf = VRF()\n\n        vrf.id = parm['id']\n        vrf.rt = parm['rt']\n        vrf.name = parm['name']\n        vrf.description = parm['description']\n\n        vrf.tags = {}\n        for tag_name in parm['tags']:\n            tag = Tag.from_dict({'name': tag_name })\n            vrf.tags[tag_name] = tag\n        vrf.avps = parm['avps']\n\n        vrf.num_prefixes_v4 = int(parm['num_prefixes_v4'])\n        vrf.num_prefixes_v6 = int(parm['num_prefixes_v6'])\n        vrf.total_addresses_v4 = int(parm['total_addresses_v4'])\n        vrf.total_addresses_v6 = int(parm['total_addresses_v6'])\n        vrf.used_addresses_v4 = int(parm['used_addresses_v4'])\n        vrf.used_addresses_v6 = int(parm['used_addresses_v6'])\n        vrf.free_addresses_v4 = int(parm['free_addresses_v4'])\n        vrf.free_addresses_v6 = int(parm['free_addresses_v6'])\n\n        return vrf"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(cls, id):\n\n        # cached?\n        if CACHE:\n            if id in _cache['VRF']:\n                log.debug('cache hit for VRF %d' % id)\n                return _cache['VRF'][id]\n            log.debug('cache miss for VRF %d' % id)\n\n        try:\n            vrf = VRF.list({ 'id': id })[0]\n        except IndexError:\n            raise NipapNonExistentError('no VRF with ID ' + str(id) + ' found')\n\n        _cache['VRF'][id] = vrf\n        return vrf", "response": "Get the VRF with id id."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsearches VRFs. A query is used to search VRFs in the backend.", "response": "def search(cls, query, search_opts=None):\n        \"\"\" Search VRFs.\n\n            Maps to the function :py:func:`nipap.backend.Nipap.search_vrf` in\n            the backend. Please see the documentation for the backend function\n            for information regarding input arguments and return values.\n        \"\"\"\n\n        if search_opts is None:\n            search_opts = {}\n\n        xmlrpc = XMLRPCConnection()\n        try:\n            search_result = xmlrpc.connection.search_vrf(\n                {\n                    'query': query,\n                    'search_options': search_opts,\n                    'auth': AuthOptions().options\n                })\n        except xmlrpclib.Fault as xml_fault:\n            raise _fault_to_exception(xml_fault)\n        result = dict()\n        result['result'] = []\n        result['search_options'] = search_result['search_options']\n        for v in search_result['result']:\n            result['result'].append(VRF.from_dict(v))\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef smart_search(cls, query_string, search_options=None, extra_query = None):\n\n        if search_options is None:\n            search_options = {}\n\n        xmlrpc = XMLRPCConnection()\n        try:\n            smart_result = xmlrpc.connection.smart_search_vrf(\n                {\n                    'query_string': query_string,\n                    'search_options': search_options,\n                    'auth': AuthOptions().options,\n                    'extra_query': extra_query\n                })\n        except xmlrpclib.Fault as xml_fault:\n            raise _fault_to_exception(xml_fault)\n        result = dict()\n        result['interpretation'] = smart_result['interpretation']\n        result['search_options'] = smart_result['search_options']\n        result['error'] = smart_result['error']\n        if 'error_message' in smart_result:\n            result['error_message'] = smart_result['error_message']\n        result['result'] = list()\n        for v in smart_result['result']:\n            result['result'].append(VRF.from_dict(v))\n\n        return result", "response": "Perform a smart VRF search."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save(self):\n\n        xmlrpc = XMLRPCConnection()\n        data = {\n            'rt': self.rt,\n            'name': self.name,\n            'description': self.description,\n            'tags': [],\n            'avps': self.avps\n        }\n        for tag_name in self.tags:\n            data['tags'].append(tag_name)\n\n        if self.id is None:\n            # New object, create\n            try:\n                vrf = xmlrpc.connection.add_vrf(\n                    {\n                        'attr': data,\n                        'auth': self._auth_opts.options\n                    })\n            except xmlrpclib.Fault as xml_fault:\n                raise _fault_to_exception(xml_fault)\n\n        else:\n            # Old object, edit\n            try:\n                vrfs = xmlrpc.connection.edit_vrf(\n                    {\n                        'vrf': { 'id': self.id },\n                        'attr': data,\n                        'auth': self._auth_opts.options\n                    })\n            except xmlrpclib.Fault as xml_fault:\n                raise _fault_to_exception(xml_fault)\n\n            if len(vrfs) != 1:\n                raise NipapError('VRF edit returned %d entries, should be 1.' % len(vrfs))\n            vrf = vrfs[0]\n\n        # Refresh object data with attributes from add/edit operation\n        VRF.from_dict(vrf, self)\n\n        _cache['VRF'][self.id] = self", "response": "Save the object to NIPAP."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove(self):\n\n        xmlrpc = XMLRPCConnection()\n        try:\n            xmlrpc.connection.remove_vrf(\n                {\n                    'vrf': { 'id': self.id },\n                    'auth': self._auth_opts.options\n                })\n        except xmlrpclib.Fault as xml_fault:\n            raise _fault_to_exception(xml_fault)\n        if self.id in _cache['VRF']:\n            del(_cache['VRF'][self.id])", "response": "Removes the innermost in inn."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsaves the object to NIPAP.", "response": "def save(self):\n        \"\"\" Save changes made to pool to NIPAP.\n\n            If the object represents a new pool unknown to NIPAP (attribute\n            `id` is `None`) this function maps to the function\n            :py:func:`nipap.backend.Nipap.add_pool` in the backend, used to\n            create a new pool. Otherwise it maps to the function\n            :py:func:`nipap.backend.Nipap.edit_pool` in the backend, used to\n            modify the pool. Please see the documentation for the backend\n            functions for information regarding input arguments and return\n            values.\n        \"\"\"\n\n        xmlrpc = XMLRPCConnection()\n        data = {\n            'name': self.name,\n            'description': self.description,\n            'default_type': self.default_type,\n            'ipv4_default_prefix_length': self.ipv4_default_prefix_length,\n            'ipv6_default_prefix_length': self.ipv6_default_prefix_length,\n            'tags': [],\n            'avps': self.avps\n        }\n        for tag_name in self.tags:\n            data['tags'].append(tag_name)\n\n        if self.id is None:\n            # New object, create\n            try:\n                pool = xmlrpc.connection.add_pool(\n                    {\n                        'attr': data,\n                        'auth': self._auth_opts.options\n                    })\n            except xmlrpclib.Fault as xml_fault:\n                raise _fault_to_exception(xml_fault)\n\n        else:\n            # Old object, edit\n            try:\n                pools = xmlrpc.connection.edit_pool(\n                    {\n                        'pool': { 'id': self.id },\n                        'attr': data,\n                        'auth': self._auth_opts.options\n                    })\n            except xmlrpclib.Fault as xml_fault:\n                raise _fault_to_exception(xml_fault)\n\n            if len(pools) != 1:\n                raise NipapError('Pool edit returned %d entries, should be 1.' % len(pools))\n            pool = pools[0]\n\n        # Refresh object data with attributes from add/edit operation\n        Pool.from_dict(pool, self)\n\n        _cache['Pool'][self.id] = self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(cls, id):\n\n        # cached?\n        if CACHE:\n            if id in _cache['Pool']:\n                log.debug('cache hit for pool %d' % id)\n                return _cache['Pool'][id]\n            log.debug('cache miss for pool %d' % id)\n\n        try:\n            pool = Pool.list({'id': id})[0]\n        except (IndexError, KeyError):\n            raise NipapNonExistentError('no pool with ID ' + str(id) + ' found')\n\n        _cache['Pool'][id] = pool\n        return pool", "response": "Get the pool with id id."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef search(cls, query, search_opts=None):\n\n        if search_opts is None:\n            search_opts = {}\n\n        xmlrpc = XMLRPCConnection()\n        try:\n            search_result = xmlrpc.connection.search_pool(\n                {\n                    'query': query,\n                    'search_options': search_opts,\n                    'auth': AuthOptions().options\n                })\n        except xmlrpclib.Fault as xml_fault:\n            raise _fault_to_exception(xml_fault)\n        result = dict()\n        result['result'] = []\n        result['search_options'] = search_result['search_options']\n        for pool in search_result['result']:\n            p = Pool.from_dict(pool)\n            result['result'].append(p)\n\n        return result", "response": "Search pools. Nipap uses the function Nipap. search_pool to search for the infrastructure in the backend."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef smart_search(cls, query_string, search_options=None, extra_query = None):\n\n        if search_options is None:\n            search_options = {}\n\n        xmlrpc = XMLRPCConnection()\n        try:\n            smart_result = xmlrpc.connection.smart_search_pool(\n                {\n                    'query_string': query_string,\n                    'search_options': search_options,\n                    'auth': AuthOptions().options,\n                    'extra_query': extra_query\n                })\n        except xmlrpclib.Fault as xml_fault:\n            raise _fault_to_exception(xml_fault)\n        result = dict()\n        result['interpretation'] = smart_result['interpretation']\n        result['search_options'] = smart_result['search_options']\n        result['error'] = smart_result['error']\n        if 'error_message' in smart_result:\n            result['error_message'] = smart_result['error_message']\n        result['result'] = list()\n        for pool in smart_result['result']:\n            p = Pool.from_dict(pool)\n            result['result'].append(p)\n\n        return result", "response": "Perform a smart search of the NIPAP database."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_dict(cls, parm, pool = None):\n\n        if pool is None:\n            pool = Pool()\n\n        pool.id = parm['id']\n        pool.name = parm['name']\n        pool.description = parm['description']\n        pool.default_type = parm['default_type']\n        pool.ipv4_default_prefix_length = parm['ipv4_default_prefix_length']\n        pool.ipv6_default_prefix_length = parm['ipv6_default_prefix_length']\n        for val in ('member_prefixes_v4', 'member_prefixes_v6',\n                'used_prefixes_v4', 'used_prefixes_v6', 'free_prefixes_v4',\n                'free_prefixes_v6', 'total_prefixes_v4', 'total_prefixes_v6',\n                'total_addresses_v4', 'total_addresses_v6', 'used_addresses_v4',\n                'used_addresses_v6', 'free_addresses_v4', 'free_addresses_v6'):\n            if parm[val] is not None:\n                setattr(pool, val, int(parm[val]))\n\n        pool.tags = {}\n        for tag_name in parm['tags']:\n            tag = Tag.from_dict({'name': tag_name })\n            pool.tags[tag_name] = tag\n\n        pool.avps = parm['avps']\n\n        # store VRF object in pool.vrf\n        if parm['vrf_id'] is not None:\n            pool.vrf = VRF.get(parm['vrf_id'])\n\n        return pool", "response": "Create a new Pool object from a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list(self, spec=None):\n\n        if spec is None:\n            spec = {}\n\n        xmlrpc = XMLRPCConnection()\n        try:\n            pool_list = xmlrpc.connection.list_pool(\n                {\n                    'pool': spec,\n                    'auth': AuthOptions().options\n                })\n        except xmlrpclib.Fault as xml_fault:\n            raise _fault_to_exception(xml_fault)\n        res = list()\n        for pool in pool_list:\n            p = Pool.from_dict(pool)\n            res.append(p)\n\n        return res", "response": "List pools.\n\n            Maps to the function :py:func:`nipap.backend.Nipap.list_pool` in\n            the backend. Please see the documentation for the backend function\n            for information regarding input arguments and return values."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(cls, id):\n\n        # cached?\n        if CACHE:\n            if id in _cache['Prefix']:\n                log.debug('cache hit for prefix %d' % id)\n                return _cache['Prefix'][id]\n            log.debug('cache miss for prefix %d' % id)\n\n        try:\n            prefix = Prefix.list({'id': id})[0]\n        except IndexError:\n            raise NipapNonExistentError('no prefix with ID ' + str(id) + ' found')\n\n        _cache['Prefix'][id] = prefix\n        return prefix", "response": "Get the prefix with id id."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_free(cls, vrf, args):\n\n        xmlrpc = XMLRPCConnection()\n        q = {\n            'args': args,\n            'auth': AuthOptions().options\n        }\n\n        # sanity checks\n        if isinstance(vrf, VRF):\n            q['vrf'] = { 'id': vrf.id }\n        elif vrf is None:\n            q['vrf'] = None\n        else:\n            raise NipapValueError('vrf parameter must be instance of VRF class')\n\n        # run XML-RPC query\n        try:\n            find_res = xmlrpc.connection.find_free_prefix(q)\n        except xmlrpclib.Fault as xml_fault:\n            raise _fault_to_exception(xml_fault)\n        pass\n\n        return find_res", "response": "Find a free prefix in the backend."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef search(cls, query, search_opts=None):\n\n        if search_opts is None:\n            search_opts = {}\n\n        xmlrpc = XMLRPCConnection()\n        try:\n            search_result = xmlrpc.connection.search_prefix(\n                {\n                    'query': query,\n                    'search_options': search_opts,\n                    'auth': AuthOptions().options\n                })\n        except xmlrpclib.Fault as xml_fault:\n            raise _fault_to_exception(xml_fault)\n        result = dict()\n        result['result'] = []\n        result['search_options'] = search_result['search_options']\n        for prefix in search_result['result']:\n            p = Prefix.from_dict(prefix)\n            result['result'].append(p)\n\n        return result", "response": "Search for prefixes.\n\n            Maps to the function :py:func:`nipap.backend.Nipap.search_prefix`\n            in the backend. Please see the documentation for the backend\n            function for information regarding input arguments and return\n            values."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nperform a smart prefix search.", "response": "def smart_search(cls, query_string, search_options=None, extra_query = None):\n        \"\"\" Perform a smart prefix search.\n\n            Maps to the function\n            :py:func:`nipap.backend.Nipap.smart_search_prefix` in the backend.\n            Please see the documentation for the backend function for\n            information regarding input arguments and return values.\n        \"\"\"\n\n        if search_options is None:\n            search_options = {}\n\n        xmlrpc = XMLRPCConnection()\n        try:\n            smart_result = xmlrpc.connection.smart_search_prefix(\n                {\n                    'query_string': query_string,\n                    'search_options': search_options,\n                    'auth': AuthOptions().options,\n                    'extra_query': extra_query\n                })\n        except xmlrpclib.Fault as xml_fault:\n            raise _fault_to_exception(xml_fault)\n        result = dict()\n        result['interpretation'] = smart_result['interpretation']\n        result['search_options'] = smart_result['search_options']\n        result['error'] = smart_result['error']\n        if 'error_message' in smart_result:\n            result['error_message'] = smart_result['error_message']\n        result['result'] = list()\n        for prefix in smart_result['result']:\n            p = Prefix.from_dict(prefix)\n            result['result'].append(p)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list(cls, spec=None):\n\n        if spec is None:\n            spec = {}\n\n        xmlrpc = XMLRPCConnection()\n        try:\n            pref_list = xmlrpc.connection.list_prefix(\n                {\n                    'prefix': spec,\n                    'auth': AuthOptions().options\n                })\n        except xmlrpclib.Fault as xml_fault:\n            raise _fault_to_exception(xml_fault)\n        res = list()\n        for pref in pref_list:\n            p = Prefix.from_dict(pref)\n            res.append(p)\n\n        return res", "response": "List the innermost in n."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsave the object to NIPAP.", "response": "def save(self, args=None):\n        \"\"\" Save prefix to NIPAP.\n\n            If the object represents a new prefix unknown to NIPAP (attribute\n            `id` is `None`) this function maps to the function\n            :py:func:`nipap.backend.Nipap.add_prefix` in the backend, used to\n            create a new prefix. Otherwise it maps to the function\n            :py:func:`nipap.backend.Nipap.edit_prefix` in the backend, used to\n            modify the VRF. Please see the documentation for the backend\n            functions for information regarding input arguments and return\n            values.\n        \"\"\"\n\n        if args is None:\n            args = {}\n\n        xmlrpc = XMLRPCConnection()\n        data = {\n            'description': self.description,\n            'comment': self.comment,\n            'tags': [],\n            'node': self.node,\n            'type': self.type,\n            'country': self.country,\n            'order_id': self.order_id,\n            'customer_id': self.customer_id,\n            'external_key': self.external_key,\n            'alarm_priority': self.alarm_priority,\n            'monitor': self.monitor,\n            'vlan': self.vlan,\n            'avps': self.avps,\n            'expires': self.expires\n        }\n\n        if self.status is not None:\n            data['status'] = self.status\n\n        for tag_name in self.tags:\n            data['tags'].append(tag_name)\n\n        if self.vrf is not None:\n            if not isinstance(self.vrf, VRF):\n                raise NipapValueError(\"'vrf' attribute not instance of VRF class.\")\n            data['vrf_id'] = self.vrf.id\n\n        # Prefix can be none if we are creating a new prefix\n        # from a pool or other prefix!\n        if self.prefix is not None:\n            data['prefix'] = self.prefix\n\n        if self.pool is None:\n            data['pool_id'] = None\n\n        else:\n            if not isinstance(self.pool, Pool):\n                raise NipapValueError(\"'pool' attribute not instance of Pool class.\")\n            data['pool_id'] = self.pool.id\n\n        # New object, create from scratch\n        if self.id is None:\n\n            # format args\n            x_args = {}\n            if 'from-pool' in args:\n                x_args['from-pool'] = { 'id': args['from-pool'].id }\n            if 'family' in args:\n                x_args['family'] = args['family']\n            if 'from-prefix' in args:\n                x_args['from-prefix'] = args['from-prefix']\n            if 'prefix_length' in args:\n                x_args['prefix_length'] = args['prefix_length']\n\n            try:\n                prefix = xmlrpc.connection.add_prefix(\n                    {\n                        'attr': data,\n                        'args': x_args,\n                        'auth': self._auth_opts.options\n                    })\n            except xmlrpclib.Fault as xml_fault:\n                raise _fault_to_exception(xml_fault)\n\n        # Old object, edit\n        else:\n\n            # Add authoritative source to data\n            data['authoritative_source'] = self.authoritative_source\n\n            try:\n                # save\n                prefixes = xmlrpc.connection.edit_prefix(\n                    {\n                        'prefix': { 'id': self.id },\n                        'attr': data,\n                        'auth': self._auth_opts.options\n                    })\n\n            except xmlrpclib.Fault as xml_fault:\n                raise _fault_to_exception(xml_fault)\n\n            if len(prefixes) != 1:\n                raise NipapError('Prefix edit returned %d entries, should be 1.' % len(prefixes))\n            prefix = prefixes[0]\n\n        # Refresh object data with attributes from add/edit operation\n        Prefix.from_dict(prefix, self)\n\n        # update cache\n        _cache['Prefix'][self.id] = self\n        if self.pool is not None:\n            if self.pool.id in _cache['Pool']:\n                del _cache['Pool'][self.pool.id]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove(self, recursive = False):\n\n        xmlrpc = XMLRPCConnection()\n        try:\n            xmlrpc.connection.remove_prefix(\n                {\n                    'prefix': { 'id': self.id },\n                    'recursive': recursive,\n                    'auth': self._auth_opts.options\n                })\n        except xmlrpclib.Fault as xml_fault:\n            raise _fault_to_exception(xml_fault)\n\n        # update cache\n        if self.id in _cache['Prefix']:\n            del(_cache['Prefix'][self.id])\n        if self.pool is not None:\n            if self.pool.id in _cache['Pool']:\n                del _cache['Pool'][self.pool.id]", "response": "Removes the prefix from the backend."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_dict(cls, pref, prefix = None):\n\n        if prefix is None:\n            prefix = Prefix()\n\n        prefix.id = pref['id']\n        if pref['vrf_id'] is not None: # VRF is not mandatory\n            prefix.vrf = VRF.get(pref['vrf_id'])\n        prefix.family = pref['family']\n        prefix.prefix = pref['prefix']\n        prefix.display_prefix = pref['display_prefix']\n        prefix.description = pref['description']\n        prefix.comment = pref['comment']\n        prefix.node = pref['node']\n        if pref['pool_id'] is not None: # Pool is not mandatory\n            prefix.pool = Pool.get(pref['pool_id'])\n        prefix.type = pref['type']\n        prefix.indent = pref['indent']\n        prefix.country = pref['country']\n        prefix.order_id = pref['order_id']\n        prefix.customer_id = pref['customer_id']\n        prefix.external_key = pref['external_key']\n        prefix.authoritative_source = pref['authoritative_source']\n        prefix.alarm_priority = pref['alarm_priority']\n        prefix.monitor = pref['monitor']\n        prefix.vlan = pref['vlan']\n        prefix.added = pref['added']\n        prefix.last_modified = pref['last_modified']\n        prefix.total_addresses = int(pref['total_addresses'])\n        prefix.used_addresses = int(pref['used_addresses'])\n        prefix.free_addresses = int(pref['free_addresses'])\n        prefix.status = pref['status']\n        prefix.avps = pref['avps']\n        prefix.expires = pref['expires']\n\n        prefix.inherited_tags = {}\n        for tag_name in pref['inherited_tags']:\n            tag = Tag.from_dict({'name': tag_name })\n            prefix.inherited_tags[tag_name] = tag\n\n        prefix.tags = {}\n        for tag_name in pref['tags']:\n            tag = Tag.from_dict({'name': tag_name })\n            prefix.tags[tag_name] = tag\n\n        if 'match' in pref:\n            prefix.match = pref['match']\n        if 'display' in pref:\n            prefix.display = pref['display']\n        if 'children' in pref:\n            prefix.children = pref['children']\n\n        return prefix", "response": "Create a new object from a dict."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef edit(self, id):\n\n        c.action = 'edit'\n        c.edit_vrf = VRF.get(int(id))\n\n        # Did we have any action passed to us?\n        if 'action' in request.params:\n\n            if request.params['action'] == 'edit':\n                if request.params['rt'].strip() == '':\n                    c.edit_vrf.rt = None\n                else:\n                    c.edit_vrf.rt = request.params['rt'].strip()\n\n                if request.params['name'].strip() == '':\n                    c.edit_vrf.name = None\n                else:\n                    c.edit_vrf.name = request.params['name'].strip()\n                c.edit_vrf.description = request.params['description']\n                c.edit_vrf.save()\n\n        return render('/vrf_edit.html')", "response": "Edit a VRF with the given ID"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a new VRF.", "response": "def add(self):\n        \"\"\" Add a new VRF.\n        \"\"\"\n\n        c.action = 'add'\n\n        if 'action' in request.params:\n            if request.params['action'] == 'add':\n                v = VRF()\n                if request.params['rt'].strip() != '':\n                    v.rt = request.params['rt']\n                if request.params['name'].strip() != '':\n                    v.name = request.params['name']\n                v.description = request.params['description']\n\n                v.save()\n                redirect(url(controller='vrf', action='list'))\n\n        return render('/vrf_add.html')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setup_app(command, conf, vars):\n    # Don't reload the app if it was loaded under the testing environment\n    if not pylons.test.pylonsapp:\n        load_environment(conf.global_conf, conf.local_conf)", "response": "Place any commands to setup nipapwww here"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_app(global_conf, full_stack=True, static_files=True, **app_conf):\n    # Configure the Pylons environment\n    config = load_environment(global_conf, app_conf)\n\n    # The Pylons WSGI app\n    app = PylonsApp(config=config)\n\n    # Routing/Session Middleware\n    app = RoutesMiddleware(app, config['routes.map'], singleton=False)\n    app = SessionMiddleware(app, config)\n\n    # CUSTOM MIDDLEWARE HERE (filtered by error handling middlewares)\n\n    if asbool(full_stack):\n        # Handle Python exceptions\n        app = ErrorHandler(app, global_conf, **config['pylons.errorware'])\n\n        # Display error documents for 401, 403, 404 status codes (and\n        # 500 when debug is disabled)\n        if asbool(config['debug']):\n            app = StatusCodeRedirect(app)\n        else:\n            app = StatusCodeRedirect(app, [400, 401, 403, 404, 500])\n\n    # Establish the Registry for this application\n    app = RegistryManager(app)\n\n    if asbool(static_files):\n        # Serve static files\n        static_app = StaticURLParser(config['pylons.paths']['static_files'])\n        app = Cascade([static_app, app])\n    app.config = config\n    return app", "response": "Create a new Pylons application and return it."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add(self):\n\n        # pass prefix to template - if we have any\n        if 'prefix' in request.params:\n            c.prefix = request.params['prefix']\n        else:\n            c.prefix = ''\n\n        c.search_opt_parent = \"all\"\n        c.search_opt_child = \"none\"\n\n        return render('/prefix_add.html')", "response": "Add a new prefix."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconfiguring the Pylons environment via the pylons. config object", "response": "def load_environment(global_conf, app_conf):\n    \"\"\"Configure the Pylons environment via the ``pylons.config``\n    object\n    \"\"\"\n    config = PylonsConfig()\n    \n    # Pylons paths\n    root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n    paths = dict(root=root,\n                 controllers=os.path.join(root, 'controllers'),\n                 static_files=os.path.join(root, 'public'),\n                 templates=[os.path.join(root, 'templates')])\n\n    # Initialize config with the basic options\n    config.init_app(global_conf, app_conf, package='nipapwww', paths=paths)\n\n    config['routes.map'] = make_map(config)\n    config['pylons.app_globals'] = app_globals.Globals(config)\n    config['pylons.h'] = nipapwww.lib.helpers\n    \n    # Setup cache object as early as possible\n    import pylons\n    pylons.cache._push_object(config['pylons.app_globals'].cache)\n    \n\n    # Create the Jinja2 Environment\n    jinja2_env = Environment(autoescape=True,\n            extensions=['jinja2.ext.autoescape'],\n            loader=FileSystemLoader(paths['templates']))\n    config['pylons.app_globals'].jinja2_env = jinja2_env\n\n    # CONFIGURATION OPTIONS HERE (note: all config options will override\n    # any Pylons config options)\n    config['pylons.strict_c'] = False\n\n    # Make sure that there is a configuration object\n    cfg = NipapConfig(config['nipap_config_path'], \n        { 'auth_cache_timeout': '3600' })\n\n    # set XML-RPC URI in pynipap module\n    pynipap.xmlrpc_uri = cfg.get('www', 'xmlrpc_uri')\n\n    return config"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting prefixes from NIPAP", "response": "def get_prefixes(self, query):\n        \"\"\" Get prefix data from NIPAP\n        \"\"\"\n        try:\n            res = Prefix.smart_search(query, {})\n        except socket.error:\n            print >> sys.stderr, \"Connection refused, please check hostname & port\"\n            sys.exit(1)\n        except xmlrpclib.ProtocolError:\n            print >> sys.stderr, \"Authentication failed, please check your username / password\"\n            sys.exit(1)\n\n        for p in res['result']:\n            p.prefix_ipy = IPy.IP(p.prefix)\n            self.prefixes.append(p)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write_conf(self):\n        f = open(self.output_filename, 'w')\n        print(self.t.render(prefixes=self.prefixes), file=f)\n        f.close()", "response": "Write the config to file\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a daemon process.", "response": "def createDaemon():\n   \"\"\"Detach a process from the controlling terminal and run it in the\n   background as a daemon.\n   \"\"\"\n\n   try:\n      # Fork a child process so the parent can exit.  This returns control to\n      # the command-line or shell.  It also guarantees that the child will not\n      # be a process group leader, since the child receives a new process ID\n      # and inherits the parent's process group ID.  This step is required\n      # to insure that the next call to os.setsid is successful.\n      pid = os.fork()\n   except OSError, e:\n      raise Exception, \"%s [%d]\" % (e.strerror, e.errno)\n\n   if (pid == 0):   # The first child.\n      # To become the session leader of this new session and the process group\n      # leader of the new process group, we call os.setsid().  The process is\n      # also guaranteed not to have a controlling terminal.\n      os.setsid()\n\n      # Is ignoring SIGHUP necessary?\n      #\n      # It's often suggested that the SIGHUP signal should be ignored before\n      # the second fork to avoid premature termination of the process.  The\n      # reason is that when the first child terminates, all processes, e.g.\n      # the second child, in the orphaned group will be sent a SIGHUP.\n      #\n      # \"However, as part of the session management system, there are exactly\n      # two cases where SIGHUP is sent on the death of a process:\n      #\n      #   1) When the process that dies is the session leader of a session that\n      #      is attached to a terminal device, SIGHUP is sent to all processes\n      #      in the foreground process group of that terminal device.\n      #   2) When the death of a process causes a process group to become\n      #      orphaned, and one or more processes in the orphaned group are\n      #      stopped, then SIGHUP and SIGCONT are sent to all members of the\n      #      orphaned group.\" [2]\n      #\n      # The first case can be ignored since the child is guaranteed not to have\n      # a controlling terminal.  The second case isn't so easy to dismiss.\n      # The process group is orphaned when the first child terminates and\n      # POSIX.1 requires that every STOPPED process in an orphaned process\n      # group be sent a SIGHUP signal followed by a SIGCONT signal.  Since the\n      # second child is not STOPPED though, we can safely forego ignoring the\n      # SIGHUP signal.  In any case, there are no ill-effects if it is ignored.\n      #\n      # import signal           # Set handlers for asynchronous events.\n      # signal.signal(signal.SIGHUP, signal.SIG_IGN)\n\n      try:\n         # Fork a second child and exit immediately to prevent zombies.  This\n         # causes the second child process to be orphaned, making the init\n         # process responsible for its cleanup.  And, since the first child is\n         # a session leader without a controlling terminal, it's possible for\n         # it to acquire one by opening a terminal in the future (System V-\n         # based systems).  This second fork guarantees that the child is no\n         # longer a session leader, preventing the daemon from ever acquiring\n         # a controlling terminal.\n         pid = os.fork()    # Fork a second child.\n      except OSError, e:\n         raise Exception, \"%s [%d]\" % (e.strerror, e.errno)\n\n      if (pid == 0):    # The second child.\n         # Since the current working directory may be a mounted filesystem, we\n         # avoid the issue of not being able to unmount the filesystem at\n         # shutdown time by changing it to the root directory.\n         os.chdir(WORKDIR)\n         # We probably don't want the file mode creation mask inherited from\n         # the parent, so we give the child complete control over permissions.\n         os.umask(UMASK)\n      else:\n         # exit() or _exit()?  See below.\n         os._exit(0)    # Exit parent (the first child) of the second child.\n   else:\n      # exit() or _exit()?\n      # _exit is like exit(), but it doesn't call any functions registered\n      # with atexit (and on_exit) or any registered signal handlers.  It also\n      # closes any open file descriptors.  Using exit() may cause all stdio\n      # streams to be flushed twice and any temporary files may be unexpectedly\n      # removed.  It's therefore recommended that child branches of a fork()\n      # and the parent branch(es) of a daemon use _exit().\n      os._exit(0)   # Exit parent of the first child.\n\n   # Close all open file descriptors.  This prevents the child from keeping\n   # open any file descriptors inherited from the parent.  There is a variety\n   # of methods to accomplish this task.  Three are listed below.\n   #\n   # Try the system configuration variable, SC_OPEN_MAX, to obtain the maximum\n   # number of open file descriptors to close.  If it doesn't exists, use\n   # the default value (configurable).\n   #\n   # try:\n   #    maxfd = os.sysconf(\"SC_OPEN_MAX\")\n   # except (AttributeError, ValueError):\n   #    maxfd = MAXFD\n   #\n   # OR\n   #\n   # if (os.sysconf_names.has_key(\"SC_OPEN_MAX\")):\n   #    maxfd = os.sysconf(\"SC_OPEN_MAX\")\n   # else:\n   #    maxfd = MAXFD\n   #\n   # OR\n   #\n   # Use the getrlimit method to retrieve the maximum file descriptor number\n   # that can be opened by this process.  If there is not limit on the\n   # resource, use the default value.\n   #\n   import resource      # Resource usage information.\n   maxfd = resource.getrlimit(resource.RLIMIT_NOFILE)[1]\n   if (maxfd == resource.RLIM_INFINITY):\n      maxfd = MAXFD\n  \n   # FIXME: this breaks our tpxmld, so it's commented for now //kll\n   # Iterate through and close all file descriptors.\n#   for fd in range(0, maxfd):\n#      try:\n#         os.close(fd)\n#      except OSError:   # ERROR, fd wasn't open to begin with (ignored)\n#         pass\n\n   # Redirect the standard I/O file descriptors to the specified file.  Since\n   # the daemon has no controlling terminal, most daemons redirect stdin,\n   # stdout, and stderr to /dev/null.  This is done to prevent side-effects\n   # from reads and writes to the standard I/O file descriptors.\n\n   # This call to open is guaranteed to return the lowest file descriptor,\n   # which will be 0 (stdin), since it was closed above.\n   os.open(REDIRECT_TO, os.O_RDWR)  # standard input (0)\n\n   # Duplicate standard input to standard output and standard error.\n   os.dup2(0, 1)            # standard output (1)\n   os.dup2(0, 2)            # standard error (2)\n\n   return(0)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing one line of text into a base - level object.", "response": "def parse_line(self, line):\n        \"\"\" Parse one line\n        \"\"\"\n\n        try:\n            # text params, ie params from the text file\n            tp = self.split_columns(line)\n        except CommentLine:\n            # just ignore comments\n            return\n\n        if tp['prefix_type'] == 'reservation':  # reservations / aggregates\n            print \"Reservation:\", tp['prefix'], tp['description']\n            p = Prefix()\n            p.schema = self.schema\n            p.prefix = tp['prefix']\n            p.type = 'reservation'\n            p.description = tp['description']\n            p.monitor = True\n            p.alarm_priority = 'low'\n            p.authoritative_source = 'nw'\n            p.save({})\n            return\n\n        elif tp['node'] == '.' and tp['description'] == '.':\n            # ignore prefixes without description or node set\n            return\n\n        elif tp['prefix_length'] == 32:   # loopback\n            # if it's a loopback, the covering prefix will be a reservation and we can just insert an assignment.\n            # if this insert fails, it means the parent prefix is an assignment and we instead insert a host\n            try:\n                p = Prefix()\n                p.schema = self.schema\n                p.prefix = tp['prefix']\n                # loopbacks are always of type 'assignment'\n                p.type = 'assignment'\n                p.node = tp['node']\n                p.description = tp['description']\n                p.monitor = True\n                p.alarm_priority = tp['alarm_priority']\n                p.authoritative_source = 'nw'\n                p.save({})\n                print \"Loopback:\", tp['prefix']\n                return\n            except:\n                p = Prefix()\n                p.schema = self.schema\n                p.prefix = tp['prefix']\n                # loopbacks are always of type 'assignment'\n                p.type = 'host'\n                p.node = tp['node']\n                p.description = tp['description']\n                p.monitor = True\n                p.alarm_priority = tp['alarm_priority']\n                p.authoritative_source = 'nw'\n                p.save({})\n                print \"Host:\", tp['prefix']\n                return\n\n        elif tp['prefix_length'] == 30 or tp['prefix_length'] == 31:   # link network\n            octets = tp['address'].split('.')\n            prefix_node1 = None\n            prefix_node2 = None\n            if tp['prefix_length'] == 30:\n                prefix_node1 = '.'.join(octets[:3] + [str( int(octets[3]) + 1 )] ) + '/32'\n                prefix_node2 = '.'.join(octets[:3] + [str( int(octets[3]) + 2 )] ) + '/32'\n            else:\n                prefix_node1 = '.'.join(octets) + '/32'\n                prefix_node2 = '.'.join(octets[:3] + [str( int(octets[3]) + 1 )] ) + '/32'\n\n            #m = re.match('(ETHER_KAP|ETHER_PORT|IP-KAP|IP-PORT|IP-SIPNET|IP-SNIX|IPSUR|L2L|RED-IPPORT|SNIX|SWIP|T2V-@|T2V-DIGTV|T2V-SUR)[0-9]{4,}', tp['order_id'])\n            m = re.match('.*[0-9]{6}$', tp['order_id'])\n            if m is not None or tp['type'] == 'CUSTOMER':\n                print \"Customer link\", tp['prefix'], ':', tp['description']\n                p = Prefix()\n                p.schema = self.schema\n                p.prefix = tp['prefix']\n                p.type = 'assignment'\n                p.description = tp['description']\n                p.alarm_priority = tp['alarm_priority']\n                p.authoritative_source = 'nw'\n                if tp['order_id'] != '.':\n                    p.order_id = tp['order_id']\n                p.save({})\n\n                # insert node1 and node2\n                p1 = Prefix()\n                p1.schema = self.schema\n                p1.prefix = prefix_node1\n                p1.type = 'host'\n                p1.description = 'Some PE router'\n                p1.authoritative_source = 'nw'\n                p1.save({})\n\n                p2 = Prefix()\n                p2.schema = self.schema\n                p2.prefix = prefix_node2\n                p2.type = 'host'\n                p2.node = tp['node']\n                p2.description = 'CPE'\n                p2.authoritative_source = 'nw'\n                p2.save({})\n\n                return\n\n\n            m = re.match(r'([^\\s]+)\\s*<->\\s*([^\\s]+)', tp['description'])\n            if m is not None:\n                node1 = m.group(1)\n                node2 = m.group(2)\n                print \"Link network: \", tp['prefix'], \"  \", node1, \"<->\", node2\n\n                p = Prefix()\n                p.schema = self.schema\n                p.prefix = tp['prefix']\n                p.type = 'assignment'\n                p.description = node1 + ' <-> ' + node2\n                p.monitor = True\n                p.alarm_priority = tp['alarm_priority']\n                p.authoritative_source = 'nw'\n                p.save({})\n\n                # insert node1 and node2\n                p1 = Prefix()\n                p1.schema = self.schema\n                p1.prefix = prefix_node1\n                p1.type = 'host'\n                p1.node = node1\n                p1.description = node1\n                p1.authoritative_source = 'nw'\n                p1.save({})\n\n                p2 = Prefix()\n                p2.schema = self.schema\n                p2.prefix = prefix_node2\n                p2.type = 'host'\n                p2.node = node2\n                p2.description = node2\n                p2.authoritative_source = 'nw'\n                p2.save({})\n\n                return\n\n            m = re.match('(DN)[0-9]{4,}', tp['order_id'])\n            if m is not None:\n                print \"Internal order link network\", tp['prefix'], ':', tp['description']\n                p = Prefix()\n                p.schema = self.schema\n                p.prefix = tp['prefix']\n                p.type = 'assignment'\n                p.description = tp['description']\n                p.monitor = True\n                p.alarm_priority = tp['alarm_priority']\n                p.authoritative_source = 'nw'\n                p.save({})\n                return\n\n            print \"Other link network\", tp['prefix'], ':', tp['description']\n            p = Prefix()\n            p.schema = self.schema\n            p.prefix = tp['prefix']\n            p.type = 'assignment'\n            p.description = tp['description']\n            p.monitor = True\n            p.alarm_priority = tp['alarm_priority']\n            p.authoritative_source = 'nw'\n            p.save({})\n            return\n\n        else:\n            try:\n                p = Prefix()\n                p.schema = self.schema\n                p.prefix = tp['prefix']\n                p.type = 'assignment'\n                p.description = tp['description']\n                p.monitor = True\n                p.alarm_priority = 'low'\n                p.authoritative_source = 'nw'\n                p.save({})\n                print \"Other:\", tp['prefix']\n            except NipapValueError, e:\n                print tp['prefix'], ':', e\n                sys.exit(1)\n\n            return"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef requires_auth(f):\n    @wraps(f)\n\n    def decorated(self, *args, **kwargs):\n        \"\"\"\n        \"\"\"\n\n        # Fetch auth options from args\n        auth_options = {}\n        nipap_args = {}\n\n        # validate function arguments\n        if len(args) == 1:\n            nipap_args = args[0]\n        else:\n            self.logger.debug(\"Malformed request: got %d parameters\" % len(args))\n            raise Fault(1000, (\"NIPAP API functions take exactly 1 argument (%d given)\") % len(args))\n\n        if type(nipap_args) != dict:\n            self.logger.debug(\"Function argument is not struct\")\n            raise Fault(1000, (\"Function argument must be XML-RPC struct/Python dict (Python %s given).\" %\n                type(nipap_args).__name__ ))\n\n        # fetch auth options\n        try:\n            auth_options = nipap_args['auth']\n            if type(auth_options) is not dict:\n                raise ValueError()\n        except (KeyError, ValueError):\n            self.logger.debug(\"Missing/invalid authentication options in request.\")\n            raise Fault(1000, (\"Missing/invalid authentication options in request.\"))\n\n        # fetch authoritative source\n        try:\n            auth_source = auth_options['authoritative_source']\n        except KeyError:\n            self.logger.debug(\"Missing authoritative source in auth options.\")\n            raise Fault(1000, (\"Missing authoritative source in auth options.\"))\n\n        if not request.authorization:\n            return authenticate()\n\n        # init AuthFacory()\n        af = AuthFactory()\n        auth = af.get_auth(request.authorization.username,\n                request.authorization.password, auth_source, auth_options or {})\n\n        # authenticated?\n        if not auth.authenticate():\n            self.logger.debug(\"Incorrect username or password.\")\n            raise Fault(1510, (\"Incorrect username or password.\"))\n\n        # Replace auth options in API call arguments with auth object\n        new_args = dict(args[0])\n        new_args['auth'] = auth\n\n        return f(self, *(new_args,), **kwargs)\n\n    return decorated", "response": "Decorator for XML - RPC functions that requires auth"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_vrf(self, args):\n        try:\n            res = self.nip.add_vrf(args.get('auth'), args.get('attr'))\n\n            # fugly cast from large numbers to string to deal with XML-RPC\n            for val in ( 'num_prefixes_v4', 'num_prefixes_v6',\n                'total_addresses_v4', 'total_addresses_v6',\n                'used_addresses_v4', 'used_addresses_v6', 'free_addresses_v4',\n                'free_addresses_v6'):\n                res[val] = unicode(res[val])\n\n            return res\n        except (AuthError, NipapError) as exc:\n            self.logger.debug(unicode(exc))\n            raise Fault(exc.error_code, unicode(exc))", "response": "Adds a new VRF to the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a prefix to the current prefix.", "response": "def add_prefix(self, args):\n        \"\"\" Add a prefix.\n\n            Valid keys in the `args`-struct:\n\n            * `auth` [struct]\n                Authentication options passed to the :class:`AuthFactory`.\n            * `attr` [struct]\n                Attributes to set on the new prefix.\n            * `args` [srgs]\n                Arguments for addition of prefix, such as what pool or prefix\n                it should be allocated from.\n\n            Returns ID of created prefix.\n        \"\"\"\n        try:\n            res = self.nip.add_prefix(args.get('auth'), args.get('attr'), args.get('args'))\n            # mangle result\n            res = _mangle_prefix(res)\n            return res\n        except (AuthError, NipapError) as exc:\n            self.logger.debug(unicode(exc))\n            raise Fault(exc.error_code, unicode(exc))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove_prefix(self, args):\n        try:\n            return self.nip.remove_prefix(args.get('auth'), args.get('prefix'), args.get('recursive'))\n        except (AuthError, NipapError) as exc:\n            self.logger.debug(unicode(exc))\n            raise Fault(exc.error_code, unicode(exc))", "response": "Remove a prefix from a specific entry in the nipap database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_free_prefix(self, args):\n\n        try:\n            return self.nip.find_free_prefix(args.get('auth'), args.get('vrf'), args.get('args'))\n        except NipapError as exc:\n            self.logger.debug(unicode(exc))\n            raise Fault(exc.error_code, unicode(exc))", "response": "Find a free prefix."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads content of NEWS file", "response": "def _readfile(self, filename):\n        \"\"\" Read content of specified NEWS file\n        \"\"\"\n        f = open(filename)\n        self.content = f.readlines()\n        f.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the content of the DCH file and store the version and entry in self. versions.", "response": "def _parse(self):\n        \"\"\" Parse content of DCH file\n        \"\"\"\n        cur_ver = None\n        cur_line = None\n        for line in self.content:\n            m = re.match('[^ ]+ \\(([0-9]+\\.[0-9]+\\.[0-9]+)-[0-9]+\\) [^ ]+; urgency=[^ ]+', line)\n            if m:\n                cur_ver = m.group(1)\n                self.versions.append(cur_ver)\n                self.entries[cur_ver] = []\n                cur_entry = self.entries[cur_ver]\n                if self.latest_version is None or StrictVersion(cur_ver) > StrictVersion(self.latest_version):\n                    self.latest_version = m.group(1)\n            elif cur_ver:\n                m = re.match('  \\* (.*)', line)\n                if m:\n                    cur_entry.append(m.group(1).strip())\n                elif not re.match('$', line) and re.match(' *[^$]+', line):\n                    cur_entry[-1] += \" \" + line.strip()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef format(self, record: logging.LogRecord) -> str:\n        msg: Union[str, dict] = record.msg\n        if not isinstance(record.msg, dict):\n            msg = {self.default_msg_fieldname: msg}\n\n        if record.exc_info:  # type: ignore\n            msg[\"exc_info\"] = record.exc_info\n        if record.exc_text:  # type: ignore\n            msg[\"exc_text\"] = record.exc_text  # type: ignore\n\n        return self.serializer(msg, default=self._default_handler)", "response": "Formats a record and serializes it as a JSON str."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef formatter_fields_for_record(self, record):\n        datetime_serialized = (\n            datetime.now(timezone.utc).astimezone(self.tz).isoformat()\n        )\n\n        default_fields = (\n            (LOGGED_AT_FIELDNAME, datetime_serialized),\n            (LINE_NUMBER_FIELDNAME, record.lineno),\n            (FUNCTION_NAME_FIELDNAME, record.funcName),\n            (LOG_LEVEL_FIELDNAME, self.level_to_name_mapping[record.levelno]),\n            (FILE_PATH_FIELDNAME, record.pathname),\n        )\n\n        for field, value in default_fields:\n            if field in self.log_fields:\n                yield field, value", "response": "Yields a list of fields that can be used to format a log record."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nformatting a log record into a string.", "response": "def format(self, record) -> str:\n        \"\"\"\n        :type record: aiologger.loggers.json.LogRecord\n        \"\"\"\n        msg = dict(self.formatter_fields_for_record(record))\n        if record.flatten and isinstance(record.msg, dict):\n            msg.update(record.msg)\n        else:\n            msg[MSG_FIELDNAME] = record.msg\n\n        if record.extra:\n            msg.update(record.extra)\n        if record.exc_info:\n            msg[\"exc_info\"] = record.exc_info\n        if record.exc_text:\n            msg[\"exc_text\"] = record.exc_text\n\n        return self.serializer(\n            msg, default=self._default_handler, **record.serializer_kwargs\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def _init_writer(self):\n        async with self._initialization_lock:\n            if not self.initialized:\n                self.stream = await aiofiles.open(\n                    file=self.absolute_file_path,\n                    mode=self.mode,\n                    encoding=self.encoding,\n                    loop=self.loop,\n                )", "response": "Open the current base file with the (original) mode and encoding.\n        Return the resulting stream."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def emit(self, record: LogRecord):  # type: ignore\n        try:\n            if self.should_rollover(record):\n                async with self._rollover_lock:\n                    if self.should_rollover(record):\n                        await self.do_rollover()\n            await super().emit(record)\n        except Exception as e:\n            await self.handleError(record)", "response": "Emit a record.\n\n        Output the record to the file, catering for rollover as described\n        in `do_rollover`."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rotation_filename(self, default_name: str) -> str:\n        if self.namer is None:\n            return default_name\n\n        return self.namer(default_name)", "response": "Modify the filename of a log file when rotating."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrotates the current log file.", "response": "async def rotate(self, source: str, dest: str):\n        \"\"\"\n        When rotating, rotate the current log.\n\n        The default implementation calls the 'rotator' attribute of the\n        handler, if it's callable, passing the source and dest arguments to\n        it. If the attribute isn't callable (the default is None), the source\n        is simply renamed to the destination.\n\n        :param source: The source filename. This is normally the base\n                       filename, e.g. 'test.log'\n        :param dest:   The destination filename. This is normally\n                       what the source is rotated to, e.g. 'test.log.1'.\n        \"\"\"\n        if self.rotator is None:\n            # logging issue 18940: A file may not have been created if delay is True.\n            if await self.loop.run_in_executor(\n                None, lambda: os.path.exists(source)\n            ):\n                await self.loop.run_in_executor(  # type: ignore\n                    None, lambda: os.rename(source, dest)\n                )\n        else:\n            self.rotator(source, dest)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute the rollover time based on the specified time.", "response": "def compute_rollover(self, current_time: int) -> int:\n        \"\"\"\n        Work out the rollover time based on the specified time.\n\n        If we are rolling over at midnight or weekly, then the interval is\n        already known. need to figure out is WHEN the next interval is.\n        In other words, if you are rolling over at midnight, then your base\n        interval is 1 day, but you want to start that one day clock at midnight,\n         not now. So, we have to fudge the `rollover_at` value in order to trigger\n         the first rollover at the right time.  After that, the regular interval\n         will take care of the rest.  Note that this code doesn't care about\n         leap seconds. :)\n        \"\"\"\n        result = current_time + self.interval\n\n        if (\n            self.when == RolloverInterval.MIDNIGHT\n            or self.when in RolloverInterval.WEEK_DAYS\n        ):\n            if self.utc:\n                t = time.gmtime(current_time)\n            else:\n                t = time.localtime(current_time)\n            current_hour = t[3]\n            current_minute = t[4]\n            current_second = t[5]\n            current_day = t[6]\n            # r is the number of seconds left between now and the next rotation\n            if self.at_time is None:\n                rotate_ts = ONE_DAY_IN_SECONDS\n            else:\n                rotate_ts = (\n                    self.at_time.hour * 60 + self.at_time.minute\n                ) * 60 + self.at_time.second\n\n            r = rotate_ts - (\n                (current_hour * 60 + current_minute) * 60 + current_second\n            )\n            if r < 0:\n                # Rotate time is before the current time (for example when\n                # self.rotateAt is 13:45 and it now 14:15), rotation is\n                # tomorrow.\n                r += ONE_DAY_IN_SECONDS\n                current_day = (current_day + 1) % 7\n            result = current_time + r\n            # If we are rolling over on a certain day, add in the number of days until\n            # the next rollover, but offset by 1 since we just calculated the time\n            # until the next day starts.  There are three cases:\n            # Case 1) The day to rollover is today; in this case, do nothing\n            # Case 2) The day to rollover is further in the interval (i.e., today is\n            #         day 2 (Wednesday) and rollover is on day 6 (Sunday).  Days to\n            #         next rollover is simply 6 - 2 - 1, or 3.\n            # Case 3) The day to rollover is behind us in the interval (i.e., today\n            #         is day 5 (Saturday) and rollover is on day 3 (Thursday).\n            #         Days to rollover is 6 - 5 + 3, or 4.  In this case, it's the\n            #         number of days left in the current week (1) plus the number\n            #         of days in the next week until the rollover day (3).\n            # The calculations described in 2) and 3) above need to have a day added.\n            # This is because the above time calculation takes us to midnight on this\n            # day, i.e. the start of the next day.\n            if self.when in RolloverInterval.WEEK_DAYS:\n                day = current_day  # 0 is Monday\n                if day != self.day_of_week:\n                    if day < self.day_of_week:\n                        days_to_wait = self.day_of_week - day\n                    else:\n                        days_to_wait = 6 - day + self.day_of_week + 1\n                    new_rollover_at = result + (days_to_wait * (60 * 60 * 24))\n                    if not self.utc:\n                        dst_now = t[-1]\n                        dst_at_rollover = time.localtime(new_rollover_at)[-1]\n                        if dst_now != dst_at_rollover:\n                            if not dst_now:\n                                # DST kicks in before next rollover, so we need to deduct an hour\n                                addend = -ONE_HOUR_IN_SECONDS\n                            else:\n                                # DST bows out before next rollover, so we need to add an hour\n                                addend = ONE_HOUR_IN_SECONDS\n                            new_rollover_at += addend\n                    result = new_rollover_at\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef should_rollover(self, record: LogRecord) -> bool:\n        t = int(time.time())\n        if t >= self.rollover_at:\n            return True\n        return False", "response": "Determine if rollover should occur."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def get_files_to_delete(self) -> List[str]:\n        dir_name, base_name = os.path.split(self.absolute_file_path)\n        file_names = await self.loop.run_in_executor(\n            None, lambda: os.listdir(dir_name)\n        )\n        result = []\n        prefix = base_name + \".\"\n        plen = len(prefix)\n        for file_name in file_names:\n            if file_name[:plen] == prefix:\n                suffix = file_name[plen:]\n                if self.ext_match.match(suffix):\n                    result.append(os.path.join(dir_name, file_name))\n        if len(result) < self.backup_count:\n            return []\n        else:\n            return result[: len(result) - self.backup_count]", "response": "Determine the files to delete when rolling over."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def do_rollover(self):\n        if self.stream:\n            await self.stream.close()\n            self.stream = None\n        # get the time that this sequence started at and make it a TimeTuple\n        current_time = int(time.time())\n        dst_now = time.localtime(current_time)[-1]\n        t = self.rollover_at - self.interval\n        if self.utc:\n            time_tuple = time.gmtime(t)\n        else:\n            time_tuple = time.localtime(t)\n            dst_then = time_tuple[-1]\n            if dst_now != dst_then:\n                if dst_now:\n                    addend = ONE_HOUR_IN_SECONDS\n                else:\n                    addend = -ONE_HOUR_IN_SECONDS\n                time_tuple = time.localtime(t + addend)\n        destination_file_path = self.rotation_filename(\n            self.absolute_file_path\n            + \".\"\n            + time.strftime(self.suffix, time_tuple)\n        )\n        if await self.loop.run_in_executor(\n            None, lambda: os.path.exists(destination_file_path)\n        ):\n            await self.loop.run_in_executor(\n                None, lambda: os.unlink(destination_file_path)\n            )\n        await self.rotate(self.absolute_file_path, destination_file_path)\n        if self.backup_count > 0:\n            files_to_delete = await self.get_files_to_delete()\n            if files_to_delete:\n                await self._delete_files(files_to_delete)\n\n        await self._init_writer()\n        new_rollover_at = self.compute_rollover(current_time)\n        while new_rollover_at <= current_time:\n            new_rollover_at = new_rollover_at + self.interval\n        # If DST changes and midnight or weekly rollover, adjust for this.\n        if (\n            self.when == RolloverInterval.MIDNIGHT\n            or self.when in RolloverInterval.WEEK_DAYS\n        ) and not self.utc:\n            dst_at_rollover = time.localtime(new_rollover_at)[-1]\n            if dst_now != dst_at_rollover:\n                if not dst_now:\n                    # DST kicks in before next rollover, so we need to deduct an hour\n                    addend = -ONE_HOUR_IN_SECONDS\n                else:\n                    # DST bows out before next rollover, so we need to add an hour\n                    addend = ONE_HOUR_IN_SECONDS\n                new_rollover_at += addend\n        self.rollover_at = new_rollover_at", "response": "Do a rollover of the current entry."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def _log(  # type: ignore\n        self,\n        level: int,\n        msg: Any,\n        args: Tuple,\n        exc_info=None,\n        extra: Dict = None,\n        stack_info=False,\n        flatten: bool = False,\n        serializer_kwargs: Dict = None,\n        caller: _Caller = None,\n    ):\n        \"\"\"\n        Low-level logging routine which creates a LogRecord and then calls\n        all the handlers of this logger to handle the record.\n\n        Overwritten to properly handle log methods kwargs\n        \"\"\"\n        sinfo = None\n        if caller:\n            fn, lno, func, sinfo = caller\n        else:  # pragma: no cover\n            fn, lno, func = \"(unknown file)\", 0, \"(unknown function)\"\n        if exc_info and isinstance(exc_info, BaseException):\n            exc_info = (type(exc_info), exc_info, exc_info.__traceback__)\n\n        joined_extra = {}\n        joined_extra.update(self.extra)\n\n        if extra:\n            joined_extra.update(extra)\n\n        record = LogRecord(\n            name=self.name,\n            level=level,\n            pathname=fn,\n            lineno=lno,\n            msg=msg,\n            args=args,\n            exc_info=exc_info,\n            func=func,\n            sinfo=sinfo,\n            extra=joined_extra,\n            flatten=flatten or self.flatten,\n            serializer_kwargs=serializer_kwargs or self.serializer_kwargs,\n        )\n        await self.handle(record)", "response": "Internal method to log a record."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def handle(self, record: LogRecord) -> bool:  # type: ignore\n        rv = self.filter(record)\n        if rv:\n            await self.emit(record)\n        return rv", "response": "Conditionally emit the specified logging record."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def emit(self, record: LogRecord):  # type: ignore\n        if self.writer is None:\n            self.writer = await self._init_writer()\n\n        try:\n            msg = self.format(record) + self.terminator\n\n            self.writer.write(msg.encode())\n            await self.writer.drain()\n        except Exception:\n            await self.handleError(record)", "response": "Actually log the specified logging record to the stream."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npassing a record to all relevant handlers.", "response": "async def callHandlers(self, record):\n        \"\"\"\n        Pass a record to all relevant handlers.\n\n        Loop through all handlers for this logger and its parents in the\n        logger hierarchy. If no handler was found, raises an error. Stop\n        searching up the hierarchy whenever a logger with the \"propagate\"\n        attribute set to zero is found - that will be the last logger\n        whose handlers are called.\n        \"\"\"\n        c = self\n        found = 0\n        while c:\n            for handler in c.handlers:\n                found = found + 1\n                if record.levelno >= handler.level:\n                    await handler.handle(record)\n            if not c.propagate:\n                c = None  # break out\n            else:\n                c = c.parent\n        if found == 0:\n            raise Exception(\"No handlers could be found for logger\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalls the handlers for the specified record. This method is used for unpickled records received from a socket, as well as those created locally. Logger-level filtering is applied.", "response": "async def handle(self, record):\n        \"\"\"\n        Call the handlers for the specified record.\n\n        This method is used for unpickled records received from a socket, as\n        well as those created locally. Logger-level filtering is applied.\n        \"\"\"\n        if (not self.disabled) and self.filter(record):\n            await self.callHandlers(record)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _make_log_task(self, level, msg, *args, **kwargs) -> Task:\n        if not self.isEnabledFor(level):\n            if self._dummy_task is None:\n                self._dummy_task = self.__make_dummy_task()\n            return self._dummy_task\n\n        if kwargs.get(\"exc_info\", False):\n            if not isinstance(kwargs[\"exc_info\"], BaseException):\n                kwargs[\"exc_info\"] = sys.exc_info()\n\n        coro = self._log(  # type: ignore\n            level, msg, *args, caller=self.findCaller(False), **kwargs\n        )\n        return self.loop.create_task(coro)", "response": "Creates an asyncio. Task for a msg if logging is enabled for level. Returns a dummy task otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef debug(self, msg, *args, **kwargs) -> Task:  # type: ignore\n        return self._make_log_task(logging.DEBUG, msg, args, **kwargs)", "response": "Log msg with severity DEBUG."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef info(self, msg, *args, **kwargs) -> Task:  # type: ignore\n        return self._make_log_task(logging.INFO, msg, args, **kwargs)", "response": "Log msg with severity INFO."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlogs msg with severity WARNING.", "response": "def warning(self, msg, *args, **kwargs) -> Task:  # type: ignore\n        \"\"\"\n        Log msg with severity 'WARNING'.\n\n        To pass exception information, use the keyword argument exc_info with\n        a true value, e.g.\n\n        await logger.warning(\"Houston, we have a bit of a problem\", exc_info=1)\n        \"\"\"\n        return self._make_log_task(logging.WARNING, msg, args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlogging msg with severity ERROR.", "response": "def error(self, msg, *args, **kwargs) -> Task:  # type: ignore\n        \"\"\"\n        Log msg with severity 'ERROR'.\n\n        To pass exception information, use the keyword argument exc_info with\n        a true value, e.g.\n\n        await logger.error(\"Houston, we have a major problem\", exc_info=1)\n        \"\"\"\n        return self._make_log_task(logging.ERROR, msg, args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlogs msg with severity CRITICAL.", "response": "def critical(self, msg, *args, **kwargs) -> Task:  # type: ignore\n        \"\"\"\n        Log msg with severity 'CRITICAL'.\n\n        To pass exception information, use the keyword argument exc_info with\n        a true value, e.g.\n\n        await logger.critical(\"Houston, we have a major disaster\", exc_info=1)\n        \"\"\"\n        return self._make_log_task(logging.CRITICAL, msg, args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef exception(  # type: ignore\n        self, msg, *args, exc_info=True, **kwargs\n    ) -> Task:\n        \"\"\"\n        Convenience method for logging an ERROR with exception information.\n        \"\"\"\n        return self.error(msg, *args, exc_info=exc_info, **kwargs)", "response": "Convenience method for logging an ERROR with exception information."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def shutdown(self):\n        if self._was_shutdown:\n            return\n        self._was_shutdown = True\n\n        for handler in reversed(self.handlers):\n            if not handler:\n                continue\n            try:\n                if handler.initialized:\n                    await handler.flush()\n                    await handler.close()\n\n            except Exception:\n                \"\"\"\n                Ignore errors which might be caused\n                because handlers have been closed but\n                references to them are still around at\n                application exit. Basically ignore everything, \n                as we're shutting down\n                \"\"\"\n                pass", "response": "Perform any cleanup actions in the logging system."}
