{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef knit(self, input_file, opts_chunk='eval=FALSE'):\n        # use temporary files at both ends to allow stdin / stdout\n        tmp_in = tempfile.NamedTemporaryFile(mode='w+')\n        tmp_out = tempfile.NamedTemporaryFile(mode='w+')\n\n        tmp_in.file.write(input_file.read())\n        tmp_in.file.flush()\n        tmp_in.file.seek(0)\n\n        self._knit(tmp_in.name, tmp_out.name, opts_chunk)\n        tmp_out.file.flush()\n        return tmp_out", "response": "Use Knitr to convert the r - markdown input_file into markdown returning a file object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _knit(fin, fout,\n              opts_knit='progress=FALSE, verbose=FALSE',\n              opts_chunk='eval=FALSE'):\n        \"\"\"Use knitr to convert r markdown (or anything knitr supports)\n        to markdown.\n\n        fin / fout - strings, input / output filenames.\n        opts_knit - string, options to pass to knit\n        opts_shunk - string, chunk options\n\n        options are passed verbatim to knitr:knit running in Rscript.\n        \"\"\"\n        script = ('sink(\"/dev/null\");'\n                  'library(knitr);'\n                  'opts_knit$set({opts_knit});'\n                  'opts_chunk$set({opts_chunk});'\n                  'knit(\"{input}\", output=\"{output}\")')\n\n        rcmd = ('Rscript', '-e',\n                script.format(input=fin, output=fout,\n                              opts_knit=opts_knit, opts_chunk=opts_chunk)\n                )\n\n        p = subprocess.Popen(rcmd,\n                             stdout=subprocess.PIPE,\n                             stderr=subprocess.PIPE)\n        stdout, stderr = p.communicate()", "response": "Use knitr to convert a markdown file to markdown."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_path_protected(path):\n    protected = True\n\n    for exclude_path in TERMS_EXCLUDE_URL_PREFIX_LIST:\n        if path.startswith(exclude_path):\n            protected = False\n\n    for contains_path in TERMS_EXCLUDE_URL_CONTAINS_LIST:\n        if contains_path in path:\n            protected = False\n\n    if path in TERMS_EXCLUDE_URL_LIST:\n        protected = False\n\n    if path.startswith(ACCEPT_TERMS_PATH):\n        protected = False\n\n\n    return protected", "response": "Returns True if given path is to be protected otherwise False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef process_request(self, request):\n\n        LOGGER.debug('termsandconditions.middleware')\n\n        current_path = request.META['PATH_INFO']\n\n        if DJANGO_VERSION <= (2, 0, 0):\n            user_authenticated = request.user.is_authenticated()\n        else:\n            user_authenticated = request.user.is_authenticated\n\n        if user_authenticated and is_path_protected(current_path):\n            for term in TermsAndConditions.get_active_terms_not_agreed_to(request.user):\n                # Check for querystring and include it if there is one\n                qs = request.META['QUERY_STRING']\n                current_path += '?' + qs if qs else ''\n                return redirect_to_terms_accept(current_path, term.slug)\n\n        return None", "response": "Process each request to app to ensure terms have been accepted"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck the URL parameters for slug and version to pull the right TermsAndConditions object", "response": "def get_terms(self, kwargs):\n        \"\"\"Checks URL parameters for slug and/or version to pull the right TermsAndConditions object\"\"\"\n\n        slug = kwargs.get(\"slug\")\n        version = kwargs.get(\"version\")\n\n        if slug and version:\n            terms = [TermsAndConditions.objects.filter(slug=slug, version_number=version).latest('date_active')]\n        elif slug:\n            terms = [TermsAndConditions.get_active(slug)]\n        else:\n            # Return a list of not agreed to terms for the current user for the list view\n            terms = TermsAndConditions.get_active_terms_not_agreed_to(self.request.user)\n        return terms"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npasses additional context data", "response": "def get_context_data(self, **kwargs):\n        \"\"\"Pass additional context data\"\"\"\n        context = super(TermsView, self).get_context_data(**kwargs)\n        context['terms_base_template'] = getattr(settings, 'TERMS_BASE_TEMPLATE', DEFAULT_TERMS_BASE_TEMPLATE)\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_initial(self):\n        LOGGER.debug('termsandconditions.views.AcceptTermsView.get_initial')\n\n        terms = self.get_terms(self.kwargs)\n        return_to = self.request.GET.get('returnTo', '/')\n\n        return {'terms': terms, 'returnTo': return_to}", "response": "Override of CreateView method queries for which T&C to accept and catches returnTo from URL"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\noverrides of CreateView method sends the email.", "response": "def form_valid(self, form):\n        \"\"\"Override of CreateView method, sends the email.\"\"\"\n        LOGGER.debug('termsandconditions.views.EmailTermsView.form_valid')\n\n        template = get_template(\"termsandconditions/tc_email_terms.html\")\n        template_rendered = template.render({\"terms\": form.cleaned_data.get('terms')})\n\n        LOGGER.debug(\"Email Terms Body:\")\n        LOGGER.debug(template_rendered)\n\n        try:\n            send_mail(form.cleaned_data.get('email_subject', _('Terms')),\n                      template_rendered,\n                      settings.DEFAULT_FROM_EMAIL,\n                      [form.cleaned_data.get('email_address')],\n                      fail_silently=False)\n            messages.add_message(self.request, messages.INFO, _(\"Terms and Conditions Sent.\"))\n        except SMTPException:  # pragma: no cover\n            messages.add_message(self.request, messages.ERROR, _(\"An Error Occurred Sending Your Message.\"))\n\n        self.success_url = form.cleaned_data.get('returnTo', '/') or '/'\n\n        return super(EmailTermsView, self).form_valid(form)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef form_invalid(self, form):\n        LOGGER.debug(\"Invalid Email Form Submitted\")\n        messages.add_message(self.request, messages.ERROR, _(\"Invalid Email Address.\"))\n        return super(EmailTermsView, self).form_invalid(form)", "response": "Override of CreateView method logs invalid email form submissions."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef terms_required(view_func):\n\n    @wraps(view_func, assigned=available_attrs(view_func))\n    def _wrapped_view(request, *args, **kwargs):\n        \"\"\"Method to wrap the view passed in\"\"\"\n        # If user has not logged in, or if they have logged in and already agreed to the terms, let the view through\n        if DJANGO_VERSION <= (2, 0, 0):\n            user_authenticated = request.user.is_authenticated()\n        else:\n            user_authenticated = request.user.is_authenticated\n\n        if not user_authenticated or not TermsAndConditions.get_active_terms_not_agreed_to(request.user):\n            return view_func(request, *args, **kwargs)\n\n        # Otherwise, redirect to terms accept\n        current_path = request.path\n        login_url_parts = list(urlparse(ACCEPT_TERMS_PATH))\n        querystring = QueryDict(login_url_parts[4], mutable=True)\n        querystring['returnTo'] = current_path\n        login_url_parts[4] = querystring.urlencode(safe='/')\n        return HttpResponseRedirect(urlunparse(login_url_parts))\n\n    return _wrapped_view", "response": "Decorator that checks to see if the user has logged in and has accepted the site terms."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_active(slug=DEFAULT_TERMS_SLUG):\n\n        active_terms = cache.get('tandc.active_terms_' + slug)\n        if active_terms is None:\n            try:\n                active_terms = TermsAndConditions.objects.filter(\n                    date_active__isnull=False,\n                    date_active__lte=timezone.now(),\n                    slug=slug).latest('date_active')\n                cache.set('tandc.active_terms_' + slug, active_terms, TERMS_CACHE_SECONDS)\n            except TermsAndConditions.DoesNotExist:  # pragma: nocover\n                LOGGER.error(\"Requested Terms and Conditions that Have Not Been Created.\")\n                return None\n\n        return active_terms", "response": "Finds the latest of a particular terms and conditions"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_active_terms_ids():\n\n        active_terms_ids = cache.get('tandc.active_terms_ids')\n        if active_terms_ids is None:\n            active_terms_dict = {}\n            active_terms_ids = []\n\n            active_terms_set = TermsAndConditions.objects.filter(date_active__isnull=False, date_active__lte=timezone.now()).order_by('date_active')\n            for active_terms in active_terms_set:\n                active_terms_dict[active_terms.slug] = active_terms.id\n\n            active_terms_dict = OrderedDict(sorted(active_terms_dict.items(), key=lambda t: t[0]))\n\n            for terms in active_terms_dict:\n                active_terms_ids.append(active_terms_dict[terms])\n\n            cache.set('tandc.active_terms_ids', active_terms_ids, TERMS_CACHE_SECONDS)\n\n        return active_terms_ids", "response": "Returns a list of the IDs of all terms and conditions"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn all the latest active terms and conditions", "response": "def get_active_terms_list():\n        \"\"\"Returns all the latest active terms and conditions\"\"\"\n\n        active_terms_list = cache.get('tandc.active_terms_list')\n        if active_terms_list is None:\n            active_terms_list = TermsAndConditions.objects.filter(id__in=TermsAndConditions.get_active_terms_ids()).order_by('slug')\n            cache.set('tandc.active_terms_list', active_terms_list, TERMS_CACHE_SECONDS)\n\n        return active_terms_list"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking to see if a user has not agreed to all the latest terms and conditions", "response": "def get_active_terms_not_agreed_to(user):\n        \"\"\"Checks to see if a specified user has agreed to all the latest terms and conditions\"\"\"\n\n        if TERMS_EXCLUDE_USERS_WITH_PERM is not None:\n            if user.has_perm(TERMS_EXCLUDE_USERS_WITH_PERM) and not user.is_superuser:\n                # Django's has_perm() returns True if is_superuser, we don't want that\n                return []\n\n        not_agreed_terms = cache.get('tandc.not_agreed_terms_' + user.get_username())\n        if not_agreed_terms is None:\n            try:\n                LOGGER.debug(\"Not Agreed Terms\")\n                not_agreed_terms = TermsAndConditions.get_active_terms_list().exclude(\n                    userterms__in=UserTermsAndConditions.objects.filter(user=user)\n                ).order_by('slug')\n\n                cache.set('tandc.not_agreed_terms_' + user.get_username(), not_agreed_terms, TERMS_CACHE_SECONDS)\n            except (TypeError, UserTermsAndConditions.DoesNotExist):\n                return []\n\n        return not_agreed_terms"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef show_terms_if_not_agreed(context, field=TERMS_HTTP_PATH_FIELD):\n    request = context['request']\n    url = urlparse(request.META[field])\n    not_agreed_terms = TermsAndConditions.get_active_terms_not_agreed_to(request.user)\n\n    if not_agreed_terms and is_path_protected(url.path):\n        return {'not_agreed_terms': not_agreed_terms, 'returnTo': url.path}\n    else:\n        return {}", "response": "Displays a small snippet showing the user s terms if they have not yet agreed to the user s terms."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if the user has accepted the terms and conditions after creation.", "response": "def user_accept_terms(backend, user, uid, social_user=None, *args, **kwargs):\n    \"\"\"Check if the user has accepted the terms and conditions after creation.\"\"\"\n\n    LOGGER.debug('user_accept_terms')\n\n    if TermsAndConditions.get_active_terms_not_agreed_to(user):\n        return redirect_to_terms_accept('/')\n    else:\n        return {'social_user': social_user, 'user': user}"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef redirect_to_terms_accept(current_path='/', slug='default'):\n    redirect_url_parts = list(urlparse(ACCEPT_TERMS_PATH))\n    if slug != 'default':\n        redirect_url_parts[2] += slug\n    querystring = QueryDict(redirect_url_parts[4], mutable=True)\n    querystring[TERMS_RETURNTO_PARAM] = current_path\n    redirect_url_parts[4] = querystring.urlencode(safe='/')\n    return HttpResponseRedirect(urlunparse(redirect_url_parts))", "response": "Redirect the user to the terms and conditions accept page."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef user_terms_updated(sender, **kwargs):\n    LOGGER.debug(\"User T&C Updated Signal Handler\")\n    if kwargs.get('instance').user:\n        cache.delete('tandc.not_agreed_terms_' + kwargs.get('instance').user.get_username())", "response": "Called when user terms and conditions are changed - to force cache clearing"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalling when terms and conditions are changed - to force cache clearing", "response": "def terms_updated(sender, **kwargs):\n    \"\"\"Called when terms and conditions is changed - to force cache clearing\"\"\"\n    LOGGER.debug(\"T&C Updated Signal Handler\")\n    cache.delete('tandc.active_terms_ids')\n    cache.delete('tandc.active_terms_list')\n    if kwargs.get('instance').slug:\n        cache.delete('tandc.active_terms_' + kwargs.get('instance').slug)\n    for utandc in UserTermsAndConditions.objects.all():\n        cache.delete('tandc.not_agreed_terms_' + utandc.user.get_username())"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npaginate the nested context variable in the current page.", "response": "def paginate(parser, token, paginator_class=None):\n    \"\"\"Paginate objects.\n\n    Usage:\n\n    .. code-block:: html+django\n\n        {% paginate entries %}\n\n    After this call, the *entries* variable in the template context is replaced\n    by only the entries of the current page.\n\n    You can also keep your *entries* original variable (usually a queryset)\n    and add to the context another name that refers to entries of the current\n    page, e.g.:\n\n    .. code-block:: html+django\n\n        {% paginate entries as page_entries %}\n\n    The *as* argument is also useful when a nested context variable is provided\n    as queryset. In this case, and only in this case, the resulting variable\n    name is mandatory, e.g.:\n\n    .. code-block:: html+django\n\n        {% paginate entries.all as entries %}\n\n    The number of paginated entries is taken from settings, but you can\n    override the default locally, e.g.:\n\n    .. code-block:: html+django\n\n        {% paginate 20 entries %}\n\n    Of course you can mix it all:\n\n    .. code-block:: html+django\n\n        {% paginate 20 entries as paginated_entries %}\n\n    By default, the first page is displayed the first time you load the page,\n    but you can change this, e.g.:\n\n    .. code-block:: html+django\n\n        {% paginate entries starting from page 3 %}\n\n    When changing the default page, it is also possible to reference the last\n    page (or the second last page, and so on) by using negative indexes, e.g:\n\n    .. code-block:: html+django\n\n        {% paginate entries starting from page -1 %}\n\n    This can be also achieved using a template variable that was passed to the\n    context, e.g.:\n\n    .. code-block:: html+django\n\n        {% paginate entries starting from page page_number %}\n\n    If the passed page number does not exist, the first page is displayed.\n\n    If you have multiple paginations in the same page, you can change the\n    querydict key for the single pagination, e.g.:\n\n    .. code-block:: html+django\n\n        {% paginate entries using article_page %}\n\n    In this case *article_page* is intended to be a context variable, but you\n    can hardcode the key using quotes, e.g.:\n\n    .. code-block:: html+django\n\n        {% paginate entries using 'articles_at_page' %}\n\n    Again, you can mix it all (the order of arguments is important):\n\n    .. code-block:: html+django\n\n        {% paginate 20 entries\n            starting from page 3 using page_key as paginated_entries %}\n\n    Additionally you can pass a path to be used for the pagination:\n\n    .. code-block:: html+django\n\n        {% paginate 20 entries\n            using page_key with pagination_url as paginated_entries %}\n\n    This way you can easily create views acting as API endpoints, and point\n    your Ajax calls to that API. In this case *pagination_url* is considered a\n    context variable, but it is also possible to hardcode the URL, e.g.:\n\n    .. code-block:: html+django\n\n        {% paginate 20 entries with \"/mypage/\" %}\n\n    If you want the first page to contain a different number of items than\n    subsequent pages, you can separate the two values with a comma, e.g. if\n    you want 3 items on the first page and 10 on other pages:\n\n    .. code-block:: html+django\n\n    {% paginate 3,10 entries %}\n\n    You must use this tag before calling the {% show_more %} one.\n    \"\"\"\n    # Validate arguments.\n    try:\n        tag_name, tag_args = token.contents.split(None, 1)\n    except ValueError:\n        msg = '%r tag requires arguments' % token.contents.split()[0]\n        raise template.TemplateSyntaxError(msg)\n\n    # Use a regexp to catch args.\n    match = PAGINATE_EXPRESSION.match(tag_args)\n    if match is None:\n        msg = 'Invalid arguments for %r tag' % tag_name\n        raise template.TemplateSyntaxError(msg)\n\n    # Retrieve objects.\n    kwargs = match.groupdict()\n    objects = kwargs.pop('objects')\n\n    # The variable name must be present if a nested context variable is passed.\n    if '.' in objects and kwargs['var_name'] is None:\n        msg = (\n            '%(tag)r tag requires a variable name `as` argumnent if the '\n            'queryset is provided as a nested context variable (%(objects)s). '\n            'You must either pass a direct queryset (e.g. taking advantage '\n            'of the `with` template tag) or provide a new variable name to '\n            'store the resulting queryset (e.g. `%(tag)s %(objects)s as '\n            'objects`).'\n        ) % {'tag': tag_name, 'objects': objects}\n        raise template.TemplateSyntaxError(msg)\n\n    # Call the node.\n    return PaginateNode(paginator_class, objects, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_pages(parser, token):\n    # Validate args.\n    try:\n        tag_name, args = token.contents.split(None, 1)\n    except ValueError:\n        var_name = 'pages'\n    else:\n        args = args.split()\n        if len(args) == 2 and args[0] == 'as':\n            var_name = args[1]\n        else:\n            msg = 'Invalid arguments for %r tag' % tag_name\n            raise template.TemplateSyntaxError(msg)\n    # Call the node.\n    return GetPagesNode(var_name)", "response": "Add to context the list of page links."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nshowing page links. Usage: .. code-block:: html+django {% show_pages %} It is just a shortcut for: .. code-block:: html+django {% get_pages %} {{ pages.get_rendered }} You can set ``ENDLESS_PAGINATION_PAGE_LIST_CALLABLE`` in your *settings.py* to a callable, or to a dotted path representing a callable, used to customize the pages that are displayed. See the *__unicode__* method of ``endless_pagination.models.PageList`` for a detailed explanation of how the callable can be used. Must be called after ``{% paginate objects %}``.", "response": "def show_pages(parser, token):\n    \"\"\"Show page links.\n\n    Usage:\n\n    .. code-block:: html+django\n\n        {% show_pages %}\n\n    It is just a shortcut for:\n\n    .. code-block:: html+django\n\n        {% get_pages %}\n        {{ pages.get_rendered }}\n\n    You can set ``ENDLESS_PAGINATION_PAGE_LIST_CALLABLE`` in your *settings.py*\n    to a callable, or to a dotted path representing a callable, used to\n    customize the pages that are displayed.\n\n    See the *__unicode__* method of ``endless_pagination.models.PageList`` for\n    a detailed explanation of how the callable can be used.\n\n    Must be called after ``{% paginate objects %}``.\n    \"\"\"\n    # Validate args.\n    if len(token.contents.split()) != 1:\n        msg = '%r tag takes no arguments' % token.contents.split()[0]\n        raise template.TemplateSyntaxError(msg)\n    # Call the node.\n    return ShowPagesNode()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef show_current_number(parser, token):\n    # Validate args.\n    try:\n        tag_name, args = token.contents.split(None, 1)\n    except ValueError:\n        key = None\n        number = None\n        tag_name = token.contents[0]\n        var_name = None\n    else:\n        # Use a regexp to catch args.\n        match = SHOW_CURRENT_NUMBER_EXPRESSION.match(args)\n        if match is None:\n            msg = 'Invalid arguments for %r tag' % tag_name\n            raise template.TemplateSyntaxError(msg)\n        # Retrieve objects.\n        groupdict = match.groupdict()\n        key = groupdict['key']\n        number = groupdict['number']\n        var_name = groupdict['var_name']\n    # Call the node.\n    return ShowCurrentNumberNode(number, key, var_name)", "response": "Show the current page number in the context."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a view dynamically switching template if the request is Ajax. Decorate a view that takes a *template* and *extra_context* keyword arguments (like generic views). The template is switched to *page_template* if request is ajax and if *querystring_key* variable passed by the request equals to *key*. This allows multiple Ajax paginations in the same page. The name of the page template is given as *page_template* in the extra context.", "response": "def page_template(template, key=PAGE_LABEL):\n    \"\"\"Return a view dynamically switching template if the request is Ajax.\n\n    Decorate a view that takes a *template* and *extra_context* keyword\n    arguments (like generic views).\n    The template is switched to *page_template* if request is ajax and\n    if *querystring_key* variable passed by the request equals to *key*.\n    This allows multiple Ajax paginations in the same page.\n    The name of the page template is given as *page_template* in the\n    extra context.\n    \"\"\"\n    def decorator(view):\n        @wraps(view)\n        def decorated(request, *args, **kwargs):\n            # Trust the developer: he wrote ``context.update(extra_context)``\n            # in his view.\n            extra_context = kwargs.setdefault('extra_context', {})\n            extra_context['page_template'] = template\n            # Switch the template when the request is Ajax.\n            querystring_key = request.GET.get(QS_KEY,\n                request.POST.get(QS_KEY, PAGE_LABEL))\n            if request.is_ajax() and querystring_key == key:\n                kwargs[TEMPLATE_VARNAME] = template\n            return view(request, *args, **kwargs)\n        return decorated\n\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the template corresponding to the given querystring_key.", "response": "def _get_template(querystring_key, mapping):\n    \"\"\"Return the template corresponding to the given ``querystring_key``.\"\"\"\n    default = None\n    try:\n        template_and_keys = mapping.items()\n    except AttributeError:\n        template_and_keys = mapping\n    for template, key in template_and_keys:\n        if key is None:\n            key = PAGE_LABEL\n            default = template\n        if key == querystring_key:\n            return template\n    return default"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef page_templates(mapping):\n    def decorator(view):\n        @wraps(view)\n        def decorated(request, *args, **kwargs):\n            # Trust the developer: he wrote ``context.update(extra_context)``\n            # in his view.\n            extra_context = kwargs.setdefault('extra_context', {})\n            querystring_key = request.GET.get(QS_KEY,\n                request.POST.get(QS_KEY, PAGE_LABEL))\n            template = _get_template(querystring_key, mapping)\n            extra_context['page_template'] = template\n            # Switch the template when the request is Ajax.\n            if request.is_ajax() and template:\n                kwargs[TEMPLATE_VARNAME] = template\n            return view(request, *args, **kwargs)\n        return decorated\n\n    return decorator", "response": "A decorator that can be used to manage multiple paginations."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_queryset(self):\n        if self.queryset is not None:\n            queryset = self.queryset\n            if hasattr(queryset, '_clone'):\n                queryset = queryset._clone()\n        elif self.model is not None:\n            queryset = self.model._default_manager.all()\n        else:\n            msg = '{0} must define ``queryset`` or ``model``'\n            raise ImproperlyConfigured(msg.format(self.__class__.__name__))\n        return queryset", "response": "Get the list of items for this view."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the name of the item to be used in the context.", "response": "def get_context_object_name(self, object_list):\n        \"\"\"Get the name of the item to be used in the context.\n\n        See original in ``django.views.generic.list.MultipleObjectMixin``.\n        \"\"\"\n        if self.context_object_name:\n            return self.context_object_name\n        elif hasattr(object_list, 'model'):\n            object_name = object_list.model._meta.object_name.lower()\n            return smart_str('{0}_list'.format(object_name))\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwrapping the get method to return 404 status code if the page parameter is invalid", "response": "def get(self, request, *args, **kwargs):\n        \"\"\"Wraps super().get(...) in order to return 404 status code if\n        the page parameter is invalid\n        \"\"\"\n        response = super().get(request, args, kwargs)\n        try:\n            response.render()\n        except Http404:\n            request.GET = request.GET.copy()\n            request.GET['page'] = '1'\n            response = super().get(request, args, kwargs)\n            response.status_code = 404\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_page_template(self, **kwargs):\n        opts = self.object_list.model._meta\n        return '{0}/{1}{2}{3}.html'.format(\n            opts.app_label,\n            opts.object_name.lower(),\n            self.template_name_suffix,\n            self.page_template_suffix,\n        )", "response": "Return the name of the page template used for this request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_template_names(self):\n        request = self.request\n        key = 'querystring_key'\n        querystring_key = request.GET.get(key,\n            request.POST.get(key, PAGE_LABEL))\n        if request.is_ajax() and querystring_key == self.key:\n            return [self.page_template or self.get_page_template()]\n        return super(\n            AjaxMultipleObjectTemplateResponseMixin, self).get_template_names()", "response": "Switch the templates for Ajax requests."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef render_link(self):\n        extra_context = {\n            'add_nofollow': settings.ADD_NOFOLLOW,\n            'page': self,\n            'querystring_key': self.querystring_key,\n        }\n        if self.is_current:\n            template_name = 'el_pagination/current_link.html'\n        else:\n            template_name = 'el_pagination/page_link.html'\n            if settings.USE_NEXT_PREVIOUS_LINKS:\n                if self.is_previous:\n                    template_name = 'el_pagination/previous_link.html'\n                if self.is_next:\n                    template_name = 'el_pagination/next_link.html'\n        if template_name not in _template_cache:\n            _template_cache[template_name] = loader.get_template(template_name)\n        template = _template_cache[template_name]\n        with self.context.push(**extra_context):\n            return template.render(self.context.flatten())", "response": "Render the page as a link."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the previous page.", "response": "def previous(self):\n        \"\"\"Return the previous page.\n\n        The page label is defined in ``settings.PREVIOUS_LABEL``.\n        Return an empty string if current page is the first.\n        \"\"\"\n        if self._page.has_previous():\n            return self._endless_page(\n                self._page.previous_page_number(),\n                label=settings.PREVIOUS_LABEL)\n        return ''"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the next page.", "response": "def next(self):\n        \"\"\"Return the next page.\n\n        The page label is defined in ``settings.NEXT_LABEL``.\n        Return an empty string if current page is the last.\n        \"\"\"\n        if self._page.has_next():\n            return self._endless_page(\n                self._page.next_page_number(),\n                label=settings.NEXT_LABEL)\n        return ''"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef start_index(self):\n        paginator = self.paginator\n        # Special case, return zero if no items.\n        if paginator.count == 0:\n            return 0\n        elif self.number == 1:\n            return 1\n        return (\n            (self.number - 2) * paginator.per_page + paginator.first_page + 1)", "response": "Return the 1 - based index of the first item on this page."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef end_index(self):\n        paginator = self.paginator\n        # Special case for the last page because there can be orphans.\n        if self.number == paginator.num_pages:\n            return paginator.count\n        return (self.number - 1) * paginator.per_page + paginator.first_page", "response": "Return the 1 - based index of the last item on this page."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndefaulting callable for page listing.", "response": "def get_page_numbers(\n        current_page, num_pages,\n        extremes=DEFAULT_CALLABLE_EXTREMES,\n        arounds=DEFAULT_CALLABLE_AROUNDS,\n        arrows=DEFAULT_CALLABLE_ARROWS):\n    \"\"\"Default callable for page listing.\n\n    Produce a Digg-style pagination.\n    \"\"\"\n    page_range = range(1, num_pages + 1)\n    pages = []\n    if current_page != 1:\n        if arrows:\n            pages.append('first')\n        pages.append('previous')\n\n    # Get first and last pages (extremes).\n    first = page_range[:extremes]\n    pages.extend(first)\n    last = page_range[-extremes:]\n\n    # Get the current pages (arounds).\n    current_start = current_page - 1 - arounds\n    if current_start < 0:\n        current_start = 0\n    current_end = current_page + arounds\n    if current_end > num_pages:\n        current_end = num_pages\n    current = page_range[current_start:current_end]\n\n    # Mix first with current pages.\n    to_add = current\n    if extremes:\n        diff = current[0] - first[-1]\n        if diff > 1:\n            pages.append(None)\n        elif diff < 1:\n            to_add = current[abs(diff) + 1:]\n    pages.extend(to_add)\n\n    # Mix current with last pages.\n    if extremes:\n        diff = last[0] - current[-1]\n        to_add = last\n        if diff > 1:\n            pages.append(None)\n        elif diff < 1:\n            to_add = last[abs(diff) + 1:]\n        pages.extend(to_add)\n\n    if current_page != num_pages:\n        pages.append('next')\n        if arrows:\n            pages.append('last')\n    return pages"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _make_elastic_range(begin, end):\n    # Limit growth for huge numbers of pages.\n    starting_factor = max(1, (end - begin) // 100)\n    factor = _iter_factors(starting_factor)\n    left_half, right_half = [], []\n    left_val, right_val = begin, end\n    right_val = end\n    while left_val < right_val:\n        left_half.append(left_val)\n        right_half.append(right_val)\n        next_factor = next(factor)\n        left_val = begin + next_factor\n        right_val = end - next_factor\n    # If the trends happen to meet exactly at one point, retain it.\n    if left_val == right_val:\n        left_half.append(left_val)\n    right_half.reverse()\n    return left_half + right_half", "response": "Generate an elastic range of pages."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_querystring_for_page(\n        request, page_number, querystring_key, default_number=1):\n    \"\"\"Return a querystring pointing to *page_number*.\"\"\"\n    querydict = request.GET.copy()\n    querydict[querystring_key] = page_number\n    # For the default page number (usually 1) the querystring is not required.\n    if page_number == default_number:\n        del querydict[querystring_key]\n    if 'querystring_key' in querydict:\n        del querydict['querystring_key']\n    if querydict:\n        return '?' + querydict.urlencode()\n    return ''", "response": "Return a querystring pointing to page_number."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading the Python object represented by dotted path.", "response": "def load_object(path):\n    \"\"\"Return the Python object represented by dotted *path*.\"\"\"\n    i = path.rfind('.')\n    module_name, object_name = path[:i], path[i + 1:]\n    # Load module.\n    try:\n        module = import_module(module_name)\n    except ImportError:\n        raise ImproperlyConfigured('Module %r not found' % module_name)\n    except ValueError:\n        raise ImproperlyConfigured('Invalid module %r' % module_name)\n    # Load object.\n    try:\n        return getattr(module, object_name)\n    except AttributeError:\n        msg = 'Module %r does not define an object named %r'\n        raise ImproperlyConfigured(msg % (module_name, object_name))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a suitable description of this field for South.", "response": "def south_field_triple(self):\n        \"Returns a suitable description of this field for South.\"\n        args, kwargs = introspector(self)\n        kwargs.update({\n            'populate_from': 'None' if callable(self.populate_from) else repr(self.populate_from),\n            'unique_with': repr(self.unique_with)\n        })\n        return ('autoslug.fields.AutoSlugField', args, kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_prepopulated_value(field, instance):\n    if hasattr(field.populate_from, '__call__'):\n        # AutoSlugField(populate_from=lambda instance: ...)\n        return field.populate_from(instance)\n    else:\n        # AutoSlugField(populate_from='foo')\n        attr = getattr(instance, field.populate_from)\n        return callable(attr) and attr() or attr", "response": "Returns preliminary value based on populate_from."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a unique slug by adding a number to given value until no model instance is found with such slug.", "response": "def generate_unique_slug(field, instance, slug, manager):\n    \"\"\"\n    Generates unique slug by adding a number to given value until no model\n    instance can be found with such slug. If ``unique_with`` (a tuple of field\n    names) was specified for the field, all these fields are included together\n    in the query when looking for a \"rival\" model instance.\n    \"\"\"\n\n    original_slug = slug = crop_slug(field, slug)\n\n    default_lookups = tuple(get_uniqueness_lookups(field, instance, field.unique_with))\n\n    index = 1\n\n    if not manager:\n        manager = field.model._default_manager\n\n\n    # keep changing the slug until it is unique\n    while True:\n        # find instances with same slug\n        lookups = dict(default_lookups, **{field.name: slug})\n        rivals = manager.filter(**lookups)\n        if instance.pk:\n            rivals = rivals.exclude(pk=instance.pk)\n\n        if not rivals:\n            # the slug is unique, no model uses it\n            return slug\n\n        # the slug is not unique; change once more\n        index += 1\n\n        # ensure the resulting string is not too long\n        tail_length = len(field.index_sep) + len(str(index))\n        combined_length = len(original_slug) + tail_length\n        if field.max_length < combined_length:\n            original_slug = original_slug[:field.max_length - tail_length]\n\n        # re-generate the slug\n        data = dict(slug=original_slug, sep=field.index_sep, index=index)\n        slug = '%(slug)s%(sep)s%(index)d' % data"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a dictable tuple of lookups to ensure uniqueness of a slug.", "response": "def get_uniqueness_lookups(field, instance, unique_with):\n    \"\"\"\n    Returns a dict'able tuple of lookups to ensure uniqueness of a slug.\n    \"\"\"\n    for original_lookup_name in unique_with:\n        if '__' in original_lookup_name:\n            field_name, inner_lookup = original_lookup_name.split('__', 1)\n        else:\n            field_name, inner_lookup = original_lookup_name, None\n\n        try:\n            other_field = instance._meta.get_field(field_name)\n        except FieldDoesNotExist:\n            raise ValueError('Could not find attribute %s.%s referenced'\n                             ' by %s.%s (see constraint `unique_with`)'\n                             % (instance._meta.object_name, field_name,\n                                instance._meta.object_name, field.name))\n\n        if field == other_field:\n            raise ValueError('Attribute %s.%s references itself in `unique_with`.'\n                             ' Please use \"unique=True\" for this case.'\n                             % (instance._meta.object_name, field_name))\n\n        value = getattr(instance, field_name)\n        if not value:\n            if other_field.blank:\n                field_object = instance._meta.get_field(field_name)\n                if isinstance(field_object, ForeignKey):\n                    lookup = '%s__isnull' % field_name\n                    yield lookup, True\n                break\n            raise ValueError('Could not check uniqueness of %s.%s with'\n                             ' respect to %s.%s because the latter is empty.'\n                             ' Please ensure that \"%s\" is declared *after*'\n                             ' all fields listed in unique_with.'\n                             % (instance._meta.object_name, field.name,\n                                instance._meta.object_name, field_name,\n                                field.name))\n        if isinstance(other_field, DateField):    # DateTimeField is a DateField subclass\n            inner_lookup = inner_lookup or 'day'\n\n            if '__' in inner_lookup:\n                raise ValueError('The `unique_with` constraint in %s.%s'\n                                 ' is set to \"%s\", but AutoSlugField only'\n                                 ' accepts one level of nesting for dates'\n                                 ' (e.g. \"date__month\").'\n                                 % (instance._meta.object_name, field.name,\n                                    original_lookup_name))\n\n            parts = ['year', 'month', 'day']\n            try:\n                granularity = parts.index(inner_lookup) + 1\n            except ValueError:\n                raise ValueError('expected one of %s, got \"%s\" in \"%s\"'\n                                    % (parts, inner_lookup, original_lookup_name))\n            else:\n                for part in parts[:granularity]:\n                    lookup = '%s__%s' % (field_name, part)\n                    yield lookup, getattr(value, part)\n        else:\n            # TODO: this part should be documented as it involves recursion\n            if inner_lookup:\n                if not hasattr(value, '_meta'):\n                    raise ValueError('Could not resolve lookup \"%s\" in `unique_with` of %s.%s'\n                                     % (original_lookup_name, instance._meta.object_name, field.name))\n                for inner_name, inner_value in get_uniqueness_lookups(field, value, [inner_lookup]):\n                    yield original_lookup_name, inner_value\n            else:\n                yield field_name, value"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the names of valid color variants given the base colors.", "response": "def derivative_colors(colors):\n    \"\"\"Return the names of valid color variants, given the base colors.\"\"\"\n    return set([('on_' + c) for c in colors] +\n               [('bright_' + c) for c in colors] +\n               [('on_bright_' + c) for c in colors])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsplit a possibly compound format string into segments.", "response": "def split_into_formatters(compound):\n    \"\"\"Split a possibly compound format string into segments.\n\n    >>> split_into_formatters('bold_underline_bright_blue_on_red')\n    ['bold', 'underline', 'bright_blue', 'on_red']\n    >>> split_into_formatters('red_no_italic_shadow_on_bright_cyan')\n    ['red', 'no_italic', 'shadow', 'on_bright_cyan']\n    \"\"\"\n    merged_segs = []\n    # These occur only as prefixes, so they can always be merged:\n    mergeable_prefixes = ['no', 'on', 'bright', 'on_bright']\n    for s in compound.split('_'):\n        if merged_segs and merged_segs[-1] in mergeable_prefixes:\n            merged_segs[-1] += '_' + s\n        else:\n            merged_segs.append(s)\n    return merged_segs"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a tuple of terminal height and terminal width.", "response": "def _height_and_width(self):\n        \"\"\"Return a tuple of (terminal height, terminal width).\n\n        Start by trying TIOCGWINSZ (Terminal I/O-Control: Get Window Size),\n        falling back to environment variables (LINES, COLUMNS), and returning\n        (None, None) if those are unavailable or invalid.\n\n        \"\"\"\n        # tigetnum('lines') and tigetnum('cols') update only if we call\n        # setupterm() again.\n        for descriptor in self._init_descriptor, sys.__stdout__:\n            try:\n                return struct.unpack(\n                        'hhhh', ioctl(descriptor, TIOCGWINSZ, '\\000' * 8))[0:2]\n            except IOError:\n                # when the output stream or init descriptor is not a tty, such\n                # as when when stdout is piped to another program, fe. tee(1),\n                # these ioctls will raise IOError\n                pass\n        try:\n            return int(environ.get('LINES')), int(environ.get('COLUMNS'))\n        except TypeError:\n            return None, None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a context manager for temporarily moving the cursor to a certain location.", "response": "def location(self, x=None, y=None):\n        \"\"\"Return a context manager for temporarily moving the cursor.\n\n        Move the cursor to a certain position on entry, let you print stuff\n        there, then return the cursor to its original position::\n\n            term = Terminal()\n            with term.location(2, 5):\n                print('Hello, world!')\n                for x in xrange(10):\n                    print('I can do it %i times!' % x)\n\n        Specify ``x`` to move to a certain column, ``y`` to move to a certain\n        row, both, or neither. If you specify neither, only the saving and\n        restoration of cursor position will happen. This can be useful if you\n        simply want to restore your place after doing some manual cursor\n        movement.\n\n        \"\"\"\n        # Save position and move to the requested column, row, or both:\n        self.stream.write(self.save)\n        if x is not None and y is not None:\n            self.stream.write(self.move(y, x))\n        elif x is not None:\n            self.stream.write(self.move_x(x))\n        elif y is not None:\n            self.stream.write(self.move_y(y))\n        try:\n            yield\n        finally:\n            # Restore original cursor position:\n            self.stream.write(self.restore)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a context manager that enters fullscreen mode while inside it and restores normal mode on leaving.", "response": "def fullscreen(self):\n        \"\"\"Return a context manager that enters fullscreen mode while inside it\n        and restores normal mode on leaving.\"\"\"\n        self.stream.write(self.enter_fullscreen)\n        try:\n            yield\n        finally:\n            self.stream.write(self.exit_fullscreen)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a context manager that hides the cursor while inside it and makes it visible on leaving.", "response": "def hidden_cursor(self):\n        \"\"\"Return a context manager that hides the cursor while inside it and\n        makes it visible on leaving.\"\"\"\n        self.stream.write(self.hide_cursor)\n        try:\n            yield\n        finally:\n            self.stream.write(self.normal_cursor)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _resolve_formatter(self, attr):\n        if attr in COLORS:\n            return self._resolve_color(attr)\n        elif attr in COMPOUNDABLES:\n            # Bold, underline, or something that takes no parameters\n            return self._formatting_string(self._resolve_capability(attr))\n        else:\n            formatters = split_into_formatters(attr)\n            if all(f in COMPOUNDABLES for f in formatters):\n                # It's a compound formatter, like \"bold_green_on_red\". Future\n                # optimization: combine all formatting into a single escape\n                # sequence.\n                return self._formatting_string(\n                    u''.join(self._resolve_formatter(s) for s in formatters))\n            else:\n                return ParametrizingString(self._resolve_capability(attr))", "response": "Resolve a sugary or plain capability name color compound\n            or parametrizingString into a callable capability."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _resolve_capability(self, atom):\n        code = tigetstr(self._sugar.get(atom, atom))\n        if code:\n            # See the comment in ParametrizingString for why this is latin1.\n            return code.decode('latin1')\n        return u''", "response": "Return a terminal code for a capname or a sugary name or an empty string Unicode."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nresolving a color like red or on_bright_green into a callable capability.", "response": "def _resolve_color(self, color):\n        \"\"\"Resolve a color like red or on_bright_green into a callable\n        capability.\"\"\"\n        # TODO: Does curses automatically exchange red and blue and cyan and\n        # yellow when a terminal supports setf/setb rather than setaf/setab?\n        # I'll be blasted if I can find any documentation. The following\n        # assumes it does.\n        color_cap = (self._background_color if 'on_' in color else\n                     self._foreground_color)\n        # curses constants go up to only 7, so add an offset to get at the\n        # bright colors at 8-15:\n        offset = 8 if 'bright_' in color else 0\n        base_color = color.rsplit('_', 1)[-1]\n        return self._formatting_string(\n            color_cap(getattr(curses, 'COLOR_' + base_color.upper()) + offset))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send_login_code(self, code, context, **kwargs):\n        from_number = self.from_number or getattr(settings, 'DEFAULT_FROM_NUMBER')\n        sms_content = render_to_string(self.template_name, context)\n\n        self.twilio_client.messages.create(\n            to=code.user.phone_number,\n            from_=from_number,\n            body=sms_content\n        )", "response": "Send a login code via SMS"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads the given t7 file using default settings.", "response": "def load(filename, **kwargs):\n    \"\"\"\n    Loads the given t7 file using default settings; kwargs are forwarded\n    to `T7Reader`.\n    \"\"\"\n    with open(filename, 'rb') as f:\n        reader = T7Reader(f, **kwargs)\n        return reader.read_obj()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_assets():\n    args = []\n    query = dict()\n    args.append(query)\n    asset_with_id = dao.get_all_listed_assets()\n    asset_ids = [a['id'] for a in asset_with_id]\n    resp_body = dict({'ids': asset_ids})\n    return Response(_sanitize_record(resp_body), 200, content_type='application/json')", "response": "Get all asset IDs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the DDO of a particular asset.", "response": "def get_ddo(did):\n    \"\"\"Get DDO of a particular asset.\n    ---\n    tags:\n      - ddo\n    parameters:\n      - name: did\n        in: path\n        description: DID of the asset.\n        required: true\n        type: string\n    responses:\n      200:\n        description: successful operation\n      404:\n        description: This asset DID is not in OceanDB\n    \"\"\"\n    try:\n        asset_record = dao.get(did)\n        return Response(_sanitize_record(asset_record), 200, content_type='application/json')\n    except Exception as e:\n        logger.error(e)\n        return f'{did} asset DID is not in OceanDB', 404"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets metadata of a particular asset", "response": "def get_metadata(did):\n    \"\"\"Get metadata of a particular asset\n    ---\n    tags:\n      - metadata\n    parameters:\n      - name: did\n        in: path\n        description: DID of the asset.\n        required: true\n        type: string\n    responses:\n      200:\n        description: successful operation.\n      404:\n        description: This asset DID is not in OceanDB.\n    \"\"\"\n    try:\n        asset_record = dao.get(did)\n        metadata = _get_metadata(asset_record['service'])\n        return Response(_sanitize_record(metadata), 200, content_type='application/json')\n    except Exception as e:\n        logger.error(e)\n        return f'{did} asset DID is not in OceanDB', 404"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef register():\n    assert isinstance(request.json, dict), 'invalid payload format.'\n    required_attributes = ['@context', 'created', 'id', 'publicKey', 'authentication', 'proof',\n                           'service']\n    required_metadata_base_attributes = ['name', 'dateCreated', 'author', 'license',\n                                         'price', 'encryptedFiles', 'type', 'checksum']\n    data = request.json\n    if not data:\n        logger.error(f'request body seems empty, expecting {required_attributes}')\n        return 400\n    msg, status = check_required_attributes(required_attributes, data, 'register')\n    if msg:\n        return msg, status\n    msg, status = check_required_attributes(required_metadata_base_attributes,\n                                            _get_base_metadata(data['service']), 'register')\n    if msg:\n        return msg, status\n    msg, status = check_no_urls_in_files(_get_base_metadata(data['service']), 'register')\n    if msg:\n        return msg, status\n    msg, status = validate_date_format(data['created'])\n    if status:\n        return msg, status\n    _record = dict()\n    _record = copy.deepcopy(data)\n    _record['created'] = datetime.strptime(data['created'], '%Y-%m-%dT%H:%M:%SZ')\n    for service in _record['service']:\n        if service['type'] == 'Metadata':\n            service_id = int(service['serviceDefinitionId'])\n            _record['service'][service_id]['metadata']['base']['datePublished'] = \\\n                datetime.strptime(f'{datetime.utcnow().replace(microsecond=0).isoformat()}Z',\n                                  '%Y-%m-%dT%H:%M:%SZ')\n            _record['service'][service_id]['metadata']['curation'] = {}\n            _record['service'][service_id]['metadata']['curation']['rating'] = 0.00\n            _record['service'][service_id]['metadata']['curation']['numVotes'] = 0\n            _record['service'][service_id]['metadata']['curation']['isListed'] = True\n    try:\n        dao.register(_record, data['id'])\n        # add new assetId to response\n        return Response(_sanitize_record(_record), 201, content_type='application/json')\n    except Exception as err:\n        logger.error(f'encounterd an error while saving the asset data to OceanDB: {str(err)}')\n        return f'Some error: {str(err)}', 500", "response": "Register a new asset with the DDO."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate the DDO of an existing asset.", "response": "def update(did):\n    \"\"\"Update DDO of an existing asset\n    ---\n    tags:\n      - ddo\n    consumes:\n      - application/json\n    parameters:\n      - in: body\n        name: body\n        required: true\n        description: DDO of the asset.\n        schema:\n          type: object\n          required:\n            - \"@context\"\n            - created\n            - id\n            - publicKey\n            - authentication\n            - proof\n            - service\n          properties:\n            \"@context\":\n              description:\n              example: https://w3id.org/future-method/v1\n              type: string\n            id:\n              description: ID of the asset.\n              example: did:op:123456789abcdefghi\n              type: string\n            created:\n              description: date of ddo creation.\n              example: \"2016-02-08T16:02:20Z\"\n              type: string\n            publicKey:\n                  type: array\n                  description: List of public keys.\n                  example: [{\"id\": \"did:op:123456789abcdefghi#keys-1\"},\n                            {\"type\": \"Ed25519VerificationKey2018\"},\n                            {\"owner\": \"did:op:123456789abcdefghi\"},\n                            {\"publicKeyBase58\": \"H3C2AVvLMv6gmMNam3uVAjZpfkcJCwDwnZn6z3wXmqPV\"}]\n            authentication:\n                  type: array\n                  description: List of authentication mechanisms.\n                  example: [{\"type\": \"RsaSignatureAuthentication2018\"},\n                            {\"publicKey\": \"did:op:123456789abcdefghi#keys-1\"}]\n            proof:\n                  type: dictionary\n                  description: Information about the creation and creator of the asset.\n                  example:  {\"type\": \"UUIDSignature\",\n                             \"created\": \"2016-02-08T16:02:20Z\",\n                             \"creator\": \"did:example:8uQhQMGzWxR8vw5P3UWH1ja\",\n                             \"signatureValue\": \"QNB13Y7Q9...1tzjn4w==\"\n                            }\n            service:\n                  type: array\n                  description: List of services.\n                  example: [{\"type\": \"Access\",\n                             \"serviceEndpoint\":\n                             \"http://mybrizo.org/api/v1/brizo/services/consume?pubKey=${\n                             pubKey}&serviceId={serviceId}&url={url}\"},\n                            {\"type\": \"Compute\",\n                             \"serviceEndpoint\":\n                             \"http://mybrizo.org/api/v1/brizo/services/compute?pubKey=${\n                             pubKey}&serviceId={serviceId}&algo={algo}&container={container}\"},\n                           {\n                            \"type\": \"Metadata\",\n                            \"serviceDefinitionId\": \"2\",\n                            \"serviceEndpoint\":\n                            \"http://myaquarius.org/api/v1/provider/assets/metadata/{did}\",\n                            \"metadata\": {\n                                \"base\": {\n                                    \"name\": \"UK Weather information 2011\",\n                                    \"type\": \"dataset\",\n                                    \"description\": \"Weather information of UK including\n                                    temperature and humidity\",\n                                    \"dateCreated\": \"2012-02-01T10:55:11Z\",\n                                    \"author\": \"Met Office\",\n                                    \"license\": \"CC-BY\",\n                                    \"copyrightHolder\": \"Met Office\",\n                                    \"compression\": \"zip\",\n                                    \"workExample\": \"stationId,latitude,longitude,datetime,\n                                    temperature,humidity/n423432fsd,51.509865,-0.118092,\n                                    2011-01-01T10:55:11+00:00,7.2,68\",\n                                    \"files\": [{\n                                            \"contentLength\": \"4535431\",\n                                            \"contentType\": \"text/csv\",\n                                            \"encoding\": \"UTF-8\",\n                                            \"compression\": \"zip\",\n                                            \"resourceId\": \"access-log2018-02-13-15-17-29-18386C502CAEA932\"\n                                    }\n                                    ],\n\n                                    \"encryptedFiles\": \"0x098213xzckasdf089723hjgdasfkjgasfv\",\n                                    \"links\": [{\n                                            \"name\": \"Sample of Asset Data\",\n                                            \"type\": \"sample\",\n                                            \"url\": \"https://foo.com/sample.csv\"\n                                        },\n                                        {\n                                            \"name\": \"Data Format Definition\",\n                                            \"type\": \"format\",\n                                            \"AssetID\":\n                                            \"4d517500da0acb0d65a716f61330969334630363ce4a6a9d39691026ac7908ea\"\n                                        }\n                                    ],\n                                    \"inLanguage\": \"en\",\n                                    \"tags\": \"weather, uk, 2011, temperature, humidity\",\n                                    \"price\": 10,\n                                    \"checksum\":\n                                    \"38803b9e6f04fce3fba4b124524672592264d31847182c689095a081c9e85262\"\n                                },\n                                \"curation\": {\n                                    \"rating\": 0.93,\n                                    \"numVotes\": 123,\n                                    \"schema\": \"Binary Voting\"\n                                },\n                                \"additionalInformation\": {\n                                    \"updateFrecuency\": \"yearly\",\n                                    \"structuredMarkup\": [{\n                                            \"uri\": \"http://skos.um.es/unescothes/C01194/jsonld\",\n                                            \"mediaType\": \"application/ld+json\"\n                                        },\n                                        {\n                                            \"uri\": \"http://skos.um.es/unescothes/C01194/turtle\",\n                                            \"mediaType\": \"text/turtle\"\n                                        }\n                                    ]\n                                }\n                            }\n                        }]\n    responses:\n      200:\n        description: Asset successfully updated.\n      201:\n        description: Asset successfully registered.\n      400:\n        description: One of the required attributes is missing.\n      404:\n        description: Invalid asset data.\n      500:\n        description: Error\n    \"\"\"\n    required_attributes = ['@context', 'created', 'id', 'publicKey', 'authentication', 'proof',\n                           'service']\n    required_metadata_base_attributes = ['name', 'dateCreated', 'author', 'license',\n                                         'price', 'encryptedFiles', 'type', 'checksum']\n    required_metadata_curation_attributes = ['rating', 'numVotes']\n\n    assert isinstance(request.json, dict), 'invalid payload format.'\n\n    data = request.json\n    if not data:\n        logger.error(f'request body seems empty, expecting {required_attributes}')\n        return 400\n    msg, status = check_required_attributes(required_attributes, data, 'update')\n    if msg:\n        return msg, status\n    msg, status = check_required_attributes(required_metadata_base_attributes,\n                                            _get_base_metadata(data['service']), 'update')\n    if msg:\n        return msg, status\n    msg, status = check_required_attributes(required_metadata_curation_attributes,\n                                            _get_curation_metadata(data['service']), 'update')\n    if msg:\n        return msg, status\n    msg, status = check_no_urls_in_files(_get_base_metadata(data['service']), 'register')\n    if msg:\n        return msg, status\n    msg, status = validate_date_format(data['created'])\n    if msg:\n        return msg, status\n\n    _record = dict()\n    _record = copy.deepcopy(data)\n    _record['created'] = datetime.strptime(data['created'], '%Y-%m-%dT%H:%M:%SZ')\n    try:\n\n        if dao.get(did) is None:\n            register()\n            return _sanitize_record(_record), 201\n        else:\n            for service in _record['service']:\n                service_id = int(service['serviceDefinitionId'])\n                if service['type'] == 'Metadata':\n                    _record['service'][service_id]['metadata']['base']['datePublished'] = _get_date(\n                        dao.get(did)['service'])\n            dao.update(_record, did)\n            return Response(_sanitize_record(_record), 200, content_type='application/json')\n    except Exception as err:\n        return f'Some error: {str(err)}', 500"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef retire(did):\n    try:\n        if dao.get(did) is None:\n            return 'This asset DID is not in OceanDB', 404\n        else:\n            dao.delete(did)\n            return 'Succesfully deleted', 200\n    except Exception as err:\n        return f'Some error: {str(err)}', 500", "response": "Retire metadata of an asset in a node"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_asset_ddos():\n    args = []\n    query = dict()\n    args.append(query)\n    assets_with_id = dao.get_all_listed_assets()\n    assets_metadata = {a['id']: a for a in assets_with_id}\n    for i in assets_metadata:\n        _sanitize_record(i)\n    return Response(json.dumps(assets_metadata, default=_my_converter), 200,\n                    content_type='application/json')", "response": "Get DDO of all assets."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nquerying the DDOs that match with the given text.", "response": "def query_text():\n    \"\"\"Get a list of DDOs that match with the given text.\n    ---\n    tags:\n      - ddo\n    parameters:\n      - name: text\n        in: query\n        description: ID of the asset.\n        required: true\n        type: string\n      - name: sort\n        in: query\n        type: object\n        description: Key or list of keys to sort the result\n        example: {\"value\":1}\n      - name: offset\n        in: query\n        type: int\n        description: Number of records per page\n        example: 100\n      - name: page\n        in: query\n        type: int\n        description: Page showed\n        example: 1\n    responses:\n      200:\n        description: successful action\n    \"\"\"\n    data = request.args\n    assert isinstance(data, dict), 'invalid `args` type, should already formatted into a dict.'\n    search_model = FullTextModel(text=data.get('text', None),\n                                 sort=None if data.get('sort', None) is None else json.loads(\n                                     data.get('sort', None)),\n                                 offset=int(data.get('offset', 100)),\n                                 page=int(data.get('page', 1)))\n    query_result = dao.query(search_model)\n    for i in query_result[0]:\n        _sanitize_record(i)\n    response = _make_paginate_response(query_result, search_model)\n    return Response(json.dumps(response, default=_my_converter), 200,\n                    content_type='application/json')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a list of DDOs that match with the executed query.", "response": "def query_ddo():\n    \"\"\"Get a list of DDOs that match with the executed query.\n    ---\n    tags:\n      - ddo\n    consumes:\n      - application/json\n    parameters:\n      - in: body\n        name: body\n        required: true\n        description: Asset metadata.\n        schema:\n          type: object\n          properties:\n            query:\n              type: string\n              description: Query to realize\n              example: {\"value\":1}\n            sort:\n              type: object\n              description: Key or list of keys to sort the result\n              example: {\"value\":1}\n            offset:\n              type: int\n              description: Number of records per page\n              example: 100\n            page:\n              type: int\n              description: Page showed\n              example: 1\n    responses:\n      200:\n        description: successful action\n    \"\"\"\n    assert isinstance(request.json, dict), 'invalid payload format.'\n    data = request.json\n    assert isinstance(data, dict), 'invalid `body` type, should be formatted as a dict.'\n    if 'query' in data:\n        search_model = QueryModel(query=data.get('query'), sort=data.get('sort'),\n                                  offset=data.get('offset', 100),\n                                  page=data.get('page', 1))\n    else:\n        search_model = QueryModel(query={}, sort=data.get('sort'),\n                                  offset=data.get('offset', 100),\n                                  page=data.get('page', 1))\n    query_result = dao.query(search_model)\n    for i in query_result[0]:\n        _sanitize_record(i)\n    response = _make_paginate_response(query_result, search_model)\n    return Response(json.dumps(response, default=_my_converter), 200,\n                    content_type='application/json')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef retire_all():\n    try:\n        all_ids = [a['id'] for a in dao.get_all_assets()]\n        for i in all_ids:\n            dao.delete(i)\n        return 'All ddo successfully deleted', 200\n    except Exception as e:\n        logger.error(e)\n        return 'An error was found', 500", "response": "Retire metadata of all the assets.\n    ---\n    tags:\n      - ddo\n    responses:\n      200:\n        description: successfully deleted\n      500:\n        description: Error"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nvalidating metadata content. --- tags: - ddo consumes: - application/json parameters: - in: body name: body required: true description: Asset metadata. schema: type: object responses: 200: description: successfully request. 500: description: Error", "response": "def validate():\n    \"\"\"Validate metadata content.\n    ---\n    tags:\n      - ddo\n    consumes:\n      - application/json\n    parameters:\n      - in: body\n        name: body\n        required: true\n        description: Asset metadata.\n        schema:\n          type: object\n    responses:\n      200:\n        description: successfully request.\n      500:\n        description: Error\n    \"\"\"\n    assert isinstance(request.json, dict), 'invalid payload format.'\n    data = request.json\n    assert isinstance(data, dict), 'invalid `body` type, should be formatted as a dict.'\n    if is_valid_dict(data):\n        return jsonify(True)\n    else:\n        error_list = list()\n        for err in list_errors_dict_local(data):\n            stack_path = list(err[1].relative_path)\n            stack_path = [str(p) for p in stack_path]\n            this_err_response = {'path': \"/\".join(stack_path), 'message': err[1].message}\n            error_list.append(this_err_response)\n        res = jsonify(error_list)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads all plugins from the active_plugins list and add them to the bot_plugins list.", "response": "def load_plugins(self):\n        ''' Given a set of plugin_path strings (directory names on the python path),\n        load any classes with Plugin in the name from any files within those dirs.\n        '''\n        self._dbg(\"Loading plugins\")\n        if not self.active_plugins:\n            self._dbg(\"No plugins specified in conf file\")\n            return  # nothing to load\n\n        for plugin_path in self.active_plugins:\n            self._dbg(\"Importing {}\".format(plugin_path))\n\n            if self.debug is True:\n                # this makes the plugin fail with stack trace in debug mode\n                cls = import_string(plugin_path)\n            else:\n                # otherwise we log the exception and carry on\n                try:\n                    cls = import_string(plugin_path)\n                except ImportError as error:\n                    logging.exception(\"Problem importing {} - {}\".format(\n                        plugin_path, error)\n                    )\n\n            plugin_config = self.config.get(cls.__name__, {})\n            plugin = cls(slack_client=self.slack_client, plugin_config=plugin_config)  # instatiate!\n            self.bot_plugins.append(plugin)\n            self._dbg(\"Plugin registered: {}\".format(plugin))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check(self):\n        ''' Returns True if `interval` seconds have passed since it last ran '''\n        if self.lastrun + self.interval < time.time():\n            return True\n        else:\n            return False", "response": "Returns True if interval seconds have passed since it last ran"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef transaction(self, request):\n        request_url = request.build_absolute_uri()\n        parsed_url = urlparse.urlparse(request_url)\n        query = parsed_url.query\n        dd = dict(map(lambda x: x.split(\"=\"), query.split(\"&\")))\n        resp = self.purchase(100, dd)\n        return HttpResponseRedirect(\"%s?status=%s\" %(reverse(\"app_offsite_amazon_fps\"),\n                                resp[\"status\"]))", "response": "This method is used to check the user id or uniquely\n        identifiable attribute against a user id or uniquely\n        identifiable attribute and then call the purchase method to get charged."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconstructs a FeatureUnion from the given transformers.", "response": "def make_union(*transformers, **kwargs):\n    \"\"\"Construct a FeatureUnion from the given transformers.\n\n    This is a shorthand for the FeatureUnion constructor; it does not require,\n    and does not permit, naming the transformers. Instead, they will be given\n    names automatically based on their types. It also does not allow weighting.\n\n    Parameters\n    ----------\n    *transformers : list of estimators\n\n    n_jobs : int, optional\n        Number of jobs to run in parallel (default 1).\n\n    Returns\n    -------\n    f : FeatureUnion\n\n    Examples\n    --------\n    >>> from sklearn.decomposition import PCA, TruncatedSVD\n    >>> from sklearn.pipeline import make_union\n    >>> make_union(PCA(), TruncatedSVD())    # doctest: +NORMALIZE_WHITESPACE\n    FeatureUnion(n_jobs=1,\n           transformer_list=[('pca',\n                              PCA(copy=True, iterated_power='auto',\n                                  n_components=None, random_state=None,\n                                  svd_solver='auto', tol=0.0, whiten=False)),\n                             ('truncatedsvd',\n                              TruncatedSVD(algorithm='randomized',\n                              n_components=2, n_iter=5,\n                              random_state=None, tol=0.0))],\n           transformer_weights=None)\n    \"\"\"\n    n_jobs = kwargs.pop('n_jobs', 1)\n    concatenate = kwargs.pop('concatenate', True)\n    if kwargs:\n       # We do not currently support `transformer_weights` as we may want to\n       # change its type spec in make_union\n       raise TypeError('Unknown keyword arguments: \"{}\"'\n                       .format(list(kwargs.keys())[0]))\n    return FeatureUnion(_name_estimators(transformers), n_jobs= n_jobs, concatenate= concatenate)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _iter(self):\n        get_weight = (self.transformer_weights or {}).get\n        return ((name, trans, get_weight(name))\n                for name, trans in self.transformer_list\n                if trans is not None)", "response": "Iterate over the available transformers and return a list of tuples excluding None transformers"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_feature_names(self):\n        feature_names = []\n        for name, trans, weight in self._iter():\n            if not hasattr(trans, 'get_feature_names'):\n                raise AttributeError(\"Transformer %s (type %s) does not \"\n                                     \"provide get_feature_names.\"\n                                     % (str(name), type(trans).__name__))\n            feature_names.extend([name + \"__\" + f for f in\n                                  trans.get_feature_names()])\n        return feature_names", "response": "Get feature names from all transformers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfit all transformers using X.", "response": "def fit(self, X, y=None):\n        \"\"\"Fit all transformers using X.\n\n        Parameters\n        ----------\n        X : iterable or array-like, depending on transformers\n            Input data, used to fit transformers.\n\n        y : array-like, shape (n_samples, ...), optional\n            Targets for supervised learning.\n\n        Returns\n        -------\n        self : FeatureUnion\n            This estimator\n        \"\"\"\n        self.transformer_list = list(self.transformer_list)\n        self._validate_transformers()\n        with Pool(self.n_jobs) as pool:\n            transformers = pool.starmap(_fit_one_transformer,\n                        ((trans, X[trans['col_pick']] if hasattr(trans, 'col_pick') else X, y) for _, trans, _ in self._iter()))\n        self._update_transformer_list(transformers)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fit_transform(self, X, y=None, **fit_params):\n        self._validate_transformers()\n        with Pool(self.n_jobs) as pool:\n            result = pool.starmap(_fit_transform_one,\n                         ((trans, weight, X[trans['col_pick']] if hasattr(trans, 'col_pick') else X, y)\n                          for name, trans, weight in self._iter()))\n        if not result:\n            # All transformers are None\n            return np.zeros((X.shape[0], 0))\n        Xs, transformers = zip(*result)\n        self._update_transformer_list(transformers)\n        if self.concatenate:\n            if any(sparse.issparse(f) for f in Xs):\n                Xs = sparse.hstack(Xs).tocsr()\n            else:\n                Xs = np.hstack(Xs)\n        return Xs", "response": "Fit all transformers transform the data and concatenate results."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntransform X separately by each transformer concatenate results.", "response": "def transform(self, X):\n        \"\"\"Transform X separately by each transformer, concatenate results.\n\n        Parameters\n        ----------\n        X : iterable or array-like, depending on transformers\n            Input data to be transformed.\n\n        Returns\n        -------\n        X_t : array-like or sparse matrix, shape (n_samples, sum_n_components)\n            hstack of results of transformers. sum_n_components is the\n            sum of n_components (output dimension) over transformers.\n        \"\"\"\n        with Pool(self.n_jobs) as pool:\n            Xs = pool.starmap(_transform_one, ((trans, weight, X[trans['col_pick']] if hasattr(trans, 'col_pick')\n                    else X) for name, trans, weight in self._iter()))\n        if not Xs:\n            # All transformers are None\n            return np.zeros((X.shape[0], 0))\n        if self.concatenate:\n            if any(sparse.issparse(f) for f in Xs):\n                Xs = sparse.hstack(Xs).tocsr()\n            else:\n                Xs = np.hstack(Xs)\n        return Xs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsplitting data into minibatches with a specified size.", "response": "def split_batches(self, data, minibatch_size= None):\n\t\t\"\"\"Split data into minibatches with a specified size\n\n\t\tParameters\n\t\t----------\n\t\tdata: iterable and indexable\n\t\t\tList-like data to be split into batches. Includes spark_contextipy matrices and Pandas DataFrames.\n\n\t\tminibatch_size: int\n\t\t\tExpected sizes of minibatches split from the data.\n\n\t\tReturns\n\t\t-------\n\t\tdata_split: list\n\t\t\tList of minibatches, each entry is a list-like object representing the data subset in a batch.\n\t\t\"\"\"\n\t\tif minibatch_size==None: minibatch_size= self.minibatch_size\n\t\tif isinstance(data, list) or isinstance(data, tuple):  len_data= len(data)\n\t\telse:  len_data= data.shape[0]\n\t\tif isinstance(data,pd.DataFrame):\n\t\t\tdata_split = [data.iloc[x * minibatch_size:(x + 1) * minibatch_size] for x in\n\t\t\t\t\t\t  range(int(ceil(len_data / minibatch_size)))]\n\t\telse:\n\t\t\tdata_split= [data[x* minibatch_size:min(len_data, (x+1)*minibatch_size)]\n\t\t\t\t\t\t for x in range(int(ceil(len_data/minibatch_size)))]\n\t\treturn data_split"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmerging a list of data minibatches into one single instance representing the data", "response": "def merge_batches(self, data):\n\t\t\"\"\"Merge a list of data minibatches into one single instance representing the data\n\n\t\tParameters\n\t\t----------\n\t\tdata: list\n\t\t\tList of minibatches to merge\n\n\t\tReturns\n\t\t-------\n\t\t(anonymous): sparse matrix | pd.DataFrame | list\n\t\t\tSingle complete list-like data merged from given batches\n\t\t\"\"\"\n\t\tif isinstance(data[0], ssp.csr_matrix):  return ssp.vstack(data)\n\t\tif isinstance(data[0], pd.DataFrame) or isinstance(data[0], pd.Series):  return pd.concat(data)\n\t\treturn [item for sublist in data for item in sublist]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nshuffles a list of samples as well as the labels.", "response": "def shuffle_batch(self, texts, labels= None, seed= None):\n\t\t\"\"\"Shuffle a list of samples, as well as the labels if specified\n\n\t\tParameters\n\t\t----------\n\t\ttexts: list-like\n\t\t\tList of samples to shuffle\n\n\t\tlabels: list-like (optional)\n\t\t\tList of labels to shuffle, should be correspondent to the samples given\n\n\t\tseed: int\n\t\t\tThe seed of the pseudo random number generator to use for shuffling\n\n\t\tReturns\n\t\t-------\n\t\ttexts: list\n\t\t\tList of shuffled samples (texts parameters)\n\n\t\tlabels: list (optional)\n\t\t\tList of shuffled labels. This will only be returned when non-None\n\t\t\tlabels is passed\n\t\t\"\"\"\n\t\tif seed!=None:  random.seed(seed)\n\t\tindex_shuf= list(range(len(texts)))\n\t\trandom.shuffle(index_shuf)\n\t\ttexts= [texts[x] for x in index_shuf]\n\t\tif labels==None:  return texts\n\t\tlabels= [labels[x] for x in index_shuf]\n\t\treturn texts, labels"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parametric_line(x, y):\n    if len(x) != len(y):\n        raise ValueError(\"Arrays must be the same length\")\n\n    X = np.ones((len(x), len(x)))*np.nan\n    Y = X.copy()\n\n    for i in range(len(x)):\n        X[i, :(i+1)] = x[:(i+1)]\n        Y[i, :(i+1)] = y[:(i+1)]\n    return X, Y", "response": "This function returns the two arrays x and y in order to compute the parametric line."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef demeshgrid(arr):\n    dim = len(arr.shape)\n    for i in range(dim):\n        Slice1 = [0]*dim\n        Slice2 = [1]*dim\n        Slice1[i] = slice(None)\n        Slice2[i] = slice(None)\n        if (arr[tuple(Slice1)] == arr[tuple(Slice2)]).all():\n            return arr[tuple(Slice1)]", "response": "Turns an ndarray created by a meshgrid back into a 1D array\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef toggle(self, ax=None):\n        if ax is None:\n            adjust_plot = {'bottom': .2}\n            rect = [.78, .03, .1, .07]\n\n            plt.subplots_adjust(**adjust_plot)\n            self.button_ax = plt.axes(rect)\n        else:\n            self.button_ax = ax\n\n        self.button = Button(self.button_ax, \"Pause\")\n        self.button.label2 = self.button_ax.text(\n            0.5, 0.5, 'Play',\n            verticalalignment='center',\n            horizontalalignment='center',\n            transform=self.button_ax.transAxes\n        )\n        self.button.label2.set_visible(False)\n\n        def pause(event):\n            if self._pause:\n                self.animation.event_source.start()\n                self.button.label.set_visible(True)\n                self.button.label2.set_visible(False)\n            else:\n                self.animation.event_source.stop()\n                self.button.label.set_visible(False)\n                self.button.label2.set_visible(True)\n            self.fig.canvas.draw()\n            self._pause ^= True\n        self.button.on_clicked(pause)", "response": "Creates a play button to start or stop the animation."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a timeline slider.", "response": "def timeline_slider(self, text='Time', ax=None, valfmt=None, color=None):\n        \"\"\"Creates a timeline slider.\n\n        Parameters\n        ----------\n        text : str, optional\n            The text to display for the slider. Defaults to 'Time'\n        ax : matplotlib.axes.Axes, optional\n            The matplotlib axes to attach the slider to.\n        valfmt : str, optional\n            a format specifier used to print the time\n            Defaults to '%s' for datetime64, timedelta64 and '%1.2f' otherwise.\n        color :\n            The color of the slider.\n        \"\"\"\n        if ax is None:\n            adjust_plot = {'bottom': .2}\n            rect = [.18, .05, .5, .03]\n\n            plt.subplots_adjust(**adjust_plot)\n            self.slider_ax = plt.axes(rect)\n        else:\n            self.slider_ax = ax\n\n        if valfmt is None:\n            if (np.issubdtype(self.timeline.t.dtype, np.datetime64)\n               or np.issubdtype(self.timeline.t.dtype, np.timedelta64)):\n                valfmt = '%s'\n            else:\n                valfmt = '%1.2f'\n\n        if self.timeline.log:\n            valfmt = '$10^{%s}$' % valfmt\n\n        self.slider = Slider(\n            self.slider_ax, text, 0, self.timeline._len-1,\n            valinit=0,\n            valfmt=(valfmt+self.timeline.units),\n            valstep=1, color=color\n        )\n        self._has_slider = True\n\n        def set_time(t):\n            self.timeline.index = int(self.slider.val)\n            self.slider.valtext.set_text(\n                self.slider.valfmt % (self.timeline[self.timeline.index]))\n            if self._pause:\n                for block in self.blocks:\n                    block._update(self.timeline.index)\n                self.fig.canvas.draw()\n        self.slider.on_changed(set_time)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate interactive controls for the animation", "response": "def controls(self, timeline_slider_args={}, toggle_args={}):\n        \"\"\"Creates interactive controls for the animation\n\n        Creates both a play/pause button, and a time slider at once\n\n        Parameters\n        ----------\n        timeline_slider_args : Dict, optional\n            A dictionary of arguments to be passed to timeline_slider()\n        toggle_args : Dict, optional\n            A dictionary of argyments to be passed to toggle()\n        \"\"\"\n        self.timeline_slider(**timeline_slider_args)\n        self.toggle(**toggle_args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsaves the animation to a gif file.", "response": "def save_gif(self, filename):\n        \"\"\"Saves the animation to a gif\n\n        A convience function. Provided to let the user avoid dealing\n        with writers.\n\n        Parameters\n        ----------\n        filename : str\n            the name of the file to be created without the file extension\n        \"\"\"\n        self.timeline.index -= 1  # required for proper starting point for save\n        self.animation.save(filename+'.gif', writer=PillowWriter(fps=self.timeline.fps))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsaving an animation with the given arguments.", "response": "def save(self, *args, **kwargs):\n        \"\"\"Saves an animation\n\n        A wrapper around :meth:`matplotlib.animation.Animation.save`\n        \"\"\"\n        self.timeline.index -= 1  # required for proper starting point for save\n        self.animation.save(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nproduce an animation of vector fields", "response": "def vector_comp(X, Y, U, V, skip=5, *, t_axis=0, pcolor_kw={}, quiver_kw={}):\n    \"\"\"produces an animation of vector fields\n\n    This takes 2D vector field, and plots the magnitude as a pcolomesh, and the\n    normalized direction as a quiver plot. It then animates it.\n\n    This is a convience function. It wraps around the Pcolormesh and Quiver\n    blocks. It will be more restrictive than using the blocks themselves. If\n    you need more control, or the ability to pass data in as a list, then use\n    the individual blocks.\n\n    Parameters\n    ----------\n    X : 2D numpy array\n        The x location of the vectors to be animated\n    Y : 2D numpy array\n        The x location of the vectors to be animated\n    U : 3D numpy array\n        The x components of the vectors to be animated.\n    V : 3D numpy array\n        The y components of the vectors to be animated.\n    skip : int, optional\n        The amount of values to skip over when making the quiver plot.\n        Higher skip means fewer arrows. For best results, the skip should\n        divide the length of the data-1. Defaults to 5.\n    t_axis : int, optional\n        The axis of the U, V array's the represent time. Defaults to 0. Note\n        this is different from the defaults that blocks choose. This default\n        is chosen to be consistent with 3D-meshgrids (meshgrid(x, y, t)).\n    pcolor_kw : dict, optional\n        A dictionary of parameters to pass to pcolormesh.\n    quiver_kw : dict, optional\n        A dictionary of parameters to pass to quiver.\n\n    Returns\n    -------\n    list of Animatplot.blocks.Block\n        A list of all the blocks used in the animation. The list\n        contains a Pcolorblock, and a Quiver block in that order.\n    \"\"\"\n    # plot the magnitude of the vectors as a pcolormesh\n    magnitude = np.sqrt(U**2+V**2)\n    pcolor_block = Pcolormesh(X, Y, magnitude, t_axis=t_axis, **pcolor_kw)\n\n    # use a subset of the data to plot the arrows as a quiver plot.\n    xy_slice = tuple([slice(None, None, skip)]*len(X.shape))\n\n    uv_slice = [slice(None, None, skip)]*len(U.shape)\n    uv_slice[t_axis] = slice(None)\n    uv_slice = tuple(uv_slice)\n\n    quiver_block = Quiver(X[xy_slice], Y[xy_slice],\n                          U[uv_slice]/magnitude[uv_slice],\n                          V[uv_slice]/magnitude[uv_slice],\n                          t_axis=t_axis, **quiver_kw)\n\n    return [pcolor_block, quiver_block]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef vector_plot(X, Y, U, V, t, skip=5, *, t_axis=0, units='', fps=10,\n                pcolor_kw={}, quiver_kw={}):\n    \"\"\"produces an animation of vector fields\n\n    This takes 2D vector field, and plots the magnitude as a pcolomesh, and the\n    normalized direction as a quiver plot. It then animates it.\n\n    This is a convience function. It wraps around the Pcolormesh and Quiver\n    blocks. It will be more restrictive than using the blocks themselves. If\n    you need more control, or the ability to pass data in as a list, then use\n    the individual blocks.\n\n    Parameters\n    ----------\n    X : 2D numpy array\n        The x location of the vectors to be animated\n    Y : 2D numpy array\n        The x location of the vectors to be animated\n    U : 3D numpy array\n        The x components of the vectors to be animated.\n    V : 3D numpy array\n        The y components of the vectors to be animated.\n    t : 1D numpy array\n        The time values\n    skip : int, optional\n        The amount of values to skip over when making the quiver plot.\n        Higher skip means fewer arrows. For best results, the skip should\n        divide the length of the data-1. Defaults to 5.\n    t_axis : int, optional\n        The axis of the U, V array's the represent time. Defaults to 0. Note\n        this is different from the defaults that blocks choose. This default\n        is chosen to be consistent with 3D-meshgrids (meshgrid(x, y, t)).\n    fps : int, optional\n        The frames per second to display the animation at.\n    units : str, optional\n        The units to display on the timeline.\n    pcolor_kw : dict, optional\n        A dictionary of parameters to pass to pcolormesh.\n    quiver_kw : dict, optional\n        A dictionary of parameters to pass to quiver.\n\n    Returns\n    -------\n    Animatplot.Animation\n        The complete animation\n    list of Animatplot.blocks.Block\n        A list of all the blocks used in the animation. The list\n        contains a Pcolorblock, and a Quiver block in that order.\n    Animatplot.Timeline\n        The timeline that was generated for the animation.\n    \"\"\"\n    # plot the magnitude of the vectors as a pcolormesh\n    blocks = vector_comp(X, Y, U, V, skip, t_axis=t_axis,\n                         pcolor_kw=pcolor_kw, quiver_kw=quiver_kw)\n\n    # create the animation\n    timeline = Timeline(t, units=units, fps=fps)\n    anim = Animation(blocks, timeline)\n\n    return anim, blocks, timeline", "response": "produces an animation of vector fields"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if an element from a list is the only element of a string.", "response": "def isin_alone(elems, line):\n    \"\"\"Check if an element from a list is the only element of a string.\n\n    :type elems: list\n    :type line: str\n\n    \"\"\"\n    found = False\n    for e in elems:\n        if line.strip().lower() == e.lower():\n            found = True\n            break\n    return found"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if an element from a list starts a string.", "response": "def isin_start(elems, line):\n    \"\"\"Check if an element from a list starts a string.\n\n    :type elems: list\n    :type line: str\n\n    \"\"\"\n    found = False\n    elems = [elems] if type(elems) is not list else elems\n    for e in elems:\n        if line.lstrip().lower().startswith(e):\n            found = True\n            break\n    return found"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef isin(elems, line):\n    found = False\n    for e in elems:\n        if e in line.lower():\n            found = True\n            break\n    return found", "response": "Check if an element from a list is in a string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the leading spaces of a string if it is not empty", "response": "def get_leading_spaces(data):\n    \"\"\"Get the leading space of a string if it is not empty\n\n    :type data: str\n\n    \"\"\"\n    spaces = ''\n    m = re.match(r'^(\\s*)', data)\n    if m:\n        spaces = m.group(1)\n    return spaces"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the list of a key elements.", "response": "def get_list_key(self, data, key, header_lines=1):\n        \"\"\"Get the list of a key elements.\n        Each element is a tuple (key=None, description, type=None).\n        Note that the tuple's element can differ depending on the key.\n\n        :param data: the data to proceed\n        :param key: the key\n\n        \"\"\"\n        data = data.splitlines()\n        init = self.get_section_key_line(data, key)\n        if init == -1:\n            return []\n        start, end = self.get_next_section_lines(data[init:])\n        # get the spacing of line with key\n        spaces = get_leading_spaces(data[init + start])\n        start += init + header_lines\n        if end != -1:\n            end += init\n        else:\n            end = len(data)\n\n        return self._get_list_key(spaces, data[start:end])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the list of exceptions.", "response": "def get_raise_list(self, data):\n        \"\"\"Get the list of exceptions.\n        The list contains tuples (name, desc)\n\n        :param data: the data to proceed\n\n        \"\"\"\n        return_list = []\n        lst = self.get_list_key(data, 'raise')\n        for l in lst:\n            # assume raises are only a name and a description\n            name, desc, _ = l\n            return_list.append((name, desc))\n\n        return return_list"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the list of returned values.", "response": "def get_return_list(self, data):\n        \"\"\"Get the list of returned values.\n        The list contains tuples (name=None, desc, type=None)\n\n        :param data: the data to proceed\n\n        \"\"\"\n        return_list = []\n        lst = self.get_list_key(data, 'return')\n        for l in lst:\n            name, desc, rtype = l\n            if l[2] is None:\n                rtype = l[0]\n                name = None\n                desc = desc.strip()\n            return_list.append((name, desc, rtype))\n\n        return return_list"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_next_section_lines(self, data):\n        end = -1\n        start = self.get_next_section_start_line(data)\n        if start != -1:\n            end = self.get_next_section_start_line(data[start + 1:])\n        return start, end", "response": "This function returns the starting line number and ending line number of the next section."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_key_section_header(self, key, spaces):\n        if key in self.section_headers:\n            header = self.section_headers[key]\n        else:\n            return ''\n\n        return header", "response": "Get the key of the section header"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_section_key_line(self, data, key, opt_extension=''):\n        start = 0\n        init = 0\n        while start != -1:\n            start = self.get_next_section_start_line(data[init:])\n            init += start\n            if start != -1:\n                if data[init].strip().lower() == self.opt[key] + opt_extension:\n                    break\n                init += 1\n        if start != -1:\n            start = init\n        return start", "response": "Get the next section line for a given key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_next_section_start_line(self, data):\n        start = -1\n        for i, line in enumerate(data):\n            if start != -1:\n                # we found the key so check if this is the underline\n                if line.strip() and isin_alone(['-' * len(line.strip())], line):\n                    break\n                else:\n                    start = -1\n            if isin_alone(self.opt.values(), line):\n                start = i\n        return start", "response": "This method returns the starting line number of next section. It will return - 1 if no next section was found."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_list_key(self, data, key, header_lines=2):\n        return super(NumpydocTools, self).get_list_key(data, key, header_lines=header_lines)", "response": "Get the list of a key elements."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_raw_not_managed(self, data):\n        keys = ['also', 'ref', 'note', 'other', 'example', 'method', 'attr']\n        elems = [self.opt[k] for k in self.opt if k in keys]\n        data = data.splitlines()\n        start = 0\n        init = 0\n        raw = ''\n        spaces = None\n        while start != -1:\n            start, end = self.get_next_section_lines(data[init:])\n            if start != -1:\n                init += start\n                if isin_alone(elems, data[init]) and \\\n                        not isin_alone([self.opt[e] for e in self.excluded_sections], data[init]):\n                    spaces = get_leading_spaces(data[init])\n                    if end != -1:\n                        section = [d.replace(spaces, '', 1).rstrip() for d in data[init:init + end]]\n                    else:\n                        section = [d.replace(spaces, '', 1).rstrip() for d in data[init:]]\n                    raw += '\\n'.join(section) + '\\n'\n                init += 2\n        return raw", "response": "Get elements not managed. They can be used as is."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_key_section_header(self, key, spaces):\n        header = super(NumpydocTools, self).get_key_section_header(key, spaces)\n        header = spaces + header + '\\n' + spaces + '-' * len(header) + '\\n'\n        return header", "response": "Get the key of the header section"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_section_key_line(self, data, key, opt_extension=':'):\n        return super(GoogledocTools, self).get_section_key_line(data, key, opt_extension)", "response": "Get the next section line for a given key."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the starting line number of next section.", "response": "def get_next_section_start_line(self, data):\n        \"\"\"Get the starting line number of next section.\n        It will return -1 if no section was found.\n        The section is a section key (e.g. 'Parameters:')\n        then the content\n\n        :param data: a list of strings containing the docstring's lines\n        :returns: the index of next section else -1\n\n        \"\"\"\n        start = -1\n        for i, line in enumerate(data):\n            if isin_alone([k + \":\" for k in self.opt.values()], line):\n                start = i\n                break\n        return start"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_key_section_header(self, key, spaces):\n        header = super(GoogledocTools, self).get_key_section_header(key, spaces)\n        header = spaces + header + ':' + '\\n'\n        return header", "response": "Get the key of the section header"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_available_styles(self):\n        options_tagstyle = {'keys': ['param', 'type', 'returns', 'return', 'rtype', 'raise'],\n                            'styles': {'javadoc': ('@', ':'),  # tuple:  key prefix, separator\n                                       'reST': (':', ':'),\n                                       'cstyle': ('\\\\', ' ')}\n                           }\n        self.tagstyles = list(options_tagstyle['styles'].keys())\n        for op in options_tagstyle['keys']:\n            self.opt[op] = {}\n            for style in options_tagstyle['styles']:\n                self.opt[op][style] = {'name': options_tagstyle['styles'][style][0] + op,\n                                       'sep': options_tagstyle['styles'][style][1]\n                                      }\n        self.opt['return']['reST']['name'] = ':returns'\n        self.opt['raise']['reST']['name'] = ':raises'\n        self.groups = {\n                    'param': ['params', 'args', 'parameters', 'arguments'],\n                    'return': ['returns', 'return'],\n                    'raise': ['raises', 'exceptions', 'raise', 'exception']\n                    }", "response": "Set the internal styles list and available options in a structure as following"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef autodetect_style(self, data):\n        # evaluate styles with keys\n\n        found_keys = defaultdict(int)\n        for style in self.tagstyles:\n            for key in self.opt:\n                found_keys[style] += data.count(self.opt[key][style]['name'])\n        fkey = max(found_keys, key=found_keys.get)\n        detected_style = fkey if found_keys[fkey] else 'unknown'\n\n        # evaluate styles with groups\n\n        if detected_style == 'unknown':\n            found_groups = 0\n            found_googledoc = 0\n            found_numpydoc = 0\n            found_numpydocsep = 0\n            for line in data.strip().splitlines():\n                for key in self.groups:\n                    found_groups += 1 if isin_start(self.groups[key], line) else 0\n                for key in self.googledoc:\n                    found_googledoc += 1 if isin_start(self.googledoc[key], line) else 0\n                for key in self.numpydoc:\n                    found_numpydoc += 1 if isin_start(self.numpydoc[key], line) else 0\n                if line.strip() and isin_alone(['-' * len(line.strip())], line):\n                    found_numpydocsep += 1\n                elif isin(self.numpydoc.keywords, line):\n                    found_numpydoc += 1\n            # TODO: check if not necessary to have > 1??\n            if found_numpydoc and found_numpydocsep:\n                detected_style = 'numpydoc'\n            elif found_googledoc >= found_groups:\n                detected_style = 'google'\n            elif found_groups:\n                detected_style = 'groups'\n        self.style['in'] = detected_style\n\n        return detected_style", "response": "Determine the style of a docstring and set it as the default input one for the instance."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_options(self, style):\n        return [self.opt[o][style]['name'] for o in self.opt]", "response": "Get the list of keywords for a particular style"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_key(self, key, target='in'):\n        target = 'out' if target == 'out' else 'in'\n        return self.opt[key][self.style[target]]['name']", "response": "Get the name of a key in current style."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_sep(self, key='param', target='in'):\n        target = 'out' if target == 'out' else 'in'\n        if self.style[target] in ['numpydoc', 'google']:\n            return ''\n        return self.opt[key][self.style[target]]['sep']", "response": "Get the separator of current style."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the next group - style key s line number.", "response": "def get_group_key_line(self, data, key):\n        \"\"\"Get the next group-style key's line number.\n\n        :param data: string to parse\n        :param key: the key category\n        :returns: the found line number else -1\n\n        \"\"\"\n        idx = -1\n        for i, line in enumerate(data.splitlines()):\n            if isin_start(self.groups[key], line):\n                idx = i\n        return idx"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_group_key_index(self, data, key):\n        idx = -1\n        li = self.get_group_key_line(data, key)\n        if li != -1:\n            idx = 0\n            for line in data.splitlines()[:li]:\n                idx += len(line) + len('\\n')\n        return idx", "response": "Get the next groups style s starting line index for a key category"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_group_line(self, data):\n        idx = -1\n        for key in self.groups:\n            i = self.get_group_key_line(data, key)\n            if (i < idx and i != -1) or idx == -1:\n                idx = i\n        return idx", "response": "Get the next group - style key s line."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the next groups style s starting line index", "response": "def get_group_index(self, data):\n        \"\"\"Get the next groups style's starting line index\n\n        :param data: string to parse\n        :returns: the index if found else -1\n\n        \"\"\"\n        idx = -1\n        li = self.get_group_line(data)\n        if li != -1:\n            idx = 0\n            for line in data.splitlines()[:li]:\n                idx += len(line) + len('\\n')\n        return idx"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_key_index(self, data, key, starting=True):\n        key = self.opt[key][self.style['in']]['name']\n        if key.startswith(':returns'):\n            data = data.replace(':return:', ':returns:')  # see issue 9\n        idx = len(data)\n        ini = 0\n        loop = True\n        if key in data:\n            while loop:\n                i = data.find(key)\n                if i != -1:\n                    if starting:\n                        if not data[:i].rstrip(' \\t').endswith('\\n') and len(data[:i].strip()) > 0:\n                            ini = i + 1\n                            data = data[ini:]\n                        else:\n                            idx = ini + i\n                            loop = False\n                    else:\n                        idx = ini + i\n                        loop = False\n                else:\n                    loop = False\n        if idx == len(data):\n            idx = -1\n        return idx", "response": "Get from a docstring the next option with a given key."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget from a docstring the next option.", "response": "def get_elem_index(self, data, starting=True):\n        \"\"\"Get from a docstring the next option.\n        In javadoc style it could be @param, @return, @type,...\n\n        :param data: string to parse\n        :param starting: does the key element must start the line (Default value = True)\n        :type starting: boolean\n        :returns: index of found element else -1\n        :rtype: integer\n\n        \"\"\"\n        idx = len(data)\n        for opt in self.opt.keys():\n            i = self.get_key_index(data, opt, starting)\n            if i < idx and i != -1:\n                idx = i\n        if idx == len(data):\n            idx = -1\n        return idx"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_raise_indexes(self, data):\n        start, end = -1, -1\n        stl_param = self.opt['raise'][self.style['in']]['name']\n        if self.style['in'] in self.tagstyles + ['unknown']:\n            idx_p = self.get_key_index(data, 'raise')\n            if idx_p >= 0:\n                idx_p += len(stl_param)\n                m = re.match(RAISES_NAME_REGEX, data[idx_p:].strip())\n                if m:\n                    param = m.group(1)\n                    start = idx_p + data[idx_p:].find(param)\n                    end = start + len(param)\n\n        if self.style['in'] in ['groups', 'unknown'] and (start, end) == (-1, -1):\n            # search = '\\s*(%s)' % '|'.join(self.groups['param'])\n            # m = re.match(search, data.lower())\n            # if m:\n            #    key_param = m.group(1)\n            pass\n\n        return start, end", "response": "Get from a docstring the next raise name indexes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting from a docstring the next raise s description.", "response": "def get_raise_description_indexes(self, data, prev=None):\n        \"\"\"Get from a docstring the next raise's description.\n        In javadoc style it is after @param.\n\n        :param data: string to parse\n        :param prev: index after the param element name (Default value = None)\n        :returns: start and end indexes of found element else (-1, -1)\n        :rtype: tuple\n\n        \"\"\"\n        start, end = -1, -1\n        if not prev:\n            _, prev = self.get_raise_indexes(data)\n        if prev < 0:\n            return -1, -1\n        m = re.match(r'\\W*(\\w+)', data[prev:])\n        if m:\n            first = m.group(1)\n            start = data[prev:].find(first)\n            if start >= 0:\n                start += prev\n                if self.style['in'] in self.tagstyles + ['unknown']:\n                    end = self.get_elem_index(data[start:])\n                    if end >= 0:\n                        end += start\n                if self.style['in'] in ['params', 'unknown'] and end == -1:\n                    p1, _ = self.get_raise_indexes(data[start:])\n                    if p1 >= 0:\n                        end = p1\n                    else:\n                        end = len(data)\n\n        return start, end"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget from a docstring the next parameter name indexes.", "response": "def get_param_indexes(self, data):\n        \"\"\"Get from a docstring the next parameter name indexes.\n        In javadoc style it is after @param.\n\n        :param data: string to parse\n        :returns: start and end indexes of found element else (-1, -1)\n          or else (-2, -2) if try to use params style but no parameters were provided.\n          Note: the end index is the index after the last name character\n        :rtype: tuple\n\n        \"\"\"\n        # TODO: new method to extract an element's name so will be available for @param and @types and other styles (:param, \\param)\n        start, end = -1, -1\n        stl_param = self.opt['param'][self.style['in']]['name']\n        if self.style['in'] in self.tagstyles + ['unknown']:\n            idx_p = self.get_key_index(data, 'param')\n            if idx_p >= 0:\n                idx_p += len(stl_param)\n                m = re.match(r'^([\\w]+)', data[idx_p:].strip())\n                if m:\n                    param = m.group(1)\n                    start = idx_p + data[idx_p:].find(param)\n                    end = start + len(param)\n\n        if self.style['in'] in ['groups', 'unknown'] and (start, end) == (-1, -1):\n            # search = '\\s*(%s)' % '|'.join(self.groups['param'])\n            # m = re.match(search, data.lower())\n            # if m:\n            #    key_param = m.group(1)\n            pass\n\n        if self.style['in'] in ['params', 'groups', 'unknown'] and (start, end) == (-1, -1):\n            if self.params is None:\n                return -2, -2\n            idx = -1\n            param = None\n            for p in self.params:\n                if type(p) is tuple:\n                    p = p[0]\n                i = data.find('\\n' + p)\n                if i >= 0:\n                    if idx == -1 or i < idx:\n                        idx = i\n                        param = p\n            if idx != -1:\n                start, end = idx, idx + len(param)\n        return start, end"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets from a docstring a parameter type indexes.", "response": "def get_param_type_indexes(self, data, name=None, prev=None):\n        \"\"\"Get from a docstring a parameter type indexes.\n        In javadoc style it is after @type.\n\n        :param data: string to parse\n        :param name: the name of the parameter (Default value = None)\n        :param prev: index after the previous element (param or param's description) (Default value = None)\n        :returns: start and end indexes of found element else (-1, -1)\n          Note: the end index is the index after the last included character or -1 if\n          reached the end\n        :rtype: tuple\n\n        \"\"\"\n        start, end = -1, -1\n        stl_type = self.opt['type'][self.style['in']]['name']\n        if not prev:\n            _, prev = self.get_param_description_indexes(data)\n        if prev >= 0:\n            if self.style['in'] in self.tagstyles + ['unknown']:\n                idx = self.get_elem_index(data[prev:])\n                if idx >= 0 and data[prev + idx:].startswith(stl_type):\n                    idx = prev + idx + len(stl_type)\n                    m = re.match(r'\\W*(\\w+)\\W+(\\w+)\\W*', data[idx:].strip())\n                    if m:\n                        param = m.group(1).strip()\n                        if (name and param == name) or not name:\n                            desc = m.group(2)\n                            start = data[idx:].find(desc) + idx\n                            end = self.get_elem_index(data[start:])\n                            if end >= 0:\n                                end += start\n\n            if self.style['in'] in ['params', 'unknown'] and (start, end) == (-1, -1):\n                # TODO: manage this\n                pass\n\n        return (start, end)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_return_description_indexes(self, data):\n        start, end = -1, -1\n        stl_return = self.opt['return'][self.style['in']]['name']\n        if self.style['in'] in self.tagstyles + ['unknown']:\n            idx = self.get_key_index(data, 'return')\n            idx_abs = idx\n            # search starting description\n            if idx >= 0:\n                # FIXME: take care if a return description starts with <, >, =,...\n                m = re.match(r'\\W*(\\w+)', data[idx_abs + len(stl_return):])\n                if m:\n                    first = m.group(1)\n                    idx = data[idx_abs:].find(first)\n                    idx_abs += idx\n                    start = idx_abs\n                else:\n                    idx = -1\n            # search the end\n            idx = self.get_elem_index(data[idx_abs:])\n            if idx > 0:\n                idx_abs += idx\n                end = idx_abs\n\n        if self.style['in'] in ['params', 'unknown'] and (start, end) == (-1, -1):\n            # TODO: manage this\n            pass\n\n        return start, end", "response": "Get from a docstring the return parameter description indexes."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_return_type_indexes(self, data):\n        start, end = -1, -1\n        stl_rtype = self.opt['rtype'][self.style['in']]['name']\n        if self.style['in'] in self.tagstyles + ['unknown']:\n            dstart, dend = self.get_return_description_indexes(data)\n            # search the start\n            if dstart >= 0 and dend > 0:\n                idx = self.get_elem_index(data[dend:])\n                if idx >= 0 and data[dend + idx:].startswith(stl_rtype):\n                    idx = dend + idx + len(stl_rtype)\n                    m = re.match(r'\\W*(\\w+)', data[idx:])\n                    if m:\n                        first = m.group(1)\n                        start = data[idx:].find(first) + idx\n            # search the end\n            idx = self.get_elem_index(data[start:])\n            if idx > 0:\n                end = idx + start\n\n        if self.style['in'] in ['params', 'unknown'] and (start, end) == (-1, -1):\n            # TODO: manage this\n            pass\n\n        return start, end", "response": "Get from a docstring the return parameter type indexes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_element(self, raw=None):\n        # TODO: retrieve return from element external code (in parameter)\n        if raw is None:\n            l = self.element['raw'].strip()\n        else:\n            l = raw.strip()\n        is_class = False\n        if l.startswith('def ') or l.startswith('class '):\n            # retrieves the type\n            if l.startswith('def'):\n                self.element['type'] = 'def'\n                l = l.replace('def ', '')\n            else:\n                self.element['type'] = 'class'\n                l = l.replace('class ', '')\n                is_class = True\n            # retrieves the name\n            self.element['name'] = l[:l.find('(')].strip()\n            if not is_class:\n                if l[-1] == ':':\n                    l = l[:-1].strip()\n                # retrieves the parameters\n                l = l[l.find('(') + 1:l.rfind('):')].strip()\n                lst = [c.strip() for c in l.split(',')]\n                for e in lst:\n                    if '=' in e:\n                        k, v = e.split('=', 1)\n                        self.element['params'].append((k.strip(), v.strip()))\n                    elif e and e != 'self' and e != 'cls':\n                        self.element['params'].append(e)\n        self.parsed_elem = True", "response": "Parses the element s elements and returns the object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _extract_docs_description(self):\n        # FIXME: the indentation of descriptions is lost\n        data = '\\n'.join([d.rstrip().replace(self.docs['out']['spaces'], '', 1) for d in self.docs['in']['raw'].splitlines()])\n        if self.dst.style['in'] == 'groups':\n            idx = self.dst.get_group_index(data)\n        elif self.dst.style['in'] == 'google':\n            lines = data.splitlines()\n            line_num = self.dst.googledoc.get_next_section_start_line(lines)\n            if line_num == -1:\n                idx = -1\n            else:\n                idx = len('\\n'.join(lines[:line_num]))\n        elif self.dst.style['in'] == 'numpydoc':\n            lines = data.splitlines()\n            line_num = self.dst.numpydoc.get_next_section_start_line(lines)\n            if line_num == -1:\n                idx = -1\n            else:\n                idx = len('\\n'.join(lines[:line_num]))\n        elif self.dst.style['in'] == 'unknown':\n            idx = -1\n        else:\n            idx = self.dst.get_elem_index(data)\n        if idx == 0:\n            self.docs['in']['desc'] = ''\n        elif idx == -1:\n            self.docs['in']['desc'] = data\n        else:\n            self.docs['in']['desc'] = data[:idx]", "response": "Extract main description from docstring"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _extract_groupstyle_docs_params(self):\n        data = '\\n'.join([d.rstrip().replace(self.docs['out']['spaces'], '', 1) for d in self.docs['in']['raw'].splitlines()])\n        idx = self.dst.get_group_key_line(data, 'param')\n        if idx >= 0:\n            data = data.splitlines()[idx + 1:]\n            end = self.dst.get_group_line('\\n'.join(data))\n            end = end if end != -1 else len(data)\n            for i in range(end):\n                # FIXME: see how retrieve multiline param description and how get type\n                line = data[i]\n                param = None\n                desc = ''\n                ptype = ''\n                m = re.match(r'^\\W*(\\w+)[\\W\\s]+(\\w[\\s\\w]+)', line.strip())\n                if m:\n                    param = m.group(1).strip()\n                    desc = m.group(2).strip()\n                else:\n                    m = re.match(r'^\\W*(\\w+)\\W*', line.strip())\n                    if m:\n                        param = m.group(1).strip()\n                if param:\n                    self.docs['in']['params'].append((param, desc, ptype))", "response": "Extract group style parameters from the raw file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextracting parameters description and type from docstring. The internal computed parameters list is composed by tuples ( parameter description type ).", "response": "def _extract_docs_params(self):\n        \"\"\"Extract parameters description and type from docstring. The internal computed parameters list is\n        composed by tuples (parameter, description, type).\n\n        \"\"\"\n        if self.dst.style['in'] == 'numpydoc':\n            data = '\\n'.join([d.rstrip().replace(self.docs['out']['spaces'], '', 1) for d in self.docs['in']['raw'].splitlines()])\n            self.docs['in']['params'] += self.dst.numpydoc.get_param_list(data)\n        elif self.dst.style['in'] == 'google':\n            data = '\\n'.join([d.rstrip().replace(self.docs['out']['spaces'], '', 1) for d in self.docs['in']['raw'].splitlines()])\n            self.docs['in']['params'] += self.dst.googledoc.get_param_list(data)\n        elif self.dst.style['in'] == 'groups':\n            self._extract_groupstyle_docs_params()\n        elif self.dst.style['in'] in ['javadoc', 'reST']:\n            self._extract_tagstyle_docs_params()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _extract_docs_raises(self):\n        if self.dst.style['in'] == 'numpydoc':\n            data = '\\n'.join([d.rstrip().replace(self.docs['out']['spaces'], '', 1) for d in self.docs['in']['raw'].splitlines()])\n            self.docs['in']['raises'] += self.dst.numpydoc.get_raise_list(data)\n        if self.dst.style['in'] == 'google':\n            data = '\\n'.join([d.rstrip().replace(self.docs['out']['spaces'], '', 1) for d in self.docs['in']['raw'].splitlines()])\n            self.docs['in']['raises'] += self.dst.googledoc.get_raise_list(data)\n        elif self.dst.style['in'] == 'groups':\n            self._extract_groupstyle_docs_raises()\n        elif self.dst.style['in'] in ['javadoc', 'reST']:\n            self._extract_tagstyle_docs_raises()", "response": "Extract raises description from docstring. The internal computed raises list is\n            composed by tuples ( raise description."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nextracts return description and type from the docstrings.", "response": "def _extract_docs_return(self):\n        \"\"\"Extract return description and type\"\"\"\n        if self.dst.style['in'] == 'numpydoc':\n            data = '\\n'.join([d.rstrip().replace(self.docs['out']['spaces'], '', 1) for d in self.docs['in']['raw'].splitlines()])\n            self.docs['in']['return'] = self.dst.numpydoc.get_return_list(data)\n            self.docs['in']['rtype'] = None\n# TODO: fix this\n        elif self.dst.style['in'] == 'google':\n            data = '\\n'.join([d.rstrip().replace(self.docs['out']['spaces'], '', 1) for d in self.docs['in']['raw'].splitlines()])\n            self.docs['in']['return'] = self.dst.googledoc.get_return_list(data)\n            self.docs['in']['rtype'] = None\n        elif self.dst.style['in'] == 'groups':\n            self._extract_groupstyle_docs_return()\n        elif self.dst.style['in'] in ['javadoc', 'reST']:\n            self._extract_tagstyle_docs_return()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextracting other specific sections", "response": "def _extract_docs_other(self):\n        \"\"\"Extract other specific sections\"\"\"\n        if self.dst.style['in'] == 'numpydoc':\n            data = '\\n'.join([d.rstrip().replace(self.docs['out']['spaces'], '', 1) for d in self.docs['in']['raw'].splitlines()])\n            lst = self.dst.numpydoc.get_list_key(data, 'also')\n            lst = self.dst.numpydoc.get_list_key(data, 'ref')\n            lst = self.dst.numpydoc.get_list_key(data, 'note')\n            lst = self.dst.numpydoc.get_list_key(data, 'other')\n            lst = self.dst.numpydoc.get_list_key(data, 'example')\n            lst = self.dst.numpydoc.get_list_key(data, 'attr')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing the docstring of the resource.", "response": "def parse_docs(self, raw=None):\n        \"\"\"Parses the docstring\n\n        :param raw: the data to parse if not internally provided (Default value = None)\n\n        \"\"\"\n        if raw is not None:\n            raw = raw.strip()\n            if raw.startswith('\"\"\"') or raw.startswith(\"'''\"):\n                raw = raw[3:]\n            if raw.endswith('\"\"\"') or raw.endswith(\"'''\"):\n                raw = raw[:-3]\n            self.docs['in']['raw'] = raw\n            self.dst.autodetect_style(raw)\n        if self.docs['in']['raw'] is None:\n            return\n        self.dst.set_known_parameters(self.element['params'])\n        self._extract_docs_doctest()\n        self._extract_docs_params()\n        self._extract_docs_return()\n        self._extract_docs_raises()\n        self._extract_docs_description()\n        self._extract_docs_other()\n        self.parsed_docs = True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_desc(self):\n        # TODO: manage different in/out styles\n        if self.docs['in']['desc']:\n            self.docs['out']['desc'] = self.docs['in']['desc']\n        else:\n            self.docs['out']['desc'] = ''", "response": "Sets the global description if any"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the parameters with types descriptions and default value if any", "response": "def _set_params(self):\n        \"\"\"Sets the parameters with types, descriptions and default value if any\"\"\"\n        # TODO: manage different in/out styles\n        if self.docs['in']['params']:\n            # list of parameters is like: (name, description, type)\n            self.docs['out']['params'] = list(self.docs['in']['params'])\n        for e in self.element['params']:\n            if type(e) is tuple:\n                # tuple is: (name, default)\n                param = e[0]\n            else:\n                param = e\n            found = False\n            for i, p in enumerate(self.docs['out']['params']):\n                if param == p[0]:\n                    found = True\n                    # add default value if any\n                    if type(e) is tuple:\n                        # param will contain: (name, desc, type, default)\n                        self.docs['out']['params'][i] = (p[0], p[1], p[2], e[1])\n            if not found:\n                if type(e) is tuple:\n                    p = (param, '', None, e[1])\n                else:\n                    p = (param, '', None, None)\n                self.docs['out']['params'].append(p)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the raises and descriptions for the archive.", "response": "def _set_raises(self):\n        \"\"\"Sets the raises and descriptions\"\"\"\n        # TODO: manage different in/out styles\n        # manage setting if not mandatory for numpy but optional\n        if self.docs['in']['raises']:\n            if self.dst.style['out'] != 'numpydoc' or self.dst.style['in'] == 'numpydoc' or \\\n                    (self.dst.style['out'] == 'numpydoc' and\n                     'raise' not in self.dst.numpydoc.get_excluded_sections()):\n                # list of parameters is like: (name, description)\n                self.docs['out']['raises'] = list(self.docs['in']['raises'])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the return parameter with description and rtype if any", "response": "def _set_return(self):\n        \"\"\"Sets the return parameter with description and rtype if any\"\"\"\n        # TODO: manage return retrieved from element code (external)\n        # TODO: manage different in/out styles\n        if type(self.docs['in']['return']) is list and self.dst.style['out'] not in ['groups', 'numpydoc', 'google']:\n            # TODO: manage return names\n            # manage not setting return if not mandatory for numpy\n            lst = self.docs['in']['return']\n            if lst:\n                if lst[0][0] is not None:\n                    self.docs['out']['return'] = \"%s-> %s\" % (lst[0][0], lst[0][1])\n                else:\n                    self.docs['out']['return'] = lst[0][1]\n                self.docs['out']['rtype'] = lst[0][2]\n        else:\n            self.docs['out']['return'] = self.docs['in']['return']\n            self.docs['out']['rtype'] = self.docs['in']['rtype']"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_other(self):\n        # manage not setting if not mandatory for numpy\n        if self.dst.style['in'] == 'numpydoc':\n            if self.docs['in']['raw'] is not None:\n                self.docs['out']['post'] = self.dst.numpydoc.get_raw_not_managed(self.docs['in']['raw'])\n            elif 'post' not in self.docs['out'] or self.docs['out']['post'] is None:\n                self.docs['out']['post'] = ''", "response": "Sets other specific sections"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_raw_params(self, sep):\n        raw = '\\n'\n        if self.dst.style['out'] == 'numpydoc':\n            spaces = ' ' * 4\n            with_space = lambda s: '\\n'.join([self.docs['out']['spaces'] + spaces +\\\n                                                    l.lstrip() if i > 0 else\\\n                                                    l for i, l in enumerate(s.splitlines())])\n            raw += self.dst.numpydoc.get_key_section_header('param', self.docs['out']['spaces'])\n            for p in self.docs['out']['params']:\n                raw += self.docs['out']['spaces'] + p[0] + ' :'\n                if p[2] is not None and len(p[2]) > 0:\n                    raw += ' ' + p[2]\n                raw += '\\n'\n                raw += self.docs['out']['spaces'] + spaces + with_space(p[1]).strip()\n                if len(p) > 2:\n                    if 'default' not in p[1].lower() and len(p) > 3 and p[3] is not None:\n                        raw += ' (Default value = ' + str(p[3]) + ')'\n                raw += '\\n'\n        elif self.dst.style['out'] == 'google':\n            spaces = ' ' * 2\n            with_space = lambda s: '\\n'.join([self.docs['out']['spaces'] +\\\n                                                    l.lstrip() if i > 0 else\\\n                                                    l for i, l in enumerate(s.splitlines())])\n            raw += self.dst.googledoc.get_key_section_header('param', self.docs['out']['spaces'])\n            for p in self.docs['out']['params']:\n                raw += self.docs['out']['spaces'] + spaces + p[0]\n                if p[2] is not None and len(p[2]) > 0:\n                    raw += '(' + p[2]\n                    if len(p) > 3 and p[3] is not None:\n                        raw += ', optional'\n                    raw += ')'\n                raw += ': ' + with_space(p[1]).strip()\n                if len(p) > 2:\n                    if 'default' not in p[1].lower() and len(p) > 3 and p[3] is not None:\n                        raw += ' (Default value = ' + str(p[3]) + ')'\n                raw += '\\n'\n        elif self.dst.style['out'] == 'groups':\n            pass\n        else:\n            with_space = lambda s: '\\n'.join([self.docs['out']['spaces'] + l\\\n                                                    if i > 0 else l for i, l in enumerate(s.splitlines())])\n            if len(self.docs['out']['params']):\n                for p in self.docs['out']['params']:\n                    raw += self.docs['out']['spaces'] + self.dst.get_key('param', 'out') + ' ' + p[0] + sep + with_space(p[1]).strip()\n                    if len(p) > 2:\n                        if 'default' not in p[1].lower() and len(p) > 3 and p[3] is not None:\n                            raw += ' (Default value = ' + str(p[3]) + ')'\n                        if p[2] is not None and len(p[2]) > 0:\n                            raw += '\\n'\n                            raw += self.docs['out']['spaces'] + self.dst.get_key('type', 'out') + ' ' + p[0] + sep + p[2]\n                        raw += '\\n'\n                    else:\n                        raw += '\\n'\n        return raw", "response": "Set the output raw parameters section\n\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the output raw exception section in the current style", "response": "def _set_raw_raise(self, sep):\n        \"\"\"Set the output raw exception section\n\n        :param sep: the separator of current style\n\n        \"\"\"\n        raw = ''\n        if self.dst.style['out'] == 'numpydoc':\n            if 'raise' not in self.dst.numpydoc.get_excluded_sections():\n                raw += '\\n'\n                if 'raise' in self.dst.numpydoc.get_mandatory_sections() or \\\n                        (self.docs['out']['raises'] and 'raise' in self.dst.numpydoc.get_optional_sections()):\n                    spaces = ' ' * 4\n                    with_space = lambda s: '\\n'.join([self.docs['out']['spaces'] + spaces + l.lstrip() if i > 0 else l for i, l in enumerate(s.splitlines())])\n                    raw += self.dst.numpydoc.get_key_section_header('raise', self.docs['out']['spaces'])\n                    if len(self.docs['out']['raises']):\n                        for p in self.docs['out']['raises']:\n                            raw += self.docs['out']['spaces'] + p[0] + '\\n'\n                            raw += self.docs['out']['spaces'] + spaces + with_space(p[1]).strip() + '\\n'\n                    raw += '\\n'\n        elif self.dst.style['out'] == 'google':\n            if 'raise' not in self.dst.googledoc.get_excluded_sections():\n                raw += '\\n'\n                if 'raise' in self.dst.googledoc.get_mandatory_sections() or \\\n                        (self.docs['out']['raises'] and 'raise' in self.dst.googledoc.get_optional_sections()):\n                    spaces = ' ' * 2\n                    with_space = lambda s: '\\n'.join([self.docs['out']['spaces'] + spaces + \\\n                                                            l.lstrip() if i > 0 else \\\n                                                            l for i, l in enumerate(s.splitlines())])\n                    raw += self.dst.googledoc.get_key_section_header('raise', self.docs['out']['spaces'])\n                    if len(self.docs['out']['raises']):\n                        for p in self.docs['out']['raises']:\n                            raw += self.docs['out']['spaces'] + spaces\n                            if p[0] is not None:\n                                raw += p[0] + sep\n                            if p[1]:\n                                raw += p[1].strip()\n                            raw += '\\n'\n                    raw += '\\n'\n        elif self.dst.style['out'] == 'groups':\n            pass\n        else:\n            with_space = lambda s: '\\n'.join([self.docs['out']['spaces'] + l if i > 0 else l for i, l in enumerate(s.splitlines())])\n            if len(self.docs['out']['raises']):\n                if not self.docs['out']['params'] and not self.docs['out']['return']:\n                    raw += '\\n'\n                for p in self.docs['out']['raises']:\n                    raw += self.docs['out']['spaces'] + self.dst.get_key('raise', 'out') + ' '\n                    if p[0] is not None:\n                        raw += p[0] + sep\n                    if p[1]:\n                        raw += with_space(p[1]).strip()\n                    raw += '\\n'\n            raw += '\\n'\n        return raw"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_raw_return(self, sep):\n        raw = ''\n        if self.dst.style['out'] == 'numpydoc':\n            raw += '\\n'\n            spaces = ' ' * 4\n            with_space = lambda s: '\\n'.join([self.docs['out']['spaces'] + spaces + l.lstrip() if i > 0 else l for i, l in enumerate(s.splitlines())])\n            raw += self.dst.numpydoc.get_key_section_header('return', self.docs['out']['spaces'])\n            if self.docs['out']['rtype']:\n                rtype = self.docs['out']['rtype']\n            else:\n                rtype = 'type'\n            # case of several returns\n            if type(self.docs['out']['return']) is list:\n                for ret_elem in self.docs['out']['return']:\n                    # if tuple (name, desc, rtype) else string desc\n                    if type(ret_elem) is tuple and len(ret_elem) == 3:\n                        rtype = ret_elem[2]\n                        if rtype is None:\n                            rtype = ''\n                        raw += self.docs['out']['spaces']\n                        if ret_elem[0]:\n                            raw += ret_elem[0] + ' : '\n                        raw += rtype + '\\n' + self.docs['out']['spaces'] + spaces + with_space(ret_elem[1]).strip() + '\\n'\n                    else:\n                        # There can be a problem\n                        raw += self.docs['out']['spaces'] + rtype + '\\n'\n                        raw += self.docs['out']['spaces'] + spaces + with_space(str(ret_elem)).strip() + '\\n'\n            # case of a unique return\n            elif self.docs['out']['return'] is not None:\n                raw += self.docs['out']['spaces'] + rtype\n                raw += '\\n' + self.docs['out']['spaces'] + spaces + with_space(self.docs['out']['return']).strip() + '\\n'\n        elif self.dst.style['out'] == 'google':\n            raw += '\\n'\n            spaces = ' ' * 2\n            with_space = lambda s: '\\n'.join([self.docs['out']['spaces'] + spaces +\\\n                                                    l.lstrip() if i > 0 else\\\n                                                    l for i, l in enumerate(s.splitlines())])\n            raw += self.dst.googledoc.get_key_section_header('return', self.docs['out']['spaces'])\n            if self.docs['out']['rtype']:\n                rtype = self.docs['out']['rtype']\n            else:\n                rtype = None\n            # case of several returns\n            if type(self.docs['out']['return']) is list:\n                for ret_elem in self.docs['out']['return']:\n                    # if tuple (name=None, desc, rtype) else string desc\n                    if type(ret_elem) is tuple and len(ret_elem) == 3:\n                        rtype = ret_elem[2]\n                        if rtype is None:\n                            rtype = ''\n                        raw += self.docs['out']['spaces'] + spaces\n                        raw += rtype + ': ' + with_space(ret_elem[1]).strip() + '\\n'\n                    else:\n                        # There can be a problem\n                        if rtype:\n                            raw += self.docs['out']['spaces'] + spaces + rtype + ': '\n                            raw += with_space(str(ret_elem)).strip() + '\\n'\n                        else:\n                            raw += self.docs['out']['spaces'] + spaces + with_space(str(ret_elem)).strip() + '\\n'\n            # case of a unique return\n            elif self.docs['out']['return'] is not None:\n                if rtype:\n                    raw += self.docs['out']['spaces'] + spaces + rtype + ': '\n                    raw += with_space(self.docs['out']['return']).strip() + '\\n'\n                else:\n                    raw += self.docs['out']['spaces'] + spaces + with_space(self.docs['out']['return']).strip() + '\\n'\n        elif self.dst.style['out'] == 'groups':\n            pass\n        else:\n            with_space = lambda s: '\\n'.join([self.docs['out']['spaces'] + l if i > 0 else l for i, l in enumerate(s.splitlines())])\n            if self.docs['out']['return']:\n                if not self.docs['out']['params']:\n                    raw += '\\n'\n                raw += self.docs['out']['spaces'] + self.dst.get_key('return', 'out') + sep + with_space(self.docs['out']['return'].rstrip()).strip() + '\\n'\n            if self.docs['out']['rtype']:\n                if not self.docs['out']['params']:\n                    raw += '\\n'\n                raw += self.docs['out']['spaces'] + self.dst.get_key('rtype', 'out') + sep + self.docs['out']['rtype'].rstrip() + '\\n'\n        return raw", "response": "Set the output raw return section"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the output raw docstring", "response": "def _set_raw(self):\n        \"\"\"Sets the output raw docstring\"\"\"\n        sep = self.dst.get_sep(target='out')\n        sep = sep + ' ' if sep != ' ' else sep\n        with_space = lambda s: '\\n'.join([self.docs['out']['spaces'] + l if i > 0 else l for i, l in enumerate(s.splitlines())])\n\n        # sets the description section\n        raw = self.docs['out']['spaces'] + self.quotes\n        desc = self.docs['out']['desc'].strip()\n        if not desc or not desc.count('\\n'):\n            if not self.docs['out']['params'] and not self.docs['out']['return'] and not self.docs['out']['rtype'] and not self.docs['out']['raises']:\n                raw += desc if desc else self.trailing_space\n                raw += self.quotes\n                self.docs['out']['raw'] = raw.rstrip()\n                return\n        if not self.first_line:\n            raw += '\\n' + self.docs['out']['spaces']\n        raw += with_space(self.docs['out']['desc']).strip() + '\\n'\n\n        # sets the parameters section\n        raw += self._set_raw_params(sep)\n\n        # sets the return section\n        raw += self._set_raw_return(sep)\n\n        # sets the raises section\n        raw += self._set_raw_raise(sep)\n\n        # sets post specific if any\n        if 'post' in self.docs['out']:\n            raw += self.docs['out']['spaces'] + with_space(self.docs['out']['post']).strip() + '\\n'\n\n        # sets the doctests if any\n        if 'doctests' in self.docs['out']:\n            raw += self.docs['out']['spaces'] + with_space(self.docs['out']['doctests']).strip() + '\\n'\n\n        if raw.count(self.quotes) == 1:\n            raw += self.docs['out']['spaces'] + self.quotes\n        self.docs['out']['raw'] = raw.rstrip()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate_docs(self):\n        if self.dst.style['out'] == 'numpydoc' and self.dst.numpydoc.first_line is not None:\n            self.first_line = self.dst.numpydoc.first_line\n        self._set_desc()\n        self._set_params()\n        self._set_return()\n        self._set_raises()\n        self._set_other()\n        self._set_raw()\n        self.generated_docs = True", "response": "Generates the output docstring"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretrieve the list of files from a folder.", "response": "def get_files_from_dir(path, recursive=True, depth=0, file_ext='.py'):\n    \"\"\"Retrieve the list of files from a folder.\n\n    @param path: file or directory where to search files\n    @param recursive: if True will search also sub-directories\n    @param depth: if explore recursively, the depth of sub directories to follow\n    @param file_ext: the files extension to get. Default is '.py'\n    @return: the file list retrieved. if the input is a file then a one element list.\n\n    \"\"\"\n    file_list = []\n    if os.path.isfile(path) or path == '-':\n        return [path]\n    if path[-1] != os.sep:\n        path = path + os.sep\n    for f in glob.glob(path + \"*\"):\n        if os.path.isdir(f):\n            if depth < MAX_DEPTH_RECUR:  # avoid infinite recursive loop\n                file_list.extend(get_files_from_dir(f, recursive, depth + 1))\n            else:\n                continue\n        elif f.endswith(file_ext):\n            file_list.append(f)\n    return file_list"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the configuration from a file.", "response": "def get_config(config_file):\n    \"\"\"Get the configuration from a file.\n\n    @param config_file: the configuration file\n    @return: the configuration\n    @rtype: dict\n\n    \"\"\"\n    config = {}\n    tobool = lambda s: True if s.lower() == 'true' else False\n    if config_file:\n        try:\n            f = open(config_file, 'r')\n        except:\n            print (\"Unable to open configuration file '{0}'\".format(config_file))\n        else:\n            for line in f.readlines():\n                if len(line.strip()):\n                    key, value = line.split(\"=\", 1)\n                    key, value = key.strip(), value.strip()\n                    if key in ['init2class', 'first_line', 'convert_only']:\n                        value = tobool(value)\n                    config[key] = value\n    return config"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _parse(self):\n        #TODO manage decorators\n        #TODO manage default params with strings escaping chars as (, ), ', ', #, ...\n        #TODO manage elements ending with comments like: def func(param): # blabla\n        elem_list = []\n        reading_element = None\n        reading_docs = None\n        waiting_docs = False\n        elem = ''\n        raw = ''\n        start = 0\n        end = 0\n\n        try:\n            if self.input_file == '-':\n                fd = sys.stdin\n            else:\n                fd = open(self.input_file)\n\n            self.input_lines = fd.readlines()\n\n            if self.input_file != '-':\n                fd.close()\n\n        except IOError:\n            msg = BaseException('Failed to open file \"' + self.input_file + '\". Please provide a valid file.')\n            raise msg\n        for i, ln in enumerate(self.input_lines):\n            l = ln.strip()\n            if reading_element:\n                elem += l\n                if l.endswith(':'):\n                    reading_element = 'end'\n            elif (l.startswith('def ') or l.startswith('class ')) and not reading_docs:\n                if self.ignore_private and l[l.find(' '):].strip().startswith(\"__\"):\n                    continue\n                reading_element = 'start'\n                elem = l\n                m = re.match(r'^(\\s*)[dc]{1}', ln)\n                if m is not None and m.group(1) is not None:\n                    spaces = m.group(1)\n                else:\n                    spaces = ''\n                if re.search(r''':(|\\s*#[^'\"]*)$''', l):\n                    reading_element = 'end'\n            if reading_element == 'end':\n                reading_element = None\n                # if currently reading an element content\n                waiting_docs = True\n                # *** Creates the DocString object ***\n                e = DocString(elem.replace('\\n', ' '), spaces, quotes=self.quotes,\n                              input_style=self.input_style,\n                              output_style=self.output_style,\n                              first_line=self.first_line,\n                              **self.kwargs)\n                elem_list.append({'docs': e, 'location': (-i, -i)})\n            else:\n                if waiting_docs and ('\"\"\"' in l or \"'''\" in l):\n                    # start of docstring bloc\n                    if not reading_docs:\n                        start = i\n                        # determine which delimiter\n                        idx_c = l.find('\"\"\"')\n                        idx_dc = l.find(\"'''\")\n                        lim = '\"\"\"'\n                        if idx_c >= 0 and idx_dc >= 0:\n                            if idx_c < idx_dc:\n                                lim = '\"\"\"'\n                            else:\n                                lim = \"'''\"\n                        elif idx_c < 0:\n                            lim = \"'''\"\n                        reading_docs = lim\n                        raw = ln\n                        # one line docstring\n                        if l.count(lim) == 2:\n                            end = i\n                            elem_list[-1]['docs'].parse_docs(raw)\n                            elem_list[-1]['location'] = (start, end)\n                            reading_docs = None\n                            waiting_docs = False\n                            reading_element = False\n                            raw = ''\n                    # end of docstring bloc\n                    elif waiting_docs and lim in l:\n                        end = i\n                        raw += ln\n                        elem_list[-1]['docs'].parse_docs(raw)\n                        elem_list[-1]['location'] = (start, end)\n                        reading_docs = None\n                        waiting_docs = False\n                        reading_element = False\n                        raw = ''\n                    # inside a docstring bloc\n                    elif waiting_docs:\n                        raw += ln\n                # no docstring found for current element\n                elif waiting_docs and l != '' and reading_docs is None:\n                    waiting_docs = False\n                else:\n                    if reading_docs is not None:\n                        raw += ln\n        if self.convert_only:\n            i = 0\n            while i < len(elem_list):\n                if elem_list[i]['docs'].get_input_docstring() is None:\n                    elem_list.pop(i)\n                else:\n                    i += 1\n        self.docs_list = elem_list\n\n        self.parsed = True\n        return elem_list", "response": "Parses the input file and generates a list of elements and docstrings."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if the class docstring and the class docstring are not empty.", "response": "def docs_init_to_class(self):\n        \"\"\"If found a __init__ method's docstring and the class\n        without any docstring, so set the class docstring with __init__one,\n        and let __init__ without docstring.\n\n        :returns: True if done\n        :rtype: boolean\n\n        \"\"\"\n        result = False\n        if not self.parsed:\n            self._parse()\n        einit = []\n        eclass = []\n        for e in self.docs_list:\n            if len(eclass) == len(einit) + 1 and e['docs'].element['name'] == '__init__':\n                einit.append(e)\n            elif not eclass and e['docs'].element['type'] == 'class':\n                eclass.append(e)\n        for c, i in zip(eclass, einit):\n            start, _ = c['location']\n            if start < 0:\n                start, _ = i['location']\n                if start > 0:\n                    result = True\n                    cspaces = c['docs'].get_spaces()\n                    ispaces = i['docs'].get_spaces()\n                    c['docs'].set_spaces(ispaces)\n                    i['docs'].set_spaces(cspaces)\n                    c['docs'].generate_docs()\n                    i['docs'].generate_docs()\n                    c['docs'], i['docs'] = i['docs'], c['docs']\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the output docstrings once formatted", "response": "def get_output_docs(self):\n        \"\"\"Return the output docstrings once formatted\n\n        :returns: the formatted docstrings\n        :rtype: list\n\n        \"\"\"\n        if not self.parsed:\n            self._parse()\n        lst = []\n        for e in self.docs_list:\n            lst.append(e['docs'].get_raw_docs())\n        return lst"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the list of lines before and after the proposed docstring changes.", "response": "def compute_before_after(self):\n        \"\"\"Compute the list of lines before and after the proposed docstring changes.\n\n        :return: tuple of before,after where each is a list of lines of python code.\n        \"\"\"\n        if not self.parsed:\n            self._parse()\n        list_from = self.input_lines\n        list_to = []\n        last = 0\n        for e in self.docs_list:\n            start, end = e['location']\n            if start <= 0:\n                start, end = -start, -end\n                list_to.extend(list_from[last:start + 1])\n            else:\n                list_to.extend(list_from[last:start])\n            docs = e['docs'].get_raw_docs()\n            list_docs = [l + '\\n' for l in docs.splitlines()]\n            list_to.extend(list_docs)\n            last = end + 1\n        if last < len(list_from):\n            list_to.extend(list_from[last:])\n\n        return list_from, list_to"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef diff(self, source_path='', target_path='', which=-1):\n        list_from, list_to = self.compute_before_after()\n\n        if source_path.startswith(os.sep):\n            source_path = source_path[1:]\n        if source_path and not source_path.endswith(os.sep):\n            source_path += os.sep\n        if target_path.startswith(os.sep):\n            target_path = target_path[1:]\n        if target_path and not target_path.endswith(os.sep):\n            target_path += os.sep\n\n        fromfile = 'a/' + source_path + os.path.basename(self.input_file)\n        tofile = 'b/' + target_path + os.path.basename(self.input_file)\n        diff_list = difflib.unified_diff(list_from, list_to, fromfile, tofile)\n        return [d for d in diff_list]", "response": "Build the diff between the original and proposed docstring."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the diff between source_path and target_path as a list of \\ n terminated lines", "response": "def get_patch_lines(self, source_path, target_path):\n        \"\"\"Return the diff between source_path and target_path\n\n        :param source_path: name of the original file (Default value = '')\n        :param target_path: name of the final file (Default value = '')\n\n        :return: the diff as a list of \\n terminated lines\n        :rtype: List[str]\n        \"\"\"\n        diff = self.diff(source_path, target_path)\n\n        return [\"# Patch generated by Pyment v{0}\\n\\n\".format(__version__)] + diff"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write_patch_file(self, patch_file, lines_to_write):\n        with open(patch_file, 'w') as f:\n            f.writelines(lines_to_write)", "response": "Write lines_to_write to a file called patch_file\n           "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\noverwriting the source file with lines_to_write", "response": "def overwrite_source_file(self, lines_to_write):\n        \"\"\"overwrite the file with line_to_write\n\n        :param lines_to_write: lines to write to the file - they should be \\n terminated\n        :type lines_to_write: List[str]\n\n        :return: None\n        \"\"\"\n        tmp_filename = '{0}.writing'.format(self.input_file)\n        ok = False\n        try:\n            with open(tmp_filename, 'w') as fh:\n                fh.writelines(lines_to_write)\n            ok = True\n        finally:\n            if ok:\n                if platform.system() == 'Windows':\n                    self._windows_rename(tmp_filename)\n                else:\n                    os.rename(tmp_filename, self.input_file)\n            else:\n                os.unlink(tmp_filename)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrename the file in the input directory.", "response": "def _windows_rename(self, tmp_filename):\n        \"\"\" Workaround the fact that os.rename raises an OSError on Windows\n        \n        :param tmp_filename: The file to rename\n    \n        \"\"\"\n\n        os.remove(self.input_file) if os.path.isfile(self.input_file) else None\n        os.rename(tmp_filename, self.input_file)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses the input file and generates the docstrings.", "response": "def proceed(self):\n        \"\"\"Parses the input file and generates/converts the docstrings.\n\n        :return: the list of docstrings\n        :rtype: list of dictionaries\n\n        \"\"\"\n        self._parse()\n        for e in self.docs_list:\n            e['docs'].generate_docs()\n        return self.docs_list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsorting the stat by exclusive elapsed time per call in descending order.", "response": "def by_own_time_per_call(stat):\n    \"\"\"Sorting by exclusive elapsed time per call in descending order.\"\"\"\n    return (-stat.own_time_per_call if stat.own_hits else -stat.own_time,\n            by_deep_time_per_call(stat))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the frozen statistics to serialize by Pickle.", "response": "def result(self):\n        \"\"\"Gets the frozen statistics to serialize by Pickle.\"\"\"\n        try:\n            cpu_time = max(0, time.clock() - self._cpu_time_started)\n            wall_time = max(0, time.time() - self._wall_time_started)\n        except AttributeError:\n            cpu_time = wall_time = 0.0\n        return self.stats, cpu_time, wall_time"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dump(self, dump_filename, pickle_protocol=pickle.HIGHEST_PROTOCOL):\n        result = self.result()\n\n        with open(dump_filename, 'wb') as f:\n            pickle.dump((self.__class__, result), f, pickle_protocol)", "response": "Saves the profiling result to a file"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmaking a statistics viewer from the profiling result.", "response": "def make_viewer(self, title=None, at=None):\n        \"\"\"Makes a statistics viewer from the profiling result.\n        \"\"\"\n        viewer = StatisticsViewer()\n        viewer.set_profiler_class(self.__class__)\n        stats, cpu_time, wall_time = self.result()\n        viewer.set_result(stats, cpu_time, wall_time, title=title, at=at)\n        viewer.activate()\n        return viewer"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run_viewer(self, title=None, at=None, mono=False,\n                   *loop_args, **loop_kwargs):\n        \"\"\"A shorter form of:\n\n        ::\n\n           viewer = profiler.make_viewer()\n           loop = viewer.loop()\n           loop.run()\n\n        \"\"\"\n        viewer = self.make_viewer(title, at=at)\n        loop = viewer.loop(*loop_args, **loop_kwargs)\n        if mono:\n            loop.screen.set_terminal_properties(1)\n        loop.run()", "response": "A shorter form of the viewer that runs the viewer."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pack_msg(method, msg, pickle_protocol=PICKLE_PROTOCOL):\n    dump = io.BytesIO()\n    pickle.dump(msg, dump, pickle_protocol)\n    size = dump.tell()\n    return (struct.pack(METHOD_STRUCT_FORMAT, method) +\n            struct.pack(SIZE_STRUCT_FORMAT, size) + dump.getvalue())", "response": "Packs a method and message."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreceives exactly size bytes. This function blocks the thread.", "response": "def recv(sock, size):\n    \"\"\"Receives exactly `size` bytes.  This function blocks the thread.\"\"\"\n    data = sock.recv(size, socket.MSG_WAITALL)\n    if len(data) < size:\n        raise socket.error(ECONNRESET, 'Connection closed')\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef recv_msg(sock):\n    data = recv(sock, struct.calcsize(METHOD_STRUCT_FORMAT))\n    method, = struct.unpack(METHOD_STRUCT_FORMAT, data)\n    data = recv(sock, struct.calcsize(SIZE_STRUCT_FORMAT))\n    size, = struct.unpack(SIZE_STRUCT_FORMAT, data)\n    data = recv(sock, size)\n    msg = pickle.loads(data)\n    return method, msg", "response": "Receives a method and message from the socket."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalling this method when a client is connected.", "response": "def connected(self, client):\n        \"\"\"Call this method when a client connected.\"\"\"\n        self.clients.add(client)\n        self._log_connected(client)\n        self._start_watching(client)\n        self.send_msg(client, WELCOME, (self.pickle_protocol, __version__),\n                      pickle_protocol=0)\n        profiler = self.profiler\n        while True:\n            try:\n                profiler = profiler.profiler\n            except AttributeError:\n                break\n        self.send_msg(client, PROFILER, type(profiler))\n        if self._latest_result_data is not None:\n            try:\n                self._send(client, self._latest_result_data)\n            except socket.error as exc:\n                if exc.errno in (EBADF, EPIPE):\n                    self.disconnected(client)\n                    return\n                raise\n        if len(self.clients) == 1:\n            self._start_profiling()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef disconnected(self, client):\n        if client not in self.clients:\n            # already disconnected.\n            return\n        self.clients.remove(client)\n        self._log_disconnected(client)\n        self._close(client)", "response": "Call this method when a client disconnected."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets an expanded collapsed or leaf icon.", "response": "def get_mark(self):\n        \"\"\"Gets an expanded, collapsed, or leaf icon.\"\"\"\n        if self.is_leaf:\n            char = self.icon_chars[2]\n        else:\n            char = self.icon_chars[int(self.expanded)]\n        return urwid.SelectableIcon(('mark', char), 0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_path(self):\n        path = deque()\n        __, node = self.get_focus()\n        while not node.is_root():\n            stats = node.get_value()\n            path.appendleft(hash(stats))\n            node = node.get_parent()\n        return path", "response": "Gets the path to the focused statistics. Each step is a hash of the statistics object. Each step is a hash of the statistics object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_node(self, node, path):\n        for hash_value in path:\n            if isinstance(node, LeafStatisticsNode):\n                break\n            for stats in node.get_child_keys():\n                if hash(stats) == hash_value:\n                    node = node.get_child_node(stats)\n                    break\n            else:\n                break\n        return node", "response": "Finds a node by the given path from the given node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating the result on the table.", "response": "def update_result(self):\n        \"\"\"Updates the result on the table.\"\"\"\n        try:\n            if self.paused:\n                result = self._paused_result\n            else:\n                result = self._final_result\n        except AttributeError:\n            self.table.update_frame()\n            return\n        stats, cpu_time, wall_time, title, at = result\n        self.table.set_result(stats, cpu_time, wall_time, title, at)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting an unbound method to get a configuration option as the given type.", "response": "def option_getter(type):\n    \"\"\"Gets an unbound method to get a configuration option as the given type.\n    \"\"\"\n    option_getters = {None: ConfigParser.get,\n                      int: ConfigParser.getint,\n                      float: ConfigParser.getfloat,\n                      bool: ConfigParser.getboolean}\n    return option_getters.get(type, option_getters[None])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef config_default(option, default=None, type=None, section=cli.name):\n    def f(option=option, default=default, type=type, section=section):\n        config = read_config()\n        if type is None and default is not None:\n            # detect type from default.\n            type = builtins.type(default)\n        get_option = option_getter(type)\n        try:\n            return get_option(config, section, option)\n        except (NoOptionError, NoSectionError):\n            return default\n    return f", "response": "A function to guess a default value of a CLI option from the configuration."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef config_flag(option, value, default=False, section=cli.name):\n    class x(object):\n        def __bool__(self, option=option, value=value,\n                     default=default, section=section):\n            config = read_config()\n            type = builtins.type(value)\n            get_option = option_getter(type)\n            try:\n                return get_option(config, section, option) == value\n            except (NoOptionError, NoSectionError):\n                return default\n        __nonzero__ = __bool__\n    return x()", "response": "Guesses whether a CLI flag should be turned on or off from the given option value."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_title(src_name, src_type=None):\n    if src_type == 'tcp':\n        return '{0}:{1}'.format(*src_name)\n    return os.path.basename(src_name)", "response": "Normalizes a source name as a string to be used for viewer s title."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_viewer(mono=False, *loop_args, **loop_kwargs):\n    viewer = StatisticsViewer()\n    loop = viewer.loop(*loop_args, **loop_kwargs)\n    if mono:\n        loop.screen.set_terminal_properties(1)\n    return (viewer, loop)", "response": "Makes a viewer with common options."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nspawn a daemon thread.", "response": "def spawn_thread(func, *args, **kwargs):\n    \"\"\"Spawns a daemon thread.\"\"\"\n    thread = threading.Thread(target=func, args=args, kwargs=kwargs)\n    thread.daemon = True\n    thread.start()\n    return thread"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef spawn(mode, func, *args, **kwargs):\n    if mode is None:\n        # 'threading' is the default mode.\n        mode = 'threading'\n    elif mode not in spawn.modes:\n        # validate the given mode.\n        raise ValueError('Invalid spawn mode: %s' % mode)\n    if mode == 'threading':\n        return spawn_thread(func, *args, **kwargs)\n    elif mode == 'gevent':\n        import gevent\n        import gevent.monkey\n        gevent.monkey.patch_select()\n        gevent.monkey.patch_socket()\n        return gevent.spawn(func, *args, **kwargs)\n    elif mode == 'eventlet':\n        import eventlet\n        eventlet.patcher.monkey_patch(select=True, socket=True)\n        return eventlet.spawn(func, *args, **kwargs)\n    assert False", "response": "Spawns a thread - like object which runs the given function concurrently."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef import_(module_name, name):\n    module = importlib.import_module(module_name, __package__)\n    return getattr(module, name)", "response": "Imports an object by a relative module path."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef profile(script, argv, profiler_factory,\n            pickle_protocol, dump_filename, mono):\n    \"\"\"Profile a Python script.\"\"\"\n    filename, code, globals_ = script\n    sys.argv[:] = [filename] + list(argv)\n    __profile__(filename, code, globals_, profiler_factory,\n                pickle_protocol=pickle_protocol, dump_filename=dump_filename,\n                mono=mono)", "response": "Profile a Python script."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef live_profile(script, argv, profiler_factory, interval, spawn, signum,\n                 pickle_protocol, mono):\n    \"\"\"Profile a Python script continuously.\"\"\"\n    filename, code, globals_ = script\n    sys.argv[:] = [filename] + list(argv)\n    parent_sock, child_sock = socket.socketpair()\n    stderr_r_fd, stderr_w_fd = os.pipe()\n    pid = os.fork()\n    if pid:\n        # parent\n        os.close(stderr_w_fd)\n        viewer, loop = make_viewer(mono)\n        # loop.screen._term_output_file = open(os.devnull, 'w')\n        title = get_title(filename)\n        client = ProfilingClient(viewer, loop.event_loop, parent_sock, title)\n        client.start()\n        try:\n            loop.run()\n        except KeyboardInterrupt:\n            os.kill(pid, signal.SIGINT)\n        except BaseException:\n            # unexpected profiler error.\n            os.kill(pid, signal.SIGTERM)\n            raise\n        finally:\n            parent_sock.close()\n        # get exit code of child.\n        w_pid, status = os.waitpid(pid, os.WNOHANG)\n        if w_pid == 0:\n            os.kill(pid, signal.SIGTERM)\n        exit_code = os.WEXITSTATUS(status)\n        # print stderr of child.\n        with os.fdopen(stderr_r_fd, 'r') as f:\n            child_stderr = f.read()\n        if child_stderr:\n            sys.stdout.flush()\n            sys.stderr.write(child_stderr)\n        # exit with exit code of child.\n        sys.exit(exit_code)\n    else:\n        # child\n        os.close(stderr_r_fd)\n        # mute stdin, stdout.\n        devnull = os.open(os.devnull, os.O_RDWR)\n        for f in [sys.stdin, sys.stdout]:\n            os.dup2(devnull, f.fileno())\n        # redirect stderr to parent.\n        os.dup2(stderr_w_fd, sys.stderr.fileno())\n        frame = sys._getframe()\n        profiler = profiler_factory(base_frame=frame, base_code=code)\n        profiler_trigger = BackgroundProfiler(profiler, signum)\n        profiler_trigger.prepare()\n        server_args = (interval, noop, pickle_protocol)\n        server = SelectProfilingServer(None, profiler_trigger, *server_args)\n        server.clients.add(child_sock)\n        spawn(server.connected, child_sock)\n        try:\n            exec_(code, globals_)\n        finally:\n            os.close(stderr_w_fd)\n            child_sock.shutdown(socket.SHUT_WR)", "response": "Profile a Python script continuously."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remote_profile(script, argv, profiler_factory, interval, spawn, signum,\n                   pickle_protocol, endpoint, verbose):\n    \"\"\"Launch a server to profile continuously.  The default endpoint is\n    127.0.0.1:8912.\n    \"\"\"\n    filename, code, globals_ = script\n    sys.argv[:] = [filename] + list(argv)\n    # create listener.\n    listener = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    listener.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n    listener.bind(endpoint)\n    listener.listen(1)\n    # be verbose or quiet.\n    if verbose:\n        log = lambda x: click.echo(click.style('> ', fg='cyan') + x)\n        bound_addr = listener.getsockname()\n        log('Listening on {0}:{1} for profiling...'.format(*bound_addr))\n    else:\n        log = noop\n    # start profiling server.\n    frame = sys._getframe()\n    profiler = profiler_factory(base_frame=frame, base_code=code)\n    profiler_trigger = BackgroundProfiler(profiler, signum)\n    profiler_trigger.prepare()\n    server_args = (interval, log, pickle_protocol)\n    server = SelectProfilingServer(listener, profiler_trigger, *server_args)\n    spawn(server.serve_forever)\n    # exec the script.\n    try:\n        exec_(code, globals_)\n    except KeyboardInterrupt:\n        pass", "response": "Launch a remote profiler."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninspect statistics by TUI view.", "response": "def view(src, mono):\n    \"\"\"Inspect statistics by TUI view.\"\"\"\n    src_type, src_name = src\n    title = get_title(src_name, src_type)\n    viewer, loop = make_viewer(mono)\n    if src_type == 'dump':\n        time = datetime.fromtimestamp(os.path.getmtime(src_name))\n        with open(src_name, 'rb') as f:\n            profiler_class, (stats, cpu_time, wall_time) = pickle.load(f)\n        viewer.set_profiler_class(profiler_class)\n        viewer.set_result(stats, cpu_time, wall_time, title=title, at=time)\n        viewer.activate()\n    elif src_type in ('tcp', 'sock'):\n        family = {'tcp': socket.AF_INET, 'sock': socket.AF_UNIX}[src_type]\n        client = FailoverProfilingClient(viewer, loop.event_loop,\n                                         src_name, family, title=title)\n        client.start()\n    try:\n        loop.run()\n    except KeyboardInterrupt:\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef timeit_profile(stmt, number, repeat, setup,\n                   profiler_factory, pickle_protocol, dump_filename, mono,\n                   **_ignored):\n    \"\"\"Profile a Python statement like timeit.\"\"\"\n    del _ignored\n    globals_ = {}\n    exec_(setup, globals_)\n    if number is None:\n        # determine number so that 0.2 <= total time < 2.0 like timeit.\n        dummy_profiler = profiler_factory()\n        dummy_profiler.start()\n        for x in range(1, 10):\n            number = 10 ** x\n            t = time.time()\n            for y in range(number):\n                exec_(stmt, globals_)\n            if time.time() - t >= 0.2:\n                break\n        dummy_profiler.stop()\n        del dummy_profiler\n    code = compile('for _ in range(%d): %s' % (number, stmt),\n                   'STATEMENT', 'exec')\n    __profile__(stmt, code, globals_, profiler_factory,\n                pickle_protocol=pickle_protocol, dump_filename=dump_filename,\n                mono=mono)", "response": "Profile a Python statement like timeit."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef command(self, *args, **kwargs):\n        aliases = kwargs.pop('aliases', None)\n        decorator = super(ProfilingCLI, self).command(*args, **kwargs)\n        if aliases is None:\n            return decorator\n        def _decorator(f):\n            cmd = decorator(f)\n            for alias in aliases:\n                self.command_name_aliases[alias] = cmd.name\n            return cmd\n        return _decorator", "response": "A decorator for the base class to register the command name for the current user."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\niterates all descendant statistics under the given root statistics. When spreader = True each iteration yields a descendant statistics and spread_t together.", "response": "def spread_stats(stats, spreader=False):\n    \"\"\"Iterates all descendant statistics under the given root statistics.\n\n    When ``spreader=True``, each iteration yields a descendant statistics and\n    `spread()` function together.  You should call `spread()` if you want to\n    spread the yielded statistics also.\n\n    \"\"\"\n    spread = spread_t() if spreader else True\n    descendants = deque(stats)\n    while descendants:\n        _stats = descendants.popleft()\n        if spreader:\n            spread.clear()\n            yield _stats, spread\n        else:\n            yield _stats\n        if spread:\n            descendants.extend(_stats)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmakes a flat members tree of the given statistics.", "response": "def make_frozen_stats_tree(stats):\n    \"\"\"Makes a flat members tree of the given statistics.  The statistics can\n    be restored by :func:`frozen_stats_from_tree`.\n    \"\"\"\n    tree, stats_tree = [], [(None, stats)]\n    for x in itertools.count():\n        try:\n            parent_offset, _stats = stats_tree[x]\n        except IndexError:\n            break\n        stats_tree.extend((x, s) for s in _stats)\n        members = (_stats.name, _stats.filename, _stats.lineno,\n                   _stats.module, _stats.own_hits, _stats.deep_time)\n        tree.append((parent_offset, members))\n    return tree"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef frozen_stats_from_tree(tree):\n    if not tree:\n        raise ValueError('Empty tree')\n    stats_index = []\n    for parent_offset, members in tree:\n        stats = FrozenStatistics(*members)\n        stats_index.append(stats)\n        if parent_offset is not None:\n            stats_index[parent_offset].children.append(stats)\n    return stats_index[0]", "response": "Restores a statistics from the given flat members tree."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef deep_hits(self):\n        hits = [self.own_hits]\n        hits.extend(stats.own_hits for stats in spread_stats(self))\n        return sum(hits)", "response": "The inclusive calling number."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmake a flat statistics from the given statistics.", "response": "def flatten(cls, stats):\n        \"\"\"Makes a flat statistics from the given statistics.\"\"\"\n        flat_children = {}\n        for _stats in spread_stats(stats):\n            key = (_stats.name, _stats.filename, _stats.lineno, _stats.module)\n            try:\n                flat_stats = flat_children[key]\n            except KeyError:\n                flat_stats = flat_children[key] = cls(*key)\n            flat_stats.own_hits += _stats.own_hits\n            flat_stats.deep_hits += _stats.deep_hits\n            flat_stats.own_time += _stats.own_time\n            flat_stats.deep_time += _stats.deep_time\n        children = list(itervalues(flat_children))\n        return cls(stats.name, stats.filename, stats.lineno, stats.module,\n                   stats.own_hits, stats.deep_hits, stats.own_time,\n                   stats.deep_time, children)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads requirements from a file.", "response": "def requirements(filename):\n    \"\"\"Reads requirements from a file.\"\"\"\n    with open(filename) as f:\n        return [x.strip() for x in f.readlines() if x.strip()]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sample(self, frame):\n        frames = self.frame_stack(frame)\n        if frames:\n            frames.pop()\n        parent_stats = self.stats\n        for f in frames:\n            parent_stats = parent_stats.ensure_child(f.f_code, void)\n        stats = parent_stats.ensure_child(frame.f_code, RecordingStatistics)\n        stats.own_hits += 1", "response": "Samples the given frame."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndefers a function call when it is being required like Go. :: with deferral() as defer: sys.setprofile(f) defer(sys.setprofile, None) # do something.", "response": "def deferral():\n    \"\"\"Defers a function call when it is being required like Go.\n\n    ::\n\n       with deferral() as defer:\n           sys.setprofile(f)\n           defer(sys.setprofile, None)\n           # do something.\n\n    \"\"\"\n    deferred = []\n    defer = lambda f, *a, **k: deferred.append((f, a, k))\n    try:\n        yield defer\n    finally:\n        while deferred:\n            f, a, k = deferred.pop()\n            f(*a, **k)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef start(self, *args, **kwargs):\n        if self.is_running():\n            raise RuntimeError('Already started')\n        self._running = self.run(*args, **kwargs)\n        try:\n            yielded = next(self._running)\n        except StopIteration:\n            raise TypeError('run() must yield just one time')\n        if yielded is not None:\n            raise TypeError('run() must yield without value')", "response": "Starts the instance.\n\n        :raises RuntimeError: has been already started.\n        :raises TypeError: :meth:`run` is not canonical."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstop the instance. :raises RuntimeError: has not been started. :raises TypeError: :meth:`run` is not canonical.", "response": "def stop(self):\n        \"\"\"Stops the instance.\n\n        :raises RuntimeError: has not been started.\n        :raises TypeError: :meth:`run` is not canonical.\n\n        \"\"\"\n        if not self.is_running():\n            raise RuntimeError('Not started')\n        running, self._running = self._running, None\n        try:\n            next(running)\n        except StopIteration:\n            # expected.\n            pass\n        else:\n            raise TypeError('run() must yield just one time')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sockets(self):\n        if self.listener is None:\n            return self.clients\n        else:\n            return self.clients.union([self.listener])", "response": "Returns the set of the sockets."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef select_sockets(self, timeout=None):\n        if timeout is not None:\n            t = time.time()\n        while True:\n            try:\n                ready, __, __ = select.select(self.sockets(), (), (), timeout)\n            except ValueError:\n                # there's fd=0 socket.\n                pass\n            except select.error as exc:\n                # ignore an interrupted system call.\n                if exc.args[0] != EINTR:\n                    raise\n            else:\n                # succeeded.\n                return ready\n            # retry.\n            if timeout is None:\n                continue\n            # decrease timeout.\n            t2 = time.time()\n            timeout -= t2 - t\n            t = t2\n            if timeout <= 0:\n                # timed out.\n                return []", "response": "EINTR safe version of select. It focuses on just incoming\n            sockets."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _profile(self, frame, event, arg):\n        # c = event.startswith('c_')\n        if event.startswith('c_'):\n            return\n        time1 = self.timer()\n        frames = self.frame_stack(frame)\n        if frames:\n            frames.pop()\n        parent_stats = self.stats\n        for f in frames:\n            parent_stats = parent_stats.ensure_child(f.f_code, void)\n        code = frame.f_code\n        frame_key = id(frame)\n        # if c:\n        #     event = event[2:]\n        #     code = mock_code(arg.__name__)\n        #     frame_key = id(arg)\n        # record\n        time2 = self.timer()\n        self.overhead += time2 - time1\n        if event == 'call':\n            time = time2 - self.overhead\n            self.record_entering(time, code, frame_key, parent_stats)\n        elif event == 'return':\n            time = time1 - self.overhead\n            self.record_leaving(time, code, frame_key, parent_stats)\n        time3 = self.timer()\n        self.overhead += time3 - time2", "response": "The callback function to register by sys. setprofile."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef record_entering(self, time, code, frame_key, parent_stats):\n        stats = parent_stats.ensure_child(code, RecordingStatistics)\n        self._times_entered[(code, frame_key)] = time\n        stats.own_hits += 1", "response": "Record that a function call was entered."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef record_leaving(self, time, code, frame_key, parent_stats):\n        try:\n            stats = parent_stats.get_child(code)\n            time_entered = self._times_entered.pop((code, frame_key))\n        except KeyError:\n            return\n        time_elapsed = time - time_entered\n        stats.deep_time += max(0, time_elapsed)", "response": "Record that a child is leaving."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build_sink(function: Callable[..., None] = None, *,\n               unpack: bool = False):\n    \"\"\" Decorator to wrap a function to return a Sink subscriber.\n\n    :param function: function to be wrapped\n    :param unpack: value from emits will be unpacked (*value)\n    \"\"\"\n    def _build_sink(function: Callable[..., None]):\n        @wraps(function)\n        def _wrapper(*args, **kwargs) -> Sink:\n            if 'unpack' in kwargs:\n                raise TypeError('\"unpack\" has to be defined by decorator')\n            return Sink(function, *args, unpack=unpack, **kwargs)\n        return _wrapper\n\n    if function:\n        return _build_sink(function)\n\n    return _build_sink", "response": "Decorator to wrap a function to return a Sink subscriber."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build_map(function: Callable[[Any], Any] = None,\n              unpack: bool = False):\n    \"\"\" Decorator to wrap a function to return a Map operator.\n\n    :param function: function to be wrapped\n    :param unpack: value from emits will be unpacked (*value)\n    \"\"\"\n    def _build_map(function: Callable[[Any], Any]):\n        @wraps(function)\n        def _wrapper(*args, **kwargs) -> Map:\n            if 'unpack' in kwargs:\n                raise TypeError('\"unpack\" has to be defined by decorator')\n            return Map(function, *args, unpack=unpack, **kwargs)\n        return _wrapper\n\n    if function:\n        return _build_map(function)\n\n    return _build_map", "response": "Decorator to wrap a function to return a Map operator."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndefaults trace handler is printing the timestamp the publisher name and the emitted value", "response": "def _trace_handler(publisher, value, label=None):\n        \"\"\" Default trace handler is printing the timestamp, the publisher name\n        and the emitted value\n        \"\"\"\n        line = '--- %8.3f: ' % (time() - Trace._timestamp_start)\n        line += repr(publisher) if label is None else label\n        line += ' %r' % (value,)\n        print(line)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef build_accumulate(function: Callable[[Any, Any], Tuple[Any, Any]] = None, *,\n                     init: Any = NONE):\n    \"\"\" Decorator to wrap a function to return an Accumulate operator.\n\n    :param function: function to be wrapped\n    :param init: optional initialization for state\n    \"\"\"\n    _init = init\n\n    def _build_accumulate(function: Callable[[Any, Any], Tuple[Any, Any]]):\n        @wraps(function)\n        def _wrapper(init=NONE) -> Accumulate:\n            init = _init if init is NONE else init\n            if init is NONE:\n                raise TypeError('\"init\" argument has to be defined')\n            return Accumulate(function, init=init)\n        return _wrapper\n\n    if function:\n        return _build_accumulate(function)\n\n    return _build_accumulate", "response": "Decorator to wrap a function to return an Accumulate operator."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nresolve a value when it s a string and starts with '>'", "response": "def resolve_meta_key(hub, key, meta):\n    \"\"\" Resolve a value when it's a string and starts with '>' \"\"\"\n    if key not in meta:\n        return None\n    value = meta[key]\n    if isinstance(value, str) and value[0] == '>':\n        topic = value[1:]\n        if topic not in hub:\n            raise KeyError('topic %s not found in hub' % topic)\n        return hub[topic].get()\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncasts and checking in one call", "response": "def checked_emit(self, value: Any) -> asyncio.Future:\n        \"\"\" Casting and checking in one call \"\"\"\n\n        if not isinstance(self._subject, Subscriber):\n            raise TypeError('Topic %r has to be a subscriber' % self._path)\n\n        value = self.cast(value)\n        self.check(value)\n        return self._subject.emit(value, who=self)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_datatype(self, name: str, datatype: DT):\n        self._datatypes[name] = datatype", "response": "Register the datatype with its name"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cast(self, topic, value):\n        datatype_key = topic.meta.get('datatype', 'none')\n        result = self._datatypes[datatype_key].cast(topic, value)\n        validate_dt = topic.meta.get('validate', None)\n        if validate_dt:\n            result = self._datatypes[validate_dt].cast(topic, result)\n        return result", "response": "Cast a string to the value based on the datatype"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check(self, topic, value):\n        datatype_key = topic.meta.get('datatype', 'none')\n        self._datatypes[datatype_key].check(topic, value)\n        validate_dt = topic.meta.get('validate', None)\n        if validate_dt:\n            self._datatypes[validate_dt].check(topic, value)", "response": "Checks the value if it fits into the given specification"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef flush(self):\n        self.notify(tuple(self._queue))\n        self._queue.clear()", "response": "Emits the current queue and clears the queue"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _periodic_callback(self):\n        try:\n            self.notify(self._state)  # emit to all subscribers\n        except Exception:  # pylint: disable=broad-except\n            self._error_callback(*sys.exc_info())\n\n        if self._subscriptions:\n            # if there are still subscriptions register next _periodic callback\n            self._call_later_handle = \\\n                self._loop.call_later(self._interval, self._periodic_callback)\n        else:\n            self._state = NONE\n            self._call_later_handle = None", "response": "Called by _periodic_callback to start the callback loop."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nflushing the queue - this will emit the current queue", "response": "def flush(self):\n        \"\"\" Flush the queue - this will emit the current queue \"\"\"\n        if not self._emit_partial and len(self._state) != self._state.maxlen:\n            self.notify(tuple(self._state))\n        self._state.clear()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build_map_async(coro=None, *, mode=None, unpack: bool = False):\n    _mode = mode\n\n    def _build_map_async(coro):\n        @wraps(coro)\n        def _wrapper(*args, mode=None, **kwargs) -> MapAsync:\n            if 'unpack' in kwargs:\n                raise TypeError('\"unpack\" has to be defined by decorator')\n            if mode is None:\n                mode = MODE.CONCURRENT if _mode is None else _mode\n            return MapAsync(coro, *args, mode=mode, unpack=unpack, **kwargs)\n        return _wrapper\n\n    if coro:\n        return _build_map_async(coro)\n\n    return _build_map_async", "response": "Decorator to wrap a coroutine to return a MapAsync operator."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncall when the coroutine is done", "response": "def _future_done(self, future):\n        \"\"\" Will be called when the coroutine is done \"\"\"\n        try:\n            # notify the subscribers (except result is an exception or NONE)\n            result = future.result()  # may raise exception\n            if result is not NONE:\n                self.notify(result)  # may also raise exception\n        except asyncio.CancelledError:\n            return\n        except Exception:  # pylint: disable=broad-except\n            self._options.error_callback(*sys.exc_info())\n\n        # check if queue is present and something is in the queue\n        if self._queue:\n            value = self._queue.popleft()\n\n            # start the coroutine\n            self._run_coro(value)\n        else:\n            self._future = None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstarts the coroutine as task", "response": "def _run_coro(self, value):\n        \"\"\" Start the coroutine as task \"\"\"\n\n        # when LAST_DISTINCT is used only start coroutine when value changed\n        if self._options.mode is MODE.LAST_DISTINCT and \\\n                value == self._last_emit:\n            self._future = None\n            return\n\n        # store the value to be emitted for LAST_DISTINCT\n        self._last_emit = value\n\n        # publish the start of the coroutine\n        self.scheduled.notify(value)\n\n        # build the coroutine\n        values = value if self._options.unpack else (value,)\n        coro = self._options.coro(*values, *self._options.args,\n                                  **self._options.kwargs)\n\n        # create a task out of it and add ._future_done as callback\n        self._future = asyncio.ensure_future(coro)\n        self._future.add_done_callback(self._future_done)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef build_filter(predicate: Callable[[Any], bool] = None, *,\n                 unpack: bool = False):\n    \"\"\" Decorator to wrap a function to return a Filter operator.\n\n    :param predicate: function to be wrapped\n    :param unpack: value from emits will be unpacked (*value)\n    \"\"\"\n    def _build_filter(predicate: Callable[[Any], bool]):\n        @wraps(predicate)\n        def _wrapper(*args, **kwargs) -> Filter:\n            if 'unpack' in kwargs:\n                raise TypeError('\"unpack\" has to be defined by decorator')\n            return Filter(predicate, *args, unpack=unpack, **kwargs)\n        return _wrapper\n\n    if predicate:\n        return _build_filter(predicate)\n\n    return _build_filter", "response": "Decorator to wrap a function to return a Filter operator."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfunctioning to apply operator overloading to a base - level object", "response": "def apply_operator_overloading():\n    \"\"\" Function to apply operator overloading to Publisher class \"\"\"\n    # operator overloading is (unfortunately) not working for the following\n    # cases:\n    # int, float, str - should return appropriate type instead of a Publisher\n    # len - should return an integer\n    # \"x in y\" - is using __bool__ which is not working with Publisher\n    for method in (\n            '__lt__', '__le__', '__eq__', '__ne__', '__ge__', '__gt__',\n            '__add__', '__and__', '__lshift__', '__mod__', '__mul__',\n            '__pow__', '__rshift__', '__sub__', '__xor__', '__concat__',\n            '__getitem__', '__floordiv__', '__truediv__'):\n        def _op(operand_left, operand_right, operation=method):\n            if isinstance(operand_right, Publisher):\n                return CombineLatest(operand_left, operand_right,\n                                     map_=getattr(operator, operation))\n            return _MapConstant(operand_left, operand_right,\n                                getattr(operator, operation))\n\n        setattr(Publisher, method, _op)\n\n    for method, _method in (\n            ('__radd__', '__add__'), ('__rand__', '__and__'),\n            ('__rlshift__', '__lshift__'), ('__rmod__', '__mod__'),\n            ('__rmul__', '__mul__'), ('__rpow__', '__pow__'),\n            ('__rrshift__', '__rshift__'), ('__rsub__', '__sub__'),\n            ('__rxor__', '__xor__'), ('__rfloordiv__', '__floordiv__'),\n            ('__rtruediv__', '__truediv__')):\n        def _op(operand_left, operand_right, operation=_method):\n            return _MapConstantReverse(operand_left, operand_right,\n                                       getattr(operator, operation))\n\n        setattr(Publisher, method, _op)\n\n    for method, _method in (\n            ('__neg__', operator.neg), ('__pos__', operator.pos),\n            ('__abs__', operator.abs), ('__invert__', operator.invert),\n            ('__round__', round), ('__trunc__', math.trunc),\n            ('__floor__', math.floor), ('__ceil__', math.ceil)):\n        def _op_unary(operand, operation=_method):\n            return _MapUnary(operand, operation)\n\n        setattr(Publisher, method, _op_unary)\n\n    def _getattr(publisher, attribute_name):\n        if not publisher.inherited_type or \\\n           not hasattr(publisher.inherited_type, attribute_name):\n            raise AttributeError('Attribute %r not found' % attribute_name)\n        return _GetAttr(publisher, attribute_name)\n\n    setattr(Publisher, '__getattr__', _getattr)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef assign(self, subject):\n        if not isinstance(subject, (Publisher, Subscriber)):\n            raise TypeError('Assignee has to be Publisher or Subscriber')\n\n        # check if not already assigned\n        if self._subject is not None:\n            raise SubscriptionError('Topic %r already assigned' % self._path)\n\n        self._subject = subject\n\n        # subscribe to subject if topic has subscriptions\n        if self._subscriptions:\n            self._subject.subscribe(self)\n\n        # if topic received emits before assignment replay those emits\n        if self._pre_assign_emit is not None:\n            for value in self._pre_assign_emit:\n                self._subject.emit(value, who=self)\n            self._pre_assign_emit = None\n\n        return subject", "response": "Assign the given subject to the topic."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef freeze(self, freeze: bool = True):\n        for topic in self._topics.values():\n            topic.freeze()\n        self._frozen = freeze", "response": "Freeze the hub means that each topic has to be assigned and no\n        new topics can be created after this point."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\norder dictionary with path : topic ordered by path", "response": "def topics(self):\n        \"\"\" Ordered dictionary with path:topic ordered by path \"\"\"\n        topics_sorted = sorted(self._topics.items(), key=lambda t: t[0])\n        return MappingProxyType(OrderedDict(topics_sorted))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nresetting the duration for throttling", "response": "def reset(self):\n        \"\"\" Reseting duration for throttling \"\"\"\n        if self._call_later_handler is not None:\n            self._call_later_handler.cancel()\n            self._call_later_handler = None\n            self._wait_done_cb()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreset the debounce time.", "response": "def reset(self):\n        \"\"\" Reset the debounce time \"\"\"\n        if self._retrigger_value is not NONE:\n            self.notify(self._retrigger_value)\n            self._state = self._retrigger_value\n            self._next_state = self._retrigger_value\n        if self._call_later_handler:\n            self._call_later_handler.cancel()\n            self._call_later_handler = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef subscribe(self, subscriber: 'Subscriber',\n                  prepend: bool = False) -> SubscriptionDisposable:\n        \"\"\" Subscribing the given subscriber.\n\n        :param subscriber: subscriber to add\n        :param prepend: For internal use - usually the subscribers will be\n            added at the end of a list. When prepend is True, it will be added\n            in front of the list. This will habe an effect in the order the\n            subscribers are called.\n        :raises SubscriptionError: if subscriber already subscribed\n        \"\"\"\n\n        # `subscriber in self._subscriptions` is not working because\n        # tuple.__contains__ is using __eq__ which is overwritten and returns\n        # a new publisher - not helpful here\n        if any(subscriber is s for s in self._subscriptions):\n            raise SubscriptionError('Subscriber already registered')\n\n        if prepend:\n            self._subscriptions.insert(0, subscriber)\n        else:\n            self._subscriptions.append(subscriber)\n\n        return SubscriptionDisposable(self, subscriber)", "response": "Subscribe the given subscriber to the internal list of the available keys."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalling .emit(value) on all subscribers. A synchronouse subscriber will just return None, a asynchronous one may returns a future. Futures will be collected. If no future was returned None will be returned by this method. If one futrue was returned that future will be returned. When multiple futures were returned a gathered future will be returned. :param value: value to be emitted to subscribers :returns: a future if at least one subscriber has returned a future, elsewise None", "response": "def notify(self, value: Any) -> asyncio.Future:\n        \"\"\" Calling .emit(value) on all subscribers. A synchronouse subscriber\n        will just return None, a asynchronous one may returns a future. Futures\n        will be collected. If no future was returned None will be returned by\n        this method. If one futrue was returned that future will be returned.\n        When multiple futures were returned a gathered future will be returned.\n\n        :param value: value to be emitted to subscribers\n        :returns: a future if at least one subscriber has returned a future,\n            elsewise None\n        \"\"\"\n        results = (s.emit(value, who=self) for s in self._subscriptions)\n        futures = tuple(r for r in results if r is not None)\n\n        if not futures:\n            return None\n\n        if len(futures) == 1:\n            return futures[0]  # return the received single future\n\n        return asyncio.gather(*futures)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef wait_for(self, timeout=None):\n        from broqer.op import OnEmitFuture  # due circular dependency\n        return self | OnEmitFuture(timeout=timeout)", "response": "When a timeout is applied use this method."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the inherit type of the object.", "response": "def inherit_type(self, type_cls: Type[TInherit]) \\\n            -> Union[TInherit, 'Publisher']:\n        \"\"\" enables the usage of method and attribute overloading for this\n        publisher.\n        \"\"\"\n        self._inherited_type = type_cls\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the state of this object if defined otherwise raises a ValueError.", "response": "def get(self):\n        \"\"\" Returns state if defined else it raises a ValueError. See also\n        Publisher.get().\n\n        :raises ValueError: if this publisher is not initialized and has not\n            received any emits.\n        \"\"\"\n        if self._state is not NONE:\n            return self._state\n        return Publisher.get(self)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef notify(self, value: Any) -> asyncio.Future:\n        if self._state == value:\n            return None\n\n        self._state = value\n        return Publisher.notify(self, value)", "response": "Notify subscribers of a new value."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _move_tuple_axes_first(array, axis):\n\n    # Figure out how many axes we are operating over\n    naxis = len(axis)\n\n    # Add remaining axes to the axis tuple\n    axis += tuple(i for i in range(array.ndim) if i not in axis)\n\n    # The new position of each axis is just in order\n    destination = tuple(range(array.ndim))\n\n    # Reorder the array so that the axes being operated on are at the beginning\n    array_new = np.moveaxis(array, axis, destination)\n\n    # Figure out the size of the product of the dimensions being operated on\n    first = np.prod(array_new.shape[:naxis])\n\n    # Collapse the dimensions being operated on into a single dimension so that\n    # we can then use axis=0 with the bottleneck functions\n    array_new = array_new.reshape((first,) + array_new.shape[naxis:])\n\n    return array_new", "response": "This function moves the array along the specified axis and returns the new array."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _nanmean(array, axis=None):\n\n    if isinstance(axis, tuple):\n        array = _move_tuple_axes_first(array, axis=axis)\n        axis = 0\n    return bottleneck.nanmean(array, axis=axis)", "response": "Bottleneck nanmean function that handle tuple axis."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _nanmedian(array, axis=None):\n\n    if isinstance(axis, tuple):\n        array = _move_tuple_axes_first(array, axis=axis)\n        axis = 0\n    return bottleneck.nanmedian(array, axis=axis)", "response": "Bottleneck nanmedian function that handle tuple axis."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _nanstd(array, axis=None, ddof=0):\n\n    if isinstance(axis, tuple):\n        array = _move_tuple_axes_first(array, axis=axis)\n        axis = 0\n    return bottleneck.nanstd(array, axis=axis, ddof=ddof)", "response": "Bottleneck nanstd function that handle tuple axis."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sigma_clip(data, sigma=3, sigma_lower=None, sigma_upper=None, maxiters=5,\n               cenfunc='median', stdfunc='std', axis=None, masked=True,\n               return_bounds=False, copy=True):\n    \"\"\"\n    Perform sigma-clipping on the provided data.\n\n    The data will be iterated over, each time rejecting values that are\n    less or more than a specified number of standard deviations from a\n    center value.\n\n    Clipped (rejected) pixels are those where::\n\n        data < cenfunc(data [,axis=int]) - (sigma_lower * stdfunc(data [,axis=int]))\n        data > cenfunc(data [,axis=int]) + (sigma_upper * stdfunc(data [,axis=int]))\n\n    Invalid data values (i.e. NaN or inf) are automatically clipped.\n\n    For an object-oriented interface to sigma clipping, see\n    :class:`SigmaClip`.\n\n    .. note::\n        `scipy.stats.sigmaclip\n        <https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.sigmaclip.html>`_\n        provides a subset of the functionality in this class.  Also, its\n        input data cannot be a masked array and it does not handle data\n        that contains invalid values (i.e.  NaN or inf).  Also note that\n        it uses the mean as the centering function.\n\n        If your data is a `~numpy.ndarray` with no invalid values and\n        you want to use the mean as the centering function with\n        ``axis=None`` and iterate to convergence, then\n        `scipy.stats.sigmaclip` is ~25-30% faster than the equivalent\n        settings here (``sigma_clip(data, cenfunc='mean', maxiters=None,\n        axis=None)``).\n\n    Parameters\n    ----------\n    data : array-like or `~numpy.ma.MaskedArray`\n        The data to be sigma clipped.\n\n    sigma : float, optional\n        The number of standard deviations to use for both the lower and\n        upper clipping limit.  These limits are overridden by\n        ``sigma_lower`` and ``sigma_upper``, if input.  The default is\n        3.\n\n    sigma_lower : float or `None`, optional\n        The number of standard deviations to use as the lower bound for\n        the clipping limit.  If `None` then the value of ``sigma`` is\n        used.  The default is `None`.\n\n    sigma_upper : float or `None`, optional\n        The number of standard deviations to use as the upper bound for\n        the clipping limit.  If `None` then the value of ``sigma`` is\n        used.  The default is `None`.\n\n    maxiters : int or `None`, optional\n        The maximum number of sigma-clipping iterations to perform or\n        `None` to clip until convergence is achieved (i.e., iterate\n        until the last iteration clips nothing).  If convergence is\n        achieved prior to ``maxiters`` iterations, the clipping\n        iterations will stop.  The default is 5.\n\n    cenfunc : {'median', 'mean'} or callable, optional\n        The statistic or callable function/object used to compute the\n        center value for the clipping.  If set to ``'median'`` or\n        ``'mean'`` then having the optional `bottleneck`_ package\n        installed will result in the best performance.  If using a\n        callable function/object and the ``axis`` keyword is used, then\n        it must be callable that can ignore NaNs (e.g. `numpy.nanmean`)\n        and has an ``axis`` keyword to return an array with axis\n        dimension(s) removed.  The default is ``'median'``.\n\n        .. _bottleneck:  https://github.com/kwgoodman/bottleneck\n\n    stdfunc : {'std'} or callable, optional\n        The statistic or callable function/object used to compute the\n        standard deviation about the center value.  If set to ``'std'``\n        then having the optional `bottleneck`_ package installed will\n        result in the best performance.  If using a callable\n        function/object and the ``axis`` keyword is used, then it must\n        be callable that can ignore NaNs (e.g. `numpy.nanstd`) and has\n        an ``axis`` keyword to return an array with axis dimension(s)\n        removed.  The default is ``'std'``.\n\n    axis : `None` or int or tuple of int, optional\n        The axis or axes along which to sigma clip the data.  If `None`,\n        then the flattened data will be used.  ``axis`` is passed to the\n        ``cenfunc`` and ``stdfunc``.  The default is `None`.\n\n    masked : bool, optional\n        If `True`, then a `~numpy.ma.MaskedArray` is returned, where the\n        mask is `True` for clipped values.  If `False`, then a\n        `~numpy.ndarray` and the minimum and maximum clipping thresholds\n        are returned.  The default is `True`.\n\n    return_bounds : bool, optional\n        If `True`, then the minimum and maximum clipping bounds are also\n        returned.\n\n    copy : bool, optional\n        If `True`, then the ``data`` array will be copied.  If `False`\n        and ``masked=True``, then the returned masked array data will\n        contain the same array as the input ``data`` (if ``data`` is a\n        `~numpy.ndarray` or `~numpy.ma.MaskedArray`).  The default is\n        `True`.\n\n    Returns\n    -------\n    result : flexible\n        If ``masked=True``, then a `~numpy.ma.MaskedArray` is returned,\n        where the mask is `True` for clipped values.  If\n        ``masked=False``, then a `~numpy.ndarray` is returned.\n\n        If ``return_bounds=True``, then in addition to the (masked)\n        array above, the minimum and maximum clipping bounds are\n        returned.\n\n        If ``masked=False`` and ``axis=None``, then the output array is\n        a flattened 1D `~numpy.ndarray` where the clipped values have\n        been removed.  If ``return_bounds=True`` then the returned\n        minimum and maximum thresholds are scalars.\n\n        If ``masked=False`` and ``axis`` is specified, then the output\n        `~numpy.ndarray` will have the same shape as the input ``data``\n        and contain ``np.nan`` where values were clipped.  If\n        ``return_bounds=True`` then the returned minimum and maximum\n        clipping thresholds will be be `~numpy.ndarray`\\\\s.\n\n    See Also\n    --------\n    SigmaClip, sigma_clipped_stats\n\n    Examples\n    --------\n    This example uses a data array of random variates from a Gaussian\n    distribution.  We clip all points that are more than 2 sample\n    standard deviations from the median.  The result is a masked array,\n    where the mask is `True` for clipped data::\n\n        >>> from astropy.stats import sigma_clip\n        >>> from numpy.random import randn\n        >>> randvar = randn(10000)\n        >>> filtered_data = sigma_clip(randvar, sigma=2, maxiters=5)\n\n    This example clips all points that are more than 3 sigma relative to\n    the sample *mean*, clips until convergence, returns an unmasked\n    `~numpy.ndarray`, and does not copy the data::\n\n        >>> from astropy.stats import sigma_clip\n        >>> from numpy.random import randn\n        >>> from numpy import mean\n        >>> randvar = randn(10000)\n        >>> filtered_data = sigma_clip(randvar, sigma=3, maxiters=None,\n        ...                            cenfunc=mean, masked=False, copy=False)\n\n    This example sigma clips along one axis::\n\n        >>> from astropy.stats import sigma_clip\n        >>> from numpy.random import normal\n        >>> from numpy import arange, diag, ones\n        >>> data = arange(5) + normal(0., 0.05, (5, 5)) + diag(ones(5))\n        >>> filtered_data = sigma_clip(data, sigma=2.3, axis=0)\n\n    Note that along the other axis, no points would be clipped, as the\n    standard deviation is higher.\n    \"\"\"\n\n    sigclip = SigmaClip(sigma=sigma, sigma_lower=sigma_lower,\n                        sigma_upper=sigma_upper, maxiters=maxiters,\n                        cenfunc=cenfunc, stdfunc=stdfunc)\n\n    return sigclip(data, axis=axis, masked=masked,\n                   return_bounds=return_bounds, copy=copy)", "response": "Perform sigma - clipped on the input data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sigma_clipped_stats(data, mask=None, mask_value=None, sigma=3.0,\n                        sigma_lower=None, sigma_upper=None, maxiters=5,\n                        cenfunc='median', stdfunc='std', std_ddof=0,\n                        axis=None):\n    \"\"\"\n    Calculate sigma-clipped statistics on the provided data.\n\n    Parameters\n    ----------\n    data : array-like or `~numpy.ma.MaskedArray`\n        Data array or object that can be converted to an array.\n\n    mask : `numpy.ndarray` (bool), optional\n        A boolean mask with the same shape as ``data``, where a `True`\n        value indicates the corresponding element of ``data`` is masked.\n        Masked pixels are excluded when computing the statistics.\n\n    mask_value : float, optional\n        A data value (e.g., ``0.0``) that is ignored when computing the\n        statistics.  ``mask_value`` will be masked in addition to any\n        input ``mask``.\n\n    sigma : float, optional\n        The number of standard deviations to use for both the lower and\n        upper clipping limit.  These limits are overridden by\n        ``sigma_lower`` and ``sigma_upper``, if input.  The default is\n        3.\n\n    sigma_lower : float or `None`, optional\n        The number of standard deviations to use as the lower bound for\n        the clipping limit.  If `None` then the value of ``sigma`` is\n        used.  The default is `None`.\n\n    sigma_upper : float or `None`, optional\n        The number of standard deviations to use as the upper bound for\n        the clipping limit.  If `None` then the value of ``sigma`` is\n        used.  The default is `None`.\n\n    maxiters : int or `None`, optional\n        The maximum number of sigma-clipping iterations to perform or\n        `None` to clip until convergence is achieved (i.e., iterate\n        until the last iteration clips nothing).  If convergence is\n        achieved prior to ``maxiters`` iterations, the clipping\n        iterations will stop.  The default is 5.\n\n    cenfunc : {'median', 'mean'} or callable, optional\n        The statistic or callable function/object used to compute the\n        center value for the clipping.  If set to ``'median'`` or\n        ``'mean'`` then having the optional `bottleneck`_ package\n        installed will result in the best performance.  If using a\n        callable function/object and the ``axis`` keyword is used, then\n        it must be callable that can ignore NaNs (e.g. `numpy.nanmean`)\n        and has an ``axis`` keyword to return an array with axis\n        dimension(s) removed.  The default is ``'median'``.\n\n        .. _bottleneck:  https://github.com/kwgoodman/bottleneck\n\n    stdfunc : {'std'} or callable, optional\n        The statistic or callable function/object used to compute the\n        standard deviation about the center value.  If set to ``'std'``\n        then having the optional `bottleneck`_ package installed will\n        result in the best performance.  If using a callable\n        function/object and the ``axis`` keyword is used, then it must\n        be callable that can ignore NaNs (e.g. `numpy.nanstd`) and has\n        an ``axis`` keyword to return an array with axis dimension(s)\n        removed.  The default is ``'std'``.\n\n    std_ddof : int, optional\n        The delta degrees of freedom for the standard deviation\n        calculation.  The divisor used in the calculation is ``N -\n        std_ddof``, where ``N`` represents the number of elements.  The\n        default is 0.\n\n    axis : `None` or int or tuple of int, optional\n        The axis or axes along which to sigma clip the data.  If `None`,\n        then the flattened data will be used.  ``axis`` is passed\n        to the ``cenfunc`` and ``stdfunc``.  The default is `None`.\n\n    Returns\n    -------\n    mean, median, stddev : float\n        The mean, median, and standard deviation of the sigma-clipped\n        data.\n\n    See Also\n    --------\n    SigmaClip, sigma_clip\n    \"\"\"\n\n    if mask is not None:\n        data = np.ma.MaskedArray(data, mask)\n    if mask_value is not None:\n        data = np.ma.masked_values(data, mask_value)\n\n    sigclip = SigmaClip(sigma=sigma, sigma_lower=sigma_lower,\n                        sigma_upper=sigma_upper, maxiters=maxiters,\n                        cenfunc=cenfunc, stdfunc=stdfunc)\n    data_clipped = sigclip(data, axis=axis, masked=False, return_bounds=False,\n                           copy=False)\n\n    if HAS_BOTTLENECK:\n        mean = _nanmean(data_clipped, axis=axis)\n        median = _nanmedian(data_clipped, axis=axis)\n        std = _nanstd(data_clipped, ddof=std_ddof, axis=axis)\n    else:  # pragma: no cover\n        mean = np.nanmean(data_clipped, axis=axis)\n        median = np.nanmedian(data_clipped, axis=axis)\n        std = np.nanstd(data_clipped, ddof=std_ddof, axis=axis)\n\n    return mean, median, std", "response": "Calculate sigma - clipped statistics on the provided data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _sigmaclip_noaxis(self, data, masked=True, return_bounds=False,\n                          copy=True):\n        \"\"\"\n        Sigma clip the data when ``axis`` is None.\n\n        In this simple case, we remove clipped elements from the\n        flattened array during each iteration.\n        \"\"\"\n\n        filtered_data = data.ravel()\n\n        # remove masked values and convert to ndarray\n        if isinstance(filtered_data, np.ma.MaskedArray):\n            filtered_data = filtered_data.data[~filtered_data.mask]\n\n        # remove invalid values\n        good_mask = np.isfinite(filtered_data)\n        if np.any(~good_mask):\n            filtered_data = filtered_data[good_mask]\n            warnings.warn('Input data contains invalid values (NaNs or '\n                          'infs), which were automatically clipped.',\n                          AstropyUserWarning)\n\n        nchanged = 1\n        iteration = 0\n        while nchanged != 0 and (iteration < self.maxiters):\n            iteration += 1\n            size = filtered_data.size\n            self._compute_bounds(filtered_data, axis=None)\n            filtered_data = filtered_data[(filtered_data >= self._min_value) &\n                                          (filtered_data <= self._max_value)]\n            nchanged = size - filtered_data.size\n\n        self._niterations = iteration\n\n        if masked:\n            # return a masked array and optional bounds\n            filtered_data = np.ma.masked_invalid(data, copy=copy)\n\n            # update the mask in place, ignoring RuntimeWarnings for\n            # comparisons with NaN data values\n            with np.errstate(invalid='ignore'):\n                filtered_data.mask |= np.logical_or(data < self._min_value,\n                                                    data > self._max_value)\n\n        if return_bounds:\n            return filtered_data, self._min_value, self._max_value\n        else:\n            return filtered_data", "response": "Clip the data when axis is None."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _sigmaclip_withaxis(self, data, axis=None, masked=True,\n                            return_bounds=False, copy=True):\n        \"\"\"\n        Sigma clip the data when ``axis`` is specified.\n\n        In this case, we replace clipped values with NaNs as placeholder\n        values.\n        \"\"\"\n\n        # float array type is needed to insert nans into the array\n        filtered_data = data.astype(float)    # also makes a copy\n\n        # remove invalid values\n        bad_mask = ~np.isfinite(filtered_data)\n        if np.any(bad_mask):\n            filtered_data[bad_mask] = np.nan\n            warnings.warn('Input data contains invalid values (NaNs or '\n                          'infs), which were automatically clipped.',\n                          AstropyUserWarning)\n\n        # remove masked values and convert to plain ndarray\n        if isinstance(filtered_data, np.ma.MaskedArray):\n            filtered_data = np.ma.masked_invalid(filtered_data).astype(float)\n            filtered_data = filtered_data.filled(np.nan)\n\n        # convert negative axis/axes\n        if not isiterable(axis):\n            axis = (axis,)\n        axis = tuple(filtered_data.ndim + n if n < 0 else n for n in axis)\n\n        # define the shape of min/max arrays so that they can be broadcast\n        # with the data\n        mshape = tuple(1 if dim in axis else size\n                       for dim, size in enumerate(filtered_data.shape))\n\n        nchanged = 1\n        iteration = 0\n        while nchanged != 0 and (iteration < self.maxiters):\n            iteration += 1\n            n_nan = np.count_nonzero(np.isnan(filtered_data))\n\n            self._compute_bounds(filtered_data, axis=axis)\n            if not np.isscalar(self._min_value):\n                self._min_value = self._min_value.reshape(mshape)\n                self._max_value = self._max_value.reshape(mshape)\n\n            with np.errstate(invalid='ignore'):\n                filtered_data[(filtered_data < self._min_value) |\n                              (filtered_data > self._max_value)] = np.nan\n\n            nchanged = n_nan - np.count_nonzero(np.isnan(filtered_data))\n\n        self._niterations = iteration\n\n        if masked:\n            # create an output masked array\n            if copy:\n                filtered_data = np.ma.masked_invalid(filtered_data)\n            else:\n                # ignore RuntimeWarnings for comparisons with NaN data values\n                with np.errstate(invalid='ignore'):\n                    out = np.ma.masked_invalid(data, copy=False)\n\n                    filtered_data = np.ma.masked_where(np.logical_or(\n                        out < self._min_value, out > self._max_value),\n                        out, copy=False)\n\n        if return_bounds:\n            return filtered_data, self._min_value, self._max_value\n        else:\n            return filtered_data", "response": "Clip the data with the specified axis."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the input data to aperture_photometry.", "response": "def _prepare_photometry_input(data, error, mask, wcs, unit):\n    \"\"\"\n    Parse the inputs to `aperture_photometry`.\n\n    `aperture_photometry` accepts a wide range of inputs, e.g. ``data``\n    could be a numpy array, a Quantity array, or a fits HDU.  This\n    requires some parsing and validation to ensure that all inputs are\n    complete and consistent.  For example, the data could carry a unit\n    and the wcs itself, so we need to check that it is consistent with\n    the unit and wcs given as input parameters.\n    \"\"\"\n\n    if isinstance(data, fits.HDUList):\n        for i in range(len(data)):\n            if data[i].data is not None:\n                warnings.warn(\"Input data is a HDUList object, photometry is \"\n                              \"run only for the {0} HDU.\"\n                              .format(i), AstropyUserWarning)\n                data = data[i]\n                break\n\n    if isinstance(data, (fits.PrimaryHDU, fits.ImageHDU)):\n        header = data.header\n        data = data.data\n\n        if 'BUNIT' in header:\n            bunit = u.Unit(header['BUNIT'], parse_strict='warn')\n            if isinstance(bunit, u.UnrecognizedUnit):\n                warnings.warn('The BUNIT in the header of the input data is '\n                              'not parseable as a valid unit.',\n                              AstropyUserWarning)\n            else:\n                data = u.Quantity(data, unit=bunit)\n\n    if wcs is None:\n        try:\n            wcs = WCS(header)\n        except Exception:\n            # A valid WCS was not found in the header.  Let the calling\n            # application raise an exception if it needs a WCS.\n            pass\n\n    data = np.asanyarray(data)\n    if data.ndim != 2:\n        raise ValueError('data must be a 2D array.')\n\n    if unit is not None:\n        unit = u.Unit(unit, parse_strict='warn')\n        if isinstance(unit, u.UnrecognizedUnit):\n            warnings.warn('The input unit is not parseable as a valid '\n                          'unit.', AstropyUserWarning)\n            unit = None\n\n    if isinstance(data, u.Quantity):\n        if unit is not None and data.unit != unit:\n            warnings.warn('The input unit does not agree with the data '\n                          'unit.', AstropyUserWarning)\n    else:\n        if unit is not None:\n            data = u.Quantity(data, unit=unit)\n\n    if error is not None:\n        if isinstance(error, u.Quantity):\n            if unit is not None and error.unit != unit:\n                warnings.warn('The input unit does not agree with the error '\n                              'unit.', AstropyUserWarning)\n\n            if np.isscalar(error.value):\n                error = u.Quantity(np.broadcast_arrays(error, data),\n                                   unit=error.unit)[0]\n        else:\n            if np.isscalar(error):\n                error = np.broadcast_arrays(error, data)[0]\n\n            if unit is not None:\n                error = u.Quantity(error, unit=unit)\n\n            error = np.asanyarray(error)\n\n        if error.shape != data.shape:\n            raise ValueError('error and data must have the same shape.')\n\n    if mask is not None:\n        mask = np.asanyarray(mask)\n        if mask.shape != data.shape:\n            raise ValueError('mask and data must have the same shape.')\n\n    return data, error, mask, wcs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nperforming aperture photometry on the input data.", "response": "def aperture_photometry(data, apertures, error=None, mask=None,\n                        method='exact', subpixels=5, unit=None, wcs=None):\n    \"\"\"\n    Perform aperture photometry on the input data by summing the flux\n    within the given aperture(s).\n\n    Parameters\n    ----------\n    data : array_like, `~astropy.units.Quantity`, `~astropy.io.fits.ImageHDU`, or `~astropy.io.fits.HDUList`\n        The 2D array on which to perform photometry. ``data`` should be\n        background-subtracted.  Units can be used during the photometry,\n        either provided with the data (i.e. a `~astropy.units.Quantity`\n        array) or the ``unit`` keyword.  If ``data`` is an\n        `~astropy.io.fits.ImageHDU` or `~astropy.io.fits.HDUList`, the\n        unit is determined from the ``'BUNIT'`` header keyword.\n\n    apertures : `~photutils.Aperture`\n        The aperture(s) to use for the photometry.\n\n    error : array_like or `~astropy.units.Quantity`, optional\n        The pixel-wise Gaussian 1-sigma errors of the input ``data``.\n        ``error`` is assumed to include *all* sources of error,\n        including the Poisson error of the sources (see\n        `~photutils.utils.calc_total_error`) .  ``error`` must have the\n        same shape as the input ``data``.\n\n    mask : array_like (bool), optional\n        A boolean mask with the same shape as ``data`` where a `True`\n        value indicates the corresponding element of ``data`` is masked.\n        Masked data are excluded from all calculations.\n\n    method : {'exact', 'center', 'subpixel'}, optional\n        The method used to determine the overlap of the aperture on the\n        pixel grid.  Not all options are available for all aperture\n        types.  Note that the more precise methods are generally slower.\n        The following methods are available:\n\n            * ``'exact'`` (default):\n                The the exact fractional overlap of the aperture and\n                each pixel is calculated.  The returned mask will\n                contain values between 0 and 1.\n\n            * ``'center'``:\n                A pixel is considered to be entirely in or out of the\n                aperture depending on whether its center is in or out of\n                the aperture.  The returned mask will contain values\n                only of 0 (out) and 1 (in).\n\n            * ``'subpixel'``:\n                A pixel is divided into subpixels (see the ``subpixels``\n                keyword), each of which are considered to be entirely in\n                or out of the aperture depending on whether its center\n                is in or out of the aperture.  If ``subpixels=1``, this\n                method is equivalent to ``'center'``.  The returned mask\n                will contain values between 0 and 1.\n\n    subpixels : int, optional\n        For the ``'subpixel'`` method, resample pixels by this factor in\n        each dimension.  That is, each pixel is divided into ``subpixels\n        ** 2`` subpixels.\n\n    unit : `~astropy.units.UnitBase` object or str, optional\n        An object that represents the unit associated with the input\n        ``data`` and ``error`` arrays.  Must be a\n        `~astropy.units.UnitBase` object or a string parseable by the\n        :mod:`~astropy.units` package.  If ``data`` or ``error`` already\n        have a different unit, the input ``unit`` will not be used and a\n        warning will be raised.  If ``data`` is an\n        `~astropy.io.fits.ImageHDU` or `~astropy.io.fits.HDUList`,\n        ``unit`` will override the ``'BUNIT'`` header keyword.\n\n    wcs : `~astropy.wcs.WCS`, optional\n        The WCS transformation to use if the input ``apertures`` is a\n        `SkyAperture` object.  If ``data`` is an\n        `~astropy.io.fits.ImageHDU` or `~astropy.io.fits.HDUList`,\n        ``wcs`` overrides any WCS transformation present in the header.\n\n    Returns\n    -------\n    table : `~astropy.table.QTable`\n        A table of the photometry with the following columns:\n\n            * ``'id'``:\n              The source ID.\n\n            * ``'xcenter'``, ``'ycenter'``:\n              The ``x`` and ``y`` pixel coordinates of the input\n              aperture center(s).\n\n            * ``'celestial_center'``:\n              The celestial coordinates of the input aperture center(s).\n              Returned only if the input ``apertures`` is a\n              `SkyAperture` object.\n\n            * ``'aperture_sum'``:\n              The sum of the values within the aperture.\n\n            * ``'aperture_sum_err'``:\n              The corresponding uncertainty in the ``'aperture_sum'``\n              values.  Returned only if the input ``error`` is not\n              `None`.\n\n        The table metadata includes the Astropy and Photutils version\n        numbers and the `aperture_photometry` calling arguments.\n\n    Notes\n    -----\n    This function is decorated with `~astropy.nddata.support_nddata` and\n    thus supports `~astropy.nddata.NDData` objects as input.\n    \"\"\"\n\n    data, error, mask, wcs = _prepare_photometry_input(data, error, mask,\n                                                       wcs, unit)\n\n    if method == 'subpixel':\n        if (int(subpixels) != subpixels) or (subpixels <= 0):\n            raise ValueError('subpixels must be a positive integer.')\n\n    scalar_aperture = False\n    if isinstance(apertures, Aperture):\n        scalar_aperture = True\n\n    apertures = np.atleast_1d(apertures)\n\n    # convert sky to pixel apertures\n    skyaper = False\n    if isinstance(apertures[0], SkyAperture):\n        if wcs is None:\n            raise ValueError('A WCS transform must be defined by the input '\n                             'data or the wcs keyword when using a '\n                             'SkyAperture object.')\n\n        skyaper = True\n        skycoord_pos = apertures[0].positions\n\n        pix_aper = [aper.to_pixel(wcs) for aper in apertures]\n        apertures = pix_aper\n\n    # do comparison in pixels to avoid comparing SkyCoord objects\n    positions = apertures[0].positions\n    for aper in apertures[1:]:\n        if not np.array_equal(aper.positions, positions):\n            raise ValueError('Input apertures must all have identical '\n                             'positions.')\n\n    meta = OrderedDict()\n    meta['name'] = 'Aperture photometry results'\n    meta['version'] = get_version_info()\n    calling_args = (\"method='{0}', subpixels={1}\".format(method, subpixels))\n    meta['aperture_photometry_args'] = calling_args\n\n    tbl = QTable(meta=meta)\n    tbl['id'] = np.arange(len(apertures[0]), dtype=int) + 1\n\n    xypos_pixel = np.transpose(apertures[0].positions) * u.pixel\n    tbl['xcenter'] = xypos_pixel[0]\n    tbl['ycenter'] = xypos_pixel[1]\n\n    if skyaper:\n        if skycoord_pos.isscalar:\n            tbl['celestial_center'] = (skycoord_pos,)\n        else:\n            tbl['celestial_center'] = skycoord_pos\n\n    for i, aper in enumerate(apertures):\n        aper_sum, aper_sum_err = aper.do_photometry(data, error=error,\n                                                    mask=mask, method=method,\n                                                    subpixels=subpixels)\n\n        sum_key = 'aperture_sum'\n        sum_err_key = 'aperture_sum_err'\n        if not scalar_aperture:\n            sum_key += '_{}'.format(i)\n            sum_err_key += '_{}'.format(i)\n\n        tbl[sum_key] = aper_sum\n        if error is not None:\n            tbl[sum_err_key] = aper_sum_err\n\n    return tbl"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _centered_edges(self):\n\n        edges = []\n        for position, bbox in zip(self.positions, self.bounding_boxes):\n            xmin = bbox.ixmin - 0.5 - position[0]\n            xmax = bbox.ixmax - 0.5 - position[0]\n            ymin = bbox.iymin - 0.5 - position[1]\n            ymax = bbox.iymax - 0.5 - position[1]\n            edges.append((xmin, xmax, ymin, ymax))\n\n        return edges", "response": "Return a list of tuples one for each aperture at the origin."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mask_area(self, method='exact', subpixels=5):\n\n        mask = self.to_mask(method=method, subpixels=subpixels)\n        return [np.sum(m.data) for m in mask]", "response": "Return the area of the aperture."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nperform aperture photometry on the input data.", "response": "def do_photometry(self, data, error=None, mask=None, method='exact',\n                      subpixels=5, unit=None):\n        \"\"\"\n        Perform aperture photometry on the input data.\n\n        Parameters\n        ----------\n        data : array_like or `~astropy.units.Quantity` instance\n            The 2D array on which to perform photometry.  ``data``\n            should be background subtracted.\n\n        error : array_like or `~astropy.units.Quantity`, optional\n            The pixel-wise Gaussian 1-sigma errors of the input\n            ``data``.  ``error`` is assumed to include *all* sources of\n            error, including the Poisson error of the sources (see\n            `~photutils.utils.calc_total_error`) .  ``error`` must have\n            the same shape as the input ``data``.\n\n        mask : array_like (bool), optional\n            A boolean mask with the same shape as ``data`` where a\n            `True` value indicates the corresponding element of ``data``\n            is masked.  Masked data are excluded from all calculations.\n\n        method : {'exact', 'center', 'subpixel'}, optional\n            The method used to determine the overlap of the aperture on\n            the pixel grid.  Not all options are available for all\n            aperture types.  Note that the more precise methods are\n            generally slower.  The following methods are available:\n\n                * ``'exact'`` (default):\n                  The the exact fractional overlap of the aperture and\n                  each pixel is calculated.  The returned mask will\n                  contain values between 0 and 1.\n\n                * ``'center'``:\n                  A pixel is considered to be entirely in or out of the\n                  aperture depending on whether its center is in or out\n                  of the aperture.  The returned mask will contain\n                  values only of 0 (out) and 1 (in).\n\n                * ``'subpixel'``\n                  A pixel is divided into subpixels (see the\n                  ``subpixels`` keyword), each of which are considered\n                  to be entirely in or out of the aperture depending on\n                  whether its center is in or out of the aperture.  If\n                  ``subpixels=1``, this method is equivalent to\n                  ``'center'``.  The returned mask will contain values\n                  between 0 and 1.\n\n        subpixels : int, optional\n            For the ``'subpixel'`` method, resample pixels by this factor\n            in each dimension.  That is, each pixel is divided into\n            ``subpixels ** 2`` subpixels.\n\n        unit : `~astropy.units.UnitBase` object or str, optional\n            An object that represents the unit associated with the input\n            ``data`` and ``error`` arrays.  Must be a\n            `~astropy.units.UnitBase` object or a string parseable by\n            the :mod:`~astropy.units` package.  If ``data`` or ``error``\n            already have a different unit, the input ``unit`` will not\n            be used and a warning will be raised.\n\n        Returns\n        -------\n        aperture_sums : `~numpy.ndarray` or `~astropy.units.Quantity`\n            The sums within each aperture.\n\n        aperture_sum_errs : `~numpy.ndarray` or `~astropy.units.Quantity`\n            The errors on the sums within each aperture.\n        \"\"\"\n\n        data = np.asanyarray(data)\n\n        if mask is not None:\n            mask = np.asanyarray(mask)\n\n            data = copy.deepcopy(data)    # do not modify input data\n            data[mask] = 0\n\n            if error is not None:\n                # do not modify input data\n                error = copy.deepcopy(np.asanyarray(error))\n                error[mask] = 0.\n\n        aperture_sums = []\n        aperture_sum_errs = []\n        for mask in self.to_mask(method=method, subpixels=subpixels):\n            data_cutout = mask.cutout(data)\n\n            if data_cutout is None:\n                aperture_sums.append(np.nan)\n            else:\n                aperture_sums.append(np.sum(data_cutout * mask.data))\n\n            if error is not None:\n                error_cutout = mask.cutout(error)\n\n                if error_cutout is None:\n                    aperture_sum_errs.append(np.nan)\n                else:\n                    aperture_var = np.sum(error_cutout ** 2 * mask.data)\n                    aperture_sum_errs.append(np.sqrt(aperture_var))\n\n        # handle Quantity objects and input units\n        aperture_sums = self._prepare_photometry_output(aperture_sums,\n                                                        unit=unit)\n        aperture_sum_errs = self._prepare_photometry_output(aperture_sum_errs,\n                                                            unit=unit)\n\n        return aperture_sums, aperture_sum_errs"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprepare to plot the aperture on a matplotlib instance.", "response": "def _prepare_plot(self, origin=(0, 0), indices=None, ax=None,\n                      fill=False, **kwargs):\n        \"\"\"\n        Prepare to plot the aperture(s) on a matplotlib\n        `~matplotlib.axes.Axes` instance.\n\n        Parameters\n        ----------\n        origin : array_like, optional\n            The ``(x, y)`` position of the origin of the displayed\n            image.\n\n        indices : int or array of int, optional\n            The indices of the aperture(s) to plot.\n\n        ax : `matplotlib.axes.Axes` instance, optional\n            If `None`, then the current `~matplotlib.axes.Axes` instance\n            is used.\n\n        fill : bool, optional\n            Set whether to fill the aperture patch.  The default is\n            `False`.\n\n        kwargs\n            Any keyword arguments accepted by `matplotlib.patches.Patch`.\n\n        Returns\n        -------\n        plot_positions : `~numpy.ndarray`\n            The positions of the apertures to plot, after any\n            ``indices`` slicing and ``origin`` shift.\n\n        ax : `matplotlib.axes.Axes` instance, optional\n            The `~matplotlib.axes.Axes` on which to plot.\n\n        kwargs\n            Any keyword arguments accepted by `matplotlib.patches.Patch`.\n        \"\"\"\n\n        import matplotlib.pyplot as plt\n\n        if ax is None:\n            ax = plt.gca()\n\n        # This is necessary because the `matplotlib.patches.Patch` default\n        # is ``fill=True``.  Here we make the default ``fill=False``.\n        kwargs['fill'] = fill\n\n        plot_positions = copy.deepcopy(self.positions)\n        if indices is not None:\n            plot_positions = plot_positions[np.atleast_1d(indices)]\n\n        plot_positions[:, 0] -= origin[0]\n        plot_positions[:, 1] -= origin[1]\n\n        return plot_positions, ax, kwargs"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts the pixel aperture parameters to those for a sky aperture.", "response": "def _to_sky_params(self, wcs, mode='all'):\n        \"\"\"\n        Convert the pixel aperture parameters to those for a sky\n        aperture.\n\n        Parameters\n        ----------\n        wcs : `~astropy.wcs.WCS`\n            The world coordinate system (WCS) transformation to use.\n\n        mode : {'all', 'wcs'}, optional\n            Whether to do the transformation including distortions\n            (``'all'``; default) or only including only the core WCS\n            transformation (``'wcs'``).\n\n        Returns\n        -------\n        sky_params : dict\n            A dictionary of parameters for an equivalent sky aperture.\n        \"\"\"\n\n        sky_params = {}\n        x, y = np.transpose(self.positions)\n        sky_params['positions'] = pixel_to_skycoord(x, y, wcs, mode=mode)\n\n        # The aperture object must have a single value for each shape\n        # parameter so we must use a single pixel scale for all positions.\n        # Here, we define the scale at the WCS CRVAL position.\n        crval = SkyCoord([wcs.wcs.crval], frame=wcs_to_celestial_frame(wcs),\n                         unit=wcs.wcs.cunit)\n        scale, angle = pixel_scale_angle_at_skycoord(crval, wcs)\n\n        params = self._params[:]\n        theta_key = 'theta'\n        if theta_key in self._params:\n            sky_params[theta_key] = (self.theta * u.rad) - angle.to(u.rad)\n            params.remove(theta_key)\n\n        param_vals = [getattr(self, param) for param in params]\n        for param, param_val in zip(params, param_vals):\n            sky_params[param] = (param_val * u.pix * scale).to(u.arcsec)\n\n        return sky_params"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting the sky aperture parameters to those for a pixel aperture.", "response": "def _to_pixel_params(self, wcs, mode='all'):\n        \"\"\"\n        Convert the sky aperture parameters to those for a pixel\n        aperture.\n\n        Parameters\n        ----------\n        wcs : `~astropy.wcs.WCS`\n            The world coordinate system (WCS) transformation to use.\n\n        mode : {'all', 'wcs'}, optional\n            Whether to do the transformation including distortions\n            (``'all'``; default) or only including only the core WCS\n            transformation (``'wcs'``).\n\n        Returns\n        -------\n        pixel_params : dict\n            A dictionary of parameters for an equivalent pixel aperture.\n        \"\"\"\n\n        pixel_params = {}\n        x, y = skycoord_to_pixel(self.positions, wcs, mode=mode)\n        pixel_params['positions'] = np.array([x, y]).transpose()\n\n        # The aperture object must have a single value for each shape\n        # parameter so we must use a single pixel scale for all positions.\n        # Here, we define the scale at the WCS CRVAL position.\n        crval = SkyCoord([wcs.wcs.crval], frame=wcs_to_celestial_frame(wcs),\n                         unit=wcs.wcs.cunit)\n        scale, angle = pixel_scale_angle_at_skycoord(crval, wcs)\n\n        params = self._params[:]\n        theta_key = 'theta'\n        if theta_key in self._params:\n            pixel_params[theta_key] = (self.theta + angle).to(u.radian).value\n            params.remove(theta_key)\n\n        param_vals = [getattr(self, param) for param in params]\n        if param_vals[0].unit.physical_type == 'angle':\n            for param, param_val in zip(params, param_vals):\n                pixel_params[param] = (param_val / scale).to(u.pixel).value\n        else:    # pixels\n            for param, param_val in zip(params, param_vals):\n                pixel_params[param] = param_val.value\n\n        return pixel_params"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_random_cmap(ncolors=256, random_state=None):\n\n    from matplotlib import colors\n\n    prng = check_random_state(random_state)\n    h = prng.uniform(low=0.0, high=1.0, size=ncolors)\n    s = prng.uniform(low=0.2, high=0.7, size=ncolors)\n    v = prng.uniform(low=0.5, high=1.0, size=ncolors)\n    hsv = np.dstack((h, s, v))\n    rgb = np.squeeze(colors.hsv_to_rgb(hsv))\n\n    return colors.ListedColormap(rgb)", "response": "Make a random colormap consisting of ( random ) muted colors."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef source_properties(data, segment_img, error=None, mask=None,\n                      background=None, filter_kernel=None, wcs=None,\n                      labels=None):\n    \"\"\"\n    Calculate photometry and morphological properties of sources defined\n    by a labeled segmentation image.\n\n    Parameters\n    ----------\n    data : array_like or `~astropy.units.Quantity`\n        The 2D array from which to calculate the source photometry and\n        properties.  ``data`` should be background-subtracted.\n        Non-finite ``data`` values (e.g. NaN or inf) are automatically\n        masked.\n\n    segment_img : `SegmentationImage` or array_like (int)\n        A 2D segmentation image, either as a `SegmentationImage` object\n        or an `~numpy.ndarray`, with the same shape as ``data`` where\n        sources are labeled by different positive integer values.  A\n        value of zero is reserved for the background.\n\n    error : array_like or `~astropy.units.Quantity`, optional\n        The total error array corresponding to the input ``data`` array.\n        ``error`` is assumed to include *all* sources of error,\n        including the Poisson error of the sources (see\n        `~photutils.utils.calc_total_error`) .  ``error`` must have the\n        same shape as the input ``data``.  Non-finite ``error`` values\n        (e.g. NaN or inf) are not automatically masked, unless they are\n        at the same position of non-finite values in the input ``data``\n        array.  Such pixels can be masked using the ``mask`` keyword.\n        See the Notes section below for details on the error\n        propagation.\n\n    mask : array_like (bool), optional\n        A boolean mask with the same shape as ``data`` where a `True`\n        value indicates the corresponding element of ``data`` is masked.\n        Masked data are excluded from all calculations.  Non-finite\n        values (e.g. NaN or inf) in the input ``data`` are automatically\n        masked.\n\n    background : float, array_like, or `~astropy.units.Quantity`, optional\n        The background level that was *previously* present in the input\n        ``data``.  ``background`` may either be a scalar value or a 2D\n        image with the same shape as the input ``data``.  Inputting the\n        ``background`` merely allows for its properties to be measured\n        within each source segment.  The input ``background`` does *not*\n        get subtracted from the input ``data``, which should already be\n        background-subtracted.  Non-finite ``background`` values (e.g.\n        NaN or inf) are not automatically masked, unless they are at the\n        same position of non-finite values in the input ``data`` array.\n        Such pixels can be masked using the ``mask`` keyword.\n\n    filter_kernel : array-like (2D) or `~astropy.convolution.Kernel2D`, optional\n        The 2D array of the kernel used to filter the data prior to\n        calculating the source centroid and morphological parameters.\n        The kernel should be the same one used in defining the source\n        segments, i.e. the detection image (e.g., see\n        :func:`~photutils.detect_sources`).  If `None`, then the\n        unfiltered ``data`` will be used instead.\n\n    wcs : `~astropy.wcs.WCS`\n        The WCS transformation to use.  If `None`, then any sky-based\n        properties will be set to `None`.\n\n    labels : int, array-like (1D, int)\n        The segmentation labels for which to calculate source\n        properties.  If `None` (default), then the properties will be\n        calculated for all labeled sources.\n\n    Returns\n    -------\n    output : `SourceCatalog` instance\n        A `SourceCatalog` instance containing the properties of each\n        source.\n\n    Notes\n    -----\n    `SExtractor`_'s centroid and morphological parameters are always\n    calculated from a filtered \"detection\" image, i.e. the image used to\n    define the segmentation image.  The usual downside of the filtering\n    is the sources will be made more circular than they actually are.\n    If you wish to reproduce `SExtractor`_ centroid and morphology\n    results, then input a filtered and background-subtracted \"detection\"\n    image into the ``filtered_data`` keyword.  If ``filtered_data`` is\n    `None`, then the unfiltered ``data`` will be used for the source\n    centroid and morphological parameters.\n\n    Negative data values (``filtered_data`` or ``data``) within the\n    source segment are set to zero when calculating morphological\n    properties based on image moments.  Negative values could occur, for\n    example, if the segmentation image was defined from a different\n    image (e.g., different bandpass) or if the background was\n    oversubtracted. Note that `~photutils.SourceProperties.source_sum`\n    always includes the contribution of negative ``data`` values.\n\n    The input ``error`` is assumed to include *all* sources of error,\n    including the Poisson error of the sources.\n    `~photutils.SourceProperties.source_sum_err` is simply the\n    quadrature sum of the pixel-wise total errors over the non-masked\n    pixels within the source segment:\n\n    .. math:: \\\\Delta F = \\\\sqrt{\\\\sum_{i \\\\in S}\n              \\\\sigma_{\\\\mathrm{tot}, i}^2}\n\n    where :math:`\\\\Delta F` is\n    `~photutils.SourceProperties.source_sum_err`, :math:`S` are the\n    non-masked pixels in the source segment, and\n    :math:`\\\\sigma_{\\\\mathrm{tot}, i}` is the input ``error`` array.\n\n    .. _SExtractor: http://www.astromatic.net/software/sextractor\n\n    See Also\n    --------\n    SegmentationImage, SourceProperties, detect_sources\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from photutils import SegmentationImage, source_properties\n    >>> image = np.arange(16.).reshape(4, 4)\n    >>> print(image)  # doctest: +SKIP\n    [[ 0.  1.  2.  3.]\n     [ 4.  5.  6.  7.]\n     [ 8.  9. 10. 11.]\n     [12. 13. 14. 15.]]\n    >>> segm = SegmentationImage([[1, 1, 0, 0],\n    ...                           [1, 0, 0, 2],\n    ...                           [0, 0, 2, 2],\n    ...                           [0, 2, 2, 0]])\n    >>> props = source_properties(image, segm)\n\n    Print some properties of the first object (labeled with ``1`` in the\n    segmentation image):\n\n    >>> props[0].id    # id corresponds to segment label number\n    1\n    >>> props[0].centroid    # doctest: +FLOAT_CMP\n    <Quantity [0.8, 0.2] pix>\n    >>> props[0].source_sum    # doctest: +FLOAT_CMP\n    5.0\n    >>> props[0].area    # doctest: +FLOAT_CMP\n    <Quantity 3. pix2>\n    >>> props[0].max_value    # doctest: +FLOAT_CMP\n    4.0\n\n    Print some properties of the second object (labeled with ``2`` in\n    the segmentation image):\n\n    >>> props[1].id    # id corresponds to segment label number\n    2\n    >>> props[1].centroid    # doctest: +FLOAT_CMP\n    <Quantity [2.36363636, 2.09090909] pix>\n    >>> props[1].perimeter    # doctest: +FLOAT_CMP\n    <Quantity 5.41421356 pix>\n    >>> props[1].orientation    # doctest: +FLOAT_CMP\n    <Quantity -0.74175931 rad>\n    \"\"\"\n\n    if not isinstance(segment_img, SegmentationImage):\n        segment_img = SegmentationImage(segment_img)\n\n    if segment_img.shape != data.shape:\n        raise ValueError('segment_img and data must have the same shape.')\n\n    # filter the data once, instead of repeating for each source\n    if filter_kernel is not None:\n        filtered_data = filter_data(data, filter_kernel, mode='constant',\n                                    fill_value=0.0, check_normalization=True)\n    else:\n        filtered_data = None\n\n    if labels is None:\n        labels = segment_img.labels\n    labels = np.atleast_1d(labels)\n\n    sources_props = []\n    for label in labels:\n        if label not in segment_img.labels:\n            warnings.warn('label {} is not in the segmentation image.'\n                          .format(label), AstropyUserWarning)\n            continue  # skip invalid labels\n\n        sources_props.append(SourceProperties(\n            data, segment_img, label, filtered_data=filtered_data,\n            error=error, mask=mask, background=background, wcs=wcs))\n\n    if len(sources_props) == 0:\n        raise ValueError('No sources are defined.')\n\n    return SourceCatalog(sources_props, wcs=wcs)", "response": "Calculate photometry and morphological properties of sources defined by a labeled segmentation image."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _properties_table(obj, columns=None, exclude_columns=None):\n\n    # default properties\n    columns_all = ['id', 'xcentroid', 'ycentroid', 'sky_centroid',\n                   'sky_centroid_icrs', 'source_sum', 'source_sum_err',\n                   'background_sum', 'background_mean',\n                   'background_at_centroid', 'xmin', 'xmax', 'ymin',\n                   'ymax', 'min_value', 'max_value', 'minval_xpos',\n                   'minval_ypos', 'maxval_xpos', 'maxval_ypos', 'area',\n                   'equivalent_radius', 'perimeter',\n                   'semimajor_axis_sigma', 'semiminor_axis_sigma',\n                   'eccentricity', 'orientation', 'ellipticity',\n                   'elongation', 'covar_sigx2', 'covar_sigxy',\n                   'covar_sigy2', 'cxx', 'cxy', 'cyy']\n\n    table_columns = None\n    if exclude_columns is not None:\n        table_columns = [s for s in columns_all if s not in exclude_columns]\n    if columns is not None:\n        table_columns = np.atleast_1d(columns)\n    if table_columns is None:\n        table_columns = columns_all\n\n    tbl = QTable()\n    for column in table_columns:\n        values = getattr(obj, column)\n\n        if isinstance(obj, SourceProperties):\n            # turn scalar values into length-1 arrays because QTable\n            # column assignment requires an object with a length\n            values = np.atleast_1d(values)\n\n            # Unfortunately np.atleast_1d creates an array of SkyCoord\n            # instead of a SkyCoord array (Quantity does work correctly\n            # with np.atleast_1d).  Here we make a SkyCoord array for\n            # the output table column.\n            if isinstance(values[0], SkyCoord):\n                values = SkyCoord(values)  # length-1 SkyCoord array\n\n        tbl[column] = values\n\n    return tbl", "response": "Constructs a ~astropy. table. QTable containing the source properties of the specified object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the total mask of the items in the current object.", "response": "def _total_mask(self):\n        \"\"\"\n        Combination of the _segment_mask, _input_mask, and _data_mask.\n\n        This mask is applied to ``data``, ``error``, and ``background``\n        inputs when calculating properties.\n        \"\"\"\n\n        mask = self._segment_mask | self._data_mask\n\n        if self._input_mask is not None:\n            mask |= self._input_mask\n\n        return mask"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_cutout(self, data, masked_array=False):\n\n        data = np.asanyarray(data)\n        if data.shape != self._segment_img.shape:\n            raise ValueError('data must have the same shape as the '\n                             'segmentation image input to SourceProperties')\n\n        if masked_array:\n            return np.ma.masked_array(data[self._slice],\n                                      mask=self._total_mask)\n        else:\n            return data[self._slice]", "response": "Create a masked cutout array from the input data using the minimal bounding box of the source segment."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_table(self, columns=None, exclude_columns=None):\n\n        return _properties_table(self, columns=columns,\n                                 exclude_columns=exclude_columns)", "response": "Create a table of properties of the source."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef moments_central(self):\n\n        ycentroid, xcentroid = self.cutout_centroid.value\n        return _moments_central(self._filtered_data_zeroed,\n                                center=(xcentroid, ycentroid), order=3)", "response": "Returns the moments of the central set of the source."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef centroid(self):\n\n        ycen, xcen = self.cutout_centroid.value\n        return (ycen + self._slice[0].start,\n                xcen + self._slice[1].start) * u.pix", "response": "The y x coordinates of the centroid within the source\n        segment."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the sky coordinates of the centroid within the source segment.", "response": "def sky_centroid(self):\n        \"\"\"\n        The sky coordinates of the centroid within the source segment,\n        returned as a `~astropy.coordinates.SkyCoord` object.\n\n        The output coordinate frame is the same as the input WCS.\n        \"\"\"\n\n        if self._wcs is not None:\n            return pixel_to_skycoord(self.xcentroid.value,\n                                     self.ycentroid.value,\n                                     self._wcs, origin=0)\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef bbox(self):\n\n        # (stop - 1) to return the max pixel location, not the slice index\n        return (self._slice[0].start, self._slice[1].start,\n                self._slice[0].stop - 1, self._slice[1].stop - 1) * u.pix", "response": "The bounding box of the minimal and the source segment containing the source segment."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sky_bbox_ll(self):\n\n        if self._wcs is not None:\n            return pixel_to_skycoord(self.xmin.value - 0.5,\n                                     self.ymin.value - 0.5,\n                                     self._wcs, origin=0)\n        else:\n            return None", "response": "Returns the sky coordinates of the lower - left vertex of the minimal\n        bounding box."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the sky coordinates of the upper - left vertex of the minimal a bounding box.", "response": "def sky_bbox_ul(self):\n        \"\"\"\n        The sky coordinates of the upper-left vertex of the minimal\n        bounding box of the source segment, returned as a\n        `~astropy.coordinates.SkyCoord` object.\n\n        The bounding box encloses all of the source segment pixels in\n        their entirety, thus the vertices are at the pixel *corners*.\n        \"\"\"\n\n        if self._wcs is not None:\n            return pixel_to_skycoord(self.xmin.value - 0.5,\n                                     self.ymax.value + 0.5,\n                                     self._wcs, origin=0)\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the sky coordinates of the lower - right vertex of the minimal bounding box.", "response": "def sky_bbox_lr(self):\n        \"\"\"\n        The sky coordinates of the lower-right vertex of the minimal\n        bounding box of the source segment, returned as a\n        `~astropy.coordinates.SkyCoord` object.\n\n        The bounding box encloses all of the source segment pixels in\n        their entirety, thus the vertices are at the pixel *corners*.\n        \"\"\"\n\n        if self._wcs is not None:\n            return pixel_to_skycoord(self.xmax.value + 0.5,\n                                     self.ymin.value - 0.5,\n                                     self._wcs, origin=0)\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the sky coordinates of the upper - right vertex of the minimal a bounding box.", "response": "def sky_bbox_ur(self):\n        \"\"\"\n        The sky coordinates of the upper-right vertex of the minimal\n        bounding box of the source segment, returned as a\n        `~astropy.coordinates.SkyCoord` object.\n\n        The bounding box encloses all of the source segment pixels in\n        their entirety, thus the vertices are at the pixel *corners*.\n        \"\"\"\n\n        if self._wcs is not None:\n            return pixel_to_skycoord(self.xmax.value + 0.5,\n                                     self.ymax.value + 0.5,\n                                     self._wcs, origin=0)\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the minimum pixel value of the data within the source segment.", "response": "def min_value(self):\n        \"\"\"\n        The minimum pixel value of the ``data`` within the source\n        segment.\n        \"\"\"\n\n        if self._is_completely_masked:\n            return np.nan * self._data_unit\n        else:\n            return np.min(self.values)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef max_value(self):\n\n        if self._is_completely_masked:\n            return np.nan * self._data_unit\n        else:\n            return np.max(self.values)", "response": "Returns the maximum pixel value of the data within the source\n        segment."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef source_sum_err(self):\n\n        if self._error is not None:\n            if self._is_completely_masked:\n                return np.nan * self._error_unit  # table output needs unit\n            else:\n                return np.sqrt(np.sum(self._error_values ** 2))\n        else:\n            return None", "response": "The uncertainty of ~photutils. SourceProperties. source_sum propagated from the input error array."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the sum of the background values within the source segment.", "response": "def background_sum(self):\n        \"\"\"\n        The sum of ``background`` values within the source segment.\n\n        Pixel values that are masked in the input ``data``, including\n        any non-finite pixel values (i.e. NaN, infs) that are\n        automatically masked, are also masked in the background array.\n        \"\"\"\n\n        if self._background is not None:\n            if self._is_completely_masked:\n                return np.nan * self._background_unit  # unit for table\n            else:\n                return np.sum(self._background_values)\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the mean of background values within the source segment.", "response": "def background_mean(self):\n        \"\"\"\n        The mean of ``background`` values within the source segment.\n\n        Pixel values that are masked in the input ``data``, including\n        any non-finite pixel values (i.e. NaN, infs) that are\n        automatically masked, are also masked in the background array.\n        \"\"\"\n\n        if self._background is not None:\n            if self._is_completely_masked:\n                return np.nan * self._background_unit  # unit for table\n            else:\n                return np.mean(self._background_values)\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the value of the background at the position of the source centroid.", "response": "def background_at_centroid(self):\n        \"\"\"\n        The value of the ``background`` at the position of the source\n        centroid.\n\n        The background value at fractional position values are\n        determined using bilinear interpolation.\n        \"\"\"\n\n        from scipy.ndimage import map_coordinates\n\n        if self._background is not None:\n            # centroid can still be NaN if all data values are <= 0\n            if (self._is_completely_masked or\n                    np.any(~np.isfinite(self.centroid))):\n                return np.nan * self._background_unit  # unit for table\n            else:\n                value = map_coordinates(self._background,\n                                        [[self.ycentroid.value],\n                                         [self.xcentroid.value]], order=1,\n                                        mode='nearest')[0]\n\n                return value * self._background_unit\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the total area of the source segment in units of pixels**2.", "response": "def area(self):\n        \"\"\"\n        The total unmasked area of the source segment in units of\n        pixels**2.\n\n        Note that the source area may be smaller than its segment area\n        if a mask is input to `SourceProperties` or `source_properties`,\n        or if the ``data`` within the segment contains invalid values\n        (e.g. NaN or infs).\n        \"\"\"\n\n        if self._is_completely_masked:\n            return np.nan * u.pix**2\n        else:\n            return len(self.values) * u.pix**2"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef perimeter(self):\n\n        if self._is_completely_masked:\n            return np.nan * u.pix  # unit for table\n        else:\n            from skimage.measure import perimeter\n            return perimeter(~self._total_mask, neighbourhood=4) * u.pix", "response": "The total perimeter of the source segment."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef covariance(self):\n\n        mu = self.moments_central\n        if mu[0, 0] != 0:\n            m = mu / mu[0, 0]\n            covariance = self._check_covariance(\n                np.array([[m[0, 2], m[1, 1]], [m[1, 1], m[2, 0]]]))\n            return covariance * u.pix**2\n        else:\n            return np.empty((2, 2)) * np.nan * u.pix**2", "response": "Returns the covariance matrix of the 2D Gaussian function that has the the\n            same second - order moments as the source."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _check_covariance(covariance):\n\n        p = 1. / 12     # arbitrary SExtractor value\n        val = (covariance[0, 0] * covariance[1, 1]) - covariance[0, 1]**2\n        if val >= p**2:\n            return covariance\n        else:\n            covar = np.copy(covariance)\n            while val < p**2:\n                covar[0, 0] += p\n                covar[1, 1] += p\n                val = (covar[0, 0] * covar[1, 1]) - covar[0, 1]**2\n            return covar", "response": "Check and modify the covariance matrix in the case of infinitely thin detections."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef covariance_eigvals(self):\n\n        if not np.isnan(np.sum(self.covariance)):\n            eigvals = np.linalg.eigvals(self.covariance)\n            if np.any(eigvals < 0):    # negative variance\n                return (np.nan, np.nan) * u.pix**2  # pragma: no cover\n            return (np.max(eigvals), np.min(eigvals)) * u.pix**2\n        else:\n            return (np.nan, np.nan) * u.pix**2", "response": "The two eigenvalues of the covariance matrix in decreasing\n        order."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef eccentricity(self):\n\n        l1, l2 = self.covariance_eigvals\n        if l1 == 0:\n            return 0.  # pragma: no cover\n        return np.sqrt(1. - (l2 / l1))", "response": "The eccentricity of the 2D Gaussian function that has the same second - order moments as the source."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef orientation(self):\n\n        a, b, b, c = self.covariance.flat\n        if a < 0 or c < 0:    # negative variance\n            return np.nan * u.rad  # pragma: no cover\n        return 0.5 * np.arctan2(2. * b, (a - c))", "response": "The orientation of the 2D Gaussian function that has the same second - order - of - the - product moments as the source."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cyy(self):\n\n        return ((np.sin(self.orientation) / self.semimajor_axis_sigma)**2 +\n                (np.cos(self.orientation) / self.semiminor_axis_sigma)**2)", "response": "SExtractor _s CYY ellipse parameter in units of pixel ** - 2."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cxy(self):\n\n        return (2. * np.cos(self.orientation) * np.sin(self.orientation) *\n                ((1. / self.semimajor_axis_sigma**2) -\n                 (1. / self.semiminor_axis_sigma**2)))", "response": "SExtractor _ s CXY ellipse parameter in units of pixel ** - 2."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nextracting all the data values in boxes of size box_size.", "response": "def _mesh_values(data, box_size):\n    \"\"\"\n    Extract all the data values in boxes of size ``box_size``.\n\n    Values from incomplete boxes, either because of the image edges or\n    masked pixels, are not returned.\n\n    Parameters\n    ----------\n    data : 2D `~numpy.ma.MaskedArray`\n        The input masked array.\n\n    box_size : int\n        The box size.\n\n    Returns\n    -------\n    result : 2D `~numpy.ndarray`\n        A 2D array containing the data values in the boxes (along the x\n        axis).\n    \"\"\"\n\n    data = np.ma.asanyarray(data)\n\n    ny, nx = data.shape\n    nyboxes = ny // box_size\n    nxboxes = nx // box_size\n\n    # include only complete boxes\n    ny_crop = nyboxes * box_size\n    nx_crop = nxboxes * box_size\n    data = data[0:ny_crop, 0:nx_crop]\n\n    # a reshaped 2D masked array with mesh data along the x axis\n    data = np.ma.swapaxes(data.reshape(\n        nyboxes, box_size, nxboxes, box_size), 1, 2).reshape(\n            nyboxes * nxboxes, box_size * box_size)\n\n    # include only boxes without any masked pixels\n    idx = np.where(np.ma.count_masked(data, axis=1) == 0)\n\n    return data[idx]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef std_blocksum(data, block_sizes, mask=None):\n\n    data = np.ma.asanyarray(data)\n\n    if mask is not None and mask is not np.ma.nomask:\n        mask = np.asanyarray(mask)\n        if data.shape != mask.shape:\n            raise ValueError('data and mask must have the same shape.')\n        data.mask |= mask\n\n    stds = []\n    block_sizes = np.atleast_1d(block_sizes)\n    for block_size in block_sizes:\n        mesh_values = _mesh_values(data, block_size)\n        block_sums = np.sum(mesh_values, axis=1)\n        stds.append(np.std(block_sums))\n\n    return np.array(stds)", "response": "Calculates the standard deviation of the block - summed data values at the specified block sizes."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef do_photometry(self, image, init_guesses=None):\n\n        if self.bkg_estimator is not None:\n            image = image - self.bkg_estimator(image)\n\n        if self.aperture_radius is None:\n            if hasattr(self.psf_model, 'fwhm'):\n                self.aperture_radius = self.psf_model.fwhm.value\n            elif hasattr(self.psf_model, 'sigma'):\n                self.aperture_radius = (self.psf_model.sigma.value *\n                                        gaussian_sigma_to_fwhm)\n\n        if init_guesses is not None:\n            # make sure the code does not modify user's input\n            init_guesses = init_guesses.copy()\n            if self.aperture_radius is None:\n                if 'flux_0' not in init_guesses.colnames:\n                    raise ValueError('aperture_radius is None and could not '\n                                     'be determined by psf_model. Please, '\n                                     'either provided a value for '\n                                     'aperture_radius or define fwhm/sigma '\n                                     'at psf_model.')\n\n            if self.finder is not None:\n                warnings.warn('Both init_guesses and finder are different '\n                              'than None, which is ambiguous. finder is '\n                              'going to be ignored.', AstropyUserWarning)\n\n            if 'flux_0' not in init_guesses.colnames:\n                apertures = CircularAperture((init_guesses['x_0'],\n                                              init_guesses['y_0']),\n                                             r=self.aperture_radius)\n\n                init_guesses['flux_0'] = aperture_photometry(\n                    image, apertures)['aperture_sum']\n        else:\n            if self.finder is None:\n                raise ValueError('Finder cannot be None if init_guesses are '\n                                 'not given.')\n            sources = self.finder(image)\n            if len(sources) > 0:\n                apertures = CircularAperture((sources['xcentroid'],\n                                              sources['ycentroid']),\n                                             r=self.aperture_radius)\n\n                sources['aperture_flux'] = aperture_photometry(\n                    image, apertures)['aperture_sum']\n\n                init_guesses = Table(names=['x_0', 'y_0', 'flux_0'],\n                                     data=[sources['xcentroid'],\n                                           sources['ycentroid'],\n                                           sources['aperture_flux']])\n\n        self._define_fit_param_names()\n        for p0, param in self._pars_to_set.items():\n            if p0 not in init_guesses.colnames:\n                init_guesses[p0] = (len(init_guesses) *\n                                    [getattr(self.psf_model, param).value])\n\n        star_groups = self.group_maker(init_guesses)\n        output_tab, self._residual_image = self.nstar(image, star_groups)\n\n        star_groups = star_groups.group_by('group_id')\n        output_tab = hstack([star_groups, output_tab])\n\n        return output_tab", "response": "Perform the photometry of the aperture in the given image."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef nstar(self, image, star_groups):\n\n        result_tab = Table()\n        for param_tab_name in self._pars_to_output.keys():\n            result_tab.add_column(Column(name=param_tab_name))\n\n        unc_tab = Table()\n        for param, isfixed in self.psf_model.fixed.items():\n            if not isfixed:\n                unc_tab.add_column(Column(name=param + \"_unc\"))\n\n        y, x = np.indices(image.shape)\n\n        star_groups = star_groups.group_by('group_id')\n        for n in range(len(star_groups.groups)):\n            group_psf = get_grouped_psf_model(self.psf_model,\n                                              star_groups.groups[n],\n                                              self._pars_to_set)\n            usepixel = np.zeros_like(image, dtype=np.bool)\n\n            for row in star_groups.groups[n]:\n                usepixel[overlap_slices(large_array_shape=image.shape,\n                                        small_array_shape=self.fitshape,\n                                        position=(row['y_0'], row['x_0']),\n                                        mode='trim')[0]] = True\n\n            fit_model = self.fitter(group_psf, x[usepixel], y[usepixel],\n                                    image[usepixel])\n            param_table = self._model_params2table(fit_model,\n                                                   len(star_groups.groups[n]))\n            result_tab = vstack([result_tab, param_table])\n\n            if 'param_cov' in self.fitter.fit_info.keys():\n                unc_tab = vstack([unc_tab,\n                                  self._get_uncertainties(\n                                      len(star_groups.groups[n]))])\n            try:\n                from astropy.nddata.utils import NoOverlapError\n            except ImportError:\n                raise ImportError(\"astropy 1.1 or greater is required in \"\n                                  \"order to use this class.\")\n            # do not subtract if the fitting did not go well\n            try:\n                image = subtract_psf(image, self.psf_model, param_table,\n                                     subshape=self.fitshape)\n            except NoOverlapError:\n                pass\n\n        if 'param_cov' in self.fitter.fit_info.keys():\n            result_tab = hstack([result_tab, unc_tab])\n\n        return result_tab, image", "response": "Fit a single model to the given image and return a new table that contains the n - star photometry results."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndefines the names of the parameters that are fitted by the current guess table and the actual names of the parameters in the model.", "response": "def _define_fit_param_names(self):\n        \"\"\"\n        Convenience function to define mappings between the names of the\n        columns in the initial guess table (and the name of the fitted\n        parameters) and the actual name of the parameters in the model.\n\n        This method sets the following parameters on the ``self`` object:\n        * ``pars_to_set`` : Dict which maps the names of the parameters\n          initial guesses to the actual name of the parameter in the\n          model.\n        * ``pars_to_output`` : Dict which maps the names of the fitted\n          parameters to the actual name of the parameter in the model.\n        \"\"\"\n\n        xname, yname, fluxname = _extract_psf_fitting_names(self.psf_model)\n        self._pars_to_set = {'x_0': xname, 'y_0': yname, 'flux_0': fluxname}\n        self._pars_to_output = {'x_fit': xname, 'y_fit': yname,\n                                'flux_fit': fluxname}\n\n        for p, isfixed in self.psf_model.fixed.items():\n            p0 = p + '_0'\n            pfit = p + '_fit'\n            if p not in (xname, yname, fluxname) and not isfixed:\n                self._pars_to_set[p0] = p\n                self._pars_to_output[pfit] = p"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving the uncertainties on fitted parameters from the fitter object.", "response": "def _get_uncertainties(self, star_group_size):\n        \"\"\"\n        Retrieve uncertainties on fitted parameters from the fitter\n        object.\n\n        Parameters\n        ----------\n        star_group_size : int\n            Number of stars in the given group.\n\n        Returns\n        -------\n        unc_tab : `~astropy.table.Table`\n            Table which contains uncertainties on the fitted parameters.\n            The uncertainties are reported as one standard deviation.\n        \"\"\"\n\n        unc_tab = Table()\n        for param_name in self.psf_model.param_names:\n            if not self.psf_model.fixed[param_name]:\n                unc_tab.add_column(Column(name=param_name + \"_unc\",\n                                          data=np.empty(star_group_size)))\n\n        if 'param_cov' in self.fitter.fit_info.keys():\n            if self.fitter.fit_info['param_cov'] is not None:\n                k = 0\n                n_fit_params = len(unc_tab.colnames)\n                for i in range(star_group_size):\n                    unc_tab[i] = np.sqrt(np.diag(\n                                          self.fitter.fit_info['param_cov'])\n                                         )[k: k + n_fit_params]\n                    k = k + n_fit_params\n        return unc_tab"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _model_params2table(self, fit_model, star_group_size):\n\n        param_tab = Table()\n\n        for param_tab_name in self._pars_to_output.keys():\n            param_tab.add_column(Column(name=param_tab_name,\n                                        data=np.empty(star_group_size)))\n\n        if star_group_size > 1:\n            for i in range(star_group_size):\n                for param_tab_name, param_name in self._pars_to_output.items():\n                    param_tab[param_tab_name][i] = getattr(fit_model,\n                                                           param_name +\n                                                           '_' + str(i)).value\n        else:\n            for param_tab_name, param_name in self._pars_to_output.items():\n                param_tab[param_tab_name] = getattr(fit_model, param_name).value\n\n        return param_tab", "response": "Place fitted parameters into an astropy table."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nperforms the photometry of the aperture in the given image.", "response": "def do_photometry(self, image, init_guesses=None):\n        \"\"\"\n        Perform PSF photometry in ``image``.\n\n        This method assumes that ``psf_model`` has centroids and flux\n        parameters which will be fitted to the data provided in\n        ``image``. A compound model, in fact a sum of ``psf_model``,\n        will be fitted to groups of stars automatically identified by\n        ``group_maker``. Also, ``image`` is not assumed to be background\n        subtracted.  If ``init_guesses`` are not ``None`` then this\n        method uses ``init_guesses`` as initial guesses for the\n        centroids. If the centroid positions are set as ``fixed`` in the\n        PSF model ``psf_model``, then the optimizer will only consider\n        the flux as a variable.\n\n        Parameters\n        ----------\n        image : 2D array-like, `~astropy.io.fits.ImageHDU`, `~astropy.io.fits.HDUList`\n            Image to perform photometry.\n        init_guesses: `~astropy.table.Table`\n            Table which contains the initial guesses (estimates) for the\n            set of parameters. Columns 'x_0' and 'y_0' which represent\n            the positions (in pixel coordinates) for each object must be\n            present.  'flux_0' can also be provided to set initial\n            fluxes.  If 'flux_0' is not provided, aperture photometry is\n            used to estimate initial values for the fluxes. Additional\n            columns of the form '<parametername>_0' will be used to set\n            the initial guess for any parameters of the ``psf_model``\n            model that are not fixed.\n\n        Returns\n        -------\n        output_table : `~astropy.table.Table` or None\n            Table with the photometry results, i.e., centroids and\n            fluxes estimations and the initial estimates used to start\n            the fitting process. Uncertainties on the fitted parameters\n            are reported as columns called ``<paramname>_unc`` provided\n            that the fitter object contains a dictionary called\n            ``fit_info`` with the key ``param_cov``, which contains the\n            covariance matrix.\n        \"\"\"\n\n        if init_guesses is not None:\n            table = super().do_photometry(image, init_guesses)\n            table['iter_detected'] = np.ones(table['x_fit'].shape,\n                                             dtype=np.int32)\n\n            # n_start = 2 because it starts in the second iteration\n            # since the first iteration is above\n            output_table = self._do_photometry(init_guesses.colnames,\n                                               n_start=2)\n            output_table = vstack([table, output_table])\n        else:\n            if self.bkg_estimator is not None:\n                self._residual_image = image - self.bkg_estimator(image)\n\n            if self.aperture_radius is None:\n                if hasattr(self.psf_model, 'fwhm'):\n                    self.aperture_radius = self.psf_model.fwhm.value\n                elif hasattr(self.psf_model, 'sigma'):\n                    self.aperture_radius = (self.psf_model.sigma.value *\n                                            gaussian_sigma_to_fwhm)\n\n            output_table = self._do_photometry(['x_0', 'y_0', 'flux_0'])\n        return output_table"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _do_photometry(self, param_tab, n_start=1):\n\n        output_table = Table()\n        self._define_fit_param_names()\n\n        for (init_parname, fit_parname) in zip(self._pars_to_set.keys(),\n                                               self._pars_to_output.keys()):\n            output_table.add_column(Column(name=init_parname))\n            output_table.add_column(Column(name=fit_parname))\n\n        sources = self.finder(self._residual_image)\n\n        n = n_start\n        while(sources is not None and\n              (self.niters is None or n <= self.niters)):\n            apertures = CircularAperture((sources['xcentroid'],\n                                          sources['ycentroid']),\n                                         r=self.aperture_radius)\n            sources['aperture_flux'] = aperture_photometry(\n                self._residual_image, apertures)['aperture_sum']\n\n            init_guess_tab = Table(names=['id', 'x_0', 'y_0', 'flux_0'],\n                                   data=[sources['id'], sources['xcentroid'],\n                                         sources['ycentroid'],\n                                         sources['aperture_flux']])\n\n            for param_tab_name, param_name in self._pars_to_set.items():\n                if param_tab_name not in (['x_0', 'y_0', 'flux_0']):\n                    init_guess_tab.add_column(\n                        Column(name=param_tab_name,\n                               data=(getattr(self.psf_model,\n                                             param_name) *\n                                     np.ones(len(sources)))))\n\n            star_groups = self.group_maker(init_guess_tab)\n            table, self._residual_image = super().nstar(\n                self._residual_image, star_groups)\n\n            star_groups = star_groups.group_by('group_id')\n            table = hstack([star_groups, table])\n\n            table['iter_detected'] = n*np.ones(table['x_fit'].shape,\n                                               dtype=np.int32)\n\n            output_table = vstack([output_table, table])\n\n            # do not warn if no sources are found beyond the first iteration\n            with warnings.catch_warnings():\n                warnings.simplefilter('ignore', NoDetectionsWarning)\n                sources = self.finder(self._residual_image)\n\n            n += 1\n\n        return output_table", "response": "This function performs the photometry of the aperture process."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the pixel scale and WCS rotation angle at the position of a SkyCoord coordinate. Parameters ---------- skycoord : `~astropy.coordinates.SkyCoord` The SkyCoord coordinate. wcs : `~astropy.wcs.WCS` The world coordinate system (WCS) transformation to use. offset : `~astropy.units.Quantity` A small angular offset to use to compute the pixel scale and position angle. Returns ------- scale : `~astropy.units.Quantity` The pixel scale in arcsec/pixel. angle : `~astropy.units.Quantity` The angle (in degrees) measured counterclockwise from the positive x axis to the \"North\" axis of the celestial coordinate system. Notes ----- If distortions are present in the image, the x and y pixel scales likely differ. This function computes a single pixel scale along the North/South axis.", "response": "def pixel_scale_angle_at_skycoord(skycoord, wcs, offset=1. * u.arcsec):\n    \"\"\"\n    Calculate the pixel scale and WCS rotation angle at the position of\n    a SkyCoord coordinate.\n\n    Parameters\n    ----------\n    skycoord : `~astropy.coordinates.SkyCoord`\n        The SkyCoord coordinate.\n    wcs : `~astropy.wcs.WCS`\n        The world coordinate system (WCS) transformation to use.\n    offset : `~astropy.units.Quantity`\n        A small angular offset to use to compute the pixel scale and\n        position angle.\n\n    Returns\n    -------\n    scale : `~astropy.units.Quantity`\n        The pixel scale in arcsec/pixel.\n    angle : `~astropy.units.Quantity`\n        The angle (in degrees) measured counterclockwise from the\n        positive x axis to the \"North\" axis of the celestial coordinate\n        system.\n\n    Notes\n    -----\n    If distortions are present in the image, the x and y pixel scales\n    likely differ.  This function computes a single pixel scale along\n    the North/South axis.\n    \"\"\"\n\n    # We take a point directly \"above\" (in latitude) the input position\n    # and convert it to pixel coordinates, then we use the pixel deltas\n    # between the input and offset point to calculate the pixel scale and\n    # angle.\n\n    # Find the coordinates as a representation object\n    coord = skycoord.represent_as('unitspherical')\n\n    # Add a a small perturbation in the latitude direction (since longitude\n    # is more difficult because it is not directly an angle)\n    coord_new = UnitSphericalRepresentation(coord.lon, coord.lat + offset)\n    coord_offset = skycoord.realize_frame(coord_new)\n\n    # Find pixel coordinates of offset coordinates and pixel deltas\n    x_offset, y_offset = skycoord_to_pixel(coord_offset, wcs, mode='all')\n    x, y = skycoord_to_pixel(skycoord, wcs, mode='all')\n    dx = x_offset - x\n    dy = y_offset - y\n\n    scale = offset.to(u.arcsec) / (np.hypot(dx, dy) * u.pixel)\n    angle = (np.arctan2(dy, dx) * u.radian).to(u.deg)\n\n    return scale, angle"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck that q is either an angle or pixel.", "response": "def assert_angle_or_pixel(name, q):\n    \"\"\"\n    Check that ``q`` is either an angular or a pixel\n    :class:`~astropy.units.Quantity`.\n    \"\"\"\n\n    if isinstance(q, u.Quantity):\n        if q.unit.physical_type == 'angle' or q.unit == u.pixel:\n            pass\n        else:\n            raise ValueError(\"{0} should have angular or pixel \"\n                             \"units\".format(name))\n    else:\n        raise TypeError(\"{0} should be a Quantity instance\".format(name))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pixel_to_icrs_coords(x, y, wcs):\n\n    icrs_coords = pixel_to_skycoord(x, y, wcs).icrs\n    icrs_ra = icrs_coords.ra.degree * u.deg\n    icrs_dec = icrs_coords.dec.degree * u.deg\n\n    return icrs_ra, icrs_dec", "response": "Convert pixel coordinates to ICRS Right Ascension and Declination."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfilter the data using a 2D kernel.", "response": "def filter_data(data, kernel, mode='constant', fill_value=0.0,\n                check_normalization=False):\n    \"\"\"\n    Convolve a 2D image with a 2D kernel.\n\n    The kernel may either be a 2D `~numpy.ndarray` or a\n    `~astropy.convolution.Kernel2D` object.\n\n    Parameters\n    ----------\n    data : array_like\n        The 2D array of the image.\n\n    kernel : array-like (2D) or `~astropy.convolution.Kernel2D`\n        The 2D kernel used to filter the input ``data``. Filtering the\n        ``data`` will smooth the noise and maximize detectability of\n        objects with a shape similar to the kernel.\n\n    mode : {'constant', 'reflect', 'nearest', 'mirror', 'wrap'}, optional\n        The ``mode`` determines how the array borders are handled.  For\n        the ``'constant'`` mode, values outside the array borders are\n        set to ``fill_value``.  The default is ``'constant'``.\n\n    fill_value : scalar, optional\n        Value to fill data values beyond the array borders if ``mode``\n        is ``'constant'``.  The default is ``0.0``.\n\n    check_normalization : bool, optional\n        If `True` then a warning will be issued if the kernel is not\n        normalized to 1.\n    \"\"\"\n\n    from scipy import ndimage\n\n    if kernel is not None:\n        if isinstance(kernel, Kernel2D):\n            kernel_array = kernel.array\n        else:\n            kernel_array = kernel\n\n        if check_normalization:\n            if not np.allclose(np.sum(kernel_array), 1.0):\n                warnings.warn('The kernel is not normalized.',\n                              AstropyUserWarning)\n\n        # NOTE:  astropy.convolution.convolve fails with zero-sum\n        # kernels (used in findstars) (cf. astropy #1647)\n        # NOTE: if data is int and kernel is float, ndimage.convolve\n        # will return an int image - here we make the data float so\n        # that a float image is always returned\n        return ndimage.convolve(data.astype(float), kernel_array, mode=mode,\n                                cval=fill_value)\n    else:\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a 2D PSF model to one suitable for use with with .", "response": "def prepare_psf_model(psfmodel, xname=None, yname=None, fluxname=None,\n                      renormalize_psf=True):\n    \"\"\"\n    Convert a 2D PSF model to one suitable for use with\n    `BasicPSFPhotometry` or its subclasses.\n\n    The resulting model may be a composite model, but should have only\n    the x, y, and flux related parameters un-fixed.\n\n    Parameters\n    ----------\n    psfmodel : a 2D model\n        The model to assume as representative of the PSF.\n    xname : str or None\n        The name of the ``psfmodel`` parameter that corresponds to the\n        x-axis center of the PSF.  If None, the model will be assumed to\n        be centered at x=0, and a new parameter will be added for the\n        offset.\n    yname : str or None\n        The name of the ``psfmodel`` parameter that corresponds to the\n        y-axis center of the PSF.  If None, the model will be assumed to\n        be centered at y=0, and a new parameter will be added for the\n        offset.\n    fluxname : str or None\n        The name of the ``psfmodel`` parameter that corresponds to the\n        total flux of the star.  If None, a scaling factor will be added\n        to the model.\n    renormalize_psf : bool\n        If True, the model will be integrated from -inf to inf and\n        re-scaled so that the total integrates to 1.  Note that this\n        renormalization only occurs *once*, so if the total flux of\n        ``psfmodel`` depends on position, this will *not* be correct.\n\n    Returns\n    -------\n    outmod : a model\n        A new model ready to be passed into `BasicPSFPhotometry` or its\n        subclasses.\n    \"\"\"\n\n    if xname is None:\n        xinmod = models.Shift(0, name='x_offset')\n        xname = 'offset_0'\n    else:\n        xinmod = models.Identity(1)\n        xname = xname + '_2'\n    xinmod.fittable = True\n\n    if yname is None:\n        yinmod = models.Shift(0, name='y_offset')\n        yname = 'offset_1'\n    else:\n        yinmod = models.Identity(1)\n        yname = yname + '_2'\n    yinmod.fittable = True\n\n    outmod = (xinmod & yinmod) | psfmodel\n\n    if fluxname is None:\n        outmod = outmod * models.Const2D(1, name='flux_scaling')\n        fluxname = 'amplitude_3'\n    else:\n        fluxname = fluxname + '_2'\n\n    if renormalize_psf:\n        # we do the import here because other machinery works w/o scipy\n        from scipy import integrate\n\n        integrand = integrate.dblquad(psfmodel, -np.inf, np.inf,\n                                      lambda x: -np.inf, lambda x: np.inf)[0]\n        normmod = models.Const2D(1./integrand, name='renormalize_scaling')\n        outmod = outmod * normmod\n\n    # final setup of the output model - fix all the non-offset/scale\n    # parameters\n    for pnm in outmod.param_names:\n        outmod.fixed[pnm] = pnm not in (xname, yname, fluxname)\n\n    # and set the names so that BasicPSFPhotometry knows what to do\n    outmod.xname = xname\n    outmod.yname = yname\n    outmod.fluxname = fluxname\n\n    # now some convenience aliases if reasonable\n    outmod.psfmodel = outmod[2]\n    if 'x_0' not in outmod.param_names and 'y_0' not in outmod.param_names:\n        outmod.x_0 = getattr(outmod, xname)\n        outmod.y_0 = getattr(outmod, yname)\n    if 'flux' not in outmod.param_names:\n        outmod.flux = getattr(outmod, fluxname)\n\n    return outmod"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a new PSF model which is a sum of PSF s templated on the given model.", "response": "def get_grouped_psf_model(template_psf_model, star_group, pars_to_set):\n    \"\"\"\n    Construct a joint PSF model which consists of a sum of PSF's templated on\n    a specific model, but whose parameters are given by a table of objects.\n\n    Parameters\n    ----------\n    template_psf_model : `astropy.modeling.Fittable2DModel` instance\n        The model to use for *individual* objects.  Must have parameters named\n        ``x_0``, ``y_0``, and ``flux``.\n    star_group : `~astropy.table.Table`\n        Table of stars for which the compound PSF will be constructed.  It\n        must have columns named ``x_0``, ``y_0``, and ``flux_0``.\n\n    Returns\n    -------\n    group_psf\n        An `astropy.modeling` ``CompoundModel`` instance which is a sum of the\n        given PSF models.\n    \"\"\"\n\n    group_psf = None\n\n    for star in star_group:\n        psf_to_add = template_psf_model.copy()\n        for param_tab_name, param_name in pars_to_set.items():\n            setattr(psf_to_add, param_name, star[param_tab_name])\n\n        if group_psf is None:\n            # this is the first one only\n            group_psf = psf_to_add\n        else:\n            group_psf += psf_to_add\n\n    return group_psf"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _extract_psf_fitting_names(psf):\n\n    if hasattr(psf, 'xname'):\n        xname = psf.xname\n    elif 'x_0' in psf.param_names:\n        xname = 'x_0'\n    else:\n        raise ValueError('Could not determine x coordinate name for '\n                         'psf_photometry.')\n\n    if hasattr(psf, 'yname'):\n        yname = psf.yname\n    elif 'y_0' in psf.param_names:\n        yname = 'y_0'\n    else:\n        raise ValueError('Could not determine y coordinate name for '\n                         'psf_photometry.')\n\n    if hasattr(psf, 'fluxname'):\n        fluxname = psf.fluxname\n    elif 'flux' in psf.param_names:\n        fluxname = 'flux'\n    else:\n        raise ValueError('Could not determine flux name for psf_photometry.')\n\n    return xname, yname, fluxname", "response": "Extract the names of the x coordinate y coordinate and flux from a PSF model."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _call_fitter(fitter, psf, x, y, data, weights):\n\n    if np.all(weights == 1.):\n        return fitter(psf, x, y, data)\n    else:\n        return fitter(psf, x, y, data, weights=weights)", "response": "Call fitters with respect to the data."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsubtracts a PSF from an image.", "response": "def subtract_psf(data, psf, posflux, subshape=None):\n    \"\"\"\n    Subtract PSF/PRFs from an image.\n\n    Parameters\n    ----------\n    data : `~astropy.nddata.NDData` or array (must be 2D)\n        Image data.\n    psf : `astropy.modeling.Fittable2DModel` instance\n        PSF/PRF model to be substracted from the data.\n    posflux : Array-like of shape (3, N) or `~astropy.table.Table`\n        Positions and fluxes for the objects to subtract.  If an array,\n        it is interpreted as ``(x, y, flux)``  If a table, the columns\n        'x_fit', 'y_fit', and 'flux_fit' must be present.\n    subshape : length-2 or None\n        The shape of the region around the center of the location to\n        subtract the PSF from.  If None, subtract from the whole image.\n\n    Returns\n    -------\n    subdata : same shape and type as ``data``\n        The image with the PSF subtracted\n    \"\"\"\n\n    if data.ndim != 2:\n        raise ValueError('{0}-d array not supported. Only 2-d arrays can be '\n                         'passed to subtract_psf.'.format(data.ndim))\n\n    #  translate array input into table\n    if hasattr(posflux, 'colnames'):\n        if 'x_fit' not in posflux.colnames:\n            raise ValueError('Input table does not have x_fit')\n        if 'y_fit' not in posflux.colnames:\n            raise ValueError('Input table does not have y_fit')\n        if 'flux_fit' not in posflux.colnames:\n            raise ValueError('Input table does not have flux_fit')\n    else:\n        posflux = Table(names=['x_fit', 'y_fit', 'flux_fit'], data=posflux)\n\n    # Set up contstants across the loop\n    psf = psf.copy()\n    xname, yname, fluxname = _extract_psf_fitting_names(psf)\n    indices = np.indices(data.shape)\n    subbeddata = data.copy()\n\n    if subshape is None:\n        indicies_reversed = indices[::-1]\n\n        for row in posflux:\n            getattr(psf, xname).value = row['x_fit']\n            getattr(psf, yname).value = row['y_fit']\n            getattr(psf, fluxname).value = row['flux_fit']\n\n            subbeddata -= psf(*indicies_reversed)\n    else:\n        for row in posflux:\n            x_0, y_0 = row['x_fit'], row['y_fit']\n\n            y = extract_array(indices[0], subshape, (y_0, x_0))\n            x = extract_array(indices[1], subshape, (y_0, x_0))\n\n            getattr(psf, xname).value = x_0\n            getattr(psf, yname).value = y_0\n            getattr(psf, fluxname).value = row['flux_fit']\n\n            subbeddata = add_array(subbeddata, -psf(x, y), (y_0, x_0))\n\n    return subbeddata"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating a pixel-wise threshold image that can be used to detect sources. Parameters ---------- data : array_like The 2D array of the image. snr : float The signal-to-noise ratio per pixel above the ``background`` for which to consider a pixel as possibly being part of a source. background : float or array_like, optional The background value(s) of the input ``data``. ``background`` may either be a scalar value or a 2D image with the same shape as the input ``data``. If the input ``data`` has been background-subtracted, then set ``background`` to ``0.0``. If `None`, then a scalar background value will be estimated using sigma-clipped statistics. error : float or array_like, optional The Gaussian 1-sigma standard deviation of the background noise in ``data``. ``error`` should include all sources of \"background\" error, but *exclude* the Poisson error of the sources. If ``error`` is a 2D image, then it should represent the 1-sigma background error in each pixel of ``data``. If `None`, then a scalar background rms value will be estimated using sigma-clipped statistics. mask : array_like, bool, optional A boolean mask with the same shape as ``data``, where a `True` value indicates the corresponding element of ``data`` is masked. Masked pixels are ignored when computing the image background statistics. mask_value : float, optional An image data value (e.g., ``0.0``) that is ignored when computing the image background statistics. ``mask_value`` will be ignored if ``mask`` is input. sigclip_sigma : float, optional The number of standard deviations to use as the clipping limit when calculating the image background statistics. sigclip_iters : int, optional The number of iterations to perform sigma clipping, or `None` to clip until convergence is achieved (i.e., continue until the last iteration clips nothing) when calculating the image background statistics. Returns ------- threshold : 2D `~numpy.ndarray` A 2D image with the same shape as ``data`` containing the pixel-wise threshold values. See Also -------- :func:`photutils.segmentation.detect_sources` Notes ----- The ``mask``, ``mask_value``, ``sigclip_sigma``, and ``sigclip_iters`` inputs are used only if it is necessary to estimate ``background`` or ``error`` using sigma-clipped background statistics. If ``background`` and ``error`` are both input, then ``mask``, ``mask_value``, ``sigclip_sigma``, and ``sigclip_iters`` are ignored.", "response": "def detect_threshold(data, snr, background=None, error=None, mask=None,\n                     mask_value=None, sigclip_sigma=3.0, sigclip_iters=None):\n    \"\"\"\n    Calculate a pixel-wise threshold image that can be used to detect\n    sources.\n\n    Parameters\n    ----------\n    data : array_like\n        The 2D array of the image.\n\n    snr : float\n        The signal-to-noise ratio per pixel above the ``background`` for\n        which to consider a pixel as possibly being part of a source.\n\n    background : float or array_like, optional\n        The background value(s) of the input ``data``.  ``background``\n        may either be a scalar value or a 2D image with the same shape\n        as the input ``data``.  If the input ``data`` has been\n        background-subtracted, then set ``background`` to ``0.0``.  If\n        `None`, then a scalar background value will be estimated using\n        sigma-clipped statistics.\n\n    error : float or array_like, optional\n        The Gaussian 1-sigma standard deviation of the background noise\n        in ``data``.  ``error`` should include all sources of\n        \"background\" error, but *exclude* the Poisson error of the\n        sources.  If ``error`` is a 2D image, then it should represent\n        the 1-sigma background error in each pixel of ``data``.  If\n        `None`, then a scalar background rms value will be estimated\n        using sigma-clipped statistics.\n\n    mask : array_like, bool, optional\n        A boolean mask with the same shape as ``data``, where a `True`\n        value indicates the corresponding element of ``data`` is masked.\n        Masked pixels are ignored when computing the image background\n        statistics.\n\n    mask_value : float, optional\n        An image data value (e.g., ``0.0``) that is ignored when\n        computing the image background statistics.  ``mask_value`` will\n        be ignored if ``mask`` is input.\n\n    sigclip_sigma : float, optional\n        The number of standard deviations to use as the clipping limit\n        when calculating the image background statistics.\n\n    sigclip_iters : int, optional\n       The number of iterations to perform sigma clipping, or `None` to\n       clip until convergence is achieved (i.e., continue until the last\n       iteration clips nothing) when calculating the image background\n       statistics.\n\n    Returns\n    -------\n    threshold : 2D `~numpy.ndarray`\n        A 2D image with the same shape as ``data`` containing the\n        pixel-wise threshold values.\n\n    See Also\n    --------\n    :func:`photutils.segmentation.detect_sources`\n\n    Notes\n    -----\n    The ``mask``, ``mask_value``, ``sigclip_sigma``, and\n    ``sigclip_iters`` inputs are used only if it is necessary to\n    estimate ``background`` or ``error`` using sigma-clipped background\n    statistics.  If ``background`` and ``error`` are both input, then\n    ``mask``, ``mask_value``, ``sigclip_sigma``, and ``sigclip_iters``\n    are ignored.\n    \"\"\"\n\n    if background is None or error is None:\n        if astropy_version < '3.1':\n            data_mean, data_median, data_std = sigma_clipped_stats(\n                data, mask=mask, mask_value=mask_value, sigma=sigclip_sigma,\n                iters=sigclip_iters)\n        else:\n            data_mean, data_median, data_std = sigma_clipped_stats(\n                data, mask=mask, mask_value=mask_value, sigma=sigclip_sigma,\n                maxiters=sigclip_iters)\n\n        bkgrd_image = np.zeros_like(data) + data_mean\n        bkgrdrms_image = np.zeros_like(data) + data_std\n\n    if background is None:\n        background = bkgrd_image\n    else:\n        if np.isscalar(background):\n            background = np.zeros_like(data) + background\n        else:\n            if background.shape != data.shape:\n                raise ValueError('If input background is 2D, then it '\n                                 'must have the same shape as the input '\n                                 'data.')\n\n    if error is None:\n        error = bkgrdrms_image\n    else:\n        if np.isscalar(error):\n            error = np.zeros_like(data) + error\n        else:\n            if error.shape != data.shape:\n                raise ValueError('If input error is 2D, then it '\n                                 'must have the same shape as the input '\n                                 'data.')\n\n    return background + (error * snr)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds local peaks within a specified threshold.", "response": "def find_peaks(data, threshold, box_size=3, footprint=None, mask=None,\n               border_width=None, npeaks=np.inf, centroid_func=None,\n               subpixel=False, error=None, wcs=None):\n    \"\"\"\n    Find local peaks in an image that are above above a specified\n    threshold value.\n\n    Peaks are the maxima above the ``threshold`` within a local region.\n    The local regions are defined by either the ``box_size`` or\n    ``footprint`` parameters.  ``box_size`` defines the local region\n    around each pixel as a square box.  ``footprint`` is a boolean array\n    where `True` values specify the region shape.\n\n    If multiple pixels within a local region have identical intensities,\n    then the coordinates of all such pixels are returned.  Otherwise,\n    there will be only one peak pixel per local region.  Thus, the\n    defined region effectively imposes a minimum separation between\n    peaks unless there are identical peaks within the region.\n\n    If ``centroid_func`` is input, then it will be used to calculate a\n    centroid within the defined local region centered on each detected\n    peak pixel.  In this case, the centroid will also be returned in the\n    output table.\n\n    Parameters\n    ----------\n    data : array_like\n        The 2D array of the image.\n\n    threshold : float or array-like\n        The data value or pixel-wise data values to be used for the\n        detection threshold.  A 2D ``threshold`` must have the same\n        shape as ``data``.  See `detect_threshold` for one way to create\n        a ``threshold`` image.\n\n    box_size : scalar or tuple, optional\n        The size of the local region to search for peaks at every point\n        in ``data``.  If ``box_size`` is a scalar, then the region shape\n        will be ``(box_size, box_size)``.  Either ``box_size`` or\n        ``footprint`` must be defined.  If they are both defined, then\n        ``footprint`` overrides ``box_size``.\n\n    footprint : `~numpy.ndarray` of bools, optional\n        A boolean array where `True` values describe the local footprint\n        region within which to search for peaks at every point in\n        ``data``.  ``box_size=(n, m)`` is equivalent to\n        ``footprint=np.ones((n, m))``.  Either ``box_size`` or\n        ``footprint`` must be defined.  If they are both defined, then\n        ``footprint`` overrides ``box_size``.\n\n    mask : array_like, bool, optional\n        A boolean mask with the same shape as ``data``, where a `True`\n        value indicates the corresponding element of ``data`` is masked.\n\n    border_width : bool, optional\n        The width in pixels to exclude around the border of the\n        ``data``.\n\n    npeaks : int, optional\n        The maximum number of peaks to return.  When the number of\n        detected peaks exceeds ``npeaks``, the peaks with the highest\n        peak intensities will be returned.\n\n    centroid_func : callable, optional\n        A callable object (e.g. function or class) that is used to\n        calculate the centroid of a 2D array.  The ``centroid_func``\n        must accept a 2D `~numpy.ndarray`, have a ``mask`` keyword, and\n        optionally an ``error`` keyword.  The callable object must\n        return a tuple of two 1D `~numpy.ndarray`\\\\s, representing the x\n        and y centroids, respectively.\n\n    error : array_like, optional\n        The 2D array of the 1-sigma errors of the input ``data``.\n        ``error`` is used only if ``centroid_func`` is input (the\n        ``error`` array is passed directly to the ``centroid_func``).\n\n    wcs : `~astropy.wcs.WCS`\n        The WCS transformation to use to convert from pixel to sky\n        coordinates.  If `None`, then the sky coordinates will not be\n        returned in the output `~astropy.table.Table`.\n\n    Returns\n    -------\n    output : `~astropy.table.Table` or `None`\n        A table containing the x and y pixel location of the peaks and\n        their values.  If ``centroid_func`` is input, then the table\n        will also contain the centroid position.  If no peaks are found\n        then `None` is returned.\n    \"\"\"\n\n    from scipy.ndimage import maximum_filter\n\n    data = np.asanyarray(data)\n\n    if np.all(data == data.flat[0]):\n        warnings.warn('Input data is constant. No local peaks can be found.',\n                      NoDetectionsWarning)\n        return None\n\n    if not np.isscalar(threshold):\n        threshold = np.asanyarray(threshold)\n        if data.shape != threshold.shape:\n            raise ValueError('A threshold array must have the same shape as '\n                             'the input data.')\n\n    # remove NaN values to avoid runtime warnings\n    nan_mask = np.isnan(data)\n    if np.any(nan_mask):\n        data = np.copy(data)  # ndarray\n        data[nan_mask] = np.nanmin(data)\n\n    if footprint is not None:\n        data_max = maximum_filter(data, footprint=footprint, mode='constant',\n                                  cval=0.0)\n    else:\n        data_max = maximum_filter(data, size=box_size, mode='constant',\n                                  cval=0.0)\n\n    peak_goodmask = (data == data_max)    # good pixels are True\n\n    if mask is not None:\n        mask = np.asanyarray(mask)\n        if data.shape != mask.shape:\n            raise ValueError('data and mask must have the same shape')\n        peak_goodmask = np.logical_and(peak_goodmask, ~mask)\n\n    if border_width is not None:\n        for i in range(peak_goodmask.ndim):\n            peak_goodmask = peak_goodmask.swapaxes(0, i)\n            peak_goodmask[:border_width] = False\n            peak_goodmask[-border_width:] = False\n            peak_goodmask = peak_goodmask.swapaxes(0, i)\n\n    peak_goodmask = np.logical_and(peak_goodmask, (data > threshold))\n    y_peaks, x_peaks = peak_goodmask.nonzero()\n    peak_values = data[y_peaks, x_peaks]\n\n    nxpeaks = len(x_peaks)\n    if nxpeaks > npeaks:\n        idx = np.argsort(peak_values)[::-1][:npeaks]\n        x_peaks = x_peaks[idx]\n        y_peaks = y_peaks[idx]\n        peak_values = peak_values[idx]\n\n    if nxpeaks == 0:\n        warnings.warn('No local peaks were found.', NoDetectionsWarning)\n        return None\n\n    # construct the output Table\n    colnames = ['x_peak', 'y_peak', 'peak_value']\n    coldata = [x_peaks, y_peaks, peak_values]\n    table = Table(coldata, names=colnames)\n\n    if wcs is not None:\n        skycoord_peaks = pixel_to_skycoord(x_peaks, y_peaks, wcs, origin=0)\n        table.add_column(skycoord_peaks, name='skycoord_peak', index=2)\n\n    # perform centroiding\n    if centroid_func is not None:\n        from ..centroids import centroid_sources  # prevents circular import\n\n        if not callable(centroid_func):\n            raise TypeError('centroid_func must be a callable object')\n\n        x_centroids, y_centroids = centroid_sources(\n            data, x_peaks, y_peaks, box_size=box_size,\n            footprint=footprint, error=error, mask=mask,\n            centroid_func=centroid_func)\n\n        table['x_centroid'] = x_centroids\n        table['y_centroid'] = y_centroids\n\n    if (centroid_func is not None or subpixel) and wcs is not None:\n        skycoord_centroids = pixel_to_skycoord(x_centroids, y_centroids,\n                                               wcs, origin=0)\n        idx = table.colnames.index('y_centroid')\n        table.add_column(skycoord_centroids, name='skycoord_centroid',\n                         index=idx+1)\n\n    return table"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run_cmd(cmd):\n\n    try:\n        p = sp.Popen(cmd, stdout=sp.PIPE, stderr=sp.PIPE)\n        # XXX: May block if either stdout or stderr fill their buffers;\n        # however for the commands this is currently used for that is\n        # unlikely (they should have very brief output)\n        stdout, stderr = p.communicate()\n    except OSError as e:\n        if DEBUG:\n            raise\n\n        if e.errno == errno.ENOENT:\n            msg = 'Command not found: `{0}`'.format(' '.join(cmd))\n            raise _CommandNotFound(msg, cmd)\n        else:\n            raise _AHBootstrapSystemExit(\n                'An unexpected error occurred when running the '\n                '`{0}` command:\\n{1}'.format(' '.join(cmd), str(e)))\n\n\n    # Can fail of the default locale is not configured properly.  See\n    # https://github.com/astropy/astropy/issues/2749.  For the purposes under\n    # consideration 'latin1' is an acceptable fallback.\n    try:\n        stdio_encoding = locale.getdefaultlocale()[1] or 'latin1'\n    except ValueError:\n        # Due to an OSX oddity locale.getdefaultlocale() can also crash\n        # depending on the user's locale/language settings.  See:\n        # http://bugs.python.org/issue18378\n        stdio_encoding = 'latin1'\n\n    # Unlikely to fail at this point but even then let's be flexible\n    if not isinstance(stdout, str):\n        stdout = stdout.decode(stdio_encoding, 'replace')\n    if not isinstance(stderr, str):\n        stderr = stderr.decode(stdio_encoding, 'replace')\n\n    return (p.returncode, stdout, stderr)", "response": "Run a command in a subprocess given as a list of command - line arguments."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_mask(self, method='exact', subpixels=5):\n\n        use_exact, subpixels = self._translate_mask_mode(method, subpixels)\n\n        if hasattr(self, 'a'):\n            a = self.a\n            b = self.b\n        elif hasattr(self, 'a_in'):    # annulus\n            a = self.a_out\n            b = self.b_out\n            b_in = self.a_in * self.b_out / self.a_out\n        else:\n            raise ValueError('Cannot determine the aperture shape.')\n\n        masks = []\n        for bbox, edges in zip(self.bounding_boxes, self._centered_edges):\n            ny, nx = bbox.shape\n            mask = elliptical_overlap_grid(edges[0], edges[1], edges[2],\n                                           edges[3], nx, ny, a, b, self.theta,\n                                           use_exact, subpixels)\n\n            # subtract the inner ellipse for an annulus\n            if hasattr(self, 'a_in'):\n                mask -= elliptical_overlap_grid(edges[0], edges[1], edges[2],\n                                                edges[3], nx, ny, self.a_in,\n                                                b_in, self.theta, use_exact,\n                                                subpixels)\n\n            masks.append(ApertureMask(mask, bbox))\n\n        return masks", "response": "Convert the Aperture object to a list of ~photutils. ApertureMask objects."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert the aperture to a SkyEllipticalAperture object defined by the WCS.", "response": "def to_sky(self, wcs, mode='all'):\n        \"\"\"\n        Convert the aperture to a `SkyEllipticalAperture` object defined\n        in celestial coordinates.\n\n        Parameters\n        ----------\n        wcs : `~astropy.wcs.WCS`\n            The world coordinate system (WCS) transformation to use.\n\n        mode : {'all', 'wcs'}, optional\n            Whether to do the transformation including distortions\n            (``'all'``; default) or only including only the core WCS\n            transformation (``'wcs'``).\n\n        Returns\n        -------\n        aperture : `SkyEllipticalAperture` object\n            A `SkyEllipticalAperture` object.\n        \"\"\"\n\n        sky_params = self._to_sky_params(wcs, mode=mode)\n        return SkyEllipticalAperture(**sky_params)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting the aperture to a SkyEllipticalAnnulus object defined by the WCS.", "response": "def to_sky(self, wcs, mode='all'):\n        \"\"\"\n        Convert the aperture to a `SkyEllipticalAnnulus` object defined\n        in celestial coordinates.\n\n        Parameters\n        ----------\n        wcs : `~astropy.wcs.WCS`\n            The world coordinate system (WCS) transformation to use.\n\n        mode : {'all', 'wcs'}, optional\n            Whether to do the transformation including distortions\n            (``'all'``; default) or only including only the core WCS\n            transformation (``'wcs'``).\n\n        Returns\n        -------\n        aperture : `SkyEllipticalAnnulus` object\n            A `SkyEllipticalAnnulus` object.\n        \"\"\"\n\n        sky_params = self._to_sky_params(wcs, mode=mode)\n        return SkyEllipticalAnnulus(**sky_params)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert the aperture to an EllipticalAperture object defined by the pixel coordinates.", "response": "def to_pixel(self, wcs, mode='all'):\n        \"\"\"\n        Convert the aperture to an `EllipticalAperture` object defined\n        in pixel coordinates.\n\n        Parameters\n        ----------\n        wcs : `~astropy.wcs.WCS`\n            The world coordinate system (WCS) transformation to use.\n\n        mode : {'all', 'wcs'}, optional\n            Whether to do the transformation including distortions\n            (``'all'``; default) or only including only the core WCS\n            transformation (``'wcs'``).\n\n        Returns\n        -------\n        aperture : `EllipticalAperture` object\n            An `EllipticalAperture` object.\n        \"\"\"\n\n        pixel_params = self._to_pixel_params(wcs, mode=mode)\n        return EllipticalAperture(**pixel_params)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert the aperture to an EllipticalAnnulus object defined in the pixel coordinates.", "response": "def to_pixel(self, wcs, mode='all'):\n        \"\"\"\n        Convert the aperture to an `EllipticalAnnulus` object defined in\n        pixel coordinates.\n\n        Parameters\n        ----------\n        wcs : `~astropy.wcs.WCS`\n            The world coordinate system (WCS) transformation to use.\n\n        mode : {'all', 'wcs'}, optional\n            Whether to do the transformation including distortions\n            (``'all'``; default) or only including only the core WCS\n            transformation (``'wcs'``).\n\n        Returns\n        -------\n        aperture : `EllipticalAnnulus` object\n            An `EllipticalAnnulus` object.\n        \"\"\"\n\n        pixel_params = self._to_pixel_params(wcs, mode=mode)\n        return EllipticalAnnulus(**pixel_params)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _area(sma, eps, phi, r):\n\n    aux = r * math.cos(phi) / sma\n    signal = aux / abs(aux)\n    if abs(aux) >= 1.:\n        aux = signal\n    return abs(sma**2 * (1.-eps) / 2. * math.acos(aux))", "response": "Compute elliptical sector area."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_center(self, image, threshold=0.1, verbose=True):\n\n        self._centerer_mask_half_size = len(IN_MASK) / 2\n        self.centerer_threshold = threshold\n\n        # number of pixels in each mask\n        sz = len(IN_MASK)\n        self._centerer_ones_in = np.ma.masked_array(np.ones(shape=(sz, sz)),\n                                                    mask=IN_MASK)\n        self._centerer_ones_out = np.ma.masked_array(np.ones(shape=(sz, sz)),\n                                                     mask=OUT_MASK)\n        self._centerer_in_mask_npix = np.sum(self._centerer_ones_in)\n        self._centerer_out_mask_npix = np.sum(self._centerer_ones_out)\n\n        # Check if center coordinates point to somewhere inside the frame.\n        # If not, set then to frame center.\n        shape = image.shape\n        _x0 = self.x0\n        _y0 = self.y0\n        if (_x0 is None or _x0 < 0 or _x0 >= shape[1] or _y0 is None or\n                _y0 < 0 or _y0 >= shape[0]):\n            _x0 = shape[1] / 2\n            _y0 = shape[0] / 2\n\n        max_fom = 0.\n        max_i = 0\n        max_j = 0\n\n        # scan all positions inside window\n        window_half_size = 5\n        for i in range(int(_x0 - window_half_size),\n                       int(_x0 + window_half_size) + 1):\n            for j in range(int(_y0 - window_half_size),\n                           int(_y0 + window_half_size) + 1):\n\n                # ensure that it stays inside image frame\n                i1 = int(max(0, i - self._centerer_mask_half_size))\n                j1 = int(max(0, j - self._centerer_mask_half_size))\n                i2 = int(min(shape[1] - 1, i + self._centerer_mask_half_size))\n                j2 = int(min(shape[0] - 1, j + self._centerer_mask_half_size))\n\n                window = image[j1:j2, i1:i2]\n\n                # averages in inner and outer regions.\n                inner = np.ma.masked_array(window, mask=IN_MASK)\n                outer = np.ma.masked_array(window, mask=OUT_MASK)\n                inner_avg = np.sum(inner) / self._centerer_in_mask_npix\n                outer_avg = np.sum(outer) / self._centerer_out_mask_npix\n\n                # standard deviation and figure of merit\n                inner_std = np.std(inner)\n                outer_std = np.std(outer)\n                stddev = np.sqrt(inner_std**2 + outer_std**2)\n\n                fom = (inner_avg - outer_avg) / stddev\n\n                if fom > max_fom:\n                    max_fom = fom\n                    max_i = i\n                    max_j = j\n\n        # figure of merit > threshold: update geometry with new coordinates.\n        if max_fom > threshold:\n            self.x0 = float(max_i)\n            self.y0 = float(max_j)\n\n            if verbose:\n                log.info(\"Found center at x0 = {0:5.1f}, y0 = {1:5.1f}\"\n                         .format(self.x0, self.y0))\n        else:\n            if verbose:\n                log.info('Result is below the threshold -- keeping the '\n                         'original coordinates.')", "response": "This method finds the center of an image in a 10x10 window."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate the polar radius for a given polar angle.", "response": "def radius(self, angle):\n        \"\"\"\n        Calculate the polar radius for a given polar angle.\n\n        Parameters\n        ----------\n        angle : float\n            The polar angle (radians).\n\n        Returns\n        -------\n        radius : float\n            The polar radius (pixels).\n        \"\"\"\n\n        return (self.sma * (1. - self.eps) /\n                np.sqrt(((1. - self.eps) * np.cos(angle))**2 +\n                        (np.sin(angle))**2))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninitializes geometry attributes associated with an elliptical sector at the given polar angle ``phi``. This function computes: * the four vertices that define the elliptical sector on the pixel array. * the sector area (saved in the ``sector_area`` attribute) * the sector angular width (saved in ``sector_angular_width`` attribute) Parameters ---------- phi : float The polar angle (radians) where the sector is located. Returns ------- x, y : 1D `~numpy.ndarray` The x and y coordinates of each vertex as 1D arrays.", "response": "def initialize_sector_geometry(self, phi):\n        \"\"\"\n        Initialize geometry attributes associated with an elliptical\n        sector at the given polar angle ``phi``.\n\n        This function computes:\n\n        * the four vertices that define the elliptical sector on the\n          pixel array.\n        * the sector area (saved in the ``sector_area`` attribute)\n        * the sector angular width (saved in ``sector_angular_width``\n          attribute)\n\n        Parameters\n        ----------\n        phi : float\n            The polar angle (radians) where the sector is located.\n\n        Returns\n        -------\n        x, y : 1D `~numpy.ndarray`\n            The x and y coordinates of each vertex as 1D arrays.\n        \"\"\"\n\n        # These polar radii bound the region between the inner\n        # and outer ellipses that define the sector.\n        sma1, sma2 = self.bounding_ellipses()\n        eps_ = 1. - self.eps\n\n        # polar vector at one side of the elliptical sector\n        self._phi1 = phi - self.sector_angular_width / 2.\n        r1 = (sma1 * eps_ / math.sqrt((eps_ * math.cos(self._phi1))**2\n                                      + (math.sin(self._phi1))**2))\n        r2 = (sma2 * eps_ / math.sqrt((eps_ * math.cos(self._phi1))**2\n                                      + (math.sin(self._phi1))**2))\n\n        # polar vector at the other side of the elliptical sector\n        self._phi2 = phi + self.sector_angular_width / 2.\n        r3 = (sma2 * eps_ / math.sqrt((eps_ * math.cos(self._phi2))**2\n                                      + (math.sin(self._phi2))**2))\n\n        r4 = (sma1 * eps_ / math.sqrt((eps_ * math.cos(self._phi2))**2\n                                      + (math.sin(self._phi2))**2))\n\n        # sector area\n        sa1 = _area(sma1, self.eps, self._phi1, r1)\n        sa2 = _area(sma2, self.eps, self._phi1, r2)\n        sa3 = _area(sma2, self.eps, self._phi2, r3)\n        sa4 = _area(sma1, self.eps, self._phi2, r4)\n        self.sector_area = abs((sa3 - sa2) - (sa4 - sa1))\n\n        # angular width of sector. It is calculated such that the sectors\n        # come out with roughly constant area along the ellipse.\n        self.sector_angular_width = max(min((self._area_factor / (r3 - r4) /\n                                             r4), self._phi_max),\n                                        self._phi_min)\n\n        # compute the 4 vertices that define the elliptical sector.\n        vertex_x = np.zeros(shape=4, dtype=float)\n        vertex_y = np.zeros(shape=4, dtype=float)\n\n        # vertices are labelled in counterclockwise sequence\n        vertex_x[0:2] = np.array([r1, r2]) * math.cos(self._phi1 + self.pa)\n        vertex_x[2:4] = np.array([r4, r3]) * math.cos(self._phi2 + self.pa)\n        vertex_y[0:2] = np.array([r1, r2]) * math.sin(self._phi1 + self.pa)\n        vertex_y[2:4] = np.array([r4, r3]) * math.sin(self._phi2 + self.pa)\n        vertex_x += self.x0\n        vertex_y += self.y0\n\n        return vertex_x, vertex_y"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute the smaller and larger values of the two ellipses that define the integrations take place.", "response": "def bounding_ellipses(self):\n        \"\"\"\n        Compute the semimajor axis of the two ellipses that bound the\n        annulus where integrations take place.\n\n        Returns\n        -------\n        sma1, sma2 : float\n            The smaller and larger values of semimajor axis length that\n            define the annulus bounding ellipses.\n        \"\"\"\n\n        if (self.linear_growth):\n            a1 = self.sma - self.astep / 2.\n            a2 = self.sma + self.astep / 2.\n        else:\n            a1 = self.sma * (1. - self.astep / 2.)\n            a2 = self.sma * (1. + self.astep / 2.)\n\n        return a1, a2"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert the given pixel coordinates to the polar coordinates.", "response": "def to_polar(self, x, y):\n        \"\"\"\n        Return the radius and polar angle in the ellipse coordinate\n        system given (x, y) pixel image coordinates.\n\n        This function takes care of the different definitions for\n        position angle (PA) and polar angle (phi):\n\n        .. math::\n            -\\\\pi < PA < \\\\pi\n\n            0 < phi < 2 \\\\pi\n\n        Note that radius can be anything.  The solution is not tied to\n        the semimajor axis length, but to the center position and tilt\n        angle.\n\n        Parameters\n        ----------\n        x, y : float\n            The (x, y) image coordinates.\n\n        Returns\n        -------\n        radius, angle : float\n            The ellipse radius and polar angle.\n        \"\"\"\n        # We split in between a scalar version and a\n        # vectorized version. This is necessary for\n        # now so we don't pay a heavy speed penalty\n        # that is incurred when using vectorized code.\n\n        # The split in two separate functions helps in\n        # the profiling analysis: most of the time is\n        # spent in the scalar function.\n\n        if isinstance(x, int) or isinstance(x, float):\n            return self._to_polar_scalar(x, y)\n        else:\n            return self._to_polar_vectorized(x, y)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncalculate the new semimajor axis length for the current semimajor axis and the given step value.", "response": "def update_sma(self, step):\n        \"\"\"\n        Calculate an updated value for the semimajor axis, given the\n        current value and the step value.\n\n        The step value must be managed by the caller to support both\n        modes: grow outwards and shrink inwards.\n\n        Parameters\n        ----------\n        step : float\n            The step value.\n\n        Returns\n        -------\n        sma : float\n            The new semimajor axis length.\n        \"\"\"\n\n        if self.linear_growth:\n            sma = self.sma + step\n        else:\n            sma = self.sma * (1. + step)\n        return sma"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nresetting the semimajor axis growth from outwards to inwards to the new step value.", "response": "def reset_sma(self, step):\n        \"\"\"\n        Change the direction of semimajor axis growth, from outwards to\n        inwards.\n\n        Parameters\n        ----------\n        step : float\n            The current step value.\n\n        Returns\n        -------\n        sma, new_step : float\n            The new semimajor axis length and the new step value to\n            initiate the shrinking of the semimajor axis length. This is\n            the step value that should be used when calling the\n            :meth:`~photutils.isophote.EllipseGeometry.update_sma`\n            method.\n        \"\"\"\n\n        if self.linear_growth:\n            sma = self.sma - step\n            step = -step\n        else:\n            aux = 1. / (1. + step)\n            sma = self.sma * aux\n            step = aux - 1.\n\n        return sma, step"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef resize_psf(psf, input_pixel_scale, output_pixel_scale, order=3):\n\n    from scipy.ndimage import zoom\n\n    ratio = input_pixel_scale / output_pixel_scale\n    return zoom(psf, ratio, order=order) / ratio**2", "response": "Resizes a PSF using spline interpolation."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a kernel to match two PSFs.", "response": "def create_matching_kernel(source_psf, target_psf, window=None):\n    \"\"\"\n    Create a kernel to match 2D point spread functions (PSF) using the\n    ratio of Fourier transforms.\n\n    Parameters\n    ----------\n    source_psf : 2D `~numpy.ndarray`\n        The source PSF.  The source PSF should have higher resolution\n        (i.e. narrower) than the target PSF.  ``source_psf`` and\n        ``target_psf`` must have the same shape and pixel scale.\n\n    target_psf : 2D `~numpy.ndarray`\n        The target PSF.  The target PSF should have lower resolution\n        (i.e. broader) than the source PSF.  ``source_psf`` and\n        ``target_psf`` must have the same shape and pixel scale.\n\n    window : callable, optional\n        The window (or taper) function or callable class instance used\n        to remove high frequency noise from the PSF matching kernel.\n        Some examples include:\n\n        * `~photutils.psf.matching.HanningWindow`\n        * `~photutils.psf.matching.TukeyWindow`\n        * `~photutils.psf.matching.CosineBellWindow`\n        * `~photutils.psf.matching.SplitCosineBellWindow`\n        * `~photutils.psf.matching.TopHatWindow`\n\n        For more information on window functions and example usage, see\n        :ref:`psf_matching`.\n\n    Returns\n    -------\n    kernel : 2D `~numpy.ndarray`\n        The matching kernel to go from ``source_psf`` to ``target_psf``.\n        The output matching kernel is normalized such that it sums to 1.\n    \"\"\"\n\n    # inputs are copied so that they are not changed when normalizing\n    source_psf = np.copy(np.asanyarray(source_psf))\n    target_psf = np.copy(np.asanyarray(target_psf))\n\n    if source_psf.shape != target_psf.shape:\n        raise ValueError('source_psf and target_psf must have the same shape '\n                         '(i.e. registered with the same pixel scale).')\n\n    # ensure input PSFs are normalized\n    source_psf /= source_psf.sum()\n    target_psf /= target_psf.sum()\n\n    source_otf = fftshift(fft2(source_psf))\n    target_otf = fftshift(fft2(target_psf))\n    ratio = target_otf / source_otf\n\n    # apply a window function in frequency space\n    if window is not None:\n        ratio *= window(target_psf.shape)\n\n    kernel = np.real(fftshift((ifft2(ifftshift(ratio)))))\n    return kernel / kernel.sum()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npads the data and mask to have an integer number of background meshes of size yextra and xextra.", "response": "def _pad_data(self, yextra, xextra):\n        \"\"\"\n        Pad the ``data`` and ``mask`` to have an integer number of\n        background meshes of size ``box_size`` in both dimensions.  The\n        padding is added on the top and/or right edges (this is the best\n        option for the \"zoom\" interpolator).\n\n        Parameters\n        ----------\n        yextra, xextra : int\n            The modulus of the data size and the box size in both the\n            ``y`` and ``x`` dimensions.  This is the number of extra\n            pixels beyond a multiple of the box size in the ``y`` and\n            ``x`` dimensions.\n\n        Returns\n        -------\n        result : `~numpy.ma.MaskedArray`\n            The padded data and mask as a masked array.\n        \"\"\"\n\n        ypad = 0\n        xpad = 0\n        if yextra > 0:\n            ypad = self.box_size[0] - yextra\n        if xextra > 0:\n            xpad = self.box_size[1] - xextra\n        pad_width = ((0, ypad), (0, xpad))\n\n        # mode must be a string for numpy < 0.11\n        # (see https://github.com/numpy/numpy/issues/7112)\n        mode = str('constant')\n        data = np.pad(self.data, pad_width, mode=mode,\n                      constant_values=[1.e10])\n\n        # mask the padded regions\n        pad_mask = np.zeros_like(data)\n        y0 = data.shape[0] - ypad\n        x0 = data.shape[1] - xpad\n        pad_mask[y0:, :] = True\n        pad_mask[:, x0:] = True\n\n        # pad the input mask separately (there is no np.ma.pad function)\n        if self.mask is not None:\n            mask = np.pad(self.mask, pad_width, mode=mode,\n                          constant_values=[True])\n            mask = np.logical_or(mask, pad_mask)\n        else:\n            mask = pad_mask\n\n        return np.ma.masked_array(data, mask=mask)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _crop_data(self):\n\n        ny_crop = self.nyboxes * self.box_size[1]\n        nx_crop = self.nxboxes * self.box_size[0]\n        crop_slc = index_exp[0:ny_crop, 0:nx_crop]\n        if self.mask is not None:\n            mask = self.mask[crop_slc]\n        else:\n            mask = False\n\n        return np.ma.masked_array(self.data[crop_slc], mask=mask)", "response": "Crop the data and mask to have an integer number of of\n            background meshes of size box_size in both dimensions."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nselects the indices of the good meshes that contain at least self. box_npixels pixels.", "response": "def _select_meshes(self, data):\n        \"\"\"\n        Define the x and y indices with respect to the low-resolution\n        mesh image of the meshes to use for the background\n        interpolation.\n\n        The ``exclude_percentile`` keyword determines which meshes are\n        not used for the background interpolation.\n\n        Parameters\n        ----------\n        data : 2D `~numpy.ma.MaskedArray`\n            A 2D array where the y dimension represents each mesh and\n            the x dimension represents the data in each mesh.\n\n        Returns\n        -------\n        mesh_idx : 1D `~numpy.ndarray`\n            The 1D mesh indices.\n        \"\"\"\n\n        # the number of masked pixels in each mesh\n        nmasked = np.ma.count_masked(data, axis=1)\n\n        # meshes that contain more than ``exclude_percentile`` percent\n        # masked pixels are excluded:\n        #   - for exclude_percentile=0, good meshes will be only where\n        #     nmasked=0\n        #   - meshes where nmasked=self.box_npixels are *always* excluded\n        #     (second conditional needed for exclude_percentile=100)\n        threshold_npixels = self.exclude_percentile / 100. * self.box_npixels\n        mesh_idx = np.where((nmasked <= threshold_npixels) &\n                            (nmasked != self.box_npixels))[0]    # good meshes\n\n        if len(mesh_idx) == 0:\n            raise ValueError('All meshes contain > {0} ({1} percent per '\n                             'mesh) masked pixels.  Please check your data '\n                             'or decrease \"exclude_percentile\".'\n                             .format(threshold_npixels,\n                                     self.exclude_percentile))\n\n        return mesh_idx"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _prepare_data(self):\n\n        self.nyboxes = self.data.shape[0] // self.box_size[0]\n        self.nxboxes = self.data.shape[1] // self.box_size[1]\n        yextra = self.data.shape[0] % self.box_size[0]\n        xextra = self.data.shape[1] % self.box_size[1]\n\n        if (xextra + yextra) == 0:\n            # no resizing of the data is necessary\n            data_ma = np.ma.masked_array(self.data, mask=self.mask)\n        else:\n            # pad or crop the data\n            if self.edge_method == 'pad':\n                data_ma = self._pad_data(yextra, xextra)\n                self.nyboxes = data_ma.shape[0] // self.box_size[0]\n                self.nxboxes = data_ma.shape[1] // self.box_size[1]\n            elif self.edge_method == 'crop':\n                data_ma = self._crop_data()\n            else:\n                raise ValueError('edge_method must be \"pad\" or \"crop\"')\n\n        self.nboxes = self.nxboxes * self.nyboxes\n\n        # a reshaped 2D masked array with mesh data along the x axis\n        mesh_data = np.ma.swapaxes(data_ma.reshape(\n            self.nyboxes, self.box_size[0], self.nxboxes, self.box_size[1]),\n            1, 2).reshape(self.nyboxes * self.nxboxes, self.box_npixels)\n\n        # first cut on rejecting meshes\n        self.mesh_idx = self._select_meshes(mesh_data)\n        self._mesh_data = mesh_data[self.mesh_idx, :]\n\n        return", "response": "Prepares the data array for the entry point."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a 1D array of mesh values to a 2D masked array.", "response": "def _make_2d_array(self, data):\n        \"\"\"\n        Convert a 1D array of mesh values to a masked 2D mesh array\n        given the 1D mesh indices ``mesh_idx``.\n\n        Parameters\n        ----------\n        data : 1D `~numpy.ndarray`\n            A 1D array of mesh values.\n\n        Returns\n        -------\n        result : 2D `~numpy.ma.MaskedArray`\n            A 2D masked array.  Pixels not defined in ``mesh_idx`` are\n            masked.\n        \"\"\"\n\n        if data.shape != self.mesh_idx.shape:\n            raise ValueError('data and mesh_idx must have the same shape')\n\n        if np.ma.is_masked(data):\n            raise ValueError('data must not be a masked array')\n\n        data2d = np.zeros(self._mesh_shape).astype(data.dtype)\n        data2d[self.mesh_yidx, self.mesh_xidx] = data\n\n        if len(self.mesh_idx) == self.nboxes:\n            # no meshes were masked\n            return data2d\n        else:\n            # some meshes were masked\n            mask2d = np.ones(data2d.shape).astype(np.bool)\n            mask2d[self.mesh_yidx, self.mesh_xidx] = False\n\n            return np.ma.masked_array(data2d, mask=mask2d)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _interpolate_meshes(self, data, n_neighbors=10, eps=0., power=1.,\n                            reg=0.):\n        \"\"\"\n        Use IDW interpolation to fill in any masked pixels in the\n        low-resolution 2D mesh background and background RMS images.\n\n        This is required to use a regular-grid interpolator to expand\n        the low-resolution image to the full size image.\n\n        Parameters\n        ----------\n        data : 1D `~numpy.ndarray`\n            A 1D array of mesh values.\n\n        n_neighbors : int, optional\n            The maximum number of nearest neighbors to use during the\n            interpolation.\n\n        eps : float, optional\n            Set to use approximate nearest neighbors; the kth neighbor\n            is guaranteed to be no further than (1 + ``eps``) times the\n            distance to the real *k*-th nearest neighbor. See\n            `scipy.spatial.cKDTree.query` for further information.\n\n        power : float, optional\n            The power of the inverse distance used for the interpolation\n            weights.  See the Notes section for more details.\n\n        reg : float, optional\n            The regularization parameter. It may be used to control the\n            smoothness of the interpolator. See the Notes section for\n            more details.\n\n        Returns\n        -------\n        result : 2D `~numpy.ndarray`\n            A 2D array of the mesh values where masked pixels have been\n            filled by IDW interpolation.\n       \"\"\"\n\n        yx = np.column_stack([self.mesh_yidx, self.mesh_xidx])\n        coords = np.array(list(product(range(self.nyboxes),\n                                       range(self.nxboxes))))\n        f = ShepardIDWInterpolator(yx, data)\n        img1d = f(coords, n_neighbors=n_neighbors, power=power, eps=eps,\n                  reg=reg)\n\n        return img1d.reshape(self._mesh_shape)", "response": "Interpolate the data array with the nearest neighbors and fill in any masked pixels in the 2D mesh background and background RMS images."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\napply a 2D median filter to the low - resolution 2D mesh.", "response": "def _filter_meshes(self):\n        \"\"\"\n        Apply a 2D median filter to the low-resolution 2D mesh,\n        including only pixels inside the image at the borders.\n        \"\"\"\n\n        from scipy.ndimage import generic_filter\n        try:\n            nanmedian_func = np.nanmedian    # numpy >= 1.9\n        except AttributeError:    # pragma: no cover\n            from scipy.stats import nanmedian\n            nanmedian_func = nanmedian\n\n        if self.filter_threshold is None:\n            # filter the entire arrays\n            self.background_mesh = generic_filter(\n                self.background_mesh, nanmedian_func, size=self.filter_size,\n                mode='constant', cval=np.nan)\n            self.background_rms_mesh = generic_filter(\n                self.background_rms_mesh, nanmedian_func,\n                size=self.filter_size, mode='constant', cval=np.nan)\n        else:\n            # selectively filter\n            indices = np.nonzero(self.background_mesh > self.filter_threshold)\n            self.background_mesh = self._selective_filter(\n                self.background_mesh, indices)\n            self.background_rms_mesh = self._selective_filter(\n                self.background_rms_mesh, indices)\n\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _calc_bkg_bkgrms(self):\n\n        if self.sigma_clip is not None:\n            data_sigclip = self.sigma_clip(self._mesh_data, axis=1)\n        else:\n            data_sigclip = self._mesh_data\n        del self._mesh_data\n\n        # preform mesh rejection on sigma-clipped data (i.e. for any\n        # newly-masked pixels)\n        idx = self._select_meshes(data_sigclip)\n        self.mesh_idx = self.mesh_idx[idx]    # indices for the output mesh\n        self._data_sigclip = data_sigclip[idx]    # always a 2D masked array\n\n        self._mesh_shape = (self.nyboxes, self.nxboxes)\n        self.mesh_yidx, self.mesh_xidx = np.unravel_index(self.mesh_idx,\n                                                          self._mesh_shape)\n\n        # These properties are needed later to calculate\n        # background_mesh_ma and background_rms_mesh_ma.  Note that _bkg1d\n        # and _bkgrms1d are masked arrays, but the mask should always be\n        # False.\n        self._bkg1d = self.bkg_estimator(self._data_sigclip, axis=1)\n        self._bkgrms1d = self.bkgrms_estimator(self._data_sigclip, axis=1)\n\n        # make the unfiltered 2D mesh arrays (these are not masked)\n        if len(self._bkg1d) == self.nboxes:\n            bkg = self._make_2d_array(self._bkg1d)\n            bkgrms = self._make_2d_array(self._bkgrms1d)\n        else:\n            bkg = self._interpolate_meshes(self._bkg1d)\n            bkgrms = self._interpolate_meshes(self._bkgrms1d)\n\n        self._background_mesh_unfiltered = bkg\n        self._background_rms_mesh_unfiltered = bkgrms\n        self.background_mesh = bkg\n        self.background_rms_mesh = bkgrms\n\n        # filter the 2D mesh arrays\n        if not np.array_equal(self.filter_size, [1, 1]):\n            self._filter_meshes()\n\n        return", "response": "Calculate the background and background RMS estimate in each of the meshes."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _calc_coordinates(self):\n\n        # the position coordinates used to initialize an interpolation\n        self.y = (self.mesh_yidx * self.box_size[0] +\n                  (self.box_size[0] - 1) / 2.)\n        self.x = (self.mesh_xidx * self.box_size[1] +\n                  (self.box_size[1] - 1) / 2.)\n        self.yx = np.column_stack([self.y, self.x])\n\n        # the position coordinates used when calling an interpolator\n        nx, ny = self.data.shape\n        self.data_coords = np.array(list(product(range(ny), range(nx))))", "response": "Calculate the coordinates used to initialize an interpolation for the current image."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mesh_nmasked(self):\n\n        return self._make_2d_array(\n            np.ma.count_masked(self._data_sigclip, axis=1))", "response": "A 2D array of the number of masked pixels in each mesh."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef background_rms_mesh_ma(self):\n\n        if len(self._bkgrms1d) == self.nboxes:\n            return self.background_rms_mesh\n        else:\n            return self._make_2d_array(self._bkgrms1d)", "response": "The background RMS 2D array mesh prior to any\n        interpolation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef plot_meshes(self, ax=None, marker='+', color='blue', outlines=False,\n                    **kwargs):\n        \"\"\"\n        Plot the low-resolution mesh boxes on a matplotlib Axes\n        instance.\n\n        Parameters\n        ----------\n        ax : `matplotlib.axes.Axes` instance, optional\n            If `None`, then the current ``Axes`` instance is used.\n\n        marker : str, optional\n            The marker to use to mark the center of the boxes.  Default\n            is '+'.\n\n        color : str, optional\n            The color for the markers and the box outlines.  Default is\n            'blue'.\n\n        outlines : bool, optional\n            Whether or not to plot the box outlines in addition to the\n            box centers.\n\n        kwargs\n            Any keyword arguments accepted by\n            `matplotlib.patches.Patch`.  Used only if ``outlines`` is\n            True.\n        \"\"\"\n\n        import matplotlib.pyplot as plt\n\n        kwargs['color'] = color\n        if ax is None:\n            ax = plt.gca()\n        ax.scatter(self.x, self.y, marker=marker, color=color)\n        if outlines:\n            from ..aperture import RectangularAperture\n            xy = np.column_stack([self.x, self.y])\n            apers = RectangularAperture(xy, self.box_size[1],\n                                        self.box_size[0], 0.)\n            apers.plot(ax=ax, **kwargs)\n        return", "response": "Plots the low - resolution mesh boxes on a matplotlib Axes instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nextracting sample data by scanning an elliptical path over the image array and extracting the intensity values.", "response": "def extract(self):\n        \"\"\"\n        Extract sample data by scanning an elliptical path over the\n        image array.\n\n        Returns\n        -------\n        result : 2D `~numpy.ndarray`\n            The rows of the array contain the angles, radii, and\n            extracted intensity values, respectively.\n        \"\"\"\n\n        # the sample values themselves are kept cached to prevent\n        # multiple calls to the integrator code.\n        if self.values is not None:\n            return self.values\n        else:\n            s = self._extract()\n            self.values = s\n            return s"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates this ~photutils. isophote. EllipseSample instance.", "response": "def update(self):\n        \"\"\"\n        Update this `~photutils.isophote.EllipseSample` instance.\n\n        This method calls the\n        :meth:`~photutils.isophote.EllipseSample.extract` method to get\n        the values that match the current ``geometry`` attribute, and\n        then computes the the mean intensity, local gradient, and other\n        associated quantities.\n        \"\"\"\n\n        step = self.geometry.astep\n\n        # Update the mean value first, using extraction from main sample.\n        s = self.extract()\n        self.mean = np.mean(s[2])\n\n        # Get sample with same geometry but at a different distance from\n        # center. Estimate gradient from there.\n        gradient, gradient_error = self._get_gradient(step)\n\n        # Check for meaningful gradient. If no meaningful gradient, try\n        # another sample, this time using larger radius. Meaningful\n        # gradient means something  shallower, but still close to within\n        # a factor 3 from previous gradient estimate. If no previous\n        # estimate is available, guess it.\n        previous_gradient = self.gradient\n        if not previous_gradient:\n            previous_gradient = -0.05    # good enough, based on usage\n\n        if gradient >= (previous_gradient / 3.):   # gradient is negative!\n            gradient, gradient_error = self._get_gradient(2 * step)\n\n        # If still no meaningful gradient can be measured, try with\n        # previous one, slightly shallower. A factor 0.8 is not too far\n        # from what is expected from geometrical sampling steps of 10-20%\n        # and a deVaucouleurs law or an exponential disk (at least at its\n        # inner parts, r <~ 5 req). Gradient error is meaningless in this\n        # case.\n        if gradient >= (previous_gradient / 3.):\n            gradient = previous_gradient * 0.8\n            gradient_error = None\n\n        self.gradient = gradient\n        self.gradient_error = gradient_error\n        if gradient_error:\n            self.gradient_relative_error = gradient_error / np.abs(gradient)\n        else:\n            self.gradient_relative_error = None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef coordinates(self):\n\n        angles = self.values[0]\n        radii = self.values[1]\n        x = np.zeros(len(angles))\n        y = np.zeros(len(angles))\n\n        for i in range(len(x)):\n            x[i] = (radii[i] * np.cos(angles[i] + self.geometry.pa) +\n                    self.geometry.x0)\n\n            y[i] = (radii[i] * np.sin(angles[i] + self.geometry.pa) +\n                    self.geometry.y0)\n\n        return x, y", "response": "Return the x and y coordinates associated with each sampled\n            point."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate this ~photutils. isophote. EllipseSample instance with the intensity integrated at the x0 y0.", "response": "def update(self):\n        \"\"\"\n        Update this `~photutils.isophote.EllipseSample` instance with\n        the intensity integrated at the (x0, y0) center position using\n        bilinear integration. The local gradient is set to `None`.\n        \"\"\"\n\n        s = self.extract()\n        self.mean = s[2][0]\n\n        self.gradient = None\n        self.gradient_error = None\n        self.gradient_relative_error = None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fit(self, conver=DEFAULT_CONVERGENCE, minit=DEFAULT_MINIT,\n            maxit=DEFAULT_MAXIT, fflag=DEFAULT_FFLAG, maxgerr=DEFAULT_MAXGERR,\n            going_inwards=False):\n        \"\"\"\n        Fit an elliptical isophote.\n\n        Parameters\n        ----------\n        conver : float, optional\n            The main convergence criterion. Iterations stop when the\n            largest harmonic amplitude becomes smaller (in absolute\n            value) than ``conver`` times the harmonic fit rms.  The\n            default is 0.05.\n        minit : int, optional\n            The minimum number of iterations to perform. A minimum of 10\n            (the default) iterations guarantees that, on average, 2\n            iterations will be available for fitting each independent\n            parameter (the four harmonic amplitudes and the intensity\n            level). For the first isophote, the minimum number of\n            iterations is 2 * ``minit`` to ensure that, even departing\n            from not-so-good initial values, the algorithm has a better\n            chance to converge to a sensible solution.\n        maxit : int, optional\n            The maximum number of iterations to perform.  The default is\n            50.\n        fflag : float, optional\n            The acceptable fraction of flagged data points in the\n            sample.  If the actual fraction of valid data points is\n            smaller than this, the iterations will stop and the current\n            `~photutils.isophote.Isophote` will be returned.  Flagged\n            data points are points that either lie outside the image\n            frame, are masked, or were rejected by sigma-clipping.  The\n            default is 0.7.\n        maxgerr : float, optional\n            The maximum acceptable relative error in the local radial\n            intensity gradient. This is the main control for preventing\n            ellipses to grow to regions of too low signal-to-noise\n            ratio.  It specifies the maximum acceptable relative error\n            in the local radial intensity gradient.  `Busko (1996; ASPC\n            101, 139)\n            <http://adsabs.harvard.edu/abs/1996ASPC..101..139B>`_ showed\n            that the fitting precision relates to that relative error.\n            The usual behavior of the gradient relative error is to\n            increase with semimajor axis, being larger in outer, fainter\n            regions of a galaxy image.  In the current implementation,\n            the ``maxgerr`` criterion is triggered only when two\n            consecutive isophotes exceed the value specified by the\n            parameter. This prevents premature stopping caused by\n            contamination such as stars and HII regions.\n\n            A number of actions may happen when the gradient error\n            exceeds ``maxgerr`` (or becomes non-significant and is set\n            to `None`).  If the maximum semimajor axis specified by\n            ``maxsma`` is set to `None`, semimajor axis growth is\n            stopped and the algorithm proceeds inwards to the galaxy\n            center. If ``maxsma`` is set to some finite value, and this\n            value is larger than the current semimajor axis length, the\n            algorithm enters non-iterative mode and proceeds outwards\n            until reaching ``maxsma``.  The default is 0.5.\n        going_inwards : bool, optional\n            Parameter to define the sense of SMA growth. When fitting\n            just one isophote, this parameter is used only by the code\n            that defines the details of how elliptical arc segments\n            (\"sectors\") are extracted from the image, when using area\n            extraction modes (see the ``integrmode`` parameter in the\n            `~photutils.isophote.EllipseSample` class).  The default is\n            `False`.\n\n        Returns\n        -------\n        result : `~photutils.isophote.Isophote` instance\n            The fitted isophote, which also contains fit status\n            information.\n\n        Examples\n        --------\n        >>> from photutils.isophote import EllipseSample, EllipseFitter\n        >>> sample = EllipseSample(data, sma=10.)\n        >>> fitter = EllipseFitter(sample)\n        >>> isophote = fitter.fit()\n        \"\"\"\n\n        sample = self._sample\n\n        # this flag signals that limiting gradient error (`maxgerr`)\n        # wasn't exceeded yet.\n        lexceed = False\n\n        # here we keep track of the sample that caused the minimum harmonic\n        # amplitude(in absolute value). This will eventually be used to\n        # build the resulting Isophote in cases where iterations run to\n        # the maximum allowed (maxit), or the maximum number of flagged\n        # data points (fflag) is reached.\n        minimum_amplitude_value = np.Inf\n        minimum_amplitude_sample = None\n\n        for iter in range(maxit):\n            # Force the sample to compute its gradient and associated values.\n            sample.update()\n\n            # The extract() method returns sampled values as a 2-d numpy array\n            # with the following structure:\n            # values[0] = 1-d array with angles\n            # values[1] = 1-d array with radii\n            # values[2] = 1-d array with intensity\n            values = sample.extract()\n\n            # Fit harmonic coefficients. Failure in fitting is\n            # a fatal error; terminate immediately with sample\n            # marked as invalid.\n            try:\n                coeffs = fit_first_and_second_harmonics(values[0], values[2])\n            except Exception as e:\n                log.info(e)\n                return Isophote(sample, iter+1, False, 3)\n\n            coeffs = coeffs[0]\n\n            # largest harmonic in absolute value drives the correction.\n            largest_harmonic_index = np.argmax(np.abs(coeffs[1:]))\n            largest_harmonic = coeffs[1:][largest_harmonic_index]\n\n            # see if the amplitude decreased; if yes, keep the\n            # corresponding sample for eventual later use.\n            if abs(largest_harmonic) < minimum_amplitude_value:\n                minimum_amplitude_value = abs(largest_harmonic)\n                minimum_amplitude_sample = sample\n\n            # check if converged\n            model = first_and_second_harmonic_function(values[0], coeffs)\n            residual = values[2] - model\n\n            if ((conver * sample.sector_area * np.std(residual))\n                    > np.abs(largest_harmonic)):\n                # Got a valid solution. But before returning, ensure\n                # that a minimum of iterations has run.\n                if iter >= minit-1:\n                    sample.update()\n                    return Isophote(sample, iter+1, True, 0)\n\n            # it may not have converged yet, but the sample contains too\n            # many invalid data points: return.\n            if sample.actual_points < (sample.total_points * fflag):\n                # when too many data points were flagged, return the\n                # best fit sample instead of the current one.\n                minimum_amplitude_sample.update()\n                return Isophote(minimum_amplitude_sample, iter+1, True, 1)\n\n            # pick appropriate corrector code.\n            corrector = _correctors[largest_harmonic_index]\n\n            # generate *NEW* EllipseSample instance with corrected\n            # parameter.  Note that this instance is still devoid of other\n            # information besides its geometry.  It needs to be explicitly\n            # updated for computations to proceed.  We have to build a new\n            # EllipseSample instance every time because of the lazy\n            # extraction process used by EllipseSample code. To minimize\n            # the number of calls to the area integrators, we pay a\n            # (hopefully smaller) price here, by having multiple calls to\n            # the EllipseSample constructor.\n            sample = corrector.correct(sample, largest_harmonic)\n            sample.update()\n\n            # see if any abnormal (or unusual) conditions warrant\n            # the change to non-iterative mode, or go-inwards mode.\n            proceed, lexceed = self._check_conditions(\n                sample, maxgerr, going_inwards, lexceed)\n\n            if not proceed:\n                sample.update()\n                return Isophote(sample, iter+1, True, -1)\n\n        # Got to the maximum number of iterations. Return with\n        # code 2, and handle it as a valid isophote. Use the\n        # best fit sample instead of the current one.\n        minimum_amplitude_sample.update()\n        return Isophote(minimum_amplitude_sample, maxit, True, 2)", "response": "Fit an elliptical isophote to a new isophote."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfit the isophote to obtain a new central pixel value.", "response": "def fit(self, conver=DEFAULT_CONVERGENCE, minit=DEFAULT_MINIT,\n            maxit=DEFAULT_MAXIT, fflag=DEFAULT_FFLAG, maxgerr=DEFAULT_MAXGERR,\n            going_inwards=False):\n        \"\"\"\n        Perform just a simple 1-pixel extraction at the current (x0, y0)\n        position using bilinear interpolation.\n\n        The input parameters are ignored, but included simple to match\n        the calling signature of the parent class.\n\n        Returns\n        -------\n        result : `~photutils.isophote.CentralEllipsePixel` instance\n            The central pixel value.  For convenience, the\n            `~photutils.isophote.CentralEllipsePixel` class inherits\n            from the `~photutils.isophote.Isophote` class, although it's\n            not really a true isophote but just a single intensity value\n            at the central position.  Thus, most of its attributes are\n            hardcoded to `None` or other default value when appropriate.\n        \"\"\"\n\n        self._sample.update()\n        return CentralPixel(self._sample)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nextracts cutout images centered on stars defined in the input data.", "response": "def extract_stars(data, catalogs, size=(11, 11)):\n    \"\"\"\n    Extract cutout images centered on stars defined in the input\n    catalog(s).\n\n    Stars where the cutout array bounds partially or completely lie\n    outside of the input ``data`` image will not be extracted.\n\n    Parameters\n    ----------\n    data : `~astropy.nddata.NDData` or list of `~astropy.nddata.NDData`\n        A `~astropy.nddata.NDData` object or a list of\n        `~astropy.nddata.NDData` objects containing the 2D image(s) from\n        which to extract the stars.  If the input ``catalogs`` contain\n        only the sky coordinates (i.e. not the pixel coordinates) of the\n        stars then each of the `~astropy.nddata.NDData` objects must\n        have a valid ``wcs`` attribute.\n\n    catalogs : `~astropy.table.Table`, list of `~astropy.table.Table`\n        A catalog or list of catalogs of sources to be extracted from\n        the input ``data``.  To link stars in multiple images as a\n        single source, you must use a single source catalog where the\n        positions defined in sky coordinates.\n\n        If a list of catalogs is input (or a single catalog with a\n        single `~astropy.nddata.NDData` object), they are assumed to\n        correspond to the list of `~astropy.nddata.NDData` objects input\n        in ``data`` (i.e. a separate source catalog for each 2D image).\n        For this case, the center of each source can be defined either\n        in pixel coordinates (in ``x`` and ``y`` columns) or sky\n        coordinates (in a ``skycoord`` column containing a\n        `~astropy.coordinates.SkyCoord` object).  If both are specified,\n        then the pixel coordinates will be used.\n\n        If a single source catalog is input with multiple\n        `~astropy.nddata.NDData` objects, then these sources will be\n        extracted from every 2D image in the input ``data``.  In this\n        case, the sky coordinates for each source must be specified as a\n        `~astropy.coordinates.SkyCoord` object contained in a column\n        called ``skycoord``.  Each `~astropy.nddata.NDData` object in\n        the input ``data`` must also have a valid ``wcs`` attribute.\n        Pixel coordinates (in ``x`` and ``y`` columns) will be ignored.\n\n        Optionally, each catalog may also contain an ``id`` column\n        representing the ID/name of stars.  If this column is not\n        present then the extracted stars will be given an ``id`` number\n        corresponding the the table row number (starting at 1).  Any\n        other columns present in the input ``catalogs`` will be ignored.\n\n    size : int or array_like (int), optional\n        The extraction box size along each axis.  If ``size`` is a\n        scalar then a square box of size ``size`` will be used.  If\n        ``size`` has two elements, they should be in ``(ny, nx)`` order.\n        The size must be greater than or equal to 3 pixel for both axes.\n\n    Returns\n    -------\n    stars : `EPSFStars` instance\n        A `EPSFStars` instance containing the extracted stars.\n    \"\"\"\n\n    if isinstance(data, NDData):\n        data = [data]\n\n    if isinstance(catalogs, Table):\n        catalogs = [catalogs]\n\n    for img in data:\n        if not isinstance(img, NDData):\n            raise ValueError('data must be a single or list of NDData '\n                             'objects.')\n\n    for cat in catalogs:\n        if not isinstance(cat, Table):\n            raise ValueError('catalogs must be a single or list of Table '\n                             'objects.')\n\n    if len(catalogs) == 1 and len(data) > 1:\n        if 'skycoord' not in catalogs[0].colnames:\n            raise ValueError('When inputting a single catalog with multiple '\n                             'NDData objects, the catalog must have a '\n                             '\"skycoord\" column.')\n\n        if any([img.wcs is None for img in data]):\n            raise ValueError('When inputting a single catalog with multiple '\n                             'NDData objects, each NDData object must have '\n                             'a wcs attribute.')\n    else:\n        for cat in catalogs:\n            if 'x' not in cat.colnames or 'y' not in cat.colnames:\n                if 'skycoord' not in cat.colnames:\n                    raise ValueError('When inputting multiple catalogs, '\n                                     'each one must have a \"x\" and \"y\" '\n                                     'column or a \"skycoord\" column.')\n                else:\n                    if any([img.wcs is None for img in data]):\n                        raise ValueError('When inputting catalog(s) with '\n                                         'only skycoord positions, each '\n                                         'NDData object must have a wcs '\n                                         'attribute.')\n\n        if len(data) != len(catalogs):\n            raise ValueError('When inputting multiple catalogs, the number '\n                             'of catalogs must match the number of input '\n                             'images.')\n\n    size = np.atleast_1d(size)\n    if len(size) == 1:\n        size = np.repeat(size, 2)\n\n    min_size = 3\n    if size[0] < min_size or size[1] < min_size:\n        raise ValueError('size must be >= {} for x and y'.format(min_size))\n\n    if len(catalogs) == 1:    # may included linked stars\n        use_xy = True\n        if len(data) > 1:\n            use_xy = False    # linked stars require skycoord positions\n\n        stars = []\n        # stars is a list of lists, one list of stars in each image\n        for img in data:\n            stars.append(_extract_stars(img, catalogs[0], size=size,\n                                        use_xy=use_xy))\n\n        # transpose the list of lists, to associate linked stars\n        stars = list(map(list, zip(*stars)))\n\n        # remove 'None' stars (i.e. no or partial overlap in one or more\n        # images) and handle the case of only one \"linked\" star\n        stars_out = []\n        n_input = len(catalogs[0]) * len(data)\n        n_extracted = 0\n        for star in stars:\n            good_stars = [i for i in star if i is not None]\n            n_extracted += len(good_stars)\n            if len(good_stars) == 0:\n                continue    # no overlap in any image\n            elif len(good_stars) == 1:\n                good_stars = good_stars[0]  # only one star, cannot be linked\n            else:\n                good_stars = LinkedEPSFStar(good_stars)\n\n            stars_out.append(good_stars)\n    else:    # no linked stars\n        stars_out = []\n        for img, cat in zip(data, catalogs):\n            stars_out.extend(_extract_stars(img, cat, size=size, use_xy=True))\n\n        n_input = len(stars_out)\n        stars_out = [star for star in stars_out if star is not None]\n        n_extracted = len(stars_out)\n\n    n_excluded = n_input - n_extracted\n    if n_excluded > 0:\n        warnings.warn('{} star(s) were not extracted because their cutout '\n                      'region extended beyond the input image.'\n                      .format(n_excluded), AstropyUserWarning)\n\n    return EPSFStars(stars_out)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nextracting cutout images from a single image centered on stars defined in the input catalog.", "response": "def _extract_stars(data, catalog, size=(11, 11), use_xy=True):\n    \"\"\"\n    Extract cutout images from a single image centered on stars defined\n    in the single input catalog.\n\n    Parameters\n    ----------\n    data : `~astropy.nddata.NDData`\n        A `~astropy.nddata.NDData` object containing the 2D image from\n        which to extract the stars.  If the input ``catalog`` contains\n        only the sky coordinates (i.e. not the pixel coordinates) of the\n        stars then the `~astropy.nddata.NDData` object must have a valid\n        ``wcs`` attribute.\n\n    catalogs : `~astropy.table.Table`\n        A single catalog of sources to be extracted from the input\n        ``data``.  The center of each source can be defined either in\n        pixel coordinates (in ``x`` and ``y`` columns) or sky\n        coordinates (in a ``skycoord`` column containing a\n        `~astropy.coordinates.SkyCoord` object).  If both are specified,\n        then the value of the ``use_xy`` keyword determines which\n        coordinates will be used.\n\n    size : int or array_like (int), optional\n        The extraction box size along each axis.  If ``size`` is a\n        scalar then a square box of size ``size`` will be used.  If\n        ``size`` has two elements, they should be in ``(ny, nx)`` order.\n        The size must be greater than or equal to 3 pixel for both axes.\n\n    use_xy : bool, optional\n        Whether to use the ``x`` and ``y`` pixel positions when both\n        pixel and sky coordinates are present in the input catalog\n        table.  If `False` then sky coordinates are used instead of\n        pixel coordinates (e.g. for linked stars).  The default is\n        `True`.\n\n    Returns\n    -------\n    stars : list of `EPSFStar` objects\n        A list of `EPSFStar` instances containing the extracted stars.\n    \"\"\"\n\n    colnames = catalog.colnames\n    if ('x' not in colnames or 'y' not in colnames) or not use_xy:\n        xcenters, ycenters = skycoord_to_pixel(catalog['skycoord'], data.wcs,\n                                               origin=0, mode='all')\n    else:\n        xcenters = catalog['x'].data.astype(np.float)\n        ycenters = catalog['y'].data.astype(np.float)\n\n    if 'id' in colnames:\n        ids = catalog['id']\n    else:\n        ids = np.arange(len(catalog), dtype=np.int) + 1\n\n    if data.uncertainty is None:\n        weights = np.ones_like(data.data)\n    else:\n        if data.uncertainty.uncertainty_type == 'weights':\n            weights = np.asanyarray(data.uncertainty.array, dtype=np.float)\n        else:\n            warnings.warn('The data uncertainty attribute has an unsupported '\n                          'type.  Only uncertainty_type=\"weights\" can be '\n                          'used to set weights.  Weights will be set to 1.',\n                          AstropyUserWarning)\n            weights = np.ones_like(data.data)\n\n    if data.mask is not None:\n        weights[data.mask] = 0.\n\n    stars = []\n    for xcenter, ycenter, obj_id in zip(xcenters, ycenters, ids):\n        try:\n            large_slc, small_slc = overlap_slices(data.data.shape, size,\n                                                  (ycenter, xcenter),\n                                                  mode='strict')\n            data_cutout = data.data[large_slc]\n            weights_cutout = weights[large_slc]\n        except (PartialOverlapError, NoOverlapError):\n            stars.append(None)\n            continue\n\n        origin = (large_slc[1].start, large_slc[0].start)\n        cutout_center = (xcenter - origin[0], ycenter - origin[1])\n        star = EPSFStar(data_cutout, weights_cutout,\n                        cutout_center=cutout_center, origin=origin,\n                        wcs_large=data.wcs, id_label=obj_id)\n\n        stars.append(star)\n\n    return stars"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef slices(self):\n\n        return (slice(self.origin[1], self.origin[1] + self.shape[1]),\n                slice(self.origin[0], self.origin[0] + self.shape[0]))", "response": "A tuple of two slices representing the cutout region with\n        respect to the original ( large ) image."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef estimate_flux(self):\n\n        from .epsf import _interpolate_missing_data\n\n        if np.any(self.mask):\n            data_interp = _interpolate_missing_data(self.data, method='cubic',\n                                                    mask=self.mask)\n            data_interp = _interpolate_missing_data(data_interp,\n                                                    method='nearest',\n                                                    mask=self.mask)\n            flux = np.sum(data_interp, dtype=np.float64)\n\n        else:\n            flux = np.sum(self.data, dtype=np.float64)\n\n        return flux", "response": "Estimate the star s flux by summing values in the input cutout\n        array."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef register_epsf(self, epsf):\n\n        yy, xx = np.indices(self.shape, dtype=np.float)\n        xx = epsf._oversampling[0] * (xx - self.cutout_center[0])\n        yy = epsf._oversampling[1] * (yy - self.cutout_center[1])\n\n        return (self.flux * np.prod(epsf._oversampling) *\n                epsf.evaluate(xx, yy, flux=1.0, x_0=0.0, y_0=0.0))", "response": "Register and scale the input ePSF to the star."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef all_stars(self):\n\n        stars = []\n        for item in self._data:\n            if isinstance(item, LinkedEPSFStar):\n                stars.extend(item.all_stars)\n            else:\n                stars.append(item)\n\n        return stars", "response": "A list of all EPSFStar objects stored in this object including those that comprise linked stars."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef all_good_stars(self):\n\n        stars = []\n        for star in self.all_stars:\n            if star._excluded_from_fit:\n                continue\n            else:\n                stars.append(star)\n\n        return stars", "response": "A list of all good EPSFStar objects stored in this object that have not been excluded from fitting including those that comprise\n        linked stars."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the maximum x and y shapes of all the EPSFStar s including the EPSFLinkedStars.", "response": "def _max_shape(self):\n        \"\"\"\n        The maximum x and y shapes of all the `EPSFStar`\\\\s (including\n        linked stars).\n        \"\"\"\n\n        return np.max([star.shape for star in self.all_stars],\n                      axis=0)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconstraining the centers of the linked EPSF objects to have the same sky coordinate.", "response": "def constrain_centers(self):\n        \"\"\"\n        Constrain the centers of linked `EPSFStar` objects (i.e. the\n        same physical star) to have the same sky coordinate.\n\n        Only `EPSFStar` objects that have not been excluded during the\n        ePSF build process will be used to constrain the centers.\n\n        The single sky coordinate is calculated as the mean of sky\n        coordinates of the linked stars.\n        \"\"\"\n\n        if len(self._data) < 2:   # no linked stars\n            return\n\n        idx = np.logical_not(self._excluded_from_fit).nonzero()[0]\n        if len(idx) == 0:\n            warnings.warn('Cannot constrain centers of linked stars because '\n                          'all the stars have been excluded during the ePSF '\n                          'build process.', AstropyUserWarning)\n            return\n\n        good_stars = [self._data[i] for i in idx]\n\n        coords = []\n        for star in good_stars:\n            coords.append(star.wcs_large.all_pix2world(star.center[0],\n                                                       star.center[1], 0))\n\n        # compute mean cartesian coordinates\n        lon, lat = np.transpose(coords)\n        lon *= np.pi / 180.\n        lat *= np.pi / 180.\n        x_mean = np.mean(np.cos(lat) * np.cos(lon))\n        y_mean = np.mean(np.cos(lat) * np.sin(lon))\n        z_mean = np.mean(np.sin(lat))\n\n        # convert mean cartesian coordinates back to spherical\n        hypot = np.hypot(x_mean, y_mean)\n        lon = np.arctan2(y_mean, x_mean)\n        lat = np.arctan2(z_mean, hypot)\n        lon *= 180. / np.pi\n        lat *= 180. / np.pi\n\n        # convert mean sky coordinates back to center pixel coordinates\n        # for each star\n        for star in good_stars:\n            center = np.array(star.wcs_large.all_world2pix(lon, lat, 0))\n            star.cutout_center = center - star.origin"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_group(self, star, starlist):\n\n        star_distance = np.hypot(star['x_0'] - starlist['x_0'],\n                                 star['y_0'] - starlist['y_0'])\n        distance_criteria = star_distance < self.crit_separation\n        return np.asarray(starlist[distance_criteria]['id'])", "response": "Find the ids of those stars in starlist which are at a distance less than self. crit_separation from star."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _from_float(cls, xmin, xmax, ymin, ymax):\n\n        ixmin = int(np.floor(xmin + 0.5))\n        ixmax = int(np.ceil(xmax + 0.5))\n        iymin = int(np.floor(ymin + 0.5))\n        iymax = int(np.ceil(ymax + 0.5))\n\n        return cls(ixmin, ixmax, iymin, iymax)", "response": "Returns a new object containing the smallest bounding box that fully contains a given float coordinate values."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef shape(self):\n\n        return self.iymax - self.iymin, self.ixmax - self.ixmin", "response": "Return the shape of the extent of the current region."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef slices(self):\n\n        return (slice(self.iymin, self.iymax), slice(self.ixmin, self.ixmax))", "response": "Returns a tuple of slice objects for the current region."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the extent of the mask in the image.", "response": "def extent(self):\n        \"\"\"\n        The extent of the mask, defined as the ``(xmin, xmax, ymin,\n        ymax)`` bounding box from the bottom-left corner of the\n        lower-left pixel to the upper-right corner of the upper-right\n        pixel.\n\n        The upper edges here are the actual pixel positions of the\n        edges, i.e. they are not \"exclusive\" indices used for python\n        indexing.  This is useful for plotting the bounding box using\n        Matplotlib.\n        \"\"\"\n\n        return (\n            self.ixmin - 0.5,\n            self.ixmax - 0.5,\n            self.iymin - 0.5,\n            self.iymax - 0.5,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a matplotlib. patches. Patch that represents the base bounding box of the current object.", "response": "def as_patch(self, **kwargs):\n        \"\"\"\n        Return a `matplotlib.patches.Rectangle` that represents the\n        bounding box.\n\n        Parameters\n        ----------\n        kwargs\n            Any keyword arguments accepted by\n            `matplotlib.patches.Patch`.\n\n        Returns\n        -------\n        result : `matplotlib.patches.Rectangle`\n            A matplotlib rectangular patch.\n\n        Examples\n        --------\n        .. plot::\n            :include-source:\n\n            import matplotlib.pyplot as plt\n            from photutils import BoundingBox\n            bbox = BoundingBox(2, 7, 3, 8)\n            fig = plt.figure()\n            ax = fig.add_subplot(1, 1, 1)\n            np.random.seed(12345)\n            ax.imshow(np.random.random((10, 10)), interpolation='nearest',\n                      cmap='viridis')\n            ax.add_patch(bbox.as_patch(facecolor='none', edgecolor='white',\n                         lw=2.))\n        \"\"\"\n\n        from matplotlib.patches import Rectangle\n\n        return Rectangle(xy=(self.extent[0], self.extent[2]),\n                         width=self.shape[1], height=self.shape[0], **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_aperture(self):\n\n        from .rectangle import RectangularAperture\n\n        xpos = (self.extent[1] + self.extent[0]) / 2.\n        ypos = (self.extent[3] + self.extent[2]) / 2.\n        xypos = (xpos, ypos)\n        h, w = self.shape\n\n        return RectangularAperture(xypos, w=w, h=h, theta=0.)", "response": "Return a ~photutils. aperture. RectangularAperture that represents the bounding box that represents the bounding box."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nplotting the bounding box of the current is image.", "response": "def plot(self, origin=(0, 0), ax=None, fill=False, **kwargs):\n        \"\"\"\n        Plot the `BoundingBox` on a matplotlib `~matplotlib.axes.Axes`\n        instance.\n\n        Parameters\n        ----------\n        origin : array_like, optional\n            The ``(x, y)`` position of the origin of the displayed\n            image.\n\n        ax : `matplotlib.axes.Axes` instance, optional\n            If `None`, then the current `~matplotlib.axes.Axes` instance\n            is used.\n\n        fill : bool, optional\n            Set whether to fill the aperture patch.  The default is\n            `False`.\n\n        kwargs\n            Any keyword arguments accepted by `matplotlib.patches.Patch`.\n        \"\"\"\n\n        aper = self.to_aperture()\n        aper.plot(origin=origin, ax=ax, fill=fill, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build_ellipse_model(shape, isolist, fill=0., high_harmonics=False):\n\n    from scipy.interpolate import LSQUnivariateSpline\n\n    # the target grid is spaced in 0.1 pixel intervals so as\n    # to ensure no gaps will result on the output array.\n    finely_spaced_sma = np.arange(isolist[0].sma, isolist[-1].sma, 0.1)\n\n    # interpolate ellipse parameters\n\n    # End points must be discarded, but how many?\n    # This seems to work so far\n    nodes = isolist.sma[2:-2]\n\n    intens_array = LSQUnivariateSpline(\n        isolist.sma, isolist.intens, nodes)(finely_spaced_sma)\n    eps_array = LSQUnivariateSpline(\n        isolist.sma, isolist.eps, nodes)(finely_spaced_sma)\n    pa_array = LSQUnivariateSpline(\n        isolist.sma, isolist.pa, nodes)(finely_spaced_sma)\n    x0_array = LSQUnivariateSpline(\n        isolist.sma, isolist.x0, nodes)(finely_spaced_sma)\n    y0_array = LSQUnivariateSpline(\n        isolist.sma, isolist.y0, nodes)(finely_spaced_sma)\n    grad_array = LSQUnivariateSpline(\n        isolist.sma, isolist.grad, nodes)(finely_spaced_sma)\n    a3_array = LSQUnivariateSpline(\n        isolist.sma, isolist.a3, nodes)(finely_spaced_sma)\n    b3_array = LSQUnivariateSpline(\n        isolist.sma, isolist.b3, nodes)(finely_spaced_sma)\n    a4_array = LSQUnivariateSpline(\n        isolist.sma, isolist.a4, nodes)(finely_spaced_sma)\n    b4_array = LSQUnivariateSpline(\n        isolist.sma, isolist.b4, nodes)(finely_spaced_sma)\n\n    # Return deviations from ellipticity to their original amplitude meaning\n    a3_array = -a3_array * grad_array * finely_spaced_sma\n    b3_array = -b3_array * grad_array * finely_spaced_sma\n    a4_array = -a4_array * grad_array * finely_spaced_sma\n    b4_array = -b4_array * grad_array * finely_spaced_sma\n\n    # correct deviations cased by fluctuations in spline solution\n    eps_array[np.where(eps_array < 0.)] = 0.\n\n    result = np.zeros(shape=shape)\n    weight = np.zeros(shape=shape)\n\n    eps_array[np.where(eps_array < 0.)] = 0.05\n\n    # for each interpolated isophote, generate intensity values on the\n    # output image array\n    # for index in range(len(finely_spaced_sma)):\n    for index in range(1, len(finely_spaced_sma)):\n        sma0 = finely_spaced_sma[index]\n        eps = eps_array[index]\n        pa = pa_array[index]\n        x0 = x0_array[index]\n        y0 = y0_array[index]\n        geometry = EllipseGeometry(x0, y0, sma0, eps, pa)\n\n        intens = intens_array[index]\n\n        # scan angles. Need to go a bit beyond full circle to ensure\n        # full coverage.\n        r = sma0\n        phi = 0.\n        while (phi <= 2*np.pi + geometry._phi_min):\n            # we might want to add the third and fourth harmonics\n            # to the basic isophotal intensity.\n            harm = 0.\n            if high_harmonics:\n                harm = (a3_array[index] * np.sin(3.*phi) +\n                        b3_array[index] * np.cos(3.*phi) +\n                        a4_array[index] * np.sin(4.*phi) +\n                        b4_array[index] * np.cos(4.*phi) / 4.)\n\n            # get image coordinates of (r, phi) pixel\n            x = r * np.cos(phi + pa) + x0\n            y = r * np.sin(phi + pa) + y0\n            i = int(x)\n            j = int(y)\n\n            # if outside image boundaries, ignore.\n            if (i > 0 and i < shape[1] - 1 and j > 0 and j < shape[0] - 1):\n                # get fractional deviations relative to target array\n                fx = x - float(i)\n                fy = y - float(j)\n\n                # add up the isophote contribution to the overlapping pixels\n                result[j, i] += (intens + harm) * (1. - fy) * (1. - fx)\n                result[j, i + 1] += (intens + harm) * (1. - fy) * fx\n                result[j + 1, i] += (intens + harm) * fy * (1. - fx)\n                result[j + 1, i + 1] += (intens + harm) * fy * fx\n\n                # add up the fractional area contribution to the\n                # overlapping pixels\n                weight[j, i] += (1. - fy) * (1. - fx)\n                weight[j, i + 1] += (1. - fy) * fx\n                weight[j + 1, i] += fy * (1. - fx)\n                weight[j + 1, i + 1] += fy * fx\n\n                # step towards next pixel on ellipse\n                phi = max((phi + 0.75 / r), geometry._phi_min)\n                r = geometry.radius(phi)\n\n    # zero weight values must be set to 1.\n    weight[np.where(weight <= 0.)] = 1.\n\n    # normalize\n    result /= weight\n\n    # fill value\n    result[np.where(result == 0.)] = fill\n\n    return result", "response": "Builds an elliptical model from a list of isophotes."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _find_stars(data, kernel, threshold_eff, min_separation=None,\n                mask=None, exclude_border=False):\n    \"\"\"\n    Find stars in an image.\n\n    Parameters\n    ----------\n    data : 2D array_like\n        The 2D array of the image.\n\n    kernel : `_StarFinderKernel`\n        The convolution kernel.\n\n    threshold_eff : float\n        The absolute image value above which to select sources.  This\n        threshold should be the threshold input to the star finder class\n        multiplied by the kernel relerr.\n\n    mask : 2D bool array, optional\n        A boolean mask with the same shape as ``data``, where a `True`\n        value indicates the corresponding element of ``data`` is masked.\n        Masked pixels are ignored when searching for stars.\n\n    exclude_border : bool, optional\n        Set to `True` to exclude sources found within half the size of\n        the convolution kernel from the image borders.  The default is\n        `False`, which is the mode used by IRAF's `DAOFIND`_ and\n        `starfind`_ tasks.\n\n    Returns\n    -------\n    objects : list of `_StarCutout`\n        A list of `_StarCutout` objects containing the image cutout for\n        each source.\n\n    .. _DAOFIND: http://stsdas.stsci.edu/cgi-bin/gethelp.cgi?daofind\n    .. _starfind: http://stsdas.stsci.edu/cgi-bin/gethelp.cgi?starfind\n    \"\"\"\n\n    convolved_data = filter_data(data, kernel.data, mode='constant',\n                                 fill_value=0.0, check_normalization=False)\n\n    # define a local footprint for the peak finder\n    if min_separation is None:   # daofind\n        footprint = kernel.mask.astype(np.bool)\n    else:\n        # define a circular footprint\n        idx = np.arange(-min_separation, min_separation + 1)\n        xx, yy = np.meshgrid(idx, idx)\n        footprint = np.array((xx**2 + yy**2) <= min_separation**2, dtype=int)\n\n    # pad the data and convolved image by the kernel x/y radius to allow\n    # for detections near the edges\n    if not exclude_border:\n        ypad = kernel.yradius\n        xpad = kernel.xradius\n        pad = ((ypad, ypad), (xpad, xpad))\n        # mode must be a string for numpy < 0.11\n        # (see https://github.com/numpy/numpy/issues/7112)\n        mode = str('constant')\n        data = np.pad(data, pad, mode=mode, constant_values=[0.])\n        if mask is not None:\n            mask = np.pad(mask, pad, mode=mode, constant_values=[0.])\n        convolved_data = np.pad(convolved_data, pad, mode=mode,\n                                constant_values=[0.])\n\n    # find local peaks in the convolved data\n    with warnings.catch_warnings():\n        # suppress any NoDetectionsWarning from find_peaks\n        warnings.filterwarnings('ignore', category=NoDetectionsWarning)\n        tbl = find_peaks(convolved_data, threshold_eff, footprint=footprint,\n                         mask=mask)\n\n    if tbl is None:\n        return None\n\n    coords = np.transpose([tbl['y_peak'], tbl['x_peak']])\n\n    star_cutouts = []\n    for (ypeak, xpeak) in coords:\n        # now extract the object from the data, centered on the peak\n        # pixel in the convolved image, with the same size as the kernel\n        x0 = xpeak - kernel.xradius\n        x1 = xpeak + kernel.xradius + 1\n        y0 = ypeak - kernel.yradius\n        y1 = ypeak + kernel.yradius + 1\n\n        if x0 < 0 or x1 > data.shape[1]:\n            continue    # pragma: no cover\n        if y0 < 0 or y1 > data.shape[0]:\n            continue    # pragma: no cover\n\n        slices = (slice(y0, y1), slice(x0, x1))\n        data_cutout = data[slices]\n        convdata_cutout = convolved_data[slices]\n\n        # correct pixel values for the previous image padding\n        if not exclude_border:\n            x0 -= kernel.xradius\n            x1 -= kernel.xradius\n            y0 -= kernel.yradius\n            y1 -= kernel.yradius\n            xpeak -= kernel.xradius\n            ypeak -= kernel.yradius\n            slices = (slice(y0, y1), slice(x0, x1))\n\n        star_cutouts.append(_StarCutout(data_cutout, convdata_cutout, slices,\n                                        xpeak, ypeak, kernel, threshold_eff))\n\n    return star_cutouts", "response": "Find stars in an image."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef daofind_marginal_fit(self, axis=0):\n\n        # define triangular weighting functions along each axis, peaked\n        # in the middle and equal to one at the edge\n        x = self.xcenter - np.abs(np.arange(self.nx) - self.xcenter) + 1\n        y = self.ycenter - np.abs(np.arange(self.ny) - self.ycenter) + 1\n        xwt, ywt = np.meshgrid(x, y)\n\n        if axis == 0:    # marginal distributions along x axis\n            wt = xwt[0]    # 1D\n            wts = ywt    # 2D\n            size = self.nx\n            center = self.xcenter\n            sigma = self.kernel.xsigma\n            dxx = center - np.arange(size)\n        elif axis == 1:    # marginal distributions along y axis\n            wt = np.transpose(ywt)[0]    # 1D\n            wts = xwt    # 2D\n            size = self.ny\n            center = self.ycenter\n            sigma = self.kernel.ysigma\n            dxx = np.arange(size) - center\n\n        # compute marginal sums for given axis\n        wt_sum = np.sum(wt)\n        dx = center - np.arange(size)\n\n        # weighted marginal sums\n        kern_sum_1d = np.sum(self.kernel.gaussian_kernel_unmasked * wts,\n                             axis=axis)\n        kern_sum = np.sum(kern_sum_1d * wt)\n        kern2_sum = np.sum(kern_sum_1d**2 * wt)\n\n        dkern_dx = kern_sum_1d * dx\n        dkern_dx_sum = np.sum(dkern_dx * wt)\n        dkern_dx2_sum = np.sum(dkern_dx**2 * wt)\n        kern_dkern_dx_sum = np.sum(kern_sum_1d * dkern_dx * wt)\n\n        data_sum_1d = np.sum(self.data * wts, axis=axis)\n        data_sum = np.sum(data_sum_1d * wt)\n        data_kern_sum = np.sum(data_sum_1d * kern_sum_1d * wt)\n        data_dkern_dx_sum = np.sum(data_sum_1d * dkern_dx * wt)\n        data_dx_sum = np.sum(data_sum_1d * dxx * wt)\n\n        # perform linear least-squares fit (where data = sky + hx*kernel)\n        # to find the amplitude (hx)\n        # reject the star if the fit amplitude is not positive\n        hx_numer = data_kern_sum - (data_sum * kern_sum) / wt_sum\n        if hx_numer <= 0.:\n            return np.nan, np.nan\n\n        hx_denom = kern2_sum - (kern_sum**2 / wt_sum)\n        if hx_denom <= 0.:\n            return np.nan, np.nan\n\n        # compute fit amplitude\n        hx = hx_numer / hx_denom\n        # sky = (data_sum - (hx * kern_sum)) / wt_sum\n\n        # compute centroid shift\n        dx = ((kern_dkern_dx_sum -\n               (data_dkern_dx_sum - dkern_dx_sum*data_sum)) /\n              (hx * dkern_dx2_sum / sigma**2))\n\n        hsize = size / 2.\n        if abs(dx) > hsize:\n            if data_sum == 0.:\n                dx = 0.0\n            else:\n                dx = data_dx_sum / data_sum\n                if abs(dx) > hsize:\n                    dx = 0.0\n\n        return dx, hx", "response": "Fit 1D Gaussians defined from the marginal x and y distributions of the original image to the marginal y of the original image."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef roundness2(self):\n\n        if np.isnan(self.hx) or np.isnan(self.hy):\n            return np.nan\n        else:\n            return 2.0 * (self.hx - self.hy) / (self.hx + self.hy)", "response": "The star roundness parameter represents the ratio of difference in the height of the best fitting Gaussian function in x and y."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_stars(self, data, mask=None):\n\n        star_cutouts = _find_stars(data, self.kernel, self.threshold_eff,\n                                   mask=mask,\n                                   exclude_border=self.exclude_border)\n\n        if star_cutouts is None:\n            warnings.warn('No sources were found.', NoDetectionsWarning)\n            return None\n\n        self._star_cutouts = star_cutouts\n\n        star_props = []\n        for star_cutout in star_cutouts:\n            props = _DAOFind_Properties(star_cutout, self.kernel, self.sky)\n\n            if np.isnan(props.dx_hx).any() or np.isnan(props.dy_hy).any():\n                continue\n\n            if (props.sharpness <= self.sharplo or\n                    props.sharpness >= self.sharphi):\n                continue\n\n            if (props.roundness1 <= self.roundlo or\n                    props.roundness1 >= self.roundhi):\n                continue\n\n            if (props.roundness2 <= self.roundlo or\n                    props.roundness2 >= self.roundhi):\n                continue\n\n            if self.peakmax is not None and props.peak >= self.peakmax:\n                continue\n\n            star_props.append(props)\n\n        nstars = len(star_props)\n        if nstars == 0:\n            warnings.warn('Sources were found, but none pass the sharpness '\n                          'and roundness criteria.', NoDetectionsWarning)\n            return None\n\n        if self.brightest is not None:\n            fluxes = [props.flux for props in star_props]\n            idx = sorted(np.argsort(fluxes)[-self.brightest:].tolist())\n            star_props = [star_props[k] for k in idx]\n            nstars = len(star_props)\n\n        table = Table()\n        table['id'] = np.arange(nstars) + 1\n        columns = ('xcentroid', 'ycentroid', 'sharpness', 'roundness1',\n                   'roundness2', 'npix', 'sky', 'peak', 'flux', 'mag')\n        for column in columns:\n            table[column] = [getattr(props, column) for props in star_props]\n\n        return table", "response": "Find stars in an astronomical image."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_stars(self, data, mask=None):\n\n        star_cutouts = _find_stars(data, self.kernel, self.threshold,\n                                   min_separation=self.min_separation,\n                                   mask=mask,\n                                   exclude_border=self.exclude_border)\n\n        if star_cutouts is None:\n            warnings.warn('No sources were found.', NoDetectionsWarning)\n            return None\n\n        self._star_cutouts = star_cutouts\n\n        star_props = []\n        for star_cutout in star_cutouts:\n            props = _IRAFStarFind_Properties(star_cutout, self.kernel,\n                                             self.sky)\n\n            # star cutout needs more than one non-zero value\n            if np.count_nonzero(props.data) <= 1:\n                continue\n\n            if (props.sharpness <= self.sharplo or\n                    props.sharpness >= self.sharphi):\n                continue\n\n            if (props.roundness <= self.roundlo or\n                    props.roundness >= self.roundhi):\n                continue\n\n            if self.peakmax is not None and props.peak >= self.peakmax:\n                continue\n\n            star_props.append(props)\n\n        nstars = len(star_props)\n        if nstars == 0:\n            warnings.warn('Sources were found, but none pass the sharpness '\n                          'and roundness criteria.', NoDetectionsWarning)\n            return None\n\n        if self.brightest is not None:\n            fluxes = [props.flux for props in star_props]\n            idx = sorted(np.argsort(fluxes)[-self.brightest:].tolist())\n            star_props = [star_props[k] for k in idx]\n            nstars = len(star_props)\n\n        table = Table()\n        table['id'] = np.arange(nstars) + 1\n        columns = ('xcentroid', 'ycentroid', 'fwhm', 'sharpness', 'roundness',\n                   'pa', 'npix', 'sky', 'peak', 'flux', 'mag')\n        for column in columns:\n            table[column] = [getattr(props, column) for props in star_props]\n\n        return table", "response": "Find stars in an astronomical image."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef detect_sources(data, threshold, npixels, filter_kernel=None,\n                   connectivity=8, mask=None):\n    \"\"\"\n    Detect sources above a specified threshold value in an image and\n    return a `~photutils.segmentation.SegmentationImage` object.\n\n    Detected sources must have ``npixels`` connected pixels that are\n    each greater than the ``threshold`` value.  If the filtering option\n    is used, then the ``threshold`` is applied to the filtered image.\n    The input ``mask`` can be used to mask pixels in the input data.\n    Masked pixels will not be included in any source.\n\n    This function does not deblend overlapping sources.  First use this\n    function to detect sources followed by\n    :func:`~photutils.segmentation.deblend_sources` to deblend sources.\n\n    Parameters\n    ----------\n    data : array_like\n        The 2D array of the image.\n\n    threshold : float or array-like\n        The data value or pixel-wise data values to be used for the\n        detection threshold.  A 2D ``threshold`` must have the same\n        shape as ``data``.  See `~photutils.detection.detect_threshold`\n        for one way to create a ``threshold`` image.\n\n    npixels : int\n        The number of connected pixels, each greater than ``threshold``,\n        that an object must have to be detected.  ``npixels`` must be a\n        positive integer.\n\n    filter_kernel : array-like (2D) or `~astropy.convolution.Kernel2D`, optional\n        The 2D array of the kernel used to filter the image before\n        thresholding.  Filtering the image will smooth the noise and\n        maximize detectability of objects with a shape similar to the\n        kernel.\n\n    connectivity : {4, 8}, optional\n        The type of pixel connectivity used in determining how pixels\n        are grouped into a detected source.  The options are 4 or 8\n        (default).  4-connected pixels touch along their edges.\n        8-connected pixels touch along their edges or corners.  For\n        reference, SExtractor uses 8-connected pixels.\n\n    mask : array_like (bool)\n        A boolean mask, with the same shape as the input ``data``, where\n        `True` values indicate masked pixels.  Masked pixels will not be\n        included in any source.\n\n    Returns\n    -------\n    segment_image : `~photutils.segmentation.SegmentationImage` or `None`\n        A 2D segmentation image, with the same shape as ``data``, where\n        sources are marked by different positive integer values.  A\n        value of zero is reserved for the background.  If no sources\n        are found then `None` is returned.\n\n    See Also\n    --------\n    :func:`photutils.detection.detect_threshold`,\n    :class:`photutils.segmentation.SegmentationImage`,\n    :func:`photutils.segmentation.source_properties`\n    :func:`photutils.segmentation.deblend_sources`\n\n    Examples\n    --------\n\n    .. plot::\n        :include-source:\n\n        # make a table of Gaussian sources\n        from astropy.table import Table\n        table = Table()\n        table['amplitude'] = [50, 70, 150, 210]\n        table['x_mean'] = [160, 25, 150, 90]\n        table['y_mean'] = [70, 40, 25, 60]\n        table['x_stddev'] = [15.2, 5.1, 3., 8.1]\n        table['y_stddev'] = [2.6, 2.5, 3., 4.7]\n        table['theta'] = np.array([145., 20., 0., 60.]) * np.pi / 180.\n\n        # make an image of the sources with Gaussian noise\n        from photutils.datasets import make_gaussian_sources_image\n        from photutils.datasets import make_noise_image\n        shape = (100, 200)\n        sources = make_gaussian_sources_image(shape, table)\n        noise = make_noise_image(shape, type='gaussian', mean=0.,\n                                 stddev=5., random_state=12345)\n        image = sources + noise\n\n        # detect the sources\n        from photutils import detect_threshold, detect_sources\n        threshold = detect_threshold(image, snr=3)\n        from astropy.convolution import Gaussian2DKernel\n        sigma = 3.0 / (2.0 * np.sqrt(2.0 * np.log(2.0)))   # FWHM = 3\n        kernel = Gaussian2DKernel(sigma, x_size=3, y_size=3)\n        kernel.normalize()\n        segm = detect_sources(image, threshold, npixels=5,\n                              filter_kernel=kernel)\n\n        # plot the image and the segmentation image\n        import matplotlib.pyplot as plt\n        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 8))\n        ax1.imshow(image, origin='lower', interpolation='nearest')\n        ax2.imshow(segm.data, origin='lower', interpolation='nearest')\n    \"\"\"\n\n    from scipy import ndimage\n\n    if (npixels <= 0) or (int(npixels) != npixels):\n        raise ValueError('npixels must be a positive integer, got '\n                         '\"{0}\"'.format(npixels))\n\n    image = (filter_data(data, filter_kernel, mode='constant', fill_value=0.0,\n                         check_normalization=True) > threshold)\n\n    if mask is not None:\n        if mask.shape != image.shape:\n            raise ValueError('mask must have the same shape as the input '\n                             'image.')\n        image &= ~mask\n\n    if connectivity == 4:\n        selem = ndimage.generate_binary_structure(2, 1)\n    elif connectivity == 8:\n        selem = ndimage.generate_binary_structure(2, 2)\n    else:\n        raise ValueError('Invalid connectivity={0}.  '\n                         'Options are 4 or 8'.format(connectivity))\n\n    segm_img, nobj = ndimage.label(image, structure=selem)\n\n    # remove objects with less than npixels\n    # NOTE:  for typical data, making the cutout images is ~10x faster\n    # than using segm_img directly\n    segm_slices = ndimage.find_objects(segm_img)\n    for i, slices in enumerate(segm_slices):\n        cutout = segm_img[slices]\n        segment_mask = (cutout == (i+1))\n        if np.count_nonzero(segment_mask) < npixels:\n            cutout[segment_mask] = 0\n\n    # now relabel to make consecutive label indices\n    segm_img, nobj = ndimage.label(segm_img, structure=selem)\n\n    if nobj == 0:\n        warnings.warn('No sources were found.', NoDetectionsWarning)\n        return None\n    else:\n        return SegmentationImage(segm_img)", "response": "Detect sources above a specified threshold value in an image and return a segmentation image object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmake a source mask using source segmentation and binary dilation. Parameters ---------- data : array_like The 2D array of the image. snr : float The signal-to-noise ratio per pixel above the ``background`` for which to consider a pixel as possibly being part of a source. npixels : int The number of connected pixels, each greater than ``threshold``, that an object must have to be detected. ``npixels`` must be a positive integer. mask : array_like, bool, optional A boolean mask with the same shape as ``data``, where a `True` value indicates the corresponding element of ``data`` is masked. Masked pixels are ignored when computing the image background statistics. mask_value : float, optional An image data value (e.g., ``0.0``) that is ignored when computing the image background statistics. ``mask_value`` will be ignored if ``mask`` is input. filter_fwhm : float, optional The full-width at half-maximum (FWHM) of the Gaussian kernel to filter the image before thresholding. ``filter_fwhm`` and ``filter_size`` are ignored if ``filter_kernel`` is defined. filter_size : float, optional The size of the square Gaussian kernel image. Used only if ``filter_fwhm`` is defined. ``filter_fwhm`` and ``filter_size`` are ignored if ``filter_kernel`` is defined. filter_kernel : array-like (2D) or `~astropy.convolution.Kernel2D`, optional The 2D array of the kernel used to filter the image before thresholding. Filtering the image will smooth the noise and maximize detectability of objects with a shape similar to the kernel. ``filter_kernel`` overrides ``filter_fwhm`` and ``filter_size``. sigclip_sigma : float, optional The number of standard deviations to use as the clipping limit when calculating the image background statistics. sigclip_iters : int, optional The number of iterations to perform sigma clipping, or `None` to clip until convergence is achieved (i.e., continue until the last iteration clips nothing) when calculating the image background statistics. dilate_size : int, optional The size of the square array used to dilate the segmentation image. Returns ------- mask : 2D `~numpy.ndarray`, bool A 2D boolean image containing the source mask.", "response": "def make_source_mask(data, snr, npixels, mask=None, mask_value=None,\n                     filter_fwhm=None, filter_size=3, filter_kernel=None,\n                     sigclip_sigma=3.0, sigclip_iters=5, dilate_size=11):\n    \"\"\"\n    Make a source mask using source segmentation and binary dilation.\n\n    Parameters\n    ----------\n    data : array_like\n        The 2D array of the image.\n\n    snr : float\n        The signal-to-noise ratio per pixel above the ``background`` for\n        which to consider a pixel as possibly being part of a source.\n\n    npixels : int\n        The number of connected pixels, each greater than ``threshold``,\n        that an object must have to be detected.  ``npixels`` must be a\n        positive integer.\n\n    mask : array_like, bool, optional\n        A boolean mask with the same shape as ``data``, where a `True`\n        value indicates the corresponding element of ``data`` is masked.\n        Masked pixels are ignored when computing the image background\n        statistics.\n\n    mask_value : float, optional\n        An image data value (e.g., ``0.0``) that is ignored when\n        computing the image background statistics.  ``mask_value`` will\n        be ignored if ``mask`` is input.\n\n    filter_fwhm : float, optional\n        The full-width at half-maximum (FWHM) of the Gaussian kernel to\n        filter the image before thresholding.  ``filter_fwhm`` and\n        ``filter_size`` are ignored if ``filter_kernel`` is defined.\n\n    filter_size : float, optional\n        The size of the square Gaussian kernel image.  Used only if\n        ``filter_fwhm`` is defined.  ``filter_fwhm`` and ``filter_size``\n        are ignored if ``filter_kernel`` is defined.\n\n    filter_kernel : array-like (2D) or `~astropy.convolution.Kernel2D`, optional\n        The 2D array of the kernel used to filter the image before\n        thresholding.  Filtering the image will smooth the noise and\n        maximize detectability of objects with a shape similar to the\n        kernel.  ``filter_kernel`` overrides ``filter_fwhm`` and\n        ``filter_size``.\n\n    sigclip_sigma : float, optional\n        The number of standard deviations to use as the clipping limit\n        when calculating the image background statistics.\n\n    sigclip_iters : int, optional\n       The number of iterations to perform sigma clipping, or `None` to\n       clip until convergence is achieved (i.e., continue until the last\n       iteration clips nothing) when calculating the image background\n       statistics.\n\n    dilate_size : int, optional\n        The size of the square array used to dilate the segmentation\n        image.\n\n    Returns\n    -------\n    mask : 2D `~numpy.ndarray`, bool\n        A 2D boolean image containing the source mask.\n    \"\"\"\n\n    from scipy import ndimage\n\n    threshold = detect_threshold(data, snr, background=None, error=None,\n                                 mask=mask, mask_value=None,\n                                 sigclip_sigma=sigclip_sigma,\n                                 sigclip_iters=sigclip_iters)\n\n    kernel = None\n    if filter_kernel is not None:\n        kernel = filter_kernel\n    if filter_fwhm is not None:\n        sigma = filter_fwhm * gaussian_fwhm_to_sigma\n        kernel = Gaussian2DKernel(sigma, x_size=filter_size,\n                                  y_size=filter_size)\n    if kernel is not None:\n        kernel.normalize()\n\n    segm = detect_sources(data, threshold, npixels, filter_kernel=kernel)\n\n    selem = np.ones((dilate_size, dilate_size))\n    return ndimage.binary_dilation(segm.data.astype(np.bool), selem)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef data(self):\n\n        cutout = np.copy(self._segment_img[self.slices])\n        cutout[cutout != self.label] = 0\n\n        return cutout", "response": "A 2D cutout image of the segment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a 2D array of the segment image cutout from the input data.", "response": "def make_cutout(self, data, masked_array=False):\n        \"\"\"\n        Create a (masked) cutout array from the input ``data`` using the\n        minimal bounding box of the segment (labeled region).\n\n        If ``masked_array`` is `False` (default), then the returned\n        cutout array is simply a `~numpy.ndarray`.  The returned cutout\n        is a view (not a copy) of the input ``data``.  No pixels are\n        altered (e.g. set to zero) within the bounding box.\n\n        If ``masked_array` is `True`, then the returned cutout array is\n        a `~numpy.ma.MaskedArray`, where the mask is `True` for pixels\n        outside of the segment (labeled region).  The data part of the\n        masked array is a view (not a copy) of the input ``data``.\n\n        Parameters\n        ----------\n        data : 2D array-like\n            The data array from which to create the masked cutout array.\n            ``data`` must have the same shape as the segmentation image.\n\n        masked_array : bool, optional\n            If `True` then a `~numpy.ma.MaskedArray` will be created\n            where the mask is `True` for pixels outside of the segment\n            (labeled region).  If `False`, then a `~numpy.ndarray` will\n            be generated.\n\n        Returns\n        -------\n        result : 2D `~numpy.ndarray` or `~numpy.ma.MaskedArray`\n            The 2D cutout array.\n        \"\"\"\n\n        data = np.asanyarray(data)\n        if data.shape != self._segment_img.shape:\n            raise ValueError('data must have the same shape as the '\n                             'segmentation image.')\n\n        if masked_array:\n            mask = (self._segment_img[self.slices] != self.label)\n            return np.ma.masked_array(data[self.slices], mask=mask)\n        else:\n            return data[self.slices]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nresets all lazy properties.", "response": "def _reset_lazy_properties(self):\n        \"\"\"Reset all lazy properties.\"\"\"\n\n        for key, value in self.__class__.__dict__.items():\n            if isinstance(value, lazyproperty):\n                self.__dict__.pop(key, None)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef segments(self):\n\n        segments = []\n        for label, slc in zip(self.labels, self.slices):\n            segments.append(Segment(self.data, label, slc,\n                                    self.get_area(label)))\n        return segments", "response": "A list of Segment objects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the index of the input label in the array.", "response": "def get_index(self, label):\n        \"\"\"\n        Find the index of the input ``label``.\n\n        Parameters\n        ----------\n        labels : int\n            The label numbers to find.\n\n        Returns\n        -------\n        index : int\n            The array index.\n\n        Raises\n        ------\n        ValueError\n            If ``label`` is invalid.\n        \"\"\"\n\n        self.check_labels(label)\n        return np.searchsorted(self.labels, label)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_indices(self, labels):\n\n        self.check_labels(labels)\n        return np.searchsorted(self.labels, labels)", "response": "Returns the indices of the input labels."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef slices(self):\n\n        from scipy.ndimage import find_objects\n\n        return [slc for slc in find_objects(self._data) if slc is not None]", "response": "A list of tuples where each tuple contains two slices representing the minimal box that contains the labeled region."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the areas of the labeled regions.", "response": "def get_areas(self, labels):\n        \"\"\"\n        The areas (in pixel**2) of the regions for the input labels.\n\n        Parameters\n        ----------\n        labels : int, 1D array-like (int)\n            The label(s) for which to return areas.  Label must be\n            non-zero.\n\n        Returns\n        -------\n        areas : `~numpy.ndarray`\n            The areas of the labeled regions.\n        \"\"\"\n\n        idx = self.get_indices(labels)\n        return self.areas[idx]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_consecutive(self):\n\n        if (self.labels[-1] - self.labels[0] + 1) == self.nlabels:\n            return True\n        else:\n            return False", "response": "Determines whether or not the segmentation contains consecutive segmented data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck that the input label numbers within the segmentation image are valid.", "response": "def check_labels(self, labels):\n        \"\"\"\n        Check that the input label(s) are valid label numbers within the\n        segmentation image.\n\n        Parameters\n        ----------\n        labels : int, 1D array-like (int)\n            The label(s) to check.\n\n        Raises\n        ------\n        ValueError\n            If any input ``labels`` are invalid.\n        \"\"\"\n\n        labels = np.atleast_1d(labels)\n        bad_labels = set()\n\n        # check for positive label numbers\n        idx = np.where(labels <= 0)[0]\n        if len(idx) > 0:\n            bad_labels.update(labels[idx])\n\n        # check if label is in the segmentation image\n        bad_labels.update(np.setdiff1d(labels, self.labels))\n\n        if len(bad_labels) > 0:\n            if len(bad_labels) == 1:\n                raise ValueError('label {} is invalid'.format(bad_labels))\n            else:\n                raise ValueError('labels {} are invalid'.format(bad_labels))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cmap(self, background_color='#000000', random_state=None):\n\n        return self.make_cmap(background_color=background_color,\n                              random_state=random_state)", "response": "Returns a matplotlib colormap consisting of ( random ) muted\n            colors."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a matplotlib colormap consisting of random muted colors.", "response": "def make_cmap(self, background_color='#000000', random_state=None):\n        \"\"\"\n        Define a matplotlib colormap consisting of (random) muted\n        colors.\n\n        This is very useful for plotting the segmentation image.\n\n        Parameters\n        ----------\n        background_color : str or `None`, optional\n            A hex string in the \"#rrggbb\" format defining the first\n            color in the colormap.  This color will be used as the\n            background color (label = 0) when plotting the segmentation\n            image.  The default is black ('#000000').\n\n        random_state : int or `~numpy.random.RandomState`, optional\n            The pseudo-random number generator state used for random\n            sampling.  Separate function calls with the same\n            ``random_state`` will generate the same colormap.\n\n        Returns\n        -------\n        cmap : `matplotlib.colors.ListedColormap`\n            The matplotlib colormap.\n        \"\"\"\n\n        from matplotlib import colors\n\n        cmap = make_random_cmap(self.max_label + 1, random_state=random_state)\n\n        if background_color is not None:\n            cmap.colors[0] = colors.hex2color(background_color)\n\n        return cmap"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreassign a label number to a new number.", "response": "def reassign_label(self, label, new_label, relabel=False):\n        \"\"\"\n        Reassign a label number to a new number.\n\n        If ``new_label`` is already present in the segmentation image,\n        then it will be combined with the input ``label`` number.\n\n        Parameters\n        ----------\n        labels : int\n            The label number to reassign.\n\n        new_label : int\n            The newly assigned label number.\n\n        relabel : bool, optional\n            If `True`, then the segmentation image will be relabeled\n            such that the labels are in consecutive order starting from\n            1.\n\n        Examples\n        --------\n        >>> from photutils import SegmentationImage\n        >>> segm = SegmentationImage([[1, 1, 0, 0, 4, 4],\n        ...                           [0, 0, 0, 0, 0, 4],\n        ...                           [0, 0, 3, 3, 0, 0],\n        ...                           [7, 0, 0, 0, 0, 5],\n        ...                           [7, 7, 0, 5, 5, 5],\n        ...                           [7, 7, 0, 0, 5, 5]])\n        >>> segm.reassign_label(label=1, new_label=2)\n        >>> segm.data\n        array([[2, 2, 0, 0, 4, 4],\n               [0, 0, 0, 0, 0, 4],\n               [0, 0, 3, 3, 0, 0],\n               [7, 0, 0, 0, 0, 5],\n               [7, 7, 0, 5, 5, 5],\n               [7, 7, 0, 0, 5, 5]])\n\n        >>> segm = SegmentationImage([[1, 1, 0, 0, 4, 4],\n        ...                           [0, 0, 0, 0, 0, 4],\n        ...                           [0, 0, 3, 3, 0, 0],\n        ...                           [7, 0, 0, 0, 0, 5],\n        ...                           [7, 7, 0, 5, 5, 5],\n        ...                           [7, 7, 0, 0, 5, 5]])\n        >>> segm.reassign_label(label=1, new_label=4)\n        >>> segm.data\n        array([[4, 4, 0, 0, 4, 4],\n               [0, 0, 0, 0, 0, 4],\n               [0, 0, 3, 3, 0, 0],\n               [7, 0, 0, 0, 0, 5],\n               [7, 7, 0, 5, 5, 5],\n               [7, 7, 0, 0, 5, 5]])\n\n        >>> segm = SegmentationImage([[1, 1, 0, 0, 4, 4],\n        ...                           [0, 0, 0, 0, 0, 4],\n        ...                           [0, 0, 3, 3, 0, 0],\n        ...                           [7, 0, 0, 0, 0, 5],\n        ...                           [7, 7, 0, 5, 5, 5],\n        ...                           [7, 7, 0, 0, 5, 5]])\n        >>> segm.reassign_label(label=1, new_label=4, relabel=True)\n        >>> segm.data\n        array([[2, 2, 0, 0, 2, 2],\n               [0, 0, 0, 0, 0, 2],\n               [0, 0, 1, 1, 0, 0],\n               [4, 0, 0, 0, 0, 3],\n               [4, 4, 0, 3, 3, 3],\n               [4, 4, 0, 0, 3, 3]])\n        \"\"\"\n\n        self.reassign_labels(label, new_label, relabel=relabel)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreassigns one or more label numbers to a new label number.", "response": "def reassign_labels(self, labels, new_label, relabel=False):\n        \"\"\"\n        Reassign one or more label numbers.\n\n        Multiple input ``labels`` will all be reassigned to the same\n        ``new_label`` number.  If ``new_label`` is already present in\n        the segmentation image, then it will be combined with the input\n        ``labels``.\n\n        Parameters\n        ----------\n        labels : int, array-like (1D, int)\n            The label numbers(s) to reassign.\n\n        new_label : int\n            The reassigned label number.\n\n        relabel : bool, optional\n            If `True`, then the segmentation image will be relabeled\n            such that the labels are in consecutive order starting from\n            1.\n\n        Examples\n        --------\n        >>> from photutils import SegmentationImage\n        >>> segm = SegmentationImage([[1, 1, 0, 0, 4, 4],\n        ...                           [0, 0, 0, 0, 0, 4],\n        ...                           [0, 0, 3, 3, 0, 0],\n        ...                           [7, 0, 0, 0, 0, 5],\n        ...                           [7, 7, 0, 5, 5, 5],\n        ...                           [7, 7, 0, 0, 5, 5]])\n        >>> segm.reassign_labels(labels=[1, 7], new_label=2)\n        >>> segm.data\n        array([[2, 2, 0, 0, 4, 4],\n               [0, 0, 0, 0, 0, 4],\n               [0, 0, 3, 3, 0, 0],\n               [2, 0, 0, 0, 0, 5],\n               [2, 2, 0, 5, 5, 5],\n               [2, 2, 0, 0, 5, 5]])\n\n        >>> segm = SegmentationImage([[1, 1, 0, 0, 4, 4],\n        ...                           [0, 0, 0, 0, 0, 4],\n        ...                           [0, 0, 3, 3, 0, 0],\n        ...                           [7, 0, 0, 0, 0, 5],\n        ...                           [7, 7, 0, 5, 5, 5],\n        ...                           [7, 7, 0, 0, 5, 5]])\n        >>> segm.reassign_labels(labels=[1, 7], new_label=4)\n        >>> segm.data\n        array([[4, 4, 0, 0, 4, 4],\n               [0, 0, 0, 0, 0, 4],\n               [0, 0, 3, 3, 0, 0],\n               [4, 0, 0, 0, 0, 5],\n               [4, 4, 0, 5, 5, 5],\n               [4, 4, 0, 0, 5, 5]])\n\n        >>> segm = SegmentationImage([[1, 1, 0, 0, 4, 4],\n        ...                           [0, 0, 0, 0, 0, 4],\n        ...                           [0, 0, 3, 3, 0, 0],\n        ...                           [7, 0, 0, 0, 0, 5],\n        ...                           [7, 7, 0, 5, 5, 5],\n        ...                           [7, 7, 0, 0, 5, 5]])\n        >>> segm.reassign_labels(labels=[1, 7], new_label=2, relabel=True)\n        >>> segm.data\n        array([[1, 1, 0, 0, 3, 3],\n               [0, 0, 0, 0, 0, 3],\n               [0, 0, 2, 2, 0, 0],\n               [1, 0, 0, 0, 0, 4],\n               [1, 1, 0, 4, 4, 4],\n               [1, 1, 0, 0, 4, 4]])\n        \"\"\"\n\n        self.check_labels(labels)\n\n        labels = np.atleast_1d(labels)\n        if len(labels) == 0:\n            return\n\n        idx = np.zeros(self.max_label + 1, dtype=int)\n        idx[self.labels] = self.labels\n        idx[labels] = new_label\n\n        # calling the data setter resets all cached properties\n        self.data = idx[self.data]\n\n        if relabel:\n            self.relabel_consecutive()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreassign the label numbers consecutively such that there are no - duplicate entries in the image.", "response": "def relabel_consecutive(self, start_label=1):\n        \"\"\"\n        Reassign the label numbers consecutively, such that there are no\n        missing label numbers.\n\n        Parameters\n        ----------\n        start_label : int, optional\n            The starting label number, which should be a positive\n            integer.  The default is 1.\n\n        Examples\n        --------\n        >>> from photutils import SegmentationImage\n        >>> segm = SegmentationImage([[1, 1, 0, 0, 4, 4],\n        ...                           [0, 0, 0, 0, 0, 4],\n        ...                           [0, 0, 3, 3, 0, 0],\n        ...                           [7, 0, 0, 0, 0, 5],\n        ...                           [7, 7, 0, 5, 5, 5],\n        ...                           [7, 7, 0, 0, 5, 5]])\n        >>> segm.relabel_consecutive()\n        >>> segm.data\n        array([[1, 1, 0, 0, 3, 3],\n               [0, 0, 0, 0, 0, 3],\n               [0, 0, 2, 2, 0, 0],\n               [5, 0, 0, 0, 0, 4],\n               [5, 5, 0, 4, 4, 4],\n               [5, 5, 0, 0, 4, 4]])\n        \"\"\"\n\n        if start_label <= 0:\n            raise ValueError('start_label must be > 0.')\n\n        if self.is_consecutive and (self.labels[0] == start_label):\n            return\n\n        new_labels = np.zeros(self.max_label + 1, dtype=np.int)\n        new_labels[self.labels] = np.arange(self.nlabels) + start_label\n        self.data = new_labels[self.data]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef keep_label(self, label, relabel=False):\n\n        self.keep_labels(label, relabel=relabel)", "response": "Keep only the specified label."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nkeep only the specified labels.", "response": "def keep_labels(self, labels, relabel=False):\n        \"\"\"\n        Keep only the specified labels.\n\n        Parameters\n        ----------\n        labels : int, array-like (1D, int)\n            The label number(s) to keep.\n\n        relabel : bool, optional\n            If `True`, then the segmentation image will be relabeled\n            such that the labels are in consecutive order starting from\n            1.\n\n        Examples\n        --------\n        >>> from photutils import SegmentationImage\n        >>> segm = SegmentationImage([[1, 1, 0, 0, 4, 4],\n        ...                           [0, 0, 0, 0, 0, 4],\n        ...                           [0, 0, 3, 3, 0, 0],\n        ...                           [7, 0, 0, 0, 0, 5],\n        ...                           [7, 7, 0, 5, 5, 5],\n        ...                           [7, 7, 0, 0, 5, 5]])\n        >>> segm.keep_labels(labels=[5, 3])\n        >>> segm.data\n        array([[0, 0, 0, 0, 0, 0],\n               [0, 0, 0, 0, 0, 0],\n               [0, 0, 3, 3, 0, 0],\n               [0, 0, 0, 0, 0, 5],\n               [0, 0, 0, 5, 5, 5],\n               [0, 0, 0, 0, 5, 5]])\n\n        >>> segm = SegmentationImage([[1, 1, 0, 0, 4, 4],\n        ...                           [0, 0, 0, 0, 0, 4],\n        ...                           [0, 0, 3, 3, 0, 0],\n        ...                           [7, 0, 0, 0, 0, 5],\n        ...                           [7, 7, 0, 5, 5, 5],\n        ...                           [7, 7, 0, 0, 5, 5]])\n        >>> segm.keep_labels(labels=[5, 3], relabel=True)\n        >>> segm.data\n        array([[0, 0, 0, 0, 0, 0],\n               [0, 0, 0, 0, 0, 0],\n               [0, 0, 1, 1, 0, 0],\n               [0, 0, 0, 0, 0, 2],\n               [0, 0, 0, 2, 2, 2],\n               [0, 0, 0, 0, 2, 2]])\n        \"\"\"\n\n        self.check_labels(labels)\n\n        labels = np.atleast_1d(labels)\n        labels_tmp = list(set(self.labels) - set(labels))\n        self.remove_labels(labels_tmp, relabel=relabel)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_label(self, label, relabel=False):\n\n        self.remove_labels(label, relabel=relabel)", "response": "This method removes the label from the segment image."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove_labels(self, labels, relabel=False):\n\n        self.check_labels(labels)\n\n        self.reassign_label(labels, new_label=0)\n        if relabel:\n            self.relabel_consecutive()", "response": "Remove one or more labels from the segment image."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_border_labels(self, border_width, partial_overlap=True,\n                             relabel=False):\n        \"\"\"\n        Remove labeled segments near the image border.\n\n        Labels within the defined border region will be removed.\n\n        Parameters\n        ----------\n        border_width : int\n            The width of the border region in pixels.\n\n        partial_overlap : bool, optional\n            If this is set to `True` (the default), a segment that\n            partially extends into the border region will be removed.\n            Segments that are completely within the border region are\n            always removed.\n\n        relabel : bool, optional\n            If `True`, then the segmentation image will be relabeled\n            such that the labels are in consecutive order starting from\n            1.\n\n        Examples\n        --------\n        >>> from photutils import SegmentationImage\n        >>> segm = SegmentationImage([[1, 1, 0, 0, 4, 4],\n        ...                           [0, 0, 0, 0, 0, 4],\n        ...                           [0, 0, 3, 3, 0, 0],\n        ...                           [7, 0, 0, 0, 0, 5],\n        ...                           [7, 7, 0, 5, 5, 5],\n        ...                           [7, 7, 0, 0, 5, 5]])\n        >>> segm.remove_border_labels(border_width=1)\n        >>> segm.data\n        array([[0, 0, 0, 0, 0, 0],\n               [0, 0, 0, 0, 0, 0],\n               [0, 0, 3, 3, 0, 0],\n               [0, 0, 0, 0, 0, 0],\n               [0, 0, 0, 0, 0, 0],\n               [0, 0, 0, 0, 0, 0]])\n\n        >>> segm = SegmentationImage([[1, 1, 0, 0, 4, 4],\n        ...                           [0, 0, 0, 0, 0, 4],\n        ...                           [0, 0, 3, 3, 0, 0],\n        ...                           [7, 0, 0, 0, 0, 5],\n        ...                           [7, 7, 0, 5, 5, 5],\n        ...                           [7, 7, 0, 0, 5, 5]])\n        >>> segm.remove_border_labels(border_width=1,\n        ...                           partial_overlap=False)\n        >>> segm.data\n        array([[0, 0, 0, 0, 0, 0],\n               [0, 0, 0, 0, 0, 0],\n               [0, 0, 3, 3, 0, 0],\n               [7, 0, 0, 0, 0, 5],\n               [7, 7, 0, 5, 5, 5],\n               [7, 7, 0, 0, 5, 5]])\n        \"\"\"\n\n        if border_width >= min(self.shape) / 2:\n            raise ValueError('border_width must be smaller than half the '\n                             'image size in either dimension')\n        border = np.zeros(self.shape, dtype=np.bool)\n        border[:border_width, :] = True\n        border[-border_width:, :] = True\n        border[:, :border_width] = True\n        border[:, -border_width:] = True\n        self.remove_masked_labels(border, partial_overlap=partial_overlap,\n                                  relabel=relabel)", "response": "This method removes labeled segments near the image border."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove_masked_labels(self, mask, partial_overlap=True,\n                             relabel=False):\n        \"\"\"\n        Remove labeled segments located within a masked region.\n\n        Parameters\n        ----------\n        mask : array_like (bool)\n            A boolean mask, with the same shape as the segmentation\n            image, where `True` values indicate masked pixels.\n\n        partial_overlap : bool, optional\n            If this is set to `True` (default), a segment that partially\n            extends into a masked region will also be removed.  Segments\n            that are completely within a masked region are always\n            removed.\n\n        relabel : bool, optional\n            If `True`, then the segmentation image will be relabeled\n            such that the labels are in consecutive order starting from\n            1.\n\n        Examples\n        --------\n        >>> from photutils import SegmentationImage\n        >>> segm = SegmentationImage([[1, 1, 0, 0, 4, 4],\n        ...                           [0, 0, 0, 0, 0, 4],\n        ...                           [0, 0, 3, 3, 0, 0],\n        ...                           [7, 0, 0, 0, 0, 5],\n        ...                           [7, 7, 0, 5, 5, 5],\n        ...                           [7, 7, 0, 0, 5, 5]])\n        >>> mask = np.zeros_like(segm.data, dtype=np.bool)\n        >>> mask[0, :] = True    # mask the first row\n        >>> segm.remove_masked_labels(mask)\n        >>> segm.data\n        array([[0, 0, 0, 0, 0, 0],\n               [0, 0, 0, 0, 0, 0],\n               [0, 0, 3, 3, 0, 0],\n               [7, 0, 0, 0, 0, 5],\n               [7, 7, 0, 5, 5, 5],\n               [7, 7, 0, 0, 5, 5]])\n\n        >>> segm = SegmentationImage([[1, 1, 0, 0, 4, 4],\n        ...                           [0, 0, 0, 0, 0, 4],\n        ...                           [0, 0, 3, 3, 0, 0],\n        ...                           [7, 0, 0, 0, 0, 5],\n        ...                           [7, 7, 0, 5, 5, 5],\n        ...                           [7, 7, 0, 0, 5, 5]])\n        >>> segm.remove_masked_labels(mask, partial_overlap=False)\n        >>> segm.data\n        array([[0, 0, 0, 0, 4, 4],\n               [0, 0, 0, 0, 0, 4],\n               [0, 0, 3, 3, 0, 0],\n               [7, 0, 0, 0, 0, 5],\n               [7, 7, 0, 5, 5, 5],\n               [7, 7, 0, 0, 5, 5]])\n        \"\"\"\n\n        if mask.shape != self.shape:\n            raise ValueError('mask must have the same shape as the '\n                             'segmentation image')\n        remove_labels = self._get_labels(self.data[mask])\n        if not partial_overlap:\n            interior_labels = self._get_labels(self.data[~mask])\n            remove_labels = list(set(remove_labels) - set(interior_labels))\n        self.remove_labels(remove_labels, relabel=relabel)", "response": "This method removes labeled segments located within a masked region."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef outline_segments(self, mask_background=False):\n\n        from scipy.ndimage import grey_erosion, grey_dilation\n\n        # mode='constant' ensures outline is included on the image borders\n        selem = np.array([[0, 1, 0], [1, 1, 1], [0, 1, 0]])\n        eroded = grey_erosion(self.data, footprint=selem, mode='constant',\n                              cval=0.)\n        dilated = grey_dilation(self.data, footprint=selem, mode='constant',\n                                cval=0.)\n\n        outlines = ((dilated != eroded) & (self.data != 0)).astype(int)\n        outlines *= self.data\n\n        if mask_background:\n            outlines = np.ma.masked_where(outlines == 0, outlines)\n\n        return outlines", "response": "Outline the labeled segments."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef gini(data):\n\n    flattened = np.sort(np.ravel(data))\n    N = np.size(flattened)\n    normalization = 1. / (np.abs(np.mean(flattened)) * N * (N - 1))\n    kernel = (2 * np.arange(1, N + 1) - N - 1) * np.abs(flattened)\n    G = normalization * np.sum(kernel)\n\n    return G", "response": "Calculates the Gini coefficient of a given 2D array."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _overlap_slices(self, shape):\n\n        if len(shape) != 2:\n            raise ValueError('input shape must have 2 elements.')\n\n        xmin = self.bbox.ixmin\n        xmax = self.bbox.ixmax\n        ymin = self.bbox.iymin\n        ymax = self.bbox.iymax\n\n        if xmin >= shape[1] or ymin >= shape[0] or xmax <= 0 or ymax <= 0:\n            # no overlap of the aperture with the data\n            return None, None\n\n        slices_large = (slice(max(ymin, 0), min(ymax, shape[0])),\n                        slice(max(xmin, 0), min(xmax, shape[1])))\n\n        slices_small = (slice(max(-ymin, 0),\n                              min(ymax - ymin, shape[0] - ymin)),\n                        slice(max(-xmin, 0),\n                              min(xmax - xmin, shape[1] - xmin)))\n\n        return slices_large, slices_small", "response": "Calculate the slices for the overlapping part of the bounding\n            box and an array of the given shape."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _to_image_partial_overlap(self, image):\n\n        # find the overlap of the mask on the output image shape\n        slices_large, slices_small = self._overlap_slices(image.shape)\n\n        if slices_small is None:\n            return None    # no overlap\n\n        # insert the mask into the output image\n        image[slices_large] = self.data[slices_small]\n\n        return image", "response": "Return an image of the mask that is not fully within the image."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_image(self, shape):\n\n        if len(shape) != 2:\n            raise ValueError('input shape must have 2 elements.')\n\n        image = np.zeros(shape)\n\n        if self.bbox.ixmin < 0 or self.bbox.iymin < 0:\n            return self._to_image_partial_overlap(image)\n\n        try:\n            image[self.bbox.slices] = self.data\n        except ValueError:    # partial or no overlap\n            image = self._to_image_partial_overlap(image)\n\n        return image", "response": "Convert the mask into an image of the given shape."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a cutout from the input data over the aperture mask bounding box and the aperture mask.", "response": "def cutout(self, data, fill_value=0., copy=False):\n        \"\"\"\n        Create a cutout from the input data over the mask bounding box,\n        taking any edge effects into account.\n\n        Parameters\n        ----------\n        data : array_like\n            A 2D array on which to apply the aperture mask.\n\n        fill_value : float, optional\n            The value is used to fill pixels where the aperture mask\n            does not overlap with the input ``data``.  The default is 0.\n\n        copy : bool, optional\n            If `True` then the returned cutout array will always be hold\n            a copy of the input ``data``.  If `False` and the mask is\n            fully within the input ``data``, then the returned cutout\n            array will be a view into the input ``data``.  In cases\n            where the mask partially overlaps or has no overlap with the\n            input ``data``, the returned cutout array will always hold a\n            copy of the input ``data`` (i.e. this keyword has no\n            effect).\n\n        Returns\n        -------\n        result : `~numpy.ndarray`\n            A 2D array cut out from the input ``data`` representing the\n            same cutout region as the aperture mask.  If there is a\n            partial overlap of the aperture mask with the input data,\n            pixels outside of the data will be assigned to\n            ``fill_value``.  `None` is returned if there is no overlap\n            of the aperture with the input ``data``.\n        \"\"\"\n\n        data = np.asanyarray(data)\n        if data.ndim != 2:\n            raise ValueError('data must be a 2D array.')\n\n        partial_overlap = False\n        if self.bbox.ixmin < 0 or self.bbox.iymin < 0:\n            partial_overlap = True\n\n        if not partial_overlap:\n            # try this for speed -- the result may still be a partial\n            # overlap, in which case the next block will be triggered\n            if copy:\n                cutout = np.copy(data[self.bbox.slices])\n            else:\n                cutout = data[self.bbox.slices]\n\n        if partial_overlap or (cutout.shape != self.shape):\n            slices_large, slices_small = self._overlap_slices(data.shape)\n\n            if slices_small is None:\n                return None    # no overlap\n\n            # cutout is a copy\n            cutout = np.zeros(self.shape, dtype=data.dtype)\n            cutout[:] = fill_value\n            cutout[slices_small] = data[slices_large]\n\n            if isinstance(data, u.Quantity):\n                cutout = u.Quantity(cutout, unit=data.unit)\n\n        return cutout"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef multiply(self, data, fill_value=0.):\n\n        cutout = self.cutout(data, fill_value=fill_value)\n        if cutout is None:\n            return None\n        else:\n            return cutout * self.data", "response": "Multiplies the aperture mask with the input data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _moments_central(data, center=None, order=1):\n\n    data = np.asarray(data).astype(float)\n\n    if data.ndim != 2:\n        raise ValueError('data must be a 2D array.')\n\n    if center is None:\n        from ..centroids import centroid_com\n        center = centroid_com(data)\n\n    indices = np.ogrid[[slice(0, i) for i in data.shape]]\n    ypowers = (indices[0] - center[1]) ** np.arange(order + 1)\n    xpowers = np.transpose(indices[1] - center[0]) ** np.arange(order + 1)\n\n    return np.dot(np.dot(np.transpose(ypowers), data), xpowers)", "response": "Calculate the central image moments of the specified order."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef first_and_second_harmonic_function(phi, c):\n\n    return (c[0] + c[1]*np.sin(phi) + c[2]*np.cos(phi) + c[3]*np.sin(2*phi) +\n            c[4]*np.cos(2*phi))", "response": "Compute the first and second harmonic function value at the given input angle."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfits the first and second harmonic function values to a set of base - level terms.", "response": "def fit_first_and_second_harmonics(phi, intensities):\n    \"\"\"\n    Fit the first and second harmonic function values to a set of\n    (angle, intensity) pairs.\n\n    This function is used to compute corrections for ellipse fitting:\n\n    .. math::\n\n        f(phi) = y0 + a1*\\\\sin(phi) + b1*\\\\cos(phi) + a2*\\\\sin(2*phi) +\n                 b2*\\\\cos(2*phi)\n\n    Parameters\n    ----------\n    phi : float or `~numpy.ndarray`\n        The angle(s) along the elliptical path, going towards the positive\n        y axis, starting coincident with the position angle. That is, the\n        angles are defined from the semimajor axis that lies in\n        the positive x quadrant.\n    intensities : `~numpy.ndarray`\n        The intensities measured along the elliptical path, at the\n        angles defined by the ``phi`` parameter.\n\n    Returns\n    -------\n    y0, a1, b1, a2, b2 : float\n        The fitted harmonic coefficent values.\n    \"\"\"\n\n    a1 = b1 = a2 = b2 = 1.\n\n    def optimize_func(x):\n        return first_and_second_harmonic_function(\n            phi, np.array([x[0], x[1], x[2], x[3], x[4]])) - intensities\n\n    return _least_squares_fit(optimize_func, [np.mean(intensities), a1, b1,\n                                              a2, b2])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfit the upper harmonic function to a set of ( angle intensity ) pairs.", "response": "def fit_upper_harmonic(phi, intensities, order):\n    \"\"\"\n    Fit upper harmonic function to a set of (angle, intensity) pairs.\n\n    With ``order`` set to 3 or 4, the resulting amplitudes, divided by\n    the semimajor axis length and local gradient, measure the deviations\n    from perfect ellipticity.\n\n    The harmonic function that is fit is:\n\n    .. math::\n        y(phi, order) = y0 + An*\\\\sin(order*phi) + Bn*\\\\cos(order*phi)\n\n    Parameters\n    ----------\n    phi : float or `~numpy.ndarray`\n        The angle(s) along the elliptical path, going towards the positive\n        y axis, starting coincident with the position angle. That is, the\n        angles are defined from the semimajor axis that lies in\n        the positive x quadrant.\n    intensities : `~numpy.ndarray`\n        The intensities measured along the elliptical path, at the\n        angles defined by the ``phi`` parameter.\n    order : int\n        The order of the harmonic to be fitted.\n\n    Returns\n    -------\n    y0, An, Bn : float\n        The fitted harmonic values.\n    \"\"\"\n\n    an = bn = 1.\n\n    def optimize_func(x):\n        return (x[0] + x[1]*np.sin(order*phi) + x[2]*np.cos(order*phi) -\n                intensities)\n\n    return _least_squares_fit(optimize_func, [np.mean(intensities), an, bn])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning an array where each value is the Euclidean distance from the base array center.", "response": "def _radial_distance(shape):\n    \"\"\"\n    Return an array where each value is the Euclidean distance from the\n    array center.\n\n    Parameters\n    ----------\n    shape : tuple of int\n        The size of the output array along each axis.\n\n    Returns\n    -------\n    result : `~numpy.ndarray`\n        An array containing the Euclidian radial distances from the\n        array center.\n    \"\"\"\n\n    if len(shape) != 2:\n        raise ValueError('shape must have only 2 elements')\n    position = (np.asarray(shape) - 1) / 2.\n    x = np.arange(shape[1]) - position[1]\n    y = np.arange(shape[0]) - position[0]\n    xx, yy = np.meshgrid(x, y)\n    return np.sqrt(xx**2 + yy**2)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget path for a given file.", "response": "def get_path(filename, location='local', cache=True, show_progress=False):\n    \"\"\"\n    Get path (location on your disk) for a given file.\n\n    Parameters\n    ----------\n    filename : str\n        File name in the local or remote data folder.\n    location : {'local', 'remote', 'photutils-datasets'}\n        File location.  ``'local'`` means bundled with ``photutils``.\n        ``'remote'`` means the astropy data server (or the\n        photutils-datasets repo as a backup) or the Astropy cache on\n        your machine. ``'photutils-datasets'`` means the\n        photutils-datasets repo or the Astropy cache on your machine.\n    cache : bool, optional\n        Whether to cache the contents of remote URLs.  Default is\n        `True`.\n    show_progress : bool, optional\n        Whether to display a progress bar during the download (default\n        is `False`).\n\n    Returns\n    -------\n    path : str\n        Path (location on your disk) of the file.\n\n    Examples\n    --------\n    >>> from astropy.io import fits\n    >>> from photutils import datasets\n    >>> hdulist = fits.open(datasets.get_path('fermi_counts.fits.gz'))\n    \"\"\"\n\n    datasets_url = ('https://github.com/astropy/photutils-datasets/raw/'\n                    'master/data/{0}'.format(filename))\n\n    if location == 'local':\n        path = get_pkg_data_filename('data/' + filename)\n    elif location == 'remote':    # pragma: no cover\n        try:\n            url = 'https://data.astropy.org/photometry/{0}'.format(filename)\n            path = download_file(url, cache=cache,\n                                 show_progress=show_progress)\n        except (URLError, HTTPError):   # timeout or not found\n            path = download_file(datasets_url, cache=cache,\n                                 show_progress=show_progress)\n    elif location == 'photutils-datasets':    # pragma: no cover\n            path = download_file(datasets_url, cache=cache,\n                                 show_progress=show_progress)\n    else:\n        raise ValueError('Invalid location: {0}'.format(location))\n\n    return path"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_spitzer_image(show_progress=False):    # pragma: no cover\n\n    path = get_path('spitzer_example_image.fits', location='remote',\n                    show_progress=show_progress)\n    hdu = fits.open(path)[0]\n\n    return hdu", "response": "Load a 4. 5 micron Spitzer image."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading a 4. 5 micron Spitzer catalog.", "response": "def load_spitzer_catalog(show_progress=False):    # pragma: no cover\n    \"\"\"\n    Load a 4.5 micron Spitzer catalog.\n\n    The image from which this catalog was derived is returned by\n    :func:`load_spitzer_image`.\n\n    Parameters\n    ----------\n    show_progress : bool, optional\n        Whether to display a progress bar during the download (default\n        is `False`).\n\n    Returns\n    -------\n    catalog : `~astropy.table.Table`\n        The catalog of sources.\n\n    See Also\n    --------\n    load_spitzer_image\n\n    Examples\n    --------\n    .. plot::\n        :include-source:\n\n        from photutils import datasets\n        catalog = datasets.load_spitzer_catalog()\n        plt.scatter(catalog['l'], catalog['b'])\n        plt.xlabel('Galactic l')\n        plt.ylabel('Galactic b')\n        plt.xlim(18.39, 18.05)\n        plt.ylim(0.13, 0.30)\n    \"\"\"\n\n    path = get_path('spitzer_example_catalog.xml', location='remote',\n                    show_progress=show_progress)\n    table = Table.read(path)\n\n    return table"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_irac_psf(channel, show_progress=False):    # pragma: no cover\n\n    channel = int(channel)\n    if channel < 1 or channel > 4:\n        raise ValueError('channel must be 1, 2, 3, or 4')\n\n    fn = 'irac_ch{0}_flight.fits'.format(channel)\n    path = get_path(fn, location='remote', show_progress=show_progress)\n    hdu = fits.open(path)[0]\n\n    return hdu", "response": "Load a Spitzer IRAC PSF image."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the median of a masked array.", "response": "def _masked_median(data, axis=None):\n    \"\"\"\n    Calculate the median of a (masked) array.\n\n    This function is necessary for a consistent interface across all\n    numpy versions.  A bug was introduced in numpy v1.10 where\n    `numpy.ma.median` (with ``axis=None``) returns a single-valued\n    `~numpy.ma.MaskedArray` if the input data is a `~numpy.ndarray` or\n    if the data is a `~numpy.ma.MaskedArray`, but the mask is `False`\n    everywhere.\n\n    Parameters\n    ----------\n    data : array-like\n        The input data.\n    axis : int or `None`, optional\n        The array axis along which the median is calculated.  If\n        `None`, then the entire array is used.\n\n    Returns\n    -------\n    result : float or `~numpy.ma.MaskedArray`\n        The resulting median.  If ``axis`` is `None`, then a float is\n        returned, otherwise a `~numpy.ma.MaskedArray` is returned.\n    \"\"\"\n\n    _median = np.ma.median(data, axis=axis)\n    if axis is None and np.ma.isMaskedArray(_median):\n        _median = _median.item()\n\n    return _median"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fit_image(self, sma0=None, minsma=0., maxsma=None, step=0.1,\n                  conver=DEFAULT_CONVERGENCE, minit=DEFAULT_MINIT,\n                  maxit=DEFAULT_MAXIT, fflag=DEFAULT_FFLAG,\n                  maxgerr=DEFAULT_MAXGERR, sclip=3., nclip=0,\n                  integrmode=BILINEAR, linear=False, maxrit=None):\n        # This parameter list is quite large and should in principle be\n        # simplified by re-distributing these controls to somewhere else.\n        # We keep this design though because it better mimics the flat\n        # architecture used in the original STSDAS task `ellipse`.\n        \"\"\"\n        Fit multiple isophotes to the image array.\n\n        This method loops over each value of the semimajor axis (sma)\n        length (constructed from the input parameters), fitting a single\n        isophote at each sma.  The entire set of isophotes is returned\n        in an `~photutils.isophote.IsophoteList` instance.\n\n        Parameters\n        ----------\n        sma0 : float, optional\n            The starting value for the semimajor axis length (pixels).\n            This value must not be the minimum or maximum semimajor axis\n            length, but something in between. The algorithm can't start\n            from the very center of the galaxy image because the\n            modelling of elliptical isophotes on that region is poor and\n            it will diverge very easily if not tied to other previously\n            fit isophotes. It can't start from the maximum value either\n            because the maximum is not known beforehand, depending on\n            signal-to-noise. The ``sma0`` value should be selected such\n            that the corresponding isophote has a good signal-to-noise\n            ratio and a clearly defined geometry. If set to `None` (the\n            default), one of two actions will be taken:  if a\n            `~photutils.isophote.EllipseGeometry` instance was input to\n            the `~photutils.isophote.Ellipse` constructor, its ``sma``\n            value will be used.  Otherwise, a default value of 10. will\n            be used.\n        minsma : float, optional\n            The minimum value for the semimajor axis length (pixels).\n            The default is 0.\n        maxsma : float or `None`, optional\n            The maximum value for the semimajor axis length (pixels).\n            When set to `None` (default), the algorithm will increase\n            the semimajor axis until one of several conditions will\n            cause it to stop and revert to fit ellipses with sma <\n            ``sma0``.\n        step : float, optional\n            The step value used to grow/shrink the semimajor axis length\n            (pixels if ``linear=True``, or a relative value if\n            ``linear=False``). See the ``linear`` parameter.  The\n            default is 0.1.\n        conver : float, optional\n            The main convergence criterion. Iterations stop when the\n            largest harmonic amplitude becomes smaller (in absolute\n            value) than ``conver`` times the harmonic fit rms.  The\n            default is 0.05.\n        minit : int, optional\n            The minimum number of iterations to perform. A minimum of 10\n            (the default) iterations guarantees that, on average, 2\n            iterations will be available for fitting each independent\n            parameter (the four harmonic amplitudes and the intensity\n            level). For the first isophote, the minimum number of\n            iterations is 2 * ``minit`` to ensure that, even departing\n            from not-so-good initial values, the algorithm has a better\n            chance to converge to a sensible solution.\n        maxit : int, optional\n            The maximum number of iterations to perform.  The default is\n            50.\n        fflag : float, optional\n            The acceptable fraction of flagged data points in the\n            sample.  If the actual fraction of valid data points is\n            smaller than this, the iterations will stop and the current\n            `~photutils.isophote.Isophote` will be returned.  Flagged\n            data points are points that either lie outside the image\n            frame, are masked, or were rejected by sigma-clipping.  The\n            default is 0.7.\n        maxgerr : float, optional\n            The maximum acceptable relative error in the local radial\n            intensity gradient. This is the main control for preventing\n            ellipses to grow to regions of too low signal-to-noise\n            ratio.  It specifies the maximum acceptable relative error\n            in the local radial intensity gradient.  `Busko (1996; ASPC\n            101, 139)\n            <http://adsabs.harvard.edu/abs/1996ASPC..101..139B>`_ showed\n            that the fitting precision relates to that relative error.\n            The usual behavior of the gradient relative error is to\n            increase with semimajor axis, being larger in outer, fainter\n            regions of a galaxy image.  In the current implementation,\n            the ``maxgerr`` criterion is triggered only when two\n            consecutive isophotes exceed the value specified by the\n            parameter. This prevents premature stopping caused by\n            contamination such as stars and HII regions.\n\n            A number of actions may happen when the gradient error\n            exceeds ``maxgerr`` (or becomes non-significant and is set\n            to `None`).  If the maximum semimajor axis specified by\n            ``maxsma`` is set to `None`, semimajor axis growth is\n            stopped and the algorithm proceeds inwards to the galaxy\n            center. If ``maxsma`` is set to some finite value, and this\n            value is larger than the current semimajor axis length, the\n            algorithm enters non-iterative mode and proceeds outwards\n            until reaching ``maxsma``.  The default is 0.5.\n        sclip : float, optional\n            The sigma-clip sigma value.  The default is 3.0.\n        nclip : int, optional\n            The number of sigma-clip interations.  The default is 0,\n            which means sigma-clipping is skipped.\n        integrmode : {'bilinear', 'nearest_neighbor', 'mean', 'median'}, optional\n            The area integration mode.  The default is 'bilinear'.\n        linear : bool, optional\n            The semimajor axis growing/shrinking mode. If `False`\n            (default), the geometric growing mode is chosen, thus the\n            semimajor axis length is increased by a factor of (1. +\n            ``step``), and the process is repeated until either the\n            semimajor axis value reaches the value of parameter\n            ``maxsma``, or the last fitted ellipse has more than a given\n            fraction of its sampled points flagged out (see ``fflag``).\n            The process then resumes from the first fitted ellipse (at\n            ``sma0``) inwards, in steps of (1./(1. + ``step``)), until\n            the semimajor axis length reaches the value ``minsma``. In\n            case of linear growing, the increment or decrement value is\n            given directly by ``step`` in pixels.  If ``maxsma`` is set\n            to `None`, the semimajor axis will grow until a low\n            signal-to-noise criterion is met. See ``maxgerr``.\n        maxrit : float or `None`, optional\n            The maximum value of semimajor axis to perform an actual\n            fit.  Whenever the current semimajor axis length is larger\n            than ``maxrit``, the isophotes will be extracted using the\n            current geometry, without being fitted.  This non-iterative\n            mode may be useful for sampling regions of very low surface\n            brightness, where the algorithm may become unstable and\n            unable to recover reliable geometry information.\n            Non-iterative mode can also be entered automatically\n            whenever the ellipticity exceeds 1.0 or the ellipse center\n            crosses the image boundaries.  If `None` (default), then no\n            maximum value is used.\n\n        Returns\n        -------\n        result : `~photutils.isophote.IsophoteList` instance\n            A list-like object of `~photutils.isophote.Isophote`\n            instances, sorted by increasing semimajor axis length.\n        \"\"\"\n\n        # multiple fitted isophotes will be stored here\n        isophote_list = []\n\n        # get starting sma from appropriate source: keyword parameter,\n        # internal EllipseGeometry instance, or fixed default value.\n        if not sma0:\n            if self._geometry:\n                sma = self._geometry.sma\n            else:\n                sma = 10.\n        else:\n            sma = sma0\n\n        # first, go from initial sma outwards until\n        # hitting one of several stopping criteria.\n        noiter = False\n        first_isophote = True\n        while True:\n            # first isophote runs longer\n            minit_a = 2 * minit if first_isophote else minit\n            first_isophote = False\n\n            isophote = self.fit_isophote(sma, step, conver, minit_a, maxit,\n                                         fflag, maxgerr, sclip, nclip,\n                                         integrmode, linear, maxrit,\n                                         noniterate=noiter,\n                                         isophote_list=isophote_list)\n\n            # check for failed fit.\n            if (isophote.stop_code < 0 or isophote.stop_code == 1):\n                # in case the fit failed right at the outset, return an\n                # empty list. This is the usual case when the user\n                # provides initial guesses that are too way off to enable\n                # the fitting algorithm to find any meaningful solution.\n\n                if len(isophote_list) == 1:\n                    warnings.warn('No meaningful fit was possible.',\n                                  AstropyUserWarning)\n                    return IsophoteList([])\n\n                self._fix_last_isophote(isophote_list, -1)\n\n                # get last isophote from the actual list, since the last\n                # `isophote` instance in this context may no longer be OK.\n                isophote = isophote_list[-1]\n\n                # if two consecutive isophotes failed to fit,\n                # shut off iterative mode. Or, bail out and\n                # change to go inwards.\n                if len(isophote_list) > 2:\n                    if ((isophote.stop_code == 5 and\n                         isophote_list[-2].stop_code == 5)\n                            or isophote.stop_code == 1):\n                        if maxsma and maxsma > isophote.sma:\n                            # if a maximum sma value was provided by\n                            # user, and the current sma is smaller than\n                            # maxsma, keep growing sma in non-iterative\n                            # mode until reaching it.\n                            noiter = True\n                        else:\n                            # if no maximum sma, stop growing and change\n                            # to go inwards.\n                            break\n\n            # reset variable from the actual list, since the last\n            # `isophote` instance may no longer be OK.\n            isophote = isophote_list[-1]\n\n            # update sma. If exceeded user-defined\n            # maximum, bail out from this loop.\n            sma = isophote.sample.geometry.update_sma(step)\n            if maxsma and sma >= maxsma:\n                break\n\n        # reset sma so as to go inwards.\n        first_isophote = isophote_list[0]\n        sma, step = first_isophote.sample.geometry.reset_sma(step)\n\n        # now, go from initial sma inwards towards center.\n        while True:\n            isophote = self.fit_isophote(sma, step, conver, minit, maxit,\n                                         fflag, maxgerr, sclip, nclip,\n                                         integrmode, linear, maxrit,\n                                         going_inwards=True,\n                                         isophote_list=isophote_list)\n\n            # if abnormal condition, fix isophote but keep going.\n            if isophote.stop_code < 0:\n                self._fix_last_isophote(isophote_list, 0)\n\n            # reset variable from the actual list, since the last\n            # `isophote` instance may no longer be OK.\n            isophote = isophote_list[-1]\n\n            # figure out next sma; if exceeded user-defined\n            # minimum, or too small, bail out from this loop\n            sma = isophote.sample.geometry.update_sma(step)\n            if sma <= max(minsma, 0.5):\n                break\n\n        # if user asked for minsma=0, extract special isophote there\n        if minsma == 0.0:\n            isophote = self.fit_isophote(0.0, isophote_list=isophote_list)\n\n        # sort list of isophotes according to sma\n        isophote_list.sort()\n\n        return IsophoteList(isophote_list)", "response": "Fit multiple isophotes to the image array."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfitting a single isophote to a given semimajor axis length.", "response": "def fit_isophote(self, sma, step=0.1, conver=DEFAULT_CONVERGENCE,\n                     minit=DEFAULT_MINIT, maxit=DEFAULT_MAXIT,\n                     fflag=DEFAULT_FFLAG, maxgerr=DEFAULT_MAXGERR,\n                     sclip=3., nclip=0, integrmode=BILINEAR,\n                     linear=False, maxrit=None, noniterate=False,\n                     going_inwards=False, isophote_list=None):\n        \"\"\"\n        Fit a single isophote with a given semimajor axis length.\n\n        The ``step`` and ``linear`` parameters are not used to actually\n        grow or shrink the current fitting semimajor axis length.  They\n        are necessary so the sampling algorithm can know where to start\n        the gradient computation and also how to compute the elliptical\n        sector areas (when area integration mode is selected).\n\n        Parameters\n        ----------\n        sma : float\n            The semimajor axis length (pixels).\n        step : float, optional\n            The step value used to grow/shrink the semimajor axis length\n            (pixels if ``linear=True``, or a relative value if\n            ``linear=False``). See the ``linear`` parameter.  The\n            default is 0.1.\n        conver : float, optional\n            The main convergence criterion. Iterations stop when the\n            largest harmonic amplitude becomes smaller (in absolute\n            value) than ``conver`` times the harmonic fit rms.  The\n            default is 0.05.\n        minit : int, optional\n            The minimum number of iterations to perform. A minimum of 10\n            (the default) iterations guarantees that, on average, 2\n            iterations will be available for fitting each independent\n            parameter (the four harmonic amplitudes and the intensity\n            level). For the first isophote, the minimum number of\n            iterations is 2 * ``minit`` to ensure that, even departing\n            from not-so-good initial values, the algorithm has a better\n            chance to converge to a sensible solution.\n        maxit : int, optional\n            The maximum number of iterations to perform.  The default is\n            50.\n        fflag : float, optional\n            The acceptable fraction of flagged data points in the\n            sample.  If the actual fraction of valid data points is\n            smaller than this, the iterations will stop and the current\n            `~photutils.isophote.Isophote` will be returned.  Flagged\n            data points are points that either lie outside the image\n            frame, are masked, or were rejected by sigma-clipping.  The\n            default is 0.7.\n        maxgerr : float, optional\n            The maximum acceptable relative error in the local radial\n            intensity gradient.  When fitting a single isophote by\n            itself this paramter doesn't have any effect on the outcome.\n        sclip : float, optional\n            The sigma-clip sigma value.  The default is 3.0.\n        nclip : int, optional\n            The number of sigma-clip interations.  The default is 0,\n            which means sigma-clipping is skipped.\n        integrmode : {'bilinear', 'nearest_neighbor', 'mean', 'median'}, optional\n            The area integration mode.  The default is 'bilinear'.\n        linear : bool, optional\n            The semimajor axis growing/shrinking mode.  When fitting\n            just one isophote, this parameter is used only by the code\n            that define the details of how elliptical arc segments\n            (\"sectors\") are extracted from the image when using area\n            extraction modes (see the ``integrmode`` parameter).\n        maxrit : float or `None`, optional\n            The maximum value of semimajor axis to perform an actual\n            fit.  Whenever the current semimajor axis length is larger\n            than ``maxrit``, the isophotes will be extracted using the\n            current geometry, without being fitted.  This non-iterative\n            mode may be useful for sampling regions of very low surface\n            brightness, where the algorithm may become unstable and\n            unable to recover reliable geometry information.\n            Non-iterative mode can also be entered automatically\n            whenever the ellipticity exceeds 1.0 or the ellipse center\n            crosses the image boundaries.  If `None` (default), then no\n            maximum value is used.\n        noniterate : bool, optional\n            Whether the fitting algorithm should be bypassed and an\n            isophote should be extracted with the geometry taken\n            directly from the most recent `~photutils.isophote.Isophote`\n            instance stored in the ``isophote_list`` parameter.  This\n            parameter is mainly used when running the method in a loop\n            over different values of semimajor axis length, and we want\n            to change from iterative to non-iterative mode somewhere\n            along the sequence of isophotes. When set to `True`, this\n            parameter overrides the behavior associated with parameter\n            ``maxrit``.  The default is `False`.\n        going_inwards : bool, optional\n            Parameter to define the sense of SMA growth. When fitting\n            just one isophote, this parameter is used only by the code\n            that defines the details of how elliptical arc segments\n            (\"sectors\") are extracted from the image, when using area\n            extraction modes (see the ``integrmode`` parameter).  The\n            default is `False`.\n        isophote_list : list or `None`, optional\n            If not `None` (the default), the fitted\n            `~photutils.isophote.Isophote` instance is appended to this\n            list. It must be created and managed by the caller.\n\n        Returns\n        -------\n        result : `~photutils.isophote.Isophote` instance\n            The fitted isophote. The fitted isophote is also appended to\n            the input list input to the ``isophote_list`` parameter.\n        \"\"\"\n\n        geometry = self._geometry\n\n        # if available, geometry from last fitted isophote will be\n        # used as initial guess for next isophote.\n        if isophote_list is not None and len(isophote_list) > 0:\n            geometry = isophote_list[-1].sample.geometry\n\n        # do the fit\n        if noniterate or (maxrit and sma > maxrit):\n            isophote = self._non_iterative(sma, step, linear, geometry,\n                                           sclip, nclip, integrmode)\n        else:\n            isophote = self._iterative(sma, step, linear, geometry, sclip,\n                                       nclip, integrmode, conver, minit,\n                                       maxit, fflag, maxgerr, going_inwards)\n\n        # store result in list\n        if isophote_list is not None and isophote.valid:\n            isophote_list.append(isophote)\n\n        return isophote"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts the aperture to a list of ~photutils. ApertureMask objects.", "response": "def to_mask(self, method='exact', subpixels=5):\n        \"\"\"\n        Return a list of `~photutils.ApertureMask` objects, one for each\n        aperture position.\n\n        Parameters\n        ----------\n        method : {'exact', 'center', 'subpixel'}, optional\n            The method used to determine the overlap of the aperture on\n            the pixel grid.  Not all options are available for all\n            aperture types.  Note that the more precise methods are\n            generally slower.  The following methods are available:\n\n                * ``'exact'`` (default):\n                  The the exact fractional overlap of the aperture and\n                  each pixel is calculated.  The returned mask will\n                  contain values between 0 and 1.\n\n                * ``'center'``:\n                  A pixel is considered to be entirely in or out of the\n                  aperture depending on whether its center is in or out\n                  of the aperture.  The returned mask will contain\n                  values only of 0 (out) and 1 (in).\n\n                * ``'subpixel'``:\n                  A pixel is divided into subpixels (see the\n                  ``subpixels`` keyword), each of which are considered\n                  to be entirely in or out of the aperture depending on\n                  whether its center is in or out of the aperture.  If\n                  ``subpixels=1``, this method is equivalent to\n                  ``'center'``.  The returned mask will contain values\n                  between 0 and 1.\n\n        subpixels : int, optional\n            For the ``'subpixel'`` method, resample pixels by this factor\n            in each dimension.  That is, each pixel is divided into\n            ``subpixels ** 2`` subpixels.\n\n        Returns\n        -------\n        mask : list of `~photutils.ApertureMask`\n            A list of aperture mask objects.\n        \"\"\"\n\n        use_exact, subpixels = self._translate_mask_mode(method, subpixels)\n\n        if hasattr(self, 'r'):\n            radius = self.r\n        elif hasattr(self, 'r_out'):    # annulus\n            radius = self.r_out\n        else:\n            raise ValueError('Cannot determine the aperture radius.')\n\n        masks = []\n        for bbox, edges in zip(self.bounding_boxes, self._centered_edges):\n            ny, nx = bbox.shape\n            mask = circular_overlap_grid(edges[0], edges[1], edges[2],\n                                         edges[3], nx, ny, radius, use_exact,\n                                         subpixels)\n\n            # subtract the inner circle for an annulus\n            if hasattr(self, 'r_in'):\n                mask -= circular_overlap_grid(edges[0], edges[1], edges[2],\n                                              edges[3], nx, ny, self.r_in,\n                                              use_exact, subpixels)\n\n            masks.append(ApertureMask(mask, bbox))\n\n        return masks"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_sky(self, wcs, mode='all'):\n\n        sky_params = self._to_sky_params(wcs, mode=mode)\n        return SkyCircularAperture(**sky_params)", "response": "Converts the aperture to a SkyCircularAperture object defined by the aperture s WCS and returns a SkyCircularAperture object defined by the sky coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting the aperture to a SkyCircularAnnulus object defined by the WCS.", "response": "def to_sky(self, wcs, mode='all'):\n        \"\"\"\n        Convert the aperture to a `SkyCircularAnnulus` object defined\n        in celestial coordinates.\n\n        Parameters\n        ----------\n        wcs : `~astropy.wcs.WCS`\n            The world coordinate system (WCS) transformation to use.\n\n        mode : {'all', 'wcs'}, optional\n            Whether to do the transformation including distortions\n            (``'all'``; default) or only including only the core WCS\n            transformation (``'wcs'``).\n\n        Returns\n        -------\n        aperture : `SkyCircularAnnulus` object\n            A `SkyCircularAnnulus` object.\n        \"\"\"\n\n        sky_params = self._to_sky_params(wcs, mode=mode)\n        return SkyCircularAnnulus(**sky_params)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting the aperture to a CircularAperture object defined in the pixel coordinates.", "response": "def to_pixel(self, wcs, mode='all'):\n        \"\"\"\n        Convert the aperture to a `CircularAperture` object defined in\n        pixel coordinates.\n\n        Parameters\n        ----------\n        wcs : `~astropy.wcs.WCS`\n            The world coordinate system (WCS) transformation to use.\n\n        mode : {'all', 'wcs'}, optional\n            Whether to do the transformation including distortions\n            (``'all'``; default) or only including only the core WCS\n            transformation (``'wcs'``).\n\n        Returns\n        -------\n        aperture : `CircularAperture` object\n            A `CircularAperture` object.\n        \"\"\"\n\n        pixel_params = self._to_pixel_params(wcs, mode=mode)\n        return CircularAperture(**pixel_params)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_pixel(self, wcs, mode='all'):\n\n        pixel_params = self._to_pixel_params(wcs, mode=mode)\n        return CircularAnnulus(**pixel_params)", "response": "Convert the aperture to a CircularAnnulus object defined in the pixel coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef apply_poisson_noise(data, random_state=None):\n\n    data = np.asanyarray(data)\n    if np.any(data < 0):\n        raise ValueError('data must not contain any negative values')\n\n    prng = check_random_state(random_state)\n\n    return prng.poisson(data)", "response": "Apply Poisson noise to an array of counts."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_noise_image(shape, type='gaussian', mean=None, stddev=None,\n                     random_state=None):\n    \"\"\"\n    Make a noise image containing Gaussian or Poisson noise.\n\n    Parameters\n    ----------\n    shape : 2-tuple of int\n        The shape of the output 2D image.\n\n    type : {'gaussian', 'poisson'}\n        The distribution used to generate the random noise:\n\n            * ``'gaussian'``: Gaussian distributed noise.\n            * ``'poisson'``: Poisson distributed noise.\n\n    mean : float\n        The mean of the random distribution.  Required for both Gaussian\n        and Poisson noise.  The default is 0.\n\n    stddev : float, optional\n        The standard deviation of the Gaussian noise to add to the\n        output image.  Required for Gaussian noise and ignored for\n        Poisson noise (the variance of the Poisson distribution is equal\n        to its mean).\n\n    random_state : int or `~numpy.random.RandomState`, optional\n        Pseudo-random number generator state used for random sampling.\n        Separate function calls with the same noise parameters and\n        ``random_state`` will generate the identical noise image.\n\n    Returns\n    -------\n    image : 2D `~numpy.ndarray`\n        Image containing random noise.\n\n    See Also\n    --------\n    apply_poisson_noise\n\n    Examples\n    --------\n    .. plot::\n        :include-source:\n\n        # make Gaussian and Poisson noise images\n        from photutils.datasets import make_noise_image\n        shape = (100, 100)\n        image1 = make_noise_image(shape, type='gaussian', mean=0., stddev=5.)\n        image2 = make_noise_image(shape, type='poisson', mean=5.)\n\n        # plot the images\n        import matplotlib.pyplot as plt\n        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n        ax1.imshow(image1, origin='lower', interpolation='nearest')\n        ax1.set_title('Gaussian noise ($\\\\mu=0$, $\\\\sigma=5.$)')\n        ax2.imshow(image2, origin='lower', interpolation='nearest')\n        ax2.set_title('Poisson noise ($\\\\mu=5$)')\n    \"\"\"\n\n    if mean is None:\n        raise ValueError('\"mean\" must be input')\n\n    prng = check_random_state(random_state)\n\n    if type == 'gaussian':\n        if stddev is None:\n            raise ValueError('\"stddev\" must be input for Gaussian noise')\n        image = prng.normal(loc=mean, scale=stddev, size=shape)\n    elif type == 'poisson':\n        image = prng.poisson(lam=mean, size=shape)\n    else:\n        raise ValueError('Invalid type: {0}. Use one of '\n                         '{\"gaussian\", \"poisson\"}.'.format(type))\n\n    return image", "response": "Make a 2D image containing Gaussian or Poisson noise."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_random_models_table(n_sources, param_ranges, random_state=None):\n\n    prng = check_random_state(random_state)\n\n    sources = Table()\n    for param_name, (lower, upper) in param_ranges.items():\n        # Generate a column for every item in param_ranges, even if it\n        # is not in the model (e.g. flux).  However, such columns will\n        # be ignored when rendering the image.\n        sources[param_name] = prng.uniform(lower, upper, n_sources)\n\n    return sources", "response": "Generates a table containing random parameters for each source in the set of sources."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates a table containing random 2D Gaussian sources.", "response": "def make_random_gaussians_table(n_sources, param_ranges, random_state=None):\n    \"\"\"\n    Make a `~astropy.table.Table` containing randomly generated\n    parameters for 2D Gaussian sources.\n\n    Each row of the table corresponds to a Gaussian source whose\n    parameters are defined by the column names.  The parameters are\n    drawn from a uniform distribution over the specified input ranges.\n\n    The output table can be input into\n    :func:`make_gaussian_sources_image` to create an image containing\n    the 2D Gaussian sources.\n\n    Parameters\n    ----------\n    n_sources : float\n        The number of random Gaussian sources to generate.\n\n    param_ranges : dict\n        The lower and upper boundaries for each of the\n        `~astropy.modeling.functional_models.Gaussian2D` parameters as a\n        `dict` mapping the parameter name to its ``(lower, upper)``\n        bounds.  The dictionary keys must be valid\n        `~astropy.modeling.functional_models.Gaussian2D` parameter names\n        or ``'flux'``.  If ``'flux'`` is specified, but not\n        ``'amplitude'`` then the 2D Gaussian amplitudes will be\n        calculated and placed in the output table.  If both ``'flux'``\n        and ``'amplitude'`` are specified, then ``'flux'`` will be\n        ignored.  Model parameters not defined in ``param_ranges`` will\n        be set to the default value.\n\n    random_state : int or `~numpy.random.RandomState`, optional\n        Pseudo-random number generator state used for random sampling.\n\n    Returns\n    -------\n    table : `~astropy.table.Table`\n        A table of parameters for the randomly generated Gaussian\n        sources.  Each row of the table corresponds to a Gaussian source\n        whose parameters are defined by the column names.\n\n    See Also\n    --------\n    make_random_models_table, make_gaussian_sources_image\n\n    Notes\n    -----\n    To generate identical parameter values from separate function calls,\n    ``param_ranges`` must be input as an `~collections.OrderedDict` with\n    the same parameter ranges and ``random_state`` must be the same.\n\n\n    Examples\n    --------\n    >>> from collections import OrderedDict\n    >>> from photutils.datasets import make_random_gaussians_table\n    >>> n_sources = 5\n    >>> param_ranges = [('amplitude', [500, 1000]),\n    ...                 ('x_mean', [0, 500]),\n    ...                 ('y_mean', [0, 300]),\n    ...                 ('x_stddev', [1, 5]),\n    ...                 ('y_stddev', [1, 5]),\n    ...                 ('theta', [0, np.pi])]\n    >>> param_ranges = OrderedDict(param_ranges)\n    >>> sources = make_random_gaussians_table(n_sources, param_ranges,\n    ...                                       random_state=12345)\n    >>> for col in sources.colnames:\n    ...     sources[col].info.format = '%.8g'  # for consistent table output\n    >>> print(sources)\n    amplitude   x_mean    y_mean   x_stddev  y_stddev   theta\n    --------- --------- --------- --------- --------- ----------\n    964.80805 297.77235 224.31444 3.6256447 3.5699013  2.2923859\n    658.18778 482.25726 288.39202 4.2392502 3.8698145  3.1227889\n    591.95941 326.58855 2.5164894 4.4887037  2.870396  2.1264615\n    602.28014 374.45332 31.933313 4.8585904 2.3023387  2.4844422\n    783.86251 326.78494 89.611114 3.8947414 2.7585784 0.53694298\n\n    To specifying the flux range instead of the amplitude range:\n\n    >>> param_ranges = [('flux', [500, 1000]),\n    ...                 ('x_mean', [0, 500]),\n    ...                 ('y_mean', [0, 300]),\n    ...                 ('x_stddev', [1, 5]),\n    ...                 ('y_stddev', [1, 5]),\n    ...                 ('theta', [0, np.pi])]\n    >>> param_ranges = OrderedDict(param_ranges)\n    >>> sources = make_random_gaussians_table(n_sources, param_ranges,\n    ...                                       random_state=12345)\n    >>> for col in sources.colnames:\n    ...     sources[col].info.format = '%.8g'  # for consistent table output\n    >>> print(sources)\n       flux     x_mean    y_mean   x_stddev  y_stddev   theta    amplitude\n    --------- --------- --------- --------- --------- ---------- ---------\n    964.80805 297.77235 224.31444 3.6256447 3.5699013  2.2923859 11.863685\n    658.18778 482.25726 288.39202 4.2392502 3.8698145  3.1227889 6.3854388\n    591.95941 326.58855 2.5164894 4.4887037  2.870396  2.1264615 7.3122209\n    602.28014 374.45332 31.933313 4.8585904 2.3023387  2.4844422 8.5691781\n    783.86251 326.78494 89.611114 3.8947414 2.7585784 0.53694298 11.611707\n\n    Note that in this case the output table contains both a flux and\n    amplitude column.  The flux column will be ignored when generating\n    an image of the models using :func:`make_gaussian_sources_image`.\n    \"\"\"\n\n    sources = make_random_models_table(n_sources, param_ranges,\n                                       random_state=random_state)\n\n    # convert Gaussian2D flux to amplitude\n    if 'flux' in param_ranges and 'amplitude' not in param_ranges:\n        model = Gaussian2D(x_stddev=1, y_stddev=1)\n\n        if 'x_stddev' in sources.colnames:\n            xstd = sources['x_stddev']\n        else:\n            xstd = model.x_stddev.value    # default\n        if 'y_stddev' in sources.colnames:\n            ystd = sources['y_stddev']\n        else:\n            ystd = model.y_stddev.value    # default\n\n        sources = sources.copy()\n        sources['amplitude'] = sources['flux'] / (2. * np.pi * xstd * ystd)\n\n    return sources"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmakes an image containing sources generated from a user - specified model.", "response": "def make_model_sources_image(shape, model, source_table, oversample=1):\n    \"\"\"\n    Make an image containing sources generated from a user-specified\n    model.\n\n    Parameters\n    ----------\n    shape : 2-tuple of int\n        The shape of the output 2D image.\n\n    model : 2D astropy.modeling.models object\n        The model to be used for rendering the sources.\n\n    source_table : `~astropy.table.Table`\n        Table of parameters for the sources.  Each row of the table\n        corresponds to a source whose model parameters are defined by\n        the column names, which must match the model parameter names.\n        Column names that do not match model parameters will be ignored.\n        Model parameters not defined in the table will be set to the\n        ``model`` default value.\n\n    oversample : float, optional\n        The sampling factor used to discretize the models on a pixel\n        grid.  If the value is 1.0 (the default), then the models will\n        be discretized by taking the value at the center of the pixel\n        bin.  Note that this method will not preserve the total flux of\n        very small sources.  Otherwise, the models will be discretized\n        by taking the average over an oversampled grid.  The pixels will\n        be oversampled by the ``oversample`` factor.\n\n    Returns\n    -------\n    image : 2D `~numpy.ndarray`\n        Image containing model sources.\n\n    See Also\n    --------\n    make_random_models_table, make_gaussian_sources_image\n\n    Examples\n    --------\n    .. plot::\n        :include-source:\n\n        from collections import OrderedDict\n        from astropy.modeling.models import Moffat2D\n        from photutils.datasets import (make_random_models_table,\n                                        make_model_sources_image)\n\n        model = Moffat2D()\n        n_sources = 10\n        shape = (100, 100)\n        param_ranges = [('amplitude', [100, 200]),\n                        ('x_0', [0, shape[1]]),\n                        ('y_0', [0, shape[0]]),\n                        ('gamma', [5, 10]),\n                        ('alpha', [1, 2])]\n        param_ranges = OrderedDict(param_ranges)\n        sources = make_random_models_table(n_sources, param_ranges,\n                                           random_state=12345)\n\n        data = make_model_sources_image(shape, model, sources)\n        plt.imshow(data)\n    \"\"\"\n\n    image = np.zeros(shape, dtype=np.float64)\n    y, x = np.indices(shape)\n\n    params_to_set = []\n    for param in source_table.colnames:\n        if param in model.param_names:\n            params_to_set.append(param)\n\n    # Save the initial parameter values so we can set them back when\n    # done with the loop.  It's best not to copy a model, because some\n    # models (e.g. PSF models) may have substantial amounts of data in\n    # them.\n    init_params = {param: getattr(model, param) for param in params_to_set}\n\n    try:\n        for i, source in enumerate(source_table):\n            for param in params_to_set:\n                setattr(model, param, source[param])\n\n            if oversample == 1:\n                image += model(x, y)\n            else:\n                image += discretize_model(model, (0, shape[1]),\n                                          (0, shape[0]), mode='oversample',\n                                          factor=oversample)\n    finally:\n        for param, value in init_params.items():\n            setattr(model, param, value)\n\n    return image"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmaking an image containing 2D Gaussian sources.", "response": "def make_gaussian_sources_image(shape, source_table, oversample=1):\n    \"\"\"\n    Make an image containing 2D Gaussian sources.\n\n    Parameters\n    ----------\n    shape : 2-tuple of int\n        The shape of the output 2D image.\n\n    source_table : `~astropy.table.Table`\n        Table of parameters for the Gaussian sources.  Each row of the\n        table corresponds to a Gaussian source whose parameters are\n        defined by the column names.  With the exception of ``'flux'``,\n        column names that do not match model parameters will be ignored\n        (flux will be converted to amplitude).  If both ``'flux'`` and\n        ``'amplitude'`` are present, then ``'flux'`` will be ignored.\n        Model parameters not defined in the table will be set to the\n        default value.\n\n    oversample : float, optional\n        The sampling factor used to discretize the models on a pixel\n        grid.  If the value is 1.0 (the default), then the models will\n        be discretized by taking the value at the center of the pixel\n        bin.  Note that this method will not preserve the total flux of\n        very small sources.  Otherwise, the models will be discretized\n        by taking the average over an oversampled grid.  The pixels will\n        be oversampled by the ``oversample`` factor.\n\n    Returns\n    -------\n    image : 2D `~numpy.ndarray`\n        Image containing 2D Gaussian sources.\n\n    See Also\n    --------\n    make_model_sources_image, make_random_gaussians_table\n\n    Examples\n    --------\n    .. plot::\n        :include-source:\n\n        # make a table of Gaussian sources\n        from astropy.table import Table\n        table = Table()\n        table['amplitude'] = [50, 70, 150, 210]\n        table['x_mean'] = [160, 25, 150, 90]\n        table['y_mean'] = [70, 40, 25, 60]\n        table['x_stddev'] = [15.2, 5.1, 3., 8.1]\n        table['y_stddev'] = [2.6, 2.5, 3., 4.7]\n        table['theta'] = np.array([145., 20., 0., 60.]) * np.pi / 180.\n\n        # make an image of the sources without noise, with Gaussian\n        # noise, and with Poisson noise\n        from photutils.datasets import make_gaussian_sources_image\n        from photutils.datasets import make_noise_image\n        shape = (100, 200)\n        image1 = make_gaussian_sources_image(shape, table)\n        image2 = image1 + make_noise_image(shape, type='gaussian', mean=5.,\n                                           stddev=5.)\n        image3 = image1 + make_noise_image(shape, type='poisson', mean=5.)\n\n        # plot the images\n        import matplotlib.pyplot as plt\n        fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(8, 12))\n        ax1.imshow(image1, origin='lower', interpolation='nearest')\n        ax1.set_title('Original image')\n        ax2.imshow(image2, origin='lower', interpolation='nearest')\n        ax2.set_title('Original image with added Gaussian noise'\n                      ' ($\\\\mu = 5, \\\\sigma = 5$)')\n        ax3.imshow(image3, origin='lower', interpolation='nearest')\n        ax3.set_title('Original image with added Poisson noise ($\\\\mu = 5$)')\n    \"\"\"\n\n    model = Gaussian2D(x_stddev=1, y_stddev=1)\n\n    if 'x_stddev' in source_table.colnames:\n        xstd = source_table['x_stddev']\n    else:\n        xstd = model.x_stddev.value    # default\n    if 'y_stddev' in source_table.colnames:\n        ystd = source_table['y_stddev']\n    else:\n        ystd = model.y_stddev.value    # default\n\n    colnames = source_table.colnames\n    if 'flux' in colnames and 'amplitude' not in colnames:\n        source_table = source_table.copy()\n        source_table['amplitude'] = (source_table['flux'] /\n                                     (2. * np.pi * xstd * ystd))\n\n    return make_model_sources_image(shape, model, source_table,\n                                    oversample=oversample)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmaking an image containing 2D Gaussian sources.", "response": "def make_gaussian_prf_sources_image(shape, source_table):\n    \"\"\"\n    Make an image containing 2D Gaussian sources.\n\n    Parameters\n    ----------\n    shape : 2-tuple of int\n        The shape of the output 2D image.\n\n    source_table : `~astropy.table.Table`\n        Table of parameters for the Gaussian sources.  Each row of the\n        table corresponds to a Gaussian source whose parameters are\n        defined by the column names.  With the exception of ``'flux'``,\n        column names that do not match model parameters will be ignored\n        (flux will be converted to amplitude).  If both ``'flux'`` and\n        ``'amplitude'`` are present, then ``'flux'`` will be ignored.\n        Model parameters not defined in the table will be set to the\n        default value.\n\n    Returns\n    -------\n    image : 2D `~numpy.ndarray`\n        Image containing 2D Gaussian sources.\n\n    See Also\n    --------\n    make_model_sources_image, make_random_gaussians_table\n\n    Examples\n    --------\n    .. plot::\n        :include-source:\n\n        # make a table of Gaussian sources\n        from astropy.table import Table\n        table = Table()\n        table['amplitude'] = [50, 70, 150, 210]\n        table['x_0'] = [160, 25, 150, 90]\n        table['y_0'] = [70, 40, 25, 60]\n        table['sigma'] = [15.2, 5.1, 3., 8.1]\n\n        # make an image of the sources without noise, with Gaussian\n        # noise, and with Poisson noise\n        from photutils.datasets import make_gaussian_prf_sources_image\n        from photutils.datasets import make_noise_image\n        shape = (100, 200)\n        image1 = make_gaussian_prf_sources_image(shape, table)\n        image2 = image1 + make_noise_image(shape, type='gaussian', mean=5.,\n                                           stddev=5.)\n        image3 = image1 + make_noise_image(shape, type='poisson', mean=5.)\n\n        # plot the images\n        import matplotlib.pyplot as plt\n        fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(8, 12))\n        ax1.imshow(image1, origin='lower', interpolation='nearest')\n        ax1.set_title('Original image')\n        ax2.imshow(image2, origin='lower', interpolation='nearest')\n        ax2.set_title('Original image with added Gaussian noise'\n                      ' ($\\\\mu = 5, \\\\sigma = 5$)')\n        ax3.imshow(image3, origin='lower', interpolation='nearest')\n        ax3.set_title('Original image with added Poisson noise ($\\\\mu = 5$)')\n    \"\"\"\n\n    model = IntegratedGaussianPRF(sigma=1)\n\n    if 'sigma' in source_table.colnames:\n        sigma = source_table['sigma']\n    else:\n        sigma = model.sigma.value    # default\n\n    colnames = source_table.colnames\n    if 'flux' not in colnames and 'amplitude' in colnames:\n        source_table = source_table.copy()\n        source_table['flux'] = (source_table['amplitude'] *\n                                (2. * np.pi * sigma * sigma))\n\n    return make_model_sources_image(shape, model, source_table,\n                                    oversample=1)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_4gaussians_image(noise=True):\n\n    table = Table()\n    table['amplitude'] = [50, 70, 150, 210]\n    table['x_mean'] = [160, 25, 150, 90]\n    table['y_mean'] = [70, 40, 25, 60]\n    table['x_stddev'] = [15.2, 5.1, 3., 8.1]\n    table['y_stddev'] = [2.6, 2.5, 3., 4.7]\n    table['theta'] = np.array([145., 20., 0., 60.]) * np.pi / 180.\n\n    shape = (100, 200)\n    data = make_gaussian_sources_image(shape, table) + 5.\n\n    if noise:\n        data += make_noise_image(shape, type='gaussian', mean=0.,\n                                 stddev=5., random_state=12345)\n\n    return data", "response": "Make an example image containing four 2D Gaussians plus a constant\n    background."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmakes an example image containing 100 2D Gaussians plus a constant background.", "response": "def make_100gaussians_image(noise=True):\n    \"\"\"\n    Make an example image containing 100 2D Gaussians plus a constant\n    background.\n\n    The background has a mean of 5.\n\n    If ``noise`` is `True`, then Gaussian noise with a mean of 0 and a\n    standard deviation of 2 is added to the output image.\n\n    Parameters\n    ----------\n    noise : bool, optional\n        Whether to include noise in the output image (default is\n        `True`).\n\n    Returns\n    -------\n    image : 2D `~numpy.ndarray`\n        Image containing 100 2D Gaussian sources.\n\n    See Also\n    --------\n    make_4gaussians_image\n\n    Examples\n    --------\n    .. plot::\n        :include-source:\n\n        from photutils import datasets\n        image = datasets.make_100gaussians_image()\n        plt.imshow(image, origin='lower', interpolation='nearest')\n    \"\"\"\n\n    n_sources = 100\n    flux_range = [500, 1000]\n    xmean_range = [0, 500]\n    ymean_range = [0, 300]\n    xstddev_range = [1, 5]\n    ystddev_range = [1, 5]\n    params = OrderedDict([('flux', flux_range),\n                          ('x_mean', xmean_range),\n                          ('y_mean', ymean_range),\n                          ('x_stddev', xstddev_range),\n                          ('y_stddev', ystddev_range),\n                          ('theta', [0, 2*np.pi])])\n\n    sources = make_random_gaussians_table(n_sources, params,\n                                          random_state=12345)\n\n    shape = (300, 500)\n    data = make_gaussian_sources_image(shape, sources) + 5.\n\n    if noise:\n        data += make_noise_image(shape, type='gaussian', mean=0.,\n                                 stddev=2., random_state=12345)\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a simple celestial WCS object in either the ICRS or Galactic WCS coordinate frame.", "response": "def make_wcs(shape, galactic=False):\n    \"\"\"\n    Create a simple celestial WCS object in either the ICRS or Galactic\n    coordinate frame.\n\n    Parameters\n    ----------\n    shape : 2-tuple of int\n        The shape of the 2D array to be used with the output\n        `~astropy.wcs.WCS` object.\n\n    galactic : bool, optional\n        If `True`, then the output WCS will be in the Galactic\n        coordinate frame.  If `False` (default), then the output WCS\n        will be in the ICRS coordinate frame.\n\n    Returns\n    -------\n    wcs : `~astropy.wcs.WCS` object\n        The world coordinate system (WCS) transformation.\n\n    See Also\n    --------\n    make_imagehdu\n\n    Examples\n    --------\n    >>> from photutils.datasets import make_wcs\n    >>> shape = (100, 100)\n    >>> wcs = make_wcs(shape)\n    >>> print(wcs.wcs.crpix)  # doctest: +FLOAT_CMP\n    [50. 50.]\n    >>> print(wcs.wcs.crval)  # doctest: +FLOAT_CMP\n    [197.8925      -1.36555556]\n    \"\"\"\n\n    wcs = WCS(naxis=2)\n    rho = np.pi / 3.\n    scale = 0.1 / 3600.\n\n    if astropy_version < '3.1':\n        wcs._naxis1 = shape[1]     # nx\n        wcs._naxis2 = shape[0]     # ny\n    else:\n        wcs.pixel_shape = shape\n\n    wcs.wcs.crpix = [shape[1] / 2, shape[0] / 2]     # 1-indexed (x, y)\n    wcs.wcs.crval = [197.8925, -1.36555556]\n    wcs.wcs.cunit = ['deg', 'deg']\n    wcs.wcs.cd = [[-scale * np.cos(rho), scale * np.sin(rho)],\n                  [scale * np.sin(rho), scale * np.cos(rho)]]\n    if not galactic:\n        wcs.wcs.radesys = 'ICRS'\n        wcs.wcs.ctype = ['RA---TAN', 'DEC--TAN']\n    else:\n        wcs.wcs.ctype = ['GLON-CAR', 'GLAT-CAR']\n\n    return wcs"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a FITS image HDU containing the input 2D array.", "response": "def make_imagehdu(data, wcs=None):\n    \"\"\"\n    Create a FITS `~astropy.io.fits.ImageHDU` containing the input 2D\n    image.\n\n    Parameters\n    ----------\n    data : 2D array-like\n        The input 2D data.\n\n    wcs : `~astropy.wcs.WCS`, optional\n        The world coordinate system (WCS) transformation to include in\n        the output FITS header.\n\n    Returns\n    -------\n    image_hdu : `~astropy.io.fits.ImageHDU`\n        The FITS `~astropy.io.fits.ImageHDU`.\n\n    See Also\n    --------\n    make_wcs\n\n    Examples\n    --------\n    >>> from photutils.datasets import make_imagehdu, make_wcs\n    >>> shape = (100, 100)\n    >>> data = np.ones(shape)\n    >>> wcs = make_wcs(shape)\n    >>> hdu = make_imagehdu(data, wcs=wcs)\n    >>> print(hdu.data.shape)\n    (100, 100)\n    \"\"\"\n\n    data = np.asanyarray(data)\n    if data.ndim != 2:\n        raise ValueError('data must be a 2D array')\n\n    if wcs is not None:\n        header = wcs.to_header()\n    else:\n        header = None\n\n    return fits.ImageHDU(data, header=header)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef centroid_com(data, mask=None):\n\n    data = data.astype(np.float)\n\n    if mask is not None and mask is not np.ma.nomask:\n        mask = np.asarray(mask, dtype=bool)\n        if data.shape != mask.shape:\n            raise ValueError('data and mask must have the same shape.')\n        data[mask] = 0.\n\n    badidx = ~np.isfinite(data)\n    if np.any(badidx):\n        warnings.warn('Input data contains input values (e.g. NaNs or infs), '\n                      'which were automatically masked.', AstropyUserWarning)\n        data[badidx] = 0.\n\n    total = np.sum(data)\n    indices = np.ogrid[[slice(0, i) for i in data.shape]]\n\n    # note the output array is reversed to give (x, y) order\n    return np.array([np.sum(indices[axis] * data) / total\n                     for axis in range(data.ndim)])[::-1]", "response": "Calculate the centroid of an n - dimensional array as its center of\n    mass determined from moments."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef gaussian1d_moments(data, mask=None):\n\n    if np.any(~np.isfinite(data)):\n        data = np.ma.masked_invalid(data)\n        warnings.warn('Input data contains input values (e.g. NaNs or infs), '\n                      'which were automatically masked.', AstropyUserWarning)\n    else:\n        data = np.ma.array(data)\n\n    if mask is not None and mask is not np.ma.nomask:\n        mask = np.asanyarray(mask)\n        if data.shape != mask.shape:\n            raise ValueError('data and mask must have the same shape.')\n        data.mask |= mask\n\n    data.fill_value = 0.\n    data = data.filled()\n\n    x = np.arange(data.size)\n    x_mean = np.sum(x * data) / np.sum(data)\n    x_stddev = np.sqrt(abs(np.sum(data * (x - x_mean)**2) / np.sum(data)))\n    amplitude = np.ptp(data)\n\n    return amplitude, x_mean, x_stddev", "response": "Estimate 1D Gaussian parameters from the moments of 1D data."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fit_2dgaussian(data, error=None, mask=None):\n\n    from ..morphology import data_properties  # prevent circular imports\n\n    data = np.ma.asanyarray(data)\n\n    if mask is not None and mask is not np.ma.nomask:\n        mask = np.asanyarray(mask)\n        if data.shape != mask.shape:\n            raise ValueError('data and mask must have the same shape.')\n        data.mask |= mask\n\n    if np.any(~np.isfinite(data)):\n        data = np.ma.masked_invalid(data)\n        warnings.warn('Input data contains input values (e.g. NaNs or infs), '\n                      'which were automatically masked.', AstropyUserWarning)\n\n    if error is not None:\n        error = np.ma.masked_invalid(error)\n        if data.shape != error.shape:\n            raise ValueError('data and error must have the same shape.')\n        data.mask |= error.mask\n        weights = 1.0 / error.clip(min=1.e-30)\n    else:\n        weights = np.ones(data.shape)\n\n    if np.ma.count(data) < 7:\n        raise ValueError('Input data must have a least 7 unmasked values to '\n                         'fit a 2D Gaussian plus a constant.')\n\n    # assign zero weight to masked pixels\n    if data.mask is not np.ma.nomask:\n        weights[data.mask] = 0.\n\n    mask = data.mask\n    data.fill_value = 0.0\n    data = data.filled()\n\n    # Subtract the minimum of the data as a crude background estimate.\n    # This will also make the data values positive, preventing issues with\n    # the moment estimation in data_properties (moments from negative data\n    # values can yield undefined Gaussian parameters, e.g. x/y_stddev).\n    props = data_properties(data - np.min(data), mask=mask)\n\n    init_const = 0.    # subtracted data minimum above\n    init_amplitude = np.ptp(data)\n    g_init = GaussianConst2D(constant=init_const, amplitude=init_amplitude,\n                             x_mean=props.xcentroid.value,\n                             y_mean=props.ycentroid.value,\n                             x_stddev=props.semimajor_axis_sigma.value,\n                             y_stddev=props.semiminor_axis_sigma.value,\n                             theta=props.orientation.value)\n    fitter = LevMarLSQFitter()\n    y, x = np.indices(data.shape)\n    gfit = fitter(g_init, x, y, data, weights=weights)\n\n    return gfit", "response": "Fit a 2D Gaussian plus a constant to a 2D image."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef centroid_1dg(data, error=None, mask=None):\n\n    data = np.ma.asanyarray(data)\n\n    if mask is not None and mask is not np.ma.nomask:\n        mask = np.asanyarray(mask)\n        if data.shape != mask.shape:\n            raise ValueError('data and mask must have the same shape.')\n        data.mask |= mask\n\n    if np.any(~np.isfinite(data)):\n        data = np.ma.masked_invalid(data)\n        warnings.warn('Input data contains input values (e.g. NaNs or infs), '\n                      'which were automatically masked.', AstropyUserWarning)\n\n    if error is not None:\n        error = np.ma.masked_invalid(error)\n        if data.shape != error.shape:\n            raise ValueError('data and error must have the same shape.')\n        data.mask |= error.mask\n\n        error.mask = data.mask\n        xy_error = np.array([np.sqrt(np.ma.sum(error**2, axis=i))\n                             for i in [0, 1]])\n        xy_weights = [(1.0 / xy_error[i].clip(min=1.e-30)) for i in [0, 1]]\n    else:\n        xy_weights = [np.ones(data.shape[i]) for i in [1, 0]]\n\n    # assign zero weight to masked pixels\n    if data.mask is not np.ma.nomask:\n        bad_idx = [np.all(data.mask, axis=i) for i in [0, 1]]\n        for i in [0, 1]:\n            xy_weights[i][bad_idx[i]] = 0.\n\n    xy_data = np.array([np.ma.sum(data, axis=i) for i in [0, 1]])\n\n    constant_init = np.ma.min(data)\n    centroid = []\n    for (data_i, weights_i) in zip(xy_data, xy_weights):\n        params_init = gaussian1d_moments(data_i)\n        g_init = Const1D(constant_init) + Gaussian1D(*params_init)\n        fitter = LevMarLSQFitter()\n        x = np.arange(data_i.size)\n        g_fit = fitter(g_init, x, data_i, weights=weights_i)\n        centroid.append(g_fit.mean_1.value)\n\n    return np.array(centroid)", "response": "Calculate the centroid of a 2D array by fitting 1D Gaussians to the base x and y distributions of the array."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the centroid of a 2D array by fitting a 2D Gaussian to the array.", "response": "def centroid_2dg(data, error=None, mask=None):\n    \"\"\"\n    Calculate the centroid of a 2D array by fitting a 2D Gaussian (plus\n    a constant) to the array.\n\n    Invalid values (e.g. NaNs or infs) in the ``data`` or ``error``\n    arrays are automatically masked.  The mask for invalid values\n    represents the combination of the invalid-value masks for the\n    ``data`` and ``error`` arrays.\n\n    Parameters\n    ----------\n    data : array_like\n        The 2D data array.\n\n    error : array_like, optional\n        The 2D array of the 1-sigma errors of the input ``data``.\n\n    mask : array_like (bool), optional\n        A boolean mask, with the same shape as ``data``, where a `True`\n        value indicates the corresponding element of ``data`` is masked.\n\n    Returns\n    -------\n    centroid : `~numpy.ndarray`\n        The ``x, y`` coordinates of the centroid.\n    \"\"\"\n\n    gfit = fit_2dgaussian(data, error=error, mask=mask)\n\n    return np.array([gfit.x_mean.value, gfit.y_mean.value])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef centroid_sources(data, xpos, ypos, box_size=11, footprint=None,\n                     error=None, mask=None, centroid_func=centroid_com):\n    \"\"\"\n    Calculate the centroid of sources at the defined positions.\n\n    A cutout image centered on each input position will be used to\n    calculate the centroid position.  The cutout image is defined either\n    using the ``box_size`` or ``footprint`` keyword.  The ``footprint``\n    keyword can be used to create a non-rectangular cutout image.\n\n    Parameters\n    ----------\n    data : array_like\n        The 2D array of the image.\n\n    xpos, ypos : float or array-like of float\n        The initial ``x`` and ``y`` pixel position(s) of the center\n        position.  A cutout image centered on this position be used to\n        calculate the centroid.\n\n    box_size : int or array-like of int, optional\n        The size of the cutout image along each axis.  If ``box_size``\n        is a number, then a square cutout of ``box_size`` will be\n        created.  If ``box_size`` has two elements, they should be in\n        ``(ny, nx)`` order.\n\n    footprint : `~numpy.ndarray` of bools, optional\n        A 2D boolean array where `True` values describe the local\n        footprint region to cutout.  ``footprint`` can be used to create\n        a non-rectangular cutout image, in which case the input ``xpos``\n        and ``ypos`` represent the center of the minimal bounding box\n        for the input ``footprint``.  ``box_size=(n, m)`` is equivalent\n        to ``footprint=np.ones((n, m))``.  Either ``box_size`` or\n        ``footprint`` must be defined.  If they are both defined, then\n        ``footprint`` overrides ``box_size``.\n\n    mask : array_like, bool, optional\n        A 2D boolean array with the same shape as ``data``, where a\n        `True` value indicates the corresponding element of ``data`` is\n        masked.\n\n    error : array_like, optional\n        The 2D array of the 1-sigma errors of the input ``data``.\n        ``error`` must have the same shape as ``data``.  ``error`` will\n        be used only if supported by the input ``centroid_func``.\n\n    centroid_func : callable, optional\n        A callable object (e.g. function or class) that is used to\n        calculate the centroid of a 2D array.  The ``centroid_func``\n        must accept a 2D `~numpy.ndarray`, have a ``mask`` keyword and\n        optionally an ``error`` keyword.  The callable object must\n        return a tuple of two 1D `~numpy.ndarray`\\\\s, representing the x\n        and y centroids.  The default is\n        `~photutils.centroids.centroid_com`.\n\n    Returns\n    -------\n    xcentroid, ycentroid : `~numpy.ndarray`\n        The ``x`` and ``y`` pixel position(s) of the centroids.\n    \"\"\"\n\n    xpos = np.atleast_1d(xpos)\n    ypos = np.atleast_1d(ypos)\n    if xpos.ndim != 1:\n        raise ValueError('xpos must be a 1D array.')\n    if ypos.ndim != 1:\n        raise ValueError('ypos must be a 1D array.')\n\n    if footprint is None:\n        if box_size is None:\n            raise ValueError('box_size or footprint must be defined.')\n        else:\n            box_size = np.atleast_1d(box_size)\n            if len(box_size) == 1:\n                box_size = np.repeat(box_size, 2)\n            if len(box_size) != 2:\n                raise ValueError('box_size must have 1 or 2 elements.')\n\n        footprint = np.ones(box_size, dtype=bool)\n    else:\n        footprint = np.asanyarray(footprint, dtype=bool)\n        if footprint.ndim != 2:\n            raise ValueError('footprint must be a 2D array.')\n\n    use_error = False\n    spec = inspect.getfullargspec(centroid_func)\n    if 'mask' not in spec.args:\n        raise ValueError('The input \"centroid_func\" must have a \"mask\" '\n                         'keyword.')\n    if 'error' in spec.args:\n        use_error = True\n\n    xcentroids = []\n    ycentroids = []\n    for xp, yp in zip(xpos, ypos):\n        slices_large, slices_small = overlap_slices(data.shape,\n                                                    footprint.shape, (yp, xp))\n        data_cutout = data[slices_large]\n\n        mask_cutout = None\n        if mask is not None:\n            mask_cutout = mask[slices_large]\n\n        footprint_mask = ~footprint\n        # trim footprint mask if partial overlap on the data\n        footprint_mask = footprint_mask[slices_small]\n\n        if mask_cutout is None:\n            mask_cutout = footprint_mask\n        else:\n            # combine the input mask and footprint mask\n            mask_cutout = np.logical_or(mask_cutout, footprint_mask)\n\n        if error is not None and use_error:\n            error_cutout = error[slices_large]\n            xcen, ycen = centroid_func(data_cutout, mask=mask_cutout,\n                                       error=error_cutout)\n        else:\n            xcen, ycen = centroid_func(data_cutout, mask=mask_cutout)\n\n        xcentroids.append(xcen + slices_large[1].start)\n        ycentroids.append(ycen + slices_large[0].start)\n\n    return np.array(xcentroids), np.array(ycentroids)", "response": "Calculate the centroid of sources at the defined positions."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef evaluate(self, x, y, flux, x_0, y_0):\n\n        # Convert x and y to index arrays\n        x = (x - x_0 + 0.5 + self.prf_shape[1] // 2).astype('int')\n        y = (y - y_0 + 0.5 + self.prf_shape[0] // 2).astype('int')\n\n        # Get subpixel indices\n        y_sub, x_sub = subpixel_indices((y_0, x_0), self.subsampling)\n\n        # Out of boundary masks\n        x_bound = np.logical_or(x < 0, x >= self.prf_shape[1])\n        y_bound = np.logical_or(y < 0, y >= self.prf_shape[0])\n        out_of_bounds = np.logical_or(x_bound, y_bound)\n\n        # Set out of boundary indices to zero\n        x[x_bound] = 0\n        y[y_bound] = 0\n        result = flux * self._prf_array[int(y_sub), int(x_sub)][y, x]\n\n        # Set out of boundary values to zero\n        result[out_of_bounds] = 0\n        return result", "response": "Evaluate the Discrete PRF model."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_from_image(cls, imdata, positions, size, fluxes=None,\n                          mask=None, mode='mean', subsampling=1,\n                          fix_nan=False):\n        \"\"\"\n        Create a discrete point response function (PRF) from image data.\n\n        Given a list of positions and size this function estimates an\n        image of the PRF by extracting and combining the individual PRFs\n        from the given positions.\n\n        NaN values are either ignored by passing a mask or can be\n        replaced by the mirrored value with respect to the center of the\n        PRF.\n\n        Note that if fluxes are *not* specified explicitly, it will be\n        flux estimated from an aperture of the same size as the PRF\n        image. This does *not* account for aperture corrections so often\n        will *not* be what you want for anything other than quick-look\n        needs.\n\n        Parameters\n        ----------\n        imdata : array\n            Data array with the image to extract the PRF from\n        positions : List or array or `~astropy.table.Table`\n            List of pixel coordinate source positions to use in creating\n            the PRF.  If this is a `~astropy.table.Table` it must have\n            columns called ``x_0`` and ``y_0``.\n        size : odd int\n            Size of the quadratic PRF image in pixels.\n        mask : bool array, optional\n            Boolean array to mask out bad values.\n        fluxes : array, optional\n            Object fluxes to normalize extracted PRFs. If not given (or\n            None), the flux is estimated from an aperture of the same\n            size as the PRF image.\n        mode : {'mean', 'median'}\n            One of the following modes to combine the extracted PRFs:\n                * 'mean':  Take the pixelwise mean of the extracted PRFs.\n                * 'median':  Take the pixelwise median of the extracted PRFs.\n        subsampling : int\n            Factor of subsampling of the PRF (default = 1).\n        fix_nan : bool\n            Fix NaN values in the data by replacing it with the\n            mirrored value. Assuming that the PRF is symmetrical.\n\n        Returns\n        -------\n        prf : `photutils.psf.sandbox.DiscretePRF`\n            Discrete PRF model estimated from data.\n        \"\"\"\n\n        # Check input array type and dimension.\n        if np.iscomplexobj(imdata):\n            raise TypeError('Complex type not supported')\n        if imdata.ndim != 2:\n            raise ValueError('{0}-d array not supported. '\n                             'Only 2-d arrays supported.'.format(imdata.ndim))\n        if size % 2 == 0:\n            raise TypeError(\"Size must be odd.\")\n\n        if fluxes is not None and len(fluxes) != len(positions):\n            raise TypeError('Position and flux arrays must be of equal '\n                            'length.')\n\n        if mask is None:\n            mask = np.isnan(imdata)\n\n        if isinstance(positions, (list, tuple)):\n            positions = np.array(positions)\n\n        if isinstance(positions, Table) or \\\n                (isinstance(positions, np.ndarray) and\n                 positions.dtype.names is not None):\n            # One can do clever things like\n            # positions['x_0', 'y_0'].as_array().view((positions['x_0'].dtype,\n            #                                          2))\n            # but that requires positions['x_0'].dtype is\n            # positions['y_0'].dtype.\n            # Better do something simple to allow type promotion if required.\n            pos = np.empty((len(positions), 2))\n            pos[:, 0] = positions['x_0']\n            pos[:, 1] = positions['y_0']\n            positions = pos\n\n        if isinstance(fluxes, (list, tuple)):\n            fluxes = np.array(fluxes)\n\n        if mode == 'mean':\n            combine = np.ma.mean\n        elif mode == 'median':\n            combine = np.ma.median\n        else:\n            raise Exception('Invalid mode to combine prfs.')\n\n        data_internal = np.ma.array(data=imdata, mask=mask)\n        prf_model = np.ndarray(shape=(subsampling, subsampling, size, size))\n        positions_subpixel_indices = \\\n            np.array([subpixel_indices(_, subsampling) for _ in positions],\n                     dtype=np.int)\n\n        for i in range(subsampling):\n            for j in range(subsampling):\n                extracted_sub_prfs = []\n                sub_prf_indices = np.all(positions_subpixel_indices == [j, i],\n                                         axis=1)\n                if not sub_prf_indices.any():\n                    raise ValueError('The source coordinates do not sample '\n                                     'all sub-pixel positions. Reduce the '\n                                     'value of the subsampling parameter.')\n\n                positions_sub_prfs = positions[sub_prf_indices]\n                for k, position in enumerate(positions_sub_prfs):\n                    x, y = position\n                    extracted_prf = extract_array(data_internal, (size, size),\n                                                  (y, x))\n                    # Check shape to exclude incomplete PRFs at the boundaries\n                    # of the image\n                    if (extracted_prf.shape == (size, size) and\n                            np.ma.sum(extracted_prf) != 0):\n                        # Replace NaN values by mirrored value, with respect\n                        # to the prf's center\n                        if fix_nan:\n                            prf_nan = extracted_prf.mask\n                            if prf_nan.any():\n                                if (prf_nan.sum() > 3 or\n                                        prf_nan[size // 2, size // 2]):\n                                    continue\n                                else:\n                                    extracted_prf = mask_to_mirrored_num(\n                                        extracted_prf, prf_nan,\n                                        (size // 2, size // 2))\n                        # Normalize and add extracted PRF to data cube\n                        if fluxes is None:\n                            extracted_prf_norm = (np.ma.copy(extracted_prf) /\n                                                  np.ma.sum(extracted_prf))\n                        else:\n                            fluxes_sub_prfs = fluxes[sub_prf_indices]\n                            extracted_prf_norm = (np.ma.copy(extracted_prf) /\n                                                  fluxes_sub_prfs[k])\n                        extracted_sub_prfs.append(extracted_prf_norm)\n                    else:\n                        continue\n                prf_model[i, j] = np.ma.getdata(\n                    combine(np.ma.dstack(extracted_sub_prfs), axis=2))\n        return cls(prf_model, subsampling=subsampling)", "response": "Create a discrete point response function from an image."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _reproject(wcs1, wcs2):\n\n        import gwcs\n\n        forward_origin = []\n        if isinstance(wcs1, fitswcs.WCS):\n            forward = wcs1.all_pix2world\n            forward_origin = [0]\n        elif isinstance(wcs2, gwcs.wcs.WCS):\n            forward = wcs1.forward_transform\n        else:\n            raise ValueError('wcs1 must be an astropy.wcs.WCS or '\n                             'gwcs.wcs.WCS object.')\n\n        inverse_origin = []\n        if isinstance(wcs2, fitswcs.WCS):\n            inverse = wcs2.all_world2pix\n            inverse_origin = [0]\n        elif isinstance(wcs2, gwcs.wcs.WCS):\n            inverse = wcs2.forward_transform.inverse\n        else:\n            raise ValueError('wcs2 must be an astropy.wcs.WCS or '\n                             'gwcs.wcs.WCS object.')\n\n        def _reproject_func(x, y):\n            forward_args = [x, y] + forward_origin\n            sky = forward(*forward_args)\n            inverse_args = sky + inverse_origin\n            return inverse(*inverse_args)\n\n        return _reproject_func", "response": "Reproject the WCSs in wcs1 onto the WCSs in wcs2."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts the input x y positions from the original image to the rectified image.", "response": "def to_rectified(self, x, y):\n        \"\"\"\n        Convert the input (x, y) positions from the original\n        (unrectified) image to the rectified image.\n\n        Parameters\n        ----------\n        x, y:  float or array-like of float\n            The zero-index pixel coordinates in the original\n            (unrectified) image.\n\n        Returns\n        -------\n        x, y:  float or array-like\n            The zero-index pixel coordinates in the rectified image.\n        \"\"\"\n\n        return self._reproject(self.wcs_original,\n                               self.wcs_rectified)(x, y)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts the input x y positions from the rectified image to the original image.", "response": "def to_original(self, x, y):\n        \"\"\"\n        Convert the input (x, y) positions from the rectified image to\n        the original (unrectified) image.\n\n        Parameters\n        ----------\n        x, y:  float or array-like of float\n            The zero-index pixel coordinates in the rectified image.\n\n        Returns\n        -------\n        x, y:  float or array-like\n            The zero-index pixel coordinates in the original\n            (unrectified) image.\n        \"\"\"\n\n        return self._reproject(self.wcs_rectified,\n                               self.wcs_original)(x, y)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef calc_total_error(data, bkg_error, effective_gain):\n\n    data = np.asanyarray(data)\n    bkg_error = np.asanyarray(bkg_error)\n\n    inputs = [data, bkg_error, effective_gain]\n    has_unit = [hasattr(x, 'unit') for x in inputs]\n    use_units = all(has_unit)\n    if any(has_unit) and not use_units:\n        raise ValueError('If any of data, bkg_error, or effective_gain has '\n                         'units, then they all must all have units.')\n\n    if use_units:\n        if data.unit != bkg_error.unit:\n            raise ValueError('data and bkg_error must have the same units.')\n\n        count_units = [u.electron, u.photon]\n        datagain_unit = data.unit * effective_gain.unit\n        if datagain_unit not in count_units:\n            raise u.UnitsError('(data * effective_gain) has units of \"{0}\", '\n                               'but it must have count units (e.g. '\n                               'u.electron or u.photon).'\n                               .format(datagain_unit))\n\n    if not isiterable(effective_gain):\n        effective_gain = np.zeros(data.shape) + effective_gain\n    else:\n        effective_gain = np.asanyarray(effective_gain)\n        if effective_gain.shape != data.shape:\n            raise ValueError('If input effective_gain is 2D, then it must '\n                             'have the same shape as the input data.')\n    if np.any(effective_gain <= 0):\n        raise ValueError('effective_gain must be strictly positive '\n                         'everywhere.')\n\n    # This calculation assumes that data and bkg_error have the same\n    # units.  source_variance is calculated to have units of\n    # (data.unit)**2 so that it can be added with bkg_error**2 below.  The\n    # final returned error will have units of data.unit.  np.maximum is\n    # used to ensure that negative data values do not contribute to the\n    # Poisson noise.\n    if use_units:\n        unit = data.unit\n        data = data.value\n        effective_gain = effective_gain.value\n        source_variance = np.maximum(data / effective_gain, 0) * unit**2\n    else:\n        source_variance = np.maximum(data / effective_gain, 0)\n\n    return np.sqrt(bkg_error**2 + source_variance)", "response": "Calculates a total error array combining a background - only error array with the Poisson noise of sources."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_mask(self, method='exact', subpixels=5):\n\n        use_exact, subpixels = self._translate_mask_mode(method, subpixels,\n                                                         rectangle=True)\n\n        if hasattr(self, 'w'):\n            w = self.w\n            h = self.h\n        elif hasattr(self, 'w_out'):    # annulus\n            w = self.w_out\n            h = self.h_out\n            h_in = self.w_in * self.h_out / self.w_out\n        else:\n            raise ValueError('Cannot determine the aperture radius.')\n\n        masks = []\n        for bbox, edges in zip(self.bounding_boxes, self._centered_edges):\n            ny, nx = bbox.shape\n            mask = rectangular_overlap_grid(edges[0], edges[1], edges[2],\n                                            edges[3], nx, ny, w, h,\n                                            self.theta, 0, subpixels)\n\n            # subtract the inner circle for an annulus\n            if hasattr(self, 'w_in'):\n                mask -= rectangular_overlap_grid(edges[0], edges[1], edges[2],\n                                                 edges[3], nx, ny, self.w_in,\n                                                 h_in, self.theta, 0,\n                                                 subpixels)\n\n            masks.append(ApertureMask(mask, bbox))\n\n        return masks", "response": "Convert the aperture to a list of ~photutils. ApertureMask objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_sky(self, wcs, mode='all'):\n\n        sky_params = self._to_sky_params(wcs, mode=mode)\n        return SkyRectangularAperture(**sky_params)", "response": "Converts the aperture to a SkyRectangularAperture object defined in celestial coordinates."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef bounding_boxes(self):\n\n        w2 = self.w_out / 2.\n        h2 = self.h_out / 2.\n        cos_theta = math.cos(self.theta)\n        sin_theta = math.sin(self.theta)\n        dx1 = abs(w2 * cos_theta - h2 * sin_theta)\n        dy1 = abs(w2 * sin_theta + h2 * cos_theta)\n        dx2 = abs(w2 * cos_theta + h2 * sin_theta)\n        dy2 = abs(w2 * sin_theta - h2 * cos_theta)\n        dx = max(dx1, dx2)\n        dy = max(dy1, dy2)\n\n        xmin = self.positions[:, 0] - dx\n        xmax = self.positions[:, 0] + dx\n        ymin = self.positions[:, 1] - dy\n        ymax = self.positions[:, 1] + dy\n\n        return [BoundingBox._from_float(x0, x1, y0, y1)\n                for x0, x1, y0, y1 in zip(xmin, xmax, ymin, ymax)]", "response": "A list of minimal bounding boxes for each position enclosing the rectangular apertures for the exact case."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_sky(self, wcs, mode='all'):\n\n        sky_params = self._to_sky_params(wcs, mode=mode)\n        return SkyRectangularAnnulus(**sky_params)", "response": "Converts the aperture to a SkyRectangularAnnulus object defined in celestial coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_pixel(self, wcs, mode='all'):\n\n        pixel_params = self._to_pixel_params(wcs, mode=mode)\n        return RectangularAperture(**pixel_params)", "response": "Converts the aperture to a RectangularAperture object defined by the WCS and mode parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert the aperture to a RectangularAnnulus object defined in pixel coordinates.", "response": "def to_pixel(self, wcs, mode='all'):\n        \"\"\"\n        Convert the aperture to a `RectangularAnnulus` object defined in\n        pixel coordinates.\n\n        Parameters\n        ----------\n        wcs : `~astropy.wcs.WCS`\n            The world coordinate system (WCS) transformation to use.\n\n        mode : {'all', 'wcs'}, optional\n            Whether to do the transformation including distortions\n            (``'all'``; default) or only including only the core WCS\n            transformation (``'wcs'``).\n\n        Returns\n        -------\n        aperture : `RectangularAnnulus` object\n            A `RectangularAnnulus` object.\n        \"\"\"\n\n        pixel_params = self._to_pixel_params(wcs, mode=mode)\n        return RectangularAnnulus(**pixel_params)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrounding the input to the nearest integer.", "response": "def _py2intround(a):\n    \"\"\"\n    Round the input to the nearest integer.\n\n    If two integers are equally close, rounding is done away from 0.\n    \"\"\"\n\n    data = np.asanyarray(a)\n    value = np.where(data >= 0, np.floor(data + 0.5),\n                     np.ceil(data - 0.5)).astype(int)\n\n    if not hasattr(a, '__iter__'):\n        value = np.asscalar(value)\n\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninterpolating missing data as identified by the mask keyword.", "response": "def _interpolate_missing_data(data, mask, method='cubic'):\n    \"\"\"\n    Interpolate missing data as identified by the ``mask`` keyword.\n\n    Parameters\n    ----------\n    data : 2D `~numpy.ndarray`\n        An array containing the 2D image.\n\n    mask : 2D bool `~numpy.ndarray`\n        A 2D booleen mask array with the same shape as the input\n        ``data``, where a `True` value indicates the corresponding\n        element of ``data`` is masked.  The masked data points are\n        those that will be interpolated.\n\n    method : {'cubic', 'nearest'}, optional\n        The method of used to interpolate the missing data:\n\n        * ``'cubic'``:  Masked data are interpolated using 2D cubic\n            splines.  This is the default.\n\n        * ``'nearest'``:  Masked data are interpolated using\n            nearest-neighbor interpolation.\n\n    Returns\n    -------\n    data_interp : 2D `~numpy.ndarray`\n        The interpolated 2D image.\n    \"\"\"\n\n    from scipy import interpolate\n\n    data_interp = np.array(data, copy=True)\n\n    if len(data_interp.shape) != 2:\n        raise ValueError('data must be a 2D array.')\n\n    if mask.shape != data.shape:\n        raise ValueError('mask and data must have the same shape.')\n\n    y, x = np.indices(data_interp.shape)\n    xy = np.dstack((x[~mask].ravel(), y[~mask].ravel()))[0]\n    z = data_interp[~mask].ravel()\n\n    if method == 'nearest':\n        interpol = interpolate.NearestNDInterpolator(xy, z)\n    elif method == 'cubic':\n        interpol = interpolate.CloughTocher2DInterpolator(xy, z)\n    else:\n        raise ValueError('Unsupported interpolation method.')\n\n    xy_missing = np.dstack((x[mask].ravel(), y[mask].ravel()))[0]\n    data_interp[mask] = interpol(xy_missing)\n\n    return data_interp"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _fit_star(self, epsf, star, fitter, fitter_kwargs,\n                  fitter_has_fit_info, fit_boxsize):\n        \"\"\"\n        Fit an ePSF model to a single star.\n\n        The input ``epsf`` will usually be modified by the fitting\n        routine in this function.  Make a copy before calling this\n        function if the original is needed.\n        \"\"\"\n\n        if fit_boxsize is not None:\n            try:\n                xcenter, ycenter = star.cutout_center\n                large_slc, small_slc = overlap_slices(star.shape,\n                                                      fit_boxsize,\n                                                      (ycenter, xcenter),\n                                                      mode='strict')\n            except (PartialOverlapError, NoOverlapError):\n                warnings.warn('The star at ({0}, {1}) cannot be fit because '\n                              'its fitting region extends beyond the star '\n                              'cutout image.'.format(star.center[0],\n                                                     star.center[1]),\n                              AstropyUserWarning)\n\n                star = copy.deepcopy(star)\n                star._fit_error_status = 1\n\n                return star\n\n            data = star.data[large_slc]\n            weights = star.weights[large_slc]\n\n            # define the origin of the fitting region\n            x0 = large_slc[1].start\n            y0 = large_slc[0].start\n        else:\n            # use the entire cutout image\n            data = star.data\n            weights = star.weights\n\n            # define the origin of the fitting region\n            x0 = 0\n            y0 = 0\n\n        scaled_data = data / np.prod(epsf._oversampling)\n\n        # define positions in the ePSF oversampled grid\n        yy, xx = np.indices(data.shape, dtype=np.float)\n        xx = (xx - (star.cutout_center[0] - x0)) * epsf._oversampling[0]\n        yy = (yy - (star.cutout_center[1] - y0)) * epsf._oversampling[1]\n\n        # define the initial guesses for fitted flux and shifts\n        epsf.flux = star.flux\n        epsf.x_0 = 0.0\n        epsf.y_0 = 0.0\n\n        # create copy to avoid overwriting original oversampling factor\n        _epsf = epsf.copy()\n        _epsf._oversampling = np.array([1., 1.])\n\n        try:\n            fitted_epsf = fitter(model=_epsf, x=xx, y=yy, z=scaled_data,\n                                 weights=weights, **fitter_kwargs)\n        except TypeError:\n            # fitter doesn't support weights\n            fitted_epsf = fitter(model=_epsf, x=xx, y=yy, z=scaled_data,\n                                 **fitter_kwargs)\n\n        fit_error_status = 0\n        if fitter_has_fit_info:\n            fit_info = copy.copy(fitter.fit_info)\n\n            if 'ierr' in fit_info and fit_info['ierr'] not in [1, 2, 3, 4]:\n                fit_error_status = 2    # fit solution was not found\n        else:\n            fit_info = None\n\n        # compute the star's fitted position\n        x_center = (star.cutout_center[0] +\n                    (fitted_epsf.x_0.value / epsf._oversampling[0]))\n        y_center = (star.cutout_center[1] +\n                    (fitted_epsf.y_0.value / epsf._oversampling[1]))\n\n        star = copy.deepcopy(star)\n        star.cutout_center = (x_center, y_center)\n\n        # set the star's flux to the ePSF-fitted flux\n        star.flux = fitted_epsf.flux.value\n\n        star._fit_info = fit_info\n        star._fit_error_status = fit_error_status\n\n        return star", "response": "Fit an ePSF model to a single star."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninitializing 2D image - type parameters that can accept either a single or two values.", "response": "def _init_img_params(param):\n        \"\"\"\n        Initialize 2D image-type parameters that can accept either a\n        single or two values.\n        \"\"\"\n\n        if param is not None:\n            param = np.atleast_1d(param)\n            if len(param) == 1:\n                param = np.repeat(param, 2)\n\n        return param"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _create_initial_epsf(self, stars):\n\n        oversampling = self.oversampling\n        shape = self.shape\n\n        # define the ePSF shape\n        if shape is not None:\n            shape = np.atleast_1d(shape).astype(int)\n            if len(shape) == 1:\n                shape = np.repeat(shape, 2)\n        else:\n            x_shape = np.int(np.ceil(stars._max_shape[1] *\n                                     oversampling[0]))\n            y_shape = np.int(np.ceil(stars._max_shape[0] *\n                                     oversampling[1]))\n            shape = np.array((y_shape, x_shape))\n\n        # ensure odd sizes\n        shape = [(i + 1) if i % 2 == 0 else i for i in shape]\n\n        data = np.zeros(shape, dtype=np.float)\n        xcenter = (shape[1] - 1) / 2.\n        ycenter = (shape[0] - 1) / 2.\n\n        epsf = EPSFModel(data=data, origin=(xcenter, ycenter),\n                         normalize=False, oversampling=oversampling)\n\n        return epsf", "response": "Create an initial ePSF model object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _resample_residual(self, star, epsf):\n\n        # find the integer index of EPSFStar pixels in the oversampled\n        # ePSF grid\n        x = epsf._oversampling[0] * star._xidx_centered\n        y = epsf._oversampling[1] * star._yidx_centered\n        epsf_xcenter, epsf_ycenter = epsf.origin\n        xidx = _py2intround(x + epsf_xcenter)\n        yidx = _py2intround(y + epsf_ycenter)\n\n        mask = np.logical_and(np.logical_and(xidx >= 0, xidx < epsf.shape[1]),\n                              np.logical_and(yidx >= 0, yidx < epsf.shape[0]))\n        xidx = xidx[mask]\n        yidx = yidx[mask]\n\n        # Compute the normalized residual image by subtracting the\n        # normalized ePSF model from the normalized star at the location\n        # of the star in the undersampled grid.  Then, resample the\n        # normalized residual image in the oversampled ePSF grid.\n        # [(star - (epsf * xov * yov)) / (xov * yov)]\n        # --> [(star / (xov * yov)) - epsf]\n        stardata = ((star._data_values_normalized / np.prod(epsf._oversampling)) -\n                    epsf.evaluate(x=x, y=y, flux=1.0, x_0=0.0, y_0=0.0,\n                                  use_oversampling=False))\n\n        resampled_img = np.full(epsf.shape, np.nan)\n        resampled_img[yidx, xidx] = stardata[mask]\n\n        return resampled_img", "response": "Resample the residual image in the oversampled ePSF grid."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute normalized residual images for all the input stars. Parameters ---------- stars : `EPSFStars` object The stars used to build the ePSF. epsf : `EPSFModel` object The ePSF model. Returns ------- star_imgs : 3D `~numpy.ndarray` A 3D cube containing the resampled residual images.", "response": "def _resample_residuals(self, stars, epsf):\n        \"\"\"\n        Compute normalized residual images for all the input stars.\n\n        Parameters\n        ----------\n        stars : `EPSFStars` object\n            The stars used to build the ePSF.\n\n        epsf : `EPSFModel` object\n            The ePSF model.\n\n        Returns\n        -------\n        star_imgs : 3D `~numpy.ndarray`\n            A 3D cube containing the resampled residual images.\n        \"\"\"\n\n        shape = (stars.n_good_stars, epsf.shape[0], epsf.shape[1])\n        star_imgs = np.zeros(shape)\n        for i, star in enumerate(stars.all_good_stars):\n            star_imgs[i, :, :] = self._resample_residual(star, epsf)\n\n        return star_imgs"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsmooth the ePSF array by convolving it with a kernel.", "response": "def _smooth_epsf(self, epsf_data):\n        \"\"\"\n        Smooth the ePSF array by convolving it with a kernel.\n\n        Parameters\n        ----------\n        epsf_data : 2D `~numpy.ndarray`\n            A 2D array containing the ePSF image.\n\n        Returns\n        -------\n        result : 2D `~numpy.ndarray`\n            The smoothed (convolved) ePSF data.\n        \"\"\"\n\n        from scipy.ndimage import convolve\n\n        if self.smoothing_kernel is None:\n            return epsf_data\n\n        elif self.smoothing_kernel == 'quartic':\n            # from Polynomial2D fit with degree=4 to 5x5 array of\n            # zeros with 1. at the center\n            # Polynomial2D(4, c0_0=0.04163265, c1_0=-0.76326531,\n            #              c2_0=0.99081633, c3_0=-0.4, c4_0=0.05,\n            #              c0_1=-0.76326531, c0_2=0.99081633, c0_3=-0.4,\n            #              c0_4=0.05, c1_1=0.32653061, c1_2=-0.08163265,\n            #              c1_3=0., c2_1=-0.08163265, c2_2=0.02040816,\n            #              c3_1=-0.)>\n            kernel = np.array(\n                [[+0.041632, -0.080816, 0.078368, -0.080816, +0.041632],\n                 [-0.080816, -0.019592, 0.200816, -0.019592, -0.080816],\n                 [+0.078368, +0.200816, 0.441632, +0.200816, +0.078368],\n                 [-0.080816, -0.019592, 0.200816, -0.019592, -0.080816],\n                 [+0.041632, -0.080816, 0.078368, -0.080816, +0.041632]])\n\n        elif self.smoothing_kernel == 'quadratic':\n            # from Polynomial2D fit with degree=2 to 5x5 array of\n            # zeros with 1. at the center\n            # Polynomial2D(2, c0_0=-0.07428571, c1_0=0.11428571,\n            #              c2_0=-0.02857143, c0_1=0.11428571,\n            #              c0_2=-0.02857143, c1_1=-0.)\n            kernel = np.array(\n                [[-0.07428311, 0.01142786, 0.03999952, 0.01142786,\n                  -0.07428311],\n                 [+0.01142786, 0.09714283, 0.12571449, 0.09714283,\n                  +0.01142786],\n                 [+0.03999952, 0.12571449, 0.15428215, 0.12571449,\n                  +0.03999952],\n                 [+0.01142786, 0.09714283, 0.12571449, 0.09714283,\n                  +0.01142786],\n                 [-0.07428311, 0.01142786, 0.03999952, 0.01142786,\n                  -0.07428311]])\n\n        elif isinstance(self.smoothing_kernel, np.ndarray):\n            kernel = self.kernel\n\n        else:\n            raise TypeError('Unsupported kernel.')\n\n        return convolve(epsf_data, kernel)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrecenters the ePSF data and return the recentered data.", "response": "def _recenter_epsf(self, epsf_data, epsf, centroid_func=centroid_com,\n                       box_size=5, maxiters=20, center_accuracy=1.0e-4):\n        \"\"\"\n        Calculate the center of the ePSF data and shift the data so the\n        ePSF center is at the center of the ePSF data array.\n\n        Parameters\n        ----------\n        epsf_data : 2D `~numpy.ndarray`\n            A 2D array containing the ePSF image.\n\n        epsf : `EPSFModel` object\n            The ePSF model.\n\n        centroid_func : callable, optional\n            A callable object (e.g. function or class) that is used to\n            calculate the centroid of a 2D array.  The callable must\n            accept a 2D `~numpy.ndarray`, have a ``mask`` keyword and\n            optionally an ``error`` keyword.  The callable object must\n            return a tuple of two 1D `~numpy.ndarray`\\\\s, representing\n            the x and y centroids.  The default is\n            `~photutils.centroids.centroid_com`.\n\n        recentering_boxsize : float or tuple of two floats, optional\n            The size (in pixels) of the box used to calculate the\n            centroid of the ePSF during each build iteration.  If a\n            single integer number is provided, then a square box will be\n            used.  If two values are provided, then they should be in\n            ``(ny, nx)`` order.  The default is 5.\n\n        maxiters : int, optional\n            The maximum number of recentering iterations to perform.\n            The default is 20.\n\n        center_accuracy : float, optional\n            The desired accuracy for the centers of stars.  The building\n            iterations will stop if the center of the ePSF changes by\n            less than ``center_accuracy`` pixels between iterations.\n            The default is 1.0e-4.\n\n        Returns\n        -------\n        result : 2D `~numpy.ndarray`\n            The recentered ePSF data.\n        \"\"\"\n\n        # Define an EPSFModel for the input data.  This EPSFModel will be\n        # used to evaluate the model on a shifted pixel grid to place the\n        # centroid at the array center.\n        epsf = EPSFModel(data=epsf_data, origin=epsf.origin, normalize=False,\n                         oversampling=epsf.oversampling)\n\n        epsf.fill_value = 0.0\n        xcenter, ycenter = epsf.origin\n\n        dx_total = 0\n        dy_total = 0\n        y, x = np.indices(epsf_data.shape, dtype=np.float)\n\n        iter_num = 0\n        center_accuracy_sq = center_accuracy ** 2\n        center_dist_sq = center_accuracy_sq + 1.e6\n        center_dist_sq_prev = center_dist_sq + 1\n        while (iter_num < maxiters and\n               center_dist_sq >= center_accuracy_sq):\n\n            iter_num += 1\n\n            # extract a cutout from the ePSF\n            slices_large, slices_small = overlap_slices(epsf_data.shape,\n                                                        box_size,\n                                                        (ycenter, xcenter))\n            epsf_cutout = epsf_data[slices_large]\n            mask = ~np.isfinite(epsf_cutout)\n\n            # find a new center position\n            xcenter_new, ycenter_new = centroid_func(epsf_cutout, mask=mask)\n            xcenter_new += slices_large[1].start\n            ycenter_new += slices_large[0].start\n\n            # calculate the shift\n            dx = xcenter - xcenter_new\n            dy = ycenter - ycenter_new\n            center_dist_sq = dx**2 + dy**2\n            if center_dist_sq >= center_dist_sq_prev:  # don't shift\n                break\n            center_dist_sq_prev = center_dist_sq\n\n            # Resample the ePSF data to a shifted grid to place the\n            # centroid in the center of the central pixel.  The shift is\n            # always performed on the input epsf_data.\n            dx_total += dx    # accumulated shifts for the input epsf_data\n            dy_total += dy\n            epsf_data = epsf.evaluate(x=x, y=y, flux=1.0,\n                                      x_0=xcenter + dx_total,\n                                      y_0=ycenter + dy_total,\n                                      use_oversampling=False)\n\n        return epsf_data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild an ePSF model for the given stars.", "response": "def _build_epsf_step(self, stars, epsf=None):\n        \"\"\"\n        A single iteration of improving an ePSF.\n\n        Parameters\n        ----------\n        stars : `EPSFStars` object\n            The stars used to build the ePSF.\n\n        epsf : `EPSFModel` object, optional\n            The initial ePSF model.  If not input, then the ePSF will be\n            built from scratch.\n\n        Returns\n        -------\n        epsf : `EPSFModel` object\n            The updated ePSF.\n        \"\"\"\n\n        if len(stars) < 1:\n            raise ValueError('stars must contain at least one EPSFStar or '\n                             'LinkedEPSFStar object.')\n\n        if epsf is None:\n            # create an initial ePSF (array of zeros)\n            epsf = self._create_initial_epsf(stars)\n        else:\n            # improve the input ePSF\n            epsf = copy.deepcopy(epsf)\n\n        # compute a 3D stack of 2D residual images\n        residuals = self._resample_residuals(stars, epsf)\n\n        self._residuals.append(residuals)\n\n        # compute the sigma-clipped median along the 3D stack\n        with warnings.catch_warnings():\n            warnings.simplefilter('ignore', category=RuntimeWarning)\n            warnings.simplefilter('ignore', category=AstropyUserWarning)\n            residuals = self.sigclip(residuals, axis=0, masked=False,\n                                     return_bounds=False)\n            if HAS_BOTTLENECK:\n                residuals = bottleneck.nanmedian(residuals, axis=0)\n            else:\n                residuals = np.nanmedian(residuals, axis=0)\n\n        self._residuals_sigclip.append(residuals)\n\n        # interpolate any missing data (np.nan)\n        mask = ~np.isfinite(residuals)\n        if np.any(mask):\n            residuals = _interpolate_missing_data(residuals, mask,\n                                                  method='cubic')\n\n            # fill any remaining nans (outer points) with zeros\n            residuals[~np.isfinite(residuals)] = 0.\n\n        self._residuals_interp.append(residuals)\n\n        # add the residuals to the previous ePSF image\n        new_epsf = epsf.normalized_data + residuals\n\n        # smooth the ePSF\n        new_epsf = self._smooth_epsf(new_epsf)\n\n        # recenter the ePSF\n        new_epsf = self._recenter_epsf(new_epsf, epsf,\n                                       centroid_func=self.recentering_func,\n                                       box_size=self.recentering_boxsize,\n                                       maxiters=self.recentering_maxiters,\n                                       center_accuracy=1.0e-4)\n\n        # normalize the ePSF data\n        new_epsf /= np.sum(new_epsf, dtype=np.float64)\n\n        # return the new ePSF object\n        xcenter = (new_epsf.shape[1] - 1) / 2.\n        ycenter = (new_epsf.shape[0] - 1) / 2.\n\n        epsf_new = EPSFModel(data=new_epsf, origin=(xcenter, ycenter),\n                             normalize=False, oversampling=epsf.oversampling)\n\n        return epsf_new"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef data_properties(data, mask=None, background=None):\n\n    from ..segmentation import SourceProperties  # prevent circular imports\n\n    segment_image = np.ones(data.shape, dtype=np.int)\n\n    return SourceProperties(data, segment_image, label=1, mask=mask,\n                            background=background)", "response": "Calculate the morphological properties of a 2D array."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes the inverse normalization factor of the raw image data.", "response": "def _compute_raw_image_norm(self, data):\n        \"\"\"\n        Helper function that computes the uncorrected inverse normalization\n        factor of input image data. This quantity is computed as the\n        *sum of all pixel values*.\n\n        .. note::\n            This function is intended to be overriden in a subclass if one\n            desires to change the way the normalization factor is computed.\n\n        \"\"\"\n        return np.sum(self._data, dtype=np.float64)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_oversampling(self, value):\n\n        try:\n            value = np.atleast_1d(value).astype(float)\n            if len(value) == 1:\n                value = np.repeat(value, 2)\n        except ValueError:\n            raise ValueError('Oversampling factors must be float')\n        if np.any(value <= 0):\n            raise ValueError('Oversampling factors must be greater than 0')\n\n        self._oversampling = value", "response": "Sets the oversampling factor of the log entry."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef compute_interpolator(self, ikwargs={}):\n        from scipy.interpolate import RectBivariateSpline\n\n        if 'degree' in ikwargs:\n            degree = ikwargs['degree']\n            if hasattr(degree, '__iter__') and len(degree) == 2:\n                degx = int(degree[0])\n                degy = int(degree[1])\n            else:\n                degx = int(degree)\n                degy = int(degree)\n            if degx < 0 or degy < 0:\n                raise ValueError(\"Interpolator degree must be a non-negative \"\n                                 \"integer\")\n        else:\n            degx = 3\n            degy = 3\n\n        if 's' in ikwargs:\n            smoothness = ikwargs['s']\n        else:\n            smoothness = 0\n\n        x = np.arange(self._nx, dtype=np.float)\n        y = np.arange(self._ny, dtype=np.float)\n        self.interpolator = RectBivariateSpline(\n            x, y, self._data.T, kx=degx, ky=degy, s=smoothness\n        )\n\n        self._store_interpolator_kwargs(ikwargs)", "response": "This method computes the interpolating spline for the current entry point."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nevaluate the model on some input variables and provided model parameters.", "response": "def evaluate(self, x, y, flux, x_0, y_0, use_oversampling=True):\n        \"\"\"\n        Evaluate the model on some input variables and provided model\n        parameters.\n\n        Parameters\n        ----------\n        use_oversampling : bool, optional\n            Whether to use the oversampling factor to calculate the\n            model pixel indices.  The default is `True`, which means the\n            input indices will be multipled by this factor.\n        \"\"\"\n\n        if use_oversampling:\n            xi = self._oversampling[0] * (np.asarray(x) - x_0)\n            yi = self._oversampling[1] * (np.asarray(y) - y_0)\n        else:\n            xi = np.asarray(x) - x_0\n            yi = np.asarray(y) - y_0\n\n        xi += self._x_origin\n        yi += self._y_origin\n\n        f = flux * self._normalization_constant\n        evaluated_model = f * self.interpolator.ev(xi, yi)\n\n        if self._fill_value is not None:\n            # find indices of pixels that are outside the input pixel grid and\n            # set these pixels to the 'fill_value':\n            invalid = (((xi < 0) | (xi > self._nx - 1)) |\n                       ((yi < 0) | (yi > self._ny - 1)))\n            evaluated_model[invalid] = self._fill_value\n\n        return evaluated_model"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding the index of the lower bound where x should be inserted into a.", "response": "def _find_bounds_1d(data, x):\n        \"\"\"\n        Find the index of the lower bound where ``x`` should be inserted\n        into ``a`` to maintain order.\n\n        The index of the upper bound is the index of the lower bound\n        plus 2.  Both bound indices must be within the array.\n\n        Parameters\n        ----------\n        data : 1D `~numpy.ndarray`\n            The 1D array to search.\n\n        x : float\n            The value to insert.\n\n        Returns\n        -------\n        index : int\n            The index of the lower bound.\n        \"\"\"\n\n        idx = np.searchsorted(data, x)\n        if idx == 0:\n            idx0 = 0\n        elif idx == len(data):  # pragma: no cover\n            idx0 = idx - 2\n        else:\n            idx0 = idx - 1\n\n        return idx0"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding the indices of the grid points that are bound by the input PSF.", "response": "def _find_bounding_points(self, x, y):\n        \"\"\"\n        Find the indices of the grid points that bound the input\n        ``(x, y)`` position.\n\n        Parameters\n        ----------\n        x, y : float\n            The ``(x, y)`` position where the PSF is to be evaluated.\n\n        Returns\n        -------\n        indices : list of int\n            A list of indices of the bounding grid points.\n        \"\"\"\n\n        if not np.isscalar(x) or not np.isscalar(y):  # pragma: no cover\n            raise TypeError('x and y must be scalars')\n\n        if (x < self._xgrid_min or x > self._xgrid_max or\n                y < self._ygrid_min or y > self._ygrid_max):  # pragma: no cover\n            raise ValueError('(x, y) position is outside of the region '\n                             'defined by grid of PSF positions')\n\n        x0 = self._find_bounds_1d(self._xgrid, x)\n        y0 = self._find_bounds_1d(self._ygrid, y)\n        points = list(itertools.product(self._xgrid[x0:x0 + 2],\n                                        self._ygrid[y0:y0 + 2]))\n\n        indices = []\n        for xx, yy in points:\n            indices.append(np.argsort(np.hypot(self._grid_xpos - xx,\n                                               self._grid_ypos - yy))[0])\n\n        return indices"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nperform bilinear interpolation of four 2D arrays located at points on a regular grid. Parameters ---------- xyref : list of 4 (x, y) pairs A list of 4 ``(x, y)`` pairs that form a rectangle. refdata : 3D `~numpy.ndarray` A 3D `~numpy.ndarray` of shape ``(4, nx, ny)``. The first axis corresponds to ``xyref``, i.e. ``refdata[0, :, :]`` is the 2D array located at ``xyref[0]``. xi, yi : float The ``(xi, yi)`` point at which to perform the interpolation. The ``(xi, yi)`` point must lie within the rectangle defined by ``xyref``. Returns ------- result : 2D `~numpy.ndarray` The 2D interpolated array.", "response": "def _bilinear_interp(xyref, zref, xi, yi):\n        \"\"\"\n        Perform bilinear interpolation of four 2D arrays located at\n        points on a regular grid.\n\n        Parameters\n        ----------\n        xyref : list of 4 (x, y) pairs\n            A list of 4 ``(x, y)`` pairs that form a rectangle.\n\n        refdata : 3D `~numpy.ndarray`\n            A 3D `~numpy.ndarray` of shape ``(4, nx, ny)``.  The first\n            axis corresponds to ``xyref``, i.e. ``refdata[0, :, :]`` is\n            the 2D array located at ``xyref[0]``.\n\n        xi, yi : float\n            The ``(xi, yi)`` point at which to perform the\n            interpolation.  The ``(xi, yi)`` point must lie within the\n            rectangle defined by ``xyref``.\n\n        Returns\n        -------\n        result : 2D `~numpy.ndarray`\n            The 2D interpolated array.\n        \"\"\"\n\n        if len(xyref) != 4:\n            raise ValueError('xyref must contain only 4 (x, y) pairs')\n\n        if zref.shape[0] != 4:\n            raise ValueError('zref must have a length of 4 on the first '\n                             'axis.')\n\n        xyref = [tuple(i) for i in xyref]\n        idx = sorted(range(len(xyref)), key=xyref.__getitem__)\n        xyref = sorted(xyref)   # sort by x, then y\n        (x0, y0), (_x0, y1), (x1, _y0), (_x1, _y1) = xyref\n\n        if x0 != _x0 or x1 != _x1 or y0 != _y0 or y1 != _y1:\n            raise ValueError('The refxy points do not form a rectangle.')\n\n        if not np.isscalar(xi):\n            xi = xi[0]\n        if not np.isscalar(yi):\n            yi = yi[0]\n\n        if not x0 <= xi <= x1 or not y0 <= yi <= y1:\n            raise ValueError('The (x, y) input is not within the rectangle '\n                             'defined by xyref.')\n\n        data = np.asarray(zref)[idx]\n        weights = np.array([(x1 - xi) * (y1 - yi), (x1 - xi) * (yi - y0),\n                            (xi - x0) * (y1 - yi), (xi - x0) * (yi - y0)])\n        norm = (x1 - x0) * (y1 - y0)\n\n        return np.sum(data * weights[:, None, None], axis=0) / norm"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nevaluate the gridded PSF model at the input parameters.", "response": "def evaluate(self, x, y, flux, x_0, y_0):\n        \"\"\"\n        Evaluate the `GriddedPSFModel` for the input parameters.\n        \"\"\"\n\n        # NOTE: this is needed because the PSF photometry routines input\n        # length-1 values instead of scalars.  TODO: fix the photometry\n        # routines.\n        if not np.isscalar(x_0):\n            x_0 = x_0[0]\n        if not np.isscalar(y_0):\n            y_0 = y_0[0]\n\n        if (x_0 < self._xgrid_min or x_0 > self._xgrid_max or\n                y_0 < self._ygrid_min or y_0 > self._ygrid_max):\n\n            # position is outside of the grid, so simply use the\n            # closest reference PSF\n            self._ref_indices = np.argsort(np.hypot(self._grid_xpos - x_0,\n                                                    self._grid_ypos - y_0))[0]\n            self._psf_interp = self.data[self._ref_indices, :, :]\n        else:\n            # find the four bounding reference PSFs and interpolate\n            self._ref_indices = self._find_bounding_points(x_0, y_0)\n            xyref = np.array(self.grid_xypos)[self._ref_indices]\n            psfs = self.data[self._ref_indices, :, :]\n\n            self._psf_interp = self._bilinear_interp(xyref, psfs, x_0, y_0)\n\n        # now evaluate the PSF at the (x_0, y_0) subpixel position on\n        # the input (x, y) values\n        psfmodel = FittableImageModel(self._psf_interp,\n                                      oversampling=self.oversampling)\n\n        return psfmodel.evaluate(x, y, flux, x_0, y_0)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef evaluate(self, x, y, flux, x_0, y_0, sigma):\n\n        return (flux / 4 *\n                ((self._erf((x - x_0 + 0.5) / (np.sqrt(2) * sigma)) -\n                  self._erf((x - x_0 - 0.5) / (np.sqrt(2) * sigma))) *\n                 (self._erf((y - y_0 + 0.5) / (np.sqrt(2) * sigma)) -\n                  self._erf((y - y_0 - 0.5) / (np.sqrt(2) * sigma)))))", "response": "Evaluate the Gaussian PSF model."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts an isophote list to a list of astropy. table. QTable.", "response": "def _isophote_list_to_table(isophote_list):\n    \"\"\"\n    Convert an `~photutils.isophote.IsophoteList` instance to\n    a `~astropy.table.QTable`.\n\n    Parameters\n    ----------\n    isophote_list : list of `~photutils.isophote.Isophote` or a `~photutils.isophote.IsophoteList` instance\n        A list of isophotes.\n\n    Returns\n    -------\n    result : `~astropy.table.QTable`\n        An astropy QTable with the main isophote parameters.\n    \"\"\"\n\n    properties = OrderedDict()\n    properties['sma'] = 'sma'\n    properties['intens'] = 'intens'\n    properties['int_err'] = 'intens_err'\n    properties['eps'] = 'ellipticity'\n    properties['ellip_err'] = 'ellipticity_err'\n    properties['pa'] = 'pa'\n    properties['pa_err'] = 'pa_err'\n    properties['grad_r_error'] = 'grad_rerr'\n    properties['ndata'] = 'ndata'\n    properties['nflag'] = 'flag'\n    properties['niter'] = 'niter'\n    properties['stop_code'] = 'stop_code'\n\n    isotable = QTable()\n\n    for k, v in properties.items():\n        isotable[v] = np.array([getattr(iso, k) for iso in isophote_list])\n\n        if k in ('pa', 'pa_err'):\n            isotable[v] = isotable[v] * 180. / np.pi * u.deg\n\n    return isotable"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes integrated flux inside an ellipse.", "response": "def _compute_fluxes(self):\n        \"\"\"\n        Compute integrated flux inside ellipse, as well as inside a\n        circle defined with the same semimajor axis.\n\n        Pixels in a square section enclosing circle are scanned; the\n        distance of each pixel to the isophote center is compared both\n        with the semimajor axis length and with the length of the\n        ellipse radius vector, and integrals are updated if the pixel\n        distance is smaller.\n        \"\"\"\n\n        # Compute limits of square array that encloses circle.\n        sma = self.sample.geometry.sma\n        x0 = self.sample.geometry.x0\n        y0 = self.sample.geometry.y0\n        xsize = self.sample.image.shape[1]\n        ysize = self.sample.image.shape[0]\n\n        imin = max(0, int(x0 - sma - 0.5) - 1)\n        jmin = max(0, int(y0 - sma - 0.5) - 1)\n        imax = min(xsize, int(x0 + sma + 0.5) + 1)\n        jmax = min(ysize, int(y0 + sma + 0.5) + 1)\n\n        # Integrate\n        if (jmax-jmin > 1) and (imax-imin) > 1:\n            y, x = np.mgrid[jmin:jmax, imin:imax]\n            radius, angle = self.sample.geometry.to_polar(x, y)\n            radius_e = self.sample.geometry.radius(angle)\n\n            midx = (radius <= sma)\n            values = self.sample.image[y[midx], x[midx]]\n            tflux_c = np.ma.sum(values)\n            npix_c = np.ma.count(values)\n\n            midx2 = (radius <= radius_e)\n            values = self.sample.image[y[midx2], x[midx2]]\n            tflux_e = np.ma.sum(values)\n            npix_e = np.ma.count(values)\n        else:\n            tflux_e = 0.\n            tflux_c = 0.\n            npix_e = 0\n            npix_c = 0\n\n        return tflux_e, tflux_c, npix_e, npix_c"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute deviations from a perfect ellipse based on the amplitudes and errors for harmonics.", "response": "def _compute_deviations(self, sample, n):\n        \"\"\"\n        Compute deviations from a perfect ellipse, based on the\n        amplitudes and errors for harmonic \"n\". Note that we first\n        subtract the first and second harmonics from the raw data.\n        \"\"\"\n\n        try:\n            coeffs = fit_first_and_second_harmonics(self.sample.values[0],\n                                                    self.sample.values[2])\n            coeffs = coeffs[0]\n            model = first_and_second_harmonic_function(self.sample.values[0],\n                                                       coeffs)\n            residual = self.sample.values[2] - model\n\n            c = fit_upper_harmonic(residual, sample.values[2], n)\n            covariance = c[1]\n            ce = np.diagonal(covariance)\n            c = c[0]\n\n            a = c[1] / self.sma / sample.gradient\n            b = c[2] / self.sma / sample.gradient\n\n            # this comes from the old code. Likely it was based on\n            # empirical experience with the STSDAS task, so we leave\n            # it here without too much thought.\n            gre = self.grad_r_error if self.grad_r_error is not None else 0.64\n\n            a_err = abs(a) * np.sqrt((ce[1] / c[1])**2 + gre**2)\n            b_err = abs(b) * np.sqrt((ce[2] / c[2])**2 + gre**2)\n\n        except Exception:    # we want to catch everything\n            a = b = a_err = b_err = None\n\n        return a, b, a_err, b_err"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute the parameter errors based on the diagonal of the covariance matrix of the four harmonic coefficients for the current resource and the current resource.", "response": "def _compute_errors(self):\n        \"\"\"\n        Compute parameter errors based on the diagonal of the covariance\n        matrix of the four harmonic coefficients for harmonics n=1 and\n        n=2.\n        \"\"\"\n\n        try:\n            coeffs = fit_first_and_second_harmonics(self.sample.values[0],\n                                                    self.sample.values[2])\n            covariance = coeffs[1]\n            coeffs = coeffs[0]\n            model = first_and_second_harmonic_function(self.sample.values[0],\n                                                       coeffs)\n            residual_rms = np.std(self.sample.values[2] - model)\n            errors = np.diagonal(covariance) * residual_rms\n\n            eps = self.sample.geometry.eps\n            pa = self.sample.geometry.pa\n\n            # parameter errors result from direct projection of\n            # coefficient errors.  These showed to be the error estimators\n            # that best convey the errors measured in Monte Carlo\n            # experiments (see Busko 1996; ASPC 101, 139).\n            ea = abs(errors[2] / self.grad)\n            eb = abs(errors[1] * (1. - eps) / self.grad)\n            self.x0_err = np.sqrt((ea * np.cos(pa))**2 + (eb * np.sin(pa))**2)\n            self.y0_err = np.sqrt((ea * np.sin(pa))**2 + (eb * np.cos(pa))**2)\n            self.ellip_err = (abs(2. * errors[4] * (1. - eps) / self.sma /\n                                  self.grad))\n            if (abs(eps) > np.finfo(float).resolution):\n                self.pa_err = (abs(2. * errors[3] * (1. - eps) / self.sma /\n                                   self.grad / (1. - (1. - eps)**2)))\n            else:\n                self.pa_err = 0.\n        except Exception:    # we want to catch everything\n            self.x0_err = self.y0_err = self.pa_err = self.ellip_err = 0."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fix_geometry(self, isophote):\n\n        self.sample.geometry.eps = isophote.sample.geometry.eps\n        self.sample.geometry.pa = isophote.sample.geometry.pa\n        self.sample.geometry.x0 = isophote.sample.geometry.x0\n        self.sample.geometry.y0 = isophote.sample.geometry.y0", "response": "Fix the geometry of a problematic isophote to be identical to the input isophote."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the isophote that has the closest semimajor axis length to the input semimajor axis.", "response": "def get_closest(self, sma):\n        \"\"\"\n        Return the `~photutils.isophote.Isophote` instance that has the\n        closest semimajor axis length to the input semimajor axis.\n\n        Parameters\n        ----------\n        sma : float\n            The semimajor axis length.\n\n        Returns\n        -------\n        isophote : `~photutils.isophote.Isophote` instance\n            The isophote with the closest semimajor axis value.\n        \"\"\"\n\n        index = (np.abs(self.sma - sma)).argmin()\n        return self._list[index]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninterpolates over masked pixels in data and optional error or background images.", "response": "def interpolate_masked_data(data, mask, error=None, background=None):\n    \"\"\"\n    Interpolate over masked pixels in data and optional error or\n    background images.\n\n    The value of masked pixels are replaced by the mean value of the\n    connected neighboring non-masked pixels.  This function is intended\n    for single, isolated masked pixels (e.g. hot/warm pixels).\n\n    Parameters\n    ----------\n    data : array_like or `~astropy.units.Quantity`\n        The data array.\n\n    mask : array_like (bool)\n        A boolean mask, with the same shape as ``data``, where a `True`\n        value indicates the corresponding element of ``data`` is masked.\n\n    error : array_like or `~astropy.units.Quantity`, optional\n        The pixel-wise Gaussian 1-sigma errors of the input ``data``.\n        ``error`` must have the same shape as ``data``.\n\n    background : array_like, or `~astropy.units.Quantity`, optional\n        The pixel-wise background level of the input ``data``.\n        ``background`` must have the same shape as ``data``.\n\n    Returns\n    -------\n    data : `~numpy.ndarray` or `~astropy.units.Quantity`\n        Input ``data`` with interpolated masked pixels.\n\n    error : `~numpy.ndarray` or `~astropy.units.Quantity`\n        Input ``error`` with interpolated masked pixels.  `None` if\n        input ``error`` is not input.\n\n    background : `~numpy.ndarray` or `~astropy.units.Quantity`\n        Input ``background`` with interpolated masked pixels.  `None` if\n        input ``background`` is not input.\n    \"\"\"\n\n    if data.shape != mask.shape:\n        raise ValueError('data and mask must have the same shape')\n\n    data_out = np.copy(data)    # do not alter input data\n    mask_idx = mask.nonzero()\n\n    if mask_idx[0].size == 0:\n        raise ValueError('All items in data are masked')\n\n    for x in zip(*mask_idx):\n        X = np.array([[max(x[i] - 1, 0), min(x[i] + 1, data.shape[i] - 1)]\n                      for i in range(len(data.shape))])\n        goodpix = ~mask[X]\n\n        if not np.any(goodpix):\n            warnings.warn('The masked pixel at \"{}\" is completely '\n                          'surrounded by (connected) masked pixels, '\n                          'thus unable to interpolate'.format(x,),\n                          AstropyUserWarning)\n            continue\n\n        data_out[x] = np.mean(data[X][goodpix])\n\n        if background is not None:\n            if background.shape != data.shape:\n                raise ValueError('background and data must have the same '\n                                 'shape')\n            background_out = np.copy(background)\n            background_out[x] = np.mean(background[X][goodpix])\n        else:\n            background_out = None\n\n        if error is not None:\n            if error.shape != data.shape:\n                raise ValueError('error and data must have the same '\n                                 'shape')\n            error_out = np.copy(error)\n            error_out[x] = np.sqrt(np.mean(error[X][goodpix]**2))\n        else:\n            error_out = None\n\n    return data_out, error_out, background_out"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmasking the image with the value of the pixel mirrored across a given center_position.", "response": "def mask_to_mirrored_num(image, mask_image, center_position, bbox=None):\n    \"\"\"\n    Replace masked pixels with the value of the pixel mirrored across a\n    given ``center_position``.  If the mirror pixel is unavailable (i.e.\n    itself masked or outside of the image), then the masked pixel value\n    is set to zero.\n\n    Parameters\n    ----------\n    image : `numpy.ndarray`, 2D\n        The 2D array of the image.\n\n    mask_image : array-like, bool\n        A boolean mask with the same shape as ``image``, where a `True`\n        value indicates the corresponding element of ``image`` is\n        considered bad.\n\n    center_position : 2-tuple\n        (x, y) center coordinates around which masked pixels will be\n        mirrored.\n\n    bbox : list, tuple, `numpy.ndarray`, optional\n        The bounding box (x_min, x_max, y_min, y_max) over which to\n        replace masked pixels.\n\n    Returns\n    -------\n    result : `numpy.ndarray`, 2D\n        A 2D array with replaced masked pixels.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from photutils.utils import mask_to_mirrored_num\n    >>> image = np.arange(16).reshape(4, 4)\n    >>> mask = np.zeros_like(image, dtype=bool)\n    >>> mask[0, 0] = True\n    >>> mask[1, 1] = True\n    >>> mask_to_mirrored_num(image, mask, (1.5, 1.5))\n    array([[15,  1,  2,  3],\n           [ 4, 10,  6,  7],\n           [ 8,  9, 10, 11],\n           [12, 13, 14, 15]])\n    \"\"\"\n\n    if bbox is None:\n        ny, nx = image.shape\n        bbox = [0, nx, 0, ny]\n    subdata = np.copy(image[bbox[2]:bbox[3]+1, bbox[0]:bbox[1]+1])\n    submask = mask_image[bbox[2]:bbox[3]+1, bbox[0]:bbox[1]+1]\n    y_masked, x_masked = np.nonzero(submask)\n    x_mirror = (2 * (center_position[0] - bbox[0]) -\n                x_masked + 0.5).astype('int32')\n    y_mirror = (2 * (center_position[1] - bbox[2]) -\n                y_masked + 0.5).astype('int32')\n\n    # Reset mirrored pixels that go out of the image.\n    outofimage = ((x_mirror < 0) | (y_mirror < 0) |\n                  (x_mirror >= subdata.shape[1]) |\n                  (y_mirror >= subdata.shape[0]))\n    if outofimage.any():\n        x_mirror[outofimage] = x_masked[outofimage].astype('int32')\n        y_mirror[outofimage] = y_masked[outofimage].astype('int32')\n\n    subdata[y_masked, x_masked] = subdata[y_mirror, x_mirror]\n\n    # Set pixels that mirrored to another masked pixel to zero.\n    # This will also set to zero any pixels that mirrored out of\n    # the image.\n    mirror_is_masked = submask[y_mirror, x_mirror]\n    x_bad = x_masked[mirror_is_masked]\n    y_bad = y_masked[mirror_is_masked]\n    subdata[y_bad, x_bad] = 0.0\n\n    outimage = np.copy(image)\n    outimage[bbox[2]:bbox[3]+1, bbox[0]:bbox[1]+1] = subdata\n\n    return outimage"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef StartExecServer():\n  sockdir = '/tmp/pyringe_%s' % os.getpid()\n  if not os.path.isdir(sockdir):\n    os.mkdir(sockdir)\n  socket_path = ('%s/%s.execsock' %\n                 (sockdir, threading.current_thread().ident))\n\n  if os.path.exists(socket_path):\n    os.remove(socket_path)\n\n  exec_sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n  exec_sock.bind(socket_path)\n  exec_sock.listen(5)\n  shutdown = False\n  while not shutdown:\n    conn, _ = exec_sock.accept()\n\n    data = conn.recv(1024)\n    if data:\n      if data == '__kill__':\n        shutdown = True\n        conn.send('__kill_ack__')\n        break\n      data = json.loads(data)\n      try:\n        conn.sendall(json.dumps(eval(data)))\n      except SyntaxError:\n        # Okay, so it probably wasn't an expression\n        try:\n          exec data  # pylint: disable=exec-used\n        except:  # pylint: disable=bare-except\n          # Whatever goes wrong when exec'ing this, we don't want to crash.\n          # TODO: think of a way to properly tunnel exceptions, if\n          # possible without introducing more magic strings.\n          pass\n        finally:\n          conn.sendall(json.dumps(None))\n  exec_sock.shutdown(socket.SHUT_RDWR)\n  exec_sock.close()\n  os.remove(socket_path)", "response": "Opens a socket in the exec directory and sends data to it and writes results back."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ThreadsWithRunningExecServers(self):\n    socket_dir = '/tmp/pyringe_%s' % self.inferior.pid\n    if os.path.isdir(socket_dir):\n      return [int(fname[:-9])\n              for fname in os.listdir(socket_dir)\n              if fname.endswith('.execsock')]\n    return []", "response": "Returns a list of tids of inferior threads with open exec servers."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninjects python code into exec socket.", "response": "def SendToExecSocket(self, code, tid=None):\n    \"\"\"Inject python code into exec socket.\"\"\"\n    response = self._SendToExecSocketRaw(json.dumps(code), tid)\n    return json.loads(response)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending kill request to exec socket.", "response": "def CloseExecSocket(self, tid=None):\n    \"\"\"Send closing request to exec socket.\"\"\"\n    response = self._SendToExecSocketRaw('__kill__', tid)\n    if response != '__kill_ack__':\n      logging.warning('May not have succeeded in closing socket, make sure '\n                      'using execsocks().')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a backtrace of the current position.", "response": "def Backtrace(self, to_string=False):\n    \"\"\"Get a backtrace of the current position.\"\"\"\n    if self.inferior.is_running:\n      res = self.inferior.Backtrace()\n      if to_string:\n        return res\n      print res\n    else:\n      logging.error('Not attached to any process.')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ListThreads(self):\n    if self.inferior.is_running:\n      return self.inferior.threads\n    logging.error('Not attached to any process.')\n    return []", "response": "List the currently running python threads."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef Refresh():\n    try:\n      GdbCache.DICT = gdb.lookup_type('PyDictObject').pointer()\n      GdbCache.TYPE = gdb.lookup_type('PyTypeObject').pointer()\n    except gdb.error as err:\n      # The symbol file we're using doesn't seem to provide type information.\n      pass\n    interp_head_name = GdbCache.FuzzySymbolLookup('interp_head')\n    if interp_head_name:\n      GdbCache.INTERP_HEAD = gdb.parse_and_eval(interp_head_name)\n    else:\n      # As a last resort, ask the inferior about it.\n      GdbCache.INTERP_HEAD = gdb.parse_and_eval('PyInterpreterState_Head()')\n    GdbCache.PENDINGBUSY = GdbCache.FuzzySymbolLookup('pendingbusy')\n    GdbCache.PENDINGCALLS_TO_DO = GdbCache.FuzzySymbolLookup('pendingcalls_to_do')", "response": "Refreshes the current state of the current state of the current symbol file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef OpenFile(self, filepath):\n    archive = False\n    if '.zip/' in filepath:\n      archive = True\n      archive_type = '.zip'\n    if '.par/' in filepath:\n      archive = True\n      archive_type = '.par'\n    if archive:\n      path, archived_file = filepath.split(archive_type)\n      path += archive_type\n      zip_file = zipfile.ZipFile(path)\n      return zip_file.open(archived_file.strip('/'))\n    return open(filepath)", "response": "OpenFile - replacement that automatically handles zip files."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef extract_filename(self):\n    globals_gdbval = self._gdbval['f_globals'].cast(GdbCache.DICT)\n    global_dict = libpython.PyDictObjectPtr(globals_gdbval)\n    for key, value in global_dict.iteritems():\n      if str(key.proxyval(set())) == '__file__':\n        return str(value.proxyval(set()))", "response": "Alternative way of getting the executed file which inspects globals."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _UnserializableObjectFallback(self, obj):\n    if isinstance(obj, libpython.PyInstanceObjectPtr):\n      # old-style classes use 'classobj'/'instance'\n      # get class attribute dictionary\n      in_class = obj.pyop_field('in_class')\n      result_dict = in_class.pyop_field('cl_dict').proxyval(set())\n\n      # let libpython.py do the work of getting the instance dict\n      instanceproxy = obj.proxyval(set())\n      result_dict.update(instanceproxy.attrdict)\n      result_dict['__pyringe_type_name__'] = instanceproxy.cl_name\n      result_dict['__pyringe_address__'] = instanceproxy.address\n      return result_dict\n\n    if isinstance(obj, libpython.HeapTypeObjectPtr):\n      # interestingly enough, HeapTypeObjectPtr seems to handle all pointers to\n      # heap type PyObjects, not only pointers to PyHeapTypeObject. This\n      # corresponds to new-style class instances. However, as all instances of\n      # new-style classes are simple PyObject pointers to the interpreter,\n      # libpython.py tends to give us HeapTypeObjectPtrs for things we can't\n      # handle properly.\n\n      try:\n        # get class attribute dictionary\n        type_ptr = obj.field('ob_type')\n        tp_dict = type_ptr.cast(GdbCache.TYPE)['tp_dict'].cast(GdbCache.DICT)\n        result_dict = libpython.PyDictObjectPtr(tp_dict).proxyval(set())\n      except gdb.error:\n        # There was probably a type mismatch triggered by wrong assumptions in\n        # libpython.py\n        result_dict = {}\n\n      try:\n        # get instance attributes\n        result_dict.update(obj.get_attr_dict().proxyval(set()))\n        result_dict['__pyringe_type_name__'] = obj.safe_tp_name()\n        result_dict['__pyringe_address__'] = long(obj._gdbval)  # pylint: disable=protected-access\n        return result_dict\n      except TypeError:\n        # This happens in the case where we're not really looking at a heap type\n        # instance. There isn't really anything we can do, so we fall back to\n        # the default handling.\n        pass\n    # Default handler -- this does not result in proxy objects or fancy dicts,\n    # but most of the time, we end up emitting strings of the format\n    # '<object at remote 0x345a235>'\n    try:\n      proxy = obj.proxyval(set())\n      # json doesn't accept non-strings as keys, so we're helping along\n      if isinstance(proxy, dict):\n        return {str(key): val for key, val in proxy.iteritems()}\n      return proxy\n    except AttributeError:\n      return str(obj)", "response": "Handles sanitizing of unserializable objects for Json."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads the RPC request from stdin and processes it and writes the result to stdout.", "response": "def _AcceptRPC(self):\n    \"\"\"Reads RPC request from stdin and processes it, writing result to stdout.\n\n    Returns:\n      True as long as execution is to be continued, False otherwise.\n    Raises:\n      RpcException: if no function was specified in the RPC or no such API\n          function exists.\n    \"\"\"\n    request = self._ReadObject()\n    if request['func'] == '__kill__':\n      self.ClearBreakpoints()\n      self._WriteObject('__kill_ack__')\n      return False\n    if 'func' not in request or request['func'].startswith('_'):\n      raise RpcException('Not a valid public API function.')\n    rpc_result = getattr(self, request['func'])(*request['args'])\n    self._WriteObject(rpc_result)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _UnpackGdbVal(self, gdb_value):\n    val_type = gdb_value.type.code\n    if val_type == gdb.TYPE_CODE_INT or val_type == gdb.TYPE_CODE_ENUM:\n      return int(gdb_value)\n    if val_type == gdb.TYPE_CODE_VOID:\n      return None\n    if val_type == gdb.TYPE_CODE_PTR:\n      return long(gdb_value)\n    if val_type == gdb.TYPE_CODE_ARRAY:\n      # This is probably a string\n      return str(gdb_value)\n    # I'm out of ideas, let's return it as a string\n    return str(gdb_value)", "response": "Unpacks gdb. Value objects and returns the best - matched python object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef EnsureGdbPosition(self, pid, tid, frame_depth):\n    position = [pid, tid, frame_depth]\n    if not pid:\n      return\n    if not self.IsAttached():\n      try:\n        self.Attach(position)\n      except gdb.error as exc:\n        raise PositionUnavailableException(exc.message)\n    if gdb.selected_inferior().pid != pid:\n      self.Detach()\n      try:\n        self.Attach(position)\n      except gdb.error as exc:\n        raise PositionUnavailableException(exc.message)\n\n    if tid:\n      tstate_head = GdbCache.INTERP_HEAD['tstate_head']\n      for tstate in self._IterateChainedList(tstate_head, 'next'):\n        if tid == tstate['thread_id']:\n          self.selected_tstate = tstate\n          break\n      else:\n        raise PositionUnavailableException('Thread %s does not exist.' %\n                                           str(tid))\n      stack_head = self.selected_tstate['frame']\n      if frame_depth is not None:\n        frames = list(self._IterateChainedList(stack_head, 'f_back'))\n        frames.reverse()\n        try:\n          self.selected_frame = frames[frame_depth]\n        except IndexError:\n          raise PositionUnavailableException('Stack is not %s frames deep' %\n                                             str(frame_depth + 1))", "response": "Ensures that our current position matches the request."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef IsSymbolFileSane(self, position):\n    pos = [position[0], None, None]\n    self.EnsureGdbPosition(*pos)\n    try:\n      if GdbCache.DICT and GdbCache.TYPE and GdbCache.INTERP_HEAD:\n        # pylint: disable=pointless-statement\n        tstate = GdbCache.INTERP_HEAD['tstate_head']\n        tstate['thread_id']\n        frame = tstate['frame']\n        frame_attrs = ['f_back',\n                       'f_locals',\n                       'f_localsplus',\n                       'f_globals',\n                       'f_builtins',\n                       'f_lineno',\n                       'f_lasti']\n        for attr_name in frame_attrs:\n          # This lookup shouldn't throw an exception\n          frame[attr_name]\n        code = frame['f_code']\n        code_attrs = ['co_name',\n                      'co_filename',\n                      'co_nlocals',\n                      'co_varnames',\n                      'co_lnotab',\n                      'co_firstlineno']\n        for attr_name in code_attrs:\n          # Same as above, just checking whether the lookup succeeds.\n          code[attr_name]\n        # if we've gotten this far, we should be fine, as it means gdb managed\n        # to look up values for all of these. They might still be null, the\n        # symbol file might still be bogus, but making gdb check for null values\n        # and letting it run into access violations is the best we can do. We\n        # haven't checked any of the python types (dict, etc.), but this symbol\n        # file seems to be useful for some things, so let's give it our seal of\n        # approval.\n        return True\n    except gdb.error:\n      return False\n    # looks like the initial GdbCache refresh failed. That's no good.\n    return False", "response": "Checks if a bunch of symbols are valid."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Detach(self):\n    # We have to work around the python APIs weirdness :\\\n    if not self.IsAttached():\n      return None\n    # Gdb doesn't drain any pending SIGINTs it may have sent to the inferior\n    # when it simply detaches. We can do this by letting the inferior continue,\n    # and gdb will intercept any SIGINT that's still to-be-delivered; as soon as\n    # we do so however, we may lose control of gdb (if we're running in\n    # synchronous mode). So we queue an interruption and continue gdb right\n    # afterwards, it will waitpid() for its inferior and collect all signals\n    # that may have been queued.\n    pid = gdb.selected_inferior().pid\n    self.Interrupt([pid, None, None])\n    self.Continue([pid, None, None])\n    result = gdb.execute('detach', to_string=True)\n    if not result:\n      return None\n    return result", "response": "Detaches from the inferior."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nperforms a function call in the inferior.", "response": "def Call(self, position, function_call):\n    \"\"\"Perform a function call in the inferior.\n\n    WARNING: Since Gdb's concept of threads can't be directly identified with\n    python threads, the function call will be made from what has to be assumed\n    is an arbitrary thread. This *will* interrupt the inferior. Continuing it\n    after the call is the responsibility of the caller.\n\n    Args:\n      position: the context of the inferior to call the function from.\n      function_call: A string corresponding to a function call. Format:\n        'foo(0,0)'\n    Returns:\n      Thre return value of the called function.\n    \"\"\"\n    self.EnsureGdbPosition(position[0], None, None)\n    if not gdb.selected_thread().is_stopped():\n      self.Interrupt(position)\n    result_value = gdb.parse_and_eval(function_call)\n    return self._UnpackGdbVal(result_value)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend a command string to gdb.", "response": "def ExecuteRaw(self, position, command):\n    \"\"\"Send a command string to gdb.\"\"\"\n    self.EnsureGdbPosition(position[0], None, None)\n    return gdb.execute(command, to_string=True)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a mapping from python tid to gdb thread num.", "response": "def _GetGdbThreadMapping(self, position):\n    \"\"\"Gets a mapping from python tid to gdb thread num.\n\n    There's no way to get the thread ident from a gdb thread.  We only get the\n    \"ID of the thread, as assigned by GDB\", which is completely useless for\n    everything except talking to gdb.  So in order to translate between these\n    two, we have to execute 'info threads' and parse its output. Note that this\n    may only work on linux, and only when python was compiled to use pthreads.\n    It may work elsewhere, but we won't guarantee it.\n\n    Args:\n      position: array of pid, tid, framedepth specifying the requested position.\n    Returns:\n      A dictionary of the form {python_tid: gdb_threadnum}.\n    \"\"\"\n\n    if len(gdb.selected_inferior().threads()) == 1:\n      # gdb's output for info threads changes and only displays PID. We cheat.\n      return {position[1]: 1}\n    # example:\n    #   8    Thread 0x7f0a637fe700 (LWP 11894) \"test.py\" 0x00007f0a69563e63 in\n    #   select () from /usr/lib64/libc.so.6\n    thread_line_regexp = r'\\s*\\**\\s*([0-9]+)\\s+[a-zA-Z]+\\s+([x0-9a-fA-F]+)\\s.*'\n    output = gdb.execute('info threads', to_string=True)\n    matches = [re.match(thread_line_regexp, line) for line\n               in output.split('\\n')[1:]]\n    return {int(match.group(2), 16): int(match.group(1))\n            for match in matches if match}"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _Inject(self, position, call):\n    self.EnsureGdbPosition(position[0], position[1], None)\n    self.ClearBreakpoints()\n    self._AddThreadSpecificBreakpoint(position)\n    gdb.parse_and_eval('%s = 1' % GdbCache.PENDINGCALLS_TO_DO)\n    gdb.parse_and_eval('%s = 1' % GdbCache.PENDINGBUSY)\n    try:\n      # We're \"armed\", risk the blocking call to Continue\n      self.Continue(position)\n      # Breakpoint was hit!\n      if not gdb.selected_thread().is_stopped():\n        # This should not happen. Depending on how gdb is being used, the\n        # semantics of self.Continue change, so I'd rather leave this check in\n        # here, in case we ever *do* end up changing to async mode.\n        raise RuntimeError('Gdb is not acting as expected, is it being run in '\n                           'async mode?')\n    finally:\n      gdb.parse_and_eval('%s = 0' % GdbCache.PENDINGBUSY)\n    self.Call(position, call)", "response": "Injects evaluation of call in a safe location in the inferior."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nassemble and returns what looks exactly like python s backtraces.", "response": "def _BacktraceFromFramePtr(self, frame_ptr):\n    \"\"\"Assembles and returns what looks exactly like python's backtraces.\"\"\"\n    # expects frame_ptr to be a gdb.Value\n    frame_objs = [PyFrameObjectPtr(frame) for frame\n                  in self._IterateChainedList(frame_ptr, 'f_back')]\n\n    # We want to output tracebacks in the same format python uses, so we have to\n    # reverse the stack\n    frame_objs.reverse()\n    tb_strings = ['Traceback (most recent call last):']\n    for frame in frame_objs:\n      line_string = ('  File \"%s\", line %s, in %s' %\n                     (frame.filename(),\n                      str(frame.current_line_num()),\n                      frame.co_name.proxyval(set())))\n      tb_strings.append(line_string)\n      line_string = '    %s' % frame.current_line().strip()\n      tb_strings.append(line_string)\n    return '\\n'.join(tb_strings)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends a kill request to Gdb and forcefully kill it if that doesn t work.", "response": "def Kill(self):\n    \"\"\"Send death pill to Gdb and forcefully kill it if that doesn't work.\"\"\"\n    try:\n      if self.is_running:\n        self.Detach()\n      if self._Execute('__kill__') == '__kill_ack__':\n        # acknowledged, let's give it some time to die in peace\n        time.sleep(0.1)\n    except (TimeoutError, ProxyError):\n      logging.debug('Termination request not acknowledged, killing gdb.')\n    if self.is_running:\n      # death pill didn't seem to work. We don't want the inferior to get killed\n      # the next time it hits a dangling breakpoint, so we send a SIGINT to gdb,\n      # which makes it disable instruction breakpoints for the time being.\n      os.kill(self._process.pid, signal.SIGINT)\n      # Since SIGINT has higher priority (with signal number 2) than SIGTERM\n      # (signal 15), SIGTERM cannot preempt the signal handler for SIGINT.\n      self._process.terminate()\n      self._process.wait()\n    self._errfile_r.close()\n    self._outfile_r.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the installed version of the gdb as a 3 - tuple.", "response": "def Version():\n    \"\"\"Gets the version of gdb as a 3-tuple.\n\n    The gdb devs seem to think it's a good idea to make --version\n    output multiple lines of welcome text instead of just the actual version,\n    so we ignore everything it outputs after the first line.\n    Returns:\n      The installed version of gdb in the form\n      (<major>, <minor or None>, <micro or None>)\n      gdb 7.7 would hence show up as version (7,7)\n    \"\"\"\n    output = subprocess.check_output(['gdb', '--version']).split('\\n')[0]\n    # Example output (Arch linux):\n    # GNU gdb (GDB) 7.7\n    # Example output (Debian sid):\n    # GNU gdb (GDB) 7.6.2 (Debian 7.6.2-1)\n    # Example output (Debian wheezy):\n    # GNU gdb (GDB) 7.4.1-debian\n    # Example output (centos 2.6.32):\n    # GNU gdb (GDB) Red Hat Enterprise Linux (7.2-56.el6)\n\n    # As we've seen in the examples above, versions may be named very liberally\n    # So we assume every part of that string may be the \"real\" version string\n    # and try to parse them all. This too isn't perfect (later strings will\n    # overwrite information gathered from previous ones), but it should be\n    # flexible enough for everything out there.\n    major = None\n    minor = None\n    micro = None\n    for potential_versionstring in output.split():\n      version = re.split('[^0-9]', potential_versionstring)\n      try:\n        major = int(version[0])\n      except (IndexError, ValueError):\n        pass\n      try:\n        minor = int(version[1])\n      except (IndexError, ValueError):\n        pass\n      try:\n        micro = int(version[2])\n      except (IndexError, ValueError):\n        pass\n    return (major, minor, micro)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending an RPC request to the gdb - internal python module and return any results.", "response": "def _Execute(self, funcname, *args, **kwargs):\n    \"\"\"Send an RPC request to the gdb-internal python.\n\n    Blocks for 3 seconds by default and returns any results.\n    Args:\n      funcname: the name of the function to call.\n      *args: the function's arguments.\n      **kwargs: Only the key 'wait_for_completion' is inspected, which decides\n        whether to wait forever for completion or just 3 seconds.\n    Returns:\n      The result of the function call.\n    \"\"\"\n    wait_for_completion = kwargs.get('wait_for_completion', False)\n    rpc_dict = {'func': funcname, 'args': args}\n    self._Send(json.dumps(rpc_dict))\n    timeout = TIMEOUT_FOREVER if wait_for_completion else TIMEOUT_DEFAULT\n\n    result_string = self._Recv(timeout)\n\n    try:\n      result = json.loads(result_string, object_hook=self._JsonDecodeDict)\n      if isinstance(result, unicode):\n        result = self._TryStr(result)\n      elif isinstance(result, list):\n        result = self._JsonDecodeList(result)\n    except ValueError:\n      raise ValueError('Response JSON invalid: ' + str(result_string))\n    except TypeError:\n      raise ValueError('Response JSON invalid: ' + str(result_string))\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _Recv(self, timeout):\n\n    buf = ''\n    # The messiness of this stems from the \"duck-typiness\" of this function.\n    # The timeout parameter of poll has different semantics depending on whether\n    # it's <=0, >0, or None. Yay.\n\n    wait_for_line = timeout is TIMEOUT_FOREVER\n    deadline = time.time() + (timeout if not wait_for_line else 0)\n\n    def TimeLeft():\n      return max(1000 * (deadline - time.time()), 0)\n\n    continue_reading = True\n\n    while continue_reading:\n      poll_timeout = None if wait_for_line else TimeLeft()\n\n      fd_list = [event[0] for event in self._poller.poll(poll_timeout)\n                 if event[1] & (select.POLLIN | select.POLLPRI)]\n      if not wait_for_line and TimeLeft() == 0:\n        continue_reading = False\n      if self._outfile_r.fileno() in fd_list:\n        buf += self._outfile_r.readline()\n        if buf.endswith('\\n'):\n          return buf\n\n      # GDB-internal exception passing\n      if self._errfile_r.fileno() in fd_list:\n        exc = self._errfile_r.readline()\n        if exc:\n          exc_text = '\\n-----------------------------------\\n'\n          exc_text += 'Error occurred within GdbService:\\n'\n          try:\n            exc_text += json.loads(exc)\n          except ValueError:\n            # whatever we got back wasn't valid JSON.\n            # This usually means we've run into an exception before the special\n            # exception handling was turned on. The first line we read up there\n            # will have been \"Traceback (most recent call last):\". Obviously, we\n            # want the rest, too, so we wait a bit and read it.\n            deadline = time.time() + 0.5\n            while self.is_running and TimeLeft() > 0:\n              exc += self._errfile_r.read()\n            try:\n              exc_text += json.loads(exc)\n            except ValueError:\n              exc_text = exc\n          raise ProxyError(exc_text)\n    # timeout\n    raise TimeoutError()", "response": "Reads the next line of gdb s stdout and stderr streams."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef needsattached(func):\n\n    @functools.wraps(func)\n    def wrap(self, *args, **kwargs):\n      if not self.attached:\n        raise PositionError('Not attached to any process.')\n      return func(self, *args, **kwargs)\n    return wrap", "response": "Decorator to prevent commands from being used when not attached to any process."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Reinit(self, pid, auto_symfile_loading=True):\n    self.ShutDownGdb()\n    self.__init__(pid, auto_symfile_loading, architecture=self.arch)", "response": "Reinitializes the object with a new pid."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef StartGdb(self):\n    if self.attached:\n      raise GdbProcessError('Gdb is already running.')\n    self._gdb = GdbProxy(arch=self.arch)\n    self._gdb.Attach(self.position)\n\n    if self.auto_symfile_loading:\n      try:\n        self.LoadSymbolFile()\n      except (ProxyError, TimeoutError) as err:\n        self._gdb = GdbProxy(arch=self.arch)\n        self._gdb.Attach(self.position)\n        if not self.gdb.IsSymbolFileSane(self.position):\n          logging.warning('Failed to automatically load a sane symbol file, '\n                          'most functionality will be unavailable until symbol'\n                          'file is provided.')\n          logging.debug(err.message)", "response": "Starts gdb and attempts to auto - load symbol file if not already running."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntrying to inject python code into current thread.", "response": "def InjectString(self, codestring, wait_for_completion=True):\n    \"\"\"Try to inject python code into current thread.\n\n    Args:\n      codestring: Python snippet to execute in inferior. (may contain newlines)\n      wait_for_completion: Block until execution of snippet has completed.\n    \"\"\"\n    if self.inferior.is_running and self.inferior.gdb.IsAttached():\n      try:\n        self.inferior.gdb.InjectString(\n            self.inferior.position,\n            codestring,\n            wait_for_completion=wait_for_completion)\n      except RuntimeError:\n        exc_type, exc_value, exc_traceback = sys.exc_info()\n        traceback.print_exception(exc_type, exc_value, exc_traceback)\n    else:\n      logging.error('Not attached to any process.')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _write_instance_repr(out, visited, name, pyop_attrdict, address):\n    '''Shared code for use by old-style and new-style classes:\n    write a representation to file-like object \"out\"'''\n    out.write('<')\n    out.write(name)\n\n    # Write dictionary of instance attributes:\n    if isinstance(pyop_attrdict, PyDictObjectPtr):\n        out.write('(')\n        first = True\n        for pyop_arg, pyop_val in pyop_attrdict.iteritems():\n            if not first:\n                out.write(', ')\n            first = False\n            out.write(pyop_arg.proxyval(visited))\n            out.write('=')\n            pyop_val.write_repr(out, visited)\n        out.write(')')\n    out.write(' at remote 0x%x>' % address)", "response": "Write a representation of a single instance of the class."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef move_in_stack(move_up):\n    '''Move up or down the stack (for the py-up/py-down command)'''\n    frame = Frame.get_selected_python_frame()\n    while frame:\n        if move_up:\n            iter_frame = frame.older()\n        else:\n            iter_frame = frame.newer()\n\n        if not iter_frame:\n            break\n\n        if iter_frame.is_evalframeex():\n            # Result:\n            if iter_frame.select():\n                iter_frame.print_summary()\n            return\n\n        frame = iter_frame\n\n    if move_up:\n        print 'Unable to find an older python frame'\n    else:\n        print 'Unable to find a newer python frame'", "response": "Move up or down the stack ( for the py - up command"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef field(self, name):\n        '''\n        Get the gdb.Value for the given field within the PyObject, coping with\n        some python 2 versus python 3 differences.\n\n        Various libpython types are defined using the \"PyObject_HEAD\" and\n        \"PyObject_VAR_HEAD\" macros.\n\n        In Python 2, this these are defined so that \"ob_type\" and (for a var\n        object) \"ob_size\" are fields of the type in question.\n\n        In Python 3, this is defined as an embedded PyVarObject type thus:\n           PyVarObject ob_base;\n        so that the \"ob_size\" field is located insize the \"ob_base\" field, and\n        the \"ob_type\" is most easily accessed by casting back to a (PyObject*).\n        '''\n        if self.is_null():\n            raise NullPyObjectPtr(self)\n\n        if name == 'ob_type':\n            pyo_ptr = self._gdbval.cast(PyObjectPtr.get_gdb_type())\n            return pyo_ptr.dereference()[name]\n\n        if name == 'ob_size':\n            try:\n            # Python 2:\n                return self._gdbval.dereference()[name]\n            except RuntimeError:\n                # Python 3:\n                return self._gdbval.dereference()['ob_base'][name]\n\n        # General case: look it up inside the object:\n        return self._gdbval.dereference()[name]", "response": "Get the gdb. Value for the given field within the object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite the representation of the named field to out.", "response": "def write_field_repr(self, name, out, visited):\n        '''\n        Extract the PyObject* field named \"name\", and write its representation\n        to file-like object \"out\"\n        '''\n        field_obj = self.pyop_field(name)\n        field_obj.write_repr(out, visited)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a repr - like string for the data but truncate it at maxlen bytes", "response": "def get_truncated_repr(self, maxlen):\n        '''\n        Get a repr-like string for the data, but truncate it at \"maxlen\" bytes\n        (ending the object graph traversal as soon as you do)\n        '''\n        out = TruncatedStringIO(maxlen)\n        try:\n            self.write_repr(out, set())\n        except StringTruncated:\n            # Truncation occurred:\n            return out.getvalue() + '...(truncated)'\n\n        # No truncation occurred:\n        return out.getvalue()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a new object representing the value of the object at the remote 0x0.", "response": "def proxyval(self, visited):\n        '''\n        Scrape a value from the inferior process, and try to represent it\n        within the gdb process, whilst (hopefully) avoiding crashes when\n        the remote data is corrupt.\n\n        Derived classes will override this.\n\n        For example, a PyIntObject* with ob_ival 42 in the inferior process\n        should result in an int(42) in this process.\n\n        visited: a set of all gdb.Value pyobject pointers already visited\n        whilst generating this value (to guard against infinite recursion when\n        visiting object graphs with loops).  Analogous to Py_ReprEnter and\n        Py_ReprLeave\n        '''\n\n        class FakeRepr(object):\n            \"\"\"\n            Class representing a non-descript PyObject* value in the inferior\n            process for when we don't have a custom scraper, intended to have\n            a sane repr().\n            \"\"\"\n\n            def __init__(self, tp_name, address):\n                self.tp_name = tp_name\n                self.address = address\n\n            def __repr__(self):\n                # For the NULL pointer, we have no way of knowing a type, so\n                # special-case it as per\n                # http://bugs.python.org/issue8032#msg100882\n                if self.address == 0:\n                    return '0x0'\n                return '<%s at remote 0x%x>' % (self.tp_name, self.address)\n\n        return FakeRepr(self.safe_tp_name(),\n                        long(self._gdbval))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_repr(self, out, visited):\n        '''\n        Write a string representation of the value scraped from the inferior\n        process to \"out\", a file-like object.\n        '''\n        # Default implementation: generate a proxy value and write its repr\n        # However, this could involve a lot of work for complicated objects,\n        # so for derived classes we specialize this\n        return out.write(repr(self.proxyval(visited)))", "response": "Write a string representation of the value scraped from the inferior\n        process to out a file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef subclass_from_type(cls, t):\n        '''\n        Given a PyTypeObjectPtr instance wrapping a gdb.Value that's a\n        (PyTypeObject*), determine the corresponding subclass of PyObjectPtr\n        to use\n\n        Ideally, we would look up the symbols for the global types, but that\n        isn't working yet:\n          (gdb) python print gdb.lookup_symbol('PyList_Type')[0].value\n          Traceback (most recent call last):\n            File \"<string>\", line 1, in <module>\n          NotImplementedError: Symbol type not yet supported in Python scripts.\n          Error while executing Python code.\n\n        For now, we use tp_flags, after doing some string comparisons on the\n        tp_name for some special-cases that don't seem to be visible through\n        flags\n        '''\n        try:\n            tp_name = t.field('tp_name').string()\n            tp_flags = int(t.field('tp_flags'))\n        except RuntimeError:\n            # Handle any kind of error e.g. NULL ptrs by simply using the base\n            # class\n            return cls\n\n        #print 'tp_flags = 0x%08x' % tp_flags\n        #print 'tp_name = %r' % tp_name\n\n        name_map = {'bool': PyBoolObjectPtr,\n                    'classobj': PyClassObjectPtr,\n                    'instance': PyInstanceObjectPtr,\n                    'NoneType': PyNoneStructPtr,\n                    'frame': PyFrameObjectPtr,\n                    'set' : PySetObjectPtr,\n                    'frozenset' : PySetObjectPtr,\n                    'builtin_function_or_method' : PyCFunctionObjectPtr,\n                    }\n        if tp_name in name_map:\n            return name_map[tp_name]\n\n        if tp_flags & Py_TPFLAGS_HEAPTYPE:\n            return HeapTypeObjectPtr\n\n        if tp_flags & Py_TPFLAGS_INT_SUBCLASS:\n            return PyIntObjectPtr\n        if tp_flags & Py_TPFLAGS_LONG_SUBCLASS:\n            return PyLongObjectPtr\n        if tp_flags & Py_TPFLAGS_LIST_SUBCLASS:\n            return PyListObjectPtr\n        if tp_flags & Py_TPFLAGS_TUPLE_SUBCLASS:\n            return PyTupleObjectPtr\n        if tp_flags & Py_TPFLAGS_STRING_SUBCLASS:\n            return PyStringObjectPtr\n        if tp_flags & Py_TPFLAGS_UNICODE_SUBCLASS:\n            return PyUnicodeObjectPtr\n        if tp_flags & Py_TPFLAGS_DICT_SUBCLASS:\n            return PyDictObjectPtr\n        if tp_flags & Py_TPFLAGS_BASE_EXC_SUBCLASS:\n            return PyBaseExceptionObjectPtr\n        #if tp_flags & Py_TPFLAGS_TYPE_SUBCLASS:\n        #    return PyTypeObjectPtr\n\n        # Use the base class:\n        return cls", "response": "Given a PyTypeObjectPtr instance wrapping a gdb. Value that s a\n            returns the corresponding subclass of the base class."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntries to locate the appropriate derived class dynamically and cast the object pointer accordingly.", "response": "def from_pyobject_ptr(cls, gdbval):\n        '''\n        Try to locate the appropriate derived class dynamically, and cast\n        the pointer accordingly.\n        '''\n        try:\n            p = PyObjectPtr(gdbval)\n            cls = cls.subclass_from_type(p.type())\n            return cls(gdbval, cast_to=cls.get_gdb_type())\n        except RuntimeError:\n            # Handle any kind of error e.g. NULL ptrs by simply using the base\n            # class\n            pass\n        return cls(gdbval)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the PyDictObject ptr representing the attribute dictionary of the current object.", "response": "def get_attr_dict(self):\n        '''\n        Get the PyDictObject ptr representing the attribute dictionary\n        (or None if there's a problem)\n        '''\n        try:\n            typeobj = self.type()\n            dictoffset = int_from_int(typeobj.field('tp_dictoffset'))\n            if dictoffset != 0:\n                if dictoffset < 0:\n                    type_PyVarObject_ptr = gdb.lookup_type('PyVarObject').pointer()\n                    tsize = int_from_int(self._gdbval.cast(type_PyVarObject_ptr)['ob_size'])\n                    if tsize < 0:\n                        tsize = -tsize\n                    size = _PyObject_VAR_SIZE(typeobj, tsize)\n                    dictoffset += size\n                    assert dictoffset > 0\n                    assert dictoffset % SIZEOF_VOID_P == 0\n\n                dictptr = self._gdbval.cast(_type_char_ptr) + dictoffset\n                PyObjectPtrPtr = PyObjectPtr.get_gdb_type().pointer()\n                dictptr = dictptr.cast(PyObjectPtrPtr)\n                return PyObjectPtr.from_pyobject_ptr(dictptr.dereference())\n        except RuntimeError:\n            # Corrupt data somewhere; fail safe\n            pass\n\n        # Not found, or some kind of error:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef proxyval(self, visited):\n        '''\n        Support for new-style classes.\n\n        Currently we just locate the dictionary using a transliteration to\n        python of _PyObject_GetDictPtr, ignoring descriptors\n        '''\n        # Guard against infinite loops:\n        if self.as_address() in visited:\n            return ProxyAlreadyVisited('<...>')\n        visited.add(self.as_address())\n\n        pyop_attr_dict = self.get_attr_dict()\n        if pyop_attr_dict:\n            attr_dict = pyop_attr_dict.proxyval(visited)\n        else:\n            attr_dict = {}\n        tp_name = self.safe_tp_name()\n\n        # New-style class:\n        return InstanceProxy(tp_name, attr_dict, long(self._gdbval))", "response": "Return a proxy for this instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the line number for a given bytecode offset", "response": "def addr2line(self, addrq):\n        '''\n        Get the line number for a given bytecode offset\n\n        Analogous to PyCode_Addr2Line; translated from pseudocode in\n        Objects/lnotab_notes.txt\n        '''\n        co_lnotab = self.pyop_field('co_lnotab').proxyval(set())\n\n        # Initialize lineno to co_firstlineno as per PyCode_Addr2Line\n        # not 0, as lnotab_notes.txt has it:\n        lineno = int_from_int(self.field('co_firstlineno'))\n\n        addr = 0\n        for addr_incr, line_incr in zip(co_lnotab[::2], co_lnotab[1::2]):\n            addr += ord(addr_incr)\n            if addr > addrq:\n                return lineno\n            lineno += ord(line_incr)\n        return lineno"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef iteritems(self):\n        '''\n        Yields a sequence of (PyObjectPtr key, PyObjectPtr value) pairs,\n        analagous to dict.iteritems()\n        '''\n        for i in safe_range(self.field('ma_mask') + 1):\n            ep = self.field('ma_table') + i\n            pyop_value = PyObjectPtr.from_pyobject_ptr(ep['me_value'])\n            if not pyop_value.is_null():\n                pyop_key = PyObjectPtr.from_pyobject_ptr(ep['me_key'])\n                yield (pyop_key, pyop_value)", "response": "Yields a sequence of ( PyObjectPtr key PyObjectPtr value ) pairs and analagous to dict. iteritems"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the value of the object in the format of a long object.", "response": "def proxyval(self, visited):\n        '''\n        Python's Include/longobjrep.h has this declaration:\n           struct _longobject {\n               PyObject_VAR_HEAD\n               digit ob_digit[1];\n           };\n\n        with this description:\n            The absolute value of a number is equal to\n                 SUM(for i=0 through abs(ob_size)-1) ob_digit[i] * 2**(SHIFT*i)\n            Negative numbers are represented with ob_size < 0;\n            zero is represented by ob_size == 0.\n\n        where SHIFT can be either:\n            #define PyLong_SHIFT        30\n            #define PyLong_SHIFT        15\n        '''\n        ob_size = long(self.field('ob_size'))\n        if ob_size == 0:\n            return 0L\n\n        ob_digit = self.field('ob_digit')\n\n        if gdb.lookup_type('digit').sizeof == 2:\n            SHIFT = 15L\n        else:\n            SHIFT = 30L\n\n        digits = [long(ob_digit[i]) * 2**(SHIFT*i)\n                  for i in safe_range(abs(ob_size))]\n        result = sum(digits)\n        if ob_size < 0:\n            result = -result\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nyields a sequence of ( name value ) pairs of PyObjectPtr instances for the local variables of this frame.", "response": "def iter_locals(self):\n        '''\n        Yield a sequence of (name,value) pairs of PyObjectPtr instances, for\n        the local variables of this frame\n        '''\n        if self.is_optimized_out():\n            return\n\n        f_localsplus = self.field('f_localsplus')\n        for i in safe_range(self.co_nlocals):\n            pyop_value = PyObjectPtr.from_pyobject_ptr(f_localsplus[i])\n            if not pyop_value.is_null():\n                pyop_name = PyObjectPtr.from_pyobject_ptr(self.co_varnames[i])\n                yield (pyop_name, pyop_value)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlooking for the named local variable returning a ( PyObjectPtr scope ) pair where scope is a string local global or builtin", "response": "def get_var_by_name(self, name):\n        '''\n        Look for the named local variable, returning a (PyObjectPtr, scope) pair\n        where scope is a string 'local', 'global', 'builtin'\n\n        If not found, return (None, None)\n        '''\n        for pyop_name, pyop_value in self.iter_locals():\n            if name == pyop_name.proxyval(set()):\n                return pyop_value, 'local'\n        for pyop_name, pyop_value in self.iter_globals():\n            if name == pyop_name.proxyval(set()):\n                return pyop_value, 'global'\n        for pyop_name, pyop_value in self.iter_builtins():\n            if name == pyop_name.proxyval(set()):\n                return pyop_value, 'builtin'\n        return None, None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef current_line(self):\n        '''Get the text of the current source line as a string, with a trailing\n        newline character'''\n        if self.is_optimized_out():\n            return '(frame information optimized out)'\n        with open(self.filename(), 'r') as f:\n            all_lines = f.readlines()\n            # Convert from 1-based current_line_num to 0-based list offset:\n            return all_lines[self.current_line_num()-1]", "response": "Get the text of the current source line as a string with a trailing\n        newline character"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef select(self):\n        '''If supported, select this frame and return True; return False if unsupported\n\n        Not all builds have a gdb.Frame.select method; seems to be present on Fedora 12\n        onwards, but absent on Ubuntu buildbot'''\n        if not hasattr(self._gdbframe, 'select'):\n            print ('Unable to select frame: '\n                   'this build of gdb does not expose a gdb.Frame.select method')\n            return False\n        self._gdbframe.select()\n        return True", "response": "Select this frame and return True if supported"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncalculate index of frame starting at 0 for the newest frame within this thread", "response": "def get_index(self):\n        '''Calculate index of frame, starting at 0 for the newest frame within\n        this thread'''\n        index = 0\n        # Go down until you reach the newest frame:\n        iter_frame = self\n        while iter_frame.newer():\n            index += 1\n            iter_frame = iter_frame.newer()\n        return index"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_evalframeex(self):\n        '''Is this a PyEval_EvalFrameEx frame?'''\n        if self._gdbframe.name() == 'PyEval_EvalFrameEx':\n            '''\n            I believe we also need to filter on the inline\n            struct frame_id.inline_depth, only regarding frames with\n            an inline depth of 0 as actually being this function\n\n            So we reject those with type gdb.INLINE_FRAME\n            '''\n            if self._gdbframe.type() == gdb.NORMAL_FRAME:\n                # We have a PyEval_EvalFrameEx frame:\n                return True\n\n        return False", "response": "Is this a PyEval_EvalFrameEx frame?"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntries to obtain the Frame for the python code in the selected frame and return the Frame object if it is not found.", "response": "def get_selected_python_frame(cls):\n        '''Try to obtain the Frame for the python code in the selected frame,\n        or None'''\n        frame = cls.get_selected_frame()\n\n        while frame:\n            if frame.is_evalframeex():\n                return frame\n            frame = frame.older()\n\n        # Not found:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ListCommands(self):\n    print 'Available commands:'\n    commands = dict(self.commands)\n    for plugin in self.plugins:\n      commands.update(plugin.commands)\n    for com in sorted(commands):\n      if not com.startswith('_'):\n        self.PrintHelpTextLine(com, commands[com])", "response": "Print a list of currently available commands and their descriptions."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef StatusLine(self):\n    pid = self.inferior.pid\n    curthread = None\n    threadnum = 0\n    if pid:\n      if not self.inferior.is_running:\n        logging.warning('Inferior is not running.')\n        self.Detach()\n        pid = None\n      else:\n        try:\n          # get a gdb running if it wasn't already.\n          if not self.inferior.attached:\n            self.inferior.StartGdb()\n          curthread = self.inferior.current_thread\n          threadnum = len(self.inferior.threads)\n        except (inferior.ProxyError,\n                inferior.TimeoutError,\n                inferior.PositionError) as err:\n          # This is not the kind of thing we want to be held up by\n          logging.debug('Error while getting information in status line:%s'\n                        % err.message)\n          pass\n    status = ('==> pid:[%s] #threads:[%s] current thread:[%s]' %\n              (pid, threadnum, curthread))\n    return status", "response": "Generate the colored line indicating plugin status."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Attach(self, pid):\n    if self.inferior.is_running:\n      answer = raw_input('Already attached to process ' +\n                         str(self.inferior.pid) +\n                         '. Detach? [y]/n ')\n      if answer and answer != 'y' and answer != 'yes':\n        return None\n      self.Detach()\n    # Whatever position we had before will not make any sense now\n    for plugin in self.plugins:\n      plugin.position = None\n    self.inferior.Reinit(pid)", "response": "Attach to the process with the given pid."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef Detach(self):\n    for plugin in self.plugins:\n      plugin.position = None\n    self.inferior.Reinit(None)", "response": "Detach from the inferior."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef interact(self, banner=None):\n    sys.ps1 = getattr(sys, 'ps1', '>>> ')\n    sys.ps2 = getattr(sys, 'ps2', '... ')\n    if banner is None:\n      print ('Pyringe (Python %s.%s.%s) on %s\\n%s' %\n             (sys.version_info.major, sys.version_info.minor,\n              sys.version_info.micro, sys.platform, _WELCOME_MSG))\n    else:\n      print banner\n    more = False\n    while True:\n      try:\n        if more:\n          prompt = sys.ps2\n        else:\n          prompt = self.StatusLine() + '\\n' + sys.ps1\n        try:\n          line = self.raw_input(prompt)\n        except EOFError:\n          print ''\n          break\n        else:\n          more = self.push(line)\n      except KeyboardInterrupt:\n        print '\\nKeyboardInterrupt'\n        self.resetbuffer()\n        more = False", "response": "Closely emulate the interactive Python console."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nhanding control over to a new gdb process.", "response": "def StartGdb(self):\n    \"\"\"Hands control over to a new gdb process.\"\"\"\n    if self.inferior.is_running:\n      self.inferior.ShutDownGdb()\n      program_arg = 'program %d ' % self.inferior.pid\n    else:\n      program_arg = ''\n    os.system('gdb ' + program_arg + ' '.join(self.gdb_args))\n    reset_position = raw_input('Reset debugger position? [y]/n ')\n    if not reset_position or reset_position == 'y' or reset_position == 'yes':\n      self.position = None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get(self, word, default=nil):\n\n\t\tnode = self.__get_node(word)\n\t\toutput = nil\n\t\tif node:\n\t\t\toutput = node.output\n\n\t\tif output is nil:\n\t\t\tif default is nil:\n\t\t\t\traise KeyError(\"no key '%s'\" % word)\n\t\t\telse:\n\t\t\t\treturn default\n\t\telse:\n\t\t\treturn output", "response": "Retrieves output value associated with word."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef items(self):\n\n\t\tL = []\n\t\tdef aux(node, s):\n\t\t\ts = s + node.char\n\t\t\tif node.output is not nil:\n\t\t\t\tL.append((s, node.output))\n\n\t\t\tfor child in node.children.values():\n\t\t\t\tif child is not node:\n\t\t\t\t\taux(child, s)\n\n\t\taux(self.root, '')\n\t\treturn iter(L)", "response": "getAllKeysAndValuesGenerator returning all keys and values stored in a trie."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_word(self, word, value):\n\t\tif not word:\n\t\t\treturn\n\n\t\tnode = self.root\n\t\tfor c in word:\n\t\t\ttry:\n\t\t\t\tnode = node.children[c]\n\t\t\texcept KeyError:\n\t\t\t\tn = TrieNode(c)\n\t\t\t\tnode.children[c] = n\n\t\t\t\tnode = n\n\n\t\tnode.output = value", "response": "Adds word and associated value to the node."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if a word exists in the trie.", "response": "def exists(self, word):\n\t\t\"\"\"\n\t\tChecks if whole word is present in the trie.\n\t\t\"\"\"\n\n\t\tnode = self.__get_node(word)\n\t\tif node:\n\t\t\treturn bool(node.output != nil)\n\t\telse:\n\t\t\treturn False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_automaton(self):\n\n\t\tqueue = deque()\n\n\t\t# 1.\n\t\tfor i in range(256):\n\t\t\tc = chr(i)\n\t\t\tif c in self.root.children:\n\t\t\t\tnode = self.root.children[c]\n\t\t\t\tnode.fail = self.root\t# f(s) = 0\n\t\t\t\tqueue.append(node)\n\t\t\telse:\n\t\t\t\tself.root.children[c] = self.root\n\n\t\t# 2.\n\t\twhile queue:\n\t\t\tr = queue.popleft()\n\t\t\tfor node in r.children.values():\n\t\t\t\tqueue.append(node)\n\t\t\t\tstate = r.fail\n\t\t\t\twhile node.char not in state.children:\n\t\t\t\t\t\tstate = state.fail\n\n\t\t\t\tnode.fail = state.children.get(node.char, self.root)", "response": "Converts trie to Aho - Corasick automaton.\n\t"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_all(self, string, callback):\n\t\tfor index, output in self.iter(string):\n\t\t\tcallback(index, output)", "response": "find all the strings in the database"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the long description from the long description file.", "response": "def get_long_description():\n    \"\"\"\n    Strip the content index from the long description.\n    \"\"\"\n    import codecs \n    with codecs.open('README.rst', encoding='UTF-8') as f:\n        readme = [line for line in f if not line.startswith('.. contents::')]\n        return ''.join(readme)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntries to add a play button to the screenshot.", "response": "def _add_play_button(self, image_url, image_path):\n        \"\"\"Try to add a play button to the screenshot.\"\"\"\n        try:\n            from PIL import Image\n            from tempfile import NamedTemporaryFile\n            import urllib\n            try:\n                urlretrieve = urllib.request.urlretrieve\n            except ImportError:\n                urlretrieve = urllib.urlretrieve\n\n            # create temporary files for image operations\n            with NamedTemporaryFile(suffix=\".jpg\") as screenshot_img:\n                with NamedTemporaryFile(suffix=\".jpg\") as button_img:\n                    # grab screenshot and button image\n                    urlretrieve(image_url, screenshot_img.name)\n                    urlretrieve(play_button_url, button_img.name)\n\n                    # layer the images using PIL and save\n                    with Image.open(screenshot_img.name) as background:\n                        with Image.open(button_img.name) as foreground:\n                            background.paste(foreground, (90, 65), foreground)\n                            background.save(image_path)\n\n        except ImportError as e:\n            print(e)\n\n        except Exception as e:\n            print('Unable to add play button to YouTube '\n                  'screenshot (%s). Using the screenshot '\n                  'on its own instead.' % e)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef process(self):\n        self.modules.sort(key=lambda x: x.priority)\n\n        for module in self.modules:\n            transforms = module.transform(self.data)\n            transforms.sort(key=lambda x: x.linenum, reverse=True)\n\n            for transform in transforms:\n                linenum = transform.linenum\n\n                if isinstance(transform.data, basestring):\n                    transform.data = [transform.data]\n\n                if transform.oper == \"prepend\":\n                    self.data[linenum:linenum] = transform.data\n\n                elif transform.oper == \"append\":\n                    self.data[linenum+1:linenum+1] = transform.data\n\n                elif transform.oper == \"swap\":\n                    self.data[linenum:linenum+1] = transform.data\n\n                elif transform.oper == \"drop\":\n                    self.data[linenum:linenum+1] = []\n\n                elif transform.oper == \"noop\":\n                    pass", "response": "This method handles the actual processing of Modules and Transforms and returns a list of the related objects."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert strings to CamelCase.", "response": "def camelize(string, uppercase_first_letter=True):\n    \"\"\"\n    Convert strings to CamelCase.\n\n    Examples::\n\n        >>> camelize(\"device_type\")\n        \"DeviceType\"\n        >>> camelize(\"device_type\", False)\n        \"deviceType\"\n\n    :func:`camelize` can be thought of as a inverse of :func:`underscore`,\n    although there are some cases where that does not hold::\n\n        >>> camelize(underscore(\"IOError\"))\n        \"IoError\"\n\n    :param uppercase_first_letter: if set to `True` :func:`camelize` converts\n        strings to UpperCamelCase. If set to `False` :func:`camelize` produces\n        lowerCamelCase. Defaults to `True`.\n    \"\"\"\n    if uppercase_first_letter:\n        return re.sub(r\"(?:^|_)(.)\", lambda m: m.group(1).upper(), string)\n    else:\n        return string[0].lower() + camelize(string)[1:]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef humanize(word):\n    word = re.sub(r\"_id$\", \"\", word)\n    word = word.replace('_', ' ')\n    word = re.sub(r\"(?i)([a-z\\d]*)\", lambda m: m.group(1).lower(), word)\n    word = re.sub(r\"^\\w\", lambda m: m.group(0).upper(), word)\n    return word", "response": "Capitalize the first word turn underscores into spaces strip a\n    trailing _id"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntranslate a string into a valid URL parameter.", "response": "def parameterize(string, separator='-'):\n    \"\"\"\n    Replace special characters in a string so that it may be used as part of a\n    'pretty' URL.\n\n    Example::\n\n        >>> parameterize(u\"Donald E. Knuth\")\n        'donald-e-knuth'\n\n    \"\"\"\n    string = transliterate(string)\n    # Turn unwanted chars into the separator\n    string = re.sub(r\"(?i)[^a-z0-9\\-_]+\", separator, string)\n    if separator:\n        re_sep = re.escape(separator)\n        # No more than one of the separator in a row.\n        string = re.sub(r'%s{2,}' % re_sep, separator, string)\n        # Remove leading/trailing separator.\n        string = re.sub(r\"(?i)^{sep}|{sep}$\".format(sep=re_sep), '', string)\n\n    return string.lower()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pluralize(word):\n    if not word or word.lower() in UNCOUNTABLES:\n        return word\n    else:\n        for rule, replacement in PLURALS:\n            if re.search(rule, word):\n                return re.sub(rule, replacement, word)\n        return word", "response": "Return the plural form of a word."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef singularize(word):\n    for inflection in UNCOUNTABLES:\n        if re.search(r'(?i)\\b(%s)\\Z' % inflection, word):\n            return word\n\n    for rule, replacement in SINGULARS:\n        if re.search(rule, word):\n            return re.sub(rule, replacement, word)\n    return word", "response": "Returns the singular form of a word."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncapitalize all the words and replace some characters in the string to create a nicer looking title.", "response": "def titleize(word):\n    \"\"\"\n    Capitalize all the words and replace some characters in the string to\n    create a nicer looking title. :func:`titleize` is meant for creating pretty\n    output.\n\n    Examples::\n\n      >>> titleize(\"man from the boondocks\")\n      \"Man From The Boondocks\"\n      >>> titleize(\"x-men: the last stand\")\n      \"X Men: The Last Stand\"\n      >>> titleize(\"TheManWithoutAPast\")\n      \"The Man Without A Past\"\n      >>> titleize(\"raiders_of_the_lost_ark\")\n      \"Raiders Of The Lost Ark\"\n\n    \"\"\"\n    return re.sub(\n        r\"\\b('?[a-z])\",\n        lambda match: match.group(1).capitalize(),\n        humanize(underscore(word))\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef underscore(word):\n    word = re.sub(r\"([A-Z]+)([A-Z][a-z])\", r'\\1_\\2', word)\n    word = re.sub(r\"([a-z\\d])([A-Z])\", r'\\1_\\2', word)\n    word = word.replace(\"-\", \"_\")\n    return word.lower()", "response": "Make an underscored lowercase form from the expression in the string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprint all objects. Handy for debugging.", "response": "def print_all(msg):\n        \"\"\"Print all objects.\n\n        Print a table of all active libvips objects. Handy for debugging.\n\n        \"\"\"\n\n        gc.collect()\n        logger.debug(msg)\n        vips_lib.vips_object_print_all()\n        logger.debug()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the GType of a GObject property. This function returns 0 if the property does not exist.", "response": "def get_typeof(self, name):\n        \"\"\"Get the GType of a GObject property.\n\n        This function returns 0 if the property does not exist.\n\n        \"\"\"\n\n        # logger.debug('VipsObject.get_typeof: self = %s, name = %s',\n        #              str(self), name)\n\n        pspec = self._get_pspec(name)\n        if pspec is None:\n            # need to clear any error, this is horrible\n            Error('')\n            return 0\n\n        return pspec.value_type"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the blurb for a GObject property.", "response": "def get_blurb(self, name):\n        \"\"\"Get the blurb for a GObject property.\"\"\"\n\n        c_str = gobject_lib.g_param_spec_get_blurb(self._get_pspec(name))\n        return _to_string(c_str)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a GObject property.", "response": "def get(self, name):\n        \"\"\"Get a GObject property.\n\n        The value of the property is converted to a Python value.\n\n        \"\"\"\n\n        logger.debug('VipsObject.get: name = %s', name)\n\n        pspec = self._get_pspec(name)\n        if pspec is None:\n            raise Error('Property not found.')\n        gtype = pspec.value_type\n\n        gv = pyvips.GValue()\n        gv.set_type(gtype)\n        go = ffi.cast('GObject *', self.pointer)\n        gobject_lib.g_object_get_property(go, _to_bytes(name), gv.pointer)\n\n        return gv.get()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set(self, name, value):\n\n        logger.debug('VipsObject.set: name = %s, value = %s', name, value)\n\n        gtype = self.get_typeof(name)\n\n        gv = pyvips.GValue()\n        gv.set_type(gtype)\n        gv.set(value)\n        go = ffi.cast('GObject *', self.pointer)\n        gobject_lib.g_object_set_property(go, _to_bytes(name), gv.pointer)", "response": "Set a GObject property."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset a series of properties using a string.", "response": "def set_string(self, string_options):\n        \"\"\"Set a series of properties using a string.\n\n        For example::\n\n            'fred=12, tile'\n            '[fred=12]'\n\n        \"\"\"\n\n        vo = ffi.cast('VipsObject *', self.pointer)\n        cstr = _to_bytes(string_options)\n        result = vips_lib.vips_object_set_from_string(vo, cstr)\n\n        return result == 0"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_description(self):\n\n        vo = ffi.cast('VipsObject *', self.pointer)\n        return _to_string(vips_lib.vips_object_get_description(vo))", "response": "Get the description of a GObject."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cdefs(features):\n\n    code = ''\n\n    # apparently the safest way to do this\n    is_64bits = sys.maxsize > 2 ** 32\n\n    # GType is an int the size of a pointer ... I don't think we can just use\n    # size_t, sadly\n    if is_64bits:\n        code += '''\n            typedef uint64_t GType;\n        '''\n    else:\n        code += '''\n            typedef uint32_t GType;\n        '''\n\n    code += '''\n        typedef void (*GLogFunc) (const char* log_domain,\n            int log_level,\n            const char* message, void* user_data);\n        int g_log_set_handler (const char* log_domain,\n            int log_levels,\n            GLogFunc log_func, void* user_data);\n\n        extern \"Python\" void _log_handler_callback (const char*, int,\n            const char*, void*);\n\n        void g_log_remove_handler (const char* log_domain, int handler_id);\n\n        typedef struct _VipsImage VipsImage;\n        typedef struct _GValue GValue;\n\n        void* g_malloc (size_t size);\n        void g_free (void* data);\n        int vips_free (void* a);\n\n        void vips_leak_set (int leak);\n\n        char* vips_path_filename7 (const char* path);\n        char* vips_path_mode7 (const char* path);\n\n        GType vips_type_find (const char* basename, const char* nickname);\n        const char* vips_nickname_find (GType type);\n\n        const char* g_type_name (GType gtype);\n        GType g_type_from_name (const char* name);\n\n        typedef void* (*VipsTypeMap2Fn) (GType type, void* a, void* b);\n        void* vips_type_map (GType base, VipsTypeMap2Fn fn, void* a, void* b);\n\n        const char* vips_error_buffer (void);\n        void vips_error_clear (void);\n\n        typedef struct _GValue {\n            GType g_type;\n            uint64_t data[2];\n        } GValue;\n\n        void g_value_init (GValue* value, GType gtype);\n        void g_value_unset (GValue* value);\n        GType g_type_fundamental (GType gtype);\n\n        int vips_enum_from_nick (const char* domain,\n            GType gtype, const char* str);\n        const char *vips_enum_nick (GType gtype, int value);\n\n        void g_value_set_boolean (GValue* value, int v_boolean);\n        void g_value_set_int (GValue* value, int i);\n        void g_value_set_uint64 (GValue* value, uint64_t ull);\n        void g_value_set_double (GValue* value, double d);\n        void g_value_set_enum (GValue* value, int e);\n        void g_value_set_flags (GValue* value, unsigned int f);\n        void g_value_set_string (GValue* value, const char* str);\n        void vips_value_set_ref_string (GValue* value, const char* str);\n        void g_value_set_object (GValue* value, void* object);\n        void vips_value_set_array_double (GValue* value,\n            const double* array, int n );\n        void vips_value_set_array_int (GValue* value,\n            const int* array, int n );\n        void vips_value_set_array_image (GValue *value, int n);\n        typedef int (*VipsCallbackFn)(void* a, void* b);\n        void vips_value_set_blob (GValue* value,\n            VipsCallbackFn free_fn, void* data, size_t length);\n\n        int g_value_get_boolean (const GValue* value);\n        int g_value_get_int (GValue* value);\n        uint64_t g_value_get_uint64 (GValue* value);\n        double g_value_get_double (GValue* value);\n        int g_value_get_enum (GValue* value);\n        unsigned int g_value_get_flags (GValue* value);\n        const char* g_value_get_string (GValue* value);\n        const char* vips_value_get_ref_string (const GValue* value,\n            size_t* length);\n        void* g_value_get_object (GValue* value);\n        double* vips_value_get_array_double (const GValue* value, int* n);\n        int* vips_value_get_array_int (const GValue* value, int* n);\n        VipsImage** vips_value_get_array_image (const GValue* value, int* n);\n        void* vips_value_get_blob (const GValue* value, size_t* length);\n\n        // need to make some of these by hand\n        GType vips_interpretation_get_type (void);\n        GType vips_operation_flags_get_type (void);\n        GType vips_band_format_get_type (void);\n        GType vips_token_get_type (void);\n        GType vips_saveable_get_type (void);\n        GType vips_image_type_get_type (void);\n\n        typedef struct _GData GData;\n\n        typedef struct _GTypeClass GTypeClass;\n\n        typedef struct _GTypeInstance {\n            GTypeClass *g_class;\n        } GTypeInstance;\n\n        typedef struct _GObject {\n            GTypeInstance g_type_instance;\n            unsigned int ref_count;\n            GData *qdata;\n        } GObject;\n\n        typedef struct _GParamSpec {\n            GTypeInstance g_type_instance;\n\n            const char* name;\n            unsigned int flags;\n            GType value_type;\n            GType owner_type;\n\n            // private, but cffi in API mode needs these to be able to get the\n            // offset of any member\n            char* _nick;\n            char* _blurb;\n            GData* qdata;\n            unsigned int ref_count;\n            unsigned int param_id;\n        } GParamSpec;\n\n        typedef struct _GEnumValue {\n            int value;\n\n            const char *value_name;\n            const char *value_nick;\n        } GEnumValue;\n\n        typedef struct _GEnumClass {\n          GTypeClass *g_type_class;\n\n          int minimum;\n          int maximum;\n          unsigned int n_values;\n          GEnumValue *values;\n        } GEnumClass;\n\n        void* g_type_class_ref (GType type);\n\n        void g_object_ref (void* object);\n        void g_object_unref (void* object);\n\n        void g_object_set_property (GObject* object,\n            const char *name, GValue* value);\n        void g_object_get_property (GObject* object,\n            const char* name, GValue* value);\n\n        typedef struct _VipsObject {\n    '''\n\n    # this field changed name in libvips 8.4\n    if _at_least(features, 8, 4):\n        code += '''\n            GObject parent_instance;\n        '''\n    else:\n        code += '''\n            GObject parent_object;\n        '''\n\n    code += '''\n            bool constructed;\n            bool static_object;\n            void *argument_table;\n            char *nickname;\n            char *description;\n            bool preclose;\n            bool close;\n            bool postclose;\n            size_t local_memory;\n        } VipsObject;\n\n        typedef struct _VipsObjectClass VipsObjectClass;\n\n        typedef struct _VipsArgument {\n            GParamSpec *pspec;\n        } VipsArgument;\n\n        typedef struct _VipsArgumentInstance {\n            VipsArgument parent;\n\n            // more\n        } VipsArgumentInstance;\n\n        typedef enum _VipsArgumentFlags {\n            VIPS_ARGUMENT_NONE = 0,\n            VIPS_ARGUMENT_REQUIRED = 1,\n            VIPS_ARGUMENT_CONSTRUCT = 2,\n            VIPS_ARGUMENT_SET_ONCE = 4,\n            VIPS_ARGUMENT_SET_ALWAYS = 8,\n            VIPS_ARGUMENT_INPUT = 16,\n            VIPS_ARGUMENT_OUTPUT = 32,\n            VIPS_ARGUMENT_DEPRECATED = 64,\n            VIPS_ARGUMENT_MODIFY = 128\n        } VipsArgumentFlags;\n\n        typedef struct _VipsArgumentClass {\n            VipsArgument parent;\n\n            VipsObjectClass *object_class;\n            VipsArgumentFlags flags;\n            int priority;\n            unsigned int offset;\n        } VipsArgumentClass;\n\n        int vips_object_get_argument (VipsObject* object,\n            const char *name, GParamSpec** pspec,\n            VipsArgumentClass** argument_class,\n            VipsArgumentInstance** argument_instance);\n\n        void vips_object_print_all (void);\n\n        int vips_object_set_from_string (VipsObject* object,\n            const char* options);\n\n        const char* vips_object_get_description (VipsObject* object);\n\n        const char* g_param_spec_get_blurb (GParamSpec* pspec);\n\n        typedef struct _VipsImage {\n    '''\n\n    # this field changed name in libvips 8.4\n    if _at_least(features, 8, 4):\n        code += '''\n            VipsObject parent_instance;\n        '''\n    else:\n        code += '''\n            VipsObject parent_object;\n        '''\n\n    code += '''\n            // more\n        } VipsImage;\n\n        const char* vips_foreign_find_load (const char* name);\n        const char* vips_foreign_find_load_buffer (const void* data,\n            size_t size);\n        const char* vips_foreign_find_save (const char* name);\n        const char* vips_foreign_find_save_buffer (const char* suffix);\n\n        VipsImage* vips_image_new_matrix_from_array (int width, int height,\n                const double* array, int size);\n        VipsImage* vips_image_new_from_memory (const void* data, size_t size,\n                int width, int height, int bands, int format);\n\n        VipsImage* vips_image_copy_memory (VipsImage* image);\n\n        GType vips_image_get_typeof (const VipsImage* image,\n            const char* name);\n        int vips_image_get (const VipsImage* image,\n            const char* name, GValue* value_copy);\n        void vips_image_set (VipsImage* image,\n            const char* name, GValue* value);\n        int vips_image_remove (VipsImage* image, const char* name);\n\n        char* vips_filename_get_filename (const char* vips_filename);\n        char* vips_filename_get_options (const char* vips_filename);\n\n        VipsImage* vips_image_new_temp_file (const char* format);\n\n        int vips_image_write (VipsImage* image, VipsImage* out);\n        void* vips_image_write_to_memory (VipsImage* in, size_t* size_out);\n\n        typedef struct _VipsInterpolate {\n            VipsObject parent_object;\n\n            // more\n        } VipsInterpolate;\n\n        VipsInterpolate* vips_interpolate_new (const char* name);\n\n        typedef struct _VipsOperation {\n            VipsObject parent_instance;\n\n            // more\n        } VipsOperation;\n\n        VipsOperation* vips_operation_new (const char* name);\n\n        typedef void* (*VipsArgumentMapFn) (VipsObject* object,\n            GParamSpec* pspec,\n            VipsArgumentClass* argument_class,\n            VipsArgumentInstance* argument_instance,\n            void* a, void* b);\n\n        void* vips_argument_map (VipsObject* object,\n            VipsArgumentMapFn fn, void* a, void* b);\n\n        typedef struct _VipsRegion {\n            GObject parent_object;\n\n            // more\n        } VipsRegion;\n\n        VipsRegion* vips_region_new (VipsImage*);\n\n        VipsOperation* vips_cache_operation_build (VipsOperation* operation);\n        void vips_object_unref_outputs (VipsObject* object);\n\n        int vips_operation_get_flags (VipsOperation* operation);\n\n        void vips_cache_set_max (int max);\n        void vips_cache_set_max_mem (size_t max_mem);\n        void vips_cache_set_max_files (int max_files);\n        void vips_cache_set_trace (int trace);\n\n    '''\n\n    if _at_least(features, 8, 5):\n        code += '''\n            char** vips_image_get_fields (VipsImage* image);\n            int vips_image_hasalpha (VipsImage* image);\n\n        '''\n\n    if _at_least(features, 8, 6):\n        code += '''\n            GType vips_blend_mode_get_type (void);\n            void vips_value_set_blob_free (GValue* value,\n                void* data, size_t length);\n\n        '''\n\n    if _at_least(features, 8, 7):\n        code += '''\n            int vips_object_get_args (VipsObject* object,\n                const char*** names, int** flags, int* n_args);\n\n        '''\n\n    if _at_least(features, 8, 8):\n        code += '''\n            char** vips_foreign_get_suffixes (void);\n\n            void* vips_region_fetch (VipsRegion*, int, int, int, int,\n                size_t* length);\n            int vips_region_width (VipsRegion*);\n            int vips_region_height (VipsRegion*);\n\n        '''\n\n    # we must only define these in API mode ... in ABI mode we need to call\n    # these things earlier\n    if features['api']:\n        code += '''\n            int vips_init (const char* argv0);\n            int vips_version (int flag);\n        '''\n\n    # ... means inherit from C defines\n    code += '#define VIPS_MAJOR_VERSION ...\\n'\n    code += '#define VIPS_MINOR_VERSION ...\\n'\n    code += '#define VIPS_MICRO_VERSION ...\\n'\n\n    # add contents of features as a comment ... handy for debugging\n    for key, value in features.items():\n        code += '//%s = %s\\n' % (key, value)\n\n    return code", "response": "Return the C API declarations for libvips."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef call(operation_name, *args, **kwargs):\n\n        logger.debug('VipsOperation.call: operation_name = %s', operation_name)\n        # logger.debug('VipsOperation.call: args = %s, kwargs =%s',\n        #              args, kwargs)\n\n        # pull out the special string_options kwarg\n        string_options = kwargs.pop('string_options', '')\n\n        logger.debug('VipsOperation.call: string_options = %s', string_options)\n\n        op = Operation.new_from_name(operation_name)\n\n        arguments = op.get_args()\n        # logger.debug('arguments = %s', arguments)\n\n        # make a thing to quickly get flags from an arg name\n        flags_from_name = {}\n\n        # count required input args\n        n_required = 0\n\n        for name, flags in arguments:\n            flags_from_name[name] = flags\n\n            if ((flags & _INPUT) != 0 and\n                    (flags & _REQUIRED) != 0 and\n                    (flags & _DEPRECATED) == 0):\n                n_required += 1\n\n        if n_required != len(args):\n            raise Error('unable to call {0}: {1} arguments given, '\n                        'but {2} required'.format(operation_name, len(args),\n                                                  n_required))\n\n        # the first image argument is the thing we expand constants to\n        # match ... look inside tables for images, since we may be passing\n        # an array of image as a single param\n        match_image = _find_inside(lambda x:\n                                   isinstance(x, pyvips.Image),\n                                   args)\n\n        logger.debug('VipsOperation.call: match_image = %s', match_image)\n\n        # set any string options before any args so they can't be\n        # overridden\n        if not op.set_string(string_options):\n            raise Error('unable to call {0}'.format(operation_name))\n\n        # set required and optional args\n        n = 0\n        for name, flags in arguments:\n            if ((flags & _INPUT) != 0 and\n                    (flags & _REQUIRED) != 0 and\n                    (flags & _DEPRECATED) == 0):\n                op.set(name, flags, match_image, args[n])\n                n += 1\n\n        for name, value in kwargs.items():\n            if name not in flags_from_name:\n                raise Error('{0} does not support argument '\n                            '{1}'.format(operation_name, name))\n\n            op.set(name, flags_from_name[name], match_image, value)\n\n        # build operation\n        vop = vips_lib.vips_cache_operation_build(op.pointer)\n        if vop == ffi.NULL:\n            raise Error('unable to call {0}'.format(operation_name))\n        op = Operation(vop)\n\n        # find all input images and gather up all the references they hold\n        references = []\n\n        def add_reference(x):\n            if isinstance(x, pyvips.Image):\n                # += won't work on non-local references\n                for i in x._references:\n                    references.append(i)\n\n            return False\n\n        _find_inside(add_reference, args)\n        for key, value in kwargs.items():\n            _find_inside(add_reference, value)\n\n        # fetch required output args, plus modified input images\n        result = []\n        for name, flags in arguments:\n            if ((flags & _OUTPUT) != 0 and\n                    (flags & _REQUIRED) != 0 and\n                    (flags & _DEPRECATED) == 0):\n                result.append(op.get(name))\n\n            if (flags & _INPUT) != 0 and (flags & _MODIFY) != 0:\n                result.append(op.get(name))\n\n        # fetch optional output args\n        opts = {}\n        for name, value in kwargs.items():\n            flags = flags_from_name[name]\n\n            if ((flags & _OUTPUT) != 0 and\n                    (flags & _REQUIRED) == 0 and\n                    (flags & _DEPRECATED) == 0):\n                opts[name] = op.get(name)\n\n        vips_lib.vips_object_unref_outputs(op.object)\n\n        if len(opts) > 0:\n            result.append(opts)\n\n        # all output images need all input references\n        def set_reference(x):\n            if isinstance(x, pyvips.Image):\n                x._references += references\n\n            return False\n\n        _find_inside(set_reference, result)\n\n        if len(result) == 0:\n            result = None\n        elif len(result) == 1:\n            result = result[0]\n\n        logger.debug('VipsOperation.call: result = %s', result)\n\n        return result", "response": "Call a libvips operation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a google - style docstring for an operation.", "response": "def generate_docstring(operation_name):\n        \"\"\"Make a google-style docstring.\n\n        This is used to generate help() output.\n\n        \"\"\"\n\n        if operation_name in Operation._docstring_cache:\n            return Operation._docstring_cache[operation_name]\n\n        op = Operation.new_from_name(operation_name)\n        if (op.get_flags() & _OPERATION_DEPRECATED) != 0:\n            raise Error('No such operator.',\n                        'operator \"{0}\" is deprecated'.format(operation_name))\n\n        # we are only interested in non-deprecated args\n        args = [[name, flags] for name, flags in op.get_args()\n                if not flags & _DEPRECATED]\n\n        # find the first required input image arg, if any ... that will be self\n        member_x = None\n        for name, flags in args:\n            if ((flags & _INPUT) != 0 and\n                    (flags & _REQUIRED) != 0 and\n                    op.get_typeof(name) == GValue.image_type):\n                member_x = name\n                break\n\n        required_input = [name for name, flags in args\n                          if (flags & _INPUT) != 0 and\n                          (flags & _REQUIRED) != 0 and\n                          name != member_x]\n\n        optional_input = [name for name, flags in args\n                          if (flags & _INPUT) != 0 and\n                             (flags & _REQUIRED) == 0]\n\n        required_output = [name for name, flags in args\n                           if ((flags & _OUTPUT) != 0 and\n                               (flags & _REQUIRED) != 0) or\n                              ((flags & _INPUT) != 0 and\n                               (flags & _REQUIRED) != 0 and\n                               (flags & _MODIFY) != 0)]\n\n        optional_output = [name for name, flags in args\n                           if (flags & _OUTPUT) != 0 and\n                              (flags & _REQUIRED) == 0]\n\n        description = op.get_description()\n        result = description[0].upper() + description[1:] + \".\\n\\n\"\n        result += \"Example:\\n\"\n\n        result += \"   \" + \", \".join(required_output) + \" = \"\n        if member_x is not None:\n            result += member_x + \".\" + operation_name + \"(\"\n        else:\n            result += \"pyvips.Image.\" + operation_name + \"(\"\n\n        result += \", \".join(required_input)\n        if len(optional_input) > 0 and len(required_input) > 0:\n            result += \", \"\n        result += \", \".join([x + \" = \" +\n                             GValue.gtype_to_python(op.get_typeof(x))\n                             for x in optional_input])\n        result += \")\\n\"\n\n        def argstr(name):\n            return (u'    {0} ({1}): {2}\\n'.\n                    format(name,\n                           GValue.gtype_to_python(op.get_typeof(name)),\n                           op.get_blurb(name)))\n\n        result += \"\\nReturns:\\n\"\n        for name in required_output:\n            result += argstr(name)\n\n        names = []\n        if member_x is not None:\n            names += [member_x]\n        names += required_input\n\n        result += \"\\nArgs:\\n\"\n        for name in names:\n            result += argstr(name)\n\n        if len(optional_input) > 0:\n            result += \"\\nKeyword args:\\n\"\n            for name in optional_input:\n                result += argstr(name)\n\n        if len(optional_output) > 0:\n            result += \"\\nOther Parameters:\\n\"\n            for name in optional_output:\n                result += argstr(name)\n\n        result += \"\\nRaises:\\n    :class:`.Error`\\n\"\n\n        # add to cache to save building again\n        Operation._docstring_cache[operation_name] = result\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates sphinx documentation for all available image methods.", "response": "def generate_sphinx_all():\n        \"\"\"Generate sphinx documentation.\n\n        This generates a .rst file for all auto-generated image methods. Use it\n        to regenerate the docs with something like::\n\n            $ python -c \\\n\"import pyvips; pyvips.Operation.generate_sphinx_all()\" > x\n\n        And copy-paste the file contents into doc/vimage.rst in the appropriate\n        place.\n\n        \"\"\"\n\n        # generate list of all nicknames we can generate docstrings for\n\n        all_nicknames = []\n\n        def add_nickname(gtype, a, b):\n            nickname = nickname_find(gtype)\n            try:\n                Operation.generate_sphinx(nickname)\n                all_nicknames.append(nickname)\n            except Error:\n                pass\n\n            type_map(gtype, add_nickname)\n\n            return ffi.NULL\n\n        type_map(type_from_name('VipsOperation'), add_nickname)\n\n        all_nicknames.sort()\n\n        # remove operations we have to wrap by hand\n\n        exclude = ['scale', 'ifthenelse', 'bandjoin', 'bandrank']\n        all_nicknames = [x for x in all_nicknames if x not in exclude]\n\n        # Output summary table\n        print('.. class:: pyvips.Image\\n')\n        print('   .. rubric:: Methods\\n')\n        print('   .. autosummary::')\n        print('      :nosignatures:\\n')\n        for nickname in all_nicknames:\n            print('      ~{0}'.format(nickname))\n        print()\n\n        # Output docs\n        print()\n        for nickname in all_nicknames:\n            docstr = Operation.generate_sphinx(nickname)\n            docstr = docstr.replace('\\n', '\\n      ')\n            print('   ' + docstr)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef new(image):\n\n        pointer = vips_lib.vips_region_new(image.pointer)\n        if pointer == ffi.NULL:\n            raise Error('unable to make region')\n\n        return pyvips.Region(pointer)", "response": "Make a region on an image."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfills a region with pixel data.", "response": "def fetch(self, x, y, w, h):\n        \"\"\"Fill a region with pixel data.\n\n        Pixels are filled with data!\n\n        Returns:\n            Pixel data.\n\n        Raises:\n            :class:`.Error`\n\n        \"\"\"\n\n        if not at_least_libvips(8, 8):\n            raise Error('libvips too old')\n\n        psize = ffi.new('size_t *')\n        pointer = vips_lib.vips_region_fetch(self.pointer, x, y, w, h, psize)\n        if pointer == ffi.NULL:\n            raise Error('unable to fetch from region')\n\n        pointer = ffi.gc(pointer, glib_lib.g_free)\n        return ffi.buffer(pointer, psize[0])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmapping a gtype to the name of the Python type we use to represent it.", "response": "def gtype_to_python(gtype):\n        \"\"\"Map a gtype to the name of the Python type we use to represent it.\n\n        \"\"\"\n\n        fundamental = gobject_lib.g_type_fundamental(gtype)\n\n        if gtype in GValue._gtype_to_python:\n            return GValue._gtype_to_python[gtype]\n        if fundamental in GValue._gtype_to_python:\n            return GValue._gtype_to_python[fundamental]\n        return '<unknown type>'"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_enum(gtype, value):\n\n        if isinstance(value, basestring if _is_PY2 else str):\n            enum_value = vips_lib.vips_enum_from_nick(b'pyvips', gtype,\n                                                      _to_bytes(value))\n            if enum_value < 0:\n                raise Error('no value {0} in gtype {1} ({2})'.\n                            format(value, type_name(gtype), gtype))\n        else:\n            enum_value = value\n\n        return enum_value", "response": "Turn a string into an enum value ready to be passed into libvips."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_enum(gtype, enum_value):\n\n        pointer = vips_lib.vips_enum_nick(gtype, enum_value)\n        if pointer == ffi.NULL:\n            raise Error('value not in enum')\n\n        return _to_string(pointer)", "response": "Turn an int back into an enum string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting a value in the current object.", "response": "def set(self, value):\n        \"\"\"Set a GValue.\n\n        The value is converted to the type of the GValue, if possible, and\n        assigned.\n\n        \"\"\"\n\n        # logger.debug('GValue.set: value = %s', value)\n\n        gtype = self.gvalue.g_type\n        fundamental = gobject_lib.g_type_fundamental(gtype)\n\n        if gtype == GValue.gbool_type:\n            gobject_lib.g_value_set_boolean(self.gvalue, value)\n        elif gtype == GValue.gint_type:\n            gobject_lib.g_value_set_int(self.gvalue, int(value))\n        elif gtype == GValue.guint64_type:\n            gobject_lib.g_value_set_uint64(self.gvalue, value)\n        elif gtype == GValue.gdouble_type:\n            gobject_lib.g_value_set_double(self.gvalue, value)\n        elif fundamental == GValue.genum_type:\n            gobject_lib.g_value_set_enum(self.gvalue,\n                                         GValue.to_enum(gtype, value))\n        elif fundamental == GValue.gflags_type:\n            gobject_lib.g_value_set_flags(self.gvalue, value)\n        elif gtype == GValue.gstr_type:\n            gobject_lib.g_value_set_string(self.gvalue, _to_bytes(value))\n        elif gtype == GValue.refstr_type:\n            vips_lib.vips_value_set_ref_string(self.gvalue, _to_bytes(value))\n        elif fundamental == GValue.gobject_type:\n            gobject_lib.g_value_set_object(self.gvalue, value.pointer)\n        elif gtype == GValue.array_int_type:\n            if isinstance(value, numbers.Number):\n                value = [value]\n\n            array = ffi.new('int[]', value)\n            vips_lib.vips_value_set_array_int(self.gvalue, array, len(value))\n        elif gtype == GValue.array_double_type:\n            if isinstance(value, numbers.Number):\n                value = [value]\n\n            array = ffi.new('double[]', value)\n            vips_lib.vips_value_set_array_double(self.gvalue, array,\n                                                 len(value))\n        elif gtype == GValue.array_image_type:\n            if isinstance(value, pyvips.Image):\n                value = [value]\n\n            vips_lib.vips_value_set_array_image(self.gvalue, len(value))\n            array = vips_lib.vips_value_get_array_image(self.gvalue, ffi.NULL)\n            for i, image in enumerate(value):\n                gobject_lib.g_object_ref(image.pointer)\n                array[i] = image.pointer\n        elif gtype == GValue.blob_type:\n            # we need to set the blob to a copy of the string that vips_lib\n            # can own\n            memory = glib_lib.g_malloc(len(value))\n            ffi.memmove(memory, value, len(value))\n\n            # this is horrible!\n            #\n            # * in API mode, we must have 8.6+ and use set_blob_free to\n            #   attach the metadata to avoid leaks\n            # * pre-8.6, we just pass a NULL free pointer and live with the\n            #   leak\n            #\n            # this is because in API mode you can't pass a builtin (what\n            # vips_lib.g_free() becomes) as a parameter to ffi.callback(), and\n            # vips_value_set_blob() needs a callback for arg 2\n            #\n            # additionally, you can't make a py def which calls g_free() and\n            # then use the py def in the callback, since libvips will trigger\n            # these functions during cleanup, and py will have shut down by\n            # then and you'll get a segv\n\n            if at_least_libvips(8, 6):\n                vips_lib.vips_value_set_blob_free(self.gvalue,\n                                                  memory, len(value))\n            else:\n                if pyvips.API_mode:\n                    vips_lib.vips_value_set_blob(self.gvalue,\n                                                 ffi.NULL, memory, len(value))\n                else:\n                    vips_lib.vips_value_set_blob(self.gvalue,\n                                                 glib_lib.g_free,\n                                                 memory, len(value))\n        else:\n            raise Error('unsupported gtype for set {0}, fundamental {1}'.\n                        format(type_name(gtype), type_name(fundamental)))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self):\n\n        # logger.debug('GValue.get: self = %s', self)\n\n        gtype = self.gvalue.g_type\n        fundamental = gobject_lib.g_type_fundamental(gtype)\n\n        result = None\n\n        if gtype == GValue.gbool_type:\n            result = bool(gobject_lib.g_value_get_boolean(self.gvalue))\n        elif gtype == GValue.gint_type:\n            result = gobject_lib.g_value_get_int(self.gvalue)\n        elif gtype == GValue.guint64_type:\n            result = gobject_lib.g_value_get_uint64(self.gvalue)\n        elif gtype == GValue.gdouble_type:\n            result = gobject_lib.g_value_get_double(self.gvalue)\n        elif fundamental == GValue.genum_type:\n            return GValue.from_enum(gtype,\n                                    gobject_lib.g_value_get_enum(self.gvalue))\n        elif fundamental == GValue.gflags_type:\n            result = gobject_lib.g_value_get_flags(self.gvalue)\n        elif gtype == GValue.gstr_type:\n            pointer = gobject_lib.g_value_get_string(self.gvalue)\n\n            if pointer != ffi.NULL:\n                result = _to_string(pointer)\n        elif gtype == GValue.refstr_type:\n            psize = ffi.new('size_t *')\n            pointer = vips_lib.vips_value_get_ref_string(self.gvalue, psize)\n\n            # psize[0] will be number of bytes in string, but just assume it's\n            # NULL-terminated\n            result = _to_string(pointer)\n        elif gtype == GValue.image_type:\n            # g_value_get_object() will not add a ref ... that is\n            # held by the gvalue\n            go = gobject_lib.g_value_get_object(self.gvalue)\n            vi = ffi.cast('VipsImage *', go)\n\n            # we want a ref that will last with the life of the vimage:\n            # this ref is matched by the unref that's attached to finalize\n            # by Image()\n            gobject_lib.g_object_ref(go)\n\n            result = pyvips.Image(vi)\n        elif gtype == GValue.array_int_type:\n            pint = ffi.new('int *')\n            array = vips_lib.vips_value_get_array_int(self.gvalue, pint)\n\n            result = []\n            for i in range(0, pint[0]):\n                result.append(array[i])\n        elif gtype == GValue.array_double_type:\n            pint = ffi.new('int *')\n            array = vips_lib.vips_value_get_array_double(self.gvalue, pint)\n\n            result = []\n            for i in range(0, pint[0]):\n                result.append(array[i])\n        elif gtype == GValue.array_image_type:\n            pint = ffi.new('int *')\n            array = vips_lib.vips_value_get_array_image(self.gvalue, pint)\n\n            result = []\n            for i in range(0, pint[0]):\n                vi = array[i]\n                gobject_lib.g_object_ref(vi)\n                image = pyvips.Image(vi)\n                result.append(image)\n        elif gtype == GValue.blob_type:\n            psize = ffi.new('size_t *')\n            array = vips_lib.vips_value_get_blob(self.gvalue, psize)\n            buf = ffi.cast('char*', array)\n\n            result = ffi.unpack(buf, psize[0])\n        else:\n            raise Error('unsupported gtype for get {0}'.\n                        format(type_name(gtype)))\n\n        return result", "response": "Get the contents of a GValue."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntransforms image coordinates to polar.", "response": "def to_polar(image):\n    \"\"\"Transform image coordinates to polar.\n\n    The image is transformed so that it is wrapped around a point in the\n    centre. Vertical straight lines become circles or segments of circles,\n    horizontal straight lines become radial spokes.\n    \"\"\"\n    # xy image, origin in the centre, scaled to fit image to a circle\n    xy = pyvips.Image.xyz(image.width, image.height)\n    xy -= [image.width / 2.0, image.height / 2.0]\n    scale = min(image.width, image.height) / float(image.width)\n    xy *= 2.0 / scale\n\n    index = xy.polar()\n\n    # scale vertical axis to 360 degrees\n    index *= [1, image.height / 360.0]\n\n    return image.mapim(index)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntransform image coordinates to rectangular.", "response": "def to_rectangular(image):\n    \"\"\"Transform image coordinates to rectangular.\n\n    The image is transformed so that it is unwrapped from a point in the\n    centre. Circles or segments of circles become vertical straight lines,\n    radial lines become horizontal lines.\n    \"\"\"\n    # xy image, vertical scaled to 360 degrees\n    xy = pyvips.Image.xyz(image.width, image.height)\n    xy *= [1, 360.0 / image.height]\n\n    index = xy.rect()\n\n    # scale to image rect\n    scale = min(image.width, image.height) / float(image.width)\n    index *= scale / 2.0\n    index += [image.width / 2.0, image.height / 2.0]\n\n    return image.mapim(index)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts to a unicode string.", "response": "def _to_string(x):\n    \"\"\"Convert to a unicode string.\n\n    If x is a byte string, assume it is utf-8 and decode to a Python unicode\n    string. You must call this on text strings you get back from libvips.\n\n    \"\"\"\n    if x == ffi.NULL:\n        x = 'NULL'\n    else:\n        x = ffi.string(x)\n        if isinstance(x, byte_type):\n            x = x.decode('utf-8')\n\n    return x"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef new(name):\n\n        # logger.debug('VipsInterpolate.new: name = %s', name)\n\n        vi = vips_lib.vips_interpolate_new(_to_bytes(name))\n        if vi == ffi.NULL:\n            raise Error('no such interpolator {0}'.format(name))\n\n        return Interpolate(vi)", "response": "Make a new interpolator by name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _run_cmplx(fn, image):\n    original_format = image.format\n\n    if image.format != 'complex' and image.format != 'dpcomplex':\n        if image.bands % 2 != 0:\n            raise Error('not an even number of bands')\n\n        if image.format != 'float' and image.format != 'double':\n            image = image.cast('float')\n\n        if image.format == 'double':\n            new_format = 'dpcomplex'\n        else:\n            new_format = 'complex'\n\n        image = image.copy(format=new_format, bands=image.bands / 2)\n\n    image = fn(image)\n\n    if original_format != 'complex' and original_format != 'dpcomplex':\n        if image.format == 'dpcomplex':\n            new_format = 'double'\n        else:\n            new_format = 'float'\n\n        image = image.copy(format=new_format, bands=image.bands * 2)\n\n    return image", "response": "Run a complex function on a non - complex image."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_suffixes():\n\n    names = []\n\n    if at_least_libvips(8, 8):\n        array = vips_lib.vips_foreign_get_suffixes()\n        i = 0\n        while array[i] != ffi.NULL:\n            name = _to_string(array[i])\n            if name not in names:\n                names.append(name)\n            glib_lib.g_free(array[i])\n            i += 1\n        glib_lib.g_free(array)\n\n    return names", "response": "Get a list of all the filename suffixes supported by libvips."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef at_least_libvips(x, y):\n\n    major = version(0)\n    minor = version(1)\n\n    return major > x or (major == x and minor >= y)", "response": "Is this at least libvips x. y?"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmapping fn over all child types of gtype.", "response": "def type_map(gtype, fn):\n    \"\"\"Map fn over all child types of gtype.\"\"\"\n\n    cb = ffi.callback('VipsTypeMap2Fn', fn)\n    return vips_lib.vips_type_map(gtype, cb, ffi.NULL, ffi.NULL)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets all values for a given enum type.", "response": "def values_for_enum(gtype):\n    \"\"\"Get all values for a enum (gtype).\"\"\"\n\n    g_type_class = gobject_lib.g_type_class_ref(gtype)\n    g_enum_class = ffi.cast('GEnumClass *', g_type_class)\n\n    values = []\n\n    # -1 since we always have a \"last\" member.\n    for i in range(0, g_enum_class.n_values - 1):\n        value = _to_string(g_enum_class.values[i].value_nick)\n        values.append(value)\n\n    return values"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating and use a logger.", "response": "def main():\n    \"\"\"Create and use a logger.\"\"\"\n    formatter = ColoredFormatter(log_colors={'TRACE': 'yellow'})\n\n    handler = logging.StreamHandler()\n    handler.setFormatter(formatter)\n\n    logger = logging.getLogger('example')\n    logger.addHandler(handler)\n    logger.setLevel('TRACE')\n\n    logger.log(5, 'a message using a custom level')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalls logging. basicConfig and override the formatter it creates.", "response": "def basicConfig(**kwargs):\n    \"\"\"Call ``logging.basicConfig`` and override the formatter it creates.\"\"\"\n    logging.basicConfig(**kwargs)\n    logging._acquireLock()\n    try:\n        stream = logging.root.handlers[0]\n        stream.setFormatter(\n            ColoredFormatter(\n                fmt=kwargs.get('format', BASIC_FORMAT),\n                datefmt=kwargs.get('datefmt', None)))\n    finally:\n        logging._releaseLock()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmodifying a function to call basicConfig first if no handlers exist.", "response": "def ensure_configured(func):\n    \"\"\"Modify a function to call ``basicConfig`` first if no handlers exist.\"\"\"\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        if len(logging.root.handlers) == 0:\n            basicConfig()\n        return func(*args, **kwargs)\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef color(self, log_colors, level_name):\n        if not self.stream.isatty():\n            log_colors = {}\n        return ColoredFormatter.color(self, log_colors, level_name)", "response": "Only returns colors if STDOUT is a TTY."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a logger with a default ColoredFormatter.", "response": "def setup_logger():\n    \"\"\"Return a logger with a default ColoredFormatter.\"\"\"\n    formatter = ColoredFormatter(\n        \"%(log_color)s%(levelname)-8s%(reset)s %(blue)s%(message)s\",\n        datefmt=None,\n        reset=True,\n        log_colors={\n            'DEBUG':    'cyan',\n            'INFO':     'green',\n            'WARNING':  'yellow',\n            'ERROR':    'red',\n            'CRITICAL': 'red',\n        }\n    )\n\n    logger = logging.getLogger('example')\n    handler = logging.StreamHandler()\n    handler.setFormatter(formatter)\n    logger.addHandler(handler)\n    logger.setLevel(logging.DEBUG)\n\n    return logger"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef main():\n    logger = setup_logger()\n\n    logger.debug('a debug message')\n    logger.info('an info message')\n    logger.warning('a warning message')\n    logger.error('an error message')\n    logger.critical('a critical message')", "response": "Create and use a logger."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving a description stub out a task dict.", "response": "def _stub_task(self, description, tags=None, **kw):\n        \"\"\" Given a description, stub out a task dict. \"\"\"\n\n        # If whitespace is not removed here, TW will do it when we pass the\n        # task to it.\n        task = {\"description\": description.strip()}\n\n        # Allow passing \"tags\" in as part of kw.\n        if 'tags' in kw and tags is None:\n            task['tags'] = tags\n            del(kw['tags'])\n\n        if tags is not None:\n            task['tags'] = tags\n\n        task.update(kw)\n\n        # Only UNIX timestamps are currently supported.\n        if 'due' in kw:\n            task['due'] = str(task['due'])\n\n        return task"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove annotations from a task and returns a list of annotations", "response": "def _extract_annotations_from_task(self, task):\n        \"\"\" Removes annotations from a task and returns a list of annotations\n        \"\"\"\n        annotations = list()\n\n        if 'annotations' in task:\n            existing_annotations = task.pop('annotations')\n            for v in existing_annotations:\n                if isinstance(v, dict):\n                    annotations.append(v['description'])\n                else:\n                    annotations.append(v)\n\n        for key in list(task.keys()):\n            if key.startswith('annotation_'):\n                annotations.append(task[key])\n                del(task[key])\n        return annotations"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef task_add(self, description, tags=None, **kw):\n\n        task = self._stub_task(description, tags, **kw)\n\n        task['status'] = Status.PENDING\n\n        # TODO -- check only valid keywords\n\n        if not 'entry' in task:\n            task['entry'] = str(int(time.time()))\n\n        if not 'uuid' in task:\n            task['uuid'] = str(uuid.uuid4())\n\n        id = self._task_add(task, Status.PENDING)\n        task['id'] = id\n        return task", "response": "Add a new task."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef task_done(self, **kw):\n        def validate(task):\n            if not Status.is_pending(task['status']):\n                raise ValueError(\"Task is not pending.\")\n\n        return self._task_change_status(Status.COMPLETED, validate, **kw)", "response": "Mark a pending task as done optionally specifying a completion\n        date with the end argument."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef task_delete(self, **kw):\n        def validate(task):\n            if task['status'] == Status.DELETED:\n                raise ValueError(\"Task is already deleted.\")\n\n        return self._task_change_status(Status.DELETED, validate, **kw)", "response": "Mark a task as deleted optionally specifying a completion\n        date with the end argument."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexecute a given taskwarrior command with arguments.", "response": "def _execute(self, *args):\n        \"\"\" Execute a given taskwarrior command with arguments\n\n        Returns a 2-tuple of stdout and stderr (respectively).\n\n        \"\"\"\n        command = (\n            [\n                'task',\n                'rc:%s' % self.config_filename,\n            ]\n            + self.get_configuration_override_args()\n            + [six.text_type(arg) for arg in args]\n        )\n\n        # subprocess is expecting bytestrings only, so nuke unicode if present\n        # and remove control characters\n        for i in range(len(command)):\n            if isinstance(command[i], six.text_type):\n                command[i] = (\n                    taskw.utils.clean_ctrl_chars(command[i].encode('utf-8')))\n\n        try:\n            proc = subprocess.Popen(\n                command,\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n            )\n            stdout, stderr = proc.communicate()\n        except OSError as e:\n            if e.errno == errno.ENOENT:\n                raise OSError(\"Unable to find the 'task' command-line tool.\")\n            raise\n\n        if proc.returncode != 0:\n            raise TaskwarriorError(command, stderr, stdout, proc.returncode)\n\n        # We should get bytes from the outside world.  Turn those into unicode\n        # as soon as we can.\n        # Everything going into and coming out of taskwarrior *should* be\n        # utf-8, but there are weird edge cases where something totally unusual\n        # made it in.. so we need to be able to handle (or at least try to\n        # handle) whatever.  Kitchen tries its best.\n        try:\n            stdout = stdout.decode(self.config.get('encoding', 'utf-8'))\n        except UnicodeDecodeError as e:\n            stdout = kitchen.text.converters.to_unicode(stdout)\n        try:\n            stderr = stderr.decode(self.config.get('encoding', 'utf-8'))\n        except UnicodeDecodeError as e:\n            stderr = kitchen.text.converters.to_unicode(stderr)\n\n        # strip any crazy terminal escape characters like bells, backspaces,\n        # and form feeds\n        for c in ('\\a', '\\b', '\\f', '\u001b'):\n            stdout = stdout.replace(c, '?')\n            stderr = stderr.replace(c, '?')\n\n        return stdout, stderr"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngiving a description stub out a task dict.", "response": "def _stub_task(self, description, tags=None, **kw):\n        \"\"\" Given a description, stub out a task dict. \"\"\"\n\n        # If whitespace is not removed here, TW will do it when we pass the\n        # task to it.\n        task = {\"description\": description.strip()}\n\n        # Allow passing \"tags\" in as part of kw.\n        if 'tags' in kw and tags is None:\n            task['tags'] = tags\n            del(kw['tags'])\n\n        if tags is not None:\n            task['tags'] = tags\n\n        task.update(kw)\n\n        if self._marshal:\n            return Task.from_stub(task, udas=self.config.get_udas())\n\n        return task"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_tasks(self, command='all'):\n\n        results = dict(\n            (db, self._get_task_objects('status:%s' % db, 'export'))\n            for db in Command.files(command)\n        )\n\n        # 'waiting' tasks are returned separately from 'pending' tasks\n        # Here we merge the waiting list back into the pending list.\n        if 'pending' in results:\n            results['pending'].extend(\n                self._get_task_objects('status:waiting', 'export'))\n\n        return results", "response": "Returns a dictionary of tasks for a list of command."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef filter_tasks(self, filter_dict):\n        query_args = taskw.utils.encode_query(filter_dict, self.get_version())\n        return self._get_task_objects(\n            'export',\n            *query_args\n        )", "response": "Return a list of tasks that match the given filter dict."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a new task.", "response": "def task_add(self, description, tags=None, **kw):\n        \"\"\" Add a new task.\n\n        Takes any of the keywords allowed by taskwarrior like proj or prior.\n        \"\"\"\n        task = self._stub_task(description, tags, **kw)\n\n        # Check if there are annotations, if so remove them from the\n        # task and add them after we've added the task.\n        annotations = self._extract_annotations_from_task(task)\n\n        # With older versions of taskwarrior, you can specify whatever uuid you\n        # want when adding a task.\n        if self.get_version() < LooseVersion('2.4'):\n            task['uuid'] = str(uuid.uuid4())\n        elif 'uuid' in task:\n            del task['uuid']\n\n        if self._marshal:\n            args = taskw.utils.encode_task_experimental(task.serialized())\n        else:\n            args = taskw.utils.encode_task_experimental(task)\n\n        stdout, stderr = self._execute('add', *args)\n\n        # However, in 2.4 and later, you cannot specify whatever uuid you want\n        # when adding a task.  Instead, you have to specify rc.verbose=new-uuid\n        # and then parse the assigned uuid out from stdout.\n        if self.get_version() >= LooseVersion('2.4'):\n            task['uuid'] = stdout.strip().split()[-1].strip('.')\n\n        id, added_task = self.get_task(uuid=task['uuid'])\n\n        # Check if 'uuid' is in the task we just added.\n        if not 'uuid' in added_task:\n            raise KeyError(\n                'Error encountered while creating task;'\n                'STDOUT: %s; STDERR: %s' % (\n                    stdout,\n                    stderr,\n                )\n            )\n\n        if annotations and 'uuid' in added_task:\n            for annotation in annotations:\n                self.task_annotate(added_task, annotation)\n\n        id, added_task = self.get_task(uuid=added_task[six.u('uuid')])\n        return added_task"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove an annotation from a task.", "response": "def task_denotate(self, task, annotation):\n        \"\"\" Removes an annotation from a task. \"\"\"\n        self._execute(\n            task['uuid'],\n            'denotate',\n            '--',\n            annotation\n        )\n        id, denotated_task = self.get_task(uuid=task[six.u('uuid')])\n        return denotated_task"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmarking a task as deleted.", "response": "def task_delete(self, **kw):\n        \"\"\" Marks a task as deleted.  \"\"\"\n\n        id, task = self.get_task(**kw)\n\n        if task['status'] == Status.DELETED:\n            raise ValueError(\"Task is already deleted.\")\n\n        self._execute(id, 'delete')\n        return self.get_task(uuid=task['uuid'])[1]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmarks a task as started.", "response": "def task_start(self, **kw):\n        \"\"\" Marks a task as started.  \"\"\"\n\n        id, task = self.get_task(**kw)\n\n        self._execute(id, 'start')\n        return self.get_task(uuid=task['uuid'])[1]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef task_stop(self, **kw):\n\n        id, task = self.get_task(**kw)\n\n        self._execute(id, 'stop')\n        return self.get_task(uuid=task['uuid'])[1]", "response": "Mark a task as stopped."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the file in which this task is stored.", "response": "def to_file(cls, status):\n        \"\"\" Returns the file in which this task is stored. \"\"\"\n        return {\n            Status.PENDING: DataFile.PENDING,\n            Status.WAITING: DataFile.PENDING,\n            Status.COMPLETED: DataFile.COMPLETED,\n            Status.DELETED: DataFile.COMPLETED\n        }[status]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a Task from an already deserialized dict.", "response": "def from_stub(cls, data, udas=None):\n        \"\"\" Create a Task from an already deserialized dict. \"\"\"\n\n        udas = udas or {}\n        fields = cls.FIELDS.copy()\n        fields.update(udas)\n\n        processed = {}\n        for k, v in six.iteritems(data):\n            processed[k] = cls._serialize(k, v, fields)\n\n        return cls(processed, udas)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a Task from stdin by reading one line from sys. stdin.", "response": "def from_input(cls, input_file=sys.stdin, modify=False, udas=None):\n        \"\"\"\n        Create a Task directly from stdin by reading one line. If modify=True,\n        two lines are expected, which is consistent with the Taskwarrior hook\n        system. The first line is interpreted as the original state of the Task,\n        and the second one as the new, modified state.\n\n        :param input_file: Input file. Defaults to sys.stdin.\n        :param modify: Flag for on-modify hook event. Defaults to False.\n        :param udas: Taskrc udas. Defaults to None.\n        :return Task\n        \"\"\"\n        original_task = input_file.readline().strip()\n        if modify:\n            modified_task = input_file.readline().strip()\n            return cls(json.loads(modified_task), udas=udas)\n        return cls(json.loads(original_task), udas=udas)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmarshal incoming data into Python objects.", "response": "def _deserialize(cls, key, value, fields):\n        \"\"\" Marshal incoming data into Python objects.\"\"\"\n        converter = cls._get_converter_for_field(key, None, fields)\n        return converter.deserialize(value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _serialize(cls, key, value, fields):\n        converter = cls._get_converter_for_field(key, None, fields)\n        return converter.serialize(value)", "response": "Marshal outgoing data into Taskwarrior s JSON format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a dictionary of changes that have occurred in the TaskWarrior.", "response": "def get_changes(self, serialized=False, keep=False):\n        \"\"\" Get a journal of changes that have occurred\n\n        :param `serialized`:\n            Return changes in the serialized format used by TaskWarrior.\n        :param `keep_changes`:\n            By default, the list of changes is reset after running\n            ``.get_changes``; set this to `True` if you would like to\n            keep the changes recorded following running this command.\n\n        :returns: A dictionary of 2-tuples of changes, where the key is the\n            name of the field that has changed, and the value is a 2-tuple\n            containing the original value and the final value respectively.\n\n        \"\"\"\n        results = {}\n\n        # Check for explicitly-registered changes\n        for k, f, t in self._changes:\n            if k not in results:\n                results[k] = [f, None]\n            results[k][1] = (\n                self._serialize(k, t, self._fields)\n                if serialized else t\n            )\n\n        # Check for changes on subordinate items\n        for k, v in six.iteritems(self):\n            if isinstance(v, Dirtyable):\n                result = v.get_changes(keep=keep)\n                if result:\n                    if not k in results:\n                        results[k] = [result[0], None]\n                    results[k][1] = (\n                        self._serialize(k, result[1], self._fields)\n                        if serialized else result[1]\n                    )\n\n        # Clear out recorded changes\n        if not keep:\n            self._changes = []\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update(self, values, force=False):\n        results = {}\n        for k, v in six.iteritems(values):\n            results[k] = self.__setitem__(k, v, force=force)\n        return results", "response": "Updates the dictionary with the specified values."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set(self, key, value):\n        return self.__setitem__(key, value, force=True)", "response": "Set a key s value regardless of whether a change is seen."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef serialized(self):\n        serialized = {}\n        for k, v in six.iteritems(self):\n            serialized[k] = self._serialize(k, v, self._fields)\n        return serialized", "response": "Returns a serialized representation of this task."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a dict - like task to its string representation", "response": "def encode_task_experimental(task):\n    \"\"\" Convert a dict-like task to its string representation\n        Used for adding a task via `task add`\n    \"\"\"\n    # First, clean the task:\n    task = task.copy()\n    if 'tags' in task:\n        task['tags'] = ','.join(task['tags'])\n    for k in task:\n        task[k] = encode_task_value(k, task[k])\n\n    # Then, format it as a string\n    return [\n        \"%s:\\\"%s\\\"\" % (k, v) if v else \"%s:\" % (k, )\n        for k, v in sorted(task.items(), key=itemgetter(0))\n    ]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a dict - like task to its string representation", "response": "def encode_task(task):\n    \"\"\" Convert a dict-like task to its string representation \"\"\"\n    # First, clean the task:\n    task = task.copy()\n    if 'tags' in task:\n        task['tags'] = ','.join(task['tags'])\n    for k in task:\n        for unsafe, safe in six.iteritems(encode_replacements):\n            if isinstance(task[k], six.string_types):\n                task[k] = task[k].replace(unsafe, safe)\n\n        if isinstance(task[k], datetime.datetime):\n            task[k] = task[k].strftime(\"%Y%m%dT%M%H%SZ\")\n\n    # Then, format it as a string\n    return \"[%s]\\n\" % \" \".join([\n        \"%s:\\\"%s\\\"\" % (k, v)\n        for k, v in sorted(task.items(), key=itemgetter(0))\n    ])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse a single record from a task database file.", "response": "def decode_task(line):\n    \"\"\" Parse a single record (task) from a task database file.\n\n    I don't understand why they don't just use JSON or YAML.  But\n    that's okay.\n\n    >>> decode_task('[description:\"Make a python API for taskwarrior\"]')\n    {'description': 'Make a python API for taskwarrior'}\n\n    \"\"\"\n\n    task = {}\n    for key, value in re.findall(r'(\\w+):\"(.*?)(?<!\\\\)\"', line):\n        value = value.replace('\\\\\"', '\"')  # unescape quotes\n        task[key] = value\n        for unsafe, safe in six.iteritems(decode_replacements):\n            task[key] = task[key].replace(unsafe, safe)\n    if 'tags' in task:\n        task['tags'] = task['tags'].split(',')\n    return task"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convert_dict_to_override_args(config, prefix=''):\n    args = []\n    for k, v in six.iteritems(config):\n        if isinstance(v, dict):\n            args.extend(\n                convert_dict_to_override_args(\n                    v,\n                    prefix='.'.join([\n                        prefix,\n                        k,\n                    ]) if prefix else k\n                )\n            )\n        else:\n            v = six.text_type(v)\n            left = 'rc' + (('.' + prefix) if prefix else '') + '.' + k\n            right = v if ' ' not in v else '\"%s\"' % v\n            args.append('='.join([left, right]))\n    return args", "response": "Converts a dictionary of override arguments into CLI arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stats_per_chunk(chunk):\n\n    for block_id in chunk.iter_block():\n        try:\n            block_counts[block_id] += 1\n        except KeyError:\n            block_counts[block_id] = 1", "response": "Given a chunk increment the block types with the number of blocks found"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving a chunk return the number of blocks types within the specified selection", "response": "def bounded_stats_per_chunk(chunk, block_counts, start, stop):\n    \"\"\"Given a chunk, return the number of blocks types within the specified selection\"\"\"\n    chunk_z, chunk_x = chunk.get_coords()\n    for z in range(16):\n        world_z = z + chunk_z*16\n        if ( (start != None and world_z < int(start[2])) or (stop != None and  world_z > int(stop[2])) ):\n            # Outside the bounding box; skip to next iteration\n            #print(\"Z break: %d,%d,%d\" % (world_z,start[2],stop[2]))\n            break\n        for x in range(16):\n            world_x = x + chunk_x*16\n            if ( (start != None and world_x < int(start[0])) or (stop != None and world_x > int(stop[0])) ):\n                # Outside the bounding box; skip to next iteration\n                #print(\"X break: %d,%d,%d\" % (world_x,start[0],stop[0]))\n                break\n            for y in range(chunk.get_max_height() + 1):\n                if ( (start != None and y < int(start[1])) or (stop != None and y > int(stop[1])) ):\n                    # Outside the bounding box; skip to next iteration\n                    #print(\"Y break: %d,%d,%d\" % (y,start[1],stop[1]))\n                    break\n                \n                #print(\"Chunk: %d,%d Coord: %d,%d,%d\" % (c['x'], c['z'],x,y,z))\n                block_id = chunk.get_block(x,y,z)\n                if block_id != None:\n                    try:\n                        block_counts[block_id] += 1\n                    except KeyError:\n                        block_counts[block_id] = 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process_region_file(region, start, stop):\n    rx = region.loc.x\n    rz = region.loc.z\n\n    # Does the region overlap the bounding box at all?\n    if (start != None):\n        if ( (rx+1)*512-1 < int(start[0]) or (rz+1)*512-1 < int(start[2]) ):\n            return\n    elif (stop != None):\n        if ( rx*512-1 > int(stop[0]) or rz*512-1 > int(stop[2]) ):\n            return\n\n    # Get all chunks\n    print(\"Parsing region %s...\" % os.path.basename(region.filename))\n    for c in region.iter_chunks_class():\n        cx, cz = c.get_coords();\n        # Does the chunk overlap the bounding box at all?\n        if (start != None):\n            if ( (cx+1)*16 + rx*512 - 1 < int(start[0]) or (cz+1)*16 + rz*512 - 1 < int(start[2]) ):\n                continue\n        elif (stop != None):\n            if ( cx*16 + rx*512 - 1 > int(stop[0]) or cz*16 + rz*512 - 1 > int(stop[2]) ):\n                continue\n\n        #print(\"Parsing chunk (\" + str(cx) + \", \" + str(cz) + \")...\")\n\n        # Fast code if no start or stop coordinates are specified\n        # TODO: also use this code if start/stop is specified, but the complete chunk is included\n        if (start == None and stop == None):\n            stats_per_chunk(c)\n        else:\n            # Slow code that iterates through each coordinate\n            bounded_stats_per_chunk(c, start, stop)", "response": "Given a region return the number of blocks of each ID in that region"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind all matching file names in the world folder. This method is private and it s deprecated. Use get_regionfiles() instead.", "response": "def get_filenames(self):\n        \"\"\"Find all matching file names in the world folder.\n        \n        This method is private, and it's use it deprecated. Use get_regionfiles() instead.\"\"\"\n        # Warning: glob returns a empty list if the directory is unreadable, without raising an Exception\n        return list(glob.glob(os.path.join(self.worldfolder,'region','r.*.*.'+self.extension)))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_regionfiles(self, filenames):\n        for filename in filenames:\n            # Assume that filenames have the name r.<x-digit>.<z-digit>.<extension>\n            m = re.match(r\"r.(\\-?\\d+).(\\-?\\d+).\"+self.extension, os.path.basename(filename))\n            if m:\n                x = int(m.group(1))\n                z = int(m.group(2))\n            else:\n                # Only raised if a .mca of .mcr file exists which does not comply to the\n                #  r.<x-digit>.<z-digit>.<extension> filename format. This may raise false\n                # errors if a copy is made, e.g. \"r.0.-1 copy.mca\". If this is an issue, override\n                # get_filenames(). In most cases, it is an error, and we like to raise that.\n                # Changed, no longer raise error, because we want to continue the loop.\n                # raise UnknownWorldFormat(\"Unrecognized filename format %s\" % os.path.basename(filename))\n                # TODO: log to stderr using logging facility.\n                pass\n            self.regionfiles[(x,z)] = filename", "response": "This method sets the region files for this instance to use."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a region using x z coordinates of a region. Cache results.", "response": "def get_region(self, x,z):\n        \"\"\"Get a region using x,z coordinates of a region. Cache results.\"\"\"\n        if (x,z) not in self.regions:\n            if (x,z) in self.regionfiles:\n                self.regions[(x,z)] = region.RegionFile(self.regionfiles[(x,z)])\n            else:\n                # Return an empty RegionFile object\n                # TODO: this does not yet allow for saving of the region file\n                # TODO: this currently fails with a ValueError!\n                # TODO: generate the correct name, and create the file\n                # and add the fie to self.regionfiles\n                self.regions[(x,z)] = region.RegionFile()\n            self.regions[(x,z)].loc = Location(x=x,z=z)\n        return self.regions[(x,z)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\niterates over all region files in the chunk.", "response": "def iter_regions(self):\n        \"\"\"\n        Return an iterable list of all region files. Use this function if you only\n        want to loop through each region files once, and do not want to cache the results.\n        \"\"\"\n        # TODO: Implement BoundingBox\n        # TODO: Implement sort order\n        for x,z in self.regionfiles.keys():\n            close_after_use = False\n            if (x,z) in self.regions:\n                regionfile = self.regions[(x,z)]\n            else:\n                # It is not yet cached.\n                # Get file, but do not cache later.\n                regionfile = region.RegionFile(self.regionfiles[(x,z)], chunkclass = self.chunkclass)\n                regionfile.loc = Location(x=x,z=z)\n                close_after_use = True\n            try:\n                yield regionfile\n            finally:\n                if close_after_use:\n                    regionfile.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a NBT object specified by the chunk coordinates x z. Raise InconceivedChunk if the NBT file is not yet generated.", "response": "def get_nbt(self,x,z):\n        \"\"\"\n        Return a NBT specified by the chunk coordinates x,z. Raise InconceivedChunk\n        if the NBT file is not yet generated. To get a Chunk object, use get_chunk.\n        \"\"\"\n        rx,cx = divmod(x,32)\n        rz,cz = divmod(z,32)\n        if (rx,rz) not in self.regions and (rx,rz) not in self.regionfiles:\n            raise InconceivedChunk(\"Chunk %s,%s is not present in world\" % (x,z))\n        nbt = self.get_region(rx,rz).get_nbt(cx,cz)\n        assert nbt != None\n        return nbt"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a chunk specified by the chunk coordinates x z. Raise InconceivedChunk if the chunk is not yet generated.", "response": "def get_chunk(self,x,z):\n        \"\"\"\n        Return a chunk specified by the chunk coordinates x,z. Raise InconceivedChunk\n        if the chunk is not yet generated. To get the raw NBT data, use get_nbt.\n        \"\"\"\n        return self.chunkclass(self.get_nbt(x, z))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of all chunks.", "response": "def get_chunks(self, boundingbox=None):\n        \"\"\"\n        Return a list of all chunks. Use this function if you access the chunk\n        list frequently and want to cache the result.\n        Use iter_chunks() if you only want to loop through the chunks once or have a\n        very large world.\n        \"\"\"\n        if self.chunks == None:\n            self.chunks = list(self.iter_chunks())\n        return self.chunks"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef chunk_count(self):\n        c = 0\n        for r in self.iter_regions():\n            c += r.chunk_count()\n        return c", "response": "Return a count of the chunks in this world folder."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the minimum and maximum x and z coordinates of the chunks that have this world save", "response": "def get_boundingbox(self):\n        \"\"\"\n        Return minimum and maximum x and z coordinates of the chunks that\n        make up this world save\n        \"\"\"\n        b = BoundingBox()\n        for rx,rz in self.regionfiles.keys():\n            region = self.get_region(rx,rz)\n            rx,rz = 32*rx,32*rz\n            for cc in region.get_chunk_coords():\n                x,z = (rx+cc['x'],rz+cc['z'])\n                b.expand(x,None,z)\n        return b"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unpack_nbt(tag):\n\n    if isinstance(tag, TAG_List):\n        return [unpack_nbt(i) for i in tag.tags]\n    elif isinstance(tag, TAG_Compound):\n        return dict((i.name, unpack_nbt(i)) for i in tag.tags)\n    else:\n        return tag.value", "response": "Unpack an NBT tag into a native Python data structure."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pack_nbt(s):\n\n    if isinstance(s, int):\n        return TAG_Long(s)\n    elif isinstance(s, float):\n        return TAG_Double(s)\n    elif isinstance(s, (str, unicode)):\n        return TAG_String(s)\n    elif isinstance(s, dict):\n        tag = TAG_Compound()\n        for k, v in s:\n            v = pack_nbt(v)\n            v.name = str(k)\n            tag.tags.append(v)\n        return tag\n    elif hasattr(s, \"__iter__\"):\n        # We arrive at a slight quandry. NBT lists must be homogenous, unlike\n        # Python lists. NBT compounds work, but require unique names for every\n        # entry. On the plus side, this technique should work for arbitrary\n        # iterables as well.\n        tags = [pack_nbt(i) for i in s]\n        t = type(tags[0])\n        # If we're homogenous...\n        if all(t == type(i) for i in tags):\n            tag = TAG_List(type=t)\n            tag.tags = tags\n        else:\n            tag = TAG_Compound()\n            for i, item in enumerate(tags):\n                item.name = str(i)\n            tag.tags = tags\n        return tag\n    else:\n        raise ValueError(\"Couldn't serialise type %s!\" % type(s))", "response": "Pack a native Python data structure into an NBT tag."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngives a size in bytes return how many sectors required to contain it.", "response": "def _bytes_to_sector(bsize, sectorlength=SECTOR_LENGTH):\n        \"\"\"Given a size in bytes, return how many sections of length sectorlen are required to contain it.\n        This is equivalent to ceil(bsize/sectorlen), if Python would use floating\n        points for division, and integers for ceil(), rather than the other way around.\"\"\"\n        sectors, remainder = divmod(bsize, sectorlength)\n        return sectors if remainder == 0 else sectors + 1"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninitialising the file header. This will erase any previously written data.", "response": "def _init_file(self):\n        \"\"\"Initialise the file header. This will erase any data previously in the file.\"\"\"\n        header_length = 2*SECTOR_LENGTH\n        if self.size > header_length:\n            self.file.truncate(header_length)\n        self.file.seek(0)\n        self.file.write(header_length*b'\\x00')\n        self.size = header_length"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _parse_header(self):\n        # update the file size, needed when parse_header is called after\n        # we have unlinked a chunk or writed a new one\n        self.size = self.get_size()\n\n        if self.size == 0:\n            # Some region files seems to have 0 bytes of size, and\n            # Minecraft handle them without problems. Take them\n            # as empty region files.\n            return\n        elif self.size < 2*SECTOR_LENGTH:\n            raise NoRegionHeader('The region file is %d bytes, too small in size to have a header.' % self.size)\n        \n        for index in range(0, SECTOR_LENGTH, 4):\n            x = int(index//4) % 32\n            z = int(index//4)//32\n            m = self.metadata[x, z]\n            \n            self.file.seek(index)\n            offset, length = unpack(\">IB\", b\"\\0\" + self.file.read(4))\n            m.blockstart, m.blocklength = offset, length\n            self.file.seek(index + SECTOR_LENGTH)\n            m.timestamp = unpack(\">I\", self.file.read(4))[0]\n            \n            if offset == 0 and length == 0:\n                m.status = STATUS_CHUNK_NOT_CREATED\n            elif length == 0:\n                m.status = STATUS_CHUNK_ZERO_LENGTH\n            elif offset < 2 and offset != 0:\n                m.status = STATUS_CHUNK_IN_HEADER\n            elif SECTOR_LENGTH * offset + 5 > self.size:\n                # Chunk header can't be read.\n                m.status = STATUS_CHUNK_OUT_OF_FILE\n            else:\n                m.status = STATUS_CHUNK_OK\n        \n        # Check for chunks overlapping in the file\n        for chunks in self._sectors()[2:]:\n            if len(chunks) > 1:\n                # overlapping chunks\n                for m in chunks:\n                    # Update status, unless these more severe errors take precedence\n                    if m.status not in (STATUS_CHUNK_ZERO_LENGTH, STATUS_CHUNK_IN_HEADER, \n                                        STATUS_CHUNK_OUT_OF_FILE):\n                        m.status = STATUS_CHUNK_OVERLAPPING", "response": "Read the region header and stores the header and status."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _sectors(self, ignore_chunk=None):\n        sectorsize = self._bytes_to_sector(self.size)\n        sectors = [[] for s in range(sectorsize)]\n        sectors[0] = True # locations\n        sectors[1] = True # timestamps\n        for m in self.metadata.values():\n            if not m.is_created():\n                continue\n            if ignore_chunk == m:\n                continue\n            if m.blocklength and m.blockstart:\n                blockend = m.blockstart + max(m.blocklength, m.requiredblocks())\n                # Ensure 2 <= b < sectorsize, as well as m.blockstart <= b < blockend\n                for b in range(max(m.blockstart, 2), min(blockend, sectorsize)):\n                    sectors[b].append(m)\n        return sectors", "response": "Return a list of all sectors each sector is a list of chunks occupying the block."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of booleans indicating the free sectors.", "response": "def _locate_free_sectors(self, ignore_chunk=None):\n        \"\"\"Return a list of booleans, indicating the free sectors.\"\"\"\n        sectors = self._sectors(ignore_chunk=ignore_chunk)\n        # Sectors are considered free, if the value is an empty list.\n        return [not i for i in sectors]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngives a list of booleans find a list of consecutive True values.", "response": "def _find_free_location(self, free_locations, required_sectors=1, preferred=None):\n        \"\"\"\n        Given a list of booleans, find a list of <required_sectors> consecutive True values.\n        If no such list is found, return length(free_locations).\n        Assumes first two values are always False.\n        \"\"\"\n        # check preferred (current) location\n        if preferred and all(free_locations[preferred:preferred+required_sectors]):\n            return preferred\n        \n        # check other locations\n        # Note: the slicing may exceed the free_location boundary.\n        # This implementation relies on the fact that slicing will work anyway,\n        # and the any() function returns True for an empty list. This ensures\n        # that blocks outside the file are considered Free as well.\n        \n        i = 2 # First two sectors are in use by the header\n        while i < len(free_locations):\n            if all(free_locations[i:i+required_sectors]):\n                break\n            i += 1\n        return i"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the x z coordinates and length of the chunks that are defined in the regionfile.", "response": "def get_chunk_coords(self):\n        \"\"\"\n        Return the x,z coordinates and length of the chunks that are defined in te regionfile.\n        This includes chunks which may not be readable for whatever reason.\n        \n        This method is deprecated. Use :meth:`get_metadata` instead.\n        \"\"\"\n        chunks = []\n        for x in range(32):\n            for z in range(32):\n                m = self.metadata[x,z]\n                if m.is_created():\n                    chunks.append({'x': x, 'z': z, 'length': m.blocklength})\n        return chunks"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nyield each chunk present in the region.", "response": "def iter_chunks(self):\n        \"\"\"\n        Yield each readable chunk present in the region.\n        Chunks that can not be read for whatever reason are silently skipped.\n        Warning: this function returns a :class:`nbt.nbt.NBTFile` object, use ``Chunk(nbtfile)`` to get a\n        :class:`nbt.chunk.Chunk` instance.\n        \"\"\"\n        for m in self.get_metadata():\n            try:\n                yield self.get_chunk(m.x, m.z)\n            except RegionFileFormatError:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\niterates over the chunks present in the region.", "response": "def iter_chunks_class(self):\n        \"\"\"\n        Yield each readable chunk present in the region.\n        Chunks that can not be read for whatever reason are silently skipped.\n        This function returns a :class:`nbt.chunk.Chunk` instance.\n        \"\"\"\n        for m in self.get_metadata():\n            try:\n                yield self.chunkclass(self.get_chunk(m.x, m.z))\n            except RegionFileFormatError:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_blockdata(self, x, z):\n        # read metadata block\n        m = self.metadata[x, z]\n        if m.status == STATUS_CHUNK_NOT_CREATED:\n            raise InconceivedChunk(\"Chunk %d,%d is not present in region\" % (x,z))\n        elif m.status == STATUS_CHUNK_IN_HEADER:\n            raise RegionHeaderError('Chunk %d,%d is in the region header' % (x,z))\n        elif m.status == STATUS_CHUNK_OUT_OF_FILE and (m.length <= 1 or m.compression == None):\n            # Chunk header is outside of the file.\n            raise RegionHeaderError('Chunk %d,%d is partially/completely outside the file' % (x,z))\n        elif m.status == STATUS_CHUNK_ZERO_LENGTH:\n            if m.blocklength == 0:\n                raise RegionHeaderError('Chunk %d,%d has zero length' % (x,z))\n            else:\n                raise ChunkHeaderError('Chunk %d,%d has zero length' % (x,z))\n        elif m.blockstart * SECTOR_LENGTH + 5 >= self.size:\n            raise RegionHeaderError('Chunk %d,%d is partially/completely outside the file' % (x,z))\n\n        # status is STATUS_CHUNK_OK, STATUS_CHUNK_MISMATCHED_LENGTHS, STATUS_CHUNK_OVERLAPPING\n        # or STATUS_CHUNK_OUT_OF_FILE.\n        # The chunk is always read, but in case of an error, the exception may be different \n        # based on the status.\n\n        err = None\n        try:\n            # offset comes in sectors of 4096 bytes + length bytes + compression byte\n            self.file.seek(m.blockstart * SECTOR_LENGTH + 5)\n            # Do not read past the length of the file.\n            # The length in the file includes the compression byte, hence the -1.\n            length = min(m.length - 1, self.size - (m.blockstart * SECTOR_LENGTH + 5))\n            chunk = self.file.read(length)\n            \n            if (m.compression == COMPRESSION_GZIP):\n                # Python 3.1 and earlier do not yet support gzip.decompress(chunk)\n                f = gzip.GzipFile(fileobj=BytesIO(chunk))\n                chunk = bytes(f.read())\n                f.close()\n            elif (m.compression == COMPRESSION_ZLIB):\n                chunk = zlib.decompress(chunk)\n            elif m.compression != COMPRESSION_NONE:\n                raise ChunkDataError('Unknown chunk compression/format (%s)' % m.compression)\n            \n            return chunk\n        except RegionFileFormatError:\n            raise\n        except Exception as e:\n            # Deliberately catch the Exception and re-raise.\n            # The details in gzip/zlib/nbt are irrelevant, just that the data is garbled.\n            err = '%s' % e # avoid str(e) due to Unicode issues in Python 2.\n        if err:\n            # don't raise during exception handling to avoid the warning \n            # \"During handling of the above exception, another exception occurred\".\n            # Python 3.3 solution (see PEP 409 & 415): \"raise ChunkDataError(str(e)) from None\"\n            if m.status == STATUS_CHUNK_MISMATCHED_LENGTHS:\n                raise ChunkHeaderError('The length in region header and the length in the header of chunk %d,%d are incompatible' % (x,z))\n            elif m.status == STATUS_CHUNK_OVERLAPPING:\n                raise ChunkHeaderError('Chunk %d,%d is overlapping with another chunk' % (x,z))\n            else:\n                raise ChunkDataError(err)", "response": "Return the decompressed binary data for a chunk."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_nbt(self, x, z):\n        # TODO: cache results?\n        data = self.get_blockdata(x, z) # This may raise a RegionFileFormatError.\n        data = BytesIO(data)\n        err = None\n        try:\n            nbt = NBTFile(buffer=data)\n            if self.loc.x != None:\n                x += self.loc.x*32\n            if self.loc.z != None:\n                z += self.loc.z*32\n            nbt.loc = Location(x=x, z=z)\n            return nbt\n            # this may raise a MalformedFileError. Convert to ChunkDataError.\n        except MalformedFileError as e:\n            err = '%s' % e # avoid str(e) due to Unicode issues in Python 2.\n        if err:\n            raise ChunkDataError(err)", "response": "Get a NBTFile of the specified chunk."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting the data to the file.", "response": "def write_blockdata(self, x, z, data, compression=COMPRESSION_ZLIB):\n        \"\"\"\n        Compress the data, write it to file, and add pointers in the header so it \n        can be found as chunk(x,z).\n        \"\"\"\n        if compression == COMPRESSION_GZIP:\n            # Python 3.1 and earlier do not yet support `data = gzip.compress(data)`.\n            compressed_file = BytesIO()\n            f = gzip.GzipFile(fileobj=compressed_file)\n            f.write(data)\n            f.close()\n            compressed_file.seek(0)\n            data = compressed_file.read()\n            del compressed_file\n        elif compression == COMPRESSION_ZLIB:\n            data = zlib.compress(data) # use zlib compression, rather than Gzip\n        elif compression != COMPRESSION_NONE:\n            raise ValueError(\"Unknown compression type %d\" % compression)\n        length = len(data)\n\n        # 5 extra bytes are required for the chunk block header\n        nsectors = self._bytes_to_sector(length + 5)\n\n        if nsectors >= 256:\n            raise ChunkDataError(\"Chunk is too large (%d sectors exceeds 255 maximum)\" % (nsectors))\n\n        # Ensure file has a header\n        if self.size < 2*SECTOR_LENGTH:\n            self._init_file()\n\n        # search for a place where to write the chunk:\n        current = self.metadata[x, z]\n        free_sectors = self._locate_free_sectors(ignore_chunk=current)\n        sector = self._find_free_location(free_sectors, nsectors, preferred=current.blockstart)\n\n        # If file is smaller than sector*SECTOR_LENGTH (it was truncated), pad it with zeroes.\n        if self.size < sector*SECTOR_LENGTH:\n            # jump to end of file\n            self.file.seek(0, SEEK_END)\n            self.file.write((sector*SECTOR_LENGTH - self.size) * b\"\\x00\")\n            assert self.file.tell() == sector*SECTOR_LENGTH\n\n        # write out chunk to region\n        self.file.seek(sector*SECTOR_LENGTH)\n        self.file.write(pack(\">I\", length + 1)) #length field\n        self.file.write(pack(\">B\", compression)) #compression field\n        self.file.write(data) #compressed data\n\n        # Write zeros up to the end of the chunk\n        remaining_length = SECTOR_LENGTH * nsectors - length - 5\n        self.file.write(remaining_length * b\"\\x00\")\n\n        #seek to header record and write offset and length records\n        self.file.seek(4 * (x + 32*z))\n        self.file.write(pack(\">IB\", sector, nsectors)[1:])\n\n        #write timestamp\n        self.file.seek(SECTOR_LENGTH + 4 * (x + 32*z))\n        timestamp = int(time.time())\n        self.file.write(pack(\">I\", timestamp))\n\n        # Update free_sectors with newly written block\n        # This is required for calculating file truncation and zeroing freed blocks.\n        free_sectors.extend((sector + nsectors - len(free_sectors)) * [True])\n        for s in range(sector, sector + nsectors):\n            free_sectors[s] = False\n        \n        # Check if file should be truncated:\n        truncate_count = list(reversed(free_sectors)).index(False)\n        if truncate_count > 0:\n            self.size = SECTOR_LENGTH * (len(free_sectors) - truncate_count)\n            self.file.truncate(self.size)\n            free_sectors = free_sectors[:-truncate_count]\n        \n        # Calculate freed sectors\n        for s in range(current.blockstart, min(current.blockstart + current.blocklength, len(free_sectors))):\n            if free_sectors[s]:\n                # zero sector s\n                self.file.seek(SECTOR_LENGTH*s)\n                self.file.write(SECTOR_LENGTH*b'\\x00')\n        \n        # update file size and header information\n        self.size = max((sector + nsectors)*SECTOR_LENGTH, self.size)\n        assert self.get_size() == self.size\n        current.blockstart = sector\n        current.blocklength = nsectors\n        current.status = STATUS_CHUNK_OK\n        current.timestamp = timestamp\n        current.length = length + 1\n        current.compression = COMPRESSION_ZLIB"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write_chunk(self, x, z, nbt_file):\n        data = BytesIO()\n        nbt_file.write_file(buffer=data) # render to buffer; uncompressed\n        self.write_blockdata(x, z, data.getvalue())", "response": "Write a chunk of NBT file to the file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unlink_chunk(self, x, z):\n        # This function fails for an empty file. If that is the case, just return.\n        if self.size < 2*SECTOR_LENGTH:\n            return\n\n        # zero the region header for the chunk (offset length and time)\n        self.file.seek(4 * (x + 32*z))\n        self.file.write(pack(\">IB\", 0, 0)[1:])\n        self.file.seek(SECTOR_LENGTH + 4 * (x + 32*z))\n        self.file.write(pack(\">I\", 0))\n\n        # Check if file should be truncated:\n        current = self.metadata[x, z]\n        free_sectors = self._locate_free_sectors(ignore_chunk=current)\n        truncate_count = list(reversed(free_sectors)).index(False)\n        if truncate_count > 0:\n            self.size = SECTOR_LENGTH * (len(free_sectors) - truncate_count)\n            self.file.truncate(self.size)\n            free_sectors = free_sectors[:-truncate_count]\n        \n        # Calculate freed sectors\n        for s in range(current.blockstart, min(current.blockstart + current.blocklength, len(free_sectors))):\n            if free_sectors[s]:\n                # zero sector s\n                self.file.seek(SECTOR_LENGTH*s)\n                self.file.write(SECTOR_LENGTH*b'\\x00')\n\n        # update the header\n        self.metadata[x, z] = ChunkMetadata(x, z)", "response": "Remove a chunk from the file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _classname(self):\n        if self.__class__.__module__ in (None,):\n            return self.__class__.__name__\n        else:\n            return \"%s.%s\" % (self.__class__.__module__, self.__class__.__name__)", "response": "Return the fully qualified class name."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef entities_per_chunk(chunk):\n    entities = []\n    for entity in chunk['Entities']:\n        x,y,z = entity[\"Pos\"]\n        entities.append(Entity(entity[\"id\"].value, (x.value,y.value,z.value)))\n    return entities", "response": "Given a chunk find all entities in that chunk"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind chests and get contents in a given chunk.", "response": "def chests_per_chunk(chunk):\n    \"\"\"Find chests and get contents in a given chunk.\"\"\"\n\n    chests = []\n\n    for entity in chunk['Entities']:\n        eid = entity[\"id\"].value\n        if eid == \"Minecart\" and entity[\"type\"].value == 1 or eid == \"minecraft:chest_minecart\":\n            x,y,z = entity[\"Pos\"]\n            x,y,z = x.value,y.value,z.value\n\n            # Treasures are empty upon first opening\n\n            try:\n                items = items_from_nbt(entity[\"Items\"])\n            except KeyError:\n                items = {}\n            chests.append(Chest(\"Minecart with chest\",(x,y,z),items))\n\n    for entity in chunk['TileEntities']:\n        eid = entity[\"id\"].value\n        if eid == \"Chest\" or eid == \"minecraft:chest\":\n            x,y,z = entity[\"x\"].value,entity[\"y\"].value,entity[\"z\"].value\n\n            # Treasures are empty upon first opening\n\n            try:\n                items = items_from_nbt(entity[\"Items\"])\n            except KeyError:\n                items = {}\n            chests.append(Chest(\"Chest\",(x,y,z),items))\n\n    return chests"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_block(self, x, y, z):\n        sy,by = divmod(y, 16)\n        section = self.get_section(sy)\n        if section == None:\n            return None\n\n        return section.get_block(x, by, z)", "response": "Get a block from relative x y z."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a dictionary with block ids keyed to ( x y z ).", "response": "def get_blocks_struct(self):\n        \"\"\"Return a dictionary with block ids keyed to (x, y, z).\"\"\"\n        cur_x = 0\n        cur_y = 0\n        cur_z = 0\n        blocks = {}\n        for block_id in self.blocksList:\n            blocks[(cur_x,cur_y,cur_z)] = block_id\n            cur_y += 1\n            if (cur_y > 127):\n                cur_y = 0\n                cur_z += 1\n                if (cur_z > 15):\n                    cur_z = 0\n                    cur_x += 1\n        return blocks"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_blocks_byte_array(self, buffer=False):\n        if buffer:\n            length = len(self.blocksList)\n            return BytesIO(pack(\">i\", length)+self.get_blocks_byte_array())\n        else:\n            return array.array('B', self.blocksList).tostring()", "response": "Return a list of all blocks in this chunk."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of data for all blocks in this chunk.", "response": "def get_data_byte_array(self, buffer=False):\n        \"\"\"Return a list of data for all blocks in this chunk.\"\"\"\n        if buffer:\n            length = len(self.dataList)\n            return BytesIO(pack(\">i\", length)+self.get_data_byte_array())\n        else:\n            return array.array('B', self.dataList).tostring()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a heightmap representing the highest solid blocks in this chunk.", "response": "def generate_heightmap(self, buffer=False, as_array=False):\n        \"\"\"Return a heightmap, representing the highest solid blocks in this chunk.\"\"\"\n        non_solids = [0, 8, 9, 10, 11, 38, 37, 32, 31]\n        if buffer:\n            return BytesIO(pack(\">i\", 256)+self.generate_heightmap()) # Length + Heightmap, ready for insertion into Chunk NBT\n        else:\n            bytes = []\n            for z in range(16):\n                for x in range(16):\n                    for y in range(127, -1, -1):\n                        offset = y + z*128 + x*128*16\n                        if (self.blocksList[offset] not in non_solids or y == 0):\n                            bytes.append(y+1)\n                            break\n            if (as_array):\n                return bytes\n            else:\n                return array.array('B', bytes).tostring()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting all blocks in this chunk using either a list or a dictionary. Air blocks are not filled if fill_air is True.", "response": "def set_blocks(self, list=None, dict=None, fill_air=False):\n        \"\"\"\n        Sets all blocks in this chunk, using either a list or dictionary.  \n        Blocks not explicitly set can be filled to air by setting fill_air to True.\n        \"\"\"\n        if list:\n            # Inputting a list like self.blocksList\n            self.blocksList = list\n        elif dict:\n            # Inputting a dictionary like result of self.get_blocks_struct()\n            list = []\n            for x in range(16):\n                for z in range(16):\n                    for y in range(128):\n                        coord = x,y,z\n                        offset = y + z*128 + x*128*16\n                        if (coord in dict):\n                            list.append(dict[coord])\n                        else:\n                            if (self.blocksList[offset] and not fill_air):\n                                list.append(self.blocksList[offset])\n                            else:\n                                list.append(0) # Air\n            self.blocksList = list\n        else:\n            # None of the above...\n            return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the block a x y z to the specified id and optionally data.", "response": "def set_block(self, x,y,z, id, data=0):\n        \"\"\"Sets the block a x, y, z to the specified id, and optionally data.\"\"\"\n        offset = y + z*128 + x*128*16\n        self.blocksList[offset] = id\n        if (offset % 2 == 1):\n            # offset is odd\n            index = (offset-1)//2\n            b = self.dataList[index]\n            self.dataList[index] = (b & 240) + (data & 15) # modify lower bits, leaving higher bits in place\n        else:\n            # offset is even\n            index = offset//2\n            b = self.dataList[index]\n            self.dataList[index] = (b & 15) + (data << 4 & 240)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the id of the block at x y z.", "response": "def get_block(self, x,y,z, coord=False):\n        \"\"\"Return the id of the block at x, y, z.\"\"\"\n        \"\"\"\n        Laid out like:\n        (0,0,0), (0,1,0), (0,2,0) ... (0,127,0), (0,0,1), (0,1,1), (0,2,1) ... (0,127,1), (0,0,2) ... (0,127,15), (1,0,0), (1,1,0) ... (15,127,15)\n        \n        ::\n        \n          blocks = []\n          for x in range(15):\n            for z in range(15):\n              for y in range(127):\n                blocks.append(Block(x,y,z))\n        \"\"\"\n\n        offset = y + z*128 + x*128*16 if (coord == False) else coord[1] + coord[2]*128 + coord[0]*128*16\n        return self.blocksList[offset]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tag_info(self):\n        return self.__class__.__name__ + (\n            '(%r)' % self.name if self.name\n            else \"\") + \": \" + self.valuestr()", "response": "Return Unicode string with class name and unnested value."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_file(self, filename=None, buffer=None, fileobj=None):\n        closefile = True\n        if buffer:\n            self.filename = None\n            self.file = buffer\n            closefile = False\n        elif filename:\n            self.filename = filename\n            self.file = GzipFile(filename, \"wb\")\n        elif fileobj:\n            self.filename = None\n            self.file = GzipFile(fileobj=fileobj, mode=\"wb\")\n        elif self.filename:\n            self.file = GzipFile(self.filename, \"wb\")\n        elif not self.file:\n            raise ValueError(\n                \"NBTFile.write_file(): Need to specify either a \"\n                \"filename or a file object\"\n            )\n        # Render tree to file\n        TAG_Byte(self.id)._render_buffer(self.file)\n        TAG_String(self.name)._render_buffer(self.file)\n        self._render_buffer(self.file)\n        # make sure the file is complete\n        try:\n            self.file.flush()\n        except (AttributeError, IOError):\n            pass\n        if closefile:\n            try:\n                self.file.close()\n            except (AttributeError, IOError):\n                pass", "response": "Write this NBT file to a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read(*parts):\n    try:\n        return io.open(os.path.join(*parts), 'r', encoding='utf-8').read()\n    except IOError:\n        return ''", "response": "Reads the content of the file located at path created from parts *."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef loads(self, value):\n        raw = False if self.encoding == \"utf-8\" else True\n        if value is None:\n            return None\n        return msgpack.loads(value, raw=raw, use_list=self.use_list)", "response": "Deserialize a bytes object into a obj\n        object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_uri_path(self, path):\n        options = {}\n        db, *_ = path[1:].split(\"/\")\n        if db:\n            options[\"db\"] = db\n        return options", "response": "Given a uri path return the Redis specific configuration\n        options in that path string according to iana definition\n        http://www. iana. org / assignments / uri - schemes / prov / redis\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef timeout(cls, func):\n        NOT_SET = \"NOT_SET\"\n\n        @functools.wraps(func)\n        async def _timeout(self, *args, timeout=NOT_SET, **kwargs):\n            timeout = self.timeout if timeout == NOT_SET else timeout\n            if timeout == 0 or timeout is None:\n                return await func(self, *args, **kwargs)\n            return await asyncio.wait_for(func(self, *args, **kwargs), timeout)\n\n        return _timeout", "response": "Decorator to set the maximum timeout for a coroutine to execute."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef aiocache_enabled(cls, fake_return=None):\n\n        def enabled(func):\n            @functools.wraps(func)\n            async def _enabled(*args, **kwargs):\n                if os.getenv(\"AIOCACHE_DISABLE\") == \"1\":\n                    return fake_return\n                return await func(*args, **kwargs)\n\n            return _enabled\n\n        return enabled", "response": "A decorator to mark a function as enabled."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def add(self, key, value, ttl=SENTINEL, dumps_fn=None, namespace=None, _conn=None):\n        start = time.monotonic()\n        dumps = dumps_fn or self._serializer.dumps\n        ns_key = self.build_key(key, namespace=namespace)\n\n        await self._add(ns_key, dumps(value), ttl=self._get_ttl(ttl), _conn=_conn)\n\n        logger.debug(\"ADD %s %s (%.4f)s\", ns_key, True, time.monotonic() - start)\n        return True", "response": "Adds the value to the given key with ttl if specified."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def get(self, key, default=None, loads_fn=None, namespace=None, _conn=None):\n        start = time.monotonic()\n        loads = loads_fn or self._serializer.loads\n        ns_key = self.build_key(key, namespace=namespace)\n\n        value = loads(await self._get(ns_key, encoding=self.serializer.encoding, _conn=_conn))\n\n        logger.debug(\"GET %s %s (%.4f)s\", ns_key, value is not None, time.monotonic() - start)\n        return value if value is not None else default", "response": "Get a value from the cache. Returns default if not found."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def multi_get(self, keys, loads_fn=None, namespace=None, _conn=None):\n        start = time.monotonic()\n        loads = loads_fn or self._serializer.loads\n\n        ns_keys = [self.build_key(key, namespace=namespace) for key in keys]\n        values = [\n            loads(value)\n            for value in await self._multi_get(\n                ns_keys, encoding=self.serializer.encoding, _conn=_conn\n            )\n        ]\n\n        logger.debug(\n            \"MULTI_GET %s %d (%.4f)s\",\n            ns_keys,\n            len([value for value in values if value is not None]),\n            time.monotonic() - start,\n        )\n        return values", "response": "Get multiple values from the cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def set(\n        self, key, value, ttl=SENTINEL, dumps_fn=None, namespace=None, _cas_token=None, _conn=None\n    ):\n        \"\"\"\n        Stores the value in the given key with ttl if specified\n\n        :param key: str\n        :param value: obj\n        :param ttl: int the expiration time in seconds. Due to memcached\n            restrictions if you want compatibility use int. In case you\n            need miliseconds, redis and memory support float ttls\n        :param dumps_fn: callable alternative to use as dumps function\n        :param namespace: str alternative namespace to use\n        :param timeout: int or float in seconds specifying maximum timeout\n            for the operations to last\n        :returns: True if the value was set\n        :raises: :class:`asyncio.TimeoutError` if it lasts more than self.timeout\n        \"\"\"\n        start = time.monotonic()\n        dumps = dumps_fn or self._serializer.dumps\n        ns_key = self.build_key(key, namespace=namespace)\n\n        res = await self._set(\n            ns_key, dumps(value), ttl=self._get_ttl(ttl), _cas_token=_cas_token, _conn=_conn\n        )\n\n        logger.debug(\"SET %s %d (%.4f)s\", ns_key, True, time.monotonic() - start)\n        return res", "response": "Stores the value in the given key with ttl if specified."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstoring multiple values in the given keys.", "response": "async def multi_set(self, pairs, ttl=SENTINEL, dumps_fn=None, namespace=None, _conn=None):\n        \"\"\"\n        Stores multiple values in the given keys.\n\n        :param pairs: list of two element iterables. First is key and second is value\n        :param ttl: int the expiration time in seconds. Due to memcached\n            restrictions if you want compatibility use int. In case you\n            need miliseconds, redis and memory support float ttls\n        :param dumps_fn: callable alternative to use as dumps function\n        :param namespace: str alternative namespace to use\n        :param timeout: int or float in seconds specifying maximum timeout\n            for the operations to last\n        :returns: True\n        :raises: :class:`asyncio.TimeoutError` if it lasts more than self.timeout\n        \"\"\"\n        start = time.monotonic()\n        dumps = dumps_fn or self._serializer.dumps\n\n        tmp_pairs = []\n        for key, value in pairs:\n            tmp_pairs.append((self.build_key(key, namespace=namespace), dumps(value)))\n\n        await self._multi_set(tmp_pairs, ttl=self._get_ttl(ttl), _conn=_conn)\n\n        logger.debug(\n            \"MULTI_SET %s %d (%.4f)s\",\n            [key for key, value in tmp_pairs],\n            len(pairs),\n            time.monotonic() - start,\n        )\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def delete(self, key, namespace=None, _conn=None):\n        start = time.monotonic()\n        ns_key = self.build_key(key, namespace=namespace)\n        ret = await self._delete(ns_key, _conn=_conn)\n        logger.debug(\"DELETE %s %d (%.4f)s\", ns_key, ret, time.monotonic() - start)\n        return ret", "response": "Deletes the given key."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if a key exists in the cache.", "response": "async def exists(self, key, namespace=None, _conn=None):\n        \"\"\"\n        Check key exists in the cache.\n\n        :param key: str key to check\n        :param namespace: str alternative namespace to use\n        :param timeout: int or float in seconds specifying maximum timeout\n            for the operations to last\n        :returns: True if key exists otherwise False\n        :raises: :class:`asyncio.TimeoutError` if it lasts more than self.timeout\n        \"\"\"\n        start = time.monotonic()\n        ns_key = self.build_key(key, namespace=namespace)\n        ret = await self._exists(ns_key, _conn=_conn)\n        logger.debug(\"EXISTS %s %d (%.4f)s\", ns_key, ret, time.monotonic() - start)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nincrement the value stored in key by delta.", "response": "async def increment(self, key, delta=1, namespace=None, _conn=None):\n        \"\"\"\n        Increments value stored in key by delta (can be negative). If key doesn't\n        exist, it creates the key with delta as value.\n\n        :param key: str key to check\n        :param delta: int amount to increment/decrement\n        :param namespace: str alternative namespace to use\n        :param timeout: int or float in seconds specifying maximum timeout\n            for the operations to last\n        :returns: Value of the key once incremented. -1 if key is not found.\n        :raises: :class:`asyncio.TimeoutError` if it lasts more than self.timeout\n        :raises: :class:`TypeError` if value is not incrementable\n        \"\"\"\n        start = time.monotonic()\n        ns_key = self.build_key(key, namespace=namespace)\n        ret = await self._increment(ns_key, delta, _conn=_conn)\n        logger.debug(\"INCREMENT %s %d (%.4f)s\", ns_key, ret, time.monotonic() - start)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the ttl to the given key.", "response": "async def expire(self, key, ttl, namespace=None, _conn=None):\n        \"\"\"\n        Set the ttl to the given key. By setting it to 0, it will disable it\n\n        :param key: str key to expire\n        :param ttl: int number of seconds for expiration. If 0, ttl is disabled\n        :param namespace: str alternative namespace to use\n        :param timeout: int or float in seconds specifying maximum timeout\n            for the operations to last\n        :returns: True if set, False if key is not found\n        :raises: :class:`asyncio.TimeoutError` if it lasts more than self.timeout\n        \"\"\"\n        start = time.monotonic()\n        ns_key = self.build_key(key, namespace=namespace)\n        ret = await self._expire(ns_key, ttl, _conn=_conn)\n        logger.debug(\"EXPIRE %s %d (%.4f)s\", ns_key, ret, time.monotonic() - start)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def clear(self, namespace=None, _conn=None):\n        start = time.monotonic()\n        ret = await self._clear(namespace, _conn=_conn)\n        logger.debug(\"CLEAR %s %d (%.4f)s\", namespace, ret, time.monotonic() - start)\n        return ret", "response": "Clears the cache in the given namespace."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend the raw command to the underlying client.", "response": "async def raw(self, command, *args, _conn=None, **kwargs):\n        \"\"\"\n        Send the raw command to the underlying client. Note that by using this CMD you\n        will lose compatibility with other backends.\n\n        Due to limitations with aiomcache client, args have to be provided as bytes.\n        For rest of backends, str.\n\n        :param command: str with the command.\n        :param timeout: int or float in seconds specifying maximum timeout\n            for the operations to last\n        :returns: whatever the underlying client returns\n        :raises: :class:`asyncio.TimeoutError` if it lasts more than self.timeout\n        \"\"\"\n        start = time.monotonic()\n        ret = await self._raw(\n            command, *args, encoding=self.serializer.encoding, _conn=_conn, **kwargs\n        )\n        logger.debug(\"%s (%.4f)s\", command, time.monotonic() - start)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def close(self, *args, _conn=None, **kwargs):\n        start = time.monotonic()\n        ret = await self._close(*args, _conn=_conn, **kwargs)\n        logger.debug(\"CLOSE (%.4f)s\", time.monotonic() - start)\n        return ret", "response": "Close the current session."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def cas(self, value: Any, **kwargs) -> bool:\n        success = await self.client.set(self.key, value, _cas_token=self._token, **kwargs)\n        if not success:\n            raise OptimisticLockError(\"Value has changed since the lock started\")\n        return True", "response": "Checks and sets the specified value for the locked key."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_url(cls, url):\n        parsed_url = urllib.parse.urlparse(url)\n        kwargs = dict(urllib.parse.parse_qsl(parsed_url.query))\n        cache_class = Cache.get_scheme_class(parsed_url.scheme)\n\n        if parsed_url.path:\n            kwargs.update(cache_class.parse_uri_path(parsed_url.path))\n\n        if parsed_url.hostname:\n            kwargs[\"endpoint\"] = parsed_url.hostname\n\n        if parsed_url.port:\n            kwargs[\"port\"] = parsed_url.port\n\n        if parsed_url.password:\n            kwargs[\"password\"] = parsed_url.password\n\n        return Cache(cache_class, **kwargs)", "response": "Given a resource uri return an instance of that cache initialized with the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a cache to the current config.", "response": "def add(self, alias: str, config: dict) -> None:\n        \"\"\"\n        Add a cache to the current config. If the key already exists, it\n        will overwrite it::\n\n            >>> caches.add('default', {\n                    'cache': \"aiocache.SimpleMemoryCache\",\n                    'serializer': {\n                        'class': \"aiocache.serializers.StringSerializer\"\n                    }\n                })\n\n        :param alias: The alias for the cache\n        :param config: Mapping containing the cache configuration\n        \"\"\"\n        self._config[alias] = config"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, alias: str):\n        try:\n            return self._caches[alias]\n        except KeyError:\n            pass\n\n        config = self.get_alias_config(alias)\n        cache = _create_cache(**deepcopy(config))\n        self._caches[alias] = cache\n        return cache", "response": "Retrieve a cache by its alias. Will return always the same instance of the cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new cache.", "response": "def create(self, alias=None, cache=None, **kwargs):\n        \"\"\"\n        Create a new cache. Either alias or cache params are required. You can use\n        kwargs to pass extra parameters to configure the cache.\n\n        .. deprecated:: 0.11.0\n            Only creating a cache passing an alias is supported. If you want to\n            create a cache passing explicit cache and kwargs use ``aiocache.Cache``.\n\n        :param alias: str alias to pull configuration from\n        :param cache: str or class cache class to use for creating the\n            new cache (when no alias is used)\n        :return: New cache instance\n        \"\"\"\n        if alias:\n            config = self.get_alias_config(alias)\n        elif cache:\n            warnings.warn(\n                \"Creating a cache with an explicit config is deprecated, use 'aiocache.Cache'\",\n                DeprecationWarning,\n            )\n            config = {\"cache\": cache}\n        else:\n            raise TypeError(\"create call needs to receive an alias or a cache\")\n        cache = _create_cache(**{**config, **kwargs})\n        return cache"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_config(self, config):\n        if \"default\" not in config:\n            raise ValueError(\"default config must be provided\")\n        for config_name in config.keys():\n            self._caches.pop(config_name, None)\n        self._config = config", "response": "Set the default config for the cache aliases."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def send(self, request: Request[HTTPRequestType], **config: Any) -> Response[HTTPRequestType, AsyncHTTPResponseType]:\n        pass", "response": "Send the request using this HTTP sender."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef send(self, request, **kwargs):\n        session = request.context.session\n\n        old_max_redirects = None\n        if 'max_redirects' in kwargs:\n            warnings.warn(\"max_redirects in operation kwargs is deprecated, use config.redirect_policy instead\",\n                          DeprecationWarning)\n            old_max_redirects = session.max_redirects\n            session.max_redirects = int(kwargs['max_redirects'])\n\n        old_trust_env = None\n        if 'use_env_proxies' in kwargs:\n            warnings.warn(\"use_env_proxies in operation kwargs is deprecated, use config.proxies instead\",\n                          DeprecationWarning)\n            old_trust_env = session.trust_env\n            session.trust_env = bool(kwargs['use_env_proxies'])\n\n        old_retries = {}\n        if 'retries' in kwargs:\n            warnings.warn(\"retries in operation kwargs is deprecated, use config.retry_policy instead\",\n                          DeprecationWarning)\n            max_retries = kwargs['retries']\n            for protocol in self._protocols:\n                old_retries[protocol] = session.adapters[protocol].max_retries\n                session.adapters[protocol].max_retries = max_retries\n\n        try:\n            return self.next.send(request, **kwargs)\n        finally:\n            if old_max_redirects:\n                session.max_redirects = old_max_redirects\n\n            if old_trust_env:\n                session.trust_env = old_trust_env\n\n            if old_retries:\n                for protocol in self._protocols:\n                    session.adapters[protocol].max_retries = old_retries[protocol]", "response": "Send the request to the next protocol."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _request(self, method, url, params, headers, content, form_content):\n        # type: (str, str, Optional[Dict[str, str]], Optional[Dict[str, str]], Any, Optional[Dict[str, Any]]) -> ClientRequest\n        \"\"\"Create ClientRequest object.\n\n        :param str url: URL for the request.\n        :param dict params: URL query parameters.\n        :param dict headers: Headers\n        :param dict form_content: Form content\n        \"\"\"\n        request = ClientRequest(method, self.format_url(url))\n\n        if params:\n            request.format_parameters(params)\n\n        if headers:\n            request.headers.update(headers)\n        # All requests should contain a Accept.\n        # This should be done by Autorest, but wasn't in old Autorest\n        # Force it for now, but might deprecate it later.\n        if \"Accept\" not in request.headers:\n            _LOGGER.debug(\"Accept header absent and forced to application/json\")\n            request.headers['Accept'] = 'application/json'\n\n        if content is not None:\n            request.add_content(content)\n\n        if form_content:\n            request.add_formdata(form_content)\n\n        return request", "response": "Create a ClientRequest object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nformatting the request URL with the client base URL unless the the supplied URL is already absolute.", "response": "def format_url(self, url, **kwargs):\n        # type: (str, Any) -> str\n        \"\"\"Format request URL with the client base URL, unless the\n        supplied URL is already absolute.\n\n        :param str url: The request URL to be formatted if necessary.\n        \"\"\"\n        url = url.format(**kwargs)\n        parsed = urlparse(url)\n        if not parsed.scheme or not parsed.netloc:\n            url = url.lstrip('/')\n            base = self.config.base_url.format(**kwargs).rstrip('/')\n            url = urljoin(base + '/', url)\n        return url"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(self, url, params=None, headers=None, content=None, form_content=None):\n        # type: (str, Optional[Dict[str, str]], Optional[Dict[str, str]], Any, Optional[Dict[str, Any]]) -> ClientRequest\n        \"\"\"Create a GET request object.\n\n        :param str url: The request URL.\n        :param dict params: Request URL parameters.\n        :param dict headers: Headers\n        :param dict form_content: Form content\n        \"\"\"\n        request = self._request('GET', url, params, headers, content, form_content)\n        request.method = 'GET'\n        return request", "response": "Create a GET request object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef put(self, url, params=None, headers=None, content=None, form_content=None):\n        # type: (str, Optional[Dict[str, str]], Optional[Dict[str, str]], Any, Optional[Dict[str, Any]]) -> ClientRequest\n        \"\"\"Create a PUT request object.\n\n        :param str url: The request URL.\n        :param dict params: Request URL parameters.\n        :param dict headers: Headers\n        :param dict form_content: Form content\n        \"\"\"\n        request = self._request('PUT', url, params, headers, content, form_content)\n        return request", "response": "Create a PUT request object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef send_formdata(self, request, headers=None, content=None, **config):\n        request.headers = headers\n        request.add_formdata(content)\n        return self.send(request, **config)", "response": "Send data as a multipart form - data request."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends a request object according to the configuration.", "response": "def send(self, request, headers=None, content=None, **kwargs):\n        \"\"\"Prepare and send request object according to configuration.\n\n        :param ClientRequest request: The request object to be sent.\n        :param dict headers: Any headers to add to the request.\n        :param content: Any body data to add to the request.\n        :param config: Any specific config overrides\n        \"\"\"\n        # \"content\" and \"headers\" are deprecated, only old SDK\n        if headers:\n            request.headers.update(headers)\n        if not request.files and request.data is None and content is not None:\n            request.add_content(content)\n        # End of deprecation\n\n        response = None\n        kwargs.setdefault('stream', True)\n        try:\n            pipeline_response = self.config.pipeline.run(request, **kwargs)\n            # There is too much thing that expects this method to return a \"requests.Response\"\n            # to break it in a compatible release.\n            # Also, to be pragmatic in the \"sync\" world \"requests\" rules anyway.\n            # However, attach the Universal HTTP response\n            # to get the streaming generator.\n            response = pipeline_response.http_response.internal_response\n            response._universal_http_response = pipeline_response.http_response\n            response.context = pipeline_response.context\n            return response\n        finally:\n            self._close_local_session_if_necessary(response, kwargs['stream'])"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstreams the response body of a request.", "response": "def stream_download(self, data, callback):\n        # type: (Union[requests.Response, ClientResponse], Callable) -> Iterator[bytes]\n        \"\"\"Generator for streaming request body data.\n\n        :param data: A response object to be streamed.\n        :param callback: Custom callback for monitoring progress.\n        \"\"\"\n        block = self.config.connection.data_block_size\n        try:\n            # Assume this is ClientResponse, which it should be if backward compat was not important\n            return cast(ClientResponse, data).stream_download(block, callback)\n        except AttributeError:\n            try:\n                # Assume this is the patched requests.Response from \"send\"\n                return data._universal_http_response.stream_download(block, callback)  # type: ignore\n            except AttributeError:\n                # Assume this is a raw requests.Response\n                from .universal_http.requests import RequestsClientResponse\n                response = RequestsClientResponse(None, data)\n                return response.stream_download(block, callback)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_header(self, header, value):\n        # type: (str, str) -> None\n        \"\"\"Add a persistent header - this header will be applied to all\n        requests sent during the current client session.\n\n        .. deprecated:: 0.5.0\n           Use config.headers instead\n\n        :param str header: The header name.\n        :param str value: The header value.\n        \"\"\"\n        warnings.warn(\"Private attribute _client.add_header is deprecated. Use config.headers instead.\",\n                      DeprecationWarning)\n        self.config.headers[header] = value", "response": "Add a persistent header - this header will be applied to all\n        requests sent during the current client session."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef signed_session(self, session=None):\n        # type: (Optional[requests.Session]) -> requests.Session\n        \"\"\"Create requests session with any required auth headers\n        applied.\n\n        If a session object is provided, configure it directly. Otherwise,\n        create a new session and return it.\n\n        :param session: The session to configure for authentication\n        :type session: requests.Session\n        :rtype: requests.Session\n        \"\"\"\n        session = super(BasicAuthentication, self).signed_session(session)\n        session.auth = HTTPBasicAuth(self.username, self.password)\n        return session", "response": "Create requests. Session object with any required auth headers\n        applied."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef signed_session(self, session=None):\n        # type: (Optional[requests.Session]) -> requests.Session\n        \"\"\"Create requests session with any required auth headers\n        applied.\n\n        If a session object is provided, configure it directly. Otherwise,\n        create a new session and return it.\n\n        :param session: The session to configure for authentication\n        :type session: requests.Session\n        :rtype: requests.Session\n        \"\"\"\n        session = super(BasicTokenAuthentication, self).signed_session(session)\n        header = \"{} {}\".format(self.scheme, self.token['access_token'])\n        session.headers['Authorization'] = header\n        return session", "response": "Create requests. Session object with any required auth headers\n        applied."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef signed_session(self, session=None):\n        # type: (Optional[requests.Session]) -> requests.Session\n        \"\"\"Create requests session with any required auth headers applied.\n\n        If a session object is provided, configure it directly. Otherwise,\n        create a new session and return it.\n\n        :param session: The session to configure for authentication\n        :type session: requests.Session\n        :rtype: requests.Session\n        \"\"\"\n        session = session or requests.Session()  # Don't call super on purpose, let's \"auth\" manage the headers.\n        session.auth = oauth.OAuth2(self.id, token=self.token)\n        return session", "response": "Create a requests. Session object with any required auth headers applied."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef signed_session(self, session=None):\n        # type: (Optional[requests.Session]) -> requests.Session\n        \"\"\"Create requests session with ApiKey.\n\n        If a session object is provided, configure it directly. Otherwise,\n        create a new session and return it.\n\n        :param session: The session to configure for authentication\n        :type session: requests.Session\n        :rtype: requests.Session\n        \"\"\"\n        session = super(ApiKeyCredentials, self).signed_session(session)\n        session.headers.update(self.in_headers)\n        try:\n            # params is actually Union[bytes, MutableMapping[Text, Text]]\n            session.params.update(self.in_query) # type: ignore\n        except AttributeError:  # requests.params can be bytes\n            raise ValueError(\"session.params must be a dict to be used in ApiKeyCredentials\")\n        return session", "response": "Create requests session with ApiKey.\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprepare and send the request according to configuration.", "response": "async def async_send(self, request, **kwargs):\n        \"\"\"Prepare and send request object according to configuration.\n\n        :param ClientRequest request: The request object to be sent.\n        :param dict headers: Any headers to add to the request.\n        :param content: Any body data to add to the request.\n        :param config: Any specific config overrides\n        \"\"\"\n        kwargs.setdefault('stream', True)\n        # In the current backward compatible implementation, return the HTTP response\n        # and plug context inside. Could be remove if we modify Autorest,\n        # but we still need it to be backward compatible\n        pipeline_response = await self.config.pipeline.run(request, **kwargs)\n        response = pipeline_response.http_response\n        response.context = pipeline_response.context\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def send(self, request: ClientRequest, **config: Any) -> AsyncClientResponse:\n        result = await self._session.request(\n            request.method,\n            request.url,\n            **config\n        )\n        response = AioHttpClientResponse(request, result)\n        if not config.get(\"stream\", False):\n            await response.load_body()\n        return response", "response": "Send the request using this HTTP sender."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stream_download(self, chunk_size: Optional[int] = None, callback: Optional[Callable] = None) -> AsyncIterator[bytes]:\n        chunk_size = chunk_size or CONTENT_CHUNK_SIZE\n        async def async_gen(resp):\n            while True:\n                chunk = await resp.content.read(chunk_size)\n                if not chunk:\n                    break\n                callback(chunk, resp)\n        return async_gen(self.internal_response)", "response": "Generator for streaming the response body data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndecode data according to content-type. Accept a stream of data as well, but will be load at once in memory for now. If no content-type, will return the string version (not bytes, not stream) :param data: Input, could be bytes or stream (will be decoded with UTF8) or text :type data: str or bytes or IO :param str content_type: The content type.", "response": "def deserialize_from_text(cls, data, content_type=None):\n        # type: (Optional[Union[AnyStr, IO]], Optional[str]) -> Any\n        \"\"\"Decode data according to content-type.\n\n        Accept a stream of data as well, but will be load at once in memory for now.\n\n        If no content-type, will return the string version (not bytes, not stream)\n\n        :param data: Input, could be bytes or stream (will be decoded with UTF8) or text\n        :type data: str or bytes or IO\n        :param str content_type: The content type.\n        \"\"\"\n        if hasattr(data, 'read'):\n            # Assume a stream\n            data = cast(IO, data).read()\n\n        if isinstance(data, bytes):\n            data_as_str = data.decode(encoding='utf-8-sig')\n        else:\n            # Explain to mypy the correct type.\n            data_as_str = cast(str, data)\n\n            # Remove Byte Order Mark if present in string\n            data_as_str = data_as_str.lstrip(_BOM)\n\n        if content_type is None:\n            return data\n\n        if content_type in cls.JSON_MIMETYPES:\n            try:\n                return json.loads(data_as_str)\n            except ValueError as err:\n                raise DeserializationError(\"JSON is invalid: {}\".format(err), err)\n        elif \"xml\" in (content_type or []):\n            try:\n                return ET.fromstring(data_as_str)\n            except ET.ParseError:\n                # It might be because the server has an issue, and returned JSON with\n                # content-type XML....\n                # So let's try a JSON load, and if it's still broken\n                # let's flow the initial exception\n                def _json_attemp(data):\n                    try:\n                        return True, json.loads(data)\n                    except ValueError:\n                        return False, None # Don't care about this one\n                success, json_result = _json_attemp(data)\n                if success:\n                    return json_result\n                # If i'm here, it's not JSON, it's not XML, let's scream\n                # and raise the last context in this block (the XML exception)\n                # The function hack is because Py2.7 messes up with exception\n                # context otherwise.\n                _LOGGER.critical(\"Wasn't XML not JSON, failing\")\n                raise_with_traceback(DeserializationError, \"XML is invalid\")\n        raise DeserializationError(\"Cannot deserialize content-type: {}\".format(content_type))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef deserialize_from_http_generics(cls, body_bytes, headers):\n        # type: (Optional[Union[AnyStr, IO]], Mapping) -> Any\n        \"\"\"Deserialize from HTTP response.\n\n        Use bytes and headers to NOT use any requests/aiohttp or whatever\n        specific implementation.\n        Headers will tested for \"content-type\"\n        \"\"\"\n        # Try to use content-type from headers if available\n        content_type = None\n        if 'content-type' in headers:\n            content_type = headers['content-type'].split(\";\")[0].strip().lower()\n        # Ouch, this server did not declare what it sent...\n        # Let's guess it's JSON...\n        # Also, since Autorest was considering that an empty body was a valid JSON,\n        # need that test as well....\n        else:\n            content_type = \"application/json\"\n\n        if body_bytes:\n            return cls.deserialize_from_text(body_bytes, content_type)\n        return None", "response": "Deserialize from HTTP response."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef on_response(self, request, response, **kwargs):\n        # type: (Request, Response, Any) -> None\n        \"\"\"Extract data from the body of a REST response object.\n\n        This will load the entire payload in memory.\n\n        Will follow Content-Type to parse.\n        We assume everything is UTF8 (BOM acceptable).\n\n        :param raw_data: Data to be processed.\n        :param content_type: How to parse if raw_data is a string/bytes.\n        :raises JSONDecodeError: If JSON is requested and parsing is impossible.\n        :raises UnicodeDecodeError: If bytes is not UTF8\n        :raises xml.etree.ElementTree.ParseError: If bytes is not valid XML\n        \"\"\"\n        # If response was asked as stream, do NOT read anything and quit now\n        if kwargs.get(\"stream\", True):\n            return\n\n        http_response = response.http_response\n\n        response.context[self.CONTEXT_NAME] = self.deserialize_from_http_generics(\n            http_response.text(),\n            http_response.headers\n        )", "response": "Extract data from the body of a REST response object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def send(self, request: Request, **config: Any) -> Response:\n        return Response(\n            request,\n            await self.driver.send(request.http_request)\n        )", "response": "Send the request using this HTTP sender."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend the request using this HTTP sender.", "response": "async def send(self, request: ClientRequest, **kwargs: Any) -> AsyncClientResponse:  # type: ignore\n        \"\"\"Send the request using this HTTP sender.\n        \"\"\"\n        # It's not recommended to provide its own session, and is mostly\n        # to enable some legacy code to plug correctly\n        session = kwargs.pop('session', self.session)\n\n        loop = kwargs.get(\"loop\", asyncio.get_event_loop())\n        future = loop.run_in_executor(\n            None,\n            functools.partial(\n                session.request,\n                request.method,\n                request.url,\n                **kwargs\n            )\n        )\n        try:\n            return AsyncRequestsClientResponse(\n                request,\n                await future\n            )\n        except requests.RequestException as err:\n            msg = \"Error occurred in request.\"\n            raise_with_traceback(ClientRequestError, msg, err)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def send(self, request: ClientRequest, **kwargs: Any) -> AsyncClientResponse:  # type: ignore\n        requests_kwargs = self._configure_send(request, **kwargs)\n        return await super(AsyncRequestsHTTPSender, self).send(request, **requests_kwargs)", "response": "Send the request using this HTTP sender."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef stream_download(self, chunk_size: Optional[int] = None, callback: Optional[Callable] = None) -> AsyncIteratorType[bytes]:\n        return StreamDownloadGenerator(\n            self.internal_response,\n            callback,\n            chunk_size\n        )", "response": "Generator for streaming the HTTP response body data."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets an arbitrary page. This is a non - blocking call.", "response": "async def async_get(self, url):\n        \"\"\"Get an arbitrary page.\n\n        This resets the iterator and then fully consumes it to return the\n        specific page **only**.\n\n        :param str url: URL to arbitrary page results.\n        \"\"\"\n        self.reset()\n        self.next_link = url\n        return await self.async_advance_page()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _start(self):\n        try:\n            self._polling_method.run()\n        except Exception as err:\n            self._exception = err\n\n        finally:\n            self._done.set()\n\n        callbacks, self._callbacks = self._callbacks, []\n        while callbacks:\n            for call in callbacks:\n                call(self._polling_method)\n            callbacks, self._callbacks = self._callbacks, []", "response": "Start the long running operation."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef wait(self, timeout=None):\n        # type: (Optional[int]) -> None\n        \"\"\"Wait on the long running operation for a specified length\n        of time. You can check if this call as ended with timeout with the\n        \"done()\" method.\n\n        :param int timeout: Period of time to wait for the long running\n         operation to complete (in seconds).\n        :raises CloudError: Server problem with the query.\n        \"\"\"\n        if self._thread is None:\n            return\n        self._thread.join(timeout=timeout)\n        try:\n            # Let's handle possible None in forgiveness here\n            raise self._exception  # type: ignore\n        except TypeError: # Was None\n            pass", "response": "Wait on the long running operation for a specified length\n         of time."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_done_callback(self, func):\n        # type: (Callable) -> None\n        \"\"\"Add callback function to be run once the long running operation\n        has completed - regardless of the status of the operation.\n\n        :param callable func: Callback function that takes at least one\n         argument, a completed LongRunningOperation.\n        \"\"\"\n        # Still use \"_done\" and not \"done\", since CBs are executed inside the thread.\n        if self._done is None or self._done.is_set():\n            func(self._polling_method)\n        # Let's add them still, for consistency (if you wish to access to it for some reasons)\n        self._callbacks.append(func)", "response": "Add a callback function to be run once the long running operation\n         has completed."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef log_request(_, request, *_args, **_kwargs):\n    # type: (Any, ClientRequest, str, str) -> None\n    \"\"\"Log a client request.\n\n    :param _: Unused in current version (will be None)\n    :param requests.Request request: The request object.\n    \"\"\"\n    if not _LOGGER.isEnabledFor(logging.DEBUG):\n        return\n\n    try:\n        _LOGGER.debug(\"Request URL: %r\", request.url)\n        _LOGGER.debug(\"Request method: %r\", request.method)\n        _LOGGER.debug(\"Request headers:\")\n        for header, value in request.headers.items():\n            if header.lower() == 'authorization':\n                value = '*****'\n            _LOGGER.debug(\"    %r: %r\", header, value)\n        _LOGGER.debug(\"Request body:\")\n\n        # We don't want to log the binary data of a file upload.\n        if isinstance(request.body, types.GeneratorType):\n            _LOGGER.debug(\"File upload\")\n        else:\n            _LOGGER.debug(str(request.body))\n    except Exception as err:  # pylint: disable=broad-except\n        _LOGGER.debug(\"Failed to log request: %r\", err)", "response": "Log a client request."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef log_response(_, _request, response, *_args, **kwargs):\n    # type: (Any, ClientRequest, ClientResponse, str, Any) -> Optional[ClientResponse]\n    \"\"\"Log a server response.\n\n    :param _: Unused in current version (will be None)\n    :param requests.Request request: The request object.\n    :param requests.Response response: The response object.\n    \"\"\"\n    if not _LOGGER.isEnabledFor(logging.DEBUG):\n        return None\n\n    try:\n        _LOGGER.debug(\"Response status: %r\", response.status_code)\n        _LOGGER.debug(\"Response headers:\")\n        for res_header, value in response.headers.items():\n            _LOGGER.debug(\"    %r: %r\", res_header, value)\n\n        # We don't want to log binary data if the response is a file.\n        _LOGGER.debug(\"Response content:\")\n        pattern = re.compile(r'attachment; ?filename=[\"\\w.]+', re.IGNORECASE)\n        header = response.headers.get('content-disposition')\n\n        if header and pattern.match(header):\n            filename = header.partition('=')[2]\n            _LOGGER.debug(\"File attachments: %s\", filename)\n        elif response.headers.get(\"content-type\", \"\").endswith(\"octet-stream\"):\n            _LOGGER.debug(\"Body contains binary data.\")\n        elif response.headers.get(\"content-type\", \"\").startswith(\"image\"):\n            _LOGGER.debug(\"Body contains image data.\")\n        else:\n            if kwargs.get('stream', False):\n                _LOGGER.debug(\"Body is streamable\")\n            else:\n                _LOGGER.debug(response.text())\n        return response\n    except Exception as err:  # pylint: disable=broad-except\n        _LOGGER.debug(\"Failed to log response: %s\", repr(err))\n        return response", "response": "Log a server response."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _clear_config(self):\n        # type: () -> None\n        \"\"\"Clearout config object in memory.\"\"\"\n        for section in self._config.sections():\n            self._config.remove_section(section)", "response": "Clear out the config object in memory."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsaves current configuration to file.", "response": "def save(self, filepath):\n        # type: (str) -> None\n        \"\"\"Save current configuration to file.\n\n        :param str filepath: Path to file where settings will be saved.\n        :raises: ValueError if supplied filepath cannot be written to.\n        \"\"\"\n        sections = [\n            \"Connection\",\n            \"Proxies\",\n            \"RedirectPolicy\"]\n        for section in sections:\n            self._config.add_section(section)\n\n        self._config.set(\"Connection\", \"timeout\", self.connection.timeout)\n        self._config.set(\"Connection\", \"verify\", self.connection.verify)\n        self._config.set(\"Connection\", \"cert\", self.connection.cert)\n\n        self._config.set(\"Proxies\", \"proxies\", self.proxies.proxies)\n        self._config.set(\"Proxies\", \"env_settings\",\n                         self.proxies.use_env_settings)\n\n        self._config.set(\"RedirectPolicy\", \"allow\", self.redirect_policy.allow)\n        self._config.set(\"RedirectPolicy\", \"max_redirects\",\n                         self.redirect_policy.max_redirects)\n\n        try:\n            with open(filepath, 'w') as configfile:\n                self._config.write(configfile)\n        except (KeyError, EnvironmentError):\n            error = \"Supplied config filepath invalid.\"\n            raise_with_traceback(ValueError, error)\n        finally:\n            self._clear_config()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading the configuration from the given file.", "response": "def load(self, filepath):\n        # type: (str) -> None\n        \"\"\"Load configuration from existing file.\n\n        :param str filepath: Path to existing config file.\n        :raises: ValueError if supplied config file is invalid.\n        \"\"\"\n        try:\n            self._config.read(filepath)\n            import ast\n            self.connection.timeout = \\\n                self._config.getint(\"Connection\", \"timeout\")\n            self.connection.verify = \\\n                self._config.getboolean(\"Connection\", \"verify\")\n            self.connection.cert = \\\n                self._config.get(\"Connection\", \"cert\")\n\n            self.proxies.proxies = \\\n                ast.literal_eval(self._config.get(\"Proxies\", \"proxies\"))\n            self.proxies.use_env_settings = \\\n                self._config.getboolean(\"Proxies\", \"env_settings\")\n\n            self.redirect_policy.allow = \\\n                self._config.getboolean(\"RedirectPolicy\", \"allow\")\n            self.redirect_policy.max_redirects = \\\n                self._config.getint(\"RedirectPolicy\", \"max_redirects\")\n\n        except (ValueError, EnvironmentError, NoOptionError):\n            error = \"Supplied config file incompatible.\"\n            raise_with_traceback(ValueError, error)\n        finally:\n            self._clear_config()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef format_parameters(self, params):\n        # type: (Dict[str, str]) -> None\n        \"\"\"Format parameters into a valid query string.\n        It's assumed all parameters have already been quoted as\n        valid URL strings.\n\n        :param dict params: A dictionary of parameters.\n        \"\"\"\n        query = urlparse(self.url).query\n        if query:\n            self.url = self.url.partition('?')[0]\n            existing_params = {\n                p[0]: p[-1]\n                for p in [p.partition('=') for p in query.split('&')]\n            }\n            params.update(existing_params)\n        query_params = [\"{}={}\".format(k, v) for k, v in params.items()]\n        query = '?' + '&'.join(query_params)\n        self.url = self.url + query", "response": "Format parameters into a valid query string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_content(self, data):\n        # type: (Optional[Union[Dict[str, Any], ET.Element]]) -> None\n        \"\"\"Add a body to the request.\n\n        :param data: Request body data, can be a json serializable\n         object (e.g. dictionary) or a generator (e.g. file data).\n        \"\"\"\n        if data is None:\n            return\n\n        if isinstance(data, ET.Element):\n            bytes_data = ET.tostring(data, encoding=\"utf8\")\n            self.headers['Content-Length'] = str(len(bytes_data))\n            self.data = bytes_data\n            return\n\n        # By default, assume JSON\n        try:\n            self.data = json.dumps(data)\n            self.headers['Content-Length'] = str(len(self.data))\n        except TypeError:\n            self.data = data", "response": "Add a body to the request."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _format_data(data):\n        # type: (Union[str, IO]) -> Union[Tuple[None, str], Tuple[Optional[str], IO, str]]\n        \"\"\"Format field data according to whether it is a stream or\n        a string for a form-data request.\n\n        :param data: The request field data.\n        :type data: str or file-like object.\n        \"\"\"\n        if hasattr(data, 'read'):\n            data = cast(IO, data)\n            data_name = None\n            try:\n                if data.name[0] != '<' and data.name[-1] != '>':\n                    data_name = os.path.basename(data.name)\n            except (AttributeError, TypeError):\n                pass\n            return (data_name, data, \"application/octet-stream\")\n        return (None, cast(str, data))", "response": "Format the data according to whether it is a stream or a file - like object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_formdata(self, content=None):\n        # type: (Optional[Dict[str, str]]) -> None\n        \"\"\"Add data as a multipart form-data request to the request.\n\n        We only deal with file-like objects or strings at this point.\n        The requests is not yet streamed.\n\n        :param dict headers: Any headers to add to the request.\n        :param dict content: Dictionary of the fields of the formdata.\n        \"\"\"\n        if content is None:\n            content = {}\n        content_type = self.headers.pop('Content-Type', None) if self.headers else None\n\n        if content_type and content_type.lower() == 'application/x-www-form-urlencoded':\n            # Do NOT use \"add_content\" that assumes input is JSON\n            self.data = {f: d for f, d in content.items() if d is not None}\n        else: # Assume \"multipart/form-data\"\n            self.files = {f: self._format_data(d) for f, d in content.items() if d is not None}", "response": "Add data as a multipart form - data request to the request."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nraising exception with a specified traceback.", "response": "def raise_with_traceback(exception, message=\"\", *args, **kwargs):\n    # type: (Callable, str, Any, Any) -> None\n    \"\"\"Raise exception with a specified traceback.\n\n    This MUST be called inside a \"except\" clause.\n\n    :param Exception exception: Error type to be raised.\n    :param str message: Message to include with error, empty by default.\n    :param args: Any additional args to be included with exception.\n    \"\"\"\n    exc_type, exc_value, exc_traceback = sys.exc_info()\n    # If not called inside a \"except\", exc_type will be None. Assume it will not happen\n    exc_msg = \"{}, {}: {}\".format(message, exc_type.__name__, exc_value)  # type: ignore\n    error = exception(exc_msg, *args, **kwargs)\n    try:\n        raise error.with_traceback(exc_traceback)\n    except AttributeError:\n        error.__traceback__ = exc_traceback\n        raise error"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stream_download(self, chunk_size: Optional[int] = None, callback: Optional[Callable] = None) -> AsyncIterator[bytes]:\n        pass", "response": "Stream the data in the request body."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _patch_redirect(session):\n    # type: (requests.Session) -> None\n    \"\"\"Whether redirect policy should be applied based on status code.\n\n    HTTP spec says that on 301/302 not HEAD/GET, should NOT redirect.\n    But requests does, to follow browser more than spec\n    https://github.com/requests/requests/blob/f6e13ccfc4b50dc458ee374e5dba347205b9a2da/requests/sessions.py#L305-L314\n\n    This patches \"requests\" to be more HTTP compliant.\n\n    Note that this is super dangerous, since technically this is not public API.\n    \"\"\"\n    def enforce_http_spec(resp, request):\n        if resp.status_code in (301, 302) and \\\n                request.method not in ['GET', 'HEAD']:\n            return False\n        return True\n\n    redirect_logic = session.resolve_redirects\n\n    def wrapped_redirect(resp, req, **kwargs):\n        attempt = enforce_http_spec(resp, req)\n        return redirect_logic(resp, req, **kwargs) if attempt else []\n    wrapped_redirect.is_msrest_patched = True  # type: ignore\n\n    session.resolve_redirects = wrapped_redirect", "response": "Patches requests to be more HTTP compliant."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stream_download(self, chunk_size=None, callback=None):\n        # type: (Optional[int], Optional[Callable]) -> Iterator[bytes]\n        \"\"\"Generator for streaming request body data.\n\n        :param callback: Custom callback for monitoring progress.\n        :param int chunk_size:\n        \"\"\"\n        chunk_size = chunk_size or CONTENT_CHUNK_SIZE\n        with contextlib.closing(self.internal_response) as response:\n            # https://github.com/PyCQA/pylint/issues/1437\n            for chunk in response.iter_content(chunk_size):  # pylint: disable=no-member\n                if not chunk:\n                    break\n                if callback and callable(callback):\n                    callback(chunk, response=response)\n                yield chunk", "response": "Generator for streaming the request body data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef send(self, request, **kwargs):\n        # type: (ClientRequest, Any) -> ClientResponse\n        \"\"\"Send request object according to configuration.\n\n        Allowed kwargs are:\n        - session : will override the driver session and use yours. Should NOT be done unless really required.\n        - anything else is sent straight to requests.\n\n        :param ClientRequest request: The request object to be sent.\n        \"\"\"\n        # It's not recommended to provide its own session, and is mostly\n        # to enable some legacy code to plug correctly\n        session = kwargs.pop('session', self.session)\n        try:\n            response = session.request(\n                request.method,\n                request.url,\n                **kwargs)\n        except requests.RequestException as err:\n            msg = \"Error occurred in request.\"\n            raise_with_traceback(ClientRequestError, msg, err)\n\n        return RequestsClientResponse(request, response)", "response": "Send a request object according to the configuration."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninitializing the session level configuration of requests. Session.", "response": "def _init_session(self, session):\n        # type: (requests.Session) -> None\n        \"\"\"Init session level configuration of requests.\n\n        This is initialization I want to do once only on a session.\n        \"\"\"\n        _patch_redirect(session)\n\n        # Change max_retries in current all installed adapters\n        max_retries = self.config.retry_policy()\n        for protocol in self._protocols:\n            session.adapters[protocol].max_retries = max_retries"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconfiguring the kwargs to use with requests. Session. request.", "response": "def _configure_send(self, request, **kwargs):\n        # type: (ClientRequest, Any) -> Dict[str, str]\n        \"\"\"Configure the kwargs to use with requests.\n\n        See \"send\" for kwargs details.\n\n        :param ClientRequest request: The request object to be sent.\n        :returns: The requests.Session.request kwargs\n        :rtype: dict[str,str]\n        \"\"\"\n        requests_kwargs = {}  # type: Any\n        session = kwargs.pop('session', self.session)\n\n        # If custom session was not create here\n        if session is not self.session:\n            self._init_session(session)\n\n        session.max_redirects = int(self.config.redirect_policy())\n        session.trust_env = bool(self.config.proxies.use_env_settings)\n\n        # Initialize requests_kwargs with \"config\" value\n        requests_kwargs.update(self.config.connection())\n        requests_kwargs['allow_redirects'] = bool(self.config.redirect_policy)\n        requests_kwargs['headers'] = self.config.headers.copy()\n\n        proxies = self.config.proxies()\n        if proxies:\n            requests_kwargs['proxies'] = proxies\n\n        # Replace by operation level kwargs\n        # We allow some of them, since some like stream or json are controled by msrest\n        for key in kwargs:\n            if key in self._REQUESTS_KWARGS:\n                requests_kwargs[key] = kwargs[key]\n\n        # Hooks. Deprecated, should be a policy\n        def make_user_hook_cb(user_hook, session):\n            def user_hook_cb(r, *args, **kwargs):\n                kwargs.setdefault(\"msrest\", {})['session'] = session\n                return user_hook(r, *args, **kwargs)\n            return user_hook_cb\n\n        hooks = []\n        for user_hook in self.config.hooks:\n            hooks.append(make_user_hook_cb(user_hook, self.session))\n\n        if hooks:\n            requests_kwargs['hooks'] = {'response': hooks}\n\n        # Configuration callback. Deprecated, should be a policy\n        output_kwargs = self.config.session_configuration_callback(\n            session,\n            self.config,\n            kwargs,\n            **requests_kwargs\n        )\n        if output_kwargs is not None:\n            requests_kwargs = output_kwargs\n\n        # If custom session was not create here\n        if session is not self.session:\n            requests_kwargs['session'] = session\n\n        ### Autorest forced kwargs now ###\n\n        # If Autorest needs this response to be streamable. True for compat.\n        requests_kwargs['stream'] = kwargs.get('stream', True)\n\n        if request.files:\n            requests_kwargs['files'] = request.files\n        elif request.data:\n            requests_kwargs['data'] = request.data\n        requests_kwargs['headers'].update(request.headers)\n\n        return requests_kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef send(self, request, **kwargs):\n        # type: (ClientRequest, Any) -> ClientResponse\n        \"\"\"Send request object according to configuration.\n\n        Available kwargs:\n        - session : will override the driver session and use yours. Should NOT be done unless really required.\n        - A subset of what requests.Session.request can receive:\n\n            - cookies\n            - verify\n            - timeout\n            - allow_redirects\n            - proxies\n            - verify\n            - cert\n\n        Everything else will be silently ignored.\n\n        :param ClientRequest request: The request object to be sent.\n        \"\"\"\n        requests_kwargs = self._configure_send(request, **kwargs)\n        return super(RequestsHTTPSender, self).send(request, **requests_kwargs)", "response": "Send the request object according to the configuration."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsaves current configuration to file.", "response": "def save(self, filepath):\n        \"\"\"Save current configuration to file.\n\n        :param str filepath: Path to file where settings will be saved.\n        :raises: ValueError if supplied filepath cannot be written to.\n        \"\"\"\n        self._config.add_section(\"RetryPolicy\")\n        self._config.set(\"RetryPolicy\", \"retries\", str(self.retry_policy.retries))\n        self._config.set(\"RetryPolicy\", \"backoff_factor\",\n                         str(self.retry_policy.backoff_factor))\n        self._config.set(\"RetryPolicy\", \"max_backoff\",\n                         str(self.retry_policy.max_backoff))\n        super(RequestHTTPSenderConfiguration, self).save(filepath)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef full_restapi_key_transformer(key, attr_desc, value):\n    keys = _FLATTEN.split(attr_desc['key'])\n    return ([_decode_attribute_map_key(k) for k in keys], value)", "response": "A key transformer that returns the full RestAPI key path."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef last_restapi_key_transformer(key, attr_desc, value):\n    key, value = full_restapi_key_transformer(key, attr_desc, value)\n    return (key[-1], value)", "response": "A key transformer that returns the last RestAPI key."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _create_xml_node(tag, prefix=None, ns=None):\n    if prefix and ns:\n        ET.register_namespace(prefix, ns)\n    if ns:\n        return ET.Element(\"{\"+ns+\"}\"+tag)\n    else:\n        return ET.Element(tag)", "response": "Create a XML node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating XML node from _xml_map.", "response": "def _create_xml_node(cls):\n        \"\"\"Create XML node from \"_xml_map\".\n        \"\"\"\n        try:\n            xml_map = cls._xml_map\n        except AttributeError:\n            raise ValueError(\"This model has no XML definition\")\n\n        return _create_xml_node(\n            xml_map.get('name', cls.__name__),\n            xml_map.get(\"prefix\", None),\n            xml_map.get(\"ns\", None)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate(self):\n        validation_result = []\n        for attr_name, value in [(attr, getattr(self, attr)) for attr in self._attribute_map]:\n            attr_desc = self._attribute_map[attr_name]\n            if attr_name == \"additional_properties\" and attr_desc[\"key\"] == '':\n                # Do NOT validate additional_properties\n                continue\n            attr_type = attr_desc['type']\n\n            try:\n                debug_name = \"{}.{}\".format(self.__class__.__name__, attr_name)\n                Serializer.validate(value, debug_name, **self._validation.get(attr_name, {}))\n            except ValidationError as validation_error:\n                validation_result.append(validation_error)\n\n            validation_result += _recursive_validate(attr_name, attr_type, value)\n        return validation_result", "response": "Validate this model recursively and return a list of ValidationError."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef serialize(self, keep_readonly=False):\n        serializer = Serializer(self._infer_class_models())\n        return serializer._serialize(self, keep_readonly=keep_readonly)", "response": "Return the JSON that would be sent to azure from this model."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef as_dict(self, keep_readonly=True, key_transformer=attribute_transformer):\n        serializer = Serializer(self._infer_class_models())\n        return serializer._serialize(self, key_transformer=key_transformer, keep_readonly=keep_readonly)", "response": "Return a dict that can be JSONified using json. dump."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef deserialize(cls, data, content_type=None):\n        deserializer = Deserializer(cls._infer_class_models())\n        return deserializer(cls.__name__, data, content_type=content_type)", "response": "Parse a str using the RestAPI syntax and return a model."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse a dict using given key extractor return a model.", "response": "def from_dict(cls, data, key_extractors=None, content_type=None):\n        \"\"\"Parse a dict using given key extractor return a model.\n\n        By default consider key\n        extractors (rest_key_case_insensitive_extractor, attribute_key_case_insensitive_extractor\n        and last_rest_key_case_insensitive_extractor)\n\n        :param dict data: A dict using RestAPI structure\n        :param str content_type: JSON by default, set application/xml if XML.\n        :returns: An instance of this model\n        :raises: DeserializationError if something went wrong\n        \"\"\"\n        deserializer = Deserializer(cls._infer_class_models())\n        deserializer.key_extractors = [\n            rest_key_case_insensitive_extractor,\n            attribute_key_case_insensitive_extractor,\n            last_rest_key_case_insensitive_extractor\n        ] if key_extractors is None else key_extractors\n        return deserializer(cls.__name__, data, content_type=content_type)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck the class _subtype_map for any child classes. We want to ignore any inherited _subtype_maps. Remove the polymorphic key from the initial data.", "response": "def _classify(cls, response, objects):\n        \"\"\"Check the class _subtype_map for any child classes.\n        We want to ignore any inherited _subtype_maps.\n        Remove the polymorphic key from the initial data.\n        \"\"\"\n        for subtype_key in cls.__dict__.get('_subtype_map', {}).keys():\n            subtype_value = None\n\n            rest_api_response_key = cls._get_rest_key_parts(subtype_key)[-1]\n            subtype_value = response.pop(rest_api_response_key, None) or response.pop(subtype_key, None)\n            if subtype_value:\n                # Try to match base class. Can be class name only\n                # (bug to fix in Autorest to support x-ms-discriminator-name)\n                if cls.__name__ == subtype_value:\n                    return cls\n                flatten_mapping_type = cls._flatten_subtype(subtype_key, objects)\n                try:\n                    return objects[flatten_mapping_type[subtype_value]]\n                except KeyError:\n                    _LOGGER.warning(\n                        \"Subtype value %s has no mapping, use base class %s.\",\n                        subtype_value,\n                        cls.__name__,\n                    )\n                    break\n            else:\n                _LOGGER.warning(\n                    \"Discriminator %s is absent or null, use base class %s.\",\n                    subtype_key,\n                    cls.__name__\n                )\n                break\n        return cls"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_rest_key_parts(cls, attr_key):\n        rest_split_key = _FLATTEN.split(cls._attribute_map[attr_key]['key'])\n        return [_decode_attribute_map_key(key_part) for key_part in rest_split_key]", "response": "Get the RestAPI key of this attr split it and decode part\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _serialize(self, target_obj, data_type=None, **kwargs):\n        key_transformer = kwargs.get(\"key_transformer\", self.key_transformer)\n        keep_readonly = kwargs.get(\"keep_readonly\", False)\n        if target_obj is None:\n            return None\n\n        attr_name = None\n        class_name = target_obj.__class__.__name__\n\n        if data_type:\n            return self.serialize_data(\n                target_obj, data_type, **kwargs)\n\n        if not hasattr(target_obj, \"_attribute_map\"):\n            data_type = type(target_obj).__name__\n            if data_type in self.basic_types.values():\n                return self.serialize_data(\n                    target_obj, data_type, **kwargs)\n\n        # Force \"is_xml\" kwargs if we detect a XML model\n        try:\n            is_xml_model_serialization = kwargs[\"is_xml\"]\n        except KeyError:\n            is_xml_model_serialization = kwargs.setdefault(\"is_xml\", target_obj.is_xml_model())\n\n        serialized = self._create_serialized_base(target_obj)  # Could be JSON or XML\n        try:\n            attributes = target_obj._attribute_map\n            for attr, attr_desc in attributes.items():\n                attr_name = attr\n                if not keep_readonly and target_obj._validation.get(attr_name, {}).get('readonly', False):\n                    continue\n\n                if attr_name == \"additional_properties\" and attr_desc[\"key\"] == '':\n                    if target_obj.additional_properties is not None:\n                        serialized.update(target_obj.additional_properties)\n                    continue\n                try:\n                    ### Extract sub-data to serialize from model ###\n                    orig_attr = getattr(target_obj, attr)\n                    if target_obj.is_xml_model():\n                        pass # Don't provide \"transformer\" for XML for now. Keep \"orig_attr\"\n                    else: # JSON\n                        keys, orig_attr = key_transformer(attr, attr_desc.copy(), orig_attr)\n                        keys = keys if isinstance(keys, list) else [keys]\n\n                    ### Serialize this data ###\n                    kwargs[\"serialization_ctxt\"] = attr_desc\n                    new_attr = self.serialize_data(orig_attr, attr_desc['type'], **kwargs)\n\n                    ### Incorporate this data in the right place ###\n                    if is_xml_model_serialization:\n                        xml_desc = attr_desc['xml']\n                        xml_name = xml_desc['name']\n                        if \"attr\" in xml_desc and xml_desc[\"attr\"]:\n                            serialized.set(xml_name, new_attr)\n                            continue\n                        if isinstance(new_attr, list):\n                            serialized.extend(new_attr)\n                        elif isinstance(new_attr, ET.Element):\n                            # If the down XML has no XML/Name, we MUST replace the tag with the local tag. But keeping the namespaces.\n                            if 'name' not in getattr(orig_attr, '_xml_map', {}):\n                                splitted_tag = new_attr.tag.split(\"}\")\n                                if len(splitted_tag) == 2: # Namespace\n                                    new_attr.tag = \"}\".join([splitted_tag[0], xml_name])\n                                else:\n                                    new_attr.tag = xml_name\n                            serialized.append(new_attr)\n                        else:  # That's a basic type\n                            # Integrate namespace if necessary\n                            local_node = _create_xml_node(\n                                xml_name,\n                                xml_desc.get('prefix', None),\n                                xml_desc.get('ns', None)\n                            )\n                            local_node.text = str(new_attr)\n                            serialized.append(local_node)\n                    else: # JSON\n                        for k in reversed(keys):\n                            unflattened = {k: new_attr}\n                            new_attr = unflattened\n\n                        _new_attr = new_attr\n                        _serialized = serialized\n                        for k in keys:\n                            if k not in _serialized:\n                                _serialized.update(_new_attr)\n                            _new_attr = _new_attr[k]\n                            _serialized = _serialized[k]\n                except ValueError:\n                    continue\n\n        except (AttributeError, KeyError, TypeError) as err:\n            msg = \"Attribute {} in object {} cannot be serialized.\\n{}\".format(\n                attr_name, class_name, str(target_obj))\n            raise_with_traceback(SerializationError, msg, err)\n        else:\n            return serialized", "response": "Serialize data into a string according to type."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef body(self, data, data_type, **kwargs):\n        if data is None:\n            raise ValidationError(\"required\", \"body\", True)\n\n        # Just in case this is a dict\n        internal_data_type = data_type.strip('[]{}')\n        internal_data_type = self.dependencies.get(internal_data_type, None)\n        if internal_data_type and not isinstance(internal_data_type, Enum):\n            try:\n                deserializer = Deserializer(self.dependencies)\n                # Since it's on serialization, it's almost sure that format is not JSON REST\n                # We're not able to deal with additional properties for now.\n                deserializer.additional_properties_detection = False\n                if issubclass(internal_data_type, Model) and internal_data_type.is_xml_model():\n                    deserializer.key_extractors = [\n                        attribute_key_case_insensitive_extractor,\n                    ]\n                else:\n                    deserializer.key_extractors = [\n                        rest_key_case_insensitive_extractor,\n                        attribute_key_case_insensitive_extractor,\n                        last_rest_key_case_insensitive_extractor\n                    ]\n                data = deserializer._deserialize(data_type, data)\n            except DeserializationError as err:\n                raise_with_traceback(\n                    SerializationError, \"Unable to build a model: \"+str(err), err)\n\n        if self.client_side_validation:\n            errors = _recursive_validate(data_type, data_type, data)\n            if errors:\n                raise errors[0]\n        return self._serialize(data, data_type, **kwargs)", "response": "Serialize data intended for a request body."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef url(self, name, data, data_type, **kwargs):\n        if self.client_side_validation:\n            data = self.validate(data, name, required=True, **kwargs)\n        try:\n            output = self.serialize_data(data, data_type, **kwargs)\n            if data_type == 'bool':\n                output = json.dumps(output)\n\n            if kwargs.get('skip_quote') is True:\n                output = str(output)\n            else:\n                output = quote(str(output), safe='')\n        except SerializationError:\n            raise TypeError(\"{} must be type {}.\".format(name, data_type))\n        else:\n            return output", "response": "Serialize data intended for a URL path."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nserializes data intended for a request header.", "response": "def header(self, name, data, data_type, **kwargs):\n        \"\"\"Serialize data intended for a request header.\n\n        :param data: The data to be serialized.\n        :param str data_type: The type to be serialized from.\n        :rtype: str\n        :raises: TypeError if serialization fails.\n        :raises: ValueError if data is None\n        \"\"\"\n        if self.client_side_validation:\n            data = self.validate(data, name, required=True, **kwargs)\n        try:\n            if data_type in ['[str]']:\n                data = [\"\" if d is None else d for d in data]\n\n            output = self.serialize_data(data, data_type, **kwargs)\n            if data_type == 'bool':\n                output = json.dumps(output)\n        except SerializationError:\n            raise TypeError(\"{} must be type {}.\".format(name, data_type))\n        else:\n            return str(output)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nvalidates that a piece of data meets certain conditions", "response": "def validate(cls, data, name, **kwargs):\n        \"\"\"Validate that a piece of data meets certain conditions\"\"\"\n        required = kwargs.get('required', False)\n        if required and data is None:\n            raise ValidationError(\"required\", name, True)\n        elif data is None:\n            return\n        elif kwargs.get('readonly'):\n            return\n\n        try:\n            for key, value in kwargs.items():\n                validator = cls.validation.get(key, lambda x, y: False)\n                if validator(data, value):\n                    raise ValidationError(key, name, value)\n        except TypeError:\n            raise ValidationError(\"unknown\", name, \"unknown\")\n        else:\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef serialize_data(self, data, data_type, **kwargs):\n        if data is None:\n            raise ValueError(\"No value for given attribute\")\n\n        try:\n            if data_type in self.basic_types.values():\n                return self.serialize_basic(data, data_type, **kwargs)\n\n            elif data_type in self.serialize_type:\n                return self.serialize_type[data_type](data, **kwargs)\n\n            # If dependencies is empty, try with current data class\n            # It has to be a subclass of Enum anyway\n            enum_type = self.dependencies.get(data_type, data.__class__)\n            if issubclass(enum_type, Enum):\n                return Serializer.serialize_enum(data, enum_obj=enum_type)\n\n            iter_type = data_type[0] + data_type[-1]\n            if iter_type in self.serialize_type:\n                return self.serialize_type[iter_type](\n                    data, data_type[1:-1], **kwargs)\n\n        except (ValueError, TypeError) as err:\n            msg = \"Unable to serialize value: {!r} as type: {!r}.\"\n            raise_with_traceback(\n                SerializationError, msg.format(data, data_type), err)\n        else:\n            return self._serialize(data, **kwargs)", "response": "Serialize generic data according to supplied data type."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef serialize_basic(self, data, data_type, **kwargs):\n        custom_serializer = self._get_custom_serializers(data_type, **kwargs)\n        if custom_serializer:\n            return custom_serializer(data)\n        if data_type == 'str':\n            return self.serialize_unicode(data)\n        return eval(data_type)(data)", "response": "Serialize basic builting data type."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef serialize_unicode(self, data):\n        try:\n            return data.value\n        except AttributeError:\n            pass\n        try:\n            if isinstance(data, unicode):\n                return data.encode(encoding='utf-8')\n        except NameError:\n            return str(data)\n        else:\n            return str(data)", "response": "Special handling for serializing unicode strings in Py2."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef serialize_iter(self, data, iter_type, div=None, **kwargs):\n        if isinstance(data, str):\n            raise SerializationError(\"Refuse str type as a valid iter type.\")\n\n        serialization_ctxt = kwargs.get(\"serialization_ctxt\", {})\n\n        serialized = []\n        for d in data:\n            try:\n                serialized.append(self.serialize_data(d, iter_type, **kwargs))\n            except ValueError:\n                serialized.append(None)\n\n        if div:\n            serialized = ['' if s is None else str(s) for s in serialized]\n            serialized = div.join(serialized)\n\n        if 'xml' in serialization_ctxt:\n            # XML serialization is more complicated\n            xml_desc = serialization_ctxt['xml']\n            xml_name = xml_desc['name']\n\n            # Create a wrap node if necessary (use the fact that Element and list have \"append\")\n            is_wrapped = \"wrapped\" in xml_desc and xml_desc[\"wrapped\"]\n            node_name = xml_desc.get(\"itemsName\", xml_name)\n            if is_wrapped:\n                final_result = _create_xml_node(\n                    xml_name,\n                    xml_desc.get('prefix', None),\n                    xml_desc.get('ns', None)\n                )\n            else:\n                final_result = []\n            # All list elements to \"local_node\"\n            for el in serialized:\n                if isinstance(el, ET.Element):\n                    el_node = el\n                else:\n                    el_node = _create_xml_node(\n                        node_name,\n                        xml_desc.get('prefix', None),\n                        xml_desc.get('ns', None)\n                    )\n                    if el is not None:  # Otherwise it writes \"None\" :-p\n                        el_node.text = str(el)\n                final_result.append(el_node)\n            return final_result\n        return serialized", "response": "Serialize an iterable of objects into a list of strings."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef serialize_dict(self, attr, dict_type, **kwargs):\n        serialization_ctxt = kwargs.get(\"serialization_ctxt\", {})\n        serialized = {}\n        for key, value in attr.items():\n            try:\n                serialized[self.serialize_unicode(key)] = self.serialize_data(\n                    value, dict_type, **kwargs)\n            except ValueError:\n                serialized[self.serialize_unicode(key)] = None\n\n        if 'xml' in serialization_ctxt:\n            # XML serialization is more complicated\n            xml_desc = serialization_ctxt['xml']\n            xml_name = xml_desc['name']\n\n            final_result = _create_xml_node(\n                xml_name,\n                xml_desc.get('prefix', None),\n                xml_desc.get('ns', None)\n            )\n            for key, value in serialized.items():\n                ET.SubElement(final_result, key).text = value\n            return final_result\n\n        return serialized", "response": "Serialize a dictionary of objects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nserializing a generic object.", "response": "def serialize_object(self, attr, **kwargs):\n        \"\"\"Serialize a generic object.\n        This will be handled as a dictionary. If object passed in is not\n        a basic type (str, int, float, dict, list) it will simply be\n        cast to str.\n\n        :param dict attr: Object to be serialized.\n        :rtype: dict or str\n        \"\"\"\n        if attr is None:\n            return None\n        if isinstance(attr, ET.Element):\n            return attr\n        obj_type = type(attr)\n        if obj_type in self.basic_types:\n            return self.serialize_basic(attr, self.basic_types[obj_type], **kwargs)\n        if obj_type is _long_type:\n            return self.serialize_long(attr)\n\n        # If it's a model or I know this dependency, serialize as a Model\n        elif obj_type in self.dependencies.values() or isinstance(obj_type, Model):\n            return self._serialize(attr)\n\n        if obj_type == dict:\n            serialized = {}\n            for key, value in attr.items():\n                try:\n                    serialized[self.serialize_unicode(key)] = self.serialize_object(\n                        value, **kwargs)\n                except ValueError:\n                    serialized[self.serialize_unicode(key)] = None\n            return serialized\n\n        if obj_type == list:\n            serialized = []\n            for obj in attr:\n                try:\n                    serialized.append(self.serialize_object(\n                        obj, **kwargs))\n                except ValueError:\n                    pass\n            return serialized\n        return str(attr)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef serialize_base64(attr, **kwargs):\n        encoded = b64encode(attr).decode('ascii')\n        return encoded.strip('=').replace('+', '-').replace('/', '_')", "response": "Serialize str into base - 64 string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nserialize a date object into ISO - 8601 formatted string.", "response": "def serialize_date(attr, **kwargs):\n        \"\"\"Serialize Date object into ISO-8601 formatted string.\n\n        :param Date attr: Object to be serialized.\n        :rtype: str\n        \"\"\"\n        if isinstance(attr, str):\n            attr = isodate.parse_date(attr)\n        t = \"{:04}-{:02}-{:02}\".format(attr.year, attr.month, attr.day)\n        return t"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef serialize_duration(attr, **kwargs):\n        if isinstance(attr, str):\n            attr = isodate.parse_duration(attr)\n        return isodate.duration_isoformat(attr)", "response": "Serialize TimeDelta object into ISO - 8601 formatted string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nserializing Datetime object into RFC - 3123 formatted string.", "response": "def serialize_rfc(attr, **kwargs):\n        \"\"\"Serialize Datetime object into RFC-1123 formatted string.\n\n        :param Datetime attr: Object to be serialized.\n        :rtype: str\n        :raises: TypeError if format invalid.\n        \"\"\"\n        try:\n            if not attr.tzinfo:\n                _LOGGER.warning(\n                    \"Datetime with no tzinfo will be considered UTC.\")\n            utc = attr.utctimetuple()\n        except AttributeError:\n            raise TypeError(\"RFC1123 object must be valid Datetime object.\")\n\n        return \"{}, {:02} {} {:04} {:02}:{:02}:{:02} GMT\".format(\n            Serializer.days[utc.tm_wday], utc.tm_mday,\n            Serializer.months[utc.tm_mon], utc.tm_year,\n            utc.tm_hour, utc.tm_min, utc.tm_sec)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef serialize_iso(attr, **kwargs):\n        if isinstance(attr, str):\n            attr = isodate.parse_datetime(attr)\n        try:\n            if not attr.tzinfo:\n                _LOGGER.warning(\n                    \"Datetime with no tzinfo will be considered UTC.\")\n            utc = attr.utctimetuple()\n            if utc.tm_year > 9999 or utc.tm_year < 1:\n                raise OverflowError(\"Hit max or min date\")\n\n            microseconds = str(attr.microsecond).rjust(6,'0').rstrip('0').ljust(3, '0')\n            if microseconds:\n                microseconds = '.'+microseconds\n            date = \"{:04}-{:02}-{:02}T{:02}:{:02}:{:02}\".format(\n                utc.tm_year, utc.tm_mon, utc.tm_mday,\n                utc.tm_hour, utc.tm_min, utc.tm_sec)\n            return date + microseconds + 'Z'\n        except (ValueError, OverflowError) as err:\n            msg = \"Unable to serialize datetime object.\"\n            raise_with_traceback(SerializationError, msg, err)\n        except AttributeError as err:\n            msg = \"ISO-8601 object must be valid Datetime object.\"\n            raise_with_traceback(TypeError, msg, err)", "response": "Serialize Datetime object into ISO - 8601 formatted string."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nserialize Datetime object into IntTime format.", "response": "def serialize_unix(attr, **kwargs):\n        \"\"\"Serialize Datetime object into IntTime format.\n        This is represented as seconds.\n\n        :param Datetime attr: Object to be serialized.\n        :rtype: int\n        :raises: SerializationError if format invalid\n        \"\"\"\n        if isinstance(attr, int):\n            return attr\n        try:\n            if not attr.tzinfo:\n                _LOGGER.warning(\n                    \"Datetime with no tzinfo will be considered UTC.\")\n            return int(calendar.timegm(attr.utctimetuple()))\n        except AttributeError:\n            raise TypeError(\"Unix time object must be valid Datetime object.\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalling the deserializer on a model. Data needs to be already deserialized as JSON or XML ElementTree :param str target_obj: Target data type to deserialize to. :param object data: Object to deserialize. :raises: DeserializationError if deserialization fails. :return: Deserialized object.", "response": "def _deserialize(self, target_obj, data):\n        \"\"\"Call the deserializer on a model.\n\n        Data needs to be already deserialized as JSON or XML ElementTree\n\n        :param str target_obj: Target data type to deserialize to.\n        :param object data: Object to deserialize.\n        :raises: DeserializationError if deserialization fails.\n        :return: Deserialized object.\n        \"\"\"\n        # This is already a model, go recursive just in case\n        if hasattr(data, \"_attribute_map\"):\n            constants = [name for name, config in getattr(data, '_validation', {}).items()\n                         if config.get('constant')]\n            try:\n                for attr, mapconfig in data._attribute_map.items():\n                    if attr in constants:\n                        continue\n                    value = getattr(data, attr)\n                    if value is None:\n                        continue\n                    local_type = mapconfig['type']\n                    internal_data_type = local_type.strip('[]{}')\n                    if internal_data_type not in self.dependencies or isinstance(internal_data_type, Enum):\n                        continue\n                    setattr(\n                        data,\n                        attr,\n                        self._deserialize(local_type, value)\n                    )\n                return data\n            except AttributeError:\n                return\n\n        response, class_name = self._classify_target(target_obj, data)\n\n        if isinstance(response, basestring):\n            return self.deserialize_data(data, response)\n        elif isinstance(response, type) and issubclass(response, Enum):\n            return self.deserialize_enum(data, response)\n\n        if data is None:\n            return data\n        try:\n            attributes = response._attribute_map\n            d_attrs = {}\n            for attr, attr_desc in attributes.items():\n                # Check empty string. If it's not empty, someone has a real \"additionalProperties\"...\n                if attr == \"additional_properties\" and attr_desc[\"key\"] == '':\n                    continue\n                raw_value = None\n                # Enhance attr_desc with some dynamic data\n                attr_desc = attr_desc.copy() # Do a copy, do not change the real one\n                internal_data_type = attr_desc[\"type\"].strip('[]{}')\n                if internal_data_type in self.dependencies:\n                    attr_desc[\"internalType\"] = self.dependencies[internal_data_type]\n\n                for key_extractor in self.key_extractors:\n                    found_value = key_extractor(attr, attr_desc, data)\n                    if found_value is not None:\n                        if raw_value is not None and raw_value != found_value:\n                            raise KeyError('Use twice the key: \"{}\"'.format(attr))\n                        raw_value = found_value\n\n                value = self.deserialize_data(raw_value, attr_desc['type'])\n                d_attrs[attr] = value\n        except (AttributeError, TypeError, KeyError) as err:\n            msg = \"Unable to deserialize to object: \" + class_name\n            raise_with_traceback(DeserializationError, msg, err)\n        else:\n            additional_properties = self._build_additional_properties(attributes, data)\n            return self._instantiate_model(response, d_attrs, additional_properties)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _classify_target(self, target, data):\n        if target is None:\n            return None, None\n\n        if isinstance(target, basestring):\n            try:\n                target = self.dependencies[target]\n            except KeyError:\n                return target, target\n\n        try:\n            target = target._classify(data, self.dependencies)\n        except AttributeError:\n            pass  # Target is not a Model, no classify\n        return target, target.__class__.__name__", "response": "Classify the target object into a subclass of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _unpack_content(raw_data, content_type=None):\n        # This avoids a circular dependency. We might want to consider RawDesializer is more generic\n        # than the pipeline concept, and put it in a toolbox, used both here and in pipeline. TBD.\n        from .pipeline.universal import RawDeserializer\n\n        # Assume this is enough to detect a Pipeline Response without importing it\n        context = getattr(raw_data, \"context\", {})\n        if context:\n            if RawDeserializer.CONTEXT_NAME in context:\n                return context[RawDeserializer.CONTEXT_NAME]\n            raise ValueError(\"This pipeline didn't have the RawDeserializer policy; can't deserialize\")\n\n        #Assume this is enough to recognize universal_http.ClientResponse without importing it\n        if hasattr(raw_data, \"body\"):\n            return RawDeserializer.deserialize_from_http_generics(\n                raw_data.text(),\n                raw_data.headers\n            )\n\n        # Assume this enough to recognize requests.Response without importing it.\n        if hasattr(raw_data, '_content_consumed'):\n            return RawDeserializer.deserialize_from_http_generics(\n                raw_data.text,\n                raw_data.headers\n            )\n\n        if isinstance(raw_data, (basestring, bytes)) or hasattr(raw_data, 'read'):\n            return RawDeserializer.deserialize_from_text(raw_data, content_type)\n        return raw_data", "response": "Unpacks the raw_data into a dict with the key as the key and the value as the value."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprocess data for deserialization according to data type.", "response": "def deserialize_data(self, data, data_type):\n        \"\"\"Process data for deserialization according to data type.\n\n        :param str data: The response string to be deserialized.\n        :param str data_type: The type to deserialize to.\n        :raises: DeserializationError if deserialization fails.\n        :return: Deserialized object.\n        \"\"\"\n        if data is None:\n            return data\n\n        try:\n            if not data_type:\n                return data\n            if data_type in self.basic_types.values():\n                return self.deserialize_basic(data, data_type)\n            if data_type in self.deserialize_type:\n                if isinstance(data, self.deserialize_expected_types.get(data_type, tuple())):\n                    return data\n\n                is_a_text_parsing_type = lambda x: x not in [\"object\", \"[]\", r\"{}\"]\n                if isinstance(data, ET.Element) and is_a_text_parsing_type(data_type) and not data.text:\n                    return None\n                data_val = self.deserialize_type[data_type](data)\n                return data_val\n\n            iter_type = data_type[0] + data_type[-1]\n            if iter_type in self.deserialize_type:\n                return self.deserialize_type[iter_type](data, data_type[1:-1])\n\n            obj_type = self.dependencies[data_type]\n            if issubclass(obj_type, Enum):\n                if isinstance(data, ET.Element):\n                    data = data.text\n                return self.deserialize_enum(data, obj_type)\n\n        except (ValueError, TypeError, AttributeError) as err:\n            msg = \"Unable to deserialize response data.\"\n            msg += \" Data: {}, {}\".format(data, data_type)\n            raise_with_traceback(DeserializationError, msg, err)\n        else:\n            return self._deserialize(obj_type, data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef deserialize_dict(self, attr, dict_type):\n        if isinstance(attr, list):\n            return {x['key']: self.deserialize_data(x['value'], dict_type) for x in attr}\n\n        if isinstance(attr, ET.Element):\n            # Transform <Key>value</Key> into {\"Key\": \"value\"}\n            attr = {el.tag: el.text for el in attr}\n        return {k: self.deserialize_data(v, dict_type) for k, v in attr.items()}", "response": "Deserialize a dictionary.\n\n        :param dict/list attr: Dictionary to be deserialized. Also accepts\n         a list of key, value pairs.\n        :param str dict_type: The object type of the items in the dictionary.\n        :rtype: dict"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef deserialize_object(self, attr, **kwargs):\n        if attr is None:\n            return None\n        if isinstance(attr, ET.Element):\n            # Do no recurse on XML, just return the tree as-is\n            return attr\n        if isinstance(attr, basestring):\n            return self.deserialize_basic(attr, 'str')\n        obj_type = type(attr)\n        if obj_type in self.basic_types:\n            return self.deserialize_basic(attr, self.basic_types[obj_type])\n        if obj_type is _long_type:\n            return self.deserialize_long(attr)\n\n        if obj_type == dict:\n            deserialized = {}\n            for key, value in attr.items():\n                try:\n                    deserialized[key] = self.deserialize_object(\n                        value, **kwargs)\n                except ValueError:\n                    deserialized[key] = None\n            return deserialized\n\n        if obj_type == list:\n            deserialized = []\n            for obj in attr:\n                try:\n                    deserialized.append(self.deserialize_object(\n                        obj, **kwargs))\n                except ValueError:\n                    pass\n            return deserialized\n\n        else:\n            error = \"Cannot deserialize generic object with type: \"\n            raise TypeError(error + str(obj_type))", "response": "Deserializes a generic object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef deserialize_basic(self, attr, data_type):\n        # If we're here, data is supposed to be a basic type.\n        # If it's still an XML node, take the text\n        if isinstance(attr, ET.Element):\n            attr = attr.text\n            if not attr:\n                if data_type == \"str\":\n                    # None or '', node <a/> is empty string.\n                    return ''\n                else:\n                    # None or '', node <a/> with a strong type is None.\n                    # Don't try to model \"empty bool\" or \"empty int\"\n                    return None\n\n        if data_type == 'bool':\n            if attr in [True, False, 1, 0]:\n                return bool(attr)\n            elif isinstance(attr, basestring):\n                if attr.lower() in ['true', '1']:\n                    return True\n                elif attr.lower() in ['false', '0']:\n                    return False\n            raise TypeError(\"Invalid boolean value: {}\".format(attr))\n\n        if data_type == 'str':\n            return self.deserialize_unicode(attr)\n        return eval(data_type)(attr)", "response": "Deserializes a basic baisc builtin data type from string."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npreserves unicode objects in Python 2 otherwise return data as a string.", "response": "def deserialize_unicode(data):\n        \"\"\"Preserve unicode objects in Python 2, otherwise return data\n        as a string.\n\n        :param str data: response string to be deserialized.\n        :rtype: str or unicode\n        \"\"\"\n        # We might be here because we have an enum modeled as string,\n        # and we try to deserialize a partial dict with enum inside\n        if isinstance(data, Enum):\n            return data\n\n        # Consider this is real string\n        try:\n            if isinstance(data, unicode):\n                return data\n        except NameError:\n            return str(data)\n        else:\n            return str(data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef deserialize_decimal(attr):\n        if isinstance(attr, ET.Element):\n            attr = attr.text\n        try:\n            return decimal.Decimal(attr)\n        except decimal.DecimalException as err:\n            msg = \"Invalid decimal {}\".format(attr)\n            raise_with_traceback(DeserializationError, msg, err)", "response": "Deserialize string into Decimal object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef deserialize_long(attr):\n        if isinstance(attr, ET.Element):\n            attr = attr.text\n        return _long_type(attr)", "response": "Deserialize string into long or int."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef deserialize_duration(attr):\n        if isinstance(attr, ET.Element):\n            attr = attr.text\n        try:\n            duration = isodate.parse_duration(attr)\n        except(ValueError, OverflowError, AttributeError) as err:\n            msg = \"Cannot deserialize duration object.\"\n            raise_with_traceback(DeserializationError, msg, err)\n        else:\n            return duration", "response": "Deserialize ISO - 8601 formatted string into TimeDelta object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef deserialize_rfc(attr):\n        if isinstance(attr, ET.Element):\n            attr = attr.text\n        try:\n            date_obj = datetime.datetime.strptime(\n                attr, \"%a, %d %b %Y %H:%M:%S %Z\")\n            if not date_obj.tzinfo:\n                date_obj = date_obj.replace(tzinfo=TZ_UTC)\n        except ValueError as err:\n            msg = \"Cannot deserialize to rfc datetime object.\"\n            raise_with_traceback(DeserializationError, msg, err)\n        else:\n            return date_obj", "response": "Deserialize RFC - 3339 formatted string into Datetime object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef deserialize_iso(attr):\n        if isinstance(attr, ET.Element):\n            attr = attr.text\n        try:\n            attr = attr.upper()\n            match = Deserializer.valid_date.match(attr)\n            if not match:\n                raise ValueError(\"Invalid datetime string: \" + attr)\n\n            check_decimal = attr.split('.')\n            if len(check_decimal) > 1:\n                decimal_str = \"\"\n                for digit in check_decimal[1]:\n                    if digit.isdigit():\n                        decimal_str += digit\n                    else:\n                        break\n                if len(decimal_str) > 6:\n                    attr = attr.replace(decimal_str, decimal_str[0:6])\n\n            date_obj = isodate.parse_datetime(attr)\n            test_utc = date_obj.utctimetuple()\n            if test_utc.tm_year > 9999 or test_utc.tm_year < 1:\n                raise OverflowError(\"Hit max or min date\")\n        except(ValueError, OverflowError, AttributeError) as err:\n            msg = \"Cannot deserialize datetime object.\"\n            raise_with_traceback(DeserializationError, msg, err)\n        else:\n            return date_obj", "response": "Deserialize ISO - 8601 formatted string into Datetime object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef deserialize_unix(attr):\n        if isinstance(attr, ET.Element):\n            attr = int(attr.text)\n        try:\n            date_obj = datetime.datetime.fromtimestamp(attr, TZ_UTC)\n        except ValueError as err:\n            msg = \"Cannot deserialize to unix datetime object.\"\n            raise_with_traceback(DeserializationError, msg, err)\n        else:\n            return date_obj", "response": "Serialize Datetime object into IntTime format."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef raw(self):\n        # type: () -> ClientRawResponse\n        \"\"\"Get current page as ClientRawResponse.\n\n        :rtype: ClientRawResponse\n        \"\"\"\n        raw = ClientRawResponse(self.current_page, self._response)\n        if self._raw_headers:\n            raw.add_headers(self._raw_headers)\n        return raw", "response": "Get current page as ClientRawResponse."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(self, url):\n        # type: (str) -> List[Model]\n        \"\"\"Get an arbitrary page.\n\n        This resets the iterator and then fully consumes it to return the\n        specific page **only**.\n\n        :param str url: URL to arbitrary page results.\n        \"\"\"\n        self.reset()\n        self.next_link = url\n        return self.advance_page()", "response": "Get an arbitrary page."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef advance_page(self):\n        # type: () -> List[Model]\n        \"\"\"Force moving the cursor to the next azure call.\n\n        This method is for advanced usage, iterator protocol is prefered.\n\n        :raises: StopIteration if no further page\n        :return: The current page list\n        :rtype: list\n        \"\"\"\n        if self.next_link is None:\n            raise StopIteration(\"End of paging\")\n        self._current_page_iter_index = 0\n        self._response = self._get_next(self.next_link)\n        self._derserializer(self, self._response)\n        return self.current_page", "response": "Force moving the cursor to the next azure call."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsending the request according to configuration.", "response": "async def send(self, request: Request, **kwargs) -> Response:\n        \"\"\"Send request object according to configuration.\n\n        :param Request request: The request object to be sent.\n        \"\"\"\n        if request.context is None:  # Should not happen, but make mypy happy and does not hurt\n            request.context = self.build_context()\n\n        if request.context.session is not self.driver.session:\n            kwargs['session'] = request.context.session\n\n        return Response(\n            request,\n            await self.driver.send(request.http_request, **kwargs)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _ensureAtomicity(fn):\n    @ensureScoopStartedProperly\n    def wrapper(*args, **kwargs):\n        \"\"\"setConst(**kwargs)\n        Set a constant that will be shared to every workers.\n        This call blocks until the constant has propagated to at least one\n        worker.\n\n        :param \\*\\*kwargs: One or more combination(s) key=value. Key being the\n            variable name and value the object to share.\n\n        :returns: None.\n\n        Usage: setConst(name=value)\n        \"\"\"\n        # Note that the docstring is the one of setConst.\n        # This is because of the documentation framework (sphinx) limitations.\n\n        from . import _control\n\n        # Enforce retrieval of currently awaiting constants\n        _control.execQueue.socket.pumpInfoSocket()\n\n        for key, value in kwargs.items():\n            # Object name existence check\n            if key in itertools.chain(*(elem.keys() for elem in elements.values())):\n                raise TypeError(\"This constant already exists: {0}.\".format(key))\n\n        # Retry element propagation until it is returned\n        while all(key in elements.get(scoop.worker, []) for key in kwargs.keys()) is not True:\n            scoop.logger.debug(\"Sending global variables {0}...\".format(\n                list(kwargs.keys())\n            ))\n            # Call the function\n            fn(*args, **kwargs)\n\n            # Enforce retrieval of currently awaiting constants\n            _control.execQueue.socket.pumpInfoSocket()\n\n            # TODO: Make previous blocking instead of sleep\n            time.sleep(0.1)\n\n        # Atomicity check\n        elementNames = list(itertools.chain(*(elem.keys() for elem in elements.values())))\n        if len(elementNames) != len(set(elementNames)):\n            raise TypeError(\"This constant already exists: {0}.\".format(key))\n\n    return wrapper", "response": "Decorator that ensures atomicity of passed elements on the whole worker pool."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset a constant that will be shared to every worker.", "response": "def setConst(**kwargs):\n    \"\"\"setConst(**kwargs)\n    Set a constant that will be shared to every workers.\n\n    :param **kwargs: One or more combination(s) key=value. Key being the\n        variable name and value the object to share.\n\n    :returns: None.\n\n    Usage: setConst(name=value)\n    \"\"\"\n    from . import _control\n    \n    sendVariable = _control.execQueue.socket.sendVariable\n\n    for key, value in kwargs.items():\n        # Propagate the constant\n        # for file-like objects, see encapsulation.py where copyreg was\n        # used to overload standard pickling.\n        if callable(value):\n            sendVariable(key, encapsulation.FunctionEncapsulation(value, key))\n        else:\n            sendVariable(key, value)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getConst(name, timeout=0.1):\n    from . import _control\n    import time\n\n    timeStamp = time.time()\n    while True:\n        # Enforce retrieval of currently awaiting constants\n        _control.execQueue.socket.pumpInfoSocket()\n\n        # Constants concatenation\n        constants = dict(reduce(\n            lambda x, y: x + list(y.items()),\n            elements.values(),\n            []\n        ))\n        timeoutHappened = time.time() - timeStamp > timeout\n        if constants.get(name) is not None or timeoutHappened:\n            return constants.get(name)\n        time.sleep(0.01)", "response": "Get a shared constant."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getArgs():\n    try:\n        nb_to_launch = int(sys.argv[1])\n    except:\n        nb_to_launch = 0\n\n    if nb_to_launch == 0:\n        nb_to_launch = getCPUcount()\n\n    try:\n        verbosity = int(sys.argv[2])\n    except:\n        verbosity = 3\n\n    return nb_to_launch, verbosity, sys.argv[3:]", "response": "Gets the arguments of the program."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlaunch the bootstrap instances in separate subprocesses", "response": "def launchBootstraps():\n    \"\"\"Launch the bootstrap instances in separate subprocesses\"\"\"\n    global processes\n    worker_amount, verbosity, args = getArgs()\n    was_origin = False\n\n    if verbosity >= 1:\n        sys.stderr.write(\"Launching {0} worker(s) using {1}.\\n\".format(\n                worker_amount,\n                os.environ['SHELL'] if 'SHELL' in os.environ else \"an unknown shell\",\n            )\n        )\n        sys.stderr.flush()\n\n    processes = []\n    for _ in range(worker_amount):\n        command = [sys.executable, \"-m\", BOOTSTRAP_MODULE] + args\n        if verbosity >= 3:\n            sys.stderr.write(\"Executing '{0}'...\\n\".format(command))\n            sys.stderr.flush()\n        processes.append(Popen(command))\n\n        # Only have a single origin\n        try:\n            args.remove(\"--origin\")\n        except ValueError:\n            pass\n        else:\n            was_origin = True\n\n    if was_origin:\n        # Only wait on the origin, this will return and notify the launcher\n        # the the job has finished and start the cleanup phase\n        try:\n            processes[0].wait()\n        except KeyboardInterrupt:\n            pass\n    else:\n        for p in processes:\n            p.wait()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nresolve strings to objects using standard import and attribute syntax.", "response": "def resolve(self, s):\n        \"\"\"\n        Resolve strings to objects using standard import and attribute\n        syntax.\n        \"\"\"\n        name = s.split('.')\n        used = name.pop(0)\n        try:\n            found = self.importer(used)\n            for frag in name:\n                used += '.' + frag\n                try:\n                    found = getattr(found, frag)\n                except AttributeError:\n                    self.importer(used)\n                    found = getattr(found, frag)\n            return found\n        except ImportError:\n            e, tb = sys.exc_info()[1:]\n            v = ValueError('Cannot resolve %r: %s' % (s, e))\n            v.__cause__, v.__traceback__ = e, tb\n            raise v"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconfiguring the logging module.", "response": "def configure(self):\n        \"\"\"Do the configuration.\"\"\"\n\n        config = self.config\n        if 'version' not in config:\n            raise ValueError(\"dictionary doesn't specify a version\")\n        if config['version'] != 1:\n            raise ValueError(\"Unsupported version: %s\" % config['version'])\n        incremental = config.pop('incremental', False)\n        EMPTY_DICT = {}\n        logging._acquireLock()\n        try:\n            if incremental:\n                handlers = config.get('handlers', EMPTY_DICT)\n                # incremental handler config only if handler name\n                # ties in to logging._handlers (Python 2.7)\n                if sys.version_info[:2] == (2, 7):\n                    for name in handlers:\n                        if name not in logging._handlers:\n                            raise ValueError('No handler found with '\n                                             'name %r'  % name)\n                        else:\n                            try:\n                                handler = logging._handlers[name]\n                                handler_config = handlers[name]\n                                level = handler_config.get('level', None)\n                                if level:\n                                    handler.setLevel(_checkLevel(level))\n                            except StandardError, e:\n                                raise ValueError('Unable to configure handler '\n                                                 '%r: %s' % (name, e))\n                loggers = config.get('loggers', EMPTY_DICT)\n                for name in loggers:\n                    try:\n                        self.configure_logger(name, loggers[name], True)\n                    except StandardError, e:\n                        raise ValueError('Unable to configure logger '\n                                         '%r: %s' % (name, e))\n                root = config.get('root', None)\n                if root:\n                    try:\n                        self.configure_root(root, True)\n                    except StandardError, e:\n                        raise ValueError('Unable to configure root '\n                                         'logger: %s' % e)\n            else:\n                disable_existing = config.pop('disable_existing_loggers', True)\n                \n                logging._handlers.clear()\n                del logging._handlerList[:]\n                    \n                # Do formatters first - they don't refer to anything else\n                formatters = config.get('formatters', EMPTY_DICT)\n                for name in formatters:\n                    try:\n                        formatters[name] = self.configure_formatter(\n                                                            formatters[name])\n                    except StandardError, e:\n                        raise ValueError('Unable to configure '\n                                         'formatter %r: %s' % (name, e))\n                # Next, do filters - they don't refer to anything else, either\n                filters = config.get('filters', EMPTY_DICT)\n                for name in filters:\n                    try:\n                        filters[name] = self.configure_filter(filters[name])\n                    except StandardError, e:\n                        raise ValueError('Unable to configure '\n                                         'filter %r: %s' % (name, e))\n\n                # Next, do handlers - they refer to formatters and filters\n                # As handlers can refer to other handlers, sort the keys\n                # to allow a deterministic order of configuration\n                handlers = config.get('handlers', EMPTY_DICT)\n                for name in sorted(handlers):\n                    try:\n                        handler = self.configure_handler(handlers[name])\n                        handler.name = name\n                        handlers[name] = handler\n                    except StandardError, e:\n                        raise ValueError('Unable to configure handler '\n                                         '%r: %s' % (name, e))\n                # Next, do loggers - they refer to handlers and filters\n                \n                #we don't want to lose the existing loggers,\n                #since other threads may have pointers to them.\n                #existing is set to contain all existing loggers,\n                #and as we go through the new configuration we\n                #remove any which are configured. At the end,\n                #what's left in existing is the set of loggers\n                #which were in the previous configuration but\n                #which are not in the new configuration.\n                root = logging.root\n                existing = root.manager.loggerDict.keys()\n                #The list needs to be sorted so that we can\n                #avoid disabling child loggers of explicitly\n                #named loggers. With a sorted list it is easier\n                #to find the child loggers.\n                existing.sort()\n                #We'll keep the list of existing loggers\n                #which are children of named loggers here...\n                child_loggers = []\n                #now set up the new ones...\n                loggers = config.get('loggers', EMPTY_DICT)\n                for name in loggers:\n                    if name in existing:\n                        i = existing.index(name)\n                        prefixed = name + \".\"\n                        pflen = len(prefixed)\n                        num_existing = len(existing)\n                        i = i + 1 # look at the entry after name\n                        while (i < num_existing) and\\\n                              (existing[i][:pflen] == prefixed):\n                            child_loggers.append(existing[i])\n                            i = i + 1\n                        existing.remove(name)\n                    try:\n                        self.configure_logger(name, loggers[name])\n                    except StandardError, e:\n                        raise ValueError('Unable to configure logger '\n                                         '%r: %s' % (name, e))\n                    \n                #Disable any old loggers. There's no point deleting\n                #them as other threads may continue to hold references\n                #and by disabling them, you stop them doing any logging.\n                #However, don't disable children of named loggers, as that's\n                #probably not what was intended by the user.\n                for log in existing:\n                    logger = root.manager.loggerDict[log]\n                    if log in child_loggers:\n                        logger.level = logging.NOTSET\n                        logger.handlers = []\n                        logger.propagate = True\n                    elif disable_existing:\n                        logger.disabled = True\n    \n                # And finally, do the root logger\n                root = config.get('root', None)\n                if root:\n                    try:\n                        self.configure_root(root)                        \n                    except StandardError, e:\n                        raise ValueError('Unable to configure root '\n                                         'logger: %s' % e)\n        finally:\n            logging._releaseLock()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef configure_formatter(self, config):\n        if '()' in config:\n            factory = config['()'] # for use in exception handler\n            try:\n                result = self.configure_custom(config)\n            except TypeError, te:\n                if \"'format'\" not in str(te):\n                    raise\n                #Name of parameter changed from fmt to format.\n                #Retry with old name.\n                #This is so that code can be used with older Python versions\n                #(e.g. by Django)\n                config['fmt'] = config.pop('format')\n                config['()'] = factory\n                result = self.configure_custom(config)\n        else:\n            fmt = config.get('format', None)\n            dfmt = config.get('datefmt', None)\n            result = logging.Formatter(fmt, dfmt)\n        return result", "response": "Configure a formatter from a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef configure_filter(self, config):\n        if '()' in config:\n            result = self.configure_custom(config)\n        else:\n            name = config.get('name', '')\n            result = logging.Filter(name)\n        return result", "response": "Configure a filter from a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconfiguring a non - root logger from a dictionary.", "response": "def configure_logger(self, name, config, incremental=False):\n        \"\"\"Configure a non-root logger from a dictionary.\"\"\"\n        logger = logging.getLogger(name)\n        self.common_logger_config(logger, config, incremental)\n        propagate = config.get('propagate', None)\n        if propagate is not None:\n            logger.propagate = propagate"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef configure_root(self, config, incremental=False):\n        root = logging.getLogger()\n        self.common_logger_config(root, config, incremental)", "response": "Configure a root logger from a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndivide the received image in multiple tiles", "response": "def sliceImage(image, divWidth, divHeight):\n    \"\"\"Divide the received image in multiple tiles\"\"\"\n    w, h = image.size\n    tiles = []\n    for y in range(0, h - 1 , h/divHeight):\n        my = min(y + h/divHeight, h)\n        for x in range(0, w - 1, w/divWidth):\n            mx = min(x + w/divWidth, w)\n            tiles.append(image.crop((x, y, mx, my)))\n    return tiles"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef resizeTile(index, size):\n    resized = tiles[index].resize(size, Image.ANTIALIAS)\n    return sImage(resized.tostring(), resized.size, resized.mode)", "response": "Apply Antialiasing resizing to tile"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef externalHostname(hosts):\n    hostname = hosts[0][0]\n    if hostname in localHostnames and len(hosts) > 1:\n        hostname = socket.getfqdn().split(\".\")[0]\n        try:\n            socket.getaddrinfo(hostname, None)\n        except socket.gaierror:\n            raise Exception(\"\\nThe first host (containing a broker) is not\"\n                            \" routable.\\nMake sure the address is correct.\")\n    return hostname", "response": "Ensure external hostname is routable."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of hosts depending on the environment", "response": "def getHosts(filename=None, hostlist=None):\n    \"\"\"Return a list of hosts depending on the environment\"\"\"\n    if filename:\n        return getHostsFromFile(filename)\n    elif hostlist:\n        return getHostsFromList(hostlist)\n    elif getEnv() == \"SLURM\":\n        return getHostsFromSLURM()\n    elif getEnv() == \"PBS\":\n        return getHostsFromPBS()\n    elif getEnv() == \"SGE\":\n        return getHostsFromSGE()\n    else:\n        return getDefaultHosts()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing a file to return a list of hosts.", "response": "def getHostsFromFile(filename):\n    \"\"\"Parse a file to return a list of hosts.\"\"\"\n    valid_hostname = r\"^[^ /\\t=\\n]+\"\n    workers = r\"\\d+\"\n    hostname_re = re.compile(valid_hostname)\n    worker_re = re.compile(workers)\n    hosts = []\n    with open(filename) as f:\n        for line in f:\n            # check to see if it is a SLURM grouping instead of a\n            # regular list of hosts\n            if re.search('[\\[\\]]', line):\n                hosts = hosts + parseSLURM(line.strip())\n            else:\n                host = hostname_re.search(line.strip())\n                if host:\n                    hostname = host.group()\n                    n = worker_re.search(line[host.end():])\n                    if n:\n                        n = n.group()\n                    else:\n                        # Automatically assign based on CPU count\n                        n = 0\n                    hosts.append((hostname, int(n)))\n    return hosts"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getHostsFromList(hostlist):\n    # check to see if it is a SLURM grouping instead of a\n    # regular list of hosts\n    if any(re.search('[\\[\\]]', x) for x in hostlist):\n        return parseSLURM(str(hostlist))\n\n    # Counter would be more efficient but:\n    # 1. Won't be Python 2.6 compatible\n    # 2. Won't be ordered\n    hostlist = groupTogether(hostlist)\n    retVal = []\n    for key, group in groupby(hostlist):\n        retVal.append((key, len(list(group))))\n    return retVal", "response": "Return the hosts from the command line"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a host list from a SLURM string", "response": "def parseSLURM(string):\n    \"\"\"Return a host list from a SLURM string\"\"\"\n    # Use scontrol utility to get the hosts list\n    import subprocess, os\n    hostsstr = subprocess.check_output([\"scontrol\", \"show\", \"hostnames\", string])\n    if sys.version_info.major > 2:\n        hostsstr = hostsstr.decode()\n    # Split using endline\n    hosts = hostsstr.split(os.linesep)\n    # Take out last empty host\n    hosts = filter(None, hosts)\n    # Create the desired pair of host and number of hosts\n    hosts = [(host, 1) for host in hosts]\n    return hosts"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of hosts in a PBS environment", "response": "def getHostsFromPBS():\n    \"\"\"Return a host list in a PBS environment\"\"\"\n    # See above comment about Counter\n    with open(os.environ[\"PBS_NODEFILE\"], 'r') as hosts:\n        hostlist = groupTogether(hosts.read().split())\n        retVal = []\n        for key, group in groupby(hostlist):\n            retVal.append((key, len(list(group))))\n        return retVal"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of hosts in a SGE environment", "response": "def getHostsFromSGE():\n    \"\"\"Return a host list in a SGE environment\"\"\"\n    with open(os.environ[\"PE_HOSTFILE\"], 'r') as hosts:\n        return [(host.split()[0], int(host.split()[1])) for host in hosts]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getWorkerQte(hosts):\n    if \"SLURM_NTASKS\" in os.environ:\n        return int(os.environ[\"SLURM_NTASKS\"])\n    elif \"PBS_NP\" in os.environ:\n        return int(os.environ[\"PBS_NP\"])\n    elif \"NSLOTS\" in os.environ:\n        return int(os.environ[\"NSLOTS\"])\n    else:\n        return sum(host[1] for host in hosts)", "response": "Return the number of workers to launch depending on the environment"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a function at runtime using binary compiled inCode name defaults globals_ and imports.", "response": "def functionFactory(in_code, name, defaults, globals_, imports):\n    \"\"\"Creates a function at runtime using binary compiled inCode\"\"\"\n    def generatedFunction():\n        pass\n    generatedFunction.__code__ = marshal.loads(in_code)\n    generatedFunction.__name__ = name\n    generatedFunction.__defaults = defaults\n    generatedFunction.__globals__.update(pickle.loads(globals_))\n    for key, value in imports.items():\n        imported_module = __import__(value)\n        scoop.logger.debug(\"Dynamically loaded module {0}\".format(value))\n        generatedFunction.__globals__.update({key: imported_module})\n    return generatedFunction"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntaking input lambda function l and makes it picklable.", "response": "def makeLambdaPicklable(lambda_function):\n    \"\"\"Take input lambda function l and makes it picklable.\"\"\"\n    if isinstance(lambda_function,\n                  type(lambda: None)) and lambda_function.__name__ == '<lambda>':\n        def __reduce_ex__(proto):\n            # TODO: argdefs, closure\n            return unpickleLambda, (marshal.dumps(lambda_function.__code__), )\n        lambda_function.__reduce_ex__ = __reduce_ex__\n    return lambda_function"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getFunction(self):\n        return functionFactory(\n            self.code,\n            self.name,\n            self.defaults,\n            self.globals,\n            self.imports,\n        )", "response": "Called by remote workers. Useful to populate main module globals (\n            self. globals"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites the current object to a temporary file.", "response": "def writeFile(self, directory=None):\n        \"\"\"Writes back the file to a temporary path (optionaly specified)\"\"\"\n        if directory:\n            # If a directory was specified\n            full_path = os.path.join(directory, self.filename)\n            with open(full_path, 'wb') as f:\n                f.write(pickle.loads(self.data).read())\n            return full_path\n\n        # if no directory was specified, create a temporary file\n        this_file = tempfile.NamedTemporaryFile(delete=False)\n        this_file.write(pickle.loads(self.data).read())\n        this_file.close()\n\n        return this_file.name"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a connector between wire1 and wire2 in the network.", "response": "def addConnector(self, wire1, wire2):\n        \"\"\"Add a connector between wire1 and wire2 in the network.\"\"\"\n        if wire1 == wire2:\n            return\n        \n        if wire1 > wire2:\n            wire1, wire2 = wire2, wire1\n        \n        try:\n            last_level = self[-1]\n        except IndexError:\n            # Empty network, create new level and connector\n            self.append([(wire1, wire2)])\n            return\n        \n        for wires in last_level:\n            if wires[1] >= wire1 and wires[0] <= wire2:\n                self.append([(wire1, wire2)])\n                return\n        \n        last_level.append((wire1, wire2))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sort(self, values):\n        for level in self:\n            for wire1, wire2 in level:\n                if values[wire1] > values[wire2]:\n                    values[wire1], values[wire2] = values[wire2], values[wire1]", "response": "Sort the values in - place based on the connectors in the network."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntrying to sort the possible cases using the network return the number of misses.", "response": "def assess(self, cases=None):\n        \"\"\"Try to sort the **cases** using the network, return the number of\n        misses. If **cases** is None, test all possible cases according to\n        the network dimensionality.\n        \"\"\"\n        if cases is None:\n            cases = product(range(2), repeat=self.dimension)\n        \n        misses = 0\n        ordered = [[0]*(self.dimension-i) + [1]*i for i in range(self.dimension+1)]\n        for sequence in cases:\n            sequence = list(sequence)\n            self.sort(sequence)\n            misses += (sequence != ordered[sum(sequence)])\n        return misses"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef draw(self):\n        str_wires = [[\"-\"]*7 * self.depth]\n        str_wires[0][0] = \"0\"\n        str_wires[0][1] = \" o\"\n        str_spaces = []\n\n        for i in range(1, self.dimension):\n            str_wires.append([\"-\"]*7 * self.depth)\n            str_spaces.append([\" \"]*7 * self.depth)\n            str_wires[i][0] = str(i)\n            str_wires[i][1] = \" o\"\n        \n        for index, level in enumerate(self):\n            for wire1, wire2 in level:\n                str_wires[wire1][(index+1)*6] = \"x\"\n                str_wires[wire2][(index+1)*6] = \"x\"\n                for i in range(wire1, wire2):\n                    str_spaces[i][(index+1)*6+1] = \"|\"\n                for i in range(wire1+1, wire2):\n                    str_wires[i][(index+1)*6] = \"|\"\n        \n        network_draw = \"\".join(str_wires[0])\n        for line, space in zip(str_wires[1:], str_spaces):\n            network_draw += \"\\n\"\n            network_draw += \"\".join(space)\n            network_draw += \"\\n\"\n            network_draw += \"\".join(line)\n        return network_draw", "response": "Return an ASCII representation of the network."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the list of the names of the workers sorted alphabetically", "response": "def getWorkersName(data):\n    \"\"\"Returns the list of the names of the workers sorted alphabetically\"\"\"\n    names = [fichier for fichier in data.keys()]\n    names.sort()\n    try:\n        names.remove(\"broker\")\n    except ValueError:\n        pass\n    return names"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef importData(directory):\n    dataTask = OrderedDict()\n    dataQueue = OrderedDict()\n    for fichier in sorted(os.listdir(directory)):\n        try:\n            with open(\"{directory}/{fichier}\".format(**locals()), 'rb') as f:\n                fileName, fileType = fichier.rsplit('-', 1)\n                if fileType == \"QUEUE\":\n                    dataQueue[fileName] = pickle.load(f)\n                else:\n                    dataTask[fileName] = pickle.load(f)\n        except:\n            # Can be a directory\n            pass\n    return dataTask, dataQueue", "response": "Parse the input files and return two dictionnaries"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getTimes(dataTasks):\n    global begin_time\n    start_time, end_time = float('inf'), 0\n    for fichier, vals in dataTask.items():\n        try:\n            if hasattr(vals, 'values'):\n                tmp_start_time = min([a['start_time'] for a in vals.values()])[0]\n                if tmp_start_time < start_time:\n                    start_time = tmp_start_time\n                tmp_end_time = max([a['end_time'] for a in vals.values()])[0]\n                if tmp_end_time > end_time:\n                    end_time = tmp_end_time\n        except ValueError:\n            continue\n    begin_time = 1000 * start_time\n    return 1000 * start_time, 1000 * end_time", "response": "Get the start time and end time of data in milliseconds"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the worker density data for the graph.", "response": "def WorkersDensity(dataTasks):\n    \"\"\"Return the worker density data for the graph.\"\"\"\n\n    start_time, end_time = getTimes(dataTasks)\n    graphdata = []\n\n    for name in getWorkersName(dataTasks):\n        vals = dataTasks[name]\n        if hasattr(vals, 'values'):\n            # Data from worker\n            workerdata = []\n            print(\"Plotting density map for {}\".format(name))\n            # We only have 800 pixels\n            try:\n                for graphtime in timeRange(start_time, end_time, DENSITY_MAP_TIME_AXIS_LENGTH):\n                    for a in vals.values():\n                        if not all((a['start_time'], a['end_time'])):\n                            print(\"Invalid data:\", a['start_time'], a['end_time'])\n                        #print(a['start_time'], a['end_time'])\n                    workerdata.append(sum([a['start_time'][0] <= float(graphtime) /\n                        1000. <= a['end_time'][0] for a in vals.values()\n                            if a['start_time'] and a['end_time']])\n                    )\n            except OverflowError:\n                print(\"Error processing {0} or {1}\".format(start_time, end_time))\n            graphdata.append(workerdata)\n\n            if args.binarydensity:\n                # Normalize [...]\n                maxval = max(graphdata[-1])\n                if maxval > 1:\n                    maxval = maxval - 1\n                    graphdata[-1] = [x - maxval for x in graphdata[-1]]\n    return graphdata"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef plotDensity(dataTask, filename):\n\n    #def format_worker(x, pos=None):\n    #    \"\"\"Formats the worker name\"\"\"\n    #    #workers = filter (lambda a: a[:6] != \"broker\", dataTask.keys())\n    #    workers = [a for a in dataTask.keys() if a[:6] != \"broker\"]\n    #    return workers[x]\n\n    def format_time(x, pos=None):\n        \"\"\"Formats the time\"\"\"\n        start_time, end_time = [(a - begin_time) / 1000 for a in getTimes(dataTask)]\n        return int(end_time * x / DENSITY_MAP_TIME_AXIS_LENGTH)\n\n    graphdata = WorkersDensity(dataTask)\n    if len(graphdata):\n        fig = plt.figure()\n        ax = fig.add_subplot(111)\n        box = ax.get_position()\n        ax.set_position([box.x0 + 0.15 * box.width, box.y0, box.width, box.height])\n        #cax = ax.imshow(graphdata, interpolation='nearest', aspect='auto')\n        if args.binarydensity:\n            cmap = ListedColormap(['r', 'g'])\n            norm = BoundaryNorm([0, 0.5, 1], cmap.N)\n            cax = ax.imshow(graphdata, interpolation='nearest', aspect='auto', cmap=cmap, norm=norm)\n        else:\n            cax = ax.imshow(graphdata, interpolation='nearest', aspect='auto')\n        plt.xlabel('time (s)'); plt.ylabel('Worker'); ax.set_title('Work density')\n        ax.yaxis.set_ticks(range(len(graphdata)))\n        ax.tick_params(axis='both', which='major', labelsize=6)\n        #ax.yaxis.set_major_formatter(ticker.FuncFormatter(format_worker))\n        interval_size = DENSITY_MAP_TIME_AXIS_LENGTH // 4\n        ax.xaxis.set_ticks(range(0,\n                                 DENSITY_MAP_TIME_AXIS_LENGTH + interval_size,\n                                 interval_size))\n        ax.xaxis.set_major_formatter(ticker.FuncFormatter(format_time))\n        if args.binarydensity:\n            cax.set_clim(0, 1)\n            cbar = fig.colorbar(cax, ticks=[0, 1])\n        else:\n            cbar = fig.colorbar(cax)\n        fig.savefig(filename)", "response": "Plot the worker density graph for the given dataTask."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef plotBrokerQueue(dataTask, filename):\n    print(\"Plotting broker queue length for {0}.\".format(filename))\n    plt.figure()\n\n    # Queue length\n    plt.subplot(211)\n    for fichier, vals in dataTask.items():\n        if type(vals) == list:\n            timestamps = list(map(datetime.fromtimestamp, map(int, list(zip(*vals))[0])))\n            # Data is from broker\n            plt.plot_date(timestamps, list(zip(*vals))[2],\n                          linewidth=1.0,\n                          marker='o',\n                          markersize=2,\n                          label=fichier)\n    plt.title('Broker queue length')\n    plt.ylabel('Tasks')\n\n    # Requests received\n    plt.subplot(212)\n    for fichier, vals in dataTask.items():\n        if type(vals) == list:\n            timestamps = list(map(datetime.fromtimestamp, map(int, list(zip(*vals))[0])))\n            # Data is from broker\n            plt.plot_date(timestamps, list(zip(*vals))[3],\n                          linewidth=1.0,\n                          marker='o',\n                          markersize=2,\n                          label=fichier)\n    plt.title('Broker pending requests')\n    plt.xlabel('time (s)')\n    plt.ylabel('Requests')\n\n    plt.savefig(filename)", "response": "Generates the broker queue length graphic."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getWorkerInfo(dataTask):\n    workertime = []\n    workertasks = []\n    for fichier, vals in dataTask.items():\n        if hasattr(vals, 'values'):\n            #workers_names.append(fichier)\n            # Data from worker\n            totaltime = sum([a['executionTime'] for a in vals.values()])\n            totaltasks = sum([1 for a in vals.values()])\n            workertime.append(totaltime)\n            workertasks.append(totaltasks)\n    return workertime, workertasks", "response": "Returns the total execution time and task quantity by worker"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef timelines(fig, y, xstart, xstop, color='b'):\n    fig.hlines(y, xstart, xstop, color, lw=4)\n    fig.vlines(xstart, y+0.03, y-0.03, color, lw=2)\n    fig.vlines(xstop, y+0.03, y-0.03, color, lw=2)", "response": "Plot timelines at y from xstart to xstop with given color."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nplot a timeline of the dataTask.", "response": "def plotTimeline(dataTask, filename):\n    \"\"\"Build a timeline\"\"\"\n\n    fig = plt.figure()\n    ax = fig.gca()\n\n    worker_names = [x for x in dataTask.keys() if \"broker\" not in x]\n\n    min_time = getMinimumTime(dataTask)\n    ystep = 1. / (len(worker_names) + 1)\n\n    y = 0\n    for worker, vals in dataTask.items():\n        if \"broker\" in worker:\n            continue\n        y += ystep\n        if hasattr(vals, 'values'):\n            for future in vals.values():\n                start_time = [future['start_time'][0] - min_time]\n                end_time = [future['end_time'][0] - min_time]\n                timelines(ax, y, start_time, end_time)\n\n    #ax.xaxis_date()\n    #myFmt = DateFormatter('%H:%M:%S')\n    #ax.xaxis.set_major_formatter(myFmt)\n    #ax.xaxis.set_major_locator(SecondLocator(0, interval=20))\n\n    #delta = (stop.max() - start.min())/10\n    ax.set_yticks(np.arange(ystep, 1, ystep))\n    ax.set_yticklabels(worker_names)\n    ax.set_ylim(0, 1)\n    #fig.xlim()\n    ax.set_xlabel('Time')\n    fig.savefig(filename)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstart an advertiser thread.", "response": "def Advertise(port, stype=\"SCOOP\", sname=\"Broker\", advertisername=\"Broker\",\n              location=\"\"):\n    \"\"\"\n    stype = always SCOOP\n    port = comma separated ports\n    sname = broker unique name\n    location = routable location (ip or dns)\n    \"\"\"\n    scoop.logger.info(\"Launching advertiser...\")\n    service = minusconf.Service(stype, port, sname, location)\n    advertiser = minusconf.ThreadAdvertiser([service], advertisername)\n    advertiser.start()\n    scoop.logger.info(\"Advertiser launched.\")\n\n    return advertiser"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a worker assignation Arguments and order to pass are advised.", "response": "def setWorker(self, *args, **kwargs):\n        \"\"\"Add a worker assignation\n            Arguments and order to pass are defined in LAUNCHING_ARGUMENTS\n            Using named args is advised.\n        \"\"\"\n        try:\n            la = self.LAUNCHING_ARGUMENTS(*args, **kwargs)\n        except TypeError as e:\n            scoop.logger.error((\"addWorker failed to convert args %s and kwargs %s \"\n                            \"to namedtuple (requires %s arguments (names %s)\") %\n                            (args, kwargs, len(self.LAUNCHING_ARGUMENTS._fields),\n                             self.LAUNCHING_ARGUMENTS._fields))\n\n        self.workersArguments = la"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning list of shell commands to prepare the environment for bootstrap.", "response": "def _WorkerCommand_environment(self):\n        \"\"\"Return list of shell commands to prepare the environment for\n           bootstrap.\"\"\"\n        worker = self.workersArguments\n        c = []\n        if worker.prolog:\n            c.extend([\n                \"source\",\n                worker.prolog,\n                \"&&\",\n            ])\n        if worker.pythonPath and not self.isLocal():\n            # Tried to make it compliant to all shell variants.\n            c.extend([\n                \"env\",\n                \"PYTHONPATH={0}:$PYTHONPATH\".format(worker.pythonPath),\n            ])\n        elif worker.pythonPath and self.isLocal():\n            # Tried to make it compliant to all shell variants.\n            c.extend([\n                \"env\",\n                \"PYTHONPATH={0}:{1}\".format(\n                    worker.pythonPath,\n                    os.environ.get(\"PYTHONPATH\", \"\"),\n                ),\n            ])\n        return c"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _WorkerCommand_launcher(self):\n        return [\n            self.workersArguments.pythonExecutable,\n            '-m',\n            'scoop.launch.__main__',\n            str(self.workerAmount),\n            str(self.workersArguments.verbose),\n        ]", "response": "Return list of commands to start the bootstrap process"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _WorkerCommand_options(self):\n        worker = self.workersArguments\n        c = []\n\n        # If broker is on localhost\n        if self.hostname == worker.brokerHostname:\n            broker = \"127.0.0.1\"\n        else:\n            broker = worker.brokerHostname\n\n        if worker.nice is not None:\n            c.extend(['--nice', str(worker.nice)])\n        c.extend(['--size', str(worker.size)])\n        if self.isLocal():\n            c.extend(['--workingDirectory', str(worker.path)])\n        else:\n            c.extend(['--workingDirectory', '\"{0}\"'.format(str(worker.path))])\n        c.extend(['--brokerHostname', broker])\n        c.extend(['--externalBrokerHostname', worker.brokerHostname])\n        c.extend(['--taskPort', str(worker.brokerPorts[0])])\n        c.extend(['--metaPort', str(worker.brokerPorts[1])])\n        if worker.origin and worker.executable:\n            c.append('--origin')\n        if worker.debug:\n            c.append('--debug')\n        if worker.profiling:\n            c.append('--profile')\n        if worker.backend:\n            c.append('--backend={0}'.format(worker.backend))\n        if worker.verbose >= 1:\n            c.append('-' + 'v' * worker.verbose)\n        return c", "response": "Return list of options for bootstrap"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns executable and any options to be executed by bootstrap", "response": "def _WorkerCommand_executable(self):\n        \"\"\"Return executable and any options to be executed by bootstrap\"\"\"\n        worker = self.workersArguments\n\n        c = []\n        if worker.executable:\n            c.append(worker.executable)\n        # This trick is used to parse correctly quotes\n        # (ie. myScript.py 'arg1 \"arg2\" arg3')\n        # Because it is parsed by a shell, every quote gets re-interpreted.\n        # It replaces simple quotation marks with \\\\\\\" which gets evaluated to\n        # \\\" by the second shell which prints it out as a double quote.\n        if worker.args:\n            if self.isLocal():\n                # If local, no shell is used so no escaping needed\n                c.extend([\n                    '{0}'.format(a) for a in worker.args\n                ])\n            else:\n                c.extend([\n                    '\"{0}\"'.format(a.replace('\"', '\\\\\\\"')) for a in worker.args\n                ])\n        return c"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate the workerCommand as list", "response": "def _getWorkerCommandList(self):\n        \"\"\"Generate the workerCommand as list\"\"\"\n        c = []\n        c.extend(self._WorkerCommand_environment())\n        c.extend(self._WorkerCommand_launcher())\n        c.extend(self._WorkerCommand_options())\n        c.extend(self._WorkerCommand_executable())\n\n        return c"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlaunches every worker assigned on this host.", "response": "def launch(self, tunnelPorts=None):\n        \"\"\"Launch every worker assigned on this host.\"\"\"\n        if self.isLocal():\n            # Launching local workers\n            c = self._getWorkerCommandList()\n            self.subprocesses.append(subprocess.Popen(c))\n        else:\n            # Launching remotely\n            BASE_SSH[0] = self.ssh_executable\n            sshCmd = BASE_SSH if not self.rsh else BASE_RSH\n            if tunnelPorts is not None:\n                sshCmd += [\n                    '-R {0}:127.0.0.1:{0}'.format(tunnelPorts[0]),\n                    '-R {0}:127.0.0.1:{0}'.format(tunnelPorts[1]),\n                ]\n            self.subprocesses.append(\n                subprocess.Popen(sshCmd + [self.hostname, self.getCommand()],\n                                 bufsize=-1,\n                                 stdout=None,\n                                 stderr=None,\n                                 stdin=subprocess.PIPE\n                )\n            )\n\n        return self.subprocesses"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef close(self):\n        # Ensure everything is cleaned up on exit\n        scoop.logger.debug('Closing workers on {0}.'.format(self))\n\n        # Terminate subprocesses\n        for process in self.subprocesses:\n            try:\n                process.terminate()\n            except OSError:\n                pass", "response": "Close all processes and processes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nswitching the current object to the given object.", "response": "def _switch(self, future):\n        \"\"\"Switch greenlet.\"\"\"\n        scoop._control.current = self\n        assert self.greenlet is not None, (\"No greenlet to switch to:\"\n                                           \"\\n{0}\".format(self.__dict__))\n        return self.greenlet.switch(future)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cancel(self):\n        if self in scoop._control.execQueue.movable:\n            self.exceptionValue = CancelledError()\n            scoop._control.futureDict[self.id]._delete()\n            scoop._control.execQueue.remove(self)\n            return True\n        return False", "response": "Cancels the current call."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if the call was successfully cancelled False otherwise.", "response": "def done(self):\n        \"\"\"Returns True if the call was successfully cancelled or finished\n           running, False otherwise. This function updates the executionQueue\n           so it receives all the awaiting message.\"\"\"\n        # Flush the current future in the local buffer (potential deadlock\n        # otherwise)\n        try:\n            scoop._control.execQueue.remove(self)\n            scoop._control.execQueue.socket.sendFuture(self)\n        except ValueError as e:\n            # Future was not in the local queue, everything is fine\n            pass\n        # Process buffers\n        scoop._control.execQueue.updateQueue()\n        return self._ended()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef result(self, timeout=None):\n        if not self._ended():\n            return scoop.futures._join(self)\n        if self.exceptionValue is not None:\n            raise self.exceptionValue\n        return self.resultValue", "response": "Return the value returned by the call."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_done_callback(self, callable_,\n                          inCallbackType=CallbackType.standard,\n                          inCallbackGroup=None):\n        \"\"\"Attach a callable to the future that will be called when the future\n        is cancelled or finishes running. Callable will be called with the\n        future as its only argument.\n\n        Added callables are called in the order that they were added and are\n        always called in a thread belonging to the process that added them. If\n        the callable raises an Exception then it will be logged and ignored. If\n        the callable raises another BaseException then behavior is not defined.\n\n        If the future has already completed or been cancelled then callable will\n        be called immediately.\"\"\"\n        self.callback.append(callbackEntry(callable_,\n                                           inCallbackType,\n                                           inCallbackGroup))\n\n        # If already completed or cancelled, execute it immediately\n        if self._ended():\n            self.callback[-1].func(self)", "response": "Attach a callable to the future that will be called when the future is done."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nappending a future to the queue.", "response": "def append(self, future):\n        \"\"\"Append a future to the queue.\"\"\"\n        if future._ended() and future.index is None:\n            self.inprogress.add(future)\n        elif future._ended() and future.index is not None:\n            self.ready.append(future)\n        elif future.greenlet is not None:\n            self.inprogress.add(future)\n        else:\n            self.movable.append(future)\n\n            # Send the oldest future in the movable deque until under the hwm\n            over_hwm = self.timelen(self.movable) > self.highwatermark\n            while over_hwm and len(self.movable) > 1:\n                sending_future = self.movable.popleft()\n                if sending_future.id[0] != scoop.worker:\n                    sending_future._delete()\n                self.socket.sendFuture(sending_future)\n                over_hwm = self.timelen(self.movable) > self.highwatermark"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef askForPreviousFutures(self):\n        # Don't request it too often (otherwise it ping-pongs because)\n        # the broker answer triggers the _poll of pop()\n        if time.time() < self.lastStatus + POLLING_TIME / 1000:\n            return\n        self.lastStatus = time.time()\n\n        for future in scoop._control.futureDict.values():\n            # Skip the root future\n            if scoop.IS_ORIGIN and future.id == (scoop.worker, 0):\n                continue\n\n            if future not in self.inprogress:\n                self.socket.sendStatusRequest(future)", "response": "Ask for the previous futures to the broker."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npop the next future from the queue ; return it ;", "response": "def pop(self):\n        \"\"\"Pop the next future from the queue;\n        in progress futures have priority over those that have not yet started;\n        higher level futures have priority over lower level ones; \"\"\"\n        self.updateQueue()\n\n        # If our buffer is underflowing, request more Futures\n        if self.timelen(self) < self.lowwatermark:\n            self.requestFuture()\n\n        # If an unmovable Future is ready to be executed, return it\n        if len(self.ready) != 0:\n            return self.ready.popleft()\n\n        # Then, use Futures in the movable queue\n        elif len(self.movable) != 0:\n            return self.movable.popleft()\n        else:\n            # Otherwise, block until a new task arrives\n            self.lastStatus = time.time()\n            while len(self) == 0:\n                # Block until message arrives\n                self.askForPreviousFutures()\n                self.socket._poll(POLLING_TIME)\n                self.updateQueue()\n            if len(self.ready) != 0:\n                return self.ready.popleft()\n            elif len(self.movable) != 0:\n                return self.movable.popleft()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef flush(self):\n        for elem in self:\n            if elem.id[0] != scoop.worker:\n                elem._delete()\n            self.socket.sendFuture(elem)\n        self.ready.clear()\n        self.movable.clear()", "response": "Empty the local queue and send its elements remotely."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprocesses inbound communication buffer. Updates the local queue with elements from the broker.", "response": "def updateQueue(self):\n        \"\"\"Process inbound communication buffer.\n        Updates the local queue with elements from the broker.\"\"\"\n        for future in self.socket.recvFuture():\n            if future._ended():\n                # If the answer is coming back, update its entry\n                try:\n                    thisFuture = scoop._control.futureDict[future.id]\n                except KeyError:\n                    # Already received?\n                    scoop.logger.warn('{0}: Received an unexpected future: '\n                                      '{1}'.format(scoop.worker, future.id))\n                    continue\n                thisFuture.resultValue = future.resultValue\n                thisFuture.exceptionValue = future.exceptionValue\n                thisFuture.executor = future.executor\n                thisFuture.isDone = future.isDone\n                # Execute standard callbacks here (on parent)\n                thisFuture._execute_callbacks(CallbackType.standard)\n                self.append(thisFuture)\n                future._delete()\n            elif future.id not in scoop._control.futureDict:\n                scoop._control.futureDict[future.id] = future\n                self.append(scoop._control.futureDict[future.id])\n            else:\n                self.append(scoop._control.futureDict[future.id])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sendResult(self, future):\n        # Greenlets cannot be pickled\n        future.greenlet = None\n        assert future._ended(), \"The results are not valid\"\n        self.socket.sendResult(future)", "response": "Send back the result of the task to broker for distribution to parent task."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nredirect the stdout and stderr of the current process to a file.", "response": "def redirectSTDOUTtoDebugFile():\n    \"\"\"Redirects the stdout and stderr of the current process to a file.\"\"\"\n    import sys\n    kwargs = {}\n    if sys.version_info >= (3,):\n        kwargs[\"encoding\"] = \"utf8\"\n    sys.stdout = open(\n        os.path.join(\n            getDebugDirectory(),\n            \"{0}.stdout\".format(getDebugIdentifier()),\n        ),\n        \"w\",\n        1, # Buffering by line\n        **kwargs\n    )\n    sys.stderr = open(\n        os.path.join(\n            getDebugDirectory(),\n            \"{0}.stderr\".format(getDebugIdentifier()),\n        ),\n        \"w\",\n        1, # Buffering by line\n        **kwargs\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nserialize the execution data using pickle and writes it into the debug directory.", "response": "def writeWorkerDebug(debugStats, queueLength, path_suffix=\"\"):\n    \"\"\"Serialize the execution data using pickle and writes it into the debug\n    directory.\"\"\"\n    createDirectory(path_suffix)\n    origin_prefix = \"origin-\" if scoop.IS_ORIGIN else \"\"\n    statsFilename = os.path.join(\n        getDebugDirectory(),\n        path_suffix,\n        \"{1}worker-{0}-STATS\".format(getDebugIdentifier(), origin_prefix)\n    )\n    lengthFilename = os.path.join(\n        getDebugDirectory(),\n        path_suffix,\n        \"{1}worker-{0}-QUEUE\".format(getDebugIdentifier(), origin_prefix)\n    )\n    with open(statsFilename, 'wb') as f:\n        pickle.dump(debugStats, f)\n    with open(lengthFilename, 'wb') as f:\n        pickle.dump(queueLength, f)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating the SCOOP module arguments parser.", "response": "def makeParser():\n    \"\"\"Create the SCOOP module arguments parser.\"\"\"\n    # TODO: Add environment variable (all + selection)\n    parser = argparse.ArgumentParser(\n        description=\"Starts a parallel program using SCOOP.\",\n        prog=\"{0} -m scoop\".format(sys.executable),\n    )\n    group = parser.add_mutually_exclusive_group()\n    group.add_argument('--hosts', '--host',\n                       help=\"The list of hosts. The first host will execute \"\n                            \"the origin. (default is 127.0.0.1)\",\n                       metavar=\"Address\",\n                       nargs='*')\n    group.add_argument('--hostfile',\n                       help=\"The hostfile name\",\n                       metavar=\"FileName\")\n    parser.add_argument('--path', '-p',\n                        help=\"The path to the executable on remote hosts \"\n                             \"(default is local directory)\",\n                        default=os.getcwd())\n    parser.add_argument('--nice',\n                        type=int,\n                        metavar=\"NiceLevel\",\n                        help=\"*nix niceness level (-20 to 19) to run the \"\n                             \"executable\")\n    parser.add_argument('--verbose', '-v',\n                        action='count',\n                        help=\"Verbosity level of this launch script (-vv for \"\n                             \"more)\",\n                        default=1)\n    parser.add_argument('--quiet', '-q',\n                        action='store_true')\n    parser.add_argument('-n',\n                        help=\"Total number of workers to launch on the hosts. \"\n                             \"Workers are spawned sequentially over the hosts. \"\n                             \"(ie. -n 3 with 2 hosts will spawn 2 workers on \"\n                             \"the first host and 1 on the second.) (default: \"\n                             \"Number of CPUs on current machine)\",\n                        type=int,\n                        metavar=\"NumberOfWorkers\")\n    parser.add_argument('-b',\n                        help=\"Total number of brokers to launch on the hosts. \"\n                             \"Brokers are spawned sequentially over the hosts. \"\n                             \"(ie. -b 3 with 2 hosts will spawn 2 brokers on \"\n                             \"the first host and 1 on the second.) (default: \"\n                             \"1)\",\n                        type=int,\n                        default=1,\n                        metavar=\"NumberOfBrokers\")\n    parser.add_argument('--rsh',\n                        help=\"Use RSH instead of SSH for the launching process. \"\n                             \"Not compatible with --tunnel flag.\",\n                        action='store_true')\n    parser.add_argument('--ssh-executable',\n                        help=\"Name of the ssh executable. (default: 'ssh')\",\n                        default=\"ssh\",\n                        metavar=\"SSHExecutable\")\n    parser.add_argument('--tunnel',\n                        help=\"Activate ssh tunnels to route toward the broker \"\n                             \"sockets over remote connections (may eliminate \"\n                             \"routing problems and activate encryption but \"\n                             \"slows down communications)\",\n                        action='store_true')\n    parser.add_argument('--external-hostname',\n                        nargs=1,\n                        help=\"The externally routable hostname / ip of this \"\n                             \"machine. (defaults to the local hostname)\",\n                        metavar=\"Address\")\n    parser.add_argument('--python-interpreter',\n                        nargs=1,\n                        help=\"The python interpreter executable with which to \"\n                             \"execute the script\",\n                        default=[sys.executable],\n                        metavar=\"Path\")\n    parser.add_argument('--pythonpath',\n                        nargs=1,\n                        help=\"The PYTHONPATH environment variable (default is \"\n                             \"current PYTHONPATH)\",\n                        default=[os.environ.get('PYTHONPATH', '')])\n    parser.add_argument('--prolog',\n                        nargs=1,\n                        help=\"Absolute Path to a shell script or executable \"\n                             \"that will be executed at the launch of every \"\n                             \"worker\",\n                        default=[None])\n    parser.add_argument('--debug',\n                        help=argparse.SUPPRESS,\n                        action='store_true')\n    parser.add_argument('--profile',\n                        help=(\"Turn on the profiling. SCOOP will call \"\n                        \"cProfile.run on the executable for every worker and\"\n                        \" will produce files in directory profile/ named \"\n                        \"workerX where X is the number of the worker.\"),\n                        action='store_true')\n    parser.add_argument('--backend',\n                        help=\"Choice of communication backend\",\n                        choices=['ZMQ', 'TCP'],\n                        default='ZMQ')\n    parser.add_argument('executable',\n                        nargs='?',\n                        help='The executable to start with SCOOP')\n    parser.add_argument('args',\n                        nargs=argparse.REMAINDER,\n                        help='The arguments to pass to the executable',\n                        default=[],\n                        metavar=\"args\")\n    return parser"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndivides processes among hosts.", "response": "def divideHosts(self, hosts, qty):\n        \"\"\"Divide processes among hosts.\"\"\"\n        maximumWorkers = sum(host[1] for host in hosts)\n\n        # If specified amount of workers is greater than sum of each specified.\n        if qty > maximumWorkers:\n            index = 0\n            while qty > maximumWorkers:\n                hosts[index] = (hosts[index][0], hosts[index][1] + 1)\n                index = (index + 1) % len(hosts)\n                maximumWorkers += 1\n\n        # If specified amount of workers if lower than sum of each specified.\n        elif qty < maximumWorkers:\n\n            while qty < maximumWorkers:\n                maximumWorkers -= hosts[-1][1]\n                if qty > maximumWorkers:\n                    hosts[-1] = (hosts[-1][0], qty - maximumWorkers)\n                    maximumWorkers += hosts[-1][1]\n                else:\n                    del hosts[-1]\n\n\n        # Checking if the broker if externally routable\n        if self.externalHostname in utils.loopbackReferences and \\\n                len(hosts) > 1 and \\\n                not self.tunnel:\n            raise Exception(\"\\n\"\n                            \"Could not find route from external worker to the \"\n                            \"broker: Unresolvable hostname or IP address.\\n \"\n                            \"Please specify your externally routable hostname \"\n                            \"or IP using the --external-hostname parameter or \"\n                            \"use the --tunnel flag.\")\n        return hosts"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nshow the worker distribution over the hosts.", "response": "def showHostDivision(self, headless):\n        \"\"\"Show the worker distribution over the hosts.\"\"\"\n        scoop.logger.info('Worker d--istribution: ')\n        for worker, number in self.worker_hosts:\n            first_worker = (worker == self.worker_hosts[0][0])\n            scoop.logger.info('   {0}:\\t{1} {2}'.format(\n                worker,\n                number - 1 if first_worker or headless else str(number),\n                \"+ origin\" if first_worker or headless else \"\",\n                )\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _setWorker_args(self, origin):\n        args = []\n        kwargs = {\n            'pythonPath': self.pythonpath,\n            'prolog': self.prolog,\n            'path': self.path,\n            'nice': self.nice,\n            'pythonExecutable': self.python_executable,\n            'size': self.n,\n            'origin': origin,\n            'brokerHostname': self.externalHostname,\n            'brokerPorts': (self.brokers[0].brokerPort,\n                            self.brokers[0].infoPort),\n            'debug': self.debug,\n            'profiling': self.profile,\n            'executable': self.executable,\n            'verbose': self.verbose,\n            'backend': self.backend,\n            'args': self.args,\n        }\n        return args, kwargs", "response": "Create the arguments to pass to the addWorker call."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setWorkerInfo(self, hostname, workerAmount, origin):\n\n        scoop.logger.debug('Initialising {0}{1} worker {2} [{3}].'.format(\n            \"local\" if hostname in utils.localHostnames else \"remote\",\n            \" origin\" if origin else \"\",\n            self.workersLeft,\n            hostname,\n            )\n        )\n\n        add_args, add_kwargs = self._setWorker_args(origin)\n        self.workers[-1].setWorker(*add_args, **add_kwargs)\n        self.workers[-1].setWorkerAmount(workerAmount)", "response": "Sets the worker information for the current host."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run(self):\n        # Launch the broker(s)\n        for hostname, nb_brokers in self.broker_hosts:\n            for ind in range(nb_brokers):\n                if self.externalHostname in utils.localHostnames:\n                    self.brokers.append(localBroker(\n                        debug=self.debug,\n                        nice=self.nice,\n                        backend=self.backend,\n                    ))\n                else:\n                    self.brokers.append(remoteBroker(\n                        hostname=hostname,\n                        pythonExecutable=self.python_executable,\n                        debug=self.debug,\n                        nice=self.nice,\n                        backend=self.backend,\n                        rsh=self.rsh,\n                        ssh_executable=self.ssh_executable,\n                    ))\n\n        # Share connection information between brokers\n        if self.b > 1:\n            for broker in self.brokers:\n                # Only send data of other brokers to a given broker\n                connect_data = [\n                    BrokerInfo(\n                        x.getHost(),\n                        *x.getPorts(),\n                        externalHostname=x.getHost()\n                    )\n                    for x in self.brokers\n                    if x is not broker\n                ]\n                broker.sendConnect(connect_data)\n\n        # Launch the workers\n        shells = []\n        origin_launched = False\n        for hostname, nb_workers in self.worker_hosts:\n            self.workers.append(self.LAUNCH_HOST_CLASS(hostname, self.rsh,\n                                                       self.ssh_executable))\n            total_workers_host = min(nb_workers, self.workersLeft)\n\n            self.setWorkerInfo(hostname, total_workers_host, not origin_launched)\n            origin_launched = True\n            self.workersLeft -= total_workers_host\n\n            # Launch every workers at the same time\n            scoop.logger.debug(\n                \"{0}: Launching '{1}'\".format(\n                    hostname,\n                    self.workers[-1].getCommand(),\n                )\n            )\n            shells.append(self.workers[-1].launch(\n                (self.brokers[0].brokerPort,\n                 self.brokers[0].infoPort)\n                    if self.tunnel else None,\n            ))\n            if self.workersLeft <= 0:\n                # We've launched every worker we needed, so let's exit the loop\n                break\n        rootProcess = shells[0][0]\n\n        # Wait for the root program\n        try:\n            if self.workers[0].isLocal():\n                self.errors = self.workers[0].subprocesses[0].wait()\n            else:\n                self.errors = rootProcess.wait()\n        except KeyboardInterrupt:\n            pass\n        scoop.logger.info('Root process is done.')\n        return self.errors", "response": "Launch the broker and workers assigned on every hosts."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a broker to the broker cluster available list.", "response": "def addBrokerList(self, aBrokerInfoList):\n        \"\"\"Add a broker to the broker cluster available list.\n        Connects to the added broker if needed.\"\"\"\n        self.cluster_available.update(set(aBrokerInfoList))\n\n        # If we need another connection to a fellow broker\n        # TODO: only connect to a given number\n        for aBrokerInfo in aBrokerInfoList:\n            self.cluster_socket.connect(\n                \"tcp://{hostname}:{port}\".format(\n                    hostname=aBrokerInfo.hostname,\n                    port=aBrokerInfo.task_port,\n                )\n            )\n            self.cluster.append(aBrokerInfo)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef processConfig(self, worker_config):\n        self.config['headless'] |= worker_config.get(\"headless\", False)\n        if self.config['headless']:\n            # Launch discovery process\n            if not self.discovery_thread:\n                self.discovery_thread = discovery.Advertise(\n                    port=\",\".join(str(a) for a in self.getPorts()),\n                )", "response": "Update the pool configuration with a worker configuration."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nredirecting messages until a shutdown message is received.", "response": "def run(self):\n        \"\"\"Redirects messages until a shutdown message is received.\"\"\"\n        while True:\n            if not self.task_socket.poll(-1):\n                continue\n\n            msg = self.task_socket.recv_multipart()\n            msg_type = msg[1]\n\n            if self.debug:\n                self.stats.append((time.time(),\n                                   msg_type,\n                                   len(self.unassigned_tasks),\n                                   len(self.available_workers)))\n                if time.time() - self.lastDebugTs > TIME_BETWEEN_PARTIALDEBUG:\n                    self.writeDebug(\"debug/partial-{0}\".format(\n                        round(time.time(), -1)\n                    ))\n                    self.lastDebugTs = time.time()\n\n            # New task inbound\n            if msg_type == TASK:\n                task_id = msg[2]\n                task = msg[3]\n                self.logger.debug(\"Received task {0}\".format(task_id))\n                try:\n                    address = self.available_workers.popleft()\n                except IndexError:\n                    self.unassigned_tasks.append((task_id, task))\n                else:\n                    self.logger.debug(\"Sent {0}\".format(task_id))\n                    self.task_socket.send_multipart([address, TASK, task])\n                    self.assigned_tasks[address].add(task_id)\n\n            # Request for task\n            elif msg_type == REQUEST:\n                address = msg[0]\n                try:\n                    task_id, task = self.unassigned_tasks.popleft()\n                except IndexError:\n                    self.available_workers.append(address)\n                else:\n                    self.logger.debug(\"Sent {0}\".format(task_id))\n                    self.task_socket.send_multipart([address, TASK, task])\n                    self.assigned_tasks[address].add(task_id)\n\n            # A task status request is requested\n            elif msg_type == STATUS_REQ:\n                self.pruneAssignedTasks()\n                address = msg[0]\n                task_id = msg[2]\n\n                if any(task_id in x for x in self.assigned_tasks.values()):\n                    status = STATUS_GIVEN\n                elif task_id in (x[0] for x in self.unassigned_tasks):\n                    status = STATUS_HERE\n                else:\n                    status = STATUS_NONE\n\n                self.task_socket.send_multipart([\n                    address, STATUS_ANS, task_id, status\n                ])\n\n            # A task status set (task done) is received\n            elif msg_type == STATUS_DONE:\n                address = msg[0]\n                task_id = msg[2]\n\n                try:\n                    self.assigned_tasks[address].discard(task_id)\n                except KeyError:\n                    pass\n\n            elif msg_type == STATUS_UPDATE:\n                address = msg[0]\n                try:\n                    tasks_ids = pickle.loads(msg[2])\n                except:\n                    self.logger.error(\"Could not unpickle status update message.\")\n                else:\n                    self.assigned_tasks[address] = tasks_ids\n                    self.status_times[address] = time.time()\n\n            # Answer needing delivery\n            elif msg_type == REPLY:\n                self.logger.debug(\"Relaying\")\n                destination = msg[-1]\n                origin = msg[0]\n                self.task_socket.send_multipart([destination] + msg[1:] + [origin])\n\n            # Shared variable to distribute\n            elif msg_type == VARIABLE:\n                address = msg[4]\n                value = msg[3]\n                key = msg[2]\n                self.shared_variables[address].update(\n                    {key: value},\n                )\n                self.info_socket.send_multipart([VARIABLE,\n                                                key,\n                                                value,\n                                                address])\n\n            # Initialize the variables of a new worker\n            elif msg_type == INIT:\n                address = msg[0]\n                try:\n                    self.processConfig(pickle.loads(msg[2]))\n                except pickle.PickleError:\n                    continue\n                self.task_socket.send_multipart([\n                    address,\n                    pickle.dumps(self.config,\n                                 pickle.HIGHEST_PROTOCOL),\n                    pickle.dumps(self.shared_variables,\n                                 pickle.HIGHEST_PROTOCOL),\n                ])\n\n                self.task_socket.send_multipart([\n                    address,\n                    pickle.dumps(self.cluster_available,\n                                 pickle.HIGHEST_PROTOCOL),\n                ])\n\n            # Add a given broker to its fellow list\n            elif msg_type == CONNECT:\n                try:\n                    connect_brokers = pickle.loads(msg[2])\n                except pickle.PickleError:\n                    self.logger.error(\"Could not understand CONNECT message.\")\n                    continue\n                self.logger.info(\"Connecting to other brokers...\")\n                self.addBrokerList(connect_brokers)\n\n            # Shutdown of this broker was requested\n            elif msg_type == SHUTDOWN:\n                self.logger.debug(\"SHUTDOWN command received.\")\n                self.shutdown()\n                break"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef main(self):\n        if self.args is None:\n            self.parse()\n\n        self.log = utils.initLogging(self.verbose)\n\n        # Change to the desired directory\n        if self.args.workingDirectory:\n            os.chdir(self.args.workingDirectory)\n\n        if not self.args.brokerHostname:\n            self.log.info(\"Discovering SCOOP Brokers on network...\")\n            pools = discovery.Seek()\n            if not pools:\n                self.log.error(\"Could not find a SCOOP Broker broadcast.\")\n                sys.exit(-1)\n            self.log.info(\"Found a broker named {name} on {host} port \"\n                          \"{ports}\".format(\n                name=pools[0].name,\n                host=pools[0].host,\n                ports=pools[0].ports,\n            ))\n            self.args.brokerHostname = pools[0].host\n            self.args.taskPort = pools[0].ports[0]\n            self.args.metaPort = pools[0].ports[0]\n            self.log.debug(\"Using following addresses:\\n{brokerAddress}\\n\"\n                           \"{metaAddress}\".format(\n                                brokerAddress=self.args.brokerAddress,\n                                metaAddress=self.args.metaAddress,\n                            ))\n\n            self.args.origin = True\n\n        self.setScoop()\n\n        self.run()", "response": "Bootstrap an arbitrary script."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef makeParser(self):\n        self.parser = argparse.ArgumentParser(description='Starts the executable.',\n                                              prog=(\"{0} -m scoop.bootstrap\"\n                                                    ).format(sys.executable))\n\n        self.parser.add_argument('--origin',\n                                 help=\"To specify that the worker is the origin\",\n                                 action='store_true')\n        self.parser.add_argument('--brokerHostname',\n                                 help=\"The routable hostname of a broker\",\n                                 default=\"\")\n        self.parser.add_argument('--externalBrokerHostname',\n                                 help=\"Externally routable hostname of local \"\n                                      \"worker\",\n                                 default=\"\")\n        self.parser.add_argument('--taskPort',\n                                 help=\"The port of the broker task socket\",\n                                 type=int)\n        self.parser.add_argument('--metaPort',\n                                 help=\"The port of the broker meta socket\",\n                                 type=int)\n        self.parser.add_argument('--size',\n                                 help=\"The size of the worker pool\",\n                                 type=int,\n                                 default=1)\n        self.parser.add_argument('--nice',\n                                 help=\"Adjust the niceness of the process\",\n                                 type=int,\n                                 default=0)\n        self.parser.add_argument('--debug',\n                                 help=\"Activate the debug\",\n                                 action='store_true')\n        self.parser.add_argument('--profile',\n                                 help=\"Activate the profiler\",\n                                 action='store_true')\n        self.parser.add_argument('--workingDirectory',\n                                 help=\"Set the working directory for the \"\n                                      \"execution\",\n                                 default=os.path.expanduser(\"~\"))\n        self.parser.add_argument('--backend',\n                                 help=\"Choice of communication backend\",\n                                 choices=['ZMQ', 'TCP'],\n                                 default='ZMQ')\n        self.parser.add_argument('executable',\n                                 nargs='?',\n                                 help='The executable to start with scoop')\n        self.parser.add_argument('args',\n                                 nargs=argparse.REMAINDER,\n                                 help='The arguments to pass to the executable',\n                                 default=[])\n        self.parser.add_argument('--verbose', '-v', action='count',\n                                 help=(\"Verbosity level of this launch script\"\n                                      \"(-vv for more)\"),\n                                 default=0)", "response": "Generate the argparse parser object containing the bootloader\n           accepted parameters"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse(self):\n        if self.parser is None:\n            self.makeParser()\n        self.args = self.parser.parse_args()\n        self.verbose = self.args.verbose", "response": "Generate a argparse parser and parse the command - line arguments"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef setupEnvironment(self=None):\n        # get the module path in the Python path\n        sys.path.append(os.path.dirname(os.path.abspath(scoop.MAIN_MODULE)))\n\n        # Add the user arguments to argv\n        sys.argv = sys.argv[:1]\n        if self:\n            sys.argv += self.args.args\n\n        try:\n            if scoop.IS_ORIGIN:\n                _ = open(scoop.MAIN_MODULE, 'r')\n                user_module = None\n            else:\n                user_module = importFunction(\n                    \"SCOOP_WORKER\",\n                    scoop.MAIN_MODULE,\n                )\n        except FileNotFoundError as e:\n            # Could not find file\n            sys.stderr.write('{0}\\nFile: {1}\\nIn path: {2}\\n'.format(\n                    str(e),\n                    scoop.MAIN_MODULE,\n                    sys.path[-1],\n                )\n            )\n            sys.stderr.flush()\n            sys.exit(-1)\n\n        globs = {}\n        try:\n            attrlist = user_module.__all__\n        except AttributeError:\n            attrlist = dir(user_module)\n        for attr in attrlist:\n            globs[attr] = getattr(user_module, attr)\n\n        if self and scoop.IS_ORIGIN:\n            return {}\n        elif self:\n            return globs\n        return user_module", "response": "Set the environment of the user."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run(self, globs=None):\n        # Without this, the underneath import clashes with the top-level one\n        global scoop\n\n        if globs is None:\n            globs = globals()\n\n        # import the user module\n        if scoop.MAIN_MODULE:\n            globs.update(self.setupEnvironment(self))\n\n        # Start the user program\n        from scoop import futures\n\n        def futures_startup():\n            \"\"\"Execute the user code.\n            Wraps futures._startup (SCOOP initialisation) over the user module.\n            Needs \"\"\"\n            return futures._startup(\n                functools.partial(\n                    runpy.run_path,\n                    scoop.MAIN_MODULE,\n                    init_globals=globs,\n                    run_name=\"__main__\"\n                )\n            )\n\n        if self.args.profile:\n            import cProfile\n            # runctx instead of run is required for local function\n            try:\n                os.makedirs(\"profile\")\n            except:\n                pass\n            cProfile.runctx(\n                \"futures_startup()\",\n                globs,\n                locals(),\n                \"./profile/{0}.prof\".format(os.getpid())\n            )\n        else:\n            try:\n                futures_startup()\n            finally:\n                # Must reimport (potentially not there after bootstrap)\n                import scoop\n\n                # Ensure a communication queue exists (may happend when a\n                # connection wasn't established such as cloud-mode wait).\n                if scoop._control.execQueue:\n                    scoop._control.execQueue.shutdown()", "response": "Start the user code and run the user module."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a broker to the broker cluster available list.", "response": "def addBrokerList(self, aBrokerInfoList):\n        \"\"\"Add a broker to the broker cluster available list.\n        Connects to the added broker if needed.\"\"\"\n        self.clusterAvailable.update(set(aBrokerInfoList))\n\n        # If we need another connection to a fellow broker\n        # TODO: only connect to a given number\n        for aBrokerInfo in aBrokerInfoList:\n            self.clusterSocket.connect(\n                \"tcp://{hostname}:{port}\".format(\n                    hostname=aBrokerInfo.hostname,\n                    port=aBrokerInfo.task_port,\n                )\n            )\n            self.cluster.append(aBrokerInfo)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend a CONNECT command to the broker", "response": "def sendConnect(self, data):\n        \"\"\"Send a CONNECT command to the broker\n            :param data: List of other broker main socket URL\"\"\"\n        # Imported dynamically - Not used if only one broker\n        if self.backend == 'ZMQ':\n            import zmq\n            self.context = zmq.Context()\n            self.socket = self.context.socket(zmq.DEALER)\n            self.socket.setsockopt(zmq.IDENTITY, b'launcher')\n            self.socket.connect(\n                \"tcp://127.0.0.1:{port}\".format(\n                    port=self.brokerPort,\n                )\n            )\n            self.socket.send_multipart([b\"CONNECT\",\n                                        pickle.dumps(data,\n                                                     pickle.HIGHEST_PROTOCOL)])\n        else:\n            # TODO\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends a CONNECT command to the broker", "response": "def sendConnect(self, data):\n        \"\"\"Send a CONNECT command to the broker\n            :param data: List of other broker main socket URL\"\"\"\n        # Imported dynamically - Not used if only one broker\n        if self.backend == 'ZMQ':\n            import zmq\n            self.context = zmq.Context()\n            self.socket = self.context.socket(zmq.DEALER)\n            if sys.version_info < (3,):\n                self.socket.setsockopt_string(zmq.IDENTITY, unicode('launcher'))\n            else:\n                self.socket.setsockopt_string(zmq.IDENTITY, 'launcher')\n            self.socket.connect(\n                \"tcp://{hostname}:{port}\".format(\n                    port=self.brokerPort,\n                    hostname = self.hostname\n                )\n            )\n            self.socket.send_multipart([b\"CONNECT\",\n                                        pickle.dumps(data,\n                                                     pickle.HIGHEST_PROTOCOL)])\n        else:\n            # TODO\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef close(self):\n        # TODO: DRY with workerLaunch.py\n        # Ensure everything is cleaned up on exit\n        scoop.logger.debug('Closing broker on host {0}.'.format(self.hostname))\n\n        # Terminate subprocesses\n        try:\n            self.shell.terminate()\n        except OSError:\n            pass\n\n        # Output child processes stdout and stderr to console\n        sys.stdout.write(self.shell.stdout.read().decode(\"utf-8\"))\n        sys.stdout.flush()\n\n        sys.stderr.write(self.shell.stderr.read().decode(\"utf-8\"))\n        sys.stderr.flush()", "response": "Closes the broker connection."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsending a Future to be executed remotely.", "response": "def sendFuture(self, future):\r\n        \"\"\"Send a Future to be executed remotely.\"\"\"\r\n        try:\r\n            if shared.getConst(hash(future.callable),\r\n                               timeout=0):\r\n                # Enforce name reference passing if already shared\r\n                future.callable = SharedElementEncapsulation(hash(future.callable))\r\n            self.socket.send_multipart([b\"TASK\",\r\n                                        pickle.dumps(future,\r\n                                                     pickle.HIGHEST_PROTOCOL)])\r\n        except pickle.PicklingError as e:\r\n            # If element not picklable, pickle its name\r\n            # TODO: use its fully qualified name\r\n            scoop.logger.warn(\"Pickling Error: {0}\".format(e))\r\n            previousCallable = future.callable\r\n            future.callable = hash(future.callable)\r\n            self.socket.send_multipart([b\"TASK\",\r\n                                        pickle.dumps(future,\r\n                                                     pickle.HIGHEST_PROTOCOL)])\r\n            future.callable = previousCallable"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend a terminated future back to its parent.", "response": "def sendResult(self, future):\r\n        \"\"\"Send a terminated future back to its parent.\"\"\"\r\n        future = copy.copy(future)\r\n\r\n        # Remove the (now) extraneous elements from future class\r\n        future.callable = future.args = future.kargs = future.greenlet = None\r\n\r\n        if not future.sendResultBack:\r\n            # Don't reply back the result if it isn't asked\r\n            future.resultValue = None\r\n\r\n        self._sendReply(\r\n            future.id.worker,\r\n            pickle.dumps(\r\n                future,\r\n                pickle.HIGHEST_PROTOCOL,\r\n            ),\r\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef shutdown(self):\r\n        if self.OPEN:\r\n            self.OPEN = False\r\n            scoop.SHUTDOWN_REQUESTED = True\r\n            self.socket.send(b\"SHUTDOWN\")\r\n            self.socket.close()\r\n            self.infoSocket.close()\r\n            time.sleep(0.3)", "response": "Sends a SHUTDOWN message to other workers."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getValue(words):\n    value = 0\n    for word in words:\n        for letter in word:\n            # shared.getConst will evaluate to the dictionary broadcasted by\n            # the root Future\n            value += shared.getConst('lettersValue')[letter]\n    return value", "response": "Computes the sum of the values of the words."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning the designated module as main namespace.", "response": "def _run_module_as_main(mod_name, alter_argv=True):\n    \"\"\"Runs the designated module in the __main__ namespace\n\n       Note that the executed module will have full access to the\n       __main__ namespace. If this is not desirable, the run_module()\n       function should be used to run the module code in a fresh namespace.\n\n       At the very least, these variables in __main__ will be overwritten:\n           __name__\n           __file__\n           __loader__\n           __package__\n    \"\"\"\n    try:\n        if alter_argv or mod_name != \"__main__\": # i.e. -m switch\n            mod_name, loader, code, fname = _get_module_details(mod_name)\n        else:          # i.e. directory or zipfile execution\n            mod_name, loader, code, fname = _get_main_module_details()\n    except ImportError as exc:\n        msg = \"%s: %s\" % (sys.executable, str(exc))\n        sys.exit(msg)\n    pkg_name = mod_name.rpartition('.')[0]\n    main_globals = sys.modules[\"__main__\"].__dict__\n    if alter_argv:\n        sys.argv[0] = fname\n    return _run_code(code, main_globals, None,\n                     \"__main__\", fname, loader, pkg_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run_module(mod_name, init_globals=None,\n               run_name=None, alter_sys=False):\n    \"\"\"Execute a module's code without importing it\n\n       Returns the resulting top level namespace dictionary\n    \"\"\"\n    mod_name, loader, code, fname = _get_module_details(mod_name)\n    if run_name is None:\n        run_name = mod_name\n    pkg_name = mod_name.rpartition('.')[0]\n    if alter_sys:\n        return _run_module_code(code, init_globals, run_name,\n                                fname, loader, pkg_name)\n    else:\n        # Leave the sys module alone\n        return _run_code(code, {}, init_globals, run_name,\n                         fname, loader, pkg_name)", "response": "Execute a module s code without importing it\nifestuggy"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexecuting code located at the specified filesystem location.", "response": "def run_path(path_name, init_globals=None, run_name=None):\n    \"\"\"Execute code located at the specified filesystem location\n\n       Returns the resulting top level namespace dictionary\n\n       The file path may refer directly to a Python script (i.e.\n       one that could be directly executed with execfile) or else\n       it may refer to a zipfile or directory containing a top\n       level __main__.py script.\n    \"\"\"\n    if run_name is None:\n        run_name = \"<run_path>\"\n    importer = _get_importer(path_name)\n    if isinstance(importer, imp.NullImporter):\n        # Not a valid sys.path entry, so run the code directly\n        # execfile() doesn't help as we want to allow compiled files\n        code = _get_code_from_file(path_name)\n        return _run_module_code(code, init_globals, run_name, path_name)\n    else:\n        # Importer is defined for path, so add it to\n        # the start of sys.path\n        sys.path.insert(0, path_name)\n        try:\n            # Here's where things are a little different from the run_module\n            # case. There, we only had to replace the module in sys while the\n            # code was running and doing so was somewhat optional. Here, we\n            # have no choice and we have to remove it even while we read the\n            # code. If we don't do this, a __loader__ attribute in the\n            # existing __main__ module may prevent location of the new module.\n            main_name = \"__main__\"\n            saved_main = sys.modules[main_name]\n            del sys.modules[main_name]\n            try:\n                mod_name, loader, code, fname = _get_main_module_details()\n            finally:\n                sys.modules[main_name] = saved_main\n            pkg_name = \"\"\n            with _ModifiedArgv0(path_name):\n                with _TempModule(run_name) as temp_module:\n                    mod_globals = temp_module.module.__dict__\n                    return _run_code(code, mod_globals, init_globals,\n                                        run_name, fname, loader, pkg_name).copy()\n        finally:\n            try:\n                sys.path.remove(path_name)\n            except ValueError:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding a tree node that represents rootValue and computes the max depth of that tree node.", "response": "def maxTreeDepthDivide(rootValue, currentDepth=0, parallelLevel=2):\n    \"\"\"Finds a tree node that represents rootValue and computes the max depth\n       of this tree branch.\n       This function will emit new futures until currentDepth=parallelLevel\"\"\"\n    thisRoot = shared.getConst('myTree').search(rootValue)\n    if currentDepth >= parallelLevel:\n        return thisRoot.maxDepth(currentDepth)\n    else:\n        # Base case\n        if not any([thisRoot.left, thisRoot.right]):\n            return currentDepth\n        if not all([thisRoot.left, thisRoot.right]):\n            return thisRoot.maxDepth(currentDepth)\n\n        # Parallel recursion\n        return max(\n            futures.map(\n                maxTreeDepthDivide,\n                [\n                    thisRoot.left.payload,\n                    thisRoot.right.payload,\n                ],\n                cycle([currentDepth + 1]),\n                cycle([parallelLevel]),\n            )\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninsert a value in the tree", "response": "def insert(self, value):\n        \"\"\"Insert a value in the tree\"\"\"\n        if not self.payload or value == self.payload:\n            self.payload = value\n        else:\n            if value <= self.payload:\n                if self.left:\n                    self.left.insert(value)\n                else:\n                    self.left = BinaryTreeNode(value)\n            else:\n                if self.right:\n                    self.right.insert(value)\n                else:\n                    self.right = BinaryTreeNode(value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute the depth of the longest branch of the tree", "response": "def maxDepth(self, currentDepth=0):\n        \"\"\"Compute the depth of the longest branch of the tree\"\"\"\n        if not any((self.left, self.right)):\n            return currentDepth\n        result = 0\n        for child in (self.left, self.right):\n            if child:\n                result = max(result, child.maxDepth(currentDepth + 1))\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsearching the tree for an element with the given value.", "response": "def search(self, value):\n        \"\"\"Find an element in the tree\"\"\"\n        if self.payload == value:\n            return self\n        else:\n            if value <= self.payload:\n                if self.left:\n                    return self.left.search(value)\n            else:\n                if self.right:\n                    return self.right.search(value)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new zmq socket of the given sock_type and deactivate message dropping", "response": "def createZMQSocket(self, sock_type):\n        \"\"\"Create a socket of the given sock_type and deactivate message dropping\"\"\"\n        sock = self.ZMQcontext.socket(sock_type)\n        sock.setsockopt(zmq.LINGER, LINGER_TIME)\n        sock.setsockopt(zmq.IPV4ONLY, 0)\n\n        # Remove message dropping\n        sock.setsockopt(zmq.SNDHWM, 0)\n        sock.setsockopt(zmq.RCVHWM, 0)\n        try:\n            sock.setsockopt(zmq.IMMEDIATE, 1)\n        except:\n            # This parameter was recently added by new libzmq versions\n            pass\n\n        # Don't accept unroutable messages\n        if sock_type == zmq.ROUTER:\n            sock.setsockopt(zmq.ROUTER_MANDATORY, 1)\n        return sock"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _reportFutures(self):\n        try:\n            while True:\n                time.sleep(scoop.TIME_BETWEEN_STATUS_REPORTS)\n                fids = set(x.id for x in scoop._control.execQueue.movable)\n                fids.update(set(x.id for x in scoop._control.execQueue.ready))\n                fids.update(set(x.id for x in scoop._control.execQueue.inprogress))\n                self.socket.send_multipart([\n                    STATUS_UPDATE,\n                    pickle.dumps(fids),\n                ])\n        except AttributeError:\n            # The process is being shut down.\n            pass", "response": "Sends futures status updates to broker at intervals of\n        scoop. TIME_BETWEEN_STATUS_REPORTS seconds."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nput the function in the main module of the main module.", "response": "def convertVariable(self, key, varName, varValue):\n        \"\"\"Puts the function in the globals() of the main module.\"\"\"\n        if isinstance(varValue, encapsulation.FunctionEncapsulation):\n            result = varValue.getFunction()\n\n            # Update the global scope of the function to match the current module\n            mainModule = sys.modules[\"__main__\"]\n            result.__name__ = varName\n            result.__globals__.update(mainModule.__dict__)\n            setattr(mainModule, varName, result)\n            shared.elements[key].update({\n                varName: result,\n            })"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sendFuture(self, future):\n        future = copy.copy(future)\n        future.greenlet = None\n        future.children = {}\n\n        try:\n            if shared.getConst(hash(future.callable), timeout=0):\n                # Enforce name reference passing if already shared\n                future.callable = SharedElementEncapsulation(hash(future.callable))\n            self.socket.send_multipart([\n                TASK,\n                pickle.dumps(future.id, pickle.HIGHEST_PROTOCOL),\n                pickle.dumps(future, pickle.HIGHEST_PROTOCOL),\n            ])\n        except (pickle.PicklingError, TypeError) as e:\n            # If element not picklable, pickle its name\n            # TODO: use its fully qualified name\n            scoop.logger.warn(\"Pickling Error: {0}\".format(e))\n            future.callable = hash(future.callable)\n            self.socket.send_multipart([\n                TASK,\n                pickle.dumps(future.id, pickle.HIGHEST_PROTOCOL),\n                pickle.dumps(future, pickle.HIGHEST_PROTOCOL),\n            ])", "response": "Send a Future to be executed remotely."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _sendReply(self, destination, fid, *args):\n        # Try to send the result directly to its parent\n        self.addPeer(destination)\n\n        try:\n            self.direct_socket.send_multipart([\n                destination,\n                REPLY,\n            ] + list(args),\n                flags=zmq.NOBLOCK)\n        except zmq.error.ZMQError as e:\n            # Fallback on Broker routing if no direct connection possible\n            scoop.logger.debug(\n                \"{0}: Could not send result directly to peer {1}, routing through \"\n                \"broker.\".format(scoop.worker, destination)\n            )\n            self.socket.send_multipart([\n                REPLY, \n                ] + list(args) + [\n                destination,\n            ])\n\n        self.socket.send_multipart([\n            STATUS_DONE,\n            fid,\n        ])", "response": "Send a REPLY directly to its destination."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsending a shutdown message to other workers.", "response": "def shutdown(self):\n        \"\"\"Sends a shutdown message to other workers.\"\"\"\n        if self.ZMQcontext and not self.ZMQcontext.closed:\n            scoop.SHUTDOWN_REQUESTED = True\n            self.socket.send(SHUTDOWN)\n            \n            # pyzmq would issue an 'no module named zmqerror' on windows\n            # without this\n            try:\n                self.direct_socket.__del__()\n                self.socket.__del__()\n                self.infoSocket.__del__()\n            except AttributeError:\n                # Older versions of pyzmq doesn't have the __del__ method\n                pass\n\n            self.ZMQcontext.destroy()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninitializing the SCOOP environment.", "response": "def _startup(rootFuture, *args, **kargs):\n    \"\"\"Initializes the SCOOP environment.\n\n    :param rootFuture: Any callable object (function or class object with *__call__*\n        method); this object will be called once and allows the use of parallel\n        calls inside this object.\n    :param args: A tuple of positional arguments that will be passed to the\n        callable object.\n    :param kargs: A dictionary of additional keyword arguments that will be\n        passed to the callable object.\n\n    :returns: The result of the root Future.\n\n    Be sure to launch your root Future using this method.\"\"\"\n    import greenlet\n    global _controller\n    _controller = greenlet.greenlet(control.runController)\n    try:\n        result = _controller.switch(rootFuture, *args, **kargs)\n    except scoop._comm.Shutdown:\n        result = None\n        control.execQueue.shutdown()\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _mapFuture(callable_, *iterables):\n    childrenList = []\n    for args in zip(*iterables):\n        childrenList.append(submit(callable_, *args))\n    return childrenList", "response": "Similar to the built - in map function but each of the given iterables will execute each Future and return the list of Futures that are spawned remotely."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef map(func, *iterables, **kwargs):\n    # TODO: Handle timeout\n    futures = _mapFuture(func, *iterables)\n    return _mapGenerator(futures)", "response": "A generator that returns a value from a function that returns a single item from the order of the items in the order of the items in the order of the items in the order they were added."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef map_as_completed(func, *iterables, **kwargs):\n    # TODO: Handle timeout\n    for future in as_completed(_mapFuture(func, *iterables)):\n        yield future.resultValue", "response": "A generator that yields the results of a function func on all the items in iterables."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates the recursive reduction tree. Used by mapReduce.", "response": "def _recursiveReduce(mapFunc, reductionFunc, scan, *iterables):\n    \"\"\"Generates the recursive reduction tree. Used by mapReduce.\"\"\"\n    if iterables:\n        half = min(len(x) // 2 for x in iterables)\n        data_left = [list(x)[:half] for x in iterables]\n        data_right = [list(x)[half:] for x in iterables]\n    else:\n        data_left = data_right = [[]]\n\n    # Submit the left and right parts of the reduction\n    out_futures = [None, None]\n    out_results = [None, None]\n    for index, data in enumerate([data_left, data_right]):\n        if any(len(x) <= 1 for x in data):\n            out_results[index] = mapFunc(*list(zip(*data))[0])\n        else:\n            out_futures[index] = submit(\n                _recursiveReduce,\n                mapFunc,\n                reductionFunc,\n                scan,\n                *data\n            )\n\n    # Wait for the results\n    for index, future in enumerate(out_futures):\n        if future:\n            out_results[index] = future.result()\n\n    # Apply a scan if needed\n    if scan:\n        last_results = copy.copy(out_results)\n        if type(out_results[0]) is not list:\n            out_results[0] = [out_results[0]]\n        else:\n            last_results[0] = out_results[0][-1]\n        if type(out_results[1]) is list:\n            out_results[0].extend(out_results[1][:-1])\n            last_results[1] = out_results[1][-1]\n        out_results[0].append(reductionFunc(*last_results))\n        return out_results[0]\n\n    return reductionFunc(*out_results)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mapScan(mapFunc, reductionFunc, *iterables, **kwargs):\n    return submit(\n        _recursiveReduce,\n        mapFunc,\n        reductionFunc,\n        True,\n        *iterables\n    ).result()", "response": "Exectues the : meth : ~scoop. futures. map function and then applies the reductionFunc to the result of every a\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _createFuture(func, *args, **kwargs):\n    assert callable(func), (\n        \"The provided func parameter is not a callable.\"\n    )\n\n    if scoop.IS_ORIGIN and \"SCOOP_WORKER\" not in sys.modules:\n        sys.modules[\"SCOOP_WORKER\"] = sys.modules[\"__main__\"]\n\n    # If function is a lambda or class method, share it (or its parent object)\n    # beforehand\n    lambdaType = type(lambda: None)\n    funcIsLambda = isinstance(func, lambdaType) and func.__name__ == '<lambda>'\n    # Determine if function is a method. Methods derived from external\n    # languages such as C++ aren't detected by ismethod.\n    funcIsMethod = ismethod(func)\n    if funcIsLambda or funcIsMethod:\n        from .shared import SharedElementEncapsulation\n        func = SharedElementEncapsulation(func)\n\n    return Future(control.current.id, func, *args, **kwargs)", "response": "Helper function to create a future."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef submit(func, *args, **kwargs):\n    child = _createFuture(func, *args, **kwargs)\n\n    control.futureDict[control.current.id].children[child] = None\n    control.execQueue.append(child)\n    return child", "response": "Submit an independent asynchronous function that will be executed locally or remotely as func * args."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwaiting on any child Future created by the calling Future.", "response": "def _waitAny(*children):\n    \"\"\"Waits on any child Future created by the calling Future.\n\n    :param children: A tuple of children Future objects spawned by the calling\n        Future.\n\n    :return: A generator function that iterates on futures that are done.\n\n    The generator produces results of the children in a non deterministic order\n    that depends on the particular parallel execution of the Futures. The\n    generator returns a tuple as soon as one becomes available.\"\"\"\n    n = len(children)\n    # check for available results and index those unavailable\n    for index, future in enumerate(children):\n        if future.exceptionValue:\n            raise future.exceptionValue\n        if future._ended():\n            future._delete()\n            yield future\n            n -= 1\n        else:\n            future.index = index\n    future = control.current\n    while n > 0:\n        # wait for remaining results; switch to controller\n        future.stopWatch.halt()\n        childFuture = _controller.switch(future)\n        future.stopWatch.resume()\n        if childFuture.exceptionValue:\n            raise childFuture.exceptionValue\n        # Only yield if executed future was in children, otherwise loop\n        if childFuture in children:\n            childFuture._delete()\n            yield childFuture\n            n -= 1"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef wait(fs, timeout=-1, return_when=ALL_COMPLETED):\n\n    DoneAndNotDoneFutures = namedtuple('DoneAndNotDoneFutures', 'done not_done')\n    if timeout < 0:\n        # Negative timeout means blocking.\n        if return_when == FIRST_COMPLETED:\n            next(_waitAny(*fs))\n        elif return_when in [ALL_COMPLETED, FIRST_EXCEPTION]:\n            for _ in _waitAll(*fs):\n                pass\n        done = set(f for f in fs if f.done())\n        not_done = set(fs) - done\n        return DoneAndNotDoneFutures(done, not_done)\n\n    elif timeout == 0:\n        # Zero-value entry means non-blocking\n        control.execQueue.flush()\n        control.execQueue.updateQueue()\n        done = set(f for f in fs if f._ended())\n        not_done = set(fs) - done\n        return DoneAndNotDoneFutures(done, not_done)\n\n    else:\n        # Any other value means blocking for a given time.\n        done = set()\n        start_time = time.time()\n        while time.time() - start_time < timeout:\n            # Flush futures on local queue (to be executed remotely)\n            control.execQueue.flush()\n            # Block until data arrives (to free CPU time)\n            control.execQueue.socket._poll(time.time() - start_time)\n            # Update queue\n            control.execQueue.updateQueue()\n\n            for f in fs:\n                if f._ended():\n                    done.add(f)\n\n            not_done = set(fs) - done\n\n            if return_when == FIRST_COMPLETED and len(done) > 0:\n                break\n            if len(not_done) == 0:\n                break\n        return DoneAndNotDoneFutures(done, not_done)", "response": "Wait for the given sequence of futures to complete."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef advertiseBrokerWorkerDown(exctype, value, traceback):\n    if not scoop.SHUTDOWN_REQUESTED:\n        execQueue.shutdown()\n    sys.__excepthook__(exctype, value, traceback)", "response": "Hook advertizing the broker if impromptu shutdown is occuring."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninitialising debug_stats and QueueLength", "response": "def init_debug():\n    \"\"\"Initialise debug_stats and QueueLength (this is not a reset)\"\"\"\n    global debug_stats\n    global QueueLength\n    if debug_stats is None:\n        list_defaultdict = partial(defaultdict, list)\n        debug_stats = defaultdict(list_defaultdict)\n        QueueLength = []"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting a future from the tree with the given id and parent id.", "response": "def delFutureById(futureId, parentId):\n    \"\"\"Delete future on id basis\"\"\"\n    try:\n        del futureDict[futureId]\n    except KeyError:\n        pass\n    try:\n        toDel = [a for a in futureDict[parentId].children if a.id == futureId]\n        for f in toDel:\n            del futureDict[parentId].children[f]\n    except KeyError:\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete a future afuture", "response": "def delFuture(afuture):\n    \"\"\"Delete future afuture\"\"\"\n    try:\n        del futureDict[afuture.id]\n    except KeyError:\n        pass\n    try:\n        del futureDict[afuture.parentId].children[afuture]\n    except KeyError:\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef runFuture(future):\n    global debug_stats\n    global QueueLength\n    if scoop.DEBUG:\n        init_debug()  # in case _control is imported before scoop.DEBUG was set\n        debug_stats[future.id]['start_time'].append(time.time())\n    future.waitTime = future.stopWatch.get()\n    future.stopWatch.reset()\n    # Get callback Group ID and assign the broker-wide unique executor ID\n    try:\n        uniqueReference = [cb.groupID for cb in future.callback][0]\n    except IndexError:\n        uniqueReference = None\n    future.executor = (scoop.worker, uniqueReference)\n    try:\n        future.resultValue = future.callable(*future.args, **future.kargs)\n    except BaseException as err:\n        future.exceptionValue = err\n        future.exceptionTraceback = str(traceback.format_exc())\n        scoop.logger.debug(\n            \"The following error occured on a worker:\\n%r\\n%s\",\n            err,\n            traceback.format_exc(),\n        )\n    future.executionTime = future.stopWatch.get()\n    future.isDone = True\n\n    # Update the worker inner work statistics\n    if future.executionTime != 0. and hasattr(future.callable, '__name__'):\n        execStats[hash(future.callable)].appendleft(future.executionTime)\n\n    # Set debugging informations if needed\n    if scoop.DEBUG:\n        t = time.time()\n        debug_stats[future.id]['end_time'].append(t)\n        debug_stats[future.id].update({\n            'executionTime': future.executionTime,\n            'worker': scoop.worker,\n            'creationTime': future.creationTime,\n            'callable': str(future.callable.__name__)\n                if hasattr(future.callable, '__name__')\n                else 'No name',\n           'parent': future.parentId\n        })\n        QueueLength.append((t, len(execQueue), execQueue.timelen(execQueue)))\n\n    # Run callback (see http://www.python.org/dev/peps/pep-3148/#future-objects)\n    future._execute_callbacks(CallbackType.universal)\n\n    # Delete references to the future\n    future._delete()\n\n    return future", "response": "This function runs the asynchronous function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute the mode of a log - normal distribution built with the stats data.", "response": "def mode(self):\n        \"\"\"Computes the mode of a log-normal distribution built with the stats data.\"\"\"\n        mu = self.mean()\n        sigma = self.std()\n        ret_val = math.exp(mu - sigma**2)\n        if math.isnan(ret_val):\n            ret_val = float(\"inf\")\n        return ret_val"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef median(self):\n        mu = self.mean()\n        ret_val = math.exp(mu)\n        if math.isnan(ret_val):\n            ret_val = float(\"inf\")\n        return ret_val", "response": "Computes the median of a log - normal distribution built with the stats data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a tupel opcode and payload. opcode is None. opcode is None. payload is None. opcode is None.", "response": "def _parse_packet(rawdata):\n    \"\"\" Returns a tupel (opcode, minusconf-data). opcode is None if this isn't a -conf packet.\"\"\"\n\n    if (len(rawdata) < len(_MAGIC) + 1) or (_MAGIC != rawdata[:len(_MAGIC)]):\n        # Wrong protocol\n        return (None, None)\n\n    opcode = rawdata[len(_MAGIC):len(_MAGIC)+1]\n    payload = rawdata[len(_MAGIC)+1:]\n\n    return (opcode, payload)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndecode a string in the buffer buf starting at position pos. Returns a tuple of the string and the next byte to read.", "response": "def _decode_string(buf, pos):\n    \"\"\" Decodes a string in the buffer buf, starting at position pos.\n    Returns a tupel of the read string and the next byte to read.\n    \"\"\"\n    for i in range(pos, len(buf)):\n        if buf[i:i+1] == _compat_bytes('\\x00'):\n            try:\n                return (buf[pos:i].decode(_CHARSET), i+1)\n            # Uncomment the following two lines for detailled information\n            #except UnicodeDecodeError as ude:\n            #   raise MinusconfError(str(ude))\n            except UnicodeDecodeError:\n                raise MinusconfError('Not a valid ' + _CHARSET + ' string: ' + repr(buf[pos:i]))\n\n    raise MinusconfError(\"Premature end of string (Forgot trailing \\\\0?), buf=\" + repr(buf))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _resolve_addrs(straddrs, port, ignore_unavailable=False, protocols=[socket.AF_INET, socket.AF_INET6]):\n\n    res = []\n    for sa in straddrs:\n        try:\n            ais = socket.getaddrinfo(sa, port)\n            for ai in ais:\n                if ai[0] in protocols:\n                    res.append((ai[0], ai[4], ai[0], ai[4][0]))\n                    break\n            else:\n                # Try to convert from IPv4 to IPv6\n                ai = ais[0]\n                if ai[0] == socket.AF_INET and socket.AF_INET6 in protocols:\n                    to = socket.getaddrinfo('::ffff:' + ai[4][0], port, socket.AF_INET6)[0][4]\n                    res.append((socket.AF_INET6, to, ai[0], ai[4][0]))\n        except socket.gaierror:\n            if not ignore_unavailable:\n                raise\n\n    return res", "response": "Resolves the given list of addresses and returns a list of tuples of family to original_addr_family original_addr."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a UDP socket for the current platform.", "response": "def _find_sock():\n    \"\"\" Create a UDP socket \"\"\"\n    if socket.has_ipv6:\n        try:\n            return socket.socket(socket.AF_INET6, socket.SOCK_DGRAM)\n        except socket.gaierror:\n            pass # Platform lied about IPv6 support\n    return socket.socket(socket.AF_INET, socket.SOCK_DGRAM)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _main():\n    import sys\n\n    if len(sys.argv) < 2:\n        _usage('Expected at least one parameter!')\n\n    sc = sys.argv[1]\n    options = sys.argv[2:]\n    if sc == 'a' or sc == 'advertise':\n        if len(options) > 5 or len(options) < 2:\n            _usage()\n\n        stype,port = options[:2]\n        advertisername = options[2] if len(options) > 2 else None\n        sname = options[3] if len(options) > 3 else ''\n        slocation = options[4] if len(options) > 4 else ''\n\n        service = Service(stype, port, sname, slocation)\n        advertiser = Advertiser([service], advertisername)\n        advertiser.run()\n    elif sc == 's' or sc == 'seek':\n        if len(options) > 4:\n            _usage()\n\n        aname = options[0] if len(options) > 0 else ''\n        stype = options[1] if len(options) > 1 else ''\n        sname = options[2] if len(options) > 2 else ''\n\n        se = Seeker(aname, stype, sname, find_callback=_print_result, error_callback=_print_error)\n        se.run()\n    else:\n        _usage('Unknown subcommand \"' + sys.argv[0] + '\"')", "response": "Main entry point for the\nTaxonomy CLI interface."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _compat_inet_pton(family, addr):\n\n    if family == socket.AF_INET:\n        # inet_aton accepts some strange forms, so we use our own\n        res = _compat_bytes('')\n        parts = addr.split('.')\n        if len(parts) != 4:\n            raise ValueError('Expected 4 dot-separated numbers')\n\n        for part in parts:\n            intval = int(part, 10)\n            if intval < 0 or intval > 0xff:\n                raise ValueError(\"Invalid integer value in IPv4 address: \" + str(intval))\n\n            res = res + struct.pack('!B', intval)\n\n        return res\n    elif family == socket.AF_INET6:\n        wordcount = 8\n        res = _compat_bytes('')\n\n        # IPv4 embedded?\n        dotpos = addr.find('.')\n        if dotpos >= 0:\n            v4start = addr.rfind(':', 0, dotpos)\n            if v4start == -1:\n                raise ValueException(\"Missing colons in an IPv6 address\")\n            wordcount = 6\n            res = socket.inet_aton(addr[v4start+1:])\n            addr = addr[:v4start] + '!' # We leave a marker that the address is not finished\n\n        # Compact version?\n        compact_pos = addr.find('::')\n        if compact_pos >= 0:\n            if compact_pos == 0:\n                addr = '0' + addr\n                compact_pos += 1\n            if compact_pos == len(addr)-len('::'):\n                addr = addr + '0'\n\n            addr = (addr[:compact_pos] + ':' +\n                ('0:' * (wordcount - (addr.count(':') - '::'.count(':')) - 2))\n                + addr[compact_pos + len('::'):])\n\n        # Remove any dots we left\n        if addr.endswith('!'):\n            addr = addr[:-len('!')]\n\n        words = addr.split(':')\n        if len(words) != wordcount:\n            raise ValueError('Invalid number of IPv6 hextets, expected ' + str(wordcount) + ', got ' + str(len(words)))\n        for w in reversed(words):\n            # 0x and negative is not valid here, but accepted by int(,16)\n            if 'x' in w or '-' in w:\n                raise ValueError(\"Invalid character in IPv6 address\")\n\n            intval = int(w, 16)\n            if intval > 0xffff:\n                raise ValueError(\"IPv6 address componenent too big\")\n            res = struct.pack('!H', intval) + res\n\n        return res\n\n    else:\n        raise ValueError(\"Unknown protocol family \" + family)", "response": "Returns a string that can be used to create a new IPv6 or IPv4 address."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef start_blocking(self):\n\n        self._cav_started.clear()\n        self.start()\n        self._cav_started.wait()", "response": "Start the advertiser in the background but wait until it is ready"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsending queries to multiple addresses. Returns the number of successful queries.", "response": "def _send_queries(self):\n        \"\"\" Sends queries to multiple addresses. Returns the number of successful queries. \"\"\"\n\n        res = 0\n\n        addrs = _resolve_addrs(self.addresses, self.port, self.ignore_senderrors, [self._sock.family])\n        for addr in addrs:\n            try:\n                self._send_query(addr[1])\n                res += 1\n            except:\n                if not self.ignore_senderrors:\n                    raise\n\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nraising a validation error message if the user entered the wrong format.", "response": "def clean(self):\n        \"\"\"\n        Always raise the default error message, because we don't\n        care what they entered here.\n        \"\"\"\n        raise forms.ValidationError(\n            self.error_messages['invalid_login'],\n            code='invalid_login',\n            params={'username': self.username_field.verbose_name}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef build_call(func, *args, **kwargs):\n\n    func = get_wrapped_func(func)\n    named, vargs, _, defs, kwonly, kwonlydefs, _ = getfullargspec(func)\n\n    nonce = object()\n    actual = dict((name, nonce) for name in named)\n\n    defs = defs or ()\n    kwonlydefs = kwonlydefs or {}\n\n    actual.update(kwonlydefs)\n    actual.update(dict(zip(reversed(named), reversed(defs))))\n    actual.update(dict(zip(named, args)))\n\n    if vargs:\n        actual[vargs] = tuple(args[len(named):])\n\n    actual.update(kwargs)\n\n    for name, value in actual.items():\n        if value is nonce:\n            raise TypeError(\"%s missing required positional argument: '%s'\" % (func.__name__, name))\n\n    return tuple_of_dict(actual)", "response": "Builds an argument dictionary suitable for passing via ** expansion given\n    function f positional arguments args and keyword arguments kwargs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nspecifying a precondition based on the types of the function's arguments.", "response": "def types(**requirements):\n    \"\"\"\n    Specify a precondition based on the types of the function's\n    arguments.\n    \"\"\"\n\n    def predicate(args):\n        for name, kind in sorted(requirements.items()):\n            assert hasattr(args, name), \"missing required argument `%s`\" % name\n\n            if not isinstance(kind, tuple):\n                kind = (kind,)\n\n            if not any(isinstance(getattr(args, name), k) for k in kind):\n                return False\n\n        return True\n\n    return condition(\"the types of arguments must be valid\", predicate, True)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ensure(arg1, arg2=None):\n\n    assert (isinstance(arg1, str) and isfunction(arg2)) or (isfunction(arg1) and arg2 is None)\n\n    description = \"\"\n    predicate = lambda x: x\n\n    if isinstance(arg1, str):\n        description = arg1\n        predicate = arg2\n    else:\n        description = get_function_source(arg1)\n        predicate = arg1\n\n    return condition(description, predicate, False, True)", "response": "Ensures that a condition is met."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a class invariant that can be used to create a new class in the hierarchy of the same name.", "response": "def invariant(arg1, arg2=None):\n    \"\"\"\n    Specify a class invariant described by `description` and tested\n    by `predicate`.\n    \"\"\"\n\n    desc = \"\"\n    predicate = lambda x: x\n\n    if isinstance(arg1, str):\n        desc = arg1\n        predicate = arg2\n    else:\n        desc = get_function_source(arg1)\n        predicate = arg1\n\n    def invariant(c):\n        def check(name, func):\n            exceptions = (\"__getitem__\", \"__setitem__\", \"__lt__\", \"__le__\", \"__eq__\",\n                          \"__ne__\", \"__gt__\", \"__ge__\", \"__init__\")\n\n            if name.startswith(\"__\") and name.endswith(\"__\") and name not in exceptions:\n                return False\n\n            if not ismethod(func) and not isfunction(func):\n                return False\n\n            if getattr(func, \"__self__\", None) is c:\n                return False\n\n            return True\n\n        class InvariantContractor(c):\n            pass\n\n        for name, value in [(name, getattr(c, name)) for name in dir(c)]:\n            if check(name, value):\n                setattr(InvariantContractor, name,\n                        condition(desc, predicate, name != \"__init__\", True, True)(value))\n        return InvariantContractor\n    return invariant"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a random ascii string from the given length chars and punctuation signs.", "response": "def mkpassword(length=16, chars=None, punctuation=None):\n    \"\"\"Generates a random ascii string - useful to generate authinfos\n\n    :param length: string wanted length\n    :type length: ``int``\n\n    :param chars: character population,\n                  defaults to alphabet (lower & upper) + numbers\n    :type chars: ``str``, ``list``, ``set`` (sequence)\n\n    :param punctuation: number of punctuation signs to include in string\n    :type punctuation: ``int``\n\n    :rtype: ``str``\n    \"\"\"\n    if chars is None:\n        chars = string.ascii_letters + string.digits\n\n    # Generate string from population\n    data = [random.choice(chars) for _ in range(length)]\n\n    # If punctuation:\n    # - remove n chars from string\n    # - add random punctuation\n    # - shuffle chars :)\n    if punctuation:\n        data = data[:-punctuation]\n\n        for _ in range(punctuation):\n            data.append(random.choice(PUNCTUATION))\n        random.shuffle(data)\n\n    return ''.join(data)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef disk_check_size(ctx, param, value):\n    if value:\n        # if we've got a prefix\n        if isinstance(value, tuple):\n            val = value[1]\n        else:\n            val = value\n        if val % 1024:\n            raise click.ClickException('Size must be a multiple of 1024.')\n    return value", "response": "Validate disk size parameter."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a dnssec key.", "response": "def create(cls, fqdn, flags, algorithm, public_key):\n        \"\"\"Create a dnssec key.\"\"\"\n        fqdn = fqdn.lower()\n\n        params = {\n            'flags': flags,\n            'algorithm': algorithm,\n            'public_key': public_key,\n        }\n\n        result = cls.call('domain.dnssec.create', fqdn, params)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving a snapshot profile accsociated to a name.", "response": "def from_name(cls, name):\n        \"\"\" Retrieve a snapshot profile accsociated to a name.\"\"\"\n        snps = cls.list({'name': name})\n        if len(snps) == 1:\n            return snps[0]['id']\n        elif not snps:\n            return\n\n        raise DuplicateResults('snapshot profile name %s is ambiguous.' % name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlist all snapshot profiles.", "response": "def list(cls, options=None, target=None):\n        \"\"\" List all snapshot profiles.\"\"\"\n        options = options or {}\n\n        result = []\n        if not target or target == 'paas':\n            for profile in cls.safe_call('paas.snapshotprofile.list', options):\n                profile['target'] = 'paas'\n                result.append((profile['id'], profile))\n\n        if not target or target == 'vm':\n            for profile in cls.safe_call('hosting.snapshotprofile.list',\n                                         options):\n                profile['target'] = 'vm'\n                result.append((profile['id'], profile))\n\n        result = sorted(result, key=lambda item: item[0])\n        return [profile for id_, profile in result]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef info(cls, resource):\n        snps = cls.list({'id': cls.usable_id(resource)})\n        if len(snps) == 1:\n            return snps[0]\n        elif not snps:\n            return\n\n        raise DuplicateResults('snapshot profile %s is ambiguous.' % resource)", "response": "Display information about a snapshot profile."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndisplaying records information about a domain.", "response": "def records(cls, fqdn, sort_by=None, text=False):\n        \"\"\"Display records information about a domain.\"\"\"\n        meta = cls.get_fqdn_info(fqdn)\n        url = meta['domain_records_href']\n        kwargs = {}\n        if text:\n            kwargs = {'headers': {'Accept': 'text/plain'}}\n        return cls.json_get(cls.get_sort_url(url, sort_by), **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates record for a domain.", "response": "def add_record(cls, fqdn, name, type, value, ttl):\n        \"\"\"Create record for a domain.\"\"\"\n        data = {\n            \"rrset_name\": name,\n            \"rrset_type\": type,\n            \"rrset_values\": value,\n        }\n        if ttl:\n            data['rrset_ttl'] = int(ttl)\n        meta = cls.get_fqdn_info(fqdn)\n        url = meta['domain_records_href']\n        return cls.json_post(url, data=json.dumps(data))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_record(cls, fqdn, name, type, value, ttl, content):\n        data = {\n            \"rrset_name\": name,\n            \"rrset_type\": type,\n            \"rrset_values\": value,\n        }\n        if ttl:\n            data['rrset_ttl'] = int(ttl)\n        meta = cls.get_fqdn_info(fqdn)\n        if content:\n            url = meta['domain_records_href']\n            kwargs = {'headers': {'Content-Type': 'text/plain'},\n                      'data': content}\n            return cls.json_put(url, **kwargs)\n\n        url = '%s/domains/%s/records/%s/%s' % (cls.api_url, fqdn, name, type)\n        return cls.json_put(url, data=json.dumps(data))", "response": "Update all records for a domain."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting a record for a domain.", "response": "def del_record(cls, fqdn, name, type):\n        \"\"\"Delete record for a domain.\"\"\"\n        meta = cls.get_fqdn_info(fqdn)\n        url = meta['domain_records_href']\n        delete_url = url\n        if name:\n            delete_url = '%s/%s' % (delete_url, name)\n        if type:\n            delete_url = '%s/%s' % (delete_url, type)\n        return cls.json_delete(delete_url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef keys(cls, fqdn, sort_by=None):\n        meta = cls.get_fqdn_info(fqdn)\n        url = meta['domain_keys_href']\n        return cls.json_get(cls.get_sort_url(url, sort_by))", "response": "Display keys information about a domain."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate new key entry for a domain.", "response": "def keys_create(cls, fqdn, flag):\n        \"\"\"Create new key entry for a domain.\"\"\"\n        data = {\n            \"flags\": flag,\n        }\n        meta = cls.get_fqdn_info(fqdn)\n        url = meta['domain_keys_href']\n        ret, headers = cls.json_post(url, data=json.dumps(data),\n                                     return_header=True)\n        return cls.json_get(headers['location'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef keys_delete(cls, fqdn, key):\n        return cls.json_delete('%s/domains/%s/keys/%s' %\n                               (cls.api_url, fqdn, key))", "response": "Delete a key for a domain."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrecovering deleted key for a domain.", "response": "def keys_recover(cls, fqdn, key):\n        \"\"\"Recover deleted key for a domain.\"\"\"\n        data = {\n            \"deleted\": False,\n        }\n        return cls.json_put('%s/domains/%s/keys/%s' % (cls.api_url, fqdn, key),\n                            data=json.dumps(data),)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndisplay information about a vlan.", "response": "def info(gandi, resource, ip):\n    \"\"\"Display information about a vlan.\"\"\"\n    output_keys = ['name', 'state', 'dc', 'subnet', 'gateway']\n\n    datacenters = gandi.datacenter.list()\n\n    vlan = gandi.vlan.info(resource)\n\n    gateway = vlan['gateway']\n    if not ip:\n        output_vlan(gandi, vlan, datacenters, output_keys, justify=11)\n        return vlan\n\n    gateway_exists = False\n\n    vms = dict([(vm_['id'], vm_) for vm_ in gandi.iaas.list()])\n    ifaces = gandi.vlan.ifaces(resource)\n\n    for iface in ifaces:\n        for ip in iface['ips']:\n            if gateway == ip['ip']:\n                gateway_exists = True\n\n    if gateway_exists:\n        vlan.pop('gateway')\n    else:\n        vlan['gateway'] = (\"%s don't exists\" % gateway if gateway\n                           else 'none')\n\n    output_vlan(gandi, vlan, datacenters, output_keys, justify=11)\n\n    output_keys = ['vm', 'bandwidth']\n    for iface in ifaces:\n        gandi.separator_line()\n        output_iface(gandi, iface, datacenters, vms, output_keys,\n                     justify=11)\n        for ip in iface['ips']:\n            output_ip(gandi, ip, None, None, None, ['ip'])\n            if gateway == ip['ip']:\n                output_line(gandi, 'gateway', 'true', justify=11)\n\n    return vlan"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a new vlan", "response": "def create(gandi, name, datacenter, subnet, gateway, background):\n    \"\"\" Create a new vlan \"\"\"\n    try:\n        gandi.datacenter.is_opened(datacenter, 'iaas')\n    except DatacenterLimited as exc:\n        gandi.echo('/!\\ Datacenter %s will be closed on %s, '\n                   'please consider using another datacenter.' %\n                   (datacenter, exc.date))\n\n    result = gandi.vlan.create(name, datacenter, subnet, gateway, background)\n\n    if background:\n        gandi.pretty_echo(result)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate a vlan ``gateway`` can be a vm name or id, or an ip.", "response": "def update(gandi, resource, name, gateway, create, bandwidth):\n    \"\"\" Update a vlan\n\n    ``gateway`` can be a vm name or id, or an ip.\n    \"\"\"\n    params = {}\n    if name:\n        params['name'] = name\n\n    vlan_id = gandi.vlan.usable_id(resource)\n\n    try:\n        if gateway:\n            IP(gateway)\n            params['gateway'] = gateway\n    except ValueError:\n        vm = gandi.iaas.info(gateway)\n        ips = [ip for sublist in\n               [[ip['ip'] for ip in iface['ips'] if ip['version'] == 4]\n                for iface in vm['ifaces']\n                if iface['vlan'] and iface['vlan'].get('id') == vlan_id]\n               for ip in sublist]\n\n        if len(ips) > 1:\n            gandi.echo(\"This vm has two ips in the vlan, don't know which one\"\n                       ' to choose (%s)' % (', '.join(ips)))\n            return\n\n        if not ips and not create:\n            gandi.echo(\"Can't find '%s' in '%s' vlan\" % (gateway, resource))\n            return\n\n        if not ips and create:\n            gandi.echo('Will create a new ip in this vlan for vm %s' % gateway)\n            oper = gandi.ip.create('4', vm['datacenter_id'], bandwidth,\n                                   vm['hostname'], resource)\n\n            iface_id = oper['iface_id']\n            iface = gandi.iface.info(iface_id)\n            ips = [ip['ip'] for ip in iface['ips'] if ip['version'] == 4]\n\n        params['gateway'] = ips[0]\n\n    result = gandi.vlan.update(resource, params)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_migration_choice(cls, datacenter):\n        datacenter_id = cls.usable_id(datacenter)\n        dc_list = cls.list()\n        available_dcs = [dc for dc in dc_list\n                         if dc['id'] == datacenter_id][0]['can_migrate_to']\n        choices = [dc for dc in dc_list\n                   if dc['id'] in available_dcs]\n        return choices", "response": "List available datacenters for migration from given datacenter."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_opened(cls, dc_code, type_):\n        options = {'dc_code': dc_code, '%s_opened' % type_: True}\n        datacenters = cls.safe_call('hosting.datacenter.list', options)\n        if not datacenters:\n            # try with ISO code\n            options = {'iso': dc_code, '%s_opened' % type_: True}\n            datacenters = cls.safe_call('hosting.datacenter.list', options)\n            if not datacenters:\n                raise DatacenterClosed(r'/!\\ Datacenter %s is closed, please '\n                                       'choose another datacenter.' % dc_code)\n\n        datacenter = datacenters[0]\n        if datacenter.get('%s_closed_for' % type_) == 'NEW':\n            dc_close_date = datacenter.get('deactivate_at', '')\n            if dc_close_date:\n                dc_close_date = dc_close_date.strftime('%d/%m/%Y')\n            raise DatacenterLimited(dc_close_date)", "response": "List opened datacenters for given type."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlist datacenters matching name and compatible with obj", "response": "def filtered_list(cls, name=None, obj=None):\n        \"\"\"List datacenters matching name and compatible\n        with obj\"\"\"\n        options = {}\n        if name:\n            options['id'] = cls.usable_id(name)\n\n        def obj_ok(dc, obj):\n            if not obj or obj['datacenter_id'] == dc['id']:\n                return True\n            return False\n\n        return [x for x in cls.list(options) if obj_ok(x, obj)]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving the first datacenter id associated to an ISO.", "response": "def from_iso(cls, iso):\n        \"\"\"Retrieve the first datacenter id associated to an ISO.\"\"\"\n        result = cls.list({'sort_by': 'id ASC'})\n        dc_isos = {}\n        for dc in result:\n            if dc['iso'] not in dc_isos:\n                dc_isos[dc['iso']] = dc['id']\n\n        return dc_isos.get(iso)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nretrieves datacenter id associated to a name.", "response": "def from_name(cls, name):\n        \"\"\"Retrieve datacenter id associated to a name.\"\"\"\n        result = cls.list()\n        dc_names = {}\n        for dc in result:\n            dc_names[dc['name']] = dc['id']\n\n        return dc_names.get(name)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_country(cls, country):\n        result = cls.list({'sort_by': 'id ASC'})\n        dc_countries = {}\n        for dc in result:\n            if dc['country'] not in dc_countries:\n                dc_countries[dc['country']] = dc['id']\n\n        return dc_countries.get(country)", "response": "Retrieve the first datacenter id associated to a country."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_dc_code(cls, dc_code):\n        result = cls.list()\n        dc_codes = {}\n        for dc in result:\n            if dc.get('dc_code'):\n                dc_codes[dc['dc_code']] = dc['id']\n\n        return dc_codes.get(dc_code)", "response": "Retrieve the datacenter id associated to a dc_code"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef usable_id(cls, id):\n        try:\n            # id is maybe a dc_code\n            qry_id = cls.from_dc_code(id)\n            if not qry_id:\n                # id is maybe a ISO\n                qry_id = cls.from_iso(id)\n                if qry_id:\n                    cls.deprecated('ISO code for datacenter filter use '\n                                   'dc_code instead')\n            if not qry_id:\n                # id is maybe a country\n                qry_id = cls.from_country(id)\n            if not qry_id:\n                qry_id = int(id)\n        except Exception:\n            qry_id = None\n\n        if not qry_id:\n            msg = 'unknown identifier %s' % id\n            cls.error(msg)\n\n        return qry_id", "response": "Retrieve id from input which can be ISO name country dc_code."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds local port in existing tunnels", "response": "def find_port(addr, user):\n    \"\"\"Find local port in existing tunnels\"\"\"\n    import pwd\n    home = pwd.getpwuid(os.getuid()).pw_dir\n    for name in os.listdir('%s/.ssh/' % home):\n        if name.startswith('unixpipe_%s@%s_' % (user, addr,)):\n            return int(name.split('_')[2])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding a free local port and allocate it", "response": "def new_port():\n    \"\"\"Find a free local port and allocate it\"\"\"\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM, socket.IPPROTO_TCP)\n    for i in range(12042, 16042):\n        try:\n            s.bind(('127.0.0.1', i))\n            s.close()\n            return i\n        except socket.error:\n            pass\n    raise Exception('No local port available')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _ssh_master_cmd(addr, user, command, local_key=None):\n    ssh_call = ['ssh', '-qNfL%d:127.0.0.1:12042' % find_port(addr, user),\n                '-o', 'ControlPath=~/.ssh/unixpipe_%%r@%%h_%d' %\n                       find_port(addr, user),\n                '-O', command, '%s@%s' % (user, addr,)]\n\n    if local_key:\n        ssh_call.insert(1, local_key)\n        ssh_call.insert(1, '-i')\n\n    return subprocess.call(ssh_call)", "response": "Exit or check ssh mux"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list(gandi, limit, step):\n    output_keys = ['id', 'type', 'step']\n\n    options = {\n        'step': step,\n        'items_per_page': limit,\n        'sort_by': 'date_created DESC'\n    }\n\n    result = gandi.oper.list(options)\n    for num, oper in enumerate(reversed(result)):\n        if num:\n            gandi.separator_line()\n        output_generic(gandi, oper, output_keys)\n\n    return result", "response": "List available resource types."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndisplay information about an operation.", "response": "def info(gandi, id):\n    \"\"\"Display information about an operation.\"\"\"\n    output_keys = ['id', 'type', 'step', 'last_error']\n\n    oper = gandi.oper.info(id)\n    output_generic(gandi, oper, output_keys)\n\n    return oper"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading global and local configuration files and update if needed.", "response": "def load_config(cls):\n        \"\"\" Load global and local configuration files and update if needed.\"\"\"\n        config_file = os.path.expanduser(cls.home_config)\n        global_conf = cls.load(config_file, 'global')\n        cls.load(cls.local_config, 'local')\n        # update global configuration if needed\n        cls.update_config(config_file, global_conf)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating configuration if needed.", "response": "def update_config(cls, config_file, config):\n        \"\"\" Update configuration if needed. \"\"\"\n        need_save = False\n        # delete old env key\n        if 'api' in config and 'env' in config['api']:\n            del config['api']['env']\n            need_save = True\n        # convert old ssh_key configuration entry\n        ssh_key = config.get('ssh_key')\n        sshkeys = config.get('sshkey')\n        if ssh_key and not sshkeys:\n            config.update({'sshkey': [ssh_key]})\n            need_save = True\n        elif ssh_key and sshkeys:\n            config.update({'sshkey': sshkeys.append(ssh_key)})\n            need_save = True\n        # remove old value\n        if ssh_key:\n            del config['ssh_key']\n            need_save = True\n\n        # save to disk\n        if need_save:\n            cls.save(config_file, config)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load(cls, filename, name=None):\n        if not os.path.exists(filename):\n            return {}\n        name = name or filename\n\n        if name not in cls._conffiles:\n            with open(filename) as fdesc:\n                content = yaml.load(fdesc, YAMLLoader)\n                # in case the file is empty\n                if content is None:\n                    content = {}\n                cls._conffiles[name] = content\n\n        return cls._conffiles[name]", "response": "Load the configuration from a file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsave configuration to a file.", "response": "def save(cls, filename, config):\n        \"\"\" Save configuration to yaml file. \"\"\"\n        mode = os.O_WRONLY | os.O_TRUNC | os.O_CREAT\n        with os.fdopen(os.open(filename, mode, 0o600), 'w') as fname:\n            yaml.safe_dump(config, fname, indent=4, default_flow_style=False)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete(cls, global_, key):\n        # first retrieve current configuration\n        scope = 'global' if global_ else 'local'\n        config = cls._conffiles.get(scope, {})\n        cls._del(scope, key)\n        conf_file = cls.home_config if global_ else cls.local_config\n        # save configuration to file\n        cls.save(os.path.expanduser(conf_file), config)", "response": "Delete key value pair from configuration file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(cls, key, default=None, separator='.', global_=False):\n        # first check environnment variables\n        # if we're not in global scope\n        if not global_:\n            ret = os.environ.get(key.upper().replace('.', '_'))\n            if ret is not None:\n                return ret\n\n        # then check in local and global configuration unless global_=True\n        scopes = ['global'] if global_ else ['local', 'global']\n        for scope in scopes:\n            ret = cls._get(scope, key, default, separator)\n            if ret is not None and ret != default:\n                return ret\n\n        if ret is None or ret == default:\n            return default", "response": "Retrieve a key value from loaded configuration."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef configure(cls, global_, key, val):\n        # first retrieve current configuration\n        scope = 'global' if global_ else 'local'\n        if scope not in cls._conffiles:\n            cls._conffiles[scope] = {}\n        config = cls._conffiles.get(scope, {})\n        # apply modification to fields\n        cls._set(scope, key, val)\n        conf_file = cls.home_config if global_ else cls.local_config\n        # save configuration to file\n        cls.save(os.path.expanduser(conf_file), config)", "response": "Update and save the current configuration value to file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef init_config(cls):\n        try:\n            # first load current conf and only overwrite needed params\n            # we don't want to reset everything\n            config_file = os.path.expanduser(cls.home_config)\n            config = cls.load(config_file, 'global')\n            cls._del('global', 'api.env')\n\n            hidden_apikey = '%s...' % cls.get('api.key', '')[:6]\n            apikey = click.prompt('Api key (xmlrpc)',\n                                  default=hidden_apikey)\n            if apikey == hidden_apikey:\n                # if default value then use actual value not hidden one\n                apikey = cls.get('api.key')\n            env_choice = click.Choice(list(cls.apienvs.keys()))\n            apienv = click.prompt('Environnment [production]/ote',\n                                  default=cls.default_apienv,\n                                  type=env_choice,\n                                  show_default=False)\n            sshkey = click.prompt('SSH keyfile',\n                                  default='~/.ssh/id_rsa.pub')\n            hidden_apikeyrest = '%s...' % cls.get('apirest.key', '')[:6]\n            apikeyrest = click.prompt('Api key (REST)',\n                                      default=hidden_apikeyrest)\n            if apikeyrest == hidden_apikeyrest:\n                # if default value then use actual value not hidden one\n                apikeyrest = cls.get('apirest.key')\n\n            config.update({\n                'api': {'key': apikey,\n                        'host': cls.apienvs[apienv]},\n            })\n            if apikeyrest:\n                config.update({\n                    'apirest': {'key': apikeyrest},\n                })\n\n            if sshkey is not None:\n                sshkey_file = os.path.expanduser(sshkey)\n                if os.path.exists(sshkey_file):\n                    config['sshkey'] = [sshkey_file]\n\n            directory = os.path.expanduser(os.path.dirname(config_file))\n            if not os.path.exists(directory):\n                mkpath(directory, 0o700)\n\n            # save to disk\n            cls.save(config_file, config)\n            # load in memory\n            cls.load(config_file, 'global')\n        except (KeyboardInterrupt, click.exceptions.Abort):\n            cls.echo('Aborted.')\n            sys.exit(1)", "response": "Initialize Gandi CLI configuration."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef info(gandi):\n    output_keys = ['handle', 'credit', 'prepaid']\n\n    account = gandi.account.all()\n    account['prepaid_info'] = gandi.contact.balance().get('prepaid', {})\n    output_account(gandi, account, output_keys)\n    return account", "response": "Display information about hosting account."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a public ip and attach it to the vm.", "response": "def create(cls, ip_version, datacenter, bandwidth, vm=None, vlan=None,\n               ip=None, background=False):\n        \"\"\" Create a public ip and attach it if vm is given. \"\"\"\n        return Iface.create(ip_version, datacenter, bandwidth, vlan, vm, ip,\n                            background)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef resource_list(cls):\n        items = cls.list({'items_per_page': 500})\n        ret = [str(ip['id']) for ip in items]\n        ret.extend([ip['ip'] for ip in items])\n        return ret", "response": "Get the possible list of resources."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef attach(cls, ip, vm, background=False, force=False):\n        vm_ = Iaas.info(vm)\n        ip_ = cls.info(ip)\n        if not cls._check_and_detach(ip_, vm_):\n            return\n\n        # then we should attach the ip to the vm\n        attach = Iface._attach(ip_['iface_id'], vm_['id'])\n        if not background:\n            cls.display_progress(attach)\n\n        return attach", "response": "Attach the ip to the vm"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete(cls, resources, background=False, force=False):\n        if not isinstance(resources, (list, tuple)):\n            resources = [resources]\n\n        ifaces = []\n        for item in resources:\n            try:\n                ip_ = cls.info(item)\n            except UsageError:\n                cls.error(\"Can't find this ip %s\" % item)\n\n            iface = Iface.info(ip_['iface_id'])\n            ifaces.append(iface['id'])\n\n        return Iface.delete(ifaces, background)", "response": "Delete an ip by deleting the iface"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_ip(cls, ip):\n        ips = dict([(ip_['ip'], ip_['id'])\n                    for ip_ in cls.list({'items_per_page': 500})])\n        return ips.get(ip)", "response": "Retrieve ip id associated to an ip."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist virtual machine vlan.", "response": "def list(cls, datacenter=None):\n        \"\"\"List virtual machine vlan\n\n        (in the future it should also handle PaaS vlan).\"\"\"\n        options = {}\n        if datacenter:\n            datacenter_id = int(Datacenter.usable_id(datacenter))\n            options['datacenter_id'] = datacenter_id\n\n        return cls.call('hosting.vlan.list', options)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the possible list of resources.", "response": "def resource_list(cls):\n        \"\"\" Get the possible list of resources (name, id). \"\"\"\n        items = cls.list()\n        ret = [vlan['name'] for vlan in items]\n        ret.extend([str(vlan['id']) for vlan in items])\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ifaces(cls, name):\n        ifaces = Iface.list({'vlan_id': cls.usable_id(name)})\n        ret = []\n        for iface in ifaces:\n            ret.append(Iface.info(iface['id']))\n        return ret", "response": "Get vlan attached ifaces."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create(cls, name, datacenter, subnet=None, gateway=None,\n               background=False):\n        \"\"\"Create a new vlan.\"\"\"\n        if not background and not cls.intty():\n            background = True\n\n        datacenter_id_ = int(Datacenter.usable_id(datacenter))\n\n        vlan_params = {\n            'name': name,\n            'datacenter_id': datacenter_id_,\n        }\n\n        if subnet:\n            vlan_params['subnet'] = subnet\n        if gateway:\n            vlan_params['gateway'] = gateway\n\n        result = cls.call('hosting.vlan.create', vlan_params)\n\n        if not background:\n            # interactive mode, run a progress bar\n            cls.echo('Creating your vlan.')\n            cls.display_progress(result)\n            cls.echo('Your vlan %s has been created.' % name)\n\n        return result", "response": "Create a new vlan."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update(cls, id, params):\n        cls.echo('Updating your vlan.')\n        result = cls.call('hosting.vlan.update', cls.usable_id(id), params)\n        return result", "response": "Update an existing vlan."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving vlan id associated to a name.", "response": "def from_name(cls, name):\n        \"\"\"Retrieve vlan id associated to a name.\"\"\"\n        result = cls.list()\n        vlans = {}\n        for vlan in result:\n            vlans[vlan['name']] = vlan['id']\n\n        return vlans.get(name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving id from input which can be num or id.", "response": "def usable_id(cls, id):\n        \"\"\" Retrieve id from input which can be num or id.\"\"\"\n        try:\n            qry_id = int(id)\n        except Exception:\n            qry_id = None\n\n        if not qry_id:\n            msg = 'unknown identifier %s' % id\n            cls.error(msg)\n\n        return qry_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nattaches an iface to a vm.", "response": "def _attach(cls, iface_id, vm_id):\n        \"\"\" Attach an iface to a vm. \"\"\"\n        oper = cls.call('hosting.vm.iface_attach', vm_id, iface_id)\n        return oper"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create(cls, ip_version, datacenter, bandwidth, vlan, vm, ip,\n               background):\n        \"\"\" Create a new iface \"\"\"\n        if not background and not cls.intty():\n            background = True\n\n        datacenter_id_ = int(Datacenter.usable_id(datacenter))\n\n        iface_params = {\n            'ip_version': ip_version,\n            'datacenter_id': datacenter_id_,\n            'bandwidth': bandwidth,\n        }\n        if vlan:\n            iface_params['vlan'] = Vlan.usable_id(vlan)\n            if ip:\n                iface_params['ip'] = ip\n\n        result = cls.call('hosting.iface.create', iface_params)\n\n        if background and not vm:\n            return result\n\n        # interactive mode, run a progress bar\n        cls.echo('Creating your iface.')\n        cls.display_progress(result)\n        iface_info = cls._info(result['iface_id'])\n        cls.echo('Your iface has been created with the following IP '\n                 'addresses:')\n        for _ip in iface_info['ips']:\n            cls.echo('ip%d:\\t%s' % (_ip['version'], _ip['ip']))\n\n        if not vm:\n            return result\n\n        vm_id = Iaas.usable_id(vm)\n        result = cls._attach(result['iface_id'], vm_id)\n\n        if background:\n            return result\n\n        cls.echo('Attaching your iface.')\n        cls.display_progress(result)\n        return result", "response": "Create a new iface."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndetach an iface from a vm.", "response": "def _detach(cls, iface_id):\n        \"\"\" Detach an iface from a vm. \"\"\"\n        iface = cls._info(iface_id)\n        opers = []\n        vm_id = iface.get('vm_id')\n        if vm_id:\n            cls.echo('The iface is still attached to the vm %s.' % vm_id)\n            cls.echo('Will detach it.')\n            opers.append(cls.call('hosting.vm.iface_detach', vm_id, iface_id))\n        return opers"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create(cls, domain, source, destinations):\n        cls.echo('Creating mail forward %s@%s' % (source, domain))\n        options = {'destinations': list(destinations)}\n        result = cls.call('domain.forward.create', domain, source, options)\n\n        return result", "response": "Create a domain mail forward."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate a domain mail forward destinations.", "response": "def update(cls, domain, source, dest_add, dest_del):\n        \"\"\"Update a domain mail forward destinations.\"\"\"\n        result = None\n\n        if dest_add or dest_del:\n            current_destinations = cls.get_destinations(domain, source)\n            fwds = current_destinations[:]\n            if dest_add:\n                for dest in dest_add:\n                    if dest not in fwds:\n                        fwds.append(dest)\n            if dest_del:\n                for dest in dest_del:\n                    if dest in fwds:\n                        fwds.remove(dest)\n\n            if ((len(current_destinations) != len(fwds))\n                    or (current_destinations != fwds)):\n                cls.echo('Updating mail forward %s@%s' % (source, domain))\n                options = {'destinations': fwds}\n                result = cls.call('domain.forward.update', domain, source,\n                                  options)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list(gandi, domain, limit):\n    options = {'items_per_page': limit}\n    mailboxes = gandi.mail.list(domain, options)\n    output_list(gandi, [mbox['login'] for mbox in mailboxes])\n    return mailboxes", "response": "List mailboxes created on a domain."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef info(gandi, email):\n    login, domain = email\n\n    output_keys = ['login', 'aliases', 'fallback', 'quota', 'responder']\n    mailbox = gandi.mail.info(domain, login)\n    output_mailbox(gandi, mailbox, output_keys)\n\n    return mailbox", "response": "Display information about a mailbox."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving a disk id associated to a name.", "response": "def from_name(cls, name):\n        \"\"\" Retrieve a disk id associated to a name. \"\"\"\n        disks = cls.list({'name': name})\n        if len(disks) == 1:\n            return disks[0]['id']\n        elif not disks:\n            return\n\n        raise DuplicateResults('disk name %s is ambiguous.' % name)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_create(cls, datacenter=None, label=None):\n        options = {\n            'items_per_page': DISK_MAXLIST\n        }\n        if datacenter:\n            datacenter_id = int(Datacenter.usable_id(datacenter))\n            options['datacenter_id'] = datacenter_id\n\n        # implement a filter by label as API doesn't handle it\n        images = cls.safe_call('hosting.disk.list', options)\n        if not label:\n            return images\n        return [img for img in images\n                if label.lower() in img['name'].lower()]", "response": "List available disks for vm creation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef disk_param(name, size, snapshot_profile, cmdline=None, kernel=None):\n        disk_params = {}\n\n        if cmdline:\n            disk_params['cmdline'] = cmdline\n\n        if kernel:\n            disk_params['kernel'] = kernel\n\n        if name:\n            disk_params['name'] = name\n\n        if snapshot_profile is not None:\n            disk_params['snapshot_profile'] = snapshot_profile\n\n        if size:\n            disk_params['size'] = size\n\n        return disk_params", "response": "Return disk parameter structure."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _detach(cls, disk_id):\n        disk = cls._info(disk_id)\n        opers = []\n        if disk.get('vms_id'):\n            for vm_id in disk['vms_id']:\n                cls.echo('The disk is still attached to the vm %s.' % vm_id)\n                cls.echo('Will detach it.')\n                opers.append(cls.call('hosting.vm.disk_detach',\n                                      vm_id, disk_id))\n        return opers", "response": "Detach a disk from a vm."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nattach a disk to a vm.", "response": "def _attach(cls, disk_id, vm_id, options=None):\n        \"\"\" Attach a disk to a vm. \"\"\"\n        options = options or {}\n        oper = cls.call('hosting.vm.disk_attach', vm_id, disk_id, options)\n        return oper"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create(cls, name, vm, size, snapshotprofile, datacenter,\n               source, disk_type='data', background=False):\n        \"\"\" Create a disk and attach it to a vm. \"\"\"\n        if isinstance(size, tuple):\n            prefix, size = size\n\n        if source:\n            size = None\n        disk_params = cls.disk_param(name, size, snapshotprofile)\n        disk_params['datacenter_id'] = int(Datacenter.usable_id(datacenter))\n        disk_params['type'] = disk_type\n\n        if source:\n            disk_id = int(Image.usable_id(source,\n                                          disk_params['datacenter_id']))\n            result = cls.call('hosting.disk.create_from', disk_params, disk_id)\n        else:\n            result = cls.call('hosting.disk.create', disk_params)\n\n        if background and not vm:\n            return result\n\n        # interactive mode, run a progress bar\n        cls.echo('Creating your disk.')\n        cls.display_progress(result)\n\n        if not vm:\n            return\n\n        vm_id = Iaas.usable_id(vm)\n        result = cls._attach(result['disk_id'], vm_id)\n\n        if background:\n            return result\n\n        cls.echo('Attaching your disk.')\n        cls.display_progress(result)", "response": "Create a new disk and attach it to a vm."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef migrate(cls, resource, datacenter_id, background=False):\n        disk_id = cls.usable_id(resource)\n        result = cls.call('hosting.disk.migrate', disk_id, datacenter_id)\n\n        if background:\n            return result\n\n        cls.echo('Disk migration in progress.')\n        cls.display_progress(result)\n        return result", "response": "Migrate a disk to another datacenter."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef format_commands(self, ctx, formatter):\n        rows = []\n\n        all_cmds = self.list_all_commands(ctx)\n        for cmd_name in sorted(all_cmds):\n            cmd = all_cmds[cmd_name]\n            help = cmd.short_help or ''\n            rows.append((cmd_name, help))\n\n        if rows:\n            with formatter.section('Commands'):\n                formatter.write_dl(rows)", "response": "Extra format methods for multi - command format"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_sub_commmands(self, cmd_name, cmd):\n        ret = {}\n        if isinstance(cmd, click.core.Group):\n            for sub_cmd_name in cmd.commands:\n                sub_cmd = cmd.commands[sub_cmd_name]\n                sub = self.list_sub_commmands(sub_cmd_name, sub_cmd)\n                if sub:\n                    if isinstance(sub, dict):\n                        for n, c in sub.items():\n                            ret['%s %s' % (cmd_name, n)] = c\n                    else:\n                        ret['%s %s' % (cmd_name, sub[0])] = sub[1]\n        elif isinstance(cmd, click.core.Command):\n            return (cmd.name, cmd)\n        return ret", "response": "Return all commands for a group"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload cli commands from submodules.", "response": "def load_commands(self):\n        \"\"\" Load cli commands from submodules. \"\"\"\n        command_folder = os.path.join(os.path.dirname(__file__),\n                                      '..', 'commands')\n        command_dirs = {\n            'gandi.cli': command_folder\n        }\n\n        if 'GANDICLI_PATH' in os.environ:\n            for _path in os.environ.get('GANDICLI_PATH').split(':'):\n                # remove trailing separator if any\n                path = _path.rstrip(os.sep)\n                command_dirs[os.path.basename(path)] = os.path.join(path,\n                                                                    'commands')\n\n        for module_basename, dir in list(command_dirs.items()):\n            for filename in sorted(os.listdir(dir)):\n                if filename.endswith('.py') and '__init__' not in filename:\n                    submod = filename[:-3]\n                    module_name = module_basename + '.commands.' + submod\n                    __import__(module_name, fromlist=[module_name])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef invoke(self, ctx):\n        ctx.obj = GandiContextHelper(verbose=ctx.obj['verbose'])\n        click.Group.invoke(self, ctx)", "response": "Invoke command in context."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve a sshkey id associated to a name.", "response": "def from_name(cls, name):\n        \"\"\"Retrieve a sshkey id associated to a name.\"\"\"\n        sshkeys = cls.list({'name': name})\n        if len(sshkeys) == 1:\n            return sshkeys[0]['id']\n        elif not sshkeys:\n            return\n\n        raise DuplicateResults('sshkey name %s is ambiguous.' % name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretrieve id from input which can be name or id.", "response": "def usable_id(cls, id):\n        \"\"\" Retrieve id from input which can be name or id.\"\"\"\n        try:\n            # id is maybe a sshkey name\n            qry_id = cls.from_name(id)\n            if not qry_id:\n                qry_id = int(id)\n        except DuplicateResults as exc:\n            cls.error(exc.errors)\n        except Exception:\n            qry_id = None\n\n        if not qry_id:\n            msg = 'unknown identifier %s' % id\n            cls.error(msg)\n\n        return qry_id"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create(cls, name, value):\n        sshkey_params = {\n            'name': name,\n            'value': value,\n        }\n\n        result = cls.call('hosting.ssh.create', sshkey_params)\n        return result", "response": "Create a new ssh key."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef convert_sshkey(cls, sshkey):\n        params = {}\n        if sshkey:\n            params['keys'] = []\n            for ssh in sshkey:\n                if os.path.exists(os.path.expanduser(ssh)):\n                    if 'ssh_key' in params:\n                        cls.echo(\"Can't have more than one sshkey file.\")\n                        continue\n                    with open(ssh) as fdesc:\n                        sshkey_ = fdesc.read()\n                    if sshkey_:\n                        params['ssh_key'] = sshkey_\n                else:\n                    sshkey_id = Sshkey.usable_id(ssh)\n                    if sshkey_id:\n                        params['keys'].append(sshkey_id)\n                    else:\n                        cls.echo('This is not a ssh key %s' % ssh)\n\n            if not params['keys']:\n                params.pop('keys')\n\n        return params", "response": "Return dict param with valid entries for vm / paas methods."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_api_connector(cls):\n        if cls._api is None:  # pragma: no cover\n            cls.load_config()\n            cls.debug('initialize connection to remote server')\n            apihost = cls.get('api.host')\n            if not apihost:\n                raise MissingConfiguration()\n\n            apienv = cls.get('api.env')\n            if apienv and apienv in cls.apienvs:\n                apihost = cls.apienvs[apienv]\n\n            cls._api = XMLRPCClient(host=apihost, debug=cls.verbose)\n\n        return cls._api", "response": "Initialize an api connector for future use."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef call(cls, method, *args, **kwargs):\n        api = None\n        empty_key = kwargs.pop('empty_key', False)\n        try:\n            api = cls.get_api_connector()\n            apikey = cls.get('api.key')\n            if not apikey and not empty_key:\n                cls.echo(\"No apikey found, please use 'gandi setup' \"\n                         \"command\")\n                sys.exit(1)\n        except MissingConfiguration:\n            if api and empty_key:\n                apikey = ''\n            elif not kwargs.get('safe'):\n                cls.echo(\"No configuration found, please use 'gandi setup' \"\n                         \"command\")\n                sys.exit(1)\n            else:\n                return []\n\n        # make the call\n        cls.debug('calling method: %s' % method)\n        for arg in args:\n            cls.debug('with params: %r' % arg)\n        try:\n            resp = api.request(method, apikey, *args,\n                               **{'dry_run': kwargs.get('dry_run', False),\n                                  'return_dry_run':\n                                  kwargs.get('return_dry_run', False)})\n            cls.dump('responded: %r' % resp)\n            return resp\n        except APICallFailed as err:\n            if kwargs.get('safe'):\n                return []\n            if err.code == 530040:\n                cls.echo(\"Error: It appears you haven't purchased any credits \"\n                         \"yet.\\n\"\n                         \"Please visit https://www.gandi.net/credit/buy to \"\n                         \"learn more and buy credits.\")\n                sys.exit(1)\n            if err.code == 510150:\n                cls.echo(\"Invalid API key, please use 'gandi setup' command.\")\n                sys.exit(1)\n            if isinstance(err, DryRunException):\n                if kwargs.get('return_dry_run', False):\n                    return err.dry_run\n                else:\n                    for msg in err.dry_run:\n                        # TODO use trads with %s\n                        cls.echo(msg['reason'])\n                        cls.echo('\\t' + ' '.join(msg['attr']))\n                    sys.exit(1)\n            error = UsageError(err.errors)\n            setattr(error, 'code', err.code)\n            raise error", "response": "Call a remote API method and return the result."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncall a remote api method but don t raise if an error occurred.", "response": "def safe_call(cls, method, *args):\n        \"\"\" Call a remote api method but don't raise if an error occurred.\"\"\"\n        return cls.call(method, *args, safe=True)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef json_call(cls, method, url, **kwargs):\n        # retrieve api key if needed\n        empty_key = kwargs.pop('empty_key', False)\n        send_key = kwargs.pop('send_key', True)\n        return_header = kwargs.pop('return_header', False)\n        try:\n            apikey = cls.get('apirest.key')\n            if not apikey and not empty_key:\n                cls.echo(\"No apikey found for REST API, please use \"\n                         \"'gandi setup' command\")\n                sys.exit(1)\n            if send_key:\n                if 'headers' in kwargs:\n                    kwargs['headers'].update({'X-Api-Key': apikey})\n                else:\n                    kwargs['headers'] = {'X-Api-Key': apikey}\n        except MissingConfiguration:\n            if not empty_key:\n                return []\n        # make the call\n        cls.debug('calling url: %s %s' % (method, url))\n        cls.debug('with params: %r' % kwargs)\n        try:\n            resp, resp_headers = JsonClient.request(method, url, **kwargs)\n            cls.dump('responded: %r' % resp)\n            if return_header:\n                return resp, resp_headers\n            return resp\n        except APICallFailed as err:\n            cls.echo('An error occured during call: %s' % err.errors)\n            sys.exit(1)", "response": "Call a remote API using json format"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if we are in a tty.", "response": "def intty(cls):\n        \"\"\" Check if we are in a tty. \"\"\"\n        # XXX: temporary hack until we can detect if we are in a pipe or not\n        return True\n\n        if hasattr(sys.stdout, 'isatty') and sys.stdout.isatty():\n            return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pretty_echo(cls, message):\n        if cls.intty():\n            if message:\n                from pprint import pprint\n                pprint(message)", "response": "Display message using pretty print formatting."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef separator_line(cls, sep='-', size=10):\n        if cls.intty():\n            cls.echo(sep * size)", "response": "Display a separator line."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef separator_sub_line(cls, sep='-', size=10):\n        if cls.intty():\n            cls.echo(\"\\t\" + sep * size)", "response": "Display a separator line."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dump(cls, message):\n        if cls.verbose > 2:\n            msg = '[DUMP] %s' % message\n            cls.echo(msg)", "response": "Display dump message if verbose level allows it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef debug(cls, message):\n        if cls.verbose > 1:\n            msg = '[DEBUG] %s' % message\n            cls.echo(msg)", "response": "Display debug message if verbose level allows it."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef log(cls, message):\n        if cls.verbose > 0:\n            msg = '[INFO] %s' % message\n            cls.echo(msg)", "response": "Display info message if verbose level allows it."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef execute(cls, command, shell=True):\n        cls.debug('execute command (shell flag:%r): %r ' % (shell, command))\n        try:\n            check_call(command, shell=shell)\n            return True\n        except CalledProcessError:\n            return False", "response": "Execute a command and return True if successful False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexecute a command and return the output of the command", "response": "def exec_output(cls, command, shell=True, encoding='utf-8'):\n        \"\"\" Return execution output\n\n        :param encoding: charset used to decode the stdout\n        :type encoding: str\n\n        :return: the return of the command\n        :rtype: unicode string\n        \"\"\"\n        proc = Popen(command, shell=shell, stdout=PIPE)\n        stdout, _stderr = proc.communicate()\n        if proc.returncode == 0:\n            return stdout.decode(encoding)\n\n        return ''"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_progress(cls, progress, starttime):\n        width, _height = click.get_terminal_size()\n        if not width:\n            return\n\n        duration = datetime.utcnow() - starttime\n        hours, remainder = divmod(duration.seconds, 3600)\n        minutes, seconds = divmod(remainder, 60)\n\n        size = int(width * .6)\n        status = \"\"\n        if isinstance(progress, int):\n            progress = float(progress)\n        if not isinstance(progress, float):\n            progress = 0\n            status = 'error: progress var must be float\\n'\n            cls.echo(type(progress))\n        if progress < 0:\n            progress = 0\n            status = 'Halt...\\n'\n        if progress >= 1:\n            progress = 1\n            # status = 'Done...\\n'\n        block = int(round(size * progress))\n        text = ('\\rProgress: [{0}] {1:.2%} {2} {3:0>2}:{4:0>2}:{5:0>2}  '\n                ''.format('#' * block + '-' * (size - block), progress,\n                          status, hours, minutes, seconds))\n        sys.stdout.write(text)\n        sys.stdout.flush()", "response": "Display a progress bar while processing the operation."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef display_progress(cls, operations):\n        start_crea = datetime.utcnow()\n\n        # count number of operations, 3 steps per operation\n        if not isinstance(operations, (list, tuple)):\n            operations = [operations]\n        count_operations = len(operations) * 3\n        updating_done = False\n        while not updating_done:\n            op_score = 0\n            for oper in operations:\n                op_ret = cls.call('operation.info', oper['id'])\n                op_step = op_ret['step']\n                if op_step in cls._op_scores:\n                    op_score += cls._op_scores[op_step]\n                else:\n                    cls.echo('')\n                    msg = 'step %s unknown, exiting' % op_step\n                    if op_step == 'ERROR':\n                        msg = ('An error has occured during operation '\n                               'processing: %s' % op_ret['last_error'])\n                    elif op_step == 'SUPPORT':\n                        msg = ('An error has occured during operation '\n                               'processing, you must contact Gandi support.')\n                    cls.echo(msg)\n                    sys.exit(1)\n\n            cls.update_progress(float(op_score) / count_operations,\n                                start_crea)\n\n            if op_score == count_operations:\n                updating_done = True\n\n            time.sleep(cls._poll_freq)\n\n        cls.echo('\\r')", "response": "Display progress of Gandi operations."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_modules(self):\n        module_folder = os.path.join(os.path.dirname(__file__),\n                                     '..', 'modules')\n        module_dirs = {\n            'gandi.cli': module_folder\n        }\n\n        if 'GANDICLI_PATH' in os.environ:\n            for _path in os.environ.get('GANDICLI_PATH').split(':'):\n                # remove trailing separator if any\n                path = _path.rstrip(os.sep)\n                module_dirs[os.path.basename(path)] = os.path.join(path,\n                                                                   'modules')\n\n        for module_basename, dir in list(module_dirs.items()):\n            for filename in sorted(os.listdir(dir)):\n                if filename.endswith('.py') and '__init__' not in filename:\n                    submod = filename[:-3]\n                    module_name = module_basename + '.modules.' + submod\n                    __import__(module_name, fromlist=[module_name])\n\n        # save internal map of loaded module classes\n        for subclass in GandiModule.__subclasses__():\n            self._modules[subclass.__name__.lower()] = subclass", "response": "Import CLI commands modules."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef request(self, method, apikey, *args, **kwargs):\n        dry_run = kwargs.get('dry_run', False)\n        return_dry_run = kwargs.get('return_dry_run', False)\n        if return_dry_run:\n            args[-1]['--dry-run'] = True\n\n        try:\n            func = getattr(self.endpoint, method)\n            return func(apikey, *args)\n        except (socket.error, requests.exceptions.ConnectionError):\n            msg = 'Gandi API service is unreachable'\n            raise APICallFailed(msg)\n        except xmlrpclib.Fault as err:\n            msg = 'Gandi API has returned an error: %s' % err\n            if dry_run:\n                args[-1]['--dry-run'] = True\n                ret = func(apikey, *args)\n                raise DryRunException(msg, err.faultCode, ret)\n            raise APICallFailed(msg, err.faultCode)\n        except TypeError as err:\n            msg = 'An unknown error has occurred: %s' % err\n            raise APICallFailed(msg)", "response": "Make a xml - rpc call to the remote API."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmake a http call to a remote API and return a json response.", "response": "def request(cls, method, url, **kwargs):\n        \"\"\"Make a http call to a remote API and return a json response.\"\"\"\n        user_agent = 'gandi.cli/%s' % __version__\n\n        headers = {'User-Agent': user_agent,\n                   'Content-Type': 'application/json; charset=utf-8'}\n        if kwargs.get('headers'):\n            headers.update(kwargs.pop('headers'))\n        try:\n            response = requests.request(method, url, headers=headers,\n                                        **kwargs)\n            response.raise_for_status()\n            try:\n                return response.json(), response.headers\n            except ValueError as err:\n                return response.text, response.headers\n        except (socket.error, requests.exceptions.ConnectionError):\n            msg = 'Remote API service is unreachable'\n            raise APICallFailed(msg)\n        except Exception as err:\n            if isinstance(err, requests.HTTPError):\n                try:\n                    resp = response.json()\n                except Exception:\n                    msg = 'An unknown error has occurred: %s' % err\n                    raise APICallFailed(msg)\n\n                if resp.get('message'):\n                    error = resp.get('message')\n                if resp.get('errors'):\n                    error = cls.format_errors(resp.get('errors'))\n                msg = '%s: %s' % (err, error)\n            else:\n                msg = 'An unknown error has occurred: %s' % err\n            raise APICallFailed(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef query(cls, resources, time_range, query, resource_type, sampler):\n        if not isinstance(resources, (list, tuple)):\n            resources = [resources]\n\n        now = time.time()\n        start_utc = datetime.utcfromtimestamp(now - time_range)\n        end_utc = datetime.utcfromtimestamp(now)\n        date_format = '%Y-%m-%d %H:%M:%S'\n        start = start_utc.strftime(date_format)\n        end = end_utc.strftime(date_format)\n        query = {'start': start,\n                 'end': end,\n                 'query': query,\n                 'resource_id': resources,\n                 'resource_type': resource_type,\n                 'sampler': sampler}\n        return cls.call('hosting.metric.query', query)", "response": "Query statistics for given resources."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef resource_list(cls):\n        items = cls.list({'items_per_page': 500})\n        ret = [vm['hostname'] for vm in items]\n        ret.extend([str(vm['id']) for vm in items])\n        return ret", "response": "Get the possible list of resources."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef required_max_memory(cls, id, memory):\n        best = int(max(2 ** math.ceil(math.log(memory, 2)), 2048))\n\n        actual_vm = cls.info(id)\n\n        if (actual_vm['state'] == 'running'\n                and actual_vm['vm_max_memory'] != best):\n            return best", "response": "Recommend a max_memory setting for this vm given memory."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update(cls, id, memory, cores, console, password, background,\n               max_memory):\n        \"\"\"Update a virtual machine.\"\"\"\n        if not background and not cls.intty():\n            background = True\n\n        vm_params = {}\n\n        if memory:\n            vm_params['memory'] = memory\n\n        if cores:\n            vm_params['cores'] = cores\n\n        if console:\n            vm_params['console'] = console\n\n        if password:\n            vm_params['password'] = password\n\n        if max_memory:\n            vm_params['vm_max_memory'] = max_memory\n\n        result = cls.call('hosting.vm.update', cls.usable_id(id), vm_params)\n        if background:\n            return result\n\n        # interactive mode, run a progress bar\n        cls.echo('Updating your Virtual Machine %s.' % id)\n        cls.display_progress(result)", "response": "Update a virtual machine."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new virtual machine.", "response": "def create(cls, datacenter, memory, cores, ip_version, bandwidth,\n               login, password, hostname, image, run, background, sshkey,\n               size, vlan, ip, script, script_args, ssh):\n        \"\"\"Create a new virtual machine.\"\"\"\n        from gandi.cli.modules.network import Ip, Iface\n        if not background and not cls.intty():\n            background = True\n\n        datacenter_id_ = int(Datacenter.usable_id(datacenter))\n\n        if not hostname:\n            hostname = randomstring('vm')\n            disk_name = 'sys_%s' % hostname[2:]\n        else:\n            disk_name = 'sys_%s' % hostname.replace('.', '')\n\n        vm_params = {\n            'hostname': hostname,\n            'datacenter_id': datacenter_id_,\n            'memory': memory,\n            'cores': cores,\n        }\n\n        if login:\n            vm_params['login'] = login\n\n        if run:\n            vm_params['run'] = run\n\n        if password:\n            vm_params['password'] = password\n\n        if ip_version:\n            vm_params['ip_version'] = ip_version\n            vm_params['bandwidth'] = bandwidth\n\n        if script:\n            with open(script) as fd:\n                vm_params['script'] = fd.read()\n            if script_args:\n                vm_params['script_args'] = script_args\n\n        vm_params.update(cls.convert_sshkey(sshkey))\n\n        # XXX: name of disk is limited to 15 chars in ext2fs, ext3fs\n        # but api allow 255, so we limit to 15 for now\n        disk_params = {'datacenter_id': vm_params['datacenter_id'],\n                       'name': disk_name[:15]}\n\n        if size:\n            if isinstance(size, tuple):\n                prefix, size = size\n            disk_params['size'] = size\n\n        sys_disk_id_ = int(Image.usable_id(image, datacenter_id_))\n\n        ip_summary = []\n        if ip_version == 4:\n            ip_summary = ['v4', 'v6']\n        elif ip_version == 6:\n            ip_summary = ['v6']\n\n        if vlan:\n            ip_ = None\n            ip_summary.append('private')\n            if ip:\n                try:\n                    ip_ = Ip.info(ip)\n                except Exception:\n                    pass\n                else:\n                    if not Ip._check_and_detach(ip_, None):\n                        return\n            if ip_:\n                iface_id = ip_['iface_id']\n            else:\n                ip_create = Ip.create(4,\n                                      vm_params['datacenter_id'],\n                                      bandwidth,\n                                      None,\n                                      vlan,\n                                      ip)\n\n                iface_id = ip_create['iface_id']\n\n            # if there is a public ip, will attach this one later, else give\n            # the iface to vm.create\n            if not ip_version:\n                vm_params['iface_id'] = iface_id\n\n        result = cls.call('hosting.vm.create_from', vm_params, disk_params,\n                          sys_disk_id_)\n\n        cls.echo('* Configuration used: %d cores, %dMb memory, ip %s, '\n                 'image %s, hostname: %s, datacenter: %s' %\n                 (cores, memory, '+'.join(ip_summary), image, hostname,\n                  datacenter))\n\n        # background mode, bail out now (skip interactive part)\n        if background and (not vlan or not ip_version):\n            return result\n\n        # interactive mode, run a progress bar\n        cls.echo('Creating your Virtual Machine %s.' % hostname)\n        cls.display_progress(result)\n        cls.echo('Your Virtual Machine %s has been created.' % hostname)\n\n        vm_id = None\n        for oper in result:\n            if oper.get('vm_id'):\n                vm_id = oper.get('vm_id')\n                break\n\n        if vlan and ip_version:\n            attach = Iface._attach(iface_id, vm_id)\n            if background:\n                return attach\n\n        if 'ssh_key' not in vm_params and 'keys' not in vm_params:\n            return\n\n        if vm_id and ip_version:\n            cls.wait_for_sshd(vm_id)\n            if ssh:\n                cls.ssh_keyscan(vm_id)\n                cls.ssh(vm_id, 'root', None)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef need_finalize(cls, resource):\n        vm_id = cls.usable_id(resource)\n        params = {'type': 'hosting_migration_vm',\n                  'step': 'RUN',\n                  'vm_id': vm_id}\n        result = cls.call('operation.list', params)\n        if not result or len(result) > 1:\n            raise MigrationNotFinalized('Cannot find VM %s '\n                                        'migration operation.' % resource)\n\n        need_finalize = result[0]['params']['inner_step'] == 'wait_finalize'\n        if not need_finalize:\n            raise MigrationNotFinalized('VM %s migration does not need '\n                                        'finalization.' % resource)", "response": "Check if vm migration need to be finalized."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_can_migrate(cls, resource):\n        vm_id = cls.usable_id(resource)\n        result = cls.call('hosting.vm.can_migrate', vm_id)\n\n        if not result['can_migrate']:\n            if result['matched']:\n                matched = result['matched'][0]\n                cls.echo('Your VM %s cannot be migrated yet. Migration will '\n                         'be available when datacenter %s is opened.'\n                         % (resource, matched))\n            else:\n                cls.echo('Your VM %s cannot be migrated.' % resource)\n            return False\n\n        return True", "response": "Check if virtual machine can be migrated to another datacenter."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmigrating a virtual machine to another datacenter.", "response": "def migrate(cls, resource, background=False, finalize=False):\n        \"\"\" Migrate a virtual machine to another datacenter. \"\"\"\n        vm_id = cls.usable_id(resource)\n        if finalize:\n            verb = 'Finalizing'\n            result = cls.call('hosting.vm.migrate', vm_id, True)\n        else:\n            verb = 'Starting'\n            result = cls.call('hosting.vm.migrate', vm_id, False)\n\n        dcs = {}\n        for dc in Datacenter.list():\n            dcs[dc['id']] = dc['dc_code']\n\n        oper = cls.call('operation.info', result['id'])\n        dc_from = dcs[oper['params']['from_dc_id']]\n        dc_to = dcs[oper['params']['to_dc_id']]\n        migration_msg = ('* %s the migration of VM %s '\n                         'from datacenter %s to %s'\n                         % (verb, resource, dc_from, dc_to))\n        cls.echo(migration_msg)\n\n        if background:\n            return result\n\n        cls.echo('VM migration in progress.')\n        cls.display_progress(result)\n        cls.echo('Your VM %s has been migrated.' % resource)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves virtual machine id associated to a hostname.", "response": "def from_hostname(cls, hostname):\n        \"\"\"Retrieve virtual machine id associated to a hostname.\"\"\"\n        result = cls.list({'hostname': str(hostname)})\n        if result:\n            return result[0]['id']"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the first usable ip address for this vm.", "response": "def vm_ip(cls, vm_id):\n        \"\"\"Return the first usable ip address for this vm.\n        Returns a (version, ip) tuple.\"\"\"\n        vm_info = cls.info(vm_id)\n\n        for iface in vm_info['ifaces']:\n            if iface['type'] == 'private':\n                continue\n            for ip in iface['ips']:\n                return ip['version'], ip['ip']"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef wait_for_sshd(cls, vm_id):\n        cls.echo('Waiting for the vm to come online')\n        version, ip_addr = cls.vm_ip(vm_id)\n        give_up = time.time() + 300\n        last_error = None\n        while time.time() < give_up:\n            try:\n                inet = socket.AF_INET\n                if version == 6:\n                    inet = socket.AF_INET6\n                sd = socket.socket(inet, socket.SOCK_STREAM,\n                                   socket.IPPROTO_TCP)\n                sd.settimeout(5)\n                sd.connect((ip_addr, 22))\n                sd.recv(1024)\n                return\n            except socket.error as err:\n                if err.errno == errno.EHOSTUNREACH and version == 6:\n                    cls.error('%s is not reachable, you may be missing '\n                              'IPv6 connectivity' % ip_addr)\n                last_error = err\n                time.sleep(1)\n            except Exception as err:\n                last_error = err\n                time.sleep(1)\n        cls.error('VM did not spin up (last error: %s)' % last_error)", "response": "Waits for the vm to come online and returns the SSHD object"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwipes this old key and learn the new one from a freshly - created VM.", "response": "def ssh_keyscan(cls, vm_id):\n        \"\"\"Wipe this old key and learn the new one from a freshly\n        created vm. This is a security risk for this VM, however\n        we dont have another way to learn the key yet, so do this\n        for the user.\"\"\"\n        cls.echo('Wiping old key and learning the new one')\n        _version, ip_addr = cls.vm_ip(vm_id)\n        cls.execute('ssh-keygen -R \"%s\"' % ip_addr)\n\n        for _ in range(5):\n            output = cls.exec_output('ssh-keyscan \"%s\"' % ip_addr)\n            if output:\n                with open(os.path.expanduser('~/.ssh/known_hosts'), 'a') as f:\n                    f.write(output)\n                return True\n            time.sleep(.5)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncopy file to remote VM.", "response": "def scp(cls, vm_id, login, identity, local_file, remote_file):\n        \"\"\"Copy file to remote VM.\"\"\"\n        cmd = ['scp']\n        if identity:\n            cmd.extend(('-i', identity,))\n\n        version, ip_addr = cls.vm_ip(vm_id)\n        if version == 6:\n            ip_addr = '[%s]' % ip_addr\n\n        cmd.extend((local_file, '%s@%s:%s' %\n                    (login, ip_addr, remote_file),))\n        cls.echo('Running %s' % ' '.join(cmd))\n        for _ in range(5):\n            ret = cls.execute(cmd, False)\n            if ret:\n                break\n            time.sleep(.5)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nspawns an ssh session to virtual machine.", "response": "def ssh(cls, vm_id, login, identity, args=None):\n        \"\"\"Spawn an ssh session to virtual machine.\"\"\"\n        cmd = ['ssh']\n        if identity:\n            cmd.extend(('-i', identity,))\n\n        version, ip_addr = cls.vm_ip(vm_id)\n        if version == 6:\n            cmd.append('-6')\n\n        if not ip_addr:\n            cls.echo('No IP address found for vm %s, aborting.' % vm_id)\n            return\n\n        cmd.append('%s@%s' % (login, ip_addr,))\n\n        if args:\n            cmd.extend(args)\n\n        cls.echo('Requesting access using: %s ...' % ' '.join(cmd))\n        return cls.execute(cmd, False)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nopen a console to virtual machine.", "response": "def console(cls, id):\n        \"\"\"Open a console to virtual machine.\"\"\"\n        vm_info = cls.info(id)\n        if not vm_info['console']:\n            # first activate console\n            cls.update(id, memory=None, cores=None, console=True,\n                       password=None, background=False, max_memory=None)\n        # now we can connect\n        # retrieve ip of vm\n        vm_info = cls.info(id)\n        version, ip_addr = cls.vm_ip(id)\n\n        console_url = vm_info.get('console_url', 'console.gandi.net')\n        access = 'ssh %s@%s' % (ip_addr, console_url)\n        cls.execute(access)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_deprecated(cls, label, datacenter=None):\n        images = cls.list(datacenter, label)\n        images_visibility = dict([(image['label'], image['visibility'])\n                                  for image in images])\n        return images_visibility.get(label, 'all') == 'deprecated'", "response": "Check if image is flagged as deprecated."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_label(cls, label, datacenter=None):\n        result = cls.list(datacenter=datacenter)\n        image_labels = dict([(image['label'], image['disk_id'])\n                             for image in result])\n\n        return image_labels.get(label)", "response": "Retrieve disk image id associated to a label."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretrieve disk id from available system disks", "response": "def from_sysdisk(cls, label):\n        \"\"\"Retrieve disk id from available system disks\"\"\"\n        disks = cls.safe_call('hosting.disk.list', {'name': label})\n        if len(disks):\n            return disks[0]['id']"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef usable_id(cls, id, datacenter=None):\n        try:\n            qry_id = int(id)\n        except Exception:\n            # if id is a string, prefer a system disk then a label\n            qry_id = cls.from_sysdisk(id) or cls.from_label(id, datacenter)\n\n        if not qry_id:\n            msg = 'unknown identifier %s' % id\n            cls.error(msg)\n\n        return qry_id", "response": "Retrieve id from input which can be label or id."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list(cls, datacenter=None, flavor=None, match='', exact_match=False):\n        if not datacenter:\n            dc_ids = [dc['id'] for dc in Datacenter.filtered_list()]\n            kmap = {}\n            for dc_id in dc_ids:\n                vals = cls.safe_call('hosting.disk.list_kernels', dc_id)\n                for key in vals:\n                    kmap.setdefault(key, []).extend(vals.get(key, []))\n            # remove duplicates\n            for key in kmap:\n                kmap[key] = list(set(kmap[key]))\n        else:\n            dc_id = Datacenter.usable_id(datacenter)\n            kmap = cls.safe_call('hosting.disk.list_kernels', dc_id)\n\n        if match:\n            for flav in kmap:\n                if exact_match:\n                    kmap[flav] = [x for x in kmap[flav] if match == x]\n                else:\n                    kmap[flav] = [x for x in kmap[flav] if match in x]\n        if flavor:\n            if flavor not in kmap:\n                cls.error('flavor %s not supported here' % flavor)\n            return dict([(flavor, kmap[flavor])])\n\n        return kmap", "response": "List available kernels for datacenter."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if kernel is available for disk.", "response": "def is_available(cls, disk, kernel):\n        \"\"\" Check if kernel is available for disk.\"\"\"\n        kmap = cls.list(disk['datacenter_id'], None, kernel, True)\n        for flavor in kmap:\n            if kernel in kmap[flavor]:\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clone(cls, name, vhost, directory, origin):\n        paas_info = cls.info(name)\n\n        if 'php' in paas_info['type'] and not vhost:\n            cls.error('PHP instances require indicating the VHOST to clone '\n                      'with --vhost <vhost>')\n\n        paas_access = '%s@%s' % (paas_info['user'], paas_info['git_server'])\n        remote_url = 'ssh+git://%s/%s.git' % (paas_access, vhost)\n\n        command = 'git clone %s %s --origin %s' \\\n                  % (remote_url, directory, origin)\n\n        init_git = cls.execute(command)\n        if init_git:\n            cls.echo('Use `git push %s master` to push your code to the '\n                     'instance.' % (origin))\n            cls.echo('Then `$ gandi deploy` to build and deploy your '\n                     'application.')", "response": "Clone a PaaS instance s vhost into a local git repository."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nattaching an instance s vhost to a remote from the local git repository.", "response": "def attach(cls, name, vhost, remote_name):\n        \"\"\"Attach an instance's vhost to a remote from the local repository.\"\"\"\n        paas_access = cls.get('paas_access')\n\n        if not paas_access:\n            paas_info = cls.info(name)\n            paas_access = '%s@%s' \\\n                          % (paas_info['user'], paas_info['git_server'])\n\n        remote_url = 'ssh+git://%s/%s.git' % (paas_access, vhost)\n\n        ret = cls.execute('git remote add %s %s' % (remote_name, remote_url,))\n\n        if ret:\n            cls.echo('Added remote `%s` to your local git repository.'\n                     % (remote_name))\n            cls.echo('Use `git push %s master` to push your code to the '\n                     'instance.' % (remote_name))\n            cls.echo('Then `$ gandi deploy` to build and deploy your '\n                     'application.')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndeploy a PaaS instance.", "response": "def deploy(cls, remote_name, branch):\n        \"\"\"Deploy a PaaS instance.\"\"\"\n        def get_remote_url(remote):\n            return 'git config --local --get remote.%s.url' % (remote)\n\n        remote_url = cls.exec_output(get_remote_url(remote_name)) \\\n            .replace('\\n', '')\n\n        if not remote_url or not re.search('gpaas.net|gandi.net', remote_url):\n            remote_name = ('$(git config --local --get branch.%s.remote)' %\n                           branch)\n            remote_url = cls.exec_output(get_remote_url(remote_name)) \\\n                .replace('\\n', '')\n\n        error = None\n\n        if not remote_url:\n            error = True\n            cls.echo('Error: Could not find git remote '\n                     'to extract deploy url from.')\n        elif not re.search('gpaas.net|gandi.net', remote_url):\n            error = True\n            cls.echo('Error: %s is not a valid Simple Hosting git remote.'\n                     % (remote_url))\n        if error:\n            cls.echo(\"\"\"This usually happens when:\n- the current directory has no Simple Hosting git remote attached,\n  in this case, please see $ gandi paas attach --help\n- the local branch being deployed hasn't been pushed to the \\\nremote repository yet,\n  in this case, please try $ git push <remote> %s\n\"\"\" % (branch))\n            cls.echo('Otherwise, it\\'s recommended to use'\n                     ' the --remote and/or --branch options:\\n'\n                     '$ gandi deploy --remote <remote> [--branch <branch>]')\n            sys.exit(2)\n\n        remote_url_no_protocol = remote_url.split('://')[1]\n        splitted_url = remote_url_no_protocol.split('/')\n\n        paas_access = splitted_url[0]\n        deploy_git_host = splitted_url[1]\n\n        command = \"ssh %s 'deploy %s %s'\" \\\n                  % (paas_access, deploy_git_host, branch)\n\n        cls.execute(command)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef quota(cls, id):\n        sampler = {'unit': 'minutes', 'value': 1, 'function': 'avg'}\n        query = 'vfs.df.bytes.all'\n        metrics = Metric.query(id, 60, query, 'paas', sampler)\n\n        df = {'free': 0, 'used': 0}\n        for metric in metrics:\n            what = metric['size'].pop()\n            # we need the most recent points\n            metric['points'].reverse()\n            for point in metric['points']:\n                if 'value' in point:\n                    df[what] = point['value']\n                    break\n        return df", "response": "return disk quota used or free"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the number of query cache for the last 24H", "response": "def cache(cls, id):\n        \"\"\"return the number of query cache for the last 24H\"\"\"\n        sampler = {'unit': 'days', 'value': 1, 'function': 'sum'}\n        query = 'webacc.requests.cache.all'\n        metrics = Metric.query(id, 60 * 60 * 24, query, 'paas', sampler)\n\n        cache = {'hit': 0, 'miss': 0, 'not': 0, 'pass': 0}\n        for metric in metrics:\n            what = metric['cache'].pop()\n            for point in metric['points']:\n                value = point.get('value', 0)\n                cache[what] += value\n        return cache"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates a PaaS instance.", "response": "def update(cls, id, name, size, quantity, password, sshkey, upgrade,\n               console, snapshot_profile, reset_mysql_password, background):\n        \"\"\"Update a PaaS instance.\"\"\"\n        if not background and not cls.intty():\n            background = True\n\n        paas_params = {}\n\n        if name:\n            paas_params['name'] = name\n\n        if size:\n            paas_params['size'] = size\n\n        if quantity:\n            paas_params['quantity'] = quantity\n\n        if password:\n            paas_params['password'] = password\n\n        paas_params.update(cls.convert_sshkey(sshkey))\n\n        if upgrade:\n            paas_params['upgrade'] = upgrade\n\n        if console:\n            paas_params['console'] = console\n\n        # XXX to delete a snapshot_profile the value has to be an empty string\n        if snapshot_profile is not None:\n            paas_params['snapshot_profile'] = snapshot_profile\n\n        if reset_mysql_password:\n            paas_params['reset_mysql_password'] = reset_mysql_password\n\n        result = cls.call('paas.update', cls.usable_id(id), paas_params)\n        if background:\n            return result\n\n        # interactive mode, run a progress bar\n        cls.echo('Updating your PaaS instance.')\n        cls.display_progress(result)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create(cls, name, size, type, quantity, duration, datacenter, vhosts,\n               password, snapshot_profile, background, sshkey):\n        \"\"\"Create a new PaaS instance.\"\"\"\n        if not background and not cls.intty():\n            background = True\n\n        datacenter_id_ = int(Datacenter.usable_id(datacenter))\n\n        paas_params = {\n            'name': name,\n            'size': size,\n            'type': type,\n            'duration': duration,\n            'datacenter_id': datacenter_id_,\n        }\n\n        if password:\n            paas_params['password'] = password\n\n        if quantity:\n            paas_params['quantity'] = quantity\n\n        paas_params.update(cls.convert_sshkey(sshkey))\n\n        if snapshot_profile:\n            paas_params['snapshot_profile'] = snapshot_profile\n\n        result = cls.call('paas.create', paas_params)\n\n        if not background:\n            # interactive mode, run a progress bar\n            cls.echo('Creating your PaaS instance.')\n            cls.display_progress(result)\n            cls.echo('Your PaaS instance %s has been created.' % name)\n\n        if vhosts:\n            paas_info = cls.info(name)\n            Vhost.create(paas_info, vhosts, True, background)\n\n        return result", "response": "Create a new PaaS instance."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the possible list of resources.", "response": "def resource_list(cls):\n        \"\"\" Get the possible list of resources (name, id and vhosts). \"\"\"\n        items = cls.list({'items_per_page': 500})\n        ret = [paas['name'] for paas in items]\n        ret.extend([str(paas['id']) for paas in items])\n        for paas in items:\n            paas = cls.info(paas['id'])\n            ret.extend([vhost['name'] for vhost in paas['vhosts']])\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nopens a console to a PaaS instance.", "response": "def console(cls, id):\n        \"\"\"Open a console to a PaaS instance.\"\"\"\n        oper = cls.call('paas.update', cls.usable_id(id), {'console': 1})\n        cls.echo('Activation of the console on your PaaS instance')\n        cls.display_progress(oper)\n        console_url = Paas.info(cls.usable_id(id))['console']\n        access = 'ssh %s' % console_url\n        cls.execute(access)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_vhost(cls, vhost):\n        result = Vhost().list()\n        paas_hosts = {}\n        for host in result:\n            paas_hosts[host['name']] = host['paas_id']\n\n        return paas_hosts.get(vhost)", "response": "Retrieve paas instance id associated to a vhost."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nretrieves paas instance id associated to a host.", "response": "def from_hostname(cls, hostname):\n        \"\"\"Retrieve paas instance id associated to a host.\"\"\"\n        result = cls.list({'items_per_page': 500})\n        paas_hosts = {}\n        for host in result:\n            paas_hosts[host['name']] = host['id']\n\n        return paas_hosts.get(hostname)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_names(cls):\n        ret = dict([(item['id'], item['name'])\n                    for item in cls.list({'items_per_page': 500})])\n        return ret", "response": "Retrieve paas id and names."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve a certificate by its common name.", "response": "def from_cn(cls, common_name):\n        \"\"\" Retrieve a certificate by its common name. \"\"\"\n        # search with cn\n        result_cn = [(cert['id'], [cert['cn']] + cert['altnames'])\n                     for cert in cls.list({'status': ['pending', 'valid'],\n                                           'items_per_page': 500,\n                                           'cn': common_name})]\n        # search with altname\n        result_alt = [(cert['id'], [cert['cn']] + cert['altnames'])\n                      for cert in cls.list({'status': ['pending', 'valid'],\n                                            'items_per_page': 500,\n                                            'altname': common_name})]\n\n        result = result_cn + result_alt\n        ret = {}\n        for id_, fqdns in result:\n            for fqdn in fqdns:\n                ret.setdefault(fqdn, []).append(id_)\n\n        cert_id = ret.get(common_name)\n        if not cert_id:\n            return\n\n        return cert_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef usable_ids(cls, id, accept_multi=True):\n        try:\n            qry_id = [int(id)]\n        except ValueError:\n            try:\n                qry_id = cls.from_cn(id)\n            except Exception:\n                qry_id = None\n\n        if not qry_id or not accept_multi and len(qry_id) != 1:\n            msg = 'unknown identifier %s' % id\n            cls.error(msg)\n\n        return qry_id if accept_multi else qry_id[0]", "response": "Retrieve id from input which can be an id or a cn."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef package_list(cls, options=None):\n        options = options or {}\n        try:\n            return cls.safe_call('cert.package.list', options)\n        except UsageError as err:\n            if err.code == 150020:\n                return []\n            raise", "response": "List possible certificate packages."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create(cls, csr, duration, package, altnames=None, dcv_method=None):\n        params = {'csr': csr, 'package': package, 'duration': duration}\n        if altnames:\n            params['altnames'] = altnames\n        if dcv_method:\n            params['dcv_method'] = dcv_method\n\n        try:\n            result = cls.call('cert.create', params)\n        except UsageError:\n            params['--dry-run'] = True\n            msg = '\\n'.join(['%s (%s)' % (err['reason'], err['attr'])\n                             for err in cls.call('cert.create', params)])\n            cls.error(msg)\n            raise\n\n        if dcv_method in ('dns', 'file'):\n            cls.advice_dcv_method(csr, package, altnames, dcv_method,\n                                  cert_id=result['params'].get('cert_id'))\n        return result", "response": "Create a new certificate."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading information from CSR and return common name.", "response": "def get_common_name(cls, csr):\n        \"\"\" Read information from CSR. \"\"\"\n        from tempfile import NamedTemporaryFile\n        fhandle = NamedTemporaryFile()\n        fhandle.write(csr.encode('latin1'))\n        fhandle.flush()\n        output = cls.exec_output('openssl req -noout -subject -in %s' %\n                                 fhandle.name)\n        if not output:\n            return\n\n        common_name = output.split('=')[-1].strip()\n        fhandle.close()\n        return common_name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a PK and a CSR if needed.", "response": "def process_csr(cls, common_name, csr=None, private_key=None,\n                    country=None, state=None, city=None, organisation=None,\n                    branch=None):\n        \"\"\" Create a PK and a CSR if needed.\"\"\"\n        if csr:\n            if branch or organisation or city or state or country:\n                cls.echo('Following options are only used to generate'\n                         ' the CSR.')\n        else:\n            params = (('CN', common_name),\n                      ('OU', branch),\n                      ('O', organisation),\n                      ('L', city),\n                      ('ST', state),\n                      ('C', country))\n            params = [(key, val) for key, val in params if val]\n            csr = cls.create_csr(common_name, private_key, params)\n\n        if csr and os.path.exists(csr):\n            with open(csr) as fcsr:\n                csr = fcsr.read()\n\n        return csr"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pretty_format_cert(cls, cert):\n        crt = cert.get('cert')\n        if crt:\n            crt = ('-----BEGIN CERTIFICATE-----\\n' +\n                   '\\n'.join([crt[index * 64:(index + 1) * 64]\n                              for index in range(int(len(crt) / 64) + 1)]).rstrip('\\n') +  # noqa\n                   '\\n-----END CERTIFICATE-----')\n        return crt", "response": "Pretty display of a certificate."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new contact.", "response": "def create_dry_run(cls, params):\n        \"\"\"Create a new contact.\"\"\"\n        return cls.call('contact.create', dict(params), empty_key=True,\n                        dry_run=True, return_dry_run=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndisplays information about a webaccelerator.", "response": "def info(gandi, resource, format):\n    \"\"\" Display information about a webaccelerator \"\"\"\n    result = gandi.webacc.info(resource)\n    if format:\n        output_json(gandi, format, result)\n        return result\n\n    output_base = {\n        'name': result['name'],\n        'algorithm': result['lb']['algorithm'],\n        'datacenter': result['datacenter']['name'],\n        'state': result['state'],\n        'ssl': 'Disable' if result['ssl_enable'] is False else 'Enabled'\n    }\n    output_keys = ['name', 'state', 'datacenter', 'ssl', 'algorithm']\n    output_generic(gandi, output_base, output_keys, justify=14)\n\n    gandi.echo('Vhosts :')\n    for vhost in result['vhosts']:\n        output_vhosts = ['vhost', 'ssl']\n        vhost['vhost'] = vhost['name']\n        vhost['ssl'] = 'None' if vhost['cert_id'] is None else 'Exists'\n        output_sub_generic(gandi, vhost, output_vhosts, justify=14)\n        gandi.echo('')\n\n    gandi.echo('Backends :')\n    for server in result['servers']:\n        try:\n            ip = gandi.ip.info(server['ip'])\n            iface = gandi.iface.info(ip['iface_id'])\n            server['name'] = gandi.iaas.info(iface['vm_id'])['hostname']\n            output_servers = ['name', 'ip', 'port', 'state']\n        except Exception:\n            warningmsg = ('\\tBackend with ip address %s no longer exists.'\n                          '\\n\\tYou should remove it.' % server['ip'])\n            gandi.echo(warningmsg)\n            output_servers = ['ip', 'port', 'state']\n        output_sub_generic(gandi, server, output_servers, justify=14)\n        gandi.echo('')\n\n    gandi.echo('Probe :')\n    output_probe = ['state', 'host', 'interval', 'method', 'response',\n                    'threshold', 'timeout', 'url', 'window']\n    result['probe']['state'] = ('Disable'\n                                if result['probe']['enable'] is False\n                                else 'Enabled')\n    output_sub_generic(gandi, result['probe'], output_probe, justify=14)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new webaccelerator.", "response": "def create(gandi, name, datacenter, backend, port, vhost, algorithm,\n           ssl_enable, zone_alter, ssl, private_key, poll_cert):\n    \"\"\" Create a webaccelerator \"\"\"\n    try:\n        gandi.datacenter.is_opened(datacenter, 'iaas')\n    except DatacenterLimited as exc:\n        gandi.echo('/!\\ Datacenter %s will be closed on %s, '\n                   'please consider using another datacenter.' %\n                   (datacenter, exc.date))\n\n    backends = backend\n    for backend in backends:\n        # Check if a port is set for each backend, else set a default port\n        if 'port' not in backend:\n            if not port:\n                backend['port'] = click.prompt('Please set a port for '\n                                               'backends. If you want to set '\n                                               'different port for each '\n                                               'backend, use `-b ip:port`',\n                                               type=int)\n            else:\n                backend['port'] = port\n\n    if vhost and not gandi.hostedcert.activate_ssl(vhost,\n                                                   ssl,\n                                                   private_key,\n                                                   poll_cert):\n        return\n\n    result = gandi.webacc.create(name, datacenter, backends, vhost, algorithm,\n                                 ssl_enable, zone_alter)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting a single resource from a webaccelerator vhost or a backend.", "response": "def delete(gandi, webacc, vhost, backend, port):\n    \"\"\" Delete a webaccelerator, a vhost or a backend \"\"\"\n    result = []\n    if webacc:\n        result = gandi.webacc.delete(webacc)\n\n    if backend:\n        backends = backend\n        for backend in backends:\n            if 'port' not in backend:\n                if not port:\n                    backend['port'] = click.prompt('Please set a port for '\n                                                   'backends. If you want to '\n                                                   ' different port for '\n                                                   'each backend, use `-b '\n                                                   'ip:port`', type=int)\n                else:\n                    backend['port'] = port\n            result = gandi.webacc.backend_remove(backend)\n\n    if vhost:\n        vhosts = vhost\n        for vhost in vhosts:\n            result = gandi.webacc.vhost_remove(vhost)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add(gandi, resource, vhost, zone_alter, backend, port, ssl, private_key,\n        poll_cert):\n    \"\"\" Add a backend or a vhost on a webaccelerator \"\"\"\n    result = []\n    if backend:\n        backends = backend\n        for backend in backends:\n            # Check if a port is set for each backend, else set a default port\n            if 'port' not in backend:\n                if not port:\n                    backend['port'] = click.prompt('Please set a port for '\n                                                   'backends. If you want to '\n                                                   ' different port for '\n                                                   'each backend, use `-b '\n                                                   'ip:port`', type=int)\n                else:\n                    backend['port'] = port\n            result = gandi.webacc.backend_add(resource, backend)\n\n    if vhost:\n        if not gandi.hostedcert.activate_ssl(vhost, ssl, private_key,\n                                             poll_cert):\n            return\n        vhosts = vhost\n        for vhost in vhosts:\n            params = {'vhost': vhost}\n            if zone_alter:\n                params['zone_alter'] = zone_alter\n            result = gandi.webacc.vhost_add(resource, params)\n    return result", "response": "Add a backend or a vhost on a webaccelerator."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef enable(gandi, resource, backend, port, probe):\n    result = []\n    if backend:\n        backends = backend\n        for backend in backends:\n            if 'port' not in backend:\n                if not port:\n                    backend['port'] = click.prompt('Please set a port for '\n                                                   'backends. If you want to '\n                                                   ' different port for '\n                                                   'each backend, use `-b '\n                                                   'ip:port`', type=int)\n                else:\n                    backend['port'] = port\n            result = gandi.webacc.backend_enable(backend)\n\n    if probe:\n        if not resource:\n            gandi.echo('You need to indicate the Webaccelerator name')\n            return\n        result = gandi.webacc.probe_enable(resource)\n\n    return result", "response": "Enable a backend or a probe on a webaccelerator"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndisabling a backend or a probe on a webaccelerator", "response": "def disable(gandi, resource, backend, port, probe):\n    \"\"\" Disable a backend or a probe on a webaccelerator \"\"\"\n    result = []\n    if backend:\n        backends = backend\n        for backend in backends:\n            if 'port' not in backend:\n                if not port:\n                    backend['port'] = click.prompt('Please set a port for '\n                                                   'backends. If you want to '\n                                                   ' different port for '\n                                                   'each backend, use `-b '\n                                                   'ip:port`', type=int)\n                else:\n                    backend['port'] = port\n            result = gandi.webacc.backend_disable(backend)\n\n    if probe:\n        if not resource:\n            gandi.echo('You need to indicate the Webaccelerator name')\n            return\n        result = gandi.webacc.probe_disable(resource)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmanaging a probe for a webaccelerator", "response": "def probe(gandi, resource, enable, disable, test, host, interval, http_method,\n          http_response, threshold, timeout, url, window):\n    \"\"\" Manage a probe for a webaccelerator \"\"\"\n    result = gandi.webacc.probe(resource, enable, disable, test, host,\n                                interval, http_method, http_response,\n                                threshold, timeout, url, window)\n    output_keys = ['status', 'timeout']\n    output_generic(gandi, result, output_keys, justify=14)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlists domains manageable by REST API.", "response": "def domain_list(gandi):\n    \"\"\"List domains manageable by REST API.\"\"\"\n    domains = gandi.dns.list()\n    for domain in domains:\n        gandi.echo(domain['fqdn'])\n\n    return domains"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndisplay records for a domain.", "response": "def list(gandi, fqdn, name, sort, type, rrset_type, text):\n    \"\"\"Display records for a domain.\"\"\"\n    domains = gandi.dns.list()\n    domains = [domain['fqdn'] for domain in domains]\n    if fqdn not in domains:\n        gandi.echo('Sorry domain %s does not exist' % fqdn)\n        gandi.echo('Please use one of the following: %s' % ', '.join(domains))\n        return\n\n    output_keys = ['name', 'ttl', 'type', 'values']\n\n    result = gandi.dns.records(fqdn, sort_by=sort, text=text)\n    if text:\n        gandi.echo(result)\n        return result\n\n    for num, rec in enumerate(result):\n        if type and rec['rrset_type'] != type:\n            continue\n        if rrset_type and rec['rrset_type'] != rrset_type:\n            continue\n        if name and rec['rrset_name'] != name:\n            continue\n        if num:\n            gandi.separator_line()\n        output_dns_records(gandi, rec, output_keys)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create(gandi, fqdn, name, type, value, ttl):\n    domains = gandi.dns.list()\n    domains = [domain['fqdn'] for domain in domains]\n    if fqdn not in domains:\n        gandi.echo('Sorry domain %s does not exist' % fqdn)\n        gandi.echo('Please use one of the following: %s' % ', '.join(domains))\n        return\n\n    result = gandi.dns.add_record(fqdn, name, type, value, ttl)\n    gandi.echo(result['message'])", "response": "Create new record entry for a domain."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update(gandi, fqdn, name, type, value, ttl, file):\n    domains = gandi.dns.list()\n    domains = [domain['fqdn'] for domain in domains]\n    if fqdn not in domains:\n        gandi.echo('Sorry domain %s does not exist' % fqdn)\n        gandi.echo('Please use one of the following: %s' % ', '.join(domains))\n        return\n\n    content = ''\n    if file:\n        content = file.read()\n    elif not sys.stdin.isatty():\n        content = click.get_text_stream('stdin').read()\n\n    content = content.strip()\n    if not content and not name and not type and not value:\n        click.echo('Cannot find parameters for zone content to update.')\n        return\n\n    if name and type and not value:\n        click.echo('You must provide one or more value parameter.')\n        return\n\n    result = gandi.dns.update_record(fqdn, name, type, value, ttl, content)\n    gandi.echo(result['message'])", "response": "Update a record entry for a domain."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting a record entry for a domain.", "response": "def delete(gandi, fqdn, name, type, force):\n    \"\"\"Delete record entry for a domain.\"\"\"\n    domains = gandi.dns.list()\n    domains = [domain['fqdn'] for domain in domains]\n    if fqdn not in domains:\n        gandi.echo('Sorry domain %s does not exist' % fqdn)\n        gandi.echo('Please use one of the following: %s' % ', '.join(domains))\n        return\n\n    if not force:\n        if not name and not type:\n            prompt = (\"Are you sure to delete all records for domain %s ?\" %\n                      fqdn)\n        elif name and not type:\n            prompt = (\"Are you sure to delete all '%s' name records for \"\n                      \"domain %s ?\" % (name, fqdn))\n        else:\n            prompt = (\"Are you sure to delete all '%s' records of type %s \"\n                      \"for domain %s ?\" % (name, type, fqdn))\n\n        proceed = click.confirm(prompt)\n\n        if not proceed:\n            return\n\n    result = gandi.dns.del_record(fqdn, name, type)\n    gandi.echo('Delete successful.')\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef keys_info(gandi, fqdn, key):\n    key_info = gandi.dns.keys_info(fqdn, key)\n    output_keys = ['uuid', 'algorithm', 'algorithm_name', 'ds', 'fingerprint',\n                   'public_key', 'flags', 'tag', 'status']\n    output_generic(gandi, key_info, output_keys, justify=15)\n    return key_info", "response": "Display information about a domain key."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef keys_create(gandi, fqdn, flag):\n    key_info = gandi.dns.keys_create(fqdn, int(flag))\n\n    output_keys = ['uuid', 'algorithm', 'algorithm_name', 'ds', 'fingerprint',\n                   'public_key', 'flags', 'tag', 'status']\n    output_generic(gandi, key_info, output_keys, justify=15)\n    return key_info", "response": "Create key for a domain."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef keys_delete(gandi, fqdn, key, force):\n    if not force:\n        proceed = click.confirm('Are you sure you want to delete key %s on '\n                                'domain %s?' % (key, fqdn))\n\n        if not proceed:\n            return\n\n    result = gandi.dns.keys_delete(fqdn, key)\n    gandi.echo('Delete successful.')\n    return result", "response": "Delete a key for a domain."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef keys_recover(gandi, fqdn, key):\n    result = gandi.dns.keys_recover(fqdn, key)\n    gandi.echo('Recover successful.')\n    return result", "response": "Recover deleted key for a domain."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef handle(cls, vm, args):\n        docker = Iaas.info(vm)\n        if not docker:\n            raise Exception('docker vm %s not found' % vm)\n\n        if docker['state'] != 'running':\n            Iaas.start(vm)\n\n        # XXX\n        remote_addr = docker['ifaces'][0]['ips'][0]['ip']\n\n        port = unixpipe.setup(remote_addr, 'root', '/var/run/docker.sock')\n\n        os.environ['DOCKER_HOST'] = 'tcp://localhost:%d' % port\n        cls.echo('using DOCKER_HOST=%s' % os.environ['DOCKER_HOST'])\n\n        subprocess.call(['docker'] + list(args))", "response": "Setup forwarding connection to given VM and pipe docker cmds over SSH."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create(cls, paas_info, vhost, alter_zone, background):\n        if not background and not cls.intty():\n            background = True\n\n        params = {'paas_id': paas_info['id'],\n                  'vhost': vhost,\n                  'zone_alter': alter_zone}\n        result = cls.call('paas.vhost.create', params, dry_run=True)\n\n        if background:\n            return result\n\n        cls.echo('Creating a new vhost.')\n        cls.display_progress(result)\n        cls.echo('Your vhost %s has been created.' % vhost)\n\n        return result", "response": "Create a new vhost."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef info(gandi, resource, stat):\n    output_keys = ['hostname', 'state', 'cores', 'memory', 'console',\n                   'datacenter', 'ip']\n    justify = 14\n    if stat is True:\n        sampler = {'unit': 'hours', 'value': 1, 'function': 'max'}\n        time_range = 3600 * 24\n        query_vif = 'vif.bytes.all'\n        query_vbd = 'vbd.bytes.all'\n\n    resource = sorted(tuple(set(resource)))\n    datacenters = gandi.datacenter.list()\n    ret = []\n    for num, item in enumerate(resource):\n        if num:\n            gandi.separator_line()\n        vm = gandi.iaas.info(item)\n        output_vm(gandi, vm, datacenters, output_keys, justify)\n        ret.append(vm)\n        for disk in vm['disks']:\n            gandi.echo('')\n            disk_out_keys = ['label', 'kernel_version', 'name', 'size']\n            output_image(gandi, disk, datacenters, disk_out_keys, justify,\n                         warn_deprecated=False)\n        if stat is True:\n            metrics_vif = gandi.metric.query(vm['id'], time_range, query_vif,\n                                             'vm', sampler)\n            metrics_vbd = gandi.metric.query(vm['id'], time_range, query_vbd,\n                                             'vm', sampler)\n            gandi.echo('')\n            gandi.echo('vm network stats')\n            output_metric(gandi, metrics_vif, 'direction', justify)\n            gandi.echo('disk network stats')\n            output_metric(gandi, metrics_vbd, 'direction', justify)\n\n    return ret", "response": "Display information about a virtual machine."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef reboot(gandi, background, resource):\n    output_keys = ['id', 'type', 'step']\n\n    resource = sorted(tuple(set(resource)))\n    opers = gandi.iaas.reboot(resource, background)\n    if background:\n        for oper in opers:\n            output_generic(gandi, oper, output_keys)\n\n    return opers", "response": "Reboot a virtual machine."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete a virtual machine.", "response": "def delete(gandi, background, force, resource):\n    \"\"\"Delete a virtual machine.\n\n    Resource can be a Hostname or an ID\n    \"\"\"\n    output_keys = ['id', 'type', 'step']\n\n    resource = sorted(tuple(set(resource)))\n    possible_resources = gandi.iaas.resource_list()\n    for item in resource:\n        if item not in possible_resources:\n            gandi.echo('Sorry virtual machine %s does not exist' % item)\n            gandi.echo('Please use one of the following: %s' %\n                       possible_resources)\n            return\n\n    if not force:\n        instance_info = \"'%s'\" % ', '.join(resource)\n        proceed = click.confirm(\"Are you sure to delete Virtual Machine %s?\" %\n                                instance_info)\n\n        if not proceed:\n            return\n\n    iaas_list = gandi.iaas.list()\n    stop_opers = []\n    for item in resource:\n        vm = next((vm for (index, vm) in enumerate(iaas_list)\n                   if vm['hostname'] == item), gandi.iaas.info(item))\n        if vm['state'] == 'running':\n            if background:\n                gandi.echo('Virtual machine not stopped, background option '\n                           'disabled')\n                background = False\n            oper = gandi.iaas.stop(item, background)\n            if not background:\n                stop_opers.append(oper)\n\n    opers = gandi.iaas.delete(resource, background)\n    if background:\n        for oper in stop_opers + opers:\n            output_generic(gandi, oper, output_keys)\n\n    return opers"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create(gandi, datacenter, memory, cores, ip_version, bandwidth, login,\n           password, hostname, image, run, background, sshkey, size, vlan, ip,\n           script, script_args, ssh, gen_password):\n    \"\"\"Create a new virtual machine.\n\n    you can specify a configuration entry named 'sshkey' containing\n    path to your sshkey file\n\n    $ gandi config set [-g] sshkey ~/.ssh/id_rsa.pub\n\n    or getting the sshkey \"my_key\" from your gandi ssh keyring\n\n    $ gandi config set [-g] sshkey my_key\n\n    to know which disk image label (or id) to use as image\n\n    $ gandi vm images\n\n    \"\"\"\n    try:\n        gandi.datacenter.is_opened(datacenter, 'iaas')\n    except DatacenterLimited as exc:\n        if exc.date:\n            gandi.echo('/!\\ Datacenter %s will be closed on %s, '\n                       'please consider using another datacenter.' %\n                       (datacenter, exc.date))\n\n    if gandi.image.is_deprecated(image, datacenter):\n        gandi.echo('/!\\ Image %s is deprecated and will soon be unavailable.'\n                   % image)\n\n    pwd = None\n    if gen_password:\n        pwd = mkpassword()\n\n    if password or (not pwd and not sshkey):\n        pwd = click.prompt('password', hide_input=True,\n                           confirmation_prompt=True)\n\n    if ip and not vlan:\n        gandi.echo(\"--ip can't be used without --vlan.\")\n        return\n\n    if not vlan and not ip_version:\n        ip_version = 6\n\n    if not ip_version:\n        gandi.echo(\"* Private only ip vm (can't enable emergency web console \"\n                   'access).')\n\n    # Display a short summary for creation\n    if login:\n        user_summary = 'root and %s users' % login\n        password_summary = 'Users root and %s' % login\n    else:\n        user_summary = 'root user'\n        password_summary = 'User root'\n\n    gandi.echo('* %s will be created.' % user_summary)\n    if sshkey:\n        gandi.echo('* SSH key authorization will be used.')\n    if pwd and gen_password:\n        gandi.echo('* %s setup with password %s' %\n                   (password_summary, pwd))\n    if not pwd:\n        gandi.echo('* No password supplied for vm (required to enable '\n                   'emergency web console access).')\n    result = gandi.iaas.create(datacenter, memory, cores, ip_version,\n                               bandwidth, login, pwd, hostname,\n                               image, run,\n                               background,\n                               sshkey, size, vlan, ip, script, script_args,\n                               ssh)\n    if background:\n        gandi.echo('* IAAS backend is now creating your VM and its '\n                   'associated resources in the background.')\n\n    return result", "response": "Create a new virtual machine."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates a virtual machine.", "response": "def update(gandi, resource, memory, cores, console, password, background,\n           reboot):\n    \"\"\"Update a virtual machine.\n\n    Resource can be a Hostname or an ID\n    \"\"\"\n    pwd = None\n    if password:\n        pwd = click.prompt('password', hide_input=True,\n                           confirmation_prompt=True)\n\n    max_memory = None\n    if memory:\n        max_memory = gandi.iaas.required_max_memory(resource, memory)\n\n    if max_memory and not reboot:\n        gandi.echo('memory update must be done offline.')\n        if not click.confirm(\"reboot machine %s?\" % resource):\n            return\n\n    result = gandi.iaas.update(resource, memory, cores, console, pwd,\n                               background, max_memory)\n    if background:\n        gandi.pretty_echo(result)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nopens a console to virtual machine.", "response": "def console(gandi, resource):\n    \"\"\"Open a console to virtual machine.\n\n    Resource can be a Hostname or an ID\n    \"\"\"\n    gandi.echo('/!\\ Please be aware that if you didn\\'t provide a password '\n               'during creation, console service will be unavailable.')\n    gandi.echo('/!\\ You can use \"gandi vm update\" command to set a password.')\n    gandi.echo('/!\\ Use ~. ssh escape key to exit.')\n\n    gandi.iaas.console(resource)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nspawn an SSH session to virtual machine.", "response": "def ssh(gandi, resource, login, identity, wipe_key, wait, args):\n    \"\"\"Spawn an SSH session to virtual machine.\n\n    Resource can be a Hostname or an ID\n    \"\"\"\n    if '@' in resource:\n        (login, resource) = resource.split('@', 1)\n    if wipe_key:\n        gandi.iaas.ssh_keyscan(resource)\n    if wait:\n        gandi.iaas.wait_for_sshd(resource)\n    gandi.iaas.ssh(resource, login, identity, args)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef images(gandi, label, datacenter):\n    output_keys = ['label', 'os_arch', 'kernel_version', 'disk_id',\n                   'dc', 'name']\n\n    datacenters = gandi.datacenter.list()\n    result = gandi.image.list(datacenter, label)\n    for num, image in enumerate(result):\n        if num:\n            gandi.separator_line()\n        output_image(gandi, image, datacenters, output_keys)\n\n    # also display usable disks\n    result = gandi.disk.list_create(datacenter, label)\n    for disk in result:\n        gandi.separator_line()\n        output_image(gandi, disk, datacenters, output_keys)\n\n    return result", "response": "List available system images for virtual machines."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef migrate(gandi, resource, force, background, finalize):\n    if not gandi.iaas.check_can_migrate(resource):\n        return\n\n    if not force:\n        proceed = click.confirm('Are you sure you want to migrate VM %s ?'\n                                % resource)\n        if not proceed:\n            return\n\n    if finalize:\n        gandi.iaas.need_finalize(resource)\n\n    output_keys = ['id', 'type', 'step']\n    oper = gandi.iaas.migrate(resource, background, finalize=finalize)\n    if background:\n        output_generic(gandi, oper, output_keys)\n\n    return oper", "response": "Migrate a virtual machine to another datacenter."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve id from single input.", "response": "def usable_id(cls, id):\n        \"\"\" Retrieve id from single input. \"\"\"\n        hcs = cls.from_fqdn(id)\n        if hcs:\n            return [hc_['id'] for hc_ in hcs]\n\n        try:\n            return int(id)\n        except (TypeError, ValueError):\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndisplay information about hosted certificates for a fqdn.", "response": "def infos(cls, fqdn):\n        \"\"\" Display information about hosted certificates for a fqdn. \"\"\"\n        if isinstance(fqdn, (list, tuple)):\n            ids = []\n            for fqd_ in fqdn:\n                ids.extend(cls.infos(fqd_))\n            return ids\n\n        ids = cls.usable_id(fqdn)\n        if not ids:\n            return []\n\n        if not isinstance(ids, (list, tuple)):\n            ids = [ids]\n\n        return [cls.info(id_) for id_ in ids]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create(cls, key, crt):\n        options = {'crt': crt, 'key': key}\n        return cls.call('cert.hosted.create', options)", "response": "Add a new crt in the hosted cert store."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndisplays information about a domain.", "response": "def info(gandi, resource):\n    \"\"\"Display information about a domain.\"\"\"\n    output_keys = ['fqdn', 'nameservers', 'services', 'zone_id', 'tags',\n                   'created', 'expires', 'updated']\n    contact_field = ['owner', 'admin', 'bill', 'tech', 'reseller']\n\n    result = gandi.domain.info(resource)\n    output_contact_info(gandi, result['contacts'], contact_field, justify=12)\n    output_domain(gandi, result, output_keys, justify=12)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninitialize Gandi CLI configuration. Create global configuration directory with API credentials", "response": "def setup(gandi):\n    \"\"\" Initialize Gandi CLI configuration.\n\n    Create global configuration directory with API credentials\n    \"\"\"\n    intro = \"\"\"Welcome to GandiCLI, let's configure a few things before we \\\nstart.\n\"\"\"\n\n    outro = \"\"\"\nSetup completed. You can now:\n* use 'gandi' to see all command.\n* use 'gandi vm create' to create and access a Virtual Machine.\n* use 'gandi paas create' to create and access a SimpleHosting instance.\n\"\"\"\n    gandi.echo(intro)\n    gandi.init_config()\n    gandi.echo(outro)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndisplay information about API used.", "response": "def api(gandi):\n    \"\"\"Display information about API used.\"\"\"\n    key_name = 'API version'\n\n    result = gandi.api.info()\n    result[key_name] = result.pop('api_version')\n    output_generic(gandi, result, [key_name])\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef help(ctx, command):\n    command = ' '.join(command)\n    if not command:\n        click.echo(cli.get_help(ctx))\n        return\n\n    cmd = cli.get_command(ctx, command)\n    if cmd:\n        click.echo(cmd.get_help(ctx))\n    else:\n        click.echo(cli.get_help(ctx))", "response": "Display help for a command."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndisplaying current status from status. gandi. net.", "response": "def status(gandi, service):\n    \"\"\"Display current status from status.gandi.net.\"\"\"\n\n    if not service:\n        global_status = gandi.status.status()\n        if global_status['status'] == 'FOGGY':\n            # something is going on but not affecting services\n            filters = {\n                'category': 'Incident',\n                'current': True,\n            }\n            events = gandi.status.events(filters)\n            for event in events:\n                if event['services']:\n                    # do not process services\n                    continue\n                event_url = gandi.status.event_timeline(event)\n                service_detail = '%s - %s' % (event['title'], event_url)\n                gandi.echo(service_detail)\n\n    # then check other services\n    descs = gandi.status.descriptions()\n    needed = services = gandi.status.services()\n    if service:\n        needed = [serv for serv in services\n                  if serv['name'].lower() == service.lower()]\n\n    for serv in needed:\n        if serv['status'] != 'STORMY':\n            output_service(gandi, serv['name'], descs[serv['status']])\n            continue\n\n        filters = {\n            'category': 'Incident',\n            'services': serv['name'],\n            'current': True,\n        }\n        events = gandi.status.events(filters)\n        for event in events:\n            event_url = gandi.status.event_timeline(event)\n            service_detail = '%s - %s' % (event['title'], event_url)\n            output_service(gandi, serv['name'], service_detail)\n\n    return services"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlist mail forwards for a domain.", "response": "def list(gandi, domain, limit):\n    \"\"\"List mail forwards for a domain.\"\"\"\n    options = {'items_per_page': limit}\n    result = gandi.forward.list(domain, options)\n    for forward in result:\n        output_forward(gandi, domain, forward)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a domain mail forward.", "response": "def create(gandi, address, destination):\n    \"\"\"Create a domain mail forward.\"\"\"\n    source, domain = address\n\n    result = gandi.forward.create(domain, source, destination)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update(gandi, address, dest_add, dest_del):\n    source, domain = address\n\n    if not dest_add and not dest_del:\n        gandi.echo('Nothing to update: you must provide destinations to '\n                   'update, use --dest-add/-a or -dest-del/-d parameters.')\n        return\n\n    result = gandi.forward.update(domain, source, dest_add, dest_del)\n\n    return result", "response": "Update a domain mail forward."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete(gandi, address, force):\n    source, domain = address\n\n    if not force:\n        proceed = click.confirm('Are you sure to delete the domain '\n                                'mail forward %s@%s ?' % (source, domain))\n\n        if not proceed:\n            return\n\n    result = gandi.forward.delete(domain, source)\n\n    return result", "response": "Delete a domain mail forward."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list(gandi, domain, zone_id, output, format, limit):\n    options = {\n        'items_per_page': limit,\n    }\n    output_keys = ['name', 'type', 'value', 'ttl']\n\n    if not zone_id:\n        result = gandi.domain.info(domain)\n        zone_id = result['zone_id']\n\n    if not zone_id:\n        gandi.echo('No zone records found, domain %s doesn\\'t seems to be '\n                   'managed at Gandi.' % domain)\n        return\n\n    records = gandi.record.list(zone_id, options)\n\n    if not output and not format:\n        for num, rec in enumerate(records):\n            if num:\n                gandi.separator_line()\n            output_generic(gandi, rec, output_keys, justify=12)\n    elif output:\n        zone_filename = domain + \"_\" + str(zone_id)\n        if os.path.isfile(zone_filename):\n            open(zone_filename, 'w').close()\n        for record in records:\n            format_record = ('%s %s IN %s %s' %\n                             (record['name'], record['ttl'],\n                              record['type'], record['value']))\n            with open(zone_filename, 'ab') as zone_file:\n                zone_file.write(format_record + '\\n')\n        gandi.echo('Your zone file have been writen in %s' % zone_filename)\n    elif format:\n        if format == 'text':\n            for record in records:\n                format_record = ('%s %s IN %s %s' %\n                                 (record['name'], record['ttl'],\n                                  record['type'], record['value']))\n                gandi.echo(format_record)\n        if format == 'json':\n            format_record = json.dumps(records, sort_keys=True,\n                                       indent=4, separators=(',', ': '))\n            gandi.echo(format_record)\n\n    return records", "response": "List DNS zone records for a domain."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create(gandi, domain, zone_id, name, type, value, ttl):\n\n    if not zone_id:\n        result = gandi.domain.info(domain)\n        zone_id = result['zone_id']\n\n    if not zone_id:\n        gandi.echo('No zone records found, domain %s doesn\\'t seems to be '\n                   'managed at Gandi.' % domain)\n        return\n\n    record = {'type': type, 'name': name, 'value': value}\n    if ttl:\n        record['ttl'] = ttl\n\n    result = gandi.record.create(zone_id, record)\n    return result", "response": "Create new DNS zone record entry for a domain."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting a record entry for a domain", "response": "def delete(gandi, domain, zone_id, name, type, value):\n    \"\"\"Delete a record entry for a domain\"\"\"\n    if not zone_id:\n        result = gandi.domain.info(domain)\n        zone_id = result['zone_id']\n\n    if not zone_id:\n        gandi.echo('No zone records found, domain %s doesn\\'t seems to be '\n                   'managed at Gandi.' % domain)\n        return\n    if not name and not type and not value:\n        proceed = click.confirm('This command without parameters --type, '\n                                '--name or --value will remove all records'\n                                ' in this zone file. Are you sur to '\n                                'perform this action ?')\n        if not proceed:\n            return\n    record = {'name': name, 'type': type, 'value': value}\n    result = gandi.record.delete(zone_id, record)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate records entries for a domain.", "response": "def update(gandi, domain, zone_id, file, record, new_record):\n    \"\"\"Update records entries for a domain.\n\n    You can update an individual record using --record and --new-record\n    parameters\n\n    Or you can use a plaintext file to update all records of a DNS zone at\n    once with --file parameter.\n    \"\"\"\n    if not zone_id:\n        result = gandi.domain.info(domain)\n        zone_id = result['zone_id']\n\n    if not zone_id:\n        gandi.echo('No zone records found, domain %s doesn\\'t seems to be'\n                   ' managed at Gandi.' % domain)\n        return\n    if file:\n        records = file.read()\n        result = gandi.record.zone_update(zone_id, records)\n        return result\n    elif record and new_record:\n        result = gandi.record.update(zone_id, record, new_record)\n        return result\n    else:\n        gandi.echo('You must indicate a zone file or a record.'\n                   ' Use `gandi record update --help` for more information')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates aliases on a mailbox.", "response": "def set_alias(cls, domain, login, aliases):\n        \"\"\"Update aliases on a mailbox.\"\"\"\n        return cls.call('domain.mailbox.alias.set', domain, login, aliases)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the xmlrpc response.", "response": "def parse_response(self, resp):\n        \"\"\"\n        Parse the xmlrpc response.\n        \"\"\"\n        p, u = self.getparser()\n        p.feed(resp.content)\n        p.close()\n        return u.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list(cls, zone_id, options=None):\n        options = options if options else {}\n        return cls.call('domain.zone.record.list', zone_id, 0, options)", "response": "List zone records for a zone."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a record to a zone.", "response": "def add(cls, zone_id, version_id, record):\n        \"\"\"Add record to a zone.\"\"\"\n        return cls.call('domain.zone.record.add', zone_id, version_id, record)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new zone version for record.", "response": "def create(cls, zone_id, record):\n        \"\"\"Create a new zone version for record.\"\"\"\n        cls.echo('Creating new zone version')\n        new_version_id = Zone.new(zone_id)\n\n        cls.echo('Updating zone version')\n        cls.add(zone_id, new_version_id, record)\n\n        cls.echo('Activation of new zone version')\n        Zone.set(zone_id, new_version_id)\n\n        return new_version_id"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete(cls, zone_id, record):\n        cls.echo('Creating new zone record')\n        new_version_id = Zone.new(zone_id)\n\n        cls.echo('Deleting zone record')\n        cls.call('domain.zone.record.delete', zone_id, new_version_id, record)\n\n        cls.echo('Activation of new zone version')\n        Zone.set(zone_id, new_version_id)\n\n        return new_version_id", "response": "Delete a record for a zone"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate records for a zone", "response": "def zone_update(cls, zone_id, records):\n        \"\"\"Update records for a zone\"\"\"\n        cls.echo('Creating new zone file')\n        new_version_id = Zone.new(zone_id)\n\n        cls.echo('Updating zone records')\n        cls.call('domain.zone.record.set', zone_id, new_version_id, records)\n\n        cls.echo('Activation of new zone version')\n        Zone.set(zone_id, new_version_id)\n\n        return new_version_id"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update(cls, zone_id, old_record, new_record):\n        cls.echo('Creating new zone file')\n        new_version_id = Zone.new(zone_id)\n\n        new_record = new_record.replace(' IN', '')\n        new_record = new_record.split(' ', 4)\n        params_newrecord = {'name': new_record[0], 'ttl': int(new_record[1]),\n                            'type': new_record[2], 'value': new_record[3]}\n\n        old_record = old_record.replace(' IN', '')\n        old_record = old_record.split(' ', 4)\n        try:\n            params = {'name': old_record[0], 'ttl': int(old_record[1]),\n                      'type': old_record[2], 'value': old_record[3]}\n        except IndexError:\n            # failed to retrieve all values, try only use the name\n            params = {'name': old_record[0]}\n        record = cls.call('domain.zone.record.list', zone_id, new_version_id,\n                          params)\n\n        if record:\n            cls.echo('Updating zone records')\n            try:\n                cls.call('domain.zone.record.update', zone_id,\n                         new_version_id, {'id': record[0]['id']},\n                         params_newrecord)\n                cls.echo('Activation of new zone version')\n                Zone.set(zone_id, new_version_id)\n                return new_version_id\n            except Exception as err:\n                cls.echo('An error as occured: %s' % err)\n                Zone.delete(zone_id, new_version_id)\n        else:\n            cls.echo('The record to update does not exist. Check records'\n                     ' already created with `gandi record list example.com'\n                     ' --output`')\n            return False", "response": "Update a record in a zone file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndisplay information about a vhost.", "response": "def info(gandi, resource, id):\n    \"\"\" Display information about a vhost.\n\n    Resource must be the vhost fqdn.\n    \"\"\"\n    output_keys = ['name', 'state', 'date_creation', 'paas_name', 'ssl']\n\n    if id:\n        # When we will have more than paas vhost, we will append rproxy_id\n        output_keys.append('paas_id')\n\n    paas_names = gandi.paas.list_names()\n\n    ret = []\n    paas = None\n    for num, item in enumerate(resource):\n        vhost = gandi.vhost.info(item)\n        try:\n            hostedcert = gandi.hostedcert.infos(vhost['name'])\n            vhost['ssl'] = 'activated' if hostedcert else 'disabled'\n        except ValueError:\n            vhost['ssl'] = 'disabled'\n        paas = paas_names.get(vhost['paas_id'])\n        if num:\n            gandi.separator_line()\n        ret.append(output_vhost(gandi, vhost, paas, output_keys))\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create(gandi, vhost, paas, ssl, private_key, alter_zone, poll_cert,\n           background):\n    \"\"\" Create a new vhost. \"\"\"\n    if not gandi.hostedcert.activate_ssl(vhost, ssl, private_key, poll_cert):\n        return\n\n    paas_info = gandi.paas.info(paas)\n    result = gandi.vhost.create(paas_info, vhost, alter_zone, background)\n\n    if background:\n        gandi.pretty_echo(result)\n\n    return result", "response": "Create a new vhost."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates a vhost. Right now you can only activate ssl on the vhost.", "response": "def update(gandi, resource, ssl, private_key, poll_cert):\n    \"\"\" Update a vhost.\n\n    Right now you can only activate ssl on the vhost.\n    \"\"\"\n    gandi.hostedcert.activate_ssl(resource, ssl, private_key, poll_cert)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef option(*param_decls, **attrs):\n    def decorator(f):\n        _param_memo(f, GandiOption(param_decls, **attrs))\n        return f\n    return decorator", "response": "Decorator to create an option."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef choices(self):\n        if not self._choices:\n            gandi = self.gandi or GandiContextHelper()\n            self._choices = self._get_choices(gandi)\n            if not self._choices:\n                api = gandi.get_api_connector()\n                gandi.echo('Please check that you are connecting to the good '\n                           \"api '%s' and that it's running.\" % (api.host))\n                sys.exit(1)\n\n        return self._choices", "response": "Retrieve choices from API if possible"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_choices(self, gandi):\n        iso_codes = []\n        dc_codes = []\n        for item in gandi.datacenter.list():\n            iso_codes.append(item['iso'])\n            if item.get('dc_code'):\n                dc_codes.append(item['dc_code'])\n        return dc_codes + iso_codes", "response": "Internal method to get choices list."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_choices(self, gandi):\n        image_list = []\n        for item in gandi.image.list():\n            label = item['label']\n            if item['visibility'] == 'deprecated':\n                label = '*%s' % label\n            image_list.append(label)\n        disk_list = [item['name'] for item in gandi.disk.list_create()]\n        return sorted(tuple(set(image_list))) + disk_list", "response": "Internal method to get choices list."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef convert(self, value, param, ctx):\n        self.gandi = ctx.obj\n        # remove deprecated * prefix\n        choices = [choice.replace('*', '') for choice in self.choices]\n        value = value.replace('*', '')\n        # Exact match\n        if value in choices:\n            return value\n\n        # Try to find 64 bits version\n        new_value = '%s 64 bits' % value\n        if new_value in choices:\n            return new_value\n\n        # Try to find without specific bits version\n        p = re.compile(' (64|32) bits')\n        new_value = p.sub('', value)\n        if new_value in choices:\n            return new_value\n\n        self.fail('invalid choice: %s. (choose from %s)' %\n                  (value, ', '.join(self.choices)), param, ctx)", "response": "Try to find correct disk image regarding version."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_choices(self, gandi):\n        kernel_families = list(gandi.kernel.list().values())\n        return [kernel for klist in kernel_families for kernel in klist]", "response": "Internal method to get choices list"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef convert(self, value, param, ctx):\n        self.gandi = ctx.obj\n        # Exact match first\n        if value in self.choices:\n            return value\n\n        # Also try with x86-64 suffix\n        new_value = '%s-x86_64' % value\n        if new_value in self.choices:\n            return new_value\n\n        self.fail('invalid choice: %s. (choose from %s)' %\n                  (value, ', '.join(self.choices)), param, ctx)", "response": "Try to find correct kernel regarding version."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_choices(self, gandi):\n        return [str(item['id'])\n                for item in gandi.snapshotprofile.list(target=self.target)]", "response": "Internal method to get choices list"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting value to int.", "response": "def convert(self, value, param, ctx):\n        \"\"\" Convert value to int. \"\"\"\n        self.gandi = ctx.obj\n        value = click.Choice.convert(self, value, param, ctx)\n        return int(value)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_choices(self, gandi):\n        packages = super(CertificatePackageType, self)._get_choices(gandi)\n        return list(set([pack.split('_')[1] for pack in packages]))", "response": "Internal method to get choices list"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_choices(self, gandi):\n        packages = super(CertificatePackageMax, self)._get_choices(gandi)\n        ret = list(set([pack.split('_')[2] for pack in packages]))\n        if 'w' in ret:\n            ret.remove('w')\n        return ret", "response": "Internal method to get choices list."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef convert(self, value, param, ctx):\n        rxp = '^[^@]+?@[-.a-z0-9]+$'\n        regex = re.compile(rxp, re.I)\n        try:\n            if regex.match(value):\n                value = value.split(\"@\")\n                return value\n            else:\n                self.fail('%s is not a valid email address' % value, param,\n                          ctx)\n        except ValueError:\n            self.fail('%s is not a valid email address' % value, param, ctx)", "response": "Validate value using regexp."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef convert(self, value, param, ctx):\n        rxp = \"^(((([1]?\\d)?\\d|2[0-4]\\d|25[0-5])\\.){3}(([1]?\\d)?\\d|2[0-4]\\d|\"\\\n              \"25[0-5]))|([\\da-fA-F]{1,4}(\\:[\\da-fA-F]{1,4}){7})|(([\\da-fA-F]\"\\\n              \"{1,4}:){0,5}::([\\da-fA-F]{1,4}:)\"\\\n              \"{0,5}[\\da-fA-F]{1,4})$\"\n        regex = re.compile(rxp, re.I)\n        backend = {}\n        if value.count(':') == 0:\n            # port is not set\n            backend['ip'] = value\n        elif value.count(':') == 7:\n            # it's an ipv6 without port\n            backend['ip'] = value\n        elif value.count(':') == 8:\n            # it's an ipv6 with port\n            backend['ip'] = value.rsplit(':', 1)[0]\n            backend['port'] = int(value.rsplit(':', 1)[1])\n        else:\n            backend['ip'] = value.split(':')[0]\n            backend['port'] = int(value.split(':')[1])\n        try:\n            if regex.match(backend['ip']):\n                return backend\n            else:\n                self.fail('%s is not a valid ip address' %\n                          backend['ip'], param, ctx)\n        except ValueError:\n            self.fail('%s is not a valid ip address' % backend['ip'], param,\n                      ctx)", "response": "Validate value using regexp."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndisplays value used for this parameter.", "response": "def display_value(self, ctx, value):\n        \"\"\" Display value to be used for this parameter. \"\"\"\n        gandi = ctx.obj\n        gandi.log('%s: %s' % (self.name, (value if value is not None\n                                          else 'Not found')))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_default(self, ctx):\n        value = click.Option.get_default(self, ctx)\n        if not self.prompt:\n            # value found in default display it\n            self.display_value(ctx, value)\n        return value", "response": "Retrieve default value and display it when prompt disabled."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef consume_value(self, ctx, opts):\n        value = click.Option.consume_value(self, ctx, opts)\n        if not value:\n            # value not found by click on command line\n            # now check using our context helper in order into\n            # local configuration\n            # global configuration\n            gandi = ctx.obj\n            value = gandi.get(self.name)\n            if value is not None:\n                # value found in configuration display it\n                self.display_value(ctx, value)\n            else:\n                if self.default is None and self.required:\n                    metavar = ''\n                    if self.type.name not in ['integer', 'text']:\n                        metavar = self.make_metavar()\n                    prompt = '%s %s' % (self.help, metavar)\n                    gandi.echo(prompt)\n        return value", "response": "Retrieve default value and display it when prompt is disabled."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef handle_parse_result(self, ctx, opts, args):\n        gandi = ctx.obj\n        needs_update = False\n        value, args = click.Option.handle_parse_result(self, ctx, opts, args)\n\n        if value is not None:\n            previous_value = gandi.get(global_=True, key=self.name)\n            if isinstance(self.type, GandiChoice):\n                if value == previous_value:\n                    needs_update = True\n                value = self.type.convert_deprecated_value(value)\n            if not previous_value or needs_update:\n                gandi.configure(global_=True, key=self.name, val=value)\n        opts[self.name] = value\n        value, args = click.Option.handle_parse_result(self, ctx, opts, args)\n        return value, args", "response": "Handle parsing of the option value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef autorenew_deactivate(cls, fqdn):\n        fqdn = fqdn.lower()\n\n        result = cls.call('domain.autorenew.deactivate', fqdn)\n\n        return result", "response": "Deactivate autorenew for a domain."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nactivating autorenew for a domain.", "response": "def autorenew_activate(cls, fqdn):\n        \"\"\"Activate autorenew\"\"\"\n        fqdn = fqdn.lower()\n\n        result = cls.call('domain.autorenew.activate', fqdn)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve domain id associated to a FQDN.", "response": "def from_fqdn(cls, fqdn):\n        \"\"\"Retrieve domain id associated to a FQDN.\"\"\"\n        result = cls.list({'fqdn': fqdn})\n        if len(result) > 0:\n            return result[0]['id']"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndisplay information about a disk.", "response": "def info(gandi, resource):\n    \"\"\" Display information about a disk.\n\n    Resource can be a disk name or ID\n    \"\"\"\n    output_keys = ['name', 'state', 'size', 'type', 'id', 'dc', 'vm',\n                   'profile', 'kernel', 'cmdline']\n\n    resource = sorted(tuple(set(resource)))\n    vms = dict([(vm['id'], vm) for vm in gandi.iaas.list()])\n    datacenters = gandi.datacenter.list()\n\n    result = []\n    for num, item in enumerate(resource):\n        if num:\n            gandi.separator_line()\n        disk = gandi.disk.info(item)\n        output_disk(gandi, disk, datacenters, vms, [], output_keys)\n        result.append(disk)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef detach(gandi, resource, background, force):\n    resource = sorted(tuple(set(resource)))\n    if not force:\n        proceed = click.confirm('Are you sure you want to detach %s?' %\n                                ', '.join(resource))\n        if not proceed:\n            return\n\n    result = gandi.disk.detach(resource, background)\n    if background:\n        gandi.pretty_echo(result)\n\n    return result", "response": "Detach disks from currectly attached vm."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nattaches a disk to a vm.", "response": "def attach(gandi, disk, vm, position, read_only, background, force):\n    \"\"\" Attach disk to vm.\n\n    disk can be a disk name, or ID\n    vm can be a vm name, or ID\n    \"\"\"\n    if not force:\n        proceed = click.confirm(\"Are you sure you want to attach disk '%s'\"\n                                \" to vm '%s'?\" % (disk, vm))\n        if not proceed:\n            return\n\n    disk_info = gandi.disk.info(disk)\n    attached = disk_info.get('vms_id', False)\n    if attached and not force:\n        gandi.echo('This disk is still attached')\n        proceed = click.confirm('Are you sure you want to detach %s?' % disk)\n\n        if not proceed:\n            return\n\n    result = gandi.disk.attach(disk, vm, background, position, read_only)\n    if background and result:\n        gandi.pretty_echo(result)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(gandi, resource, cmdline, kernel, name, size,\n           snapshotprofile, delete_snapshotprofile, background):\n    \"\"\" Update a disk.\n\n    Resource can be a disk name, or ID\n    \"\"\"\n    if snapshotprofile and delete_snapshotprofile:\n        raise UsageError('You must not set snapshotprofile and '\n                         'delete-snapshotprofile.')\n\n    if delete_snapshotprofile:\n        snapshotprofile = ''\n\n    if kernel:\n        source_info = gandi.disk.info(resource)\n        available = gandi.kernel.is_available(source_info, kernel)\n        if not available:\n            raise UsageError('Kernel %s is not available for disk %s' %\n                             (kernel, resource))\n\n    result = gandi.disk.update(resource, name, size, snapshotprofile,\n                               background, cmdline, kernel)\n    if background:\n        gandi.pretty_echo(result)\n\n    return result", "response": "Update a disk.\n\n    Resource can be a disk name, or ID"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new disk.", "response": "def create(gandi, name, vm, size, snapshotprofile, datacenter, source,\n           background):\n    \"\"\" Create a new disk. \"\"\"\n    try:\n        gandi.datacenter.is_opened(datacenter, 'iaas')\n    except DatacenterLimited as exc:\n        gandi.echo('/!\\ Datacenter %s will be closed on %s, '\n                   'please consider using another datacenter.' %\n                   (datacenter, exc.date))\n\n    if vm:\n        vm_dc = gandi.iaas.info(vm)\n        vm_dc_id = vm_dc['datacenter_id']\n        dc_id = int(gandi.datacenter.usable_id(datacenter))\n        if vm_dc_id != dc_id:\n            gandi.echo('/!\\ VM %s datacenter will be used instead of %s.'\n                       % (vm, datacenter))\n        datacenter = vm_dc_id\n\n    output_keys = ['id', 'type', 'step']\n    name = name or randomstring('vdi')\n\n    disk_type = 'data'\n    oper = gandi.disk.create(name, vm, size, snapshotprofile, datacenter,\n                             source, disk_type, background)\n\n    if background:\n        output_generic(gandi, oper, output_keys)\n\n    return oper"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef snapshot(gandi, name, resource, background):\n    name = name or randomstring('snp')\n\n    source_info = gandi.disk.info(resource)\n    datacenter = source_info['datacenter_id']\n    result = gandi.disk.create(name, None, None, None, datacenter, resource,\n                               'snapshot', background)\n\n    if background:\n        gandi.pretty_echo(result)\n    return result", "response": "Create a snapshot on the fly."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef migrate(gandi, resource, force, background):\n    # check it's not attached\n    source_info = gandi.disk.info(resource)\n    if source_info['vms_id']:\n        click.echo('Cannot start the migration: disk %s is attached. '\n                   'Please detach the disk before starting the migration.'\n                   % resource)\n        return\n\n    disk_datacenter = source_info['datacenter_id']\n    dc_choices = gandi.datacenter.list_migration_choice(disk_datacenter)\n    if not dc_choices:\n        click.echo('No datacenter is available for migration')\n        return\n    elif len(dc_choices) == 1:\n        # use the only one available\n        datacenter_id = dc_choices[0]['id']\n    else:\n        choice_list = [dc['dc_code'] for dc in dc_choices]\n        dc_choice = click.Choice(choice_list)\n        dc_chosen = click.prompt('Select a datacenter [%s]' % '|'.join(choice_list),  # noqa\n                                 type=dc_choice,\n                                 show_default=True)\n        datacenter_id = [dc['id'] for dc in dc_choices\n                         if dc['dc_code'] == dc_chosen][0]\n\n    if not force:\n        proceed = click.confirm('Are you sure you want to migrate disk %s ?'\n                                % resource)\n        if not proceed:\n            return\n\n    datacenters = gandi.datacenter.list()\n    dc_from = [dc['dc_code']\n               for dc in datacenters if dc['id'] == disk_datacenter][0]\n    dc_to = [dc['dc_code']\n             for dc in datacenters if dc['id'] == datacenter_id][0]\n    migration_msg = ('* Starting the migration of disk %s from datacenter %s '\n                     'to %s' % (resource, dc_from, dc_to))\n    gandi.echo(migration_msg)\n\n    output_keys = ['id', 'type', 'step']\n    oper = gandi.disk.migrate(resource, datacenter_id, background)\n    if background:\n        output_generic(gandi, oper, output_keys)\n\n    return oper", "response": "Migrate a disk to another datacenter."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef format_list(data):\n    if isinstance(data, (list, tuple)):\n        to_clean = ['[', ']', '(', ')', \"'\"]\n        for item in to_clean:\n            data = str(data).replace(\"u\\\"\", \"\\\"\").replace(\"u\\'\", \"\\'\")\n            data = str(data).replace(item, '')\n    return data", "response": "Remove useless characters to output a clean list."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbasing helper to output a key value using left justify.", "response": "def output_line(gandi, key, val, justify):\n    \"\"\" Base helper to output a key value using left justify.\"\"\"\n    msg = ('%%-%ds:%%s' % justify) % (key, (' %s' % val) if val else '')\n    gandi.echo(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef output_generic(gandi, data, output_keys, justify=10):\n    for key in output_keys:\n        if key in data:\n            output_line(gandi, key, data[key], justify)", "response": "Generic helper to output info from a data dict."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef output_account(gandi, account, output_keys, justify=17):\n    output_generic(gandi, account, output_keys, justify)\n\n    if 'prepaid' in output_keys:\n        prepaid = '%s %s' % (account['prepaid_info']['amount'],\n                             account['prepaid_info']['currency'])\n        output_line(gandi, 'prepaid', prepaid, justify)\n\n    if 'credit' in output_keys:\n        output_line(gandi, 'credits', None, justify)\n        available = account.get('credits')\n        output_line(gandi, '        available', available, justify)\n        # sometimes rating is returning nothing\n        usage_str = left_str = 'not available'\n        usage = account.get('credit_usage', 0)\n        left = account.get('left')\n        if usage:\n            usage_str = '%d/h' % usage\n\n            years, months, days, hours = left\n            left_str = ('%d year(s) %d month(s) %d day(s) %d hour(s)' %\n                        (years, months, days, hours))\n\n        output_line(gandi, '        usage', usage_str, justify)\n        output_line(gandi, '        time left', left_str, justify)", "response": "Helper to output an account information."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef output_vm(gandi, vm, datacenters, output_keys, justify=10):\n    output_generic(gandi, vm, output_keys, justify)\n\n    if 'datacenter' in output_keys:\n        for dc in datacenters:\n            if dc['id'] == vm['datacenter_id']:\n                dc_name = dc.get('dc_code', dc.get('iso', ''))\n                break\n\n        output_line(gandi, 'datacenter', dc_name, justify)\n\n    if 'ip' in output_keys:\n        for iface in vm['ifaces']:\n            gandi.separator_line()\n            output_line(gandi, 'bandwidth', iface['bandwidth'], justify)\n\n            for ip in iface['ips']:\n                ip_addr = ip['ip']\n\n                output_line(gandi, 'ip%s' % ip['version'], ip_addr, justify)", "response": "Helper to output a VM information."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef output_paas(gandi, paas, datacenters, vhosts, output_keys, justify=11):\n    output_generic(gandi, paas, output_keys, justify)\n\n    if 'sftp_server' in output_keys:\n        output_line(gandi, 'sftp_server', paas['ftp_server'], justify)\n\n    if 'vhost' in output_keys:\n        for entry in vhosts:\n            output_line(gandi, 'vhost', entry, justify)\n\n    if 'dc' in output_keys:\n        dc_name = paas['datacenter'].get('dc_code',\n                                         paas['datacenter'].get('iso', ''))\n        output_line(gandi, 'datacenter', dc_name, justify)\n\n    if 'df' in paas:\n        df = paas['df']\n        total = df['free'] + df['used']\n        if total:\n            disk_used = '%.1f%%' % (df['used'] * 100 / total)\n            output_line(gandi, 'quota used', disk_used, justify)\n\n    if 'snapshot' in output_keys:\n        val = None\n        if paas['snapshot_profile']:\n            val = paas['snapshot_profile']['name']\n        output_line(gandi, 'snapshot', val, justify)\n\n    if 'cache' in paas:\n        cache = paas['cache']\n        total = cache['hit'] + cache['miss'] + cache['not'] + cache['pass']\n        if total:\n            output_line(gandi, 'cache', None, justify)\n            for key in sorted(cache):\n                str_value = '%.1f%%' % (cache[key] * 100 / total)\n                output_sub_line(gandi, key, str_value, 5)", "response": "Helper to output a paas information."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef output_image(gandi, image, datacenters, output_keys, justify=14,\n                 warn_deprecated=True):\n    \"\"\" Helper to output a disk image.\"\"\"\n\n    for key in output_keys:\n        if key in image:\n            if (key == 'label' and image['visibility'] == 'deprecated' and\n                    warn_deprecated):\n                image[key] = '%s /!\\ DEPRECATED' % image[key]\n            output_line(gandi, key, image[key], justify)\n\n    dc_name = 'Nowhere'\n\n    if 'dc' in output_keys:\n        for dc in datacenters:\n            if dc['id'] == image['datacenter_id']:\n                dc_name = dc.get('dc_code', dc.get('iso', ''))\n\n                break\n\n        output_line(gandi, 'datacenter', dc_name, justify)", "response": "Helper to output a disk image."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef output_sshkey(gandi, sshkey, output_keys, justify=12):\n    output_generic(gandi, sshkey, output_keys, justify)", "response": "Helper to output an ssh key information."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef output_cert(gandi, cert, output_keys, justify=13):\n    output = list(output_keys)\n\n    display_altnames = False\n    if 'altnames' in output:\n        display_altnames = True\n        output.remove('altnames')\n\n    display_output = False\n    if 'cert' in output:\n        display_output = True\n        output.remove('cert')\n\n    output_generic(gandi, cert, output, justify)\n\n    if display_output:\n        crt = gandi.certificate.pretty_format_cert(cert)\n        if crt:\n            output_line(gandi, 'cert', '\\n' + crt, justify)\n\n    if display_altnames:\n        for altname in cert['altnames']:\n            output_line(gandi, 'altname', altname, justify)", "response": "Helper to output a certificate information."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef output_json(gandi, format, value):\n    if format == 'json':\n        gandi.echo(json.dumps(value, default=date_handler, sort_keys=True))\n    elif format == 'pretty-json':\n        gandi.echo(json.dumps(value, default=date_handler, sort_keys=True,\n                              indent=2, separators=(',', ': ')))", "response": "Helper to show json output"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbases helper to output a key value using left justify.", "response": "def output_sub_line(gandi, key, val, justify):\n    \"\"\" Base helper to output a key value using left justify.\"\"\"\n    msg = ('\\t%%-%ds:%%s' % justify) % (key, (' %s' % val) if val else '')\n    gandi.echo(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef output_sub_generic(gandi, data, output_keys, justify=10):\n    for key in output_keys:\n        if key in data:\n            output_sub_line(gandi, key, data[key], justify)", "response": "Generic helper to output info from a data dict."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef output_service(gandi, service, status, justify=10):\n    output_line(gandi, service, status, justify)", "response": "Helper to output a status service information."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef output_forward(gandi, domain, forward, justify=14):\n    for dest in forward['destinations']:\n        output_line(gandi, forward['source'], dest, justify)", "response": "Helper to output a mail forward information."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef info(gandi, resource):\n    output_keys = ['ip', 'state', 'dc', 'type', 'vm', 'reverse']\n\n    datacenters = gandi.datacenter.list()\n\n    ip = gandi.ip.info(resource)\n    iface = gandi.iface.info(ip['iface_id'])\n    vms = None\n    if iface.get('vm_id'):\n        vm = gandi.iaas.info(iface['vm_id'])\n        vms = {vm['id']: vm}\n\n    output_ip(gandi, ip, datacenters, vms, {iface['id']: iface},\n              output_keys)\n\n    return ip", "response": "Display information about an ip."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef attach(gandi, ip, vm, background, force):\n    try:\n        ip_ = gandi.ip.info(ip)\n        vm_ = gandi.iaas.info(vm)\n    except UsageError:\n        gandi.error(\"Can't find this ip %s\" % ip)\n\n    iface = gandi.iface.info(ip_['iface_id'])\n    if iface.get('vm_id'):\n        if vm_ and iface['vm_id'] == vm_.get('id'):\n            gandi.echo('This ip is already attached to this vm.')\n            return\n\n        if not force:\n            proceed = click.confirm('Are you sure you want to detach'\n                                    ' %s from vm %s' %\n                                    (ip_['ip'], iface['vm_id']))\n            if not proceed:\n                return\n\n    return gandi.ip.attach(ip, vm, background, force)", "response": "Attach an ip to a vm."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create(gandi, datacenter, bandwidth, ip_version, vlan, ip, attach,\n           background):\n    \"\"\"Create a public or private ip\n    \"\"\"\n    if ip_version != 4 and vlan:\n        gandi.echo('You must have an --ip-version to 4 when having a vlan.')\n        return\n\n    if ip and not vlan:\n        gandi.echo('You must have a --vlan when giving an --ip.')\n        return\n\n    vm_ = gandi.iaas.info(attach) if attach else None\n\n    if datacenter and vm_:\n        dc_id = gandi.datacenter.usable_id(datacenter)\n        if dc_id != vm_['datacenter_id']:\n            gandi.echo('The datacenter you provided does not match the '\n                       'datacenter of the vm you want to attach to.')\n            return\n\n    if not datacenter:\n        datacenter = vm_['datacenter_id'] if vm_ else 'LU'\n\n    try:\n        gandi.datacenter.is_opened(datacenter, 'iaas')\n    except DatacenterLimited as exc:\n        gandi.echo('/!\\ Datacenter %s will be closed on %s, '\n                   'please consider using another datacenter.' %\n                   (datacenter, exc.date))\n\n    return gandi.ip.create(ip_version, datacenter, bandwidth, attach,\n                           vlan, ip, background)", "response": "Helper to create a public or private ip."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef detach(gandi, resource, background, force):\n    if not force:\n        proceed = click.confirm('Are you sure you want to detach ip %s?' %\n                                resource)\n        if not proceed:\n            return\n\n    return gandi.ip.detach(resource, background, force)", "response": "Detach an ip from it s currently attached vm."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete(gandi, resource, background, force):\n    resource = sorted(tuple(set(resource)))\n    possible_resources = gandi.ip.resource_list()\n\n    # check that each IP can be deleted\n    for item in resource:\n        if item not in possible_resources:\n            gandi.echo('Sorry interface %s does not exist' % item)\n            gandi.echo('Please use one of the following: %s' %\n                       possible_resources)\n            return\n\n    if not force:\n        proceed = click.confirm('Are you sure you want to delete ip(s) %s' %\n                                ', '.join(resource))\n        if not proceed:\n            return\n\n    return gandi.ip.delete(resource, background, force)", "response": "Delete one or more IPs."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndisplays value of a given config key.", "response": "def get(gandi, g, key):\n    \"\"\"Display value of a given config key.\"\"\"\n    val = gandi.get(key=key, global_=g)\n    if not val:\n        gandi.echo(\"No value found.\")\n        sys.exit(1)\n    gandi.echo(val)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating or create config key / value.", "response": "def set(gandi, g, key, value):\n    \"\"\"Update or create config key/value.\"\"\"\n    gandi.configure(global_=g, key=key, val=value)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nedit config file with prefered text editor", "response": "def edit(gandi, g):\n    \"\"\"Edit config file with prefered text editor\"\"\"\n    config_file = gandi.home_config if g else gandi.local_config\n    path = os.path.expanduser(config_file)\n    editor = gandi.get('editor')\n    if not editor:\n        try:\n            editor = click.prompt(\"Please enter the path of your prefered \"\n                                  \"editor. eg: '/usr/bin/vi' or 'vi'\")\n        except Abort:\n            gandi.echo(\"\"\"\nWarning: editor is not configured.\nYou can use both 'gandi config set [-g] editor <value>'\nor the $EDITOR environment variable to configure it.\"\"\")\n            sys.exit(1)\n\n    subprocess.call([editor, path])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete(gandi, g, key):\n    gandi.delete(global_=g, key=key)", "response": "Delete a key value pair from configuration."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new webaccelerator.", "response": "def create(cls, name, datacenter, backends, vhosts, algorithm,\n               ssl_enable, zone_alter):\n        \"\"\" Create a webaccelerator \"\"\"\n        datacenter_id_ = int(Datacenter.usable_id(datacenter))\n        params = {\n            'datacenter_id': datacenter_id_,\n            'name': name,\n            'lb': {'algorithm': algorithm},\n            'override': True,\n            'ssl_enable': ssl_enable,\n            'zone_alter': zone_alter\n        }\n        if vhosts:\n            params['vhosts'] = vhosts\n        if backends:\n            params['servers'] = backends\n        try:\n            result = cls.call('hosting.rproxy.create', params)\n            cls.echo('Creating your webaccelerator %s' % params['name'])\n            cls.display_progress(result)\n            cls.echo('Your webaccelerator have been created')\n            return result\n        except Exception as err:\n            if err.code == 580142:\n                for vhost in params['vhosts']:\n                    dns_entry = cls.call(\n                        'hosting.rproxy.vhost.get_dns_entries',\n                        {'datacenter': datacenter_id_, 'vhost': vhost})\n                    txt_record = \"@ 3600 IN TXT \\\"%s=%s\\\"\" % (dns_entry['key'],\n                                                              dns_entry['txt'])\n\n                    cname_record = \"%s 3600 IN CNAME %s\" % (dns_entry['key'],\n                                                            dns_entry['cname'])\n\n                    cls.echo('The domain %s don\\'t use Gandi DNS or you have'\n                             ' not sufficient right to alter the zone file. '\n                             'Edit your zone file adding this TXT and CNAME '\n                             'record and try again :' % vhost)\n                    cls.echo(txt_record)\n                    cls.echo(cname_record)\n                    cls.echo('\\nOr add a file containing %s at :\\n'\n                             'http://%s/%s.txt\\n' % (dns_entry['txt'],\n                                                     dns_entry['domain'],\n                                                     dns_entry['txt']))\n                    cls.separator_line('-', 4)\n            else:\n                cls.echo(err)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef backend_add(cls, name, backend):\n        oper = cls.call(\n            'hosting.rproxy.server.create', cls.usable_id(name), backend)\n        cls.echo('Adding backend %s:%s into webaccelerator' %\n                 (backend['ip'], backend['port']))\n        cls.display_progress(oper)\n        cls.echo('Backend added')\n        return oper", "response": "Add a backend into a webaccelerator"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef backend_disable(cls, backend):\n        server = cls.backend_list(backend)\n        oper = cls.call('hosting.rproxy.server.disable',\n                        server[0]['id'])\n        cls.echo('Desactivating backend on server %s' %\n                 server[0]['ip'])\n        cls.display_progress(oper)\n        cls.echo('Backend desactivated')\n        return oper", "response": "Disable a backend for a server"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef vhost_add(cls, resource, params):\n        try:\n            oper = cls.call(\n                'hosting.rproxy.vhost.create', cls.usable_id(resource), params)\n            cls.echo('Adding your virtual host (%s) into %s' %\n                     (params['vhost'], resource))\n            cls.display_progress(oper)\n            cls.echo('Your virtual host habe been added')\n            return oper\n        except Exception as err:\n            if err.code == 580142:\n                dc = cls.info(resource)\n                dns_entry = cls.call('hosting.rproxy.vhost.get_dns_entries',\n                                     {'datacenter': dc['datacenter']['id'],\n                                      'vhost': params['vhost']})\n                txt_record = \"%s 3600 IN TXT \\\"%s=%s\\\"\" % (dns_entry['key'],\n                                                           dns_entry['key'],\n                                                           dns_entry['txt'])\n\n                cname_record = \"%s 3600 IN CNAME %s\" % (dns_entry['key'],\n                                                        dns_entry['cname'])\n\n                cls.echo('The domain don\\'t use Gandi DNS or you have not'\n                         ' sufficient right to alter the zone file. '\n                         'Edit your zone file adding this TXT and CNAME '\n                         'record and try again :')\n                cls.echo(txt_record)\n                cls.echo(cname_record)\n                cls.echo('\\nOr add a file containing %s at :\\n'\n                         'http://%s/%s.txt\\n' % (dns_entry['txt'],\n                                                 dns_entry['domain'],\n                                                 dns_entry['txt']))\n\n            else:\n                cls.echo(err)", "response": "Add a vhost into a webaccelerator"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef vhost_remove(cls, name):\n        oper = cls.call('hosting.rproxy.vhost.delete', name)\n        cls.echo('Deleting your virtual host %s' % name)\n        cls.display_progress(oper)\n        cls.echo('Your virtual host have been removed')\n        return oper", "response": "Delete a vhost in a webaccelerator"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting a probe for a webaccelerator", "response": "def probe(cls, resource, enable, disable, test, host, interval,\n              http_method, http_response, threshold, timeout, url, window):\n        \"\"\" Set a probe for a webaccelerator \"\"\"\n        params = {\n            'host': host,\n            'interval': interval,\n            'method': http_method,\n            'response': http_response,\n            'threshold': threshold,\n            'timeout': timeout,\n            'url': url,\n            'window': window\n        }\n        if enable:\n            params['enable'] = True\n        elif disable:\n            params['enable'] = False\n        if test:\n            result = cls.call(\n                'hosting.rproxy.probe.test', cls.usable_id(resource), params)\n        else:\n            result = cls.call(\n                'hosting.rproxy.probe.update', cls.usable_id(resource), params)\n            cls.display_progress(result)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef probe_enable(cls, resource):\n        oper = cls.call('hosting.rproxy.probe.enable', cls.usable_id(resource))\n        cls.echo('Activating probe on %s' % resource)\n        cls.display_progress(oper)\n        cls.echo('The probe have been activated')\n        return oper", "response": "Activate a probe on a webaccelerator"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndisable a probe on a webaccelerator", "response": "def probe_disable(cls, resource):\n        \"\"\" Disable a probe on a webaccelerator \"\"\"\n        oper = cls.call('hosting.rproxy.probe.disable',\n                        cls.usable_id(resource))\n        cls.echo('Desactivating probe on %s' % resource)\n        cls.display_progress(oper)\n        cls.echo('The probe have been desactivated')\n        return oper"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves id from input which can be hostname ip vhost or id.", "response": "def usable_id(cls, id):\n        \"\"\" Retrieve id from input which can be hostname, vhost, id. \"\"\"\n        try:\n            # id is maybe a hostname\n            qry_id = cls.from_name(id)\n            if not qry_id:\n                # id is maybe an ip\n                qry_id = cls.from_ip(id)\n            if not qry_id:\n                qry_id = cls.from_vhost(id)\n        except Exception:\n            qry_id = None\n\n        if not qry_id:\n            msg = 'unknown identifier %s' % id\n            cls.error(msg)\n\n        return qry_id"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_name(cls, name):\n        result = cls.list({'items_per_page': 500})\n        webaccs = {}\n        for webacc in result:\n            webaccs[webacc['name']] = webacc['id']\n        return webaccs.get(name)", "response": "Retrieve webacc id associated to a webacc name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_ip(cls, ip):\n        result = cls.list({'items_per_page': 500})\n        webaccs = {}\n        for webacc in result:\n            for server in webacc['servers']:\n                webaccs[server['ip']] = webacc['id']\n        return webaccs.get(ip)", "response": "Retrieve webacc id associated to a webacc ip"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_vhost(cls, vhost):\n        result = cls.list({'items_per_page': 500})\n        webaccs = {}\n        for webacc in result:\n            for vhost in webacc['vhosts']:\n                webaccs[vhost['name']] = webacc['id']\n        return webaccs.get(vhost)", "response": "Retrieve webbacc id associated to a webacc vhost"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving status descriptions from status. gandi. net.", "response": "def descriptions(cls):\n        \"\"\" Retrieve status descriptions from status.gandi.net. \"\"\"\n        schema = cls.json_get('%s/status/schema' % cls.api_url, empty_key=True,\n                              send_key=False)\n        descs = {}\n        for val in schema['fields']['status']['value']:\n            descs.update(val)\n        return descs"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef services(cls):\n        return cls.json_get('%s/services' % cls.api_url, empty_key=True,\n                            send_key=False)", "response": "Retrieve statuses from status. gandi. net."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef status(cls):\n        return cls.json_get('%s/status' % cls.api_url, empty_key=True,\n                            send_key=False)", "response": "Retrieve global status from status. gandi. net."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef events(cls, filters):\n        current = filters.pop('current', False)\n        current_params = []\n        if current:\n            current_params = [('current', 'true')]\n\n        filter_url = uparse.urlencode(sorted(list(filters.items())) + current_params)  # noqa\n        events = cls.json_get('%s/events?%s' % (cls.api_url, filter_url),\n                              empty_key=True, send_key=False)\n        return events", "response": "Retrieve events details from status. gandi. net."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndisplaying information about a PaaS instance.", "response": "def info(gandi, resource, stat):\n    \"\"\"Display information about a PaaS instance.\n\n    Resource can be a vhost, a hostname, or an ID\n    Cache statistics are based on 24 hours data.\n    \"\"\"\n    output_keys = ['name', 'type', 'size', 'memory', 'console', 'vhost',\n                   'dc', 'sftp_server', 'git_server', 'snapshot']\n\n    paas = gandi.paas.info(resource)\n    paas_hosts = []\n    list_vhost = gandi.vhost.list({'paas_id': paas['id']})\n\n    df = gandi.paas.quota(paas['id'])\n    paas.update({'df': df})\n\n    if stat:\n        cache = gandi.paas.cache(paas['id'])\n        paas.update({'cache': cache})\n\n    for host in list_vhost:\n        paas_hosts.append(host['name'])\n\n    output_paas(gandi, paas, [], paas_hosts, output_keys)\n\n    return paas"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clone(gandi, name, vhost, directory, origin):\n    if vhost != 'default':\n        directory = vhost\n    else:\n        directory = name if not directory else directory\n\n    return gandi.paas.clone(name, vhost, directory, origin)", "response": "Clone a remote vhost in a local git repository."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef attach(gandi, name, vhost, remote):\n    return gandi.paas.attach(name, vhost, remote)", "response": "Attach an instance to a remote."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new PaaS instance and initialize associated git repository.", "response": "def create(gandi, name, size, type, quantity, duration, datacenter, vhosts,\n           password, snapshotprofile, background, sshkey, ssl, private_key,\n           poll_cert):\n    \"\"\"Create a new PaaS instance and initialize associated git repository.\n\n    you can specify a configuration entry named 'sshkey' containing\n    path to your sshkey file\n\n    $ gandi config set [-g] sshkey ~/.ssh/id_rsa.pub\n\n    or getting the sshkey \"my_key\" from your gandi ssh keyring\n\n    $ gandi config set [-g] sshkey my_key\n\n    to know which PaaS instance type to use as type\n\n    $ gandi paas types\n\n    \"\"\"\n    try:\n        gandi.datacenter.is_opened(datacenter, 'paas')\n    except DatacenterLimited as exc:\n        gandi.echo('/!\\ Datacenter %s will be closed on %s, '\n                   'please consider using another datacenter.' %\n                   (datacenter, exc.date))\n\n    if not password:\n        password = click.prompt('password', hide_input=True,\n                                confirmation_prompt=True)\n\n    if not name:\n        name = randomstring('paas')\n\n    if vhosts and not gandi.hostedcert.activate_ssl(vhosts,\n                                                    ssl,\n                                                    private_key,\n                                                    poll_cert):\n        return\n\n    result = gandi.paas.create(name, size, type, quantity, duration,\n                               datacenter, vhosts, password,\n                               snapshotprofile, background, sshkey)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update(gandi, resource, name, size, quantity, password, sshkey,\n           upgrade, console, snapshotprofile, reset_mysql_password,\n           background, delete_snapshotprofile):\n    \"\"\"Update a PaaS instance.\n\n    Resource can be a Hostname or an ID\n    \"\"\"\n\n    if snapshotprofile and delete_snapshotprofile:\n        raise UsageError('You must not set snapshotprofile and '\n                         'delete-snapshotprofile.')\n\n    pwd = None\n    if password:\n        pwd = click.prompt('password', hide_input=True,\n                           confirmation_prompt=True)\n\n    if delete_snapshotprofile:\n        snapshotprofile = ''\n\n    result = gandi.paas.update(resource, name, size, quantity, pwd,\n                               sshkey, upgrade, console, snapshotprofile,\n                               reset_mysql_password, background)\n    if background:\n        gandi.pretty_echo(result)\n\n    return result", "response": "Update a PaaS instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrestarting a PaaS instance.", "response": "def restart(gandi, resource, background, force):\n    \"\"\"Restart a PaaS instance.\n\n    Resource can be a vhost, a hostname, or an ID\n    \"\"\"\n    output_keys = ['id', 'type', 'step']\n\n    possible_resources = gandi.paas.resource_list()\n    for item in resource:\n        if item not in possible_resources:\n            gandi.echo('Sorry PaaS instance %s does not exist' % item)\n            gandi.echo('Please use one of the following: %s' %\n                       possible_resources)\n            return\n\n    if not force:\n        instance_info = \"'%s'\" % ', '.join(resource)\n        proceed = click.confirm(\"Are you sure to restart PaaS instance %s?\" %\n                                instance_info)\n\n        if not proceed:\n            return\n\n    opers = gandi.paas.restart(resource, background)\n    if background:\n        for oper in opers:\n            output_generic(gandi, oper, output_keys)\n\n    return opers"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef types(gandi):\n    options = {}\n    types = gandi.paas.type_list(options)\n    for type_ in types:\n        gandi.echo(type_['name'])\n\n    return types", "response": "List types PaaS instances."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndisplays information about an SSH key.", "response": "def info(gandi, resource, id, value):\n    \"\"\"Display information about an SSH key.\n\n    Resource can be a name or an ID\n    \"\"\"\n    output_keys = ['name', 'fingerprint']\n    if id:\n        output_keys.append('id')\n\n    if value:\n        output_keys.append('value')\n\n    ret = []\n    for item in resource:\n        sshkey = gandi.sshkey.info(item)\n        ret.append(output_sshkey(gandi, sshkey, output_keys))\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a new SSH key.", "response": "def create(gandi, name, value=None, filename=None):\n    \"\"\" Create a new SSH key. \"\"\"\n    if not value and not filename:\n        raise UsageError('You must set value OR filename.')\n\n    if value and filename:\n        raise UsageError('You must not set value AND filename.')\n\n    if filename:\n        value = filename.read()\n\n    ret = gandi.sshkey.create(name, value)\n\n    output_keys = ['id', 'name', 'fingerprint']\n    return output_sshkey(gandi, ret, output_keys)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create(gandi):\n    contact = {}\n\n    for field, label, checks in FIELDS:\n        ask_field(gandi, contact, field, label, checks)\n\n    default_pwd = randomstring(16)\n    contact['password'] = click.prompt('Please enter your password',\n                                       hide_input=True,\n                                       confirmation_prompt=True,\n                                       default=default_pwd)\n\n    result = True\n    while result:\n        result = gandi.contact.create_dry_run(contact)\n\n        # display errors\n        for err in result:\n            gandi.echo(err['reason'])\n            field = err['field']\n\n            if field not in FIELDS_POSITION:\n                return\n\n            desc = FIELDS[FIELDS_POSITION.get(field)]\n            ask_field(gandi, contact, *desc)\n\n    result = gandi.contact.create(contact)\n    handle = result['handle']\n\n    gandi.echo('Please activate you public api access from gandi website, and '\n               'get the apikey.')\n    gandi.echo('Your handle is %s, and the password is the one you defined.' %\n               handle)\n\n    # open new browser window\n    webbrowser.open('https://www.gandi.net/admin/api_key')\n    # just to avoid missing the next question in webbrowser stderr\n    time.sleep(1)\n\n    # get the apikey from shell\n    apikey = None\n    while not apikey:\n        apikey = click.prompt('What is your production apikey')\n\n    caller = gandi.get('api.key')\n    # save apikey in the conf if none defined else display an help on how to\n    # use it\n    if caller:\n        gandi.echo('You already have an apikey defined, if you want to use the'\n                   ' newly created contact, use the env var : ')\n        gandi.echo('export API_KEY=%s' % apikey)\n    else:\n        gandi.echo('Will save your apikey into the config file.')\n        gandi.configure(True, 'api.key', apikey)\n\n    return handle", "response": "Create a new contact."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets credit usage per hour", "response": "def creditusage(cls):\n        \"\"\"Get credit usage per hour\"\"\"\n        rating = cls.call('hosting.rating.list')\n        if not rating:\n            return 0\n\n        rating = rating.pop()\n        usage = [sum(resource.values())\n                 for resource in rating.values()\n                 if isinstance(resource, dict)]\n        return sum(usage)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget all informations about this account", "response": "def all(cls):\n        \"\"\" Get all informations about this account \"\"\"\n        account = cls.info()\n        creditusage = cls.creditusage()\n\n        if not creditusage:\n            return account\n\n        left = account['credits'] / creditusage\n        years, hours = divmod(left, 365 * 24)\n        months, hours = divmod(hours, 31 * 24)\n        days, hours = divmod(hours, 24)\n\n        account.update({'credit_usage': creditusage,\n                        'left': (years, months, days, hours)})\n\n        return account"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef info(gandi, resource):\n    output_keys = ['id', 'name', 'kept_total', 'target', 'quota_factor',\n                   'schedules']\n\n    result = gandi.snapshotprofile.info(resource)\n    output_snapshot_profile(gandi, result, output_keys)\n    return result", "response": "Display information about a snapshot profile."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlist certificate packages. /!\\\\ deprecated call.", "response": "def packages(gandi):\n    \"\"\" List certificate packages.\n    /!\\\\ deprecated call.\n    \"\"\"\n    gandi.echo('/!\\ \"gandi certificate packages\" is deprecated.')\n    gandi.echo('Please use \"gandi certificate plans\".')\n    return _plans(gandi, with_name=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndisplay information about a certificate.", "response": "def info(gandi, resource, id, altnames, csr, cert, all_status):\n    \"\"\" Display information about a certificate.\n\n    Resource can be a CN or an ID\n    \"\"\"\n    output_keys = ['cn', 'date_created', 'date_end', 'plan', 'status']\n\n    if id:\n        output_keys.append('id')\n\n    if altnames:\n        output_keys.append('altnames')\n\n    if csr:\n        output_keys.append('csr')\n\n    if cert:\n        output_keys.append('cert')\n\n    ids = []\n    for res in resource:\n        ids.extend(gandi.certificate.usable_ids(res))\n\n    result = []\n    for num, id_ in enumerate(set(ids)):\n        cert = gandi.certificate.info(id_)\n        if not all_status and cert['status'] not in ['valid', 'pending']:\n            continue\n        if num:\n            gandi.separator_line()\n        cert['plan'] = package_desc(gandi, cert['package'])\n        output_cert(gandi, cert, output_keys)\n        result.append(cert)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef export(gandi, resource, output, force, intermediate):\n    ids = []\n    for res in resource:\n        ids.extend(gandi.certificate.usable_ids(res))\n\n    if output and len(ids) > 1:\n        gandi.echo('Too many certs found, you must specify which cert you '\n                   'want to export')\n        return\n\n    for id_ in set(ids):\n        cert = gandi.certificate.info(id_)\n        if 'cert' not in cert:\n            continue\n\n        if cert['status'] != 'valid':\n            gandi.echo('The certificate must be in valid status to be '\n                       'exported (%s).' % id_)\n            continue\n\n        cert_filename = cert['cn'].replace('*.', 'wildcard.', 1)\n        crt_filename = output or cert_filename + '.crt'\n        if not force and os.path.isfile(crt_filename):\n            gandi.echo('The file %s already exists.' % crt_filename)\n            continue\n\n        crt = gandi.certificate.pretty_format_cert(cert)\n        if crt:\n            with open(crt_filename, 'w') as crt_file:\n                crt_file.write(crt)\n                gandi.echo('wrote %s' % crt_filename)\n\n        package = cert['package']\n        if 'bus' in package and intermediate:\n            gandi.echo('Business certs do not need intermediates.')\n        elif intermediate:\n            crtf = 'pem'\n            sha_version = cert['sha_version']\n            type_ = package.split('_')[1]\n            extra = ('sgc' if 'SGC' in package\n                     and 'pro' in package\n                     and sha_version == 1 else 'default')\n\n            if extra == 'sgc':\n                crtf = 'pem'\n\n            inters = gandi.certificate.urls[sha_version][type_][extra][crtf]\n            if isinstance(inters, basestring):\n                inters = [inters]\n\n            fhandle = open(cert_filename + '.inter.crt', 'w+b')\n            for inter in inters:\n                if inter.startswith('http'):\n                    data = requests.get(inter).text\n                else:\n                    data = inter\n                fhandle.write(data.encode('latin1'))\n\n            gandi.echo('wrote %s' % cert_filename + '.inter.crt')\n            fhandle.close()\n\n        return crt", "response": "Export a certificate to a file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new certificate.", "response": "def create(gandi, csr, private_key, common_name, country, state, city,\n           organisation, branch, duration, package, type, max_altname,\n           warranty, altnames, dcv_method):\n    \"\"\"Create a new certificate.\"\"\"\n    if not (csr or common_name):\n        gandi.echo('You need a CSR or a CN to create a certificate.')\n        return\n\n    if package and (type or max_altname or warranty):\n        gandi.echo('Please do not use --package at the same time you use '\n                   '--type, --max-altname or --warranty.')\n        return\n\n    if type and warranty and type != 'pro':\n        gandi.echo('The warranty can only be specified for pro certificates.')\n        return\n\n    csr = gandi.certificate.process_csr(common_name, csr, private_key, country,\n                                        state, city, organisation, branch)\n    if not csr:\n        return\n\n    if not common_name:\n        common_name = gandi.certificate.get_common_name(csr)\n        if not common_name:\n            gandi.echo('Unable to parse provided csr: %s' % csr)\n            return\n\n    if '*' in common_name and altnames and len(altnames) > 1:\n        gandi.echo(\"You can't have a wildcard with multidomain certificate.\")\n        return\n\n    if package:\n        gandi.echo('/!\\ Using --package is deprecated, please replace it by '\n                   '--type (in std, pro or bus) and --max-altname to set '\n                   'the max number of altnames.')\n    elif type or max_altname or warranty:\n        package = gandi.certificate.get_package(common_name,\n                                                type,\n                                                max_altname,\n                                                altnames,\n                                                warranty)\n        if not package:\n            gandi.echo(\"Can't find any plan with your params.\")\n            gandi.echo('Please call : \"gandi certificate plans\".')\n            return\n\n    result = gandi.certificate.create(csr, duration, package, altnames,\n                                      dcv_method)\n\n    gandi.echo('The certificate create operation is %s' % result['id'])\n    gandi.echo('You can follow it with:')\n    gandi.echo('$ gandi certificate follow %s' % result['id'])\n    if common_name:\n        gandi.echo('When the operation is DONE, you can retrieve the .crt'\n                   ' with:')\n        gandi.echo('$ gandi certificate export \"%s\"' % common_name)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update(gandi, resource, csr, private_key, country, state, city,\n           organisation, branch, altnames, dcv_method):\n    \"\"\" Update a certificate CSR.\n\n    Resource can be a CN or an ID\n    \"\"\"\n    ids = gandi.certificate.usable_ids(resource)\n\n    if len(ids) > 1:\n        gandi.echo('Will not update, %s is not precise enough.' % resource)\n        gandi.echo('  * cert : ' +\n                   '\\n  * cert : '.join([str(id_) for id_ in ids]))\n        return\n\n    id_ = ids[0]\n\n    result = gandi.certificate.update(id_, csr, private_key, country, state,\n                                      city, organisation, branch, altnames,\n                                      dcv_method)\n\n    gandi.echo('The certificate update operation is %s' % result['id'])\n    gandi.echo('You can follow it with:')\n    gandi.echo('$ gandi certificate follow %s' % result['id'])\n    gandi.echo('When the operation is DONE, you can retrieve the .crt'\n               ' with:')\n    gandi.echo('$ gandi certificate export \"%s\"' % resource)\n\n    return result", "response": "Update a certificate CSR."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef follow(gandi, resource):\n    oper = gandi.oper.info(int(resource))\n    assert(oper['type'].startswith('certificate_'))\n    output_cert_oper(gandi, oper)\n    return oper", "response": "Get the operation status\n\n    Resource is an operation ID"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef change_dcv(gandi, resource, dcv_method):\n    ids = gandi.certificate.usable_ids(resource)\n\n    if len(ids) > 1:\n        gandi.echo('Will not update, %s is not precise enough.' % resource)\n        gandi.echo('  * cert : ' +\n                   '\\n  * cert : '.join([str(id_) for id_ in ids]))\n        return\n\n    id_ = ids[0]\n\n    opers = gandi.oper.list({'cert_id': id_})\n    if not opers:\n        gandi.echo('Can not find any operation for this certificate.')\n        return\n\n    oper = opers[0]\n    if (oper['step'] != 'RUN'\n            and oper['params']['inner_step'] != 'comodo_oper_updated'):\n        gandi.echo('This certificate operation is not in the good step to '\n                   'update the DCV method.')\n        return\n\n    gandi.certificate.change_dcv(oper['id'], dcv_method)\n    cert = gandi.certificate.info(id_)\n\n    csr = oper['params']['csr']\n    package = cert['package']\n    altnames = oper['params'].get('altnames')\n    gandi.certificate.advice_dcv_method(csr, package, altnames, dcv_method,\n                                        cert_id=id_)", "response": "Change the DCV for a running certificate operation."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef resend_dcv(gandi, resource):\n    ids = gandi.certificate.usable_ids(resource)\n\n    if len(ids) > 1:\n        gandi.echo('Will not update, %s is not precise enough.' % resource)\n        gandi.echo('  * cert : ' +\n                   '\\n  * cert : '.join([str(id_) for id_ in ids]))\n        return\n\n    id_ = ids[0]\n\n    opers = gandi.oper.list({'cert_id': id_})\n    if not opers:\n        gandi.echo('Can not find any operation for this certificate.')\n        return\n\n    oper = opers[0]\n    if (oper['step'] != 'RUN'\n            and oper['params']['inner_step'] != 'comodo_oper_updated'):\n        gandi.echo('This certificate operation is not in the good step to '\n                   'resend the DCV.')\n        return\n\n    if oper['params']['dcv_method'] != 'email':\n        gandi.echo('This certificate operation is not in email DCV.')\n        return\n\n    gandi.certificate.resend_dcv(oper['id'])", "response": "Resend the DCV mail."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete(gandi, resource, background, force):\n    ids = gandi.certificate.usable_ids(resource)\n\n    if len(ids) > 1:\n        gandi.echo('Will not delete, %s is not precise enough.' % resource)\n        gandi.echo('  * cert : ' +\n                   '\\n  * cert : '.join([str(id_) for id_ in ids]))\n        return\n\n    if not force:\n        proceed = click.confirm(\"Are you sure to delete the certificate %s?\" %\n                                resource)\n        if not proceed:\n            return\n\n    result = gandi.certificate.delete(ids[0], background)\n    return result", "response": "Revoke the certificate.\n\n    Resource can be a CN or an ID"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef info(gandi, resource):\n    output_keys = ['id', 'subject', 'date_created', 'date_expire',\n                   'fqdns', 'vhosts']\n\n    result = gandi.hostedcert.infos(resource)\n    for num, hcert in enumerate(result):\n        if num:\n            gandi.separator_line()\n        output_hostedcert(gandi, hcert, output_keys)\n\n    return result", "response": "Display information about a hosted certificate."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new hosted certificate.", "response": "def create(gandi, private_key, certificate, certificate_id):\n    \"\"\" Create a new hosted certificate. \"\"\"\n    if not certificate and not certificate_id:\n        gandi.echo('One of --certificate or --certificate-id is needed.')\n        return\n    if certificate and certificate_id:\n        gandi.echo('Only one of --certificate or --certificate-id is needed.')\n\n    if os.path.isfile(private_key):\n        with open(private_key) as fhandle:\n            private_key = fhandle.read()\n\n    if certificate:\n        if os.path.isfile(certificate):\n            with open(certificate) as fhandle:\n                certificate = fhandle.read()\n    else:\n        cert = gandi.certificate.info(certificate_id)\n        certificate = gandi.certificate.pretty_format_cert(cert)\n\n    result = gandi.hostedcert.create(private_key, certificate)\n\n    output_keys = ['id', 'subject', 'date_created', 'date_expire',\n                   'fqdns', 'vhosts']\n\n    output_hostedcert(gandi, result, output_keys)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete(gandi, resource, force):\n    infos = gandi.hostedcert.infos(resource)\n    if not infos:\n        return\n\n    if not force:\n        proceed = click.confirm('Are you sure to delete the following hosted '\n                                'certificates ?\\n' +\n                                '\\n'.join(['%s: %s' % (res['id'],\n                                                       res['subject'])\n                                           for res in infos]) + '\\n')\n        if not proceed:\n            return\n\n    for res in infos:\n        gandi.hostedcert.delete(res['id'])", "response": "Delete a hosted certificate."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nflattening nested list of lists into a single list.", "response": "def flatten(l, types=(list, float)):\n    \"\"\"\n    Flat nested list of lists into a single list.\n    \"\"\"\n    l = [item if isinstance(item, types) else [item] for item in l]\n    return [item for sublist in l for item in sublist]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _find_links(self):\n        processed = {}\n        links = []\n        body = re.search('<[^>]*body[^>]*>(.+?)</body>', self.text, re.S).group(1)\n        \"\"\"\n        The link follow by the span.t-mark-rev will contained c++xx information.\n        Consider the below case\n          <a href=\"LinkA\">LinkA</a>\n          <a href=\"LinkB\">LinkB</a>\n          <span class=\"t-mark-rev\">(C++11)</span>\n        We're reversing the body so it is easier to write the regex to get the pair of (std, url).\n        \"\"\"\n        bodyr = body[::-1]\n        href = \"href\"[::-1]\n        span = \"span\"[::-1]\n        mark_rev = \"t-mark-rev\"[::-1]\n        _class = \"class\"[::-1]\n        for std, url in re.findall(\n            '>' + span + '/<\\)([^(<>]*)\\(' + '>[^<]*?' +\n            '''['\"][^'\"]*''' + mark_rev + '''[^'\"]*['\"]\\s*=\\s*''' + _class +\n            '[^<]*' + span + '''<.*?['\"]([^'\"]+)['\"]=''' + href\n            , bodyr):\n            std = std[::-1]\n            url = url[::-1]\n            links.append(Link(url, std))\n            processed[url] = True\n\n\n        for url in re.findall('''href\\s*=\\s*['\"]\\s*([^'\"]+)['\"]''', self.text):\n            if url in processed:\n                continue\n            links.append(Link(url, \"\"))\n            processed[url] = True\n\n        return links", "response": "Find links in the page."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nescaping <pre > section in table.", "response": "def escape_pre_section(table):\n    \"\"\"Escape <pre> section in table.\"\"\"\n    def replace_newline(g):\n        return g.group(1).replace('\\n', '\\n.br\\n')\n\n    return re.sub('<pre.*?>(.*?)</pre>', replace_newline, table, flags=re.S)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef html2groff(data, name):\n    # Remove sidebar\n    try:\n        data = data[data.index('<div class=\"C_doc\">'):]\n    except ValueError:\n        pass\n\n    # Pre replace all\n    for rp in pre_rps:\n        data = re.compile(rp[0], rp[2]).sub(rp[1], data)\n\n    for table in re.findall(r'<table.*?>.*?</table>', data, re.S):\n        tbl = parse_table(escape_pre_section(table))\n        # Escape column with '.' as prefix\n        tbl = re.compile(r'T{\\n(\\..*?)\\nT}', re.S).sub(r'T{\\n\\\\E \\1\\nT}', tbl)\n        data = data.replace(table, tbl)\n\n    # Replace all\n    for rp in rps:\n        data = re.compile(rp[0], rp[2]).sub(rp[1], data)\n\n    # Upper case all section headers\n    for st in re.findall(r'.SH .*\\n', data):\n        data = data.replace(st, st.upper())\n\n    # Add tags to member/inherited member functions\n    # e.g. insert -> vector::insert\n    #\n    # .SE is a pseudo macro I created which means 'SECTION END'\n    # The reason I use it is because I need a marker to know where section\n    # ends.\n    # re.findall find patterns which does not overlap, which means if I do\n    # this: secs = re.findall(r'\\n\\.SH \"(.+?)\"(.+?)\\.SH', data, re.S)\n    # re.findall will skip the later .SH tag and thus skip the later section.\n    # To fix this, '.SE' is used to mark the end of the section so the next\n    # '.SH' can be find by re.findall\n\n    page_type = re.search(r'\\n\\.SH \"TYPE\"\\n(.+?)\\n', data)\n    if page_type and 'class' in page_type.group(1):\n        class_name = re.search(r'\\n\\.SH \"NAME\"\\n(?:.*::)?(.+?) ', data).group(1)\n\n        secs = re.findall(r'\\n\\.SH \"(.+?)\"(.+?)\\.SE', data, re.S)\n\n        for sec, content in secs:\n            # Member functions\n            if ('MEMBER' in sec and\n                'NON-MEMBER' not in sec and\n                'INHERITED' not in sec and\n                sec != 'MEMBER TYPES'):\n                content2 = re.sub(r'\\n\\.IP \"([^:]+?)\"', r'\\n.IP \"%s::\\1\"'\n                                  % class_name, content)\n                # Replace (constructor) (destructor)\n                content2 = re.sub(r'\\(constructor\\)', r'%s' % class_name,\n                                  content2)\n                content2 = re.sub(r'\\(destructor\\)', r'~%s' % class_name,\n                                  content2)\n                data = data.replace(content, content2)\n            # Inherited member functions\n            elif 'MEMBER' in sec and 'INHERITED' in sec:\n                inherit = re.search(r'.+?INHERITED FROM (.+)',\n                                    sec).group(1).lower()\n                content2 = re.sub(r'\\n\\.IP \"(.+)\"', r'\\n.IP \"%s::\\1\"'\n                                  % inherit, content)\n                data = data.replace(content, content2)\n\n    # Remove pseudo macro '.SE'\n    data = data.replace('\\n.SE', '')\n\n    return data", "response": "Convert HTML text from cplusplus. com to Groff - formatted text."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_mandb_path():\n    manpath_file = os.path.join(environ.HOME, \".manpath\")\n    man_dir      = environ.cache_dir\n    manindex_dir = environ.manindex_dirl\n\n    lines = []\n\n    \"\"\" read all lines \"\"\"\n    try:\n        with open(manpath_file, 'r') as f:\n            lines = f.readlines()\n    except IOError:\n        return\n\n    \"\"\" remove MANDATORY_MANPATH and MANDB_MAP entry \"\"\"\n    lines = [line for line in lines if man_dir not in line]\n\n    with open(manpath_file, 'w') as f:\n        if environ.config.UpdateManPath:\n            lines.append('MANDATORY_MANPATH\\t%s\\n' % man_dir)\n            lines.append('MANDB_MAP\\t\\t\\t%s\\t%s\\n' % (man_dir, manindex_dir))\n\n        f.writelines(lines)", "response": "Update MANDATORY_MANPATH and MANDB_MAP entries."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads groff - formatted text and output man pages.", "response": "def groff2man(data):\n    \"\"\"Read groff-formatted text and output man pages.\"\"\"\n    width = get_width()\n\n    cmd = 'groff -t -Tascii -m man -rLL=%dn -rLT=%dn' % (width, width)\n    handle = subprocess.Popen(\n        cmd, shell=True, stdin=subprocess.PIPE, stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE)\n    man_text, stderr = handle.communicate(data)\n    return man_text"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts HTML text from cplusplus. com to man pages.", "response": "def html2man(data, formatter):\n    \"\"\"Convert HTML text from cplusplus.com to man pages.\"\"\"\n    groff_text = formatter(data)\n    man_text = groff2man(groff_text)\n    return man_text"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts HTML text from cppreference. com to Groff - formatted text.", "response": "def html2groff(data, name):\n    \"\"\"Convert HTML text from cppreference.com to Groff-formatted text.\"\"\"\n    # Remove header and footer\n    try:\n        data = data[data.index('<div id=\"cpp-content-base\">'):]\n        data = data[:data.index('<div class=\"printfooter\">') + 25]\n    except ValueError:\n        pass\n\n    # Remove non-printable characters\n    data = ''.join([x for x in data if x in string.printable])\n\n    for table in re.findall(\n            r'<table class=\"(?:wikitable|dsctable)\"[^>]*>.*?</table>',\n            data, re.S):\n        tbl = parse_table(table)\n        # Escape column with '.' as prefix\n        tbl = re.compile(r'T{\\n(\\..*?)\\nT}', re.S).sub(r'T{\\n\\\\E \\1\\nT}', tbl)\n        data = data.replace(table, tbl)\n\n    # Pre replace all\n    for rp in rps:\n        data = re.compile(rp[0], rp[2]).sub(rp[1], data)\n\n    # Remove non-printable characters\n    data = ''.join([x for x in data if x in string.printable])\n\n    # Upper case all section headers\n    for st in re.findall(r'.SH .*\\n', data):\n        data = data.replace(st, st.upper())\n\n    # Add tags to member/inherited member functions\n    # e.g. insert -> vector::insert\n    #\n    # .SE is a pseudo macro I created which means 'SECTION END'\n    # The reason I use it is because I need a marker to know where section\n    # ends.\n    # re.findall find patterns which does not overlap, which means if I do\n    # this: secs = re.findall(r'\\n\\.SH \"(.+?)\"(.+?)\\.SH', data, re.S)\n    # re.findall will skip the later .SH tag and thus skip the later section.\n    # To fix this, '.SE' is used to mark the end of the section so the next\n    # '.SH' can be find by re.findall\n\n    try:\n        idx = data.index('.IEND')\n    except ValueError:\n        idx = None\n\n    def add_header_multi(prefix, g):\n        if ',' in g.group(1):\n            res = ', '.join(['%s::%s' % (prefix, x.strip())\n                            for x in g.group(1).split(',')])\n        else:\n            res = '%s::%s' % (prefix, g.group(1))\n\n        return '\\n.IP \"%s\"' % res\n\n    if idx:\n        class_name = name\n        if class_name.startswith('std::'):\n            normalized_class_name = class_name[len('std::'):]\n        else:\n            normalized_class_name = class_name\n        class_member_content = data[:idx]\n        secs = re.findall(r'\\.SH \"(.+?)\"(.+?)\\.SE', class_member_content, re.S)\n\n        for sec, content in secs:\n            # Member functions\n            if ('MEMBER' in sec and\n                'NON-MEMBER' not in sec and\n                'INHERITED' not in sec and\n                 sec != 'MEMBER TYPES'):\n                content2 = re.sub(r'\\n\\.IP \"([^:]+?)\"',\n                                  partial(add_header_multi, class_name),\n                                  content)\n                # Replace (constructor) (destructor)\n                content2 = re.sub(r'\\(constructor\\)', r'%s' %\n                                  normalized_class_name, content2)\n                content2 = re.sub(r'\\(destructor\\)', r'~%s' %\n                                  normalized_class_name, content2)\n                data = data.replace(content, content2)\n\n    blocks = re.findall(r'\\.IBEGIN\\s*(.+?)\\s*\\n(.+?)\\.IEND', data, re.S)\n\n    for inherited_class, content in blocks:\n        content2 = re.sub(r'\\.SH \"(.+?)\"', r'\\n.SH \"\\1 INHERITED FROM %s\"'\n                          % inherited_class.upper(), content)\n        data = data.replace(content, content2)\n\n        secs = re.findall(r'\\.SH \"(.+?)\"(.+?)\\.SE', content, re.S)\n\n        for sec, content in secs:\n            # Inherited member functions\n            if 'MEMBER' in sec and \\\n               sec != 'MEMBER TYPES':\n                content2 = re.sub(r'\\n\\.IP \"(.+)\"',\n                                  partial(add_header_multi, inherited_class),\n                                  content)\n                data = data.replace(content, content2)\n\n    # Remove unneeded pseudo macro\n    data = re.sub('(?:\\n.SE|.IBEGIN.*?\\n|\\n.IEND)', '', data)\n\n    # Replace all macros\n    desc_re = re.search(r'.SH \"DESCRIPTION\"\\n.*?([^\\n\\s].*?)\\n', data)\n    shortdesc = ''\n\n    # not empty description\n    if desc_re and not desc_re.group(1).startswith('.SH'):\n        shortdesc = '- ' + desc_re.group(1)\n\n    def dereference(g):\n        d = dict(name=name, shortdesc=shortdesc)\n        if g.group(1) in d:\n            return d[g.group(1)]\n\n    data = re.sub('{{(.*?)}}', dereference, data)\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract man page name from web page.", "response": "def extract_name(self, data):\n        \"\"\"Extract man page name from web page.\"\"\"\n        name = re.search('<h1[^>]*>(.+?)</h1>', data).group(1)\n        name = re.sub(r'<([^>]+)>', r'', name)\n        name = re.sub(r'&gt;', r'>', name)\n        name = re.sub(r'&lt;', r'<', name)\n        return name"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrebuild index database from cplusplus. com and cppreference. com.", "response": "def rebuild_index(self):\n        \"\"\"Rebuild index database from cplusplus.com and cppreference.com.\"\"\"\n        try:\n            os.remove(environ.index_db_re)\n        except:\n            pass\n\n        self.db_conn = sqlite3.connect(environ.index_db_re)\n        self.db_cursor = self.db_conn.cursor()\n        self.db_cursor.execute('CREATE TABLE \"cplusplus.com\" '\n                               '(name VARCHAR(255), url VARCHAR(255), std VARCHAR(255))')\n        self.db_cursor.execute('CREATE TABLE \"cppreference.com\" '\n                               '(name VARCHAR(255), url VARCHAR(255), std VARCHAR(255))')\n\n        try:\n            self.add_url_filter('\\.(jpg|jpeg|gif|png|js|css|swf|svg)$')\n            self.set_follow_mode(Crawler.F_SAME_PATH)\n\n            # cplusplus.com\n            self.crawl('http://www.cplusplus.com/reference/')\n            for name, url, std in self.results:\n                self.insert_index('cplusplus.com', name, url, std)\n            self.db_conn.commit()\n\n            # Rename duplicate entries\n            duplicates = self.db_cursor.execute('SELECT name, COUNT(name) '\n                                                'AS NON '\n                                                'FROM \"cplusplus.com\" '\n                                                'GROUP BY NAME '\n                                                'HAVING (NON > 1)').fetchall()\n            for name, num in duplicates:\n                dump = self.db_cursor.execute('SELECT name, url FROM '\n                                              '\"cplusplus.com\" WHERE name=\"%s\"'\n                                              % name).fetchall()\n                for n, u in dump:\n                    if u not in self.name_exceptions:\n                        n2 = n[5:] if n.startswith('std::') else n\n                        try:\n                            group = re.search('/([^/]+)/%s/$' % n2, u).group(1)\n                        except Exception:\n                            group = re.search('/([^/]+)/[^/]+/$', u).group(1)\n\n                        new_name = '%s (%s)' % (n, group)\n                        self.db_cursor.execute('UPDATE \"cplusplus.com\" '\n                                               'SET name=\"%s\", url=\"%s\" '\n                                               'WHERE url=\"%s\"' %\n                                               (new_name, u, u))\n            self.db_conn.commit()\n\n            # cppreference.com\n            self.results = set()\n            self.crawl('https://en.cppreference.com/w/cpp', '/w/cpp')\n\n            for name, url, std in self.results:\n                self.insert_index('cppreference.com', name, url, std)\n            self.db_conn.commit()\n\n        except KeyboardInterrupt:\n            os.remove(environ.index_db_re)\n            raise KeyboardInterrupt\n        finally:\n            self.db_conn.close()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_expression(self, expr):\n        m = re.match(r'^(.*?(?:::)?(?:operator)?)((?:::[^:]*|[^:]*)?)$', expr);\n        prefix = m.group(1)\n        tail = m.group(2)\n        return [prefix, tail]", "response": "parse the expression into prefix and tail"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_title(self, title):\n        m = re.match(r'^\\s*((?:\\(size_type\\)|(?:.|\\(\\))*?)*)((?:\\([^)]+\\))?)\\s*$', title)\n        postfix = m.group(2)\n\n        t_names = m.group(1).split(',')\n        t_names = [n.strip() for n in t_names]\n        prefix = self.parse_expression(t_names[0])[0]\n        names = []\n        for n in t_names:\n            r = self.parse_expression(n);\n            if prefix == r[0]:\n                names.append(n + postfix)\n            else:\n                names.append(prefix + r[1] + postfix)\n        return names", "response": "Parse the title of a resource entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef insert_index(self, table, name, url, std=\"\"):\n        names = self.parse_title(name);\n\n        for n in names:\n            self.db_cursor.execute(\n                'INSERT INTO \"%s\" (name, url, std) VALUES (?, ?, ?)' % table, (\n                n, url, std))", "response": "callback to insert index"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncaching all man pages in the cache directory.", "response": "def cache_all(self):\n        \"\"\"Cache all available man pages\"\"\"\n\n        respond = input(\n              'By default, cppman fetches pages on-the-fly if corresponding '\n              'page is not found in the cache. The \"cache-all\" option is only '\n              'useful if you want to view man pages offline. '\n              'Caching all contents will take several minutes, '\n              'do you want to continue [y/N]? ')\n        if not (respond and 'yes'.startswith(respond.lower())):\n            raise KeyboardInterrupt\n\n        try:\n            os.makedirs(environ.cache_dir)\n        except:\n            pass\n\n        self.success_count = 0\n        self.failure_count = 0\n\n        if not os.path.exists(environ.index_db):\n            raise RuntimeError(\"can't find index.db\")\n\n        conn = sqlite3.connect(environ.index_db)\n        cursor = conn.cursor()\n\n        source = environ.config.source\n        print('Caching manpages from %s ...' % source)\n        data = cursor.execute('SELECT * FROM \"%s\"' % source).fetchall()\n\n        for name, url, _ in data:\n            print('Caching %s ...' % name)\n            retries = 3\n            while retries > 0:\n                try:\n                    self.cache_man_page(source, url, name)\n                except Exception:\n                    print('Retrying ...')\n                    retries -= 1\n                else:\n                    self.success_count += 1\n                    break\n            else:\n                print('Error caching %s ...' % name)\n                self.failure_count += 1\n\n        conn.close()\n\n        print('\\n%d manual pages cached successfully.' % self.success_count)\n        print('%d manual pages failed to cache.' % self.failure_count)\n        self.update_mandb(False)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalls viewer. sh to view man page", "response": "def man(self, pattern):\n        \"\"\"Call viewer.sh to view man page\"\"\"\n        try:\n            avail = os.listdir(os.path.join(environ.cache_dir, environ.source))\n        except OSError:\n            avail = []\n\n        if not os.path.exists(environ.index_db):\n            raise RuntimeError(\"can't find index.db\")\n\n        conn = sqlite3.connect(environ.index_db)\n        cursor = conn.cursor()\n\n        # Try direct match\n        try:\n            page_name, url = cursor.execute(\n                'SELECT name,url FROM \"%s\" '\n                'WHERE name=\"%s\" ORDER BY LENGTH(name)'\n                % (environ.source, pattern)).fetchone()\n        except TypeError:\n            # Try standard library\n            try:\n                page_name, url = cursor.execute(\n                    'SELECT name,url FROM \"%s\" '\n                    'WHERE name=\"std::%s\" ORDER BY LENGTH(name)'\n                    % (environ.source, pattern)).fetchone()\n            except TypeError:\n                try:\n                    page_name, url = cursor.execute(\n                        'SELECT name,url FROM \"%s\" '\n                        'WHERE name LIKE \"%%%s%%\" ORDER BY LENGTH(name)'\n                        % (environ.source, pattern)).fetchone()\n                except TypeError:\n                    raise RuntimeError('No manual entry for ' + pattern)\n        finally:\n            conn.close()\n\n        page_filename = self.get_normalized_page_name(page_name)\n        if self.forced or page_filename + '.3.gz' not in avail:\n            self.cache_man_page(environ.source, url, page_name)\n\n        pager_type = environ.pager if sys.stdout.isatty() else 'pipe'\n\n        # Call viewer\n        columns = (util.get_width() if self.force_columns == -1 else\n                   self.force_columns)\n        pid = os.fork()\n        if pid == 0:\n            os.execl('/bin/sh', '/bin/sh', environ.pager_script, pager_type,\n                     self.get_page_path(environ.source, page_name),\n                     str(columns), environ.pager_config, page_name)\n        return pid"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find(self, pattern):\n\n        if not os.path.exists(environ.index_db):\n            raise RuntimeError(\"can't find index.db\")\n\n        conn = sqlite3.connect(environ.index_db)\n        cursor = conn.cursor()\n        selected = cursor.execute(\n            'SELECT * FROM \"%s\" WHERE name '\n            'LIKE \"%%%s%%\" ORDER BY LENGTH(name)'\n            % (environ.source, pattern)).fetchall()\n\n        pat = re.compile('(%s)' % re.escape(pattern), re.I)\n\n        if selected:\n            for name, url, std in selected:\n                if os.isatty(sys.stdout.fileno()):\n                    print(pat.sub(r'\\033[1;31m\\1\\033[0m', name) +\n                          (' \\033[1;33m[%s]\\033[0m' % std if std else ''))\n                else:\n                    print(name + (' [%s]' % std if std else ''))\n        else:\n            raise RuntimeError('%s: nothing appropriate.' % pattern)", "response": "Find pages in database."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_default(self):\n        try:\n            os.makedirs(os.path.dirname(self._configfile))\n        except:\n            pass\n\n        self._config = configparser.RawConfigParser()\n        self._config.add_section('Settings')\n\n        for key, val in self.DEFAULTS.items():\n            self._config.set('Settings', key, val)\n\n        with open(self._configfile, 'w') as f:\n            self._config.write(f)", "response": "Set config to default."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstoring config back to file.", "response": "def save(self):\n        \"\"\"Store config back to file.\"\"\"\n        try:\n            os.makedirs(os.path.dirname(self._configfile))\n        except:\n            pass\n\n        with open(self._configfile, 'w') as f:\n            self._config.write(f)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef grab_gpus(num_gpus=1, gpu_select=None, gpu_fraction=0.95, max_procs=-1):\n    # Set the visible devices to blank.\n    os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n\n    if num_gpus == 0:\n        return 0\n\n    # Try connect with NVIDIA drivers\n    logger = logging.getLogger(__name__)\n    try:\n        py3nvml.nvmlInit()\n    except:\n        str_ = \"\"\" Couldn't connect to nvml drivers. Check they are installed correctly.\nProceeding on cpu only...\"\"\"\n        warnings.warn(str_, RuntimeWarning)\n        logger.warn(str_)\n        return 0\n\n    numDevices = py3nvml.nvmlDeviceGetCount()\n    gpu_free = [False]*numDevices\n\n    # Flag which gpus we can check\n    if gpu_select is None:\n        gpu_check = [True] * numDevices\n    else:\n        gpu_check = [False] * numDevices\n        try:\n            gpu_check[gpu_select] = True\n        except TypeError:\n            try:\n                for i in gpu_select:\n                    gpu_check[i] = True\n            except:\n                raise ValueError('''Please provide an int or an iterable of ints\n                    for gpu_select''')\n\n    # Print out GPU device info. Useful for debugging.\n    for i in range(numDevices):\n        # If the gpu was specified, examine it\n        if not gpu_check[i]:\n            continue\n\n        handle = py3nvml.nvmlDeviceGetHandleByIndex(i)\n        info = py3nvml.nvmlDeviceGetMemoryInfo(handle)\n\n        str_ = \"GPU {}:\\t\".format(i) + \\\n               \"Used Mem: {:>6}MB\\t\".format(info.used/(1024*1024)) + \\\n               \"Total Mem: {:>6}MB\".format(info.total/(1024*1024))\n        logger.debug(str_)\n\n    # Check the number of procs running on each gpu\n    if max_procs >= 0:\n        procs_ok = get_free_gpus(max_procs=max_procs)\n    else:\n        procs_ok = [True,] * numDevices\n\n    # Now check if any devices are suitable\n    for i in range(numDevices):\n        # If the gpu was not specified, skip it\n        if gpu_check[i] and procs_ok[i]:\n\n            handle = py3nvml.nvmlDeviceGetHandleByIndex(i)\n            info = py3nvml.nvmlDeviceGetMemoryInfo(handle)\n\n            # Sometimes GPU has a few MB used when it is actually free\n            if (info.free+10)/info.total >= gpu_fraction:\n                gpu_free[i] = True\n            else:\n                logger.info('GPU {} has processes on it. Skipping.'.format(i))\n\n    py3nvml.nvmlShutdown()\n\n    # Now check whether we can create the session\n    if sum(gpu_free) == 0:\n        warnings.warn(\"Could not find enough GPUs for your job\", RuntimeWarning)\n        logger.warn(str_)\n        return 0\n    else:\n        if sum(gpu_free) >= num_gpus:\n            # only use the first num_gpus gpus. Hide the rest from greedy\n            # tensorflow\n            available_gpus = [i for i, x in enumerate(gpu_free) if x]\n            use_gpus = ','.join(list(str(s) for s in available_gpus[:num_gpus]))\n            logger.debug('{} Gpus found free'.format(sum(gpu_free)))\n            logger.info('Using {}'.format(use_gpus))\n            os.environ['CUDA_VISIBLE_DEVICES'] = use_gpus\n            return num_gpus\n        else:\n            # use everything we can.\n            s = \"Only {} GPUs found but {}\".format(sum(gpu_free), num_gpus) + \\\n                \"requested. Allocating these and continuing.\"\n            warnings.warn(s, RuntimeWarning)\n            logger.warn(s)\n            available_gpus = [i for i, x in enumerate(gpu_free) if x]\n            use_gpus = ','.join(list(str(s) for s in available_gpus))\n            logger.debug('{} Gpus found free'.format(sum(gpu_free)))\n            logger.info('Using {}'.format(use_gpus))\n            os.environ['CUDA_VISIBLE_DEVICES'] = use_gpus\n            return sum(gpu_free)", "response": "Returns a base NVIDIA driver that will grab NVIDIA drivers on the specified GPUs."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of free GPUs for the N - gpu system.", "response": "def get_free_gpus(max_procs=0):\n    \"\"\"\n    Checks the number of processes running on your GPUs.\n\n    Parameters\n    ----------\n    max_procs : int\n        Maximum number of procs allowed to run on a gpu for it to be considered\n        'available'\n\n    Returns\n    -------\n    availabilities : list(bool)\n        List of length N for an N-gpu system. The nth value will be true, if the\n        nth gpu had at most max_procs processes running on it. Set to 0 to look\n        for gpus with no procs on it.\n\n    Note\n    ----\n    If function can't query the driver will return an empty list rather than raise an\n    Exception.\n    \"\"\"\n    # Try connect with NVIDIA drivers\n    logger = logging.getLogger(__name__)\n    try:\n        py3nvml.nvmlInit()\n    except:\n        str_ = \"\"\"Couldn't connect to nvml drivers. Check they are installed correctly.\"\"\"\n        warnings.warn(str_, RuntimeWarning)\n        logger.warn(str_)\n        return []\n\n    num_gpus = py3nvml.nvmlDeviceGetCount()\n    gpu_free = [False]*num_gpus\n    for i in range(num_gpus):\n        try:\n            h = py3nvml.nvmlDeviceGetHandleByIndex(i)\n        except:\n            continue\n\n        procs = try_get_info(py3nvml.nvmlDeviceGetComputeRunningProcesses, h,\n                             ['something'])\n        if len(procs) <= max_procs:\n            gpu_free[i] = True\n\n    py3nvml.nvmlShutdown()\n    return gpu_free"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the number of processes running on each gpu", "response": "def get_num_procs():\n    \"\"\" Gets the number of processes running on each gpu\n\n    Returns\n    -------\n    num_procs : list(int)\n        Number of processes running on each gpu\n\n    Note\n    ----\n    If function can't query the driver will return an empty list rather than raise an\n    Exception.\n\n    Note\n    ----\n    If function can't get the info from the gpu will return -1 in that gpu's place\n    \"\"\"\n    # Try connect with NVIDIA drivers\n    logger = logging.getLogger(__name__)\n    try:\n        py3nvml.nvmlInit()\n    except:\n        str_ = \"\"\"Couldn't connect to nvml drivers. Check they are installed correctly.\"\"\"\n        warnings.warn(str_, RuntimeWarning)\n        logger.warn(str_)\n        return []\n\n    num_gpus = py3nvml.nvmlDeviceGetCount()\n    gpu_procs = [-1]*num_gpus\n    for i in range(num_gpus):\n        try:\n            h = py3nvml.nvmlDeviceGetHandleByIndex(i)\n        except:\n            continue\n        procs = try_get_info(py3nvml.nvmlDeviceGetComputeRunningProcesses, h,\n                             ['something'])\n        gpu_procs[i] = len(procs)\n\n    py3nvml.nvmlShutdown()\n    return gpu_procs"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _extractNVMLErrorsAsClasses():\n    this_module = sys.modules[__name__]\n    nvmlErrorsNames = [x for x in dir(this_module) if x.startswith(\"NVML_ERROR_\")]\n    for err_name in nvmlErrorsNames:\n        # e.g. Turn NVML_ERROR_ALREADY_INITIALIZED into NVMLError_AlreadyInitialized\n        class_name = \"NVMLError_\" + string.capwords(err_name.replace(\"NVML_ERROR_\", \"\"), \"_\").replace(\"_\", \"\")\n        err_val = getattr(this_module, err_name)\n        def gen_new(val):\n            def new(typ):\n                obj = NVMLError.__new__(typ, val)\n                return obj\n            return new\n        new_error_class = type(class_name, (NVMLError,), {'__new__': gen_new(err_val)})\n        new_error_class.__module__ = __name__\n        setattr(this_module, class_name, new_error_class)\n        NVMLError._valClassMapping[err_val] = new_error_class", "response": "Extracts the NVMLError classes from the module and creates them as subclasses of the NVMLError class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading the NVML library if it isn t loaded already", "response": "def _LoadNvmlLibrary():\n    \"\"\"\n    Load the library if it isn't loaded already\n    \"\"\"\n    global nvmlLib\n\n    if (nvmlLib is None):\n        # lock to ensure only one caller loads the library\n        libLoadLock.acquire()\n\n        try:\n            # ensure the library still isn't loaded\n            if (nvmlLib is None):\n                try:\n                    if (sys.platform[:3] == \"win\"):\n                        searchPaths = [\n                            os.path.join(os.getenv(\"ProgramFiles\", r\"C:\\Program Files\"), r\"NVIDIA Corporation\\NVSMI\\nvml.dll\"),\n                            os.path.join(os.getenv(\"WinDir\", r\"C:\\Windows\"), r\"System32\\nvml.dll\"),\n                        ]\n                        nvmlPath = next((x for x in searchPaths if os.path.isfile(x)), None)\n                        if (nvmlPath == None):\n                            _nvmlCheckReturn(NVML_ERROR_LIBRARY_NOT_FOUND)\n                        else:\n                            # cdecl calling convention\n                            nvmlLib = CDLL(nvmlPath)\n                    else:\n                        # assume linux\n                        nvmlLib = CDLL(\"libnvidia-ml.so.1\")\n                except OSError as ose:\n                    _nvmlCheckReturn(NVML_ERROR_LIBRARY_NOT_FOUND)\n                if (nvmlLib == None):\n                    _nvmlCheckReturn(NVML_ERROR_LIBRARY_NOT_FOUND)\n        finally:\n            # lock is always freed\n            libLoadLock.release()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef nvmlSystemGetNVMLVersion():\n    c_version = create_string_buffer(NVML_SYSTEM_NVML_VERSION_BUFFER_SIZE)\n    fn = _nvmlGetFunctionPointer(\"nvmlSystemGetNVMLVersion\")\n    ret = fn(c_version, c_uint(NVML_SYSTEM_NVML_VERSION_BUFFER_SIZE))\n    _nvmlCheckReturn(ret)\n    return bytes_to_str(c_version.value)", "response": "r Retrieves the version of the NVML library."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef nvmlSystemGetProcessName(pid):\n    c_name = create_string_buffer(1024)\n    fn = _nvmlGetFunctionPointer(\"nvmlSystemGetProcessName\")\n    ret = fn(c_uint(pid), c_name, c_uint(1024))\n    _nvmlCheckReturn(ret)\n    return bytes_to_str(c_name.value)", "response": "r Returns the process name of the given process id."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef nvmlUnitGetHandleByIndex(index):\n    \"\"\"\n/**\n * Acquire the handle for a particular unit, based on its index.\n *\n * For S-class products.\n *\n * Valid indices are derived from the \\a unitCount returned by \\ref nvmlUnitGetCount().\n *   For example, if \\a unitCount is 2 the valid indices are 0 and 1, corresponding to UNIT 0 and UNIT 1.\n *\n * The order in which NVML enumerates units has no guarantees of consistency between reboots.\n *\n * @param index                                The index of the target unit, >= 0 and < \\a unitCount\n * @param unit                                 Reference in which to return the unit handle\n *\n * @return\n *         - \\ref NVML_SUCCESS                 if \\a unit has been set\n *         - \\ref NVML_ERROR_UNINITIALIZED     if the library has not been successfully initialized\n *         - \\ref NVML_ERROR_INVALID_ARGUMENT  if \\a index is invalid or \\a unit is NULL\n *         - \\ref NVML_ERROR_UNKNOWN           on any unexpected error\n */\n    \"\"\"\n    c_index = c_uint(index)\n    unit = c_nvmlUnit_t()\n    fn = _nvmlGetFunctionPointer(\"nvmlUnitGetHandleByIndex\")\n    ret = fn(c_index, byref(unit))\n    _nvmlCheckReturn(ret)\n    return bytes_to_str(unit)", "response": "r Returns the handle for a particular unit based on its index."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef nvmlUnitGetPsuInfo(unit):\n    \"\"\"\n/**\n * Retrieves the PSU stats for the unit.\n *\n * For S-class products.\n *\n * See \\ref nvmlPSUInfo_t for details on available PSU info.\n *\n * @param unit                                 The identifier of the target unit\n * @param psu                                  Reference in which to return the PSU information\n *\n * @return\n *         - \\ref NVML_SUCCESS                 if \\a psu has been populated\n *         - \\ref NVML_ERROR_UNINITIALIZED     if the library has not been successfully initialized\n *         - \\ref NVML_ERROR_INVALID_ARGUMENT  if \\a unit is invalid or \\a psu is NULL\n *         - \\ref NVML_ERROR_NOT_SUPPORTED     if this is not an S-class product\n *         - \\ref NVML_ERROR_UNKNOWN           on any unexpected error\n */\n    \"\"\"\n    c_info = c_nvmlPSUInfo_t()\n    fn = _nvmlGetFunctionPointer(\"nvmlUnitGetPsuInfo\")\n    ret = fn(unit, byref(c_info))\n    _nvmlCheckReturn(ret)\n    return bytes_to_str(c_info)", "response": "r Returns the PSU information for the given unit."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef nvmlUnitGetTemperature(unit, type):\n    \"\"\"\n/**\n * Retrieves the temperature readings for the unit, in degrees C.\n *\n * For S-class products.\n *\n * Depending on the product, readings may be available for intake (type=0),\n * exhaust (type=1) and board (type=2).\n *\n * @param unit                                 The identifier of the target unit\n * @param type                                 The type of reading to take\n * @param temp                                 Reference in which to return the intake temperature\n *\n * @return\n *         - \\ref NVML_SUCCESS                 if \\a temp has been populated\n *         - \\ref NVML_ERROR_UNINITIALIZED     if the library has not been successfully initialized\n *         - \\ref NVML_ERROR_INVALID_ARGUMENT  if \\a unit or \\a type is invalid or \\a temp is NULL\n *         - \\ref NVML_ERROR_NOT_SUPPORTED     if this is not an S-class product\n *         - \\ref NVML_ERROR_UNKNOWN           on any unexpected error\n */\n    \"\"\"\n    c_temp = c_uint()\n    fn = _nvmlGetFunctionPointer(\"nvmlUnitGetTemperature\")\n    ret = fn(unit, c_uint(type), byref(c_temp))\n    _nvmlCheckReturn(ret)\n    return bytes_to_str(c_temp.value)", "response": "r Returns the temperature of the given unit in degrees C."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef nvmlUnitGetDevices(unit):\n    \"\"\"\n/**\n * Retrieves the set of GPU devices that are attached to the specified unit.\n *\n * For S-class products.\n *\n * The \\a deviceCount argument is expected to be set to the size of the input \\a devices array.\n *\n * @param unit                                 The identifier of the target unit\n * @param deviceCount                          Reference in which to provide the \\a devices array size, and\n *                                             to return the number of attached GPU devices\n * @param devices                              Reference in which to return the references to the attached GPU devices\n *\n * @return\n *         - \\ref NVML_SUCCESS                 if \\a deviceCount and \\a devices have been populated\n *         - \\ref NVML_ERROR_UNINITIALIZED     if the library has not been successfully initialized\n *         - \\ref NVML_ERROR_INSUFFICIENT_SIZE if \\a deviceCount indicates that the \\a devices array is too small\n *         - \\ref NVML_ERROR_INVALID_ARGUMENT  if \\a unit is invalid, either of \\a deviceCount or \\a devices is NULL\n *         - \\ref NVML_ERROR_UNKNOWN           on any unexpected error\n */\n    \"\"\"\n    c_count = c_uint(nvmlUnitGetDeviceCount(unit))\n    device_array = c_nvmlDevice_t * c_count.value\n    c_devices = device_array()\n    fn = _nvmlGetFunctionPointer(\"nvmlUnitGetDevices\")\n    ret = fn(unit, byref(c_count), c_devices)\n    _nvmlCheckReturn(ret)\n    return bytes_to_str(c_devices)", "response": "r Returns the set of GPU devices that are attached to the specified unit."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef nvmlDeviceGetHandleByPciBusId(pciBusId):\n    \"\"\"\n/**\n * Acquire the handle for a particular device, based on its PCI bus id.\n *\n * For all products.\n *\n * This value corresponds to the nvmlPciInfo_t::busId returned by \\ref nvmlDeviceGetPciInfo().\n *\n * Starting from NVML 5, this API causes NVML to initialize the target GPU\n * NVML may initialize additional GPUs if:\n *  - The target GPU is an SLI slave\n *\n * \\note NVML 4.304 and older version of nvmlDeviceGetHandleByPciBusId\"_v1\" returns NVML_ERROR_NOT_FOUND\n *       instead of NVML_ERROR_NO_PERMISSION.\n *\n * @param pciBusId                             The PCI bus id of the target GPU\n * @param device                               Reference in which to return the device handle\n *\n * @return\n *         - \\ref NVML_SUCCESS                  if \\a device has been set\n *         - \\ref NVML_ERROR_UNINITIALIZED      if the library has not been successfully initialized\n *         - \\ref NVML_ERROR_INVALID_ARGUMENT   if \\a pciBusId is invalid or \\a device is NULL\n *         - \\ref NVML_ERROR_NOT_FOUND          if \\a pciBusId does not match a valid device on the system\n *         - \\ref NVML_ERROR_INSUFFICIENT_POWER if the attached device has improperly attached external power cables\n *         - \\ref NVML_ERROR_NO_PERMISSION      if the user doesn't have permission to talk to this device\n *         - \\ref NVML_ERROR_IRQ_ISSUE          if NVIDIA kernel detected an interrupt issue with the attached GPUs\n *         - \\ref NVML_ERROR_GPU_IS_LOST        if the target GPU has fallen off the bus or is otherwise inaccessible\n *         - \\ref NVML_ERROR_UNKNOWN            on any unexpected error\n */\n    \"\"\"\n    c_busId = c_char_p(pciBusId)\n    device = c_nvmlDevice_t()\n    fn = _nvmlGetFunctionPointer(\"nvmlDeviceGetHandleByPciBusId_v2\")\n    ret = fn(c_busId, byref(device))\n    _nvmlCheckReturn(ret)\n    return bytes_to_str(device)", "response": "r Returns the handle for a particular device based on its PCI bus id."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef nvmlDeviceGetBoardId(handle):\n    c_id = c_uint();\n    fn = _nvmlGetFunctionPointer(\"nvmlDeviceGetBoardId\")\n    ret = fn(handle, byref(c_id))\n    _nvmlCheckReturn(ret)\n    return bytes_to_str(c_id.value)", "response": "r Gets the boardId of the device."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef nvmlDeviceGetSerial(handle):\n    c_serial = create_string_buffer(NVML_DEVICE_SERIAL_BUFFER_SIZE)\n    fn = _nvmlGetFunctionPointer(\"nvmlDeviceGetSerial\")\n    ret = fn(handle, c_serial, c_uint(NVML_DEVICE_SERIAL_BUFFER_SIZE))\n    _nvmlCheckReturn(ret)\n    return bytes_to_str(c_serial.value)", "response": "r Gets the globally unique board serial number associated with this device."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef nvmlDeviceGetInforomVersion(handle, infoRomObject):\n    c_version = create_string_buffer(NVML_DEVICE_INFOROM_VERSION_BUFFER_SIZE)\n    fn = _nvmlGetFunctionPointer(\"nvmlDeviceGetInforomVersion\")\n    ret = fn(handle, _nvmlInforomObject_t(infoRomObject),\n\t         c_version, c_uint(NVML_DEVICE_INFOROM_VERSION_BUFFER_SIZE))\n    _nvmlCheckReturn(ret)\n    return bytes_to_str(c_version.value)", "response": "r Returns the inforom version of the infoROM object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef nvmlDeviceGetInforomImageVersion(handle):\n    c_version = create_string_buffer(NVML_DEVICE_INFOROM_VERSION_BUFFER_SIZE)\n    fn = _nvmlGetFunctionPointer(\"nvmlDeviceGetInforomImageVersion\")\n    ret = fn(handle, c_version, c_uint(NVML_DEVICE_INFOROM_VERSION_BUFFER_SIZE))\n    _nvmlCheckReturn(ret)\n    return bytes_to_str(c_version.value)", "response": "r Gets the global infoROM image version of the inforom."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef nvmlDeviceGetPciInfo(handle):\n    c_info = nvmlPciInfo_t()\n    fn = _nvmlGetFunctionPointer(\"nvmlDeviceGetPciInfo_v2\")\n    ret = fn(handle, byref(c_info))\n    _nvmlCheckReturn(ret)\n    return bytes_to_str(c_info)", "response": "r Returns the PCI attributes of the device."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef nvmlDeviceGetSupportedMemoryClocks(handle):\n    # first call to get the size\n    c_count = c_uint(0)\n    fn = _nvmlGetFunctionPointer(\"nvmlDeviceGetSupportedMemoryClocks\")\n    ret = fn(handle, byref(c_count), None)\n\n    if (ret == NVML_SUCCESS):\n        # special case, no clocks\n        return []\n    elif (ret == NVML_ERROR_INSUFFICIENT_SIZE):\n        # typical case\n        clocks_array = c_uint * c_count.value\n        c_clocks = clocks_array()\n\n        # make the call again\n        ret = fn(handle, byref(c_count), c_clocks)\n        _nvmlCheckReturn(ret)\n\n        procs = []\n        for i in range(c_count.value):\n            procs.append(c_clocks[i])\n\n        return procs\n    else:\n        # error case\n        raise NVMLError(ret)", "response": "r Returns the list of possible memory clocks that can be used for the given device."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef nvmlDeviceGetTemperatureThreshold(handle, threshold):\n    c_temp = c_uint()\n    fn = _nvmlGetFunctionPointer(\"nvmlDeviceGetTemperatureThreshold\")\n    ret = fn(handle, _nvmlTemperatureThresholds_t(threshold), byref(c_temp))\n    _nvmlCheckReturn(ret)\n    return bytes_to_str(c_temp.value)", "response": "r Returns the temperature threshold for the specified target device."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef nvmlDeviceGetPowerState(handle):\n    c_pstate = _nvmlPstates_t()\n    fn = _nvmlGetFunctionPointer(\"nvmlDeviceGetPowerState\")\n    ret = fn(handle, byref(c_pstate))\n    _nvmlCheckReturn(ret)\n    return bytes_to_str(c_pstate.value)", "response": "r Returns the current power state of the specified device."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef nvmlDeviceGetPowerManagementMode(handle):\n    c_pcapMode = _nvmlEnableState_t()\n    fn = _nvmlGetFunctionPointer(\"nvmlDeviceGetPowerManagementMode\")\n    ret = fn(handle, byref(c_pcapMode))\n    _nvmlCheckReturn(ret)\n    return bytes_to_str(c_pcapMode.value)", "response": "r Returns the power management mode associated with the given device."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef nvmlDeviceGetPowerManagementLimitConstraints(handle):\n    c_minLimit = c_uint()\n    c_maxLimit = c_uint()\n    fn = _nvmlGetFunctionPointer(\"nvmlDeviceGetPowerManagementLimitConstraints\")\n    ret = fn(handle, byref(c_minLimit), byref(c_maxLimit))\n    _nvmlCheckReturn(ret)\n    return [c_minLimit.value, c_maxLimit.value]", "response": "r Returns the minimum and maximum power management limits on the target GPU."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef nvmlDeviceGetGpuOperationMode(handle):\n    c_currState = _nvmlGpuOperationMode_t()\n    c_pendingState = _nvmlGpuOperationMode_t()\n    fn = _nvmlGetFunctionPointer(\"nvmlDeviceGetGpuOperationMode\")\n    ret = fn(handle, byref(c_currState), byref(c_pendingState))\n    _nvmlCheckReturn(ret)\n    return [c_currState.value, c_pendingState.value]", "response": "r Gets the current and pending GOM state of the GPU."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef nvmlDeviceGetComputeMode(handle):\n    c_mode = _nvmlComputeMode_t()\n    fn = _nvmlGetFunctionPointer(\"nvmlDeviceGetComputeMode\")\n    ret = fn(handle, byref(c_mode))\n    _nvmlCheckReturn(ret)\n    return bytes_to_str(c_mode.value)", "response": "r Gets the current compute mode for the device."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef nvmlDeviceGetEccMode(handle):\n    c_currState = _nvmlEnableState_t()\n    c_pendingState = _nvmlEnableState_t()\n    fn = _nvmlGetFunctionPointer(\"nvmlDeviceGetEccMode\")\n    ret = fn(handle, byref(c_currState), byref(c_pendingState))\n    _nvmlCheckReturn(ret)\n    return [c_currState.value, c_pendingState.value]", "response": "r Gets the current and pending ECC modes for a device."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef nvmlDeviceGetEncoderUtilization(handle):\n    c_util = c_uint()\n    c_samplingPeriod = c_uint()\n    fn = _nvmlGetFunctionPointer(\"nvmlDeviceGetEncoderUtilization\")\n    ret = fn(handle, byref(c_util), byref(c_samplingPeriod))\n    _nvmlCheckReturn(ret)\n    return [c_util.value, c_samplingPeriod.value]", "response": "r Returns the current utilization and sampling size for the encoder."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef nvmlDeviceGetPcieReplayCounter(handle):\n    c_replay = c_uint()\n    fn = _nvmlGetFunctionPointer(\"nvmlDeviceGetPcieReplayCounter\")\n    ret = fn(handle, byref(c_replay))\n    _nvmlCheckReturn(ret)\n    return bytes_to_str(c_replay.value)", "response": "r Returns the PCIe replay counter."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef nvmlDeviceGetDriverModel(handle):\n    c_currModel = _nvmlDriverModel_t()\n    c_pendingModel = _nvmlDriverModel_t()\n    fn = _nvmlGetFunctionPointer(\"nvmlDeviceGetDriverModel\")\n    ret = fn(handle, byref(c_currModel), byref(c_pendingModel))\n    _nvmlCheckReturn(ret)\n    return [c_currModel.value, c_pendingModel.value]", "response": "r Returns the current and pending driver model for the device."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef nvmlDeviceGetComputeRunningProcesses(handle):\n    # first call to get the size\n    c_count = c_uint(0)\n    fn = _nvmlGetFunctionPointer(\"nvmlDeviceGetComputeRunningProcesses\")\n    ret = fn(handle, byref(c_count), None)\n\n    if (ret == NVML_SUCCESS):\n        # special case, no running processes\n        return []\n    elif (ret == NVML_ERROR_INSUFFICIENT_SIZE):\n        # typical case\n        # oversize the array incase more processes are created\n        c_count.value = c_count.value * 2 + 5\n        proc_array = c_nvmlProcessInfo_t * c_count.value\n        c_procs = proc_array()\n\n        # make the call again\n        ret = fn(handle, byref(c_count), c_procs)\n        _nvmlCheckReturn(ret)\n\n        procs = []\n        for i in range(c_count.value):\n            # use an alternative struct for this object\n            obj = nvmlStructToFriendlyObject(c_procs[i])\n            if (obj.usedGpuMemory == NVML_VALUE_NOT_AVAILABLE_ulonglong.value):\n                # special case for WDDM on Windows, see comment above\n                obj.usedGpuMemory = None\n            procs.append(obj)\n\n        return procs\n    else:\n        # error case\n        raise NVMLError(ret)", "response": "r This function returns the information about the processes running on a device."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef nvmlDeviceGetAutoBoostedClocksEnabled(handle):\n    c_isEnabled = _nvmlEnableState_t()\n    c_defaultIsEnabled = _nvmlEnableState_t()\n    fn = _nvmlGetFunctionPointer(\"nvmlDeviceGetAutoBoostedClocksEnabled\")\n    ret = fn(handle, byref(c_isEnabled), byref(c_defaultIsEnabled))\n    _nvmlCheckReturn(ret)\n    return [c_isEnabled.value, c_defaultIsEnabled.value]", "response": "r Device Auto Boosted Clocks is enabled on a target device."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef nvmlDeviceClearEccErrorCounts(handle, counterType):\n    fn = _nvmlGetFunctionPointer(\"nvmlDeviceClearEccErrorCounts\")\n    ret = fn(handle, _nvmlEccCounterType_t(counterType))\n    _nvmlCheckReturn(ret)\n    return None", "response": "r Clear the error counts for a given device."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef nvmlDeviceSetAutoBoostedClocksEnabled(handle, enabled):\n    fn = _nvmlGetFunctionPointer(\"nvmlDeviceSetAutoBoostedClocksEnabled\")\n    ret = fn(handle, _nvmlEnableState_t(enabled))\n    _nvmlCheckReturn(ret)\n    return None", "response": "r Set Auto Boosted Clocks on a device."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef nvmlDeviceSetApplicationsClocks(handle, maxMemClockMHz, maxGraphicsClockMHz):\n    fn = _nvmlGetFunctionPointer(\"nvmlDeviceSetApplicationsClocks\")\n    ret = fn(handle, c_uint(maxMemClockMHz), c_uint(maxGraphicsClockMHz))\n    _nvmlCheckReturn(ret)\n    return None", "response": "r Set the clocks that compute and graphics applications will lock to."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef nvmlDeviceRegisterEvents(handle, eventTypes, eventSet):\n    fn = _nvmlGetFunctionPointer(\"nvmlDeviceRegisterEvents\")\n    ret = fn(handle, c_ulonglong(eventTypes), eventSet)\n    _nvmlCheckReturn(ret)\n    return None", "response": "r This function is used to register events on a specific device."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef nvmlDeviceOnSameBoard(handle1, handle2):\n    fn = _nvmlGetFunctionPointer(\"nvmlDeviceOnSameBoard\")\n    onSameBoard = c_int()\n    ret = fn(handle1, handle2, byref(onSameBoard))\n    _nvmlCheckReturn(ret)\n    return (onSameBoard.value != 0)", "response": "r Check if two GPUs are on the same board."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef nvmlDeviceGetAccountingMode(handle):\n    c_mode = _nvmlEnableState_t()\n    fn = _nvmlGetFunctionPointer(\"nvmlDeviceGetAccountingMode\")\n    ret = fn(handle, byref(c_mode))\n    _nvmlCheckReturn(ret)\n    return bytes_to_str(c_mode.value)", "response": "r Returns the current accounting mode of the specified device."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef nvmlDeviceGetAccountingPids(handle):\n    count = c_uint(nvmlDeviceGetAccountingBufferSize(handle))\n    pids = (c_uint * count.value)()\n    fn = _nvmlGetFunctionPointer(\"nvmlDeviceGetAccountingPids\")\n    ret = fn(handle, byref(count), pids)\n    _nvmlCheckReturn(ret)\n    return list(map(int, pids[0:count.value]))", "response": "r Returns a list of process ids that can be queried for accounting mode."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef nvmlDeviceGetAccountingBufferSize(handle):\n    bufferSize = c_uint()\n    fn = _nvmlGetFunctionPointer(\"nvmlDeviceGetAccountingBufferSize\")\n    ret = fn(handle, byref(bufferSize))\n    _nvmlCheckReturn(ret)\n    return int(bufferSize.value)", "response": "r Returns the size of the circular buffer that can be used for accounting."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef nvmlDeviceSetAPIRestriction(handle, apiType, isRestricted):\n    fn = _nvmlGetFunctionPointer(\"nvmlDeviceSetAPIRestriction\")\n    ret = fn(handle, _nvmlRestrictedAPI_t(apiType), _nvmlEnableState_t(isRestricted))\n    _nvmlCheckReturn(ret)\n    return None", "response": "r Sets the API restrictions for a device."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef nvmlDeviceGetTopologyNearestGpus(device, level):\n    c_count = c_uint(0)\n    fn = _nvmlGetFunctionPointer(\"nvmlDeviceGetTopologyNearestGpus\")\n\n    # First call will get the size\n    ret = fn(device, level, byref(c_count), None)\n\n    if ret != NVML_SUCCESS:\n        raise NVMLError(ret)\n\n    # call again with a buffer\n    device_array = c_nvmlDevice_t * c_count.value\n    c_devices = device_array()\n    ret = fn(device, level, byref(c_count), c_devices)\n    _nvmlCheckReturn(ret)\n    return list(c_devices[0:c_count.value])", "response": "r Returns the set of GPUs that are nearest to a given device at a specific interconnectivity level."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef nvmlDeviceGetTopologyCommonAncestor(device1, device2):\n    c_level = _nvmlGpuTopologyLevel_t()\n    fn = _nvmlGetFunctionPointer(\"nvmlDeviceGetTopologyCommonAncestor\")\n    ret = fn(device1, device2, byref(c_level))\n    _nvmlCheckReturn(ret)\n    return bytes_to_str(c_level.value)", "response": "r Returns the common ancestor of two devices."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef encode_notifications(tokens, notifications):\n  \n  fmt = \"!BH32sH%ds\"\n  structify = lambda t, p: struct.pack(fmt % len(p), 0, 32, t, len(p), p)\n  binaryify = lambda t: t.decode('hex')\n  if type(notifications) is dict and type(tokens) in (str, unicode):\n    tokens, notifications = ([tokens], [notifications])\n  if type(notifications) is list and type(tokens) is list:\n    return ''.join(map(lambda y: structify(*y), ((binaryify(t), json.dumps(p, separators=(',',':'), ensure_ascii=False).encode('utf-8'))\n                                    for t, p in zip(tokens, notifications))))", "response": "Encodes the given tokens and notifications into a byte string."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of tuples in ( datetime token_str ) format binary_tuples the binary - encoded feedback tuples athorian", "response": "def decode_feedback(binary_tuples):\n  \"\"\" Returns a list of tuples in (datetime, token_str) format \n  \n        binary_tuples   the binary-encoded feedback tuples\n  \"\"\"\n  \n  fmt = '!lh32s'\n  size = struct.calcsize(fmt)\n  with StringIO(binary_tuples) as f:\n    return [(datetime.datetime.fromtimestamp(ts), binascii.hexlify(tok))\n            for ts, toklen, tok in (struct.unpack(fmt, tup) \n                              for tup in iter(lambda: f.read(size), ''))]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconnecting to the APNS service and send notifications", "response": "def write(self, notifications):\n    \"Connect to the APNS service and send notifications\"\n    if not self.factory:\n      log.msg('APNSService write (connecting)')\n      server, port = ((APNS_SERVER_SANDBOX_HOSTNAME \n                      if self.environment == 'sandbox'\n                      else APNS_SERVER_HOSTNAME), APNS_SERVER_PORT)\n      self.factory = self.clientProtocolFactory()\n      context = self.getContextFactory()\n      reactor.connectSSL(server, port, self.factory, context)\n    \n    client = self.factory.clientProtocol\n    if client:\n      return client.sendMessage(notifications)\n    else:      \n      d = self.factory.deferred\n      timeout = reactor.callLater(self.timeout, \n        lambda: d.called or d.errback(\n          Exception('Notification timed out after %i seconds' % self.timeout)))\n      def cancel_timeout(r):\n        try: timeout.cancel()\n        except: pass\n        return r\n      \n      d.addCallback(lambda p: p.sendMessage(notifications))\n      d.addErrback(log_errback('apns-service-write'))\n      d.addBoth(cancel_timeout)\n      return d"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read(self):\n    \"Connect to the feedback service and read all data.\"\n    log.msg('APNSService read (connecting)')\n    try:\n      server, port = ((FEEDBACK_SERVER_SANDBOX_HOSTNAME \n                      if self.environment == 'sandbox'\n                      else FEEDBACK_SERVER_HOSTNAME), FEEDBACK_SERVER_PORT)\n      factory = self.feedbackProtocolFactory()\n      context = self.getContextFactory()\n      reactor.connectSSL(server, port, factory, context)\n      factory.deferred.addErrback(log_errback('apns-feedback-read'))\n      \n      timeout = reactor.callLater(self.timeout,\n        lambda: factory.deferred.called or factory.deferred.errback(\n          Exception('Feedbcak fetch timed out after %i seconds' % self.timeout)))\n      def cancel_timeout(r):\n        try: timeout.cancel()\n        except: pass\n        return r\n      \n      factory.deferred.addBoth(cancel_timeout)\n    except Exception, e:\n      log.err('APNService feedback error initializing: %s' % str(e))\n      raise\n    return factory.deferred", "response": "Connect to the feedback service and read all data."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstarts an APNSService for the app_id and store it in self. app_ids.", "response": "def xmlrpc_provision(self, app_id, path_to_cert_or_cert, environment, timeout=15):\n    \"\"\" Starts an APNSService for the this app_id and keeps it running\n    \n      Arguments:\n          app_id                 the app_id to provision for APNS\n          path_to_cert_or_cert   absolute path to the APNS SSL cert or a \n                                 string containing the .pem file\n          environment            either 'sandbox' or 'production'\n          timeout                seconds to timeout connection attempts\n                                 to the APNS server\n      Returns:\n          None\n    \"\"\"\n    \n    if environment not in ('sandbox', 'production'):\n      raise xmlrpc.Fault(401, 'Invalid environment provided `%s`. Valid '\n                              'environments are `sandbox` and `production`' % (\n                              environment,))\n    if not app_id in self.app_ids:\n      # log.msg('provisioning ' + app_id + ' environment ' + environment)\n      self.app_ids[app_id] = APNSService(path_to_cert_or_cert, environment, timeout)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsends push notifications to the APNS server.", "response": "def xmlrpc_notify(self, app_id, token_or_token_list, aps_dict_or_list):\n    \"\"\" Sends push notifications to the Apple APNS server. Multiple \n    notifications can be sent by sending pairing the token/notification\n    arguments in lists [token1, token2], [notification1, notification2].\n    \n      Arguments:\n          app_id                provisioned app_id to send to\n          token_or_token_list   token to send the notification or a list of tokens\n          aps_dict_or_list      notification dicts or a list of notifications\n      Returns:\n          None\n    \"\"\"\n    d = self.apns_service(app_id).write(\n      encode_notifications(\n        [t.replace(' ', '') for t in token_or_token_list] \n          if (type(token_or_token_list) is list)\n          else token_or_token_list.replace(' ', ''),\n        aps_dict_or_list))\n    if d:\n      def _finish_err(r):\n        # so far, the only error that could really become of this\n        # request is a timeout, since APNS simply terminates connectons\n        # that are made unsuccessfully, which twisted will try endlessly\n        # to reconnect to, we timeout and notifify the client\n        raise xmlrpc.Fault(500, 'Connection to the APNS server could not be made.')\n      return d.addCallbacks(lambda r: None, _finish_err)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef xmlrpc_feedback(self, app_id):\n    \n    return self.apns_service(app_id).read().addCallback(\n      lambda r: decode_feedback(r))", "response": "Queries the APNS feedback server for inactive app tokens. Returns a list of tuples as ( datetime_went_dark token_str )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwraps the `errback` callback of the API functions, automatically trying to re-provision if the app ID can not be found during the operation. If that's unsuccessful, it will raise the UnknownAppID error.", "response": "def reprovision_and_retry(func):\n  \"\"\"\n  Wraps the `errback` callback of the API functions, automatically trying to\n  re-provision if the app ID can not be found during the operation. If that's\n  unsuccessful, it will raise the UnknownAppID error.\n  \"\"\"\n  @functools.wraps(func)\n  def wrapper(*a, **kw):\n    errback = kw.get('errback', None)\n    if errback is None:\n      def errback(e):\n        raise e\n    def errback_wrapper(e):\n      if isinstance(e, UnknownAppID) and 'INITIAL' in OPTIONS:\n        try:\n          for initial in OPTIONS['INITIAL']:\n            provision(*initial) # retry provisioning the initial setup\n          func(*a, **kw) # and try the function once more\n        except Exception, new_exc:\n          errback(new_exc) # throwing the new exception\n      else:\n        errback(e) # not an instance of UnknownAppID - nothing we can do here\n    kw['errback'] = errback_wrapper\n    return func(*a, **kw)\n  return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning all text till it encounters the given string or one of the given strings.", "response": "def text_till(self, strings, keep_index=False):\n        \"\"\"Returns all text till it encounters the given string (or one of the given strings)\"\"\"\n        if isinstance(strings, str):\n            strings = [strings]\n\n        original_index = self.index\n\n        text = \"\"\n        matched_string = \"\"\n\n        while self.more:\n            test_against = self.characters(len(max(strings, key=len)))\n            for string in strings:\n                if string.startswith(\"^\"):\n                    if test_against[0] in (\" \", \"\\t\", \"\\n\", \")\", \"(\") and test_against[1:].startswith(string[1:]):\n                        matched_string = string\n                        break\n                if test_against.startswith(string):\n                    matched_string = string\n                    break\n\n            if matched_string:\n                break\n\n            text += self.pop()\n\n        self += 1\n\n        if keep_index:\n            self.index = original_index\n\n        return (text, matched_string)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef text_after(self, start, match_on):\n        text = \"\"\n        index = start - 1\n        while index > 0:\n            text = self.code[index:start]\n            if text.startswith(match_on):\n                return text.lstrip(match_on)\n            index -= 1\n\n        return text.lstrip(match_on)", "response": "Returns all text till it encounters the given string or one of the given strings."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pop(self):\n        char = self.code[self.index]\n        self.index += 1\n        return char", "response": "removes the current character moves to the next one returning the current character"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef characters(self, numberOfCharacters):\n        return self.code[self.index:self.index + numberOfCharacters]", "response": "Returns the characters at index + number of characters"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the next non - whitespace characters in the code.", "response": "def next_content(self, start, amount=1):\n        \"\"\"Returns the next non-whitespace characters\"\"\"\n        while start < len(self.code) and self.code[start] in (' ', '\\t', '\\n'):\n            start += 1\n\n        return self.code[start: start + amount]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the previous non - whitespace characters", "response": "def prev_content(self, start, amount=1):\n        \"\"\"Returns the prev non-whitespace characters\"\"\"\n        while start > 0 and self.code[start] in (' ', '\\t', '\\n'):\n            start -= 1\n\n        return self.code[(start or amount) - amount: start]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the command line arguments and returns the parsed arguments.", "response": "def parse_arguments(\n        argv: Optional[Sequence[str]] = None) -> argparse.Namespace:\n    \"\"\"\n    Parse the command line arguments.\n\n    Args:\n        argv:\n            If not ``None``, use the provided command line arguments for\n            parsing. Otherwise, extract them automatically.\n\n    Returns:\n        The argparse object representing the parsed arguments.\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        description='Git credential helper using pass as the data source.',\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n    parser.add_argument(\n        '-m', '--mapping',\n        type=argparse.FileType('r'),\n        metavar='MAPPING_FILE',\n        default=None,\n        help='A mapping file to be used, specifying how hosts '\n             'map to pass entries. Overrides the default mapping files from '\n             'XDG config locations, usually: {config_file}'.format(\n                 config_file=DEFAULT_CONFIG_FILE))\n    parser.add_argument(\n        '-l', '--logging',\n        action='store_true',\n        default=False,\n        help='Print debug messages on stderr. '\n             'Might include sensitive information')\n    parser.add_argument(\n        'action',\n        type=str,\n        metavar='ACTION',\n        help='Action to preform as specified in the git credential API')\n\n    args = parser.parse_args(argv)\n\n    return args"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the file containing the mappings from hosts to pass entries.", "response": "def parse_mapping(mapping_file: Optional[str]) -> configparser.ConfigParser:\n    \"\"\"\n    Parse the file containing the mappings from hosts to pass entries.\n\n    Args:\n        mapping_file:\n            Name of the file to parse. If ``None``, the default file from the\n            XDG location is used.\n    \"\"\"\n    LOGGER.debug('Parsing mapping file. Command line: %s', mapping_file)\n\n    def parse(mapping_file):\n        config = configparser.ConfigParser()\n        config.read_file(mapping_file)\n        return config\n\n    # give precedence to the user-specified file\n    if mapping_file is not None:\n        LOGGER.debug('Parsing command line mapping file')\n        return parse(mapping_file)\n\n    # fall back on XDG config location\n    xdg_config_dir = xdg.BaseDirectory.load_first_config('pass-git-helper')\n    if xdg_config_dir is None:\n        raise RuntimeError(\n            'No mapping configured so far at any XDG config location. '\n            'Please create {config_file}'.format(\n                config_file=DEFAULT_CONFIG_FILE))\n    mapping_file = os.path.join(xdg_config_dir, CONFIG_FILE_NAME)\n    LOGGER.debug('Parsing mapping file %s', mapping_file)\n    with open(mapping_file, 'r') as file_handle:\n        return parse(file_handle)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse the request of the git credential API from stdin and return a dictionary with all key - value pairs of the request.", "response": "def parse_request() -> Dict[str, str]:\n    \"\"\"\n    Parse the request of the git credential API from stdin.\n\n    Returns:\n        A dictionary with all key-value pairs of the request\n    \"\"\"\n    in_lines = sys.stdin.readlines()\n    LOGGER.debug('Received request \"%s\"', in_lines)\n\n    request = {}\n    for line in in_lines:\n        # skip empty lines to be a bit resilient against protocol errors\n        if not line.strip():\n            continue\n\n        parts = line.split('=', 1)\n        assert len(parts) == 2\n        request[parts[0].strip()] = parts[1].strip()\n\n    return request"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the password from the given credential request.", "response": "def get_password(request, mapping) -> None:\n    \"\"\"\n    Resolve the given credential request in the provided mapping definition.\n\n    The result is printed automatically.\n\n    Args:\n        request:\n            The credential request specified as a dict of key-value pairs.\n        mapping:\n            The mapping configuration as a ConfigParser instance.\n    \"\"\"\n    LOGGER.debug('Received request \"%s\"', request)\n    if 'host' not in request:\n        LOGGER.error('host= entry missing in request. '\n                     'Cannot query without a host')\n        return\n\n    host = request['host']\n    if 'path' in request:\n        host = '/'.join([host, request['path']])\n\n    def skip(line, skip):\n        return line[skip:]\n\n    LOGGER.debug('Iterating mapping to match against host \"%s\"', host)\n    for section in mapping.sections():\n        if fnmatch.fnmatch(host, section):\n            LOGGER.debug('Section \"%s\" matches requested host \"%s\"',\n                         section, host)\n            # TODO handle exceptions\n            pass_target = mapping.get(section, 'target').replace(\n                \"${host}\", request['host'])\n\n            password_extractor = SpecificLineExtractor(\n                0, 0, option_suffix='_password')\n            password_extractor.configure(mapping[section])\n            # username_extractor = SpecificLineExtractor(\n            #     1, 0, option_suffix='_username')\n            username_extractor = _username_extractors[mapping[section].get(\n                'username_extractor', fallback=_line_extractor_name)]\n            username_extractor.configure(mapping[section])\n\n            LOGGER.debug('Requesting entry \"%s\" from pass', pass_target)\n            output = subprocess.check_output(\n                ['pass', 'show', pass_target]).decode('utf-8')\n            lines = output.splitlines()\n\n            password = password_extractor.get_value(pass_target, lines)\n            username = username_extractor.get_value(pass_target, lines)\n            if password:\n                print('password={password}'.format(  # noqa: T001\n                    password=password))\n            if 'username' not in request and username:\n                print('username={username}'.format(  # noqa: T001\n                    username=username))\n            return\n\n    LOGGER.warning('No mapping matched')\n    sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef main(argv: Optional[Sequence[str]] = None) -> None:\n    args = parse_arguments(argv=argv)\n\n    if args.logging:\n        logging.basicConfig(level=logging.DEBUG)\n\n    handle_skip()\n\n    action = args.action\n    request = parse_request()\n    LOGGER.debug('Received action %s with request:\\n%s',\n                 action, request)\n\n    try:\n        mapping = parse_mapping(args.mapping)\n    except Exception as error:\n        LOGGER.critical('Unable to parse mapping file', exc_info=True)\n        print(  # noqa: P101\n            'Unable to parse mapping file: {error}'.format(\n                error=error),\n            file=sys.stderr)\n        sys.exit(1)\n\n    if action == 'get':\n        get_password(request, mapping)\n    else:\n        LOGGER.info('Action %s is currently not supported', action)\n        sys.exit(1)", "response": "Main entry point for pass - git - helper."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconfiguring the amount of characters to skip.", "response": "def configure(self, config):\n        \"\"\"Configure the amount of characters to skip.\"\"\"\n        self._prefix_length = config.getint(\n            'skip{suffix}'.format(suffix=self._option_suffix),\n            fallback=self._prefix_length)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_value(self,\n                  entry_name: Text,\n                  entry_lines: Sequence[Text]) -> Optional[Text]:\n        \"\"\"See base class method.\"\"\"\n        raw_value = self._get_raw(entry_name, entry_lines)\n        if raw_value is not None:\n            return raw_value[self._prefix_length:]\n        else:\n            return None", "response": "Get the value of a resource entry."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef configure(self, config):\n        super().configure(config)\n        self._line = config.getint(\n            'line{suffix}'.format(suffix=self._option_suffix),\n            fallback=self._line)", "response": "Configure the object with the configuration parameters."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef configure(self, config):\n        super().configure(config)\n\n        self._regex = self._build_matcher(config.get(\n            'regex{suffix}'.format(suffix=self._option_suffix),\n            fallback=self._regex.pattern))", "response": "Configure the object based on the configuration parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the value of the entry_name from the entry_lines.", "response": "def get_value(self,\n                  entry_name: Text,\n                  entry_lines: Sequence[Text]) -> Optional[Text]:\n        \"\"\"See base class method.\"\"\"\n        # Search through all lines and return the first matching one\n        for line in entry_lines:\n            match = self._regex.match(line)\n            if match:\n                return match.group(1)\n        # nothing matched\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_value(self,\n                  entry_name: Text,\n                  entry_lines: Sequence[Text]) -> Optional[Text]:\n        \"\"\"See base class method.\"\"\"\n        return os.path.split(entry_name)[1]", "response": "Get the value of the key from the entry name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef insert_metric_changes(db, metrics, metric_mapping, commit):\n    values = [\n        [commit.sha, metric_mapping[metric.name], metric.value]\n        for metric in metrics\n        if metric.value != 0\n    ]\n    db.executemany(\n        'INSERT INTO metric_changes (sha, metric_id, value) VALUES (?, ?, ?)',\n        values,\n    )", "response": "Insert into the metric_changes tables."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of Commit objects.", "response": "def get_commits(self, since_sha=None):\n        \"\"\"Returns a list of Commit objects.\n\n        Args:\n           since_sha - (optional) A sha to search from\n        \"\"\"\n        assert self.tempdir\n\n        cmd = ['git', 'log', '--first-parent', '--reverse', COMMIT_FORMAT]\n        if since_sha:\n            commits = [self.get_commit(since_sha)]\n            cmd.append('{}..HEAD'.format(since_sha))\n        else:\n            commits = []\n            cmd.append('HEAD')\n\n        output = cmd_output(*cmd, cwd=self.tempdir)\n\n        for sha, date in chunk_iter(output.splitlines(), 2):\n            commits.append(Commit(sha, int(date)))\n\n        return commits"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef discover(package, cls_match_func):\n    matched_classes = set()\n\n    for _, module_name, _ in pkgutil.walk_packages(\n            package.__path__,\n            prefix=package.__name__ + '.',\n    ):\n        module = __import__(module_name, fromlist=[str('__trash')], level=0)\n\n        # Check all the classes in that module\n        for _, imported_class in inspect.getmembers(module, inspect.isclass):\n            # Don't include things that are only there due to a side-effect of\n            # importing\n            if imported_class.__module__ != module.__name__:\n                continue\n\n            if cls_match_func(imported_class):\n                matched_classes.add(imported_class)\n\n    return matched_classes", "response": "Returns a set of classes in the directory matched by cls_match_func\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nyield an iterator in chunks", "response": "def chunk_iter(iterable, n):\n    \"\"\"Yields an iterator in chunks\n\n    For example you can do\n\n    for a, b in chunk_iter([1, 2, 3, 4, 5, 6], 2):\n        print('{} {}'.format(a, b))\n\n    # Prints\n    # 1 2\n    # 3 4\n    # 5 6\n\n    Args:\n        iterable - Some iterable\n        n - Chunk size (must be greater than 0)\n    \"\"\"\n    assert n > 0\n    iterable = iter(iterable)\n\n    chunk = tuple(itertools.islice(iterable, n))\n    while chunk:\n        yield chunk\n        chunk = tuple(itertools.islice(iterable, n))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_metric_cls(cls):\n    return (\n        cls is not DiffParserBase and\n        cls.__dict__.get('__metric__', True) and\n        issubclass(cls, DiffParserBase)\n    )", "response": "A metric class is defined as follows"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a set of all of the metric parsers that can be used for the given packages.", "response": "def get_metric_parsers(metric_packages=tuple(), include_defaults=True):\n    \"\"\"Gets all of the metric parsers.\n\n    Args:\n        metric_packages - Defaults to no extra packages. An iterable of\n            metric containing packages.  A metric inherits DiffParserBase\n            and does not have __metric__ = False\n            A metric package must be imported using import a.b.c\n        include_defaults - Whether to include the generic metric parsers\n    \"\"\"\n    metric_parsers = set()\n\n    if include_defaults:\n        import git_code_debt.metrics\n        metric_parsers.update(discover(git_code_debt.metrics, is_metric_cls))\n\n    for metric_package in metric_packages:\n        metric_parsers.update(discover(metric_package, is_metric_cls))\n    return metric_parsers"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating the database schema.", "response": "def create_schema(db):\n    \"\"\"Creates the database schema.\"\"\"\n    schema_dir = pkg_resources.resource_filename('git_code_debt', 'schema')\n    schema_files = os.listdir(schema_dir)\n\n    for sql_file in schema_files:\n        resource_filename = os.path.join(schema_dir, sql_file)\n        with open(resource_filename, 'r') as resource:\n            db.executescript(resource.read())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef timeago_template(locale, index, ago_in):\n    '''\n    simple locale implement\n    '''\n    try:\n        LOCALE = __import__('timeago.locales.' + locale)\n        LOCALE = locale_module(LOCALE, locale)\n    except:\n        locale = setting.DEFAULT_LOCALE\n        LOCALE = __import__('timeago.locales.' + locale)\n        LOCALE = locale_module(LOCALE, locale)\n\n    if isinstance(LOCALE, list):\n        return LOCALE[index][ago_in]\n    else:\n        return LOCALE(index, ago_in)", "response": "get a locale - specific template for a given locale"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse(input):\n    '''\n    parse input to datetime\n    '''\n    if isinstance(input, datetime):\n        return input\n    if isinstance(input, date):\n        return date_to_datetime(input)\n    if isinstance(input, time):\n        return time_to_datetime(input)\n    if isinstance(input, (int, float)):\n        return timestamp_to_datetime(input)\n    if isinstance(input, (str)):\n        return string_to_data_time(input)\n    return None", "response": "parse input to datetime\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef string_to_data_time(d):\n    '''\n    simple parse date string, such as:\n    2016-5-27 21:22:20\n    2016-05-27 21:22:2\n    2016/05/27 21:22:2\n\n    2016-05-27\n    2016/5/27\n\n    21:22:2\n    '''\n    if d:\n        d = d.replace('/', '-')\n        if ' ' in d:\n            _datetime = d.split(' ')\n            if len(_datetime) == 2:\n                _d = _string_to_date(_datetime[0])\n                _t = _string_to_time(_datetime[1])\n                return _combine_date_time(_d, _t)\n        else:\n            # no space\n            if '-' in d:\n                return date_to_datetime(_string_to_date(d))\n            elif ':' in d:\n                return time_to_datetime(_string_to_time(d))\n    return None", "response": "converts a string to a date or time object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the string representation of the date in the specified locale", "response": "def format(date, now=None, locale='en'):\n    '''\n    the entry method\n    '''\n    if not isinstance(date, timedelta):\n        if now is None:\n            now = datetime.now()\n        date = parser.parse(date)\n        now = parser.parse(now)\n\n        if date is None:\n            raise ParameterUnvalid('the parameter `date` should be datetime '\n                                   '/ timedelta, or datetime formated string.')\n        if now is None:\n            raise ParameterUnvalid('the parameter `now` should be datetime, '\n                                   'or datetime formated string.')\n        date = now - date\n    # the gap sec\n    diff_seconds = int(total_seconds(date))\n\n    # is ago or in\n    ago_in = 0\n    if diff_seconds < 0:\n        ago_in = 1  # date is later then now, is the time in future\n        diff_seconds *= -1  # chango to positive\n\n    tmp = 0\n    i = 0\n    while i < SEC_ARRAY_LEN:\n        tmp = SEC_ARRAY[i]\n        if diff_seconds >= tmp:\n            i += 1\n            diff_seconds /= tmp\n        else:\n            break\n    diff_seconds = int(diff_seconds)\n    i *= 2\n\n    if diff_seconds > (i == 0 and 9 or 1):\n        i += 1\n\n    if locale is None:\n        locale = DEFAULT_LOCALE\n\n    tmp = timeago_template(locale, i, ago_in)\n    if hasattr(tmp, '__call__'):\n        tmp = tmp(diff_seconds)\n    return '%s' in tmp and tmp % diff_seconds or tmp"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _is_parent_of(parent, child):\n    if child.is_partition:\n        return child.partition_slave == parent\n    if child.is_toplevel:\n        return child.drive == parent and child != parent\n    return False", "response": "Check whether the first device is the parent of the second device."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlaunches file manager on the mount path of the specified device.", "response": "async def browse(self, device):\n        \"\"\"\n        Launch file manager on the mount path of the specified device.\n\n        :param device: device object, block device path or mount path\n        :returns: whether the program was successfully launched.\n        \"\"\"\n        device = self._find_device(device)\n        if not device.is_mounted:\n            self._log.error(_(\"not browsing {0}: not mounted\", device))\n            return False\n        if not self._browser:\n            self._log.error(_(\"not browsing {0}: no program\", device))\n            return False\n        self._log.debug(_('opening {0} on {0.mount_paths[0]}', device))\n        self._browser(device.mount_paths[0])\n        self._log.info(_('opened {0} on {0.mount_paths[0]}', device))\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def terminal(self, device):\n        device = self._find_device(device)\n        if not device.is_mounted:\n            self._log.error(_(\"not opening terminal {0}: not mounted\", device))\n            return False\n        if not self._terminal:\n            self._log.error(_(\"not opening terminal {0}: no program\", device))\n            return False\n        self._log.debug(_('opening {0} on {0.mount_paths[0]}', device))\n        self._terminal(device.mount_paths[0])\n        self._log.info(_('opened {0} on {0.mount_paths[0]}', device))\n        return True", "response": "Launch a terminal on the specified block device path or mount path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def mount(self, device):\n        device = self._find_device(device)\n        if not self.is_handleable(device) or not device.is_filesystem:\n            self._log.warn(_('not mounting {0}: unhandled device', device))\n            return False\n        if device.is_mounted:\n            self._log.info(_('not mounting {0}: already mounted', device))\n            return True\n        options = match_config(self._config, device, 'options', None)\n        kwargs = dict(options=options)\n        self._log.debug(_('mounting {0} with {1}', device, kwargs))\n        self._check_device_before_mount(device)\n        mount_path = await device.mount(**kwargs)\n        self._log.info(_('mounted {0} on {1}', device, mount_path))\n        return True", "response": "Mount the device if not already mounted."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def unmount(self, device):\n        device = self._find_device(device)\n        if not self.is_handleable(device) or not device.is_filesystem:\n            self._log.warn(_('not unmounting {0}: unhandled device', device))\n            return False\n        if not device.is_mounted:\n            self._log.info(_('not unmounting {0}: not mounted', device))\n            return True\n        self._log.debug(_('unmounting {0}', device))\n        await device.unmount()\n        self._log.info(_('unmounted {0}', device))\n        return True", "response": "Unmount a device if mounted."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def unlock(self, device):\n        device = self._find_device(device)\n        if not self.is_handleable(device) or not device.is_crypto:\n            self._log.warn(_('not unlocking {0}: unhandled device', device))\n            return False\n        if device.is_unlocked:\n            self._log.info(_('not unlocking {0}: already unlocked', device))\n            return True\n        if not self._prompt:\n            self._log.error(_('not unlocking {0}: no password prompt', device))\n            return False\n        unlocked = await self._unlock_from_cache(device)\n        if unlocked:\n            return True\n        unlocked = await self._unlock_from_keyfile(device)\n        if unlocked:\n            return True\n        options = dict(allow_keyfile=self.udisks.keyfile_support,\n                       allow_cache=self._cache is not None,\n                       cache_hint=self._cache_hint)\n        password = await self._prompt(device, options)\n        # password can be: None, str, or udiskie.prompt.PasswordResult\n        cache_hint = getattr(password, 'cache_hint', self._cache_hint)\n        password = getattr(password, 'password', password)\n        if password is None:\n            self._log.debug(_('not unlocking {0}: cancelled by user', device))\n            return False\n        if isinstance(password, bytes):\n            self._log.debug(_('unlocking {0} using keyfile', device))\n            await device.unlock_keyfile(password)\n        else:\n            self._log.debug(_('unlocking {0}', device))\n            await device.unlock(password)\n        self._update_cache(device, password, cache_hint)\n        self._log.info(_('unlocked {0}', device))\n        return True", "response": "Unlock the device if not already unlocked."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlocking the specified device.", "response": "async def lock(self, device):\n        \"\"\"\n        Lock device if unlocked.\n\n        :param device: device object, block device path or mount path\n        :returns: whether the device is locked\n        \"\"\"\n        device = self._find_device(device)\n        if not self.is_handleable(device) or not device.is_crypto:\n            self._log.warn(_('not locking {0}: unhandled device', device))\n            return False\n        if not device.is_unlocked:\n            self._log.info(_('not locking {0}: not unlocked', device))\n            return True\n        self._log.debug(_('locking {0}', device))\n        await device.lock()\n        self._log.info(_('locked {0}', device))\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmounts or unlock the device depending on its type.", "response": "async def add(self, device, recursive=None):\n        \"\"\"\n        Mount or unlock the device depending on its type.\n\n        :param device: device object, block device path or mount path\n        :param bool recursive: recursively mount and unlock child devices\n        :returns: whether all attempted operations succeeded\n        \"\"\"\n        device, created = await self._find_device_losetup(device)\n        if created and recursive is False:\n            return device\n        if device.is_filesystem:\n            success = await self.mount(device)\n        elif device.is_crypto:\n            success = await self.unlock(device)\n            if success and recursive:\n                await self.udisks._sync()\n                device = self.udisks[device.object_path]\n                success = await self.add(\n                    device.luks_cleartext_holder,\n                    recursive=True)\n        elif (recursive\n              and device.is_partition_table\n              and self.is_handleable(device)):\n            tasks = [\n                self.add(dev, recursive=True)\n                for dev in self.get_all_handleable()\n                if dev.is_partition and dev.partition_slave == device\n            ]\n            results = await gather(*tasks)\n            success = all(results)\n        else:\n            self._log.info(_('not adding {0}: unhandled device', device))\n            return False\n        return success"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def remove(self, device, force=False, detach=False, eject=False,\n                     lock=False):\n        \"\"\"\n        Unmount or lock the device depending on device type.\n\n        :param device: device object, block device path or mount path\n        :param bool force: recursively remove all child devices\n        :param bool detach: detach the root drive\n        :param bool eject: remove media from the root drive\n        :param bool lock: lock the associated LUKS cleartext slave\n        :returns: whether all attempted operations succeeded\n        \"\"\"\n        device = self._find_device(device)\n        if device.is_filesystem:\n            if device.is_mounted or not device.is_loop or detach is False:\n                success = await self.unmount(device)\n        elif device.is_crypto:\n            if force and device.is_unlocked:\n                await self.auto_remove(device.luks_cleartext_holder, force=True)\n            success = await self.lock(device)\n        elif (force\n              and (device.is_partition_table or device.is_drive)\n              and self.is_handleable(device)):\n            kw = dict(force=True, detach=detach, eject=eject, lock=lock)\n            tasks = [\n                self.auto_remove(child, **kw)\n                for child in self.get_all_handleable()\n                if _is_parent_of(device, child)\n            ]\n            results = await gather(*tasks)\n            success = all(results)\n        else:\n            self._log.info(_('not removing {0}: unhandled device', device))\n            success = False\n        # if these operations work, everything is fine, we can return True:\n        if lock and device.is_luks_cleartext:\n            device = device.luks_cleartext_slave\n            if self.is_handleable(device):\n                success = await self.lock(device)\n        if eject:\n            success = await self.eject(device)\n        if (detach or detach is None) and device.is_loop:\n            success = await self.delete(device, remove=False)\n        elif detach:\n            success = await self.detach(device)\n        return success", "response": "Remove the specified device."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nejects a device after unmounting all its mounted filesystems.", "response": "async def eject(self, device, force=False):\n        \"\"\"\n        Eject a device after unmounting all its mounted filesystems.\n\n        :param device: device object, block device path or mount path\n        :param bool force: remove child devices before trying to eject\n        :returns: whether the operation succeeded\n        \"\"\"\n        device = self._find_device(device)\n        if not self.is_handleable(device):\n            self._log.warn(_('not ejecting {0}: unhandled device'))\n            return False\n        drive = device.drive\n        if not (drive.is_drive and drive.is_ejectable):\n            self._log.warn(_('not ejecting {0}: drive not ejectable', drive))\n            return False\n        if force:\n            # Can't autoremove 'device.drive', because that will be filtered\n            # due to block=False:\n            await self.auto_remove(device.root, force=True)\n        self._log.debug(_('ejecting {0}', device))\n        await drive.eject()\n        self._log.info(_('ejected {0}', device))\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def detach(self, device, force=False):\n        device = self._find_device(device)\n        if not self.is_handleable(device):\n            self._log.warn(_('not detaching {0}: unhandled device', device))\n            return False\n        drive = device.root\n        if not drive.is_detachable:\n            self._log.warn(_('not detaching {0}: drive not detachable', drive))\n            return False\n        if force:\n            await self.auto_remove(drive, force=True)\n        self._log.debug(_('detaching {0}', device))\n        await drive.detach()\n        self._log.info(_('detached {0}', device))\n        return True", "response": "Detach a device after unmounting all its mounted filesystems."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def add_all(self, recursive=False):\n        tasks = [self.auto_add(device, recursive=recursive)\n                 for device in self.get_all_handleable_leaves()]\n        results = await gather(*tasks)\n        success = all(results)\n        return success", "response": "Add all handleable devices that available at start."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def remove_all(self, detach=False, eject=False, lock=False):\n        kw = dict(force=True, detach=detach, eject=eject, lock=lock)\n        tasks = [self.auto_remove(device, **kw)\n                 for device in self.get_all_handleable_roots()]\n        results = await gather(*tasks)\n        success = all(results)\n        return success", "response": "Remove all filesystems handleable by udiskie."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes the loop device.", "response": "async def delete(self, device, remove=True):\n        \"\"\"\n        Detach the loop device.\n\n        :param device: device object, block device path or mount path\n        :param bool remove: whether to unmount the partition etc.\n        :returns: whether the loop device is deleted\n        \"\"\"\n        device = self._find_device(device)\n        if not self.is_handleable(device) or not device.is_loop:\n            self._log.warn(_('not deleting {0}: unhandled device', device))\n            return False\n        if remove:\n            await self.auto_remove(device, force=True)\n        self._log.debug(_('deleting {0}', device))\n        await device.delete()\n        self._log.info(_('deleted {0}', device))\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck whether this device should be handled by udiskie.", "response": "def is_handleable(self, device):\n        # TODO: handle pathes in first argument\n        \"\"\"\n        Check whether this device should be handled by udiskie.\n\n        :param device: device object, block device path or mount path\n        :returns: handleability\n\n        Currently this just means that the device is removable and holds a\n        filesystem or the device is a LUKS encrypted volume.\n        \"\"\"\n        ignored = self._ignore_device(device)\n        # propagate handleability of parent devices:\n        if ignored is None and device is not None:\n            return self.is_handleable(_get_parent(device))\n        return not ignored"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_addable(self, device, automount=True):\n        if not self.is_automount(device, automount):\n            return False\n        if device.is_filesystem:\n            return not device.is_mounted\n        if device.is_crypto:\n            return self._prompt and not device.is_unlocked\n        if device.is_partition_table:\n            return any(self.is_addable(dev)\n                       for dev in self.get_all_handleable()\n                       if dev.partition_slave == device)\n        return False", "response": "Check if a device can be added with auto_add."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_removable(self, device):\n        if not self.is_handleable(device):\n            return False\n        if device.is_filesystem:\n            return device.is_mounted\n        if device.is_crypto:\n            return device.is_unlocked\n        if device.is_partition_table or device.is_drive:\n            return any(self.is_removable(dev)\n                       for dev in self.get_all_handleable()\n                       if _is_parent_of(device, dev))\n        return False", "response": "Check if the device can be removed with auto_remove."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_all_handleable(self):\n        nodes = self.get_device_tree()\n        return [node.device\n                for node in sorted(nodes.values(), key=DevNode._sort_key)\n                if not node.ignored and node.device]", "response": "Get list of all known handleable devices."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets list of all handleable devices return only those that represent root nodes within the filtered device tree.", "response": "def get_all_handleable_roots(self):\n        \"\"\"\n        Get list of all handleable devices, return only those that represent\n        root nodes within the filtered device tree.\n        \"\"\"\n        nodes = self.get_device_tree()\n        return [node.device\n                for node in sorted(nodes.values(), key=DevNode._sort_key)\n                if not node.ignored and node.device\n                and (node.root == '/' or nodes[node.root].ignored)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets list of all handleable devices return only those that represent leaf nodes within the filtered device tree.", "response": "def get_all_handleable_leaves(self):\n        \"\"\"\n        Get list of all handleable devices, return only those that represent\n        leaf nodes within the filtered device tree.\n        \"\"\"\n        nodes = self.get_device_tree()\n        return [node.device\n                for node in sorted(nodes.values(), key=DevNode._sort_key)\n                if not node.ignored and node.device\n                and all(child.ignored for child in node.children)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a tree of all devices.", "response": "def get_device_tree(self):\n        \"\"\"Get a tree of all devices.\"\"\"\n        root = DevNode(None, None, [], None)\n        device_nodes = {\n            dev.object_path: DevNode(dev, dev.parent_object_path, [],\n                                     self._ignore_device(dev))\n            for dev in self.udisks\n        }\n        for node in device_nodes.values():\n            device_nodes.get(node.root, root).children.append(node)\n        device_nodes['/'] = root\n        for node in device_nodes.values():\n            node.children.sort(key=DevNode._sort_key)\n\n        # use parent as fallback, update top->down:\n        def propagate_ignored(node):\n            for child in node.children:\n                if child.ignored is None:\n                    child.ignored = node.ignored\n                propagate_ignored(child)\n        propagate_ignored(root)\n        return device_nodes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndetect all currently known devices.", "response": "def detect(self, root_device='/'):\n        \"\"\"\n        Detect all currently known devices.\n\n        :param str root_device: object path of root device to return\n        :returns: root node of device hierarchy\n        \"\"\"\n        root = Device(None, [], None, \"\", [])\n        device_nodes = dict(map(self._device_node,\n                                self._mounter.get_all_handleable()))\n        # insert child devices as branches into their roots:\n        for node in device_nodes.values():\n            device_nodes.get(node.root, root).branches.append(node)\n        device_nodes['/'] = root\n        for node in device_nodes.values():\n            node.branches.sort(key=lambda node: node.label)\n        return device_nodes[root_device]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning an iterable over all available methods the device has.", "response": "def _get_device_methods(self, device):\n        \"\"\"Return an iterable over all available methods the device has.\"\"\"\n        if device.is_filesystem:\n            if device.is_mounted:\n                if self._mounter._browser:\n                    yield 'browse'\n                if self._mounter._terminal:\n                    yield 'terminal'\n                yield 'unmount'\n            else:\n                yield 'mount'\n        elif device.is_crypto:\n            if device.is_unlocked:\n                yield 'lock'\n            else:\n                yield 'unlock'\n            cache = self._mounter._cache\n            if cache and device in cache:\n                yield 'forget_password'\n        if device.is_ejectable and device.has_media:\n            yield 'eject'\n        if device.is_detachable:\n            yield 'detach'\n        if device.is_loop:\n            yield 'delete'"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _device_node(self, device):\n        label = device.ui_label\n        dev_label = device.ui_device_label\n        # determine available methods\n        methods = [Action(method, device,\n                          self._labels[method].format(label, dev_label),\n                          partial(self._actions[method], device))\n                   for method in self._get_device_methods(device)]\n        # find the root device:\n        root = device.parent_object_path\n        # in this first step leave branches empty\n        return device.object_path, Device(root, [], device, dev_label, methods)", "response": "Create an empty menu node for the specified device."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef samefile(a: str, b: str) -> bool:\n    try:\n        return os.path.samefile(a, b)\n    except OSError:\n        return os.path.normpath(a) == os.path.normpath(b)", "response": "Check if two paths represent the same file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlikes update but values in self take priority.", "response": "def setdefault(self: dict, other: dict):\n    \"\"\"Like .update() but values in self take priority.\"\"\"\n    for k, v in other.items():\n        self.setdefault(k, v)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef extend(a: dict, b: dict) -> dict:\n    res = a.copy()\n    res.update(b)\n    return res", "response": "Merge two dicts and return a new dict. Much like subclassing works works."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cachedproperty(func):\n    key = '_' + func.__name__\n    @wraps(func)\n    def get(self):\n        try:\n            return getattr(self, key)\n        except AttributeError:\n            val = func(self)\n            setattr(self, key, val)\n            return val\n    return property(get)", "response": "A memoize decorator for class properties."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert binary blob from DBus queries to strings.", "response": "def decode_ay(ay):\n    \"\"\"Convert binary blob from DBus queries to strings.\"\"\"\n    if ay is None:\n        return ''\n    elif isinstance(ay, str):\n        return ay\n    elif isinstance(ay, bytes):\n        return ay.decode('utf-8')\n    else:\n        # dbus.Array([dbus.Byte]) or any similar sequence type:\n        return bytearray(ay).rstrip(bytearray((0,))).decode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef format_exc(*exc_info):\n    typ, exc, tb = exc_info or sys.exc_info()\n    error = traceback.format_exception(typ, exc, tb)\n    return \"\".join(error)", "response": "Show exception with traceback."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntriggers an event by name.", "response": "def trigger(self, event, *args):\n        \"\"\"Trigger event by name.\"\"\"\n        for handler in self._event_handlers[event]:\n            handler(*args)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _check(self, args):\n        if sum(bool(args[arg]) for arg in self._mapping) > 1:\n            raise DocoptExit(_('These options are mutually exclusive: {0}',\n                               ', '.join(self._mapping)))", "response": "Exit in case of multiple exclusive arguments."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget program options from docopt parsed options.", "response": "def program_options(self, args):\n        \"\"\"Get program options from docopt parsed options.\"\"\"\n        options = {}\n        for name, rule in self.option_rules.items():\n            val = rule(args)\n            if val is not None:\n                options[name] = val\n        return options"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nruns the main loop. Returns exit code.", "response": "def run(self):\n        \"\"\"Run the main loop. Returns exit code.\"\"\"\n        self.exit_code = 1\n        self.mainloop = GLib.MainLoop()\n        try:\n            future = ensure_future(self._start_async_tasks())\n            future.callbacks.append(self.set_exit_code)\n            self.mainloop.run()\n            return self.exit_code\n        except KeyboardInterrupt:\n            return 1"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmounting newly mountable devices.", "response": "def device_changed(self, old_state, new_state):\n        \"\"\"Mount newly mountable devices.\"\"\"\n        # udisks2 sometimes adds empty devices and later updates them - which\n        # makes is_external become true at a time later than device_added:\n        if (self._mounter.is_addable(new_state)\n                and not self._mounter.is_addable(old_state)\n                and not self._mounter.is_removable(old_state)):\n            self.auto_add(new_state)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def call(proxy, method_name, signature, args, flags=0, timeout_msec=-1):\n    future = Future()\n    cancellable = None\n    proxy.call(\n        method_name,\n        GLib.Variant(signature, tuple(args)),\n        flags,\n        timeout_msec,\n        cancellable,\n        gio_callback,\n        future,\n    )\n    result = await future\n    value = proxy.call_finish(result)\n    return pack(*unpack_variant(value))", "response": "Asynchronously call a method on a DBus object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def proxy_new(connection, flags, info, name, object_path, interface_name):\n    future = Future()\n    cancellable = None\n    Gio.DBusProxy.new(\n        connection,\n        flags,\n        info,\n        name,\n        object_path,\n        interface_name,\n        cancellable,\n        gio_callback,\n        future,\n    )\n    result = await future\n    value = Gio.DBusProxy.new_finish(result)\n    if value is None:\n        raise RuntimeError(\"Failed to connect DBus object!\")\n    return value", "response": "Asynchronously call the specified method on a DBus proxy object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def connect_service(bus_name, object_path, interface):\n    proxy = await proxy_new_for_bus(\n        Gio.BusType.SYSTEM,\n        Gio.DBusProxyFlags.DO_NOT_LOAD_PROPERTIES |\n        Gio.DBusProxyFlags.DO_NOT_CONNECT_SIGNALS,\n        info=None,\n        name=bus_name,\n        object_path=object_path,\n        interface_name=interface,\n    )\n    return InterfaceProxy(proxy)", "response": "Connect to the service object on DBus."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting an ObjectProxy instanec for the underlying object.", "response": "def object(self):\n        \"\"\"Get an ObjectProxy instanec for the underlying object.\"\"\"\n        proxy = self._proxy\n        return ObjectProxy(proxy.get_connection(),\n                           proxy.get_name(),\n                           proxy.get_object_path())"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconnects to a DBus signal returns subscription id", "response": "def connect(self, event, handler):\n        \"\"\"Connect to a DBus signal, returns subscription id (int).\"\"\"\n        interface = self._proxy.get_interface_name()\n        return self.object.connect(interface, event, handler)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a Future ( Gio. DBusProxy for the specified interface.", "response": "def _get_interface(self, name):\n        \"\"\"Get a Future(Gio.DBusProxy) for the specified interface.\"\"\"\n        return proxy_new(\n            self.connection,\n            Gio.DBusProxyFlags.DO_NOT_LOAD_PROPERTIES |\n            Gio.DBusProxyFlags.DO_NOT_CONNECT_SIGNALS,\n            info=None,\n            name=self.bus_name,\n            object_path=self.object_path,\n            interface_name=name,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef connect(self, interface, event, handler):\n        object_path = self.object_path\n        return self.bus.connect(interface, event, object_path, handler)", "response": "Connect to a DBus signal. Returns the subscription id."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconnect to a DBus signal.", "response": "def connect(self, interface, event, object_path, handler):\n        \"\"\"\n        Connect to a DBus signal. If ``object_path`` is None, subscribe for\n        all objects and invoke the callback with the object_path as its first\n        argument.\n        \"\"\"\n        if object_path:\n            def callback(connection, sender_name, object_path,\n                         interface_name, signal_name, parameters):\n                return handler(*unpack_variant(parameters))\n        else:\n            def callback(connection, sender_name, object_path,\n                         interface_name, signal_name, parameters):\n                return handler(object_path, *unpack_variant(parameters))\n        return self.connection.signal_subscribe(\n            self.bus_name,\n            interface,\n            event,\n            object_path,\n            None,\n            Gio.DBusSignalFlags.NONE,\n            callback,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef require_Gtk(min_version=2):\n    if not _in_X:\n        raise RuntimeError('Not in X session.')\n    if _has_Gtk < min_version:\n        raise RuntimeError('Module gi.repository.Gtk not available!')\n    if _has_Gtk == 2:\n        logging.getLogger(__name__).warn(\n            _(\"Missing runtime dependency GTK 3. Falling back to GTK 2 \"\n              \"for password prompt\"))\n    from gi.repository import Gtk\n    # if we attempt to create any GUI elements with no X server running the\n    # program will just crash, so let's make a way to catch this case:\n    if not Gtk.init_check(None)[0]:\n        raise RuntimeError(_(\"X server not connected!\"))\n    return Gtk", "response": "Require Gtk to be initialized."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _(text, *args, **kwargs):\n    msg = _t.gettext(text)\n    if args or kwargs:\n        return msg.format(*args, **kwargs)\n    else:\n        return msg", "response": "Translate and then and format the text with str. format."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves None values from a dictionary.", "response": "def filter_opt(opt):\n    \"\"\"Remove ``None`` values from a dictionary.\"\"\"\n    return {k: GLib.Variant(*v) for k, v in opt.items() if v[1] is not None}"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef eject(self, auth_no_user_interaction=None):\n        return self._assocdrive._M.Drive.Eject(\n            '(a{sv})',\n            filter_opt({\n                'auth.no_user_interaction': ('b', auth_no_user_interaction),\n            })\n        )", "response": "Eject media from the device."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef detach(self, auth_no_user_interaction=None):\n        return self._assocdrive._M.Drive.PowerOff(\n            '(a{sv})',\n            filter_opt({\n                'auth.no_user_interaction': ('b', auth_no_user_interaction),\n            })\n        )", "response": "Detach the device by e. g. powering down the physical port."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef device_id(self):\n        if self.is_block:\n            for filename in self._P.Block.Symlinks:\n                parts = decode_ay(filename).split('/')\n                if parts[-2] == 'by-id':\n                    return parts[-1]\n        elif self.is_drive:\n            return self._assocdrive._P.Drive.Id\n        return ''", "response": "Return a unique and persistent identifier for the device."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if the device is external.", "response": "def is_external(self):\n        \"\"\"Check if the device is external.\"\"\"\n        # NOTE: Checking for equality HintSystem==False returns False if the\n        # property is resolved to a None value (interface not available).\n        if self._P.Block.HintSystem == False:       # noqa: E712\n            return True\n        # NOTE: udisks2 seems to guess incorrectly in some cases. This\n        # leads to HintSystem=True for unlocked devices. In order to show\n        # the device anyway, it needs to be recursively checked if any\n        # parent device is recognized as external.\n        if self.is_luks_cleartext and self.luks_cleartext_slave.is_external:\n            return True\n        if self.is_partition and self.partition_slave.is_external:\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting wrapper to the drive containing this device.", "response": "def drive(self):\n        \"\"\"Get wrapper to the drive containing this device.\"\"\"\n        if self.is_drive:\n            return self\n        cleartext = self.luks_cleartext_slave\n        if cleartext:\n            return cleartext.drive\n        if self.is_block:\n            return self._daemon[self._P.Block.Drive]\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef root(self):\n        drive = self.drive\n        for device in self._daemon:\n            if device.is_drive:\n                continue\n            if device.is_toplevel and device.drive == drive:\n                return device\n        return None", "response": "Get the top level block device in the ancestry of this device."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef symlinks(self):\n        if not self._P.Block.Symlinks:\n            return []\n        return [decode_ay(path) for path in self._P.Block.Symlinks]", "response": "Return a list of symlinks of the block device."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef luks_cleartext_holder(self):\n        if not self.is_luks:\n            return None\n        for device in self._daemon:\n            if device.luks_cleartext_slave == self:\n                return device\n        return None", "response": "Get wrapper to the unlocked luks cleartext device."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset autoclear flag for loop partition.", "response": "def set_autoclear(self, value, auth_no_user_interaction=None):\n        \"\"\"Set autoclear flag for loop partition.\"\"\"\n        return self._M.Loop.SetAutoclear(\n            '(ba{sv})',\n            value,\n            filter_opt({\n                'auth.no_user_interaction': ('b', auth_no_user_interaction),\n            })\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks whether this device is in use i. e. mounted or unlocked.", "response": "def in_use(self):\n        \"\"\"Check whether this device is in use, i.e. mounted or unlocked.\"\"\"\n        if self.is_mounted or self.is_unlocked:\n            return True\n        if self.is_partition_table:\n            for device in self._daemon:\n                if device.partition_slave == self and device.in_use:\n                    return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ui_device_label(self):\n        return ': '.join(filter(None, [\n            self.ui_device_presentation,\n            self.loop_file or\n            self.drive_label or self.ui_id_label or self.ui_id_uuid\n        ]))", "response": "UI string identifying the device."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds a device proxy by path.", "response": "def find(self, path):\n        \"\"\"\n        Get a device proxy by device name or any mount path of the device.\n\n        This searches through all accessible devices and compares device\n        path as well as mount pathes.\n        \"\"\"\n        if isinstance(path, Device):\n            return path\n        for device in self:\n            if device.is_file(path):\n                self._log.debug(_('found device owning \"{0}\": \"{1}\"',\n                                  path, device))\n                return device\n        raise FileNotFoundError(_('no device found owning \"{0}\"', path))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, object_path, interfaces_and_properties=None):\n        # check this before creating the DBus object for more\n        # controlled behaviour:\n        if not interfaces_and_properties:\n            interfaces_and_properties = self._objects.get(object_path)\n            if not interfaces_and_properties:\n                return None\n        property_hub = PropertyHub(interfaces_and_properties)\n        method_hub = MethodHub(\n            self._proxy.object.bus.get_object(object_path))\n        return Device(self, object_path, property_hub, method_hub)", "response": "Create a Device instance from object path."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalls when a job has completed.", "response": "def _job_completed(self, job_name, success, message):\n        \"\"\"\n        Internal method.\n\n        Called when a job of a long running task completes.\n        \"\"\"\n        job = self._objects[job_name][Interface['Job']]\n        action = self._action_by_operation.get(job['Operation'])\n        if not action:\n            return\n        # We only handle events, which are associated to exactly one object:\n        object_path, = job['Objects']\n        device = self[object_path]\n        if success:\n            # It rarely happens, but sometimes UDisks posts the\n            # Job.Completed event before PropertiesChanged, so we have to\n            # check if the operation has been carried out yet:\n            if self._check_action_success[action](device):\n                event_name = self._event_by_action[action]\n                self.trigger(event_name, device)\n        else:\n            self.trigger('job_failed', device, action, message)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nshowing mount notification for specified device object.", "response": "def device_mounted(self, device):\n        \"\"\"Show mount notification for specified device object.\"\"\"\n        if not self._mounter.is_handleable(device):\n            return\n        browse_action = ('browse', _('Browse directory'),\n                         self._mounter.browse, device)\n        terminal_action = ('terminal', _('Open terminal'),\n                           self._mounter.terminal, device)\n        self._show_notification(\n            'device_mounted',\n            _('Device mounted'),\n            _('{0.ui_label} mounted on {0.mount_paths[0]}', device),\n            device.icon_name,\n            self._mounter._browser and browse_action,\n            self._mounter._terminal and terminal_action)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef device_unmounted(self, device):\n        if not self._mounter.is_handleable(device):\n            return\n        self._show_notification(\n            'device_unmounted',\n            _('Device unmounted'),\n            _('{0.ui_label} unmounted', device),\n            device.icon_name)", "response": "Show unmount notification for specified device object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nshow lock notification for specified device object.", "response": "def device_locked(self, device):\n        \"\"\"Show lock notification for specified device object.\"\"\"\n        if not self._mounter.is_handleable(device):\n            return\n        self._show_notification(\n            'device_locked',\n            _('Device locked'),\n            _('{0.device_presentation} locked', device),\n            device.icon_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nshows unlock notification for specified device object.", "response": "def device_unlocked(self, device):\n        \"\"\"Show unlock notification for specified device object.\"\"\"\n        if not self._mounter.is_handleable(device):\n            return\n        self._show_notification(\n            'device_unlocked',\n            _('Device unlocked'),\n            _('{0.device_presentation} unlocked', device),\n            device.icon_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nshows discovery notification for specified device object.", "response": "def device_added(self, device):\n        \"\"\"Show discovery notification for specified device object.\"\"\"\n        if not self._mounter.is_handleable(device):\n            return\n        if self._has_actions('device_added'):\n            # wait for partitions etc to be reported to udiskie, otherwise we\n            # can't discover the actions\n            GLib.timeout_add(500, self._device_added, device)\n        else:\n            self._device_added(device)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nshows removal notification for specified device object.", "response": "def device_removed(self, device):\n        \"\"\"Show removal notification for specified device object.\"\"\"\n        if not self._mounter.is_handleable(device):\n            return\n        device_file = device.device_presentation\n        if (device.is_drive or device.is_toplevel) and device_file:\n            self._show_notification(\n                'device_removed',\n                _('Device removed'),\n                _('device disappeared on {0.device_presentation}', device),\n                device.icon_name)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nshowing Job failed notification with Retry button.", "response": "def job_failed(self, device, action, message):\n        \"\"\"Show 'Job failed' notification with 'Retry' button.\"\"\"\n        if not self._mounter.is_handleable(device):\n            return\n        device_file = device.device_presentation or device.object_path\n        if message:\n            text = _('failed to {0} {1}:\\n{2}', action, device_file, message)\n        else:\n            text = _('failed to {0} device {1}.', action, device_file)\n        try:\n            retry = getattr(self._mounter, action)\n        except AttributeError:\n            retry_action = None\n        else:\n            retry_action = ('retry', _('Retry'), retry, device)\n        self._show_notification(\n            'job_failed',\n            _('Job failed'), text,\n            device.icon_name,\n            retry_action)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nshow a notification. :param str event: event name :param str summary: notification title :param str message: notification body :param str icon: icon name :param actions: each item is a tuple with parameters for _add_action", "response": "def _show_notification(self,\n                           event, summary, message, icon,\n                           *actions):\n        \"\"\"\n        Show a notification.\n\n        :param str event: event name\n        :param str summary: notification title\n        :param str message: notification body\n        :param str icon: icon name\n        :param actions: each item is a tuple with parameters for _add_action\n        \"\"\"\n        notification = self._notify(summary, message, icon)\n        timeout = self._get_timeout(event)\n        if timeout != -1:\n            notification.set_timeout(int(timeout * 1000))\n        for action in actions:\n            if action and self._action_enabled(event, action[0]):\n                self._add_action(notification, *action)\n        try:\n            notification.show()\n        except GLib.GError as exc:\n            # Catch and log the exception. Starting udiskie with notifications\n            # enabled while not having a notification service installed is a\n            # mistake too easy to be made, but it shoud not render the rest of\n            # udiskie's logic useless by raising an exception before the\n            # automount handler gets invoked.\n            self._log.error(_(\"Failed to show notification: {0}\", exc_message(exc)))\n            self._log.debug(format_exc())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd an action button to the mount notifications.", "response": "def _add_action(self, notification, action, label, callback, *args):\n        \"\"\"\n        Show an action button button in mount notifications.\n\n        Note, this only works with some libnotify services.\n        \"\"\"\n        on_action_click = run_bg(lambda *_: callback(*args))\n        try:\n            # this is the correct signature for Notify-0.7, the last argument\n            # being 'user_data':\n            notification.add_action(action, label, on_action_click, None)\n        except TypeError:\n            # this is the signature for some older version, I don't know what\n            # the last argument is for.\n            notification.add_action(action, label, on_action_click, None, None)\n        # gi.Notify does not store hard references to the notification\n        # objects. When a signal is received and the notification does not\n        # exist anymore, no handler will be called. Therefore, we need to\n        # prevent these notifications from being destroyed by storing\n        # references:\n        notification.connect('closed', self._notifications.remove)\n        self._notifications.append(notification)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if an action for a notification is enabled.", "response": "def _action_enabled(self, event, action):\n        \"\"\"Check if an action for a notification is enabled.\"\"\"\n        event_actions = self._aconfig.get(event)\n        if event_actions is None:\n            return True\n        if event_actions is False:\n            return False\n        return action in event_actions"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _has_actions(self, event):\n        event_actions = self._aconfig.get(event)\n        return event_actions is None or bool(event_actions)", "response": "Check if a notification type has any enabled actions."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmatch devices against multiple DeviceFilter s.", "response": "def match_config(filters, device, kind, default):\n    \"\"\"\n    Matches devices against multiple :class:`DeviceFilter`s.\n\n    :param list filters: device filters\n    :param Device device: device to be mounted\n    :param str kind: value kind\n    :param default: default value\n    :returns: value of the first matching filter\n    \"\"\"\n    if device is None:\n        return default\n    matches = (f.value(kind, device)\n               for f in filters\n               if f.has_value(kind) and f.match(device))\n    return next(matches, default)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if the device object matches this filter.", "response": "def match(self, device):\n        \"\"\"Check if the device object matches this filter.\"\"\"\n        return all(match_value(getattr(device, k), v)\n                   for k, v in self._match.items())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the value for the given kind of object.", "response": "def value(self, kind, device):\n        \"\"\"\n        Get the value for the device object associated with this filter.\n\n        If :meth:`match` is False for the device, the return value of this\n        method is undefined.\n        \"\"\"\n        self._log.debug(_('{0}(match={1!r}, {2}={3!r}) used for {4}',\n                          self.__class__.__name__,\n                          self._match,\n                          kind, self._values[kind],\n                          device.object_path))\n        return self._values[kind]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the default config file pathes as a list.", "response": "def default_pathes(cls):\n        \"\"\"Return the default config file pathes as a list.\"\"\"\n        try:\n            from xdg.BaseDirectory import xdg_config_home as config_home\n        except ImportError:\n            config_home = os.path.expanduser('~/.config')\n        return [os.path.join(config_home, 'udiskie', 'config.yml'),\n                os.path.join(config_home, 'udiskie', 'config.json')]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_file(cls, path=None):\n        # None => use default\n        if path is None:\n            for path in cls.default_pathes():\n                try:\n                    return cls.from_file(path)\n                except IOError as e:\n                    logging.getLogger(__name__).debug(\n                        _(\"Failed to read config file: {0}\", exc_message(e)))\n                except ImportError as e:\n                    logging.getLogger(__name__).warn(\n                        _(\"Failed to read {0!r}: {1}\", path, exc_message(e)))\n            return cls({})\n        # False/'' => no config\n        if not path:\n            return cls({})\n        if os.path.splitext(path)[1].lower() == '.json':\n            from json import load\n        else:\n            from yaml import safe_load as load\n        with open(path) as f:\n            return cls(load(f))", "response": "Read YAML config file. Returns Config object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads Gtk. Image from udiskie - internal id.", "response": "def get_icon(self, icon_id: str, size: \"Gtk.IconSize\") -> \"Gtk.Image\":\n        \"\"\"Load Gtk.Image from udiskie-internal id.\"\"\"\n        return Gtk.Image.new_from_gicon(self.get_gicon(icon_id), size)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_gicon(self, icon_id: str) -> \"Gio.Icon\":\n        return Gio.ThemedIcon.new_from_names(self._icon_names[icon_id])", "response": "Lookup Gio. Icon from udiskie - internal id."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds configuration options to the menu.", "response": "def _insert_options(self, menu):\n        \"\"\"Add configuration options to menu.\"\"\"\n        menu.append(Gtk.SeparatorMenuItem())\n        menu.append(self._menuitem(\n            _('Mount disc image'),\n            self._icons.get_icon('losetup', Gtk.IconSize.MENU),\n            run_bg(lambda _: self._losetup())\n        ))\n        menu.append(Gtk.SeparatorMenuItem())\n        menu.append(self._menuitem(\n            _(\"Enable automounting\"),\n            icon=None,\n            onclick=lambda _: self._daemon.automounter.toggle_on(),\n            checked=self._daemon.automounter.is_on(),\n        ))\n        menu.append(self._menuitem(\n            _(\"Enable notifications\"),\n            icon=None,\n            onclick=lambda _: self._daemon.notify.toggle(),\n            checked=self._daemon.notify.active,\n        ))\n        # append menu item for closing the application\n        if self._quit_action:\n            menu.append(Gtk.SeparatorMenuItem())\n            menu.append(self._menuitem(\n                _('Quit'),\n                self._icons.get_icon('quit', Gtk.IconSize.MENU),\n                lambda _: self._quit_action()\n            ))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef detect(self):\n        root = self._actions.detect()\n        prune_empty_node(root, set())\n        return root", "response": "Detect all currently known devices. Returns the root device."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a menu from the given node.", "response": "def _create_menu(self, items):\n        \"\"\"\n        Create a menu from the given node.\n\n        :param list items: list of menu items\n        :returns: a new Gtk.Menu object holding all items of the node\n        \"\"\"\n        menu = Gtk.Menu()\n        self._create_menu_items(menu, items)\n        return menu"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a generic menu item.", "response": "def _menuitem(self, label, icon, onclick, checked=None):\n        \"\"\"\n        Create a generic menu item.\n\n        :param str label: text\n        :param Gtk.Image icon: icon (may be ``None``)\n        :param onclick: onclick handler, either a callable or Gtk.Menu\n        :returns: the menu item object\n        :rtype: Gtk.MenuItem\n        \"\"\"\n        if checked is not None:\n            item = Gtk.CheckMenuItem()\n            item.set_active(checked)\n        elif icon is None:\n            item = Gtk.MenuItem()\n        else:\n            item = Gtk.ImageMenuItem()\n            item.set_image(icon)\n            # I don't really care for the \"show icons only for nouns, not\n            # for verbs\" policy:\n            item.set_always_show_image(True)\n        if label is not None:\n            item.set_label(label)\n        if isinstance(onclick, Gtk.Menu):\n            item.set_submenu(onclick)\n        elif onclick is not None:\n            item.connect('activate', onclick)\n        return item"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprepares the menu hierarchy from the given device tree.", "response": "def _prepare_menu(self, node, flat=None):\n        \"\"\"\n        Prepare the menu hierarchy from the given device tree.\n\n        :param Device node: root node of device hierarchy\n        :returns: menu hierarchy as list\n        \"\"\"\n        if flat is None:\n            flat = self.flat\n        ItemGroup = MenuSection if flat else SubMenu\n        return [\n            ItemGroup(branch.label, self._collapse_device(branch, flat))\n            for branch in node.branches\n            if branch.methods or branch.branches\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncollapse device hierarchy into a flat folder.", "response": "def _collapse_device(self, node, flat):\n        \"\"\"Collapse device hierarchy into a flat folder.\"\"\"\n        items = [item\n                 for branch in node.branches\n                 for item in self._collapse_device(branch, flat)\n                 if item]\n        show_all = not flat or self._quickmenu_actions == 'all'\n        methods = node.methods if show_all else [\n            method\n            for method in node.methods\n            if method.method in self._quickmenu_actions\n        ]\n        if flat:\n            items.extend(methods)\n        else:\n            items.append(MenuSection(None, methods))\n        return items"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a new Gtk. StatusIcon object.", "response": "def _create_statusicon(self):\n        \"\"\"Return a new Gtk.StatusIcon.\"\"\"\n        statusicon = Gtk.StatusIcon()\n        statusicon.set_from_gicon(self._icons.get_gicon('media'))\n        statusicon.set_tooltip_text(_(\"udiskie\"))\n        return statusicon"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nshows or hide the tray icon.", "response": "def show(self, show=True):\n        \"\"\"Show or hide the tray icon.\"\"\"\n        if show and not self.visible:\n            self._show()\n        if not show and self.visible:\n            self._hide()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _show(self):\n        if not self._icon:\n            self._icon = self._create_statusicon()\n        widget = self._icon\n        widget.set_visible(True)\n        self._conn_left = widget.connect(\"activate\", self._activate)\n        self._conn_right = widget.connect(\"popup-menu\", self._popup_menu)", "response": "Show the tray icon."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _hide(self):\n        self._icon.set_visible(False)\n        self._icon.disconnect(self._conn_left)\n        self._icon.disconnect(self._conn_right)\n        self._conn_left = None\n        self._conn_right = None", "response": "Hide the tray icon."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate the context menu.", "response": "def create_context_menu(self, extended):\n        \"\"\"Create the context menu.\"\"\"\n        menu = Gtk.Menu()\n        self._menu(menu, extended)\n        return menu"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nhandle a left click event ( show the menu", "response": "def _activate(self, icon):\n        \"\"\"Handle a left click event (show the menu).\"\"\"\n        self._popup_menu(icon, button=0, time=Gtk.get_current_event_time(),\n                         extended=False)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nhandling a right click event ( show the menu", "response": "def _popup_menu(self, icon, button, time, extended=True):\n        \"\"\"Handle a right click event (show the menu).\"\"\"\n        m = self.create_context_menu(extended)\n        m.show_all()\n        m.popup(parent_menu_shell=None,\n                parent_menu_item=None,\n                func=icon.position_menu,\n                data=icon,\n                button=button,\n                activate_time=time)\n        # need to store reference or menu will be destroyed before showing:\n        self._m = m"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nshowing or hide icon depending on whether there are devices.", "response": "def update(self, *args):\n        \"\"\"Show/hide icon depending on whether there are devices.\"\"\"\n        if self.smart:\n            self._icon.show(self.has_menu())\n        else:\n            self._icon.show(True)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def password_dialog(key, title, message, options):\n    with PasswordDialog.create(key, title, message, options) as dialog:\n        response = await dialog\n        if response == Gtk.ResponseType.OK:\n            return PasswordResult(dialog.get_text(),\n                                  dialog.use_cache.get_active())\n        return None", "response": "Show a Gtk password dialog."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_password_gui(device, options):\n    text = _('Enter password for {0.device_presentation}: ', device)\n    try:\n        return password_dialog(device.id_uuid, 'udiskie', text, options)\n    except RuntimeError:\n        return None", "response": "Get the password to unlock a device from GUI."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the password to unlock a device from terminal.", "response": "async def get_password_tty(device, options):\n    \"\"\"Get the password to unlock a device from terminal.\"\"\"\n    # TODO: make this a TRUE async\n    text = _('Enter password for {0.device_presentation}: ', device)\n    try:\n        return getpass.getpass(text)\n    except EOFError:\n        print(\"\")\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a password prompt function.", "response": "def password(password_command):\n    \"\"\"Create a password prompt function.\"\"\"\n    gui = lambda: has_Gtk() and get_password_gui\n    tty = lambda: sys.stdin.isatty() and get_password_tty\n    if password_command == 'builtin:gui':\n        return gui() or tty()\n    elif password_command == 'builtin:tty':\n        return tty() or gui()\n    elif password_command:\n        return DeviceCommand(password_command).password\n    else:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a browse - directory function.", "response": "def browser(browser_name='xdg-open'):\n\n    \"\"\"Create a browse-directory function.\"\"\"\n\n    if not browser_name:\n        return None\n    argv = shlex.split(browser_name)\n    executable = find_executable(argv[0])\n    if executable is None:\n        # Why not raise an exception? -I think it is more convenient (for\n        # end users) to have a reasonable default, without enforcing it.\n        logging.getLogger(__name__).warn(\n            _(\"Can't find file browser: {0!r}. \"\n              \"You may want to change the value for the '-f' option.\",\n              browser_name))\n        return None\n\n    def browse(path):\n        return subprocess.Popen(argv + [path])\n\n    return browse"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef notify_command(command_format, mounter):\n    udisks = mounter.udisks\n    for event in ['device_mounted', 'device_unmounted',\n                  'device_locked', 'device_unlocked',\n                  'device_added', 'device_removed',\n                  'job_failed']:\n        udisks.connect(event, run_bg(DeviceCommand(command_format, event=event)))", "response": "Command notification tool.\n\n    This works similar to Notify, but will issue command instead of showing\n    the notifications on the desktop. This can then be used to react to events\n    from shell scripts.\n\n    The command can contain modern pythonic format placeholders like:\n    {device_file}. The following placeholders are supported:\n    event, device_file, device_id, device_size, drive, drive_label, id_label,\n    id_type, id_usage, id_uuid, mount_path, root\n\n    :param str command_format: command to run when an event occurs.\n    :param mounter: Mounter object"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make_mo(self, po_filename, mo_filename):\n        try:\n            call(['msgfmt', po_filename, '-o', mo_filename])\n        except OSError as e:\n            # ignore failures since i18n support is optional:\n            logging.warning(e)", "response": "Create a machine object from a portable object file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run(self):\n        orig_install.run(self)\n        try:\n            call(['gtk-update-icon-cache', 'share/icons/hicolor'])\n        except OSError as e:\n            # ignore failures since the tray icon is an optional component:\n            logging.warning(e)", "response": "Perform old - style install then update GTK icon cache."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreceiving a result from a single subtask.", "response": "def _subtask_result(self, idx, value):\n        \"\"\"Receive a result from a single subtask.\"\"\"\n        self._results[idx] = value\n        if len(self._results) == self._num_tasks:\n            self.set_result([\n                self._results[i]\n                for i in range(self._num_tasks)\n            ])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _subtask_error(self, idx, error):\n        self.set_exception(error)\n        self.errbacks.clear()", "response": "Receive an error from a single subtask."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _resume(self, func, *args):\n        try:\n            value = func(*args)\n        except StopIteration:\n            self._generator.close()\n            self.set_result(None)\n        except Exception as e:\n            self._generator.close()\n            self.set_exception(e)\n        else:\n            assert isinstance(value, Future)\n            value.callbacks.append(partial(self._resume, self._generator.send))\n            value.errbacks.append(partial(self._resume, self._generator.throw))", "response": "Resume the coroutine by throwing a value or returning a value from\n            the await and handle further awaits."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse a commit message according to the 1. 0 version of python - semantic - release.", "response": "def parse_commit_message(message: str) -> Tuple[int, str, Optional[str], Tuple[str, str, str]]:\n    \"\"\"\n    Parses a commit message according to the 1.0 version of python-semantic-release. It expects\n    a tag of some sort in the commit message and will use the rest of the first line as changelog\n    content.\n\n    :param message: A string of a commit message.\n    :raises UnknownCommitMessageStyleError: If it does not recognise the commit style\n    :return: A tuple of (level to bump, type of change, scope of change, a tuple with descriptions)\n    \"\"\"\n\n    parsed = re_parser.match(message)\n\n    if not parsed:\n        raise UnknownCommitMessageStyleError(\n            'Unable to parse the given commit message: {0}'.format(message)\n        )\n\n    subject = parsed.group('subject')\n\n    if config.get('semantic_release', 'minor_tag') in message:\n        level = 'feature'\n        level_bump = 2\n        if subject:\n            subject = subject.replace(config.get('semantic_release', 'minor_tag'.format(level)), '')\n\n    elif config.get('semantic_release', 'fix_tag') in message:\n        level = 'fix'\n        level_bump = 1\n        if subject:\n            subject = subject.replace(config.get('semantic_release', 'fix_tag'.format(level)), '')\n\n    else:\n        raise UnknownCommitMessageStyleError(\n            'Unable to parse the given commit message: {0}'.format(message)\n        )\n\n    if parsed.group('text') and 'BREAKING CHANGE' in parsed.group('text'):\n        level = 'breaking'\n        level_bump = 3\n\n    body, footer = parse_text_block(parsed.group('text'))\n\n    return level_bump, level, None, (subject.strip(), body.strip(), footer.strip())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef checker(func: Callable) -> Callable:\n\n    def func_wrapper(*args, **kwargs):\n        try:\n            func(*args, **kwargs)\n            return True\n        except AssertionError:\n            raise CiVerificationError(\n                'The verification check for the environment did not pass.'\n            )\n\n    return func_wrapper", "response": "A decorator that will convert AssertionErrors into CiVerificationError."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef travis(branch: str):\n    assert os.environ.get('TRAVIS_BRANCH') == branch\n    assert os.environ.get('TRAVIS_PULL_REQUEST') == 'false'", "response": "Checks that the environment is in the Travis branch."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks that the semaphore build is successful.", "response": "def semaphore(branch: str):\n    \"\"\"\n    Performs necessary checks to ensure that the semaphore build is successful,\n    on the correct branch and not a pull-request.\n\n    :param branch:  The branch the environment should be running against.\n    \"\"\"\n    assert os.environ.get('BRANCH_NAME') == branch\n    assert os.environ.get('PULL_REQUEST_NUMBER') is None\n    assert os.environ.get('SEMAPHORE_THREAD_RESULT') != 'failed'"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef frigg(branch: str):\n    assert os.environ.get('FRIGG_BUILD_BRANCH') == branch\n    assert not os.environ.get('FRIGG_PULL_REQUEST')", "response": "Checks that the frigg build is one of the required environment variables."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef circle(branch: str):\n    assert os.environ.get('CIRCLE_BRANCH') == branch\n    assert not os.environ.get('CI_PULL_REQUEST')", "response": "Checks that the environment is in the circle build environment."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bitbucket(branch: str):\n    assert os.environ.get('BITBUCKET_BRANCH') == branch\n    assert not os.environ.get('BITBUCKET_PR_ID')", "response": "Checks that the bitbucket build is one of the branches in the environment that the environment should be run against."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef check(branch: str = 'master'):\n    if os.environ.get('TRAVIS') == 'true':\n        travis(branch)\n    elif os.environ.get('SEMAPHORE') == 'true':\n        semaphore(branch)\n    elif os.environ.get('FRIGG') == 'true':\n        frigg(branch)\n    elif os.environ.get('CIRCLECI') == 'true':\n        circle(branch)\n    elif os.environ.get('GITLAB_CI') == 'true':\n        gitlab(branch)\n    elif 'BITBUCKET_BUILD_NUMBER' in os.environ:\n        bitbucket(branch)", "response": "Detects the current CI environment if any and performs necessary\n    environment checks."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_commit_message(message: str) -> Tuple[int, str, str, Tuple[str, str, str]]:\n    parsed = re_parser.match(message)\n    if not parsed:\n        raise UnknownCommitMessageStyleError(\n            'Unable to parse the given commit message: {}'.format(message)\n        )\n\n    level_bump = 0\n    if parsed.group('text') and 'BREAKING CHANGE' in parsed.group('text'):\n        level_bump = 3\n\n    if parsed.group('type') == 'feat':\n        level_bump = max([level_bump, 2])\n\n    if parsed.group('type') == 'fix':\n        level_bump = max([level_bump, 1])\n\n    body, footer = parse_text_block(parsed.group('text'))\n    if debug.enabled:\n        debug('parse_commit_message -> ({}, {}, {}, {})'.format(\n            level_bump,\n            TYPES[parsed.group('type')],\n            parsed.group('scope'),\n            (parsed.group('subject'), body, footer)\n        ))\n    return (\n        level_bump,\n        TYPES[parsed.group('type')],\n        parsed.group('scope'),\n        (parsed.group('subject'), body, footer)\n    )", "response": "Parses a commit message according to the angular commit guidelines specification."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_text_block(text: str) -> Tuple[str, str]:\n    body, footer = '', ''\n    if text:\n        body = text.split('\\n\\n')[0]\n        if len(text.split('\\n\\n')) == 2:\n            footer = text.split('\\n\\n')[1]\n\n    return body.replace('\\n', ' '), footer.replace('\\n', ' ')", "response": "This will take a text block and return a tuple with body and footer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate the wheel and uploads it to pypi with twine.", "response": "def upload_to_pypi(\n        dists: str = 'sdist bdist_wheel',\n        username: str = None,\n        password: str = None,\n        skip_existing: bool = False\n):\n    \"\"\"Creates the wheel and uploads to pypi with twine.\n\n    :param dists: The dists string passed to setup.py. Default: 'bdist_wheel'\n    :param username: PyPI account username string\n    :param password: PyPI account password string\n    :param skip_existing: Continue uploading files if one already exists. (Only valid when\n         uploading to PyPI. Other implementations may not support this.)\n    \"\"\"\n    if username is None or password is None or username == \"\" or password == \"\":\n        raise ImproperConfigurationError('Missing credentials for uploading')\n    run('rm -rf build dist')\n    run('python setup.py {}'.format(dists))\n    run(\n        'twine upload -u {} -p {} {} {}'.format(\n            username,\n            password,\n            '--skip-existing' if skip_existing else '',\n            'dist/*'\n        )\n    )\n    run('rm -rf build dist')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nyielding all commit messages from last to first.", "response": "def get_commit_log(from_rev=None):\n    \"\"\"\n    Yields all commit messages from last to first.\n    \"\"\"\n\n    check_repo()\n    rev = None\n    if from_rev:\n        rev = '...{from_rev}'.format(from_rev=from_rev)\n    for commit in repo.iter_commits(rev):\n        yield (commit.hexsha, commit.message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns last version from repo tags.", "response": "def get_last_version(skip_tags=None) -> Optional[str]:\n    \"\"\"\n    Return last version from repo tags.\n\n    :return: A string contains version number.\n    \"\"\"\n\n    debug('get_last_version skip_tags=', skip_tags)\n    check_repo()\n    skip_tags = skip_tags or []\n\n    def version_finder(tag):\n        if isinstance(tag.commit, TagObject):\n            return tag.tag.tagged_date\n        return tag.commit.committed_date\n\n    for i in sorted(repo.tags, reverse=True, key=version_finder):\n        if re.match(r'v\\d+\\.\\d+\\.\\d+', i.name):\n            if i.name in skip_tags:\n                continue\n            return i.name[1:]\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_version_from_tag(tag_name: str) -> Optional[str]:\n\n    debug('get_version_from_tag({})'.format(tag_name))\n    check_repo()\n    for i in repo.tags:\n        if i.name == tag_name:\n            return i.commit.hexsha\n    return None", "response": "Get the git hash of the tag"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_repository_owner_and_name() -> Tuple[str, str]:\n\n    check_repo()\n    url = repo.remote('origin').url\n    parts = re.search(r'([^/:]+)/([^/]+).git$', url)\n    if not parts:\n        raise HvcsRepoParseError\n    debug('get_repository_owner_and_name', parts)\n    return parts.group(1), parts.group(2)", "response": "Checks the origin remote to get the owner and name of the remote repository."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncommitting the file containing the version number variable with the version number as the commit message.", "response": "def commit_new_version(version: str):\n    \"\"\"\n    Commits the file containing the version number variable with the version number as the commit\n    message.\n\n    :param version: The version number to be used in the commit message.\n    \"\"\"\n\n    check_repo()\n    commit_message = config.get('semantic_release', 'commit_message')\n    message = '{0}\\n\\n{1}'.format(version, commit_message)\n    repo.git.add(config.get('semantic_release', 'version_variable').split(':')[0])\n    return repo.git.commit(m=message, author=\"semantic-release <semantic-release>\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new tag with the version number prefixed with v.", "response": "def tag_new_version(version: str):\n    \"\"\"\n    Creates a new tag with the version number prefixed with v.\n\n    :param version: The version number used in the tag as a string.\n    \"\"\"\n\n    check_repo()\n    return repo.git.tag('-a', 'v{0}'.format(version), m='v{0}'.format(version))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npush a new version of the current version of the current version of the current version of the current version of the current version.", "response": "def push_new_version(gh_token: str = None, owner: str = None, name: str = None):\n    \"\"\"\n    Runs git push and git push --tags.\n\n    :param gh_token: Github token used to push.\n    :param owner: Organisation or user that owns the repository.\n    :param name: Name of repository.\n    :raises GitError: if GitCommandError is raised\n    \"\"\"\n\n    check_repo()\n    server = 'origin'\n    if gh_token:\n        server = 'https://{token}@{repo}'.format(\n            token=gh_token,\n            repo='github.com/{owner}/{name}.git'.format(owner=owner, name=name)\n        )\n\n    try:\n        repo.git.push(server, 'master')\n        repo.git.push('--tags', server, 'master')\n    except GitCommandError as error:\n        message = str(error)\n        if gh_token:\n            message = message.replace(gh_token, '[GH_TOKEN]')\n        raise GitError(message)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the current commit parser", "response": "def current_commit_parser() -> Callable:\n    \"\"\"Current commit parser\n\n    :raises ImproperConfigurationError: if ImportError or AttributeError is raised\n    \"\"\"\n\n    try:\n        parts = config.get('semantic_release', 'commit_parser').split('.')\n        module = '.'.join(parts[:-1])\n        return getattr(importlib.import_module(module), parts[-1])\n    except (ImportError, AttributeError) as error:\n        raise ImproperConfigurationError('Unable to import parser \"{}\"'.format(error))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_current_version_by_config_file() -> str:\n    debug('get_current_version_by_config_file')\n    filename, variable = config.get('semantic_release',\n                                    'version_variable').split(':')\n    variable = variable.strip()\n    debug(filename, variable)\n    with open(filename, 'r') as fd:\n        parts = re.search(\n            r'^{0}\\s*=\\s*[\\'\"]([^\\'\"]*)[\\'\"]'.format(variable),\n            fd.read(),\n            re.MULTILINE\n        )\n        if not parts:\n            raise ImproperConfigurationError\n        debug(parts)\n        return parts.group(1)", "response": "Get current version from the version variable defined in the configuration file"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the next version number based on the given bump level.", "response": "def get_new_version(current_version: str, level_bump: str) -> str:\n    \"\"\"\n    Calculates the next version based on the given bump level with semver.\n\n    :param current_version: The version the package has now.\n    :param level_bump: The level of the version number that should be bumped. Should be a `'major'`,\n                       `'minor'` or `'patch'`.\n    :return: A string with the next version number.\n    \"\"\"\n    debug('get_new_version(\"{}\", \"{}\")'.format(current_version, level_bump))\n    if not level_bump:\n        return current_version\n    return getattr(semver, 'bump_{0}'.format(level_bump))(current_version)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_previous_version(version: str) -> Optional[str]:\n    debug('get_previous_version')\n    found_version = False\n    for commit_hash, commit_message in get_commit_log():\n        debug('checking commit {}'.format(commit_hash))\n        if version in commit_message:\n            found_version = True\n            debug('found_version in \"{}\"'.format(commit_message))\n            continue\n\n        if found_version:\n            matches = re.match(r'v?(\\d+.\\d+.\\d+)', commit_message)\n            if matches:\n                debug('version matches', commit_message)\n                return matches.group(1).strip()\n\n    return get_last_version([version, 'v{}'.format(version)])", "response": "Returns the previous version number."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngives the content of a file finds the version string and updates it.", "response": "def replace_version_string(content, variable, new_version):\n    \"\"\"\n    Given the content of a file, finds the version string and updates it.\n\n    :param content: The file contents\n    :param variable: The version variable name as a string\n    :param new_version: The new version number as a string\n    :return: A string with the updated version number\n    \"\"\"\n    return re.sub(\n        r'({0} ?= ?[\"\\'])\\d+\\.\\d+(?:\\.\\d+)?([\"\\'])'.format(variable),\n        r'\\g<1>{0}\\g<2>'.format(new_version),\n        content\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreplacing the version number in the correct place and writes the changed file to disk.", "response": "def set_new_version(new_version: str) -> bool:\n    \"\"\"\n    Replaces the version number in the correct place and writes the changed file to disk.\n\n    :param new_version: The new version number as a string.\n    :return: `True` if it succeeded.\n    \"\"\"\n    filename, variable = config.get(\n        'semantic_release', 'version_variable').split(':')\n    variable = variable.strip()\n    with open(filename, mode='r') as fr:\n        content = fr.read()\n\n    content = replace_version_string(content, variable, new_version)\n\n    with open(filename, mode='w') as fw:\n        fw.write(content)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nevaluating the current version of the release.", "response": "def evaluate_version_bump(current_version: str, force: str = None) -> Optional[str]:\n    \"\"\"\n    Reads git log since last release to find out if should be a major, minor or patch release.\n\n    :param current_version: A string with the current version number.\n    :param force: A string with the bump level that should be forced.\n    :return: A string with either major, minor or patch if there should be a release. If no release\n             is necessary None will be returned.\n    \"\"\"\n    debug('evaluate_version_bump(\"{}\", \"{}\")'.format(current_version, force))\n    if force:\n        return force\n\n    bump = None\n\n    changes = []\n    commit_count = 0\n\n    for _hash, commit_message in get_commit_log('v{0}'.format(current_version)):\n        if (current_version in commit_message and\n                config.get('semantic_release', 'version_source') == 'commit'):\n            debug('found {} in \"{}. breaking loop'.format(current_version, commit_message))\n            break\n        try:\n            message = current_commit_parser()(commit_message)\n            changes.append(message[0])\n        except UnknownCommitMessageStyleError as err:\n            debug('ignored', err)\n            pass\n\n        commit_count += 1\n\n    if changes:\n        level = max(changes)\n        if level in LEVELS:\n            bump = LEVELS[level]\n    if config.getboolean('semantic_release', 'patch_without_tag') and commit_count:\n        bump = 'patch'\n    return bump"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_changelog(from_version: str, to_version: str = None) -> dict:\n    debug('generate_changelog(\"{}\", \"{}\")'.format(from_version, to_version))\n    changes: dict = {'feature': [], 'fix': [],\n                     'documentation': [], 'refactor': [], 'breaking': []}\n\n    found_the_release = to_version is None\n\n    rev = None\n    if from_version:\n        rev = 'v{0}'.format(from_version)\n\n    for _hash, commit_message in get_commit_log(rev):\n        if not found_the_release:\n            if to_version and to_version not in commit_message:\n                continue\n            else:\n                found_the_release = True\n\n        if from_version is not None and from_version in commit_message:\n            break\n\n        try:\n            message = current_commit_parser()(commit_message)\n            if message[1] not in changes:\n                continue\n\n            changes[message[1]].append((_hash, message[3][0]))\n\n            if message[3][1] and 'BREAKING CHANGE' in message[3][1]:\n                parts = re_breaking.match(message[3][1])\n                if parts:\n                    changes['breaking'].append(parts.group(1))\n\n            if message[3][2] and 'BREAKING CHANGE' in message[3][2]:\n                parts = re_breaking.match(message[3][2])\n                if parts:\n                    changes['breaking'].append(parts.group(1))\n\n        except UnknownCommitMessageStyleError as err:\n            debug('Ignoring', err)\n            pass\n\n    return changes", "response": "Generates a changelog for the given version."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate a markdown version of the changelog.", "response": "def markdown_changelog(version: str, changelog: dict, header: bool = False) -> str:\n    \"\"\"\n    Generates a markdown version of the changelog. Takes a parsed changelog dict from\n    generate_changelog.\n\n    :param version: A string with the version number.\n    :param changelog: A dict from generate_changelog.\n    :param header: A boolean that decides whether a header should be included or not.\n    :return: The markdown formatted changelog.\n    \"\"\"\n    debug('markdown_changelog(version=\"{}\", header={}, changelog=...)'.format(version, header))\n    output = ''\n    if header:\n        output += '## v{0}\\n'.format(version)\n\n    for section in CHANGELOG_SECTIONS:\n        if not changelog[section]:\n            continue\n\n        output += '\\n### {0}\\n'.format(section.capitalize())\n        for item in changelog[section]:\n            output += '* {0} ({1})\\n'.format(item[1], item[0])\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets HVCS helper class", "response": "def get_hvcs() -> Base:\n    \"\"\"Get HVCS helper class\n\n    :raises ImproperConfigurationError: if the hvcs option provided is not valid\n    \"\"\"\n    hvcs = config.get('semantic_release', 'hvcs')\n    debug('get_hvcs: hvcs=', hvcs)\n    try:\n        return globals()[hvcs.capitalize()]\n    except KeyError:\n        raise ImproperConfigurationError('\"{0}\" is not a valid option for hvcs.')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_build_status(owner: str, repository: str, ref: str) -> bool:\n    debug('check_build_status')\n    return get_hvcs().check_build_status(owner, repository, ref)", "response": "Checks the build status of a commit on the hosted version control provider."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nposts the changelog to the current hvcs release API", "response": "def post_changelog(owner: str, repository: str, version: str, changelog: str) -> Tuple[bool, dict]:\n    \"\"\"\n    Posts the changelog to the current hvcs release API\n\n    :param owner: The owner of the repository\n    :param repository: The repository name\n    :param version: A string with the new version\n    :param changelog: A string with the changelog in correct format\n    :return: a tuple with success status and payload from hvcs\n    \"\"\"\n    debug('post_changelog(owner={}, repository={}, version={})'.format(owner, repository, version))\n    return get_hvcs().post_release_changelog(owner, repository, version, changelog)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking the build status of the current branch", "response": "def check_build_status(owner: str, repo: str, ref: str) -> bool:\n        \"\"\"Check build status\n\n        :param owner: The owner namespace of the repository\n        :param repo: The repository name\n        :param ref: The sha1 hash of the commit ref\n\n        :return: Was the build status success?\n        \"\"\"\n        url = '{domain}/repos/{owner}/{repo}/commits/{ref}/status'\n        response = requests.get(\n            url.format(domain=Github.DOMAIN, owner=owner, repo=repo, ref=ref)\n        )\n        if debug_gh.enabled:\n            debug_gh('check_build_status: state={}'.format(response.json()['state']))\n        return response.json()['state'] == 'success'"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nposts the changelog for a specific version number.", "response": "def post_release_changelog(\n            cls, owner: str, repo: str, version: str, changelog: str) -> Tuple[bool, dict]:\n        \"\"\"Check build status\n\n        :param owner: The owner namespace of the repository\n        :param repo: The repository name\n        :param version: The version number\n        :param changelog: The release notes for this version\n\n        :return: The status of the request and the response json\n        \"\"\"\n        url = '{domain}/repos/{owner}/{repo}/releases?access_token={token}'\n        tag = 'v{0}'.format(version)\n        debug_gh('listing releases')\n        response = requests.post(\n            url.format(\n                domain=Github.DOMAIN,\n                owner=owner,\n                repo=repo,\n                token=Github.token()\n            ),\n            json={'tag_name': tag, 'body': changelog, 'draft': False, 'prerelease': False}\n        )\n        status, payload = response.status_code == 201, response.json()\n        debug_gh('response #1, status_code={}, status={}'.format(response.status_code, status))\n\n        if not status:\n            debug_gh('not status, getting tag', tag)\n            url = '{domain}/repos/{owner}/{repo}/releases/tags/{tag}?access_token={token}'\n            response = requests.get(\n                url.format(\n                    domain=Github.DOMAIN,\n                    owner=owner,\n                    repo=repo,\n                    token=Github().token(),\n                    tag=tag\n                ),\n            )\n            release_id = response.json()['id']\n            debug_gh('response #2, status_code={}'.format(response.status_code))\n            url = '{domain}/repos/{owner}/{repo}/releases/{id}?access_token={token}'\n            debug_gh('getting release_id', release_id)\n            response = requests.post(\n                url.format(\n                    domain=Github.DOMAIN,\n                    owner=owner,\n                    repo=repo,\n                    token=Github().token(),\n                    id=release_id\n                ),\n                json={'tag_name': tag, 'body': changelog, 'draft': False, 'prerelease': False}\n            )\n            status, payload = response.status_code == 200, response.json()\n            debug_gh('response #3, status_code={}, status={}'.format(response.status_code, status))\n        return status, payload"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef version(**kwargs):\n    retry = kwargs.get(\"retry\")\n    if retry:\n        click.echo('Retrying publication of the same version...')\n    else:\n        click.echo('Creating new version..')\n\n    try:\n        current_version = get_current_version()\n    except GitError as e:\n        click.echo(click.style(str(e), 'red'), err=True)\n        return False\n\n    click.echo('Current version: {0}'.format(current_version))\n    level_bump = evaluate_version_bump(current_version, kwargs['force_level'])\n    new_version = get_new_version(current_version, level_bump)\n\n    if new_version == current_version and not retry:\n        click.echo(click.style('No release will be made.', fg='yellow'))\n        return False\n\n    if kwargs['noop'] is True:\n        click.echo('{0} Should have bumped from {1} to {2}.'.format(\n            click.style('No operation mode.', fg='yellow'),\n            current_version,\n            new_version\n        ))\n        return False\n\n    if config.getboolean('semantic_release', 'check_build_status'):\n        click.echo('Checking build status..')\n        owner, name = get_repository_owner_and_name()\n        if not check_build_status(owner, name, get_current_head_hash()):\n            click.echo(click.style('The build has failed', 'red'))\n            return False\n        click.echo(click.style('The build was a success, continuing the release', 'green'))\n\n    if retry:\n        # No need to make changes to the repo, we're just retrying.\n        return True\n\n    if config.get('semantic_release', 'version_source') == 'commit':\n        set_new_version(new_version)\n        commit_new_version(new_version)\n    tag_new_version(new_version)\n    click.echo('Bumping with a {0} version to {1}.'.format(level_bump, new_version))\n    return True", "response": "Detects the new version according to git log and semver. Writes the new version and commits it unless the noop - option is True."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate the changelog for the current version of the current version.", "response": "def changelog(**kwargs):\n    \"\"\"\n    Generates the changelog since the last release.\n    :raises ImproperConfigurationError: if there is no current version\n    \"\"\"\n    current_version = get_current_version()\n    debug('changelog got current_version', current_version)\n\n    if current_version is None:\n        raise ImproperConfigurationError(\n            \"Unable to get the current version. \"\n            \"Make sure semantic_release.version_variable \"\n            \"is setup correctly\"\n        )\n    previous_version = get_previous_version(current_version)\n    debug('changelog got previous_version', previous_version)\n\n    log = generate_changelog(previous_version, current_version)\n    click.echo(markdown_changelog(current_version, log, header=False))\n\n    debug('noop={}, post={}'.format(kwargs.get('noop'), kwargs.get('post')))\n    if not kwargs.get('noop') and kwargs.get('post'):\n        if check_token():\n            owner, name = get_repository_owner_and_name()\n            click.echo('Updating changelog')\n            post_changelog(\n                owner,\n                name,\n                current_version,\n                markdown_changelog(current_version, log, header=False)\n            )\n        else:\n            click.echo(\n                click.style('Missing token: cannot post changelog', 'red'), err=True)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npublishing the current version to PyPI.", "response": "def publish(**kwargs):\n    \"\"\"\n    Runs the version task before pushing to git and uploading to pypi.\n    \"\"\"\n\n    current_version = get_current_version()\n    click.echo('Current version: {0}'.format(current_version))\n    retry = kwargs.get(\"retry\")\n    debug('publish: retry=', retry)\n    if retry:\n        # The \"new\" version will actually be the current version, and the\n        # \"current\" version will be the previous version.\n        new_version = current_version\n        current_version = get_previous_version(current_version)\n    else:\n        level_bump = evaluate_version_bump(current_version, kwargs['force_level'])\n        new_version = get_new_version(current_version, level_bump)\n    owner, name = get_repository_owner_and_name()\n\n    ci_checks.check('master')\n    checkout('master')\n\n    if version(**kwargs):\n        push_new_version(\n            gh_token=os.environ.get('GH_TOKEN'),\n            owner=owner,\n            name=name\n        )\n\n        if config.getboolean('semantic_release', 'upload_to_pypi'):\n            upload_to_pypi(\n                username=os.environ.get('PYPI_USERNAME'),\n                password=os.environ.get('PYPI_PASSWORD'),\n                # We are retrying, so we don't want errors for files that are already on PyPI.\n                skip_existing=retry,\n            )\n\n        if check_token():\n            click.echo('Updating changelog')\n            try:\n                log = generate_changelog(current_version, new_version)\n                post_changelog(\n                    owner,\n                    name,\n                    new_version,\n                    markdown_changelog(new_version, log, header=False)\n                )\n            except GitError:\n                click.echo(click.style('Posting changelog failed.', 'red'), err=True)\n\n        else:\n            click.echo(\n                click.style('Missing token: cannot post changelog', 'red'), err=True)\n\n        click.echo(click.style('New release published', 'green'))\n    else:\n        click.echo('Version failed, no release will be published.', err=True)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a HttpResponse that implements the TinyMCE spellchecker protocol.", "response": "def spell_check(request):\n    \"\"\"\n    Returns a HttpResponse that implements the TinyMCE spellchecker protocol.\n    \"\"\"\n    try:\n        if not enchant:\n            raise RuntimeError(\"install pyenchant for spellchecker functionality\")\n\n        raw = force_text(request.body)\n        input = json.loads(raw)\n        id = input['id']\n        method = input['method']\n        params = input['params']\n        lang = params[0]\n        arg = params[1]\n\n        if not enchant.dict_exists(str(lang)):\n            raise RuntimeError(\"dictionary not found for language {!r}\".format(lang))\n\n        checker = enchant.Dict(str(lang))\n\n        if method == 'checkWords':\n            result = [word for word in arg if word and not checker.check(word)]\n        elif method == 'getSuggestions':\n            result = checker.suggest(arg)\n        else:\n            raise RuntimeError(\"Unknown spellcheck method: {!r}\".format(method))\n        output = {\n            'id': id,\n            'result': result,\n            'error': None,\n        }\n    except Exception:\n        logging.exception(\"Error running spellchecker\")\n        return HttpResponse(_(\"Error running spellchecker\"))\n    return HttpResponse(json.dumps(output),\n                        content_type='application/json')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef flatpages_link_list(request):\n    from django.contrib.flatpages.models import FlatPage\n    link_list = [(page.title, page.url) for page in FlatPage.objects.all()]\n    return render_to_link_list(link_list)", "response": "Returns a HttpResponse whose content is a Javascript file representing a\n    list of links to flatpages."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _interactive_loop(self, sin: IO[str], sout: IO[str]) -> None:\n        self._sin = sin\n        self._sout = sout\n        tasknum = len(all_tasks(loop=self._loop))\n        s = '' if tasknum == 1 else 's'\n        self._sout.write(self.intro.format(tasknum=tasknum, s=s))\n        try:\n            while not self._closing.is_set():\n                self._sout.write(self.prompt)\n                self._sout.flush()\n                try:\n                    user_input = sin.readline().strip()\n                except Exception as e:\n                    msg = 'Could not read from user input due to:\\n{}\\n'\n                    log.exception(msg)\n                    self._sout.write(msg.format(repr(e)))\n                    self._sout.flush()\n                else:\n                    try:\n                        self._command_dispatch(user_input)\n                    except Exception as e:\n                        msg = 'Unexpected Exception during command execution:\\n{}\\n'  # noqa\n                        log.exception(msg)\n                        self._sout.write(msg.format(repr(e)))\n                        self._sout.flush()\n        finally:\n            self._sin = None  # type: ignore\n            self._sout = None", "response": "Main interactive loop of the monitor"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef do_help(self, *cmd_names: str) -> None:\n        def _h(cmd: str, template: str) -> None:\n            try:\n                func = getattr(self, cmd)\n            except AttributeError:\n                self._sout.write('No such command: {}\\n'.format(cmd))\n            else:\n                doc = func.__doc__ if func.__doc__ else ''\n                doc_firstline = doc.split('\\n', maxsplit=1)[0]\n                arg_list = ' '.join(\n                    p for p in inspect.signature(func).parameters)\n                self._sout.write(\n                    template.format(\n                        cmd_name=cmd[len(self._cmd_prefix):],\n                        arg_list=arg_list,\n                        cmd_arg_sep=' ' if arg_list else '',\n                        doc=doc,\n                        doc_firstline=doc_firstline\n                    ) + '\\n'\n                )\n\n        if not cmd_names:\n            cmds = sorted(\n                c.method_name for c in self._filter_cmds(with_alts=False)\n            )\n            self._sout.write('Available Commands are:\\n\\n')\n            for cmd in cmds:\n                _h(cmd, self.help_short_template)\n        else:\n            for cmd in cmd_names:\n                _h(self._cmd_prefix + cmd, self.help_template)", "response": "Show help for command name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef do_where(self, taskid: int) -> None:\n        task = task_by_id(taskid, self._loop)\n        if task:\n            self._sout.write(_format_stack(task))\n            self._sout.write('\\n')\n        else:\n            self._sout.write('No task %d\\n' % taskid)", "response": "Show stack frames for a task"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsending a Unix signal", "response": "def do_signal(self, signame: str) -> None:\n        \"\"\"Send a Unix signal\"\"\"\n        if hasattr(signal, signame):\n            os.kill(os.getpid(), getattr(signal, signame))\n        else:\n            self._sout.write('Unknown signal %s\\n' % signame)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef do_stacktrace(self) -> None:\n        frame = sys._current_frames()[self._event_loop_thread_id]\n        traceback.print_stack(frame, file=self._sout)", "response": "Print a stack trace from the event loop thread."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef do_cancel(self, taskid: int) -> None:\n        task = task_by_id(taskid, self._loop)\n        if task:\n            fut = asyncio.run_coroutine_threadsafe(\n                cancel_task(task), loop=self._loop)\n            fut.result(timeout=3)\n            self._sout.write('Cancel task %d\\n' % taskid)\n        else:\n            self._sout.write('No task %d\\n' % taskid)", "response": "Cancel an indicated task"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nswitch to async Python REPL", "response": "def do_console(self) -> None:\n        \"\"\"Switch to async Python REPL\"\"\"\n        if not self._console_enabled:\n            self._sout.write('Python console disabled for this sessiong\\n')\n            self._sout.flush()\n            return\n\n        h, p = self._host, self._console_port\n        log.info('Starting console at %s:%d', h, p)\n        fut = init_console_server(\n            self._host, self._console_port, self._locals, self._loop)\n        server = fut.result(timeout=3)\n        try:\n            console_proxy(\n                self._sin, self._sout, self._host, self._console_port)\n        finally:\n            coro = close_server(server)\n            close_fut = asyncio.run_coroutine_threadsafe(coro, loop=self._loop)\n            close_fut.result(timeout=15)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nusing the /hello GET interface There is one optional argument, \"name\". This name argument must be provided with proper URL excape codes, like %20 for spaces.", "response": "def do_hello(self, sin, sout, name=None):\n        \"\"\"Using the /hello GET interface\n\n        There is one optional argument, \"name\".  This name argument must be\n        provided with proper URL excape codes, like %20 for spaces.\n        \"\"\"\n        name = '' if name is None else '/' + name\n        r = requests.get('http://localhost:8090/hello' + name)\n        sout.write(r.text + '\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef alt_names(names: str) -> Callable[..., Any]:\n    names_split = names.split()\n\n    def decorator(func: Callable[..., Any]) -> Callable[..., Any]:\n        func.alt_names = names_split  # type: ignore\n        return func\n    return decorator", "response": "Add alternative names to you custom commands."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nuses an interactive event loop by default.", "response": "def set_interactive_policy(*, locals=None, banner=None, serve=None,\n                           prompt_control=None):\n    \"\"\"Use an interactive event loop by default.\"\"\"\n    policy = InteractiveEventLoopPolicy(\n        locals=locals,\n        banner=banner,\n        serve=serve,\n        prompt_control=prompt_control)\n    asyncio.set_event_loop_policy(policy)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns the interactive event loop.", "response": "def run_console(*, locals=None, banner=None, serve=None, prompt_control=None):\n    \"\"\"Run the interactive event loop.\"\"\"\n    loop = InteractiveEventLoop(\n        locals=locals,\n        banner=banner,\n        serve=serve,\n        prompt_control=prompt_control)\n    asyncio.set_event_loop(loop)\n    try:\n        loop.run_forever()\n    except KeyboardInterrupt:\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmakes an ast function argument.", "response": "def make_arg(key, annotation=None):\n    \"\"\"Make an ast function argument.\"\"\"\n    arg = ast.arg(key, annotation)\n    arg.lineno, arg.col_offset = 0, 0\n    return arg"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreproduces default exec behavior", "response": "def exec_result(obj, local, stream):\n    \"\"\"Reproduce default exec behavior (print and builtins._)\"\"\"\n    local['_'] = obj\n    if obj is not None:\n        print(repr(obj), file=stream)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_tree(statement, filename=\"<aexec>\", symbol=\"single\", local={}):\n    # Create tree\n    tree = ast.parse(CORO_CODE, filename, symbol)\n    # Check expression statement\n    if isinstance(statement, ast.Expr):\n        tree.body[0].body[0].value.elts[0] = statement.value\n    else:\n        tree.body[0].body.insert(0, statement)\n    # Check and return coroutine\n    exec(compile(tree, filename, symbol))\n    return tree", "response": "Helper for * aexec *."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_coroutine_from_tree(tree, filename=\"<aexec>\", symbol=\"single\",\n                             local={}):\n    \"\"\"Make a coroutine from a tree structure.\"\"\"\n    dct = {}\n    tree.body[0].args.args = list(map(make_arg, local))\n    exec(compile(tree, filename, symbol), dct)\n    return asyncio.coroutine(dct[CORO_NAME])(**local)", "response": "Make a coroutine from a tree structure."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncompiles source for an interactive Python interpreter.", "response": "def compile_for_aexec(source, filename=\"<aexec>\", mode=\"single\",\n                      dont_imply_dedent=False, local={}):\n    \"\"\"Return a list of (coroutine object, abstract base tree).\"\"\"\n    flags = ast.PyCF_ONLY_AST\n    if dont_imply_dedent:\n        flags |= codeop.PyCF_DONT_IMPLY_DEDENT\n    if compat.PY35:\n        # Avoid a syntax error by wrapping code with `async def`\n        indented = '\\n'.join(line and ' ' * 4 + line\n                             for line in source.split('\\n'))\n        coroutine = CORO_DEF + '\\n' + indented + '\\n'\n        interactive = compile(coroutine, filename, mode, flags).body[0]\n        # Check EOF errors\n        try:\n            compile(source, filename, mode, flags)\n        except SyntaxError as exc:\n            if exc.msg == 'unexpected EOF while parsing':\n                raise\n    else:\n        interactive = compile(source, filename, mode, flags)\n    return [make_tree(statement, filename, mode) for\n            statement in interactive.body]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef aexec(source, local=None, stream=None):\n    if local is None:\n        local = {}\n    if isinstance(source, str):\n        source = compile_for_aexec(source)\n    for tree in source:\n        coro = make_coroutine_from_tree(tree, local=local)\n        result, new_local = yield from coro\n        exec_result(result, new_local, stream)\n        full_update(local, new_local)", "response": "Asynchronous equivalent to * exec*."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ainput(prompt='', *, streams=None, use_stderr=False, loop=None):\n    # Get standard streams\n    if streams is None:\n        streams = yield from get_standard_streams(\n            use_stderr=use_stderr, loop=loop)\n    reader, writer = streams\n    # Write prompt\n    writer.write(prompt.encode())\n    yield from writer.drain()\n    # Get data\n    data = yield from reader.readline()\n    # Decode data\n    data = data.decode()\n    # Return or raise EOF\n    if not data.endswith('\\n'):\n        raise EOFError\n    return data.rstrip('\\n')", "response": "Asynchronous equivalent to * input*."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef feature_needs(*feas):\n\n    fmap = {'stateful_files': 22,\n            'stateful_dirs':  23,\n            'stateful_io':    ('stateful_files', 'stateful_dirs'),\n            'stateful_files_keep_cache': 23,\n            'stateful_files_direct_io': 23,\n            'keep_cache':     ('stateful_files_keep_cache',),\n            'direct_io':      ('stateful_files_direct_io',),\n            'has_opendir':    ('stateful_dirs',),\n            'has_releasedir': ('stateful_dirs',),\n            'has_fsyncdir':   ('stateful_dirs',),\n            'has_create':     25,\n            'has_access':     25,\n            'has_fgetattr':   25,\n            'has_ftruncate':  25,\n            'has_fsinit':     ('has_init'),\n            'has_fsdestroy':  ('has_destroy'),\n            'has_lock':       26,\n            'has_utimens':    26,\n            'has_bmap':       26,\n            'has_init':       23,\n            'has_destroy':    23,\n            '*':              '!re:^\\*$'}\n\n    if not feas:\n        return fmap\n\n    def resolve(args, maxva):\n\n        for fp in args:\n            if isinstance(fp, int):\n                maxva[0] = max(maxva[0], fp)\n                continue\n            if isinstance(fp, list) or isinstance(fp, tuple):\n                for f in fp:\n                    yield f\n                continue\n            ma = isinstance(fp, str) and re.compile(\"(!\\s*|)re:(.*)\").match(fp)\n            if isinstance(fp, type(re.compile(''))) or ma:\n                neg = False\n                if ma:\n                    mag = ma.groups()\n                    fp = re.compile(mag[1])\n                    neg = bool(mag[0])\n                for f in list(fmap.keys()) + [ 'has_' + a for a in Fuse._attrs ]:\n                    if neg != bool(re.search(fp, f)):\n                        yield f\n                continue\n            ma = re.compile(\"has_(.*)\").match(fp)\n            if ma and ma.groups()[0] in Fuse._attrs and not fp in fmap:\n                yield 21\n                continue\n            yield fmap[fp]\n\n    maxva = [0]\n    while feas:\n        feas = set(resolve(feas, maxva))\n\n    return maxva[0]", "response": "This function returns a list of features that are needed for the FUSE API version."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef feature_assert(*feas):\n\n    fav = APIVersion()\n\n    for fea in feas:\n        fn = feature_needs(fea)\n        if fav < fn:\n            raise FuseError(\n              \"FUSE API version %d is required for feature `%s' but only %d is available\" % \\\n              (fn, str(fea), fav))", "response": "Assert that a kernel FUSE kernel has at least one of the specified features."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef assemble(self):\n\n        self.canonify()\n        args = [sys.argv and sys.argv[0] or \"python\"]\n        if self.mountpoint:\n            args.append(self.mountpoint)\n        for m, v in self.modifiers.items():\n            if v:\n                args.append(self.fuse_modifiers[m])\n\n        opta = []\n        for o, v in self.optdict.items():\n                opta.append(o + '=' + v)\n        opta.extend(self.optlist)\n\n        if opta:\n            args.append(\"-o\" + \",\".join(opta))\n\n        return args", "response": "Mangle self into an argument array"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef filter(self, other=None):\n\n        if not other:\n            other = Fuse.fuseoptref()\n\n        return SubOptsHive.filter(self, other)", "response": "Same as for SubOptsHive but with the following difference"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse(self, *args, **kw):\n\n        ev = 'errex' in kw and kw.pop('errex')\n        if ev and not isinstance(ev, int):\n            raise TypeError(\"error exit value should be an integer\")\n\n        try:\n            self.cmdline = self.parser.parse_args(*args, **kw)\n        except OptParseError:\n          if ev:\n              sys.exit(ev)\n          raise\n\n        return self.fuse_args", "response": "Parse command line fill fuse_args attribute."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nenter filesystem service loop.", "response": "def main(self, args=None):\n        \"\"\"Enter filesystem service loop.\"\"\"\n\n        if get_compat_0_1():\n            args = self.main_0_1_preamble()\n\n        d = {'multithreaded': self.multithreaded and 1 or 0}\n        d['fuse_args'] = args or self.fuse_args.assemble()\n\n        for t in 'file_class', 'dir_class':\n            if hasattr(self, t):\n                getattr(self.methproxy, 'set_' + t)(getattr(self,t))\n\n        for a in self._attrs:\n            b = a\n            if get_compat_0_1() and a in self.compatmap:\n                b = self.compatmap[a]\n            if hasattr(self, b):\n                c = ''\n                if get_compat_0_1() and hasattr(self, a + '_compat_0_1'):\n                    c = '_compat_0_1'\n                d[a] = ErrnoWrapper(self.lowwrap(a + c))\n\n        try:\n            main(**d)\n        except FuseError:\n            if args or self.fuse_args.mount_expected():\n                raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwraps the fname method when the C code expects a different kind of callback than we have in the fusepy API. (The wrapper is usually for performing some checks or transfromations which could be done in C but is simpler if done in Python.) Currently `open` and `create` are wrapped: a boolean flag is added which indicates if the result is to be kept during the opened file's lifetime or can be thrown away. Namely, it's considered disposable if it's an instance of FuseFileInfo.", "response": "def lowwrap(self, fname):\n        \"\"\"\n        Wraps the fname method when the C code expects a different kind of\n        callback than we have in the fusepy API. (The wrapper is usually for\n        performing some checks or transfromations which could be done in C but\n        is simpler if done in Python.)\n\n        Currently `open` and `create` are wrapped: a boolean flag is added\n        which indicates if the result is to be kept during the opened file's\n        lifetime or can be thrown away. Namely, it's considered disposable\n        if it's an instance of FuseFileInfo.\n        \"\"\"\n        fun = getattr(self, fname)\n\n        if fname in ('open', 'create'):\n            def wrap(*a, **kw):\n                res = fun(*a, **kw)\n                if not res or type(res) == type(0):\n                    return res\n                else:\n                    return (res, type(res) != FuseFileInfo)\n        elif fname == 'utimens':\n            def wrap(path, acc_sec, acc_nsec, mod_sec, mod_nsec):\n                ts_acc = Timespec(tv_sec = acc_sec, tv_nsec = acc_nsec)\n                ts_mod = Timespec(tv_sec = mod_sec, tv_nsec = mod_nsec)\n                return fun(path, ts_acc, ts_mod)\n        else:\n            wrap = fun\n\n        return wrap"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a FuseArgs instance with the list of supported options.", "response": "def fuseoptref(cls):\n        \"\"\"\n        Find out which options are recognized by the library.\n        Result is a `FuseArgs` instance with the list of supported\n        options, suitable for passing on to the `filter` method of\n        another `FuseArgs` instance.\n        \"\"\"\n\n        import os, re\n\n        pr, pw = os.pipe()\n        pid = os.fork()\n        if pid == 0:\n             os.dup2(pw, 2)\n             os.close(pr)\n\n             fh = cls()\n             fh.fuse_args = FuseArgs()\n             fh.fuse_args.setmod('showhelp')\n             fh.main()\n             sys.exit()\n\n        os.close(pw)\n\n        fa = FuseArgs()\n        ore = re.compile(\"-o\\s+([\\w\\[\\]]+(?:=\\w+)?)\")\n        fpr = os.fdopen(pr)\n        for l in fpr:\n             m = ore.search(l)\n             if m:\n                 o = m.groups()[0]\n                 oa = [o]\n                 # try to catch two-in-one options (like \"[no]foo\")\n                 opa = o.split(\"[\")\n                 if len(opa) == 2:\n                    o1, ox = opa\n                    oxpa = ox.split(\"]\")\n                    if len(oxpa) == 2:\n                       oo, o2 = oxpa\n                       oa = [o1 + o2, o1 + oo + o2]\n                 for o in oa:\n                     fa.add(o)\n\n        fpr.close()\n        return fa"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntransform self to an equivalent canonical form.", "response": "def canonify(self):\n        \"\"\"\n        Transform self to an equivalent canonical form:\n        delete optdict keys with False value, move optdict keys\n        with True value to optlist, stringify other values.\n        \"\"\"\n\n        for k, v in self.optdict.items():\n            if v == False:\n                self.optdict.pop(k)\n            elif v == True:\n                self.optdict.pop(k)\n                self.optlist.add(v)\n            else:\n                self.optdict[k] = str(v)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a new instance with the rejected options removed from self.", "response": "def filter(self, other):\n        \"\"\"\n        Throw away those options which are not in the other one.\n        Returns a new instance with the rejected options.\n        \"\"\"\n\n        self.canonify()\n        other.canonify()\n\n        rej = self.__class__()\n        rej.optlist = self.optlist.difference(other.optlist)\n        self.optlist.difference_update(rej.optlist)\n        for x in self.optdict.copy():\n             if x not in other.optdict:\n                 self.optdict.pop(x)\n                 rej.optdict[x] = None\n\n        return rej"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nregisters argument a suboption for self.", "response": "def register_sub(self, o):\n        \"\"\"Register argument a suboption for `self`.\"\"\"\n\n        if o.subopt in self.subopt_map:\n            raise OptionConflictError(\n              \"conflicting suboption handlers for `%s'\" % o.subopt,\n              o)\n        self.subopt_map[o.subopt] = o"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __return_json(url):\n        with try_URL():\n            response = requests.get(url)\n            if response.status_code == 200:\n                return response.json()\n            else:\n                return False", "response": "Returns the JSON data returned by the API service"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the passed tuc_content and returns a list containing the parsed data from the tuc_content", "response": "def __parse_content(tuc_content, content_to_be_parsed):\n        \"\"\"\n        parses the passed \"tuc_content\" for\n         - meanings\n         - synonym\n        received by querying the glosbe API\n\n        Called by\n         - meaning()\n         - synonym()\n\n        :param tuc_content: passed on the calling Function. A list object\n        :param content_to_be_parsed: data to be parsed from. Whether to parse \"tuc\" for meanings or synonyms\n        :returns: returns a list which contains the parsed data from \"tuc\"\n        \"\"\"\n        initial_parsed_content = {}\n\n        i = 0\n        for content_dict in tuc_content:\n            if content_to_be_parsed in content_dict.keys():\n                contents_raw = content_dict[content_to_be_parsed]\n                if content_to_be_parsed == \"phrase\":\n                    # for 'phrase', 'contents_raw' is a dictionary\n                    initial_parsed_content[i] = contents_raw['text']\n                    i += 1\n                elif content_to_be_parsed == \"meanings\":\n                    # for 'meanings', 'contents_raw' is a list\n                    for meaning_content in contents_raw:\n                        initial_parsed_content[i] = meaning_content['text']\n                        i += 1\n\n        final_parsed_content = {}\n        # removing duplicates(if any) from the dictionary\n        for key, value in initial_parsed_content.items():\n            if value not in final_parsed_content.values():\n                final_parsed_content[key] = value\n\n        # calling __clean_dict\n\n        formatted_list = Vocabulary.__clean_dict(final_parsed_content)\n        return formatted_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntakes a dictionary from __parse_content and creates a well formatted list of dict s as it s elements", "response": "def __clean_dict(dictionary):\n        \"\"\"\n        Takes the dictionary from __parse_content() and creates a well formatted list\n\n        :param dictionary: unformatted dict\n        :returns: a list which contains dict's as it's elements\n        \"\"\"\n        key_dict = {}\n        value_dict = {}\n        final_list = []\n        for key in dictionary.keys():\n            key_dict[key] = \"seq\"\n\n        for value in dictionary.values():\n            value_dict[value] = \"text\"\n\n        for (key1, value1), (key2, value2) in zip(key_dict.items(), value_dict.items()):\n            final_list.append({value1: int(key1), value2: key2})\n\n        return final_list"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef meaning(phrase, source_lang=\"en\", dest_lang=\"en\", format=\"json\"):\n        base_url = Vocabulary.__get_api_link(\"glosbe\")\n        url = base_url.format(word=phrase, source_lang=source_lang, dest_lang=dest_lang)\n        json_obj = Vocabulary.__return_json(url)\n\n        if json_obj:\n            try:\n                tuc_content = json_obj[\"tuc\"]  # \"tuc_content\" is a \"list\"\n            except KeyError:\n                return False\n            '''get meanings'''\n            meanings_list = Vocabulary.__parse_content(tuc_content, \"meanings\")\n            return Response().respond(meanings_list, format)\n            # print(meanings_list)\n            # return json.dumps(meanings_list)\n        else:\n            return False", "response": "get the meaning of a word"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nquery the bighugelabs API for the antonym of a word.", "response": "def antonym(phrase, format=\"json\"):\n        \"\"\"\n        queries the bighugelabs API for the antonym. The results include\n         - \"syn\" (synonym)\n         - \"ant\" (antonym)\n         - \"rel\" (related terms)\n         - \"sim\" (similar terms)\n         - \"usr\" (user suggestions)\n\n        But currently parsing only the antonym as I have already done\n        - synonym (using glosbe API)\n\n        :param phrase: word for which antonym is to be found\n        :param format: response structure type. Defaults to: \"json\"\n        :returns: returns a json object\n        :raises KeyError: returns False when no antonyms are found\n        \"\"\"\n        base_url = Vocabulary.__get_api_link(\"bighugelabs\")\n        url = base_url.format(word=phrase)\n        json_obj = Vocabulary.__return_json(url)\n\n        if not json_obj:\n            return False\n\n        result = []\n        visited = {}\n        idx = 0\n        for key in json_obj.keys():\n            antonyms = json_obj[key].get('ant', False)\n            if not antonyms:\n                continue\n\n            for antonym in antonyms:\n                if visited.get(antonym, False):\n                    continue\n\n                result.append({'seq': idx, 'text': antonym})\n                idx += 1\n                visited[antonym] = True\n\n        if not result:\n            return False\n\n        return Response().respond(result, format)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef usage_example(phrase, format='json'):\n        base_url = Vocabulary.__get_api_link(\"urbandict\")\n        url = base_url.format(action=\"define\", word=phrase)\n        word_examples = {}\n        json_obj = Vocabulary.__return_json(url)\n        if json_obj:\n            examples_list = json_obj[\"list\"]\n            for i, example in enumerate(examples_list):\n                if example[\"thumbs_up\"] > example[\"thumbs_down\"]:\n                    word_examples[i] = example[\"example\"].replace(\"\\r\", \"\").replace(\"\\n\", \"\")\n            if word_examples:\n                # reforamatting \"word_examples\" using \"__clean_dict()\"\n                # return json.dumps(Vocabulary.__clean_dict(word_examples))\n                # return Vocabulary.__clean_dict(word_examples)\n                return Response().respond(Vocabulary.__clean_dict(word_examples), format)\n            else:\n                return False\n        else:\n            return False", "response": "Takes the source phrase and queries it to the urbandict API to get the usage example for the specified word. Returns a json object if the phrase is invalid or False if the phrase is invalid."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pronunciation(phrase, format='json'):\n        base_url = Vocabulary.__get_api_link(\"wordnik\")\n        url = base_url.format(word=phrase.lower(), action=\"pronunciations\")\n        json_obj = Vocabulary.__return_json(url)\n        if json_obj:\n            '''\n            Refer : http://stackoverflow.com/q/18337407/3834059\n            '''\n            ## TODO: Fix the unicode issue mentioned in\n            ## https://github.com/tasdikrahman/vocabulary#181known-issues\n            for idx, obj in enumerate(json_obj):\n                obj['seq'] = idx\n\n            if sys.version_info[:2] <= (2, 7):  ## python2\n                # return json_obj\n                return Response().respond(json_obj, format)\n            else:  # python3\n                # return json.loads(json.dumps(json_obj, ensure_ascii=False))\n                return Response().respond(json_obj, format)\n        else:\n            return False", "response": "Gets the pronunciation from the Wordnik API."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef hyphenation(phrase, format='json'):\n        base_url = Vocabulary.__get_api_link(\"wordnik\")\n        url = base_url.format(word=phrase.lower(), action=\"hyphenation\")\n        json_obj = Vocabulary.__return_json(url)\n        if json_obj:\n            # return json.dumps(json_obj)\n            # return json_obj\n            return Response().respond(json_obj, format)\n        else:\n            return False", "response": "Returns back the stress points in the phrase passed in."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild a python dictionary from a json object", "response": "def __respond_with_dict(self, data):\n        \"\"\"\n        Builds a python dictionary from a json object\n\n        :param data: the json object\n        :returns: a nested dictionary\n        \"\"\"\n        response = {}\n        if isinstance(data, list):\n            temp_data, data = data, {}\n            for key, value in enumerate(temp_data):\n                data[key] = value\n\n        data.pop('seq', None)\n        for index, item in data.items():\n            values = item\n            if isinstance(item, list) or isinstance(item, dict):\n                values = self.__respond_with_dict(item)\n\n            if isinstance(values, dict) and len(values) == 1:\n                (key, values), = values.items()\n            response[index] = values\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild a python list from a json object", "response": "def __respond_with_list(self, data):\n        \"\"\"\n        Builds a python list from a json object\n\n        :param data: the json object\n        :returns: a nested list\n        \"\"\"\n        response = []\n        if isinstance(data, dict):\n            data.pop('seq', None)\n            data = list(data.values())\n\n        for item in data:\n            values = item\n            if isinstance(item, list) or isinstance(item, dict):\n                values = self.__respond_with_list(item)\n\n            if isinstance(values, list) and len(values) == 1:\n                response.extend(values)\n            else:\n                response.append(values)\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef respond(self, data, format='json'):\n        dispatchers = {\n            \"dict\": self.__respond_with_dict,\n            \"list\": self.__respond_with_list\n        }\n\n        if not dispatchers.get(format, False):\n            return json.dumps(data)\n\n        return dispatchers[format](data)", "response": "Converts a json object to a python datastructure based on the format specified"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _process_flags(self):\n        super()._process_flags()\n\n        if len(self.args) == 0:\n            self.multi_mode = False", "response": "Override to add additional check after processing the flags"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_todos(self):\n        if self.is_expression:\n            self.get_todos_from_expr()\n        else:\n            if self.last_argument:\n                numbers = self.args[:-1]\n            else:\n                numbers = self.args\n\n            for number in numbers:\n                try:\n                    self.todos.append(self.todolist.todo(number))\n                except InvalidTodoException:\n                    self.invalid_numbers.append(number)", "response": "Gets todo objects from supplied todo IDs."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns an attribute spec for the colors that correspond to the given todo item.", "response": "def _markup(p_todo, p_focus):\n    \"\"\"\n    Returns an attribute spec for the colors that correspond to the given todo\n    item.\n    \"\"\"\n    pri = p_todo.priority()\n    pri = 'pri_' + pri if pri else PaletteItem.DEFAULT\n\n    if not p_focus:\n        attr_dict = {None: pri}\n    else:\n        # use '_focus' palette entries instead of standard ones\n        attr_dict = {None: pri + '_focus'}\n        attr_dict[PaletteItem.PROJECT] = PaletteItem.PROJECT_FOCUS\n        attr_dict[PaletteItem.CONTEXT] = PaletteItem.CONTEXT_FOCUS\n        attr_dict[PaletteItem.METADATA] = PaletteItem.METADATA_FOCUS\n        attr_dict[PaletteItem.LINK] = PaletteItem.LINK_FOCUS\n\n    return attr_dict"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a TodoWidget instance for the given todo item.", "response": "def create(p_class, p_todo, p_id_width=4):\n        \"\"\"\n        Creates a TodoWidget instance for the given todo. Widgets are\n        cached, the same object is returned for the same todo item.\n        \"\"\"\n\n        def parent_progress_may_have_changed(p_todo):\n            \"\"\"\n            Returns True when a todo's progress should be updated because it is\n            dependent on the parent's progress.\n            \"\"\"\n            return p_todo.has_tag('p') and not p_todo.has_tag('due')\n\n        source = p_todo.source()\n\n        if source in p_class.cache:\n            widget = p_class.cache[source]\n\n            if p_todo is not widget.todo:\n                # same source text but different todo instance (could happen\n                # after an edit where a new Todo instance is created with the\n                # same text as before)\n                # simply fix the reference in the stored widget.\n                widget.todo = p_todo\n\n            if parent_progress_may_have_changed(p_todo):\n                widget.update_progress()\n        else:\n            widget = p_class(p_todo, p_id_width)\n            p_class.cache[source] = widget\n\n        return widget"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _history_move(self, p_step):\n        if len(self.history) > 0:\n            # don't pollute real history - use temporary storage\n            self.history_tmp[self.history_pos] = self.edit_text\n            self.history_pos = self.history_pos + p_step\n            self.set_edit_text(self.history_tmp[self.history_pos])", "response": "Move the history item to the next value obtained by addition of p_step to the history_tmp list with index calculated by addition of p_step to the history_pos attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninserts currently chosen completion into edit_text adjusts cursor position accordingly.", "response": "def insert_completion(self, p_insert):\n        \"\"\"\n        Inserts currently chosen completion (p_insert parameter) into proper\n        place in edit_text and adjusts cursor position accordingly.\n        \"\"\"\n        start, end = self._surrounding_text\n        final_text = start + p_insert + end\n        self.set_edit_text(final_text)\n        self.set_edit_pos(len(start) + len(p_insert))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmoving the completion to the next item in the completion box.", "response": "def _completion_move(self, p_step, p_size):\n        \"\"\"\n        Visually selects completion specified by p_step (positive numbers\n        forwards, negative numbers backwards) and inserts it into edit_text.\n\n        If p_step results in value out of range of currently evaluated\n        completion candidates, list is rewinded to the start (if cycling\n        forwards) or to the end (if cycling backwards).\n        \"\"\"\n        current_position = self.completion_box.focus_position\n\n        try:\n            self.completion_box.set_focus(current_position + p_step)\n        except IndexError:\n            position = 0 if p_step > 0 else len(self.completion_box) - 1\n            self.completion_box.set_focus(position)\n\n        maxcols, = p_size\n        size = (maxcols, self.completion_box.height)\n        self.completion_box.calculate_visible(size)\n\n        candidate = self.completion_box.focus.original_widget.text\n        self.insert_completion(candidate)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _home_del(self):\n        text = self.edit_text[self.edit_pos:]\n        self.set_edit_text(text)\n        self._home()", "response": "Deletes the line content before the cursor"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _end_del(self):\n        text = self.edit_text[:self.edit_pos]\n        self.set_edit_text(text)", "response": "Delete the line content after the cursor"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_node(self, p_id):\n        if not self.has_node(p_id):\n            self._edges[p_id] = set()", "response": "Adds a node to the graph."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_edge(self, p_from, p_to, p_id=None):\n        if not self.has_edge(p_from, p_to):\n            if not self.has_node(p_from):\n                self.add_node(p_from)\n\n            if not self.has_node(p_to):\n                self.add_node(p_to)\n\n            self._edges[p_from].add(p_to)\n            self._edge_numbers[(p_from, p_to)] = p_id", "response": "Adds an edge from p_from to p_to."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef reachable_nodes(self, p_id, p_recursive=True, p_reverse=False):\n        stack = [p_id]\n        visited = set()\n        result = set()\n\n        while len(stack):\n            current = stack.pop()\n\n            if current in visited or current not in self._edges:\n                continue\n\n            visited.add(current)\n\n            if p_reverse:\n                parents = [node for node, neighbors in self._edges.items()\n                           if current in neighbors]\n\n                stack = stack + parents\n                result = result.union(parents)\n            else:\n                stack = stack + list(self._edges[current])\n                result = result.union(self._edges[current])\n\n            if not p_recursive:\n                break\n\n        return result", "response": "Returns the set of all neighbors that the given node can reach."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding neighbors in the inverse graph.", "response": "def reachable_nodes_reverse(self, p_id, p_recursive=True):\n        \"\"\" Find neighbors in the inverse graph. \"\"\"\n        return self.reachable_nodes(p_id, p_recursive, True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_node(self, p_id, remove_unconnected_nodes=True):\n        if self.has_node(p_id):\n            for neighbor in self.incoming_neighbors(p_id):\n                self._edges[neighbor].remove(p_id)\n\n            neighbors = set()\n            if remove_unconnected_nodes:\n                neighbors = self.outgoing_neighbors(p_id)\n\n            del self._edges[p_id]\n\n            for neighbor in neighbors:\n                if self.is_isolated(neighbor):\n                    self.remove_node(neighbor)", "response": "Removes a node from the graph."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True iff the given node is isolated.", "response": "def is_isolated(self, p_id):\n        \"\"\"\n        Returns True iff the given node has no incoming or outgoing edges.\n        \"\"\"\n        return(len(self.incoming_neighbors(p_id)) == 0\n               and len(self.outgoing_neighbors(p_id)) == 0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True when the given edge is present in the graph.", "response": "def has_edge(self, p_from, p_to):\n        \"\"\" Returns True when the graph has the given edge. \"\"\"\n        return p_from in self._edges and p_to in self._edges[p_from]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving an edge from the graph.", "response": "def remove_edge(self, p_from, p_to, p_remove_unconnected_nodes=True):\n        \"\"\"\n        Removes an edge from the graph.\n\n        When remove_unconnected_nodes is True, then the nodes are also removed\n        if they become isolated.\n        \"\"\"\n        if self.has_edge(p_from, p_to):\n            self._edges[p_from].remove(p_to)\n\n        try:\n            del self._edge_numbers[(p_from, p_to)]\n        except KeyError:\n            return None\n\n        if p_remove_unconnected_nodes:\n            if self.is_isolated(p_from):\n                self.remove_node(p_from)\n\n            if self.is_isolated(p_to):\n                self.remove_node(p_to)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef transitively_reduce(self):\n        removals = set()\n\n        for from_node, neighbors in self._edges.items():\n            childpairs = \\\n                [(c1, c2) for c1 in neighbors for c2 in neighbors if c1 != c2]\n\n            for child1, child2 in childpairs:\n                if self.has_path(child1, child2) \\\n                   and not self.has_path(child1, from_node):\n                    removals.add((from_node, child2))\n\n        for edge in removals:\n            self.remove_edge(edge[0], edge[1])", "response": "A transitive reduction on the graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dot(self, p_print_labels=True):\n        out = 'digraph g {\\n'\n\n        for from_node, neighbors in sorted(self._edges.items()):\n            out += \"  {}\\n\".format(from_node)\n\n            for neighbor in sorted(neighbors):\n                out += \"  {} -> {}\".format(from_node, neighbor)\n\n                edge_id = self.edge_id(from_node, neighbor)\n                if edge_id and p_print_labels:\n                    out += ' [label=\"{}\"]'.format(edge_id)\n\n                out += \"\\n\"\n\n        out += '}\\n'\n        return out", "response": "Prints the graph in Dot format."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _filters(self):\n        filters = super()._filters()\n\n        if self.ids:\n            def get_todo(p_id):\n                \"\"\"\n                Safely obtains a todo item given the user-supplied ID.\n                Returns None if an invalid ID was entered.\n                \"\"\"\n                try:\n                    return self.todolist.todo(p_id)\n                except InvalidTodoException:\n                    return None\n\n            todos = [get_todo(i) for i in self.ids]\n            filters.append(InstanceFilter(todos))\n\n        if not self.show_all:\n            filters.append(HiddenTagFilter())\n\n        return filters", "response": "Returns a list of filters to be applied to all todo items."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprinting the todos in the right format.", "response": "def _print(self):\n        \"\"\"\n        Prints the todos in the right format.\n\n        Defaults to normal text output (with possible colors and other pretty\n        printing). If a format was specified on the commandline, this format is\n        sent to the output.\n        \"\"\"\n        if self.printer is None:\n            # create a standard printer with some filters\n            indent = config().list_indent()\n            final_format = ' ' * indent + self.format\n\n            filters = []\n            filters.append(PrettyPrinterFormatFilter(self.todolist, final_format))\n\n            self.printer = pretty_printer_factory(self.todolist, filters)\n\n        try:\n            if self.group_expression:\n                self.out(self.printer.print_groups(self._view().groups))\n            else:\n                self.out(self.printer.print_list(self._view().todos))\n        except ListFormatError:\n            self.error('Error while parsing format string (list_format config'\n                       ' option or -F)')"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetermine how many lines of items we can display in the terminal.", "response": "def _N_lines():\n        ''' Determine how many lines to print, such that the number of items\n            displayed will fit on the terminal (i.e one 'screen-ful' of items)\n\n            This looks at the environmental prompt variable, and tries to determine\n            how many lines it takes up.\n\n            On Windows, it does this by looking for the '$_' sequence, which indicates\n            a new line, in the environmental variable PROMPT.\n\n            Otherwise, it looks for a newline ('\\n') in the environmental variable\n            PS1.\n        '''\n        lines_in_prompt = 1     # prompt is assumed to take up one line, even\n                                #   without any newlines in it\n        if \"win32\" in sys.platform:\n            lines_in_prompt += 1  # Windows will typically print a free line after\n                                  #   the program output\n            a = re.findall(r'\\$_', os.getenv('PROMPT', ''))\n            lines_in_prompt += len(a)\n        else:\n            a = re.findall('\\\\n', os.getenv('PS1', ''))\n            lines_in_prompt += len(a)\n        n_lines = get_terminal_size().lines - lines_in_prompt\n\n        # print a minimum of one item\n        n_lines = max(n_lines, 1)\n\n        return n_lines"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_line(p_string):\n    result = {\n        'completed': False,\n        'completionDate': None,\n        'priority': None,\n        'creationDate': None,\n        'text': \"\",\n        'projects': [],\n        'contexts': [],\n        'tags': {},\n    }\n\n    completed_head = _COMPLETED_HEAD_MATCH.match(p_string)\n    normal_head = _NORMAL_HEAD_MATCH.match(p_string)\n\n    rest = p_string\n\n    if completed_head:\n        result['completed'] = True\n\n        completion_date = completed_head.group('completionDate')\n        try:\n            result['completionDate'] = date_string_to_date(completion_date)\n        except ValueError:\n            pass\n\n        creation_date = completed_head.group('creationDate')\n\n        try:\n            result['creationDate'] = date_string_to_date(creation_date)\n        except ValueError:\n            pass\n\n        rest = completed_head.group('rest')\n    elif normal_head:\n        result['priority'] = normal_head.group('priority')\n\n        creation_date = normal_head.group('creationDate')\n\n        try:\n            result['creationDate'] = date_string_to_date(creation_date)\n        except ValueError:\n            pass\n\n        rest = normal_head.group('rest')\n\n    for word in rest.split():\n        project = _PROJECT_MATCH.match(word)\n        if project:\n            result['projects'].append(project.group(1))\n\n        context = _CONTEXT_MATCH.match(word)\n        if context:\n            result['contexts'].append(context.group(1))\n\n        tag = _TAG_MATCH.match(word)\n        if tag:\n            tag_name = tag.group('tag')\n            tag_value = tag.group('value')\n            try:\n                result['tags'][tag_name].append(tag_value)\n            except KeyError:\n                result['tags'][tag_name] = [tag_value]\n        else:\n            result['text'] += word + ' '\n\n    # strip trailing space from resulting text\n    result['text'] = result['text'][:-1]\n\n    return result", "response": "Parses a single line of todo. txt file into a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _dates(p_word_before_cursor):\n    to_absolute = lambda s: relative_date_to_date(s).isoformat()\n\n    start_value_pos = p_word_before_cursor.find(':') + 1\n    value = p_word_before_cursor[start_value_pos:]\n\n    for reldate in date_suggestions():\n        if not reldate.startswith(value):\n            continue\n\n        yield Completion(reldate, -len(value), display_meta=to_absolute(reldate))", "response": "Generator for date completion."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_completions(self, p_completions):\n        palette = PaletteItem.MARKED\n        for completion in p_completions:\n            width = len(completion)\n            if width > self.min_width:\n                self.min_width = width\n            w = urwid.Text(completion)\n            self.items.append(urwid.AttrMap(w, None, focus_map=palette))\n            self.items.set_focus(0)", "response": "Adds completion candidates to the items attribute."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _apply_filters(self, p_todos):\n        result = p_todos\n\n        for _filter in sorted(self._filters, key=lambda f: f.order):\n            result = _filter.filter(result)\n\n        return result", "response": "Applies the filters to the list of todo items."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef todos(self):\n        result = self._sorter.sort(self.todolist.todos())\n        return self._apply_filters(result)", "response": "Returns a sorted and filtered list of todos in this view."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef execute_specific(self, p_todo):\n        self._handle_recurrence(p_todo)\n        self.execute_specific_core(p_todo)\n\n        printer = PrettyPrinter()\n        self.out(self.prefix() + printer.print_todo(p_todo))", "response": "Actions specific to this command."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef date_string_to_date(p_date):\n    result = None\n\n    if p_date:\n        parsed_date = re.match(r'(\\d{4})-(\\d{2})-(\\d{2})', p_date)\n        if parsed_date:\n            result = date(\n                int(parsed_date.group(1)),  # year\n                int(parsed_date.group(2)),  # month\n                int(parsed_date.group(3))   # day\n            )\n        else:\n            raise ValueError\n\n    return result", "response": "Given a date in YYYY - MM - DD returns a Python date object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef translate_key_to_config(p_key):\n    if len(p_key) > 1:\n        key = p_key.capitalize()\n        if key.startswith('Ctrl') or key.startswith('Meta'):\n            key = key[0] + '-' + key[5:]\n        key = '<' + key + '>'\n    else:\n        key = p_key\n\n    return key", "response": "Translate urwid key event to form understandable by topydo config parser."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a relative date string from a datetime object.", "response": "def humanize_date(p_datetime):\n    \"\"\" Returns a relative date string from a datetime object. \"\"\"\n    now = arrow.now()\n    _date = now.replace(day=p_datetime.day, month=p_datetime.month, year=p_datetime.year)\n    return _date.humanize(now).replace('just now', 'today')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if there are any invalid todo IDs in p_ids list. Returns proper error message if any invalid todo ID is invalid and None otherwise.", "response": "def _check_id_validity(self, p_ids):\n        \"\"\"\n        Checks if there are any invalid todo IDs in p_ids list.\n\n        Returns proper error message if any ID is invalid and None otherwise.\n        \"\"\"\n        errors = []\n        valid_ids = self.todolist.ids()\n\n        if len(p_ids) == 0:\n            errors.append('No todo item was selected')\n        else:\n            errors = [\"Invalid todo ID: {}\".format(todo_id)\n                      for todo_id in p_ids - valid_ids]\n\n        errors = '\\n'.join(errors) if errors else None\n        return errors"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _execute_handler(self, p_command, p_todo_id=None, p_output=None):\n        p_output = p_output or self._output\n        self._console_visible = False\n\n        self._last_cmd = (p_command, p_output == self._output)\n\n        try:\n            p_command = shlex.split(p_command)\n        except ValueError as verr:\n            self._print_to_console('Error: ' + str(verr))\n            return\n\n        try:\n            subcommand, args = get_subcommand(p_command)\n        except ConfigError as cerr:\n            self._print_to_console(\n                'Error: {}. Check your aliases configuration.'.format(cerr))\n            return\n\n        if subcommand is None:\n            self._print_to_console(GENERIC_HELP)\n            return\n\n        env_args = (self.todolist, p_output, self._output, self._input)\n        ids = None\n\n        if '{}' in args:\n            if self._has_marked_todos():\n                ids = self.marked_todos\n            else:\n                ids = {p_todo_id} if p_todo_id else set()\n\n            invalid_ids = self._check_id_validity(ids)\n\n            if invalid_ids:\n                self._print_to_console('Error: ' + invalid_ids)\n                return\n\n        transaction = Transaction(subcommand, env_args, ids)\n        transaction.prepare(args)\n        label = transaction.label\n        self._backup(subcommand, p_label=label)\n\n        try:\n            if transaction.execute():\n                post_archive_action = transaction.execute_post_archive_actions\n                self._post_archive_action = post_archive_action\n                self._post_execute()\n            else:\n                self._rollback()\n        except TypeError:\n            # TODO: show error message\n            pass", "response": "Executes a command and returns a dictionary of the result."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _viewdata_to_view(self, p_data):\n        sorter = Sorter(p_data['sortexpr'], p_data['groupexpr'])\n        filters = []\n\n        if not p_data['show_all']:\n            filters.append(DependencyFilter(self.todolist))\n            filters.append(RelevanceFilter())\n            filters.append(HiddenTagFilter())\n\n        filters += get_filter_list(p_data['filterexpr'].split())\n\n        return UIView(sorter, filters, self.todolist, p_data)", "response": "Converts a dictionary describing a view to an actual UIView instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate the view widget with the data entered in the view widget.", "response": "def _update_view(self, p_data):\n        \"\"\" Creates a view from the data entered in the view widget. \"\"\"\n        view = self._viewdata_to_view(p_data)\n\n        if self.column_mode == _APPEND_COLUMN or self.column_mode == _COPY_COLUMN:\n            self._add_column(view)\n        elif self.column_mode == _INSERT_COLUMN:\n            self._add_column(view, self.columns.focus_position)\n        elif self.column_mode == _EDIT_COLUMN:\n            current_column = self.columns.focus\n\n            current_column.title = p_data['title']\n            current_column.view = view\n\n        self._viewwidget_visible = False\n        self._blur_commandline()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _add_column(self, p_view, p_pos=None):\n        def execute_silent(p_cmd, p_todo_id=None):\n            self._execute_handler(p_cmd, p_todo_id, lambda _: None)\n\n        todolist = TodoListWidget(p_view, p_view.data['title'], self.keymap)\n        urwid.connect_signal(todolist, 'execute_command_silent',\n                             execute_silent)\n        urwid.connect_signal(todolist, 'execute_command', self._execute_handler)\n        urwid.connect_signal(todolist, 'repeat_cmd', self._repeat_last_cmd)\n        urwid.connect_signal(todolist, 'refresh', self.mainloop.screen.clear)\n        urwid.connect_signal(todolist, 'add_pending_action', self._set_alarm)\n        urwid.connect_signal(todolist, 'remove_pending_action', self._remove_alarm)\n        urwid.connect_signal(todolist, 'column_action', self._column_action_handler)\n        urwid.connect_signal(todolist, 'show_keystate', self._print_keystate)\n        urwid.connect_signal(todolist, 'toggle_mark',\n                             self._process_mark_toggle)\n\n        options = self.columns.options(\n            width_type='given',\n            width_amount=config().column_width(),\n            box_widget=True\n        )\n\n        item = (todolist, options)\n\n        if p_pos == None:\n            p_pos = len(self.columns.contents)\n\n        self.columns.contents.insert(p_pos, item)\n\n        self.columns.focus_position = p_pos\n        self._blur_commandline()", "response": "Adds a new column widget with the todos in that view."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _process_mark_toggle(self, p_todo_id, p_force=None):\n        if p_force in ['mark', 'unmark']:\n            action = p_force\n        else:\n            action = 'mark' if p_todo_id not in self.marked_todos else 'unmark'\n\n        if action == 'mark':\n            self.marked_todos.add(p_todo_id)\n            return True\n        else:\n            self.marked_todos.remove(p_todo_id)\n            return False", "response": "Internal method that processes the mark toggle action."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _convert_priority(p_priority):\n    result = 0\n\n    prio_map = {\n        'A': 1,\n        'B': 5,\n        'C': 6,\n        'D': 7,\n        'E': 8,\n        'F': 9,\n    }\n\n    try:\n        result = prio_map[p_priority]\n    except KeyError:\n        if p_priority:\n            # todos with no priority have priority None, and result of this\n            # function will be 0. For all other letters, return 9 (lowest\n            # priority in RFC 2445).\n            result = 9\n\n    return result", "response": "Converts a todo. txt priority to an iCalendar priority."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a Todo instance to an icalendar Todo instance.", "response": "def _convert_todo(self, p_todo):\n        \"\"\" Converts a Todo instance (Topydo) to an icalendar Todo instance. \"\"\"\n\n        def _get_uid(p_todo):\n            \"\"\"\n            Gets a unique ID from a todo item, stored by the ical tag. If the\n            tag is not present, a random value is assigned to it and returned.\n            \"\"\"\n\n            def generate_uid(p_length=4):\n                \"\"\"\n                Generates a random string of the given length, used as\n                identifier.\n                \"\"\"\n                return ''.join(\n                    random.choice(string.ascii_letters + string.digits)\n                    for i in range(p_length))\n\n            uid = p_todo.tag_value('ical')\n            if not uid:\n                uid = generate_uid()\n                p_todo.set_tag('ical', uid)\n                self.todolist.dirty = True\n\n            return uid\n\n        result = self.icalendar.Todo()\n\n        # this should be called first, it may set the ical: tag and therefore\n        # change the source() output.\n        result['uid'] = _get_uid(p_todo)\n\n        result['summary'] = self.icalendar.vText(p_todo.text())\n        result['description'] = self.icalendar.vText(p_todo.source())\n        result.add('priority', _convert_priority(p_todo.priority()))\n\n        start = p_todo.start_date()\n        if start:\n            result.add('dtstart', start)\n\n        due = p_todo.due_date()\n        if due:\n            result.add('due', due)\n\n        created = p_todo.creation_date()\n        if created:\n            result.add('created', created)\n\n        completed = p_todo.completion_date()\n        if completed:\n            completed = datetime.combine(completed, time(0, 0))\n            result.add('completed', completed)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a tag value associated with p_key. Returns p_default if p_key is not set.", "response": "def tag_value(self, p_key, p_default=None):\n        \"\"\"\n        Returns a tag value associated with p_key. Returns p_default if p_key\n        does not exist (which defaults to None).\n        \"\"\"\n        return self.tag_values(p_key)[0] if p_key in self.fields['tags'] else p_default"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef has_tag(self, p_key, p_value=\"\"):\n        tags = self.fields['tags']\n        return p_key in tags and (p_value == \"\" or p_value in tags[p_key])", "response": "Returns true when there is at least one tag with the given key - value combination."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove a tag from the internal todo dictionary. Only those instances with the given value are removed. If the value is empty, all tags with the given key are removed.", "response": "def _remove_tag_helper(self, p_key, p_value):\n        \"\"\"\n        Removes a tag from the internal todo dictionary. Only those instances\n        with the given value are removed. If the value is empty, all tags with\n        the given key are removed.\n        \"\"\"\n        tags = self.fields['tags']\n\n        try:\n            tags[p_key] = [t for t in tags[p_key] if p_value != \"\" and t != p_value]\n            if len(tags[p_key]) == 0:\n                del tags[p_key]\n        except KeyError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_tag(self, p_key, p_value=\"\", p_force_add=False, p_old_value=\"\"):\n        if p_value == \"\":\n            self.remove_tag(p_key, p_old_value)\n            return\n\n        tags = self.fields['tags']\n        value = p_old_value if p_old_value else self.tag_value(p_key)\n\n        if not p_force_add and value:\n            self._remove_tag_helper(p_key, value)\n\n            self.src = re.sub(\n                r'\\b' + p_key + ':' + value + r'\\b',\n                p_key + ':' + p_value,\n                self.src\n            )\n        else:\n            self.src += ' ' + p_key + ':' + p_value\n\n        try:\n            tags[p_key].append(p_value)\n        except KeyError:\n            tags[p_key] = [p_value]", "response": "Sets a occurrence of the tag identified by p_key to p_value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving a tag from the todo.", "response": "def remove_tag(self, p_key, p_value=\"\"):\n        \"\"\"\n        Removes a tag from the todo.\n        When the value is empty (default), all occurrences of the tag will be\n        removed.\n        Else, only those tags with the value will be removed.\n        \"\"\"\n        self._remove_tag_helper(p_key, p_value)\n\n        # when value == \"\", match any value having key p_key\n        value = p_value if p_value != \"\" else r'\\S+'\n        self.src = re.sub(r'\\s?\\b' + p_key + ':' + value + r'\\b', '', self.src)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of tuples with key - value pairs representing tags in this todo item.", "response": "def tags(self):\n        \"\"\"\n        Returns a list of tuples with key-value pairs representing tags in\n        this todo item.\n        \"\"\"\n        tags = self.fields['tags']\n        return [(t, v) for t in tags for v in tags[t]]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the priority of the todo. Must be a single capital letter [ A - Z ]", "response": "def set_priority(self, p_priority):\n        \"\"\"\n        Sets the priority of the todo. Must be a single capital letter [A-Z],\n        or None to unset the priority.\n        Priority remains unchanged when an invalid priority is given, or when\n        the task was completed.\n        \"\"\"\n        if not self.is_completed() and (p_priority is None or\n                                        is_valid_priority(p_priority)):\n            self.fields['priority'] = p_priority\n\n            priority_str = '' if p_priority is None else '(' + p_priority + ') '\n            self.src = re.sub(r'^(\\([A-Z]\\) )?', priority_str, self.src)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_source_text(self, p_text):\n        self.src = p_text.strip()\n        self.fields = parse_line(self.src)", "response": "Sets the todo source text."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the todo as completed and sets the completion date to today.", "response": "def set_completed(self, p_completion_date=date.today()):\n        \"\"\"\n        Marks the todo as complete.\n        Sets the completed flag and sets the completion date to today.\n        \"\"\"\n        if not self.is_completed():\n            self.set_priority(None)\n\n            self.fields['completed'] = True\n            self.fields['completionDate'] = p_completion_date\n\n            self.src = re.sub(r'^(\\([A-Z]\\) )?',\n                              'x ' + p_completion_date.isoformat() + ' ',\n                              self.src)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the creation date of a todo. Should be passed a date object.", "response": "def set_creation_date(self, p_date=date.today()):\n        \"\"\"\n        Sets the creation date of a todo. Should be passed a date object.\n        \"\"\"\n        self.fields['creationDate'] = p_date\n\n        # not particularly pretty, but inspired by\n        # http://bugs.python.org/issue1519638 non-existent matches trigger\n        # exceptions, hence the lambda\n        self.src = re.sub(\n            r'^(x \\d{4}-\\d{2}-\\d{2} |\\([A-Z]\\) )?(\\d{4}-\\d{2}-\\d{2} )?(.*)$',\n            lambda m:\n            u\"{}{} {}\".format(m.group(1) or '', p_date.isoformat(),\n                                m.group(3)), self.src)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate the todo list according to the todos in the view associated with this list.", "response": "def update(self):\n        \"\"\"\n        Updates the todo list according to the todos in the view associated\n        with this list.\n        \"\"\"\n        old_focus_position = self.todolist.focus\n        id_length = max_id_length(self.view.todolist.count())\n\n        del self.todolist[:]\n\n        for group, todos in self.view.groups.items():\n            if len(self.view.groups) > 1:\n                grouplabel = \", \".join(group)\n                self.todolist.append(urwid.Text(grouplabel))\n                self.todolist.append(urwid.Divider('-'))\n\n            for todo in todos:\n                todowidget = TodoWidget.create(todo, id_length)\n                todowidget.number = self.view.todolist.number(todo)\n                self.todolist.append(todowidget)\n                self.todolist.append(urwid.Divider('-'))\n\n        if old_focus_position:\n            try:\n                self.todolist.set_focus(old_focus_position)\n            except IndexError:\n                # scroll to the bottom if the last item disappeared from column\n                # -2 for the same reason as in self._scroll_to_bottom()\n                self.todolist.set_focus(len(self.todolist) - 2)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _execute_on_selected(self, p_cmd_str, p_execute_signal):\n        try:\n            todo = self.listbox.focus.todo\n            todo_id = str(self.view.todolist.number(todo))\n\n            urwid.emit_signal(self, p_execute_signal, p_cmd_str, todo_id)\n\n            # force screen redraw after editing\n            if p_cmd_str.startswith('edit'):\n                urwid.emit_signal(self, 'refresh')\n        except AttributeError:\n            # No todo item selected\n            pass", "response": "Executes command specified by p_cmd_str on selected todo item."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef resolve_action(self, p_action_str, p_size=None):\n        if p_action_str.startswith(('cmd ', 'cmdv ')):\n            prefix, cmd = p_action_str.split(' ', 1)\n            execute_signal = get_execute_signal(prefix)\n\n            if '{}' in cmd:\n                self._execute_on_selected(cmd, execute_signal)\n            else:\n                urwid.emit_signal(self, execute_signal, cmd)\n        else:\n            self.execute_builtin_action(p_action_str, p_size)", "response": "Resolves the action specified in p_action_str and executes it if it is built - in."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexecutes built - in action specified in p_action_str.", "response": "def execute_builtin_action(self, p_action_str, p_size=None):\n        \"\"\"\n        Executes built-in action specified in p_action_str.\n\n        Currently supported actions are: 'up', 'down', 'home', 'end',\n        'first_column', 'last_column', 'prev_column', 'next_column',\n        'append_column', 'insert_column', 'edit_column', 'delete_column',\n        'copy_column', swap_right', 'swap_left', 'postpone', 'postpone_s',\n        'pri', 'mark', 'mark_all, 'reset' and 'repeat'.\n        \"\"\"\n        column_actions = ['first_column',\n                          'last_column',\n                          'prev_column',\n                          'next_column',\n                          'append_column',\n                          'insert_column',\n                          'edit_column',\n                          'delete_column',\n                          'copy_column',\n                          'swap_left',\n                          'swap_right',\n                          'reset',\n                          ]\n\n        if p_action_str in column_actions:\n            urwid.emit_signal(self, 'column_action', p_action_str)\n        elif p_action_str in ['up', 'down']:\n            self.listbox.keypress(p_size, p_action_str)\n        elif p_action_str == 'home':\n            self._scroll_to_top(p_size)\n        elif p_action_str == 'end':\n            self._scroll_to_bottom(p_size)\n        elif p_action_str in ['postpone', 'postpone_s']:\n            pass\n        elif p_action_str == 'pri':\n            pass\n        elif p_action_str == 'mark':\n            self._toggle_marked_status()\n        elif p_action_str == 'mark_all':\n            self._mark_all()\n        elif p_action_str == 'repeat':\n            self._repeat_cmd()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates action waiting for execution and forwards it to mainloop.", "response": "def _add_pending_action(self, p_action, p_size):\n        \"\"\"\n        Creates action waiting for execution and forwards it to the mainloop.\n        \"\"\"\n        def generate_callback():\n            def callback(*args):\n                self.resolve_action(p_action, p_size)\n                self.keystate = None\n\n            return callback\n\n        urwid.emit_signal(self, 'add_pending_action', generate_callback())"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn True if postpone command is called and False otherwise.", "response": "def _postpone_selected(self, p_pattern, p_mode):\n        \"\"\"\n        Postpones selected todo item by <COUNT><PERIOD>.\n\n        Returns True after 'postpone' command is called (i.e. p_pattern is valid\n        <PERIOD>), False when p_pattern is invalid and None if p_pattern is\n        digit (i.e. part of <COUNT>).\n\n        p_pattern accepts digit (<COUNT>) or one of the <PERIOD> letters:\n        'd'(ay), 'w'(eek), 'm'(onth), 'y'(ear). If digit is specified, it is\n        appended to _pp_offset attribute. If p_pattern contains one of the\n        <PERIOD> letters, 'postpone' command is forwarded to execution with\n        value of _pp_offset attribute used as <COUNT>. If _pp_offset is None,\n        <COUNT> is set to 1.\n\n        p_mode should be one of 'postpone_s' or 'postpone'. It decides whether\n        'postpone' command should be called with or without '-s' flag.\n        \"\"\"\n        if p_pattern.isdigit():\n            if not self._pp_offset:\n                self._pp_offset = ''\n            self._pp_offset += p_pattern\n            result = None\n        else:\n            if p_pattern in ['d', 'w', 'm', 'y', 'b']:\n                offset = self._pp_offset or '1'\n                if p_mode == 'postpone':\n                    pp_cmd = 'cmd postpone {} '\n                else:\n                    pp_cmd = 'cmd postpone -s {} '\n                pp_cmd += offset + p_pattern\n                self.resolve_action(pp_cmd)\n                result = True\n            self._pp_offset = None\n            result = False\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read(self):\n        todos = []\n        try:\n            todofile = codecs.open(self.path, 'r', encoding=\"utf-8\")\n            todos = todofile.readlines()\n            todofile.close()\n        except IOError:\n            pass\n\n        return todos", "response": "Reads the todo. txt file and returns a list of todo items."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write(self, p_todos):\n\n        todofile = codecs.open(self.path, 'w', encoding=\"utf-8\")\n\n        if p_todos is list:\n            for todo in p_todos:\n                todofile.write(str(todo))\n        else:\n            todofile.write(p_todos)\n\n        todofile.write(\"\\n\")\n\n        todofile.close()", "response": "Writes all the todo items to the todo. txt file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef main():\n    try:\n        args = sys.argv[1:]\n\n        try:\n            _, args = getopt.getopt(args, MAIN_OPTS, MAIN_LONG_OPTS)\n        except getopt.GetoptError as e:\n            error(str(e))\n            sys.exit(1)\n\n        if args[0] == 'prompt':\n            try:\n                from topydo.ui.prompt.Prompt import PromptApplication\n                PromptApplication().run()\n            except ImportError:\n                error(\"Some additional dependencies for prompt mode were not installed, please install with 'pip3 install topydo[prompt]'\")\n        elif args[0] == 'columns':\n            try:\n                from topydo.ui.columns.Main import UIApplication\n                UIApplication().run()\n            except ImportError:\n                error(\"Some additional dependencies for column mode were not installed, please install with 'pip3 install topydo[columns]'\")\n            except NameError as err:\n                if _WINDOWS:\n                    error(\"Column mode is not supported on Windows.\")\n                else:\n                    error(\"Could not load column mode: {}\".format(err))\n        else:\n            CLIApplication().run()\n    except IndexError:\n        CLIApplication().run()", "response": "Main entry point of the CLI."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the chosen number of the tag value to process or None if no value is selected.", "response": "def _choose(self):\n        \"\"\"\n        Returns the chosen number of the tag value to process (or \"all\").\n        \"\"\"\n        answer = \"all\"\n\n        if not self.force:\n            for i, value in enumerate(self.current_values):\n                self.out(\"{:>2d}. {}\".format(i + 1, value))\n\n            answer = self.prompt(\n                'Which value to remove? Enter number or \"all\": ')\n\n        if answer != \"all\":\n            try:\n                answer = int(answer) - 1\n\n                if answer < 0 or answer >= len(self.current_values):\n                    answer = None\n            except ValueError:\n                answer = None\n\n        return answer"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a Command instance for the given subcommand.", "response": "def get_subcommand(p_args):\n    \"\"\"\n    Retrieves the to-be executed Command and returns a tuple (Command, args).\n\n    If args is an empty list, then the Command that corresponds with the\n    default command specified in the configuration will be returned.\n\n    If the first argument is 'help' and the second a valid subcommand, the\n    help text this function returns the Command instance of that subcommand\n    with a single argument 'help' (every Command has a help text).\n\n    If no valid command could be found, the subcommand part of the tuple\n    is None.\n    \"\"\"\n    def import_subcommand(p_subcommand):\n        \"\"\"\n        Returns the class of the requested subcommand. An invalid p_subcommand\n        will result in an ImportError, since this is a programming mistake\n        (most likely an error in the SUBCOMMAND_MAP).\n        \"\"\"\n        classname = SUBCOMMAND_MAP[p_subcommand]\n        modulename = 'topydo.commands.{}'.format(classname)\n\n        __import__(modulename, globals(), locals(), [classname], 0)\n        return getattr(sys.modules[modulename], classname)\n\n    def join_args(p_cli_args, p_alias_args):\n        \"\"\"\n        Returns properly joined args from alias definition and from user input.\n        \"\"\"\n        if '{}' in p_alias_args:\n            pos = p_alias_args.index('{}')\n            args = p_alias_args[:pos] + p_cli_args + p_alias_args[pos+1:]\n        else:\n            args = p_alias_args + p_cli_args\n\n        return args\n\n    def resolve_alias(p_alias, p_args):\n        \"\"\"\n        Resolves a subcommand alias and returns a tuple (Command, args).\n\n        If alias resolves to non-existent command, main help message is\n        returned.\n        \"\"\"\n        try:\n            real_subcommand, alias_args = alias_map[p_alias]\n        except ValueError as ve:\n            raise ConfigError(alias_map[p_alias]) from ve\n\n        try:\n            result = import_subcommand(real_subcommand)\n            args = join_args(p_args, alias_args)\n            return (result, args)\n        except KeyError:\n            return get_subcommand(['help'])\n\n    result = None\n    args = p_args\n    alias_map = config().aliases()\n\n    try:\n        subcommand = p_args[0]\n\n        if subcommand in alias_map:\n            result, args = resolve_alias(subcommand, args[1:])\n        elif subcommand in SUBCOMMAND_MAP:\n            result = import_subcommand(subcommand)\n            args = args[1:]\n        elif subcommand == 'help':\n            try:\n                subcommand = args[1]\n\n                if subcommand in SUBCOMMAND_MAP:\n                    args = [subcommand, 'help']\n                    return get_subcommand(args)\n            except IndexError:\n                # will result in empty result\n                pass\n        else:\n            p_command = config().default_command()\n            if p_command in alias_map:\n                result, args = resolve_alias(p_command, args)\n            elif p_command in SUBCOMMAND_MAP:\n                result = import_subcommand(p_command)\n                # leave args unchanged\n    except IndexError:\n        p_command = config().default_command()\n        if p_command in alias_map:\n            result, args = resolve_alias(p_command, args)\n        elif p_command in SUBCOMMAND_MAP:\n            result = import_subcommand(p_command)\n\n    return (result, args)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True when the given task is due next Monday.", "response": "def is_due_next_monday(p_todo):\n    \"\"\" Returns True when today is Friday (or the weekend) and the given task\n    is due next Monday.\n    \"\"\"\n    today = date.today()\n    due = p_todo.due_date()\n\n    return due and due.weekday() == 0 and today.weekday() >= 4 and \\\n        p_todo.days_till_due() <= 3"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncalculate the importance of a given task.", "response": "def importance(p_todo, p_ignore_weekend=config().ignore_weekends()):\n    \"\"\"\n    Calculates the importance of the given task.\n    Returns an importance of zero when the task has been completed.\n\n    If p_ignore_weekend is True, the importance value of the due date will be\n    calculated as if Friday is immediately followed by Monday. This in case of\n    a todo list at the office and you don't work during the weekends (you\n    don't, right?)\n    \"\"\"\n    result = 2\n\n    priority = p_todo.priority()\n    result += IMPORTANCE_VALUE[priority] if priority in IMPORTANCE_VALUE else 0\n\n    if p_todo.has_tag(config().tag_due()):\n        days_left = p_todo.days_till_due()\n\n        if days_left >= 7 and days_left < 14:\n            result += 1\n        elif days_left >= 2 and days_left < 7:\n            result += 2\n        elif days_left >= 1 and days_left < 2:\n            result += 3\n        elif days_left >= 0 and days_left < 1:\n            result += 5\n        elif days_left < 0:\n            result += 6\n\n    if p_ignore_weekend and is_due_next_monday(p_todo):\n        result += 1\n\n    if p_todo.has_tag(config().tag_star()):\n        result += 1\n\n    return result if not p_todo.is_completed() else 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmaintains the dependency graph according to the given todo.", "response": "def _maintain_dep_graph(self, p_todo):\n        \"\"\"\n        Makes sure that the dependency graph is consistent according to the\n        given todo.\n        \"\"\"\n        dep_id = p_todo.tag_value('id')\n        # maintain dependency graph\n        if dep_id:\n            self._parentdict[dep_id] = p_todo\n            self._depgraph.add_node(hash(p_todo))\n\n            # connect all tasks we have in memory so far that refer to this\n            # task\n            for dep in \\\n                    [dep for dep in self._todos if dep.has_tag('p', dep_id)]:\n\n                self._add_edge(p_todo, dep, dep_id)\n\n        for dep_id in p_todo.tag_values('p'):\n            try:\n                parent = self._parentdict[dep_id]\n                self._add_edge(parent, p_todo, dep_id)\n            except KeyError:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting a todo item from the list.", "response": "def delete(self, p_todo, p_leave_tags=False):\n        \"\"\" Deletes a todo item from the list. \"\"\"\n        try:\n            number = self._todos.index(p_todo)\n\n            if p_todo.has_tag('id'):\n                for child in self.children(p_todo):\n                    self.remove_dependency(p_todo, child, p_leave_tags)\n\n            if p_todo.has_tag('p'):\n                for parent in self.parents(p_todo):\n                    self.remove_dependency(parent, p_todo, p_leave_tags)\n\n            del self._todos[number]\n            self._update_todo_ids()\n\n            self.dirty = True\n        except ValueError:\n            # todo item couldn't be found, ignore\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_dependency(self, p_from_todo, p_to_todo):\n        def find_next_id():\n            \"\"\"\n            Find a new unused ID.\n            Unused means that no task has it as an 'id' value or as a 'p'\n            value.\n            \"\"\"\n            def id_exists(p_id):\n                \"\"\"\n                Returns True if there exists a todo with the given parent ID.\n                \"\"\"\n                for todo in self._todos:\n                    number = str(p_id)\n                    if todo.has_tag('id', number) or todo.has_tag('p', number):\n                        return True\n\n                return False\n\n            new_id = 1\n            while id_exists(new_id):\n                new_id += 1\n\n            return str(new_id)\n\n        def append_projects_to_subtodo():\n            \"\"\"\n            Appends projects in the parent todo item that are not present in\n            the sub todo item.\n            \"\"\"\n            if config().append_parent_projects():\n                for project in p_from_todo.projects() - p_to_todo.projects():\n                    self.append(p_to_todo, \"+{}\".format(project))\n\n        def append_contexts_to_subtodo():\n            \"\"\"\n            Appends contexts in the parent todo item that are not present in\n            the sub todo item.\n            \"\"\"\n            if config().append_parent_contexts():\n                for context in p_from_todo.contexts() - p_to_todo.contexts():\n                    self.append(p_to_todo, \"@{}\".format(context))\n\n        if p_from_todo != p_to_todo and not self._depgraph.has_edge(\n                hash(p_from_todo), hash(p_to_todo)):\n\n            dep_id = None\n            if p_from_todo.has_tag('id'):\n                dep_id = p_from_todo.tag_value('id')\n            else:\n                dep_id = find_next_id()\n                p_from_todo.set_tag('id', dep_id)\n\n            p_to_todo.add_tag('p', dep_id)\n            self._add_edge(p_from_todo, p_to_todo, dep_id)\n            append_projects_to_subtodo()\n            append_contexts_to_subtodo()\n            self.dirty = True", "response": "Adds a dependency from task 1 to task 2."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving a dependency between two todos.", "response": "def remove_dependency(self, p_from_todo, p_to_todo, p_leave_tags=False):\n        \"\"\" Removes a dependency between two todos. \"\"\"\n        dep_id = p_from_todo.tag_value('id')\n\n        if dep_id:\n            self._depgraph.remove_edge(hash(p_from_todo), hash(p_to_todo))\n            self.dirty = True\n\n        # clean dangling dependency tags\n        if dep_id and not p_leave_tags:\n            p_to_todo.remove_tag('p', dep_id)\n\n            if not self.children(p_from_todo, True):\n                p_from_todo.remove_tag('id')\n                del self._parentdict[dep_id]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of parent todos that depend on the given todo.", "response": "def parents(self, p_todo, p_only_direct=False):\n        \"\"\"\n        Returns a list of parent todos that (in)directly depend on the\n        given todo.\n        \"\"\"\n        parents = self._depgraph.incoming_neighbors(\n            hash(p_todo), not p_only_direct)\n        return [self._tododict[parent] for parent in parents]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef children(self, p_todo, p_only_direct=False):\n        children = \\\n            self._depgraph.outgoing_neighbors(hash(p_todo), not p_only_direct)\n        return [self._tododict[child] for child in children]", "response": "Returns a list of child todos that the given todo depends\n        on."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef clean_dependencies(self):\n        def remove_tag(p_todo, p_tag, p_value):\n            \"\"\"\n            Removes a tag from a todo item.\n            \"\"\"\n            p_todo.remove_tag(p_tag, p_value)\n            self.dirty = True\n\n        def clean_parent_relations():\n            \"\"\"\n            Remove id: tags for todos without child todo items.\n            \"\"\"\n\n            for todo in [todo for todo in self._todos if todo.has_tag('id')]:\n                value = todo.tag_value('id')\n                if not self._depgraph.has_edge_id(value):\n                    remove_tag(todo, 'id', value)\n                    del self._parentdict[value]\n\n        def clean_orphan_relations():\n            \"\"\"\n            Remove p: tags for todos referring to a parent that is not in the\n            dependency graph anymore.\n            \"\"\"\n\n            for todo in [todo for todo in self._todos if todo.has_tag('p')]:\n                for value in todo.tag_values('p'):\n                    parent = self.todo_by_dep_id(value)\n\n                    if not self._depgraph.has_edge(hash(parent), hash(todo)):\n                        remove_tag(todo, 'p', value)\n\n        self._depgraph.transitively_reduce()\n        clean_parent_relations()\n        clean_orphan_relations()", "response": "Cleans the dependency graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _convert_todo(p_todo):\n    creation_date = p_todo.creation_date()\n    completion_date = p_todo.completion_date()\n\n    result = {\n        'source': p_todo.source(),\n        'text': p_todo.text(),\n        'priority': p_todo.priority(),\n        'completed': p_todo.is_completed(),\n        'tags': p_todo.tags(),\n        'projects': list(p_todo.projects()),\n        'contexts': list(p_todo.contexts()),\n        'creation_date':\n            creation_date.isoformat() if creation_date else None,\n        'completion_date':\n            completion_date.isoformat() if completion_date else None\n    }\n\n    return result", "response": "Converts a Todo instance to a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_backup_path():\n    dirname, filename = path.split(path.splitext(config().todotxt())[0])\n    filename = '.' + filename + '.bak'\n\n    return path.join(dirname, filename)", "response": "Returns full path and filename of backup file"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _read(self):\n        self.json_file.seek(0)\n        try:\n            data = zlib.decompress(self.json_file.read())\n            self.backup_dict = json.loads(data.decode('utf-8'))\n        except (EOFError, zlib.error):\n            self.backup_dict = {}", "response": "Reads backup file from json_file property and sets backup_dict property\n        with data deserialized from that file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites data from backup_dict property in serialized and compressed form to json_file property.", "response": "def _write(self):\n        \"\"\"\n        Writes data from backup_dict property in serialized and compressed form\n        to backup file pointed in json_file property.\n        \"\"\"\n        self.json_file.seek(0)\n        self.json_file.truncate()\n        dump = json.dumps(self.backup_dict)\n        dump_c = zlib.compress(dump.encode('utf-8'))\n        self.json_file.write(dump_c)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save(self, p_todolist):\n        self._trim()\n\n        current_hash = hash_todolist(p_todolist)\n        list_todo = (self.todolist.print_todos()+'\\n').splitlines(True)\n        try:\n            list_archive = (self.archive.print_todos()+'\\n').splitlines(True)\n        except AttributeError:\n            list_archive = []\n\n        self.backup_dict[self.timestamp] = (list_todo, list_archive,  self.label)\n\n        index = self._get_index()\n        index.insert(0, (self.timestamp, current_hash))\n        self._save_index(index)\n\n        self._write()\n        self.close()", "response": "Save a tuple with archive todolist and command with its arguments\n        into the backup file with the unix timestamp as the key."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete(self, p_timestamp=None, p_write=True):\n        timestamp = p_timestamp or self.timestamp\n        index = self._get_index()\n\n        try:\n            del self.backup_dict[timestamp]\n            index.remove(index[[change[0] for change in index].index(timestamp)])\n            self._save_index(index)\n\n            if p_write:\n                self._write()\n        except KeyError:\n            pass", "response": "Removes backup from the backup file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving oldest backups that exceed the limit configured in backup_count option.", "response": "def _trim(self):\n        \"\"\"\n        Removes oldest backups that exceed the limit configured in backup_count\n        option.\n\n        Does not write back to file system, make sure to call self._write()\n        afterwards.\n        \"\"\"\n        index = self._get_index()\n        backup_limit = config().backup_count() - 1\n\n        for changeset in index[backup_limit:]:\n            self.delete(changeset[0], p_write=False)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_backup(self, p_todolist=None, p_timestamp=None):\n        if not p_timestamp:\n            change_hash = hash_todolist(p_todolist)\n            index = self._get_index()\n            self.timestamp = index[[change[1] for change in index].index(change_hash)][0]\n        else:\n            self.timestamp = p_timestamp\n\n        d = self.backup_dict[self.timestamp]\n\n        self.todolist = TodoList(d[0])\n        self.archive = TodoList(d[1])\n        self.label = d[2]", "response": "Reads a backup file and sets the timestamp to the first entry in the dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef apply(self, p_todolist, p_archive):\n        if self.todolist and p_todolist:\n            p_todolist.replace(self.todolist.todos())\n\n        if self.archive and p_archive:\n            p_archive.replace(self.archive.todos())", "response": "Applies backup on supplied p_todolist."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pretty_printer_factory(p_todolist, p_additional_filters=None):\n    p_additional_filters = p_additional_filters or []\n\n    printer = PrettyPrinter()\n    printer.add_filter(PrettyPrinterNumbers(p_todolist))\n\n    for ppf in p_additional_filters:\n        printer.add_filter(ppf)\n\n    # apply colors at the last step, the ANSI codes may confuse the\n    # preceding filters.\n    printer.add_filter(PrettyPrinterColorFilter())\n\n    return printer", "response": "Returns a pretty printer suitable for ls and dep subcommands."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef print_todo(self, p_todo):\n        todo_str = p_todo.source()\n\n        for ppf in self.filters:\n            todo_str = ppf.filter(todo_str, p_todo)\n\n        return TopydoString(todo_str)", "response": "Given a todo item print it."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef group(self, p_todos):\n        # preorder todos for the group sort\n        p_todos = _apply_sort_functions(p_todos, self.pregroupfunctions)\n\n        # initialize result with a single group\n        result = OrderedDict([((), p_todos)])\n\n        for (function, label), _ in self.groupfunctions:\n            oldresult = result\n            result = OrderedDict()\n            for oldkey, oldgroup in oldresult.items():\n                for key, _group in groupby(oldgroup, function):\n                    newgroup = list(_group)\n\n                    if not isinstance(key, list):\n                        key = [key]\n\n                    for subkey in key:\n                        subkey = \"{}: {}\".format(label, subkey)\n                        newkey = oldkey + (subkey,)\n\n                        if newkey in result:\n                            result[newkey] = result[newkey] + newgroup\n                        else:\n                            result[newkey] = newgroup\n\n        # sort all groups\n        for key, _group in result.items():\n            result[key] = self.sort(_group)\n\n        return result", "response": "Groups the todos according to the given group string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef humanize_dates(p_due=None, p_start=None, p_creation=None):\n    dates_list = []\n    if p_creation:\n        dates_list.append(humanize_date(p_creation))\n    if p_due:\n        dates_list.append('due ' + humanize_date(p_due))\n    if p_start:\n        now = arrow.now().date()\n        dates_list.append('{} {}'.format(\n            'started' if p_start <= now else 'starts',\n            humanize_date(p_start)\n        ))\n\n    return ', '.join(dates_list)", "response": "Returns a string with humanized versions of p_due p_start and p_creation."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _strip_placeholder_braces(p_matchobj):\n    before = p_matchobj.group('before') or ''\n    placeholder = p_matchobj.group('placeholder')\n    after = p_matchobj.group('after') or ''\n    whitespace = p_matchobj.group('whitespace') or ''\n\n    return before + '%' + placeholder + after + whitespace", "response": "Returns a string with conditional braces around placeholder stripped and\n    percent sign glued into placeholder character."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _truncate(p_str, p_repl):\n    # 4 is for '...' and an extra space at the end\n    text_lim = _columns() - len(escape_ansi(p_str)) - 4\n    truncated_str = re.sub(re.escape(p_repl), p_repl[:text_lim] + '...', p_str)\n\n    return truncated_str", "response": "Truncates a string with the given repl."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _right_align(p_str):\n    to_fill = _columns() - len(escape_ansi(p_str))\n\n    if to_fill > 0:\n        p_str = re.sub('\\t', ' '*to_fill, p_str)\n    else:\n        p_str = re.sub('\\t', ' ', p_str)\n\n    return p_str", "response": "Returns p_str with content after <TAB > character aligned right."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse(self, p_todo):\n        parsed_list = []\n        repl_trunc = None\n\n        for substr, placeholder, getter in self.format_list:\n            repl = getter(p_todo) if getter else ''\n            pattern = MAIN_PATTERN.format(ph=placeholder)\n\n            if placeholder == 'S':\n                repl_trunc = repl\n\n            try:\n                if repl == '':\n                    substr = re.sub(pattern, '', substr)\n                else:\n                    substr = re.sub(pattern, _strip_placeholder_braces, substr)\n                    substr = re.sub(r'(?<!\\\\)%({ph}|\\[{ph}\\])'.format(ph=placeholder), repl, substr)\n            except re.error:\n                raise ListFormatError\n\n            parsed_list.append(substr)\n\n        parsed_str = _unescape_percent_sign(''.join(parsed_list))\n        parsed_str = _remove_redundant_spaces(parsed_str)\n\n        if self.one_line and len(escape_ansi(parsed_str)) >= _columns():\n            parsed_str = _truncate(parsed_str, repl_trunc)\n\n        if re.search('.*\\t', parsed_str):\n            parsed_str = _right_align(parsed_str)\n\n        return parsed_str.rstrip()", "response": "Parses the format_string attribute of the list of all available allCOOKIE names and returns a string with allCOOKIE names substituted by content obtained from p_todo."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _load_file(self):\n        self.todolist.erase()\n        self.todolist.add_list(self.todofile.read())\n        self.completer = PromptCompleter(self.todolist)", "response": "Reads the todo. txt file and loads it into the todo list\n        instance."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef execute(self):\n        if self.args and self.argument(0) == \"help\":\n            self.error(self.usage() + \"\\n\\n\" + self.help())\n            return False\n\n        return True", "response": "Execute the command. Intercepts the help subsubcommand to show the help text."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef argument(self, p_number):\n        try:\n            return self.args[p_number]\n        except IndexError as ie:\n            raise InvalidCommandArgument from ie", "response": "Retrieves a value from the argument list at the given position."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef append(self, p_string, p_color):\n        self.colors[len(self.data)] = p_color\n        self.data += p_string", "response": "Append a string to the end of the log."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves the config instance.", "response": "def config(p_path=None, p_overrides=None):\n    \"\"\"\n    Retrieve the config instance.\n\n    If a path is given, the instance is overwritten by the one that supplies an\n    additional filename (for testability). Moreover, no other configuration\n    files will be read when a path is given.\n\n    Overrides will discard a setting in any configuration file and use the\n    passed value instead. Structure: (section, option) => value\n    The previous configuration instance will be discarded.\n    \"\"\"\n    if not config.instance or p_path is not None or p_overrides is not None:\n        try:\n            config.instance = _Config(p_path, p_overrides)\n        except configparser.ParsingError as perr:\n            raise ConfigError(str(perr)) from perr\n\n    return config.instance"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning 0 16 or 256 representing the number of colors that should be used in the output.", "response": "def colors(self, p_hint_possible=True):\n        \"\"\"\n        Returns 0, 16 or 256 representing the number of colors that should be\n        used in the output.\n\n        A hint can be passed whether the device that will output the text\n        supports colors.\n        \"\"\"\n        lookup = {\n            'false': 0,\n            'no': 0,\n            '0': 0,\n            '1': 16,\n            'true': 16,\n            'yes': 16,\n            '16': 16,\n            '256': 256,\n        }\n\n        try:\n            forced = self.cp.get('topydo', 'force_colors') == '1'\n        except ValueError:\n            forced = self.defaults['topydo']['force_colors'] == '1'\n\n        try:\n            colors = lookup[self.cp.get('topydo', 'colors').lower()]  # pylint: disable=no-member\n        except ValueError:\n            colors = lookup[self.defaults['topydo']['colors'].lower()]  # pylint: disable=no-member\n        except KeyError:\n            # for invalid values or 'auto'\n            colors = 16 if p_hint_possible else 0\n\n        # disable colors when no colors are enforced on the commandline and\n        # color support is determined automatically\n        return 0 if not forced and not p_hint_possible else colors"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of tags to be hidden from the ls output.", "response": "def hidden_tags(self):\n        \"\"\" Returns a list of tags to be hidden from the 'ls' output. \"\"\"\n        hidden_tags = self.cp.get('ls', 'hide_tags')\n        # pylint: disable=no-member\n        return [] if hidden_tags == '' else [tag.strip() for tag in\n                                             hidden_tags.split(',')]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef hidden_item_tags(self):\n        hidden_item_tags = self.cp.get('ls', 'hidden_item_tags')\n        # pylint: disable=no-member\n        return [] if hidden_item_tags == '' else [tag.strip() for tag in\n                                                  hidden_item_tags.split(',')]", "response": "Returns a list of tags which hide an item from the ls output."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a dict with priorities as keys and color numbers as values.", "response": "def priority_color(self, p_priority):\n        \"\"\"\n        Returns a dict with priorities as keys and color numbers as value.\n        \"\"\"\n        def _str_to_dict(p_string):\n            pri_colors_dict = dict()\n            for pri_color in p_string.split(','):\n                pri, color = pri_color.split(':')\n                pri_colors_dict[pri] = Color(color)\n\n            return pri_colors_dict\n\n        try:\n            pri_colors_str = self.cp.get('colorscheme', 'priority_colors')\n\n            if pri_colors_str == '':\n                pri_colors_dict = _str_to_dict('A:-1,B:-1,C:-1')\n            else:\n                pri_colors_dict = _str_to_dict(pri_colors_str)\n        except ValueError:\n            pri_colors_dict = _str_to_dict(self.defaults['colorscheme']['priority_colors'])\n\n        return pri_colors_dict[p_priority] if p_priority in pri_colors_dict else Color('NEUTRAL')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a dictionary with aliases names as keys and pairs of actual subcommand and alias args as values.", "response": "def aliases(self):\n        \"\"\"\n        Returns dict with aliases names as keys and pairs of actual\n        subcommand and alias args as values.\n        \"\"\"\n        aliases = self.cp.items('aliases')\n        alias_dict = dict()\n\n        for alias, meaning in aliases:\n            try:\n                meaning = shlex.split(meaning)\n                real_subcommand = meaning[0]\n                alias_args = meaning[1:]\n                alias_dict[alias] = (real_subcommand, alias_args)\n            except ValueError as verr:\n                alias_dict[alias] = str(verr)\n\n        return alias_dict"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef column_keymap(self):\n        keystates = set()\n\n        shortcuts = self.cp.items('column_keymap')\n        keymap_dict = dict(shortcuts)\n\n        for combo, action in shortcuts:\n            # add all possible prefixes to keystates\n            combo_as_list = re.split('(<[A-Z].+?>|.)', combo)[1::2]\n            if len(combo_as_list) > 1:\n                keystates |= set(accumulate(combo_as_list[:-1]))\n\n            if action in ['pri', 'postpone', 'postpone_s']:\n                keystates.add(combo)\n\n            if action == 'pri':\n                for c in ascii_lowercase:\n                    keymap_dict[combo + c] = 'cmd pri {} ' + c\n\n        return (keymap_dict, keystates)", "response": "Returns a keymap and keystates used in column mode"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef editor(self):\n        result = 'vi'\n        if 'TOPYDO_EDITOR' in os.environ and os.environ['TOPYDO_EDITOR']:\n            result = os.environ['TOPYDO_EDITOR']\n        else:\n            try:\n                result = str(self.cp.get('edit', 'editor'))\n            except configparser.NoOptionError:\n                if 'EDITOR' in os.environ and os.environ['EDITOR']:\n                    result = os.environ['EDITOR']\n\n        return shlex.split(result)", "response": "Returns the editor to invoke. It returns a list with the first position and its arguments in the remainder."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef execute(self):\n        if not super().execute():\n            return False\n\n        self.printer.add_filter(PrettyPrinterNumbers(self.todolist))\n        self._process_flags()\n\n        if self.from_file:\n            try:\n                new_todos = self.get_todos_from_file()\n\n                for todo in new_todos:\n                    self._add_todo(todo)\n            except (IOError, OSError):\n                self.error('File not found: ' + self.from_file)\n        else:\n            if self.text:\n                self._add_todo(self.text)\n            else:\n                self.error(self.usage())", "response": "Adds a todo item to the list."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef advance_recurring_todo(p_todo, p_offset=None, p_strict=False):\n    todo = Todo(p_todo.source())\n    pattern = todo.tag_value('rec')\n\n    if not pattern:\n        raise NoRecurrenceException()\n    elif pattern.startswith('+'):\n        p_strict = True\n        # strip off the +\n        pattern = pattern[1:]\n\n    if p_strict:\n        offset = p_todo.due_date() or p_offset or date.today()\n    else:\n        offset = p_offset or date.today()\n\n    length = todo.length()\n    new_due = relative_date_to_date(pattern, offset)\n\n    if not new_due:\n        raise NoRecurrenceException()\n\n    # pylint: disable=E1103\n    todo.set_tag(config().tag_due(), new_due.isoformat())\n\n    if todo.start_date():\n        new_start = new_due - timedelta(length)\n        todo.set_tag(config().tag_start(), new_start.isoformat())\n\n    todo.set_creation_date(date.today())\n\n    return todo", "response": "Given a Todo item returns a new Todo item with the dates shifted according to the recurrence rule."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_table_size(p_alphabet, p_num):\n    try:\n        for width, size in sorted(_TABLE_SIZES[len(p_alphabet)].items()):\n            if p_num < size * 0.01:\n                return width, size\n    except KeyError:\n        pass\n\n    raise _TableSizeException('Could not find appropriate table size for given alphabet')", "response": "Returns the table size for the given alphabet and number."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef hash_list_values(p_list, p_key=lambda i: i):  # pragma: no branch\n    def to_base(p_alphabet, p_value):\n        \"\"\"\n        Converts integer to text ID with characters from the given alphabet.\n\n        Based on answer at\n        https://stackoverflow.com/questions/1181919/python-base-36-encoding\n        \"\"\"\n        result = ''\n        while p_value:\n            p_value, i = divmod(p_value, len(p_alphabet))\n            result = p_alphabet[i] + result\n\n        return result or p_alphabet[0]\n\n    result = []\n    used = set()\n    alphabet = config().identifier_alphabet()\n\n    try:\n        _, size = _get_table_size(alphabet, len(p_list))\n    except _TableSizeException:\n        alphabet = _DEFAULT_ALPHABET\n        _, size = _get_table_size(alphabet, len(p_list))\n\n    for item in p_list:\n        # obtain the to-be-hashed value\n        raw_value = p_key(item)\n\n        # hash\n        hasher = sha1()\n        hasher.update(raw_value.encode('utf-8'))\n        hash_value = int(hasher.hexdigest(), 16) % size\n\n        # resolve possible collisions\n        while hash_value in used:\n            hash_value = (hash_value + 1) % size\n\n        used.add(hash_value)\n        result.append((item, to_base(alphabet, hash_value)))\n\n    return result", "response": "Hashes a list of items using the given key function."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef max_id_length(p_num):\n    try:\n        alphabet = config().identifier_alphabet()\n        length, _ = _get_table_size(alphabet, p_num)\n    except _TableSizeException:\n        length, _ = _get_table_size(_DEFAULT_ALPHABET, p_num)\n\n    return length", "response": "Returns the length of the ID used given the number of items that are\n    assigned an ID. Used for padding in lists."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\napplying the colors to the todo string.", "response": "def filter(self, p_todo_str, p_todo):\n        \"\"\" Applies the colors. \"\"\"\n        if config().colors():\n            p_todo_str = TopydoString(p_todo_str, p_todo)\n\n            priority_color = config().priority_color(p_todo.priority())\n\n            colors = [\n                (r'\\B@(\\S*\\w)', AbstractColor.CONTEXT),\n                (r'\\B\\+(\\S*\\w)', AbstractColor.PROJECT),\n                (r'\\b\\S+:[^/\\s]\\S*\\b', AbstractColor.META),\n                (r'(^|\\s)(\\w+:){1}(//\\S+)', AbstractColor.LINK),\n            ]\n\n            # color by priority\n            p_todo_str.set_color(0, priority_color)\n\n            for pattern, color in colors:\n                for match in re.finditer(pattern, p_todo_str.data):\n                    p_todo_str.set_color(match.start(), color)\n                    p_todo_str.set_color(match.end(), priority_color)\n\n            p_todo_str.append('', AbstractColor.NEUTRAL)\n\n        return p_todo_str"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_filter_list(p_expression):\n    result = []\n    for arg in p_expression:\n        # when a word starts with -, it should be negated\n        is_negated = len(arg) > 1 and arg[0] == '-'\n        arg = arg[1:] if is_negated else arg\n\n        argfilter = None\n        for match, _filter in MATCHES:\n            if re.match(match, arg):\n                argfilter = _filter(arg)\n                break\n\n        if not argfilter:\n            argfilter = GrepFilter(arg)\n\n        if is_negated:\n            argfilter = NegationFilter(argfilter)\n\n        result.append(argfilter)\n\n    return result", "response": "Returns a list of GrepFilters OrdinalTagFilters or NegationFilters based on the given filter expression."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns True when there are no uncompleted children.", "response": "def match(self, p_todo):\n        \"\"\"\n        Returns True when there are no children that are uncompleted yet.\n        \"\"\"\n        children = self.todolist.children(p_todo)\n        uncompleted = [todo for todo in children if not todo.is_completed()]\n\n        return not uncompleted"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True when p_todo appears in the list of todos.", "response": "def match(self, p_todo):\n        \"\"\"\n        Returns True when p_todo appears in the list of given todos.\n        \"\"\"\n        try:\n            self.todos.index(p_todo)\n            return True\n        except ValueError:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns True when the given todo matches the current state.", "response": "def match(self, p_todo):\n        \"\"\"\n        Returns True when p_todo doesn't have a tag to mark it as hidden.\n        \"\"\"\n        for my_tag in config().hidden_item_tags():\n            my_values = p_todo.tag_values(my_tag)\n            for my_value in my_values:\n                if not my_value in (0, '0', False, 'False'):\n                    return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef compare_operands(self, p_operand1, p_operand2):\n        if self.operator == '<':\n            return p_operand1 < p_operand2\n        elif self.operator == '<=':\n            return p_operand1 <= p_operand2\n        elif self.operator == '=':\n            return p_operand1 == p_operand2\n        elif self.operator == '>=':\n            return p_operand1 >= p_operand2\n        elif self.operator == '>':\n            return p_operand1 > p_operand2\n        elif self.operator == '!':\n            return p_operand1 != p_operand2\n\n        return False", "response": "Compares two operands and returns True if conditional constructed from both operands and self. operator is valid. Returns False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef match(self, p_todo):\n        def resort_to_grep_filter():\n            grep = GrepFilter(self.expression)\n            return grep.match(p_todo)\n\n        if not self.key or not p_todo.has_tag(self.key):\n            return False\n\n        if len(p_todo.tag_values(self.key)) > 1:\n            # we cannot apply an ordening on a tag that appears more than once\n            # in this todo item, therefore use a simple value match\n            return resort_to_grep_filter()\n\n        try:\n            operand1 = date_string_to_date(p_todo.tag_value(self.key))\n            operand2 = relative_date_to_date(self.value)\n\n            if not operand2:\n                operand2 = date_string_to_date(self.value)\n\n        except ValueError:\n            operand1 = p_todo.tag_value(self.key)\n            operand2 = self.value\n\n            try:\n                operand1 = int(operand1)\n                operand2 = int(operand2)\n            except ValueError:\n                return resort_to_grep_filter()\n\n        return self.compare_operands(operand1, operand2)", "response": "Returns True if the given key value tag matches the given todo text."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if the todo matches the current value with the user - entered key - value pair.", "response": "def match(self, p_todo):\n        \"\"\"\n        Performs a match on a priority in the todo.\n\n        It gets priority from p_todo and compares it with user-entered\n        expression based on the given operator (default ==). It does that however\n        in reversed order to obtain more intuitive result. Example: (>B) will\n        match todos with priority (A).\n        Items without priority are designated with corresponding operand set to\n        'ZZ', because python doesn't allow NoneType() and str() comparisons.\n        \"\"\"\n        operand1 = self.value\n        operand2 = p_todo.priority() or 'ZZ'\n\n        return self.compare_operands(operand1, operand2)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef as_rgb(self):\n\n        html = self.as_html()\n\n        return (\n            int(html[1:3], 16),\n            int(html[3:5], 16),\n            int(html[5:7], 16)\n        )", "response": "Returns a tuple of r g b of the color."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of relative date that is presented to the user as auto complete suggestions.", "response": "def date_suggestions():\n    \"\"\"\n    Returns a list of relative date that is presented to the user as auto\n    complete suggestions.\n    \"\"\"\n    # don't use strftime, prevent locales to kick in\n    days_of_week = {\n        0: \"Monday\",\n        1: \"Tuesday\",\n        2: \"Wednesday\",\n        3: \"Thursday\",\n        4: \"Friday\",\n        5: \"Saturday\",\n        6: \"Sunday\"\n    }\n\n    dates = [\n        'today',\n        'tomorrow',\n    ]\n\n    # show days of week up to next week\n    dow = datetime.date.today().weekday()\n    for i in range(dow + 2 % 7, dow + 7):\n        dates.append(days_of_week[i % 7])\n\n    # and some more relative days starting from next week\n    dates += [\"1w\", \"2w\", \"1m\", \"2m\", \"3m\", \"1y\"]\n\n    return dates"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite a string to a file p_file.", "response": "def write(p_file, p_string):\n    \"\"\"\n    Write p_string to file p_file, trailed by a newline character.\n\n    ANSI codes are removed when the file is not a TTY (and colors are\n    automatically determined).\n    \"\"\"\n    if not config().colors(p_file.isatty()):\n        p_string = escape_ansi(p_string)\n\n    if p_string:\n        p_file.write(p_string + \"\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef lookup_color(p_color):\n    if not lookup_color.colors:\n        lookup_color.colors[AbstractColor.NEUTRAL] = Color('NEUTRAL')\n        lookup_color.colors[AbstractColor.PROJECT] = config().project_color()\n        lookup_color.colors[AbstractColor.CONTEXT] = config().context_color()\n        lookup_color.colors[AbstractColor.META] = config().metadata_color()\n        lookup_color.colors[AbstractColor.LINK] = config().link_color()\n\n    try:\n        return lookup_color.colors[p_color]\n    except KeyError:\n        return p_color", "response": "Converts an AbstractColor to a normal Color. Returns the Color itself when a normal color is passed."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef insert_ansi(p_string):\n    result = p_string.data\n\n    for pos, color in sorted(p_string.colors.items(), reverse=True):\n        color = lookup_color(color)\n\n        result = result[:pos] + color.as_ansi() + result[pos:]\n\n    return result", "response": "Inserts ANSI escape codes at the right positions."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprinting the current version and exit.", "response": "def version():\n    \"\"\" Print the current version and exit. \"\"\"\n    from topydo.lib.Version import VERSION, LICENSE\n    print(\"topydo {}\\n\".format(VERSION))\n    print(LICENSE)\n    sys.exit(0)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving the archive content", "response": "def _retrieve_archive():\n    \"\"\"\n    Returns a tuple with archive content: the first element is a TodoListBase\n    and the second element is a TodoFile.\n    \"\"\"\n    archive_file = TodoFile.TodoFile(config().archive())\n    archive = TodoListBase.TodoListBase(archive_file.read())\n\n    return (archive, archive_file)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nperforms an archive action on the todolist.", "response": "def _archive(self):\n        \"\"\"\n        Performs an archive action on the todolist.\n\n        This means that all completed tasks are moved to the archive file\n        (defaults to done.txt).\n        \"\"\"\n        archive, archive_file = _retrieve_archive()\n\n        if self.backup:\n            self.backup.add_archive(archive)\n\n        if archive:\n            from topydo.commands.ArchiveCommand import ArchiveCommand\n            command = ArchiveCommand(self.todolist, archive)\n            command.execute()\n\n            if archive.dirty:\n                archive_file.write(archive.print_todos())"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True when the given command class is read - only.", "response": "def is_read_only(p_command):\n        \"\"\" Returns True when the given command class is read-only. \"\"\"\n        read_only_commands = tuple(cmd for cmd\n                                   in ('revert', ) + READ_ONLY_COMMANDS)\n        return p_command.name() in read_only_commands"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexecute a command with arguments.", "response": "def _execute(self, p_command, p_args):\n        \"\"\"\n        Execute a subcommand with arguments. p_command is a class (not an\n        object).\n        \"\"\"\n        self._backup(p_command, p_args)\n\n        command = p_command(\n            p_args,\n            self.todolist,\n            output,\n            error,\n            input)\n\n        if command.execute() != False:\n            self._post_archive_action = command.execute_post_archive_actions\n            return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _post_execute(self):\n\n        if self.todolist.dirty:\n            # do not archive when the value of the filename is an empty string\n            # (i.e. explicitly left empty in the configuration\n            if self.do_archive and config().archive():\n                self._archive()\n            elif config().archive() and self.backup:\n                archive = _retrieve_archive()[0]\n                self.backup.add_archive(archive)\n\n            self._post_archive_action()\n\n            if config().keep_sorted():\n                from topydo.commands.SortCommand import SortCommand\n                self._execute(SortCommand, [])\n\n            if self.backup:\n                self.backup.save(self.todolist)\n\n            self.todofile.write(self.todolist.print_todos())\n            self.todolist.dirty = False\n\n        self.backup = None", "response": "Called when the user has completed the command."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngive a date tag return a date object.", "response": "def get_date(self, p_tag):\n        \"\"\" Given a date tag, return a date object. \"\"\"\n        string = self.tag_value(p_tag)\n        result = None\n\n        try:\n            result = date_string_to_date(string) if string else None\n        except ValueError:\n            pass\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_active(self):\n        start = self.start_date()\n        return not self.is_completed() and (not start or start <= date.today())", "response": "Returns True when the task is active."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef days_till_due(self):\n        due = self.due_date()\n        if due:\n            diff = due - date.today()\n            return diff.days\n        return 0", "response": "Returns the number of days till the due date."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef length(self):\n        start = self.start_date() or self.creation_date()\n        due = self.due_date()\n\n        if start and due and start < due:\n            diff = due - start\n            return diff.days\n        else:\n            return 0", "response": "Returns the length of the task in days."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _handle_ls(self):\n        try:\n            arg1 = self.argument(1)\n            arg2 = self.argument(2)\n\n            todos = []\n            if arg2 == 'to' or arg1 == 'before':\n                # dep ls 1 to OR dep ls before 1\n                number = arg1 if arg2 == 'to' else arg2\n                todo = self.todolist.todo(number)\n                todos = self.todolist.children(todo)\n            elif arg1 in {'to', 'after'}:\n                # dep ls to 1 OR dep ls after 1\n                number = arg2\n                todo = self.todolist.todo(number)\n                todos = self.todolist.parents(todo)\n            else:\n                raise InvalidCommandArgument\n\n            sorter = Sorter(config().sort_string())\n            instance_filter = Filter.InstanceFilter(todos)\n            view = View(sorter, [instance_filter], self.todolist)\n            self.out(self.printer.print_list(view.todos))\n        except InvalidTodoException:\n            self.error(\"Invalid todo number given.\")\n        except InvalidCommandArgument:\n            self.error(self.usage())", "response": "Handles the ls subsubcommand."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _handle_dot(self):\n        self.printer = DotPrinter(self.todolist)\n\n        try:\n            arg = self.argument(1)\n            todo = self.todolist.todo(arg)\n            arg = self.argument(1)\n            todos = set([self.todolist.todo(arg)])\n            todos |= set(self.todolist.children(todo))\n            todos |= set(self.todolist.parents(todo))\n            todos = sorted(todos, key=lambda t: t.text())\n\n            self.out(self.printer.print_list(todos))\n        except InvalidTodoException:\n            self.error(\"Invalid todo number given.\")\n        except InvalidCommandArgument:\n            self.error(self.usage())", "response": "Handles the dot subsubcommand."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the todo object for the given identifier.", "response": "def todo(self, p_identifier):\n        \"\"\"\n        The _todos list has the same order as in the backend store (usually\n        a todo.txt file. The user refers to the first task as number 1, so use\n        index 0, etc.\n\n        Alternative ways to identify a todo is using a hashed version based on\n        the todo's text, or a regexp that matches the todo's source. The regexp\n        match is a fallback.\n\n        Returns None when the todo couldn't be found.\n        \"\"\"\n        result = None\n\n        def todo_by_uid(p_identifier):\n            \"\"\" Returns the todo that corresponds to the unique ID. \"\"\"\n            result = None\n\n            if config().identifiers() == 'text':\n                try:\n                    result = self._id_todo_map[p_identifier]\n                except KeyError:\n                    pass  # we'll try something else\n\n            return result\n\n        def todo_by_linenumber(p_identifier):\n            \"\"\"\n            Attempts to find the todo on the given line number.\n\n            When the identifier is a number but has leading zeros, the result\n            will be None.\n            \"\"\"\n            result = None\n\n            if config().identifiers() != 'text':\n                try:\n                    if re.match('[1-9]\\d*', p_identifier):\n                        # the expression is a string and no leading zeroes,\n                        # treat it as an integer\n                        raise TypeError\n                except TypeError as te:\n                    try:\n                        result = self._todos[int(p_identifier) - 1]\n                    except (ValueError, IndexError):\n                        raise InvalidTodoException from te\n\n            return result\n\n        def todo_by_regexp(p_identifier):\n            \"\"\"\n            Returns the todo that is (uniquely) identified by the given regexp.\n            If the regexp matches more than one item, no result is returned.\n            \"\"\"\n            result = None\n\n            candidates = Filter.GrepFilter(p_identifier).filter(self._todos)\n\n            if len(candidates) == 1:\n                result = candidates[0]\n            else:\n                raise InvalidTodoException\n\n            return result\n\n        result = todo_by_uid(p_identifier)\n\n        if not result:\n            result = todo_by_linenumber(p_identifier)\n\n        if not result:\n            # convert integer to text so we pass on a valid regex\n            result = todo_by_regexp(str(p_identifier))\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add(self, p_src):\n        todos = self.add_list([p_src])\n\n        return todos[0] if len(todos) else None", "response": "Given a todo string parse it and put it into the end of the list."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes a todo item from the list.", "response": "def delete(self, p_todo):\n        \"\"\" Deletes a todo item from the list. \"\"\"\n        try:\n            number = self._todos.index(p_todo)\n            del self._todos[number]\n            self._update_todo_ids()\n            self.dirty = True\n        except ValueError:\n            # todo item couldn't be found, ignore\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef replace(self, p_todos):\n        self.erase()\n        self.add_todos(p_todos)\n        self.dirty = True", "response": "Replaces all todo objects in the todolist with the given list of todo objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef append(self, p_todo, p_string):\n        if len(p_string) > 0:\n            new_text = p_todo.source() + ' ' + p_string\n            p_todo.set_source_text(new_text)\n            self._update_todo_ids()\n            self.dirty = True", "response": "Append a string to the todo."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef projects(self):\n        result = set()\n        for todo in self._todos:\n            projects = todo.projects()\n            result = result.union(projects)\n\n        return result", "response": "Returns a set of all projects in this list."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a set of all contexts in this list.", "response": "def contexts(self):\n        \"\"\" Returns a set of all contexts in this list. \"\"\"\n        result = set()\n        for todo in self._todos:\n            contexts = todo.contexts()\n            result = result.union(contexts)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef linenumber(self, p_todo):\n        try:\n            return self._todos.index(p_todo) + 1\n        except ValueError as ex:\n            raise InvalidTodoException from ex", "response": "Returns the line number of the todo item."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the unique text - based ID for a todo item.", "response": "def uid(self, p_todo):\n        \"\"\"\n        Returns the unique text-based ID for a todo item.\n        \"\"\"\n        try:\n            return self._todo_id_map[p_todo]\n        except KeyError as ex:\n            raise InvalidTodoException from ex"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the line number or text ID of a todo.", "response": "def number(self, p_todo):\n        \"\"\"\n        Returns the line number or text ID of a todo (depends on the\n        configuration.\n        \"\"\"\n        if config().identifiers() == \"text\":\n            return self.uid(p_todo)\n        else:\n            return self.linenumber(p_todo)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef max_id_length(self):\n        if config().identifiers() == \"text\":\n            return max_id_length(len(self._todos))\n        else:\n            try:\n                return math.ceil(math.log(len(self._todos), 10))\n            except ValueError:\n                return 0", "response": "Returns the maximum length of a todo ID used for formatting purposes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a pretty - printed string of the todo items in this list.", "response": "def print_todos(self):\n        \"\"\"\n        Returns a pretty-printed string (without colors) of the todo items in\n        this list.\n        \"\"\"\n        printer = PrettyPrinter()\n        return \"\\n\".join([str(s) for s in printer.print_list(self._todos)])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ids(self):\n        if config().identifiers() == 'text':\n            ids = self._id_todo_map.keys()\n        else:\n            ids = [str(i + 1) for i in range(self.count())]\n        return set(ids)", "response": "Returns set with all todo IDs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npreparing list of operations to execute based on p_args", "response": "def prepare(self, p_args):\n        \"\"\"\n        Prepares list of operations to execute based on p_args, list of\n        todo items contained in _todo_ids attribute and _subcommand\n        attribute.\n        \"\"\"\n        if self._todo_ids:\n            id_position = p_args.index('{}')\n\n            # Not using MultiCommand abilities would make EditCommand awkward\n            if self._multi:\n                p_args[id_position:id_position + 1] = self._todo_ids\n                self._operations.append(p_args)\n            else:\n                for todo_id in self._todo_ids:\n                    operation_args = p_args[:]\n                    operation_args[id_position] = todo_id\n                    self._operations.append(operation_args)\n        else:\n            self._operations.append(p_args)\n\n        self._create_label()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexecute each operation from _operations attribute.", "response": "def execute(self):\n        \"\"\"\n        Executes each operation from _operations attribute.\n        \"\"\"\n        last_operation = len(self._operations) - 1\n        for i, operation in enumerate(self._operations):\n            command = self._cmd(operation)\n\n            if command.execute() is False:\n                return False\n            else:\n                action = command.execute_post_archive_actions\n                self._post_archive_actions.append(action)\n\n                if i == last_operation:\n                    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a number of months to the source date.", "response": "def _add_months(p_sourcedate, p_months):\n    \"\"\"\n    Adds a number of months to the source date.\n\n    Takes into account shorter months and leap years and such.\n\n    https://stackoverflow.com/questions/4130922/how-to-increment-datetime-month-in-python\n    \"\"\"\n    month = p_sourcedate.month - 1 + p_months\n    year = p_sourcedate.year + month // 12\n    month = month % 12 + 1\n    day = min(p_sourcedate.day, calendar.monthrange(year, month)[1])\n\n    return date(year, month, day)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a number of business days to the source date.", "response": "def _add_business_days(p_sourcedate, p_bdays):\n    \"\"\" Adds a number of business days to the source date. \"\"\"\n    result = p_sourcedate\n    delta = 1 if p_bdays > 0 else -1\n\n    while abs(p_bdays) > 0:\n        result += timedelta(delta)\n\n        weekday = result.weekday()\n        if weekday >= 5:\n            continue\n\n        p_bdays = p_bdays - 1 if delta > 0 else p_bdays + 1\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a pattern in the form 0 - 9 [ dwmyb ] and returns a date from the base date.", "response": "def _convert_pattern(p_length, p_periodunit, p_offset=None):\n    \"\"\"\n    Converts a pattern in the form [0-9][dwmyb] and returns a date from the\n    offset with the period of time added to it.\n    \"\"\"\n    result = None\n\n    p_offset = p_offset or date.today()\n    p_length = int(p_length)\n\n    if p_periodunit == 'd':\n        result = p_offset + timedelta(p_length)\n    elif p_periodunit == 'w':\n        result = p_offset + timedelta(weeks=p_length)\n    elif p_periodunit == 'm':\n        result = _add_months(p_offset, p_length)\n    elif p_periodunit == 'y':\n        result = _add_months(p_offset, p_length * 12)\n    elif p_periodunit == 'b':\n        result = _add_business_days(p_offset, p_length)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a weekday name to an absolute date.", "response": "def _convert_weekday_pattern(p_weekday):\n    \"\"\"\n    Converts a weekday name to an absolute date.\n\n    When today's day of the week is entered, it will return next week's date.\n    \"\"\"\n    day_value = {\n        'mo': 0,\n        'tu': 1,\n        'we': 2,\n        'th': 3,\n        'fr': 4,\n        'sa': 5,\n        'su': 6\n        }\n\n    target_day_string = p_weekday[:2].lower()\n    target_day = day_value[target_day_string]\n\n    day = date.today().weekday()\n\n    shift = 7 - (day - target_day) % 7\n    return date.today() + timedelta(shift)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntransform a relative date into a date object.", "response": "def relative_date_to_date(p_date, p_offset=None):\n    \"\"\"\n    Transforms a relative date into a date object.\n\n    The following formats are understood:\n\n    * [0-9][dwmy]\n    * 'yesterday', 'today' or 'tomorrow'\n    * days of the week (in full or abbreviated)\n    \"\"\"\n    result = None\n    p_date = p_date.lower()\n    p_offset = p_offset or date.today()\n\n    relative = re.match('(?P<length>-?[0-9]+)(?P<period>[dwmyb])$',\n                        p_date, re.I)\n\n    monday = 'mo(n(day)?)?$'\n    tuesday = 'tu(e(sday)?)?$'\n    wednesday = 'we(d(nesday)?)?$'\n    thursday = 'th(u(rsday)?)?$'\n    friday = 'fr(i(day)?)?$'\n    saturday = 'sa(t(urday)?)?$'\n    sunday = 'su(n(day)?)?$'\n\n    weekday = re.match('|'.join(\n        [monday, tuesday, wednesday, thursday, friday, saturday, sunday]),\n        p_date)\n\n    if relative:\n        length = relative.group('length')\n        period = relative.group('period')\n        result = _convert_pattern(length, period, p_offset)\n\n    elif weekday:\n        result = _convert_weekday_pattern(weekday.group(0))\n\n    elif re.match('tod(ay)?$', p_date):\n        result = _convert_pattern('0', 'd')\n\n    elif re.match('tom(orrow)?$', p_date):\n        result = _convert_pattern('1', 'd')\n\n    elif re.match('yes(terday)?$', p_date):\n        result = _convert_pattern('-1', 'd')\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a string that will be used to filter the todo string.", "response": "def filter(self, p_todo_str, p_todo):\n        \"\"\" Prepends the number to the todo string. \"\"\"\n        return \"|{:>3}| {}\".format(self.todolist.number(p_todo), p_todo_str)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef postprocess_input_todo(self, p_todo):\n        def convert_date(p_tag):\n            value = p_todo.tag_value(p_tag)\n\n            if value:\n                dateobj = relative_date_to_date(value)\n                if dateobj:\n                    p_todo.set_tag(p_tag, dateobj.isoformat())\n\n        def add_dependencies(p_tag):\n            for value in p_todo.tag_values(p_tag):\n                try:\n                    dep = self.todolist.todo(value)\n\n                    if p_tag == 'after':\n                        self.todolist.add_dependency(p_todo, dep)\n                    elif p_tag == 'before' or p_tag == 'partof':\n                        self.todolist.add_dependency(dep, p_todo)\n                    elif p_tag.startswith('parent'):\n                        for parent in self.todolist.parents(dep):\n                            self.todolist.add_dependency(parent, p_todo)\n                    elif p_tag.startswith('child'):\n                        for child in self.todolist.children(dep):\n                            self.todolist.add_dependency(p_todo, child)\n                except InvalidTodoException:\n                    pass\n\n                p_todo.remove_tag(p_tag, value)\n\n        convert_date(config().tag_start())\n        convert_date(config().tag_due())\n\n        keywords = [\n            'after',\n            'before',\n            'child-of',\n            'childof',\n            'children-of',\n            'childrenof',\n            'parent-of',\n            'parentof',\n            'parents-of',\n            'parentsof',\n            'partof',\n        ]\n\n        for keyword in keywords:\n            add_dependencies(keyword)", "response": "Post - processes a parsed todo when adding it to the list."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning list with complete column configuration dicts.", "response": "def columns(p_alt_layout_path=None):\n    \"\"\"\n    Returns list with complete column configuration dicts.\n    \"\"\"\n    def _get_column_dict(p_cp, p_column):\n        column_dict = dict()\n\n        filterexpr = p_cp.get(p_column, 'filterexpr')\n\n        try:\n            title = p_cp.get(p_column, 'title')\n        except NoOptionError:\n            title = filterexpr\n\n        column_dict['title'] = title or 'Yet another column'\n        column_dict['filterexpr'] = filterexpr\n        column_dict['sortexpr'] = p_cp.get(p_column, 'sortexpr')\n        column_dict['groupexpr'] = p_cp.get(p_column, 'groupexpr')\n        column_dict['show_all'] = p_cp.getboolean(p_column, 'show_all')\n\n        return column_dict\n\n    defaults = {\n            'filterexpr': '',\n            'sortexpr': config().sort_string(),\n            'groupexpr': config().group_string(),\n            'show_all': '0',\n    }\n\n    cp = RawConfigParser(defaults, strict=False)\n    files = [\n        \"topydo_columns.ini\",\n        \"topydo_columns.conf\",\n        \".topydo_columns\",\n        home_config_path('.topydo_columns'),\n        home_config_path('.config/topydo/columns'),\n        \"/etc/topydo_columns.conf\",\n    ]\n\n    if p_alt_layout_path is not None:\n        files.insert(0, expanduser(p_alt_layout_path))\n    for filename in files:\n        if cp.read(filename):\n            break\n\n    column_list = []\n\n    for column in cp.sections():\n        column_list.append(_get_column_dict(cp, column))\n\n    return column_list"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _active_todos(self):\n        return [todo for todo in self.todolist.todos()\n                if not self._uncompleted_children(todo) and todo.is_active()]", "response": "Returns a list of active todos taking uncompleted subtodos into\n        account."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndecompresses available input into an output buffer. Returns True if data in output buffer should be emitted.", "response": "def _decompress_into_buffer(self, out_buffer):\n        \"\"\"Decompress available input into an output buffer.\n\n        Returns True if data in output buffer should be emitted.\n        \"\"\"\n        zresult = lib.ZSTD_decompressStream(self._decompressor._dctx,\n                                            out_buffer, self._in_buffer)\n\n        if self._in_buffer.pos == self._in_buffer.size:\n            self._in_buffer.src = ffi.NULL\n            self._in_buffer.pos = 0\n            self._in_buffer.size = 0\n            self._source_buffer = None\n\n            if not hasattr(self._source, 'read'):\n                self._finished_input = True\n\n        if lib.ZSTD_isError(zresult):\n            raise ZstdError('zstd decompress error: %s' %\n                            _zstd_error(zresult))\n\n        # Emit data if there is data AND either:\n        # a) output buffer is full (read amount is satisfied)\n        # b) we're at end of a frame and not in frame spanning mode\n        return (out_buffer.pos and\n                (out_buffer.pos == out_buffer.size or\n                 zresult == 0 and not self._read_across_frames))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_c_extension(support_legacy=False, system_zstd=False, name='zstd',\n                    warnings_as_errors=False, root=None):\n    \"\"\"Obtain a distutils.extension.Extension for the C extension.\n\n    ``support_legacy`` controls whether to compile in legacy zstd format support.\n\n    ``system_zstd`` controls whether to compile against the system zstd library.\n    For this to work, the system zstd library and headers must match what\n    python-zstandard is coded against exactly.\n\n    ``name`` is the module name of the C extension to produce.\n\n    ``warnings_as_errors`` controls whether compiler warnings are turned into\n    compiler errors.\n\n    ``root`` defines a root path that source should be computed as relative\n    to. This should be the directory with the main ``setup.py`` that is\n    being invoked. If not defined, paths will be relative to this file.\n    \"\"\"\n    actual_root = os.path.abspath(os.path.dirname(__file__))\n    root = root or actual_root\n\n    sources = set([os.path.join(actual_root, p) for p in ext_sources])\n    if not system_zstd:\n        sources.update([os.path.join(actual_root, p) for p in zstd_sources])\n        if support_legacy:\n            sources.update([os.path.join(actual_root, p)\n                            for p in zstd_sources_legacy])\n    sources = list(sources)\n\n    include_dirs = set([os.path.join(actual_root, d) for d in ext_includes])\n    if not system_zstd:\n        include_dirs.update([os.path.join(actual_root, d)\n                             for d in zstd_includes])\n        if support_legacy:\n            include_dirs.update([os.path.join(actual_root, d)\n                                 for d in zstd_includes_legacy])\n    include_dirs = list(include_dirs)\n\n    depends = [os.path.join(actual_root, p) for p in zstd_depends]\n\n    compiler = distutils.ccompiler.new_compiler()\n\n    # Needed for MSVC.\n    if hasattr(compiler, 'initialize'):\n        compiler.initialize()\n\n    if compiler.compiler_type == 'unix':\n        compiler_type = 'unix'\n    elif compiler.compiler_type == 'msvc':\n        compiler_type = 'msvc'\n    elif compiler.compiler_type == 'mingw32':\n        compiler_type = 'mingw32'\n    else:\n        raise Exception('unhandled compiler type: %s' %\n                        compiler.compiler_type)\n\n    extra_args = ['-DZSTD_MULTITHREAD']\n\n    if not system_zstd:\n        extra_args.append('-DZSTDLIB_VISIBILITY=')\n        extra_args.append('-DZDICTLIB_VISIBILITY=')\n        extra_args.append('-DZSTDERRORLIB_VISIBILITY=')\n\n        if compiler_type == 'unix':\n            extra_args.append('-fvisibility=hidden')\n\n    if not system_zstd and support_legacy:\n        extra_args.append('-DZSTD_LEGACY_SUPPORT=1')\n\n    if warnings_as_errors:\n        if compiler_type in ('unix', 'mingw32'):\n            extra_args.append('-Werror')\n        elif compiler_type == 'msvc':\n            extra_args.append('/WX')\n        else:\n            assert False\n\n    libraries = ['zstd'] if system_zstd else []\n\n    # Python 3.7 doesn't like absolute paths. So normalize to relative.\n    sources = [os.path.relpath(p, root) for p in sources]\n    include_dirs = [os.path.relpath(p, root) for p in include_dirs]\n    depends = [os.path.relpath(p, root) for p in depends]\n\n    # TODO compile with optimizations.\n    return Extension(name, sources,\n                     include_dirs=include_dirs,\n                     depends=depends,\n                     extra_compile_args=extra_args,\n                     libraries=libraries)", "response": "Return a distutils. extension. Extension for the C extension."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning fn multiple times and returns the results.", "response": "def timer(fn, miniter=3, minwall=3.0):\n    \"\"\"Runs fn() multiple times and returns the results.\n\n    Runs for at least ``miniter`` iterations and ``minwall`` wall time.\n    \"\"\"\n\n    results = []\n    count = 0\n\n    # Ideally a monotonic clock, but doesn't matter too much.\n    wall_begin = time.time()\n\n    while True:\n        wstart = time.time()\n        start = os.times()\n        fn()\n        end = os.times()\n        wend = time.time()\n        count += 1\n\n        user = end[0] - start[0]\n        system = end[1] - start[1]\n        cpu = user + system\n        wall = wend - wstart\n\n        results.append((cpu, user, system, wall))\n\n        # Ensure we run at least ``miniter`` times.\n        if count < miniter:\n            continue\n\n        # And for ``minwall`` seconds.\n        elapsed = wend - wall_begin\n\n        if elapsed < minwall:\n            continue\n\n        break\n\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef timezone(self):\n\n        if not self._timezone_group and not self._timezone_location:\n            return None\n\n        if self._timezone_location != \"\":\n            return \"%s/%s\" % (self._timezone_group, self._timezone_location)\n        else:\n            return self._timezone_group", "response": "The name of the time zone for the location."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn dawn sunrise noon sunset and dusk as a dictionary.", "response": "def sun(self, date=None, local=True, use_elevation=True):\n        \"\"\"Returns dawn, sunrise, noon, sunset and dusk as a dictionary.\n\n        :param date: The date for which to calculate the times.\n                     If no date is specified then the current date will be used.\n        :type date:  :class:`~datetime.date`\n\n        :param local: True  = Time to be returned in location's time zone;\n                      False = Time to be returned in UTC.\n                      If not specified then the time will be returned in local time\n        :type local:  bool\n\n        :param use_elevation: True  = Return times that allow for the location's elevation;\n                              False = Return times that don't use elevation.\n                              If not specified then times will take elevation into account.\n        :type use_elevation:  bool\n\n        :returns: Dictionary with keys ``dawn``, ``sunrise``, ``noon``,\n            ``sunset`` and ``dusk`` whose values are the results of the\n            corresponding methods.\n        :rtype: dict\n         \"\"\"\n\n        if local and self.timezone is None:\n            raise ValueError(\"Local time requested but Location has no timezone set.\")\n\n        if self.astral is None:\n            self.astral = Astral()\n\n        if date is None:\n            date = datetime.date.today()\n\n        elevation = self.elevation if use_elevation else 0\n        sun = self.astral.sun_utc(date, self.latitude, self.longitude, observer_elevation=elevation)\n\n        if local:\n            for key, dt in sun.items():\n                sun[key] = dt.astimezone(self.tz)\n\n        return sun"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sunrise(self, date=None, local=True, use_elevation=True):\n\n        if local and self.timezone is None:\n            raise ValueError(\"Local time requested but Location has no timezone set.\")\n\n        if self.astral is None:\n            self.astral = Astral()\n\n        if date is None:\n            date = datetime.date.today()\n\n        elevation = self.elevation if use_elevation else 0\n        sunrise = self.astral.sunrise_utc(date, self.latitude, self.longitude, elevation)\n\n        if local:\n            return sunrise.astimezone(self.tz)\n        else:\n            return sunrise", "response": "Return the sunrise time."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the solar noon time for the current location.", "response": "def solar_noon(self, date=None, local=True):\n        \"\"\"Calculates the solar noon (the time when the sun is at its highest\n        point.)\n\n        :param date: The date for which to calculate the noon time.\n                     If no date is specified then the current date will be used.\n        :type date:  :class:`~datetime.date`\n\n        :param local: True  = Time to be returned in location's time zone;\n                      False = Time to be returned in UTC.\n                      If not specified then the time will be returned in local time\n        :type local:  bool\n\n        :returns: The date and time at which the solar noon occurs.\n        :rtype: :class:`~datetime.datetime`\n        \"\"\"\n\n        if local and self.timezone is None:\n            raise ValueError(\"Local time requested but Location has no timezone set.\")\n\n        if self.astral is None:\n            self.astral = Astral()\n\n        if date is None:\n            date = datetime.date.today()\n\n        noon = self.astral.solar_noon_utc(date, self.longitude)\n\n        if local:\n            return noon.astimezone(self.tz)\n        else:\n            return noon"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dusk(self, date=None, local=True, use_elevation=True):\n\n        if local and self.timezone is None:\n            raise ValueError(\"Local time requested but Location has no timezone set.\")\n\n        if self.astral is None:\n            self.astral = Astral()\n\n        if date is None:\n            date = datetime.date.today()\n\n        elevation = self.elevation if use_elevation else 0\n        dusk = self.astral.dusk_utc(date, self.latitude, self.longitude, observer_elevation=elevation)\n\n        if local:\n            return dusk.astimezone(self.tz)\n        else:\n            return dusk", "response": "Calculates the dusk time for the given location."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef solar_midnight(self, date=None, local=True):\n\n        if local and self.timezone is None:\n            raise ValueError(\"Local time requested but Location has no timezone set.\")\n\n        if self.astral is None:\n            self.astral = Astral()\n\n        if date is None:\n            date = datetime.date.today()\n\n        midnight = self.astral.solar_midnight_utc(date, self.longitude)\n\n        if local:\n            return midnight.astimezone(self.tz)\n        else:\n            return midnight", "response": "Calculates the solar midnight time for the given date."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef daylight(self, date=None, local=True, use_elevation=True):\n\n        if local and self.timezone is None:\n            raise ValueError(\"Local time requested but Location has no timezone set.\")\n\n        if self.astral is None:\n            self.astral = Astral()\n\n        if date is None:\n            date = datetime.date.today()\n\n        elevation = self.elevation if use_elevation else 0\n        start, end = self.astral.daylight_utc(date, self.latitude, self.longitude, observer_elevation=elevation)\n\n        if local:\n            return start.astimezone(self.tz), end.astimezone(self.tz)\n        else:\n            return start, end", "response": "Calculates the daylight time between sunrise and sunset."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef night(self, date=None, local=True, use_elevation=True):\n\n        if local and self.timezone is None:\n            raise ValueError(\"Local time requested but Location has no timezone set.\")\n\n        if self.astral is None:\n            self.astral = Astral()\n\n        if date is None:\n            date = datetime.date.today()\n\n        elevation = self.elevation if use_elevation else 0\n        start, end = self.astral.night_utc(date, self.latitude, self.longitude, elevation)\n\n        if local:\n            return start.astimezone(self.tz), end.astimezone(self.tz)\n        else:\n            return start, end", "response": "Calculates the night time between astronomical dusk and a date."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the start and end times of Twilight in the UTC timezone when the sun is traversing in the specified direction.", "response": "def twilight(self, direction=SUN_RISING, date=None, local=True, use_elevation=True):\n        \"\"\"Returns the start and end times of Twilight in the UTC timezone when\n        the sun is traversing in the specified direction.\n\n        This method defines twilight as being between the time\n        when the sun is at -6 degrees and sunrise/sunset.\n\n        :param direction:  Determines whether the time is for the sun rising or setting.\n                           Use ``astral.SUN_RISING`` or ``astral.SUN_SETTING``.\n        :type direction:   int\n\n        :param date: The date for which to calculate the times.\n        :type date: :class:`datetime.date`\n\n        :param local: True  = Time to be returned in location's time zone;\n                      False = Time to be returned in UTC.\n                      If not specified then the time will be returned in local time\n        :type local:  bool\n\n        :param use_elevation: True  = Return times that allow for the location's elevation;\n                              False = Return times that don't use elevation.\n                              If not specified then times will take elevation into account.\n        :type use_elevation:  bool\n\n        :return: A tuple of the UTC date and time at which twilight starts and ends.\n        :rtype: (:class:`~datetime.datetime`, :class:`~datetime.datetime`)\n        \"\"\"\n\n        if local and self.timezone is None:\n            raise ValueError(\"Local time requested but Location has no timezone set.\")\n\n        if date is None:\n            date = datetime.date.today()\n\n        elevation = self.elevation if use_elevation else 0\n        start, end = self.astral.twilight_utc(\n            direction, date, self.latitude, self.longitude, elevation\n        )\n\n        if local:\n            return start.astimezone(self.tz), end.astimezone(self.tz)\n        else:\n            return start, end"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the time at which the sun is at the specified elevation.", "response": "def time_at_elevation(self, elevation, direction=SUN_RISING, date=None, local=True):\n        \"\"\"Calculate the time when the sun is at the specified elevation.\n\n        Note:\n            This method uses positive elevations for those above the horizon.\n\n            Elevations greater than 90 degrees are converted to a setting sun\n            i.e. an elevation of 110 will calculate a setting sun at 70 degrees.\n\n        :param elevation:  Elevation in degrees above the horizon to calculate for.\n        :type elevation:   float\n\n        :param direction:  Determines whether the time is for the sun rising or setting.\n                           Use ``astral.SUN_RISING`` or ``astral.SUN_SETTING``. Default is rising.\n        :type direction:   int\n\n        :param date: The date for which to calculate the elevation time.\n                     If no date is specified then the current date will be used.\n        :type date:  :class:`~datetime.date`\n\n        :param local: True  = Time to be returned in location's time zone;\n                      False = Time to be returned in UTC.\n                      If not specified then the time will be returned in local time\n        :type local:  bool\n\n        :returns: The date and time at which dusk occurs.\n        :rtype: :class:`~datetime.datetime`\n        \"\"\"\n\n        if local and self.timezone is None:\n            raise ValueError(\"Local time requested but Location has no timezone set.\")\n\n        if self.astral is None:\n            self.astral = Astral()\n\n        if date is None:\n            date = datetime.date.today()\n\n        if elevation > 90.0:\n            elevation = 180.0 - elevation\n            direction = SUN_SETTING\n\n        time_ = self.astral.time_at_elevation_utc(\n            elevation, direction, date, self.latitude, self.longitude\n        )\n\n        if local:\n            return time_.astimezone(self.tz)\n        else:\n            return time_"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef blue_hour(self, direction=SUN_RISING, date=None, local=True, use_elevation=True):\n\n        if local and self.timezone is None:\n            raise ValueError(\"Local time requested but Location has no timezone set.\")\n\n        if self.astral is None:\n            self.astral = Astral()\n\n        if date is None:\n            date = datetime.date.today()\n\n        elevation = self.elevation if use_elevation else 0\n        start, end = self.astral.blue_hour_utc(\n            direction, date, self.latitude, self.longitude, elevation\n        )\n\n        if local:\n            start = start.astimezone(self.tz)\n            end = end.astimezone(self.tz)\n\n        return start, end", "response": "Returns the start and end times of the Blue Hour when the sun is traversing in the specified direction."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the solar azimuth angle for a specific date and time.", "response": "def solar_azimuth(self, dateandtime=None):\n        \"\"\"Calculates the solar azimuth angle for a specific date/time.\n\n        :param dateandtime: The date and time for which to calculate the angle.\n        :type dateandtime: :class:`~datetime.datetime`\n\n        :returns: The azimuth angle in degrees clockwise from North.\n        :rtype: float\n        \"\"\"\n\n        if self.astral is None:\n            self.astral = Astral()\n\n        if dateandtime is None:\n            dateandtime = datetime.datetime.now(self.tz)\n        elif not dateandtime.tzinfo:\n            dateandtime = self.tz.localize(dateandtime)\n\n        dateandtime = dateandtime.astimezone(pytz.UTC)\n\n        return self.astral.solar_azimuth(dateandtime, self.latitude, self.longitude)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef moon_phase(self, date=None, rtype=int):\n\n        if self.astral is None:\n            self.astral = Astral()\n\n        if date is None:\n            date = datetime.date.today()\n\n        return self.astral.moon_phase(date, rtype)", "response": "Calculates the moon phase for a specific date."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_locations(self, locations):\n\n        if isinstance(locations, (str, ustr)):\n            self._add_from_str(locations)\n        elif isinstance(locations, (list, tuple)):\n            self._add_from_list(locations)", "response": "Add extra locations to AstralGeocoder."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd locations from a string", "response": "def _add_from_str(self, s):\n        \"\"\"Add locations from a string\"\"\"\n\n        if sys.version_info[0] < 3 and isinstance(s, str):\n            s = s.decode('utf-8')\n\n        for line in s.split(\"\\n\"):\n            self._parse_line(line)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _add_from_list(self, l):\n\n        for item in l:\n            if isinstance(item, (str, ustr)):\n                self._add_from_str(item)\n            elif isinstance(item, (list, tuple)):\n                location = Location(item)\n                self._add_location(location)", "response": "Add locations from a list of strings lists and tuples."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_geocoding(self, key, location):\n\n        url = self._location_query_base % quote_plus(key)\n        if self.api_key:\n            url += \"&key=%s\" % self.api_key\n        data = self._read_from_url(url)\n        response = json.loads(data)\n        if response[\"status\"] == \"OK\":\n            formatted_address = response[\"results\"][0][\"formatted_address\"]\n            pos = formatted_address.find(\",\")\n            if pos == -1:\n                location.name = formatted_address\n                location.region = \"\"\n            else:\n                location.name = formatted_address[:pos].strip()\n                location.region = formatted_address[pos + 1 :].strip()\n\n            geo_location = response[\"results\"][0][\"geometry\"][\"location\"]\n            location.latitude = float(geo_location[\"lat\"])\n            location.longitude = float(geo_location[\"lng\"])\n        else:\n            raise AstralError(\"GoogleGeocoder: Unable to locate %s. Server Response=%s\" %\n                              (key, response[\"status\"]))", "response": "Lookup the Google geocoding API information for key and location."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_timezone(self, location):\n\n        url = self._timezone_query_base % (\n            location.latitude,\n            location.longitude,\n            int(time()),\n        )\n        if self.api_key != \"\":\n            url += \"&key=%s\" % self.api_key\n        data = self._read_from_url(url)\n        response = json.loads(data)\n        if response[\"status\"] == \"OK\":\n            location.timezone = response[\"timeZoneId\"]\n        else:\n            location.timezone = \"UTC\"", "response": "Query the timezone information with the latitude and longitude of\n        the specified location."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nquery the elevation information with the latitude and longitude of the specified location.", "response": "def _get_elevation(self, location):\n        \"\"\"Query the elevation information with the latitude and longitude of\n        the specified `location`.\n        \"\"\"\n\n        url = self._elevation_query_base % (location.latitude, location.longitude)\n        if self.api_key != \"\":\n            url += \"&key=%s\" % self.api_key\n        data = self._read_from_url(url)\n        response = json.loads(data)\n        if response[\"status\"] == \"OK\":\n            location.elevation = int(float(response[\"results\"][0][\"elevation\"]))\n        else:\n            location.elevation = 0"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sun_utc(self, date, latitude, longitude, observer_elevation=0):\n\n        dawn = self.dawn_utc(date, latitude, longitude, observer_elevation=observer_elevation)\n        sunrise = self.sunrise_utc(date, latitude, longitude, observer_elevation=observer_elevation)\n        noon = self.solar_noon_utc(date, longitude)\n        sunset = self.sunset_utc(date, latitude, longitude, observer_elevation=observer_elevation)\n        dusk = self.dusk_utc(date, latitude, longitude, observer_elevation=observer_elevation)\n\n        return {\n            \"dawn\": dawn,\n            \"sunrise\": sunrise,\n            \"noon\": noon,\n            \"sunset\": sunset,\n            \"dusk\": dusk,\n        }", "response": "Calculate all the info for the sun at once."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the dawn time in the UTC timezone.", "response": "def dawn_utc(self, date, latitude, longitude, depression=0, observer_elevation=0):\n        \"\"\"Calculate dawn time in the UTC timezone.\n\n        :param date:       Date to calculate for.\n        :type date:        :class:`datetime.date`\n        :param latitude:   Latitude - Northern latitudes should be positive\n        :type latitude:    float\n        :param longitude:  Longitude - Eastern longitudes should be positive\n        :type longitude:   float\n        :param depression: Override the depression used\n        :type depression:  float\n        :param observer_elevation:  Elevation in metres to calculate dawn for\n        :type observer_elevation:   int\n\n        :return: The UTC date and time at which dawn occurs.\n        :rtype: :class:`~datetime.datetime`\n        \"\"\"\n\n        if depression == 0:\n            depression = self._depression\n        depression += 90\n\n        try:\n            return self._calc_time(depression, SUN_RISING, date, latitude, longitude, observer_elevation)\n        except ValueError as exc:\n            if exc.args[0] == \"math domain error\":\n                raise AstralError(\n                    (\n                        \"Sun never reaches %d degrees below the horizon, \"\n                        \"at this location.\"\n                    )\n                    % (depression - 90)\n                )\n            else:\n                raise"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncalculate sunrise time in the UTC timezone.", "response": "def sunrise_utc(self, date, latitude, longitude, observer_elevation=0):\n        \"\"\"Calculate sunrise time in the UTC timezone.\n\n        :param date:       Date to calculate for.\n        :type date:        :class:`datetime.date`\n        :param latitude:   Latitude - Northern latitudes should be positive\n        :type latitude:    float\n        :param longitude:  Longitude - Eastern longitudes should be positive\n        :type longitude:   float\n        :param observer_elevation:  Elevation in metres to calculate sunrise for\n        :type observer_elevation:   int\n\n        :return: The UTC date and time at which sunrise occurs.\n        :rtype: :class:`~datetime.datetime`\n        \"\"\"\n\n        try:\n            return self._calc_time(90 + 0.833, SUN_RISING, date, latitude, longitude, observer_elevation)\n        except ValueError as exc:\n            if exc.args[0] == \"math domain error\":\n                raise AstralError(\n                    (\"Sun never reaches the horizon on this day, \" \"at this location.\")\n                )\n            else:\n                raise"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the solar noon time in the UTC timezone.", "response": "def solar_noon_utc(self, date, longitude):\n        \"\"\"Calculate solar noon time in the UTC timezone.\n\n        :param date:       Date to calculate for.\n        :type date:        :class:`datetime.date`\n        :param longitude:  Longitude - Eastern longitudes should be positive\n        :type longitude:   float\n\n        :return: The UTC date and time at which noon occurs.\n        :rtype: :class:`~datetime.datetime`\n        \"\"\"\n\n        jc = self._jday_to_jcentury(self._julianday(date))\n        eqtime = self._eq_of_time(jc)\n        timeUTC = (720.0 - (4 * longitude) - eqtime) / 60.0\n\n        hour = int(timeUTC)\n        minute = int((timeUTC - hour) * 60)\n        second = int((((timeUTC - hour) * 60) - minute) * 60)\n\n        if second > 59:\n            second -= 60\n            minute += 1\n        elif second < 0:\n            second += 60\n            minute -= 1\n\n        if minute > 59:\n            minute -= 60\n            hour += 1\n        elif minute < 0:\n            minute += 60\n            hour -= 1\n\n        if hour > 23:\n            hour -= 24\n            date += datetime.timedelta(days=1)\n        elif hour < 0:\n            hour += 24\n            date -= datetime.timedelta(days=1)\n\n        noon = datetime.datetime(date.year, date.month, date.day, hour, minute, second)\n        noon = pytz.UTC.localize(noon)  # pylint: disable=E1120\n\n        return noon"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sunset_utc(self, date, latitude, longitude, observer_elevation=0):\n\n        try:\n            return self._calc_time(90 + 0.833, SUN_SETTING, date, latitude, longitude, observer_elevation)\n        except ValueError as exc:\n            if exc.args[0] == \"math domain error\":\n                raise AstralError(\n                    (\"Sun never reaches the horizon on this day, \" \"at this location.\")\n                )\n            else:\n                raise", "response": "Calculate sunset time in the UTC timezone."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dusk_utc(self, date, latitude, longitude, depression=0, observer_elevation=0):\n\n        if depression == 0:\n            depression = self._depression\n        depression += 90\n\n        try:\n            return self._calc_time(depression, SUN_SETTING, date, latitude, longitude, observer_elevation)\n        except ValueError as exc:\n            if exc.args[0] == \"math domain error\":\n                raise AstralError(\n                    (\n                        \"Sun never reaches %d degrees below the horizon, \"\n                        \"at this location.\"\n                    )\n                    % (depression - 90)\n                )\n            else:\n                raise", "response": "Calculate dusk time in the UTC timezone."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef solar_midnight_utc(self, date, longitude):\n\n        julianday = self._julianday(date)\n\n        newt = self._jday_to_jcentury(julianday + 0.5 + -longitude / 360.0)\n\n        eqtime = self._eq_of_time(newt)\n        timeUTC = (-longitude * 4.0) - eqtime\n\n        timeUTC = timeUTC / 60.0\n        hour = int(timeUTC)\n        minute = int((timeUTC - hour) * 60)\n        second = int((((timeUTC - hour) * 60) - minute) * 60)\n\n        if second > 59:\n            second -= 60\n            minute += 1\n        elif second < 0:\n            second += 60\n            minute -= 1\n\n        if minute > 59:\n            minute -= 60\n            hour += 1\n        elif minute < 0:\n            minute += 60\n            hour -= 1\n\n        if hour < 0:\n            hour += 24\n            date -= datetime.timedelta(days=1)\n\n        midnight = datetime.datetime(\n            date.year, date.month, date.day, hour, minute, second\n        )\n        midnight = pytz.UTC.localize(midnight)  # pylint: disable=E1120\n\n        return midnight", "response": "Calculate the solar midnight time in the UTC timezone."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating daylight start and end times in the UTC timezone.", "response": "def daylight_utc(self, date, latitude, longitude, observer_elevation=0):\n        \"\"\"Calculate daylight start and end times in the UTC timezone.\n\n        :param date:       Date to calculate for.\n        :type date:        :class:`datetime.date`\n        :param latitude:   Latitude - Northern latitudes should be positive\n        :type latitude:    float\n        :param longitude:  Longitude - Eastern longitudes should be positive\n        :type longitude:   float\n        :param observer_elevation:  Elevation in metres to calculate daylight for\n        :type observer_elevation:   int\n\n        :return: A tuple of the UTC date and time at which daylight starts and ends.\n        :rtype: (:class:`~datetime.datetime`, :class:`~datetime.datetime`)\n        \"\"\"\n\n        start = self.sunrise_utc(date, latitude, longitude, observer_elevation)\n        end = self.sunset_utc(date, latitude, longitude, observer_elevation)\n\n        return start, end"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates night start and end times in the UTC timezone.", "response": "def night_utc(self, date, latitude, longitude, observer_elevation=0):\n        \"\"\"Calculate night start and end times in the UTC timezone.\n\n        Night is calculated to be between astronomical dusk on the\n        date specified and astronomical dawn of the next day.\n\n        :param date:       Date to calculate for.\n        :type date:        :class:`datetime.date`\n        :param latitude:   Latitude - Northern latitudes should be positive\n        :type latitude:    float\n        :param longitude:  Longitude - Eastern longitudes should be positive\n        :type longitude:   float\n        :param observer_elevation:  Elevation in metres to calculate night for\n        :type observer_elevation:   int\n\n        :return: A tuple of the UTC date and time at which night starts and ends.\n        :rtype: (:class:`~datetime.datetime`, :class:`~datetime.datetime`)\n        \"\"\"\n\n        start = self.dusk_utc(date, latitude, longitude, 18, observer_elevation)\n        tomorrow = date + datetime.timedelta(days=1)\n        end = self.dawn_utc(tomorrow, latitude, longitude, 18, observer_elevation)\n\n        return start, end"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the start and end times of Twilight in the UTC timezone when the sun is traversing in the specified direction.", "response": "def twilight_utc(self, direction, date, latitude, longitude, observer_elevation=0):\n        \"\"\"Returns the start and end times of Twilight in the UTC timezone when\n        the sun is traversing in the specified direction.\n\n        This method defines twilight as being between the time\n        when the sun is at -6 degrees and sunrise/sunset.\n\n        :param direction:  Determines whether the time is for the sun rising or setting.\n                           Use ``astral.SUN_RISING`` or ``astral.SUN_SETTING``.\n        :type direction:   int\n        :param date: The date for which to calculate the times.\n        :type date: :class:`datetime.date`\n        :param latitude:   Latitude - Northern latitudes should be positive\n        :type latitude:    float\n        :param longitude:  Longitude - Eastern longitudes should be positive\n        :type longitude:   float\n        :param observer_elevation:  Elevation in metres to calculate twilight for\n        :type observer_elevation:   int\n\n        :return: A tuple of the UTC date and time at which twilight starts and ends.\n        :rtype: (:class:`~datetime.datetime`, :class:`~datetime.datetime`)\n        \"\"\"\n\n        if date is None:\n            date = datetime.date.today()\n\n        start = self.time_at_elevation_utc(-6, direction, date, latitude, longitude, observer_elevation)\n        if direction == SUN_RISING:\n            end = self.sunrise_utc(date, latitude, longitude)\n        else:\n            end = self.sunset_utc(date, latitude, longitude)\n\n        if direction == SUN_RISING:\n            return start, end\n        else:\n            return end, start"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the start and end times of the blue hour in the UTC timezone.", "response": "def blue_hour_utc(self, direction, date, latitude, longitude, observer_elevation=0):\n        \"\"\"Returns the start and end times of the Blue Hour in the UTC timezone\n        when the sun is traversing in the specified direction.\n\n        This method uses the definition from PhotoPills i.e. the\n        blue hour is when the sun is between 6 and 4 degrees below the horizon.\n\n        :param direction:  Determines whether the time is for the sun rising or setting.\n                           Use ``astral.SUN_RISING`` or ``astral.SUN_SETTING``.\n        :type direction:   int\n        :param date: The date for which to calculate the times.\n        :type date: :class:`datetime.date`\n        :param latitude:   Latitude - Northern latitudes should be positive\n        :type latitude:    float\n        :param longitude:  Longitude - Eastern longitudes should be positive\n        :type longitude:   float\n        :param observer_elevation:  Elevation in metres to calculate the blue hour for\n        :type observer_elevation:   int\n\n        :return: A tuple of the UTC date and time at which the Blue Hour starts and ends.\n        :rtype: (:class:`~datetime.datetime`, :class:`~datetime.datetime`)\n        \"\"\"\n\n        if date is None:\n            date = datetime.date.today()\n\n        start = self.time_at_elevation_utc(-6, direction, date, latitude, longitude, observer_elevation)\n        end = self.time_at_elevation_utc(-4, direction, date, latitude, longitude, observer_elevation)\n\n        if direction == SUN_RISING:\n            return start, end\n        else:\n            return end, start"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef time_at_elevation_utc(self, elevation, direction, date, latitude, longitude, observer_elevation=0):\n\n        if elevation > 90.0:\n            elevation = 180.0 - elevation\n            direction = SUN_SETTING\n\n        depression = 90 - elevation\n        try:\n            return self._calc_time(depression, direction, date, latitude, longitude, observer_elevation)\n        except ValueError as exc:\n            if exc.args[0] == \"math domain error\":\n                raise AstralError(\n                    (\"Sun never reaches an elevation of %d degrees\" \"at this location.\")\n                    % elevation\n                )\n            else:\n                raise", "response": "Calculate the time at which the sun is at the specified elevation on the specified date."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef solar_azimuth(self, dateandtime, latitude, longitude):\n\n        if latitude > 89.8:\n            latitude = 89.8\n\n        if latitude < -89.8:\n            latitude = -89.8\n\n        if dateandtime.tzinfo is None:\n            zone = 0\n            utc_datetime = dateandtime\n        else:\n            zone = -dateandtime.utcoffset().total_seconds() / 3600.0\n            utc_datetime = dateandtime.astimezone(pytz.utc)\n\n        timenow = (\n            utc_datetime.hour\n            + (utc_datetime.minute / 60.0)\n            + (utc_datetime.second / 3600.0)\n        )\n\n        JD = self._julianday(dateandtime)\n        t = self._jday_to_jcentury(JD + timenow / 24.0)\n        theta = self._sun_declination(t)\n        eqtime = self._eq_of_time(t)\n        solarDec = theta  # in degrees\n\n        solarTimeFix = eqtime - (4.0 * -longitude) + (60 * zone)\n        trueSolarTime = (\n            dateandtime.hour * 60.0\n            + dateandtime.minute\n            + dateandtime.second / 60.0\n            + solarTimeFix\n        )\n        #    in minutes\n\n        while trueSolarTime > 1440:\n            trueSolarTime = trueSolarTime - 1440\n\n        hourangle = trueSolarTime / 4.0 - 180.0\n        #    Thanks to Louis Schwarzmayr for the next line:\n        if hourangle < -180:\n            hourangle = hourangle + 360.0\n\n        harad = radians(hourangle)\n\n        csz = sin(radians(latitude)) * sin(radians(solarDec)) + cos(\n            radians(latitude)\n        ) * cos(radians(solarDec)) * cos(harad)\n\n        if csz > 1.0:\n            csz = 1.0\n        elif csz < -1.0:\n            csz = -1.0\n\n        zenith = degrees(acos(csz))\n\n        azDenom = cos(radians(latitude)) * sin(radians(zenith))\n\n        if abs(azDenom) > 0.001:\n            azRad = (\n                (sin(radians(latitude)) * cos(radians(zenith))) - sin(radians(solarDec))\n            ) / azDenom\n\n            if abs(azRad) > 1.0:\n                if azRad < 0:\n                    azRad = -1.0\n                else:\n                    azRad = 1.0\n\n            azimuth = 180.0 - degrees(acos(azRad))\n\n            if hourangle > 0.0:\n                azimuth = -azimuth\n        else:\n            if latitude > 0.0:\n                azimuth = 180.0\n            else:\n                azimuth = 0.0\n\n        if azimuth < 0.0:\n            azimuth = azimuth + 360.0\n\n        return azimuth", "response": "Calculate the azimuth angle of the sun."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef solar_elevation(self, dateandtime, latitude, longitude):\n\n        if latitude > 89.8:\n            latitude = 89.8\n\n        if latitude < -89.8:\n            latitude = -89.8\n\n        if dateandtime.tzinfo is None:\n            zone = 0\n            utc_datetime = dateandtime\n        else:\n            zone = -dateandtime.utcoffset().total_seconds() / 3600.0\n            utc_datetime = dateandtime.astimezone(pytz.utc)\n\n        timenow = (\n            utc_datetime.hour\n            + (utc_datetime.minute / 60.0)\n            + (utc_datetime.second / 3600)\n        )\n\n        JD = self._julianday(dateandtime)\n        t = self._jday_to_jcentury(JD + timenow / 24.0)\n        theta = self._sun_declination(t)\n        eqtime = self._eq_of_time(t)\n        solarDec = theta  # in degrees\n\n        solarTimeFix = eqtime - (4.0 * -longitude) + (60 * zone)\n        trueSolarTime = (\n            dateandtime.hour * 60.0\n            + dateandtime.minute\n            + dateandtime.second / 60.0\n            + solarTimeFix\n        )\n        #    in minutes\n\n        while trueSolarTime > 1440:\n            trueSolarTime = trueSolarTime - 1440\n\n        hourangle = trueSolarTime / 4.0 - 180.0\n        # Thanks to Louis Schwarzmayr for the next line:\n        if hourangle < -180:\n            hourangle = hourangle + 360.0\n\n        harad = radians(hourangle)\n\n        csz = sin(radians(latitude)) * sin(radians(solarDec)) + cos(\n            radians(latitude)\n        ) * cos(radians(solarDec)) * cos(harad)\n\n        if csz > 1.0:\n            csz = 1.0\n        elif csz < -1.0:\n            csz = -1.0\n\n        zenith = degrees(acos(csz))\n\n        azDenom = cos(radians(latitude)) * sin(radians(zenith))\n\n        if abs(azDenom) > 0.001:\n            azRad = (\n                (sin(radians(latitude)) * cos(radians(zenith))) - sin(radians(solarDec))\n            ) / azDenom\n\n            if abs(azRad) > 1.0:\n                if azRad < 0:\n                    azRad = -1.0\n                else:\n                    azRad = 1.0\n\n            azimuth = 180.0 - degrees(acos(azRad))\n\n            if hourangle > 0.0:\n                azimuth = -azimuth\n        else:\n            if latitude > 0.0:\n                azimuth = 180.0\n            else:\n                azimuth = 0.0\n\n        if azimuth < 0.0:\n            azimuth = azimuth + 360.0\n\n        exoatmElevation = 90.0 - zenith\n\n        if exoatmElevation > 85.0:\n            refractionCorrection = 0.0\n        else:\n            te = tan(radians(exoatmElevation))\n            if exoatmElevation > 5.0:\n                refractionCorrection = (\n                    58.1 / te\n                    - 0.07 / (te * te * te)\n                    + 0.000086 / (te * te * te * te * te)\n                )\n            elif exoatmElevation > -0.575:\n                step1 = -12.79 + exoatmElevation * 0.711\n                step2 = 103.4 + exoatmElevation * (step1)\n                step3 = -518.2 + exoatmElevation * (step2)\n                refractionCorrection = 1735.0 + exoatmElevation * (step3)\n            else:\n                refractionCorrection = -20.774 / te\n\n            refractionCorrection = refractionCorrection / 3600.0\n\n        solarzen = zenith - refractionCorrection\n\n        solarelevation = 90.0 - solarzen\n\n        return solarelevation", "response": "Calculate the solar elevation angle of the sun."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates the solar zenith angle.", "response": "def solar_zenith(self, dateandtime, latitude, longitude):\n        \"\"\"Calculates the solar zenith angle.\n\n        :param dateandtime: The date and time for which to calculate\n                            the angle.\n        :type dateandtime: :class:`~datetime.datetime`\n        :param latitude:   Latitude - Northern latitudes should be positive\n        :type latitude:    float\n        :param longitude:  Longitude - Eastern longitudes should be positive\n        :type longitude:   float\n\n        :return: The zenith angle in degrees from vertical.\n        :rtype: float\n\n        If `dateandtime` is a naive Python datetime then it is assumed to be\n        in the UTC timezone.\n        \"\"\"\n\n        return 90.0 - self.solar_elevation(dateandtime, latitude, longitude)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the phase of the moon on the specified date.", "response": "def moon_phase(self, date, rtype=int):\n        \"\"\"Calculates the phase of the moon on the specified date.\n\n        :param date: The date to calculate the phase for.\n        :type date: :class:`datetime.date`\n        :param rtype: The type to return either int (default) or float.\n\n        :return:\n            A number designating the phase.\n\n                | 0  = New moon\n                | 7  = First quarter\n                | 14 = Full moon\n                | 21 = Last quarter\n        \"\"\"\n\n        if rtype != float and rtype != int:\n            rtype = int\n\n        moon = self._moon_phase_asfloat(date)\n        if moon >= 28.0:\n            moon -= 28.0\n        moon = rtype(moon)\n\n        return moon"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate ruhakaalam times in the UTC timezone.", "response": "def rahukaalam_utc(self, date, latitude, longitude, observer_elevation=0):\n        \"\"\"Calculate ruhakaalam times in the UTC timezone.\n\n        :param date:       Date to calculate for.\n        :type date:        :class:`datetime.date`\n        :param latitude:   Latitude - Northern latitudes should be positive\n        :type latitude:    float\n        :param longitude:  Longitude - Eastern longitudes should be positive\n        :type longitude:   float\n        :param observer_elevation:  Elevation in metres to calculate Rahukaalam for\n        :type observer_elevation:   int\n\n        :return: Tuple containing the start and end times for Rahukaalam.\n        :rtype: tuple\n        \"\"\"\n\n        if date is None:\n            date = datetime.date.today()\n\n        sunrise = self.sunrise_utc(date, latitude, longitude, observer_elevation)\n        sunset = self.sunset_utc(date, latitude, longitude, observer_elevation)\n\n        octant_duration = datetime.timedelta(seconds=(sunset - sunrise).seconds / 8)\n\n        # Mo,Sa,Fr,We,Th,Tu,Su\n        octant_index = [1, 6, 4, 5, 3, 2, 7]\n\n        weekday = date.weekday()\n        octant = octant_index[weekday]\n\n        start = sunrise + (octant_duration * octant)\n        end = start + octant_duration\n\n        return start, end"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _depression_adjustment(self, elevation):\n\n        if elevation <= 0:\n            return 0\n\n        r = 6356900 # radius of the earth\n        a1 = r\n        h1 = r + elevation\n        theta1 = acos(a1 / h1)\n\n        a2 = r * sin(theta1)\n        b2 = r - (r * cos(theta1))\n        h2 = sqrt(pow(a2, 2) + pow(b2, 2))\n        alpha = acos(a2 / h2)\n\n        return degrees(alpha)", "response": "Calculate the extra degrees of depression due to the increase in elevation."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_config_files(self):\n\n    files = []\n    check_environ()\n\n    # Where to look for the system-wide Distutils config file\n    sys_dir = os.path.dirname(sys.modules['distutils'].__file__)\n\n    # Look for the system config file\n    sys_file = os.path.join(sys_dir, \"distutils.cfg\")\n    if os.path.isfile(sys_file):\n        files.append(sys_file)\n\n    # What to call the per-user config file\n    if os.name == 'posix':\n        user_filename = \".pydistutils.cfg\"\n    else:\n        user_filename = \"pydistutils.cfg\"\n\n    # And look for the user config file\n    if self.want_user_cfg:\n        user_file = os.path.join(os.path.expanduser('~'), user_filename)\n        if os.path.isfile(user_file):\n            files.append(user_file)\n\n    # All platforms support local setup.cfg\n    local_file = \"setup.cfg\"\n    if os.path.isfile(local_file):\n        files.append(local_file)\n\n    local_dev_file = \"setup-dev.cfg\"\n    if os.path.isfile(local_dev_file):\n        files.append(local_dev_file)\n\n    if DEBUG:\n        self.announce(\"using config files: %s\" % ', '.join(files))\n\n    return files", "response": "Find all configuration files that should be parsed for this platform and return a list of filenames in the order in which they should be parsed."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef callback(status, message, job, result, exception, stacktrace):\n    assert status in ['invalid', 'success', 'timeout', 'failure']\n    assert isinstance(message, Message)\n\n    if status == 'invalid':\n        assert job is None\n        assert result is None\n        assert exception is None\n        assert stacktrace is None\n\n    if status == 'success':\n        assert isinstance(job, Job)\n        assert exception is None\n        assert stacktrace is None\n\n    elif status == 'timeout':\n        assert isinstance(job, Job)\n        assert result is None\n        assert exception is None\n        assert stacktrace is None\n\n    elif status == 'failure':\n        assert isinstance(job, Job)\n        assert result is None\n        assert exception is not None\n        assert stacktrace is not None", "response": "Example callback function.\n\n    :param status: Job status. Possible values are \"invalid\" (job could not be\n        deserialized or was malformed), \"failure\" (job raised an exception),\n        \"timeout\" (job timed out), or \"success\" (job finished successfully and\n        returned a result).\n    :type status: str\n    :param message: Kafka message.\n    :type message: kq.Message\n    :param job: Job object, or None if **status** was \"invalid\".\n    :type job: kq.Job\n    :param result: Job result, or None if an exception was raised.\n    :type result: object | None\n    :param exception: Exception raised by job, or None if there was none.\n    :type exception: Exception | None\n    :param stacktrace: Exception traceback, or None if there was none.\n    :type stacktrace: str | None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _execute_callback(self, status, message, job, res, err, stacktrace):\n        if self._callback is not None:\n            try:\n                self._logger.info('Executing callback ...')\n                self._callback(status, message, job, res, err, stacktrace)\n            except Exception as e:\n                self._logger.exception(\n                    'Callback raised an exception: {}'.format(e))", "response": "Execute the callback.\n\n        :param status: Job status. Possible values are \"invalid\" (job could not\n            be deserialized or was malformed), \"failure\" (job raised an error),\n            \"timeout\" (job timed out), or \"success\" (job finished successfully\n            and returned a result).\n        :type status: str\n        :param message: Kafka message.\n        :type message: :doc:`kq.Message <message>`\n        :param job: Job object, or None if **status** was \"invalid\".\n        :type job: kq.Job\n        :param res: Job result, or None if an exception was raised.\n        :type res: object | None\n        :param err: Exception raised by job, or None if there was none.\n        :type err: Exception | None\n        :param stacktrace: Exception traceback, or None if there was none.\n        :type stacktrace: str | None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _process_message(self, msg):\n        self._logger.info(\n            'Processing Message(topic={}, partition={}, offset={}) ...'\n            .format(msg.topic, msg.partition, msg.offset))\n        try:\n            job = self._deserializer(msg.value)\n            job_repr = get_call_repr(job.func, *job.args, **job.kwargs)\n\n        except Exception as err:\n            self._logger.exception('Job was invalid: {}'.format(err))\n            self._execute_callback('invalid', msg, None, None, None, None)\n        else:\n            self._logger.info('Executing job {}: {}'.format(job.id, job_repr))\n\n            if job.timeout:\n                timer = threading.Timer(job.timeout, _thread.interrupt_main)\n                timer.start()\n            else:\n                timer = None\n            try:\n                res = job.func(*job.args, **job.kwargs)\n            except KeyboardInterrupt:\n                self._logger.error(\n                    'Job {} timed out or was interrupted'.format(job.id))\n                self._execute_callback('timeout', msg, job, None, None, None)\n            except Exception as err:\n                self._logger.exception(\n                    'Job {} raised an exception:'.format(job.id))\n                tb = traceback.format_exc()\n                self._execute_callback('failure', msg, job, None, err, tb)\n            else:\n                self._logger.info('Job {} returned: {}'.format(job.id, res))\n                self._execute_callback('success', msg, job, res, None, None)\n            finally:\n                if timer is not None:\n                    timer.cancel()", "response": "De - serialize the message and execute the job."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef start(self, max_messages=math.inf, commit_offsets=True):\n        self._logger.info('Starting {} ...'.format(self))\n\n        self._consumer.unsubscribe()\n        self._consumer.subscribe([self.topic])\n\n        messages_processed = 0\n        while messages_processed < max_messages:\n            record = next(self._consumer)\n\n            message = Message(\n                topic=record.topic,\n                partition=record.partition,\n                offset=record.offset,\n                key=record.key,\n                value=record.value\n            )\n            self._process_message(message)\n\n            if commit_offsets:\n                self._consumer.commit()\n\n            messages_processed += 1\n\n        return messages_processed", "response": "Starts processing Kafka messages and executing jobs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_call_repr(func, *args, **kwargs):\n    # Functions, builtins and methods\n    if ismethod(func) or isfunction(func) or isbuiltin(func):\n        func_repr = '{}.{}'.format(func.__module__, func.__qualname__)\n    # A callable class instance\n    elif not isclass(func) and hasattr(func, '__call__'):\n        func_repr = '{}.{}'.format(func.__module__, func.__class__.__name__)\n    else:\n        func_repr = repr(func)\n\n    args_reprs = [repr(arg) for arg in args]\n    kwargs_reprs = [k + '=' + repr(v) for k, v in sorted(kwargs.items())]\n    return '{}({})'.format(func_repr, ', '.join(args_reprs + kwargs_reprs))", "response": "Return the string representation of the function call."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef using(self, timeout=None, key=None, partition=None):\n        return EnqueueSpec(\n            topic=self._topic,\n            producer=self._producer,\n            serializer=self._serializer,\n            logger=self._logger,\n            timeout=timeout or self._timeout,\n            key=key,\n            partition=partition\n        )", "response": "Set the enqueue specifications such as timeout key and partition."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef enqueue(self, obj, *args, **kwargs):\n        timestamp = int(time.time() * 1000)\n\n        if isinstance(obj, Job):\n            job_id = uuid.uuid4().hex if obj.id is None else obj.id\n            func = obj.func\n            args = tuple() if obj.args is None else obj.args\n            kwargs = {} if obj.kwargs is None else obj.kwargs\n            timeout = self._timeout if obj.timeout is None else obj.timeout\n            key = self._key if obj.key is None else obj.key\n            partition = self._part if obj.partition is None else obj.partition\n\n            assert is_str(job_id), 'Job.id must be a str'\n            assert callable(func), 'Job.func must be a callable'\n            assert is_iter(args), 'Job.args must be a list or tuple'\n            assert is_dict(kwargs), 'Job.kwargs must be a dict'\n            assert is_number(timeout), 'Job.timeout must be an int or float'\n            assert is_none_or_bytes(key), 'Job.key must be a bytes'\n            assert is_none_or_int(partition), 'Job.partition must be an int'\n        else:\n            assert callable(obj), 'first argument must be a callable'\n            job_id = uuid.uuid4().hex\n            func = obj\n            args = args\n            kwargs = kwargs\n            timeout = self._timeout\n            key = self._key\n            partition = self._part\n\n        job = Job(\n            id=job_id,\n            timestamp=timestamp,\n            topic=self._topic,\n            func=func,\n            args=args,\n            kwargs=kwargs,\n            timeout=timeout,\n            key=key,\n            partition=partition\n        )\n        self._logger.info('Enqueueing {} ...'.format(job))\n        self._producer.send(\n            self._topic,\n            value=self._serializer(job),\n            key=self._serializer(key) if key else None,\n            partition=partition,\n            timestamp_ms=timestamp\n        )\n        return job", "response": "Enqueue a function call or job instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nensuring that a path exists.", "response": "def ensure_path_exists(dir_path):\n    \"\"\"\n    Make sure that a path exists\n    \"\"\"\n    if not os.path.exists(dir_path):\n        os.makedirs(dir_path)\n        return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend a list of bytes to a specific backend.", "response": "def send(instructions, printer_identifier=None, backend_identifier=None, blocking=True):\n    \"\"\"\n    Send instruction bytes to a printer.\n\n    :param bytes instructions: The instructions to be sent to the printer.\n    :param str printer_identifier: Identifier for the printer.\n    :param str backend_identifier: Can enforce the use of a specific backend.\n    :param bool blocking: Indicates whether the function call should block while waiting for the completion of the printing.\n    \"\"\"\n\n    status = {\n      'instructions_sent': True, # The instructions were sent to the printer.\n      'outcome': 'unknown', # String description of the outcome of the sending operation like: 'unknown', 'sent', 'printed', 'error'\n      'printer_state': None, # If the selected backend supports reading back the printer state, this key will contain it.\n      'did_print': False, # If True, a print was produced. It defaults to False if the outcome is uncertain (due to a backend without read-back capability).\n      'ready_for_next_job': False, # If True, the printer is ready to receive the next instructions. It defaults to False if the state is unknown.\n    }\n    selected_backend = None\n    if backend_identifier:\n        selected_backend = backend_identifier\n    else:\n        try:\n            selected_backend = guess_backend(printer_identifier)\n        except:\n            logger.info(\"No backend stated. Selecting the default linux_kernel backend.\")\n            selected_backend = 'linux_kernel'\n\n    be = backend_factory(selected_backend)\n    list_available_devices = be['list_available_devices']\n    BrotherQLBackend       = be['backend_class']\n\n    printer = BrotherQLBackend(printer_identifier)\n\n    start = time.time()\n    logger.info('Sending instructions to the printer. Total: %d bytes.', len(instructions))\n    printer.write(instructions)\n    status['outcome'] = 'sent'\n\n    if not blocking:\n        return status\n    if selected_backend == 'network':\n        \"\"\" No need to wait for completion. The network backend doesn't support readback. \"\"\"\n        return status\n\n    while time.time() - start < 10:\n        data = printer.read()\n        if not data:\n            time.sleep(0.005)\n            continue\n        try:\n            result = interpret_response(data)\n        except ValueError:\n            logger.error(\"TIME %.3f - Couln't understand response: %s\", time.time()-start, data)\n            continue\n        status['printer_state'] = result\n        logger.debug('TIME %.3f - result: %s', time.time()-start, result)\n        if result['errors']:\n            logger.error('Errors occured: %s', result['errors'])\n            status['outcome'] = 'error'\n            break\n        if result['status_type'] == 'Printing completed':\n            status['did_print'] = True\n            status['outcome'] = 'printed'\n        if result['status_type'] == 'Phase change' and result['phase_type'] == 'Waiting to receive':\n            status['ready_for_next_job'] = True\n        if status['did_print'] and status['ready_for_next_job']:\n            break\n\n    if not status['did_print']:\n        logger.warning(\"'printing completed' status not received.\")\n    if not status['ready_for_next_job']:\n        logger.warning(\"'waiting to receive' status not received.\")\n    if (not status['did_print']) or (not status['ready_for_next_job']):\n        logger.warning('Printing potentially not successful?')\n    if status['did_print'] and status['ready_for_next_job']:\n        logger.info(\"Printing was successful. Waiting for the next job.\")\n\n    return status"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef chunker(data, raise_exception=False):\n    instructions = []\n    data = bytes(data)\n    while True:\n        if len(data) == 0: break\n        try:\n            opcode = match_opcode(data)\n        except:\n            msg = 'unknown opcode starting with {}...)'.format(hex_format(data[0:4]))\n            if raise_exception:\n                raise ValueError(msg)\n            else:\n                logger.warning(msg)\n                data = data[1:]\n                continue\n        opcode_def = OPCODES[opcode]\n        num_bytes = len(opcode)\n        if opcode_def[1] > 0: num_bytes += opcode_def[1]\n        if 'raster' in opcode_def[0]:\n            num_bytes += data[2] + 2\n        #payload = data[len(opcode):num_bytes]\n        instructions.append(data[:num_bytes])\n        data = data[num_bytes:]\n    return instructions", "response": "Splits data into a list of bytes objects containing single instructions each."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmerge specific instructions into a single list of instructions.", "response": "def merge_specific_instructions(chunks, join_preamble=True, join_raster=True):\n    \"\"\"\n    Process a list of instructions by merging subsequent instuctions with\n    identical opcodes into \"large instructions\".\n    \"\"\"\n    new_instructions = []\n    last_opcode = None\n    instruction_buffer = b''\n    for instruction in chunks:\n        opcode = match_opcode(instruction)\n        if   join_preamble and OPCODES[opcode][0] == 'preamble' and last_opcode == 'preamble':\n            instruction_buffer += instruction\n        elif join_raster   and 'raster' in OPCODES[opcode][0] and 'raster' in last_opcode:\n            instruction_buffer += instruction\n        else:\n            if instruction_buffer:\n                new_instructions.append(instruction_buffer)\n            instruction_buffer = instruction\n        last_opcode = OPCODES[opcode][0]\n    if instruction_buffer:\n        new_instructions.append(instruction_buffer)\n    return new_instructions"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfilters an image by HSV", "response": "def filtered_hsv(im, filter_h, filter_s, filter_v, default_col=(255,255,255)):\n    \"\"\" https://stackoverflow.com/a/22237709/183995 \"\"\"\n\n    hsv_im = im.convert('HSV')\n    H, S, V = 0, 1, 2\n    hsv = hsv_im.split()\n    mask_h = hsv[H].point(filter_h)\n    mask_s = hsv[S].point(filter_s)\n    mask_v = hsv[V].point(filter_v)\n\n    Mdat = []\n    for h, s, v in zip(mask_h.getdata(), mask_s.getdata(), mask_v.getdata()):\n        Mdat.append(255 if (h and s and v) else 0)\n\n    mask = mask_h\n    mask.putdata(Mdat)\n\n    filtered_im = Image.new(\"RGB\", im.size, color=default_col)\n    filtered_im.paste(im, None, mask)\n    return filtered_im"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _warn(self, problem, kind=BrotherQLRasterError):\n        if self.exception_on_warning:\n            raise kind(problem)\n        else:\n            logger.warning(problem)", "response": "Logs a warning message problem or raises a\n            exception."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nswitching dynamic command mode", "response": "def add_switch_mode(self):\n        \"\"\"\n        Switch dynamic command mode\n        Switch to the raster mode on the printers that support\n        the mode change (others are in raster mode already).\n        \"\"\"\n        if self.model not in modesetting:\n            self._unsupported(\"Trying to switch the operating mode on a printer that doesn't support the command.\")\n            return\n        self.data += b'\\x1B\\x69\\x61\\x01'"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_compression(self, compression=True):\n        if self.model not in compressionsupport:\n            self._unsupported(\"Trying to set compression on a printer that doesn't support it\")\n            return\n        self._compression = compression\n        self.data += b'\\x4D' # M\n        self.data += bytes([compression << 1])", "response": "Add an instruction enabling or disabling compression for the transmitted raster image lines."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_raster_data(self, image, second_image=None):\n        logger.debug(\"raster_image_size: {0}x{1}\".format(*image.size))\n        if image.size[0] != self.get_pixel_width():\n            fmt = 'Wrong pixel width: {}, expected {}'\n            raise BrotherQLRasterError(fmt.format(image.size[0], self.get_pixel_width()))\n        images = [image]\n        if second_image:\n            if image.size != second_image.size:\n                fmt = \"First and second image don't have the same dimesions: {} vs {}.\"\n                raise BrotherQLRasterError(fmt.format(image.size, second_image.size))\n            images.append(second_image)\n        frames = []\n        for image in images:\n            image = image.transpose(Image.FLIP_LEFT_RIGHT)\n            image = image.convert(\"1\")\n            frames.append(bytes(image.tobytes(encoder_name='raw')))\n        frame_len = len(frames[0])\n        row_len = images[0].size[0]//8\n        start = 0\n        file_str = BytesIO()\n        while start + row_len <= frame_len:\n            for i, frame in enumerate(frames):\n                row = frame[start:start+row_len]\n                if second_image:\n                    file_str.write(b'\\x77\\x01' if i == 0 else b'\\x77\\x02')\n                else:\n                    file_str.write(b'\\x67\\x00')\n                if self._compression:\n                    row = packbits.encode(row)\n                file_str.write(bytes([len(row)]))\n                file_str.write(row)\n            start += row_len\n        self.data += file_str.getvalue()", "response": "Add the image data to the instructions."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cli(ctx, *args, **kwargs):\n\n    backend = kwargs.get('backend', None)\n    model = kwargs.get('model', None)\n    printer = kwargs.get('printer', None)\n    debug = kwargs.get('debug')\n\n    # Store the general CLI options in the context meta dictionary.\n    # The name corresponds to the second half of the respective envvar:\n    ctx.meta['MODEL'] = model\n    ctx.meta['BACKEND'] = backend\n    ctx.meta['PRINTER'] = printer\n\n    logging.basicConfig(level='DEBUG' if debug else 'INFO')", "response": "Command line interface for the brother_ql Python package."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef labels(ctx, *args, **kwargs):\n    from brother_ql.output_helpers import textual_label_description\n    print(textual_label_description(label_sizes))", "response": "Display the label sizes of the selected items."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef env(ctx, *args, **kwargs):\n    import sys, platform, os, shutil\n    from pkg_resources import get_distribution, working_set\n    print(\"\\n##################\\n\")\n    print(\"Information about the running environment of brother_ql.\")\n    print(\"(Please provide this information when reporting any issue.)\\n\")\n    # computer\n    print(\"About the computer:\")\n    for attr in ('platform', 'processor', 'release', 'system', 'machine', 'architecture'):\n        print('  * '+attr.title()+':', getattr(platform, attr)())\n    # Python\n    print(\"About the installed Python version:\")\n    py_version = str(sys.version).replace('\\n', ' ')\n    print(\"  *\", py_version)\n    # brother_ql\n    print(\"About the brother_ql package:\")\n    pkg = get_distribution('brother_ql')\n    print(\"  * package location:\", pkg.location)\n    print(\"  * package version: \", pkg.version)\n    try:\n        cli_loc = shutil.which('brother_ql')\n    except:\n        cli_loc = 'unknown'\n    print(\"  * brother_ql CLI path:\", cli_loc)\n    # brother_ql's requirements\n    print(\"About the requirements of brother_ql:\")\n    fmt = \"  {req:14s} | {spec:10s} | {ins_vers:17s}\"\n    print(fmt.format(req='requirement', spec='requested', ins_vers='installed version'))\n    print(fmt.format(req='-' * 14, spec='-'*10, ins_vers='-'*17))\n    requirements = list(pkg.requires())\n    requirements.sort(key=lambda x: x.project_name)\n    for req in requirements:\n        proj = req.project_name\n        req_pkg = get_distribution(proj)\n        spec = ' '.join(req.specs[0]) if req.specs else 'any'\n        print(fmt.format(req=proj, spec=spec, ins_vers=req_pkg.version))\n    print(\"\\n##################\\n\")", "response": "Print the current running environment of brother_ql."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprinting a label of the IMAGE.", "response": "def print_cmd(ctx, *args, **kwargs):\n    \"\"\" Print a label of the provided IMAGE. \"\"\"\n    backend = ctx.meta.get('BACKEND', 'pyusb')\n    model = ctx.meta.get('MODEL')\n    printer = ctx.meta.get('PRINTER')\n    from brother_ql.conversion import convert\n    from brother_ql.backends.helpers import send\n    from brother_ql.raster import BrotherQLRaster\n    qlr = BrotherQLRaster(model)\n    qlr.exception_on_warning = True\n    kwargs['cut'] = not kwargs['no_cut']\n    del kwargs['no_cut']\n    instructions = convert(qlr=qlr, **kwargs)\n    send(instructions=instructions, printer_identifier=printer, backend_identifier=backend, blocking=True)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlist all available devices for the respective backend.", "response": "def list_available_devices():\n    \"\"\"\n    List all available devices for the respective backend\n\n    returns: devices: a list of dictionaries with the keys 'identifier' and 'instance': \\\n        [ {'identifier': 'usb://0x04f9:0x2015/C5Z315686', 'instance': pyusb.core.Device()}, ]\n        The 'identifier' is of the format idVendor:idProduct_iSerialNumber.\n    \"\"\"\n\n    class find_class(object):\n        def __init__(self, class_):\n            self._class = class_\n        def __call__(self, device):\n            # first, let's check the device\n            if device.bDeviceClass == self._class:\n                return True\n            # ok, transverse all devices to find an interface that matches our class\n            for cfg in device:\n                # find_descriptor: what's it?\n                intf = usb.util.find_descriptor(cfg, bInterfaceClass=self._class)\n                if intf is not None:\n                    return True\n            return False\n\n    # only Brother printers\n    printers = usb.core.find(find_all=1, custom_match=find_class(7), idVendor=0x04f9)\n\n    def identifier(dev):\n        try:\n            serial = usb.util.get_string(dev, 256, dev.iSerialNumber)\n            return 'usb://0x{:04x}:0x{:04x}_{}'.format(dev.idVendor, dev.idProduct, serial)\n        except:\n            return 'usb://0x{:04x}:0x{:04x}'.format(dev.idVendor, dev.idProduct)\n\n    return [{'identifier': identifier(printer), 'instance': printer} for printer in printers]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npopulating the global structures that are used by the legacy label types.", "response": "def _populate_label_legacy_structures():\n    \"\"\"\n    We contain this code inside a function so that the imports\n    we do in here are not visible at the module level.\n    \"\"\"\n    global DIE_CUT_LABEL, ENDLESS_LABEL, ROUND_DIE_CUT_LABEL\n    global label_sizes, label_type_specs\n\n    from brother_ql.labels import FormFactor\n    DIE_CUT_LABEL =       FormFactor.DIE_CUT\n    ENDLESS_LABEL =       FormFactor.ENDLESS\n    ROUND_DIE_CUT_LABEL = FormFactor.ROUND_DIE_CUT\n\n    from brother_ql.labels import LabelsManager\n    lm = LabelsManager()\n    label_sizes = list(lm.iter_identifiers())\n    for label in lm.iter_elements():\n        l = {}\n        l['name'] = label.name\n        l['kind'] = label.form_factor\n        l['color'] = label.color\n        l['tape_size'] = label.tape_size\n        l['dots_total'] = label.dots_total\n        l['dots_printable'] = label.dots_printable\n        l['right_margin_dots'] = label.offset_r\n        l['feed_margin'] = label.feed_margin\n        l['restrict_printers'] = label.restricted_to_models\n        label_type_specs[label.identifier] = l"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef guess_backend(identifier):\n    if identifier.startswith('usb://') or identifier.startswith('0x'):\n        return 'pyusb'\n    elif identifier.startswith('file://') or identifier.startswith('/dev/usb/') or identifier.startswith('lp'):\n        return 'linux_kernel'\n    elif identifier.startswith('tcp://'):\n        return 'network'\n    else:\n        raise ValueError('Cannot guess backend for given identifier: %s' % identifier)", "response": "Guess the backend from a given identifier string"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef autocomplete_query(self, **kwargs):\n        if not kwargs.get('text'):\n            raise ValueError('Valid text (parameter \"text\") must be provided.')\n\n        return self._query(AUTOCOMPLETE_API_URL, **kwargs)", "response": "Query the Yelp Autocomplete API."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nquery the Yelp Business API.", "response": "def business_query(self, id, **kwargs):\n        \"\"\"\n            Query the Yelp Business API.\n            \n            documentation: https://www.yelp.com/developers/documentation/v3/business\n\n            required parameters:\n                * id - business ID\n        \"\"\"\n        if not id:\n            raise ValueError('A valid business ID (parameter \"id\") must be provided.')\n\n        return self._query(BUSINESS_API_URL.format(id), **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nqueries the Yelp Business Match API.", "response": "def business_match_query(self, **kwargs):\n        \"\"\"\n            Query the Yelp Business Match API.\n            \n            documentation: https://www.yelp.com/developers/documentation/v3/business_match\n\n            required parameters:\n                * name - business name\n                * city\n                * state\n                * country\n                * address1\n\n            NOTE: `match_type` is deprecated since April 1, 2019.\n        \"\"\"\n        if not kwargs.get('name'):\n            raise ValueError('Valid business name (parameter \"name\") must be provided.')\n\n        if not kwargs.get('city'):\n            raise ValueError('Valid city (parameter \"city\") must be provided.')\n\n        if not kwargs.get('state'):\n            raise ValueError('Valid state (parameter \"state\") must be provided.')\n\n        if not kwargs.get('country'):\n            raise ValueError('Valid country (parameter \"country\") must be provided.')\n\n        if not kwargs.get('address1'):\n            raise ValueError('Valid address (parameter \"address1\") must be provided.')\n\n        return self._query(BUSINESS_MATCH_API_URL, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nquerying the Yelp Event Lookup API.", "response": "def event_lookup_query(self, id, **kwargs):\n        \"\"\"\n            Query the Yelp Event Lookup API.\n            \n            documentation: https://www.yelp.com/developers/documentation/v3/event\n\n            required parameters:\n                * id - event ID\n        \"\"\"\n        if not id:\n            raise ValueError('A valid event ID (parameter \"id\") must be provided.')\n\n        return self._query(EVENT_LOOKUP_API_URL.format(id), **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nquery the Yelp Featured Event API.", "response": "def featured_event_query(self, **kwargs):\n        \"\"\"\n            Query the Yelp Featured Event API.\n\n            documentation: https://www.yelp.com/developers/documentation/v3/featured_event\n\n            required parameters:\n                * one of either:\n                    * location - text specifying a location to search for\n                    * latitude and longitude\n        \"\"\"\n        if not kwargs.get('location') and (not kwargs.get('latitude') or not kwargs.get('longitude')):\n            raise ValueError('A valid location (parameter \"location\") or latitude/longitude combination '\n                             '(parameters \"latitude\" and \"longitude\") must be provided.')\n\n        return self._query(FEATURED_EVENT_API_URL, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nqueries the Yelp Phone Search API.", "response": "def phone_search_query(self, **kwargs):\n        \"\"\"\n            Query the Yelp Phone Search API.\n            \n            documentation: https://www.yelp.com/developers/documentation/v3/business_search_phone\n\n            required parameters:\n                * phone - phone number\n        \"\"\"\n        if not kwargs.get('phone'):\n            raise ValueError('A valid phone number (parameter \"phone\") must be provided.')\n\n        return self._query(PHONE_SEARCH_API_URL, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reviews_query(self, id, **kwargs):\n        if not id:\n            raise ValueError('A valid business ID (parameter \"id\") must be provided.')\n\n        return self._query(REVIEWS_API_URL.format(id), **kwargs)", "response": "Query the Yelp Reviews API."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsearching for a specific entry in the cache.", "response": "def search_query(self, **kwargs):\n        \"\"\"\n            Query the Yelp Search API.\n            \n            documentation: https://www.yelp.com/developers/documentation/v3/business_search\n\n            required parameters:\n                * one of either:\n                    * location - text specifying a location to search for\n                    * latitude and longitude\n        \"\"\"\n        if not kwargs.get('location') and (not kwargs.get('latitude') or not kwargs.get('longitude')):\n            raise ValueError('A valid location (parameter \"location\") or latitude/longitude combination '\n                             '(parameters \"latitude\" and \"longitude\") must be provided.')\n\n        return self._query(SEARCH_API_URL, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef transaction_search_query(self, transaction_type, **kwargs):\n        if not transaction_type:\n            raise ValueError('A valid transaction type (parameter \"transaction_type\") must be provided.')\n\n        if not kwargs.get('location') and (not kwargs.get('latitude') or not kwargs.get('longitude')):\n            raise ValueError('A valid location (parameter \"location\") or latitude/longitude combination '\n                             '(parameters \"latitude\" and \"longitude\") must be provided.')\n\n        return self._query(TRANSACTION_SEARCH_API_URL.format(transaction_type), **kwargs)", "response": "This method is used to query the Yelp Transaction Search API."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncleans the parameters by filtering out any parameters that have a None value.", "response": "def _get_clean_parameters(kwargs):\n        \"\"\"\n            Clean the parameters by filtering out any parameters that have a None value.\n        \"\"\"\n        return dict((k, v) for k, v in kwargs.items() if v is not None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _query(self, url, **kwargs):\n        parameters = YelpAPI._get_clean_parameters(kwargs)\n        response = self._yelp_session.get(\n            url,\n            headers=self._headers,\n            params=parameters,\n            timeout=self._timeout_s,\n        )\n        response_json = response.json()  # shouldn't happen, but this will raise a ValueError if the response isn't JSON\n\n        # Yelp can return one of many different API errors, so check for one of them.\n        # The Yelp Fusion API does not yet have a complete list of errors, but this is on the TODO list; see\n        # https://github.com/Yelp/yelp-fusion/issues/95 for more info.\n        if 'error' in response_json:\n            raise YelpAPI.YelpAPIError('{}: {}'.format(response_json['error']['code'],\n                                                       response_json['error']['description']))\n\n        # we got a good response, so return\n        return response_json", "response": "Query the Yelp API for the specified URL and return the parsed JSON."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the fully qualified key for the given key.", "response": "def _qualified_key(self, key):\n        \"\"\"\n        Prepends the configured prefix to the key (if applicable).\n\n        For Consul we also lstrip any '/' chars from the prefixed key.\n\n        :param key: The unprefixed key.\n        :return: The key with any configured prefix prepended.\n        \"\"\"\n        fq_key = super(Reader, self)._qualified_key(key)\n        return fq_key.lstrip('/')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the qualified key for the given key.", "response": "def _qualified_key(self, key):\n        \"\"\"\n        Prepends the configured prefix to the key (if applicable).\n\n        :param key: The unprefixed key.\n        :return: The key with any configured prefix prepended.\n        \"\"\"\n        pfx = self.key_prefix if self.key_prefix is not None else ''\n        return '{}{}'.format(pfx, key)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef url_join(base, *args):\n    scheme, netloc, path, query, fragment = urlsplit(base)\n    path = path if len(path) else \"/\"\n    path = posixpath.join(path, *[('%s' % x) for x in args])\n    return urlunsplit([scheme, netloc, path, query, fragment])", "response": "Helper function to join an arbitrary number of url segments together."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef probe_to_graphsrv(probe):\n\n    config = probe.config\n\n    # manual group set up via `group` config key\n\n    if \"group\" in config:\n        source, group = config[\"group\"].split(\".\")\n        group_field = config.get(\"group_field\", \"host\")\n        group_value = config[group_field]\n        graphsrv.group.add(source, group, {group_value:{group_field:group_value}}, **config)\n        return\n\n    # automatic group setup for fping\n    # FIXME: this should be somehow more dynamic\n\n    for k, v in list(config.items()):\n        if isinstance(v, dict) and \"hosts\" in v:\n            r = {}\n            for host in v.get(\"hosts\"):\n                if isinstance(host, dict):\n                    r[host[\"host\"]] = host\n                else:\n                    r[host] = {\"host\":host}\n            graphsrv.group.add(probe.name, k, r, **v)", "response": "Takes a probe instance and generates a graphsrv data group for it using the probe s config"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new message setting type source ts data", "response": "def new_message(self):\n        \"\"\"\n        creates a new message, setting `type`, `source`, `ts`, `data`\n        - `data` is initialized to an empty array\n        \"\"\"\n        msg = {}\n        msg['data'] = []\n        msg['type'] = self.plugin_type\n        msg['source'] = self.name\n        msg['ts'] = (datetime.datetime.utcnow() - datetime.datetime(1970, 1, 1)).total_seconds()\n        return msg"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a subprocess with passed args", "response": "def popen(self, args, **kwargs):\n        \"\"\"\n        creates a subprocess with passed args\n        \"\"\"\n        self.log.debug(\"popen %s\", ' '.join(args))\n        return vaping.io.subprocess.Popen(args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nqueuing an emission of a message for all output plugins", "response": "def queue_emission(self, msg):\n        \"\"\"\n        queue an emission of a message for all output plugins\n        \"\"\"\n        if not msg:\n            return\n        for _emitter in self._emit:\n            if not hasattr(_emitter, 'emit'):\n                continue\n            def emit(emitter=_emitter):\n                self.log.debug(\"emit to {}\".format(emitter.name))\n                emitter.emit(msg)\n            self.log.debug(\"queue emission to {} ({})\".format(\n                           _emitter.name, self._emit_queue.qsize()))\n            self._emit_queue.put(emit)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends an emission from the queue", "response": "def send_emission(self):\n        \"\"\"\n        emit and remove the first emission in the queue\n        \"\"\"\n        if self._emit_queue.empty():\n            return\n        emit = self._emit_queue.get()\n        emit()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate_file_handler(self):\n        if self.fh.closed:\n            try:\n                self.fh = open(self.path, \"r\")\n                self.fh.seek(0, 2)\n            except OSError as err:\n                logging.error(\"Could not reopen file: {}\".format(err))\n                return False\n\n        open_stat = os.fstat(self.fh.fileno())\n        try:\n            file_stat = os.stat(self.path)\n        except OSError as err:\n            logging.error(\"Could not stat file: {}\".format(err))\n            return False\n\n        if open_stat != file_stat:\n            self.log\n            self.fh.close()\n            return False\n\n        return True", "response": "This function checks that our filehandler is pointing to an existing file and that the file is still open and that the file is still open."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef probe(self):\n\n        # make sure the filehandler is still valid\n        # (e.g. file stat hasnt changed, file exists etc.)\n        if not self.validate_file_handler():\n            return []\n\n        messages = []\n\n        # read any new lines and push them onto the stack\n        for line in self.fh.readlines(self.max_lines):\n            data = {\"path\":self.path}\n            msg = self.new_message()\n\n            # process the line - this is where parsing happens\n            parsed = self.process_line(line, data)\n            if not parsed:\n                continue\n            data.update(parsed)\n\n            # process the probe - this is where data assignment\n            # happens\n            data = self.process_probe(data)\n            msg[\"data\"] = [data]\n            messages.append(msg)\n\n\n        # process all new messages before returning them\n        # for emission\n        messages = self.process_messages(messages)\n\n        return messages", "response": "Probe the file for new lines and return a list of the messages."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef filename_formatters(self, data, row):\n\n        r = {\n            \"source\" : data.get(\"source\"),\n            \"field\" : self.field,\n            \"type\" : data.get(\"type\")\n        }\n        r.update(**row)\n        return r", "response": "Returns a dict containing the various filename formatter values that are used in the vaping message."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef format_filename(self, data, row):\n        return self.filename.format(**self.filename_formatters(data, row))", "response": "Formats the filename using the filename_formatters"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef emit(self, message):\n        # handle vaping data that arrives in a list\n        if isinstance(message.get(\"data\"), list):\n            for row in message.get(\"data\"):\n\n\n                # format filename from data\n                filename = self.format_filename(message, row)\n\n                # create database file if it does not exist yet\n                if not os.path.exists(filename):\n                    self.create(filename)\n\n                # update database\n                self.log.debug(\"storing time:%d, %s:%.5f in %s\" % (\n                    message.get(\"ts\"), self.field, row.get(self.field), filename))\n                self.update(filename, message.get(\"ts\"), row.get(self.field))", "response": "handle vaping data that arrives in a list of dicts"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_interval(val):\n    re_intv = re.compile(r\"([\\d\\.]+)([a-zA-Z]+)\")\n    val = val.strip()\n\n    total = 0.0\n    for match in re_intv.findall(val):\n        unit = match[1]\n        count = float(match[0])\n        if unit == 's':\n            total += count\n        elif unit == 'm':\n            total += count * 60\n        elif unit == 'ms':\n            total += count / 1000\n        elif unit == \"h\":\n            total += count * 3600\n        elif unit == 'd':\n            total += count * 86400\n        else:\n            raise ValueError(\"unknown unit from interval string '%s'\" % val)\n    return total", "response": "converts a string to float of seconds\nAttributeNames. 5 = 500ms\nAttributeNames 90 = 1m30s\nAttributeNames. 5 = 90ms\nAttributeNames. 5 = 500ms\nAttributeNames 90 = 1m30s\nAttributeNames. 5 = 500ms\nAttributeNames 90 = 1m30s\nAttributeNames. 5 = 500ms\nAttributeNames 90 = 1m30s\nAttributeNames. 5 = 500ms\nAttributeNames 90 = 1m30s\nAttributeNames. 5 = 500ms\n"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of hosts that can be passed to the user", "response": "def hosts_args(self):\n        \"\"\"\n        hosts list can contain strings specifying a host directly\n        or dicts containing a \"host\" key to specify the host\n\n        this way we can allow passing further config details (color, name etc.)\n        with each host as well as simply dropping in addresses for quick\n        setup depending on the user's needs\n        \"\"\"\n\n        host_args = []\n        for row in self.hosts:\n            if isinstance(row, dict):\n                host_args.append(row[\"host\"])\n            else:\n                host_args.append(row)\n\n        # using a set changes the order\n        dedupe = list()\n        for each in host_args:\n            if each not in dedupe:\n                dedupe.append(each)\n        return dedupe"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse output from verbose format", "response": "def parse_verbose(self, line):\n        \"\"\"\n        parse output from verbose format\n        \"\"\"\n        try:\n            logging.debug(line)\n            (host, pings) = line.split(' : ')\n            cnt = 0\n            lost = 0\n            times = []\n            pings = pings.strip().split(' ')\n            cnt = len(pings)\n            for latency in pings:\n                if latency == '-':\n                    continue\n                times.append(float(latency))\n\n            lost = cnt - len(times)\n            if lost:\n                loss = lost / float(cnt)\n            else:\n                loss = 0.0\n\n            rv = {\n                'host': host.strip(),\n                'cnt': cnt,\n                'loss': loss,\n                'data': times,\n                }\n            if times:\n                rv['min'] = min(times)\n                rv['max'] = max(times)\n                rv['avg'] = sum(times) / len(times)\n                rv['last'] = times[-1]\n            return rv\n\n        except Exception as e:\n            logging.error(\"failed to get data: {}\".format(e))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstarts a vaping process", "response": "def start(ctx, **kwargs):\n    \"\"\"\n    start a vaping process\n    \"\"\"\n    update_context(ctx, kwargs)\n\n    daemon = mk_daemon(ctx)\n\n    if ctx.debug or kwargs['no_fork']:\n        daemon.run()\n    else:\n        daemon.start()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stop(ctx, **kwargs):\n    update_context(ctx, kwargs)\n\n    daemon = mk_daemon(ctx)\n    daemon.stop()", "response": "stop a vaping process"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrestarts a vaping process", "response": "def restart(ctx, **kwargs):\n    \"\"\"\n    restart a vaping process\n    \"\"\"\n    update_context(ctx, kwargs)\n\n    daemon = mk_daemon(ctx)\n    daemon.stop()\n    daemon.start()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _exec(self, detach=True):\n        kwargs = {\n            'pidfile': self.pidfile,\n            'working_directory': self.home_dir,\n            }\n\n        # FIXME - doesn't work\n        if not detach:\n            kwargs.update({\n                'detach_process': False,\n                'files_preserve': [0,1,2],\n                'stdout': sys.stdout,\n                'stderr': sys.stderr,\n                })\n\n        ctx = daemon.DaemonContext(**kwargs)\n\n        with ctx:\n            self._main()", "response": "daemonize and exec main"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlog the ASCII traceback into a file object.", "response": "def log(self, logfile=None):\n        \"\"\"Log the ASCII traceback into a file object.\"\"\"\n        if logfile is None:\n            logfile = sys.stderr\n        tb = self.plaintext.encode('utf-8', 'replace').rstrip() + '\\n'\n        logfile.write(tb)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef render_summary(self, app, include_title=True):\n        title = ''\n        frames = []\n        classes = ['traceback']\n        if not self.frames:\n            classes.append('noframe-traceback')\n\n        if include_title:\n            if self.is_syntax_error:\n                title = text_('Syntax Error')\n            else:\n                title = text_('Traceback <small>(most recent call last)'\n                              '</small>')\n\n        for frame in self.frames:\n            txt = frame.info\n            if not txt:\n                txt = text_(' title=\"%s\"' % escape(frame.info))\n            if not txt:\n                txt = text_('')\n            frames.append(\n                text_('<li%s>%s') % (txt, frame.render()))\n\n        if self.is_syntax_error:\n            description_wrapper = text_('<pre class=syntaxerror>%s</pre>')\n        else:\n            description_wrapper = text_('<blockquote>%s</blockquote>')\n        vars = {\n            'classes': text_(' '.join(classes)),\n            'title': title and text_('<h3 class=\"traceback\">%s</h3>'\n                                     % title) or text_(''),\n            'frames': text_('\\n'.join(frames)),\n            'description': description_wrapper % escape(self.exception),\n        }\n        return render('exception_summary.jinja2', app, vars)", "response": "Render the traceback for the interactive console."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef render_full(self, request, lodgeit_url=None):\n        static_path = request.app.router[STATIC_ROUTE_NAME].url_for(\n            filename='')\n        root_path = request.app.router[ROOT_ROUTE_NAME].url_for()\n        exc = escape(self.exception)\n        summary = self.render_summary(request.app, include_title=False)\n        token = request.app[APP_KEY]['pdtb_token']\n        qs = {'token': token, 'tb': str(self.id)}\n\n        url = request.app.router[EXC_ROUTE_NAME].url_for().with_query(qs)\n        evalex = request.app[APP_KEY]['exc_history'].eval_exc\n\n        vars = {\n            'evalex': evalex and 'true' or 'false',\n            'console': 'false',\n            'lodgeit_url': escape(lodgeit_url),\n            'title': exc,\n            'exception': exc,\n            'exception_type': escape(self.exception_type),\n            'summary': summary,\n            'plaintext': self.plaintext,\n            'plaintext_cs': re.sub('-{2,}', '-', self.plaintext),\n            'traceback_id': self.id,\n            'static_path': static_path,\n            'token': token,\n            'root_path': root_path,\n            'url': url,\n        }\n        return render('exception.jinja2', request.app, vars, request=request)", "response": "Render the Full HTML page with the traceback info."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrender a single frame in a traceback.", "response": "def render(self):\n        \"\"\"Render a single frame in a traceback.\"\"\"\n        return FRAME_HTML % {\n            'id': self.id,\n            'filename': escape(self.filename),\n            'lineno': self.lineno,\n            'function_name': escape(self.function_name),\n            'current_line': escape(self.current_line.strip())\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nevaluates code in the context of the frame.", "response": "def eval(self, code, mode='single'):\n        \"\"\"Evaluate code in the context of the frame.\"\"\"\n        if isinstance(code, str):\n            if isinstance(code, str):\n                code = UTF8_COOKIE + code.encode('utf-8')\n            code = compile(code, '<interactive>', mode)\n        if mode != 'exec':\n            return eval(code, self.globals, self.locals)\n        exec(code, self.globals, self.locals)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the HTML to be rendered for the current panel.", "response": "def render_content(self, request):\n        \"\"\"Return a string containing the HTML to be rendered for the panel.\n\n        By default this will render the template defined by the\n        :attr:`.template` attribute with a rendering context defined by\n        :attr:`.data` combined with the ``dict`` returned from\n        :meth:`.render_vars`.\n\n        The ``request`` here is the active request in the toolbar. Not the\n        original request that this panel represents.\n        \"\"\"\n        context = self.data.copy()\n        context.update(self.render_vars(request))\n        return render(self.template, request.app, context, request=request)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef inject(self, request, response):\n        # called in host app\n        if not isinstance(response, Response):\n            return\n        settings = request.app[APP_KEY]['settings']\n        response_html = response.body\n        route = request.app.router['debugtoolbar.request']\n        toolbar_url = route.url_for(request_id=request['id'])\n\n        button_style = settings['button_style']\n\n        css_path = request.app.router[STATIC_ROUTE_NAME].url_for(\n            filename='css/toolbar_button.css')\n\n        toolbar_css = toolbar_css_template % {'css_path': css_path}\n        toolbar_html = toolbar_html_template % {\n            'button_style': button_style,\n            'css_path': css_path,\n            'toolbar_url': toolbar_url}\n\n        toolbar_html = toolbar_html.encode(response.charset or 'utf-8')\n        toolbar_css = toolbar_css.encode(response.charset or 'utf-8')\n        response_html = replace_insensitive(\n            response_html, b'</head>', toolbar_css + b'</head>')\n        response.body = replace_insensitive(\n            response_html, b'</body>',\n            toolbar_html + b'</body>')", "response": "Inject the debug toolbar iframe into an HTML response."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef replace_insensitive(string, target, replacement):\n    no_case = string.lower()\n    index = no_case.rfind(target.lower())\n    if index >= 0:\n        return string[:index] + replacement + string[index + len(target):]\n    else:  # no results so return the original string\n        return string", "response": "Similar to string. replace but is case insensitive"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef common_segment_count(path, value):\n    i = 0\n    if len(path) <= len(value):\n        for x1, x2 in zip(path, value):\n            if x1 == x2:\n                i += 1\n            else:\n                return 0\n    return i", "response": "Return the number of path segments common to both."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef escape(s, quote=False):\n    if s is None:\n        return ''\n\n    if not isinstance(s, (str, bytes)):\n        s = str(s)\n    if isinstance(s, bytes):\n        try:\n            s.decode('ascii')\n        except UnicodeDecodeError:\n            s = s.decode('utf-8', 'replace')\n    s = s.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')\n    if quote:\n        s = s.replace('\"', \"&quot;\")\n    return s", "response": "Escape special characters &lt and < and > to HTML - safe sequences."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsends data to statsd.", "response": "def _send(self, data):\n        \"\"\"Send data to statsd.\"\"\"\n        try:\n            self._sock.sendto(data.encode('ascii'), self._addr)\n        except (socket.error, RuntimeError):\n            # No time for love, Dr. Jones!\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsending new timing information.", "response": "def timing(self, stat, delta, rate=1):\n        \"\"\"\n        Send new timing information.\n\n        `delta` can be either a number of milliseconds or a timedelta.\n        \"\"\"\n        if isinstance(delta, timedelta):\n            # Convert timedelta to number of milliseconds.\n            delta = delta.total_seconds() * 1000.\n        self._send_stat(stat, '%0.6f|ms' % delta, rate)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef incr(self, stat, count=1, rate=1):\n        self._send_stat(stat, '%s|c' % count, rate)", "response": "Increment a stat by count."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef decr(self, stat, count=1, rate=1):\n        self.incr(stat, -count, rate)", "response": "Decrement a stat by count."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting a gauge value.", "response": "def gauge(self, stat, value, rate=1, delta=False):\n        \"\"\"Set a gauge value.\"\"\"\n        if value < 0 and not delta:\n            if rate < 1:\n                if random.random() > rate:\n                    return\n            with self.pipeline() as pipe:\n                pipe._send_stat(stat, '0|g', 1)\n                pipe._send_stat(stat, '%s|g' % value, 1)\n        else:\n            prefix = '+' if delta and value >= 0 else ''\n            self._send_stat(stat, '%s%s|g' % (prefix, value), rate)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset a stat value.", "response": "def set(self, stat, value, rate=1):\n        \"\"\"Set a set value.\"\"\"\n        self._send_stat(stat, '%s|s' % value, rate)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending data to statsd.", "response": "def _send(self, data):\n        \"\"\"Send data to statsd.\"\"\"\n        if not self._sock:\n            self.connect()\n        self._do_send(data)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_rule_classes(extra_path):\n\n    files = []\n    modules = []\n\n    if os.path.isfile(extra_path):\n        files = [os.path.basename(extra_path)]\n        directory = os.path.dirname(extra_path)\n    elif os.path.isdir(extra_path):\n        files = os.listdir(extra_path)\n        directory = extra_path\n    else:\n        raise UserRuleError(u\"Invalid extra-path: {0}\".format(extra_path))\n\n    # Filter out files that are not python modules\n    for filename in files:\n        if fnmatch.fnmatch(filename, '*.py'):\n            modules.append(os.path.splitext(filename)[0])\n\n    # No need to continue if there are no modules specified\n    if not modules:\n        return []\n\n    # Append the extra rules path to python path so that we can import them\n    sys.path.append(directory)\n\n    # Find all the rule classes in the found python files\n    rule_classes = []\n    for module in modules:\n        # Import the module\n        try:\n            importlib.import_module(module)\n        except Exception as e:\n            raise UserRuleError(u\"Error while importing extra-path module '{0}': {1}\".format(module, ustr(e)))\n\n        # Find all rule classes in the module. We do this my inspecting all members of the module and checking\n        # 1) is it a class, if not, skip\n        # 2) is the parent path the current module. If not, we are dealing with an imported class, skip\n        # 3) is it a subclass of rule\n        rule_classes.extend([clazz for _, clazz in inspect.getmembers(sys.modules[module])\n                             if\n                             inspect.isclass(clazz) and  # check isclass to ensure clazz.__module__ exists\n                             clazz.__module__ == module and  # ignore imported classes\n                             (issubclass(clazz, rules.LineRule) or issubclass(clazz, rules.CommitRule))])\n\n        # validate that the rule classes are valid user-defined rules\n        for rule_class in rule_classes:\n            assert_valid_rule_class(rule_class)\n\n    return rule_classes", "response": "Searches a given directory or python module for rule classes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nasserting that a given rule class is valid by checking the number of properties.", "response": "def assert_valid_rule_class(clazz):\n    \"\"\"\n    Asserts that a given rule clazz is valid by checking a number of its properties:\n     - Rules must extend from  LineRule or CommitRule\n     - Rule classes must have id and name string attributes.\n       The options_spec is optional, but if set, it must be a list of gitlint Options.\n     - Rule classes must have a validate method. In case of a CommitRule, validate must take a single commit parameter.\n       In case of LineRule, validate must take line and commit as first and second parameters.\n     - LineRule classes must have a target class attributes that is set to either\n       CommitMessageTitle or CommitMessageBody.\n     - User Rule id's cannot start with R, T, B or M as these rule ids are reserved for gitlint itself.\n    \"\"\"\n\n    # Rules must extend from LineRule or CommitRule\n    if not (issubclass(clazz, rules.LineRule) or issubclass(clazz, rules.CommitRule)):\n        msg = u\"User-defined rule class '{0}' must extend from {1}.{2} or {1}.{3}\"\n        raise UserRuleError(msg.format(clazz.__name__, rules.CommitRule.__module__,\n                                       rules.LineRule.__name__, rules.CommitRule.__name__))\n\n    # Rules must have an id attribute\n    if not hasattr(clazz, 'id') or clazz.id is None or not clazz.id:\n        raise UserRuleError(u\"User-defined rule class '{0}' must have an 'id' attribute\".format(clazz.__name__))\n\n    # Rule id's cannot start with gitlint reserved letters\n    if clazz.id[0].upper() in ['R', 'T', 'B', 'M']:\n        msg = u\"The id '{1}' of '{0}' is invalid. Gitlint reserves ids starting with R,T,B,M\"\n        raise UserRuleError(msg.format(clazz.__name__, clazz.id[0]))\n\n    # Rules must have a name attribute\n    if not hasattr(clazz, 'name') or clazz.name is None or not clazz.name:\n        raise UserRuleError(u\"User-defined rule class '{0}' must have a 'name' attribute\".format(clazz.__name__))\n\n    # if set, options_spec must be a list of RuleOption\n    if not isinstance(clazz.options_spec, list):\n        msg = u\"The options_spec attribute of user-defined rule class '{0}' must be a list of {1}.{2}\"\n        raise UserRuleError(msg.format(clazz.__name__, options.RuleOption.__module__, options.RuleOption.__name__))\n\n    # check that all items in options_spec are actual gitlint options\n    for option in clazz.options_spec:\n        if not isinstance(option, options.RuleOption):\n            msg = u\"The options_spec attribute of user-defined rule class '{0}' must be a list of {1}.{2}\"\n            raise UserRuleError(msg.format(clazz.__name__, options.RuleOption.__module__, options.RuleOption.__name__))\n\n    # Rules must have a validate method. We use isroutine() as it's both python 2 and 3 compatible.\n    # For more info see http://stackoverflow.com/a/17019998/381010\n    if not hasattr(clazz, 'validate') or not inspect.isroutine(clazz.validate):\n        raise UserRuleError(u\"User-defined rule class '{0}' must have a 'validate' method\".format(clazz.__name__))\n\n    # LineRules must have a valid target: rules.CommitMessageTitle or rules.CommitMessageBody\n    if issubclass(clazz, rules.LineRule):\n        if clazz.target not in [rules.CommitMessageTitle, rules.CommitMessageBody]:\n            msg = u\"The target attribute of the user-defined LineRule class '{0}' must be either {1}.{2} or {1}.{3}\"\n            msg = msg.format(clazz.__name__, rules.CommitMessageTitle.__module__,\n                             rules.CommitMessageTitle.__name__, rules.CommitMessageBody.__name__)\n            raise UserRuleError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ustr(obj):\n    if sys.version_info[0] == 2:\n        # If we are getting a string, then do an explicit decode\n        # else, just call the unicode method of the object\n        if type(obj) in [str, basestring]:  # pragma: no cover # noqa\n            return unicode(obj, DEFAULT_ENCODING)  # pragma: no cover # noqa\n        else:\n            return unicode(obj)  # pragma: no cover # noqa\n    else:\n        if type(obj) in [bytes]:\n            return obj.decode(DEFAULT_ENCODING)\n        else:\n            return str(obj)", "response": "Python 2 and 3 utility method that converts an object to unicode in python 2 and str in python 3"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_rule_option(self, rule_name_or_id, option_name):\n        option = self._get_option(rule_name_or_id, option_name)\n        return option.value", "response": "Returns the value of a given option for a given rule."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_rule_option(self, rule_name_or_id, option_name, option_value):\n        option = self._get_option(rule_name_or_id, option_name)\n        try:\n            option.set(option_value)\n        except options.RuleOptionError as e:\n            msg = u\"'{0}' is not a valid value for option '{1}.{2}'. {3}.\"\n            raise LintConfigError(msg.format(option_value, rule_name_or_id, option_name, ustr(e)))", "response": "Attempts to set a given value for a given option for a given rule."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_config_from_commit(self, commit):\n        for line in commit.message.body:\n            pattern = re.compile(r\"^gitlint-ignore:\\s*(.*)\")\n            matches = pattern.match(line)\n            if matches and len(matches.groups()) == 1:\n                self.set_option('general', 'ignore', matches.group(1))", "response": "Applies config specified in the commit message."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngiving a list of config options of the form \"<rule>.<option>=<value>\", parses out the correct rule and option and sets the value accordingly in this factory object.", "response": "def set_config_from_string_list(self, config_options):\n        \"\"\" Given a list of config options of the form \"<rule>.<option>=<value>\", parses out the correct rule and option\n        and sets the value accordingly in this factory object. \"\"\"\n        for config_option in config_options:\n            try:\n                config_name, option_value = config_option.split(\"=\", 1)\n                if not option_value:\n                    raise ValueError()\n                rule_name, option_name = config_name.split(\".\", 1)\n                self.set_option(rule_name, option_name, option_value)\n            except ValueError:  # raised if the config string is invalid\n                raise LintConfigError(\n                    u\"'{0}' is an invalid configuration option. Use '<rule>.<option>=<value>'\".format(config_option))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_from_config_file(self, filename):\n        if not os.path.exists(filename):\n            raise LintConfigError(u\"Invalid file path: {0}\".format(filename))\n        self._config_path = os.path.abspath(filename)\n        try:\n            parser = ConfigParser()\n            parser.read(filename)\n\n            for section_name in parser.sections():\n                for option_name, option_value in parser.items(section_name):\n                    self.set_option(section_name, option_name, ustr(option_value))\n\n        except ConfigParserError as e:\n            raise LintConfigError(ustr(e))", "response": "Loads a lint config from a ini - style config file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef build(self, config=None):\n\n        # If we are passed a config object, then rebuild that object instead of building a new lintconfig object from\n        # scratch\n        if not config:\n            config = LintConfig()\n\n        config._config_path = self._config_path\n\n        # Set general options first as this might change the behavior or validity of the other options\n        general_section = self._config_blueprint.get('general')\n        if general_section:\n            for option_name, option_value in general_section.items():\n                config.set_general_option(option_name, option_value)\n\n        for section_name, section_dict in self._config_blueprint.items():\n            for option_name, option_value in section_dict.items():\n                # Skip over the general section, as we've already done that above\n                if section_name != \"general\":\n                    config.set_rule_option(section_name, option_name, option_value)\n\n        return config", "response": "Build a real LintConfig object by normalizing and validating the options that were previously set on this object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate an exact copy of this LintConfigBuilder.", "response": "def clone(self):\n        \"\"\" Creates an exact copy of a LintConfigBuilder.  \"\"\"\n        builder = LintConfigBuilder()\n        builder._config_blueprint = copy.deepcopy(self._config_blueprint)\n        builder._config_path = self._config_path\n        return builder"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef git_commentchar():\n    commentchar = _git(\"config\", \"--get\", \"core.commentchar\", _ok_code=[1])\n    # git will return an exit code of 1 if it can't find a config value, in this case we fall-back to # as commentchar\n    if hasattr(commentchar, 'exit_code') and commentchar.exit_code == 1:  # pylint: disable=no-member\n        commentchar = \"#\"\n    return ustr(commentchar).replace(u\"\\n\", u\"\")", "response": "Shortcut for retrieving comment char from git config"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_full_message(commit_msg_str):\n        all_lines = commit_msg_str.splitlines()\n        try:\n            cutline_index = all_lines.index(GitCommitMessage.CUTLINE)\n        except ValueError:\n            cutline_index = None\n        lines = [line for line in all_lines[:cutline_index] if not line.startswith(GitCommitMessage.COMMENT_CHAR)]\n        full = \"\\n\".join(lines)\n        title = lines[0] if lines else \"\"\n        body = lines[1:] if len(lines) > 1 else []\n        return GitCommitMessage(original=commit_msg_str, full=full, title=title, body=body)", "response": "Parses a git commit message string into a different parts of a commit message."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndetermining a git context based on a commit message.", "response": "def from_commit_msg(commit_msg_str):\n        \"\"\" Determines git context based on a commit message.\n        :param commit_msg_str: Full git commit message.\n        \"\"\"\n        context = GitContext()\n        commit_msg_obj = GitCommitMessage.from_full_message(commit_msg_str)\n\n        commit = GitCommit(context, commit_msg_obj)\n\n        context.commits.append(commit)\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve the git context from a local git repository.", "response": "def from_local_repository(repository_path, refspec=None):\n        \"\"\" Retrieves the git context from a local git repository.\n        :param repository_path: Path to the git repository to retrieve the context from\n        :param refspec: The commit(s) to retrieve\n        \"\"\"\n\n        context = GitContext()\n\n        # If no refspec is defined, fallback to the last commit on the current branch\n        if refspec is None:\n            # We tried many things here e.g.: defaulting to e.g. HEAD or HEAD^... (incl. dealing with\n            # repos that only have a single commit - HEAD^... doesn't work there), but then we still get into\n            # problems with e.g. merge commits. Easiest solution is just taking the SHA from `git log -1`.\n            sha_list = [_git(\"log\", \"-1\", \"--pretty=%H\", _cwd=repository_path).replace(u\"\\n\", u\"\")]\n        else:\n            sha_list = _git(\"rev-list\", refspec, _cwd=repository_path).split()\n\n        for sha in sha_list:\n            # Get info from the local git repository: https://git-scm.com/docs/pretty-formats\n            long_format = \"--pretty=%aN%x00%aE%x00%ai%x00%P%n%B\"\n            raw_commit = _git(\"log\", sha, \"-1\", long_format, _cwd=repository_path).split(\"\\n\")\n\n            (name, email, date, parents), commit_msg = raw_commit[0].split('\\x00'), \"\\n\".join(raw_commit[1:])\n\n            commit_parents = parents.split(\" \")\n            commit_is_merge_commit = len(commit_parents) > 1\n\n            # changed files in last commit\n            changed_files = _git(\"diff-tree\", \"--no-commit-id\", \"--name-only\", \"-r\", sha, _cwd=repository_path).split()\n\n            # \"YYYY-MM-DD HH:mm:ss Z\" -> ISO 8601-like format\n            # Use arrow for datetime parsing, because apparently python is quirky around ISO-8601 dates:\n            # http://stackoverflow.com/a/30696682/381010\n            commit_date = arrow.get(ustr(date), \"YYYY-MM-DD HH:mm:ss Z\").datetime\n\n            # Create Git commit object with the retrieved info\n            commit_msg_obj = GitCommitMessage.from_full_message(commit_msg)\n\n            commit = GitCommit(context, commit_msg_obj, sha=sha, author_name=name,\n                               author_email=email, date=commit_date, changed_files=changed_files,\n                               parents=commit_parents, is_merge_commit=commit_is_merge_commit)\n\n            context.commits.append(commit)\n\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndetermine whether a rule should be ignored based on the general list of commits to ignore", "response": "def should_ignore_rule(self, rule):\n        \"\"\" Determines whether a rule should be ignored based on the general list of commits to ignore \"\"\"\n        return rule.id in self.config.ignore or rule.name in self.config.ignore"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\niterating over the lines in a given list of lines and validates each rule against each line.", "response": "def _apply_line_rules(lines, commit, rules, line_nr_start):\n        \"\"\" Iterates over the lines in a given list of lines and validates a given list of rules against each line \"\"\"\n        all_violations = []\n        line_nr = line_nr_start\n        for line in lines:\n            for rule in rules:\n                violations = rule.validate(line, commit)\n                if violations:\n                    for violation in violations:\n                        violation.line_nr = line_nr\n                        all_violations.append(violation)\n            line_nr += 1\n        return all_violations"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _apply_commit_rules(rules, commit):\n        all_violations = []\n        for rule in rules:\n            violations = rule.validate(commit)\n            if violations:\n                all_violations.extend(violations)\n        return all_violations", "response": "Applies a set of rules against a given commit and gitcontext."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef lint(self, commit):\n        LOG.debug(\"Linting commit %s\", commit.sha or \"[SHA UNKNOWN]\")\n        LOG.debug(\"Commit Object\\n\" + ustr(commit))\n\n        # Apply config rules\n        for rule in self.configuration_rules:\n            rule.apply(self.config, commit)\n\n        # Skip linting if this is a special commit type that is configured to be ignored\n        ignore_commit_types = [\"merge\", \"squash\", \"fixup\"]\n        for commit_type in ignore_commit_types:\n            if getattr(commit, \"is_{0}_commit\".format(commit_type)) and \\\n               getattr(self.config, \"ignore_{0}_commits\".format(commit_type)):\n                return []\n\n        violations = []\n        # determine violations by applying all rules\n        violations.extend(self._apply_line_rules([commit.message.title], commit, self.title_line_rules, 1))\n        violations.extend(self._apply_line_rules(commit.message.body, commit, self.body_line_rules, 2))\n        violations.extend(self._apply_commit_rules(self.commit_rules, commit))\n\n        # Sort violations by line number and rule_id. If there's no line nr specified (=common certain commit rules),\n        # we replace None with -1 so that it always get's placed first. Note that we need this to do this to support\n        # python 3, as None is not allowed in a list that is being sorted.\n        violations.sort(key=lambda v: (-1 if v.line_nr is None else v.line_nr, v.rule_id))\n        return violations", "response": "Lints the last commit in a given git context."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef print_violations(self, violations):\n        for v in violations:\n            line_nr = v.line_nr if v.line_nr else \"-\"\n            self.display.e(u\"{0}: {1}\".format(line_nr, v.rule_id), exact=True)\n            self.display.ee(u\"{0}: {1} {2}\".format(line_nr, v.rule_id, v.message), exact=True)\n            if v.content:\n                self.display.eee(u\"{0}: {1} {2}: \\\"{3}\\\"\".format(line_nr, v.rule_id, v.message, v.content),\n                                 exact=True)\n            else:\n                self.display.eee(u\"{0}: {1} {2}\".format(line_nr, v.rule_id, v.message), exact=True)", "response": "Print a set of violations to the standard error output"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _output(self, message, verbosity, exact, stream):\n        if exact:\n            if self.config.verbosity == verbosity:\n                stream.write(message + \"\\n\")\n        else:\n            if self.config.verbosity >= verbosity:\n                stream.write(message + \"\\n\")", "response": "Output a message if the config s verbosity is > = to the given verbosity."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build_config(ctx, target, config_path, c, extra_path, ignore, verbose, silent, debug):\n    config_builder = LintConfigBuilder()\n    try:\n        # Config precedence:\n        # First, load default config or config from configfile\n        if config_path:\n            config_builder.set_from_config_file(config_path)\n        elif os.path.exists(DEFAULT_CONFIG_FILE):\n            config_builder.set_from_config_file(DEFAULT_CONFIG_FILE)\n\n        # Then process any commandline configuration flags\n        config_builder.set_config_from_string_list(c)\n\n        # Finally, overwrite with any convenience commandline flags\n        if ignore:\n            config_builder.set_option('general', 'ignore', ignore)\n        if silent:\n            config_builder.set_option('general', 'verbosity', 0)\n        elif verbose > 0:\n            config_builder.set_option('general', 'verbosity', verbose)\n\n        if extra_path:\n            config_builder.set_option('general', 'extra-path', extra_path)\n\n        if target:\n            config_builder.set_option('general', 'target', target)\n\n        if debug:\n            config_builder.set_option('general', 'debug', debug)\n\n        config = config_builder.build()\n\n        return config, config_builder\n    except LintConfigError as e:\n        click.echo(u\"Config Error: {0}\".format(ustr(e)))\n    ctx.exit(CONFIG_ERROR_CODE)", "response": "Builds a LintConfig object based on a set of commandline parameters."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef lint(ctx):\n    lint_config = ctx.obj[0]\n    msg_filename = ctx.obj[3]\n\n    # Let's determine where our input data is coming from:\n    # Order of precedence:\n    # 1. Any data specified via --msg-filename\n    # 2. Any data sent to stdin\n    # 3. Fallback to reading from local repository\n    stdin_input = get_stdin_data()\n    if msg_filename:\n        LOG.debug(\"Attempting to read from --msg-filename.\")\n        gitcontext = GitContext.from_commit_msg(ustr(msg_filename.read()))\n    elif stdin_input:\n        LOG.debug(\"No --msg-filename flag. Attempting to read from stdin.\")\n        gitcontext = GitContext.from_commit_msg(stdin_input)\n    else:\n        LOG.debug(\"No --msg-filename flag, no or empty data passed to stdin. Attempting to read from the local repo.\")\n        gitcontext = GitContext.from_local_repository(lint_config.target, ctx.obj[2])\n\n    number_of_commits = len(gitcontext.commits)\n    # Exit if we don't have commits in the specified range. Use a 0 exit code, since a popular use-case is one\n    # where users are using --commits in a check job to check the commit messages inside a CI job. By returning 0, we\n    # ensure that these jobs don't fail if for whatever reason the specified commit range is empty.\n    if number_of_commits == 0:\n        LOG.debug(u'No commits in range \"%s\"', ctx.obj[2])\n        ctx.exit(0)\n\n    general_config_builder = ctx.obj[1]\n    last_commit = gitcontext.commits[-1]\n\n    # Let's get linting!\n    first_violation = True\n    exit_code = 0\n    for commit in gitcontext.commits:\n        # Build a config_builder taking into account the commit specific config (if any)\n        config_builder = general_config_builder.clone()\n        config_builder.set_config_from_commit(commit)\n\n        # Create a deepcopy from the original config, so we have a unique config object per commit\n        # This is important for configuration rules to be able to modifying the config on a per commit basis\n        commit_config = config_builder.build(copy.deepcopy(lint_config))\n\n        # Actually do the linting\n        linter = GitLinter(commit_config)\n        violations = linter.lint(commit)\n        # exit code equals the total number of violations in all commits\n        exit_code += len(violations)\n        if violations:\n            # Display the commit hash & new lines intelligently\n            if number_of_commits > 1 and commit.sha:\n                linter.display.e(u\"{0}Commit {1}:\".format(\n                    \"\\n\" if not first_violation or commit is last_commit else \"\",\n                    commit.sha[:10]\n                ))\n            linter.print_violations(violations)\n            first_violation = False\n\n    # cap actual max exit code because bash doesn't like exit codes larger than 255:\n    # http://tldp.org/LDP/abs/html/exitcodes.html\n    exit_code = min(MAX_VIOLATION_ERROR_CODE, exit_code)\n    LOG.debug(\"Exit Code = %s\", exit_code)\n    ctx.exit(exit_code)", "response": "Lints a git repository."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninstalls gitlint as a git commit - msg hook.", "response": "def install_hook(ctx):\n    \"\"\" Install gitlint as a git commit-msg hook. \"\"\"\n    try:\n        lint_config = ctx.obj[0]\n        hooks.GitHookInstaller.install_commit_msg_hook(lint_config)\n        # declare victory :-)\n        hook_path = hooks.GitHookInstaller.commit_msg_hook_path(lint_config)\n        click.echo(u\"Successfully installed gitlint commit-msg hook in {0}\".format(hook_path))\n        ctx.exit(0)\n    except hooks.GitHookInstallerError as e:\n        click.echo(ustr(e), err=True)\n        ctx.exit(GIT_CONTEXT_ERROR_CODE)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef uninstall_hook(ctx):\n    try:\n        lint_config = ctx.obj[0]\n        hooks.GitHookInstaller.uninstall_commit_msg_hook(lint_config)\n        # declare victory :-)\n        hook_path = hooks.GitHookInstaller.commit_msg_hook_path(lint_config)\n        click.echo(u\"Successfully uninstalled gitlint commit-msg hook from {0}\".format(hook_path))\n        ctx.exit(0)\n    except hooks.GitHookInstallerError as e:\n        click.echo(ustr(e), err=True)\n        ctx.exit(GIT_CONTEXT_ERROR_CODE)", "response": "Uninstall gitlint commit - msg hook."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a sample gitlint config file.", "response": "def generate_config(ctx):\n    \"\"\" Generates a sample gitlint config file. \"\"\"\n    path = click.prompt('Please specify a location for the sample gitlint config file', default=DEFAULT_CONFIG_FILE)\n    path = os.path.abspath(path)\n    dir_name = os.path.dirname(path)\n    if not os.path.exists(dir_name):\n        click.echo(u\"Error: Directory '{0}' does not exist.\".format(dir_name), err=True)\n        ctx.exit(USAGE_ERROR_CODE)\n    elif os.path.exists(path):\n        click.echo(u\"Error: File \\\"{0}\\\" already exists.\".format(path), err=True)\n        ctx.exit(USAGE_ERROR_CODE)\n\n    LintConfigGenerator.generate_config(path)\n    click.echo(u\"Successfully generated {0}\".format(path))\n    ctx.exit(0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nasserts that a given target directory is a git repository.", "response": "def _assert_git_repo(target):\n        \"\"\" Asserts that a given target directory is a git repository \"\"\"\n        hooks_dir = os.path.abspath(os.path.join(target, HOOKS_DIR_PATH))\n        if not os.path.isdir(hooks_dir):\n            raise GitHookInstallerError(u\"{0} is not a git repository.\".format(target))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntakes the given response and tries digest - auth if needed.", "response": "def handle_407(self, r):\n        \"\"\"Takes the given response and tries digest-auth, if needed.\"\"\"\n\n        num_407_calls = r.request.hooks['response'].count(self.handle_407)\n\n        s_auth = r.headers.get('Proxy-authenticate', '')\n\n        if 'digest' in s_auth.lower() and num_407_calls < 2:\n\n            self.chal = requests.auth.parse_dict_header(s_auth.replace('Digest ', ''))\n\n            # Consume content and release the original connection\n            # to allow our new request to reuse the same one.\n            r.content\n            r.raw.release_conn()\n\n            r.request.headers['Authorization'] = self.build_digest_header(r.request.method, r.request.url)\n            r.request.send(anyway=True)\n            _r = r.request.response\n            _r.history.append(r)\n\n            return _r\n\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_backend_stats_url(config, hub, backend_type):\n    if ((config is not None) and ('hub' in config) and (hub is None)):\n        hub = config[\"hub\"]\n    if (hub is not None):\n        return '/Network/{}/devices/{}'.format(hub, backend_type)\n    return '/Backends/{}'.format(backend_type)", "response": "Util method to get backend stats url"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_backend_url(config, hub, group, project):\n    if ((config is not None) and ('hub' in config) and (hub is None)):\n        hub = config[\"hub\"]\n    if ((config is not None) and ('group' in config) and (group is None)):\n        group = config[\"group\"]\n    if ((config is not None) and ('project' in config) and (project is None)):\n        project = config[\"project\"]\n    if ((hub is not None) and (group is not None) and (project is not None)):\n        return '/Network/{}/Groups/{}/Projects/{}/devices'.format(hub, group, project)\n    return '/Backends'", "response": "Util method to get backend url"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef obtain_token(self, config=None):\n        client_application = CLIENT_APPLICATION\n        if self.config and (\"client_application\" in self.config):\n            client_application += ':' + self.config[\"client_application\"]\n        headers = {'x-qx-client-application': client_application}\n\n        if self.token_unique:\n            try:\n                response = requests.post(str(self.config.get('url') +\n                                             \"/users/loginWithToken\"),\n                                         data={'apiToken': self.token_unique},\n                                         verify=self.verify,\n                                         headers=headers,\n                                         **self.extra_args)\n            except requests.RequestException as e:\n                raise ApiError('error during login: %s' % str(e))\n        elif config and (\"email\" in config) and (\"password\" in config):\n            email = config.get('email', None)\n            password = config.get('password', None)\n            credentials = {\n                'email': email,\n                'password': password\n            }\n            try:\n                response = requests.post(str(self.config.get('url') +\n                                             \"/users/login\"),\n                                         data=credentials,\n                                         verify=self.verify,\n                                         headers=headers,\n                                         **self.extra_args)\n            except requests.RequestException as e:\n                raise ApiError('error during login: %s' % str(e))\n        else:\n            raise CredentialsError('invalid token')\n\n        if response.status_code == 401:\n            error_message = None\n            try:\n                # For 401: ACCEPT_LICENSE_REQUIRED, a detailed message is\n                # present in the response and passed to the exception.\n                error_message = response.json()['error']['message']\n            except:\n                pass\n\n            if error_message:\n                raise CredentialsError('error during login: %s' % error_message)\n            else:\n                raise CredentialsError('invalid token')\n        try:\n            response.raise_for_status()\n            self.data_credentials = response.json()\n        except (requests.HTTPError, ValueError) as e:\n            raise ApiError('error during login: %s' % str(e))\n\n        if self.get_token() is None:\n            raise CredentialsError('invalid token')", "response": "Obtain the token to access to QX Platform."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_token(self, respond):\n        if respond.status_code == 401:\n            self.credential.obtain_token(config=self.config)\n            return False\n        return True", "response": "Check if the user s token is valid"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrap of the REST API to POST a resource.", "response": "def post(self, path, params='', data=None):\n        \"\"\"\n        POST Method Wrapper of the REST API\n        \"\"\"\n        self.result = None\n        data = data or {}\n        headers = {'Content-Type': 'application/json',\n                   'x-qx-client-application': self.client_application}\n        url = str(self.credential.config['url'] + path + '?access_token=' +\n                  self.credential.get_token() + params)\n        retries = self.retries\n        while retries > 0:\n            respond = requests.post(url, data=data, headers=headers,\n                                    verify=self.verify, **self.extra_args)\n            if not self.check_token(respond):\n                respond = requests.post(url, data=data, headers=headers,\n                                        verify=self.verify,\n                                        **self.extra_args)\n\n            if self._response_good(respond):\n                if self.result:\n                    return self.result\n                elif retries < 2:\n                    return respond.json()\n                else:\n                    retries -= 1\n            else:\n                retries -= 1\n                time.sleep(self.timeout_interval)\n\n        # timed out\n        raise ApiError(usr_msg='Failed to get proper ' +\n                       'response from backend.')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks response to a specific object and return True if the response is good.", "response": "def _response_good(self, respond):\n        \"\"\"check response\n\n        Args:\n            respond (str): HTTP response.\n\n        Returns:\n            bool: True if the response is good, else False.\n\n        Raises:\n            ApiError: response isn't formatted properly.\n        \"\"\"\n        if respond.status_code != requests.codes.ok:\n            log.warning('Got a {} code response to {}: {}'.format(\n                respond.status_code,\n                respond.url,\n                respond.text))\n            if respond.status_code in self.errorsNotRetry:\n              raise ApiError(usr_msg='Got a {} code response to {}: {}'.format(\n                respond.status_code,\n                respond.url,\n                respond.text))\n            else:\n              return self._parse_response(respond)\n        try:\n            if (str(respond.headers['content-type']).startswith(\"text/html;\")):\n                self.result = respond.text\n                return True\n            else:\n                self.result = respond.json()\n        except (json.JSONDecodeError, ValueError):\n            usr_msg = 'device server returned unexpected http response'\n            dev_msg = usr_msg + ': ' + respond.text\n            raise ApiError(usr_msg=usr_msg, dev_msg=dev_msg)\n        if not isinstance(self.result, (list, dict)):\n            msg = ('JSON not a list or dict: url: {0},'\n                   'status: {1}, reason: {2}, text: {3}')\n            raise ApiError(\n                usr_msg=msg.format(respond.url,\n                                   respond.status_code,\n                                   respond.reason, respond.text))\n        if ('error' not in self.result or\n                ('status' not in self.result['error'] or\n                 self.result['error']['status'] != 400)):\n            return True\n        else:\n            log.warning(\"Got a 400 code JSON response to %s\", respond.url)\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses text of response for HTTP errors returns True if the request should be retried False otherwise", "response": "def _parse_response(self, respond):\n        \"\"\"parse text of response for HTTP errors\n\n        This parses the text of the response to decide whether to\n        retry request or raise exception. At the moment this only\n        detects an exception condition.\n\n        Args:\n            respond (Response): requests.Response object\n\n        Returns:\n            bool: False if the request should be retried, True\n                if not.\n\n        Raises:\n            RegisterSizeError\n        \"\"\"\n        # convert error messages into exceptions\n        mobj = self._max_qubit_error_re.match(respond.text)\n        if mobj:\n            raise RegisterSizeError(\n                'device register size must be <= {}'.format(mobj.group(1)))\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _check_backend(self, backend, endpoint):\n        # First check against hacks for old backend names\n        original_backend = backend\n        backend = backend.lower()\n        if endpoint == 'experiment':\n            if backend in self.__names_backend_ibmqxv2:\n                return 'real'\n            elif backend in self.__names_backend_ibmqxv3:\n                return 'ibmqx3'\n            elif backend in self.__names_backend_simulator:\n                return 'sim_trivial_2'\n\n        # Check for new-style backends\n        backends = self.available_backends()\n        for backend in backends:\n            if backend['name'] == original_backend:\n              return original_backend\n        # backend unrecognized\n        return None", "response": "Check if the name of a backend is valid for QX Platform"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_execution(self, id_execution, access_token=None, user_id=None):\n        if access_token:\n            self.req.credential.set_token(access_token)\n        if user_id:\n            self.req.credential.set_user_id(user_id)\n        if not self.check_credentials():\n            raise CredentialsError('credentials invalid')\n        execution = self.req.get('/Executions/' + id_execution)\n        if \"codeId\" in execution:\n            execution['code'] = self.get_code(execution[\"codeId\"])\n        return execution", "response": "Get a execution by its id"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_result_from_execution(self, id_execution, access_token=None, user_id=None):\n        if access_token:\n            self.req.credential.set_token(access_token)\n        if user_id:\n            self.req.credential.set_user_id(user_id)\n        if not self.check_credentials():\n            raise CredentialsError('credentials invalid')\n        execution = self.req.get('/Executions/' + id_execution)\n        result = {}\n        if \"result\" in execution and \"data\" in execution[\"result\"]:\n            if execution[\"result\"][\"data\"].get('p', None):\n                result[\"measure\"] = execution[\"result\"][\"data\"][\"p\"]\n            if execution[\"result\"][\"data\"].get('valsxyz', None):\n                result[\"bloch\"] = execution[\"result\"][\"data\"][\"valsxyz\"]\n            if \"additionalData\" in execution[\"result\"][\"data\"]:\n                ad_aux = execution[\"result\"][\"data\"][\"additionalData\"]\n                result[\"extraInfo\"] = ad_aux\n            if \"calibration\" in execution:\n                result[\"calibration\"] = execution[\"calibration\"]\n            if execution[\"result\"][\"data\"].get('cregLabels', None):\n                result[\"creg_labels\"] = execution[\"result\"][\"data\"][\"cregLabels\"]\n            if execution[\"result\"][\"data\"].get('time', None):\n                result[\"time_taken\"] = execution[\"result\"][\"data\"][\"time\"]\n\n        return result", "response": "Get the result of a execution by the id_execution."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a code by its id", "response": "def get_code(self, id_code, access_token=None, user_id=None):\n        \"\"\"\n        Get a code, by its id\n        \"\"\"\n        if access_token:\n            self.req.credential.set_token(access_token)\n        if user_id:\n            self.req.credential.set_user_id(user_id)\n        if not self.check_credentials():\n            raise CredentialsError('credentials invalid')\n        code = self.req.get('/Codes/' + id_code)\n        executions = self.req.get('/Codes/' + id_code + '/executions',\n                                  '&filter={\"limit\":3}')\n        if isinstance(executions, list):\n            code[\"executions\"] = executions\n        return code"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the image of a code by its id", "response": "def get_image_code(self, id_code, access_token=None, user_id=None):\n        \"\"\"\n        Get the image of a code, by its id\n        \"\"\"\n        if access_token:\n            self.req.credential.set_token(access_token)\n        if user_id:\n            self.req.credential.set_user_id(user_id)\n        if not self.check_credentials():\n            raise CredentialsError('credentials invalid')\n        return self.req.get('/Codes/' + id_code + '/export/png/url')"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the last codes of the user", "response": "def get_last_codes(self, access_token=None, user_id=None):\n        \"\"\"\n        Get the last codes of the user\n        \"\"\"\n        if access_token:\n            self.req.credential.set_token(access_token)\n        if user_id:\n            self.req.credential.set_user_id(user_id)\n        if not self.check_credentials():\n            raise CredentialsError('credentials invalid')\n        last = '/users/' + self.req.credential.get_user_id() + '/codes/lastest'\n        return self.req.get(last, '&includeExecutions=true')['codes']"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_job(self, id_job, hub=None, group=None, project=None,\n                access_token=None, user_id=None):\n        \"\"\"\n        Get the information about a job, by its id\n        \"\"\"\n        if access_token:\n            self.req.credential.set_token(access_token)\n        if user_id:\n            self.req.credential.set_user_id(user_id)\n        if not self.check_credentials():\n            respond = {}\n            respond[\"status\"] = 'Error'\n            respond[\"error\"] = \"Not credentials valid\"\n            return respond\n        if not id_job:\n            respond = {}\n            respond[\"status\"] = 'Error'\n            respond[\"error\"] = \"Job ID not specified\"\n            return respond\n\n        url = get_job_url(self.config, hub, group, project)\n\n        url += '/' + id_job\n\n        job = self.req.get(url)\n\n        if 'qasms' in job: \n            for qasm in job['qasms']:\n                if ('result' in qasm) and ('data' in qasm['result']):\n                    qasm['data'] = qasm['result']['data']\n                    del qasm['result']['data']\n                    for key in qasm['result']:\n                        qasm['data'][key] = qasm['result'][key]\n                    del qasm['result']\n\n        return job", "response": "Get information about a job by its id"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the information about the user jobs", "response": "def get_jobs(self, limit=10, skip=0, backend=None, only_completed=False, filter=None, hub=None, group=None, project=None, access_token=None, user_id=None):\n        \"\"\"\n        Get the information about the user jobs\n        \"\"\"\n        if access_token:\n            self.req.credential.set_token(access_token)\n        if user_id:\n            self.req.credential.set_user_id(user_id)\n        if not self.check_credentials():\n            return {\"error\": \"Not credentials valid\"}\n\n        url = get_job_url(self.config, hub, group, project)\n        url_filter = '&filter='\n        query = {\n          \"order\": \"creationDate DESC\",\n          \"limit\": limit,\n          \"skip\": skip,\n          \"where\" : {}\n        }\n        if filter is not None:\n          query['where'] = filter\n        else:\n          if backend is not None:\n            query['where']['backend.name'] = backend\n          if only_completed:\n            query['where']['status'] = 'COMPLETED'\n  \n        url_filter = url_filter + json.dumps(query)\n        jobs = self.req.get(url, url_filter)\n        return jobs"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the status of a job by its id", "response": "def get_status_job(self, id_job, hub=None, group=None, project=None,\n                       access_token=None, user_id=None):\n        \"\"\"\n        Get the status about a job, by its id\n        \"\"\"\n        if access_token:\n            self.req.credential.set_token(access_token)\n        if user_id:\n            self.req.credential.set_user_id(user_id)\n        if not self.check_credentials():\n            respond = {}\n            respond[\"status\"] = 'Error'\n            respond[\"error\"] = \"Not credentials valid\"\n            return respond\n        if not id_job:\n            respond = {}\n            respond[\"status\"] = 'Error'\n            respond[\"error\"] = \"Job ID not specified\"\n            return respond\n\n        url = get_job_url(self.config, hub, group, project)\n\n        url += '/' + id_job + '/status'\n\n        status = self.req.get(url)\n\n        return status"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cancel_job(self, id_job, hub=None, group=None, project=None,\n                   access_token=None, user_id=None):\n        \"\"\"\n        Cancel the information about a job, by its id\n        \"\"\"\n        if access_token:\n            self.req.credential.set_token(access_token)\n        if user_id:\n            self.req.credential.set_user_id(user_id)\n        if not self.check_credentials():\n            respond = {}\n            respond[\"status\"] = 'Error'\n            respond[\"error\"] = \"Not credentials valid\"\n            return respond\n        if not id_job:\n            respond = {}\n            respond[\"status\"] = 'Error'\n            respond[\"error\"] = \"Job ID not specified\"\n            return respond\n        \n        url = get_job_url(self.config, hub, group, project)\n\n        url += '/{}/cancel'.format(id_job)\n\n        res = self.req.post(url)\n\n        return res", "response": "Cancel a job by its id"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the status of a chip", "response": "def backend_status(self, backend='ibmqx4', access_token=None, user_id=None):\n        \"\"\"\n        Get the status of a chip\n        \"\"\"\n        if access_token:\n            self.req.credential.set_token(access_token)\n        if user_id:\n            self.req.credential.set_user_id(user_id)\n        backend_type = self._check_backend(backend, 'status')\n        if not backend_type:\n            raise BadBackendError(backend)\n\n        status = self.req.get('/Backends/' + backend_type + '/queue/status',\n                              with_token=False)\n\n        ret = {}\n        if 'state' in status:\n            ret['available'] = bool(status['state'])\n        if 'busy' in status:\n            ret['busy'] = bool(status['busy'])\n        if 'lengthQueue' in status:\n            ret['pending_jobs'] = status['lengthQueue']\n        \n        ret['backend'] = backend_type\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef backend_calibration(self, backend='ibmqx4', hub=None, access_token=None, user_id=None):\n        if access_token:\n            self.req.credential.set_token(access_token)\n        if user_id:\n            self.req.credential.set_user_id(user_id)\n        if not self.check_credentials():\n            raise CredentialsError('credentials invalid')\n\n        backend_type = self._check_backend(backend, 'calibration')\n\n        if not backend_type:\n            raise BadBackendError(backend)\n\n        if backend_type in self.__names_backend_simulator:\n            ret = {}\n            return ret\n\n        url = get_backend_stats_url(self.config, hub, backend_type)\n\n        ret = self.req.get(url + '/calibration')\n        if not bool(ret):\n          ret = {}\n        else:\n          ret[\"backend\"] = backend_type\n        return ret", "response": "Get the calibration of a real chip"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the available backends for the QX Platform", "response": "def available_backends(self, hub=None, group=None, project=None, access_token=None, user_id=None):\n        \"\"\"\n        Get the backends available to use in the QX Platform\n        \"\"\"\n        if access_token:\n            self.req.credential.set_token(access_token)\n        if user_id:\n            self.req.credential.set_user_id(user_id)\n        if not self.check_credentials():\n            raise CredentialsError('credentials invalid')\n        else:\n\n            url = get_backend_url(self.config, hub, group, project)\n\n            ret = self.req.get(url)\n            if (ret is not None) and (isinstance(ret, dict)):\n                return []\n            return [backend for backend in ret\n                    if backend.get('status') == 'on']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the backend simulators available to use in the QX Platform", "response": "def available_backend_simulators(self, access_token=None, user_id=None):\n        \"\"\"\n        Get the backend simulators available to use in the QX Platform\n        \"\"\"\n        if access_token:\n            self.req.credential.set_token(access_token)\n        if user_id:\n            self.req.credential.set_user_id(user_id)\n        if not self.check_credentials():\n            raise CredentialsError('credentials invalid')\n        else:\n            ret = self.req.get('/Backends')\n            if (ret is not None) and (isinstance(ret, dict)):\n                return []\n            return [backend for backend in ret\n                    if backend.get('status') == 'on' and\n                    backend.get('simulator') is True]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_my_credits(self, access_token=None, user_id=None):\n        if access_token:\n            self.req.credential.set_token(access_token)\n        if user_id:\n            self.req.credential.set_user_id(user_id)\n        if not self.check_credentials():\n            raise CredentialsError('credentials invalid')\n        else:\n            user_data_url = '/users/' + self.req.credential.get_user_id()\n            user_data = self.req.get(user_data_url)\n            if \"credit\" in user_data:\n                if \"promotionalCodesUsed\" in user_data[\"credit\"]:\n                    del user_data[\"credit\"][\"promotionalCodesUsed\"]\n                if \"lastRefill\" in user_data[\"credit\"]:\n                    del user_data[\"credit\"][\"lastRefill\"]\n                return user_data[\"credit\"]\n            return {}", "response": "Get the credits by user."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save_one_data(self, data, table):\n        '''\n        \u5c06\u4e00\u6761\u8bb0\u5f55\u4fdd\u5b58\u5230\u6570\u636e\u5e93\n        Args:\n            table: \u8868\u540d\u5b57 str\n            data:  \u8bb0\u5f55 dict\n        return:\n            \u6210\u529f\uff1a 1\n            \u5931\u8d25\uff1a -1 \u5e76\u6253\u5370\u8fd4\u56de\u62a5\u9519\u4fe1\u606f\n        \u6bcf\u6761\u8bb0\u5f55\u90fd\u4ee5\u4e00\u4e2a\u5b57\u5178\u7684\u5f62\u5f0f\u4f20\u8fdb\u6765\n        '''\n        key_map = {}\n        if len(data) == 0:\n            print('\u8bf7\u786e\u4fdddata\u88ab\u6b63\u786e\u4f20\u5165\u4e86')\n            return -1\n        fields = ''\n        values = ''\n        datas = {}\n        for k, v in data.items():\n            # \u9632\u6b62sql\u6ce8\u5165\n            datas.update({k: pymysql.escape_string(str(v))})\n        for d in datas:\n            fields += \"`{}`,\".format(str(d))\n            values += \"'{}',\".format(str(datas[d]))\n        if len(fields) <= 0 or len(values) <= 0:\n            return -1\n        # \u751f\u6210sql\u8bed\u53e5\n        sql = \"insert ignore into {}({}) values({})\".format(\n            table, fields[:-1], values[:-1])\n        res = self.query(sql)\n        return 1 if res != -1 else res", "response": "Save one data dict to a table."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the record by id", "response": "def update_by_id(self, data, table, id_value):\n        '''\n        \u901a\u8fc7id\u66f4\u65b0\u8bb0\u5f55\n        Args:\n            table: \u8868\u540d\u5b57 str\n            data:  \u8bb0\u5f55 dict\n            id_value: id\u503c\n        return:\n            \u6210\u529f\uff1a \uff11\n            \u5931\u8d25\uff1a -1 \u5e76\u6253\u5370\u8fd4\u56de\u62a5\u9519\u4fe1\u606f\n        \u6bcf\u6761\u8bb0\u5f55\u90fd\u4ee5\u4e00\u4e2a\u5b57\u5178\u7684\u5f62\u5f0f\u4f20\u8fdb\u6765\n        '''\n        key_map = {}\n        if len(data) == 0:\n            print('\u8bf7\u786e\u4fdddata\u88ab\u6b63\u786e\u4f20\u5165\u4e86')\n            return -1\n        datas = {}\n        updates = ''\n        for k, v in data.items():\n            # \u9632\u6b62sql\u6ce8\u5165\n            datas.update({k: pymysql.escape_string(str(v))})\n        for d in datas:\n            updates += \"{}='{}',\".format(str(d), str(datas[d]))\n        if len(updates) <= 0:\n            return -1\n        # \u751f\u6210sql\u8bed\u53e5\n        sql = \"update {} set {} where id = '{}'\".format(\n            table, updates[:-1], str(id_value))\n        res = self.query(sql)\n        return 1 if res != -1 else res"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_all(self, table, limit=10):\n        '''\n        \u4ece\u6570\u636e\u5e93\u91cc\u67e5\u8be2\u6240\u6709\u8bb0\u5f55\n        Args:\n            table: \u8868\u540d\u5b57 str\n            limit: \u9650\u5236\u6570\u91cf\n        return:\n            \u6210\u529f\uff1a [dict] \u4fdd\u5b58\u7684\u8bb0\u5f55\n            \u5931\u8d25\uff1a -1 \u5e76\u6253\u5370\u8fd4\u56de\u62a5\u9519\u4fe1\u606f\n        '''\n        sql = \"select * from {} limit 0,{}\".format(table, limit)\n        res = self.query(sql)\n        return res", "response": "Returns all the n - th records in a table"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of the national cache entries in a table where the field value is field_value", "response": "def find_by_field(self, table, field, field_value):\n        '''\n        \u4ece\u6570\u636e\u5e93\u91cc\u67e5\u8be2\u6307\u5b9a\u6761\u4ef6\u7684\u8bb0\u5f55\n        Args:\n            table: \u8868\u540d\u5b57 str\n            field: \u5b57\u6bb5\u540d\n            field_value: \u5b57\u6bb5\u503c\n        return:\n            \u6210\u529f\uff1a [dict] \u4fdd\u5b58\u7684\u8bb0\u5f55\n            \u5931\u8d25\uff1a -1 \u5e76\u6253\u5370\u8fd4\u56de\u62a5\u9519\u4fe1\u606f\n        '''\n        sql = \"select * from {} where {} = '{}'\".format(\n            table, field, field_value)\n        res = self.query(sql)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of all the keys in the specified table that match the given queryset.", "response": "def find_by_fields(self, table, queryset={}):\n        '''\n        \u4ece\u6570\u636e\u5e93\u91cc\u67e5\u8be2 \u7b26\u5408\u591a\u4e2a\u6761\u4ef6\u7684\u8bb0\u5f55 \n        Args:\n            table: \u8868\u540d\u5b57 str\n            queryset : key \u5b57\u6bb5 value \u503c dict\n        return:\n            \u6210\u529f\uff1a [dict] \u4fdd\u5b58\u7684\u8bb0\u5f55\n            \u5931\u8d25\uff1a -1 \u5e76\u6253\u5370\u8fd4\u56de\u62a5\u9519\u4fe1\u606f                      \n        '''\n        querys = \"\"\n        for k, v in queryset.items():\n            querys += \"{} = '{}' and \".format(k, v)\n        sql = \"select * from {} where {} \".format(\n            table, querys[:-4])\n        res = self.query(sql)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstrip a list of stop words from a string", "response": "def _stripStrList(self, raw_str, stop_strs):\n        '''\n        \u53bb\u9664\u5b57\u7b26\u4e32\u4e2d\u7684\u6240\u6709\u6307\u5b9a\u5b57\u7b26\u4e32\n        args\uff1a\n            raw_str \u6e90\u5b57\u7b26\u4e32\n            stop_strs \u6307\u5b9a\u5b57\u7b26\u4e32 \u5217\u8868\n        return\n            str \u7b5b\u9009\u540e\u7684\u5b57\u7b26\u4e32\n        '''\n        if type(stop_strs) == list:\n            for word in stop_strs:\n                raw_str = self._stripStr(raw_str, word)\n            return raw_str\n        else:\n            raise Exception('stop_words must be list!')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _judeNOtIn(self, raw_str, ele_list):\n        '''\n        \u5224\u65adele\u662f\u5426\u5728\u539f\u59cb\u5b57\u7b26\u4e32\u4e2d\n        args\uff1a\n            raw_str \u6e90\u5b57\u7b26\u4e32\n            ele_list  \u5f85\u68c0\u67e5\u7684\u5217\u8868\n        return\n            boolean\n        '''\n        for ele in ele_list:\n            if ele in raw_str:\n                return False\n        return True", "response": "Returns True if raw_str is in ele_list False otherwise"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getCookies(self):\n        '''\n        \u4ece\u5b57\u7b26\u4e32\u4e2d\u683c\u5f0f\u5316\u51fa\u5b57\u5178\u5f62\u5f0f\u7684Cookies\n        '''\n        items = self.data\n        for item in items:\n            if 'cookie' in item or 'Cookie' in item:\n                cookies = SimpleCookie(item[7:])\n                return {i.key: i.value for i in cookies.values()}\n        return {}", "response": "getCookie - Returns a dict of all cookies"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getHeaders(self):\n        '''\n        \u4ece\u5b57\u7b26\u4e32\u4e2d\u683c\u5f0f\u5316\u51fa\u5b57\u5178\u5f62\u5f0f\u7684Headers\n        '''\n        items = self.data\n        headers = {}\n        for item in items:\n            if len(item) > 0 and self._judeNOtIn(item, ['curl', 'GET', 'Cookie', 'cookie']):\n                sp = item.split(':')\n                headers[sp[0]] = sp[1]\n        return headers", "response": "getHeaders - Returns a dictionary of all the headers that are set in the object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstarting tracing with the given callable.", "response": "def trace(self, predicate):\n        \"\"\"\n        Starts tracing with the given callable.\n\n        Args:\n            predicate (callable that accepts a single :obj:`hunter.Event` argument):\n        Return:\n            self\n        \"\"\"\n        self._handler = predicate\n        if self.threading_support is None or self.threading_support:\n            self._threading_previous = getattr(threading, '_trace_hook', None)\n            threading.settrace(self)\n        self._previous = sys.gettrace()\n        sys.settrace(self)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstops tracing. Reinstalls the Hunter. Tracer. previous tracer.", "response": "def stop(self):\n        \"\"\"\n        Stop tracing. Reinstalls the :ref:`hunter.Tracer.previous` tracer.\n        \"\"\"\n        if self._handler is not None:\n            sys.settrace(self._previous)\n            self._handler = self._previous = None\n            if self.threading_support is None or self.threading_support:\n                threading.settrace(self._threading_previous)\n                self._threading_previous = None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef Q(*predicates, **query):\n    optional_actions = query.pop(\"actions\", [])\n    if \"action\" in query:\n        optional_actions.append(query.pop(\"action\"))\n\n    for p in predicates:\n        if not callable(p):\n            raise TypeError(\"Predicate {0!r} is not callable.\".format(p))\n\n    for a in optional_actions:\n        if not callable(a):\n            raise TypeError(\"Action {0!r} is not callable.\".format(a))\n\n    if predicates:\n        predicates = tuple(\n            p() if inspect.isclass(p) and issubclass(p, Action) else p\n            for p in predicates\n        )\n        if any(isinstance(p, (CallPrinter, CodePrinter)) for p in predicates):\n            # the user provided an action as a filter, remove the action then to prevent double output\n            for action in optional_actions:\n                if action in (CallPrinter, CodePrinter) or isinstance(action, (CallPrinter, CodePrinter)):\n                    optional_actions.remove(action)\n        if query:\n            predicates += Query(**query),\n\n        result = And(*predicates)\n    else:\n        result = Query(**query)\n\n    if optional_actions:\n        result = When(result, *optional_actions)\n\n    return result", "response": "A function that returns a new node that matches the given predicates."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstarting tracing the given predicates.", "response": "def trace(*predicates, **options):\n    \"\"\"\n    Starts tracing. Can be used as a context manager (with slightly incorrect semantics - it starts tracing\n    before ``__enter__`` is called).\n\n    Parameters:\n        *predicates (callables): Runs actions if **all** of the given predicates match.\n    Keyword Args:\n        clear_env_var: Disables tracing in subprocess. Default: ``False``.\n        threading_support: Enable tracing *new* threads. Default: ``None``.\n\n            Modes:\n\n            - ``None`` - automatic (enabled but actions only prefix with thread name if more than 1 thread)\n            - ``False`` - completely disabled\n            - ``True`` - enabled (actions always prefix with thread name)\n\n            You can also use:\n            ``threads_support``, ``thread_support``, ``threadingsupport``, ``threadssupport``, ``threadsupport``,\n            ``threading``, ``threads`` or ``thread``.\n        action: Action to run if all the predicates return ``True``. Default: ``CodePrinter``.\n        actions: Actions to run (in case you want more than 1).\n        **kwargs: for convenience you can also pass anything that you'd pass to :obj:`hunter.Q`\n    \"\"\"\n    global _last_tracer\n\n    predicates, options = load_config(predicates, options)\n\n    clear_env_var = options.pop(\"clear_env_var\", False)\n    threading_support = None\n    for alias in THREADING_SUPPORT_ALIASES:\n        if alias in options:\n            threading_support = options.pop(alias)\n    predicate = _prepare_predicate(*predicates, **options)\n\n    if clear_env_var:\n        os.environ.pop(\"PYTHONHUNTER\", None)\n\n    _last_tracer = Tracer(threading_support)\n\n    @atexit.register\n    def atexit_cleanup(ref=weakref.ref(_last_tracer)):\n        maybe_tracer = ref()\n        if maybe_tracer is not None:\n            maybe_tracer.stop()\n\n    return _last_tracer.trace(predicate)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfunctions decorated with this will be traced. Use ``local=True`` to only trace local code, eg:: @hunter.wrap(local=True) def my_function(): ... Keyword arguments are allowed, eg:: @hunter.wrap(action=hunter.CallPrinter) def my_function(): ... Or, filters:: @hunter.wrap(module='foobar') def my_function(): ...", "response": "def wrap(function_to_trace=None, **trace_options):\n    \"\"\"\n    Functions decorated with this will be traced.\n\n    Use ``local=True`` to only trace local code, eg::\n\n        @hunter.wrap(local=True)\n        def my_function():\n            ...\n\n    Keyword arguments are allowed, eg::\n\n        @hunter.wrap(action=hunter.CallPrinter)\n        def my_function():\n            ...\n\n    Or, filters::\n\n        @hunter.wrap(module='foobar')\n        def my_function():\n            ...\n    \"\"\"\n\n    def tracing_decorator(func):\n        @functools.wraps(func)\n        def tracing_wrapper(*args, **kwargs):\n            predicates = []\n            local = trace_options.pop('local', False)\n            if local:\n                predicates.append(Q(depth_lt=2))\n            predicates.append(~When(Q(calls_gt=0, depth=0) & ~Q(kind='return'), Stop))\n            local_tracer = trace(*predicates, **trace_options)\n            try:\n                return func(*args, **kwargs)\n            finally:\n                local_tracer.stop()\n        return tracing_wrapper\n    if function_to_trace is None:\n        return tracing_decorator\n    else:\n        return tracing_decorator(function_to_trace)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef threadid(self):\n        current = self.thread.ident\n        main = get_main_thread()\n        if main is None:\n            return current\n        else:\n            return current if current != main.ident else None", "response": "Return the thread ident."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef module(self):\n        module = self.frame.f_globals.get('__name__', '')\n        if module is None:\n            module = ''\n\n        return module", "response": "A string with module name like foo. bar."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the absolute path to the file that contains the current thread s local cache.", "response": "def filename(self, exists=os.path.exists, cython_suffix_re=CYTHON_SUFFIX_RE):\n        \"\"\"\n        A string with absolute path to file.\n\n        :type: str\n        \"\"\"\n        filename = self.frame.f_globals.get('__file__', '')\n        if filename is None:\n            filename = ''\n\n        if filename.endswith(('.pyc', '.pyo')):\n            filename = filename[:-1]\n        elif filename.endswith('$py.class'):  # Jython\n            filename = filename[:-9] + \".py\"\n        elif filename.endswith(('.so', '.pyd')):\n            basename = cython_suffix_re.sub('', filename)\n            for ext in ('.pyx', '.py'):\n                cyfilename = basename + ext\n                if exists(cyfilename):\n                    filename = cyfilename\n                    break\n        return filename"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef stdlib(self):\n        if self.module == 'pkg_resources' or self.module.startswith('pkg_resources.'):\n            return False\n        elif self.filename.startswith(SITE_PACKAGES_PATHS):\n            # if it's in site-packages then its definitely not stdlib\n            return False\n        elif self.filename.startswith(SYS_PREFIX_PATHS):\n            return True\n        else:\n            return False", "response": "A boolean flag. True if frame is in stdlib."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the sourcecode for the current line of the source code.", "response": "def source(self, getline=linecache.getline):\n        \"\"\"\n        A string with the sourcecode for the current line (from ``linecache`` - failures are ignored).\n\n        Fast but sometimes incomplete.\n\n        :type: str\n        \"\"\"\n        try:\n            return getline(self.filename, self.lineno)\n        except Exception as exc:\n            return \"??? NO SOURCE: {!r}\".format(exc)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _iter_symbols(code):\n        for node in ast.walk(ast.parse(code)):\n            if isinstance(node, ast.Name):\n                yield node.id", "response": "Iterate all the variable names in the given expression."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse HAR entry request url and queryString and make teststep url and params", "response": "def __make_request_url(self, teststep_dict, entry_json):\n        \"\"\" parse HAR entry request url and queryString, and make teststep url and params\n\n        Args:\n            entry_json (dict):\n                {\n                    \"request\": {\n                        \"url\": \"https://httprunner.top/home?v=1&w=2\",\n                        \"queryString\": [\n                            {\"name\": \"v\", \"value\": \"1\"},\n                            {\"name\": \"w\", \"value\": \"2\"}\n                        ],\n                    },\n                    \"response\": {}\n                }\n\n        Returns:\n            {\n                \"name: \"/home\",\n                \"request\": {\n                    url: \"https://httprunner.top/home\",\n                    params: {\"v\": \"1\", \"w\": \"2\"}\n                }\n            }\n\n        \"\"\"\n        request_params = utils.convert_list_to_dict(\n            entry_json[\"request\"].get(\"queryString\", [])\n        )\n\n        url = entry_json[\"request\"].get(\"url\")\n        if not url:\n            logging.exception(\"url missed in request.\")\n            sys.exit(1)\n\n        parsed_object = urlparse.urlparse(url)\n        if request_params:\n            parsed_object = parsed_object._replace(query='')\n            teststep_dict[\"request\"][\"url\"] = parsed_object.geturl()\n            teststep_dict[\"request\"][\"params\"] = request_params\n        else:\n            teststep_dict[\"request\"][\"url\"] = url\n\n        teststep_dict[\"name\"] = parsed_object.path"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __make_request_method(self, teststep_dict, entry_json):\n        method = entry_json[\"request\"].get(\"method\")\n        if not method:\n            logging.exception(\"method missed in request.\")\n            sys.exit(1)\n\n        teststep_dict[\"request\"][\"method\"] = method", "response": "parse HAR entry request method and make teststep method."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __make_request_headers(self, teststep_dict, entry_json):\n        teststep_headers = {}\n        for header in entry_json[\"request\"].get(\"headers\", []):\n            if header[\"name\"].lower() in IGNORE_REQUEST_HEADERS:\n                continue\n\n            teststep_headers[header[\"name\"]] = header[\"value\"]\n\n        if teststep_headers:\n            teststep_dict[\"request\"][\"headers\"] = teststep_headers", "response": "Parse HAR entry request headers and make teststep headers."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _make_request_data(self, teststep_dict, entry_json):\n        method = entry_json[\"request\"].get(\"method\")\n        if method in [\"POST\", \"PUT\", \"PATCH\"]:\n            postData = entry_json[\"request\"].get(\"postData\", {})\n            mimeType = postData.get(\"mimeType\")\n\n            # Note that text and params fields are mutually exclusive.\n            if \"text\" in postData:\n                post_data = postData.get(\"text\")\n            else:\n                params = postData.get(\"params\", [])\n                post_data = utils.convert_list_to_dict(params)\n\n            request_data_key = \"data\"\n            if not mimeType:\n                pass\n            elif mimeType.startswith(\"application/json\"):\n                try:\n                    post_data = json.loads(post_data)\n                    request_data_key = \"json\"\n                except JSONDecodeError:\n                    pass\n            elif mimeType.startswith(\"application/x-www-form-urlencoded\"):\n                post_data = utils.convert_x_www_form_urlencoded_to_dict(post_data)\n            else:\n                # TODO: make compatible with more mimeType\n                pass\n\n            teststep_dict[\"request\"][request_data_key] = post_data", "response": "Parse HAR entry request data and make teststep request data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _make_validate(self, teststep_dict, entry_json):\n        teststep_dict[\"validate\"].append(\n            {\"eq\": [\"status_code\", entry_json[\"response\"].get(\"status\")]}\n        )\n\n        resp_content_dict = entry_json[\"response\"].get(\"content\")\n\n        headers_mapping = utils.convert_list_to_dict(\n            entry_json[\"response\"].get(\"headers\", [])\n        )\n        if \"Content-Type\" in headers_mapping:\n            teststep_dict[\"validate\"].append(\n                {\"eq\": [\"headers.Content-Type\", headers_mapping[\"Content-Type\"]]}\n            )\n\n        text = resp_content_dict.get(\"text\")\n        if not text:\n            return\n\n        mime_type = resp_content_dict.get(\"mimeType\")\n        if mime_type and mime_type.startswith(\"application/json\"):\n\n            encoding = resp_content_dict.get(\"encoding\")\n            if encoding and encoding == \"base64\":\n                content = base64.b64decode(text).decode('utf-8')\n            else:\n                content = text\n\n            try:\n                resp_content_json = json.loads(content)\n            except JSONDecodeError:\n                logging.warning(\n                    \"response content can not be loaded as json: {}\".format(content.encode(\"utf-8\"))\n                )\n                return\n\n            if not isinstance(resp_content_json, dict):\n                return\n\n            for key, value in resp_content_json.items():\n                if isinstance(value, (dict, list)):\n                    continue\n\n                teststep_dict[\"validate\"].append(\n                    {\"eq\": [\"content.{}\".format(key), value]}\n                )", "response": "Parse HAR entry response and make teststep validate."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload HAR file and return log entries list", "response": "def load_har_log_entries(file_path):\n    \"\"\" load HAR file and return log entries list\n\n    Args:\n        file_path (str)\n\n    Returns:\n        list: entries\n            [\n                {\n                    \"request\": {},\n                    \"response\": {}\n                },\n                {\n                    \"request\": {},\n                    \"response\": {}\n                }\n            ]\n\n    \"\"\"\n    with io.open(file_path, \"r+\", encoding=\"utf-8-sig\") as f:\n        try:\n            content_json = json.loads(f.read())\n            return content_json[\"log\"][\"entries\"]\n        except (KeyError, TypeError):\n            logging.error(\"HAR file content error: {}\".format(file_path))\n            sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert origin dict to x - www - form - urlencoded", "response": "def x_www_form_urlencoded(post_data):\n    \"\"\" convert origin dict to x-www-form-urlencoded\n\n    Args:\n        post_data (dict):\n            {\"a\": 1, \"b\":2}\n\n    Returns:\n        str:\n            a=1&b=2\n\n    \"\"\"\n    if isinstance(post_data, dict):\n        return \"&\".join([\n            u\"{}={}\".format(key, value)\n            for key, value in post_data.items()\n        ])\n    else:\n        return post_data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef convert_x_www_form_urlencoded_to_dict(post_data):\n    if isinstance(post_data, str):\n        converted_dict = {}\n        for k_v in post_data.split(\"&\"):\n            try:\n                key, value = k_v.split(\"=\")\n            except ValueError:\n                raise Exception(\n                    \"Invalid x_www_form_urlencoded data format: {}\".format(post_data)\n                )\n            converted_dict[key] = unquote(value)\n        return converted_dict\n    else:\n        return post_data", "response": "convert x_www_form_urlencoded data to dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndump HAR entries to YAML testcase", "response": "def dump_yaml(testcase, yaml_file):\n    \"\"\" dump HAR entries to yaml testcase\n    \"\"\"\n    logging.info(\"dump testcase to YAML format.\")\n\n    with io.open(yaml_file, 'w', encoding=\"utf-8\") as outfile:\n        yaml.dump(testcase, outfile, allow_unicode=True, default_flow_style=False, indent=4)\n\n    logging.info(\"Generate YAML testcase successfully: {}\".format(yaml_file))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dump_json(testcase, json_file):\n    logging.info(\"dump testcase to JSON format.\")\n\n    with io.open(json_file, 'w', encoding=\"utf-8\") as outfile:\n        my_json_str = json.dumps(testcase, ensure_ascii=ensure_ascii, indent=4)\n        if isinstance(my_json_str, bytes):\n            my_json_str = my_json_str.decode(\"utf-8\")\n\n        outfile.write(my_json_str)\n\n    logging.info(\"Generate JSON testcase successfully: {}\".format(json_file))", "response": "dump HAR entries to json testcase"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef main():\n    parser = argparse.ArgumentParser(description=__description__)\n    parser.add_argument(\n        '-V', '--version', dest='version', action='store_true',\n        help=\"show version\")\n    parser.add_argument(\n        '--log-level', default='INFO',\n        help=\"Specify logging level, default is INFO.\")\n    parser.add_argument('har_source_file', nargs='?',\n        help=\"Specify HAR source file\")\n    parser.add_argument(\n        '-2y', '--to-yml', '--to-yaml',\n        dest='to_yaml', action='store_true',\n        help=\"Convert to YAML format, if not specified, convert to JSON format by default.\")\n    parser.add_argument(\n        '--filter', help=\"Specify filter keyword, only url include filter string will be converted.\")\n    parser.add_argument(\n        '--exclude',\n        help=\"Specify exclude keyword, url that includes exclude string will be ignored, multiple keywords can be joined with '|'\")\n\n    args = parser.parse_args()\n\n    if args.version:\n        print(\"{}\".format(__version__))\n        exit(0)\n\n    log_level = getattr(logging, args.log_level.upper())\n    logging.basicConfig(level=log_level)\n\n    har_source_file = args.har_source_file\n    if not har_source_file or not har_source_file.endswith(\".har\"):\n        logging.error(\"HAR file not specified.\")\n        sys.exit(1)\n\n    output_file_type = \"YML\" if args.to_yaml else \"JSON\"\n    HarParser(\n        har_source_file, args.filter, args.exclude\n    ).gen_testcase(output_file_type)\n\n    return 0", "response": "HAR converter main function."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nincluding the request ID if available in the outgoing request", "response": "def prepare_request(self, request):\n        \"\"\"Include the request ID, if available, in the outgoing request\"\"\"\n        try:\n            request_id = local.request_id\n        except AttributeError:\n            request_id = NO_REQUEST_ID\n\n        if self.request_id_header and request_id != NO_REQUEST_ID:\n            request.headers[self.request_id_header] = request_id\n\n        return super(Session, self).prepare_request(request)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef short(self, url):\n        url = self.clean_url(url)\n        shorten_url = f'{self.api_url}v1/shorten'\n        payload = {\n            'domain': getattr(self, 'domain', 'adf.ly'),\n            'advert_type': getattr(self, 'type', 'int'),\n            'group_id': getattr(self, 'group_id', None),\n            'key': self.api_key,\n            'user_id': self.user_id,\n            'url': url,\n        }\n        response = self._post(shorten_url, data=payload)\n        if not response.ok:\n            raise BadAPIResponseException(response.content)\n\n        try:\n            data = response.json()\n        except json.decoder.JSONDecodeError:\n            raise BadAPIResponseException('API response could not be decoded')\n\n        if data.get('errors'):\n            errors = ','.join(i['msg'] for i in data['errors'])\n            raise ShorteningErrorException(errors)\n\n        if not data.get('data'):\n            raise BadAPIResponseException(response.content)\n\n        return data['data'][0]['short_url']", "response": "Short implementation for Adf. ly\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef expand(self, url):\n        url = self.clean_url(url)\n        expand_url = f'{self.api_url}v1/expand'\n        payload = {\n            'domain': getattr(self, 'domain', 'adf.ly'),\n            'advert_type': getattr(self, 'type', 'int'),\n            'group_id': getattr(self, 'group_id', None),\n            'key': self.api_key,\n            'user_id': self.user_id,\n            'url': url,\n        }\n        response = self._post(expand_url, data=payload)\n        if not response.ok:\n            raise BadAPIResponseException(response.content)\n\n        try:\n            data = response.json()\n        except json.decoder.JSONDecodeError:\n            raise BadAPIResponseException('API response could not be decoded')\n\n        if data.get('errors'):\n            errors = ','.join(i['msg'] for i in data['errors'])\n            raise ShorteningErrorException(errors)\n\n        if not data.get('data'):\n            raise BadAPIResponseException(response.content)\n\n        return data['data'][0]['url']", "response": "Expand implementation for Adf. ly\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef short(self, url):\n\n        self.clean_url(url)\n        shorten_url = f'{self.api_url}v3/shorten'\n        params = {\n            'uri': url,\n            'access_token': self.api_key,\n            'format': 'txt',\n        }\n        response = self._get(shorten_url, params=params)\n        if response.ok:\n            return response.text.strip()\n        raise ShorteningErrorException(response.content)", "response": "Short implementation for Bit. ly\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef expand(self, url):\n        expand_url = f'{self.api_url}v3/expand'\n        params = {\n            'shortUrl': url,\n            'access_token': self.api_key,\n            'format': 'txt',\n        }\n        response = self._get(expand_url, params=params)\n        if response.ok:\n            return response.text.strip()\n        raise ExpandingErrorException(response.content)", "response": "Expand implementation for Bit. ly\n           "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntotaling clicks implementation for Bit. ly", "response": "def total_clicks(self, url):\n        \"\"\"Total clicks implementation for Bit.ly\n        Args:\n            url: the URL you want to get the total clicks count\n\n        Returns:\n            An int containing the total clicks count\n\n        Raises:\n            BadAPIResponseException: If the API Returns an error as response\n        \"\"\"\n        url = self.clean_url(url)\n        clicks_url = f'{self.api_url}v3/link/clicks'\n        params = {\n            'link': url,\n            'access_token': self.api_key,\n            'format': 'txt'\n        }\n        response = self._get(clicks_url, params=params)\n        if not response.ok:\n            raise BadAPIResponseException(response.content)\n\n        try:\n            total_clicks = int(response.text)\n        except (KeyError, TypeError) as e:\n            logger.warning('Bad value from total_clicks response: %s', e)\n            return 0\n\n        return total_clicks"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get(self, url, params=None, headers=None):\n        url = self.clean_url(url)\n        response = requests.get(url, params=params, verify=self.verify,\n                                timeout=self.timeout, headers=headers)\n        return response", "response": "Wraps a GET request with a url check"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwrapping a POST request with a url check", "response": "def _post(self, url, data=None, json=None, params=None, headers=None):\n        \"\"\"Wraps a POST request with a url check\"\"\"\n        url = self.clean_url(url)\n        response = requests.post(url, data=data, json=json, params=params,\n                                 headers=headers, timeout=self.timeout,\n                                 verify=self.verify)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbasing expand method. Only visits the link and return the response url", "response": "def expand(self, url):\n        \"\"\"Base expand method. Only visits the link, and return the response\n        url\"\"\"\n        url = self.clean_url(url)\n        response = self._get(url)\n        if response.ok:\n            return response.url\n        raise ExpandingErrorException"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pdu_to_function_code_or_raise_error(resp_pdu):\n    function_code = struct.unpack('>B', resp_pdu[0:1])[0]\n\n    if function_code not in function_code_to_function_map.keys():\n        error_code = struct.unpack('>B', resp_pdu[1:2])[0]\n        raise error_code_to_exception_map[error_code]\n\n    return function_code", "response": "Parses response PDU and returns function code."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_function_from_response_pdu(resp_pdu, req_pdu=None):\n    function_code = pdu_to_function_code_or_raise_error(resp_pdu)\n    function = function_code_to_function_map[function_code]\n\n    if req_pdu is not None and \\\n        'req_pdu' in inspect.getargspec(function.create_from_response_pdu).args:  # NOQA\n\n        return function.create_from_response_pdu(resp_pdu, req_pdu)\n\n    return function.create_from_response_pdu(resp_pdu)", "response": "Parse response PDU and return instance of ModbusFunction."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a function instance based on request PDU.", "response": "def create_function_from_request_pdu(pdu):\n    \"\"\" Return function instance, based on request PDU.\n\n    :param pdu: Array of bytes.\n    :return: Instance of a function.\n    \"\"\"\n    function_code = get_function_code_from_request_pdu(pdu)\n    try:\n        function_class = function_code_to_function_map[function_code]\n    except KeyError:\n        raise IllegalFunctionError(function_code)\n\n    return function_class.create_from_request_pdu(pdu)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef request_pdu(self):\n        if None in [self.starting_address, self.quantity]:\n            # TODO Raise proper exception.\n            raise Exception\n\n        return struct.pack('>BHH', self.function_code, self.starting_address,\n                           self.quantity)", "response": "Builds request PDU to read coils."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_response_pdu(self, data):\n        log.debug('Create single bit response pdu {0}.'.format(data))\n        bytes_ = [data[i:i + 8] for i in range(0, len(data), 8)]\n\n        # Reduce each all bits per byte to a number. Byte\n        # [0, 0, 0, 0, 0, 1, 1, 1] is intepreted as binary en is decimal 3.\n        for index, byte in enumerate(bytes_):\n            bytes_[index] = \\\n                reduce(lambda a, b: (a << 1) + b, list(reversed(byte)))\n\n        log.debug('Reduced single bit data to {0}.'.format(bytes_))\n        # The first 2 B's of the format encode the function code (1 byte) and\n        # the length (1 byte) of the following byte series. Followed by # a B\n        # for every byte in the series of bytes. 3 lead to the format '>BBB'\n        # and 257 lead to the format '>BBBB'.\n        fmt = '>BB' + self.format_character * len(bytes_)\n        return struct.pack(fmt, self.function_code, len(bytes_), *bytes_)", "response": "Create response pdu.\n\n        :param data: A list with 0's and/or 1's.\n        :return: Byte array of at least 3 bytes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_from_response_pdu(resp_pdu, req_pdu):\n        read_coils = ReadCoils()\n        read_coils.quantity = struct.unpack('>H', req_pdu[-2:])[0]\n        byte_count = struct.unpack('>B', resp_pdu[1:2])[0]\n\n        fmt = '>' + ('B' * byte_count)\n        bytes_ = struct.unpack(fmt, resp_pdu[2:])\n\n        data = list()\n\n        for i, value in enumerate(bytes_):\n            padding = 8 if (read_coils.quantity - (8 * i)) // 8 > 0 \\\n                else read_coils.quantity % 8\n\n            fmt = '{{0:0{padding}b}}'.format(padding=padding)\n\n            # Create binary representation of integer, convert it to a list\n            # and reverse the list.\n            data = data + [int(i) for i in fmt.format(value)][::-1]\n\n        read_coils.data = data\n        return read_coils", "response": "Create instance of read_coils from response PDU."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef execute(self, slave_id, route_map):\n        try:\n            values = []\n\n            for address in range(self.starting_address,\n                                 self.starting_address + self.quantity):\n                endpoint = route_map.match(slave_id, self.function_code,\n                                           address)\n                values.append(endpoint(slave_id=slave_id, address=address,\n                                       function_code=self.function_code))\n\n            return values\n\n        # route_map.match() returns None if no match is found. Calling None\n        # results in TypeError.\n        except TypeError:\n            raise IllegalDataAddressError()", "response": "Execute the function registered for a route."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_from_request_pdu(pdu):\n\n        \"\"\" Create instance from request PDU.\n        :param pdu: A request PDU.\n        :return: Instance of this class.\n        \"\"\"\n        _, starting_address, quantity = struct.unpack('>BHH', pdu)\n\n        instance = ReadHoldingRegisters()\n        instance.starting_address = starting_address\n        instance.quantity = quantity\n\n        return instance", "response": "Create an instance of this class from a request PDU."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating response pdu. :param data: A list with values. :return: Byte array of at least 4 bytes.", "response": "def create_response_pdu(self, data):\n        \"\"\" Create response pdu.\n\n        :param data: A list with values.\n        :return: Byte array of at least 4 bytes.\n        \"\"\"\n        log.debug('Create multi bit response pdu {0}.'.format(data))\n        fmt = '>BB' + conf.TYPE_CHAR * len(data)\n\n        return struct.pack(fmt, self.function_code, len(data) * 2, *data)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_from_response_pdu(resp_pdu, req_pdu):\n        read_holding_registers = ReadHoldingRegisters()\n        read_holding_registers.quantity = struct.unpack('>H', req_pdu[-2:])[0]\n        read_holding_registers.byte_count = \\\n            struct.unpack('>B', resp_pdu[1:2])[0]\n\n        fmt = '>' + (conf.TYPE_CHAR * read_holding_registers.quantity)\n        read_holding_registers.data = list(struct.unpack(fmt, resp_pdu[2:]))\n\n        return read_holding_registers", "response": "Create instance of read_holding_registers from response PDU."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates instance of ReadCoils from response PDU.", "response": "def create_from_response_pdu(resp_pdu, req_pdu):\n        \"\"\" Create instance from response PDU.\n\n        Response PDU is required together with the number of registers read.\n\n        :param resp_pdu: Byte array with request PDU.\n        :param quantity: Number of coils read.\n        :return: Instance of :class:`ReadCoils`.\n        \"\"\"\n        read_input_registers = ReadInputRegisters()\n        read_input_registers.quantity = struct.unpack('>H', req_pdu[-2:])[0]\n\n        fmt = '>' + (conf.TYPE_CHAR * read_input_registers.quantity)\n        read_input_registers.data = list(struct.unpack(fmt, resp_pdu[2:]))\n\n        return read_input_registers"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds request PDU to write single coil.", "response": "def request_pdu(self):\n        \"\"\" Build request PDU to write single coil.\n\n        :return: Byte array of 5 bytes with PDU.\n        \"\"\"\n        if None in [self.address, self.value]:\n            # TODO Raise proper exception.\n            raise Exception\n\n        return struct.pack('>BHH', self.function_code, self.address,\n                           self._value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_from_request_pdu(pdu):\n        _, address, value = struct.unpack('>BHH', pdu)\n\n        value = 1 if value == 0xFF00 else value\n\n        instance = WriteSingleCoil()\n        instance.address = address\n        instance.value = value\n\n        return instance", "response": "Create a WriteSingleCoil instance from a request PDU."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_response_pdu(self):\n        fmt = '>BHH'\n        return struct.pack(fmt, self.function_code, self.address, self._value)", "response": "Create response pdu.\n\n        :param data: A list with values.\n        :return: Byte array of at least 4 bytes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating instance of WriteSingleCoil from response PDU.", "response": "def create_from_response_pdu(resp_pdu):\n        \"\"\" Create instance from response PDU.\n\n        :param resp_pdu: Byte array with request PDU.\n        :return: Instance of :class:`WriteSingleCoil`.\n        \"\"\"\n        write_single_coil = WriteSingleCoil()\n\n        address, value = struct.unpack('>HH', resp_pdu[1:5])\n        value = 1 if value == 0xFF00 else value\n\n        write_single_coil.address = address\n        write_single_coil.data = value\n\n        return write_single_coil"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef execute(self, slave_id, route_map):\n        endpoint = route_map.match(slave_id, self.function_code, self.address)\n        try:\n            endpoint(slave_id=slave_id, address=self.address, value=self.value,\n                     function_code=self.function_code)\n        # route_map.match() returns None if no match is found. Calling None\n        # results in TypeError.\n        except TypeError:\n            raise IllegalDataAddressError()", "response": "Execute the function registered for a route."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef value(self, value):\n        try:\n            struct.pack('>' + conf.TYPE_CHAR, value)\n        except struct.error:\n            raise IllegalDataValueError\n\n        self._value = value", "response": "Set the value of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef request_pdu(self):\n        if None in [self.address, self.value]:\n            # TODO Raise proper exception.\n            raise Exception\n\n        return struct.pack('>BH' + conf.TYPE_CHAR, self.function_code,\n                           self.address, self.value)", "response": "Builds request PDU to write single register."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_from_request_pdu(pdu):\n        _, address, value = \\\n            struct.unpack('>BH' + conf.MULTI_BIT_VALUE_FORMAT_CHARACTER, pdu)\n\n        instance = WriteSingleRegister()\n        instance.address = address\n        instance.value = value\n\n        return instance", "response": "Create an instance of the class from a request PDU."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating instance of WriteSingleRegister from response PDU.", "response": "def create_from_response_pdu(resp_pdu):\n        \"\"\" Create instance from response PDU.\n\n        :param resp_pdu: Byte array with request PDU.\n        :return: Instance of :class:`WriteSingleRegister`.\n        \"\"\"\n        write_single_register = WriteSingleRegister()\n\n        address, value = struct.unpack('>H' + conf.TYPE_CHAR, resp_pdu[1:5])\n\n        write_single_register.address = address\n        write_single_register.data = value\n\n        return write_single_register"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_from_request_pdu(pdu):\n        _, starting_address, quantity, byte_count = \\\n            struct.unpack('>BHHB', pdu[:6])\n\n        fmt = '>' + (conf.SINGLE_BIT_VALUE_FORMAT_CHARACTER * byte_count)\n        values = struct.unpack(fmt, pdu[6:])\n\n        res = list()\n\n        for i, value in enumerate(values):\n            padding = 8 if (quantity - (8 * i)) // 8 > 0 else quantity % 8\n            fmt = '{{0:0{padding}b}}'.format(padding=padding)\n\n            # Create binary representation of integer, convert it to a list\n            # and reverse the list.\n            res = res + [int(i) for i in fmt.format(value)][::-1]\n\n        instance = WriteMultipleCoils()\n        instance.starting_address = starting_address\n        instance.quantity = quantity\n\n        instance.values = res\n\n        return instance", "response": "Create a new entry in the cache for the current coil status and value."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_response_pdu(self):\n        return struct.pack('>BHH', self.function_code, self.starting_address,\n                           len(self.values))", "response": "Create response pdu.\n\n        :param data: A list with values.\n        :return: Byte array 5 bytes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexecuting the function registered for a route.", "response": "def execute(self, slave_id, route_map):\n        \"\"\" Execute the Modbus function registered for a route.\n\n        :param slave_id: Slave id.\n        :param eindpoint: Instance of modbus.route.Map.\n        \"\"\"\n        for index, value in enumerate(self.values):\n            address = self.starting_address + index\n            endpoint = route_map.match(slave_id, self.function_code, address)\n\n            try:\n                endpoint(slave_id=slave_id, address=address, value=value,\n                         function_code=self.function_code)\n            # route_map.match() returns None if no match is found. Calling None\n            # results in TypeError.\n            except TypeError:\n                raise IllegalDataAddressError()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_from_request_pdu(pdu):\n        _, starting_address, quantity, byte_count = \\\n            struct.unpack('>BHHB', pdu[:6])\n\n        # Values are 16 bit, so each value takes up 2 bytes.\n        fmt = '>' + (conf.MULTI_BIT_VALUE_FORMAT_CHARACTER *\n                     int((byte_count / 2)))\n\n        values = list(struct.unpack(fmt, pdu[6:]))\n\n        instance = WriteMultipleRegisters()\n        instance.starting_address = starting_address\n        instance.values = values\n\n        return instance", "response": "Create an instance of this class from a request PDU."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_server(server_class, serial_port):\n    s = server_class()\n    s.serial_port = serial_port\n\n    s.route_map = Map()\n    s.route = MethodType(route, s)\n\n    return s", "response": "Returns a new instance of server_class with the given serial_port bound to it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef serve_forever(self, poll_interval=0.5):\n        self.serial_port.timeout = poll_interval\n\n        while not self._shutdown_request:\n            try:\n                self.serve_once()\n            except (CRCError, struct.error) as e:\n                log.error('Can\\'t handle request: {0}'.format(e))\n            except (SerialTimeoutException, ValueError):\n                pass", "response": "Wait for incomming requests."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef process(self, request_adu):\n        meta_data = self.get_meta_data(request_adu)\n        request_pdu = self.get_request_pdu(request_adu)\n\n        response_pdu = self.execute_route(meta_data, request_pdu)\n        response_adu = self.create_response_adu(meta_data, response_pdu)\n\n        return response_adu", "response": "Process the request ADU and return the response."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef execute_route(self, meta_data, request_pdu):\n        try:\n            function = create_function_from_request_pdu(request_pdu)\n            results =\\\n                function.execute(meta_data['unit_id'], self.route_map)\n\n            try:\n                # ReadFunction's use results of callbacks to build response\n                # PDU...\n                return function.create_response_pdu(results)\n            except TypeError:\n                # ...other functions don't.\n                return function.create_response_pdu()\n        except ModbusError as e:\n            function_code = get_function_code_from_request_pdu(request_pdu)\n            return pack_exception_pdu(function_code, e.error_code)\n        except Exception as e:\n            log.exception('Could not handle request: {0}.'.format(e))\n            function_code = get_function_code_from_request_pdu(request_pdu)\n\n            return pack_exception_pdu(function_code,\n                                      ServerDeviceFailureError.error_code)", "response": "Execute the configured route based on the meta data and the request PDU."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends an ADU to the client.", "response": "def respond(self, response_adu):\n        \"\"\" Send response ADU back to client.\n\n        :param response_adu: A bytearray containing the response of an ADU.\n        \"\"\"\n        log.debug('--> {0}'.format(hexlify(response_adu)))\n        self.serial_port.write(response_adu)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the timeouts on the serial port based on baudrate.", "response": "def serial_port(self, serial_port):\n        \"\"\" Set timeouts on serial port based on baudrate to detect frames. \"\"\"\n        char_size = get_char_size(serial_port.baudrate)\n\n        # See docstring of get_char_size() for meaning of constants below.\n        serial_port.inter_byte_timeout = 1.5 * char_size\n        serial_port.timeout = 3.5 * char_size\n        self._serial_port = serial_port"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlistens and handle 1 request.", "response": "def serve_once(self):\n        \"\"\" Listen and handle 1 request. \"\"\"\n        # 256 is the maximum size of a Modbus RTU frame.\n        request_adu = self.serial_port.read(256)\n        log.debug('<-- {0}'.format(hexlify(request_adu)))\n\n        if len(request_adu) == 0:\n            raise ValueError\n\n        response_adu = self.process(request_adu)\n        self.respond(response_adu)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprocesses request ADU and return response.", "response": "def process(self, request_adu):\n        \"\"\" Process request ADU and return response.\n\n        :param request_adu: A bytearray containing the ADU request.\n        :return: A bytearray containing the response of the ADU request.\n        \"\"\"\n        validate_crc(request_adu)\n        return super(RTUServer, self).process(request_adu)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_response_adu(self, meta_data, response_pdu):\n        first_part_adu = struct.pack('>B', meta_data['unit_id']) + response_pdu\n        return first_part_adu + get_crc(first_part_adu)", "response": "Builds response ADU from meta data and response PDU and return it."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates look up table.", "response": "def generate_look_up_table():\n    \"\"\" Generate look up table.\n\n    :return: List\n    \"\"\"\n    poly = 0xA001\n    table = []\n\n    for index in range(256):\n\n        data = index << 1\n        crc = 0\n        for _ in range(8, 0, -1):\n            data >>= 1\n            if (data ^ crc) & 0x0001:\n                crc = (crc >> 1) ^ poly\n            else:\n                crc >>= 1\n        table.append(crc)\n\n    return table"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning CRC of 2 byte for message.", "response": "def get_crc(msg):\n    \"\"\" Return CRC of 2 byte for message.\n\n        >>> assert get_crc(b'\\x02\\x07') == struct.unpack('<H', b'\\x41\\x12')\n\n    :param msg: A byte array.\n    :return: Byte array of 2 bytes.\n    \"\"\"\n    register = 0xFFFF\n\n    for byte_ in msg:\n        try:\n            val = struct.unpack('<B', byte_)[0]\n        # Iterating over a bit-like objects in Python 3 gets you ints.\n        # Because fuck logic.\n        except TypeError:\n            val = byte_\n\n        register = \\\n            (register >> 8) ^ look_up_table[(register ^ val) & 0xFF]\n\n    # CRC is little-endian!\n    return struct.pack('<H', register)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nvalidates CRC of message.", "response": "def validate_crc(msg):\n    \"\"\" Validate CRC of message.\n\n    :param msg: Byte array with message with CRC.\n    :raise: CRCError.\n    \"\"\"\n    if not struct.unpack('<H', get_crc(msg[:-2])) ==\\\n            struct.unpack('<H', msg[-2:]):\n        raise CRCError('CRC validation failed.')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _create_request_adu(slave_id, req_pdu):\n    first_part_adu = struct.pack('>B', slave_id) + req_pdu\n\n    return first_part_adu + get_crc(first_part_adu)", "response": "Create request ADU for Modbus RTU."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_coils(slave_id, starting_address, quantity):\n    function = ReadCoils()\n    function.starting_address = starting_address\n    function.quantity = quantity\n\n    return _create_request_adu(slave_id, function.request_pdu)", "response": "Return the ADU for reading Coils."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_discrete_inputs(slave_id, starting_address, quantity):\n    function = ReadDiscreteInputs()\n    function.starting_address = starting_address\n    function.quantity = quantity\n\n    return _create_request_adu(slave_id, function.request_pdu)", "response": "Return the ADU for reading discrete inputs."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_holding_registers(slave_id, starting_address, quantity):\n    function = ReadHoldingRegisters()\n    function.starting_address = starting_address\n    function.quantity = quantity\n\n    return _create_request_adu(slave_id, function.request_pdu)", "response": "This function returns the value of the Read Holding Registers command."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_input_registers(slave_id, starting_address, quantity):\n    function = ReadInputRegisters()\n    function.starting_address = starting_address\n    function.quantity = quantity\n\n    return _create_request_adu(slave_id, function.request_pdu)", "response": "This function returns the value of the Read Input Registers request PDU."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write_single_coil(slave_id, address, value):\n    function = WriteSingleCoil()\n    function.address = address\n    function.value = value\n\n    return _create_request_adu(slave_id, function.request_pdu)", "response": "Write a single Coil to a Modbus slave."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_single_register(slave_id, address, value):\n    function = WriteSingleRegister()\n    function.address = address\n    function.value = value\n\n    return _create_request_adu(slave_id, function.request_pdu)", "response": "Write a single register to the slave."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn ADU for Modbus function code 15: Write Multiple Coils. :param slave_id: Number of slave. :return: Byte array with ADU.", "response": "def write_multiple_coils(slave_id, starting_address, values):\n    \"\"\" Return ADU for Modbus function code 15: Write Multiple Coils.\n\n    :param slave_id: Number of slave.\n    :return: Byte array with ADU.\n    \"\"\"\n    function = WriteMultipleCoils()\n    function.starting_address = starting_address\n    function.values = values\n\n    return _create_request_adu(slave_id, function.request_pdu)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write_multiple_registers(slave_id, starting_address, values):\n    function = WriteMultipleRegisters()\n    function.starting_address = starting_address\n    function.values = values\n\n    return _create_request_adu(slave_id, function.request_pdu)", "response": "Write multiple registers to the slave."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_response_adu(resp_adu, req_adu=None):\n    resp_pdu = resp_adu[1:-2]\n    validate_crc(resp_adu)\n\n    req_pdu = None\n\n    if req_adu is not None:\n        req_pdu = req_adu[1:-2]\n\n    function = create_function_from_response_pdu(resp_pdu, req_pdu)\n\n    return function.data", "response": "Parse response ADU and return response data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send_message(adu, serial_port):\n    serial_port.write(adu)\n    serial_port.flush()\n\n    # Check exception ADU (which is shorter than all other responses) first.\n    exception_adu_size = 5\n    response_error_adu = recv_exactly(serial_port.read, exception_adu_size)\n    raise_for_exception_adu(response_error_adu)\n\n    expected_response_size = \\\n        expected_response_pdu_size_from_request_pdu(adu[1:-2]) + 3\n    response_remainder = recv_exactly(\n        serial_port.read, expected_response_size - exception_adu_size)\n\n    return parse_response_adu(response_error_adu + response_remainder, adu)", "response": "Send ADU over serial to server and return parsed response."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef respond(self, response_adu):\n        log.info('--> {0} - {1}.'.format(self.client_address[0],\n                 hexlify(response_adu)))\n        self.request.sendall(response_adu)", "response": "Send an ADU to the client."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_server(server_class, server_address, request_handler_class):\n    s = server_class(server_address, request_handler_class)\n\n    s.route_map = Map()\n    s.route = MethodType(route, s)\n\n    return s", "response": "Returns a new instance of server_class with route_map bound to it."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_meta_data(self, request_adu):\n        try:\n            transaction_id, protocol_id, length, unit_id = \\\n                unpack_mbap(request_adu[:7])\n        except struct.error:\n            raise ServerDeviceFailureError()\n\n        return {\n            'transaction_id': transaction_id,\n            'protocol_id': protocol_id,\n            'length': length,\n            'unit_id': unit_id,\n        }", "response": "Extracts the MBAP header from the request adu and returns it as a dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_response_adu(self, meta_data, response_pdu):\n        response_mbap = pack_mbap(\n            transaction_id=meta_data['transaction_id'],\n            protocol_id=meta_data['protocol_id'],\n            length=len(response_pdu) + 1,\n            unit_id=meta_data['unit_id']\n        )\n\n        return response_mbap + response_pdu", "response": "Builds response ADU from meta data and response PDU and return it."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a StreamHandler to the logger which logs to a stream.", "response": "def log_to_stream(stream=sys.stderr, level=logging.NOTSET,\n                  fmt=logging.BASIC_FORMAT):\n    \"\"\" Add :class:`logging.StreamHandler` to logger which logs to a stream.\n\n    :param stream. Stream to log to, default STDERR.\n    :param level: Log level, default NOTSET.\n    :param fmt: String with log format, default is BASIC_FORMAT.\n    \"\"\"\n    fmt = Formatter(fmt)\n    handler = StreamHandler()\n    handler.setFormatter(fmt)\n    handler.setLevel(level)\n\n    log.addHandler(handler)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pack_mbap(transaction_id, protocol_id, length, unit_id):\n    return struct.pack('>HHHB', transaction_id, protocol_id, length, unit_id)", "response": "Create and return response MBAP."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef recv_exactly(recv_fn, size):\n    recv_bytes = 0\n    chunks = []\n    while recv_bytes < size:\n        chunk = recv_fn(size - recv_bytes)\n        if len(chunk) == 0:  # when closed or empty\n            break\n        recv_bytes += len(chunk)\n        chunks.append(chunk)\n\n    response = b''.join(chunks)\n\n    if len(response) != size:\n        raise ValueError\n\n    return response", "response": "Use the function to read and return exactly size bytes."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _create_mbap_header(slave_id, pdu):\n    # 65535 = (2**16)-1 aka maximum number that fits in 2 bytes.\n    transaction_id = randint(0, 65535)\n    length = len(pdu) + 1\n\n    return struct.pack('>HHHB', transaction_id, 0, length, slave_id)", "response": "Create MBAP header for PDU."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses response ADU and return response data.", "response": "def parse_response_adu(resp_adu, req_adu=None):\n    \"\"\" Parse response ADU and return response data. Some functions require\n    request ADU to fully understand request ADU.\n\n    :param resp_adu: Resonse ADU.\n    :param req_adu: Request ADU, default None.\n    :return: Response data.\n    \"\"\"\n    resp_pdu = resp_adu[7:]\n    function = create_function_from_response_pdu(resp_pdu, req_adu)\n\n    return function.data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send_message(adu, sock):\n    sock.sendall(adu)\n\n    # Check exception ADU (which is shorter than all other responses) first.\n    exception_adu_size = 9\n    response_error_adu = recv_exactly(sock.recv, exception_adu_size)\n    raise_for_exception_adu(response_error_adu)\n\n    expected_response_size = \\\n        expected_response_pdu_size_from_request_pdu(adu[7:]) + 7\n    response_remainder = recv_exactly(\n        sock.recv, expected_response_size - exception_adu_size)\n\n    return parse_response_adu(response_error_adu + response_remainder, adu)", "response": "Send ADU over socket and return parsed response."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_serial_port():\n    port = Serial(port='/dev/ttyS1', baudrate=9600, parity=PARITY_NONE,\n                  stopbits=1, bytesize=8, timeout=1)\n\n    fh = port.fileno()\n\n    # A struct with configuration for serial port.\n    serial_rs485 = struct.pack('hhhhhhhh', 1, 0, 0, 0, 0, 0, 0, 0)\n    fcntl.ioctl(fh, 0x542F, serial_rs485)\n\n    return port", "response": "Return a serial. Serial instance ready to use for RS485."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_multi_bit_value_format_character(self):\n        self.MULTI_BIT_VALUE_FORMAT_CHARACTER = \\\n            self.MULTI_BIT_VALUE_FORMAT_CHARACTER.upper()\n\n        if self.SIGNED_VALUES:\n            self.MULTI_BIT_VALUE_FORMAT_CHARACTER = \\\n                self.MULTI_BIT_VALUE_FORMAT_CHARACTER.lower()", "response": "Set the format character for multibit values."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a png if needed.", "response": "def png(contents, kvs):\n    \"\"\"Creates a png if needed.\"\"\"\n    outfile = os.path.join(IMAGEDIR, sha(contents + str(kvs['staffsize'])))\n    src = outfile + '.png'\n    if not os.path.isfile(src):\n        try:\n            os.mkdir(IMAGEDIR)\n            stderr.write('Created directory ' + IMAGEDIR + '\\n')\n        except OSError:\n            pass\n        ly2png(contents, outfile, kvs)\n        stderr.write('Created image ' + src + '\\n')\n    return src"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate filename based on content", "response": "def get_filename4code(module, content, ext=None):\n    \"\"\"Generate filename based on content\n\n    The function ensures that the (temporary) directory exists, so that the\n    file can be written.\n\n    Example:\n        filename = get_filename4code(\"myfilter\", code)\n    \"\"\"\n    imagedir = module + \"-images\"\n    fn = hashlib.sha1(content.encode(sys.getfilesystemencoding())).hexdigest()\n    try:\n        os.mkdir(imagedir)\n        sys.stderr.write('Created directory ' + imagedir + '\\n')\n    except OSError:\n        pass\n    if ext:\n        fn += \".\" + ext\n    return os.path.join(imagedir, fn)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting value from the keyvalues", "response": "def get_value(kv, key, value = None):\n    \"\"\"get value from the keyvalues (options)\"\"\"\n    res = []\n    for k, v in kv:\n        if k == key:\n            value = v\n        else:\n            res.append([k, v])\n    return value, res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_caption(kv):\n    caption = []\n    typef = \"\"\n    value, res = get_value(kv, u\"caption\")\n    if value is not None:\n        caption = [Str(value)]\n        typef = \"fig:\"\n\n    return caption, typef, res", "response": "get caption from the keyvalues"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwalk a tree applying an action to every object in x.", "response": "def walk(x, action, format, meta):\n    \"\"\"Walk a tree, applying an action to every object.\n    Returns a modified tree.  An action is a function of the form\n    `action(key, value, format, meta)`, where:\n\n    * `key` is the type of the pandoc object (e.g. 'Str', 'Para') `value` is\n    * the contents of the object (e.g. a string for 'Str', a list of\n      inline elements for 'Para')\n    * `format` is the target output format (as supplied by the\n      `format` argument of `walk`)\n    * `meta` is the document's metadata\n\n    The return of an action is either:\n\n    * `None`: this means that the object should remain unchanged\n    * a pandoc object: this will replace the original object\n    * a list of pandoc objects: these will replace the original object; the\n      list is merged with the neighbors of the orignal objects (spliced into\n      the list the original object belongs to); returning an empty list deletes\n      the object\n    \"\"\"\n    if isinstance(x, list):\n        array = []\n        for item in x:\n            if isinstance(item, dict) and 't' in item:\n                res = action(item['t'],\n                             item['c'] if 'c' in item else None, format, meta)\n                if res is None:\n                    array.append(walk(item, action, format, meta))\n                elif isinstance(res, list):\n                    for z in res:\n                        array.append(walk(z, action, format, meta))\n                else:\n                    array.append(walk(res, action, format, meta))\n            else:\n                array.append(walk(item, action, format, meta))\n        return array\n    elif isinstance(x, dict):\n        for k in x:\n            x[k] = walk(x[k], action, format, meta)\n        return x\n    else:\n        return x"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating a JSON - to - JSON filter from stdin to stdout.", "response": "def toJSONFilters(actions):\n    \"\"\"Generate a JSON-to-JSON filter from stdin to stdout\n\n    The filter:\n\n    * reads a JSON-formatted pandoc document from stdin\n    * transforms it by walking the tree and performing the actions\n    * returns a new JSON-formatted pandoc document to stdout\n\n    The argument `actions` is a list of functions of the form\n    `action(key, value, format, meta)`, as described in more\n    detail under `walk`.\n\n    This function calls `applyJSONFilters`, with the `format`\n    argument provided by the first command-line argument,\n    if present.  (Pandoc sets this by default when calling\n    filters.)\n    \"\"\"\n    try:\n        input_stream = io.TextIOWrapper(sys.stdin.buffer, encoding='utf-8')\n    except AttributeError:\n        # Python 2 does not have sys.stdin.buffer.\n        # REF: https://stackoverflow.com/questions/2467928/python-unicodeencode\n        input_stream = codecs.getreader(\"utf-8\")(sys.stdin)\n\n    source = input_stream.read()\n    if len(sys.argv) > 1:\n        format = sys.argv[1]\n    else:\n        format = \"\"\n\n    sys.stdout.write(applyJSONFilters(actions, source, format))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwalk through the JSON structure and apply filters to the pandoc document.", "response": "def applyJSONFilters(actions, source, format=\"\"):\n    \"\"\"Walk through JSON structure and apply filters\n\n    This:\n\n    * reads a JSON-formatted pandoc document from a source string\n    * transforms it by walking the tree and performing the actions\n    * returns a new JSON-formatted pandoc document as a string\n\n    The `actions` argument is a list of functions (see `walk`\n    for a full description).\n\n    The argument `source` is a string encoded JSON object.\n\n    The argument `format` is a string describing the output format.\n\n    Returns a the new JSON-formatted pandoc document.\n    \"\"\"\n\n    doc = json.loads(source)\n\n    if 'meta' in doc:\n        meta = doc['meta']\n    elif doc[0]:  # old API\n        meta = doc[0]['unMeta']\n    else:\n        meta = {}\n    altered = doc\n    for action in actions:\n        altered = walk(altered, action, format, meta)\n\n    return json.dumps(altered)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a string representation of the tree x.", "response": "def stringify(x):\n    \"\"\"Walks the tree x and returns concatenated string content,\n    leaving out all formatting.\n    \"\"\"\n    result = []\n\n    def go(key, val, format, meta):\n        if key in ['Str', 'MetaString']:\n            result.append(val)\n        elif key == 'Code':\n            result.append(val[1])\n        elif key == 'Math':\n            result.append(val[1])\n        elif key == 'LineBreak':\n            result.append(\" \")\n        elif key == 'SoftBreak':\n            result.append(\" \")\n        elif key == 'Space':\n            result.append(\" \")\n\n    walk(x, go, \"\", {})\n    return ''.join(result)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef attributes(attrs):\n    attrs = attrs or {}\n    ident = attrs.get(\"id\", \"\")\n    classes = attrs.get(\"classes\", [])\n    keyvals = [[x, attrs[x]] for x in attrs if (x != \"classes\" and x != \"id\")]\n    return [ident, classes, keyvals]", "response": "Returns an attribute list constructed from the\n    dictionary attrs."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a LaTeX snippet for the given code.", "response": "def latexsnippet(code, kvs, staffsize=17, initiallines=1):\n    \"\"\"Take in account key/values\"\"\"\n    snippet = ''\n    staffsize = int(kvs['staffsize']) if 'staffsize' in kvs \\\n        else staffsize\n    initiallines = int(kvs['initiallines']) if 'initiallines' in kvs \\\n        else initiallines\n    annotationsize = .5 * staffsize\n    if 'mode' in kvs:\n        snippet = (\n            \"\\\\greannotation{{\\\\fontsize{%s}{%s}\\\\selectfont{}%s}}\\n\" %\n            (annotationsize, annotationsize, kvs['mode'])\n        ) + snippet\n    if 'annotation' in kvs:\n        snippet = (\n            \"\\\\grechangedim{annotationseparation}{%s mm}{fixed}\\n\"\n            \"\\\\greannotation{{\\\\fontsize{%s}{%s}\\\\selectfont{}%s}}\\n\" %\n            (staffsize / 60, annotationsize, annotationsize, kvs['annotation'])\n        ) + snippet\n    snippet = (\n        \"\\\\gresetinitiallines{%s}\\n\" % initiallines +\n        \"\\\\grechangestaffsize{%s}\\n\" % staffsize +\n        \"\\\\grechangestyle{initial}{\\\\fontsize{%s}{%s}\\\\selectfont{}}\" %\n        (2.5 * staffsize, 2.5 * staffsize)\n    ) + snippet\n    snippet = \"\\\\setlength{\\\\parskip}{0pt}\\n\" + snippet + code\n    return snippet"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef latex2png(snippet, outfile):\n    pngimage = os.path.join(IMAGEDIR, outfile + '.png')\n    texdocument = os.path.join(IMAGEDIR, 'tmp.tex')\n    with open(texdocument, 'w') as doc:\n        doc.write(LATEX_DOC % (snippet))\n    environment = os.environ\n    environment['shell_escape_commands'] = \\\n        \"bibtex,bibtex8,kpsewhich,makeindex,mpost,repstopdf,\" + \\\n        ','.join(\n            os.path.basename(n) for n in chain.from_iterable(\n                iglob(os.path.join(chemin, 'gregorio*'))\n                for chemin in os.environ[\"PATH\"].split(os.pathsep)\n            )\n        )\n    proc = Popen(\n        [\"lualatex\", '-output-directory=' + IMAGEDIR, texdocument],\n        stdin=PIPE,\n        stdout=STDERR,\n        env=environment\n    )\n    proc.communicate()\n    proc.stdin.close()\n    call([\"pdfcrop\", os.path.join(IMAGEDIR, \"tmp.pdf\")], stdout=STDERR)\n    call(\n        [\n            \"gs\",\n            \"-sDEVICE=pngalpha\",\n            \"-r144\",\n            \"-sOutputFile=\" + pngimage,\n            os.path.join(IMAGEDIR, \"tmp-crop.pdf\"),\n        ],\n        stdout=STDERR,\n    )", "response": "Compiles a LaTeX snippet to png"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef png(contents, latex_command):\n    outfile = sha(contents + latex_command)\n    src = os.path.join(IMAGEDIR, outfile + '.png')\n    if not os.path.isfile(src):\n        try:\n            os.mkdir(IMAGEDIR)\n            stderr.write('Created directory ' + IMAGEDIR + '\\n')\n        except OSError:\n            pass\n        latex2png(latex_command + \"{\" + contents + \"}\", outfile)\n        stderr.write('Created image ' + src + '\\n')\n    return src", "response": "Creates a png if needed."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the list of jokes in a language.", "response": "def get_jokes(language='en', category='neutral'):\n    \"\"\"\n    Parameters\n    ----------\n    category: str\n        Choices: 'neutral', 'chuck', 'all', 'twister'\n    lang: str\n        Choices: 'en', 'de', 'es', 'gl', 'eu', 'it'\n\n    Returns\n    -------\n    jokes: list\n    \"\"\"\n\n    if language not in all_jokes:\n        raise LanguageNotFoundError('No such language %s' % language)\n\n    jokes = all_jokes[language]\n\n    if category not in jokes:\n        raise CategoryNotFoundError('No such category %s in language %s' % (category, language))\n\n    return jokes[category]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a random joke from the available languages.", "response": "def get_joke(language='en', category='neutral'):\n    \"\"\"\n    Parameters\n    ----------\n    category: str\n        Choices: 'neutral', 'chuck', 'all', 'twister'\n    lang: str\n        Choices: 'en', 'de', 'es', 'gl', 'eu', 'it'\n\n    Returns\n    -------\n    joke: str\n    \"\"\"\n\n    jokes = get_jokes(language, category)\n    return random.choice(jokes)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _capture_original_object(self):\n        try:\n            self._doubles_target = getattr(self.target, self._name)\n        except AttributeError:\n            raise VerifyingDoubleError(self.target, self._name)", "response": "Capture the original python object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_value(self, value):\n        self._value = value\n        setattr(self.target, self._name, value)", "response": "Set the value of the attribute in the target object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef patch_class(input_class):\n    class Instantiator(object):\n        @classmethod\n        def _doubles__new__(self, *args, **kwargs):\n            pass\n\n    new_class = type(input_class.__name__, (input_class, Instantiator), {})\n\n    return new_class", "response": "Create a new class based on the input_class."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef clear(*objects_to_clear):\n    if not hasattr(_thread_local_data, 'current_space'):\n        return\n\n    space = current_space()\n    for obj in objects_to_clear:\n        space.clear(obj)", "response": "Clears allowances and expectations on objects_to_clear"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef satisfy_any_args_match(self):\n\n        is_match = super(Expectation, self).satisfy_any_args_match()\n\n        if is_match:\n            self._satisfy()\n\n        return is_match", "response": "Returns a boolean indicating whether or not the mock accepts arbitrary arguments."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a boolean indicating whether or not the mock will accept the provided arguments.", "response": "def satisfy_exact_match(self, args, kwargs):\n        \"\"\"\n        Returns a boolean indicating whether or not the mock will accept the provided arguments.\n\n        :return: Whether or not the mock accepts the provided arguments.\n        :rtype: bool\n        \"\"\"\n\n        is_match = super(Expectation, self).satisfy_exact_match(args, kwargs)\n\n        if is_match:\n            self._satisfy()\n\n        return is_match"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef satisfy_custom_matcher(self, args, kwargs):\n\n        is_match = super(Expectation, self).satisfy_custom_matcher(args, kwargs)\n\n        if is_match:\n            self._satisfy()\n\n        return is_match", "response": "Returns a boolean indicating whether or not the mock will accept the provided arguments."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_satisfied(self):\n\n        return self._call_counter.has_correct_call_count() and (\n            self._call_counter.never() or self._is_satisfied)", "response": "Returns a boolean indicating whether or not the double has been satisfied."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntests if there have been too many calls in the current instance.", "response": "def has_too_many_calls(self):\n        \"\"\"Test if there have been too many calls\n\n        :rtype boolean\n        \"\"\"\n\n        if self.has_exact and self._call_count > self._exact:\n            return True\n        if self.has_maximum and self._call_count > self._maximum:\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef has_too_few_calls(self):\n\n        if self.has_exact and self._call_count < self._exact:\n            return True\n        if self.has_minimum and self._call_count < self._minimum:\n            return True\n        return False", "response": "Test if there have not been enough calls to the class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _restriction_string(self):\n\n        if self.has_minimum:\n            string = 'at least '\n            value = self._minimum\n        elif self.has_maximum:\n            string = 'at most '\n            value = self._maximum\n        elif self.has_exact:\n            string = ''\n            value = self._exact\n\n        return (string + '{} {}').format(\n            value,\n            pluralize('time', value)\n        )", "response": "Get a string explaining the currently set\n            e. g at least 5 times or 2 times or an exact value."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a well formed error message for the current exception.", "response": "def error_string(self):\n        \"\"\"Returns a well formed error message\n\n        e.g at least 5 times but was called 4 times\n\n        :rtype string\n        \"\"\"\n\n        if self.has_correct_call_count():\n            return ''\n\n        return '{} instead of {} {} '.format(\n            self._restriction_string(),\n            self.count,\n            pluralize('time', self.count)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the Patch object for the given absolute module path.", "response": "def patch_for(self, path):\n        \"\"\"Returns the ``Patch`` for the target path, creating it if necessary.\n\n        :param str path: The absolute module path to the target.\n        :return: The mapped ``Patch``.\n        :rtype: Patch\n        \"\"\"\n\n        if path not in self._patches:\n            self._patches[path] = Patch(path)\n\n        return self._patches[path]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the Proxy object for the target object creating it if necessary.", "response": "def proxy_for(self, obj):\n        \"\"\"Returns the ``Proxy`` for the target object, creating it if necessary.\n\n        :param object obj: The object that will be doubled.\n        :return: The mapped ``Proxy``.\n        :rtype: Proxy\n        \"\"\"\n\n        obj_id = id(obj)\n\n        if obj_id not in self._proxies:\n            self._proxies[obj_id] = Proxy(obj)\n\n        return self._proxies[obj_id]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef teardown(self):\n\n        for proxy in self._proxies.values():\n            proxy.restore_original_object()\n\n        for patch in self._patches.values():\n            patch.restore_original_object()", "response": "Restores all doubled objects to their original state."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clear(self, obj):\n        self.proxy_for(obj).restore_original_object()\n        del self._proxies[id(obj)]", "response": "Clears allowances and expectations set on an object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef verify(self):\n\n        if self._is_verified:\n            return\n\n        for proxy in self._proxies.values():\n            proxy.verify()\n\n        self._is_verified = True", "response": "Verifies expectations on all doubled objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef restore_original_method(self):\n\n        if self._target.is_class_or_module():\n            setattr(self._target.obj, self._method_name, self._original_method)\n            if self._method_name == '__new__' and sys.version_info >= (3, 0):\n                _restore__new__(self._target.obj, self._original_method)\n            else:\n                setattr(self._target.obj, self._method_name, self._original_method)\n        elif self._attr.kind == 'property':\n            setattr(self._target.obj.__class__, self._method_name, self._original_method)\n            del self._target.obj.__dict__[double_name(self._method_name)]\n        elif self._attr.kind == 'attribute':\n            self._target.obj.__dict__[self._method_name] = self._original_method\n        else:\n            # TODO: Could there ever have been a value here that needs to be restored?\n            del self._target.obj.__dict__[self._method_name]\n\n        if self._method_name in ['__call__', '__enter__', '__exit__']:\n            self._target.restore_attr(self._method_name)", "response": "Replaces the proxy method on the target object with its original value."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreplacing the target method on the target object with the proxy method.", "response": "def _hijack_target(self):\n        \"\"\"Replaces the target method on the target object with the proxy method.\"\"\"\n\n        if self._target.is_class_or_module():\n            setattr(self._target.obj, self._method_name, self)\n        elif self._attr.kind == 'property':\n            proxy_property = ProxyProperty(\n                double_name(self._method_name),\n                self._original_method,\n            )\n            setattr(self._target.obj.__class__, self._method_name, proxy_property)\n            self._target.obj.__dict__[double_name(self._method_name)] = self\n        else:\n            self._target.obj.__dict__[self._method_name] = self\n\n        if self._method_name in ['__call__', '__enter__', '__exit__']:\n            self._target.hijack_attr(self._method_name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nraise an exception with a useful message.", "response": "def _raise_exception(self, args, kwargs):\n        \"\"\" Raises an ``UnallowedMethodCallError`` with a useful message.\n\n        :raise: ``UnallowedMethodCallError``\n        \"\"\"\n\n        error_message = (\n            \"Received unexpected call to '{}' on {!r}.  The supplied arguments \"\n            \"{} do not match any available allowances.\"\n        )\n\n        raise UnallowedMethodCallError(\n            error_message.format(\n                self._method_name,\n                self._target.obj,\n                build_argument_repr_string(args, kwargs)\n            )\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef method_double_for(self, method_name):\n\n        if method_name not in self._method_doubles:\n            self._method_doubles[method_name] = MethodDouble(method_name, self._target)\n\n        return self._method_doubles[method_name]", "response": "Returns the method double for the provided method name creating one if necessary."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_doubles_target(module, class_name, path):\n\n    try:\n        doubles_target = getattr(module, class_name)\n        if isinstance(doubles_target, ObjectDouble):\n            return doubles_target._doubles_target\n\n        if not isclass(doubles_target):\n            raise VerifyingDoubleImportError(\n                'Path does not point to a class: {}.'.format(path)\n            )\n\n        return doubles_target\n    except AttributeError:\n        raise VerifyingDoubleImportError(\n            'No object at path: {}.'.format(path)\n        )", "response": "Validate and return the class that will be doubled."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncauses the double to raise the provided exception when called. If provided, additional arguments (positional and keyword) passed to `and_raise` are used in the exception instantiation. :param Exception exception: The exception to raise.", "response": "def and_raise(self, exception, *args, **kwargs):\n        \"\"\"Causes the double to raise the provided exception when called.\n\n        If provided, additional arguments (positional and keyword) passed to\n        `and_raise` are used in the exception instantiation.\n\n        :param Exception exception: The exception to raise.\n        \"\"\"\n        def proxy_exception(*proxy_args, **proxy_kwargs):\n            raise exception\n\n        self._return_value = proxy_exception\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef and_return_future(self, *return_values):\n        futures = []\n        for value in return_values:\n            future = _get_future()\n            future.set_result(value)\n            futures.append(future)\n        return self.and_return(*futures)", "response": "Similar to and_return but returns a future."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef and_return(self, *return_values):\n\n        if not return_values:\n            raise TypeError('and_return() expected at least 1 return value')\n\n        return_values = list(return_values)\n        final_value = return_values.pop()\n\n        self.and_return_result_of(\n            lambda: return_values.pop(0) if return_values else final_value\n        )\n        return self", "response": "Set a return value for an allowance\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncause the double to return the result of calling the provided value.", "response": "def and_return_result_of(self, return_value):\n        \"\"\" Causes the double to return the result of calling the provided value.\n\n        :param return_value: A callable that will be invoked to determine the double's return value.\n        :type return_value: any callable object\n        \"\"\"\n        if not check_func_takes_args(return_value):\n            self._return_value = lambda *args, **kwargs: return_value()\n        else:\n            self._return_value = return_value\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef with_args(self, *args, **kwargs):\n\n        self.args = args\n        self.kwargs = kwargs\n        self.verify_arguments()\n        return self", "response": "Declares that the double can only be called with the provided arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndefines a custom function for testing arguments", "response": "def with_args_validator(self, matching_function):\n        \"\"\"Define a custom function for testing arguments\n\n        :param func matching_function:  The function used to test arguments passed to the stub.\n        \"\"\"\n        self.args = None\n        self.kwargs = None\n        self._custom_matcher = matching_function\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a boolean indicating whether or not the stub will accept the provided arguments.", "response": "def satisfy_exact_match(self, args, kwargs):\n        \"\"\"Returns a boolean indicating whether or not the stub will accept the provided arguments.\n\n        :return: Whether or not the stub accepts the provided arguments.\n        :rtype: bool\n        \"\"\"\n\n        if self.args is None and self.kwargs is None:\n            return False\n        elif self.args is _any and self.kwargs is _any:\n            return True\n        elif args == self.args and kwargs == self.kwargs:\n            return True\n        elif len(args) != len(self.args) or len(kwargs) != len(self.kwargs):\n            return False\n\n        if not all(x == y or y == x for x, y in zip(args, self.args)):\n            return False\n\n        for key, value in self.kwargs.items():\n            if key not in kwargs:\n                return False\n            elif not (kwargs[key] == value or value == kwargs[key]):\n                return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef satisfy_custom_matcher(self, args, kwargs):\n        if not self._custom_matcher:\n            return False\n        try:\n            return self._custom_matcher(*args, **kwargs)\n        except Exception:\n            return False", "response": "Returns a boolean indicating if the stub accepts the provided arguments."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract the real value to be returned from the wrapping callable.", "response": "def return_value(self, *args, **kwargs):\n        \"\"\"Extracts the real value to be returned from the wrapping callable.\n\n        :return: The value the double should return when called.\n        \"\"\"\n\n        self._called()\n        return self._return_value(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nensures that the arguments specified match the signature of the real method.", "response": "def verify_arguments(self, args=None, kwargs=None):\n        \"\"\"Ensures that the arguments specified match the signature of the real method.\n\n        :raise: ``VerifyingDoubleError`` if the arguments do not match.\n        \"\"\"\n\n        args = self.args if args is None else args\n        kwargs = self.kwargs if kwargs is None else kwargs\n\n        try:\n            verify_arguments(self._target, self._method_name, args, kwargs)\n        except VerifyingBuiltinDoubleArgumentError:\n            if doubles.lifecycle.ignore_builtin_verification():\n                raise"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef raise_failure_exception(self, expect_or_allow='Allowed'):\n\n        raise MockExpectationError(\n            \"{} '{}' to be called {}on {!r} with {}, but was not. ({}:{})\".format(\n                expect_or_allow,\n                self._method_name,\n                self._call_counter.error_string(),\n                self._target.obj,\n                self._expected_argument_string(),\n                self._caller.filename,\n                self._caller.lineno,\n            )\n        )", "response": "Raises a MockExpectationError with a useful message."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating a string describing what arguments the double expected.", "response": "def _expected_argument_string(self):\n        \"\"\"Generates a string describing what arguments the double expected.\n\n        :return: A string describing expected arguments.\n        :rtype: str\n        \"\"\"\n\n        if self.args is _any and self.kwargs is _any:\n            return 'any args'\n        elif self._custom_matcher:\n            return \"custom matcher: '{}'\".format(self._custom_matcher.__name__)\n        else:\n            return build_argument_repr_string(self.args, self.kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndetermines if the object is a class or a module.", "response": "def is_class_or_module(self):\n        \"\"\"Determines if the object is a class or a module\n\n        :return: True if the object is a class or a module, False otherwise.\n        :rtype: bool\n        \"\"\"\n\n        if isinstance(self.obj, ObjectDouble):\n            return self.obj.is_class\n\n        return isclass(self.doubled_obj) or ismodule(self.doubled_obj)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the target object.", "response": "def _determine_doubled_obj(self):\n        \"\"\"Return the target object.\n\n        Returns the object that should be treated as the target object. For partial doubles, this\n        will be the same as ``self.obj``, but for pure doubles, it's pulled from the special\n        ``_doubles_target`` attribute.\n\n        :return: The object to be doubled.\n        :rtype: object\n        \"\"\"\n\n        if isinstance(self.obj, ObjectDouble):\n            return self.obj._doubles_target\n        else:\n            return self.obj"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the type of the target object.", "response": "def _determine_doubled_obj_type(self):\n        \"\"\"Returns the type (class) of the target object.\n\n        :return: The type (class) of the target.\n        :rtype: type, classobj\n        \"\"\"\n\n        if isclass(self.doubled_obj) or ismodule(self.doubled_obj):\n            return self.doubled_obj\n\n        return self.doubled_obj.__class__"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _generate_attrs(self):\n        attrs = {}\n\n        if ismodule(self.doubled_obj):\n            for name, func in getmembers(self.doubled_obj, is_callable):\n                attrs[name] = Attribute(func, 'toplevel', self.doubled_obj)\n        else:\n            for attr in classify_class_attrs(self.doubled_obj_type):\n                attrs[attr.name] = attr\n\n        return attrs", "response": "Generate the attributes dict for the target object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef hijack_attr(self, attr_name):\n        if not self._original_attr(attr_name):\n            setattr(\n                self.obj.__class__,\n                attr_name,\n                _proxy_class_method_to_instance(\n                    getattr(self.obj.__class__, attr_name, None), attr_name\n                ),\n            )", "response": "Hijack an attribute on the target object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrestore an attribute back onto the target object.", "response": "def restore_attr(self, attr_name):\n        \"\"\"Restore an attribute back onto the target object.\n\n        :param str attr_name: the name of the attribute to restore\n        \"\"\"\n        original_attr = self._original_attr(attr_name)\n        if self._original_attr(attr_name):\n            setattr(self.obj.__class__, attr_name, original_attr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _original_attr(self, attr_name):\n        try:\n            return getattr(\n                getattr(self.obj.__class__, attr_name), '_doubles_target_method', None\n            )\n        except AttributeError:\n            return None", "response": "Return the original attribute off of the proxy on the target object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_callable_attr(self, attr_name):\n\n        if not hasattr(self.doubled_obj, attr_name):\n            return None\n\n        func = getattr(self.doubled_obj, attr_name)\n        if not is_callable(func):\n            return None\n\n        attr = Attribute(\n            func,\n            'attribute',\n            self.doubled_obj if self.is_class_or_module() else self.doubled_obj_type,\n        )\n        self.attrs[attr_name] = attr\n        return attr", "response": "Used to double methods added to an object after creation."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_attr(self, method_name):\n        return self.attrs.get(method_name) or self.get_callable_attr(method_name)", "response": "Get the attribute from the target object"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a new allowance for the method.", "response": "def add_allowance(self, caller):\n        \"\"\"Adds a new allowance for the method.\n\n        :param: tuple caller: A tuple indicating where the method was called\n        :return: The new ``Allowance``.\n        :rtype: Allowance\n        \"\"\"\n\n        allowance = Allowance(self._target, self._method_name, caller)\n        self._allowances.insert(0, allowance)\n        return allowance"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a new expectation for the method.", "response": "def add_expectation(self, caller):\n        \"\"\"Adds a new expectation for the method.\n\n        :return: The new ``Expectation``.\n        :rtype: Expectation\n        \"\"\"\n\n        expectation = Expectation(self._target, self._method_name, caller)\n        self._expectations.insert(0, expectation)\n        return expectation"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the first allowance that matches the ones declared in the given arguments.", "response": "def _find_matching_allowance(self, args, kwargs):\n        \"\"\"Return a matching allowance.\n\n        Returns the first allowance that matches the ones declared. Tries one with specific\n        arguments first, then falls back to an allowance that allows arbitrary arguments.\n\n        :return: The matching ``Allowance``, if one was found.\n        :rtype: Allowance, None\n        \"\"\"\n\n        for allowance in self._allowances:\n            if allowance.satisfy_exact_match(args, kwargs):\n                return allowance\n\n        for allowance in self._allowances:\n            if allowance.satisfy_custom_matcher(args, kwargs):\n                return allowance\n\n        for allowance in self._allowances:\n            if allowance.satisfy_any_args_match():\n                return allowance"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the first matching expectation or allowance that matches the ones declared in the given arguments.", "response": "def _find_matching_double(self, args, kwargs):\n        \"\"\"Returns the first matching expectation or allowance.\n\n        Returns the first allowance or expectation that matches the ones declared. Tries one\n        with specific arguments first, then falls back to an expectation that allows arbitrary\n        arguments.\n\n        :return: The matching ``Allowance`` or ``Expectation``, if one was found.\n        :rtype: Allowance, Expectation, None\n        \"\"\"\n\n        expectation = self._find_matching_expectation(args, kwargs)\n\n        if expectation:\n            return expectation\n\n        allowance = self._find_matching_allowance(args, kwargs)\n\n        if allowance:\n            return allowance"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the first expectation that matches the ones declared in the given arguments.", "response": "def _find_matching_expectation(self, args, kwargs):\n        \"\"\"Return a matching expectation.\n\n        Returns the first expectation that matches the ones declared. Tries one with specific\n        arguments first, then falls back to an expectation that allows arbitrary arguments.\n\n        :return: The matching ``Expectation``, if one was found.\n        :rtype: Expectation, None\n        \"\"\"\n\n        for expectation in self._expectations:\n            if expectation.satisfy_exact_match(args, kwargs):\n                return expectation\n\n        for expectation in self._expectations:\n            if expectation.satisfy_custom_matcher(args, kwargs):\n                return expectation\n\n        for expectation in self._expectations:\n            if expectation.satisfy_any_args_match():\n                return expectation"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _verify_method(self):\n\n        class_level = self._target.is_class_or_module()\n\n        verify_method(self._target, self._method_name, class_level=class_level)", "response": "Verify that a method is doubled."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef verify_method(target, method_name, class_level=False):\n\n    attr = target.get_attr(method_name)\n\n    if not attr:\n        raise VerifyingDoubleError(method_name, target.doubled_obj).no_matching_method()\n\n    if attr.kind == 'data' and not isbuiltin(attr.object) and not is_callable(attr.object):\n        raise VerifyingDoubleError(method_name, target.doubled_obj).not_callable()\n\n    if class_level and attr.kind == 'method' and method_name != '__new__':\n        raise VerifyingDoubleError(method_name, target.doubled_obj).requires_instance()", "response": "Verifies that the method exists on the target object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef verify_arguments(target, method_name, args, kwargs):\n\n    if method_name == '_doubles__new__':\n        return _verify_arguments_of_doubles__new__(target, args, kwargs)\n\n    attr = target.get_attr(method_name)\n    method = attr.object\n\n    if attr.kind in ('data', 'attribute', 'toplevel', 'class method', 'static method'):\n        try:\n            method = method.__get__(None, attr.defining_class)\n        except AttributeError:\n            method = method.__call__\n    elif attr.kind == 'property':\n        if args or kwargs:\n            raise VerifyingDoubleArgumentError(\"Properties do not accept arguments.\")\n        return\n    else:\n        args = ['self_or_cls'] + list(args)\n\n    _verify_arguments(method, method_name, args, kwargs)", "response": "Verifies that the provided arguments match the signature of the provided method."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nallow a new class double to be created.", "response": "def allow_constructor(target):\n    \"\"\"\n    Set an allowance on a ``ClassDouble`` constructor\n\n    This allows the caller to control what a ClassDouble returns when a new instance is created.\n\n    :param ClassDouble target:  The ClassDouble to set the allowance on.\n    :return: an ``Allowance`` for the __new__ method.\n    :raise: ``ConstructorDoubleError`` if target is not a ClassDouble.\n    \"\"\"\n    if not isinstance(target, ClassDouble):\n        raise ConstructorDoubleError(\n            'Cannot allow_constructor of {} since it is not a ClassDouble.'.format(target),\n        )\n\n    return allow(target)._doubles__new__"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreplacing the specified object with the specified value.", "response": "def patch(target, value):\n    \"\"\"\n    Replace the specified object\n\n    :param str target: A string pointing to the target to patch.\n    :param object value: The value to replace the target with.\n    :return: A ``Patch`` object.\n    \"\"\"\n    patch = current_space().patch_for(target)\n    patch.set_value(value)\n    return patch"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_path_components(path):\n\n    path_segments = path.split('.')\n    module_path = '.'.join(path_segments[:-1])\n\n    if module_path == '':\n        raise VerifyingDoubleImportError('Invalid import path: {}.'.format(path))\n\n    class_name = path_segments[-1]\n\n    return module_path, class_name", "response": "Extract the module name and class name out of the fully qualified path to the class."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset an expectation on a ClassDouble constructor.", "response": "def expect_constructor(target):\n    \"\"\"\n    Set an expectation on a ``ClassDouble`` constructor\n\n    :param ClassDouble target:  The ClassDouble to set the expectation on.\n    :return: an ``Expectation`` for the __new__ method.\n    :raise: ``ConstructorDoubleError`` if target is not a ClassDouble.\n    \"\"\"\n    if not isinstance(target, ClassDouble):\n        raise ConstructorDoubleError(\n            'Cannot allow_constructor of {} since it is not a ClassDouble.'.format(target),\n        )\n\n    return expect(target)._doubles__new__"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite the table of values for the current locale.", "response": "def write_table(self):\n        \"\"\"\n        |write_table| with\n        `Labeled Tab-separated Values (LTSV) <http://ltsv.org/>`__ format.\n        Invalid characters in labels/data are removed.\n\n        :raises pytablewriter.EmptyHeaderError: If the |headers| is empty.\n        :Example:\n            :ref:`example-ltsv-table-writer`\n        \"\"\"\n\n        with self._logger:\n            self._verify_property()\n            self._preprocess()\n\n            for values in self._table_value_matrix:\n                ltsv_item_list = [\n                    \"{:s}:{}\".format(pathvalidate.sanitize_ltsv_label(header_name), value)\n                    for header_name, value in zip(self.headers, values)\n                    if typepy.is_not_null_string(value)\n                ]\n\n                if typepy.is_empty_sequence(ltsv_item_list):\n                    continue\n\n                self._write_line(\"\\t\".join(ltsv_item_list))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_table(self):\n\n        import toml\n\n        with self._logger:\n            self._verify_property()\n            self.stream.write(toml.dumps(self.tabledata.as_dict()))", "response": "Write the table to the output stream."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting the table of items in the current locale.", "response": "def write_table(self):\n        \"\"\"\n        |write_table| with Markdown table format.\n\n        :raises pytablewriter.EmptyHeaderError: If the |headers| is empty.\n        :Example:\n            :ref:`example-markdown-table-writer`\n\n        .. note::\n            - |None| values are written as an empty string\n            - Vertical bar characters (``'|'``) in table items are escaped\n        \"\"\"\n\n        with self._logger:\n            self._verify_property()\n            self.__write_chapter()\n            self._write_table()\n            if self.is_write_null_line_after_table:\n                self.write_null_line()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nvalidates the Excel sheet name.", "response": "def validate_excel_sheet_name(sheet_name):\n    \"\"\"\n    :param str sheet_name: Excel sheet name to validate.\n    :raises pathvalidate.NullNameError: If the ``sheet_name`` is empty.\n    :raises pathvalidate.InvalidCharError:\n        If the ``sheet_name`` includes invalid char(s):\n        |invalid_excel_sheet_chars|.\n    :raises pathvalidate.InvalidLengthError:\n        If the ``sheet_name`` is longer than 31 characters.\n    \"\"\"\n\n    validate_null_string(sheet_name)\n\n    if len(sheet_name) > __MAX_SHEET_NAME_LEN:\n        raise InvalidLengthError(\n            \"sheet name is too long: expected<={:d}, actual={:d}\".format(\n                __MAX_SHEET_NAME_LEN, len(sheet_name)\n            )\n        )\n\n    unicode_sheet_name = _preprocess(sheet_name)\n    match = __RE_INVALID_EXCEL_SHEET_NAME.search(unicode_sheet_name)\n    if match is not None:\n        raise InvalidCharError(\n            \"invalid char found in the sheet name: '{:s}'\".format(re.escape(match.group()))\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sanitize_excel_sheet_name(sheet_name, replacement_text=\"\"):\n\n    try:\n        unicode_sheet_name = _preprocess(sheet_name)\n    except AttributeError as e:\n        raise ValueError(e)\n\n    modify_sheet_name = __RE_INVALID_EXCEL_SHEET_NAME.sub(replacement_text, unicode_sheet_name)\n\n    return modify_sheet_name[:__MAX_SHEET_NAME_LEN]", "response": "Sanitize an Excel sheet name."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndumps a tabledata. TableData instance to a string.", "response": "def dumps_tabledata(value, format_name=\"rst_grid_table\", **kwargs):\n    \"\"\"\n    :param tabledata.TableData value: Tabular data to dump.\n    :param str format_name:\n        Dumped format name of tabular data.\n        Available formats are described in\n        :py:meth:`~pytablewriter.TableWriterFactory.create_from_format_name`\n\n    :Example:\n        .. code:: python\n\n            >>> dumps_tabledata(value)\n            .. table:: sample_data\n\n                ======  ======  ======\n                attr_a  attr_b  attr_c\n                ======  ======  ======\n                     1     4.0  a\n                     2     2.1  bb\n                     3   120.9  ccc\n                ======  ======  ======\n    \"\"\"\n\n    from ._factory import TableWriterFactory\n\n    if not value:\n        raise TypeError(\"value must be a tabledata.TableData instance\")\n\n    writer = TableWriterFactory.create_from_format_name(format_name)\n\n    for attr_name, attr_value in kwargs.items():\n        setattr(writer, attr_name, attr_value)\n\n    writer.from_tabledata(value)\n\n    return writer.dumps()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites the log entry table.", "response": "def write_table(self):\n        \"\"\"\n        |write_table|.\n\n        .. note::\n            - |None| values are written as an empty string.\n        \"\"\"\n\n        super(TextTableWriter, self).write_table()\n        if self.is_write_null_line_after_table:\n            self.write_null_line()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndumping the current state of the entry to the output file.", "response": "def dump(self, output, close_after_write=True):\n        \"\"\"Write data to the output with tabular format.\n\n        Args:\n            output (file descriptor or str):\n                file descriptor or path to the output file.\n            close_after_write (bool, optional):\n                Close the output after write.\n                Defaults to |True|.\n        \"\"\"\n\n        try:\n            output.write\n            self.stream = output\n        except AttributeError:\n            self.stream = io.open(output, \"w\", encoding=\"utf-8\")\n\n        try:\n            self.write_table()\n        finally:\n            if close_after_write:\n                self.stream.close()\n                self.stream = sys.stdout"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dumps(self):\n\n        old_stream = self.stream\n\n        try:\n            self.stream = six.StringIO()\n            self.write_table()\n            tabular_text = self.stream.getvalue()\n        finally:\n            self.stream = old_stream\n\n        return tabular_text", "response": "Get rendered tabular text from the table data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef open(self, file_path):\n\n        if self.is_opened() and self.workbook.file_path == file_path:\n            self._logger.logger.debug(\"workbook already opened: {}\".format(self.workbook.file_path))\n            return\n\n        self.close()\n        self._open(file_path)", "response": "Open an Excel workbook file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset following attributes from |TableData| and create worksheet named from the table name.", "response": "def from_tabledata(self, value, is_overwrite_table_name=True):\n        \"\"\"\n        Set following attributes from |TableData|\n\n        - :py:attr:`~.table_name`.\n        - :py:attr:`~.headers`.\n        - :py:attr:`~.value_matrix`.\n\n        And create worksheet named from :py:attr:`~.table_name` ABC\n        if not existed yet.\n\n        :param tabledata.TableData value: Input table data.\n        \"\"\"\n\n        super(ExcelTableWriter, self).from_tabledata(value)\n\n        if self.is_opened():\n            self.make_worksheet(self.table_name)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_worksheet(self, sheet_name=None):\n\n        if sheet_name is None:\n            sheet_name = self.table_name\n        if not sheet_name:\n            sheet_name = \"\"\n\n        self._stream = self.workbook.add_worksheet(sheet_name)\n        self._current_data_row = self._first_data_row", "response": "Make a new worksheet to the current workbook."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dump(self, output, close_after_write=True):\n\n        self.open(output)\n        try:\n            self.make_worksheet(self.table_name)\n            self.write_table()\n        finally:\n            if close_after_write:\n                self.close()", "response": "Writes a table to the current workbook."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nopening a SQLite database file.", "response": "def open(self, file_path):\n        \"\"\"\n        Open a SQLite database file.\n\n        :param str file_path: SQLite database file path to open.\n        \"\"\"\n\n        from simplesqlite import SimpleSQLite\n\n        if self.is_opened():\n            if self.stream.database_path == abspath(file_path):\n                self._logger.logger.debug(\n                    \"database already opened: {}\".format(self.stream.database_path)\n                )\n                return\n\n            self.close()\n\n        self._stream = SimpleSQLite(file_path, \"w\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_from_file_extension(cls, file_extension):\n\n        ext = os.path.splitext(file_extension)[1]\n        if typepy.is_null_string(ext):\n            file_extension = file_extension\n        else:\n            file_extension = ext\n\n        file_extension = file_extension.lstrip(\".\").lower()\n\n        for table_format in TableFormat:\n            if file_extension not in table_format.file_extensions:\n                continue\n\n            if table_format.format_attribute & FormatAttr.SECONDARY_EXT:\n                continue\n\n            return table_format.writer_class()\n\n        raise WriterNotFoundError(\n            \"\\n\".join(\n                [\n                    \"{:s} (unknown file extension).\".format(file_extension),\n                    \"\",\n                    \"acceptable file extensions are: {}.\".format(\", \".join(cls.get_extensions())),\n                ]\n            )\n        )", "response": "Create a table writer class instance from a file extension string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_from_format_name(cls, format_name):\n\n        format_name = format_name.lower()\n\n        for table_format in TableFormat:\n            if format_name in table_format.names and not (\n                table_format.format_attribute & FormatAttr.SECONDARY_NAME\n            ):\n                return table_format.writer_class()\n\n        raise WriterNotFoundError(\n            \"\\n\".join(\n                [\n                    \"{} (unknown format name).\".format(format_name),\n                    \"acceptable format names are: {}.\".format(\", \".join(cls.get_format_names())),\n                ]\n            )\n        )", "response": "Create a table writer class instance from a format name."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of available format names.", "response": "def get_format_names(cls):\n        \"\"\"\n        :return: Available format names.\n        :rtype: list\n\n        :Example:\n            .. code:: python\n\n                >>> import pytablewriter as ptw\n                >>> for name in ptw.TableWriterFactory.get_format_names():\n                ...     print(name)\n                ...\n                csv\n                elasticsearch\n                excel\n                htm\n                html\n                javascript\n                js\n                json\n                json_lines\n                jsonl\n                latex_matrix\n                latex_table\n                ldjson\n                ltsv\n                markdown\n                md\n                mediawiki\n                ndjson\n                null\n                numpy\n                pandas\n                py\n                python\n                rst\n                rst_csv\n                rst_csv_table\n                rst_grid\n                rst_grid_table\n                rst_simple\n                rst_simple_table\n                space_aligned\n                sqlite\n                toml\n                tsv\n                unicode\n\n        \"\"\"\n\n        format_name_set = set()\n        for table_format in TableFormat:\n            for format_name in table_format.names:\n                format_name_set.add(format_name)\n\n        return sorted(list(format_name_set))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_extensions(cls):\n\n        file_extension_set = set()\n        for table_format in TableFormat:\n            for file_extension in table_format.file_extensions:\n                file_extension_set.add(file_extension)\n\n        return sorted(list(file_extension_set))", "response": "Returns a list of available file extensions."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset |Style| for a specific column.", "response": "def set_style(self, column, style):\n        \"\"\"Set |Style| for a specific column.\n\n        Args:\n            column (|int| or |str|):\n                Column specifier. column index or header name correlated with the column.\n            style (|Style|):\n                Style value to be set to the column.\n\n        Raises:\n            ValueError: If the column specifier is invalid.\n        \"\"\"\n\n        column_idx = None\n\n        while len(self.headers) > len(self.__style_list):\n            self.__style_list.append(None)\n\n        if isinstance(column, six.integer_types):\n            column_idx = column\n        elif isinstance(column, six.string_types):\n            try:\n                column_idx = self.headers.index(column)\n            except ValueError:\n                pass\n\n        if column_idx is not None:\n            self.__style_list[column_idx] = style\n            self.__clear_preprocess()\n            self._dp_extractor.format_flags_list = [\n                _ts_to_flag[self.__get_thousand_separator(col_idx)]\n                for col_idx in range(len(self.__style_list))\n            ]\n            return\n\n        raise ValueError(\"column must be an int or string: actual={}\".format(column))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef close(self):\n\n        if self.stream is None:\n            return\n\n        try:\n            self.stream.isatty()\n\n            if self.stream.name in [\"<stdin>\", \"<stdout>\", \"<stderr>\"]:\n                return\n        except AttributeError:\n            pass\n        except ValueError:\n            # raised when executing an operation to a closed stream\n            pass\n\n        try:\n            from _pytest.compat import CaptureIO\n            from _pytest.capture import EncodedFile\n\n            if isinstance(self.stream, (CaptureIO, EncodedFile)):\n                # avoid closing streams for pytest\n                return\n        except ImportError:\n            pass\n\n        try:\n            from ipykernel.iostream import OutStream\n\n            if isinstance(self.stream, OutStream):\n                # avoid closing streams for Jupyter Notebook\n                return\n        except ImportError:\n            pass\n\n        try:\n            self.stream.close()\n        except AttributeError:\n            self._logger.logger.warn(\n                \"the stream has no close method implementation: type={}\".format(type(self.stream))\n            )\n        finally:\n            self._stream = None", "response": "Closes the current |stream|."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting tabular attributes to the writer from |TableData|.", "response": "def from_tabledata(self, value, is_overwrite_table_name=True):\n        \"\"\"\n        Set tabular attributes to the writer from |TableData|.\n        Following attributes are configured:\n\n        - :py:attr:`~.table_name`.\n        - :py:attr:`~.headers`.\n        - :py:attr:`~.value_matrix`.\n\n        |TableData| can be created from various data formats by\n        ``pytablereader``. More detailed information can be found in\n        https://pytablereader.rtfd.io/en/latest/\n\n        :param tabledata.TableData value: Input table data.\n        \"\"\"\n\n        self.__clear_preprocess()\n\n        if is_overwrite_table_name:\n            self.table_name = value.table_name\n\n        self.headers = value.headers\n        self.value_matrix = value.rows\n\n        if not value.has_value_dp_matrix:\n            return\n\n        self._table_value_dp_matrix = value.value_dp_matrix\n        self._column_dp_list = self._dp_extractor.to_column_dp_list(\n            self._table_value_dp_matrix, self._column_dp_list\n        )\n        self.__set_type_hints([col_dp.type_class for col_dp in self._column_dp_list])\n\n        self._is_complete_table_dp_preprocess = True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_csv(self, csv_source, delimiter=\",\"):\n\n        import pytablereader as ptr\n\n        loader = ptr.CsvTableTextLoader(csv_source, quoting_flags=self._quoting_flags)\n        loader.delimiter = delimiter\n        try:\n            for table_data in loader.load():\n                self.from_tabledata(table_data, is_overwrite_table_name=False)\n            return\n        except ptr.DataError:\n            pass\n\n        loader = ptr.CsvTableFileLoader(csv_source, quoting_flags=self._quoting_flags)\n        loader.delimiter = delimiter\n        for table_data in loader.load():\n            self.from_tabledata(table_data)", "response": "Reads a CSV file and populates the internal state of this object with the data from it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting tabular attributes to the writer from a pandas. DataFrame object or pickle.", "response": "def from_dataframe(self, dataframe, add_index_column=False):\n        \"\"\"\n        Set tabular attributes to the writer from :py:class:`pandas.DataFrame`.\n        Following attributes are set by the method:\n\n            - :py:attr:`~.headers`\n            - :py:attr:`~.value_matrix`\n            - :py:attr:`~.type_hints`\n\n        Args:\n            dataframe(pandas.DataFrame or |str|):\n                Input pandas.DataFrame object or pickle.\n            add_index_column(bool, optional):\n                If |True|, add a column of ``index`` of the ``dataframe``.\n                Defaults to |False|.\n\n        Example:\n            :ref:`example-from-pandas-dataframe`\n        \"\"\"\n\n        if typepy.String(dataframe).is_type():\n            import pandas as pd\n\n            dataframe = pd.read_pickle(dataframe)\n\n        self.headers = list(dataframe.columns.values)\n        self.type_hints = [self.__get_typehint_from_dtype(dtype) for dtype in dataframe.dtypes]\n\n        if add_index_column:\n            self.headers = [\"\"] + self.headers\n            if self.type_hints:\n                self.type_hints = [None] + self.type_hints\n            self.value_matrix = [\n                [index] + row\n                for index, row in zip(dataframe.index.tolist(), dataframe.values.tolist())\n            ]\n        else:\n            self.value_matrix = dataframe.values.tolist()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninitializing the object from a pandas. Series object.", "response": "def from_series(self, series, add_index_column=True):\n        \"\"\"\n        Set tabular attributes to the writer from :py:class:`pandas.Series`.\n        Following attributes are set by the method:\n\n            - :py:attr:`~.headers`\n            - :py:attr:`~.value_matrix`\n            - :py:attr:`~.type_hints`\n\n        Args:\n            series(pandas.Series):\n                Input pandas.Series object.\n            add_index_column(bool, optional):\n                If |True|, add a column of ``index`` of the ``series``.\n                Defaults to |True|.\n        \"\"\"\n\n        if series.name:\n            self.headers = [series.name]\n        else:\n            self.headers = [\"value\"]\n\n        self.type_hints = [self.__get_typehint_from_dtype(series.dtype)]\n\n        if add_index_column:\n            self.headers = [\"\"] + self.headers\n            if self.type_hints:\n                self.type_hints = [None] + self.type_hints\n            self.value_matrix = [\n                [index] + [value] for index, value in zip(series.index.tolist(), series.tolist())\n            ]\n        else:\n            self.value_matrix = [[value] for value in series.tolist()]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets tabular attributes to the writer from a tablib. Dataset.", "response": "def from_tablib(self, tablib_dataset):\n        \"\"\"\n        Set tabular attributes to the writer from :py:class:`tablib.Dataset`.\n        \"\"\"\n\n        self.headers = tablib_dataset.headers\n        self.value_matrix = [row for row in tablib_dataset]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write_table(self):\n\n        with self._logger:\n            self._verify_property()\n            self._preprocess()\n\n            for values in self._table_value_matrix:\n                self._write_line(json.dumps(values))", "response": "Write the contents of the internal table."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef upgrade(self, name, params=None):\n        # Allow non-namespaced upgrades. (e.g. advanced vs logging:advanced)\n        if ':' not in name:\n            name = '{0}:{1}'.format(self.type, name)\n\n        r = self._h._http_resource(\n            method='PUT',\n            resource=('apps', self.app.name, 'addons', quote(name)),\n            params=params,\n            data=' '   # Server weirdness.\n        )\n        r.raise_for_status()\n        return self.app.addons[name]", "response": "Upgrades an addon to the given tier."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new app.", "response": "def new(self, name=None, stack='cedar', region=None):\n        \"\"\"Creates a new app.\"\"\"\n\n        payload = {}\n\n        if name:\n            payload['app[name]'] = name\n\n        if stack:\n            payload['app[stack]'] = stack\n\n        if region:\n            payload['app[region]'] = region\n\n        r = self._h._http_resource(\n            method='POST',\n            resource=('apps',),\n            data=payload\n        )\n\n        name = json.loads(r.content).get('name')\n        return self._h.apps.get(name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef collaborators(self):\n        return self._h._get_resources(\n            resource=('apps', self.name, 'collaborators'),\n            obj=Collaborator, app=self\n        )", "response": "Returns a list of collaborators for this app."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef domains(self):\n        return self._h._get_resources(\n            resource=('apps', self.name, 'domains'),\n            obj=Domain, app=self\n        )", "response": "The domains for this app."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef releases(self):\n        return self._h._get_resources(\n            resource=('apps', self.name, 'releases'),\n            obj=Release, app=self\n        )", "response": "The releases for this app."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef processes(self):\n        return self._h._get_resources(\n            resource=('apps', self.name, 'ps'),\n            obj=Process, app=self, map=ProcessListResource\n        )", "response": "The processes for this app."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning current info for this app.", "response": "def info(self):\n        \"\"\"Returns current info for this app.\"\"\"\n\n        return self._h._get_resource(\n            resource=('apps', self.name),\n            obj=App,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrolling back the release to the given version.", "response": "def rollback(self, release):\n        \"\"\"Rolls back the release to the given version.\"\"\"\n        r = self._h._http_resource(\n            method='POST',\n            resource=('apps', self.name, 'releases'),\n            data={'rollback': release}\n        )\n        return self.releases[-1]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrename app to given name.", "response": "def rename(self, name):\n        \"\"\"Renames app to given name.\"\"\"\n\n        r = self._h._http_resource(\n            method='PUT',\n            resource=('apps', self.name),\n            data={'app[name]': name}\n        )\n        return r.ok"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntransferring app to given username s account.", "response": "def transfer(self, user):\n        \"\"\"Transfers app to given username's account.\"\"\"\n\n        r = self._h._http_resource(\n            method='PUT',\n            resource=('apps', self.name),\n            data={'app[transfer_owner]': user}\n        )\n        return r.ok"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the requested log.", "response": "def logs(self, num=None, source=None, ps=None, tail=False):\n        \"\"\"Returns the requested log.\"\"\"\n\n        # Bootstrap payload package.\n        payload = {'logplex': 'true'}\n\n        if num:\n            payload['num'] = num\n\n        if source:\n            payload['source'] = source\n\n        if ps:\n            payload['ps'] = ps\n\n        if tail:\n            payload['tail'] = 1\n\n        # Grab the URL of the logplex endpoint.\n        r = self._h._http_resource(\n            method='GET',\n            resource=('apps', self.name, 'logs'),\n            data=payload\n        )\n\n        # Grab the actual logs.\n        r = requests.get(r.content.decode(\"utf-8\"), verify=False, stream=True)\n\n        if not tail:\n            return r.content\n        else:\n            # Return line iterator for tail!\n            return r.iter_lines()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef new(self, command, attach=\"\"):\n        r = self._h._http_resource(\n            method='POST',\n            resource=('apps', self.app.name, 'ps',),\n            data={'attach': attach, 'command': command}\n        )\n\n        r.raise_for_status()\n        return self.app.processes[r.json()['process']]", "response": "Creates a new process with the given command"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef restart(self, all=False):\n\n        if all:\n            data = {'type': self.type}\n\n        else:\n            data = {'ps': self.process}\n\n        r = self._h._http_resource(\n            method='POST',\n            resource=('apps', self.app.name, 'ps', 'restart'),\n            data=data\n        )\n\n        r.raise_for_status()", "response": "Restarts the given process."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nscaling the given process to the given number of dynos.", "response": "def scale(self, quantity):\n        \"\"\"Scales the given process to the given number of dynos.\"\"\"\n\n        r = self._h._http_resource(\n            method='POST',\n            resource=('apps', self.app.name, 'ps', 'scale'),\n            data={'type': self.type, 'qty': quantity}\n        )\n\n        r.raise_for_status()\n\n        try:\n            return self.app.processes[self.type]\n        except KeyError:\n            return ProcessListResource()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_collection(obj):\n\n    col = getattr(obj, '__getitem__', False)\n    val = False if (not col) else True\n\n    if isinstance(obj, basestring):\n        val = False\n\n    return val", "response": "Tests if an object is a collection."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_python(obj,\n    in_dict,\n    str_keys=None,\n    date_keys=None,\n    int_keys=None,\n    object_map=None,\n    bool_keys=None,\n    dict_keys=None,\n    **kwargs):\n    \"\"\"Extends a given object for API Consumption.\n\n    :param obj: Object to extend.\n    :param in_dict: Dict to extract data from.\n    :param string_keys: List of in_dict keys that will be extracted as strings.\n    :param date_keys: List of in_dict keys that will be extrad as datetimes.\n    :param object_map: Dict of {key, obj} map, for nested object results.\n    \"\"\"\n\n    d = dict()\n\n    if str_keys:\n        for in_key in str_keys:\n            d[in_key] = in_dict.get(in_key)\n\n    if date_keys:\n        for in_key in date_keys:\n            in_date = in_dict.get(in_key)\n            try:\n                out_date = parse_datetime(in_date)\n            except TypeError as e:\n                raise e\n                out_date = None\n\n            d[in_key] = out_date\n\n    if int_keys:\n        for in_key in int_keys:\n            if (in_dict is not None) and (in_dict.get(in_key) is not None):\n                d[in_key] = int(in_dict.get(in_key))\n\n    if bool_keys:\n        for in_key in bool_keys:\n            if in_dict.get(in_key) is not None:\n                d[in_key] = bool(in_dict.get(in_key))\n\n    if dict_keys:\n        for in_key in dict_keys:\n            if in_dict.get(in_key) is not None:\n                d[in_key] = dict(in_dict.get(in_key))\n\n    if object_map:\n        for (k, v) in object_map.items():\n            if in_dict.get(k):\n                d[k] = v.new_from_dict(in_dict.get(k))\n\n    obj.__dict__.update(d)\n    obj.__dict__.update(kwargs)\n\n    # Save the dictionary, for write comparisons.\n    # obj._cache = d\n    # obj.__cache = in_dict\n\n    return obj", "response": "Extends a given object for API Consumption."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_api(in_dict, int_keys=None, date_keys=None, bool_keys=None):\n\n    # Cast all int_keys to int()\n    if int_keys:\n        for in_key in int_keys:\n            if (in_key in in_dict) and (in_dict.get(in_key, None) is not None):\n                in_dict[in_key] = int(in_dict[in_key])\n\n    # Cast all date_keys to datetime.isoformat\n    if date_keys:\n        for in_key in date_keys:\n            if (in_key in in_dict) and (in_dict.get(in_key, None) is not None):\n\n                _from = in_dict[in_key]\n\n                if isinstance(_from, basestring):\n                    dtime = parse_datetime(_from)\n\n                elif isinstance(_from, datetime):\n                    dtime = _from\n\n                in_dict[in_key] = dtime.isoformat()\n\n            elif (in_key in in_dict) and in_dict.get(in_key, None) is None:\n                del in_dict[in_key]\n\n    # Remove all Nones\n    for k, v in in_dict.items():\n        if v is None:\n            del in_dict[k]\n\n    return in_dict", "response": "Extends a given object for API Production."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving all SSH keys from a user s system.", "response": "def clear(self):\n        \"\"\"Removes all SSH keys from a user's system.\"\"\"\n\n        r = self._h._http_resource(\n            method='DELETE',\n            resource=('user', 'keys'),\n        )\n\n        return r.ok"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef authenticate(self, api_key):\n        self._api_key = api_key\n\n        # Attach auth to session.\n        self._session.auth = ('', self._api_key)\n\n        return self._verify_api_key()", "response": "Logs user into Heroku with given api_key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _http_resource(self, method, resource, params=None, data=None):\n\n        if not is_collection(resource):\n            resource = [resource]\n\n        url = self._url_for(*resource)\n        r = self._session.request(method, url, params=params, data=data)\n\n        if r.status_code == 422:\n            http_error = HTTPError('%s Client Error: %s' %\n                                   (r.status_code, r.content.decode(\"utf-8\")))\n            http_error.response = r\n            raise http_error\n\n        r.raise_for_status()\n\n        return r", "response": "Makes an HTTP request."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a mapped object from an HTTP resource.", "response": "def _get_resource(self, resource, obj, params=None, **kwargs):\n        \"\"\"Returns a mapped object from an HTTP resource.\"\"\"\n        r = self._http_resource('GET', resource, params=params)\n        item = self._resource_deserialize(r.content.decode(\"utf-8\"))\n\n        return obj.new_from_dict(item, h=self, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_resources(self, resource, obj, params=None, map=None, **kwargs):\n        r = self._http_resource('GET', resource, params=params)\n        d_items = self._resource_deserialize(r.content.decode(\"utf-8\"))\n\n        items =  [obj.new_from_dict(item, h=self, **kwargs) for item in d_items]\n\n        if map is None:\n            map = KeyedListResource\n\n        list_resource = map(items=items)\n        list_resource._h = self\n        list_resource._obj = obj\n        list_resource._kwargs = kwargs\n\n        return list_resource", "response": "Returns a list of mapped objects from an HTTP resource."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_key(api_key, **kwargs):\n\n    h = Heroku(**kwargs)\n\n    # Login.\n    h.authenticate(api_key)\n\n    return h", "response": "Returns an authenticated Heroku instance via API Key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_setup_version(location, reponame, pkgname=None, archive_commit=None):\n    import warnings\n    pkgname = reponame if pkgname is None else pkgname\n    if archive_commit is None:\n        warnings.warn(\"No archive commit available; git archives will not contain version information\")\n    return Version.setup_version(os.path.dirname(os.path.abspath(location)),reponame,pkgname=pkgname,archive_commit=archive_commit)", "response": "Helper for use in setup. py to get the current version from either the current version file or the current version file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_setupcfg_version():\n    try:\n        import configparser\n    except ImportError:\n        import ConfigParser as configparser # python2 (also prevents dict-like access)\n    import re\n    cfg = \"setup.cfg\"\n    autover_section = 'tool:autover'\n    config = configparser.ConfigParser()\n    config.read(cfg)\n    pkgname = config.get('metadata','name')\n    reponame = config.get(autover_section,'reponame',vars={'reponame':pkgname}) if autover_section in config.sections() else pkgname\n\n    ###\n    # hack archive_commit into section heading; see docstring\n    archive_commit = None\n    archive_commit_key = autover_section+'.configparser_workaround.archive_commit'\n    for section in config.sections():\n        if section.startswith(archive_commit_key):\n            archive_commit = re.match(r\".*=\\s*(\\S*)\\s*\",section).group(1)\n    ###\n    return get_setup_version(cfg,reponame=reponame,pkgname=pkgname,archive_commit=archive_commit)", "response": "Get the version of the setuptools package."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fetch(self):\n        if self._release is not None:\n            return self\n\n        self._release = self.expected_release\n        if not self.fpath:\n            self._commit = self._expected_commit\n            return self\n\n         # Only git right now but easily extended to SVN, Mercurial, etc.\n        for cmd in ['git', 'git.cmd', 'git.exe']:\n            try:\n                self.git_fetch(cmd)\n                break\n            except EnvironmentError:\n                pass\n        return self", "response": "Fetch the current version of the current version of the current version."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _known_stale(self):\n        if self._output_from_file() is None:\n            commit = None\n        else:\n            commit = self.commit\n\n        known_stale = (self.archive_commit is not None\n                       and not self.archive_commit.startswith('$Format')\n                       and self.archive_commit != commit)\n        if known_stale: self._commit_count = None\n        return known_stale", "response": "Return True if the commit is known to be from a file and therefore stale."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _output_from_file(self, entry='git_describe'):\n        try:\n            vfile = os.path.join(os.path.dirname(self.fpath), '.version')\n            with open(vfile, 'r') as f:\n                return json.loads(f.read()).get(entry, None)\n        except: # File may be missing if using pip + git archive\n            return None", "response": "Read the version from a. version file that may exist alongside __init__. py."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _update_from_vcs(self, output):\n        \"Update state based on the VCS state e.g the output of git describe\"\n        split = output[1:].split('-')\n        dot_split = split[0].split('.')\n        for prefix in ['a','b','rc']:\n            if prefix in dot_split[-1]:\n                prefix_split = dot_split[-1].split(prefix)\n                self._prerelease = prefix + prefix_split[-1]\n                dot_split[-1] = prefix_split[0]\n\n\n        self._release = tuple(int(el) for el in dot_split)\n        self._commit_count = int(split[1])\n\n        self._commit = str(split[2][1:]) # Strip out 'g' prefix ('g'=>'git')\n\n        self._dirty = (split[-1]=='dirty')\n        return self", "response": "Update state based on the VCS state e. g the output of git describe"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _update_from_vcs(self, output):\n        \"Update state based on the VCS state e.g the output of git describe\"\n        split = output[1:].split('-')\n        if 'dev' in split[0]:\n            dev_split = split[0].split('dev')\n            self.dev = int(dev_split[1])\n            split[0] = dev_split[0]\n            # Remove the pep440 dot if present\n            if split[0].endswith('.'):\n                split[0] = dev_split[0][:-1]\n\n        self._release = tuple(int(el) for el in split[0].split('.'))\n        self._commit_count = int(split[1])\n        self._commit = str(split[2][1:]) # Strip out 'g' prefix ('g'=>'git')\n        self._dirty = (split[-1]=='dirty')\n        return self", "response": "Update state based on the VCS state e. g the output of git describe"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nabbreviates the current locale.", "response": "def abbrev(self,dev_suffix=\"\"):\n        \"\"\"\n        Abbreviated string representation, optionally declaring whether it is\n        a development version.\n        \"\"\"\n        return '.'.join(str(el) for el in self.release) + \\\n            (dev_suffix if self.commit_count > 0 or self.dirty else \"\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef verify(self, string_version=None):\n        if string_version and string_version != str(self):\n            raise Exception(\"Supplied string version does not match current version.\")\n\n        if self.dirty:\n            raise Exception(\"Current working directory is dirty.\")\n\n        if self.release != self.expected_release:\n            raise Exception(\"Declared release does not match current release tag.\")\n\n        if self.commit_count !=0:\n            raise Exception(\"Please update the VCS version tag before release.\")\n\n        if self._expected_commit not in [None, \"$Format:%h$\"]:\n            raise Exception(\"Declared release does not match the VCS version tag\")", "response": "Verify that the version information of the VCS is consistent with the current version."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _check_time_fn(self, time_instance=False):\n        if time_instance and not isinstance(self.time_fn, param.Time):\n            raise AssertionError(\"%s requires a Time object\"\n                                 % self.__class__.__name__)\n\n        if self.time_dependent:\n            global_timefn = self.time_fn is param.Dynamic.time_fn\n            if global_timefn and not param.Dynamic.time_dependent:\n                raise AssertionError(\"Cannot use Dynamic.time_fn as\"\n                                     \" parameters are ignoring time.\")", "response": "Checks that the time_fn is the global time function supplied by the resource."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _rational(self, val):\n\n        I32 = 4294967296 # Maximum 32 bit unsigned int (i.e. 'I') value\n        if isinstance(val, int):\n             numer, denom = val, 1\n        elif isinstance(val, fractions.Fraction):\n            numer, denom = val.numerator, val.denominator\n        elif hasattr(val, 'numer'):\n            (numer, denom) = (int(val.numer()), int(val.denom()))\n        else:\n            param.main.param.warning(\"Casting type '%s' to Fraction.fraction\"\n                               % type(val).__name__)\n            frac = fractions.Fraction(str(val))\n            numer, denom = frac.numerator, frac.denominator\n        return numer % I32, denom % I32", "response": "Convert the given value to a rational if necessary."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _initialize_random_state(self, seed=None, shared=True, name=None):\n        if seed is None: # Equivalent to an uncontrolled seed.\n            seed = random.Random().randint(0, 1000000)\n            suffix = ''\n        else:\n            suffix = str(seed)\n\n        # If time_dependent, independent state required: otherwise\n        # time-dependent seeding (via hash) will affect shared\n        # state. Note that if all objects have time_dependent=True\n        # shared random state is safe and more memory efficient.\n        if self.time_dependent or not shared:\n            self.random_generator = type(self.random_generator)(seed)\n\n        # Seed appropriately (if not shared)\n        if not shared:\n            self.random_generator.seed(seed)\n\n        if name is None:\n            self._verify_constrained_hash()\n\n        hash_name = name if name else self.name\n        if not shared:  hash_name += suffix\n        self._hashfn = Hash(hash_name, input_count=2)\n\n        if self.time_dependent:\n            self._hash_and_seed()", "response": "Initializes the random state of the object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _verify_constrained_hash(self):\n        changed_params = dict(self.param.get_param_values(onlychanged=True))\n        if self.time_dependent and ('name' not in changed_params):\n            self.param.warning(\"Default object name used to set the seed: \"\n                               \"random values conditional on object instantiation order.\")", "response": "Warn if the object name is not explicitly set."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _hash_and_seed(self):\n        hashval = self._hashfn(self.time_fn(), param.random_seed)\n        self.random_generator.seed(hashval)", "response": "Hash and seed the random generator with the given seed value."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nuse autover to get up to date version.", "response": "def get_setup_version(reponame):\n    \"\"\"Use autover to get up to date version.\"\"\"\n    # importing self into setup.py is unorthodox, but param has no\n    # required dependencies outside of python\n    from param.version import Version\n    return Version.setup_version(os.path.dirname(__file__),reponame,archive_commit=\"$Format:%h$\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the parameter dictionary the list of modifed parameters and the dictionary or parameter values.", "response": "def get_param_info(self, obj, include_super=True):\n        \"\"\"\n        Get the parameter dictionary, the list of modifed parameters\n        and the dictionary or parameter values. If include_super is\n        True, parameters are also collected from the super classes.\n        \"\"\"\n\n        params = dict(obj.param.objects('existing'))\n        if isinstance(obj,type):\n            changed = []\n            val_dict = dict((k,p.default) for (k,p) in params.items())\n            self_class = obj\n        else:\n            changed = [name for (name,_) in obj.param.get_param_values(onlychanged=True)]\n            val_dict = dict(obj.param.get_param_values())\n            self_class = obj.__class__\n\n        if not include_super:\n            params = dict((k,v) for (k,v) in params.items()\n                          if k in self_class.__dict__)\n\n        params.pop('name') # Already displayed in the title.\n        return (params, val_dict, changed)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef param_docstrings(self, info, max_col_len=100, only_changed=False):\n\n        (params, val_dict, changed) = info\n        contents = []\n        displayed_params = {}\n        for name, p in params.items():\n            if only_changed and not (name in changed):\n                continue\n            displayed_params[name] = p\n\n        right_shift = max(len(name) for name in displayed_params.keys())+2\n\n        for i, name in enumerate(sorted(displayed_params)):\n            p = displayed_params[name]\n            heading = \"%s: \" % name\n            unindented = textwrap.dedent(\"< No docstring available >\" if p.doc is None else p.doc)\n\n            if (WARN_MISFORMATTED_DOCSTRINGS\n                and not unindented.startswith(\"\\n\")  and len(unindented.splitlines()) > 1):\n                param.main.warning(\"Multi-line docstring for %r is incorrectly formatted \"\n                                   \" (should start with newline)\", name)\n            # Strip any starting newlines\n            while unindented.startswith(\"\\n\"):\n                unindented = unindented[1:]\n\n            lines = unindented.splitlines()\n            if len(lines) > 1:\n                tail = ['%s%s' % (' '  * right_shift, line) for line in lines[1:]]\n                all_lines = [ heading.ljust(right_shift) + lines[0]] + tail\n            elif len(lines) == 1:\n                all_lines = [ heading.ljust(right_shift) + lines[0]]\n            else:\n                all_lines = []\n\n            if i % 2:  # Alternate red and blue for docstrings\n                contents.extend([red %el for el in all_lines])\n            else:\n                contents.extend([blue %el for el in all_lines])\n\n        return \"\\n\".join(contents)", "response": "Build a string to that presents all of the parameter docstrings in a clean format."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _build_table(self, info, order, max_col_len=40, only_changed=False):\n\n        info_dict, bounds_dict = {}, {}\n        (params, val_dict, changed) = info\n        col_widths = dict((k,0) for k in order)\n\n        for name, p in params.items():\n            if only_changed and not (name in changed):\n                continue\n\n            constant = 'C' if p.constant else 'V'\n            readonly = 'RO' if p.readonly else 'RW'\n            allow_None = ' AN' if hasattr(p, 'allow_None') and p.allow_None else ''\n\n            mode = '%s %s%s' % (constant, readonly, allow_None)\n            info_dict[name] = {'name': name, 'type':p.__class__.__name__,\n                               'mode':mode}\n\n            if hasattr(p, 'bounds'):\n                lbound, ubound = (None,None) if p.bounds is None else p.bounds\n\n                mark_lbound, mark_ubound = False, False\n                # Use soft_bounds when bounds not defined.\n                if hasattr(p, 'get_soft_bounds'):\n                    soft_lbound, soft_ubound = p.get_soft_bounds()\n                    if lbound is None and soft_lbound is not None:\n                        lbound = soft_lbound\n                        mark_lbound = True\n                    if ubound is None and soft_ubound is not None:\n                        ubound = soft_ubound\n                        mark_ubound = True\n\n                if (lbound, ubound) != (None,None):\n                    bounds_dict[name] = (mark_lbound, mark_ubound)\n                    info_dict[name]['bounds'] = '(%s, %s)' % (lbound, ubound)\n\n            value = repr(val_dict[name])\n            if len(value) > (max_col_len - 3):\n                value = value[:max_col_len-3] + '...'\n            info_dict[name]['value'] = value\n\n            for col in info_dict[name]:\n                max_width = max([col_widths[col], len(info_dict[name][col])])\n                col_widths[col] = max_width\n\n        return self._tabulate(info_dict, col_widths, changed, order, bounds_dict)", "response": "Build a table of information about the parameters needed to build a new a\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _tabulate(self, info_dict, col_widths, changed, order, bounds_dict):\n\n        contents, tail = [], []\n        column_set = set(k for row in info_dict.values() for k in row)\n        columns = [col for col in order if col in column_set]\n\n        title_row = []\n        # Generate the column headings\n        for i, col in enumerate(columns):\n            width = col_widths[col]+2\n            col = col.capitalize()\n            formatted = col.ljust(width) if i == 0 else col.center(width)\n            title_row.append(formatted)\n        contents.append(blue % ''.join(title_row)+\"\\n\")\n\n        # Format the table rows\n        for row in sorted(info_dict):\n            row_list = []\n            info = info_dict[row]\n            for i,col in enumerate(columns):\n                width = col_widths[col]+2\n                val = info[col] if (col in info) else ''\n                formatted = val.ljust(width) if i==0 else val.center(width)\n\n                if col == 'bounds' and bounds_dict.get(row,False):\n                    (mark_lbound, mark_ubound) = bounds_dict[row]\n                    lval, uval = formatted.rsplit(',')\n                    lspace, lstr = lval.rsplit('(')\n                    ustr, uspace = uval.rsplit(')')\n                    lbound = lspace + '('+(cyan % lstr) if mark_lbound else lval\n                    ubound = (cyan % ustr)+')'+uspace if mark_ubound else uval\n                    formatted = \"%s,%s\" % (lbound, ubound)\n                row_list.append(formatted)\n\n            row_text = ''.join(row_list)\n            if row in changed:\n                row_text = red % row_text\n\n            contents.append(row_text)\n\n        return '\\n'.join(contents+tail)", "response": "Returns the supplied information as a table suitable for printing or paging."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_ordered_dict(d):\n    py3_ordered_dicts = (sys.version_info.major == 3) and (sys.version_info.minor >= 6)\n    vanilla_odicts = (sys.version_info.major > 3) or py3_ordered_dicts\n    return isinstance(d, (OrderedDict))or (vanilla_odicts and isinstance(d, dict))", "response": "Predicate checking for ordered dictionaries."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef hashable(x):\n    if isinstance(x, collections.MutableSequence):\n        return tuple(x)\n    elif isinstance(x, collections.MutableMapping):\n        return tuple([(k,v) for k,v in x.items()])\n    else:\n        return x", "response": "Returns a hashable version of the given object x with lists and\n    dictionaries converted to tuples."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef named_objs(objlist, namesdict=None):\n    objs = OrderedDict()\n\n    if namesdict is not None:\n        objtoname = {hashable(v): k for k, v in namesdict.items()}\n\n    for obj in objlist:\n        if namesdict is not None and hashable(obj) in objtoname:\n            k = objtoname[hashable(obj)]\n        elif hasattr(obj, \"name\"):\n            k = obj.name\n        elif hasattr(obj, '__name__'):\n            k = obj.__name__\n        else:\n            k = as_unicode(obj)\n        objs[k] = obj\n    return objs", "response": "Given a list of objects returns a dictionary mapping from string name for the object to the object itself."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngives a set of Parameterized objects returns a dictionary with the union of all param name value pairs across them.", "response": "def param_union(*parameterizeds, **kwargs):\n    \"\"\"\n    Given a set of Parameterized objects, returns a dictionary\n    with the union of all param name,value pairs across them.\n    If warn is True (default), warns if the same parameter has\n    been given multiple values; otherwise uses the last value\n    \"\"\"\n    warn = kwargs.pop('warn', True)\n    if len(kwargs):\n        raise TypeError(\n            \"param_union() got an unexpected keyword argument '{}'\".format(\n                kwargs.popitem()[0]))\n    d = dict()\n    for o in parameterizeds:\n        for k in o.param:\n            if k != 'name':\n                if k in d and warn:\n                    get_logger().warning(\"overwriting parameter {}\".format(k))\n                d[k] = getattr(o, k)\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a set of keyword literals promote to the appropriate parameter type based on some simple heuristics.", "response": "def guess_param_types(**kwargs):\n    \"\"\"\n    Given a set of keyword literals, promote to the appropriate\n    parameter type based on some simple heuristics.\n    \"\"\"\n    params = {}\n    for k, v in kwargs.items():\n        kws = dict(default=v, constant=True)\n        if isinstance(v, Parameter):\n            params[k] = v\n        elif isinstance(v, dt_types):\n            params[k] = Date(**kws)\n        elif isinstance(v, bool):\n            params[k] = Boolean(**kws)\n        elif isinstance(v, int):\n            params[k] = Integer(**kws)\n        elif isinstance(v, float):\n            params[k] = Number(**kws)\n        elif isinstance(v, str):\n            params[k] = String(**kws)\n        elif isinstance(v, dict):\n            params[k] = Dict(**kws)\n        elif isinstance(v, tuple):\n            if all(_is_number(el) for el in v):\n                params[k] = NumericTuple(**kws)\n            elif all(isinstance(el. dt_types) for el in v) and len(v)==2:\n                params[k] = DateRange(**kws)\n            else:\n                params[k] = Tuple(**kws)\n        elif isinstance(v, list):\n            params[k] = List(**kws)\n        elif isinstance(v, np.ndarray):\n            params[k] = Array(**kws)\n        else:\n            from pandas import DataFrame as pdDFrame\n            from pandas import Series as pdSeries\n\n            if isinstance(v, pdDFrame):\n                params[k] = DataFrame(**kws)\n            elif isinstance(v, pdSeries):\n                params[k] = Series(**kws)\n            else:\n                params[k] = Parameter(**kws)\n\n    return params"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parameterized_class(name, params, bases=Parameterized):\n    if not (isinstance(bases, list) or isinstance(bases, tuple)):\n          bases=[bases]\n    return type(name, tuple(bases), params)", "response": "Dynamically create a parameterized class with the given name and the given parameters inheriting from the specified base."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef guess_bounds(params, **overrides):\n    guessed = {}\n    for name, p in params.items():\n        new_param = copy.copy(p)\n        if isinstance(p, (Integer, Number)):\n            if name in overrides:\n                minv,maxv = overrides[name]\n            else:\n                minv, maxv, _ = _get_min_max_value(None, None, value=p.default)\n            new_param.bounds = (minv, maxv)\n        guessed[name] = new_param\n    return guessed", "response": "Given a dictionary of Parameter instances return a corresponding\n    set of copies with the bounds appropriately set."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a dictionary containing all subclasses of the specified including the parentclass.", "response": "def concrete_descendents(parentclass):\n    \"\"\"\n    Return a dictionary containing all subclasses of the specified\n    parentclass, including the parentclass.  Only classes that are\n    defined in scripts that have been run or modules that have been\n    imported are included, so the caller will usually first do ``from\n    package import *``.\n\n    Only non-abstract classes will be included.\n    \"\"\"\n    return dict((c.__name__,c) for c in descendents(parentclass)\n                if not _is_abstract(c))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef abbreviate_paths(pathspec,named_paths):\n    from os.path import commonprefix, dirname, sep\n\n    prefix = commonprefix([dirname(name)+sep for name in named_paths.keys()]+[pathspec])\n    return OrderedDict([(name[len(prefix):],path) for name,path in named_paths.items()])", "response": "Given a dict of pathname - > path pairs removes any prefix shared by all pathnames."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _initialize_generator(self,gen,obj=None):\n        # CEBALERT: use a dictionary to hold these things.\n        if hasattr(obj,\"_Dynamic_time_fn\"):\n            gen._Dynamic_time_fn = obj._Dynamic_time_fn\n\n        gen._Dynamic_last = None\n        # CEB: I'd use None for this, except can't compare a fixedpoint\n        # number with None (e.g. 1>None but FixedPoint(1)>None can't be done)\n        gen._Dynamic_time = -1\n\n        gen._saved_Dynamic_last = []\n        gen._saved_Dynamic_time = []", "response": "Initialize the generator with the current values of the entries in the object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a value from gen.", "response": "def _produce_value(self,gen,force=False):\n        \"\"\"\n        Return a value from gen.\n\n        If there is no time_fn, then a new value will be returned\n        (i.e. gen will be asked to produce a new value).\n\n        If force is True, or the value of time_fn() is different from\n        what it was was last time produce_value was called, a new\n        value will be produced and returned. Otherwise, the last value\n        gen produced will be returned.\n        \"\"\"\n\n        if hasattr(gen,\"_Dynamic_time_fn\"):\n            time_fn = gen._Dynamic_time_fn\n        else:\n            time_fn = self.time_fn\n\n        if (time_fn is None) or (not self.time_dependent):\n            value = produce_value(gen)\n            gen._Dynamic_last = value\n        else:\n\n            time = time_fn()\n\n            if force or time!=gen._Dynamic_time:\n                value = produce_value(gen)\n                gen._Dynamic_last = value\n                gen._Dynamic_time = time\n            else:\n                value = gen._Dynamic_last\n\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _value_is_dynamic(self,obj,objtype=None):\n        return hasattr(super(Dynamic,self).__get__(obj,objtype),'_Dynamic_last')", "response": "Return True if the parameter is actually dynamic."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _inspect(self,obj,objtype=None):\n        gen=super(Dynamic,self).__get__(obj,objtype)\n\n        if hasattr(gen,'_Dynamic_last'):\n            return gen._Dynamic_last\n        else:\n            return gen", "response": "Return the last generated value for this parameter."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _force(self,obj,objtype=None):\n        gen=super(Dynamic,self).__get__(obj,objtype)\n\n        if hasattr(gen,'_Dynamic_last'):\n            return self._produce_value(gen,force=True)\n        else:\n            return gen", "response": "Force a new value to be generated and return it."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_in_bounds(self,obj,val):\n        if not callable(val):\n            bounded_val = self.crop_to_bounds(val)\n        else:\n            bounded_val = val\n        super(Number,self).__set__(obj,bounded_val)", "response": "Sets the value of the object to val but cropped to be within the legal bounds."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef crop_to_bounds(self,val):\n        # Currently, values outside the bounds are silently cropped to\n        # be inside the bounds; it may be appropriate to add a warning\n        # in such cases.\n        if _is_number(val):\n            if self.bounds is None:\n                return val\n            vmin, vmax = self.bounds\n            if vmin is not None:\n                if val < vmin:\n                    return  vmin\n\n            if vmax is not None:\n                if val > vmax:\n                    return vmax\n\n        elif self.allow_None and val is None:\n            return val\n\n        else:\n            # non-numeric value sent in: reverts to default value\n            return  self.default\n\n        return val", "response": "Return the given value cropped to be within the hard bounds\n            for this parameter."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvalidate that the value is a numeric value and that it is within the hard - available bounds.", "response": "def _validate(self, val):\n        \"\"\"\n        Checks that the value is numeric and that it is within the hard\n        bounds; if not, an exception is raised.\n        \"\"\"\n        if callable(val):\n            return val\n\n        if self.allow_None and val is None:\n            return\n\n        if not _is_number(val):\n            raise ValueError(\"Parameter '%s' only takes numeric values\"%(self.name))\n\n        if self.step is not None and not _is_number(self.step):\n            raise ValueError(\"Step parameter can only be None or a numeric value\")\n\n        self._checkBounds(val)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the soft bound for the current instance.", "response": "def get_soft_bounds(self):\n        \"\"\"\n        For each soft bound (upper and lower), if there is a defined bound (not equal to None)\n        then it is returned, otherwise it defaults to the hard bound. The hard bound could still be None.\n        \"\"\"\n        if self.bounds is None:\n            hl,hu=(None,None)\n        else:\n            hl,hu=self.bounds\n\n        if self._softbounds is None:\n            sl,su=(None,None)\n        else:\n            sl,su=self._softbounds\n\n\n        if sl is None: l = hl\n        else:          l = sl\n\n        if su is None: u = hu\n        else:          u = su\n\n        return (l,u)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvalidate that val is one of the objects in self. objects.", "response": "def _validate(self, val):\n        \"\"\"\n        val must be None or one of the objects in self.objects.\n        \"\"\"\n        if not self.check_on_set:\n            self._ensure_value_is_in_objects(val)\n            return\n\n        if not (val in self.objects or (self.allow_None and val is None)):\n            # CEBALERT: can be called before __init__ has called\n            # super's __init__, i.e. before attrib_name has been set.\n            try:\n                attrib_name = self.name\n            except AttributeError:\n                attrib_name = \"\"\n\n            items = []\n            limiter = ']'\n            length = 0\n            for item in self.objects:\n                string = str(item)\n                length += len(string)\n                if length < 200:\n                    items.append(string)\n                else:\n                    limiter = ', ...]'\n                    break\n            items = '[' + ', '.join(items) + limiter\n            raise ValueError(\"%s not in Parameter %s's list of possible objects, \"\n                             \"valid options include %s\"%(val,attrib_name, items))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _ensure_value_is_in_objects(self,val):\n        if not (val in self.objects):\n           self.objects.append(val)", "response": "Ensure that the provided value is present on the objects list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _validate(self,val):\n        if isinstance(self.class_, tuple):\n            class_name = ('(%s)' % ', '.join(cl.__name__ for cl in self.class_))\n        else:\n            class_name = self.class_.__name__\n        if self.is_instance:\n            if not (isinstance(val,self.class_)) and not (val is None and self.allow_None):\n                raise ValueError(\n                    \"Parameter '%s' value must be an instance of %s, not '%s'\" %\n                    (self.name, class_name, val))\n        else:\n            if not (val is None and self.allow_None) and not (issubclass(val,self.class_)):\n                raise ValueError(\n                    \"Parameter '%s' must be a subclass of %s, not '%s'\" %\n                    (val.__name__, class_name, val.__class__.__name__))", "response": "Validate the value of the parameter."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the possible types for this parameter s value.", "response": "def get_range(self):\n        \"\"\"\n        Return the possible types for this parameter's value.\n\n        (I.e. return {name: <class>} for all classes that are\n        concrete_descendents() of self.class_.)\n\n        Only classes from modules that have been imported are added\n        (see concrete_descendents()).\n        \"\"\"\n        classes = concrete_descendents(self.class_)\n        d=OrderedDict((name,class_) for name,class_ in classes.items())\n        if self.allow_None:\n            d['None']=None\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks that the list is of the right length and has the right contents. If not an exception is raised.", "response": "def _validate(self, val):\n        \"\"\"\n        Checks that the list is of the right length and has the right contents.\n        Otherwise, an exception is raised.\n        \"\"\"\n        if self.allow_None and val is None:\n            return\n\n        if not isinstance(val, list):\n            raise ValueError(\"List '%s' must be a list.\"%(self.name))\n\n        if self.bounds is not None:\n            min_length,max_length = self.bounds\n            l=len(val)\n            if min_length is not None and max_length is not None:\n                if not (min_length <= l <= max_length):\n                    raise ValueError(\"%s: list length must be between %s and %s (inclusive)\"%(self.name,min_length,max_length))\n            elif min_length is not None:\n                if not min_length <= l:\n                    raise ValueError(\"%s: list length must be at least %s.\"%(self.name,min_length))\n            elif max_length is not None:\n                if not l <= max_length:\n                    raise ValueError(\"%s: list length must be at most %s.\"%(self.name,max_length))\n\n        self._check_type(val)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _validate(self, val):\n        if self.allow_None and val is None:\n            return\n\n        if not isinstance(val, dt_types) and not (self.allow_None and val is None):\n            raise ValueError(\"Date '%s' only takes datetime types.\"%self.name)\n\n        if self.step is not None and not isinstance(self.step, dt_types):\n            raise ValueError(\"Step parameter can only be None or a datetime type\")\n\n        self._checkBounds(val)", "response": "Checks that the value is numeric and that it is within the hard - available time range."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks that the value is numeric and that it is within the hard bounds ; if not raises an exception.", "response": "def _validate(self, val):\n        \"\"\"\n        Checks that the value is numeric and that it is within the hard\n        bounds; if not, an exception is raised.\n        \"\"\"\n        if self.allow_None and val is None:\n            return\n        super(Range, self)._validate(val)\n\n        self._checkBounds(val)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef logging_level(level):\n    level = level.upper()\n    levels = [DEBUG, INFO, WARNING, ERROR, CRITICAL, VERBOSE]\n    level_names = ['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL', 'VERBOSE']\n\n    if level not in level_names:\n        raise Exception(\"Level %r not in %r\" % (level, levels))\n\n    param_logger = get_logger()\n    logging_level = param_logger.getEffectiveLevel()\n    param_logger.setLevel(levels[level_names.index(level)])\n    try:\n        yield None\n    finally:\n        param_logger.setLevel(logging_level)", "response": "Temporarily modify param s logging level."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of the class hierarchy below and including the given class.", "response": "def descendents(class_):\n    \"\"\"\n    Return a list of the class hierarchy below (and including) the given class.\n\n    The list is ordered from least- to most-specific.  Can be useful for\n    printing the contents of an entire class hierarchy.\n    \"\"\"\n    assert isinstance(class_,type)\n    q = [class_]\n    out = []\n    while len(q):\n        x = q.pop(0)\n        out.insert(0,x)\n        for b in x.__subclasses__():\n            if b not in q and b not in out:\n                q.append(b)\n    return out[::-1]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_all_slots(class_):\n    # A subclass's __slots__ attribute does not contain slots defined\n    # in its superclass (the superclass' __slots__ end up as\n    # attributes of the subclass).\n    all_slots = []\n    parent_param_classes = [c for c in classlist(class_)[1::]]\n    for c in parent_param_classes:\n        if hasattr(c,'__slots__'):\n            all_slots+=c.__slots__\n    return all_slots", "response": "Return a list of slot names for all slots defined in class_ and its\n    superclasses."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_occupied_slots(instance):\n    return [slot for slot in get_all_slots(type(instance))\n            if hasattr(instance,slot)]", "response": "Returns a list of slots for which values have been set."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a single boolean for arg1 == arg2 even for numpy arrays and arg1 == arg2 otherwise.", "response": "def all_equal(arg1,arg2):\n    \"\"\"\n    Return a single boolean for arg1==arg2, even for numpy arrays\n    using element-wise comparison.\n\n    Uses all(arg1==arg2) for sequences, and arg1==arg2 otherwise.\n\n    If both objects have an '_infinitely_iterable' attribute, they are\n    not be zipped together and are compared directly instead.\n    \"\"\"\n    if all(hasattr(el, '_infinitely_iterable') for el in [arg1,arg2]):\n        return arg1==arg2\n    try:\n        return all(a1 == a2 for a1, a2 in zip(arg1, arg2))\n    except TypeError:\n        return arg1==arg2"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef depends(func, *dependencies, **kw):\n\n    # python3 would allow kw-only args\n    # (i.e. \"func,*dependencies,watch=False\" rather than **kw and the check below)\n    watch = kw.pop(\"watch\",False)\n    assert len(kw)==0, \"@depends accepts only 'watch' kw\"\n\n    # TODO: rename dinfo\n    _dinfo = getattr(func, '_dinfo', {})\n    _dinfo.update({'dependencies': dependencies,\n                   'watch': watch})\n\n    @wraps(func)\n    def _depends(*args,**kw):\n        return func(*args,**kw)\n\n    # storing here risks it being tricky to find if other libraries\n    # mess around with methods\n    _depends._dinfo = _dinfo\n\n    return _depends", "response": "Annotates a Parameterized method to express its dependencies."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef output(func, *output, **kw):\n    if output:\n        outputs = []\n        for i, out in enumerate(output):\n            i = i if len(output) > 1 else None\n            if isinstance(out, tuple) and len(out) == 2 and isinstance(out[0], str):\n                outputs.append(out+(i,))\n            elif isinstance(out, str):\n                outputs.append((out, Parameter(), i))\n            else:\n                outputs.append((None, out, i))\n    elif kw:\n        py_major = sys.version_info.major\n        py_minor = sys.version_info.minor\n        if (py_major < 3 or (py_major == 3 and py_minor < 6)) and len(kw) > 1:\n            raise ValueError('Multiple output declaration using keywords '\n                             'only supported in Python >= 3.6.')\n          # (requires keywords to be kept ordered, which was not true in previous versions)\n        outputs = [(name, otype, i if len(kw) > 1 else None)\n                   for i, (name, otype) in enumerate(kw.items())]\n    else:\n        outputs = [(None, Parameter(), None)]\n\n    names, processed = [], []\n    for name, otype, i in outputs:\n        if isinstance(otype, type):\n            if issubclass(otype, Parameter):\n                otype = otype()\n            else:\n                from .import ClassSelector\n                otype = ClassSelector(class_=otype)\n        elif isinstance(otype, tuple) and all(isinstance(t, type) for t in otype):\n            from .import ClassSelector\n            otype = ClassSelector(class_=otype)\n        if not isinstance(otype, Parameter):\n            raise ValueError('output type must be declared with a Parameter class, '\n                             'instance or a Python object type.')\n        processed.append((name, otype, i))\n        names.append(name)\n\n    if len(set(names)) != len(names):\n        raise ValueError('When declaring multiple outputs each value '\n                         'must be unique.')\n\n    _dinfo = getattr(func, '_dinfo', {})\n    _dinfo.update({'outputs': processed})\n\n    @wraps(func)\n    def _output(*args,**kw):\n        return func(*args,**kw)\n\n    _output._dinfo = _dinfo\n\n    return _output", "response": "This function is used to output a method on a Parameterized class. It allows annotating a method on a Parameterized class to get an output of a specific type."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef script_repr(val,imports,prefix,settings):\n    return pprint(val,imports,prefix,settings,unknown_value=None,\n                  qualify=True,separator=\"\\n\")", "response": "Returns a string representation of a parameter."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef print_all_param_defaults():\n    print(\"_______________________________________________________________________________\")\n    print(\"\")\n    print(\"                           Parameter Default Values\")\n    print(\"\")\n    classes = descendents(Parameterized)\n    classes.sort(key=lambda x:x.__name__)\n    for c in classes:\n        c.print_param_defaults()\n    print(\"_______________________________________________________________________________\")", "response": "Print the default values for all imported Parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninitializes default and keyword parameter values for mutable parameters.", "response": "def _setup_params(self_,**params):\n        \"\"\"\n        Initialize default and keyword parameter values.\n\n        First, ensures that all Parameters with 'instantiate=True'\n        (typically used for mutable Parameters) are copied directly\n        into each object, to ensure that there is an independent copy\n        (to avoid suprising aliasing errors).  Then sets each of the\n        keyword arguments, warning when any of them are not defined as\n        parameters.\n\n        Constant Parameters can be set during calls to this method.\n        \"\"\"\n        self = self_.param.self\n        ## Deepcopy all 'instantiate=True' parameters\n        # (build a set of names first to avoid redundantly instantiating\n        #  a later-overridden parent class's parameter)\n        params_to_instantiate = {}\n        for class_ in classlist(type(self)):\n            if not issubclass(class_, Parameterized):\n                continue\n            for (k,v) in class_.__dict__.items():\n                # (avoid replacing name with the default of None)\n                if isinstance(v,Parameter) and v.instantiate and k!=\"name\":\n                    params_to_instantiate[k]=v\n\n        for p in params_to_instantiate.values():\n            self.param._instantiate_param(p)\n\n        ## keyword arg setting\n        for name,val in params.items():\n            desc = self.__class__.get_param_descriptor(name)[0] # pylint: disable-msg=E1101\n            if not desc:\n                self.param.warning(\"Setting non-parameter attribute %s=%s using a mechanism intended only for parameters\",name,val)\n            # i.e. if not desc it's setting an attribute in __dict__, not a Parameter\n            setattr(self,name,val)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef deprecate(cls, fn):\n        def inner(*args, **kwargs):\n            if cls._disable_stubs:\n                raise AssertionError('Stubs supporting old API disabled')\n            elif cls._disable_stubs is None:\n                pass\n            elif cls._disable_stubs is False:\n                get_logger(name=args[0].__class__.__name__).log(\n                    WARNING, 'Use method %r via param namespace ' % fn.__name__)\n            return fn(*args, **kwargs)\n\n        inner.__doc__= \"Inspect .param.%s method for the full docstring\"  % fn.__name__\n        return inner", "response": "Decorator to issue warnings for API moving onto the param. param namespace and adding a docstring directing people to the param. class namespace."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprint the default values of all cls s Parameters.", "response": "def print_param_defaults(self_):\n        \"\"\"Print the default values of all cls's Parameters.\"\"\"\n        cls = self_.cls\n        for key,val in cls.__dict__.items():\n            if isinstance(val,Parameter):\n                print(cls.__name__+'.'+key+ '='+ repr(val.default))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the default value of param_name.", "response": "def set_default(self_,param_name,value):\n        \"\"\"\n        Set the default value of param_name.\n\n        Equivalent to setting param_name on the class.\n        \"\"\"\n        cls = self_.cls\n        setattr(cls,param_name,value)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _add_parameter(self_, param_name,param_obj):\n        # CEBALERT: can't we just do\n        # setattr(cls,param_name,param_obj)?  The metaclass's\n        # __setattr__ is actually written to handle that.  (Would also\n        # need to do something about the params() cache.  That cache\n        # is a pain, but it definitely improved the startup time; it\n        # would be worthwhile making sure no method except for one\n        # \"add_param()\" method has to deal with it (plus any future\n        # remove_param() method.)\n        cls = self_.cls\n        type.__setattr__(cls,param_name,param_obj)\n        ParameterizedMetaclass._initialize_parameter(cls,param_name,param_obj)\n        # delete cached params()\n        try:\n            delattr(cls,'_%s__params'%cls.__name__)\n        except AttributeError:\n            pass", "response": "Add a new Parameter object into this object s class."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef params(self_, parameter_name=None):\n        if self_.self is not None and self_.self._instance__params:\n            self_.warning('The Parameterized instance has instance '\n                          'parameters created using new-style param '\n                          'APIs, which are incompatible with .params. '\n                          'Use the new more explicit APIs on the '\n                          '.param accessor to query parameter instances.'\n                          'To query all parameter instances use '\n                          '.param.objects with the option to return '\n                          'either class or instance parameter objects. '\n                          'Alternatively use .param[name] indexing to '\n                          'access a specific parameter object by name.')\n\n        pdict = self_.objects(instance='existing')\n        if parameter_name is None:\n            return pdict\n        else:\n            return pdict[parameter_name]", "response": "Return the Parameters of this class as the thewkalite dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the corresponding param value for this object or class.", "response": "def set_param(self_, *args,**kwargs):\n        \"\"\"\n        For each param=value keyword argument, sets the corresponding\n        parameter of this object or class to the given value.\n\n        For backwards compatibility, also accepts\n        set_param(\"param\",value) for a single parameter value using\n        positional arguments, but the keyword interface is preferred\n        because it is more compact and can set multiple values.\n        \"\"\"\n        BATCH_WATCH = self_.self_or_cls.param._BATCH_WATCH\n        self_.self_or_cls.param._BATCH_WATCH = True\n        self_or_cls = self_.self_or_cls\n        if args:\n            if len(args) == 2 and not args[0] in kwargs and not kwargs:\n                kwargs[args[0]] = args[1]\n            else:\n                self_.self_or_cls.param._BATCH_WATCH = False\n                raise ValueError(\"Invalid positional arguments for %s.set_param\" %\n                                 (self_or_cls.name))\n\n        for (k, v) in kwargs.items():\n            if k not in self_or_cls.param:\n                self_.self_or_cls.param._BATCH_WATCH = False\n                raise ValueError(\"'%s' is not a parameter of %s\" % (k, self_or_cls.name))\n            try:\n                setattr(self_or_cls, k, v)\n            except:\n                self_.self_or_cls.param._BATCH_WATCH = False\n                raise\n\n        self_.self_or_cls.param._BATCH_WATCH = BATCH_WATCH\n        if not BATCH_WATCH:\n            self_._batch_call_watchers()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef objects(self_, instance=True):\n        cls = self_.cls\n        # CB: we cache the parameters because this method is called often,\n        # and parameters are rarely added (and cannot be deleted)\n        try:\n            pdict = getattr(cls, '_%s__params' % cls.__name__)\n        except AttributeError:\n            paramdict = {}\n            for class_ in classlist(cls):\n                for name, val in class_.__dict__.items():\n                    if isinstance(val, Parameter):\n                        paramdict[name] = val\n\n            # We only want the cache to be visible to the cls on which\n            # params() is called, so we mangle the name ourselves at\n            # runtime (if we were to mangle it now, it would be\n            # _Parameterized.__params for all classes).\n            setattr(cls, '_%s__params' % cls.__name__, paramdict)\n            pdict = paramdict\n\n        if instance and self_.self is not None:\n            if instance == 'existing':\n                if self_.self._instance__params:\n                    return dict(pdict, **self_.self._instance__params)\n                return pdict\n            else:\n                return {k: self_.self.param[k] for k in pdict}\n        return pdict", "response": "Returns the Parameters of this instance or class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntriggering the watchers for the given set of parameter names.", "response": "def trigger(self_, *param_names):\n        \"\"\"\n        Trigger watchers for the given set of parameter names. Watchers\n        will be triggered whether or not the parameter values have\n        actually changed.\n        \"\"\"\n        events = self_.self_or_cls.param._events\n        watchers = self_.self_or_cls.param._watchers\n        self_.self_or_cls.param._events  = []\n        self_.self_or_cls.param._watchers = []\n        param_values = dict(self_.get_param_values())\n        params = {name: param_values[name] for name in param_names}\n        self_.self_or_cls.param._TRIGGER = True\n        self_.set_param(**params)\n        self_.self_or_cls.param._TRIGGER = False\n        self_.self_or_cls.param._events = events\n        self_.self_or_cls.param._watchers = watchers"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _update_event_type(self_, watcher, event, triggered):\n        if triggered:\n            event_type = 'triggered'\n        else:\n            event_type = 'changed' if watcher.onlychanged else 'set'\n        return Event(what=event.what, name=event.name, obj=event.obj, cls=event.cls,\n                     old=event.old, new=event.new, type=event_type)", "response": "Update the type field of an event."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninvoke the given the watcher appropriately given a Event object.", "response": "def _call_watcher(self_, watcher, event):\n        \"\"\"\n        Invoke the given the watcher appropriately given a Event object.\n        \"\"\"\n        if self_.self_or_cls.param._TRIGGER:\n            pass\n        elif watcher.onlychanged and (not self_._changed(event)):\n            return\n\n        if self_.self_or_cls.param._BATCH_WATCH:\n            self_._events.append(event)\n            if watcher not in self_._watchers:\n                self_._watchers.append(watcher)\n        elif watcher.mode == 'args':\n            with batch_watch(self_.self_or_cls, run=False):\n                watcher.fn(self_._update_event_type(watcher, event, self_.self_or_cls.param._TRIGGER))\n        else:\n            with batch_watch(self_.self_or_cls, run=False):\n                event = self_._update_event_type(watcher, event, self_.self_or_cls.param._TRIGGER)\n                watcher.fn(**{event.name: event.new})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _batch_call_watchers(self_):\n        while self_.self_or_cls.param._events:\n            event_dict = OrderedDict([((event.name, event.what), event)\n                                      for event in self_.self_or_cls.param._events])\n            watchers = self_.self_or_cls.param._watchers[:]\n            self_.self_or_cls.param._events = []\n            self_.self_or_cls.param._watchers = []\n\n            for watcher in watchers:\n                events = [self_._update_event_type(watcher, event_dict[(name, watcher.what)],\n                                                   self_.self_or_cls.param._TRIGGER)\n                          for name in watcher.parameter_names\n                          if (name, watcher.what) in event_dict]\n                with batch_watch(self_.self_or_cls, run=False):\n                    if watcher.mode == 'args':\n                        watcher.fn(*events)\n                    else:\n                        watcher.fn(**{c.name:c.new for c in events})", "response": "Batch call a set of watchers based on the parameter value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the time_fn for all Dynamic Parameters of this class or object.", "response": "def set_dynamic_time_fn(self_,time_fn,sublistattr=None):\n        \"\"\"\n        Set time_fn for all Dynamic Parameters of this class or\n        instance object that are currently being dynamically\n        generated.\n\n        Additionally, sets _Dynamic_time_fn=time_fn on this class or\n        instance object, so that any future changes to Dynamic\n        Parmeters can inherit time_fn (e.g. if a Number is changed\n        from a float to a number generator, the number generator will\n        inherit time_fn).\n\n        If specified, sublistattr is the name of an attribute of this\n        class or instance that contains an iterable collection of\n        subobjects on which set_dynamic_time_fn should be called.  If\n        the attribute sublistattr is present on any of the subobjects,\n        set_dynamic_time_fn() will be called for those, too.\n        \"\"\"\n        self_or_cls = self_.self_or_cls\n        self_or_cls._Dynamic_time_fn = time_fn\n\n        if isinstance(self_or_cls,type):\n            a = (None,self_or_cls)\n        else:\n            a = (self_or_cls,)\n\n        for n,p in self_or_cls.param.objects('existing').items():\n            if hasattr(p, '_value_is_dynamic'):\n                if p._value_is_dynamic(*a):\n                    g = self_or_cls.param.get_value_generator(n)\n                    g._Dynamic_time_fn = time_fn\n\n        if sublistattr:\n            try:\n                sublist = getattr(self_or_cls,sublistattr)\n            except AttributeError:\n                sublist = []\n\n            for obj in sublist:\n                obj.param.set_dynamic_time_fn(time_fn,sublistattr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of name value pairs for all Parameters of this object.", "response": "def get_param_values(self_,onlychanged=False):\n        \"\"\"\n        Return a list of name,value pairs for all Parameters of this\n        object.\n\n        When called on an instance with onlychanged set to True, will\n        only return values that are not equal to the default value\n        (onlychanged has no effect when called on a class).\n        \"\"\"\n        self_or_cls = self_.self_or_cls\n        # CEB: we'd actually like to know whether a value has been\n        # explicitly set on the instance, but I'm not sure that's easy\n        # (would need to distinguish instantiation of default from\n        # user setting of value).\n        vals = []\n        for name,val in self_or_cls.param.objects('existing').items():\n            value = self_or_cls.param.get_value_generator(name)\n            # (this is pointless for cls)\n            if not onlychanged or not all_equal(value,val.default):\n                vals.append((name,value))\n\n        vals.sort(key=itemgetter(0))\n        return vals"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nforce a new value to be generated for the dynamic attribute name and return it.", "response": "def force_new_dynamic_value(self_, name): # pylint: disable-msg=E0213\n        \"\"\"\n        Force a new value to be generated for the dynamic attribute\n        name, and return it.\n\n        If name is not dynamic, its current value is returned\n        (i.e. equivalent to getattr(name).\n        \"\"\"\n        cls_or_slf = self_.self_or_cls\n        param_obj = cls_or_slf.param.objects('existing').get(name)\n\n        if not param_obj:\n            return getattr(cls_or_slf, name)\n\n        cls, slf = None, None\n        if isinstance(cls_or_slf,type):\n            cls = cls_or_slf\n        else:\n            slf = cls_or_slf\n\n        if not hasattr(param_obj,'_force'):\n            return param_obj.__get__(slf, cls)\n        else:\n            return param_obj._force(slf, cls)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the value of the namedCOOKIE attribute.", "response": "def get_value_generator(self_,name): # pylint: disable-msg=E0213\n        \"\"\"\n        Return the value or value-generating object of the named\n        attribute.\n\n        For most parameters, this is simply the parameter's value\n        (i.e. the same as getattr()), but Dynamic parameters have\n        their value-generating object returned.\n        \"\"\"\n        cls_or_slf = self_.self_or_cls\n        param_obj = cls_or_slf.param.objects('existing').get(name)\n\n        if not param_obj:\n            value = getattr(cls_or_slf,name)\n\n        # CompositeParameter detected by being a Parameter and having 'attribs'\n        elif hasattr(param_obj,'attribs'):\n            value = [cls_or_slf.param.get_value_generator(a) for a in param_obj.attribs]\n\n        # not a Dynamic Parameter\n        elif not hasattr(param_obj,'_value_is_dynamic'):\n            value = getattr(cls_or_slf,name)\n\n        # Dynamic Parameter...\n        else:\n            internal_name = \"_%s_param_value\"%name\n            if hasattr(cls_or_slf,internal_name):\n                # dealing with object and it's been set on this object\n                value = getattr(cls_or_slf,internal_name)\n            else:\n                # dealing with class or isn't set on the object\n                value = param_obj.default\n\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef inspect_value(self_,name): # pylint: disable-msg=E0213\n        cls_or_slf = self_.self_or_cls\n        param_obj = cls_or_slf.param.objects('existing').get(name)\n\n        if not param_obj:\n            value = getattr(cls_or_slf,name)\n        elif hasattr(param_obj,'attribs'):\n            value = [cls_or_slf.param.inspect_value(a) for a in param_obj.attribs]\n        elif not hasattr(param_obj,'_inspect'):\n            value = getattr(cls_or_slf,name)\n        else:\n            if isinstance(cls_or_slf,type):\n                value = param_obj._inspect(None,cls_or_slf)\n            else:\n                value = param_obj._inspect(cls_or_slf,None)\n\n        return value", "response": "Return the current value of the named attribute without modifying it."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a mapping between any declared outputs and a tuple of the declared Parameter type the output method and the parameter index into the output.", "response": "def outputs(self_):\n        \"\"\"\n        Returns a mapping between any declared outputs and a tuple\n        of the declared Parameter type, the output method, and the\n        index into the output if multiple outputs are returned.\n        \"\"\"\n        outputs = {}\n        for cls in classlist(self_.cls):\n            for name in dir(cls):\n                method = getattr(self_.self_or_cls, name)\n                dinfo = getattr(method, '_dinfo', {})\n                if 'outputs' not in dinfo:\n                    continue\n                for override, otype, idx in dinfo['outputs']:\n                    if override is not None:\n                        name = override\n                    outputs[name] = (otype, method, idx)\n        return outputs"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unwatch(self_,watcher):\n        try:\n            self_._watch('remove',watcher)\n        except:\n            self_.warning('No such watcher {watcher} to remove.'.format(watcher=watcher))", "response": "Unwatch a specific watcher."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef defaults(self_):\n        self = self_.self\n        d = {}\n        for param_name,param in self.param.objects('existing').items():\n            if param.constant:\n                pass\n            elif param.instantiate:\n                self.param._instantiate_param(param,dict_=d,key=param_name)\n            else:\n                d[param_name]=param.default\n        return d", "response": "Return a dictionary of all non - constant parameters and their default values."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprints a message to the database.", "response": "def __db_print(self_,level,msg,*args,**kw):\n        \"\"\"\n        Calls the logger returned by the get_logger() function,\n        prepending the result of calling dbprint_prefix() (if any).\n\n        See python's logging module for details.\n        \"\"\"\n        self_or_cls = self_.self_or_cls\n        if get_logger(name=self_or_cls.name).isEnabledFor(level):\n\n            if dbprint_prefix and callable(dbprint_prefix):\n                msg = dbprint_prefix() + \": \" + msg  # pylint: disable-msg=E1102\n\n            get_logger(name=self_or_cls.name).log(level, msg, *args, **kw)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef print_param_values(self_):\n        self = self_.self\n        for name,val in self.param.get_param_values():\n            print('%s.%s = %s' % (self.name,name,val))", "response": "Print the values of all this object s Parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef warning(self_, msg,*args,**kw):\n        if not warnings_as_exceptions:\n            global warning_count\n            warning_count+=1\n            self_.__db_print(WARNING,msg,*args,**kw)\n        else:\n            raise Exception(\"Warning: \" + msg % args)", "response": "Print msg merged with args as a warning."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprint msg merged with args as a message.", "response": "def message(self_,msg,*args,**kw):\n        \"\"\"\n        Print msg merged with args as a message.\n\n        See Python's logging module for details of message formatting.\n        \"\"\"\n        self_.__db_print(INFO,msg,*args,**kw)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef verbose(self_,msg,*args,**kw):\n        self_.__db_print(VERBOSE,msg,*args,**kw)", "response": "Print msg merged with args as a verbose message."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprint msg merged with args as a debugging statement.", "response": "def debug(self_,msg,*args,**kw):\n        \"\"\"\n        Print msg merged with args as a debugging statement.\n\n        See Python's logging module for details of message formatting.\n        \"\"\"\n        self_.__db_print(DEBUG,msg,*args,**kw)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlook for Parameter values in superclasses of this Parameterized class. Ordinarily, when a Python object is instantiated, attributes not given values in the constructor will inherit the value given in the object's class, or in its superclasses. For Parameters owned by Parameterized classes, we have implemented an additional level of default lookup, should this ordinary lookup return only None. In such a case, i.e. when no non-None value was found for a Parameter by the usual inheritance mechanisms, we explicitly look for Parameters with the same name in superclasses of this Parameterized class, and use the first such value that we find. The goal is to be able to set the default value (or other slots) of a Parameter within a Parameterized class, just as we can set values for non-Parameter objects in Parameterized classes, and have the values inherited through the Parameterized hierarchy as usual. Note that instantiate is handled differently: if there is a parameter with the same name in one of the superclasses with instantiate set to True, this parameter will inherit instatiate=True.", "response": "def __param_inheritance(mcs,param_name,param):\n        \"\"\"\n        Look for Parameter values in superclasses of this\n        Parameterized class.\n\n        Ordinarily, when a Python object is instantiated, attributes\n        not given values in the constructor will inherit the value\n        given in the object's class, or in its superclasses.  For\n        Parameters owned by Parameterized classes, we have implemented\n        an additional level of default lookup, should this ordinary\n        lookup return only None.\n\n        In such a case, i.e. when no non-None value was found for a\n        Parameter by the usual inheritance mechanisms, we explicitly\n        look for Parameters with the same name in superclasses of this\n        Parameterized class, and use the first such value that we\n        find.\n\n        The goal is to be able to set the default value (or other\n        slots) of a Parameter within a Parameterized class, just as we\n        can set values for non-Parameter objects in Parameterized\n        classes, and have the values inherited through the\n        Parameterized hierarchy as usual.\n\n        Note that instantiate is handled differently: if there is a\n        parameter with the same name in one of the superclasses with\n        instantiate set to True, this parameter will inherit\n        instatiate=True.\n        \"\"\"\n        # get all relevant slots (i.e. slots defined in all\n        # superclasses of this parameter)\n        slots = {}\n        for p_class in classlist(type(param))[1::]:\n            slots.update(dict.fromkeys(p_class.__slots__))\n\n\n        # note for some eventual future: python 3.6+ descriptors grew\n        # __set_name__, which could replace this and _set_names\n        setattr(param,'owner',mcs)\n        del slots['owner']\n\n        # backwards compatibility (see Composite parameter)\n        if 'objtype' in slots:\n            setattr(param,'objtype',mcs)\n            del slots['objtype']\n\n        # instantiate is handled specially\n        for superclass in classlist(mcs)[::-1]:\n            super_param = superclass.__dict__.get(param_name)\n            if isinstance(super_param, Parameter) and super_param.instantiate is True:\n                param.instantiate=True\n        del slots['instantiate']\n\n\n        for slot in slots.keys():\n            superclasses = iter(classlist(mcs)[::-1])\n\n            # Search up the hierarchy until param.slot (which has to\n            # be obtained using getattr(param,slot)) is not None, or\n            # we run out of classes to search.\n            while getattr(param,slot) is None:\n                try:\n                    param_super_class = next(superclasses)\n                except StopIteration:\n                    break\n\n                new_param = param_super_class.__dict__.get(param_name)\n                if new_param is not None and hasattr(new_param,slot):\n                    # (slot might not be there because could be a more\n                    # general type of Parameter)\n                    new_value = getattr(new_param,slot)\n                    setattr(param,slot,new_value)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the Parameter class attribute and the class itself if it is a Parameter class attribute.", "response": "def get_param_descriptor(mcs,param_name):\n        \"\"\"\n        Goes up the class hierarchy (starting from the current class)\n        looking for a Parameter class attribute param_name. As soon as\n        one is found as a class attribute, that Parameter is returned\n        along with the class in which it is declared.\n        \"\"\"\n        classes = classlist(mcs)\n        for c in classes[::-1]:\n            attribute = c.__dict__.get(param_name)\n            if isinstance(attribute,Parameter):\n                return attribute,c\n        return None,None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a dictionary containing items from the originally overridden object whose names are parameters of the overridden object.", "response": "def param_keywords(self):\n        \"\"\"\n        Return a dictionary containing items from the originally\n        supplied dict_ whose names are parameters of the\n        overridden object (i.e. not extra keywords/parameters).\n        \"\"\"\n        return dict((key, self[key]) for key in self if key not in self.extra_keywords())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprinting a warning if the parameters contains something that is not a Parameter of the overridden object.", "response": "def _check_params(self,params):\n        \"\"\"\n        Print a warning if params contains something that is not a\n        Parameter of the overridden object.\n        \"\"\"\n        overridden_object_params = list(self._overridden.param)\n        for item in params:\n            if item not in overridden_object_params:\n                self.param.warning(\"'%s' will be ignored (not a Parameter).\",item)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextracting any items in params that are not also also parameters of the overridden object.", "response": "def _extract_extra_keywords(self,params):\n        \"\"\"\n        Return any items in params that are not also\n        parameters of the overridden object.\n        \"\"\"\n        extra_keywords = {}\n        overridden_object_params = list(self._overridden.param)\n        for name, val in params.items():\n            if name not in overridden_object_params:\n                extra_keywords[name]=val\n                # CEBALERT: should we remove name from params\n                # (i.e. del params[name]) so that it's only available\n                # via extra_keywords()?\n        return extra_keywords"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning an instance of this class copying parameters from any existing instance provided.", "response": "def instance(self_or_cls,**params):\n        \"\"\"\n        Return an instance of this class, copying parameters from any\n        existing instance provided.\n        \"\"\"\n\n        if isinstance (self_or_cls,ParameterizedMetaclass):\n            cls = self_or_cls\n        else:\n            p = params\n            params = dict(self_or_cls.get_param_values())\n            params.update(p)\n            params.pop('name')\n            cls = self_or_cls.__class__\n\n        inst=Parameterized.__new__(cls)\n        Parameterized.__init__(inst,**params)\n        if 'name' in params:  inst.__name__ = params['name']\n        else:                 inst.__name__ = self_or_cls.name\n        return inst"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a string representation of the current object.", "response": "def script_repr(self,imports=[],prefix=\"    \"):\n        \"\"\"\n        Same as Parameterized.script_repr, except that X.classname(Y\n        is replaced with X.classname.instance(Y\n        \"\"\"\n        return self.pprint(imports,prefix,unknown_value='',qualify=True,\n                           separator=\"\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprinting the object as a string.", "response": "def pprint(self, imports=None, prefix=\"\\n    \",unknown_value='<?>',\n               qualify=False, separator=\"\"):\n        \"\"\"\n        Same as Parameterized.pprint, except that X.classname(Y\n        is replaced with X.classname.instance(Y\n        \"\"\"\n        r = Parameterized.pprint(self,imports,prefix,\n                                 unknown_value=unknown_value,\n                                 qualify=qualify,separator=separator)\n        classname=self.__class__.__name__\n        return r.replace(\".%s(\"%classname,\".%s.instance(\"%classname)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds a directory containing all Sass and CSS files in the path.", "response": "def build_directory(\n    sass_path, css_path, output_style='nested',\n    _root_sass=None, _root_css=None, strip_extension=False,\n):\n    \"\"\"Compiles all Sass/SCSS files in ``path`` to CSS.\n\n    :param sass_path: the path of the directory which contains source files\n                      to compile\n    :type sass_path: :class:`str`, :class:`basestring`\n    :param css_path: the path of the directory compiled CSS files will go\n    :type css_path: :class:`str`, :class:`basestring`\n    :param output_style: an optional coding style of the compiled result.\n                         choose one of: ``'nested'`` (default), ``'expanded'``,\n                         ``'compact'``, ``'compressed'``\n    :type output_style: :class:`str`\n    :returns: a dictionary of source filenames to compiled CSS filenames\n    :rtype: :class:`collections.abc.Mapping`\n\n    .. versionadded:: 0.6.0\n       The ``output_style`` parameter.\n\n    \"\"\"\n    if _root_sass is None or _root_css is None:\n        _root_sass = sass_path\n        _root_css = css_path\n    result = {}\n    if not os.path.isdir(css_path):\n        os.mkdir(css_path)\n    for name in os.listdir(sass_path):\n        sass_fullname = os.path.join(sass_path, name)\n        if SUFFIX_PATTERN.search(name) and os.path.isfile(sass_fullname):\n            if name[0] == '_':\n                # Do not compile if it's partial\n                continue\n            if strip_extension:\n                name, _ = os.path.splitext(name)\n            css_fullname = os.path.join(css_path, name) + '.css'\n            css = compile(\n                filename=sass_fullname,\n                output_style=output_style,\n                include_paths=[_root_sass],\n            )\n            with io.open(\n                css_fullname, 'w', encoding='utf-8', newline='',\n            ) as css_file:\n                css_file.write(css)\n            result[os.path.relpath(sass_fullname, _root_sass)] = \\\n                os.path.relpath(css_fullname, _root_css)\n        elif os.path.isdir(sass_fullname):\n            css_fullname = os.path.join(css_path, name)\n            subresult = build_directory(\n                sass_fullname, css_fullname,\n                output_style=output_style,\n                _root_sass=_root_sass,\n                _root_css=_root_css,\n                strip_extension=strip_extension,\n            )\n            result.update(subresult)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef resolve_filename(self, package_dir, filename):\n        sass_path = os.path.join(package_dir, self.sass_path, filename)\n        if self.strip_extension:\n            filename, _ = os.path.splitext(filename)\n        css_filename = filename + '.css'\n        css_path = os.path.join(package_dir, self.css_path, css_filename)\n        return sass_path, css_path", "response": "Resolves the filename of the Sass source and CSS source that will be generated according to package_dir and filename."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef unresolve_filename(self, package_dir, filename):\n        filename, _ = os.path.splitext(filename)\n        if self.strip_extension:\n            for ext in ('.scss', '.sass'):\n                test_path = os.path.join(\n                    package_dir, self.sass_path, filename + ext,\n                )\n                if os.path.exists(test_path):\n                    return filename + ext\n            else:  # file not found, let it error with `.scss` extension\n                return filename + '.scss'\n        else:\n            return filename", "response": "Returns the probable source path from the output filename."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef build(self, package_dir, output_style='nested'):\n        sass_path = os.path.join(package_dir, self.sass_path)\n        css_path = os.path.join(package_dir, self.css_path)\n        css_files = build_directory(\n            sass_path, css_path,\n            output_style=output_style,\n            strip_extension=self.strip_extension,\n        ).values()\n        return frozenset(\n            os.path.join(self.css_path, filename)\n            for filename in css_files\n        )", "response": "Builds the Sass and SCSS files in the specified package directory."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef build_one(self, package_dir, filename, source_map=False):\n        sass_filename, css_filename = self.resolve_filename(\n            package_dir, filename,\n        )\n        root_path = os.path.join(package_dir, self.sass_path)\n        css_path = os.path.join(package_dir, self.css_path, css_filename)\n        if source_map:\n            source_map_path = css_filename + '.map'\n            css, source_map = compile(\n                filename=sass_filename,\n                include_paths=[root_path],\n                source_map_filename=source_map_path,  # FIXME\n                output_filename_hint=css_path,\n            )\n        else:\n            css = compile(filename=sass_filename, include_paths=[root_path])\n            source_map_path = None\n            source_map = None\n        css_folder = os.path.dirname(css_path)\n        if not os.path.exists(css_folder):\n            os.makedirs(css_folder)\n        with io.open(css_path, 'w', encoding='utf-8', newline='') as f:\n            f.write(css)\n        if source_map:\n            # Source maps are JSON, and JSON has to be UTF-8 encoded\n            with io.open(\n                source_map_path, 'w', encoding='utf-8', newline='',\n            ) as f:\n                f.write(source_map)\n        return css_filename", "response": "Builds one Sass file and returns the path to the CSS file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _validate_importers(importers):\n    # They could have no importers, that's chill\n    if importers is None:\n        return None\n\n    def _to_importer(priority, func):\n        assert isinstance(priority, int), priority\n        assert callable(func), func\n        return (priority, _importer_callback_wrapper(func))\n\n    # Our code assumes tuple of tuples\n    return tuple(_to_importer(priority, func) for priority, func in importers)", "response": "Validates the importers and decorates the callables with our output\n    formatter."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef compile(**kwargs):\n    modes = set()\n    for mode_name in MODES:\n        if mode_name in kwargs:\n            modes.add(mode_name)\n    if not modes:\n        raise TypeError('choose one at least in ' + and_join(MODES))\n    elif len(modes) > 1:\n        raise TypeError(\n            and_join(modes) + ' are exclusive each other; '\n            'cannot be used at a time',\n        )\n    precision = kwargs.pop('precision', 5)\n    output_style = kwargs.pop('output_style', 'nested')\n    if not isinstance(output_style, string_types):\n        raise TypeError(\n            'output_style must be a string, not ' +\n            repr(output_style),\n        )\n    try:\n        output_style = OUTPUT_STYLES[output_style]\n    except KeyError:\n        raise CompileError(\n            '{} is unsupported output_style; choose one of {}'\n            ''.format(output_style, and_join(OUTPUT_STYLES)),\n        )\n    source_comments = kwargs.pop('source_comments', False)\n    if source_comments in SOURCE_COMMENTS:\n        if source_comments == 'none':\n            deprecation_message = (\n                'you can simply pass False to '\n                \"source_comments instead of 'none'\"\n            )\n            source_comments = False\n        elif source_comments in ('line_numbers', 'default'):\n            deprecation_message = (\n                'you can simply pass True to '\n                \"source_comments instead of \" +\n                repr(source_comments)\n            )\n            source_comments = True\n        else:\n            deprecation_message = (\n                \"you don't have to pass 'map' to \"\n                'source_comments but just need to '\n                'specify source_map_filename'\n            )\n            source_comments = False\n        warnings.warn(\n            \"values like 'none', 'line_numbers', and 'map' for \"\n            'the source_comments parameter are deprecated; ' +\n            deprecation_message,\n            FutureWarning,\n        )\n    if not isinstance(source_comments, bool):\n        raise TypeError(\n            'source_comments must be bool, not ' +\n            repr(source_comments),\n        )\n    fs_encoding = sys.getfilesystemencoding() or sys.getdefaultencoding()\n\n    def _get_file_arg(key):\n        ret = kwargs.pop(key, None)\n        if ret is not None and not isinstance(ret, string_types):\n            raise TypeError('{} must be a string, not {!r}'.format(key, ret))\n        elif isinstance(ret, text_type):\n            ret = ret.encode(fs_encoding)\n        if ret and 'filename' not in modes:\n            raise CompileError(\n                '{} is only available with filename= keyword argument since '\n                'has to be aware of it'.format(key),\n            )\n        return ret\n\n    source_map_filename = _get_file_arg('source_map_filename')\n    output_filename_hint = _get_file_arg('output_filename_hint')\n\n    source_map_contents = kwargs.pop('source_map_contents', False)\n    source_map_embed = kwargs.pop('source_map_embed', False)\n    omit_source_map_url = kwargs.pop('omit_source_map_url', False)\n    source_map_root = kwargs.pop('source_map_root', None)\n\n    if isinstance(source_map_root, text_type):\n        source_map_root = source_map_root.encode('utf-8')\n\n    # #208: cwd is always included in include paths\n    include_paths = (os.getcwd(),)\n    include_paths += tuple(kwargs.pop('include_paths', ()) or ())\n    include_paths = os.pathsep.join(include_paths)\n    if isinstance(include_paths, text_type):\n        include_paths = include_paths.encode(fs_encoding)\n\n    custom_functions = kwargs.pop('custom_functions', ())\n    if isinstance(custom_functions, collections_abc.Mapping):\n        custom_functions = [\n            SassFunction.from_lambda(name, lambda_)\n            for name, lambda_ in custom_functions.items()\n        ]\n    elif isinstance(\n            custom_functions,\n            (collections_abc.Set, collections_abc.Sequence),\n    ):\n        custom_functions = [\n            func if isinstance(func, SassFunction)\n            else SassFunction.from_named_function(func)\n            for func in custom_functions\n        ]\n    else:\n        raise TypeError(\n            'custom_functions must be one of:\\n'\n            '- a set/sequence of {0.__module__}.{0.__name__} objects,\\n'\n            '- a mapping of function name strings to lambda functions,\\n'\n            '- a set/sequence of named functions,\\n'\n            'not {1!r}'.format(SassFunction, custom_functions),\n        )\n\n    if kwargs.pop('custom_import_extensions', None) is not None:\n        warnings.warn(\n            '`custom_import_extensions` has no effect and will be removed in '\n            'a future version.',\n            FutureWarning,\n        )\n\n    importers = _validate_importers(kwargs.pop('importers', None))\n\n    if 'string' in modes:\n        string = kwargs.pop('string')\n        if isinstance(string, text_type):\n            string = string.encode('utf-8')\n        indented = kwargs.pop('indented', False)\n        if not isinstance(indented, bool):\n            raise TypeError(\n                'indented must be bool, not ' +\n                repr(source_comments),\n            )\n        _check_no_remaining_kwargs(compile, kwargs)\n        s, v = _sass.compile_string(\n            string, output_style, source_comments, include_paths, precision,\n            custom_functions, indented, importers,\n            source_map_contents, source_map_embed, omit_source_map_url,\n            source_map_root,\n        )\n        if s:\n            return v.decode('utf-8')\n    elif 'filename' in modes:\n        filename = kwargs.pop('filename')\n        if not isinstance(filename, string_types):\n            raise TypeError('filename must be a string, not ' + repr(filename))\n        elif not os.path.isfile(filename):\n            raise IOError('{!r} seems not a file'.format(filename))\n        elif isinstance(filename, text_type):\n            filename = filename.encode(fs_encoding)\n        _check_no_remaining_kwargs(compile, kwargs)\n        s, v, source_map = _sass.compile_filename(\n            filename, output_style, source_comments, include_paths, precision,\n            source_map_filename, custom_functions, importers,\n            output_filename_hint,\n            source_map_contents, source_map_embed, omit_source_map_url,\n            source_map_root,\n        )\n        if s:\n            v = v.decode('utf-8')\n            if source_map_filename:\n                source_map = source_map.decode('utf-8')\n                v = v, source_map\n            return v\n    elif 'dirname' in modes:\n        try:\n            search_path, output_path = kwargs.pop('dirname')\n        except ValueError:\n            raise ValueError(\n                'dirname must be a pair of (source_dir, '\n                'output_dir)',\n            )\n        _check_no_remaining_kwargs(compile, kwargs)\n        s, v = compile_dirname(\n            search_path, output_path, output_style, source_comments,\n            include_paths, precision, custom_functions, importers,\n            source_map_contents, source_map_embed, omit_source_map_url,\n            source_map_root,\n        )\n        if s:\n            return\n    else:\n        raise TypeError('something went wrong')\n    assert not s\n    raise CompileError(v)", "response": "r A function to compile a CSS file into a CSS string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef and_join(strings):\n    last = len(strings) - 1\n    if last == 0:\n        return strings[0]\n    elif last < 0:\n        return ''\n    iterator = enumerate(strings)\n    return ', '.join('and ' + s if i == last else s for i, s in iterator)", "response": "Join the given list of strings by commas with last conjuction."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmake a custom function wrapper of the given lambda function.", "response": "def from_lambda(cls, name, lambda_):\n        \"\"\"Make a :class:`SassFunction` object from the given ``lambda_``\n        function.  Since lambda functions don't have their name, it need\n        its ``name`` as well.  Arguments are automatically inspected.\n\n        :param name: the function name\n        :type name: :class:`str`\n        :param lambda_: the actual lambda function to be called\n        :type lambda_: :class:`types.LambdaType`\n        :returns: a custom function wrapper of the ``lambda_`` function\n        :rtype: :class:`SassFunction`\n\n        \"\"\"\n        if PY2:  # pragma: no cover\n            a = inspect.getargspec(lambda_)\n            varargs, varkw, defaults, kwonlyargs = (\n                a.varargs, a.keywords, a.defaults, None,\n            )\n        else:  # pragma: no cover\n            a = inspect.getfullargspec(lambda_)\n            varargs, varkw, defaults, kwonlyargs = (\n                a.varargs, a.varkw, a.defaults, a.kwonlyargs,\n            )\n\n        if varargs or varkw or defaults or kwonlyargs:\n            raise TypeError(\n                'functions cannot have starargs or defaults: {} {}'.format(\n                    name, lambda_,\n                ),\n            )\n        return cls(name, a.args, lambda_)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmake a : class:`SassFunction` object from the named function.", "response": "def from_named_function(cls, function):\n        \"\"\"Make a :class:`SassFunction` object from the named ``function``.\n        Function name and arguments are automatically inspected.\n\n        :param function: the named function to be called\n        :type function: :class:`types.FunctionType`\n        :returns: a custom function wrapper of the ``function``\n        :rtype: :class:`SassFunction`\n\n        \"\"\"\n        if not getattr(function, '__name__', ''):\n            raise TypeError('function must be named')\n        return cls.from_lambda(function.__name__, function)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nverifying that value is an expected mapping of package to .", "response": "def validate_manifests(dist, attr, value):\n    \"\"\"Verifies that ``value`` is an expected mapping of package to\n    :class:`sassutils.builder.Manifest`.\n\n    \"\"\"\n    try:\n        Manifest.normalize_manifests(value)\n    except TypeError:\n        raise distutils.errors.DistutilsSetupError(\n            attr + \"must be a mapping object like: {'package.name': \"\n            \"sassutils.distutils.Manifest('sass/path')}, or as shorten form: \"\n            \"{'package.name': ('sass/path', 'css/path'}), not \" +\n            repr(value),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_package_dir(self, package):\n        path = package.split('.')\n        if not self.package_dir:\n            if path:\n                return os.path.join(*path)\n            return ''\n        tail = []\n        while path:\n            try:\n                pdir = self.package_dir['.'.join(path)]\n            except KeyError:\n                tail.insert(0, path[-1])\n                del path[-1]\n            else:\n                tail.insert(0, pdir)\n                return os.path.join(*tail)\n        else:\n            pdir = self.package_dir.get('')\n            if pdir is not None:\n                tail.insert(0, pdir)\n            if tail:\n                return os.path.join(*tail)\n            return ''", "response": "Returns the directory relative to the top of the source\n            distribution where package should be found."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef has_permission(self, request, view):\n        if not self.global_permissions:\n            return True\n\n        serializer_class = view.get_serializer_class()\n\n        assert serializer_class.Meta.model is not None, (\n            \"global_permissions set to true without a model \"\n            \"set on the serializer for '%s'\" % view.__class__.__name__\n        )\n\n        model_class = serializer_class.Meta.model\n\n        action_method_name = None\n        if hasattr(view, 'action'):\n            action = self._get_action(view.action)\n            action_method_name = \"has_{action}_permission\".format(action=action)\n            # If the specific action permission exists then use it, otherwise use general.\n            if hasattr(model_class, action_method_name):\n                return getattr(model_class, action_method_name)(request)\n\n        if request.method in permissions.SAFE_METHODS:\n            assert hasattr(model_class, 'has_read_permission'), \\\n                self._get_error_message(model_class, 'has_read_permission', action_method_name)\n            return model_class.has_read_permission(request)\n        else:\n            assert hasattr(model_class, 'has_write_permission'), \\\n                self._get_error_message(model_class, 'has_write_permission', action_method_name)\n            return model_class.has_write_permission(request)", "response": "Returns True if the user has permission for the current request."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef has_object_permission(self, request, view, obj):\n        if not self.object_permissions:\n            return True\n\n        serializer_class = view.get_serializer_class()\n        model_class = serializer_class.Meta.model\n        action_method_name = None\n        if hasattr(view, 'action'):\n            action = self._get_action(view.action)\n            action_method_name = \"has_object_{action}_permission\".format(action=action)\n            # If the specific action permission exists then use it, otherwise use general.\n            if hasattr(obj, action_method_name):\n                return getattr(obj, action_method_name)(request)\n\n        if request.method in permissions.SAFE_METHODS:\n            assert hasattr(obj, 'has_object_read_permission'), \\\n                self._get_error_message(model_class, 'has_object_read_permission', action_method_name)\n            return obj.has_object_read_permission(request)\n        else:\n            assert hasattr(obj, 'has_object_write_permission'), \\\n                self._get_error_message(model_class, 'has_object_write_permission', action_method_name)\n            return obj.has_object_write_permission(request)", "response": "Returns True if the object has permission for the given request."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting assertion error message depending on whether there are actions permissions methods defined.", "response": "def _get_error_message(self, model_class, method_name, action_method_name):\n        \"\"\"\n        Get assertion error message depending if there are actions permissions methods defined.\n        \"\"\"\n        if action_method_name:\n            return \"'{}' does not have '{}' or '{}' defined.\".format(model_class, method_name, action_method_name)\n        else:\n            return \"'{}' does not have '{}' defined.\".format(model_class, method_name)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbinding the fields to the parent object.", "response": "def bind(self, field_name, parent):\n        \"\"\"\n        Check the model attached to the serializer to see what methods are defined and save them.\n        \"\"\"\n        assert parent.Meta.model is not None, \\\n            \"DRYPermissions is used on '{}' without a model\".format(parent.__class__.__name__)\n\n        for action in self.actions:\n\n            if not self.object_only:\n                global_method_name = \"has_{action}_permission\".format(action=action)\n                if hasattr(parent.Meta.model, global_method_name):\n                    self.action_method_map[action] = {'global': global_method_name}\n\n            if not self.global_only:\n                object_method_name = \"has_object_{action}_permission\".format(action=action)\n                if hasattr(parent.Meta.model, object_method_name):\n                    if self.action_method_map.get(action, None) is None:\n                        self.action_method_map[action] = {}\n                    self.action_method_map[action]['object'] = object_method_name\n\n        super(DRYPermissionsField, self).bind(field_name, parent)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting the given value into a dictionary.", "response": "def to_representation(self, value):\n        \"\"\"\n        Calls the developer defined permission methods\n        (both global and object) and formats the results into a dictionary.\n        \"\"\"\n        results = {}\n        for action, method_names in self.action_method_map.items():\n            # If using global permissions and the global method exists for this action.\n            if not self.object_only and method_names.get('global', None) is not None:\n                results[action] = getattr(self.parent.Meta.model, method_names['global'])(self.context['request'])\n            # If using object permissions, the global permission did not already evaluate to False and the object\n            # method exists for this action.\n            if not self.global_only and results.get(action, True) and method_names.get('object', None) is not None:\n                results[action] = getattr(value, method_names['object'])(self.context['request'])\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef skip_prepare(func):\n    @wraps(func)\n    def _wrapper(self, *args, **kwargs):\n        value = func(self, *args, **kwargs)\n        return Data(value, should_prepare=False)\n    return _wrapper", "response": "A convenience decorator for indicating the raw data should not be prepared."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nusing for hooking up the all endpoints (including custom ones), this returns a wrapper function that creates a new instance of the resource class & calls the correct view method for it. :param view_type: Should be one of ``list``, ``detail`` or ``custom``. :type view_type: string :param init_args: (Optional) Positional params to be persisted along for instantiating the class itself. :param init_kwargs: (Optional) Keyword params to be persisted along for instantiating the class itself. :returns: View function", "response": "def as_view(cls, view_type, *init_args, **init_kwargs):\n        \"\"\"\n        Used for hooking up the all endpoints (including custom ones), this\n        returns a wrapper function that creates a new instance of the resource\n        class & calls the correct view method for it.\n\n        :param view_type: Should be one of ``list``, ``detail`` or ``custom``.\n        :type view_type: string\n\n        :param init_args: (Optional) Positional params to be persisted along\n            for instantiating the class itself.\n\n        :param init_kwargs: (Optional) Keyword params to be persisted along\n            for instantiating the class itself.\n\n        :returns: View function\n        \"\"\"\n        @wraps(cls)\n        def _wrapper(request, *args, **kwargs):\n            # Make a new instance so that no state potentially leaks between\n            # instances.\n            inst = cls(*init_args, **init_kwargs)\n            inst.request = request\n            return inst.handle(view_type, *args, **kwargs)\n\n        return _wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef build_error(self, err):\n        data = {\n            'error': err.args[0],\n        }\n\n        if self.is_debug():\n            # Add the traceback.\n            data['traceback'] = format_traceback(sys.exc_info())\n\n        body = self.serializer.serialize(data)\n        status = getattr(err, 'status', 500)\n        return self.build_response(body, status=status)", "response": "Builds an error response from an exception."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef deserialize(self, method, endpoint, body):\n        if endpoint == 'list':\n            return self.deserialize_list(body)\n\n        return self.deserialize_detail(body)", "response": "Deserializes the body of a request into a list or dict."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef serialize_list(self, data):\n        if data is None:\n            return ''\n\n        # Check for a ``Data``-like object. We should assume ``True`` (all\n        # data gets prepared) unless it's explicitly marked as not.\n        if not getattr(data, 'should_prepare', True):\n            prepped_data = data.value\n        else:\n            prepped_data = [self.prepare(item) for item in data]\n\n        final_data = self.wrap_list_response(prepped_data)\n        return self.serializer.serialize(final_data)", "response": "Serialize a list of items into a string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef serialize_detail(self, data):\n        if data is None:\n            return ''\n\n        # Check for a ``Data``-like object. We should assume ``True`` (all\n        # data gets prepared) unless it's explicitly marked as not.\n        if not getattr(data, 'should_prepare', True):\n            prepped_data = data.value\n        else:\n            prepped_data = self.prepare(data)\n\n        return self.serializer.serialize(prepped_data)", "response": "Serialize a single item in the format that is expected by the user."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef as_view(cls, view_type, *init_args, **init_kwargs):\n        global _method\n\n        new_cls = type(\n            cls.__name__ + '_' + _BridgeMixin.__name__ + '_restless',\n            (_BridgeMixin, cls._request_handler_base_,),\n            dict(\n                __resource_cls__=cls,\n                __resource_args__=init_args,\n                __resource_kwargs__=init_kwargs,\n                __resource_view_type__=view_type)\n        )\n\n        \"\"\"\n        Add required http-methods to the newly created class\n        We need to scan through MRO to find what functions users declared,\n        and then add corresponding http-methods used by Tornado.\n        \"\"\"\n        bases = inspect.getmro(cls)\n        bases = bases[0:bases.index(Resource)-1]\n        for k, v in cls.http_methods[view_type].items():\n            if any(v in base_cls.__dict__ for base_cls in bases):\n                setattr(new_cls, k.lower(), _method)\n\n        return new_cls", "response": "Return a subclass of tornado. web. RequestHandler and add required http - methods to the class."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef prepare(self, data):\n        result = {}\n\n        if not self.fields:\n            # No fields specified. Serialize everything.\n            return data\n\n        for fieldname, lookup in self.fields.items():\n            if isinstance(lookup, SubPreparer):\n                result[fieldname] = lookup.prepare(data)\n            else:\n                result[fieldname] = self.lookup_data(lookup, data)\n\n        return result", "response": "Handles transforming the provided data into the fielded data that should be exposed to the end user."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving a string and a dictionary of data attempts to descend through nested data looking for the value.", "response": "def lookup_data(self, lookup, data):\n        \"\"\"\n        Given a lookup string, attempts to descend through nested data looking for\n        the value.\n\n        Can work with either dictionary-alikes or objects (or any combination of\n        those).\n\n        Lookups should be a string. If it is a dotted path, it will be split on\n        ``.`` & it will traverse through to find the final value. If not, it will\n        simply attempt to find either a key or attribute of that name & return it.\n\n        Example::\n\n            >>> data = {\n            ...     'type': 'message',\n            ...     'greeting': {\n            ...         'en': 'hello',\n            ...         'fr': 'bonjour',\n            ...         'es': 'hola',\n            ...     },\n            ...     'person': Person(\n            ...         name='daniel'\n            ...     )\n            ... }\n            >>> lookup_data('type', data)\n            'message'\n            >>> lookup_data('greeting.en', data)\n            'hello'\n            >>> lookup_data('person.name', data)\n            'daniel'\n\n        \"\"\"\n        value = data\n        parts = lookup.split('.')\n\n        if not parts or not parts[0]:\n            return value\n\n        part = parts[0]\n        remaining_lookup = '.'.join(parts[1:])\n\n        if callable(getattr(data, 'keys', None)) and hasattr(data, '__getitem__'):\n            # Dictionary enough for us.\n            value = data[part]\n        elif data is not None:\n            # Assume it's an object.\n            value = getattr(data, part)\n\n        # Call if it's callable except if it's a Django DB manager instance\n        #   We check if is a manager by checking the db_manager (duck typing)\n        if callable(value) and not hasattr(value, 'db_manager'):\n            value = value()\n\n        if not remaining_lookup:\n            return value\n\n        # There's more to lookup, so dive in recursively.\n        return self.lookup_data(remaining_lookup, value)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prepare(self, data):\n        result = []\n\n        for item in self.get_inner_data(data):\n            result.append(self.preparer.prepare(item))\n\n        return result", "response": "Handles passing each item in the collection data to the configured\n        subpreparer."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives a ``name`` & an optional ``name_prefix``, this generates a name for a URL. :param name: The name for the URL (ex. 'detail') :type name: string :param name_prefix: (Optional) A prefix for the URL's name (for resolving). The default is ``None``, which will autocreate a prefix based on the class name. Ex: ``BlogPostResource`` -> ``api_blog_post_list`` :type name_prefix: string :returns: The final name :rtype: string", "response": "def build_url_name(cls, name, name_prefix=None):\n        \"\"\"\n        Given a ``name`` & an optional ``name_prefix``, this generates a name\n        for a URL.\n\n        :param name: The name for the URL (ex. 'detail')\n        :type name: string\n\n        :param name_prefix: (Optional) A prefix for the URL's name (for\n            resolving). The default is ``None``, which will autocreate a prefix\n            based on the class name. Ex: ``BlogPostResource`` ->\n            ``api_blog_post_list``\n        :type name_prefix: string\n\n        :returns: The final name\n        :rtype: string\n        \"\"\"\n        if name_prefix is None:\n            name_prefix = 'api_{}'.format(\n                cls.__name__.replace('Resource', '').lower()\n            )\n\n        name_prefix = name_prefix.rstrip('_')\n        return '_'.join([name_prefix, name])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef urls(cls, name_prefix=None):\n        return [\n            url(r'^$', cls.as_list(), name=cls.build_url_name('list', name_prefix)),\n            url(r'^(?P<pk>[\\w-]+)/$', cls.as_detail(), name=cls.build_url_name('detail', name_prefix)),\n        ]", "response": "A convenience method for hooking up the URLs."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef build_endpoint_name(cls, name, endpoint_prefix=None):\n        if endpoint_prefix is None:\n            endpoint_prefix = 'api_{}'.format(\n                cls.__name__.replace('Resource', '').lower()\n            )\n\n        endpoint_prefix = endpoint_prefix.rstrip('_')\n        return '_'.join([endpoint_prefix, name])", "response": "This function generates a name that can be used to lookup a resource in a specific endpoint."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a ``name`` & an optional ``routename_prefix``, this generates a name for a URL. :param name: The name for the URL (ex. 'detail') :type name: string :param routename_prefix: (Optional) A prefix for the URL's name (for resolving). The default is ``None``, which will autocreate a prefix based on the class name. Ex: ``BlogPostResource`` -> ``api_blogpost_list`` :type routename_prefix: string :returns: The final name :rtype: string", "response": "def build_routename(cls, name, routename_prefix=None):\n        \"\"\"\n        Given a ``name`` & an optional ``routename_prefix``, this generates a\n        name for a URL.\n\n        :param name: The name for the URL (ex. 'detail')\n        :type name: string\n\n        :param routename_prefix: (Optional) A prefix for the URL's name (for\n            resolving). The default is ``None``, which will autocreate a prefix\n            based on the class name. Ex: ``BlogPostResource`` ->\n            ``api_blogpost_list``\n        :type routename_prefix: string\n\n        :returns: The final name\n        :rtype: string\n        \"\"\"\n        if routename_prefix is None:\n            routename_prefix = 'api_{}'.format(\n                cls.__name__.replace('Resource', '').lower()\n            )\n\n        routename_prefix = routename_prefix.rstrip('_')\n        return '_'.join([routename_prefix, name])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_views(cls, config, rule_prefix, routename_prefix=None):\n        methods = ('GET', 'POST', 'PUT', 'DELETE')\n\n        config.add_route(\n            cls.build_routename('list', routename_prefix),\n            rule_prefix\n        )\n        config.add_view(\n            cls.as_list(),\n            route_name=cls.build_routename('list', routename_prefix),\n            request_method=methods\n        )\n\n        config.add_route(\n            cls.build_routename('detail', routename_prefix),\n            rule_prefix + '{name}/'\n        )\n        config.add_view(\n            cls.as_detail(),\n            route_name=cls.build_routename('detail', routename_prefix),\n            request_method=methods\n        )\n        return config", "response": "This method adds the routes and views to the config."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convert_mnist(directory, output_directory, output_filename=None,\n                  dtype=None):\n    \"\"\"Converts the MNIST dataset to HDF5.\n\n    Converts the MNIST dataset to an HDF5 dataset compatible with\n    :class:`fuel.datasets.MNIST`. The converted dataset is\n    saved as 'mnist.hdf5'.\n\n    This method assumes the existence of the following files:\n    `train-images-idx3-ubyte.gz`, `train-labels-idx1-ubyte.gz`\n    `t10k-images-idx3-ubyte.gz`, `t10k-labels-idx1-ubyte.gz`\n\n    It assumes the existence of the following files:\n\n    * `train-images-idx3-ubyte.gz`\n    * `train-labels-idx1-ubyte.gz`\n    * `t10k-images-idx3-ubyte.gz`\n    * `t10k-labels-idx1-ubyte.gz`\n\n    Parameters\n    ----------\n    directory : str\n        Directory in which input files reside.\n    output_directory : str\n        Directory in which to save the converted dataset.\n    output_filename : str, optional\n        Name of the saved dataset. Defaults to `None`, in which case a name\n        based on `dtype` will be used.\n    dtype : str, optional\n        Either 'float32', 'float64', or 'bool'. Defaults to `None`,\n        in which case images will be returned in their original\n        unsigned byte format.\n\n    Returns\n    -------\n    output_paths : tuple of str\n        Single-element tuple containing the path to the converted dataset.\n\n    \"\"\"\n    if not output_filename:\n        if dtype:\n            output_filename = 'mnist_{}.hdf5'.format(dtype)\n        else:\n            output_filename = 'mnist.hdf5'\n    output_path = os.path.join(output_directory, output_filename)\n    h5file = h5py.File(output_path, mode='w')\n\n    train_feat_path = os.path.join(directory, TRAIN_IMAGES)\n    train_features = read_mnist_images(train_feat_path, dtype)\n    train_lab_path = os.path.join(directory, TRAIN_LABELS)\n    train_labels = read_mnist_labels(train_lab_path)\n    test_feat_path = os.path.join(directory, TEST_IMAGES)\n    test_features = read_mnist_images(test_feat_path, dtype)\n    test_lab_path = os.path.join(directory, TEST_LABELS)\n    test_labels = read_mnist_labels(test_lab_path)\n    data = (('train', 'features', train_features),\n            ('train', 'targets', train_labels),\n            ('test', 'features', test_features),\n            ('test', 'targets', test_labels))\n    fill_hdf5_file(h5file, data)\n    h5file['features'].dims[0].label = 'batch'\n    h5file['features'].dims[1].label = 'channel'\n    h5file['features'].dims[2].label = 'height'\n    h5file['features'].dims[3].label = 'width'\n    h5file['targets'].dims[0].label = 'batch'\n    h5file['targets'].dims[1].label = 'index'\n\n    h5file.flush()\n    h5file.close()\n\n    return (output_path,)", "response": "Converts the MNIST dataset to HDF5."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fill_subparser(subparser):\n    subparser.add_argument(\n        \"--dtype\", help=\"dtype to save to; by default, images will be \" +\n        \"returned in their original unsigned byte format\",\n        choices=('float32', 'float64', 'bool'), type=str, default=None)\n    return convert_mnist", "response": "Sets up a subparser to convert the MNIST dataset files."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_mnist_images(filename, dtype=None):\n    with gzip.open(filename, 'rb') as f:\n        magic, number, rows, cols = struct.unpack('>iiii', f.read(16))\n        if magic != MNIST_IMAGE_MAGIC:\n            raise ValueError(\"Wrong magic number reading MNIST image file\")\n        array = numpy.frombuffer(f.read(), dtype='uint8')\n        array = array.reshape((number, 1, rows, cols))\n    if dtype:\n        dtype = numpy.dtype(dtype)\n\n        if dtype.kind == 'b':\n            # If the user wants Booleans, threshold at half the range.\n            array = array >= 128\n        elif dtype.kind == 'f':\n            # Otherwise, just convert.\n            array = array.astype(dtype)\n            array /= 255.\n        else:\n            raise ValueError(\"Unknown dtype to convert MNIST to\")\n    return array", "response": "Read MNIST images from the original ubyte file format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading MNIST labels from the original ubyte file format.", "response": "def read_mnist_labels(filename):\n    \"\"\"Read MNIST labels from the original ubyte file format.\n\n    Parameters\n    ----------\n    filename : str\n        Filename/path from which to read labels.\n\n    Returns\n    -------\n    labels : :class:`~numpy.ndarray`, shape (nlabels, 1)\n        A one-dimensional unsigned byte array containing the\n        labels as integers.\n\n    \"\"\"\n    with gzip.open(filename, 'rb') as f:\n        magic, _ = struct.unpack('>ii', f.read(8))\n        if magic != MNIST_LABEL_MAGIC:\n            raise ValueError(\"Wrong magic number reading MNIST label file\")\n        array = numpy.frombuffer(f.read(), dtype='uint8')\n    array = array.reshape(array.size, 1)\n    return array"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef prepare_metadata(devkit_archive, test_groundtruth_path):\n    # Read what's necessary from the development kit.\n    synsets, cost_matrix, raw_valid_groundtruth = read_devkit(devkit_archive)\n\n    # Mapping to take WordNet IDs to our internal 0-999 encoding.\n    wnid_map = dict(zip((s.decode('utf8') for s in synsets['WNID']),\n                        xrange(1000)))\n\n    # Map the 'ILSVRC2010 ID' to our zero-based ID.\n    ilsvrc_id_to_zero_based = dict(zip(synsets['ILSVRC2010_ID'],\n                                   xrange(len(synsets))))\n\n    # Map the validation set groundtruth to 0-999 labels.\n    valid_groundtruth = [ilsvrc_id_to_zero_based[id_]\n                         for id_ in raw_valid_groundtruth]\n\n    # Raw test data groundtruth, ILSVRC2010 IDs.\n    raw_test_groundtruth = numpy.loadtxt(test_groundtruth_path,\n                                         dtype=numpy.int16)\n\n    # Map the test set groundtruth to 0-999 labels.\n    test_groundtruth = [ilsvrc_id_to_zero_based[id_]\n                        for id_ in raw_test_groundtruth]\n\n    # Ascertain the number of filenames to prepare appropriate sized\n    # arrays.\n    n_train = int(synsets['num_train_images'].sum())\n    log.info('Training set: {} images'.format(n_train))\n    log.info('Validation set: {} images'.format(len(valid_groundtruth)))\n    log.info('Test set: {} images'.format(len(test_groundtruth)))\n    n_total = n_train + len(valid_groundtruth) + len(test_groundtruth)\n    log.info('Total (train/valid/test): {} images'.format(n_total))\n    return n_train, valid_groundtruth, test_groundtruth, wnid_map", "response": "Extract dataset metadata required for HDF5 file setup."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate datasets within a given HDF5 file.", "response": "def prepare_hdf5_file(hdf5_file, n_train, n_valid, n_test):\n    \"\"\"Create datasets within a given HDF5 file.\n\n    Parameters\n    ----------\n    hdf5_file : :class:`h5py.File` instance\n        HDF5 file handle to which to write.\n    n_train : int\n        The number of training set examples.\n    n_valid : int\n        The number of validation set examples.\n    n_test : int\n        The number of test set examples.\n\n    \"\"\"\n    n_total = n_train + n_valid + n_test\n    splits = create_splits(n_train, n_valid, n_test)\n    hdf5_file.attrs['split'] = H5PYDataset.create_split_array(splits)\n    vlen_dtype = h5py.special_dtype(vlen=numpy.dtype('uint8'))\n    hdf5_file.create_dataset('encoded_images', shape=(n_total,),\n                             dtype=vlen_dtype)\n    hdf5_file.create_dataset('targets', shape=(n_total, 1), dtype=numpy.int16)\n    hdf5_file.create_dataset('filenames', shape=(n_total, 1), dtype='S32')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef process_train_set(hdf5_file, train_archive, patch_archive, n_train,\n                      wnid_map, shuffle_seed=None):\n    \"\"\"Process the ILSVRC2010 training set.\n\n    Parameters\n    ----------\n    hdf5_file : :class:`h5py.File` instance\n        HDF5 file handle to which to write. Assumes `features`, `targets`\n        and `filenames` already exist and have first dimension larger than\n        `n_train`.\n    train_archive :  str or file-like object\n        Filename or file handle for the TAR archive of training images.\n    patch_archive :  str or file-like object\n        Filename or file handle for the TAR archive of patch images.\n    n_train : int\n        The number of items in the training set.\n    wnid_map : dict\n        A dictionary mapping WordNet IDs to class indices.\n    shuffle_seed : int or sequence, optional\n        Seed for a NumPy random number generator that permutes the\n        training set on disk. If `None`, no permutation is performed\n        (this is the default).\n\n    \"\"\"\n    producer = partial(train_set_producer, train_archive=train_archive,\n                       patch_archive=patch_archive, wnid_map=wnid_map)\n    consumer = partial(image_consumer, hdf5_file=hdf5_file,\n                       num_expected=n_train, shuffle_seed=shuffle_seed)\n    producer_consumer(producer, consumer)", "response": "Process the ILSVRC2010 training set."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef train_set_producer(socket, train_archive, patch_archive, wnid_map):\n    patch_images = extract_patch_images(patch_archive, 'train')\n    num_patched = 0\n    with tar_open(train_archive) as tar:\n        for inner_tar_info in tar:\n            with tar_open(tar.extractfile(inner_tar_info.name)) as inner:\n                wnid = inner_tar_info.name.split('.')[0]\n                class_index = wnid_map[wnid]\n                filenames = sorted(info.name for info in inner\n                                   if info.isfile())\n                images_gen = (load_from_tar_or_patch(inner, filename,\n                                                     patch_images)\n                              for filename in filenames)\n                pathless_filenames = (os.path.split(fn)[-1]\n                                      for fn in filenames)\n                stream = equizip(pathless_filenames, images_gen)\n                for image_fn, (image_data, patched) in stream:\n                    if patched:\n                        num_patched += 1\n                    socket.send_pyobj((image_fn, class_index), zmq.SNDMORE)\n                    socket.send(image_data)\n    if num_patched != len(patch_images):\n        raise ValueError('not all patch images were used')", "response": "Load and send images from the training set TAR file or patch images."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef image_consumer(socket, hdf5_file, num_expected, shuffle_seed=None,\n                   offset=0):\n    \"\"\"Fill an HDF5 file with incoming images from a socket.\n\n    Parameters\n    ----------\n    socket : :class:`zmq.Socket`\n        PULL socket on which to receive images.\n    hdf5_file : :class:`h5py.File` instance\n        HDF5 file handle to which to write. Assumes `features`, `targets`\n        and `filenames` already exist and have first dimension larger than\n        `sum(images_per_class)`.\n    num_expected : int\n        The number of items we expect to be sent over the socket.\n    shuffle_seed : int or sequence, optional\n        Seed for a NumPy random number generator that permutes the\n        images on disk.\n    offset : int, optional\n        The offset in the HDF5 datasets at which to start writing\n        received examples. Defaults to 0.\n\n    \"\"\"\n    with progress_bar('images', maxval=num_expected) as pb:\n        if shuffle_seed is None:\n            index_gen = iter(xrange(num_expected))\n        else:\n            rng = numpy.random.RandomState(shuffle_seed)\n            index_gen = iter(rng.permutation(num_expected))\n        for i, num in enumerate(index_gen):\n            image_filename, class_index = socket.recv_pyobj(zmq.SNDMORE)\n            image_data = numpy.fromstring(socket.recv(), dtype='uint8')\n            _write_to_hdf5(hdf5_file, num + offset, image_filename,\n                           image_data, class_index)\n            pb.update(i + 1)", "response": "This function is used to fill an HDF5 file with incoming images from a socket."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process_other_set(hdf5_file, which_set, image_archive, patch_archive,\n                      groundtruth, offset):\n    \"\"\"Process the validation or test set.\n\n    Parameters\n    ----------\n    hdf5_file : :class:`h5py.File` instance\n        HDF5 file handle to which to write. Assumes `features`, `targets`\n        and `filenames` already exist and have first dimension larger than\n        `sum(images_per_class)`.\n    which_set : str\n        Which set of images is being processed. One of 'train', 'valid',\n        'test'.  Used for extracting the appropriate images from the patch\n        archive.\n    image_archive : str or file-like object\n        The filename or file-handle for the TAR archive containing images.\n    patch_archive : str or file-like object\n        Filename or file handle for the TAR archive of patch images.\n    groundtruth : iterable\n        Iterable container containing scalar 0-based class index for each\n        image, sorted by filename.\n    offset : int\n        The offset in the HDF5 datasets at which to start writing.\n\n    \"\"\"\n    producer = partial(other_set_producer, image_archive=image_archive,\n                       patch_archive=patch_archive,\n                       groundtruth=groundtruth, which_set=which_set)\n    consumer = partial(image_consumer, hdf5_file=hdf5_file,\n                       num_expected=len(groundtruth), offset=offset)\n    producer_consumer(producer, consumer)", "response": "Process the validation or test set."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef other_set_producer(socket, which_set, image_archive, patch_archive,\n                       groundtruth):\n    \"\"\"Push image files read from the valid/test set TAR to a socket.\n\n    Parameters\n    ----------\n    socket : :class:`zmq.Socket`\n        PUSH socket on which to send images.\n    which_set : str\n        Which set of images is being processed. One of 'train', 'valid',\n        'test'.  Used for extracting the appropriate images from the patch\n        archive.\n    image_archive : str or file-like object\n        The filename or file-handle for the TAR archive containing images.\n    patch_archive : str or file-like object\n        Filename or file handle for the TAR archive of patch images.\n    groundtruth : iterable\n        Iterable container containing scalar 0-based class index for each\n        image, sorted by filename.\n\n    \"\"\"\n    patch_images = extract_patch_images(patch_archive, which_set)\n    num_patched = 0\n    with tar_open(image_archive) as tar:\n        filenames = sorted(info.name for info in tar if info.isfile())\n        images = (load_from_tar_or_patch(tar, filename, patch_images)\n                  for filename in filenames)\n        pathless_filenames = (os.path.split(fn)[-1] for fn in filenames)\n        image_iterator = equizip(images, pathless_filenames, groundtruth)\n        for (image_data, patched), filename, class_index in image_iterator:\n            if patched:\n                num_patched += 1\n            socket.send_pyobj((filename, class_index), zmq.SNDMORE)\n            socket.send(image_data, copy=False)\n    if num_patched != len(patch_images):\n        raise Exception", "response": "Produce a list of images from the other set TAR."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading an image from a TAR file or patch dictionary.", "response": "def load_from_tar_or_patch(tar, image_filename, patch_images):\n    \"\"\"Do everything necessary to process an image inside a TAR.\n\n    Parameters\n    ----------\n    tar : `TarFile` instance\n        The tar from which to read `image_filename`.\n    image_filename : str\n        Fully-qualified path inside of `tar` from which to read an\n        image file.\n    patch_images : dict\n        A dictionary containing filenames (without path) of replacements\n        to be substituted in place of the version of the same file found\n        in `tar`.\n\n    Returns\n    -------\n    image_data : bytes\n        The JPEG bytes representing either the image from the TAR archive\n        or its replacement from the patch dictionary.\n    patched : bool\n        True if the image was retrieved from the patch dictionary. False\n        if it was retrieved from the TAR file.\n\n    \"\"\"\n    patched = True\n    image_bytes = patch_images.get(os.path.basename(image_filename), None)\n    if image_bytes is None:\n        patched = False\n        try:\n            image_bytes = tar.extractfile(image_filename).read()\n            numpy.array(Image.open(io.BytesIO(image_bytes)))\n        except (IOError, OSError):\n            with gzip.GzipFile(fileobj=tar.extractfile(image_filename)) as gz:\n                image_bytes = gz.read()\n                numpy.array(Image.open(io.BytesIO(image_bytes)))\n    return image_bytes, patched"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_devkit(f):\n    with tar_open(f) as tar:\n        # Metadata table containing class hierarchy, textual descriptions, etc.\n        meta_mat = tar.extractfile(DEVKIT_META_PATH)\n        synsets, cost_matrix = read_metadata_mat_file(meta_mat)\n\n        # Raw validation data groundtruth, ILSVRC2010 IDs. Confusingly\n        # distributed inside the development kit archive.\n        raw_valid_groundtruth = numpy.loadtxt(tar.extractfile(\n            DEVKIT_VALID_GROUNDTRUTH_PATH), dtype=numpy.int16)\n    return synsets, cost_matrix, raw_valid_groundtruth", "response": "Read relevant information from the development kit archive."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef extract_patch_images(f, which_set):\n    if which_set not in ('train', 'valid', 'test'):\n        raise ValueError('which_set must be one of train, valid, or test')\n    which_set = 'val' if which_set == 'valid' else which_set\n    patch_images = {}\n    with tar_open(f) as tar:\n        for info_obj in tar:\n            if not info_obj.name.endswith('.JPEG'):\n                continue\n            # Pretty sure that '/' is used for tarfile regardless of\n            # os.path.sep, but I officially don't care about Windows.\n            tokens = info_obj.name.split('/')\n            file_which_set = tokens[-2]\n            if file_which_set != which_set:\n                continue\n            filename = tokens[-1]\n            patch_images[filename] = tar.extractfile(info_obj.name).read()\n    return patch_images", "response": "Extracts the patch images from a TAR file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef convert_cifar10(directory, output_directory,\n                    output_filename='cifar10.hdf5'):\n    \"\"\"Converts the CIFAR-10 dataset to HDF5.\n\n    Converts the CIFAR-10 dataset to an HDF5 dataset compatible with\n    :class:`fuel.datasets.CIFAR10`. The converted dataset is saved as\n    'cifar10.hdf5'.\n\n    It assumes the existence of the following file:\n\n    * `cifar-10-python.tar.gz`\n\n    Parameters\n    ----------\n    directory : str\n        Directory in which input files reside.\n    output_directory : str\n        Directory in which to save the converted dataset.\n    output_filename : str, optional\n        Name of the saved dataset. Defaults to 'cifar10.hdf5'.\n\n    Returns\n    -------\n    output_paths : tuple of str\n        Single-element tuple containing the path to the converted dataset.\n\n    \"\"\"\n    output_path = os.path.join(output_directory, output_filename)\n    h5file = h5py.File(output_path, mode='w')\n    input_file = os.path.join(directory, DISTRIBUTION_FILE)\n    tar_file = tarfile.open(input_file, 'r:gz')\n\n    train_batches = []\n    for batch in range(1, 6):\n        file = tar_file.extractfile(\n            'cifar-10-batches-py/data_batch_%d' % batch)\n        try:\n            if six.PY3:\n                array = cPickle.load(file, encoding='latin1')\n            else:\n                array = cPickle.load(file)\n            train_batches.append(array)\n        finally:\n            file.close()\n\n    train_features = numpy.concatenate(\n        [batch['data'].reshape(batch['data'].shape[0], 3, 32, 32)\n            for batch in train_batches])\n    train_labels = numpy.concatenate(\n        [numpy.array(batch['labels'], dtype=numpy.uint8)\n            for batch in train_batches])\n    train_labels = numpy.expand_dims(train_labels, 1)\n\n    file = tar_file.extractfile('cifar-10-batches-py/test_batch')\n    try:\n        if six.PY3:\n            test = cPickle.load(file, encoding='latin1')\n        else:\n            test = cPickle.load(file)\n    finally:\n        file.close()\n\n    test_features = test['data'].reshape(test['data'].shape[0],\n                                         3, 32, 32)\n    test_labels = numpy.array(test['labels'], dtype=numpy.uint8)\n    test_labels = numpy.expand_dims(test_labels, 1)\n\n    data = (('train', 'features', train_features),\n            ('train', 'targets', train_labels),\n            ('test', 'features', test_features),\n            ('test', 'targets', test_labels))\n    fill_hdf5_file(h5file, data)\n    h5file['features'].dims[0].label = 'batch'\n    h5file['features'].dims[1].label = 'channel'\n    h5file['features'].dims[2].label = 'height'\n    h5file['features'].dims[3].label = 'width'\n    h5file['targets'].dims[0].label = 'batch'\n    h5file['targets'].dims[1].label = 'index'\n\n    h5file.flush()\n    h5file.close()\n\n    return (output_path,)", "response": "Converts the CIFAR - 10 dataset to HDF5."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fill_hdf5_file(h5file, data):\n    # Check that all sources for a split have the same length\n    split_names = set(split_tuple[0] for split_tuple in data)\n    for name in split_names:\n        lengths = [len(split_tuple[2]) for split_tuple in data\n                   if split_tuple[0] == name]\n        if not all(le == lengths[0] for le in lengths):\n            raise ValueError(\"split '{}' has sources that \".format(name) +\n                             \"vary in length\")\n\n    # Initialize split dictionary\n    split_dict = dict([(split_name, {}) for split_name in split_names])\n\n    # Compute total source lengths and check that splits have the same dtype\n    # across a source\n    source_names = set(split_tuple[1] for split_tuple in data)\n    for name in source_names:\n        splits = [s for s in data if s[1] == name]\n        indices = numpy.cumsum([0] + [len(s[2]) for s in splits])\n        if not all(s[2].dtype == splits[0][2].dtype for s in splits):\n            raise ValueError(\"source '{}' has splits that \".format(name) +\n                             \"vary in dtype\")\n        if not all(s[2].shape[1:] == splits[0][2].shape[1:] for s in splits):\n            raise ValueError(\"source '{}' has splits that \".format(name) +\n                             \"vary in shapes\")\n        dataset = h5file.create_dataset(\n            name, (sum(len(s[2]) for s in splits),) + splits[0][2].shape[1:],\n            dtype=splits[0][2].dtype)\n        dataset[...] = numpy.concatenate([s[2] for s in splits], axis=0)\n        for i, j, s in zip(indices[:-1], indices[1:], splits):\n            if len(s) == 4:\n                split_dict[s[0]][name] = (i, j, None, s[3])\n            else:\n                split_dict[s[0]][name] = (i, j)\n    h5file.attrs['split'] = H5PYDataset.create_split_array(split_dict)", "response": "Fills an HDF5 file in a H5PYDataset - compatible manner."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef progress_bar(name, maxval, prefix='Converting'):\n    widgets = ['{} {}: '.format(prefix, name), Percentage(), ' ',\n               Bar(marker='=', left='[', right=']'), ' ', ETA()]\n    bar = ProgressBar(widgets=widgets, max_value=maxval, fd=sys.stdout).start()\n    try:\n        yield bar\n    finally:\n        bar.update(maxval)\n        bar.finish()", "response": "A context manager that displays a progress bar for a conversion."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts the Iris dataset to HDF5.", "response": "def convert_iris(directory, output_directory, output_filename='iris.hdf5'):\n    \"\"\"Convert the Iris dataset to HDF5.\n\n    Converts the Iris dataset to an HDF5 dataset compatible with\n    :class:`fuel.datasets.Iris`. The converted dataset is\n    saved as 'iris.hdf5'.\n    This method assumes the existence of the file `iris.data`.\n\n    Parameters\n    ----------\n    directory : str\n        Directory in which input files reside.\n    output_directory : str\n        Directory in which to save the converted dataset.\n    output_filename : str, optional\n        Name of the saved dataset. Defaults to `None`, in which case a name\n        based on `dtype` will be used.\n\n    Returns\n    -------\n    output_paths : tuple of str\n        Single-element tuple containing the path to the converted dataset.\n\n    \"\"\"\n    classes = {b'Iris-setosa': 0, b'Iris-versicolor': 1, b'Iris-virginica': 2}\n    data = numpy.loadtxt(\n        os.path.join(directory, 'iris.data'),\n        converters={4: lambda x: classes[x]},\n        delimiter=',')\n    features = data[:, :-1].astype('float32')\n    targets = data[:, -1].astype('uint8').reshape((-1, 1))\n    data = (('all', 'features', features),\n            ('all', 'targets', targets))\n\n    output_path = os.path.join(output_directory, output_filename)\n    h5file = h5py.File(output_path, mode='w')\n    fill_hdf5_file(h5file, data)\n    h5file['features'].dims[0].label = 'batch'\n    h5file['features'].dims[1].label = 'feature'\n    h5file['targets'].dims[0].label = 'batch'\n    h5file['targets'].dims[1].label = 'index'\n\n    h5file.flush()\n    h5file.close()\n\n    return (output_path,)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fill_subparser(subparser):\n    urls = ([None] * len(ALL_FILES))\n    filenames = list(ALL_FILES)\n    subparser.set_defaults(urls=urls, filenames=filenames)\n    subparser.add_argument('-P', '--url-prefix', type=str, default=None,\n                           help=\"URL prefix to prepend to the filenames of \"\n                                \"non-public files, in order to download them. \"\n                                \"Be sure to include the trailing slash.\")\n    return default_downloader", "response": "Sets up a subparser to download the ILSVRC2012 dataset files."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the index where the target window starts.", "response": "def _get_target_index(self):\n        \"\"\"Return the index where the target window starts.\"\"\"\n        return (self.index + self.source_window * (not self.overlapping) +\n                self.offset)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_end_index(self):\n        return max(self.index + self.source_window,\n                   self._get_target_index() + self.target_window)", "response": "Return the end of both windows."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert the SVHN dataset ( format 1 ) to HDF5.", "response": "def convert_svhn_format_1(directory, output_directory,\n                          output_filename='svhn_format_1.hdf5'):\n    \"\"\"Converts the SVHN dataset (format 1) to HDF5.\n\n    This method assumes the existence of the files\n    `{train,test,extra}.tar.gz`, which are accessible through the\n    official website [SVHNSITE].\n\n    .. [SVHNSITE] http://ufldl.stanford.edu/housenumbers/\n\n    Parameters\n    ----------\n    directory : str\n        Directory in which input files reside.\n    output_directory : str\n        Directory in which to save the converted dataset.\n    output_filename : str, optional\n        Name of the saved dataset. Defaults to 'svhn_format_1.hdf5'.\n\n    Returns\n    -------\n    output_paths : tuple of str\n        Single-element tuple containing the path to the converted dataset.\n\n    \"\"\"\n    try:\n        output_path = os.path.join(output_directory, output_filename)\n        h5file = h5py.File(output_path, mode='w')\n        TMPDIR = tempfile.mkdtemp()\n\n        # Every image has three channels (RGB) and variable height and width.\n        # It features a variable number of bounding boxes that identify the\n        # location and label of digits. The bounding box location is specified\n        # using the x and y coordinates of its top left corner along with its\n        # width and height.\n        BoundingBoxes = namedtuple(\n            'BoundingBoxes', ['labels', 'heights', 'widths', 'lefts', 'tops'])\n        sources = ('features',) + tuple('bbox_{}'.format(field)\n                                        for field in BoundingBoxes._fields)\n        source_dtypes = dict([(source, 'uint8') for source in sources[:2]] +\n                             [(source, 'uint16') for source in sources[2:]])\n        source_axis_labels = {\n            'features': ('channel', 'height', 'width'),\n            'bbox_labels': ('bounding_box', 'index'),\n            'bbox_heights': ('bounding_box', 'height'),\n            'bbox_widths': ('bounding_box', 'width'),\n            'bbox_lefts': ('bounding_box', 'x'),\n            'bbox_tops': ('bounding_box', 'y')}\n\n        # The dataset is split into three sets: the training set, the test set\n        # and an extra set of examples that are somewhat less difficult but\n        # can be used as extra training data. These sets are stored separately\n        # as 'train.tar.gz', 'test.tar.gz' and 'extra.tar.gz'. Each file\n        # contains a directory named after the split it stores. The examples\n        # are stored in that directory as PNG images. The directory also\n        # contains a 'digitStruct.mat' file with all the bounding box and\n        # label information.\n        splits = ('train', 'test', 'extra')\n        file_paths = dict(zip(splits, FORMAT_1_FILES))\n        for split, path in file_paths.items():\n            file_paths[split] = os.path.join(directory, path)\n        digit_struct_paths = dict(\n            [(split, os.path.join(TMPDIR, split, 'digitStruct.mat'))\n             for split in splits])\n\n        # We first extract the data files in a temporary directory. While doing\n        # that, we also count the number of examples for each split. Files are\n        # extracted individually, which allows to display a progress bar. Since\n        # the splits will be concatenated in the HDF5 file, we also compute the\n        # start and stop intervals of each split within the concatenated array.\n        def extract_tar(split):\n            with tarfile.open(file_paths[split], 'r:gz') as f:\n                members = f.getmembers()\n                num_examples = sum(1 for m in members if '.png' in m.name)\n                progress_bar_context = progress_bar(\n                    name='{} file'.format(split), maxval=len(members),\n                    prefix='Extracting')\n                with progress_bar_context as bar:\n                    for i, member in enumerate(members):\n                        f.extract(member, path=TMPDIR)\n                        bar.update(i)\n            return num_examples\n\n        examples_per_split = OrderedDict(\n            [(split, extract_tar(split)) for split in splits])\n        cumulative_num_examples = numpy.cumsum(\n            [0] + list(examples_per_split.values()))\n        num_examples = cumulative_num_examples[-1]\n        intervals = zip(cumulative_num_examples[:-1],\n                        cumulative_num_examples[1:])\n        split_intervals = dict(zip(splits, intervals))\n\n        # The start and stop indices are used to create a split dict that will\n        # be parsed into the split array required by the H5PYDataset interface.\n        # The split dict is organized as follows:\n        #\n        #     dict(split -> dict(source -> (start, stop)))\n        #\n        split_dict = OrderedDict([\n            (split, OrderedDict([(s, split_intervals[split])\n                                 for s in sources]))\n            for split in splits])\n        h5file.attrs['split'] = H5PYDataset.create_split_array(split_dict)\n\n        # We then prepare the HDF5 dataset. This involves creating datasets to\n        # store data sources and datasets to store auxiliary information\n        # (namely the shapes for variable-length axes, and labels to indicate\n        # what these variable-length axes represent).\n        def make_vlen_dataset(source):\n            # Create a variable-length 1D dataset\n            dtype = h5py.special_dtype(vlen=numpy.dtype(source_dtypes[source]))\n            dataset = h5file.create_dataset(\n                source, (num_examples,), dtype=dtype)\n            # Create a dataset to store variable-length shapes.\n            axis_labels = source_axis_labels[source]\n            dataset_shapes = h5file.create_dataset(\n                '{}_shapes'.format(source), (num_examples, len(axis_labels)),\n                dtype='uint16')\n            # Create a dataset to store labels for variable-length axes.\n            dataset_vlen_axis_labels = h5file.create_dataset(\n                '{}_vlen_axis_labels'.format(source), (len(axis_labels),),\n                dtype='S{}'.format(\n                    numpy.max([len(label) for label in axis_labels])))\n            # Fill variable-length axis labels\n            dataset_vlen_axis_labels[...] = [\n                label.encode('utf8') for label in axis_labels]\n            # Attach auxiliary datasets as dimension scales of the\n            # variable-length 1D dataset. This is in accordance with the\n            # H5PYDataset interface.\n            dataset.dims.create_scale(dataset_shapes, 'shapes')\n            dataset.dims[0].attach_scale(dataset_shapes)\n            dataset.dims.create_scale(dataset_vlen_axis_labels, 'shape_labels')\n            dataset.dims[0].attach_scale(dataset_vlen_axis_labels)\n            # Tag fixed-length axis with its label\n            dataset.dims[0].label = 'batch'\n\n        for source in sources:\n            make_vlen_dataset(source)\n\n        # The \"fun\" part begins: we extract the bounding box and label\n        # information contained in 'digitStruct.mat'. This is a version 7.3\n        # Matlab file, which uses HDF5 under the hood, albeit with a very\n        # convoluted layout.\n        def get_boxes(split):\n            boxes = []\n            with h5py.File(digit_struct_paths[split], 'r') as f:\n                bar_name = '{} digitStruct'.format(split)\n                bar_maxval = examples_per_split[split]\n                with progress_bar(bar_name, bar_maxval) as bar:\n                    for image_number in range(examples_per_split[split]):\n                        # The 'digitStruct' group is the main group of the HDF5\n                        # file. It contains two datasets: 'bbox' and 'name'.\n                        # The 'name' dataset isn't of interest to us, as it\n                        # stores file names and there's already a one-to-one\n                        # mapping between row numbers and image names (e.g.\n                        # row 0 corresponds to '1.png', row 1 corresponds to\n                        # '2.png', and so on).\n                        main_group = f['digitStruct']\n                        # The 'bbox' dataset contains the bounding box and\n                        # label information we're after. It has as many rows\n                        # as there are images, and one column. Elements of the\n                        # 'bbox' dataset are object references that point to\n                        # (yet another) group that contains the information\n                        # for the corresponding image.\n                        image_reference = main_group['bbox'][image_number, 0]\n\n                        # There are five datasets contained in that group:\n                        # 'label', 'height', 'width', 'left' and 'top'. Each of\n                        # those datasets has as many rows as there are bounding\n                        # boxes in the corresponding image, and one column.\n                        def get_dataset(name):\n                            return main_group[image_reference][name][:, 0]\n                        names = ('label', 'height', 'width', 'left', 'top')\n                        datasets = dict(\n                            [(name, get_dataset(name)) for name in names])\n\n                        # If there is only one bounding box, the information is\n                        # stored directly in the datasets. If there are\n                        # multiple bounding boxes, elements of those datasets\n                        # are object references pointing to 1x1 datasets that\n                        # store the information (fortunately, it's the last\n                        # hop we need to make).\n                        def get_elements(dataset):\n                            if len(dataset) > 1:\n                                return [int(main_group[reference][0, 0])\n                                        for reference in dataset]\n                            else:\n                                return [int(dataset[0])]\n                        # Names are pluralized in the BoundingBox named tuple.\n                        kwargs = dict(\n                            [(name + 's', get_elements(dataset))\n                             for name, dataset in iteritems(datasets)])\n                        boxes.append(BoundingBoxes(**kwargs))\n                        if bar:\n                            bar.update(image_number)\n            return boxes\n\n        split_boxes = dict([(split, get_boxes(split)) for split in splits])\n\n        # The final step is to fill the HDF5 file.\n        def fill_split(split, bar=None):\n            for image_number in range(examples_per_split[split]):\n                image_path = os.path.join(\n                    TMPDIR, split, '{}.png'.format(image_number + 1))\n                image = numpy.asarray(\n                    Image.open(image_path)).transpose(2, 0, 1)\n                bounding_boxes = split_boxes[split][image_number]\n                num_boxes = len(bounding_boxes.labels)\n                index = image_number + split_intervals[split][0]\n\n                h5file['features'][index] = image.flatten()\n                h5file['features'].dims[0]['shapes'][index] = image.shape\n                for field in BoundingBoxes._fields:\n                    name = 'bbox_{}'.format(field)\n                    h5file[name][index] = numpy.maximum(0,\n                                                        getattr(bounding_boxes,\n                                                                field))\n                    h5file[name].dims[0]['shapes'][index] = [num_boxes, 1]\n\n                # Replace label '10' with '0'.\n                labels = h5file['bbox_labels'][index]\n                labels[labels == 10] = 0\n                h5file['bbox_labels'][index] = labels\n\n                if image_number % 1000 == 0:\n                    h5file.flush()\n                if bar:\n                    bar.update(index)\n\n        with progress_bar('SVHN format 1', num_examples) as bar:\n            for split in splits:\n                fill_split(split, bar=bar)\n    finally:\n        if 'TMPDIR' in locals() and os.path.isdir(TMPDIR):\n            shutil.rmtree(TMPDIR)\n        if 'h5file' in locals():\n            h5file.flush()\n            h5file.close()\n\n    return (output_path,)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef convert_svhn_format_2(directory, output_directory,\n                          output_filename='svhn_format_2.hdf5'):\n    \"\"\"Converts the SVHN dataset (format 2) to HDF5.\n\n    This method assumes the existence of the files\n    `{train,test,extra}_32x32.mat`, which are accessible through the\n    official website [SVHNSITE].\n\n    Parameters\n    ----------\n    directory : str\n        Directory in which input files reside.\n    output_directory : str\n        Directory in which to save the converted dataset.\n    output_filename : str, optional\n        Name of the saved dataset. Defaults to 'svhn_format_2.hdf5'.\n\n    Returns\n    -------\n    output_paths : tuple of str\n        Single-element tuple containing the path to the converted dataset.\n\n    \"\"\"\n    output_path = os.path.join(output_directory, output_filename)\n    h5file = h5py.File(output_path, mode='w')\n\n    train_set = loadmat(os.path.join(directory, FORMAT_2_TRAIN_FILE))\n    train_features = train_set['X'].transpose(3, 2, 0, 1)\n    train_targets = train_set['y']\n    train_targets[train_targets == 10] = 0\n\n    test_set = loadmat(os.path.join(directory, FORMAT_2_TEST_FILE))\n    test_features = test_set['X'].transpose(3, 2, 0, 1)\n    test_targets = test_set['y']\n    test_targets[test_targets == 10] = 0\n\n    extra_set = loadmat(os.path.join(directory, FORMAT_2_EXTRA_FILE))\n    extra_features = extra_set['X'].transpose(3, 2, 0, 1)\n    extra_targets = extra_set['y']\n    extra_targets[extra_targets == 10] = 0\n\n    data = (('train', 'features', train_features),\n            ('test', 'features', test_features),\n            ('extra', 'features', extra_features),\n            ('train', 'targets', train_targets),\n            ('test', 'targets', test_targets),\n            ('extra', 'targets', extra_targets))\n    fill_hdf5_file(h5file, data)\n    for i, label in enumerate(('batch', 'channel', 'height', 'width')):\n        h5file['features'].dims[i].label = label\n    for i, label in enumerate(('batch', 'index')):\n        h5file['targets'].dims[i].label = label\n\n    h5file.flush()\n    h5file.close()\n\n    return (output_path,)", "response": "Converts the SVHN dataset ( format 2 ) to HDF5."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert the SVHN dataset to HDF5.", "response": "def convert_svhn(which_format, directory, output_directory,\n                 output_filename=None):\n    \"\"\"Converts the SVHN dataset to HDF5.\n\n    Converts the SVHN dataset [SVHN] to an HDF5 dataset compatible\n    with :class:`fuel.datasets.SVHN`. The converted dataset is\n    saved as 'svhn_format_1.hdf5' or 'svhn_format_2.hdf5', depending\n    on the `which_format` argument.\n\n    .. [SVHN] Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco,\n       Bo Wu, Andrew Y. Ng. *Reading Digits in Natural Images with\n       Unsupervised Feature Learning*, NIPS Workshop on Deep Learning\n       and Unsupervised Feature Learning, 2011.\n\n    Parameters\n    ----------\n    which_format : int\n        Either 1 or 2. Determines which format (format 1: full numbers\n        or format 2: cropped digits) to convert.\n    directory : str\n        Directory in which input files reside.\n    output_directory : str\n        Directory in which to save the converted dataset.\n    output_filename : str, optional\n        Name of the saved dataset. Defaults to 'svhn_format_1.hdf5' or\n        'svhn_format_2.hdf5', depending on `which_format`.\n\n    Returns\n    -------\n    output_paths : tuple of str\n        Single-element tuple containing the path to the converted dataset.\n\n    \"\"\"\n    if which_format not in (1, 2):\n        raise ValueError(\"SVHN format needs to be either 1 or 2.\")\n    if not output_filename:\n        output_filename = 'svhn_format_{}.hdf5'.format(which_format)\n    if which_format == 1:\n        return convert_svhn_format_1(\n            directory, output_directory, output_filename)\n    else:\n        return convert_svhn_format_2(\n            directory, output_directory, output_filename)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef open_(filename, mode='r', encoding=None):\n    if filename.endswith('.gz'):\n        if six.PY2:\n            zf = io.BufferedReader(gzip.open(filename, mode))\n            if encoding:\n                return codecs.getreader(encoding)(zf)\n            else:\n                return zf\n        else:\n            return io.BufferedReader(gzip.open(filename, mode,\n                                               encoding=encoding))\n    if six.PY2:\n        if encoding:\n            return codecs.open(filename, mode, encoding=encoding)\n        else:\n            return open(filename, mode)\n    else:\n        return open(filename, mode, encoding=encoding)", "response": "Open a text file with encoding and optional gzip compression."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nopens either a filename or a file - like object as a TarFile.", "response": "def tar_open(f):\n    \"\"\"Open either a filename or a file-like object as a TarFile.\n\n    Parameters\n    ----------\n    f : str or file-like object\n        The filename or file-like object from which to read.\n\n    Returns\n    -------\n    TarFile\n        A `TarFile` instance.\n\n    \"\"\"\n    if isinstance(f, six.string_types):\n        return tarfile.open(name=f)\n    else:\n        return tarfile.open(fileobj=f)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cache_file(filename):\n    dataset_local_dir = config.local_data_path\n    dataset_remote_dir = os.path.dirname(filename)\n    if dataset_remote_dir == \"\" or dataset_local_dir == \"\":\n        log.debug(\"Local dataset cache is deactivated\")\n\n    remote_name = filename\n\n    # Check if a local directory for data has been defined. Otherwise,\n    # do not locally copy the data\n    if dataset_local_dir == \"\":\n        return filename\n\n    common_msg = (\"Message from fuel local cache of dataset\"\n                  \"(specified by the environment variable \"\n                  \"FUEL_LOCAL_DATA_PATH): \")\n    # Make sure the file to cache exists and really is a file\n    if not os.path.exists(remote_name):\n        log.error(\n            \"Error : Specified file {} does not exist\".format(remote_name))\n        return filename\n\n    if not os.path.isfile(remote_name):\n        log.error(\n            \"Error : Specified name {} is not a file\".format(remote_name))\n        return filename\n\n    if not remote_name.startswith(dataset_remote_dir):\n        log.warning(\n            common_msg +\n            \"We cache in the local directory only what is\"\n            \" under $FUEL_DATA_PATH: {}\".format(remote_name))\n        return filename\n\n    # Create the $FUEL_LOCAL_DATA_PATH folder if needed\n    safe_mkdir(dataset_local_dir,\n               (stat.S_IRUSR | stat.S_IWUSR | stat.S_IXUSR |\n                stat.S_IRGRP | stat.S_IWGRP | stat.S_IXGRP |\n                stat.S_IROTH | stat.S_IWOTH | stat.S_IXOTH))\n\n    # Determine local path to which the file is to be cached\n    local_name = os.path.join(dataset_local_dir,\n                              os.path.relpath(remote_name,\n                                              dataset_remote_dir))\n\n    # Create the folder structure to receive the remote file\n    local_folder = os.path.split(local_name)[0]\n    try:\n        safe_mkdir(local_folder)\n    except Exception:\n        log.warning(\n            (common_msg +\n             \"While creating the directory {}, we got an error.\"\n             \" We won't cache to the local disk.\").format(local_folder))\n        return filename\n\n    # Acquire writelock on the local file to prevent the possibility\n    # of any other process modifying it while we cache it if needed.\n    # Also, if another process is currently caching the same file,\n    # it forces the current process to wait for it to be done before\n    # using the file.\n    if not os.access(local_folder, os.W_OK):\n        log.warning(common_msg +\n                    \"Local folder {} isn't writable.\"\n                    \" This is needed for synchronization.\"\n                    \" We will use the remote version.\"\n                    \" Manually fix the permission.\"\n                    .format(local_folder))\n        return filename\n    get_writelock(local_name)\n\n    # If the file does not exist locally, consider creating it\n    if not os.path.exists(local_name):\n\n        # Check that there is enough space to cache the file\n        if not check_enough_space(dataset_local_dir, remote_name,\n                                  local_name):\n            log.warning(common_msg +\n                        \"File {} not cached: Not enough free space\"\n                        .format(remote_name))\n            release_writelock()\n            return filename\n\n        # There is enough space; make a local copy of the file\n        copy_from_server_to_local(dataset_remote_dir, dataset_local_dir,\n                                  remote_name, local_name)\n        log.info(common_msg + \"File {} has been locally cached to {}\"\n                 .format(remote_name, local_name))\n    elif os.path.getmtime(remote_name) > os.path.getmtime(local_name):\n        remote_modified_time = time.strftime(\n            '%Y-%m-%d %H:%M:%S',\n            time.localtime(os.path.getmtime(remote_name)))\n        local_modified_time = time.strftime(\n            '%Y-%m-%d %H:%M:%S',\n            time.localtime(os.path.getmtime(local_name)))\n        log.warning(common_msg +\n                    \"File {} in cache will not be used: The remote file \"\n                    \"(modified {}) is newer than the locally cached file \"\n                    \"{} (modified {}).\"\n                    .format(remote_name, remote_modified_time,\n                            local_name, local_modified_time))\n        release_writelock()\n        return filename\n    elif os.path.getsize(local_name) != os.path.getsize(remote_name):\n        log.warning(common_msg +\n                    \"File {} not cached: The remote file ({} bytes) is of \"\n                    \"a different size than the locally cached file {} \"\n                    \"({} bytes). The local cache might be corrupt.\"\n                    .format(remote_name, os.path.getsize(remote_name),\n                            local_name, os.path.getsize(local_name)))\n        release_writelock()\n        return filename\n    elif not os.access(local_name, os.R_OK):\n        log.warning(common_msg +\n                    \"File {} in cache isn't readable. We will use the\"\n                    \" remote version. Manually fix the permission.\"\n                    .format(local_name))\n        release_writelock()\n        return filename\n    else:\n        log.debug(\"File {} has previously been locally cached to {}\"\n                  .format(remote_name, local_name))\n\n    # Obtain a readlock on the downloaded file before releasing the\n    # writelock. This is to prevent having a moment where there is no\n    # lock on this file which could give the impression that it is\n    # unused and therefore safe to delete.\n    get_readlock(pid, local_name)\n    release_writelock()\n\n    return local_name", "response": "Caches a file locally if possible."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncopies a remote file locally to a local file.", "response": "def copy_from_server_to_local(dataset_remote_dir, dataset_local_dir,\n                              remote_fname, local_fname):\n    \"\"\"Copies a remote file locally.\n\n    Parameters\n    ----------\n    remote_fname : str\n        Remote file to copy\n    local_fname : str\n        Path and name of the local copy to be made of the remote file.\n\n    \"\"\"\n    log.debug(\"Copying file `{}` to a local directory `{}`.\"\n              .format(remote_fname, dataset_local_dir))\n\n    head, tail = os.path.split(local_fname)\n    head += os.path.sep\n    if not os.path.exists(head):\n        os.makedirs(os.path.dirname(head))\n\n    shutil.copyfile(remote_fname, local_fname)\n\n    # Copy the original group id and file permission\n    st = os.stat(remote_fname)\n    os.chmod(local_fname, st.st_mode)\n    # If the user have read access to the data, but not a member\n    # of the group, he can't set the group. So we must catch the\n    # exception. But we still want to do this, for directory where\n    # only member of the group can read that data.\n    try:\n        os.chown(local_fname, -1, st.st_gid)\n    except OSError:\n        pass\n\n    # Need to give group write permission to the folders\n    # For the locking mechanism\n    # Try to set the original group as above\n    dirs = os.path.dirname(local_fname).replace(dataset_local_dir, '')\n    sep = dirs.split(os.path.sep)\n    if sep[0] == \"\":\n        sep = sep[1:]\n    for i in range(len(sep)):\n        orig_p = os.path.join(dataset_remote_dir, *sep[:i + 1])\n        new_p = os.path.join(dataset_local_dir, *sep[:i + 1])\n        orig_st = os.stat(orig_p)\n        new_st = os.stat(new_p)\n        if not new_st.st_mode & stat.S_IWGRP:\n            os.chmod(new_p, new_st.st_mode | stat.S_IWGRP)\n        if orig_st.st_gid != new_st.st_gid:\n            try:\n                os.chown(new_p, -1, orig_st.st_gid)\n            except OSError:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a list of continous integer values y into one - hot representation.", "response": "def convert_to_one_hot(y):\n    \"\"\"\n    converts y into one hot reprsentation.\n\n    Parameters\n    ----------\n    y : list\n        A list containing continous integer values.\n\n    Returns\n    -------\n    one_hot : numpy.ndarray\n        A numpy.ndarray object, which is one-hot representation of y.\n\n    \"\"\"\n    max_value = max(y)\n    min_value = min(y)\n    length = len(y)\n    one_hot = numpy.zeros((length, (max_value - min_value + 1)))\n    one_hot[numpy.arange(length), y] = 1\n    return one_hot"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert the Adult dataset to HDF5.", "response": "def convert_adult(directory, output_directory,\n                  output_filename='adult.hdf5'):\n    \"\"\"\n    Convert the Adult dataset to HDF5.\n\n    Converts the Adult dataset to an HDF5 dataset compatible with\n    :class:`fuel.datasets.Adult`. The converted dataset is saved as\n    'adult.hdf5'.\n    This method assumes the existence of the file `adult.data` and\n    `adult.test`.\n\n    Parameters\n    ----------\n    directory : str\n        Directory in which input files reside.\n    output_directory : str\n        Directory in which to save the converted dataset.\n    output_filename : str, optional\n        Name of the saved dataset. Defaults to `adult.hdf5`.\n\n    Returns\n    -------\n    output_paths : tuple of str\n        Single-element tuple containing the path to the converted dataset.\n\n    \"\"\"\n    train_path = os.path.join(directory, 'adult.data')\n    test_path = os.path.join(directory, 'adult.test')\n    output_path = os.path.join(output_directory, output_filename)\n\n    train_content = open(train_path, 'r').readlines()\n    test_content = open(test_path, 'r').readlines()\n    train_content = train_content[:-1]\n    test_content = test_content[1:-1]\n\n    features_list = []\n    targets_list = []\n    for content in [train_content, test_content]:\n        # strip out examples with missing features\n        content = [line for line in content if line.find('?') == -1]\n        # strip off endlines, separate entries\n        content = list(map(lambda l: l[:-1].split(', '), content))\n\n        features = list(map(lambda l: l[:-1], content))\n        targets = list(map(lambda l: l[-1], content))\n        del content\n        y = list(map(lambda l: [l[0] == '>'], targets))\n        y = numpy.array(y)\n        del targets\n\n        # Process features into a matrix\n        variables = [\n            'age', 'workclass', 'fnlwgt', 'education', 'education-num',\n            'marital-status', 'occupation', 'relationship', 'race', 'sex',\n            'capital-gain', 'capital-loss', 'hours-per-week', 'native-country'\n        ]\n        continuous = set([\n            'age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss',\n            'hours-per-week'\n        ])\n\n        pieces = []\n        for i, var in enumerate(variables):\n            data = list(map(lambda l: l[i], features))\n            if var in continuous:\n                data = list(map(lambda l: float(l), data))\n                data = numpy.array(data)\n                data = data.reshape(data.shape[0], 1)\n            else:\n                unique_values = list(set(data))\n                data = list(map(lambda l: unique_values.index(l), data))\n                data = convert_to_one_hot(data)\n            pieces.append(data)\n\n        X = numpy.concatenate(pieces, axis=1)\n\n        features_list.append(X)\n        targets_list.append(y)\n\n    # the largets value in the last variable of test set is only 40, thus\n    # the one hot representation has 40 at the second dimention. While in\n    # training set it is 41. Since it lies in the last variable, so it is\n    # safe to simply add a last column with zeros.\n    features_list[1] = numpy.concatenate(\n        (features_list[1],\n         numpy.zeros((features_list[1].shape[0], 1),\n                     dtype=features_list[1].dtype)),\n        axis=1)\n    h5file = h5py.File(output_path, mode='w')\n    data = (('train', 'features', features_list[0]),\n            ('train', 'targets', targets_list[0]),\n            ('test', 'features', features_list[1]),\n            ('test', 'targets', targets_list[1]))\n\n    fill_hdf5_file(h5file, data)\n    h5file['features'].dims[0].label = 'batch'\n    h5file['features'].dims[1].label = 'feature'\n    h5file['targets'].dims[0].label = 'batch'\n    h5file['targets'].dims[1].label = 'index'\n\n    h5file.flush()\n    h5file.close()\n\n    return (output_path,)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts the binarized MNIST dataset to HDF5.", "response": "def convert_binarized_mnist(directory, output_directory,\n                            output_filename='binarized_mnist.hdf5'):\n    \"\"\"Converts the binarized MNIST dataset to HDF5.\n\n    Converts the binarized MNIST dataset used in R. Salakhutdinov's DBN\n    paper [DBN] to an HDF5 dataset compatible with\n    :class:`fuel.datasets.BinarizedMNIST`. The converted dataset is\n    saved as 'binarized_mnist.hdf5'.\n\n    This method assumes the existence of the files\n    `binarized_mnist_{train,valid,test}.amat`, which are accessible\n    through Hugo Larochelle's website [HUGO].\n\n    .. [DBN] Ruslan Salakhutdinov and Iain Murray, *On the Quantitative\n       Analysis of Deep Belief Networks*, Proceedings of the 25th\n       international conference on Machine learning, 2008, pp. 872-879.\n\n    Parameters\n    ----------\n    directory : str\n        Directory in which input files reside.\n    output_directory : str\n        Directory in which to save the converted dataset.\n    output_filename : str, optional\n        Name of the saved dataset. Defaults to 'binarized_mnist.hdf5'.\n\n    Returns\n    -------\n    output_paths : tuple of str\n        Single-element tuple containing the path to the converted dataset.\n\n    \"\"\"\n    output_path = os.path.join(output_directory, output_filename)\n    h5file = h5py.File(output_path, mode='w')\n\n    train_set = numpy.loadtxt(\n        os.path.join(directory, TRAIN_FILE)).reshape(\n            (-1, 1, 28, 28)).astype('uint8')\n    valid_set = numpy.loadtxt(\n        os.path.join(directory, VALID_FILE)).reshape(\n            (-1, 1, 28, 28)).astype('uint8')\n    test_set = numpy.loadtxt(\n        os.path.join(directory, TEST_FILE)).reshape(\n            (-1, 1, 28, 28)).astype('uint8')\n    data = (('train', 'features', train_set),\n            ('valid', 'features', valid_set),\n            ('test', 'features', test_set))\n    fill_hdf5_file(h5file, data)\n    for i, label in enumerate(('batch', 'channel', 'height', 'width')):\n        h5file['features'].dims[i].label = label\n\n    h5file.flush()\n    h5file.close()\n\n    return (output_path,)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset up a subparser to download the CIFAR - 10 dataset file.", "response": "def fill_subparser(subparser):\n    \"\"\"Sets up a subparser to download the CIFAR-10 dataset file.\n\n    The CIFAR-10 dataset file is downloaded from Alex Krizhevsky's\n    website [ALEX].\n\n    Parameters\n    ----------\n    subparser : :class:`argparse.ArgumentParser`\n        Subparser handling the `cifar10` command.\n\n    \"\"\"\n    url = 'http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n    filename = 'cifar-10-python.tar.gz'\n    subparser.set_defaults(urls=[url], filenames=[filename])\n    return default_downloader"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts the aligned and cropped CelebA dataset to HDF5.", "response": "def convert_celeba_aligned_cropped(directory, output_directory,\n                                   output_filename=OUTPUT_FILENAME):\n    \"\"\"Converts the aligned and cropped CelebA dataset to HDF5.\n\n    Converts the CelebA dataset to an HDF5 dataset compatible with\n    :class:`fuel.datasets.CelebA`. The converted dataset is saved as\n    'celeba_aligned_cropped.hdf5'.\n\n    It assumes the existence of the following files:\n\n    * `img_align_celeba.zip`\n    * `list_attr_celeba.txt`\n\n    Parameters\n    ----------\n    directory : str\n        Directory in which input files reside.\n    output_directory : str\n        Directory in which to save the converted dataset.\n    output_filename : str, optional\n        Name of the saved dataset. Defaults to\n        'celeba_aligned_cropped.hdf5'.\n\n    Returns\n    -------\n    output_paths : tuple of str\n        Single-element tuple containing the path to the converted\n        dataset.\n\n    \"\"\"\n    output_path = os.path.join(output_directory, output_filename)\n    h5file = _initialize_conversion(directory, output_path, (218, 178))\n\n    features_dataset = h5file['features']\n    image_file_path = os.path.join(directory, IMAGE_FILE)\n    with zipfile.ZipFile(image_file_path, 'r') as image_file:\n        with progress_bar('images', NUM_EXAMPLES) as bar:\n            for i in range(NUM_EXAMPLES):\n                image_name = 'img_align_celeba/{:06d}.jpg'.format(i + 1)\n                features_dataset[i] = numpy.asarray(\n                    Image.open(\n                        image_file.open(image_name, 'r'))).transpose(2, 0, 1)\n                bar.update(i + 1)\n\n    h5file.flush()\n    h5file.close()\n\n    return (output_path,)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convert_celeba(which_format, directory, output_directory,\n                   output_filename=None):\n    \"\"\"Converts the CelebA dataset to HDF5.\n\n    Converts the CelebA dataset to an HDF5 dataset compatible with\n    :class:`fuel.datasets.CelebA`. The converted dataset is\n    saved as 'celeba_aligned_cropped.hdf5' or 'celeba_64.hdf5',\n    depending on the `which_format` argument.\n\n    Parameters\n    ----------\n    which_format : str\n        Either 'aligned_cropped' or '64'. Determines which format\n        to convert to.\n    directory : str\n        Directory in which input files reside.\n    output_directory : str\n        Directory in which to save the converted dataset.\n    output_filename : str, optional\n        Name of the saved dataset. Defaults to\n        'celeba_aligned_cropped.hdf5' or 'celeba_64.hdf5',\n        depending on `which_format`.\n\n    Returns\n    -------\n    output_paths : tuple of str\n        Single-element tuple containing the path to the converted dataset.\n\n    \"\"\"\n    if which_format not in ('aligned_cropped', '64'):\n        raise ValueError(\"CelebA format needs to be either \"\n                         \"'aligned_cropped' or '64'.\")\n    if not output_filename:\n        output_filename = 'celeba_{}.hdf5'.format(which_format)\n    if which_format == 'aligned_cropped':\n        return convert_celeba_aligned_cropped(\n            directory, output_directory, output_filename)\n    else:\n        return convert_celeba_64(\n            directory, output_directory, output_filename)", "response": "Converts the CelebA dataset to an HDF5 dataset compatible with the current version of Fuel."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef disk_usage(path):\n    st = os.statvfs(path)\n    total = st.f_blocks * st.f_frsize\n    used = (st.f_blocks - st.f_bfree) * st.f_frsize\n    return total, used", "response": "Return free usage about the given path in bytes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate the specified folder.", "response": "def safe_mkdir(folder_name, force_perm=None):\n    \"\"\"Create the specified folder.\n\n    If the parent folders do not exist, they are also created.\n    If the folder already exists, nothing is done.\n\n    Parameters\n    ----------\n    folder_name : str\n        Name of the folder to create.\n    force_perm : str\n        Mode to use for folder creation.\n\n    \"\"\"\n    if os.path.exists(folder_name):\n        return\n    intermediary_folders = folder_name.split(os.path.sep)\n\n    # Remove invalid elements from intermediary_folders\n    if intermediary_folders[-1] == \"\":\n        intermediary_folders = intermediary_folders[:-1]\n    if force_perm:\n        force_perm_path = folder_name.split(os.path.sep)\n        if force_perm_path[-1] == \"\":\n            force_perm_path = force_perm_path[:-1]\n\n    for i in range(1, len(intermediary_folders)):\n        folder_to_create = os.path.sep.join(intermediary_folders[:i + 1])\n\n        if os.path.exists(folder_to_create):\n            continue\n        os.mkdir(folder_to_create)\n        if force_perm:\n            os.chmod(folder_to_create, force_perm)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_enough_space(dataset_local_dir, remote_fname, local_fname,\n                       max_disk_usage=0.9):\n    \"\"\"Check if the given local folder has enough space.\n\n    Check if the given local folder has enough space to store\n    the specified remote file.\n\n    Parameters\n    ----------\n    remote_fname : str\n        Path to the remote file\n    remote_fname : str\n        Path to the local folder\n    max_disk_usage : float\n        Fraction indicating how much of the total space in the\n        local folder can be used before the local cache must stop\n        adding to it.\n\n    Returns\n    -------\n    output : boolean\n        True if there is enough space to store the remote file.\n\n    \"\"\"\n    storage_need = os.path.getsize(remote_fname)\n    storage_total, storage_used = disk_usage(dataset_local_dir)\n\n    # Instead of only looking if there's enough space, we ensure we do not\n    # go over max disk usage level to avoid filling the disk/partition\n    return ((storage_used + storage_need) <\n            (storage_total * max_disk_usage))", "response": "Checks if the given local folder has enough space to store the remote file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef convert_cifar100(directory, output_directory,\n                     output_filename='cifar100.hdf5'):\n    \"\"\"Converts the CIFAR-100 dataset to HDF5.\n\n    Converts the CIFAR-100 dataset to an HDF5 dataset compatible with\n    :class:`fuel.datasets.CIFAR100`. The converted dataset is saved as\n    'cifar100.hdf5'.\n\n    This method assumes the existence of the following file:\n    `cifar-100-python.tar.gz`\n\n    Parameters\n    ----------\n    directory : str\n        Directory in which the required input files reside.\n    output_directory : str\n        Directory in which to save the converted dataset.\n    output_filename : str, optional\n        Name of the saved dataset. Defaults to 'cifar100.hdf5'.\n\n    Returns\n    -------\n    output_paths : tuple of str\n        Single-element tuple containing the path to the converted dataset.\n\n    \"\"\"\n    output_path = os.path.join(output_directory, output_filename)\n    h5file = h5py.File(output_path, mode=\"w\")\n    input_file = os.path.join(directory, 'cifar-100-python.tar.gz')\n    tar_file = tarfile.open(input_file, 'r:gz')\n\n    file = tar_file.extractfile('cifar-100-python/train')\n    try:\n        if six.PY3:\n            train = cPickle.load(file, encoding='latin1')\n        else:\n            train = cPickle.load(file)\n    finally:\n        file.close()\n\n    train_features = train['data'].reshape(train['data'].shape[0],\n                                           3, 32, 32)\n    train_coarse_labels = numpy.array(train['coarse_labels'],\n                                      dtype=numpy.uint8)\n    train_fine_labels = numpy.array(train['fine_labels'],\n                                    dtype=numpy.uint8)\n\n    file = tar_file.extractfile('cifar-100-python/test')\n    try:\n        if six.PY3:\n            test = cPickle.load(file, encoding='latin1')\n        else:\n            test = cPickle.load(file)\n    finally:\n        file.close()\n\n    test_features = test['data'].reshape(test['data'].shape[0],\n                                         3, 32, 32)\n    test_coarse_labels = numpy.array(test['coarse_labels'], dtype=numpy.uint8)\n    test_fine_labels = numpy.array(test['fine_labels'], dtype=numpy.uint8)\n\n    data = (('train', 'features', train_features),\n            ('train', 'coarse_labels', train_coarse_labels.reshape((-1, 1))),\n            ('train', 'fine_labels', train_fine_labels.reshape((-1, 1))),\n            ('test', 'features', test_features),\n            ('test', 'coarse_labels', test_coarse_labels.reshape((-1, 1))),\n            ('test', 'fine_labels', test_fine_labels.reshape((-1, 1))))\n    fill_hdf5_file(h5file, data)\n    h5file['features'].dims[0].label = 'batch'\n    h5file['features'].dims[1].label = 'channel'\n    h5file['features'].dims[2].label = 'height'\n    h5file['features'].dims[3].label = 'width'\n    h5file['coarse_labels'].dims[0].label = 'batch'\n    h5file['coarse_labels'].dims[1].label = 'index'\n    h5file['fine_labels'].dims[0].label = 'batch'\n    h5file['fine_labels'].dims[1].label = 'index'\n\n    h5file.flush()\n    h5file.close()\n\n    return (output_path,)", "response": "Converts the CIFAR - 100 dataset to HDF5."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nverify that the axis labels for a given source are as expected and that they are equal.", "response": "def verify_axis_labels(self, expected, actual, source_name):\n        \"\"\"Verify that axis labels for a given source are as expected.\n\n        Parameters\n        ----------\n        expected : tuple\n            A tuple of strings representing the expected axis labels.\n        actual : tuple or None\n            A tuple of strings representing the actual axis labels, or\n            `None` if they could not be determined.\n        source_name : str\n            The name of the source being checked. Used for caching the\n            results of checks so that the check is only performed once.\n\n        Notes\n        -----\n        Logs a warning in case of `actual=None`, raises an error on\n        other mismatches.\n\n        \"\"\"\n        if not getattr(self, '_checked_axis_labels', False):\n            self._checked_axis_labels = defaultdict(bool)\n        if not self._checked_axis_labels[source_name]:\n            if actual is None:\n                log.warning(\"%s instance could not verify (missing) axis \"\n                            \"expected %s, got None\",\n                            self.__class__.__name__, expected)\n            else:\n                if expected != actual:\n                    raise AxisLabelsMismatchError(\"{} expected axis labels \"\n                                                  \"{}, got {} instead\".format(\n                                                      self.__class__.__name__,\n                                                      expected, actual))\n            self._checked_axis_labels[source_name] = True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_data(self, request=None):\n        if request is None:\n            raise ValueError\n        data = [[] for _ in self.sources]\n        for i in range(request):\n            try:\n                for source_data, example in zip(\n                        data, next(self.child_epoch_iterator)):\n                    source_data.append(example)\n            except StopIteration:\n                # If some data has been extracted and `strict` is not set,\n                # we should spit out this data before stopping iteration.\n                if not self.strictness and data[0]:\n                    break\n                elif self.strictness > 1 and data[0]:\n                    raise ValueError\n                raise\n        return tuple(numpy.asarray(source_data) for source_data in data)", "response": "Get data from the dataset."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _spawn_producer(f, port, addr='tcp://127.0.0.1'):\n    process = Process(target=_producer_wrapper, args=(f, port, addr))\n    process.start()\n    return process", "response": "Spawn a process that sends results on a ZeroMQ PUSH socket."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef producer_consumer(producer, consumer, addr='tcp://127.0.0.1',\n                      port=None, context=None):\n    \"\"\"A producer-consumer pattern.\n\n    Parameters\n    ----------\n    producer : callable\n        Callable that takes a single argument, a handle\n        for a ZeroMQ PUSH socket. Must be picklable.\n    consumer : callable\n        Callable that takes a single argument, a handle\n        for a ZeroMQ PULL socket.\n    addr : str, optional\n        Address to which the socket should connect. Defaults\n        to localhost ('tcp://127.0.0.1').\n    port : int, optional\n        The port on which the consumer should listen.\n    context : zmq.Context, optional\n        The ZeroMQ Context to use. One will be created otherwise.\n\n    Returns\n    -------\n    result\n        Passes along whatever `consumer` returns.\n\n    Notes\n    -----\n    This sets up a PULL socket in the calling process and forks\n    a process that calls `producer` on a PUSH socket. When the\n    consumer returns, the producer process is terminated.\n\n    Wrap `consumer` or `producer` in a `functools.partial` object\n    in order to send additional arguments; the callables passed in\n    should expect only one required, positional argument, the socket\n    handle.\n\n    \"\"\"\n    context_created = False\n    if context is None:\n        context_created = True\n        context = zmq.Context()\n    try:\n        consumer_socket = context.socket(zmq.PULL)\n        if port is None:\n            port = consumer_socket.bind_to_random_port(addr)\n        try:\n            process = _spawn_producer(producer, port)\n            result = consumer(consumer_socket)\n        finally:\n            process.terminate()\n        return result\n    finally:\n        # Works around a Python 3.x bug.\n        if context_created:\n            context.destroy()", "response": "A producer - consumer pattern."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef convert_dogs_vs_cats(directory, output_directory,\n                         output_filename='dogs_vs_cats.hdf5'):\n    \"\"\"Converts the Dogs vs. Cats dataset to HDF5.\n\n    Converts the Dogs vs. Cats dataset to an HDF5 dataset compatible with\n    :class:`fuel.datasets.dogs_vs_cats`. The converted dataset is saved as\n    'dogs_vs_cats.hdf5'.\n\n    It assumes the existence of the following files:\n\n    * `dogs_vs_cats.train.zip`\n    * `dogs_vs_cats.test1.zip`\n\n    Parameters\n    ----------\n    directory : str\n        Directory in which input files reside.\n    output_directory : str\n        Directory in which to save the converted dataset.\n    output_filename : str, optional\n        Name of the saved dataset. Defaults to 'dogs_vs_cats.hdf5'.\n\n    Returns\n    -------\n    output_paths : tuple of str\n        Single-element tuple containing the path to the converted dataset.\n\n    \"\"\"\n    # Prepare output file\n    output_path = os.path.join(output_directory, output_filename)\n    h5file = h5py.File(output_path, mode='w')\n    dtype = h5py.special_dtype(vlen=numpy.dtype('uint8'))\n    hdf_features = h5file.create_dataset('image_features', (37500,),\n                                         dtype=dtype)\n    hdf_shapes = h5file.create_dataset('image_features_shapes', (37500, 3),\n                                       dtype='int32')\n    hdf_labels = h5file.create_dataset('targets', (25000, 1), dtype='uint8')\n\n    # Attach shape annotations and scales\n    hdf_features.dims.create_scale(hdf_shapes, 'shapes')\n    hdf_features.dims[0].attach_scale(hdf_shapes)\n\n    hdf_shapes_labels = h5file.create_dataset('image_features_shapes_labels',\n                                              (3,), dtype='S7')\n    hdf_shapes_labels[...] = ['channel'.encode('utf8'),\n                              'height'.encode('utf8'),\n                              'width'.encode('utf8')]\n    hdf_features.dims.create_scale(hdf_shapes_labels, 'shape_labels')\n    hdf_features.dims[0].attach_scale(hdf_shapes_labels)\n\n    # Add axis annotations\n    hdf_features.dims[0].label = 'batch'\n    hdf_labels.dims[0].label = 'batch'\n    hdf_labels.dims[1].label = 'index'\n\n    # Convert\n    i = 0\n    for split, split_size in zip([TRAIN, TEST], [25000, 12500]):\n        # Open the ZIP file\n        filename = os.path.join(directory, split)\n        zip_file = zipfile.ZipFile(filename, 'r')\n        image_names = zip_file.namelist()[1:]  # Discard the directory name\n\n        # Shuffle the examples\n        if split == TRAIN:\n            rng = numpy.random.RandomState(123522)\n            rng.shuffle(image_names)\n        else:\n            image_names.sort(key=lambda fn: int(os.path.splitext(fn[6:])[0]))\n\n        # Convert from JPEG to NumPy arrays\n        with progress_bar(filename, split_size) as bar:\n            for image_name in image_names:\n                # Save image\n                image = numpy.array(Image.open(zip_file.open(image_name)))\n                image = image.transpose(2, 0, 1)\n                hdf_features[i] = image.flatten()\n                hdf_shapes[i] = image.shape\n\n                # Cats are 0, Dogs are 1\n                if split == TRAIN:\n                    hdf_labels[i] = 0 if 'cat' in image_name else 1\n\n                # Update progress\n                i += 1\n                bar.update(i if split == TRAIN else i - 25000)\n\n    # Add the labels\n    split_dict = {}\n    sources = ['image_features', 'targets']\n    split_dict['train'] = dict(zip(sources, [(0, 25000)] * 2))\n    split_dict['test'] = {sources[0]: (25000, 37500)}\n    h5file.attrs['split'] = H5PYDataset.create_split_array(split_dict)\n\n    h5file.flush()\n    h5file.close()\n\n    return (output_path,)", "response": "Converts the Dogs vs. Cats dataset to an HDF5 dataset compatible with the current directory."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef main(args=None):\n    built_in_datasets = dict(downloaders.all_downloaders)\n    if fuel.config.extra_downloaders:\n        for name in fuel.config.extra_downloaders:\n            extra_datasets = dict(\n                importlib.import_module(name).all_downloaders)\n            if any(key in built_in_datasets for key in extra_datasets.keys()):\n                raise ValueError('extra downloaders conflict in name with '\n                                 'built-in downloaders')\n            built_in_datasets.update(extra_datasets)\n    parser = argparse.ArgumentParser(\n        description='Download script for built-in datasets.')\n    parent_parser = argparse.ArgumentParser(add_help=False)\n    parent_parser.add_argument(\n        \"-d\", \"--directory\", help=\"where to save the downloaded files\",\n        type=str, default=os.getcwd())\n    parent_parser.add_argument(\n        \"--clear\", help=\"clear the downloaded files\", action='store_true')\n    subparsers = parser.add_subparsers()\n    download_functions = {}\n    for name, fill_subparser in built_in_datasets.items():\n        subparser = subparsers.add_parser(\n            name, parents=[parent_parser],\n            help='Download the {} dataset'.format(name))\n        # Allows the parser to know which subparser was called.\n        subparser.set_defaults(which_=name)\n        download_functions[name] = fill_subparser(subparser)\n    args = parser.parse_args()\n    args_dict = vars(args)\n    download_function = download_functions[args_dict.pop('which_')]\n    try:\n        download_function(**args_dict)\n    except NeedURLPrefix:\n        parser.error(url_prefix_message)", "response": "This function is called by the command line interface to download the built - in datasets."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fill_subparser(subparser):\n    filenames = ['train-images-idx3-ubyte.gz', 'train-labels-idx1-ubyte.gz',\n                 't10k-images-idx3-ubyte.gz', 't10k-labels-idx1-ubyte.gz']\n    urls = ['http://yann.lecun.com/exdb/mnist/' + f for f in filenames]\n    subparser.set_defaults(urls=urls, filenames=filenames)\n    return default_downloader", "response": "Sets up a subparser to download the MNIST dataset files."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef main(args=None):\n    parser = argparse.ArgumentParser(\n        description='Extracts metadata from a Fuel-converted HDF5 file.')\n    parser.add_argument(\"filename\", help=\"HDF5 file to analyze\")\n    args = parser.parse_args()\n\n    with h5py.File(args.filename, 'r') as h5file:\n        interface_version = h5file.attrs.get('h5py_interface_version', 'N/A')\n        fuel_convert_version = h5file.attrs.get('fuel_convert_version', 'N/A')\n        fuel_convert_command = h5file.attrs.get('fuel_convert_command', 'N/A')\n\n    message_prefix = message_prefix_template.format(\n        os.path.basename(args.filename))\n    message_body = message_body_template.format(\n        fuel_convert_command, interface_version, fuel_convert_version)\n    message = ''.join(['\\n', message_prefix, '\\n', '=' * len(message_prefix),\n                       message_body])\n    print(message)", "response": "Entry point for Fuel s information\n    utility."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts the CalTech 101 Silhouettes Datasets to HDF5.", "response": "def convert_silhouettes(size, directory, output_directory,\n                        output_filename=None):\n    \"\"\" Convert the CalTech 101 Silhouettes Datasets.\n\n    Parameters\n    ----------\n    size : {16, 28}\n        Convert either the 16x16 or 28x28 sized version of the dataset.\n    directory : str\n        Directory in which the required input files reside.\n    output_filename : str\n        Where to save the converted dataset.\n\n    \"\"\"\n    if size not in (16, 28):\n        raise ValueError('size must be 16 or 28')\n\n    if output_filename is None:\n        output_filename = 'caltech101_silhouettes{}.hdf5'.format(size)\n    output_file = os.path.join(output_directory, output_filename)\n\n    input_file = 'caltech101_silhouettes_{}_split1.mat'.format(size)\n    input_file = os.path.join(directory, input_file)\n\n    if not os.path.isfile(input_file):\n        raise MissingInputFiles('Required files missing', [input_file])\n\n    with h5py.File(output_file, mode=\"w\") as h5file:\n        mat = loadmat(input_file)\n\n        train_features = mat['train_data'].reshape([-1, 1, size, size])\n        train_targets = mat['train_labels']\n        valid_features = mat['val_data'].reshape([-1, 1, size, size])\n        valid_targets = mat['val_labels']\n        test_features = mat['test_data'].reshape([-1, 1, size, size])\n        test_targets = mat['test_labels']\n\n        data = (\n            ('train', 'features', train_features),\n            ('train', 'targets', train_targets),\n            ('valid', 'features', valid_features),\n            ('valid', 'targets', valid_targets),\n            ('test', 'features', test_features),\n            ('test', 'targets', test_targets),\n        )\n        fill_hdf5_file(h5file, data)\n\n        for i, label in enumerate(('batch', 'channel', 'height', 'width')):\n            h5file['features'].dims[i].label = label\n\n        for i, label in enumerate(('batch', 'index')):\n            h5file['targets'].dims[i].label = label\n    return (output_file,)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cross_validation(scheme_class, num_examples, num_folds, strict=True,\n                     **kwargs):\n    \"\"\"Return pairs of schemes to be used for cross-validation.\n\n    Parameters\n    ----------\n    scheme_class : subclass of :class:`IndexScheme` or :class:`BatchScheme`\n        The type of the returned schemes. The constructor is called with an\n        iterator and `**kwargs` as arguments.\n    num_examples : int\n        The number of examples in the datastream.\n    num_folds : int\n        The number of folds to return.\n    strict : bool, optional\n        If `True`, enforce that `num_examples` is divisible by `num_folds`\n        and so, that all validation sets have the same size. If `False`,\n        the size of the validation set is returned along the iteration\n        schemes. Defaults to `True`.\n\n    Yields\n    ------\n    fold : tuple\n        The generator returns `num_folds` tuples. The first two elements of\n        the tuple are the training and validation iteration schemes. If\n        `strict` is set to `False`, the tuple has a third element\n        corresponding to the size of the validation set.\n\n    \"\"\"\n    if strict and num_examples % num_folds != 0:\n        raise ValueError((\"{} examples are not divisible in {} evenly-sized \" +\n                          \"folds. To allow this, have a look at the \" +\n                          \"`strict` argument.\").format(num_examples,\n                                                       num_folds))\n\n    for i in xrange(num_folds):\n        begin = num_examples * i // num_folds\n        end = num_examples * (i+1) // num_folds\n        train = scheme_class(list(chain(xrange(0, begin),\n                                        xrange(end, num_examples))),\n                             **kwargs)\n        valid = scheme_class(xrange(begin, end), **kwargs)\n\n        if strict:\n            yield (train, valid)\n        else:\n            yield (train, valid, end - begin)", "response": "Generates a sequence of tuples that can be used to cross - validation."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main(args=None):\n    built_in_datasets = dict(converters.all_converters)\n    if fuel.config.extra_converters:\n        for name in fuel.config.extra_converters:\n            extra_datasets = dict(\n                importlib.import_module(name).all_converters)\n            if any(key in built_in_datasets for key in extra_datasets.keys()):\n                raise ValueError('extra converters conflict in name with '\n                                 'built-in converters')\n            built_in_datasets.update(extra_datasets)\n    parser = argparse.ArgumentParser(\n        description='Conversion script for built-in datasets.')\n    subparsers = parser.add_subparsers()\n    parent_parser = argparse.ArgumentParser(add_help=False)\n    parent_parser.add_argument(\n        \"-d\", \"--directory\", help=\"directory in which input files reside\",\n        type=str, default=os.getcwd())\n    convert_functions = {}\n    for name, fill_subparser in built_in_datasets.items():\n        subparser = subparsers.add_parser(\n            name, parents=[parent_parser],\n            help='Convert the {} dataset'.format(name))\n        subparser.add_argument(\n            \"-o\", \"--output-directory\", help=\"where to save the dataset\",\n            type=str, default=os.getcwd(), action=CheckDirectoryAction)\n        subparser.add_argument(\n            \"-r\", \"--output_filename\", help=\"new name of the created dataset\",\n            type=str, default=None)\n        # Allows the parser to know which subparser was called.\n        subparser.set_defaults(which_=name)\n        convert_functions[name] = fill_subparser(subparser)\n\n    args = parser.parse_args(args)\n    args_dict = vars(args)\n    if args_dict['output_filename'] is not None and\\\n        os.path.splitext(args_dict['output_filename'])[1] not in\\\n            ('.hdf5', '.hdf', '.h5'):\n        args_dict['output_filename'] += '.hdf5'\n    if args_dict['output_filename'] is None:\n        args_dict.pop('output_filename')\n\n    convert_function = convert_functions[args_dict.pop('which_')]\n    try:\n        output_paths = convert_function(**args_dict)\n    except MissingInputFiles as e:\n        intro = \"The following required files were not found:\\n\"\n        message = \"\\n\".join([intro] + [\"   * \" + f for f in e.filenames])\n        message += \"\\n\\nDid you forget to run fuel-download?\"\n        parser.error(message)\n\n    # Tag the newly-created file(s) with H5PYDataset version and command-line\n    # options\n    for output_path in output_paths:\n        h5file = h5py.File(output_path, 'a')\n        interface_version = H5PYDataset.interface_version.encode('utf-8')\n        h5file.attrs['h5py_interface_version'] = interface_version\n        fuel_convert_version = converters.__version__.encode('utf-8')\n        h5file.attrs['fuel_convert_version'] = fuel_convert_version\n        command = [os.path.basename(sys.argv[0])] + sys.argv[1:]\n        h5file.attrs['fuel_convert_command'] = (\n            ' '.join(command).encode('utf-8'))\n        h5file.flush()\n        h5file.close()", "response": "Entry point for Fuel s conversion function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrefresh an existing lock by re - writing the file containing the unique id of the current node.", "response": "def refresh_lock(lock_file):\n    \"\"\"'Refresh' an existing lock.\n\n    'Refresh' an existing lock by re-writing the file containing the\n    owner's unique id, using a new (randomly generated) id, which is also\n    returned.\n\n    \"\"\"\n    unique_id = '%s_%s_%s' % (\n        os.getpid(),\n        ''.join([str(random.randint(0, 9)) for i in range(10)]), hostname)\n    try:\n        lock_write = open(lock_file, 'w')\n        lock_write.write(unique_id + '\\n')\n        lock_write.close()\n    except Exception:\n        # In some strange case, this happen.  To prevent all tests\n        # from failing, we release the lock, but as there is a\n        # problem, we still keep the original exception.\n        # This way, only 1 test would fail.\n        while get_lock.n_lock > 0:\n            release_lock()\n        raise\n    return unique_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef lock(tmp_dir, timeout=NOT_SET, min_wait=None, max_wait=None, verbosity=1):\n    if min_wait is None:\n        min_wait = MIN_WAIT\n    if max_wait is None:\n        max_wait = min_wait * 2\n    if timeout is NOT_SET:\n        timeout = TIMEOUT\n    # Create base of lock directory if required.\n    base_lock = os.path.dirname(tmp_dir)\n    if not os.path.isdir(base_lock):\n        try:\n            os.makedirs(base_lock)\n        except OSError:\n            # Someone else was probably trying to create it at the same time.\n            # We wait two seconds just to make sure the following assert does\n            # not fail on some NFS systems.\n            time.sleep(2)\n    assert os.path.isdir(base_lock)\n\n    # Variable initialization.\n    lock_file = os.path.join(tmp_dir, 'lock')\n    random.seed()\n    my_pid = os.getpid()\n    no_display = (verbosity == 0)\n\n    nb_error = 0\n    # The number of time we sleep when their is no errors.\n    # Used to don't display it the first time to display it less frequently.\n    # And so don't get as much email about this!\n    nb_wait = 0\n    # Acquire lock.\n    while True:\n        try:\n            last_owner = 'no_owner'\n            time_start = time.time()\n            other_dead = False\n            while os.path.isdir(tmp_dir):\n                try:\n                    with open(lock_file) as f:\n                        read_owner = f.readlines()[0].strip()\n\n                    # The try is transition code for old locks.\n                    # It may be removed when people have upgraded.\n                    try:\n                        other_host = read_owner.split('_')[2]\n                    except IndexError:\n                        other_host = ()  # make sure it isn't equal to any host\n                    if other_host == hostname:\n                        try:\n                            # Just check if the other process still exist.\n                            os.kill(int(read_owner.split('_')[0]), 0)\n                        except OSError:\n                            other_dead = True\n                        except AttributeError:\n                            pass  # os.kill does not exist on windows\n                except Exception:\n                    read_owner = 'failure'\n                if other_dead:\n                    if not no_display:\n                        msg = \"process '%s'\" % read_owner.split('_')[0]\n                        logger.warning(\"Overriding existing lock by dead %s \"\n                                       \"(I am process '%s')\", msg, my_pid)\n                    get_lock.unlocker.unlock()\n                    continue\n                if last_owner == read_owner:\n                    if (timeout is not None and\n                            time.time() - time_start >= timeout):\n                        # Timeout exceeded or locking process dead.\n                        if not no_display:\n                            if read_owner == 'failure':\n                                msg = 'unknown process'\n                            else:\n                                msg = \"process '%s'\" % read_owner.split('_')[0]\n                            logger.warning(\"Overriding existing lock by %s \"\n                                           \"(I am process '%s')\", msg, my_pid)\n                        get_lock.unlocker.unlock()\n                        continue\n                else:\n                    last_owner = read_owner\n                    time_start = time.time()\n                    no_display = (verbosity == 0)\n                if not no_display and nb_wait > 0:\n                    if read_owner == 'failure':\n                        msg = 'unknown process'\n                    else:\n                        msg = \"process '%s'\" % read_owner.split('_')[0]\n                    logger.info(\"Waiting for existing lock by %s (I am \"\n                                \"process '%s')\", msg, my_pid)\n                    logger.info(\"To manually release the lock, delete %s\",\n                                tmp_dir)\n                    if verbosity <= 1:\n                        no_display = True\n                nb_wait += 1\n                time.sleep(random.uniform(min_wait, max_wait))\n\n            try:\n                os.mkdir(tmp_dir)\n            except OSError:\n                # Error while creating the directory: someone else\n                # must have tried at the exact same time.\n                nb_error += 1\n                if nb_error < 10:\n                    continue\n                else:\n                    raise\n            # Safety check: the directory should be here.\n            assert os.path.isdir(tmp_dir)\n\n            # Write own id into lock file.\n            unique_id = refresh_lock(lock_file)\n\n            # Verify we are really the lock owner (this should not be needed,\n            # but better be safe than sorry).\n            with open(lock_file) as f:\n                owner = f.readlines()[0].strip()\n\n            if owner != unique_id:\n                # Too bad, try again.\n                continue\n            else:\n                # We got the lock, hoorray!\n                return\n\n        except Exception as e:\n            # If something wrong happened, we try again.\n            logger.warning(\"Something wrong happened: %s %s\", type(e), e)\n            nb_error += 1\n            if nb_error > 10:\n                raise\n            time.sleep(random.uniform(min_wait, max_wait))\n            continue", "response": "Obtain a lock for a given process."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_lock(lock_dir, **kw):\n    if not hasattr(get_lock, 'n_lock'):\n        # Initialization.\n        get_lock.n_lock = 0\n        if not hasattr(get_lock, 'lock_is_enabled'):\n            # Enable lock by default.\n            get_lock.lock_is_enabled = True\n        get_lock.lock_dir = lock_dir\n        get_lock.unlocker = Unlocker(get_lock.lock_dir)\n    else:\n        if lock_dir != get_lock.lock_dir:\n            # Compilation directory has changed.\n            # First ensure all old locks were released.\n            assert get_lock.n_lock == 0\n            # Update members for new compilation directory.\n            get_lock.lock_dir = lock_dir\n            get_lock.unlocker = Unlocker(get_lock.lock_dir)\n\n    if get_lock.lock_is_enabled:\n        # Only really try to acquire the lock if we do not have it already.\n        if get_lock.n_lock == 0:\n            lock(get_lock.lock_dir, **kw)\n            atexit.register(Unlocker.unlock, get_lock.unlocker)\n            # Store time at which the lock was set.\n            get_lock.start_time = time.time()\n        else:\n            # Check whether we need to 'refresh' the lock. We do this\n            # every 'config.compile.timeout / 2' seconds to ensure\n            # no one else tries to override our lock after their\n            # 'config.compile.timeout' timeout period.\n            if get_lock.start_time is None:\n                # This should not happen. So if this happen, clean up\n                # the lock state and raise an error.\n                while get_lock.n_lock > 0:\n                    release_lock()\n                raise Exception(\n                    \"For some unknow reason, the lock was already taken,\"\n                    \" but no start time was registered.\")\n            now = time.time()\n            if now - get_lock.start_time > TIMEOUT:\n                lockpath = os.path.join(get_lock.lock_dir, 'lock')\n                logger.info('Refreshing lock %s', str(lockpath))\n                refresh_lock(lockpath)\n                get_lock.start_time = now\n    get_lock.n_lock += 1", "response": "Obtain a lock on the compilation directory."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef release_lock():\n    get_lock.n_lock -= 1\n    assert get_lock.n_lock >= 0\n    # Only really release lock once all lock requests have ended.\n    if get_lock.lock_is_enabled and get_lock.n_lock == 0:\n        get_lock.start_time = None\n        get_lock.unlocker.unlock()", "response": "Release lock on compilation directory."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef release_readlock(lockdir_name):\n    # Make sure the lock still exists before deleting it\n    if os.path.exists(lockdir_name) and os.path.isdir(lockdir_name):\n        os.rmdir(lockdir_name)", "response": "Release a previously obtained readlock."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nobtains a readlock on a file.", "response": "def get_readlock(pid, path):\n    \"\"\"Obtain a readlock on a file.\n\n    Parameters\n    ----------\n    path : str\n        Name of the file on which to obtain a readlock\n\n    \"\"\"\n    timestamp = int(time.time() * 1e6)\n    lockdir_name = \"%s.readlock.%i.%i\" % (path, pid, timestamp)\n    os.mkdir(lockdir_name)\n\n    # Register function to release the readlock at the end of the script\n    atexit.register(release_readlock, lockdir_name=lockdir_name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove current lock. This function does not crash if it is unable to properly delete the lock file and directory. The reason is that it should be allowed for multiple jobs running in parallel to unlock the same directory at the same time (e.g. when reaching their timeout limit).", "response": "def unlock(self):\n        \"\"\"Remove current lock.\n\n        This function does not crash if it is unable to properly\n        delete the lock file and directory. The reason is that it\n        should be allowed for multiple jobs running in parallel to\n        unlock the same directory at the same time (e.g. when reaching\n        their timeout limit).\n\n        \"\"\"\n        # If any error occurs, we assume this is because someone else tried to\n        # unlock this directory at the same time.\n        # Note that it is important not to have both remove statements within\n        # the same try/except block. The reason is that while the attempt to\n        # remove the file may fail (e.g. because for some reason this file does\n        # not exist), we still want to try and remove the directory.\n        try:\n            self.os.remove(self.os.path.join(self.tmp_dir, 'lock'))\n        except Exception:\n            pass\n        try:\n            self.os.rmdir(self.tmp_dir)\n        except Exception:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef filename_from_url(url, path=None):\n    r = requests.get(url, stream=True)\n    if 'Content-Disposition' in r.headers:\n        filename = re.findall(r'filename=([^;]+)',\n                              r.headers['Content-Disposition'])[0].strip('\"\\\"')\n    else:\n        filename = os.path.basename(urllib.parse.urlparse(url).path)\n    return filename", "response": "Parses a URL to determine a file name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef download(url, file_handle, chunk_size=1024):\n    r = requests.get(url, stream=True)\n    total_length = r.headers.get('content-length')\n    if total_length is None:\n        maxval = UnknownLength\n    else:\n        maxval = int(total_length)\n    name = file_handle.name\n    with progress_bar(name=name, maxval=maxval) as bar:\n        for i, chunk in enumerate(r.iter_content(chunk_size)):\n            if total_length:\n                bar.update(i * chunk_size)\n            file_handle.write(chunk)", "response": "Downloads a given URL to a specific file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndownload or clears files from URLs and filenames. Parameters ---------- directory : str The directory in which downloaded files are saved. urls : list A list of URLs to download. filenames : list A list of file names for the corresponding URLs. url_prefix : str, optional If provided, this is prepended to filenames that lack a corresponding URL. clear : bool, optional If `True`, delete the given filenames from the given directory rather than download them.", "response": "def default_downloader(directory, urls, filenames, url_prefix=None,\n                       clear=False):\n    \"\"\"Downloads or clears files from URLs and filenames.\n\n    Parameters\n    ----------\n    directory : str\n        The directory in which downloaded files are saved.\n    urls : list\n        A list of URLs to download.\n    filenames : list\n        A list of file names for the corresponding URLs.\n    url_prefix : str, optional\n        If provided, this is prepended to filenames that\n        lack a corresponding URL.\n    clear : bool, optional\n        If `True`, delete the given filenames from the given\n        directory rather than download them.\n\n    \"\"\"\n    # Parse file names from URL if not provided\n    for i, url in enumerate(urls):\n        filename = filenames[i]\n        if not filename:\n            filename = filename_from_url(url)\n        if not filename:\n            raise ValueError(\"no filename available for URL '{}'\".format(url))\n        filenames[i] = filename\n    files = [os.path.join(directory, f) for f in filenames]\n\n    if clear:\n        for f in files:\n            if os.path.isfile(f):\n                os.remove(f)\n    else:\n        print('Downloading ' + ', '.join(filenames) + '\\n')\n        ensure_directory_exists(directory)\n\n        for url, f, n in zip(urls, files, filenames):\n            if not url:\n                if url_prefix is None:\n                    raise NeedURLPrefix\n                url = url_prefix + n\n            with open(f, 'wb') as file_handle:\n                download(url, file_handle)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_in_data_path(filename):\n    for path in config.data_path:\n        path = os.path.expanduser(os.path.expandvars(path))\n        file_path = os.path.join(path, filename)\n        if os.path.isfile(file_path):\n            return file_path\n    raise IOError(\"{} not found in Fuel's data path\".format(filename))", "response": "Searches for a file within Fuel s data path and returns the first path in which it is found."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef lazy_property_factory(lazy_property):\n    def lazy_property_getter(self):\n        if not hasattr(self, '_' + lazy_property):\n            self.load()\n        if not hasattr(self, '_' + lazy_property):\n            raise ValueError(\"{} wasn't loaded\".format(lazy_property))\n        return getattr(self, '_' + lazy_property)\n\n    def lazy_property_setter(self, value):\n        setattr(self, '_' + lazy_property, value)\n\n    return lazy_property_getter, lazy_property_setter", "response": "Create properties that perform lazy loading of attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sorted_fancy_indexing(indexable, request):\n        if len(request) > 1:\n            indices = numpy.argsort(request)\n            data = numpy.empty(shape=(len(request),) + indexable.shape[1:],\n                               dtype=indexable.dtype)\n            data[indices] = indexable[numpy.array(request)[indices], ...]\n        else:\n            data = indexable[request]\n        return data", "response": "Safe fancy indexing.\n\n        Some objects, such as h5py datasets, only support list indexing\n        if the list is sorted.\n\n        This static method adds support for unsorted list indexing by\n        sorting the requested indices, accessing the corresponding\n        elements and re-shuffling the result.\n\n        Parameters\n        ----------\n        request : list of int\n            Unsorted list of example indices.\n        indexable : any fancy-indexable object\n            Indexable we'd like to do unsorted fancy indexing on."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef slice_to_numerical_args(slice_, num_examples):\n        start = slice_.start if slice_.start is not None else 0\n        stop = slice_.stop if slice_.stop is not None else num_examples\n        step = slice_.step if slice_.step is not None else 1\n        return start, stop, step", "response": "Translate a slice s attributes into numerical attributes."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn this subset s representation as a list of indices.", "response": "def get_list_representation(self):\n        \"\"\"Returns this subset's representation as a list of indices.\"\"\"\n        if self.is_list:\n            return self.list_or_slice\n        else:\n            return self[list(range(self.num_examples))]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nindex an indexable object within the context of this subset.", "response": "def index_within_subset(self, indexable, subset_request,\n                            sort_indices=False):\n        \"\"\"Index an indexable object within the context of this subset.\n\n        Parameters\n        ----------\n        indexable : indexable object\n            The object to index through.\n        subset_request : :class:`list` or :class:`slice`\n            List of positive integer indices or slice that constitutes\n            the request *within the context of this subset*. This\n            request will be translated to a request on the indexable\n            object.\n        sort_indices : bool, optional\n            If the request is a list of indices, indexes in sorted order\n            and reshuffles the result in the original order. Defaults to\n            `False`.\n\n        \"\"\"\n        # Translate the request within the context of this subset to a\n        # request to the indexable object\n        if isinstance(subset_request, numbers.Integral):\n            request, = self[[subset_request]]\n        else:\n            request = self[subset_request]\n        # Integer or slice requests can be processed directly.\n        if isinstance(request, numbers.Integral) or hasattr(request, 'step'):\n            return indexable[request]\n        # If requested, we do fancy indexing in sorted order and reshuffle the\n        # result back in the original order.\n        if sort_indices:\n            return self.sorted_fancy_indexing(indexable, request)\n        # If the indexable supports fancy indexing (numpy array, HDF5 dataset),\n        # the request can be processed directly.\n        if isinstance(indexable, (numpy.ndarray, h5py.Dataset)):\n            return indexable[request]\n        # Anything else (e.g. lists) isn't considered to support fancy\n        # indexing, so Subset does it manually.\n        return iterable_fancy_indexing(indexable, request)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget an epoch iterator for the data stream.", "response": "def get_epoch_iterator(self, **kwargs):\n        \"\"\"Get an epoch iterator for the data stream.\"\"\"\n        if not self._fresh_state:\n            self.next_epoch()\n        else:\n            self._fresh_state = False\n        return super(DataStream, self).get_epoch_iterator(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting up a subparser to download the binarized MNIST dataset files.", "response": "def fill_subparser(subparser):\n    \"\"\"Sets up a subparser to download the binarized MNIST dataset files.\n\n    The binarized MNIST dataset files\n    (`binarized_mnist_{train,valid,test}.amat`) are downloaded from\n    Hugo Larochelle's website [HUGO].\n\n    .. [HUGO] http://www.cs.toronto.edu/~larocheh/public/datasets/\n       binarized_mnist/binarized_mnist_{train,valid,test}.amat\n\n    Parameters\n    ----------\n    subparser : :class:`argparse.ArgumentParser`\n        Subparser handling the `binarized_mnist` command.\n\n    \"\"\"\n    sets = ['train', 'valid', 'test']\n    urls = ['http://www.cs.toronto.edu/~larocheh/public/datasets/' +\n            'binarized_mnist/binarized_mnist_{}.amat'.format(s) for s in sets]\n    filenames = ['binarized_mnist_{}.amat'.format(s) for s in sets]\n    subparser.set_defaults(urls=urls, filenames=filenames)\n    return default_downloader"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndetermines the URL corresponding to Python object", "response": "def linkcode_resolve(domain, info):\n    \"\"\"\n    Determine the URL corresponding to Python object\n    \"\"\"\n    if domain != 'py':\n        return None\n\n    modname = info['module']\n    fullname = info['fullname']\n\n    submod = sys.modules.get(modname)\n    if submod is None:\n        return None\n\n    obj = submod\n    for part in fullname.split('.'):\n        try:\n            obj = getattr(obj, part)\n        except:\n            return None\n    if hasattr(obj, '__wrapped__'):\n        obj = obj.__wrapped__\n\n    try:\n        fn = inspect.getsourcefile(obj)\n    except:\n        fn = None\n    if not fn:\n        return None\n\n    try:\n        _, lineno = inspect.findsource(obj)\n    except:\n        lineno = None\n\n    if lineno:\n        linespec = \"#L%d\" % (lineno + 1)\n    else:\n        linespec = \"\"\n\n    fn = os.path.relpath(fn, start=os.path.dirname(fuel.__file__))\n\n    github = \"https://github.com/mila-udem/fuel/blob/master/fuel/{}{}\"\n    return github.format(fn, linespec)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndownloads the audio of a YouTube video.", "response": "def download(directory, youtube_id, clear=False):\n    \"\"\"Download the audio of a YouTube video.\n\n    The audio is downloaded in the highest available quality. Progress is\n    printed to `stdout`. The file is named `youtube_id.m4a`, where\n    `youtube_id` is the 11-character code identifiying the YouTube video\n    (can be determined from the URL).\n\n    Parameters\n    ----------\n    directory : str\n        The directory in which to save the downloaded audio file.\n    youtube_id : str\n        11-character video ID (taken from YouTube URL)\n    clear : bool\n        If `True`, it deletes the downloaded video. Otherwise it downloads\n        it. Defaults to `False`.\n\n    \"\"\"\n    filepath = os.path.join(directory, '{}.m4a'.format(youtube_id))\n    if clear:\n        os.remove(filepath)\n        return\n    if not PAFY_AVAILABLE:\n        raise ImportError(\"pafy is required to download YouTube videos\")\n    url = 'https://www.youtube.com/watch?v={}'.format(youtube_id)\n    video = pafy.new(url)\n    audio = video.getbestaudio()\n    audio.download(quiet=False, filepath=filepath)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fill_subparser(subparser):\n    subparser.add_argument(\n        '--youtube-id', type=str, required=True,\n        help=(\"The YouTube ID of the video from which to extract audio, \"\n              \"usually an 11-character string.\")\n    )\n    return download", "response": "Sets up a subparser to download audio of YouTube videos."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts downloaded YouTube audio to HDF5 format.", "response": "def convert_youtube_audio(directory, output_directory, youtube_id, channels,\n                          sample, output_filename=None):\n    \"\"\"Converts downloaded YouTube audio to HDF5 format.\n\n    Requires `ffmpeg` to be installed and available on the command line\n    (i.e. available on your `PATH`).\n\n    Parameters\n    ----------\n    directory : str\n        Directory in which input files reside.\n    output_directory : str\n        Directory in which to save the converted dataset.\n    youtube_id : str\n        11-character video ID (taken from YouTube URL)\n    channels : int\n        The number of audio channels to use in the PCM Wave file.\n    sample : int\n        The sampling rate to use in Hz, e.g. 44100 or 16000.\n    output_filename : str, optional\n        Name of the saved dataset. If `None` (the default),\n        `youtube_id.hdf5` is used.\n\n    \"\"\"\n    input_file = os.path.join(directory, '{}.m4a'.format(youtube_id))\n    wav_filename = '{}.wav'.format(youtube_id)\n    wav_file = os.path.join(directory, wav_filename)\n    ffmpeg_not_available = subprocess.call(['ffmpeg', '-version'])\n    if ffmpeg_not_available:\n        raise RuntimeError('conversion requires ffmpeg')\n    subprocess.check_call(['ffmpeg', '-y', '-i', input_file, '-ac',\n                           str(channels), '-ar', str(sample), wav_file],\n                          stdout=sys.stdout)\n\n    # Load WAV into array\n    _, data = scipy.io.wavfile.read(wav_file)\n    if data.ndim == 1:\n        data = data[:, None]\n    data = data[None, :]\n\n    # Store in HDF5\n    if output_filename is None:\n        output_filename = '{}.hdf5'.format(youtube_id)\n    output_file = os.path.join(output_directory, output_filename)\n\n    with h5py.File(output_file, 'w') as h5file:\n        fill_hdf5_file(h5file, (('train', 'features', data),))\n        h5file['features'].dims[0].label = 'batch'\n        h5file['features'].dims[1].label = 'time'\n        h5file['features'].dims[2].label = 'feature'\n\n    return (output_file,)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fill_subparser(subparser):\n    subparser.add_argument(\n        '--youtube-id', type=str, required=True,\n        help=(\"The YouTube ID of the video from which to extract audio, \"\n              \"usually an 11-character string.\")\n    )\n    subparser.add_argument(\n        '--channels', type=int, default=1,\n        help=(\"The number of audio channels to convert to. The default of 1\"\n              \"means audio is converted to mono.\")\n    )\n    subparser.add_argument(\n        '--sample', type=int, default=16000,\n        help=(\"The sampling rate in Hz. The default of 16000 is \"\n              \"significantly downsampled compared to normal WAVE files; \"\n              \"pass 44100 for the usual sampling rate.\")\n    )\n    return convert_youtube_audio", "response": "Sets up a subparser to convert YouTube audio files."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert the ILSVRC 2012 dataset into a single HDF5 file.", "response": "def convert_ilsvrc2012(directory, output_directory,\n                       output_filename='ilsvrc2012.hdf5',\n                       shuffle_seed=config.default_seed):\n    \"\"\"Converter for data from the ILSVRC 2012 competition.\n\n    Source files for this dataset can be obtained by registering at\n    [ILSVRC2012WEB].\n\n    Parameters\n    ----------\n    input_directory : str\n        Path from which to read raw data files.\n    output_directory : str\n        Path to which to save the HDF5 file.\n    output_filename : str, optional\n        The output filename for the HDF5 file. Default: 'ilsvrc2012.hdf5'.\n    shuffle_seed : int or sequence, optional\n        Seed for a random number generator used to shuffle the order\n        of the training set on disk, so that sequential reads will not\n        be ordered by class.\n\n    .. [ILSVRC2012WEB] http://image-net.org/challenges/LSVRC/2012/index\n\n    \"\"\"\n    devkit_path = os.path.join(directory, DEVKIT_ARCHIVE)\n    train, valid, test = [os.path.join(directory, fn) for fn in IMAGE_TARS]\n    n_train, valid_groundtruth, n_test, wnid_map = prepare_metadata(\n        devkit_path)\n    n_valid = len(valid_groundtruth)\n    output_path = os.path.join(output_directory, output_filename)\n\n    with h5py.File(output_path, 'w') as f, create_temp_tar() as patch:\n        log.info('Creating HDF5 datasets...')\n        prepare_hdf5_file(f, n_train, n_valid, n_test)\n        log.info('Processing training set...')\n        process_train_set(f, train, patch, n_train, wnid_map, shuffle_seed)\n        log.info('Processing validation set...')\n        process_other_set(f, 'valid', valid, patch, valid_groundtruth, n_train)\n        log.info('Processing test set...')\n        process_other_set(f, 'test', test, patch, (None,) * n_test,\n                          n_train + n_valid)\n        log.info('Done.')\n\n    return (output_path,)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fill_subparser(subparser):\n    subparser.add_argument(\n        \"--shuffle-seed\", help=\"Seed to use for randomizing order of the \"\n                               \"training set on disk.\",\n        default=config.default_seed, type=int, required=False)\n    return convert_ilsvrc2012", "response": "Sets up a subparser to convert the ILSVRC2012 dataset files."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef prepare_metadata(devkit_archive):\n    # Read what's necessary from the development kit.\n    synsets, raw_valid_groundtruth = read_devkit(devkit_archive)\n\n    # Mapping to take WordNet IDs to our internal 0-999 encoding.\n    wnid_map = dict(zip((s.decode('utf8') for s in synsets['WNID']),\n                        xrange(1000)))\n\n    # Map the 'ILSVRC2012 ID' to our zero-based ID.\n    ilsvrc_id_to_zero_based = dict(zip(synsets['ILSVRC2012_ID'],\n                                       xrange(len(synsets))))\n\n    # Map the validation set groundtruth to 0-999 labels.\n    valid_groundtruth = [ilsvrc_id_to_zero_based[id_]\n                         for id_ in raw_valid_groundtruth]\n\n    # Get number of test examples from the test archive\n    with tar_open(TEST_IMAGES_TAR) as f:\n        n_test = sum(1 for _ in f)\n\n    # Ascertain the number of filenames to prepare appropriate sized\n    # arrays.\n    n_train = int(synsets['num_train_images'].sum())\n    log.info('Training set: {} images'.format(n_train))\n    log.info('Validation set: {} images'.format(len(valid_groundtruth)))\n    log.info('Test set: {} images'.format(n_test))\n    n_total = n_train + len(valid_groundtruth) + n_test\n    log.info('Total (train/valid): {} images'.format(n_total))\n    return n_train, valid_groundtruth, n_test, wnid_map", "response": "Extract dataset metadata required for HDF5 file setup."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_metadata_mat_file(meta_mat):\n    mat = loadmat(meta_mat, squeeze_me=True)\n    synsets = mat['synsets']\n    new_dtype = numpy.dtype([\n        ('ILSVRC2012_ID', numpy.int16),\n        ('WNID', ('S', max(map(len, synsets['WNID'])))),\n        ('wordnet_height', numpy.int8),\n        ('gloss', ('S', max(map(len, synsets['gloss'])))),\n        ('num_children', numpy.int8),\n        ('words', ('S', max(map(len, synsets['words'])))),\n        ('children', (numpy.int8, max(synsets['num_children']))),\n        ('num_train_images', numpy.uint16)\n    ])\n    new_synsets = numpy.empty(synsets.shape, dtype=new_dtype)\n    for attr in ['ILSVRC2012_ID', 'WNID', 'wordnet_height', 'gloss',\n                 'num_children', 'words', 'num_train_images']:\n        new_synsets[attr] = synsets[attr]\n    children = [numpy.atleast_1d(ch) for ch in synsets['children']]\n    padded_children = [\n        numpy.concatenate((c,\n                           -numpy.ones(new_dtype['children'].shape[0] - len(c),\n                                       dtype=numpy.int16)))\n        for c in children\n    ]\n    new_synsets['children'] = padded_children\n    return new_synsets", "response": "Read ILSVRC2012 metadata from a distributed MAT file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses extra_{downloader converter arguments.", "response": "def extra_downloader_converter(value):\n    \"\"\"Parses extra_{downloader,converter} arguments.\n\n    Parameters\n    ----------\n    value : iterable or str\n        If the value is a string, it is split into a list using spaces\n        as delimiters. Otherwise, it is returned as is.\n\n    \"\"\"\n    if isinstance(value, six.string_types):\n        value = value.split(\" \")\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef multiple_paths_parser(value):\n    if isinstance(value, six.string_types):\n        value = value.split(os.path.pathsep)\n    return value", "response": "Parses data_path argument.\n\n    Parameters\n    ----------\n    value : str\n        a string of data paths separated by  \":\".\n\n    Returns\n    -------\n    value : list\n        a list of strings indicating each data paths."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_config(self, key, type_, default=NOT_SET, env_var=None):\n        self.config[key] = {'type': type_}\n        if env_var is not None:\n            self.config[key]['env_var'] = env_var\n        if default is not NOT_SET:\n            self.config[key]['default'] = default", "response": "Adds a configuration setting to the configuration file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend NumPy arrays over a socket.", "response": "def send_arrays(socket, arrays, stop=False):\n    \"\"\"Send NumPy arrays using the buffer interface and some metadata.\n\n    Parameters\n    ----------\n    socket : :class:`zmq.Socket`\n        The socket to send data over.\n    arrays : list\n        A list of :class:`numpy.ndarray` to transfer.\n    stop : bool, optional\n        Instead of sending a series of NumPy arrays, send a JSON object\n        with a single `stop` key. The :func:`recv_arrays` will raise\n        ``StopIteration`` when it receives this.\n\n    Notes\n    -----\n    The protocol is very simple: A single JSON object describing the array\n    format (using the same specification as ``.npy`` files) is sent first.\n    Subsequently the arrays are sent as bytestreams (through NumPy's\n    support of the buffering protocol).\n\n    \"\"\"\n    if arrays:\n        # The buffer protocol only works on contiguous arrays\n        arrays = [numpy.ascontiguousarray(array) for array in arrays]\n    if stop:\n        headers = {'stop': True}\n        socket.send_json(headers)\n    else:\n        headers = [header_data_from_array_1_0(array) for array in arrays]\n        socket.send_json(headers, zmq.SNDMORE)\n        for array in arrays[:-1]:\n            socket.send(array, zmq.SNDMORE)\n        socket.send(arrays[-1])"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreceives a list of NumPy arrays.", "response": "def recv_arrays(socket):\n    \"\"\"Receive a list of NumPy arrays.\n\n    Parameters\n    ----------\n    socket : :class:`zmq.Socket`\n        The socket to receive the arrays on.\n\n    Returns\n    -------\n    list\n        A list of :class:`numpy.ndarray` objects.\n\n    Raises\n    ------\n    StopIteration\n        If the first JSON object received contains the key `stop`,\n        signifying that the server has finished a single epoch.\n\n    \"\"\"\n    headers = socket.recv_json()\n    if 'stop' in headers:\n        raise StopIteration\n    arrays = []\n    for header in headers:\n        data = socket.recv(copy=False)\n        buf = buffer_(data)\n        array = numpy.frombuffer(buf, dtype=numpy.dtype(header['descr']))\n        array.shape = header['shape']\n        if header['fortran_order']:\n            array.shape = header['shape'][::-1]\n            array = array.transpose()\n        arrays.append(array)\n    return arrays"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef start_server(data_stream, port=5557, hwm=10):\n    logging.basicConfig(level='INFO')\n\n    context = zmq.Context()\n    socket = context.socket(zmq.PUSH)\n    socket.set_hwm(hwm)\n    socket.bind('tcp://*:{}'.format(port))\n\n    it = data_stream.get_epoch_iterator()\n\n    logger.info('server started')\n    while True:\n        try:\n            data = next(it)\n            stop = False\n            logger.debug(\"sending {} arrays\".format(len(data)))\n        except StopIteration:\n            it = data_stream.get_epoch_iterator()\n            data = None\n            stop = True\n            logger.debug(\"sending StopIteration\")\n        send_arrays(socket, data, stop=stop)", "response": "Start a data processing server."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmoving png - files one directory up from path / image. png -> path / image. png", "response": "def move_images(self, image_directory):\n        \"\"\" Moves png-files one directory up from path/image/*.png -> path/*.png\"\"\"\n\n        image_paths = glob(image_directory + \"/**/*.png\", recursive=True)\n        for image_path in image_paths:\n            destination = image_path.replace(\"\\\\image\\\\\", \"\\\\\")\n            shutil.move(image_path, destination)\n        image_folders = glob(image_directory + \"/**/image\", recursive=True)\n        for image_folder in image_folders:\n            os.removedirs(image_folder)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a visual representation of the Homus Dataset.", "response": "def create_images(raw_data_directory: str,\n                      destination_directory: str,\n                      stroke_thicknesses: List[int],\n                      canvas_width: int = None,\n                      canvas_height: int = None,\n                      staff_line_spacing: int = 14,\n                      staff_line_vertical_offsets: List[int] = None,\n                      random_position_on_canvas: bool = False) -> dict:\n        \"\"\"\n        Creates a visual representation of the Homus Dataset by parsing all text-files and the symbols as specified\n        by the parameters by drawing lines that connect the points from each stroke of each symbol.\n\n        Each symbol will be drawn in the center of a fixed canvas, specified by width and height.\n\n        :param raw_data_directory: The directory, that contains the text-files that contain the textual representation\n                                    of the music symbols\n        :param destination_directory: The directory, in which the symbols should be generated into. One sub-folder per\n                                      symbol category will be generated automatically\n        :param stroke_thicknesses: The thickness of the pen, used for drawing the lines in pixels. If multiple are\n                                   specified, multiple images will be generated that have a different suffix, e.g.\n                                   1-16-3.png for the 3-px version and 1-16-2.png for the 2-px version of the image 1-16\n        :param canvas_width: The width of the canvas, that each image will be drawn upon, regardless of the original size of\n                      the symbol. Larger symbols will be cropped. If the original size of the symbol should be used,\n                      provided None here.\n        :param canvas_height: The height of the canvas, that each image will be drawn upon, regardless of the original size of\n                       the symbol. Larger symbols will be cropped. If the original size of the symbol should be used,\n                       provided None here\n        :param staff_line_spacing: Number of pixels spacing between each of the five staff-lines\n        :param staff_line_vertical_offsets: List of vertical offsets, where the staff-lines will be superimposed over\n                                            the drawn images. If None is provided, no staff-lines will be superimposed.\n                                            If multiple values are provided, multiple versions of each symbol will be\n                                            generated with the appropriate staff-lines, e.g. 1-5_3_offset_70.png and\n                                            1-5_3_offset_77.png for two versions of the symbol 1-5 with stroke thickness\n                                            3 and staff-line offsets 70 and 77 pixels from the top.\n        :param random_position_on_canvas: True, if the symbols should be randomly placed on the fixed canvas.\n                                          False, if the symbols should be centered in the fixed canvas.\n                                          Note that this flag only has an effect, if fixed canvas sizes are used.\n        :return: A dictionary that contains the file-names of all generated symbols and the respective bounding-boxes\n                 of each symbol.\n        \"\"\"\n        all_symbol_files = [y for x in os.walk(raw_data_directory) for y in glob(os.path.join(x[0], '*.txt'))]\n\n        staff_line_multiplier = 1\n        if staff_line_vertical_offsets is not None and staff_line_vertical_offsets:\n            staff_line_multiplier = len(staff_line_vertical_offsets)\n\n        total_number_of_symbols = len(all_symbol_files) * len(stroke_thicknesses) * staff_line_multiplier\n        output = \"Generating {0} images with {1} symbols in {2} different stroke thicknesses ({3})\".format(\n            total_number_of_symbols, len(all_symbol_files), len(stroke_thicknesses), stroke_thicknesses)\n\n        if staff_line_vertical_offsets is not None:\n            output += \" and with staff-lines with {0} different offsets from the top ({1})\".format(\n                staff_line_multiplier, staff_line_vertical_offsets)\n\n        if canvas_width is not None and canvas_height is not None:\n            if random_position_on_canvas is False:\n                output += \"\\nRandomly drawn on a fixed canvas of size {0}x{1} (Width x Height)\".format(canvas_width,\n                                                                                                       canvas_height)\n            else:\n                output += \"\\nCentrally drawn on a fixed canvas of size {0}x{1} (Width x Height)\".format(canvas_width,\n                                                                                                        canvas_height)\n\n        print(output)\n        print(\"In directory {0}\".format(os.path.abspath(destination_directory)), flush=True)\n\n        bounding_boxes = dict()\n\n        progress_bar = tqdm(total=total_number_of_symbols, mininterval=0.25)\n        for symbol_file in all_symbol_files:\n            with open(symbol_file) as file:\n                content = file.read()\n\n            symbol = HomusSymbol.initialize_from_string(content)\n\n            target_directory = os.path.join(destination_directory, symbol.symbol_class)\n            os.makedirs(target_directory, exist_ok=True)\n\n            raw_file_name_without_extension = os.path.splitext(os.path.basename(symbol_file))[0]\n\n            for stroke_thickness in stroke_thicknesses:\n                export_path = ExportPath(destination_directory, symbol.symbol_class, raw_file_name_without_extension,\n                                         'png', stroke_thickness)\n                if canvas_width is None and canvas_height is None:\n                    symbol.draw_into_bitmap(export_path, stroke_thickness, margin=2)\n                else:\n                    symbol.draw_onto_canvas(export_path, stroke_thickness, 0, canvas_width,\n                                            canvas_height, staff_line_spacing, staff_line_vertical_offsets,\n                                            bounding_boxes, random_position_on_canvas)\n\n                progress_bar.update(1 * staff_line_multiplier)\n\n        progress_bar.close()\n        return bounding_boxes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndownload and extracts the MUSCIMA dataset and extracts the images from the CVC - MUSCIMA dataset.", "response": "def download_and_extract_dataset(self, destination_directory: str):\n        \"\"\"\n        Downloads and extracts the MUSCIMA++ dataset along with the images from the CVC-MUSCIMA dataset\n        that were manually annotated (140 out of 1000 images).\n        \"\"\"\n        if not os.path.exists(self.get_dataset_filename()):\n            print(\"Downloading MUSCIMA++ Dataset...\")\n            self.download_file(self.get_dataset_download_url(), self.get_dataset_filename())\n\n        if not os.path.exists(self.get_imageset_filename()):\n            print(\"Downloading MUSCIMA++ Images...\")\n            self.download_file(self.get_images_download_url(), self.get_imageset_filename())\n\n        print(\"Extracting MUSCIMA++ Dataset...\")\n        self.extract_dataset(os.path.abspath(destination_directory))\n\n        absolute_path_to_temp_folder = os.path.abspath('MuscimaPpImages')\n        self.extract_dataset(absolute_path_to_temp_folder, self.get_imageset_filename())\n        DatasetDownloader.copytree(os.path.join(absolute_path_to_temp_folder, \"fulls\"),\n                                   os.path.join(os.path.abspath(destination_directory), self.dataset_version(), \"data\",\n                                                \"images\"))\n        self.clean_up_temp_directory(absolute_path_to_temp_folder)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef download_and_extract_measure_annotations(self, destination_directory: str):\n        if not os.path.exists(self.get_measure_annotation_filename()):\n            print(\"Downloading MUSCIMA++ Measure Annotations...\")\n            self.download_file(self.get_measure_annotation_download_url(), self.get_measure_annotation_filename())\n\n        print(\"Extracting MUSCIMA++ Annotations...\")\n        absolute_path_to_temp_folder = os.path.abspath('MuscimaPpMeasureAnnotations')\n        self.extract_dataset(absolute_path_to_temp_folder, self.get_measure_annotation_filename())\n        DatasetDownloader.copytree(os.path.join(absolute_path_to_temp_folder, \"coco\"),\n                                   os.path.join(os.path.abspath(destination_directory), self.dataset_version(), \"data\",\n                                                \"coco\"))\n        DatasetDownloader.copytree(os.path.join(absolute_path_to_temp_folder, \"json\"),\n                                   os.path.join(os.path.abspath(destination_directory), self.dataset_version(), \"data\",\n                                                \"json\"))\n        self.clean_up_temp_directory(absolute_path_to_temp_folder)", "response": "Downloads and extracts the annotations of the Muscima - Pp measure and system - measures and staves that were extracted from the MUSCIMA ++ dataset via the MuscimaPlusPlusAnnotationConverter."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef extract_and_render_all_symbol_masks(self, raw_data_directory: str, destination_directory: str):\n        print(\"Extracting Symbols from Muscima++ Dataset...\")\n\n        xml_files = self.get_all_xml_file_paths(raw_data_directory)\n        crop_objects = self.load_crop_objects_from_xml_files(xml_files)\n        self.render_masks_of_crop_objects_into_image(crop_objects, destination_directory)", "response": "Extracts all symbols from the raw XML documents and generates individual symbols from the masks"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload all XML - files that are located in the raw directory.", "response": "def get_all_xml_file_paths(self, raw_data_directory: str) -> List[str]:\n        \"\"\" Loads all XML-files that are located in the folder.\n        :param raw_data_directory: Path to the raw directory, where the MUSCIMA++ dataset was extracted to\n        \"\"\"\n        raw_data_directory = os.path.join(raw_data_directory, \"v1.0\", \"data\", \"cropobjects_manual\")\n        xml_files = [y for x in os.walk(raw_data_directory) for y in glob(os.path.join(x[0], '*.xml'))]\n        return xml_files"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef invert_images(self, image_directory: str, image_file_ending: str = \"*.bmp\"):\n        image_paths = [y for x in os.walk(image_directory) for y in glob(os.path.join(x[0], image_file_ending))]\n        for image_path in tqdm(image_paths, desc=\"Inverting all images in directory {0}\".format(image_directory)):\n            white_on_black_image = Image.open(image_path).convert(\"L\")\n            black_on_white_image = ImageOps.invert(white_on_black_image)\n            black_on_white_image.save(os.path.splitext(image_path)[0] + \".png\")", "response": "In - situ converts white on black images to black on white images"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a visual representation of the Capitan strokes and the scores of each stroke.", "response": "def create_capitan_images(self, raw_data_directory: str,\n                              destination_directory: str,\n                              stroke_thicknesses: List[int]) -> None:\n        \"\"\"\n        Creates a visual representation of the Capitan strokes by parsing all text-files and the symbols as specified\n        by the parameters by drawing lines that connect the points from each stroke of each symbol.\n\n        :param raw_data_directory: The directory, that contains the raw capitan dataset\n        :param destination_directory: The directory, in which the symbols should be generated into. One sub-folder per\n                                      symbol category will be generated automatically\n        :param stroke_thicknesses: The thickness of the pen, used for drawing the lines in pixels. If multiple are\n                                   specified, multiple images will be generated that have a different suffix, e.g.\n                                   1-16-3.png for the 3-px version and 1-16-2.png for the 2-px version of the image 1-16\n        \"\"\"\n        symbols = self.load_capitan_symbols(raw_data_directory)\n        self.draw_capitan_stroke_images(symbols, destination_directory, stroke_thicknesses)\n        self.draw_capitan_score_images(symbols, destination_directory)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndraws the images that connect the points from each stroke of each symbol to each stroke in the specified directory.", "response": "def draw_capitan_stroke_images(self, symbols: List[CapitanSymbol],\n                                   destination_directory: str,\n                                   stroke_thicknesses: List[int]) -> None:\n        \"\"\"\n        Creates a visual representation of the Capitan strokes by drawing lines that connect the points\n        from each stroke of each symbol.\n\n        :param symbols: The list of parsed Capitan-symbols\n        :param destination_directory: The directory, in which the symbols should be generated into. One sub-folder per\n                                      symbol category will be generated automatically\n        :param stroke_thicknesses: The thickness of the pen, used for drawing the lines in pixels. If multiple are\n                                   specified, multiple images will be generated that have a different suffix, e.g.\n                                   1-16-3.png for the 3-px version and 1-16-2.png for the 2-px version of the image 1-16\n        \"\"\"\n\n        total_number_of_symbols = len(symbols) * len(stroke_thicknesses)\n        output = \"Generating {0} images with {1} symbols in {2} different stroke thicknesses ({3})\".format(\n            total_number_of_symbols, len(symbols), len(stroke_thicknesses), stroke_thicknesses)\n\n        print(output)\n        print(\"In directory {0}\".format(os.path.abspath(destination_directory)), flush=True)\n\n        progress_bar = tqdm(total=total_number_of_symbols, mininterval=0.25, desc=\"Rendering strokes\")\n        capitan_file_name_counter = 0\n        for symbol in symbols:\n            capitan_file_name_counter += 1\n            target_directory = os.path.join(destination_directory, symbol.symbol_class)\n            os.makedirs(target_directory, exist_ok=True)\n\n            raw_file_name_without_extension = \"capitan-{0}-{1}-stroke\".format(symbol.symbol_class,\n                                                                              capitan_file_name_counter)\n\n            for stroke_thickness in stroke_thicknesses:\n                export_path = ExportPath(destination_directory, symbol.symbol_class, raw_file_name_without_extension,\n                                         'png', stroke_thickness)\n                symbol.draw_capitan_stroke_onto_canvas(export_path, stroke_thickness, 0)\n                progress_bar.update(1)\n\n        progress_bar.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate and initialize a new CapitanSymbol from a string.", "response": "def initialize_from_string(content: str) -> 'CapitanSymbol':\n        \"\"\"\n        Create and initializes a new symbol from a string\n        :param content: The content of a symbol as read from the text-file in the form <label>:<sequence>:<image>\n        :return: The initialized symbol\n        :rtype: CapitanSymbol\n        \"\"\"\n\n        if content is None or content is \"\":\n            return None\n\n        parts = content.split(\":\")\n        min_x = 100000\n        max_x = 0\n        min_y = 100000\n        max_y = 0\n\n        symbol_name = parts[0]\n\n        sequence = parts[1]\n        image_numbers = parts[2].split(',')\n        image_data = numpy.asarray(image_numbers, numpy.uint8).reshape((30, 30))\n\n        stroke = []\n\n        for point_string in sequence.split(\";\"):\n            if point_string is \"\":\n                continue  # Skip the last element, that is due to a trailing ; in each line\n\n            point_x, point_y = point_string.split(\",\")\n            x = float(point_x)\n            y = float(point_y)\n            stroke.append(SimplePoint2D(x, y))\n\n            max_x = max(max_x, x)\n            min_x = min(min_x, x)\n            max_y = max(max_y, y)\n            min_y = min(min_y, y)\n\n        dimensions = Rectangle(Point2D(min_x, min_y), int(max_x - min_x + 1), int(max_y - min_y + 1))\n        return CapitanSymbol(content, stroke, image_data, symbol_name, dimensions)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef draw_capitan_score_bitmap(self, export_path: ExportPath) -> None:\n        with Image.fromarray(self.image_data, mode='L') as image:\n            image.save(export_path.get_full_path())", "response": "Draw the 30x30 symbol into the given file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef draw_capitan_stroke_onto_canvas(self, export_path: ExportPath, stroke_thickness: int, margin: int):\n        width = int(self.dimensions.width + 2 * margin)\n        height = int(self.dimensions.height + 2 * margin)\n        offset = Point2D(self.dimensions.origin.x - margin, self.dimensions.origin.y - margin)\n\n        image = Image.new('RGB', (width, height), \"white\")  # create a new white image\n        draw = ImageDraw.Draw(image)\n        black = (0, 0, 0)\n\n        for i in range(0, len(self.stroke) - 1):\n            start_point = self.__subtract_offset(self.stroke[i], offset)\n            end_point = self.__subtract_offset(self.stroke[i + 1], offset)\n            distance = self.__euclidean_distance(start_point, end_point)\n            if distance > 1600:  # User moved more than 40 pixels - probably we should not draw a line here\n                continue\n            draw.line((start_point.x, start_point.y, end_point.x, end_point.y), black, stroke_thickness)\n\n        del draw\n\n        image.save(export_path.get_full_path())\n        image.close()", "response": "Draws the symbol strokes onto a canvas."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef overlap(r1: 'Rectangle', r2: 'Rectangle'):\n        h_overlaps = (r1.left <= r2.right) and (r1.right >= r2.left)\n        v_overlaps = (r1.bottom >= r2.top) and (r1.top <= r2.bottom)\n        return h_overlaps and v_overlaps", "response": "Returns True if two rectangles overlap both horizontally & vertically."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract the symbols from the raw XML documents and matching images of the Audiveris OMR dataset into the destination_directory.", "response": "def extract_symbols(self, raw_data_directory: str, destination_directory: str):\n        \"\"\"\n        Extracts the symbols from the raw XML documents and matching images of the Audiveris OMR dataset into\n        individual symbols\n\n        :param raw_data_directory: The directory, that contains the xml-files and matching images\n        :param destination_directory: The directory, in which the symbols should be generated into. One sub-folder per\n                                      symbol category will be generated automatically\n        \"\"\"\n        print(\"Extracting Symbols from Audiveris OMR Dataset...\")\n\n        all_xml_files = [y for x in os.walk(raw_data_directory) for y in glob(os.path.join(x[0], '*.xml'))]\n        all_image_files = [y for x in os.walk(raw_data_directory) for y in glob(os.path.join(x[0], '*.png'))]\n\n        data_pairs = []\n        for i in range(len(all_xml_files)):\n            data_pairs.append((all_xml_files[i], all_image_files[i]))\n\n        for data_pair in data_pairs:\n            self.__extract_symbols(data_pair[0], data_pair[1], destination_directory)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef convert_csv_annotations_to_cropobject(annotations_path: str, image_path: str) -> List[CropObject]:\n    annotations = pd.read_csv(annotations_path)\n    image = Image.open(image_path) # type: Image.Image\n\n    crop_objects = []\n    node_id = 0\n    for index, annotation in annotations.iterrows():\n        # Annotation example:\n        # image_name,top,left,bottom,right,class_name,confidence\n        # CVC-MUSCIMA_W-01_N-10_D-ideal_1.png,138.93,2286.36,185.20,2316.52,8th_flag,1.00\n        image_name = annotation[\"image_name\"]\n        class_name = annotation[\"class_name\"]\n        top = round(annotation[\"top\"])\n        left = round(annotation[\"left\"])\n        width = round(annotation[\"right\"] - annotation[\"left\"])\n        heigth = round(annotation[\"bottom\"] - annotation[\"top\"])\n        crop_object = CropObject(node_id, class_name, top, left, width, heigth)\n        crop_object.set_doc(image_name)\n        crop_image = image.crop((left, top, crop_object.right, crop_object.bottom)).convert(\"1\")\n        # noinspection PyTypeChecker\n        cropped_image_mask = np.array(crop_image)\n        crop_object.set_mask(cropped_image_mask)\n        crop_objects.append(crop_object)\n        node_id += 1\n\n    return crop_objects", "response": "Converts a normalized dataset of objects into CropObjects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the full path to the file that contains all the fields.", "response": "def get_full_path(self, offset: int = None):\n        \"\"\"\n        :return: Returns the full path that will join all fields according to the following format if no offset if provided:\n        'destination_directory'/'symbol_class'/'raw_file_name_without_extension'_'stroke_thickness'.'extension',\n        e.g.: data/images/3-4-Time/1-13_3.png\n\n        or with an additional offset-appendix if an offset is provided\n        'destination_directory'/'symbol_class'/'raw_file_name_without_extension'_'stroke_thickness'_offset_'offset'.'extension',\n        e.g.: data/images/3-4-Time/1-13_3_offset_74.png\n        \"\"\"\n        stroke_thickness = \"\"\n        if self.stroke_thickness is not None:\n            stroke_thickness = \"_{0}\".format(self.stroke_thickness)\n\n        staffline_offset = \"\"\n        if offset is not None:\n            staffline_offset = \"_offset_{0}\".format(offset)\n\n        return os.path.join(self.destination_directory, self.symbol_class,\n                            \"{0}{1}{2}.{3}\".format(self.raw_file_name_without_extension,\n                                                   stroke_thickness, staffline_offset, self.extension))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating and initializes a new symbol from a string.", "response": "def initialize_from_string(content: str) -> 'HomusSymbol':\n        \"\"\"\n        Create and initializes a new symbol from a string\n\n        :param content: The content of a symbol as read from the text-file\n        :return: The initialized symbol\n        :rtype: HomusSymbol\n        \"\"\"\n\n        if content is None or content is \"\":\n            return None\n\n        lines = content.splitlines()\n        min_x = sys.maxsize\n        max_x = 0\n        min_y = sys.maxsize\n        max_y = 0\n\n        symbol_name = lines[0]\n        strokes = []\n\n        for stroke_string in lines[1:]:\n            stroke = []\n\n            for point_string in stroke_string.split(\";\"):\n                if point_string is \"\":\n                    continue  # Skip the last element, that is due to a trailing ; in each line\n\n                point_x, point_y = point_string.split(\",\")\n                x = int(point_x)\n                y = int(point_y)\n                stroke.append(Point2D(x, y))\n\n                max_x = max(max_x, x)\n                min_x = min(min_x, x)\n                max_y = max(max_y, y)\n                min_y = min(min_y, y)\n\n            strokes.append(stroke)\n\n        dimensions = Rectangle(Point2D(min_x, min_y), max_x - min_x + 1, max_y - min_y + 1)\n        return HomusSymbol(content, strokes, symbol_name, dimensions)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef draw_into_bitmap(self, export_path: ExportPath, stroke_thickness: int, margin: int = 0) -> None:\n        self.draw_onto_canvas(export_path,\n                              stroke_thickness,\n                              margin,\n                              self.dimensions.width + 2 * margin,\n                              self.dimensions.height + 2 * margin)", "response": "Draw the symbol in the original size that it has plus an optional margin for each symbol."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndraw the symbol onto the canvas.", "response": "def draw_onto_canvas(self, export_path: ExportPath, stroke_thickness: int, margin: int, destination_width: int,\n                         destination_height: int, staff_line_spacing: int = 14,\n                         staff_line_vertical_offsets: List[int] = None,\n                         bounding_boxes: dict = None, random_position_on_canvas: bool = False) -> None:\n        \"\"\"\n        Draws the symbol onto a canvas with a fixed size\n\n        :param bounding_boxes: The dictionary into which the bounding-boxes will be added of each generated image\n        :param export_path: The path, where the symbols should be created on disk\n        :param stroke_thickness:\n        :param margin:\n        :param destination_width:\n        :param destination_height:\n        :param staff_line_spacing:\n        :param staff_line_vertical_offsets: Offsets used for drawing staff-lines. If None provided, no staff-lines will be drawn if multiple integers are provided, multiple images will be generated\n        \"\"\"\n        width = self.dimensions.width + 2 * margin\n        height = self.dimensions.height + 2 * margin\n        if random_position_on_canvas:\n            # max is required for elements that are larger than the canvas,\n            # where the possible range for the random value would be negative\n            random_horizontal_offset = random.randint(0, max(0, destination_width - width))\n            random_vertical_offset = random.randint(0, max(0, destination_height - height))\n            offset = Point2D(self.dimensions.origin.x - margin - random_horizontal_offset,\n                             self.dimensions.origin.y - margin - random_vertical_offset)\n        else:\n            width_offset_for_centering = (destination_width - width) / 2\n            height_offset_for_centering = (destination_height - height) / 2\n            offset = Point2D(self.dimensions.origin.x - margin - width_offset_for_centering,\n                             self.dimensions.origin.y - margin - height_offset_for_centering)\n\n        image_without_staff_lines = Image.new('RGB', (destination_width, destination_height),\n                                              \"white\")  # create a new white image\n        draw = ImageDraw.Draw(image_without_staff_lines)\n        black = (0, 0, 0)\n\n        for stroke in self.strokes:\n            for i in range(0, len(stroke) - 1):\n                start_point = self.__subtract_offset(stroke[i], offset)\n                end_point = self.__subtract_offset(stroke[i + 1], offset)\n                draw.line((start_point.x, start_point.y, end_point.x, end_point.y), black, stroke_thickness)\n\n        location = self.__subtract_offset(self.dimensions.origin, offset)\n        bounding_box_in_image = Rectangle(location, self.dimensions.width, self.dimensions.height)\n        # self.draw_bounding_box(draw, location)\n\n        del draw\n\n        if staff_line_vertical_offsets is not None and staff_line_vertical_offsets:\n            for staff_line_vertical_offset in staff_line_vertical_offsets:\n                image_with_staff_lines = image_without_staff_lines.copy()\n                self.__draw_staff_lines_into_image(image_with_staff_lines, stroke_thickness,\n                                                   staff_line_spacing, staff_line_vertical_offset)\n                file_name_with_offset = export_path.get_full_path(staff_line_vertical_offset)\n                image_with_staff_lines.save(file_name_with_offset)\n                image_with_staff_lines.close()\n\n                if bounding_boxes is not None:\n                    # Note that the ImageDatasetGenerator does not yield the full path, but only the class_name and\n                    # the file_name, e.g. '3-4-Time\\\\1-13_3_offset_74.png', so we store only that part in the dictionary\n                    class_and_file_name = export_path.get_class_name_and_file_path(staff_line_vertical_offset)\n                    bounding_boxes[class_and_file_name] = bounding_box_in_image\n        else:\n            image_without_staff_lines.save(export_path.get_full_path())\n            if bounding_boxes is not None:\n                # Note that the ImageDatasetGenerator does not yield the full path, but only the class_name and\n                # the file_name, e.g. '3-4-Time\\\\1-13_3_offset_74.png', so we store only that part in the dictionary\n                class_and_file_name = export_path.get_class_name_and_file_path()\n                bounding_boxes[class_and_file_name] = bounding_box_in_image\n\n        image_without_staff_lines.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\niterates over all of the detectors that are included in this sub - package.", "response": "def iter_detector_clss():\n    \"\"\"Iterate over all of the detectors that are included in this sub-package.\n    This is a convenience method for capturing all new Detectors that are added\n    over time and it is used both by the unit tests and in the\n    ``Scrubber.__init__`` method.\n    \"\"\"\n    return iter_subclasses(\n        os.path.dirname(os.path.abspath(__file__)),\n        Detector,\n        _is_abstract_detector,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninspects all modules in this directory for subclasses of inherit from base_cls.", "response": "def _iter_module_subclasses(package, module_name, base_cls):\n    \"\"\"inspect all modules in this directory for subclasses of inherit from\n    ``base_cls``. inpiration from http://stackoverflow.com/q/1796180/564709\n    \"\"\"\n    module = importlib.import_module('.' + module_name, package)\n    for name, obj in inspect.getmembers(module):\n        if inspect.isclass(obj) and issubclass(obj, base_cls):\n            yield obj"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_locals(locals_instance, instance_iterator, *args, **kwargs):\n    # http://stackoverflow.com/a/4526709/564709\n    # http://stackoverflow.com/a/511059/564709\n    for instance in instance_iterator():\n        locals_instance.update({type(instance).__name__: instance.__class__})", "response": "Update the local namespace with the detector classes from the given iterator."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef iter_filth_clss():\n    return iter_subclasses(\n        os.path.dirname(os.path.abspath(__file__)),\n        Filth,\n        _is_abstract_filth,\n    )", "response": "Iterate over all of the filths that are included in this sub - package."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef iter_filths():\n    for filth_cls in iter_filth_clss():\n        if issubclass(filth_cls, RegexFilth):\n            m = next(re.finditer(r\"\\s+\", \"fake pattern string\"))\n            yield filth_cls(m)\n        else:\n            yield filth_cls()", "response": "Iterate over all filths in the tree"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _update_content(self, other_filth):\n        if self.end < other_filth.beg or other_filth.end < self.beg:\n            raise exceptions.FilthMergeError(\n                \"a_filth goes from [%s, %s) and b_filth goes from [%s, %s)\" % (\n                    self.beg, self.end, other_filth.beg, other_filth.end\n                ))\n\n        # get the text over lap correct\n        if self.beg < other_filth.beg:\n            first = self\n            second = other_filth\n        else:\n            second = self\n            first = other_filth\n        end_offset = second.end - first.end\n        if end_offset > 0:\n            self.text = first.text + second.text[-end_offset:]\n\n        # update the beg/end strings\n        self.beg = min(self.beg, other_filth.beg)\n        self.end = max(self.end, other_filth.end)\n        if self.end - self.beg != len(self.text):\n            raise exceptions.FilthMergeError(\"text length isn't consistent\")\n\n        # update the placeholder\n        self.filths.append(other_filth)\n        self._placeholder = '+'.join([filth.type for filth in self.filths])", "response": "this updates the bounds text and placeholder for the merged Arc with the content of the other Arc Arc."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_detector(self, detector_cls):\n        if not issubclass(detector_cls, detectors.base.Detector):\n            raise TypeError((\n                '\"%(detector_cls)s\" is not a subclass of Detector'\n            ) % locals())\n        # TODO: should add tests to make sure filth_cls is actually a proper\n        # filth_cls\n        name = detector_cls.filth_cls.type\n        if name in self._detectors:\n            raise KeyError((\n                'can not add Detector \"%(name)s\"---it already exists. '\n                'Try removing it first.'\n            ) % locals())\n        self._detectors[name] = detector_cls()", "response": "Add a detector to scrubadub"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef iter_filth(self, text):\n        # currently doing this by aggregating all_filths and then sorting\n        # inline instead of with a Filth.__cmp__ method, which is apparently\n        # much slower http://stackoverflow.com/a/988728/564709\n        #\n        # NOTE: we could probably do this in a more efficient way by iterating\n        # over all detectors simultaneously. just trying to get something\n        # working right now and we can worry about efficiency later\n        all_filths = []\n        for detector in self._detectors.values():\n            for filth in detector.iter_filth(text):\n                if not isinstance(filth, Filth):\n                    raise TypeError('iter_filth must always yield Filth')\n                all_filths.append(filth)\n\n        # Sort by start position. If two filths start in the same place then\n        # return the longer one first\n        all_filths.sort(key=lambda f: (f.beg, -f.end))\n\n        # this is where the Scrubber does its hard work and merges any\n        # overlapping filths.\n        if not all_filths:\n            raise StopIteration\n        filth = all_filths[0]\n        for next_filth in all_filths[1:]:\n            if filth.end < next_filth.beg:\n                yield filth\n                filth = next_filth\n            else:\n                filth = filth.merge(next_filth)\n        yield filth", "response": "Iterate over the different types of filth that can exist."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninitialize the cache pool.", "response": "async def init(self, *args, dialect=None, **kwargs):\n        \"\"\"\n        :param args: args for pool\n        :param dialect: sqlalchemy postgres dialect\n        :param kwargs: kwargs for pool\n        :return: None\n        \"\"\"\n        self.__pool = await create_pool(*args, dialect=dialect, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmaking a read only query. Ideal for select statements.", "response": "def query(self, query, *args, prefetch=None, timeout=None):\n        \"\"\"\n        make a read only query. Ideal for select statements.\n        This method converts the query to a prepared statement\n        and uses a cursor to return the results. So you only get\n        so many rows at a time. This can dramatically increase performance\n        for queries that have a lot of results/responses as not everything has\n        to be loaded into memory at once.\n        You can use this with the `await` keyword to not use a cursor.\n\n        Use the following syntax for a cursor\n        async with query() as cursor:\n            async for row in cursor:\n                a = row['col_name']\n\n        or the following for a all results and no cursor/transaction:\n        results = await query()\n\n        :param query: query to be performed\n        :param args: parameters to query (if a string)\n        :param callback: a callback to call with the responses\n        :param int prefetch: The number of rows the *cursor iterator*\n                             will prefetch (defaults to ``50``.)\n        :param float timeout: Optional timeout in seconds.\n        :return:\n        \"\"\"\n        compiled_q, compiled_args = compile_query(query)\n        query, args = compiled_q, compiled_args or args\n\n        return QueryContextManager(self.pool, query, args,\n                                   prefetch=prefetch, timeout=timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def download_file(self, Bucket, Key, Filename, ExtraArgs=None, Callback=None, Config=None):\n    with open(Filename, 'wb') as open_file:\n        await download_fileobj(self, Bucket, Key, open_file, ExtraArgs=ExtraArgs, Callback=Callback, Config=Config)", "response": "Download an S3 object to a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndownloads an object from S3 to a file - like object.", "response": "async def download_fileobj(self, Bucket, Key, Fileobj, ExtraArgs=None, Callback=None, Config=None):\n    \"\"\"Download an object from S3 to a file-like object.\n\n    The file-like object must be in binary mode.\n\n    This is a managed transfer which will perform a multipart download in\n    multiple threads if necessary.\n\n    Usage::\n\n        import boto3\n        s3 = boto3.client('s3')\n\n        with open('filename', 'wb') as data:\n            s3.download_fileobj('mybucket', 'mykey', data)\n\n    :type Fileobj: a file-like object\n    :param Fileobj: A file-like object to download into. At a minimum, it must\n        implement the `write` method and must accept bytes.\n\n    :type Bucket: str\n    :param Bucket: The name of the bucket to download from.\n\n    :type Key: str\n    :param Key: The name of the key to download from.\n\n    :type ExtraArgs: dict\n    :param ExtraArgs: Extra arguments that may be passed to the\n        client operation.\n\n    :type Callback: method\n    :param Callback: A method which takes a number of bytes transferred to\n        be periodically called during the download.\n\n    :type Config: boto3.s3.transfer.TransferConfig\n    :param Config: The transfer configuration to be used when performing the\n        download.\n    \"\"\"\n\n    try:\n        resp = await self.get_object(Bucket=Bucket, Key=Key)\n    except ClientError as err:\n        if err.response['Error']['Code'] == 'NoSuchKey':\n            # Convert to 404 so it looks the same when boto3.download_file fails\n            raise ClientError({'Error': {'Code': '404', 'Message': 'Not Found'}}, 'HeadObject')\n        raise\n\n    body = resp['Body']\n\n    while True:\n        data = await body.read(4096)\n\n        if data == b'':\n            break\n\n        if Callback:\n            try:\n                Callback(len(data))\n            except:  # noqa: E722\n                pass\n\n        Fileobj.write(data)\n        await asyncio.sleep(0.0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nuploads a file - like object to S3.", "response": "async def upload_fileobj(self, Fileobj: BinaryIO, Bucket: str, Key: str, ExtraArgs: Optional[Dict[str, Any]] = None,\n                         Callback: Optional[Callable[[int], None]] = None,\n                         Config: Optional[S3TransferConfig] = None):\n    \"\"\"Upload a file-like object to S3.\n\n    The file-like object must be in binary mode.\n\n    This is a managed transfer which will perform a multipart upload in\n    multiple threads if necessary.\n\n    Usage::\n\n        import boto3\n        s3 = boto3.client('s3')\n\n        with open('filename', 'rb') as data:\n            s3.upload_fileobj(data, 'mybucket', 'mykey')\n\n    :type Fileobj: a file-like object\n    :param Fileobj: A file-like object to upload. At a minimum, it must\n        implement the `read` method, and must return bytes.\n\n    :type Bucket: str\n    :param Bucket: The name of the bucket to upload to.\n\n    :type Key: str\n    :param Key: The name of the key to upload to.\n\n    :type ExtraArgs: dict\n    :param ExtraArgs: Extra arguments that may be passed to the\n        client operation.\n\n    :type Callback: method\n    :param Callback: A method which takes a number of bytes transferred to\n        be periodically called during the upload.\n\n    :type Config: boto3.s3.transfer.TransferConfig\n    :param Config: The transfer configuration to be used when performing the\n        upload.\n    \"\"\"\n    if not ExtraArgs:\n        ExtraArgs = {}\n\n    # I was debating setting up a queue etc...\n    # If its too slow I'll then be bothered\n    multipart_chunksize = 8388608 if Config is None else Config.multipart_chunksize\n    io_chunksize = 262144 if Config is None else Config.io_chunksize\n    # max_concurrency = 10 if Config is None else Config.max_concurrency\n    # max_io_queue = 100 if config is None else Config.max_io_queue\n\n    # Start multipart upload\n\n    resp = await self.create_multipart_upload(Bucket=Bucket, Key=Key, **ExtraArgs)\n    upload_id = resp['UploadId']\n\n    part = 0\n    parts = []\n    running = True\n    sent_bytes = 0\n\n    try:\n        while running:\n            part += 1\n            multipart_payload = b''\n            while len(multipart_payload) < multipart_chunksize:\n                if asyncio.iscoroutinefunction(Fileobj.read):  # handles if we pass in aiofiles obj\n                    data = await Fileobj.read(io_chunksize)\n                else:\n                    data = Fileobj.read(io_chunksize)\n\n                if data == b'':  # End of file\n                    running = False\n                    break\n                multipart_payload += data\n\n            # Submit part to S3\n            resp = await self.upload_part(\n                Body=multipart_payload,\n                Bucket=Bucket,\n                Key=Key,\n                PartNumber=part,\n                UploadId=upload_id\n            )\n            parts.append({'ETag': resp['ETag'], 'PartNumber': part})\n            sent_bytes += len(multipart_payload)\n            try:\n                Callback(sent_bytes)  # Attempt to call the callback, if it fails, ignore, if no callback, ignore\n            except:  # noqa: E722\n                pass\n\n        # By now the uploads must have been done\n        await self.complete_multipart_upload(\n            Bucket=Bucket,\n            Key=Key,\n            UploadId=upload_id,\n            MultipartUpload={'Parts': parts}\n        )\n    except:  # noqa: E722\n        # Cancel multipart upload\n        await self.abort_multipart_upload(\n            Bucket=Bucket,\n            Key=Key,\n            UploadId=upload_id\n        )\n\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def upload_file(self, Filename, Bucket, Key, ExtraArgs=None, Callback=None, Config=None):\n    with open(Filename, 'rb') as open_file:\n        await upload_fileobj(self, open_file, Bucket, Key, ExtraArgs=ExtraArgs, Callback=Callback, Config=Config)", "response": "Upload a file to an S3 object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading a single resource from a json definition.", "response": "def load_from_definition(self, resource_name,\n                             single_resource_json_definition, service_context):\n        \"\"\"\n        Loads a resource from a model, creating a new\n        :py:class:`~boto3.resources.base.ServiceResource` subclass\n        with the correct properties and methods, named based on the service\n        and resource name, e.g. EC2.Instance.\n\n        :type resource_name: string\n        :param resource_name: Name of the resource to look up. For services,\n                              this should match the ``service_name``.\n\n        :type single_resource_json_definition: dict\n        :param single_resource_json_definition:\n            The loaded json of a single service resource or resource\n            definition.\n\n        :type service_context: :py:class:`~boto3.utils.ServiceContext`\n        :param service_context: Context about the AWS service\n\n        :rtype: Subclass of :py:class:`~boto3.resources.base.ServiceResource`\n        :return: The service or resource class.\n        \"\"\"\n        logger.debug('Loading %s:%s', service_context.service_name,\n                     resource_name)\n\n        # Using the loaded JSON create a ResourceModel object.\n        resource_model = ResourceModel(\n            resource_name, single_resource_json_definition,\n            service_context.resource_json_definitions\n        )\n\n        # Do some renaming of the shape if there was a naming collision\n        # that needed to be accounted for.\n        shape = None\n        if resource_model.shape:\n            shape = service_context.service_model.shape_for(\n                resource_model.shape)\n        resource_model.load_rename_map(shape)\n\n        # Set some basic info\n        meta = ResourceMeta(\n            service_context.service_name, resource_model=resource_model)\n        attrs = {\n            'meta': meta,\n        }\n\n        # Create and load all of attributes of the resource class based\n        # on the models.\n\n        # Identifiers\n        self._load_identifiers(\n            attrs=attrs, meta=meta, resource_name=resource_name,\n            resource_model=resource_model\n        )\n\n        # Load/Reload actions\n        self._load_actions(\n            attrs=attrs, resource_name=resource_name,\n            resource_model=resource_model, service_context=service_context\n        )\n\n        # Attributes that get auto-loaded\n        self._load_attributes(\n            attrs=attrs, meta=meta, resource_name=resource_name,\n            resource_model=resource_model,\n            service_context=service_context)\n\n        # Collections and their corresponding methods\n        self._load_collections(\n            attrs=attrs, resource_model=resource_model,\n            service_context=service_context)\n\n        # References and Subresources\n        self._load_has_relations(\n            attrs=attrs, resource_name=resource_name,\n            resource_model=resource_model, service_context=service_context\n        )\n\n        # Waiter resource actions\n        self._load_waiters(\n            attrs=attrs, resource_name=resource_name,\n            resource_model=resource_model, service_context=service_context\n        )\n\n        # Create the name based on the requested service and resource\n        cls_name = resource_name\n        if service_context.service_name == resource_name:\n            cls_name = 'ServiceResource'\n        cls_name = service_context.service_name + '.' + cls_name\n\n        base_classes = [AIOBoto3ServiceResource]\n        if self._emitter is not None:\n            self._emitter.emit(\n                'creating-resource-class.%s' % cls_name,\n                class_attributes=attrs, base_classes=base_classes,\n                service_context=service_context)\n        return type(str(cls_name), tuple(base_classes), attrs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new action in this closure.", "response": "def _create_action(factory_self, action_model, resource_name,\n                       service_context, is_load=False):\n        \"\"\"\n        Creates a new method which makes a request to the underlying\n        AWS service.\n        \"\"\"\n        # Create the action in in this closure but before the ``do_action``\n        # method below is invoked, which allows instances of the resource\n        # to share the ServiceAction instance.\n        action = AIOServiceAction(\n            action_model, factory=factory_self,\n            service_context=service_context\n        )\n\n        # A resource's ``load`` method is special because it sets\n        # values on the resource instead of returning the response.\n        if is_load:\n            # We need a new method here because we want access to the\n            # instance via ``self``.\n            async def do_action(self, *args, **kwargs):\n                # response = action(self, *args, **kwargs)\n                response = await action.async_call(self, *args, **kwargs)\n                self.meta.data = response\n\n            # Create the docstring for the load/reload mehtods.\n            lazy_docstring = docstring.LoadReloadDocstring(\n                action_name=action_model.name,\n                resource_name=resource_name,\n                event_emitter=factory_self._emitter,\n                load_model=action_model,\n                service_model=service_context.service_model,\n                include_signature=False\n            )\n        else:\n            # We need a new method here because we want access to the\n            # instance via ``self``.\n            async def do_action(self, *args, **kwargs):\n                response = await action.async_call(self, *args, **kwargs)\n\n                if hasattr(self, 'load'):\n                    # Clear cached data. It will be reloaded the next\n                    # time that an attribute is accessed.\n                    # TODO: Make this configurable in the future?\n                    self.meta.data = None\n\n                return response\n\n            lazy_docstring = docstring.ActionDocstring(\n                resource_name=resource_name,\n                event_emitter=factory_self._emitter,\n                action_model=action_model,\n                service_model=service_context.service_model,\n                include_signature=False\n            )\n\n        do_action.__name__ = str(action_model.name)\n        do_action.__doc__ = lazy_docstring\n        return do_action"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef client(*args, loop=None, **kwargs):\n    return _get_default_session(loop=loop).client(*args, **kwargs)", "response": "Create a low - level service client by name using the default session."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a resource service client by name using the default session.", "response": "def resource(*args, loop=None, **kwargs):\n    \"\"\"\n    Create a resource service client by name using the default session.\n    See :py:meth:`aioboto3.session.Session.resource`.\n    \"\"\"\n    return _get_default_session(loop=loop).resource(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the AES key for a given S3 object.", "response": "async def get_decryption_aes_key(self, key: bytes, material_description: Dict[str, Any]) -> bytes:\n        \"\"\"\n        Get decryption key for a given S3 object\n\n        :param key: Base64 decoded version of x-amz-key-v2\n        :param material_description: JSON decoded x-amz-matdesc\n        :return: Raw AES key bytes\n        \"\"\"\n        raise NotImplementedError()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the AES key for a given S3 object.", "response": "async def get_decryption_aes_key(self, key: bytes, material_description: Dict[str, Any]) -> bytes:\n        \"\"\"\n        Get decryption key for a given S3 object\n\n        :param key: Base64 decoded version of x-amz-key\n        :param material_description: JSON decoded x-amz-matdesc\n        :return: Raw AES key bytes\n        \"\"\"\n        if self.private_key is None:\n            raise ValueError('Private key not provided during initialisation, cannot decrypt key encrypting key')\n\n        plaintext = await self._loop.run_in_executor(None, lambda: (self.private_key.decrypt(key, padding.PKCS1v15())))\n\n        return plaintext"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the AES key to encrypt an S3 object", "response": "async def get_encryption_aes_key(self) -> Tuple[bytes, Dict[str, str], str]:\n        \"\"\"\n        Get encryption key to encrypt an S3 object\n\n        :return: Raw AES key bytes, Stringified JSON x-amz-matdesc, Base64 encoded x-amz-key\n        \"\"\"\n        if self.public_key is None:\n            raise ValueError('Public key not provided during initialisation, cannot encrypt key encrypting key')\n\n        random_bytes = os.urandom(32)\n\n        ciphertext = await self._loop.run_in_executor(\n            None, lambda: (self.public_key.encrypt(random_bytes, padding.PKCS1v15())))\n\n        return random_bytes, {}, base64.b64encode(ciphertext).decode()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_der_private_key(data: bytes, password: Optional[str] = None) -> _RSAPrivateKey:\n        return serialization.load_der_private_key(data, password, default_backend())", "response": "Convert a DER encoded private key in DER encoding to a Private key object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def get_decryption_aes_key(self, key: bytes, material_description: Dict[str, Any]) -> bytes:\n\n        # So it seems when java just calls Cipher.getInstance('AES') it'll default to AES/ECB/PKCS5Padding\n        aesecb = self._cipher.decryptor()\n        padded_result = await self._loop.run_in_executor(None, lambda: (aesecb.update(key) + aesecb.finalize()))\n\n        unpadder = PKCS7(AES.block_size).unpadder()\n        result = await self._loop.run_in_executor(None, lambda: (unpadder.update(padded_result) + unpadder.finalize()))\n\n        return result", "response": "Get the decryption AES key for a given S3 object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the AES key to encrypt an S3 object.", "response": "async def get_encryption_aes_key(self) -> Tuple[bytes, Dict[str, str], str]:\n        \"\"\"\n        Get encryption key to encrypt an S3 object\n\n        :return: Raw AES key bytes, Stringified JSON x-amz-matdesc, Base64 encoded x-amz-key\n        \"\"\"\n\n        random_bytes = os.urandom(32)\n\n        padder = PKCS7(AES.block_size).padder()\n        padded_result = await self._loop.run_in_executor(\n            None, lambda: (padder.update(random_bytes) + padder.finalize()))\n\n        aesecb = self._cipher.encryptor()\n        encrypted_result = await self._loop.run_in_executor(\n            None, lambda: (aesecb.update(padded_result) + aesecb.finalize()))\n\n        return random_bytes, {}, base64.b64encode(encrypted_result).decode()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def get_object(self, Bucket: str, Key: str, **kwargs) -> dict:\n        if self._s3_client is None:\n            await self.setup()\n\n        # Ok so if we are doing a range get. We need to align the range start/end with AES block boundaries\n        # 9223372036854775806 is 8EiB so I have no issue with hardcoding it.\n        # We pass the actual start, desired start and desired end to the decrypt function so that it can\n        # generate the correct IV's for starting decryption at that block and then chop off the start and end of the\n        # AES block so it matches what the user is expecting.\n        _range = kwargs.get('Range')\n        actual_range_start = None\n        desired_range_start = None\n        desired_range_end = None\n        if _range:\n            range_match = RANGE_REGEX.match(_range)\n            if not range_match:\n                raise ValueError('Dont understand this range value {0}'.format(_range))\n\n            desired_range_start = int(range_match.group(1))\n            desired_range_end = range_match.group(2)\n            if desired_range_end is None:\n                desired_range_end = 9223372036854775806\n            else:\n                desired_range_end = int(desired_range_end)\n\n            actual_range_start, actual_range_end = _get_adjusted_crypto_range(desired_range_start, desired_range_end)\n\n            # Update range with actual start_end\n            kwargs['Range'] = 'bytes={0}-{1}'.format(actual_range_start, actual_range_end)\n\n        s3_response = await self._s3_client.get_object(Bucket=Bucket, Key=Key, **kwargs)\n        file_data = await s3_response['Body'].read()\n        metadata = s3_response['Metadata']\n        whole_file_length = int(s3_response['ResponseMetadata']['HTTPHeaders']['content-length'])\n\n        if 'x-amz-key' not in metadata and 'x-amz-key-v2' not in metadata:\n            # No crypto\n            return s3_response\n\n        if 'x-amz-key' in metadata:\n            # Crypto V1\n            body = await self._decrypt_v1(file_data, metadata, actual_range_start)\n        else:\n            # Crypto V2\n            body = await self._decrypt_v2(file_data, metadata, whole_file_length,\n                                          actual_range_start, desired_range_start,\n                                          desired_range_end)\n\n        s3_response['Body'] = DummyAIOFile(body)\n\n        return s3_response", "response": "S3 GetObject. Takes same args as Boto3 documentation and returns dict of object metadata."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def put_object(self, Body: Union[bytes, IO], Bucket: str, Key: str, Metadata: Dict = None, **kwargs):\n        if self._s3_client is None:\n            await self.setup()\n\n        if hasattr(Body, 'read'):\n            if inspect.iscoroutinefunction(Body.read):\n                Body = await Body.read()\n            else:\n                Body = Body.read()\n\n        # We do some different V2 stuff if using kms\n        is_kms = isinstance(self._crypto_context, KMSCryptoContext)\n        # noinspection PyUnresolvedReferences\n        authenticated_crypto = is_kms and self._crypto_context.authenticated_encryption\n\n        Metadata = Metadata if Metadata is not None else {}\n\n        aes_key, matdesc_metadata, key_metadata = await self._crypto_context.get_encryption_aes_key()\n\n        if is_kms and authenticated_crypto:\n            Metadata['x-amz-cek-alg'] = 'AES/GCM/NoPadding'\n            Metadata['x-amz-tag-len'] = str(AES_BLOCK_SIZE)\n            iv = os.urandom(12)\n\n            # 16byte 128bit authentication tag forced\n            aesgcm = AESGCM(aes_key)\n\n            result = await self._loop.run_in_executor(None, lambda: aesgcm.encrypt(iv, Body, None))\n\n        else:\n            if is_kms:  # V1 is always AES/CBC/PKCS5Padding\n                Metadata['x-amz-cek-alg'] = 'AES/CBC/PKCS5Padding'\n\n            iv = os.urandom(16)\n\n            padder = PKCS7(AES.block_size).padder()\n            padded_result = await self._loop.run_in_executor(None, lambda: (padder.update(Body) + padder.finalize()))\n\n            aescbc = Cipher(AES(aes_key), CBC(iv), backend=self._backend).encryptor()\n            result = await self._loop.run_in_executor(None, lambda: (aescbc.update(padded_result) + aescbc.finalize()))\n\n        # For all V1 and V2\n        Metadata['x-amz-unencrypted-content-length'] = str(len(Body))\n        Metadata['x-amz-iv'] = base64.b64encode(iv).decode()\n        Metadata['x-amz-matdesc'] = json.dumps(matdesc_metadata)\n\n        if is_kms:\n            Metadata['x-amz-wrap-alg'] = 'kms'\n            Metadata['x-amz-key-v2'] = key_metadata\n        else:\n            Metadata['x-amz-key'] = key_metadata\n\n        await self._s3_client.put_object(\n            Bucket=Bucket,\n            Key=Key,\n            Body=result,\n            Metadata=Metadata,\n            **kwargs\n        )", "response": "This method writes an object to the S3 Bucket."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing a 1D histogram assuming equally spaced bins.", "response": "def histogram1d(x, bins, range, weights=None):\n    \"\"\"\n    Compute a 1D histogram assuming equally spaced bins.\n\n    Parameters\n    ----------\n    x : `~numpy.ndarray`\n        The position of the points to bin in the 1D histogram\n    bins : int\n        The number of bins\n    range : iterable\n        The range as a tuple of (xmin, xmax)\n    weights : `~numpy.ndarray`\n        The weights of the points in the 1D histogram\n\n    Returns\n    -------\n    array : `~numpy.ndarray`\n        The 1D histogram array\n    \"\"\"\n\n    nx = bins\n\n    if not np.isscalar(bins):\n        raise TypeError('bins should be an integer')\n\n    xmin, xmax = range\n\n    if not np.isfinite(xmin):\n        raise ValueError(\"xmin should be finite\")\n\n    if not np.isfinite(xmax):\n        raise ValueError(\"xmax should be finite\")\n\n    if xmax <= xmin:\n        raise ValueError(\"xmax should be greater than xmin\")\n\n    if nx <= 0:\n        raise ValueError(\"nx should be strictly positive\")\n\n    if weights is None:\n        return _histogram1d(x, nx, xmin, xmax)\n    else:\n        return _histogram1d_weighted(x, weights, nx, xmin, xmax)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef histogram2d(x, y, bins, range, weights=None):\n\n    if isinstance(bins, numbers.Integral):\n        nx = ny = bins\n    else:\n        nx, ny = bins\n\n    if not np.isscalar(nx) or not np.isscalar(ny):\n        raise TypeError('bins should be an iterable of two integers')\n\n    (xmin, xmax), (ymin, ymax) = range\n\n    if not np.isfinite(xmin):\n        raise ValueError(\"xmin should be finite\")\n\n    if not np.isfinite(xmax):\n        raise ValueError(\"xmax should be finite\")\n\n    if not np.isfinite(ymin):\n        raise ValueError(\"ymin should be finite\")\n\n    if not np.isfinite(ymax):\n        raise ValueError(\"ymax should be finite\")\n\n    if xmax <= xmin:\n        raise ValueError(\"xmax should be greater than xmin\")\n\n    if ymax <= ymin:\n        raise ValueError(\"xmax should be greater than xmin\")\n\n    if nx <= 0:\n        raise ValueError(\"nx should be strictly positive\")\n\n    if ny <= 0:\n        raise ValueError(\"ny should be strictly positive\")\n\n    if weights is None:\n        return _histogram2d(x, y, nx, xmin, xmax, ny, ymin, ymax)\n    else:\n        return _histogram2d_weighted(x, y, weights, nx, xmin, xmax, ny, ymin, ymax)", "response": "Compute a 2D histogram assuming equally spaced bins."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_networkx(self):\n        return nx_util.to_networkx(self.session.get(self.__url).json())", "response": "Return this network in NetworkX graph object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns this network in pandas DataFrame.", "response": "def to_dataframe(self, extra_edges_columns=[]):\n        \"\"\"\n        Return this network in pandas DataFrame.\n\n        :return: Network as DataFrame.  This is equivalent to SIF.\n        \"\"\"\n        return df_util.to_dataframe(\n            self.session.get(self.__url).json(),\n            edges_attr_cols=extra_edges_columns\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_node(self, node_name, dataframe=False):\n        if node_name is None:\n            return None\n        return self.add_nodes([node_name], dataframe=dataframe)", "response": "Add a single node to the network."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd new nodes to the network.", "response": "def add_nodes(self, node_name_list, dataframe=False):\n        \"\"\"\n        Add new nodes to the network\n\n        :param node_name_list: list of node names, e.g. ['a', 'b', 'c']\n        :param dataframe: If True, return a pandas dataframe instead of a dict.\n        :return: A dict mapping names to SUIDs for the newly-created nodes.\n        \"\"\"\n        res = self.session.post(self.__url + 'nodes', data=json.dumps(node_name_list), headers=HEADERS)\n        check_response(res)\n        nodes = res.json()\n        if dataframe:\n            return pd.DataFrame(nodes).set_index(['SUID'])\n        else:\n            return {node['name']: node['SUID'] for node in nodes}"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_edge(self, source, target, interaction='-', directed=True, dataframe=True):\n        new_edge = {\n            'source': source,\n            'target': target,\n            'interaction': interaction,\n            'directed': directed\n        }\n        return self.add_edges([new_edge], dataframe=dataframe)", "response": "Add a single edge from source to target."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a list of edges to the Cytoscape SUIDs for the newly - created edges.", "response": "def add_edges(self, edge_list, dataframe=True):\n        \"\"\"\n        Add a all edges in edge_list.\n        :return: A data structure with Cytoscape SUIDs for the newly-created edges.\n        :param edge_list: List of (source, target, interaction) tuples *or*\n                          list of dicts with 'source', 'target', 'interaction', 'direction' keys.\n        :param dataframe: If dataframe is True (default), return a Pandas DataFrame.\n                          If dataframe is False, return a list of dicts with keys 'SUID', 'source' and 'target'.\n        \"\"\"\n        # It might be nice to have an option pass a list of dicts instead of list of tuples\n        if not isinstance(edge_list[0], dict):\n            edge_list = [{'source': edge_tuple[0],\n                          'target': edge_tuple[1],\n                          'interaction': edge_tuple[2]}\n                         for edge_tuple in edge_list]\n        res = self.session.post(self.__url + 'edges', data=json.dumps(edge_list), headers=HEADERS)\n        check_response(res)\n        edges = res.json()\n        if dataframe:\n            return pd.DataFrame(edges).set_index(['SUID'])\n        else:\n            return edges"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_views(self):\n        url = self.__url + 'views'\n        return self.session.get(url).json()", "response": "Get views as a list of SUIDs\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_first_view(self, fmt='json'):\n        url = self.__url + 'views/first'\n        return self.session.get(url).json()", "response": "Get a first view model as dict\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a Cytoscape. js - style JSON object into NetworkX object.", "response": "def to_networkx(cyjs, directed=True):\n    \"\"\"\n    Convert Cytoscape.js-style JSON object into NetworkX object.\n\n    By default, data will be handles as a directed graph.\n    \"\"\"\n\n    if directed:\n        g = nx.MultiDiGraph()\n    else:\n        g = nx.MultiGraph()\n\n    network_data = cyjs[DATA]\n    if network_data is not None:\n        for key in network_data.keys():\n            g.graph[key] = network_data[key]\n\n    nodes = cyjs[ELEMENTS][NODES]\n    edges = cyjs[ELEMENTS][EDGES]\n\n    for node in nodes:\n        data = node[DATA]\n        g.add_node(data[ID], attr_dict=data)\n\n    for edge in edges:\n        data = edge[DATA]\n        source = data[SOURCE]\n        target = data[TARGET]\n\n        g.add_edge(source, target, attr_dict=data)\n\n    return g"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlaunch and HTML browser in a separate window.", "response": "def dialog(self=None, wid=None, text=None, title=None, url=None, debug=False, verbose=False):\n        \"\"\"\n        Launch and HTML browser in a separate window.\n\n        :param wid: Window ID\n        :param text: HTML text\n        :param title: Window Title\n        :param url: URL\n        :param debug: Show debug tools. boolean\n        :param verbose: print more\n        \"\"\"\n\n        PARAMS=set_param([\"id\",\"text\",\"title\",\"url\",\"debug\"],[wid,text,title,url,debug])\n        response=api(url=self.__url+\"/dialog?\",PARAMS=PARAMS, method=\"GET\", verbose=verbose)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhide and HTML browser in the Results Panel.", "response": "def hide(self, wid, verbose=False):\n        \"\"\"\n        Hide and HTML browser in the Results Panel.\n\n        :param wid: Window ID\n        :param verbose: print more\n        \"\"\"\n\n        PARAMS={\"id\":wid}\n\n        response=api(url=self.__url+\"/hide?\",PARAMS=PARAMS, method=\"GET\", verbose=verbose)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlaunch an HTML browser in the Results Panel. :param wid: Window ID :param text: HTML text :param title: Window Title :param url: URL :param verbose: print more", "response": "def show(self, wid=None, text=None, title=None, url=None, verbose=False):\n        \"\"\"\n        Launch an HTML browser in the Results Panel.\n\n        :param wid: Window ID\n        :param text: HTML text\n        :param title: Window Title\n        :param url: URL\n        :param verbose: print more\n        \"\"\"\n\n        PARAMS={}\n        for p,v in zip([\"id\",\"text\",\"title\",\"url\"],[wid,text,title,url]):\n            if v:\n                PARAMS[p]=v\n\n        response=api(url=self.__url+\"/show?\",PARAMS=PARAMS, method=\"GET\", verbose=verbose)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_response(res):\n    try:\n        res.raise_for_status() # Alternative is res.ok\n    except Exception as exc:\n        # Bad response code, e.g. if adding an edge with nodes that doesn't exist\n        try:\n            err_info = res.json()\n            err_msg = err_info['message'] # or 'localizeMessage'\n        except ValueError:\n            err_msg = res.text[:40] # Take the first 40 chars of the response\n        except KeyError:\n            err_msg = res.text[:40] + (\"(No 'message' in err_info dict: %s\"\n                                       % list(err_info.keys()))\n        exc.args += (err_msg,)\n        raise exc", "response": "Check HTTP response and raise exception if response is not OK."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_dataframe(df,\n                   source_col='source',\n                   target_col='target',\n                   interaction_col='interaction',\n                   name='From DataFrame',\n                   edge_attr_cols=[]):\n    \"\"\"\n    Utility to convert Pandas DataFrame object into Cytoscape.js JSON\n\n    :param df: Dataframe to convert.\n    :param source_col: Name of source column.\n    :param target_col: Name of target column.\n    :param interaction_col: Name of interaction column.\n    :param name: Name of network.\n    :param edge_attr_cols: List containing other columns to consider in df as\n        edges' attributes.\n    :return: Dictionary version of df.\n    \"\"\"\n\n    network = cyjs.get_empty_network(name=name)\n    nodes = set()\n    if edge_attr_cols is None:\n        edge_attr_cols = []\n\n    for index, row in df.iterrows():\n        s = row[source_col]\n        t = row[target_col]\n        if s not in nodes:\n            nodes.add(s)\n            source = get_node(s)\n            network['elements']['nodes'].append(source)\n        if t not in nodes:\n            nodes.add(t)\n            target = get_node(t)\n            network['elements']['nodes'].append(target)\n\n        extra_values = {column: row[column]\n                        for column in edge_attr_cols\n                        if column in df.columns}\n\n        network['elements']['edges'].append(\n            get_edge(s, t, interaction=row[interaction_col], **extra_values)\n        )\n    return network", "response": "Utility to convert Pandas DataFrame object into Cytoscape. js JSON object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_dataframe(network,\n                 interaction='interaction',\n                 default_interaction='-',\n                 edges_attr_cols=[]):\n    \"\"\"\n    Utility to convert a Cytoscape dictionary into a Pandas Dataframe.\n\n    :param network: Dictionary to convert.\n    :param interaction: Name of interaction column.\n    :param default_interaction: Default value for missing interactions.\n    :param edges_attr_cols: List containing other edges' attributes to include\n        in the Dataframe, if present in network.\n    :return: Converted Pandas Dataframe.\n    \"\"\"\n\n    edges = network['elements']['edges']\n    if edges_attr_cols is None:\n        edges_attr_cols = []\n    edges_attr_cols = sorted(edges_attr_cols)\n\n    network_array = []\n    # the set avoids duplicates\n    valid_extra_cols = set()\n    for edge in edges:\n        edge_data = edge['data']\n        source = edge_data['source']\n        target = edge_data['target']\n        if interaction in edge_data:\n            itr = edge_data[interaction]\n        else:\n            itr = default_interaction\n        extra_values = []\n        for extra_column in edges_attr_cols:\n            if extra_column in edge_data:\n                extra_values.append(edge_data[extra_column])\n                valid_extra_cols.add(extra_column)\n        row = tuple([source, itr, target] + extra_values)\n        network_array.append(row)\n\n    return pd.DataFrame( network_array, columns=['source', 'interaction', 'target'] + sorted(valid_extra_cols))", "response": "Utility to convert a Cytoscape dictionary into a Pandas Dataframe."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrendering a network data with embedded Cytoscape. js widget.", "response": "def render(network,\n           style=DEF_STYLE,\n           layout_algorithm=DEF_LAYOUT,\n           background=DEF_BACKGROUND_COLOR,\n           height=DEF_HEIGHT,\n           width=DEF_WIDTH,\n           style_file=STYLE_FILE,\n           def_nodes=DEF_NODES,\n           def_edges=DEF_EDGES):\n    \"\"\"Render network data with embedded Cytoscape.js widget.\n\n    :param network: dict (required)\n        The network data should be in Cytoscape.js JSON format.\n    :param style: str or dict\n        If str, pick one of the preset style. [default: 'default']\n        If dict, it should be Cytoscape.js style CSS object\n    :param layout_algorithm: str\n        Name of Cytoscape.js layout algorithm\n    :param background: str\n        Background in CSS format\n    :param height: int\n        Height of the widget.\n    :param width: int\n        Width of the widget.\n    :param style_file: a styles file. [default: 'default_style.json']\n    :param def_nodes: default: [\n    {'data': {'id': 'Network Data'}},\n    {'data': {'id': 'Empty'}} ]\n    :param def_edges: default: [ {'data': {'id': 'is', 'source': 'Network Data', 'target': 'Empty'}} ]\n    \"\"\"\n\n    from jinja2 import Template\n    from IPython.core.display import display, HTML\n\n    STYLES=set_styles(style_file)\n\n    # Load style file if none available\n    if isinstance(style, str):\n        # Specified by name\n        style = STYLES[style]\n\n    if network is None:\n        nodes = def_nodes\n        edges = def_edges\n    else:\n        nodes = network['elements']['nodes']\n        edges = network['elements']['edges']\n\n    path = os.path.abspath(os.path.dirname(__file__)) + '/' + HTML_TEMPLATE_FILE\n    template = Template(open(path).read())\n    cyjs_widget = template.render(\n        nodes=json.dumps(nodes),\n        edges=json.dumps(edges),\n        background=background,\n        uuid=\"cy\" + str(uuid.uuid4()),\n        widget_width=str(width),\n        widget_height=str(height),\n        layout=layout_algorithm,\n        style_json=json.dumps(style)\n    )\n\n    display(HTML(cyjs_widget))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getPanelStatus(self, panelName, verbose=None):\n\n        response=api(url=self.___url+'ui/panels/'+str(panelName)+'', method=\"GET\", verbose=verbose, parse_params=False)\n        return response", "response": "Returns the status of the specified panel."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef updateLodState(self, verbose=None):\n\n        response=api(url=self.___url+'ui/lod', method=\"PUT\", verbose=verbose)\n        return response", "response": "Update the state of the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_attribute(self,column=None,listType=None,namespace=None, network=None, atype=None, verbose=False):\n        network=check_network(self,network,verbose=verbose)\n        PARAMS=set_param([\"column\",\"listType\",\"namespace\",\"network\",\"type\"],[column,listType,namespace,network,atype])\n        response=api(url=self.__url+\"/create attribute\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response", "response": "This method creates a new edge column."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the SUID of an edge that matches the passed parameters. If multiple edges are found, only one will be returned, and a warning will be reported in the Cytoscape Task History dialog. :param edge (string, optional): Selects an edge by name, or, if the parameter has the prefix suid:, selects an edge by SUID. If this parameter is set, all other edge matching parameters are ignored. :param network (string, optional): Specifies a network by name, or by SUID if the prefix SUID: is used. The keyword CURRENT, or a blank value can also be used to specify the current network. :param sourceNode (string, optional): Selects a node by name, or, if the parameter has the prefix suid:, selects a node by SUID. Specifies that the edge matched must have this node as its source. This parameter must be used with the targetNode parameter to produce results. :param targetNode (string, optional): Selects a node by name, or, if the parameter has the prefix suid:, selects a node by SUID. Specifies that the edge matched must have this node as its target. This parameter must be used with the sourceNode parameter to produce results. :param atype (string, optional): Specifies that the edge matched must be of the specified type. This parameter must be used with the sourceNode and targetNode parameters to produce results. :param verbose: print more :returns: {\"columnName\": columnName }", "response": "def get(self,edge=None,network=None,sourceNode=None, targetNode=None, atype=None, verbose=False):\n        \"\"\"\n        Returns the SUID of an edge that matches the passed parameters. If\n        multiple edges are found, only one will be returned, and a warning will\n        be reported in the Cytoscape Task History dialog.\n\n        :param edge (string, optional): Selects an edge by name, or, if the\n            parameter has the prefix suid:, selects an edge by SUID. If this\n            parameter is set, all other edge matching parameters are ignored.\n        :param network (string, optional): Specifies a network by name, or by\n            SUID if the prefix SUID: is used. The keyword CURRENT, or a blank\n            value can also be used to specify the current network.\n        :param sourceNode (string, optional): Selects a node by name, or, if\n            the parameter has the prefix suid:, selects a node by SUID. Specifies\n            that the edge matched must have this node as its source. This parameter\n            must be used with the targetNode parameter to produce results.\n        :param targetNode (string, optional): Selects a node by name, or, if\n            the parameter has the prefix suid:, selects a node by SUID. Specifies\n            that the edge matched must have this node as its target. This parameter\n            must be used with the sourceNode parameter to produce results.\n        :param atype (string, optional): Specifies that the edge matched must\n            be of the specified type. This parameter must be used with the\n            sourceNode and targetNode parameters to produce results.\n        :param verbose: print more\n\n        :returns: {\"columnName\": columnName }\n\n        \"\"\"\n        network=check_network(self,network,verbose=verbose)\n        PARAMS=set_param([\"edge\",\"network\",\"sourceNode\",\"targetNode\",\"type\"],[edge,network,sourceNode,targetNode,atype])\n        response=api(url=self.__url+\"/get\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getNetworkViewCount(self, networkId, verbose=None):\n\n        response=api(url=self.___url+'networks/'+str(networkId)+'/views/count', method=\"GET\", verbose=verbose, parse_params=False)\n        return response", "response": "This method returns a count of the Network Views available for the specified network."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a PDF of the first available Network View for the Network specified by the `networkId` parameter. Default size is 600 px :param networkId: SUID of the Network :param h: Height of the image. Width is set automatically -- Not required, can be None :param verbose: print more :returns: 200: PDF image stream.", "response": "def getFirstImageAsPdf(self, networkId, h, verbose=None):\n        \"\"\"\n        Returns a PDF of the first available Network View for the Network specified by the `networkId` parameter.\n        \n        Default size is 600 px\n\n        :param networkId: SUID of the Network\n        :param h: Height of the image. Width is set automatically -- Not required, can be None\n        :param verbose: print more\n\n        :returns: 200: PDF image stream.\n        \"\"\"\n\n        response=api(url=self.___url+'networks/'+str(networkId)+'/views/first.pdf', PARAMS={'h':h}, method=\"GET\", verbose=verbose, parse_params=False)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getTableAsCsv(self, networkId, tableType, verbose=None):\n\n        response=api(url=self.___url+'networks/'+str(networkId)+'/tables/'+str(tableType)+'.csv', method=\"GET\", verbose=verbose, parse_params=False)\n        return response", "response": "This method returns a CSV representation of the table specified by the networkId and tableType parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbypassing the Visual Style of the Network with the Visual Property specificed by the `visualProperty`, `viewId`, and `networkId` parameters. Additional details on common Visual Properties can be found in the [Basic Visual Lexicon JavaDoc API](http://chianti.ucsd.edu/cytoscape-3.6.1/API/org/cytoscape/view/presentation/property/BasicVisualLexicon.html) :param networkId: SUID of the Network :param viewId: SUID of the Network View :param visualProperty: Name of the Visual Property :param body: A Visual Property and its value. :param verbose: print more :returns: 200: successful operation", "response": "def putNetworkVisualPropBypass(self, networkId, viewId, visualProperty, body, verbose=None):\n        \"\"\"\n        Bypasses the Visual Style of the Network with the Visual Property specificed by the `visualProperty`, `viewId`, and `networkId` parameters.\n        \n        Additional details on common Visual Properties can be found in the [Basic Visual Lexicon JavaDoc API](http://chianti.ucsd.edu/cytoscape-3.6.1/API/org/cytoscape/view/presentation/property/BasicVisualLexicon.html)\n\n        :param networkId: SUID of the Network\n        :param viewId: SUID of the Network View\n        :param visualProperty: Name of the Visual Property\n        :param body: A Visual Property and its value.\n        :param verbose: print more\n\n        :returns: 200: successful operation\n        \"\"\"\n\n        response=api(url=self.___url+'networks/'+str(networkId)+'/views/'+str(viewId)+'/network/'+str(visualProperty)+'/bypass', method=\"PUT\", body=body, verbose=verbose)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef deleteNetworkVisualProp(self, networkId, viewId, visualProperty, verbose=None):\n\n        response=api(url=self.___url+'networks/'+str(networkId)+'/views/'+str(viewId)+'/network/'+str(visualProperty)+'/bypass', method=\"DELETE\", verbose=verbose)\n        return response", "response": "This method deletes the bypass Visual Property in the specified view and network."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setCurrentNetwork(self, body, verbose=None):\n\n        response=api(url=self.___url+'networks/currentNetwork', method=\"PUT\", body=body, verbose=verbose)\n        return response", "response": "Sets the current network."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef createNetworkFromSelected(self, networkId, title, verbose=None):\n\n        PARAMS=set_param(['networkId','title'],[networkId,title])\n        response=api(url=self.___url+'networks/'+str(networkId)+'', PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response", "response": "This method creates a new sub - network from the selected nodes and edges."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate the table specified by the `tableType` and `networkId` parameters. New columns will be created if they do not exist in the target table. Current limitations: * Numbers are handled as Double * List column is not supported in this version :param networkId: SUID containing the table :param tableType: Type of table :param body: The data with which to update the table. :param class_: None -- Not required, can be None :param verbose: print more :returns: default: successful operation", "response": "def updateTable(self, networkId, tableType, body, class_, verbose=None):\n        \"\"\"\n        Updates the table specified by the `tableType` and `networkId` parameters.  New columns will be created if they do not exist in the target table.\n        \n        Current limitations:\n        * Numbers are handled as Double\n        * List column is not supported in this version\n\n        :param networkId: SUID containing the table\n        :param tableType: Type of table\n        :param body: The data with which to update the table.\n        :param class_: None -- Not required, can be None\n        :param verbose: print more\n\n        :returns: default: successful operation\n        \"\"\"\n\n        response=api(url=self.___url+'networks/'+str(networkId)+'/tables/'+str(tableType)+'', method=\"PUT\", body=body, verbose=verbose)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the Visual Property specificed by the `visualProperty` parameter for the node or edge specified by the `objectId` parameter in the Network View specified by the `viewId` and `networkId` parameters. Additional details on common Visual Properties can be found in the [Basic Visual Lexicon JavaDoc API](http://chianti.ucsd.edu/cytoscape-3.6.1/API/org/cytoscape/view/presentation/property/BasicVisualLexicon.html) :param networkId: SUID of the Network :param viewId: SUID of the Network View :param objectType: Type of Object :param objectId: SUID of the Object :param visualProperty: Name of the Visual Property :param verbose: print more :returns: 200: successful operation", "response": "def getSingleVisualPropertyValue(self, networkId, viewId, objectType, objectId, visualProperty, verbose=None):\n        \"\"\"\n        Gets the Visual Property specificed by the `visualProperty` parameter for the node or edge specified by the `objectId` parameter in the Network View specified by the `viewId` and `networkId` parameters.\n        \n        Additional details on common Visual Properties can be found in the [Basic Visual Lexicon JavaDoc API](http://chianti.ucsd.edu/cytoscape-3.6.1/API/org/cytoscape/view/presentation/property/BasicVisualLexicon.html)\n\n        :param networkId: SUID of the Network\n        :param viewId: SUID of the Network View\n        :param objectType: Type of Object\n        :param objectId: SUID of the Object\n        :param visualProperty: Name of the Visual Property\n        :param verbose: print more\n\n        :returns: 200: successful operation\n        \"\"\"\n\n        response=api(url=self.___url+'networks/'+str(networkId)+'/views/'+str(viewId)+'/'+str(objectType)+'/'+str(objectId)+'/'+str(visualProperty)+'', method=\"H\", verbose=verbose, parse_params=False)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate multiple node or edge Visual Properties as defined by the `objectType` parameter, in the Network View specified by the `viewId` and `networkId` parameters. Examples of Visual Properties: ``` { \"visualProperty\": \"NODE_BORDER_WIDTH\", \"value\": 2 } ``` ``` { \"visualProperty\": \"NODE_BORDER_PAINT\", \"value\": \"#CCCCCC\" } ``` ``` { \"visualProperty\": \"EDGE_TRANSPARENCY\", \"value\": 170 }``` ``` { \"visualProperty\": \"EDGE_PAINT\", \"value\": \"#808080\" }``` Additional details on common Visual Properties can be found in the [Basic Visual Lexicon JavaDoc API](http://chianti.ucsd.edu/cytoscape-3.6.1/API/org/cytoscape/view/presentation/property/BasicVisualLexicon.html) Note that this sets the Visual Properties temporarily unless the `bypass` parameter is set to `true`. If the `bypass` parameter is set to `true`, the Visual Style will be overridden by these Visual Property values. If the `bypass` parameter is not used or is set to `false`, any Visual Properties set will return to those defined in the Visual Style if the Network View is updated. :param networkId: SUID of the Network :param viewId: SUID of the Network View :param objectType: Type of Object :param bypass: Bypass the Visual Style with these Visual Properties -- Not required, can be None :param body: A list of Objects with Visual Properties. :param verbose: print more :returns: default: successful operation", "response": "def updateViews(self, networkId, viewId, objectType, bypass, body, verbose=None):\n        \"\"\"\n        Updates multiple node or edge Visual Properties as defined by the `objectType` parameter, in the Network View specified by the `viewId` and `networkId` parameters.\n        \n        Examples of Visual Properties:\n        \n        ```\n        {\n        \"visualProperty\": \"NODE_BORDER_WIDTH\",\n        \"value\": 2\n        }\n        ```\n        ```\n        {\n        \"visualProperty\": \"NODE_BORDER_PAINT\",\n        \"value\": \"#CCCCCC\"\n        }\n        ```\n        \n        ```\n        {\n        \"visualProperty\": \"EDGE_TRANSPARENCY\",\n        \"value\": 170\n        }```\n        ```\n        {\n        \"visualProperty\": \"EDGE_PAINT\",\n        \"value\": \"#808080\"\n        }```\n        \n        \n        Additional details on common Visual Properties can be found in the [Basic Visual Lexicon JavaDoc API](http://chianti.ucsd.edu/cytoscape-3.6.1/API/org/cytoscape/view/presentation/property/BasicVisualLexicon.html)\n        \n        Note that this sets the Visual Properties temporarily unless the `bypass` parameter is set to `true`. If the `bypass` parameter is set to `true`, the Visual Style will be overridden by these Visual Property values. If the `bypass` parameter is not used or is set to `false`, any Visual Properties set will return to those defined in the Visual Style if the Network View is updated.\n\n        :param networkId: SUID of the Network\n        :param viewId: SUID of the Network View\n        :param objectType: Type of Object\n        :param bypass: Bypass the Visual Style with these Visual Properties -- Not required, can be None\n        :param body: A list of Objects with Visual Properties.\n        :param verbose: print more\n\n        :returns: default: successful operation\n        \"\"\"\n\n        response=api(url=self.___url+'networks/'+str(networkId)+'/views/'+str(viewId)+'/'+str(objectType)+'', method=\"PUT\", body=body, verbose=verbose)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of all Visual Property values for the Visual Property specified by the `visualProperty` and `objectType` parameters, in the Network View specified by the `viewId` and `networkId` parameters. Additional details on common Visual Properties can be found in the [Basic Visual Lexicon JavaDoc API](http://chianti.ucsd.edu/cytoscape-3.6.1/API/org/cytoscape/view/presentation/property/BasicVisualLexicon.html) :param networkId: SUID of the Network :param viewId: SUID of the Network View :param objectType: Type of Object :param visualProperty: Name of the Visual Property -- Not required, can be None :param verbose: print more :returns: 200: successful operation", "response": "def getViews(self, networkId, viewId, objectType, visualProperty, verbose=None):\n        \"\"\"\n        Returns a list of all Visual Property values for the Visual Property specified by the `visualProperty` and `objectType` parameters, in the Network View specified by the `viewId` and `networkId` parameters.\n        \n        Additional details on common Visual Properties can be found in the [Basic Visual Lexicon JavaDoc API](http://chianti.ucsd.edu/cytoscape-3.6.1/API/org/cytoscape/view/presentation/property/BasicVisualLexicon.html)\n\n        :param networkId: SUID of the Network\n        :param viewId: SUID of the Network View\n        :param objectType: Type of Object\n        :param visualProperty: Name of the Visual Property -- Not required, can be None\n        :param verbose: print more\n\n        :returns: 200: successful operation\n        \"\"\"\n\n        response=api(url=self.___url+'networks/'+str(networkId)+'/views/'+str(viewId)+'/'+str(objectType)+'', PARAMS={'visualProperty':visualProperty}, method=\"H\", verbose=verbose, parse_params=False)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef updateColumnName(self, networkId, tableType, body, verbose=None):\n\n        response=api(url=self.___url+'networks/'+str(networkId)+'/tables/'+str(tableType)+'/columns', method=\"PUT\", body=body, verbose=verbose)\n        return response", "response": "This method updates the name of an existing column in the specified network."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getEdgeDirected(self, networkId, edgeId, verbose=None):\n\n        response=api(url=self.___url+'networks/'+str(networkId)+'/edges/'+str(edgeId)+'/isDirected', method=\"GET\", verbose=verbose, parse_params=False)\n        return response", "response": "This method returns true if the edge specified by the edgeId and networkId parameters is directed."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbypasses the Visual Style of the object specified by the `objectId` and `objectType` parameters, in the Network View specified by the `viewId` and `networkId` parameters. The Visual Property included in the message body will be used instead of the definition provided by the Visual Style. Examples of Visual Properties: ``` { \"visualProperty\": \"NODE_BORDER_WIDTH\", \"value\": 2 } ``` ``` { \"visualProperty\": \"EDGE_TRANSPARENCY\", \"value\": 170 }``` ``` { \"visualProperty\": \"NETWORK_BACKGROUND_PAINT\", \"value\": \"#000000\" }``` Additional details on common Visual Properties can be found in the [Basic Visual Lexicon JavaDoc API](http://chianti.ucsd.edu/cytoscape-3.6.1/API/org/cytoscape/view/presentation/property/BasicVisualLexicon.html) :param networkId: Network SUID :param viewId: Network View SUID :param objectType: Type of Object :param objectId: SUID of the Object :param visualProperty: Name of the Visual Property :param body: A Visual Property and its value. :param verbose: print more :returns: default: successful operation", "response": "def putSingleVisualPropertyValueBypass(self, networkId, viewId, objectType, objectId, visualProperty, body, verbose=None):\n        \"\"\"\n        Bypasses the Visual Style of the object specified by the `objectId` and `objectType` parameters, in the Network View specified by the `viewId` and `networkId` parameters. The Visual Property included in the message body will be used instead of the definition provided by the Visual Style.\n        \n        Examples of Visual Properties:\n        \n        ```\n        {\n        \"visualProperty\": \"NODE_BORDER_WIDTH\",\n        \"value\": 2\n        }\n        ```\n        \n        ```\n        {\n        \"visualProperty\": \"EDGE_TRANSPARENCY\",\n        \"value\": 170\n        }```\n        \n        ```\n        {\n        \"visualProperty\": \"NETWORK_BACKGROUND_PAINT\",\n        \"value\": \"#000000\"\n        }```\n        \n        \n        Additional details on common Visual Properties can be found in the [Basic Visual Lexicon JavaDoc API](http://chianti.ucsd.edu/cytoscape-3.6.1/API/org/cytoscape/view/presentation/property/BasicVisualLexicon.html)\n\n        :param networkId: Network SUID\n        :param viewId: Network View SUID\n        :param objectType: Type of Object\n        :param objectId: SUID of the Object\n        :param visualProperty: Name of the Visual Property\n        :param body: A Visual Property and its value.\n        :param verbose: print more\n\n        :returns: default: successful operation\n        \"\"\"\n\n        response=api(url=self.___url+'networks/'+str(networkId)+'/views/'+str(viewId)+'/'+str(objectType)+'/'+str(objectId)+'/'+str(visualProperty)+'/bypass', method=\"PUT\", body=body, verbose=verbose)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes the node specified by the `nodeId` and `networkId` parameters. :param networkId: SUID of the network containing the node. :param nodeId: SUID of the node :param verbose: print more :returns: default: successful operation", "response": "def deleteNode(self, networkId, nodeId, verbose=None):\n        \"\"\"\n        Deletes the node specified by the `nodeId` and `networkId` parameters.\n\n        :param networkId: SUID of the network containing the node.\n        :param nodeId: SUID of the node\n        :param verbose: print more\n\n        :returns: default: successful operation\n        \"\"\"\n\n        response=api(url=self.___url+'networks/'+str(networkId)+'/nodes/'+str(nodeId)+'', method=\"DELETE\", verbose=verbose)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef setSelectedEdges(self, networkId, body, verbose=None):\n\n        response=api(url=self.___url+'networks/'+str(networkId)+'/edges/selected', method=\"PUT\", body=body, verbose=verbose)\n        return response", "response": "Sets as selected the edges specified by the suids and networkId parameters."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef deleteGroup(self, networkId, groupNodeId, verbose=None):\n\n        response=api(url=self.___url+'networks/'+str(networkId)+'/groups/'+str(groupNodeId)+'', method=\"DELETE\", verbose=verbose)\n        return response", "response": "This method deletes the group specified by the groupNodeId and networkId parameters."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the group specified by the `groupNodeId` and `networkId` parameters. :param networkId: SUID of the Network :param groupNodeId: SUID of the Node representing the Group :param verbose: print more :returns: 200: successful operation", "response": "def getGroup(self, networkId, groupNodeId, verbose=None):\n        \"\"\"\n        Returns the group specified by the `groupNodeId` and `networkId` parameters.\n\n        :param networkId: SUID of the Network\n        :param groupNodeId: SUID of the Node representing the Group\n        :param verbose: print more\n\n        :returns: 200: successful operation\n        \"\"\"\n\n        response=api(url=self.___url+'networks/'+str(networkId)+'/groups/'+str(groupNodeId)+'', method=\"GET\", verbose=verbose, parse_params=False)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the values for cells in the table specified by the `tableType` and `networkId` parameters. If the 'default` parameter is not specified, the message body should consist of key-value pairs with which to set values. If the `default` parameter is specified, its value will be used for every cell in the column. This is useful to set columns like \"selected.\" :param networkId: SUID of the network containing the table :param tableType: The type of table :param columnName: Name of the column in which to set values :param default: Default Value. If this value is provided, all cells will be set to this. -- Not required, can be None :param body: Array of SUID Keyed values :param verbose: print more :returns: default: successful operation", "response": "def updateColumnValues(self, networkId, tableType, columnName, default, body, verbose=None):\n        \"\"\"\n        Sets the values for cells in the table specified by the `tableType` and `networkId` parameters.\n        \n        If the 'default` parameter is not specified, the message body should consist of key-value pairs with which to set values.\n        \n        If the `default` parameter is specified, its value will be used for every cell in the column. This is useful to set columns like \"selected.\"\n\n        :param networkId: SUID of the network containing the table\n        :param tableType: The type of table\n        :param columnName: Name of the column in which to set values\n        :param default: Default Value. If this value is provided, all cells will be set to this. -- Not required, can be None\n        :param body: Array of SUID Keyed values\n        :param verbose: print more\n\n        :returns: default: successful operation\n        \"\"\"\n\n        response=api(url=self.___url+'networks/'+str(networkId)+'/tables/'+str(tableType)+'/columns/'+str(columnName)+'', method=\"PUT\", body=body, verbose=verbose)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef deleteColumn(self, networkId, tableType, columnName, verbose=None):\n\n        response=api(url=self.___url+'networks/'+str(networkId)+'/tables/'+str(tableType)+'/columns/'+str(columnName)+'', method=\"DELETE\", verbose=verbose)\n        return response", "response": "This method deletes the specified column from the table specified by the columnName parameter in the network specified by the networkId and tableType and networkId parameters."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getNodes(self, networkId, column, query, verbose=None):\n\n        response=api(url=self.___url+'networks/'+str(networkId)+'/nodes', PARAMS={'column':column, 'query':query}, method=\"GET\", verbose=verbose, parse_params=False)\n        return response", "response": "This method returns a list of all nodes in the specified network as SUIDs. nodeTable where the value in the column specified by the query parameter matches the value in the column specified by the query parameter."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef deleteEdge(self, networkId, edgeId, verbose=None):\n\n        response=api(url=self.___url+'networks/'+str(networkId)+'/edges/'+str(edgeId)+'', method=\"DELETE\", verbose=verbose)\n        return response", "response": "This method deletes the edge specified by the edgeId and networkId parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getFirstNetworkView(self, networkId, file, verbose=None):\n\n        response=api(url=self.___url+'networks/'+str(networkId)+'/views/first', PARAMS={'file':file}, method=\"GET\", verbose=verbose, parse_params=False)\n        return response", "response": "This method returns the first available view of the network."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getAdjEdges(self, networkId, nodeId, verbose=None):\n\n        response=api(url=self.___url+'networks/'+str(networkId)+'/nodes/'+str(nodeId)+'/adjEdges', method=\"GET\", verbose=verbose, parse_params=False)\n        return response", "response": "This method returns a list of connected edges as SUIDs for the node specified by the nodeId and networkId parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new Network View for the Network specified by the `networkId` parameter. :param networkId: SUID of the Network :param verbose: print more :returns: 201: Network View SUID", "response": "def createNetworkView(self, networkId, verbose=None):\n        \"\"\"\n        Creates a new Network View for the Network specified by the `networkId` parameter.\n\n        :param networkId: SUID of the Network\n        :param verbose: print more\n\n        :returns: 201: Network View SUID\n        \"\"\"\n\n        PARAMS=set_param(['networkId'],[networkId])\n        response=api(url=self.___url+'networks/'+str(networkId)+'/views', PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef deleteAllNetworkViews(self, networkId, verbose=None):\n\n        response=api(url=self.___url+'networks/'+str(networkId)+'/views', method=\"DELETE\", verbose=verbose)\n        return response", "response": "This method deletes all Network Views available in the specified network."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of the Visual Properties for the Network View specified by the `viewId` and `networkId` parameters. Additional details on common Visual Properties can be found in the [Basic Visual Lexicon JavaDoc API](http://chianti.ucsd.edu/cytoscape-3.6.1/API/org/cytoscape/view/presentation/property/BasicVisualLexicon.html) :param networkId: SUID of the Network :param viewId: SUID of the Network View :param verbose: print more :returns: 200: successful operation", "response": "def getNetworkVisualProps(self, networkId, viewId, verbose=None):\n        \"\"\"\n        Returns a list of the Visual Properties for the Network View specified by the `viewId` and `networkId` parameters.\n        \n        Additional details on common Visual Properties can be found in the [Basic Visual Lexicon JavaDoc API](http://chianti.ucsd.edu/cytoscape-3.6.1/API/org/cytoscape/view/presentation/property/BasicVisualLexicon.html)\n\n        :param networkId: SUID of the Network\n        :param viewId: SUID of the Network View\n        :param verbose: print more\n\n        :returns: 200: successful operation\n        \"\"\"\n\n        response=api(url=self.___url+'networks/'+str(networkId)+'/views/'+str(viewId)+'/network', method=\"GET\", verbose=verbose, parse_params=False)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new group in the network specified by the parameter `networkId`. The contents are specified the message body. :param networkId: SUID of the Network :param body: New Group name and contents :param verbose: print more :returns: 200: successful operation", "response": "def createGroup(self, networkId, body, verbose=None):\n        \"\"\"\n        Create a new group in the network specified by the parameter `networkId`. The contents are specified the message body.\n\n        :param networkId: SUID of the Network\n        :param body: New Group name and contents\n        :param verbose: print more\n\n        :returns: 200: successful operation\n        \"\"\"\n\n        PARAMS=set_param(['networkId','body'],[networkId,body])\n        response=api(url=self.___url+'networks/'+str(networkId)+'/groups', PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_edge(self, isDirected=None,name=None,network=None,sourceName=None,targetName=None, verbose=False):\n        network=check_network(self,network,verbose=verbose)\n        PARAMS=set_param([\"isDirected\",\"name\",\"network\",\"sourceName\",\"targetName\"],\\\n        [isDirected,name,network,sourceName,targetName])\n        response=api(url=self.__url+\"/add edge\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response", "response": "This method adds a new edge between two nodes in a network."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new network from a list of nodes and edges in an existing source network. The SUID of the network and view are returned. :param edgeList (string, optional): Specifies a list of edges. The keywords all, selected, or unselected can be used to specify edges by their selection state. The pattern COLUMN:VALUE sets this parameter to any rows that contain the specified column value; if the COLUMN prefix is not used, the NAME column is matched by default. A list of COLUMN:VALUE pairs of the format COLUMN1:VALUE1,COLUMN2:VALUE2,... can be used to match multiple values. :param excludeEdges (string, optional): Unless this is set to true, edges that connect nodes in the nodeList are implicitly included :param networkName (string, optional): :param nodeList (string, optional): Specifies a list of nodes. The keywords all, selected, or unselected can be used to specify nodes by their selection state. The pattern COLUMN:VALUE sets this parameter to any rows that contain the specified column value; if the COLUMN prefix is not used, the NAME column is matched by default. A list of COLUMN:VALUE pairs of the format COLUMN1:VALUE1,COLUMN2:VALUE2,... can be used to match multiple values. :param source (string, optional): Specifies a network by name, or by SUID if the prefix SUID: is used. The keyword CURRENT, or a blank value can also be used to specify the current network. :param verbose: print more :returns: { netowrk, view }", "response": "def create(self, edgeList=None, excludeEdges=None, networkName=None, nodeList=None, source=None, verbose=False):\n        \"\"\"\n        Create a new network from a list of nodes and edges in an existing source network.\n        The SUID of the network and view are returned.\n\n        :param edgeList (string, optional): Specifies a list of edges. The keywords\n            all, selected, or unselected can be used to specify edges by their\n            selection state. The pattern COLUMN:VALUE sets this parameter to any\n            rows that contain the specified column value; if the COLUMN prefix is\n            not used, the NAME column is matched by default. A list of COLUMN:VALUE\n            pairs of the format COLUMN1:VALUE1,COLUMN2:VALUE2,... can be used to\n            match multiple values.\n        :param excludeEdges (string, optional): Unless this is set to true, edges\n            that connect nodes in the nodeList are implicitly included\n        :param networkName (string, optional):\n        :param nodeList (string, optional): Specifies a list of nodes. The keywords\n            all, selected, or unselected can be used to specify nodes by their\n            selection state. The pattern COLUMN:VALUE sets this parameter to any\n            rows that contain the specified column value; if the COLUMN prefix is\n            not used, the NAME column is matched by default. A list of COLUMN:VALUE\n            pairs of the format COLUMN1:VALUE1,COLUMN2:VALUE2,... can be used to\n            match multiple values.\n        :param source (string, optional): Specifies a network by name, or by SUID\n            if the prefix SUID: is used. The keyword CURRENT, or a blank value can\n            also be used to specify the current network.\n        :param verbose: print more\n\n        :returns: { netowrk, view }\n        \"\"\"\n        network=check_network(self,source, verbose=verbose)\n        PARAMS=set_param([\"edgeList\",\"excludeEdges\",\"networkName\",\"nodeList\",\"source\"], \\\n        [edgeList,excludeEdges,networkName,nodeList,network])\n        response=api(url=self.__url+\"/create\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_empty(self, name=None, renderers=None, RootNetworkList=None, verbose=False):\n        PARAMS=set_param([\"name\",\"renderers\",\"RootNetworkList\"],[name,renderers,RootNetworkList])\n        response=api(url=self.__url+\"/create empty\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response", "response": "Create a new empty network."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexports a network to a network file.", "response": "def export(self, options=None, OutputFile=None, verbose=False):\n        \"\"\"\n        Export a network to a network file (e.g. XGMML, SIF, etc.)\n\n        :param options (string, optional): The format of the output file. = ['CX JSON (*.cx)',\n            'Cytoscape.js JSON (*.cyjs)', 'GraphML files (*.graphml, *.xml)', 'NNF (*.nnf)',\n            'PSI-MI Level 1', 'PSI-MI Level 2.5', 'SIF (*.sif)', 'XGMML (*.xgmml, *.xml)']\n        :param OutputFile (string, optional):\n        :param verbose: print more\n\n        :returns: { file }\n        \"\"\"\n        PARAMS=set_param([\"options\",\"OutputFile\"],[options,OutputFile])\n        response=api(url=self.__url+\"/export\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nimport a new network from a tabular formatted file type (e.g. csv, tsv, Excel, etc.). Use network load file to load network formatted files. This command will create a new network collection if no current network collection is selected, otherwise it will add the network to the current collection. The SUIDs of the new networks and views are returned. :param dataTypeList (string, optional): List of column data types ordered by column index (e.g. \"string,int,long,double,boolean,intlist\" or just \"s,i,l,d,b,il\"): , :param defaultInteraction (string, optional): Used to set the default interaction type to use when there is no interaction type column. :param delimiters (string, optional): Select the delimiters to use to separate columns in the table, from the list ',',' ','TAB', or ';'. TAB and ',' are used by default = [',', ';', ' ', '\\t'] :param delimitersForDataList (string, optional): Select the delimiters to use to separate list entries in a list, from the list '|','\\','/', or ','. | is used by default = ['\\|', '\\', '/', ','] :param afile (string): The path to the file that contains the table or network to be imported. :param firstRowAsColumnNames (string, optional): If this is true then the first row should contain the names of the columns. Note that startLoadRow must be set for this to work properly :param indexColumnSourceInteraction (string): The column index that contains the source node identifiers. :param indexColumnTargetInteraction (string, optional): The column index that contains the target node identifiers. If this is not specified then the resulting network will have no edges :param indexColumnTypeInteraction (string, optional): The column index that contains the interaction type. This is not required. :param NetworkViewRendererList (string, optional): Enter the network view renderer that this network should use. This is only useful if multiple renderers have been installed, which is rare. = [''] :param RootNetworkList (string, optional): The name of the network collection (root network) that the imported network should be part of. A name of -- Create new network collection -- will result in the creation of a new network collection for this import. = ['-- Create new network collection --', 'cy:command_documentation_generation'] :param startLoadRow (string, optional): The starting row of the import. This is used to skip over comments and other non-data rows at the beginning of the file. :param TargetColumnList (string, optional): Enter the name of the column in the existing network collection (root network) that you want to map your input identifiers to. = [''] :param verbose: print more :returns: { SUIDs of the new networks and views }", "response": "def import_file(self, dataTypeList=None, defaultInteraction=None, delimiters=None, \\\n        delimitersForDataList=None, afile=None, firstRowAsColumnNames=None, \\\n        indexColumnSourceInteraction=None, indexColumnTargetInteraction=None, indexColumnTypeInteraction=None, \\\n        NetworkViewRendererList=None, RootNetworkList=None, startLoadRow=None,\\\n        TargetColumnList=None, verbose=False):\n        \"\"\"\n        Import a new network from a tabular formatted file type (e.g. csv, tsv,\n        Excel, etc.). Use network load file to load network formatted files. This\n        command will create a new network collection if no current network collection\n        is selected, otherwise it will add the network to the current collection. The\n        SUIDs of the new networks and views are returned.\n\n        :param dataTypeList (string, optional): List of column data types ordered\n            by column index (e.g. \"string,int,long,double,boolean,intlist\" or\n            just \"s,i,l,d,b,il\"): ,\n        :param defaultInteraction (string, optional): Used to set the default\n            interaction type to use when there is no interaction type column.\n        :param delimiters (string, optional): Select the delimiters to use to\n            separate columns in the table, from the list ',',' ','TAB', or ';'.\n            TAB and ',' are used by default = [',', ';', ' ', '\\t']\n        :param delimitersForDataList (string, optional): Select the delimiters\n            to use to separate list entries in a list, from the list '|','\\','/',\n            or ','. | is used by default = ['\\|', '\\', '/', ',']\n        :param afile (string): The path to the file that contains the table or\n            network to be imported.\n        :param firstRowAsColumnNames (string, optional): If this is true then\n            the first row should contain the names of the columns. Note that\n            startLoadRow must be set for this to work properly\n        :param indexColumnSourceInteraction (string): The column index that\n            contains the source node identifiers.\n        :param indexColumnTargetInteraction (string, optional): The column index\n            that contains the target node identifiers. If this is not specified\n            then the resulting network will have no edges\n        :param indexColumnTypeInteraction (string, optional): The column index\n            that contains the interaction type. This is not required.\n        :param NetworkViewRendererList (string, optional): Enter the network\n            view renderer that this network should use. This is only useful if\n            multiple renderers have been installed, which is rare. = ['']\n        :param RootNetworkList (string, optional): The name of the network\n            collection (root network) that the imported network should be part of.\n            A name of -- Create new network collection -- will result in the\n            creation of a new network collection for this import. = ['-- Create\n            new network collection --', 'cy:command_documentation_generation']\n        :param startLoadRow (string, optional): The starting row of the import.\n            This is used to skip over comments and other non-data rows at the\n            beginning of the file.\n        :param TargetColumnList (string, optional): Enter the name of the column\n            in the existing network collection (root network) that you want to\n            map your input identifiers to. = ['']\n        :param verbose: print more\n\n        :returns:  { SUIDs of the new networks and views }\n        \"\"\"\n\n        PARAMS=set_param([\"dataTypeList\",\"defaultInteraction\",\"delimiters\",\"delimitersForDataList\",\\\n        \"file\",\"firstRowAsColumnNames\",\"indexColumnSourceInteraction\",\"indexColumnTargetInteraction\",\\\n        \"indexColumnTypeInteraction\",\"NetworkViewRendererList\",\"RootNetworkList\",\"startLoadRow\",\"TargetColumnList\"],\\\n        [dataTypeList,defaultInteraction,delimiters,delimitersForDataList,\\\n        afile,firstRowAsColumnNames,indexColumnSourceInteraction,indexColumnTargetInteraction,\\\n        indexColumnTypeInteraction,NetworkViewRendererList,RootNetworkList,startLoadRow,TargetColumnList])\n        response=api(url=self.__url+\"/import file\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlisting all of the networks in the current session.", "response": "def list(self, verbose=False):\n        \"\"\"\n        List all of the networks in the current session.\n\n        :param verbose: print more\n\n        :returns: [ list of network suids ]\n        \"\"\"\n\n        response=api(url=self.__url+\"/list\", method=\"POST\", verbose=verbose)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_attributes(self, namespace=None, network=None, verbose=False):\n        network=check_network(self,network,verbose=verbose)\n        PARAMS=set_param([\"namespace\",\"network\"],[namespace,network])\n        response=api(url=self.__url+\"/list attributes\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response", "response": "Returns a list of column names associated with a network."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_file(self, afile=None, verbose=False):\n        PARAMS=set_param([\"file\"],[afile])\n        response=api(url=self.__url+\"/load file\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response", "response": "This command loads a new network from a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads a new network from a URL that points to a network file type (e.g. SIF, XGMML, etc.). Use network import url to load networks from Excel or csv files. This command will create a new network collection if no current network collection is selected, otherwise it will add the network to the current collection. The SUIDs of the new networks and views are returned. :param url (string): Select a URL that points to a network format file. This command does not support csv or Excel files. Use network import url for that. :param verbose: print more :returns: { SUIDs of the new networks and views }", "response": "def load_url(self, url=None, verbose=False):\n        \"\"\"\n        Load a new network from a URL that points to a network file type (e.g.\n        SIF, XGMML, etc.). Use network import url to load networks from Excel or\n        csv files. This command will create a new network collection if no current\n        network collection is selected, otherwise it will add the network to the\n        current collection. The SUIDs of the new networks and views are returned.\n\n        :param url (string): Select a URL that points to a network format file.\n            This command does not support csv or Excel files. Use network import\n            url for that.\n        :param verbose: print more\n\n        :returns: { SUIDs of the new networks and views }\n        \"\"\"\n        PARAMS=set_param([\"url\"],[url])\n        response=api(url=self.__url+\"/load url\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rename(self, name=None, sourceNetwork=None, verbose=False):\n        sourceNetwork=check_network(self,sourceNetwork,verbose=verbose)\n        PARAMS=set_param([\"name\",\"sourceNetwork\"],[name,sourceNetwork])\n        response=api(url=self.__url+\"/rename\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response", "response": "This operation renames an existing network."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nselecting nodes and/or edges in a network. This command provides options to invert the selection, add first neighbors, add adjacent edges of selected nodes, and add adjacent nodes of selected edges :param adjacentEdges (string, optional): If 'true', then select any edges adjacent to any selected nodes. This happens before any inversion :param edgeList (string, optional): Specifies a list of edges. The keywords all, selected, or unselected can be used to specify edges by their selection state. The pattern COLUMN:VALUE sets this parameter to any rows that contain the specified column value; if the COLUMN prefix is not used, the NAME column is matched by default. A list of COLUMN:VALUE pairs of the format COLUMN1:VALUE1,COLUMN2:VALUE2,... can be used to match multiple values. :param extendEdges (string, optional): If 'true', then select any nodes adjacent to any selected edges. This happens before any inversion :param firstNeighbors (string, optional): If this option is anything other than 'none', add nodes to the selection based on the value of the argument. If 'incoming', add nodes to the selection that have edges pointing to one of the selected nodes. If 'output', add nodes to the selection that have edges that point to them from one of the selected nodes. If 'undirected' add any neighbors that have undirected edges connecting to any of the selected nodes. Finally, if 'any', then add all first neighbors to the selection list. = ['none', 'incoming', 'outgoing', 'undirected', 'any'], :param invert (string, optional): If this option is not 'none', then the selected nodes or edges (or both) will be deselected and all other nodes or edges will be selected = ['none', 'nodes', 'edges', 'both'] :param network (string, optional): Specifies a network by name, or by SUID if the prefix SUID: is used. The keyword CURRENT, or a blank value can also be used to specify the current network. :param nodeList (string, optional): Specifies a list of nodes. The keywords all, selected, or unselected can be used to specify nodes by their selection state. The pattern COLUMN:VALUE sets this parameter to any rows that contain the specified column value; if the COLUMN prefix is not used, the NAME column is matched by default. A list of COLUMN:VALUE pairs of the format COLUMN1:VALUE1,COLUMN2:VALUE2,... can be used to match multiple values. :param verbose: print more :returns: [ list of selected edges and nodes ]", "response": "def select(self, adjacentEdges=None, edgeList=None, extendEdges=None, firstNeighbors=None, \\\n        invert=None, network=None, nodeList=None, verbose=False):\n        \"\"\"\n        Select nodes and/or edges in a network. This command provides options to\n        invert the selection, add first neighbors, add adjacent edges of selected\n        nodes, and add adjacent nodes of selected edges\n\n        :param adjacentEdges (string, optional): If 'true', then select any edges\n            adjacent to any selected nodes. This happens before any inversion\n        :param edgeList (string, optional): Specifies a list of edges. The keywords\n            all, selected, or unselected can be used to specify edges by their\n            selection state. The pattern COLUMN:VALUE sets this parameter to any\n            rows that contain the specified column value; if the COLUMN prefix is\n            not used, the NAME column is matched by default. A list of COLUMN:VALUE\n            pairs of the format COLUMN1:VALUE1,COLUMN2:VALUE2,... can be used to\n            match multiple values.\n        :param extendEdges (string, optional): If 'true', then select any nodes\n            adjacent to any selected edges. This happens before any inversion\n        :param firstNeighbors (string, optional): If this option is anything other\n            than 'none', add nodes to the selection based on the value of the\n            argument. If 'incoming', add nodes to the selection that have edges\n            pointing to one of the selected nodes. If 'output', add nodes to the\n            selection that have edges that point to them from one of the selected\n            nodes. If 'undirected' add any neighbors that have undirected edges\n            connecting to any of the selected nodes. Finally, if 'any', then add\n            all first neighbors to the selection list. = ['none', 'incoming',\n            'outgoing', 'undirected', 'any'],\n        :param invert (string, optional): If this option is not 'none', then the\n            selected nodes or edges (or both) will be deselected and all other\n            nodes or edges will be selected = ['none', 'nodes', 'edges', 'both']\n        :param network (string, optional): Specifies a network by name, or by\n            SUID if the prefix SUID: is used. The keyword CURRENT, or a blank value\n            can also be used to specify the current network.\n        :param nodeList (string, optional): Specifies a list of nodes. The keywords\n            all, selected, or unselected can be used to specify nodes by their\n            selection state. The pattern COLUMN:VALUE sets this parameter to any\n            rows that contain the specified column value; if the COLUMN prefix is\n            not used, the NAME column is matched by default. A list of COLUMN:VALUE\n            pairs of the format COLUMN1:VALUE1,COLUMN2:VALUE2,... can be used to\n            match multiple values.\n        :param verbose: print more\n\n        :returns: [ list of selected edges and nodes ]\n        \"\"\"\n        network=check_network(self,network,verbose=verbose)\n        PARAMS=set_param([\"adjacentEdges\",\"edgeList\",\"extendEdges\",\"firstNeighbors\",\\\n        \"invert\",\"network\",\"nodeList\"], \\\n        [adjacentEdges,edgeList,extendEdges,firstNeighbors,\\\n        invert,network,nodeList])\n        response=api(url=self.__url+\"/select\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef new(self, verbose=False):\n\n        response=api(url=self.__url+\"/new\", verbose=verbose)\n        return response", "response": "Destroys the current session and creates a new empty one."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef open(self, session_file=None,session_url=None, verbose=False):\n\n        PARAMS=set_param([\"file\", \"url\"],[session_file, session_url])\n        response=api(url=self.__url+\"/open\", PARAMS=PARAMS, verbose=verbose)\n        return response", "response": "Opens a session from a local file or URL."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsaves the current session to an existing file.", "response": "def save(self, session_file, verbose=False):\n        \"\"\"\n        Saves the current session to an existing file, which will be replaced.\n        If this is a new session that has not been saved yet, use 'save as'\n        instead.\n\n        :param session_file: The path to the file where the current session\n        must be saved to.\n        :param verbose: print more\n        \"\"\"\n\n        PARAMS={\"file\":session_file}\n\n        response=api(url=self.__url+\"/save\", PARAMS=PARAMS, verbose=verbose)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef createSessionFile(self, file, verbose=None):\n\n        PARAMS=set_param(['file'],[file])\n        response=api(url=self.___url+'session', PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response", "response": "Creates a new session file for the current session."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getSessionFromFile(self, file, verbose=None):\n\n        response=api(url=self.___url+'session', PARAMS={'file':file}, method=\"GET\", verbose=verbose, parse_params=False)\n        return response", "response": "This method loads a session from a local file and returns the session file name"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\napplying the specified style to the selected views and returns the SUIDs of the affected views.", "response": "def apply(self, styles=None, verbose=False):\n        \"\"\"\n        Applies the specified style to the selected views and returns the\n        SUIDs of the affected views.\n\n        :param styles (string): Name of Style to be applied to the selected\n            views. = ['Directed', 'BioPAX_SIF', 'Bridging Reads Histogram:unique_0',\n            'PSIMI 25 Style', 'Coverage Histogram:best&unique', 'Minimal',\n            'Bridging Reads Histogram:best&unique_0', 'Coverage Histogram_0',\n            'Big Labels', 'No Histogram:best&unique_0', 'Bridging Reads Histogram:best',\n            'No Histogram_0', 'No Histogram:best&unique', 'Bridging Reads Histogram_0',\n            'Ripple', 'Coverage Histogram:unique_0', 'Nested Network Style',\n            'Coverage Histogram:best', 'Coverage Histogram:best&unique_0',\n            'default black', 'No Histogram:best_0', 'No Histogram:unique',\n            'No Histogram:unique_0', 'Solid', 'Bridging Reads Histogram:unique',\n            'No Histogram:best', 'Coverage Histogram', 'BioPAX', 'Bridging Reads Histogram',\n            'Coverage Histogram:best_0', 'Sample1', 'Universe', 'Bridging Reads Histogram:best_0',\n            'Coverage Histogram:unique', 'Bridging Reads Histogram:best&unique',\n            'No Histogram', 'default']\n        :param verbose: print more\n        :returns: SUIDs of the affected views\n\n        \"\"\"\n\n        PARAMS=set_param([\"styles\"],[styles])\n        response=api(url=self.__url+\"/apply\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new visual style for the current node.", "response": "def create_style(self,title=None,defaults=None,mappings=None,verbose=VERBOSE):\n        \"\"\"\n        Creates a new visual style\n\n        :param title: title of the visual style\n        :param defaults: a list of dictionaries for each visualProperty\n        :param mappings: a list of dictionaries for each visualProperty\n        :param host: cytoscape host address, default=cytoscape_host\n        :param port: cytoscape port, default=1234\n\n        :returns: nothing\n        \"\"\"\n        u=self.__url\n        host=u.split(\"//\")[1].split(\":\")[0]\n        port=u.split(\":\")[2].split(\"/\")[0]\n        version=u.split(\":\")[2].split(\"/\")[1]\n\n        if defaults:\n            defaults_=[]\n            for d in defaults:\n                if d:\n                    defaults_.append(d)\n            defaults=defaults_\n\n        if mappings:\n            mappings_=[]\n            for m in mappings:\n                if m:\n                    mappings_.append(m)\n            mappings=mappings_\n\n        try:\n            update_style(title=title,defaults=defaults,mappings=mappings,host=host,port=port)\n            print(\"Existing style was updated.\")\n            sys.stdout.flush()\n        except:\n            print(\"Creating new style.\")\n            sys.stdout.flush()\n            URL=\"http://\"+str(host)+\":\"+str(port)+\"/v1/styles\"\n            PARAMS={\"title\":title,\\\n                \"defaults\":defaults,\\\n                \"mappings\":mappings}\n            r = requests.post(url = URL, json = PARAMS)\n            checkresponse(r)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_style(self, title=None,defaults=None,mappings=None, verbose=False):\n        u=self.__url\n        host=u.split(\"//\")[1].split(\":\")[0]\n        port=u.split(\":\")[2].split(\"/\")[0]\n        version=u.split(\":\")[2].split(\"/\")[1]\n\n        if defaults:\n            defaults_=[]\n            for d in defaults:\n                if d:\n                    defaults_.append(d)\n            defaults=defaults_\n\n        if mappings:\n            mappings_=[]\n            for m in mappings:\n                if m:\n                    mappings_.append(m)\n            mappings=mappings_\n\n        URL=\"http://\"+str(host)+\":\"+str(port)+\"/v1/styles/\"+str(title)\n        if verbose:\n            print(URL)\n            sys.stdout.flush()\n\n        response = requests.get(URL).json()\n\n        olddefaults=response[\"defaults\"]\n        oldmappings=response[\"mappings\"]\n\n        if mappings:\n            mappings_visual_properties=[ m[\"visualProperty\"] for m in mappings ]\n            newmappings=[ m for m in oldmappings if m[\"visualProperty\"] not in mappings_visual_properties ]\n            for m in mappings:\n                newmappings.append(m)\n        else:\n            newmappings=oldmappings\n\n        if defaults:\n            defaults_visual_properties=[ m[\"visualProperty\"] for m in defaults ]\n            newdefaults=[ m for m in olddefaults if m[\"visualProperty\"] not in defaults_visual_properties ]\n            for m in defaults:\n                newdefaults.append(m)\n        else:\n            newdefaults=olddefaults\n\n        r=requests.delete(URL)\n        checkresponse(r)\n\n        URL=\"http://\"+str(host)+\":\"+str(port)+\"/v1/styles\"\n        PARAMS={\"title\":title,\\\n            \"defaults\":newdefaults,\\\n            \"mappings\":newmappings}\n        r = requests.post(url = URL, json = PARAMS)\n        checkresponse(r)", "response": "Updates a visual style of the current node."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mapVisualProperty(self, visualProperty=None,mappingType=None, mappingColumn=None,\n                        lower=None,center=None,upper=None,\\\n                        discrete=None,\\\n                        network=\"current\",table=\"node\",\\\n                        namespace=\"default\",verbose=False):\n        \"\"\"\"\n        Generates a dictionary for a given visual property\n\n        :param visualProperty: visualProperty\n        :param mappingType: mappingType\n        :param mappingColumn: mappingColumn\n        :param lower: for \"continuous\" mappings a list of the form [value,rgb_string]\n        :param center: for \"continuous\" mappings a list of the form [value,rgb_string]\n        :param upper: for \"continuous\" mappings a list of the form [value,rgb_string]\n        :param discrete: for discrete mappings, a list of lists of the form [ list_of_keys, list_of_values ]\n\t\t:param network (string, optional): Specifies a network by name, or by\n            SUID if the prefix SUID: is used. The keyword CURRENT, or a blank\n            value can also be used to specify the current network.\n        :param namespace (string, optional): Node, Edge, and Network objects support\n            the default, local, and hidden namespaces. Root networks also support the\n            shared namespace. Custom namespaces may be specified by Apps.\n        :returns: a dictionary for the respective visual property\n        \"\"\"\n        u=self.__url\n        host=u.split(\"//\")[1].split(\":\")[0]\n        port=u.split(\":\")[2].split(\"/\")[0]\n        version=u.split(\":\")[2].split(\"/\")[1]\n\n        if type(network) != int:\n            network=check_network(self,network,verbose=verbose)\n            PARAMS=set_param([\"columnList\",\"namespace\",\"network\"],[\"SUID\",namespace,network])\n            networkID=api(namespace=\"network\", command=\"get attribute\",PARAMS=PARAMS, host=host,port=str(port),version=version)\n            PARAMS=set_param([\"columnList\",\"namespace\",\"network\"],[\"name\",namespace,network])\n            networkname=api(namespace=\"network\", command=\"get attribute\",PARAMS=PARAMS, host=host,port=str(port),version=version)\n            network=networkID[0][\"SUID\"]\n            networkname=networkname[0][\"name\"]\n\n        URL=\"http://\"+str(host)+\":\"+str(port)+\"/v1/networks/\"+str(network)+\"/tables/\"+namespace+table+\"/columns/\"\n        if verbose:\n            print(URL)\n            sys.stdout.flush()\n        response = requests.get(URL).json()\n\n        mappingColumnType=None\n        for r in response:\n            if r[\"name\"]==mappingColumn:\n                mappingColumnType=r[\"type\"]\n                break\n        if not mappingColumnType:\n            print(\"For mappingType: \"+mappingType+\" it was not possible to find a  mappingColumnType.\")\n            sys.stdout.flush()\n\n        PARAMS={\"mappingType\" : mappingType,\\\n                \"mappingColumn\" : mappingColumn,\n                \"mappingColumnType\" : mappingColumnType,\n                \"visualProperty\" : visualProperty}\n        if mappingType == \"continuous\":\n            PARAMS[\"points\"]=[{\"value\" : lower[0],\\\n                            \"lesser\" : lower[1],\\\n                            \"equal\" : lower[1],\\\n                            \"greater\" : lower[1]},\\\n                            {\"value\" : center[0],\n                            \"lesser\" : center[1],\n                            \"equal\" : center[1],\n                            \"greater\" : center[1] },\\\n                            {\"value\" : upper[0],\\\n                            \"lesser\" : upper[1],\\\n                            \"equal\" : upper[1],\\\n                            \"greater\" : upper[1]}]\n\n        if discrete:\n            PARAMS[\"map\"]=[]\n            for k,v in zip(discrete[0],discrete[1]):\n                PARAMS[\"map\"].append({ \"key\":k,\"value\":v})\n\n        if not mappingColumnType:\n            res=None\n        else:\n            res=PARAMS\n\n        return res", "response": "This function maps a visual property to a set of attributes."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef simple_defaults(self, defaults_dic):\n\n        defaults=[]\n        for d in defaults_dic.keys():\n            dic={}\n            dic[\"visualProperty\"]=d\n            dic[\"value\"]=defaults_dic[d]\n            defaults.append(dic)\n        return defaults", "response": "Simplifies defaults.\n\n        :param defaults_dic: a dictionary of the form { visualProperty_A:value_A, visualProperty_B:value_B, ..}\n\n        :returns: a list of dictionaries with each item corresponding to a given key in defaults_dic"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef attribute_circle(self, EdgeAttribute=None, network=None, \\\n\tNodeAttribute=None, nodeList=None, singlePartition=None,\\\n\tspacing=None, verbose=False):\n\t\t\"\"\"\n\t\tExecute the Attribute Circle Layout on a network.\n\n\t\t:param EdgeAttribute (string, optional): The name of the edge column\n\t\t\tcontaining numeric values that will be used as weights in the layout\n\t\t\talgorithm. Only columns containing numeric values are shown\n\t\t:param network (string, optional): Specifies a network by name, or by\n\t\t\tSUID if the prefix SUID: is used. The keyword CURRENT, or a blank\n\t\t\tvalue can also be used to specify the current network.\n\t\t:param NodeAttribute (string, optional): The name of the node column\n\t\t\tcontaining numeric values that will be used as weights in the layout\n\t\t\talgorithm. Only columns containing numeric values are shown\n\t\t:param nodeList (string, optional): Specifies a list of nodes. The\n\t\t\tkeywords all, selected, or unselected can be used to specify nodes\n\t\t\tby their selection state. The pattern COLUMN:VALUE sets this parameter\n\t\t\tto any rows that contain the specified column value; if the COLUMN\n\t\t\tprefix is not used, the NAME column is matched by default. A list of\n\t\t\tCOLUMN:VALUE pairs of the format COLUMN1:VALUE1,COLUMN2:VALUE2,...\n\t\t\tcan be used to match multiple values.\n\t\t:param singlePartition (string, optional): Don't partition graph before\n\t\t\tlayout, only boolean values allowed: true or false\n\t\t:param spacing (string, optional): Circle size, in numeric value\n\t\t:param verbose: print more\n\n\t\t\"\"\"\n\t\tnetwork=check_network(self,network,verbose=verbose)\n\t\tPARAMS=set_param([\"EdgeAttribute\",\"network\",\"NodeAttribute\",\"nodeList\",\"singlePartition\",\"spacing\"],\\\n\t\t[EdgeAttribute,network,NodeAttribute,nodeList,singlePartition,spacing])\n\t\tresponse=api(url=self.__url+\"/attribute-circle\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n\t\treturn response", "response": "Execute the Attribute Circle Layout on a network."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef attributes_layout(self, EdgeAttribute=None, maxwidth=None, minrad=None, \\\n\tnetwork=None, NodeAttribute=None,nodeList=None, radmult=None, \\\n\tspacingx=None, spacingy=None, verbose=False):\n\t\t\"\"\"\n\t\tExecute the Group Attributes Layout on a network\n\n\t\t:param EdgeAttribute (string, optional): The name of the edge column\n\t\t\tcontaining numeric values that will be used as weights in the layout\n\t\t\t\talgorithm. Only columns containing numeric values are shown\n\t\t:param maxwidth (string, optional): Maximum width of a row, in numeric value\n\t\t:param minrad (string, optional): Minimum width of a partition, in\n\t\t\tnumeric value\n\t\t:param network (string, optional): Specifies a network by name, or by\n\t\t\tSUID if the prefix SUID: is used. The keyword CURRENT, or a blank\n\t\t\tvalue can also be used to specify the current network.\n\t\t:param NodeAttribute (string, optional): The name of the node column\n\t\t\tcontaining numeric values that will be used as weights in the layout\n\t\t\talgorithm. Only columns containing numeric values are shown\n\t\t:param nodeList (string, optional): Specifies a list of nodes. The\n\t\t\tkeywords all, selected, or unselected can be used to specify nodes\n\t\t\tby their selection state. The pattern COLUMN:VALUE sets this parameter\n\t\t\tto any rows that contain the specified column value; if the COLUMN\n\t\t\tprefix is not used, the NAME column is matched by default. A list\n\t\t\tof COLUMN:VALUE pairs of the format COLUMN1:VALUE1,COLUMN2:VALUE2,...\n\t\t\tcan be used to match multiple values.\n\t\t:param radmult (string, optional): Minimum width of a partition, in\n\t\t\tnumeric value\n\t\t:param spacingx (string, optional): Horizontal spacing between two\n\t\t\tpartitions in a row, in numeric value\n\t\t:param spacingy (string, optional): Vertical spacing between the largest\n\t\t\tpartitions of two rows, in numeric value\n\t\t:param verbose: print more\n\n\t\t\"\"\"\n\t\tnetwork=check_network(self,network,verbose=verbose)\n\t\tPARAMS=set_param([\"EdgeAttribute\",\"network\",\"NodeAttribute\",\"nodeList\",\"singlePartition\",\"spacing\"],\\\n\t\t[EdgeAttribute, maxwidth, \\\n\t\tminrad, network, NodeAttribute,nodeList, radmult, \\\n\t\tspacingx, spacingy])\n\t\tresponse=api(url=self.__url+\"/attributes-layout\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n\t\treturn response", "response": "Execute the Group Attributes Layout on a network."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexecute the Circular Layout on a network.", "response": "def circular(self,EdgeAttribute=None,leftEdge=None,network=None,\\\n\tNodeAttribute=None,nodeHorizontalSpacing=None,nodeList=None,\\\n\tnodeVerticalSpacing=None,rightMargin=None,singlePartition=None,topEdge=None,\\\n\tverbose=None):\n\t\t\"\"\"\n\t\tExecute the Circular Layout on a network\n\n\t\t:param EdgeAttribute (string, optional): The name of the edge column contai\n\t\t\tning numeric values that will be used as weights in the layout algor\n\t\t\tithm. Only columns containing numeric values are shown\n\t\t:param leftEdge (string, optional): Left edge margin, in numeric value\n\t\t:param network (string, optional): Specifies a network by name, or by SUID\n\t\t\tif the prefix SUID: is used. The keyword CURRENT, or a blank value c\n\t\t\tan also be used to specify the current network.\n\t\t:param NodeAttribute (string, optional): The name of the node column contai\n\t\t\tning numeric values that will be used as weights in the layout algor\n\t\t\tithm. Only columns containing numeric values are shown\n\t\t:param nodeHorizontalSpacing (string, optional): Horizontal spacing between\n\t\t\t\tnodes, in numeric value\n\t\t:param nodeList (string, optional): Specifies a list of nodes. The keywords\n\t\t\t\tall, selected, or unselected can be used to specify nodes by their\n\t\t\tselection state. The pattern COLUMN:VALUE sets this parameter to any\n\t\t\t\trows that contain the specified column value; if the COLUMN prefix\n\t\t\tis not used, the NAME column is matched by default. A list of COLUMN\n\t\t\t:VALUE pairs of the format COLUMN1:VALUE1,COLUMN2:VALUE2,... can be\n\t\t\tused to match multiple values.\n\t\t:param nodeVerticalSpacing (string, optional): Vertical spacing between nod\n\t\t\tes, in numeric value\n\t\t:param rightMargin (string, optional): Right edge margin, in numeric value\n\t\t:param singlePartition (string, optional): Don't partition graph before lay\n\t\t\tout; only boolean values are allowed: true or false\n\t\t:param topEdge (string, optional): Top edge margin, in numeric value\n\t\t\"\"\"\n\t\tnetwork=check_network(self,network,verbose=verbose)\n\t\tPARAMS=set_param(['EdgeAttribute','leftEdge','network','NodeAttribute',\\\n\t\t'nodeHorizontalSpacing','nodeList','nodeVerticalSpacing','rightMargin',\\\n\t\t'singlePartition','topEdge'],[EdgeAttribute,leftEdge,network,NodeAttribute,\\\n\t\tnodeHorizontalSpacing,nodeList,nodeVerticalSpacing,rightMargin,\\\n\t\tsinglePartition,topEdge])\n\t\tresponse=api(url=self.__url+\"/circular\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n\t\treturn response"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the coordinates for each node in the target network to the coordinates of a matching node in the source network. Optional parameters such as gridUnmapped and selectUnmapped determine the behavior of target network nodes that could not be matched. :param gridUnmapped (string, optional): If this is set to true, any nodes i n the target network that could not be matched to a node in the sour ce network will be laid out in a grid :param selectUnmapped (string, optional): If this is set to true, any nodes in the target network that could not be matched to a node in the so urce network will be selected in the target network :param sourceColumn (string): The name of column in the node table used to match nodes :param sourceNetwork (string): The name of network to get node coordinates from :param targetColumn (string): The name of column in the node table used to match nodes :param targetNetwork (string): The name of the network to apply coordinates to.", "response": "def copycat(self,gridUnmapped=None,selectUnmapped=None,sourceColumn=None,\\\n\tsourceNetwork=None,targetColumn=None,targetNetwork=None,verbose=None):\n\t\t\"\"\"\n\t\tSets the coordinates for each node in the target network to the coordinates\n\t\tof a matching node in the source network.\n\t\tOptional parameters such as gridUnmapped and selectUnmapped determine\n\t\tthe behavior of target network nodes that could not be matched.\n\n\t\t:param gridUnmapped (string, optional): If this is set to true, any nodes i\n\t\t\tn the target network that could not be matched to a node in the sour\n\t\t\tce network will be laid out in a grid\n\t\t:param selectUnmapped (string, optional): If this is set to true, any nodes\n\t\t\t\tin the target network that could not be matched to a node in the so\n\t\t\turce network will be selected in the target network\n\t\t:param sourceColumn (string): The name of column in the node table used to\n\t\t\tmatch nodes\n\t\t:param sourceNetwork (string): The name of network to get node coordinates\n\t\t\tfrom\n\t\t:param targetColumn (string): The name of column in the node table used to\n\t\t\tmatch nodes\n\t\t:param targetNetwork (string): The name of the network to apply coordinates\n\t\t\t\tto.\n\t\t\"\"\"\n\t\tPARAMS=set_param(['gridUnmapped','selectUnmapped','sourceColumn',\\\n\t\t'sourceNetwork','targetColumn','targetNetwork'],[gridUnmapped,\\\n\t\tselectUnmapped,sourceColumn,sourceNetwork,targetColumn,targetNetwork])\n\t\tresponse=api(url=self.__url+\"/copycat\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n\t\treturn response"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cose(self,compoundGravityRange=None,compoundGravityStrength=None,\\\n\t\tEdgeAttribute=None,gravityRange=None,gravityStrength=None,idealEdgeLength=None,\\\n\t\tincremental=None,LayoutQuality=None,network=None,NodeAttribute=None,\\\n\t\tnodeList=None,repulsionStrength=None,smartEdgeLengthCalc=None,\\\n\t\tsmartRepulsionRangeCalc=None,springStrength=None,verbose=None):\n\t\t\"\"\"\n\t\tExecute the Compound Spring Embedder (CoSE) on a network\n\n\t\t:param compoundGravityRange (string, optional): Compound gravity range (0-1\n\t\t\t00)\n\t\t:param compoundGravityStrength (string, optional): Compound gravity strengt\n\t\t\th (0-100)\n\t\t:param EdgeAttribute (string, optional): The name of the edge column contai\n\t\t\tning numeric values that will be used as weights in the layout algor\n\t\t\tithm. Only columns containing numeric values are shown\n\t\t:param gravityRange (string, optional): Gravity range (0-100)\n\t\t:param gravityStrength (string, optional): Gravity strength (0-100)\n\t\t:param idealEdgeLength (string, optional): Ideal edge length, any positive\n\t\t\tinteger\n\t\t:param incremental (string, optional): Incremental; whether the algorithm w\n\t\t\till be applied incrementally; boolean values only, true or false; de\n\t\t\tfaults to false\n\t\t:param LayoutQuality (string, optional): Layout quality; allowed values are\n\t\t\t\tProof, Default and Draft = ['Proof', 'Default', 'Draft']\n\t\t:param network (string, optional): Specifies a network by name, or by SUID\n\t\t\tif the prefix SUID: is used. The keyword CURRENT, or a blank value c\n\t\t\tan also be used to specify the current network.\n\t\t:param NodeAttribute (string, optional): The name of the node column contai\n\t\t\tning numeric values that will be used as weights in the layout algor\n\t\t\tithm. Only columns containing numeric values are shown\n\t\t:param nodeList (string, optional): Specifies a list of nodes. The keywords\n\t\t\t\tall, selected, or unselected can be used to specify nodes by their\n\t\t\tselection state. The pattern COLUMN:VALUE sets this parameter to any\n\t\t\t\trows that contain the specified column value; if the COLUMN prefix\n\t\t\tis not used, the NAME column is matched by default. A list of COLUMN\n\t\t\t:VALUE pairs of the format COLUMN1:VALUE1,COLUMN2:VALUE2,... can be\n\t\t\tused to match multiple values.\n\t\t:param repulsionStrength (string, optional): Repulsion strength (0-100)\n\t\t:param smartEdgeLengthCalc (string, optional): Use smart edge length calcul\n\t\t\tation; boolean values only, true or false; defaults to true\n\t\t:param smartRepulsionRangeCalc (string, optional): Use smart repulsion rang\n\t\t\te calculation; boolean values only, true or false; defaults to true\n\t\t:param springStrength (string, optional): Spring strength (0-100)\n\t\t\"\"\"\n\t\tnetwork=check_network(self,network,verbose=verbose)\n\t\tPARAMS=set_param(['compoundGravityRange','compoundGravityStrength',\\\n\t\t'EdgeAttribute','gravityRange','gravityStrength','idealEdgeLength',\\\n\t\t'incremental','LayoutQuality','network','NodeAttribute','nodeList',\\\n\t\t'repulsionStrength','smartEdgeLengthCalc','smartRepulsionRangeCalc',\\\n\t\t'springStrength'],[compoundGravityRange,compoundGravityStrength,EdgeAttribute,\\\n\t\tgravityRange,gravityStrength,idealEdgeLength,incremental,LayoutQuality,\\\n\t\tnetwork,NodeAttribute,nodeList,repulsionStrength,smartEdgeLengthCalc,\\\n\t\tsmartRepulsionRangeCalc,springStrength])\n\t\tresponse=api(url=self.__url+\"/cose\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n\t\treturn response", "response": "Execute the Compound Spring Embedder on a network."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexecute the Degree Sorted Circle Layout on a network.", "response": "def degree_circle(self,EdgeAttribute=None,network=None,NodeAttribute=None,\\\n\t\tnodeList=None,singlePartition=None,verbose=None):\n\t\t\"\"\"\n\t\tExecute the Degree Sorted Circle Layout on a network.\n\n\t\t:param EdgeAttribute (string, optional): The name of the edge column contai\n\t\t\tning numeric values that will be used as weights in the layout algor\n\t\t\tithm. Only columns containing numeric values are shown\n\t\t:param network (string, optional): Specifies a network by name, or by SUID\n\t\t\tif the prefix SUID: is used. The keyword CURRENT, or a blank value c\n\t\t\tan also be used to specify the current network.\n\t\t:param NodeAttribute (string, optional): The name of the node column contai\n\t\t\tning numeric values that will be used as weights in the layout algor\n\t\t\tithm. Only columns containing numeric values are shown\n\t\t:param nodeList (string, optional): Specifies a list of nodes. The keywords\n\t\t\t\tall, selected, or unselected can be used to specify nodes by their\n\t\t\tselection state. The pattern COLUMN:VALUE sets this parameter to any\n\t\t\t\trows that contain the specified column value; if the COLUMN prefix\n\t\t\tis not used, the NAME column is matched by default. A list of COLUMN\n\t\t\t:VALUE pairs of the format COLUMN1:VALUE1,COLUMN2:VALUE2,... can be\n\t\t\tused to match multiple values.\n\t\t:param singlePartition (string, optional): Don't partition graph before lay\n\t\t\tout; boolean values only, true or false; defaults to false\n\t\t\"\"\"\n\t\tnetwork=check_network(self,network,verbose=verbose)\n\t\tPARAMS=set_param(['EdgeAttribute','network','NodeAttribute','nodeList',\\\n\t\t'singlePartition'],[EdgeAttribute,network,NodeAttribute,nodeList,\\\n\t\tsinglePartition])\n\t\tresponse=api(url=self.__url+\"/degree-circle\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n\t\treturn response"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexecutes the Prefuse Force Directed Layout on a network.", "response": "def force_directed(self,defaultEdgeWeight=None,defaultNodeMass=None,\\\n\t\tdefaultSpringCoefficient=None,defaultSpringLength=None,EdgeAttribute=None,\\\n\t\tisDeterministic=None,maxWeightCutoff=None,minWeightCutoff=None,network=None,\\\n\t\tNodeAttribute=None,nodeList=None,numIterations=None,singlePartition=None,\\\n\t\tType=None,verbose=None):\n\t\t\"\"\"\n\t\tExecute the Prefuse Force Directed Layout on a network\n\n\t\t:param defaultEdgeWeight (string, optional): The default edge weight to con\n\t\t\tsider, default is 0.5\n\t\t:param defaultNodeMass (string, optional): Default Node Mass, in numeric va\n\t\t\tlue\n\t\t:param defaultSpringCoefficient (string, optional): Default Spring Coeffici\n\t\t\tent, in numeric value\n\t\t:param defaultSpringLength (string, optional): Default Spring Length, in nu\n\t\t\tmeric value\n\t\t:param EdgeAttribute (string, optional): The name of the edge column contai\n\t\t\tning numeric values that will be used as weights in the layout algor\n\t\t\tithm. Only columns containing numeric values are shown\n\t\t:param isDeterministic (string, optional): Force deterministic layouts (slo\n\t\t\twer); boolean values only, true or false; defaults to false\n\t\t:param maxWeightCutoff (string, optional): The maximum edge weight to consi\n\t\t\tder, default to the Double.MAX value\n\t\t:param minWeightCutoff (string, optional): The minimum edge weight to consi\n\t\t\tder, numeric values, default is 0\n\t\t:param network (string, optional): Specifies a network by name, or by SUID\n\t\t\tif the prefix SUID: is used. The keyword CURRENT, or a blank value c\n\t\t\tan also be used to specify the current network.\n\t\t:param NodeAttribute (string, optional): The name of the node column contai\n\t\t\tning numeric values that will be used as weights in the layout algor\n\t\t\tithm. Only columns containing numeric values are shown\n\t\t:param nodeList (string, optional): Specifies a list of nodes. The keywords\n\t\t\t\tall, selected, or unselected can be used to specify nodes by their\n\t\t\tselection state. The pattern COLUMN:VALUE sets this parameter to any\n\t\t\t\trows that contain the specified column value; if the COLUMN prefix\n\t\t\tis not used, the NAME column is matched by default. A list of COLUMN\n\t\t\t:VALUE pairs of the format COLUMN1:VALUE1,COLUMN2:VALUE2,... can be\n\t\t\tused to match multiple values.\n\t\t:param numIterations (string, optional): Number of Iterations, in numeric v\n\t\t\talue\n\t\t:param singlePartition (string, optional): Don't partition graph before lay\n\t\t\tout; boolean values only, true or false; defaults to false\n\t\t:param Type (string, optional): How to interpret weight values; must be one\n\t\t\t\tof Heuristic, -Log(value), 1 - normalized value and normalized valu\n\t\t\te. Defaults to Heuristic = ['Heuristic', '-Log(value)', '1 - normali\n\t\t\tzed value', 'normalized value']\n\t\t\"\"\"\n\t\tnetwork=check_network(self,network,verbose=verbose)\n\t\tPARAMS=set_param(['defaultEdgeWeight','defaultNodeMass','defaultSpringCoefficient',\\\n\t\t'defaultSpringLength','EdgeAttribute','isDeterministic','maxWeightCutoff',\\\n\t\t'minWeightCutoff','network','NodeAttribute','nodeList','numIterations',\\\n\t\t'singlePartition','Type'],[defaultEdgeWeight,defaultNodeMass,\\\n\t\tdefaultSpringCoefficient,defaultSpringLength,EdgeAttribute,isDeterministic,\\\n\t\tmaxWeightCutoff,minWeightCutoff,network,NodeAttribute,nodeList,numIterations,\\\n\t\tsinglePartition,Type])\n\t\tresponse=api(url=self.__url+\"/force-directed\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n\t\treturn response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fruchterman_rheingold(self,attraction_multiplier=None,conflict_avoidance=None,\\\n\t\tdefaultEdgeWeight=None,EdgeAttribute=None,gravity_multiplier=None,\\\n\t\tlayout3D=None,max_distance_factor=None,maxWeightCutoff=None,minWeightCutoff=None,\\\n\t\tnetwork=None,nIterations=None,NodeAttribute=None,nodeList=None,randomize=None,\\\n\t\trepulsion_multiplier=None,singlePartition=None,spread_factor=None,\\\n\t\ttemperature=None,Type=None,update_iterations=None,verbose=None):\n\t\t\"\"\"\n\t\tExecute the Edge-weighted Force directed (BioLayout) on a network\n\n\t\t:param attraction_multiplier (string, optional): Divisor to calculate the a\n\t\t\tttraction force, in numeric value\n\t\t:param conflict_avoidance (string, optional): Constant force applied to avo\n\t\t\tid conflicts, in numeric value\n\t\t:param defaultEdgeWeight (string, optional): The default edge weight to con\n\t\t\tsider, default is 0.5\n\t\t:param EdgeAttribute (string, optional): The name of the edge column contai\n\t\t\tning numeric values that will be used as weights in the layout algor\n\t\t\tithm. Only columns containing numeric values are shown\n\t\t:param gravity_multiplier (string, optional): Multiplier to calculate the g\n\t\t\travity force, in numeric value\n\t\t:param layout3D (string, optional): Layout nodes in 3D; boolean values only\n\t\t\t, true or false; defaults to true\n\t\t:param max_distance_factor (string, optional): Percent of graph used for no\n\t\t\tde repulsion calculations, in numeric value\n\t\t:param maxWeightCutoff (string, optional): The maximum edge weight to consi\n\t\t\tder, default to the Double.MAX value\n\t\t:param minWeightCutoff (string, optional): The minimum edge weight to consi\n\t\t\tder, numeric values, default is 0\n\t\t:param network (string, optional): Specifies a network by name, or by SUID\n\t\t\tif the prefix SUID: is used. The keyword CURRENT, or a blank value c\n\t\t\tan also be used to specify the current network.\n\t\t:param nIterations (string, optional): Number of iterations, in numeric val\n\t\t\tue\n\t\t:param NodeAttribute (string, optional): The name of the node column contai\n\t\t\tning numeric values that will be used as weights in the layout algor\n\t\t\tithm. Only columns containing numeric values are shown\n\t\t:param nodeList (string, optional): Specifies a list of nodes. The keywords\n\t\t\t\tall, selected, or unselected can be used to specify nodes by their\n\t\t\tselection state. The pattern COLUMN:VALUE sets this parameter to any\n\t\t\t\trows that contain the specified column value; if the COLUMN prefix\n\t\t\tis not used, the NAME column is matched by default. A list of COLUMN\n\t\t\t:VALUE pairs of the format COLUMN1:VALUE1,COLUMN2:VALUE2,... can be\n\t\t\tused to match multiple values.\n\t\t:param randomize (string, optional): Randomize graph before layout; boolean\n\t\t\t\tvalues only, true or false; defaults to true\n\t\t:param repulsion_multiplier (string, optional): Multiplier to calculate the\n\t\t\t\trepulsion force, in numeric value\n\t\t:param singlePartition (string, optional): Don't partition graph before lay\n\t\t\tout; boolean values only, true or false; defaults to false\n\t\t:param spread_factor (string, optional): Amount of extra room for layout, i\n\t\t\tn numeric value\n\t\t:param temperature (string, optional): Initial temperature, in numeric valu\n\t\t\te\n\t\t:param Type (string, optional): How to interpret weight values; must be one\n\t\t\t\tof Heuristic, -Log(value), 1 - normalized value and normalized valu\n\t\t\te. Defaults to Heuristic = ['Heuristic', '-Log(value)', '1 - normali\n\t\t\tzed value', 'normalized value']\n\t\t:param update_iterations (string, optional): Number of iterations before up\n\t\t\tdating display, in numeric value (0: update only at end)\n\t\t\"\"\"\n\t\tnetwork=check_network(self,network,verbose=verbose)\n\t\tPARAMS=set_param(['attraction_multiplier','conflict_avoidance',\\\n\t\t'defaultEdgeWeight','EdgeAttribute','gravity_multiplier','layout3D',\\\n\t\t'max_distance_factor','maxWeightCutoff','minWeightCutoff','network',\\\n\t\t'nIterations','NodeAttribute','nodeList','randomize','repulsion_multiplier',\\\n\t\t'singlePartition','spread_factor','temperature','Type','update_iterations'],\\\n\t\t[attraction_multiplier,conflict_avoidance,defaultEdgeWeight,EdgeAttribute,\\\n\t\tgravity_multiplier,layout3D,max_distance_factor,maxWeightCutoff,\\\n\t\tminWeightCutoff,network,nIterations,NodeAttribute,nodeList,randomize,\\\n\t\trepulsion_multiplier,singlePartition,spread_factor,temperature,Type,\\\n\t\tupdate_iterations])\n\t\tresponse=api(url=self.__url+\"/fruchterman-rheingold\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n\t\treturn response", "response": "Execute the fruchterman - rheingold command on a network."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef genemania_force_directed(self,curveSteepness=None,defaultEdgeWeight=None,\\\n\t\tdefaultSpringCoefficient=None,defaultSpringLength=None,EdgeAttribute=None,\\\n\t\tignoreHiddenElements=None,isDeterministic=None,maxNodeMass=None,\\\n\t\tmaxWeightCutoff=None,midpointEdges=None,minNodeMass=None,minWeightCutoff=None,\\\n\t\tnetwork=None,NodeAttribute=None,nodeList=None,numIterations=None,\\\n\t\tsinglePartition=None,Type=None,verbose=None):\n\t\t\"\"\"\n\t\tExecute the GeneMANIA Force Directed Layout on a network.\n\n\t\t:param curveSteepness (string, optional):\n\t\t:param defaultEdgeWeight (string, optional): The default edge weight to con\n\t\t\tsider, default is 0.5\n\t\t:param defaultSpringCoefficient (string, optional):\n\t\t:param defaultSpringLength (string, optional):\n\t\t:param EdgeAttribute (string, optional): The name of the edge column contai\n\t\t\tning numeric values that will be used as weights in the layout algor\n\t\t\tithm. Only columns containing numeric values are shown\n\t\t:param ignoreHiddenElements (string, optional):\n\t\t:param isDeterministic (string, optional):\n\t\t:param maxNodeMass (string, optional):\n\t\t:param maxWeightCutoff (string, optional): The maximum edge weight to consi\n\t\t\tder, default to the Double.MAX value\n\t\t:param midpointEdges (string, optional):\n\t\t:param minNodeMass (string, optional):\n\t\t:param minWeightCutoff (string, optional): The minimum edge weight to consi\n\t\t\tder, numeric values, default is 0\n\t\t:param network (string, optional): Specifies a network by name, or by SUID\n\t\t\tif the prefix SUID: is used. The keyword CURRENT, or a blank value c\n\t\t\tan also be used to specify the current network.\n\t\t:param NodeAttribute (string, optional): The name of the node column contai\n\t\t\tning numeric values that will be used as weights in the layout algor\n\t\t\tithm. Only columns containing numeric values are shown\n\t\t:param nodeList (string, optional): Specifies a list of nodes. The keywords\n\t\t\t\tall, selected, or unselected can be used to specify nodes by their\n\t\t\tselection state. The pattern COLUMN:VALUE sets this parameter to any\n\t\t\t\trows that contain the specified column value; if the COLUMN prefix\n\t\t\tis not used, the NAME column is matched by default. A list of COLUMN\n\t\t\t:VALUE pairs of the format COLUMN1:VALUE1,COLUMN2:VALUE2,... can be\n\t\t\tused to match multiple values.\n\t\t:param numIterations (string, optional):\n\t\t:param singlePartition (string, optional):\n\t\t:param Type (string, optional): How to interpret weight values; must be one\n\t\t\t\tof Heuristic, -Log(value), 1 - normalized value and normalized valu\n\t\t\te. Defaults to Heuristic = ['Heuristic', '-Log(value)', '1 - normali\n\t\t\tzed value', 'normalized value']\n\t\t\"\"\"\n\t\tnetwork=check_network(self,network,verbose=verbose)\n\t\tPARAMS=set_param(['curveSteepness','defaultEdgeWeight',\\\n\t\t'defaultSpringCoefficient','defaultSpringLength','EdgeAttribute',\\\n\t\t'ignoreHiddenElements','isDeterministic','maxNodeMass','maxWeightCutoff',\\\n\t\t'midpointEdges','minNodeMass','minWeightCutoff','network','NodeAttribute',\\\n\t\t'nodeList','numIterations','singlePartition','Type'],[curveSteepness,\\\n\t\tdefaultEdgeWeight,defaultSpringCoefficient,defaultSpringLength,EdgeAttribute,\\\n\t\tignoreHiddenElements,isDeterministic,maxNodeMass,maxWeightCutoff,\\\n\t\tmidpointEdges,minNodeMass,minWeightCutoff,network,NodeAttribute,nodeList,\\\n\t\tnumIterations,singlePartition,Type])\n\t\tresponse=api(url=self.__url+\"/genemania-force-directed\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n\t\treturn response", "response": "Execute the GeneMANIA Force Directed Layout on a network."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_preferred(self,network=None,verbose=None):\n\t\tnetwork=check_network(self,network,verbose=verbose)\n\t\tPARAMS=set_param(['network'],[network])\n\t\tresponse=api(url=self.__url+\"/get preferred\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n\t\treturn response", "response": "This method returns the name of the current preferred layout or empty string. Default is grid."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef grid(self,EdgeAttribute=None,network=None,NodeAttribute=None,\\\n\t\tnodeHorizontalSpacing=None,nodeList=None,nodeVerticalSpacing=None,verbose=None):\n\t\t\"\"\"\n\t\tExecute the Grid Layout on a network.\n\n\t\t:param EdgeAttribute (string, optional): The name of the edge column contai\n\t\t\tning numeric values that will be used as weights in the layout algor\n\t\t\tithm. Only columns containing numeric values are shown\n\t\t:param network (string, optional): Specifies a network by name, or by SUID\n\t\t\tif the prefix SUID: is used. The keyword CURRENT, or a blank value c\n\t\t\tan also be used to specify the current network.\n\t\t:param NodeAttribute (string, optional): The name of the node column contai\n\t\t\tning numeric values that will be used as weights in the layout algor\n\t\t\tithm. Only columns containing numeric values are shown\n\t\t:param nodeHorizontalSpacing (string, optional): Horizontal spacing between\n\t\t\t\tnodes, in numeric value\n\t\t:param nodeList (string, optional): Specifies a list of nodes. The keywords\n\t\t\t\tall, selected, or unselected can be used to specify nodes by their\n\t\t\tselection state. The pattern COLUMN:VALUE sets this parameter to any\n\t\t\t\trows that contain the specified column value; if the COLUMN prefix\n\t\t\tis not used, the NAME column is matched by default. A list of COLUMN\n\t\t\t:VALUE pairs of the format COLUMN1:VALUE1,COLUMN2:VALUE2,... can be\n\t\t\tused to match multiple values.\n\t\t:param nodeVerticalSpacing (string, optional): Vertical spacing between nod\n\t\t\tes, in numeric value\n\t\t\"\"\"\n\t\tnetwork=check_network(self,network,verbose=verbose)\n\t\tPARAMS=set_param(['EdgeAttribute','network','NodeAttribute',\\\n\t\t'nodeHorizontalSpacing','nodeList','nodeVerticalSpacing'],\\\n\t\t[EdgeAttribute,network,NodeAttribute,nodeHorizontalSpacing,nodeList,\\\n\t\tnodeVerticalSpacing])\n\t\tresponse=api(url=self.__url+\"/grid\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n\t\treturn response", "response": "Execute the Grid Layout on a network."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef hierarchical(self,bandGap=None,componentSpacing=None,EdgeAttribute=None,\\\n\t\tleftEdge=None,network=None,NodeAttribute=None,nodeHorizontalSpacing=None,\\\n\t\tnodeList=None,nodeVerticalSpacing=None,rightMargin=None,topEdge=None,\\\n\t\tverbose=None):\n\t\t\"\"\"\n\t\tExecute the Hierarchical Layout on a network.\n\n\t\t:param bandGap (string, optional): Band gap, in numeric value\n\t\t:param componentSpacing (string, optional): Component spacing, in numeric v\n\t\t\talue\n\t\t:param EdgeAttribute (string, optional): The name of the edge column contai\n\t\t\tning numeric values that will be used as weights in the layout algor\n\t\t\tithm. Only columns containing numeric values are shown\n\t\t:param leftEdge (string, optional): Left edge margin, in numeric value\n\t\t:param network (string, optional): Specifies a network by name, or by SUID\n\t\t\tif the prefix SUID: is used. The keyword CURRENT, or a blank value c\n\t\t\tan also be used to specify the current network.\n\t\t:param NodeAttribute (string, optional): The name of the node column contai\n\t\t\tning numeric values that will be used as weights in the layout algor\n\t\t\tithm. Only columns containing numeric values are shown\n\t\t:param nodeHorizontalSpacing (string, optional): Horizontal spacing between\n\t\t\t\tnodes, in numeric value\n\t\t:param nodeList (string, optional): Specifies a list of nodes. The keywords\n\t\t\t\tall, selected, or unselected can be used to specify nodes by their\n\t\t\tselection state. The pattern COLUMN:VALUE sets this parameter to any\n\t\t\t\trows that contain the specified column value; if the COLUMN prefix\n\t\t\tis not used, the NAME column is matched by default. A list of COLUMN\n\t\t\t:VALUE pairs of the format COLUMN1:VALUE1,COLUMN2:VALUE2,... can be\n\t\t\tused to match multiple values.\n\t\t:param nodeVerticalSpacing (string, optional): Vertical spacing between nod\n\t\t\tes, in numeric value\n\t\t:param rightMargin (string, optional): Right edge margin, in numeric value\n\t\t:param topEdge (string, optional): Top edge margin, in numeric value\n\t\t\"\"\"\n\t\tnetwork=check_network(self,network,verbose=verbose)\n\t\tPARAMS=set_param(['bandGap','componentSpacing','EdgeAttribute','leftEdge',\\\n\t\t'network','NodeAttribute','nodeHorizontalSpacing','nodeList',\\\n\t\t'nodeVerticalSpacing','rightMargin','topEdge'],[bandGap,componentSpacing,\\\n\t\tEdgeAttribute,leftEdge,network,NodeAttribute,nodeHorizontalSpacing,\\\n\t\tnodeList,nodeVerticalSpacing,rightMargin,topEdge])\n\t\tresponse=api(url=self.__url+\"/hierarchical\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n\t\treturn response", "response": "Execute the Hierarchical Layout on a network."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef isom(self,coolingFactor=None,EdgeAttribute=None,initialAdaptation=None,\\\n\t\tmaxEpoch=None,minAdaptation=None,minRadius=None,network=None,NodeAttribute=None,\\\n\t\tnodeList=None,radius=None,radiusConstantTime=None,singlePartition=None,\\\n\t\tsizeFactor=None,verbose=None):\n\t\t\"\"\"\n\t\tExecute the Inverted Self-Organizing Map Layout on a network.\n\n\t\t:param coolingFactor (string, optional): Cooling factor, in numeric value\n\t\t:param EdgeAttribute (string, optional): The name of the edge column contai\n\t\t\tning numeric values that will be used as weights in the layout algor\n\t\t\tithm. Only columns containing numeric values are shown\n\t\t:param initialAdaptation (string, optional): Initial adaptation, in numeric\n\t\t\t\tvalue\n\t\t:param maxEpoch (string, optional): Number of iterations, in numeric value\n\t\t:param minAdaptation (string, optional): Minimum adaptation value, in numer\n\t\t\tic value\n\t\t:param minRadius (string, optional): Minimum radius, in numeric value\n\t\t:param network (string, optional): Specifies a network by name, or by SUID\n\t\t\tif the prefix SUID: is used. The keyword CURRENT, or a blank value c\n\t\t\tan also be used to specify the current network.\n\t\t:param NodeAttribute (string, optional): The name of the node column contai\n\t\t\tning numeric values that will be used as weights in the layout algor\n\t\t\tithm. Only columns containing numeric values are shown\n\t\t:param nodeList (string, optional): Specifies a list of nodes. The keywords\n\t\t\t\tall, selected, or unselected can be used to specify nodes by their\n\t\t\tselection state. The pattern COLUMN:VALUE sets this parameter to any\n\t\t\t\trows that contain the specified column value; if the COLUMN prefix\n\t\t\tis not used, the NAME column is matched by default. A list of COLUMN\n\t\t\t:VALUE pairs of the format COLUMN1:VALUE1,COLUMN2:VALUE2,... can be\n\t\t\tused to match multiple values.\n\t\t:param radius (string, optional): Radius, in numeric value\n\t\t:param radiusConstantTime (string, optional): Radius constant, in numeric v\n\t\t\talue\n\t\t:param singlePartition (string, optional): Don't partition graph before lay\n\t\t\tout; boolean values only, true or false; defaults to false\n\t\t:param sizeFactor (string, optional): Size factor, in numeric value\n\t\t\"\"\"\n\t\tnetwork=check_network(self,network,verbose=verbose)\n\t\tPARAMS=set_param(['coolingFactor','EdgeAttribute','initialAdaptation',\\\n\t\t'maxEpoch','minAdaptation','minRadius','network','NodeAttribute','nodeList',\\\n\t\t'radius','radiusConstantTime','singlePartition','sizeFactor'],[coolingFactor,\\\n\t\tEdgeAttribute,initialAdaptation,maxEpoch,minAdaptation,minRadius,network,\\\n\t\tNodeAttribute,nodeList,radius,radiusConstantTime,singlePartition,sizeFactor])\n\t\tresponse=api(url=self.__url+\"/isom\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n\t\treturn response", "response": "Execute the Inverted Self - Organizing Map Layout on a network."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexecutes the Kamada Kawai operation on a network.", "response": "def kamada_kawai(self,defaultEdgeWeight=None,EdgeAttribute=None,\\\n\t\tm_anticollisionSpringStrength=None,m_averageIterationsPerNode=None,\\\n\t\tm_disconnectedNodeDistanceSpringRestLength=None,\\\n\t\tm_disconnectedNodeDistanceSpringStrength=None,m_layoutPass=None,\\\n\t\tm_nodeDistanceRestLengthConstant=None,m_nodeDistanceStrengthConstant=None,\\\n\t\tmaxWeightCutoff=None,minWeightCutoff=None,network=None,NodeAttribute=None,\\\n\t\tnodeList=None,randomize=None,singlePartition=None,Type=None,unweighted=None,\\\n\t\tverbose=None):\n\t\t\"\"\"\n\t\tExecute the Edge-weighted Spring Embedded Layout on a network.\n\n\t\t:param defaultEdgeWeight (string, optional): The default edge weight to con\n\t\t\tsider, default is 0.5\n\t\t:param EdgeAttribute (string, optional): The name of the edge column contai\n\t\t\tning numeric values that will be used as weights in the layout algor\n\t\t\tithm. Only columns containing numeric values are shown\n\t\t:param m_anticollisionSpringStrength (string, optional): Strength to apply\n\t\t\tto avoid collisions, in numeric value\n\t\t:param m_averageIterationsPerNode (string, optional): Average number of ite\n\t\t\tratations for each node, in numeric value\n\t\t:param m_disconnectedNodeDistanceSpringRestLength (string, optional): Rest\n\t\t\tlength of a 'disconnected' spring, in numeric value\n\t\t:param m_disconnectedNodeDistanceSpringStrength (string, optional): Strengt\n\t\t\th of a 'disconnected' spring, in numeric value\n\t\t:param m_layoutPass (string, optional): Number of layout passes, in numeric\n\t\t\t\tvalue\n\t\t:param m_nodeDistanceRestLengthConstant (string, optional): Spring rest len\n\t\t\tgth, in numeric value\n\t\t:param m_nodeDistanceStrengthConstant (string, optional): Spring strength,\n\t\t\tin numeric value\n\t\t:param maxWeightCutoff (string, optional): The maximum edge weight to consi\n\t\t\tder, default to the Double.MAX value\n\t\t:param minWeightCutoff (string, optional): The minimum edge weight to consi\n\t\t\tder, numeric values, default is 0\n\t\t:param network (string, optional): Specifies a network by name, or by SUID\n\t\t\tif the prefix SUID: is used. The keyword CURRENT, or a blank value c\n\t\t\tan also be used to specify the current network.\n\t\t:param NodeAttribute (string, optional): The name of the node column contai\n\t\t\tning numeric values that will be used as weights in the layout algor\n\t\t\tithm. Only columns containing numeric values are shown\n\t\t:param nodeList (string, optional): Specifies a list of nodes. The keywords\n\t\t\t\tall, selected, or unselected can be used to specify nodes by their\n\t\t\tselection state. The pattern COLUMN:VALUE sets this parameter to any\n\t\t\t\trows that contain the specified column value; if the COLUMN prefix\n\t\t\tis not used, the NAME column is matched by default. A list of COLUMN\n\t\t\t:VALUE pairs of the format COLUMN1:VALUE1,COLUMN2:VALUE2,... can be\n\t\t\tused to match multiple values.\n\t\t:param randomize (string, optional): Randomize graph before layout; boolean\n\t\t\t\tvalues only, true or false; defaults to true\n\t\t:param singlePartition (string, optional): Don't partition graph before lay\n\t\t\tout; boolean values only, true or false; defaults to false\n\t\t:param Type (string, optional): How to interpret weight values; must be one\n\t\t\t\tof Heuristic, -Log(value), 1 - normalized value and normalized valu\n\t\t\te. Defaults to Heuristic = ['Heuristic', '-Log(value)', '1 - normali\n\t\t\tzed value', 'normalized value']\n\t\t:param unweighted (string, optional): Use unweighted edges; boolean values\n\t\t\tonly, true or false; defaults to false\n\t\t\"\"\"\n\t\tnetwork=check_network(self,network,verbose=verbose)\n\t\tPARAMS=set_param(['defaultEdgeWeight','EdgeAttribute',\\\n\t\t'm_anticollisionSpringStrength','m_averageIterationsPerNode',\\\n\t\t'm_disconnectedNodeDistanceSpringRestLength',\\\n\t\t'm_disconnectedNodeDistanceSpringStrength','m_layoutPass',\\\n\t\t'm_nodeDistanceRestLengthConstant','m_nodeDistanceStrengthConstant',\\\n\t\t'maxWeightCutoff','minWeightCutoff','network','NodeAttribute','nodeList',\\\n\t\t'randomize','singlePartition','Type','unweighted'],[defaultEdgeWeight,\\\n\t\tEdgeAttribute,m_anticollisionSpringStrength,m_averageIterationsPerNode,\\\n\t\tm_disconnectedNodeDistanceSpringRestLength,\\\n\t\tm_disconnectedNodeDistanceSpringStrength,m_layoutPass,\\\n\t\tm_nodeDistanceRestLengthConstant,m_nodeDistanceStrengthConstant,\\\n\t\tmaxWeightCutoff,minWeightCutoff,network,NodeAttribute,nodeList,randomize,\\\n\t\tsinglePartition,Type,unweighted])\n\t\tresponse=api(url=self.__url+\"/kamada-kawai\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n\t\treturn response"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_preferred(self,preferredLayout=None,verbose=None):\n\t\tPARAMS=set_param(['preferredLayout'],[preferredLayout])\n\t\tresponse=api(url=self.__url+\"/set preferred\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n\t\treturn response", "response": "Sets the preferred layout for this cell."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexecutes the Stacked Node Layout on a network.", "response": "def stacked_node_layout(self,EdgeAttribute=None,network=None,NodeAttribute=None,\\\n\t\tnodeList=None,x_position=None,y_start_position=None,verbose=None):\n\t\t\"\"\"\n\t\tExecute the Stacked Node Layout on a network.\n\n\t\t:param EdgeAttribute (string, optional): The name of the edge column contai\n\t\t\tning numeric values that will be used as weights in the layout algor\n\t\t\tithm. Only columns containing numeric values are shown\n\t\t:param network (string, optional): Specifies a network by name, or by SUID\n\t\t\tif the prefix SUID: is used. The keyword CURRENT, or a blank value c\n\t\t\tan also be used to specify the current network.\n\t\t:param NodeAttribute (string, optional): The name of the node column contai\n\t\t\tning numeric values that will be used as weights in the layout algor\n\t\t\tithm. Only columns containing numeric values are shown\n\t\t:param nodeList (string, optional): Specifies a list of nodes. The keywords\n\t\t\t\tall, selected, or unselected can be used to specify nodes by their\n\t\t\tselection state. The pattern COLUMN:VALUE sets this parameter to any\n\t\t\t\trows that contain the specified column value; if the COLUMN prefix\n\t\t\tis not used, the NAME column is matched by default. A list of COLUMN\n\t\t\t:VALUE pairs of the format COLUMN1:VALUE1,COLUMN2:VALUE2,... can be\n\t\t\tused to match multiple values.\n\t\t:param x_position (string, optional): X start position, in numeric value\n\t\t:param y_start_position (string, optional): Y start position, in numeric va\n\t\t\tlue\n\t\t\"\"\"\n\t\tnetwork=check_network(self,network,verbose=verbose)\n\t\tPARAMS=set_param(['EdgeAttribute','network','NodeAttribute','nodeList',\\\n\t\t'x_position','y_start_position'],[EdgeAttribute,network,NodeAttribute,\\\n\t\tnodeList,x_position,y_start_position])\n\t\tresponse=api(url=self.__url+\"/stacked-node-layout\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n\t\treturn response"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nappend an additional column of attribute values to the current table. :param columnName (string, optional): The new column name :param listType (string, optional): Can be one of integer, long, double, or string. :param table (string, optional): Specifies a table by table name. If the pr efix SUID: is used, the table corresponding the SUID will be returne d. :param ntype (string, optional): Can be one of integer, long, double, string , or list.", "response": "def create_column(self,columnName=None,listType=None,table=None,ntype=None,verbose=None):\n        \"\"\"\n        Appends an additional column of attribute values to the current table.\n\n        :param columnName (string, optional): The new column name\n        :param listType (string, optional): Can be one of integer, long, double, or\n                string.\n        :param table (string, optional): Specifies a table by table name. If the pr\n            efix SUID: is used, the table corresponding the SUID will be returne\n            d.\n        :param ntype (string, optional): Can be one of integer, long, double, string\n            , or list.\n        \"\"\"\n        PARAMS=set_param(['columnName','listType','table','type'],[columnName,\\\n        listType,table,ntype])\n        response=api(url=self.__url+\"/create column\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_table(self,keyColumn=None,keyColumnType=None,title=None,verbose=None):\n        PARAMS=set_param(['keyColumn','keyColumnType','title'],[keyColumn,\\\n        keyColumnType,title])\n        response=api(url=self.__url+\"/create table\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response", "response": "This method creates a new table in the network. The table is created in the network."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove a column from a table.", "response": "def delete_column(self,column=None,table=None,verbose=None):\n        \"\"\"\n        Remove a column from a table, specified by its name. Returns the name of\n        the column removed.\n\n        :param column (string, optional): Specifies the name of a column in the tab\n            le\n        :param table (string, optional): Specifies a table by table name. If the pr\n            efix SUID: is used, the table corresponding the SUID will be returne\n            d.\n        \"\"\"\n        PARAMS=set_param(['column','table'],[column,table])\n        response=api(url=self.__url+\"/delete column\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete_row(self,keyValue=None,table=None,verbose=None):\n        PARAMS=set_param(['keyValue','table'],[keyValue,table])\n        response=api(url=self.__url+\"/delete row\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response", "response": "Deletes a row from a table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the value of the specified column and key value in a table.", "response": "def get_value(self,column=None,keyValue=None,table=None,verbose=None):\n        \"\"\"\n        Returns the value from a cell as specified by row and column ids.\n\n        :param column (string, optional): Specifies the name of a column in the tab\n            le\n        :param keyValue (string, optional): Specifies a row of a table using the pr\n            imary key as the indentifier\n        :param table (string, optional): Specifies a table by table name. If the pr\n            efix SUID: is used, the table corresponding the SUID will be returne\n            d.\n        :returns: value from a cell as specified by row and column ids\n\n        \"\"\"\n        PARAMS=set_param(['column','keyValue','table'],[column,keyValue,table])\n        response=api(url=self.__url+\"/get value\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_tables(self,includePrivate=None,namespace=None,atype=None,verbose=None):\n        PARAMS=set_param(['includePrivate','namespace','type'],\\\n        [includePrivate,namespace,atype])\n        response=api(url=self.__url+\"/list\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response", "response": "This API endpoint returns a list of the tables associated with the passed network parameter."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_columns(self,table=None,verbose=None):\n        PARAMS=set_param(['table'],[table])\n        response=api(url=self.__url+\"/list columns\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response", "response": "Returns the list of columns in a table."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the list of primary keys for each of the rows in the specified table.", "response": "def list_rows(self,rowList=None,table=None,verbose=None):\n        \"\"\"\n        Returns the list of primary keys for each of the rows in the specified table.\n\n        :param rowList (string, optional): Specifies a list of rows. The pattern CO\n            LUMN:VALUE sets this parameter to any rows that contain the specifie\n            d column value; if the COLUMN prefix is not used, the NAME column is\n                matched by default. A list of COLUMN:VALUE pairs of the format COLU\n            MN1:VALUE1,COLUMN2:VALUE2,... can be used to match multiple values.\n            This parameter can also be set to all to include all rows.\n        :param table (string, optional): Specifies a table by table name. If the pr\n            efix SUID: is used, the table corresponding the SUID will be returne\n            d.\n        \"\"\"\n        PARAMS=set_param(['rowList','table'],[rowList,table])\n        response=api(url=self.__url+\"/list rows\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef merge(self,DataTypeTargetForNetworkCollection=None,\\\n        dataTypeTargetForNetworkList=None,mergeType=None,SourceMergeColumns=None,\\\n        SourceMergeKey=None,SourceTable=None,TargetKeyNetworkCollection=None,\\\n        TargetMergeKey=None,TargetNetworkCollection=None,TargetNetworkList=None,\\\n        UnassignedTable=None,WhereMergeTable=None,verbose=None):\n        \"\"\"\n        Merge tables together joining around a designated key column. Depending\n        on the arguments, might merge into multiple local tables.\n\n        :param DataTypeTargetForNetworkCollection (string, optional): The collectio\n            n of networks where the merged table will reside\n        :param dataTypeTargetForNetworkList (string, optional):\n        :param mergeType (string, optional): A choice between ''Copy Columns'' and\n            ''Link To Columns'' that determines if replicates are created\n        :param SourceMergeColumns (string, optional): A list of columns that will b\n            e brought into the merged table\n        :param SourceMergeKey (string, optional): The name of the columns that exis\n            ts in both tables and is used to correlate rows\n        :param SourceTable (string, optional): The name of the table used as the ba\n            se data in the merge\n        :param TargetKeyNetworkCollection (string, optional): The name of the prima\n            ry column about which the merge is made\n        :param TargetMergeKey (string, optional):\n        :param TargetNetworkCollection (string, optional): The group of networks th\n            at will be merged into the source table\n        :param TargetNetworkList (string, optional): The list of networks where the\n                merged table will be added\n        :param UnassignedTable (string, optional):\n        :param WhereMergeTable (string, optional): The destination path of the resu\n            ltant merged table. The choices are ''Network Collection'', ''Select\n            ed Networks'', or ''All Unassigned Tables''.\n        \"\"\"\n        PARAMS=set_param(['DataTypeTargetForNetworkCollection','dataTypeTargetForNetworkList','mergeType','SourceMergeColumns','SourceMergeKey','SourceTable','TargetKeyNetworkCollection','TargetMergeKey','TargetNetworkCollection','TargetNetworkList','UnassignedTable','WhereMergeTable'],\\\n        [DataTypeTargetForNetworkCollection,dataTypeTargetForNetworkList,mergeType,SourceMergeColumns,SourceMergeKey,SourceTable,TargetKeyNetworkCollection,TargetMergeKey,TargetNetworkCollection,TargetNetworkList,UnassignedTable,WhereMergeTable])\n        response=api(url=self.__url+\"/merge\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response", "response": "This method merges the contents of the specified tables into a single table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rename_column(self,columnName=None,newColumnName=None,table=None,verbose=None):\n        PARAMS=set_param(['columnName','newColumnName','table'],[columnName,newColumnName,table])\n        response=api(url=self.__url+\"/rename column\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response", "response": "This API endpoint allows you to change the name of a specified column in a table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nchange the visible identifier of a single table.", "response": "def set_title(self,table=None,title=None,verbose=None):\n        \"\"\"\n        Changes the visible identifier of a single table.\n\n        :param table (string, optional): Specifies a table by table name. If the pr\n            efix SUID: is used, the table corresponding the SUID will be returne\n            d.\n        :param title (string, optional): The name of the table used in the current\n            network\n        \"\"\"\n        PARAMS=set_param(['table','title'],[table,title])\n        response=api(url=self.__url+\"/set title\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_values(self,columnName=None,rowList=None,table=None,value=None,verbose=None):\n        PARAMS=set_param(['columnName','rowList','table','value'],[columnName,rowList,table,value])\n        response=api(url=self.__url+\"/set values\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response", "response": "This method allows you to set all the values in the specified list of rows with a single value."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getTable(self, columns=None, table=None, network = \"current\", namespace='default', verbose=VERBOSE):\n\n        u=self.__url \n        host=u.split(\"//\")[1].split(\":\")[0]\n        port=u.split(\":\")[2].split(\"/\")[0]\n        version=u.split(\":\")[2].split(\"/\")[1]\n\n        if type(network) != int:\n            network=check_network(self,network,verbose=verbose)\n            PARAMS=set_param([\"columnList\",\"namespace\",\"network\"],[\"SUID\",namespace,network])\n            network=api(namespace=\"network\", command=\"get attribute\",PARAMS=PARAMS, host=host,port=str(port),version=version)\n            network=network[0][\"SUID\"]\n\n        df=pd.DataFrame()\n        def target(column):\n            URL=\"http://\"+str(host)+\":\"+str(port)+\"/v1/networks/\"+str(network)+\"/tables/\"+namespace+table+\"/columns/\"+column\n            if verbose:\n                print(\"'\"+URL+\"'\")\n                sys.stdout.flush()\n            response = urllib2.urlopen(URL)\n            response = response.read()\n            colA=json.loads(response)\n\n            col=pd.DataFrame()    \n            colHeader=colA[\"name\"]\n            colValues=colA[\"values\"]\n            col[colHeader]=colValues\n            return col\n\n        ncols=[\"name\"]\n        for c in columns:\n            ncols.append(c.replace(\" \",\"%20\") )\n        for c in ncols:\n            try:\n                col=target(c)\n                df=pd.concat([df,col],axis=1)\n            except:\n                print(\"Could not find \"+c)\n                sys.stdout.flush()\n\n        df.index=df[\"name\"].tolist()\n        df=df.drop([\"name\"],axis=1)\n        return df", "response": "Gets tables from cytoscape."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading the data from cytoscape into a table.", "response": "def loadTableData(self, df, df_key='index',table=\"node\", table_key_column = \"name\", \\\n        network=\"current\",namespace=\"default\",verbose=False):\n        \"\"\"\n        Loads tables into cytoscape.\n\n        :param df: a pandas dataframe to load\n        :param df_key: key column in df, default=\"index\"\n        :param table: target table, default=\"node\"\n        :param table_key_column: table key column, default=\"name\"\n        :param network (string, optional): Specifies a network by name, or by\n            SUID if the prefix SUID: is used. The keyword CURRENT, or a blank\n            value can also be used to specify the current network.\n        :param namespace (string, optional): Node, Edge, and Network objects support\n            the default, local, and hidden namespaces. Root networks also support the\n            shared namespace. Custom namespaces may be specified by Apps.\n        :param verbose: print more information\n\n        :returns: output of put request\n        \"\"\"\n\n        u=self.__url \n        host=u.split(\"//\")[1].split(\":\")[0]\n        port=u.split(\":\")[2].split(\"/\")[0]\n        version=u.split(\":\")[2].split(\"/\")[1]\n\n        if type(network) != int:\n            network=check_network(self,network,verbose=verbose)\n            \n            PARAMS=set_param([\"columnList\",\"namespace\",\"network\"],[\"SUID\",namespace,network])\n            networkID=api(namespace=\"network\", command=\"get attribute\",PARAMS=PARAMS, host=host,port=str(port),version=version)\n            \n            PARAMS=set_param([\"columnList\",\"namespace\",\"network\"],[\"name\",namespace,network])\n            networkname=api(namespace=\"network\", command=\"get attribute\",PARAMS=PARAMS, host=host,port=str(port),version=version)\n                    \n            network=networkID[0][\"SUID\"]\n            networkname=networkname[0][\"name\"]\n\n        tmp=df.copy()\n        if df_key!=\"index\":\n            tmp.index=tmp[df_key].tolist()\n            tmp=tmp.drop([df_key],axis=1)\n                \n        tablen=networkname+\" default node\"\n\n        data=[]\n\n        for c in tmp.columns.tolist():\n            tmpcol=tmp[[c]].dropna()\n            for r in tmpcol.index.tolist():\n                cell={}\n                cell[str(table_key_column)]=str(r) # {\"name\":\"p53\"}\n                val=tmpcol.loc[r,c]\n                if type(val) != str:\n                    val=float(val)\n                cell[str(c)]=val\n                data.append(cell)\n\n\n        upload={\"key\":table_key_column,\"dataKey\":table_key_column,\\\n                \"data\":data}\n\n\n        URL=\"http://\"+str(host)+\":\"+str(port)+\"/v1/networks/\"+str(network)+\"/tables/\"+namespace+table  \n        if verbose:\n            print(\"'\"+URL+\"'\", upload)\n            sys.stdout.flush()\n        r = requests.put(url = URL, json = upload)\n        if verbose:\n            print(r)\n        checkresponse(r)\n        res=r.content\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getTableCount(verbose=None):\n\n        response=api(url=self.url+'tables/count', method=\"GET\", verbose=verbose, parse_params=False)\n        return response", "response": "Returns the number of global tables."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets a single Visual Property Value", "response": "def set_value(self, visual_property, value):\n        \"\"\"Set a single Visual Property Value\n\n        :param visual_property: Visual Property ID\n        :param value: New value for the VP\n        :return: None\n        \"\"\"\n        if visual_property is None or value is None:\n            raise ValueError('Both VP and value are required.')\n\n        new_value = [\n            {\n                'visualProperty': visual_property,\n                \"value\": value\n            }\n        ]\n        requests.put(self.url, data=json.dumps(new_value), headers=HEADERS)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting multiple Visual properties at once.", "response": "def set_values(self, values):\n        \"\"\"\n        Set multiple Visual properties at once.\n\n        :param values:\n        :return:\n        \"\"\"\n        if values is None:\n            raise ValueError('Values are required.')\n\n        new_values = []\n        for vp in values.keys():\n            new_val = {\n                'visualProperty': vp,\n                'value': values[vp]\n            }\n            new_values.append(new_val)\n\n        requests.put(self.url, data=json.dumps(new_values), headers=HEADERS)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_value(self, visual_property):\n        res = requests.get(self.url + '/' + visual_property)\n        return res.json()['value']", "response": "Get a value for the Visual Property\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_values(self):\n\n        results = requests.get(self.url).json()\n        values = {}\n        for entry in results:\n            values[entry['visualProperty']] = entry['value']\n        return values", "response": "Get all visual property values for the object"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_network_view(self, visual_property=None, value=None):\n\n        new_value = [\n            {\n                \"visualProperty\": visual_property,\n                \"value\": value\n            }\n        ]\n        res = requests.put(self.__url + '/network',\n                           data=json.dumps(new_value),\n                           headers=HEADERS)\n        check_response(res)", "response": "Updates single value for Network - related VP."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\napply the Layout specified by the `algorithmName` parameter to the Network specified by the `networkId` parameter. If the Layout is has an option to use a Column, it can be specified by the `column` parameter. :param algorithmName: Name of layout algorithm :param networkId: SUID of the Network :param column: Name of the Column to be used by the Layout -- Not required, can be None :param verbose: print more :returns: 200: successful operation", "response": "def applyLayout(self, algorithmName, networkId, column, verbose=None):\n        \"\"\"\n        Applies the Layout specified by the `algorithmName` parameter to the Network specified by the `networkId` parameter. If the Layout is has an option to use a Column, it can be specified by the `column` parameter.\n\n        :param algorithmName: Name of layout algorithm\n        :param networkId: SUID of the Network\n        :param column: Name of the Column to be used by the Layout -- Not required, can be None\n        :param verbose: print more\n\n        :returns: 200: successful operation\n        \"\"\"\n\n        response=api(url=self.___url+'apply/layouts/'+str(algorithmName)+'/'+str(networkId)+'', PARAMS={'column':column}, method=\"GET\", verbose=verbose, parse_params=False)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef copyCurrentLayout(self, sourceViewSUID, targetViewSUID, body, verbose=None):\n\n        response=api(url=self.___url+'apply/layouts/copycat/'+str(sourceViewSUID)+'/'+str(targetViewSUID)+'', method=\"PUT\", body=body, verbose=verbose)\n        return response", "response": "Copy one network view layout onto another setting the node location and view scale to match. This makes visually comparing networks simple."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef applyStyle(self, styleName, networkId, verbose=None):\n\n        response=api(url=self.___url+'apply/styles/'+str(styleName)+'/'+str(networkId)+'', method=\"GET\", verbose=verbose, parse_params=False)\n        return response", "response": "This method applies the Visual Style specified by styleName to the network specified by networkId."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef updateLayoutParameters(self, algorithmName, body, verbose=None):\n\n        response=api(url=self.___url+'apply/layouts/'+str(algorithmName)+'/parameters', method=\"PUT\", body=body, verbose=verbose)\n        return response", "response": "Update the Layout parameters for the algorithm specified by algorithmName."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getLayout(self, algorithmName, verbose=None):\n\n        response=api(url=self.___url+'apply/layouts/'+str(algorithmName)+'', method=\"H\", verbose=verbose, parse_params=False)\n        return response", "response": "Returns all the details including names parameters and compatible column types for the Layout algorithm specified by algorithmName."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef updateNetworkInNdex(self, suid, body, verbose=None):\n\n        surl=self.___url\n        sv=surl.split('/')[-1]\n        surl=surl.rstrip(sv+'/')\n        response=api(url=surl+'/cyndex2/'+sv+'/networks/'+str(suid)+'', method=\"PUT\", body=body, verbose=verbose)\n        return response", "response": "Update an NDEx network record in Cytoscape Collection / Subnetwork."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef saveNetworkToNdex(self, suid, body, verbose=None):\n\n        surl=self.___url\n        sv=surl.split('/')[-1]\n        surl=surl.rstrip(sv+'/')\n        PARAMS=set_param(['suid','body'],[suid,body])\n        response=api(url=surl+'/cyndex2/'+sv+'/networks/'+str(suid)+'', PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response", "response": "Save a network to NDEx"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getNetworkSummary(self, suid, verbose=None):\n\n        surl=self.___url\n        sv=surl.split('/')[-1]\n        surl=surl.rstrip(sv+'/')\n        response=api(url=surl+'/cyndex2/'+sv+'/networks/'+str(suid)+'', method=\"GET\", verbose=verbose, parse_params=False)\n        return response", "response": "This method returns the summary of the specified network."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate current network s record in NDEx", "response": "def updateCurrentNetworkInNdex(self, body, verbose=None):\n        \"\"\"\n        Update current network's record in NDEx\n\n        :param body: Properties required to update a network record in NDEx.\n        :param verbose: print more\n\n        :returns: 200: successful operation; 404: Network does not exist\n        \"\"\"\n\n        surl=self.___url\n        sv=surl.split('/')[-1]\n        surl=surl.rstrip(sv+'/')\n        response=api(url=surl+'/cyndex2/'+sv+'/networks/current', method=\"PUT\", body=body, verbose=verbose)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef saveCurrentNetworkToNdex(self, body, verbose=None):\n\n        surl=self.___url\n        sv=surl.split('/')[-1]\n        surl=surl.rstrip(sv+'/')\n        PARAMS=set_param(['body'],[body])\n        response=api(url=surl+'/cyndex2/'+sv+'/networks/current', PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response", "response": "Save current network to NDEx"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef export(self, Height=None, options=None, outputFile=None, Resolution=None,\\\n        Units=None, Width=None, Zoom=None, view=\"current\", verbose=False):\n        \"\"\"\n        Exports the current view to a graphics file and returns the path to the\n            saved file. PNG and JPEG formats have options for scaling, while other\n            formats only have the option 'exportTextAsFont'. For the PDF format,\n            exporting text as font does not work for two-byte characters such as\n            Chinese or Japanese. To avoid corrupted texts in the exported PDF,\n            please set false to 'exportTextAsFont' when exporting networks including\n            those non-English characters.\n\n        :param Height (string, optional): The height of the exported image. Valid\n            only for bitmap formats, such as PNG and JPEG.\n        :param options (string, optional): The format of the output file. =\n            ['JPEG (*.jpeg, *.jpg)', 'PDF (*.pdf)', 'PNG (*.png)', 'PostScript (*.ps)',\n             'SVG (*.svg)']\n        :param OutputFile (string, optional): The path name of the file where\n            the view must be saved to. By default, the view's title is used as\n            the file name.\n        :param Resolution (string, optional): The resolution of the exported\n            image, in DPI. Valid only for bitmap formats, when the selected width\n            and height 'units' is inches. The possible values are: 72 (default),\n            100, 150, 300, 600. = ['72', '100', '150', '300', '600']\n        :param Units (string, optional): The units for the 'width' and 'height'\n            values. Valid only for bitmap formats, such as PNG and JPEG. The\n            possible values are: pixels (default), inches. = ['pixels', 'inches']\n        :param Width (string, optional): The width of the exported image. Valid\n            only for bitmap formats, such as PNG and JPEG.\n        :param Zoom (string, optional): The zoom value to proportionally scale\n            the image. The default value is 100.0. Valid only for bitmap formats,\n            such as PNG and JPEG\n        :param verbose: print more\n\n        :returns: path to the saved file\n        \"\"\"\n        PARAMS=set_param([\"Height\",\"options\",\"outputFile\",\"Resolution\",\\\n        \"Units\",\"Width\",\"Zoom\",\"view\"],\\\n        [Height,options,outputFile,Resolution,Units,Width,Zoom,view ])\n        response=api(url=self.__url+\"/export\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response", "response": "Exports the current view to a graphics file and returns the path to the exported image."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfits out the current view in order to display all of its elements.", "response": "def fit_content(self, verbose=False):\n        \"\"\"\n        Zooms out the current view in order to display all of its elements.\n\n        :param verbose: print more\n\n        \"\"\"\n        PARAMS={}\n        response=api(url=self.__url+\"/fit content\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the current view of the current item in the current network.", "response": "def get_current(self, layout=None, network=None, verbose=False):\n        \"\"\"\n        Returns the current view or null if there is none.\n\n        :param verbose: print more\n\n        :returns: current view or null if there is none\n        \"\"\"\n        PARAMS={}\n        response=api(url=self.__url+\"/get_current\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_defaults(self, prop_value_dict):\n\n        body = []\n        for key in prop_value_dict:\n            entry = {\n                'visualProperty': key,\n                'value': prop_value_dict[key]\n            }\n            body.append(entry)\n\n        url = self.__url + 'defaults'\n        requests.put(url, data=json.dumps(body), headers=HEADERS)", "response": "Updates the value of one or more visual properties."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef updateDefaults(self, name, body, verbose=None):\n\n        response=api(url=self.___url+'styles/'+str(name)+'/defaults', method=\"PUT\", body=body, verbose=verbose)\n        return response", "response": "Update the default values for the Visual Properties in the given Visual Style."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the Visual Property specified by the `visualProperty` parameter. Additional details on common Visual Properties can be found in the [Basic Visual Lexicon JavaDoc API](http://chianti.ucsd.edu/cytoscape-3.6.1/API/org/cytoscape/view/presentation/property/BasicVisualLexicon.html) :param visualProperty: ID of the Visual Property :param verbose: print more :returns: 200: successful operation", "response": "def getSingleVisualProperty(self, visualProperty, verbose=None):\n        \"\"\"\n        Return the Visual Property specified by the `visualProperty` parameter.\n        \n        Additional details on common Visual Properties can be found in the [Basic Visual Lexicon JavaDoc API](http://chianti.ucsd.edu/cytoscape-3.6.1/API/org/cytoscape/view/presentation/property/BasicVisualLexicon.html)\n\n        :param visualProperty: ID of the Visual Property\n        :param verbose: print more\n\n        :returns: 200: successful operation\n        \"\"\"\n\n        response=api(url=self.___url+'styles/visualproperties/'+str(visualProperty)+'', method=\"GET\", verbose=verbose, parse_params=False)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new Visual Style using the message body.", "response": "def createStyle(self, body, verbose=None):\n        \"\"\"\n        Creates a new Visual Style using the message body.\n        \n        Returns the title of the new Visual Style. If the title of the Visual Style already existed in the session, a new one will be automatically generated and returned.\n\n        :param body: The details of the new Visual Style to be created.\n        :param verbose: print more\n\n        :returns: 200: successful operation\n        \"\"\"\n\n        PARAMS=set_param(['body'],[body])\n        response=api(url=self.___url+'styles', PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes all vision styles except for default style", "response": "def deleteAllStyles(self, verbose=None):\n        \"\"\"\n        Deletes all vision styles except for default style\n\n        :param verbose: print more\n\n        :returns: default: successful operation\n        \"\"\"\n\n        response=api(url=self.___url+'styles', method=\"DELETE\", verbose=verbose)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getStyleCount(self, verbose=None):\n\n        response=api(url=self.___url+'styles/count', method=\"GET\", verbose=verbose, parse_params=False)\n        return response", "response": "Returns the number of Visual Styles available in the current session."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef deleteMapping(self, name, vpName, verbose=None):\n\n        response=api(url=self.___url+'styles/'+str(name)+'/mappings/'+str(vpName)+'', method=\"DELETE\", verbose=verbose)\n        return response", "response": "This method deletes the Visual Property mapping specified by vpName and name parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of all available values for the Visual Property specified by the `vp` parameter. This method is only for Visual Properties with a Discrete Range, such as NODE_SHAPE or EDGE_LINE_TYPE. Additional details on common Visual Properties can be found in the [Basic Visual Lexicon JavaDoc API](http://chianti.ucsd.edu/cytoscape-3.6.1/API/org/cytoscape/view/presentation/property/BasicVisualLexicon.html) :param vp: ID of the Visual Property :param verbose: print more :returns: 200: successful operation", "response": "def getRangeValues(self, vp, verbose=None):\n        \"\"\"\n        Returns a list of all available values for the Visual Property specified by the `vp` parameter.\n        \n        This method is only for Visual Properties with a Discrete Range, such as NODE_SHAPE or EDGE_LINE_TYPE.\n        \n        Additional details on common Visual Properties can be found in the [Basic Visual Lexicon JavaDoc API](http://chianti.ucsd.edu/cytoscape-3.6.1/API/org/cytoscape/view/presentation/property/BasicVisualLexicon.html)\n\n        :param vp: ID of the Visual Property\n        :param verbose: print more\n\n        :returns: 200: successful operation\n        \"\"\"\n\n        response=api(url=self.___url+'styles/visualproperties/'+str(vp)+'/values', method=\"GET\", verbose=verbose, parse_params=False)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete the Visual Style specified by the `name` parameter. :param name: Visual Style Name :param verbose: print more :returns: default: successful operation", "response": "def deleteStyle(self, name, verbose=None):\n        \"\"\"\n        Deletes the Visual Style specified by the `name` parameter.\n\n        :param name: Visual Style Name\n        :param verbose: print more\n\n        :returns: default: successful operation\n        \"\"\"\n\n        response=api(url=self.___url+'styles/'+str(name)+'', method=\"DELETE\", verbose=verbose)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new Visual Mapping function and add it to the Visual Style.", "response": "def createMappings(self, name, body, verbose=None):\n        \"\"\"\n        Create a new Visual Mapping function and add it to the Visual Style specified by the `name` parameter. Existing mappings in the Visual Style will be overidden by the new mappings created.\n        \n        The types of mapping available in Cytoscape are explained in depth [here](http://manual.cytoscape.org/en/stable/Styles.html#how-mappings-work). An example of the data format for each is included below. For additional details, such as what Visual Properties supported by each Mapping, click on the relevant JavaDoc API link.\n        \n        #### Discrete Mapping\n        [JavaDoc API](http://chianti.ucsd.edu/cytoscape-3.6.1/API/org/cytoscape/view/vizmap/mappings/DiscreteMapping.html)\n        ```\n        { \"mappingType\": \"discrete\",\n        \"mappingColumn\": \"interaction\",\n            \"mappingColumnType\": \"String\",\n            \"visualProperty\": \"EDGE_WIDTH\", \n            \"map\": [\n            { \"key\" : \"pd\",\n                \"value\" : \"20\"\n            },\n            { \"key\" : \"pp\",\n                \"value\" : \"1.5\"\n            }\n            ]\n        }```\n        #### Continuous Mapping\n        [JavaDoc API](http://chianti.ucsd.edu/cytoscape-3.6.1/API/org/cytoscape/view/vizmap/mappings/ContinuousMapping.html)\n        ```\n        { \"mappingType\": \"continuous\",\n        \"mappingColumn\": \"Degree\",\n        \"mappingColumnType\": \"Integer\",\n        \"visualProperty\": \"NODE_SIZE\",\n        \"points\": [\n            { \"value\" : 1,\n                \"lesser\" : \"20\",\n                \"equal\" : \"20\",\n                \"greater\" : \"20\"\n            },\n                { \"value\" : 20,\n                \"lesser\" : \"120\",\n                \"equal\" : \"120\",\n                \"greater\" : \"220\"      }\n            ]\n        }```\n        #### Passthrough Mapping\n        [JavaDoc API](http://chianti.ucsd.edu/cytoscape-3.6.1/API/org/cytoscape/view/vizmap/mappings/PassthroughMapping.html)\n        ```\n        { \"mappingType\": \"passthrough\",\n        \"mappingColumn\": \"name\",\n        \"mappingColumnType\": \"String\",\n        \"visualProperty\": \"EDGE_LABEL\" \n        }```\n        \n        Additional details on common Visual Properties can be found in the [Basic Visual Lexicon JavaDoc API](http://chianti.ucsd.edu/cytoscape-3.6.1/API/org/cytoscape/view/presentation/property/BasicVisualLexicon.html)\n\n        :param name: Name of the Visual Style\n        :param body: A list of new mappings.\n        :param verbose: print more\n\n        :returns: default: successful operation\n        \"\"\"\n\n        PARAMS=set_param(['name','body'],[name,body])\n        response=api(url=self.___url+'styles/'+str(name)+'/mappings', PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating the visual mapping of the given name and vp.", "response": "def updateMapping(self, name, vp, body, verbose=None):\n        \"\"\"\n        Update the visual mapping specified by the `name` and `vp` parameters.\n        \n        The types of mapping available in Cytoscape are explained in depth [here](http://manual.cytoscape.org/en/stable/Styles.html#how-mappings-work). An example of the data format for each is included below. For additional details, such as what Visual Properties supported by each Mapping, click on the relevant JavaDoc API link.\n        \n        #### Discrete Mapping\n        [JavaDoc API](http://chianti.ucsd.edu/cytoscape-3.6.1/API/org/cytoscape/view/vizmap/mappings/DiscreteMapping.html)\n        ```\n        { \"mappingType\": \"discrete\",\n        \"mappingColumn\": \"interaction\",\n            \"mappingColumnType\": \"String\",\n            \"visualProperty\": \"EDGE_WIDTH\", \n            \"map\": [\n            { \"key\" : \"pd\",\n                \"value\" : \"20\"\n            },\n            { \"key\" : \"pp\",\n                \"value\" : \"1.5\"\n            }\n            ]\n        }```\n        #### Continuous Mapping\n        [JavaDoc API](http://chianti.ucsd.edu/cytoscape-3.6.1/API/org/cytoscape/view/vizmap/mappings/ContinuousMapping.html)\n        ```\n        { \"mappingType\": \"continuous\",\n        \"mappingColumn\": \"Degree\",\n        \"mappingColumnType\": \"Integer\",\n        \"visualProperty\": \"NODE_SIZE\",\n        \"points\": [\n            { \"value\" : 1,\n                \"lesser\" : \"20\",\n                \"equal\" : \"20\",\n                \"greater\" : \"20\"\n            },\n                { \"value\" : 20,\n                \"lesser\" : \"120\",\n                \"equal\" : \"120\",\n                \"greater\" : \"220\"      }\n            ]\n        }```\n        #### Passthrough Mapping\n        [JavaDoc API](http://chianti.ucsd.edu/cytoscape-3.6.1/API/org/cytoscape/view/vizmap/mappings/PassthroughMapping.html)\n        ```\n        { \"mappingType\": \"passthrough\",\n        \"mappingColumn\": \"name\",\n        \"mappingColumnType\": \"String\",\n        \"visualProperty\": \"EDGE_LABEL\" \n        }```\n        \n        Additional details on common Visual Properties can be found in the [Basic Visual Lexicon JavaDoc API](http://chianti.ucsd.edu/cytoscape-3.6.1/API/org/cytoscape/view/presentation/property/BasicVisualLexicon.html)\n\n        :param name: Name of the Visual Style containing the Visual Mapping\n        :param vp: Name of the Visual Property that the Visual Mapping controls\n        :param body: A list of new mappings.\n        :param verbose: print more\n\n        :returns: default: successful operation\n        \"\"\"\n\n        response=api(url=self.___url+'styles/'+str(name)+'/mappings/'+str(vp)+'', method=\"PUT\", body=body, verbose=verbose)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the mapping assigned to the given name and vp.", "response": "def getMapping(self, name, vp, verbose=None):\n        \"\"\"\n        Returns the Visual Mapping assigned to the Visual Property specified by the `name` and `vp` parameters.\n        \n        The types of mapping available in Cytoscape are explained in depth [here](http://manual.cytoscape.org/en/stable/Styles.html#how-mappings-work). An example of the data format for each is included below. For additional details, such as what Visual Properties supported by each Mapping, click on the relevant JavaDoc API link.\n        \n        #### Discrete Mapping\n        [JavaDoc API](http://chianti.ucsd.edu/cytoscape-3.6.1/API/org/cytoscape/view/vizmap/mappings/DiscreteMapping.html)\n        ```\n        { \"mappingType\": \"discrete\",\n        \"mappingColumn\": \"interaction\",\n            \"mappingColumnType\": \"String\",\n            \"visualProperty\": \"EDGE_WIDTH\", \n            \"map\": [\n            { \"key\" : \"pd\",\n                \"value\" : \"20\"\n            },\n            { \"key\" : \"pp\",\n                \"value\" : \"1.5\"\n            }\n            ]\n        }```\n        #### Continuous Mapping\n        [JavaDoc API](http://chianti.ucsd.edu/cytoscape-3.6.1/API/org/cytoscape/view/vizmap/mappings/ContinuousMapping.html)\n        ```\n        { \"mappingType\": \"continuous\",\n        \"mappingColumn\": \"Degree\",\n        \"mappingColumnType\": \"Integer\",\n        \"visualProperty\": \"NODE_SIZE\",\n        \"points\": [\n            { \"value\" : 1,\n                \"lesser\" : \"20\",\n                \"equal\" : \"20\",\n                \"greater\" : \"20\"\n            },\n                { \"value\" : 20,\n                \"lesser\" : \"120\",\n                \"equal\" : \"120\",\n                \"greater\" : \"220\"      }\n            ]\n        }```\n        #### Passthrough Mapping\n        [JavaDoc API](http://chianti.ucsd.edu/cytoscape-3.6.1/API/org/cytoscape/view/vizmap/mappings/PassthroughMapping.html)\n        ```\n        { \"mappingType\": \"passthrough\",\n        \"mappingColumn\": \"name\",\n        \"mappingColumnType\": \"String\",\n        \"visualProperty\": \"EDGE_LABEL\" \n        }```\n        \n        Additional details on common Visual Properties can be found in the [Basic Visual Lexicon JavaDoc API](http://chianti.ucsd.edu/cytoscape-3.6.1/API/org/cytoscape/view/presentation/property/BasicVisualLexicon.html)\n\n        :param name: Name of the Visual Style containing the Visual Property mapping\n        :param vp: Name of the Visual Property that the Visual Mapping controls\n        :param verbose: print more\n\n        :returns: 200: successful operation\n        \"\"\"\n\n        response=api(url=self.___url+'styles/'+str(name)+'/mappings/'+str(vp)+'', method=\"GET\", verbose=verbose, parse_params=False)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef status(self, verbose=False):\n        try:\n            response=api(url=self.__url, method=\"GET\", verbose=verbose)\n        except Exception as e:\n            print('Could not get status from CyREST:\\n\\n' + str(e))\n        else:\n            print('CyREST online!')", "response": "Checks the status of the current user s object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef result(self, filetype=\"PNG\", saveas=None, verbose=False):\n        from wand.image import Image as WImage\n        from shutil import copyfile\n        import tempfile\n        from time import sleep\n        import os\n\n        sleep(1)\n        u=self.__url \n        host=u.split(\"//\")[1].split(\":\")[0]\n        port=u.split(\":\")[2].split(\"/\")[0]\n        version=u.split(\":\")[2].split(\"/\")[1]\n\n        def MAKETMP():\n            (fd, tmp_file) = tempfile.mkstemp()\n            tmp_dir=tempfile.gettempdir()\n            tmp_file=tmp_dir+\"/\"+tmp_file.split(\"/\")[-1]\n            return tmp_file\n        \n        outfile=MAKETMP()\n        \n        extensions={\"PNG\":\".png\",\"PDF\":\".pdf\",\"CYS\":\".cys\",\"CYJS\":\".cyjs\"}\n        ext=extensions[filetype]\n        \n        response=api(\"view\",\"fit content\",host=host,port=port, version=version, verbose=verbose)\n        sleep(2)\n        response=api(\"view\", \"export\" , {\"options\":filetype,\"outputFile\":outfile, \"view\":\"current\"}, host=host,port=port,version=version,verbose=verbose)\n        if host!='localhost':\n            import paramiko\n            print(\"Looking to ssh keys for remote access.\")\n            ssh = paramiko.SSHClient()\n            ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n            ssh.connect(host)\n            ftp_client=ssh.open_sftp()\n            ftp_client.get(outfile+ext,outfile+ext)\n            ssh_stdin, ssh_stdout, ssh_stderr = ssh.exec_command(\"rm \"+outfile+ext )\n            \n        img = WImage(filename=outfile+ext)\n        if saveas:\n            copyfile(outfile+ext,saveas)\n        os.remove(outfile+ext)\n        return img", "response": "Returns an image object for the current network."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef map_column(self, only_use_one=None, source_column=None, species=None, target_selection= None, verbose=False):\n        PARAMS=set_param([\"only_use_one\",\"source_column\",\"species\",\"target_selection\"],[only_use_one,source_column,species,target_selection])\n        response=api(url=self.__url+\"/map column\", PARAMS=PARAMS, method=\"POST\", verbose=verbose)\n        return response", "response": "This method maps an analogous identifiers from one column to another column."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nopening a command line dialog that displays the current namespace names and the commands and arguments.", "response": "def open_dialog(self, verbose=False):\n        \"\"\"\n        The command line dialog provides a field to enter commands and view\n        results. It also provides the help command to display namespaces,\n        commands, and arguments.\n\n        :param verbose: print more\n        \"\"\"\n        response=api(url=self.__url+\"/open dialog\", verbose=verbose)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pause(self, message=None, verbose=False):\n\n        PARAMS=set_param([\"message\"],[message])\n        response=api(url=self.__url+\"/pause\", PARAMS=PARAMS, verbose=verbose)\n        return response", "response": "The pause command displays a dialog with the text provided in the\n        message argument and waits for the user to click OK"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(self,script_file,args=None,verbose=False):\n\n        PARAMS=set_param([\"file\",\"args\"],[script_file,args])\n        response=api(url=self.__url+\"/run\", PARAMS=PARAMS, verbose=verbose)\n        return response", "response": "This command will execute a script from the file pointed to by the file argument. The script file argument should contain one per\n        line."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_curl(request, compressed=False, verify=True):\n    parts = [\n        ('curl', None),\n        ('-X', request.method),\n    ]\n\n    for k, v in sorted(request.headers.items()):\n        parts += [('-H', '{0}: {1}'.format(k, v))]\n\n    if request.body:\n        body = request.body\n        if isinstance(body, bytes):\n            body = body.decode('utf-8')\n        parts += [('-d', body)]\n\n    if compressed:\n        parts += [('--compressed', None)]\n\n    if not verify:\n        parts += [('--insecure', None)]\n\n    parts += [(None, request.url)]\n\n    flat_parts = []\n    for k, v in parts:\n        if k:\n            flat_parts.append(k)\n        if v:\n            flat_parts.append(\"'{0}'\".format(v))\n\n    return ' '.join(flat_parts)", "response": "Returns string with curl command by provided request object"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndefaulting class options to pass to the CLI commands.", "response": "def shared_options(rq):\n    \"Default class options to pass to the CLI commands.\"\n    return {\n        'url': rq.redis_url,\n        'config': None,\n        'worker_class': rq.worker_class,\n        'job_class': rq.job_class,\n        'queue_class': rq.queue_class,\n        'connection_class': rq.connection_class,\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef info(rq, ctx, path, interval, raw, only_queues, only_workers, by_queue,\n         queues):\n    \"RQ command-line monitor.\"\n    return ctx.invoke(\n        rq_cli.info,\n        path=path,\n        interval=interval,\n        raw=raw,\n        only_queues=only_queues,\n        only_workers=only_workers,\n        by_queue=by_queue,\n        queues=queues or rq.queues,\n        **shared_options(rq)\n    )", "response": "RQ command - line monitor."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstarting an RQ worker.", "response": "def worker(rq, ctx, burst, logging_level, name, path, results_ttl,\n           worker_ttl, verbose, quiet, sentry_dsn, exception_handler, pid,\n           queues):\n    \"Starts an RQ worker.\"\n    ctx.invoke(\n        rq_cli.worker,\n        burst=burst,\n        logging_level=logging_level,\n        name=name,\n        path=path,\n        results_ttl=results_ttl,\n        worker_ttl=worker_ttl,\n        verbose=verbose,\n        quiet=quiet,\n        sentry_dsn=sentry_dsn,\n        exception_handler=exception_handler or rq._exception_handlers,\n        pid=pid,\n        queues=queues or rq.queues,\n        **shared_options(rq)\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef scheduler(rq, ctx, verbose, burst, queue, interval, pid):\n    \"Periodically checks for scheduled jobs.\"\n    scheduler = rq.get_scheduler(interval=interval, queue=queue)\n    if pid:\n        with open(os.path.expanduser(pid), 'w') as fp:\n            fp.write(str(os.getpid()))\n    if verbose:\n        level = 'DEBUG'\n    else:\n        level = 'INFO'\n    setup_loghandlers(level)\n    scheduler.run(burst=burst)", "response": "Periodically checks for scheduled jobs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cron(self, pattern, name, *args, **kwargs):\n        queue_name = kwargs.pop('queue', self.queue_name)\n        timeout = kwargs.pop('timeout', self.timeout)\n        description = kwargs.pop('description', None)\n        repeat = kwargs.pop('repeat', None)\n        return self.rq.get_scheduler().cron(\n            pattern,\n            self.wrapped,\n            args=args,\n            kwargs=kwargs,\n            repeat=repeat,\n            queue_name=queue_name,\n            id='cron-%s' % name,\n            timeout=timeout,\n            description=description,\n        )", "response": "A function to setup a crontab job as a crontab job."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef init_app(self, app):\n        # The connection related config values\n        self.redis_url = app.config.setdefault(\n            'RQ_REDIS_URL',\n            self.redis_url,\n        )\n        self.connection_class = app.config.setdefault(\n            'RQ_CONNECTION_CLASS',\n            self.connection_class,\n        )\n        # all infos to create a Redis connection are now avaiable.\n        self._ready_to_connect = True\n\n        self.queues = app.config.setdefault(\n            'RQ_QUEUES',\n            self.queues,\n        )\n        self.queue_class = app.config.setdefault(\n            'RQ_QUEUE_CLASS',\n            self.queue_class,\n        )\n        self.worker_class = app.config.setdefault(\n            'RQ_WORKER_CLASS',\n            self.worker_class,\n        )\n        self.job_class = app.config.setdefault(\n            'RQ_JOB_CLASS',\n            self.job_class,\n        )\n        self.scheduler_class = app.config.setdefault(\n            'RQ_SCHEDULER_CLASS',\n            self.scheduler_class,\n        )\n        self.scheduler_queue = app.config.setdefault(\n            'RQ_SCHEDULER_QUEUE',\n            self.scheduler_queue,\n        )\n        self.scheduler_interval = app.config.setdefault(\n            'RQ_SCHEDULER_INTERVAL',\n            self.scheduler_interval,\n        )\n\n        #: Whether or not to run RQ jobs asynchronously or not,\n        #: defaults to asynchronous\n        _async = app.config.setdefault('RQ_ASYNC', True)\n        if self._is_async is None:\n            self._is_async = _async\n\n        # register extension with app\n        app.extensions = getattr(app, 'extensions', {})\n        app.extensions['rq2'] = self\n\n        if hasattr(app, 'cli'):\n            self.init_cli(app)", "response": "Initialize the application with the config values from the app."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef init_cli(self, app):\n        # in case click isn't installed after all\n        if click is None:\n            raise RuntimeError('Cannot import click. Is it installed?')\n        # only add commands if we have a click context available\n        from .cli import add_commands\n        add_commands(app.cli, self)", "response": "Initialize the Flask CLI support for the application."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_scheduler(self, interval=None, queue=None):\n        if interval is None:\n            interval = self.scheduler_interval\n\n        if not queue:\n            queue = self.scheduler_queue\n\n        scheduler_cls = import_attribute(self.scheduler_class)\n\n        scheduler = scheduler_cls(\n            queue_name=queue,\n            interval=interval,\n            connection=self.connection,\n        )\n        return scheduler", "response": "When installed returns a scheduler instance to\n            scheduler instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_queue(self, name=None):\n        if not name:\n            name = self.default_queue\n        queue = self._queue_instances.get(name)\n        if queue is None:\n            queue_cls = import_attribute(self.queue_class)\n            queue = queue_cls(\n                name=name,\n                default_timeout=self.default_timeout,\n                is_async=self._is_async,\n                connection=self.connection,\n                job_class=self.job_class\n            )\n            self._queue_instances[name] = queue\n        return queue", "response": "Returns an instance of the specified name or None if no name is given."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning an instance of the worker class for the given queues.", "response": "def get_worker(self, *queues):\n        \"\"\"\n        Returns an RQ worker instance for the given queue names, e.g.::\n\n            configured_worker = rq.get_worker()\n            default_worker = rq.get_worker('default')\n            default_low_worker = rq.get_worker('default', 'low')\n\n        :param \\\\*queues: Names of queues the worker should act on, falls back\n                          to the configured queues.\n        \"\"\"\n        if not queues:\n            queues = self.queues\n        queues = [self.get_queue(name) for name in queues]\n        worker_cls = import_attribute(self.worker_class)\n        worker = worker_cls(\n            queues,\n            connection=self.connection,\n            job_class=self.job_class,\n            queue_class=self.queue_class,\n        )\n        for exception_handler in self._exception_handlers:\n            worker.push_exc_handler(import_attribute(exception_handler))\n        return worker"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_trace(host=None, port=None, patch_stdstreams=False):\n    if host is None:\n        host = os.environ.get('REMOTE_PDB_HOST', '127.0.0.1')\n    if port is None:\n        port = int(os.environ.get('REMOTE_PDB_PORT', '0'))\n    rdb = RemotePdb(host=host, port=port, patch_stdstreams=patch_stdstreams)\n    rdb.set_trace(frame=sys._getframe().f_back)", "response": "Opens a remote PDB on first available port."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef quasi_newton_uniform_lloyd(points, cells, *args, omega=1.0, **kwargs):\n\n    def get_new_points(mesh):\n        x = (\n            mesh.node_coords\n            - omega / 2 * jac_uniform(mesh) / mesh.control_volumes[:, None]\n        )\n        # update boundary and ghosts\n        idx = mesh.is_boundary_node & ~ghosted_mesh.is_ghost_point\n        x[idx] = mesh.node_coords[idx]\n        x[ghosted_mesh.is_ghost_point] = ghosted_mesh.reflect_ghost(\n            x[ghosted_mesh.mirrors]\n        )\n        return x\n\n    ghosted_mesh = GhostedMesh(points, cells)\n\n    runner(\n        get_new_points,\n        ghosted_mesh,\n        *args,\n        **kwargs,\n        update_topology=lambda mesh: ghosted_mesh.update_topology(),\n        # get_stats_mesh=lambda mesh: ghosted_mesh.get_unghosted_mesh(),\n    )\n\n    mesh = ghosted_mesh.get_unghosted_mesh()\n    return mesh.node_coords, mesh.cells[\"nodes\"]", "response": "Relaxed Lloyd s algorithm. omega = 1 leads to Lloyd s algorithm overrelaxation\n    omega = 2 gives good results."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fixed_point_uniform(points, cells, *args, **kwargs):\n\n    def get_new_points(mesh):\n        return get_new_points_volume_averaged(mesh, mesh.cell_barycenters)\n\n    mesh = MeshTri(points, cells)\n    runner(get_new_points, mesh, *args, **kwargs)\n    return mesh.node_coords, mesh.cells[\"nodes\"]", "response": "Idea - specific function to move interior mesh points into the weighted averages of the centroids\n    ( barycenters of the adjacent cells."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _energy_uniform_per_node(X, cells):\n    dim = 2\n    mesh = MeshTri(X, cells)\n\n    star_integrals = numpy.zeros(mesh.node_coords.shape[0])\n    # Python loop over the cells... slow!\n    for cell, cell_volume in zip(mesh.cells[\"nodes\"], mesh.cell_volumes):\n        for idx in cell:\n            xi = mesh.node_coords[idx]\n            tri = mesh.node_coords[cell]\n            val = quadpy.triangle.integrate(\n                lambda x: numpy.einsum(\"ij,ij->i\", x.T - xi, x.T - xi),\n                tri,\n                # Take any scheme with order 2\n                quadpy.triangle.Dunavant(2),\n            )\n            star_integrals[idx] += val\n\n    return star_integrals / (dim + 1)", "response": "Calculates the energy of each node in the CPT mesh."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nliking linear_solve above, but assuming rho==1. Note that the energy gradient \\\\partial E_i = 2/(d+1) sum_{tau_j in omega_i} (x_i - b_j) \\\\int_{tau_j} rho becomes \\\\partial E_i = 2/(d+1) sum_{tau_j in omega_i} (x_i - b_j) |tau_j|. Because of the dependence of |tau_j| on the point coordinates, this is a nonlinear problem. This method makes the simplifying assumption that |tau_j| does in fact _not_ depend on the point coordinates. With this, one still only needs to solve a linear system.", "response": "def quasi_newton_uniform(points, cells, *args, **kwargs):\n    \"\"\"Like linear_solve above, but assuming rho==1. Note that the energy gradient\n\n        \\\\partial E_i = 2/(d+1) sum_{tau_j in omega_i} (x_i - b_j) \\\\int_{tau_j} rho\n\n    becomes\n\n        \\\\partial E_i = 2/(d+1) sum_{tau_j in omega_i} (x_i - b_j) |tau_j|.\n\n    Because of the dependence of |tau_j| on the point coordinates, this is a nonlinear\n    problem.\n\n    This method makes the simplifying assumption that |tau_j| does in fact _not_ depend\n    on the point coordinates. With this, one still only needs to solve a linear system.\n    \"\"\"\n\n    def get_new_points(mesh):\n        # do one Newton step\n        # TODO need copy?\n        x = mesh.node_coords.copy()\n        cells = mesh.cells[\"nodes\"]\n        jac_x = jac_uniform(x, cells)\n        x -= solve_hessian_approx_uniform(x, cells, jac_x)\n        return x\n\n    mesh = MeshTri(points, cells)\n    runner(get_new_points, mesh, *args, **kwargs)\n    return mesh.node_coords, mesh.cells[\"nodes\"]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fixed_point(points, cells, *args, **kwargs):\n\n    def get_new_points(mesh):\n        # move interior points into average of their neighbors\n        num_neighbors = numpy.zeros(len(mesh.node_coords), dtype=int)\n        idx = mesh.edges[\"nodes\"]\n        fastfunc.add.at(num_neighbors, idx, numpy.ones(idx.shape, dtype=int))\n\n        new_points = numpy.zeros(mesh.node_coords.shape)\n        fastfunc.add.at(new_points, idx[:, 0], mesh.node_coords[idx[:, 1]])\n        fastfunc.add.at(new_points, idx[:, 1], mesh.node_coords[idx[:, 0]])\n\n        new_points /= num_neighbors[:, None]\n        idx = mesh.is_boundary_node\n        new_points[idx] = mesh.node_coords[idx]\n        return new_points\n\n    mesh = MeshTri(points, cells)\n    runner(get_new_points, mesh, *args, **kwargs)\n    return mesh.node_coords, mesh.cells[\"nodes\"]", "response": "Perform k steps of Laplacian smoothing to the mesh i. e. moving each\n    interior vertex to the arithmetic average of its neighboring points."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef energy(mesh, uniform_density=False):\n    # E = 1/(d+1) sum_i ||x_i||^2 |omega_i| - int_Omega_i ||x||^2\n    dim = mesh.cells[\"nodes\"].shape[1] - 1\n\n    star_volume = numpy.zeros(mesh.node_coords.shape[0])\n    for i in range(3):\n        idx = mesh.cells[\"nodes\"][:, i]\n        if uniform_density:\n            # rho = 1,\n            # int_{star} phi_i * rho = 1/(d+1) sum_{triangles in star} |triangle|\n            fastfunc.add.at(star_volume, idx, mesh.cell_volumes)\n        else:\n            # rho = 1 / tau_j,\n            # int_{star} phi_i * rho = 1/(d+1) |num triangles in star|\n            fastfunc.add.at(star_volume, idx, numpy.ones(idx.shape, dtype=float))\n    x2 = numpy.einsum(\"ij,ij->i\", mesh.node_coords, mesh.node_coords)\n    out = 1 / (dim + 1) * numpy.dot(star_volume, x2)\n\n    # could be cached\n    assert dim == 2\n    x = mesh.node_coords[:, :2]\n    triangles = numpy.moveaxis(x[mesh.cells[\"nodes\"]], 0, 1)\n    val = quadpy.triangle.integrate(\n        lambda x: x[0] ** 2 + x[1] ** 2,\n        triangles,\n        # Take any scheme with order 2\n        quadpy.triangle.Dunavant(2),\n    )\n    if uniform_density:\n        val = numpy.sum(val)\n    else:\n        rho = 1.0 / mesh.cell_volumes\n        val = numpy.dot(val, rho)\n\n    assert out >= val\n\n    return out - val", "response": "The energy of a mesh is defined as\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fixed_point_uniform(points, cells, *args, **kwargs):\n\n    def get_new_points(mesh):\n        # Get circumcenters everywhere except at cells adjacent to the boundary;\n        # barycenters there.\n        cc = mesh.cell_circumcenters\n        bc = mesh.cell_barycenters\n        # Find all cells with a boundary edge\n        boundary_cell_ids = mesh.edges_cells[1][:, 0]\n        cc[boundary_cell_ids] = bc[boundary_cell_ids]\n        return get_new_points_volume_averaged(mesh, cc)\n\n    mesh = MeshTri(points, cells)\n    runner(get_new_points, mesh, *args, **kwargs)\n    return mesh.node_coords, mesh.cells[\"nodes\"]", "response": "This function moves interior mesh points into the weighted averages of the circumcenters\n    of their adjacent cells."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fixed_point_density_preserving(points, cells, *args, **kwargs):\n\n    def get_new_points(mesh):\n        # Get circumcenters everywhere except at cells adjacent to the boundary;\n        # barycenters there.\n        cc = mesh.cell_circumcenters\n        bc = mesh.cell_barycenters\n        # Find all cells with a boundary edge\n        boundary_cell_ids = mesh.edges_cells[1][:, 0]\n        cc[boundary_cell_ids] = bc[boundary_cell_ids]\n        return get_new_points_count_averaged(mesh, cc)\n\n    mesh = MeshTri(points, cells)\n    runner(get_new_points, mesh, *args, **kwargs)\n    return mesh.node_coords, mesh.cells[\"nodes\"]", "response": "This function takes a set of points and cells and returns the node coordinates and the number of barycenters that are used to calculate the weighted averages of the circumcenters."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new layer manager and append it to the end of the existing layer manager.", "response": "def create_append(filename: str, layers: Union[np.ndarray, Dict[str, np.ndarray], loompy.LayerManager], row_attrs: Dict[str, np.ndarray], col_attrs: Dict[str, np.ndarray], *, file_attrs: Dict[str, str] = None, fill_values: Dict[str, np.ndarray] = None) -> None:\n\t\"\"\"\n\t**DEPRECATED** - Use `new` instead; see https://github.com/linnarsson-lab/loompy/issues/42\n\t\"\"\"\n\tdeprecated(\"'create_append' is deprecated. See https://github.com/linnarsson-lab/loompy/issues/42\")\n\tif os.path.exists(filename):\n\t\twith connect(filename) as ds:\n\t\t\tds.add_columns(layers, col_attrs, fill_values=fill_values)\n\telse:\n\t\tcreate(filename, layers, row_attrs, col_attrs, file_attrs=file_attrs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef new(filename: str, *, file_attrs: Optional[Dict[str, str]] = None) -> LoomConnection:\n\tif filename.startswith(\"~/\"):\n\t\tfilename = os.path.expanduser(filename)\n\tif file_attrs is None:\n\t\tfile_attrs = {}\n\n\t# Create the file (empty).\n\t# Yes, this might cause an exception, which we prefer to send to the caller\n\tf = h5py.File(name=filename, mode='w')\n\tf.create_group('/layers')\n\tf.create_group('/row_attrs')\n\tf.create_group('/col_attrs')\n\tf.create_group('/row_graphs')\n\tf.create_group('/col_graphs')\n\tf.flush()\n\tf.close()\n\n\tds = connect(filename, validate=False)\n\tfor vals in file_attrs:\n\t\tds.attrs[vals] = file_attrs[vals]\n\t# store creation date\n\tcurrentTime = time.localtime(time.time())\n\tds.attrs['CreationDate'] = timestamp()\n\tds.attrs[\"LOOM_SPEC_VERSION\"] = loompy.loom_spec_version\n\treturn ds", "response": "Create an empty Loom file and return it as a context manager."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new Loom file from the given data.", "response": "def create(filename: str, layers: Union[np.ndarray, Dict[str, np.ndarray], loompy.LayerManager], row_attrs: Union[loompy.AttributeManager, Dict[str, np.ndarray]], col_attrs: Union[loompy.AttributeManager, Dict[str, np.ndarray]], *, file_attrs: Dict[str, str] = None) -> None:\n\t\"\"\"\n\tCreate a new Loom file from the given data.\n\n\tArgs:\n\t\tfilename (str):         The filename (typically using a ``.loom`` file extension)\n\t\tlayers:\t\t\t\t\tOne of the following:\n\n\t\t\t\t\t\t\t\t* Two-dimensional (N-by-M) numpy ndarray of float values\n\t\t\t\t\t\t\t\t* Sparse matrix (e.g. :class:`scipy.sparse.csr_matrix`)\n\t\t\t\t\t\t\t\t* Dictionary of named layers, each an N-by-M ndarray or sparse matrix\n\t\t\t\t\t\t\t\t* A :class:`.LayerManager`, with each layer an N-by-M ndarray\n\t\trow_attrs (dict):       Row attributes, where keys are attribute names and values\n\t\t\t\t\t\t\t\tare numpy arrays (float or string) of length N\n\t\tcol_attrs (dict):       Column attributes, where keys are attribute names and\n\t\t\t\t\t\t\t\tvalues are numpy arrays (float or string) of length M\n\t\tfile_attrs (dict):      Global attributes, where keys are attribute names and\n\t\t\t\t\t\t\t\tvalues are strings\n\tReturns:\n\t\tNothing\n\n\tRemarks:\n\t\tIf the file exists, it will be overwritten.\n\t\"\"\"\n\n\tif isinstance(row_attrs, loompy.AttributeManager):\n\t\trow_attrs = {k: v[:] for k, v in row_attrs.items()}\n\tif isinstance(col_attrs, loompy.AttributeManager):\n\t\tcol_attrs = {k: v[:] for k, v in col_attrs.items()}\n\n\tif isinstance(layers, np.ndarray) or scipy.sparse.issparse(layers):\n\t\tlayers = {\"\": layers}\n\telif isinstance(layers, loompy.LayerManager):\n\t\tlayers = {k: v[:, :] for k, v in layers.items()}\n\tif \"\" not in layers:\n\t\traise ValueError(\"Data for default layer must be provided\")\n\n\t# Sanity checks\n\tshape = layers[\"\"].shape  # type: ignore\n\tif shape[0] == 0 or shape[1] == 0:\n\t\traise ValueError(\"Main matrix cannot be empty\")\n\tfor name, layer in layers.items():\n\t\tif layer.shape != shape:  # type: ignore\n\t\t\traise ValueError(f\"Layer '{name}' is not the same shape as the main matrix\")\n\tfor name, ra in row_attrs.items():\n\t\tif ra.shape[0] != shape[0]:\n\t\t\traise ValueError(f\"Row attribute '{name}' is not the same length ({ra.shape[0]}) as number of rows in main matrix ({shape[0]})\")\n\tfor name, ca in col_attrs.items():\n\t\tif ca.shape[0] != shape[1]:\n\t\t\traise ValueError(f\"Column attribute '{name}' is not the same length ({ca.shape[0]}) as number of columns in main matrix ({shape[1]})\")\n\n\ttry:\n\t\twith new(filename, file_attrs=file_attrs) as ds:\n\t\t\tfor key, vals in layers.items():\n\t\t\t\tds.layer[key] = vals\n\n\t\t\tfor key, vals in row_attrs.items():\n\t\t\t\tds.ra[key] = vals\n\n\t\t\tfor key, vals in col_attrs.items():\n\t\t\t\tds.ca[key] = vals\n\n\texcept ValueError as ve:\n\t\t#ds.close(suppress_warning=True) # ds does not exist here\n\t\tif os.path.exists(filename):\n\t\t\tos.remove(filename)\n\t\traise ve"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a. loom file from 10X Genomics cellranger output", "response": "def create_from_cellranger(indir: str, outdir: str = None, genome: str = None) -> str:\n\t\"\"\"\n\tCreate a .loom file from 10X Genomics cellranger output\n\n\tArgs:\n\t\tindir (str):\tpath to the cellranger output folder (the one that contains 'outs')\n\t\toutdir (str):\toutput folder wher the new loom file should be saved (default to indir)\n\t\tgenome (str):\tgenome build to load (e.g. 'mm10'; if None, determine species from outs folder)\n\n\tReturns:\n\t\tpath (str):\t\tFull path to the created loom file.\n\n\tRemarks:\n\t\tThe resulting file will be named ``{sampleID}.loom``, where the sampleID is the one given by cellranger.\n\t\"\"\"\n\tif outdir is None:\n\t\toutdir = indir\n\tsampleid = os.path.split(os.path.abspath(indir))[-1]\n\tmatrix_folder = os.path.join(indir, 'outs', 'filtered_gene_bc_matrices')\n\tif os.path.exists(matrix_folder):\n\t\tif genome is None:\n\t\t\tgenome = [f for f in os.listdir(matrix_folder) if not f.startswith(\".\")][0]\n\t\tmatrix_folder = os.path.join(matrix_folder, genome)\n\t\tmatrix = mmread(os.path.join(matrix_folder, \"matrix.mtx\")).astype(\"float32\").todense()\n\t\tgenelines = open(os.path.join(matrix_folder, \"genes.tsv\"), \"r\").readlines()\n\t\tbclines = open(os.path.join(matrix_folder, \"barcodes.tsv\"), \"r\").readlines()\n\telse: # cellranger V3 file locations\n\t\tif genome is None:\n\t\t\tgenome = \"\" # Genome is not visible from V3 folder\n\t\tmatrix_folder = os.path.join(indir, 'outs', 'filtered_feature_bc_matrix')\n\t\tmatrix = mmread(os.path.join(matrix_folder, \"matrix.mtx.gz\")).astype(\"float32\").todense()\n\t\tgenelines = [ l.decode() for l in gzip.open(os.path.join(matrix_folder, \"features.tsv.gz\"), \"r\").readlines() ]\n\t\tbclines = [ l.decode() for l in gzip.open(os.path.join(matrix_folder, \"barcodes.tsv.gz\"), \"r\").readlines() ]\n\n\taccession = np.array([x.split(\"\\t\")[0] for x in genelines]).astype(\"str\")\n\tgene = np.array([x.split(\"\\t\")[1].strip() for x in genelines]).astype(\"str\")\n\tcellids = np.array([sampleid + \":\" + x.strip() for x in bclines]).astype(\"str\")\n\n\tcol_attrs = {\"CellID\": cellids}\n\trow_attrs = {\"Accession\": accession, \"Gene\": gene}\n\n\ttsne_file = os.path.join(indir, \"outs\", \"analysis\", \"tsne\", \"projection.csv\")\n\t# In cellranger V2 the file moved one level deeper\n\tif not os.path.exists(tsne_file):\n\t\ttsne_file = os.path.join(indir, \"outs\", \"analysis\", \"tsne\", \"2_components\", \"projection.csv\")\n\tif os.path.exists(tsne_file):\n\t\ttsne = np.loadtxt(tsne_file, usecols=(1, 2), delimiter=',', skiprows=1)\n\t\tcol_attrs[\"X\"] = tsne[:, 0].astype('float32')\n\t\tcol_attrs[\"Y\"] = tsne[:, 1].astype('float32')\n\n\tclusters_file = os.path.join(indir, \"outs\", \"analysis\", \"clustering\", \"graphclust\", \"clusters.csv\")\n\tif os.path.exists(clusters_file):\n\t\tlabels = np.loadtxt(clusters_file, usecols=(1, ), delimiter=',', skiprows=1)\n\t\tcol_attrs[\"ClusterID\"] = labels.astype('int') - 1\n\n\tpath = os.path.join(outdir, sampleid + \".loom\")\n\tcreate(path, matrix, row_attrs, col_attrs, file_attrs={\"Genome\": genome})\n\treturn path"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef combine(files: List[str], output_file: str, key: str = None, file_attrs: Dict[str, str] = None, batch_size: int = 1000, convert_attrs: bool = False) -> None:\n\tif file_attrs is None:\n\t\tfile_attrs = {}\n\n\tif len(files) == 0:\n\t\traise ValueError(\"The input file list was empty\")\n\n\tcopyfile(files[0], output_file)\n\n\tds = connect(output_file)\n\tfor a in file_attrs:\n\t\tds.attrs[a] = file_attrs[a]\n\n\tif len(files) >= 2:\n\t\tfor f in files[1:]:\n\t\t\tds.add_loom(f, key, batch_size=batch_size, convert_attrs=convert_attrs)\n\tds.close()", "response": "Combine two or more loom files and save as a new loom file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncombines a list of files and save as a new loom file.", "response": "def combine_faster(files: List[str], output_file: str, file_attrs: Dict[str, str] = None, selections: List[np.ndarray] = None, key: str = None, skip_attrs: List[str] = None) -> None:\n\t\"\"\"\n\tCombine loom files and save as a new loom file\n\n\tArgs:\n\t\tfiles (list of str):    the list of input files (full paths)\n\t\toutput_file (str):      full path of the output loom file\n\t\tfile_attrs (dict):      file attributes (title, description, url, etc.)\n\t\tselections:\t\t\t\tlist of indicator arrays (one per file; or None to include all cells for the file) determining which columns to include from each file, or None to include all cells from all files\n\t\tkey:\t\t\t\t\trow attribute to use as key for ordering the rows, or None to skip ordering\n\t\tskip_attrs:\t\t\t\tlist of column attributes that should not be included in the output\n\n\tReturns:\n\t\tNothing, but creates a new loom file combining the input files.\n\n\t\tNote that the loom files must have exactly the same\n\t\tnumber of rows, in exactly the same order, and must have exactly the same column attributes.\n\t\tValues in layers missing from one or more files will be replaced by zeros\n\n\t\t.. warning::\n\t\t\tThe files will be combined without changing\n\t\t\tthe ordering of rows or columns. Row attributes will be taken from the first file.\n\t\t\tHence, if rows are not in the same order in all files, the result may be meaningless.\n\t\n\tRemarks:\n\t\tThis version assumes that the individual files will fit in memory. If you run out of memory, try the standard combine() method.\n\t\"\"\"\n\tif file_attrs is None:\n\t\tfile_attrs = {}\n\n\tif len(files) == 0:\n\t\traise ValueError(\"The input file list was empty\")\n\n\tif selections is None:\n\t\tselections = [None for _ in files]  # None means take all cells from the file\n\n\tn_cells = 0\n\tn_genes = 0\n\tfor f, s in zip(files, selections):\n\t\twith loompy.connect(f, \"r\") as ds:\n\t\t\tif n_genes == 0:\n\t\t\t\tn_genes = ds.shape[0]\n\t\t\telif n_genes != ds.shape[0]:\n\t\t\t\traise ValueError(f\"All files must have exactly the same number of rows, but {f} had {ds.shape[0]} rows while previous files had {n_genes}\")\n\t\t\tif s is None:\n\t\t\t\tn_cells += ds.shape[1]\n\t\t\telse:\n\t\t\t\tn_cells += s.sum()\n\n\tcol_attrs: Dict[str, np.ndarray] = {}\n\tix = 0\n\twith loompy.new(output_file, file_attrs=file_attrs) as dsout:\n\t\tfor f, s in zip(files, selections):\n\t\t\twith loompy.connect(f, \"r\") as ds:\n\t\t\t\tif key is not None:\n\t\t\t\t\tordering = np.argsort(ds.ra[key])\n\t\t\t\tdsout.shape = (ds.shape[0], n_cells)  # Not really necessary to set this for each file, but no harm either; needed in order to make sure the first layer added will be the right shape\n\t\t\t\tn_selected = s.sum()\n\t\t\t\tfor layer in ds.layers.keys():\n\t\t\t\t\t# Create the layer if it doesn't exist\n\t\t\t\t\tif layer not in dsout.layers:\n\t\t\t\t\t\tdsout[layer] = ds[layer].dtype.name\n\t\t\t\t\t# Make sure the dtype didn't change between files\n\t\t\t\t\tif dsout.layers[layer].dtype != ds[layer].dtype:\n\t\t\t\t\t\traise ValueError(f\"Each layer must be same datatype in all files, but {layer} of type {ds[layer].dtype} in {f} differs from previous files where it was {dsout[layer].dtype}\")\n\n\t\t\t\t\tif key is None:\n\t\t\t\t\t\tdsout[layer][:, ix: ix + n_selected] = ds[layer][:, :][:, s]\n\t\t\t\t\telse:\n\t\t\t\t\t\tdsout[layer][:, ix: ix + n_selected] = ds[layer][:, :][:, s][ordering, :]\n\t\t\t\tfor attr, vals in ds.ca.items():\n\t\t\t\t\tif attr in skip_attrs:\n\t\t\t\t\t\tcontinue\n\t\t\t\t\tif attr in col_attrs:\n\t\t\t\t\t\tif col_attrs[attr].dtype != vals.dtype:\n\t\t\t\t\t\t\traise ValueError(f\"Each column attribute must be same datatype in all files, but {attr} is {vals.dtype} in {f} but was {col_attrs[attr].dtype} in previous files\")\n\t\t\t\t\telse:\n\t\t\t\t\t\tshape = list(vals.shape)\n\t\t\t\t\t\tshape[0] = n_cells\n\t\t\t\t\t\tcol_attrs[attr] = np.zeros(shape, dtype=vals.dtype)\n\t\t\t\t\tcol_attrs[attr][ix: ix + n_selected] = vals[s]\n\t\t\t\tfor attr, vals in ds.ra.items():\n\t\t\t\t\tif attr not in dsout.ra:\n\t\t\t\t\t\tif key is None:\n\t\t\t\t\t\t\tdsout.ra[attr] = vals\n\t\t\t\t\t\telse:\n\t\t\t\t\t\t\tdsout.ra[attr] = vals[ordering]\n\t\t\tix = ix + n_selected\n\t\tfor attr, vals in col_attrs.items():\n\t\t\tdsout.ca[attr] = vals"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef connect(filename: str, mode: str = 'r+', *, validate: bool = True, spec_version: str = \"2.0.1\") -> LoomConnection:\n\treturn LoomConnection(filename, mode, validate=validate, spec_version=spec_version)", "response": "Establish a connection to a. loom file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning an ISO8601 timestamp indicating when the file was last modified.", "response": "def last_modified(self) -> str:\n\t\t\"\"\"\n\t\tReturn an ISO8601 timestamp indicating when the file was last modified\n\n\t\tReturns:\n\t\t\tAn ISO8601 timestamp indicating when the file was last modified\n\n\t\tRemarks:\n\t\t\tIf the file has no timestamp, and mode is 'r+', a new timestamp is created and returned.\n\t\t\tOtherwise, the current time in UTC is returned\n\t\t\"\"\"\n\t\tif \"last_modified\" in self.attrs:\n\t\t\treturn self.attrs[\"last_modified\"]\n\t\telif self.mode == \"r+\":\n\t\t\t# Make sure the file has modification timestamps\n\t\t\tself.attrs[\"last_modified\"] = timestamp()\n\t\t\treturn self.attrs[\"last_modified\"]\n\t\treturn timestamp()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a summary of the parts of the file that changed since the given time", "response": "def get_changes_since(self, timestamp: str) -> Dict[str, List]:\n\t\t\"\"\"\n\t\tGet a summary of the parts of the file that changed since the given time\n\n\t\tArgs:\n\t\t\ttimestamp:\tISO8601 timestamp\n\n\t\tReturn:\n\t\t\tdict:\tDictionary like ``{\"row_graphs\": rg, \"col_graphs\": cg, \"row_attrs\": ra, \"col_attrs\": ca, \"layers\": layers}`` listing the names of objects that were modified since the given time\n\t\t\"\"\"\n\t\trg = []\n\t\tcg = []\n\t\tra = []\n\t\tca = []\n\t\tlayers = []\n\n\t\tif self.last_modified() > timestamp:\n\t\t\tif self.row_graphs.last_modified() > timestamp:\n\t\t\t\tfor name in self.row_graphs.keys():\n\t\t\t\t\tif self.row_graphs.last_modified(name) > timestamp:\n\t\t\t\t\t\trg.append(name)\n\t\t\tif self.col_graphs.last_modified() > timestamp:\n\t\t\t\tfor name in self.col_graphs.keys():\n\t\t\t\t\tif self.col_graphs.last_modified(name) > timestamp:\n\t\t\t\t\t\tcg.append(name)\n\t\t\tif self.ra.last_modified() > timestamp:\n\t\t\t\tfor name in self.ra.keys():\n\t\t\t\t\tif self.ra.last_modified(name) > timestamp:\n\t\t\t\t\t\tra.append(name)\n\t\t\tif self.ca.last_modified() > timestamp:\n\t\t\t\tfor name in self.ca.keys():\n\t\t\t\t\tif self.ca.last_modified(name) > timestamp:\n\t\t\t\t\t\tca.append(name)\n\t\t\tif self.layers.last_modified() > timestamp:\n\t\t\t\tfor name in self.layers.keys():\n\t\t\t\t\tif self.layers.last_modified(name) > timestamp:\n\t\t\t\t\t\tlayers.append(name)\n\t\treturn {\"row_graphs\": rg, \"col_graphs\": cg, \"row_attrs\": ra, \"col_attrs\": ca, \"layers\": layers}"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the main matrix or specified layer as a scipy. sparse. coo_matrix without loading dense matrix in RAM.", "response": "def sparse(self, rows: np.ndarray = None, cols: np.ndarray = None, layer: str = None) -> scipy.sparse.coo_matrix:\n\t\t\"\"\"\n\t\tReturn the main matrix or specified layer as a scipy.sparse.coo_matrix, without loading dense matrix in RAM\n\n\t\tArgs:\n\t\t\trows:\t\tRows to include, or None to include all\n\t\t\tcols:\t\tColumns to include, or None to include all\n\t\t\tlayer:\t\tLayer to return, or None to return the default layer\n\n\t\tReturns:\n\t\t\tSparse matrix (:class:`scipy.sparse.coo_matrix`)\n\t\t\"\"\"\n\t\tif layer is None:\n\t\t\treturn self.layers[\"\"].sparse(rows=rows, cols=cols)\n\t\telse:\n\t\t\treturn self.layers[layer].sparse(rows=rows, cols=cols)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nclose the connection. After this, the connection object becomes invalid. Warns user if called after closing. Args: suppress_warning: Suppresses warning message if True (defaults to false)", "response": "def close(self, suppress_warning: bool = False) -> None:\n\t\t\"\"\"\n\t\tClose the connection. After this, the connection object becomes invalid. Warns user if called after closing.\n\n\t\tArgs:\n\t\t\tsuppress_warning:\t\tSuppresses warning message if True (defaults to false)\n\t\t\"\"\"\n\t\tif self._file is None:\n\t\t\tif not suppress_warning:\n\t\t\t\t# Warn user that they're being paranoid\n\t\t\t\t# and should clean up their code\n\t\t\t\tlogging.warn(\"Connection to %s is already closed\", self.filename)\n\t\telse:\n\t\t\tself._file.close()\n\t\t\tself._file = None\n\t\tself.layers = None  # type: ignore\n\t\tself.ra = None  # type: ignore\n\t\tself.row_attrs = None  # type: ignore\n\t\tself.ca = None  # type: ignore\n\t\tself.col_attrs = None  # type: ignore\n\t\tself.row_graphs = None  # type: ignore\n\t\tself.col_graphs = None  # type: ignore\n\t\tself.shape = (0, 0)\n\t\tself._closed = True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_layer(self, name: str, matrix: np.ndarray, chunks: Tuple[int, int] = (64, 64), chunk_cache: int = 512, dtype: str = \"float32\", compression_opts: int = 2) -> None:\n\t\tdeprecated(\"'set_layer' is deprecated. Use 'ds.layer.Name = matrix' or 'ds.layer['Name'] = matrix' instead\")\n\t\tself.layers[name] = matrix", "response": "Set a new layer."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_columns(self, layers: Union[np.ndarray, Dict[str, np.ndarray], loompy.LayerManager], col_attrs: Dict[str, np.ndarray], *, row_attrs: Dict[str, np.ndarray] = None, fill_values: Dict[str, np.ndarray] = None) -> None:\n\t\tif self._file.mode != \"r+\":\n\t\t\traise IOError(\"Cannot add columns when connected in read-only mode\")\n\n\t\t# If this is an empty loom file, just assign the provided row and column attributes, and set the shape\n\t\tis_new = self.shape == (0, 0)\n\t\tif is_new:\n\t\t\tif row_attrs is None:\n\t\t\t\traise ValueError(\"row_attrs must be provided when adding to an empty (new) Loom file\")\n\t\t\tfor k, v in row_attrs.items():\n\t\t\t\tself.ra[k] = v\n\t\t\t\tself.shape = (self.ra[k].shape[0], self.shape[1])\n\t\t\tif len(self.ca) == 0:\n\t\t\t\tfor k, v in col_attrs.items():\n\t\t\t\t\tself.ca[k] = np.zeros(0, v.dtype)\n\n\t\tlayers_dict: Dict[str, np.ndarray] = {}\n\t\tif isinstance(layers, np.ndarray):\n\t\t\tlayers_dict = {\"\": layers}\n\t\telif isinstance(layers, loompy.LayerManager):\n\t\t\tlayers_dict = {k: v[:, :] for k, v in layers.items()}\n\t\telif isinstance(layers, dict):\n\t\t\tlayers_dict = layers\n\t\telse:\n\t\t\traise ValueError(\"Invalid type for layers argument\")\n\t\tn_cols = 0\n\t\tfor layer, matrix in layers_dict.items():\n\t\t\tif not is_new and layer not in self.layers.keys():\n\t\t\t\traise ValueError(f\"Layer {layer} does not exist in the target loom file\")\n\t\t\tif matrix.shape[0] != self.shape[0]:\n\t\t\t\traise ValueError(f\"Layer {layer} has {matrix.shape[0]} rows but file has {self.shape[0]}\")\n\t\t\tif n_cols == 0:\n\t\t\t\tn_cols = matrix.shape[1]\n\t\t\telif matrix.shape[1] != n_cols:\n\t\t\t\traise ValueError(f\"Layer {layer} has {matrix.shape[1]} columns but the first layer had {n_cols}\")\n\n\t\tdid_remove = False\n\t\ttodel = []  # type: List[str]\n\t\tfor key, vals in col_attrs.items():\n\t\t\tif key not in self.col_attrs:\n\t\t\t\tif fill_values is not None:\n\t\t\t\t\tif fill_values == \"auto\":\n\t\t\t\t\t\tfill_with = np.zeros(1, dtype=col_attrs[key].dtype)[0]\n\t\t\t\t\telse:\n\t\t\t\t\t\tfill_with = fill_values[key]\n\t\t\t\t\tself.ca[key] = np.array([fill_with] * self.shape[1])\n\t\t\t\telse:\n\t\t\t\t\tdid_remove = True\n\t\t\t\t\ttodel.append(key)\n\t\t\tif len(vals) != n_cols:\n\t\t\t\traise ValueError(f\"Each column attribute must have exactly {n_cols} values, but {key} had {len(vals)}\")\n\t\tfor key in todel:\n\t\t\tdel col_attrs[key]\n\t\tif did_remove:\n\t\t\tlogging.debug(\"Some column attributes were removed: \" + \",\".join(todel))\n\n\t\ttodel = []\n\t\tdid_remove = False\n\t\tfor key in self.col_attrs.keys():\n\t\t\tif key not in col_attrs:\n\t\t\t\tif fill_values is not None:\n\t\t\t\t\tif fill_values == \"auto\":\n\t\t\t\t\t\tfill_with = np.zeros(1, dtype=self.col_attrs[key].dtype)[0]\n\t\t\t\t\telse:\n\t\t\t\t\t\tfill_with = fill_values[key]\n\t\t\t\t\tcol_attrs[key] = np.array([fill_with] * n_cols)\n\t\t\t\telse:\n\t\t\t\t\tdid_remove = True\n\t\t\t\t\ttodel.append(key)\n\t\tfor key in todel:\n\t\t\tdel self.ca[key]  # delete_attr(key, axis=1)\n\t\tif did_remove:\n\t\t\tlogging.debug(\"Some column attributes were removed: \" + \",\".join(todel))\n\n\t\tif is_new:\n\t\t\tfor k, v in layers_dict.items():\n\t\t\t\tself.layers[k] = v\n\t\t\tfor k, v in col_attrs.items():\n\t\t\t\tself.ca[k] = v\n\t\telse:\n\t\t\tn_cols = n_cols + self.shape[1]\n\t\t\told_n_cols = self.shape[1]\n\t\t\t# Must set new shape here, otherwise the attribute manager will complain\n\t\t\tself.shape = (self.shape[0], n_cols)\n\t\t\ttodel = []\n\t\t\tfor key, vals in col_attrs.items():\n\t\t\t\tif vals.shape[1:] != self.col_attrs[key].shape[1:]:\n\t\t\t\t\tlogging.debug(f\"Removing attribute {key} because shape {vals.shape} did not match existing shape {self.col_attrs[key].shape} beyond first dimension\")\n\t\t\t\t\ttodel.append(key)\n\t\t\t\telse:\n\t\t\t\t\tself.ca[key] = np.concatenate([self.ca[key], vals])\n\t\t\tfor key in todel:\n\t\t\t\tdel self.ca[key]\n\n\t\t\t# Add the columns layerwise\n\t\t\tfor key in self.layers.keys():\n\t\t\t\tself.layers[key]._resize(n_cols, axis=1)\n\t\t\t\tself.layers[key][:, old_n_cols:n_cols] = layers_dict[key]\n\t\tself._file.flush()", "response": "This function adds columns of data and attribute values to the dataset."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds the content of a loom file to the current loom file.", "response": "def add_loom(self, other_file: str, key: str = None, fill_values: Dict[str, np.ndarray] = None, batch_size: int = 1000, convert_attrs: bool = False, include_graphs: bool = False) -> None:\n\t\t\"\"\"\n\t\tAdd the content of another loom file\n\n\t\tArgs:\n\t\t\tother_file:       filename of the loom file to append\n\t\t\tkey:                    Primary key to use to align rows in the other file with this file\n\t\t\tfill_values:     default values to use for missing attributes (or None to drop missing attrs, or 'auto' to fill with sensible defaults)\n\t\t\tbatch_size:       the batch size used by batchscan (limits the number of rows/columns read in memory)\n\t\t\tconvert_attrs:   convert file attributes that differ between files into column attributes\n\t\t\tinclude_graphs:  if true, include all the column graphs from other_file that are also present in this file\n\n\t\tReturns:\n\t\t\tNothing, but adds the loom file. Note that the other loom file must have exactly the same\n\t\t\tnumber of rows, and must have exactly the same column attributes.\n\t\t\tAdds all the contents including layers but ignores layers in `other_file` that are not already present in self\n\t\t\tNote that graphs are normally not added, unless include_graphs == True, in which case column graphs are added\n\t\t\"\"\"\n\t\tif self._file.mode != \"r+\":\n\t\t\traise IOError(\"Cannot add data when connected in read-only mode\")\n\t\t# Connect to the loom files\n\t\twith loompy.connect(other_file) as other:\n\t\t\t# Verify that the row keys can be aligned\n\t\t\tordering = None\n\t\t\tif key is not None:\n\t\t\t\t# This was original Sten's version but it creates a 400M entries array in memory\n\t\t\t\t# ordering = np.where(other.row_attrs[key][None, :] == self.row_attrs[key][:, None])[1]\n\n\t\t\t\tdef ixs_thatsort_a2b(a: np.ndarray, b: np.ndarray, check_content: bool = True) -> np.ndarray:\n\t\t\t\t\t\"This is super duper magic sauce to make the order of one list to be like another\"\n\t\t\t\t\tif check_content:\n\t\t\t\t\t\tassert len(np.intersect1d(a, b)) == len(a), \"The two arrays are not matching\"\n\t\t\t\t\treturn np.argsort(a)[np.argsort(np.argsort(b))]\n\n\t\t\t\tordering = ixs_thatsort_a2b(a=other.row_attrs[key], b=self.row_attrs[key])\n\t\t\t\tpk1 = sorted(other.row_attrs[key])\n\t\t\t\tpk2 = sorted(self.row_attrs[key])\n\t\t\t\tfor ix, val in enumerate(pk1):\n\t\t\t\t\tif pk2[ix] != val:\n\t\t\t\t\t\traise ValueError(\"Primary keys are not 1-to-1 alignable!\")\n\t\t\tdiff_layers = set(self.layers.keys()) - set(other.layers.keys())\n\t\t\tif len(diff_layers) > 0:\n\t\t\t\traise ValueError(\"%s is missing a layer, cannot merge with current file. layers missing:%s\" % (other_file, diff_layers))\n\n\t\t\tif convert_attrs:\n\t\t\t\t# Prepare to replace any global attribute that differ between looms or is missing in either loom with a column attribute.\n\t\t\t\tglobalkeys = set(self.attrs)\n\t\t\t\tglobalkeys.update(other.attrs)\n\t\t\t\tfor globalkey in globalkeys:\n\t\t\t\t\tif globalkey in self.attrs and globalkey in other.attrs and self.attrs[globalkey] == other.attrs[globalkey]:\n\t\t\t\t\t\tcontinue\n\t\t\t\t\tif globalkey not in self.col_attrs:\n\t\t\t\t\t\tself_value = self.attrs[globalkey] if globalkey in self.attrs else np.zeros(1, dtype=other.attrs[globalkey].dtype)[0]\n\t\t\t\t\t\tself.col_attrs[globalkey] = np.array([self_value] * self.shape[1])\n\t\t\t\t\tif globalkey not in other.col_attrs:\n\t\t\t\t\t\tother_value = other.attrs[globalkey] if globalkey in other.attrs else np.zeros(1, dtype=self.attrs[globalkey].dtype)[0]\n\t\t\t\t\t\tother.col_attrs[globalkey] = np.array([other_value] * other.shape[1])\n\t\t\t\t\tif globalkey in self.attrs:\n\t\t\t\t\t\tdelattr(self.attrs, globalkey)\n\n\t\t\tfor (ix, selection, vals) in other.batch_scan_layers(axis=1, layers=self.layers.keys(), batch_size=batch_size):\n\t\t\t\tca = {key: v[selection] for key, v in other.col_attrs.items()}\n\t\t\t\tif ordering is not None:\n\t\t\t\t\tvals = {key: val[ordering, :] for key, val in vals.items()}\n\t\t\t\tself.add_columns(vals, ca, fill_values=fill_values)\n\t\t\t\n\t\t\tif include_graphs:\n\t\t\t\tfor gname in self.col_graphs.keys():\n\t\t\t\t\tif gname in other.col_graphs:\n\t\t\t\t\t\tg1 = self.col_graphs[gname]\n\t\t\t\t\t\tg2 = other.col_graphs[gname]\n\t\t\t\t\t\tn = self.shape[1]\n\t\t\t\t\t\tm = other.shape[1]\n\t\t\t\t\t\tg3 = scipy.sparse.coo_matrix((np.concatenate([g1.data, g2.data]), (np.concatenate([g1.row, g2.row + n]), np.concatenate([g1.col, g2.col + n]))), shape=(n + m, n + m))\n\t\t\t\t\t\tself.col_graphs[gname] = g3"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete an attribute from the dataset.", "response": "def delete_attr(self, name: str, axis: int = 0) -> None:\n\t\t\"\"\"\n\t\t**DEPRECATED** - Use `del ds.ra.key` or `del ds.ca.key` instead, where `key` is replaced with the attribute name\n\t\t\"\"\"\n\t\tdeprecated(\"'delete_attr' is deprecated. Use 'del ds.ra.key' or 'del ds.ca.key' instead\")\n\t\tif axis == 0:\n\t\t\tdel self.ra[name]\n\t\telse:\n\t\t\tdel self.ca[name]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the value of an attribute in the dataset.", "response": "def set_attr(self, name: str, values: np.ndarray, axis: int = 0, dtype: str = None) -> None:\n\t\t\"\"\"\n\t\t**DEPRECATED** - Use `ds.ra.key = values` or `ds.ca.key = values` instead\n\t\t\"\"\"\n\t\tdeprecated(\"'set_attr' is deprecated. Use 'ds.ra.key = values' or 'ds.ca.key = values' instead\")\n\t\tif axis == 0:\n\t\t\tself.ra[name] = values\n\t\telse:\n\t\t\tself.ca[name] = values"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_edges(self, *, axis: int) -> List[str]:\n\t\tdeprecated(\"'list_edges' is deprecated. Use 'ds.row_graphs.keys()' or 'ds.col_graphs.keys()' instead\")\n\t\tif axis == 0:\n\t\t\treturn self.row_graphs.keys()\n\t\telif axis == 1:\n\t\t\treturn self.col_graphs.keys()\n\t\telse:\n\t\t\treturn []", "response": "Return a list of edges in the given axis."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_edges(self, name: str, *, axis: int) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n\t\tdeprecated(\"'get_edges' is deprecated. Use 'ds.row_graphs[name]' or 'ds.col_graphs[name]' instead\")\n\t\tif axis == 0:\n\t\t\tg = self.row_graphs[name]\n\t\t\treturn (g.row, g.col, g.data)\n\t\tif axis == 1:\n\t\t\tg = self.col_graphs[name]\n\t\t\treturn (g.row, g.col, g.data)\n\t\traise ValueError(\"Axis must be 0 or 1\")", "response": "Get the edges of a graph along a given axis."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the edges of a graph.", "response": "def set_edges(self, name: str, a: np.ndarray, b: np.ndarray, w: np.ndarray, *, axis: int) -> None:\n\t\t\"\"\"\n\t\t**DEPRECATED** - Use `ds.row_graphs[name] = g` or `ds.col_graphs[name] = g` instead\n\t\t\"\"\"\n\t\tdeprecated(\"'set_edges' is deprecated. Use 'ds.row_graphs[name] = g' or 'ds.col_graphs[name] = g' instead\")\n\t\ttry:\n\t\t\tg = scipy.sparse.coo_matrix((w, (a, b)), (self.shape[axis], self.shape[axis]))\n\t\texcept Exception:\n\t\t\traise ValueError(\"Input arrays could not be converted to a sparse matrix\")\n\t\tif axis == 0:\n\t\t\tself.row_graphs[name] = g\n\t\telif axis == 1:\n\t\t\tself.col_graphs[name] = g\n\t\telse:\n\t\t\traise ValueError(\"axis must be 0 (rows) or 1 (columns)\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef scan(self, *, items: np.ndarray = None, axis: int = None, layers: Iterable = None, key: str = None, batch_size: int = 8 * 64) -> Iterable[Tuple[int, np.ndarray, loompy.LoomView]]:\n\t\tif axis is None:\n\t\t\traise ValueError(\"Axis must be given (0 = rows, 1 = cols)\")\n\t\tif layers is None:\n\t\t\tlayers = self.layers.keys()\n\t\tif layers == \"\":\n\t\t\tlayers = [\"\"]\n\n\t\tif (items is not None) and (np.issubdtype(items.dtype, np.bool_)):\n\t\t\titems = np.where(items)[0]\n\n\t\tordering: Union[np.ndarray, slice] = None\n\t\tvals: Dict[str, loompy.MemoryLoomLayer] = {}\n\t\tif axis == 1:\n\t\t\tif key is not None:\n\t\t\t\tordering = np.argsort(self.ra[key])\n\t\t\telse:\n\t\t\t\t# keep everything in original order\n\t\t\t\tordering = slice(None)\n\t\t\tif items is None:\n\t\t\t\titems = np.fromiter(range(self.shape[1]), dtype='int')\n\t\t\tcols_per_chunk = batch_size\n\t\t\tix = 0\n\t\t\twhile ix < self.shape[1]:\n\t\t\t\tcols_per_chunk = min(self.shape[1] - ix, cols_per_chunk)\n\t\t\t\tselection = items - ix\n\t\t\t\t# Pick out the cells that are in this batch\n\t\t\t\tselection = selection[np.where(np.logical_and(selection >= 0, selection < cols_per_chunk))[0]]\n\t\t\t\tif selection.shape[0] == 0:\n\t\t\t\t\tix += cols_per_chunk\n\t\t\t\t\tcontinue\n\n\t\t\t\t# Load the whole chunk from the file, then extract genes and cells using fancy indexing\n\t\t\t\tfor layer in layers:\n\t\t\t\t\ttemp = self.layers[layer][:, ix:ix + cols_per_chunk]\n\t\t\t\t\ttemp = temp[ordering, :]\n\t\t\t\t\ttemp = temp[:, selection]\n\t\t\t\t\tvals[layer] = loompy.MemoryLoomLayer(layer, temp)\n\t\t\t\tlm = loompy.LayerManager(None)\n\t\t\t\tfor key, layer in vals.items():\n\t\t\t\t\tlm[key] = loompy.MemoryLoomLayer(key, layer)\n\t\t\t\tview = loompy.LoomView(lm, self.ra[ordering], self.ca[ix + selection], self.row_graphs[ordering], self.col_graphs[ix + selection], filename=self.filename, file_attrs=self.attrs)\n\t\t\t\tyield (ix, ix + selection, view)\n\t\t\t\tix += cols_per_chunk\n\t\telif axis == 0:\n\t\t\tif key is not None:\n\t\t\t\tordering = np.argsort(self.ca[key])\n\t\t\telse:\n\t\t\t\t# keep everything in original order\n\t\t\t\tordering = slice(None)\n\t\t\tif items is None:\n\t\t\t\titems = np.fromiter(range(self.shape[0]), dtype='int')\n\t\t\trows_per_chunk = batch_size\n\t\t\tix = 0\n\t\t\twhile ix < self.shape[0]:\n\t\t\t\trows_per_chunk = min(self.shape[0] - ix, rows_per_chunk)\n\t\t\t\tselection = items - ix\n\t\t\t\t# Pick out the genes that are in this batch\n\t\t\t\tselection = selection[np.where(np.logical_and(selection >= 0, selection < rows_per_chunk))[0]]\n\t\t\t\tif selection.shape[0] == 0:\n\t\t\t\t\tix += rows_per_chunk\n\t\t\t\t\tcontinue\n\n\t\t\t\t# Load the whole chunk from the file, then extract genes and cells using fancy indexing\n\t\t\t\tfor layer in layers:\n\t\t\t\t\ttemp = self.layers[layer][ix:ix + rows_per_chunk, :]\n\t\t\t\t\ttemp = temp[:, ordering]\n\t\t\t\t\ttemp = temp[selection, :]\n\t\t\t\t\tvals[layer] = loompy.MemoryLoomLayer(layer, temp)\n\t\t\t\tlm = loompy.LayerManager(None)\n\t\t\t\tfor key, layer in vals.items():\n\t\t\t\t\tlm[key] = loompy.MemoryLoomLayer(key, layer)\n\t\t\t\tview = loompy.LoomView(lm, self.ra[ix + selection], self.ca[ordering], self.row_graphs[ix + selection], self.col_graphs[ordering], filename=self.filename, file_attrs=self.attrs)\n\t\t\t\tyield (ix, ix + selection, view)\n\t\t\t\tix += rows_per_chunk\n\t\telse:\n\t\t\traise ValueError(\"axis must be 0 or 1\")", "response": "Scan the data set for a given set of items and return a list of tuples."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef batch_scan(self, cells: np.ndarray = None, genes: np.ndarray = None, axis: int = 0, batch_size: int = 1000, layer: str = None) -> Iterable[Tuple[int, np.ndarray, np.ndarray]]:\n\t\tdeprecated(\"'batch_scan' is deprecated. Use 'scan' instead\")\n\t\tif cells is None:\n\t\t\tcells = np.fromiter(range(self.shape[1]), dtype='int')\n\t\tif genes is None:\n\t\t\tgenes = np.fromiter(range(self.shape[0]), dtype='int')\n\t\tif layer is None:\n\t\t\tlayer = \"\"\n\t\tif axis == 1:\n\t\t\tcols_per_chunk = batch_size\n\t\t\tix = 0\n\t\t\twhile ix < self.shape[1]:\n\t\t\t\tcols_per_chunk = min(self.shape[1] - ix, cols_per_chunk)\n\n\t\t\t\tselection = cells - ix\n\t\t\t\t# Pick out the cells that are in this batch\n\t\t\t\tselection = selection[np.where(np.logical_and(selection >= 0, selection < cols_per_chunk))[0]]\n\t\t\t\tif selection.shape[0] == 0:\n\t\t\t\t\tix += cols_per_chunk\n\t\t\t\t\tcontinue\n\n\t\t\t\t# Load the whole chunk from the file, then extract genes and cells using fancy indexing\n\t\t\t\tvals = self.layers[layer][:, ix:ix + cols_per_chunk]\n\t\t\t\tvals = vals[genes, :]\n\t\t\t\tvals = vals[:, selection]\n\n\t\t\t\tyield (ix, ix + selection, vals)\n\t\t\t\tix += cols_per_chunk\n\n\t\tif axis == 0:\n\t\t\trows_per_chunk = batch_size\n\t\t\tix = 0\n\t\t\twhile ix < self.shape[0]:\n\t\t\t\trows_per_chunk = min(self.shape[0] - ix, rows_per_chunk)\n\n\t\t\t\tselection = genes - ix\n\t\t\t\t# Pick out the genes that are in this batch\n\t\t\t\tselection = selection[np.where(np.logical_and(selection >= 0, selection < rows_per_chunk))[0]]\n\t\t\t\tif selection.shape[0] == 0:\n\t\t\t\t\tix += rows_per_chunk\n\t\t\t\t\tcontinue\n\n\t\t\t\t# Load the whole chunk from the file, then extract genes and cells using fancy indexing\n\t\t\t\tvals = self.layers[layer][ix:ix + rows_per_chunk, :]\n\t\t\t\tvals = vals[selection, :]\n\t\t\t\tvals = vals[:, cells]\n\t\t\t\tyield (ix, ix + selection, vals)\n\t\t\t\tix += rows_per_chunk", "response": "Yields a batch of cells and genes from the file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nyields the batch of cells and genes for each layer in the given batch_size.", "response": "def batch_scan_layers(self, cells: np.ndarray = None, genes: np.ndarray = None, axis: int = 0, batch_size: int = 1000, layers: Iterable = None) -> Iterable[Tuple[int, np.ndarray, Dict]]:\n\t\t\"\"\"\n\t\t**DEPRECATED** - Use `scan` instead\n\t\t\"\"\"\n\t\tdeprecated(\"'batch_scan_layers' is deprecated. Use 'scan' instead\")\n\t\tif cells is None:\n\t\t\tcells = np.fromiter(range(self.shape[1]), dtype='int')\n\t\tif genes is None:\n\t\t\tgenes = np.fromiter(range(self.shape[0]), dtype='int')\n\t\tif layers is None:\n\t\t\tlayers = self.layers.keys()\n\t\tif axis == 1:\n\t\t\tcols_per_chunk = batch_size\n\t\t\tix = 0\n\t\t\twhile ix < self.shape[1]:\n\t\t\t\tcols_per_chunk = min(self.shape[1] - ix, cols_per_chunk)\n\n\t\t\t\tselection = cells - ix\n\t\t\t\t# Pick out the cells that are in this batch\n\t\t\t\tselection = selection[np.where(np.logical_and(selection >= 0, selection < cols_per_chunk))[0]]\n\t\t\t\tif selection.shape[0] == 0:\n\t\t\t\t\tix += cols_per_chunk\n\t\t\t\t\tcontinue\n\n\t\t\t\t# Load the whole chunk from the file, then extract genes and cells using fancy indexing\n\t\t\t\tvals = dict()\n\t\t\t\tfor key in layers:\n\t\t\t\t\tvals[key] = self.layers[key][:, ix:ix + cols_per_chunk]\n\t\t\t\t\tvals[key] = vals[key][genes, :]\n\t\t\t\t\tvals[key] = vals[key][:, selection]\n\n\t\t\t\tyield (ix, ix + selection, vals)\n\t\t\t\tix += cols_per_chunk\n\n\t\tif axis == 0:\n\t\t\trows_per_chunk = batch_size\n\t\t\tix = 0\n\t\t\twhile ix < self.shape[0]:\n\t\t\t\trows_per_chunk = min(self.shape[0] - ix, rows_per_chunk)\n\n\t\t\t\tselection = genes - ix\n\t\t\t\t# Pick out the genes that are in this batch\n\t\t\t\tselection = selection[np.where(np.logical_and(selection >= 0, selection < rows_per_chunk))[0]]\n\t\t\t\tif selection.shape[0] == 0:\n\t\t\t\t\tix += rows_per_chunk\n\t\t\t\t\tcontinue\n\n\t\t\t\t# Load the whole chunk from the file, then extract genes and cells using fancy indexing\n\t\t\t\tvals = dict()\n\t\t\t\tfor key in layers:\n\t\t\t\t\tvals[key] = self.layers[key][ix:ix + rows_per_chunk, :]\n\t\t\t\t\tvals[key] = vals[key][selection, :]\n\t\t\t\t\tvals[key] = vals[key][:, cells]\n\t\t\t\tyield (ix, ix + selection, vals)\n\t\t\t\tix += rows_per_chunk"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\napply a function along an axis without loading the entire dataset in memory. Args: f: Function(s) that takes a numpy ndarray as argument axis: Axis along which to apply the function (0 = rows, 1 = columns) chunksize: Number of rows (columns) to load per chunk selection: Columns (rows) to include Returns: numpy.ndarray result of function application The result is a list of numpy arrays, one per supplied function in f_list. This is more efficient than repeatedly calling map() one function at a time.", "response": "def map(self, f_list: List[Callable[[np.ndarray], int]], *, axis: int = 0, chunksize: int = 1000, selection: np.ndarray = None) -> List[np.ndarray]:\n\t\t\"\"\"\n\t\tApply a function along an axis without loading the entire dataset in memory.\n\n\t\tArgs:\n\t\t\tf:\t\tFunction(s) that takes a numpy ndarray as argument\n\n\t\t\taxis:\t\tAxis along which to apply the function (0 = rows, 1 = columns)\n\n\t\t\tchunksize: Number of rows (columns) to load per chunk\n\n\t\t\tselection: Columns (rows) to include\n\n\t\tReturns:\n\t\t\tnumpy.ndarray result of function application\n\t\t\tThe result is a list of numpy arrays, one per supplied function in f_list.\n\t\t\tThis is more efficient than repeatedly calling map() one function at a time.\n\t\t\"\"\"\n\t\treturn self.layers[\"\"].map(f_list, axis, chunksize, selection)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef permute(self, ordering: np.ndarray, axis: int) -> None:\n\t\tif self._file.__contains__(\"tiles\"):\n\t\t\tdel self._file['tiles']\n\n\t\tordering = list(np.array(ordering).flatten())  # Flatten the ordering, in case we got a column vector\n\t\tself.layers._permute(ordering, axis=axis)\n\t\tif axis == 0:\n\t\t\tself.row_attrs._permute(ordering)\n\t\t\tself.row_graphs._permute(ordering)\n\t\tif axis == 1:\n\t\t\tself.col_attrs._permute(ordering)\n\t\t\tself.col_graphs._permute(ordering)", "response": "Permute the dataset along the specified axis."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pandas(self, row_attr: str = None, selector: Union[List, Tuple, np.ndarray, slice] = None, columns: List[str] = None) -> pd.DataFrame:\n\t\tif columns is None:\n\t\t\tcolumns = [x for x in self.ca.keys()]\n\n\t\tdata: Dict[str, np.ndarray] = {}\n\t\tfor col in columns:\n\t\t\tvals = self.ca[col]\n\t\t\tif vals.ndim >= 2:\n\t\t\t\tfor i in range(vals.ndim):\n\t\t\t\t\tdata[col + f\".{i+1}\"] = vals[:, 0]\n\t\t\telse:\n\t\t\t\tdata[col] = self.ca[col]\n\t\tif row_attr is not None:  # Pick out some rows (genes)\n\t\t\tif selector is None:  # Actually, pick all the rows\n\t\t\t\tnames = self.ra[row_attr]\n\t\t\t\tvals = self[:, :]\n\t\t\t\tfor ix, name in enumerate(names):\n\t\t\t\t\tdata[name] = vals[ix, :][0]\n\t\t\telse:  # Pick some specific rows\n\t\t\t\tif type(selector) is slice:  # Based on a slice\n\t\t\t\t\tnames = self.ra[row_attr][selector]\n\t\t\t\t\tvals = self[selector, :]\n\t\t\t\t\tfor ix, name in enumerate(names):\n\t\t\t\t\t\tdata[name] = vals[ix, :][0]\n\t\t\t\t# Based on specific string values\n\t\t\t\telif all([type(s) is str for s in selector]):  # type: ignore\n\t\t\t\t\tnames = self.ra[row_attr][np.in1d(self.ra[row_attr], selector)]\n\t\t\t\t\tfor name in names:\n\t\t\t\t\t\tvals = self[self.ra[row_attr] == name, :][0]\n\t\t\t\t\t\tdata[name] = vals\n\t\t\t\telse:  # Give up\n\t\t\t\t\traise ValueError(\"Invalid selector\")\n\t\treturn pd.DataFrame(data)", "response": "Create a Pandas DataFrame corresponding to the selected parts of the Loom file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\naggregating the Loom file by applying aggregation functions to the main matrix as well as to the column attributes Args: out_file The name of the output Loom file (will be appended to if it exists) select Bool array giving the columns to include (or None, to include all) group_by The column attribute to group by, or an np.ndarray of integer group labels aggr_by The aggregation function for the main matrix aggr_ca_by A dictionary of aggregation functions for the column attributes (or None to skip) Returns: m Aggregated main matrix Remarks: aggr_by gives the aggregation function for the main matrix aggr_ca_by is a dictionary with column attributes as keys and aggregation functionas as values Aggregation functions can be any valid aggregation function from here: https://github.com/ml31415/numpy-groupies In addition, you can specify: \"tally\" to count the number of occurences of each value of a categorical attribute", "response": "def aggregate(self, out_file: str = None, select: np.ndarray = None, group_by: Union[str, np.ndarray] = \"Clusters\", aggr_by: str = \"mean\", aggr_ca_by: Dict[str, str] = None) -> np.ndarray:\n\t\t\"\"\"\n\t\tAggregate the Loom file by applying aggregation functions to the main matrix as well as to the column attributes\n\n\t\tArgs:\n\t\t\tout_file\tThe name of the output Loom file (will be appended to if it exists)\n\t\t\tselect\t\tBool array giving the columns to include (or None, to include all)\n\t\t\tgroup_by\tThe column attribute to group by, or an np.ndarray of integer group labels\n\t\t\taggr_by \tThe aggregation function for the main matrix\n\t\t\taggr_ca_by\tA dictionary of aggregation functions for the column attributes (or None to skip)\n\n\t\tReturns:\n\t\t\tm\t\t\tAggregated main matrix\n\n\t\tRemarks:\n\t\t\taggr_by gives the aggregation function for the main matrix\n\t\t\taggr_ca_by is a dictionary with column attributes as keys and aggregation functionas as values\n\t\t\t\n\t\t\tAggregation functions can be any valid aggregation function from here: https://github.com/ml31415/numpy-groupies\n\n\t\t\tIn addition, you can specify:\n\t\t\t\t\"tally\" to count the number of occurences of each value of a categorical attribute\n\t\t\n\t\t\"\"\"\n\t\tca = {}  # type: Dict[str, np.ndarray]\n\t\tif select is not None:\n\t\t\traise ValueError(\"The 'select' argument is deprecated\")\n\t\tif isinstance(group_by, np.ndarray):\n\t\t\tlabels = group_by\n\t\telse:\n\t\t\tlabels = (self.ca[group_by]).astype('int')\n\t\t_, zero_strt_sort_noholes_lbls = np.unique(labels, return_inverse=True)\n\t\tn_groups = len(set(labels))\n\t\tif aggr_ca_by is not None:\n\t\t\tfor key in self.ca.keys():\n\t\t\t\tif key not in aggr_ca_by:\n\t\t\t\t\tcontinue\n\t\t\t\tfunc = aggr_ca_by[key]\n\t\t\t\tif func == \"tally\":\n\t\t\t\t\tfor val in set(self.ca[key]):\n\t\t\t\t\t\tif np.issubdtype(type(val), np.str_):\n\t\t\t\t\t\t\tvalnew = val.replace(\"/\", \"-\")  # Slashes are not allowed in attribute names\n\t\t\t\t\t\t\tvalnew = valnew.replace(\".\", \"_\")  # Nor are periods\n\t\t\t\t\t\tca[key + \"_\" + str(valnew)] = npg.aggregate(zero_strt_sort_noholes_lbls, (self.ca[key] == val).astype('int'), func=\"sum\", fill_value=0)\n\t\t\t\telif func == \"mode\":\n\t\t\t\t\tdef mode(x):  # type: ignore\n\t\t\t\t\t\treturn scipy.stats.mode(x)[0][0]\n\t\t\t\t\tca[key] = npg.aggregate(zero_strt_sort_noholes_lbls, self.ca[key], func=mode, fill_value=0).astype('str')\n\t\t\t\telif func == \"mean\":\n\t\t\t\t\tca[key] = npg.aggregate(zero_strt_sort_noholes_lbls, self.ca[key], func=func, fill_value=0)\n\t\t\t\telif func == \"first\":\n\t\t\t\t\tca[key] = npg.aggregate(zero_strt_sort_noholes_lbls, self.ca[key], func=func, fill_value=self.ca[key][0])\n\n\t\tm = np.empty((self.shape[0], n_groups))\n\t\tfor (_, selection, view) in self.scan(axis=0, layers=[\"\"]):\n\t\t\tvals_aggr = npg.aggregate(zero_strt_sort_noholes_lbls, view[:, :], func=aggr_by, axis=1, fill_value=0)\n\t\t\tm[selection, :] = vals_aggr\n\n\t\tif out_file is not None:\n\t\t\tloompy.create(out_file, m, self.ra, ca)\n\n\t\treturn m"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nexports the matrix as tab - delimited file.", "response": "def export(self, out_file: str, layer: str = None, format: str = \"tab\") -> None:\n\t\t\"\"\"\n\t\tExport the specified layer and row/col attributes as tab-delimited file.\n\n\t\tArgs:\n\t\t\tout_file:\tPath to the output file\n\t\t\tlayer:\tName of the layer to export, or None to export the main matrix\n\t\t\tformat: Desired file format (only 'tab' is supported)\n\t\t\"\"\"\n\t\tif format != \"tab\":\n\t\t\traise NotImplementedError(\"Only 'tab' is supported\")\n\n\t\twith open(out_file, \"w\") as f:\n\t\t\t# Emit column attributes\n\t\t\tfor ca in self.col_attrs.keys():\n\t\t\t\tfor ra in self.row_attrs.keys():\n\t\t\t\t\tf.write(\"\\t\")\n\t\t\t\tf.write(ca + \"\\t\")\n\t\t\t\tfor v in self.col_attrs[ca]:\n\t\t\t\t\tf.write(str(v) + \"\\t\")\n\t\t\t\tf.write(\"\\n\")\n\n\t\t\t# Emit row attribute names\n\t\t\tfor ra in self.row_attrs.keys():\n\t\t\t\tf.write(ra + \"\\t\")\n\t\t\tf.write(\"\\t\")\n\t\t\tfor v in range(self.shape[1]):\n\t\t\t\tf.write(\"\\t\")\n\t\t\tf.write(\"\\n\")\n\n\t\t\t# Emit row attr values and matrix values\n\t\t\tfor row in range(self.shape[0]):\n\t\t\t\tfor ra in self.row_attrs.keys():\n\t\t\t\t\tf.write(str(self.row_attrs[ra][row]) + \"\\t\")\n\t\t\t\tf.write(\"\\t\")\n\n\t\t\t\tif layer is None:\n\t\t\t\t\tfor v in self[row, :]:\n\t\t\t\t\t\tf.write(str(v) + \"\\t\")\n\t\t\t\telse:\n\t\t\t\t\tfor v in self.layers[layer][row, :]:\n\t\t\t\t\t\tf.write(str(v) + \"\\t\")\n\t\t\t\tf.write(\"\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, name: str, default: Any = None) -> np.ndarray:\n\t\tif name in self:\n\t\t\treturn self[name]\n\t\telse:\n\t\t\treturn default", "response": "Get the value for a named attribute."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef last_modified(self, name: str = None) -> str:\n\t\tif name is not None:\n\t\t\treturn self[name].last_modified()\n\t\tts = \"\"\n\t\tfor name in self.keys():\n\t\t\tif ts is None:\n\t\t\t\tts = self[name].last_modified()\n\t\t\telse:\n\t\t\t\tif self[name].last_modified() > ts:\n\t\t\t\t\tts = self[name].last_modified()\n\t\treturn ts", "response": "Returns a compact ISO8601 timestamp indicating when the layer was last modified by the given name."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates a colormap suitable for N categorical values.", "response": "def cat_colors(N: int = 1, *, hue: str = None, luminosity: str = None, bgvalue: int = None, loop: bool = False, seed: str = \"cat\") -> Union[List[Any], colors.LinearSegmentedColormap]:\n\t\"\"\"\n\tReturn a colormap suitable for N categorical values, optimized to be both aesthetically pleasing and perceptually distinct.\n\n\tArgs:\n\t\tN\t\t\tThe number of colors requested.\n\t\thue\t\t\tControls the hue of the generated color. You can pass a string representing a color name: \"red\", \"orange\", \"yellow\", \"green\", \"blue\", \"purple\", \"pink\" and \"monochrome\" are currently supported. If you pass a hexidecimal color string such as \"#00FFFF\", its hue value will be used to generate colors.\n\t\tluminosity\tControls the luminosity of the generated color: \"bright\", \"light\" or \"dark\".\n\t\tbgvalue\t\tIf not None, then the corresponding index color will be set to light gray\n\t\tloop\t\tIf True, loop the color alphabet instead of generating random colors\n\t\tseed\t\tIf not None, use as the random seed (default: \"cat\")\n\t\n\tReturns:\n\t\tA set of colors in the requested format, either a list of values or a matplotlib LinearSegmentedColormap (when format=\"cmap\")\n\t\tIf N <= 25 and hue and luminosity are both None, a subset of the optimally perceptually distinct \"color alphabet\" is returned.\n\t\tElse, a pleasing set of random colors is returned.\n\n\t\tColors are designed to be displayed on a white background.\n\t\"\"\"\n\tc: List[str] = []\n\tif N <= 25 and hue is None and luminosity is None:\n\t\tc = _color_alphabet[:N]\n\telif not loop:\n\t\tc = RandomColor(seed=seed).generate(count=N, hue=hue, luminosity=luminosity, format_=\"hex\")\n\telse:\n\t\tn = N\n\t\twhile n > 0:\n\t\t\tc += _color_alphabet[:n]\n\t\t\tn -= 25\n\tif bgvalue is not None:\n\t\tc[bgvalue] = \"#aaaaaa\"\n\treturn colors.LinearSegmentedColormap.from_list(\"\", c, N)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrenumber a by replacing any occurrence of keys by the corresponding values.", "response": "def _renumber(a: np.ndarray, keys: np.ndarray, values: np.ndarray) -> np.ndarray:\n\t\"\"\"\n\tRenumber 'a' by replacing any occurrence of 'keys' by the corresponding 'values'\n\t\"\"\"\n\tordering = np.argsort(keys)\n\tkeys = keys[ordering]\n\tvalues = keys[ordering]\n\tindex = np.digitize(a.ravel(), keys, right=True)\n\treturn(values[index].reshape(a.shape))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nvalidates a file for conformance to the Loom specification.", "response": "def validate(self, path: str, strictness: str = \"speconly\") -> bool:\n\t\t\"\"\"\n\t\tValidate a file for conformance to the Loom specification\n\n\t\tArgs:\n\t\t\tpath: \t\t\tFull path to the file to be validated\n\t\t\tstrictness:\t\t\"speconly\" or \"conventions\"\n\n\t\tRemarks:\n\t\t\tIn \"speconly\" mode, conformance is assessed relative to the file format specification\n\t\t\tat http://linnarssonlab.org/loompy/format/. In \"conventions\" mode, conformance is additionally\n\t\t\tassessed relative to attribute name and data type conventions given at http://linnarssonlab.org/loompy/conventions/.\n\t\t\"\"\"\n\t\tvalid1 = True\n\t\twith h5py.File(path, mode=\"r\") as f:\n\t\t\tvalid1 = self.validate_spec(f)\n\t\t\tif not valid1:\n\t\t\t\tself.errors.append(\"For help, see http://linnarssonlab.org/loompy/format/\")\n\n\t\tvalid2 = True\n\t\tif strictness == \"conventions\":\n\t\t\twith loompy.connect(path, mode=\"r\") as ds:\n\t\t\t\tvalid2 = self.validate_conventions(ds)\n\t\t\t\tif not valid2:\n\t\t\t\t\tself.errors.append(\"For help, see http://linnarssonlab.org/loompy/conventions/\")\n\n\t\treturn valid1 and valid2"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef validate_conventions(self, ds: loompy.LoomConnection) -> bool:\n\t\t(n_genes, n_cells) = ds.shape\n\n\t\tself._warn(\"Description\" in ds.attrs, \"Optional global attribute 'Description' is missing\")\n\t\tself._warn(\"Journal\" in ds.attrs, \"Optional global attribute 'Journal' is missing\")\n\t\tself._warn(\"Authors\" in ds.attrs, \"Optional global attribute 'Authors' is missing\")\n\t\tself._warn(\"Title\" in ds.attrs, \"Optional global attribute 'Title' is missing\")\n\t\tself._warn(\"Year\" in ds.attrs, \"Optional global attribute 'Year' is missing\")\n\t\tself._warn(\"CreationDate\" in ds.attrs, \"Optional global attribute 'CreationDate' is missing\")\n\n\t\tif self._check(\"ClusterID\" in ds.ca, \"Column attribute 'ClusterID' is missing\"):\n\t\t\tself._check(np.issubdtype(ds.ca.ClusterID.dtype, np.int_), \"Column attribute 'ClusterID' must be integer dtype\")\n\t\t\tself._check(len(np.unique(ds.ca.ClusterID)) == np.max(ds.ca.ClusterID) and np.min(ds.ca.ClusterID) == 0, \"Column attribute 'ClusterID' must be integers 0, 1, 2, ... with no missing values\")\n\t\t\tself._check(ds.ca.ClusterID.shape == (n_cells,), f\"Column attribute 'ClusterID' must be 1-dimensional array of {n_cells} elements\")\n\n\t\tif \"ClusterName\" in ds.ca:\n\t\t\tself._check(ds.ca.ClusterName.dtype == object and np.issubdtype(ds.ca.ClusterName[0].dtype, np.str_), \"Column attribute 'ClusterName' must be an array of strings\")\n\t\t\tself._check(ds.ca.ClusterName.shape == (n_cells,), f\"Column attribute 'ClusterName' must be 1-dimensional array of {n_cells} elements\")\n\t\t\tone_to_one = True\n\t\t\tfor cid in np.unique(ds.ca.ClusterID):\n\t\t\t\tif len(np.unique(ds.ca.ClusterName[ds.ca.ClusterID == cid])) != 1:\n\t\t\t\t\tone_to_one = False\n\t\t\t\t\tbreak\n\t\t\tfor cn in np.unique(ds.ca.ClusterName):\n\t\t\t\tif len(np.unique(ds.ca.ClusterID[ds.ca.ClusterName == cn])) != 1:\n\t\t\t\t\tone_to_one = False\n\t\t\t\t\tbreak\n\t\t\tif not one_to_one:\n\t\t\t\tself._check(False, \"ClusterName must correspond 1:1 with ClusterID\")\n\t\telse:\n\t\t\tself.warnings.append(\"Optional column attribute 'ClusterName' is missing\")\n\n\t\tif self._check(\"CellID\" in ds.ca, \"Column attribute 'CellID' is missing\"):\n\t\t\tself._check(ds.ca.CellID.dtype == object and np.issubdtype(ds.ca.CellID[0].dtype, np.str_), f\"Column attribute 'CellID' must be an array of strings, not '{ds.ca.CellID[0].dtype}'\")\n\t\t\tself._check(ds.ca.CellID.shape == (n_cells,), f\"Column attribute 'CellID' must be 1-dimensional array of {n_cells} elements\")\n\t\t\tself._check(len(np.unique(ds.ca.CellID)) == n_cells, \"Column attribute 'CellID' cannot contain duplicate values\")\n\n\t\tif \"Valid\" in ds.ca:\n\t\t\tself._check(np.issubdtype(ds.ca.Valid.dtype, np.int_), f\"Column attribute 'Valid' must be integer dtype, not '{ds.ca.Valid.dtype}'\")\n\t\t\tvalids = np.unique(ds.ca.Valid)\n\t\t\tself._check(np.all(np.isin(ds.ca.Valid, [0, 1])), \"Column attribute 'Valid' must be integers 0 or 1 only\")\n\t\t\tself._check(ds.ca.Valid.shape == (n_cells,), f\"Column attribute 'Valid' must be 1-dimensional array of {n_cells} elements\")\n\t\telse:\n\t\t\tself.warnings.append(\"Optional column attribute 'Valid' is missing\")\n\n\t\tif \"Outliers\" in ds.ca:\n\t\t\tself._check(np.issubdtype(ds.ca.Outliers.dtype, np.int_), f\"Column attribute 'Outliers' must be integer dtype, not '{ds.ca.Outliers.dtype}'\")\n\t\t\tself._check(np.all(np.isin(ds.ca.Outliers, [0, 1])), \"Column attribute 'Outliers' must be integers 0 or 1 only\")\n\t\t\tself._check(ds.ca.Outliers.shape == (n_cells,), f\"Column attribute 'Outliers' must be 1-dimensional array of {n_cells} elements\")\n\t\telse:\n\t\t\tself.warnings.append(\"Optional column attribute 'Outliers' is missing\")\n\n\t\tif self._check(\"Accession\" in ds.ra, \"Row attribute 'Accession' is missing\"):\n\t\t\tself._check(ds.ra.Accession.dtype == object and np.issubdtype(ds.ra.Accession[0].dtype, np.str_), f\"Row attribute 'Accession' must be an array of strings, not '{ds.ra.Accession[0].dtype}'\")\n\t\t\tself._check(ds.ra.Accession.shape == (n_genes,), f\"Row attribute 'Accession' must be 1-dimensional array of {n_genes} elements\")\n\t\t\tself._check(len(np.unique(ds.ra.Accession)) == n_genes, \"Row attribute 'Accession' cannot contain duplicate values\")\n\n\t\tif self._check(\"Gene\" in ds.ra, \"Row attribute 'Gene' is missing\"):\n\t\t\tself._check(ds.ra.Gene.dtype == object and np.issubdtype(ds.ra.Gene[0].dtype, np.str_), f\"Row attribute 'Gene' must be an array of strings, not '{ds.ra.Gene[0].dtype}'\")\n\t\t\tself._check(ds.ra.Gene.shape == (n_genes,), f\"Row attribute 'Gene' must be 1-dimensional array of {n_genes} elements\")\n\n\t\tif \"Valid\" in ds.ra:\n\t\t\tself._check(np.issubdtype(ds.ra.Valid.dtype, np.int_), f\"Row attribute 'Valid' must be integer dtype, not '{ds.ra.Valid.dtype}'\")\n\t\t\tvalids = np.unique(ds.ra.Valid)\n\t\t\tself._check(np.all(np.isin(ds.ra.Valid, [0, 1])), \"Row attribute 'Valid' must be integers 0 or 1 only\")\n\t\t\tself._check(ds.ra.Valid.shape == (n_cells,), f\"Row attribute 'Valid' must be 1-dimensional array of {n_cells} elements\")\n\t\telse:\n\t\t\tself.warnings.append(\"Optional row attribute 'Valid' is missing\")\n\n\t\tif \"Selected\" in ds.ra:\n\t\t\tself._check(np.issubdtype(ds.ra.Selected.dtype, np.int_), f\"Row attribute 'Selected' must be integer dtype, not '{ds.ra.Selected.dtype}'\")\n\t\t\tvalids = np.unique(ds.ra.Selected)\n\t\t\tself._check(np.all(np.isin(ds.ra.Selected, [0, 1])), \"Row attribute 'Selected' must be integers 0 or 1 only\")\n\t\t\tself._check(ds.ra.Selected.shape == (n_cells,), f\"Row attribute 'Selected' must be 1-dimensional array of {n_cells} elements\")\n\t\telse:\n\t\t\tself.warnings.append(\"Optional row attribute 'Selected' is missing\")\n\n\t\treturn len(self.errors) == 0", "response": "Validate the object to see if it conforms to the conventions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nvalidating the LoomConnection object against the format specification.", "response": "def validate_spec(self, file: h5py.File) -> bool:\n\t\t\"\"\"\n\t\tValidate the LoomConnection object against the format specification.\n\n\t\tArgs:\n\t\t\tfile:\t\t\th5py File object\n\t\t\n\t\tReturns:\n\t\t\tTrue if the file conforms to the specs, else False\n\t\t\n\t\tRemarks:\n\t\t\tUpon return, the instance attributes 'self.errors' and 'self.warnings' contain\n\t\t\tlists of errors and warnings, and the 'self.summary' attribute contains a summary\n\t\t\tof the file contents.\n\t\t\"\"\"\n\t\tmatrix_types = [\"float16\", \"float32\", \"float64\", \"int8\", \"int16\", \"int32\", \"int64\", \"uint8\", \"uint16\", \"uint32\", \"uint64\"]\n\t\tvertex_types = [\"int8\", \"int16\", \"int32\", \"int64\", \"uint8\", \"uint16\", \"uint32\", \"uint64\"]\n\t\tweight_types = [\"float16\", \"float32\", \"float64\"]\n\n\t\tdef delay_print(text: str) -> None:\n\t\t\tself.summary.append(text)\n\n\t\tdef dt(t: str) -> str:\n\t\t\tif str(t).startswith(\"|S\"):\n\t\t\t\treturn f\"string\"\n\t\t\treturn str(t)\n\n\t\twidth_ra = 0\n\t\twidth_ca = 0\n\t\twidth_globals = 0\n\t\tif self._check(\"row_attrs\" in file, \"'row_attrs' group is missing\"):\n\t\t\twidth_ra = max([len(x) for x in (file[\"row_attrs\"].keys())], default=0)\n\t\tif self._check(\"col_attrs\" in file, \"'col_attrs' group is missing\"):\n\t\t\twidth_ca = max([len(x) for x in (file[\"col_attrs\"].keys())], default=0)\n\t\tif len(file.attrs) > 0:\n\t\t\twidth_globals = max([len(x) for x in file.attrs.keys()])\n\t\twidth_layers = 0\n\t\tif \"layers\" in file and len(file[\"layers\"]) > 0:\n\t\t\twidth_layers = max([len(x) for x in file[\"layers\"].keys()])\n\t\twidth_layers = max(width_layers, len(\"Main matrix\"))\n\t\twidth = max(width_ca, width_ra, width_globals)\n\n\t\tdelay_print(\"Global attributes:\")\n\t\tfor key, value in file.attrs.items():\n\t\t\tif type(value) is str:\n\t\t\t\tself.warnings.append(f\"Global attribute '{key}' has dtype string, which will be deprecated in future Loom versions\")\n\t\t\t\tdelay_print(f\"{key: >{width}} string\")\n\t\t\telif type(value) is bytes:\n\t\t\t\tself.warnings.append(f\"Global attribute '{key}' has dtype bytes, which will be deprecated in future Loom versions\")\n\t\t\t\tdelay_print(f\"{key: >{width}} bytes\")\n\t\t\telse:\n\t\t\t\tdelay_print(f\"{key: >{width}} {dt(file.attrs[key].dtype)}\")\n\t\t\t\t\n\t\tif self._check(\"matrix\" in file, \"Main matrix missing\"):\n\t\t\tself._check(file[\"matrix\"].dtype in matrix_types, f\"Main matrix dtype={file['matrix'].dtype} is not allowed\")\n\t\t\tshape = file[\"matrix\"].shape\n\t\t\tdelay_print(f\"Layers shape={shape}:\")\n\t\t\tdelay_print(f\"{'Main matrix': >{width}} {file['matrix'].dtype}\")\n\n\t\tif \"layers\" in file:\n\t\t\tfor layer in file[\"layers\"]:\n\t\t\t\tself._check(file[\"layers\"][layer].shape == shape, f\"Layer '{layer}' shape {file['layers'][layer].shape} does not match main matrix shape {shape}\")\n\t\t\t\tself._check(file[\"layers\"][layer].dtype in matrix_types, f\"Layer '{layer}' dtype={file['layers'][layer].dtype} is not allowed\")\n\t\t\t\tdelay_print(f\"{layer: >{width}} {file['layers'][layer].dtype}\")\n\n\t\tdelay_print(\"Row attributes:\")\n\t\tif self._check(\"row_attrs\" in file, \"'row_attrs' group is missing\"):\n\t\t\tfor ra in file[\"row_attrs\"]:\n\t\t\t\tself._check(file[\"row_attrs\"][ra].shape[0] == shape[0], f\"Row attribute '{ra}' shape {file['row_attrs'][ra].shape[0]} first dimension does not match row dimension {shape}\")\n\t\t\t\tself._check(file[\"row_attrs\"][ra].dtype in matrix_types or np.issubdtype(file['row_attrs'][ra].dtype, np.string_), f\"Row attribute '{ra}' dtype {file['row_attrs'][ra].dtype} is not allowed\")\n\t\t\t\tra_shape = file['row_attrs'][ra].shape\n\t\t\t\tdelay_print(f\"{ra: >{width}} {dt(file['row_attrs'][ra].dtype)} {ra_shape if len(ra_shape) > 1 else ''}\")\n\t\t\tif len(file[\"row_attrs\"]) == 0:\n\t\t\t\tdelay_print(\"    (none)\")\n\n\t\tdelay_print(\"Column attributes:\")\n\t\tif self._check(\"col_attrs\" in file, \"'col_attrs' group is missing\"):\n\t\t\tfor ca in file[\"col_attrs\"]:\n\t\t\t\tself._check(file[\"col_attrs\"][ca].shape[0] == shape[1], f\"Column attribute '{ca}' shape {file['col_attrs'][ca].shape[0]} first dimension does not match column dimension {shape}\")\n\t\t\t\tself._check(file[\"col_attrs\"][ca].dtype in matrix_types or np.issubdtype(file[\"col_attrs\"][ca].dtype, np.string_), f\"Column attribute '{ca}' dtype {file['col_attrs'][ca].dtype} is not allowed\")\n\t\t\t\tca_shape = file['col_attrs'][ca].shape\n\t\t\t\tdelay_print(f\"{ca: >{width}} {dt(file['col_attrs'][ca].dtype)} {ca_shape if len(ca_shape) > 1 else ''}\")\n\t\t\tif len(file[\"col_attrs\"]) == 0:\n\t\t\t\tdelay_print(\"    (none)\")\n\n\t\tdelay_print(\"Row graphs:\")\n\t\tif \"row_graphs\" in file:\n\t\t\tif self.version == \"2.0.1\":\n\t\t\t\tself._check(\"row_graphs\" in file, \"'row_graphs' group is missing (try spec_version='old')\")\n\t\t\tfor g in file[\"row_graphs\"]:\n\t\t\t\tself._check(\"a\" in file[\"row_graphs\"][g], f\"Row graph '{g}' is missing vector 'a', denoting start vertices\")\n\t\t\t\tself._check(file[\"row_graphs\"][g]['a'].dtype in vertex_types, f\"/row_graphs/{g}/a.dtype {file['row_graphs'][g]['a'].dtype} must be integer\")\n\t\t\t\tself._check(\"b\" in file[\"row_graphs\"][g], f\"Row graph '{g}' is missing vector 'b', denoting end vertices\")\n\t\t\t\tself._check(file[\"row_graphs\"][g]['b'].dtype in vertex_types, f\"/row_graphs/{g}/b.dtype {file['row_graphs'][g]['b'].dtype} must be integer\")\n\t\t\t\tself._check(\"w\" in file[\"row_graphs\"][g], f\"Row graph '{g}' is missing vector 'w', denoting vertex weights\")\n\t\t\t\tself._check(file[\"row_graphs\"][g]['w'].dtype in weight_types, f\"/row_graphs/{g}/w.dtype {file['row_graphs'][g]['w'].dtype} must be float\")\n\t\t\t\tself._check(file['row_graphs'][g]['a'].shape[0] == file['row_graphs'][g]['b'].shape[0] and file['row_graphs'][g]['a'].shape[0] == file['row_graphs'][g]['w'].shape[0], f\"Row graph '{g}' sparse vectors a, b and w must have equal length\")\n\t\t\t\tdelay_print(f\"    '{g}' with {file['row_graphs'][g]['a'].shape[0]} edges\")\n\t\t\tif len(file[\"row_graphs\"]) == 0:\n\t\t\t\tdelay_print(\"    (none)\")\n\n\t\tdelay_print(\"Column graphs:\")\n\t\tif \"col_graphs\" in file:\n\t\t\tif self.version == \"2.0.1\":\n\t\t\t\tself._check(\"col_graphs\" in file, \"'col_graphs' group is missing (try spec_version='old')\")\n\t\t\tfor g in file[\"col_graphs\"]:\n\t\t\t\tself._check(\"a\" in file[\"col_graphs\"][g], f\"Column graph '{g}' is missing vector 'a', denoting start vertices\")\n\t\t\t\tself._check(file[\"col_graphs\"][g]['a'].dtype in vertex_types, f\"/col_graphs/{g}/a.dtype {file['col_graphs'][g]['a'].dtype} must be integer\")\n\t\t\t\tself._check(\"b\" in file[\"col_graphs\"][g], f\"Column graph '{g}' is missing vector 'b', denoting end vertices\")\n\t\t\t\tself._check(file[\"col_graphs\"][g]['b'].dtype in vertex_types, f\"/col_graphs/{g}/b.dtype {file['col_graphs'][g]['b'].dtype} must be integer\")\n\t\t\t\tself._check(\"w\" in file[\"col_graphs\"][g], f\"Column graph '{g}' is missing vector 'w', denoting vertex weights\")\n\t\t\t\tself._check(file[\"col_graphs\"][g]['w'].dtype in weight_types, f\"/col_graphs/{g}/w.dtype {file['col_graphs'][g]['w'].dtype} must be float\")\n\t\t\t\tself._check(file['col_graphs'][g]['a'].shape[0] == file['col_graphs'][g]['b'].shape[0] and file['col_graphs'][g]['a'].shape[0] == file['col_graphs'][g]['w'].shape[0], f\"Column graph '{g}' sparse vectors a, b and w must have equal length\")\n\t\t\t\tdelay_print(f\"    '{g}' with {file['col_graphs'][g]['a'].shape[0]} edges\")\n\t\t\tif len(file[\"col_graphs\"]) == 0:\n\t\t\t\tdelay_print(\"    (none)\")\n\n\t\treturn len(self.errors) == 0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a compact ISO8601 timestamp indicating when an attribute was last modified.", "response": "def last_modified(self, name: str = None) -> str:\n\t\t\"\"\"\n\t\tReturn a compact ISO8601 timestamp (UTC timezone) indicating when an attribute was last modified\n\n\t\tNote: if no attribute name is given (the default), the modification time of the most recently modified attribute will be returned\n\t\tNote: if the attributes do not contain a timestamp, and the mode is 'r+', a new timestamp is created and returned.\n\t\tOtherwise, the current time in UTC will be returned.\n\t\t\"\"\"\n\t\ta = [\"/row_attrs/\", \"/col_attrs/\"][self.axis]\n\n\t\tif self.ds is not None:\n\t\t\tif name is None:\n\t\t\t\tif \"last_modified\" in self.ds._file[a].attrs:\n\t\t\t\t\treturn self.ds._file[a].attrs[\"last_modified\"]\n\t\t\t\telif self.ds._file.mode == 'r+':\n\t\t\t\t\tself.ds._file[a].attrs[\"last_modified\"] = timestamp()\n\t\t\t\t\tself.ds._file.flush()\n\t\t\t\t\treturn self.ds._file[a].attrs[\"last_modified\"]\n\t\t\tif name is not None:\n\t\t\t\tif \"last_modified\" in self.ds._file[a + name].attrs:\n\t\t\t\t\treturn self.ds._file[a + name].attrs[\"last_modified\"]\n\t\t\t\telif self.ds._file.mode == 'r+':\n\t\t\t\t\tself.ds._file[a + name].attrs[\"last_modified\"] = timestamp()\n\t\t\t\t\tself.ds._file.flush()\n\t\t\t\t\treturn self.ds._file[a + name].attrs[\"last_modified\"]\n\t\treturn timestamp()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npermuting all the attributes in the collection", "response": "def _permute(self, ordering: np.ndarray) -> None:\n\t\t\"\"\"\n\t\tPermute all the attributes in the collection\n\n\t\tRemarks:\n\t\t\tThis permutes the order of the values for each attribute in the file\n\t\t\"\"\"\n\t\tfor key in self.keys():\n\t\t\tself[key] = self[key][ordering]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the value for a named attribute.", "response": "def get(self, name: str, default: np.ndarray) -> np.ndarray:\n\t\t\"\"\"\n\t\tReturn the value for a named attribute if it exists, else default.\n\t\tDefault has to be a numpy array of correct size.\n\t\t\"\"\"\n\n\t\tif name in self:\n\t\t\treturn self[name]\n\t\telse:\n\t\t\tif not isinstance(default, np.ndarray):\n\t\t\t\traise ValueError(f\"Default must be an np.ndarray with exactly {self.ds.shape[self.axis]} values\")\n\n\t\t\tif default.shape[0] != self.ds.shape[self.axis]:\n\t\t\t\traise ValueError(f\"Default must be an np.ndarray with exactly {self.ds.shape[self.axis]} values but {len(default)} were given\")\n\n\t\t\treturn default"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef normalize_attr_strings(a: np.ndarray) -> np.ndarray:\n\tif np.issubdtype(a.dtype, np.object_):\n\t\t# if np.all([type(x) is str for x in a]) or np.all([type(x) is np.str_ for x in a]) or np.all([type(x) is np.unicode_ for x in a]):\n\t\tif np.all([(type(x) is str or type(x) is np.str_ or type(x) is np.unicode_) for x in a]):\n\t\t\treturn np.array([x.encode('ascii', 'xmlcharrefreplace') for x in a])\n\t\telif np.all([type(x) is np.string_ for x in a]) or np.all([type(x) is np.bytes_ for x in a]):\n\t\t\treturn a.astype(\"string_\")\n\t\telse:\n\t\t\tlogging.debug(f\"Attribute contains mixed object types ({np.unique([str(type(x)) for x in a])}); casting all to string\")\n\t\t\treturn np.array([str(x) for x in a], dtype=\"string_\")\n\telif np.issubdtype(a.dtype, np.string_) or np.issubdtype(a.dtype, np.object_):\n\t\treturn a\n\telif np.issubdtype(a.dtype, np.str_) or np.issubdtype(a.dtype, np.unicode_):\n\t\treturn np.array([x.encode('ascii', 'xmlcharrefreplace') for x in a])\n\telse:\n\t\traise ValueError(\"String values must be object, ascii or unicode.\")", "response": "Normalizes an attribute array to be ascii or unicode."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef normalize_attr_array(a: Any) -> np.ndarray:\n\tif type(a) is np.ndarray:\n\t\treturn a\n\telif type(a) is np.matrix:\n\t\tif a.shape[0] == 1:\n\t\t\treturn np.array(a)[0, :]\n\t\telif a.shape[1] == 1:\n\t\t\treturn np.array(a)[:, 0]\n\t\telse:\n\t\t\traise ValueError(\"Attribute values must be 1-dimensional.\")\n\telif type(a) is list or type(a) is tuple:\n\t\treturn np.array(a)\n\telif sparse.issparse(a):\n\t\treturn normalize_attr_array(a.todense())\n\telse:\n\t\traise ValueError(\"Argument must be a list, tuple, numpy matrix, numpy ndarray or sparse matrix.\")", "response": "Normalizes all kinds of array - like inputs and normalize to a one - dimensional np. ndarray."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntake all kinds of input values and validate them and return a normalized version of the input array.", "response": "def normalize_attr_values(a: Any) -> np.ndarray:\n\t\"\"\"\n\tTake all kinds of input values and validate/normalize them.\n\t\n\tArgs:\n\t\ta\tList, tuple, np.matrix, np.ndarray or sparse matrix\n\t\t\tElements can be strings, numbers or bools\n\t\n\tReturns\n\t\ta_normalized    An np.ndarray with elements conforming to one of the valid Loom attribute types\n\t\n\tRemarks:\n\t\tThis method should be used to prepare the values to be stored in the HDF5 file. You should not\n\t\treturn the values to the caller; for that, use materialize_attr_values()\n\t\"\"\"\n\tscalar = False\n\tif np.isscalar(a):\n\t\ta = np.array([a])\n\t\tscalar = True\n\tarr = normalize_attr_array(a)\n\tif np.issubdtype(arr.dtype, np.integer) or np.issubdtype(arr.dtype, np.floating):\n\t\tpass  # We allow all these types\n\telif np.issubdtype(arr.dtype, np.character) or np.issubdtype(arr.dtype, np.object_):\n\t\tarr = normalize_attr_strings(arr)\n\telif np.issubdtype(arr.dtype, np.bool_):\n\t\tarr = arr.astype('ubyte')\n\tif scalar:\n\t\treturn arr[0]\n\telse:\n\t\treturn arr"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_html(ds: Any) -> str:\n\trm = min(10, ds.shape[0])\n\tcm = min(10, ds.shape[1])\n\thtml = \"<p>\"\n\tif ds.attrs.__contains__(\"title\"):\n\t\thtml += \"<strong>\" + ds.attrs[\"title\"] + \"</strong> \"\n\thtml += f\"{ds.shape[0]} rows, {ds.shape[1]} columns, {len(ds.layers)} layer{'s' if len(ds.layers) > 1 else ''}<br/>(showing up to 10x10)<br/>\"\n\thtml += ds.filename + \"<br/>\"\n\tfor (name, val) in ds.attrs.items():\n\t\thtml += f\"name: <em>{val}</em><br/>\"\n\thtml += \"<table>\"\n\t# Emit column attributes\n\tfor ca in ds.col_attrs.keys():\n\t\thtml += \"<tr>\"\n\t\tfor ra in ds.row_attrs.keys():\n\t\t\thtml += \"<td>&nbsp;</td>\"  # Space for row attrs\n\t\thtml += \"<td><strong>\" + ca + \"</strong></td>\"  # Col attr name\n\t\tfor v in ds.col_attrs[ca][:cm]:\n\t\t\thtml += \"<td>\" + str(v) + \"</td>\"\n\t\tif ds.shape[1] > cm:\n\t\t\thtml += \"<td>...</td>\"\n\t\thtml += \"</tr>\"\n\n\t# Emit row attribute names\n\thtml += \"<tr>\"\n\tfor ra in ds.row_attrs.keys():\n\t\thtml += \"<td><strong>\" + ra + \"</strong></td>\"  # Row attr name\n\thtml += \"<td>&nbsp;</td>\"  # Space for col attrs\n\tfor v in range(cm):\n\t\thtml += \"<td>&nbsp;</td>\"\n\tif ds.shape[1] > cm:\n\t\thtml += \"<td>...</td>\"\n\thtml += \"</tr>\"\n\n\t# Emit row attr values and matrix values\n\tfor row in range(rm):\n\t\thtml += \"<tr>\"\n\t\tfor ra in ds.row_attrs.keys():\n\t\t\thtml += \"<td>\" + str(ds.row_attrs[ra][row]) + \"</td>\"\n\t\thtml += \"<td>&nbsp;</td>\"  # Space for col attrs\n\n\t\tfor v in ds[row, :cm]:\n\t\t\thtml += \"<td>\" + str(v) + \"</td>\"\n\t\tif ds.shape[1] > cm:\n\t\t\thtml += \"<td>...</td>\"\n\t\thtml += \"</tr>\"\n\t# Emit ellipses\n\tif ds.shape[0] > rm:\n\t\thtml += \"<tr>\"\n\t\tfor v in range(rm + 1 + len(ds.row_attrs.keys())):\n\t\t\thtml += \"<td>...</td>\"\n\t\tif ds.shape[1] > cm:\n\t\t\thtml += \"<td>...</td>\"\n\t\thtml += \"</tr>\"\n\thtml += \"</table>\"\n\treturn html", "response": "Return an HTML representation of the loom file or view."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npermuting the view by permuting layers attributes and graphs along the specified axis.", "response": "def permute(self, ordering: np.ndarray, *, axis: int) -> None:\n\t\t\"\"\"\n\t\tPermute the view, by permuting its layers, attributes and graphs\n\n\t\tArgs:\n\t\t\tordering (np.ndarray):\tThe desired ordering along the axis\n\t\t\taxis (int):\t\t\t\t0, permute rows; 1, permute columns\n\t\t\"\"\"\n\t\tif axis not in (0, 1):\n\t\t\traise ValueError(\"Axis must be 0 (rows) or 1 (columns)\")\n\t\tfor layer in self.layers.values():\n\t\t\tlayer._permute(ordering, axis=axis)\n\t\tif axis == 0:\n\t\t\tif self.row_graphs is not None:\n\t\t\t\tfor g in self.row_graphs.values():\n\t\t\t\t\tg._permute(ordering)\n\t\t\tfor a in self.row_attrs.values():\n\t\t\t\ta._permute(ordering)\n\t\telif axis == 1:\n\t\t\tif self.col_graphs is not None:\n\t\t\t\tfor g in self.col_graphs.values():\n\t\t\t\t\tg._permute(ordering)\n\t\t\tfor a in self.col_attrs.values():\n\t\t\t\ta._permute(ordering)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sparse(self, rows: np.ndarray, cols: np.ndarray) -> scipy.sparse.coo_matrix:\n\t\treturn scipy.sparse.coo_matrix(self.values[rows, :][:, cols])", "response": "Return the layer as scipy. sparse. coo_matrix."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef permute(self, ordering: np.ndarray, *, axis: int) -> None:\n\t\tif axis == 0:\n\t\t\tself.values = self.values[ordering, :]\n\t\telif axis == 1:\n\t\t\tself.values = self.values[:, ordering]\n\t\telse:\n\t\t\traise ValueError(\"axis must be 0 or 1\")", "response": "Permute the layer along an axis."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef map(self, f_list: List[Callable[[np.ndarray], int]], axis: int = 0, chunksize: int = 1000, selection: np.ndarray = None) -> List[np.ndarray]:\n\t\tif hasattr(f_list, '__call__'):\n\t\t\traise ValueError(\"f_list must be a list of functions, not a function itself\")\n\n\t\tresult = []\n\t\tif axis == 0:\n\t\t\trows_per_chunk = chunksize\n\t\t\tfor i in range(len(f_list)):\n\t\t\t\tresult.append(np.zeros(self.shape[0]))\n\t\t\tix = 0\n\t\t\twhile ix < self.shape[0]:\n\t\t\t\trows_per_chunk = min(self.shape[0] - ix, rows_per_chunk)\n\t\t\t\tif selection is not None:\n\t\t\t\t\tchunk = self[ix:ix + rows_per_chunk, :][:, selection]\n\t\t\t\telse:\n\t\t\t\t\tchunk = self[ix:ix + rows_per_chunk, :]\n\t\t\t\tfor i in range(len(f_list)):\n\t\t\t\t\tresult[i][ix:ix + rows_per_chunk] = np.apply_along_axis(f_list[i], 1, chunk)\n\t\t\t\tix = ix + rows_per_chunk\n\t\telif axis == 1:\n\t\t\tcols_per_chunk = chunksize\n\t\t\tfor i in range(len(f_list)):\n\t\t\t\tresult.append(np.zeros(self.shape[1]))\n\t\t\tix = 0\n\t\t\twhile ix < self.shape[1]:\n\t\t\t\tcols_per_chunk = min(self.shape[1] - ix, cols_per_chunk)\n\t\t\t\tif selection is not None:\n\t\t\t\t\tchunk = self[:, ix:ix + cols_per_chunk][selection, :]\n\t\t\t\telse:\n\t\t\t\t\tchunk = self[:, ix:ix + cols_per_chunk]\n\t\t\t\tfor i in range(len(f_list)):\n\t\t\t\t\tresult[i][ix:ix + cols_per_chunk] = np.apply_along_axis(f_list[i], 0, chunk)\n\t\t\t\tix = ix + cols_per_chunk\n\t\treturn result", "response": "This function maps a function along an axis with loading the entire dataset in memory."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_datafile_valid(datafile):\n\n  try:\n    datafile_json = json.loads(datafile)\n  except:\n    return False\n\n  try:\n    jsonschema.Draft4Validator(constants.JSON_SCHEMA).validate(datafile_json)\n  except:\n    return False\n\n  return True", "response": "Determines if a datafile is valid or not."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndetermines if user profile is valid or not.", "response": "def is_user_profile_valid(user_profile):\n  \"\"\" Determine if provided user profile is valid or not.\n\n  Args:\n    user_profile: User's profile which needs to be validated.\n\n  Returns:\n    Boolean depending upon whether profile is valid or not.\n  \"\"\"\n\n  if not user_profile:\n    return False\n\n  if not type(user_profile) is dict:\n    return False\n\n  if UserProfile.USER_ID_KEY not in user_profile:\n    return False\n\n  if UserProfile.EXPERIMENT_BUCKET_MAP_KEY not in user_profile:\n    return False\n\n  experiment_bucket_map = user_profile.get(UserProfile.EXPERIMENT_BUCKET_MAP_KEY)\n  if not type(experiment_bucket_map) is dict:\n    return False\n\n  for decision in experiment_bucket_map.values():\n    if type(decision) is not dict or UserProfile.VARIATION_ID_KEY not in decision:\n      return False\n\n  return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_attribute_valid(attribute_key, attribute_value):\n\n  if not isinstance(attribute_key, string_types):\n    return False\n\n  if isinstance(attribute_value, (string_types, bool)):\n    return True\n\n  if isinstance(attribute_value, (numbers.Integral, float)):\n    return is_finite_number(attribute_value)\n\n  return False", "response": "Checks if given attribute is valid."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_finite_number(value):\n  if not isinstance(value, (numbers.Integral, float)):\n      # numbers.Integral instead of int to accomodate long integer in python 2\n    return False\n\n  if isinstance(value, bool):\n    # bool is a subclass of int\n    return False\n\n  if isinstance(value, float):\n    if math.isnan(value) or math.isinf(value):\n      return False\n\n  if abs(value) > (2**53):\n    return False\n\n  return True", "response": "Validates if the given value is a number and enforces nanos and inf."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmaking a standard python logger object with default formatter handler etc.", "response": "def reset_logger(name, level=None, handler=None):\n  \"\"\"\n  Make a standard python logger object with default formatter, handler, etc.\n\n  Defaults are:\n    - level == logging.INFO\n    - handler == logging.StreamHandler()\n\n  Args:\n    name: a logger name.\n    level: an optional initial log level for this logger.\n    handler: an optional initial handler for this logger.\n\n  Returns: a standard python logger with a single handler.\n\n  \"\"\"\n  # Make the logger and set its level.\n  if level is None:\n    level = logging.INFO\n  logger = logging.getLogger(name)\n  logger.setLevel(level)\n\n  # Make the handler and attach it.\n  handler = handler or logging.StreamHandler()\n  handler.setFormatter(logging.Formatter(_DEFAULT_LOG_FORMAT))\n\n  # We don't use ``.addHandler``, since this logger may have already been\n  #   instantiated elsewhere with a different handler. It should only ever\n  #   have one, not many.\n  logger.handlers = [handler]\n  return logger"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadapts a logger into a standard python logger object.", "response": "def adapt_logger(logger):\n  \"\"\"\n  Adapt our custom logger.BaseLogger object into a standard logging.Logger object.\n\n  Adaptations are:\n    - NoOpLogger turns into a logger with a single NullHandler.\n    - SimpleLogger turns into a logger with a StreamHandler and level.\n\n  Args:\n    logger: Possibly a logger.BaseLogger, or a standard python logging.Logger.\n\n  Returns: a standard python logging.Logger.\n\n  \"\"\"\n  if isinstance(logger, logging.Logger):\n    return logger\n\n  # Use the standard python logger created by these classes.\n  if isinstance(logger, (SimpleLogger, NoOpLogger)):\n    return logger.logger\n\n  # Otherwise, return whatever we were given because we can't adapt.\n  return logger"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the variation ID corresponding to the given experiment.", "response": "def get_variation_for_experiment(self, experiment_id):\n    \"\"\" Helper method to retrieve variation ID for given experiment.\n\n    Args:\n      experiment_id: ID for experiment for which variation needs to be looked up for.\n\n    Returns:\n      Variation ID corresponding to the experiment. None if no decision available.\n    \"\"\"\n\n    return self.experiment_bucket_map.get(experiment_id, {self.VARIATION_ID_KEY: None}).get(self.VARIATION_ID_KEY)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nimplementing 32bit murmur3 hash.", "response": "def hash( key, seed = 0x0 ):\n    ''' Implements 32bit murmur3 hash. '''\n\n    key = bytearray( xencode(key) )\n\n    def fmix( h ):\n        h ^= h >> 16\n        h  = ( h * 0x85ebca6b ) & 0xFFFFFFFF\n        h ^= h >> 13\n        h  = ( h * 0xc2b2ae35 ) & 0xFFFFFFFF\n        h ^= h >> 16\n        return h\n\n    length = len( key )\n    nblocks = int( length / 4 )\n\n    h1 = seed\n\n    c1 = 0xcc9e2d51\n    c2 = 0x1b873593\n\n    # body\n    for block_start in xrange( 0, nblocks * 4, 4 ):\n        # ??? big endian?\n        k1 = key[ block_start + 3 ] << 24 | \\\n             key[ block_start + 2 ] << 16 | \\\n             key[ block_start + 1 ] <<  8 | \\\n             key[ block_start + 0 ]\n             \n        k1 = ( c1 * k1 ) & 0xFFFFFFFF\n        k1 = ( k1 << 15 | k1 >> 17 ) & 0xFFFFFFFF # inlined ROTL32\n        k1 = ( c2 * k1 ) & 0xFFFFFFFF\n        \n        h1 ^= k1\n        h1  = ( h1 << 13 | h1 >> 19 ) & 0xFFFFFFFF # inlined ROTL32\n        h1  = ( h1 * 5 + 0xe6546b64 ) & 0xFFFFFFFF\n\n    # tail\n    tail_index = nblocks * 4\n    k1 = 0\n    tail_size = length & 3\n\n    if tail_size >= 3:\n        k1 ^= key[ tail_index + 2 ] << 16\n    if tail_size >= 2:\n        k1 ^= key[ tail_index + 1 ] << 8\n    if tail_size >= 1:\n        k1 ^= key[ tail_index + 0 ]\n    \n    if tail_size > 0:\n        k1  = ( k1 * c1 ) & 0xFFFFFFFF\n        k1  = ( k1 << 15 | k1 >> 17 ) & 0xFFFFFFFF # inlined ROTL32\n        k1  = ( k1 * c2 ) & 0xFFFFFFFF\n        h1 ^= k1\n\n    #finalization\n    unsigned_val = fmix( h1 ^ length )\n    if unsigned_val & 0x80000000 == 0:\n        return unsigned_val\n    else:\n        return -( (unsigned_val ^ 0xFFFFFFFF) + 1 )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef hash128( key, seed = 0x0, x64arch = True ):\n    ''' Implements 128bit murmur3 hash. '''\n    def hash128_x64( key, seed ):\n        ''' Implements 128bit murmur3 hash for x64. '''\n\n        def fmix( k ):\n            k ^= k >> 33\n            k  = ( k * 0xff51afd7ed558ccd ) & 0xFFFFFFFFFFFFFFFF\n            k ^= k >> 33\n            k  = ( k * 0xc4ceb9fe1a85ec53 ) & 0xFFFFFFFFFFFFFFFF\n            k ^= k >> 33\n            return k\n\n        length = len( key )\n        nblocks = int( length / 16 )\n\n        h1 = seed\n        h2 = seed\n\n        c1 = 0x87c37b91114253d5\n        c2 = 0x4cf5ad432745937f\n\n        #body\n        for block_start in xrange( 0, nblocks * 8, 8 ):\n            # ??? big endian?\n            k1 = key[ 2 * block_start + 7 ] << 56 | \\\n                 key[ 2 * block_start + 6 ] << 48 | \\\n                 key[ 2 * block_start + 5 ] << 40 | \\\n                 key[ 2 * block_start + 4 ] << 32 | \\\n                 key[ 2 * block_start + 3 ] << 24 | \\\n                 key[ 2 * block_start + 2 ] << 16 | \\\n                 key[ 2 * block_start + 1 ] <<  8 | \\\n                 key[ 2 * block_start + 0 ]\n\n            k2 = key[ 2 * block_start + 15 ] << 56 | \\\n                 key[ 2 * block_start + 14 ] << 48 | \\\n                 key[ 2 * block_start + 13 ] << 40 | \\\n                 key[ 2 * block_start + 12 ] << 32 | \\\n                 key[ 2 * block_start + 11 ] << 24 | \\\n                 key[ 2 * block_start + 10 ] << 16 | \\\n                 key[ 2 * block_start + 9 ] <<  8 | \\\n                 key[ 2 * block_start + 8 ]\n\n            k1  = ( c1 * k1 ) & 0xFFFFFFFFFFFFFFFF\n            k1  = ( k1 << 31 | k1 >> 33 ) & 0xFFFFFFFFFFFFFFFF # inlined ROTL64\n            k1  = ( c2 * k1 ) & 0xFFFFFFFFFFFFFFFF\n            h1 ^= k1\n\n            h1 = ( h1 << 27 | h1 >> 37 ) & 0xFFFFFFFFFFFFFFFF # inlined ROTL64\n            h1 = ( h1 + h2 ) & 0xFFFFFFFFFFFFFFFF\n            h1 = ( h1 * 5 + 0x52dce729 ) & 0xFFFFFFFFFFFFFFFF\n\n            k2  = ( c2 * k2 ) & 0xFFFFFFFFFFFFFFFF\n            k2  = ( k2 << 33 | k2 >> 31 ) & 0xFFFFFFFFFFFFFFFF # inlined ROTL64\n            k2  = ( c1 * k2 ) & 0xFFFFFFFFFFFFFFFF\n            h2 ^= k2\n\n            h2 = ( h2 << 31 | h2 >> 33 ) & 0xFFFFFFFFFFFFFFFF # inlined ROTL64\n            h2 = ( h1 + h2 ) & 0xFFFFFFFFFFFFFFFF\n            h2 = ( h2 * 5 + 0x38495ab5 ) & 0xFFFFFFFFFFFFFFFF\n\n        #tail\n        tail_index = nblocks * 16\n        k1 = 0\n        k2 = 0\n        tail_size = length & 15\n\n        if tail_size >= 15:\n            k2 ^= key[ tail_index + 14 ] << 48\n        if tail_size >= 14:\n            k2 ^= key[ tail_index + 13 ] << 40\n        if tail_size >= 13:\n            k2 ^= key[ tail_index + 12 ] << 32\n        if tail_size >= 12:\n            k2 ^= key[ tail_index + 11 ] << 24\n        if tail_size >= 11:\n            k2 ^= key[ tail_index + 10 ] << 16\n        if tail_size >= 10:\n            k2 ^= key[ tail_index +  9 ] << 8\n        if tail_size >=  9:\n            k2 ^= key[ tail_index +  8 ]\n\n        if tail_size > 8:\n            k2  = ( k2 * c2 ) & 0xFFFFFFFFFFFFFFFF\n            k2  = ( k2 << 33 | k2 >> 31 ) & 0xFFFFFFFFFFFFFFFF # inlined ROTL64\n            k2  = ( k2 * c1 ) & 0xFFFFFFFFFFFFFFFF\n            h2 ^= k2\n\n        if tail_size >=  8:\n            k1 ^= key[ tail_index +  7 ] << 56\n        if tail_size >=  7:\n            k1 ^= key[ tail_index +  6 ] << 48\n        if tail_size >=  6:\n            k1 ^= key[ tail_index +  5 ] << 40\n        if tail_size >=  5:\n            k1 ^= key[ tail_index +  4 ] << 32\n        if tail_size >=  4:\n            k1 ^= key[ tail_index +  3 ] << 24\n        if tail_size >=  3:\n            k1 ^= key[ tail_index +  2 ] << 16\n        if tail_size >=  2:\n            k1 ^= key[ tail_index +  1 ] << 8\n        if tail_size >=  1:\n            k1 ^= key[ tail_index +  0 ]\n\n        if tail_size > 0:\n            k1  = ( k1 * c1 ) & 0xFFFFFFFFFFFFFFFF\n            k1  = ( k1 << 31 | k1 >> 33 ) & 0xFFFFFFFFFFFFFFFF # inlined ROTL64\n            k1  = ( k1 * c2 ) & 0xFFFFFFFFFFFFFFFF\n            h1 ^= k1\n\n        #finalization\n        h1 ^= length\n        h2 ^= length\n\n        h1  = ( h1 + h2 ) & 0xFFFFFFFFFFFFFFFF\n        h2  = ( h1 + h2 ) & 0xFFFFFFFFFFFFFFFF\n\n        h1  = fmix( h1 )\n        h2  = fmix( h2 )\n\n        h1  = ( h1 + h2 ) & 0xFFFFFFFFFFFFFFFF\n        h2  = ( h1 + h2 ) & 0xFFFFFFFFFFFFFFFF\n\n        return ( h2 << 64 | h1 )\n\n    def hash128_x86( key, seed ):\n        ''' Implements 128bit murmur3 hash for x86. '''\n\n        def fmix( h ):\n            h ^= h >> 16\n            h  = ( h * 0x85ebca6b ) & 0xFFFFFFFF\n            h ^= h >> 13\n            h  = ( h * 0xc2b2ae35 ) & 0xFFFFFFFF\n            h ^= h >> 16\n            return h\n\n        length = len( key )\n        nblocks = int( length / 16 )\n\n        h1 = seed\n        h2 = seed\n        h3 = seed\n        h4 = seed\n\n        c1 = 0x239b961b\n        c2 = 0xab0e9789\n        c3 = 0x38b34ae5\n        c4 = 0xa1e38b93\n\n        #body\n        for block_start in xrange( 0, nblocks * 16, 16 ):\n            k1 = key[ block_start +  3 ] << 24 | \\\n                 key[ block_start +  2 ] << 16 | \\\n                 key[ block_start +  1 ] <<  8 | \\\n                 key[ block_start +  0 ]\n\n            k2 = key[ block_start +  7 ] << 24 | \\\n                 key[ block_start +  6 ] << 16 | \\\n                 key[ block_start +  5 ] <<  8 | \\\n                 key[ block_start +  4 ]\n\n            k3 = key[ block_start + 11 ] << 24 | \\\n                 key[ block_start + 10 ] << 16 | \\\n                 key[ block_start +  9 ] <<  8 | \\\n                 key[ block_start +  8 ]\n\n            k4 = key[ block_start + 15 ] << 24 | \\\n                 key[ block_start + 14 ] << 16 | \\\n                 key[ block_start + 13 ] <<  8 | \\\n                 key[ block_start + 12 ]\n\n            k1  = ( c1 * k1 ) & 0xFFFFFFFF\n            k1  = ( k1 << 15 | k1 >> 17 ) & 0xFFFFFFFF # inlined ROTL32\n            k1  = ( c2 * k1 ) & 0xFFFFFFFF\n            h1 ^= k1\n\n            h1 = ( h1 << 19 | h1 >> 13 ) & 0xFFFFFFFF # inlined ROTL32\n            h1 = ( h1 + h2 ) & 0xFFFFFFFF\n            h1 = ( h1 * 5 + 0x561ccd1b ) & 0xFFFFFFFF\n\n            k2  = ( c2 * k2 ) & 0xFFFFFFFF\n            k2  = ( k2 << 16 | k2 >> 16 ) & 0xFFFFFFFF # inlined ROTL32\n            k2  = ( c3 * k2 ) & 0xFFFFFFFF\n            h2 ^= k2\n\n            h2 = ( h2 << 17 | h2 >> 15 ) & 0xFFFFFFFF # inlined ROTL32\n            h2 = ( h2 + h3 ) & 0xFFFFFFFF\n            h2 = ( h2 * 5 + 0x0bcaa747 ) & 0xFFFFFFFF\n\n            k3  = ( c3 * k3 ) & 0xFFFFFFFF\n            k3  = ( k3 << 17 | k3 >> 15 ) & 0xFFFFFFFF # inlined ROTL32\n            k3  = ( c4 * k3 ) & 0xFFFFFFFF\n            h3 ^= k3\n\n            h3 = ( h3 << 15 | h3 >> 17 ) & 0xFFFFFFFF # inlined ROTL32\n            h3 = ( h3 + h4 ) & 0xFFFFFFFF\n            h3 = ( h3 * 5 + 0x96cd1c35 ) & 0xFFFFFFFF\n\n            k4  = ( c4 * k4 ) & 0xFFFFFFFF\n            k4  = ( k4 << 18 | k4 >> 14 ) & 0xFFFFFFFF # inlined ROTL32\n            k4  = ( c1 * k4 ) & 0xFFFFFFFF\n            h4 ^= k4\n\n            h4 = ( h4 << 13 | h4 >> 19 ) & 0xFFFFFFFF # inlined ROTL32\n            h4 = ( h1 + h4 ) & 0xFFFFFFFF\n            h4 = ( h4 * 5 + 0x32ac3b17 ) & 0xFFFFFFFF\n\n        #tail\n        tail_index = nblocks * 16\n        k1 = 0\n        k2 = 0\n        k3 = 0\n        k4 = 0\n        tail_size = length & 15\n\n        if tail_size >= 15:\n            k4 ^= key[ tail_index + 14 ] << 16\n        if tail_size >= 14:\n            k4 ^= key[ tail_index + 13 ] << 8\n        if tail_size >= 13:\n            k4 ^= key[ tail_index + 12 ]\n\n        if tail_size > 12:\n            k4  = ( k4 * c4 ) & 0xFFFFFFFF\n            k4  = ( k4 << 18 | k4 >> 14 ) & 0xFFFFFFFF # inlined ROTL32\n            k4  = ( k4 * c1 ) & 0xFFFFFFFF\n            h4 ^= k4\n\n        if tail_size >= 12:\n            k3 ^= key[ tail_index + 11 ] << 24\n        if tail_size >= 11:\n            k3 ^= key[ tail_index + 10 ] << 16\n        if tail_size >= 10:\n            k3 ^= key[ tail_index +  9 ] << 8\n        if tail_size >=  9:\n            k3 ^= key[ tail_index +  8 ]\n\n        if tail_size > 8:\n            k3  = ( k3 * c3 ) & 0xFFFFFFFF\n            k3  = ( k3 << 17 | k3 >> 15 ) & 0xFFFFFFFF # inlined ROTL32\n            k3  = ( k3 * c4 ) & 0xFFFFFFFF\n            h3 ^= k3\n\n        if tail_size >= 8:\n            k2 ^= key[ tail_index + 7 ] << 24\n        if tail_size >= 7:\n            k2 ^= key[ tail_index + 6 ] << 16\n        if tail_size >= 6:\n            k2 ^= key[ tail_index + 5 ] << 8\n        if tail_size >= 5:\n            k2 ^= key[ tail_index + 4 ]\n\n        if tail_size > 4:\n            k2  = ( k2 * c2 ) & 0xFFFFFFFF\n            k2  = ( k2 << 16 | k2 >> 16 ) & 0xFFFFFFFF # inlined ROTL32\n            k2  = ( k2 * c3 ) & 0xFFFFFFFF\n            h2 ^= k2\n\n        if tail_size >= 4:\n            k1 ^= key[ tail_index + 3 ] << 24\n        if tail_size >= 3:\n            k1 ^= key[ tail_index + 2 ] << 16\n        if tail_size >= 2:\n            k1 ^= key[ tail_index + 1 ] << 8\n        if tail_size >= 1:\n            k1 ^= key[ tail_index + 0 ]\n\n        if tail_size > 0:\n            k1  = ( k1 * c1 ) & 0xFFFFFFFF\n            k1  = ( k1 << 15 | k1 >> 17 ) & 0xFFFFFFFF # inlined ROTL32\n            k1  = ( k1 * c2 ) & 0xFFFFFFFF\n            h1 ^= k1\n\n        #finalization\n        h1 ^= length\n        h2 ^= length\n        h3 ^= length\n        h4 ^= length\n\n        h1 = ( h1 + h2 ) & 0xFFFFFFFF\n        h1 = ( h1 + h3 ) & 0xFFFFFFFF\n        h1 = ( h1 + h4 ) & 0xFFFFFFFF\n        h2 = ( h1 + h2 ) & 0xFFFFFFFF\n        h3 = ( h1 + h3 ) & 0xFFFFFFFF\n        h4 = ( h1 + h4 ) & 0xFFFFFFFF\n\n        h1 = fmix( h1 )\n        h2 = fmix( h2 )\n        h3 = fmix( h3 )\n        h4 = fmix( h4 )\n\n        h1 = ( h1 + h2 ) & 0xFFFFFFFF\n        h1 = ( h1 + h3 ) & 0xFFFFFFFF\n        h1 = ( h1 + h4 ) & 0xFFFFFFFF\n        h2 = ( h1 + h2 ) & 0xFFFFFFFF\n        h3 = ( h1 + h3 ) & 0xFFFFFFFF\n        h4 = ( h1 + h4 ) & 0xFFFFFFFF\n\n        return ( h4 << 96 | h3 << 64 | h2 << 32 | h1 )\n\n    key = bytearray( xencode(key) )\n\n    if x64arch:\n        return hash128_x64( key, seed )\n    else:\n        return hash128_x86( key, seed )", "response": "Implements 128bit murmur3 hash for a 128bit key."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef hash64( key, seed = 0x0, x64arch = True ):\n    ''' Implements 64bit murmur3 hash. Returns a tuple. '''\n\n    hash_128 = hash128( key, seed, x64arch )\n\n    unsigned_val1 = hash_128 & 0xFFFFFFFFFFFFFFFF\n    if unsigned_val1 & 0x8000000000000000 == 0:\n        signed_val1 = unsigned_val1\n    else:\n        signed_val1 = -( (unsigned_val1 ^ 0xFFFFFFFFFFFFFFFF) + 1 )\n\n    unsigned_val2 = ( hash_128 >> 64 ) & 0xFFFFFFFFFFFFFFFF\n    if unsigned_val2 & 0x8000000000000000 == 0:\n        signed_val2 = unsigned_val2\n    else:\n        signed_val2 = -( (unsigned_val2 ^ 0xFFFFFFFFFFFFFFFF) + 1 )\n\n    return ( int( signed_val1 ), int( signed_val2 ) )", "response": "Implements 64bit murmur3 hash. Returns a tuple."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nimplement 128bit murmur3 hash. Returns a byte string.", "response": "def hash_bytes( key, seed = 0x0, x64arch = True ):\n    ''' Implements 128bit murmur3 hash. Returns a byte string. '''\n\n    hash_128 = hash128( key, seed, x64arch )\n\n    bytestring = ''\n\n    for i in xrange(0, 16, 1):\n        lsbyte = hash_128 & 0xFF\n        bytestring = bytestring + str( chr( lsbyte ) )\n        hash_128 = hash_128 >> 8\n\n    return bytestring"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _generate_bucket_value(self, bucketing_id):\n\n    ratio = float(self._generate_unsigned_hash_code_32_bit(bucketing_id)) / MAX_HASH_VALUE\n    return math.floor(ratio * MAX_TRAFFIC_VALUE)", "response": "Generates a bucket value in half - closed interval [ 0 MAX_TRAFFIC_VALUE )."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_bucket(self, bucketing_id, parent_id, traffic_allocations):\n\n    bucketing_key = BUCKETING_ID_TEMPLATE.format(bucketing_id=bucketing_id, parent_id=parent_id)\n    bucketing_number = self._generate_bucket_value(bucketing_key)\n    self.config.logger.debug('Assigned bucket %s to user with bucketing ID \"%s\".' % (\n      bucketing_number,\n      bucketing_id\n    ))\n\n    for traffic_allocation in traffic_allocations:\n      current_end_of_range = traffic_allocation.get('endOfRange')\n      if bucketing_number < current_end_of_range:\n        return traffic_allocation.get('entityId')\n\n    return None", "response": "Determine the entity ID for a bucket based on bucketing_id and parent_id."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef bucket(self, experiment, user_id, bucketing_id):\n\n    if not experiment:\n      return None\n\n    # Determine if experiment is in a mutually exclusive group\n    if experiment.groupPolicy in GROUP_POLICIES:\n      group = self.config.get_group(experiment.groupId)\n\n      if not group:\n        return None\n\n      user_experiment_id = self.find_bucket(bucketing_id, experiment.groupId, group.trafficAllocation)\n      if not user_experiment_id:\n        self.config.logger.info('User \"%s\" is in no experiment.' % user_id)\n        return None\n\n      if user_experiment_id != experiment.id:\n        self.config.logger.info('User \"%s\" is not in experiment \"%s\" of group %s.' % (\n          user_id,\n          experiment.key,\n          experiment.groupId\n        ))\n        return None\n\n      self.config.logger.info('User \"%s\" is in experiment %s of group %s.' % (\n        user_id,\n        experiment.key,\n        experiment.groupId\n      ))\n\n    # Bucket user if not in white-list and in group (if any)\n    variation_id = self.find_bucket(bucketing_id, experiment.id, experiment.trafficAllocation)\n    if variation_id:\n      variation = self.config.get_variation_from_id(experiment.key, variation_id)\n      self.config.logger.info('User \"%s\" is in variation \"%s\" of experiment %s.' % (\n        user_id,\n        variation.key,\n        experiment.key\n      ))\n      return variation\n\n    self.config.logger.info('User \"%s\" is in no variation.' % user_id)\n    return None", "response": "This function determines the variation for a given user and bucketing ID."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the value of the typecasted feature flag.", "response": "def get_typecast_value(self, value, type):\n    \"\"\" Helper method to determine actual value based on type of feature variable.\n\n    Args:\n      value: Value in string form as it was parsed from datafile.\n      type: Type denoting the feature flag type.\n\n    Return:\n      Value type-casted based on type of feature variable.\n    \"\"\"\n\n    if type == entities.Variable.Type.BOOLEAN:\n      return value == 'true'\n    elif type == entities.Variable.Type.INTEGER:\n      return int(value)\n    elif type == entities.Variable.Type.DOUBLE:\n      return float(value)\n    else:\n      return value"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_experiment_from_key(self, experiment_key):\n\n    experiment = self.experiment_key_map.get(experiment_key)\n\n    if experiment:\n      return experiment\n\n    self.logger.error('Experiment key \"%s\" is not in datafile.' % experiment_key)\n    self.error_handler.handle_error(exceptions.InvalidExperimentException(enums.Errors.INVALID_EXPERIMENT_KEY_ERROR))\n    return None", "response": "Get the experiment corresponding to the provided experiment key."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_experiment_from_id(self, experiment_id):\n\n    experiment = self.experiment_id_map.get(experiment_id)\n\n    if experiment:\n      return experiment\n\n    self.logger.error('Experiment ID \"%s\" is not in datafile.' % experiment_id)\n    self.error_handler.handle_error(exceptions.InvalidExperimentException(enums.Errors.INVALID_EXPERIMENT_KEY_ERROR))\n    return None", "response": "Get the experiment corresponding to the provided experiment ID."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget group for the provided group ID.", "response": "def get_group(self, group_id):\n    \"\"\" Get group for the provided group ID.\n\n    Args:\n      group_id: Group ID for which group is to be determined.\n\n    Returns:\n      Group corresponding to the provided group ID.\n    \"\"\"\n\n    group = self.group_id_map.get(group_id)\n\n    if group:\n      return group\n\n    self.logger.error('Group ID \"%s\" is not in datafile.' % group_id)\n    self.error_handler.handle_error(exceptions.InvalidGroupException(enums.Errors.INVALID_GROUP_ID_ERROR))\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the audience object for the provided audience ID.", "response": "def get_audience(self, audience_id):\n    \"\"\" Get audience object for the provided audience ID.\n\n    Args:\n      audience_id: ID of the audience.\n\n    Returns:\n      Dict representing the audience.\n    \"\"\"\n\n    audience = self.audience_id_map.get(audience_id)\n    if audience:\n      return audience\n\n    self.logger.error('Audience ID \"%s\" is not in datafile.' % audience_id)\n    self.error_handler.handle_error(exceptions.InvalidAudienceException((enums.Errors.INVALID_AUDIENCE_ERROR)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets variation given experiment and variation key.", "response": "def get_variation_from_key(self, experiment_key, variation_key):\n    \"\"\" Get variation given experiment and variation key.\n\n    Args:\n      experiment: Key representing parent experiment of variation.\n      variation_key: Key representing the variation.\n\n    Returns\n      Object representing the variation.\n    \"\"\"\n\n    variation_map = self.variation_key_map.get(experiment_key)\n\n    if variation_map:\n      variation = variation_map.get(variation_key)\n      if variation:\n        return variation\n      else:\n        self.logger.error('Variation key \"%s\" is not in datafile.' % variation_key)\n        self.error_handler.handle_error(exceptions.InvalidVariationException(enums.Errors.INVALID_VARIATION_ERROR))\n        return None\n\n    self.logger.error('Experiment key \"%s\" is not in datafile.' % experiment_key)\n    self.error_handler.handle_error(exceptions.InvalidExperimentException(enums.Errors.INVALID_EXPERIMENT_KEY_ERROR))\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets variation given experiment and variation ID.", "response": "def get_variation_from_id(self, experiment_key, variation_id):\n    \"\"\" Get variation given experiment and variation ID.\n\n    Args:\n      experiment: Key representing parent experiment of variation.\n      variation_id: ID representing the variation.\n\n    Returns\n      Object representing the variation.\n    \"\"\"\n\n    variation_map = self.variation_id_map.get(experiment_key)\n\n    if variation_map:\n      variation = variation_map.get(variation_id)\n      if variation:\n        return variation\n      else:\n        self.logger.error('Variation ID \"%s\" is not in datafile.' % variation_id)\n        self.error_handler.handle_error(exceptions.InvalidVariationException(enums.Errors.INVALID_VARIATION_ERROR))\n        return None\n\n    self.logger.error('Experiment key \"%s\" is not in datafile.' % experiment_key)\n    self.error_handler.handle_error(exceptions.InvalidExperimentException(enums.Errors.INVALID_EXPERIMENT_KEY_ERROR))\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_event(self, event_key):\n\n    event = self.event_key_map.get(event_key)\n\n    if event:\n      return event\n\n    self.logger.error('Event \"%s\" is not in datafile.' % event_key)\n    self.error_handler.handle_error(exceptions.InvalidEventException(enums.Errors.INVALID_EVENT_KEY_ERROR))\n    return None", "response": "Get event corresponding to the provided event key."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_attribute_id(self, attribute_key):\n\n    attribute = self.attribute_key_map.get(attribute_key)\n    has_reserved_prefix = attribute_key.startswith(RESERVED_ATTRIBUTE_PREFIX)\n\n    if attribute:\n      if has_reserved_prefix:\n        self.logger.warning(('Attribute %s unexpectedly has reserved prefix %s; using attribute ID '\n                             'instead of reserved attribute name.' % (attribute_key, RESERVED_ATTRIBUTE_PREFIX)))\n\n      return attribute.id\n\n    if has_reserved_prefix:\n      return attribute_key\n\n    self.logger.error('Attribute \"%s\" is not in datafile.' % attribute_key)\n    self.error_handler.handle_error(exceptions.InvalidAttributeException(enums.Errors.INVALID_ATTRIBUTE_ERROR))\n    return None", "response": "Get the attribute ID corresponding to the provided attribute key."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_feature_from_key(self, feature_key):\n    feature = self.feature_key_map.get(feature_key)\n\n    if feature:\n      return feature\n\n    self.logger.error('Feature \"%s\" is not in datafile.' % feature_key)\n    return None", "response": "Get the feature corresponding to the provided feature key."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a single rollout from the provided ID.", "response": "def get_rollout_from_id(self, rollout_id):\n    \"\"\" Get rollout for the provided ID.\n\n    Args:\n      rollout_id: ID of the rollout to be fetched.\n\n    Returns:\n      Rollout corresponding to the provided ID.\n    \"\"\"\n    layer = self.rollout_id_map.get(rollout_id)\n\n    if layer:\n      return layer\n\n    self.logger.error('Rollout with ID \"%s\" is not in datafile.' % rollout_id)\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_variable_value_for_variation(self, variable, variation):\n\n    if not variable or not variation:\n      return None\n\n    if variation.id not in self.variation_variable_usage_map:\n      self.logger.error('Variation with ID \"%s\" is not in the datafile.' % variation.id)\n      return None\n\n    # Get all variable usages for the given variation\n    variable_usages = self.variation_variable_usage_map[variation.id]\n\n    # Find usage in given variation\n    variable_usage = None\n    if variable_usages:\n      variable_usage = variable_usages.get(variable.id)\n\n    if variable_usage:\n      variable_value = variable_usage.value\n      self.logger.info('Value for variable \"%s\" for variation \"%s\" is \"%s\".' % (\n        variable.key,\n        variation.key,\n        variable_value\n      ))\n\n    else:\n      variable_value = variable.defaultValue\n      self.logger.info('Variable \"%s\" is not used in variation \"%s\". Assigning default value \"%s\".' % (\n        variable.key,\n        variation.key,\n        variable_value\n      ))\n\n    return variable_value", "response": "Get the value for the given variable and variation."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_variable_for_feature(self, feature_key, variable_key):\n    feature = self.feature_key_map.get(feature_key)\n    if not feature:\n      self.logger.error('Feature with key \"%s\" not found in the datafile.' % feature_key)\n      return None\n\n    if variable_key not in feature.variables:\n      self.logger.error('Variable with key \"%s\" not found in the datafile.' % variable_key)\n      return None\n\n    return feature.variables.get(variable_key)", "response": "Get the variable with the given key for the given feature."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the user to a map of experiments to forced variations.", "response": "def set_forced_variation(self, experiment_key, user_id, variation_key):\n    \"\"\" Sets users to a map of experiments to forced variations.\n\n      Args:\n        experiment_key: Key for experiment.\n        user_id: The user ID.\n        variation_key: Key for variation. If None, then clear the existing experiment-to-variation mapping.\n\n      Returns:\n        A boolean value that indicates if the set completed successfully.\n    \"\"\"\n    experiment = self.get_experiment_from_key(experiment_key)\n    if not experiment:\n      # The invalid experiment key will be logged inside this call.\n      return False\n\n    experiment_id = experiment.id\n    if variation_key is None:\n      if user_id in self.forced_variation_map:\n        experiment_to_variation_map = self.forced_variation_map.get(user_id)\n        if experiment_id in experiment_to_variation_map:\n          del(self.forced_variation_map[user_id][experiment_id])\n          self.logger.debug('Variation mapped to experiment \"%s\" has been removed for user \"%s\".' % (\n            experiment_key,\n            user_id\n          ))\n        else:\n          self.logger.debug('Nothing to remove. Variation mapped to experiment \"%s\" for user \"%s\" does not exist.' % (\n            experiment_key,\n            user_id\n          ))\n      else:\n        self.logger.debug('Nothing to remove. User \"%s\" does not exist in the forced variation map.' % user_id)\n      return True\n\n    if not validator.is_non_empty_string(variation_key):\n      self.logger.debug('Variation key is invalid.')\n      return False\n\n    forced_variation = self.get_variation_from_key(experiment_key, variation_key)\n    if not forced_variation:\n      # The invalid variation key will be logged inside this call.\n      return False\n\n    variation_id = forced_variation.id\n\n    if user_id not in self.forced_variation_map:\n      self.forced_variation_map[user_id] = {experiment_id: variation_id}\n    else:\n      self.forced_variation_map[user_id][experiment_id] = variation_id\n\n    self.logger.debug('Set variation \"%s\" for experiment \"%s\" and user \"%s\" in the forced variation map.' % (\n      variation_id,\n      experiment_id,\n      user_id\n    ))\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the forced variation for the given user and experiment.", "response": "def get_forced_variation(self, experiment_key, user_id):\n    \"\"\" Gets the forced variation key for the given user and experiment.\n\n      Args:\n        experiment_key: Key for experiment.\n        user_id: The user ID.\n\n      Returns:\n        The variation which the given user and experiment should be forced into.\n    \"\"\"\n\n    if user_id not in self.forced_variation_map:\n      self.logger.debug('User \"%s\" is not in the forced variation map.' % user_id)\n      return None\n\n    experiment = self.get_experiment_from_key(experiment_key)\n    if not experiment:\n      # The invalid experiment key will be logged inside this call.\n      return None\n\n    experiment_to_variation_map = self.forced_variation_map.get(user_id)\n\n    if not experiment_to_variation_map:\n      self.logger.debug('No experiment \"%s\" mapped to user \"%s\" in the forced variation map.' % (\n        experiment_key,\n        user_id\n      ))\n      return None\n\n    variation_id = experiment_to_variation_map.get(experiment.id)\n    if variation_id is None:\n      self.logger.debug(\n        'No variation mapped to experiment \"%s\" in the forced variation map.' % experiment_key\n      )\n      return None\n\n    variation = self.get_variation_from_id(experiment_key, variation_id)\n\n    self.logger.debug('Variation \"%s\" is mapped to experiment \"%s\" and user \"%s\" in the forced variation map' % (\n      variation.key,\n      experiment_key,\n      user_id\n    ))\n    return variation"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndispatch the event to Optimizely backend.", "response": "def dispatch_event(event):\n    \"\"\" Dispatch the event being represented by the Event object.\n\n    Args:\n      event: Object holding information about the request to be dispatched to the Optimizely backend.\n    \"\"\"\n\n    try:\n      if event.http_verb == enums.HTTPVerbs.GET:\n        requests.get(event.url, params=event.params, timeout=REQUEST_TIMEOUT).raise_for_status()\n      elif event.http_verb == enums.HTTPVerbs.POST:\n        requests.post(\n          event.url, data=json.dumps(event.params), headers=event.headers, timeout=REQUEST_TIMEOUT\n        ).raise_for_status()\n\n    except request_exception.RequestException as error:\n      logging.error('Dispatch event failed. Error: %s' % str(error))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _validate_user_inputs(self, attributes=None, event_tags=None):\n\n    if attributes and not validator.are_attributes_valid(attributes):\n      self.logger.error('Provided attributes are in an invalid format.')\n      self.error_handler.handle_error(exceptions.InvalidAttributeException(enums.Errors.INVALID_ATTRIBUTE_FORMAT))\n      return False\n\n    if event_tags and not validator.are_event_tags_valid(event_tags):\n      self.logger.error('Provided event tags are in an invalid format.')\n      self.error_handler.handle_error(exceptions.InvalidEventTagException(enums.Errors.INVALID_EVENT_TAG_FORMAT))\n      return False\n\n    return True", "response": "Helper method to validate user inputs."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend an impression event to the notification center.", "response": "def _send_impression_event(self, experiment, variation, user_id, attributes):\n    \"\"\" Helper method to send impression event.\n\n    Args:\n      experiment: Experiment for which impression event is being sent.\n      variation: Variation picked for user for the given experiment.\n      user_id: ID for user.\n      attributes: Dict representing user attributes and values which need to be recorded.\n    \"\"\"\n\n    impression_event = self.event_builder.create_impression_event(experiment,\n                                                                  variation.id,\n                                                                  user_id,\n                                                                  attributes)\n\n    self.logger.debug('Dispatching impression event to URL %s with params %s.' % (\n      impression_event.url,\n      impression_event.params\n    ))\n\n    try:\n      self.event_dispatcher.dispatch_event(impression_event)\n    except:\n      self.logger.exception('Unable to dispatch impression event!')\n\n    self.notification_center.send_notifications(enums.NotificationTypes.ACTIVATE,\n                                                experiment, user_id, attributes, variation, impression_event)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_feature_variable_for_type(self, feature_key, variable_key, variable_type, user_id, attributes):\n    if not validator.is_non_empty_string(feature_key):\n      self.logger.error(enums.Errors.INVALID_INPUT_ERROR.format('feature_key'))\n      return None\n\n    if not validator.is_non_empty_string(variable_key):\n      self.logger.error(enums.Errors.INVALID_INPUT_ERROR.format('variable_key'))\n      return None\n\n    if not isinstance(user_id, string_types):\n      self.logger.error(enums.Errors.INVALID_INPUT_ERROR.format('user_id'))\n      return None\n\n    if not self._validate_user_inputs(attributes):\n      return None\n\n    feature_flag = self.config.get_feature_from_key(feature_key)\n    if not feature_flag:\n      return None\n\n    variable = self.config.get_variable_for_feature(feature_key, variable_key)\n    if not variable:\n      return None\n\n    # Return None if type differs\n    if variable.type != variable_type:\n      self.logger.warning(\n        'Requested variable type \"%s\", but variable is of type \"%s\". '\n        'Use correct API to retrieve value. Returning None.' % (variable_type, variable.type)\n      )\n      return None\n\n    feature_enabled = False\n    source_info = {}\n    variable_value = variable.defaultValue\n    decision = self.decision_service.get_variation_for_feature(feature_flag, user_id, attributes)\n    if decision.variation:\n\n      feature_enabled = decision.variation.featureEnabled\n      if feature_enabled:\n        variable_value = self.config.get_variable_value_for_variation(variable, decision.variation)\n        self.logger.info(\n          'Got variable value \"%s\" for variable \"%s\" of feature flag \"%s\".' % (\n            variable_value, variable_key, feature_key\n          )\n        )\n      else:\n        self.logger.info(\n          'Feature \"%s\" for variation \"%s\" is not enabled. '\n          'Returning the default variable value \"%s\".' % (feature_key, decision.variation.key, variable_value)\n        )\n    else:\n      self.logger.info(\n        'User \"%s\" is not in any variation or rollout rule. '\n        'Returning default value for variable \"%s\" of feature flag \"%s\".' % (user_id, variable_key, feature_key)\n      )\n\n    if decision.source == enums.DecisionSources.FEATURE_TEST:\n      source_info = {\n        'experiment_key': decision.experiment.key,\n        'variation_key': decision.variation.key\n      }\n\n    try:\n      actual_value = self.config.get_typecast_value(variable_value, variable_type)\n    except:\n      self.logger.error('Unable to cast value. Returning None.')\n      actual_value = None\n\n    self.notification_center.send_notifications(\n      enums.NotificationTypes.DECISION,\n      enums.DecisionNotificationTypes.FEATURE_VARIABLE,\n      user_id,\n      attributes or {},\n      {\n        'feature_key': feature_key,\n        'feature_enabled': feature_enabled,\n        'source': decision.source,\n        'variable_key': variable_key,\n        'variable_value': actual_value,\n        'variable_type': variable_type,\n        'source_info': source_info\n      }\n    )\n    return actual_value", "response": "Helper method to determine the value of a certain variable attached to a feature flag based on type of variable."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nactivate a user in an experiment and dispatches an impression event to Optimizely.", "response": "def activate(self, experiment_key, user_id, attributes=None):\n    \"\"\" Buckets visitor and sends impression event to Optimizely.\n\n    Args:\n      experiment_key: Experiment which needs to be activated.\n      user_id: ID for user.\n      attributes: Dict representing user attributes and values which need to be recorded.\n\n    Returns:\n      Variation key representing the variation the user will be bucketed in.\n      None if user is not in experiment or if experiment is not Running.\n    \"\"\"\n\n    if not self.is_valid:\n      self.logger.error(enums.Errors.INVALID_DATAFILE.format('activate'))\n      return None\n\n    if not validator.is_non_empty_string(experiment_key):\n      self.logger.error(enums.Errors.INVALID_INPUT_ERROR.format('experiment_key'))\n      return None\n\n    if not isinstance(user_id, string_types):\n      self.logger.error(enums.Errors.INVALID_INPUT_ERROR.format('user_id'))\n      return None\n\n    variation_key = self.get_variation(experiment_key, user_id, attributes)\n\n    if not variation_key:\n      self.logger.info('Not activating user \"%s\".' % user_id)\n      return None\n\n    experiment = self.config.get_experiment_from_key(experiment_key)\n    variation = self.config.get_variation_from_key(experiment_key, variation_key)\n\n    # Create and dispatch impression event\n    self.logger.info('Activating user \"%s\" in experiment \"%s\".' % (user_id, experiment.key))\n    self._send_impression_event(experiment, variation, user_id, attributes)\n\n    return variation.key"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef track(self, event_key, user_id, attributes=None, event_tags=None):\n\n    if not self.is_valid:\n      self.logger.error(enums.Errors.INVALID_DATAFILE.format('track'))\n      return\n\n    if not validator.is_non_empty_string(event_key):\n      self.logger.error(enums.Errors.INVALID_INPUT_ERROR.format('event_key'))\n      return\n\n    if not isinstance(user_id, string_types):\n      self.logger.error(enums.Errors.INVALID_INPUT_ERROR.format('user_id'))\n      return\n\n    if not self._validate_user_inputs(attributes, event_tags):\n      return\n\n    event = self.config.get_event(event_key)\n    if not event:\n      self.logger.info('Not tracking user \"%s\" for event \"%s\".' % (user_id, event_key))\n      return\n\n    conversion_event = self.event_builder.create_conversion_event(event_key, user_id, attributes, event_tags)\n    self.logger.info('Tracking event \"%s\" for user \"%s\".' % (event_key, user_id))\n    self.logger.debug('Dispatching conversion event to URL %s with params %s.' % (\n      conversion_event.url,\n      conversion_event.params\n    ))\n    try:\n      self.event_dispatcher.dispatch_event(conversion_event)\n    except:\n      self.logger.exception('Unable to dispatch conversion event!')\n    self.notification_center.send_notifications(enums.NotificationTypes.TRACK, event_key, user_id,\n                                                attributes, event_tags, conversion_event)", "response": "Send a conversion event to Optimizely."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting variation for a user in a given experiment.", "response": "def get_variation(self, experiment_key, user_id, attributes=None):\n    \"\"\" Gets variation where user will be bucketed.\n\n    Args:\n      experiment_key: Experiment for which user variation needs to be determined.\n      user_id: ID for user.\n      attributes: Dict representing user attributes.\n\n    Returns:\n      Variation key representing the variation the user will be bucketed in.\n      None if user is not in experiment or if experiment is not Running.\n    \"\"\"\n\n    if not self.is_valid:\n      self.logger.error(enums.Errors.INVALID_DATAFILE.format('get_variation'))\n      return None\n\n    if not validator.is_non_empty_string(experiment_key):\n      self.logger.error(enums.Errors.INVALID_INPUT_ERROR.format('experiment_key'))\n      return None\n\n    if not isinstance(user_id, string_types):\n      self.logger.error(enums.Errors.INVALID_INPUT_ERROR.format('user_id'))\n      return None\n\n    experiment = self.config.get_experiment_from_key(experiment_key)\n    variation_key = None\n\n    if not experiment:\n      self.logger.info('Experiment key \"%s\" is invalid. Not activating user \"%s\".' % (\n        experiment_key,\n        user_id\n      ))\n      return None\n\n    if not self._validate_user_inputs(attributes):\n      return None\n\n    variation = self.decision_service.get_variation(experiment, user_id, attributes)\n    if variation:\n      variation_key = variation.key\n\n    if self.config.is_feature_experiment(experiment.id):\n      decision_notification_type = enums.DecisionNotificationTypes.FEATURE_TEST\n    else:\n      decision_notification_type = enums.DecisionNotificationTypes.AB_TEST\n\n    self.notification_center.send_notifications(\n      enums.NotificationTypes.DECISION,\n      decision_notification_type,\n      user_id,\n      attributes or {},\n      {\n         'experiment_key': experiment_key,\n         'variation_key': variation_key\n      }\n    )\n\n    return variation_key"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if the feature is enabled for the given user.", "response": "def is_feature_enabled(self, feature_key, user_id, attributes=None):\n    \"\"\" Returns true if the feature is enabled for the given user.\n\n    Args:\n      feature_key: The key of the feature for which we are determining if it is enabled or not for the given user.\n      user_id: ID for user.\n      attributes: Dict representing user attributes.\n\n    Returns:\n      True if the feature is enabled for the user. False otherwise.\n    \"\"\"\n\n    if not self.is_valid:\n      self.logger.error(enums.Errors.INVALID_DATAFILE.format('is_feature_enabled'))\n      return False\n\n    if not validator.is_non_empty_string(feature_key):\n      self.logger.error(enums.Errors.INVALID_INPUT_ERROR.format('feature_key'))\n      return False\n\n    if not isinstance(user_id, string_types):\n      self.logger.error(enums.Errors.INVALID_INPUT_ERROR.format('user_id'))\n      return False\n\n    if not self._validate_user_inputs(attributes):\n      return False\n\n    feature = self.config.get_feature_from_key(feature_key)\n    if not feature:\n      return False\n\n    feature_enabled = False\n    source_info = {}\n    decision = self.decision_service.get_variation_for_feature(feature, user_id, attributes)\n    is_source_experiment = decision.source == enums.DecisionSources.FEATURE_TEST\n\n    if decision.variation:\n      if decision.variation.featureEnabled is True:\n        feature_enabled = True\n      # Send event if Decision came from an experiment.\n      if is_source_experiment:\n        source_info = {\n          'experiment_key': decision.experiment.key,\n          'variation_key': decision.variation.key\n        }\n        self._send_impression_event(decision.experiment,\n                                    decision.variation,\n                                    user_id,\n                                    attributes)\n\n    if feature_enabled:\n      self.logger.info('Feature \"%s\" is enabled for user \"%s\".' % (feature_key, user_id))\n    else:\n      self.logger.info('Feature \"%s\" is not enabled for user \"%s\".' % (feature_key, user_id))\n\n    self.notification_center.send_notifications(\n        enums.NotificationTypes.DECISION,\n        enums.DecisionNotificationTypes.FEATURE,\n        user_id,\n        attributes or {},\n        {\n          'feature_key': feature_key,\n          'feature_enabled': feature_enabled,\n          'source': decision.source,\n          'source_info': source_info\n        }\n    )\n\n    return feature_enabled"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_enabled_features(self, user_id, attributes=None):\n\n    enabled_features = []\n    if not self.is_valid:\n      self.logger.error(enums.Errors.INVALID_DATAFILE.format('get_enabled_features'))\n      return enabled_features\n\n    if not isinstance(user_id, string_types):\n      self.logger.error(enums.Errors.INVALID_INPUT_ERROR.format('user_id'))\n      return enabled_features\n\n    if not self._validate_user_inputs(attributes):\n      return enabled_features\n\n    for feature in self.config.feature_key_map.values():\n      if self.is_feature_enabled(feature.key, user_id, attributes):\n        enabled_features.append(feature.key)\n\n    return enabled_features", "response": "Returns the list of features that are enabled for the user."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the value of a certain boolean variable attached to a feature flag.", "response": "def get_feature_variable_boolean(self, feature_key, variable_key, user_id, attributes=None):\n    \"\"\" Returns value for a certain boolean variable attached to a feature flag.\n\n    Args:\n      feature_key: Key of the feature whose variable's value is being accessed.\n      variable_key: Key of the variable whose value is to be accessed.\n      user_id: ID for user.\n      attributes: Dict representing user attributes.\n\n    Returns:\n      Boolean value of the variable. None if:\n      - Feature key is invalid.\n      - Variable key is invalid.\n      - Mismatch with type of variable.\n    \"\"\"\n\n    variable_type = entities.Variable.Type.BOOLEAN\n    return self._get_feature_variable_for_type(feature_key, variable_key, variable_type, user_id, attributes)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_feature_variable_double(self, feature_key, variable_key, user_id, attributes=None):\n\n    variable_type = entities.Variable.Type.DOUBLE\n    return self._get_feature_variable_for_type(feature_key, variable_key, variable_type, user_id, attributes)", "response": "Returns the value of a certain double variable attached to a feature flag."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_feature_variable_integer(self, feature_key, variable_key, user_id, attributes=None):\n\n    variable_type = entities.Variable.Type.INTEGER\n    return self._get_feature_variable_for_type(feature_key, variable_key, variable_type, user_id, attributes)", "response": "Returns the value of a certain integer variable attached to a feature flag."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the value of a certain string variable attached to a feature.", "response": "def get_feature_variable_string(self, feature_key, variable_key, user_id, attributes=None):\n    \"\"\" Returns value for a certain string variable attached to a feature.\n\n    Args:\n      feature_key: Key of the feature whose variable's value is being accessed.\n      variable_key: Key of the variable whose value is to be accessed.\n      user_id: ID for user.\n      attributes: Dict representing user attributes.\n\n    Returns:\n      String value of the variable. None if:\n      - Feature key is invalid.\n      - Variable key is invalid.\n      - Mismatch with type of variable.\n    \"\"\"\n\n    variable_type = entities.Variable.Type.STRING\n    return self._get_feature_variable_for_type(feature_key, variable_key, variable_type, user_id, attributes)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nforces a user into a variation for a given experiment.", "response": "def set_forced_variation(self, experiment_key, user_id, variation_key):\n    \"\"\" Force a user into a variation for a given experiment.\n\n    Args:\n     experiment_key: A string key identifying the experiment.\n     user_id: The user ID.\n     variation_key: A string variation key that specifies the variation which the user.\n     will be forced into. If null, then clear the existing experiment-to-variation mapping.\n\n    Returns:\n      A boolean value that indicates if the set completed successfully.\n    \"\"\"\n\n    if not self.is_valid:\n      self.logger.error(enums.Errors.INVALID_DATAFILE.format('set_forced_variation'))\n      return False\n\n    if not validator.is_non_empty_string(experiment_key):\n      self.logger.error(enums.Errors.INVALID_INPUT_ERROR.format('experiment_key'))\n      return False\n\n    if not isinstance(user_id, string_types):\n      self.logger.error(enums.Errors.INVALID_INPUT_ERROR.format('user_id'))\n      return False\n\n    return self.config.set_forced_variation(experiment_key, user_id, variation_key)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_forced_variation(self, experiment_key, user_id):\n\n    if not self.is_valid:\n      self.logger.error(enums.Errors.INVALID_DATAFILE.format('get_forced_variation'))\n      return None\n\n    if not validator.is_non_empty_string(experiment_key):\n      self.logger.error(enums.Errors.INVALID_INPUT_ERROR.format('experiment_key'))\n      return None\n\n    if not isinstance(user_id, string_types):\n      self.logger.error(enums.Errors.INVALID_INPUT_ERROR.format('user_id'))\n      return None\n\n    forced_variation = self.config.get_forced_variation(experiment_key, user_id)\n    return forced_variation.key if forced_variation else None", "response": "Gets the forced variation for a given user and experiment."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_user_in_experiment(config, experiment, attributes, logger):\n\n  audience_conditions = experiment.getAudienceConditionsOrIds()\n\n  logger.debug(audience_logs.EVALUATING_AUDIENCES_COMBINED.format(\n    experiment.key,\n    json.dumps(audience_conditions)\n  ))\n\n  # Return True in case there are no audiences\n  if audience_conditions is None or audience_conditions == []:\n    logger.info(audience_logs.AUDIENCE_EVALUATION_RESULT_COMBINED.format(\n      experiment.key,\n      'TRUE'\n    ))\n\n    return True\n\n  if attributes is None:\n    attributes = {}\n\n  def evaluate_custom_attr(audienceId, index):\n    audience = config.get_audience(audienceId)\n    custom_attr_condition_evaluator = condition_helper.CustomAttributeConditionEvaluator(\n      audience.conditionList, attributes, logger)\n\n    return custom_attr_condition_evaluator.evaluate(index)\n\n  def evaluate_audience(audienceId):\n    audience = config.get_audience(audienceId)\n\n    if audience is None:\n      return None\n\n    logger.debug(audience_logs.EVALUATING_AUDIENCE.format(audienceId, audience.conditions))\n\n    result = condition_tree_evaluator.evaluate(\n      audience.conditionStructure,\n      lambda index: evaluate_custom_attr(audienceId, index)\n    )\n\n    result_str = str(result).upper() if result is not None else 'UNKNOWN'\n    logger.info(audience_logs.AUDIENCE_EVALUATION_RESULT.format(audienceId, result_str))\n\n    return result\n\n  eval_result = condition_tree_evaluator.evaluate(\n    audience_conditions,\n    evaluate_audience\n  )\n\n  eval_result = eval_result or False\n\n  logger.info(audience_logs.AUDIENCE_EVALUATION_RESULT_COMBINED.format(\n      experiment.key,\n      str(eval_result).upper()\n    ))\n\n  return eval_result", "response": "Determines if a user is in given experiment."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets params which are used same in both conversion and impression events.", "response": "def _get_common_params(self, user_id, attributes):\n    \"\"\" Get params which are used same in both conversion and impression events.\n\n    Args:\n      user_id: ID for user.\n      attributes: Dict representing user attributes and values which need to be recorded.\n\n    Returns:\n     Dict consisting of parameters common to both impression and conversion events.\n    \"\"\"\n    commonParams = {}\n\n    commonParams[self.EventParams.PROJECT_ID] = self._get_project_id()\n    commonParams[self.EventParams.ACCOUNT_ID] = self._get_account_id()\n\n    visitor = {}\n    visitor[self.EventParams.END_USER_ID] = user_id\n    visitor[self.EventParams.SNAPSHOTS] = []\n\n    commonParams[self.EventParams.USERS] = []\n    commonParams[self.EventParams.USERS].append(visitor)\n    commonParams[self.EventParams.USERS][0][self.EventParams.ATTRIBUTES] = self._get_attributes(attributes)\n\n    commonParams[self.EventParams.SOURCE_SDK_TYPE] = 'python-sdk'\n    commonParams[self.EventParams.ENRICH_DECISIONS] = True\n    commonParams[self.EventParams.SOURCE_SDK_VERSION] = version.__version__\n    commonParams[self.EventParams.ANONYMIZE_IP] = self._get_anonymize_ip()\n    commonParams[self.EventParams.REVISION] = self._get_revision()\n\n    return commonParams"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_attributes(self, attributes):\n\n    params = []\n\n    if isinstance(attributes, dict):\n      for attribute_key in attributes.keys():\n        attribute_value = attributes.get(attribute_key)\n        # Omit attribute values that are not supported by the log endpoint.\n        if validator.is_attribute_valid(attribute_key, attribute_value):\n          attribute_id = self.config.get_attribute_id(attribute_key)\n          if attribute_id:\n            params.append({\n              'entity_id': attribute_id,\n              'key': attribute_key,\n              'type': self.EventParams.CUSTOM,\n              'value': attribute_value\n            })\n\n    # Append Bot Filtering Attribute\n    bot_filtering_value = self._get_bot_filtering()\n    if isinstance(bot_filtering_value, bool):\n      params.append({\n          'entity_id': enums.ControlAttributes.BOT_FILTERING,\n          'key': enums.ControlAttributes.BOT_FILTERING,\n          'type': self.EventParams.CUSTOM,\n          'value': bot_filtering_value\n      })\n\n    return params", "response": "Get the user s attributes and values which need to be recorded."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a dictionary of parameters that are required for the impression event to be recorded.", "response": "def _get_required_params_for_impression(self, experiment, variation_id):\n    \"\"\" Get parameters that are required for the impression event to register.\n\n    Args:\n      experiment: Experiment for which impression needs to be recorded.\n      variation_id: ID for variation which would be presented to user.\n\n    Returns:\n      Dict consisting of decisions and events info for impression event.\n    \"\"\"\n    snapshot = {}\n\n    snapshot[self.EventParams.DECISIONS] = [{\n      self.EventParams.EXPERIMENT_ID: experiment.id,\n      self.EventParams.VARIATION_ID: variation_id,\n      self.EventParams.CAMPAIGN_ID: experiment.layerId\n    }]\n\n    snapshot[self.EventParams.EVENTS] = [{\n      self.EventParams.EVENT_ID: experiment.layerId,\n      self.EventParams.TIME: self._get_time(),\n      self.EventParams.KEY: 'campaign_activated',\n      self.EventParams.UUID: str(uuid.uuid4())\n    }]\n\n    return snapshot"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the parameters that are required for the conversion event.", "response": "def _get_required_params_for_conversion(self, event_key, event_tags):\n    \"\"\" Get parameters that are required for the conversion event to register.\n\n    Args:\n      event_key: Key representing the event which needs to be recorded.\n      event_tags: Dict representing metadata associated with the event.\n\n    Returns:\n      Dict consisting of the decisions and events info for conversion event.\n    \"\"\"\n    snapshot = {}\n\n    event_dict = {\n      self.EventParams.EVENT_ID: self.config.get_event(event_key).id,\n      self.EventParams.TIME: self._get_time(),\n      self.EventParams.KEY: event_key,\n      self.EventParams.UUID: str(uuid.uuid4())\n    }\n\n    if event_tags:\n      revenue_value = event_tag_utils.get_revenue_value(event_tags)\n      if revenue_value is not None:\n        event_dict[event_tag_utils.REVENUE_METRIC_TYPE] = revenue_value\n\n      numeric_value = event_tag_utils.get_numeric_value(event_tags, self.config.logger)\n      if numeric_value is not None:\n        event_dict[event_tag_utils.NUMERIC_METRIC_TYPE] = numeric_value\n\n      if len(event_tags) > 0:\n        event_dict[self.EventParams.TAGS] = event_tags\n\n    snapshot[self.EventParams.EVENTS] = [event_dict]\n    return snapshot"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating an impression event.", "response": "def create_impression_event(self, experiment, variation_id, user_id, attributes):\n    \"\"\" Create impression Event to be sent to the logging endpoint.\n\n    Args:\n      experiment: Experiment for which impression needs to be recorded.\n      variation_id: ID for variation which would be presented to user.\n      user_id: ID for user.\n      attributes: Dict representing user attributes and values which need to be recorded.\n\n    Returns:\n      Event object encapsulating the impression event.\n    \"\"\"\n\n    params = self._get_common_params(user_id, attributes)\n    impression_params = self._get_required_params_for_impression(experiment, variation_id)\n\n    params[self.EventParams.USERS][0][self.EventParams.SNAPSHOTS].append(impression_params)\n\n    return Event(self.EVENTS_URL,\n                 params,\n                 http_verb=self.HTTP_VERB,\n                 headers=self.HTTP_HEADERS)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a conversion event.", "response": "def create_conversion_event(self, event_key, user_id, attributes, event_tags):\n    \"\"\" Create conversion Event to be sent to the logging endpoint.\n\n    Args:\n      event_key: Key representing the event which needs to be recorded.\n      user_id: ID for user.\n      attributes: Dict representing user attributes and values.\n      event_tags: Dict representing metadata associated with the event.\n\n    Returns:\n      Event object encapsulating the conversion event.\n    \"\"\"\n\n    params = self._get_common_params(user_id, attributes)\n    conversion_params = self._get_required_params_for_conversion(event_key, event_tags)\n\n    params[self.EventParams.USERS][0][self.EventParams.SNAPSHOTS].append(conversion_params)\n    return Event(self.EVENTS_URL,\n                 params,\n                 http_verb=self.HTTP_VERB,\n                 headers=self.HTTP_HEADERS)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef loads(conditions_string):\n  decoder = ConditionDecoder(_audience_condition_deserializer)\n\n  # Create a custom JSONDecoder using the ConditionDecoder's object_hook method\n  # to create the condition_structure as well as populate the condition_list\n  json_decoder = json.JSONDecoder(object_hook=decoder.object_hook)\n\n  # Perform the decoding\n  condition_structure = json_decoder.decode(conditions_string)\n  condition_list = decoder.condition_list\n\n  return (condition_structure, condition_list)", "response": "Deserializes the conditions property into its corresponding\n components."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_condition_json(self, index):\n    condition = self.condition_data[index]\n    condition_log = {\n      'name': condition[0],\n      'value': condition[1],\n      'type': condition[2],\n      'match': condition[3]\n    }\n\n    return json.dumps(condition_log)", "response": "Method to generate json for logging audience condition."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef exists_evaluator(self, index):\n    attr_name = self.condition_data[index][0]\n    return self.attributes.get(attr_name) is not None", "response": "Evaluate the given exists match condition for the user attributes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nevaluate the given greater than match condition for the user attributes.", "response": "def greater_than_evaluator(self, index):\n    \"\"\" Evaluate the given greater than match condition for the user attributes.\n\n      Args:\n        index: Index of the condition to be evaluated.\n\n      Returns:\n        Boolean:\n          - True if the user attribute value is greater than the condition value.\n          - False if the user attribute value is less than or equal to the condition value.\n        None: if the condition value isn't finite or the user attribute value isn't finite.\n    \"\"\"\n    condition_name = self.condition_data[index][0]\n    condition_value = self.condition_data[index][1]\n    user_value = self.attributes.get(condition_name)\n\n    if not validator.is_finite_number(condition_value):\n      self.logger.warning(audience_logs.UNKNOWN_CONDITION_VALUE.format(\n        self._get_condition_json(index)\n      ))\n      return None\n\n    if not self.is_value_a_number(user_value):\n      self.logger.warning(audience_logs.UNEXPECTED_TYPE.format(\n          self._get_condition_json(index),\n          type(user_value),\n          condition_name\n      ))\n      return None\n\n    if not validator.is_finite_number(user_value):\n      self.logger.warning(audience_logs.INFINITE_ATTRIBUTE_VALUE.format(\n        self._get_condition_json(index),\n        condition_name\n      ))\n      return None\n\n    return user_value > condition_value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nevaluating the given substring match condition for the given user attributes.", "response": "def substring_evaluator(self, index):\n    \"\"\" Evaluate the given substring match condition for the given user attributes.\n\n    Args:\n      index: Index of the condition to be evaluated.\n\n    Returns:\n      Boolean:\n        - True if the condition value is a substring of the user attribute value.\n        - False if the condition value is not a substring of the user attribute value.\n      None: if the condition value isn't a string or the user attribute value isn't a string.\n    \"\"\"\n    condition_name = self.condition_data[index][0]\n    condition_value = self.condition_data[index][1]\n    user_value = self.attributes.get(condition_name)\n\n    if not isinstance(condition_value, string_types):\n      self.logger.warning(audience_logs.UNKNOWN_CONDITION_VALUE.format(\n        self._get_condition_json(index),\n      ))\n      return None\n\n    if not isinstance(user_value, string_types):\n      self.logger.warning(audience_logs.UNEXPECTED_TYPE.format(\n          self._get_condition_json(index),\n          type(user_value),\n          condition_name\n      ))\n      return None\n\n    return condition_value in user_value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef evaluate(self, index):\n\n    if self.condition_data[index][2] != self.CUSTOM_ATTRIBUTE_CONDITION_TYPE:\n      self.logger.warning(audience_logs.UNKNOWN_CONDITION_TYPE.format(self._get_condition_json(index)))\n      return None\n\n    condition_match = self.condition_data[index][3]\n    if condition_match is None:\n      condition_match = ConditionMatchTypes.EXACT\n\n    if condition_match not in self.EVALUATORS_BY_MATCH_TYPE:\n      self.logger.warning(audience_logs.UNKNOWN_MATCH_TYPE.format(self._get_condition_json(index)))\n      return None\n\n    if condition_match != ConditionMatchTypes.EXISTS:\n      attribute_key = self.condition_data[index][0]\n      if attribute_key not in self.attributes:\n        self.logger.debug(audience_logs.MISSING_ATTRIBUTE_VALUE.format(self._get_condition_json(index), attribute_key))\n        return None\n\n      if self.attributes.get(attribute_key) is None:\n        self.logger.debug(audience_logs.NULL_ATTRIBUTE_VALUE.format(self._get_condition_json(index), attribute_key))\n        return None\n\n    return self.EVALUATORS_BY_MATCH_TYPE[condition_match](self, index)", "response": "Evaluates the audience condition against the user attributes."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef object_hook(self, object_dict):\n    instance = self.decoder(object_dict)\n    self.condition_list.append(instance)\n    self.index += 1\n    return self.index", "response": "Hook which will be called by the json. JSONDecoder to convert each dict into an object and add it to the condition_list."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_bucketing_id(self, user_id, attributes):\n\n    attributes = attributes or {}\n    bucketing_id = attributes.get(enums.ControlAttributes.BUCKETING_ID)\n\n    if bucketing_id is not None:\n      if isinstance(bucketing_id, string_types):\n        return bucketing_id\n\n      self.logger.warning('Bucketing ID attribute is not a string. Defaulted to user_id.')\n\n    return user_id", "response": "Helper method to determine the bucketing ID for the user."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndetermines if a user is forced into a variation for the given experiment and returns that variation.", "response": "def get_forced_variation(self, experiment, user_id):\n    \"\"\" Determine if a user is forced into a variation for the given experiment and return that variation.\n\n    Args:\n      experiment: Object representing the experiment for which user is to be bucketed.\n      user_id: ID for the user.\n\n    Returns:\n      Variation in which the user with ID user_id is forced into. None if no variation.\n    \"\"\"\n\n    forced_variations = experiment.forcedVariations\n    if forced_variations and user_id in forced_variations:\n      variation_key = forced_variations.get(user_id)\n      variation = self.config.get_variation_from_key(experiment.key, variation_key)\n      if variation:\n        self.logger.info('User \"%s\" is forced in variation \"%s\".' % (user_id, variation_key))\n      return variation\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_stored_variation(self, experiment, user_profile):\n\n    user_id = user_profile.user_id\n    variation_id = user_profile.get_variation_for_experiment(experiment.id)\n\n    if variation_id:\n      variation = self.config.get_variation_from_id(experiment.key, variation_id)\n      if variation:\n        self.logger.info('Found a stored decision. User \"%s\" is in variation \"%s\" of experiment \"%s\".' % (\n          user_id,\n          variation.key,\n          experiment.key\n        ))\n        return variation\n\n    return None", "response": "Determines if the user has a stored variation available for the given experiment and returns that."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_variation_for_rollout(self, rollout, user_id, attributes=None):\n\n    # Go through each experiment in order and try to get the variation for the user\n    if rollout and len(rollout.experiments) > 0:\n      for idx in range(len(rollout.experiments) - 1):\n        experiment = self.config.get_experiment_from_key(rollout.experiments[idx].get('key'))\n\n        # Check if user meets audience conditions for targeting rule\n        if not audience_helper.is_user_in_experiment(self.config, experiment, attributes, self.logger):\n          self.logger.debug('User \"%s\" does not meet conditions for targeting rule %s.' % (\n            user_id,\n            idx + 1\n          ))\n          continue\n\n        self.logger.debug('User \"%s\" meets conditions for targeting rule %s.' % (user_id, idx + 1))\n        # Determine bucketing ID to be used\n        bucketing_id = self._get_bucketing_id(user_id, attributes)\n        variation = self.bucketer.bucket(experiment, user_id, bucketing_id)\n        if variation:\n          self.logger.debug('User \"%s\" is in variation %s of experiment %s.' % (\n            user_id,\n            variation.key,\n            experiment.key\n          ))\n          return Decision(experiment, variation, enums.DecisionSources.ROLLOUT)\n        else:\n          # Evaluate no further rules\n          self.logger.debug('User \"%s\" is not in the traffic group for the targeting else. '\n                            'Checking \"Everyone Else\" rule now.' % user_id)\n          break\n\n      # Evaluate last rule i.e. \"Everyone Else\" rule\n      everyone_else_experiment = self.config.get_experiment_from_key(rollout.experiments[-1].get('key'))\n      if audience_helper.is_user_in_experiment(self.config,\n                                               self.config.get_experiment_from_key(rollout.experiments[-1].get('key')),\n                                               attributes,\n                                               self.logger):\n        # Determine bucketing ID to be used\n        bucketing_id = self._get_bucketing_id(user_id, attributes)\n        variation = self.bucketer.bucket(everyone_else_experiment, user_id, bucketing_id)\n        if variation:\n          self.logger.debug('User \"%s\" meets conditions for targeting rule \"Everyone Else\".' % user_id)\n          return Decision(everyone_else_experiment, variation, enums.DecisionSources.ROLLOUT)\n\n    return Decision(None, None, enums.DecisionSources.ROLLOUT)", "response": "Returns the variation for a given user in a given rollout."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndetermines which experiment in the specified group is bucketed into. Returns None if the user is not bucketed into an experiment.", "response": "def get_experiment_in_group(self, group, bucketing_id):\n    \"\"\" Determine which experiment in the group the user is bucketed into.\n\n    Args:\n      group: The group to bucket the user into.\n      bucketing_id: ID to be used for bucketing the user.\n\n    Returns:\n      Experiment if the user is bucketed into an experiment in the specified group. None otherwise.\n    \"\"\"\n\n    experiment_id = self.bucketer.find_bucket(bucketing_id, group.id, group.trafficAllocation)\n    if experiment_id:\n      experiment = self.config.get_experiment_from_id(experiment_id)\n      if experiment:\n        self.logger.info('User with bucketing ID \"%s\" is in experiment %s of group %s.' % (\n          bucketing_id,\n          experiment.key,\n          group.id\n        ))\n        return experiment\n\n    self.logger.info('User with bucketing ID \"%s\" is not in any experiments of group %s.' % (\n      bucketing_id,\n      group.id\n    ))\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the experiment and variation for the given feature and user.", "response": "def get_variation_for_feature(self, feature, user_id, attributes=None):\n    \"\"\" Returns the experiment/variation the user is bucketed in for the given feature.\n\n    Args:\n      feature: Feature for which we are determining if it is enabled or not for the given user.\n      user_id: ID for user.\n      attributes: Dict representing user attributes.\n\n    Returns:\n      Decision namedtuple consisting of experiment and variation for the user.\n    \"\"\"\n\n    experiment = None\n    variation = None\n    bucketing_id = self._get_bucketing_id(user_id, attributes)\n\n    # First check if the feature is in a mutex group\n    if feature.groupId:\n      group = self.config.get_group(feature.groupId)\n      if group:\n        experiment = self.get_experiment_in_group(group, bucketing_id)\n        if experiment and experiment.id in feature.experimentIds:\n          variation = self.get_variation(experiment, user_id, attributes)\n\n          if variation:\n            self.logger.debug('User \"%s\" is in variation %s of experiment %s.' % (\n              user_id,\n              variation.key,\n              experiment.key\n            ))\n            return Decision(experiment, variation, enums.DecisionSources.FEATURE_TEST)\n      else:\n        self.logger.error(enums.Errors.INVALID_GROUP_ID_ERROR.format('_get_variation_for_feature'))\n\n    # Next check if the feature is being experimented on\n    elif feature.experimentIds:\n      # If an experiment is not in a group, then the feature can only be associated with one experiment\n      experiment = self.config.get_experiment_from_id(feature.experimentIds[0])\n      if experiment:\n        variation = self.get_variation(experiment, user_id, attributes)\n\n        if variation:\n          self.logger.debug('User \"%s\" is in variation %s of experiment %s.' % (\n            user_id,\n            variation.key,\n            experiment.key\n          ))\n          return Decision(experiment, variation, enums.DecisionSources.FEATURE_TEST)\n\n    # Next check if user is part of a rollout\n    if feature.rolloutId:\n      rollout = self.config.get_rollout_from_id(feature.rolloutId)\n      return self.get_variation_for_rollout(rollout, user_id, attributes)\n    else:\n      return Decision(None, None, enums.DecisionSources.ROLLOUT)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a notification listener to the notification center.", "response": "def add_notification_listener(self, notification_type, notification_callback):\n    \"\"\" Add a notification callback to the notification center.\n\n    Args:\n      notification_type: A string representing the notification type from .helpers.enums.NotificationTypes\n      notification_callback: closure of function to call when event is triggered.\n\n    Returns:\n      Integer notification id used to remove the notification or -1 if the notification has already been added.\n    \"\"\"\n\n    if notification_type not in self.notifications:\n      self.notifications[notification_type] = [(self.notification_id, notification_callback)]\n    else:\n      if reduce(lambda a, b: a + 1,\n                filter(lambda tup: tup[1] == notification_callback, self.notifications[notification_type]),\n                0) > 0:\n          return -1\n      self.notifications[notification_type].append((self.notification_id, notification_callback))\n\n    ret_val = self.notification_id\n\n    self.notification_id += 1\n\n    return ret_val"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove_notification_listener(self, notification_id):\n\n    for v in self.notifications.values():\n      toRemove = list(filter(lambda tup: tup[0] == notification_id, v))\n      if len(toRemove) > 0:\n        v.remove(toRemove[0])\n        return True\n\n    return False", "response": "Removes a previously added notification callback."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef send_notifications(self, notification_type, *args):\n\n    if notification_type in self.notifications:\n      for notification_id, callback in self.notifications[notification_type]:\n        try:\n          callback(*args)\n        except:\n          self.logger.exception('Problem calling notify callback!')", "response": "Fires off the notification for the specific event."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nevaluating a list of conditions as if the evaluator had been applied to each entry and returns True if all operands evaluate to True otherwise False.", "response": "def and_evaluator(conditions, leaf_evaluator):\n  \"\"\" Evaluates a list of conditions as if the evaluator had been applied\n  to each entry and the results AND-ed together.\n\n  Args:\n    conditions: List of conditions ex: [operand_1, operand_2].\n    leaf_evaluator: Function which will be called to evaluate leaf condition values.\n\n  Returns:\n    Boolean:\n      - True if all operands evaluate to True.\n      - False if a single operand evaluates to False.\n    None: if conditions couldn't be evaluated.\n  \"\"\"\n  saw_null_result = False\n\n  for condition in conditions:\n    result = evaluate(condition, leaf_evaluator)\n    if result is False:\n      return False\n    if result is None:\n      saw_null_result = True\n\n  return None if saw_null_result else True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nevaluates a list of conditions as if the evaluator had been applied to a single entry and NOT was applied to the result.", "response": "def not_evaluator(conditions, leaf_evaluator):\n  \"\"\" Evaluates a list of conditions as if the evaluator had been applied\n  to a single entry and NOT was applied to the result.\n\n  Args:\n    conditions: List of conditions ex: [operand_1, operand_2].\n    leaf_evaluator: Function which will be called to evaluate leaf condition values.\n\n  Returns:\n    Boolean:\n      - True if the operand evaluates to False.\n      - False if the operand evaluates to True.\n    None: if conditions is empty or condition couldn't be evaluated.\n  \"\"\"\n  if not len(conditions) > 0:\n    return None\n\n  result = evaluate(conditions[0], leaf_evaluator)\n  return None if result is None else not result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef evaluate(conditions, leaf_evaluator):\n\n  if isinstance(conditions, list):\n    if conditions[0] in list(EVALUATORS_BY_OPERATOR_TYPE.keys()):\n      return EVALUATORS_BY_OPERATOR_TYPE[conditions[0]](conditions[1:], leaf_evaluator)\n    else:\n      # assume OR when operator is not explicit.\n      return EVALUATORS_BY_OPERATOR_TYPE[ConditionOperatorTypes.OR](conditions, leaf_evaluator)\n\n  leaf_condition = conditions\n  return leaf_evaluator(leaf_condition)", "response": "Evaluates the conditions using the operator rules and the evaluator function."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef data_objet_class(data_mode='value', time_mode='framewise'):\n    classes_table = {('value', 'global'): GlobalValueObject,\n                     ('value', 'event'): EventValueObject,\n                     ('value', 'segment'): SegmentValueObject,\n                     ('value', 'framewise'): FrameValueObject,\n                     ('label', 'global'): GlobalLabelObject,\n                     ('label', 'event'): EventLabelObject,\n                     ('label', 'segment'): SegmentLabelObject,\n                     ('label', 'framewise'): FrameLabelObject}\n\n    try:\n        return classes_table[(data_mode, time_mode)]\n    except KeyError as e:\n        raise ValueError('Wrong arguments')", "response": "Returns the object class for the data object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef JSON_NumpyArrayEncoder(obj):\n    '''Define Specialize JSON encoder for numpy array'''\n    if isinstance(obj, np.ndarray):\n        return {'numpyArray': obj.tolist(),\n                'dtype': obj.dtype.__str__()}\n    elif isinstance(obj, np.generic):\n        return np.asscalar(obj)\n    else:\n        print type(obj)\n        raise TypeError(repr(obj) + \" is not JSON serializable\")", "response": "Define Specialize JSON encoder for numpy arrays"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_hdf5(self, h5group):\n        # Write attributes\n        name = 'label_type'\n        if self.__getattribute__(name) is not None:\n            h5group.attrs[name] = self.__getattribute__(name)\n\n        for name in ['label', 'description']:\n            subgroup = h5group.create_group(name)\n            if self.__getattribute__(name):\n                hdf5.dict_to_hdf5(self.__getattribute__(name), subgroup)", "response": "Save a dictionnary - like object inside a h5 file group\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef render(self):\n        '''Render a matplotlib figure from the analyzer result\n\n           Return the figure, use fig.show() to display if neeeded\n        '''\n\n        fig, ax = plt.subplots()\n        self.data_object._render_plot(ax)\n        return fig", "response": "Render a matplotlib figure from the analyzer result\n           Return the figure"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a new result object with the same attributes as the current one.", "response": "def new_result(self, data_mode='value', time_mode='framewise'):\n        '''\n        Create a new result\n\n        Attributes\n        ----------\n        data_object : MetadataObject\n        id_metadata : MetadataObject\n        audio_metadata : MetadataObject\n        frame_metadata : MetadataObject\n        label_metadata : MetadataObject\n        parameters : dict\n\n        '''\n\n        from datetime import datetime\n\n        result = AnalyzerResult(data_mode=data_mode,\n                                time_mode=time_mode)\n\n        # Automatically write known metadata\n        result.id_metadata.date = datetime.now().replace(\n            microsecond=0).isoformat(' ')\n        result.id_metadata.version = timeside.core.__version__\n        result.id_metadata.author = 'TimeSide'\n        result.id_metadata.id = self.id()\n        result.id_metadata.name = self.name()\n        result.id_metadata.description = self.description()\n        result.id_metadata.unit = self.unit()\n        result.id_metadata.proc_uuid = self.uuid()\n\n        result.audio_metadata.uri = self.mediainfo()['uri']\n        result.audio_metadata.sha1 = self.mediainfo()['sha1']\n        result.audio_metadata.start = self.mediainfo()['start']\n        result.audio_metadata.duration = self.mediainfo()['duration']\n        result.audio_metadata.is_segment = self.mediainfo()['is_segment']\n        result.audio_metadata.channels = self.channels()\n\n        result.parameters = Parameters(self.get_parameters())\n\n        if time_mode == 'framewise':\n            result.data_object.frame_metadata.samplerate = self.result_samplerate\n            result.data_object.frame_metadata.blocksize = self.result_blocksize\n            result.data_object.frame_metadata.stepsize = self.result_stepsize\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_uri(self):\n        if self.source_file and os.path.exists(self.source_file.path):\n            return self.source_file.path\n        elif self.source_url:\n            return self.source_url\n        return None", "response": "Return the Item source URI"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_audio_duration(self):\n        decoder = timeside.core.get_processor('file_decoder')(\n            uri=self.get_uri())\n        return decoder.uri_total_duration", "response": "Return item audio duration"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the path to the results directory for this item.", "response": "def get_results_path(self):\n        \"\"\"\n        Return Item result path\n        \"\"\"\n        result_path = os.path.join(RESULTS_ROOT, self.uuid)\n        if not os.path.exists(result_path):\n            os.makedirs(result_path)\n        return result_path"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting numpy array to gstreamer buffer", "response": "def numpy_array_to_gst_buffer(frames, chunk_size, num_samples, sample_rate):\n    from gst import Buffer\n    \"\"\" gstreamer buffer to numpy array conversion \"\"\"\n    buf = Buffer(getbuffer(frames.astype(\"float32\")))\n    # Set its timestamp and duration\n    buf.timestamp = gst.util_uint64_scale(num_samples, gst.SECOND, sample_rate)\n    buf.duration = gst.util_uint64_scale(chunk_size, gst.SECOND, sample_rate)\n    return buf"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef gst_buffer_to_numpy_array(buf, chan):\n    samples = frombuffer(buf.data, dtype='float32').reshape((-1, chan))\n    return samples", "response": "gstreamer buffer to numpy array conversion"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking a media source as a valid file or uri and return the proper uri", "response": "def get_uri(source):\n    \"\"\"\n    Check a media source as a valid file or uri and return the proper uri\n    \"\"\"\n\n    import gst\n\n    src_info = source_info(source)\n\n    if src_info['is_file']:  # Is this a file?\n        return get_uri(src_info['uri'])\n\n    elif gst.uri_is_valid(source):  # Is this a valid URI source for Gstreamer\n        uri_protocol = gst.uri_get_protocol(source)\n        if gst.uri_protocol_is_supported(gst.URI_SRC, uri_protocol):\n            return source\n        else:\n            raise IOError('Invalid URI source for Gstreamer')\n    else:\n        raise IOError('Failed getting uri for path %s: no such file' % source)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sha1sum_file(filename):\n    '''\n    Return the secure hash digest with sha1 algorithm for a given file\n\n    >>> from timeside.core.tools.test_samples import samples\n    >>> wav_file = samples[\"C4_scale.wav\"]\n    >>> print sha1sum_file(wav_file)\n    a598e78d0b5c90da54a77e34c083abdcd38d42ba\n    '''\n    import hashlib\n    import io\n\n    sha1 = hashlib.sha1()\n    chunk_size = sha1.block_size * io.DEFAULT_BUFFER_SIZE\n\n    with open(filename, 'rb') as f:\n        for chunk in iter(lambda: f.read(chunk_size), b''):\n            sha1.update(chunk)\n    return sha1.hexdigest()", "response": "Return the secure hash digest with sha1 algorithm for a given file"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sha1sum_url(url):\n    '''Return the secure hash digest with sha1 algorithm for a given url\n\n    >>> url = \"https://github.com/yomguy/timeside-samples/raw/master/samples/guitar.wav\"\n    >>> print sha1sum_url(url)\n    08301c3f9a8d60926f31e253825cc74263e52ad1\n\n    '''\n    import hashlib\n    import urllib\n    from contextlib import closing\n\n    sha1 = hashlib.sha1()\n    chunk_size = sha1.block_size * 8192\n\n    max_file_size = 10 * 1024 * 1024  # 10Mo limit in case of very large file\n\n    total_read = 0\n    with closing(urllib.urlopen(url)) as url_obj:\n        for chunk in iter(lambda: url_obj.read(chunk_size), b''):\n            sha1.update(chunk)\n            total_read += chunk_size\n            if total_read > max_file_size:\n                break\n\n    return sha1.hexdigest()", "response": "Return the secure hash digest with sha1 algorithm for a given url\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sha1sum_numpy(np_array):\n    '''\n    Return the secure hash digest with sha1 algorithm for a numpy array\n    '''\n    import hashlib\n    return hashlib.sha1(np_array.view(np.uint8)).hexdigest()", "response": "Returns the secure hash digest with sha1 algorithm for a numpy array\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwraps around importlib. import_module to import TimeSide subpackage and ignoring ImportError if Aubio Yaafe and Vamp Host are not available.", "response": "def import_module_with_exceptions(name, package=None):\n    \"\"\"Wrapper around importlib.import_module to import TimeSide subpackage\n    and ignoring ImportError if Aubio, Yaafe and Vamp Host are not available\"\"\"\n\n    from timeside.core import _WITH_AUBIO, _WITH_YAAFE, _WITH_VAMP\n\n    if name.count('.server.'):\n        # TODO:\n        # Temporary skip all timeside.server submodules before check dependencies\n        return\n    try:\n        import_module(name, package)\n    except VampImportError:\n        # No Vamp Host\n        if _WITH_VAMP:\n            raise VampImportError\n        else:\n            # Ignore Vamp ImportError\n            return\n    except ImportError as e:\n        if str(e).count('yaafelib') and not _WITH_YAAFE:\n            # Ignore Yaafe ImportError\n            return\n        elif str(e).count('aubio') and not _WITH_AUBIO:\n            # Ignore Aubio ImportError\n            return\n        elif str(e).count('DJANGO_SETTINGS_MODULE'):\n            # Ignore module requiring DJANGO_SETTINGS_MODULE in environnement\n            return\n        else:\n            print (name, package)\n            raise e\n    return name"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef check_vamp():\n    \"Check Vamp host availability\"\n\n    try:\n        from timeside.plugins.analyzer.externals import vamp_plugin\n    except VampImportError:\n        warnings.warn('Vamp host is not available', ImportWarning,\n                      stacklevel=2)\n        _WITH_VAMP = False\n    else:\n        _WITH_VAMP = True\n        del vamp_plugin\n\n    return _WITH_VAMP", "response": "Check Vamp host availability"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving a list of colors create a larger list of colors interpolating the first one. If flat is True a list of numers will be returned. If flat is False a list of numers will be returned.", "response": "def interpolate_colors(colors, flat=False, num_colors=256):\n    \"\"\" Given a list of colors, create a larger list of colors interpolating\n    the first one. If flatten is True a list of numers will be returned. If\n    False, a list of (r,g,b) tuples. num_colors is the number of colors wanted\n    in the final list \"\"\"\n\n    palette = []\n\n    for i in range(num_colors):\n        index = (i * (len(colors) - 1)) / (num_colors - 1.0)\n        index_int = int(index)\n        alpha = index - float(index_int)\n\n        if alpha > 0:\n            r = (1.0 - alpha) * colors[index_int][\n                0] + alpha * colors[index_int + 1][0]\n            g = (1.0 - alpha) * colors[index_int][\n                1] + alpha * colors[index_int + 1][1]\n            b = (1.0 - alpha) * colors[index_int][\n                2] + alpha * colors[index_int + 1][2]\n        else:\n            r = (1.0 - alpha) * colors[index_int][0]\n            g = (1.0 - alpha) * colors[index_int][1]\n            b = (1.0 - alpha) * colors[index_int][2]\n\n        if flat:\n            palette.extend((int(r), int(g), int(b)))\n        else:\n            palette.append((int(r), int(g), int(b)))\n\n    return palette"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef downsample(vector, factor):\n    if (len(vector) % factor):\n        print \"Length of 'vector' is not divisible by 'factor'=%d!\" % factor\n        return 0\n    vector.shape = (len(vector) / factor, factor)\n    return numpy.mean(vector, axis=1)", "response": "Downsample a vector by an integer factor."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef smooth(x, window_len=10, window='hanning'):\n\n    # TODO: the window parameter could be the window itself if an array\n    # instead of a string\n\n    if x.ndim != 1:\n        raise ValueError(\"smooth only accepts 1 dimension arrays.\")\n    if x.size < window_len:\n        raise ValueError(\"Input vector needs to be bigger than window size.\")\n    if window_len < 3:\n        return x\n    if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:\n        raise ValueError(\"Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\")\n\n    s = numpy.r_[2 * x[0] - x[window_len:1:-1],\n                 x, 2 * x[-1] - x[-1:-window_len:-1]]\n\n    if window == 'flat':  # moving average\n        w = numpy.ones(window_len, 'd')\n    else:\n        w = getattr(numpy, window)(window_len)\n\n    y = numpy.convolve(w / w.sum(), s, mode='same')\n    return y[window_len - 1:-window_len + 1]", "response": "Smooth the data using a scaled window with requested size."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef im_watermark(im, inputtext, font=None, color=None, opacity=.6, margin=(30, 30)):\n    if im.mode != \"RGBA\":\n        im = im.convert(\"RGBA\")\n    textlayer = Image.new(\"RGBA\", im.size, (0, 0, 0, 0))\n    textdraw = ImageDraw.Draw(textlayer)\n    textsize = textdraw.textsize(inputtext, font=font)\n    textpos = [im.size[i] - textsize[i] - margin[i] for i in [0, 1]]\n    textdraw.text(textpos, inputtext, font=font, fill=color)\n    if opacity != 1:\n        textlayer = reduce_opacity(textlayer, opacity)\n    return Image.composite(textlayer, im, textlayer)", "response": "imprints a PIL image with the indicated text in lower - right corner"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef peaks(samples):\n    max_index = numpy.argmax(samples)\n    max_value = samples[max_index]\n\n    min_index = numpy.argmin(samples)\n    min_value = samples[min_index]\n\n    if min_index < max_index:\n        return (min_value, max_value)\n    else:\n        return (max_value, min_value)", "response": "Find the minimum and maximum peak of the samples."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef nextpow2(value):\n    if value >= 1:\n        return 2**np.ceil(np.log2(value)).astype(int)\n    elif value > 0:\n        return 1\n    elif value == 0:\n        return 0\n    else:\n        raise ValueError('Value must be positive')", "response": "Compute the nearest power of two greater or equal to the input value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread the dependencies from a Conda environment file in YAML and return a list of such dependencies.", "response": "def get_dependencies(env_yml_file):\n    \"\"\"\n    Read the dependencies from a Conda environment file in YAML\n    and return a list of such dependencies (from conda and pip list)\n    Be sure to match packages specification for each of:\n    - Conda : http://conda.pydata.org/docs/spec.html#build-version-spec\n    - Pip & Setuptool :\n       - http://pythonhosted.org/setuptools/setuptools.html?highlight=install_require#declaring-dependencies\n       - https://pythonhosted.org/setuptools/pkg_resources.html#requirement-objects\n    \"\"\"\n    import yaml\n    with open_here(env_yml_file) as f:\n        environment = yaml.load(f)\n    conda_dependencies = []\n    package_map = {\n        'pytables': 'tables',  # insert 'tables' instead of 'pytables'\n        'yaafe': '',\n        'essentia': '',\n        'pytorch': '',\n        # Yaafe and essentia are not seen by pip during pip install -e .\n        # and not visible with pip list\n        # TODO: check if setuptools can help\n    }\n    for dep in environment['dependencies']:\n        if isinstance(dep, str) and not(dep.startswith('python')):\n            if dep in package_map:\n                conda_dependencies.append(package_map[dep])\n            else:\n                conda_dependencies.append(dep)\n        elif isinstance(dep, dict) and 'pip' in dep:\n            pip_dependencies = dep['pip']\n\n    return conda_dependencies + pip_dependencies"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef blocksize(self, input_totalframes):\n\n        blocksize = input_totalframes\n        if self.pad:\n            mod = input_totalframes % self.buffer_size\n            if mod:\n                blocksize += self.buffer_size - mod\n\n        return blocksize", "response": "Return the total number of frames that this adapter will output\n            according to the input_totalframes argument."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning an iterator over tuples of the form buffer eod and remaining.", "response": "def process(self, frames, eod):\n        \"\"\"Returns an iterator over tuples of the form (buffer, eod)\n        where buffer is a fixed-sized block of data, and eod indicates whether\n        this is the last block.\n        In case padding is deactivated the last block may be smaller than\n        the buffer size.\n        \"\"\"\n        src_index = 0\n        remaining = len(frames)\n\n        while remaining:\n            space = self.buffer_size - self.len\n            copylen = remaining < space and remaining or space\n            src = frames[src_index:src_index + copylen]\n            if self.len == 0 and copylen == self.buffer_size:\n                # avoid unnecessary copy\n                buffer = src\n            else:\n                buffer = self.buffer\n                buffer[self.len:self.len + copylen] = src\n\n            remaining -= copylen\n            src_index += copylen\n            self.len += copylen\n\n            if self.len == self.buffer_size:\n                yield buffer, (eod and not remaining)\n                self.len = 0\n\n        if eod and self.len:\n            block = self.buffer\n            if self.pad:\n                self.buffer[self.len:self.buffer_size] = 0\n            else:\n                block = self.buffer[0:self.len]\n\n            yield block, True\n            self.len = 0"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nappending a new processor to the pipe", "response": "def append_processor(self, proc, source_proc=None):\n        \"Append a new processor to the pipe\"\n        if source_proc is None and len(self.processors):\n            source_proc = self.processors[0]\n\n        if source_proc and not isinstance(source_proc, Processor):\n            raise TypeError('source_proc must be a Processor or None')\n\n        if not isinstance(proc, Processor):\n            raise TypeError('proc must be a Processor or None')\n\n        if proc.type == 'decoder' and len(self.processors):\n            raise ValueError('Only the first processor in a pipe could be a Decoder')\n\n        # TODO : check if the processor is already in the pipe\n        if source_proc:\n            for child in self._graph.neighbors_iter(source_proc.uuid()):\n                child_proc = self._graph.node[child]['processor']\n                if proc == child_proc:\n                    proc._uuid = child_proc.uuid()\n                    proc.process_pipe = self\n                    break\n        if not self._graph.has_node(proc.uuid()):\n            self.processors.append(proc)  # Add processor to the pipe\n            self._graph.add_node(proc.uuid(), processor=proc, id=proc.id())\n            if source_proc:\n                self._graph.add_edge(self.processors[0].uuid(), proc.uuid(),\n                                     type='audio_source')\n            proc.process_pipe = self\n            # Add an edge between each parent and proc\n            for parent in proc.parents.values():\n                self._graph.add_edge(parent.uuid(), proc.uuid(),\n                                     type='data_source')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run(self, channels=None, samplerate=None, blocksize=None):\n\n        source = self.processors[0]\n        items = self.processors[1:]\n\n        # Check if any processor in items need to force the samplerate\n        force_samplerate = set([item.force_samplerate for item in items\n                                if item.force_samplerate])\n        if force_samplerate:\n            if len(force_samplerate) > 1:\n                raise(ValueError,\n                      \"Some processors specify different samplerate\")\n            force_samplerate = force_samplerate.pop()\n\n            if samplerate and samplerate != force_samplerate:\n                raise(ValueError, \"A processor try to force the samplerate\")\n\n            samplerate = force_samplerate\n\n        source.setup(channels=channels, samplerate=samplerate,\n                     blocksize=blocksize)\n        source.SIG_STOP = False\n        last = source\n\n        # setup/reset processors and configure properties throughout the pipe\n        for item in items:\n            item.source_mediainfo = source.mediainfo()\n            item.setup(channels=last.channels(),\n                       samplerate=last.samplerate(),\n                       blocksize=last.blocksize(),\n                       totalframes=last.totalframes())\n            self._register_streamer(item)\n            last = item\n\n        # now stream audio data along the pipe\n        if self._stream_thread:\n            self._running_cond.acquire()\n        self._is_running = True\n        if self._stream_thread:\n            self._running_cond.notify()\n            self._running_cond.release()\n\n        eod = False\n\n        if source.id() == 'live_decoder':\n            # Set handler for Interruption signal\n            import signal\n\n            def signal_handler(signum, frame):\n                source.stop()\n\n            signal.signal(signal.SIGINT, signal_handler)\n\n        while not eod:\n            frames, eod = source.process()\n            for item in items:\n                frames, eod = item.process(frames, eod)\n\n        if source.id() == 'live_decoder':\n            # Restore default handler for Interruption signal\n            signal.signal(signal.SIGINT, signal.SIG_DFL)\n\n        # Post-processing\n        for item in items:\n            item.post_process()\n\n        # Release source\n        source.release()\n        # Release processors\n        for item in items:\n            item.release()\n\n        self._is_running = False", "response": "Run all the processors and configure the properties of the items in cascade."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef simple_host_process(argslist):\n\n    vamp_host = 'vamp-simple-host'\n    command = [vamp_host]\n    command.extend(argslist)\n    # try ?\n    stdout = subprocess.check_output(command,\n                                     stderr=subprocess.STDOUT).splitlines()\n\n    return stdout", "response": "Call vamp - simple - host"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_scale(self):\n\n        f_min = float(self.lower_freq)\n        f_max = float(self.higher_freq)\n        y_min = f_min\n        y_max = f_max\n        for y in range(self.image_height):\n            freq = y_min + y / (self.image_height - 1.0) * (y_max - y_min)\n            fft_bin = freq / f_max * (self.fft_size / 2 + 1)\n            if fft_bin < self.fft_size / 2:\n                alpha = fft_bin - int(fft_bin)\n                self.y_to_bin.append((int(fft_bin), alpha * 255))", "response": "generate the lookup which translates y - coordinate to fft - bin"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dict_to_hdf5(dict_like, h5group):\n    # Write attributes\n    for key, value in dict_like.items():\n        if value is not None:\n            h5group.attrs[str(key)] = value", "response": "Save a dictionnary - like object inside a h5 file group\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload a dictionnary - like object from a h5 file group", "response": "def dict_from_hdf5(dict_like, h5group):\n    \"\"\"\n    Load a dictionnary-like object from a h5 file group\n    \"\"\"\n    # Read attributes\n    for name, value in h5group.attrs.items():\n        dict_like[name] = value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndefine an iterator that will return frames at the given blocksize", "response": "def get_frames(self):\n        \"Define an iterator that will return frames at the given blocksize\"\n        nb_frames = self.input_totalframes // self.output_blocksize\n\n        if self.input_totalframes % self.output_blocksize == 0:\n            nb_frames -= 1  # Last frame must send eod=True\n\n        for index in xrange(0,\n                            nb_frames * self.output_blocksize,\n                            self.output_blocksize):\n            yield (self.samples[index:index + self.output_blocksize], False)\n\n        yield (self.samples[nb_frames * self.output_blocksize:], True)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef validate_parameters(cls, parameters, schema=None):\n        if schema is None:\n            schema = cls.get_parameters_schema()\n        jsonschema.validate(parameters, schema)", "response": "Validate the parameters format against the schema specification"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the components implementing interface and recursively any of descendants of interface.", "response": "def implementations(interface, recurse=True, abstract=False):\n    \"\"\"Returns the components implementing interface, and if recurse, any of\n    the descendants of interface. If abstract is True, also return the\n    abstract implementations.\"\"\"\n    result = []\n    find_implementations(interface, recurse, abstract, result)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef extend_unique(list1, list2):\n    for item in list2:\n        if item not in list1:\n            list1.append(item)", "response": "Extend list1 with list2 as list. extend but doesn t append duplicates\n            to list1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_implementations(interface, recurse, abstract, result):\n    for item in MetaComponent.implementations:\n        if (item['interface'] == interface and (abstract or not item['abstract'])):\n            extend_unique(result, [item['class']])\n\n    if recurse:\n        subinterfaces = interface.__subclasses__()\n        if subinterfaces:\n            for i in subinterfaces:\n                find_implementations(i, recurse, abstract, result)", "response": "Find implementations of an interface or of one of its descendants and extend result with the classes found."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_queryset(self):\n        queryset = self.model.objects.all()\n        analysis_uuid = self.request.query_params.get('analysis', None)\n        item_uuid = self.request.query_params.get('item', None)\n        if analysis_uuid is not None:\n            queryset = queryset.filter(analysis__uuid__startswith=analysis_uuid)\n        if item_uuid is not None:\n            queryset = queryset.filter(item__uuid__startswith=item_uuid)\n\n        return queryset", "response": "Returns a queryset of all purchases analysis track objects that match the given request query parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef process(self, frames, eod, spec_range=120.0):\n\n        samples = frames[:, 0]\n        nsamples = len(frames[:, 0])\n        if nsamples != self.blocksize:\n            self.window = self.window_function(nsamples)\n        samples *= self.window\n\n        while nsamples > self.fft_size:\n            self.fft_size = 2 * self.fft_size\n\n        zeros_p = numpy.zeros(self.fft_size / 2 - int(nsamples / 2))\n        if nsamples % 2:\n            zeros_n = numpy.zeros(self.fft_size / 2 - int(nsamples / 2) - 1)\n        else:\n            zeros_n = numpy.zeros(self.fft_size / 2 - int(nsamples / 2))\n        samples = numpy.concatenate((zeros_p, samples, zeros_n), axis=0)\n\n        fft = numpy.fft.fft(samples)\n        # normalized abs(FFT) between 0 and 1\n        spectrum = numpy.abs(fft[:fft.shape[0] / 2 + 1]) / float(nsamples)\n        length = numpy.float64(spectrum.shape[0])\n\n        # scale the db spectrum from [- spec_range db ... 0 db] > [0..1]\n        db_spectrum = ((20 * (numpy.log10(spectrum + 1e-30)))\n                       .clip(-spec_range, 0.0) + spec_range) / spec_range\n        energy = spectrum.sum()\n        spectral_centroid = 0\n\n        if energy > 1e-20:\n            # calculate the spectral centroid\n            if self.spectrum_range is None:\n                self.spectrum_range = numpy.arange(length)\n            spectral_centroid = (spectrum * self.spectrum_range).sum() / \\\n                (energy * (length - 1)) * \\\n                self.samplerate * 0.5\n            # clip > log10 > scale between 0 and 1\n            spectral_centroid = (math.log10(self.clip(spectral_centroid,\n                                                      self.lower,\n                                                      self.higher)) -\n                                 self.lower_log) / (self.higher_log -\n                                                    self.lower_log)\n\n        return (spectral_centroid, db_spectrum)", "response": "Process the audio frames and return a tuple containing the spectral centroid and the spectrum of the input audio frames."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef draw_peaks(self, x, peaks, line_color):\n\n        y1 = self.image_height * 0.5 - peaks[0] * (self.image_height - 4) * 0.5\n        y2 = self.image_height * 0.5 - peaks[1] * (self.image_height - 4) * 0.5\n\n        if self.previous_y:\n            self.draw.line(\n                [self.previous_x, self.previous_y, x, y1, x, y2], line_color)\n        else:\n            self.draw.line([x, y1, x, y2], line_color)\n\n        self.draw_anti_aliased_pixels(x, y1, y2, line_color)\n        self.previous_x, self.previous_y = x, y2", "response": "Draw 2 peaks at x"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndraws 2 inverted peaks at x", "response": "def draw_peaks_inverted(self, x, peaks, line_color):\n        \"\"\"Draw 2 inverted peaks at x\"\"\"\n\n        y1 = self.image_height * 0.5 - peaks[0] * (self.image_height - 4) * 0.5\n        y2 = self.image_height * 0.5 - peaks[1] * (self.image_height - 4) * 0.5\n\n        if self.previous_y and x < self.image_width - 1:\n            if y1 < y2:\n                self.draw.line((x, 0, x, y1), line_color)\n                self.draw.line((x, self.image_height, x, y2), line_color)\n            else:\n                self.draw.line((x, 0, x, y2), line_color)\n                self.draw.line((x, self.image_height, x, y1), line_color)\n        else:\n            self.draw.line((x, 0, x, self.image_height), line_color)\n        self.draw_anti_aliased_pixels(x, y1, y2, line_color)\n        self.previous_x, self.previous_y = x, y1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef draw_anti_aliased_pixels(self, x, y1, y2, color):\n\n        y_max = max(y1, y2)\n        y_max_int = int(y_max)\n        alpha = y_max - y_max_int\n\n        if alpha > 0.0 and alpha < 1.0 and y_max_int + 1 < self.image_height:\n            current_pix = self.pixel[int(x), y_max_int + 1]\n            r = int((1 - alpha) * current_pix[0] + alpha * color[0])\n            g = int((1 - alpha) * current_pix[1] + alpha * color[1])\n            b = int((1 - alpha) * current_pix[2] + alpha * color[2])\n            self.pixel[x, y_max_int + 1] = (r, g, b)\n\n        y_min = min(y1, y2)\n        y_min_int = int(y_min)\n        alpha = 1.0 - (y_min - y_min_int)\n\n        if alpha > 0.0 and alpha < 1.0 and y_min_int - 1 >= 0:\n            current_pix = self.pixel[x, y_min_int - 1]\n            r = int((1 - alpha) * current_pix[0] + alpha * color[0])\n            g = int((1 - alpha) * current_pix[1] + alpha * color[1])\n            b = int((1 - alpha) * current_pix[2] + alpha * color[2])\n            self.pixel[x, y_min_int - 1] = (r, g, b)", "response": "vertical anti - aliased at y1 and y2"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\napply last 2D transforms", "response": "def post_process(self):\n        \"\"\" Apply last 2D transforms\"\"\"\n        self.image.putdata(self.pixels)\n        self.image = self.image.transpose(Image.ROTATE_90)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite all ID3v2. 4 tags to file from self. metadata", "response": "def write_metadata(self):\n        \"\"\"Write all ID3v2.4 tags to file from self.metadata\"\"\"\n        import mutagen\n        from mutagen import id3\n\n        id3 = id3.ID3(self.filename)\n        for tag in self.metadata.keys():\n            value = self.metadata[tag]\n            frame = mutagen.id3.Frames[tag](3, value)\n            try:\n                id3.add(frame)\n            except:\n                raise IOError('EncoderError: cannot tag \"' + tag + '\"')\n        try:\n            id3.save()\n        except:\n            raise IOError('EncoderError: cannot write tags')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_completerlib():\n    #-----------------------------------------------------------------------------\n    #  Copyright (C) 2010-2011 The IPython Development Team.\n    #\n    #  Distributed under the terms of the BSD License.\n    #\n    #  The full license is in the file COPYING.txt, distributed with this software.\n    #-----------------------------------------------------------------------------\n\n    #-----------------------------------------------------------------------------\n    # Imports\n    #-----------------------------------------------------------------------------\n    #from __future__ import print_function\n\n    import inspect\n    import os\n    #import re\n    #import sys\n\n    try:\n        # Python >= 3.3\n        from importlib.machinery import all_suffixes\n        _suffixes = all_suffixes()\n    except ImportError:\n        from imp import get_suffixes\n        _suffixes = [ s[0] for s in get_suffixes() ]\n\n    # Third-party imports\n    from time import time\n    from zipimport import zipimporter\n\n    TIMEOUT_STORAGE = 2\n\n    TIMEOUT_GIVEUP = 20\n\n    # Regular expression for the python import statement\n    import_re = re.compile(r'(?P<name>[a-zA-Z_][a-zA-Z0-9_]*?)'\n                           r'(?P<package>[/\\\\]__init__)?'\n                           r'(?P<suffix>%s)$' %\n                           r'|'.join(re.escape(s) for s in _suffixes))\n\n    # RE for the ipython %run command (python + ipython scripts)\n    magic_run_re = re.compile(r'.*(\\.ipy|\\.ipynb|\\.py[w]?)$')\n\n    def module_list(path):\n        \"\"\"\n        Return the list containing the names of the modules available in the given\n        folder.\n        \"\"\"\n        # sys.path has the cwd as an empty string, but isdir/listdir need it as '.'\n        if path == '':\n            path = '.'\n\n        # A few local constants to be used in loops below\n        pjoin = os.path.join\n\n        if os.path.isdir(path):\n            # Build a list of all files in the directory and all files\n            # in its subdirectories. For performance reasons, do not\n            # recurse more than one level into subdirectories.\n            files = []\n            for root, dirs, nondirs in os.walk(path):\n                subdir = root[len(path)+1:]\n                if subdir:\n                    files.extend(pjoin(subdir, f) for f in nondirs)\n                    dirs[:] = [] # Do not recurse into additional subdirectories.\n                else:\n                    files.extend(nondirs)\n\n        else:\n            try:\n                files = list(zipimporter(path)._files.keys())\n            except:\n                files = []\n\n        # Build a list of modules which match the import_re regex.\n        modules = []\n        for f in files:\n            m = import_re.match(f)\n            if m:\n                modules.append(m.group('name'))\n        return list(set(modules))\n\n\n    def get_root_modules():\n        \"\"\"\n        Returns a list containing the names of all the modules available in the\n        folders of the pythonpath.\n\n        ip.db['rootmodules_cache'] maps sys.path entries to list of modules.\n        \"\"\"\n        #ip = get_ipython()\n        #rootmodules_cache = ip.db.get('rootmodules_cache', {})\n        rootmodules_cache = {}\n        rootmodules = list(sys.builtin_module_names)\n        start_time = time()\n        #store = False\n        for path in sys.path:\n            try:\n                modules = rootmodules_cache[path]\n            except KeyError:\n                modules = module_list(path)\n                try:\n                    modules.remove('__init__')\n                except ValueError:\n                    pass\n                if path not in ('', '.'): # cwd modules should not be cached\n                    rootmodules_cache[path] = modules\n                if time() - start_time > TIMEOUT_STORAGE and not store:\n                    #store = True\n                    #print(\"\\nCaching the list of root modules, please wait!\")\n                    #print(\"(This will only be done once - type '%rehashx' to \"\n                          #\"reset cache!)\\n\")\n                    sys.stdout.flush()\n                if time() - start_time > TIMEOUT_GIVEUP:\n                    print(\"This is taking too long, we give up.\\n\")\n                    return []\n            rootmodules.extend(modules)\n        #if store:\n            #ip.db['rootmodules_cache'] = rootmodules_cache\n        rootmodules = list(set(rootmodules))\n        return rootmodules\n\n\n    def is_importable(module, attr, only_modules):\n        if only_modules:\n            return inspect.ismodule(getattr(module, attr))\n        else:\n            return not(attr[:2] == '__' and attr[-2:] == '__')\n\n\n    def try_import(mod, only_modules=False):\n        try:\n            m = __import__(mod)\n        except:\n            return []\n        mods = mod.split('.')\n        for module in mods[1:]:\n            m = getattr(m, module)\n\n        m_is_init = hasattr(m, '__file__') and '__init__' in m.__file__\n\n        completions = []\n        if (not hasattr(m, '__file__')) or (not only_modules) or m_is_init:\n            completions.extend( [attr for attr in dir(m) if\n                                 is_importable(m, attr, only_modules)])\n\n        completions.extend(getattr(m, '__all__', []))\n        if m_is_init:\n            completions.extend(module_list(os.path.dirname(m.__file__)))\n        completions = set(completions)\n        if '__init__' in completions:\n            completions.remove('__init__')\n        return list(completions)\n\n\n    def module_completion(line):\n        \"\"\"\n        Returns a list containing the completion possibilities for an import line.\n\n        The line looks like this :\n        'import xml.d'\n        'from xml.dom import'\n        \"\"\"\n\n        words = line.split(' ')\n        nwords = len(words)\n\n        # from whatever <tab> -> 'import '\n        if nwords == 3 and words[0] == 'from':\n            return ['import ']\n\n        # 'from xy<tab>' or 'import xy<tab>'\n        if nwords < 3 and (words[0] in ['import','from']) :\n            if nwords == 1:\n                return get_root_modules()\n            mod = words[1].split('.')\n            if len(mod) < 2:\n                return get_root_modules()\n            completion_list = try_import('.'.join(mod[:-1]), True)\n            return ['.'.join(mod[:-1] + [el]) for el in completion_list]\n\n        # 'from xyz import abc<tab>'\n        if nwords >= 3 and words[0] == 'from':\n            mod = words[1]\n            return try_import(mod)\n\n    return module_completion, module_list", "response": "Returns a new completerlib that can be used to complete the current IPython environment."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_backends(title):\n    path = os.path.dirname(fulltext.backends.__file__)\n    errs = []\n    for name in os.listdir(path):\n        if not name.endswith('.py'):\n            continue\n        if name == '__init__.py':\n            continue\n\n        mod_name = \"fulltext.backends.%s\" % (\n            os.path.splitext(os.path.basename(name))[0])\n\n        try:\n            mod = __import__(mod_name, fromlist=[' '])\n        except ImportError as err:\n            errs.append((mod_name, str(err)))\n            continue\n\n        kw = dict(encoding='utf8', encoding_errors='strict',\n                  kwargs={})\n        try:\n            inst = getattr(mod, \"Backend\")(**kw)\n            if hasattr(inst, \"check\"):\n                inst.check(title=title)\n        except Exception as err:\n            errs.append((mod.__name__, str(err)))\n    if errs:\n        for mod, err in errs:\n            msg = hilite(\"%s: %s\" % (mod, err), ok=False)\n            print(msg, file=sys.stderr)\n        sys.exit(1)", "response": "Invoke test method for all backends and fail if some backend is missing."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nextract text from a file. Commands: extract - extract text from path check - make sure all deps are installed Usage: fulltext extract [-v] [-f] <path>... fulltext check [-t] Options: -f, --file Open file first. -t, --title Check deps for title. -v, --verbose More verbose output.", "response": "def main(args=sys.argv[1:]):\n    \"\"\"Extract text from a file.\n\n    Commands:\n        extract - extract text from path\n        check   - make sure all deps are installed\n\n    Usage:\n        fulltext extract [-v] [-f] <path>...\n        fulltext check [-t]\n\n    Options:\n        -f, --file           Open file first.\n        -t, --title          Check deps for title.\n        -v, --verbose        More verbose output.\n    \"\"\"\n    opt = docopt(main.__doc__.strip(), args, options_first=True)\n\n    config_logging(opt['--verbose'])\n\n    if opt['check']:\n        check_backends(opt['--title'])\n    elif opt['extract']:\n        handler = fulltext.get\n\n        if opt['--file']:\n            handler = _handle_open\n\n        for path in opt['<path>']:\n            print(handler(path))\n    else:\n        # we should never get here\n        raise ValueError(\"don't know how to handle cmd\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef register_backend(mimetype, module, extensions=None):\n    if mimetype in MIMETYPE_TO_BACKENDS:\n        warn(\"overwriting %r mimetype which was already set\" % mimetype)\n    MIMETYPE_TO_BACKENDS[mimetype] = module\n    if extensions is None:\n        try:\n            ext = _MIMETYPES_TO_EXT[mimetype]\n        except KeyError:\n            raise KeyError(\n                \"mimetypes module has no extension associated \"\n                \"with %r mimetype; use 'extensions' arg yourself\" % mimetype)\n        assert ext, ext\n        EXTS_TO_MIMETYPES[ext] = mimetype\n    else:\n        if not isinstance(extensions, (list, tuple, set, frozenset)):\n            raise TypeError(\"invalid extensions type (got %r)\" % extensions)\n        for ext in set(extensions):\n            ext = ext if ext.startswith('.') else '.' + ext\n            assert ext, ext\n            EXTS_TO_MIMETYPES[ext] = mimetype", "response": "Register a backend.\n    `mimetype`: a mimetype string (e.g. 'text/plain')\n    `module`: an import string (e.g. path.to.my.module)\n    `extensions`: a list of extensions (e.g. ['txt', 'text'])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_binary(f):\n    # NOTE: order matters here. We don't bail on Python 2 just yet. Both\n    # codecs.open() and io.open() can open in text mode, both set the encoding\n    # attribute. We must do that check first.\n\n    # If it has a decoding attribute with a value, it is text mode.\n    if getattr(f, \"encoding\", None):\n        return False\n\n    # Python 2 makes no further distinction.\n    if not PY3:\n        return True\n\n    # If the file has a mode, and it contains b, it is binary.\n    try:\n        if 'b' in getattr(f, 'mode', ''):\n            return True\n    except TypeError:\n        import gzip\n        if isinstance(f, gzip.GzipFile):\n            return True  # in gzip mode is an integer\n        raise\n\n    # Can we sniff?\n    try:\n        f.seek(0, os.SEEK_CUR)\n    except (AttributeError, IOError):\n        return False\n\n    # Finally, let's sniff by reading a byte.\n    byte = f.read(1)\n    f.seek(-1, os.SEEK_CUR)\n    return hasattr(byte, 'decode')", "response": "Return True if the file is binary mode."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef handle_path(backend_inst, path, **kwargs):\n    if callable(getattr(backend_inst, 'handle_path', None)):\n        # Prefer handle_path() if present.\n        LOGGER.debug(\"using handle_path\")\n        return backend_inst.handle_path(path)\n\n    elif callable(getattr(backend_inst, 'handle_fobj', None)):\n        # Fallback to handle_fobj(). No warning here since the performance hit\n        # is minimal.\n        LOGGER.debug(\"using handle_fobj\")\n        with open(path, 'rb') as f:\n            return backend_inst.handle_fobj(f)\n\n    else:\n        raise AssertionError(\n            'Backend %s has no _get functions' % backend_inst.__name__)", "response": "Handle a path.\n\n    Called by `get()` when provided a path. This function will prefer the\n    backend's `handle_path()` if one is provided Otherwise, it will open the\n    given path then use `handle_fobj()`."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef handle_fobj(backend, f, **kwargs):\n    if not is_binary(f):\n        raise AssertionError('File must be opened in binary mode.')\n\n    if callable(getattr(backend, 'handle_fobj', None)):\n        # Prefer handle_fobj() if present.\n        LOGGER.debug(\"using handle_fobj\")\n        return backend.handle_fobj(f)\n\n    elif callable(getattr(backend, 'handle_path', None)):\n        # Fallback to handle_path(). Warn user since this is potentially\n        # expensive.\n        LOGGER.debug(\"using handle_path\")\n        LOGGER.warning(\n            \"Using disk, %r backend does not provide `handle_fobj()`\", backend)\n\n        ext = ''\n        if 'ext' in kwargs:\n            ext = '.' + kwargs['ext']\n\n        with fobj_to_tempfile(f, suffix=ext) as fname:\n            return backend.handle_path(fname, **kwargs)\n    else:\n        raise AssertionError(\n            'Backend %s has no _get functions' % backend.__name__)", "response": "Handle a file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef backend_from_mime(mime):\n    try:\n        mod_name = MIMETYPE_TO_BACKENDS[mime]\n\n    except KeyError:\n        msg = \"No handler for %r, defaulting to %r\" % (mime, DEFAULT_MIME)\n        if 'FULLTEXT_TESTING' in os.environ:\n            warn(msg)\n        else:\n            LOGGER.debug(msg)\n\n        mod_name = MIMETYPE_TO_BACKENDS[DEFAULT_MIME]\n    mod = import_mod(mod_name)\n    return mod", "response": "Determine backend module object from a mime string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef backend_from_fname(name):\n    ext = splitext(name)[1]\n\n    try:\n        mime = EXTS_TO_MIMETYPES[ext]\n\n    except KeyError:\n        try:\n            f = open(name, 'rb')\n\n        except IOError as e:\n            # The file may not exist, we are being asked to determine it's type\n            # from it's name. Other errors are unexpected.\n            if e.errno != errno.ENOENT:\n                raise\n\n            # We will have to fall back upon the default backend.\n            msg = \"No handler for %r, defaulting to %r\" % (ext, DEFAULT_MIME)\n            if 'FULLTEXT_TESTING' in os.environ:\n                warn(msg)\n            else:\n                LOGGER.debug(msg)\n\n            mod_name = MIMETYPE_TO_BACKENDS[DEFAULT_MIME]\n\n        else:\n            with f:\n                return backend_from_fobj(f)\n\n    else:\n        mod_name = MIMETYPE_TO_BACKENDS[mime]\n\n    mod = import_mod(mod_name)\n    return mod", "response": "Determine backend module object from a file name."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetermine backend module object from a file object.", "response": "def backend_from_fobj(f):\n    \"\"\"Determine backend module object from a file object.\"\"\"\n    if magic is None:\n        warn(\"magic lib is not installed; assuming mime type %r\" % (\n            DEFAULT_MIME))\n        return backend_from_mime(DEFAULT_MIME)\n    else:\n        offset = f.tell()\n        try:\n            f.seek(0)\n            chunk = f.read(MAGIC_BUFFER_SIZE)\n            mime = magic.from_buffer(chunk, mime=True)\n            return backend_from_mime(mime)\n        finally:\n            f.seek(offset)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngives a mod and a set of opts return an instantiated Backend class.", "response": "def backend_inst_from_mod(mod, encoding, encoding_errors, kwargs):\n    \"\"\"Given a mod and a set of opts return an instantiated\n    Backend class.\n    \"\"\"\n    kw = dict(encoding=encoding, encoding_errors=encoding_errors,\n              kwargs=kwargs)\n    try:\n        klass = getattr(mod, \"Backend\")\n    except AttributeError:\n        raise AttributeError(\"%r mod does not define any backend class\" % mod)\n    inst = klass(**kw)\n    try:\n        inst.check(title=False)\n    except Exception as err:\n        bin_mod = \"fulltext.backends.__bin\"\n        warn(\"can't use %r due to %r; use %r backend instead\" % (\n             mod, str(err), bin_mod))\n        inst = import_mod(bin_mod).Backend(**kw)\n        inst.check(title=False)\n    LOGGER.debug(\"using %r\" % inst)\n    return inst"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the full text of a single object.", "response": "def get(path_or_file, default=SENTINAL, mime=None, name=None, backend=None,\n        encoding=None, encoding_errors=None, kwargs=None,\n        _wtitle=False):\n    \"\"\"\n    Get document full text.\n\n    Accepts a path or file-like object.\n     * If given, `default` is returned instead of an error.\n     * `backend` is either a module object or a string specifying which\n       default backend to use (e.g. \"doc\"); take a look at backends\n       directory to see a list of default backends.\n     * `mime` and `name` should be passed if the information\n       is available to caller, otherwise a best guess is made.\n       If both are specified `mime` takes precedence.\n     * `encoding` and `encoding_errors` are used to handle text encoding.\n       They are taken into consideration mostly only by pure-python\n       backends which do not rely on CLI tools.\n       Default to \"utf8\" and \"strict\" respectively.\n     * `kwargs` are passed to the underlying backend.\n    \"\"\"\n    try:\n        text, title = _get(\n            path_or_file, default=default, mime=mime, name=name,\n            backend=backend, kwargs=kwargs, encoding=encoding,\n            encoding_errors=encoding_errors, _wtitle=_wtitle)\n        if _wtitle:\n            return (text, title)\n        else:\n            return text\n    except Exception as e:\n        if default is not SENTINAL:\n            LOGGER.exception(e)\n            return default\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef memoize(fun):\n    @functools.wraps(fun)\n    def wrapper(*args, **kwargs):\n        key = (args, frozenset(sorted(kwargs.items())))\n        try:\n            return cache[key]\n        except KeyError:\n            ret = cache[key] = fun(*args, **kwargs)\n            return ret\n\n    def cache_clear():\n        \"\"\"Clear cache.\"\"\"\n        cache.clear()\n\n    cache = {}\n    wrapper.cache_clear = cache_clear\n    return wrapper", "response": "A simple memoize decorator for functions supporting ( hashable )\n    positional arguments."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef hilite(s, ok=True, bold=False):\n    if not term_supports_colors():\n        return s\n    attr = []\n    if ok is None:  # no color\n        pass\n    elif ok:   # green\n        attr.append('32')\n    else:   # red\n        attr.append('31')\n    if bold:\n        attr.append('1')\n    return '\\x1b[%sm%s\\x1b[0m' % (';'.join(attr), s)", "response": "Return an highlighted version of string."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fobj_to_tempfile(f, suffix=''):\n    with tempfile.NamedTemporaryFile(\n            dir=TEMPDIR, suffix=suffix, delete=False) as t:\n        shutil.copyfileobj(f, t)\n    try:\n        yield t.name\n    finally:\n        os.remove(t.name)", "response": "Context manager which copies a file object to disk and returns its\nCTYPE name. When done the file is deleted."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprints a string to the console encoded depending on the file encoding.", "response": "def safe_print(text, file=sys.stdout, flush=False):\n    \"\"\"Prints a (unicode) string to the console, encoded depending on\n    the stdout/file encoding (eg. cp437 on Windows). This is to avoid\n    encoding errors in case of funky path names.\n    Works with Python 2 and 3.\n    \"\"\"\n    if not isinstance(text, basestring):\n        return print(text, file=file)\n    try:\n        file.write(text)\n    except UnicodeEncodeError:\n        bytes_string = text.encode(file.encoding, 'backslashreplace')\n        if hasattr(file, 'buffer'):\n            file.buffer.write(bytes_string)\n        else:\n            text = bytes_string.decode(file.encoding, 'strict')\n            file.write(text)\n    file.write(\"\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef clean():\n    rm(\"$testfn*\")\n    rm(\"*.bak\")\n    rm(\"*.core\")\n    rm(\"*.egg-info\")\n    rm(\"*.orig\")\n    rm(\"*.pyc\")\n    rm(\"*.pyd\")\n    rm(\"*.pyo\")\n    rm(\"*.rej\")\n    rm(\"*.so\")\n    rm(\"*.~\")\n    rm(\"*__pycache__\")\n    rm(\".coverage\")\n    rm(\".tox\")\n    rm(\".coverage\")\n    rm(\"build\")\n    rm(\"dist\")\n    rm(\"docs/_build\")\n    rm(\"htmlcov\")\n    rm(\"tmp\")\n    rm(\"venv\")", "response": "Deletes all the dev files"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrun flake8 against all py files", "response": "def lint():\n    \"\"\"Run flake8 against all py files\"\"\"\n    py_files = subprocess.check_output(\"git ls-files\")\n    if PY3:\n        py_files = py_files.decode()\n    py_files = [x for x in py_files.split() if x.endswith('.py')]\n    py_files = ' '.join(py_files)\n    sh(\"%s -m flake8 %s\" % (PYTHON, py_files), nolog=True)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninstall venv + deps.", "response": "def venv():\n    \"\"\"Install venv + deps.\"\"\"\n    try:\n        import virtualenv  # NOQA\n    except ImportError:\n        sh(\"%s -m pip install virtualenv\" % PYTHON)\n    if not os.path.isdir(\"venv\"):\n        sh(\"%s -m virtualenv venv\" % PYTHON)\n    sh(\"venv\\\\Scripts\\\\pip install -r %s\" % (REQUIREMENTS_TXT))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef compute_transformed(context):\n\n    key_composite = compute_key_composite(\n        password=context._._.password,\n        keyfile=context._._.keyfile\n    )\n    kdf_parameters = context._.header.value.dynamic_header.kdf_parameters.data.dict\n\n    if context._._.transformed_key is not None:\n        transformed_key = context._._.transformed_key\n    elif kdf_parameters['$UUID'].value == kdf_uuids['argon2']:\n        transformed_key = argon2.low_level.hash_secret_raw(\n            secret=key_composite,\n            salt=kdf_parameters['S'].value,\n            hash_len=32,\n            type=argon2.low_level.Type.D,\n            time_cost=kdf_parameters['I'].value,\n            memory_cost=kdf_parameters['M'].value // 1024,\n            parallelism=kdf_parameters['P'].value,\n            version=kdf_parameters['V'].value\n        )\n    elif kdf_parameters['$UUID'].value == kdf_uuids['aeskdf']:\n        transformed_key = aes_kdf(\n            kdf_parameters['S'].value,\n            kdf_parameters['R'].value,\n            key_composite\n        )\n    else:\n        raise Exception('Unsupported key derivation method')\n\n    return transformed_key", "response": "Compute transformed key for opening database"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing HMAC - SHA256 hash of header. Used to prevent header tampering.", "response": "def compute_header_hmac_hash(context):\n    \"\"\"Compute HMAC-SHA256 hash of header.\n    Used to prevent header tampering.\"\"\"\n\n    return hmac.new(\n        hashlib.sha512(\n            b'\\xff' * 8 +\n            hashlib.sha512(\n                context._.header.value.dynamic_header.master_seed.data +\n                context.transformed_key +\n                b'\\x01'\n            ).digest()\n        ).digest(),\n        context._.header.data,\n        hashlib.sha256\n    ).digest()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute hash of each payload block. Used to prevent payload corruption and tampering.", "response": "def compute_payload_block_hash(this):\n    \"\"\"Compute hash of each payload block.\n    Used to prevent payload corruption and tampering.\"\"\"\n\n    return hmac.new(\n        hashlib.sha512(\n            struct.pack('<Q', this._index) +\n            hashlib.sha512(\n                this._._.header.value.dynamic_header.master_seed.data +\n                this._.transformed_key + b'\\x01'\n            ).digest()\n        ).digest(),\n        struct.pack('<Q', this._index) +\n        struct.pack('<I', len(this.block_data)) +\n        this.block_data, hashlib.sha256\n    ).digest()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes transformed key for opening database", "response": "def compute_transformed(context):\n    \"\"\"Compute transformed key for opening database\"\"\"\n\n    if context._._.transformed_key is not None:\n        transformed_key = context._._transformed_key\n    else:\n        transformed_key = aes_kdf(\n            context._.header.value.dynamic_header.transform_seed.data,\n            context._.header.value.dynamic_header.transform_rounds.data,\n            password=context._._.password,\n            keyfile=context._._.keyfile\n        )\n\n    return transformed_key"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_key(self, key):\n\n        key_len = len(key)\n        if key_len not in [16, 24, 32]:\n            # XXX: add padding?\n            raise KeyError(\"key must be 16, 24 or 32 bytes\")\n        if key_len % 4:\n            # XXX: add padding?\n            raise KeyError(\"key not a multiple of 4\")\n        if key_len > 32:\n            # XXX: prune?\n            raise KeyError(\"key_len > 32\")\n\n        self.context = TWI()\n\n        key_word32 = [0] * 32\n        i = 0\n        while key:\n            key_word32[i] = struct.unpack(\"<L\", key[0:4])[0]\n            key = key[4:]\n            i += 1\n\n        set_key(self.context, key_word32, key_len)", "response": "Set the key of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a key for AES128 - ECB encryption", "response": "def aes_kdf(key, rounds, password=None, keyfile=None):\n    \"\"\"Set up a context for AES128-ECB encryption to find transformed_key\"\"\"\n\n    cipher = AES.new(key, AES.MODE_ECB)\n    key_composite = compute_key_composite(\n        password=password,\n        keyfile=keyfile\n    )\n\n    # get the number of rounds from the header and transform the key_composite\n    transformed_key = key_composite\n    for _ in range(0, rounds):\n        transformed_key = cipher.encrypt(transformed_key)\n\n    return hashlib.sha256(transformed_key).digest()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef compute_key_composite(password=None, keyfile=None):\n\n    # hash the password\n    if password:\n        password_composite = hashlib.sha256(password.encode('utf-8')).digest()\n    else:\n        password_composite = b''\n    # hash the keyfile\n    if keyfile:\n        # try to read XML keyfile\n        try:\n            with open(keyfile, 'r') as f:\n                tree = etree.parse(f).getroot()\n                keyfile_composite = base64.b64decode(tree.find('Key/Data').text)\n        # otherwise, try to read plain keyfile\n        except (etree.XMLSyntaxError, UnicodeDecodeError):\n            try:\n                with open(keyfile, 'rb') as f:\n                    key = f.read()\n\n                    try:\n                        int(key, 16)\n                        is_hex = True\n                    except ValueError:\n                        is_hex = False\n                    # if the length is 32 bytes we assume it is the key\n                    if len(key) == 32:\n                        keyfile_composite = key\n                    # if the length is 64 bytes we assume the key is hex encoded\n                    elif len(key) == 64 and is_hex:\n                        keyfile_composite =  codecs.decode(key, 'hex')\n                    # anything else may be a file to hash for the key\n                    else:\n                        keyfile_composite = hashlib.sha256(key).digest()\n            except:\n                raise IOError('Could not read keyfile')\n\n    else:\n        keyfile_composite = b''\n\n    # create composite key from password and keyfile composites\n    return hashlib.sha256(password_composite + keyfile_composite).digest()", "response": "Compute composite key.\n    Used in header verification and payload decryption."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes master key from transformed key and master seed Used in payload decryption.", "response": "def compute_master(context):\n    \"\"\"Computes master key from transformed key and master seed.\n    Used in payload decryption.\"\"\"\n\n    # combine the transformed key with the header master seed to find the master_key\n    master_key = hashlib.sha256(\n        context._.header.value.dynamic_header.master_seed.data +\n        context.transformed_key).digest()\n    return master_key"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nselect stream cipher based on protected_stream_id", "response": "def Unprotect(protected_stream_id, protected_stream_key, subcon):\n    \"\"\"Select stream cipher based on protected_stream_id\"\"\"\n\n    return Switch(\n        protected_stream_id,\n        {'arcfourvariant': ARCFourVariantStream(protected_stream_key, subcon),\n         'salsa20': Salsa20Stream(protected_stream_key, subcon),\n         'chacha20': ChaCha20Stream(protected_stream_key, subcon),\n        },\n        default=subcon\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef encrypt(self,plaintext,n=''):\n        #self.ed = 'e' if chain is encrypting, 'd' if decrypting,\n        # None if nothing happened with the chain yet\n        #assert self.ed in ('e',None) \n        # makes sure you don't encrypt with a cipher that has started decrypting\n        self.ed = 'e'\n        if self.mode == MODE_XTS:\n            # data sequence number (or 'tweak') has to be provided when in XTS mode\n            return self.chain.update(plaintext,'e',n)\n        else:\n            return self.chain.update(plaintext,'e')", "response": "Encrypt some plaintext with the cipher and return the result."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef decrypt(self,ciphertext,n=''):\n        #self.ed = 'e' if chain is encrypting, 'd' if decrypting,\n        # None if nothing happened with the chain yet\n        #assert self.ed in ('d',None)\n        # makes sure you don't decrypt with a cipher that has started encrypting\n        self.ed = 'd'\n        if self.mode == MODE_XTS:\n            # data sequence number (or 'tweak') has to be provided when in XTS mode\n            return self.chain.update(ciphertext,'d',n)\n        else:\n            return self.chain.update(ciphertext,'d')", "response": "Decrypt some ciphertext containing the supplied ciphertext and return the decrypted data."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinalizing the encryption by padding the cache and then decrypt the last block.", "response": "def final(self,style='pkcs7'):\n        # TODO: after calling final, reset the IV? so the cipher is as good as new?\n        \"\"\"Finalizes the encryption by padding the cache\n\n            padfct = padding function\n                     import from CryptoPlus.Util.padding\n\n        For ECB, CBC: the remaining bytes in the cache will be padded and\n                      encrypted.\n        For OFB,CFB, CTR: an encrypted padding will be returned, making the\n                          total outputed bytes since construction of the cipher\n                          a multiple of the blocksize of that cipher.\n\n        If the cipher has been used for decryption, the final function won't do\n          anything. You have to manually unpad if necessary.\n\n        After finalization, the chain can still be used but the IV, counter etc\n          aren't reset but just continue as they were after the last step (finalization step).\n        \"\"\"\n        assert self.mode not in (MODE_XTS, MODE_CMAC) # finalizing (=padding) doesn't make sense when in XTS or CMAC mode\n        if self.ed == b'e':\n            # when the chain is in encryption mode, finalizing will pad the cache and encrypt this last block\n            if self.mode in (MODE_OFB,MODE_CFB,MODE_CTR):\n                dummy = b'0'*(self.chain.totalbytes%self.blocksize) # a dummy string that will be used to get a valid padding\n            else: #ECB, CBC\n                dummy = self.chain.cache\n            pdata = pad(dummy,self.blocksize,style=style)[len(dummy):]\n            #~ pad = padfct(dummy,padding.PAD,self.blocksize)[len(dummy):] # construct the padding necessary\n            return self.chain.update(pdata,b'e') # supply the padding to the update function => chain cache will be \"cache+padding\"\n        else:\n            # final function doesn't make sense when decrypting => padding should be removed manually\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprocess the given ciphertext/plaintext Inputs: data: raw string of any length ed: 'e' for encryption, 'd' for decryption Output: processed raw string block(s), if any When the supplied data is not a multiple of the blocksize of the cipher, then the remaining input data will be cached. The next time the update function is called with some data, the new data will be concatenated to the cache and then cache+data will be processed and full blocks will be outputted.", "response": "def update(self, data, ed):\n        \"\"\"Processes the given ciphertext/plaintext\n\n        Inputs:\n            data: raw string of any length\n            ed:   'e' for encryption, 'd' for decryption\n        Output:\n            processed raw string block(s), if any\n\n        When the supplied data is not a multiple of the blocksize\n          of the cipher, then the remaining input data will be cached.\n        The next time the update function is called with some data,\n          the new data will be concatenated to the cache and then\n          cache+data will be processed and full blocks will be outputted.\n        \"\"\"\n        if ed == 'e':\n            encrypted_blocks = b''\n            self.cache += data\n            if len(self.cache) < self.blocksize:\n                return b''\n            for i in range(0, len(self.cache)-self.blocksize+1, self.blocksize):\n                self.IV = self.codebook.encrypt(strxor(self.cache[i:i+self.blocksize],self.IV))\n                encrypted_blocks += self.IV\n            self.cache = self.cache[i+self.blocksize:]\n            return encrypted_blocks\n        else:\n            decrypted_blocks = b''\n            self.cache += data\n            if len(self.cache) < self.blocksize:\n                return b''\n            for i in range(0, len(self.cache)-self.blocksize+1, self.blocksize):\n                plaintext = strxor(self.IV,self.codebook.decrypt(self.cache[i:i + self.blocksize]))\n                self.IV = self.cache[i:i + self.blocksize]\n                decrypted_blocks+=plaintext\n            self.cache = self.cache[i+self.blocksize:]\n            return decrypted_blocks"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _datetime_to_utc(self, dt):\n\n        if not dt.tzinfo:\n            dt = dt.replace(tzinfo=tz.gettz())\n        return dt.astimezone(tz.gettz('UTC'))", "response": "Convert naive datetimes to UTC"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _encode_time(self, value):\n\n        if self._kp.version >= (4, 0):\n            diff_seconds = int(\n                (\n                    self._datetime_to_utc(value) -\n                    datetime(\n                        year=1,\n                        month=1,\n                        day=1,\n                        tzinfo=tz.gettz('UTC')\n                    )\n                ).total_seconds()\n            )\n            return base64.b64encode(\n                struct.pack('<Q', diff_seconds)\n            ).decode('utf-8')\n        else:\n            return self._datetime_to_utc(value).isoformat()", "response": "Convert datetime to base64 or plaintext string"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _decode_time(self, text):\n\n        if self._kp.version >= (4, 0):\n            # decode KDBX4 date from b64 format\n            try:\n                return (\n                    datetime(year=1, month=1, day=1, tzinfo=tz.gettz('UTC')) +\n                    timedelta(\n                        seconds = struct.unpack('<Q', base64.b64decode(text))[0]\n                    )\n                )\n            except BinasciiError:\n                return parser.parse(\n                    text,\n                    tzinfos={'UTC':tz.gettz('UTC')}\n                )\n        else:\n            return parser.parse(\n                text,\n                tzinfos={'UTC':tz.gettz('UTC')}\n            )", "response": "Convert base64 time or plaintext time to datetime"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fromrdd(rdd, dims=None, nrecords=None, dtype=None, labels=None, ordered=False):\n    from .images import Images\n    from bolt.spark.array import BoltArraySpark\n\n    if dims is None or dtype is None:\n        item = rdd.values().first()\n        dtype = item.dtype\n        dims = item.shape\n\n    if nrecords is None:\n        nrecords = rdd.count()\n\n    def process_keys(record):\n        k, v = record\n        if isinstance(k, int):\n            k = (k,)\n        return k, v\n\n    values = BoltArraySpark(rdd.map(process_keys), shape=(nrecords,) + tuple(dims), dtype=dtype, split=1, ordered=ordered)\n    return Images(values, labels=labels)", "response": "Load a new image from a Spark RDD."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fromarray(values, labels=None, npartitions=None, engine=None):\n    from .images import Images\n    import bolt\n\n    if isinstance(values, bolt.spark.array.BoltArraySpark):\n        return Images(values)\n\n    values = asarray(values)\n\n    if values.ndim < 2:\n        raise ValueError('Array for images must have at least 2 dimensions, got %g' % values.ndim)\n\n    if values.ndim == 2:\n        values = expand_dims(values, 0)\n\n    shape = None\n    dtype = None\n    for im in values:\n        if shape is None:\n            shape = im.shape\n            dtype = im.dtype\n        if not im.shape == shape:\n            raise ValueError('Arrays must all be of same shape; got both %s and %s' %\n                             (str(shape), str(im.shape)))\n        if not im.dtype == dtype:\n            raise ValueError('Arrays must all be of same data type; got both %s and %s' %\n                             (str(dtype), str(im.dtype)))\n\n    if spark and isinstance(engine, spark):\n        if not npartitions:\n            npartitions = engine.defaultParallelism\n        values = bolt.array(values, context=engine, npartitions=npartitions, axis=(0,))\n        values._ordered = True\n        return Images(values)\n\n    return Images(values, labels=labels)", "response": "Load a single image from an array."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fromlist(items, accessor=None, keys=None, dims=None, dtype=None, labels=None, npartitions=None, engine=None):\n    if spark and isinstance(engine, spark):\n        nrecords = len(items)\n        if keys:\n            items = zip(keys, items)\n        else:\n            keys = [(i,) for i in range(nrecords)]\n            items = zip(keys, items)\n        if not npartitions:\n            npartitions = engine.defaultParallelism\n        rdd = engine.parallelize(items, npartitions)\n        if accessor:\n            rdd = rdd.mapValues(accessor)\n        return fromrdd(rdd, nrecords=nrecords, dims=dims, dtype=dtype, labels=labels, ordered=True)\n\n    else:\n        if accessor:\n            items = asarray([accessor(i) for i in items])\n        return fromarray(items, labels=labels)", "response": "Load images from a list of items using the given accessor."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef frompath(path, accessor=None, ext=None, start=None, stop=None, recursive=False, npartitions=None, dims=None, dtype=None, labels=None, recount=False, engine=None, credentials=None):\n    from thunder.readers import get_parallel_reader\n    reader = get_parallel_reader(path)(engine, credentials=credentials)\n    data = reader.read(path, ext=ext, start=start, stop=stop,\n                       recursive=recursive, npartitions=npartitions)\n\n    if spark and isinstance(engine, spark):\n        if accessor:\n            data = data.flatMap(accessor)\n        if recount:\n            nrecords = None\n\n            def switch(record):\n                ary, idx = record\n                return (idx,), ary\n\n            data = data.values().zipWithIndex().map(switch)\n        else:\n            nrecords = reader.nfiles\n        return fromrdd(data, nrecords=nrecords, dims=dims, dtype=dtype, labels=labels, ordered=True)\n\n    else:\n        if accessor:\n            data = [accessor(d) for d in data]\n        flattened = list(itertools.chain(*data))\n        values = [kv[1] for kv in flattened]\n        return fromarray(values, labels=labels)", "response": "Load images from a path using a given accessor."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading a flat binary file into a new object.", "response": "def frombinary(path, shape=None, dtype=None, ext='bin', start=None, stop=None, recursive=False, nplanes=None, npartitions=None, labels=None, conf='conf.json', order='C', engine=None, credentials=None):\n    \"\"\"\n    Load images from flat binary files.\n\n    Assumes one image per file, each with the shape and ordering as given\n    by the input arguments.\n\n    Parameters\n    ----------\n    path : str\n        Path to data files or directory, specified as either a local filesystem path\n        or in a URI-like format, including scheme. May include a single '*' wildcard character.\n\n    shape : tuple of positive int\n        Dimensions of input image data.\n\n    ext : string, optional, default = 'bin'\n        Extension required on data files to be loaded.\n\n    start, stop : nonnegative int, optional, default = None\n        Indices of the first and last-plus-one file to load, relative to the sorted\n        filenames matching `path` and `ext`. Interpreted using python slice indexing conventions.\n\n    recursive : boolean, optional, default = False\n        If true, will recursively descend directories from path, loading all files\n        with an extension matching 'ext'.\n\n    nplanes : positive integer, optional, default = None\n        If passed, will cause single files to be subdivided into nplanes separate images.\n        Otherwise, each file is taken to represent one image.\n\n    npartitions : int, optional, default = None\n        Number of partitions for computational engine,\n        if None will use default for engine.\n\n    labels : array, optional, default = None\n        Labels for records. If provided, should be one-dimensional.\n    \"\"\"\n    import json\n    from thunder.readers import get_file_reader, FileNotFoundError\n    try:\n        reader = get_file_reader(path)(credentials=credentials)\n        buf = reader.read(path, filename=conf).decode('utf-8')\n        params = json.loads(buf)\n    except FileNotFoundError:\n        params = {}\n\n    if 'dtype' in params.keys():\n        dtype = params['dtype']\n    if 'dims' in params.keys():\n        shape = params['dims']\n    if 'shape' in params.keys():\n        shape = params['shape']\n\n    if not shape:\n        raise ValueError('Image shape must be specified as argument or in a conf.json file')\n\n    if not dtype:\n        dtype = 'int16'\n\n    if nplanes is not None:\n        if nplanes <= 0:\n            raise ValueError('nplanes must be positive if passed, got %d' % nplanes)\n        if shape[-1] % nplanes:\n            raise ValueError(\"Last dimension '%d' must be divisible by nplanes '%d'\" %\n                             (shape[-1], nplanes))\n\n    def getarray(idx_buffer_filename):\n        idx, buf, _ = idx_buffer_filename\n        ary = frombuffer(buf, dtype=dtype, count=int(prod(shape))).reshape(shape, order=order)\n        if nplanes is None:\n            yield (idx,), ary\n        else:\n            # divide array into chunks of nplanes\n            npoints = shape[-1] / nplanes  # integer division\n            if shape[-1] % nplanes:\n                npoints += 1\n            timepoint = 0\n            last_plane = 0\n            current_plane = 1\n            while current_plane < ary.shape[-1]:\n                if current_plane % nplanes == 0:\n                    slices = [slice(None)] * (ary.ndim - 1) + [slice(last_plane, current_plane)]\n                    yield idx*npoints + timepoint, ary[slices].squeeze()\n                    timepoint += 1\n                    last_plane = current_plane\n                current_plane += 1\n            # yield remaining planes\n            slices = [slice(None)] * (ary.ndim - 1) + [slice(last_plane, ary.shape[-1])]\n            yield (idx*npoints + timepoint,), ary[slices].squeeze()\n\n    recount = False if nplanes is None else True\n    append = [nplanes] if (nplanes is not None and nplanes > 1) else []\n    newdims = tuple(list(shape[:-1]) + append) if nplanes else shape\n    return frompath(path, accessor=getarray, ext=ext, start=start,\n                    stop=stop, recursive=recursive, npartitions=npartitions,\n                    dims=newdims, dtype=dtype, labels=labels, recount=recount,\n                    engine=engine, credentials=credentials)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fromtif(path, ext='tif', start=None, stop=None, recursive=False, nplanes=None, npartitions=None, labels=None, engine=None, credentials=None, discard_extra=False):\n    from tifffile import TiffFile\n\n    if nplanes is not None and nplanes <= 0:\n        raise ValueError('nplanes must be positive if passed, got %d' % nplanes)\n\n    def getarray(idx_buffer_filename):\n        idx, buf, fname = idx_buffer_filename\n        fbuf = BytesIO(buf)\n        tfh = TiffFile(fbuf)\n        ary = tfh.asarray()\n        pageCount = ary.shape[0]\n        if nplanes is not None:\n            extra = pageCount % nplanes\n            if extra:\n                if discard_extra:\n                    pageCount = pageCount - extra\n                    logging.getLogger('thunder').warn('Ignored %d pages in file %s' % (extra, fname))\n                else:\n                    raise ValueError(\"nplanes '%d' does not evenly divide '%d in file %s'\" % (nplanes, pageCount,\n                                                                                              fname))\n            values = [ary[i:(i+nplanes)] for i in range(0, pageCount, nplanes)]\n        else:\n            values = [ary]\n        tfh.close()\n\n        if ary.ndim == 3:\n            values = [val.squeeze() for val in values]\n\n        nvals = len(values)\n        keys = [(idx*nvals + timepoint,) for timepoint in range(nvals)]\n        return zip(keys, values)\n\n    recount = False if nplanes is None else True\n    data = frompath(path, accessor=getarray, ext=ext, start=start, stop=stop,\n                    recursive=recursive, npartitions=npartitions, recount=recount,\n                    labels=labels, engine=engine, credentials=credentials)\n    if engine is not None and npartitions is not None and data.npartitions() < npartitions:\n        data = data.repartition(npartitions)\n    return data", "response": "Loads images from a single or multi - page TIF file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload a new node from PNG files.", "response": "def frompng(path, ext='png', start=None, stop=None, recursive=False, npartitions=None, labels=None, engine=None, credentials=None):\n    \"\"\"\n    Load images from PNG files.\n\n    Parameters\n    ----------\n    path : str\n        Path to data files or directory, specified as either a local filesystem path\n        or in a URI-like format, including scheme. May include a single '*' wildcard character.\n\n    ext : string, optional, default = 'tif'\n        Extension required on data files to be loaded.\n\n    start, stop : nonnegative int, optional, default = None\n        Indices of the first and last-plus-one file to load, relative to the sorted\n        filenames matching `path` and `ext`. Interpreted using python slice indexing conventions.\n\n    recursive : boolean, optional, default = False\n        If true, will recursively descend directories from path, loading all files\n        with an extension matching 'ext'.\n\n    npartitions : int, optional, default = None\n        Number of partitions for computational engine,\n        if None will use default for engine.\n\n    labels : array, optional, default = None\n        Labels for records. If provided, should be one-dimensional.\n    \"\"\"\n    from scipy.misc import imread\n\n    def getarray(idx_buffer_filename):\n        idx, buf, _ = idx_buffer_filename\n        fbuf = BytesIO(buf)\n        yield (idx,), imread(fbuf)\n\n    return frompath(path, accessor=getarray, ext=ext, start=start,\n                    stop=stop, recursive=recursive, npartitions=npartitions,\n                    labels=labels, engine=engine, credentials=credentials)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates random image data.", "response": "def fromrandom(shape=(10, 50, 50), npartitions=1, seed=42, engine=None):\n    \"\"\"\n    Generate random image data.\n\n    Parameters\n    ----------\n    shape : tuple, optional, default=(10, 50, 50)\n        Dimensions of images.\n\n    npartitions : int, optional, default=1\n        Number of partitions.\n\n    seed : int, optional, default=42\n        Random seed.\n    \"\"\"\n    seed = hash(seed)\n\n    def generate(v):\n        random.seed(seed + v)\n        return random.randn(*shape[1:])\n\n    return fromlist(range(shape[0]), accessor=generate, npartitions=npartitions, engine=engine)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload an example image data.", "response": "def fromexample(name=None, engine=None):\n    \"\"\"\n    Load example image data.\n\n    Data are downloaded from S3, so this method requires an internet connection.\n\n    Parameters\n    ----------\n    name : str\n        Name of dataset, if not specified will print options.\n\n    engine : object, default = None\n        Computational engine (e.g. a SparkContext for Spark)\n    \"\"\"\n    datasets = ['mouse', 'fish']\n\n    if name is None:\n        print('Availiable example image datasets')\n        for d in datasets:\n            print('- ' + d)\n        return\n\n    check_options(name, datasets)\n\n    path = 's3n://thunder-sample-data/images/' + name\n\n    if name == 'mouse':\n        data = frombinary(path=path, npartitions=1, order='F', engine=engine)\n\n    if name == 'fish':\n        data = fromtif(path=path, npartitions=1, engine=engine)\n\n    if spark and isinstance(engine, spark):\n        data.cache()\n        data.compute()\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the first value in the sequence.", "response": "def first(self):\n        \"\"\"\n        First chunk\n        \"\"\"\n        return self.values[tuple(zeros(len(self.values.shape)))]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreconstituting the chunked array back into a full ndarray.", "response": "def unchunk(self):\n        \"\"\"\n        Reconstitute the chunked array back into a full ndarray.\n\n        Returns\n        -------\n        ndarray\n        \"\"\"\n        if self.padding != len(self.shape)*(0,):\n            shape = self.values.shape\n            arr = empty(shape, dtype=object)\n            for inds in product(*[arange(s) for s in shape]):\n                slices = []\n                for i, p, n in zip(inds, self.padding, shape):\n                    start = None if (i == 0 or p == 0) else p\n                    stop = None if (i == n-1 or p == 0) else -p\n                    slices.append(slice(start, stop, None))\n                arr[inds] = self.values[inds][tuple(slices)]\n        else:\n            arr = self.values\n\n        return allstack(arr.tolist())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a chunked array from a full array and a chunk size.", "response": "def chunk(arr, chunk_size=\"150\", padding=None):\n        \"\"\"\n        Created a chunked array from a full array and a chunk size.\n\n        Parameters\n        ----------\n        array : ndarray\n            Array that will be broken into chunks\n\n        chunk_size : string or tuple, default = '150'\n            Size of each image chunk.\n            If a str, size of memory footprint in KB.\n            If a tuple, then the dimensions of each chunk.\n            If an int, then all dimensions will use this number\n\n        padding : tuple or int\n            Amount of padding along each dimensions for chunks. If an int, then\n            the same amount of padding is used for all dimensions\n\n        Returns\n        -------\n        LocalChunks\n        \"\"\"\n\n        plan, _ = LocalChunks.getplan(chunk_size, arr.shape[1:], arr.dtype)\n        plan = r_[arr.shape[0], plan]\n\n        if padding is None:\n            pad = arr.ndim*(0,)\n        elif isinstance(padding, int):\n            pad = (0,) + (arr.ndim-1)*(padding,)\n        else:\n            pad = (0,) + padding\n\n        shape = arr.shape\n\n        if any([x + y > z for x, y, z in zip(plan, pad, shape)]):\n            raise ValueError(\"Chunk sizes %s plus padding sizes %s cannot exceed value dimensions %s along any axis\"\n                             % (tuple(plan), tuple(pad), tuple(shape)))\n\n        if any([x > y for x, y in zip(pad, plan)]):\n            raise ValueError(\"Padding sizes %s cannot exceed chunk sizes %s along any axis\"\n                             % (tuple(pad), tuple(plan)))\n\n        def rectify(x):\n            x[x<0] = 0\n            return x\n\n        breaks = [r_[arange(0, n, s), n] for n, s in zip(shape, plan)]\n        limits = [zip(rectify(b[:-1]-p), b[1:]+p) for b, p in zip(breaks, pad)]\n        slices = product(*[[slice(x[0], x[1]) for x in l] for l in limits])\n        vals = [arr[s] for s in slices]\n        newarr = empty(len(vals), dtype=object)\n        for i in range(len(vals)):\n            newarr[i] = vals[i]\n        newsize = [b.shape[0]-1 for b in breaks]\n        newarr = newarr.reshape(*newsize)\n        return LocalChunks(newarr, shape, plan, dtype=arr.dtype, padding=pad)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute the count of the current set of items in the current set.", "response": "def compute(self):\n        \"\"\"\n        Force lazy computations to execute for datasets backed by Spark (Spark only).\n        \"\"\"\n        if self.mode == 'spark':\n            self.values.tordd().count()\n        else:\n            notsupported(self.mode)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncoalescing the data of the current instance.", "response": "def coalesce(self, npartitions):\n        \"\"\"\n        Coalesce data (Spark only).\n\n        Parameters\n        ----------\n        npartitions : int\n            Number of partitions after coalescing.\n        \"\"\"\n        if self.mode == 'spark':\n            current = self.values.tordd().getNumPartitions()\n            if npartitions > current:\n                raise Exception('Trying to increase number of partitions (from %g to %g), '\n                                'cannot use coalesce, try repartition' % (current, npartitions))\n            self.values._rdd = self.values._rdd.coalesce(npartitions)\n            return self\n        else:\n            notsupported(self.mode)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nenables in - memory caching for the current instance of the class.", "response": "def cache(self):\n        \"\"\"\n        Enable in-memory caching (Spark only).\n        \"\"\"\n        if self.mode == 'spark':\n            self.values.cache()\n            return self\n        else:\n            notsupported(self.mode)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndisables in-memory caching (Spark only).", "response": "def uncache(self):\n        \"\"\"\n        Disable in-memory caching (Spark only).\n        \"\"\"\n        if self.mode == 'spark':\n            self.values.unpersist()\n            return self\n        else:\n            notsupported(self.mode)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns True if the object is cached.", "response": "def iscached(self):\n        \"\"\"\n        Get whether object is cached (Spark only).\n        \"\"\"\n        if self.mode == 'spark':\n            return self.tordd().is_cached\n        else:\n            notsupported(self.mode)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the number of partitions in the current instance.", "response": "def npartitions(self):\n        \"\"\"\n        Get number of partitions (Spark only).\n        \"\"\"\n        if self.mode == 'spark':\n            return self.tordd().getNumPartitions()\n        else:\n            notsupported(self.mode)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef repartition(self, npartitions):\n        if self.mode == 'spark':\n            return self._constructor(self.values.repartition(npartitions)).__finalize__(self)\n        else:\n            notsupported(self.mode)", "response": "Repartition the set of keys."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef astype(self, dtype, casting='unsafe'):\n        return self._constructor(\n            self.values.astype(dtype=dtype, casting=casting)).__finalize__(self)", "response": "Cast the array to the specified type."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfilters array along an axis.", "response": "def filter(self, func):\n        \"\"\"\n        Filter array along an axis.\n\n        Applies a function which should evaluate to boolean,\n        along a single axis or multiple axes. Array will be\n        aligned so that the desired set of axes are in the\n        keys, which may require a transpose/reshape.\n\n        Parameters\n        ----------\n        func : function\n            Function to apply, should return boolean\n        \"\"\"\n\n        if self.mode == 'local':\n            reshaped = self._align(self.baseaxes)\n            filtered = asarray(list(filter(func, reshaped)))\n\n            if self.labels is not None:\n                mask = asarray(list(map(func, reshaped)))\n\n        if self.mode == 'spark':\n\n            sort = False if self.labels is None else True\n            filtered = self.values.filter(func, axis=self.baseaxes, sort=sort)\n\n            if self.labels is not None:\n                keys, vals = zip(*self.values.map(func, axis=self.baseaxes, value_shape=(1,)).tordd().collect())\n                perm = sorted(range(len(keys)), key=keys.__getitem__)\n                mask = asarray(vals)[perm]\n\n        if self.labels is not None:\n            s1 = prod(self.baseshape)\n            newlabels = self.labels.reshape(s1, 1)[mask].squeeze()\n        else:\n            newlabels = None\n\n        return self._constructor(filtered, labels=newlabels).__finalize__(self, noprop=('labels',))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\napplying an array - like function across an axis and returns a new array with the resulting elements.", "response": "def map(self, func, value_shape=None, dtype=None, with_keys=False):\n        \"\"\"\n        Apply an array -> array function across an axis.\n\n        Array will be aligned so that the desired set of axes\n        are in the keys, which may require a transpose/reshape.\n\n        Parameters\n        ----------\n        func : function\n            Function of a single array to apply. If with_keys=True,\n            function should be of a (tuple, array) pair.\n\n        axis : tuple or int, optional, default=(0,)\n            Axis or multiple axes to apply function along.\n\n        value_shape : tuple, optional, default=None\n            Known shape of values resulting from operation. Only\n            valid in spark mode.\n\n        dtype : numpy dtype, optional, default=None\n            Known shape of dtype resulting from operation. Only\n            valid in spark mode.\n\n        with_keys : bool, optional, default=False\n            Include keys as an argument to the function\n        \"\"\"\n        axis = self.baseaxes\n\n        if self.mode == 'local':\n            axes = sorted(tupleize(axis))\n            key_shape = [self.shape[axis] for axis in axes]\n            reshaped = self._align(axes, key_shape=key_shape)\n\n            if with_keys:\n                keys = zip(*unravel_index(range(prod(key_shape)), key_shape))\n                mapped = asarray(list(map(func, zip(keys, reshaped))))\n            else:\n                mapped = asarray(list(map(func, reshaped)))\n\n            try:\n                elem_shape = mapped[0].shape\n            except:\n                elem_shape = (1,)\n\n            expand = list(elem_shape)\n            expand = [1] if len(expand) == 0 else expand\n\n            # invert the previous reshape operation, using the shape of the map result\n            linearized_shape_inv = key_shape + expand\n            reordered = mapped.reshape(*linearized_shape_inv)\n\n            return self._constructor(reordered, mode=self.mode).__finalize__(self, noprop=('index'))\n\n        if self.mode == 'spark':\n            expand = lambda x: array(func(x), ndmin=1)\n            mapped = self.values.map(expand, axis, value_shape, dtype, with_keys)\n            return self._constructor(mapped, mode=self.mode).__finalize__(self, noprop=('index',))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreduce the array along an axis.", "response": "def _reduce(self, func, axis=0):\n        \"\"\"\n        Reduce an array along an axis.\n\n        Applies an associative/commutative function of two arguments\n        cumulatively to all arrays along an axis. Array will be aligned\n        so that the desired set of axes are in the keys, which may\n        require a transpose/reshape.\n\n        Parameters\n        ----------\n        func : function\n            Function of two arrays that returns a single array\n\n        axis : tuple or int, optional, default=(0,)\n            Axis or multiple axes to reduce along.\n        \"\"\"\n        if self.mode == 'local':\n            axes = sorted(tupleize(axis))\n\n            # if the function is a ufunc, it can automatically handle reducing over multiple axes\n            if isinstance(func, ufunc):\n                inshape(self.shape, axes)\n                reduced = func.reduce(self, axis=tuple(axes))\n            else:\n                reshaped = self._align(axes)\n                reduced = reduce(func, reshaped)\n\n            # ensure that the shape of the reduced array is valid\n            expected_shape = [self.shape[i] for i in range(len(self.shape)) if i not in axes]\n            if reduced.shape != tuple(expected_shape):\n                raise ValueError(\"reduce did not yield an array with valid dimensions\")\n\n            return self._constructor(reduced[newaxis, :]).__finalize__(self)\n\n        if self.mode == 'spark':\n            reduced = self.values.reduce(func, axis, keepdims=True)\n            return self._constructor(reduced).__finalize__(self)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef element_wise(self, other, op):\n        if not isscalar(other) and not self.shape == other.shape:\n            raise ValueError(\"shapes %s and %s must be equal\" % (self.shape, other.shape))\n\n        if not isscalar(other) and isinstance(other, Data) and not self.mode == other.mode:\n            raise NotImplementedError\n\n        if isscalar(other):\n            return self.map(lambda x: op(x, other))\n\n        if self.mode == 'local' and isinstance(other, ndarray):\n            return self._constructor(op(self.values, other)).__finalize__(self)\n\n        if self.mode == 'local' and isinstance(other, Data):\n            return self._constructor(op(self.values, other.values)).__finalize__(self)\n\n        if self.mode == 'spark' and isinstance(other, Data):\n\n            def func(record):\n                (k1, x), (k2, y) = record\n                return k1, op(x, y)\n\n            rdd = self.tordd().zip(other.tordd()).map(func)\n            barray = BoltArraySpark(rdd, shape=self.shape, dtype=self.dtype, split=self.values.split)\n            return self._constructor(barray).__finalize__(self)", "response": "Applies an elementwise operation to data."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nclips the set of keys in the sequence.", "response": "def clip(self, min=None, max=None):\n        \"\"\"\n        Clip values above and below.\n\n        Parameters\n        ----------\n        min : scalar or array-like\n            Minimum value. If array, will be broadcasted\n\n        max : scalar or array-like\n            Maximum value. If array, will be broadcasted.\n        \"\"\"\n        return self._constructor(\n            self.values.clip(min=min, max=max)).__finalize__(self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fromrdd(rdd, nrecords=None, shape=None, index=None, labels=None, dtype=None, ordered=False):\n    from .series import Series\n    from bolt.spark.array import BoltArraySpark\n\n    if index is None or dtype is None:\n        item = rdd.values().first()\n\n    if index is None:\n        index = range(len(item))\n\n    if dtype is None:\n        dtype = item.dtype\n\n    if nrecords is None and shape is not None:\n        nrecords = prod(shape[:-1])\n\n    if nrecords is None:\n        nrecords = rdd.count()\n\n    if shape is None:\n        shape = (nrecords, asarray(index).shape[0])\n\n    def process_keys(record):\n        k, v = record\n        if isinstance(k, int):\n            k = (k,)\n        return k, v\n\n    values = BoltArraySpark(rdd.map(process_keys), shape=shape, dtype=dtype, split=len(shape)-1, ordered=ordered)\n    return Series(values, index=index, labels=labels)", "response": "Load series data from a Spark RDD."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload series data from an array.", "response": "def fromarray(values, index=None, labels=None, npartitions=None, engine=None):\n    \"\"\"\n    Load series data from an array.\n\n    Assumes that all but final dimension index the records,\n    and the size of the final dimension is the length of each record,\n    e.g. a (2, 3, 4) array will be treated as 2 x 3 records of size (4,)\n\n    Parameters\n    ----------\n    values : array-like\n        An array containing the data. Can be a numpy array,\n        a bolt array, or an array-like.\n\n    index : array, optional, default = None\n        Index for records, if not provided will use (0,1,...,N)\n        where N is the length of each record.\n\n    labels : array, optional, default = None\n        Labels for records. If provided, should have same shape as values.shape[:-1].\n\n    npartitions : int, default = None\n        Number of partitions for parallelization (Spark only)\n\n    engine : object, default = None\n        Computational engine (e.g. a SparkContext for Spark)\n    \"\"\"\n    from .series import Series\n    import bolt\n\n    if isinstance(values, bolt.spark.array.BoltArraySpark):\n        return Series(values)\n\n    values = asarray(values)\n\n    if values.ndim < 2:\n        values = expand_dims(values, 0)\n\n    if index is not None and not asarray(index).shape[0] == values.shape[-1]:\n        raise ValueError('Index length %s not equal to record length %s'\n                         % (asarray(index).shape[0], values.shape[-1]))\n    if index is None:\n        index = arange(values.shape[-1])\n\n    if spark and isinstance(engine, spark):\n        axis = tuple(range(values.ndim - 1))\n        values = bolt.array(values, context=engine, npartitions=npartitions, axis=axis)\n        values._ordered = True\n        return Series(values, index=index)\n\n    return Series(values, index=index, labels=labels)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fromlist(items, accessor=None, index=None, labels=None, dtype=None, npartitions=None, engine=None):\n    if spark and isinstance(engine, spark):\n        if dtype is None:\n            dtype = accessor(items[0]).dtype if accessor else items[0].dtype\n        nrecords = len(items)\n        keys = map(lambda k: (k, ), range(len(items)))\n        if not npartitions:\n            npartitions = engine.defaultParallelism\n        items = zip(keys, items)\n        rdd = engine.parallelize(items, npartitions)\n        if accessor:\n            rdd = rdd.mapValues(accessor)\n        return fromrdd(rdd, nrecords=nrecords, index=index, labels=labels, dtype=dtype, ordered=True)\n\n    else:\n        if accessor:\n            items = [accessor(i) for i in items]\n        return fromarray(items, index=index, labels=labels)", "response": "Load series data from a list of items."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading a series data from text files.", "response": "def fromtext(path, ext='txt', dtype='float64', skip=0, shape=None, index=None, labels=None, npartitions=None, engine=None, credentials=None):\n    \"\"\"\n    Loads series data from text files.\n\n    Assumes data are formatted as rows, where each record is a row\n    of numbers separated by spaces e.g. 'v v v v v'. You can\n    optionally specify a fixed number of initial items per row to skip / discard.\n\n    Parameters\n    ----------\n    path : string\n        Directory to load from, can be a URI string with scheme\n        (e.g. 'file://', 's3n://', or 'gs://'), or a single file,\n        or a directory, or a directory with a single wildcard character.\n\n    ext : str, optional, default = 'txt'\n        File extension.\n\n    dtype : dtype or dtype specifier, default 'float64'\n        Numerical type to use for data after converting from text.\n\n    skip : int, optional, default = 0\n        Number of items in each record to skip.\n\n    shape : tuple or list, optional, default = None\n        Shape of data if known, will be inferred otherwise.\n\n    index : array, optional, default = None\n        Index for records, if not provided will use (0, 1, ...)\n\n    labels : array, optional, default = None\n        Labels for records. If provided, should have length equal to number of rows.\n\n    npartitions : int, default = None\n        Number of partitions for parallelization (Spark only)\n\n    engine : object, default = None\n        Computational engine (e.g. a SparkContext for Spark)\n\n    credentials : dict, default = None\n        Credentials for remote storage (e.g. S3) in the form {access: ***, secret: ***}\n    \"\"\"\n    from thunder.readers import normalize_scheme, get_parallel_reader\n    path = normalize_scheme(path, ext)\n\n    if spark and isinstance(engine, spark):\n\n        def parse(line, skip):\n            vec = [float(x) for x in line.split(' ')]\n            return array(vec[skip:], dtype=dtype)\n\n        lines = engine.textFile(path, npartitions)\n        data = lines.map(lambda x: parse(x, skip))\n\n        def switch(record):\n            ary, idx = record\n            return (idx,), ary\n\n        rdd = data.zipWithIndex().map(switch)\n        return fromrdd(rdd, dtype=str(dtype), shape=shape, index=index, ordered=True)\n\n    else:\n        reader = get_parallel_reader(path)(engine, credentials=credentials)\n        data = reader.read(path, ext=ext)\n\n        values = []\n        for kv in data:\n            for line in str(kv[1].decode('utf-8')).split('\\n')[:-1]:\n                values.append(fromstring(line, sep=' '))\n        values = asarray(values)\n\n        if skip > 0:\n            values = values[:, skip:]\n\n        if shape:\n            values = values.reshape(shape)\n\n        return fromarray(values, index=index, labels=labels)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef frombinary(path, ext='bin', conf='conf.json', dtype=None, shape=None, skip=0, index=None, labels=None, engine=None, credentials=None):\n    shape, dtype = _binaryconfig(path, conf, dtype, shape, credentials)\n\n    from thunder.readers import normalize_scheme, get_parallel_reader\n    path = normalize_scheme(path, ext)\n\n    from numpy import dtype as dtype_func\n    nelements = shape[-1] + skip\n    recordsize = dtype_func(dtype).itemsize * nelements\n\n    if spark and isinstance(engine, spark):\n        lines = engine.binaryRecords(path, recordsize)\n        raw = lines.map(lambda x: frombuffer(buffer(x), offset=0, count=nelements, dtype=dtype)[skip:])\n\n        def switch(record):\n            ary, idx = record\n            return (idx,), ary\n\n        rdd = raw.zipWithIndex().map(switch)\n\n        if shape and len(shape) > 2:\n            expand = lambda k: unravel_index(k[0], shape[0:-1])\n            rdd = rdd.map(lambda kv: (expand(kv[0]), kv[1]))\n\n        if not index:\n            index = arange(shape[-1])\n\n        return fromrdd(rdd, dtype=dtype, shape=shape, index=index, ordered=True)\n\n    else:\n        reader = get_parallel_reader(path)(engine, credentials=credentials)\n        data = reader.read(path, ext=ext)\n\n        values = []\n        for record in data:\n            buf = record[1]\n            offset = 0\n            while offset < len(buf):\n                v = frombuffer(buffer(buf), offset=offset, count=nelements, dtype=dtype)\n                values.append(v[skip:])\n                offset += recordsize\n\n        if not len(values) == prod(shape[0:-1]):\n            raise ValueError('Unexpected shape, got %g records but expected %g'\n                             % (len(values), prod(shape[0:-1])))\n\n        values = asarray(values, dtype=dtype)\n\n        if shape:\n            values = values.reshape(shape)\n\n        return fromarray(values, index=index, labels=labels)", "response": "Load series data from flat binary files."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading a binary config file into memory.", "response": "def _binaryconfig(path, conf, dtype=None, shape=None, credentials=None):\n    \"\"\"\n    Collects parameters to use for binary series loading.\n    \"\"\"\n    import json\n    from thunder.readers import get_file_reader, FileNotFoundError\n\n    reader = get_file_reader(path)(credentials=credentials)\n    try:\n        buf = reader.read(path, filename=conf)\n        params = json.loads(str(buf.decode('utf-8')))\n    except FileNotFoundError:\n        params = {}\n\n    if dtype:\n        params['dtype'] = dtype\n\n    if shape:\n        params['shape'] = shape\n\n    if 'dtype' not in params.keys():\n        raise ValueError('dtype not specified either in conf.json or as argument')\n\n    if 'shape' not in params.keys():\n        raise ValueError('shape not specified either in conf.json or as argument')\n\n    return params['shape'], params['dtype']"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads an example series data.", "response": "def fromexample(name=None, engine=None):\n    \"\"\"\n    Load example series data.\n\n    Data are downloaded from S3, so this method requires an internet connection.\n\n    Parameters\n    ----------\n    name : str\n        Name of dataset, options include 'iris' | 'mouse' | 'fish'.\n        If not specified will print options.\n\n    engine : object, default = None\n        Computational engine (e.g. a SparkContext for Spark)\n    \"\"\"\n    import os\n    import tempfile\n    import shutil\n    from boto.s3.connection import S3Connection\n\n    datasets = ['iris', 'mouse', 'fish']\n\n    if name is None:\n        print('Availiable example series datasets')\n        for d in datasets:\n            print('- ' + d)\n        return\n\n    check_options(name, datasets)\n\n    d = tempfile.mkdtemp()\n\n    try:\n        os.mkdir(os.path.join(d, 'series'))\n        os.mkdir(os.path.join(d, 'series', name))\n        conn = S3Connection(anon=True)\n        bucket = conn.get_bucket('thunder-sample-data')\n        for key in bucket.list(os.path.join('series', name) + '/'):\n            if not key.name.endswith('/'):\n                key.get_contents_to_filename(os.path.join(d, key.name))\n        data = frombinary(os.path.join(d, 'series', name), engine=engine)\n\n        if spark and isinstance(engine, spark):\n            data.cache()\n            data.compute()\n\n    finally:\n        shutil.rmtree(d)\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites out data to binary format.", "response": "def tobinary(series, path, prefix='series', overwrite=False, credentials=None):\n    \"\"\"\n    Writes out data to binary format.\n\n    Parameters\n    ----------\n    series : Series\n        The data to write\n\n    path : string path or URI to directory to be created\n        Output files will be written underneath path.\n        Directory will be created as a result of this call.\n\n    prefix : str, optional, default = 'series'\n        String prefix for files.\n\n    overwrite : bool\n        If true, path and all its contents will be deleted and\n        recreated as partof this call.\n    \"\"\"\n    from six import BytesIO\n    from thunder.utils import check_path\n    from thunder.writers import get_parallel_writer\n\n    if not overwrite:\n        check_path(path, credentials=credentials)\n        overwrite = True\n\n    def tobuffer(kv):\n        firstkey = None\n        buf = BytesIO()\n        for k, v in kv:\n            if firstkey is None:\n                firstkey = k\n            buf.write(v.tostring())\n        val = buf.getvalue()\n        buf.close()\n        if firstkey is None:\n            return iter([])\n        else:\n            label = prefix + '-' + getlabel(firstkey) + \".bin\"\n            return iter([(label, val)])\n\n    writer = get_parallel_writer(path)(path, overwrite=overwrite, credentials=credentials)\n\n    if series.mode == 'spark':\n        binary = series.values.tordd().sortByKey().mapPartitions(tobuffer)\n        binary.foreach(writer.write)\n\n    else:\n        basedims = [series.shape[d] for d in series.baseaxes]\n\n        def split(k):\n            ind = unravel_index(k, basedims)\n            return ind, series.values[ind]\n\n        buf = tobuffer([split(i) for i in range(prod(basedims))])\n        [writer.write(b) for b in buf]\n\n    shape = series.shape\n    dtype = series.dtype\n\n    write_config(path, shape=shape, dtype=dtype, overwrite=overwrite, credentials=credentials)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite a conf. json file with required information to load Series binary data.", "response": "def write_config(path, shape=None, dtype=None, name=\"conf.json\", overwrite=True, credentials=None):\n    \"\"\"\n    Write a conf.json file with required information to load Series binary data.\n    \"\"\"\n    import json\n    from thunder.writers import get_file_writer\n\n    writer = get_file_writer(path)\n    conf = {'shape': shape, 'dtype': str(dtype)}\n\n    confwriter = writer(path, name, overwrite=overwrite, credentials=credentials)\n    confwriter.write(json.dumps(conf, indent=2))\n\n    successwriter = writer(path, \"SUCCESS\", overwrite=overwrite, credentials=credentials)\n    successwriter.write('')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef first(self):\n        if self.mode == 'local':\n            return self.values[0]\n\n        if self.mode == 'spark':\n            return self.values.first().toarray()", "response": "Return the first element of the list."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef toblocks(self, chunk_size='auto', padding=None):\n        from thunder.blocks.blocks import Blocks\n        from thunder.blocks.local import LocalChunks\n\n        if self.mode == 'spark':\n            if chunk_size is 'auto':\n                chunk_size = str(max([int(1e5/self.shape[0]), 1]))\n            chunks = self.values.chunk(chunk_size, padding=padding).keys_to_values((0,))\n\n        if self.mode == 'local':\n            if chunk_size is 'auto':\n                chunk_size = self.shape[1:]\n            chunks = LocalChunks.chunk(self.values, chunk_size, padding=padding)\n\n        return Blocks(chunks)", "response": "Convert to blocks which represent subdivisions of the images data."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef toseries(self, chunk_size='auto'):\n        from thunder.series.series import Series\n\n        if chunk_size is 'auto':\n            chunk_size = str(max([int(1e5/self.shape[0]), 1]))\n\n        n = len(self.shape) - 1\n        index = arange(self.shape[0])\n\n        if self.mode == 'spark':\n            return Series(self.values.swap((0,), tuple(range(n)), size=chunk_size), index=index)\n\n        if self.mode == 'local':\n            return Series(self.values.transpose(tuple(range(1, n+1)) + (0,)), index=index)", "response": "Converts to series data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert to local mode.", "response": "def tolocal(self):\n        \"\"\"\n        Convert to local mode.\n        \"\"\"\n        from thunder.images.readers import fromarray\n\n        if self.mode == 'local':\n            logging.getLogger('thunder').warn('images already in local mode')\n            pass\n\n        return fromarray(self.toarray())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tospark(self, engine=None):\n        from thunder.images.readers import fromarray\n\n        if self.mode == 'spark':\n            logging.getLogger('thunder').warn('images already in spark mode')\n            pass\n\n        if engine is None:\n            raise ValueError('Must provide a SparkContext')\n\n        return fromarray(self.toarray(), engine=engine)", "response": "Convert to distributed spark mode."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef foreach(self, func):\n        if self.mode == 'spark':\n            self.values.tordd().map(lambda kv: (kv[0][0], kv[1])).foreach(func)\n        else:\n            [func(kv) for kv in enumerate(self.values)]", "response": "Execute a function on each image."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nextract a random sample of images.", "response": "def sample(self, nsamples=100, seed=None):\n        \"\"\"\n        Extract a random sample of images.\n\n        Parameters\n        ----------\n        nsamples : int, optional, default = 100\n            The number of data points to sample.\n\n        seed : int, optional, default = None\n            Random seed.\n        \"\"\"\n        if nsamples < 1:\n            raise ValueError(\"Number of samples must be larger than 0, got '%g'\" % nsamples)\n\n        if seed is None:\n            seed = random.randint(0, 2 ** 32)\n\n        if self.mode == 'spark':\n            result = asarray(self.values.tordd().values().takeSample(False, nsamples, seed))\n\n        else:\n            inds = [int(k) for k in random.rand(nsamples) * self.shape[0]]\n            result = asarray([self.values[i] for i in inds])\n\n        return self._constructor(result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes the variance across images.", "response": "def var(self):\n        \"\"\"\n        Compute the variance across images.\n        \"\"\"\n        return self._constructor(self.values.var(axis=0, keepdims=True))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef std(self):\n        return self._constructor(self.values.std(axis=0, keepdims=True))", "response": "Compute the standard deviation across images."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef squeeze(self):\n        axis = tuple(range(1, len(self.shape) - 1)) if prod(self.shape[1:]) == 1 else None\n        return self.map(lambda x: x.squeeze(axis=axis))", "response": "Return a new image with all the elements removed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute maximum projections of images along a dimension.", "response": "def max_projection(self, axis=2):\n        \"\"\"\n        Compute maximum projections of images along a dimension.\n\n        Parameters\n        ----------\n        axis : int, optional, default = 2\n            Which axis to compute projection along.\n        \"\"\"\n        if axis >= size(self.value_shape):\n            raise Exception('Axis for projection (%s) exceeds '\n                            'image dimensions (%s-%s)' % (axis, 0, size(self.value_shape)-1))\n\n        new_value_shape = list(self.value_shape)\n        del new_value_shape[axis]\n        return self.map(lambda x: amax(x, axis), value_shape=new_value_shape)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes maximum - minimum projection along a dimension.", "response": "def max_min_projection(self, axis=2):\n        \"\"\"\n        Compute maximum-minimum projection along a dimension.\n\n        This computes the sum of the maximum and minimum values.\n\n        Parameters\n        ----------\n        axis : int, optional, default = 2\n            Which axis to compute projection along.\n        \"\"\"\n        if axis >= size(self.value_shape):\n            raise Exception('Axis for projection (%s) exceeds '\n                            'image dimensions (%s-%s)' % (axis, 0, size(self.value_shape)-1))\n\n        new_value_shape = list(self.value_shape)\n        del new_value_shape[axis]\n        return self.map(lambda x: amax(x, axis) + amin(x, axis), value_shape=new_value_shape)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsubtracting a constant value or an image from all images.", "response": "def subtract(self, val):\n        \"\"\"\n        Subtract a constant value or an image from all images.\n\n        Parameters\n        ----------\n        val : int, float, or ndarray\n            Value to subtract.\n        \"\"\"\n        if isinstance(val, ndarray):\n            if val.shape != self.value_shape:\n                raise Exception('Cannot subtract image with dimensions %s '\n                                'from images with dimension %s' % (str(val.shape), str(self.value_shape)))\n\n        return self.map(lambda x: x - val, value_shape=self.value_shape)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite 2d images as PNG files.", "response": "def topng(self, path, prefix='image', overwrite=False):\n        \"\"\"\n        Write 2d images as PNG files.\n\n        Files will be written into a newly-created directory.\n        Three-dimensional data will be treated as RGB channels.\n\n        Parameters\n        ----------\n        path : string\n            Path to output directory, must be one level below an existing directory.\n\n        prefix : string\n            String to prepend to filenames.\n\n        overwrite : bool\n            If true, the directory given by path will first be deleted if it exists.\n        \"\"\"\n        from thunder.images.writers import topng\n        # TODO add back colormap and vmin/vmax\n        topng(self, path, prefix=prefix, overwrite=overwrite)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\napplies a function to each image and returns the resulting images as series data.", "response": "def map_as_series(self, func, value_size=None, dtype=None, chunk_size='auto'):\n        \"\"\"\n        Efficiently apply a function to images as series data.\n\n        For images data that represent image sequences, this method\n        applies a function to each pixel's series, and then returns to\n        the images format, using an efficient intermediate block\n        representation.\n\n        Parameters\n        ----------\n        func : function\n            Function to apply to each time series. Should take one-dimensional\n            ndarray and return the transformed one-dimensional ndarray.\n\n        value_size : int, optional, default = None\n            Size of the one-dimensional ndarray resulting from application of\n            func. If not supplied, will be automatically inferred for an extra\n            computational cost.\n\n        dtype : str, optional, default = None\n            dtype of one-dimensional ndarray resulting from application of func.\n            If not supplied it will be automatically inferred for an extra computational cost.\n\n        chunk_size : str or tuple, size of image chunk used during conversion, default = 'auto'\n            String interpreted as memory size (in kilobytes, e.g. '64').\n            The exception is the string 'auto'. In spark mode, 'auto' will choose a chunk size to make the\n            resulting blocks ~100 MB in size. In local mode, 'auto' will create a single block.\n            Tuple of ints interpreted as 'pixels per dimension'.\n        \"\"\"\n        blocks = self.toblocks(chunk_size=chunk_size)\n\n        if value_size is not None:\n            dims = list(blocks.blockshape)\n            dims[0] = value_size\n        else:\n            dims = None\n\n        def f(block):\n            return apply_along_axis(func, 0, block)\n\n        return blocks.map(f, value_shape=dims, dtype=dtype).toimages()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncollects the blocks in a list", "response": "def collect_blocks(self):\n        \"\"\"\n        Collect the blocks in a list\n        \"\"\"\n        if self.mode == 'spark':\n            return self.values.tordd().sortByKey().values().collect()\n\n        if self.mode == 'local':\n            return self.values.values.flatten().tolist()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef map(self, func, value_shape=None, dtype=None):\n        mapped = self.values.map(func, value_shape=value_shape, dtype=dtype)\n        return self._constructor(mapped).__finalize__(self, noprop=('dtype',))", "response": "Apply an array - like function to each entry in the array"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the first element of the list.", "response": "def first(self):\n        \"\"\"\n        Return the first element.\n        \"\"\"\n        if self.mode == 'spark':\n            return self.values.tordd().values().first()\n\n        if self.mode == 'local':\n            return self.values.first"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts the blocks to images.", "response": "def toimages(self):\n        \"\"\"\n        Convert blocks to images.\n        \"\"\"\n        from thunder.images.images import Images\n\n        if self.mode == 'spark':\n            values = self.values.values_to_keys((0,)).unchunk()\n\n        if self.mode == 'local':\n            values = self.values.unchunk()\n\n        return Images(values)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef toseries(self):\n        from thunder.series.series import Series\n\n        if self.mode == 'spark':\n            values = self.values.values_to_keys(tuple(range(1, len(self.shape)))).unchunk()\n\n        if self.mode == 'local':\n            values = self.values.unchunk()\n            values = rollaxis(values, 0, values.ndim)\n\n        return Series(values)", "response": "Converts the blocks to series. Series."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts the blocks to local ndarray", "response": "def toarray(self):\n        \"\"\"\n        Convert blocks to local ndarray\n        \"\"\"\n        if self.mode == 'spark':\n            return self.values.unchunk().toarray()\n\n        if self.mode == 'local':\n            return self.values.unchunk()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef flatten(self):\n        size = prod(self.shape[:-1])\n        return self.reshape(size, self.shape[-1])", "response": "Flatten the array into a single array."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef first(self):\n        if self.mode == 'local':\n            return self.values[tuple(zeros(len(self.baseaxes))) + (slice(None, None),)]\n\n        if self.mode == 'spark':\n            return self.values.first().toarray()", "response": "Return the first element of the array."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting to local mode.", "response": "def tolocal(self):\n        \"\"\"\n        Convert to local mode.\n        \"\"\"\n        from thunder.series.readers import fromarray\n\n        if self.mode == 'local':\n            logging.getLogger('thunder').warn('images already in local mode')\n            pass\n\n        return fromarray(self.toarray(), index=self.index, labels=self.labels)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tospark(self, engine=None):\n        from thunder.series.readers import fromarray\n\n        if self.mode == 'spark':\n            logging.getLogger('thunder').warn('images already in local mode')\n            pass\n\n        if engine is None:\n            raise ValueError('Must provide SparkContext')\n\n        return fromarray(self.toarray(), index=self.index, labels=self.labels, engine=engine)", "response": "Convert to spark mode."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract random sample of records.", "response": "def sample(self, n=100, seed=None):\n        \"\"\"\n        Extract random sample of records.\n\n        Parameters\n        ----------\n        n : int, optional, default = 100\n            The number of data points to sample.\n\n        seed : int, optional, default = None\n            Random seed.\n        \"\"\"\n        if n < 1:\n            raise ValueError(\"Number of samples must be larger than 0, got '%g'\" % n)\n\n        if seed is None:\n            seed = random.randint(0, 2 ** 32)\n\n        if self.mode == 'spark':\n            result = asarray(self.values.tordd().values().takeSample(False, n, seed))\n\n        else:\n            basedims = [self.shape[d] for d in self.baseaxes]\n            inds = [unravel_index(int(k), basedims) for k in random.rand(n) * prod(basedims)]\n            result = asarray([self.values[tupleize(i) + (slice(None, None),)] for i in inds])\n\n        return self._constructor(result, index=self.index)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmap an array - like function over each record.", "response": "def map(self, func, index=None, value_shape=None, dtype=None, with_keys=False):\n        \"\"\"\n        Map an array -> array function over each record.\n\n        Parameters\n        ----------\n        func : function\n            A function of a single record.\n\n        index : array-like, optional, default = None\n            If known, the index to be used following function evaluation.\n\n        value_shape : int, optional, default=None\n            Known shape of values resulting from operation. Only\n            valid in spark mode.\n\n        dtype : numpy.dtype, optional, default = None\n            If known, the type of the data following function evaluation.\n\n        with_keys : boolean, optional, default = False\n            If true, function should be of both tuple indices and series values.\n        \"\"\"\n        # if new index is given, can infer missing value_shape\n        if value_shape is None and index is not None:\n            value_shape = len(index)\n\n        if isinstance(value_shape, int):\n            values_shape = (value_shape, )\n        new = super(Series, self).map(func, value_shape=value_shape, dtype=dtype, with_keys=with_keys)\n\n        if index is not None:\n            new.index = index\n        # if series shape did not change and no index was supplied, propagate original index\n        else:\n            if len(new.index) == len(self.index):\n                new.index = self.index\n\n        return new"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes the mean across records", "response": "def mean(self):\n        \"\"\"\n        Compute the mean across records\n        \"\"\"\n        return self._constructor(self.values.mean(axis=self.baseaxes, keepdims=True))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sum(self):\n        return self._constructor(self.values.sum(axis=self.baseaxes, keepdims=True))", "response": "Compute the sum across records."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef max(self):\n        return self._constructor(self.values.max(axis=self.baseaxes, keepdims=True))", "response": "Compute the max across records."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef min(self):\n        return self._constructor(self.values.min(axis=self.baseaxes, keepdims=True))", "response": "Compute the min across records."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef between(self, left, right):\n        crit = lambda x: left <= x < right\n        return self.select(crit)", "response": "Select subset of values within the given index range."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nselects subset of values that match a given index criterion.", "response": "def select(self, crit):\n        \"\"\"\n        Select subset of values that match a given index criterion.\n\n        Parameters\n        ----------\n        crit : function, list, str, int\n            Criterion function to map to indices, specific index value,\n            or list of indices.\n        \"\"\"\n        import types\n\n        # handle lists, strings, and ints\n        if not isinstance(crit, types.FunctionType):\n            # set(\"foo\") -> {\"f\", \"o\"}; wrap in list to prevent:\n            if isinstance(crit, string_types):\n                critlist = set([crit])\n            else:\n                try:\n                    critlist = set(crit)\n                except TypeError:\n                    # typically means crit is not an iterable type; for instance, crit is an int\n                    critlist = set([crit])\n            crit = lambda x: x in critlist\n\n        # if only one index, return it directly or throw an error\n        index = self.index\n        if size(index) == 1:\n            if crit(index[0]):\n                return self\n            else:\n                raise Exception('No indices found matching criterion')\n\n        # determine new index and check the result\n        newindex = [i for i in index if crit(i)]\n        if len(newindex) == 0:\n            raise Exception('No indices found matching criterion')\n        if array(newindex == index).all():\n            return self\n\n        # use fast logical indexing to get the new values\n        subinds = where([crit(i) for i in index])\n        new = self.map(lambda x: x[subinds], index=newindex)\n\n        # if singleton, need to check whether it's an array or a scalar/int\n        # if array, recompute a new set of indices\n        if len(newindex) == 1:\n            new = new.map(lambda x: x[0], index=newindex)\n            val = new.first()\n            if size(val) == 1:\n                newindex = [newindex[0]]\n            else:\n                newindex = arange(0, size(val))\n\n        new._index = newindex\n\n        return new"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsubtracting the mean either within or across records.", "response": "def center(self, axis=1):\n        \"\"\"\n        Subtract the mean either within or across records.\n\n        Parameters\n        ----------\n        axis : int, optional, default = 1\n            Which axis to center along, within (1) or across (0) records.\n        \"\"\"\n        if axis == 1:\n            return self.map(lambda x: x - mean(x))\n        elif axis == 0:\n            meanval = self.mean().toarray()\n            return self.map(lambda x: x - meanval)\n        else:\n            raise Exception('Axis must be 0 or 1')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef standardize(self, axis=1):\n        if axis == 1:\n            return self.map(lambda x: x / std(x))\n        elif axis == 0:\n            stdval = self.std().toarray()\n            return self.map(lambda x: x / stdval)\n        else:\n            raise Exception('Axis must be 0 or 1')", "response": "Divide by standard deviation either within or across records."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef zscore(self, axis=1):\n        if axis == 1:\n            return self.map(lambda x: (x - mean(x)) / std(x))\n        elif axis == 0:\n            meanval = self.mean().toarray()\n            stdval = self.std().toarray()\n            return self.map(lambda x: (x - meanval) / stdval)\n        else:\n            raise Exception('Axis must be 0 or 1')", "response": "Subtract the mean and divide by standard deviation within or across records."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef squelch(self, threshold):\n        func = lambda x: zeros(x.shape) if max(x) < threshold else x\n        return self.map(func)", "response": "Return a new Series with all records that are below threshold."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef correlate(self, signal):\n        s = asarray(signal)\n\n        if s.ndim == 1:\n            if size(s) != self.shape[-1]:\n                raise ValueError(\"Length of signal '%g' does not match record length '%g'\"\n                                 % (size(s), self.shape[-1]))\n\n            return self.map(lambda x: corrcoef(x, s)[0, 1], index=[1])\n\n        elif s.ndim == 2:\n            if s.shape[1] != self.shape[-1]:\n                raise ValueError(\"Length of signal '%g' does not match record length '%g'\"\n                                 % (s.shape[1], self.shape[-1]))\n            newindex = arange(0, s.shape[0])\n            return self.map(lambda x: array([corrcoef(x, y)[0, 1] for y in s]), index=newindex)\n\n        else:\n            raise Exception('Signal to correlate with must have 1 or 2 dimensions')", "response": "Correlate records against one or many one - dimensional arrays."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _check_panel(self, length):\n        n = len(self.index)\n        if divmod(n, length)[1] != 0:\n            raise ValueError(\"Panel length '%g' must evenly divide length of series '%g'\"\n                             % (length, n))\n        if n == length:\n            raise ValueError(\"Panel length '%g' cannot be length of series '%g'\"\n                             % (length, n))", "response": "Check that given fixed panel length evenly divides index."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the mean across fixed sized panels of each record.", "response": "def mean_by_panel(self, length):\n        \"\"\"\n        Compute the mean across fixed sized panels of each record.\n\n        Splits each record into panels of size `length`,\n        and then computes the mean across panels.\n        Panel length must subdivide record exactly.\n\n        Parameters\n        ----------\n        length : int\n            Fixed length with which to subdivide.\n        \"\"\"\n        self._check_panel(length)\n        func = lambda v: v.reshape(-1, length).mean(axis=0)\n        newindex = arange(length)\n        return self.map(func, index=newindex)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _makemasks(self, index=None, level=0):\n        if index is None:\n            index = self.index\n\n        try:\n            dims = len(array(index).shape)\n            if dims == 1:\n                index = array(index, ndmin=2).T\n        except:\n            raise TypeError('A multi-index must be convertible to a numpy ndarray')\n\n        try:\n            index = index[:, level]\n        except:\n            raise ValueError(\"Levels must be indices into individual elements of the index\")\n\n        lenIdx = index.shape[0]\n        nlevels = index.shape[1]\n\n        combs = product(*[unique(index.T[i, :]) for i in range(nlevels)])\n        combs = array([l for l in combs])\n\n        masks = array([[array_equal(index[i], c) for i in range(lenIdx)] for c in combs])\n\n        return zip(*[(masks[x], combs[x]) for x in range(len(masks)) if masks[x].any()])", "response": "Internal function for generating masks for selecting values based on multi - index values."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nselect or filter elements of the Series by a given index value.", "response": "def select_by_index(self, val, level=0, squeeze=False, filter=False, return_mask=False):\n        \"\"\"\n        Select or filter elements of the Series by index values (across levels, if multi-index).\n\n        The index is a property of a Series object that assigns a value to each position within\n        the arrays stored in the records of the Series. This function returns a new Series where,\n        within each record, only the elements indexed by a given value(s) are retained. An index\n        where each value is a list of a fixed length is referred to as a 'multi-index',\n        as it provides multiple labels for each index location. Each of the dimensions in these\n        sublists is a 'level' of the multi-index. If the index of the Series is a multi-index, then\n        the selection can proceed by first selecting one or more levels, and then selecting one\n        or more values at each level.\n\n        Parameters\n        ----------\n        val : list of lists\n            Specifies the selected index values. List must contain one list for each level of the\n            multi-index used in the selection. For any singleton lists, the list may be replaced\n            with just the integer.\n\n        level : list of ints, optional, default=0\n            Specifies which levels in the multi-index to use when performing selection. If a single\n            level is selected, the list can be replaced with an integer. Must be the same length\n            as val.\n\n        squeeze : bool, optional, default=False\n            If True, the multi-index of the resulting Series will drop any levels that contain\n            only a single value because of the selection. Useful if indices are used as unique\n            identifiers.\n\n        filter : bool, optional, default=False\n            If True, selection process is reversed and all index values EXCEPT those specified\n            are selected.\n\n        return_mask : bool, optional, default=False\n            If True, return the mask used to implement the selection.\n        \"\"\"\n        try:\n            level[0]\n        except:\n            level = [level]\n        try:\n            val[0]\n        except:\n            val = [val]\n\n        remove = []\n        if len(level) == 1:\n            try:\n                val[0][0]\n            except:\n                val = [val]\n            if squeeze and not filter and len(val) == 1:\n                remove.append(level[0])\n        else:\n            for i in range(len(val)):\n                try:\n                    val[i][0]\n                except:\n                    val[i] = [val[i]]\n                if squeeze and not filter and len(val[i]) == 1:\n                    remove.append(level[i])\n\n        if len(level) != len(val):\n            raise ValueError(\"List of levels must be same length as list of corresponding values\")\n\n        p = product(*val)\n        selected = set([x for x in p])\n\n        masks, ind = self._makemasks(index=self.index, level=level)\n        nmasks = len(masks)\n        masks = array([masks[x] for x in range(nmasks) if tuple(ind[x]) in selected])\n\n        final_mask = masks.any(axis=0)\n        if filter:\n            final_mask = logical_not(final_mask)\n\n        indFinal = array(self.index)\n        if len(indFinal.shape) == 1:\n            indFinal = array(indFinal, ndmin=2).T\n        indFinal = indFinal[final_mask]\n\n        if squeeze:\n            indFinal = delete(indFinal, remove, axis=1)\n\n        if len(indFinal[0]) == 1:\n            indFinal = ravel(indFinal)\n\n        elif len(indFinal[1]) == 0:\n            indFinal = arange(sum(final_mask))\n\n        result = self.map(lambda v: v[final_mask], index=indFinal)\n\n        if return_mask:\n            return result, final_mask\n        else:\n            return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef aggregate_by_index(self, function, level=0):\n        result = self._map_by_index(function, level=level)\n        return result.map(lambda v: array(v), index=result.index)", "response": "Aggregate the data in each record by index."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stat_by_index(self, stat, level=0):\n        from numpy import sum, min, max\n\n        STATS = {\n            'sum': sum,\n            'mean': mean,\n            'median': median,\n            'stdev': std,\n            'max': max,\n            'min': min,\n            'count': size\n        }\n        func = STATS[stat.lower()]\n        return self.aggregate_by_index(level=level, function=func)", "response": "Compute the desired statistic for each uniue index value"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef gramian(self):\n        if self.mode == 'spark':\n            rdd = self.values.tordd()\n\n            from pyspark.accumulators import AccumulatorParam\n\n            class MatrixAccumulator(AccumulatorParam):\n                def zero(self, value):\n                    return zeros(shape(value))\n\n                def addInPlace(self, val1, val2):\n                    val1 += val2\n                    return val1\n\n            global mat\n            init = zeros((self.shape[1], self.shape[1]))\n            mat = rdd.context.accumulator(init, MatrixAccumulator())\n\n            def outer_sum(x):\n                global mat\n                mat += outer(x, x)\n\n            rdd.values().foreach(outer_sum)\n            return self._constructor(mat.value, index=self.index)\n\n        if self.mode == 'local':\n            return self._constructor(dot(self.values.T, self.values), index=self.index)", "response": "Compute the gramian of a distributed matrix."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef times(self, other):\n        if isinstance(other, ScalarType):\n            other = asarray(other)\n            index = self.index\n        else:\n            if isinstance(other, list):\n                other = asarray(other)\n            if isinstance(other, ndarray) and other.ndim < 2:\n                other = expand_dims(other, 1)\n            if not self.shape[1] == other.shape[0]:\n                raise ValueError('shapes %s and %s are not aligned' % (self.shape, other.shape))\n            index = arange(other.shape[1])\n\n        if self.mode == 'local' and isinstance(other, Series) and other.mode == 'spark':\n            raise NotImplementedError\n\n        if self.mode == 'spark' and isinstance(other, Series) and other.mode == 'spark':\n            raise NotImplementedError\n\n        if self.mode == 'local' and isinstance(other, (ndarray, ScalarType)):\n            return self._constructor(dot(self.values, other), index=index)\n\n        if self.mode == 'local' and isinstance(other, Series):\n            return self._constructor(dot(self.values, other.values), index=index)\n\n        if self.mode == 'spark' and isinstance(other, (ndarray, ScalarType)):\n            return self.map(lambda x: dot(x, other), index=index)\n\n        if self.mode == 'spark' and isinstance(other, Series):\n            return self.map(lambda x: dot(x, other.values), index=index)", "response": "Multiply a matrix by another one."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _makewindows(self, indices, window):\n        div = divmod(window, 2)\n        before = div[0]\n        after = div[0] + div[1]\n        index = asarray(self.index)\n        indices = asarray(indices)\n        if where(index == max(indices))[0][0] + after > len(index):\n            raise ValueError(\"Maximum requested index %g, with window %g, exceeds length %g\"\n                             % (max(indices), window, len(index)))\n        if where(index == min(indices))[0][0] - before < 0:\n            raise ValueError(\"Minimum requested index %g, with window %g, is less than 0\"\n                             % (min(indices), window))\n        masks = [arange(where(index == i)[0][0]-before, where(index == i)[0][0]+after, dtype='int') for i in indices]\n        return masks", "response": "This function creates a list of masks used by windowing functions that can be used by windowing functions."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\naveraging series across multiple windows specified by their centers.", "response": "def mean_by_window(self, indices, window):\n        \"\"\"\n        Average series across multiple windows specified by their centers.\n\n        Parameters\n        ----------\n        indices : array-like\n            List of times specifying window centers\n\n        window : int\n            Window size\n        \"\"\"\n        masks = self._makewindows(indices, window)\n        newindex = arange(0, len(masks[0]))\n        return self.map(lambda x: mean([x[m] for m in masks], axis=0), index=newindex)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef downsample(self, sample_factor=2):\n        if sample_factor < 0:\n            raise Exception('Factor for subsampling must be postive, got %g' % sample_factor)\n        newlength = floor(len(self.index) / sample_factor)\n        func = lambda v: v[0:int(newlength * sample_factor)].reshape(-1, sample_factor).mean(axis=1)\n        newindex = arange(newlength)\n        return self.map(func, index=newindex)", "response": "Downsample series by an integer factor by averaging."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute statistics of a Fourier decomposition on series data.", "response": "def fourier(self, freq=None):\n        \"\"\"\n        Compute statistics of a Fourier decomposition on series data.\n\n        Parameters\n        ----------\n        freq : int\n            Digital frequency at which to compute coherence and phase\n        \"\"\"\n        def get(y, freq):\n            y = y - mean(y)\n            nframes = len(y)\n            ft = fft.fft(y)\n            ft = ft[0:int(fix(nframes/2))]\n            ampFt = 2*abs(ft)/nframes\n            amp = ampFt[freq]\n            ampSum = sqrt(sum(ampFt**2))\n            co = amp / ampSum\n            ph = -(pi/2) - angle(ft[freq])\n            if ph < 0:\n                ph += pi * 2\n            return array([co, ph])\n\n        if freq >= int(fix(size(self.index)/2)):\n            raise Exception('Requested frequency, %g, is too high, '\n                            'must be less than half the series duration' % freq)\n\n        index = ['coherence', 'phase']\n        return self.map(lambda x: get(x, freq), index=index)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convolve(self, signal, mode='full'):\n\n        from numpy import convolve\n\n        s = asarray(signal)\n\n        n = size(self.index)\n        m = size(s)\n\n        # use expected lengths to make a new index\n        if mode == 'same':\n            newmax = max(n, m)\n        elif mode == 'valid':\n            newmax = max(m, n) - min(m, n) + 1\n        else:\n            newmax = n+m-1\n        newindex = arange(0, newmax)\n\n        return self.map(lambda x: convolve(x, signal, mode), index=newindex)", "response": "Convolve series data against another signal."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef crosscorr(self, signal, lag=0):\n        from scipy.linalg import norm\n\n        s = asarray(signal)\n        s = s - mean(s)\n        s = s / norm(s)\n\n        if size(s) != size(self.index):\n            raise Exception('Size of signal to cross correlate with, %g, '\n                            'does not match size of series' % size(s))\n\n        # created a matrix with lagged signals\n        if lag is not 0:\n            shifts = range(-lag, lag+1)\n            d = len(s)\n            m = len(shifts)\n            sshifted = zeros((m, d))\n            for i in range(0, len(shifts)):\n                tmp = roll(s, shifts[i])\n                if shifts[i] < 0:\n                    tmp[(d+shifts[i]):] = 0\n                if shifts[i] > 0:\n                    tmp[:shifts[i]] = 0\n                sshifted[i, :] = tmp\n            s = sshifted\n        else:\n            shifts = [0]\n\n        def get(y, s):\n            y = y - mean(y)\n            n = norm(y)\n            if n == 0:\n                b = zeros((s.shape[0],))\n            else:\n                y /= n\n                b = dot(s, y)\n            return b\n\n        return self.map(lambda x: get(x, s), index=shifts)", "response": "Cross correlate series data against another signal."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef detrend(self, method='linear', order=5):\n        check_options(method, ['linear', 'nonlinear'])\n\n        if method == 'linear':\n            order = 1\n\n        def func(y):\n            x = arange(len(y))\n            p = polyfit(x, y, order)\n            p[-1] = 0\n            yy = polyval(p, x)\n            return y - yy\n\n        return self.map(func)", "response": "Return a Series with the specified method and order."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nnormalize the data by subtracting and dividing by a baseline.", "response": "def normalize(self, method='percentile', window=None, perc=20, offset=0.1):\n        \"\"\"\n        Normalize by subtracting and dividing by a baseline.\n\n        Baseline can be derived from a global mean or percentile,\n        or a smoothed percentile estimated within a rolling window.\n        Windowed baselines may only be well-defined for\n        temporal series data.\n\n        Parameters\n        ----------\n        baseline : str, optional, default = 'percentile'\n            Quantity to use as the baseline, options are 'mean', 'percentile',\n            'window', or 'window-exact'.\n\n        window : int, optional, default = 6\n            Size of window for baseline estimation,\n            for 'window' and 'window-exact' baseline only.\n\n        perc : int, optional, default = 20\n            Percentile value to use, for 'percentile',\n            'window', or 'window-exact' baseline only.\n\n        offset : float, optional, default = 0.1\n             Scalar added to baseline during division to avoid division by 0.\n        \"\"\"\n\n        check_options(method, ['mean', 'percentile', 'window', 'window-exact'])\n\n        from warnings import warn\n        if not (method == 'window' or method == 'window-exact') and window is not None:\n            warn('Setting window without using method \"window\" has no effect')\n\n        if method == 'mean':\n            baseFunc = mean\n\n        if method == 'percentile':\n            baseFunc = lambda x: percentile(x, perc)\n\n        if method == 'window':\n            from scipy.ndimage.filters import percentile_filter\n            baseFunc = lambda x: percentile_filter(x.astype(float64), perc, window, mode='nearest')\n\n        if method == 'window-exact':\n            if window & 0x1:\n                left, right = (ceil(window/2), ceil(window/2) + 1)\n            else:\n                left, right = (window/2, window/2)\n\n            n = len(self.index)\n            baseFunc = lambda x: asarray([percentile(x[max(ix-left, 0):min(ix+right+1, n)], perc)\n                                          for ix in arange(0, n)])\n\n        def get(y):\n            b = baseFunc(y)\n            return (y - b) / (b + offset)\n\n        return self.map(get)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting to images data.", "response": "def toimages(self, chunk_size='auto'):\n        \"\"\"\n        Converts to images data.\n\n        This method is equivalent to series.toblocks(size).toimages().\n\n        Parameters\n        ----------\n        chunk_size : str or tuple, size of series chunk used during conversion, default = 'auto'\n            String interpreted as memory size (in kilobytes, e.g. '64').\n            The exception is the string 'auto', which will choose a chunk size to make the\n            resulting blocks ~100 MB in size. Int interpreted as 'number of elements'.\n            Only valid in spark mode.\n        \"\"\"\n        from thunder.images.images import Images\n\n        if chunk_size is 'auto':\n            chunk_size = str(max([int(1e5/prod(self.baseshape)), 1]))\n\n        n = len(self.shape) - 1\n\n        if self.mode == 'spark':\n            return Images(self.values.swap(tuple(range(n)), (0,), size=chunk_size))\n\n        if self.mode == 'local':\n            return Images(self.values.transpose((n,) + tuple(range(0, n))))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites data to binary files.", "response": "def tobinary(self, path, prefix='series', overwrite=False, credentials=None):\n        \"\"\"\n        Write data to binary files.\n\n        Parameters\n        ----------\n        path : string path or URI to directory to be created\n            Output files will be written underneath path.\n            Directory will be created as a result of this call.\n\n        prefix : str, optional, default = 'series'\n            String prefix for files.\n\n        overwrite : bool\n            If true, path and all its contents will be deleted and\n            recreated as partof this call.\n        \"\"\"\n        from thunder.series.writers import tobinary\n        tobinary(self, path, prefix=prefix, overwrite=overwrite, credentials=credentials)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nselect a set of files from a list of files.", "response": "def select(files, start, stop):\n    \"\"\"\n    Helper function for handling start and stop indices\n    \"\"\"\n    if start or stop:\n        if start is None:\n            start = 0\n        if stop is None:\n            stop = len(files)\n        files = files[start:stop]\n    return files"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef readlocal(path, offset=None, size=-1):\n    try:\n        with open(path, 'rb') as f:\n            if offset:\n                f.seek(offset)\n            buf = f.read(size)\n    except IOError as e:\n        if e.errno == errno.ENOENT:\n            raise FileNotFoundError(e)\n        else:\n            raise\n    return buf", "response": "Reads a local file into a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef listrecursive(path, ext=None):\n    filenames = set()\n    for root, dirs, files in os.walk(path):\n        if ext:\n            if ext == 'tif' or ext == 'tiff':\n                tmp = fnmatch.filter(files, '*.' + 'tiff')\n                files = tmp + fnmatch.filter(files, '*.' + 'tif')\n            else:\n                files = fnmatch.filter(files, '*.' + ext)\n        for filename in files:\n            filenames.add(os.path.join(root, filename))\n    filenames = list(filenames)\n    filenames.sort()\n    return sorted(filenames)", "response": "List all files in a directory recursively."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlist all files in a directory.", "response": "def listflat(path, ext=None):\n    \"\"\"\n    List files without recursion\n    \"\"\"\n    if os.path.isdir(path):\n        if ext:\n            if ext == 'tif' or ext == 'tiff':\n                files = glob.glob(os.path.join(path, '*.tif'))\n                files = files + glob.glob(os.path.join(path, '*.tiff'))\n            else:\n                files = glob.glob(os.path.join(path, '*.' + ext))\n        else:\n            files = [os.path.join(path, fname) for fname in os.listdir(path)]\n    else:\n        files = glob.glob(path)\n    # filter out directories\n    files = [fpath for fpath in files if not isinstance(fpath, list) and not os.path.isdir(fpath)]\n    return sorted(files)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef normalize_scheme(path, ext):\n    path = addextension(path, ext)\n\n    parsed = urlparse(path)\n    if parsed.scheme:\n        # this appears to already be a fully-qualified URI\n        return path\n    else:\n        # this looks like a local path spec\n        import os\n        dirname, filename = os.path.split(path)\n        if not os.path.isabs(dirname):\n            # need to make relative local paths absolute\n            dirname = os.path.abspath(dirname)\n            path = os.path.join(dirname, filename)\n        return \"file://\" + path", "response": "Normalize scheme for paths related to hdfs\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list(path, ext=None, start=None, stop=None, recursive=False):\n        files = listflat(path, ext) if not recursive else listrecursive(path, ext)\n        if len(files) < 1:\n            raise FileNotFoundError('Cannot find files of type \"%s\" in %s'\n                                    % (ext if ext else '*', path))\n        files = select(files, start, stop)\n\n        return files", "response": "Get sorted list of files matching path and extension."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read(self, path, ext=None, start=None, stop=None, recursive=False, npartitions=None):\n        path = uri_to_path(path)\n        files = self.list(path, ext=ext, start=start, stop=stop, recursive=recursive)\n\n        nfiles = len(files)\n        self.nfiles = nfiles\n\n        if spark and isinstance(self.engine, spark):\n            npartitions = min(npartitions, nfiles) if npartitions else nfiles\n            rdd = self.engine.parallelize(enumerate(files), npartitions)\n            return rdd.map(lambda kv: (kv[0], readlocal(kv[1]), kv[1]))\n        else:\n            return [(k, readlocal(v), v) for k, v in enumerate(files)]", "response": "Reads the file with the given path and returns an RDD of k - v pairs."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlists files in a directory or file.", "response": "def list(path, filename=None, start=None, stop=None, recursive=False, directories=False):\n        \"\"\"\n        List files specified by dataPath.\n\n        Datapath may include a single wildcard ('*') in the filename specifier.\n\n        Returns sorted list of absolute path strings.\n        \"\"\"\n        path = uri_to_path(path)\n\n        if not filename and recursive:\n            return listrecursive(path)\n\n        if filename:\n            if os.path.isdir(path):\n                path = os.path.join(path, filename)\n            else:\n                path = os.path.join(os.path.dirname(path), filename)\n        else:\n            if os.path.isdir(path) and not directories:\n                path = os.path.join(path, \"*\")\n\n        files = glob.glob(path)\n\n        if not directories:\n            files = [fpath for fpath in files if not os.path.isdir(fpath)]\n\n        files.sort()\n        files = select(files, start, stop)\n        return files"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_query(query, delim='/'):\n        key = ''\n        prefix = ''\n        postfix = ''\n\n        parsed = urlparse(query)\n        query = parsed.path.lstrip(delim)\n        bucket = parsed.netloc\n\n        if not parsed.scheme.lower() in ('', \"gs\", \"s3\", \"s3n\"):\n            raise ValueError(\"Query scheme must be one of '', 'gs', 's3', or 's3n'; \"\n                             \"got: '%s'\" % parsed.scheme)\n        storage = parsed.scheme.lower()\n\n        if not bucket.strip() and query:\n            toks = query.split(delim, 1)\n            bucket = toks[0]\n            if len(toks) == 2:\n                key = toks[1]\n            else:\n                key = ''\n\n        if not bucket.strip():\n            raise ValueError(\"Could not parse bucket name from query string '%s'\" % query)\n\n        tokens = query.split(\"*\")\n        n = len(tokens)\n        if n == 0:\n            pass\n        elif n == 1:\n            key = tokens[0]\n        elif n == 2:\n            index = tokens[0].rfind(delim)\n            if index >= 0:\n                key = tokens[0][:(index + 1)]\n                prefix = tokens[0][(index + 1):] if len(tokens[0]) > (index + 1) else ''\n            else:\n                prefix = tokens[0]\n            postfix = tokens[1]\n        else:\n            raise ValueError(\"Only one wildcard ('*') allowed in query string, got: '%s'\" % query)\n\n        return storage, bucket, key, prefix, postfix", "response": "Parse a boto query string and return a tuple of storage bucket key prefix postfix"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve keys from a bucket.", "response": "def retrieve_keys(bucket, key, prefix='', postfix='', delim='/',\n                      directories=False, recursive=False):\n        \"\"\"\n        Retrieve keys from a bucket\n        \"\"\"\n        if key and prefix:\n            assert key.endswith(delim)\n\n        key += prefix\n        # check whether key is a directory\n        if not key.endswith(delim) and key:\n            # check for matching prefix\n            if BotoClient.check_prefix(bucket, key + delim, delim=delim):\n                # found a directory\n                key += delim\n\n        listdelim = delim if not recursive else None\n        results = bucket.list(prefix=key, delimiter=listdelim)\n        if postfix:\n            func = lambda k_: BotoClient.filter_predicate(k_, postfix, inclusive=True)\n            return filter(func, results)\n        elif not directories:\n            func = lambda k_: BotoClient.filter_predicate(k_, delim, inclusive=False)\n            return filter(func, results)\n        else:\n            return results"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting scheme bucket and keys for a set of files", "response": "def getfiles(self, path, ext=None, start=None, stop=None, recursive=False):\n        \"\"\"\n        Get scheme, bucket, and keys for a set of files\n        \"\"\"\n        from .utils import connection_with_anon, connection_with_gs\n\n        parse = BotoClient.parse_query(path)\n\n        scheme = parse[0]\n        bucket_name = parse[1]\n\n        if scheme == 's3' or scheme == 's3n':\n            conn = connection_with_anon(self.credentials)\n            bucket = conn.get_bucket(parse[1])\n        elif scheme == 'gs':\n            conn = connection_with_gs(bucket_name)\n            bucket = conn.get_bucket()\n        else:\n            raise NotImplementedError(\"No file reader implementation for URL scheme \" + scheme)\n\n        keys = BotoClient.retrieve_keys(\n            bucket, parse[2], prefix=parse[3], postfix=parse[4], recursive=recursive)\n        keylist = [key.name for key in keys]\n        if ext:\n            if ext == 'tif' or ext == 'tiff':\n                keylist = [keyname for keyname in keylist if keyname.endswith('tif')]\n                keylist.append([keyname for keyname in keylist if keyname.endswith('tiff')])\n            else:\n                keylist = [keyname for keyname in keylist if keyname.endswith(ext)]\n\n        keylist.sort()\n        keylist = select(keylist, start, stop)\n\n        return scheme, bucket.name, keylist"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list(self, dataPath, ext=None, start=None, stop=None, recursive=False):\n        scheme, bucket_name, keylist = self.getfiles(\n            dataPath, ext=ext, start=start, stop=stop, recursive=recursive)\n\n        return [\"%s:///%s/%s\" % (scheme, bucket_name, key) for key in keylist]", "response": "List files from remote storage"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read(self, path, ext=None, start=None, stop=None, recursive=False, npartitions=None):\n        from .utils import connection_with_anon, connection_with_gs\n\n        path = addextension(path, ext)\n        scheme, bucket_name, keylist = self.getfiles(\n            path, start=start, stop=stop, recursive=recursive)\n\n        if not keylist:\n            raise FileNotFoundError(\"No objects found for '%s'\" % path)\n\n        credentials = self.credentials\n\n        self.nfiles = len(keylist)\n\n        if spark and isinstance(self.engine, spark):\n\n            def getsplit(kvIter):\n                if scheme == 's3' or scheme == 's3n':\n                    conn = connection_with_anon(credentials)\n                    bucket = conn.get_bucket(bucket_name)\n                elif scheme == 'gs':\n                    conn = boto.storage_uri(bucket_name, 'gs')\n                    bucket = conn.get_bucket()\n                else:\n                    raise NotImplementedError(\"No file reader implementation for URL scheme \" + scheme)\n\n                for kv in kvIter:\n                    idx, keyname = kv\n                    key = bucket.get_key(keyname)\n                    buf = key.get_contents_as_string()\n                    yield idx, buf, keyname\n\n            npartitions = min(npartitions, self.nfiles) if npartitions else self.nfiles\n            rdd = self.engine.parallelize(enumerate(keylist), npartitions)\n            return rdd.mapPartitions(getsplit)\n\n        else:\n\n            if scheme == 's3' or scheme == 's3n':\n                conn = connection_with_anon(credentials)\n                bucket = conn.get_bucket(bucket_name)\n            elif scheme == 'gs':\n                conn = connection_with_gs(bucket_name)\n                bucket = conn.get_bucket()\n            else:\n                raise NotImplementedError(\"No file reader implementation for URL scheme \" + scheme)\n\n            def getsplit(kv):\n                idx, keyName = kv\n                key = bucket.get_key(keyName)\n                buf = key.get_contents_as_string()\n                return idx, buf, keyName\n\n            return [getsplit(kv) for kv in enumerate(keylist)]", "response": "Reads a file and returns an RDD of bucket keyname buffer k - v pairs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getkeys(self, path, filename=None, directories=False, recursive=False):\n        from .utils import connection_with_anon, connection_with_gs\n\n        parse = BotoClient.parse_query(path)\n\n        scheme = parse[0]\n        bucket_name = parse[1]\n        key = parse[2]\n\n        if scheme == 's3' or scheme == 's3n':\n            conn = connection_with_anon(self.credentials)\n            bucket = conn.get_bucket(bucket_name)\n        elif scheme == 'gs':\n            conn = connection_with_gs(bucket_name)\n            bucket = conn.get_bucket()\n        else:\n            raise NotImplementedError(\"No file reader implementation for URL scheme \" + scheme)\n\n        if filename:\n            if not key.endswith(\"/\"):\n                if self.check_prefix(bucket, key + \"/\"):\n                    key += \"/\"\n                else:\n                    index = key.rfind(\"/\")\n                    if index >= 0:\n                        key = key[:(index+1)]\n                    else:\n                        key = \"\"\n            key += filename\n\n        keylist = BotoClient.retrieve_keys(bucket, key, prefix=parse[3], postfix=parse[4],\n                                           directories=directories, recursive=recursive)\n        return scheme, keylist", "response": "Get matching keys for a path."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a single matching key for a path.", "response": "def getkey(self, path, filename=None):\n        \"\"\"\n        Get single matching key for a path\n        \"\"\"\n        scheme, keys = self.getkeys(path, filename=filename)\n        try:\n            key = next(keys)\n        except StopIteration:\n            raise FileNotFoundError(\"Could not find object for: '%s'\" % path)\n\n        # we expect to only have a single key returned\n        nextKey = None\n        try:\n            nextKey = next(keys)\n        except StopIteration:\n            pass\n        if nextKey:\n            raise ValueError(\"Found multiple keys for: '%s'\" % path)\n        return scheme, key"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list(self, path, filename=None, start=None, stop=None, recursive=False, directories=False):\n        storageScheme, keys = self.getkeys(\n            path, filename=filename, directories=directories, recursive=recursive)\n        keys = [storageScheme + \":///\" + key.bucket.name + \"/\" + key.name for key in keys]\n        keys.sort()\n        keys = select(keys, start, stop)\n        return keys", "response": "List objects specified by path."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read(self, path, filename=None, offset=None, size=-1):\n        storageScheme, key = self.getkey(path, filename=filename)\n\n        if offset or (size > -1):\n            if not offset:\n                offset = 0\n            if size > -1:\n                sizeStr = offset + size - 1  # range header is inclusive\n            else:\n                sizeStr = \"\"\n            headers = {\"Range\": \"bytes=%d-%s\" % (offset, sizeStr)}\n            return key.get_contents_as_string(headers=headers)\n        else:\n            return key.get_contents_as_string()", "response": "Read a file specified by path."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef open(self, path, filename=None):\n        scheme, key = self.getkey(path, filename=filename)\n        return BotoReadFileHandle(scheme, key)", "response": "Open a file specified by path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking that specified output path does not already exist.", "response": "def check_path(path, credentials=None):\n    \"\"\"\n    Check that specified output path does not already exist\n\n    The ValueError message will suggest calling with overwrite=True;\n    this function is expected to be called from the various output methods\n    that accept an 'overwrite' keyword argument.\n    \"\"\"\n    from thunder.readers import get_file_reader\n    reader = get_file_reader(path)(credentials=credentials)\n    existing = reader.list(path, directories=True)\n    if existing:\n        raise ValueError('Path %s appears to already exist. Specify a new directory, '\n                         'or call with overwrite=True to overwrite.' % path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconnects to S3 with automatic handling for anonymous access.", "response": "def connection_with_anon(credentials, anon=True):\n    \"\"\"\n    Connect to S3 with automatic handling for anonymous access.\n\n    Parameters\n    ----------\n    credentials : dict\n        AWS access key ('access') and secret access key ('secret')\n\n    anon : boolean, optional, default = True\n        Whether to make an anonymous connection if credentials fail to authenticate\n    \"\"\"\n    from boto.s3.connection import S3Connection\n    from boto.exception import NoAuthHandlerFound\n\n    try:\n        conn = S3Connection(aws_access_key_id=credentials['access'],\n                            aws_secret_access_key=credentials['secret'])\n        return conn\n\n    except NoAuthHandlerFound:\n        if anon:\n            conn = S3Connection(anon=True)\n            return conn\n        else:\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nactivate a new object.", "response": "def activate(self, path, isdirectory):\n        \"\"\"\n        Set up a boto connection.\n        \"\"\"\n        from .utils import connection_with_anon, connection_with_gs\n\n        parsed = BotoClient.parse_query(path)\n\n        scheme = parsed[0]\n        bucket_name = parsed[1]\n        key = parsed[2]\n\n        if scheme == 's3' or scheme == 's3n':\n            conn = connection_with_anon(self.credentials)\n            bucket = conn.get_bucket(bucket_name)\n        elif scheme == 'gs':\n            conn = connection_with_gs(bucket_name)\n            bucket = conn.get_bucket()\n        else:\n            raise NotImplementedError(\"No file reader implementation for URL scheme \" + scheme)\n\n        if isdirectory and (not key.endswith(\"/\")):\n            key += \"/\"\n\n        self._scheme = scheme\n        self._conn = conn\n        self._key = key\n        self._bucket = bucket\n        self._active = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef topng(images, path, prefix=\"image\", overwrite=False, credentials=None):\n    value_shape = images.value_shape\n    if not len(value_shape) in [2, 3]:\n        raise ValueError(\"Only 2D or 3D images can be exported to png, \"\n                         \"images are %d-dimensional.\" % len(value_shape))\n\n    from scipy.misc import imsave\n    from io import BytesIO\n    from thunder.writers import get_parallel_writer\n\n    def tobuffer(kv):\n        key, img = kv\n        fname = prefix+\"-\"+\"%05d.png\" % int(key)\n        bytebuf = BytesIO()\n        imsave(bytebuf, img, format='PNG')\n        return fname, bytebuf.getvalue()\n\n    writer = get_parallel_writer(path)(path, overwrite=overwrite, credentials=credentials)\n    images.foreach(lambda x: writer.write(tobuffer(x)))", "response": "Write out PNG files for 2D or 3D images."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tobinary(images, path, prefix=\"image\", overwrite=False, credentials=None):\n    from thunder.writers import get_parallel_writer\n\n    def tobuffer(kv):\n        key, img = kv\n        fname = prefix + \"-\" + \"%05d.bin\" % int(key)\n        return fname, img.copy()\n\n    writer = get_parallel_writer(path)(path, overwrite=overwrite, credentials=credentials)\n    images.foreach(lambda x: writer.write(tobuffer(x)))\n    config(path, list(images.value_shape), images.dtype, overwrite=overwrite)", "response": "Write out images as binary files."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates the days in a lunar year from the lunar year s info", "response": "def yearInfo2yearDay(yearInfo):\n    '''calculate the days in a lunar year from the lunar year's info\n\n    >>> yearInfo2yearDay(0) # no leap month, and every month has 29 days.\n    348\n    >>> yearInfo2yearDay(1) # 1 leap month, and every month has 29 days.\n    377\n    >>> yearInfo2yearDay((2**12-1)*16) # no leap month, and every month has 30 days.\n    360\n    >>> yearInfo2yearDay((2**13-1)*16+1) # 1 leap month, and every month has 30 days.\n    390\n    >>> # 1 leap month, and every normal month has 30 days, and leap month has 29 days.\n    >>> yearInfo2yearDay((2**12-1)*16+1)\n    389\n    '''\n    yearInfo = int(yearInfo)\n\n    res = 29 * 12\n\n    leap = False\n    if yearInfo % 16 != 0:\n        leap = True\n        res += 29\n\n    yearInfo //= 16\n\n    for i in range(12 + leap):\n        if yearInfo % 2 == 1:\n            res += 1\n        yearInfo //= 2\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a new instance of the class LunarDate from a given solar date.", "response": "def fromSolarDate(year, month, day):\n        '''\n        >>> LunarDate.fromSolarDate(1900, 1, 31)\n        LunarDate(1900, 1, 1, 0)\n        >>> LunarDate.fromSolarDate(2008, 10, 2)\n        LunarDate(2008, 9, 4, 0)\n        >>> LunarDate.fromSolarDate(1976, 10, 1)\n        LunarDate(1976, 8, 8, 1)\n        >>> LunarDate.fromSolarDate(2033, 10, 23)\n        LunarDate(2033, 10, 1, 0)\n        '''\n        solarDate = datetime.date(year, month, day)\n        offset = (solarDate - LunarDate._startDate).days\n        return LunarDate._fromOffset(offset)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef toSolarDate(self):\n        '''\n        >>> LunarDate(1900, 1, 1).toSolarDate()\n        datetime.date(1900, 1, 31)\n        >>> LunarDate(2008, 9, 4).toSolarDate()\n        datetime.date(2008, 10, 2)\n        >>> LunarDate(1976, 8, 8, 1).toSolarDate()\n        datetime.date(1976, 10, 1)\n        >>> LunarDate(2004, 1, 30).toSolarDate()\n        Traceback (most recent call last):\n        ...\n        ValueError: day out of range\n        >>> LunarDate(2004, 13, 1).toSolarDate()\n        Traceback (most recent call last):\n        ...\n        ValueError: month out of range\n        >>> LunarDate(2100, 1, 1).toSolarDate()\n        Traceback (most recent call last):\n        ...\n        ValueError: year out of range [1900, 2100)\n        >>>\n        '''\n        def _calcDays(yearInfo, month, day, isLeapMonth):\n            isLeapMonth = int(isLeapMonth)\n            res = 0\n            ok = False\n            for _month, _days, _isLeapMonth in self._enumMonth(yearInfo):\n                if (_month, _isLeapMonth) == (month, isLeapMonth):\n                    if 1 <= day <= _days:\n                        res += day - 1\n                        return res\n                    else:\n                        raise ValueError(\"day out of range\")\n                res += _days\n\n            raise ValueError(\"month out of range\")\n\n        offset = 0\n        start_year = 1900\n        end_year = start_year + len(yearInfos)\n        if start_year < 1900 or self.year >= end_year:\n            raise ValueError('year out of range [{}, {})'.format(start_year, end_year))\n        yearIdx = self.year - 1900\n        for i in range(yearIdx):\n            offset += yearDays[i]\n\n        offset += _calcDays(yearInfos[yearIdx], self.month, self.day, self.isLeapMonth)\n        return self._startDate + datetime.timedelta(days=offset)", "response": "Convert a LunarDate object to a Solar date."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getContext(context):\n    context = aq_parent(aq_base(context))\n    if not context or IBrowserView.providedBy(context):\n        return getSite()\n    return context", "response": "Return a safe context."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncleaning up a unique id which doesn t match the system generated ids", "response": "def cleanupFilename(self, name):\n        \"\"\"Generate a unique id which doesn't match the system generated ids\"\"\"\n\n        context = self.context\n        id = ''\n        name = name.replace('\\\\', '/')  # Fixup Windows filenames\n        name = name.split('/')[-1]  # Throw away any path part.\n        for c in name:\n            if c.isalnum() or c in '._':\n                id += c\n\n        # Raise condition here, but not a lot we can do about that\n        if context.check_id(id) is None and getattr(context, id, None) is None:\n            return id\n\n        # Now make the id unique\n        count = 1\n        while 1:\n            if count == 1:\n                sc = ''\n            else:\n                sc = str(count)\n            newid = \"copy{0:s}_of_{1:s}\".format(sc, id)\n            if context.check_id(newid) is None \\\n                    and getattr(context, newid, None) is None:\n                return newid\n            count += 1"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_data_slots(value):\n    value = unquote(value)\n    if '>' in value:\n        wrappers, children = value.split('>', 1)\n    else:\n        wrappers = value\n        children = ''\n    if '*' in children:\n        prepends, appends = children.split('*', 1)\n    else:\n        prepends = children\n        appends = ''\n\n    wrappers = list(filter(bool, list(map(str.strip, wrappers.split()))))\n    prepends = list(filter(bool, list(map(str.strip, prepends.split()))))\n    appends = list(filter(bool, list(map(str.strip, appends.split()))))\n\n    return wrappers, prepends, appends", "response": "Parse data - slots value into a list of slots used to wrap node prepend to node and append to node."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a main_template compatible layout", "response": "def cook_layout(layout, ajax):\n    \"\"\"Return main_template compatible layout\"\"\"\n    # Fix XHTML layouts with CR[+LF] line endings\n    layout = re.sub('\\r', '\\n', re.sub('\\r\\n', '\\n', layout))\n\n    # Parse layout\n    if isinstance(layout, six.text_type):\n        result = getHTMLSerializer([layout.encode('utf-8')], encoding='utf-8')\n    else:\n        result = getHTMLSerializer([layout], encoding='utf-8')\n\n    # Fix XHTML layouts with inline js (etree.tostring breaks all <![CDATA[)\n    if '<![CDATA[' in layout:\n        result.serializer = html.tostring\n\n    # Wrap all panels with a metal:fill-slot -tag:\n    all_slots = []\n    for layoutPanelNode in slotsXPath(result.tree):\n        data_slots = layoutPanelNode.attrib['data-slots']\n        all_slots += wrap_append_prepend_slots(layoutPanelNode, data_slots)\n        del layoutPanelNode.attrib['data-slots']\n\n    # When no slots are explicitly defined, try to inject the very default\n    # slots\n    if len(all_slots) == 0:\n        for node in result.tree.xpath('//*[@data-panel=\"content\"]'):\n            wrap_append_prepend_slots(\n                node, 'content > body header main * content-core')\n\n    # Append implicit slots\n    head = result.tree.getroot().find('head')\n    if not ajax and head is not None:\n        for name in ['top_slot', 'head_slot',\n                     'style_slot', 'javascript_head_slot']:\n            slot = etree.Element('{{{0:s}}}{1:s}'.format(NSMAP['metal'], name),\n                                 nsmap=NSMAP)\n            slot.attrib['define-slot'] = name\n            head.append(slot)\n\n    template = TEMPLATE\n    metal = 'xmlns:metal=\"http://namespaces.zope.org/metal\"'\n    return (template % ''.join(result)).replace(metal, '')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef existing(self):\n        catalog = api.portal.get_tool('portal_catalog')\n        results = []\n        layout_path = self._get_layout_path(\n            self.request.form.get('layout', '')\n        )\n        for brain in catalog(layout=layout_path):\n            results.append({\n                'title': brain.Title,\n                'url': brain.getURL()\n            })\n        return json.dumps({\n            'total': len(results),\n            'data': results\n        })", "response": "find existing content assigned to this layout"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncompiles a LaTeX snippet to png", "response": "def latex2png(snippet, outfile):\n    \"\"\"Compiles a LaTeX snippet to png\"\"\"\n    pngimage = os.path.join(IMAGEDIR, outfile + '.png')\n    environment = os.environ\n    environment['openout_any'] = 'a'\n    environment['shell_escape_commands'] = \\\n        \"bibtex,bibtex8,kpsewhich,makeindex,mpost,repstopdf,gregorio\"\n    proc = Popen(\n        [\"lualatex\", '-output-directory=' + IMAGEDIR],\n        stdin=PIPE,\n        stdout=DEVNULL,\n        env=environment\n    )\n    proc.stdin.write(\n        (\n            LATEX_DOC % (snippet)\n        ).encode(\"utf-8\")\n    )\n    proc.communicate()\n    proc.stdin.close()\n    call([\"pdfcrop\", os.path.join(IMAGEDIR, \"texput.pdf\")], stdout=DEVNULL)\n    call(\n        [\n            \"gs\",\n            \"-sDEVICE=pngalpha\",\n            \"-r144\",\n            \"-sOutputFile=\" + pngimage,\n            os.path.join(IMAGEDIR, \"texput-crop.pdf\"),\n        ],\n        stdout=DEVNULL,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef gabc(elem, doc):\n    if type(elem) == Code and \"gabc\" in elem.classes:\n        if doc.format == \"latex\":\n            if elem.identifier == \"\":\n                label = \"\"\n            else:\n                label = '\\\\label{' + elem.identifier + '}'\n            return latex(\n                \"\\n\\\\smallskip\\n{%\\n\" +\n                latexsnippet('\\\\gregorioscore{' + elem.text + '}', elem.attributes) +\n                \"%\\n}\" +\n                label\n            )\n        else:\n            infile = elem.text + (\n                '.gabc' if '.gabc' not in elem.text else ''\n            )\n            with open(infile, 'r') as doc:\n                code = doc.read().split('%%\\n')[1]\n            return Image(png(\n                    elem.text,\n                    latexsnippet('\\\\gregorioscore', elem.attributes)\n                ))\n    elif type(elem) == CodeBlock and \"gabc\" in elem.classes:\n        if doc.format == \"latex\":\n            if elem.identifier == \"\":\n                label = \"\"\n            else:\n                label = '\\\\label{' + elem.identifier + '}'\n            return latexblock(\n                \"\\n\\\\smallskip\\n{%\\n\" +\n                latexsnippet('\\\\gabcsnippet{' + elem.text + '}', elem.attributes) +\n                \"%\\n}\" +\n                label\n                )\n        else:\n            return Para(Image(url=png(elem.text, latexsnippet('\\\\gabcsnippet', elem.attributes))))", "response": "Handle gabc file inclusion and gabc code block."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load(input_stream=None):\n\n    if input_stream is None:\n        input_stream = io.open(sys.stdin.fileno()) if py2 else io.TextIOWrapper(sys.stdin.buffer, encoding='utf-8')\n\n    # Load JSON and validate it\n    doc = json.load(input_stream, object_pairs_hook=from_json)\n\n    # Notes:\n    # - We use 'object_pairs_hook' instead of 'object_hook' to preserve the\n    #   order of the metadata.\n    # - The hook gets called for dicts (not lists), and the deepest dicts\n    #   get called first (so you can ensure that when you receive a dict,\n    #   its contents have already been fed to the hook).\n\n    # Compatibility:\n    # - Before Pandoc 1.8 (1.7 or earlier, AKA \"Pandoc Legacy\"),\n    #   the JSON is a list:\n    #   [{\"unMeta\":{META}},[BLOCKS]]\n    # - Afterwards, it's a dict:\n    #   {\"pandoc-api-version\" : [MAJ, MIN, REV],\n    #    \"meta\" : META, \"blocks\": BLOCKS}\n    # - This means that on legacy, the hook WILL NOT get called on the entire\n    #   document and we need to create the Doc() element by hand\n\n    # Corner cases:\n    # - If META is missing, 'object_pairs_hook' will receive an empty list\n\n    # Output format\n    format = sys.argv[1] if len(sys.argv) > 1 else 'html'\n\n    # API Version\n    if isinstance(doc, Doc):\n        # Modern Pandoc\n        doc.format = format\n        pass\n    else:\n        # Legacy Pandoc\n        metadata, items = doc\n        assert type(items) == list\n        assert len(doc) == 2, 'json.load returned list with unexpected size:'\n        doc = Doc(*items, metadata=metadata, format=format)\n\n    return doc", "response": "Load a JSON - encoded document and return a : class :. Doc element."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndumps a Palflute. Doc object into a JSON - encoded text string.", "response": "def dump(doc, output_stream=None):\n    \"\"\"\n    Dump a :class:`.Doc` object into a JSON-encoded text string.\n\n    The output will be sent to :data:`sys.stdout` unless an alternative\n    text stream is given.\n\n    To dump to :data:`sys.stdout` just do:\n\n        >>> import panflute as pf\n        >>> doc = pf.Doc(Para(Str('a')))  # Create sample document\n        >>> pf.dump(doc)\n\n    To dump to file:\n\n        >>> with open('some-document.json', 'w'. encoding='utf-8') as f:\n        >>>     pf.dump(doc, f)\n\n    To dump to a  string:\n\n        >>> import io\n        >>> with io.StringIO() as f:\n        >>>     pf.dump(doc, f)\n        >>>     contents = f.getvalue()\n\n    :param doc: document, usually created with :func:`.load`\n    :type doc: :class:`.Doc`\n    :param output_stream: text stream used as output\n        (default is :data:`sys.stdout`)\n    \"\"\"\n\n    assert type(doc) == Doc, \"panflute.dump needs input of type panflute.Doc\"\n    if output_stream is None:\n        sys.stdout = codecs.getwriter(\"utf-8\")(sys.stdout) if py2 else codecs.getwriter(\"utf-8\")(sys.stdout.detach())\n        output_stream = sys.stdout\n\n    # Switch to legacy JSON output; eg: {'t': 'Space', 'c': []}\n    if doc.api_version is None:\n\n        # Switch .to_json() to legacy\n        Citation.backup = Citation.to_json\n        Citation.to_json = Citation.to_json_legacy\n\n        # Switch ._slots_to_json() to legacy\n        for E in [Table, OrderedList, Quoted, Math]:\n            E.backup = E._slots_to_json\n            E._slots_to_json = E._slots_to_json_legacy\n\n        # Switch .to_json() to method of base class\n        for E in EMPTY_ELEMENTS:\n            E.backup = E.to_json\n            E.to_json = Element.to_json\n\n    json_serializer = lambda elem: elem.to_json()\n\n    output_stream.write(json.dumps(\n        obj=doc,\n        default=json_serializer,  # Serializer\n        check_circular=False,\n        separators=(',', ':'),  # Compact separators, like Pandoc\n        ensure_ascii=False  # For Pandoc compat\n    ))\n\n    # Undo legacy changes\n    if doc.api_version is None:\n        Citation.to_json = Citation.backup\n        for E in [Table, OrderedList, Quoted, Math]:\n            E._slots_to_json = E.backup\n        for E in EMPTY_ELEMENTS:\n            E.to_json = E.backup"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning the actions on the specified Pandoc document and returns the resulting Pandoc document.", "response": "def run_filters(actions,\n                prepare=None, finalize=None,\n                input_stream=None, output_stream=None,\n                doc=None,\n                **kwargs):\n    \"\"\"\n    Receive a Pandoc document from the input stream (default is stdin),\n    walk through it applying the functions in *actions* to each element,\n    and write it back to the output stream (default is stdout).\n\n    Notes:\n\n    - It receives and writes the Pandoc documents as JSON--encoded strings;\n      this is done through the :func:`.load` and :func:`.dump` functions.\n    - It walks through the document once for every function in *actions*,\n      so the actions are applied sequentially.\n    - By default, it will read from stdin and write to stdout,\n      but these can be modified.\n    - It can also apply functions to the entire document at the beginning and\n      end; this allows for global operations on the document.\n    - If ``doc`` is a :class:`.Doc` instead of ``None``, ``run_filters``\n      will return the document instead of writing it to the output stream.\n\n    :param actions: sequence of functions; each function takes (element, doc)\n     as argument, so a valid header would be ``def action(elem, doc):``\n    :type actions: [:class:`function`]\n    :param prepare: function executed at the beginning;\n     right after the document is received and parsed\n    :type prepare: :class:`function`\n    :param finalize: function executed at the end;\n     right before the document is converted back to JSON and written to stdout.\n    :type finalize: :class:`function`\n    :param input_stream: text stream used as input\n        (default is :data:`sys.stdin`)\n    :param output_stream: text stream used as output\n        (default is :data:`sys.stdout`)\n    :param doc: ``None`` unless running panflute as a filter, in which case this will be a :class:`.Doc` element\n    :type doc: ``None`` | :class:`.Doc`\n    :param \\*kwargs: keyword arguments will be passed through to the *action*\n     functions (so they can actually receive more than just two arguments\n     (*element* and *doc*)\n    \"\"\"\n\n    load_and_dump = (doc is None)\n\n    if load_and_dump:\n        doc = load(input_stream=input_stream)\n\n    if prepare is not None:\n        prepare(doc)\n\n    for action in actions:\n        if kwargs:\n            action = partial(action, **kwargs)\n        doc = doc.walk(action, doc)\n\n    if finalize is not None:\n        finalize(doc)\n\n    if load_and_dump:\n        dump(doc, output_stream=output_stream)\n    else:\n        return(doc)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve Pandoc Reader options from the environment", "response": "def load_reader_options():\n    \"\"\"\n    Retrieve Pandoc Reader options from the environment\n    \"\"\"\n    options = os.environ['PANDOC_READER_OPTIONS']\n    options = json.loads(options, object_pairs_hook=OrderedDict)\n    return options"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef gabc(key, value, fmt, meta):                   # pylint:disable=I0011,W0613\n    if key == 'Code':\n        [[ident, classes, kvs], contents] = value  # pylint:disable=I0011,W0612\n        kvs = {key: value for key, value in kvs}\n        if \"gabc\" in classes:\n            if fmt == \"latex\":\n                if ident == \"\":\n                    label = \"\"\n                else:\n                    label = '\\\\label{' + ident + '}'\n                return latex(\n                    \"\\n\\\\smallskip\\n{%\\n\" +\n                    latexsnippet('\\\\gregorioscore{' + contents + '}', kvs) +\n                    \"%\\n}\" +\n                    label\n                )\n            else:\n                infile = contents + (\n                    '.gabc' if '.gabc' not in contents else ''\n                )\n                with open(infile, 'r') as doc:\n                    code = doc.read().split('%%\\n')[1]\n                return [Image(['', [], []], [], [\n                    png(\n                        contents,\n                        latexsnippet('\\\\gregorioscore', kvs)\n                    ),\n                    \"\"\n                ])]\n    elif key == 'CodeBlock':\n        [[ident, classes, kvs], contents] = value\n        kvs = {key: value for key, value in kvs}\n        if \"gabc\" in classes:\n            if fmt == \"latex\":\n                if ident == \"\":\n                    label = \"\"\n                else:\n                    label = '\\\\label{' + ident + '}'\n                return [latexblock(\n                    \"\\n\\\\smallskip\\n{%\\n\" +\n                    latexsnippet('\\\\gabcsnippet{' + contents + '}', kvs) +\n                    \"%\\n}\" +\n                    label\n                    )]\n            else:\n                return Para([Image(['', [], []], [], [\n                    png(\n                        contents,\n                        latexsnippet('\\\\gabcsnippet', kvs)\n                    ),\n                    \"\"\n                ])])", "response": "Handles gabc file inclusion and gabc code block."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the raw text version of an element and its children element.", "response": "def stringify(element, newlines=True):\n    \"\"\"\n    Return the raw text version of an elements (and its children element).\n\n    Example:\n\n        >>> from panflute import *\n        >>> e1 = Emph(Str('Hello'), Space, Str('world!'))\n        >>> e2 = Strong(Str('Bye!'))\n        >>> para = Para(e1, Space, e2)\n        >>> stringify(para)\n        'Hello world! Bye!\\n\\n'\n\n    :param newlines: add a new line after a paragraph (default True)\n    :type newlines: :class:`bool`\n    :rtype: :class:`str`\n    \"\"\"\n\n    def attach_str(e, doc, answer):\n        if hasattr(e, 'text'):\n            ans = e.text\n        elif isinstance(e, HorizontalSpaces):\n            ans = ' '\n        elif isinstance(e, VerticalSpaces) and newlines:\n            ans = '\\n\\n'\n        elif type(e) == Citation:\n            ans = ''\n        else:\n            ans = ''\n        answer.append(ans)\n\n    answer = []\n    f = partial(attach_str, answer=answer)\n    element.walk(f)\n    return ''.join(answer)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_metadata(self, key='', default=None, builtin=True):\n\n    # Retrieve metadata\n    assert isinstance(key, str)\n    meta = self.metadata\n\n    # Retrieve specific key\n    if key:\n        for k in key.split('.'):\n            if isinstance(meta, MetaMap) and k in meta.content:\n                meta = meta[k]\n            else:\n                return default\n\n    # Stringify contents\n    return meta2builtin(meta) if builtin else meta", "response": "Get the metadata for a specific key."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexecutes the external command and get its exitcode stdout and stderr.", "response": "def shell(args, wait=True, msg=None):\n    \"\"\"\n    Execute the external command and get its exitcode, stdout and stderr.\n    \"\"\"\n\n    # Fix Windows error if passed a string\n    if isinstance(args, str):\n        args = shlex.split(args, posix=(os.name != \"nt\"))\n        if os.name == \"nt\":\n            args = [arg.replace('/', '\\\\') for arg in args]\n\n    if wait:\n        proc = Popen(args, stdin=PIPE, stdout=PIPE, stderr=PIPE)\n        out, err = proc.communicate(input=msg)\n        exitcode = proc.returncode\n        if exitcode != 0:\n            raise IOError(err)\n        return out\n    else:\n        DETACHED_PROCESS = 0x00000008\n        proc = Popen(args, creationflags=DETACHED_PROCESS)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run_pandoc(text='', args=None):\n\n    if args is None:\n        args = []\n\n    pandoc_path = which('pandoc')\n    if pandoc_path is None or not os.path.exists(pandoc_path):\n        raise OSError(\"Path to pandoc executable does not exists\")\n\n    proc = Popen([pandoc_path] + args, stdin=PIPE, stdout=PIPE, stderr=PIPE)\n    out, err = proc.communicate(input=text.encode('utf-8'))\n    exitcode = proc.returncode\n    if exitcode != 0:\n        raise IOError(err)\n    return out.decode('utf-8')", "response": "Low level function that calls Pandoc with some input text and optionally arguments"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convert_text(text,\n                 input_format='markdown',\n                 output_format='panflute',\n                 standalone=False,\n                 extra_args=None):\n    \"\"\"\n    Convert formatted text (usually markdown) by calling Pandoc internally\n\n    The default output format ('panflute') will return a tree\n    of Pandoc elements. When combined with 'standalone=True', the tree root\n    will be a 'Doc' element.\n\n    Example:\n\n        >>> from panflute import *\n        >>> md = 'Some *markdown* **text** ~xyz~'\n        >>> tex = r'Some $x^y$ or $x_n = \\sqrt{a + b}$ \\textit{a}'\n        >>> convert_text(md)\n        [Para(Str(Some) Space Emph(Str(markdown)) Space Strong(Str(text)) Space Subscript(Str(xyz)))]\n        >>> convert_text(tex)\n        [Para(Str(Some) Space Math(x^y; format='InlineMath') Space Str(or) Space Math(x_n = \\sqrt{a + b}; format='InlineMath') Space RawInline(\\textit{a}; format='tex'))]\n\n\n    :param text: text that will be converted\n    :type text: :class:`str` | :class:`.Element` | :class:`list` of :class:`.Element`\n    :param input_format: format of the text (default 'markdown').\n     Any Pandoc input format is valid, plus 'panflute' (a tree of Pandoc\n     elements)\n    :param output_format: format of the output\n     (default is 'panflute' which creates the tree of Pandoc elements).\n     Non-binary Pandoc formats are allowed (e.g. markdown, latex is allowed,\n     but docx and pdf are not).\n    :param standalone: whether the results will be a standalone document\n     or not.\n    :type standalone: :class:`bool`\n    :param extra_args: extra arguments passed to Pandoc\n    :type extra_args: :class:`list`\n    :rtype: :class:`list` | :class:`.Doc` | :class:`str`\n\n    Note: for a more general solution,\n    see `pyandoc <https://github.com/kennethreitz/pyandoc/>`_\n    by Kenneth Reitz.\n    \"\"\"\n\n    if input_format == 'panflute':\n\n        # Problem:\n        #  We need a Doc element, but received a list of elements.\n        #  So we wrap-up the list in a Doc, but with what pandoc-api version?\n        #  (remember that Pandoc requires a matching api-version!)\n        # Workaround: call Pandoc with empty text to get its api-version\n        if not isinstance(text, Doc):\n            tmp_doc = convert_text('', standalone=True)\n            api_version = tmp_doc.api_version\n            if isinstance(text, Element):\n                text = [text]\n            text = Doc(*text, api_version=api_version)\n\n        # Dump the Doc into json\n        with io.StringIO() as f:\n            dump(text, f)\n            text = f.getvalue()\n\n    in_fmt = 'json' if input_format == 'panflute' else input_format\n    out_fmt = 'json' if output_format == 'panflute' else output_format\n\n    if extra_args is None:\n        extra_args = []\n\n    if standalone:\n        extra_args.append('--standalone')\n\n    out = inner_convert_text(text, in_fmt, out_fmt, extra_args)\n\n    if output_format == 'panflute':\n        out = json.loads(out, object_pairs_hook=from_json)\n\n        if standalone:\n            if not isinstance(out, Doc):  # Pandoc 1.7.2 and earlier\n                metadata, items = out\n                out = Doc(*items, metadata=metadata)\n        else:\n            if isinstance(out, Doc):  # Pandoc 1.8 and later\n                out = out.content.list\n            else:\n                out = out[1]  # Pandoc 1.7.2 and earlier\n\n    return out", "response": "Convert a text string into a tree of Pandoc elements."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreplace the keyword in the sequence of elements with the replacement.", "response": "def _replace_keyword(self, keyword, replacement, count=0):\n    \"\"\"\n    replace_keyword(keyword, replacement[, count])\n\n    Walk through the element and its children\n    and look for Str() objects that contains\n    exactly the keyword. Then, replace it.\n\n    Usually applied to an entire document (a :class:`.Doc` element)\n\n    Note: If the replacement is a block, it cannot be put in place of\n    a Str element. As a solution, the closest ancestor (e.g. the parent)\n    will be replaced instead, but only if possible\n    (if the parent only has one child).\n\n    Example:\n\n    >>> from panflute import *\n    >>> p1 = Para(Str('Spam'), Space, Emph(Str('and'), Space, Str('eggs')))\n    >>> p2 = Para(Str('eggs'))\n    >>> p3 = Plain(Emph(Str('eggs')))\n    >>> doc = Doc(p1, p2, p3)\n    >>> doc.content\n    ListContainer(Para(Str(Spam) Space Emph(Str(and) Space Str(eggs))) Para(Str(eggs)) Plain(Emph(Str(eggs))))\n    >>> doc.replace_keyword('eggs', Str('ham'))\n    >>> doc.content\n    ListContainer(Para(Str(Spam) Space Emph(Str(and) Space Str(ham))) Para(Str(ham)) Plain(Emph(Str(ham))))\n    >>> doc.replace_keyword(keyword='ham', replacement=Para(Str('spam')))\n    >>> doc.content\n    ListContainer(Para(Str(Spam) Space Emph(Str(and) Space Str(ham))) Para(Str(spam)) Para(Str(spam)))\n\n    :param keyword: string that will be searched (cannot have spaces!)\n    :type keyword: :class:`str`\n    :param replacement: element that will be placed in turn of the ``Str``\n     element that contains the keyword.\n    :type replacement: :class:`.Element`\n    :param count: number of occurrences that will be replaced.\n     If count is not given or is set to zero, all occurrences\n     will be replaced.\n    :type count: :class:`int`\n    \"\"\"\n\n    def replace_with_inline(e, doc):\n        if type(e) == Str and e.text == keyword:\n            doc.num_matches += 1\n            if not count or doc.num_matches <= count:\n                return replacement\n\n    def replace_with_block(e, doc):\n        if hasattr(e, 'content') and len(e.content) == 1:\n            ee = e.content[0]\n            if type(ee) == Str and ee.text == keyword:\n                if isinstance(e, Block):\n                    doc.num_matches += 1\n                    if not count or doc.num_matches <= count:\n                        return replacement\n                elif isinstance(e, Inline):\n                    return Str(keyword)\n\n    doc = self.doc\n    if doc is None:\n        raise Exception('No root document')\n    doc.num_matches = 0\n    if isinstance(replacement, Inline):\n        return self.walk(replace_with_inline, doc)\n    elif isinstance(replacement, Block):\n        return self.walk(replace_with_block, doc)\n    else:\n        raise NotImplementedError(type(replacement))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_option(options=None, local_tag=None, doc=None, doc_tag=None, default=None, error_on_none=True):\n    variable = None\n    \n    # element level\n    if options is not None and local_tag is not None:\n        if local_tag in options and options[local_tag] is not None:\n            variable = options[local_tag]\n    if variable is not None:\n        return variable\n\n    # doc level\n    if doc is not None and doc_tag is not None:\n        variable = doc.get_metadata(doc_tag, None)\n    if variable is not None:\n        return variable\n\n    # default level\n    variable = default\n    if variable is None and error_on_none:\n        raise ValueError(\"could not retrieve a value for tag; local={0}, doc={1}\".format(local_tag, doc_tag))\n    \n    return variable", "response": "fetch an option variable from either a local level option or a document level metadata tag or a default value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_content(self, value, oktypes):\n        if value is None:\n            value = []\n        self._content = ListContainer(*value, oktypes=oktypes, parent=self)", "response": "Set the content of the object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef container(self):\n        if self.parent is None:\n            return None\n        elif self.location is None:\n            return self.parent.content\n        else:\n            container = getattr(self.parent, self.location)\n            if isinstance(container, (ListContainer, DictContainer)):\n                return container\n            else:\n                assert self is container", "response": "Rarely used attribute that returns the ListContainer that contains the element\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a sibling element by n", "response": "def offset(self, n):\n        \"\"\"\n        Return a sibling element offset by n\n\n        :rtype: :class:`Element` | ``None``\n        \"\"\"\n\n        idx = self.index\n        if idx is not None:\n            sibling = idx + n\n            container = self.container\n            if 0 <= sibling < len(container):\n                return container[sibling]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the n - th ancestor of the current element.", "response": "def ancestor(self, n):\n        \"\"\"\n        Return the n-th ancestor.\n        Note that ``elem.ancestor(1) == elem.parent``\n\n        :rtype: :class:`Element` | ``None``\n        \"\"\"\n        if not isinstance(n, int) or n < 1:\n            raise TypeError('Ancestor needs to be positive, received', n)\n\n        if n == 1 or self.parent is None:\n            return self.parent\n        else:\n            return self.parent.ancestor(n-1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the root Doc element if there is one.", "response": "def doc(self):\n        \"\"\"\n        Return the root Doc element (if there is one)\n        \"\"\"\n        guess = self\n        while guess is not None and guess.tag != 'Doc':\n            guess = guess.parent  # If no parent, this will be None\n        return guess"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef walk(self, action, doc=None):\n\n        # Infer the document thanks to .parent magic\n        if doc is None:\n            doc = self.doc\n\n        # First iterate over children\n        for child in self._children:\n            obj = getattr(self, child)\n            if isinstance(obj, Element):\n                ans = obj.walk(action, doc)\n            elif isinstance(obj, ListContainer):\n                ans = (item.walk(action, doc) for item in obj)\n                # We need to convert single elements to iterables, so that they\n                # can be flattened later\n                ans = ((item,) if type(item) != list else item for item in ans)\n                # Flatten the list, by expanding any sublists\n                ans = list(chain.from_iterable(ans))\n            elif isinstance(obj, DictContainer):\n                ans = [(k, v.walk(action, doc)) for k, v in obj.items()]\n                ans = [(k, v) for k, v in ans if v != []]\n            elif obj is None:\n                ans = None  # Empty table headers or captions\n            else:\n                raise TypeError(type(obj))\n            setattr(self, child, ans)\n\n        # Then apply the action to the element\n        altered = action(self, doc)\n        return self if altered is None else altered", "response": "Walk through the element and all its children and apply the provided function action to each element and all its children."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading JSON from stdin and dumps it to the output stream.", "response": "def stdio(filters=None, search_dirs=None, data_dir=True, sys_path=True, panfl_=False, input_stream=None, output_stream=None):\n    \"\"\"\n    Reads JSON from stdin and second CLI argument:\n    ``sys.argv[1]``. Dumps JSON doc to the stdout.\n\n    :param filters: Union[List[str], None]\n        if None then read from metadata\n    :param search_dirs: Union[List[str], None]\n        if None then read from metadata\n    :param data_dir: bool\n    :param sys_path: bool\n    :param panfl_: bool\n    :param input_stream: io.StringIO or None\n        for debug purpose\n    :param output_stream: io.StringIO or None\n        for debug purpose\n    :return: None\n    \"\"\"\n    doc = load(input_stream)\n    # meta = doc.metadata  # Local variable 'meta' value is not used\n    verbose = doc.get_metadata('panflute-verbose', False)\n\n    if search_dirs is None:\n        # metadata 'panflute-path' can be a list, a string, or missing\n        # `search_dirs` should be a list of str\n        search_dirs = doc.get_metadata('panflute-path', [])\n        if type(search_dirs) != list:\n            search_dirs = [search_dirs]\n        if '--data-dir' in search_dirs:\n            data_dir = True\n        if '--no-sys-path' in search_dirs:\n            sys_path = False\n        search_dirs = [dir_ for dir_ in search_dirs\n                       if dir_ not in ('--data-dir', '--no-sys-path')]\n\n    if verbose:\n        debug('panflute: data_dir={} sys_path={}'.format(data_dir, sys_path))\n    search_dirs = [p.normpath(p.expanduser(p.expandvars(dir_))) for dir_ in search_dirs]\n\n    if not panfl_:\n        # default panflute behaviour:\n        search_dirs.append('.')\n        if data_dir:\n            search_dirs.append(get_filter_dir())\n        if sys_path:\n            search_dirs += sys.path\n    else:\n        # panfl/pandoctools behaviour:\n        if data_dir:\n            search_dirs.append(get_filter_dir())\n        if sys_path:\n            search_dirs += reduced_sys_path\n\n    # Display message (tests that everything is working ok)\n    msg = doc.get_metadata('panflute-echo', False)\n    if msg:\n        debug(msg)\n\n    if filters is None:\n        # metadata 'panflute-filters' can be a list, a string, or missing\n        # `filters` should be a list of str\n        filters = doc.get_metadata('panflute-filters', [])\n        if type(filters) != list:\n            filters = [filters]\n\n    if filters:\n        if verbose:\n            msg = \"panflute: will run the following filters:\"\n            debug(msg, ' '.join(filters))\n        doc = autorun_filters(filters, doc, search_dirs, verbose)\n    elif verbose:\n        debug(\"panflute: no filters were provided\")\n\n    dump(doc, output_stream)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef panfl(filters, to, search_dirs, data_dir, sys_path):\n    if to is None:\n        if (len(filters) > 1) or search_dirs or not sys_path or data_dir:\n            raise ValueError('When no `--to` option then Pandoc filter mode assumed and ' +\n                             'only one positional argument is allowed of all options.')\n        else:\n            filters, search_dirs = None, None\n            sys_path, data_dir = True, False\n    else:\n        filters, search_dirs = list(filters), list(search_dirs)\n        # `load()` in `stdio()` needs `to` in the 2nd arg\n        sys.argv[1:] = []\n        sys.argv.append(to)\n\n    stdio(filters, search_dirs, data_dir, sys_path, panfl_=True)", "response": "This function is used to import a Pandoc filter from a Pandoc file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef autorun_filters(filters, doc, search_dirs, verbose):\n    def remove_py(s):\n            return s[:-3] if s.endswith('.py') else s\n\n    filter_paths = []\n    for filter_ in filters:\n        filter_exp = p.normpath(p.expanduser(p.expandvars(filter_)))\n\n        if filter_exp == remove_py(p.basename(filter_exp)).lstrip('.'):\n            # import .foo  # is not supported\n            module = True\n            mod_path = filter_exp.replace('.', p.sep)\n            path_postfixes = (p.join(mod_path, '__init__.py'), mod_path + '.py')\n        else:\n            module = False\n            # allow with and without .py ending\n            path_postfixes = (remove_py(filter_exp) + '.py',)\n\n        for path, path_postf in [(path, path_postf)\n                                 for path in search_dirs\n                                 for path_postf in path_postfixes]:\n            if p.isabs(path_postf):\n                filter_path = path_postf\n            else:\n                filter_path = p.abspath(p.normpath(p.join(path, path_postf)))\n\n            if p.isfile(filter_path):\n                if verbose:\n                    debug(\"panflute: filter <{}> found in {}\".format(filter_, filter_path))\n\n                if module and not (path in reduced_sys_path):\n                    extra_dir = p.abspath(path)\n                    # `path` already doesn't contain `.`, `..`, env vars or `~`\n                else:\n                    extra_dir = None\n                module_ = filter_exp if module else filter_path\n\n                filter_paths.append((filter_, filter_path, module_, extra_dir))\n                break\n            elif p.isabs(path_postf):\n                if verbose:\n                    debug(\"          filter <{}> NOT found in {}\".format(filter_, filter_path))\n                raise Exception(\"filter not found: \" + filter_)\n            elif verbose:\n                debug(\"          filter <{}> NOT found in {}\".format(filter_, filter_path))\n        else:\n            raise Exception(\"filter not found: \" + filter_)\n\n    for filter_, filter_path, module_, extra_dir in filter_paths:\n        if verbose:\n            debug(\"panflute: running filter <{}>\".format(filter_))\n        with ContextImport(module_, extra_dir) as module:\n            try:\n                module.main(doc)\n            except Exception as e:\n                debug(\"Failed to run filter: \" + filter_)\n                if not hasattr(module, 'main'):\n                    debug(' - Possible cause: filter lacks a main() function')\n                debug('Filter code:')\n                debug('-' * 64)\n                with open(filter_path) as fp:\n                    debug(fp.read())\n                debug('-' * 64)\n                raise Exception(e)\n        if verbose:\n            debug(\"panflute: filter <{}> completed\".format(filter_))\n\n    return doc", "response": "autorun filters in a single document."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsearch for names that match some pattern.", "response": "def search(self, term: str, case_sensitive: bool = False) -> 'PrettyDir':\n        \"\"\"Searches for names that match some pattern.\n\n        Args:\n            term: String used to match names. A name is returned if it matches\n              the whole search term.\n            case_sensitive: Boolean to match case or not, default is False\n              (case insensitive).\n\n        Return:\n            A PrettyDir object with matched names.\n        \"\"\"\n        if case_sensitive:\n            return PrettyDir(\n                self.obj, [pattr for pattr in self.pattrs if term in pattr.name]\n            )\n        else:\n            term = term.lower()\n            return PrettyDir(\n                self.obj, [pattr for pattr in self.pattrs if term in pattr.name.lower()]\n            )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef properties(self) -> 'PrettyDir':\n        return PrettyDir(\n            self.obj,\n            [\n                pattr\n                for pattr in self.pattrs\n                if category_match(pattr.category, AttrCategory.PROPERTY)\n            ],\n        )", "response": "Returns all properties of the inspected object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef methods(self) -> 'PrettyDir':\n        return PrettyDir(\n            self.obj,\n            [\n                pattr\n                for pattr in self.pattrs\n                if category_match(pattr.category, AttrCategory.FUNCTION)\n            ],\n        )", "response": "Returns a PrettyDir object containing all methods of the inspected object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef public(self) -> 'PrettyDir':\n        return PrettyDir(\n            self.obj, [pattr for pattr in self.pattrs if not pattr.name.startswith('_')]\n        )", "response": "Returns the public attributes of the inspected object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef own(self) -> 'PrettyDir':\n        return PrettyDir(\n            self.obj,\n            [\n                pattr\n                for pattr in self.pattrs\n                if pattr.name in type(self.obj).__dict__\n                or pattr.name in self.obj.__dict__\n            ],\n        )", "response": "Returns attributes that are not inhterited from parent classes."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the oneline doc of the attribute.", "response": "def get_oneline_doc(self) -> str:\n        \"\"\"\n        Doc doesn't necessarily mean doctring. It could be anything that\n        should be put after the attr's name as an explanation.\n        \"\"\"\n        attr = self.attr_obj\n        if self.display_group == AttrCategory.DESCRIPTOR:\n            if isinstance(attr, property):\n                doc_list = ['@property with getter']\n                if attr.fset:\n                    doc_list.append(SETTER)\n                if attr.fdel:\n                    doc_list.append(DELETER)\n            else:\n                doc_list = ['class %s' % attr.__class__.__name__]\n                if hasattr(attr, '__get__'):\n                    doc_list.append(GETTER)\n                if hasattr(attr, '__set__'):\n                    doc_list.append(SETTER)\n                if hasattr(attr, '__delete__'):\n                    doc_list.append(DELETER)\n                doc_list[0] = ' '.join([doc_list[0], 'with', doc_list.pop(1)])\n            if attr.__doc__ is not None:\n                doc_list.append(inspect.getdoc(attr).split('\\n', 1)[0])\n            return ', '.join(doc_list)\n\n        if hasattr(attr, '__doc__'):\n            doc = inspect.getdoc(attr)\n            return doc.split('\\n', 1)[0] if doc else ''  # default doc is None\n        return ''"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef format_pattrs(pattrs: List['api.PrettyAttribute']) -> str:\n    output = []\n    pattrs.sort(\n        key=lambda x: (\n            _FORMATTER[x.display_group].display_index,\n            x.display_group,\n            x.name,\n        )\n    )\n    for display_group, grouped_pattrs in groupby(pattrs, lambda x: x.display_group):\n        output.append(\n            _FORMATTER[display_group].formatter(display_group, grouped_pattrs)\n        )\n\n    return '\\n'.join(output)", "response": "Generates a repr string given a list of pattrs."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_attr_from_dict(inspected_obj: Any, attr_name: str) -> Any:\n    if inspect.isclass(inspected_obj):\n        obj_list = [inspected_obj] + list(inspected_obj.__mro__)\n    else:\n        obj_list = [inspected_obj] + list(inspected_obj.__class__.__mro__)\n    for obj in obj_list:\n        if hasattr(obj, '__dict__') and attr_name in obj.__dict__:\n            return obj.__dict__[attr_name]\n    # This happens when user-defined __dir__ returns something that's not\n    # in any __dict__. See test_override_dir.\n    # Returns attr_name so that it's treated as a normal property.\n    return attr_name", "response": "Ensures we get descriptor object instead of its return value."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef attr_category_postprocess(get_attr_category_func):\n    @functools.wraps(get_attr_category_func)\n    def wrapped(\n        name: str, attr: Any, obj: Any\n    ) -> Tuple[AttrCategory, ...]:\n        category = get_attr_category_func(name, attr, obj)\n        category = list(category) if isinstance(category, tuple) else [category]\n        if is_slotted_attr(obj, name):\n            # Refactoring all tuples to lists is not easy\n            # and pleasant. Maybe do this in future if necessary\n            category.append(AttrCategory.SLOT)\n        return tuple(category)\n\n    return wrapped", "response": "Unifies attr_category to a tuple add AttrCategory. SLOT if needed."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns peak memory use since process starts till the moment its called", "response": "def get_peak_mem():\n    '''\n    this returns peak memory use since process starts till the moment its called\n    '''\n    import resource\n    rusage_denom = 1024.\n    if sys.platform == 'darwin':\n        # ... it seems that in OSX the output is different units ...\n        rusage_denom = rusage_denom * rusage_denom\n    mem = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss / rusage_denom\n    return mem"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef record(self, ch_node):\n        '''\n        Incremental changes\n        '''\n        rec = self.serialize_node(ch_node)\n        self.history.append(rec)", "response": "Record a node in the history."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndetermine if the result of multiplications should be sparse or not.", "response": "def sparse_is_desireable(lhs, rhs):\n    '''\n    Examines a pair of matrices and determines if the result of their multiplication should be sparse or not.\n    '''\n    return False\n    if len(lhs.shape) == 1:\n        return False\n    else:\n        lhs_rows, lhs_cols = lhs.shape\n\n    if len(rhs.shape) == 1:\n        rhs_rows = 1\n        rhs_cols = rhs.size\n    else:\n        rhs_rows, rhs_cols = rhs.shape\n\n    result_size = lhs_rows * rhs_cols\n\n    if sp.issparse(lhs) and sp.issparse(rhs):\n        return True\n    elif sp.issparse(lhs):\n        lhs_zero_rows = lhs_rows - np.unique(lhs.nonzero()[0]).size\n        rhs_zero_cols = np.all(rhs==0, axis=0).sum()\n        \n    elif sp.issparse(rhs):\n        lhs_zero_rows = np.all(lhs==0, axis=1).sum()\n        rhs_zero_cols = rhs_cols- np.unique(rhs.nonzero()[1]).size\n    else:\n        lhs_zero_rows = np.all(lhs==0, axis=1).sum()\n        rhs_zero_cols = np.all(rhs==0, axis=0).sum()\n\n    num_zeros = lhs_zero_rows * rhs_cols + rhs_zero_cols * lhs_rows - lhs_zero_rows * rhs_zero_cols\n\n    # A sparse matrix uses roughly 16 bytes per nonzero element (8 + 2 4-byte inds), while a dense matrix uses 8 bytes per element. So the break even point for sparsity is 50% nonzero. But in practice, it seems to be that the compression in a csc or csr matrix gets us break even at ~65% nonzero, which lets us say 50% is a conservative, worst cases cutoff.\n    return (float(num_zeros) / float(size)) >= 0.5"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef convert_inputs_to_sparse_if_necessary(lhs, rhs):\n    '''\n    This function checks to see if a sparse output is desireable given the inputs and if so, casts the inputs to sparse in order to make it so.\n    '''\n    if not sp.issparse(lhs) or not sp.issparse(rhs):\n        if sparse_is_desireable(lhs, rhs):\n            if not sp.issparse(lhs):\n                lhs = sp.csc_matrix(lhs)\n                #print \"converting lhs into sparse matrix\"\n            if not sp.issparse(rhs):\n                rhs = sp.csc_matrix(rhs)\n                #print \"converting rhs into sparse matrix\"\n    return lhs, rhs", "response": "This function checks to see if a sparse output is desireable given the inputs and if so casts the inputs to sparse if necessary."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloops over free variables and delete cache for the whole tree after finished each one", "response": "def dr_wrt(self, wrt, profiler=None):\n        '''\n        Loop over free variables and delete cache for the whole tree after finished each one\n        '''\n        if wrt is self.x:\n            jacs = []\n            for fvi, freevar in enumerate(self.free_variables):\n                tm = timer()\n                if isinstance(freevar, ch.Select):\n                    new_jac = self.obj.dr_wrt(freevar.a, profiler=profiler)\n                    try:\n                        new_jac = new_jac[:, freevar.idxs]\n                    except:\n                        # non-csc sparse matrices may not support column-wise indexing\n                        new_jac = new_jac.tocsc()[:, freevar.idxs]\n                else:\n                    new_jac = self.obj.dr_wrt(freevar, profiler=profiler)\n\n                pif('dx wrt {} in {}sec, sparse: {}'.format(freevar.short_name, tm(), sp.issparse(new_jac)))\n\n                if self._make_dense and sp.issparse(new_jac):\n                    new_jac = new_jac.todense()\n                if self._make_sparse and not sp.issparse(new_jac):\n                    new_jac = sp.csc_matrix(new_jac)\n\n                if new_jac is None:\n                    raise Exception(\n                        'Objective has no derivative wrt free variable {}. '\n                        'You should likely remove it.'.format(fvi))\n\n                jacs.append(new_jac)\n            tm = timer()\n            utils.dfs_do_func_on_graph(self.obj, clear_cache_single)\n            pif('dfs_do_func_on_graph in {}sec'.format(tm()))\n            tm = timer()\n            J = hstack(jacs)\n            pif('hstack in {}sec'.format(tm()))\n            return J"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes Jacobian. Analyze dr graph first to disable unnecessary caching", "response": "def J(self):\n        '''\n        Compute Jacobian. Analyze dr graph first to disable unnecessary caching\n        '''\n        result = self.dr_wrt(self.x, profiler=self.profiler).copy()\n        if self.profiler:\n            self.profiler.harvest()\n        return np.atleast_2d(result) if not sp.issparse(result) else result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndefaulting method for objects that just contain a number or ndarray", "response": "def compute_dr_wrt(self,wrt):\n        \"\"\"Default method for objects that just contain a number or ndarray\"\"\"\n        if wrt is self: # special base case  \n            return sp.eye(self.x.size, self.x.size)\n            #return np.array([[1]])\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef show_tree_cache(self, label, current_node=None):\n        '''\n        Show tree and cache info with color represent _status\n        Optionally accpet current_node arg to highlight the current node we are in\n        '''\n        import os\n        import tempfile\n        import subprocess\n\n        assert DEBUG, \"Please use dr tree visualization functions in debug mode\"\n\n        cache_path = os.path.abspath('profiles')\n        def string_for(self, my_name):\n\n            color_mapping = {'new' : 'grey', 'pending':'red', 'cached':'yellow', 'done': 'green'}\n            if hasattr(self, 'label'):\n                my_name = self.label\n            my_name = '%s (%s)' % (my_name, str(self.__class__.__name__))\n            result = []\n            if not hasattr(self, 'dterms'):\n                return result\n            for dterm in self.dterms:\n                if hasattr(self, dterm):\n                    dtval = getattr(self, dterm)\n                    if hasattr(dtval, 'dterms') or hasattr(dtval, 'terms'):\n                        child_label = getattr(dtval, 'label') if hasattr(dtval, 'label') else dterm\n                        child_label = '%s (%s)' % (child_label, str(dtval.__class__.__name__))\n                        src = 'aaa%d' % (id(self))\n                        dst = 'aaa%d' % (id(dtval))\n\n                        s = ''\n                        color = color_mapping[dtval._status] if hasattr(dtval, '_status') else 'grey'\n                        if dtval == current_node:\n                            color = 'blue'\n                        if isinstance(dtval, Concatenate) and len(dtval.dr_cached) > 0:\n                            s = 'dr_cached\\n'\n                            for k, v in dtval.dr_cached.items():\n                                if v is not None:\n                                    issparse = sp.issparse(v)\n                                    size = v.size \n                                    if issparse:\n                                        size = v.shape[0] * v.shape[1]\n                                        nonzero = len(v.data)\n                                    else:\n                                        nonzero = np.count_nonzero(v)  \n                                    s += '\\nsparse: %s\\nsize: %d\\nnonzero: %d\\n' % (issparse, size, nonzero)\n                            # if dtval.called_dr_wrt:\n                            # #   dtval.called_dr_wrt = False\n                            #     color = 'brown3'\n                            # else:\n                            #     color = 'azure1'\n                        elif len(dtval._cache['drs']) > 0:\n                            s = '_cache\\n'\n                            \n                            for k, v in dtval._cache['drs'].items():\n                                if v is not None:\n                                    issparse = sp.issparse(v)\n                                    size = v.size\n                                    if issparse:\n                                        size = v.shape[0] * v.shape[1]\n                                        nonzero = len(v.data)\n                                    else:\n                                        nonzero = np.count_nonzero(v)     \n\n                                    s += '\\nsparse: %s\\nsize: %d\\nnonzero: %d\\n' % (issparse, size, nonzero)\n                                    if hasattr(dtval, '_cache_info'):\n                                        s += '\\ncache hit:%s\\n' % dtval._cache_info[k]\n                            # if hasattr(dtval,'called_dr_wrt') and dtval.called_dr_wrt:\n                            # #   dtval.called_dr_wrt = False\n                            #     color = 'brown3'\n                            # else:\n                            #     color = 'azure1'\n                        result += ['%s -> %s;' % (src, dst)]\n                        # Do not overwrite src\n                        #result += ['%s [label=\"%s\"];' % (src, my_name)]\n                        result += ['%s [label=\"%s\\n%s\\n\", color=%s, style=filled];' %\n                                   (dst, child_label, s, color)]\n                        result += string_for(getattr(self, dterm), dterm)\n            return result\n            \n\n        dot_file_contents = 'digraph G {\\n%s\\n}' % '\\n'.join(list(set(string_for(self, 'root'))))\n        dot_file_name = os.path.join(cache_path, label)\n        png_file_name = os.path.join(cache_path, label+'.png')\n        with open(dot_file_name, 'w') as dot_file:\n            with open(png_file_name, 'w') as png_file:\n                dot_file.write(dot_file_contents)\n                dot_file.flush()\n\n                png_file = tempfile.NamedTemporaryFile(suffix='.png', delete=False)\n                subprocess.call(['dot', '-Tpng', '-o', png_file.name, dot_file.name])\n\n        import webbrowser\n        webbrowser.open('file://' + png_file.name)\n        \n        self.loop_children_do(self.reset_flag)", "response": "Show tree and cache info with color represent _status"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nshow the tree of the object.", "response": "def show_tree(self, cachelim=np.inf):\n        \"\"\"Cachelim is in Mb. For any cached jacobians above cachelim, they are also added to the graph. \"\"\"\n        import tempfile\n        import subprocess\n\n        assert DEBUG, \"Please use dr tree visualization functions in debug mode\"\n\n        def string_for(self, my_name):\n            if hasattr(self, 'label'):\n                my_name = self.label\n            my_name = '%s (%s)' % (my_name, str(self.__class__.__name__))\n            result = []\n            if not hasattr(self, 'dterms'):\n                return result\n            for dterm in self.dterms:\n                if hasattr(self, dterm):\n                    dtval = getattr(self, dterm)\n                    if hasattr(dtval, 'dterms') or hasattr(dtval, 'terms'):\n                        child_label = getattr(dtval, 'label') if hasattr(dtval, 'label') else dterm\n                        child_label = '%s (%s)' % (child_label, str(dtval.__class__.__name__))\n                        src = 'aaa%d' % (id(self))\n                        dst = 'aaa%d' % (id(dtval))\n                        result += ['%s -> %s;' % (src, dst)]\n                        result += ['%s [label=\"%s\"];' % (src, my_name)]\n                        result += ['%s [label=\"%s\"];' % (dst, child_label)]\n                        result += string_for(getattr(self, dterm), dterm)\n\n            if cachelim != np.inf and hasattr(self, '_cache') and 'drs' in self._cache:\n                from six.moves import cPickle as pickle\n                for dtval, jac in list(self._cache['drs'].items()):\n                    # child_label = getattr(dtval, 'label') if hasattr(dtval, 'label') else dterm\n                    # child_label = '%s (%s)' % (child_label, str(dtval.__class__.__name__))\n                    src = 'aaa%d' % (id(self))\n                    dst = 'aaa%d' % (id(dtval))\n                    try:                    \n                        sz = sys.getsizeof(pickle.dumps(jac, -1))\n                    except: # some are functions\n                        sz = 0\n                    # colorattr = \"#%02x%02x%02x\" % (szpct*255, 0, (1-szpct)*255)\n                    # print colorattr\n                    if sz > (cachelim * 1024 * 1024):\n                        result += ['%s -> %s [style=dotted,color=\"<<<%d>>>\"];' % (src, dst, sz)]\n                    #\n                    # result += ['%s -> %s [style=dotted];' % (src, dst)]\n                    # result += ['%s [label=\"%s\"];' % (src, my_name)]\n                    # result += ['%s [label=\"%s\"];' % (dst, child_label)]\n                    # result += string_for(getattr(self, dterm), dterm)\n                    \n            return result\n\n        dot_file_contents = 'digraph G {\\n%s\\n}' % '\\n'.join(list(set(string_for(self, 'root'))))\n        if cachelim != np.inf:\n            import re\n            strs = re.findall(r'<<<(\\d+)>>>', dot_file_contents, re.DOTALL)\n            if len(strs) > 0:\n                the_max = np.max(np.array([int(d) for d in strs]))\n                for s in strs:\n                    szpct = float(s)/the_max\n                    sz = float(s)\n                    unit = 'b'\n                    if sz > 1024.: \n                        sz /= 1024\n                        unit = 'K'\n                    if sz > 1024.: \n                        sz /= 1024\n                        unit = 'M'\n                    if sz > 1024.: \n                        sz /= 1024\n                        unit = 'G'\n                    if sz > 1024.: \n                        sz /= 1024\n                        unit = 'T'\n                        \n                    dot_file_contents = re.sub('<<<%s>>>' % s, '#%02x%02x%02x\",label=\"%d%s' % (szpct*255, 0, (1-szpct)*255, sz, unit), dot_file_contents)\n\n        dot_file = tempfile.NamedTemporaryFile()\n        dot_file.write(dot_file_contents)\n        dot_file.flush()\n        png_file = tempfile.NamedTemporaryFile(suffix='.png', delete=False)\n        subprocess.call(['dot', '-Tpng', '-o', png_file.name, dot_file.name])\n        import webbrowser\n        webbrowser.open('file://' + png_file.name)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tree_iterator(self, visited=None, path=None):\n        '''\n        Generator function that traverse the dr tree start from this node (self).\n        '''\n        if visited is None:\n            visited = set()\n\n        if self not in visited:\n            if path and isinstance(path, list):\n                path.append(self)\n\n            visited.add(self)\n            yield self\n\n            if not hasattr(self, 'dterms'):\n                yield\n\n            for dterm in self.dterms:\n                if hasattr(self, dterm):\n                    child = getattr(self, dterm)\n                    if hasattr(child, 'dterms') or hasattr(child, 'terms'):\n                        for node in child.tree_iterator(visited):\n                            yield node", "response": "Generator function that traverse the dr tree start from this node."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets Ubuntu release codename from sentry unit.", "response": "def get_ubuntu_release_from_sentry(self, sentry_unit):\n        \"\"\"Get Ubuntu release codename from sentry unit.\n\n        :param sentry_unit: amulet sentry/service unit pointer\n        :returns: list of strings - release codename, failure message\n        \"\"\"\n        msg = None\n        cmd = 'lsb_release -cs'\n        release, code = sentry_unit.run(cmd)\n        if code == 0:\n            self.log.debug('{} lsb_release: {}'.format(\n                sentry_unit.info['unit_name'], release))\n        else:\n            msg = ('{} `{}` returned {} '\n                   '{}'.format(sentry_unit.info['unit_name'],\n                               cmd, release, code))\n        if release not in self.ubuntu_releases:\n            msg = (\"Release ({}) not found in Ubuntu releases \"\n                   \"({})\".format(release, self.ubuntu_releases))\n        return release, msg"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nvalidating that lists of commands succeed on system services on service units.", "response": "def validate_services(self, commands):\n        \"\"\"Validate that lists of commands succeed on service units.  Can be\n           used to verify system services are running on the corresponding\n           service units.\n\n        :param commands: dict with sentry keys and arbitrary command list vals\n        :returns: None if successful, Failure string message otherwise\n        \"\"\"\n        self.log.debug('Checking status of system services...')\n\n        # /!\\ DEPRECATION WARNING (beisner):\n        # New and existing tests should be rewritten to use\n        # validate_services_by_name() as it is aware of init systems.\n        self.log.warn('DEPRECATION WARNING:  use '\n                      'validate_services_by_name instead of validate_services '\n                      'due to init system differences.')\n\n        for k, v in six.iteritems(commands):\n            for cmd in v:\n                output, code = k.run(cmd)\n                self.log.debug('{} `{}` returned '\n                               '{}'.format(k.info['unit_name'],\n                                           cmd, code))\n                if code != 0:\n                    return \"command `{}` returned {}\".format(cmd, str(code))\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef validate_services_by_name(self, sentry_services):\n        self.log.debug('Checking status of system services...')\n\n        # Point at which systemd became a thing\n        systemd_switch = self.ubuntu_releases.index('vivid')\n\n        for sentry_unit, services_list in six.iteritems(sentry_services):\n            # Get lsb_release codename from unit\n            release, ret = self.get_ubuntu_release_from_sentry(sentry_unit)\n            if ret:\n                return ret\n\n            for service_name in services_list:\n                if (self.ubuntu_releases.index(release) >= systemd_switch or\n                        service_name in ['rabbitmq-server', 'apache2',\n                                         'memcached']):\n                    # init is systemd (or regular sysv)\n                    cmd = 'sudo service {} status'.format(service_name)\n                    output, code = sentry_unit.run(cmd)\n                    service_running = code == 0\n                elif self.ubuntu_releases.index(release) < systemd_switch:\n                    # init is upstart\n                    cmd = 'sudo status {}'.format(service_name)\n                    output, code = sentry_unit.run(cmd)\n                    service_running = code == 0 and \"start/running\" in output\n\n                self.log.debug('{} `{}` returned '\n                               '{}'.format(sentry_unit.info['unit_name'],\n                                           cmd, code))\n                if not service_running:\n                    return u\"command `{}` returned {} {}\".format(\n                        cmd, output, str(code))\n        return None", "response": "Validate system service status by service name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_config(self, unit, filename):\n        file_contents = unit.file_contents(filename)\n\n        # NOTE(beisner):  by default, ConfigParser does not handle options\n        # with no value, such as the flags used in the mysql my.cnf file.\n        # https://bugs.python.org/issue7005\n        config = configparser.ConfigParser(allow_no_value=True)\n        config.readfp(io.StringIO(file_contents))\n        return config", "response": "Get a ConfigParser object for parsing a unit s config file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate_config_data(self, sentry_unit, config_file, section,\n                             expected):\n        \"\"\"Validate config file data.\n\n           Verify that the specified section of the config file contains\n           the expected option key:value pairs.\n\n           Compare expected dictionary data vs actual dictionary data.\n           The values in the 'expected' dictionary can be strings, bools, ints,\n           longs, or can be a function that evaluates a variable and returns a\n           bool.\n           \"\"\"\n        self.log.debug('Validating config file data ({} in {} on {})'\n                       '...'.format(section, config_file,\n                                    sentry_unit.info['unit_name']))\n        config = self._get_config(sentry_unit, config_file)\n\n        if section != 'DEFAULT' and not config.has_section(section):\n            return \"section [{}] does not exist\".format(section)\n\n        for k in expected.keys():\n            if not config.has_option(section, k):\n                return \"section [{}] is missing option {}\".format(section, k)\n\n            actual = config.get(section, k)\n            v = expected[k]\n            if (isinstance(v, six.string_types) or\n                    isinstance(v, bool) or\n                    isinstance(v, six.integer_types)):\n                # handle explicit values\n                if actual != v:\n                    return \"section [{}] {}:{} != expected {}:{}\".format(\n                           section, k, actual, k, expected[k])\n            # handle function pointers, such as not_null or valid_ip\n            elif not v(actual):\n                return \"section [{}] {}:{} != expected {}:{}\".format(\n                       section, k, actual, k, expected[k])\n        return None", "response": "Validate the config file data."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nvalidates dictionary data. Compare expected dictionary data vs actual dictionary data. The values in the 'expected' dictionary can be strings, bools, ints, longs, or can be a function that evaluates a variable and returns a bool.", "response": "def _validate_dict_data(self, expected, actual):\n        \"\"\"Validate dictionary data.\n\n           Compare expected dictionary data vs actual dictionary data.\n           The values in the 'expected' dictionary can be strings, bools, ints,\n           longs, or can be a function that evaluates a variable and returns a\n           bool.\n           \"\"\"\n        self.log.debug('actual: {}'.format(repr(actual)))\n        self.log.debug('expected: {}'.format(repr(expected)))\n\n        for k, v in six.iteritems(expected):\n            if k in actual:\n                if (isinstance(v, six.string_types) or\n                        isinstance(v, bool) or\n                        isinstance(v, six.integer_types)):\n                    # handle explicit values\n                    if v != actual[k]:\n                        return \"{}:{}\".format(k, actual[k])\n                # handle function pointers, such as not_null or valid_ip\n                elif not v(actual[k]):\n                    return \"{}:{}\".format(k, actual[k])\n            else:\n                return \"key '{}' does not exist\".format(k)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nvalidates actual relation data based on expected relation data.", "response": "def validate_relation_data(self, sentry_unit, relation, expected):\n        \"\"\"Validate actual relation data based on expected relation data.\"\"\"\n        actual = sentry_unit.relation(relation[0], relation[1])\n        return self._validate_dict_data(expected, actual)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _validate_list_data(self, expected, actual):\n        for e in expected:\n            if e not in actual:\n                return \"expected item {} not found in actual list\".format(e)\n        return None", "response": "Compare expected list vs actual list data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the start time of a process based on the last modification time of the process directory.", "response": "def _get_proc_start_time(self, sentry_unit, service, pgrep_full=None):\n        \"\"\"Get start time of a process based on the last modification time\n           of the /proc/pid directory.\n\n        :sentry_unit:  The sentry unit to check for the service on\n        :service:  service name to look for in process table\n        :pgrep_full:  [Deprecated] Use full command line search mode with pgrep\n        :returns:  epoch time of service process start\n        :param commands:  list of bash commands\n        :param sentry_units:  list of sentry unit pointers\n        :returns:  None if successful; Failure message otherwise\n        \"\"\"\n        pid_list = self.get_process_id_list(\n            sentry_unit, service, pgrep_full=pgrep_full)\n        pid = pid_list[0]\n        proc_dir = '/proc/{}'.format(pid)\n        self.log.debug('Pid for {} on {}: {}'.format(\n            service, sentry_unit.info['unit_name'], pid))\n\n        return self._get_dir_mtime(sentry_unit, proc_dir)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if a service has been restarted.", "response": "def service_restarted(self, sentry_unit, service, filename,\n                          pgrep_full=None, sleep_time=20):\n        \"\"\"Check if service was restarted.\n\n           Compare a service's start time vs a file's last modification time\n           (such as a config file for that service) to determine if the service\n           has been restarted.\n           \"\"\"\n        # /!\\ DEPRECATION WARNING (beisner):\n        # This method is prone to races in that no before-time is known.\n        # Use validate_service_config_changed instead.\n\n        # NOTE(beisner) pgrep_full is no longer implemented, as pidof is now\n        # used instead of pgrep.  pgrep_full is still passed through to ensure\n        # deprecation WARNS.  lp1474030\n        self.log.warn('DEPRECATION WARNING:  use '\n                      'validate_service_config_changed instead of '\n                      'service_restarted due to known races.')\n\n        time.sleep(sleep_time)\n        if (self._get_proc_start_time(sentry_unit, service, pgrep_full) >=\n                self._get_file_mtime(sentry_unit, filename)):\n            return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if a service was started since a given time.", "response": "def service_restarted_since(self, sentry_unit, mtime, service,\n                                pgrep_full=None, sleep_time=20,\n                                retry_count=30, retry_sleep_time=10):\n        \"\"\"Check if service was been started after a given time.\n\n        Args:\n          sentry_unit (sentry): The sentry unit to check for the service on\n          mtime (float): The epoch time to check against\n          service (string): service name to look for in process table\n          pgrep_full: [Deprecated] Use full command line search mode with pgrep\n          sleep_time (int): Initial sleep time (s) before looking for file\n          retry_sleep_time (int): Time (s) to sleep between retries\n          retry_count (int): If file is not found, how many times to retry\n\n        Returns:\n          bool: True if service found and its start time it newer than mtime,\n                False if service is older than mtime or if service was\n                not found.\n        \"\"\"\n        # NOTE(beisner) pgrep_full is no longer implemented, as pidof is now\n        # used instead of pgrep.  pgrep_full is still passed through to ensure\n        # deprecation WARNS.  lp1474030\n\n        unit_name = sentry_unit.info['unit_name']\n        self.log.debug('Checking that %s service restarted since %s on '\n                       '%s' % (service, mtime, unit_name))\n        time.sleep(sleep_time)\n        proc_start_time = None\n        tries = 0\n        while tries <= retry_count and not proc_start_time:\n            try:\n                proc_start_time = self._get_proc_start_time(sentry_unit,\n                                                            service,\n                                                            pgrep_full)\n                self.log.debug('Attempt {} to get {} proc start time on {} '\n                               'OK'.format(tries, service, unit_name))\n            except IOError as e:\n                # NOTE(beisner) - race avoidance, proc may not exist yet.\n                # https://bugs.launchpad.net/charm-helpers/+bug/1474030\n                self.log.debug('Attempt {} to get {} proc start time on {} '\n                               'failed\\n{}'.format(tries, service,\n                                                   unit_name, e))\n                time.sleep(retry_sleep_time)\n                tries += 1\n\n        if not proc_start_time:\n            self.log.warn('No proc start time found, assuming service did '\n                          'not start')\n            return False\n        if proc_start_time >= mtime:\n            self.log.debug('Proc start time is newer than provided mtime'\n                           '(%s >= %s) on %s (OK)' % (proc_start_time,\n                                                      mtime, unit_name))\n            return True\n        else:\n            self.log.warn('Proc start time (%s) is older than provided mtime '\n                          '(%s) on %s, service did not '\n                          'restart' % (proc_start_time, mtime, unit_name))\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if a file was modified since a given time.", "response": "def config_updated_since(self, sentry_unit, filename, mtime,\n                             sleep_time=20, retry_count=30,\n                             retry_sleep_time=10):\n        \"\"\"Check if file was modified after a given time.\n\n        Args:\n          sentry_unit (sentry): The sentry unit to check the file mtime on\n          filename (string): The file to check mtime of\n          mtime (float): The epoch time to check against\n          sleep_time (int): Initial sleep time (s) before looking for file\n          retry_sleep_time (int): Time (s) to sleep between retries\n          retry_count (int): If file is not found, how many times to retry\n\n        Returns:\n          bool: True if file was modified more recently than mtime, False if\n                file was modified before mtime, or if file not found.\n        \"\"\"\n        unit_name = sentry_unit.info['unit_name']\n        self.log.debug('Checking that %s updated since %s on '\n                       '%s' % (filename, mtime, unit_name))\n        time.sleep(sleep_time)\n        file_mtime = None\n        tries = 0\n        while tries <= retry_count and not file_mtime:\n            try:\n                file_mtime = self._get_file_mtime(sentry_unit, filename)\n                self.log.debug('Attempt {} to get {} file mtime on {} '\n                               'OK'.format(tries, filename, unit_name))\n            except IOError as e:\n                # NOTE(beisner) - race avoidance, file may not exist yet.\n                # https://bugs.launchpad.net/charm-helpers/+bug/1474030\n                self.log.debug('Attempt {} to get {} file mtime on {} '\n                               'failed\\n{}'.format(tries, filename,\n                                                   unit_name, e))\n                time.sleep(retry_sleep_time)\n                tries += 1\n\n        if not file_mtime:\n            self.log.warn('Could not determine file mtime, assuming '\n                          'file does not exist')\n            return False\n\n        if file_mtime >= mtime:\n            self.log.debug('File mtime is newer than provided mtime '\n                           '(%s >= %s) on %s (OK)' % (file_mtime,\n                                                      mtime, unit_name))\n            return True\n        else:\n            self.log.warn('File mtime is older than provided mtime'\n                          '(%s < on %s) on %s' % (file_mtime,\n                                                  mtime, unit_name))\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if the service and file were updated after the given time.", "response": "def validate_service_config_changed(self, sentry_unit, mtime, service,\n                                        filename, pgrep_full=None,\n                                        sleep_time=20, retry_count=30,\n                                        retry_sleep_time=10):\n        \"\"\"Check service and file were updated after mtime\n\n        Args:\n          sentry_unit (sentry): The sentry unit to check for the service on\n          mtime (float): The epoch time to check against\n          service (string): service name to look for in process table\n          filename (string): The file to check mtime of\n          pgrep_full: [Deprecated] Use full command line search mode with pgrep\n          sleep_time (int): Initial sleep in seconds to pass to test helpers\n          retry_count (int): If service is not found, how many times to retry\n          retry_sleep_time (int): Time in seconds to wait between retries\n\n        Typical Usage:\n            u = OpenStackAmuletUtils(ERROR)\n            ...\n            mtime = u.get_sentry_time(self.cinder_sentry)\n            self.d.configure('cinder', {'verbose': 'True', 'debug': 'True'})\n            if not u.validate_service_config_changed(self.cinder_sentry,\n                                                     mtime,\n                                                     'cinder-api',\n                                                     '/etc/cinder/cinder.conf')\n                amulet.raise_status(amulet.FAIL, msg='update failed')\n        Returns:\n          bool: True if both service and file where updated/restarted after\n                mtime, False if service is older than mtime or if service was\n                not found or if filename was modified before mtime.\n        \"\"\"\n\n        # NOTE(beisner) pgrep_full is no longer implemented, as pidof is now\n        # used instead of pgrep.  pgrep_full is still passed through to ensure\n        # deprecation WARNS.  lp1474030\n\n        service_restart = self.service_restarted_since(\n            sentry_unit, mtime,\n            service,\n            pgrep_full=pgrep_full,\n            sleep_time=sleep_time,\n            retry_count=retry_count,\n            retry_sleep_time=retry_sleep_time)\n\n        config_update = self.config_updated_since(\n            sentry_unit,\n            filename,\n            mtime,\n            sleep_time=sleep_time,\n            retry_count=retry_count,\n            retry_sleep_time=retry_sleep_time)\n\n        return service_restart and config_update"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a relative file path to a file URL.", "response": "def file_to_url(self, file_rel_path):\n        \"\"\"Convert a relative file path to a file URL.\"\"\"\n        _abs_path = os.path.abspath(file_rel_path)\n        return urlparse.urlparse(_abs_path, scheme='file').geturl()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_commands_on_units(self, commands, sentry_units):\n        self.log.debug('Checking exit codes for {} commands on {} '\n                       'sentry units...'.format(len(commands),\n                                                len(sentry_units)))\n        for sentry_unit in sentry_units:\n            for cmd in commands:\n                output, code = sentry_unit.run(cmd)\n                if code == 0:\n                    self.log.debug('{} `{}` returned {} '\n                                   '(OK)'.format(sentry_unit.info['unit_name'],\n                                                 cmd, code))\n                else:\n                    return ('{} `{}` returned {} '\n                            '{}'.format(sentry_unit.info['unit_name'],\n                                        cmd, code, output))\n        return None", "response": "Check that all commands in a list exit zero on all sentry units in a list"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a list of process IDs from a single sentry juju unit.", "response": "def get_process_id_list(self, sentry_unit, process_name,\n                            expect_success=True, pgrep_full=False):\n        \"\"\"Get a list of process ID(s) from a single sentry juju unit\n        for a single process name.\n\n        :param sentry_unit: Amulet sentry instance (juju unit)\n        :param process_name: Process name\n        :param expect_success: If False, expect the PID to be missing,\n            raise if it is present.\n        :returns: List of process IDs\n        \"\"\"\n        if pgrep_full:\n            cmd = 'pgrep -f \"{}\"'.format(process_name)\n        else:\n            cmd = 'pidof -x \"{}\"'.format(process_name)\n        if not expect_success:\n            cmd += \" || exit 0 && exit 1\"\n        output, code = sentry_unit.run(cmd)\n        if code != 0:\n            msg = ('{} `{}` returned {} '\n                   '{}'.format(sentry_unit.info['unit_name'],\n                               cmd, code, output))\n            amulet.raise_status(amulet.FAIL, msg=msg)\n        return str(output).split()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_unit_process_ids(\n            self, unit_processes, expect_success=True, pgrep_full=False):\n        \"\"\"Construct a dict containing unit sentries, process names, and\n        process IDs.\n\n        :param unit_processes: A dictionary of Amulet sentry instance\n            to list of process names.\n        :param expect_success: if False expect the processes to not be\n            running, raise if they are.\n        :returns: Dictionary of Amulet sentry instance to dictionary\n            of process names to PIDs.\n        \"\"\"\n        pid_dict = {}\n        for sentry_unit, process_list in six.iteritems(unit_processes):\n            pid_dict[sentry_unit] = {}\n            for process in process_list:\n                pids = self.get_process_id_list(\n                    sentry_unit, process, expect_success=expect_success,\n                    pgrep_full=pgrep_full)\n                pid_dict[sentry_unit].update({process: pids})\n        return pid_dict", "response": "Returns a dictionary containing unit sentries process names and process IDs."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef validate_unit_process_ids(self, expected, actual):\n        self.log.debug('Checking units for running processes...')\n        self.log.debug('Expected PIDs: {}'.format(expected))\n        self.log.debug('Actual PIDs: {}'.format(actual))\n\n        if len(actual) != len(expected):\n            return ('Unit count mismatch.  expected, actual: {}, '\n                    '{} '.format(len(expected), len(actual)))\n\n        for (e_sentry, e_proc_names) in six.iteritems(expected):\n            e_sentry_name = e_sentry.info['unit_name']\n            if e_sentry in actual.keys():\n                a_proc_names = actual[e_sentry]\n            else:\n                return ('Expected sentry ({}) not found in actual dict data.'\n                        '{}'.format(e_sentry_name, e_sentry))\n\n            if len(e_proc_names.keys()) != len(a_proc_names.keys()):\n                return ('Process name count mismatch.  expected, actual: {}, '\n                        '{}'.format(len(expected), len(actual)))\n\n            for (e_proc_name, e_pids), (a_proc_name, a_pids) in \\\n                    zip(e_proc_names.items(), a_proc_names.items()):\n                if e_proc_name != a_proc_name:\n                    return ('Process name mismatch.  expected, actual: {}, '\n                            '{}'.format(e_proc_name, a_proc_name))\n\n                a_pids_length = len(a_pids)\n                fail_msg = ('PID count mismatch. {} ({}) expected, actual: '\n                            '{}, {} ({})'.format(e_sentry_name, e_proc_name,\n                                                 e_pids, a_pids_length,\n                                                 a_pids))\n\n                # If expected is a list, ensure at least one PID quantity match\n                if isinstance(e_pids, list) and \\\n                        a_pids_length not in e_pids:\n                    return fail_msg\n                # If expected is not bool and not list,\n                # ensure PID quantities match\n                elif not isinstance(e_pids, bool) and \\\n                        not isinstance(e_pids, list) and \\\n                        a_pids_length != e_pids:\n                    return fail_msg\n                # If expected is bool True, ensure 1 or more PIDs exist\n                elif isinstance(e_pids, bool) and \\\n                        e_pids is True and a_pids_length < 1:\n                    return fail_msg\n                # If expected is bool False, ensure 0 PIDs exist\n                elif isinstance(e_pids, bool) and \\\n                        e_pids is False and a_pids_length != 0:\n                    return fail_msg\n                else:\n                    self.log.debug('PID check OK: {} {} {}: '\n                                   '{}'.format(e_sentry_name, e_proc_name,\n                                               e_pids, a_pids))\n        return None", "response": "Validate process id quantities for services on units."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking that all dicts within a list are identical.", "response": "def validate_list_of_identical_dicts(self, list_of_dicts):\n        \"\"\"Check that all dicts within a list are identical.\"\"\"\n        hashes = []\n        for _dict in list_of_dicts:\n            hashes.append(hash(frozenset(_dict.items())))\n\n        self.log.debug('Hashes: {}'.format(hashes))\n        if len(set(hashes)) == 1:\n            self.log.debug('Dicts within list are identical')\n        else:\n            return 'Dicts within list are not identical'\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate_sectionless_conf(self, file_contents, expected):\n        for line in file_contents.split('\\n'):\n            if '=' in line:\n                args = line.split('=')\n                if len(args) <= 1:\n                    continue\n                key = args[0].strip()\n                value = args[1].strip()\n                if key in expected.keys():\n                    if expected[key] != value:\n                        msg = ('Config mismatch.  Expected, actual:  {}, '\n                               '{}'.format(expected[key], value))\n                        amulet.raise_status(amulet.FAIL, msg=msg)", "response": "A crude conf parser. Useful to inspect configuration files which have section headers."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_unit_hostnames(self, units):\n        host_names = {}\n        for unit in units:\n            host_names[unit.info['unit_name']] = \\\n                str(unit.file_contents('/etc/hostname').strip())\n        self.log.debug('Unit host names: {}'.format(host_names))\n        return host_names", "response": "Return a dict of juju unit names to hostnames."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns a command on a unit return the output and exit code.", "response": "def run_cmd_unit(self, sentry_unit, cmd):\n        \"\"\"Run a command on a unit, return the output and exit code.\"\"\"\n        output, code = sentry_unit.run(cmd)\n        if code == 0:\n            self.log.debug('{} `{}` command returned {} '\n                           '(OK)'.format(sentry_unit.info['unit_name'],\n                                         cmd, code))\n        else:\n            msg = ('{} `{}` command returned {} '\n                   '{}'.format(sentry_unit.info['unit_name'],\n                               cmd, code, output))\n            amulet.raise_status(amulet.FAIL, msg=msg)\n        return str(output), code"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef file_exists_on_unit(self, sentry_unit, file_name):\n        try:\n            sentry_unit.file_stat(file_name)\n            return True\n        except IOError:\n            return False\n        except Exception as e:\n            msg = 'Error checking file {}: {}'.format(file_name, e)\n            amulet.raise_status(amulet.FAIL, msg=msg)", "response": "Check if a file exists on a unit."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef file_contents_safe(self, sentry_unit, file_name,\n                           max_wait=60, fatal=False):\n        \"\"\"Get file contents from a sentry unit.  Wrap amulet file_contents\n        with retry logic to address races where a file checks as existing,\n        but no longer exists by the time file_contents is called.\n        Return None if file not found. Optionally raise if fatal is True.\"\"\"\n        unit_name = sentry_unit.info['unit_name']\n        file_contents = False\n        tries = 0\n        while not file_contents and tries < (max_wait / 4):\n            try:\n                file_contents = sentry_unit.file_contents(file_name)\n            except IOError:\n                self.log.debug('Attempt {} to open file {} from {} '\n                               'failed'.format(tries, file_name,\n                                               unit_name))\n                time.sleep(4)\n                tries += 1\n\n        if file_contents:\n            return file_contents\n        elif not fatal:\n            return None\n        elif fatal:\n            msg = 'Failed to get file contents from unit.'\n            amulet.raise_status(amulet.FAIL, msg)", "response": "Get file contents from a sentry unit."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nopens a TCP socket to check for a listening sevice on a host.", "response": "def port_knock_tcp(self, host=\"localhost\", port=22, timeout=15):\n        \"\"\"Open a TCP socket to check for a listening sevice on a host.\n\n        :param host: host name or IP address, default to localhost\n        :param port: TCP port number, default to 22\n        :param timeout: Connect timeout, default to 15 seconds\n        :returns: True if successful, False if connect failed\n        \"\"\"\n\n        # Resolve host name if possible\n        try:\n            connect_host = socket.gethostbyname(host)\n            host_human = \"{} ({})\".format(connect_host, host)\n        except socket.error as e:\n            self.log.warn('Unable to resolve address: '\n                          '{} ({}) Trying anyway!'.format(host, e))\n            connect_host = host\n            host_human = connect_host\n\n        # Attempt socket connection\n        try:\n            knock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            knock.settimeout(timeout)\n            knock.connect((connect_host, port))\n            knock.close()\n            self.log.debug('Socket connect OK for host '\n                           '{} on port {}.'.format(host_human, port))\n            return True\n        except socket.error as e:\n            self.log.debug('Socket connect FAIL for'\n                           ' {} port {} ({})'.format(host_human, port, e))\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nopen a TCP socket to check for a listening sevice on each juju unit.", "response": "def port_knock_units(self, sentry_units, port=22,\n                         timeout=15, expect_success=True):\n        \"\"\"Open a TCP socket to check for a listening sevice on each\n        listed juju unit.\n\n        :param sentry_units: list of sentry unit pointers\n        :param port: TCP port number, default to 22\n        :param timeout: Connect timeout, default to 15 seconds\n        :expect_success: True by default, set False to invert logic\n        :returns: None if successful, Failure message otherwise\n        \"\"\"\n        for unit in sentry_units:\n            host = unit.info['public-address']\n            connected = self.port_knock_tcp(host, port, timeout)\n            if not connected and expect_success:\n                return 'Socket connect failed.'\n            elif connected and not expect_success:\n                return 'Socket connected unexpectedly.'"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run_action(self, unit_sentry, action,\n                   _check_output=subprocess.check_output,\n                   params=None):\n        \"\"\"Translate to amulet's built in run_action(). Deprecated.\n\n        Run the named action on a given unit sentry.\n\n        params a dict of parameters to use\n        _check_output parameter is no longer used\n\n        @return action_id.\n        \"\"\"\n        self.log.warn('charmhelpers.contrib.amulet.utils.run_action has been '\n                      'deprecated for amulet.run_action')\n        return unit_sentry.run_action(action, action_args=params)", "response": "Translate to amulet s built in run_action."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwaiting for a given action returning if it completed or not.", "response": "def wait_on_action(self, action_id, _check_output=subprocess.check_output):\n        \"\"\"Wait for a given action, returning if it completed or not.\n\n        action_id a string action uuid\n        _check_output parameter is no longer used\n        \"\"\"\n        data = amulet.actions.get_action_output(action_id, full_output=True)\n        return data.get(u\"status\") == \"completed\""}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef status_get(self, unit):\n        raw_status, return_code = unit.run(\n            \"status-get --format=json --include-data\")\n        if return_code != 0:\n            return (\"unknown\", \"\")\n        status = json.loads(raw_status)\n        return (status[\"status\"], status[\"message\"])", "response": "Return the current status of this unit."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef execute(self, sql):\n        cursor = self.connection.cursor()\n        try:\n            cursor.execute(sql)\n        finally:\n            cursor.close()", "response": "Execute arbitary SQL against the database."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexecute arbitrary SQL select query against the database and return the results.", "response": "def select(self, sql):\n        \"\"\"\n        Execute arbitrary SQL select query against the database\n        and return the results.\n\n        :param sql: SQL select query to execute\n        :type sql: string\n        :returns: SQL select query result\n        :rtype: list of lists\n        :raises: MySQLdb.Error\n        \"\"\"\n        cursor = self.connection.cursor()\n        try:\n            cursor.execute(sql)\n            results = [list(i) for i in cursor.fetchall()]\n        finally:\n            cursor.close()\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmigrate any passwords storage on disk to leader storage.", "response": "def migrate_passwords_to_leader_storage(self, excludes=None):\n        \"\"\"Migrate any passwords storage on disk to leader storage.\"\"\"\n        if not is_leader():\n            log(\"Skipping password migration as not the lead unit\",\n                level=DEBUG)\n            return\n        dirname = os.path.dirname(self.root_passwd_file_template)\n        path = os.path.join(dirname, '*.passwd')\n        for f in glob.glob(path):\n            if excludes and f in excludes:\n                log(\"Excluding %s from leader storage migration\" % (f),\n                    level=DEBUG)\n                continue\n\n            key = os.path.basename(f)\n            with open(f, 'r') as passwd:\n                _value = passwd.read().strip()\n\n            try:\n                leader_set(settings={key: _value})\n\n                if self.delete_ondisk_passwd_file:\n                    os.unlink(f)\n            except ValueError:\n                # NOTE cluster relation not yet ready - skip for now\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_mysql_password_on_disk(self, username=None, password=None):\n        if username:\n            template = self.user_passwd_file_template\n            passwd_file = template.format(username)\n        else:\n            passwd_file = self.root_passwd_file_template\n\n        _password = None\n        if os.path.exists(passwd_file):\n            log(\"Using existing password file '%s'\" % passwd_file, level=DEBUG)\n            with open(passwd_file, 'r') as passwd:\n                _password = passwd.read().strip()\n        else:\n            log(\"Generating new password file '%s'\" % passwd_file, level=DEBUG)\n            if not os.path.isdir(os.path.dirname(passwd_file)):\n                # NOTE: need to ensure this is not mysql root dir (which needs\n                # to be mysql readable)\n                mkdir(os.path.dirname(passwd_file), owner='root', group='root',\n                      perms=0o770)\n                # Force permissions - for some reason the chmod in makedirs\n                # fails\n                os.chmod(os.path.dirname(passwd_file), 0o770)\n\n            _password = password or pwgen(length=32)\n            write_file(passwd_file, _password, owner='root', group='root',\n                       perms=0o660)\n\n        return _password", "response": "Retrieve or generate a mysql password for the provided username on disk."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nretrieves or generate a mysql password for the provided username using the peer relation cluster.", "response": "def get_mysql_password(self, username=None, password=None):\n        \"\"\"Retrieve, generate or store a mysql password for the provided\n        username using peer relation cluster.\"\"\"\n        excludes = []\n\n        # First check peer relation.\n        try:\n            for key in self.passwd_keys(username):\n                _password = leader_get(key)\n                if _password:\n                    break\n\n            # If root password available don't update peer relation from local\n            if _password and not username:\n                excludes.append(self.root_passwd_file_template)\n\n        except ValueError:\n            # cluster relation is not yet started; use on-disk\n            _password = None\n\n        # If none available, generate new one\n        if not _password:\n            _password = self.get_mysql_password_on_disk(username, password)\n\n        # Put on wire if required\n        if self.migrate_passwd_to_leader_storage:\n            self.migrate_passwords_to_leader_storage(excludes=excludes)\n\n        return _password"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef normalize_address(self, hostname):\n        if config_get('prefer-ipv6'):\n            # TODO: add support for ipv6 dns\n            return hostname\n\n        if hostname != unit_get('private-address'):\n            return get_host_ip(hostname, fallback=hostname)\n\n        # Otherwise assume localhost\n        return '127.0.0.1'", "response": "Ensure that the given hostname is an IP address."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget list of units with access grants for database with username.", "response": "def get_allowed_units(self, database, username, relation_id=None):\n        \"\"\"Get list of units with access grants for database with username.\n\n        This is typically used to provide shared-db relations with a list of\n        which units have been granted access to the given database.\n        \"\"\"\n        self.connect(password=self.get_mysql_root_password())\n        allowed_units = set()\n        for unit in related_units(relation_id):\n            settings = relation_get(rid=relation_id, unit=unit)\n            # First check for setting with prefix, then without\n            for attr in [\"%s_hostname\" % (database), 'hostname']:\n                hosts = settings.get(attr, None)\n                if hosts:\n                    break\n\n            if hosts:\n                # hostname can be json-encoded list of hostnames\n                try:\n                    hosts = json.loads(hosts)\n                except ValueError:\n                    hosts = [hosts]\n            else:\n                hosts = [settings['private-address']]\n\n            if hosts:\n                for host in hosts:\n                    host = self.normalize_address(host)\n                    if self.grant_exists(database, username, host):\n                        log(\"Grant exists for host '%s' on db '%s'\" %\n                            (host, database), level=DEBUG)\n                        if unit not in allowed_units:\n                            allowed_units.add(unit)\n                    else:\n                        log(\"Grant does NOT exist for host '%s' on db '%s'\" %\n                            (host, database), level=DEBUG)\n            else:\n                log(\"No hosts found for grant check\", level=INFO)\n\n        return allowed_units"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef configure_db(self, hostname, database, username, admin=False):\n        self.connect(password=self.get_mysql_root_password())\n        if not self.database_exists(database):\n            self.create_database(database)\n\n        remote_ip = self.normalize_address(hostname)\n        password = self.get_mysql_password(username)\n        if not self.grant_exists(database, username, remote_ip):\n            if not admin:\n                self.create_grant(database, username, remote_ip, password)\n            else:\n                self.create_admin_grant(username, remote_ip, password)\n            self.flush_priviledges()\n\n        return password", "response": "Configure access to database for username from hostname."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert human readable configuration options to bytes.", "response": "def human_to_bytes(self, human):\n        \"\"\"Convert human readable configuration options to bytes.\"\"\"\n        num_re = re.compile('^[0-9]+$')\n        if num_re.match(human):\n            return human\n\n        factors = {\n            'K': 1024,\n            'M': 1048576,\n            'G': 1073741824,\n            'T': 1099511627776\n        }\n        modifier = human[-1]\n        if modifier in factors:\n            return int(human[:-1]) * factors[modifier]\n\n        if modifier == '%':\n            total_ram = self.human_to_bytes(self.get_mem_total())\n            if self.is_32bit_system() and total_ram > self.sys_mem_limit():\n                total_ram = self.sys_mem_limit()\n            factor = int(human[:-1]) * 0.01\n            pctram = total_ram * factor\n            return int(pctram - (pctram % self.DEFAULT_PAGE_SIZE))\n\n        raise ValueError(\"Can only convert K,M,G, or T\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndetermining the default memory limit for the current service unit.", "response": "def sys_mem_limit(self):\n        \"\"\"Determine the default memory limit for the current service unit.\"\"\"\n        if platform.machine() in ['armv7l']:\n            _mem_limit = self.human_to_bytes('2700M')  # experimentally determined\n        else:\n            # Limit for x86 based 32bit systems\n            _mem_limit = self.human_to_bytes('4G')\n\n        return _mem_limit"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the total memory in the current service unit.", "response": "def get_mem_total(self):\n        \"\"\"Calculate the total memory in the current service unit.\"\"\"\n        with open('/proc/meminfo') as meminfo_file:\n            for line in meminfo_file:\n                key, mem = line.split(':', 2)\n                if key == 'MemTotal':\n                    mtot, modifier = mem.strip().split(' ')\n                    return '%s%s' % (mtot, modifier[0].upper())"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_config(self):\n        config = config_get()\n        mysql_config = {}\n        if 'max-connections' in config:\n            mysql_config['max_connections'] = config['max-connections']\n\n        if 'wait-timeout' in config:\n            mysql_config['wait_timeout'] = config['wait-timeout']\n\n        if 'innodb-flush-log-at-trx-commit' in config:\n            mysql_config['innodb_flush_log_at_trx_commit'] = \\\n                config['innodb-flush-log-at-trx-commit']\n        elif 'tuning-level' in config:\n            mysql_config['innodb_flush_log_at_trx_commit'] = \\\n                self.INNODB_FLUSH_CONFIG_VALUES.get(config['tuning-level'], 1)\n\n        if ('innodb-change-buffering' in config and\n                config['innodb-change-buffering'] in self.INNODB_VALID_BUFFERING_VALUES):\n            mysql_config['innodb_change_buffering'] = config['innodb-change-buffering']\n\n        if 'innodb-io-capacity' in config:\n            mysql_config['innodb_io_capacity'] = config['innodb-io-capacity']\n\n        # Set a sane default key_buffer size\n        mysql_config['key_buffer'] = self.human_to_bytes('32M')\n        total_memory = self.human_to_bytes(self.get_mem_total())\n\n        dataset_bytes = config.get('dataset-size', None)\n        innodb_buffer_pool_size = config.get('innodb-buffer-pool-size', None)\n\n        if innodb_buffer_pool_size:\n            innodb_buffer_pool_size = self.human_to_bytes(\n                innodb_buffer_pool_size)\n        elif dataset_bytes:\n            log(\"Option 'dataset-size' has been deprecated, please use\"\n                \"innodb_buffer_pool_size option instead\", level=\"WARN\")\n            innodb_buffer_pool_size = self.human_to_bytes(\n                dataset_bytes)\n        else:\n            # NOTE(jamespage): pick the smallest of 50% of RAM or 512MB\n            #                  to ensure that deployments in containers\n            #                  without constraints don't try to consume\n            #                  silly amounts of memory.\n            innodb_buffer_pool_size = min(\n                int(total_memory * self.DEFAULT_INNODB_BUFFER_FACTOR),\n                self.DEFAULT_INNODB_BUFFER_SIZE_MAX\n            )\n\n        if innodb_buffer_pool_size > total_memory:\n            log(\"innodb_buffer_pool_size; {} is greater than system available memory:{}\".format(\n                innodb_buffer_pool_size,\n                total_memory), level='WARN')\n\n        mysql_config['innodb_buffer_pool_size'] = innodb_buffer_pool_size\n        return mysql_config", "response": "Parse the charm configuration and calculate values for config files."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef persistent_modprobe(module):\n    with open('/etc/modules', 'r+') as modules:\n        if module not in modules.read():\n            modules.write(module + \"\\n\")", "response": "Load a kernel module and configure for auto - load on reboot."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef loopback_devices():\n    '''\n    Parse through 'losetup -a' output to determine currently mapped\n    loopback devices. Output is expected to look like:\n\n        /dev/loop0: [0807]:961814 (/tmp/my.img)\n\n    :returns: dict: a dict mapping {loopback_dev: backing_file}\n    '''\n    loopbacks = {}\n    cmd = ['losetup', '-a']\n    output = check_output(cmd)\n    if six.PY3:\n        output = output.decode('utf-8')\n    devs = [d.strip().split(' ') for d in output.splitlines() if d != '']\n    for dev, _, f in devs:\n        loopbacks[dev.replace(':', '')] = re.search(r'\\((\\S+)\\)', f).groups()[0]\n    return loopbacks", "response": "Parse through losetup - a output to determine currently mapped loopback devices."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a loopback device for a given backing file.", "response": "def create_loopback(file_path):\n    '''\n    Create a loopback device for a given backing file.\n\n    :returns: str: Full path to new loopback device (eg, /dev/loop0)\n    '''\n    file_path = os.path.abspath(file_path)\n    check_call(['losetup', '--find', file_path])\n    for d, f in six.iteritems(loopback_devices()):\n        if f == file_path:\n            return d"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ensure_loopback_device(path, size):\n    '''\n    Ensure a loopback device exists for a given backing file path and size.\n    If it a loopback device is not mapped to file, a new one will be created.\n\n    TODO: Confirm size of found loopback device.\n\n    :returns: str: Full path to the ensured loopback device (eg, /dev/loop0)\n    '''\n    for d, f in six.iteritems(loopback_devices()):\n        if f == path:\n            return d\n\n    if not os.path.exists(path):\n        cmd = ['truncate', '--size', size, path]\n        check_call(cmd)\n\n    return create_loopback(path)", "response": "Ensures a loopback device exists for a given backing file path and size."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrap to ensure that the leader - get settings are migrated from the relation.", "response": "def leader_get(attribute=None, rid=None):\n    \"\"\"Wrapper to ensure that settings are migrated from the peer relation.\n\n    This is to support upgrading an environment that does not support\n    Juju leadership election to one that does.\n\n    If a setting is not extant in the leader-get but is on the relation-get\n    peer rel, it is migrated and marked as such so that it is not re-migrated.\n    \"\"\"\n    migration_key = '__leader_get_migrated_settings__'\n    if not is_leader():\n        return _leader_get(attribute=attribute)\n\n    settings_migrated = False\n    leader_settings = _leader_get(attribute=attribute)\n    previously_migrated = _leader_get(attribute=migration_key)\n\n    if previously_migrated:\n        migrated = set(json.loads(previously_migrated))\n    else:\n        migrated = set([])\n\n    try:\n        if migration_key in leader_settings:\n            del leader_settings[migration_key]\n    except TypeError:\n        pass\n\n    if attribute:\n        if attribute in migrated:\n            return leader_settings\n\n        # If attribute not present in leader db, check if this unit has set\n        # the attribute in the peer relation\n        if not leader_settings:\n            peer_setting = _relation_get(attribute=attribute, unit=local_unit(),\n                                         rid=rid)\n            if peer_setting:\n                leader_set(settings={attribute: peer_setting})\n                leader_settings = peer_setting\n\n        if leader_settings:\n            settings_migrated = True\n            migrated.add(attribute)\n    else:\n        r_settings = _relation_get(unit=local_unit(), rid=rid)\n        if r_settings:\n            for key in set(r_settings.keys()).difference(migrated):\n                # Leader setting wins\n                if not leader_settings.get(key):\n                    leader_settings[key] = r_settings[key]\n\n                settings_migrated = True\n                migrated.add(key)\n\n            if settings_migrated:\n                leader_set(**leader_settings)\n\n    if migrated and settings_migrated:\n        migrated = json.dumps(list(migrated))\n        leader_set(settings={migration_key: migrated})\n\n    return leader_settings"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef relation_set(relation_id=None, relation_settings=None, **kwargs):\n    try:\n        if relation_id in relation_ids('cluster'):\n            return leader_set(settings=relation_settings, **kwargs)\n        else:\n            raise NotImplementedError\n    except NotImplementedError:\n        return _relation_set(relation_id=relation_id,\n                             relation_settings=relation_settings, **kwargs)", "response": "Returns a new relation - set for the given relation id."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef relation_get(attribute=None, unit=None, rid=None):\n    try:\n        if rid in relation_ids('cluster'):\n            return leader_get(attribute, rid)\n        else:\n            raise NotImplementedError\n    except NotImplementedError:\n        return _relation_get(attribute=attribute, rid=rid, unit=unit)", "response": "Get a relation by its rid."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving a named key from peer relation relation_name.", "response": "def peer_retrieve(key, relation_name='cluster'):\n    \"\"\"Retrieve a named key from peer relation `relation_name`.\"\"\"\n    cluster_rels = relation_ids(relation_name)\n    if len(cluster_rels) > 0:\n        cluster_rid = cluster_rels[0]\n        return relation_get(attribute=key, rid=cluster_rid,\n                            unit=local_unit())\n    else:\n        raise ValueError('Unable to detect'\n                         'peer relation {}'.format(relation_name))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves k - v pairs given a prefix and filter using inc_list exc_list", "response": "def peer_retrieve_by_prefix(prefix, relation_name='cluster', delimiter='_',\n                            inc_list=None, exc_list=None):\n    \"\"\" Retrieve k/v pairs given a prefix and filter using {inc,exc}_list \"\"\"\n    inc_list = inc_list if inc_list else []\n    exc_list = exc_list if exc_list else []\n    peerdb_settings = peer_retrieve('-', relation_name=relation_name)\n    matched = {}\n    if peerdb_settings is None:\n        return matched\n    for k, v in peerdb_settings.items():\n        full_prefix = prefix + delimiter\n        if k.startswith(full_prefix):\n            new_key = k.replace(full_prefix, '')\n            if new_key in exc_list:\n                continue\n            if new_key in inc_list or len(inc_list) == 0:\n                matched[new_key] = v\n    return matched"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef peer_store(key, value, relation_name='cluster'):\n    cluster_rels = relation_ids(relation_name)\n    if len(cluster_rels) > 0:\n        cluster_rid = cluster_rels[0]\n        relation_set(relation_id=cluster_rid,\n                     relation_settings={key: value})\n    else:\n        raise ValueError('Unable to detect '\n                         'peer relation {}'.format(relation_name))", "response": "Store the key value pair on the named peer relation relation_name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nechoing filtered attributes back onto the same relation for storage.", "response": "def peer_echo(includes=None, force=False):\n    \"\"\"Echo filtered attributes back onto the same relation for storage.\n\n    This is a requirement to use the peerstorage module - it needs to be called\n    from the peer relation's changed hook.\n\n    If Juju leader support exists this will be a noop unless force is True.\n    \"\"\"\n    try:\n        is_leader()\n    except NotImplementedError:\n        pass\n    else:\n        if not force:\n            return  # NOOP if leader-election is supported\n\n    # Use original non-leader calls\n    relation_get = _relation_get\n    relation_set = _relation_set\n\n    rdata = relation_get()\n    echo_data = {}\n    if includes is None:\n        echo_data = rdata.copy()\n        for ex in ['private-address', 'public-address']:\n            if ex in echo_data:\n                echo_data.pop(ex)\n    else:\n        for attribute, value in six.iteritems(rdata):\n            for include in includes:\n                if include in attribute:\n                    echo_data[attribute] = value\n    if len(echo_data) > 0:\n        relation_set(relation_settings=echo_data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstore passed - in arguments both in argument relation and in peer storage.", "response": "def peer_store_and_set(relation_id=None, peer_relation_name='cluster',\n                       peer_store_fatal=False, relation_settings=None,\n                       delimiter='_', **kwargs):\n    \"\"\"Store passed-in arguments both in argument relation and in peer storage.\n\n    It functions like doing relation_set() and peer_store() at the same time,\n    with the same data.\n\n    @param relation_id: the id of the relation to store the data on. Defaults\n                        to the current relation.\n    @param peer_store_fatal: Set to True, the function will raise an exception\n                             should the peer sotrage not be avialable.\"\"\"\n\n    relation_settings = relation_settings if relation_settings else {}\n    relation_set(relation_id=relation_id,\n                 relation_settings=relation_settings,\n                 **kwargs)\n    if is_relation_made(peer_relation_name):\n        for key, value in six.iteritems(dict(list(kwargs.items()) +\n                                             list(relation_settings.items()))):\n            key_prefix = relation_id or current_relation_id()\n            peer_store(key_prefix + delimiter + key,\n                       value,\n                       relation_name=peer_relation_name)\n    else:\n        if peer_store_fatal:\n            raise ValueError('Unable to detect '\n                             'peer relation {}'.format(peer_relation_name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sed(filename, before, after, flags='g'):\n    expression = r's/{0}/{1}/{2}'.format(before,\n                                         after, flags)\n\n    return subprocess.check_call([\"sed\", \"-i\", \"-r\", \"-e\",\n                                  expression,\n                                  os.path.expanduser(filename)])", "response": "Search and replaces the given pattern on filename."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef lsb_release():\n    d = {}\n    with open('/etc/os-release', 'r') as lsb:\n        for l in lsb:\n            s = l.split('=')\n            if len(s) != 2:\n                continue\n            d[s[0].strip()] = s[1].strip()\n    return d", "response": "Return a dict of all the available OS - release items in the system."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cmp_pkgrevno(package, revno, pkgcache=None):\n    if not pkgcache:\n        y = yum.YumBase()\n        packages = y.doPackageLists()\n        pkgcache = {i.Name: i.version for i in packages['installed']}\n    pkg = pkgcache[package]\n    if pkg > revno:\n        return 1\n    if pkg < revno:\n        return -1\n    return 0", "response": "Compare the given package with the given revision number."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_listening(self, listen=['0.0.0.0']):\n        if listen == ['0.0.0.0']:\n            return listen\n\n        value = []\n        for network in listen:\n            try:\n                ip = get_address_in_network(network=network, fatal=True)\n            except ValueError:\n                if is_ip(network):\n                    ip = network\n                else:\n                    try:\n                        ip = get_iface_addr(iface=network, fatal=False)[0]\n                    except IndexError:\n                        continue\n            value.append(ip)\n        if value == []:\n            return ['0.0.0.0']\n        return value", "response": "Returns a list of addresses SSH can listen on."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_loader(templates_dir, os_release):\n    tmpl_dirs = [(rel, os.path.join(templates_dir, rel))\n                 for rel in six.itervalues(OPENSTACK_CODENAMES)]\n\n    if not os.path.isdir(templates_dir):\n        log('Templates directory not found @ %s.' % templates_dir,\n            level=ERROR)\n        raise OSConfigException\n\n    # the bottom contains tempaltes_dir and possibly a common templates dir\n    # shipped with the helper.\n    loaders = [FileSystemLoader(templates_dir)]\n    helper_templates = os.path.join(os.path.dirname(__file__), 'templates')\n    if os.path.isdir(helper_templates):\n        loaders.append(FileSystemLoader(helper_templates))\n\n    for rel, tmpl_dir in tmpl_dirs:\n        if os.path.isdir(tmpl_dir):\n            loaders.insert(0, FileSystemLoader(tmpl_dir))\n        if rel == os_release:\n            break\n    # demote this log to the lowest level; we don't really need to see these\n    # lots in production even when debugging.\n    log('Creating choice loader with dirs: %s' %\n        [l.searchpath for l in loaders], level=TRACE)\n    return ChoiceLoader(loaders)", "response": "Create a ChoiceLoader containing templates dirs up to and including os_release."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of interfaces that have satisfied contexts.", "response": "def complete_contexts(self):\n        '''\n        Return a list of interfaces that have satisfied contexts.\n        '''\n        if self._complete_contexts:\n            return self._complete_contexts\n        self.context()\n        return self._complete_contexts"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef register(self, config_file, contexts, config_template=None):\n        self.templates[config_file] = OSConfigTemplate(\n            config_file=config_file,\n            contexts=contexts,\n            config_template=config_template\n        )\n        log('Registered config file: {}'.format(config_file),\n            level=INFO)", "response": "Register a config file with a list of context generators to be called by the context generators."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_template_from_string(self, ostmpl):\n        '''\n        Get a jinja2 template object from a string.\n        :param ostmpl: OSConfigTemplate to use as a data source.\n        '''\n        self._get_tmpl_env()\n        template = self._tmpl_env.from_string(ostmpl.config_template)\n        log('Loaded a template from a string for {}'.format(\n            ostmpl.config_file),\n            level=INFO)\n        return template", "response": "Get a jinja2 template object from a string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite a single config file.", "response": "def write(self, config_file):\n        \"\"\"\n        Write a single config file, raises if config file is not registered.\n        \"\"\"\n        if config_file not in self.templates:\n            log('Config not registered: %s' % config_file, level=ERROR)\n            raise OSConfigException\n\n        _out = self.render(config_file)\n        if six.PY3:\n            _out = _out.encode('UTF-8')\n\n        with open(config_file, 'wb') as out:\n            out.write(_out)\n\n        log('Wrote template %s.' % config_file, level=INFO)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites out all registered config files.", "response": "def write_all(self):\n        \"\"\"\n        Write out all registered config files.\n        \"\"\"\n        [self.write(k) for k in six.iterkeys(self.templates)]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the template environment and generates a new template loader based on a new openstack release.", "response": "def set_release(self, openstack_release):\n        \"\"\"\n        Resets the template environment and generates a new template loader\n        based on a the new openstack release.\n        \"\"\"\n        self._tmpl_env = None\n        self.openstack_release = openstack_release\n        self._get_tmpl_env()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of context interfaces that yield a complete context.", "response": "def complete_contexts(self):\n        '''\n        Returns a list of context interfaces that yield a complete context.\n        '''\n        interfaces = []\n        [interfaces.extend(i.complete_contexts())\n         for i in six.itervalues(self.templates)]\n        return interfaces"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_incomplete_context_data(self, interfaces):\n        '''\n        Return dictionary of relation status of interfaces and any missing\n        required context data. Example:\n            {'amqp': {'missing_data': ['rabbitmq_password'], 'related': True},\n             'zeromq-configuration': {'related': False}}\n        '''\n        incomplete_context_data = {}\n\n        for i in six.itervalues(self.templates):\n            for context in i.contexts:\n                for interface in interfaces:\n                    related = False\n                    if interface in context.interfaces:\n                        related = context.get_related()\n                        missing_data = context.missing_data\n                        if missing_data:\n                            incomplete_context_data[interface] = {'missing_data': missing_data}\n                        if related:\n                            if incomplete_context_data.get(interface):\n                                incomplete_context_data[interface].update({'related': True})\n                            else:\n                                incomplete_context_data[interface] = {'related': True}\n                        else:\n                            incomplete_context_data[interface] = {'related': False}\n        return incomplete_context_data", "response": "Return dictionary of relation status of interfaces and any missing_data required context data. Example"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if the charm executing this is the elected leader.", "response": "def is_elected_leader(resource):\n    \"\"\"\n    Returns True if the charm executing this is the elected cluster leader.\n\n    It relies on two mechanisms to determine leadership:\n        1. If juju is sufficiently new and leadership election is supported,\n        the is_leader command will be used.\n        2. If the charm is part of a corosync cluster, call corosync to\n        determine leadership.\n        3. If the charm is not part of a corosync cluster, the leader is\n        determined as being \"the alive unit with the lowest unit numer\". In\n        other words, the oldest surviving unit.\n    \"\"\"\n    try:\n        return juju_is_leader()\n    except NotImplementedError:\n        log('Juju leadership election feature not enabled'\n            ', using fallback support',\n            level=WARNING)\n\n    if is_clustered():\n        if not is_crm_leader(resource):\n            log('Deferring action to CRM leader.', level=INFO)\n            return False\n    else:\n        peers = peer_units()\n        if peers and not oldest_peer(peers):\n            log('Deferring action to oldest service unit.', level=INFO)\n            return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndetermine if the current DC is the leadership by querying the pacemaker Designated Controller and checking if the current DC is the same as the unit hostname.", "response": "def is_crm_dc():\n    \"\"\"\n    Determine leadership by querying the pacemaker Designated Controller\n    \"\"\"\n    cmd = ['crm', 'status']\n    try:\n        status = subprocess.check_output(cmd, stderr=subprocess.STDOUT)\n        if not isinstance(status, six.text_type):\n            status = six.text_type(status, \"utf-8\")\n    except subprocess.CalledProcessError as ex:\n        raise CRMDCNotFound(str(ex))\n\n    current_dc = ''\n    for line in status.split('\\n'):\n        if line.startswith('Current DC'):\n            # Current DC: juju-lytrusty-machine-2 (168108163) - partition with quorum\n            current_dc = line.split(':')[1].split()[0]\n    if current_dc == get_unit_hostname():\n        return True\n    elif current_dc == 'NONE':\n        raise CRMDCNotFound('Current DC: NONE')\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_crm_leader(resource, retry=False):\n    if resource == DC_RESOURCE_NAME:\n        return is_crm_dc()\n    cmd = ['crm', 'resource', 'show', resource]\n    try:\n        status = subprocess.check_output(cmd, stderr=subprocess.STDOUT)\n        if not isinstance(status, six.text_type):\n            status = six.text_type(status, \"utf-8\")\n    except subprocess.CalledProcessError:\n        status = None\n\n    if status and get_unit_hostname() in status:\n        return True\n\n    if status and \"resource %s is NOT running\" % (resource) in status:\n        raise CRMResourceNotFound(\"CRM resource %s not found\" % (resource))\n\n    return False", "response": "Returns True if the charm calling this is the elected corosync leader."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef peer_ips(peer_relation='cluster', addr_key='private-address'):\n    '''Return a dict of peers and their private-address'''\n    peers = {}\n    for r_id in relation_ids(peer_relation):\n        for unit in relation_list(r_id):\n            peers[unit] = relation_get(addr_key, rid=r_id, unit=unit)\n    return peers", "response": "Return a dict of peers and their private - address"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndetermine who the oldest peer is by comparing unit numbers.", "response": "def oldest_peer(peers):\n    \"\"\"Determines who the oldest peer is by comparing unit numbers.\"\"\"\n    local_unit_no = int(os.getenv('JUJU_UNIT_NAME').split('/')[1])\n    for peer in peers:\n        remote_unit_no = int(peer.split('/')[1])\n        if remote_unit_no < local_unit_no:\n            return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetermine whether enough data has been provided in configuration or relation data to configure HTTPS.", "response": "def https():\n    '''\n    Determines whether enough data has been provided in configuration\n    or relation data to configure HTTPS\n    .\n    returns: boolean\n    '''\n    use_https = config_get('use-https')\n    if use_https and bool_from_string(use_https):\n        return True\n    if config_get('ssl_cert') and config_get('ssl_key'):\n        return True\n    for r_id in relation_ids('certificates'):\n        for unit in relation_list(r_id):\n            ca = relation_get('ca', rid=r_id, unit=unit)\n            if ca:\n                return True\n    for r_id in relation_ids('identity-service'):\n        for unit in relation_list(r_id):\n            # TODO - needs fixing for new helper as ssl_cert/key suffixes with CN\n            rel_state = [\n                relation_get('https_keystone', rid=r_id, unit=unit),\n                relation_get('ca_cert', rid=r_id, unit=unit),\n            ]\n            # NOTE: works around (LP: #1203241)\n            if (None not in rel_state) and ('' not in rel_state):\n                return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndetermining the correct port for the API server listening on the given service.", "response": "def determine_api_port(public_port, singlenode_mode=False):\n    '''\n    Determine correct API server listening port based on\n    existence of HTTPS reverse proxy and/or haproxy.\n\n    public_port: int: standard public port for given service\n\n    singlenode_mode: boolean: Shuffle ports when only a single unit is present\n\n    returns: int: the correct listening port for the API service\n    '''\n    i = 0\n    if singlenode_mode:\n        i += 1\n    elif len(peer_units()) > 0 or is_clustered():\n        i += 1\n    if https():\n        i += 1\n    return public_port - (i * 10)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef determine_apache_port(public_port, singlenode_mode=False):\n    '''\n    Description: Determine correct apache listening port based on public IP +\n    state of the cluster.\n\n    public_port: int: standard public port for given service\n\n    singlenode_mode: boolean: Shuffle ports when only a single unit is present\n\n    returns: int: the correct listening port for the HAProxy service\n    '''\n    i = 0\n    if singlenode_mode:\n        i += 1\n    elif len(peer_units()) > 0 or is_clustered():\n        i += 1\n    return public_port - (i * 10)", "response": "This function determines the apache listening port based on the given public IP + the state of the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_hacluster_config(exclude_keys=None):\n    '''\n    Obtains all relevant configuration from charm configuration required\n    for initiating a relation to hacluster:\n\n        ha-bindiface, ha-mcastport, vip, os-internal-hostname,\n        os-admin-hostname, os-public-hostname, os-access-hostname\n\n    param: exclude_keys: list of setting key(s) to be excluded.\n    returns: dict: A dict containing settings keyed by setting name.\n    raises: HAIncompleteConfig if settings are missing or incorrect.\n    '''\n    settings = ['ha-bindiface', 'ha-mcastport', 'vip', 'os-internal-hostname',\n                'os-admin-hostname', 'os-public-hostname', 'os-access-hostname']\n    conf = {}\n    for setting in settings:\n        if exclude_keys and setting in exclude_keys:\n            continue\n\n        conf[setting] = config_get(setting)\n\n    if not valid_hacluster_config():\n        raise HAIncorrectConfig('Insufficient or incorrect config data to '\n                                'configure hacluster.')\n    return conf", "response": "Returns all relevant configuration data for the current charm."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef valid_hacluster_config():\n    '''\n    Check that either vip or dns-ha is set. If dns-ha then one of os-*-hostname\n    must be set.\n\n    Note: ha-bindiface and ha-macastport both have defaults and will always\n    be set. We only care that either vip or dns-ha is set.\n\n    :returns: boolean: valid config returns true.\n    raises: HAIncompatibileConfig if settings conflict.\n    raises: HAIncompleteConfig if settings are missing.\n    '''\n    vip = config_get('vip')\n    dns = config_get('dns-ha')\n    if not(bool(vip) ^ bool(dns)):\n        msg = ('HA: Either vip or dns-ha must be set but not both in order to '\n               'use high availability')\n        status_set('blocked', msg)\n        raise HAIncorrectConfig(msg)\n\n    # If dns-ha then one of os-*-hostname must be set\n    if dns:\n        dns_settings = ['os-internal-hostname', 'os-admin-hostname',\n                        'os-public-hostname', 'os-access-hostname']\n        # At this point it is unknown if one or all of the possible\n        # network spaces are in HA. Validate at least one is set which is\n        # the minimum required.\n        for setting in dns_settings:\n            if config_get(setting):\n                log('DNS HA: At least one hostname is set {}: {}'\n                    ''.format(setting, config_get(setting)),\n                    level=DEBUG)\n                return True\n\n        msg = ('DNS HA: At least one os-*-hostname(s) must be set to use '\n               'DNS HA')\n        status_set('blocked', msg)\n        raise HAIncompleteConfig(msg)\n\n    log('VIP HA: VIP is set {}'.format(vip), level=DEBUG)\n    return True", "response": "Validate that the configuration of the HA cluster is valid."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef canonical_url(configs, vip_setting='vip'):\n    '''\n    Returns the correct HTTP URL to this host given the state of HTTPS\n    configuration and hacluster.\n\n    :configs    : OSTemplateRenderer: A config tempating object to inspect for\n                                      a complete https context.\n\n    :vip_setting:                str: Setting in charm config that specifies\n                                      VIP address.\n    '''\n    scheme = 'http'\n    if 'https' in configs.complete_contexts():\n        scheme = 'https'\n    if is_clustered():\n        addr = config_get(vip_setting)\n    else:\n        addr = unit_get('private-address')\n    return '%s://%s' % (scheme, addr)", "response": "Returns the canonical URL for the given config and hacluster."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndistributes operations by waiting based on modulo_distribution", "response": "def distributed_wait(modulo=None, wait=None, operation_name='operation'):\n    ''' Distribute operations by waiting based on modulo_distribution\n\n    If modulo and or wait are not set, check config_get for those values.\n    If config values are not set, default to modulo=3 and wait=30.\n\n    :param modulo: int The modulo number creates the group distribution\n    :param wait: int The constant time wait value\n    :param operation_name: string Operation name for status message\n                           i.e.  'restart'\n    :side effect: Calls config_get()\n    :side effect: Calls log()\n    :side effect: Calls status_set()\n    :side effect: Calls time.sleep()\n    '''\n    if modulo is None:\n        modulo = config_get('modulo-nodes') or 3\n    if wait is None:\n        wait = config_get('known-wait') or 30\n    if juju_is_leader():\n        # The leader should never wait\n        calculated_wait = 0\n    else:\n        # non_zero_wait=True guarantees the non-leader who gets modulo 0\n        # will still wait\n        calculated_wait = modulo_distribution(modulo=modulo, wait=wait,\n                                              non_zero_wait=True)\n    msg = \"Waiting {} seconds for {} ...\".format(calculated_wait,\n                                                 operation_name)\n    log(msg, DEBUG)\n    status_set('maintenance', msg)\n    time.sleep(calculated_wait)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef filter_installed_packages(packages):\n    yb = yum.YumBase()\n    package_list = yb.doPackageLists()\n    temp_cache = {p.base_package_name: 1 for p in package_list['installed']}\n\n    _pkgs = [p for p in packages if not temp_cache.get(p, False)]\n    return _pkgs", "response": "Return a list of packages that require installation."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninstalls one or more packages.", "response": "def install(packages, options=None, fatal=False):\n    \"\"\"Install one or more packages.\"\"\"\n    cmd = ['yum', '--assumeyes']\n    if options is not None:\n        cmd.extend(options)\n    cmd.append('install')\n    if isinstance(packages, six.string_types):\n        cmd.append(packages)\n    else:\n        cmd.extend(packages)\n    log(\"Installing {} with options: {}\".format(packages,\n                                                options))\n    _run_yum_command(cmd, fatal)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update(fatal=False):\n    cmd = ['yum', '--assumeyes', 'update']\n    log(\"Update with fatal: {}\".format(fatal))\n    _run_yum_command(cmd, fatal)", "response": "Update local yum cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npurge one or more packages.", "response": "def purge(packages, fatal=False):\n    \"\"\"Purge one or more packages.\"\"\"\n    cmd = ['yum', '--assumeyes', 'remove']\n    if isinstance(packages, six.string_types):\n        cmd.append(packages)\n    else:\n        cmd.extend(packages)\n    log(\"Purging {}\".format(packages))\n    _run_yum_command(cmd, fatal)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef yum_search(packages):\n    output = {}\n    cmd = ['yum', 'search']\n    if isinstance(packages, six.string_types):\n        cmd.append(packages)\n    else:\n        cmd.extend(packages)\n    log(\"Searching for {}\".format(packages))\n    result = subprocess.check_output(cmd)\n    for package in list(packages):\n        output[package] = package in result\n    return output", "response": "Search for a package."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_source(source, key=None):\n    if source is None:\n        log('Source is not present. Skipping')\n        return\n\n    if source.startswith('http'):\n        directory = '/etc/yum.repos.d/'\n        for filename in os.listdir(directory):\n            with open(directory + filename, 'r') as rpm_file:\n                if source in rpm_file.read():\n                    break\n        else:\n            log(\"Add source: {!r}\".format(source))\n            # write in the charms.repo\n            with open(directory + 'Charms.repo', 'a') as rpm_file:\n                rpm_file.write('[%s]\\n' % source[7:].replace('/', '_'))\n                rpm_file.write('name=%s\\n' % source[7:])\n                rpm_file.write('baseurl=%s\\n\\n' % source)\n    else:\n        log(\"Unknown source: {!r}\".format(source))\n\n    if key:\n        if '-----BEGIN PGP PUBLIC KEY BLOCK-----' in key:\n            with NamedTemporaryFile('w+') as key_file:\n                key_file.write(key)\n                key_file.flush()\n                key_file.seek(0)\n                subprocess.check_call(['rpm', '--import', key_file.name])\n        else:\n            subprocess.check_call(['rpm', '--import', key])", "response": "Add a source to the system s package list."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _run_yum_command(cmd, fatal=False):\n    env = os.environ.copy()\n\n    if fatal:\n        retry_count = 0\n        result = None\n\n        # If the command is considered \"fatal\", we need to retry if the yum\n        # lock was not acquired.\n\n        while result is None or result == YUM_NO_LOCK:\n            try:\n                result = subprocess.check_call(cmd, env=env)\n            except subprocess.CalledProcessError as e:\n                retry_count = retry_count + 1\n                if retry_count > YUM_NO_LOCK_RETRY_COUNT:\n                    raise\n                result = e.returncode\n                log(\"Couldn't acquire YUM lock. Will retry in {} seconds.\"\n                    \"\".format(YUM_NO_LOCK_RETRY_DELAY))\n                time.sleep(YUM_NO_LOCK_RETRY_DELAY)\n\n    else:\n        subprocess.call(cmd, env=env)", "response": "Run an YUM command."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nanalyzes a function s signature and return a data structure suitable for passing in as arguments to an argparse parser s add_argument method.", "response": "def describe_arguments(func):\n    \"\"\"\n    Analyze a function's signature and return a data structure suitable for\n    passing in as arguments to an argparse parser's add_argument() method.\"\"\"\n\n    argspec = inspect.getargspec(func)\n    # we should probably raise an exception somewhere if func includes **kwargs\n    if argspec.defaults:\n        positional_args = argspec.args[:-len(argspec.defaults)]\n        keyword_names = argspec.args[-len(argspec.defaults):]\n        for arg, default in zip(keyword_names, argspec.defaults):\n            yield ('--{}'.format(arg),), {'default': default}\n    else:\n        positional_args = argspec.args\n\n    for arg in positional_args:\n        yield (arg,), {}\n    if argspec.varargs:\n        yield (argspec.varargs,), {'nargs': '*'}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\noutputting data as raw string", "response": "def raw(self, output):\n        \"\"\"Output data as raw string (default)\"\"\"\n        if isinstance(output, (list, tuple)):\n            output = '\\n'.join(map(str, output))\n        self.outfile.write(str(output))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\noutput data as a nicely - formatted python data structure", "response": "def py(self, output):\n        \"\"\"Output data as a nicely-formatted python data structure\"\"\"\n        import pprint\n        pprint.pprint(output, stream=self.outfile)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef csv(self, output):\n        import csv\n        csvwriter = csv.writer(self.outfile)\n        csvwriter.writerows(output)", "response": "Output data as excel - compatible CSV"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\noutputs data in excel - compatible tab - delimited format", "response": "def tab(self, output):\n        \"\"\"Output data in excel-compatible tab-delimited format\"\"\"\n        import csv\n        csvwriter = csv.writer(self.outfile, dialect=csv.excel_tab)\n        csvwriter.writerows(output)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef subcommand(self, command_name=None):\n        def wrapper(decorated):\n            cmd_name = command_name or decorated.__name__\n            subparser = self.subparsers.add_parser(cmd_name,\n                                                   description=decorated.__doc__)\n            for args, kwargs in describe_arguments(decorated):\n                subparser.add_argument(*args, **kwargs)\n            subparser.set_defaults(func=decorated)\n            return decorated\n        return wrapper", "response": "Decorator to add a subcommand to the parser"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndecorates a function that builds a subcommand. Builders should accept a single argument (the subparser instance) and return the function to be run as the command.", "response": "def subcommand_builder(self, command_name, description=None):\n        \"\"\"\n        Decorate a function that builds a subcommand. Builders should accept a\n        single argument (the subparser instance) and return the function to be\n        run as the command.\"\"\"\n        def wrapper(decorated):\n            subparser = self.subparsers.add_parser(command_name)\n            func = decorated(subparser)\n            subparser.set_defaults(func=func)\n            subparser.description = description or func.__doc__\n        return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning cli processing arguments and executing subcommands.", "response": "def run(self):\n        \"Run cli, processing arguments and executing subcommands.\"\n        arguments = self.argument_parser.parse_args()\n        argspec = inspect.getargspec(arguments.func)\n        vargs = []\n        for arg in argspec.args:\n            vargs.append(getattr(arguments, arg))\n        if argspec.varargs:\n            vargs.extend(getattr(arguments, argspec.varargs))\n        output = arguments.func(*vargs)\n        if getattr(arguments.func, '_cli_test_command', False):\n            self.exit_code = 0 if output else 1\n            output = ''\n        if getattr(arguments.func, '_cli_no_output', False):\n            output = ''\n        self.formatter.format_output(output, arguments.format)\n        if charmhelpers.core.unitdata._KV:\n            charmhelpers.core.unitdata._KV.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef collect_authed_hosts(peer_interface):\n    '''Iterate through the units on peer interface to find all that\n    have the calling host in its authorized hosts list'''\n    hosts = []\n    for r_id in (relation_ids(peer_interface) or []):\n        for unit in related_units(r_id):\n            private_addr = relation_get('private-address',\n                                        rid=r_id, unit=unit)\n            authed_hosts = relation_get('ssh_authorized_hosts',\n                                        rid=r_id, unit=unit)\n\n            if not authed_hosts:\n                log('Peer %s has not authorized *any* hosts yet, skipping.' %\n                    (unit), level=INFO)\n                continue\n\n            if unit_private_ip() in authed_hosts.split(':'):\n                hosts.append(private_addr)\n            else:\n                log('Peer %s has not authorized *this* host yet, skipping.' %\n                    (unit), level=INFO)\n    return hosts", "response": "Iterate through the units on peer interface to find all that\n    have the calling host in its authorized hosts list"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sync_to_peers(peer_interface, user, paths=None, verbose=False, cmd=None,\n                  gid=None, fatal=False):\n    \"\"\"Sync all hosts to an specific path\n\n    The type of group is integer, it allows user has permissions to\n    operate a directory have a different group id with the user id.\n\n    Propagates exception if any operation fails and fatal=True.\n    \"\"\"\n    if paths:\n        for host in collect_authed_hosts(peer_interface):\n            sync_to_peer(host, user, paths, verbose, cmd, gid, fatal)", "response": "Sync all hosts to peers"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pip_execute(*args, **kwargs):\n    try:\n        _path = sys.path\n        try:\n            from pip import main as _pip_execute\n        except ImportError:\n            apt_update()\n            if six.PY2:\n                apt_install('python-pip')\n            else:\n                apt_install('python3-pip')\n            from pip import main as _pip_execute\n        _pip_execute(*args, **kwargs)\n    finally:\n        sys.path = _path", "response": "Overriden pip_execute to stop sys. path being changed."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_options(given, available):\n    for key, value in sorted(given.items()):\n        if not value:\n            continue\n        if key in available:\n            yield \"--{0}={1}\".format(key, value)", "response": "Given a set of options check if available"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pip_install_requirements(requirements, constraints=None, **options):\n    command = [\"install\"]\n\n    available_options = ('proxy', 'src', 'log', )\n    for option in parse_options(options, available_options):\n        command.append(option)\n\n    command.append(\"-r {0}\".format(requirements))\n    if constraints:\n        command.append(\"-c {0}\".format(constraints))\n        log(\"Installing from file: {} with constraints {} \"\n            \"and options: {}\".format(requirements, constraints, command))\n    else:\n        log(\"Installing from file: {} with options: {}\".format(requirements,\n                                                               command))\n    pip_execute(command)", "response": "Install a requirements file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninstall a python package", "response": "def pip_install(package, fatal=False, upgrade=False, venv=None,\n                constraints=None, **options):\n    \"\"\"Install a python package\"\"\"\n    if venv:\n        venv_python = os.path.join(venv, 'bin/pip')\n        command = [venv_python, \"install\"]\n    else:\n        command = [\"install\"]\n\n    available_options = ('proxy', 'src', 'log', 'index-url', )\n    for option in parse_options(options, available_options):\n        command.append(option)\n\n    if upgrade:\n        command.append('--upgrade')\n\n    if constraints:\n        command.extend(['-c', constraints])\n\n    if isinstance(package, list):\n        command.extend(package)\n    else:\n        command.append(package)\n\n    log(\"Installing {} package with options: {}\".format(package,\n                                                        command))\n    if venv:\n        subprocess.check_call(command)\n    else:\n        pip_execute(command)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pip_uninstall(package, **options):\n    command = [\"uninstall\", \"-q\", \"-y\"]\n\n    available_options = ('proxy', 'log', )\n    for option in parse_options(options, available_options):\n        command.append(option)\n\n    if isinstance(package, list):\n        command.extend(package)\n    else:\n        command.append(package)\n\n    log(\"Uninstalling {} package with options: {}\".format(package,\n                                                          command))\n    pip_execute(command)", "response": "Uninstall a python package"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pip_create_virtualenv(path=None):\n    if six.PY2:\n        apt_install('python-virtualenv')\n    else:\n        apt_install('python3-virtualenv')\n\n    if path:\n        venv_path = path\n    else:\n        venv_path = os.path.join(charm_dir(), 'venv')\n\n    if not os.path.exists(venv_path):\n        subprocess.check_call(['virtualenv', venv_path])", "response": "Create an isolated Python environment."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef configure_sources(update=False,\n                      sources_var='install_sources',\n                      keys_var='install_keys'):\n    \"\"\"Configure multiple sources from charm configuration.\n\n    The lists are encoded as yaml fragments in the configuration.\n    The fragment needs to be included as a string. Sources and their\n    corresponding keys are of the types supported by add_source().\n\n    Example config:\n        install_sources: |\n          - \"ppa:foo\"\n          - \"http://example.com/repo precise main\"\n        install_keys: |\n          - null\n          - \"a1b2c3d4\"\n\n    Note that 'null' (a.k.a. None) should not be quoted.\n    \"\"\"\n    sources = safe_load((config(sources_var) or '').strip()) or []\n    keys = safe_load((config(keys_var) or '').strip()) or None\n\n    if isinstance(sources, six.string_types):\n        sources = [sources]\n\n    if keys is None:\n        for source in sources:\n            add_source(source, None)\n    else:\n        if isinstance(keys, six.string_types):\n            keys = [keys]\n\n        if len(sources) != len(keys):\n            raise SourceConfigError(\n                'Install sources and keys lists are different lengths')\n        for source, key in zip(sources, keys):\n            add_source(source, key)\n    if update:\n        _fetch_update(fatal=True)", "response": "Configure multiple sources from charm configuration."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninstalling a file tree from a remote source.", "response": "def install_remote(source, *args, **kwargs):\n    \"\"\"Install a file tree from a remote source.\n\n    The specified source should be a url of the form:\n        scheme://[host]/path[#[option=value][&...]]\n\n    Schemes supported are based on this modules submodules.\n    Options supported are submodule-specific.\n    Additional arguments are passed through to the submodule.\n\n    For example::\n\n        dest = install_remote('http://example.com/archive.tgz',\n                              checksum='deadbeef',\n                              hash_type='sha1')\n\n    This will download `archive.tgz`, validate it using SHA1 and, if\n    the file is ok, extract it and return the directory in which it\n    was extracted.  If the checksum fails, it will raise\n    :class:`charmhelpers.core.host.ChecksumError`.\n    \"\"\"\n    # We ONLY check for True here because can_handle may return a string\n    # explaining why it can't handle a given source.\n    handlers = [h for h in plugins() if h.can_handle(source) is True]\n    for handler in handlers:\n        try:\n            return handler.install(source, *args, **kwargs)\n        except UnhandledSource as e:\n            log('Install source attempt unsuccessful: {}'.format(e),\n                level='WARNING')\n    raise UnhandledSource(\"No handler found for source {}\".format(source))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef base_url(self, url):\n        parts = list(self.parse_url(url))\n        parts[4:] = ['' for i in parts[4:]]\n        return urlunparse(parts)", "response": "Return url without querystring or fragment"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_mapped_luks_device(dev):\n    _, dirs, _ = next(os.walk(\n        '/sys/class/block/{}/holders/'\n        .format(os.path.basename(os.path.realpath(dev))))\n    )\n    is_held = len(dirs) > 0\n    return is_held and is_luks_device(dev)", "response": "Determines if a device is a mapped LUKS device"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_block_device(path):\n    '''\n    Confirm device at path is a valid block device node.\n\n    :returns: boolean: True if path is a block device, False if not.\n    '''\n    if not os.path.exists(path):\n        return False\n    return S_ISBLK(os.stat(path).st_mode)", "response": "Checks if a path is a block device node."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef zap_disk(block_device):\n    '''\n    Clear a block device of partition table. Relies on sgdisk, which is\n    installed as pat of the 'gdisk' package in Ubuntu.\n\n    :param block_device: str: Full path of block device to clean.\n    '''\n    # https://github.com/ceph/ceph/commit/fdd7f8d83afa25c4e09aaedd90ab93f3b64a677b\n    # sometimes sgdisk exits non-zero; this is OK, dd will clean up\n    call(['sgdisk', '--zap-all', '--', block_device])\n    call(['sgdisk', '--clear', '--mbrtogpt', '--', block_device])\n    dev_end = check_output(['blockdev', '--getsz',\n                            block_device]).decode('UTF-8')\n    gpt_end = int(dev_end.split()[0]) - 100\n    check_call(['dd', 'if=/dev/zero', 'of=%s' % (block_device),\n                'bs=1M', 'count=1'])\n    check_call(['dd', 'if=/dev/zero', 'of=%s' % (block_device),\n                'bs=512', 'count=100', 'seek=%s' % (gpt_end)])", "response": "Clear a block device of partition table. Relies on sgdisk which is passed in as pat of the gdisk package in Ubuntu."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngives a device path return True if that device is mounted and False otherwise.", "response": "def is_device_mounted(device):\n    '''Given a device path, return True if that device is mounted, and False\n    if it isn't.\n\n    :param device: str: Full path of the device to check.\n    :returns: boolean: True if the path represents a mounted device, False if\n        it doesn't.\n    '''\n    try:\n        out = check_output(['lsblk', '-P', device]).decode('UTF-8')\n    except Exception:\n        return False\n    return bool(re.search(r'MOUNTPOINT=\".+\"', out))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nformats device with XFS filesystem.", "response": "def mkfs_xfs(device, force=False):\n    \"\"\"Format device with XFS filesystem.\n\n    By default this should fail if the device already has a filesystem on it.\n    :param device: Full path to device to format\n    :ptype device: tr\n    :param force: Force operation\n    :ptype: force: boolean\"\"\"\n    cmd = ['mkfs.xfs']\n    if force:\n        cmd.append(\"-f\")\n\n    cmd += ['-i', 'size=1024', device]\n    check_call(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef wait_for_machine(num_machines=1, timeout=300):\n    # You may think this is a hack, and you'd be right. The easiest way\n    # to tell what environment we're working in (LXC vs EC2) is to check\n    # the dns-name of the first machine. If it's localhost we're in LXC\n    # and we can just return here.\n    if get_machine_data()[0]['dns-name'] == 'localhost':\n        return 1, 0\n    start_time = time.time()\n    while True:\n        # Drop the first machine, since it's the Zookeeper and that's\n        # not a machine that we need to wait for. This will only work\n        # for EC2 environments, which is why we return early above if\n        # we're in LXC.\n        machine_data = get_machine_data()\n        non_zookeeper_machines = [\n            machine_data[key] for key in list(machine_data.keys())[1:]]\n        if len(non_zookeeper_machines) >= num_machines:\n            all_machines_running = True\n            for machine in non_zookeeper_machines:\n                if machine.get('instance-state') != 'running':\n                    all_machines_running = False\n                    break\n            if all_machines_running:\n                break\n        if time.time() - start_time >= timeout:\n            raise RuntimeError('timeout waiting for service to start')\n        time.sleep(SLEEP_AMOUNT)\n    return num_machines, time.time() - start_time", "response": "Wait for num_machines machines to come up."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwait for a given service name to come up.", "response": "def wait_for_unit(service_name, timeout=480):\n    \"\"\"Wait `timeout` seconds for a given service name to come up.\"\"\"\n    wait_for_machine(num_machines=1)\n    start_time = time.time()\n    while True:\n        state = unit_info(service_name, 'agent-state')\n        if 'error' in state or state == 'started':\n            break\n        if time.time() - start_time >= timeout:\n            raise RuntimeError('timeout waiting for service to start')\n        time.sleep(SLEEP_AMOUNT)\n    if state != 'started':\n        raise RuntimeError('unit did not start, agent-state: ' + state)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwaiting for a given relation to come up.", "response": "def wait_for_relation(service_name, relation_name, timeout=120):\n    \"\"\"Wait `timeout` seconds for a given relation to come up.\"\"\"\n    start_time = time.time()\n    while True:\n        relation = unit_info(service_name, 'relations').get(relation_name)\n        if relation is not None and relation['state'] == 'up':\n            break\n        if time.time() - start_time >= timeout:\n            raise RuntimeError('timeout waiting for relation to be up')\n        time.sleep(SLEEP_AMOUNT)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ensure_init(path):\n    '''\n    ensure directories leading up to path are importable, omitting\n    parent directory, eg path='/hooks/helpers/foo'/:\n        hooks/\n        hooks/helpers/__init__.py\n        hooks/helpers/foo/__init__.py\n    '''\n    for d, dirs, files in os.walk(os.path.join(*path.split('/')[:2])):\n        _i = os.path.join(d, '__init__.py')\n        if not os.path.exists(_i):\n            logging.info('Adding missing __init__.py: %s' % _i)\n            open(_i, 'wb').close()", "response": "ensure that all the modules in the path are imported"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef service_available(service_name):\n    try:\n        subprocess.check_output(\n            ['service', service_name, 'status'],\n            stderr=subprocess.STDOUT).decode('UTF-8')\n    except subprocess.CalledProcessError as e:\n        return b'unrecognized service' not in e.output\n    else:\n        return True", "response": "Determine whether a system service is available."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef lsb_release():\n    d = {}\n    with open('/etc/lsb-release', 'r') as lsb:\n        for l in lsb:\n            k, v = l.split('=')\n            d[k.strip()] = v.strip()\n    return d", "response": "Return a dict of all the items in the lsb - release file"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cmp_pkgrevno(package, revno, pkgcache=None):\n    import apt_pkg\n    if not pkgcache:\n        from charmhelpers.fetch import apt_cache\n        pkgcache = apt_cache()\n    pkg = pkgcache[package]\n    return apt_pkg.version_compare(pkg.current_ver.ver_str, revno)", "response": "Compare the given package with the given revision number."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef install_salt_support(from_ppa=True):\n    if from_ppa:\n        subprocess.check_call([\n            '/usr/bin/add-apt-repository',\n            '--yes',\n            'ppa:saltstack/salt',\n        ])\n        subprocess.check_call(['/usr/bin/apt-get', 'update'])\n    # We install salt-common as salt-minion would run the salt-minion\n    # daemon.\n    charmhelpers.fetch.apt_install('salt-common')", "response": "Installs the salt - minion helper for machine state."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_machine_state(state_path):\n    charmhelpers.contrib.templating.contexts.juju_state_to_yaml(\n        salt_grains_path)\n    subprocess.check_call([\n        'salt-call',\n        '--local',\n        'state.template',\n        state_path,\n    ])", "response": "Update the machine state using the provided state declaration."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nuse to validate these: http://docs.ceph.com/docs/master/rados/operations/pools/#set-pool-values Example input: validator(value=1, valid_type=int, valid_range=[0, 2]) This says I'm testing value=1. It must be an int inclusive in [0,2] :param value: The value to validate :param valid_type: The type that value should be. :param valid_range: A range of values that value can assume. :return:", "response": "def validator(value, valid_type, valid_range=None):\n    \"\"\"\n    Used to validate these: http://docs.ceph.com/docs/master/rados/operations/pools/#set-pool-values\n    Example input:\n        validator(value=1,\n                  valid_type=int,\n                  valid_range=[0, 2])\n    This says I'm testing value=1.  It must be an int inclusive in [0,2]\n\n    :param value: The value to validate\n    :param valid_type: The type that value should be.\n    :param valid_range: A range of values that value can assume.\n    :return:\n    \"\"\"\n    assert isinstance(value, valid_type), \"{} is not a {}\".format(\n        value,\n        valid_type)\n    if valid_range is not None:\n        assert isinstance(valid_range, list), \\\n            \"valid_range must be a list, was given {}\".format(valid_range)\n        # If we're dealing with strings\n        if isinstance(value, six.string_types):\n            assert value in valid_range, \\\n                \"{} is not in the list {}\".format(value, valid_range)\n        # Integer, float should have a min and max\n        else:\n            if len(valid_range) != 2:\n                raise ValueError(\n                    \"Invalid valid_range list of {} for {}.  \"\n                    \"List must be [min,max]\".format(valid_range, value))\n            assert value >= valid_range[0], \\\n                \"{} is less than minimum allowed value of {}\".format(\n                    value, valid_range[0])\n            assert value <= valid_range[1], \\\n                \"{} is greater than maximum allowed value of {}\".format(\n                    value, valid_range[1])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the current monitor map.", "response": "def get_mon_map(service):\n    \"\"\"\n    Returns the current monitor map.\n    :param service: six.string_types. The Ceph user name to run the command under\n    :return: json string. :raise: ValueError if the monmap fails to parse.\n      Also raises CalledProcessError if our ceph command fails\n    \"\"\"\n    try:\n        mon_status = check_output(['ceph', '--id', service,\n                                   'mon_status', '--format=json'])\n        if six.PY3:\n            mon_status = mon_status.decode('UTF-8')\n        try:\n            return json.loads(mon_status)\n        except ValueError as v:\n            log(\"Unable to parse mon_status json: {}. Error: {}\"\n                .format(mon_status, str(v)))\n            raise\n    except CalledProcessError as e:\n        log(\"mon_status command failed with message: {}\"\n            .format(str(e)))\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of monitor hashes for a given service", "response": "def hash_monitor_names(service):\n    \"\"\"\n    Uses the get_mon_map() function to get information about the monitor\n    cluster.\n    Hash the name of each monitor.  Return a sorted list of monitor hashes\n    in an ascending order.\n    :param service: six.string_types. The Ceph user name to run the command under\n    :rtype : dict.   json dict of monitor name, ip address and rank\n    example: {\n        'name': 'ip-172-31-13-165',\n        'rank': 0,\n        'addr': '172.31.13.165:6789/0'}\n    \"\"\"\n    try:\n        hash_list = []\n        monitor_list = get_mon_map(service=service)\n        if monitor_list['monmap']['mons']:\n            for mon in monitor_list['monmap']['mons']:\n                hash_list.append(\n                    hashlib.sha224(mon['name'].encode('utf-8')).hexdigest())\n            return sorted(hash_list)\n        else:\n            return None\n    except (ValueError, CalledProcessError):\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete a key value pair from the monitor cluster.", "response": "def monitor_key_delete(service, key):\n    \"\"\"\n    Delete a key and value pair from the monitor cluster\n    :param service: six.string_types. The Ceph user name to run the command under\n    Deletes a key value pair on the monitor cluster.\n    :param key: six.string_types.  The key to delete.\n    \"\"\"\n    try:\n        check_output(\n            ['ceph', '--id', service,\n             'config-key', 'del', str(key)])\n    except CalledProcessError as e:\n        log(\"Monitor config-key put failed with message: {}\".format(\n            e.output))\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef monitor_key_set(service, key, value):\n    try:\n        check_output(\n            ['ceph', '--id', service,\n             'config-key', 'put', str(key), str(value)])\n    except CalledProcessError as e:\n        log(\"Monitor config-key put failed with message: {}\".format(\n            e.output))\n        raise", "response": "Sets a key value pair on the monitor cluster."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef monitor_key_get(service, key):\n    try:\n        output = check_output(\n            ['ceph', '--id', service,\n             'config-key', 'get', str(key)]).decode('UTF-8')\n        return output\n    except CalledProcessError as e:\n        log(\"Monitor config-key get failed with message: {}\".format(\n            e.output))\n        return None", "response": "Get the value of an existing key in the monitor cluster."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef monitor_key_exists(service, key):\n    try:\n        check_call(\n            ['ceph', '--id', service,\n             'config-key', 'exists', str(key)])\n        # I can return true here regardless because Ceph returns\n        # ENOENT if the key wasn't found\n        return True\n    except CalledProcessError as e:\n        if e.returncode == errno.ENOENT:\n            return False\n        else:\n            log(\"Unknown error from ceph config-get exists: {} {}\".format(\n                e.returncode, e.output))\n            raise", "response": "Checks if a monitor key exists in the monitor cluster."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the erasure profile for a user.", "response": "def get_erasure_profile(service, name):\n    \"\"\"\n    :param service: six.string_types. The Ceph user name to run the command under\n    :param name:\n    :return:\n    \"\"\"\n    try:\n        out = check_output(['ceph', '--id', service,\n                            'osd', 'erasure-code-profile', 'get',\n                            name, '--format=json'])\n        if six.PY3:\n            out = out.decode('UTF-8')\n        return json.loads(out)\n    except (CalledProcessError, OSError, ValueError):\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pool_set(service, pool_name, key, value):\n    cmd = ['ceph', '--id', service, 'osd', 'pool', 'set', pool_name, key,\n           str(value).lower()]\n    try:\n        check_call(cmd)\n    except CalledProcessError:\n        raise", "response": "Sets a value for a RADOS pool in ceph. Natural order."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_pool_snapshot(service, pool_name, snapshot_name):\n    cmd = ['ceph', '--id', service, 'osd', 'pool', 'rmsnap', pool_name, snapshot_name]\n    try:\n        check_call(cmd)\n    except CalledProcessError:\n        raise", "response": "Remove a snapshot from a RADOS pool in ceph. Namely this is a hack to remove a snapshot from a RADOS pool in ceph. Namely this is a hack to remove a snapshot from a RADOS pool in ceph. Namely this is a hack to remove a snapshot from a RADOS pool in ceph. Namely this is a hack to remove a snapshot from a RADOS pool in ceph. Namely"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_pool_quota(service, pool_name, max_bytes=None, max_objects=None):\n    cmd = ['ceph', '--id', service, 'osd', 'pool', 'set-quota', pool_name]\n    if max_bytes:\n        cmd = cmd + ['max_bytes', str(max_bytes)]\n    if max_objects:\n        cmd = cmd + ['max_objects', str(max_objects)]\n    check_call(cmd)", "response": "Set the quota of a single resource in a Ceph pool."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a new erasure code profile.", "response": "def create_erasure_profile(service, profile_name, erasure_plugin_name='jerasure',\n                           failure_domain='host',\n                           data_chunks=2, coding_chunks=1,\n                           locality=None, durability_estimator=None,\n                           device_class=None):\n    \"\"\"\n    Create a new erasure code profile if one does not already exist for it.  Updates\n    the profile if it exists. Please see http://docs.ceph.com/docs/master/rados/operations/erasure-code-profile/\n    for more details\n    :param service: six.string_types. The Ceph user name to run the command under\n    :param profile_name: six.string_types\n    :param erasure_plugin_name: six.string_types\n    :param failure_domain: six.string_types.  One of ['chassis', 'datacenter', 'host', 'osd', 'pdu', 'pod', 'rack', 'region',\n        'room', 'root', 'row'])\n    :param data_chunks: int\n    :param coding_chunks: int\n    :param locality: int\n    :param durability_estimator: int\n    :param device_class: six.string_types\n    :return: None.  Can raise CalledProcessError\n    \"\"\"\n    # Ensure this failure_domain is allowed by Ceph\n    validator(failure_domain, six.string_types,\n              ['chassis', 'datacenter', 'host', 'osd', 'pdu', 'pod', 'rack', 'region', 'room', 'root', 'row'])\n\n    cmd = ['ceph', '--id', service, 'osd', 'erasure-code-profile', 'set', profile_name,\n           'plugin=' + erasure_plugin_name, 'k=' + str(data_chunks), 'm=' + str(coding_chunks)\n           ]\n    if locality is not None and durability_estimator is not None:\n        raise ValueError(\"create_erasure_profile should be called with k, m and one of l or c but not both.\")\n\n    luminous_or_later = cmp_pkgrevno('ceph-common', '12.0.0') >= 0\n    # failure_domain changed in luminous\n    if luminous_or_later:\n        cmd.append('crush-failure-domain=' + failure_domain)\n    else:\n        cmd.append('ruleset-failure-domain=' + failure_domain)\n\n    # device class new in luminous\n    if luminous_or_later and device_class:\n        cmd.append('crush-device-class={}'.format(device_class))\n    else:\n        log('Skipping device class configuration (ceph < 12.0.0)',\n            level=DEBUG)\n\n    # Add plugin specific information\n    if locality is not None:\n        # For local erasure codes\n        cmd.append('l=' + str(locality))\n    if durability_estimator is not None:\n        # For Shec erasure codes\n        cmd.append('c=' + str(durability_estimator))\n\n    if erasure_profile_exists(service, profile_name):\n        cmd.append('--force')\n\n    try:\n        check_call(cmd)\n    except CalledProcessError:\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rename_pool(service, old_name, new_name):\n    validator(value=old_name, valid_type=six.string_types)\n    validator(value=new_name, valid_type=six.string_types)\n\n    cmd = ['ceph', '--id', service, 'osd', 'pool', 'rename', old_name, new_name]\n    check_call(cmd)", "response": "Rename a Ceph pool from old_name to new_name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef erasure_profile_exists(service, name):\n    validator(value=name, valid_type=six.string_types)\n    try:\n        check_call(['ceph', '--id', service,\n                    'osd', 'erasure-code-profile', 'get',\n                    name])\n        return True\n    except CalledProcessError:\n        return False", "response": "Check to see if an Erasure code profile already exists."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind the current caching mode of the pool_name given.", "response": "def get_cache_mode(service, pool_name):\n    \"\"\"\n    Find the current caching mode of the pool_name given.\n    :param service: six.string_types. The Ceph user name to run the command under\n    :param pool_name: six.string_types\n    :return: int or None\n    \"\"\"\n    validator(value=service, valid_type=six.string_types)\n    validator(value=pool_name, valid_type=six.string_types)\n    out = check_output(['ceph', '--id', service,\n                        'osd', 'dump', '--format=json'])\n    if six.PY3:\n        out = out.decode('UTF-8')\n    try:\n        osd_json = json.loads(out)\n        for pool in osd_json['pools']:\n            if pool['pool_name'] == pool_name:\n                return pool['cache_mode']\n        return None\n    except ValueError:\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks to see if a RADOS pool already exists.", "response": "def pool_exists(service, name):\n    \"\"\"Check to see if a RADOS pool already exists.\"\"\"\n    try:\n        out = check_output(['rados', '--id', service, 'lspools'])\n        if six.PY3:\n            out = out.decode('UTF-8')\n    except CalledProcessError:\n        return False\n\n    return name in out.split()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of all Ceph Object Storage Daemons currently in the cluster.", "response": "def get_osds(service, device_class=None):\n    \"\"\"Return a list of all Ceph Object Storage Daemons currently in the\n    cluster (optionally filtered by storage device class).\n\n    :param device_class: Class of storage device for OSD's\n    :type device_class: str\n    \"\"\"\n    luminous_or_later = cmp_pkgrevno('ceph-common', '12.0.0') >= 0\n    if luminous_or_later and device_class:\n        out = check_output(['ceph', '--id', service,\n                            'osd', 'crush', 'class',\n                            'ls-osd', device_class,\n                            '--format=json'])\n    else:\n        out = check_output(['ceph', '--id', service,\n                            'osd', 'ls',\n                            '--format=json'])\n    if six.PY3:\n        out = out.decode('UTF-8')\n    return json.loads(out)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck to see if a RADOS block device exists.", "response": "def rbd_exists(service, pool, rbd_img):\n    \"\"\"Check to see if a RADOS block device exists.\"\"\"\n    try:\n        out = check_output(['rbd', 'list', '--id',\n                            service, '--pool', pool])\n        if six.PY3:\n            out = out.decode('UTF-8')\n    except CalledProcessError:\n        return False\n\n    return rbd_img in out"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new RADOS block device.", "response": "def create_rbd_image(service, pool, image, sizemb):\n    \"\"\"Create a new RADOS block device.\"\"\"\n    cmd = ['rbd', 'create', image, '--size', str(sizemb), '--id', service,\n           '--pool', pool]\n    check_call(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the app name for the specified pool.", "response": "def set_app_name_for_pool(client, pool, name):\n    \"\"\"\n    Calls `osd pool application enable` for the specified pool name\n\n    :param client: Name of the ceph client to use\n    :type client: str\n    :param pool: Pool to set app name for\n    :type pool: str\n    :param name: app name for the specified pool\n    :type name: str\n\n    :raises: CalledProcessError if ceph call fails\n    \"\"\"\n    if cmp_pkgrevno('ceph-common', '12.0.0') >= 0:\n        cmd = ['ceph', '--id', client, 'osd', 'pool',\n               'application', 'enable', pool, name]\n        check_call(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_pool(service, name, replicas=3, pg_num=None):\n    if pool_exists(service, name):\n        log(\"Ceph pool {} already exists, skipping creation\".format(name),\n            level=WARNING)\n        return\n\n    if not pg_num:\n        # Calculate the number of placement groups based\n        # on upstream recommended best practices.\n        osds = get_osds(service)\n        if osds:\n            pg_num = (len(osds) * 100 // replicas)\n        else:\n            # NOTE(james-page): Default to 200 for older ceph versions\n            # which don't support OSD query from cli\n            pg_num = 200\n\n    cmd = ['ceph', '--id', service, 'osd', 'pool', 'create', name, str(pg_num)]\n    check_call(cmd)\n\n    update_pool(service, name, settings={'size': str(replicas)})", "response": "Create a new RADOS pool."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_key(service, key):\n    keyring = _keyring_path(service)\n    if os.path.exists(keyring):\n        with open(keyring, 'r') as ring:\n            if key in ring.read():\n                log('Ceph keyring exists at %s and has not changed.' % keyring,\n                    level=DEBUG)\n                return\n            log('Updating existing keyring %s.' % keyring, level=DEBUG)\n\n    cmd = ['ceph-authtool', keyring, '--create-keyring',\n           '--name=client.{}'.format(service), '--add-key={}'.format(key)]\n    check_call(cmd)\n    log('Created new ceph keyring at %s.' % keyring, level=DEBUG)", "response": "Adds a key to a keyring. Returns if the key already exists."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting an existing Ceph keyring.", "response": "def delete_keyring(service):\n    \"\"\"Delete an existing Ceph keyring.\"\"\"\n    keyring = _keyring_path(service)\n    if not os.path.exists(keyring):\n        log('Keyring does not exist at %s' % keyring, level=WARNING)\n        return\n\n    os.remove(keyring)\n    log('Deleted ring at %s.' % keyring, level=INFO)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a file containing key.", "response": "def create_key_file(service, key):\n    \"\"\"Create a file containing key.\"\"\"\n    keyfile = _keyfile_path(service)\n    if os.path.exists(keyfile):\n        log('Keyfile exists at %s.' % keyfile, level=WARNING)\n        return\n\n    with open(keyfile, 'w') as fd:\n        fd.write(key)\n\n    log('Created new keyfile at %s.' % keyfile, level=INFO)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_ceph_nodes(relation='ceph'):\n    hosts = []\n    for r_id in relation_ids(relation):\n        for unit in related_units(r_id):\n            hosts.append(relation_get('private-address', unit=unit, rid=r_id))\n\n    return hosts", "response": "Query named relation to determine current nodes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nperforming basic configuration of Ceph.", "response": "def configure(service, key, auth, use_syslog):\n    \"\"\"Perform basic configuration of Ceph.\"\"\"\n    add_key(service, key)\n    create_key_file(service, key)\n    hosts = get_ceph_nodes()\n    with open('/etc/ceph/ceph.conf', 'w') as ceph_conf:\n        ceph_conf.write(CEPH_CONF.format(auth=auth,\n                                         keyring=_keyring_path(service),\n                                         mon_hosts=\",\".join(map(str, hosts)),\n                                         use_syslog=use_syslog))\n    modprobe('rbd')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef image_mapped(name):\n    try:\n        out = check_output(['rbd', 'showmapped'])\n        if six.PY3:\n            out = out.decode('UTF-8')\n    except CalledProcessError:\n        return False\n\n    return name in out", "response": "Determine whether a RADOS block device is mapped locally."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmapping a RADOS block device for local use.", "response": "def map_block_storage(service, pool, image):\n    \"\"\"Map a RADOS block device for local use.\"\"\"\n    cmd = [\n        'rbd',\n        'map',\n        '{}/{}'.format(pool, image),\n        '--user',\n        service,\n        '--secret',\n        _keyfile_path(service),\n    ]\n    check_call(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmaking a new filesystem on the specified block device.", "response": "def make_filesystem(blk_device, fstype='ext4', timeout=10):\n    \"\"\"Make a new filesystem on the specified block device.\"\"\"\n    count = 0\n    e_noent = os.errno.ENOENT\n    while not os.path.exists(blk_device):\n        if count >= timeout:\n            log('Gave up waiting on block device %s' % blk_device,\n                level=ERROR)\n            raise IOError(e_noent, os.strerror(e_noent), blk_device)\n\n        log('Waiting for block device %s to appear' % blk_device,\n            level=DEBUG)\n        count += 1\n        time.sleep(1)\n    else:\n        log('Formatting block device %s as filesystem %s.' %\n            (blk_device, fstype), level=INFO)\n        check_call(['mkfs', '-t', fstype, blk_device])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmigrates data in data_src_dst to blk_device and then remount.", "response": "def place_data_on_block_device(blk_device, data_src_dst):\n    \"\"\"Migrate data in data_src_dst to blk_device and then remount.\"\"\"\n    # mount block device into /mnt\n    mount(blk_device, '/mnt')\n    # copy data to /mnt\n    copy_files(data_src_dst, '/mnt')\n    # umount block device\n    umount('/mnt')\n    # Grab user/group ID's from original source\n    _dir = os.stat(data_src_dst)\n    uid = _dir.st_uid\n    gid = _dir.st_gid\n    # re-mount where the data should originally be\n    # TODO: persist is currently a NO-OP in core.host\n    mount(blk_device, data_src_dst, persist=True)\n    # ensure original ownership of new mount.\n    os.chown(data_src_dst, uid, gid)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ensure_ceph_storage(service, pool, rbd_img, sizemb, mount_point,\n                        blk_device, fstype, system_services=[],\n                        replicas=3):\n    \"\"\"NOTE: This function must only be called from a single service unit for\n    the same rbd_img otherwise data loss will occur.\n\n    Ensures given pool and RBD image exists, is mapped to a block device,\n    and the device is formatted and mounted at the given mount_point.\n\n    If formatting a device for the first time, data existing at mount_point\n    will be migrated to the RBD device before being re-mounted.\n\n    All services listed in system_services will be stopped prior to data\n    migration and restarted when complete.\n    \"\"\"\n    # Ensure pool, RBD image, RBD mappings are in place.\n    if not pool_exists(service, pool):\n        log('Creating new pool {}.'.format(pool), level=INFO)\n        create_pool(service, pool, replicas=replicas)\n\n    if not rbd_exists(service, pool, rbd_img):\n        log('Creating RBD image ({}).'.format(rbd_img), level=INFO)\n        create_rbd_image(service, pool, rbd_img, sizemb)\n\n    if not image_mapped(rbd_img):\n        log('Mapping RBD Image {} as a Block Device.'.format(rbd_img),\n            level=INFO)\n        map_block_storage(service, pool, rbd_img)\n\n    # make file system\n    # TODO: What happens if for whatever reason this is run again and\n    # the data is already in the rbd device and/or is mounted??\n    # When it is mounted already, it will fail to make the fs\n    # XXX: This is really sketchy!  Need to at least add an fstab entry\n    #      otherwise this hook will blow away existing data if its executed\n    #      after a reboot.\n    if not filesystem_mounted(mount_point):\n        make_filesystem(blk_device, fstype)\n\n        for svc in system_services:\n            if service_running(svc):\n                log('Stopping services {} prior to migrating data.'\n                    .format(svc), level=DEBUG)\n                service_stop(svc)\n\n        place_data_on_block_device(blk_device, mount_point)\n\n        for svc in system_services:\n            log('Starting service {} after migrating data.'\n                .format(svc), level=DEBUG)\n            service_start(svc)", "response": "Ensure that the given pool and rbd image exists and is mapped to a block device."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nensuring a ceph keyring is created for a named service and optionally generates user and group ownership.", "response": "def ensure_ceph_keyring(service, user=None, group=None,\n                        relation='ceph', key=None):\n    \"\"\"Ensures a ceph keyring is created for a named service and optionally\n    ensures user and group ownership.\n\n    @returns boolean: Flag to indicate whether a key was successfully written\n                      to disk based on either relation data or a supplied key\n    \"\"\"\n    if not key:\n        for rid in relation_ids(relation):\n            for unit in related_units(rid):\n                key = relation_get('key', rid=rid, unit=unit)\n                if key:\n                    break\n\n    if not key:\n        return False\n\n    add_key(service=service, key=key)\n    keyring = _keyring_path(service)\n    if user and group:\n        check_call(['chown', '%s.%s' % (user, group), keyring])\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_previous_request(rid):\n    request = None\n    broker_req = relation_get(attribute='broker_req', rid=rid,\n                              unit=local_unit())\n    if broker_req:\n        request_data = json.loads(broker_req)\n        request = CephBrokerRq(api_version=request_data['api-version'],\n                               request_id=request_data['request-id'])\n        request.set_ops(request_data['ops'])\n\n    return request", "response": "Return the last ceph broker request sent on a given relation"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_request_states(request, relation='ceph'):\n    complete = []\n    requests = {}\n    for rid in relation_ids(relation):\n        complete = False\n        previous_request = get_previous_request(rid)\n        if request == previous_request:\n            sent = True\n            complete = is_request_complete_for_rid(previous_request, rid)\n        else:\n            sent = False\n            complete = False\n\n        requests[rid] = {\n            'sent': sent,\n            'complete': complete,\n        }\n\n    return requests", "response": "Return a dict of requests per relation id with their corresponding\n       completion state."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_request_sent(request, relation='ceph'):\n    states = get_request_states(request, relation=relation)\n    for rid in states.keys():\n        if not states[rid]['sent']:\n            return False\n\n    return True", "response": "Check to see if a functionally equivalent request has already been sent"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if a given request has been completed on the given relation ID", "response": "def is_request_complete_for_rid(request, rid):\n    \"\"\"Check if a given request has been completed on the given relation\n\n    @param request: A CephBrokerRq object\n    @param rid: Relation ID\n    \"\"\"\n    broker_key = get_broker_rsp_key()\n    for unit in related_units(rid):\n        rdata = relation_get(rid=rid, unit=unit)\n        if rdata.get(broker_key):\n            rsp = CephBrokerRsp(rdata.get(broker_key))\n            if rsp.request_id == request.request_id:\n                if not rsp.exit_code:\n                    return True\n        else:\n            # The remote unit sent no reply targeted at this unit so either the\n            # remote ceph cluster does not support unit targeted replies or it\n            # has not processed our request yet.\n            if rdata.get('broker_rsp'):\n                request_data = json.loads(rdata['broker_rsp'])\n                if request_data.get('request-id'):\n                    log('Ignoring legacy broker_rsp without unit key as remote '\n                        'service supports unit specific replies', level=DEBUG)\n                else:\n                    log('Using legacy broker_rsp as remote service does not '\n                        'supports unit specific replies', level=DEBUG)\n                    rsp = CephBrokerRsp(rdata['broker_rsp'])\n                    if not rsp.exit_code:\n                        return True\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef send_request_if_needed(request, relation='ceph'):\n    if is_request_sent(request, relation=relation):\n        log('Request already sent but not complete, not sending new request',\n            level=DEBUG)\n    else:\n        for rid in relation_ids(relation):\n            log('Sending request {}'.format(request.request_id), level=DEBUG)\n            relation_set(relation_id=rid, broker_req=request.request)", "response": "Send a CephBrokerRq object to all the VISA broker s peers if they are not already sent."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck whether broker action has completed yet.", "response": "def is_broker_action_done(action, rid=None, unit=None):\n    \"\"\"Check whether broker action has completed yet.\n\n    @param action: name of action to be performed\n    @returns True if action complete otherwise False\n    \"\"\"\n    rdata = relation_get(rid, unit) or {}\n    broker_rsp = rdata.get(get_broker_rsp_key())\n    if not broker_rsp:\n        return False\n\n    rsp = CephBrokerRsp(broker_rsp)\n    unit_name = local_unit().partition('/')[2]\n    key = \"unit_{}_ceph_broker_action.{}\".format(unit_name, action)\n    kvstore = kv()\n    val = kvstore.get(key=key)\n    if val and val == rsp.request_id:\n        return True\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mark_broker_action_done(action, rid=None, unit=None):\n    rdata = relation_get(rid, unit) or {}\n    broker_rsp = rdata.get(get_broker_rsp_key())\n    if not broker_rsp:\n        return\n\n    rsp = CephBrokerRsp(broker_rsp)\n    unit_name = local_unit().partition('/')[2]\n    key = \"unit_{}_ceph_broker_action.{}\".format(unit_name, action)\n    kvstore = kv()\n    kvstore.set(key=key, value=rsp.request_id)\n    kvstore.flush()", "response": "Mark action as having been completed."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_cache_tier(self, cache_pool, mode):\n        # Check the input types and values\n        validator(value=cache_pool, valid_type=six.string_types)\n        validator(value=mode, valid_type=six.string_types, valid_range=[\"readonly\", \"writeback\"])\n\n        check_call(['ceph', '--id', self.service, 'osd', 'tier', 'add', self.name, cache_pool])\n        check_call(['ceph', '--id', self.service, 'osd', 'tier', 'cache-mode', cache_pool, mode])\n        check_call(['ceph', '--id', self.service, 'osd', 'tier', 'set-overlay', self.name, cache_pool])\n        check_call(['ceph', '--id', self.service, 'osd', 'pool', 'set', cache_pool, 'hit_set_type', 'bloom'])", "response": "Add a new cache tier to an existing pool."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving a cache tier from the specified cache pool.", "response": "def remove_cache_tier(self, cache_pool):\n        \"\"\"\n        Removes a cache tier from Ceph.  Flushes all dirty objects from writeback pools and waits for that to complete.\n        :param cache_pool: six.string_types.  The cache tier pool name to remove.\n        :return: None\n        \"\"\"\n        # read-only is easy, writeback is much harder\n        mode = get_cache_mode(self.service, cache_pool)\n        if mode == 'readonly':\n            check_call(['ceph', '--id', self.service, 'osd', 'tier', 'cache-mode', cache_pool, 'none'])\n            check_call(['ceph', '--id', self.service, 'osd', 'tier', 'remove', self.name, cache_pool])\n\n        elif mode == 'writeback':\n            pool_forward_cmd = ['ceph', '--id', self.service, 'osd', 'tier',\n                                'cache-mode', cache_pool, 'forward']\n            if cmp_pkgrevno('ceph-common', '10.1') >= 0:\n                # Jewel added a mandatory flag\n                pool_forward_cmd.append('--yes-i-really-mean-it')\n\n            check_call(pool_forward_cmd)\n            # Flush the cache and wait for it to return\n            check_call(['rados', '--id', self.service, '-p', cache_pool, 'cache-flush-evict-all'])\n            check_call(['ceph', '--id', self.service, 'osd', 'tier', 'remove-overlay', self.name])\n            check_call(['ceph', '--id', self.service, 'osd', 'tier', 'remove', self.name, cache_pool])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_pgs(self, pool_size, percent_data=DEFAULT_POOL_WEIGHT,\n                device_class=None):\n        \"\"\"Return the number of placement groups to use when creating the pool.\n\n        Returns the number of placement groups which should be specified when\n        creating the pool. This is based upon the calculation guidelines\n        provided by the Ceph Placement Group Calculator (located online at\n        http://ceph.com/pgcalc/).\n\n        The number of placement groups are calculated using the following:\n\n            (Target PGs per OSD) * (OSD #) * (%Data)\n            ----------------------------------------\n                         (Pool size)\n\n        Per the upstream guidelines, the OSD # should really be considered\n        based on the number of OSDs which are eligible to be selected by the\n        pool. Since the pool creation doesn't specify any of CRUSH set rules,\n        the default rule will be dependent upon the type of pool being\n        created (replicated or erasure).\n\n        This code makes no attempt to determine the number of OSDs which can be\n        selected for the specific rule, rather it is left to the user to tune\n        in the form of 'expected-osd-count' config option.\n\n        :param pool_size: int. pool_size is either the number of replicas for\n            replicated pools or the K+M sum for erasure coded pools\n        :param percent_data: float. the percentage of data that is expected to\n            be contained in the pool for the specific OSD set. Default value\n            is to assume 10% of the data is for this pool, which is a\n            relatively low % of the data but allows for the pg_num to be\n            increased. NOTE: the default is primarily to handle the scenario\n            where related charms requiring pools has not been upgraded to\n            include an update to indicate their relative usage of the pools.\n        :param device_class: str. class of storage to use for basis of pgs\n            calculation; ceph supports nvme, ssd and hdd by default based\n            on presence of devices of each type in the deployment.\n        :return: int.  The number of pgs to use.\n        \"\"\"\n\n        # Note: This calculation follows the approach that is provided\n        # by the Ceph PG Calculator located at http://ceph.com/pgcalc/.\n        validator(value=pool_size, valid_type=int)\n\n        # Ensure that percent data is set to something - even with a default\n        # it can be set to None, which would wreak havoc below.\n        if percent_data is None:\n            percent_data = DEFAULT_POOL_WEIGHT\n\n        # If the expected-osd-count is specified, then use the max between\n        # the expected-osd-count and the actual osd_count\n        osd_list = get_osds(self.service, device_class)\n        expected = config('expected-osd-count') or 0\n\n        if osd_list:\n            if device_class:\n                osd_count = len(osd_list)\n            else:\n                osd_count = max(expected, len(osd_list))\n\n            # Log a message to provide some insight if the calculations claim\n            # to be off because someone is setting the expected count and\n            # there are more OSDs in reality. Try to make a proper guess\n            # based upon the cluster itself.\n            if not device_class and expected and osd_count != expected:\n                log(\"Found more OSDs than provided expected count. \"\n                    \"Using the actual count instead\", INFO)\n        elif expected:\n            # Use the expected-osd-count in older ceph versions to allow for\n            # a more accurate pg calculations\n            osd_count = expected\n        else:\n            # NOTE(james-page): Default to 200 for older ceph versions\n            # which don't support OSD query from cli\n            return LEGACY_PG_COUNT\n\n        percent_data /= 100.0\n        target_pgs_per_osd = config('pgs-per-osd') or DEFAULT_PGS_PER_OSD_TARGET\n        num_pg = (target_pgs_per_osd * osd_count * percent_data) // pool_size\n\n        # NOTE: ensure a sane minimum number of PGS otherwise we don't get any\n        #       reasonable data distribution in minimal OSD configurations\n        if num_pg < DEFAULT_MINIMUM_PGS:\n            num_pg = DEFAULT_MINIMUM_PGS\n\n        # The CRUSH algorithm has a slight optimization for placement groups\n        # with powers of 2 so find the nearest power of 2. If the nearest\n        # power of 2 is more than 25% below the original value, the next\n        # highest value is used. To do this, find the nearest power of 2 such\n        # that 2^n <= num_pg, check to see if its within the 25% tolerance.\n        exponent = math.floor(math.log(num_pg, 2))\n        nearest = 2 ** exponent\n        if (num_pg - nearest) > (num_pg * 0.25):\n            # Choose the next highest power of 2 since the nearest is more\n            # than 25% below the original value.\n            return int(nearest * 2)\n        else:\n            return int(nearest)", "response": "This function returns the number of placement groups required for the given pool size and percentage of data that should be used for the given device class."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_op_request_access_to_group(self, name, namespace=None,\n                                       permission=None, key_name=None,\n                                       object_prefix_permissions=None):\n        \"\"\"\n        Adds the requested permissions to the current service's Ceph key,\n        allowing the key to access only the specified pools or\n        object prefixes. object_prefix_permissions should be a dictionary\n        keyed on the permission with the corresponding value being a list\n        of prefixes to apply that permission to.\n            {\n                'rwx': ['prefix1', 'prefix2'],\n                'class-read': ['prefix3']}\n        \"\"\"\n        self.ops.append({\n            'op': 'add-permissions-to-key', 'group': name,\n            'namespace': namespace,\n            'name': key_name or service_name(),\n            'group-permission': permission,\n            'object-prefix-permissions': object_prefix_permissions})", "response": "Adds the requested permissions to the current Ceph key and the key name of the group."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_op_create_pool(self, name, replica_count=3, pg_num=None,\n                           weight=None, group=None, namespace=None,\n                           app_name=None, max_bytes=None, max_objects=None):\n        \"\"\"DEPRECATED: Use ``add_op_create_replicated_pool()`` or\n                       ``add_op_create_erasure_pool()`` instead.\n        \"\"\"\n        return self.add_op_create_replicated_pool(\n            name, replica_count=replica_count, pg_num=pg_num, weight=weight,\n            group=group, namespace=namespace, app_name=app_name,\n            max_bytes=max_bytes, max_objects=max_objects)", "response": "Deprecated. Use add_op_create_erasure_pool instead."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_op_create_replicated_pool(self, name, replica_count=3, pg_num=None,\n                                      weight=None, group=None, namespace=None,\n                                      app_name=None, max_bytes=None,\n                                      max_objects=None):\n        \"\"\"Adds an operation to create a replicated pool.\n\n        :param name: Name of pool to create\n        :type name: str\n        :param replica_count: Number of copies Ceph should keep of your data.\n        :type replica_count: int\n        :param pg_num: Request specific number of Placement Groups to create\n                       for pool.\n        :type pg_num: int\n        :param weight: The percentage of data that is expected to be contained\n                       in the pool from the total available space on the OSDs.\n                       Used to calculate number of Placement Groups to create\n                       for pool.\n        :type weight: float\n        :param group: Group to add pool to\n        :type group: str\n        :param namespace: Group namespace\n        :type namespace: str\n        :param app_name: (Optional) Tag pool with application name.  Note that\n                         there is certain protocols emerging upstream with\n                         regard to meaningful application names to use.\n                         Examples are ``rbd`` and ``rgw``.\n        :type app_name: str\n        :param max_bytes: Maximum bytes quota to apply\n        :type max_bytes: int\n        :param max_objects: Maximum objects quota to apply\n        :type max_objects: int\n        \"\"\"\n        if pg_num and weight:\n            raise ValueError('pg_num and weight are mutually exclusive')\n\n        self.ops.append({'op': 'create-pool', 'name': name,\n                         'replicas': replica_count, 'pg_num': pg_num,\n                         'weight': weight, 'group': group,\n                         'group-namespace': namespace, 'app-name': app_name,\n                         'max-bytes': max_bytes, 'max-objects': max_objects})", "response": "Adds an operation to create a replicated pool."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd an operation to create an erasure coded pool.", "response": "def add_op_create_erasure_pool(self, name, erasure_profile=None,\n                                   weight=None, group=None, app_name=None,\n                                   max_bytes=None, max_objects=None):\n        \"\"\"Adds an operation to create a erasure coded pool.\n\n        :param name: Name of pool to create\n        :type name: str\n        :param erasure_profile: Name of erasure code profile to use.  If not\n                                set the ceph-mon unit handling the broker\n                                request will set its default value.\n        :type erasure_profile: str\n        :param weight: The percentage of data that is expected to be contained\n                       in the pool from the total available space on the OSDs.\n        :type weight: float\n        :param group: Group to add pool to\n        :type group: str\n        :param app_name: (Optional) Tag pool with application name.  Note that\n                         there is certain protocols emerging upstream with\n                         regard to meaningful application names to use.\n                         Examples are ``rbd`` and ``rgw``.\n        :type app_name: str\n        :param max_bytes: Maximum bytes quota to apply\n        :type max_bytes: int\n        :param max_objects: Maximum objects quota to apply\n        :type max_objects: int\n        \"\"\"\n        self.ops.append({'op': 'create-pool', 'name': name,\n                         'pool-type': 'erasure',\n                         'erasure-profile': erasure_profile,\n                         'weight': weight,\n                         'group': group, 'app-name': app_name,\n                         'max-bytes': max_bytes, 'max-objects': max_objects})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_nagios_unit_name(relation_name='nrpe-external-master'):\n    host_context = get_nagios_hostcontext(relation_name)\n    if host_context:\n        unit = \"%s:%s\" % (host_context, local_unit())\n    else:\n        unit = local_unit()\n    return unit", "response": "Returns the nagios unit name prepended with host_context if needed"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_init_service_checks(nrpe, services, unit_name, immediate_check=True):\n    for svc in services:\n        # Don't add a check for these services from neutron-gateway\n        if svc in ['ext-port', 'os-charm-phy-nic-mtu']:\n            next\n\n        upstart_init = '/etc/init/%s.conf' % svc\n        sysv_init = '/etc/init.d/%s' % svc\n\n        if host.init_is_systemd():\n            nrpe.add_check(\n                shortname=svc,\n                description='process check {%s}' % unit_name,\n                check_cmd='check_systemd.py %s' % svc\n            )\n        elif os.path.exists(upstart_init):\n            nrpe.add_check(\n                shortname=svc,\n                description='process check {%s}' % unit_name,\n                check_cmd='check_upstart_job %s' % svc\n            )\n        elif os.path.exists(sysv_init):\n            cronpath = '/etc/cron.d/nagios-service-check-%s' % svc\n            checkpath = '%s/service-check-%s.txt' % (nrpe.homedir, svc)\n            croncmd = (\n                '/usr/local/lib/nagios/plugins/check_exit_status.pl '\n                '-e -s /etc/init.d/%s status' % svc\n            )\n            cron_file = '*/5 * * * * root %s > %s\\n' % (croncmd, checkpath)\n            f = open(cronpath, 'w')\n            f.write(cron_file)\n            f.close()\n            nrpe.add_check(\n                shortname=svc,\n                description='service check {%s}' % unit_name,\n                check_cmd='check_status_file.py -f %s' % checkpath,\n            )\n            # if /var/lib/nagios doesn't exist open(checkpath, 'w') will fail\n            # (LP: #1670223).\n            if immediate_check and os.path.isdir(nrpe.homedir):\n                f = open(checkpath, 'w')\n                subprocess.call(\n                    croncmd.split(),\n                    stdout=f,\n                    stderr=subprocess.STDOUT\n                )\n                f.close()\n                os.chmod(checkpath, 0o644)", "response": "Add checks for each service in list to check that it is not in sysv init"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncopies the nrpe checks into place orrow", "response": "def copy_nrpe_checks(nrpe_files_dir=None):\n    \"\"\"\n    Copy the nrpe checks into place\n\n    \"\"\"\n    NAGIOS_PLUGINS = '/usr/local/lib/nagios/plugins'\n    if nrpe_files_dir is None:\n        # determine if \"charmhelpers\" is in CHARMDIR or CHARMDIR/hooks\n        for segment in ['.', 'hooks']:\n            nrpe_files_dir = os.path.abspath(os.path.join(\n                os.getenv('CHARM_DIR'),\n                segment,\n                'charmhelpers',\n                'contrib',\n                'openstack',\n                'files'))\n            if os.path.isdir(nrpe_files_dir):\n                break\n        else:\n            raise RuntimeError(\"Couldn't find charmhelpers directory\")\n    if not os.path.exists(NAGIOS_PLUGINS):\n        os.makedirs(NAGIOS_PLUGINS)\n    for fname in glob.glob(os.path.join(nrpe_files_dir, \"check_*\")):\n        if os.path.isfile(fname):\n            shutil.copy2(fname,\n                         os.path.join(NAGIOS_PLUGINS, os.path.basename(fname)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds checks for each service in list", "response": "def add_haproxy_checks(nrpe, unit_name):\n    \"\"\"\n    Add checks for each service in list\n\n    :param NRPE nrpe: NRPE object to add check to\n    :param str unit_name: Unit name to use in check description\n    \"\"\"\n    nrpe.add_check(\n        shortname='haproxy_servers',\n        description='Check HAProxy {%s}' % unit_name,\n        check_cmd='check_haproxy.sh')\n    nrpe.add_check(\n        shortname='haproxy_queue',\n        description='Check HAProxy queue depth {%s}' % unit_name,\n        check_cmd='check_haproxy_queue_depth.sh')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_vaultlocker_conf(context, priority=100):\n    charm_vl_path = \"/var/lib/charm/{}/vaultlocker.conf\".format(\n        hookenv.service_name()\n    )\n    host.mkdir(os.path.dirname(charm_vl_path), perms=0o700)\n    templating.render(source='vaultlocker.conf.j2',\n                      target=charm_vl_path,\n                      context=context, perms=0o600),\n    alternatives.install_alternative('vaultlocker.conf',\n                                     '/etc/vaultlocker/vaultlocker.conf',\n                                     charm_vl_path, priority)", "response": "Write vaultlocker configuration to disk and install alternative"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef vault_relation_complete(backend=None):\n    vault_kv = VaultKVContext(secret_backend=backend or VAULTLOCKER_BACKEND)\n    vault_kv()\n    return vault_kv.complete", "response": "Determine whether vault relation is complete"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve a response - wrapped secret_id from Vault", "response": "def retrieve_secret_id(url, token):\n    \"\"\"Retrieve a response-wrapped secret_id from Vault\n\n    :param url: URL to Vault Server\n    :ptype url: str\n    :param token: One shot Token to use\n    :ptype token: str\n    :returns: secret_id to use for Vault Access\n    :rtype: str\"\"\"\n    import hvac\n    client = hvac.Client(url=url, token=token)\n    response = client._post('/v1/sys/wrapping/unwrap')\n    if response.status_code == 200:\n        data = response.json()\n        return data['data']['secret_id']"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexecutes snap commands. :param commands: List commands :return: Integer exit code", "response": "def _snap_exec(commands):\n    \"\"\"\n    Execute snap commands.\n\n    :param commands: List commands\n    :return: Integer exit code\n    \"\"\"\n    assert type(commands) == list\n\n    retry_count = 0\n    return_code = None\n\n    while return_code is None or return_code == SNAP_NO_LOCK:\n        try:\n            return_code = subprocess.check_call(['snap'] + commands,\n                                                env=os.environ)\n        except subprocess.CalledProcessError as e:\n            retry_count += + 1\n            if retry_count > SNAP_NO_LOCK_RETRY_COUNT:\n                raise CouldNotAcquireLockException(\n                    'Could not aquire lock after {} attempts'\n                    .format(SNAP_NO_LOCK_RETRY_COUNT))\n            return_code = e.returncode\n            log('Snap failed to acquire lock, trying again in {} seconds.'\n                .format(SNAP_NO_LOCK_RETRY_DELAY, level='WARN'))\n            sleep(SNAP_NO_LOCK_RETRY_DELAY)\n\n    return return_code"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef snap_remove(packages, *flags):\n    if type(packages) is not list:\n        packages = [packages]\n\n    flags = list(flags)\n\n    message = 'Removing snap(s) \"%s\"' % ', '.join(packages)\n    if flags:\n        message += ' with options \"%s\"' % ', '.join(flags)\n\n    log(message, level='INFO')\n    return _snap_exec(['remove'] + flags + packages)", "response": "Remove a snap package."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef persistent_modprobe(module):\n    if not os.path.exists('/etc/rc.modules'):\n        open('/etc/rc.modules', 'a')\n        os.chmod('/etc/rc.modules', 111)\n    with open('/etc/rc.modules', 'r+') as modules:\n        if module not in modules.read():\n            modules.write('modprobe %s\\n' % module)", "response": "Load a kernel module and configure for auto - load on reboot."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nvalidating endpoint data. Pick the correct validator based on the OpenStack release.", "response": "def validate_endpoint_data(self, endpoints, admin_port, internal_port,\n                               public_port, expected, openstack_release=None):\n        \"\"\"Validate endpoint data. Pick the correct validator based on\n           OpenStack release. Expected data should be in the v2 format:\n           {\n               'id': id,\n               'region': region,\n               'adminurl': adminurl,\n               'internalurl': internalurl,\n               'publicurl': publicurl,\n               'service_id': service_id}\n\n           \"\"\"\n        validation_function = self.validate_v2_endpoint_data\n        xenial_queens = OPENSTACK_RELEASES_PAIRS.index('xenial_queens')\n        if openstack_release and openstack_release >= xenial_queens:\n            validation_function = self.validate_v3_endpoint_data\n            expected = {\n                'id': expected['id'],\n                'region': expected['region'],\n                'region_id': 'RegionOne',\n                'url': self.valid_url,\n                'interface': self.not_null,\n                'service_id': expected['service_id']}\n        return validation_function(endpoints, admin_port, internal_port,\n                                   public_port, expected)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate endpoint data vs expected endpoint data.", "response": "def validate_v2_endpoint_data(self, endpoints, admin_port, internal_port,\n                                  public_port, expected):\n        \"\"\"Validate endpoint data.\n\n           Validate actual endpoint data vs expected endpoint data. The ports\n           are used to find the matching endpoint.\n           \"\"\"\n        self.log.debug('Validating endpoint data...')\n        self.log.debug('actual: {}'.format(repr(endpoints)))\n        found = False\n        for ep in endpoints:\n            self.log.debug('endpoint: {}'.format(repr(ep)))\n            if (admin_port in ep.adminurl and\n                    internal_port in ep.internalurl and\n                    public_port in ep.publicurl):\n                found = True\n                actual = {'id': ep.id,\n                          'region': ep.region,\n                          'adminurl': ep.adminurl,\n                          'internalurl': ep.internalurl,\n                          'publicurl': ep.publicurl,\n                          'service_id': ep.service_id}\n                ret = self._validate_dict_data(expected, actual)\n                if ret:\n                    return 'unexpected endpoint data - {}'.format(ret)\n\n        if not found:\n            return 'endpoint not found'"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate_v3_endpoint_data(self, endpoints, admin_port, internal_port,\n                                  public_port, expected, expected_num_eps=3):\n        \"\"\"Validate keystone v3 endpoint data.\n\n        Validate the v3 endpoint data which has changed from v2.  The\n        ports are used to find the matching endpoint.\n\n        The new v3 endpoint data looks like:\n\n        [<Endpoint enabled=True,\n                   id=0432655fc2f74d1e9fa17bdaa6f6e60b,\n                   interface=admin,\n                   links={u'self': u'<RESTful URL of this endpoint>'},\n                   region=RegionOne,\n                   region_id=RegionOne,\n                   service_id=17f842a0dc084b928e476fafe67e4095,\n                   url=http://10.5.6.5:9312>,\n         <Endpoint enabled=True,\n                   id=6536cb6cb92f4f41bf22b079935c7707,\n                   interface=admin,\n                   links={u'self': u'<RESTful url of this endpoint>'},\n                   region=RegionOne,\n                   region_id=RegionOne,\n                   service_id=72fc8736fb41435e8b3584205bb2cfa3,\n                   url=http://10.5.6.6:35357/v3>,\n                   ... ]\n        \"\"\"\n        self.log.debug('Validating v3 endpoint data...')\n        self.log.debug('actual: {}'.format(repr(endpoints)))\n        found = []\n        for ep in endpoints:\n            self.log.debug('endpoint: {}'.format(repr(ep)))\n            if ((admin_port in ep.url and ep.interface == 'admin') or\n                    (internal_port in ep.url and ep.interface == 'internal') or\n                    (public_port in ep.url and ep.interface == 'public')):\n                found.append(ep.interface)\n                # note we ignore the links member.\n                actual = {'id': ep.id,\n                          'region': ep.region,\n                          'region_id': ep.region_id,\n                          'interface': self.not_null,\n                          'url': ep.url,\n                          'service_id': ep.service_id, }\n                ret = self._validate_dict_data(expected, actual)\n                if ret:\n                    return 'unexpected endpoint data - {}'.format(ret)\n\n        if len(found) != expected_num_eps:\n            return 'Unexpected number of endpoints found'", "response": "Validate the v3 endpoint data."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts v2 endpoint data into v3.", "response": "def convert_svc_catalog_endpoint_data_to_v3(self, ep_data):\n        \"\"\"Convert v2 endpoint data into v3.\n\n           {\n               'service_name1': [\n                   {\n                       'adminURL': adminURL,\n                       'id': id,\n                       'region': region.\n                       'publicURL': publicURL,\n                       'internalURL': internalURL\n                   }],\n               'service_name2': [\n                   {\n                       'adminURL': adminURL,\n                       'id': id,\n                       'region': region.\n                       'publicURL': publicURL,\n                       'internalURL': internalURL\n                   }],\n           }\n          \"\"\"\n        self.log.warn(\"Endpoint ID and Region ID validation is limited to not \"\n                      \"null checks after v2 to v3 conversion\")\n        for svc in ep_data.keys():\n            assert len(ep_data[svc]) == 1, \"Unknown data format\"\n            svc_ep_data = ep_data[svc][0]\n            ep_data[svc] = [\n                {\n                    'url': svc_ep_data['adminURL'],\n                    'interface': 'admin',\n                    'region': svc_ep_data['region'],\n                    'region_id': self.not_null,\n                    'id': self.not_null},\n                {\n                    'url': svc_ep_data['publicURL'],\n                    'interface': 'public',\n                    'region': svc_ep_data['region'],\n                    'region_id': self.not_null,\n                    'id': self.not_null},\n                {\n                    'url': svc_ep_data['internalURL'],\n                    'interface': 'internal',\n                    'region': svc_ep_data['region'],\n                    'region_id': self.not_null,\n                    'id': self.not_null}]\n        return ep_data"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nvalidates service catalog endpoint data. Pick the correct validator for the OpenStack version.", "response": "def validate_svc_catalog_endpoint_data(self, expected, actual,\n                                           openstack_release=None):\n        \"\"\"Validate service catalog endpoint data. Pick the correct validator\n           for the OpenStack version. Expected data should be in the v2 format:\n           {\n               'service_name1': [\n                   {\n                       'adminURL': adminURL,\n                       'id': id,\n                       'region': region.\n                       'publicURL': publicURL,\n                       'internalURL': internalURL\n                   }],\n               'service_name2': [\n                   {\n                       'adminURL': adminURL,\n                       'id': id,\n                       'region': region.\n                       'publicURL': publicURL,\n                       'internalURL': internalURL\n                   }],\n           }\n\n           \"\"\"\n        validation_function = self.validate_v2_svc_catalog_endpoint_data\n        xenial_queens = OPENSTACK_RELEASES_PAIRS.index('xenial_queens')\n        if openstack_release and openstack_release >= xenial_queens:\n            validation_function = self.validate_v3_svc_catalog_endpoint_data\n            expected = self.convert_svc_catalog_endpoint_data_to_v3(expected)\n        return validation_function(expected, actual)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate_v2_svc_catalog_endpoint_data(self, expected, actual):\n        self.log.debug('Validating service catalog endpoint data...')\n        self.log.debug('actual: {}'.format(repr(actual)))\n        for k, v in six.iteritems(expected):\n            if k in actual:\n                ret = self._validate_dict_data(expected[k][0], actual[k][0])\n                if ret:\n                    return self.endpoint_error(k, ret)\n            else:\n                return \"endpoint {} does not exist\".format(k)\n        return ret", "response": "Validate a list of actual service catalog endpoints vs a list of expected service catalog endpoints."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef validate_v3_svc_catalog_endpoint_data(self, expected, actual):\n        self.log.debug('Validating v3 service catalog endpoint data...')\n        self.log.debug('actual: {}'.format(repr(actual)))\n        for k, v in six.iteritems(expected):\n            if k in actual:\n                l_expected = sorted(v, key=lambda x: x['interface'])\n                l_actual = sorted(actual[k], key=lambda x: x['interface'])\n                if len(l_actual) != len(l_expected):\n                    return (\"endpoint {} has differing number of interfaces \"\n                            \" - expected({}), actual({})\"\n                            .format(k, len(l_expected), len(l_actual)))\n                for i_expected, i_actual in zip(l_expected, l_actual):\n                    self.log.debug(\"checking interface {}\"\n                                   .format(i_expected['interface']))\n                    ret = self._validate_dict_data(i_expected, i_actual)\n                    if ret:\n                        return self.endpoint_error(k, ret)\n            else:\n                return \"endpoint {} does not exist\".format(k)\n        return ret", "response": "Validate the service endpoint data."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nvalidating a list of actual tenant data vs list of expected tenant data.", "response": "def validate_tenant_data(self, expected, actual):\n        \"\"\"Validate tenant data.\n\n           Validate a list of actual tenant data vs list of expected tenant\n           data.\n           \"\"\"\n        self.log.debug('Validating tenant data...')\n        self.log.debug('actual: {}'.format(repr(actual)))\n        for e in expected:\n            found = False\n            for act in actual:\n                a = {'enabled': act.enabled, 'description': act.description,\n                     'name': act.name, 'id': act.id}\n                if e['name'] == a['name']:\n                    found = True\n                    ret = self._validate_dict_data(e, a)\n                    if ret:\n                        return \"unexpected tenant data - {}\".format(ret)\n            if not found:\n                return \"tenant {} does not exist\".format(e['name'])\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate_user_data(self, expected, actual, api_version=None):\n        self.log.debug('Validating user data...')\n        self.log.debug('actual: {}'.format(repr(actual)))\n        for e in expected:\n            found = False\n            for act in actual:\n                if e['name'] == act.name:\n                    a = {'enabled': act.enabled, 'name': act.name,\n                         'email': act.email, 'id': act.id}\n                    if api_version == 3:\n                        a['default_project_id'] = getattr(act,\n                                                          'default_project_id',\n                                                          'none')\n                    else:\n                        a['tenantId'] = act.tenantId\n                    found = True\n                    ret = self._validate_dict_data(e, a)\n                    if ret:\n                        return \"unexpected user data - {}\".format(ret)\n            if not found:\n                return \"user {} does not exist\".format(e['name'])\n        return ret", "response": "Validate a list of actual user data vs a list of expected user data."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nvalidates a list of actual flavors vs a list of expected flavors.", "response": "def validate_flavor_data(self, expected, actual):\n        \"\"\"Validate flavor data.\n\n           Validate a list of actual flavors vs a list of expected flavors.\n           \"\"\"\n        self.log.debug('Validating flavor data...')\n        self.log.debug('actual: {}'.format(repr(actual)))\n        act = [a.name for a in actual]\n        return self._validate_list_data(expected, act)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tenant_exists(self, keystone, tenant):\n        self.log.debug('Checking if tenant exists ({})...'.format(tenant))\n        return tenant in [t.name for t in keystone.tenants.list()]", "response": "Return True if tenant exists."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwaiting until api_version has the expected value.", "response": "def keystone_wait_for_propagation(self, sentry_relation_pairs,\n                                      api_version):\n        \"\"\"Iterate over list of sentry and relation tuples and verify that\n           api_version has the expected value.\n\n        :param sentry_relation_pairs: list of sentry, relation name tuples used\n                                      for monitoring propagation of relation\n                                      data\n        :param api_version: api_version to expect in relation data\n        :returns: None if successful.  Raise on error.\n        \"\"\"\n        for (sentry, relation_name) in sentry_relation_pairs:\n            rel = sentry.relation('identity-service',\n                                  relation_name)\n            self.log.debug('keystone relation data: {}'.format(rel))\n            if rel.get('api_version') != str(api_version):\n                raise Exception(\"api_version not propagated through relation\"\n                                \" data yet ('{}' != '{}').\"\n                                \"\".format(rel.get('api_version'), api_version))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef keystone_configure_api_version(self, sentry_relation_pairs, deployment,\n                                       api_version):\n        \"\"\"Configure preferred-api-version of keystone in deployment and\n           monitor provided list of relation objects for propagation\n           before returning to caller.\n\n        :param sentry_relation_pairs: list of sentry, relation tuples used for\n                                      monitoring propagation of relation data\n        :param deployment: deployment to configure\n        :param api_version: value preferred-api-version will be set to\n        :returns: None if successful.  Raise on error.\n        \"\"\"\n        self.log.debug(\"Setting keystone preferred-api-version: '{}'\"\n                       \"\".format(api_version))\n\n        config = {'preferred-api-version': api_version}\n        deployment.d.configure('keystone', config)\n        deployment._auto_wait_for_status()\n        self.keystone_wait_for_propagation(sentry_relation_pairs, api_version)", "response": "Configure preferred - api - version of keystone in deployment and wait for propagation of relation objects before returning to caller."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nauthenticate admin user with cinder.", "response": "def authenticate_cinder_admin(self, keystone, api_version=2):\n        \"\"\"Authenticates admin user with cinder.\"\"\"\n        self.log.debug('Authenticating cinder admin...')\n        _clients = {\n            1: cinder_client.Client,\n            2: cinder_clientv2.Client}\n        return _clients[api_version](session=keystone.session)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_keystone_session(self, keystone_ip, username, password,\n                             api_version=False, admin_port=False,\n                             user_domain_name=None, domain_name=None,\n                             project_domain_name=None, project_name=None):\n        \"\"\"Return a keystone session object\"\"\"\n        ep = self.get_keystone_endpoint(keystone_ip,\n                                        api_version=api_version,\n                                        admin_port=admin_port)\n        if api_version == 2:\n            auth = v2.Password(\n                username=username,\n                password=password,\n                tenant_name=project_name,\n                auth_url=ep\n            )\n            sess = keystone_session.Session(auth=auth)\n        else:\n            auth = v3.Password(\n                user_domain_name=user_domain_name,\n                username=username,\n                password=password,\n                domain_name=domain_name,\n                project_domain_name=project_domain_name,\n                project_name=project_name,\n                auth_url=ep\n            )\n            sess = keystone_session.Session(auth=auth)\n        return (sess, auth)", "response": "Return a keystone session object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a keystone session object and client object assuming standard settings", "response": "def get_default_keystone_session(self, keystone_sentry,\n                                     openstack_release=None, api_version=2):\n        \"\"\"Return a keystone session object and client object assuming standard\n           default settings\n\n           Example call in amulet tests:\n               self.keystone_session, self.keystone = u.get_default_keystone_session(\n                   self.keystone_sentry,\n                   openstack_release=self._get_openstack_release())\n\n           The session can then be used to auth other clients:\n               neutronclient.Client(session=session)\n               aodh_client.Client(session=session)\n               eyc\n        \"\"\"\n        self.log.debug('Authenticating keystone admin...')\n        # 11 => xenial_queens\n        if api_version == 3 or (openstack_release and openstack_release >= 11):\n            client_class = keystone_client_v3.Client\n            api_version = 3\n        else:\n            client_class = keystone_client.Client\n        keystone_ip = keystone_sentry.info['public-address']\n        session, auth = self.get_keystone_session(\n            keystone_ip,\n            api_version=api_version,\n            username='admin',\n            password='openstack',\n            project_name='admin',\n            user_domain_name='admin_domain',\n            project_domain_name='admin_domain')\n        client = client_class(session=session)\n        # This populates the client.service_catalog\n        client.auth_ref = auth.get_access(session)\n        return session, client"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef authenticate_keystone_admin(self, keystone_sentry, user, password,\n                                    tenant=None, api_version=None,\n                                    keystone_ip=None, user_domain_name=None,\n                                    project_domain_name=None,\n                                    project_name=None):\n        \"\"\"Authenticates admin user with the keystone admin endpoint.\"\"\"\n        self.log.debug('Authenticating keystone admin...')\n        if not keystone_ip:\n            keystone_ip = keystone_sentry.info['public-address']\n\n        # To support backward compatibility usage of this function\n        if not project_name:\n            project_name = tenant\n        if api_version == 3 and not user_domain_name:\n            user_domain_name = 'admin_domain'\n        if api_version == 3 and not project_domain_name:\n            project_domain_name = 'admin_domain'\n        if api_version == 3 and not project_name:\n            project_name = 'admin'\n\n        return self.authenticate_keystone(\n            keystone_ip, user, password,\n            api_version=api_version,\n            user_domain_name=user_domain_name,\n            project_domain_name=project_domain_name,\n            project_name=project_name,\n            admin_port=True)", "response": "Authenticates admin user with the keystone admin endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef authenticate_keystone_user(self, keystone, user, password, tenant):\n        self.log.debug('Authenticating keystone user ({})...'.format(user))\n        ep = keystone.service_catalog.url_for(service_type='identity',\n                                              interface='publicURL')\n        keystone_ip = urlparse.urlparse(ep).hostname\n\n        return self.authenticate_keystone(keystone_ip, user, password,\n                                          project_name=tenant)", "response": "Authenticates a regular user with the keystone public endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nauthenticates admin user with glance.", "response": "def authenticate_glance_admin(self, keystone, force_v1_client=False):\n        \"\"\"Authenticates admin user with glance.\"\"\"\n        self.log.debug('Authenticating glance admin...')\n        ep = keystone.service_catalog.url_for(service_type='image',\n                                              interface='adminURL')\n        if not force_v1_client and keystone.session:\n            return glance_clientv2.Client(\"2\", session=keystone.session)\n        else:\n            return glance_client.Client(ep, token=keystone.auth_token)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nauthenticate the admin user with heat.", "response": "def authenticate_heat_admin(self, keystone):\n        \"\"\"Authenticates the admin user with heat.\"\"\"\n        self.log.debug('Authenticating heat admin...')\n        ep = keystone.service_catalog.url_for(service_type='orchestration',\n                                              interface='publicURL')\n        if keystone.session:\n            return heat_client.Client(endpoint=ep, session=keystone.session)\n        else:\n            return heat_client.Client(endpoint=ep, token=keystone.auth_token)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef authenticate_nova_user(self, keystone, user, password, tenant):\n        self.log.debug('Authenticating nova user ({})...'.format(user))\n        ep = keystone.service_catalog.url_for(service_type='identity',\n                                              interface='publicURL')\n        if keystone.session:\n            return nova_client.Client(NOVA_CLIENT_VERSION,\n                                      session=keystone.session,\n                                      auth_url=ep)\n        elif novaclient.__version__[0] >= \"7\":\n            return nova_client.Client(NOVA_CLIENT_VERSION,\n                                      username=user, password=password,\n                                      project_name=tenant, auth_url=ep)\n        else:\n            return nova_client.Client(NOVA_CLIENT_VERSION,\n                                      username=user, api_key=password,\n                                      project_id=tenant, auth_url=ep)", "response": "Authenticates a regular user with nova - api."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nauthenticates a regular user with swift api.", "response": "def authenticate_swift_user(self, keystone, user, password, tenant):\n        \"\"\"Authenticates a regular user with swift api.\"\"\"\n        self.log.debug('Authenticating swift user ({})...'.format(user))\n        ep = keystone.service_catalog.url_for(service_type='identity',\n                                              interface='publicURL')\n        if keystone.session:\n            return swiftclient.Connection(session=keystone.session)\n        else:\n            return swiftclient.Connection(authurl=ep,\n                                          user=user,\n                                          key=password,\n                                          tenant_name=tenant,\n                                          auth_version='2.0')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_flavor(self, nova, name, ram, vcpus, disk, flavorid=\"auto\",\n                      ephemeral=0, swap=0, rxtx_factor=1.0, is_public=True):\n        \"\"\"Create the specified flavor.\"\"\"\n        try:\n            nova.flavors.find(name=name)\n        except (exceptions.NotFound, exceptions.NoUniqueMatch):\n            self.log.debug('Creating flavor ({})'.format(name))\n            nova.flavors.create(name, ram, vcpus, disk, flavorid,\n                                ephemeral, swap, rxtx_factor, is_public)", "response": "Create the specified flavor."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef glance_create_image(self, glance, image_name, image_url,\n                            download_dir='tests',\n                            hypervisor_type=None,\n                            disk_format='qcow2',\n                            architecture='x86_64',\n                            container_format='bare'):\n        \"\"\"Download an image and upload it to glance, validate its status\n        and return an image object pointer. KVM defaults, can override for\n        LXD.\n\n        :param glance: pointer to authenticated glance api connection\n        :param image_name: display name for new image\n        :param image_url: url to retrieve\n        :param download_dir: directory to store downloaded image file\n        :param hypervisor_type: glance image hypervisor property\n        :param disk_format: glance image disk format\n        :param architecture: glance image architecture property\n        :param container_format: glance image container format\n        :returns: glance image pointer\n        \"\"\"\n        self.log.debug('Creating glance image ({}) from '\n                       '{}...'.format(image_name, image_url))\n\n        # Download image\n        http_proxy = os.getenv('AMULET_HTTP_PROXY')\n        self.log.debug('AMULET_HTTP_PROXY: {}'.format(http_proxy))\n        if http_proxy:\n            proxies = {'http': http_proxy}\n            opener = urllib.FancyURLopener(proxies)\n        else:\n            opener = urllib.FancyURLopener()\n\n        abs_file_name = os.path.join(download_dir, image_name)\n        if not os.path.exists(abs_file_name):\n            opener.retrieve(image_url, abs_file_name)\n\n        # Create glance image\n        glance_properties = {\n            'architecture': architecture,\n        }\n        if hypervisor_type:\n            glance_properties['hypervisor_type'] = hypervisor_type\n        # Create glance image\n        if float(glance.version) < 2.0:\n            with open(abs_file_name) as f:\n                image = glance.images.create(\n                    name=image_name,\n                    is_public=True,\n                    disk_format=disk_format,\n                    container_format=container_format,\n                    properties=glance_properties,\n                    data=f)\n        else:\n            image = glance.images.create(\n                name=image_name,\n                visibility=\"public\",\n                disk_format=disk_format,\n                container_format=container_format)\n            glance.images.upload(image.id, open(abs_file_name, 'rb'))\n            glance.images.update(image.id, **glance_properties)\n\n        # Wait for image to reach active status\n        img_id = image.id\n        ret = self.resource_reaches_status(glance.images, img_id,\n                                           expected_stat='active',\n                                           msg='Image status wait')\n        if not ret:\n            msg = 'Glance image failed to reach expected state.'\n            amulet.raise_status(amulet.FAIL, msg=msg)\n\n        # Re-validate new image\n        self.log.debug('Validating image attributes...')\n        val_img_name = glance.images.get(img_id).name\n        val_img_stat = glance.images.get(img_id).status\n        val_img_cfmt = glance.images.get(img_id).container_format\n        val_img_dfmt = glance.images.get(img_id).disk_format\n\n        if float(glance.version) < 2.0:\n            val_img_pub = glance.images.get(img_id).is_public\n        else:\n            val_img_pub = glance.images.get(img_id).visibility == \"public\"\n\n        msg_attr = ('Image attributes - name:{} public:{} id:{} stat:{} '\n                    'container fmt:{} disk fmt:{}'.format(\n                        val_img_name, val_img_pub, img_id,\n                        val_img_stat, val_img_cfmt, val_img_dfmt))\n\n        if val_img_name == image_name and val_img_stat == 'active' \\\n                and val_img_pub is True and val_img_cfmt == container_format \\\n                and val_img_dfmt == disk_format:\n            self.log.debug(msg_attr)\n        else:\n            msg = ('Image validation failed, {}'.format(msg_attr))\n            amulet.raise_status(amulet.FAIL, msg=msg)\n\n        return image", "response": "Download an image and upload it to glance validate its status and return an image object pointer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndownloading the latest cirros image and upload it to glance validate and return a resource pointer.", "response": "def create_cirros_image(self, glance, image_name, hypervisor_type=None):\n        \"\"\"Download the latest cirros image and upload it to glance,\n        validate and return a resource pointer.\n\n        :param glance: pointer to authenticated glance connection\n        :param image_name: display name for new image\n        :param hypervisor_type: glance image hypervisor property\n        :returns: glance image pointer\n        \"\"\"\n        # /!\\ DEPRECATION WARNING\n        self.log.warn('/!\\\\ DEPRECATION WARNING:  use '\n                      'glance_create_image instead of '\n                      'create_cirros_image.')\n\n        self.log.debug('Creating glance cirros image '\n                       '({})...'.format(image_name))\n\n        # Get cirros image URL\n        http_proxy = os.getenv('AMULET_HTTP_PROXY')\n        self.log.debug('AMULET_HTTP_PROXY: {}'.format(http_proxy))\n        if http_proxy:\n            proxies = {'http': http_proxy}\n            opener = urllib.FancyURLopener(proxies)\n        else:\n            opener = urllib.FancyURLopener()\n\n        f = opener.open('http://download.cirros-cloud.net/version/released')\n        version = f.read().strip()\n        cirros_img = 'cirros-{}-x86_64-disk.img'.format(version)\n        cirros_url = 'http://{}/{}/{}'.format('download.cirros-cloud.net',\n                                              version, cirros_img)\n        f.close()\n\n        return self.glance_create_image(\n            glance,\n            image_name,\n            cirros_url,\n            hypervisor_type=hypervisor_type)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes the specified image.", "response": "def delete_image(self, glance, image):\n        \"\"\"Delete the specified image.\"\"\"\n\n        # /!\\ DEPRECATION WARNING\n        self.log.warn('/!\\\\ DEPRECATION WARNING:  use '\n                      'delete_resource instead of delete_image.')\n        self.log.debug('Deleting glance image ({})...'.format(image))\n        return self.delete_resource(glance.images, image, msg='glance image')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_instance(self, nova, image_name, instance_name, flavor):\n        self.log.debug('Creating instance '\n                       '({}|{}|{})'.format(instance_name, image_name, flavor))\n        image = nova.glance.find_image(image_name)\n        flavor = nova.flavors.find(name=flavor)\n        instance = nova.servers.create(name=instance_name, image=image,\n                                       flavor=flavor)\n\n        count = 1\n        status = instance.status\n        while status != 'ACTIVE' and count < 60:\n            time.sleep(3)\n            instance = nova.servers.get(instance.id)\n            status = instance.status\n            self.log.debug('instance status: {}'.format(status))\n            count += 1\n\n        if status != 'ACTIVE':\n            self.log.error('instance creation timed out')\n            return None\n\n        return instance", "response": "Create the specified instance."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete the specified instance.", "response": "def delete_instance(self, nova, instance):\n        \"\"\"Delete the specified instance.\"\"\"\n\n        # /!\\ DEPRECATION WARNING\n        self.log.warn('/!\\\\ DEPRECATION WARNING:  use '\n                      'delete_resource instead of delete_instance.')\n        self.log.debug('Deleting instance ({})...'.format(instance))\n        return self.delete_resource(nova.servers, instance,\n                                    msg='nova instance')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new keypair or return pointer if it already exists.", "response": "def create_or_get_keypair(self, nova, keypair_name=\"testkey\"):\n        \"\"\"Create a new keypair, or return pointer if it already exists.\"\"\"\n        try:\n            _keypair = nova.keypairs.get(keypair_name)\n            self.log.debug('Keypair ({}) already exists, '\n                           'using it.'.format(keypair_name))\n            return _keypair\n        except Exception:\n            self.log.debug('Keypair ({}) does not exist, '\n                           'creating it.'.format(keypair_name))\n\n        _keypair = nova.keypairs.create(name=keypair_name)\n        return _keypair"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_cinder_volume(self, cinder, vol_name=\"demo-vol\", vol_size=1,\n                             img_id=None, src_vol_id=None, snap_id=None):\n        \"\"\"Create cinder volume, optionally from a glance image, OR\n        optionally as a clone of an existing volume, OR optionally\n        from a snapshot.  Wait for the new volume status to reach\n        the expected status, validate and return a resource pointer.\n\n        :param vol_name: cinder volume display name\n        :param vol_size: size in gigabytes\n        :param img_id: optional glance image id\n        :param src_vol_id: optional source volume id to clone\n        :param snap_id: optional snapshot id to use\n        :returns: cinder volume pointer\n        \"\"\"\n        # Handle parameter input and avoid impossible combinations\n        if img_id and not src_vol_id and not snap_id:\n            # Create volume from image\n            self.log.debug('Creating cinder volume from glance image...')\n            bootable = 'true'\n        elif src_vol_id and not img_id and not snap_id:\n            # Clone an existing volume\n            self.log.debug('Cloning cinder volume...')\n            bootable = cinder.volumes.get(src_vol_id).bootable\n        elif snap_id and not src_vol_id and not img_id:\n            # Create volume from snapshot\n            self.log.debug('Creating cinder volume from snapshot...')\n            snap = cinder.volume_snapshots.find(id=snap_id)\n            vol_size = snap.size\n            snap_vol_id = cinder.volume_snapshots.get(snap_id).volume_id\n            bootable = cinder.volumes.get(snap_vol_id).bootable\n        elif not img_id and not src_vol_id and not snap_id:\n            # Create volume\n            self.log.debug('Creating cinder volume...')\n            bootable = 'false'\n        else:\n            # Impossible combination of parameters\n            msg = ('Invalid method use - name:{} size:{} img_id:{} '\n                   'src_vol_id:{} snap_id:{}'.format(vol_name, vol_size,\n                                                     img_id, src_vol_id,\n                                                     snap_id))\n            amulet.raise_status(amulet.FAIL, msg=msg)\n\n        # Create new volume\n        try:\n            vol_new = cinder.volumes.create(display_name=vol_name,\n                                            imageRef=img_id,\n                                            size=vol_size,\n                                            source_volid=src_vol_id,\n                                            snapshot_id=snap_id)\n            vol_id = vol_new.id\n        except TypeError:\n            vol_new = cinder.volumes.create(name=vol_name,\n                                            imageRef=img_id,\n                                            size=vol_size,\n                                            source_volid=src_vol_id,\n                                            snapshot_id=snap_id)\n            vol_id = vol_new.id\n        except Exception as e:\n            msg = 'Failed to create volume: {}'.format(e)\n            amulet.raise_status(amulet.FAIL, msg=msg)\n\n        # Wait for volume to reach available status\n        ret = self.resource_reaches_status(cinder.volumes, vol_id,\n                                           expected_stat=\"available\",\n                                           msg=\"Volume status wait\")\n        if not ret:\n            msg = 'Cinder volume failed to reach expected state.'\n            amulet.raise_status(amulet.FAIL, msg=msg)\n\n        # Re-validate new volume\n        self.log.debug('Validating volume attributes...')\n        val_vol_name = self._get_cinder_obj_name(cinder.volumes.get(vol_id))\n        val_vol_boot = cinder.volumes.get(vol_id).bootable\n        val_vol_stat = cinder.volumes.get(vol_id).status\n        val_vol_size = cinder.volumes.get(vol_id).size\n        msg_attr = ('Volume attributes - name:{} id:{} stat:{} boot:'\n                    '{} size:{}'.format(val_vol_name, vol_id,\n                                        val_vol_stat, val_vol_boot,\n                                        val_vol_size))\n\n        if val_vol_boot == bootable and val_vol_stat == 'available' \\\n                and val_vol_name == vol_name and val_vol_size == vol_size:\n            self.log.debug(msg_attr)\n        else:\n            msg = ('Volume validation failed, {}'.format(msg_attr))\n            amulet.raise_status(amulet.FAIL, msg=msg)\n\n        return vol_new", "response": "Create a cinder volume."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete_resource(self, resource, resource_id,\n                        msg=\"resource\", max_wait=120):\n        \"\"\"Delete one openstack resource, such as one instance, keypair,\n        image, volume, stack, etc., and confirm deletion within max wait time.\n\n        :param resource: pointer to os resource type, ex:glance_client.images\n        :param resource_id: unique name or id for the openstack resource\n        :param msg: text to identify purpose in logging\n        :param max_wait: maximum wait time in seconds\n        :returns: True if successful, otherwise False\n        \"\"\"\n        self.log.debug('Deleting OpenStack resource '\n                       '{} ({})'.format(resource_id, msg))\n        num_before = len(list(resource.list()))\n        resource.delete(resource_id)\n\n        tries = 0\n        num_after = len(list(resource.list()))\n        while num_after != (num_before - 1) and tries < (max_wait / 4):\n            self.log.debug('{} delete check: '\n                           '{} [{}:{}] {}'.format(msg, tries,\n                                                  num_before,\n                                                  num_after,\n                                                  resource_id))\n            time.sleep(4)\n            num_after = len(list(resource.list()))\n            tries += 1\n\n        self.log.debug('{}:  expected, actual count = {}, '\n                       '{}'.format(msg, num_before - 1, num_after))\n\n        if num_after == (num_before - 1):\n            return True\n        else:\n            self.log.error('{} delete timed out'.format(msg))\n            return False", "response": "Delete one OpenStack resource such as one instance keypair image volume stack etc. and confirm deletion within max wait time."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef resource_reaches_status(self, resource, resource_id,\n                                expected_stat='available',\n                                msg='resource', max_wait=120):\n        \"\"\"Wait for an openstack resources status to reach an\n           expected status within a specified time.  Useful to confirm that\n           nova instances, cinder vols, snapshots, glance images, heat stacks\n           and other resources eventually reach the expected status.\n\n        :param resource: pointer to os resource type, ex: heat_client.stacks\n        :param resource_id: unique id for the openstack resource\n        :param expected_stat: status to expect resource to reach\n        :param msg: text to identify purpose in logging\n        :param max_wait: maximum wait time in seconds\n        :returns: True if successful, False if status is not reached\n        \"\"\"\n\n        tries = 0\n        resource_stat = resource.get(resource_id).status\n        while resource_stat != expected_stat and tries < (max_wait / 4):\n            self.log.debug('{} status check: '\n                           '{} [{}:{}] {}'.format(msg, tries,\n                                                  resource_stat,\n                                                  expected_stat,\n                                                  resource_id))\n            time.sleep(4)\n            resource_stat = resource.get(resource_id).status\n            tries += 1\n\n        self.log.debug('{}:  expected, actual status = {}, '\n                       '{}'.format(msg, resource_stat, expected_stat))\n\n        if resource_stat == expected_stat:\n            return True\n        else:\n            self.log.debug('{} never reached expected status: '\n                           '{}'.format(resource_id, expected_stat))\n            return False", "response": "Wait for an openstack resource to reach expected status within a specified time."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a dict of ceph pools from a single ceph unit", "response": "def get_ceph_pools(self, sentry_unit):\n        \"\"\"Return a dict of ceph pools from a single ceph unit, with\n        pool name as keys, pool id as vals.\"\"\"\n        pools = {}\n        cmd = 'sudo ceph osd lspools'\n        output, code = sentry_unit.run(cmd)\n        if code != 0:\n            msg = ('{} `{}` returned {} '\n                   '{}'.format(sentry_unit.info['unit_name'],\n                               cmd, code, output))\n            amulet.raise_status(amulet.FAIL, msg=msg)\n\n        # For mimic ceph osd lspools output\n        output = output.replace(\"\\n\", \",\")\n\n        # Example output: 0 data,1 metadata,2 rbd,3 cinder,4 glance,\n        for pool in str(output).split(','):\n            pool_id_name = pool.split(' ')\n            if len(pool_id_name) == 2:\n                pool_id = pool_id_name[0]\n                pool_name = pool_id_name[1]\n                pools[pool_name] = int(pool_id)\n\n        self.log.debug('Pools on {}: {}'.format(sentry_unit.info['unit_name'],\n                                                pools))\n        return pools"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning dict of ceph df json output including ceph pool state.", "response": "def get_ceph_df(self, sentry_unit):\n        \"\"\"Return dict of ceph df json output, including ceph pool state.\n\n        :param sentry_unit: Pointer to amulet sentry instance (juju unit)\n        :returns: Dict of ceph df output\n        \"\"\"\n        cmd = 'sudo ceph df --format=json'\n        output, code = sentry_unit.run(cmd)\n        if code != 0:\n            msg = ('{} `{}` returned {} '\n                   '{}'.format(sentry_unit.info['unit_name'],\n                               cmd, code, output))\n            amulet.raise_status(amulet.FAIL, msg=msg)\n        return json.loads(output)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_ceph_pool_sample(self, sentry_unit, pool_id=0):\n        df = self.get_ceph_df(sentry_unit)\n        for pool in df['pools']:\n            if pool['id'] == pool_id:\n                pool_name = pool['name']\n                obj_count = pool['stats']['objects']\n                kb_used = pool['stats']['kb_used']\n\n        self.log.debug('Ceph {} pool (ID {}): {} objects, '\n                       '{} kb used'.format(pool_name, pool_id,\n                                           obj_count, kb_used))\n        return pool_name, obj_count, kb_used", "response": "Take a sample of attributes of a ceph pool returning the pool name object count and disk space used for the specified pool ID number."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate_ceph_pool_samples(self, samples, sample_type=\"resource pool\"):\n        original, created, deleted = range(3)\n        if samples[created] <= samples[original] or \\\n                samples[deleted] >= samples[created]:\n            return ('Ceph {} samples ({}) '\n                    'unexpected.'.format(sample_type, samples))\n        else:\n            self.log.debug('Ceph {} samples (OK): '\n                           '{}'.format(sample_type, samples))\n            return None", "response": "Validate ceph pool samples taken over time."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwaiting for rmq units extended status to show cluster readiness.", "response": "def rmq_wait_for_cluster(self, deployment, init_sleep=15, timeout=1200):\n        \"\"\"Wait for rmq units extended status to show cluster readiness,\n        after an optional initial sleep period.  Initial sleep is likely\n        necessary to be effective following a config change, as status\n        message may not instantly update to non-ready.\"\"\"\n\n        if init_sleep:\n            time.sleep(init_sleep)\n\n        message = re.compile('^Unit is ready and clustered$')\n        deployment._auto_wait_for_status(message=message,\n                                         timeout=timeout,\n                                         include_only=['rabbitmq-server'])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexecute rabbitmq cluster status command on a unit and return the full output.", "response": "def get_rmq_cluster_status(self, sentry_unit):\n        \"\"\"Execute rabbitmq cluster status command on a unit and return\n        the full output.\n\n        :param unit: sentry unit\n        :returns: String containing console output of cluster status command\n        \"\"\"\n        cmd = 'rabbitmqctl cluster_status'\n        output, _ = self.run_cmd_unit(sentry_unit, cmd)\n        self.log.debug('{} cluster_status:\\n{}'.format(\n            sentry_unit.info['unit_name'], output))\n        return str(output)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses rabbitmqctl cluster_status output string return list of running rabbitmq cluster nodes.", "response": "def get_rmq_cluster_running_nodes(self, sentry_unit):\n        \"\"\"Parse rabbitmqctl cluster_status output string, return list of\n        running rabbitmq cluster nodes.\n\n        :param unit: sentry unit\n        :returns: List containing node names of running nodes\n        \"\"\"\n        # NOTE(beisner): rabbitmqctl cluster_status output is not\n        # json-parsable, do string chop foo, then json.loads that.\n        str_stat = self.get_rmq_cluster_status(sentry_unit)\n        if 'running_nodes' in str_stat:\n            pos_start = str_stat.find(\"{running_nodes,\") + 15\n            pos_end = str_stat.find(\"]},\", pos_start) + 1\n            str_run_nodes = str_stat[pos_start:pos_end].replace(\"'\", '\"')\n            run_nodes = json.loads(str_run_nodes)\n            return run_nodes\n        else:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck that all rmq unit hostnames are represented in the cluster_status output of all units.", "response": "def validate_rmq_cluster_running_nodes(self, sentry_units):\n        \"\"\"Check that all rmq unit hostnames are represented in the\n        cluster_status output of all units.\n\n        :param host_names: dict of juju unit names to host names\n        :param units: list of sentry unit pointers (all rmq units)\n        :returns: None if successful, otherwise return error message\n        \"\"\"\n        host_names = self.get_unit_hostnames(sentry_units)\n        errors = []\n\n        # Query every unit for cluster_status running nodes\n        for query_unit in sentry_units:\n            query_unit_name = query_unit.info['unit_name']\n            running_nodes = self.get_rmq_cluster_running_nodes(query_unit)\n\n            # Confirm that every unit is represented in the queried unit's\n            # cluster_status running nodes output.\n            for validate_unit in sentry_units:\n                val_host_name = host_names[validate_unit.info['unit_name']]\n                val_node_name = 'rabbit@{}'.format(val_host_name)\n\n                if val_node_name not in running_nodes:\n                    errors.append('Cluster member check failed on {}: {} not '\n                                  'in {}\\n'.format(query_unit_name,\n                                                   val_node_name,\n                                                   running_nodes))\n        if errors:\n            return ''.join(errors)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rmq_ssl_is_enabled_on_unit(self, sentry_unit, port=None):\n        host = sentry_unit.info['public-address']\n        unit_name = sentry_unit.info['unit_name']\n\n        conf_file = '/etc/rabbitmq/rabbitmq.config'\n        conf_contents = str(self.file_contents_safe(sentry_unit,\n                                                    conf_file, max_wait=16))\n        # Checks\n        conf_ssl = 'ssl' in conf_contents\n        conf_port = str(port) in conf_contents\n\n        # Port explicitly checked in config\n        if port and conf_port and conf_ssl:\n            self.log.debug('SSL is enabled  @{}:{} '\n                           '({})'.format(host, port, unit_name))\n            return True\n        elif port and not conf_port and conf_ssl:\n            self.log.debug('SSL is enabled @{} but not on port {} '\n                           '({})'.format(host, port, unit_name))\n            return False\n        # Port not checked (useful when checking that ssl is disabled)\n        elif not port and conf_ssl:\n            self.log.debug('SSL is enabled  @{}:{} '\n                           '({})'.format(host, port, unit_name))\n            return True\n        elif not conf_ssl:\n            self.log.debug('SSL not enabled @{}:{} '\n                           '({})'.format(host, port, unit_name))\n            return False\n        else:\n            msg = ('Unknown condition when checking SSL status @{}:{} '\n                   '({})'.format(host, port, unit_name))\n            amulet.raise_status(amulet.FAIL, msg)", "response": "Check a single juju rmq unit for ssl and port in the config file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking that ssl is enabled on rmq juju sentry units.", "response": "def validate_rmq_ssl_enabled_units(self, sentry_units, port=None):\n        \"\"\"Check that ssl is enabled on rmq juju sentry units.\n\n        :param sentry_units: list of all rmq sentry units\n        :param port: optional ssl port override to validate\n        :returns: None if successful, otherwise return error message\n        \"\"\"\n        for sentry_unit in sentry_units:\n            if not self.rmq_ssl_is_enabled_on_unit(sentry_unit, port=port):\n                return ('Unexpected condition:  ssl is disabled on unit '\n                        '({})'.format(sentry_unit.info['unit_name']))\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef validate_rmq_ssl_disabled_units(self, sentry_units):\n        for sentry_unit in sentry_units:\n            if self.rmq_ssl_is_enabled_on_unit(sentry_unit):\n                return ('Unexpected condition:  ssl is enabled on unit '\n                        '({})'.format(sentry_unit.info['unit_name']))\n        return None", "response": "Check that ssl is enabled on all rmq juju sentry units."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nturn ssl charm config option on with optional non - default ssl port specification.", "response": "def configure_rmq_ssl_on(self, sentry_units, deployment,\n                             port=None, max_wait=60):\n        \"\"\"Turn ssl charm config option on, with optional non-default\n        ssl port specification.  Confirm that it is enabled on every\n        unit.\n\n        :param sentry_units: list of sentry units\n        :param deployment: amulet deployment object pointer\n        :param port: amqp port, use defaults if None\n        :param max_wait: maximum time to wait in seconds to confirm\n        :returns: None if successful.  Raise on error.\n        \"\"\"\n        self.log.debug('Setting ssl charm config option:  on')\n\n        # Enable RMQ SSL\n        config = {'ssl': 'on'}\n        if port:\n            config['ssl_port'] = port\n\n        deployment.d.configure('rabbitmq-server', config)\n\n        # Wait for unit status\n        self.rmq_wait_for_cluster(deployment)\n\n        # Confirm\n        tries = 0\n        ret = self.validate_rmq_ssl_enabled_units(sentry_units, port=port)\n        while ret and tries < (max_wait / 4):\n            time.sleep(4)\n            self.log.debug('Attempt {}: {}'.format(tries, ret))\n            ret = self.validate_rmq_ssl_enabled_units(sentry_units, port=port)\n            tries += 1\n\n        if ret:\n            amulet.raise_status(amulet.FAIL, ret)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef configure_rmq_ssl_off(self, sentry_units, deployment, max_wait=60):\n        self.log.debug('Setting ssl charm config option:  off')\n\n        # Disable RMQ SSL\n        config = {'ssl': 'off'}\n        deployment.d.configure('rabbitmq-server', config)\n\n        # Wait for unit status\n        self.rmq_wait_for_cluster(deployment)\n\n        # Confirm\n        tries = 0\n        ret = self.validate_rmq_ssl_disabled_units(sentry_units)\n        while ret and tries < (max_wait / 4):\n            time.sleep(4)\n            self.log.debug('Attempt {}: {}'.format(tries, ret))\n            ret = self.validate_rmq_ssl_disabled_units(sentry_units)\n            tries += 1\n\n        if ret:\n            amulet.raise_status(amulet.FAIL, ret)", "response": "Turn ssl charm config option off confirm that it is disabled\n        on every unit."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef connect_amqp_by_unit(self, sentry_unit, ssl=False,\n                             port=None, fatal=True,\n                             username=\"testuser1\", password=\"changeme\"):\n        \"\"\"Establish and return a pika amqp connection to the rabbitmq service\n        running on a rmq juju unit.\n\n        :param sentry_unit: sentry unit pointer\n        :param ssl: boolean, default to False\n        :param port: amqp port, use defaults if None\n        :param fatal: boolean, default to True (raises on connect error)\n        :param username: amqp user name, default to testuser1\n        :param password: amqp user password\n        :returns: pika amqp connection pointer or None if failed and non-fatal\n        \"\"\"\n        host = sentry_unit.info['public-address']\n        unit_name = sentry_unit.info['unit_name']\n\n        # Default port logic if port is not specified\n        if ssl and not port:\n            port = 5671\n        elif not ssl and not port:\n            port = 5672\n\n        self.log.debug('Connecting to amqp on {}:{} ({}) as '\n                       '{}...'.format(host, port, unit_name, username))\n\n        try:\n            credentials = pika.PlainCredentials(username, password)\n            parameters = pika.ConnectionParameters(host=host, port=port,\n                                                   credentials=credentials,\n                                                   ssl=ssl,\n                                                   connection_attempts=3,\n                                                   retry_delay=5,\n                                                   socket_timeout=1)\n            connection = pika.BlockingConnection(parameters)\n            assert connection.is_open is True\n            assert connection.is_closing is False\n            self.log.debug('Connect OK')\n            return connection\n        except Exception as e:\n            msg = ('amqp connection failed to {}:{} as '\n                   '{} ({})'.format(host, port, username, str(e)))\n            if fatal:\n                amulet.raise_status(amulet.FAIL, msg)\n            else:\n                self.log.warn(msg)\n                return None", "response": "Establish and return a pika amqp connection to a rabbitmq service unit."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npublishes an amqp message to a rmq juju unit.", "response": "def publish_amqp_message_by_unit(self, sentry_unit, message,\n                                     queue=\"test\", ssl=False,\n                                     username=\"testuser1\",\n                                     password=\"changeme\",\n                                     port=None):\n        \"\"\"Publish an amqp message to a rmq juju unit.\n\n        :param sentry_unit: sentry unit pointer\n        :param message: amqp message string\n        :param queue: message queue, default to test\n        :param username: amqp user name, default to testuser1\n        :param password: amqp user password\n        :param ssl: boolean, default to False\n        :param port: amqp port, use defaults if None\n        :returns: None.  Raises exception if publish failed.\n        \"\"\"\n        self.log.debug('Publishing message to {} queue:\\n{}'.format(queue,\n                                                                    message))\n        connection = self.connect_amqp_by_unit(sentry_unit, ssl=ssl,\n                                               port=port,\n                                               username=username,\n                                               password=password)\n\n        # NOTE(beisner): extra debug here re: pika hang potential:\n        #   https://github.com/pika/pika/issues/297\n        #   https://groups.google.com/forum/#!topic/rabbitmq-users/Ja0iyfF0Szw\n        self.log.debug('Defining channel...')\n        channel = connection.channel()\n        self.log.debug('Declaring queue...')\n        channel.queue_declare(queue=queue, auto_delete=False, durable=True)\n        self.log.debug('Publishing message...')\n        channel.basic_publish(exchange='', routing_key=queue, body=message)\n        self.log.debug('Closing channel...')\n        channel.close()\n        self.log.debug('Closing connection...')\n        connection.close()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_amqp_message_by_unit(self, sentry_unit, queue=\"test\",\n                                 username=\"testuser1\",\n                                 password=\"changeme\",\n                                 ssl=False, port=None):\n        \"\"\"Get an amqp message from a rmq juju unit.\n\n        :param sentry_unit: sentry unit pointer\n        :param queue: message queue, default to test\n        :param username: amqp user name, default to testuser1\n        :param password: amqp user password\n        :param ssl: boolean, default to False\n        :param port: amqp port, use defaults if None\n        :returns: amqp message body as string.  Raise if get fails.\n        \"\"\"\n        connection = self.connect_amqp_by_unit(sentry_unit, ssl=ssl,\n                                               port=port,\n                                               username=username,\n                                               password=password)\n        channel = connection.channel()\n        method_frame, _, body = channel.basic_get(queue)\n\n        if method_frame:\n            self.log.debug('Retreived message from {} queue:\\n{}'.format(queue,\n                                                                         body))\n            channel.basic_ack(method_frame.delivery_tag)\n            channel.close()\n            connection.close()\n            return body\n        else:\n            msg = 'No message retrieved.'\n            amulet.raise_status(amulet.FAIL, msg)", "response": "Get an amqp message from a rmq juju unit."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks that memcache is running and is configured and is configured to be used.", "response": "def validate_memcache(self, sentry_unit, conf, os_release,\n                          earliest_release=5, section='keystone_authtoken',\n                          check_kvs=None):\n        \"\"\"Check Memcache is running and is configured to be used\n\n        Example call from Amulet test:\n\n            def test_110_memcache(self):\n                u.validate_memcache(self.neutron_api_sentry,\n                                    '/etc/neutron/neutron.conf',\n                                    self._get_openstack_release())\n\n        :param sentry_unit: sentry unit\n        :param conf: OpenStack config file to check memcache settings\n        :param os_release: Current OpenStack release int code\n        :param earliest_release: Earliest Openstack release to check int code\n        :param section: OpenStack config file section to check\n        :param check_kvs: Dict of settings to check in config file\n        :returns: None\n        \"\"\"\n        if os_release < earliest_release:\n            self.log.debug('Skipping memcache checks for deployment. {} <'\n                           'mitaka'.format(os_release))\n            return\n        _kvs = check_kvs or {'memcached_servers': 'inet6:[::1]:11211'}\n        self.log.debug('Checking memcached is running')\n        ret = self.validate_services_by_name({sentry_unit: ['memcached']})\n        if ret:\n            amulet.raise_status(amulet.FAIL, msg='Memcache running check'\n                                'failed {}'.format(ret))\n        else:\n            self.log.debug('OK')\n        self.log.debug('Checking memcache url is configured in {}'.format(\n            conf))\n        if self.validate_config_data(sentry_unit, conf, section, _kvs):\n            message = \"Memcache config error in: {}\".format(conf)\n            amulet.raise_status(amulet.FAIL, msg=message)\n        else:\n            self.log.debug('OK')\n        self.log.debug('Checking memcache configuration in '\n                       '/etc/memcached.conf')\n        contents = self.file_contents_safe(sentry_unit, '/etc/memcached.conf',\n                                           fatal=True)\n        ubuntu_release, _ = self.run_cmd_unit(sentry_unit, 'lsb_release -cs')\n        if CompareHostReleases(ubuntu_release) <= 'trusty':\n            memcache_listen_addr = 'ip6-localhost'\n        else:\n            memcache_listen_addr = '::1'\n        expected = {\n            '-p': '11211',\n            '-l': memcache_listen_addr}\n        found = []\n        for key, value in expected.items():\n            for line in contents.split('\\n'):\n                if line.startswith(key):\n                    self.log.debug('Checking {} is set to {}'.format(\n                        key,\n                        value))\n                    assert value == line.split()[-1]\n                    self.log.debug(line.split()[-1])\n                    found.append(key)\n        if sorted(found) == sorted(expected.keys()):\n            self.log.debug('OK')\n        else:\n            message = \"Memcache config error in: /etc/memcached.conf\"\n            amulet.raise_status(amulet.FAIL, msg=message)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nacquire the named lock non - blocking.", "response": "def acquire(self, lock):\n        '''Acquire the named lock, non-blocking.\n\n        The lock may be granted immediately, or in a future hook.\n\n        Returns True if the lock has been granted. The lock will be\n        automatically released at the end of the hook in which it is\n        granted.\n\n        Do not mindlessly call this method, as it triggers a cascade of\n        hooks. For example, if you call acquire() every time in your\n        peers relation-changed hook you will end up with an infinite loop\n        of hooks. It should almost always be guarded by some condition.\n        '''\n        unit = hookenv.local_unit()\n        ts = self.requests[unit].get(lock)\n        if not ts:\n            # If there is no outstanding request on the peers relation,\n            # create one.\n            self.requests.setdefault(lock, {})\n            self.requests[unit][lock] = _timestamp()\n            self.msg('Requested {}'.format(lock))\n\n        # If the leader has granted the lock, yay.\n        if self.granted(lock):\n            self.msg('Acquired {}'.format(lock))\n            return True\n\n        # If the unit making the request also happens to be the\n        # leader, it must handle the request now. Even though the\n        # request has been stored on the peers relation, the peers\n        # relation-changed hook will not be triggered.\n        if hookenv.is_leader():\n            return self.grant(lock, unit)\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if a previously requested lock has been granted", "response": "def granted(self, lock):\n        '''Return True if a previously requested lock has been granted'''\n        unit = hookenv.local_unit()\n        ts = self.requests[unit].get(lock)\n        if ts and self.grants.get(unit, {}).get(lock) == ts:\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef request_timestamp(self, lock):\n        '''Return the timestamp of our outstanding request for lock, or None.\n\n        Returns a datetime.datetime() UTC timestamp, with no tzinfo attribute.\n        '''\n        ts = self.requests[hookenv.local_unit()].get(lock, None)\n        if ts is not None:\n            return datetime.strptime(ts, _timestamp_format)", "response": "Return the timestamp of our outstanding request for lock or None."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef grant(self, lock, unit):\n        '''Maybe grant the lock to a unit.\n\n        The decision to grant the lock or not is made for $lock\n        by a corresponding method grant_$lock, which you may define\n        in a subclass. If no such method is defined, the default_grant\n        method is used. See Serial.default_grant() for details.\n        '''\n        if not hookenv.is_leader():\n            return False  # Not the leader, so we cannot grant.\n\n        # Set of units already granted the lock.\n        granted = set()\n        for u in self.grants:\n            if lock in self.grants[u]:\n                granted.add(u)\n        if unit in granted:\n            return True  # Already granted.\n\n        # Ordered list of units waiting for the lock.\n        reqs = set()\n        for u in self.requests:\n            if u in granted:\n                continue  # In the granted set. Not wanted in the req list.\n            for _lock, ts in self.requests[u].items():\n                if _lock == lock:\n                    reqs.add((ts, u))\n        queue = [t[1] for t in sorted(reqs)]\n        if unit not in queue:\n            return False  # Unit has not requested the lock.\n\n        # Locate custom logic, or fallback to the default.\n        grant_func = getattr(self, 'grant_{}'.format(lock), self.default_grant)\n\n        if grant_func(lock, unit, granted, queue):\n            # Grant the lock.\n            self.msg('Leader grants {} to {}'.format(lock, unit))\n            self.grants.setdefault(unit, {})[lock] = self.requests[unit][lock]\n            return True\n\n        return False", "response": "Grant the lock to a unit."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalling on the leader when it has released a lock.", "response": "def released(self, unit, lock, timestamp):\n        '''Called on the leader when it has released a lock.\n\n        By default, does nothing but log messages. Override if you\n        need to perform additional housekeeping when a lock is released,\n        for example recording timestamps.\n        '''\n        interval = _utcnow() - timestamp\n        self.msg('Leader released {} from {}, held {}'.format(lock, unit,\n                                                              interval))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef require(self, lock, guard_func, *guard_args, **guard_kw):\n        def decorator(f):\n            @wraps(f)\n            def wrapper(*args, **kw):\n                if self.granted(lock):\n                    self.msg('Granted {}'.format(lock))\n                    return f(*args, **kw)\n                if guard_func(*guard_args, **guard_kw) and self.acquire(lock):\n                    return f(*args, **kw)\n                return None\n            return wrapper\n        return decorator", "response": "Decorator to be used only when a lock is granted."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nemits a message. Override to customize log spam.", "response": "def msg(self, msg):\n        '''Emit a message. Override to customize log spam.'''\n        hookenv.log('coordinator.{} {}'.format(self._name(), msg),\n                    level=hookenv.INFO)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a deprecation warning to the order of the functions in the order they were added.", "response": "def deprecate(warning, date=None, log=None):\n    \"\"\"Add a deprecation warning the first time the function is used.\n    The date, which is a string in semi-ISO8660 format indicate the year-month\n    that the function is officially going to be removed.\n\n    usage:\n\n    @deprecate('use core/fetch/add_source() instead', '2017-04')\n    def contributed_add_source_thing(...):\n        ...\n\n    And it then prints to the log ONCE that the function is deprecated.\n    The reason for passing the logging function (log) is so that hookenv.log\n    can be used for a charm if needed.\n\n    :param warning:  String to indicat where it has moved ot.\n    :param date: optional sting, in YYYY-MM format to indicate when the\n                 function will definitely (probably) be removed.\n    :param log: The log function to call to log.  If not, logs to stdout\n    \"\"\"\n    def wrap(f):\n\n        @functools.wraps(f)\n        def wrapped_f(*args, **kwargs):\n            try:\n                module = inspect.getmodule(f)\n                file = inspect.getsourcefile(f)\n                lines = inspect.getsourcelines(f)\n                f_name = \"{}-{}-{}..{}-{}\".format(\n                    module.__name__, file, lines[0], lines[-1], f.__name__)\n            except (IOError, TypeError):\n                # assume it was local, so just use the name of the function\n                f_name = f.__name__\n            if f_name not in __deprecated_functions:\n                __deprecated_functions[f_name] = True\n                s = \"DEPRECATION WARNING: Function {} is being removed\".format(\n                    f.__name__)\n                if date:\n                    s = \"{} on/around {}\".format(s, date)\n                if warning:\n                    s = \"{} : {}\".format(s, warning)\n                if log:\n                    log(s)\n                else:\n                    print(s)\n            return f(*args, **kwargs)\n        return wrapped_f\n    return wrap"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef splituser(host):\n    '''urllib.splituser(), but six's support of this seems broken'''\n    _userprog = re.compile('^(.*)@(.*)$')\n    match = _userprog.match(host)\n    if match:\n        return match.group(1, 2)\n    return None, host", "response": "splituser - split user into user and user name"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef splitpasswd(user):\n    '''urllib.splitpasswd(), but six's support of this is missing'''\n    _passwdprog = re.compile('^([^:]*):(.*)$', re.S)\n    match = _passwdprog.match(user)\n    if match:\n        return match.group(1, 2)\n    return user, None", "response": "urllib. splitpasswd - returns the first two parts of the passwd"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef download(self, source, dest):\n        # propagate all exceptions\n        # URLError, OSError, etc\n        proto, netloc, path, params, query, fragment = urlparse(source)\n        if proto in ('http', 'https'):\n            auth, barehost = splituser(netloc)\n            if auth is not None:\n                source = urlunparse((proto, barehost, path, params, query, fragment))\n                username, password = splitpasswd(auth)\n                passman = HTTPPasswordMgrWithDefaultRealm()\n                # Realm is set to None in add_password to force the username and password\n                # to be used whatever the realm\n                passman.add_password(None, source, username, password)\n                authhandler = HTTPBasicAuthHandler(passman)\n                opener = build_opener(authhandler)\n                install_opener(opener)\n        response = urlopen(source)\n        try:\n            with open(dest, 'wb') as dest_file:\n                dest_file.write(response.read())\n        except Exception as e:\n            if os.path.isfile(dest):\n                os.unlink(dest)\n            raise e", "response": "Download an archive file from source to dest."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef install(self, source, dest=None, checksum=None, hash_type='sha1'):\n        url_parts = self.parse_url(source)\n        dest_dir = os.path.join(os.environ.get('CHARM_DIR'), 'fetched')\n        if not os.path.exists(dest_dir):\n            mkdir(dest_dir, perms=0o755)\n        dld_file = os.path.join(dest_dir, os.path.basename(url_parts.path))\n        try:\n            self.download(source, dld_file)\n        except URLError as e:\n            raise UnhandledSource(e.reason)\n        except OSError as e:\n            raise UnhandledSource(e.strerror)\n        options = parse_qs(url_parts.fragment)\n        for key, value in options.items():\n            if not six.PY3:\n                algorithms = hashlib.algorithms\n            else:\n                algorithms = hashlib.algorithms_available\n            if key in algorithms:\n                if len(value) != 1:\n                    raise TypeError(\n                        \"Expected 1 hash value, not %d\" % len(value))\n                expected = value[0]\n                check_hash(dld_file, expected, key)\n        if checksum:\n            check_hash(dld_file, checksum, hash_type)\n        return extract(dld_file, dest)", "response": "Download and install an archive file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting a trace point using the remote debugger", "response": "def set_trace(addr=DEFAULT_ADDR, port=DEFAULT_PORT):\n    \"\"\"\n    Set a trace point using the remote debugger\n    \"\"\"\n    atexit.register(close_port, port)\n    try:\n        log(\"Starting a remote python debugger session on %s:%s\" % (addr,\n                                                                    port))\n        open_port(port)\n        debugger = Rpdb(addr=addr, port=port)\n        debugger.set_trace(sys._getframe().f_back)\n    except Exception:\n        _error(\"Cannot start a remote debug session on %s:%s\" % (addr,\n                                                                 port))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a DeviceInfo object with the current device settings", "response": "def device_info(device):\n    \"\"\"Returns a DeviceInfo object with the current device settings\"\"\"\n\n    status = subprocess.check_output([\n        'ibstat', device, '-s']).splitlines()\n\n    regexes = {\n        \"CA type: (.*)\": \"device_type\",\n        \"Number of ports: (.*)\": \"num_ports\",\n        \"Firmware version: (.*)\": \"fw_ver\",\n        \"Hardware version: (.*)\": \"hw_ver\",\n        \"Node GUID: (.*)\": \"node_guid\",\n        \"System image GUID: (.*)\": \"sys_guid\",\n    }\n\n    device = DeviceInfo()\n\n    for line in status:\n        for expression, key in regexes.items():\n            matches = re.search(expression, line)\n            if matches:\n                setattr(device, key, matches.group(1))\n\n    return device"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of IPOIB capable ethernet interfaces", "response": "def ipoib_interfaces():\n    \"\"\"Return a list of IPOIB capable ethernet interfaces\"\"\"\n    interfaces = []\n\n    for interface in network_interfaces():\n        try:\n            driver = re.search('^driver: (.+)$', subprocess.check_output([\n                'ethtool', '-i',\n                interface]), re.M).group(1)\n\n            if driver in IPOIB_DRIVERS:\n                interfaces.append(interface)\n        except Exception:\n            log(\"Skipping interface %s\" % interface, level=INFO)\n            continue\n\n    return interfaces"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_audits():\n    audits = [TemplatedFile('/etc/login.defs', LoginContext(),\n                            template_dir=TEMPLATES_DIR,\n                            user='root', group='root', mode=0o0444)]\n    return audits", "response": "Get OS hardening login. defs audits.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload the default config for the provided modules.", "response": "def _get_defaults(modules):\n    \"\"\"Load the default config for the provided modules.\n\n    :param modules: stack modules config defaults to lookup.\n    :returns: modules default config dictionary.\n    \"\"\"\n    default = os.path.join(os.path.dirname(__file__),\n                           'defaults/%s.yaml' % (modules))\n    return yaml.safe_load(open(default))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_schema(modules):\n    schema = os.path.join(os.path.dirname(__file__),\n                          'defaults/%s.yaml.schema' % (modules))\n    return yaml.safe_load(open(schema))", "response": "Load the config schema for the provided modules."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading user - provided config overrides. yaml file and return the overrides dictionary.", "response": "def _get_user_provided_overrides(modules):\n    \"\"\"Load user-provided config overrides.\n\n    :param modules: stack modules to lookup in user overrides yaml file.\n    :returns: overrides dictionary.\n    \"\"\"\n    overrides = os.path.join(os.environ['JUJU_CHARM_DIR'],\n                             'hardening.yaml')\n    if os.path.exists(overrides):\n        log(\"Found user-provided config overrides file '%s'\" %\n            (overrides), level=DEBUG)\n        settings = yaml.safe_load(open(overrides))\n        if settings and settings.get(modules):\n            log(\"Applying '%s' overrides\" % (modules), level=DEBUG)\n            return settings.get(modules)\n\n        log(\"No overrides found for '%s'\" % (modules), level=DEBUG)\n    else:\n        log(\"No hardening config overrides file '%s' found in charm \"\n            \"root dir\" % (overrides), level=DEBUG)\n\n    return {}"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _apply_overrides(settings, overrides, schema):\n    if overrides:\n        for k, v in six.iteritems(overrides):\n            if k in schema:\n                if schema[k] is None:\n                    settings[k] = v\n                elif type(schema[k]) is dict:\n                    settings[k] = _apply_overrides(settings[k], overrides[k],\n                                                   schema[k])\n                else:\n                    raise Exception(\"Unexpected type found in schema '%s'\" %\n                                    type(schema[k]), level=ERROR)\n            else:\n                log(\"Unknown override key '%s' - ignoring\" % (k), level=INFO)\n\n    return settings", "response": "Apply overrides config overlayed onto stack modules defaults."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ensure_permissions(path, user, group, permissions, maxdepth=-1):\n    if not os.path.exists(path):\n        log(\"File '%s' does not exist - cannot set permissions\" % (path),\n            level=WARNING)\n        return\n\n    _user = pwd.getpwnam(user)\n    os.chown(path, _user.pw_uid, grp.getgrnam(group).gr_gid)\n    os.chmod(path, permissions)\n\n    if maxdepth == 0:\n        log(\"Max recursion depth reached - skipping further recursion\",\n            level=DEBUG)\n        return\n    elif maxdepth > 0:\n        maxdepth -= 1\n\n    if os.path.isdir(path):\n        contents = glob.glob(\"%s/*\" % (path))\n        for c in contents:\n            ensure_permissions(c, user=user, group=group,\n                               permissions=permissions, maxdepth=maxdepth)", "response": "Ensures that the user and group of path have the specified permissions."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create(sysctl_dict, sysctl_file, ignore=False):\n    if type(sysctl_dict) is not dict:\n        try:\n            sysctl_dict_parsed = yaml.safe_load(sysctl_dict)\n        except yaml.YAMLError:\n            log(\"Error parsing YAML sysctl_dict: {}\".format(sysctl_dict),\n                level=ERROR)\n            return\n    else:\n        sysctl_dict_parsed = sysctl_dict\n\n    with open(sysctl_file, \"w\") as fd:\n        for key, value in sysctl_dict_parsed.items():\n            fd.write(\"{}={}\\n\".format(key, value))\n\n    log(\"Updating sysctl_file: {} values: {}\".format(sysctl_file,\n                                                     sysctl_dict_parsed),\n        level=DEBUG)\n\n    call = [\"sysctl\", \"-p\", sysctl_file]\n    if ignore:\n        call.append(\"-e\")\n\n    check_call(call)", "response": "Creates a sysctl. conf file from a YAML - formatted string of sysctl."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef canonical_url(configs, endpoint_type=PUBLIC):\n    scheme = _get_scheme(configs)\n\n    address = resolve_address(endpoint_type)\n    if is_ipv6(address):\n        address = \"[{}]\".format(address)\n\n    return '%s://%s' % (scheme, address)", "response": "Returns the correct HTTP URL to this host given the state of HTTPS\n    configuration hacluster and charm configuration."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn any address overrides that the user has defined based on the endpoint type.", "response": "def _get_address_override(endpoint_type=PUBLIC):\n    \"\"\"Returns any address overrides that the user has defined based on the\n    endpoint type.\n\n    Note: this function allows for the service name to be inserted into the\n    address if the user specifies {service_name}.somehost.org.\n\n    :param endpoint_type: the type of endpoint to retrieve the override\n                          value for.\n    :returns: any endpoint address or hostname that the user has overridden\n              or None if an override is not present.\n    \"\"\"\n    override_key = ADDRESS_MAP[endpoint_type]['override']\n    addr_override = config(override_key)\n    if not addr_override:\n        return None\n    else:\n        return addr_override.format(service_name=service_name())"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef resolve_address(endpoint_type=PUBLIC, override=True):\n    resolved_address = None\n    if override:\n        resolved_address = _get_address_override(endpoint_type)\n        if resolved_address:\n            return resolved_address\n\n    vips = config('vip')\n    if vips:\n        vips = vips.split()\n\n    net_type = ADDRESS_MAP[endpoint_type]['config']\n    net_addr = config(net_type)\n    net_fallback = ADDRESS_MAP[endpoint_type]['fallback']\n    binding = ADDRESS_MAP[endpoint_type]['binding']\n    clustered = is_clustered()\n\n    if clustered and vips:\n        if net_addr:\n            for vip in vips:\n                if is_address_in_network(net_addr, vip):\n                    resolved_address = vip\n                    break\n        else:\n            # NOTE: endeavour to check vips against network space\n            #       bindings\n            try:\n                bound_cidr = resolve_network_cidr(\n                    network_get_primary_address(binding)\n                )\n                for vip in vips:\n                    if is_address_in_network(bound_cidr, vip):\n                        resolved_address = vip\n                        break\n            except (NotImplementedError, NoNetworkBinding):\n                # If no net-splits configured and no support for extra\n                # bindings/network spaces so we expect a single vip\n                resolved_address = vips[0]\n    else:\n        if config('prefer-ipv6'):\n            fallback_addr = get_ipv6_addr(exc_list=vips)[0]\n        else:\n            fallback_addr = unit_get(net_fallback)\n\n        if net_addr:\n            resolved_address = get_address_in_network(net_addr, fallback_addr)\n        else:\n            # NOTE: only try to use extra bindings if legacy network\n            #       configuration is not in use\n            try:\n                resolved_address = network_get_primary_address(binding)\n            except (NotImplementedError, NoNetworkBinding):\n                resolved_address = fallback_addr\n\n    if resolved_address is None:\n        raise ValueError(\"Unable to resolve a suitable IP address based on \"\n                         \"charm state and configuration. (net_type=%s, \"\n                         \"clustered=%s)\" % (net_type, clustered))\n\n    return resolved_address", "response": "Resolves the given endpoint type to the corresponding address."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef hugepage_support(user, group='hugetlb', nr_hugepages=256,\n                     max_map_count=65536, mnt_point='/run/hugepages/kvm',\n                     pagesize='2MB', mount=True, set_shmmax=False):\n    \"\"\"Enable hugepages on system.\n\n    Args:\n    user (str)  -- Username to allow access to hugepages to\n    group (str) -- Group name to own hugepages\n    nr_hugepages (int) -- Number of pages to reserve\n    max_map_count (int) -- Number of Virtual Memory Areas a process can own\n    mnt_point (str) -- Directory to mount hugepages on\n    pagesize (str) -- Size of hugepages\n    mount (bool) -- Whether to Mount hugepages\n    \"\"\"\n    group_info = add_group(group)\n    gid = group_info.gr_gid\n    add_user_to_group(user, group)\n    if max_map_count < 2 * nr_hugepages:\n        max_map_count = 2 * nr_hugepages\n    sysctl_settings = {\n        'vm.nr_hugepages': nr_hugepages,\n        'vm.max_map_count': max_map_count,\n        'vm.hugetlb_shm_group': gid,\n    }\n    if set_shmmax:\n        shmmax_current = int(check_output(['sysctl', '-n', 'kernel.shmmax']))\n        shmmax_minsize = bytes_from_string(pagesize) * nr_hugepages\n        if shmmax_minsize > shmmax_current:\n            sysctl_settings['kernel.shmmax'] = shmmax_minsize\n    sysctl.create(yaml.dump(sysctl_settings), '/etc/sysctl.d/10-hugepage.conf')\n    mkdir(mnt_point, owner='root', group='root', perms=0o755, force=False)\n    lfstab = fstab.Fstab()\n    fstab_entry = lfstab.get_entry_by_attr('mountpoint', mnt_point)\n    if fstab_entry:\n        lfstab.remove_entry(fstab_entry)\n    entry = lfstab.Entry('nodev', mnt_point, 'hugetlbfs',\n                         'mode=1770,gid={},pagesize={}'.format(gid, pagesize), 0, 0)\n    lfstab.add_entry(entry)\n    if mount:\n        fstab_mount(mnt_point)", "response": "Enable hugepages on system."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nensuring that the modules are not loaded and that they are not compatible.", "response": "def ensure_compliance(self):\n        \"\"\"Ensures that the modules are not loaded.\"\"\"\n        if not self.modules:\n            return\n\n        try:\n            loaded_modules = self._get_loaded_modules()\n            non_compliant_modules = []\n            for module in self.modules:\n                if module in loaded_modules:\n                    log(\"Module '%s' is enabled but should not be.\" %\n                        (module), level=INFO)\n                    non_compliant_modules.append(module)\n\n            if len(non_compliant_modules) == 0:\n                return\n\n            for module in non_compliant_modules:\n                self._disable_module(module)\n            self._restart_apache()\n        except subprocess.CalledProcessError as e:\n            log('Error occurred auditing apache module compliance. '\n                'This may have been already reported. '\n                'Output is: %s' % e.output, level=ERROR)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_loaded_modules():\n        output = subprocess.check_output(['apache2ctl', '-M'])\n        if six.PY3:\n            output = output.decode('utf-8')\n        modules = []\n        for line in output.splitlines():\n            # Each line of the enabled module output looks like:\n            #  module_name (static|shared)\n            # Plus a header line at the top of the output which is stripped\n            # out by the regex.\n            matcher = re.search(r'^ (\\S*)_module (\\S*)', line)\n            if matcher:\n                modules.append(matcher.group(1))\n        return modules", "response": "Returns the modules which are enabled in Apache."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndisables the specified module in Apache.", "response": "def _disable_module(module):\n        \"\"\"Disables the specified module in Apache.\"\"\"\n        try:\n            subprocess.check_call(['a2dismod', module])\n        except subprocess.CalledProcessError as e:\n            # Note: catch error here to allow the attempt of disabling\n            # multiple modules in one go rather than failing after the\n            # first module fails.\n            log('Error occurred disabling module %s. '\n                'Output is: %s' % (module, e.output), level=ERROR)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the path to the template file which would be used to render the path.", "response": "def get_template_path(template_dir, path):\n    \"\"\"Returns the template file which would be used to render the path.\n\n    The path to the template file is returned.\n    :param template_dir: the directory the templates are located in\n    :param path: the file path to be written to.\n    :returns: path to the template file\n    \"\"\"\n    return os.path.join(template_dir, os.path.basename(path))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrenders the specified template into the specified file.", "response": "def render_and_write(template_dir, path, context):\n    \"\"\"Renders the specified template into the file.\n\n    :param template_dir: the directory to load the template from\n    :param path: the path to write the templated contents to\n    :param context: the parameters to pass to the rendering engine\n    \"\"\"\n    env = Environment(loader=FileSystemLoader(template_dir))\n    template_file = os.path.basename(path)\n    template = env.get_template(template_file)\n    log('Rendering from template: %s' % template.name, level=DEBUG)\n    rendered_content = template.render(context)\n    if not rendered_content:\n        log(\"Render returned None - skipping '%s'\" % path,\n            level=WARNING)\n        return\n\n    write(path, rendered_content.encode('utf-8').strip())\n    log('Wrote template %s' % path, level=DEBUG)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets OS hardening apt audits.", "response": "def get_audits():\n    \"\"\"Get OS hardening apt audits.\n\n    :returns:  dictionary of audits\n    \"\"\"\n    audits = [AptConfig([{'key': 'APT::Get::AllowUnauthenticated',\n                          'expected': 'false'}])]\n\n    settings = get_settings('os')\n    clean_packages = settings['security']['packages_clean']\n    if clean_packages:\n        security_packages = settings['security']['packages_list']\n        if security_packages:\n            audits.append(RestrictedPackages(security_packages))\n\n    return audits"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_audits():\n    audits = []\n\n    settings = utils.get_settings('os')\n\n    if settings['auth']['pam_passwdqc_enable']:\n        audits.append(PasswdqcPAM('/etc/passwdqc.conf'))\n\n    if settings['auth']['retries']:\n        audits.append(Tally2PAM('/usr/share/pam-configs/tally2'))\n    else:\n        audits.append(DeletedFile('/usr/share/pam-configs/tally2'))\n\n    return audits", "response": "Get OS hardening PAM authentication audits."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninstalls the ansible package.", "response": "def install_ansible_support(from_ppa=True, ppa_location='ppa:rquillo/ansible'):\n    \"\"\"Installs the ansible package.\n\n    By default it is installed from the `PPA`_ linked from\n    the ansible `website`_ or from a ppa specified by a charm config..\n\n    .. _PPA: https://launchpad.net/~rquillo/+archive/ansible\n    .. _website: http://docs.ansible.com/intro_installation.html#latest-releases-via-apt-ubuntu\n\n    If from_ppa is empty, you must ensure that the package is available\n    from a configured repository.\n    \"\"\"\n    if from_ppa:\n        charmhelpers.fetch.add_source(ppa_location)\n        charmhelpers.fetch.apt_update(fatal=True)\n    charmhelpers.fetch.apt_install('ansible')\n    with open(ansible_hosts_path, 'w+') as hosts_file:\n        hosts_file.write('localhost ansible_connection=local ansible_remote_tmp=/root/.ansible/tmp')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexecute the hook followed by the playbook using the hook as tag.", "response": "def execute(self, args):\n        \"\"\"Execute the hook followed by the playbook using the hook as tag.\"\"\"\n        hook_name = os.path.basename(args[0])\n        extra_vars = None\n        if hook_name in self._actions:\n            extra_vars = self._actions[hook_name](args[1:])\n        else:\n            super(AnsibleHooks, self).execute(args)\n\n        charmhelpers.contrib.ansible.apply_playbook(\n            self.playbook_path, tags=[hook_name], extra_vars=extra_vars)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a logger object that will log to stdout.", "response": "def get_logger(self, name=\"deployment-logger\", level=logging.DEBUG):\n        \"\"\"Get a logger object that will log to stdout.\"\"\"\n        log = logging\n        logger = log.getLogger(name)\n        fmt = log.Formatter(\"%(asctime)s %(funcName)s \"\n                            \"%(levelname)s: %(message)s\")\n\n        handler = log.StreamHandler(stream=sys.stdout)\n        handler.setLevel(level)\n        handler.setFormatter(fmt)\n\n        logger.addHandler(handler)\n        logger.setLevel(level)\n\n        return logger"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndetermines the branch locations for the other services.", "response": "def _determine_branch_locations(self, other_services):\n        \"\"\"Determine the branch locations for the other services.\n\n           Determine if the local branch being tested is derived from its\n           stable or next (dev) branch, and based on this, use the corresonding\n           stable or next branches for the other_services.\"\"\"\n\n        self.log.info('OpenStackAmuletDeployment:  determine branch locations')\n\n        # Charms outside the ~openstack-charmers\n        base_charms = {\n            'mysql': ['trusty'],\n            'mongodb': ['trusty'],\n            'nrpe': ['trusty', 'xenial'],\n        }\n\n        for svc in other_services:\n            # If a location has been explicitly set, use it\n            if svc.get('location'):\n                continue\n            if svc['name'] in base_charms:\n                # NOTE: not all charms have support for all series we\n                #       want/need to test against, so fix to most recent\n                #       that each base charm supports\n                target_series = self.series\n                if self.series not in base_charms[svc['name']]:\n                    target_series = base_charms[svc['name']][-1]\n                svc['location'] = 'cs:{}/{}'.format(target_series,\n                                                    svc['name'])\n            elif self.stable:\n                svc['location'] = 'cs:{}/{}'.format(self.series,\n                                                    svc['name'])\n            else:\n                svc['location'] = 'cs:~openstack-charmers-next/{}/{}'.format(\n                    self.series,\n                    svc['name']\n                )\n\n        return other_services"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _add_services(self, this_service, other_services, use_source=None,\n                      no_origin=None):\n        \"\"\"Add services to the deployment and optionally set\n        openstack-origin/source.\n\n        :param this_service dict: Service dictionary describing the service\n                                  whose amulet tests are being run\n        :param other_services dict: List of service dictionaries describing\n                                    the services needed to support the target\n                                    service\n        :param use_source list: List of services which use the 'source' config\n                                option rather than 'openstack-origin'\n        :param no_origin list: List of services which do not support setting\n                               the Cloud Archive.\n        Service Dict:\n            {\n                'name': str charm-name,\n                'units': int number of units,\n                'constraints': dict of juju constraints,\n                'location': str location of charm,\n            }\n        eg\n        this_service = {\n            'name': 'openvswitch-odl',\n            'constraints': {'mem': '8G'},\n        }\n        other_services = [\n            {\n                'name': 'nova-compute',\n                'units': 2,\n                'constraints': {'mem': '4G'},\n                'location': cs:~bob/xenial/nova-compute\n            },\n            {\n                'name': 'mysql',\n                'constraints': {'mem': '2G'},\n            },\n            {'neutron-api-odl'}]\n        use_source = ['mysql']\n        no_origin = ['neutron-api-odl']\n        \"\"\"\n        self.log.info('OpenStackAmuletDeployment:  adding services')\n\n        other_services = self._determine_branch_locations(other_services)\n\n        super(OpenStackAmuletDeployment, self)._add_services(this_service,\n                                                             other_services)\n\n        services = other_services\n        services.append(this_service)\n\n        use_source = use_source or []\n        no_origin = no_origin or []\n\n        # Charms which should use the source config option\n        use_source = list(set(\n            use_source + ['mysql', 'mongodb', 'rabbitmq-server', 'ceph',\n                          'ceph-osd', 'ceph-radosgw', 'ceph-mon',\n                          'ceph-proxy', 'percona-cluster', 'lxd']))\n\n        # Charms which can not use openstack-origin, ie. many subordinates\n        no_origin = list(set(\n            no_origin + ['cinder-ceph', 'hacluster', 'neutron-openvswitch',\n                         'nrpe', 'openvswitch-odl', 'neutron-api-odl',\n                         'odl-controller', 'cinder-backup', 'nexentaedge-data',\n                         'nexentaedge-iscsi-gw', 'nexentaedge-swift-gw',\n                         'cinder-nexentaedge', 'nexentaedge-mgmt',\n                         'ceilometer-agent']))\n\n        if self.openstack:\n            for svc in services:\n                if svc['name'] not in use_source + no_origin:\n                    config = {'openstack-origin': self.openstack}\n                    self.d.configure(svc['name'], config)\n\n        if self.source:\n            for svc in services:\n                if svc['name'] in use_source and svc['name'] not in no_origin:\n                    config = {'source': self.source}\n                    self.d.configure(svc['name'], config)", "response": "Add services to the deployment and optionally set the source config option to the source config."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _auto_wait_for_status(self, message=None, exclude_services=None,\n                              include_only=None, timeout=None):\n        \"\"\"Wait for all units to have a specific extended status, except\n        for any defined as excluded.  Unless specified via message, any\n        status containing any case of 'ready' will be considered a match.\n\n        Examples of message usage:\n\n          Wait for all unit status to CONTAIN any case of 'ready' or 'ok':\n              message = re.compile('.*ready.*|.*ok.*', re.IGNORECASE)\n\n          Wait for all units to reach this status (exact match):\n              message = re.compile('^Unit is ready and clustered$')\n\n          Wait for all units to reach any one of these (exact match):\n              message = re.compile('Unit is ready|OK|Ready')\n\n          Wait for at least one unit to reach this status (exact match):\n              message = {'ready'}\n\n        See Amulet's sentry.wait_for_messages() for message usage detail.\n        https://github.com/juju/amulet/blob/master/amulet/sentry.py\n\n        :param message: Expected status match\n        :param exclude_services: List of juju service names to ignore,\n            not to be used in conjuction with include_only.\n        :param include_only: List of juju service names to exclusively check,\n            not to be used in conjuction with exclude_services.\n        :param timeout: Maximum time in seconds to wait for status match\n        :returns: None.  Raises if timeout is hit.\n        \"\"\"\n        if not timeout:\n            timeout = int(os.environ.get('AMULET_SETUP_TIMEOUT', 1800))\n        self.log.info('Waiting for extended status on units for {}s...'\n                      ''.format(timeout))\n\n        all_services = self.d.services.keys()\n\n        if exclude_services and include_only:\n            raise ValueError('exclude_services can not be used '\n                             'with include_only')\n\n        if message:\n            if isinstance(message, re._pattern_type):\n                match = message.pattern\n            else:\n                match = message\n\n            self.log.debug('Custom extended status wait match: '\n                           '{}'.format(match))\n        else:\n            self.log.debug('Default extended status wait match:  contains '\n                           'READY (case-insensitive)')\n            message = re.compile('.*ready.*', re.IGNORECASE)\n\n        if exclude_services:\n            self.log.debug('Excluding services from extended status match: '\n                           '{}'.format(exclude_services))\n        else:\n            exclude_services = []\n\n        if include_only:\n            services = include_only\n        else:\n            services = list(set(all_services) - set(exclude_services))\n\n        self.log.debug('Waiting up to {}s for extended status on services: '\n                       '{}'.format(timeout, services))\n        service_messages = {service: message for service in services}\n\n        # Check for idleness\n        self.d.sentry.wait(timeout=timeout)\n        # Check for error states and bail early\n        self.d.sentry.wait_for_status(self.d.juju_env, services, timeout=timeout)\n        # Check for ready messages\n        self.d.sentry.wait_for_messages(service_messages, timeout=timeout)\n\n        self.log.info('OK')", "response": "Wait for all units to have an extended status."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_openstack_release(self):\n        # Must be ordered by OpenStack release (not by Ubuntu release):\n        for i, os_pair in enumerate(OPENSTACK_RELEASES_PAIRS):\n            setattr(self, os_pair, i)\n\n        releases = {\n            ('trusty', None): self.trusty_icehouse,\n            ('trusty', 'cloud:trusty-kilo'): self.trusty_kilo,\n            ('trusty', 'cloud:trusty-liberty'): self.trusty_liberty,\n            ('trusty', 'cloud:trusty-mitaka'): self.trusty_mitaka,\n            ('xenial', None): self.xenial_mitaka,\n            ('xenial', 'cloud:xenial-newton'): self.xenial_newton,\n            ('xenial', 'cloud:xenial-ocata'): self.xenial_ocata,\n            ('xenial', 'cloud:xenial-pike'): self.xenial_pike,\n            ('xenial', 'cloud:xenial-queens'): self.xenial_queens,\n            ('yakkety', None): self.yakkety_newton,\n            ('zesty', None): self.zesty_ocata,\n            ('artful', None): self.artful_pike,\n            ('bionic', None): self.bionic_queens,\n            ('bionic', 'cloud:bionic-rocky'): self.bionic_rocky,\n            ('bionic', 'cloud:bionic-stein'): self.bionic_stein,\n            ('cosmic', None): self.cosmic_rocky,\n            ('disco', None): self.disco_stein,\n        }\n        return releases[(self.series, self.openstack)]", "response": "Return an integer representing the enum value of the openstack release."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_openstack_release_string(self):\n        releases = OrderedDict([\n            ('trusty', 'icehouse'),\n            ('xenial', 'mitaka'),\n            ('yakkety', 'newton'),\n            ('zesty', 'ocata'),\n            ('artful', 'pike'),\n            ('bionic', 'queens'),\n            ('cosmic', 'rocky'),\n            ('disco', 'stein'),\n        ])\n        if self.openstack:\n            os_origin = self.openstack.split(':')[1]\n            return os_origin.split('%s-' % self.series)[1].split('/')[0]\n        else:\n            return releases[self.series]", "response": "Get the openstack release string."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_ceph_expected_pools(self, radosgw=False):\n\n        if self._get_openstack_release() == self.trusty_icehouse:\n            # Icehouse\n            pools = [\n                'data',\n                'metadata',\n                'rbd',\n                'cinder-ceph',\n                'glance'\n            ]\n        elif (self.trusty_kilo <= self._get_openstack_release() <=\n              self.zesty_ocata):\n            # Kilo through Ocata\n            pools = [\n                'rbd',\n                'cinder-ceph',\n                'glance'\n            ]\n        else:\n            # Pike and later\n            pools = [\n                'cinder-ceph',\n                'glance'\n            ]\n\n        if radosgw:\n            pools.extend([\n                '.rgw.root',\n                '.rgw.control',\n                '.rgw',\n                '.rgw.gc',\n                '.users.uid'\n            ])\n\n        return pools", "response": "Return a list of expected ceph pools based on OpenStack release and whether radosgw is True or not."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_platform():\n    # linux_distribution is deprecated and will be removed in Python 3.7\n    # Warings *not* disabled, as we certainly need to fix this.\n    tuple_platform = platform.linux_distribution()\n    current_platform = tuple_platform[0]\n    if \"Ubuntu\" in current_platform:\n        return \"ubuntu\"\n    elif \"CentOS\" in current_platform:\n        return \"centos\"\n    elif \"debian\" in current_platform:\n        # Stock Python does not detect Ubuntu and instead returns debian.\n        # Or at least it does in some build environments like Travis CI\n        return \"ubuntu\"\n    else:\n        raise RuntimeError(\"This module is not supported on {}.\"\n                           .format(current_platform))", "response": "Return the current OS platform."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_audits():\n    checks = []\n    settings = utils.get_settings('os')\n    if not settings['security']['suid_sgid_enforce']:\n        log(\"Skipping suid/sgid hardening\", level=INFO)\n        return checks\n\n    # Build the blacklist and whitelist of files for suid/sgid checks.\n    # There are a total of 4 lists:\n    #   1. the system blacklist\n    #   2. the system whitelist\n    #   3. the user blacklist\n    #   4. the user whitelist\n    #\n    # The blacklist is the set of paths which should NOT have the suid/sgid bit\n    # set and the whitelist is the set of paths which MAY have the suid/sgid\n    # bit setl. The user whitelist/blacklist effectively override the system\n    # whitelist/blacklist.\n    u_b = settings['security']['suid_sgid_blacklist']\n    u_w = settings['security']['suid_sgid_whitelist']\n\n    blacklist = set(BLACKLIST) - set(u_w + u_b)\n    whitelist = set(WHITELIST) - set(u_b + u_w)\n\n    checks.append(NoSUIDSGIDAudit(blacklist))\n\n    dry_run = settings['security']['suid_sgid_dry_run_on_unknown']\n\n    if settings['security']['suid_sgid_remove_from_unknown'] or dry_run:\n        # If the policy is a dry_run (e.g. complain only) or remove unknown\n        # suid/sgid bits then find all of the paths which have the suid/sgid\n        # bit set and then remove the whitelisted paths.\n        root_path = settings['environment']['root_path']\n        unknown_paths = find_paths_with_suid_sgid(root_path) - set(whitelist)\n        checks.append(NoSUIDSGIDAudit(unknown_paths, unless=dry_run))\n\n    return checks", "response": "Get OS hardening suid and sgid audits."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_paths_with_suid_sgid(root_path):\n    cmd = ['find', root_path, '-perm', '-4000', '-o', '-perm', '-2000',\n           '-type', 'f', '!', '-path', '/proc/*', '-print']\n\n    p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    out, _ = p.communicate()\n    return set(out.split('\\n'))", "response": "Finds all paths which have a suid or sgid bit set enabled."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef current_version_string():\n    return \"{0}.{1}.{2}\".format(sys.version_info.major,\n                                sys.version_info.minor,\n                                sys.version_info.micro)", "response": "Return the current python version as string major. minor. micro"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_audits():\n    if subprocess.call(['which', 'mysql'], stdout=subprocess.PIPE) != 0:\n        log(\"MySQL does not appear to be installed on this node - \"\n            \"skipping mysql hardening\", level=WARNING)\n        return []\n\n    settings = utils.get_settings('mysql')\n    hardening_settings = settings['hardening']\n    my_cnf = hardening_settings['mysql-conf']\n\n    audits = [\n        FilePermissionAudit(paths=[my_cnf], user='root',\n                            group='root', mode=0o0600),\n\n        TemplatedFile(hardening_settings['hardening-conf'],\n                      MySQLConfContext(),\n                      TEMPLATES_DIR,\n                      mode=0o0750,\n                      user='mysql',\n                      group='root',\n                      service_actions=[{'service': 'mysql',\n                                        'actions': ['restart']}]),\n\n        # MySQL and Percona charms do not allow configuration of the\n        # data directory, so use the default.\n        DirectoryPermissionAudit('/var/lib/mysql',\n                                 user='mysql',\n                                 group='mysql',\n                                 recursive=False,\n                                 mode=0o755),\n\n        DirectoryPermissionAudit('/etc/mysql',\n                                 user='root',\n                                 group='root',\n                                 recursive=False,\n                                 mode=0o700),\n    ]\n\n    return audits", "response": "Get MySQL hardening config audits."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreloading a system service optionally falling back to restart if reload fails.", "response": "def service_reload(service_name, restart_on_failure=False, **kwargs):\n    \"\"\"Reload a system service, optionally falling back to restart if\n    reload fails.\n\n    The specified service name is managed via the system level init system.\n    Some init systems (e.g. upstart) require that additional arguments be\n    provided in order to directly control service instances whereas other init\n    systems allow for addressing instances of a service directly by name (e.g.\n    systemd).\n\n    The kwargs allow for the additional parameters to be passed to underlying\n    init systems for those systems which require/allow for them. For example,\n    the ceph-osd upstart script requires the id parameter to be passed along\n    in order to identify which running daemon should be reloaded. The follow-\n    ing example restarts the ceph-osd service for instance id=4:\n\n    service_reload('ceph-osd', id=4)\n\n    :param service_name: the name of the service to reload\n    :param restart_on_failure: boolean indicating whether to fallback to a\n                               restart if the reload fails.\n    :param **kwargs: additional parameters to pass to the init system when\n                     managing services. These will be passed as key=value\n                     parameters to the  init system's commandline. kwargs\n                     are ignored for init systems not allowing additional\n                     parameters via the commandline (systemd).\n    \"\"\"\n    service_result = service('reload', service_name, **kwargs)\n    if not service_result and restart_on_failure:\n        service_result = service('restart', service_name, **kwargs)\n    return service_result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef service_pause(service_name, init_dir=\"/etc/init\", initd_dir=\"/etc/init.d\",\n                  **kwargs):\n    \"\"\"Pause a system service.\n\n    Stop it, and prevent it from starting again at boot.\n\n    :param service_name: the name of the service to pause\n    :param init_dir: path to the upstart init directory\n    :param initd_dir: path to the sysv init directory\n    :param **kwargs: additional parameters to pass to the init system when\n                     managing services. These will be passed as key=value\n                     parameters to the init system's commandline. kwargs\n                     are ignored for init systems which do not support\n                     key=value arguments via the commandline.\n    \"\"\"\n    stopped = True\n    if service_running(service_name, **kwargs):\n        stopped = service_stop(service_name, **kwargs)\n    upstart_file = os.path.join(init_dir, \"{}.conf\".format(service_name))\n    sysv_file = os.path.join(initd_dir, service_name)\n    if init_is_systemd():\n        service('disable', service_name)\n        service('mask', service_name)\n    elif os.path.exists(upstart_file):\n        override_path = os.path.join(\n            init_dir, '{}.override'.format(service_name))\n        with open(override_path, 'w') as fh:\n            fh.write(\"manual\\n\")\n    elif os.path.exists(sysv_file):\n        subprocess.check_call([\"update-rc.d\", service_name, \"disable\"])\n    else:\n        raise ValueError(\n            \"Unable to detect {0} as SystemD, Upstart {1} or\"\n            \" SysV {2}\".format(\n                service_name, upstart_file, sysv_file))\n    return stopped", "response": "Pause a system service."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef service_resume(service_name, init_dir=\"/etc/init\",\n                   initd_dir=\"/etc/init.d\", **kwargs):\n    \"\"\"Resume a system service.\n\n    Reenable starting again at boot. Start the service.\n\n    :param service_name: the name of the service to resume\n    :param init_dir: the path to the init dir\n    :param initd dir: the path to the initd dir\n    :param **kwargs: additional parameters to pass to the init system when\n                     managing services. These will be passed as key=value\n                     parameters to the init system's commandline. kwargs\n                     are ignored for systemd enabled systems.\n    \"\"\"\n    upstart_file = os.path.join(init_dir, \"{}.conf\".format(service_name))\n    sysv_file = os.path.join(initd_dir, service_name)\n    if init_is_systemd():\n        service('unmask', service_name)\n        service('enable', service_name)\n    elif os.path.exists(upstart_file):\n        override_path = os.path.join(\n            init_dir, '{}.override'.format(service_name))\n        if os.path.exists(override_path):\n            os.unlink(override_path)\n    elif os.path.exists(sysv_file):\n        subprocess.check_call([\"update-rc.d\", service_name, \"enable\"])\n    else:\n        raise ValueError(\n            \"Unable to detect {0} as SystemD, Upstart {1} or\"\n            \" SysV {2}\".format(\n                service_name, upstart_file, sysv_file))\n    started = service_running(service_name, **kwargs)\n\n    if not started:\n        started = service_start(service_name, **kwargs)\n    return started", "response": "Resume a system service."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncontrol a system service.", "response": "def service(action, service_name, **kwargs):\n    \"\"\"Control a system service.\n\n    :param action: the action to take on the service\n    :param service_name: the name of the service to perform th action on\n    :param **kwargs: additional params to be passed to the service command in\n                    the form of key=value.\n    \"\"\"\n    if init_is_systemd():\n        cmd = ['systemctl', action, service_name]\n    else:\n        cmd = ['service', service_name, action]\n        for key, value in six.iteritems(kwargs):\n            parameter = '%s=%s' % (key, value)\n            cmd.append(parameter)\n    return subprocess.call(cmd) == 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndetermines if a system service is running.", "response": "def service_running(service_name, **kwargs):\n    \"\"\"Determine whether a system service is running.\n\n    :param service_name: the name of the service\n    :param **kwargs: additional args to pass to the service command. This is\n                     used to pass additional key=value arguments to the\n                     service command line for managing specific instance\n                     units (e.g. service ceph-osd status id=2). The kwargs\n                     are ignored in systemd services.\n    \"\"\"\n    if init_is_systemd():\n        return service('is-active', service_name)\n    else:\n        if os.path.exists(_UPSTART_CONF.format(service_name)):\n            try:\n                cmd = ['status', service_name]\n                for key, value in six.iteritems(kwargs):\n                    parameter = '%s=%s' % (key, value)\n                    cmd.append(parameter)\n                output = subprocess.check_output(\n                    cmd, stderr=subprocess.STDOUT).decode('UTF-8')\n            except subprocess.CalledProcessError:\n                return False\n            else:\n                # This works for upstart scripts where the 'service' command\n                # returns a consistent string to represent running\n                # 'start/running'\n                if (\"start/running\" in output or\n                        \"is running\" in output or\n                        \"up and running\" in output):\n                    return True\n        elif os.path.exists(_INIT_D_CONF.format(service_name)):\n            # Check System V scripts init script return codes\n            return service('status', service_name)\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef adduser(username, password=None, shell='/bin/bash',\n            system_user=False, primary_group=None,\n            secondary_groups=None, uid=None, home_dir=None):\n    \"\"\"Add a user to the system.\n\n    Will log but otherwise succeed if the user already exists.\n\n    :param str username: Username to create\n    :param str password: Password for user; if ``None``, create a system user\n    :param str shell: The default shell for the user\n    :param bool system_user: Whether to create a login or system user\n    :param str primary_group: Primary group for user; defaults to username\n    :param list secondary_groups: Optional list of additional groups\n    :param int uid: UID for user being created\n    :param str home_dir: Home directory for user\n\n    :returns: The password database entry struct, as returned by `pwd.getpwnam`\n    \"\"\"\n    try:\n        user_info = pwd.getpwnam(username)\n        log('user {0} already exists!'.format(username))\n        if uid:\n            user_info = pwd.getpwuid(int(uid))\n            log('user with uid {0} already exists!'.format(uid))\n    except KeyError:\n        log('creating user {0}'.format(username))\n        cmd = ['useradd']\n        if uid:\n            cmd.extend(['--uid', str(uid)])\n        if home_dir:\n            cmd.extend(['--home', str(home_dir)])\n        if system_user or password is None:\n            cmd.append('--system')\n        else:\n            cmd.extend([\n                '--create-home',\n                '--shell', shell,\n                '--password', password,\n            ])\n        if not primary_group:\n            try:\n                grp.getgrnam(username)\n                primary_group = username  # avoid \"group exists\" error\n            except KeyError:\n                pass\n        if primary_group:\n            cmd.extend(['-g', primary_group])\n        if secondary_groups:\n            cmd.extend(['-G', ','.join(secondary_groups)])\n        cmd.append(username)\n        subprocess.check_call(cmd)\n        user_info = pwd.getpwnam(username)\n    return user_info", "response": "Add a user to the system."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if a user exists in the current directory", "response": "def user_exists(username):\n    \"\"\"Check if a user exists\"\"\"\n    try:\n        pwd.getpwnam(username)\n        user_exists = True\n    except KeyError:\n        user_exists = False\n    return user_exists"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef uid_exists(uid):\n    try:\n        pwd.getpwuid(uid)\n        uid_exists = True\n    except KeyError:\n        uid_exists = False\n    return uid_exists", "response": "Check if a uid exists"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef group_exists(groupname):\n    try:\n        grp.getgrnam(groupname)\n        group_exists = True\n    except KeyError:\n        group_exists = False\n    return group_exists", "response": "Check if a group exists"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef gid_exists(gid):\n    try:\n        grp.getgrgid(gid)\n        gid_exists = True\n    except KeyError:\n        gid_exists = False\n    return gid_exists", "response": "Check if a gid exists"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_user_to_group(username, group):\n    cmd = ['gpasswd', '-a', username, group]\n    log(\"Adding user {} to group {}\".format(username, group))\n    subprocess.check_call(cmd)", "response": "Add a user to a group"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchanging user password expiry information in a random user.", "response": "def chage(username, lastday=None, expiredate=None, inactive=None,\n          mindays=None, maxdays=None, root=None, warndays=None):\n    \"\"\"Change user password expiry information\n\n    :param str username: User to update\n    :param str lastday: Set when password was changed in YYYY-MM-DD format\n    :param str expiredate: Set when user's account will no longer be\n                           accessible in YYYY-MM-DD format.\n                           -1 will remove an account expiration date.\n    :param str inactive: Set the number of days of inactivity after a password\n                         has expired before the account is locked.\n                         -1 will remove an account's inactivity.\n    :param str mindays: Set the minimum number of days between password\n                        changes to MIN_DAYS.\n                        0 indicates the password can be changed anytime.\n    :param str maxdays: Set the maximum number of days during which a\n                        password is valid.\n                        -1 as MAX_DAYS will remove checking maxdays\n    :param str root: Apply changes in the CHROOT_DIR directory\n    :param str warndays: Set the number of days of warning before a password\n                         change is required\n    :raises subprocess.CalledProcessError: if call to chage fails\n    \"\"\"\n    cmd = ['chage']\n    if root:\n        cmd.extend(['--root', root])\n    if lastday:\n        cmd.extend(['--lastday', lastday])\n    if expiredate:\n        cmd.extend(['--expiredate', expiredate])\n    if inactive:\n        cmd.extend(['--inactive', inactive])\n    if mindays:\n        cmd.extend(['--mindays', mindays])\n    if maxdays:\n        cmd.extend(['--maxdays', maxdays])\n    if warndays:\n        cmd.extend(['--warndays', warndays])\n    cmd.append(username)\n    subprocess.check_call(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreplicate the contents of a path", "response": "def rsync(from_path, to_path, flags='-r', options=None, timeout=None):\n    \"\"\"Replicate the contents of a path\"\"\"\n    options = options or ['--delete', '--executability']\n    cmd = ['/usr/bin/rsync', flags]\n    if timeout:\n        cmd = ['timeout', str(timeout)] + cmd\n    cmd.extend(options)\n    cmd.append(from_path)\n    cmd.append(to_path)\n    log(\" \".join(cmd))\n    return subprocess.check_output(cmd, stderr=subprocess.STDOUT).decode('UTF-8').strip()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a symbolic link between source and destination", "response": "def symlink(source, destination):\n    \"\"\"Create a symbolic link\"\"\"\n    log(\"Symlinking {} as {}\".format(source, destination))\n    cmd = [\n        'ln',\n        '-sf',\n        source,\n        destination,\n    ]\n    subprocess.check_call(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates or overwrite a file with the contents of a byte string.", "response": "def write_file(path, content, owner='root', group='root', perms=0o444):\n    \"\"\"Create or overwrite a file with the contents of a byte string.\"\"\"\n    uid = pwd.getpwnam(owner).pw_uid\n    gid = grp.getgrnam(group).gr_gid\n    # lets see if we can grab the file and compare the context, to avoid doing\n    # a write.\n    existing_content = None\n    existing_uid, existing_gid, existing_perms = None, None, None\n    try:\n        with open(path, 'rb') as target:\n            existing_content = target.read()\n        stat = os.stat(path)\n        existing_uid, existing_gid, existing_perms = (\n            stat.st_uid, stat.st_gid, stat.st_mode\n        )\n    except Exception:\n        pass\n    if content != existing_content:\n        log(\"Writing file {} {}:{} {:o}\".format(path, owner, group, perms),\n            level=DEBUG)\n        with open(path, 'wb') as target:\n            os.fchown(target.fileno(), uid, gid)\n            os.fchmod(target.fileno(), perms)\n            if six.PY3 and isinstance(content, six.string_types):\n                content = content.encode('UTF-8')\n            target.write(content)\n        return\n    # the contents were the same, but we might still need to change the\n    # ownership or permissions.\n    if existing_uid != uid:\n        log(\"Changing uid on already existing content: {} -> {}\"\n            .format(existing_uid, uid), level=DEBUG)\n        os.chown(path, uid, -1)\n    if existing_gid != gid:\n        log(\"Changing gid on already existing content: {} -> {}\"\n            .format(existing_gid, gid), level=DEBUG)\n        os.chown(path, -1, gid)\n    if existing_perms != perms:\n        log(\"Changing permissions on existing content: {} -> {}\"\n            .format(existing_perms, perms), level=DEBUG)\n        os.chmod(path, perms)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd the given device entry to the Fstab file", "response": "def fstab_add(dev, mp, fs, options=None):\n    \"\"\"Adds the given device entry to the /etc/fstab file\"\"\"\n    return Fstab.add(dev, mp, fs, options=options)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mount(device, mountpoint, options=None, persist=False, filesystem=\"ext3\"):\n    cmd_args = ['mount']\n    if options is not None:\n        cmd_args.extend(['-o', options])\n    cmd_args.extend([device, mountpoint])\n    try:\n        subprocess.check_output(cmd_args)\n    except subprocess.CalledProcessError as e:\n        log('Error mounting {} at {}\\n{}'.format(device, mountpoint, e.output))\n        return False\n\n    if persist:\n        return fstab_add(device, mountpoint, filesystem, options=options)\n    return True", "response": "Mount a filesystem at a particular mountpoint"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mounts():\n    with open('/proc/mounts') as f:\n        # [['/mount/point','/dev/path'],[...]]\n        system_mounts = [m[1::-1] for m in [l.strip().split()\n                                            for l in f.readlines()]]\n    return system_mounts", "response": "Get a list of all mounted volumes as [[ mountpoint device ]..."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmounts filesystem using fstab", "response": "def fstab_mount(mountpoint):\n    \"\"\"Mount filesystem using fstab\"\"\"\n    cmd_args = ['mount', mountpoint]\n    try:\n        subprocess.check_output(cmd_args)\n    except subprocess.CalledProcessError as e:\n        log('Error unmounting {}\\n{}'.format(mountpoint, e.output))\n        return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef file_hash(path, hash_type='md5'):\n    if os.path.exists(path):\n        h = getattr(hashlib, hash_type)()\n        with open(path, 'rb') as source:\n            h.update(source.read())\n        return h.hexdigest()\n    else:\n        return None", "response": "Generate a hash checksum of the contents of path or None if not found."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nvalidate a file using a cryptographic checksum.", "response": "def check_hash(path, checksum, hash_type='md5'):\n    \"\"\"Validate a file using a cryptographic checksum.\n\n    :param str checksum: Value of the checksum used to validate the file.\n    :param str hash_type: Hash algorithm used to generate `checksum`.\n        Can be any hash alrgorithm supported by :mod:`hashlib`,\n        such as md5, sha1, sha256, sha512, etc.\n    :raises ChecksumError: If the file fails the checksum\n\n    \"\"\"\n    actual_checksum = file_hash(path, hash_type)\n    if checksum != actual_checksum:\n        raise ChecksumError(\"'%s' != '%s'\" % (checksum, actual_checksum))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef restart_on_change(restart_map, stopstart=False, restart_functions=None):\n    def wrap(f):\n        @functools.wraps(f)\n        def wrapped_f(*args, **kwargs):\n            return restart_on_change_helper(\n                (lambda: f(*args, **kwargs)), restart_map, stopstart,\n                restart_functions)\n        return wrapped_f\n    return wrap", "response": "Restarts services based on configuration files changing\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating a random pasword.", "response": "def pwgen(length=None):\n    \"\"\"Generate a random pasword.\"\"\"\n    if length is None:\n        # A random length is ok to use a weak PRNG\n        length = random.choice(range(35, 45))\n    alphanumeric_chars = [\n        l for l in (string.ascii_letters + string.digits)\n        if l not in 'l0QD1vAEIOUaeiou']\n    # Use a crypto-friendly PRNG (e.g. /dev/urandom) for making the\n    # actual password\n    random_generator = random.SystemRandom()\n    random_chars = [\n        random_generator.choice(alphanumeric_chars) for _ in range(length)]\n    return(''.join(random_chars))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if interface is virtual otherwise False.", "response": "def is_phy_iface(interface):\n    \"\"\"Returns True if interface is not virtual, otherwise False.\"\"\"\n    if interface:\n        sys_net = '/sys/class/net'\n        if os.path.isdir(sys_net):\n            for iface in glob.glob(os.path.join(sys_net, '*')):\n                if '/virtual/' in os.path.realpath(iface):\n                    continue\n\n                if interface == os.path.basename(iface):\n                    return True\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_bond_master(interface):\n    if interface:\n        iface_path = '/sys/class/net/%s' % (interface)\n        if os.path.exists(iface_path):\n            if '/virtual/' in os.path.realpath(iface_path):\n                return None\n\n            master = os.path.join(iface_path, 'master')\n            if os.path.exists(master):\n                master = os.path.realpath(master)\n                # make sure it is a bond master\n                if os.path.exists(os.path.join(master, 'bonding')):\n                    return os.path.basename(master)\n\n    return None", "response": "Returns bond slave if interface is bond slave otherwise None."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of nics of given type", "response": "def list_nics(nic_type=None):\n    \"\"\"Return a list of nics of given type(s)\"\"\"\n    if isinstance(nic_type, six.string_types):\n        int_types = [nic_type]\n    else:\n        int_types = nic_type\n\n    interfaces = []\n    if nic_type:\n        for int_type in int_types:\n            cmd = ['ip', 'addr', 'show', 'label', int_type + '*']\n            ip_output = subprocess.check_output(cmd).decode('UTF-8')\n            ip_output = ip_output.split('\\n')\n            ip_output = (line for line in ip_output if line)\n            for line in ip_output:\n                if line.split()[1].startswith(int_type):\n                    matched = re.search('.*: (' + int_type +\n                                        r'[0-9]+\\.[0-9]+)@.*', line)\n                    if matched:\n                        iface = matched.groups()[0]\n                    else:\n                        iface = line.split()[1].replace(\":\", \"\")\n\n                    if iface not in interfaces:\n                        interfaces.append(iface)\n    else:\n        cmd = ['ip', 'a']\n        ip_output = subprocess.check_output(cmd).decode('UTF-8').split('\\n')\n        ip_output = (line.strip() for line in ip_output if line)\n\n        key = re.compile(r'^[0-9]+:\\s+(.+):')\n        for line in ip_output:\n            matched = re.search(key, line)\n            if matched:\n                iface = matched.group(1)\n                iface = iface.partition(\"@\")[0]\n                if iface not in interfaces:\n                    interfaces.append(iface)\n\n    return interfaces"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the Maximum Transmission Unit for a network interface.", "response": "def get_nic_mtu(nic):\n    \"\"\"Return the Maximum Transmission Unit (MTU) for a network interface.\"\"\"\n    cmd = ['ip', 'addr', 'show', nic]\n    ip_output = subprocess.check_output(cmd).decode('UTF-8').split('\\n')\n    mtu = \"\"\n    for line in ip_output:\n        words = line.split()\n        if 'mtu' in words:\n            mtu = words[words.index(\"mtu\") + 1]\n    return mtu"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the Media Access Control MAC address for a network interface.", "response": "def get_nic_hwaddr(nic):\n    \"\"\"Return the Media Access Control (MAC) for a network interface.\"\"\"\n    cmd = ['ip', '-o', '-0', 'addr', 'show', nic]\n    ip_output = subprocess.check_output(cmd).decode('UTF-8')\n    hwaddr = \"\"\n    words = ip_output.split()\n    if 'link/ether' in words:\n        hwaddr = words[words.index('link/ether') + 1]\n    return hwaddr"}
