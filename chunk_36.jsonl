{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading a line from stdin and return it.", "response": "def gets(self):\n        \"\"\"\n        Read line from stdin.\n\n        The trailing newline will be omitted.\n        :return: string:\n        \"\"\"\n        ret = self.stdin.readline()\n        if ret == '':\n            raise EOFError  # To break out of EOF loop\n        return ret.rstrip('\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate the subparser for this particular command", "response": "def create_parser(self, subparsers):\n        \"\"\"\n        Creates the subparser for this particular command\n        \"\"\"\n        self.parser = subparsers.add_parser(self.name, help=self.help, parents=self.parents)\n        self.add_arguments()\n        self.parser.set_defaults(func=self.handle)\n        return self.parser"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_arguments(self):\n        if self.parser is None:\n            raise TypeError(\"Parser cannot be None, has create_parser been called?\")\n\n        for keys, kwargs in self.args.items():\n            if not isinstance(keys, tuple):\n                keys = (keys,)\n            self.parser.add_argument(*keys, **kwargs)", "response": "Add all arguments to the parser."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef count(index,h):\n    '''\n    Gives count of the documents stored in Elasticsearch. If index option is\n    provided, it will provide document count of that index.\n    '''\n    try:\n        response = base.es.cat.count(index,h=h)\n        table = base.draw_table(response)\n    except Exception as e:\n        click.echo(e)\n    else:\n        click.echo(table)", "response": "Returns count of the documents stored in Elasticsearch."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nclosing the connection to the AMQP compliant broker.", "response": "def close(self):\n        \"\"\"\n        Close the connection to the AMQP compliant broker.\n        \"\"\"\n        if self.channel is not None: self.channel.close()\n        if self.__connection is not None: self.__connection.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nopens a connection to the AMQP compliant broker.", "response": "def open(self):\n        \"\"\"\n        Open a connection to the AMQP compliant broker.\n        \"\"\"\n        self._connection = \\\n          amqp.Connection(host='%s:%s' % (self.hostname, self.port),\n                          userid=self.username, password=self.password,\n                          virtual_host=self.virtual_host, insist=False)\n        self.channel = self._connection.channel()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef publish(self, message_type, message_payload):\n        payload = json.dumps(jsonpickle.Pickler(unpicklable=False).flatten(message_payload))\n        message = amqp.Message(payload)\n        message.properties[\"delivery_mode\"] = 2\n\n        name = 'majormode.%s.%s.%s' % (settings.ENVIRONMENT_STAGE, self.service_name.lower(), message_type.lower())\n\n        self.channel.queue_declare(queue=name, durable=True, exclusive=False, auto_delete=False)\n        self.channel.exchange_declare(exchange=name, type=\"direct\", durable=True, auto_delete=False,)\n        self.channel.queue_bind(queue=name, exchange=name, routing_key=name)\n\n        self.channel.basic_publish(message, exchange=name, routing_key=name)", "response": "Publish the specified object that the function automatically converts the object into a JSON string representation and then sends it to the AMQP broker."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconsuming message from the Advanced Message Queuing Protocol (AMPQ) compliant broker as soon as they are queued, and call the instance method ``__on_message_received`` that the inheriting class must have implemented.", "response": "def run(self):\n        \"\"\"\n        Consume message from the Advanced Message Queuing Protocol\n        (AMPQ) compliant broker as soon as they are queued, and call\n        the instance method ``__on_message_received`` that the\n        inheriting class must have implemented.\n        \"\"\"\n        self._setUp()\n\n        naming = 'skunkworks.lbs.%s.%s.%s' % (settings.ENVIRONMENT_STAGE, \\\n            self.service_name.lower(), self.message_type.lower())\n\n        self.channel.queue_declare(queue=naming, durable=True, exclusive=False, auto_delete=False)\n        self.channel.exchange_declare(exchange=naming, type=\"direct\", durable=True, auto_delete=False,)\n        self.channel.queue_bind(queue=naming, exchange=naming, routing_key=naming)\n\n        self.channel.basic_consume(queue=self.queue, no_ack=True,\n               callback=self._on_message_received,\n               consumer_tag=self.__class__.__name__)\n        try:\n            while True:\n                self.channel.wait()\n        finally:\n            self.channel.basic_cancel(self.__class__.__name__)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_py_dtype(np_dtype):\n    '''\n    Args:\n\n        np_dtype (numpy.dtype)\n\n    Returns:\n\n        (type) : Python data type that corresponds to the specified numpy\n            dtype.\n    '''\n    if np_dtype.type == np.object_:\n        return object\n    elif hasattr(np_dtype.type(0), 'item'):\n        return type(np_dtype.type(0).item())\n    else:\n        return type(np_dtype.type(0))", "response": "Returns the Python data type that corresponds to the specified numpy\n            dtype."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a pandas. DataFrame containing the Python type information for the columns in data_frame.", "response": "def get_py_dtypes(data_frame):\n    '''\n    Return a `pandas.DataFrame` containing Python type information for the\n    columns in `data_frame`.\n\n    Args:\n\n        data_frame (pandas.DataFrame) : Data frame containing data columns.\n\n    Returns:\n\n        (pandas.DataFrame) : Data frame indexed by the column names from\n            `data_frame`, with the columns `'i'` and `'dtype'` indicating the\n            index and Python type of the corresponding `data_frame` column,\n            respectively.\n    '''\n    df_py_dtypes = data_frame.dtypes.map(get_py_dtype).to_frame('dtype').copy()\n    df_py_dtypes.loc[df_py_dtypes.dtype == object, 'dtype'] = \\\n        (df_py_dtypes.loc[df_py_dtypes.dtype == object].index\n         .map(lambda c: str if data_frame[c]\n              .map(lambda v: isinstance(v, str)).all() else object))\n\n    df_py_dtypes.insert(0, 'i', range(df_py_dtypes.shape[0]))\n    df_py_dtypes.index.name = 'column'\n    return df_py_dtypes"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_list_store(data_frame):\n    '''\n    Return a `pandas.DataFrame` containing Python type information for the\n    columns in `data_frame` and a `gtk.ListStore` matching the contents of the\n    data frame.\n\n    Args:\n\n        data_frame (pandas.DataFrame) : Data frame containing data columns.\n\n    Returns:\n\n        (tuple) : The first element is a data frame as returned by\n            `get_py_dtypes` and the second element is a `gtk.ListStore`\n            matching the contents of the data frame.\n    '''\n    df_py_dtypes = get_py_dtypes(data_frame)\n    list_store = gtk.ListStore(*df_py_dtypes.dtype)\n    for i, row_i in data_frame.iterrows():\n        list_store.append(row_i.tolist())\n    return df_py_dtypes, list_store", "response": "Returns a pandas. DataFrame containing Python type information for the\nvms columns in data_frame and a gtk. ListStore matching the contents of the data frame."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_columns(tree_view, df_py_dtypes, list_store):\n    '''\n    Add columns to a `gtk.TreeView` for the types listed in `df_py_dtypes`.\n\n    Args:\n\n        tree_view (gtk.TreeView) : Tree view to append columns to.\n        df_py_dtypes (pandas.DataFrame) : Data frame containing type\n            information for one or more columns in `list_store`.\n        list_store (gtk.ListStore) : Model data.\n\n    Returns:\n\n        None\n    '''\n    tree_view.set_model(list_store)\n\n    for column_i, (i, dtype_i) in df_py_dtypes[['i', 'dtype']].iterrows():\n        tree_column_i = gtk.TreeViewColumn(column_i)\n        tree_column_i.set_name(column_i)\n        if dtype_i in (int, long):\n            property_name = 'text'\n            cell_renderer_i = gtk.CellRendererSpin()\n        elif dtype_i == float:\n            property_name = 'text'\n            cell_renderer_i = gtk.CellRendererSpin()\n        elif dtype_i in (bool, ):\n            property_name = 'active'\n            cell_renderer_i = gtk.CellRendererToggle()\n        elif dtype_i in (str, ):\n            property_name = 'text'\n            cell_renderer_i = gtk.CellRendererText()\n        else:\n            raise ValueError('No cell renderer for dtype: %s' % dtype_i)\n        cell_renderer_i.set_data('column_i', i)\n        cell_renderer_i.set_data('column', tree_column_i)\n        tree_column_i.pack_start(cell_renderer_i, True)\n        tree_column_i.add_attribute(cell_renderer_i, property_name, i)\n        tree_view.append_column(tree_column_i)", "response": "Add columns to a gtk. TreeView for the types listed in df_py_dtypes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_column_format(tree_column, model_column_index, format_str,\n                      cell_renderer=None):\n    '''\n    Set the text of a cell according to a [format][1] string.\n\n    [1]: https://docs.python.org/2/library/string.html#formatstrings\n\n    Args:\n\n        tree_column (gtk.TreeViewColumn) : Tree view to append columns to.\n        model_column_index (int) : Index in list store model corresponding to\n            tree view column.\n        format_str (str) : Format string as accepted by Python string `format`\n            method (e.g., `'{value}'`).  N.B., the value of a cell is passed to\n            the `format` method as a keyword argument.\n        cell_renderer (gtk.CellRenderer) : Cell renderer for column.  If\n            `None`, defaults to all cell renderers for column.\n\n    Returns:\n\n        None\n    '''\n    def set_property(column, cell_renderer, list_store, iter, store_i):\n        value = list_store[iter][store_i]\n        cell_renderer.set_property('text', format_str.format(value=value))\n    if cell_renderer is None:\n        cells = tree_column.get_cells()\n    else:\n        cells = [cell_renderer]\n    for cell_renderer_i in cells:\n        tree_column.set_cell_data_func(cell_renderer_i, set_property,\n                                       model_column_index)", "response": "Set the text of a column according to a format string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the text of a numeric cell according to SI prefixes.", "response": "def set_column_si_format(tree_column, model_column_index, cell_renderer=None,\n                         digits=2):\n    '''\n    Set the text of a numeric cell according to [SI prefixes][1]\n\n    For example, `1000 -> '1.00k'`.\n\n    [1]: https://en.wikipedia.org/wiki/Metric_prefix#List_of_SI_prefixes\n\n    Args:\n\n        tree_column (gtk.TreeViewColumn) : Tree view to append columns to.\n        model_column_index (int) : Index in list store model corresponding to\n            tree view column.\n        cell_renderer (gtk.CellRenderer) : Cell renderer for column.  If\n            `None`, defaults to all cell renderers for column.\n        digits (int) : Number of digits after decimal (default=2).\n\n    Returns:\n\n        None\n    '''\n    def set_property(column, cell_renderer, list_store, iter, store_i):\n        cell_renderer.set_property('text', si_format(list_store[iter][store_i],\n                                                     digits))\n    if cell_renderer is None:\n        cells = tree_column.get_cells()\n    else:\n        cells = [cell_renderer]\n    for cell_renderer_i in cells:\n        tree_column.set_cell_data_func(cell_renderer_i, set_property,\n                                       model_column_index)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef on_edited_dataframe_sync(cell_renderer, iter, new_value, column,\n                             df_py_dtypes, list_store, df_data):\n    '''\n    Handle the `'edited'` signal from a `gtk.CellRenderer` to:\n\n     * Update the corresponding entry in the list store.\n     * Update the corresponding entry in the provided data frame instance.\n\n    The callback can be connected to the cell renderer as follows:\n\n        cell_renderer.connect('edited', on_edited_dataframe_sync, column,\n                              list_store, df_py_dtypes, df_data)\n\n    where `column` is the `gtk.TreeViewColumn` the cell renderer belongs to,\n    and `df_py_dtypes` and `list_store` are the return values from calling\n    `get_list_store` on the `df_data` data frame.\n\n    Args:\n\n        cell_renderer (gtk.CellRenderer)\n        iter (str) : Gtk TreeView iterator\n        new_value (str) : New value resulting from edit operation.\n        column (gtk.TreeViewColumn) : Column containing edited cell.\n        df_py_dtypes (pandas.DataFrame) : Data frame containing type\n            information for columns in tree view (and `list_store`).\n        list_store (gtk.ListStore) : Model containing data bound to tree view.\n        df_data (pandas.DataFrame) : Data frame containing data in `list_store`.\n\n    Returns:\n\n        None\n    '''\n    # Extract name of column (name of TreeView column must match data frame\n    # column name).\n    column_name = column.get_name()\n    # Look up the list store column index and data type for column.\n    i, dtype = df_py_dtypes.ix[column_name]\n    # Update the list store with the new value.\n    if dtype == float:\n        value = si_parse(new_value)\n    elif dtype == bool:\n        value = not list_store[iter][i]\n\n    if value == list_store[iter][i]:\n        # Value has not changed.\n        return False\n    list_store[iter][i] = value\n    # Update the data frame with the new value.\n    df_data[column_name].values[int(iter)] = value\n    return True", "response": "This function is called when a cell is edited and the new value is returned from the edit operation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving if the given PID file is staled.", "response": "def remove_if_stale_pidfile(pidfile):\n    \"\"\"\n    @pidfile: PID file to remove if it is staled.\n\n    Exceptions are logged and are not propagated.\n    \"\"\"\n    c14n_prog_name = lambda arg: os.path.basename(re.sub(r'\\.py$', '', arg))\n    try:\n        try:\n            pid_maydaemon = int(file(pidfile).readline().strip())\n        except IOError, e:\n            if e.errno == errno.ENOENT:\n                return # nothing to suppress, so do nothing...\n            raise\n        # Who are we?\n        i_am = c14n_prog_name(sys.argv[0])\n        try:\n            other_cmdline = file(os.path.join(SLASH_PROC, str(pid_maydaemon), PROG_CMDLN)).read().split('\\0')\n            if len(other_cmdline) and other_cmdline[-1] == \"\":\n                other_cmdline.pop()\n        except IOError, e:\n            if e.errno == errno.ENOENT:\n                # no process with the PID extracted from the\n                # pidfile, so no problem to remove the latter\n                os.unlink(pidfile)\n                return\n            raise\n        # Check the whole command line of the other process\n        if i_am in map(c14n_prog_name, other_cmdline):\n            log.warning(\"A pidfile %r already exists (contains pid %d) and the correponding process command line contains our own name %r\",\n                        pidfile, pid_maydaemon, i_am)\n            return\n        # It may not be us, but we must be quite sure about that so also try\n        # to validate with the name of the executable.\n        full_pgm = lock_pgm = None\n        try:\n            full_pgm = os.readlink(os.path.join(SLASH_PROC, str(pid_maydaemon), PROG_SLINK))\n            lock_pgm = os.path.basename(full_pgm)\n        except OSError, e:\n            if e.errno == errno.EACCES:\n                # We consider it's ok not being able to access\n                # \"/proc/<pid>/exe\" if we could previously access\n                # \"/proc/<pid>/cmdline\", because if we do not have\n                # the needed permissions to run the daemon this will\n                # be catched latter (potentially when creating our\n                # own pidfile)\n                lock_pgm = None\n            else:\n                raise\n        if i_am == lock_pgm:\n            log.warning(\"A pidfile %r already exists (contains pid %d) and an executable with our name %r is runnning with that pid.\",\n                        pidfile, pid_maydaemon, i_am)\n            return\n        # Ok to remove the previously existing pidfile now.\n        log.info(\"A pidfile %r already exists (contains pid %d) but the corresponding process does not seem to match with our own name %r.  \"\n                 \"Will remove the pidfile.\", pidfile, pid_maydaemon, i_am)\n        log.info(\"Splitted command line of the other process: %s\", other_cmdline)\n        if lock_pgm:\n            log.info(\"Name of the executable the other process comes from: %s\", full_pgm)\n        os.unlink(pidfile)\n        return\n    except Exception: # pylint: disable-msg=W0703\n        log.exception(\"unexpected error\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef lock_pidfile_or_die(pidfile):\n    pid = os.getpid()\n    try:\n        remove_if_stale_pidfile(pidfile)\n        pid_write_file = pidfile + '.' + str(pid)\n        fpid = open(pid_write_file, 'w')\n        try:\n            fpid.write(\"%s\\n\" % pid)\n        finally:\n            fpid.close()\n        if not take_file_lock(pid_write_file, pidfile, \"%s\\n\" % pid):\n            sys.exit(1)\n    except SystemExit:\n        raise\n    except Exception:\n        log.exception(\"unable to take pidfile\")\n        sys.exit(1)\n    return pid", "response": "Lock a file and return the PID."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef daemonize():\n    try:\n        pid = os.fork()\n        if pid > 0:\n            os._exit(0) # pylint: disable-msg=W0212\n    except OSError, e:\n        log.exception(\"first fork() failed: %d (%s)\", e.errno, e.strerror)\n        sys.exit(1)\n\n    os.setsid()\n    os.umask(0)\n    os.chdir(\"/\")\n\n    try:\n        pid = os.fork()\n        if pid > 0:\n            os._exit(0) # pylint: disable-msg=W0212\n    except OSError, e:\n        log.exception(\"second fork() failed: %d (%s)\", e.errno, e.strerror)\n        sys.exit(1)\n\n    try:\n        devnull_fd = os.open(os.devnull, os.O_RDWR)\n\n        for stdf in (sys.__stdout__, sys.__stderr__):\n            try:\n                stdf.flush()\n            except Exception: # pylint: disable-msg=W0703,W0704\n                pass\n\n        for stdf in (sys.__stdin__, sys.__stdout__, sys.__stderr__):\n            try:\n                os.dup2(devnull_fd, stdf.fileno())\n            except OSError: # pylint: disable-msg=W0704\n                pass\n    except Exception: # pylint: disable-msg=W0703\n        log.exception(\"error during file descriptor redirection\")", "response": "Daemonize the current process."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nredirect a system stream to a specified file.", "response": "def redirect_stream(system_stream, target_stream):\n        \"\"\" Redirect a system stream to a specified file.\n            `system_stream` is a standard system stream such as\n            ``sys.stdout``. `target_stream` is an open file object that\n            should replace the corresponding system stream object.\n            If `target_stream` is ``None``, defaults to opening the\n            operating system's null device and using its file descriptor.\n            \"\"\"\n        if target_stream is None:\n            target_fd = os.open(os.devnull, os.O_RDWR)\n        else:\n            target_fd = target_stream.fileno()\n        os.dup2(target_fd, system_stream.fileno())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ensure_utf8_streams():\n\n        def ensure_utf8_stream(stream):\n            if not isinstance(stream, io.StringIO):\n                stream = getwriter(\"utf-8\")(getattr(stream, \"buffer\", stream))\n                stream.encoding = \"utf-8\"\n            return stream\n\n        sys.stdout, sys.stderr = (ensure_utf8_stream(s)\n                                  for s in (sys.stdout, sys.stderr))", "response": "Forces UTF - 8 on stdout and stderr."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef event(self, name, etype, **info):\n        if etype not in (\"begin\", \"end\", \"single\"):\n            raise ValueError(\"Event type must any of the following: 'begin', \"\n                             \"'end', 'single'\")\n        for handler in logging.getLogger().handlers:\n            if isinstance(handler, MongoLogHandler):\n                data = {\"session\": handler.log_id,\n                        \"instance\": handler.node_id,\n                        \"time\": time(),\n                        \"domain\": self.__class__.__name__,\n                        \"name\": name,\n                        \"type\": etype}\n                dupkeys = set(data.keys()).intersection(set(info.keys()))\n                if len(dupkeys) > 0:\n                    raise ValueError(\"Event kwargs may not contain %s\" %\n                                     dupkeys)\n                data.update(info)\n                handler.events.insert(data, w=0)", "response": "Records an event to MongoDB."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconfiguring the ES ports.", "response": "def configure(name, host, port, auth, current):\n    '''\n    Configure is used to add various ES ports you are working on.\n    The user can add as many es ports as the one wants,\n    but one will remain active at one point.\n    '''\n    Config = ConfigParser.ConfigParser()\n    if not os.path.exists(os.path.dirname(filename)):\n        try:\n            os.makedirs(os.path.dirname(filename))\n        except Exception as e:\n            click.echo(e)\n            return\n    section_name = None\n    if(current.lower() == 'y'):\n        section_name = 'Current'\n        change_current()\n    else:\n        section_name = name.capitalize()\n    cfgfile = open(filename,'a')\n    Config.add_section(section_name)\n    Config.set(section_name,'host',host)\n    Config.set(section_name,'port',port)\n    Config.set(section_name,'auth',auth)\n    Config.set(section_name,'name',name.capitalize())\n    Config.write(cfgfile)\n    cfgfile.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef content_item(path1, path2, path_sep='/'):\n    p1_parts = path1.split(path_sep)\n    p2_parts = path2.split(path_sep)\n    # special case when path1 is root\n    if path1 == path_sep and len(p2_parts) >= 2:\n        return p2_parts[1]\n    if len(p2_parts) <= len(p1_parts):\n        return ''\n    for i, item in enumerate(p1_parts):\n        if item != p2_parts[i]:\n            return ''\n    return p2_parts[i+1]", "response": "get the content item of a path1 and path2"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncompares two path strings.", "response": "def compare_path_strings(path1, path2, path_sep='/'):\n    \"\"\"\n    find out, if path1 is a file, or a directory (or unknown).\n    \"\"\"\n    if len(path2) < len(path1):\n        return 0\n    if path1 == path2:\n        return ISFILE\n    else:\n        p1_parts = path1.split(path_sep)\n        p2_parts = path2.split(path_sep)\n        if len(p2_parts) < len(p1_parts):\n            return 0\n        else:\n            return compare_parts(p1_parts, p2_parts)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef compare_parts(list1, list2):\n\n    for i, item in enumerate(list1):\n        if item != list2[i]:\n            return 0\n    if len(list2) > len(list1):\n        return ISDIR\n    else:\n        return ISFILE", "response": "compare list1 and list2 to return the first item that matches list2"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend some e - mail using a template.", "response": "def sendTemplate(mailer, sender, recipient, template, context, hook=_nop):\n    \"\"\"\n    Simple case for sending some e-mail using a template.\n    \"\"\"\n    headers, parts = template.evaluate(context)\n    headers[\"From\"] = sender\n    headers[\"To\"] = recipient\n    hook(headers, parts)\n\n    content = mime.buildMessage(headers, parts)\n    return mailer.send(sender, recipient, content)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef export_cmd(cmd, src_path, dest_dir=None, item_id=None, export_format=None, scale=None):\n  ''' Executes a `sketchtool export` command and returns formatted output\n\n  :src_path: File to export. :type <str>\n  :dest_dir: Items are exported at /dest_dir/name@scale.export_format e.g. `~/Desktop/Page 1@2x.png`\n  :param export_format: 'png', 'pdf' etc. :type <ExportFormat>\n  :param scale: Specify as 1.0, 2.0 etc. :type <float>\n  :param item_id: id or name of an Exportable :type <str>\n  :returns: list of exported item paths\n  '''\n  cmd.extend([src_path])\n\n  if not dest_dir:\n    dest_dir = mkdtemp(prefix='pyglass')\n\n  cmd.extend(['--output=%s' % dest_dir])\n\n  if export_format:\n    cmd.extend(['--formats=%s' % export_format])\n\n  if scale:\n    cmd.extend(['--scales=%s' % scale])\n\n  if item_id:\n    cmd.extend(['--items=%s' % item_id])\n\n  logger.debug(u'Executing cmd: %s' % cmd)\n  exported_str = execute(cmd)\n  logger.debug(u'Raw result: %s' % exported_str)\n  # Raw result is in the form: 'Exported <item-name-1>\\nExported <item-name-2>\\n'\n\n  exported_items = [os.path.join(dirpath, f)\n                    for dirpath, dirnames, files in os.walk(dest_dir)\n                    for f in files if f.endswith('.%s' % export_format)]\n\n  return exported_items", "response": "Executes a sketchtool export command and returns formatted output"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_binaries():\n    paths = []\n    for arp in [False, True]:\n        paths.append(get_binary(arp=arp))\n    return paths", "response": "Download and return paths of all platform - specific binaries"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef layer_sizes(X, Y):\n    n_x = X.shape[0]  # size of input layer\n    n_h = 4\n    n_y = Y.shape[0]  # size of output layer\n    return (n_x, n_h, n_y)", "response": "Returns the sizes of the layer in the order of the input and output."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninitializing parameters for the last n_x hidden layers.", "response": "def initialize_parameters(n_x, n_h, n_y):\n    \"\"\"\n    Argument:\n    n_x -- size of the input layer\n    n_h -- size of the hidden layer\n    n_y -- size of the output layer\n\n    Returns:\n    params -- python dictionary containing your parameters:\n                    W1 -- weight matrix of shape (n_h, n_x)\n                    b1 -- bias vector of shape (n_h, 1)\n                    W2 -- weight matrix of shape (n_y, n_h)\n                    b2 -- bias vector of shape (n_y, 1)\n    \"\"\"\n\n    np.random.seed(2)\n\n    W1 = np.random.randn(n_h, n_x) * 0.01\n    b1 = np.zeros((n_h, 1))\n    W2 = np.random.randn(n_y, n_h) * 0.01\n    b2 = np.zeros((n_y, 1))\n\n    assert (W1.shape == (n_h, n_x))\n    assert (b1.shape == (n_h, 1))\n    assert (W2.shape == (n_y, n_h))\n    assert (b2.shape == (n_y, 1))\n\n    parameters = {\"W1\": W1,\n                  \"b1\": b1,\n                  \"W2\": W2,\n                  \"b2\": b2}\n\n    return parameters"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the A2 and cache for the forward propagation of X.", "response": "def forward_propagation(X, parameters):\n    \"\"\"\n    Argument:\n    X -- input data of size (n_x, m)\n    parameters -- python dictionary containing your parameters (output of initialization function)\n\n    Returns:\n    A2 -- The sigmoid output of the second activation\n    cache -- a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\"\n    \"\"\"\n    # Retrieve each parameter from the dictionary \"parameters\"\n    W1 = parameters[\"W1\"]\n    b1 = parameters[\"b1\"]\n    W2 = parameters[\"W2\"]\n    b2 = parameters[\"b2\"]\n\n    # Implement Forward Propagation to calculate A2 (probabilities)\n    Z1 = np.dot(W1, X) + b1\n    A1 = np.tanh(Z1)\n    Z2 = np.dot(W2, A1) + b2\n    A2 = sigmoid(Z2)\n\n    assert (A2.shape == (1, X.shape[1]))\n\n    cache = {\"Z1\": Z1,\n             \"A1\": A1,\n             \"Z2\": Z2,\n             \"A2\": A2}\n\n    return A2, cache"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute the cross - entropy cost given in equation 13.", "response": "def compute_cost(A2, Y):\n    \"\"\"\n    Computes the cross-entropy cost given in equation (13)\n\n    Arguments:\n    A2 -- The sigmoid output of the second activation, of shape (1, number of examples)\n    Y -- \"true\" labels vector of shape (1, number of examples)\n    parameters -- python dictionary containing your parameters W1, b1, W2 and b2\n\n    Returns:\n    cost -- cross-entropy cost given equation (13)\n    \"\"\"\n\n    m = Y.shape[1]  # number of example\n\n    # Compute the cross-entropy cost\n    logprobs = np.multiply(np.log(A2), Y) + np.multiply(np.log(1 - A2), (1 - Y))\n    cost = -np.sum(logprobs) / m\n\n    cost = np.squeeze(cost)  # makes sure cost is the dimension we expect.\n    # E.g., turns [[17]] into 17\n\n    assert (isinstance(cost, float))\n\n    return cost"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef backward_propagation(parameters, cache, X, Y):\n    m = X.shape[1]\n\n    # First, retrieve W1 and W2 from the dictionary \"parameters\".\n    W1 = parameters[\"W1\"]\n    W2 = parameters[\"W2\"]\n\n    # Retrieve also A1 and A2 from dictionary \"cache\".\n    A1 = cache[\"A1\"]\n    A2 = cache[\"A2\"]\n\n    # Backward propagation: calculate dW1, db1, dW2, db2.\n    dZ2 = A2 - Y\n    dW2 = 1.0 / m * np.dot(dZ2, A1.T)\n    db2 = 1.0 / m * np.sum(dZ2, axis=1, keepdims=True)\n    dZ1 = W2.T * dZ2 * (1 - np.power(A1, 2))\n    dW1 = 1.0 / m * np.dot(dZ1, X.T)\n    db1 = 1.0 / m * np.sum(dZ1, axis=1, keepdims=True)\n\n    grads = {\"dW1\": dW1,\n             \"db1\": db1,\n             \"dW2\": dW2,\n             \"db2\": db2}\n\n    return grads", "response": "Implement the backward propagation using the instructions above."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate the parameters using the gradient descent update rule given above", "response": "def update_parameters(parameters, grads, learning_rate=1.2):\n    \"\"\"\n    Updates parameters using the gradient descent update rule given above\n\n    Arguments:\n    parameters -- python dictionary containing your parameters\n    grads -- python dictionary containing your gradients\n\n    Returns:\n    parameters -- python dictionary containing your updated parameters\n    \"\"\"\n    # Retrieve each parameter from the dictionary \"parameters\"\n    W1 = parameters[\"W1\"]\n    b1 = parameters[\"b1\"]\n    W2 = parameters[\"W2\"]\n    b2 = parameters[\"b2\"]\n\n    # Retrieve each gradient from the dictionary \"grads\"\n    dW1 = grads[\"dW1\"]\n    db1 = grads[\"db1\"]\n    dW2 = grads[\"dW2\"]\n    db2 = grads[\"db2\"]\n\n    # Update rule for each parameter\n    W1 -= learning_rate * dW1\n    b1 -= learning_rate * db1\n    W2 -= learning_rate * dW2\n    b2 -= learning_rate * db2\n\n    parameters = {\"W1\": W1,\n                  \"b1\": b1,\n                  \"W2\": W2,\n                  \"b2\": b2}\n\n    return parameters"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef nn_model(X, Y, n_h, num_iterations=10000, print_cost=False):\n\n    np.random.seed(3)\n    n_x = layer_sizes(X, Y)[0]\n    n_y = layer_sizes(X, Y)[2]\n\n    # Initialize parameters, then retrieve W1, b1, W2, b2.\n    # Inputs: \"n_x, n_h, n_y\". Outputs = \"W1, b1, W2, b2, parameters\".\n    parameters = initialize_parameters(n_x, n_h, n_y)\n    W1 = parameters[\"W1\"]\n    b1 = parameters[\"b1\"]\n    W2 = parameters[\"W2\"]\n    b2 = parameters[\"b2\"]\n\n    # Loop (gradient descent)\n\n    for i in range(0, num_iterations):\n\n        # Forward propagation. Inputs: \"X, parameters\". Outputs: \"A2, cache\".\n        A2, cache = forward_propagation(X, parameters)\n\n        # Cost function. Inputs: \"A2, Y, parameters\". Outputs: \"cost\".\n        cost = compute_cost(A2, Y, parameters)\n\n        # Backpropagation. Inputs: \"parameters, cache, X, Y\". Outputs: \"grads\".\n        grads = backward_propagation(parameters, cache, X, Y)\n\n        # Gradient descent parameter update. Inputs: \"parameters, grads\". Outputs: \"parameters\".\n        parameters = update_parameters(parameters, grads)\n\n        # Print the cost every 1000 iterations\n        if print_cost and i % 1000 == 0:\n            print(\"Cost after iteration %i: %f\" % (i, cost))\n\n    return parameters", "response": "This function computes the model for the hidden layer."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npredict a class for each example in X.", "response": "def predict(parameters, X):\n    \"\"\"\n    Using the learned parameters, predicts a class for each example in X\n\n    Arguments:\n    parameters -- python dictionary containing your parameters\n    X -- input data of size (n_x, m)\n\n    Returns\n    predictions -- vector of predictions of our model (red: 0 / blue: 1)\n    \"\"\"\n\n    # Computes probabilities using forward propagation,\n    # and classifies to 0/1 using 0.5 as the threshold.\n    A2, cache = forward_propagation(X, parameters)\n    predictions = np.array([1 if (i > 0.5) else 0 for i in A2[0]])\n\n    return predictions"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npushes a message to the server.", "response": "def server_chan_push(title, content, key=None):\n    \"\"\"\u4f7f\u7528server\u9171\u63a8\u9001\u6d88\u606f\u5230\u5fae\u4fe1\uff0c\u5173\u4e8eserver\u9171\uff0c\n    \u8bf7\u53c2\u8003\uff1ahttp://sc.ftqq.com/3.version\n\n    :param title: str\n        \u6d88\u606f\u6807\u9898\n    :param content: str\n        \u6d88\u606f\u5185\u5bb9\uff0c\u6700\u957f64Kb\uff0c\u53ef\u7a7a\uff0c\u652f\u6301MarkDown\n    :param key: str\n        \u4ece[Server\u9171](https://sc.ftqq.com/3.version)\u83b7\u53d6\u7684key\n    :return: None\n    \"\"\"\n    if not key:\n        raise ValueError(\"\u8bf7\u914d\u7f6ekey\uff0c\u5982\u679c\u8fd8\u6ca1\u6709key\uff0c\"\n                         \"\u53ef\u4ee5\u5230\u8fd9\u91cc\u7533\u8bf7\u4e00\u4e2a\uff1ahttp://sc.ftqq.com/3.version\")\n    url = 'https://sc.ftqq.com/%s.send' % key\n    requests.post(url, data={'text': title, 'desp': content})"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bear_push(title, content, send_key=None):\n    if not send_key:\n        raise ValueError(\"\u8bf7\u914d\u7f6e\u901a\u9053send_key\uff0c\u5982\u679c\u8fd8\u6ca1\u6709\uff0c\"\n                         \"\u53ef\u4ee5\u5230\u8fd9\u91cc\u521b\u5efa\u901a\u9053\u83b7\u53d6\uff1ahttps://pushbear.ftqq.com/admin/#/\")\n    api = \"https://pushbear.ftqq.com/sub\"\n    requests.post(api, data={'text': title, 'desp': content, \"sendkey\": send_key})", "response": "Push a new item to the pushbear API."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send_email(sender, pw, to, subject, content, files=None, service='163'):\n    se = EmailSender(from_=sender, pw=pw, service=service)\n    se.send_email(to=to, subject=subject, content=content, files=files)\n    se.quit()", "response": "send email to 163 mailbox"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconstructs a message with the given parameters.", "response": "def _construct_msg(self, to, subject, content, files=None):\n        \"\"\"\u6784\u9020email\u4fe1\u606f\n\n        parameters\n        ---------------\n        subject     \u90ae\u4ef6\u4e3b\u9898\n        content     \u90ae\u4ef6\u6587\u672c\u5185\u5bb9\n        files       \u9644\u4ef6\uff08list\uff09\n                    \u53ef\u4ee5\u662f\u76f8\u5bf9\u8def\u5f84\u4e0b\u7684\u6587\u4ef6\uff0c\u4e5f\u53ef\u4ee5\u662f\u7edd\u5bf9\u8def\u5f84\u4e0b\u7684\u6587\u4ef6\uff1b\n                    \u63a8\u8350\u4f7f\u7528\u7edd\u5bf9\u8def\u5f84\u3002\n\n        return\n        --------------\n        msg         \u6784\u9020\u597d\u7684\u90ae\u4ef6\u4fe1\u606f\n        \"\"\"\n        msg = MIMEMultipart()\n        msg['from'] = self.from_\n        msg['to'] = to\n        msg['subject'] = subject\n        txt = MIMEText(content)\n        msg.attach(txt)\n\n        # \u6dfb\u52a0\u9644\u4ef6\n        if files is not None:\n            for file in files:\n                f = MIMEApplication(open(file, 'rb').read())\n                f.add_header('Content-Disposition', 'attachment',\n                             filename=os.path.split(file)[-1])\n                msg.attach(f)\n\n        return msg"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef nodes(self, node=None):\n        '''walks through tree and yields each node'''\n        if node is None:\n            for root in self.stack:\n                yield from self.nodes(root)\n        else:\n            yield node\n            if node.is_container():\n                for child in node.children:\n                    yield from self.nodes(child)", "response": "walks through tree and yields each node"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef debug_print(self):\n        '''Print tree'''\n\n        def print_node(node, depth=0):\n            print('{}{}'.format('  ' * depth, repr(node)))\n            if node.is_container():\n               for child in node.children:\n                   print_node(child, depth + 1)\n\n        for root in self.stack:\n            print_node(root)", "response": "Print tree with debug information."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef context(self, message):\n        '''\n        Function decorator which adds \"context\" around a group of TestCases and may have\n        a `before` and `after` func.\n\n            >>> s = Suite()\n            >>> @s.context('context 1')\n            ... def _():\n            ...     @s.before\n            ...     def _(): print('before 1 called.')\n            ...     @s.it('runs a test')\n            ...     def _(): print('test case 1 called.')\n            >>> @s.context('context 2')\n            ... def _():\n            ...     @s.before\n            ...     def _(): print('before 2 called.')\n            ...     @s.it('runs a test')\n            ...     def _(): print('test case 2 called.')\n            >>> tc1 = list(s.nodes())[2]\n            >>> tc1.run()\n            before 1 called.\n            test case 1 called.\n            >>> tc1 = list(s.nodes())[4]\n            >>> tc1.run()\n            before 2 called.\n            test case 2 called.\n        '''\n        def decorator(context_func):\n            self.push_container(message)\n            context_func()\n            self.pop_container()\n        return decorator", "response": "A decorator which adds a context around a group of TestCases and may have\n            a before and after func."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef it(self, message, repeat=None):\n        '''\n        Function decorator which adds a TestCase to the Suite\n\n            >>> s = Suite()\n            >>> @s.it('always passes')\n            ... def _(): pass\n            >>> list(s.nodes())\n            [<Container: root>, <TestCase:  always passes>]\n\n\n        `repeat` will add multiple test cases with extra parameters.\n\n            >>> s = Suite()\n            >>> @s.it('a={} b={}', repeat=[(1, 2), (3, 4)])\n            ... def _(a, b): pass\n            >>> list(s.nodes())\n            [<Container: root>, <TestCase:  a=1 b=2>, <TestCase:  a=3 b=4>]\n        '''\n        def decorator(test_func):\n            if repeat:\n                for set_of_args in repeat:\n                    self.add_test(message, test_func, set_of_args)\n            else:\n                self.add_test(message, test_func)\n        return decorator", "response": "Function decorator which adds a TestCase to the Suite and returns the ID of the current instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nviews for setting cookies on spammers.", "response": "def spammer_view(request):\n    \"\"\"View for setting cookies on spammers.\"\"\"\n\n    # Permits use of CSRF middleware\n    context = RequestContext(request, {})\n    template = Template(\"\")\n\n    response = HttpResponse(template.render(context))\n    # Sets a cookie with a 10 years lifetime, accessible only via HTTP:\n    response.set_cookie(COOKIE_KEY, value=COOKIE_SPAM, httponly=True,\n                        expires=datetime.now()+timedelta(days=3650))\n    \n    if DJANGOSPAM_LOG:\n        log(\"BLOCK RESPONSE\", request.method, request.path_info,\n            request.META.get(\"HTTP_USER_AGENT\", \"undefined\"))\n\n    return response"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload an object from a module by name", "response": "def load_object_by_name(object_name):\n    \"\"\"Load an object from a module by name\"\"\"\n    mod_name, attr = object_name.rsplit('.', 1)\n    mod = import_module(mod_name)\n    return getattr(mod, attr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef bench_factory():\n\n    class TestSchema(BaseSchema):\n        attr_1 = StringNode()\n        attr_2 = IntegerNode()\n\n        @property\n        def attr_3(self):\n            return 'FooBar'\n\n        @staticmethod\n        def prepare_attr_1(value):\n            return 'Attr#{}'.format(value)\n\n        @staticmethod\n        def prepare_attr_2(value):\n            return 'Attr#2{}'.format(value)\n\n    return [TestSchema(**obj) for obj in object_loader()]", "response": "Benchmark for 1000 objects with 2 fields.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbenchmarking for 1000 objects with 2 fields.", "response": "def bench_voluptuous():\n    \"\"\"Benchmark for 1000 objects with 2 fields.\n    \"\"\"\n    schema = Schema({\n        Required('attr_1'): str,\n        Required('attr_2'): int})\n\n    return [schema(obj) for obj in object_loader()]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning an instance of Locale corresponding to the string representation of a locale.", "response": "def from_string(locale, strict=True):\n        \"\"\"\n        Return an instance ``Locale`` corresponding to the string\n        representation of a locale.\n\n\n        @param locale: a string representation of a locale, i.e., a ISO 639-3\n           alpha-3 code (or alpha-2 code), optionally followed by a dash\n           character ``-`` and a ISO 3166-1 alpha-2 code.\n\n        @param strict: indicate whether the string representation of a locale\n            has to be strictly compliant with RFC 4646, or whether a Java-style\n            locale (character ``_`` instead of ``-``) is accepted.\n\n\n        @return: an instance ``Locale``.\n        \"\"\"\n        (language_code, country_code) = Locale.decompose_locale(locale, strict)\n        return Locale(language_code, country_code)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_http_string(self):\n        return self.language_code[:2] if self.country_code is None \\\n                else '%s-%s' % (self.language_code[:2], self.country_code)", "response": "Return the string representation of the locale compatible with HTTP."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndecomposing a locale into a language code a country code and a second code.", "response": "def decompose_locale(locale, strict=True):\n        \"\"\"\n        Return the decomposition of the specified locale into a language code\n        and a country code.\n\n\n        @param locale: a string representation of a locale, i.e., a ISO 639-3\n            alpha-3 code (or alpha-2 code), optionally followed by a dash\n            character ``-`` and a ISO 3166-1 alpha-2 code.  If ``None`` passed,\n            the function returns the default locale, i.e., standard English\n            ``('eng', None)``.\n\n        @param strict: indicate whether the string representation of a locale\n            has to be strictly compliant with RFC 4646, or whether a Java-\n            style locale (character ``_`` instead of ``-``) is accepted.\n\n\n        @return: a tuple ``(language_code, country_code)``, where the first\n                 code represents a ISO 639-3 alpha-3 code (or alpha-2 code),\n                 and the second code a ISO 3166-1 alpha-2 code.\n        \"\"\"\n        if locale is None:\n            return ('eng', None)\n\n        match = REGEX_LOCALE.match(locale)\n        if match is None:\n            if strict == True:\n                raise Locale.MalformedLocaleException()\n            match = REGEX_JAVA_LOCALE.match(locale)\n            if match is None:\n                raise Locale.MalformedLocaleException()\n\n        (_, locale_language_code, locale_country_code, language_code) =  match.groups()\n        return (locale_language_code, locale_country_code) if language_code is None \\\n            else (language_code, None)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading the drops object from the given dropin.", "response": "def load_drops(self, dropin):\n        \"\"\"Load `drops` from the given dropin.\n\n        Args:\n            dropin (string): path of a dropin, e.g. dropin.auth\n\n        Returns:\n            An iterable contains the drops object in the given dropin\n\n        This method load drops object by some sort of convension. For example, assuming\n        we want to load drops type `models` from dropin `dropin.articls`. The drops are\n        discoveried with the following sequence::\n\n            import dropin.articles\n            drops = dropin.articles.models\n\n        if anything goes wrong, next try is ::\n\n            import dropin.articles.models as drops\n\n        if the current drops object has attribute **__drops__** ::\n\n            drops = drops.__drops__\n\n        if the current drops object is a callable ::\n\n            drops = drops()\n\n        if not drops was found, an empty list is returned.\n\n        \"\"\"\n        obj = load_object(dropin)\n        try:\n            drops = getattr(obj, self.drops_type)\n        except AttributeError:\n            try:\n                drops = load_object('%s.%s' % (dropin, self.drops_type))\n            except ImportError:\n                drops = None\n        if hasattr(drops, '__drops__'):\n            drops = drops.__drops__\n        if callable(drops):\n            drops = drops(self.app)\n        return drops or []"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef register_drops(self, dropin):\n        drops = self.app.extensions['dropin'].setdefault(self.drops_type, [])\n        drops.extend(self.load_drops(dropin))", "response": "Register the drops in given dropin to a flask app."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmerge the schema into this instance.", "response": "def merge(cls, *others):\n        \"\"\"\n        Merge the `others` schema into this instance.\n\n        The values will all be read from the provider of the original object.\n        \"\"\"\n        for other in others:\n            for k, v in other:\n                setattr(cls, k, BoundValue(cls, k, v.value))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_tracker_url(ticket_url):\n    if ticket_url.startswith('http://') or ticket_url.startswith('https://'):\n        o = urlparse(ticket_url)\n        scheme, netloc = o.scheme, o.netloc\n    else:\n        scheme = 'http'\n        (netloc, _) = ticket_url.split('/', 1)\n    return '%s://%s' % (scheme, netloc)", "response": "Given a ticket url return the URL that the tracker will be used."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_valid(self, value):\n        if not self.is_array:\n            return self._valid(value)\n\n        if isinstance(value, (list, set, tuple)):\n            return all([self._valid(item) for item in value])\n\n        return self._valid(value)", "response": "Validate value before actual instance setting based on type."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef config_dir(self):\n        \"Return dir(self).\"\n\n        my_vars = set(self)\n        skips = self.bad_names | my_vars\n\n        yield from (\n            attr\n            for attr in dir(type(self))\n            if (\n                attr not in skips and\n                not (\n                    attr.startswith('_') and\n                    not attr.startswith('__') and\n                    hasattr(self, attr[1:])\n                ) and hasattr(self, attr)\n            )\n        )\n\n        yield from my_vars", "response": "Return dir ( self )."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmakes an empty object with a new __slots__ definition.", "response": "def _attr_data_(self, slots):\n        \"\"\"\n        Does not work as expected, makes an empty object with a new __slots__\n        definition.\n        \"\"\"\n        self.__attr_data = type(\n            ''.join([type(self).__name__, 'Data']),\n            (),\n            {\n                '__module__': type(self).__module__,\n                '__slots__': tuple(set(slots))\n            }\n        )()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _attr_func_(self):\n        \"Special property containing functions to be lazily-evaluated.\"\n\n        try:\n            return self.__attr_func\n\n        except AttributeError:\n            self.__attr_func = type(\n                ''.join([type(self).__name__, 'EmptyFuncs']),\n                (),\n                {\n                    '__module__': type(self).__module__,\n                    '__slots__': ()\n                }\n            )()\n            return self.__attr_func", "response": "Special property containing functions to be lazily - evaluated."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndoes not work as expected makes an empty object with a new __slots__ definition.", "response": "def _attr_func_(self, slots):\n        \"\"\"\n        Does not work as expected, makes an empty object with a new __slots__\n        definition.\n        \"\"\"\n\n        self.__attr_func = type(\n            ''.join([type(self).__name__, 'Funcs']),\n            (),\n            {\n                '__module__': type(self).__module__,\n                '__slots__': tuple(set(slots))\n            }\n        )()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nuse to lazily - evaluate & memoize an attribute.", "response": "def _loadable_get_(name, self):\n        \"Used to lazily-evaluate & memoize an attribute.\"\n\n        func = getattr(self._attr_func_, name)\n        ret = func()\n        setattr(self._attr_data_, name, ret)\n        setattr(\n            type(self),\n            name,\n            property(\n                functools.partial(self._simple_get_, name)\n            )\n        )\n        delattr(self._attr_func_, name)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _setable_get_(name, self):\n        \"Used to raise an exception for attributes unable to be evaluated yet.\"\n\n        raise AttributeError(\n            \"'{typename}' object has no attribute '{name}'\".format(\n                typename=type(self).__name__,\n                name=name\n            )\n        )", "response": "Used to raise an exception for attributes unable to be evaluated yet."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nuse to set the attribute a single time using the given function.", "response": "def _setable_set_(name, self, func):\n        \"Used to set the attribute a single time using the given function.\"\n\n        setattr(self._attr_data_, name, func())\n\n        if hasattr(self._attr_func_, name):\n            delattr(self._attr_func_, name)\n\n        setattr(\n            type(self),\n            name,\n            property(\n                functools.partial(self._simple_get_, name)\n            )\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreset an attribute ( or adds a new attribute to be lazily - evaluated.", "response": "def _reset_attr(self, name, func=None, doc=None, preload=False):\n        \"Resets an attribute (or adds a new attribute) to be lazily-evaluated.\"\n\n        keys = set(self)\n        if name not in keys:\n            try:\n                data, funcs = zip(*[\n                    (\n                        (\n                            key, (\n                                getattr(self._attr_data_, key)\n                                if hasattr(self._attr_data_, key)\n                                else None\n                            )\n                        ),\n                        (\n                            key, (\n                                getattr(self._attr_func_, key)\n                                if hasattr(self._attr_func_, key)\n                                else None\n                            )\n                        ),\n                    )\n                    for key in keys\n                ])\n\n                keys.add(name)\n                self._attr_data_ = keys\n                self._attr_func_ = keys\n\n                [\n                    setattr(self._attr_data_, key,  value)\n                    for key, value in data\n                    if value is not None\n                ]\n                [\n                    setattr(self._attr_func_, key,  value)\n                    for key, value in funcs\n                    if value is not None\n                ]\n\n            except ValueError:\n                keys.add(name)\n                self._attr_data_ = keys\n                self._attr_func_ = keys\n\n        if hasattr(self._attr_data_, name):\n            delattr(self._attr_data_, name)\n\n        if func is not None:\n            setattr(self._attr_func_, name, func)\n\n        elif hasattr(self._attr_func_, name):\n            delattr(self._attr_func_, name)\n\n        self._set_attr(name, doc, preload)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ev_bias(seq):\n    if len(seq) < 4:\n        return ''\n    if seq == [252, 1, 6, 0]:\n        return '-2/3 EV'\n    if seq == [253, 1, 6, 0]:\n        return '-1/2 EV'\n    if seq == [254, 1, 6, 0]:\n        return '-1/3 EV'\n    if seq == [0, 1, 6, 0]:\n        return '0 EV'\n    if seq == [2, 1, 6, 0]:\n        return '+1/3 EV'\n    if seq == [3, 1, 6, 0]:\n        return '+1/2 EV'\n    if seq == [4, 1, 6, 0]:\n        return '+2/3 EV'\n        # Handle combinations not in the table.\n    a = seq[0]\n    # Causes headaches for the +/- logic, so special case it.\n    if a == 0:\n        return '0 EV'\n    if a > 127:\n        a = 256 - a\n        ret_str = '-'\n    else:\n        ret_str = '+'\n    step = seq[2]  # Assume third value means the step size\n    whole = a / step\n    a = a % step\n    if whole != 0:\n        ret_str = '%s%s ' % (ret_str, str(whole))\n    if a == 0:\n        ret_str += 'EV'\n    else:\n        r = Ratio(a, step)\n        ret_str = ret_str + r.__repr__() + ' EV'\n    return ret_str", "response": "Returns the EV bias for the given sequence."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef download(url):\n    file_name = os.path.split(url)[1]\n    file = urlopen(url)\n    with open(file_name, 'wb') as f:\n        f.write(file.read())\n        print(\"\u6587\u4ef6\u4e0b\u8f7d\u6210\u529f\uff1a%s \" % file_name)", "response": "downloads a file from url"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef open_filechooser(title, parent=None, patterns=None,\n                     folder=None, filter=None, multiple=False,\n                     _before_run=None, action=None):\n    \"\"\"An open dialog.\n\n    :param parent: window or None\n    :param patterns: file match patterns\n    :param folder: initial folder\n    :param filter: file filter\n\n    Use of filter and patterns at the same time is invalid.\n    \"\"\"\n\n    assert not (patterns and filter)\n    if multiple:\n        if action is not None and action != gtk.FILE_CHOOSER_ACTION_OPEN:\n            raise ValueError('`multiple` is only valid for the action '\n                             '`gtk.FILE_CHOOSER_ACTION_OPEN`.')\n        action = gtk.FILE_CHOOSER_ACTION_OPEN\n    else:\n        assert action is not None\n    filechooser = gtk.FileChooserDialog(title,\n                                        parent,\n                                        action,\n                                        (gtk.STOCK_CANCEL, gtk.RESPONSE_CANCEL,\n                                         gtk.STOCK_OPEN, gtk.RESPONSE_OK))\n    if multiple:\n        filechooser.set_select_multiple(True)\n\n    if patterns or filter:\n        if not filter:\n            filter = gtk.FileFilter()\n            for pattern in patterns:\n                filter.add_pattern(pattern)\n        filechooser.set_filter(filter)\n    filechooser.set_default_response(gtk.RESPONSE_OK)\n\n    if folder:\n        filechooser.set_current_folder(folder)\n\n    try:\n        if _before_run is not None:\n            _before_run(filechooser)\n        response = filechooser.run()\n        if response not in (gtk.RESPONSE_OK, gtk.RESPONSE_NONE):\n            return\n\n        if multiple:\n            return filechooser.get_filenames()\n        else:\n            return filechooser.get_filename()\n    finally:\n        _destroy(filechooser)", "response": "An open dialog.\n\n    :param parent: window or None\n    :param patterns: file match patterns\n    :param folder: initial folder\n    :param filter: file filter\n\n    Use of filter and patterns at the same time is invalid."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef save(title='Save', parent=None, current_name='', folder=None,\n         _before_run=None, _before_overwrite=None):\n    \"\"\"Displays a save dialog.\"\"\"\n    filechooser = gtk.FileChooserDialog(title, parent,\n                                        gtk.FILE_CHOOSER_ACTION_SAVE,\n                                        (gtk.STOCK_CANCEL, gtk.RESPONSE_CANCEL,\n                                         gtk.STOCK_SAVE, gtk.RESPONSE_OK))\n    if current_name:\n        filechooser.set_current_name(current_name)\n    filechooser.set_default_response(gtk.RESPONSE_OK)\n\n    if folder:\n        filechooser.set_current_folder(folder)\n\n    path = None\n    while True:\n        if _before_run:\n            _before_run(filechooser)\n            _before_run = None  # XXX: find better implications\n        response = filechooser.run()\n        if response != gtk.RESPONSE_OK:\n            path = None\n            break\n\n        path = filechooser.get_filename()\n        if not os.path.exists(path):\n            break\n\n        if ask_overwrite(path, parent, _before_run=_before_overwrite):\n            break\n        _before_overwrite = None  # XXX: same\n    _destroy(filechooser)\n    return path", "response": "Displays a save dialog."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef animation_dialog(images, delay_s=1., loop=True, **kwargs):\n    '''\n    .. versionadded:: v0.19\n\n    Parameters\n    ----------\n    images : list\n        Filepaths to images or :class:`gtk.Pixbuf` instances.\n    delay_s : float, optional\n        Number of seconds to display each frame.\n\n        Default: ``1.0``.\n    loop : bool, optional\n        If ``True``, restart animation after last image has been displayed.\n\n        Default: ``True``.\n\n    Returns\n    -------\n    gtk.MessageDialog\n        Message dialog with animation displayed in `gtk.Image` widget when\n        dialog is run.\n    '''\n    def _as_pixbuf(image):\n        if isinstance(image, types.StringTypes):\n            return gtk.gdk.pixbuf_new_from_file(image)\n        else:\n            return image\n\n    pixbufs = map(_as_pixbuf, images)\n\n    # Need this to support background thread execution with GTK.\n    gtk.gdk.threads_init()\n\n    dialog = gtk.MessageDialog(**kwargs)\n\n    # Append image to dialog content area.\n    image = gtk.Image()\n    content_area = dialog.get_content_area()\n    content_area.pack_start(image)\n    content_area.show_all()\n\n    stop_animation = threading.Event()\n\n    def _stop_animation(*args):\n        stop_animation.set()\n\n    def _animate(dialog):\n        def __animate():\n            if loop:\n                frames = it.cycle(pixbufs)\n            else:\n                frames = pixbufs\n\n            for pixbuf_i in frames:\n                gobject.idle_add(image.set_from_pixbuf, pixbuf_i)\n                if stop_animation.wait(delay_s):\n                    break\n        thread = threading.Thread(target=__animate)\n        thread.daemon = True\n        thread.start()\n\n    dialog.connect('destroy', _stop_animation)\n    dialog.connect('show', _animate)\n    return dialog", "response": "Create a message dialog with animation."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef count_nans(df):\n    cols = df.columns\n    res = []\n    for col in cols:\n        length = len(df[col])\n        not_nas = len(df[col].dropna())\n        nas = length - not_nas\n        rate = round(nas/length, 4)\n        # add unique value\n        uv = len(df[col].unique())\n        res_ = (col, nas, not_nas, rate, uv)\n        res.append(res_)\n    nas_df = pd.DataFrame(res, columns=['Column', 'NaNs', 'Not_NaNs',\n                                        'Rate', 'UV'])\n    return nas_df", "response": "Count the total number of NaNs in every column\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nattempting to find the project root returns None if not found", "response": "def find_project_dir(path=os.getcwd()):\n    \"\"\"Attempt to find the project root, returns None if not found\"\"\"\n    path_split = os.path.split(path)\n    while path_split[1]:\n        if in_armstrong_project(path):\n            return path\n        path = path_split[0]\n        path_split = os.path.split(path)\n    # we ran out of parents\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngive a list of pathnames returns the longest common leading component", "response": "def _commonprefix(m):\n    \"Given a list of pathnames, returns the longest common leading component\"\n    if not m:\n        return ''\n    prefix = m[0]\n    for item in m:\n        for i in range(len(prefix)):\n            if prefix[:i+1] != item[:i+1]:\n                prefix = prefix[:i]\n                if i == 0:\n                    return ''\n                break\n    return prefix"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef prepare_headers(self, headers, cache_info=None):\n        if self.use_advanced and cache_info:\n            hkeys = headers.keys()\n            if cache_info.access_time and \"If-Modified-Since\" not in hkeys:\n                headers['If-Modified-Since'] = cache_info.access_time.strftime(\n                    \"%a, %d %b %Y %H:%M:%S GMT\"\n                )\n            if cache_info.etag and \"If-None-Match\" not in hkeys:\n                headers['If-None-Match'] = cache_info.etag\n        return headers", "response": "Prepare headers object for request"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(self, url, ignore_access_time=False):\n        key = hashlib.md5(url).hexdigest()\n        accessed = self._cache_meta_get(key)\n\n        if not accessed:\n            # not previously cached\n            self.debug(\"From inet {}\".format(url))\n            return None, None\n\n        if isinstance(accessed, dict):\n            cached = CacheInfo.from_dict(accessed)\n        else:\n            cached = CacheInfo(accessed)\n        now = now_utc()\n        if now - cached.access_time > self.duration and not ignore_access_time:\n            # cached expired -> remove\n            self.debug(\"From inet (expired) {}\".format(url))\n            return None, cached\n\n        try:\n            res = self._cache_get(key)\n        except:\n            self.exception(\"Failed to read cache\")\n            self.debug(\"From inet (failure) {}\".format(url))\n            return None, None\n        self.debug(\"From cache {}\".format(url))\n        return res, cached", "response": "Try to retrieve url from cache if available returns None None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating the cache information for a given url.", "response": "def update(self, url, cache_info=None):\n        \"\"\"\n        Update cache information for url\n\n        :param url: Update for this url\n        :type url: str | unicode\n        :param cache_info: Cache info\n        :type cache_info: floscraper.models.CacheInfo\n        :rtype: None\n        \"\"\"\n        key = hashlib.md5(url).hexdigest()\n        access_time = None\n        if not cache_info:\n            cache_info = CacheInfo()\n        if not access_time:\n            cache_info.access_time = now_utc()\n        self._cache_meta_set(key, cache_info.to_dict())"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef put(self, url, html, cache_info=None):\n        key = hashlib.md5(url).hexdigest()\n\n        try:\n            self._cache_set(key, html)\n        except:\n            self.exception(\"Failed to write cache\")\n            return\n        self.update(url, cache_info)", "response": "Put response into cache"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the row of df_points that is closest to point.", "response": "def find_closest(df_points, point):\n    '''\n    Parameters\n    ----------\n    df_points : pandas.DataFrame\n        Table with at least ``x`` and ``y`` columns.\n    point : pandas.Series\n        Series with at least ``x`` and ``y`` keys.\n\n    Returns\n    -------\n    pandas.Series\n        Row of :data:`df_points` table with point closest to specified\n        :data:`point`.\n\n\n    .. versionchanged:: 0.21\n        Discontinue use of deprecated ``pandas.Series.argmin``.\n    '''\n    return df_points.iloc[((df_points - point) ** 2).sum(axis=1).values\n                          .argmin()]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef uriunsplit(uri):\n    (scheme, authority, path, query, fragment) = uri\n    result = ''\n    if scheme:\n        result += scheme + ':'\n    if authority:\n        result += '//' + authority\n    if path:\n        result += path\n    if query:\n        result += '?' + query\n    if fragment:\n        result += '#' + fragment\n    return result", "response": "Reverse of urisplit()\n\n       >>> uriunsplit(('scheme','authority','path','query','fragment'))\n       \"scheme://authority/path?query#fragment\""}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef join_authority(authority):\n    (user, passwd, host, port) = authority\n    result = ''\n    if user:\n        result += user\n        if passwd:\n            result += ':' + passwd\n        result += '@'\n    result += host\n    if port:\n        result += ':' + port\n    return result", "response": "Join authority with user password host and port."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\njoining a base URL and a URL.", "response": "def urljoin(base, url):\n    \"\"\"Join a base URL and a (possiby relative) URL.\n\n    base - base url\n    url - a (possibly relative) URL to join to the base URL\n\n    Returns the result as an absolute URL.\n\n    \"\"\"\n    import posixpath\n    bscheme, bauthority, bpath, bquery, bfragment = urisplit(base)\n    uscheme, uauthority, upath, uquery, ufragment = urisplit(url)\n    if uscheme is not None and bscheme != uscheme:\n        return url\n    if uauthority is not None:\n        bauthority, bpath, bquery, bfragment = \\\n            uauthority, upath, uquery, ufragment\n    elif upath != '':\n        bpath = posixpath.normpath(_pathjoin(_dirname(bpath), upath))\n        bquery, bfragment = uquery, ufragment\n    elif uquery is not None:\n        bquery, bfragment = uquery, ufragment\n    elif ufragment is not None:\n        bfragment = ufragment\n    return uriunsplit((bscheme, bauthority, bpath, bquery, bfragment))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse the URI. uri is the uri to parse. defaults is a scheme-dependent list of values to use if there is no value for that part in the supplied URI. The return value is a tuple of scheme-dependent length.", "response": "def parse(self, uri, defaults=None):\n        \"\"\"Parse the URI.\n\n        uri is the uri to parse.\n        defaults is a scheme-dependent list of values to use if there\n        is no value for that part in the supplied URI.\n\n        The return value is a tuple of scheme-dependent length.\n        \"\"\"\n        return tuple([self.scheme_of(uri)] + list(self.parser_for(uri)(defaults).parse(uri)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef unparse(self, pieces, defaults=None):\n        return self.parser_for(pieces[0])(defaults).unparse(pieces)", "response": "Join the parts of a URI back together to form a valid URI."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parser_for(self, uri):\n        return self._parsers.get(self.scheme_of(uri), DefaultURIParser)", "response": "Return the Parser object used to parse a particular URI."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clear_temp(wdir, rmdir=True):\n    wdir = pathlib.Path(wdir)\n    extensions = [\"*.log\", \"*.dat\", \"*.txt\"]\n\n    for ext in extensions:\n        for ff in wdir.glob(ext):\n            ff.unlink()\n\n    if rmdir:\n        wdir.rmdir()", "response": "Remove all files in wdir"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nextract the electric field from the simulation file V_0Ereim. dat", "response": "def load_field(wdir, shape_grid):\n    \"\"\"Extract electric field from simulation file \"V_0Ereim.dat\"\n\n    Parameters\n    ----------\n    wdir: str or pathlib.Path\n        path to the working directory\n    shape_grid: tuple of ints\n        the shape of the simulation data grid\n\n    Notes\n    -----\n    These are the files present in the working directory\n\n    bhfield.log:\n        log file containing scattering coeffs etc\n        (as well as definitions of the output fields)\n\n    bhdebug.log:\n        extra information (checking roundoff errors etc)\n\n    E_0allf.dat:\n        E2 = EFSQ[dimensionless] = (relative) squared amplitude\n        of complex E-field; Ec*(Ec^*) / E0**2\n\n    E_1core.dat:\n        E2 inside the core\n\n    E_2coat.dat:\n        E2 inside the coating\n\n    E_3exte.dat:\n        E2 at the outside of the sphere\n\n    U_*.dat:\n        U = UABS[F m-1 s-1] is the (relative) absorbed energy per\n        unit volume and time; Ua [W m-3] / E0**2\n\n    EU_zax.txt:\n        E2(0,0,z) and U(0,0,z) along z-axis; it may be blank if\n        the grid does not include such points\n\n    V_0Eelli.dat:\n        vector electric field; vibration ellipse (major & minor axes),\n        ellipticity, azimuth[deg], p-a angle (phi)[deg], handedness\n        angle[deg] & handedness\n\n    V_0Ereim.dat: vector electric field;\n        snapshots [Re (t=0), Im (t=period/4)]\n\n    V_0Helli.dat:\n        vector magnetic field; vibration ellipse (major & minor axes),\n        ellipticity, azimuth[deg], p-a angle (phi)[deg],\n        E-&H-phase dif[deg], handedness angle[deg] & handedness\n\n    V_0Hreim.dat: vector magnetic field;\n        snapshots [Re (t=0), Im (t=period/4)]\n\n    V_0Poynt.dat:\n        Poynting vector <S>, EH angle, optical irradiance (intensity)\n        (norm<S>), I(plane), -div<S> (1st-3rd), UABS & DIVSR\n\n    V_1*.dat:\n        vector fields inside the core\n\n    V_2*.dat:\n        vector fields inside the coating\n\n    V_3*.dat:\n        vector fields at the outside of the sphere\n    \"\"\"\n    wdir = pathlib.Path(wdir)\n    check_simulation(wdir)\n    field_file = wdir / \"V_0Ereim.dat\"\n\n    a = np.loadtxt(field_file)\n\n    assert shape_grid[0] == int(\n        shape_grid[0]), \"resulting x-size is not an integer\"\n    assert shape_grid[1] == int(\n        shape_grid[1]), \"resulting y-size is not an integer\"\n\n    Ex = a[:, 3] + 1j * a[:, 6]\n    # Ey = a[:,4] + 1j*a[:,7]\n    # Ez = a[:,5] + 1j*a[:,8]\n\n    Exend = Ex.reshape((shape_grid[1], shape_grid[0])).transpose()\n    return Exend"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsimulating a sphere in a new site.", "response": "def simulate_sphere(radius_sphere_um=2.5,\n                    size_simulation_um=[7, 7],\n                    shape_grid=(50, 50),\n                    refractive_index_medium=1.0,\n                    refractive_index_sphere=1.01,\n                    measurement_position_um=2.5,\n                    wavelength_nm=500,\n                    offset_x_um=0,\n                    offset_y_um=0,\n                    arp=True,\n                    working_directory=None):\n    \"\"\"\n    Parameters\n    ----------\n    radius_sphere_um : float\n        Radius of sphere in um\n    size_simulation_um : list of floats\n        Size of simulation volume in lateral dimension in um.\n        If a float is given, then a square simulation size is assumed. If\n        a tuple is given, then a rectangular shape is assumed.\n    shape_grid : tuple of ints\n        Grid points in each lateral dimension.\n        If a float is given, then a square simulation size is assumed. If\n        a tuple is given, then a rectangular shape is assumed.\n    refractive_index : float\n        RI of sphere\n    measurement_position_um : float\n        Axial measurement position in um\n    wavelength_nm : float\n        Light wavelength in nanometers\n    offset_x_um : float\n        x coordinate of center of the sphere in um\n    offset_y_um : float\n        y coordinate of center of the sphere in um\n    arp: bool\n        Use arbitrary precision\n    working_directory: str or pathlib.Path or None\n        User-defined working directory; used for testing\n    \"\"\"\n    wavelength_um = wavelength_nm / 1000\n\n    # size simulation tuple\n    sizeum = list(size_simulation_um)\n    shape_grid = list(shape_grid)\n\n    # The size of the simulation must be zero\n    # if there is only one grid point.\n    if shape_grid[0] == 1:\n        sizeum[0] = 0\n    if shape_grid[1] == 1:\n        sizeum[1] = 0\n\n    assert np.allclose(shape_grid[0], int(\n        shape_grid[0])), \"resulting x-size is not an integer\"\n    assert np.allclose(shape_grid[1], int(\n        shape_grid[1])), \"resulting y-size is not an integer\"\n\n    while True:\n        if working_directory is None:\n            # create temp dir\n            wdir = tempfile.mkdtemp(prefix=\"qpsphere_bhfield_\")\n        else:\n            wdir = pathlib.Path(working_directory)\n\n        try:\n            run_simulation(wdir=wdir,\n                           arp=arp,\n                           wl=wavelength_um,\n                           r_core=radius_sphere_um,\n                           r_coat=radius_sphere_um,\n                           n_grid_x=int(shape_grid[0]),\n                           xspan_min=-sizeum[0] / 2 - offset_x_um,\n                           xspan_max=sizeum[0] / 2 - offset_x_um,\n                           n_grid_y=int(shape_grid[1]),\n                           yspan_min=-sizeum[1] / 2 - offset_y_um,\n                           yspan_max=sizeum[1] / 2 - offset_y_um,\n                           n_grid_z=1,\n                           zspan_min=measurement_position_um,\n                           zspan_max=measurement_position_um,\n                           case=\"other\",\n                           Kreibig=0,\n                           n_med=refractive_index_medium,\n                           n_core=refractive_index_sphere,\n                           k_core=0,\n                           n_coat=refractive_index_medium,\n                           k_coat=0)\n        except BaseException:\n            if arp:\n                raise\n            else:\n                msg = \"bhfield: Standard precision failed. \" \\\n                      + \"Retrying with arbitrary precision.\"\n                warnings.warn(msg)\n                arp = True\n            clear_temp(wdir=wdir)\n        else:\n            break\n\n    result = load_field(wdir=wdir, shape_grid=shape_grid)\n    clear_temp(wdir=wdir)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run_simulation(wdir, arp=True, **kwargs):\n    wdir = pathlib.Path(wdir)\n    cmd = \"{pathbhfield} {mpdigit} {wl:f} {r_core:f} {r_coat:f} \" \\\n          + \"{n_grid_x:d} {xspan_min:f} {xspan_max:f} \" \\\n          + \"{n_grid_y:d} {yspan_min:f} {yspan_max:f} \" \\\n          + \"{n_grid_z:d} {zspan_min:f} {zspan_max:f} \" \\\n          + \"{case} {Kreibig:f} {n_med:f} {n_core:f} {k_core:f} \" \\\n          + \"{n_coat:f} {k_coat:f}\"\n    old_dir = pathlib.Path.cwd()\n    os.chdir(wdir)\n\n    kwargs[\"pathbhfield\"] = get_binary(arp=arp)\n\n    if arp:\n        kwargs[\"mpdigit\"] = 16\n    else:\n        kwargs[\"mpdigit\"] = \"\"\n\n    # run simulation with kwargs\n    sp.check_output(cmd.format(**kwargs), shell=True)\n\n    # Go back to orgignal directory before checking (checking might fail)\n    os.chdir(old_dir)\n\n    # Check bhdebug.txt to make sure that you specify enough digits to\n    # overcome roundoff errors.\n    check_simulation(wdir)", "response": "Runs the simulation of the log - likelihood of the given WD directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_simulation(wdir):\n    wdir = pathlib.Path(wdir)\n    field = wdir / \"V_0Ereim.dat\"\n    if not (field.exists() and\n            field.stat().st_size > 130):\n        msg = \"Output {} does not exist or is too small!\".format(field)\n        raise BHFIELDExecutionError(msg)", "response": "Check that the simulation is valid."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_cmd(cmd, src_path):\n  ''' Executes a `sketchtool list` command and parse the output\n  :cmd: A sketchtool list command :type <list>\n  :src_path: File to export. :type <str>\n  :returns: A list of pages. Artboards & slices are included in the page hierarchy\n  '''\n  cmd.extend([src_path])\n\n  logger.debug(u'Executing cmd: %s' % cmd)\n  result = execute(cmd)\n  if not result:\n    return None\n\n  logger.debug(u'Raw result: %s' % result)\n  list_dict = json.loads(result)\n  pages = parse_pages(src_path, list_dict)\n  return pages", "response": "Executes a sketchtool list command and parses the output\n ata"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning slices as a flat list", "response": "def slices(src_path):\n  ''' Return slices as a flat list '''\n  pages = list_slices(src_path)\n  slices = []\n  for page in pages:\n    slices.extend(page.slices)\n  return slices"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn artboards as a flat list", "response": "def artboards(src_path):\n  ''' Return artboards as a flat list '''\n  pages = list_artboards(src_path)\n  artboards = []\n  for page in pages:\n    artboards.extend(page.artboards)\n  return artboards"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a preview of src_path as PNG. \u00d7", "response": "def preview(src_path):\n  ''' Generates a preview of src_path as PNG.\n  :returns: A list of preview paths, one for each page.\n  '''\n  previews = []\n  for page in list_artboards(src_path):\n    previews.append(page.export())\n    for artboard in page.artboards:\n      previews.append(artboard.export())\n  return previews"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the password as per the API specification.", "response": "def get_password(self, username, request_url):\n        \"\"\"\n        Calculate the password as per the API specification.\n        :param username: \n        :param request_url:\n        :return: password (string)\n        \"\"\"\n        content = \"%s%s%s\" % (username, self.shared_secret, request_url)\n        return hashlib.sha256(content.encode('utf8')).hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef verify_signature(self, signature, nonce, timestamp, signed_id):\n        message = \"%s%s%s%s\" % (self.api_key, nonce, timestamp, signed_id)\n\n        if self._pub_key is None:\n            warnings.warn(\"Skipping RSA signature verification. Please pass public key on class initialization to ensure highest level of security!\")\n            return True\n\n        try:\n            rsa.verify(message.encode('utf-8'), signature, self._pub_key)\n        except rsa.VerificationError:\n            return False\n\n        return True", "response": "Verify the server response signature."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef verify_response(self, response_json, signed_id_name='transactionid'):\n        auth_json = response_json.get('auth', {})\n\n        nonce = auth_json.get('nonce', '')\n        timestamp = auth_json.get('timestamp', '')\n        signature = binascii.unhexlify(auth_json.get('signature', ''))\n\n        signed_id = response_json.get(signed_id_name, '')\n\n        return self.verify_signature(signature=signature, nonce=nonce, timestamp=timestamp, signed_id=signed_id)", "response": "Verify the response message."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts decimal amount to string 1010", "response": "def convert_decimal_to_hundreds(self, amount):\n        \"\"\"\n        Convert Decimal(10.10) to string \"1010\"\n        :param amount: \n        :return: \n        \"\"\"\n        return str((amount.quantize(Decimal('.01'), rounding=ROUND_FLOOR) * 100).quantize(Decimal('0')))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef soup(self):\n        '''\n            Returns HTML as a BeautifulSoup element.\n        '''\n        components_soup = Tag(name=self.tagname, builder=BUILDER)\n        components_soup.attrs = self.attributes\n        for c in flatten(self.components):\n            if hasattr(c, 'soup'):\n                components_soup.append(c.soup())\n            elif type(c) in (str, ):\n                # components_soup.append(BeautifulSoup(str(c)))\n                components_soup.append(str(c))\n            # else:\n                # Component should not be integrated\n                # pass\n        return components_soup", "response": "Returns HTML as a BeautifulSoup element."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef plugins(self, deduplicate=False):\n        '''\n            Returns a flattened list of all plugins used by page components.\n        '''\n        plugins = []\n        for c in self.components:\n            if hasattr(c, 'plugins'):\n                plugins += c.plugins()\n            elif isinstance(c, Lib):\n                plugins.append(c)\n            elif hasattr(c, 'is_plugin') and c.is_plugin:\n                plugins.append(c)\n\n        if deduplicate:\n            plugins = list(OrderedDict.fromkeys(plugins))\n        return plugins", "response": "Returns a flattened list of all plugins used by page components."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef soup(self):\n        '''\n            Running plugins and adding an HTML doctype to the\n            generated Tag HTML.\n        '''\n        dom = BeautifulSoup('<!DOCTYPE html>')\n\n        # BeautifulSoup behaves differently if lxml is installed or not,\n        # and will create a basic HTML structure if lxml is installed.\n        if len(dom) > 1:\n            list(dom.children)[1].replaceWith('')  # Removing default content\n\n        soup = Element.soup(self)\n        dom.append(soup)\n\n        for plugin in self.plugins(deduplicate=True):\n            dom = plugin(dom)\n\n        return dom", "response": "Returns a BeautifulSoup object with the current tag as a child of the current element."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompare the current place object to another passed to the comparison method.", "response": "def _eq__(self, other):\n        \"\"\"\n        Compare the current place object to another passed to the comparison\n        method.  The two place objects must have the same identification, even\n        if some of their attributes might be different.\n\n        @param other: a ``Place`` instance to compare with the current place\n            object.\n\n        @return: ``True`` if the given place corresponds to the current place;\n            ``False`` otherwise.\n        \"\"\"\n        return self.place_id and other.place_id \\\n            and self.place_id == other.place_id"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_json(payload):\n        return payload and \\\n            Place([ (float(lon), float(lat), float(alt)) for (lon, lat, alt) in payload['boundaries']]\n                       if payload.get('boundaries') else GeoPoint.from_json(payload['location']),\n                address=payload.get('address') and (\n                    Place.__parse_address__(payload['address']) if isinstance(payload['address'], dict)\n                        else [ Place.__parse_address__(address) for address in payload['address'] ]),\n                category_id=cast.string_to_uuid(payload.get('category_id')),\n                area_id=cast.string_to_uuid(payload.get('area_id')),\n                contacts=payload.get('contacts') and [\n                        (cast.string_to_enum(contact[0], ContactPropertyName), # name\n                         contact[1],                                           # value\n                         contact[2] if len(contact) >= 3 else None,            # is_primary\n                         contact[3] if len(contact) == 4 else None)            # is_verified\n                    for contact in payload['contacts'] ],\n                cover_photo_id=cast.string_to_uuid(payload.get('cover_photo_id')),\n                cover_photo_url=payload.get('cover_photo_url'),\n                locale=cast.string_to_locale(payload.get('locale')) and DEFAULT_LOCALE,\n                object_status=payload.get(\"object_status\"),\n                place_id=cast.string_to_uuid(payload.get('place_id')),\n                timezone=payload.get('timezone'))", "response": "Builds a Place instance from the specified JSON object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_classes(package_str):\n    '''Load all classes from modules of a given `package_str`. All class instances are stored in a case-insensitive `dict`\n    and returned. If a package doesn't contain any class `None` is returned'''\n\n    _logger.debug('Loading all modules from %s', package_str)\n    package = importlib.import_module(package_str)\n    package_path = package.__path__\n    _logger.debug('Searching for modules in package %s (%s)', package_str, package_path)\n    for _, name, ispkg in pkgutil.iter_modules(package_path, package_str + \".\"):\n        if not ispkg:\n            _logger.debug('Found module: %s', name)\n            module = importlib.import_module(name)\n            if hasattr(module, CLASS_NAME_ATTR):\n                class_name = getattr(module, CLASS_NAME_ATTR)\n                _logger.debug('Found class: %s', class_name)\n                clasz = getattr(module, class_name)\n\n                if package_str not in _dynamo_cache:\n                    _dynamo_cache[package_str] = CaseInsensitiveDict()\n                \n                if class_name not in _dynamo_cache[package_str]:\n                    _dynamo_cache[package_str][class_name] = clasz\n                    _logger.debug('Correctly loaded class: %s from: \"%s\"', class_name, package_str)\n                else:\n                    _logger.warning('Already loaded class: %s from: \"%s\"', class_name, package_str)\n            else:\n                _logger.warning('Module inside %s does not contain required attribute: %s', package_str, CLASS_NAME_ATTR)\n        else:\n            _logger.warning('Ignoring package: %s', name)\n\n    if package_str in _dynamo_cache:\n        return _dynamo_cache[package_str]\n    else:\n        return None", "response": "Load all classes from modules of a given package_str. All classes are stored in a case - insensitive dict and returned."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(package_str, classname):\n    '''Retrieve from the internal cache a class instance. All arguments are case-insensitive''' \n    if (package_str in _dynamo_cache) and (classname in _dynamo_cache[package_str]):\n        return _dynamo_cache[package_str][classname]\n    return None", "response": "Retrieve from the internal cache a class instance. All arguments are case - insensitive"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ex_literal(val):\n    if val is None:\n        return ast.Name('None', ast.Load())\n    elif isinstance(val, int):\n        return ast.Num(val)\n    elif isinstance(val, bool):\n        return ast.Name(bytes(val), ast.Load())\n    elif isinstance(val, str):\n        return ast.Str(val)\n    raise TypeError(u'no literal for {0}'.format(type(val)))", "response": "An integer float long bool string or None literal with the given\n    value."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ex_varassign(name, expr):\n    if not isinstance(expr, ast.expr):\n        expr = ex_literal(expr)\n    return ast.Assign([ex_lvalue(name)], expr)", "response": "Assign an expression into a single variable."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncompiling a list of statements as the body of a function and return the resulting Python function. If debug is True then print out the bytecode of the compiled function.", "response": "def compile_func(arg_names, statements, name='_the_func', debug=False):\n    \"\"\"Compile a list of statements as the body of a function and return\n    the resulting Python function. If `debug`, then print out the\n    bytecode of the compiled function.\n    \"\"\"\n    func_def = ast.FunctionDef(\n        name=name,\n        args=ast.arguments(\n            args=[ast.arg(arg=n, annotation=None) for n in arg_names],\n            kwonlyargs=[],\n            kw_defaults=[],\n            defaults=[ex_literal(None) for _ in arg_names],\n        ),\n        body=statements,\n        decorator_list=[],\n    )\n\n    mod = ast.Module([func_def])\n    ast.fix_missing_locations(mod)\n\n    prog = compile(mod, '<generated>', 'exec')\n\n    # Debug: show bytecode.\n    if debug:\n        dis.dis(prog)\n        for const in prog.co_consts:\n            if isinstance(const, types.CodeType):\n                dis.dis(const)\n\n    the_locals = {}\n    exec(prog, {}, the_locals)\n    return the_locals[name]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parse(template):\n    parser = Parser(template)\n    parser.parse_expression()\n\n    parts = parser.parts\n    remainder = parser.string[parser.pos:]\n    if remainder:\n        parts.append(remainder)\n    return Expression(parts)", "response": "Parse a top - level template string Expression. Any extraneous text\n    is considered literal text."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nevaluates the symbol in the environment returning a Unicode string.", "response": "def evaluate(self, env):\n        \"\"\"Evaluate the symbol in the environment, returning a Unicode\n        string.\n        \"\"\"\n        if self.ident in env.values:\n            # Substitute for a value.\n            return env.values[self.ident]\n        else:\n            # Keep original text.\n            return self.original"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompile the variable lookup.", "response": "def translate(self):\n        \"\"\"Compile the variable lookup.\"\"\"\n        ident = self.ident\n        expr = ex_rvalue(VARIABLE_PREFIX + ident)\n        return [expr], set([ident]), set()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef evaluate(self, env):\n        if self.ident in env.functions:\n            arg_vals = [expr.evaluate(env) for expr in self.args]\n            try:\n                out = env.functions[self.ident](*arg_vals)\n            except Exception as exc:\n                # Function raised exception! Maybe inlining the name of\n                # the exception will help debug.\n                return u'<%s>' % str(exc)\n            return str(out)\n        else:\n            return self.original", "response": "Evaluate the function call in the environment returning a\n        Unicode string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompile the function call.", "response": "def translate(self):\n        \"\"\"Compile the function call.\"\"\"\n        varnames = set()\n        ident = self.ident\n        funcnames = set([ident])\n\n        arg_exprs = []\n        for arg in self.args:\n            subexprs, subvars, subfuncs = arg.translate()\n            varnames.update(subvars)\n            funcnames.update(subfuncs)\n\n            # Create a subexpression that joins the result components of\n            # the arguments.\n            arg_exprs.append(ex_call(\n                ast.Attribute(ex_literal(u''), 'join', ast.Load()),\n                [ex_call(\n                    'map',\n                    [\n                        ex_rvalue(str.__name__),\n                        ast.List(subexprs, ast.Load()),\n                    ]\n                )],\n            ))\n\n        subexpr_call = ex_call(\n            FUNCTION_PREFIX + ident,\n            arg_exprs\n        )\n        return [subexpr_call], varnames, funcnames"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nevaluating the entire expression in the environment returning a Unicode string.", "response": "def evaluate(self, env):\n        \"\"\"Evaluate the entire expression in the environment, returning\n        a Unicode string.\n        \"\"\"\n        out = []\n        for part in self.parts:\n            if isinstance(part, str):\n                out.append(part)\n            else:\n                out.append(part.evaluate(env))\n        return u''.join(map(str, out))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncompiling the expression to a list of Python AST expressions a set of variable names used and a set of function names.", "response": "def translate(self):\n        \"\"\"Compile the expression to a list of Python AST expressions, a\n        set of variable names used, and a set of function names.\n        \"\"\"\n        expressions = []\n        varnames = set()\n        funcnames = set()\n        for part in self.parts:\n            if isinstance(part, str):\n                expressions.append(ex_literal(part))\n            else:\n                e, v, f = part.translate()\n                expressions.extend(e)\n                varnames.update(v)\n                funcnames.update(f)\n        return expressions, varnames, funcnames"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses a template expression starting at the current position.", "response": "def parse_expression(self):\n        \"\"\"Parse a template expression starting at ``pos``. Resulting\n        components (Unicode strings, Symbols, and Calls) are added to\n        the ``parts`` field, a list.  The ``pos`` field is updated to be\n        the next character after the expression.\n        \"\"\"\n        # Append comma (ARG_SEP) to the list of special characters only when\n        # parsing function arguments.\n        extra_special_chars = ()\n        special_char_re = self.special_char_re\n        if self.in_argument:\n            extra_special_chars = (ARG_SEP,)\n            special_char_re = re.compile(\n                r'[%s]|\\Z' % u''.join(\n                    re.escape(c) for c in\n                    self.special_chars + extra_special_chars\n                )\n            )\n\n        text_parts = []\n\n        while self.pos < len(self.string):\n            char = self.string[self.pos]\n\n            if char not in self.special_chars + extra_special_chars:\n                # A non-special character. Skip to the next special\n                # character, treating the interstice as literal text.\n                next_pos = (\n                    special_char_re.search(\n                        self.string[self.pos:]).start() + self.pos\n                )\n                text_parts.append(self.string[self.pos:next_pos])\n                self.pos = next_pos\n                continue\n\n            if self.pos == len(self.string) - 1:\n                # The last character can never begin a structure, so we\n                # just interpret it as a literal character (unless it\n                # terminates the expression, as with , and }).\n                if char not in self.terminator_chars + extra_special_chars:\n                    text_parts.append(char)\n                    self.pos += 1\n                break\n\n            next_char = self.string[self.pos + 1]\n            if char == ESCAPE_CHAR and next_char in (self.escapable_chars +\n                                                     extra_special_chars):\n                # An escaped special character ($$, $}, etc.). Note that\n                # ${ is not an escape sequence: this is ambiguous with\n                # the start of a symbol and it's not necessary (just\n                # using { suffices in all cases).\n                text_parts.append(next_char)\n                self.pos += 2  # Skip the next character.\n                continue\n\n            # Shift all characters collected so far into a single string.\n            if text_parts:\n                self.parts.append(u''.join(text_parts))\n                text_parts = []\n\n            if char == SYMBOL_DELIM:\n                # Parse a symbol.\n                self.parse_symbol()\n            elif char == FUNC_DELIM:\n                # Parse a function call.\n                self.parse_call()\n            elif char in self.terminator_chars + extra_special_chars:\n                # Template terminated.\n                break\n            elif char == GROUP_OPEN:\n                # Start of a group has no meaning hear; just pass\n                # through the character.\n                text_parts.append(char)\n                self.pos += 1\n            else:\n                assert False\n\n        # If any parsed characters remain, shift them into a string.\n        if text_parts:\n            self.parts.append(u''.join(text_parts))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_symbol(self):\n        assert self.pos < len(self.string)\n        assert self.string[self.pos] == SYMBOL_DELIM\n\n        if self.pos == len(self.string) - 1:\n            # Last character.\n            self.parts.append(SYMBOL_DELIM)\n            self.pos += 1\n            return\n\n        next_char = self.string[self.pos + 1]\n        start_pos = self.pos\n        self.pos += 1\n\n        if next_char == GROUP_OPEN:\n            # A symbol like ${this}.\n            self.pos += 1  # Skip opening.\n            closer = self.string.find(GROUP_CLOSE, self.pos)\n            if closer == -1 or closer == self.pos:\n                # No closing brace found or identifier is empty.\n                self.parts.append(self.string[start_pos:self.pos])\n            else:\n                # Closer found.\n                ident = self.string[self.pos:closer]\n                self.pos = closer + 1\n                self.parts.append(Symbol(ident,\n                                         self.string[start_pos:self.pos]))\n\n        else:\n            # A bare-word symbol.\n            ident = self._parse_ident()\n            if ident:\n                # Found a real symbol.\n                self.parts.append(Symbol(ident,\n                                         self.string[start_pos:self.pos]))\n            else:\n                # A standalone $.\n                self.parts.append(SYMBOL_DELIM)", "response": "Parse a variable reference symbol. Possibly appends a Symbol object to the parts field and updates pos."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses a function call.", "response": "def parse_call(self):\n        \"\"\"Parse a function call (like ``%foo{bar,baz}``) starting at\n        ``pos``.  Possibly appends a Call object to ``parts`` and update\n        ``pos``. The character at ``pos`` must be ``%``.\n        \"\"\"\n        assert self.pos < len(self.string)\n        assert self.string[self.pos] == FUNC_DELIM\n\n        start_pos = self.pos\n        self.pos += 1\n\n        ident = self._parse_ident()\n        if not ident:\n            # No function name.\n            self.parts.append(FUNC_DELIM)\n            return\n\n        if self.pos >= len(self.string):\n            # Identifier terminates string.\n            self.parts.append(self.string[start_pos:self.pos])\n            return\n\n        if self.string[self.pos] != GROUP_OPEN:\n            # Argument list not opened.\n            self.parts.append(self.string[start_pos:self.pos])\n            return\n\n        # Skip past opening brace and try to parse an argument list.\n        self.pos += 1\n        args = self.parse_argument_list()\n        if self.pos >= len(self.string) or \\\n           self.string[self.pos] != GROUP_CLOSE:\n            # Arguments unclosed.\n            self.parts.append(self.string[start_pos:self.pos])\n            return\n\n        self.pos += 1  # Move past closing brace.\n        self.parts.append(Call(ident, args, self.string[start_pos:self.pos]))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses a list of arguments starting at the current position returning a list of Expression objects. Does not modify parts.", "response": "def parse_argument_list(self):\n        \"\"\"Parse a list of arguments starting at ``pos``, returning a\n        list of Expression objects. Does not modify ``parts``. Should\n        leave ``pos`` pointing to a } character or the end of the\n        string.\n        \"\"\"\n        # Try to parse a subexpression in a subparser.\n        expressions = []\n\n        while self.pos < len(self.string):\n            subparser = Parser(self.string[self.pos:], in_argument=True)\n            subparser.parse_expression()\n\n            # Extract and advance past the parsed expression.\n            expressions.append(Expression(subparser.parts))\n            self.pos += subparser.pos\n\n            if self.pos >= len(self.string) or \\\n               self.string[self.pos] == GROUP_CLOSE:\n                # Argument list terminated by EOF or closing brace.\n                break\n\n            # Only other way to terminate an expression is with ,.\n            # Continue to the next argument.\n            assert self.string[self.pos] == ARG_SEP\n            self.pos += 1\n\n        return expressions"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing an identifier and return it.", "response": "def _parse_ident(self):\n        \"\"\"Parse an identifier and return it (possibly an empty string).\n        Updates ``pos``.\n        \"\"\"\n        remainder = self.string[self.pos:]\n        ident = re.match(r'\\w*', remainder).group(0)\n        self.pos += len(ident)\n        return ident"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef interpret(self, values={}, functions={}):\n        return self.expr.evaluate(Environment(values, functions))", "response": "Like substitute but forces the interpreter to be used."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nevaluating the template given the values and functions.", "response": "def substitute(self, values={}, functions={}):\n        \"\"\"Evaluate the template given the values and functions.\n        \"\"\"\n        try:\n            res = self.compiled(values, functions)\n        except Exception:  # Handle any exceptions thrown by compiled version.\n            res = self.interpret(values, functions)\n\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef translate(self):\n        expressions, varnames, funcnames = self.expr.translate()\n\n        argnames = []\n        for varname in varnames:\n            argnames.append(VARIABLE_PREFIX + varname)\n        for funcname in funcnames:\n            argnames.append(FUNCTION_PREFIX + funcname)\n\n        func = compile_func(\n            argnames,\n            [ast.Return(ast.List(expressions, ast.Load()))],\n        )\n\n        def wrapper_func(values={}, functions={}):\n            args = {}\n            for varname in varnames:\n                args[VARIABLE_PREFIX + varname] = values[varname]\n            for funcname in funcnames:\n                args[FUNCTION_PREFIX + funcname] = functions[funcname]\n            parts = func(**args)\n            return u''.join(parts)\n\n        return wrapper_func", "response": "Compile the template to a Python function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef uri_from_parts(parts):\n    \"simple function to merge three parts into an uri\"\n    uri = \"%s://%s%s\" % (parts[0], parts[1], parts[2])\n    if parts[3]:\n        extra = '?'+urlencode(parts[3])\n        uri += extra\n    return uri", "response": "simple function to merge three parts into an uri"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns some attributes as a list", "response": "def as_list(self):\n        \"return some attributes as a list\"\n        netloc = ''\n        if self.vpath_connector:\n            netloc = '(('+self.vpath_connector+'))'\n        elif self.authority:\n            netloc = self.authority\n        else:\n            netloc = self.netloc\n        return [\n            self.scheme,\n            netloc,\n            self.path,\n            self.query,\n            '',\n            ]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if value is print False otherwise.", "response": "def is_print(value, space = True, tab = False, crlf = False):\n    \"\"\" Returns True if is print or False otherwise \"\"\"\n    if not isinstance(value, basestring):\n        return False\n\n    regex = r'\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F\\x7F'\n\n    if not space:\n        regex += r'\\x20'\n\n    if tab:\n        regex += r'\\x09'\n\n    if crlf:\n        regex += r'\\x0A\\x0D'\n\n    return re.match(r'[' + regex + ']', value, re.U) is None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rm_rf(path):\n    if os.path.isdir(path) and not os.path.islink(path):\n        shutil.rmtree(path)\n    elif os.path.lexists(path):\n        os.remove(path)", "response": "Delete the file at the given path."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef file_writelines_flush_sync(path, lines):\n    fp = open(path, 'w')\n    try:\n        fp.writelines(lines)\n        flush_sync_file_object(fp)\n    finally:\n        fp.close()", "response": "Write lines to file at path and flush all buffers"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef file_w_create_directories(filepath):\n    dirname = os.path.dirname(filepath)\n\n    if dirname and dirname != os.path.curdir and not os.path.isdir(dirname):\n        os.makedirs(dirname)\n\n    return open(filepath, 'w')", "response": "Recursively create directories if needed so that the directory where\n    @filepath must be written exists and return the file object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef linesubst(line, variables):\n    # trivial no substitution early detection:\n    if '{{' not in line and '\\\\' not in line:\n        return line\n    st = NORM\n    out = \"\"\n    curvar = \"\"\n    for c in line:\n        if st is NORM:\n            if c == '{':\n                st = ONE\n            elif c == '\\\\':\n                st = LIT\n            else:\n                out += c\n        elif st is LIT:\n            out += c\n            st = NORM\n        elif st is ONE:\n            if c == '{':\n                st = TWO\n            elif c == '\\\\':\n                out += '{'\n                st = LIT\n            else:\n                out += '{' + c\n                st = NORM\n        elif st is TWO:\n            if c == '\\\\':\n                st = TLIT\n            elif c == '}':\n                st = TERM\n            else:\n                curvar += c\n        elif st is TLIT:\n            curvar += c\n            st = TWO\n        elif st is TERM:\n            if c == '}':\n                if curvar not in variables:\n                    LOG.warning(\"Unknown variable %r detected, will just be replaced by an empty string\", curvar)\n                else:\n                    LOG.debug(\"Substitution of {{%s}} by %r\", curvar, variables[curvar])\n\n                    value = variables[curvar]\n                    if isinstance(value, (float, int, long)):\n                        value = str(value)\n\n                    out += value\n                curvar = ''\n                st = NORM\n            elif c == '\\\\':\n                curvar += '}'\n                st = TLIT\n            else:\n                curvar += '}' + c\n                st = TWO\n    if st is not NORM:\n        LOG.warning(\"st is not NORM at end of line: \" + line)\n        LOG.warning(\"returned substitution: \" + out)\n    return out", "response": "Substitute the variable names with the values of the variables in the line."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef txtsubst(lines, variables, target_file=None, charset=None):\n    if target_file:\n        LOG.info(\"In process of generating file %r\", target_file)\n\n    if not charset:\n        return [linesubst(line, variables) for line in lines]\n\n    ret = []\n    for line in lines:\n        linesub = linesubst(line, variables)\n        if isinstance(line, unicode):\n            ret.append(linesub.encode(charset))\n        else:\n            ret.append(linesub)\n    return ret", "response": "Given a list of lines and a set of variables return the text of the linesubsted by the linesubst function."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new sale.", "response": "def create_new_sale(self, amount, purpose, payment_reference=None, order_id=None, channel_id=None, capture=True):\n        \"\"\"\n        Create new sale.\n        :param amount: \n        :param purpose: \n        :param payment_reference: \n        :param order_id: \n        :param channel_id: \n        :param capture: \n        :return: tuple (transaction_id, payment_token_number, status)\n        \"\"\"\n        request_data = {\n            \"amount\": self.base.convert_decimal_to_hundreds(amount),\n            \"currency\": self.currency,\n            \"purpose\": purpose,\n            \"capture\": capture\n        }\n\n        if payment_reference:\n            request_data['paymentreference'] = payment_reference\n\n        if order_id:\n            request_data['orderid'] = order_id\n\n        if channel_id:\n            request_data['channelid'] = channel_id\n\n        url = \"%s%s\" % (self.api_endpoint, constants.NEW_SALE_ENDPOINT)\n\n        username = self.base.get_username()\n        password = self.base.get_password(username=username, request_url=url)\n\n        response = requests.post(url, json=request_data, auth=HTTPBasicAuth(username=username, password=password))\n\n        if not self.base.verify_response(response.json()):\n            raise SignatureValidationException('Server signature verification has failed')\n\n        response_json = response.json()\n\n        return response_json.get('transactionid'), response_json.get('paymenttokennumber'), response_json.get('status')"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the current status of a transaction.", "response": "def fetch_transaction_status(self, transaction_id):\n        \"\"\"\n        Get the transaction current status. \n\n        :param transaction_id: \n        :return: \n        \"\"\"\n        url = \"%s%s%s/status\" % (self.api_endpoint, constants.TRANSACTION_STATUS_ENDPOINT, transaction_id)\n\n        username = self.base.get_username()\n        password = self.base.get_password(username=username, request_url=url)\n\n        response = requests.get(url, auth=HTTPBasicAuth(username=username, password=password))\n\n        if response.status_code == 404:\n            raise TransactionDoesNotExist('Wrong transaction ID!')\n\n        if not self.base.verify_response(response.json()):\n            raise SignatureValidationException('Server signature verification has failed')\n\n        return response.json()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncapturing existing preauth. :param transaction_id: :param capture_amount: :param message: :return: status code", "response": "def capture_sale(self, transaction_id, capture_amount, message=None):\n        \"\"\"\n        Capture existing preauth.\n\n        :param transaction_id:\n        :param capture_amount:\n        :param message:\n        :return: status code\n        \"\"\"\n        request_data = {\n            \"amount\": self.base.convert_decimal_to_hundreds(capture_amount),\n            \"currency\": self.currency,\n            \"message\": message\n        }\n\n        url = \"%s%s%s/capture\" % (self.api_endpoint, constants.TRANSACTION_STATUS_ENDPOINT, transaction_id)\n\n        username = self.base.get_username()\n        password = self.base.get_password(username=username, request_url=url)\n\n        response = requests.put(url, json=request_data, auth=HTTPBasicAuth(username=username, password=password))\n\n        if response.status_code == 404:\n            raise TransactionDoesNotExist('Wrong transaction ID!')\n\n        if not self.base.verify_response(response.json()):\n            raise SignatureValidationException('Server signature verification has failed')\n\n        response_json = response.json()\n\n        return response_json.get('status')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef caller_folder():\n    import inspect\n    caller_file = inspect.stack()[2][1]\n    if os.path.exists(caller_file):\n        return os.path.abspath(os.path.dirname(caller_file))\n    else:\n        return os.path.abspath(os.getcwd())", "response": "Returns the folder where the code of the caller lives\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_dict(self):\n        cache_info = None\n        if self.cache_info:\n            cache_info = self.cache_info.to_dict()\n        return {\n            'cache_info': cache_info,\n            'html': self.html,\n            'scraped': self.scraped,\n            'raw': self.raw\n        }", "response": "Return a dictionary representation of the object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_dict(d):\n        if d is None:\n            return None\n        return Response(\n            d.get('html'),\n            CacheInfo.from_dict(d.get('cache_info')),\n            d.get('scraped'),\n            d.get('raw')\n        )", "response": "Load a response from a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts input value to request type", "response": "def convert(input, type):\n        \"\"\"\n        Converts input value to request type\n        :param input: input value\n        :param type: type to cast\n        :return: converted value\n        \"\"\"\n        try:\n            if not input:\n                if type == Types.TYPE_STRING:\n                    return ''\n                else:\n                    return None\n            if type == Types.TYPE_STRING:\n                if isinstance(input, datetime.date):\n                    return input.strftime('%Y-%m-%d')\n                else:\n                    return input\n            if type == Types.TYPE_FLOAT:\n                return float(input)\n            elif type == Types.TYPE_INT:\n                return int(input)\n            elif type == Types.TYPE_DATE:\n                if isinstance(input, datetime.date):\n                    return input\n                else:\n                    return datetime.datetime.strptime(input[0:10], '%Y-%m-%d')\n            elif type == Types.TYPE_DATETIME:\n                if isinstance(input, datetime.datetime):\n                    return input\n                else:\n                    return datetime.datetime.strptime(input[0:19], '%Y-%m-%dT%H:%M:%S') # 2017-10-01T10:01:00.479+0300\n            else:\n                return NotImplementedError('Not supported type - {}'.format(type))\n        except Exception as e:\n            logging.error(e, exc_info=True)\n            raise Exception(e)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef df2list(df):\n        for column in df:\n            df[column] = df[column].astype(object).where(df[column].notnull(), None)\n        return df.to_dict(orient='records')", "response": "Converts pandas. DataFrame values into list of tuples"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a cv image of the board.", "response": "def _create_board_image_cv(self, board=None):\n        \"\"\"Return a cv image of the board or empty board if not provided.\"\"\"\n        board = board or base.Board()  # empty board by default\n        tile_h, tile_w = self._TILE_SHAPE[0:2]\n        board_shape = tile_h * 8, tile_w * 8, 3\n        board_image = numpy.zeros(board_shape, dtype=numpy.uint8)\n        # place each tile on the image\n        for (row, col), tile in board.positions_with_tile():\n            tile_image = self._tile_images[tile._type]\n            t, l = row * tile_h, col * tile_w\n            b, r = t + tile_h, l + tile_w\n            board_image[t:b, l:r] = tile_image\n        return board_image"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndrawing a white border to indicate the swap.", "response": "def _draw_swap_cv(self, board_image, swap):\n        \"\"\"Add a white tile border to indicate the swap.\"\"\"\n        tile_h, tile_w = self._TILE_SHAPE[0:2]\n        # get a single bounding box\n        (row_1, col_1), (row_2, col_2) = swap\n        t = tile_h * min(row_1, row_2)\n        b = tile_h * (1 + max(row_1, row_2))\n        l = tile_w * min(col_1, col_2)\n        r = tile_w * (1 + max(col_1, col_2))\n        top_left = (l, t)\n        bottom_right = (r, b)\n        data.cv2.rectangle(board_image, top_left, bottom_right,\n                           color=(255, 255, 255), thickness = 4)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _convert_cv_to_tk(self, image_cv):\n        # convert BGR to RGB\n        image_cv_rgb = data.cv2.cvtColor(image_cv, data.cv2.COLOR_BGR2RGB)\n        # convert opencv to PIL\n        image_pil = PIL_Image.fromarray(image_cv_rgb)\n        # convert PIL to tkinter\n        return ImageTk.PhotoImage(image_pil)", "response": "Convert an OpenCV image to a tkinter PhotoImage"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstarts the analysis of the game on screen.", "response": "def _analyze(self):\n        \"\"\"(Re)start analysis of the game on screen.\"\"\"\n        self._analyze_start_time = time.time()\n        self._clear_ui()\n        try:\n            self._analysis_process.terminate()  # clear anything existing\n        except AttributeError:  # there wasn't actually a process\n            pass\n        # self._analysis_process = _AsyncReadyFunction(self._analysis_function,\n        #                                              None, 'async_results_q')\n        out_q = mp.Queue()\n        self._analysis_process = mp.Process(target=self._analysis_function,\n                                            kwargs={'async_results_q': out_q})\n        setattr(self._analysis_process, 'out_q', out_q)\n        self._analysis_process.start()\n        self._base.after(self._POLL_PERIOD_MILLISECONDS,\n                         self._scheduled_check_for_summaries)\n        self._update_notification('Analyzing the on-screen game.')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npresent the results if they have become available or timed out.", "response": "def _scheduled_check_for_summaries(self):\n        \"\"\"Present the results if they have become available or timed out.\"\"\"\n        if self._analysis_process is None:\n            return\n        # handle time out\n        timed_out = time.time() - self._analyze_start_time > self.time_limit\n        if timed_out:\n            self._handle_results('Analysis timed out but managed\\n'\n                                 ' to get lower turn results.',\n                                 'Analysis timed out with no results.')\n            return\n        # handle standard completion\n        try:\n            self._analysis_process.join(0.001)\n        except AssertionError:\n            pass  # if some timing issue with closed process, just continue\n        if not self._analysis_process.is_alive():\n            self._handle_results('Completed analysis.',\n                                 'Unable to find the game on screen.')\n            return\n        #finally, if it's still alive, then come back later\n        self._base.after(self._POLL_PERIOD_MILLISECONDS,\n                         self._scheduled_check_for_summaries)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _next(self):\n        self.summaries.rotate(-1)\n        current_summary = self.summaries[0]\n        self._update_summary(current_summary)", "response": "Get the next summary and present it."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _previous(self):\n        self.summaries.rotate()\n        current_summary = self.summaries[0]\n        self._update_summary(current_summary)", "response": "Get the previous summary and present it."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the message area with blank or a message.", "response": "def _update_notification(self, message=None):\n        \"\"\"Update the message area with blank or a message.\"\"\"\n        if message is None:\n            message = ''\n        message_label = self._parts['notification label']\n        message_label.config(text=message)\n        self._base.update()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _update_summary(self, summary=None):\n        board_image_label = self._parts['board image label']\n        # get content for update or use blanks when no summary\n        if summary:\n            # make a board image with the swap drawn on it\n            # board, action, text = summary.board, summary.action, summary.text\n            board_image_cv = self._create_board_image_cv(summary.board)\n            self._draw_swap_cv(board_image_cv, summary.action)\n            board_image_tk = self._convert_cv_to_tk(board_image_cv)\n            text = ''\n            if not summary.score is None:\n                text += 'Score: {:3.1f}'.format(summary.score)\n            if (not summary.mana_drain_leaves is None) and\\\n                    (not summary.total_leaves is None):\n                text += '       Mana Drains: {}/{}' \\\n                        ''.format(summary.mana_drain_leaves,\n                                  summary.total_leaves)\n        else:\n            #clear any stored state image and use the blank\n            board_image_tk = board_image_label._blank_image\n            text = ''\n        # update the UI parts with the content\n        board_image_label._board_image = board_image_tk\n        board_image_label.config(image=board_image_tk)\n        # update the summary text\n        summary_label = self._parts['summary label']\n        summary_label.config(text=text)\n        # refresh the UI\n        self._base.update()", "response": "Update all parts of the summary or clear when no summary."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nasserts types of the function arguments and return value. :param return_type: expected type of the return value :param arg_types: expected types of the arguments :example: @types(float, x=int, y=float, z=ListOf(int)) def f(x, y, z): return x * y + sum(z)", "response": "def types(*return_type, **arg_types):\n    \"\"\"\n    Assert types of the function arguments and return value.\n    :param return_type: expected type of the return value\n    :param arg_types: expected types of the arguments\n\n    :example:\n    @types(float, x=int, y=float, z=ListOf(int))\n    def f(x, y, z):\n        return x * y + sum(z)\n    \"\"\"\n    assert len(return_type) <= 1, 'You can specify at most one return type.'\n\n    arg_msg = '%s must be %s, not %s.'\n    return_msg = 'must return %s, not %s.'\n\n    def f(func):\n        import functools\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # convert args to call args\n            call_args = getcallargs(func, *args, **kwargs)\n\n            for arg_name, expect in arg_types.items():\n                assert arg_name in call_args, 'Not found argument: %s' % arg_name\n                actual = call_args[arg_name]\n                if not _check_type(actual, expect):\n                    raise TypeError(arg_msg % (arg_name, _get_name(expect), type(actual).__name__))\n\n            ret = func(*args, **kwargs)\n            if return_type:\n                if not _check_type(ret, return_type[0]):\n                    raise TypeError(return_msg % (_get_name(return_type[0]), type(ret).__name__))\n            return ret\n\n        return wrapper\n\n    return f"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nissue the request and return the response.", "response": "def send(self):\n        \"\"\"Issue the request.\n\n        Uses httplib2.Http support for handling redirects.  Returns an\n        httplib2.Response, which may be augmented by the\n        proc_response() method.\n\n        Note that the default implementation of proc_response() causes\n        an appropriate exception to be raised if the response code is\n        >= 400.\n        \"\"\"\n\n        # Pre-process the request\n        try:\n            self.procstack.proc_request(self)\n        except exc.ShortCircuit, e:\n            self._debug(\"Request pre-processing short-circuited\")\n\n            # Short-circuited; we have an (already processed) response\n            return e.response\n\n        self._debug(\"Sending %r request to %r (body %r, headers %r)\",\n                    self.method, self.url, self.body, self.headers)\n\n        # Issue the request\n        (resp, content) = self.client.request(self.url, self.method,\n                                              self.body, self.headers,\n                                              self.max_redirects)\n\n        # Save the body in the response\n        resp.body = content\n\n        # Do any processing on the response that's desired\n        try:\n            self.proc_response(resp)\n        except:\n            # Process the exception\n            result = self.procstack.proc_exception(*sys.exc_info())\n            if not result:\n                # Not handled, re-raise it\n                raise\n            else:\n                # Handled and we have a fully post-processed response\n                return result\n\n        # Return the response, post-processing it\n        return self.procstack.proc_response(resp)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprocesses non - redirect responses received by the send method.", "response": "def proc_response(self, resp):\n        \"\"\"Process response hook.\n\n        Process non-redirect responses received by the send() method.\n        May augment the response.  The default implementation causes\n        an exception to be raised if the response status code is >=\n        400.\n        \"\"\"\n\n        # Raise exceptions for error responses\n        if resp.status >= 400:\n            e = exc.exception_map.get(resp.status, exc.HTTPException)\n            self._debug(\"  Response was a %d fault, raising %s\",\n                        resp.status, e.__name__)\n            raise e(resp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef submit(self, method, method_args=(), method_kwargs={}, done_callback=None, done_kwargs={}, loop=None):\n        '''\n        used to send async notifications\n        :param method:\n        :param method_args:\n        :param method_kwargs:\n        :param done_callback:\n        :param done_kwargs:\n        :param loop:\n        :return:\n        '''\n        _future = self.pool.submit(method, *method_args, **method_kwargs)\n        self.current_id += 1\n        if done_callback:\n            _future.add_done_callback(lambda _f:done_callback(_f,loop,**done_kwargs))#done kwargs, hardcoded kwargs\n        self.request_pool[self.current_id] = _future\n        return self.current_id, _future", "response": "used to send async notifications"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef default(self, obj):\n\n\t\t# If we have a datetime object\n\t\tif isinstance(obj, datetime):\n\t\t\treturn obj.strftime('%Y-%m-%d %H:%M:%S')\n\n\t\t# Else if we have a decimal object\n\t\telif isinstance(obj, Decimal):\n\t\t\treturn '{0:f}'.format(obj)\n\n\t\t# Bubble back up to the parent default\n\t\treturn json.JSONEncoder.default(self, obj)", "response": "Default encoder for unknown objects"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_arguments(self):\n        super(LabelCommand, self).add_arguments()\n        self.parser.add_argument('labels', metavar=self.label, nargs=\"+\")", "response": "Add the labels argument to the parser."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a new enumeration object extended with the specified items.", "response": "def extend(self, *keys, **kwargs):\n        \"\"\"\n        Return a new enumeration object extended with the specified items.\n        \"\"\"\n        this = copy.deepcopy(self)\n\n        value_type = kwargs.get('value_type', EnumValue)\n\n        if not keys:\n            raise EnumEmptyError()\n\n        keys = tuple(keys)\n        values = [None] * len(keys)\n\n        for i, key in enumerate(keys):\n            value = value_type(this, i, key)\n            values[i] = value\n            try:\n                super(Enum, this).__setattr__(key, value)\n            except TypeError:\n                raise EnumBadKeyError(key)\n\n        this.__dict__['_keys'] = this.__dict__['_keys'] + keys\n        this.__dict__['_values'] += values\n\n        return this"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_valid_preview(preview):\n  ''' Verifies that the preview is a valid filetype '''\n  if not preview:\n    return False\n\n  if mimetype(preview) not in [ExportMimeType.PNG, ExportMimeType.PDF]:\n    return False\n\n  return True", "response": "Verifies that the preview is a valid filetype"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating a preview of src_path in the requested format.", "response": "def preview(src_path):\n  ''' Generates a preview of src_path in the requested format.\n  :returns: A list of preview paths, one for each page. Blank list if unsupported.\n  '''\n  preview = embedded_preview(src_path)\n\n  if not is_valid_preview(preview):\n    preview = generator_preview(src_path)\n\n  if not is_valid_preview(preview):\n    preview = thumbnail_preview(src_path)\n\n  # Ensure the preview is returned in the right format\n  if is_valid_preview(preview):\n    if mimetype(preview) in [ExportMimeType.PNG]:\n      return [preview]\n\n    if mimetype(preview) in [ExportMimeType.PDF]:\n      return to_pngs(preview)\n\n  return []"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates folders to best match metadata.", "response": "def options(self, data):\n        \"\"\"Generate folders to best match metadata.\n\n        The results will be a single, perfectly matched folder, or the two nearest\n        neighbours of an imperfect match.\n\n        :param dict data: metadata matching criteria.\n\n        This method is a generator. It yields\n        :py:class:`turberfield.dialogue.model.SceneScript.Folder` objects.\n\n        \"\"\"\n        if self.mapping_key(data) in self.keys:\n            yield next(i for i in self.folders if i.metadata == data)\n        else:\n            index = bisect.bisect_left(self.keys, self.mapping_key(data))\n            posns = sorted(set([max(0, index - 1), index]))\n            yield from (self.folders[i] for i in posns)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef factory(cfg, login, pswd, request_type):\n        if request_type == ImportRequest.TYPE_GET_LIST:\n            return ListImportRequest(cfg, login, pswd)\n        elif request_type == ImportRequest.TYPE_GET_SINGLE_OBJECT:\n            return SingleObjectImportRequest(cfg, login, pswd)\n        else:\n            raise NotImplementedError('Not supported request type - {}'.format(request_type))", "response": "Instantiate an ImportRequest instance based on the request type."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a widget for a schema item", "response": "def widget_for(element):\n    \"\"\"Create a widget for a schema item\n    \"\"\"\n    view_type = _view_type_for_element(element)\n    if view_type is None:\n        raise KeyError('No view type for %r' % element)\n    builder = view_widgets.get(view_type)\n    if builder is None:\n        raise KeyError('No widget type for %r' % view_type)\n    return builder(element)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef projection(radius=5e-6, sphere_index=1.339, medium_index=1.333,\n               wavelength=550e-9, pixel_size=1e-7, grid_size=(80, 80),\n               center=(39.5, 39.5)):\n    \"\"\"Optical path difference projection of a dielectric sphere\n\n    Parameters\n    ----------\n    radius: float\n        Radius of the sphere [m]\n    sphere_index: float\n        Refractive index of the sphere\n    medium_index: float\n        Refractive index of the surrounding medium\n    wavelength: float\n        Vacuum wavelength of the imaging light [m]\n    pixel_size: float\n        Pixel size [m]\n    grid_size: tuple of floats\n        Resulting image size in x and y [px]\n    center: tuple of floats\n        Center position in image coordinates [px]\n\n    Returns\n    -------\n    qpi: qpimage.QPImage\n        Quantitative phase data set\n    \"\"\"\n    # grid\n    x = np.arange(grid_size[0]).reshape(-1, 1)\n    y = np.arange(grid_size[1]).reshape(1, -1)\n    cx, cy = center\n    # sphere location\n    rpx = radius / pixel_size\n    r = rpx**2 - (x - cx)**2 - (y - cy)**2\n    # distance\n    z = np.zeros_like(r)\n    rvalid = r > 0\n    z[rvalid] = 2 * np.sqrt(r[rvalid]) * pixel_size\n    # phase = delta_n * 2PI * z / wavelength\n    phase = (sphere_index - medium_index) * 2 * np.pi * z / wavelength\n    meta_data = {\"pixel size\": pixel_size,\n                 \"wavelength\": wavelength,\n                 \"medium index\": medium_index,\n                 \"sim center\": center,\n                 \"sim radius\": radius,\n                 \"sim index\": sphere_index,\n                 \"sim model\": \"projection\",\n                 }\n    qpi = qpimage.QPImage(data=phase, which_data=\"phase\",\n                          meta_data=meta_data)\n    return qpi", "response": "Optical path difference projection of a dielectric sphere"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_first_builder_window(builder):\n    for obj in builder.get_objects():\n        if isinstance(obj, gtk.Window):\n            # first window\n            return obj", "response": "Get the first toplevel widget in a gtk. Builder hierarchy."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef show_and_run(self):\n        self.display_widget = gtk.Window()\n        self.display_widget.add(self.widget)\n        self.display_widget.show()\n        BaseDelegate.show_and_run(self)", "response": "Show the main widget in a window and run the gtk loop"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_builder_toplevel(self, builder):\n        toplevel = builder.get_object(self.toplevel_name)\n        if not gobject.type_is_a(toplevel, gtk.Window):\n            toplevel = None\n        if toplevel is None:\n            toplevel = get_first_builder_window(builder)\n        return toplevel", "response": "Get the toplevel widget from a gtk. Builder file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwrapping the call_cmd so it can be executed by subprocess. call and related flavors as args", "response": "def wrap_call(self, call_cmd):\n        \"\"\"\n        \"wraps\" the call_cmd so it can be executed by subprocess.call (and related flavors) as \"args\" argument\n\n        :param call_cmd: original args like argument (string or sequence)\n\n        :return: a sequence with the original command \"executed\" under trickle\n        \"\"\"\n\n        if isinstance(call_cmd, basestring):  # FIXME python 3 unsafe\n            call_cmd = [call_cmd]\n\n        return [self._trickle_cmd, \"-s\"] + self._settings.to_argument_list() + list(call_cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_unicode(s, encoding=None, errors='strict'):\n    encoding = encoding or 'utf-8'\n\n    if is_unicode(s):\n        return s\n    elif is_strlike(s):\n        return s.decode(encoding, errors)\n    else:\n        if six.PY2:\n            return str(s).decode(encoding, errors)\n        else:\n            return str(s)", "response": "Make unicode string from any value\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_str(s, encoding=None, errors='strict'):\n    encoding = encoding or 'utf-8'\n\n    if is_strlike(s):\n        if six.PY2:\n            return s.encode(encoding, errors) if isinstance(s, unicode) else s\n        else:\n            return s.decode(encoding, errors) if isinstance(s, bytes) else s\n    else:\n        return str(s)", "response": "Make str from any value\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts string to bytes.", "response": "def to_bytes(s, encoding=None, errors='strict'):\n    \"\"\"Convert string to bytes.\"\"\"\n    encoding = encoding or 'utf-8'\n\n    if is_unicode(s):\n        return s.encode(encoding, errors)\n    elif is_strlike(s):\n        return s\n    else:\n        if six.PY2:\n            return str(s)\n        else:\n            return str(s).encode(encoding, errors)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef edge_just(left, right, width, fillchar=' ', min_padding_length=1):\n    assert unicode_width(fillchar) == 1, 'fillchar must be single-width char'\n    padding = fillchar * max(min_padding_length, width - unicode_width(left + right))\n    return left + padding + right", "response": "Return a new node with left and right padding."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncut unicode string from left to fit a given width.", "response": "def unicode_left(s, width):\n    \"\"\"Cut unicode string from left to fit a given width.\"\"\"\n    i = 0\n    j = 0\n    for ch in s:\n        j += __unicode_width_mapping[east_asian_width(ch)]\n        if width < j:\n            break\n        i += 1\n    return s[:i]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncuts unicode string from right to fit a given width.", "response": "def unicode_right(s, width):\n    \"\"\"Cut unicode string from right to fit a given width.\"\"\"\n    i = len(s)\n    j = 0\n    for ch in reversed(s):\n        j += __unicode_width_mapping[east_asian_width(ch)]\n        if width < j:\n            break\n        i -= 1\n    return s[i:]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef unicode_decode(data, encoding_list):\n    assert encoding_list, 'encodings must not be empty.'\n\n    xs = distinct(encoding_list if isinstance(encoding_list, list) else [encoding_list])\n    first_exp = None\n    for i, encoding in enumerate(xs):\n        try:\n            return data.decode(encoding)\n        except UnicodeDecodeError as e:\n            if i == 0:\n                first_exp = e\n    raise first_exp", "response": "Decode string data with one or more encodings trying sequentially\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef diff(a, b):\n        delta = diff(a, b)\n        if not a:\n            return delta\n        for item in delta:\n            if isinstance(a[item], list):\n                if delta[item] == []:\n                    delta[item] = {JSONUtils.DIFF_DELETE : a[item]}\n                elif isinstance(delta[item], dict):\n                    for key in delta[item].keys():\n                        if str(key) == JSONUtils.DIFF_DELETE:\n                            delta_upd = {JSONUtils.DIFF_DELETE : []}\n                            for i in delta[item][key]:\n                                delta_upd[JSONUtils.DIFF_DELETE].append(a[item][i])\n                                delta[item] = delta_upd\n        return delta", "response": "Compares two JSON objects returning a dictionary with the difference in the same format."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef serialize(self, *fields):\n        if fields:\n            if not set(fields).issubset(self.data_nodes):\n                raise SchemaError('Invalid field for serialization: {}'.format(set(fields).difference(self.data_nodes)))\n\n            return OrderedDict([(k, getattr(self, k)) for k in fields])\n\n        return OrderedDict([(k, getattr(self, k)) for k in self.data_nodes])", "response": "Serialize Nodes and attributes\n           "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sanitize(configuration, error_fn):\n    for name, sanitize_fn in _SANITIZERS.items():\n        sanitize_fn(configuration, lambda warning, n=name: error_fn(n, warning))", "response": "Run all available sanitizers across a configuration."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the doc string with the deprecated and deprecated entries.", "response": "def _update_doc(self, func_doc):\n        \"\"\"\u66f4\u65b0\u6587\u6863\u4fe1\u606f\uff0c\u628a\u539f\u6765\u7684\u6587\u6863\u4fe1\u606f\u8fdb\u884c\u5408\u5e76\u683c\u5f0f\u5316,\n        \u5373\u7b2c\u4e00\u884c\u4e3adeprecated_doc(Deprecated: tip_info)\uff0c\u4e0b\u4e00\u884c\u4e3a\u539f\u59cbfunc_doc\"\"\"\n        deprecated_doc = \"Deprecated\"\n        if self.tip_info:\n            deprecated_doc = \"{}: {}\".format(deprecated_doc, self.tip_info)\n        if func_doc:\n            func_doc = \"{}\\n{}\".format(deprecated_doc, func_doc)\n        return func_doc"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef s2n(self, offset, length, signed=0):\n        self.file.seek(self.offset + offset)\n        sliced = self.file.read(length)\n        if self.endian == 'I':\n            val = s2n_intel(sliced)\n        else:\n            val = s2n_motorola(sliced)\n            # Sign extension?\n        if signed:\n            msb = 1 << (8 * length - 1)\n            if val & msb:\n                val -= (msb << 1)\n        return val", "response": "Convert slice to integer based on sign and endian flags."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef n2s(self, offset, length):\n        s = ''\n        for dummy in range(length):\n            if self.endian == 'I':\n                s += chr(offset & 0xFF)\n            else:\n                s = chr(offset & 0xFF) + s\n            offset = offset >> 8\n        return s", "response": "Convert offset to string."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _next_ifd(self, ifd):\n        entries = self.s2n(ifd, 2)\n        next_ifd = self.s2n(ifd + 2 + 12 * entries, 4)\n        if next_ifd == ifd:\n            return 0\n        else:\n            return next_ifd", "response": "Return the pointer to next IFD."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_ifd(self):\n        i = self._first_ifd()\n        ifds = []\n        while i:\n            ifds.append(i)\n            i = self._next_ifd(i)\n        return ifds", "response": "Return the list of IFDs in the header."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dump_ifd(self, ifd, ifd_name, tag_dict=EXIF_TAGS, relative=0, stop_tag=DEFAULT_STOP_TAG):\n        # make sure we can process the entries\n        try:\n            entries = self.s2n(ifd, 2)\n        except TypeError:\n            logger.warning(\"Possibly corrupted IFD: %s\" % ifd)\n            return\n\n        for i in range(entries):\n            # entry is index of start of this IFD in the file\n            entry = ifd + 2 + 12 * i\n            tag = self.s2n(entry, 2)\n\n            # get tag name early to avoid errors, help debug\n            tag_entry = tag_dict.get(tag)\n            if tag_entry:\n                tag_name = tag_entry[0]\n            else:\n                tag_name = 'Tag 0x%04X' % tag\n\n            # ignore certain tags for faster processing\n            if not (not self.detailed and tag in IGNORE_TAGS):\n                field_type = self.s2n(entry + 2, 2)\n\n                # unknown field type\n                if not 0 < field_type < len(FIELD_TYPES):\n                    if not self.strict:\n                        continue\n                    else:\n                        raise ValueError('Unknown type %d in tag 0x%04X' % (field_type, tag))\n\n                type_length = FIELD_TYPES[field_type][0]\n                count = self.s2n(entry + 4, 4)\n                # Adjust for tag id/type/count (2+2+4 bytes)\n                # Now we point at either the data or the 2nd level offset\n                offset = entry + 8\n\n                # If the value fits in 4 bytes, it is inlined, else we\n                # need to jump ahead again.\n                if count * type_length > 4:\n                    # offset is not the value; it's a pointer to the value\n                    # if relative we set things up so s2n will seek to the right\n                    # place when it adds self.offset.  Note that this 'relative'\n                    # is for the Nikon type 3 makernote.  Other cameras may use\n                    # other relative offsets, which would have to be computed here\n                    # slightly differently.\n                    if relative:\n                        tmp_offset = self.s2n(offset, 4)\n                        offset = tmp_offset + ifd - 8\n                        if self.fake_exif:\n                            offset += 18\n                    else:\n                        offset = self.s2n(offset, 4)\n\n                field_offset = offset\n                values = None\n                if field_type == 2:\n                    # special case: null-terminated ASCII string\n                    # XXX investigate\n                    # sometimes gets too big to fit in int value\n                    if count != 0:  # and count < (2**31):  # 2E31 is hardware dependant. --gd\n                        file_position = self.offset + offset\n                        try:\n                            self.file.seek(file_position)\n                            values = self.file.read(count)\n                            #print(values)\n                            # Drop any garbage after a null.\n                            values = values.split(b'\\x00', 1)[0]\n                            if isinstance(values, bytes):\n                                try:\n                                    values = values.decode(\"utf-8\")\n                                except UnicodeDecodeError:\n                                    logger.warning(\"Possibly corrupted field %s in %s IFD\", tag_name, ifd_name)\n                        except OverflowError:\n                            logger.warn('OverflowError at position: %s, length: %s', file_position, count)\n                            values = ''\n                        except MemoryError:\n                            logger.warn('MemoryError at position: %s, length: %s', file_position, count)\n                            values = ''\n                else:\n                    values = []\n                    signed = (field_type in [6, 8, 9, 10])\n\n                    # XXX investigate\n                    # some entries get too big to handle could be malformed\n                    # file or problem with self.s2n\n                    if count < 1000:\n                        for dummy in range(count):\n                            if field_type in (5, 10):\n                                # a ratio\n                                value = Ratio(self.s2n(offset, 4, signed),\n                                              self.s2n(offset + 4, 4, signed))\n                            else:\n                                value = self.s2n(offset, type_length, signed)\n                            values.append(value)\n                            offset = offset + type_length\n                    # The test above causes problems with tags that are\n                    # supposed to have long values! Fix up one important case.\n                    elif tag_name in ('MakerNote', makernote.canon.CAMERA_INFO_TAG_NAME):\n                        for dummy in range(count):\n                            value = self.s2n(offset, type_length, signed)\n                            values.append(value)\n                            offset = offset + type_length\n\n                # now 'values' is either a string or an array\n                if count == 1 and field_type != 2:\n                    printable = str(values[0])\n                elif count > 50 and len(values) > 20:\n                    printable = str(values[0:20])[0:-1] + \", ... ]\"\n                else:\n                    try:\n                        printable = str(values)\n                    # fix for python2's handling of unicode values\n                    except UnicodeEncodeError:\n                        printable = unicode(values)\n\n                # compute printable version of values\n                if tag_entry:\n                    # optional 2nd tag element is present\n                    if len(tag_entry) != 1:\n                        if callable(tag_entry[1]):\n                            # call mapping function\n                            printable = tag_entry[1](values)\n                        elif type(tag_entry[1]) is tuple:\n                            ifd_info = tag_entry[1]\n                            try:\n                                logger.debug('%s SubIFD at offset %d:', ifd_info[0], values[0])\n                                self.dump_ifd(values[0], ifd_info[0], tag_dict=ifd_info[1], stop_tag=stop_tag)\n                            except IndexError:\n                                logger.warn('No values found for %s SubIFD', ifd_info[0])\n                        else:\n                            printable = ''\n                            for i in values:\n                                # use lookup table for this tag\n                                printable += tag_entry[1].get(i, repr(i))\n\n                self.tags[ifd_name + ' ' + tag_name] = IfdTag(printable, tag,\n                                                              field_type,\n                                                              values, field_offset,\n                                                              count * type_length)\n                try:\n                    tag_value = repr(self.tags[ifd_name + ' ' + tag_name])\n                # fix for python2's handling of unicode values\n                except UnicodeEncodeError:\n                    tag_value = unicode(self.tags[ifd_name + ' ' + tag_name])\n                logger.debug(' %s: %s', tag_name, tag_value)\n\n            if tag_name == stop_tag:\n                break", "response": "Dump the contents of an IFD into a list of entries."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef extract_tiff_thumbnail(self, thumb_ifd):\n        thumb = self.tags.get('Thumbnail Compression')\n        if not thumb or thumb.printable != 'Uncompressed TIFF':\n            return\n\n        entries = self.s2n(thumb_ifd, 2)\n        # this is header plus offset to IFD ...\n        if self.endian == 'M':\n            tiff = 'MM\\x00*\\x00\\x00\\x00\\x08'\n        else:\n            tiff = 'II*\\x00\\x08\\x00\\x00\\x00'\n            # ... plus thumbnail IFD data plus a null \"next IFD\" pointer\n        self.file.seek(self.offset + thumb_ifd)\n        tiff += self.file.read(entries * 12 + 2) + '\\x00\\x00\\x00\\x00'\n\n        # fix up large value offset pointers into data area\n        for i in range(entries):\n            entry = thumb_ifd + 2 + 12 * i\n            tag = self.s2n(entry, 2)\n            field_type = self.s2n(entry + 2, 2)\n            type_length = FIELD_TYPES[field_type][0]\n            count = self.s2n(entry + 4, 4)\n            old_offset = self.s2n(entry + 8, 4)\n            # start of the 4-byte pointer area in entry\n            ptr = i * 12 + 18\n            # remember strip offsets location\n            if tag == 0x0111:\n                strip_off = ptr\n                strip_len = count * type_length\n                # is it in the data area?\n            if count * type_length > 4:\n                # update offset pointer (nasty \"strings are immutable\" crap)\n                # should be able to say \"tiff[ptr:ptr+4]=newoff\"\n                newoff = len(tiff)\n                tiff = tiff[:ptr] + self.n2s(newoff, 4) + tiff[ptr + 4:]\n                # remember strip offsets location\n                if tag == 0x0111:\n                    strip_off = newoff\n                    strip_len = 4\n                # get original data and store it\n                self.file.seek(self.offset + old_offset)\n                tiff += self.file.read(count * type_length)\n\n        # add pixel strips and update strip offset info\n        old_offsets = self.tags['Thumbnail StripOffsets'].values\n        old_counts = self.tags['Thumbnail StripByteCounts'].values\n        for i in range(len(old_offsets)):\n            # update offset pointer (more nasty \"strings are immutable\" crap)\n            offset = self.n2s(len(tiff), strip_len)\n            tiff = tiff[:strip_off] + offset + tiff[strip_off + strip_len:]\n            strip_off += strip_len\n            # add pixel strip to end\n            self.file.seek(self.offset + old_offsets[i])\n            tiff += self.file.read(old_counts[i])\n\n        self.tags['TIFFThumbnail'] = tiff", "response": "Extract uncompressed TIFF thumbnail."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extract_jpeg_thumbnail(self):\n        thumb_offset = self.tags.get('Thumbnail JPEGInterchangeFormat')\n        if thumb_offset:\n            self.file.seek(self.offset + thumb_offset.values[0])\n            size = self.tags['Thumbnail JPEGInterchangeFormatLength'].values[0]\n            self.tags['JPEGThumbnail'] = self.file.read(size)\n\n        # Sometimes in a TIFF file, a JPEG thumbnail is hidden in the MakerNote\n        # since it's not allowed in a uncompressed TIFF IFD\n        if 'JPEGThumbnail' not in self.tags:\n            thumb_offset = self.tags.get('MakerNote JPEGThumbnail')\n            if thumb_offset:\n                self.file.seek(self.offset + thumb_offset.values[0])\n                self.tags['JPEGThumbnail'] = self.file.read(thumb_offset.field_length)", "response": "Extract JPEG thumbnail.\n\n        (Thankfully the JPEG data is stored as a unit.)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef decode_maker_note(self):\n        note = self.tags['EXIF MakerNote']\n\n        # Some apps use MakerNote tags but do not use a format for which we\n        # have a description, so just do a raw dump for these.\n        make = self.tags['Image Make'].printable\n\n        # Nikon\n        # The maker note usually starts with the word Nikon, followed by the\n        # type of the makernote (1 or 2, as a short).  If the word Nikon is\n        # not at the start of the makernote, it's probably type 2, since some\n        # cameras work that way.\n        if 'NIKON' in make:\n            if note.values[0:7] == [78, 105, 107, 111, 110, 0, 1]:\n                logger.debug(\"Looks like a type 1 Nikon MakerNote.\")\n                self.dump_ifd(note.field_offset + 8, 'MakerNote',\n                              tag_dict=makernote.nikon.TAGS_OLD)\n            elif note.values[0:7] == [78, 105, 107, 111, 110, 0, 2]:\n                logger.debug(\"Looks like a labeled type 2 Nikon MakerNote\")\n                if note.values[12:14] != [0, 42] and note.values[12:14] != [42, 0]:\n                    raise ValueError(\"Missing marker tag '42' in MakerNote.\")\n                    # skip the Makernote label and the TIFF header\n                self.dump_ifd(note.field_offset + 10 + 8, 'MakerNote',\n                              tag_dict=makernote.nikon.TAGS_NEW, relative=1)\n            else:\n                # E99x or D1\n                logger.debug(\"Looks like an unlabeled type 2 Nikon MakerNote\")\n                self.dump_ifd(note.field_offset, 'MakerNote',\n                              tag_dict=makernote.nikon.TAGS_NEW)\n            return\n\n        # Olympus\n        if make.startswith('OLYMPUS'):\n            self.dump_ifd(note.field_offset + 8, 'MakerNote',\n                          tag_dict=makernote.olympus.TAGS)\n            # TODO\n            #for i in (('MakerNote Tag 0x2020', makernote.OLYMPUS_TAG_0x2020),):\n            #    self.decode_olympus_tag(self.tags[i[0]].values, i[1])\n            #return\n\n        # Casio\n        if 'CASIO' in make or 'Casio' in make:\n            self.dump_ifd(note.field_offset, 'MakerNote',\n                          tag_dict=makernote.casio.TAGS)\n            return\n\n        # Fujifilm\n        if make == 'FUJIFILM':\n            # bug: everything else is \"Motorola\" endian, but the MakerNote\n            # is \"Intel\" endian\n            endian = self.endian\n            self.endian = 'I'\n            # bug: IFD offsets are from beginning of MakerNote, not\n            # beginning of file header\n            offset = self.offset\n            self.offset += note.field_offset\n            # process note with bogus values (note is actually at offset 12)\n            self.dump_ifd(12, 'MakerNote', tag_dict=makernote.fujifilm.TAGS)\n            # reset to correct values\n            self.endian = endian\n            self.offset = offset\n            return\n\n        # Apple\n        if make == 'Apple' and \\\n                note.values[0:10] == [65, 112, 112, 108, 101, 32, 105, 79, 83, 0]:\n            t = self.offset\n            self.offset += note.field_offset+14\n            self.dump_ifd(0, 'MakerNote',\n                          tag_dict=makernote.apple.TAGS)\n            self.offset = t\n            return\n\n        # Canon\n        if make == 'Canon':\n            self.dump_ifd(note.field_offset, 'MakerNote',\n                          tag_dict=makernote.canon.TAGS)\n\n            for i in (('MakerNote Tag 0x0001', makernote.canon.CAMERA_SETTINGS),\n                      ('MakerNote Tag 0x0002', makernote.canon.FOCAL_LENGTH),\n                      ('MakerNote Tag 0x0004', makernote.canon.SHOT_INFO),\n                      ('MakerNote Tag 0x0026', makernote.canon.AF_INFO_2),\n                      ('MakerNote Tag 0x0093', makernote.canon.FILE_INFO)):\n                if i[0] in self.tags:\n                    logger.debug('Canon ' + i[0])\n                    self._canon_decode_tag(self.tags[i[0]].values, i[1])\n                    del self.tags[i[0]]\n            if makernote.canon.CAMERA_INFO_TAG_NAME in self.tags:\n                tag = self.tags[makernote.canon.CAMERA_INFO_TAG_NAME]\n                logger.debug('Canon CameraInfo')\n                self._canon_decode_camera_info(tag)\n                del self.tags[makernote.canon.CAMERA_INFO_TAG_NAME]\n            return", "response": "Decode all the camera - specific MakerNote tags into a MakerNote object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndecoding Canon MakerNote tag based on offset within tag.", "response": "def _canon_decode_tag(self, value, mn_tags):\n        \"\"\"\n        Decode Canon MakerNote tag based on offset within tag.\n\n        See http://www.burren.cx/david/canon.html by David Burren\n        \"\"\"\n        for i in range(1, len(value)):\n            tag = mn_tags.get(i, ('Unknown', ))\n            name = tag[0]\n            if len(tag) > 1:\n                val = tag[1].get(value[i], 'Unknown')\n            else:\n                val = value[i]\n            try:\n                logger.debug(\" %s %s %s\", i, name, hex(value[i]))\n            except TypeError:\n                logger.debug(\" %s %s %s\", i, name, value[i])\n\n            # it's not a real IFD Tag but we fake one to make everybody\n            # happy. this will have a \"proprietary\" type\n            self.tags['MakerNote ' + name] = IfdTag(str(val), None, 0, None,\n                                                    None, None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndecodes the variable length encoded camera info section.", "response": "def _canon_decode_camera_info(self, camera_info_tag):\n        \"\"\"\n        Decode the variable length encoded camera info section.\n        \"\"\"\n        model = self.tags.get('Image Model', None)\n        if not model:\n            return\n        model = str(model.values)\n\n        camera_info_tags = None\n        for (model_name_re, tag_desc) in makernote.canon.CAMERA_INFO_MODEL_MAP.items():\n            if re.search(model_name_re, model):\n                camera_info_tags = tag_desc\n                break\n        else:\n            return\n\n        # We are assuming here that these are all unsigned bytes (Byte or\n        # Unknown)\n        if camera_info_tag.field_type not in (1, 7):\n            return\n        camera_info = struct.pack('<%dB' % len(camera_info_tag.values),\n                                  *camera_info_tag.values)\n\n        # Look for each data value and decode it appropriately.\n        for offset, tag in camera_info_tags.items():\n            tag_format = tag[1]\n            tag_size = struct.calcsize(tag_format)\n            if len(camera_info) < offset + tag_size:\n                continue\n            packed_tag_value = camera_info[offset:offset + tag_size]\n            tag_value = struct.unpack(tag_format, packed_tag_value)[0]\n\n            tag_name = tag[0]\n            if len(tag) > 2:\n                if callable(tag[2]):\n                    tag_value = tag[2](tag_value)\n                else:\n                    tag_value = tag[2].get(tag_value, tag_value)\n            logger.debug(\" %s %s\", tag_name, tag_value)\n\n            self.tags['MakerNote ' + tag_name] = IfdTag(str(tag_value), None,\n                                                        0, None, None, None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses arguments returns options and args.", "response": "def parse_args(args=None):\n    \"\"\"Parses arguments, returns (options, args).\"\"\"\n    import sys\n    from argparse import ArgumentParser\n    from path_helpers import path\n\n    if args is None:\n        args = sys.argv\n\n    parser = ArgumentParser(description='Example app for drawing shapes from '\n                            'dataframe, scaled to fit to GTK canvas while '\n                            'preserving aspect ratio (a.k.a., aspect fit).')\n    parser.add_argument('svg_filepath', type=path, default=None)\n    parser.add_argument('-p', '--padding-fraction', type=float, default=0)\n\n    args = parser.parse_args()\n    return args"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_ui(self):\n        '''\n        .. versionchanged:: 0.20\n            Debounce window expose and resize handlers to improve\n            responsiveness.\n\n        .. versionchanged:: X.X.X\n            Call debounced `_on_expose_event` handler on _leading_ edge to make\n            UI update more responsive when, e.g., changing window focus.\n\n            Decrease debounce time to 250 ms.\n        '''\n        super(GtkShapesCanvasView, self).create_ui()\n        self.widget.set_events(gtk.gdk.BUTTON_PRESS |\n                               gtk.gdk.BUTTON_RELEASE |\n                               gtk.gdk.BUTTON_MOTION_MASK |\n                               gtk.gdk.BUTTON_PRESS_MASK |\n                               gtk.gdk.BUTTON_RELEASE_MASK |\n                               gtk.gdk.POINTER_MOTION_HINT_MASK)\n        self._dirty_check_timeout_id = gtk.timeout_add(30, self.check_dirty)\n\n        self.resize = Debounce(self._resize, wait=250)\n        debounced_on_expose_event = Debounce(self._on_expose_event, wait=250,\n                                             leading=True, trailing=True)\n        self.widget.connect('expose-event', debounced_on_expose_event)", "response": "Create the UI for the current version of the user."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if the dirty state of the log is still valid.", "response": "def check_dirty(self):\n        '''\n        .. versionchanged:: 0.20\n            Do not log size change.\n        '''\n        if self._dirty_size is None:\n            if self._dirty_render:\n                self.render()\n                self._dirty_render = False\n            if self._dirty_draw:\n                self.draw()\n                self._dirty_draw = False\n            return True\n        width, height = self._dirty_size\n        self._dirty_size = None\n        self.reset_canvas(width, height)\n        self._dirty_render = True\n        self._dirty_draw = True\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalling when size of drawing area changes.", "response": "def on_widget__configure_event(self, widget, event):\n        '''\n        Called when size of drawing area changes.\n        '''\n        if event.x < 0 and event.y < 0:\n            # Widget has not been allocated a size yet, so do nothing.\n            return\n        self.resize(event.width, event.height)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalls when a Cairo surface is drawn and the event is emitted.", "response": "def _on_expose_event(self, widget, event):\n        '''\n        .. versionchanged:: 0.20\n            Renamed from ``on_widget__expose_event`` to allow wrapping for\n            debouncing to improve responsiveness.\n\n        Called when drawing area is first displayed and, for example, when part\n        of drawing area is uncovered after being covered up by another window.\n\n        Clear canvas, draw frame off screen, and mark dirty.\n        '''\n        logger.info('on_widget__expose_event')\n\n        # Request immediate paint of pre-rendered off-screen Cairo surface to\n        # drawing area widget, but also mark as dirty to redraw after next\n        # render.\n        self.draw()\n        self._dirty_draw = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndraws label on specified shape.", "response": "def render_label(self, cairo_context, shape_id, text=None, label_scale=.9):\n        '''\n        Draw label on specified shape.\n\n        Parameters\n        ----------\n        cairo_context : cairo.Context\n            Cairo context to draw text width.  Can be preconfigured, for\n            example, to set font style, etc.\n        shape_id : str\n            Shape identifier.\n        text : str, optional\n            Label text.  If not specified, shape identifier is used.\n        label_scale : float, optional\n            Fraction of limiting dimension of shape bounding box to scale text\n            to.\n        '''\n        text = shape_id if text is None else text\n        shape = self.canvas.df_bounding_shapes.ix[shape_id]\n        shape_center = self.canvas.df_shape_centers.ix[shape_id]\n        font_size, text_shape = \\\n            aspect_fit_font_size(text, shape * label_scale,\n                                 cairo_context=cairo_context)\n        cairo_context.set_font_size(font_size)\n        cairo_context.move_to(shape_center[0] - .5 * text_shape.width,\n                              shape_center[1] + .5 * text_shape.height)\n        cairo_context.show_text(text)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate the UI for the current locale.", "response": "def create_ui(self):\n        '''\n        .. versionchanged:: 0.21.2\n            Load the builder configuration file using :func:`pkgutil.getdata`,\n            which supports loading from `.zip` archives (e.g., in an app\n            packaged with Py2Exe).\n        '''\n        builder = gtk.Builder()\n        # Read glade file using `pkgutil` to also support loading from `.zip`\n        # files (e.g., in app packaged with Py2Exe).\n        glade_str = pkgutil.get_data(__name__,\n                                     'glade/form_view_dialog.glade')\n        builder.add_from_string(glade_str)\n\n        self.window = builder.get_object('form_view_dialog')\n        self.vbox_form = builder.get_object('vbox_form')\n        if self.title:\n            self.window.set_title(self.title)\n        if self.short_desc:\n            self.short_label = gtk.Label()\n            self.short_label.set_text(self.short_desc)\n            self.short_label.set_alignment(0, .5)\n            self.vbox_form.pack_start(self.short_label, expand=True, fill=True)\n        if self.long_desc:\n            self.long_label = gtk.Label()\n            self.long_label.set_text(self.long_desc)\n            self.long_label.set_alignment(.1, .5)\n            self.long_expander = gtk.Expander(label='Details')\n            self.long_expander.set_spacing(5)\n            self.long_expander.add(self.long_label)\n            self.vbox_form.pack_start(self.long_expander, expand=True,\n                                      fill=True)\n        if self.parent is None:\n            self.parent = self.default_parent\n        self.window.set_default_response(gtk.RESPONSE_OK)\n        self.window.set_position(gtk.WIN_POS_CENTER_ON_PARENT)\n        if self.parent:\n            self.window.set_transient_for(self.parent)\n        self.window.show_all()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating the user interface that is used by the Delegate s base class.", "response": "def create_ui(self):\n        \"\"\"Create the user interface\n\n           create_ui is a method called during the Delegate's\n           initialisation process, to create, add to, or modify any UI\n           created by GtkBuilder files.\n        \"\"\"\n        self.entry = gtk.Entry()\n        self.widget.add(self.entry)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate the fields of the objectlist item based on the row values.", "response": "def _update_row_fields(self, form_name, row_id, attrs):\n        '''\n        -get row values for (form_name, row_id)\n        -set affected objectlist item attributes based on row values\n        '''\n        if form_name not in self._forms or row_id >= len(self):\n            return\n        combined_row = self[row_id]\n        form_row = combined_row.get_row_fields(form_name)\n\n        for attr, value in attrs.items():\n            setattr(form_row, attr, value)\n        self.update(combined_row)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfunctioning group_singles2array Creates array of strings or ints from objects field. single", "response": "def group_singles2array(input, **params):\n    \"\"\"\n    Creates array of strings or ints from objects' fields\n    :param input: list of objects\n    :param params:\n    :return: list\n    \"\"\"\n    PARAM_FIELD_KEY = 'field.key'\n    PARAM_FIELD_ARRAY = 'field.array'\n    PARAM_FIELD_SINGLE = 'field.single'\n\n    field_key = params.get(PARAM_FIELD_KEY) if PARAM_FIELD_KEY in params else None\n    field_array = params.get(PARAM_FIELD_ARRAY)\n    field_single = params.get(PARAM_FIELD_SINGLE)\n\n    if not field_key:\n        res = []\n        for item in input:\n            res.append(item[field_single])\n        return {field_array: res}\n    else:\n        tdict = {}\n        for row in input:\n            if not row[field_key] in tdict:\n                tdict.update({row[field_key]: [row[field_single]]})\n            else:\n                tdict[row[field_key]].append(row[field_single])\n        res = []\n        for key, value in tdict.items():\n            res.append({field_key: key, field_array: value})\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfunctions ungroup_array2singles - Creates list of objects from array of singles.", "response": "def ungroup_array2singles(input, **params):\n    \"\"\"\n    Creates list of objects from array of singles\n    :param input: list of strings or ints\n    :param params:\n    :return:\n    \"\"\"\n    PARAM_FIELD_KEY = 'field.key'\n    PARAM_FIELD_ARRAY = 'field.array'\n    PARAM_FIELD_SINGLE = 'field.single'\n\n    res = []\n    field_key = params.get(PARAM_FIELD_KEY) if PARAM_FIELD_KEY in params else None\n    field_array = params.get(PARAM_FIELD_ARRAY)\n    field_single = params.get(PARAM_FIELD_SINGLE)\n    for row in input:\n        if row[field_array] and len(row[field_array]) > 0:\n            for value in row[field_array]:\n                res.append({field_single: value} if not field_key else {field_key: row[field_key], field_single: value})\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\napply WHERE filter to input dataset", "response": "def filter_set(input, **params):\n    \"\"\"\n    Apply WHERE filter to input dataset\n    :param input:\n    :param params:\n    :return: filtered data\n    \"\"\"\n    PARAM_WHERE = 'where'\n\n    return Converter.df2list(pd.DataFrame.from_records(input).query(params.get(PARAM_WHERE)))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\napplying sorting to input dataset", "response": "def sort_set(input, **params):\n    \"\"\"\n    Apply sorting to input dataset\n    :param input:\n    :param params:\n    :return: sorted data\n    \"\"\"\n    PARAM_SORT_FIELD = 'sort.field'\n    PARAM_SORT_ORDER = 'sort.order'\n\n    df = pd.DataFrame.from_records(input)\n    sort_field = params.get(PARAM_SORT_FIELD)\n    sort_order = params.get(PARAM_SORT_ORDER) if PARAM_SORT_ORDER in params else None\n    if sort_order:\n        df[sort_field] = df[sort_field].astype('category')\n        df[sort_field].cat.set_categories(sort_order, inplace=True)\n    df.sort_values(by=sort_field, inplace=True)\n    return Converter.df2list(df)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a copy of the input or input s selected fields", "response": "def copy(input, **params):\n    \"\"\"\n    Copies input or input's selected fields\n    :param input:\n    :param params:\n    :return: input\n    \"\"\"\n    PARAM_FIELDS = 'fields'\n\n    def filter_fields(obj, fields):\n        return {k:v for k,v in obj.items() if k in fields}\n\n    if PARAM_FIELDS in params:\n        fields = params.get(PARAM_FIELDS)\n        if isinstance(input, list):\n            res = []\n            for row in input:\n                res.append(filter_fields(row, fields))\n            return res\n        elif isinstance(input, dict):\n            return filter_fields(input, fields)\n        else:\n            raise NotImplementedError('{} is not supported'.format(type(input)))\n    else:\n        return input"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing input according to pattern", "response": "def regexp(input, **params):\n    \"\"\"\n    Parses input according to pattern\n    :param input:\n    :param params:\n    :return:\n    \"\"\"\n    PARAM_FIELD_TO_PARSE = 'input.field'\n    PARAM_PATTERN = 'pattern'\n    PARAM_OUTPUT = 'output'\n    OUT_DESC_FIELD = 'field'\n    OUT_DESC_IDX = 'idx'\n    OUT_DESC_TYPE = 'type'\n\n    res = []\n    regex = re.compile(params.get(PARAM_PATTERN))\n    field2parse = params.get(PARAM_FIELD_TO_PARSE)\n    out_desc = params.get(PARAM_OUTPUT)\n    for row in input:\n        matches = regex.findall(row[field2parse])[0]\n        obj = {}\n        for desc in out_desc:\n            obj[desc[OUT_DESC_FIELD]] = Converter.convert(matches[desc[OUT_DESC_IDX]], desc[OUT_DESC_TYPE])\n        res.append(obj)\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef format(input, **params):\n    PARAM_FORMAT_STRING = 'format.string'\n    PARAM_FORMAT_INPUT = 'format.input'\n    PARAM_RESULT_FIELD = 'result.field'\n    IN_DESC_FIELD = 'field'\n    IN_DESC_TYPE = 'type'\n\n    format_string = params.get(PARAM_FORMAT_STRING)\n    format_inputs = params.get(PARAM_FORMAT_INPUT)\n    result_field = params.get(PARAM_RESULT_FIELD)\n    for row in input:\n        row_input = []\n        for desc in format_inputs:\n            row_input.append(Converter.convert(row[desc[IN_DESC_FIELD]], desc[IN_DESC_TYPE]))\n        row[result_field] = format_string.format(*row_input)\n    return input", "response": "Formats the object in the order they appear in the order they appear in the object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nleave join transformation :param input: :param params: :return:", "response": "def left_join(input, **params):\n    \"\"\"\n    Left join transformation\n    :param input:\n    :param params:\n    :return:\n    \"\"\"\n    PARAM_COL_RIGHT = 'col.right'\n    PARAM_COL_LEFT = 'col.left'\n    PARAM_FIELD_JOIN = 'field.join'\n\n    right_df = pd.DataFrame.from_records(input[params.get(PARAM_COL_RIGHT)])\n    left_df = pd.DataFrame.from_records(input[params.get(PARAM_COL_LEFT)])\n    join_on = params.get(PARAM_FIELD_JOIN)\n    res = right_df.set_index(join_on, drop=False).join(left_df.set_index(join_on, drop=False), on=[join_on], rsuffix='_right')\n    return Converter.df2list(res)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_doc(input, **params):\n    PARAM_SOURCE = 'source'\n    SOURCE_COL = 'src.col'\n    SOURCE_FIELD = 'src.field'\n    PARAM_RESULT = 'result'\n\n    res = input[params.get(PARAM_RESULT)]\n    for src in params.get(PARAM_SOURCE):\n        res[src[SOURCE_FIELD]] = input[src[SOURCE_COL]][src[SOURCE_FIELD]]\n    return res", "response": "Updates a document with value from another document"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate a document with value from another document / collection / constant", "response": "def update_col(input, **params):\n    \"\"\"\n    Updates document with value from another document/collection/constant\n    :param input:\n    :param params:\n    :return:\n    \"\"\"\n    PARAM_TARGET = 'target'\n    PARAM_UPDATE = 'update'\n    SOURCE_TYPE = 'src.type'\n    SOURCE_COL = 'src.col'\n    SOURCE_FIELD = 'src.field'\n    DEST_FIELD = 'dest.field'\n    SOURCE_TYPE_DOC = 'doc'\n    SOURCE_TYPE_CONST = 'const'\n    CONST_VALUE = 'const.value'\n\n    update_list = params.get(PARAM_UPDATE)\n    res = input[params.get(PARAM_TARGET)] if PARAM_TARGET in params else input\n    for row in res:\n        for update_desc in update_list:\n            if update_desc[SOURCE_TYPE] == SOURCE_TYPE_DOC:\n                row[update_desc[DEST_FIELD]] = input[update_desc[SOURCE_COL]][update_desc[SOURCE_FIELD]]\n            elif update_desc[SOURCE_TYPE] == SOURCE_TYPE_CONST:\n                row[update_desc[DEST_FIELD]] = update_desc[CONST_VALUE]\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef replace(input, **params):\n    PARAM_REPLACE_LIST = 'replace'\n    REPLACE_FIELD = 'field'\n    REPLACE_FIND_VALUE = 'value.to_find'\n    REPLACE_WITH_VALUE = 'value.replace_with'\n\n    replace_list = params.get(PARAM_REPLACE_LIST)\n    for row in input:\n        for replace in replace_list:\n            if row[replace[REPLACE_FIELD]] == replace[REPLACE_FIND_VALUE]:\n                row[replace[REPLACE_FIELD]] = replace[REPLACE_WITH_VALUE]\n    return input", "response": "Replaces field value in a node."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rename_fields(input, **params):\n    PARAM_RENAME_LIST = 'rename'\n    RENAME_SRC_FIELD = 'src.field'\n    RENAME_DEST_FIELD = 'dest.field'\n\n    rename_list = params.get(PARAM_RENAME_LIST)\n    for row in input:\n        for rename in rename_list:\n            row[rename[RENAME_DEST_FIELD]] = row[rename[RENAME_SRC_FIELD]]\n            row.pop(rename[RENAME_SRC_FIELD])\n    return input", "response": "Renames field in collection\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfunctioning that takes a list of dictionaries and returns a new list of the same size.", "response": "def list_concat(input, **params):\n    \"\"\"\n    Concatenates two or more lists and put result into dest field\n    :param input:\n    :param params:\n    :return:\n    \"\"\"\n    PARAM_SOURCE_FIELDS = 'src.fields'\n    PARAM_DEST_FIELD = 'dest.field'\n\n    field_list = params.get(PARAM_SOURCE_FIELDS)\n    for row in input:\n        res = []\n        for field in field_list:\n            res += row[field]\n        row[params.get(PARAM_DEST_FIELD)] = res\n    return input"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef factory(cfg, src_db, dest_db):\n        return obj_for_name(cfg[Transformation.__CFG_KEY_TRANSFORMATION_CLASS])(\n            cfg[Transformation.CFG_KEY_TRANSFORMATION_CFG], src_db, dest_db)", "response": "Instantiate a new Transformation object from a configuration."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef perform(self, cfg):\n        self.__src = self._load(cfg[Transformation.__CFG_KEY_LOAD])\n        self.__transform(cfg[Transformation.__CFG_KEY_TRANSFORM])\n        self.__cleanup(cfg[Transformation.__CFG_KEY_CLEANUP])\n        self.__save(cfg[Transformation.__CFG_KEY_SAVE])", "response": "Perform transformation according to configuration\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nnote Expects Compressor Block like objects", "response": "def do_heavy_work(self, block):\n        \"\"\"\n        Note: Expects Compressor Block like objects\n        \"\"\"\n\n        destinations = self.destinations()\n        ''' FIXME currently we return block whether it was correctly processed or not because MailSenders are chained\n            and not doing that would mean other wouldn't be able to try.'''\n        if not set(destinations).issubset(block.destinations):\n            self.log.debug(\"Block not for any of the associated destinations: %s\", destinations)\n        else:\n            try:\n                self.do_send(block)\n                # mark the block as sent by this sender\n                block.send_destinations.extend(destinations)\n\n                verif_data = self.verification_data()\n                if verif_data is not None:\n                    for destination in destinations:\n                        block.destinations_verif_data[destination] = verif_data\n            except SendingError:\n                self.log.exception(\"Failed to send block (%s) to destination (%s)\", block, destinations)\n        return block"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate hash for given file", "response": "def get_file_hash(file_path, block_size=1024, hasher=None):\n    \"\"\"\n    Generate hash for given file\n\n    :param file_path: Path to file\n    :type file_path: str\n    :param block_size: Size of block to be read at once (default: 1024)\n    :type block_size: int\n    :param hasher: Use specific hasher, defaults to md5 (default: None)\n    :type hasher: _hashlib.HASH\n    :return: Hash of file\n    :rtype: str\n    \"\"\"\n    if hasher is None:\n        hasher = hashlib.md5()\n    with open(file_path, 'rb') as f:\n        while True:\n            buffer = f.read(block_size)\n            if len(buffer) <= 0:\n                break\n            hasher.update(buffer)\n    return hasher.hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef resource_get_list(self):\n        if not self._resources:\n            return self.resource_update_list()\n        res = []\n        with self._resource_lock:\n            for key in self._resources:\n                res.append((key, self._resources[key]['hash']))\n        return res", "response": "Get list of this plugins resources and a hash to check for file changes"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef resource_update_list(self, reset=False):\n        if not self._resource_path:\n            raise PluginException(\"No resource path set\")\n        if not os.path.isdir(self._resource_path):\n            raise PluginException(\n                u\"Resource path directory '{}' not found\".format(\n                    self._resource_path\n                )\n            )\n        res = []\n        with self._resource_lock:\n            if reset:\n                self._resources = {}\n            old = dict(self._resources)\n            for dirname, dirnames, filenames in os.walk(self._resource_path):\n                for file_name in filenames:\n                    file_ext = os.path.splitext(file_name)[1].lower()[1:]\n                    if file_ext not in self._resource_file_types:\n                        self.debug(u\"Skipping '{}'\".format(file_name))\n                        continue\n                    file_path = os.path.join(dirname, file_name)\n                    try:\n                        file_hash = get_file_hash(file_path)\n                    except:\n                        self.exception(\n                            u\"Failed to hash '{}'\".format(file_path)\n                        )\n                        continue\n                    self._resources[file_name] = {\n                        'name': file_name,\n                        'path': file_path,\n                        'hash': file_hash,\n                        'checked': datetime.datetime.utcnow()\n                    }\n\n            # generate diff\n            for key in self._resources:\n                resource = self._resources[key]\n                if key not in old or old[key]['hash'] != resource['hash']:\n                    # new file or hash changed\n                    res.append((key, resource['hash']))\n        return res", "response": "Update internal struct of resource and hash list and get diff"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef resource_get(self, resource_name):\n        try:\n            with self._resource_lock:\n                res = self._resources[resource_name]\n        except KeyError:\n            return {}\n        return res", "response": "Get resource info by resource name"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef special_mode(v):\n    mode1 = {\n        0: 'Normal',\n        1: 'Unknown',\n        2: 'Fast',\n        3: 'Panorama',\n    }\n    mode2 = {\n        0: 'Non-panoramic',\n        1: 'Left to right',\n        2: 'Right to left',\n        3: 'Bottom to top',\n        4: 'Top to bottom',\n    }\n    if not v or (v[0] not in mode1 or v[2] not in mode2):\n        return v\n    return '%s - sequence %d - %s' % (mode1[v[0]], v[1], mode2[v[2]])", "response": "decode Olympus SpecialMode tag in MakerNote"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef main(arguments=None):\n\n    # SETUP VARIABLES\n    # MAKE SURE HEALPIX SMALL ENOUGH TO MATCH FOOTPRINTS CORRECTLY\n    nside = 1024\n    pi = (4 * math.atan(1.0))\n    DEG_TO_RAD_FACTOR = pi / 180.0\n    RAD_TO_DEG_FACTOR = 180.0 / pi\n    tileSide = 5.46\n\n    i = 0\n    outputList = []\n    rsyncContent = []\n    obscodes = {\"02\": \"T05\", \"01\": \"T08\"}\n\n    # SETUP THE COMMAND-LINE UTIL SETTINGS\n    su = tools(\n        arguments=arguments,\n        docString=__doc__,\n        logLevel=\"WARNING\",\n        options_first=False,\n        projectName=False\n    )\n    arguments, settings, log, dbConn = su.setup()\n\n    # UNPACK REMAINING CL ARGUMENTS USING `EXEC` TO SETUP THE VARIABLE NAMES\n    # AUTOMATICALLY\n    for arg, val in arguments.iteritems():\n        if arg[0] == \"-\":\n            varname = arg.replace(\"-\", \"\") + \"Flag\"\n        else:\n            varname = arg.replace(\"<\", \"\").replace(\">\", \"\")\n        if isinstance(val, str) or isinstance(val, unicode):\n            exec(varname + \" = '%s'\" % (val,))\n        else:\n            exec(varname + \" = %s\" % (val,))\n        if arg == \"--dbConn\":\n            dbConn = val\n        log.debug('%s = %s' % (varname, val,))\n\n    dbSettings = {\n        'host': '127.0.0.1',\n        'user': 'dryx',\n        'tunnel': {\n            'remote ip': 'starbase.mp.qub.ac.uk',\n            'remote datbase host': 'dormammu',\n            'remote user': 'dry',\n            'port': 5003\n        },\n        'password': 'dryxPass',\n        'db': 'atlas_moving_objects'\n    }\n\n    # SETUP DATABASE CONNECTIONS\n    dbConn = database(\n        log=log,\n        dbSettings=dbSettings\n    ).connect()\n\n    # GRAB THE EXPOSURE LISTING\n    for expPrefix, obscode in obscodes.iteritems():\n        exposureList = []\n        mjds = []\n        sqlQuery = \"select * from atlas_exposures where expname like '%(expPrefix)s%%'\" % locals(\n        )\n        connected = 0\n        while connected == 0:\n            try:\n                rows = readquery(\n                    log=log,\n                    sqlQuery=sqlQuery,\n                    dbConn=dbConn,\n                    quiet=False\n                )\n                connected = 1\n            except:\n                # SETUP DATABASE CONNECTIONS\n                dbConn = database(\n                    log=log,\n                    dbSettings=dbSettings\n                ).connect()\n                print \"Can't connect to DB - try again\"\n                time.sleep(2)\n\n        t = len(rows)\n\n        print \"There are %(t)s '%(expPrefix)s' exposures to check - hang tight\" % locals()\n\n        for row in rows:\n            row[\"mjd\"] = row[\"mjd\"] + row[\"exp_time\"] / (2. * 60 * 60 * 24)\n            exposureList.append(row)\n            mjds.append(row[\"mjd\"])\n\n        results = []\n\n        batchSize = 500\n        total = len(mjds[1:])\n        batches = int(total / batchSize)\n\n        start = 0\n        end = 0\n        theseBatches = []\n        for i in range(batches + 1):\n            end = end + batchSize\n            start = i * batchSize\n            thisBatch = mjds[start:end]\n            theseBatches.append(thisBatch)\n\n        i = 0\n        totalLen = len(theseBatches)\n        index = 0\n        for batch in theseBatches:\n            i += 1\n\n            if index > 1:\n                # Cursor up one line and clear line\n                sys.stdout.write(\"\\x1b[1A\\x1b[2K\")\n            print \"Requesting batch %(i)04d/%(totalLen)s from JPL\" % locals()\n            index += 1\n\n            eph = jpl_horizons_ephemeris(\n                log=log,\n                objectId=[ssobject],\n                mjd=batch,\n                obscode=obscode,\n                verbose=False\n            )\n\n            for b in batch:\n                match = 0\n                # print b\n                for row in eph:\n                    if math.floor(row[\"mjd\"] * 10000 + 0.01) == math.floor(b * 10000 + 0.01):\n                        match = 1\n                        results.append(row)\n                if match == 0:\n                    for row in eph:\n                        if math.floor(row[\"mjd\"] * 10000) == math.floor(b * 10000):\n                            match = 1\n                            results.append(row)\n                if match == 0:\n                    results.append(None)\n                    this = math.floor(b * 10000 + 0.01)\n                    print \"MJD %(b)s (%(this)s) is missing\" % locals()\n                    for row in eph:\n                        print math.floor(row[\"mjd\"] * 10000 + 0.00001)\n                    print \"\"\n\n        print \"Finding the exopsures containing the SS object\"\n\n        for e, r in zip(exposureList, results):\n            # CALCULATE SEPARATION IN ARCSEC\n            if not r:\n                continue\n\n            calculator = separations(\n                log=log,\n                ra1=r[\"ra_deg\"],\n                dec1=r[\"dec_deg\"],\n                ra2=e[\"raDeg\"],\n                dec2=e[\"decDeg\"],\n            )\n            angularSeparation, north, east = calculator.get()\n            sep = float(angularSeparation) / 3600.\n            if sep < 5.:\n\n                # THE SKY-LOCATION AS A HEALPIXEL ID\n                pinpoint = hp.ang2pix(nside, theta=r[\"ra_deg\"], phi=r[\n                                      \"dec_deg\"], lonlat=True)\n\n                decCorners = (e[\"decDeg\"] - tileSide / 2,\n                              e[\"decDeg\"] + tileSide / 2)\n                corners = []\n                for d in decCorners:\n                    if d > 90.:\n                        d = 180. - d\n                    elif d < -90.:\n                        d = -180 - d\n                    raCorners = (e[\"raDeg\"] - (tileSide / 2) / np.cos(d * DEG_TO_RAD_FACTOR),\n                                 e[\"raDeg\"] + (tileSide / 2) / np.cos(d * DEG_TO_RAD_FACTOR))\n                    for rc in raCorners:\n                        if rc > 360.:\n                            rc = 720. - rc\n                        elif rc < 0.:\n                            rc = 360. + rc\n                        corners.append(hp.ang2vec(rc, d, lonlat=True))\n\n                # NEAR THE POLES RETURN SQUARE INTO TRIANGE - ALMOST DEGENERATE\n                pole = False\n                for d in decCorners:\n                    if d > 87.0 or d < -87.0:\n                        pole = True\n\n                if pole == True:\n                    corners = corners[1:]\n                else:\n                    # FLIP CORNERS 3 & 4 SO HEALPY UNDERSTANDS POLYGON SHAPE\n                    corners = [corners[0], corners[1],\n                               corners[3], corners[2]]\n\n                # RETURN HEALPIXELS IN EXPOSURE AREA\n                expPixels = hp.query_polygon(nside, np.array(\n                    corners))\n                if pinpoint in expPixels:\n                    outputList.append(\n                        {\"obs\": e[\"expname\"],\n                         \"mjd\": e[\"mjd\"],\n                         \"raDeg\": r[\"ra_deg\"],\n                         \"decDeg\": r[\"dec_deg\"],\n                         \"mag\": r[\"apparent_mag\"],\n                         \"sep\": sep\n                         })\n                    thisMjd = int(math.floor(e[\"mjd\"]))\n                    expname = e[\"expname\"]\n                    ssobject_ = ssobject.replace(\" \", \"_\")\n                    raStr = r[\"ra_deg\"]\n                    decStr = r[\"dec_deg\"]\n                    rsyncContent.append(\n                        \"rsync -av dyoung@atlas-base-adm01.ifa.hawaii.edu:/atlas/red/%(expPrefix)sa/%(thisMjd)s/%(expname)s.fits.fz %(ssobject_)s_atlas_exposures/\" % locals())\n                    rsyncContent.append(\n                        \"touch %(ssobject_)s_atlas_exposures/%(expname)s.location\" % locals())\n                    rsyncContent.append(\n                        'echo \"_RAJ2000,_DEJ2000,OBJECT\\n%(raStr)s,%(decStr)s,%(ssobject)s\" > %(ssobject_)s_atlas_exposures/%(expname)s.location' % locals())\n\n    dataSet = list_of_dictionaries(\n        log=log,\n        listOfDictionaries=outputList,\n        # use re.compile('^[0-9]{4}-[0-9]{2}-[0-9]{2}T') for mysql\n        reDatetime=False\n    )\n\n    ssobject = ssobject.replace(\" \", \"_\")\n    csvData = dataSet.csv(\n        filepath=\"./%(ssobject)s_atlas_exposure_matches.csv\" % locals())\n\n    rsyncContent = (\"\\n\").join(rsyncContent)\n    pathToWriteFile = \"./%(ssobject)s_atlas_exposure_rsync.sh\" % locals()\n    try:\n        log.debug(\"attempting to open the file %s\" % (pathToWriteFile,))\n        writeFile = codecs.open(pathToWriteFile, encoding='utf-8', mode='w')\n    except IOError, e:\n        message = 'could not open the file %s' % (pathToWriteFile,)\n        log.critical(message)\n        raise IOError(message)\n    writeFile.write(rsyncContent)\n    writeFile.close()\n\n    return", "response": "This is the main function used when find_atlas_exposure_containing_ssobject. py is run as a single script from the cl"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the first matching word available.", "response": "async def get_word(self, term: str) -> 'asyncurban.word.Word':\n        \"\"\"Gets the first matching word available.\n        \n        Args:\n            term: The word to be defined.\n        \n        Returns:\n            The closest matching :class:`Word` from UrbanDictionary.\n        \n        Raises:\n            UrbanConnectionError: If the response status isn't ``200``.\n            WordNotFoundError: If the response doesn't contain data (i.e. no word found).\n        \"\"\"\n        resp = await self._get(term=term)\n        return Word(resp['list'][0])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def search(self, term: str, limit: int = 3) -> 'List[Word]':\n        resp = await self._get(term=term)\n        words = resp['list']\n        return [Word(x) for x in words[:limit]]", "response": "Performs a search for a term and returns a list of possible matching words."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a random word.", "response": "async def get_random(self) -> Word:\n        \"\"\"Gets a random word.\n        \n        Returns:\n            A random :class:`Word`\\.\n        \n        Raises:\n            UrbanConnectionError: If the response status isn't ``200``.\n        \"\"\"\n        resp = await self._get(random=True)\n        return Word(resp['list'][0])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def search_raw(self, term: str, limit: int = 3) -> List[dict]:\n        return (await self._get(term=term))['list'][:limit]", "response": "Performs a search for a term and returns the raw response."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convert_content(self) -> dict:\n        source_content = self.load_content()\n\n        converted = {}\n\n        md_extenstions = [\n            'full_yaml_metadata',\n            'markdown.extensions.fenced_code',\n        ]\n        md = markdown.Markdown(md_extenstions)\n        content = md.convert(source_content)\n        meta = md.Meta\n\n        if meta:\n            converted.update(meta)\n\n        if content:\n            converted['content'] = content.strip()\n\n        return converted", "response": "Convert content of source file into dict result."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(self):\n        self.log.info('starting the ``get`` method')\n\n        cachePath = self.settings[\"atlas archive path\"]\n\n        global exposureIds\n        exposureIds, remaining = self._select_exposures_requiring_dophot_extraction(\n            batch=int(self.settings[\"dophot\"][\"batch size\"]))\n        if remaining == 0:\n            print \"%(remaining)s locally cached dophot files remain needing to be parsed for orbfit predicted known asteroid positions\" % locals()\n            return None\n\n        # SELECT 100 EXPOSURES REQUIRING DOPHOT EXTRACTION\n        while remaining > 0:\n            exposureIds, remaining = self._select_exposures_requiring_dophot_extraction(\n                batch=int(self.settings[\"dophot\"][\"batch size\"]))\n            print \"%(remaining)s locally cached dophot files remain needing to be parsed for orbfit predicted known asteroid positions\" % locals()\n            if remaining == 0:\n                continue\n            dophotMatches = fmultiprocess(log=self.log, function=_extract_phot_from_exposure,\n                                          inputArray=range(len(exposureIds)), poolSize=5, timeout=300, cachePath=cachePath, settings=self.settings)\n            self._add_dophot_matches_to_database(\n                dophotMatches=dophotMatches, exposureIds=exposureIds)\n            dophotMatches = None\n\n        self._add_value_to_dophot_table()\n\n        self.log.info('completed the ``get`` method')\n        return None", "response": "Get the next available dophot entry in the database."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _select_exposures_requiring_dophot_extraction(\n            self,\n            batch=10):\n        \"\"\"* select exposures requiring dophot extraction*\n\n        **Key Arguments:**\n            - ``batch`` -- the batch size of dophot file to process\n\n        **Return:**\n            - ``expnames`` -- the names of the expsoures in the batch\n            - ``remaining`` -- the number of exposured remainging that require orbfit/dophot crossmatching\n        \"\"\"\n        self.log.info(\n            'starting the ``_select_exposures_requiring_dophot_extraction`` method')\n\n        sqlQuery = u\"\"\"\n            select expname, floor(mjd) as mjd from atlas_exposures where local_data = 1 and dophot_match = 0 and orbfit_positions = 1;\n        \"\"\" % locals()\n        rows = readquery(\n            log=self.log,\n            sqlQuery=sqlQuery,\n            dbConn=self.atlasMoversDBConn,\n            quiet=False\n        )\n\n        remaining = len(rows)\n\n        expnames = []\n        expnames[:] = [(r[\"expname\"], int(r[\"mjd\"])) for r in rows[:batch]]\n\n        self.log.info(\n            'completed the ``_select_exposures_requiring_dophot_extraction`` method')\n        return expnames, remaining", "response": "This method returns a list of all the exposures that require dophot extraction."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds dophot matches to database", "response": "def _add_dophot_matches_to_database(\n            self,\n            dophotMatches,\n            exposureIds):\n        \"\"\"*add dophot matches to database*\n\n        **Key Arguments:**\n            - ``dophotMatches`` -- a list of lists of dophot matches\n            - ``exposureIds`` -- the ATLAS exposure IDs these matches were found in\n\n        **Return:**\n            - None\n        \"\"\"\n        self.log.info(\n            'starting the ``_add_dophot_matches_to_database`` method')\n\n        insertList = []\n        for d in dophotMatches:\n            insertList += d\n\n        dbSettings = self.settings[\"database settings\"][\"atlasMovers\"]\n\n        insert_list_of_dictionaries_into_database_tables(\n            dbConn=self.atlasMoversDBConn,\n            log=self.log,\n            dictList=insertList,\n            dbTableName=\"dophot_photometry\",\n            uniqueKeyList=[\"expname\", \"idx\"],\n            dateModified=True,\n            batchSize=10000,\n            replace=True,\n            dbSettings=dbSettings\n        )\n\n        exps = []\n        exps[:] = [e[0] for e in exposureIds]\n\n        exps = ('\",\"').join(exps)\n\n        sqlQuery = \"\"\"\nupdate atlas_exposures set dophot_match = 1 where dophot_match = 0 and expname in (\"%(exps)s\");\nupdate atlas_exposures set dophot_match = 2 where dophot_match = 1 and expname not in (select distinct expname from dophot_photometry);\"\"\" % locals(\n        )\n        writequery(\n            log=self.log,\n            sqlQuery=sqlQuery,\n            dbConn=self.atlasMoversDBConn\n        )\n\n        self.log.info(\n            'completed the ``_add_dophot_matches_to_database`` method')\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds value to dophot table", "response": "def _add_value_to_dophot_table(\n            self):\n        \"\"\"*add value to dophot table*\n        \"\"\"\n        self.log.info('starting the ``_add_value_to_dophot_table`` method')\n\n        # ADD SEPARATION RANK TO DOPHOT TABLE\n        sqlQuery = \"\"\"\nUPDATE dophot_photometry a,\n    (SELECT\n        t.primaryId,\n            (SELECT\n                    COUNT(*) + 1\n                FROM\n                    dophot_photometry t2\n                WHERE\n                    t2.expname = t.expname\n                        AND t2.orbfit_postions_id = t.orbfit_postions_id\n                        AND t2.orbfit_separation_arcsec < t.orbfit_separation_arcsec) AS match_rank\n    FROM\n        dophot_photometry t where t.sep_rank is null) b\nSET\n    a.sep_rank = b.match_rank\nWHERE\n    a.primaryId = b.primaryId\n        AND a.sep_rank IS NULL;\n\"\"\" % locals()\n        writequery(\n            log=self.log,\n            sqlQuery=sqlQuery,\n            dbConn=self.atlasMoversDBConn\n        )\n\n        sqlQuery = \"\"\"UPDATE dophot_photometry d,\n    orbfit_positions o\nSET\n    d.object_name = o.object_name,\n    d.orbital_elements_id = o.orbital_elements_id\nWHERE\n    d.orbfit_postions_id = o.primaryId;\"\"\" % locals()\n        writequery(\n            log=self.log,\n            sqlQuery=sqlQuery,\n            dbConn=self.atlasMoversDBConn\n        )\n\n        self.log.info('completed the ``_add_value_to_dophot_table`` method')\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _safe_call(obj, methname, *args, **kwargs):\n\n    meth = getattr(obj, methname, None)\n    if meth is None or not callable(meth):\n        return\n\n    return meth(*args, **kwargs)", "response": "Safely calls the given method with the given methname on the given\n    object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef proc_request(self, req):\n\n        for idx in range(len(self)):\n            resp = _safe_call(self[idx], 'proc_request', req)\n\n            # Do we have a response?\n            if resp is not None:\n                # Short-circuit\n                raise exc.ShortCircuit(self.proc_response(resp, idx - 1))\n\n        # Return the request we were passed\n        return req", "response": "Process a request through all processors in the stack and return the request we were passed to the method."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef proc_response(self, resp, startidx=None):\n\n        # If we're empty, bail out early\n        if not self:\n            return resp\n\n        # Select appropriate starting index\n        if startidx is None:\n            startidx = len(self)\n\n        for idx in range(startidx, -1, -1):\n            _safe_call(self[idx], 'proc_response', resp)\n\n        # Return the response we were passed\n        return resp", "response": "Process a response through all the processors in the stack."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef proc_exception(self, exc_type, exc_value, traceback):\n\n        # If we're empty, bail out early\n        if not self:\n            return\n\n        for idx in range(len(self), -1, -1):\n            # First, process the response...\n            if hasattr(exc_value, 'response'):\n                _safe_call(self[idx], 'proc_response', exc_value.response)\n\n            resp = _safe_call(self[idx], 'proc_exception',\n                              exc_type, exc_value, traceback)\n\n            # If we have a response, finish processing and return it\n            if resp:\n                return self.proc_response(resp, idx - 1)", "response": "Processes an exception and returns a response object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef connect_by_uri(uri):\n    puri = urisup.uri_help_split(uri)\n    #params = __dict_from_query(puri[QUERY])\n    params = {}\n\n    if puri[AUTHORITY]:\n        user, passwd, host, port = puri[AUTHORITY]\n        if user:\n            params['user'] = user\n        if passwd:\n            params['password'] = passwd\n        if host:\n            params['host'] = host\n        if port:\n            params['port'] = port\n    if puri[PATH]:\n        params['database'] = puri[PATH]\n        if params['database'] and params['database'][0] == '/':\n            params['database'] = params['database'][1:]\n\n    #__apply_types(params, __typemap)\n\n    return psycopg2.connect(**params)", "response": "Connect to a postgresql database by URI."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding a build cache somewhere in a parent directory.", "response": "def find_config():\n    \"\"\"Find a build cache somewhere in a parent directory.\"\"\"\n    previous = \"\"\n    current = os.getcwd()\n    while previous != current:\n        check_path = os.path.join(current, \"build.cache\")\n        if os.path.isfile(check_path):\n            return check_path\n        else:\n            previous = current\n            current = os.path.dirname(current)\n    raise Exception(\"Can't find build cache\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_cache(force=False, cache_file=None):\n    if not cache_file:\n        cache_file = find_config()\n    cache_config = devpipeline_configure.parser.read_config(cache_file)\n    cache = devpipeline_configure.cache._CachedConfig(cache_config, cache_file)\n    if force or _is_outdated(cache_file, cache):\n        cache = devpipeline_configure.config.process_config(\n            cache_config.get(\"DEFAULT\", \"dp.build_config\"),\n            os.path.dirname(cache_file),\n            \"build.cache\",\n            profiles=cache_config.get(\"DEFAULT\", \"dp.profile_name\", fallback=None),\n            overrides=cache_config.get(\"DEFAULT\", \"dp.overrides\", fallback=None),\n        )\n        devpipeline_core.sanitizer.sanitize(\n            cache, lambda n, m: print(\"{} [{}]\".format(m, n))\n        )\n    return cache", "response": "Load a build cache updating it if necessary."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef app(environ, start_response):\n    r = HttpRequestHandler(environ, start_response, Router).dispatch()\n    return r", "response": "Function called by the WSGI server."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef batch_add_ips(ips):\n        ips_created = 0\n        if len(ips) > 0:\n            # for each ip, check if already existent, if not add\n            for ip in ips:\n                (s0, s1, s2, s3) = ip.split('.')\n                (ip_db, is_ip_created) = IP.objects.get_or_create(seg_0=s0, seg_1=s1, seg_2=s2, seg_3=s3, )\n                if is_ip_created:\n                    ips_created += 1\n        return ips_created", "response": "Adds the given list of IPs to the database if the IP is not already there."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nunifies the currently saved IPs.", "response": "def unify_ips():\n        \"\"\"\n        Unifies the currently saved IPs.\n        Unification is based on last IP segment.\n        So if there are is e.g. 192.168.128.121 and 192.168.128.122 tthey will be merged to 192.168.128.121.\n        This is a little aggressive but the spammers are aggressive, too.\n        :return: number of merged ips\n        :rtype: int\n        \"\"\"\n        processed_ips = 0\n        ips = {}\n\n        # query for the IPs, also includes the starred IPs\n        for ip in IP.objects.raw(\n            'select distinct a.id, a.seg_0, a.seg_1, a.seg_2 '\n            'from ip_assembler_ip a, ip_assembler_ip b '\n            'where a.seg_0 = b.seg_0 and a.seg_1 = b.seg_1 and a.seg_2 = b.seg_2 and a.seg_3 != b.seg_3 '\n            'order by a.seg_0, a.seg_1, a.seg_2',\n        ):\n            key = '%d.%d.%d' % (int(ip.seg_0), int(ip.seg_1), int(ip.seg_2))\n            if not key in ips:\n                ips[key] = []\n            ips[key].append(ip)\n\n        for key, ip_list in ips.items():\n            # check if a starred ip is in list\n            starred_ip = None\n            for ip in ip_list:\n                if ip.seg_3 == '*':\n                    starred_ip = ip\n\n            if starred_ip is None:\n                IP.objects.create(seg_0=ip_list[0].seg_0, seg_1=ip_list[0].seg_1, seg_2=ip_list[0].seg_2, seg_3='*', )\n\n            # delete the other ips\n            for ip in ip_list:\n                if ip != starred_ip:\n                    processed_ips += 1\n                    ip.delete()\n\n        return processed_ips"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_job(job_name, **kwargs):\n    def wraps(func):\n        kwargs['process'] = func\n        job = type(job_name, (Job,), kwargs)\n        globals()[job_name] = job\n        return job\n    return wraps", "response": "Decorator to create a Job from a function."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprints unicode or bytes universally.", "response": "def print_safe(str_or_bytes, encoding='utf-8', errors='ignore', output=sys.stdout, newline='\\n'):\n    \"\"\"\n    Print unicode or bytes universally.\n\n    :param str_or_bytes: string\n    :param encoding: encoding\n    :param output: output file handler\n    :param errors: error handling scheme. Refer to codecs.register_error.\n    \"\"\"\n    writer = output.buffer if hasattr(output, 'buffer') else output\n\n    # When the input type is bytes, verify it can be decoded with the specified encoding.\n    decoded = str_or_bytes if is_unicode(str_or_bytes) else to_unicode(str_or_bytes, encoding, errors)\n    encoded = to_bytes(decoded, encoding, errors)\n\n    writer.write(encoded + to_bytes(newline, encoding, errors))\n    output.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the verified status of the message_info.", "response": "def set_verified(self, msg_info):\n        \"\"\"\n            expects \"msg_info\" to have the field 'files_containers_id'\n\n            This call already executes \"update_last_checked_time\" so it doesn't need to be called separately\n        \"\"\"\n        assert hasattr(msg_info, 'files_containers_id')\n        with self._session_resource as session:\n            session.execute(\n                update(FilesDestinations)\n                    .where(FilesDestinations.file_containers_id == msg_info.files_containers_id)\n                    .values(verification_info=msg_info.msg_id)\n            )\n\n        self.update_last_checked_time(msg_info)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns 1 if the message is an uploaded container and 0 if it doesn t correspond to an uploaded container and 1 if it corresponds to an uploaded container and is OK", "response": "def is_uploaded_container(self, msg_info):\n        \"\"\"\n            returns 0 if it doesn't correspond to an uploaded container\n                   -1 if it corresponds to an uploaded container but it is corrupted\n                    1 if it corresponds to an uploaded container and is OK\n        \"\"\"\n        results = {\n            'BAD': -1,\n            'NOT_FCB': 0,\n            'OK': 1\n        }\n\n        for part in msg_info.msg_body.walk():\n            if part.is_multipart():\n                continue\n\n            \"\"\"\n            if part.get('Content-Disposition') is None:\n                print(\"no content dispo\")\n                continue\n            \"\"\"\n            if part.get_content_type() == 'text/plain':\n                if self._is_content_from_fcb(part.get_payload()):\n                    self._log.debug(\"Body detected as FCB: %s\", part.get_payload())\n                else:\n                    self._log.debug(\"Body doesn't match FCB: %s\", part.get_payload())\n                    continue\n\n            attachment_name = self._get_attachment_name(part)\n            if not attachment_name:\n                self._log.debug(\"Couldn't get attachment name. Will ignore the part.\")\n                continue\n\n            files_container = self._get_files_container_by_name(attachment_name)\n            if files_container:\n                sha1_in_db = files_container.sha1\n                msg_info.files_containers_id = files_container.id\n                tmp_file = FileInfo(os.path.join(tempfile.gettempdir(), \"downloaded.tmp\"))\n                fp = open(tmp_file.path, 'wb')\n                fp.write(part.get_payload(decode=1))\n                fp.flush()\n                fp.close()\n\n                if tmp_file.sha1 == sha1_in_db:\n                    self._log.info(\"File container '%s' verified!\", attachment_name)\n                    result = results['OK']\n                else:\n                    self._log.error(\"File container '%s' doesn't match the sha1 sum. Expected '%s' but got '%s'\",\n                                    attachment_name, sha1_in_db, tmp_file.sha1)\n                    result = results['BAD']\n                os.remove(tmp_file.path)\n                return result\n            else:\n                self._log.debug(\"Attached file '%s' not found in DB. Will ignore this mail.\", attachment_name)\n        return results['NOT_FCB']"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(self,\n            singleExposure=False):\n        \"\"\"\n        *get the orbfitPositions object*\n\n        **Key Arguments:**\n            - ``singleExposure`` -- only execute fot a single exposure (useful for debugging)\n\n        **Return:**\n            - None\n\n        **Usage:**\n\n            See class docstring\n        \"\"\"\n        self.log.info('starting the ``get`` method')\n\n        if singleExposure:\n            batchSize = 1\n        else:\n            batchSize = int(self.settings[\"orbfit\"][\"batch size\"])\n\n        exposureCount = 1\n        while exposureCount > 0:\n            expsoureObjects, astorbString, exposureCount = self._get_exposures_requiring_orbfit_positions(\n                batchSize=batchSize)\n            if exposureCount:\n                orbfitPositions = self._get_orbfit_positions(\n                    expsoureObjects, astorbString)\n                self._add_orbfit_eph_to_database(\n                    orbfitPositions, expsoureObjects)\n            if singleExposure:\n                exposureCount = 0\n\n        self.log.info('completed the ``get`` method')\n        return None", "response": "get the orbfit positions object"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets next batch of exposures requiring orbfit positions", "response": "def _get_exposures_requiring_orbfit_positions(\n            self,\n            batchSize=25):\n        \"\"\"*get next batch of exposures requiring orbfit positions*\n\n        **Key Arguments:**\n            - ``batchSize`` -- number of exposures to process per batch\n\n        **Return:**\n            - ``expsoureObjects`` -- a dictionary with exposure names as keys and a dictionary of exposure ra, dec and moving object names/mpc number as values\n            - ``astorbString`` -- as string of the object orbital elements to be used later for orbfit ephemerides\n        \"\"\"\n        self.log.info(\n            'starting the ``_get_exposures_requiring_orbfit_positions`` method')\n\n        if self.dev_flag == True:\n            dev_flag = \" and dev_flag = 1\"\n        else:\n            dev_flag = \"\"\n\n        sqlQuery = u\"\"\"\n            select count(*) as count from atlas_exposures where pyephem_positions = 1 and orbfit_positions = 0 and local_data = 1  %(dev_flag)s order by pyephem_mjd asc\n        \"\"\" % locals()\n        rows = readquery(\n            log=self.log,\n            sqlQuery=sqlQuery,\n            dbConn=self.atlasMoversDBConn,\n            quiet=False\n        )\n\n        exposureCount = rows[0][\"count\"]\n\n        if batchSize > 1:\n            text = \"%(batchSize)s exposures\" % locals()\n        else:\n            text = \"%(batchSize)s exposure\" % locals()\n\n        if exposureCount:\n            print \"There are currently %(exposureCount)s ATLAS exposures with pyephem positions needing tightened - processing the next %(text)s with orbfit\" % locals()\n        else:\n            print \"There are no more ATLAS exposures requiring to be processed with orbfit\"\n            return {}, '', exposureCount\n\n        sqlQuery = u\"\"\"\n            SELECT\n                a.expname, a.mjd, o.primaryId, a.raDeg, a.decDeg, p.object_name, p.mpc_number, o.astorb_string, a.mjd+a.exp_time/(2*3600*24) as `mjd_mid`\n            FROM\n                atlas_exposures a,\n                pyephem_positions p,\n                orbital_elements o\n            WHERE\n                a.expname=p.expname\n                 %(dev_flag)s\n                and\n                p.object_name=o.name\n                and\n                a.expname IN (SELECT\n                        *\n                    FROM\n                        (SELECT\n                            expname\n                        FROM\n                            atlas_exposures\n                        WHERE\n                            pyephem_positions = 1\n                                AND orbfit_positions = 0 and local_data = 1 order by mjd\n                        LIMIT %(batchSize)s) AS a);\n                    \"\"\" % locals()\n        objects = readquery(\n            log=self.log,\n            sqlQuery=sqlQuery,\n            dbConn=self.atlasMoversDBConn,\n            quiet=False\n        )\n\n        expsoureObjects = {}\n        astorbDict = {}\n\n        for o in objects:\n            if o[\"expname\"] not in expsoureObjects:\n                expsoureObjects[o[\"expname\"]] = {\n                    \"ra\": o[\"raDeg\"],\n                    \"dec\": o[\"decDeg\"],\n                    \"mjd\": o[\"mjd_mid\"],\n                    \"objects\": [[o[\"mpc_number\"], o[\"object_name\"], o[\"primaryId\"]]]\n                }\n            else:\n                expsoureObjects[o[\"expname\"]][\"objects\"].append(\n                    [o[\"mpc_number\"], o[\"object_name\"], o[\"primaryId\"]])\n\n            if o[\"object_name\"] not in astorbDict:\n                astorbDict[o[\"object_name\"]] = o[\"astorb_string\"]\n\n        astorbString = (\"\\n\").join(astorbDict.values())\n\n        self.log.info(\n            'completed the ``_get_exposures_requiring_orbfit_positions`` method')\n        return expsoureObjects, astorbString, exposureCount"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_orbfit_positions(\n            self,\n            expsoureObjects,\n            astorbString):\n        \"\"\"* get orbfit positions*\n\n        **Key Arguments:**\n            - ``expsoureObjects`` -- a dictionary with exposure names as keys and a dictionary of exposure ra, dec and moving object names/mpc number as values\n            - ``astorbString`` -- as string of the object orbital elements to be used with orbfit\n\n        **Return:**\n            - ``orbfitMatches`` -- all of the ephemerides generated by Orbfit that match against the exact ATLAS exposure footprint\n        \"\"\"\n        self.log.info('starting the ``_get_orbfit_positions`` method')\n\n        # WRITE THE CUSTOM ORBFIT DATABASE TO FILE\n        now = datetime.now()\n        astorbFilepath = now.strftime(\"/tmp/astorb-%Y%m%dt%H%M%S%f.dat\")\n\n        try:\n            self.log.debug(\"attempting to open the file %s\" %\n                           (astorbFilepath,))\n            writeFile = codecs.open(astorbFilepath, encoding='utf-8', mode='w')\n        except IOError, e:\n            message = 'could not open the file %s' % (astorbFilepath,)\n            self.log.critical(message)\n            raise IOError(message)\n        writeFile.write(astorbString)\n        writeFile.close()\n\n        orbfitMatches = []\n        for expname, v in expsoureObjects.iteritems():\n            raDeg = v[\"ra\"]\n            decDeg = v[\"dec\"]\n            mjd = v[\"mjd\"]\n            objects = {}\n\n            for o in v[\"objects\"]:\n\n                if o[0]:\n                    objects[o[0]] = [o[0], o[1], o[2]]\n                else:\n                    objects[o[1].replace(\" \", \"\")] = [o[0], o[1], o[2]]\n\n            if expname[:2] == \"02\":\n                obscode = \"T05\"\n            elif expname[:2] == \"01\":\n                obscode = \"T08\"\n\n            orbfitEph = orbfit_ephemeris(\n                log=self.log,\n                obscode=obscode,\n                objectId=objects.keys(),\n                mjd=mjd,\n                settings=self.settings,\n                verbose=True,\n                astorbPath=astorbFilepath\n            )\n\n            for o in orbfitEph:\n                o[\"expname\"] = expname\n                o[\"mpc_number\"] = objects[o[\"object_name\"]][0]\n                o[\"orbital_elements_id\"] = objects[o[\"object_name\"]][\n                    2]\n                o[\"object_name\"] = objects[o[\"object_name\"]][\n                    1]\n\n            matchedEph = self._match_objects_against_atlas_footprint(\n                orbfitEph=orbfitEph, ra=raDeg, dec=decDeg)\n\n            orbfitMatches += matchedEph\n\n        try:\n            os.remove(astorbFilepath)\n        except:\n            pass\n\n        self.log.info('completed the ``_get_orbfit_positions`` method')\n        return orbfitMatches", "response": "This method returns the orbfit positions for the specified object in the Orbfit database."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding orbfit eph to database", "response": "def _add_orbfit_eph_to_database(\n            self,\n            orbfitMatches,\n            expsoureObjects):\n        \"\"\"* add orbfit eph to database*\n\n        **Key Arguments:**\n            - ``orbfitMatches`` -- all of the ephemerides generated by Orbfit that match against the exact ATLAS exposure footprint\n            - ``expsoureObjects`` -- the dictionary of original exposure objects\n\n        **Return:**\n            - None\n        \"\"\"\n        self.log.info('starting the ``_add_orbfit_eph_to_database`` method')\n\n        dbSettings = self.settings[\"database settings\"][\"atlasMovers\"]\n\n        insert_list_of_dictionaries_into_database_tables(\n            dbConn=self.atlasMoversDBConn,\n            log=self.log,\n            dictList=orbfitMatches,\n            dbTableName=\"orbfit_positions\",\n            uniqueKeyList=[\"expname\", \"object_name\"],\n            dateModified=True,\n            batchSize=10000,\n            replace=True,\n            dbSettings=dbSettings\n        )\n\n        exposures = expsoureObjects.keys()\n        exposures = '\",\"'.join(exposures)\n\n        sqlQuery = \"\"\"update atlas_exposures set  orbfit_positions = 1 where expname in (\"%(exposures)s\")\"\"\" % locals(\n        )\n        writequery(\n            log=self.log,\n            sqlQuery=sqlQuery,\n            dbConn=self.atlasMoversDBConn,\n        )\n\n        sqlQuery = \"\"\"update\n            atlas_exposures\n        set orbfit_positions = 2, dophot_match = 2\n        WHERE\n            orbfit_positions = 1\n                AND (dophot_match = 0) and local_data = 1 and expname not in (select distinct expname from orbfit_positions);\"\"\" % locals(\n        )\n        writequery(\n            log=self.log,\n            sqlQuery=sqlQuery,\n            dbConn=self.atlasMoversDBConn,\n        )\n\n        self.log.info('completed the ``_add_orbfit_eph_to_database`` method')\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef abort(self, count=2, timeout=60):\n        '''\n        Send an abort sequence using CAN bytes.\n        '''\n        for counter in xrange(0, count):\n            self.putc(CAN, timeout)", "response": "Send an abort sequence using CAN bytes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend a stream to the XMODEM protocol.", "response": "def send(self, stream, retry=16, timeout=60, quiet=0, callback=None):\n        '''\n        Send a stream via the XMODEM protocol.\n\n            >>> stream = file('/etc/issue', 'rb')\n            >>> print modem.send(stream)\n            True\n\n        Returns ``True`` upon succesful transmission or ``False`` in case of\n        failure.\n\n        :param stream: The stream object to send data from.\n        :type stream: stream (file, etc.)\n        :param retry: The maximum number of times to try to resend a failed\n                      packet before failing.\n        :type retry: int\n        :param timeout: The number of seconds to wait for a response before\n                        timing out.\n        :type timeout: int\n        :param quiet: If 0, it prints info to stderr.  If 1, it does not print any info.\n        :type quiet: int\n        :param callback: Reference to a callback function that has the\n                         following signature.  This is useful for\n                         getting status updates while a xmodem\n                         transfer is underway.\n                         Expected callback signature:\n                         def callback(total_packets, success_count, error_count)\n        :type callback: callable\n        '''\n\n        # initialize protocol\n        try:\n            packet_size = dict(\n                xmodem    = 128,\n                xmodem1k  = 1024,\n            )[self.mode]\n        except AttributeError:\n            raise ValueError(\"An invalid mode was supplied\")\n\n        error_count = 0\n        crc_mode = 0\n        cancel = 0\n        while True:\n            char = self.getc(1)\n            if char:\n                if char == NAK:\n                    crc_mode = 0\n                    break\n                elif char == CRC:\n                    crc_mode = 1\n                    break\n                elif char == CAN:\n                    if not quiet:\n                        print >> sys.stderr, 'received CAN'\n                    if cancel:\n                        return False\n                    else:\n                        cancel = 1\n                else:\n                    log.error('send ERROR expected NAK/CRC, got %s' % \\\n                        (ord(char),))\n\n            error_count += 1\n            if error_count >= retry:\n                self.abort(timeout=timeout)\n                return False\n\n        # send data\n        error_count = 0\n        success_count = 0\n        total_packets = 0\n        sequence = 1\n        while True:\n            data = stream.read(packet_size)\n            if not data:\n                log.info('sending EOT')\n                # end of stream\n                break\n            total_packets += 1\n            data = data.ljust(packet_size, self.pad)\n            if crc_mode:\n                crc = self.calc_crc(data)\n            else:\n                crc = self.calc_checksum(data)\n\n            # emit packet\n            while True:\n                if packet_size == 128:\n                    self.putc(SOH)\n                else:  # packet_size == 1024\n                    self.putc(STX)\n                self.putc(chr(sequence))\n                self.putc(chr(0xff - sequence))\n                self.putc(data)\n                if crc_mode:\n                    self.putc(chr(crc >> 8))\n                    self.putc(chr(crc & 0xff))\n                else:\n                    self.putc(chr(crc))\n\n                char = self.getc(1, timeout)\n                if char == ACK:\n                    success_count += 1\n                    if callable(callback):\n                        callback(total_packets, success_count, error_count)\n                    break\n                if char == NAK:\n                    error_count += 1\n                    if callable(callback):\n                        callback(total_packets, success_count, error_count)\n                    if error_count >= retry:\n                        # excessive amounts of retransmissions requested,\n                        # abort transfer\n                        self.abort(timeout=timeout)\n                        log.warning('excessive NAKs, transfer aborted')\n                        return False\n\n                    # return to loop and resend\n                    continue\n\n                # protocol error\n                self.abort(timeout=timeout)\n                log.error('protocol error')\n                return False\n\n            # keep track of sequence\n            sequence = (sequence + 1) % 0x100\n\n        while True:\n            # end of transmission\n            self.putc(EOT)\n            \n            #An ACK should be returned\n            char = self.getc(1, timeout)\n            if char == ACK:\n                break\n            else:\n                error_count += 1\n                if error_count >= retry:\n                    self.abort(timeout=timeout)\n                    log.warning('EOT was not ACKd, transfer aborted')\n                    return False\n        \n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef recv(self, stream, crc_mode=1, retry=16, timeout=60, delay=1, quiet=0):\n        '''\n        Receive a stream via the XMODEM protocol.\n\n            >>> stream = file('/etc/issue', 'wb')\n            >>> print modem.recv(stream)\n            2342\n\n        Returns the number of bytes received on success or ``None`` in case of\n        failure.\n        '''\n\n        # initiate protocol\n        error_count = 0\n        char = 0\n        cancel = 0\n        while True:\n            # first try CRC mode, if this fails,\n            # fall back to checksum mode\n            if error_count >= retry:\n                self.abort(timeout=timeout)\n                return None\n            elif crc_mode and error_count < (retry / 2):\n                if not self.putc(CRC):\n                    time.sleep(delay)\n                    error_count += 1\n            else:\n                crc_mode = 0\n                if not self.putc(NAK):\n                    time.sleep(delay)\n                    error_count += 1\n\n            char = self.getc(1, timeout)\n            if not char:\n                error_count += 1\n                continue\n            elif char == SOH:\n                #crc_mode = 0\n                break\n            elif char == STX:\n                break\n            elif char == CAN:\n                if cancel:\n                    return None\n                else:\n                    cancel = 1\n            else:\n                error_count += 1\n\n        # read data\n        error_count = 0\n        income_size = 0\n        packet_size = 128\n        sequence = 1\n        cancel = 0\n        while True:\n            while True:\n                if char == SOH:\n                    packet_size = 128\n                    break\n                elif char == STX:\n                    packet_size = 1024\n                    break\n                elif char == EOT:\n                    # We received an EOT, so send an ACK and return the received\n                    # data length\n                    self.putc(ACK)\n                    return income_size\n                elif char == CAN:\n                    # cancel at two consecutive cancels\n                    if cancel:\n                        return None\n                    else:\n                        cancel = 1\n                else:\n                    if not quiet:\n                        print >> sys.stderr, \\\n                            'recv ERROR expected SOH/EOT, got', ord(char)\n                    error_count += 1\n                    if error_count >= retry:\n                        self.abort()\n                        return None\n            # read sequence\n            error_count = 0\n            cancel = 0\n            seq1 = ord(self.getc(1))\n            seq2 = 0xff - ord(self.getc(1))\n            if seq1 == sequence and seq2 == sequence:\n                # sequence is ok, read packet\n                # packet_size + checksum\n                data = self.getc(packet_size + 1 + crc_mode, timeout)\n                if crc_mode:\n                    csum = (ord(data[-2]) << 8) + ord(data[-1])\n                    data = data[:-2]\n                    log.debug('CRC (%04x <> %04x)' % \\\n                        (csum, self.calc_crc(data)))\n                    valid = csum == self.calc_crc(data)\n                else:\n                    csum = data[-1]\n                    data = data[:-1]\n                    log.debug('checksum (checksum(%02x <> %02x)' % \\\n                        (ord(csum), self.calc_checksum(data)))\n                    valid = ord(csum) == self.calc_checksum(data)\n\n                # valid data, append chunk\n                if valid:\n                    income_size += len(data)\n                    stream.write(data)\n                    self.putc(ACK)\n                    sequence = (sequence + 1) % 0x100\n                    char = self.getc(1, timeout)\n                    continue\n            else:\n                # consume data\n                self.getc(packet_size + 1 + crc_mode)\n                self.debug('expecting sequence %d, got %d/%d' % \\\n                    (sequence, seq1, seq2))\n\n            # something went wrong, request retransmission\n            self.putc(NAK)", "response": "Receive a stream via the XMODEM protocol."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef calc_crc(self, data, crc=0):\n        '''\n        Calculate the Cyclic Redundancy Check for a given block of data, can\n        also be used to update a CRC.\n\n            >>> crc = modem.calc_crc('hello')\n            >>> crc = modem.calc_crc('world', crc)\n            >>> hex(crc)\n            '0xd5e3'\n\n        '''\n        for char in data:\n            crc = (crc << 8) ^ self.crctable[((crc >> 8) ^ ord(char)) & 0xff]\n        return crc & 0xffff", "response": "Calculate the Cyclic Redundancy Check for a given block of data."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef combobox_set_model_from_list(cb, items):\n    cb.clear()\n    model = gtk.ListStore(str)\n    for i in items:\n        model.append([i])\n    cb.set_model(model)\n    if type(cb) == gtk.ComboBoxEntry:\n        cb.set_text_column(0)\n    elif type(cb) == gtk.ComboBox:\n        cell = gtk.CellRendererText()\n        cb.pack_start(cell, True)\n        cb.add_attribute(cell, 'text', 0)", "response": "Setup a ComboBox or ComboBoxEntry based on a list of strings."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates an adapter which uses only the last construct.", "response": "def LastOf(*subcons):\n    \"\"\"\n    Create an adapter which uses only the last construct.\n\n    If first argument is a string it will be the name.\n\n    \"\"\"\n    name = \"seq\"\n    if isinstance(subcons[0], six.string_types):\n        name = subcons[0]\n        subcons = subcons[1:]\n    return IndexingAdapter(Sequence(name, *subcons), -1)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _make_scm(current_target):\n    # pylint: disable=protected-access\n    tool_key = devpipeline_core.toolsupport.choose_tool_key(\n        current_target, devpipeline_scm._SCM_TOOL_KEYS\n    )\n\n    return devpipeline_core.toolsupport.tool_builder(\n        current_target.config, tool_key, devpipeline_scm.SCMS, current_target\n    )", "response": "Create an Scm for a component."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef checkout_task(current_target):\n    try:\n        scm = _make_scm(current_target)\n        src_dir = current_target.config.get(\"dp.src_dir\")\n        shared_dir = current_target.config.get(\"dp.src_dir_shared\")\n        scm.checkout(repo_dir=src_dir, shared_dir=shared_dir)\n        scm.update(repo_dir=src_dir)\n    except devpipeline_core.toolsupport.MissingToolKey as mtk:\n        current_target.executor.warning(mtk)", "response": "Update or local checkout."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef proc_response(self, resp):\n\n        # Try to interpret any JSON\n        try:\n            resp.obj = json.loads(resp.body)\n            self._debug(\"  Received entity: %r\", resp.obj)\n        except ValueError:\n            resp.obj = None\n            self._debug(\"  No received entity; body %r\", resp.body)\n\n        # Now, call superclass method for error handling\n        super(JSONRequest, self).proc_response(resp)", "response": "Process JSON data found in the response."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds the absolute path of the deployed egg package that may contain the specified module path.", "response": "def find_module_egg_path(module_path):\n    \"\"\"\n    Find the path of the deployed egg package that may contain the\n    specified module path.\n\n\n    @param module_path: the path of a Python module.\n\n\n    @return: the absolute path of the deployed egg package that contains\n        the specified module path, or ``None`` if no deployed egg\n        package contains this module path.\n    \"\"\"\n    if module_path.find('.egg') == -1:\n        return None\n\n    _module_absolute_path = os.path.abspath(module_path)\n\n    egg_paths = [os.path.relpath(_module_absolute_path, egg_path)\n        for egg_path in [egg_path for egg_path in sys.path\n            if REGEX_EGG_PACKAGE_PATH.match(egg_path) \\\n               and _module_absolute_path.startswith(egg_path)]]\n\n    return None if len(egg_paths) == 0 else egg_paths[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef log(ltype, method, page, user_agent):\n\n    try:\n        f = open(settings.DJANGOSPAM_LOG, \"a\")\n        f.write(\"%s: %s method %s page %s user agent %s\\n\" % \\\n                (datetime.datetime.now(), ltype, method, page, user_agent))\n        f.close()\n    except:\n        if settings.DJANGOSPAM_FAIL_ON_LOG:\n            exc_type, exc_value = sys.exc_info()[:2]\n            raise LogError(exc_type, exc_value)", "response": "Writes to the log a message in the following format ::\n        \n        \"<datetime>: method page <path > user_agent"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef functions(self):\n        out = {}\n        for key in self._func_names:\n            out[key[len(self._prefix):]] = getattr(self, key)\n        return out", "response": "Returns a dictionary containing the functions defined in this\n        object. The keys are function names and the values are Python functions."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef tmpl_alphanum(self, text):\n        text = self.tmpl_asciify(text)\n        text = re.sub(r'[^a-zA-Z0-9]+', ' ', text)\n        return re.sub(r'\\s+', ' ', text)", "response": "This function returns the text that contains all non - alphanumerics characters and all non - whitespace characters replaced with whitespaces."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tmpl_asciify(text):\n        ger_umlaute = {'ae': u'\u00e4',\n                       'oe': u'\u00f6',\n                       'ue': u'\u00fc',\n                       'Ae': u'\u00c4',\n                       'Oe': u'\u00d6',\n                       'Ue': u'\u00dc'}\n        for replace, search in ger_umlaute.items():\n            text = text.replace(search, replace)\n        return str(unidecode(text).replace('[?]', ''))", "response": "Translate non - ASCII characters to their ASCII equivalents."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete every single character in chars in text.", "response": "def tmpl_delchars(text, chars):\n        \"\"\"\n        * synopsis: ``%delchars{text,chars}``\n        * description: Delete every single character of \u201cchars\u201c in \u201ctext\u201d.\n        \"\"\"\n        for char in chars:\n            text = text.replace(char, '')\n        return text"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tmpl_deldupchars(text, chars=r'-_\\.'):\n        import re\n        return re.sub(r'([' + chars + r'])\\1*', r'\\1', text)", "response": "* synopsis: ``%deldupchars{text,chars}``\n        * description: Search for duplicate characters and replace with only \\\n            one occurrance of this characters."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the first item in the string text.", "response": "def tmpl_first(text, count=1, skip=0, sep=u'; ', join_str=u'; '):\n        \"\"\"\n        * synopsis: ``%first{text}`` or ``%first{text,count,skip}`` or \\\n            ``%first{text,count,skip,sep,join}``\n        * description: Returns the first item, separated by ; . You can use \\\n            %first{text,count,skip}, where count is the number of items \\\n            (default 1) and skip is number to skip (default 0). You can also \\\n            use %first{text,count,skip,sep,join} where sep is the separator, \\\n            like ; or / and join is the text to concatenate the items.\n\n        :param text: the string\n        :param count: The number of items included\n        :param skip: The number of items skipped\n        :param sep: the separator. Usually is '; ' (default) or '/ '\n        :param join_str: the string which will join the items, default '; '.\n        \"\"\"\n        skip = int(skip)\n        count = skip + int(count)\n        return join_str.join(text.split(sep)[skip:count])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the value of the condition argument if provided.", "response": "def tmpl_if(condition, trueval, falseval=u''):\n        \"\"\"If ``condition`` is nonempty and nonzero, emit ``trueval``;\n        otherwise, emit ``falseval`` (if provided).\n\n        * synopsis: ``%if{condition,truetext}`` or \\\n            ``%if{condition,truetext,falsetext}``\n        * description: If condition is nonempty (or nonzero, if it\u2019s a \\\n            number), then returns the second argument. Otherwise, returns the \\\n            third argument if specified (or nothing if falsetext is left off).\n\n        \"\"\"\n        try:\n            int_condition = _int_arg(condition)\n        except ValueError:\n            if condition.lower() == \"false\":\n                return falseval\n        else:\n            condition = int_condition\n\n        if condition:\n            return trueval\n        else:\n            return falseval"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the string that is used to generate the value of the field in the log.", "response": "def tmpl_ifdef(self, field, trueval=u'', falseval=u''):\n        \"\"\"If field exists return trueval or the field (default) otherwise,\n        emit return falseval (if provided).\n\n        * synopsis: ``%ifdef{field}``, ``%ifdef{field,text}`` or \\\n            ``%ifdef{field,text,falsetext}``\n        * description: If field exists, then return truetext or field \\\n            (default). Otherwise, returns falsetext. The field should be \\\n            entered without $.\n\n        :param field: The name of the field\n        :param trueval: The string if the condition is true\n        :param falseval: The string if the condition is false\n        :return: The string, based on condition\n        \"\"\"\n        if field in self.values:\n            return trueval\n        else:\n            return falseval"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tmpl_ifdefnotempty(self, field, trueval=u'', falseval=u''):\n        if field not in self.values or \\\n           (field in self.values and not self.values[field]) or \\\n           re.search(r'^\\s*$', self.values[field]):\n            return falseval\n        else:\n            return trueval", "response": "Returns the string that is used to determine if the field is not emtpy or the field is empty."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tmpl_replchars(text, replace, chars):\n        for char in chars:\n            text = text.replace(char, replace)\n        return text", "response": "Template function for replacing characters in text with replace."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nshorten the given text to max_size", "response": "def tmpl_shorten(text, max_size=32):\n        \"\"\"Shorten the given text to ``max_size``\n\n        * synopsis: ``%shorten{text}`` or ``%shorten{text,max_size}``\n        * example: ``%shorten{$title,32}``\n        * description: Shorten \u201ctext\u201d on word boundarys.\n        \"\"\"\n        max_size = int(max_size)\n        if len(text) <= max_size:\n            return text\n        text = textwrap.wrap(text, max_size)[0]\n        import re\n        text = re.sub(r'\\W+$', '', text)\n        return text.strip()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nformat a time value using strftime.", "response": "def tmpl_time(text, fmt, cur_fmt):\n        \"\"\"Format a time value using `strftime`.\n\n        * synopsis: ``%time{date_time,format,curformat}``\n        * description: Return the date and time in any format accepted by \\\n            strftime. For example, to get the year some music was added to \\\n            your library, use %time{$added,%Y}.\n        \"\"\"\n        return time.strftime(fmt, time.strptime(text, cur_fmt))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef on_new(self, button):\n        '''\n        Copy selected notebook template to notebook directory.\n\n        ## Notes ##\n\n         - An exception is raised if the parent of the selected file is the\n           notebook directory.\n         - If notebook with same name already exists in notebook directory,\n           offer is made to overwrite (the new copy of the file is renamed with\n           a count if overwrite is not selected).\n        '''\n        buttons = (gtk.STOCK_CANCEL, gtk.RESPONSE_CANCEL,\n                   gtk.STOCK_OPEN, gtk.RESPONSE_OK)\n        dialog = gtk.FileChooserDialog(\"Select notebook template\", self.parent,\n                                       gtk.FILE_CHOOSER_ACTION_OPEN, buttons)\n        add_filters(dialog, [{'name': 'Jupyter notebook (*.ipynb)',\n                              'pattern': '*.ipynb'}])\n        if self.template_dir is not None:\n            dialog.set_current_folder(self.template_dir)\n        response = dialog.run()\n        if response == gtk.RESPONSE_OK:\n            selected_path = path(dialog.get_filename())\n            output_path = self.notebook_dir.joinpath(selected_path.name)\n\n            overwrite = False\n            if output_path.isfile():\n                response = yesno('%s already exists. Overwrite?' %\n                                 output_path.name)\n                if response == gtk.RESPONSE_YES:\n                    overwrite = True\n                else:\n                    counter = 1\n                    renamed_path = output_path\n                    while renamed_path.isfile():\n                        new_name = '%s (%d)%s' % (output_path.namebase, counter,\n                                                  output_path.ext)\n                        renamed_path = output_path.parent.joinpath(new_name)\n                        counter += 1\n                    output_path = renamed_path\n            self.notebook_manager\\\n                .launch_from_template(selected_path, overwrite=overwrite,\n                                      output_name=output_path.name,\n                                      notebook_dir=self.notebook_dir)\n        dialog.destroy()", "response": "Copy selected notebook template to notebook directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndownloads all binaries for the current platform and return a list of paths to the binaries in the resources directory.", "response": "def download_binaries(package_dir=False):\n    \"\"\"Download all binaries for the current platform\n\n    Parameters\n    ----------\n    package_dir: bool\n        If set to `True`, the binaries will be downloaded to the\n        `resources` directory of the qpsphere package instead of\n        to the users application data directory. Note that this\n        might require administrative rights if qpsphere is installed\n        in a system directory.\n\n    Returns\n    -------\n    paths: list of pathlib.Path\n        List of paths to binaries. This will always return binaries in\n        the `resources` directory of the qpsphere package (if binaries\n        are present there), in disregard of the parameter `package_dir`.\n    \"\"\"\n    # bhfield\n    # make sure the binary is available on the system\n    paths = _bhfield.fetch.get_binaries()\n\n    if package_dir:\n        # Copy the binaries to the `resources` directory\n        # of qpsphere.\n        pdir = RESCR_PATH\n        outpaths = []\n        for pp in paths:\n            target = pdir / pp.name\n            if not target.exists():\n                shutil.copy(pp, target)\n            outpaths.append(target)\n    else:\n        outpaths = paths\n\n    return outpaths"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves all binaries from the current platform s resources directory.", "response": "def remove_binaries(package_dir=False):\n    \"\"\"Remove all binaries for the current platform\n\n    Parameters\n    ----------\n    package_dir: bool\n        If True, remove all binaries from the `resources`\n        directory of the qpsphere package. If False,\n        remove all binaries from the user's cache directory.\n    \"\"\"\n    paths = []\n\n    if package_dir:\n        pdir = RESCR_PATH\n    else:\n        pdir = CACHE_PATH\n\n    for pp in pdir.iterdir():\n        if pp.name != \"shipped_resources_go_here\":\n            paths.append(pp)\n\n    for pp in paths:\n        pp.unlink()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef elapsed(func):\n\n    @functools.wraps(func)\n    def wrapper(*args, **kw):\n        start = time.time()\n        print('Running `%s()` ...' % func.__name__)\n        res = func(*args, **kw)\n        end = time.time()\n        print('Function `%s()` running elapsed %.2f s' %\n              (func.__name__, end - start))\n        return res\n\n    return wrapper", "response": "A decorator for calculating time elapsed when execute function"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_logger(log_file, name='logger', cmd=True):\n    import logging\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.DEBUG)\n\n    # set format\n    formatter = logging.Formatter('%(asctime)s | %(name)s | %(levelname)s | %(message)s',\n                                  datefmt='%Y-%m-%d %H:%M:%S')\n\n    # file handler\n    fh = logging.FileHandler(log_file)\n    fh.setLevel(logging.DEBUG)\n    fh.setFormatter(formatter)\n    logger.addHandler(fh)\n\n    # cmd handler\n    if cmd:\n        ch = logging.StreamHandler()\n        ch.setLevel(logging.DEBUG)\n        ch.setFormatter(formatter)\n        logger.addHandler(ch)\n\n    return logger", "response": "create a logger for your program\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef euclidean_distant(vector1, vector2):\n    vector1 = np.mat(vector1)\n    vector2 = np.mat(vector2)\n    return np.sqrt((vector1 - vector2) * (vector1 - vector2).T).item()", "response": "euclidean distance between two vectors"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cosine_distant(vector1, vector2):\n    vector1 = np.mat(vector1)\n    vector2 = np.mat(vector2)\n    vector1_norm = np.linalg.norm(vector1)\n    vector2_norm = np.linalg.norm(vector2)\n    dot_norm = vector1_norm * vector2_norm\n    dot_vs = np.dot(vector1, vector2)\n    return np.divide(dot_vs, dot_norm).item()", "response": "returns cosine distance between two vectors"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pearson_similar(vector1, vector2):\n    if len(vector1) < 3:\n        return 1.0\n    return 0.5 + 0.5 * np.corrcoef(vector1, vector2, rowvar=0)[0][1]", "response": "Computes the Pearson similarity between two vectors."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexpect Compressor Block like objects", "response": "def do_heavy_work(self, block):\n        \"\"\"\n        Expects Compressor Block like objects\n        \"\"\"\n        cipher_key = self.gen_key(32)\n        in_file_path = block.latest_file_info.path\n        dst_file_path = block.processed_data_file_info.path + self.get_extension()\n        self.log.debug(\"Encrypting file '%s' with key '%s' to file '%s'\",\n                       in_file_path, cipher_key, dst_file_path)\n        self.encrypt_file(key=cipher_key,\n                          in_filename=in_file_path,\n                          out_filename=dst_file_path)\n        block.cipher_key = cipher_key\n        block.ciphered_file_info = FileInfo(dst_file_path)\n        block.latest_file_info = block.ciphered_file_info\n        return block"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef encrypt_file(cls, key, in_filename, out_filename=None, chunksize=64 * 1024):\n        if not out_filename:\n            out_filename = in_filename + '.enc'\n\n        iv = ''.join(chr(random.randint(0, 0xFF)) for _ in range(16))\n        encryptor = AES.new(key, AES.MODE_CBC, iv)\n        filesize = os.path.getsize(in_filename)\n\n        with open(in_filename, 'rb') as infile:\n            with open(out_filename, 'wb') as outfile:\n                outfile.write(struct.pack('<Q', filesize))\n                outfile.write(iv)\n\n                while True:\n                    chunk = infile.read(chunksize)\n                    if len(chunk) == 0:\n                        break\n                    elif len(chunk) % 16 != 0:\n                        chunk += ' ' * (16 - len(chunk) % 16)\n\n                    outfile.write(encryptor.encrypt(chunk))", "response": "Encrypts a file using the given key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef decrypt_file(cls, key, in_filename, out_filename=None, chunksize=24 * 1024):\n        if not out_filename:\n            out_filename = os.path.splitext(in_filename)[0]\n\n        with open(in_filename, 'rb') as infile:\n            origsize = struct.unpack('<Q', infile.read(struct.calcsize('Q')))[0]\n            iv = infile.read(16)\n            decryptor = AES.new(key, AES.MODE_CBC, iv)\n\n            with open(out_filename, 'wb') as outfile:\n                while True:\n                    chunk = infile.read(chunksize)\n                    if len(chunk) == 0:\n                        break\n                    outfile.write(decryptor.decrypt(chunk))\n\n                outfile.truncate(origsize)", "response": "Decrypts a file using the given key."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef init():\n    print(yellow(\"# Setting up environment...\\n\", True))\n    virtualenv.init()\n    virtualenv.update_requirements()\n    print(green(\"\\n# DONE.\", True))\n    print(green(\"Type \") + green(\"activate\", True) + green(\" to enable your virtual environment.\"))", "response": "Initialize the virtual environment"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef autocommit(f):\n    \"A decorator to commit to the storage if autocommit is set to True.\"\n    @wraps(f)\n    def wrapper(self, *args, **kwargs):\n        result = f(self, *args, **kwargs)\n        if self._meta.commit_ready():\n            self.commit()\n        return result\n    return wrapper", "response": "A decorator to commit to the storage if autocommit is set to True."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef intersect(d1, d2):\n    return dict((k, d1[k]) for k in d1 if k in d2 and d1[k] == d2[k])", "response": "Intersect dictionaries d1 and d2 by key and value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset value to the key store.", "response": "def set(self, key, value):\n        \"Set value to the key store.\"\n        # if key already in data, update indexes\n        if not isinstance(value, dict):\n            raise BadValueError(\n                'The value {} is incorrect.'\n                ' Values should be strings'.format(value))\n        _value = deepcopy(value)\n        if key in self.data:\n            self.delete_from_index(key)\n        self.data[key] = _value\n        self.update_index(key, _value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninserting value in the keystore. Return the UUID key.", "response": "def insert(self, value):\n        \"Insert value in the keystore. Return the UUID key.\"\n        key = str(uuid4())\n        self.set(key, value)\n        return key"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete(self, key):\n        \"Delete a `key` from the keystore.\"\n        if key in self.data:\n            self.delete_from_index(key)\n        del self.data[key]", "response": "Delete a key from the keystore."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update(self, key, value):\n        if not isinstance(value, dict):\n            raise BadValueError(\n                'The value {} is incorrect.'\n                ' Values should be strings'.format(value))\n        if key in self.data:\n            v = self.get(key)\n            v.update(value)\n        else:\n            v = value\n        self.set(key, v)", "response": "Update a key in the keystore."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting the key_to_delete for the record found with key.", "response": "def del_key(self, key, key_to_delete):\n        \"Delete the `key_to_delete` for the record found with `key`.\"\n        v = self.get(key)\n        if key_to_delete in v:\n            del v[key_to_delete]\n            self.set(key, v)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncommitting data to the storage.", "response": "def commit(self):\n        \"Commit data to the storage.\"\n        if self._meta.path:\n            with open(self._meta.path, 'wb') as fd:\n                raw = deepcopy(self.raw)\n                # LAZY INDEX PROCESSING\n                # Save indexes only if not lazy\n                lazy_indexes = self.lazy_indexes  # Keep this list safe\n                if not self._meta.lazy_indexes:\n                    # Remove indexes if needed\n                    for idx_name in lazy_indexes:\n                        del raw['indexes'][idx_name]\n                    for index_name, values in raw['indexes'].items():\n                        for value, keys in values.items():\n                            raw['indexes'][index_name][value] = list(keys)\n                # don't store indexes if not needed\n                if not raw['indexes'] or self._meta.lazy_indexes:\n                    del raw['indexes']\n                try:\n                    fd.write(six.u(self.serialize(raw)))\n                except TypeError:\n                    fd.write(six.b(self.serialize(raw)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the items in the keystore with keys in keys.", "response": "def keys_to_values(self, keys):\n        \"Return the items in the keystore with keys in `keys`.\"\n        return dict((k, v) for k, v in self.data.items() if k in keys)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef filter_keys(self, **kwargs):\n        \"Return a set of keys filtered according to the given arguments.\"\n        self._used_index = False\n        keys = set(self.data.keys())\n        for key_filter, v_filter in kwargs.items():\n            if key_filter in self.indexes:\n                self._used_index = True\n                if v_filter not in self.indexes[key_filter]:\n                    keys = set([])\n                else:\n                    keys = keys.intersection(\n                        self.indexes[key_filter][v_filter])\n            else:\n                keys = keys.intersection(\n                    self.simple_filter(key_filter, v_filter))\n        return keys", "response": "Return a set of keys filtered according to the given arguments."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef simple_filter(self, key, value):\n        \"Search keys whose values match with the searched values\"\n        searched = {key: value}\n        return set([k for k, v in self.data.items() if\n                    intersect(searched, v) == searched])", "response": "Search keys whose values match with the searched values"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfilters the data according to the given arguments.", "response": "def filter(self, **kwargs):\n        \"\"\"\n        Filter data according to the given arguments.\n        \"\"\"\n        keys = self.filter_keys(**kwargs)\n        return self.keys_to_values(keys)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndelete references from the index of the key old value ( s ).", "response": "def delete_from_index(self, key):\n        \"Delete references from the index of the key old value(s).\"\n        old_value = self.data[key]\n        keys = set(old_value.keys()).intersection(self.indexes.keys())\n        for index_name in keys:\n            if old_value[index_name] in self.indexes[index_name]:\n                del self.indexes[index_name][old_value[index_name]]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_index(self, key, value):\n        \"Update the index with the new key/values.\"\n        for k, v in value.items():\n            if k in self.indexes:\n                # A non-string index value switches it into a lazy one.\n                if not isinstance(v, six.string_types):\n                    self.index_defs[k]['type'] = 'lazy'\n                if v not in self.indexes[k]:\n                    self.indexes[k][v] = set([])\n                self.indexes[k][v].add(key)", "response": "Update the index with the new key / values."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate an index. If recreate is True, recreate even if already there.", "response": "def create_index(self, name, recreate=False, _type='default'):\n        \"\"\"\n        Create an index.\n        If recreate is True, recreate even if already there.\n        \"\"\"\n        if name not in self.indexes or recreate:\n            self.build_index(name, _type)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build_index(self, idx_name, _type='default'):\n        \"Build the index related to the `name`.\"\n        indexes = {}\n        has_non_string_values = False\n        for key, item in self.data.items():\n            if idx_name in item:\n                value = item[idx_name]\n                # A non-string index value switches it into a lazy one.\n                if not isinstance(value, six.string_types):\n                    has_non_string_values = True\n                if value not in indexes:\n                    indexes[value] = set([])\n                indexes[value].add(key)\n        self.indexes[idx_name] = indexes\n        if self._meta.lazy_indexes or has_non_string_values:\n            # Every index is lazy\n            _type = 'lazy'\n        self.index_defs[idx_name] = {'type': _type}", "response": "Build the index related to the name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _clean_index(self):\n        \"Clean index values after loading.\"\n        for idx_name, idx_def in self.index_defs.items():\n            if idx_def['type'] == 'lazy':\n                self.build_index(idx_name)\n        for index_name, values in self.indexes.items():\n            for value in values:\n                if not isinstance(values[value], set):\n                    values[value] = set(values[value])", "response": "Clean index values after loading."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a TaskCommand with defined tasks.", "response": "def make_command(tasks, *args, **kwargs):\n    \"\"\"\n    Create a TaskCommand with defined tasks.\n\n    This is a helper function to avoid boiletplate when dealing with simple\n    cases (e.g., all cli arguments can be handled by TaskCommand), with no\n    special processing.  In general, this means a command only needs to run\n    established tasks.\n\n    Arguments:\n    tasks - the tasks to execute\n    args - extra arguments to pass to the TargetCommand constructor\n    kwargs - extra keyword arguments to pass to the TargetCommand constructor\n    \"\"\"\n    command = TaskCommand(tasks=tasks, *args, **kwargs)\n    return command"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexecute the provided command with the given args.", "response": "def execute_command(command, args):\n    \"\"\"\n    Runs the provided command with the given args.\n\n    Exceptions, if any, are propogated to the caller.\n\n    Arguments:\n    command - something that extends the Command class\n    args - A list of command line arguments.  If args is None, sys.argv\n           (without the first argument--assumed to be the command name) will\n           be used.\n    \"\"\"\n    if args is None:\n        args = sys.argv[1:]\n    try:\n        command.execute(args)\n\n    except IOError as failure:\n        if failure.errno == errno.EPIPE:\n            # This probably means we were piped into something that terminated\n            # (e.g., head).  Might be a better way to handle this, but for now\n            # silently swallowing the error isn't terrible.\n            pass\n\n    except _PartialFailureException as failed:\n        for failure, skipped, message in failed.failed:\n            print(\"\\nTask {} failed\".format(failure), file=sys.stderr)\n            print(\"\\tError: {}\".format(message), file=sys.stderr)\n            print(\"\\tSkipped: {}\".format(skipped), file=sys.stderr)\n        sys.exit(1)\n\n    except Exception as failure:  # pylint: disable=broad-except\n        print(\"Error: {}\".format(str(failure)), file=sys.stderr)\n        sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the version of the resource manager.", "response": "def set_version(self, version):\n        \"\"\"\n        Add the --version string with appropriate output.\n\n        Arguments:\n        version - the version of whatever provides the command\n        \"\"\"\n        self.parser.add_argument(\n            \"--version\",\n            action=\"version\",\n            version=\"%(prog)s {} (core {})\".format(\n                version, devpipeline_core.version.STRING\n            ),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninitialize and runs the tool.", "response": "def execute(self, *args, **kwargs):\n        \"\"\"\n        Initializes and runs the tool.\n\n        This is shorhand to parse command line arguments, then calling:\n            self.setup(parsed_arguments)\n            self.process()\n        \"\"\"\n        args = self.parser.parse_args(*args, **kwargs)\n        self.process(args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalls the tasks with the appropriate options for each of the targets.", "response": "def process_targets(self, targets, full_config, arguments):\n        \"\"\"\n        Calls the tasks with the appropriate options for each of the targets.\n        \"\"\"\n        executor = _get_executor(arguments)\n        resolver = _get_resolver(arguments)\n        dep_manager = resolver(targets, full_config, self._task_order)\n        task_queue = dep_manager.get_queue()\n        config_info = devpipeline_core.configinfo.ConfigInfo(executor)\n\n        try:\n            failed = []\n\n            def _keep_going_on_failure(failure, task):\n                skipped = task_queue.fail(task)\n                failed.append((task, skipped, str(failure)))\n\n            def _fail_immediately(failure, task):\n                del task\n                raise failure\n\n            fail_fn = _fail_immediately\n            if arguments.keep_going:\n                fail_fn = _keep_going_on_failure\n\n            self._execute_targets(task_queue, config_info, full_config, fail_fn)\n            if failed:\n                raise _PartialFailureException(failed)\n        finally:\n            full_config.write()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _user_input() -> str:\n\n    lines = []\n    try:\n        while True:\n            line = input()\n            if line != '':\n                lines.append(line)\n            else:\n                break\n    except (EOFError, KeyboardInterrupt):\n        return '\\n'.join(lines)", "response": "A helper function which waits for user multi - line input."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef infile_path(self) -> Optional[PurePath]:\n        if not self.__infile_path:\n            return Path(self.__infile_path).expanduser()\n        return None", "response": "Read - only property."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generator(self) -> Iterator[str]:\n        stream = self.stream  # In case that ``self.stream`` is changed.\n        stream.seek(0)\n        for line in stream:\n            yield line", "response": "Create a generate that iterates the whole content of the file or string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a generator that iterates the whole content of the file or string and tells which offset is now.", "response": "def generator_telling_position(self) -> Iterator[Tuple[str, int]]:\n        \"\"\"\n        Create a generate that iterates the whole content of the file or string, and also tells which offset is now.\n\n        :return: An iterator iterating tuples, containing lines of the text stream,...\n            separated by ``'\\\\n'`` or ``'\\\\r'``; and the offset (in bytes) of current line.\n        \"\"\"\n        stream = self.stream  # In case that ``self.stream`` is changed.\n        stream.seek(0)\n        for line in stream:\n            yield line, stream.tell()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generator_starts_from(self, offset, whence: Optional[int] = 0) -> Iterator[str]:\n\n        stream = self.stream  # In case that ``self.stream`` is changed.\n        stream.seek(offset, whence)\n        for line in stream:\n            yield line", "response": "Create a generator that iterates the entire content of the file or string starting from the given byte offset."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generator_between(self, begin: int, end: int) -> Iterator[str]:\n\n        s: str = self.content[begin:end + 1]\n        for line in s:\n            yield line", "response": "Create a generator that iterates the whole content of the file or string and yields the lines that are between begin and end."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef obj_for_name(obj_name):\n    parts = obj_name.split('.')\n    module = \".\".join(parts[:-1])\n    m = __import__( module )\n    for comp in parts[1:]:\n        m = getattr(m, comp)\n    return m", "response": "Instantiate class or function\n    from string name."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts the payload to the type of the cerberus item.", "response": "async def type_cast_payload(schema: dict, payload: dict):\n    \"\"\"\n    Make schema little forgiving! use case:  multipart data\n    \"\"\"\n    # In ideal case this should be done using serializer. A temp measure right now\n    cerberus_type_map = {\n        'string': str,\n        'integer': int,\n        'float': float,\n    }\n    for field, validator in schema.items():\n        field_type = validator['type']\n        if field_type in ['integer', 'string', 'float']:\n            payload_value = payload.get(field)\n            if not payload_value:\n                break\n            try:\n                payload[field] = cerberus_type_map[field_type](payload_value)\n            except ValueError:\n                break\n    return payload"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nextract the value of a key from the docstrings", "response": "def extract_value(self, string, key, inline_code=True):\n        \"\"\"Extract strings from the docstrings\n\n        .. code-block:: text\n\n            * synopsis: ``%shorten{text, max_size}``\n            * example: ``%shorten{$title, 32}``\n            * description: Shorten \u201ctext\u201d on word boundarys.\n\n        \"\"\"\n        regex = r'\\* ' + key + ': '\n        if inline_code:\n            regex = regex + '``(.*)``'\n        else:\n            regex = regex + '(.*)'\n        value = re.findall(regex, string)\n        if value:\n            return value[0].replace('``', '')\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nunderlines a given text", "response": "def underline(self, text, indent=4):\n        \"\"\"Underline a given text\"\"\"\n        length = len(text)\n        indentation = (' ' * indent)\n        return indentation + text + '\\n' + indentation + ('-' * length)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\napplies textwrap to a given text string", "response": "def format(self, text, width=78, indent=4):\n        \"\"\"Apply textwrap to a given text string\"\"\"\n        return textwrap.fill(\n            text,\n            width=width,\n            initial_indent=' ' * indent,\n            subsequent_indent=' ' * indent,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretrieve a formated text string", "response": "def get(self):\n        \"\"\"Retrieve a formated text string\"\"\"\n        output = ''\n        for f in self.functions:\n            output += self.underline(f) + '\\n\\n'\n            if f in self.synopsises and isinstance(self.synopsises[f], str):\n                output += self.format(self.synopsises[f]) + '\\n'\n            if f in self.descriptions and isinstance(\n                self.descriptions[f], str\n            ):\n                output += self.format(self.descriptions[f], indent=8) + '\\n'\n            if f in self.examples and isinstance(self.examples[f], str):\n                output += self.format(self.examples[f], indent=8) + '\\n'\n            output += '\\n'\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef propagate(w, b, X, Y):\n    m = X.shape[1]\n    A = sigmoid(np.dot(w.T, X) + b)\n    cost = -1 / m * np.sum(Y * np.log(A) + (1 - Y) * np.log(1 - A))\n\n    # BACKWARD PROPAGATION (TO FIND GRAD)\n    dw = 1.0 / m * np.dot(X, (A - Y).T)\n    db = 1.0 / m * np.sum(A - Y)\n\n    assert (dw.shape == w.shape)\n    assert (db.dtype == float)\n    cost = np.squeeze(cost)\n    assert (cost.shape == ())\n\n    grads = {\"dw\": dw,\n             \"db\": db}\n\n    return grads, cost", "response": "This function computes the cost function and its gradient for the propagation of a single object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npredicting whether the label is 0 or 1 using learned logistic regression parameters.", "response": "def LR_predict(w, b, X):\n    \"\"\"\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    \"\"\"\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1, m))\n    w = w.reshape(X.shape[0], 1)\n\n    A = sigmoid(np.dot(w.T, X) + b)\n\n    for i in range(A.shape[1]):\n        if A[0, i] > 0.5:\n            Y_prediction[0, i] = 1.0\n        else:\n            Y_prediction[0, i] = 0.0\n\n    assert (Y_prediction.shape == (1, m))\n\n    return Y_prediction"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef model(X_train, Y_train, X_test, Y_test, num_iterations=2000,\n          learning_rate=0.5, print_cost=True):\n    \"\"\"\n    Builds the logistic regression model by calling the function\n    implemented above\n\n    Arguments:\n    X_train     training set represented by a numpy array of shape (dim, m_train)\n    Y_train     training labels represented by a numpy array (vector) of shape (1, m_train)\n    X_test      test set represented by a numpy array of shape (dim, m_test)\n    Y_test      test labels represented by a numpy array (vector) of shape (1, m_test)\n    num_iterations  hyperparameter representing the number of iterations to optimize the parameters\n    learning_rate   hyperparameter representing the learning rate used in the update rule of optimize()\n    print_cost      Set to true to print the cost every 100 iterations\n\n    Returns:\n    d -- dictionary containing information about the model.\n    \"\"\"\n    print('X_train shape:', X_train.shape)\n\n    # initialize parameters with zeros\n    w, b = initialize_with_zeros(X_train.shape[0])\n\n    print('w shape:', w.shape)\n    # Gradient descent\n    parameters, grads, costs = LR_train(w, b, X_train, Y_train, num_iterations,\n                                        learning_rate, print_cost)\n\n    # Retrieve parameters w and b from dictionary \"parameters\"\n    w = parameters[\"w\"]\n    b = parameters[\"b\"]\n\n    print('w shape params:', w.shape)\n\n    Y_prediction_test = LR_predict(w, b, X_test)\n    Y_prediction_train = LR_predict(w, b, X_train)\n\n    # Print train/test Errors\n    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n\n    d = {\"costs\": costs,\n         \"Y_prediction_test\": Y_prediction_test,\n         \"Y_prediction_train\": Y_prediction_train,\n         \"w\": w,\n         \"b\": b,\n         \"learning_rate\": learning_rate,\n         \"num_iterations\": num_iterations}\n\n    return d", "response": "Builds the logistic regression model."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfunction to plot learning curve", "response": "def plot_lc(d):\n    \"\"\"plot learning curve\n\n    Arguments:\n    d       Returned by model function. Dictionary containing information about the model.\n    \"\"\"\n    costs = np.squeeze(d['costs'])\n    plt.plot(costs)\n    plt.ylabel('cost')\n    plt.xlabel('iterations (per hundreds)')\n    plt.title(\"Learning rate =\" + str(d[\"learning_rate\"]))\n    plt.show()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getLogLevelNo(level):\n    if isinstance(level,(int,long)):\n        return level\n    try:\n        return(int(logging.getLevelName(level.upper())))\n    except:\n        raise ValueError('illegal loglevel %s' % level)", "response": "Return numerical log level or raise ValueError."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns full command line with any necessary quoting.", "response": "def cmdLine(useBasename=False):\n    \"\"\"Return full command line with any necessary quoting.\"\"\"\n    qargv = []\n    cmdwords = list(sys.argv)\n    if useBasename:\n        cmdwords[0] = os.path.basename(cmdwords[0])\n    for s in cmdwords:\n        # any white space or special characters in word so we need quoting?\n        if re.search(r'\\s|\\*|\\?', s):\n            if \"'\" in s:\n                qargv.append('\"%s\"' % re.sub('\"', \"'\", s))\n            else:\n                qargv.append(\"'%s'\" % re.sub(\"'\", '\"', s))\n        else:\n            qargv.append(s)\n    cmd = ' '.join(qargv)\n    return cmd"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef handleError(exception, debugFlag=False, abortFlag=True):\n    if isinstance(exception, CmdError) or not debugFlag:\n        error(str(exception))\n    else:\n        import traceback\n        traceback.print_exc()\n        error(str(exception))   # or log complete traceback as well?\n    if abortFlag:\n        sys.exit(1)", "response": "Error handling utility. Print more or less error information about the current thread. Unless abort is set False exits with\n       error code 1."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef confirm(msg, acceptByDefault=False, exitCodeOnAbort=1, batch=False):\n    if batch:\n        return\n    if acceptByDefault:\n        msg += ' - are you sure [y] ? '\n    else:\n        msg += ' - are you sure [n] ? '\n    while True:\n        reply = raw_input(msg).lower()\n        print\n        if reply == '':\n            reply = 'y' if acceptByDefault else 'n'\n        if reply == 'y':\n            return True\n        elif reply == 'n':\n            if exitCodeOnAbort is None:\n                return False\n            else:\n                error('Program execution aborted by user')\n                sys.exit(exitCodeOnAbort)\n        else:\n            print \"ERROR: Invalid reply - please enter either 'y' or 'n', or press just enter to accept default\\n\"", "response": "Get user confirmation or abort execution."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run(cmd, printOutput=False,\n        exceptionOnError=False, warningOnError=True,\n        parseForRegEx=None, regExFlags=0,\n        printOutputIfParsed=False, printErrorsIfParsed=False, exceptionIfParsed=False,\n        dryrun=None):\n    \"\"\"Run cmd and return (status,output,parsedOutput).\n\n    Unless dryrun is set True, cmd is run using subprocess.Popen. It\n    returns the exit status from cmd, its output, and any output found\n    by searching for the regular expression parseForRegEx. cmd is\n    logged at the debug level.\n\n    The parameters are:\n\n    cmd                  The command to be executed in either a string\n                         or a sequence of program arguments. If cmd is a\n                         string (str or unicode), it will be executed through\n                         a shell (see subprocess for a discussion of associated\n                         security risks).\n\n    printOutput          Specifies if output is written to stdout.\n\n    exceptionOnError     Specifies if a non-zero exit status of cmd should\n                         raise an Exception.\n\n    warningOnError       Specifies whether to log a warning in case of a\n                         non-zero exit status of cmd.\n\n    parseForRegEx        If not None, search cmd output for regular expression.\n\n    regExFlags           Any regular expression flags used with parseForRegEx.\n\n    printOutputIfParsed  Specifies if any matches found by parseForRegEx\n                         should be printed to stdout.\n\n    printErrorsIfParsed  Specifies if any matches found by parseForRegEx\n                         should be logged as error.\n\n    exceptionIfParsed    Specifies if an Exception should be raised if\n                         parseForRegEx finds any matches.\n\n    dryrun               If set True, cmd is only logged to debug and\n                         nothing is run. Returns (0,'',None) in this case.\n    \"\"\"\n    if dryrun:\n        debug('would run cmd: %s' % cmd)\n        return (0, '', None)\n    debug('running cmd: %s' % cmd)\n    outputBuffer = []\n    interactive =  os.environ.get('PYTHONINSPECT',None)\n    if interactive:\n        del os.environ['PYTHONINSPECT']\n    p = subprocess.Popen(cmd,\n                         stdout=subprocess.PIPE,\n                         stderr=subprocess.STDOUT,\n                         shell=isinstance(cmd, (str,unicode)),\n                         universal_newlines=True)\n    if interactive:\n        os.environ['PYTHONINSPECT'] = interactive\n    for line in iter(p.stdout.readline, \"\"):\n        outputBuffer.append(line.strip('\\n'))\n        if printOutput:\n            sys.stdout.write(line)\n    status = p.wait()\n    output = '\\n'.join(outputBuffer)\n    if status and exceptionOnError:\n        raise Exception('Error %s running command: %s: %s' %\n                        (status, cmd, output))\n    if status and warningOnError:\n        warning('Error %s running command: %s: %s' % (status, cmd, output))\n    if parseForRegEx:\n        regex = re.compile(parseForRegEx, regExFlags)\n        parsedOutput = '\\n'.join([s for s in outputBuffer if regex.search(s)])\n    else:\n        parsedOutput = None\n    if printOutputIfParsed and parsedOutput and not printOutput:\n        print output\n    if printErrorsIfParsed and parsedOutput:\n        for l in parsedOutput.strip().split('\\n'):\n            error('found in command output: %s' % l)\n    if exceptionIfParsed and parsedOutput:\n        raise Exception('Errors found in command output - please check')\n    return (status, output, parsedOutput)", "response": "Runs a command and returns the exit status and output of the command."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write(self, text):\n        self.logger.log(self.loglevel, text, extra={'terminator': None})", "response": "Write text to the log file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef emit(self, record):\n        try:\n            msg = self.format(record)\n            if isinstance(msg,unicode):\n                if hasattr(self.stream, \"encoding\") and self.stream.encoding:\n                    # Stream should take care of encoding, but do it explicitly to\n                    # prevent bug in Python 2.6 - see\n                    # https://stackoverflow.com/questions/8016236/python-unicode-handling-differences-between-print-and-sys-stdout-write\n                    self.stream.write(msg.encode(self.stream.encoding))\n                else:\n                    self.stream.write(msg.encode(encoding))\n            else:\n                self.stream.write(msg)\n            terminator = getattr(record, 'terminator', '\\n')\n            if terminator is not None:\n                self.stream.write(terminator)\n            self.flush()\n        except (KeyboardInterrupt, SystemExit):\n            raise\n        except:\n            self.handleError(record)", "response": "Emit a record. Unless record. terminator is set a trailing trailing\n           newline will be written to the output stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nflushes the stream. In contrast to StreamHandler, errors are not caught so the program doesn't iterate through tons of logging errors e.g. in case of a broken pipe.", "response": "def flush(self):\n        \"\"\"Flush the stream.\n\n        In contrast to StreamHandler, errors are not caught so the program doesn't iterate\n        through tons of logging errors e.g. in case of a broken pipe.\"\"\"\n        # See /usr/lib64/python2.7/logging/__init__.py, StreamHander.flush()\n        self.acquire()\n        try:\n            if self.stream and hasattr(self.stream, \"flush\"):\n                self.stream.flush()\n        except IOError as e:\n            if self.abortOnIOError:\n                sys.exit('IOError: %s' % e)\n            else:\n                raise e\n        finally:\n            self.release()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef emit(self, record):\n        if self.triggerLevelNo is not None and record.levelno>=self.triggerLevelNo:\n            self.triggered = True\n        logging.handlers.BufferingHandler.emit(self,record)", "response": "Emit record after checking if message triggers later sending of e - mail."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends messages by e - mail.", "response": "def flush(self):\n        \"\"\"Send messages by e-mail.\n\n        The sending of messages is suppressed if a trigger severity\n        level has been set and none of the received messages was at\n        that level or above. In that case the messages are\n        discarded. Empty e-mails are discarded.\"\"\"\n        if self.triggered and len(self.buffer) > 0:\n            # Do not send empty e-mails\n            text = []\n            for record in self.buffer:\n                terminator = getattr(record, 'terminator', '\\n')\n                s = self.format(record)\n                if terminator is not None:\n                    text.append(s + terminator)\n                else:\n                    text.append(s)\n            msg = MIMEText(''.join(text))\n            msg['From'] = self.fromAddr\n            msg['To'] = self.toAddr\n            msg['Subject'] = self.subject\n            # print 'BufferingSMTPHandler'\n            # print msg.as_string()\n            smtp = smtplib.SMTP('localhost')\n            smtp.sendmail(self.fromAddr, [self.toAddr], msg.as_string())\n            smtp.quit()\n        self.buffer = []"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding optparse or argparse option depending on CmdHelper initialization.", "response": "def add_option(self, *args, **kwargs):\n        \"\"\"Add optparse or argparse option depending on CmdHelper initialization.\"\"\"\n        if self.parseTool == 'argparse':\n            if args and args[0] == '':   # no short option\n                args = args[1:]\n            return self.parser.add_argument(*args, **kwargs)\n        else:\n            return self.parser.add_option(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse(self):\n        if self.parseTool == 'argparse':\n            self.options = self.parser.parse_args()   # called options for backward compat.\n        else:\n            (self.options, self.args) = self.parser.parse_args()\n\n        # If -i is given, make sure we go into interactive mode at the end\n        try:\n            if self.options.interactive:\n                os.environ['PYTHONINSPECT'] = '1'\n        except AttributeError:\n            pass\n\n        # Configure logging to file\n        if getattr(self.options,'logfile',None):\n            self.fileHandler = MyStreamHandler(open(self.options.logfile, 'a'))\n            self.fileHandler.setFormatter(FileFormatter(self.options.logtimestampfmt))\n            self.logger.addHandler(self.fileHandler)\n            if self.options.loglevel is None:\n                if self.options.debug:\n                    self.options.loglevel = 'DEBUG'\n                else:\n                    self.options.loglevel = 'INFO'\n            try:\n                self.fileHandler.setLevel(getLogLevelNo(self.options.loglevel))\n            except:\n                self.fileHandler.setLevel(logging.INFO)\n                error('illegal loglevel: %s',self.options.loglevel)\n\n        # Log command being executed. This goes only to self.fileHandler, because\n        # at this point self.emailHandler and consoleHandler are intentionally not yet\n        # configured (consoleHandler is still set to level STDOUT).\n        info('')\n        if self.options.logseparator:\n            info(self.options.logseparator)\n        #info('%s %s' % (time.asctime(), cmdLine()))\n        info(cmdLine())\n        info('')\n\n        # Configure logging to e-mail\n        if getattr(self.options,'emailto',None):\n            hostname = socket.gethostname()\n            fromAddr = '%s@%s' % (getpass.getuser(),hostname)\n            if self.options.emailsubject:\n                subject = self.options.emailsubject\n            else:\n                subject = 'Report from %s (%s)' % (cmdLine(True),hostname)\n            if self.options.emailtriglevel is not None:\n                try:\n                    triggerLevelNo = getLogLevelNo(self.options.emailtriglevel)\n                except:\n                    triggerLevelNo = None\n                    error('illegal email trigger level %s' % self.options.emailtriglevel)\n            else:\n                triggerLevelNo = None\n            self.emailHandler = BufferingSMTPHandler(fromAddr,self.options.emailto,subject,\n                                                     triggerLevelNo=triggerLevelNo)\n            self.emailHandler.setFormatter(ConsoleFormatter())\n            self.emailHandler.setLevel(logging.WARNING)\n            self.logger.addHandler(self.emailHandler)\n            try:\n                self.emailHandler.setLevel(getLogLevelNo(self.options.emaillevel))\n            except:\n                self.emailHandler.setLevel(logging.WARNING)\n                error('illegal emaillevel %s', self.options.emaillevel)\n\n        # Configure console logging level\n        # NOTE: do this after logging command being executed, so that we don't get a logseparator\n        #       or the command on the screen\n        if self.options.verbose:\n            self.consoleHandler.setLevel(logging.INFO)\n        if self.options.debug:\n            self.consoleHandler.setLevel(logging.DEBUG)\n        if getattr(self.options, 'noscreen', False):\n            self.consoleHandler.setLevel(9999)   # disable logging to consoleHandler\n        if self.errorHandler:\n            self.errorHandler.setLevel(logging.STDOUT)\n            if self.options.verbose:\n                self.errorHandler.setLevel(logging.INFO)\n            if self.options.debug:\n                self.errorHandler.setLevel(logging.DEBUG)\n            if getattr(self.options, 'noscreen', False):\n                self.errorHandler.setLevel(9999)   # disable logging to errorHandler\n\n        if self.parseTool == 'argparse':\n            return self.options\n        else:\n            return (self.options, self.args)", "response": "Parse options and handle defaults."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_string(seq):\n    string = ''\n    for c in seq:\n        # Screen out non-printing characters\n        try:\n            if 32 <= c and c < 256:\n                string += chr(c)\n        except TypeError:\n            pass\n        # If no printing chars\n    if not string:\n        return str(seq)\n    return string", "response": "Make a string from a sequence of characters."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextracting multi - byte integer in Motorola format ( little endian.", "response": "def s2n_motorola(string):\n    \"\"\"Extract multi-byte integer in Motorola format (little endian).\"\"\"\n    x = 0\n    for c in string:\n        x = (x << 8) | ord_(c)\n    return x"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef s2n_intel(string):\n    x = 0\n    y = 0\n    for c in string:\n        x = x | (ord_(c) << y)\n        y += + 8\n    return x", "response": "Extract multi - byte integer in Intel format ( big endian."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread the content of the specified file.", "response": "def read_file(file_path_name):\n    \"\"\"\n    Read the content of the specified file.\n\n\n    @param file_path_name: path and name of the file to read.\n\n\n    @return: content of the specified file.\n    \"\"\"\n    with io.open(os.path.join(os.path.dirname(__file__), file_path_name), mode='rt', encoding='utf-8') as fd:\n        return fd.read()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nselecting a cast and perform the next scene.", "response": "def run(self, react=True, strict=True, roles=1):\n        \"\"\"Select a cast and perform the next scene.\n\n        :param bool react: If `True`, then Property directives are executed\n            at the point they are encountered. Pass `False` to skip them\n            so they can be enacted later on.\n        :param bool strict: Only fully-cast scripts to be performed.\n        :param int roles: Maximum number of roles permitted each character.\n\n        This method is a generator. It yields events from the performance.\n\n        If a :py:class:`~turberfield.dialogue.model.Model.Condition` is\n        encountered, it is evaluated. No events are generated while the most recent\n        condition is False.\n\n        A new :py:class:`~turberfield.dialogue.model.Model.Shot` resets the\n        current condition.\n\n        \"\"\"\n        try:\n            folder, index, self.script, self.selection, interlude = self.next(\n                self.folders, self.ensemble,\n                strict=strict, roles=roles\n            )\n        except TypeError:\n            raise GeneratorExit\n        with self.script as dialogue:\n            model = dialogue.cast(self.selection).run()\n            for shot, item in model:\n\n                if self.condition is not False:\n                    yield shot\n                    yield item\n\n                if not self.shots or self.shots[-1][:2] != shot[:2]:\n                    self.shots.append(shot._replace(items=self.script.fP))\n                    self.condition = None\n\n                if isinstance(item, Model.Condition):\n                    self.condition = self.allows(item)\n\n                if react:\n                    self.react(item)\n\n            for key, value in model.metadata:\n                if value not in self.metadata[key]:\n                    self.metadata[key].append(value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts images to PDF", "response": "def img2pdf(path, pdf_name=None):\n    \"\"\"\u5408\u5e76path\u76ee\u5f55\u4e0b\u7684\u6240\u6709\u56fe\u7247\u5230pdf\u6587\u4ef6\u4e2d\n\n    :param path: str\n        \u56fe\u7247\u8def\u5f84\n    :param pdf_name: str\n        \u9ed8\u8ba4\u503c \u56fe\u7247\u8def\u5f84.pdf; pdf\u6587\u4ef6\u540d\n    \"\"\"\n    print(\"merge images in %s ...\" % path)\n    if not pdf_name:\n        pdf_name = os.path.join(path, '%s.pdf' % os.path.split(path)[1])\n    file_list = os.listdir(path)\n\n    # filter pic in path\n    pic_names = []\n    img_suffix = ['.png', '.jpg', '.jpeg']\n    for x in file_list:\n        _, suffix = os.path.splitext(x)\n        if suffix.lower() in img_suffix:\n            pic_names.append(os.path.join(path, x))\n    pic_names.sort()\n\n    if len(pic_names) == 0:\n        print(\"There is no images in %s\" % path)\n        return\n\n    im_list = []\n    im1 = Image.open(pic_names[0])\n    pic_names.pop(0)\n    for i in pic_names:\n        img = Image.open(i)\n        if img.mode == \"RGBA\":\n            img = img.convert('RGB')\n            im_list.append(img)\n        else:\n            im_list.append(img)\n    im1.save(pdf_name, \"PDF\", resolution=100.0, save_all=True,\n             append_images=im_list)\n    print(\"images saved to\uff1a\", pdf_name)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_connection(self,\n        scheme='',\n        hostname=None,\n        port=None,\n        username=None,\n        password=None,\n        vpath_connector=None,\n        **extras\n        ):\n        \"\"\"\n        get_connection: get connection for 'scheme' or create a new one.\n\n        @type scheme: str\n        @param scheme: the scheme to use (i.e. 'file', 'ssh', etc.)\n\n        @type hostname: str|None\n        @param hostname: the hostname (extracted from parsed uri)\n\n        @type port: str|None\n        @param port: the port (extracted from parsed uri)\n\n        @type username: str|None\n        @param username: the username (extracted from parsed uri)\n\n        @type password: str|None\n        @param password: the password (extracted from parsed uri)\n\n        @type extras: dict\n        @param extras: parameters that are given to the backend factory\n\n        A key is calculated from given parameters. This key is used\n        to check for existing connection.\n        \"\"\"\n        if scheme not in self.schemes:\n            raise NoSchemeError(\n                'There is no handler registered for \"{}\" (available: {})'.format(scheme, list(self.schemes.keys()))\n                )\n        key = (\n            scheme,\n            hostname,\n            port,\n            username,\n            password,\n            vpath_connector,\n            frozenset(extras.items())\n            )\n\n        if not key in self.connections:\n            self.create(scheme, key, extras)\n        return self.connections[key]", "response": "get_connection - get a connection for scheme or create a new one if it does not exist."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef shutdown(self):\n        self.run_clean_thread = False\n        self.cleanup(True)\n        if self.cleaner_thread.isAlive():\n            self.cleaner_thread.join()", "response": "shutdown - shutdown the thread that will clean up all resources."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlikes os. path. split AttributeNames but returns a 2 tuple. The first element is a URI instance and the second is a string representing the basename.", "response": "def split(self):\n        \"\"\"\n        split: like os.path.split\n\n        @rtype: tuple(URI, str)\n        @return: a 2 tuple. The first element is a URI instance and the second\n                 a string, representing the basename.\n        \"\"\"\n        try:\n            first, second = self.uri.rsplit('/', 1)\n        except ValueError:\n            first = ''\n            second = self.uri\n        # we might be already on the root\n        if first.endswith('//'):\n            first = first + '/'\n        if not first:\n            first = '.'\n        return (self.__class__(\n            first,\n            sep=self.sep,\n            **self._extras()\n            ),\n            second.partition('?')[0]\n            )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlast is similar to basename but makes sure that the last part is", "response": "def last(self):\n        \"\"\"\n        last: similar to 'basename', but makes sure that the last part is\n              really returned.\n              example: URI('/some/dir/').basename() will return '' while\n                       URI('/some/dir/').last() will return 'dir'.\n\n        @return: last part of uri\n        @rvalue: str\n        \"\"\"\n        parts = self.uri.split('/')\n        if not parts:\n            return ''\n        if len(parts) > 1:\n            if not parts[-1]:\n                return parts[-2]\n            else:\n                return parts[-1]\n        else:\n            return parts[-1]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef join(self, *args):\n        sep = self.sep\n        if sep != '/':\n            args = [x.replace(sep, '/') for x in args]\n        args = (\n            [self.parse_result.path.rstrip('/')] +\n            [x.strip('/') for x in args[:-1]] +\n            [args[-1]]\n            )\n        parts = self.parse_result.as_list()\n        parts[2] = '/'.join(args)\n\n        result = self.__class__(\n            uri_from_parts(parts),\n            sep=sep,\n            **self._extras()\n            )\n\n        result.parse_result.query = self.query.copy()\n\n        return result", "response": "join paths parts together to represent a path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncopy self to other", "response": "def copy(self, other, recursive=False, ignore=None,\n             followlinks=True):\n        \"\"\"\n        copy: copy self to other\n\n        @type other: URI\n        @param other: the path to copy itself over.\n\n        What will really happen depends on the backend.\n\n        Note that file properties are only copied when self and other are\n        located in the same backend, i.e. it is not possible to copy\n        permissions etc. from a memory:// to a file:// based path.\n        \"\"\"\n        return self.connection.copy(self, other,\n                                    recursive=recursive,\n                                    ignore=ignore,\n                                    followlinks=followlinks)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef remove(self, recursive=False):\n        if self.connection.islink(self):\n            return self.connection.removefile(self)\n\n        if not self.connection.exists(self):\n            raise FileDoesNotExistError(str(self))\n\n        if self.connection.isdir(self):\n            if recursive:\n                return remove_dir_recursively(self.connection, self)\n            else:\n                return self.connection.removedir(self)\n        elif self.connection.isfile(self):\n            return self.connection.removefile(self)", "response": "remove - remove the entry from the database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef open(self, options=None, mimetype='application/octet-stream'):\n        return self.connection.open(self, options, mimetype)", "response": "open returns a file like object for the current object"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nindicate whether the path points to a file or folder containing a executable flag set.", "response": "def isexec(self, mode=stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH):\n        \"\"\"\n        isexec:\n\n        @rtype: bool\n        @return: Indicates whether the path points to a file or folder\n        which has the executable flag set.\n\n        Note that on systems which do not support executables flags the\n        result may be unpredicatable.  On Windows the value is determined\n        by the file extension, a *.exe file is executable, a *.sh not.\n        \"\"\"\n        return self.connection.isexec(self, mode)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwalk walk the filesystem (just like os.walk). Use like: path = URI('/some/dir') for root, dirs, files in path.walk(): do_something() root will be an URI object.", "response": "def walk(self, topdown=True, followlinks=True):\n        \"\"\"\n        walk: walk the filesystem (just like os.walk).\n        Use like:\n\n        path = URI('/some/dir')\n        for root, dirs, files in path.walk():\n            do_something()\n\n        root will be an URI object.\n        \"\"\"\n        return self.connection.walk(self, topdown=topdown, followlinks=followlinks)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef info(self, set_info=None, followlinks=True):\n        return self.connection.info(self, set_info=set_info, followlinks=followlinks)", "response": "Return info about the current object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef md5(self):\n        hash_ = hashlib.md5()\n        with self.open(\"rb\") as inf:\n            block = inf.read(4096)\n            while block:\n                hash_.update(block)\n                block = inf.read(4096)\n\n        return hash_.hexdigest()", "response": "Returns the md5 - sum of this file. This is of course expensive!"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef lock(self, fail_on_lock=False, cleanup=False):\n        return self.connection.lock(self, fail_on_lock, cleanup)", "response": "Lock a file via abl. util. LockFile."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef move(self, source, destination):\n        if source.isfile():\n            source.copy(destination)\n            source.remove()\n        else:\n            source.copy(destination, recursive=True)\n            source.remove('r')", "response": "move source to destination"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nhandles any default arguments that all commands should implement here.", "response": "def handle_default_args(args):\n    \"\"\"\n    Include handling of any default arguments that all commands should\n    implement here (for example, specifying the pythonpath).\n    \"\"\"\n\n    if hasattr(args, 'pythonpath'):\n        if args.pythonpath:\n            sys.path.insert(0, args.pythonpath)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parser(self):\n        if self._parser is None:\n            apkw = {\n                'description': self.description,\n                'epilog':      self.epilog,\n            }\n            self._parser = argparse.ArgumentParser(**apkw)\n\n            # For Python 3 add version as a default command\n            if self.version:\n                self._parser.add_argument(\n                    '-v', '--version', action='version',\n                    version=\"%(prog)s {}\".format(self.version),\n                )\n\n        return self._parser", "response": "Instantiates the argparse parser for the current object"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef subparsers(self):\n        if self._subparsers is None:\n            apkw = {\n                'title': 'commands',\n                'description': 'Commands for the %s program' % self.parser.prog,\n            }\n            self._subparsers = self.parser.add_subparsers(**apkw)\n        return self._subparsers", "response": "Returns the subparsers for all commands"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nregisters a command with the program", "response": "def register(self, command):\n        \"\"\"\n        Registers a command with the program\n        \"\"\"\n        command = command()\n        if command.name in self.commands:\n            raise ConsoleError(\n                \"Command %s already registered!\" % command.name\n            )\n\n        command.create_parser(self.subparsers)\n        self.commands[command.name] = command"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef exit(self, code=0, message=None):\n\n        ## If we have a parser, use it to exit\n        if self._parser:\n            if code > 0:\n                self.parser.error(message)\n            else:\n                self.parser.exit(code, message)\n\n        ## Else we are exiting before parser creation\n        else:\n            if message is not None:\n                if code > 0:\n                    sys.stderr.write(message)\n                else:\n                    sys.stdout.write(message)\n            sys.exit(code)\n\n        ## If we're here we didn't exit for some reason?\n        raise Exception(\"Unable to exit the %s\" % self.__class__.__name__)", "response": "Exit the console program sanely."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef execute(self):\n        # Ensure that we have commands registered\n        if not self.commands or self._parser is None:\n            raise NotImplementedError(\n                \"No commands registered with this program!\"\n            )\n\n        # Handle input from the command line\n        args = self.parser.parse_args()                # Parse the arguments\n\n        try:\n\n            handle_default_args(args)                  # Handle the default args\n\n            if not hasattr(args, 'func'):              # Handle no subcommands\n                self.parser.print_help()\n                self.exit(0)\n\n            msg = args.func(args)                      # Call the default function\n            msg = \"{}\\n\".format(msg) if msg else ''    # Format the message\n            self.exit(0, msg)                          # Exit cleanly with message\n\n        except Exception as e:\n            if hasattr(args, 'traceback') and args.traceback:\n                traceback.print_exc()\n\n            msg = color.format(str(e), color.RED)\n            self.exit(1, msg)", "response": "Execute the command line and exit cleanly with the message."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_server(\n        host=\"localhost\", port=5000, debug=False,\n        observer_name=\"twisted\", flask_app=None\n):\n    \"\"\"\n    Create and setup twisted server\n    (only need to do a reactor.run() after)\n\n    :param host: Host address to bind to (default: localhost)\n    :type host: str\n    :param port: Port to bind to (default: 5000)\n    :type port: int\n    :param debug: Should use debug mode (default: False)\n    :type debug: bool\n    :param observer_name: Name of twisted observer to log to stdlib\n        (default: twisted)\n        if None -> do not create observer\n    :type observer_name: None | str\n    :param flask_app: Flask object to be served (default: None)\n        if None -> use imported app\n    :type flask_app: flask.Flask\n    :rtype: None\n    \"\"\"\n    if observer_name is not None:\n        observer = STDLibLogObserver(name=observer_name)\n        globalLogBeginner.beginLoggingTo([observer])\n    if flask_app is None:\n        flask_app = create_app(debug=debug)\n\n    # Create a Twisted Web resource for our WebSocket server\n    ws_factory = WebSocketServerFactory(\n        u\"ws://{}:{}\".format(host, port)\n    )\n\n    ws_factory.protocol = PluginServerProtocol\n    # Needed if Hixie76 is to be supported\n    # ws_factory.setProtocolOptions(allowHixie76=True)\n    ws_resource = WebSocketResource(ws_factory)\n\n    # Create a Twisted Web WSGI resource for our Flask server\n    wsgi_resource = WSGIResource(reactor, reactor.getThreadPool(), flask_app)\n\n    # Create a root resource serving everything via WSGI/Flask, but\n    # The path \"/ws\" served by our webocket\n    root_resource = WSGIRootResource(wsgi_resource, {'ws': ws_resource})\n\n    # Create a Twisted Web Site and run everything\n    site = Site(root_resource)\n    # Needed if Hixie76 is to be supported\n    # site.protocol = HTTPChannelHixie76Aware\n\n    reactor.listenTCP(port, site)", "response": "Create and setup twisted server"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_lang_array(self):\n\n        r = self.yandex_translate_request(\"getLangs\", \"\")\n        self.handle_errors(r)\n\n        return r.json()[\"dirs\"]", "response": "gets supported langs as an array"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget supported langs as a dictionary", "response": "def get_lang_dict(self):\n        \"\"\"gets supported langs as an dictionary\"\"\"\n        r = self.yandex_translate_request(\"getLangs\")\n        self.handle_errors(r)\n\n        return r.json()[\"langs\"]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndetecting the language of a text.", "response": "def detect_language(self, text: str, hint: str = None):\n        \"\"\"\n        Detects the language of a text\n        :param text:\n            Text to analyze \n        :param hint: \n            A list which are hints for the API \n            in which language the text is written in  \n            example:\n            \"de, en\"\n        :return: \n            detected language code. example: \"en\"\n        \"\"\"\n        encodedtext = urllib.parse.quote(text)\n\n        args = \"&text=\" + encodedtext\n        if hint is not None:\n            args += \"&hint=\" + hint\n\n        r = self.yandex_translate_request(\"detect\", args)\n        self.handle_errors(r)\n        return r.json()[\"lang\"]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef translate(self, text: str, lang: str, form: FORMAT = FORMAT.PLAIN_TEXT):\n        encodedtext = urllib.parse.quote(text)\n        args = \"&text=\" + encodedtext + \"&lang=\" + lang + \"&format=\"\n        if form == FORMAT.PLAIN_TEXT:\n            args += \"plain\"\n        else:\n            args += \"html\"\n\n        r = self.yandex_translate_request(\"translate\", args)\n        self.handle_errors(r)\n\n        return r.json()[\"text\"]", "response": "Translate a text in Yandex and return a list of translated text."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _browser_init(self):\n        if self.session:\n            return\n\n        self.session = requests.Session()\n        headers = {}\n\n        if self.user_agent:\n            headers['User-agent'] = self.user_agent\n        self.session.headers.update(headers)\n\n        if self._auth_method in [None, \"\", \"HTTPBasicAuth\"]:\n            if self._auth_username is not None:\n                self.session.auth = (self._auth_username, self._auth_password)", "response": "Initialize the browser instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the settings for the object in the html2text class", "response": "def _set_html2text(self, settings):\n        \"\"\"\n        Load settings for html2text (https://github.com/Alir3z4/html2text)\n\n        Warning: does not check options/values\n\n        :param settings: Settings for the object\n            (see:https://github.com/Alir3z4/html2text/blob/master/docs/usage.md)\n        :type settings: dict\n        :rtype: None\n        \"\"\"\n        self._text_maker = html2text.HTML2Text()\n        for param in settings:\n            if not hasattr(self._text_maker, param):\n                raise WEBParameterException(\n                    \"Setting html2text failed - unknown parameter {}\".format(\n                        param\n                    )\n                )\n            setattr(self._text_maker, param, settings[param])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_scrap(self, path):\n        try:\n            conf = self.load_settings(path)\n        except:\n            # Should only be IOError\n            self.exception(\"Failed to load file\")\n            raise WEBFileException(\"Failed to load from {}\".format(path))\n\n        if \"scheme\" not in conf:\n            raise WEBParameterException(\"Missing scheme definition\")\n        if \"url\" not in conf:\n            raise WEBParameterException(\"Missing url definition\")\n        version = conf.get('version', None)\n        if version != \"1.0\":\n            raise WEBParameterException(\n                \"Unsupported version {}\".format(version)\n            )\n        self.scheme = conf['scheme']\n        self.url = conf['url']\n        self.timeout = conf.get('timeout', self.timeout)\n        if conf.get('html2text'):\n            self._set_html2text(conf['html2text'])", "response": "Loads scraper settings from file"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmaking a request to the specified url.", "response": "def request(\n            self, method, url, timeout=None,\n            headers=None, data=None, params=None\n    ):\n        \"\"\"\n        Make a request using the requests library\n\n        :param method: Which http method to use (GET/POST)\n        :type method: str | unicode\n        :param url: Url to make request to\n        :type url: str | unicode\n        :param timeout: Timeout for request (default: None)\n            None -> infinite timeout\n        :type timeout: None | int | float\n        :param headers: Headers to be passed along (default: None)\n        :type headers: None | dict\n        :param data: Data to be passed along (e.g. body in POST)\n            (default: None)\n        :type data: None | dict\n        :param params: Parameters to be passed along (e.g. with url in GET)\n            (default: None)\n        :type params: None | dict\n        :return: Response to the request\n        :rtype: requests.Response\n        :raises WEBConnectException: Loading failed\n        \"\"\"\n        if headers is None:\n            headers = {}\n        if not self.session:\n            self._browser_init()\n\n        try:\n            response = self.session.request(\n                method,\n                url,\n                timeout=timeout,\n                allow_redirects=self._handle_redirect,\n                headers=headers,\n                data=data,\n                params=params\n            )\n        except SSLError as e:\n            raise WEBConnectException(e)\n        except HTTPError:\n            raise WEBConnectException(\"Unable to load {}\".format(url))\n        except (Timeout, socket.timeout):\n            raise WEBConnectException(\"Timeout loading {}\".format(url))\n        except ConnectionError:\n            raise WEBConnectException(\"Failed to load {}\".format(url))\n        except Exception:\n            self.exception(\"Failed to load {}\".format(url))\n            raise WEBConnectException(\n                \"Unknown failure loading {}\".format(url)\n            )\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, url, timeout=None, headers=None, params=None, cache_ext=None):\n        if headers is None:\n            headers = {}\n        cached = cache_info = None\n        # TODO: add params to caching key\n        if self.cache:\n            cached, cache_info = self.cache.get(url)\n\n        if cache_ext:\n            # Check local cache\n            if not cache_info:\n                cache_info = cache_ext\n            if cache_info.access_time and cache_ext.access_time:\n                if cache_info.access_time < cache_ext.access_time:\n                    cached = None\n                    cache_info = cache_ext\n            if cache_info.etag != cache_ext.etag:\n                cached = None\n                cache_info = cache_ext\n        if cached:\n            # Using cached\n            return Response(cached, cache_info)\n        # Not using cached\n\n        if not self.session:\n            self._browser_init()\n\n        if self.cache:\n            headers = self.cache.prepare_headers(headers, cache_info)\n\n        response = self._get(\n            url,\n            timeout=timeout,\n            headers=headers,\n            params=params\n        )\n        if \"etag\" in response.headers:\n            if not cache_info:\n                cache_info = CacheInfo()\n            cache_info.etag = response.headers.get('etag')\n\n        res = Response(cache_info=cache_info)\n\n        if response.history:\n            # list of responses in redirects\n            code = 0\n\n            for resp in response.history + [None]:\n                if resp is None:\n                    resp = response\n                if code in [\n                    requests.codes.FOUND,\n                    requests.codes.SEE_OTHER,\n                    requests.codes.TEMPORARY_REDIRECT\n                ]:\n                    self.info(\"Temporary redirect to {}\".format(resp.url))\n                elif code in [\n                    requests.codes.MOVED_PERMANENTLY,\n                    requests.codes.PERMANENT_REDIRECT\n                ]:\n                    self.warning(\"Moved to {}\".format(resp.url))\n                elif code != 0:\n                    self.error(\"Code {} to {}\".format(code, resp.url))\n                code = resp.status_code\n\n        if response.status_code == requests.codes.NOT_MODIFIED:\n            self.info(\"Not modified {}\".format(url))\n            res.html, _ = self.cache.get(url, ignore_access_time=True)\n            if self.cache:\n                self.cache.update(url, cache_info)\n            return res\n\n        try:\n            response.raise_for_status()\n        except HTTPError as e:\n            raise WEBConnectException(\"{} - {}\".format(e, url))\n\n        try:\n            raw = response.content\n            html = response.text\n            if raw is None:\n                self.warning(\"Response returned None\")\n                raise Exception()\n            if html is None:\n                self.warning(\"Response parsed returned None\")\n                raise Exception()\n        except Exception:\n            raise WEBConnectException(\"Unable to load {}\".format(url))\n\n        # TODO: cache raw / whole response object\n        if self.cache:\n            self.cache.put(url, html, cache_info)\n        if url != response.url:\n            if not response.history:\n                self.warning(\n                    \"Response url different despite no redirects \"\n                    \"{} - {}\".format(url, response.url)\n                )\n            if self.cache:\n                self.cache.put(response.url, html, cache_info)\n        res.html = html\n        res.raw = raw\n        return res", "response": "Makes a GET request to url and returns a Response object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_tag_match(self, ele, tree):\n        if tree in [None, []]:\n            return [ele]\n\n        res = []\n        t = tree[0]\n        branch = tree[1:]\n        attributes = {}\n\n        for attr in t:\n            if isinstance(t[attr], dict):\n                if t[attr].get(\"type\", None) == \"reg\":\n                    t[attr] = re.compile(t[attr]['reg'])\n\n        attributes.update(t)\n\n        if \"name\" in attributes:\n            del attributes['name']\n        if \"text\" in attributes:\n            del attributes['text']\n        if \"recursive\" in attributes:\n            del attributes['recursive']\n        if \"[]\" in attributes:\n            del attributes['[]']\n\n        possibles = ele.find_all(\n            t.get('name', None),\n            text=t.get('text', None),\n            attrs=attributes,\n            recursive=t.get('recursive', True)\n        )\n\n        if not possibles:\n            return None\n        else:\n            pass\n\n        if \"[]\" in t:\n            try:\n                possibles = eval(\"possibles[{}]\".format(t[\"[]\"]))\n            except:\n                # no possibles\n                return None\n\n        if not isinstance(possibles, list):\n            possibles = [possibles]\n\n        for a in possibles:\n            match = self._get_tag_match(a, branch)\n\n            if match:\n                res.extend(match)\n\n        if not res:\n            return None\n        else:\n            return res", "response": "Returns the list of elements that match the given tag."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nscrapping a url and parse the content according to scheme.", "response": "def scrap(self,\n              url=None, scheme=None, timeout=None,\n              html_parser=None, cache_ext=None\n    ):\n        \"\"\"\n        Scrap a url and parse the content according to scheme\n\n        :param url: Url to parse (default: self._url)\n        :type url: str\n        :param scheme: Scheme to apply to html (default: self._scheme)\n        :type scheme: dict\n        :param timeout: Timeout for http operation (default: self._timout)\n        :type timeout: float\n        :param html_parser: What html parser to use (default: self._html_parser)\n        :type html_parser: str | unicode\n        :param cache_ext: External cache info\n        :type cache_ext: floscraper.models.CacheInfo\n        :return: Response data from url and parsed info\n        :rtype: floscraper.models.Response\n        :raises WEBConnectException: HTTP get failed\n        :raises WEBParameterException: Missing scheme or url\n        \"\"\"\n        if not url:\n            url = self.url\n        if not scheme:\n            scheme = self.scheme\n        if not timeout:\n            timeout = self.timeout\n        if not html_parser:\n            html_parser = self.html_parser\n        if not scheme:\n            raise WEBParameterException(\"Missing scheme definition\")\n        if not url:\n            raise WEBParameterException(\"Missing url definition\")\n        resp = self.get(url, timeout, cache_ext=cache_ext)\n        soup = BeautifulSoup(resp.html, html_parser)\n        resp.scraped = self._parse_scheme(soup, scheme)\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nshrinks the list of items in the list", "response": "def _shrink_list(self, shrink):\n        \"\"\"\n        Shrink list down to essentials\n\n        :param shrink: List to shrink\n        :type shrink: list\n        :return: Shrunk list\n        :rtype: list\n        \"\"\"\n        res = []\n\n        if len(shrink) == 1:\n            return self.shrink(shrink[0])\n        else:\n            for a in shrink:\n                temp = self.shrink(a)\n\n                if temp:\n                    res.append(temp)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _shrink_dict(self, shrink):\n        res = {}\n\n        if len(shrink.keys()) == 1 and \"value\" in shrink:\n            return self.shrink(shrink['value'])\n        else:\n            for a in shrink:\n                res[a] = self.shrink(shrink[a])\n\n                if not res[a]:\n                    del res[a]\n        return res", "response": "Shrinks the dict to essentials\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef shrink(self, shrink):\n        if isinstance(shrink, list):\n            return self._shrink_list(shrink)\n        if isinstance(shrink, dict):\n            return self._shrink_dict(shrink)\n        return shrink", "response": "Remove unnecessary parts\n\n        :param shrink: Object to shringk\n        :type shrink: dict | list\n        :return: Shrunk object\n        :rtype: dict | list"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mode_name(mode):\n    '''Tries best-effortly to get the right mode name'''\n\n    if mode:\n        l = mode.lower()\n\n        if l in ('java', ):\n            return ('clike', 'text/x-java')\n        if l in ('c', ):\n            return ('clike', 'text/x-csrc')\n        if l in ('c++', 'cxx'):\n            return ('clike', 'text/x-c++src')\n        if l in ('csharp', 'c#'):\n            return ('clike', 'text/x-csharp')\n\n        if l in ('sh', 'bash', ):\n            return ('shell', 'text/x-sh')\n\n        if l in codemirror_modes:\n            return (l, None)\n\n    return (None, None)", "response": "Tries best -effortly to get the right mode name"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef simulate(radius=5e-6, sphere_index=1.339, medium_index=1.333,\n             wavelength=550e-9, grid_size=(80, 80), model=\"projection\",\n             pixel_size=None, center=None):\n    \"\"\"Simulate scattering at a sphere\n\n    Parameters\n    ----------\n    radius: float\n        Radius of the sphere [m]\n    sphere_index: float\n        Refractive index of the object\n    medium_index: float\n        Refractive index of the surrounding medium\n    wavelength: float\n        Vacuum wavelength of the imaging light [m]\n    grid_size: tuple of ints or int\n        Resulting image size in x and y [px]\n    model: str\n        Sphere model to use (see :const:`available`)\n    pixel_size: float or None\n        Pixel size [m]; if set to `None` the pixel size is\n        chosen such that the radius fits at least three to\n        four times into the grid.\n    center: tuple of floats or None\n        Center position in image coordinates [px]; if set to\n        None, the center of the image (grid_size - 1)/2 is\n        used.\n\n    Returns\n    -------\n    qpi: qpimage.QPImage\n        Quantitative phase data set\n    \"\"\"\n    if isinstance(grid_size, numbers.Integral):\n        # default to square-shape grid\n        grid_size = (grid_size, grid_size)\n    if pixel_size is None:\n        # select simulation automatically\n        rl = radius / wavelength\n        if rl < 5:\n            # a lot of diffraction artifacts may occur;\n            # use 4x radius to capture the full field\n            fact = 4\n        elif rl >= 5 and rl <= 10:\n            # linearly decrease towards 3x radius\n            fact = 4 - (rl - 5) / 5\n        else:\n            # not many diffraction artifacts occur;\n            # 3x radius is enough and allows to\n            # simulate larger radii with BHFIELD\n            fact = 3\n        pixel_size = fact * radius / np.min(grid_size)\n\n    if center is None:\n        center = (np.array(grid_size) - 1) / 2\n\n    model = model_dict[model]\n    qpi = model(radius=radius,\n                sphere_index=sphere_index,\n                medium_index=medium_index,\n                wavelength=wavelength,\n                pixel_size=pixel_size,\n                grid_size=grid_size,\n                center=center)\n\n    return qpi", "response": "Simulate a single object at a given radius with a single object at a given medium and return a QPImage object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef range_n(self):\n        return self.sphere_index - self.dn, self.sphere_index + self.dn", "response": "Current interpolation range of refractive index"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef range_r(self):\n        return self.radius - self.dr, self.radius + self.dr", "response": "Current interpolation range of radius"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compute_qpi(self):\n        kwargs = self.model_kwargs.copy()\n        kwargs[\"radius\"] = self.radius\n        kwargs[\"sphere_index\"] = self.sphere_index\n        kwargs[\"center\"] = [self.posx_offset, self.posy_offset]\n        qpi = self.sphere_method(**kwargs)\n        # apply phase offset\n        bg_data = np.ones(qpi.shape) * -self.pha_offset\n        qpi.set_bg_data(bg_data=bg_data, which_data=\"phase\")\n        return qpi", "response": "Compute model data with current parameters Returns ------- qpi QPImage\n            Modeled phase data"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns one of nine border fields.", "response": "def get_border_phase(self, idn=0, idr=0):\n        \"\"\"Return one of nine border fields\n\n        Parameters\n        ----------\n        idn: int\n            Index for refractive index.\n            One of -1 (left), 0 (center), 1 (right)\n        idr: int\n            Index for radius.\n            One of -1 (left), 0 (center), 1 (right)\n        \"\"\"\n        assert idn in [-1, 0, 1]\n        assert idr in [-1, 0, 1]\n\n        n = self.sphere_index + self.dn * idn\n        r = self.radius + self.dr * idr\n\n        # convert to array indices\n        idn += 1\n        idr += 1\n        # find out whether we need to compute a new border field\n        if self._n_border[idn, idr] == n and self._r_border[idn, idr] == r:\n            if self.verbose > 3:\n                print(\"Using cached border phase (n{}, r{})\".format(idn, idr))\n            # return previously computed field\n            pha = self._border_pha[(idn, idr)]\n        else:\n            if self.verbose > 3:\n                print(\"Computing border phase (n{}, r{})\".format(idn, idr))\n            kwargs = self.model_kwargs.copy()\n            kwargs[\"radius\"] = r\n            kwargs[\"sphere_index\"] = n\n            kwargs[\"center\"] = [self.posx_offset, self.posy_offset]\n            tb = time.time()\n            pha = self.sphere_method(**kwargs).pha\n            if self.verbose > 2:\n                print(\"Border phase computation time:\",\n                      self.sphere_method.__module__, time.time() - tb)\n            self._border_pha[(idn, idr)] = pha\n            self._n_border[idn, idr] = n\n            self._r_border[idn, idr] = r\n\n        return pha"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the phase of the current species.", "response": "def get_phase(self, nintp=None, rintp=None,\n                  delta_offset_x=0, delta_offset_y=0):\n        \"\"\"Interpolate from the border fields to new coordinates\n\n        Parameters\n        ----------\n        nintp: float or None\n            Refractive index of the sphere\n        rintp: float or None\n            Radius of sphere [m]\n        delta_offset_x: float\n            Offset in x-direction [px]\n        delta_offset_y: float\n            Offset in y-direction [px]\n\n        Returns\n        -------\n        phase_intp: 2D real-valued np.ndarray\n            Interpolated phase at the given parameters\n\n        Notes\n        -----\n        Not all combinations are poosible, e.g.\n\n        - One of nintp or rintp must be None\n        - The current interpolation range must include the values\n          for rintp and nintp\n        \"\"\"\n        if nintp is None:\n            nintp = self.sphere_index\n\n        if rintp is None:\n            rintp = self.radius\n\n        assert (rintp == self.radius or nintp ==\n                self.sphere_index), \"Only r or n can be changed at a time.\"\n        assert rintp >= self.radius - self.dr\n        assert rintp <= self.radius + self.dr\n        assert nintp >= self.sphere_index - \\\n            self.dn, \"Out of range: {} !> {}\".format(\n                nintp, self.sphere_index - self.dn)\n        assert nintp <= self.sphere_index + self.dn\n\n        left = self.get_border_phase(0, 0)\n        if rintp == self.radius:\n            dist = nintp - self.sphere_index\n            dmax = self.dn\n            if dist < 0:\n                righ = self.get_border_phase(-1, 0)\n            else:\n                righ = self.get_border_phase(1, 0)\n        else:\n            dist = rintp - self.radius\n            dmax = self.dr\n            if dist < 0:\n                righ = self.get_border_phase(0, -1)\n            else:\n                righ = self.get_border_phase(0, 1)\n\n        # make dist positive so that we are interpolating from left to right\n        dist = np.abs(dist)\n        # perform linear interpolation of data.\n        phas = left + (righ - left) * dist / dmax\n\n        # interpolation of lateral movement\n        ti = time.time()\n        ipphas = spintp.RectBivariateSpline(np.arange(phas.shape[0]),\n                                            np.arange(phas.shape[1]),\n                                            phas)\n\n        if delta_offset_x != 0 or delta_offset_y != 0:\n            # Shift the image. The offset values used here\n            # are not self.posx_offset and self.posy_offset!\n            # The offset values are added to the fields computed\n            # with self.posx_offset and self.posy_offset.\n            newx = np.arange(phas.shape[0]) + delta_offset_x\n            newy = np.arange(phas.shape[1]) + delta_offset_y\n            phas = ipphas(newx, newy)\n        if self.verbose > 2:\n            print(\"Interpolation time for {}: {}\".format(\n                  self.model, time.time() - ti))\n\n        return phas + self.pha_offset"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind a user match with username and email", "response": "def user_query(username, email):\n    \"\"\"\n    Find a user match with username and email\n    :param username:\n    :param email:\n    :returns:\n    \"\"\"\n    query = db.query(User)\n    if username:\n        query = query.filter_by(username=username)\n\n    if email:\n        query = query.filter_by(username=username)\n\n    return query"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndisplay the empty text in the log.", "response": "def set_empty_text(self):\n        \"\"\"Display the empty text\n        \"\"\"\n        self.buffer.insert_with_tags_by_name(\n            self.buffer.get_start_iter(),\n            self.empty_text, 'empty-text')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process_data(self, file_info):\n        if self._has_reached_stop_limit():\n            self.log.info(\"Remaining bytes in quota (%d) has reached minimum to request stop (%d)\",\n                          self._quota.remaining, self._stop_on_remaining)\n            self.fire(events.TransmissionQuotaReached())\n        elif not self._fits_in_quota(file_info):\n            self.log.debug(\"File would exceed quota. Won't process '%s'\", str(file_info))\n        else:\n            return file_info\n        self.fire(events.FilteredFile(file_info))", "response": "Process the file_info and fire an event if the file is filtered or not."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef buildMessage(headers, parts):\n    message = multipart.MIMEMultipart('alternative')\n\n    for name, value in headers.iteritems():\n        name = name.title()\n        if name == \"From\":\n            multipart[name] = _encodeAddress(value)\n        elif name in [\"To\", \"Cc\", \"Bcc\"]:\n            multipart[name] = _encodeAddresses(value)\n        else:\n            multipart[name] = _encodeHeader(value)\n\n    for partType, part in parts.iteritems():\n        mimeText = text.MIMEText(part.encode(\"utf-8\"), partType, \"UTF-8\")\n        message.attach(mimeText.encode())\n\n    return message", "response": "Builds a message from some headers and MIME parts."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _encodeHeader(headerValue):\n    try:\n        return headerValue.encode('ascii', 'strict')\n    except UnicodeError:\n        encoded = headerValue.encode(\"utf-8\")\n        return header.Header(encoded, \"UTF-8\").encode()", "response": "Encodes a header value."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef messageToFile(message):\n    outFile = StringIO()\n    messageGenerator = generator.Generator(outFile, False)\n    messageGenerator.flatten(message)\n    outFile.seek(0, 0)\n    return outFile", "response": "Flattens a message into a file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndetermine refractive index and radius using Canny edge detection", "response": "def analyze(qpi, r0, edgekw={}, ret_center=False, ret_edge=False):\n    \"\"\"Determine refractive index and radius using Canny edge detection\n\n    Compute the refractive index of a spherical phase object by\n    detection of an edge in the phase image, a subsequent circle\n    fit to the edge, and finally a weighted average over the phase\n    image assuming a parabolic phase profile.\n\n    Parameters\n    ----------\n    qpi: QPImage\n        Quantitative phase image information\n    r0: float\n        Approximate radius of the sphere [m]\n    edgekw: dict\n        Additional keyword arguments for :func:`contour_canny`\n    ret_center: bool\n        Return the center coordinate of the sphere\n\n    Returns\n    -------\n    n: float\n        Computed refractive index\n    r: float\n        Computed radius [m]\n    center: tuple of floats\n        Center position of the sphere [px], only returned\n        if `ret_center` is `True`\n    \"\"\"\n    nmed = qpi[\"medium index\"]\n    px_m = qpi[\"pixel size\"]\n    wl_m = qpi[\"wavelength\"]\n    px_wl = px_m / wl_m\n\n    phase = qpi.pha\n    # determine edge\n    edge = contour_canny(image=phase,\n                         radius=r0 / px_m,\n                         verbose=False,\n                         **edgekw,\n                         )\n    # fit circle to edge\n    center, r = circle_fit(edge)\n    # compute average phase density\n    avg_phase = average_sphere(phase, center, r)\n    # convert phase average to refractive index\n    n = nmed + avg_phase / (2 * np.pi * px_wl)\n    # convert radius from pixels to meters\n    ret = [n, r * px_m]\n    if ret_center:\n        ret.append(center)\n    if ret_edge:\n        ret.append(edge)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute the average phase from a phase image center and radius.", "response": "def average_sphere(image, center, radius, weighted=True, ret_crop=False):\n    \"\"\"Compute the weighted average phase from a phase image of a sphere\n\n    Parameters\n    ----------\n    image: 2d ndarray\n        Quantitative phase image of a sphere\n    center: tuble (x,y)\n        Center of the sphere in `image` in ndarray coordinates\n    radius: float\n        Radius of the sphere in pixels\n    weighted: bool\n        If `True`, return average phase density weighted with the\n        height profile obtained from the radius, otherwise return\n        simple average phase density. Weighting gives data points\n        at the center of the sphere more weight than those points\n        at the boundary of the sphere, avoiding edge artifacts.\n    ret_crop: bool\n        Return the cropped image.\n\n    Returns\n    -------\n    average: float\n        The average phase value of the sphere from which the refractive\n        index can be computed\n    cropped_image: 2d ndarray\n        Returned if `ret_crop` is True\n    \"\"\"\n    sx, sy = image.shape\n    x = np.arange(sx).reshape(-1, 1)\n    y = np.arange(sy).reshape(1, -1)\n    discsq = ((x - center[0])**2 + (y - center[1])**2)\n    root = radius**2 - discsq\n    # height of the cell for each x and y\n    h = 2 * np.sqrt(root * (root > 0))\n    # compute phase density\n    rho = np.zeros(image.shape)\n    hbin = h != 0\n    # phase density [rad/px]\n    rho[hbin] = image[hbin] / h[hbin]\n    if weighted:\n        # compute weighted average\n        average = np.sum(rho * h) / np.sum(h)\n    else:\n        # compute simple average\n        average = np.sum(rho) / np.sum(hbin)\n\n    ret = average\n    if ret_crop:\n        ret = (ret, rho)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfit a circle to a 2d boolean edge image", "response": "def circle_fit(edge, ret_dev=False):\n    \"\"\"Fit a circle to a boolean edge image\n\n    Parameters\n    ----------\n    edge: 2d boolean ndarray\n        Edge image\n    ret_dev: bool\n        Return the average deviation of the distance from contour to\n        center of the fitted circle.\n\n    Returns\n    -------\n    center: tuple of (float, float)\n        Coordinates of the circle center\n    radius: float\n        Radius of the circle [px]\n    rdev:\n        Only returned if `ret_dev` is True\n        Average deviation of the radius from the circle\n    \"\"\"\n    sx, sy = edge.shape\n    x = np.linspace(0, sx, sx, endpoint=False).reshape(-1, 1)\n    y = np.linspace(0, sy, sy, endpoint=False).reshape(1, -1)\n    params = lmfit.Parameters()\n    # initial parameters\n    sum_edge = np.sum(edge)\n    params.add(\"cx\", np.sum(x * edge) / sum_edge)\n    params.add(\"cy\", np.sum(y * edge) / sum_edge)\n    # data\n    xedge, yedge = np.where(edge)\n    # minimize\n    out = lmfit.minimize(circle_residual, params, args=(xedge, yedge))\n    center = (out.params[\"cx\"].value, out.params[\"cy\"].value)\n    radii = circle_radii(out.params, xedge, yedge)\n    radius = np.mean(radii)\n\n    ret = [center, radius]\n    if ret_dev:\n        dev = np.average(np.abs(radii - radius))\n        ret.append(dev)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes the distance to the center from cartesian coordinates xedge yedge", "response": "def circle_radii(params, xedge, yedge):\n    \"\"\"Compute the distance to the center from cartesian coordinates\n\n    This method is used for fitting a circle to a set of contour\n    points.\n\n    Parameters\n    ----------\n    params: lmfit.Parameters\n        Must contain the keys:\n\n        - \"cx\": origin of x coordinate [px]\n        - \"cy\": origin of y coordinate [px]\n    xedge: 1D np.ndarray\n        Edge coordinates x [px]\n    yedge: 1D np.ndarray\n        Edge coordinates y [px]\n\n    Returns\n    -------\n    radii: 1D np.ndarray\n        Radii corresponding to edge coordinates relative to origin\n    \"\"\"\n    cx = params[\"cx\"].value\n    cy = params[\"cy\"].value\n    radii = np.sqrt((cx - xedge)**2 + (cy - yedge)**2)\n    return radii"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef circle_residual(params, xedge, yedge):\n    radii = circle_radii(params, xedge, yedge)\n    return radii - np.mean(radii)", "response": "Residuals for circle fitting\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef contour_canny(image, radius, mult_coarse=.40, mult_fine=.1,\n                  clip_rmin=.9, clip_rmax=1.1, maxiter=20,\n                  verbose=True):\n    \"\"\"Heuristic Canny edge detection for circular objects\n\n    Two Canny-based edge detections with different filter sizes are\n    performed to find the outmost contour of an object in a phase image\n    while keeping artifacts at a minimum.\n\n    Parameters\n    ----------\n    image: 2d ndarray\n        Image containing an approximately spherically symmetric object\n    radius: float\n        The approximate object radius in pixels (required for filtering)\n    mult_coarse: float\n        The coarse edge detection has a filter size of\n        ``sigma = mult_coarse * radius``\n    mult_fine: float\n        The fine edge detection has a filter size of\n        ``sigma = mult_fine * radius``\n    clip_rmin: float\n        Removes edge points that are closer than `clip_rmin` times the\n        average radial edge position from the center of the image.\n    clip_rmax: float\n        Removes edge points that are further than `clip_rmin` times the\n        average radial edge position from the center of the image.\n    maxiter: int\n        Maximum number iterations for coarse edge detection, see Notes\n    verbose: bool\n        If set to `True`, issues EdgeDetectionWarning where applicable\n\n    Returns\n    -------\n    edge : 2d boolean ndarray\n        The detected edge positions of the object.\n\n    Notes\n    -----\n    If no edge is found using the filter size defined by `mult_coarse`,\n    then the coarse filter size is reduced by a factor of 2 until an\n    edge is found or until `maxiter` is reached.\n\n    The edge found using the filter size defined by `mult_fine` is\n    heuristically filtered (parts at the center and at the edge of the\n    image are removed). This heuristic filtering assumes that the\n    circular object is centered in the image.\n\n    See Also\n    --------\n    skimage.feature.canny: Canny edge detection algorithm used\n    \"\"\"\n    image = (image - image.min()) / (image.max() - image.min())\n\n    if radius > image.shape[0] / 2:\n        msg = \"`radius` in pixels exceeds image size: {}\".format(radius)\n        raise RadiusExceedsImageSizeError(msg)\n    # 1. Perform a coarse Canny edge detection. If the edge found is empty,\n    # the coarse filter size is reduced by a factor of 2.\n    for ii in range(maxiter):\n        fact_coarse = .5**ii\n        sigma_coarse = radius * mult_coarse * fact_coarse\n        edge_coarse = feature.canny(image=image,\n                                    sigma=sigma_coarse)\n        if np.sum(edge_coarse) != 0:\n            break\n    else:\n        msg = \"Could not find edge! Try to reducing `mult_coarse` \" \\\n              + \"or increasing `maxiter`.\"\n        raise EdgeDetectionError(msg)\n\n    fact_fine = .7**ii\n\n    if fact_fine != 1 and verbose:\n        msg = \"The keyword argument `mult_coarse` is too large. \" \\\n              + \"If errors occur, adjust `mult_fine` as well.\\n\" \\\n              + \"Given `mult_coarse`: {}\\n\".format(mult_coarse) \\\n              + \"New `mult_coarse`: {}\\n\".format(mult_coarse * fact_coarse) \\\n              + \"Given `mult_fine`: {}\\n\".format(mult_fine) \\\n              + \"New `mult_fine`: {}\".format(mult_fine * fact_fine)\n        warnings.warn(msg, EdgeDetectionWarning)\n\n    # 2. Perform a fine Canny edge detection.\n    sigma_fine = radius * mult_fine * fact_fine\n    edge_fine = feature.canny(image, sigma_fine)\n\n    # 3. Remove parts from the fine edge\n    # Assume that the object is centered.\n    sx, sy = image.shape\n    x = np.linspace(-sx / 2, sx / 2, sx, endpoint=True).reshape(-1, 1)\n    y = np.linspace(-sy / 2, sy / 2, sy, endpoint=True).reshape(1, -1)\n    # 3.a. Remove detected edge parts from the corners of the image\n    # Radius of this disk is approximately\n    ellipse = (x / sx)**2 + (y / sy)**2 < .25\n    edge_fine *= ellipse\n    edge_coarse *= ellipse\n\n    if np.sum(edge_fine):\n        # 3.b Also filter inside of edge\n        rad = np.sqrt(x**2 + y**2)\n        # Filter coarse edge with `clip_rmin` and `clip_rmax`\n        rad_coarse = rad * edge_coarse\n        avg_coarse = np.sum(rad_coarse) / np.sum(edge_coarse)\n        rad_coarse[rad_coarse < avg_coarse * clip_rmin] = 0\n        rad_coarse[rad_coarse > avg_coarse * clip_rmax] = 0\n        # Filter inside of fine edge with smallest radius of\n        # coarse edge, i.e. `rad_coarse.min()`.\n        rad_fine = rad * edge_fine\n        if np.sum(rad_coarse):\n            edge_fine[rad_fine < rad_coarse[rad_coarse != 0].min()] = 0\n        # Filter outside of fine edge with `clip_rmax` twice\n        for __ in range(2):\n            rad_fine = rad * edge_fine\n            avg_fine = np.sum(rad_fine) / np.sum(edge_fine)\n            edge_fine[rad_fine > avg_fine * clip_rmax] = 0\n    elif np.sum(edge_coarse):\n        # No fine edge detected.\n        edge_fine = edge_coarse\n    else:\n        msg = \"Could not find edge! Try reducing `mult_coarse` \" \\\n              + \"and `mult_fine`.\"\n        raise EdgeDetectionError(msg)\n    # make sure there are more than 4 points\n    if np.sum(edge_fine) < 4:\n        msg = \"Detected edge too small! Try increasing `maxiter`, \" \\\n              + \"modifying `radius`, or reducing `mult_coarse`.\"\n        raise EdgeDetectionError(msg)\n    return edge_fine", "response": "Heuristic Canny - based edge detection for circular objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_run_command_dialog(command, shell=False, title='', data_callback=None,\n                           parent=None, **kwargs):\n    '''\n    Launch command in a subprocess and create a dialog window to monitor the\n    output of the process.\n\n    Parameters\n    ----------\n    command : list or str\n        Subprocess command to execute.\n    shell : bool, optional\n        If :data:`shell` is ``False``, :data:`command` **must** be a\n        :class:`list`.\n\n        If :data:`shell` is ``True``, :data:`command` **must** be a\n        :class:`str`.\n    title : str, optional\n        Title for dialog window and initial contents of main label.\n    data_callback : func(dialog, command_view, fd, data), optional\n        Callback function called when data is available for one of the file\n        descriptors.\n\n        The :data:`fd` callback parameter is 1 for ``stdout`` and 2 for\n        ``stderr``.\n    **kwargs\n        Additional keyword arguments are interpreted as dialog widget property\n        values and are applied to the dialog widget.\n\n    Returns\n    -------\n    gtk.Dialog\n        Dialog with a progress bar and an expandable text view to monitor the\n        output of the specified :data:`command`.\n\n        .. note::\n\n            Subprocess is launched before returning dialog.\n    '''\n    dialog = gtk.Dialog(title=title or None, parent=parent)\n    dialog.set_size_request(540, -1)\n    for key, value in kwargs.iteritems():\n        setattr(dialog.props, key, value)\n\n    dialog.add_buttons(gtk.STOCK_OK, gtk.RESPONSE_OK)\n    dialog.set_default_response(gtk.RESPONSE_OK)\n\n    content_area = dialog.get_content_area()\n    label = gtk.Label(title)\n    label.props.xalign = .1\n    content_area.pack_start(label, expand=False, fill=True, padding=10)\n\n    progress_bar = gtk.ProgressBar()\n\n    expander = gtk.Expander('Details')\n\n    # Resize window based on whether or not expander is open.\n    expander.connect('activate', functools\n                     .partial(lambda w, e, *args:\n                              w.set_size_request(540, -1 if e.props.expanded\n                                                 else 480), dialog))\n\n    command_view = CommandTextView()\n    if data_callback is not None:\n        command_view.connect('data-written', functools.partial(data_callback,\n                                                               dialog))\n\n    expander.add(command_view.widget)\n\n    content_area.pack_start(progress_bar, expand=False)\n    content_area.pack_start(expander, expand=True, fill=True)\n\n    button = dialog.get_action_area().get_children()[0]\n    content_area.show_all()\n\n    def _run_command(label, progress_bar, button, view, command, shell):\n        button.props.sensitive = False\n        text_buffer = command_view.text_view.get_buffer()\n        text_buffer.delete(*text_buffer.get_bounds())\n\n        def _pulse(*args):\n            progress_bar.pulse()\n            return True\n\n        timeout_id = gobject.timeout_add(250, _pulse)\n        command_view.run(command, shell=shell)\n        gobject.source_remove(timeout_id)\n        progress_bar.set_fraction(1.)\n        button.props.sensitive = True\n        label.set_markup('{} <b>done</b>.'.format(title))\n\n    gobject.idle_add(_run_command, label, progress_bar, button, command_view,\n                     command, shell)\n    return dialog", "response": "Launch command in a subprocess and create a dialog window and expandable text view to monitor the output of the process."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\noverriding dict. fromkeys to title - case keys.", "response": "def fromkeys(cls, seq, v=None):\n        \"\"\"Override dict.fromkeys() to title-case keys.\"\"\"\n\n        return super(HeaderDict, cls).fromkeys(cls,\n                                               [s.title() for s in seq], v)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\noverride dict. get to title - case keys.", "response": "def get(self, k, d=None):\n        \"\"\"Override dict.get() to title-case keys.\"\"\"\n\n        return super(HeaderDict, self).get(k.title(), d)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\noverride dict. setdefault to title - case keys.", "response": "def setdefault(self, k, d=None):\n        \"\"\"Override dict.setdefault() to title-case keys.\"\"\"\n\n        return super(HeaderDict, self).setdefault(k.title(), d)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\noverrides dict. update to title - case keys.", "response": "def update(self, e=None, **f):\n        \"\"\"Override dict.update() to title-case keys.\"\"\"\n\n        # Handle e first\n        if e is not None:\n            if hasattr(e, 'keys'):\n                for k in e:\n                    self[k.title()] = e[k]\n            else:\n                for (k, v) in e:\n                    self[k.title()] = v\n\n        # Now handle f\n        if len(f):\n            for k in f:\n                self[k.title()] = f[k]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef api_key_from_file(url):\n    path = os.path.expanduser('~/.config/python-bugzilla/bugzillarc')\n    cfg = SafeConfigParser()\n    cfg.read(path)\n    domain = urlparse(url)[1]\n    if domain not in cfg.sections():\n        return None\n    if not cfg.has_option(domain, 'api_key'):\n        return None\n    return cfg.get(domain, 'api_key')", "response": "Check bugzillarc for an API key for this Bugzilla URL."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmaking an XML - RPC call to the server.", "response": "def call(self, action, payload):\n        \"\"\"\n        Make an XML-RPC call to the server. This method will automatically\n        authenticate the call with self.api_key, if that is set.\n\n        returns: deferred that when fired returns a dict with data from this\n                 XML-RPC call.\n        \"\"\"\n        if self.api_key:\n            payload['Bugzilla_api_key'] = self.api_key\n        d = self.proxy.callRemote(action, payload)\n        d.addErrback(self._parse_errback)\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a single bug object. Similar to python - bugzilla s getbugsimple.", "response": "def get_bug_simple(self, bugid):\n        \"\"\"\n        Get a single bug object. Similar to python-bugzilla's getbugsimple().\n\n        param bugid: integer, a bug's number.\n        returns: deferred that when fired returns an AttrDict representing this\n                 bug.\n        \"\"\"\n        payload = {'ids': bugid}\n        d = self.call('Bug.get', payload)\n        d.addCallback(self._parse_bug_callback)\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_bugs_simple(self, bugids):\n        payload = {'ids': bugids}\n        d = self.call('Bug.get', payload)\n        d.addCallback(self._parse_bugs_callback)\n        return d", "response": "Get multiple bug objects. Similar to python - bugzilla s getbugssimple."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_bugs_summaries(self, bugids):\n        payload = {'ids': bugids, 'include_fields': ['id', 'summary']}\n        d = self.call('Bug.get', payload)\n        d.addCallback(self._parse_bugs_callback)\n        return d", "response": "Get multiple bug objects s summaries only ( faster."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef assign(self, bugids, user):\n        payload = {'ids': (bugids,), 'assigned_to': user}\n        d = self.call('Bug.update', payload)\n        d.addCallback(self._parse_bug_assigned_callback)\n        return d", "response": "Assign a bug to a user."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_by_external_tracker(self, url, id_):\n        payload = {\n            'include_fields': ['id', 'summary', 'status'],\n            'f1': 'external_bugzilla.url',\n            'o1': 'substring',\n            'v1': url,\n            'f2': 'ext_bz_bug_map.ext_bz_bug_id',\n            'o2': 'equals',\n            'v2': id_,\n        }\n        d = self.call('Bug.search', payload)\n        d.addCallback(self._parse_bugs_callback)\n        return d", "response": "Find a list of bugs by searching an external tracker URL and ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _parse_bugs_callback(self, value):\n        return list(map(lambda x: self._parse_bug(x), value['bugs']))", "response": "A callback that is called when we get bugs from the XML - RPC server."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses an error from an XML - RPC call and raise an exception.", "response": "def _parse_errback(self, error):\n        \"\"\"\n        Parse an error from an XML-RPC call.\n\n        raises: ``IOError`` when the Twisted XML-RPC connection times out.\n        raises: ``BugzillaNotFoundException``\n        raises: ``BugzillaNotAuthorizedException``\n        raises: ``BugzillaException`` if we got a response from the XML-RPC\n                server but it is not one of the ``xmlrpc.Fault``s above that\n                we know about.\n        raises: ``Exception`` if it is not one of the above.\n        \"\"\"\n        if isinstance(error.value, IOError):\n            raise error.value\n        if hasattr(xmlrpc, 'Fault'):  # Python 2:\n            fault = xmlrpc.Fault\n        else:\n            fault = xmlrpc.client.Fault\n        if isinstance(error.value, fault):\n            if error.value.faultCode == 101:\n                raise BugzillaNotFoundException(error.value.faultString)\n            if error.value.faultCode == 102:\n                raise BugzillaNotAuthorizedException(error.value.faultString)\n            if error.value.faultCode == 32000:\n                raise BugzillaTokenExpiredException(error.value.faultString)\n            raise BugzillaException(error.value)\n        # We don't know what this is, so just raise it.\n        raise error"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parse_bug(self, data):\n        if 'id' in data:\n            data['weburl'] = self.url.replace('xmlrpc.cgi', str(data['id']))\n        bug = AttrDict(data)\n        return bug", "response": "Parse a bug from XML - RPC server and return a dictionary of attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef id(self):\n        m = re.match(r'Bug #(\\d+) does not exist', self.message)\n        return m.group(1)", "response": "Bug ID that caused this error"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef id(self):\n        m = re.match(r'You are not authorized to access bug #(\\d+)',\n                     self.message)\n        return m.group(1)", "response": "Bug ID that caused this error"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncall when a plugin has been changed by the frontend.", "response": "def onSettingsChange(self, plugin_name, data):\n        \"\"\"\n        The plugin has been changed by the frontend\n\n        :param plugin_name: Name of plugin that changed\n        :type plugin_name: str\n        :param data: Complete data (changed and unchanged)\n        :type data: dict\n        :rtype: None\n        \"\"\"\n        logger.info(u\"onSettingsChange: {}\".format(data))\n        if not plugin_name:\n            logger.error(\"Missing plugin name\")\n            return\n        if not data:\n            logger.error(\"Missing data\")\n            return\n        logger.info(u\"Sending data {}\".format(data))\n        reactor.callFromThread(self._sendJSON, {\n            'msg': \"plugin_data_set\",\n            'plugin_name': plugin_name,\n            'data': data\n        })\n        # trigger db update\n        reactor.callFromThread(self._sendJSON, {\n            'msg': \"plugin_data_get\",\n            'plugin_name': plugin_name\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalling when a plugin is refreshed.", "response": "def onRefreshPluginData(self, plugin_name, data):\n        \"\"\"\n        Frontend requests a data refresh\n\n        :param plugin_name: Name of plugin that changed\n        :type plugin_name: str\n        :param data: Additional data\n        :type data: None\n        :rtype: None\n        \"\"\"\n        logger.info(u\"onRefreshPluginData: {}\".format(plugin_name))\n        if not plugin_name:\n            logger.error(\"Missing plugin name\")\n            return\n        reactor.callFromThread(self._sendJSON, {\n            'msg': \"plugin_data_get\",\n            'plugin_name': plugin_name\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef move(self, source, dest):\n        if dest.scheme == 'file':\n            if source.isdir() and dest.isdir():\n                dest /= source.basename()\n            return shutil.move(source.path, dest.path)\n        else:\n            return super(LocalFileSystem, self).move(source, dest)", "response": "move the file or directory source to dest"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend a WELCOME message to the server and wait for the welcome message before proceeding", "response": "def hello(self,details=None):\n        \"\"\" Say hello to the server and wait for the welcome\n            message before proceeding\n        \"\"\"\n        self._welcome_queue = queue.Queue()\n\n        if details is None:\n            details = {}\n        if self.authid:\n            details.setdefault('authid', self.authid)\n        details.setdefault('agent', u'swampyer-1.0')\n        details.setdefault('authmethods', self.authmethods or [u'anonymous'])\n        details.setdefault('roles', {\n                                        'subscriber': {},\n                                        'publisher': {},\n                                        'caller': {},\n                                        'callee': {},\n                                    })\n        self._state = STATE_AUTHENTICATING\n        self.send_message(HELLO(\n                                realm = self.realm,\n                                details = details\n                            ))\n\n        # Wait till we get a welcome message\n        try:\n            message = self._welcome_queue.get(block=True,timeout=self.timeout)\n        except Exception as ex:\n            raise ExWelcomeTimeout(\"Timed out waiting for WELCOME response\")\n        if message == WAMP_ABORT:\n            raise ExAbort(\"Received abort when trying to connect: {}\".format(\n                    message.details.get('message',\n                      message.reason)))\n        self.session_id = message.session_id\n        self.peer = message\n        self._state = STATE_CONNECTED\n\n        # And hook register/subscribe to anything that's required\n        self.handle_join(message)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef call(self, uri, *args, **kwargs ):\n        if self._state == STATE_DISCONNECTED:\n            raise Exception(\"WAMP is currently disconnected!\")\n        options = {\n            'disclose_me': True\n        }\n        uri = self.get_full_uri(uri)\n        message = self.send_and_await_response(CALL(\n                      options=options,\n                      procedure=uri,\n                      args=args,\n                      kwargs=kwargs\n                    ))\n\n        if message == WAMP_RESULT:\n            return message.args[0]\n\n        if message == WAMP_ERROR:\n            if message.args:\n                err = message.args[0]\n            else:\n                err = message.error\n            raise ExInvocationError(err)\n\n        return message", "response": "Sends a request to the WAMP server and returns the response."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send_message(self,message):\n        if self._state == STATE_DISCONNECTED:\n            raise Exception(\"WAMP is currently disconnected!\")\n        message = message.as_str()\n        logger.debug(\"SND>: {}\".format(message))\n        if not self.ws:\n            raise Exception(\"WAMP is currently disconnected!\")\n        self.ws.send(message)", "response": "Send a message to the server."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend a request then waits for a response.", "response": "def send_and_await_response(self,request):\n        \"\"\" Used by most things. Sends out a request then awaits a response\n            keyed by the request_id\n        \"\"\"\n        if self._state == STATE_DISCONNECTED:\n            raise Exception(\"WAMP is currently disconnected!\")\n        wait_queue = queue.Queue()\n        request_id = request.request_id\n        self._requests_pending[request_id] = wait_queue;\n        self.send_message(request)\n        try:\n            return wait_queue.get(block=True,timeout=self.timeout)\n        except Exception as ex:\n            raise Exception(\"Did not receive a response!\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dispatch_to_awaiting(self,result):\n\n        # If we are awaiting to login, then we might also get\n        # an abort message. Handle that here....\n        if self._state == STATE_AUTHENTICATING:\n            # If the authentication message is something unexpected,\n            # we'll just ignore it for now\n            if result == WAMP_ABORT \\\n               or result == WAMP_WELCOME \\\n               or result == WAMP_GOODBYE:\n                self._welcome_queue.put(result)\n            return\n\n        try:\n            request_id = result.request_id\n            if request_id in self._requests_pending:\n                self._requests_pending[request_id].put(result)\n                del self._requests_pending[request_id]\n        except:\n            raise Exception(\"Response does not have a request id. Do not know who to send data to. Data: {} \".format(result.dump()))", "response": "Dispatch the result to the appropriate queues."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npassing the invocation request to the appropriate WAMP Invoke wrapper.", "response": "def handle_invocation(self, message):\n        \"\"\" Passes the invocation request to the appropriate\n            callback.\n        \"\"\"\n        req_id = message.request_id\n        reg_id = message.registration_id\n        if reg_id in self._registered_calls:\n            handler = self._registered_calls[reg_id][REGISTERED_CALL_CALLBACK]\n            invoke = WampInvokeWrapper(self,handler,message)\n            invoke.start()\n        else:\n            error_uri = self.get_full_uri('error.unknown.uri')\n            self.send_message(ERROR(\n                request_code = WAMP_INVOCATION,\n                request_id = req_id,\n                details = {},\n                error =error_uri\n            ))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef handle_event(self, event):\n        subscription_id = event.subscription_id\n        if subscription_id in self._subscriptions:\n            # FIXME: [1] should be a constant\n            handler = self._subscriptions[subscription_id][SUBSCRIPTION_CALLBACK]\n            WampSubscriptionWrapper(self,handler,event).start()", "response": "Send the event to the subclass or simply reject\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef subscribe(self,topic,callback=None,options=None):\n        full_topic = self.get_full_uri(topic)\n        result = self.send_and_await_response(SUBSCRIBE(\n                                    options=options or {},\n                                    topic=full_topic\n                                ))\n        if result == WAMP_SUBSCRIBED:\n            if not callback:\n                callback = lambda a: None\n            self._subscriptions[result.subscription_id] = [topic,callback]", "response": "Subscribe to a uri for events from a publisher\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npublishes a message to the server", "response": "def publish(self,topic,options=None,args=None,kwargs=None):\n        \"\"\" Publishes a messages to the server\n        \"\"\"\n        topic = self.get_full_uri(topic)\n        if options is None:\n            options = {'acknowledge':True}\n        if options.get('acknowledge'):\n            request = PUBLISH(\n                        options=options or {},\n                        topic=topic,\n                        args=args or [],\n                        kwargs=kwargs or {}\n                      )\n            result = self.send_and_await_response(request)\n            return result\n        else:\n            request = PUBLISH(\n                        options=options or {},\n                        topic=topic,\n                        args=args or [],\n                        kwargs=kwargs or {}\n                      )\n            self.send_message(request)\n            return request.request_id"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndisconnect from the process and pause the process till we reconnect", "response": "def disconnect(self):\n        \"\"\" Disconnect from the websocket and pause the process\n            till we reconnect\n        \"\"\"\n        logger.debug(\"Disconnecting\")\n\n        # Close off the websocket\n        if self.ws:\n            try:\n                if self._state == STATE_CONNECTED:\n                    self.handle_leave()\n                    self.send_message(GOODBYE(\n                          details={},\n                          reason=\"wamp.error.system_shutdown\"\n                        ))\n                logger.debug(\"Closing Websocket\")\n                try:\n                    self.ws.close()\n                except Exception as ex:\n                    logger.debug(\"Could not close websocket connection because: {}\".format(ex))\n            except Exception as ex:\n                logger.debug(\"Could not send Goodbye message because {}\".format(ex))\n                pass # FIXME: Maybe do better handling here\n            self.ws = None\n\n        # Cleanup the state variables. By settings this\n        # we're going to be telling the main loop to stop\n        # trying to read from a websocket and await a notice\n        # of restart via a threading.Condition object\n        self._state = STATE_DISCONNECTED\n\n        # Send a message to all queues that we have disconnected\n        # Without this, any requests that are awaiting a response\n        # will block until timeout needlessly\n        for request_id, request_queue in self._requests_pending.items():\n            request_queue.put(GOODBYE(\n                          details={},\n                          reason=\"wamp.error.system_shutdown\"\n                        ))\n        self._requests_pending = {}\n        self.handle_disconnect()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef shutdown(self):\n        self._request_shutdown = True\n        for i in range(100):\n            if self._state == STATE_DISCONNECTED:\n                break\n            time.sleep(0.1)", "response": "Request the system to shutdown the main loop and shutdown the system\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef start(self):\n        self.connect()\n        if not self.isAlive():\n            super(WAMPClient,self).start()\n        self.hello()\n        return self", "response": "Initialize websockets say hello and start listening for events\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwait and receives messages from the server. This function somewhat needs to block so is executed in its own thread until self._request_shutdown is called.", "response": "def run(self):\n        \"\"\" Waits and receives messages from the server. This\n            function somewhat needs to block so is executed in its\n            own thread until self._request_shutdown is called.\n        \"\"\"\n        while not self._request_shutdown:\n\n            # Find out if we have any data pending from the\n            # server\n            try:\n\n                # If we've been asked to stop running the\n                # request loop. We'll just sit and wait\n                # till we get asked to run again\n                if self._state not in [STATE_AUTHENTICATING,STATE_WEBSOCKET_CONNECTED,STATE_CONNECTED]:\n                    self._request_loop_notify_restart.acquire()\n                    self._request_loop_notify_restart.wait(self._loop_timeout)\n                    self._request_loop_notify_restart.release()\n                    continue\n\n                # If we don't have a websocket defined.\n                # we don't go further either\n                elif not self.ws:\n                    logger.debug(\"No longer have a websocket. Marking disconnected\")\n                    self._state = STATE_DISCONNECTED\n                    continue\n\n                # Okay, we think we're okay so let's try and read some data\n                data = self.ws.recv()\n            except io.BlockingIOError:\n                continue\n            except websocket.WebSocketTimeoutException:\n                continue\n            except websocket.WebSocketConnectionClosedException as ex:\n                logger.debug(\"WebSocketConnectionClosedException: Requesting disconnect:\".format(ex))\n                self.disconnect()\n\n                # If the server disconnected, let's try and reconnect\n                # back to the service after a random few seconds\n                if self.auto_reconnect:\n                    # As doing a reconnect would block and would then\n                    # prevent us from ticking the websoocket, we'll\n                    # go into a subthread to deal with the reconnection\n                    def reconnect():\n                        self.reconnect()\n                    t = threading.Thread(target=reconnect)\n                    t.start()\n\n                    # FIXME: need to randomly wait\n                    time.sleep(1)\n                    if not data: continue\n            except Exception as ex:\n                logger.error(\"ERROR in main loop: {}\".format(ex))\n                continue\n\n            try:\n                logger.debug(\"<RCV: {}\".format(data))\n                message = WampMessage.loads(data)\n                logger.debug(\"<RCV: {}\".format(message.dump()))\n                try:\n                    code_name = message.code_name.lower()\n                    handler_name = \"handle_\"+code_name\n                    handler_function = getattr(self,handler_name)\n                    handler_function(message)\n                except AttributeError as ex:\n                    self.handle_unknown(message)\n            except Exception as ex:\n                logger.error(\"ERROR in main loop: {}\".format(ex))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncall when the server requests a challenge.", "response": "def handle_challenge(self,data):\n        \"\"\" Executed when the server requests additional\n            authentication\n        \"\"\"\n        # Send challenge response\n        self.send_message(AUTHENTICATE(\n            signature = self.password,\n            extra = {}\n        ))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates the pyephem solar - system snapshot database for the given MJD.", "response": "def _generate_pyephem_snapshot(\n        mjd,\n        log,\n        magLimit):\n    \"\"\"* generate pyephem snapshot*\n\n    **Key Arguments:**\n        - ``mjd`` -- the mjd to generate the pyephem snapshot database for\n        - ``xephemOE`` -- a list of xephem database format strings for use with pyephem\n\n    **Return:**\n        - ``pyephemDB`` -- the pyephem solar-system snapshot database\n    \"\"\"\n    log.info('starting the ``_generate_pyephem_snapshot`` method')\n\n    print \"generating pyephem database for MJD %(mjd)s\" % locals()\n\n    global xephemOE\n    global DEG_TO_RAD_FACTOR\n    global RAD_TO_DEG_FACTOR\n    global nside\n\n    # THE PYEPHEM OBSERVER\n    obs = ephem.Observer()\n    # PYEPHEM WORKS IN DUBLIN JD, TO CONVERT FROM MJD SUBTRACT 15019.5\n    obs.date = float(mjd) - 15019.5\n    pyephemDB = {\n        \"ra_deg\": [],\n        \"dec_deg\": [],\n        \"mpc_number\": [],\n        \"object_name\": [],\n        \"healpix\": [],\n        \"mag\": []\n    }\n\n    for d in xephemOE:\n\n        # GENERATE EPHEMERIS FOR THIS OBJECT\n        minorPlanet = ephem.readdb(d[\"pyephem_string\"])\n        minorPlanet.compute(obs)\n\n        if minorPlanet.mag > magLimit:\n            continue\n\n        if d[\"mpc_number\"]:\n            d[\"mpc_number\"] = int(d[\"mpc_number\"])\n\n        thisRa = minorPlanet.a_ra * RAD_TO_DEG_FACTOR\n        thisDec = minorPlanet.a_dec * RAD_TO_DEG_FACTOR\n        pyephemDB[\"mag\"].append(minorPlanet.mag)\n        pyephemDB[\"ra_deg\"].append(thisRa)\n        pyephemDB[\"dec_deg\"].append(thisDec)\n        pyephemDB[\"mpc_number\"].append(d[\"mpc_number\"])\n        pyephemDB[\"object_name\"].append(d[\"name\"])\n        pyephemDB[\"healpix\"].append(hp.ang2pix(\n            nside, theta=thisRa, phi=thisDec, lonlat=True))\n\n    log.info('completed the ``_generate_pyephem_snapshot`` method')\n    return pyephemDB"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _match_single_exposure_against_pyephem_db(\n        exposure,\n        log):\n    \"\"\"*summary of function*\n\n    **Key Arguments:**\n        - ``exposure`` -- the atlas expsosure metadata\n        - ``log`` -- logger\n\n    **Return:**\n        - None\n\n    **Usage:**\n        .. todo::\n\n            add usage info\n            create a sublime snippet for usage\n\n        .. code-block:: python \n\n            usage code            \n    \"\"\"\n    log.info('starting the ``_match_single_exposure_against_pyephem_db`` function')\n\n    global tileSide\n    global magLimit\n    global DEG_TO_RAD_FACTOR\n    global nside\n    global moversDict\n\n    matchedObjects = []\n    expId = exposure[\"expname\"]\n    raFc = float(exposure[\"raDeg\"])\n    decFc = float(exposure[\"decDeg\"])\n\n    # GENERATE THE EXPOSURE HEALPIX ID MAP\n    decCorners = (decFc - tileSide / 2,\n                  decFc + tileSide / 2)\n    corners = []\n    for d in decCorners:\n        if d > 90.:\n            d = 180. - d\n        elif d < -90.:\n            d = -180 - d\n        raCorners = (raFc - (tileSide / 2) / np.cos(d * DEG_TO_RAD_FACTOR),\n                     raFc + (tileSide / 2) / np.cos(d * DEG_TO_RAD_FACTOR))\n        for r in raCorners:\n            if r > 360.:\n                r = 720. - r\n            elif r < 0.:\n                r = 360. + r\n            corners.append(hp.ang2vec(r, d, lonlat=True))\n\n    # NEAR THE POLES RETURN SQUARE INTO TRIANGE - ALMOST DEGENERATE\n    pole = False\n    for d in decCorners:\n        if d > 87.0 or d < -87.0:\n            pole = True\n\n    if pole == True:\n        corners = corners[1:]\n    else:\n        # FLIP CORNERS 3 & 4 SO HEALPY UNDERSTANDS POLYGON SHAPE\n        corners = [corners[0], corners[1],\n                   corners[3], corners[2]]\n\n    # RETURN HEALPIXELS IN EXPOSURE AREA\n    expPixels = hp.query_polygon(nside, np.array(\n        corners))\n\n    # MATCH HEALPIX ON EXPOSURE AGAINST PYEPHEM DATABASE\n    for ele in expPixels:\n        if ele in moversDict:\n            for o in moversDict[ele]:\n                d2 = copy.deepcopy(o)\n                d2[\"expname\"] = expId\n                matchedObjects.append(d2)\n\n    log.info('completed the ``_match_single_exposure_against_pyephem_db`` function')\n    return matchedObjects", "response": "This function matches a single exposure against the pyephem database."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(self, singleSnapshot=False):\n        self.log.info('starting the ``get`` method')\n\n        global xephemOE\n        global tileSide\n        global magLimit\n\n        # GRAB PARAMETERS FROM SETTINGS FILE\n        tileSide = float(self.settings[\"pyephem\"][\"atlas exposure match side\"])\n        magLimit = float(self.settings[\"pyephem\"][\"magnitude limit\"])\n\n        snapshotsRequired = 1\n        while snapshotsRequired > 0:\n            nextMjds, exposures, snapshotsRequired = self._get_exposures_requiring_pyephem_positions(\n                concurrentSnapshots=int(self.settings[\"pyephem\"][\"batch size\"]))\n            print \"There are currently %(snapshotsRequired)s more pyephem snapshots required \" % locals()\n            if snapshotsRequired == 0:\n                return\n\n            if len(xephemOE) == 0:\n                xephemOE = self._get_xephem_orbital_elements()\n\n            # DEFINE AN INPUT ARRAY\n            magLimit = self.settings[\"pyephem\"][\"magnitude limit\"]\n            pyephemDB = fmultiprocess(log=self.log, function=_generate_pyephem_snapshot, timeout=300,\n                                      inputArray=nextMjds, magLimit=magLimit)\n\n            matchedObjects = []\n            for p, e, m in zip(pyephemDB, exposures, nextMjds):\n                matchedObjects.append(\n                    self._match_pyephem_snapshot_to_atlas_exposures(p, e, m))\n\n            self._add_matched_objects_to_database(matchedObjects)\n            self._update_database_flag(exposures)\n\n            if singleSnapshot:\n                snapshotsRequired = 0\n\n        self.log.info('completed the ``get`` method')\n        return None", "response": "Returns the pyephem positions for the current user - specified pyephem instance."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_exposures_requiring_pyephem_positions(\n            self,\n            concurrentSnapshots=10):\n        \"\"\"*get next batch of exposures requiring pyephem positions*\n\n        **Key Arguments:**\n            -  ``concurrentSnapshots`` -- number of concurrent PyEphem snapshots to process\n        \"\"\"\n        self.log.info(\n            'starting the ``_get_exposures_requiring_pyephem_positions`` method')\n\n        if self.dev_flag == True:\n            dev_flag = \" and dev_flag = 1\"\n        else:\n            dev_flag = \"\"\n\n        sqlQuery = u\"\"\"\n            select distinct pyephem_mjd from atlas_exposures where pyephem_positions = 0 and local_data = 1 %(dev_flag)s order by pyephem_mjd asc\n        \"\"\" % locals()\n        rows = readquery(\n            log=self.log,\n            sqlQuery=sqlQuery,\n            dbConn=self.atlasMoversDBConn,\n            quiet=False\n        )\n\n        snapshotsRequired = len(rows)\n\n        if snapshotsRequired == 0:\n            return [], [], 0\n\n        nextMjds = []\n        nextMjds[:] = [r[\"pyephem_mjd\"] for r in rows[:concurrentSnapshots]]\n\n        exposures = []\n        for nextMjd in nextMjds:\n            sqlQuery = u\"\"\"\n                select * from atlas_exposures where pyephem_positions = 0 %(dev_flag)s and pyephem_mjd = %(nextMjd)s\n            \"\"\" % locals()\n            theseExps = readquery(\n                log=self.log,\n                sqlQuery=sqlQuery,\n                dbConn=self.atlasMoversDBConn,\n                quiet=False\n            )\n            exposures.append(list(theseExps))\n\n        self.log.info(\n            'completed the ``_get_exposures_requiring_pyephem_positions`` method')\n        return nextMjds, exposures, snapshotsRequired", "response": "get next batch of exposures requiring pyephem positions"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _add_matched_objects_to_database(\n            self,\n            matchedObjects):\n        \"\"\"*add mathced objects to database*\n\n        **Key Arguments:**\n            - ``matchedObjects`` -- these objects matched in the neighbourhood of the ATLAS exposures (list of dictionaries)\n        \"\"\"\n        self.log.info(\n            'starting the ``_add_matched_objects_to_database`` method')\n\n        print \"Adding the matched sources to the `pyephem_positions` database table\"\n\n        allMatches = []\n        for m in matchedObjects:\n            allMatches += m\n\n        dbSettings = self.settings[\"database settings\"][\"atlasMovers\"]\n\n        insert_list_of_dictionaries_into_database_tables(\n            dbConn=self.atlasMoversDBConn,\n            log=self.log,\n            dictList=allMatches,\n            dbTableName=\"pyephem_positions\",\n            uniqueKeyList=[\"expname\", \"object_name\"],\n            dateModified=True,\n            batchSize=10000,\n            replace=True,\n            dbSettings=dbSettings\n        )\n\n        self.log.info(\n            'completed the ``_add_matched_objects_to_database`` method')\n        return None", "response": "Adds mathced objects to the database table."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates database flag for the given atlas exposures", "response": "def _update_database_flag(\n            self,\n            exposures):\n        \"\"\"* update database flag*\n\n        **Key Arguments:**\n            - ``exposures`` -- the atlas exposure to update the database flags for\n        \"\"\"\n        self.log.info('starting the ``_update_database_flag`` method')\n\n        allExposures = []\n        for e in exposures:\n            allExposures += e\n\n        expIds = []\n        expIds[:] = [e[\"expname\"] for e in allExposures]\n\n        expIds = ('\",\"').join(expIds)\n\n        sqlQuery = \"\"\"update atlas_exposures a, pyephem_positions p set a.pyephem_positions = 1 where a.pyephem_positions = 0 and a.expname=p.expname;\"\"\" % locals(\n        )\n        writequery(\n            log=self.log,\n            sqlQuery=sqlQuery,\n            dbConn=self.atlasMoversDBConn,\n        )\n\n        sqlQuery = \"\"\"update atlas_exposures set pyephem_positions = 2, dophot_match = 2, orbfit_positions = 2 where pyephem_positions = 0 and expname in (\"%(expIds)s\");\"\"\" % locals(\n        )\n        writequery(\n            log=self.log,\n            sqlQuery=sqlQuery,\n            dbConn=self.atlasMoversDBConn,\n        )\n\n        self.log.info('completed the ``_update_database_flag`` method')\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_xephem_orbital_elements(\n            self):\n        \"\"\"*get xephem orbital elements*\n\n        **Key Arguments:**\n            - ``xephemOE`` -- a list of xephem database format strings for use with pyephem\n        \"\"\"\n        self.log.info('starting the ``_get_xephem_orbital_elements`` method')\n\n        print \"Getting the XEphem orbital element strings from the database\"\n\n        sqlQuery = u\"\"\"\n            select pyephem_string, name, mpc_number from orbital_elements where include_in_match = 1\n        \"\"\" % locals()\n        rows = readquery(\n            log=self.log,\n            sqlQuery=sqlQuery,\n            dbConn=self.atlasMoversDBConn,\n            quiet=False\n        )\n\n        xephemOE = list(rows)\n\n        self.log.info('completed the ``_get_xephem_orbital_elements`` method')\n        return xephemOE", "response": "get the list of XEphem orbital elements from the database"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _match_pyephem_snapshot_to_atlas_exposures(\n            self,\n            pyephemDB,\n            exposures,\n            mjd):\n        \"\"\"*match pyephem snapshot to atlas exposures*\n\n        **Key Arguments:**\n            - ``pyephemDB`` -- the pyephem solar-system snapshot database\n            - ``exposures`` -- the atlas exposures to match against the snapshot\n            - ``mjd`` -- the MJD of the pyephem snapshot\n\n        **Return:**\n            - ``matchedObjects`` -- these objects matched in the neighbourhood of the ATLAS exposures (list of dictionaries)\n        \"\"\"\n        self.log.info(\n            'starting the ``_match_pyephem_snapshot_to_atlas_exposures`` method')\n\n        global DEG_TO_RAD_FACTOR\n        global RAD_TO_DEG_FACTOR\n        global moversDict\n\n        e = len(exposures)\n\n        print \"Matching %(e)s ATLAS exposures against the pyephem snapshot for MJD = %(mjd)s\" % locals()\n\n        # MAKE SURE HEALPIX SMALL ENOUGH TO MATCH FOOTPRINTS CORRECTLY\n        global nside\n\n        # GRAB PARAMETERS FROM SETTINGS FILE\n        tileSide = float(self.settings[\"pyephem\"][\"atlas exposure match side\"])\n        magLimit = float(self.settings[\"pyephem\"][\"magnitude limit\"])\n\n        # EXPLODE OUT THE PYEPHEM DATABASE\n        ra = pyephemDB[\"ra_deg\"]\n        dec = pyephemDB[\"dec_deg\"]\n        healpix = pyephemDB[\"healpix\"]\n        objects = pyephemDB[\"object_name\"]\n        mpc_numbers = pyephemDB[\"mpc_number\"]\n        mag = pyephemDB[\"mag\"]\n\n        # INDEX PYEPHEM MOVERS IN DICTIONARY BY HEALPIX ID\n        moversDict = defaultdict(list)\n        for ind, (p, r, d, o, m, g) in enumerate(zip(healpix, ra, dec, objects, mpc_numbers, mag)):\n            moversDict[p].append(\n                {\"object_name\": o,\n                 \"ra_deg\": r,\n                 \"dec_deg\": d,\n                 \"mpc_number\": m,\n                 \"mag\": g\n                 }\n            )\n\n        # MATCH THE PYEPHEM MOVERS AGAINST THE ATLAS EXPOSURES\n        matchedObjects = []\n        results = fmultiprocess(log=self.log, function=_match_single_exposure_against_pyephem_db, timeout=120,\n                                inputArray=exposures)\n        for r in results:\n            matchedObjects += r\n\n        self.log.info(\n            'completed the ``_match_pyephem_snapshot_to_atlas_exposures`` method')\n        return matchedObjects", "response": "Match the pyephem snapshot to the atlas exposures."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncorrect isotopic proxy data for ice - volume contribution.", "response": "def icevol_correction(age, proxyvalue, proxytype='d18o', timeunit='ya', \n                      benthic_stack=None):\n    \"\"\"Correct isotopic proxy data for ice-volume contribution\n\n    This function uses the LR04 benthic stack [1]_ scaled\n    such that the LGM-present change is assumed to be 1.0 \u2030 in accordance\n    with the pore-water estimate from [2]_. This correction method\n    is adapted from [3]_.\n\n    Parameters\n    ----------\n    age: ndarray\n        Age array associated with proxy data.\n    proxyvalue: ndarray\n        Isotopic proxy data to be corrected.\n    proxytype: str, optional\n        Type of proxy. Must be 'd18o' for \u03b418O or 'dd' for \u03b4D. \n        Default is 'd18o'.\n    timeunit: str, optional\n        Time unit for 'age'. Must be 'ya' (for years BP), 'ka' \n        (thousand years BP), or 'ma' (million years BP). Default is 'ya'.\n    benthic_stack: obj, optional\n        Benthic stack to use for ice-volume correction. Uses \n        erebusfall.benthic_stacks.lr04 by default. This is derived from LR04.\n\n    Returns\n    -------\n    A numpy array giving the corrected isotope data.\n\n    References\n    ----------\n    .. [1] Lisiecki, L. E., & Raymo, M. E. (2005). A Pliocene-Pleistocene stack\n       of 57 globally distributed benthic \u03b418O records: PLIOCENE-PLEISTOCENE\n       BENTHIC STACK. Paleoceanography, 20(1). https://doi.org/10.1029/2004PA001071\n    .. [2] Schrag, D. P., Hampt, G., & Murray, D. W. (1996). Pore Fluid\n       Constraints on the Temperature and Oxygen Isotopic Composition of the\n       Glacial Ocean. Science, 272(5270), 1930\u20131932. https://doi.org/10.1126/science.272.5270.1930\n    .. [3] Tierney, J. E., deMenocal, P. B., & Zander, P. D. (2017). A climatic\n       context for the out-of-Africa migration. Geology, 45(11), 1023\u20131026.\n       https://doi.org/10.1130/G39457.1\n\n    Examples\n    --------\n    >>> import erebusfall\n    >>> import numpy as np\n    >>> age_ka = np.arange(0, 20, 1)\n    >>> proxy = np.random.normal(loc=-2.0, size=len(age_ka))\n    >>> proxy_adjusted = erebusfall.icevol_correction(age_ka, proxy,\n    ...                                               proxytype='d18o',\n    ...                                               timeunit='ka')\n\n    \"\"\"\n    age = np.array(age)\n    proxyvalue = np.array(proxyvalue)\n    assert len(age) == len(proxyvalue)\n\n    proxytype = proxytype.lower()\n    timeunit = timeunit.lower()\n    assert proxytype in ['d18o', 'dd']\n    assert timeunit in ['ya', 'ka', 'ma']\n\n    if benthic_stack is None:\n        benthic_stack = stacks.lr04\n\n    sage = benthic_stack.age.copy()\n    if timeunit == 'ya':\n        sage *= 1000\n    elif timeunit == 'ma':\n        sage /= 1000\n\n    # Linearly interpolate the scaled benthic stack to the target data ages.\n    interp_f = interp1d(sage, benthic_stack.delo_scaled, kind='linear', \n                        bounds_error=False)\n    target = interp_f(age)\n\n    # Find any ages that are negative (e.g., post-1950) and turn to 0\n    modern = age < 0\n    if any(modern):\n        target[modern] = 0\n\n    # Find any ages that are greater than the end of the benthic stack and set\n    # then to nan.\n    ancient = age > max(sage)\n    if any(ancient):\n        target[ancient] = np.nan\n\n    # adjust the isotope data\n    if proxytype == 'dd':\n        target = 8 * target\n    corrected = ((1000 + proxyvalue) / (target / 1000 + 1)) - 1000\n\n    return corrected"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extract(input, **params):\n    EXTRACT_FIELD = 'field'\n\n    extract_params = params\n    extract_params.update({AccessParams.KEY_TYPE: AccessParams.TYPE_SINGLE})\n    return __extract(input, params)[params.get(EXTRACT_FIELD)]", "response": "Extracts field value from document\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef aggregate(input, **params):\n    PARAM_CFG_EXTRACT = 'extract'\n    PARAM_CFG_SUBSTITUTE = 'substitute'\n    PARAM_CFG_AGGREGATE = 'aggregate'\n    AGGR_FIELD = 'field'\n    AGGR_FUNC = 'func'\n\n    extract_params = params.get(PARAM_CFG_EXTRACT)\n    extract_params.update({AccessParams.KEY_TYPE: AccessParams.TYPE_MULTI})\n    dataset = __extract(input, extract_params)\n    if PARAM_CFG_SUBSTITUTE in params:\n        dataset = __substitute(input, dataset, params.get(PARAM_CFG_SUBSTITUTE))\n    cfg = params.get(PARAM_CFG_AGGREGATE)\n    res = Aggregator.agg_single_func(dataset, cfg[AGGR_FIELD], cfg[AGGR_FUNC])\n    return res", "response": "Returns aggregate\n    :param input:\n    :param params:\n    :return:"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning violation message if validated value greater than constraint otherwise None", "response": "def limit_exceed(to_validate, constraint, violation_cfg):\n    \"\"\"\n    Compares 2 values and returns violation message if validated value bigger than constraint\n    :param to_validate:\n    :param constraint:\n    :param violation_cfg:\n    :return:\n    \"\"\"\n    if to_validate > constraint:\n        violation_cfg[Check.CFG_KEY_VIOLATION_MSG] = violation_cfg[Check.CFG_KEY_VIOLATION_MSG].format(constraint)\n        return violation_cfg\n    else:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a violation message if validated and constraint sets have no intersection", "response": "def no_intersection(to_validate, constraint, violation_cfg):\n    \"\"\"\n    Returns violation message if validated and constraint sets have no intersection\n    :param to_validate:\n    :param constraint:\n    :param violation_cfg:\n    :return:\n    \"\"\"\n    if len(constraint) == 0 or len(set(constraint).intersection(to_validate)) > 0:\n        return None\n    else:\n        violation_cfg[Check.CFG_KEY_VIOLATION_MSG] = violation_cfg[Check.CFG_KEY_VIOLATION_MSG].format(constraint)\n        return violation_cfg"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nperform validation against the object.", "response": "def validate(self, obj_to_validate, is_substitute=True):\n        \"\"\"\n        Performs validation\n        :param obj_to_validate:\n        :param is_substitute:\n        :return: list of validation messages or None\n        \"\"\"\n        res = []\n        for check in self.__cfg[Validator.__CFG_KEY_CHECKS]:\n            self.__logger.info('Performing {} validation against {}'.format(check, obj_to_validate))\n            check_res = Check(self.__cfg[Validator.__CFG_KEY_CHECKS][check]).validate(obj_to_validate, is_substitute)\n            if check_res:\n                if type(check_res) == dict:\n                    res.append(check_res)\n                else:\n                    res.extend(check_res)\n        return None if len(res) == 0 else res"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate(self, input, is_substitute): # ToDo: apply 'no substitute' for initial load validations\n        constraint = self.__get_constraint(input)\n        to_validate = self.__get_to_validate(input)\n        return self.__compare(to_validate, constraint)", "response": "Performs validation\n        :param input: object to validate\n        :param is_substitute: will be used for what-if in the future\n        :return: validation result if violated or None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfunctioning DocString Function DocString", "response": "def question_image_filepath(instance, filename):\n    \"\"\"\n        Function DocString\n    \"\"\"\n    return '/'.join(['images', str(instance.question_level), str(instance.question_level_id), binascii.b2a_hex(os.urandom(15)), filename])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run_through(script, ensemble, roles=1, strict=False):\n    with script as dialogue:\n        selection = dialogue.select(ensemble, roles=roles)\n        if not any(selection.values()) or strict and not all(selection.values()):\n            return\n\n        try:\n            model = dialogue.cast(selection).run()\n        except (AttributeError, ValueError) as e:\n            log = logging.getLogger(\"turberfield.dialogue.player.run_through\")\n            log.warning(\". \".join(getattr(e, \"args\", e) or e))\n            return\n        else:\n            yield from model", "response": "Yields the model instances of the ensemble in a sequence."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rehearse(\n    folders, references, handler,\n    repeat=0, roles=1, strict=False,\n    loop=None\n):\n    \"\"\"Cast a set of objects into a sequence of scene scripts. Deliver the performance.\n\n    :param folders: A sequence of\n        :py:class:`turberfield.dialogue.model.SceneScript.Folder` objects.\n    :param references: A sequence of Python objects.\n    :param handler: A callable object. This will be invoked with every event from the\n                    performance.\n    :param int repeat: Extra repetitions of each folder.\n    :param int roles: Maximum number of roles permitted each character.\n    :param bool strict: Only fully-cast scripts to be performed.\n\n    This function is a generator. It yields events from the performance.\n\n    \"\"\"\n    if isinstance(folders, SceneScript.Folder):\n        folders = [folders]\n\n    yield from handler(references, loop=loop)\n\n    matcher = Matcher(folders)\n    performer = Performer(folders, references)\n    while True:\n        folder, index, script, selection, interlude = performer.next(\n            folders, references, strict=strict, roles=roles\n        )\n        yield from handler(script, loop=loop)\n\n        for item in performer.run(react=False, strict=strict, roles=roles):\n            yield from handler(item, loop=loop)\n\n        if isinstance(interlude, Callable):\n            metadata = next(handler(\n                interlude, folder, index, references, loop=loop\n            ), None)\n            yield metadata\n            if metadata is None:\n                return\n\n            branch = next(matcher.options(metadata))\n            if branch != folder:\n                performer = Performer([branch], references)\n\n        if not repeat:\n            break\n        else:\n            repeat -= 1", "response": "Cast a set of objects into a sequence of scene scripts. Deliver the performance."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_last_nonce(app, key, nonce):\n    uk = ses.query(um.UserKey).filter(um.UserKey.key==key)\\\n            .filter(um.UserKey.last_nonce<nonce * 1000).first()\n    if not uk:\n        return None\n    lastnonce = copy.copy(uk.last_nonce)\n    # TODO Update DB record in same query as above, if possible\n    uk.last_nonce = nonce * 1000\n    try:\n        ses.commit()\n    except Exception as e:\n        current_app.logger.exception(e)\n        ses.rollback()\n        ses.flush()\n    return lastnonce", "response": "Get the last_nonce used by the given key from the SQLAlchemy database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_user_by_key(app, key):\n    user = ses.query(um.User).join(um.UserKey).filter(um.UserKey.key==key).first()\n    return user", "response": "An SQLAlchemy User getting function. Get a user by public key."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the latest balance for a single User", "response": "def get_balance():\n    \"\"\"\n    Get the latest balance(s) for a single User.\n    Currently no search parameters are supported. All balances returned.\n    ---\n    responses:\n      '200':\n        description: the User's balance(s)\n        schema:\n          items:\n            $ref: '#/definitions/Balance'\n          type: array\n      default:\n        description: unexpected error\n        schema:\n          $ref: '#/definitions/errorModel'\n    security:\n      - kid: []\n      - typ: []\n      - alg: []\n    operationId: getBalance\n    \"\"\"\n    balsq = ses.query(wm.Balance).filter(wm.Balance.user_id == current_user.id)\n    if not balsq:\n        return None\n    bals = [json.loads(jsonify2(b, 'Balance')) for b in balsq]\n    print \"returning bals %s\" % bals\n    response = current_app.bitjws.create_response(bals)\n    ses.close()\n    return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_address():\n    currency = request.jws_payload['data'].get('currency')\n    network = request.jws_payload['data'].get('network')\n    state = 'active'\n    if network.lower() in ps:\n        try:\n            addy = ps[network.lower()].get_new_address()\n        except Exception as e:\n            print type(e)\n            print e\n            current_app.logger.error(e)\n            return 'wallet temporarily unavailable', 500\n    else:\n        return 'Invalid network', 400\n    address = wm.Address(addy, currency, network, state, current_user.id)\n    ses.add(address)\n    try:\n        ses.commit()\n    except Exception as ie:\n        ses.rollback()\n        ses.flush()\n        return 'Could not save address', 500\n    newaddy = json.loads(jsonify2(address, 'Address'))\n    current_app.logger.info(\"created new address %s\" % newaddy)\n    ses.close()\n    return current_app.bitjws.create_response(newaddy)", "response": "This function creates a new pseudo - address owned by your user."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_address():\n    address = request.jws_payload['data'].get('address')\n    currency = request.jws_payload['data'].get('currency')\n    network = request.jws_payload['data'].get('network')\n    addysq = ses.query(wm.Address).filter(wm.Address.user_id == current_user.id)\n    if address:\n        addysq = addysq.filter(wm.Address.address == address)\n    elif currency:\n        addysq = addysq.filter(wm.Address.currency == currency)\n    elif network:\n        addysq = addysq.filter(wm.Address.network == network)\n    if addysq.count() == 0:\n        return \"Invalid Request\", 400\n\n    addys = [json.loads(jsonify2(a, 'Address')) for a in addysq]\n    response = current_app.bitjws.create_response(addys)\n    ses.close()\n    return response", "response": "Get one or more existing address owned by your user."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsearches Debit for a single User", "response": "def search_debit():\n    \"\"\"\n    Get one to ten debit(s) for a single User.\n    ---\n    parameters:\n      - name: searchcd\n        in: body\n        description: The Debit(s) you'd like to get.\n        required: false\n        schema:\n          $ref: '#/definitions/SearchCD'\n    responses:\n      '200':\n        description: the User's debit(s)\n        schema:\n          items:\n            $ref: '#/definitions/Debit'\n          type: array\n      default:\n        description: unexpected error\n        schema:\n          $ref: '#/definitions/errorModel'\n    security:\n      - kid: []\n      - typ: []\n      - alg: []\n    operationId: searchDebits\n    \"\"\"\n    sid = request.jws_payload['data'].get('id')\n    address = request.jws_payload['data'].get('address')\n    currency = request.jws_payload['data'].get('currency')\n    network = request.jws_payload['data'].get('network')\n    #reference = request.jws_payload['data'].get('reference')\n    ref_id = request.jws_payload['data'].get('ref_id')\n    page = request.jws_payload['data'].get('page') or 0\n\n    debsq = ses.query(wm.Debit).filter(wm.Debit.user_id == current_user.id)\n    if not debsq:\n        return None\n\n    if sid:\n        debsq = debsq.filter(wm.Debit.id == sid)\n    if address:\n        debsq = debsq.filter(wm.Debit.address == address)\n    if currency:\n        debsq = debsq.filter(wm.Debit.currency == currency)\n    if network:\n        debsq = debsq.filter(wm.Debit.network == network)\n    #if reference:\n    #    debsq = debsq.filter(wm.Debit.reference == reference)\n    if ref_id:\n        debsq = debsq.filter(wm.Debit.ref_id == ref_id)\n    debsq = debsq.order_by(wm.Debit.time.desc()).limit(10)\n    if page and isinstance(page, int):\n        debsq = debsq.offset(page * 10)\n\n    debits = [json.loads(jsonify2(d, 'Debit')) for d in debsq]\n    response = current_app.bitjws.create_response(debits)\n    ses.close()\n    return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsearches CREDENTIAL for a single User", "response": "def search_credit():\n    \"\"\"\n    Get one to ten credit(s) for a single User.\n    ---\n    parameters:\n      - name: searchcd\n        in: body\n        description: The Credit(s) you'd like to get.\n        required: false\n        schema:\n          $ref: '#/definitions/SearchCD'\n    responses:\n      '200':\n        description: the User's credit(s)\n        schema:\n          items:\n            $ref: '#/definitions/Credit'\n          type: array\n      default:\n        description: unexpected error\n        schema:\n          $ref: '#/definitions/errorModel'\n    security:\n      - kid: []\n      - typ: []\n      - alg: []\n    operationId: searchCredits\n    \"\"\"\n    sid = request.jws_payload['data'].get('id')\n    address = request.jws_payload['data'].get('address')\n    currency = request.jws_payload['data'].get('currency')\n    network = request.jws_payload['data'].get('network')\n    #reference = request.jws_payload['data'].get('reference')\n    ref_id = request.jws_payload['data'].get('ref_id')\n    page = request.jws_payload['data'].get('page') or 0\n\n    credsq = ses.query(wm.Credit).filter(wm.Credit.user_id == current_user.id)\n    if not credsq:\n        return None\n    if sid:\n        credsq = credsq.filter(wm.Credit.id == sid)\n    if address:\n        credsq = credsq.filter(wm.Credit.address == address)\n    if currency:\n        credsq = credsq.filter(wm.Credit.currency == currency)\n    if network:\n        credsq = credsq.filter(wm.Credit.network == network)\n    #if reference:\n    #    credsq = credsq.filter(wm.Credit.reference == reference)\n    if ref_id:\n        credsq = credsq.filter(wm.Credit.ref_id == ref_id)\n    credsq = credsq.order_by(wm.Credit.time.desc()).limit(10)\n    if page and isinstance(page, int):\n        credsq = credsq.offset(page * 10)\n\n    credits = [json.loads(jsonify2(c, 'Credit')) for c in credsq]\n    response = current_app.bitjws.create_response(credits)\n    ses.close()\n    return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget information about the transaction network indicated.", "response": "def network_info(network):\n    \"\"\"\n    Get information about the transaction network indicated.\n    Returned info is: enabled/disabled, available hot wallet balance,\n    & the transaction fee.\n    ---\n    description: Get information about the transaction network indicated.\n    operationId: getinfo\n    produces:\n      - application/json\n    parameters:\n      - name: network\n        in: path\n        type: string\n        required: true\n        description: The network name i.e. Bitcoin, Dash\n    responses:\n      '200':\n        description: the network information\n        schema:\n          $ref: '#/definitions/NetworkInfo'\n      default:\n        description: an error\n        schema:\n          $ref: '#/definitions/errorModel'\n    \"\"\"\n    lnet = network.lower()\n    isenabled = lnet in ps\n    fee = float(CFG.get(lnet, 'FEE'))\n    roughAvail = str(int(ps[lnet].get_balance()['available'].to_double()))\n    available = float(10 ** (len(roughAvail) - 1))\n    response = json.dumps({'isenabled': isenabled, 'fee': fee,\n                           'available': available})\n    ses.close()\n    return response"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_debit():\n    currency = request.jws_payload['data'].get('currency')\n    amount = Amount(\"%s %s\" % (request.jws_payload['data'].get('amount'),\n                               currency))\n    address = request.jws_payload['data'].get('address')\n    network = request.jws_payload['data'].get('network')\n    reference = request.jws_payload['data'].get('reference')\n    state = 'unconfirmed'\n    try:\n        debit = plugin.create_debit(current_user, amount, currency, address, network, reference, state='unconfirmed',\n                                    plugins=ps, session=ses)\n        plugin.process_debit(debit, plugins=ps, session=ses)\n    except (IOError, ValueError) as e:\n        current_app.logger.exception(e)\n        ses.rollback()\n        ses.flush()\n        return \"Unable to send money\", 400\n    except Exception as e:\n        current_app.logger.exception(e)\n        ses.rollback()\n        ses.flush()\n        return \"Unable to send money\", 500\n    result = json.loads(jsonify2(debit, 'Debit'))\n    current_app.logger.info(\"created new debit %s\" % result)\n    ses.close()\n    return current_app.bitjws.create_response(result)", "response": "Create a new debit and send tokens out of your User s account."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting your user object.", "response": "def get_user():\n    \"\"\"\n    Get your user object.\n\n    Users may only get their own info, not others'.\n    ---\n    responses:\n      '200':\n        description: user response\n        schema:\n          $ref: '#/definitions/User'\n      default:\n        description: unexpected error\n        schema:\n          $ref: '#/definitions/errorModel'\n    description: get your user record\n    security:\n      - kid: []\n      - typ: []\n      - alg: []\n    operationId: getUserList\n    \"\"\"\n    userdict = json.loads(jsonify2(current_user.dbuser, 'User'))\n    return current_app.bitjws.create_response(userdict)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_user():\n    load_jws_from_request(request)\n    if not hasattr(request, 'jws_header') or request.jws_header is None:\n        return \"Invalid Payload\", 401\n    username = request.jws_payload['data'].get('username')\n    address = request.jws_header['kid']\n    last_nonce = request.jws_payload['iat']*1000\n    try:\n        user, userkey = create_user_and_key(username=username, address=address, last_nonce=last_nonce, session=ses)\n    except IOError:\n        ses.rollback()\n        ses.flush()\n        return 'username or key taken', 400\n    jresult = json.loads(jsonify2(userkey, 'UserKey'))\n    current_app.logger.info(\"registered user %s with key %s\" % (user.id, userkey.key))\n    ses.close()\n    return current_app.bitjws.create_response(jresult)", "response": "Register a new User and a UserKey based on the JWS header and payload."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes the ratio of all the items in a list of key value pairs.", "response": "def compute_ratio(x):\n        \"\"\"\n        \u8ba1\u7b97\u6bcf\u4e00\u7c7b\u6570\u636e\u7684\u5360\u6bd4\n        \"\"\"\n        sum_ = sum(x)\n        ratios = []\n        for i in x:\n            ratio = i / sum_\n            ratios.append(ratio)\n        return ratios"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a proxy for a Widget", "response": "def proxy_for(widget):\n    \"\"\"Create a proxy for a Widget\n\n    :param widget: A gtk.Widget to proxy\n\n    This will raise a KeyError if there is no proxy type registered for the\n    widget type.\n    \"\"\"\n    proxy_type = widget_proxies.get(widget.__class__)\n    if proxy_type is None:\n        raise KeyError('There is no proxy type registered for %r' % widget)\n    return proxy_type(widget)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the widget s value", "response": "def update(self, value):\n        \"\"\"Update the widget's value\n        \"\"\"\n        self.update_internal(value)\n        self.emit('changed', self.get_widget_value())"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_internal(self, value):\n        self.block()\n        self.set_widget_value(value)\n        self.unblock()", "response": "Update the widget s value without firing a changed signal"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nperforming the initial connection of the widget with the signal_name and add the SID to the list of connections that are connected to the widgets.", "response": "def connect_widget(self):\n        \"\"\"Perform the initial connection of the widget\n\n        the default implementation will connect to the widgets signal\n        based on self.signal_name\n        \"\"\"\n        if self.signal_name is not None:\n            # None for read only widgets\n            sid = self.widget.connect(self.signal_name, self.widget_changed)\n            self.connections.append(sid)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_proxy_for(self, name, widget):\n        proxy = proxy_for(widget)\n        self.add_proxy(name, proxy)", "response": "Create a proxy for a widget and add it to this group\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the mapping of arguments to values.", "response": "def _getcallargs(func, positional, named):\n    \"\"\"Get the mapping of arguments to values.\n\n    Generates a dict, with keys being the function argument names\n    (including the names of the * and ** arguments, if any), and\n    values the respective bound values from 'positional' and 'named'.\n    A parameter for the request is injected.  Returns a tuple of the\n    dict, the object the method is being called on, and the name of\n    the injected request argument.\n    \"\"\"\n\n    args, varargs, varkw, defaults = inspect.getargspec(func)\n    f_name = func.__name__\n    arg2value = {}\n\n    # The following closures are basically because of tuple parameter\n    # unpacking.\n    assigned_tuple_params = []\n\n    def assign(arg, value):\n        if isinstance(arg, str):\n            arg2value[arg] = value\n        else:\n            assigned_tuple_params.append(arg)\n            value = iter(value)\n            for i, subarg in enumerate(arg):\n                try:\n                    subvalue = next(value)\n                except StopIteration:\n                    raise ValueError('need more than %d %s to unpack' %\n                                     (i, 'values' if i > 1 else 'value'))\n                assign(subarg, subvalue)\n            try:\n                next(value)\n            except StopIteration:\n                pass\n            else:\n                raise ValueError('too many values to unpack')\n\n    def is_assigned(arg):\n        if isinstance(arg, str):\n            return arg in arg2value\n        return arg in assigned_tuple_params\n\n    # Inject a place-holder for the request and get the self and the\n    # req_name\n    positional = positional[:1] + (None,) + positional[1:]\n    theSelf = positional[0]\n    req_name = args[1]\n\n    num_pos = len(positional)\n    num_total = num_pos + len(named)\n    num_args = len(args)\n    num_defaults = len(defaults) if defaults else 0\n\n    # Start with our positional parameters...\n    for arg, value in zip(args, positional):\n        assign(arg, value)\n\n    # Deal with the variable argument list...\n    if varargs:\n        if num_pos > num_args:\n            assign(varargs, positional[-(num_pos-num_args):])\n        else:\n            assign(varargs, ())\n    elif 0 < num_args < num_pos:\n        raise TypeError('%s() takes %s %d %s (%d given)' % (\n            f_name, 'at most' if defaults else 'exactly', num_args,\n            'arguments' if num_args > 1 else 'argument', num_total))\n    elif num_args == 0 and num_total:\n        raise TypeError('%s() takes no arguments (%d given)' %\n                        (f_name, num_total))\n\n    # Exclusion rules on keyword arguments\n    for arg in args:\n        if isinstance(arg, str) and arg in named:\n            if is_assigned(arg):\n                raise TypeError(\"%s() got multiple values for keyword \"\n                                \"argument '%s'\" % (f_name, arg))\n            else:\n                assign(arg, named.pop(arg))\n\n    # Fill in any missing values with the defaults\n    if defaults:\n        for arg, value in zip(args[-num_defaults:], defaults):\n            if not is_assigned(arg):\n                assign(arg, value)\n\n    # Handle the **names\n    if varkw:\n        assign(varkw, named)\n    elif named:\n        unexpected = next(iter(named))\n        if isinstance(unexpected, unicode):\n            unexpected = unexpected.encode(sys.getdefaultencoding(), 'replace')\n        raise TypeError(\"%s() got an unexpected keyword argument '%s'\" %\n                        (f_name, unexpected))\n\n    # Anything left over?\n    unassigned = num_args - len([arg for arg in args if is_assigned(arg)])\n    if unassigned:\n        num_required = num_args - num_defaults\n        raise TypeError('%s() takes %s %d %s (%d given)' % (\n            f_name, 'at least' if defaults else 'exactly', num_required,\n            'arguments' if num_required > 1 else 'argument', num_total))\n\n    # Return the mapping and the name of the request argument\n    return arg2value, theSelf, req_name"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\njoins two URLs into a single URL.", "response": "def _urljoin(left, right):\n    \"\"\"Join two URLs.\n\n    Takes URLs specified by left and right and joins them into a\n    single URL.  If right is an absolute URL, it is returned directly.\n    This differs from urlparse.urljoin() in that the latter always\n    chops off the left-most component of left unless it is trailed by\n    '/', which is not the behavior we want.\n    \"\"\"\n\n    # Handle the tricky case of right being a full URL\n    tmp = urlparse.urlparse(right)\n    if tmp.scheme or tmp.netloc:\n        # Go ahead and use urlparse.urljoin()\n        return urlparse.urljoin(left, right)\n\n    # Check for slashes\n    joincond = (left[-1:], right[:1])\n    if joincond == ('/', '/'):\n        # Too many, preserve only one\n        return left + right[1:]\n    elif '/' in joincond:\n        # Just one; great!\n        return left + right\n    else:\n        # Not enough; add one\n        return left + '/' + right"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef restmethod(method, reluri, *qargs, **headers):\n\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Process the arguments against the original function\n            argmap, theSelf, req_name = _getcallargs(func, args, kwargs)\n\n            # Build the URL\n            url = _urljoin(theSelf._baseurl, reluri.format(**argmap))\n\n            # Build the query string, as needed\n            if qargs:\n                query = dict([(k, argmap[k]) for k in qargs\n                              if argmap[k] is not None])\n                if query:\n                    url += '?%s' % urllib.urlencode(query)\n\n            # Build the headers, if needed\n            hlist = None\n            if headers:\n                hlist = hdrs.HeaderDict()\n                for aname, hname in headers.items():\n                    if argmap[aname]:\n                        hlist[hname] = argmap[aname]\n                if not hlist:\n                    # If there are no headers, don't send any\n                    hlist = None\n\n            # Now, build the request and pass it to the method\n            argmap[req_name] = theSelf._make_req(method, url,\n                                                 func.__name__, hlist)\n\n            # Call the method\n            return func(**argmap)\n\n        # Return the function wrapper\n        return wrapper\n\n    # Return the actual decorator\n    return decorator", "response": "Decorate a method to inject an HTTPRequest using the given HTTP method and relative URI."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef apply_addons(widget, *addon_types, **named_addon_types):\n    for addon_type in addon_types:\n        addon_type(widget)\n\n    for name, addon_type in named_addon_types.items():\n        addon_type(widget, addon_name=name)", "response": "Applies some addons to a widget."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a path based on component configuration.", "response": "def make_path(config, *endings):\n    \"\"\"\n    Create a path based on component configuration.\n\n    All paths are relative to the component's configuration directory; usually\n    this will be the same for an entire session, but this function supuports\n    component-specific configuration directories.\n\n    Arguments:\n    config - the configuration object for a component\n    endings - a list of file paths to append to the component's configuration\n              directory\n    \"\"\"\n    config_dir = config.get(\"dp.config_dir\")\n    return os.path.join(config_dir, *endings)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts the JSON expression of a contact information into an instance of Contact.", "response": "def from_json(payload):\n        \"\"\"\n        Convert the JSON expression of a contact information into an instance\n        `Contact.\n\n\n        @param payload: a JSON expression representing a contact information:\n\n            [ type:ContactName, value:string, [is_primary:boolean, [is_verified:boolean]] ]\n\n\n        @return: an instance `Contact`.\n\n\n        @raise AssertError: if the specified type of this contact information\n            is not a string representation of an item of the enumeration\n            `ContactName`.\n\n        @raise ValueError: if the value of this contact information is null.\n        \"\"\"\n        contact_item_number = len(payload)\n        assert 2 <= contact_item_number <= 4, 'Invalid contact information format'\n\n        is_primary = is_verified = None\n\n        # Unpack the contact information to each component.\n        if contact_item_number == 2:\n            (name, value) = payload\n        elif contact_item_number == 3:\n            (name, value, is_primary) = payload\n        else:\n            (name, value, is_primary, is_verified) = payload\n\n        return Contact(cast.string_to_enum(name, Contact.ContactName), value,\n                is_primary=is_primary and cast.string_to_boolean(is_primary, strict=True),\n                is_verified=is_verified and cast.string_to_boolean(is_verified, strict=True))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting an object representing a contact information to an instance of the instance containing the specified instance of Contact.", "response": "def from_object(obj):\n        \"\"\"\n        Convert an object representing a contact information to an instance\n        `Contact`.\n\n\n        @param obj: an object containg the following attributes:\n\n            * `name`: an item of the enumeration `ContactName` representing the\n              type of this contact information.\n\n            * `value`: value of this contact information representing by a string,\n              such as ``+84.01272170781``, the formatted value for a telephone\n              number property.\n\n            * `is_primary`: indicate whether this contact property is the first to\n              be used to contact the entity that this contact information\n              corresponds to.  There is only one primary contact property for a\n              given property name (e.g., `EMAIL`, `PHONE`, `WEBSITE`).\n\n            * `is_verified`: indicate whether this contact information has been\n              verified, whether it has been grabbed from a trusted Social\n              Networking Service (SNS), or whether through a challenge/response\n              process.\n\n\n        @raise ValueError: if the value of this contact information is null.\n        \"\"\"\n        return obj if isinstance(obj, Contact) \\\n            else Contact(cast.string_to_enum(obj.name, Contact.ContactName),\n                         obj.value,\n                         is_primary=obj.is_primary and cast.string_to_boolean(obj.is_primary, strict=True),\n                         is_verified=obj.is_verified and cast.string_to_boolean(obj.is_verified, strict=True))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef post(self, request, question_level, question_number, format=None):\n\n        user = User.objects.get(username=request.user.username)\n        question = Question.objects.filter(question_level=question_level).filter(question_number=question_number)\n        if int(user.profile.user_access_level) < int(question_level):\n            content = {'user_nick':profile.user_nick, 'please move along': 'Nothing to see here' }\n            return Response(content, status=status.HTTP_406_NOT_ACCEPTABLE)\n\n        time_last = None\n        time_last_query = Submission.objects.filter(submission_user__username=request.user.username).filter(submission_question__question_level=question_level).filter(submission_question__question_number=question_number).filter(submission_state='WA').order_by('submission_timestamp').last()\n        check_resubmission = AcceptedQuestion.objects.filter(record_user=request.user).filter(record_question=question)\n        if check_resubmission:\n            content = {'user_nick':profile.user_nick, 'Do not try to resubmit': 'Already Accepted' }\n            return Response(content, status=status.HTTP_406_NOT_ACCEPTABLE)\n        if time_last_query:\n            time_last = time_last_query.submission_timestamp\n        time_limit = self.get_contest_consecutive_submission_halt_time()\n\n#        print time_last, time_limit, datetime.datetime.now(), time_limit <= datetime.datetime.now()\n\n        if(time_last is None or time_last + time_limit <= datetime.datetime.now()):\n\n            type_of_contest =  self.get_contest_type()\n            type_of_submission = self.get_question_type()\n            if type_of_submission != STRING:\n                content = { 'user_nick':profile.user_nick, 'please move along': 'WRONG TYPE SUBMISSION'}\n                return Response(content, status=status.HTTP_405_METHOD_NOT_ALLOWED)\n\n            serializer = SubmissionSerializer(data=request.data)\n            if serializer.is_valid():\n                serializer.save(submission_user = request.user,\n                                submission_question = self.get_object(question_level,question_number)[0],\n                )\n                # checker_queue.delay(int(serializer.data['id']))\n                return Response(serializer.data, status=status.HTTP_201_CREATED)\n            else:\n                return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)\n        else:\n            content = {'user_nick':profile.user_nick, 'Try to submit after some time': 'Nothing to see here' }\n            return Response(content, status=status.HTTP_406_NOT_ACCEPTABLE)", "response": "This function is used to submit a new entry in the database."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef post(self, request, question_level, question_number, format=None):\n        user = User.objects.get(username=request.user.username)\n        question = Question.objects.filter(question_level=question_level).filter(question_number=question_number)\n        if int(user.profile.user_access_level) < int(question_level):\n            content = {'user_nick':profile.user_nick, 'please move along': 'Nothing to see here' }\n            return Response(content, status=status.HTTP_406_NOT_ACCEPTABLE)\n\n        time_last = None\n        time_last_query = Comment.objects.filter(comment_user__username=request.user.username).order_by('comment_timestamp').last()\n        if time_last_query:\n            time_last = time_last_query.comment_timestamp\n        time_limit = self.get_contest_consecutive_submission_halt_time() # the halt time for submission is kept same as submission halt time\n\n#        print time_last, time_limit, datetime.datetime.now(), time_limit <= datetime.datetime.now()\n\n        if(time_last is None or time_last + time_limit <= datetime.datetime.now()):\n\n            serializer = CommentSerializer(data=request.data)\n            if not request.data['comment_message'] or len(str(request.data['comment_message'])) >= 255:\n                content = {'user_nick':profile.user_nick, 'Try to submit something small': 'Like your Dick' }\n                return Response(content, status=status.HTTP_406_NOT_ACCEPTABLE)\n            if serializer.is_valid():\n                serializer.save(comment_user = request.user,\n                                comment_question = question[0],\n                )\n                checker_queue.delay(int(serializer.data['id']))\n                return Response(serializer.data, status=status.HTTP_201_CREATED)\n            else:\n                return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)\n        else:\n            content = {'user_nick':profile.user_nick, 'Try to submit after some time': 'Nothing to see here' }\n            return Response(content, status=status.HTTP_406_NOT_ACCEPTABLE)", "response": "This function is used to submit a comment for a user."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing arguments returns options and args.", "response": "def parse_args(args=None):\n    \"\"\"Parses arguments, returns (options, args).\"\"\"\n\n    if args is None:\n        args = sys.argv\n\n    parser = ArgumentParser(description='Barcode scanner based on GStreamer, '\n                            'zbar, and gtk.')\n    log_levels = ('critical', 'error', 'warning', 'info', 'debug', 'notset')\n\n    parser.add_argument('-l', '--log-level', type=str, choices=log_levels,\n                        default='info')\n    parser.add_argument('-d', '--device-name', type=str, help='GStreamer video'\n                        ' device name')\n    parser.add_argument('-w', '--max-width', type=int,\n                        help='Maximum video width')\n    parser.add_argument('-f', '--max-fps', type=float, help='Maximum video '\n                        'frame rate (frames/second)')\n    parser.add_argument('schema', type=str, help='jsonschema schema')\n\n    args = parser.parse_args()\n    if hasattr(args, 'log_level'):\n        args.log_level = getattr(logging, args.log_level.upper())\n    return args"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef calculate_base_sequence(base_offsets):\n    return ''.join([ chr(c) for c in list(itertools.chain.from_iterable(\n                      [ range(ord(x), ord(y) + 1) for (x, y) in base_offsets ])) ])", "response": "Return a sequence of characters corresponding to the specified base."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating a secured key from an integer value.", "response": "def generate_secured_key(value,\n        key_nonce_separator='.',\n        nonce_length=4,\n        base=BASE62):\n    \"\"\"\n    Generate a secured key composed of the integer value encoded in Base62\n    and a nonce.\n\n    @param value: an integer value.\n\n    @param key_nonce_separator: the character that is used to separate the\n        key and the nonce to form the secured key.\n\n    @param nonce_length: the number of characters to compose the nonce.\n\n    @param base: a sequence of characters that is used to encode the\n           integer value.\n\n    @return: a tuple ``(key, nonce, secured_key)``:\n        * ``key``: string representation of the integer value in Base62.\n        * ``nonce``: \"number used once\", a pseudo-random number to\n          ensure that the key cannot be reused in replay attacks.\n        * ``secured_key``: a string composed of the key concatenated with\n          the nonce.\n    \"\"\"\n    if not isinstance(value, (int, long)):\n        raise ValueError()\n\n    posix_time = int(time.mktime(datetime.datetime.now().timetuple()))\n    nonce = hashlib.md5(str(posix_time)).hexdigest()[:nonce_length]\n    key = int_to_key(value, base=base)\n    return key, nonce, '%s%s%s' % (key, key_nonce_separator, nonce)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert the specified integer value to a key using the given base.", "response": "def int_to_key(value, base=BASE62):\n    \"\"\"\n    Convert the specified integer to a key using the given base.\n\n    @param value: a positive integer.\n\n    @param base: a sequence of characters that is used to encode the\n           integer value.\n\n    @return: a key expressed in the specified base.\n    \"\"\"\n    def key_sequence_generator(value, base):\n        \"\"\"\n        Generator for producing sequence of characters of a key providing an\n        integer value and a base of characters for encoding, such as Base62\n        for instance.\n\n        @param value: a positive integer.\n        @param base: a sequence of characters that is used to encode the\n               integer value.\n\n        @return: the next character of the object's key encoded with the\n                 specified base.\n            \"\"\"\n        base_length = len(base)\n        while True:\n            yield base[value % base_length]\n            if value < base_length:\n                break\n            value /= base_length\n\n    return ''.join([ c for c in key_sequence_generator(value, base) ])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef key_to_int(key, base=BASE62):\n    base_length = len(base)\n\n    value = 0\n    for c in reversed(key):\n        value = (value * base_length) + base.index(c)\n\n    return value", "response": "Convert the following key to an integer."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses a given secured key and return its associated integer the key itself and the embedded nonce.", "response": "def parse_secured_key(secured_key,\n        key_nonce_separator='.',\n        nonce_length=4,\n        base=BASE62):\n    \"\"\"\n    Parse a given secured key and return its associated integer, the key\n    itself, and the embedded nonce.\n\n    @param secured_key a string representation of a secured key composed\n           of a key in Base62, a separator character, and a nonce.\n\n    @param key_nonce_separator: the character that is used to separate the\n           key and the nonce to form the secured key.\n\n    @param nonce_length: the number of characters to compose the nonce.\n\n    @param base: a sequence of characters that is used to encode the\n           integer value.\n\n    @return: a tuple ``(value, key, nonce)``:\n             * ``value``: the integer value of the key.\n             * ``key``: the plain-text key.\n             * ``nonce``: \"number used once\", a pseudo-random number to\n               ensure that the key cannot be reused in replay attacks.\n\n    @raise ValueError: if the format of the secured key is invalid, or if\n           the embedded nonce is of the wrong length.\n       \"\"\"\n    parts = secured_key.split(key_nonce_separator)\n    if len(parts) != 2:\n        raise ValueError('Invalid secured key format')\n\n    (key, nonce) = parts\n    if len(nonce) != nonce_length:\n        raise ValueError('Invalid length of the key nonce')\n\n    return key_to_int(key, base=base), key, nonce"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef uuid4():\r\n    # Otherwise, get randomness from urandom or the 'random' module.\r\n    try:\r\n        import os\r\n        return UUID(bytes=os.urandom(16), version=4)\r\n    except Exception:\r\n        import random\r\n        bytes = [chr(random.randrange(256)) for i in range(16)]\r\n        return UUID(bytes=bytes, version=4)", "response": "Generate a random UUID."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef uuid5(namespace, name):\r\n    from hashlib import sha1\r\n    hash = sha1(namespace.bytes + name).digest()\r\n    return UUID(bytes=hash[:16], version=5)", "response": "Generate a UUID from the SHA - 1 hash of a namespace UUID and a name."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a single template by name.", "response": "def get(args):\n    \"\"\"\n    Get a template by name.\n    \"\"\"\n    m = TemplateManager(args.hosts)\n    t = m.get(args.name)\n    if t:\n        print(json.dumps(t, indent=2))\n    else:\n        sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting a template by name", "response": "def delete(args):\n    \"\"\"\n    Delete a template by name\n    \"\"\"\n    m = TemplateManager(args.hosts)\n    m.delete(args.name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses a user object into a single object", "response": "def user_parser(user):\n    \"\"\"\n    Parses a user object\n    \"\"\"\n    if __is_deleted(user):\n        return deleted_parser(user)\n\n    if user['id'] in item_types:\n        raise Exception('Not a user name')\n    if type(user['id']) == int:\n        raise Exception('Not a user name')\n\n    return User(\n        user['id'],\n        user['delay'],\n        user['created'],\n        user['karma'],\n        user['about'],\n        user['submitted'],\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef story_parser(story):\n    if __is_deleted(story):\n        return deleted_parser(story)\n    if story['type'] != 'story':\n        return item_parser(story)\n    return Story(\n        __check_key('id', story),\n        __check_key('by', story),\n        __check_key('kids', story),\n        __check_key('score', story),\n        __check_key('time', story),\n        __check_key('title', story),\n        __check_key('type', story),\n        __check_key('url', story),\n    )", "response": "Parses a story object into a new object"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing a comment object into a single object", "response": "def comment_parser(comment):\n    \"\"\"\n    Parses a comment object\n    \"\"\"\n    try:\n        if comment['type'] != 'comment':\n            return item_parser(comment)\n    except KeyError:\n        return deleted_parser(comment)\n    return Comment(\n        comment['id'],\n        comment['by'],\n        __check_key('kids', comment),  # some comments do not have kids key\n        comment['parent'],\n        comment['text'],\n        comment['time'],\n        comment['type'],\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse a poll object returning a new object", "response": "def poll_parser(poll):\n    \"\"\"\n    Parses a poll object\n    \"\"\"\n    if __is_deleted(poll):\n        return deleted_parser(poll)\n    if poll['type'] not in poll_types:\n        raise Exception('Not a poll type')\n    return Poll(\n        poll['id'],\n        poll['by'],\n        __check_key('kids', poll),  # poll and pollopt differ this property\n        __check_key('parts', poll),  # poll and pollopt differ this property\n        poll['score'],\n        poll['text'],\n        poll['time'],\n        poll['title'],\n        poll['type'],\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse a item object into a base Item object", "response": "def item_parser(item):\n    \"\"\"\n    Parses a item object\n    It gives None for the property not present\n    Used when some item types do not get parsed easily when using gevent\n    \"\"\"\n    if __is_deleted(item):\n        return deleted_parser(item)\n    return Item(\n        __check_key('id', item),\n        __check_key('deleted', item),\n        __check_key('type', item),\n        __check_key('by', item),\n        __check_key('time', item),\n        __check_key('text', item),\n        __check_key('dead', item),\n        __check_key('parent', item),\n        __check_key('kids', item),\n        __check_key('url', item),\n        __check_key('score', item),\n        __check_key('title', item),\n        __check_key('parts', item),\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a string representation of the specified JSON object.", "response": "def json_to_string(value, null_string_repr='[]', trimable=False):\n    \"\"\"\n    Return a string representation of the specified JSON object.\n\n    @param value: a JSON object.\n\n    @param null_string_rep: the string representation of the null\n        object.\n\n    @return: a string representation of the specified JSON object.\n    \"\"\"\n    return null_string_repr if is_undefined(value) \\\n        else obj.jsonify(value, trimable=trimable)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef string_to_boolean(value, strict=False, default_value=False):\n    if is_undefined(value) and default_value:\n        return default_value\n\n    if isinstance(value, bool):\n        return value\n\n    if isinstance(value, basestring) and value is not None:\n        value = value.lower()\n\n    is_true = value in ('yes', 'true', 't', '1')\n\n    if not is_true and strict == True and \\\n       value not in ('no', 'false', 'f', '0'):\n        raise ValueError(\"The specified string doesn't represent a boolean value\")\n\n    return is_true", "response": "Converts a string representation of a boolean into a boolean value."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef string_to_date(value):\n    if isinstance(value, datetime.date):\n        return value\n\n    return dateutil.parser.parse(value).date()", "response": "Returns a Python date that corresponds to the specified string representation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a string representation of an integer to a decimal number.", "response": "def string_to_decimal(value, strict=True):\n    \"\"\"\n    Return a decimal corresponding to the string representation of a\n    number.\n\n    @param value: a string representation of an decimal number.\n\n    @param strict:  indicate whether the specified string MUST be of a\n        valid decimal number representation.\n\n    @return: the decimal value represented by the string.\n\n    @raise ValueError: if the string doesn't represent a valid decimal,\n        while the argument ``strict`` equals ``True``.\n    \"\"\"\n    if is_undefined(value):\n        if strict:\n            raise ValueError('The value cannot be null')\n        return None\n\n    try:\n        return float(value)\n\n    except ValueError:\n        raise ValueError(\n            'The specified string \"%s\" does not represent an integer' % value)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef string_to_enum(value, enumeration, strict=True, default_value=None):\n    if not isinstance(enumeration, Enum):\n        raise ValueError('The specified enumeration is not an instance of Enum')\n\n    if is_undefined(value):\n        if strict:\n            raise ValueError('The value cannot be null')\n\n        if default_value is not None and not default_value in enumeration:\n            raise ValueError('The default value must be an item of the specified enumeration')\n\n        return default_value\n\n    item = [ item for item in enumeration if str(item) == value]\n    if len(item) == 0:\n        raise ValueError('The specified string \"%s\" does not represent any item of the enumeration' % value)\n\n    return item[0]", "response": "Converts a string representation of an item of an enumeration to an item of a Python enumeration."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a string representation of an integer number to an integer number.", "response": "def string_to_integer(value, strict=False):\n    \"\"\"\n    Return an integer corresponding to the string representation of a\n    number.\n\n    @param value: a string representation of an integer number.\n\n    @param strict:  indicate whether the specified string MUST be of a\n        valid integer number representation.\n\n    @return: the integer value represented by the string.\n\n    @raise ValueError: if the string doesn't represent a valid integer,\n        while the argument ``strict`` equals ``True``.\n    \"\"\"\n    if is_undefined(value):\n        if strict:\n            raise ValueError('The value cannot be null')\n        return None\n\n    try:\n        return int(value)\n\n    except ValueError:\n        raise ValueError('The specified string \"%s\" does not represent an integer' % value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a dotted - decimal notation IPv4 address to a tuple of four decimal numbers.", "response": "def string_to_ipv4(value, strict=False):\n    \"\"\"\n    Return a tuple corresponding to the string representation of an IPv4\n    address.\n\n    An IPv4 address is canonically represented in dot-decimal notation,\n    which consists of four decimal numbers, each ranging from 0 to 255,\n    separated by dots, e.g., ``172.16.254.1``.\n\n\n    @param value: a dotted-decimal notation of an IPv4 address, consisting\n        of four decimal numbers, each ranging from ``0`` to ``255``,\n        separated by dots.\n\n    @param strict: indicate whether the ``None`` value is accepted.\n\n\n    @return: a tuple of four decimal numbers ``(byte1, byte2, byte3, byte4)``,\n        each ranging from ``0`` to ``255``.\n    \"\"\"\n    if is_undefined(value):\n        if strict:\n            raise ValueError('The value cannot be null')\n        return None\n\n    if not REGEX_IPV4.match(value):\n        raise ValueError('The specified string \"%s\" does not represent a IPv4' % value)\n\n    ipv4 = [ int(byte) for byte in value.split('.') if int(byte) < 256]\n\n    if len(ipv4) != 4:\n        raise ValueError('The IPv4 \"%s\" has invalid byte(s)' % value)\n\n    return ipv4"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef string_to_locale(value, strict=True):\n    try:\n        return None if is_undefined(value) else Locale.from_string(value, strict=strict)\n    except Locale.MalformedLocaleException, exception:\n        if strict:\n            raise exception", "response": "Converts a string representation of a locale into a locale object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef string_to_macaddr(value, strict=False):\n    if is_undefined(value):\n        if strict:\n            raise ValueError('The value cannot be null')\n        return None\n\n    match = REGEX_MAC_ADDRESS.match(value.lower())\n    if match is None:\n        raise ValueError('The specified string \"%s\" does not represent a MAC address' % value)\n\n    return match.groups()", "response": "Converts a string representation of a MAC address into a 6 - character tuple."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a string representation of a time into a time object.", "response": "def string_to_time(value):\n    \"\"\"\n    Return an instance ``datetime.time`` that corresponds to the specified\n    string representation.\n\n    @param value: a string representation of a time ``HH:MM[:SS]``, where:\n\n        * ``HH``: hour (24-hour clock) as a zero-padded decimal number.\n\n        * ``MM``: minute as a zero-padded decimal number.\n\n        * ``SS``: second as a zero-padded decimal number.\n\n    @return: an instance ``datetime.time`` represented by the string.\n\n    @raise ValueError: if the string representation doesn't correspond to\n        a valid time.\n    \"\"\"\n    try:\n        return datetime.datetime.strptime(value, '%H:%M:%S').time()\n    except ValueError:\n        return datetime.datetime.strptime(value, '%H:%M').time()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef string_to_timestamp(value,\n        second_digits=3,\n        default_utc_offset=None,\n        rounding_method=TimestampRoundingMethod.ceiling):\n    \"\"\"\n    Return the ISO 8601 date time that corresponds to the specified string\n    representation.\n\n    When the required precision is lower than microsecond, the function\n    rounds the sub-second time to the specified number of digits.\n\n    By default, when possible, it returns the smallest value greater than\n    or equal to the sub-second time for specified precision, also know as\n    \"ceiling conversion\"; for instance, the function converts ``918845``\n    microseconds to ``919`` milliseconds.  Otherwise, the function return\n    the largest value equal to the sub-second time for specified\n    precision, also known as \"floor conversion\"; for instance, the\n    function converts ``999916`` microseconds to ``999`` milliseconds.\n\n\n    @param value: string representation of an ISO date time.\n\n    @param second_digits: indicate the number of second digits after the\n        decimal point, to determine the time precision.  For instance, 3\n        digits corresponds to milliseconds, 6 digits corresponds to\n        microseconds.\n\n    @param default_utc_offset: if the specified string representation\n        doesn't mention any time zone, use this offset as the time zone\n        of the corresponding ISO 8601 date time, or use the time zone\n        of the machine this code is running on as the default time zone.\n\n    @param rounding_method: one of the rounding method, as declared in\n        ``TimestampRoundingMethod``, when the required precision is lower\n        than microsecond.\n\n\n    @return: an instance ``ISO8601DateTime`` represented by the string.\n\n\n    @raise ValueError: if the specified number of second digits after the\n        decimal point is not in 0..6, or if the string representation\n        doesn't correspond to a valid ISO 8601 date time.\n    \"\"\"\n    if second_digits < 0 or second_digits > 6:\n        raise ValueError('The number of second digits after the decimal point must be in 0..6')\n\n    if not value:\n        return None\n\n    if isinstance(value, datetime.date):\n        pydatetime = ISO8601DateTime.from_datetime(value)\n\n    else:\n        if default_utc_offset is not None:\n            value = '%s%s%02d' % (value[:19], '-' if default_utc_offset < 0 else '+', default_utc_offset)\n\n        d = dateutil.parser.parse(value)\n\n        if second_digits >= 6:\n            microsecond = d.microsecond\n        else:\n            f = 10 ** (6 - second_digits)\n            if rounding_method == TimestampRoundingMethod.ceiling:\n                m = int(math.ceil(float(d.microsecond) / f))\n                if m >= f:\n                    m -= 1\n            else:\n                m = int(math.floor(float(d.microsecond) / f))\n\n            microsecond = m * f\n\n        pydatetime = ISO8601DateTime(\n                d.year, d.month, d.day,\n                d.hour, d.minute, d.second, microsecond,\n                d.tzinfo or dateutil.tz.tzlocal())\n\n    pydatetime.set_second_digits(second_digits)\n\n    return pydatetime", "response": "Converts a string representation of an ISO 8601 date time to a timestamp."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef string_to_uuid(value, strict=True):\n    try:\n        return None if is_undefined(value) else uuid.UUID(value)\n    except ValueError, error:\n        if strict:\n            raise error", "response": "Converts a string representation of a UUID to a Universally Unique Identifier ( UUID object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating the flask app", "response": "def create_app(debug=False):\n    \"\"\"\n    Create the flask app\n\n    :param debug: Use debug mode\n    :type debug: bool\n    :return: Created app\n    :rtype: flask.Flask\n    \"\"\"\n    app = Flask(__name__)\n    app.secret_key = str(uuid.uuid4())\n    app.json_encoder = DateTimeEncoder\n    app.register_blueprint(page)\n    Bower(app)\n    api = Api(app)\n    api.add_resource(\n        PluginListAPI,\n        api_path + \"plugins/\",\n        endpoint=\"APIPlugins\"\n    )\n    api.add_resource(\n        PluginAPI,\n        api_path + \"plugins/<plugin_key>\",\n        endpoint=\"APIPlugin\"\n    )\n    api.add_resource(\n        PluginResourceAPI,\n        api_path + \"plugins/<plugin_key>/resources/\",\n        endpoint=\"APIPluginResource\"\n    )\n\n    if debug:\n        # Setup app for real debuging mode\n        app.debug = True\n        # Force update of static files (even in dev mode, browsers still cache)\n        app.config['SEND_FILE_MAX_AGE_DEFAULT'] = 0\n\n        @app.after_request\n        def add_header(response):\n            response.headers['Cache-Control'] = \"public, max-age=0\"\n            return response\n    return app"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef plugin(plugin_key=None):\n    p = None\n    if plugin_key:\n        try:\n            p = db_plugin_instance.plugin_get(plugin_key)\n        except KeyError:\n            logger.error(u\"Plugin '{}' not found\".format(plugin_key))\n\n    return render_template(\"plugin.html\", title=\"Plugins\", plugin=p)", "response": "Serve plugin page\n ArcGIS"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if point q lies on line segment pr", "response": "def on_segment(point_p, point_q, point_r):\n    \"\"\"\n    Given three colinear points p, q, r, the function checks if point q\n    lies on line segment \"pr\"\n\n    :param point_p:\n    :type point_p: models.Point\n    :param point_q:\n    :type point_q: models.Point\n    :param point_r:\n    :type point_r: models.Point\n    :return: if point r on line segment \"pr\"\n    :rtype: bool\n    \"\"\"\n    if (point_q.x <= max(point_p.x, point_r.x)\n            and point_q.x >= min(point_p.x, point_r.x)\n            and point_q.y <= max(point_p.y, point_r.y)\n            and point_q.y >= min(point_p.y, point_r.y)):\n        return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds the orientation of the ordered triplet.", "response": "def orientation(point_p, point_q, point_r):\n    \"\"\"\n    To find orientation of ordered triplet (p, q, r).\n\n    :param point_p:\n    :type point_p: models.Point\n    :param point_q:\n    :type point_q: models.Point\n    :param point_r:\n    :type point_r: models.Point\n    :return: 0: p, q and r are colinear\n             1: clockwise\n             2: counterclockwise\n    :rtype: int\n    \"\"\"\n    # Set https://www.geeksforgeeks.org/orientation-3-ordered-points/\n    # for details of below formula.\n    r = ((point_q.y - point_p.y) * (point_r.x - point_q.x) -\n         (point_q.x - point_p.x) * (point_r.y - point_q.y))\n    if r == 0:\n        return 0\n    return 1 if r > 0 else 2"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_intersect(line_a, line_b):\n    # Find the four orientations needed for general and special cases\n    orientation_1 = orientation(line_a.endpoint_a, line_a.endpoint_b,\n                                line_b.endpoint_a)\n    orientation_2 = orientation(line_a.endpoint_a, line_a.endpoint_b,\n                                line_b.endpoint_b)\n    orientation_3 = orientation(line_b.endpoint_a, line_b.endpoint_b,\n                                line_a.endpoint_a)\n    orientation_4 = orientation(line_b.endpoint_a, line_b.endpoint_b,\n                                line_a.endpoint_b)\n\n    # General case\n    if (orientation_1 != orientation_2 and orientation_3 != orientation_4):\n        return True\n\n    # Special cases\n    if (orientation_1 == 0 and on_segment(line_a.endpoint_a, line_b.endpoint_a,\n                                          line_a.endpoint_b)):\n        return True\n    if (orientation_2 == 0 and on_segment(line_a.endpoint_a, line_b.endpoint_b,\n                                          line_a.endpoint_b)):\n        return True\n    if (orientation_3 == 0 and on_segment(line_b.endpoint_a, line_a.endpoint_a,\n                                          line_b.endpoint_b)):\n        return True\n    if (orientation_4 == 0 and on_segment(line_b.endpoint_a, line_a.endpoint_b,\n                                          line_b.endpoint_b)):\n        return True\n\n    return False", "response": "Determines if two Line objects intersect with the current Line objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns True if point is inside a region.", "response": "def is_inside(point, region):\n    \"\"\"\n    Detemine if point is in region\n\n    :param point:\n    :type point: models.Point\n    :param region:\n    :type region: Region\n    \"\"\"\n    points = region.vertices\n    extrame = models.Point(x=1000000, y=point.y)\n\n    points = points + [points[0]]\n    intersect_count = 0\n    for i in range(len(points) - 1):\n        if is_intersect(models.Line(point, extrame),\n                        models.Line(points[i], points[i+1])):\n            intersect_count += 1\n    return intersect_count % 2 == 1"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef analyze(qpi, r0, method=\"edge\", model=\"projection\", edgekw={}, imagekw={},\n            ret_center=False, ret_pha_offset=False, ret_qpi=False):\n    \"\"\"Determine refractive index and radius of a spherical object\n\n    Parameters\n    ----------\n    qpi: qpimage.QPImage\n        Quantitative phase image data\n    r0: float\n        Approximate radius of the sphere [m]\n    method: str\n        The method used to determine the refractive index\n        can either be \"edge\" (determine the radius from the\n        edge detected in the phase image) or \"image\" (perform\n        a 2D phase image fit).\n    model: str\n        The light-scattering model used by `method`. If\n        `method` is \"edge\", only \"projection\" is allowed.\n        If `method` is \"image\", `model` can be one of\n        \"mie\", \"projection\", \"rytov\", or \"rytov-sc\".\n    edgekw: dict\n        Keyword arguments for tuning the edge detection algorithm,\n        see :func:`qpsphere.edgefit.contour_canny`.\n    imagekw: dict\n        Keyword arguments for tuning the image fitting algorithm,\n        see :func:`qpsphere.imagefit.alg.match_phase`\n    ret_center: bool\n        If True, return the center coordinate of the sphere.\n    ret_pha_offset: bool\n        If True, return the phase image background offset.\n    ret_qpi: bool\n        If True, return the modeled data as a :class:`qpimage.QPImage`.\n\n    Returns\n    -------\n    n: float\n        Computed refractive index\n    r: float\n        Computed radius [m]\n    c: tuple of floats\n        Only returned if `ret_center` is True;\n        Center position of the sphere [px]\n    pha_offset: float\n        Only returned if `ret_pha_offset` is True;\n        Phase image background offset\n    qpi_sim: qpimage.QPImage\n        Only returned if `ret_qpi` is True;\n        Modeled data\n\n    Notes\n    -----\n    If `method` is \"image\", then the \"edge\" method is used\n    as a first step to estimate initial parameters for radius,\n    refractive index, and position of the sphere using `edgekw`.\n    If this behavior is not desired, please make use of the\n    method :func:`qpsphere.imagefit.analyze`.\n    \"\"\"\n    if method == \"edge\":\n        if model != \"projection\":\n            raise ValueError(\"`method='edge'` requires `model='projection'`!\")\n        n, r, c = edgefit.analyze(qpi=qpi,\n                                  r0=r0,\n                                  edgekw=edgekw,\n                                  ret_center=True,\n                                  ret_edge=False,\n                                  )\n        res = [n, r]\n        if ret_center:\n            res.append(c)\n        if ret_pha_offset:\n            res.append(0)\n        if ret_qpi:\n            qpi_sim = simulate(radius=r,\n                               sphere_index=n,\n                               medium_index=qpi[\"medium index\"],\n                               wavelength=qpi[\"wavelength\"],\n                               grid_size=qpi.shape,\n                               model=\"projection\",\n                               pixel_size=qpi[\"pixel size\"],\n                               center=c)\n            res.append(qpi_sim)\n    elif method == \"image\":\n        n0, r0, c0 = edgefit.analyze(qpi=qpi,\n                                     r0=r0,\n                                     edgekw=edgekw,\n                                     ret_center=True,\n                                     ret_edge=False,\n                                     )\n        res = imagefit.analyze(qpi=qpi,\n                               model=model,\n                               n0=n0,\n                               r0=r0,\n                               c0=c0,\n                               imagekw=imagekw,\n                               ret_center=ret_center,\n                               ret_pha_offset=ret_pha_offset,\n                               ret_qpi=ret_qpi\n                               )\n    else:\n        raise NotImplementedError(\"`method` must be 'edge' or 'image'!\")\n\n    return res", "response": "Return a list of refractive index and radius of a spherical object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef bg_phase_mask_from_sim(sim, radial_clearance=1.1):\n    # Mask values around the object\n    cx, cy = sim[\"sim center\"]\n    radius = sim[\"sim radius\"]\n    px_um = sim[\"pixel size\"]\n    x = np.arange(sim.shape[0]).reshape(-1, 1)\n    y = np.arange(sim.shape[1]).reshape(1, -1)\n    rsq = (x - cx)**2 + (y - cy)**2\n    mask = rsq > (radius/px_um * radial_clearance)**2\n    return mask", "response": "Returns the background phase mask of a qpsphere simulation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndetermine the background phase mask for a spherical phase image.", "response": "def bg_phase_mask_for_qpi(qpi, r0, method=\"edge\", model=\"projection\",\n                          edgekw={}, imagekw={}, radial_clearance=1.1):\n    \"\"\"Determine the background phase mask for a spherical phase object\n\n    The position and radius of the phase object are determined with\n    :func:`analyze`, to which the corresponding keyword arguments\n    are passed. A binary mask is created from the simulation results\n    via :func:`bg_phase_mask_from_sim`.\n\n    Parameters\n    ----------\n    qpi: qpimage.QPImage\n        Quantitative phase image data\n    r0: float\n        Approximate radius of the sphere [m]\n    method: str\n        The method used to determine the refractive index\n        can either be \"edge\" (determine the radius from the\n        edge detected in the phase image) or \"image\" (perform\n        a 2D phase image fit).\n    model: str\n        The light-scattering model used by `method`. If\n        `method` is \"edge\", only \"projection\" is allowed.\n        If `method` is \"image\", `model` can be one of\n        \"mie\", \"projection\", \"rytov\", or \"rytov-sc\".\n    edgekw: dict\n        Keyword arguments for tuning the edge detection algorithm,\n        see :func:`qpsphere.edgefit.contour_canny`.\n    imagekw: dict\n        Keyword arguments for tuning the image fitting algorithm,\n        see :func:`qpsphere.imagefit.alg.match_phase`\n    radial_clearance: float\n        Multiplicator to the fitted radius of the sphere; modifies\n        the size of the mask; set to \"1\" to use the radius determined\n        by :func:`qpsphere.analyze`.\n        The circular area containing the phase object is set to\n        `False` in the output `mask` image.\n\n    Returns\n    -------\n    mask: boolean 2d np.ndarray\n        The mask is `True` for background regions and `False` for\n        object regions.\n    \"\"\"\n    # fit sphere\n    _, _, sim = analyze(qpi=qpi,\n                        r0=r0,\n                        method=method,\n                        model=model,\n                        edgekw=edgekw,\n                        imagekw=imagekw,\n                        ret_qpi=True)\n    # determine mask\n    mask = bg_phase_mask_from_sim(sim=sim,\n                                  radial_clearance=radial_clearance)\n    return mask"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the template file", "response": "def template(filename, **locals):\n    ''' Returns '''\n    path = 'templates/{}'.format(filename)\n    with open(path) as source:\n        code = compile(source.read(), path, 'exec')\n        global_vars = {'t': t,\n                       'f': f,\n                       'e': e,\n                       'escape': html.escape,\n                       'ctime': time.ctime}\n        exec(code, global_vars, locals)\n        return locals['page']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a subtype segment to the current object.", "response": "def with_subtype(self, subtype):\n        \"\"\"Add a subtype segment\n\n        Args:\n            subtype (str): May be one of ``['a', 'c', 'r']``. See the\n                `Reference Definition <https://elections.democracyclub.org.uk/reference_definition>`_.\n                for valid election type/subtype combinations.\n\n        Returns:\n            IdBuilder\n\n        Raises:\n            ValueError\n        \"\"\"\n        self._validate_subtype(subtype)\n        self.subtype = subtype\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding an organisation segment.", "response": "def with_organisation(self, organisation):\n        \"\"\"Add an organisation segment.\n\n        Args:\n            organisation (str): Official name of an administrative body\n                holding an election.\n\n        Returns:\n            IdBuilder\n\n        Raises:\n            ValueError\n        \"\"\"\n        if organisation is None:\n            organisation = ''\n        organisation = slugify(organisation)\n        self._validate_organisation(organisation)\n        self.organisation = organisation\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef with_division(self, division):\n        if division is None:\n            division = ''\n        division = slugify(division)\n        self._validate_division(division)\n        self.division = division\n        return self", "response": "Add a division segment to the internal calendar."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the election group ID for this election group.", "response": "def election_group_id(self):\n        \"\"\"\n        str: Election Group ID\n        \"\"\"\n        self._validate()\n        # there are no additional validation checks for the top-level group id\n        parts = []\n        parts.append(self.election_type)\n        parts.append(self.date)\n        return \".\".join(parts)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef subtype_group_id(self):\n        self._validate()\n        self._validate_for_subtype_group_id()\n\n        parts = []\n        parts.append(self.election_type)\n        parts.append(self.subtype)\n        parts.append(self.date)\n        return \".\".join(parts)", "response": "str - Name of the subtype group of this entry"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the ballot ID of the current instance.", "response": "def ballot_id(self):\n        \"\"\"\n        str: Ballot ID\n        \"\"\"\n        self._validate()\n        self._validate_division(self.division)\n        self._validate_for_ballot_id()\n\n        parts = []\n        parts.append(self.election_type)\n        if self.subtype:\n            parts.append(self.subtype)\n        if self.organisation:\n            parts.append(self.organisation)\n        if self.division:\n            parts.append(self.division)\n        if self.contest_type:\n            parts.append(self.contest_type)\n        parts.append(self.date)\n        return \".\".join(parts)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ids(self):\n        ids = []\n\n        try:\n            ids.append(self.election_group_id)\n        except ValueError:\n            pass\n\n        if isinstance(self.spec.subtypes, tuple):\n            try:\n                ids.append(self.subtype_group_id)\n            except ValueError:\n                pass\n\n        if self.spec.can_have_orgs:\n            try:\n                ids.append(self.organisation_group_id)\n            except ValueError:\n                pass\n\n        try:\n            if self.ballot_id not in ids:\n                ids.append(self.ballot_id)\n        except ValueError:\n            pass\n\n        return ids", "response": "Return a list of all applicable IDs for this instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a modified environment.", "response": "def create_environment(component_config):\n    \"\"\"\n    Create a modified environment.\n\n    Arguments\n    component_config - The configuration for a component.\n    \"\"\"\n    ret = os.environ.copy()\n    for env in component_config.get_list(\"dp.env_list\"):\n        real_env = env.upper()\n        value = os.environ.get(real_env)\n        value = _prepend_env(component_config, env, value)\n        value = _append_env(component_config, env, value)\n        _apply_change(ret, real_env, value, component_config)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the contents of the treeview to show one row per surface with the corresponding alpha multiplier for each corresponding surface.", "response": "def set_surfaces(self, df_surfaces):\n        '''\n        Reset the contents of the tree view to show one row per surface, with\n        a column containing the alpha multiplier for the corresponding surface\n        (in the range [0, 1]), indexed by surface name.\n\n        For example:\n\n            | index  | alpha  |\n            |--------|--------|\n            | layer1 | 1.00   |\n            | layer2 | 0.65   |\n            | ...    | ...    |\n        '''\n        for column in self.treeview_layers.get_columns():\n            self.treeview_layers.remove_column(column)\n\n        self.df_surfaces = pd.DataFrame(df_surfaces.index.values,\n                                        columns=[df_surfaces.index.name or\n                                                 'index'],\n                                        index=df_surfaces.index)\n\n        if 'alpha' in df_surfaces:\n            self.df_surfaces['alpha'] = df_surfaces.alpha.copy()\n        else:\n            self.df_surfaces['alpha'] = 1.\n\n        self.df_py_dtypes, self.list_store = get_list_store(self.df_surfaces)\n        add_columns(self.treeview_layers, self.df_py_dtypes, self.list_store)\n\n        self._inserted_row_path = None\n\n        # Adjustment for alpha multiplier for each surface.\n        adjustment = gtk.Adjustment(1, 0, 1, .01, .1, 0)\n        column = [c for c in self.treeview_layers.get_columns()\n                  if c.get_name() == 'alpha'][0]\n        cell_renderer = column.get_cells()[0]\n        cell_renderer.set_properties(digits=2, editable=True,\n                                     adjustment=adjustment)\n        cell_renderer.connect('edited', self.on_edited, column,\n                              self.df_py_dtypes, self.list_store,\n                              self.df_surfaces)\n        set_column_format(column, self.df_py_dtypes.ix['alpha'].i,\n                          '{value:.2f}', cell_renderer=cell_renderer)\n        # Bind handlers for reordering of surface layers.\n        for k in ('inserted', 'deleted'):\n            self.list_store.connect('row-' + k, getattr(self, 'on_row_' + k))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset scale marker to alpha for selected layer.", "response": "def set_scale_alpha_from_selection(self):\n        '''\n        Set scale marker to alpha for selected layer.\n        '''\n        #  1. Look up selected layer.\n        selection = self.treeview_layers.get_selection()\n        list_store, selected_iter = selection.get_selected()\n\n        # 2. Set adjustment to current alpha value for selected layer (if any).\n        if selected_iter is None:\n            # No layer was selected, so disable scale widget.\n            self.adjustment_alpha.set_value(100)\n            self.scale_alpha.set_sensitive(False)\n            return\n        else:\n            surface_name, alpha = list_store[selected_iter]\n            self.adjustment_alpha.set_value(alpha * 100)\n            self.scale_alpha.set_sensitive(True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset alpha for selected layer.", "response": "def set_alpha_for_selection(self, alpha):\n        '''\n        Set alpha for selected layer.\n        '''\n        #  1. Look up selected layer.\n        selection = self.treeview_layers.get_selection()\n        list_store, selected_iter = selection.get_selected()\n\n        # 2. Set alpha value for layer (if selected).\n        if selected_iter is None:\n            # No layer was selected, so disable scale widget.\n            return\n        else:\n            surface_name, original_alpha = list_store[selected_iter]\n\n            self.set_alpha(surface_name, alpha)\n            self.set_scale_alpha_from_selection()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef process_data(self, block):\n        if hasattr(block, 'send_destinations') and block.send_destinations:\n            self.fire(events.FileProcessed(block))\n            self._log_in_db(block)\n            if self._sent_log_file:\n                self._log_in_sent_log(block)\n            self.log.info(\"Sent to '%s' file '%s' containing files: %s\",\n                          str(block.send_destinations),\n                          block.processed_data_file_info.basename,\n                          str([file_info.path for file_info in block.content_file_infos]))\n        else:\n            self.log.info(\"File %s wasn't sent\", block.processed_data_file_info.basename)\n        return block", "response": "process_data - Processes the data block"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn an uploaded file or None if there is no such file.", "response": "def _get_uploaded_file(session, file_info, fragment_count=0):\n        \"\"\"\n        :param session: locked session (with self._session_resource as >> session <<)\n        :param file_info: contains file information to save or query\n        :param fragment_count: amount of fragments associated to the file\n        :return: an UploadedFile associated to the file_info\n        \"\"\"\n        try:\n            return session.query(UploadedFile).filter(UploadedFile.sha1 == file_info.sha1).one()\n        except NoResultFound:\n            new_instance = UploadedFile(\n                sha1=file_info.sha1,\n                file_name=file_info.upath,\n                fragment_count=fragment_count\n            )\n            session.add(new_instance)\n            return new_instance"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlogging the contents of the block in the sent log file.", "response": "def _log_in_sent_log(self, block):\n        \"\"\" Logs:\n                block file | bfile (not encrypted) sha1 [| bfile encryption key | encrypted bfile sha1]\n                <tab>content file | cfile sha1 | part of parts [| whole file sha1]\n        \"\"\"\n        # FIXME all these should be done by the block itself\n        self._sent_log_file.write(\"\\n\")\n        sent_file_info = block.latest_file_info\n        self._sent_log_file.write(\"|\".join((sent_file_info.basename, sent_file_info.sha1)))\n        if hasattr(block, 'cipher_key'):\n            self._sent_log_file.write(\"|\")\n            self._sent_log_file.write(\"|\".join((block.cipher_key, block.ciphered_file_info.sha1)))\n        for file_info in block.content_file_infos:\n            self._sent_log_file.write(\"\\n\\t\")\n            self._sent_log_file.write(\"|\".join((file_info.path, file_info.sha1)))\n            if hasattr(file_info, 'fragment_info'):  # check if it is a fragment\n                self._sent_log_file.write(\"|\")\n                self._sent_log_file.write(\"|\".join((\n                    \"%d of %d\" % (file_info.fragment_info.fragment_num, file_info.fragment_info.fragments_count),\n                    file_info.fragment_info.file_info.sha1)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning whether or not the request should be sent to the the modules based on the filters.", "response": "def should_send(self, request):\n        \"\"\"Returns whether or not the request should be sent to the\n        modules, based on the filters.\"\"\"\n        if self.filters.get('whitelist', None):\n            return request.tree.type in self.filters['whitelist']\n        elif self.filters.get('blacklist', None):\n            return request.tree.type not in self.filters['blacklist']\n        else:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _download_one_night_of_atlas_data(\n        mjd,\n        log,\n        archivePath):\n    \"\"\"*summary of function*\n\n    **Key Arguments:**\n        - ``mjd`` -- the mjd of the night of data to download\n        - ``archivePath`` -- the path to the root of the local archive         \n    \"\"\"\n\n    # SETUP A DATABASE CONNECTION FOR THE remote database\n    global dbSettings\n\n    # SETUP ALL DATABASE CONNECTIONS\n    atlasMoversDBConn = database(\n        log=log,\n        dbSettings=dbSettings\n    ).connect()\n\n    cmd = \"rsync -avzL --include='*.dph' --include='*.meta' --include='*/' --exclude='*' dyoung@atlas-base-adm01.ifa.hawaii.edu:/atlas/red/02a/%(mjd)s %(archivePath)s/02a/\" % locals(\n    )\n\n    p = Popen(cmd, stdout=PIPE, stderr=PIPE, shell=True)\n    stdout, stderr = p.communicate()\n    if len(stderr):\n        if \"No such file or directory\" in stderr:\n            baseFolderPath = \"%(archivePath)s/02a/%(mjd)s\" % locals()\n            # Recursively create missing directories\n            if not os.path.exists(baseFolderPath):\n                os.makedirs(baseFolderPath)\n            print 'MJD %(mjd)s data: %(stderr)s' % locals()\n        else:\n            print 'error in rsyncing MJD %(mjd)s data: %(stderr)s' % locals()\n            return None\n\n    cmd = \"rsync -avzL --include='*.dph' --include='*.meta' --include='*/' --exclude='*' dyoung@atlas-base-adm01.ifa.hawaii.edu:/atlas/red/01a/%(mjd)s %(archivePath)s/01a/\" % locals(\n    )\n    p = Popen(cmd, stdout=PIPE, stderr=PIPE, shell=True)\n    stdout, stderr = p.communicate()\n    if len(stderr):\n        if \"No such file or directory\" in stderr:\n            baseFolderPath = \"%(archivePath)s/01a/%(mjd)s\" % locals()\n            # Recursively create missing directories\n            if not os.path.exists(baseFolderPath):\n                os.makedirs(baseFolderPath)\n            print 'MJD %(mjd)s data: %(stderr)s' % locals()\n        else:\n            print 'error in rsyncing MJD %(mjd)s data: %(stderr)s' % locals()\n            return None\n\n    theseFiles = recursive_directory_listing(\n        log=log,\n        baseFolderPath=\"%(archivePath)s/02a/%(mjd)s\" % locals(),\n        whatToList=\"files\"  # all | files | dirs\n    )\n    theseFiles += recursive_directory_listing(\n        log=log,\n        baseFolderPath=\"%(archivePath)s/01a/%(mjd)s\" % locals(),\n        whatToList=\"files\"  # all | files | dirs\n    )\n\n    metaFilenames = []\n    metaFilenames[:] = [(os.path.splitext(os.path.basename(m))[\n        0], m) for m in theseFiles if \"meta\" in m]\n\n    metaDict = {}\n    for m in metaFilenames:\n        metaDict[m[0]] = m[1]\n\n    sqlQuery = u\"\"\"\n            select expname from atlas_exposures where floor(mjd) = %(mjd)s \n        \"\"\" % locals()\n    rows = readquery(\n        log=log,\n        sqlQuery=sqlQuery,\n        dbConn=atlasMoversDBConn\n    )\n\n    dbExps = []\n    dbExps[:] = [r[\"expname\"]for r in rows]\n\n    missingMeta = []\n    missingMeta[:] = [m for m in metaDict.keys() if m not in dbExps]\n\n    fitskw = {\n        \"MJD-OBS\": \"mjd\",\n        \"OBJECT\": \"atlas_object_id\",\n        \"RA\": \"raDeg\",\n        \"DEC\": \"decDeg\",\n        \"FILTER\": \"filter\",\n        \"EXPTIME\": \"exp_time\",\n        \"OBSNAME\": \"expname\"\n    }\n\n    allData = []\n    for m in missingMeta:\n\n        pathToReadFile = metaDict[m]\n        try:\n            log.debug(\"attempting to open the file %s\" %\n                      (pathToReadFile,))\n            readFile = codecs.open(\n                pathToReadFile, encoding='utf-8', mode='r')\n            thisData = readFile.read()\n            readFile.close()\n        except IOError, e:\n            message = 'could not open the file %s' % (pathToReadFile,)\n            log.critical(message)\n            raise IOError(message)\n\n        fitsDict = {}\n        for l in thisData.split(\"\\n\"):\n            kw = l.split(\"=\")[0].strip()\n            if kw in fitskw.keys() and kw not in fitsDict.keys():\n                fitsDict[fitskw[kw]] = l.split(\n                    \"=\")[1].split(\"/\")[0].strip().replace(\"'\", \"\")\n\n        if len(fitsDict) == 7:\n            allData.append(fitsDict)\n\n    sqlQuery = \"\"\"\nupdate atlas_exposures set dev_flag = 1 where dev_flag = 0 and floor(mjd) in (select mjd from day_tracker where dev_flag = 1);\"\"\" % locals(\n    )\n    writequery(\n        log=log,\n        sqlQuery=sqlQuery,\n        dbConn=atlasMoversDBConn\n    )\n\n    return (allData, str(int(mjd)))", "response": "Download one night of data from the atlasMovers database."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndownloads a cache of ATLAS nights data", "response": "def get(\n            self,\n            days):\n        \"\"\"\n        *download a cache of ATLAS nights data*\n\n        **Key Arguments:**\n            - ``days`` -- the number of days data to cache locally\n\n        **Return:**\n            - None\n\n        **Usage:**\n\n            See class docstring\n        \"\"\"\n        self.log.info('starting the ``get`` method')\n\n        self._remove_processed_data()\n\n        archivePath = self.settings[\"atlas archive path\"]\n        self._update_day_tracker_table()\n        mjds = self._determine_mjds_to_download(days=days)\n\n        if len(mjds) == 0:\n            return\n\n        dbConn = self.atlasMoversDBConn\n\n        # DOWNLOAD THE DATA IN PARALLEL\n        results = fmultiprocess(log=self.log, function=_download_one_night_of_atlas_data, timeout=3600,\n                                inputArray=mjds, archivePath=archivePath)\n\n        global dbSettings\n\n        dbSettings = self.settings[\"database settings\"][\"atlasMovers\"]\n\n        for d in results:\n            if d and len(d[0]):\n                insert_list_of_dictionaries_into_database_tables(\n                    dbConn=dbConn,\n                    log=self.log,\n                    dictList=d[0],\n                    dbTableName=\"atlas_exposures\",\n                    dateModified=True,\n                    batchSize=10000,\n                    replace=True,\n                    dbSettings=dbSettings\n                )\n\n        # UPDATE BOOKKEEPING\n        mjds = []\n        mjds[:] = [r[1] for r in results if (r and r[1] is not None)]\n        mjds = (',').join(mjds)\n\n        if len(mjds):\n            sqlQuery = \"\"\"update atlas_exposures set local_data = 1 where floor(mjd) in (%(mjds)s);\n        update day_tracker set processed = 1 where mjd in (%(mjds)s);\"\"\" % locals(\n            )\n            writequery(\n                log=self.log,\n                sqlQuery=sqlQuery,\n                dbConn=self.atlasMoversDBConn,\n            )\n\n        bk = bookkeeper(\n            log=self.log,\n            settings=self.settings,\n            fullUpdate=False\n        )\n        bk.clean_all()\n\n        self.log.info('completed the ``get`` method')\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _remove_processed_data(\n            self):\n        \"\"\"*remove processed data*\n        \"\"\"\n        self.log.info('starting the ``_remove_processed_data`` method')\n\n        archivePath = self.settings[\"atlas archive path\"]\n\n        from fundamentals.mysql import readquery\n        sqlQuery = u\"\"\"\n            select mjd from (SELECT DISTINCT\n    FLOOR(mjd) as mjd\nFROM\n    atlas_exposures\nWHERE\n    local_data = 1 AND dophot_match > 0) as a\n        where mjd NOT IN (SELECT \n            *\n        FROM\n            (SELECT DISTINCT\n                FLOOR(mjd)\n            FROM\n                atlas_exposures\n            WHERE\n                local_data = 1 AND dophot_match = 0) AS a);\n        \"\"\" % locals()\n        mjds = readquery(\n            log=self.log,\n            sqlQuery=sqlQuery,\n            dbConn=self.atlasMoversDBConn\n        )\n\n        if not len(mjds):\n            return None\n\n        oldMjds = []\n        oldMjds[:] = [str(int(o[\"mjd\"])) for o in mjds]\n\n        for m in oldMjds:\n            for i in [\"01a\", \"02a\"]:\n                datapath = archivePath + \"/%(i)s/%(m)s\" % locals()\n                # shutil.rmtree(datapath)\n                try:\n                    shutil.rmtree(datapath)\n                except:\n                    self.log.warning(\n                        \"The path %(datapath)s does not exist - no need to delete\" % locals())\n\n        mjdString = (',').join(oldMjds)\n\n        sqlQuery = \"\"\"\nupdate day_tracker set local_data = 0 where floor(mjd) in (%(mjdString)s);\nupdate  atlas_exposures set local_data = 0 where floor(mjd) in (%(mjdString)s) and dophot_match != 0;\"\"\" % locals(\n        )\n        print sqlQuery\n        writequery(\n            log=self.log,\n            sqlQuery=sqlQuery,\n            dbConn=self.atlasMoversDBConn\n        )\n\n        self.log.info('completed the ``_remove_processed_data`` method')\n        return None", "response": "remove processed data from the atlas archive"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _update_day_tracker_table(\n            self):\n        \"\"\"* update day tracker table*\n\n        **Key Arguments:**\n            # -\n\n        **Return:**\n            - None\n\n        **Usage:**\n            ..  todo::\n\n                - add usage info\n                - create a sublime snippet for usage\n                - write a command-line tool for this method\n                - update package tutorial with command-line tool info if needed\n\n            .. code-block:: python \n\n                usage code \n\n        \"\"\"\n        self.log.info('starting the ``_update_day_tracker_table`` method')\n\n        # YESTERDAY MJD\n        mjd = now(\n            log=self.log\n        ).get_mjd()\n        yesterday = int(math.floor(mjd - 1))\n\n        sqlQuery = u\"\"\"\n            SELECT mjd FROM atlas_moving_objects.day_tracker order by mjd desc limit 1\n        \"\"\" % locals()\n        rows = readquery(\n            log=self.log,\n            sqlQuery=sqlQuery,\n            dbConn=self.atlasMoversDBConn,\n        )\n        highestMjd = int(rows[0][\"mjd\"])\n\n        converter = conversions(\n            log=self.log\n        )\n\n        sqlData = []\n        for m in range(highestMjd, yesterday):\n            # CONVERTER TO CONVERT MJD TO DATE\n            utDate = converter.mjd_to_ut_datetime(\n                mjd=m,\n                sqlDate=True,\n                datetimeObject=False\n            )\n            sqlData.append({\n                \"mjd\": m,\n                \"ut_date\": utDate\n            })\n\n        insert_list_of_dictionaries_into_database_tables(\n            dbConn=self.atlasMoversDBConn,\n            log=self.log,\n            dictList=sqlData,\n            dbTableName=\"day_tracker\",\n            uniqueKeyList=[\"mjd\"],\n            dateModified=False,\n            batchSize=10000,\n            replace=True\n        )\n\n        self.atlasMoversDBConn.commit()\n\n        self.log.info('completed the ``_update_day_tracker_table`` method')\n        return None", "response": "update the day tracker table"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_recipe_detail(recipe_url):\n    response = requests.get(recipe_url, headers=get_header())\n    html = BeautifulSoup(response.text, 'lxml')\n\n    # \u83b7\u53d6\u83dc\u540d\n    name = html.find(\"div\", {\"class\": \"re-up\"}).h1.text\n\n    # \u4e3b\u56fe\n    img = html.find(\"div\", {\"class\": \"gallery\"}).a['href']\n    img = urljoin(HOME_URL, img)\n\n    all_info = html.find_all(\"div\", {\"class\": \"dd\"})\n\n    if len(all_info) == 4:\n        # \u7b80\u4ecb\n        intro = re.sub('\\n|\\t|\\r| ', '', all_info[0].text)\n        material_i = 1\n        method_i = 2\n    else:\n        intro = None\n        material_i = 0\n        method_i = 1\n\n    # \u98df\u6750\n    material = all_info[material_i].text.strip()\n    material = re.sub('\\r\\n|\\r\\n \\n|\\n\\n\\n', '\\n', material)\n\n    # \u505a\u6cd5\n    try:\n        method_steps = html.find(\"ol\", {\"class\": \"re-step-wpic\"}).find_all('li')\n        method = []\n        for i, m in enumerate(method_steps, 1):\n            step = dict(step_num=i)\n            step['text'] = m.text.strip()\n            if m.img:\n                step['img_url'] = urljoin(HOME_URL, m.img['src'])\n            method.append(step)\n    except:\n        method = all_info[method_i].text.strip()\n        method = re.sub('\\r\\n|\\r\\n \\n|\\n\\n\\n\\n', '\\n', method)\n\n    # \u76f8\u5173\u83dc\u54c1\n    classify = all_info[-1].text.strip()\n    if '\\xa0\\xa0' in classify:\n        classify = classify.replace('\\xa0\\xa0', ' | ')\n    else:\n        classify = \"\"\n\n    return {\n        \"name\": name,\n        \"url\": recipe_url,\n        \"img\": img,\n        \"intro\": intro,\n        \"material\": material,\n        \"method\": method,\n        \"classify\": classify\n    }", "response": "Get the detail of a recipe."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_class_recipes(class_url, max_page=20, sleep=0.1):\n    class_url = class_url + \"?page={page}\"\n    recipes = dict()\n\n    # \u66b4\u529b\u722c\u53d6\u65b9\u6848\uff0c\u6bcf\u4e2a\u83dc\u8c31\u5206\u7c7b\u8bf7\u6c42100\u9875\n    for page in range(1, max_page):\n        time.sleep(sleep)\n        url = class_url.format(page=page)\n        print(\"current url: \", url)\n        response = requests.get(url, headers=get_header())\n        html = BeautifulSoup(response.text, \"lxml\")\n\n        # \u83b7\u53d6\u672c\u9875\u83dc\u8c31\n        menus = html.find(\"div\", {'class': 'new-menu-list search-menu-list clearfix mt10'})\n        if menus:\n            print(\"get recipes fail: \", url)\n            menus = menus.find_all('a')\n            for m in menus:\n                name = re.sub(\"\\n| \", \"\", m.text)\n                recipe_url = urljoin(HOME_URL, m['href'])\n                recipes[name] = recipe_url\n\n        # \u5224\u65ad\u662f\u5426\u662f\u6700\u540e\u4e00\u9875\n        # next_page = html.find('div', {'class': 'paging mt20'}).text\n        # if \"\u4e0b\u4e00\u9875\" in next_page:\n        #     page += 1\n        # else:\n        #     break\n    return recipes", "response": "get recipes from class url"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a river by name.", "response": "def get(args):\n    \"\"\"\n    Get a river by name.\n    \"\"\"\n    m = RiverManager(args.hosts)\n    r = m.get(args.name)\n    if r:\n        print(json.dumps(r, indent=2))\n    else:\n        sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a river. This command expects to be fed a JSON document on STDIN.", "response": "def create(args):\n    \"\"\"\n    Create a river. This command expects to be fed a JSON document on STDIN.\n    \"\"\"\n    data = json.load(sys.stdin)\n    m = RiverManager(args.hosts)\n    m.create(args.name, data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndelete a river by name", "response": "def delete(args):\n    \"\"\"\n    Delete a river by name\n    \"\"\"\n    m = RiverManager(args.hosts)\n    m.delete(args.name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compare(args):\n    data = json.load(sys.stdin)\n    m = RiverManager(args.hosts)\n    if m.compare(args.name, data):\n        sys.exit(0)\n    else:\n        sys.exit(1)", "response": "Compare the extant river with the given name to the passed JSON."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfit refractive index and radius to a phase image of a single sphere.", "response": "def analyze(qpi, model, n0, r0, c0=None, imagekw={},\n            ret_center=False, ret_pha_offset=False, ret_qpi=False):\n    \"\"\"Fit refractive index and radius to a phase image of a sphere\n\n    Parameters\n    ----------\n    qpi: QPImage\n        Quantitative phase image information\n    model: str\n        Name of the light-scattering model\n        (see :const:`qpsphere.models.available`)\n    n0: float\n        Approximate refractive index of the sphere\n    r0: float\n        Approximate radius of the sphere [m]\n    c0: tuple of (float, float)\n        Approximate center position in ndarray index coordinates [px];\n        if set to `None` (default), the center of the image is used.\n    imagekw: dict\n        Additional keyword arguments to\n        :func:`qpsphere.imagefit.alg.match_phase`.\n    ret_center: bool\n        Return the center coordinate of the sphere\n    ret_pha_offset: bool\n        If True, return the phase image background offset.\n    ret_qpi: bool\n        If True, return the modeled data as a :class:`qpimage.QPImage`.\n\n    Returns\n    -------\n    n: float\n        Computed refractive index\n    r: float\n        Computed radius [m]\n    c: tuple of floats\n        Only returned if `ret_center` is True\n        Center position of the sphere [px]\n    pha_offset: float\n        Only returned if `ret_pha_offset` is True\n        Phase image background offset\n    qpi_sim: qpimage.QPImage\n        Only returned if `ret_qpi` is True\n        Modeled data\n    \"\"\"\n    res = match_phase(qpi, model=model, n0=n0, r0=r0, c0=c0,\n                      ret_center=ret_center,\n                      ret_pha_offset=ret_pha_offset,\n                      ret_qpi=ret_qpi,\n                      **imagekw)\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove temporary build folders", "response": "def rm_tempdirs():\n  ''' Remove temporary build folders '''\n  tempdirs = [Dir.BUILD, Dir.COCOA_BUILD, Dir.LIB]\n  for tempdir in tempdirs:\n    if os.path.exists(tempdir):\n      shutil.rmtree(tempdir, ignore_errors=True)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef lib_list():\n  ''' Returns the contents of 'pyglass/lib' as a list of 'lib/*' items for package_data '''\n  lib_list = []\n  for (root, dirs, files) in os.walk(Dir.LIB):\n    for filename in files:\n      root = root.replace('pyglass/', '')\n      lib_list.append(join(root, filename))\n  return lib_list", "response": "Returns the contents of pyglass. lib as a list of lib items for package_data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreformats the user provided pattern to generate a new regular expression.", "response": "def reformat_pattern(pattern, compile=False):\n    '''\n    Apply the filters on user pattern to generate a new regular expression\n    pattern.\n    A user provided variable, should start with an alphabet, can be\n    alphanumeric and can have _.\n    '''\n    # User pattern: (w:<name>)  --> Changes to (?P<name>\\w)\n    rex_pattern = re.sub(r'\\(w:<([\\w\\d_]+)>\\)', '(?P<\\\\1>\\w+)', pattern)\n\n    # User pattern: (d:<name>)  --> change to (?P<name>\\d)\n    rex_pattern = re.sub(r'\\(d:<([\\w\\d_]+)>\\)', '(?P<\\\\1>\\d+)', rex_pattern)\n\n    # User pattern: (W:<name>)  --> change to (?P<name>\\w)\n    rex_pattern = re.sub(r'\\(W:<([\\w\\d_]+)>\\)', '(?P<\\\\1>\\W+)', rex_pattern)\n\n    # User pattern: (any:<anyvalue> --> change to (?P<anyvalue>.*)\n    rex_pattern = re.sub(r'\\(any:<([\\w\\d_]+)>\\)', '(?P<\\\\1>.*)', rex_pattern)\n\n    # User pattern: (ip:<ipaddr>) --> Change to (?P<ipaddr>\\d+\\.\\d+\\.\\d+\\.\\d+)\n    rex_pattern = re.sub(r'\\(ip:<([\\w\\d_]+)>\\)',\n                         '(?P<\\\\1>\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})',\n                         rex_pattern)\n\n    # User pattern: (mac:<macaddr>) --> Change to (?P<mac>\\w\\w:\\w\\w:\\w\\w:..)\n    rex_pattern = re.sub(r'\\(mac:<([\\w\\d_]+)>\\)',\n                         '(?P<\\\\1>\\w\\w:\\w\\w:\\w\\w:\\w\\w:\\w\\w:\\w\\w)', rex_pattern)\n\n    # User pattern: (decimal:<name>) --> Change to (?P<name>\\d*\\.\\d+|\\d+)\n    rex_pattern = re.sub(r'\\(decimal:<([\\w\\d_]+)>\\)',\n                         '(?P<\\\\1>\\d*\\.\\d+|\\d+)', rex_pattern)\n\n    # User pattern: (measurement:<name> --> change to \\\n    # (?P<name>\\d*\\.\\d+|\\d+)(\\w+|\\w+/\\w+)\n    rex_pattern = re.sub(r'\\(measurement:<([\\w\\d_]+)>\\)',\n                         '(?P<\\\\1>\\d*\\.\\d+|\\d+)(?P<\\\\1_unit>\\w+|\\w+/\\w+)',\n                         rex_pattern)\n\n\n    ######################################\n    # Timestamp patterns.\n    # User pattern: (ts[n]:<timestamp>) -->\n    # Converted to: The below options.\n    ######################################\n\n    # User pattern: (ts1:<timestamp>)\n    # Keystone, nova, libvirt, cinder\n    # Example: 2015-11-13 06:38:04.571\n    rex_pattern = re.sub(\n        r'\\(ts1:<([\\w\\d_]+)>\\)',\n        '(?P<\\\\1>(\\d{4})-(\\d{1,2})-(\\d{1,2}) (\\d+):(\\d+):(\\d+)\\.(\\d+))',\n        rex_pattern)\n\n    # User pattern: (ts2:<timestamp>)\n    # contrail\n    # Example: 2015-11-13 Fri 13:14:51:907.395 PST\n    rex_pattern = re.sub(\n        r'\\(ts2:<([\\w\\d_]+)>\\)',\n        '(?P<\\\\1>(\\d{4})-(\\d{1,2})-(\\d{1,2}) (\\w{3}) (\\d+):(\\d+):(\\d+):(\\d+)\\.(\\d+))',\n        rex_pattern)\n\n    # User pattern: (ts3:<timestamp>)\n    # apache2\n    # Example: Thu Aug 20 14:18:34 2015\n    rex_pattern = re.sub(\n        r'\\(ts3:<([\\w\\d_]+)>\\)',\n        '(?P<\\\\1>(\\w{3}) (\\w{3}) (\\d{1,2}) (\\d+):(\\d+):(\\d+) (\\d{4}))',\n        rex_pattern)\n\n    # User pattern: (ts4:<timestamp>)\n    # Example: 02/Nov/2015:09:03:19 -0800\n    rex_pattern = re.sub(\n        r'\\(ts4:<([\\w\\d_]+)>\\)',\n        '(?P<\\\\1>(\\d+)\\/(\\w{3})\\/(\\d{4}):(\\d+):(\\d+):(\\d+) -(\\d+))',\n        rex_pattern)\n\n    # User pattern: (ts5:<timestamp>)\n    # ceph logs.\n    # Example: 2015-11-13 06:25:29.436844\n    rex_pattern = re.sub(\n        r'\\(ts5:<([\\w\\d_]+)>\\)',\n        '(?P<\\\\1>(\\d{4})-(\\d{1,2})-(\\d{1,2}) (\\d+):(\\d+):(\\d+)\\.(\\d+))',\n        rex_pattern)\n\n    # User pattern: (ts6:<timestamp>)\n    # cassandra\n    # Example:2015-10-23 12:38:15\n    rex_pattern = re.sub(\n        r'\\(ts6:<([\\w\\d_]+)>\\)',\n        '(?P<\\\\1>(\\d{4})-(\\d{1,2})-(\\d{1,2}) (\\d+):(\\d+):(\\d+))',\n        rex_pattern)\n\n    # User pattern: (ts7:<timestamp>)\n    # haproxy\n    # Example: 13/Nov/2015:06:25:05.465\n    rex_pattern = re.sub(\n        r'\\(ts7:<([\\w\\d_]+)>\\)',\n        '(?P<\\\\1>(\\d+)\\/(\\w{3})\\/(\\d{4}):(\\d+):(\\d+):(\\d+)\\.(\\d+))',\n        rex_pattern)\n\n    # User pattern: (ts8:<timestamp>)\n    # mysql\n    # Example: 12:03:28\n    rex_pattern = re.sub(\n        r'\\(ts8:<([\\w\\d_]+)>\\)',\n        '(?P<\\\\1>(\\d+):(\\d+):(\\d+))',\n        rex_pattern)\n\n    # User pattern: (ts9:<timestamp>)\n    # reddis\n    # Example: 08 Nov 06:26:05.084\n    rex_pattern = re.sub(\n        r'\\(ts9:<([\\w\\d_]+)>\\)',\n        '(?P<\\\\1>(\\d+) (\\w{3}) (\\d+):(\\d+):(\\d+)\\.(\\d+))',\n        rex_pattern)\n\n    # user pattern: (ts10:<timestamp>)\n    # supervisord, zookeeper\n    # Example: 2015-06-30 10:59:18,133\n    rex_pattern = re.sub(\n        r'\\(ts10:<([\\w\\d_]+)>\\)',\n        '(?P<\\\\1>(\\d{4})-(\\d{1,2})-(\\d{1,2}) (\\d+):(\\d+):(\\d+),(\\d+))',\n        rex_pattern)\n\n    # User pattern: (ts11:<timestamp>)\n    # dmesg\n    # Example: 11148214.574583\n    rex_pattern = re.sub(\n        r'\\(ts11:<([\\w\\d_]+)>\\)',\n        '(?P<\\\\1>(\\d+)\\.(\\d+))',\n        rex_pattern)\n\n    # Finally if no prefix is specified take default action.\n    rex_pattern = re.sub(r'\\(<([\\w\\d_]+)>\\)', '(?P<\\\\1>.*)', rex_pattern)\n\n    if compile:\n        return re.compile(rex_pattern)\n\n    return rex_pattern"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmatch a pattern in a string", "response": "def match_string(pattern, search_string):\n    '''\n    Match a pattern in a string\n    '''\n\n    rexobj = REX(pattern, None)\n\n    rexpatstr = reformat_pattern(pattern)\n    #print \"rexpatstr: \", rexpatstr\n\n    rexpat = re.compile(rexpatstr)\n    rexobj.rex_patternstr = rexpatstr\n    rexobj.rex_pattern = rexpat\n\n    line_count = 1\n    for line in search_string.splitlines():\n        line = line.strip()\n        mobj = rexpat.match(line)\n        if mobj:\n            populate_resobj(rexobj, mobj, line_count)\n        line_count += 1\n\n    return rexobj"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npopulating the result object with the given match object and location.", "response": "def populate_resobj(rexobj, mobj, loc):\n    '''\n    Popuate the result object and append it to the\n    rexobj results.\n    '''\n    resobj = REXResult(mobj, loc)\n    rexobj.matches.append(resobj)\n    rexobj.res_count += 1"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_lrvalue_string(search_string,\n                         delimiter=\":\"):\n    '''\n    The function takes a multi-line output/string with the format\n    \"name/descr   : value\", and converts it to a dictionary object\n    with key value pairs, where key is built from the name/desc\n    part and value as the value.\n\n    eg:  \"Serial Number: FCH1724V1GT\" will be translated to\n    dict['serial_number'] = \"FCH1724V1GT\"\n    '''\n    mac_search_pattern = r\"(.*) *%s ([\\w|\\d]+.*)\" % delimiter\n    search_pattern = r\"(.*) *%s *(.*)\" % delimiter\n\n    rexdict = {}\n    for line in search_string.splitlines():\n        line = line.strip()\n        mobj = re.match(mac_search_pattern, line)\n        if mobj:\n            key = mobj.group(1).lower()\n            key = \"_\".join(key.split()[0:3])\n            key = key.strip()\n            rexdict[key] = mobj.group(2)\n            continue\n\n        mobj = re.match(search_pattern, line)\n        if mobj:\n            key = mobj.group(1).lower()\n            key = \"_\".join(key.split()[0:3])\n            key = key.strip()\n            rexdict[key] = mobj.group(2)\n\n    return rexdict", "response": "This function parses a multi - line output string with the format\n    name / descr   : value and returns a dictionary with key value pairs."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_multi_lrvalue_string(search_string, split_string,\n                               delimiter=\":\"):\n    '''\n    The function is an extension of the parse_lrvalue_string() API.\n    The function takes a multi-line output/string of the format\n    \"Category: xyz\n       name: foo\n       id: bar\n     Category: abc\n       name: foox\n       id: barx\n    :\n    \"\n    It splits the output based on the splitstring passed as\n    argument (eg \"Category\"), and converts the individual\n    lines of the form \"name:  value\" to a dictionary object with\n    key value pairs. The key is built from the name (LV) part.\n    eg \"First Name: Behzad\" --> dict[first_name] = \"Behzad\"\n    '''\n    dictlist = []\n    for out in search_string.split(split_string):\n        tdict = parse_lrvalue_string(split_string + out,\n                                     delimiter=delimiter)\n        dictlist.append(tdict)\n\n    return dictlist", "response": "This function parses a multi - line string of the format xyz\n       name barx\n     Category and id of a single - line object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive a string in a tabular format parse it and return a dictionary containing the a articles.", "response": "def parse_tabular_string(search_string,\n                         header_keys,\n                         delimiter=None,\n                         merge_list=None):\n    '''\n    Given a string in a tabular format, parse it and return a\n    dictionary\n    @args:\n        search_string: This is a string in tabular format (e.g.: output of df\n        command)\n        header_keys: This is a list of strings for the headers.\n        delimiter(optional): Default is None, which translates to spaces\n        merge_list(optional): In some cases 2 fields need to be merged as they\n        are one value.\n    '''\n    first_line = True\n    parsed_results = []\n    for line in search_string.splitlines():\n        if first_line:\n            first_line = False\n        else:\n            result = {}\n            row = line.split()\n            if merge_list:\n                for mergeset in merge_list:\n                    fidx = mergeset[0]\n                    lidx = mergeset[1]\n                    try:\n                        row[fidx] = \"_\".join(row[fidx:(lidx+1)])\n                        row.remove(row[lidx])\n                    except IndexError:\n                        pass\n\n            if len(row) != len(header_keys):\n                print \"Incorrect fields len \"\n                continue\n            key_count = 0\n            for column in row:\n                result[header_keys[key_count]] = column\n                key_count += 1\n            parsed_results.append(result)\n\n    return parsed_results"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprints all the results of rexobj.", "response": "def dump_rexobj_results(rexobj, options=None):\n    '''\n    print all the results.\n    '''\n    print(\"-\" * 60)\n    print(\"Match count: \", rexobj.res_count)\n    matches = rexobj.matches\n    for match in matches:\n        print(\"Loc:\", match.loc, \":: \")\n        for key in match.named_groups.keys():\n            print(\"%s: %s\" %\n                  (key, match.named_groups[key]))\n        print(\"\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a matched value for the key for a specific match from the results.", "response": "def get_match_value(rexobj, key, index=0):\n    '''\n    Return a matched value for the key for a specific match from the\n    results.\n    '''\n    if rexobj is None:\n        return None\n\n    if rexobj.res_count == 0:\n        return None\n\n    try:\n        return rexobj.matches[index].named_groups[key]\n    except IndexError:\n        return None\n    except KeyError:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save_resource(plugin_name, resource_name, resource_data):\n    path = os.path.join(resource_dir_path, plugin_name)\n    if not os.path.exists(path):\n        os.makedirs(path)\n    path = os.path.join(path, resource_name)\n    logger.debug(\"Saving {}\".format(path))\n    with open(path, 'wb') as f:\n        f.write(base64.b64decode(resource_data))", "response": "Save a resource in local cache"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nkill one or many workers.", "response": "def kill(self, nb = 1):\n        \"\"\"\n        Kill one or many workers.\n        \"\"\"\n        self.count_lock.acquire()\n        if nb > self.shared['workers']:\n            nb = self.shared['workers']\n        self.count_lock.release()\n        for x in xrange(nb):\n            self.tasks.put_nowait(WorkerExit)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_max_workers(self, nb):\n        self.count_lock.acquire()\n        self.shared['max_workers'] = nb\n        if self.shared['workers'] > self.shared['max_workers']:\n            self.kill(self.shared['workers'] - self.shared['max_workers'])\n        self.count_lock.release()", "response": "Set the maximum number of workers to create."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add(self, nb = 1, name = None):\n        for x in xrange(nb):\n            self.count_lock.acquire()\n            self.shared['workers'] += 1\n            xid = self.shared['workers']\n            self.kill_event.clear()\n            self.count_lock.release()\n            w   = WorkerProc(xid, self.queue, self.shared, self.tasks, self.life_time, self.count_lock, self.kill_event)\n            w.name = self.get_name(xid, name)\n            w.start()", "response": "Create one or many workers."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef put(self, target, callback = None, name = None, *args, **kargs):\n        self.count_lock.acquire()\n        if not self.shared['workers']:\n            self.add(name = name)\n        self.count_lock.release()\n        self.queue.put_nowait((target, callback, name, args, kargs))", "response": "Put a task into the queue."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef killall(self, wait = None):\n        self.queue.close()\n        self.count_lock.acquire()\n        self.kill(self.shared['workers'])\n        self.count_lock.release()\n        self.tasks.close()\n        self.terminate()\n        self.kill_event.wait(wait)", "response": "Kill all active workers."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef expand_items(form_values, sep='.'):\n    '''\n    Parameters\n    ----------\n    form_values : list\n        List of ``(key, value)`` tuples, where ``key`` corresponds to the\n        ancestor keys of the respective value joined by ``'.'``.  For example,\n        the key ``'a.b.c'`` would be expanded to the dictionary\n        ``{'a': {'b': {'c': 'foo'}}}``.\n\n    Returns\n    -------\n    dict\n        Nested dictionary, where levels are inferred from each key by splitting\n        on ``'.'``.\n    '''\n    output = {}\n    for keys_str_i, value_i in form_values:\n        keys_i = keys_str_i.split(sep)\n        parents_i = keys_i[:-1]\n        fieldname_i = keys_i[-1]\n\n        dict_j = output\n        for key_j in parents_i:\n            dict_j = dict_j.setdefault(key_j,  {})\n        dict_j[fieldname_i] = value_i\n    return output", "response": "Expand items in a nested dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nflattens a nested dictionary into a list of tuples.", "response": "def flatten_dict(root, parents=None, sep='.'):\n    '''\n    Args:\n\n        root (dict) : Nested dictionary (e.g., JSON object).\n        parents (list) : List of ancestor keys.\n\n    Returns\n    -------\n    list\n        List of ``(key, value)`` tuples, where ``key`` corresponds to the\n        ancestor keys of the respective value joined by ``'.'``.  For example,\n        for the item in the dictionary ``{'a': {'b': {'c': 'foo'}}}``, the\n        joined key would be ``'a.b.c'``.\n\n    See also :func:`expand_items`.\n    '''\n    if parents is None:\n        parents = []\n\n    result = []\n    for i, (k, v) in enumerate(root.iteritems()):\n        parents_i = parents + [k]\n        key_i = sep.join(parents_i)\n        if isinstance(v, dict):\n            value_i = flatten_dict(v, parents=parents_i, sep=sep)\n            result.extend(value_i)\n        else:\n            value_i = v\n            result.append((key_i, value_i))\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a DataFrame containing the fields of the object.", "response": "def get_fields_frame(schema):\n    '''\n    Parameters\n    ----------\n    schema : dict\n        `JSON schema <http://spacetelescope.github.io/understanding-json-schema/>`_\n    '''\n    fields = []\n\n    def get_field_record(i, key, value, parents):\n        if value.get('private') or 'default' not in value:\n            raise Skip\n        field = (len(parents) - 1, i, tuple(parents[:-1]), parents[-1],\n                 value['type'], value['default'])\n        return fields.append(field)\n\n    # Fill fields list.\n    get_types(schema['properties'], get_field_record)\n\n    # Order by level, then explicit index.\n    df_fields = pd.DataFrame(sorted(fields), columns=['level_i', 'field_i',\n                                                      'parents', 'field',\n                                                      'field_type', 'default'])\n\n    df_fields['attributes'] = df_fields.apply(lambda row:\n                                              get_nested_item(row, schema\n                                                              ['properties'],\n                                                              row.parents +\n                                                              (row.field, )),\n                                              axis=1)\n    return df_fields"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef schema_dialog(schema, data=None, device_name=None, max_width=None,\n                  max_fps=None, **kwargs):\n    '''\n    Parameters\n    ----------\n    schema : dict\n        jsonschema definition.  Each property *must* have a default value.\n    device_name : False or None or str or list_like, optional\n        GStreamer video source device name(s).\n\n        If `None` (default), first available video device is used.\n\n        If `False`, video is disabled.\n    max_width : int\n        Maximum video frame width.\n    max_fps : float\n        Maximum video frame rate (frames/second).\n\n    Returns\n    -------\n    dict\n        json-encodable dictionary containing validated values for properties\n        included in the specified schema.\n\n    Raises\n    ------\n    KeyError\n        If no video configuration is found that matches the specified\n        parameters.\n    ValueError\n        If values to not validate.\n    '''\n    # TODO Remove pygst code (or at least gracefully handle case where it is\n    # not available).\n    if not device_name and device_name is not None:\n        dialog = SchemaDialog(schema, **kwargs)\n    else:\n        with nostderr():\n            import pygst_utils as pu\n\n        gtk.threads_init()\n        df_modes = pu.get_available_video_source_configs()\n        query = (df_modes.width == df_modes.width)\n        if device_name is not None:\n            if isinstance(device_name, types.StringTypes):\n                query &= (df_modes.device_name == device_name)\n            else:\n                query &= (df_modes.device_name.isin(device_name))\n        if max_width is not None:\n            query &= (df_modes.width <= max_width)\n        if max_fps is not None:\n            query &= (df_modes.framerate <= max_fps)\n        df_modes = df_modes.loc[query]\n        if not df_modes.shape[0]:\n            raise KeyError('No compatible video mode found.')\n        config = df_modes.sort_values(['width', 'framerate'],\n                                      ascending=False).iloc[0]\n        pipeline_command = pu.pipeline_command_from_json(config,\n                                                         colorspace='rgb')\n        dialog = MetaDataDialog(schema, pipeline_command, **kwargs)\n    with nostderr():\n        valid, results = dialog.run(values=data)\n    if not valid:\n        raise ValueError('Invalid values.')\n    return results", "response": "Create a new window with a schema."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _capture_stdout(callable: Callable[..., CaptureResult], *args, **kwargs) -> CaptureResult:\n        stream = StringIO()\n        with redirect_stdout(stream):\n            return_value = callable(*args, **kwargs)\n        assert return_value.stdout is None, \"stdout appears to have already been captured\"\n        return CaptureResult(return_value=return_value.return_value, stdout=stream.getvalue(),\n                             stderr=return_value.stderr, exception=return_value.exception)", "response": "Wrap the given callable to capture the stdout."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrap a callable to capture the output of the standard error.", "response": "def _capture_stderr(callable: Callable[..., CaptureResult], *args, **kwargs) -> CaptureResult:\n        \"\"\"\n        Captures content written to standard error.\n        :param callable: the callable to wrap\n        :param args: positional arguments passed to the callable\n        :param kwargs: keyword arguments passed to the callable\n        :return: the captured result\n        \"\"\"\n        stream = StringIO()\n        with redirect_stderr(stream):\n            return_value = callable(*args, **kwargs)\n        assert return_value.stderr is None, \"stderr appears to have already been captured\"\n        return CaptureResult(return_value=return_value.return_value, stdout=return_value.stdout,\n                             stderr=stream.getvalue(), exception=return_value.exception)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _capture_exceptions(callable: Callable[..., CaptureResult], *args, **kwargs) -> CaptureResult:\n        try:\n            return_value = callable(*args, **kwargs)\n            assert return_value.exception is None, \"exception appears to have already been captured\"\n            return CaptureResult(return_value=return_value.return_value, stdout=return_value.stdout,\n                                 stderr=return_value.stderr)\n        except BaseException as e:\n            return CaptureResult(exception=e)", "response": "A wrapper for the capture_exceptions method that wraps the exception and returns a CaptureResult object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _create_capture_exceptions(capture_decider: Callable[[BaseException], bool]) -> Callable:\n        def wrapped(*args, **kwargs):\n            result = CaptureWrapBuilder._capture_exceptions(*args, **kwargs)\n            if result.exception is not None:\n                if not capture_decider(result.exception):\n                    raise result.exception\n            return result\n\n        return wrapped", "response": "Creates exception capturer using given capture decider."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwraps the given method in the given wrapper passing through the callable s arguments to the wrapper.", "response": "def _wrap(method: Callable, wrapper: Callable) -> Callable:\n        \"\"\"\n        Wraps the given callable method in the given wrapper, passing through the callable's arguments to the wrapper.\n        :param method: the callable method to wrap\n        :param wrapper: the wrapper to wrap callable with\n        :return:\n        \"\"\"\n        def wrapped(*args, **kwargs):\n            return wrapper(method, *args, **kwargs)\n        return wrapped"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding a method that captures the required information when the given callable is called.", "response": "def build(self, callable: Callable) -> Callable[..., CaptureResult]:\n        \"\"\"\n        Build a method that captures the required information when the given callable is called.\n        :param callable: the callable to capture information from\n        :return: the wrapped callable\n        \"\"\"\n        def capturing_callable(*args, **kwargs) -> CaptureResult:\n            return CaptureResult(return_value=callable(*args, **kwargs))\n\n        if self.capture_exceptions:\n            # Need to capture exceptions first else other (non-return) captured information will be lost\n            exceptions_wrapper = CaptureWrapBuilder._create_capture_exceptions(self.capture_exceptions)\n            capturing_callable = CaptureWrapBuilder._wrap(capturing_callable, exceptions_wrapper)\n        if self.capture_stdout:\n            capturing_callable = CaptureWrapBuilder._wrap(capturing_callable, CaptureWrapBuilder._capture_stdout)\n        if self.capture_stderr:\n            capturing_callable = CaptureWrapBuilder._wrap(capturing_callable, CaptureWrapBuilder._capture_stderr)\n\n        return capturing_callable"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts environment variables to bytes not unicode on Windows.", "response": "def __convert_env(env, encoding):\n    \"\"\"Environment variables should be bytes not unicode on Windows.\"\"\"\n    d = dict(os.environ, **(oget(env, {})))\n\n    # workaround for Windows+Python3 environment\n    if not SHOULD_NOT_ENCODE_ARGS:\n        return dict((k.encode(encoding), v.encode(encoding)) for k, v in d.items())\n    else:\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexecuting external command :param args: command line arguments : [unicode] :param shell: True when using shell : boolean :param cwd: working directory : string :param env: environment variables : dict :param stdin: standard input :param stdout: standard output :param stderr: standard error :param cmd_encoding: command line encoding: string :return: return code", "response": "def execute_command(args, shell=False, cwd=None, env=None, stdin=None, stdout=None, stderr=None, cmd_encoding='utf-8'):\n    \"\"\"\n    Execute external command\n    :param args: command line arguments : [unicode]\n    :param shell: True when using shell : boolean\n    :param cwd: working directory : string\n    :param env: environment variables : dict\n    :param stdin: standard input\n    :param stdout: standard output\n    :param stderr: standard error\n    :param cmd_encoding: command line encoding: string\n    :return: return code\n    \"\"\"\n    return subprocess.call(\n        args=__convert_args(args, shell, cmd_encoding), shell=shell, cwd=cwd, env=__convert_env(env, cmd_encoding),\n        stdin=stdin, stdout=stdout, stderr=stderr)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexecuting external command and capture output", "response": "def capture_command(args, shell=False, cwd=None, env=None, stdin=None, cmd_encoding='utf-8'):\n    \"\"\"\n    Execute external command and capture output\n    :param args: command line arguments : [string]\n    :param shell: True when using shell : boolean\n    :param cwd: working directory : string\n    :param env: environment variables : dict\n    :param stdin: standard input\n    :param cmd_encoding: command line encoding: string\n    :return: tuple of return code, stdout data and stderr data\n    \"\"\"\n    p = subprocess.Popen(\n        __convert_args(args, shell, cmd_encoding), shell=shell, cwd=cwd, env=__convert_env(env, cmd_encoding),\n        stdin=stdin, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    stdout_data, stderr_data = p.communicate()\n    return p.returncode, stdout_data, stderr_data"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck whether a process with the given pid exists in the current process table.", "response": "def pid_exists(pid):\n    \"\"\"\n    Check whether pid exists in the current process table.\n\n    stole from https://github.com/giampaolo/psutil/blob/master/psutil/_psposix.py\n    \"\"\"\n\n    if os.name == 'nt':\n        # check the output of TASKLIST command\n        returncode, stdout, stderr = capture_command(['TASKLIST', '/FO', 'CSV', '/NH', '/FI', 'PID eq %d' % pid])\n        return stdout[:1] == b'\"'\n    else:\n        if pid == 0:\n            # According to \"man 2 kill\" PID 0 has a special meaning:\n            # it refers to <<every process in the process group of the\n            # calling process>> so we don't want to go any further.\n            # If we get here it means this UNIX platform *does* have\n            # a process with id 0.\n            return True\n        try:\n            os.kill(pid, 0)\n        except OSError as err:\n            if err.errno == errno.ESRCH:\n                # ESRCH == No such process\n                return False\n            elif err.errno == errno.EPERM:\n                # EPERM clearly means there's a process to deny access to\n                return True\n            else:\n                # According to \"man 2 kill\" possible error values are\n                # (EINVAL, EPERM, ESRCH) therefore we should never get\n                # here. If we do let's be explicit in considering this\n                # an error.\n                raise err\n        else:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef length(self):\n        return math.sqrt(\n            (self.endpoint_a.northing - self.endpoint_b.northing) ** 2 +\n            (self.endpoint_a.easting - self.endpoint_b.easting) ** 2\n        )", "response": "Return length of the line in the national region."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates total length of the polyline", "response": "def length(self):\n        \"\"\"\n        Calculate total length of the polyline\n\n        :return: total length in meters\n        :rtype: float\n        \"\"\"\n        total_length = 0\n        for location_a, location_b in zip(\n                self.locations[:-1], self.locations[1:]):\n            total_length += Line(location_a, location_b).length\n        return total_length"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef main():\n    args, otherthings = parse_known_args()\n\n    if args.version:\n        print_version()\n        return 0\n\n    directory = os.path.abspath(os.curdir)\n    if args.folder:\n        directory = args.folder\n\n    verbosity = 0\n    if args.verbose:\n        verbosity = verbosity_level['low']\n    elif args.verbosity:\n        verbosity = args.verbosity\n\n    pulla = Pulla(verbosity=verbosity, recursive=False)\n\n    if is_this_a_git_dir(directory):\n        pulla.do_pull_in(directory)\n    else:\n        pulla.pull_all(directory)", "response": "Main entry point for the\n    script."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninstall the configured exception hook wrapping the old exception hook", "response": "def install_hook(dialog=SimpleExceptionDialog, invoke_old_hook=False, **extra):\n    \"\"\"\n    install the configured exception hook wrapping the old exception hook\n\n    don't use it twice\n\n    :oparam dialog: a different exception dialog class\n    :oparam invoke_old_hook: should we invoke the old exception hook?\n    \"\"\"\n    global _old_hook\n    assert _old_hook is None\n\n    def new_hook(etype, eval, trace):\n        gobject.idle_add(dialog_handler, dialog, etype, eval, trace, extra)\n        if invoke_old_hook:\n            _old_hook(etype, eval, trace)\n\n    _old_hook = sys.excepthook\n    sys.excepthook = new_hook"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a dictionary with various information about this root_action.", "response": "def _summarize_action(self, root_action):\n        \"\"\"Return a dictionary with various information about this root_action.\n\n        Note:\n        Scoring assumes that each actor makes the \"best\" choices in their turn\n        based on the simulation available.\n        \"\"\"\n        def is_target_node(node):\n            return isinstance(node, base.EOT) or (node is root_action)\n        # store per-turn results from the bottom up.\n        realistic_ends_by_node = dict()\n        for node in root_action.post_order_nodes():  # bottom up to this action\n            # only work with EOT or the root action\n            if not is_target_node(node):\n                continue\n            # by the time this node is reached, the results of all children\n            # have been stored under it in realistic_ends (except leaves)\n            # so choose the best of the available results and send it\n            # up to the next valid node\n            try:  # get the results stored previously in the deeper turn\n                realistic_ends = realistic_ends_by_node[node]\n            except KeyError:  # leaves are own realistic end\n                realistic_ends = [node]\n            # identify the \"best\" end for this node\n            if node is root_action:\n                active = node.parent.active\n                passive = node.parent.passive\n            else:\n                active = node.parent.passive\n                passive = node.parent.active\n            ends_by_score = dict()\n            for realistic_end in realistic_ends:\n                # determine the relative score. i.e. if delta is positive\n                # then the end result is better for active than passive\n                relative_score = self._relative_score(node, realistic_end,\n                                                      active, passive)\n                ends_by_score[relative_score] = realistic_end\n            best_end = ends_by_score[max(ends_by_score.keys())]\n            # done after determining realistic result for root action\n            if node is root_action:\n                return self._summarize_result(root_action, best_end)\n            # not done: place best end on the parent EOT's list of possibilities\n            parent = node.parent\n            while parent:\n                if is_target_node(parent):\n                    break\n                parent = parent.parent  # keep moving up until target found\n            # at this point the parent is either root_action or another EOT\n            realistic_ends_by_node.setdefault(parent, list()).append(best_end)\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the balance of perception between two nodes. A positive score indicates the result is relatively better for passive.", "response": "def _relative_score(self, start_eot, end_eot, active, passive):\n        \"\"\"Return the balance of perception between the two nodes.\n        A positive score indicates the result is relatively better for active.\n        \"\"\"\n        active_start = self._score_eot_for_actor(start_eot, active)\n        passive_start = self._score_eot_for_actor(start_eot, passive)\n        active_end = self._score_eot_for_actor(end_eot, active)\n        passive_end = self._score_eot_for_actor(end_eot, passive)\n        return (active_end - passive_end) - (active_start - passive_start)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _score_eot_for_actor(self, eot, actor):\n        # currently just simple sum of own attributes\n        # could be much more sophisticated in both analysis (e.g. formulas)\n        # and breadth of items analyzed (e.g. require other actor, the board)\n        end_state = eot.parent\n        a = {'player': end_state.player,\n             'opponent': end_state.opponent}[actor.name]\n        # simple prioritization without regard to character attributes\n        health = a.health * 2\n        r, g, b, y = a.r, a.g, a.b, a.y\n        x, m = 0.5 * a.x, 0.5 * a.m\n        return sum((health, r, g, b, y, x, m))", "response": "Score the end of turn for an actor."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a dict with useful information that summarizes this action.", "response": "def _summarize_result(self, root_action, leaf_eot):\n        \"\"\"Return a dict with useful information that summarizes this action.\"\"\"\n        root_board = root_action.parent.board\n        action_detail = root_action.position_pair\n        score = self._relative_score(root_action, leaf_eot,\n                                     root_action.parent.player,\n                                     root_action.parent.opponent)\n        # mana drain info\n        total_leaves = 0\n        mana_drain_leaves = 0\n        for leaf in root_action.leaves():\n            total_leaves += 1\n            if leaf.is_mana_drain:\n                mana_drain_leaves += 1\n        summary = base.Summary(root_board, action_detail, score,\n                               mana_drain_leaves, total_leaves)\n        return summary"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mie_avg(radius=5e-6, sphere_index=1.339, medium_index=1.333,\n            wavelength=550e-9, pixel_size=1e-7, grid_size=(80, 80),\n            center=(39.5, 39.5), interpolate=3, focus=0, arp=True):\n    \"\"\"Mie-simulated non-polarized field behind a dielectric sphere\n\n    Parameters\n    ----------\n    radius: float\n        Radius of the sphere [m]\n    sphere_index: float\n        Refractive index of the sphere\n    medium_index: float\n        Refractive index of the surrounding medium\n    wavelength: float\n        Vacuum wavelength of the imaging light [m]\n    pixel_size: float\n        Pixel size [m]\n    grid_size: tuple of floats\n        Resulting image size in x and y [px]\n    center: tuple of floats\n        Center position in image coordinates [px]\n    interpolate: int\n        Compute the radial field with sampling that is by a factor of\n        `interpolate` higher than the required data and interpolate the\n        2D field from there.\n    focus: float\n        .. versionadded:: 0.5.0\n\n        Axial focus position [m] measured from the center of the\n        sphere in the direction of light propagation.\n    arp: bool\n        Use arbitrary precision (ARPREC) in BHFIELD computations\n\n    Returns\n    -------\n    qpi: qpimage.QPImage\n        Quantitative phase data set\n    \"\"\"\n    center = np.array(center)\n    grid_size = np.array(grid_size)\n    # simulation parameters\n    radius_um = radius * 1e6  # radius of sphere in um\n    propd_um = radius_um  # simulate propagation through full sphere\n    propd_lamd = radius / wavelength  # radius in wavelengths\n    wave_nm = wavelength * 1e9\n\n    kwargs = {\"radius_sphere_um\": radius_um,\n              \"refractive_index_medium\": medium_index,\n              \"refractive_index_sphere\": sphere_index,\n              \"measurement_position_um\": propd_um,\n              \"wavelength_nm\": wave_nm}\n\n    upres = wavelength / pixel_size * interpolate\n    max_off = np.max(np.abs(grid_size / 2 - .5 - center))\n\n    latsize = int(np.round((np.max(grid_size) + max_off)))\n\n    num = latsize * upres / 2\n    # find the maximum interpolation range in the 2d image\n\n    bignum = int(np.ceil(np.sqrt(np.sum((np.array(grid_size) /\n                                         2 + max_off)**2))) * interpolate)\n\n    # Compare this number to the radius of the sphere and cut it off at\n    # three times the radius.\n    radnum = int(np.ceil(3 * radius / pixel_size) * interpolate)\n    bignum = min(bignum, radnum)\n\n    latsize *= bignum / num\n    latsize *= wavelength * 1e6\n    upres /= wavelength * 1e6\n\n    background = np.exp(1j * 2 * np.pi * propd_lamd * medium_index)\n\n    # [sic]: Not times upres\n    ofx_px = grid_size[0] / 2 - center[0]\n    ofy_px = grid_size[1] / 2 - center[1]\n\n    kwargsx = kwargs.copy()\n    kwargsx.update({\"size_simulation_um\": (latsize / 2, 1 / upres),\n                    \"shape_grid\": (bignum, 1),\n                    \"offset_x_um\": -latsize / 4,\n                    \"offset_y_um\": 0})\n\n    fieldx = simulate_sphere(arp=arp, **kwargsx) / background\n\n    kwargsy = kwargs.copy()\n    kwargsy.update({\"size_simulation_um\": (1 / upres, latsize / 2),\n                    \"shape_grid\": (1, bignum),\n                    \"offset_x_um\": 0,\n                    \"offset_y_um\": -latsize / 4})\n    fieldy = simulate_sphere(arp=arp, **kwargsy) / background\n\n    field = (fieldx.flatten() + fieldy.flatten()) / 2\n\n    xo = np.linspace(0, bignum, bignum, endpoint=True) / interpolate\n\n    x = np.linspace(-grid_size[0] / 2,\n                    grid_size[0] / 2,\n                    grid_size[0] * interpolate,\n                    endpoint=True)\n\n    y = np.linspace(-grid_size[1] / 2,\n                    grid_size[1] / 2,\n                    grid_size[1] * interpolate,\n                    endpoint=True)\n\n    yv, xv = np.meshgrid(y, x)\n    r = np.sqrt(xv**2 + yv**2)\n    inpt_kwargs = {\"kind\": \"linear\",\n                   \"assume_sorted\": True,\n                   \"bounds_error\": False,\n                   }\n\n    ipltph = spinterp.interp1d(xo, np.unwrap(\n        np.angle(field)), fill_value=0, **inpt_kwargs)\n    ipltam = spinterp.interp1d(xo, np.abs(field), fill_value=1, **inpt_kwargs)\n    phase2d = ipltph(r)\n    field2d = ipltam(r) * np.exp(1j * phase2d)\n\n    # Numerical refocusing\n    # We need to perform numerical focusing with the upsampled array,\n    # or else we will loose spatial information and the resulting\n    # spherical image becomes asymmetric.\n    refoc_field2d = nrefocus.refocus(\n        field2d,\n        d=-((radius+focus) / pixel_size) * interpolate,\n        nm=medium_index,\n        res=wavelength / pixel_size * interpolate\n        )\n\n    # Phase (2PI offset corrected) and amplitude\n    ampli, phase = field2ap_corr(refoc_field2d)\n\n    # Perform new interpolation on requested grid\n    intpp = spinterp.RectBivariateSpline(x, y, phase, kx=1, ky=1)\n    intpa = spinterp.RectBivariateSpline(x, y, ampli, kx=1, ky=1)\n\n    xp = np.linspace(-grid_size[0] / 2,\n                     grid_size[0] / 2,\n                     grid_size[0],\n                     endpoint=False) + ofx_px\n\n    yp = np.linspace(-grid_size[1] / 2,\n                     grid_size[1] / 2,\n                     grid_size[1],\n                     endpoint=False) + ofy_px\n\n    amp_off = intpa(xp, yp)\n    pha_off = intpp(xp, yp)\n\n    meta_data = {\"pixel size\": pixel_size,\n                 \"wavelength\": wavelength,\n                 \"medium index\": medium_index,\n                 \"sim center\": center,\n                 \"sim radius\": radius,\n                 \"sim index\": sphere_index,\n                 \"sim model\": \"mie-avg\",\n                 }\n\n    qpi = qpimage.QPImage(data=(pha_off, amp_off),\n                          which_data=\"phase,amplitude\",\n                          meta_data=meta_data)\n\n    return qpi", "response": "Mie - simulated non - polarized field behind a dielectric sphere."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef match_phase(qpi, model, n0, r0, c0=None, pha_offset=0,\n                fix_pha_offset=False, nrel=.10, rrel=.05, crel=.05,\n                stop_dn=.0005, stop_dr=.0010, stop_dc=1, min_iter=3,\n                max_iter=100, ret_center=False, ret_pha_offset=False,\n                ret_qpi=False, ret_num_iter=False, ret_interim=False,\n                verbose=0, verbose_h5path=\"./match_phase_error.h5\"):\n    \"\"\"Fit a scattering model to a quantitative phase image\n\n    Parameters\n    ----------\n    qpi: qpimage.QPImage\n        QPI data to fit (e.g. experimental data)\n    model: str\n        Name of the light-scattering model\n        (see :const:`qpsphere.models.available`)\n    n0: float\n        Initial refractive index of the sphere\n    r0: float\n        Initial radius of the sphere [m]\n    c0: tuple of (float, float)\n        Initial center position of the sphere in ndarray index\n        coordinates [px]; if set to `None` (default), the center\n        of the image is used.\n    pha_offset: float\n        Initial phase offset [rad]\n    fix_pha_offset: bool\n        If True, do not fit the phase offset `pha_offset`. The phase\n        offset is determined from the mean of all pixels whose absolute\n        phase is\n\n        - below 1% of the modeled phase and\n        - within a 5px or 20% border (depending on which is larger)\n          around the phase image.\n    nrel: float\n        Determines the border of the interpolation range for the\n        refractive index: [n-(n-nmed)*nrel, n+(n-nmed)*nrel]\n        with nmed=qpi[\"medium_index\"] and, initially, n=n0.\n    rrel: float\n        Determines the border of the interpolation range for the\n        radius: [r*(1-rrel), r*(1+rrel)] with, initially, r=r0.\n    crel: float\n        Determines the border of the interpolation range for the\n        center position: [cxy - dc, cxy + dc] with the center\n        position (along x or y) cxy, and the interval radius dc\n        defined by dc=max(lambda, crel * r0) with the vacuum\n        wavelength lambda=qpi[\"wavelenght\"].\n    stop_dn: float\n        Stopping criterion for refractive index\n    stop_dr: float\n        Stopping criterion for radius\n    stop_dc: float\n        Stopping criterion for lateral offsets\n    min_iter: int\n        Minimum number of fitting iterations to perform\n    max_iter: int\n        Maximum number of fitting iterations to perform\n    ret_center: bool\n        If True, return the fitted center coordinates\n    ret_pha_offset: bool\n        If True, return the fitted phase offset\n    ret_qpi: bool\n        If True, return the final fit as a data set\n    ret_num_iter: bool\n        If True, return the number of iterations\n    ret_interim: bool\n        If True, return intermediate parameters of each iteration\n    verbose: int\n        Higher values increase verbosity\n    verbose_h5path: str\n        Path to hdf5 output file, created when `verbosity >= 2`\n\n    Returns\n    -------\n    n: float\n        Fitted refractive index\n    r: float\n        Fitted radius [m]\n    c: tuple of (float, float)\n        Only returned if `ret_center` is True\n        Center position of the sphere in ndarray index coordinates [px]\n    pha_offset: float\n        Only returned if `ret_pha_offset` is True\n        Fitted phase offset [rad]\n    qpi: qpimage.QPImage\n        Only returned if `ret_qpi` is True\n        Simulation using `model` with the final fit parameters\n    num_iter: int\n        Only returned if `ret_num_iter` is True\n        Number of iterations performed; negative number is\n        returned when iteration fails\n    interim: list\n        Only returned if `ret_interim` is True\n        Intermediate fitting parameters\n    \"\"\"\n    if not isinstance(qpi, qpimage.QPImage):\n        raise ValueError(\"`qpi` must be instance of `QPImage`!\")\n    for var in [\"medium index\", \"pixel size\", \"wavelength\"]:\n        if var not in qpi:\n            raise ValueError(\"meta data '{}' not defined in `qpi`!\")\n\n    if c0 is None:\n        c0 = [qpi.shape[0] / 2, qpi.shape[1] / 2]\n\n    model_kwargs = {\"radius\": r0,\n                    \"sphere_index\": n0,\n                    \"medium_index\": qpi[\"medium index\"],\n                    \"wavelength\": qpi[\"wavelength\"],\n                    \"pixel_size\": qpi[\"pixel size\"],\n                    \"grid_size\": qpi.shape,\n                    \"center\": c0\n                    }\n\n    spi = SpherePhaseInterpolator(model=model,\n                                  model_kwargs=model_kwargs,\n                                  pha_offset=pha_offset,\n                                  nrel=nrel,\n                                  rrel=rrel,\n                                  verbose=verbose)\n\n    # Results recorder to detect stuck iterations\n    recorder = []\n\n    # intermediate results\n    interim = []\n    interim.append([0, spi.params])\n\n    phase = qpi.pha\n    range_ipol = 47\n    range_off = 13\n    # allow to vary center offset for 5 % of radius or 1 wavelengths\n    dc = max(qpi[\"wavelength\"], crel * r0) / qpi[\"pixel size\"]  # [px]\n    if verbose:\n        print(\"Starting phase fitting.\")\n    ii = 0\n    message = None\n    if \"identifier\" in qpi:\n        ident = qpi[\"identifier\"]\n    else:\n        ident = str(time.time())\n    while True:\n        if verbose >= 2:\n            export_phase_error_hdf5(h5path=verbose_h5path,\n                                    identifier=ident,\n                                    index=ii,\n                                    phase=phase,\n                                    mphase=spi.get_phase(),\n                                    model=model,\n                                    n0=n0,\n                                    r0=r0,\n                                    spi_params=spi.params)\n\n        ii += 1\n\n        # remember old values\n        r_old = spi.radius\n        n_old = spi.sphere_index\n\n        # 1st step: vary radius\n        rs = np.linspace(\n            spi.range_r[0], spi.range_r[1], range_ipol, endpoint=True)\n        assert np.allclose(np.min(np.abs(rs - spi.radius)), 0)\n        lsqs = []\n        for ri in rs:\n            phasei = spi.get_phase(rintp=ri)\n            lsqs.append(sq_phase_diff(phase, phasei))\n        idr = np.argmin(lsqs)\n        spi.radius = rs[idr]\n\n        # 2nd step: vary n_object\n        ns = np.linspace(\n            spi.range_n[0], spi.range_n[1], range_ipol, endpoint=True)\n        assert np.allclose(np.min(np.abs(ns - spi.sphere_index)), 0)\n        lsqs = []\n        for ni in ns:\n            phasei = spi.get_phase(nintp=ni)\n            lsqs.append(sq_phase_diff(phase, phasei))\n        idn = np.argmin(lsqs)\n        spi.sphere_index = ns[idn]\n\n        # 3rd step: vary center position\n        x = np.linspace(-dc, dc, range_off, endpoint=True)\n        assert np.allclose(np.min(np.abs(x)), 0)\n        xintp, yintp = np.meshgrid(x, x)\n        lsqs = []\n        for xoff, yoff in zip(xintp.flatten(), yintp.flatten()):\n            phasei = spi.get_phase(delta_offset_x=xoff, delta_offset_y=yoff)\n            err = sq_phase_diff(phase, phasei)\n            lsqs.append(err)\n\n        idc = np.argmin(lsqs)\n        deltax = xintp.flatten()[idc]\n        deltay = yintp.flatten()[idc]\n\n        # offsets must be added incrementally, because they are not overridden\n        # in the 3rd step\n        spi.posx_offset = spi.posx_offset - deltax\n        spi.posy_offset = spi.posy_offset - deltay\n\n        if not fix_pha_offset:\n            # Use average phase at image border without sphere\n            cabphase = spi.get_phase() - spi.pha_offset\n            # Determine background\n            cabphase[np.abs(cabphase) > .01 * np.abs(cabphase).max()] = np.nan\n            cb_border = max(5, min(cabphase.shape) // 5)\n            cabphase[cb_border:-cb_border, cb_border:-cb_border] = np.nan\n            phai_offset = np.nanmean(cabphase - phase)\n\n            if np.isnan(phai_offset):\n                phai_offset = 0\n\n            spi.pha_offset = - phai_offset\n\n        if verbose == 1:\n            print(\"Iteration {}: n={:.5e}, r={:.5e}m\".format(ii,\n                                                             spi.sphere_index,\n                                                             spi.radius))\n        elif verbose >= 2:\n            print(\"Iteration {}: {}\".format(ii, spi.params))\n\n        interim.append([ii, spi.params])\n\n        # update accuracies\n        if (idn > range_ipol / 2 - range_ipol / 10 and\n                idn < range_ipol / 2 + range_ipol / 10):\n            spi.dn /= 2\n            if verbose >= 2:\n                print(\"Halved search interval: spi.dn={:.8f}\".format(spi.dn))\n        if (idr > range_ipol / 2 - range_ipol / 10 and\n                idr < range_ipol / 2 + range_ipol / 10):\n            spi.dr /= 2\n            if verbose >= 2:\n                print(\"Halved search interval: spi.dr={:.8f}\".format(spi.dr))\n        if deltax**2 + deltay**2 < dc**2:\n            dc /= 2\n            if verbose >= 2:\n                print(\"Halved search interval: dc={:.8f}\".format(dc))\n\n        if ii < min_iter:\n            if verbose:\n                print(\"Keep iterating because `min_iter`={}.\".format(min_iter))\n            continue\n        elif ii >= max_iter:\n            ii *= -1\n            if verbose:\n                print(\"Stopping iteration: reached `max_iter`={}\".format(\n                    max_iter))\n            message = \"fail, reached maximum number of iterations\"\n            break\n\n        if stop_dc:\n            # check movement of center location and enforce next iteration\n            curoff = np.sqrt(deltax**2 + deltay**2)\n            if curoff > stop_dc:\n                if verbose:\n                    print(\"Keep iterating because center location moved by \"\n                          + \"{} > `stop_dc`={}.\".format(curoff, stop_dc))\n                continue\n\n        if (abs(spi.radius - r_old) / spi.radius < stop_dr and\n                abs(spi.sphere_index - n_old) < stop_dn):\n            # Radius, refractive index, and center position changed below\n            # user-defined threshold.\n            if verbose:\n                print(\"Stopping iteration: `stop_dr` and `stop_dn` satisfied\")\n            message = \"success, satisfied stopping criteria\"\n            break\n\n        thisresult = (spi.sphere_index, spi.radius)\n        recorder.append(thisresult)\n        if recorder.count(thisresult) > 2:\n            ii *= -1\n            # We have already had this result 2 times and therefore we abort.\n            # TODO:\n            # - Select the one with the least error\n            warnings.warn(\"Aborting stuck iteration for {}!\".format(qpi))\n            if verbose:\n                print(\"Stop iteration: encountered same parameters twice.\")\n            message = \"fail, same parameters encountered twice\"\n            break\n\n        if verbose >= 2:\n            infostring = \"\"\n            if not abs(spi.sphere_index - n_old) < stop_dn:\n                infostring += \" delta_n = {} > {}\".format(\n                    abs(spi.sphere_index - n_old), stop_dn)\n            if not abs(spi.radius - r_old) / spi.radius < stop_dr:\n                infostring += \" delta_r = {} > {}\".format(\n                    abs(spi.radius - r_old) / spi.radius, stop_dr)\n            print(\"Keep iterating: {} (no convergence)\".format(infostring))\n\n    if verbose:\n        print(\"Number of iterations: {}\".format(ii))\n        print(\"Stopping rationale: {}\".format(message))\n\n    if verbose >= 2:\n        export_phase_error_hdf5(h5path=verbose_h5path,\n                                identifier=ident,\n                                index=ii,\n                                phase=phase,\n                                mphase=spi.get_phase(),\n                                model=model,\n                                n0=n0,\n                                r0=r0,\n                                spi_params=spi.params)\n\n    res = [spi.sphere_index, spi.radius]\n\n    if ret_center:\n        res += [[spi.posx_offset, spi.posy_offset]]\n    if ret_pha_offset:\n        res += [spi.pha_offset]\n    if ret_qpi:\n        res += [spi.compute_qpi()]\n    if ret_num_iter:\n        res += [ii]\n    if ret_interim:\n        res += [interim]\n\n    return res", "response": "Fit a scattering model to a quantitative phase image."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef export_phase_error_hdf5(h5path, identifier, index, phase, mphase,\n                            model, n0, r0, spi_params):\n    \"\"\"Export the phase error to an hdf5 file\n\n    Parameters\n    ----------\n    h5path: str or pathlib.Path\n        path to hdf5 output file\n    identifier: str\n        unique identifier of the input phase\n        (e.g. `qpimage.QPImage[\"identifier\"]`)\n    index: int\n        iteration index\n    phase: 2d real-valued np.ndarray\n        phase image\n    mphase: 2d real-valued np.ndarray\n        reference phase image\n    model: str\n        sphere model name\n    n0: float\n        initial object index\n    r0: float\n        initial object radius [m]\n    spi_params: dict\n        parameter dictionary of :func:`SpherePhaseInterpolator`\n    \"\"\"\n    with h5py.File(h5path, mode=\"a\") as h5:\n        if identifier in h5:\n            grp = h5[identifier]\n        else:\n            grp = h5.create_group(identifier)\n        ds = grp.create_dataset(\"phase_error_{:05d}\".format(index),\n                                data=mphase-phase)\n        ds.attrs[\"index initial\"] = n0\n        ds.attrs[\"radius initial\"] = r0\n        ds.attrs[\"sim model\"] = model\n        ds.attrs[\"sim index\"] = spi_params[\"sphere_index\"]\n        ds.attrs[\"sim radius\"] = spi_params[\"radius\"]\n        ds.attrs[\"sim center\"] = spi_params[\"center\"]\n        ds.attrs[\"fit iteration\"] = index\n        ds.attrs[\"fit iteration\"] = index", "response": "Export the phase error to an hdf5 file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read(text, name=None):\n        doc = docutils.utils.new_document(name, SceneScript.settings)\n        parser = docutils.parsers.rst.Parser()\n        parser.parse(text, doc)\n        return doc", "response": "Read a block of text as a docutils document."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nselects a persona for each entity declared in the scene.", "response": "def select(self, personae, relative=False, roles=1):\n        \"\"\"Select a persona for each entity declared in the scene.\n\n        :param personae: A sequence of Personae.\n        :param bool relative: Affects imports from namespace packages.\n            Used for testing only.\n        :param int roles: The maximum number of roles allocated to each persona.\n        :return: An OrderedDict of {Entity: Persona}.\n\n        \"\"\"\n\n        def constrained(entity):\n            return (\n                len(entity[\"options\"].get(\"types\", [])) +\n                len(entity[\"options\"].get(\"states\", []))\n            )\n\n        rv = OrderedDict()\n        performing = defaultdict(set)\n        pool = list(personae)\n        self.log.debug(pool)\n        entities = OrderedDict([\n            (\"\".join(entity.attributes[\"names\"]), entity)\n            for entity in sorted(\n                group_by_type(self.doc)[EntityDirective.Declaration],\n                key=constrained,\n                reverse=True\n            )\n        ])\n        for e in entities.values():\n            types = tuple(filter(\n                None,\n                (e.string_import(t, relative)\n                 for t in e[\"options\"].get(\"types\", []))\n            ))\n            states = tuple(filter(\n                None,\n                (int(t) if t.isdigit() else e.string_import(t, relative)\n                 for t in e[\"options\"].get(\"states\", []))\n            ))\n            otherRoles = {i.lower() for i in e[\"options\"].get(\"roles\", [])}\n            typ = types or object\n            persona = next(\n                (i for i in pool\n                 if isinstance(i, typ) and\n                 getattr(i, \"get_state\", not states) and\n                 all(str(i.get_state(type(s))).startswith(str(s)) for s in states) and\n                 (performing[i].issubset(otherRoles) or not otherRoles)),\n                None\n            )\n            rv[e] = persona\n            performing[persona].update(set(e.attributes[\"names\"]))\n\n            if not otherRoles or list(rv.values()).count(persona) == roles:\n                try:\n                    pool.remove(persona)\n                except ValueError:\n                    self.log.debug(\n                        \"No persona for type {0} and states {1} with {2} {3}.\".format(\n                            typ, states, roles, \"role\" if roles == 1 else \"roles\"\n                        )\n                    )\n        return rv"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cast(self, mapping):\n        # See 'citation' method in\n        # http://docutils.sourceforge.net/docutils/parsers/rst/states.py\n        for c, p in mapping.items():\n            self.doc.note_citation(c)\n            self.doc.note_explicit_target(c, c)\n            c.persona = p\n            self.log.debug(\"{0} to be played by {1}\".format(\n                c[\"names\"][0].capitalize(), p)\n            )\n        return self", "response": "Allocate the scene script a cast of persona for each of its entities."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the script file and return a model object.", "response": "def run(self):\n        \"\"\"Parse the script file.\n\n        :rtype: :py:class:`~turberfield.dialogue.model.Model`\n        \"\"\"\n        model = Model(self.fP, self.doc)\n        self.doc.walkabout(model)\n        return model"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef my_main(context):\n    print('starting MyApp...')\n    if context['debug']:\n        print('Context:')\n        for k in context:\n            print('Key: {}\\nValue: {}'.format(k, context[k]))\n        print('Done!')\n    return 0", "response": "The main function for the main function."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the summaries of the likely resutls of each available action.", "response": "def versus_summaries(turns=2, sims_to_average=2, async_results_q=None):\n    \"\"\"Return summaries of the likely resutls of each available action..\n\n    Arguments:\n    - turns: how many turns to simulate.\n        - in 2013, 1 is fast (seconds), 2 is slow (seconds), 3 who knows\n    - sims_to_average: how many times to run the simulation\n        to get more representative average results of each action.\n    - async_results_q: provide a multiprocessing Queue on which\n        the summaries of each turn will be placed. this is an asynchronous\n        alternative to waiting for the final return value\n    \"\"\"\n    board, player, opponent, extra_actions = _state_investigator.get_versus()\n    if extra_actions: extra_actions = 1  # limit value for realistic time\n    if board is None:\n        return tuple()\n    averaged_summaries = list()  # default return value is empty\n    # keep a separate advisor for each simulation to average\n    advisors = list()\n    for i in range(sims_to_average):\n        advisor = versus.Advisor()\n        advisor.reset(board, player, opponent, extra_actions)\n        advisors.append(advisor)\n    # provide async sim results per turn; final results as return value\n    for turn in range(turns):\n        # store    {action: list of results from each simulation}\n        summaries_by_action = dict()\n        for i in range(sims_to_average):\n            advisor = advisors[i]\n            advisor.simulate_next_turn()\n            for s in advisor.sorted_current_summaries():\n                summaries_by_action.setdefault(s.action, list()).append(s)\n        # now all sims and analysis for this turn have been completed\n        averaged_summaries = list()\n        for action, summaries in summaries_by_action.items():\n            board = summaries[0].board  # any board. they are all the same\n            action = summaries[0].action  # any action. they are all the same\n            score_sum = sum(s.score for s in summaries)\n            score_avg = score_sum / len(summaries)\n            manadrain_sum = sum(s.mana_drain_leaves for s in summaries)\n            leaves_sum = sum(s.total_leaves for s in summaries)\n            avg_summary = base.Summary(board, action, score_avg,\n                                       manadrain_sum, leaves_sum)\n            averaged_summaries.append(avg_summary)\n        averaged_summaries.sort(key=lambda s: s.score, reverse=True)\n        # option to provide the results asynchronouslys\n        if not async_results_q is None:\n            async_results_q.put(averaged_summaries)\n    return averaged_summaries"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbuild a tree pathname from a filename with the specified directory depth.", "response": "def build_tree_pathname(filename, directory_depth=8, pathname_separator_character=os.sep):\n    \"\"\"\n    Return a pathname built of the specified number of sub-directories,\n    and where each directory is named after the nth letter of the filename\n    corresponding to the directory depth.\n\n    Examples::\n\n      >>> build_tree_pathname('foo.txt', 2, '/')\n      'f/o/'\n      >>> build_tree_pathname('0123456789abcdef')\n      '0/1/2/3/4/5/6/7/'\n\n    @param filename: name of a file, with or without extension.\n\n    @param directory_depth: number of sub-directories to be generated.\n\n    @param pathname_separator_character: character to be used to separate\n           pathname components, such as '/' for POSIX and '\\\\' for\n           Windows.  If not defined, the default is the character used by\n           the operating system ``os.sep``.\n\n    @return: a file pathname.\n    \"\"\"\n    pathname = ''\n    (filename_without_extension, _file_extension_) = os.path.splitext(filename)\n\n    for i in range(min(directory_depth, len(filename_without_extension))):\n        pathname += filename_without_extension[i] + pathname_separator_character\n\n    return pathname"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef build_tree_file_pathname(filename, directory_depth=8, pathname_separator_character=os.sep):\n    return build_tree_pathname(filename, directory_depth, pathname_separator_character) + filename", "response": "Build a tree file pathname which is built of the specified directory depth and where each directory is named after the nth letter of the filename corresponding to the directory depth."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_root_path(absolute_path, relative_path):\n    _absolute_path = os.path.normpath(absolute_path)\n    _relative_path = os.path.normpath(relative_path)\n\n    index = _absolute_path.rfind(_relative_path)\n    if index == -1 or len(_relative_path) + index < len(_absolute_path):\n        raise ValueError('The relative path does not end the specified absolute path')\n\n    return _absolute_path[:index]", "response": "Return the root path of a path relative to an absolute path."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_file_checksum(file_path_name,\n        hash_algorithm_name='md5'):\n    \"\"\"\n    Generate the MD5 checksum of the specified file.\n\n\n    @param file_path_name: the absolute path and name of the file to\n        generate its MD5 checksum.\n\n    @param hash_algorithm_name: specify the hash algorithm to use.  Refer\n        to ``hashlib.algorithms`` to get the names of the hash algorithms\n        guaranteed to be supported by this module.\n\n\n    @return: hash digest returned as a string of double length, containing\n        only hexadecimal digits.  This may be used to exchange the value\n        safely in email or other non-binary environments.\n\n\n    @note: the file can not be entirely read to memory, but it needs to\n        be read by chunks of memory that will be freed after each\n        iteration.  What's important to notice is that the file  must be\n        opened in binary mode.  The function breaks the file into chunks\n        using block size of any multiple of 128 (say 8192, 32768, etc.)\n        and its feed them to MD5 consecutively using ``update()``.  This\n        takes advantage advantage of the fact that MD5 has 128-byte digest\n        blocks.  The function actually uses a block size that depends on the block\n        size of the filesystem to avoid performances issues.\n\n    @note: The ``F_FRSIZE`` value is the actual minimum allocation unit\n        of the filesystem, while the ``F_BSIZE`` is the block size that\n        would lead to most efficient use of the disk with io calls.\n    \"\"\"\n    hash_algorithm = hashlib.new(hash_algorithm_name)\n\n    if sys.platform == \"win32\":\n        import ctypes\n        sectors_per_cluster = ctypes.c_ulonglong(0)\n        bytes_per_sector = ctypes.c_ulonglong(0)\n        root_path_name = ctypes.c_wchar_p(u\"C:\\\\\")\n        ctypes.windll.kernel32.GetDiskFreeSpaceW(root_path_name,\n                ctypes.pointer(sectors_per_cluster),\n                ctypes.pointer(bytes_per_sector),\n                None,\n                None)\n        block_size = bytes_per_sector.value\n    else:\n        import statvfs\n        block_size = os.statvfs('/')[statvfs.F_BSIZE]\n\n    with open(file_path_name, 'rb') as handle:\n        for chunk in iter(lambda: handle.read(block_size), b''):\n            hash_algorithm.update(chunk)\n\n    return hash_algorithm.hexdigest()", "response": "Generate the MD5 checksum of the specified file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating the specified path if it does not exist.", "response": "def make_directory_if_not_exists(path):\n    \"\"\"\n    Create the specified path, making all intermediate-level directories\n    needed to contain the leaf directory.  Ignore any error that would\n    occur if the leaf directory already exists.\n\n    @note: all the intermediate-level directories are created with the\n        default mode is 0777 (octal).\n\n    @param path: the path to create.\n\n    @raise OSError: an error that would occur if the path cannot be\n        created.\n    \"\"\"\n    try:\n        os.makedirs(path)\n    except OSError, error: # Ignore if the directory has been already created.\n        if error.errno <> errno.EEXIST:\n            raise error"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmove the specified file to another location.", "response": "def move_file(source_file_pathname, destination_file_pathname):\n    \"\"\"\n    Move the the specified file to another location.  If the destination\n    already exists, it is replaced silently.\n\n    This function is an alternative to ``shutil.move(src, dst)``, which\n    might raise ``OSError`` if the destination already exists.\n\n    @param source_file_pathname: the complete path and name of the file to\n        move.\n\n    @param destination_file_pathname: the complete path and name of the\n        file once moved.\n    \"\"\"\n    if os.path.exists(destination_file_pathname):\n        os.remove(destination_file_pathname)\n\n    shutil.move(source_file_pathname, destination_file_pathname)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nopens an encoded file using the given mode and return a wrapped version providing transparent encoding and decoding.", "response": "def smart_open(file_path_name,\n        mode='r',\n        encoding='utf-8'):\n    \"\"\"\n    Open an encoded file using the given mode and return a wrapped version\n    providing transparent encoding/decoding.  The default file mode is 'r'\n    meaning to open the file in read mode.\n\n\n    @param file_path_name: the absolute path and name of the file to\n        open.\n\n    @param mode: indicate how the file is to be opened.  The most\n        commonly-used values of mode are 'r' for reading, 'w' for\n        writing (truncating the file if it already exists), and 'a'\n        for appending (which on some Unix systems means that all writes\n        append to the end of the file regardless of the current seek\n        position). If mode is omitted, it defaults to 'r'.\n\n    @param encoding: specify the encoding which is to be used for the\n        file.\n\n\n    @return: an object of the file type.\n    \"\"\"\n    if file_path_name and file_path_name != '-':\n        file_handle = codecs.open(file_path_name, mode=mode, encoding='utf-8')\n    else:\n        file_handle = sys.stdout\n\n    try:\n        yield file_handle\n    finally:\n        if file_handle is not sys.stdout:\n            file_handle.close()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlocate a program file in the user s path.", "response": "def which(exe_name):\n    \"\"\"\n    Locate a program file in the user's path.\n\n    @param exec_name: name of the executable file.\n\n    @return: ``None`` if the executable has not been found in the user's\n        path, or the path for the executable file.\n    \"\"\"\n    def is_exe(file_path_name):\n        return os.path.isfile(file_path_name) and os.access(file_path_name, os.X_OK)\n\n    is_platform_windows = (platform.system() == 'Windows')\n\n    fpath, _fname = os.path.split(exe_name)\n    if fpath:\n        if is_exe(exe_name):\n            return exe_name\n    else:\n        for path in os.environ['PATH'].split(os.pathsep):\n            exe_file_path_name = os.path.join(path, exe_name)\n            if is_exe(exe_file_path_name):\n                return exe_file_path_name\n\n            if is_platform_windows:\n                windows_exe_file_path_name = '%s.exe' % exe_file_path_name\n                if is_exe(windows_exe_file_path_name):\n                    return windows_exe_file_path_name\n\n                windows_com_file_path_name = '%s.exe' % exe_file_path_name\n                if is_exe(windows_com_file_path_name):\n                    return windows_com_file_path_name\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the great circle distance between two points on the earth", "response": "def haversine(lat1, lon1, lat2, lon2):\r\n    \"\"\"\r\n    Calculate the great circle distance between two points\r\n    on the earth (specified in decimal degrees)\r\n    Thanks to a answer on stackoverflow by Michael Dunn.\r\n    http://stackoverflow.com/questions/4913349/haversine-formula-in-python-bearing-and-distance-between-two-gps-points\r\n    \"\"\"\r\n    if abs(lat1) > 90 or abs(lat2) > 90:\r\n        raise InvalidCoordinate('invalid latitude')\r\n    if abs(lon1) > 180 or abs(lon2) > 180:\r\n        raise InvalidCoordinate('invalid longitude')\r\n    # convert decimal degrees to radians\r\n    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\r\n    # haversine formula\r\n    dlon = lon2 - lon1\r\n    dlat = lat2 - lat1\r\n    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\r\n    c = 2 * asin(sqrt(a))\r\n    km = 6371 * c\r\n    return km"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget most reliable timestamp from a picture running down a couple of options.", "response": "def get_time(filename, tags):\r\n    \"\"\"\r\n    Get most reliable timestamp from a picture, running down a couple of options.\r\n    Filename, exif tags, modification time.\r\n    \"\"\"\r\n    # use exif 'Image DateTime' field as the time\r\n    if 'Image DateTime' in tags.keys():\r\n        return time.strptime(str(tags['Image DateTime']), '%Y:%m:%d %H:%M:%S')\r\n\r\n    # very fuzzy time machting on filename\r\n    # TODO: very fuzzy part, now it just matches the iphone naming convention\r\n    m = re.match('^(\\d{4}-\\d{2}-\\d{2} \\d{2}\\.\\d{2}\\.\\d{2}).*', filename)\r\n    if m:\r\n        return time.strptime(m.group(0), '%Y-%m-%d %H.%M.%S')\r\n\r\n    # if all else fails use stat().st_mtime (consistent on windows/linux as last modification time)\r\n    return time.localtime(Path(filename).stat().st_mtime)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndecode the exif - gcs format into a decimal point.", "response": "def convert_to_decimal(string):\r\n    \"\"\"\r\n    Decode the exif-gps format into a decimal point.\r\n    '[51, 4, 1234/34]'  ->  51.074948366\r\n    \"\"\"\r\n    number_or_fraction = '(?:\\d{1,2}) | (?:\\d{1,10} \\\\ \\d{1,10})'\r\n    m = re.compile('''\\[?\\s?            # opening bracket\r\n                    \\d{{1,2}}\\s?,\\s?    # first number\r\n                    {0} \\s?,\\s?         # second number (can be a fraction)\r\n                    {0} \\s?,\\s?         # third number (can be a fraction)\r\n                    \\]?\\s?              # closing bracket\r\n                    '''.format(number_or_fraction), re.VERBOSE)\r\n    if not m.match(string):\r\n        raise ValueError\r\n\r\n    h, m, s = re.sub('\\[|\\]', '', string).split(', ')\r\n    result = int(h)\r\n    if '/' in m:\r\n        m = m.split('/')\r\n        result += int(m[0]) * 1.0 / int(m[1]) / 60\r\n    else:\r\n        result += int(m) * 1.0 / 60\r\n    if '/' in s:\r\n        s = s.split('/')\r\n        result += int(s[0]) * 1.0 / int(s[1]) / 3600\r\n    else:\r\n        result += int(s) * 1.0 / 60\r\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild a dict from files from iterator", "response": "def build_dict(img_iterator):\r\n    \"\"\"\r\n    Build a dict from files from iterator.\r\n    {'absolute_filename': {'EXIF field': 'exif tag value'}}\r\n    Parse DateTime from filename in the same loop, added as 'TIME'.\r\n    \"\"\"\r\n    files_with_tags = dict()\r\n    for f in img_iterator:\r\n        with open(str(f.abspath()), 'rb') as jpg:\r\n            tags = exifread.process_file(jpg)\r\n            # Dont waste space on thumbnails\r\n            try:\r\n                del tags['JPEGThumbnail']\r\n            except KeyError:\r\n                pass\r\n            tags['TIME'] = get_time(str(f.abspath()), tags)\r\n            files_with_tags[str(f.abspath())] = tags\r\n    return files_with_tags"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a dictionary of photos taken within the specified radius from a given point.", "response": "def location_filter(files_with_tags, location, radius):\r\n    '''\r\n    Get photos taken within the specified radius from a given point.\r\n    '''\r\n    on_location = dict()\r\n    for f, tags in files_with_tags.items():\r\n        if 'GPS GPSLatitude' in tags:\r\n            try:\r\n                lat = convert_to_decimal(str(tags['GPS GPSLatitude']))\r\n                long = convert_to_decimal(str(tags['GPS GPSLongitude']))\r\n            except ValueError:\r\n                print('{0} has invalid gps info'.format(f))\r\n            try:\r\n                if haversine(lat, long, location['lat'], location['long']) < radius:\r\n                    on_location[f] = tags\r\n            except InvalidCoordinate:\r\n                print('{0} has invalid gps info'.format(f))\r\n    return on_location"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd photos based on time.", "response": "def add_based_on_time(files_with_tags, on_location):\r\n    '''\r\n    Sometimes the first photo in a series does not have gps coordinates because the phone\r\n    doesnt have a gps-fix yet. To add these photos as well we take the list of photos wich where\r\n    taken in the right location. Then add any photos taken whitin 10 minutes of these photos,\r\n    because they are almost certainly taken in the same area.\r\n    '''\r\n    to_add = dict()\r\n    for veiling_f, veiling_tags in on_location.items():\r\n        for compare_f, compare_tags in files_with_tags.items():\r\n            delta = abs(veiling_tags['TIME'] - compare_tags['TIME'])\r\n            if (delta.total_seconds() < 10 * 60) and (compare_f not in on_location.keys()):\r\n                to_add[compare_f] = compare_tags\r\n    return to_add"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _debug(self, msg, *args, **kwargs):\n\n        # Do nothing if debugging is disabled\n        if self._debug_stream is None or self._debug_stream is False:\n            return\n\n        # What are we passing to the format?\n        if kwargs:\n            fmtargs = kwargs\n        else:\n            fmtargs = args\n\n        # Emit the message\n        print >>self._debug_stream, msg % fmtargs", "response": "Emit a debug message."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npush a processor onto the processor stack.", "response": "def _push_processor(self, proc, index=None):\n        \"\"\"\n        Pushes a processor onto the processor stack.  Processors are\n        objects with proc_request(), proc_response(), and/or\n        proc_exception() methods, which can intercept requests,\n        responses, and exceptions.  When a method invokes the send()\n        method on a request, the proc_request() method on each\n        processor is called in turn.  Likewise, responses are\n        processed by the proc_response() method of each processor, in\n        the reverse order of the calls to proc_request().  The\n        proc_exception() methods are called if an exception is raised\n        instead of a response being returned.\n\n        Note that this method can append a processor to the stack, if\n        the index parameter is None (the default), or a processor may\n        be inserted into the stack by specifying an integer index.\n\n        For more information about processors, see the\n        requiem.Processor class.\n        \"\"\"\n\n        if index is None:\n            self._procstack.append(proc)\n        else:\n            self._procstack.insert(index, proc)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _make_req(self, method, url, methname, headers=None):\n\n        # Build up headers\n        hset = hdrs.HeaderDict()\n\n        # Walk through our global headers\n        for hdr, value in self._headers.items():\n            # If it's a callable, call it\n            if callable(value):\n                value = value(methname)\n            else:\n                # OK, just stringify it\n                value = str(value)\n\n            # If it's meaningful, attach it\n            if value:\n                hset[hdr] = value\n\n        # Were headers passed in?\n        if headers is not None:\n            # Update from specified headers\n            hset.update(headers)\n\n        # Hook method to instantiate requests\n        self._debug(\"Creating request %s.%s(%r, %r, headers=%r)\",\n                    self._req_class.__module__, self._req_class.__name__,\n                    method, url, hset)\n        return self._req_class(method, url, self._client, self._procstack,\n                               headers=hset, debug=self._debug)", "response": "Create a request object for the specified method and url."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding all plugins with a specific entry_point.", "response": "def query_plugins(entry_point_name):\n    \"\"\"\n    Find everything with a specific entry_point.  Results will be returned as a\n    dictionary, with the name as the key and the entry_point itself as the\n    value.\n\n    Arguments:\n    entry_point_name - the name of the entry_point to populate\n    \"\"\"\n    entries = {}\n    for entry_point in pkg_resources.iter_entry_points(entry_point_name):\n        entries[entry_point.name] = entry_point.load()\n    return entries"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwarn : depends on python - yaml internals", "response": "def _construct_node(loader, node, base_tag):\n    \"Warning: depends on python-yaml internals\"\n    node = copy.copy(node) # bypass YAML anti recursion\n    best_tag = base_tag\n    best_fit = 0\n    for key, val in loader.DEFAULT_TAGS.iteritems():\n        lenk = len(key)\n        if lenk <= best_fit:\n            continue\n        if base_tag.startswith(key):\n            best_tag = val + base_tag[lenk:]\n            best_fit = lenk\n    node.tag = best_tag\n    return loader.construct_object(node, deep=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsplitting comma - separated tag_suffix[: - 1 and map with _maybe_int", "response": "def _split_params(tag_prefix, tag_suffix):\n    \"Split comma-separated tag_suffix[:-1] and map with _maybe_int\"\n    if tag_suffix[-1:] != ')':\n        raise ValueError, \"unbalanced parenthesis in type %s%s\" % (tag_prefix, tag_suffix)\n    return map(_maybe_int, tag_suffix[:-1].split(','))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a validator function to the tree structure.", "response": "def add_validator(validator, base_tag, tag=None):\n    \"\"\"\n    Add a validator for the given tag, which defines a subset of base_tag.\n    If tag is None, it is automatically constructed as\n    u'!~' + validator.__name__\n    Validator is a function that accepts a document node (in the form of a\n    Python object), a schema node (also a Python object) and a tracing\n    object, and returns True if the document node is valid according to the\n    schema node.  Note that the validator function does not have to recurse\n    in sub-nodes, because XYS already does it.\n    \"\"\"\n    if not tag:\n        tag = u'!~' + validator.__name__\n\n    for xid, opts in _VALIDATOR_MODES.iteritems():\n        mtag = \"%s%s\" % (tag, xid)\n\n        yaml.add_constructor(mtag,\n                             ContructorValidatorNode(mtag,\n                                                     base_tag,\n                                                     validator,\n                                                     opts['name'],\n                                                     opts['min'],\n                                                     opts['max']))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_parameterized_validator(param_validator, base_tag, tag_prefix=None):\n    # pylint: disable-msg=C0111,W0621\n    if not tag_prefix:\n        tag_prefix = u'!~%s(' % param_validator.__name__\n    def multi_constructor(loader, tag_suffix, node):\n        def temp_validator(node, schema):\n            return param_validator(node, schema, *_split_params(tag_prefix, tag_suffix))\n        temp_validator.__name__ = str(tag_prefix + tag_suffix)\n        return ContructorValidatorNode(base_tag,\n                                       base_tag,\n                                       temp_validator)(loader, node)\n\n    yaml.add_multi_constructor(tag_prefix, multi_constructor)", "response": "Adds a parameterized validator function to the given tag prefix."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if nstr is a decimal string.", "response": "def prefixedDec(nstr, schema):\n    \"\"\"\n    !~~prefixedDec\n        corresponding strings in documents must begin with the\n        associated string in the schema, and the right part of strings\n        in documents must be decimal.\n    \"\"\"\n    if not nstr.startswith(schema):\n        return False\n    postfix = nstr[len(schema):]\n    try:\n        int(postfix)\n    except ValueError:\n        return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if input is a float.", "response": "def isFloat(nstr, schema):\n    \"\"\"\n    !~~isFloat\n    \"\"\"\n    if isinstance(nstr, (float, int, long)):\n        return True\n    elif not isinstance(nstr, basestring):\n        return False\n\n    try:\n        float(nstr)\n    except ValueError:\n        return False\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef digit(nstr, schema):\n    if isinstance(nstr, int):\n        nstr = str(nstr)\n    elif not isinstance(nstr, basestring):\n        return False\n\n    return nstr.isdigit()", "response": "Check if a string is a digit."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if a string is a valid uint value.", "response": "def uint(nstr, schema):\n    \"\"\"\n    !~~uint\n    \"\"\"\n    if isinstance(nstr, basestring):\n        if not nstr.isdigit():\n            return False\n        nstr = long(nstr)\n    elif not isinstance(nstr, (int, long)):\n        return False\n\n    return nstr > 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if a value is in a specific key.", "response": "def isIn(val, schema, name = None): # pylint: disable-msg=W0613\n    \"\"\"\n    !~~isIn(data)\n    \"\"\"\n    if name is None:\n        name = schema\n\n    if not _lists.has_key(name):\n        return False\n\n    try:\n        return val in _lists[name]\n    except TypeError:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef regex(val, schema, name = None): # pylint: disable-msg=W0613\n    if name is None:\n        name = schema\n\n    if not _regexs.has_key(name):\n        return False\n\n    try:\n        if _regexs[name](val):\n            return True\n    except TypeError:\n        pass\n\n    return False", "response": "Check if a value is a regex."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _transschema(x):\n    if isinstance(x, tuple):\n        return x.__class__(_transschema(x[0]), *x[1:])\n    elif isinstance(x, dict):\n        return dict((_qualify_map(key, _transschema(val)) for key, val in x.iteritems()))\n    elif isinstance(x, list):\n        return map(_transschema, x)\n    else:\n        return x", "response": "Transform a schema once loaded from its YAML representation to its\n    final internal representation."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvalidate a document according to a schema.", "response": "def validate(document, schema, log_qualifier = True):\n    \"\"\"\n    If the document is valid according to the schema, this function returns\n    True.\n    If the document is not valid according to the schema, errors are logged\n    then False is returned.\n    \"\"\"\n    if isinstance(schema, ValidatorNode):\n        if not validate(document, schema.content):\n            return False\n        if not schema.validator(document, schema.content):\n            if log_qualifier:\n                LOG.error(\"%r failed to validate with qualifier %s\", document, schema.validator.__name__)\n            return False\n        return True\n    elif isinstance(schema, dict):\n        if not isinstance(document, dict):\n            LOG.error(\"wanted a dictionary, got a %s\", document.__class__.__name__)\n            return False\n        generic = []\n        optional = {}\n        optionalnull = {}\n        mandatory = []\n        for key, schema_val in schema.iteritems():\n            if isinstance(key, ValidatorNode):\n                if key.mode == 'mandatory':\n                    mandatory.append((key, schema_val))\n                else:\n                    generic.append((key, schema_val))\n            elif isinstance(schema_val, Optional):\n                optional[key] = schema_val\n            elif isinstance(schema_val, OptionalNull):\n                optional[key] = schema_val\n                optionalnull[key] = True\n            else:\n                mandatory.append((key, schema_val))\n\n        doc_copy = document.copy()\n\n        for key, schema_val in mandatory:\n            if isinstance(key, ValidatorNode):\n                nb = 0\n                rm = []\n                for doc_key, doc_val in doc_copy.iteritems():\n                    if not validate(doc_key, key, False):\n                        continue\n\n                    nb += 1\n\n                    if validate(doc_val, schema_val):\n                        rm.append(doc_key)\n                    else:\n                        return False\n\n                if nb == 0:\n                    LOG.error(\"missing document %r for qualifier: %r\", key.content, key.validator.__name__)\n                    return False\n                elif key.min is not None and nb < key.min:\n                    LOG.error(\"no enough document %r for qualifier: %r (min: %r, found: %r)\", key.content, key.validator.__name__, key.min, nb)\n                    return False\n                elif key.max is not None and nb > key.max:\n                    LOG.error(\"too many document %r for qualifier: %r (max: %r, found: %r)\", key.content, key.validator.__name__, key.max, nb)\n                    return False\n                else:\n                    for x in rm:\n                        del doc_copy[x]\n                    continue\n\n            doc_val = doc_copy.get(key, Nothing)\n            if doc_val is Nothing:\n                LOG.error(\"missing key %r in document\", key)\n                return False\n\n            if helpers.is_scalar(schema_val):\n                if not validate(doc_val, schema_val):\n                    return False\n                del doc_copy[key]\n                continue\n\n            if schema_val.modifier:\n                for modname in schema_val.modifier:\n                    if modname in _modifiers:\n                        document[key] = _modifiers[modname](document[key])\n                        doc_val = _modifiers[modname](doc_val)\n                    elif hasattr(doc_val, modname):\n                        document[key] = getattr(document[key], modname)()\n                        doc_val = getattr(doc_val, modname)()\n\n            if _valid_len(key, doc_val, schema_val.min_len, schema_val.max_len) is False:\n                return False\n            if not validate(doc_val, schema_val.content):\n                return False\n            del doc_copy[key]\n\n        for key, schema_val in generic:\n            nb = 0\n            rm = []\n\n            for doc_key, doc_val in doc_copy.iteritems():\n                if not validate(doc_key, key, False):\n                    continue\n\n                nb += 1\n\n                if validate(doc_val, schema_val):\n                    rm.append(doc_key)\n                else:\n                    return False\n\n            if key.min is not None and nb < key.min:\n                LOG.error(\"no enough document %r for qualifier: %r (min: %r, found: %r)\", key.content, key.validator.__name__, key.min, nb)\n                return False\n            elif key.max is not None and nb > key.max:\n                LOG.error(\"too many document %r for qualifier: %r (max: %r, found: %r)\", key.content, key.validator.__name__, key.max, nb)\n                return False\n            else:\n                for x in rm:\n                    del doc_copy[x]\n                continue\n\n        for key, doc_val in doc_copy.iteritems():\n            schema_val = optional.get(key, Nothing)\n            if schema_val is Nothing:\n                LOG.error(\"forbidden key %s in document\", key)\n                return False\n            elif optionalnull.has_key(key) and doc_val is None:\n                continue\n            elif schema_val.min_len == 0 and doc_val is \"\":\n                continue\n\n            if schema_val.modifier:\n                for modname in schema_val.modifier:\n                    if modname in _modifiers:\n                        document[key] = _modifiers[modname](document[key])\n                        doc_val = _modifiers[modname](doc_val)\n                    elif hasattr(doc_val, modname):\n                        document[key] = getattr(document[key], modname)()\n                        doc_val = getattr(doc_val, modname)()\n                if optionalnull.has_key(key) and doc_val is None:\n                    continue\n                elif schema_val.min_len == 0 and doc_val is \"\":\n                    continue\n\n            if _valid_len(key, doc_val, schema_val.min_len, schema_val.max_len) is False:\n                return False\n            if not validate(doc_val, schema_val.content):\n                return False\n        return True\n    elif isinstance(schema, list):\n        if not isinstance(document, list):\n            LOG.error(\"wanted a list, got a %s\", document.__class__.__name__)\n        for elt in document:\n            # XXX: give a meaning when there are multiple element in a sequence of a schema?\n            if len(schema) < 2:\n                if not validate(elt, schema[0]):\n                    return False\n            elif isinstance(schema[0], dict):\n                tmp = {}\n                for x in schema:\n                    for key, val in x.iteritems():\n                        tmp[key] = val\n                if not validate(elt, tmp):\n                    return False\n            else:\n                if not validate(elt, schema[0]):\n                    return False\n        return True\n    elif isinstance(schema, Any):\n        return True\n    elif isinstance(schema, Scalar):\n        return helpers.is_scalar(document)\n    else: # scalar\n        if isinstance(schema, str):\n            schema = unicode(schema)\n        if isinstance(document, str):\n            document = unicode(document, 'utf8')\n        if schema.__class__ != document.__class__:\n            LOG.error(\"wanted a %s, got a %s\", schema.__class__.__name__, document.__class__.__name__)\n            return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npopulate entries dictionaries from index.", "response": "def _fill_entries(self):\n        \"\"\"Populate entries dictionaries from index.\"\"\"\n        for file in self.index.files:\n            path = self.index.paths[file.pathIndex]\n            data_offset = file.dataOffset\n            data_size = file.dataSize\n            obj = RAFEntry(self._data_handle, path, data_offset, data_size)\n            # Add to full path dictionary\n            assert path not in self.entries_full\n            self.entries_full[path.lower()] = obj\n            # Add to name dictionary\n            name = os.path.basename(path).lower()\n            if name not in self.entries_name:\n                self.entries_name[name] = []\n            self.entries_name[name].append(obj)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find(self, path=None, name=None):\n        if path is None and name is None:\n            # TODO: Correct error type\n            raise ValueError(\"Path or name is required.\")\n            # Entries are sorted by version number, so the last will be the most recent\n        # TODO: Reduce redundancy with RAFArchive\n        if path:\n            return self.entries_full[path.lower()][-1]\n        else:\n            return self.entries_name[name.lower()][-1][-1]", "response": "Returns the most recent version of the file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_re(self, pattern):\n        # TODO: Reduce redundancy with RAFArchive\n        pattern = re.compile(pattern, re.I)\n        for k, v in six.iteritems(self.entries_full):\n            if pattern.search(k):\n                # Most recent version will be last\n                yield v[-1]", "response": "Find the most recent versions of all entries whose path matches a given pattern."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef colorize(string, color, *args, **kwargs):\n    string = string.format(*args, **kwargs)\n    return color + string + colorama.Fore.RESET", "response": "Implements string formatting along with color specified in colorama. Fore\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef process_file(f, stop_tag=DEFAULT_STOP_TAG, details=True, strict=False, debug=False):\n\n    # by default do not fake an EXIF beginning\n    fake_exif = 0\n\n    # determine whether it's a JPEG or TIFF\n    data = f.read(12)\n    if data[0:4] in [b'II*\\x00', b'MM\\x00*']:\n        # it's a TIFF file\n        logger.debug(\"TIFF format recognized in data[0:4]\")\n        f.seek(0)\n        endian = f.read(1)\n        f.read(1)\n        offset = 0\n    elif data[0:2] == b'\\xFF\\xD8':\n        # it's a JPEG file\n        logger.debug(\"JPEG format recognized data[0:2]=0x%X%X\", ord_(data[0]), ord_(data[1]))\n        base = 2\n        logger.debug(\"data[2]=0x%X data[3]=0x%X data[6:10]=%s\",\n                     ord_(data[2]), ord_(data[3]), data[6:10])\n        while ord_(data[2]) == 0xFF and data[6:10] in (b'JFIF', b'JFXX', b'OLYM', b'Phot'):\n            length = ord_(data[4]) * 256 + ord_(data[5])\n            logger.debug(\" Length offset is %s\", length)\n            f.read(length - 8)\n            # fake an EXIF beginning of file\n            # I don't think this is used. --gd\n            data = b'\\xFF\\x00' + f.read(10)\n            fake_exif = 1\n            if base > 2:\n                logger.debug(\" Added to base\")\n                base = base + length + 4 - 2\n            else:\n                logger.debug(\" Added to zero\")\n                base = length + 4\n            logger.debug(\" Set segment base to 0x%X\", base)\n\n        # Big ugly patch to deal with APP2 (or other) data coming before APP1\n        f.seek(0)\n        # in theory, this could be insufficient since 64K is the maximum size--gd\n        data = f.read(base + 4000)\n        # base = 2\n        while 1:\n            logger.debug(\" Segment base 0x%X\", base)\n            if data[base:base + 2] == b'\\xFF\\xE1':\n                # APP1\n                logger.debug(\"  APP1 at base 0x%X\", base)\n                logger.debug(\"  Length: 0x%X 0x%X\", ord_(data[base + 2]),\n                             ord_(data[base + 3]))\n                logger.debug(\"  Code: %s\", data[base + 4:base + 8])\n                if data[base + 4:base + 8] == b\"Exif\":\n                    logger.debug(\"  Decrement base by 2 to get to pre-segment header (for compatibility with later code)\")\n                    base -= 2\n                    break\n                increment = increment_base(data, base)\n                logger.debug(\" Increment base by %s\", increment)\n                base += increment\n            elif data[base:base + 2] == b'\\xFF\\xE0':\n                # APP0\n                logger.debug(\"  APP0 at base 0x%X\", base)\n                logger.debug(\"  Length: 0x%X 0x%X\", ord_(data[base + 2]),\n                             ord_(data[base + 3]))\n                logger.debug(\"  Code: %s\", data[base + 4:base + 8])\n                increment = increment_base(data, base)\n                logger.debug(\" Increment base by %s\", increment)\n                base += increment\n            elif data[base:base + 2] == b'\\xFF\\xE2':\n                # APP2\n                logger.debug(\"  APP2 at base 0x%X\", base)\n                logger.debug(\"  Length: 0x%X 0x%X\", ord_(data[base + 2]),\n                             ord_(data[base + 3]))\n                logger.debug(\" Code: %s\", data[base + 4:base + 8])\n                increment = increment_base(data, base)\n                logger.debug(\" Increment base by %s\", increment)\n                base += increment\n            elif data[base:base + 2] == b'\\xFF\\xEE':\n                # APP14\n                logger.debug(\"  APP14 Adobe segment at base 0x%X\", base)\n                logger.debug(\"  Length: 0x%X 0x%X\", ord_(data[base + 2]),\n                             ord_(data[base + 3]))\n                logger.debug(\"  Code: %s\", data[base + 4:base + 8])\n                increment = increment_base(data, base)\n                logger.debug(\" Increment base by %s\", increment)\n                base += increment\n                logger.debug(\"  There is useful EXIF-like data here, but we have no parser for it.\")\n            elif data[base:base + 2] == b'\\xFF\\xDB':\n                logger.debug(\"  JPEG image data at base 0x%X No more segments are expected.\",\n                             base)\n                break\n            elif data[base:base + 2] == b'\\xFF\\xD8':\n                # APP12\n                logger.debug(\"  FFD8 segment at base 0x%X\", base)\n                logger.debug(\"  Got 0x%X 0x%X and %s instead\",\n                             ord_(data[base]),\n                             ord_(data[base + 1]),\n                             data[4 + base:10 + base])\n                logger.debug(\"  Length: 0x%X 0x%X\", ord_(data[base + 2]),\n                             ord_(data[base + 3]))\n                logger.debug(\"  Code: %s\", data[base + 4:base + 8])\n                increment = increment_base(data, base)\n                logger.debug(\"  Increment base by %s\", increment)\n                base += increment\n            elif data[base:base + 2] == b'\\xFF\\xEC':\n                # APP12\n                logger.debug(\"  APP12 XMP (Ducky) or Pictureinfo segment at base 0x%X\",\n                             base)\n                logger.debug(\"  Got 0x%X and 0x%X instead\", ord_(data[base]),\n                             ord_(data[base + 1]))\n                logger.debug(\"  Length: 0x%X 0x%X\",\n                             ord_(data[base + 2]),\n                             ord_(data[base + 3]))\n                logger.debug(\"Code: %s\", data[base + 4:base + 8])\n                increment = increment_base(data, base)\n                logger.debug(\"  Increment base by %s\", increment)\n                base += increment\n                logger.debug(\n                    \"  There is useful EXIF-like data here (quality, comment, copyright), but we have no parser for it.\")\n            else:\n                try:\n                    increment = increment_base(data, base)\n                    logger.debug(\"  Got 0x%X and 0x%X instead\",\n                                 ord_(data[base]),\n                                 ord_(data[base + 1]))\n                except IndexError:\n                    logger.debug(\"  Unexpected/unhandled segment type or file content.\")\n                    return {}\n                else:\n                    logger.debug(\"  Increment base by %s\", increment)\n                    base += increment\n        f.seek(base + 12)\n        if ord_(data[2 + base]) == 0xFF and data[6 + base:10 + base] == b'Exif':\n            # detected EXIF header\n            offset = f.tell()\n            endian = f.read(1)\n            #HACK TEST:  endian = 'M'\n        elif ord_(data[2 + base]) == 0xFF and data[6 + base:10 + base + 1] == b'Ducky':\n            # detected Ducky header.\n            logger.debug(\"EXIF-like header (normally 0xFF and code): 0x%X and %s\",\n                         ord_(data[2 + base]), data[6 + base:10 + base + 1])\n            offset = f.tell()\n            endian = f.read(1)\n        elif ord_(data[2 + base]) == 0xFF and data[6 + base:10 + base + 1] == b'Adobe':\n            # detected APP14 (Adobe)\n            logger.debug(\"EXIF-like header (normally 0xFF and code): 0x%X and %s\",\n                         ord_(data[2 + base]), data[6 + base:10 + base + 1])\n            offset = f.tell()\n            endian = f.read(1)\n        else:\n            # no EXIF information\n            logger.debug(\"No EXIF header expected data[2+base]==0xFF and data[6+base:10+base]===Exif (or Duck)\")\n            logger.debug(\"Did get 0x%X and %s\",\n                         ord_(data[2 + base]), data[6 + base:10 + base + 1])\n            return {}\n    else:\n        # file format not recognized\n        logger.debug(\"File format not recognized.\")\n        return {}\n\n    endian = chr(ord_(endian[0]))\n    # deal with the EXIF info we found\n    logger.debug(\"Endian format is %s (%s)\", endian, {\n        'I': 'Intel',\n        'M': 'Motorola',\n        '\\x01': 'Adobe Ducky',\n        'd': 'XMP/Adobe unknown'\n    }[endian])\n\n    hdr = ExifHeader(f, endian, offset, fake_exif, strict, debug, details)\n    ifd_list = hdr.list_ifd()\n    thumb_ifd = False\n    ctr = 0\n    for ifd in ifd_list:\n        if ctr == 0:\n            ifd_name = 'Image'\n        elif ctr == 1:\n            ifd_name = 'Thumbnail'\n            thumb_ifd = ifd\n        else:\n            ifd_name = 'IFD %d' % ctr\n        logger.debug('IFD %d (%s) at offset %s:', ctr, ifd_name, ifd)\n        hdr.dump_ifd(ifd, ifd_name, stop_tag=stop_tag)\n        ctr += 1\n    # EXIF IFD\n    exif_off = hdr.tags.get('Image ExifOffset')\n    if exif_off:\n        logger.debug('Exif SubIFD at offset %s:', exif_off.values[0])\n        hdr.dump_ifd(exif_off.values[0], 'EXIF', stop_tag=stop_tag)\n\n    # deal with MakerNote contained in EXIF IFD\n    # (Some apps use MakerNote tags but do not use a format for which we\n    # have a description, do not process these).\n    if details and 'EXIF MakerNote' in hdr.tags and 'Image Make' in hdr.tags:\n        hdr.decode_maker_note()\n\n    # extract thumbnails\n    if details and thumb_ifd:\n        hdr.extract_tiff_thumbnail(thumb_ifd)\n        hdr.extract_jpeg_thumbnail()\n\n    # parse XMP tags (experimental)\n    if debug and details:\n        xmp_string = b''\n        # Easy we already have them\n        if 'Image ApplicationNotes' in hdr.tags:\n            logger.debug('XMP present in Exif')\n            xmp_string = make_string(hdr.tags['Image ApplicationNotes'].values)\n        # We need to look in the entire file for the XML\n        else:\n            logger.debug('XMP not in Exif, searching file for XMP info...')\n            xml_started = False\n            xml_finished = False\n            for line in f:\n                open_tag = line.find(b'<x:xmpmeta')\n                close_tag = line.find(b'</x:xmpmeta>')\n\n                if open_tag != -1:\n                    xml_started = True\n                    line = line[open_tag:]\n                    logger.debug('XMP found opening tag at line position %s' % open_tag)\n\n                if close_tag != -1:\n                    logger.debug('XMP found closing tag at line position %s' % close_tag)\n                    line_offset = 0\n                    if open_tag != -1:\n                        line_offset = open_tag\n                    line = line[:(close_tag - line_offset) + 12]\n                    xml_finished = True\n\n                if xml_started:\n                    xmp_string += line\n\n                if xml_finished:\n                    break\n\n            logger.debug('XMP Finished searching for info')\n        if xmp_string:\n            hdr.parse_xmp(xmp_string)\n\n    return hdr.tags", "response": "Process an image file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a string to a valid filename.", "response": "def legitimize(text):\n    \"\"\"Converts a string to a valid filename.\n    \"\"\"\n    import platform\n    os_ = platform.system()\n    # POSIX systems\n    text = text.translate({\n        0: None,\n        ord('/'): '-',\n        ord('|'): '-',\n    })\n\n    if os_ == 'Windows':\n        # Windows (non-POSIX namespace)\n        text = text.translate({\n            # Reserved in Windows VFAT and NTFS\n            ord(':'): '-',\n            ord('*'): '-',\n            ord('?'): '-',\n            ord('\\\\'): '-',\n            ord('\\\"'): '\\'',\n            # Reserved in Windows VFAT\n            ord('+'): '-',\n            ord('<'): '-',\n            ord('>'): '-',\n            ord('['): '(',\n            ord(']'): ')',\n        })\n    else:\n        # *nix\n        if os_ == 'Darwin':\n            # Mac OS HFS+\n            text = text.translate({\n                ord(':'): '-',\n            })\n\n        # Remove leading .\n        if text.startswith(\".\"):\n            text = text[1:]\n\n    text = text[:82]  # Trim to 82 Unicode characters long\n    return text"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmodifying the content of a file.", "response": "def modify_content(file, old, new):\n    \"\"\"\u66ff\u6362\u6587\u4ef6\u4e2d\u7684\u6307\u5b9a\u5185\u5bb9\uff0c\u9010\u884c\u8fdb\u884c\"\"\"\n    try:\n        lines = open(file, 'r').readlines()\n        f_len = len(lines) - 1\n        for i in range(f_len):\n            if old in lines[i]:\n                lines[i] = lines[i].replace(old, new)\n        open(file, 'w').writelines(lines)\n    except Exception as e:\n        print(e)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes a file from the archive.", "response": "def batch_del_file(path, in_name=None, yn=None):\n    \"\"\"\u6279\u91cf\u5220\u9664\u6587\u4ef6\uff08\u7ed9\u51fa\u4e00\u5b9a\u7684\u89c4\u5219\uff09\"\"\"\n    if in_name is None:\n        file_to_del = [os.path.join(path, i) for i in os.listdir(path)]\n    else:\n        file_to_del = [os.path.join(path, i) for i in os.listdir(path) if in_name in i]\n    print('\u4ee5\u4e0b\u662f\u8981\u5220\u9664\u7684\u6587\u4ef6\u5217\u8868\uff1a\\n')\n    print(file_to_del)\n\n    if yn is None:\n        yn = input('\u5220\u9664\u4ee5\u4e0a\u6587\u4ef6\uff08\u8f93\u5165\uff1ay/n\uff09, \u4fdd\u7559\u90e8\u5206\u6587\u4ef6\uff08\u8f93\u5165\uff1ak\uff09\uff1a')\n\n    if yn == 'k':\n        file_to_save = []\n        while True:\n            f = input('\u8bf7\u8f93\u5165\u8981\u4fdd\u7559\u7684\u6587\u4ef6\u540d\uff08\u8f93\u5165\u201cb\u201d\u7ed3\u675f\uff09\uff1a')\n            if f == 'b':\n                break\n            file_to_save.append(f)\n        file_to_del = [i for i in file_to_del if i not in file_to_save]\n        for file in file_to_del:\n            os.remove(file)\n            print('\u5df2\u5220\u9664\uff1a', file)\n    elif yn == 'y' or yn == 'yes':\n        for file in file_to_del:\n            os.remove(file)\n            print('\u5df2\u5220\u9664\uff1a', file)\n    else:\n        print('\u6ca1\u6709\u4efb\u4f55\u6587\u4ef6\u88ab\u5220\u9664\uff01')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef batch_move_file(path, dest, in_name=None, copy=True):\n    assert os.path.exists(path), '%s \u6587\u4ef6\u5939\u4e0d\u5b58\u5728' % path\n    assert os.path.exists(dest), '%s \u6587\u4ef6\u5939\u4e0d\u5b58\u5728' % dest\n    if copy:\n        mv = shutil.copy\n    else:\n        mv = shutil.move\n\n    if in_name is None:\n        file_list = os.listdir(path)\n    else:\n        file_list = [i for i in os.listdir(path) if in_name in i]\n\n    if len(file_list) != 0:\n        for file in file_list:\n            f = os.path.join(path, file)\n            d = os.path.join(dest, file)\n            mv(f, d)\n            print('\u5df2\u8f6c\u79fb\uff1a%s' % f)\n    else:\n        if in_name is None:\n            print('%s \u4e2d\u6ca1\u6709\u6587\u4ef6' % path)\n        else:\n            print('%s \u4e2d\u6ca1\u6709\u5305\u542b\u3010 %s \u3011\u7684\u6587\u4ef6' % (path, in_name))", "response": "move_file - Move a file to another location"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrenaming a file in a folder", "response": "def batch_rename_file(path, f, t):\n    \"\"\"\u6839\u636ereplaces\u4e2d\u5b9a\u4e49\u7684\u89c4\u5219\uff0c\u6279\u91cf\u91cd\u547d\u540d\"\"\"\n    files = os.listdir(path)\n    for file in files:\n        if f in file:\n            new_fn = file.replace(f, t)\n            old = os.path.join(path, file)\n            new = os.path.join(path, new_fn)\n            os.rename(old, new)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_zip(folder_path, output_filename):\n    cwd = os.getcwd()\n\n    # \u83b7\u53d6\u9700\u8981\u6253\u5305\u7684\u6587\u4ef6\u5217\u8868\n    file_lists = []\n    for root, dirs, files in os.walk(folder_path):\n        for file in files:\n            file_1 = os.path.join(root, file).replace(folder_path + '/', '')\n            if 'zip' not in file_1:\n                file_lists.append(file_1)\n\n    # \u5c06\u6587\u4ef6\u5217\u8868\u6253\u5305\u6210zip\n    os.chdir(folder_path)\n    with zipfile.ZipFile(output_filename, 'w') as myzip:\n        for file in file_lists:\n            myzip.write(file)\n\n    # \u5c06\u5de5\u4f5c\u76ee\u5f55\u5207\u6362\u56de\u539f\u59cb\n    os.chdir(cwd)", "response": "make_zip - create a zip file from folder_path"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef channel_width(im, chanangle=None, *, chanapproxangle=None,\n                  isccsedge=False):\n    \"\"\"Get an estimation of the channel width.\n\n    Parameters:\n    -----------\n    im: 2d array\n        The channel image\n    chanangle: number, optional\n        The angle of the channel (None if unknown)\n    chanapproxangle: number, optional\n        If chanangle is None, the approximate channel angle\n    isccsedge: boolean, default False\n        Set to True if im is the dft of egde.\n               False if it is an image of a channel.\n\n    Returns:\n    --------\n    width: number\n        The channel width\n    angle: number\n        The corresponding angle\n\n    Notes:\n    ------\n\n    This function assumes two parallel lines along angle chanangle.\n    The perpendicular line in the fourrier plane will have a mark of this,\n    under the form of an oscillation at some frequency corresponding\n    to the distance between the two parallel lines.\n    This can be extracted by another fft.\n\n    This second fft might have large components at low frequency,\n    So the first few frequencies are neglected.\n    The threshold is the first position below mean\n\n    If the chanangle is not specified, the direction with higher\n    contribution will be picked.\n\n    If chanapproxangle is given, only angles close to this angle\n    are taken into account\n    \"\"\"\n    # check input is numpy array\n    im = np.asarray(im)\n\n    # Compute the dft if it is not already done\n    if not isccsedge:\n        im = reg.dft_optsize(np.float32(edge(im)))\n\n    # save the truesize for later use\n    truesize = im.shape\n\n    # get centered magnitude squared (This changes the size)\n    im = reg.centered_mag_sq_ccs(im)\n\n    # if the channel direction is not given, deduce it from channel_angle\n    if chanangle is None:\n        chanangle = channel_angle(im, isshiftdftedge=True,\n                                  chanapproxangle=chanapproxangle,\n                                  truesize=truesize)\n\n    # get vector perpendicular to angle\n    fdir = np.asarray([math.cos(chanangle), -math.sin(chanangle)])  # y,x = 0,1\n\n    # need to be in the RHS of the cadran for rfft\n    if fdir[1] < 0:\n        fdir *= -1\n\n    # get center of shifted fft\n    center = np.asarray([im.shape[0] // 2, 0])\n\n    # get size\n    shape = np.asarray([im.shape[0] // 2, im.shape[1]])\n\n    # get evenly spaced positions between 0 and 1 (not included)\n    # should be replaced with linspace\n    pos = np.r_[:1:(shape.min() + 1) * 1j][:-1]\n\n    # get index of a line of length 1 in normalized units from center\n    # in direction of chdir\n    idx = ((fdir * shape)[:, np.newaxis].dot(pos[np.newaxis])\n           + center[:, np.newaxis])\n\n    # get the line\n    idx = np.float32(idx)\n    f = cv2.remap(np.float32(im), idx[1, :], idx[0, :], cv2.INTER_LINEAR)\n    f = np.squeeze(f)\n\n    # The central line of the fft will have a periodic feature for parallel\n    # lines which we can detect with fft\n    f = abs(irfft(f**2))\n    # filter to avoid \"interferences\"\n    f = gaussian_filter(f, 1)\n    # the offset is determined by the first pixel below mean\n    wmin = np.nonzero(f - f.mean() < 0)[0][0]\n\n    \"\"\"\n    import matplotlib.pyplot as plt\n    plt.figure()\n    plt.plot(f,'x')\n    plt.plot([wmin,wmin],[0,f.max()])\n    plt.plot([0,500],[f.mean()+3*f.std(),f.mean()+3*f.std()])\n    #\"\"\"\n\n    # find max excluding the first few points\n    ret = reg.get_peak_pos(f[wmin:f.size // 2])\n\n    # return max and corresponding angle\n    return (wmin + ret), chanangle", "response": "This function returns an estimation of the channel width."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef channel_angle(im, chanapproxangle=None, *, isshiftdftedge=False,\n                  truesize=None):\n    \"\"\"Extract the channel angle from the rfft\n\n    Parameters:\n    -----------\n    im: 2d array\n        The channel image\n    chanapproxangle: number, optional\n        If not None, an approximation of the result\n    isshiftdftedge: boolean, default False\n        If The image has already been treated:\n        (edge, dft, fftshift), set to True\n    truesize: 2 numbers, required if isshiftdftedge is True\n        The true size of the image\n\n    Returns:\n    --------\n    angle: number\n        The channel angle\n\n\n    \"\"\"\n    im = np.asarray(im)\n    # Compute edge\n    if not isshiftdftedge:\n        im = edge(im)\n    return reg.orientation_angle(im, isshiftdft=isshiftdftedge,\n                                 approxangle=chanapproxangle,\n                                 truesize=truesize)", "response": "Extract the channel angle from the rfft\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nextracting the edges using Scharr kernel (Sobel optimized for rotation invariance) Parameters: ----------- im: 2d array The image blurRadius: number, default 10 The gaussian blur raduis (The kernel has size 2*blurRadius+1) imblur: 2d array, OUT If not None, will be fille with blurred image Returns: -------- out: 2d array The edges of the images computed with the Scharr algorithm", "response": "def Scharr_edge(im, blurRadius=10, imblur=None):\n    \"\"\"Extract the edges using Scharr kernel (Sobel optimized for rotation\n    invariance)\n\n    Parameters:\n    -----------\n    im: 2d array\n        The image\n    blurRadius: number, default 10\n        The gaussian blur raduis (The kernel has size 2*blurRadius+1)\n    imblur: 2d array, OUT\n        If not None, will be fille with blurred image\n\n    Returns:\n    --------\n    out: 2d array\n        The edges of the images computed with the Scharr algorithm\n\n    \"\"\"\n    im = np.asarray(im, dtype='float32')\n    blurRadius = 2 * blurRadius + 1\n    im = cv2.GaussianBlur(im, (blurRadius, blurRadius), 0)\n    Gx = cv2.Scharr(im, -1, 0, 1)\n    Gy = cv2.Scharr(im, -1, 1, 0)\n    ret = cv2.magnitude(Gx, Gy)\n    if imblur is not None and imblur.shape == im.shape:\n        imblur[:, :] = im\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef register_channel(im0, im1, scale=None, ch0angle=None,\n                     chanapproxangle=None):\n    \"\"\"Register the images assuming they are channels\n\n    Parameters:\n    -----------\n    im0: 2d array\n        The first image\n    im1: 2d array\n        The second image\n    scale: number, optional\n        The scale difference if known\n    ch0angle: number, optional\n        The angle of the channel in the first image if known\n    chanapproxangle: number, optional\n        The approximate angle for both images if known\n\n    Returns:\n    --------\n    angle: number\n        The angle difference\n    scale: number\n        The scale difference\n    [y, x]: 2 numbers\n        The offset\n    e2: 2d array\n        The second image rotated and translated for performances reasons\n\n    \"\"\"\n    im0 = np.asarray(im0)\n    im1 = np.asarray(im1)\n    # extract the channels edges\n    e0 = edge(im0)\n    e1 = edge(im1)\n    fe0, fe1 = reg.dft_optsize_same(np.float32(e0), np.float32(e1))\n\n    # compute the angle and channel width of biggest angular feature\n    w0, a0 = channel_width(\n        fe0, isccsedge=True, chanapproxangle=chanapproxangle)\n    w1, a1 = channel_width(\n        fe1, isccsedge=True, chanapproxangle=chanapproxangle)\n\n    # get angle diff\n    angle = reg.clamp_angle(a0 - a1)\n    if ch0angle is not None:\n        a0 = ch0angle\n        a1 = a0 - angle\n\n    # if the scale is unknown, ratio of the channels\n    if scale is None:\n        scale = w1 / w0\n    #scale and rotate\n    e2 = reg.rotate_scale(e1, angle, scale)\n    # get edge from scaled and rotated im1\n    fe2 = reg.dft_optsize(np.float32(e2), shape=fe0.shape)\n    # find offset\n    y, x = reg.find_shift_dft(fe0, fe2, isccs=True)\n    # return all infos\n    return angle, scale, [y, x], e2", "response": "Register the images assuming they are channels"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef uint8sc(im):\n    im = np.asarray(im)\n    immin = im.min()\n    immax = im.max()\n    imrange = immax - immin\n    return cv2.convertScaleAbs(im - immin, alpha=255 / imrange)", "response": "Scale the image to uint8"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngreeting each person by name.", "response": "def handle(self, args):\n        \"\"\"\n        Greet each person by name.\n        \"\"\"\n        salutation = {\n            'french': 'Bonjour',\n            'spanish': 'Hola',\n            'english': 'Hello',\n        }[args.lang.lower()]\n\n        output = []\n        for name in args.name:\n            output.append(\"{} {}!\".format(salutation, name))\n        return \"\\n\".join(output)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntries to solve the board described by board_string. Return sequence of summaries that describe how to get to the solution.", "response": "def capture(board):\n    \"\"\"Try to solve the board described by board_string.\n\n    Return sequence of summaries that describe how to get to the solution.\n    \"\"\"\n    game = Game()\n    v = (0, 0)\n    stub_actor = base.Actor('capture', v, v, v, v, v, v, v, v, v)\n    root = base.State(board, stub_actor, stub_actor,\n                      turn=1, actions_remaining=1)\n    solution_node = None\n    for eot in game.all_ends_of_turn(root):\n        # check for a solution\n        if eot.is_mana_drain:  # quick check before checking whole board\n            if eot.parent.board.is_empty():\n                solution_node = eot\n                break\n    # if solution found, build the list of swaps\n    solution_sequence = list()  # empty sequence (no solution) by default\n    if solution_node:\n        node = solution_node\n        while node:\n            # record each swap in the path to the root\n            if not isinstance(node, base.Swap):\n                node = node.parent\n                continue\n            summary = base.Summary(node.parent.board, node.position_pair,\n                                   None, None, None)\n            solution_sequence.append(summary)\n            node = node.parent\n    return tuple(reversed(solution_sequence))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _disallow_state(self, state):\n        disallow_methods = (self._is_duplicate_board,\n                            self._is_impossible_by_count)\n        for disallow_method in disallow_methods:\n            if disallow_method(state):\n                return True\n        return False", "response": "Disallow states that are not useful to continue simulating."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _is_impossible_by_count(self, state):\n        # count all the tile types and name them for readability\n        counts = {tile_type: 0 for tile_type in base.Tile._all_types}\n        standard_wildcard_type = '2'\n        for p, tile in state.board.positions_with_tile():\n            # count all wildcards as one value\n            tile_type = tile._type\n            try:\n                int(tile_type)\n                counts[standard_wildcard_type] += 1\n            except ValueError:\n                counts[tile_type] += 1\n        skullbomb = counts['*']\n        skull = counts['s']\n        wildcard = counts[standard_wildcard_type]\n        red = counts['r']\n        green = counts['g']\n        blue = counts['b']\n        yellow = counts['y']\n        exp = counts['x']\n        money = counts['m']\n        # always allow skullbomb with enough skulls\n        if skullbomb and skullbomb + skull >= 3:\n            return False\n        # always allow wildcard with enough of one color\n        if wildcard:\n            if any(wildcard + color >= 3\n                   for color in (red, green, blue, yellow)):\n                return False\n        # disallow simple cases since special cases didn't occur\n        if any(tile and tile < 3 for tile in (red, green, blue, yellow,\n                                              exp, money, skull)):\n            return True\n        # allow the state if counts seem ok\n        return False", "response": "Disallow any board that has insufficient tile count to solve."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_or_graft(self, board):\n        is_duplicate_board = True  # assume same until find a difference\n        # compare each position\n        node = self\n        for p, new_tile in board.positions_with_tile():\n            found_tile = False  # assume no tile in same position until found\n            for child in node.children:\n                if child.tile == new_tile:\n                    # same tile found in this position --> continue this branch\n                    node = child\n                    found_tile = True\n                    break\n            if found_tile:\n                pass  # go on to the next position\n            else:\n                # different tile --> start new branch and mark not exact match\n                child = _DuplicateTree(new_tile)\n                node.graft_child(child)\n                node = child\n                is_duplicate_board = False  # this will get set many times. ok\n        return is_duplicate_board", "response": "Find or create a tree with each level corresponding to a fixed position on\n        board."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_capture(self):\n        # game\n        game_image = self._game_image_from_screen('capture')\n        if game_image is None:\n            return\n        # board\n        board = self._board_from_game_image(game_image)\n        if board is None:\n            return\n        if board.is_empty():\n            return\n        return board", "response": "Return the capture board or None if can t find it."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the versus board player opponent and extra actions.", "response": "def get_versus(self):\n        \"\"\"Return the versus board, player, opponent and extra actions.\n        Return None for any parts that can't be found.\n        \"\"\"\n        # game\n        game_image = self._game_image_from_screen('versus')\n        if game_image is None:\n            return None, None, None, None  # nothing else will work\n        # board\n        board = self._board_from_game_image(game_image)  # may be None\n        # safety check. there should be no blanks in a versus board\n        if board:\n            for p, tile in board.positions_with_tile():\n                if tile.is_blank():\n                    board = None\n        # actors\n        player = self._actor_from_game_image('player', game_image)\n        opponent = self._actor_from_game_image('opponent', game_image)\n        # extra actions\n        extra_actions = self._count_extra_actions(game_image)\n        return board, player, opponent, extra_actions"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _game_image_from_screen(self, game_type):\n        # screen\n        screen_img = self._screen_shot()\n        # game image\n        game_rect = self._game_finders[game_type].locate_in(screen_img)\n        if game_rect is None:\n            return\n        t, l, b, r = game_rect\n        game_img = screen_img[t:b, l:r]\n        return game_img", "response": "Return the game image of the given game type from the screen."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a board object matching the board in the game image.", "response": "def _board_from_game_image(self, game_image):\n        \"\"\"Return a board object matching the board in the game image.\n        Return None if any tiles are not identified.\n        \"\"\"\n        # board image\n        board_rect = self._board_tools['board_region'].region_in(game_image)\n        t, l, b, r = board_rect\n        board_image = game_image[t:b, l:r]\n        # board grid and tiles --> fill in a Board object\n        board = Board()\n        grid = self._board_tools['grid']\n        tile_id = self._board_tools['tile_id']\n        for p, borders in grid.borders_by_grid_position(board_image):\n            t, l, b, r = borders\n            tile = board_image[t:b, l:r]\n            tile_character = tile_id.identify(tile)\n            if tile_character is None:\n                return None  # soft failure\n            board[p] = Tile.singleton(tile_character)\n        return board"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _actor_from_game_image(self, name, game_image):\n        HEALTH_MAX = 100\n        MANA_MAX = 40\n        # get the set of tools for investigating this actor\n        tools = {'player': self._player_tools,\n                 'opponent': self._oppnt_tools}[name]\n\n        # setup the arguments to be set:\n        args = [name]\n\n        # health:\n        t, l, b, r = tools['health_region'].region_in(game_image)\n        health_image = game_image[t:b, l:r]\n        health_image = numpy.rot90(health_image)  # upright for the TankLevel\n        how_full = tools['health_tank'].how_full(health_image)\n        if how_full is None:\n            return None  # failure\n        health = int(round(HEALTH_MAX * how_full))\n        args.append((health, HEALTH_MAX))\n        # mana\n        for color in ('r', 'g', 'b', 'y'):\n            t, l, b, r = tools[color + '_region'].region_in(game_image)\n            mana_image = game_image[t:b, l:r]\n            how_full = tools[color + '_tank'].how_full(mana_image)\n            if how_full is None:\n                return None  # failure\n            mana = int(round(MANA_MAX * how_full))\n            args.append((mana, MANA_MAX))\n        # experience and coins simply start at zero\n        x_m = (0, 1000), (0, 1000)\n        args.extend(x_m)\n        # hammer and scroll are unused\n        h_c = (0, 0), (0, 0)\n        args.extend(h_c)\n        # build the actor and return it\n        return Actor(*args)", "response": "Return an actor object matching the one in the game image."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncount the number of extra actions for player in this turn.", "response": "def _count_extra_actions(self, game_image):\n        \"\"\"Count the number of extra actions for player in this turn.\"\"\"\n        proportional = self._bonus_tools['extra_action_region']\n        # Use ProportionalRegion to isolate the extra actions area\n        t, l, b, r = proportional.region_in(game_image)\n        token_region = game_image[t:b, l:r]\n        # Use TemplateFinder (multiple) to check for extra actions\n        game_h, game_w = game_image.shape[0:2]\n        token_h = int(round(game_h * 27.0 / 960))\n        token_w = int(round(game_w * 22.0 / 1280))\n        sizes = (token_h, token_w),\n        # sizes change every time so just remake it.\n        # thresholds are tight since need to count conservatively\n        finder = v.TemplateFinder(pq_data.extra_action_template,\n                                  sizes=sizes,\n                                  acceptable_threshold=0.1,\n                                  immediate_threshold=0.1)\n        found_tokens = finder.locate_multiple_in(token_region)\n        return len(found_tokens)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ends_of_one_state(self, root=None, root_eot=None):\n        # basic confirmation of valid arguments\n        self._argument_gauntlet(root_eot, root)\n        # setup the starting state\n        if root:\n            start_state = root\n        else:\n            start_state = State(root_eot.parent.board.copy(),\n                                root_eot.parent.player.copy(),\n                                root_eot.parent.opponent.copy(),\n                                root_eot.parent.turn + 1, 1)\n            root_eot.graft_child(start_state)\n        # track states that are stable - i.e. no remaining chain reactions\n        ready_for_action = [start_state]\n        # simulate all actions for each state until reaching EOTs\n        while ready_for_action:\n            ready_state = ready_for_action.pop()\n            # handle states that have run out of actions (end of turn)\n            if ready_state.actions_remaining <= 0:\n                root_eot = self._simulated_EOT(ready_state)\n                yield root_eot\n                continue  # no more simulation for an EOT\n            # handle swaps when there are actions remaining\n            for swap_result in self._simulated_swap_results(ready_state):\n                # handle any chain reactions\n                if swap_result.actions_remaining \\\n                        >= ready_state.actions_remaining:\n                    already_used_bonus = True\n                else:\n                    already_used_bonus = False\n                chain_result = self._simulated_chain_result(swap_result,\n                                                            already_used_bonus)\n                # chain results may be filtered so test first\n                if chain_result:\n                    ready_for_action.append(chain_result)\n            #at this point all swaps have been tried\n            #if nothing was valid, it's a manadrain\n            if not tuple(ready_state.children):\n                mana_drain_eot = self._simulated_mana_drain(ready_state)\n                yield mana_drain_eot\n                continue\n            # if something was valid, now spells can be simulated\n            else:\n                pass", "response": "Simulate a complete turn from one state only and generate each entry in the simulation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsimulating one complete turn to completion and generate each end of the tree that is reached during the simulation.", "response": "def ends_of_next_whole_turn(self, root):\n        \"\"\"Simulate one complete turn to completion and generate each end of\n        turn reached during the simulation.\n\n        Note on mana drain:\n        Generates but does not continue simulation of mana drains.\n\n        Arguments:\n        root: a start state with no parent\n        \"\"\"\n        # simple confirmation that the root is actually a root.\n        # otherwise it may seem to work but would be totally out of spec\n        if root.parent:\n            raise ValueError('Unexpectedly received a node with a parent for'\n                             ' root:\\n{}'.format(root))\n        # build the list of eots (or just the root if first turn) to be run\n        leaves = list(root.leaves())\n        kw_starts = list()\n        if leaves[0] is root:\n            # build ends of state kwargs as only the root\n            kw_starts.append({'root': root})\n        else:\n            # build ends of state kwargs as eots in the tree\n            for leaf in leaves:\n                # ignore mana drains\n                if not leaf.is_mana_drain:\n                    kw_starts.append({'root_eot': leaf})\n        # run a single turn for each starting point\n        for kw_start in kw_starts:\n            for eot in self.ends_of_one_state(**kw_start):\n                yield eot"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef all_ends_of_turn(self, root):\n        # simple confirmation that the root is actually a root.\n        # otherwise it may seem to work but would be totally out of spec\n        if root.parent:\n            raise ValueError('Unexpectedly received a node with a parent for'\n                             ' root:\\n{}'.format(root))\n        # run a single turn for each eot from a stack\n        jobs = [root]\n        while jobs:\n            random_job_index = random.randint(0, len(jobs) - 1)\n            start_eot = jobs.pop(random_job_index)\n            # special case: handle the root once\n            if start_eot is root:\n                kw_root = {'root': start_eot}\n            else:\n                kw_root = {'root_eot': start_eot}\n            for eot in self.ends_of_one_state(**kw_root):\n                # only continue simulating non-mana drains\n                if not eot.is_mana_drain:\n                    jobs.append(eot)\n                yield eot", "response": "Simulate the root and continue generating ends of turn until everything has reached mana drain."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsimulates any chain reactions.", "response": "def _simulated_chain_result(self, potential_chain, already_used_bonus):\n        \"\"\"Simulate any chain reactions.\n\n        Arguments:\n        potential_chain: a state to be tested for chain reactions\n        already_used_bonus: boolean indicating whether a bonus turn was already\n            applied during this action\n\n        Return: final result state or None (if state is filtered out in capture)\n\n        Note that if there is no chain reaction, the final result is the\n        same as the original state received.\n        \"\"\"\n        while potential_chain:\n            # hook for capture game optimizations. no effect in base\n            # warning: only do this ONCE for any given state or it will\n            # always filter the second time\n            if self._disallow_state(potential_chain):\n                potential_chain.graft_child(Filtered())\n                return None  # no more simulation for this filtered state\n            result_board, destroyed_groups = \\\n                potential_chain.board.execute_once(random_fill=\n                                                   self.random_fill)\n            # yield the state if nothing happened during execution (chain done)\n            if not destroyed_groups:\n                # yield this state as the final result of the chain\n                return potential_chain\n            # attach the transition\n            chain = ChainReaction()\n            potential_chain.graft_child(chain)\n            # attach the result state\n            if already_used_bonus:\n                # disallow bonus action if already applied\n                bonus_action = 0\n            else:\n                # allow bonus action once and then flag as used\n                bonus_action = any(len(group) >= 4\n                                   for group in destroyed_groups)\n                already_used_bonus = True\n            cls = potential_chain.__class__\n            chain_result = cls(board=result_board,\n                               turn=potential_chain.turn,\n                               actions_remaining=\n                               potential_chain.actions_remaining + bonus_action,\n                               player=potential_chain.player.copy(),\n                               opponent=potential_chain.opponent.copy())\n            # update the player and opponent\n            base_attack = \\\n                chain_result.active.apply_tile_groups(destroyed_groups)\n            chain_result.passive.apply_attack(base_attack)\n            chain.graft_child(chain_result)\n            # prepare to try for another chain reaction\n            potential_chain = chain_result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsimulating a normal or mana drain EOT and return it.", "response": "def _simulated_EOT(self, state):\n        \"\"\"Simulate a normal or mana drain EOT and return it.\"\"\"\n        # determine if this is a manadrain or just end of turn\n        is_manadrain = True  # default mana drain until valid swap found\n        for swap_pair in state.board.potential_swaps():\n            result_board, destroyed_groups = \\\n                state.board.execute_once(swap=swap_pair,\n                                         random_fill=self.random_fill)\n            if destroyed_groups:\n                is_manadrain = False\n                break  # stop when the first valid swap found\n        # attach appropriate EOT or ManaDrain\n        if is_manadrain:\n            end = self._simulated_mana_drain(state)\n        else:\n            end = EOT(False)\n            state.graft_child(end)\n        return end"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\napplying mana drain effects to this state attach a mana drain EOT and return the mana drain EOT.", "response": "def _simulated_mana_drain(self, mana_drain_state):\n        \"\"\"Apply mana drain effects to this state, attach a mana drain EOT\n        and return the mana drain EOT.\"\"\"\n        # clear all mana\n        mana_drain_state.player.apply_mana_drain()\n        mana_drain_state.opponent.apply_mana_drain()\n        # force change of turn\n        mana_drain_state.actions_remaining = 0\n        # randomize the board if this game uses random fill\n        if self.random_fill:\n            random_start_board = mana_drain_state.board.random_start_board()\n            mana_drain_state.board = random_start_board\n        # attach the mana drain EOT\n        mana_drain = EOT(True)\n        mana_drain_state.graft_child(mana_drain)\n        return mana_drain"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef random_start_board(cls):\n        board = cls()\n        board._random_fill()\n        destructions = True  # prime the loop\n        while destructions:\n            board, destructions = board.execute_once()\n            board._random_fill()\n        return board", "response": "Produce a full stable start board with random tiles."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef execute_once(self, swap=None,\n                     spell_changes=None, spell_destructions=None,\n                     random_fill=False):\n        \"\"\"Execute the board only one time. Do not execute chain reactions.\n\n        Arguments:\n        swap - pair of adjacent positions\n        spell_changes - sequence of (position, tile) changes\n        spell_destructions - sequence of positions to be destroyed\n\n        Return: (copy of the board, destroyed tile groups)\n        \"\"\"\n        bcopy = self.copy()  # work with a copy, not self\n        total_destroyed_tile_groups = list()\n        # swap if any\n        bcopy._swap(swap)\n        # spell changes if any\n        bcopy._change(spell_changes)\n        # spell destructions and record if any\n        # first convert simple positions to groups\n        spell_destructions = spell_destructions or tuple()\n        destruction_groups = [[p] for p in spell_destructions]\n        destroyed_tile_groups = bcopy._destroy(destruction_groups)\n        total_destroyed_tile_groups.extend(destroyed_tile_groups)\n        # execute one time only\n        # look for matched groups\n        matched_position_groups = bcopy._match()\n        # destroy and record matched groups\n        destroyed_tile_groups = bcopy._destroy(matched_position_groups)\n        total_destroyed_tile_groups.extend(destroyed_tile_groups)\n        bcopy._fall()\n        if random_fill:\n            bcopy._random_fill()\n        return bcopy, total_destroyed_tile_groups", "response": "Execute the board only one time. Do not execute chain reactions."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsimulates swapping as in PQ.", "response": "def _swap(self, swap):\n        \"\"\"Simulate swapping as in PQ.\n\n        swap should be a sequence of two positions with a square distance of\n        exactly 1.\n\n        Non-adjacent swaps cause a ValueError.\n        \"\"\"\n        if swap is None:\n            return\n        p1, p2 = swap\n        square_distance = abs(p1[0] - p2[0]) + abs(p1[1] - p2[1])\n        if square_distance != 1:\n            raise ValueError('Positions unexpectedly not adjacent: square'\n                             ' distance between {} and {} is'\n                             ' {}'.format(p1, p2,\n                                          square_distance))\n        a = self._array\n        a[p1], a[p2] = a[p2], a[p1]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _change(self, changes):\n        if changes is None:\n            return\n        for position, new_tile in changes:\n            self._array[position] = new_tile", "response": "Apply the given changes to the board."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _match(self):\n        #disable optimized matching\n        optimized_rows = None\n        optimized_columns = None\n        for match in self.__match_rows(optimized_rows):\n            #match in rows\n            yield match\n        for match in self.__match_rows(optimized_columns,\n                                       transpose=True):\n            #match in columns and transpose coordinates\n            yield match", "response": "Find all matches and generate a position group for each match."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nyielding the target positions of all matches in the given rows.", "response": "def __match_rows(self, optimized_lines=None, transpose=False):\n        \"\"\"Main functionality of _match, but works only on rows.\n        Full matches are found by running this once with original board and\n        once with a transposed board.\n\n        Arguments:\n        optimized_lines is an optional argument that identifies the lines\n        that need to be matched.\n\n        transpose indicates whether the match is looking at rows or columns\n\n        \"\"\"\n        MIN_LENGTH = 3\n        a = self._array\n        if transpose:\n            a = a.T\n        rows = optimized_lines or range(8)\n        # check for matches in each row separately\n        for row in rows:\n            NUM_COLUMNS = 8\n            match_length = 1\n            start_position = 0  # next tile pointer\n            #set next start position as long as a match is still possible\n            while start_position + MIN_LENGTH <= NUM_COLUMNS:\n                group_type = a[row, start_position]\n                # try to increase match length as long as there is room\n                while start_position + match_length + 1 <= NUM_COLUMNS:\n                    next_tile = a[row, start_position + match_length]\n                    # if no match, stop looking for further matches\n                    if not group_type.matches(next_tile):\n                        break\n                    # if group_type is wildcard, try to find a real type\n                    if group_type.is_wildcard():\n                        group_type = next_tile\n                    match_length += 1\n                #produce a matched position group if the current match qualifies\n                if match_length >= MIN_LENGTH and not group_type.is_wildcard():\n                    row_ = row\n                    target_positions = [(row_, col_) for col_\n                                        in range(start_position,\n                                                 start_position + match_length)]\n                    if transpose:\n                        target_positions = [(col_, row_)\n                                            for row_, col_ in target_positions]\n                    yield target_positions\n                #setup for continuing to look for matches after the current one\n                start_position += match_length\n                match_length = 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _destroy(self, target_position_groups):\n        target_position_groups = list(target_position_groups)  # work on a copy\n        destroyed_tile_groups = list()\n        blank = Tile.singleton('.')\n        a = self._array\n        while target_position_groups:  # continue as long as more targets exist\n            # delay actual clearing of destroyed tiles until all claiming\n            # groups have been stored (e.g. overlapping matches, bombs)\n            clear_after_storing = list()\n            new_target_position_groups = list()\n            for target_position_group in target_position_groups:\n                destroyed_tile_group = list()\n                for target_position in target_position_group:\n                    target_tile = a[target_position]\n                    # no handling for blanks that appear in destruction\n                    if target_tile.is_blank():\n                        continue\n                    destroyed_tile_group.append(target_tile)\n                    clear_after_storing.append(target_position)\n                    # skull bombs require further destructions\n                    if target_tile.is_skullbomb():\n                        new_positions = self.__skullbomb_radius(target_position)\n                        # convert individual positions to position groups\n                        new_position_groups = [(new_position,) for new_position\n                                               in new_positions]\n                        new_target_position_groups.extend(new_position_groups)\n                if destroyed_tile_group:\n                    destroyed_tile_groups.append(destroyed_tile_group)\n            # Finally clear positions after all records have been made\n            for position in clear_after_storing:\n                a[position] = blank\n            # Replace the completed target position groups with any new ones\n            target_position_groups = new_target_position_groups\n        return destroyed_tile_groups", "response": "Destroy indicated position groups handle any chain destructions and return all destroyed groups."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __skullbomb_radius(self, position):\n        #get the boundaries of the explosion\n        sb_row, sb_col = position\n        left = max(sb_row - 1, 0)  # standard radius or 0 if out of bounds\n        right = min(sb_row + 1, 7)  # standard radius or 7 if out of bounds\n        top = max(sb_col - 1, 0)\n        bottom = min(sb_col + 1, 7)\n        for explosion_row in xrange(left, right + 1):\n            for explosion_col in xrange(top, bottom + 1):\n                yield (explosion_row, explosion_col)", "response": "Generate all valid positions in the square around position."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncause tiles to fall down to fill blanks below them.", "response": "def _fall(self):\n        \"\"\"Cause tiles to fall down to fill blanks below them.\"\"\"\n        a = self._array\n        for column in [a[:, c] for c in range(a.shape[1])]:\n            # find blanks and fill them with tiles above them\n            target_p = column.shape[0] - 1  # start at the bottom\n            fall_distance = 1  # increases every time a new gap is found\n            while target_p - fall_distance >= 0:  # step up the target position\n                if column[target_p].is_blank():\n                    blank = column[target_p]  # move the blank\n                    #find the next nonblank position\n                    while target_p - fall_distance >= 0:\n                        next_p = target_p - fall_distance\n                        if column[next_p].is_blank():\n                            fall_distance += 1\n                        else:\n                            break  # stop expanding blank space when nonblank\n                    if target_p - fall_distance >= 0:\n                        #move the nonblank position to the target if gap exists\n                        source_position = target_p - fall_distance\n                        column[target_p] = column[source_position]\n                        column[source_position] = blank\n                        #in any case, move on to the next target position\n                target_p -= 1"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfill the board with random tiles based on the Tile class.", "response": "def _random_fill(self):\n        \"\"\"Fill the board with random tiles based on the Tile class.\"\"\"\n        a = self._array\n        for p, tile in self.positions_with_tile():\n            if tile.is_blank():\n                a[p] = Tile.random_tile()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef potential_swaps(self):\n        a = self._array\n        rows, cols = a.shape\n        for this_position, tile in self.positions_with_tile():\n            #produce horizontal swap for this position\n            r, c = this_position\n            if c < cols - 1:\n                other_position = (r, c + 1)\n                if self._swap_optimizer_allows(this_position, other_position):\n                    yield (this_position, other_position)\n            #produce vertical swap for this position. not DRY but maybe ok\n            if r < rows - 1:\n                other_position = (r + 1, c)\n                if self._swap_optimizer_allows(this_position, other_position):\n                    yield (this_position, other_position)", "response": "Generate a sequence of at least all valid swaps for this board."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if the optimizer allows the swap between two locations.", "response": "def _swap_optimizer_allows(self, p1, p2):\n        \"\"\"Identify easily discarded meaningless swaps.\n\n        This is motivated by the cost of millions of swaps being simulated.\n        \"\"\"\n        # setup local shortcuts\n        a = self._array\n        tile1 = a[p1]\n        tile2 = a[p2]\n        # 1) disallow same tiles\n        if tile1 == tile2:\n            return False\n        # 2) disallow matches unless a wildcard is involved\n        if tile1.matches(tile2) and not any(t.is_wildcard()\n                                            for t in (tile1, tile2)):\n            return False\n        # 3) disallow when both tiles (post-swap) are surrounded by non-matches\n        center_other_pairs = ((p1, p2), (p2, p1))\n\n        class MatchedTiles(Exception):\n            pass\n        try:\n            for center_p, other_p in center_other_pairs:\n                up_down_left_right = ((center_p[0] - 1, center_p[1]),\n                                      (center_p[0] + 1, center_p[1]),\n                                      (center_p[0],     center_p[1] - 1),\n                                      (center_p[0],     center_p[1] + 1))\n                post_swap_center_tile = a[other_p]\n                for surrounding_p in up_down_left_right:\n                    # ignore out of bounds positions\n                    # and ignore the inner swap which is handled elsewhere\n                    if any((not (0 <= surrounding_p[0] <= 7),  # out of bounds\n                            not (0 <= surrounding_p[1] <= 7),  # out of bounds\n                            surrounding_p == other_p)):  # inner swap\n                        continue\n                    surrounding_tile = a[surrounding_p]\n                    if post_swap_center_tile.matches(surrounding_tile):\n                        raise MatchedTiles()\n        except MatchedTiles:\n            pass  # if any match found, stop checking and pass this filter\n        else:\n            return False  # if no match is found, then this can be filtered\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate all positions and tiles as tuples of row col tile. docstring to make my IDE stop assuming tile is a standard dtype.", "response": "def positions_with_tile(self):\n        \"\"\"Generate all positions and tiles as tuples of (row,col), tile.\n\n        docstring to make my IDE stop assuming tile is a standard dtype. sorry!\n        :rtype : tuple\n        \"\"\"\n        for p, tile in numpy.ndenumerate(self._array):\n            yield p, tile"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef copy(self):\n        health = self.health, self.health_max\n        r = self.r, self.r_max\n        g = self.g, self.g_max\n        b = self.b, self.b_max\n        y = self.y, self.y_max\n        x = self.x, self.x_max\n        m = self.m, self.m_max\n        h = self.h, self.h_max\n        c = self.c, self.c_max\n        return self.__class__(self.name, health, r, g, b, y, x, m, h, c)", "response": "Return a copy of this actor with the same attribute values."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nclears current mana values.", "response": "def apply_mana_drain(self):\n        \"\"\"Clear current mana values.\"\"\"\n        self.r = self.g = self.b = self.y = 0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nincrease mana xp money anvils and scrolls based on tile groups.", "response": "def apply_tile_groups(self, tile_groups):\n        \"\"\"Increase mana, xp, money, anvils and scrolls based on tile groups.\"\"\"\n        self_increase_types = ('r', 'g', 'b', 'y', 'x', 'm', 'h', 'c')\n        attack_types = ('s', '*')\n        total_attack = 0\n        for tile_group in tile_groups:\n            group_type = None\n            type_count = 0\n            type_multiplier = 1\n            for tile in tile_group:\n                # try to get the group type\n                if not group_type:\n                    # try to set the group type to a non-wildcard type\n                    if tile._type in self_increase_types:\n                        group_type = tile._type\n                    elif tile._type in attack_types:\n                        group_type = 's'  # always use base skull\n                # handle special case of wildcard\n                if tile.is_wildcard():\n                    type_multiplier *= int(tile._type)\n                    continue  # done with this tile\n                # handle special case of skullbomb / skull\n                elif tile.is_skullbomb():\n                    total_attack += 5\n                    continue\n                elif tile.is_skull():\n                    total_attack += 1\n                    continue\n                # handle standard case of normal tiles\n                else:\n                    type_count += 1\n            if group_type is None:\n                continue  # ignore this group. could be all wildcards or empty\n            # adjust self value\n            if type_count:\n                new_value = type_count * type_multiplier\n                original = getattr(self, group_type)\n                setattr(self, group_type, original + new_value)\n        # return any attack value\n        return total_attack"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef copytree(src, dst, overwrite=False, ignore_list=None, debug=False):\n    if ignore_list is None:\n        ignore_list = []\n    if debug:\n        print('copytree {} to {}'.format(src, dst))\n    for child in Path(src).iterdir():\n        if debug:\n            print(\"  on file {}\".format(child))\n        if child.name not in ignore_list:\n            if child.is_dir():\n                new_dir = Path(dst) / child.relative_to(src)\n                new_dir.mkdir(exist_ok=True)\n                # call recursively\n                copytree(child, new_dir, overwrite, ignore_list, debug)\n            elif child.is_file():\n                new_file = new_dir = Path(dst) / child.relative_to(src)\n                if debug:\n                    print(\"    to file {}\".format(new_file))\n                if new_file.exists():\n                    if overwrite:\n                        new_file.unlink()\n                        shutil.copy2(child, new_file)\n                else:\n                    shutil.copy2(child, new_file)\n        else:\n            if debug:\n                print(\"  Skipping copy of {}\".format(child))", "response": "Copy a tree of files over."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read_requirements(*parts):\n    requirements = []\n    for line in read(*parts).splitlines():\n        new_line = re.sub(r'(\\s*)?#.*$',  # the space immediately before the\n                                          # hash mark, the hash mark, and\n                                          # anything that follows it\n                          '',  # replace with a blank string\n                          line)\n        if new_line:  # i.e. we have a non-zero-length string\n            requirements.append(new_line)\n    return requirements", "response": "Reads a requirements. txt file and returns a list of requirements."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pdf2text(path, password=\"\", headers=None):\n    if path.startswith(\"http\"):\n        if headers:\n            request = Request(url=path, headers=headers)\n        else:\n            request = Request(url=path, headers={})\n        fp = urlopen(request)  # \u6253\u5f00\u5728\u7ebfPDF\u6587\u6863\n    else:\n        fp = open(path, 'rb')\n\n    parser = PDFParser(fp)\n    doc = PDFDocument()\n    parser.set_document(doc)\n    doc.set_parser(parser)\n\n    # \u63d0\u4f9b\u521d\u59cb\u5316\u5bc6\u7801\n    # \u5982\u679c\u6ca1\u6709\u5bc6\u7801 \u5c31\u521b\u5efa\u4e00\u4e2a\u7a7a\u7684\u5b57\u7b26\u4e32\n    doc.initialize(password)\n\n    # \u68c0\u6d4b\u6587\u6863\u662f\u5426\u63d0\u4f9btxt\u8f6c\u6362\uff0c\u4e0d\u63d0\u4f9b\u5c31\u5ffd\u7565\n    if not doc.is_extractable:\n        raise PDFTextExtractionNotAllowed\n    else:\n        rsrcmgr = PDFResourceManager()\n        laparams = LAParams()\n        device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n        interpreter = PDFPageInterpreter(rsrcmgr, device)\n\n        text = []\n        for page in doc.get_pages():\n            interpreter.process_page(page)\n            layout = device.get_result()\n            for x in layout:\n                if isinstance(x, LTTextBoxHorizontal):\n                    text.append(x.get_text())\n    return text", "response": "\u4ecepdf\u6587\u4ef6\u4e2d\u63d0\u53d6\u6587\u672c\n\n    :param path: str\n        pdf\u6587\u4ef6\u5728\u672c\u5730\u7684\u5730\u5740\u6216\u8005url\u5730\u5740\n    :param password: str\n        pdf\u6587\u4ef6\u7684\u6253\u5f00\u5bc6\u7801\uff0c\u9ed8\u8ba4\u4e3a\u7a7a\n    :param headers: dict\n        \u8bf7\u6c42url\u6240\u9700\u8981\u7684 header\uff0c\u9ed8\u8ba4\u503c\u4e3a None\n    :return: text"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef merge_pdf(pdf_files, output_file):\n    merger = PyPDF2.PdfFileMerger()\n    for file in pdf_files:\n        f = open(file, 'rb')\n        file_rd = PyPDF2.PdfFileReader(f)\n        # use file name as bookmark\n        bookmark = os.path.basename(os.path.splitext(file)[0])\n        if file_rd.isEncrypted:\n            print('%s is encrypted, not supported!' % file)\n            continue\n        merger.append(file_rd, bookmark=bookmark, import_bookmarks=True)\n        f.close()\n    merger.write(output_file)\n    merger.close()", "response": "Merge pdf files into single list of lang_id and lang_id"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nacquire a read lock for the current thread waiting at most timeout seconds.", "response": "def acquire_read(self, timeout=None):\n        \"\"\"\n        Acquire a read lock for the current thread, waiting at most\n        timeout seconds or doing a non-blocking check in case timeout\n        is <= 0.\n\n        In case timeout is None, the call to acquire_read blocks until\n        the lock request can be serviced.\n\n        If the lock has been successfully acquired, this function\n        returns True, on a timeout it returns None.\n        \"\"\"\n        if timeout is not None:\n            endtime = time.time() + timeout\n        me = threading.currentThread()\n        self.__condition.acquire()\n        try:\n            if self.__writer is me:\n                self.__writer_lock_count += 1\n                return True\n            while True:\n                if self.__writer is None:\n                    if self.__pending_writers:\n                        if me in self.__readers:\n                            # Grant the lock anyway if we already\n                            # hold one, because this would otherwise\n                            # cause a deadlock between the pending\n                            # writers and ourself.\n                            self.__readers[me] += 1\n                            return True\n                        # else: does nothing, will wait below\n                        # writers are given priority\n                    else:\n                        self.__readers[me] = self.__readers.get(me, 0) + 1\n                        return True\n                if timeout is not None:\n                    remaining = endtime - time.time()\n                    if remaining <= 0:\n                        return None\n                    self.__condition.wait(remaining)\n                else:\n                    self.__condition.wait()\n        finally:\n            self.__condition.release()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nacquire a write lock for the current thread waiting at most timeout seconds or doing a non - blocking check if the lock is already acquired.", "response": "def acquire_write(self, timeout=None):\n        \"\"\"\n        Acquire a write lock for the current thread, waiting at most\n        timeout seconds or doing a non-blocking check in case timeout\n        is <= 0.\n\n        In case timeout is None, the call to acquire_write blocks until\n        the lock request can be serviced.\n\n        If the lock has been successfully acquired, this function\n        returns True. On a timeout it returns None. In case a trivial\n        deadlock condition is detected (the current thread already hold\n        a reader lock) it returns False.\n        \"\"\"\n        if timeout is not None:\n            endtime = time.time() + timeout\n        me = threading.currentThread()\n        self.__condition.acquire()\n        try:\n            if self.__writer is me:\n                self.__writer_lock_count += 1\n                return True\n            if me in self.__readers:\n                # trivial deadlock detected (we do not handle promotion)\n                return False\n            self.__pending_writers.append(me)\n            while True:\n                if not self.__readers and self.__writer is None and self.__pending_writers[0] is me:\n                    self.__writer = me\n                    self.__writer_lock_count = 1\n                    self.__pending_writers = self.__pending_writers[1:]\n                    return True\n                if timeout is not None:\n                    remaining = endtime - time.time()\n                    if remaining <= 0:\n                        self.__pending_writers.remove(me)\n                        return None\n                    self.__condition.wait(remaining)\n                else:\n                    self.__condition.wait()\n        finally:\n            self.__condition.release()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef release(self):\n        me = threading.currentThread()\n        self.__condition.acquire()\n        try:\n            if self.__writer is me:\n                self.__writer_lock_count -= 1\n                if self.__writer_lock_count == 0:\n                    self.__writer = None\n                    self.__condition.notifyAll()\n            elif me in self.__readers:\n                self.__readers[me] -= 1\n                if self.__readers[me] == 0:\n                    del self.__readers[me]\n                    if not self.__readers:\n                        self.__condition.notifyAll()\n            else:\n                raise thread.error, \"release unlocked lock\"\n        finally:\n            self.__condition.release()", "response": "Release the currently held lock."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntries to acquire the specified resource.", "response": "def try_acquire(self, elt):\n        \"\"\"\n        elt must be hashable.\n\n        If not yet locked, elt is captured for the current thread and\n        True is returned.\n\n        If already locked by the current thread its recursive counter\n        is incremented and True is returned.\n\n        If already locked by another thread False is returned.\n        \"\"\"\n        me = threading.currentThread()\n        self.lock.acquire()\n        try:\n            if elt not in self.locked:\n                self.locked[elt] = [me, 1]\n                return True\n            elif self.locked[elt][0] == me:\n                self.locked[elt][1] += 1\n                return True\n        finally:\n            self.lock.release()\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreleasing the lock for the specified element.", "response": "def release(self, elt):\n        \"\"\"\n        elt must be already locked (if it is not a thread.error\n        exception will be raised)\n\n        The recursive counter for elt is decremented and when it\n        reaches zero the lock is released.\n        \"\"\"\n        self.lock.acquire()\n        try:\n            if elt not in self.locked:\n                raise thread.error, \"release unlocked lock for %s\" % `elt`\n            self.locked[elt][1] -= 1\n            if not self.locked[elt][1]:\n                del self.locked[elt]\n        finally:\n            self.lock.release()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nretrieves a string value from the componnet.", "response": "def get(self, key, raw=False, fallback=None):\n        \"\"\"\n        Get a string value from the componnet.\n\n        Arguments:\n        key - the key to retrieve\n        raw - Control whether the value is interpolated or returned raw.  By\n              default, values are interpolated.\n        fallback - The return value if key isn't in the component.\n        \"\"\"\n        return self._component.get(key, raw=raw, fallback=fallback)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving a value in list form.", "response": "def get_list(self, key, fallback=None, split=\",\"):\n        \"\"\"\n        Retrieve a value in list form.\n\n        The interpolated value will be split on some key (by default, ',') and\n        the resulting list will be returned.\n\n        Arguments:\n        key - the key to return\n        fallback - The result to return if key isn't in the component.  By\n                   default, this will be an empty list.\n        split - The key to split the value on.  By default, a comma (,).\n        \"\"\"\n        fallback = fallback or []\n        raw = self.get(key, None)\n        if raw:\n            return [value.strip() for value in raw.split(split)]\n        return fallback"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets a value in the component.", "response": "def set(self, key, value):\n        \"\"\"\n        Set a value in the component.\n\n        Arguments:\n        key - the key to set\n        value - the new value\n        \"\"\"\n        if self._component.get(key, raw=True) != value:\n            self._component[key] = value\n            self._main_config.dirty = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_files(args):\n    '''\n    Return list of spec files. `args` may be filenames which are passed right\n    through, or directories in which case they are searched recursively for\n    *._spec.py\n    '''\n    files_or_dirs = args or ['.']\n    filenames = []\n    for f in files_or_dirs:\n        if path.isdir(f):\n            filenames.extend(glob.glob(path.join(f, '**', '*_spec.py'), recursive=True))\n        elif path.isfile(f):\n            filenames.append(f)\n        else:\n            raise FileNotFoundError('could not spec file {}'.format(repr(f)))\n    return filenames", "response": "Return list of spec files."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process_request(self, request):\n        \n        if COOKIE_KEY in request.COOKIES and \\\n            request.COOKIES[COOKIE_KEY] == COOKIE_SPAM:\n                # Is a known spammer.\n                response = HttpResponse(\"\")\n                # We do not reveal why it has been forbbiden:\n                response.status_code = 404\n                if DJANGOSPAM_LOG:\n                    logger.log(\"SPAM REQUEST\", request.method,\n                       request.path_info,\n                       request.META.get(\"HTTP_USER_AGENT\", \"undefined\"))\n                return response\n        if DJANGOSPAM_LOG:\n            logger.log(\"PASS REQUEST\", request.method, request.path_info,\n                       request.META.get(\"HTTP_USER_AGENT\", \"undefined\"))\n        return None", "response": "Discovers if a request is from a knwon spam bot and denies access."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset OK cookie on unknown users and go on...", "response": "def process_response(self, request, response):\n        \"\"\"Sets \"Ok\" cookie on unknown users.\"\"\"\n        if COOKIE_KEY not in request.COOKIES:\n        # Unknown user, set cookie and go on...\n            response.set_cookie(COOKIE_KEY, COOKIE_PASS, httponly=True,\n                                expires=datetime.now()+timedelta(days=30))\n            # Only logged if we have to set the PASS cookie\n            if DJANGOSPAM_LOG:\n                logger.log(\"PASS RESPONSE\", request.method, request.path_info,\n                           request.META.get(\"HTTP_USER_AGENT\", \"undefined\"))                \n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_version():\n    version_file = os.path.join(\"paps_settings\", \"__init__.py\")\n    initfile_lines = open(version_file, 'rt').readlines()\n    version_reg = r\"^__version__ = ['\\\"]([^'\\\"]*)['\\\"]\"\n    for line in initfile_lines:\n        mo = re.search(version_reg, line, re.M)\n        if mo:\n            return mo.group(1)\n    raise RuntimeError(\n        \"Unable to find version string in {}\".format(version_file)\n    )", "response": "Parse the version information from the init file and return the version string"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef connect_by_uri(uri):\n    puri = urisup.uri_help_split(uri)\n    params = __dict_from_query(puri[QUERY])\n    if puri[AUTHORITY]:\n        user, passwd, host, port = puri[AUTHORITY]\n        if user:\n            params['user'] = user\n        if passwd:\n            params['passwd'] = passwd\n        if host:\n            params['host'] = host\n        if port:\n            params['port'] = port\n    if puri[PATH]:\n        params['db'] = puri[PATH]\n        if params['db'] and params['db'][0] == '/':\n            params['db'] = params['db'][1:]\n\n    __merge_typemap = __typemap.copy()\n    __merge_typemap.update(__conn_typemap)\n\n    __apply_types(params, __merge_typemap)\n\n    # The next affectation work around a bug in python-mysqldb which\n    # happens when using an unicode charset: the conv parameter is\n    # defaulted to the common dictionary MySQLdb.converters.conversions\n    # when not explicitly given to the __init__() of\n    # MySQLdb.connections.Connection, the _mysql module just store it in\n    # the .converter member in the __init__() method of the base class\n    # _mysql.connection, and later, back in the __init__() of\n    # MySQLdb.connections.Connection, some children of .converter, which\n    # are lists, are prepended by dynamically generated functions. The net\n    # result is that every times a new Mysql connection is asked for with\n    # no individualised conversion dictionary passed to the conv parameter,\n    # a bunch of new functions and tuples are created, on which the process\n    # will keep references forever, effectively leaking some memory as some\n    # won't be used anymore after the termination of any connection.\n    # This work around is believed to be effective because the only\n    # references to the dynamically created conversion functions generated\n    # by MySQLdb.connections will be in this instance-specific copy of\n    # MySQLdb.converters.conversions. A unique reference to this copy will\n    # be held by the connection instance, so when the latter is garbage\n    # collected, the copied conversion dictionary is freed, and eventually\n    # the now orphan tuples and generated functions are too.\n    params['conv'] = CST_CONVERSIONS.copy()\n\n    cparams = {}\n\n    for key, value in __conn_typemap.iteritems():\n        if key in params:\n            cparams[key] = params[key]\n            del params[key]\n\n    conn =  MySQLdb.connect(**params)\n\n    for key, value in cparams.iteritems():\n        if value is None:\n            continue\n        elif isinstance(value, basestring) and value:\n            conn.query(\"SET @@session.%s = '%s'\" % (key, MySQLdb.escape_string(value)))\n        elif isinstance(value, (bool, int, long)):\n            conn.query(\"SET @@session.%s = %d\" % (key, value))\n\n    return conn", "response": "Connect to a MySQL database by URI."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert the first letter of each word to capital letter without modifying the case of the rest of the word.", "response": "def inicap_string(string,\n        cleanse=False):\n    \"\"\"\n    Convert the first letter of each word to capital letter without\n    touching the rest of the word.\n\n    @param string: a string.\n\n    @param cleanse: ``True`` to remove any separator character from the\n        string, such as comma; ``False`` to keeps any character but space.\n\n    @return: a string for which the first letter of each word has been\n        capitalized without modifying the case of the rest of the word.\n    \"\"\"\n    return string and ' '.join(word[0].upper() + word[1:]\n            for word in (string.split() if cleanse else string.split(' ')))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_email_address(string):\n    return string and isinstance(string, base_string) \\\n        and REGEX_PATTERN_EMAIL_ADDRESS.match(string.strip().lower())", "response": "Checks whether the specified string corresponds to an email address."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a string into a list of keywords.", "response": "def string_to_keywords(string,\n        keyword_minimal_length=1):\n    \"\"\"\n    Remove any punctuation character from the specified list of keywords,\n    remove any double or more space character and represent Unicode\n    characters in ASCII.\n\n\n    @param keywords: a list of keywords strip out any punctuation characters.\n\n    @param keyword_minimal_length: minimal number of characters of the\n        keywords to be returned.\n\n\n    @return: the set of keywords cleansed from any special Unicode\n        accentuated character, punctuation character, and double space\n        character.\n    \"\"\"\n    # Convert the string to ASCII lower characters.\n    ascii_string = unidecode.unidecode(string).lower()\n\n    # Replace any punctuation character with space.\n    punctuationless_string = re.sub(r\"\"\"[.,\\\\/#!$%\\^&*;:{}=\\-_`~()<>\"']\"\"\", ' ', ascii_string)\n\n    # Remove any double space character.\n    cleansed_string = re.sub(r'\\s{2,}', ' ', punctuationless_string)\n\n    # Decompose the string into distinct keywords.\n    keywords = set(cleansed_string.split(' '))\n\n    # Filter out sub-keywords of less than 2 characters.\n    return [ keyword for keyword in keywords if len(keyword) > keyword_minimal_length ]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef preview(src_path):\n  ''' Generates a preview of src_path in the requested format.\n  :returns: A list of preview paths, one for each page.\n  '''\n  previews = []\n\n  if sketch.is_sketchfile(src_path):\n    previews = sketch.preview(src_path)\n\n  if not previews:\n    previews = quicklook.preview(src_path)\n\n  previews = [safely_decode(preview) for preview in previews]\n\n  return previews", "response": "Generates a preview of src_path in the requested format."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update(self, *args, **kwargs):\n        self._call_helper(\"Updating\", self.real.update, *args, **kwargs)", "response": "This funcion updates a checkout of source code."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint the dependency information for the given targets components and tasks.", "response": "def _print_layers(targets, components, tasks):\n    \"\"\"\n    Print dependency information, grouping components based on their position\n    in the dependency graph.  Components with no dependnecies will be in layer\n    0, components that only depend on layer 0 will be in layer 1, and so on.\n\n    If there's a circular dependency, those nodes and their dependencies will\n    be colored red.\n\n    Arguments\n    targets - the targets explicitly requested\n    components - full configuration for all components in a project\n    \"\"\"\n    layer = 0\n    expected_count = len(tasks)\n    counts = {}\n\n    def _add_layer(resolved, dep_fn):\n        nonlocal layer\n        nonlocal counts\n        nonlocal expected_count\n\n        really_resolved = []\n        for resolved_task in resolved:\n            resolved_component_tasks = counts.get(resolved_task[0], [])\n            resolved_component_tasks.append(resolved_task)\n            if len(resolved_component_tasks) == expected_count:\n                really_resolved.extend(resolved_component_tasks)\n                del counts[resolved_task[0]]\n            else:\n                counts[resolved_task[0]] = resolved_component_tasks\n\n        if really_resolved:\n            indentation = \" \" * 4\n            print(\"{}subgraph cluster_{} {{\".format(indentation, layer))\n            print('{}label=\"Layer {}\"'.format(indentation * 2, layer))\n            dep_fn(indentation * 2, really_resolved)\n            print(\"{}}}\".format(indentation))\n            layer += 1\n\n    _do_dot(targets, components, tasks, _add_layer)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _print_graph(targets, components, tasks):\n    indentation = \" \" * 4\n    _do_dot(\n        targets,\n        components,\n        tasks,\n        lambda resolved, dep_fn: dep_fn(indentation, resolved),\n    )", "response": "Print dependency information using a dot directed graph."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeprecating function to print a graph of the given targets and components.", "response": "def _print_dot(targets, components, tasks):\n    \"\"\"\n    Deprecated function; use print_graph.\n\n    Arguments\n    targets - the targets explicitly requested\n    components - full configuration for all components in a project\n    \"\"\"\n    print(\"Warning: dot option is deprecated.  Use graph instead.\", file=sys.stderr)\n    _print_graph(targets, components, tasks)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_selected_items(self):\n        selection = self.get_selection()\n        if selection.get_mode() != gtk.SELECTION_MULTIPLE:\n            raise AttributeError('selected_items only valid for '\n                                 'select_multiple')\n        model, selected_paths = selection.get_selected_rows()\n        result = []\n        for path in selected_paths:\n            result.append(model[path][0])\n        return result", "response": "Return a list of currently selected items"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_selected_ids(self):\n        selection = self.get_selection()\n        if selection.get_mode() != gtk.SELECTION_MULTIPLE:\n            raise AttributeError('selected_ids only valid for select_multiple')\n        model, selected_paths = selection.get_selected_rows()\n        if selected_paths:\n            return zip(*selected_paths)[0]\n        else:\n            return ()", "response": "Return a list of currently selected ids"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update(self, item):\n        self.model.set(self._iter_for(item), 0, item)", "response": "Manually update an item s display in the list\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef move_item_down(self, item):\n        next_iter = self._next_iter_for(item)\n        if next_iter is not None:\n            self.model.swap(self._iter_for(item), next_iter)", "response": "Move an item down in the list."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef move_item_up(self, item):\n        prev_iter = self._prev_iter_for(item)\n        if prev_iter is not None:\n            self.model.swap(prev_iter, self._iter_for(item))", "response": "Move an item up in the list."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the function to decide visibility of an item in the hierarchy", "response": "def set_visible_func(self, visible_func):\n        \"\"\"Set the function to decide visibility of an item\n\n        :param visible_func: A callable that returns a boolean result to\n                             decide if an item should be visible, for\n                             example::\n\n                                def is_visible(item):\n                                    return True\n        \"\"\"\n        self.model_filter.set_visible_func(\n                self._internal_visible_func,\n                visible_func,\n                )\n        self._visible_func = visible_func\n        self.model_filter.refilter()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sort_by(self, attr_or_key, direction='asc'):\n        # work out the direction\n        if direction in ('+', 'asc', gtk.SORT_ASCENDING):\n            direction = gtk.SORT_ASCENDING\n        elif direction in ('-', 'desc', gtk.SORT_DESCENDING):\n            direction = gtk.SORT_DESCENDING\n        else:\n            raise AttributeError('unrecognised direction')\n        if callable(attr_or_key):\n            # is a key\n            sort_func = self._key_sort_func\n        else:\n            # it's an attribute\n            sort_func = self._attr_sort_func\n        self.model.set_default_sort_func(sort_func, attr_or_key)\n        self.model.set_sort_column_id(-1, direction)", "response": "Sort the view by an attribute or key or key."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove(self, item):\n        if item not in self:\n            raise ValueError('objectlist.remove(item) failed, item not in list')\n        item_id = int(self._view_path_for(item))\n        giter = self._iter_for(item)\n        del self[giter]\n        self.emit('item-removed', item, item_id)", "response": "Removes an item from the list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef insert(self, position, item, select=False):\n        if item in self:\n            raise ValueError(\"item %s already in list\" % item)\n        modeliter = self.model.insert(position, (item,))\n        self._id_to_iter[id(item)] = modeliter\n        if select:\n            self.selected_item = item\n        self.emit('item-inserted', item, position)", "response": "Insert an item at the specified position in the list."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds an item to the end of the list.", "response": "def append(self, item, select=False):\n        \"\"\"Add an item to the end of the list.\n\n        :param item: The item to be added\n        :param select: Whether the item should be selected after adding\n        \"\"\"\n        if item in self:\n            raise ValueError(\"item %s already in list\" % item)\n        modeliter = self.model.append((item,))\n        self._id_to_iter[id(item)] = modeliter\n        if select:\n            self.selected_item = item\n        self.emit('item-added', item)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding an item to the end of the list.", "response": "def append(self, item, parent=None, select=False):\n        \"\"\"Add an item to the end of the list.\n\n        :param item: The item to be added\n        :param parent: The parent item to add this as a child of, or None for\n                       a top-level node\n        :param select: Whether the item should be selected after adding\n        \"\"\"\n        if item in self:\n            raise ValueError(\"item %s already in list\" % item)\n        if parent is not None:\n            giter = self._iter_for(parent)\n        else:\n            giter = None\n        modeliter = self.model.append(giter, (item,))\n        self._id_to_iter[id(item)] = modeliter\n        if select:\n            self.selected_item = item"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extend(self, iter, parent=None):\n        for item in iter:\n            self.append(item, parent)", "response": "Add a sequence of items to the end of the list."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndisplays a node as expanded.", "response": "def expand_item(self, item, open_all=True):\n        \"\"\"Display a node as expanded\n\n        :param item: The item to show expanded\n        :param open_all: Whether all child nodes should be recursively\n                         expanded.\n        \"\"\"\n        self.expand_row(self._view_path_for(item), open_all)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves an item from the list.", "response": "def remove(self, item):\n        \"\"\"Remove an item from the list\n\n        :param item: The item to remove from the list.\n        :raises ValueError: If the item is not present in the list.\n        \"\"\"\n        if item not in self:\n            raise ValueError('objectlist.remove(item) failed, item not in list')\n        item_path = self._view_path_for(item)\n        giter = self._iter_for(item)\n        del self[giter]\n        self.emit('item-removed', item, item_path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef jsonify(obj, trimmable=False):\n    # def jsonify_ex(obj, trimmable=False):\n    #     if obj is None:\n    #         return None\n    #     elif isinstance(obj, (basestring, bool, int, long, float, complex)):\n    #         return obj\n    #     elif isinstance(obj, (list, set, tuple)):\n    #         return [jsonify_ex(item, trimmable=trimmable) for item in obj] # MUST NOT remove nil value\n    #     elif isinstance(obj, dict):\n    #         return dict([(jsonify_ex(key, trimmable=trimmable), jsonify_ex(value, trimmable=trimmable))\n    #                 for (key, value) in obj.iteritems() if not trimmable or value is not None])\n    #     elif isinstance(obj, (uuid.UUID, EnumValue, ISO8601DateTime, Locale)):\n    #         return str(obj)\n    #     elif isinstance(obj, datetime.datetime):\n    #         return str(ISO8601DateTime.from_datetime(obj)) if obj.tzinfo else str(obj)\n    #     elif '__dict__' in dir(obj):\n    #         return dict([(key, jsonify_ex(value, trimmable=trimmable))\n    #                 for (key, value) in obj.__dict__.iteritems() if not trimmable or value is not None])\n    #     else:\n    #         return str(obj)\n    #\n    # return json.dumps(jsonify_ex(obj, trimmable=trimmable))\n    return json.dumps(stringify(obj, trimmable=trimmable))", "response": "Serialize an object to a JSON formatted string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stringify(obj, trimmable=False):\n    if obj is None:\n        return None\n    elif isinstance(obj, (basestring, bool, int, long, float, complex)):\n        return obj\n    elif isinstance(obj, (list, set, tuple)):\n        return [stringify(item, trimmable=trimmable) for item in obj]\n    elif isinstance(obj, dict):\n        return dict([(unicode(key), stringify(value, trimmable=trimmable))\n                for (key, value) in obj.iteritems() if not trimmable or value is not None])\n    elif isinstance(obj, (uuid.UUID, EnumValue, ISO8601DateTime, Locale)):\n        return unicode(obj)\n    elif isinstance(obj, datetime.datetime):\n        return str(ISO8601DateTime.from_datetime(obj)) if obj.tzinfo else str(obj)\n    elif hasattr(obj, '__dict__'): # '__dict__' in dir(obj):\n        return dict([(key, stringify(value, trimmable=trimmable))\n                for (key, value) in obj.__dict__.iteritems() if not trimmable or value is not None])\n    else:\n        return unicode(obj)", "response": "Convert an object to a stringified version of this object where the initial object s attribute values have been stringified when these values are not native Python types."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a shallow copy of the given object including only the specified attributes of this object.", "response": "def shallow_copy(obj, attribute_names,\n        ignore_missing_attributes=True):\n    \"\"\"\n    Return a shallow copy of the given object, including only the\n    specified attributes of this object.\n\n\n    @param obj: an object to copy.\n\n    @param attribute_names: a list of names of the attributes to copy.\n\n    @param ignore_missing_attributes: ``False`` indicates that the function\n        can ignore attributes that have been specified but that are not\n        defined in the given object; ``True`` indicates that the function\n        MUST raise a ``KeyError`` exception if some specified attributes\n        are not defined in the given object.\n\n\n    @return: a shallow copy of the given object with the specified\n        attributes only.\n\n\n    @raise KeyError: if the argument ``ignore_missing_attributes`` equals\n        ``False`` and if some specified attributes are not defined in the\n        the given object.\n    \"\"\"\n    shallow_object = copy.copy(obj)\n    shallow_object.__dict__ = {}\n\n    for attribute_name in attribute_names:\n        try:\n            setattr(shallow_object, attribute_name, getattr(obj, attribute_name))\n        except KeyError, error:\n            if not ignore_missing_attributes:\n                raise error\n\n    return shallow_object"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild an object from a JSON dictionary.", "response": "def from_json(payload):\n        \"\"\"\n        Build an object from a JSON dictionary.\n\n\n        @param payload: a JSON dictionary which key/value pairs represent\n           the members of the Python object to build, or ``None``.\n\n\n        @return: an instance ``Object`` with members built from the key/value\n             pairs of the given JSON dictionary, or ``None`` if the payload\n             is ``None`` or the given JSON dictionary is empty.\n        \"\"\"\n        if payload is None:\n            return None\n\n        if isinstance(payload, dict):\n            return Object(**dict([(k, v if not isinstance(v, (dict, list)) else Object.from_json(v))\n                    for (k, v) in payload.iteritems()]))\n\n        elif isinstance(payload, list):\n            return payload and [Object.from_json(v) if isinstance(v, (dict, list)) else v for v in payload]\n\n        else:\n            raise ValueError('The payload MUST be a dictionary or a list')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_usable(host, port, timeout=3):\n    try:\n        proxies = {\n            'http': 'http://%s:%s' % (host, port),\n            'https': 'https://%s:%s' % (host, port)\n        }\n        requests.get('http://www.baidu.com/', proxies=proxies, timeout=timeout)\n    except HTTPError:\n        print('failed: ', host, port)\n        return False\n    else:\n        print('success: ', host, port)\n        return True", "response": "is_usable - Check if a base is usable."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef allow(self, comment, content_object, request):\n        # Tests for cookie:\n        if settings.COOKIE_KEY not in request.COOKIES \\\n            and (settings.DISCARD_SPAM or settings.DISCARD_NO_COOKIE):\n                return False\n        elif settings.COOKIE_KEY not in request.COOKIES:\n            comment.is_removed = True\n            comment.is_public = False\n            return True\n        return True", "response": "Tests if the comment post request is allowed for the djangospam cookie."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate(self, value):\n\n        cast_callback = self.cast_callback if self.cast_callback else self.cast_type\n\n        try:\n            return value if isinstance(value, self.cast_type) else cast_callback(value)\n\n        except Exception:\n            raise NodeTypeError('Invalid value `{}` for {}.'.format(value, self.cast_type))", "response": "Base validation method. Check if type is valid or try brute casting."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef init(cfg):\n    global na3x_cfg\n    with open(cfg[NA3X_DB]) as db_cfg_file:\n        na3x_cfg[NA3X_DB] = json.load(db_cfg_file, strict=False)\n    with open(cfg[NA3X_TRIGGERS]) as triggers_cfg_file:\n        na3x_cfg[NA3X_TRIGGERS] = json.load(triggers_cfg_file, strict=False)\n    with open(cfg[NA3X_ENV]) as env_cfg_file:\n        na3x_cfg[NA3X_ENV] = json.load(env_cfg_file, strict=False)", "response": "Initialize na3x_cfg with the given configuration."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _is_cache_dir_appropriate(cache_dir, cache_file):\n    if os.path.exists(cache_dir):\n        files = os.listdir(cache_dir)\n        if cache_file in files:\n            return True\n        return not bool(files)\n    return True", "response": "Determine if a directory is acceptable for building."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef process_config(raw_path, cache_dir, cache_file, **kwargs):\n    config = _create_cache(raw_path, cache_dir, cache_file)\n    for modifier in _CONFIG_MODIFIERS:\n        modifier(config, **kwargs)\n    # pylint: disable=protected-access\n    cache = devpipeline_configure.cache._CachedConfig(\n        config, os.path.join(cache_dir, cache_file)\n    )\n    _handle_value_modifiers(cache)\n    _add_package_options(cache)\n    _write_config(cache, cache_dir)\n    return cache", "response": "Read a build configuration and create a build\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef copy(self, **kwargs):\n        for k in kwargs:\n            assert k in self._keys, 'Invalid key: %s' % k\n\n        d = self.values()\n        d.update(kwargs)\n        return self.__class__(**d)", "response": "Returns a copy of the current object modifying the kwargs"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef values(self):\n        return dict((k, getattr(self, k)) for k in self._keys)", "response": "Return a dictionary of all the keys and values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_urls(self):\n        urls = super(IPAdmin, self).get_urls()\n        my_urls = patterns(\n            '',\n            url(r'^batch_process_ips/$', self.admin_site.admin_view(self.batch_process_ips_view), name='batch_process_ips_view')\n        )\n        return my_urls + urls", "response": "Returns the urls for the model."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef field2ap_corr(field):\n    phase = unwrap.unwrap_phase(np.angle(field), seed=47)\n    samples = []\n    samples.append(phase[:, :3].flatten())\n    samples.append(phase[:, -3:].flatten())\n    samples.append(phase[:3, 3:-3].flatten())\n    samples.append(phase[-3:, 3:-3].flatten())\n    pha_offset = np.median(np.hstack(samples))\n    num_2pi = np.round(pha_offset / (2 * np.pi))\n    phase -= num_2pi * 2 * np.pi\n    ampli = np.abs(field)\n    return ampli, phase", "response": "Determine amplitude and offset - corrected phase from a complex field."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef execute_command(cls, command):\n        return Popen(\n            command,\n            stdout=PIPE,\n            stderr=STDOUT,\n            start_new_session=True\n        )", "response": "Execute a command and return a Popen object with stderr redirected to stdout"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_single_item(d):\n    assert len(d) == 1, 'Single-item dict must have just one item, not %d.' % len(d)\n    return next(six.iteritems(d))", "response": "Get an item from a dict which contains just one item."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_single_key(d):\n    assert len(d) == 1, 'Single-item dict must have just one item, not %d.' % len(d)\n    return next(six.iterkeys(d))", "response": "Get a key from a dict which contains just one item."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a value from a dict which contains just one item.", "response": "def get_single_value(d):\n    \"\"\"Get a value from a dict which contains just one item.\"\"\"\n    assert len(d) == 1, 'Single-item dict must have just one item, not %d.' % len(d)\n    return next(six.itervalues(d))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef distinct(xs):\n    # don't use collections.OrderedDict because we do support Python 2.6\n    seen = set()\n    return [x for x in xs if x not in seen and not seen.add(x)]", "response": "Get the list of distinct values with preserving order."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconfigure object based on its initialization", "response": "def configure(self):\n        # type: () -> None\n        \"\"\"\n            Configures object based on its initialization\n        \"\"\"\n        for i in vars(self):\n            if i.startswith(\"_\"):\n                continue\n            val = self.__get(i, return_type=type(getattr(self, i)))\n            if val is not None:\n                setattr(self, i, val)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run(self, **kwargs):\n        logger.info('UpdateLocationsIfNecessaryTask was called')\n\n        # read last ip count\n        try:\n            with open(app_settings.IP_ASSEMBLER_IP_CHANGED_FILE, 'r') as f:\n                content_list = f.readlines()\n                if len(content_list) == 0:\n                    ip_count_old = -1\n                else:\n                    ip_count_old = int(content_list[0])\n        except IOError:\n            ip_count_old = -1\n\n        logger.info('read IP count of %(count)d' % {'count': ip_count_old})\n\n        # if IPs have significantly changed, update the locations\n        ip_count_now = IP.objects.count()\n        if ip_count_now == -1 or ip_count_now > ip_count_old + app_settings.IP_ASSEMBLER_IP_CHANGED_THRESHOLD:\n            logger.info('Checking IP counts, last: %(ip_count_old)d - now: %(ip_count_now)d' % {\n                'ip_count_old': ip_count_old,\n                'ip_count_now': ip_count_now\n            })\n\n            # call the updater task\n            UpdateHtaccessLocationsTask().delay()\n\n            # write the new count to the file\n            try:\n                open(app_settings.IP_ASSEMBLER_IP_CHANGED_FILE, 'w').close()\n                with open(app_settings.IP_ASSEMBLER_IP_CHANGED_FILE, 'w') as f:\n                    f.write(str(ip_count_now))\n            except IOError:\n                logger.exception('unable to write to file %(file_path)s' % {'file_path': app_settings.IP_ASSEMBLER_IP_CHANGED_FILE})\n        else:\n            logger.info('nothing to do here')", "response": "Update the locations of the objects in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run(self, **kwargs):\n        try:\n            # connect to server and login\n            box = imaplib.IMAP4_SSL(settings.IMAP_SERVER)\n            box.login(settings.IMAP_USERNAME, settings.IMAP_PASSWORD)\n            box.select()\n\n            # search for all mails in the mailbox\n            result, mail_indices = box.search(None, 'ALL')\n\n            # if everything was ok...\n            if result == 'OK':\n\n                # check number of mails\n                mail_count = len(mail_indices[0].split())\n                logger.info('found %(mail_count)d mails...' % {'mail_count': mail_count})\n\n                # iterate the mail indices and fetch the mails\n                ips_created = 0\n                for mail_index in mail_indices[0].split():\n                    logger.info('fetching mail %(mail_index)s...' % {'mail_index': int(mail_index)})\n                    # mail data is a list with a tuple\n                    sub_result, mail_data = box.fetch(mail_index, '(BODY[TEXT])')\n                    if sub_result == 'OK':\n\n                        # fetch the ips\n                        ips = list_remove_duplicates(\n                            self.find_ips(''.join([str(data) for data in mail_data[0]]))\n                        )\n\n                        # if ips found, add them and delete the mail\n                        if len(ips) > 0:\n                            logger.info('found %(count)d IPs' % {'count': len(ips)})\n                            ips_created += IP.batch_add_ips(ips)\n                            box.store(mail_index, '+FLAGS', '\\\\Deleted')\n\n                    else:\n                        logger.error('fetching mail with index %(index)d failed' % {'index': mail_index})\n\n                # finally, if ips were added, unify the IPs\n                if ips_created > 0:\n                    logger.info('created %(count)d IPs' % {'count': ips_created})\n                    IP.unify_ips()\n\n            else:\n                logger.error('search returned not OK')\n\n            box.close()\n            box.logout()\n        except:\n            logger.exception('retrieving mail failed')", "response": "Checks the IMAP mailbox for new mails and tries to handle them."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nuse some regex to find IPs within the text.", "response": "def find_ips(self, text):\n        \"\"\"\n        Uses some regex to find IPs within the text.\n        :param text: the text to search in\n        :type text: str\n        :return: list of ips\n        :rtype: list\n        \"\"\"\n        for regex in self.regex_expressions:\n            ips = regex.findall(text)\n            if len(ips) > 0:\n                return ips\n        return []"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwrapping for pymongo. find_one", "response": "def read_single(db, collection, match_params=None):\n        \"\"\"\n        Wrapper for pymongo.find_one()\n        :param db: db connection\n        :param collection: collection to read data from\n        :param match_params: a query that matches the documents to select\n        :return: document ('_id' is excluded from result)\n        \"\"\"\n        return db[collection].find_one(match_params if match_params else {}, {'_id': False})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_multi(db, collection, match_params=None):\n        return list(db[collection].find(match_params if match_params else {}, {'_id': False}))", "response": "Wrapper for pymongo. find"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef upsert_single(db, collection, object, match_params=None):\n        return str(db[collection].update_one(match_params, {\"$set\": object}, upsert=True).upserted_id)", "response": "Wrapper for pymongo. update_one"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrap for pymongo. insert_many and pymongo. update_many", "response": "def upsert_multi(db, collection, object, match_params=None):\n        \"\"\"\n        Wrapper for pymongo.insert_many() and update_many()\n        :param db: db connection\n        :param collection: collection to update\n        :param object: the modifications to apply\n        :param match_params: a query that matches the documents to update\n        :return: ids of inserted/updated document\n        \"\"\"\n        if isinstance(object, list) and len(object) > 0:\n            return str(db[collection].insert_many(object).inserted_ids)\n        elif isinstance(object, dict):\n            return str(db[collection].update_many(match_params, {\"$set\": object}, upsert=False).upserted_id)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexecute a trigger on the specified collection.", "response": "def __exec_trigger(self, action, collection, input_object, match_params):\n        \"\"\"\n        Executes trigger\n        :param action: Trigger.ACTION_BEFORE_DELETE, ACTION_AFTER_DELETE, ACTION_BEFORE_UPSERT, ACTION_AFTER_DELETE\n        :param collection: see corresponding parameter in delete/update method\n        :param input_object: see corresponding parameter in update method\n        :param match_params: see corresponding parameter in delete/update method\n        \"\"\"\n        trigger = Trigger.factory(self.__db, collection, action)\n        if trigger:\n            self.__logger.info('exec trigger {} on {}'.format(action, collection))\n            # ToDo: catch exception\n            trigger.execute(input_object, match_params)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread single document or list of documents from MongoDB collection", "response": "def get(self, cfg):\n        \"\"\"\n        Reads single document or list of documents from MongoDB collection\n        :param cfg:\n            {\n                AccessParams.KEY_COLLECTION: <Collection to read data from>,\n                AccessParams.KEY_MATCH_PARAMS: <A query that matches the documents to select>,\n                AccessParams.KEY_TYPE: <AccessParams.TYPE_SINGLE or AccessParams.TYPE_MULTI>\n            }\n        :return: single document or list of documents\n        \"\"\"\n        collection = cfg[AccessParams.KEY_COLLECTION]\n        match_params = cfg[AccessParams.KEY_MATCH_PARAMS] if AccessParams.KEY_MATCH_PARAMS in cfg else None\n\n        target_type = cfg[AccessParams.KEY_TYPE] if AccessParams.KEY_TYPE in cfg else AccessParams.TYPE_MULTI\n        if target_type == AccessParams.TYPE_SINGLE:\n            result = CRUD.read_single(self.__db, collection, match_params)\n        elif target_type == AccessParams.TYPE_MULTI:\n            result = CRUD.read_multi(self.__db, collection, match_params)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete(self, cfg, triggers_on=True):\n        collection = cfg[AccessParams.KEY_COLLECTION]\n        match_params = cfg[AccessParams.KEY_MATCH_PARAMS] if AccessParams.KEY_MATCH_PARAMS in cfg else {}\n        target_type = cfg[AccessParams.KEY_TYPE] if AccessParams.KEY_TYPE in cfg else AccessParams.TYPE_MULTI\n        if triggers_on:\n            self.__exec_trigger(Trigger.ACTION_BEFORE_DELETE, collection, None, match_params)\n        if target_type == AccessParams.TYPE_SINGLE:\n            result = CRUD.delete_single(self.__db, collection, match_params)\n        elif target_type == AccessParams.TYPE_MULTI:\n            result = CRUD.delete_multi(self.__db, collection, match_params)\n        if triggers_on:\n            self.__exec_trigger(Trigger.ACTION_AFTER_DELETE, collection, None, match_params)\n        return result", "response": "Delete the specified document from MongoDB"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef upsert(self, cfg, triggers_on=True):\n        input_object = cfg[AccessParams.KEY_OBJECT]\n        collection = cfg[AccessParams.KEY_COLLECTION]\n        match_params = cfg[AccessParams.KEY_MATCH_PARAMS] if AccessParams.KEY_MATCH_PARAMS in cfg else {}\n        if triggers_on:\n            self.__exec_trigger(Trigger.ACTION_BEFORE_UPSERT, collection, input_object, match_params)\n        if cfg[AccessParams.KEY_TYPE] == AccessParams.TYPE_SINGLE:\n            result =  CRUD.upsert_single(self.__db, collection, input_object, match_params)\n        elif cfg[AccessParams.KEY_TYPE] == AccessParams.TYPE_MULTI:\n            result =  CRUD.upsert_multi(self.__db, collection, input_object, match_params)\n        if triggers_on:\n            self.__exec_trigger(Trigger.ACTION_AFTER_UPSERT, collection, input_object, match_params)\n        return result", "response": "Updates or inserts single document or list of documents into MongoDB collection."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef authorize(client_key, client_secret, credfile=CONFIG_FILE, app='trlo.py',\n              expiration='never', scope='read,write'):\n    \"\"\"\n    Authorize with Trello, saving creds to `credfile`.\n    \"\"\"\n    # 1. Obtain the request token.\n    oauth = OAuth1Session(client_key, client_secret=client_secret)\n    request_token = oauth.fetch_request_token(OAUTH_REQUEST_TOKEN_URL)\n\n    # 2. Authorize the user (in the browser).\n    authorization_url = oauth.authorization_url(OAUTH_BASE_AUTHORIZE_URL,\n        name=app, expiration=expiration, scope=scope)\n    print(\"Please visit the following URL to authorize this app:\")\n    print(authorization_url)\n    print('')\n    print(\"Once you've authorized, copy and paste the token Trello gives you below.\")\n    # Py3K backwards-compatibility shim\n    global input\n    try:\n        input = raw_input\n    except NameError:\n        pass\n    verifier = input(\"Trello's token: \").strip()\n\n    # 3. Obtain the access token\n    oauth = OAuth1Session(client_key, client_secret=client_secret,\n        resource_owner_key=request_token['oauth_token'],\n        resource_owner_secret=request_token['oauth_token_secret'],\n        verifier=verifier)\n    access_token = oauth.fetch_access_token(OAUTH_ACCESS_TOKEN_URL)\n\n    # Save all our creds to ~/.trlo so we can get at 'em later.\n    # The names are specially chosen so we can do OAuth1Session(**creds)\n    creds = {\n        'client_key': client_key,\n        'client_secret': client_secret,\n        'resource_owner_key': access_token['oauth_token'],\n        'resource_owner_secret': access_token['oauth_token_secret'],\n    }\n    with open(credfile, 'w') as fp:\n        json.dump(creds, fp)", "response": "Authorize with Trello saving creds to credfile."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_executable(path_str):\n  ''' Performs the equivalent of `chmod +x` on the file at path_str.\n  :returns: path_str if success, else None\n  '''\n  try:\n    mode = os.stat(path_str).st_mode\n    os.chmod(path_str, mode | stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH)\n  except Exception as e:\n    print 'Exception: %s' % e\n    return None\n  return path_str", "response": "Makes the equivalent of chmod + x on the file at path_str."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getCountry(value):\n        if not helpers.has_len(value):\n            return False\n\n        return COUNTRIES.get(str(value).lower(), False)", "response": "Returns the country name from country code."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate(value):\n        if not helpers.has_len(value):\n            return False\n\n        return COUNTRIES.has_key(str(value).lower())", "response": "Checks if given value is a valid country codes\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a gtk. TreeViewColumn for the configuration.", "response": "def create_treecolumn(self, objectlist):\n        \"\"\"Create a gtk.TreeViewColumn for the configuration.\n        \"\"\"\n        col = gtk.TreeViewColumn(self.title)\n        col.set_data('pygtkhelpers::objectlist', objectlist)\n        col.set_data('pygtkhelpers::column', self)\n        col.props.visible = self.visible\n        if self.expand is not None:\n            col.props.expand = self.expand\n        if self.resizable is not None:\n            col.props.resizable = self.resizable\n        if self.width is not None:\n            col.set_sizing(gtk.TREE_VIEW_COLUMN_FIXED)\n            col.set_fixed_width(self.width)\n        for cell in self.cells:\n            view_cell = cell.create_renderer(self, objectlist)\n            view_cell.set_data('pygtkhelpers::column', self)\n            # XXX: better control over packing\n            col.pack_start(view_cell)\n            col.set_cell_data_func(view_cell, cell.cell_data_func)\n        col.set_reorderable(True)\n        col.set_sort_indicator(False)\n        col.set_sort_order(gtk.SORT_DESCENDING)\n        if objectlist and objectlist.sortable and self.sorted:\n            idx = objectlist.columns.index(self)\n            sort_func = self._default_sort_func\n            objectlist.model_sort.set_sort_func(idx, sort_func, objectlist)\n            col.set_sort_column_id(idx)\n        if objectlist and objectlist.searchable and self.searchable:\n            self.search_by(objectlist)\n        col.connect('clicked', self._on_viewcol_clicked)\n        return col"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrenders the tooltip for this column for an object", "response": "def render_tooltip(self, tooltip, obj):\n        \"\"\"Render the tooltip for this column for an object\n        \"\"\"\n        if self.tooltip_attr:\n            val = getattr(obj, self.tooltip_attr)\n        elif self.tooltip_value:\n            val = self.tooltip_value\n        else:\n            return False\n        setter = getattr(tooltip, TOOLTIP_SETTERS.get(self.tooltip_type))\n        if self.tooltip_type in TOOLTIP_SIZED_TYPES:\n            setter(val, self.tooltip_image_size)\n        else:\n            setter(val)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef choose_tool_key(full_configuration, keys):\n    tool_key = _choose_key(full_configuration.config, keys)\n    if tool_key != keys[0]:\n        full_configuration.executor.warning(\n            \"{} is deprecated; migrate to {}\".format(tool_key, keys[0])\n        )\n    return tool_key", "response": "Select the key for a tool from a list of supported tools."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprocess arguments a tool cares about. Since most tools require configuration, this function helps deal with the boilerplate. Each option will be processed based on all modifications supported by dev-pipeline (i.e., profiles and overrides) in the proper order. Arguments: prefix -- The prefix for each argument. This will be applied to everything in args_dict. current_target -- Information about the current target being processed. args_dict -- Something that acts like a dictionary. The keys should be options to deal with and the value should be the separtor value the option requires. The separator can be any type that has a join method, or None if lists are supported for that key. value_found_fn -- A function to call when a match is found.", "response": "def args_builder(prefix, current_target, args_dict, value_found_fn):\n    \"\"\"\n    Process arguments a tool cares about.\n\n    Since most tools require configuration, this function helps deal with the\n    boilerplate.  Each option will be processed based on all modifications\n    supported by dev-pipeline (i.e., profiles and overrides) in the proper\n    order.\n\n    Arguments:\n    prefix -- The prefix for each argument.  This will be applied to\n              everything in args_dict.\n    current_target -- Information about the current target being processed.\n    args_dict -- Something that acts like a dictionary.  The keys should be\n                 options to deal with and the value should be the separtor\n                 value the option requires.  The separator can be any type\n                 that has a join method, or None if lists are supported for\n                 that key.\n    value_found_fn -- A function to call when a match is found.\n    \"\"\"\n    current_config = current_target.config\n    for key, separator in args_dict.items():\n        option = \"{}.{}\".format(prefix, key)\n        value = current_config.get_list(option)\n        if value:\n            if separator is None:\n                separator = _NullJoiner(current_config.name, option)\n            value_found_fn(separator.join(value), key)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\njoins the list of values into one value.", "response": "def join(self, vals):\n        \"\"\"\n        Either return the non-list value or raise an Exception.\n\n        Arguments:\n        vals - a list of values to process\n        \"\"\"\n        if len(vals) == 1:\n            return vals[0]\n        raise Exception(\n            \"Too many values for {}:{}\".format(self._component_name, self._key)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef handle_audio(obj, wait=False):\n        if not simpleaudio:\n            return obj\n\n        fp = pkg_resources.resource_filename(obj.package, obj.resource)\n        data = wave.open(fp, \"rb\")\n        nChannels = data.getnchannels()\n        bytesPerSample = data.getsampwidth()\n        sampleRate = data.getframerate()\n        nFrames = data.getnframes()\n        framesPerMilliSecond = nChannels * sampleRate // 1000\n\n        offset = framesPerMilliSecond * obj.offset\n        duration = nFrames - offset\n        duration = min(\n            duration,\n            framesPerMilliSecond * obj.duration if obj.duration is not None else duration\n        )\n\n        data.readframes(offset)\n        frames = data.readframes(duration)\n        for i in range(obj.loop):\n            waveObj = simpleaudio.WaveObject(frames, nChannels, bytesPerSample, sampleRate)\n            playObj = waveObj.play()\n            if obj.loop > 1 or wait:\n                playObj.wait_done()\n        return obj", "response": "This function plays an audio file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhandle an interlude event. Interlude functions permit branching. They return a folder which the application can choose to adopt as the next supplier of dialogue. This handler calls the interlude with the supplied arguments and returns the result. :param obj: A callable object. :param folder: A :py:class:`~turberfield.dialogue.model.SceneScript.Folder` object. :param int index: Indicates which scene script in the folder is being processed. :param ensemble: A sequence of Python objects. :param branches: A sequence of :py:class:`~turberfield.dialogue.model.SceneScript.Folder` objects. from which to pick a branch in the action. :return: A :py:class:`~turberfield.dialogue.model.SceneScript.Folder` object.", "response": "def handle_interlude(\n        self, obj, folder, index, ensemble,\n        loop=None, **kwargs\n    ):\n        \"\"\"Handle an interlude event.\n\n        Interlude functions permit branching. They return a folder which the\n        application can choose to adopt as the next supplier of dialogue.\n\n        This handler calls the interlude with the supplied arguments and\n        returns the result.\n\n        :param obj: A callable object.\n        :param folder: A\n            :py:class:`~turberfield.dialogue.model.SceneScript.Folder` object.\n        :param int index: Indicates which scene script in the folder\n            is being processed.\n        :param ensemble: A sequence of Python objects.\n        :param branches: A sequence of\n            :py:class:`~turberfield.dialogue.model.SceneScript.Folder` objects.\n            from which to pick a branch in the action.\n        :return: A :py:class:`~turberfield.dialogue.model.SceneScript.Folder`\n            object.\n\n        \"\"\"\n        if obj is None:\n            return folder.metadata\n        else:\n            return obj(folder, index, ensemble, loop=loop, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nhandles a line event. This function displays a line of dialogue. It generates a blocking wait for a period of time calculated from the length of the line. :param obj: A :py:class:`~turberfield.dialogue.model.Model.Line` object. :return: The supplied object.", "response": "def handle_line(self, obj):\n        \"\"\"Handle a line event.\n\n        This function displays a line of dialogue. It generates a blocking wait\n        for a period of time calculated from the length of the line.\n\n        :param obj: A :py:class:`~turberfield.dialogue.model.Model.Line` object.\n        :return: The supplied object.\n\n        \"\"\"\n        if obj.persona is None:\n            return obj\n\n        name = getattr(obj.persona, \"_name\", \"\")\n        print(\n            textwrap.indent(\n                \"{t.normal}{name}\".format(name=name, t=self.terminal),\n                \" \" * 2\n            ),\n            end=\"\\n\",\n            file=self.terminal.stream\n        )\n        print(\n            textwrap.indent(\n                \"{t.normal}{obj.text}\".format(\n                    obj=obj, t=self.terminal\n                ),\n                \" \" * 10\n            ),\n            end=\"\\n\" * 2,\n            file=self.terminal.stream\n        )\n        interval = self.pause + self.dwell * obj.text.count(\" \")\n        time.sleep(interval)\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhandle a memory event. This function accesses the internal database. It writes a record containing state information and an optional note. :param obj: A :py:class:`~turberfield.dialogue.model.Model.Memory` object. :return: The supplied object.", "response": "def handle_memory(self, obj):\n        \"\"\"Handle a memory event.\n\n        This function accesses the internal database. It writes a record\n        containing state information and an optional note.\n\n        :param obj: A :py:class:`~turberfield.dialogue.model.Model.Memory`\n            object.\n        :return: The supplied object.\n\n        \"\"\"\n        if obj.subject is not None:\n            with self.con as db:\n                SchemaBase.note(\n                    db,\n                    obj.subject,\n                    obj.state,\n                    obj.object,\n                    text=obj.text,\n                    html=obj.html,\n                )\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef handle_property(self, obj):\n        if obj.object is not None:\n            try:\n                setattr(obj.object, obj.attr, obj.val)\n            except AttributeError as e:\n                self.log.error(\". \".join(getattr(e, \"args\", e) or e))\n            try:\n                print(\n                    \"{t.dim}{obj.object._name}.{obj.attr} = {obj.val!s}{t.normal}\".format(\n                        obj=obj, t=self.terminal\n                    ),\n                    end=\"\\n\" * 2,\n                    file=self.terminal.stream\n                )\n            except AttributeError as e:\n                self.log.error(\". \".join(getattr(e, \"args\", e) or e))\n        return obj", "response": "This function will set an attribute on an object and print the object name and value."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhandles a scene event. This function applies a blocking wait at the start of a scene. :param obj: A :py:class:`~turberfield.dialogue.model.Model.Shot` object. :return: The supplied object.", "response": "def handle_scene(self, obj):\n        \"\"\"Handle a scene event.\n\n        This function applies a blocking wait at the start of a scene.\n\n        :param obj: A :py:class:`~turberfield.dialogue.model.Model.Shot`\n            object.\n        :return: The supplied object.\n\n        \"\"\"\n        print(\n            \"{t.dim}{scene}{t.normal}\".format(\n                scene=obj.scene.capitalize(), t=self.terminal\n            ),\n            end=\"\\n\" * 3,\n            file=self.terminal.stream\n        )\n        time.sleep(self.pause)\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nhandling a shot event.", "response": "def handle_shot(self, obj):\n        \"\"\"Handle a shot event.\n\n        :param obj: A :py:class:`~turberfield.dialogue.model.Model.Shot` object.\n        :return: The supplied object.\n\n        \"\"\"\n        print(\n            \"{t.dim}{shot}{t.normal}\".format(\n                shot=obj.name.capitalize(), t=self.terminal\n            ),\n            end=\"\\n\" * 3,\n            file=self.terminal.stream\n        )\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_db_version(session):\n    value = session.query(ProgramInformation.value).filter(ProgramInformation.name == \"db_version\").scalar()\n    return int(value)", "response": "get the database version number"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses a coverage report and returns the total number of items in the tree.", "response": "def parse_coverage(coverage_report, parser):\n    \"\"\"\n    :param coverage_report: A string with the contents of a coverage file\n    :type coverage_report: String\n    :param parser: A string with name of the parser to use\n    :type parser: String\n    :return: Total coverage\n    \"\"\"\n    if parser in PARSERS:\n        if coverage_report:\n            return PARSERS[parser].parse_coverage_report(coverage_report)\n        return None\n    return NotImplemented"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef handle_request(self):\n        try:\n            request, client_address = self.get_request()\n        except socket.error:\n            return\n\n        if self.verify_request(request, client_address):\n            self.workerpool.run(self.process_request_thread,\n                                **{'request': request,\n                                   'client_address': client_address})", "response": "simply collect requests and put them on the queue for the workers."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nobtains request from queue instead of directly from server socket", "response": "def process_request_thread(self, mainthread):\n        \"\"\"obtain request from queue instead of directly from server socket\"\"\"\n        life_time   = time.time()\n        nb_requests = 0\n\n        while not mainthread.killed():\n            if self.max_life_time > 0:\n                if (time.time() - life_time) >= self.max_life_time:\n                    mainthread.add_worker(1)\n                    return\n                try:\n                    SocketServer.ThreadingTCPServer.process_request_thread(self, *self.requests.get(True, 0.5))\n                except Queue.Empty:\n                    continue\n            else:\n                SocketServer.ThreadingTCPServer.process_request_thread(self, *self.requests.get())\n\n            LOG.debug(\"nb_requests: %d, max_requests: %d\", nb_requests, self.max_requests)\n            nb_requests += 1\n\n            if self.max_requests > 0 and nb_requests >= self.max_requests:\n                mainthread.add_worker(1)\n                return"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef handle_request(self):\n        try:\n            request, client_address = self.get_request()\n        except socket.error:\n            return\n\n        if self.verify_request(request, client_address):\n            self.requests.put((request, client_address))", "response": "simply collect requests and put them on the queue for the workers."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_version_number(ctx, bump=None, ignore_prerelease=False):\n    if bump is not None and bump.lower() not in VALID_BUMPS:\n        print(textwrap.fill(\"[{}WARN{}] bump level, as provided on command \"\n                            \"line, is invalid. Trying value given in \"\n                            \"configuration file. Valid values are {}.\"\n                            .format(WARNING_COLOR, RESET_COLOR,\n                                    VALID_BUMPS_STR),\n                            width=text.get_terminal_size().columns - 1,\n                            subsequent_indent=' '*7))\n        bump = None\n    else:\n        update_level = bump\n\n    # Find current version\n    temp_file = Path(ctx.releaser.version).resolve().parent / (\"~\" + Path(ctx.releaser.version).name)\n    with temp_file.open(mode='w', encoding='utf-8') as g:\n        with Path(ctx.releaser.version).resolve().open(mode='r', encoding='utf-8') as f:\n            for line in f:\n                version_matches = bare_version_re.match(line)\n                if version_matches:\n                    bare_version_str = version_matches.groups(0)[0]\n                    if semantic_version.validate(bare_version_str):\n                        old_version = Version(bare_version_str)\n                        print(\"{}Current version is {}\".format(\" \"*4,\n                                                               old_version))\n                    else:\n                        old_version = Version.coerce(bare_version_str)\n                        ans = text.query_yes_quit(\"{}I think the version is {}.\"\n                                                   \" Use it?\".format(\" \"*4,\n                                                                     old_version),\n                                                   default=\"yes\")\n                        if ans == text.Answers.QUIT:\n                            exit('[{}ERROR{}] Please set an initial version '\n                                 'number to continue.'.format(ERROR_COLOR,\n                                                              RESET_COLOR))\n\n                    # if bump level not defined by command line options\n                    if bump is None:\n                        try:\n                            update_level = ctx.releaser.version_bump\n                        except AttributeError:\n                            print(\"[{}WARN{}] bump level not defined in \"\n                                  \"configuration. Use key \"\n                                  \"'releaser.version_bump'\"\n                                  .format(WARNING_COLOR, RESET_COLOR))\n                            print(textwrap.fill(\"{}Valid bump levels are: \"\n                                                \"{}. Or use 'quit' to exit.\"\n                                                .format(\" \"*7,\n                                                        VALID_BUMPS_STR),\n                                                width=text.get_terminal_size().columns - 1,\n                                                subsequent_indent=' '*7))\n                            my_input = input(\"What bump level to use? \")\n                            if my_input.lower() in [\"quit\", \"q\", \"exit\", \"y\"]:\n                                sys.exit(0)\n                            elif my_input.lower() not in VALID_BUMPS:\n                                exit(\"[{}ERROR{}] invalid bump level provided. \"\n                                     \"Exiting...\".format(ERROR_COLOR, RESET_COLOR))\n                            else:\n                                update_level = my_input\n\n                    # Determine new version number\n                    if update_level is None or update_level.lower() in ['none']:\n                        update_level = None\n                    elif update_level is not None:\n                        update_level = update_level.lower()\n\n                    if update_level in ['breaking', 'major']:\n                        current_version = old_version.next_major()\n                    elif update_level in ['feature', 'minor']:\n                        current_version = old_version.next_minor()\n                    elif update_level in ['bugfix', 'patch']:\n                        current_version = old_version.next_patch()\n                    elif update_level in ['dev', 'development', 'prerelease']:\n                        if not old_version.prerelease:\n                            current_version = old_version.next_patch()\n                            current_version.prerelease = ('dev', )\n                        else:\n                            current_version = old_version\n                    elif update_level is None:\n                        # don't update version\n                        current_version = old_version\n                    else:\n                        exit('[{}ERROR{}] Cannot update version in {} mode'\n                             .format(ERROR_COLOR, RESET_COLOR, update_level))\n\n                    # warn on pre-release versions\n                    if current_version.prerelease and not ignore_prerelease:\n                        ans = text.query_yes_quit(\"[{}WARN{}] Current version \"\n                                                  \"is a pre-release version. \"\n                                                  \"Continue anyway?\"\n                                                  .format(WARNING_COLOR,\n                                                          RESET_COLOR),\n                                                  default=\"quit\")\n                        if ans == text.Answers.QUIT:\n                            sys.exit(1)\n\n                    print(\"{}New version is     {}\".format(\" \"*4,\n                                                           current_version))\n\n                    # Update version number\n                    line = '__version__ = \"{}\"\\n'.format(current_version)\n                print(line, file=g, end=\"\")\n        #print('', file=g)  # add a blank line at the end of the file\n    shutil.copyfile(str(temp_file), str(Path(ctx.releaser.version).resolve()))\n    os.remove(str(temp_file))\n    return(old_version, current_version)", "response": "Update version number of the current version."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbuild distributions of the code.", "response": "def build_distribution():\n    \"\"\"Build distributions of the code.\"\"\"\n    result = invoke.run('python setup.py sdist bdist_egg bdist_wheel',\n                        warn=True, hide=True)\n    if result.ok:\n        print(\"[{}GOOD{}] Distribution built without errors.\"\n              .format(GOOD_COLOR, RESET_COLOR))\n    else:\n        print('[{}ERROR{}] Something broke trying to package your '\n              'code...'.format(ERROR_COLOR, RESET_COLOR))\n        print(result.stderr)\n        sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninstalling things that need to be in place before installing the main package.", "response": "def other_dependencies(ctx, server, environment):\n    \"\"\"Install things that need to be in place before installing the main package.\"\"\"\n    if 'extra_packages' in ctx.releaser:\n        server = server.lower()\n        extra_pkgs = []\n        if server in [\"local\"]:\n            if 'local' in ctx.releaser.extra_packages:\n                extra_pkgs.extend(ctx.releaser.extra_packages.local)\n        elif server in [\"testpypi\", \"pypitest\"]:\n            # these are packages not available on the test server, so install them\n            # off the regular pypi server\n            if 'test' in ctx.releaser.extra_packages and \\\n                                ctx.releaser.extra_packages.test is not None:\n                extra_pkgs.extend(ctx.releaser.extra_packages.test)\n        elif server in [\"pypi\"]:\n            if 'pypi' in ctx.releaser.extra_packages and \\\n                                ctx.releaser.extra_packages.pypi is not None:\n                extra_pkgs.extend(ctx.releaser.extra_packages.pypi)\n        else:\n            print(\"** Nothing more to install **\")\n\n        if extra_pkgs:\n            print('** Other Dependencies, based on server', server, '**')\n\n        for pkg in extra_pkgs:\n            result = invoke.run('env{0}{1}{0}Scripts{0}pip{2} install {3}'\n                                .format(os.sep, environment, PIP_EXT, pkg),\n                                hide=True)\n            if result.ok:\n                print('{}[{}GOOD{}] Installed {}'.format(\"\", GOOD_COLOR,\n                                                         RESET_COLOR, pkg))\n            else:\n                print('{}[{}ERROR{}] Something broke trying to install '\n                      'package: {}'.format(\"\", ERROR_COLOR, RESET_COLOR, pkg))\n                print(result.stderr)\n                sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_local_install(ctx, version, ext, server=\"local\"):\n    here = Path(ctx.releaser.here).resolve()\n    dist_dir = here / 'dist'\n\n    all_files = list(dist_dir.glob('*.{}'.format(ext)))\n    the_file = all_files[0]\n    for f in all_files[1:]:\n        if f.stat().st_mtime > the_file.stat().st_mtime:\n            the_file = f\n            # this is the latest generated file of the given version\n\n    environment = 'env-{}-{}-{}'.format(version, ext, server)\n    if server == \"local\":\n        pass\n    else:\n        # upload to server\n        print(\"** Uploading to server **\")\n        cmd = 'twine upload {}'.format(the_file)\n        # for PyPI, let twine pick the server\n        if server != \"pypi\":\n            cmd = cmd + ' -r {}'.format(server)\n        result = invoke.run(cmd, warn=True)\n        if result.failed:\n            print(textwrap.fill(\"[{}ERROR{}] Something broke trying to upload \"\n                                \"your package. This will be the case if you \"\n                                \"have already uploaded it before. To upload \"\n                                \"again, use a different version number \"\n                                \"(or a different build by including a '+' \"\n                                \"suffix to your version number).\"\n                                .format(ERROR_COLOR, RESET_COLOR),\n                                width=text.get_terminal_size().columns - 1,\n                                subsequent_indent=' '*8))\n            # print(result.stderr)\n\n    # remove directory if it exists\n    if (here / 'env' / environment).exists():\n        shutil.rmtree('env' + os.sep + environment)\n    invoke.run('python -m venv env{}{}'.format(os.sep, environment))\n    other_dependencies(ctx, server, environment)\n    if server == \"local\":\n        result = invoke.run('env{0}{1}{0}Scripts{0}pip{2} install {3} --no-cache'\n                            .format(os.sep, environment, '.exe', the_file),\n                            hide=True)\n    else:\n        #print(\"  **Install from server**\")\n        result = invoke.run('env{0}{1}{0}Scripts{0}pip{2} install -i {3} '\n                            '{4}=={5} --no-cache'\n                            .format(os.sep, environment, '.exe',\n                                    server_url(server),\n                                    ctx.releaser.module_name, version),\n                            hide=True)\n        if result.failed:\n            print('[{}ERROR{}] Something broke trying to install your package.'\n                  .format(ERROR_COLOR, RESET_COLOR))\n            print(result.stderr)\n            sys.exit(1)\n    print(\"** Test version of installed package **\")\n\n    result = invoke.run('env{0}{1}{0}Scripts{0}python{2} -c '\n                        'exec(\"\"\"import {3}\\\\nprint({3}.__version__)\"\"\")'\n                        .format(os.sep, environment, '.exe',\n                                (ctx.releaser.module_name).strip()))\n    test_version = result.stdout.strip()\n    # print(test_version, type(test_version), type(expected_version))\n    if Version(test_version) == version:\n        results = '{}{} install {} works!{}'.format(GOOD_COLOR, server, ext,\n                                                    RESET_COLOR)\n    else:\n        results = '{}{} install {} broken{}'.format(ERROR_COLOR, server, ext,\n                                                    RESET_COLOR)\n    print(results)\n    return results", "response": "Check if local install works?"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_release(ctx, bump=None, skip_local=False, skip_test=False,\n                 skip_pypi=False, skip_isort=False):\n    \"\"\"Make and upload the release.\"\"\"\n    colorama.init()\n    text.title(\"Minchin 'Make Release' for Python Projects v{}\".format(__version__))\n    print()\n\n    text.subtitle(\"Configuration\")\n    extra_keys = ['here',\n                  'source',\n                  'test',\n                  'docs',\n                  'version',\n                  'module_name',\n                 ]\n    check_configuration(ctx, 'releaser', extra_keys)\n\n    check_existence(ctx.releaser.here, \"base dir\", \"releaser.here\")\n\n    here = Path(ctx.releaser.here).resolve()\n    try:\n        check_existence(ctx.releaser.source, \"source\", \"releaser.source\", here)\n        check_existence(ctx.releaser.test, \"test dir\", \"releaser.test\", here, True)\n        check_existence(ctx.releaser.docs, \"doc dir\", \"releaser.docs\", here, True)\n        check_existence(ctx.releaser.version, \"version file\", \"releaser.version\", here)\n    except FileNotFoundError as e:\n        print(e)\n        sys.exit(1)\n    print()\n\n    text.subtitle(\"Git -- Clean directory?\")\n    try:\n        repo = git.Repo(str(here))\n    except git.exc.InvalidGitRepositoryError:\n        repo = None\n        print(textwrap.fill('[{}WARN{}] base directory does not appear to be '\n                            'a valid git repo.'.format(WARNING_COLOR,\n                                                       RESET_COLOR),\n                            width=text.get_terminal_size().columns - 1,\n                            subsequent_indent=' '*7))\n\n    if repo is not None:\n        if repo.is_dirty():\n            print(textwrap.fill('[{}WARN{}] git repo is dirty. You should '\n                                'probably commit your changes before '\n                                'continuing.'.format(WARNING_COLOR,\n                                                     RESET_COLOR),\n                                width=text.get_terminal_size().columns - 1,\n                                subsequent_indent=' '*7))\n            # True = yes, False = Quit\n            ans = text.query_yes_quit(' '*7 + 'Continue anyway or quit?',\n                                      default=\"quit\")\n            if ans == text.Answers.QUIT:\n                sys.exit(1)\n        else:\n            print(\"[{}GOOD{}] Clean Git repo.\".format(GOOD_COLOR, RESET_COLOR))\n    print()\n\n    text.subtitle(\"Sort Import Statements\")\n    if not skip_isort:\n        for f in Path(ctx.releaser.source).resolve().glob('**/*.py'):\n            isort.SortImports(f)\n            print('.', end=\"\")\n        if ctx.releaser.test is not None:\n            for f in Path(ctx.releaser.test).resolve().glob('**/*.py'):\n                isort.SortImports(f)\n                print('.', end=\"\")\n        print(' Done!')\n    else:\n        print(\"[{}WARN{}] Skipped!\".format(WARNING_COLOR, RESET_COLOR))\n    print()\n\n    if \"vendor_packages\" in ctx.releaser.keys():\n        text.subtitle(\"Vendorize!\")\n        vendorize(ctx, internal_call=True)\n\n    text.subtitle(\"Run Tests\")\n    # check setup.py\n    # python setup.py -r -s\n    # https://stackoverflow.com/questions/30328259/what-does-python-setup-py-check-actually-do\n    try:\n        cmd_none = (ctx.releaser.test_command).lower()\n    except AttributeError:\n        print(\"[{}WARN{}] test command not configured. Use key \"\n              \"'releaser.test_command'.\".format(WARNING_COLOR, RESET_COLOR))\n        cmd_none = 'none'\n    if cmd_none != 'none':\n        result = invoke.run(ctx.releaser.test_command, warn=True)\n        if not result.ok:\n            print(\"[{}WARN{}] the test suite reported errors.\"\n                  .format(WARNING_COLOR, RESET_COLOR))\n            ans = text.query_yes_quit(' '*7 + 'Continue anyway or quit?',\n                                      default=\"quit\")\n            if ans == text.Answers.QUIT:\n                sys.exit(1)\n    else:\n        print('[{}WARN{}] No test command given.'.format(WARNING_COLOR,\n                                                         RESET_COLOR))\n    print()\n\n    text.subtitle(\"Update Version Number\")\n    old_version, new_version = update_version_number(ctx, bump)\n    print()\n\n    text.subtitle(\"Add Release to Changelog\")\n    if old_version == new_version:\n        print(\"[{}WARN{}] Version hasn't changed. Not updating Changelog.\"\n              .format(WARNING_COLOR, RESET_COLOR))\n    else:\n        print(\"[{}WARN{}] I can't do this yet, but you probably should.\\n\"\n              \"           Not updating Changelog.\"\n              .format(WARNING_COLOR, RESET_COLOR))\n        # https://github.com/bitprophet/releases/blob/master/releases/util.py#L21\n        # https://github.com/pyinvoke/invocations/blob/master/invocations/packaging/release.py#L362\n    print()\n\n    text.subtitle(\"Build Documentation\")\n    try:\n        cmd_none = (ctx.releaser.doc_command).lower()\n    except (AttributeError, KeyError):\n        print(\"[{}WARN{}] documentation generation command not configured.\\n\"\n              \"           Use key 'releaser.doc_command'.\"\n              .format(WARNING_COLOR, RESET_COLOR))\n        cmd_none = 'none'\n    if cmd_none != 'none':\n        result = invoke.run(ctx.releaser.doc_command, warn=True)\n        if not result.ok:\n            print(\"[{}WARN{}] the documentation generation reported errors.\"\n                  .format(WARNING_COLOR, RESET_COLOR))\n            ans = text.query_yes_quit(' '*7 + 'Continue anyway or quit?',\n                                      default=\"quit\")\n            if ans == text.Answers.QUIT:\n                sys.exit(1)\n    else:\n        print('[{}WARN{}] No docmentation generation command given.'\n              .format(WARNING_COLOR, RESET_COLOR))\n    print()\n\n    ans = text.query_yes_quit('All good and ready to go?')\n    if ans == text.Answers.QUIT:\n        sys.exit(1)\n    print()\n\n    text.subtitle(\"Build Distributions\")\n    build_distribution()\n    print()\n\n    text.subtitle(\"Check Readme Rendering\")\n    result = invoke.run('twine check dist/*', warn=True)\n    if not result.ok:\n        print(\"[{}WARN{}] Readme reported ReST rendering errors.\"\n                .format(WARNING_COLOR, RESET_COLOR))\n        ans = text.query_yes_quit(' '*7 + 'Continue anyway or quit?',\n                                    default=\"quit\")\n        if ans == text.Answers.QUIT:\n            sys.exit(1)\n    else:\n        print(\"[{}GOOD{}] Readme renders.\".format(GOOD_COLOR, RESET_COLOR))\n    print()\n\n    server_list = []\n    if not skip_local:\n        server_list.append('local')\n    if not skip_test:\n        server_list.append('testpypi')\n    if not skip_pypi:\n        server_list.append('pypi')\n\n    success_list = []\n    for server in server_list:\n        for file_format in [\"tar.gz\", \"whl\"]:\n            text.subtitle(\"Test {} Build {}\".format(file_format, server))\n            s = check_local_install(ctx, new_version, file_format, server)\n            success_list.append(s)\n            print()\n\n    text.subtitle(\"Install Test Summary\")\n    for line in success_list:\n        print(line)\n    print()\n\n    # git commit\n\n    if repo is not None:\n        text.subtitle(\"Create Git Tag\")\n        _create_tag = True\n\n        # don't duplicate existing tag\n        tags = repo.tags\n        for tag in tags:\n            if tag.name == new_version:\n                print(\"[{}WARN{}] Git tag for version {} already exists. \"\n                      \"Skipping.\".format(WARNING_COLOR, RESET_COLOR, tag.name))\n                _create_tag = False\n                break\n\n        # warn on pre-release versions\n        if new_version.prerelease:\n            print(\"[{}WARN{}] Currently a pre-release version.\"\n                  .format(WARNING_COLOR, RESET_COLOR))\n            # True = yes, False = Quit\n            ans = text.query_yes_no(' '*7 + 'Create Git tag anyway?',\n                                    default=\"no\")\n            if ans == text.Answers.NO:\n                _create_tag = False\n        else:\n            ans = text.query_yes_no('Create Git tag for version {}?'.format(new_version),\n                                    default=\"no\")\n            if ans == text.Answers.NO:\n                _create_tag = False\n\n        if _create_tag:\n            print(\"Creating Git tag for version {}\".format(new_version))\n            repo.create_tag(new_version)\n        print()\n\n    text.subtitle(\"Bump Version to Pre-release?\")\n    ans = text.query_yes_no(\"Bump version to pre-release now?\")\n    if ans == text.Answers.YES:\n        old_version, new_version = update_version_number(ctx, 'prerelease', True)", "response": "Make and upload the release."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef iscm_md_update_dict(self, keypath, data):\n        current = self.metadata\n        for k in string.split(keypath, \".\"):\n            if not current.has_key(k):\n                current[k] = {}\n            current = current[k]\n        current.update(data)", "response": "Update a metadata dictionary entry\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef iscm_md_append_array(self, arraypath, member):\n        array_path = string.split(arraypath, \".\")\n        array_key = array_path.pop()\n        current = self.metadata\n        for k in array_path:\n            if not current.has_key(k):\n                current[k] = {}\n            current = current[k]\n        if not current.has_key(array_key):\n            current[array_key] = []\n        if not type(current[array_key]) == list:\n            raise KeyError(\"%s doesn't point to an array\" % arraypath)\n        current[array_key].append(member)", "response": "Append a member to a metadata array entry"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\napplies this ISCM configuration into a launchable resource such as a CloudCast instance or AutoScalingGroup.", "response": "def apply_to(self, launchable):\n        \"\"\"\n        Apply this ISCM configuration into a launchable resource, such as\n        an EC2 instance or an AutoScalingGroup LaunchConfig.\n        \"\"\"\n        # Update user data\n        if launchable.get_property(\"UserData\") is not None:\n            raise NotImplementedError(\"It's not yet supported to append SCM to existing userdata\")\n        user_data = {\n            \"Fn::Base64\" : {\n                \"Fn::Join\" : [\"\", [\n                    \"\\n\".join([\n                        r'#!/bin/bash',\n                        r'FATAL() { code=$1; shift; echo \"[FATAL] $*\" >&2; exit $code; }',\n                        r'ERROR() { echo \"[ERROR] $*\" >&2 ; }',\n                        r'WARN()  { echo \"[WARNING] $*\" >&2 ; }',\n                        r'INFO()  { echo \"[INFO] $*\" >&2 ; }', \"\",\n                    ])\n                ] + (self.wc_handle is not None and [\n                    cfnjoin(\"\",\n                        r'ISCM_WCHANDLE_URL=\"', self.wc_handle, '\"\\n'\n                    )\n                ] or []) + [\n                    \"\\n\".join([\n                        r'{',\n                        r'INFO \"CloudCast ISCM booting on $(date)\"',\n                        \"\\n\\n\"\n                    ])\n                ] + self.userdata_elems + [\n                    \"\\n\".join([ \"\",\n                        r'iscm_result=$?',\n                        r'[ -n \"$ISCM_WCHANDLE_URL\" ] && [ -n \"$(which cfn-signal)\" ] && cfn-signal -e $iscm_result $ISCM_WCHANDLE_URL',\n                        '\\nINFO \"CloudCast ISCM successfully completed on $(date)\"',\n                        '} 2>&1 | tee -a /iscm.log\\n'\n                    ])\n                ]\n            ]} \n        }\n        launchable.add_property(\"UserData\", user_data)\n\n        # Set meta data keys\n        for k in self.metadata:\n            if launchable.get_metadata_key(k) is not None:\n                raise NotImplementedError(\"It's not yet supported to append to existing metadata keys\")\n            launchable.add_metadata_key(k, self.metadata[k])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrefresh the orbital elements in the astorb. dat database table", "response": "def refresh(self):\n        \"\"\"\n        *refresh the orbital elements in the astorb.dat database table*\n\n        **Return:**\n            - ``astorb``\n\n        **Usage:**\n\n            See class docstring\n        \"\"\"\n        self.log.info('starting the ``refresh`` method')\n\n        astorbgz = self._download_astorb()\n        astorbDictList = self._parse_astorb_database_file(astorbgz)\n        self._import_astorb_to_database(astorbDictList)\n\n        self.log.info('completed the ``refresh`` method')\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndownloads the astorb database file", "response": "def _download_astorb(\n            self):\n        \"\"\"*download the astorb database file*\n\n        **Key Arguments:**\n            - ``astorbgz`` -- path to the downloaded astorb database file\n        \"\"\"\n        self.log.info('starting the ``_download_astorb`` method')\n\n        # DOWNLOAD ASTORB\n        url = self.settings[\"astorb\"][\"url\"]\n        print \"Downloading orbital elements from '%(url)s'\" % locals()\n\n        response = urllib2.urlopen(url)\n        data = response.read()\n        astorbgz = \"/tmp/astorb.dat.gz\"\n        file_ = open(astorbgz, 'w')\n        file_.write(data)\n        file_.close()\n\n        print \"Finished downloading orbital elements\" % locals()\n\n        self.log.info('completed the ``_download_astorb`` method')\n        return astorbgz"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _parse_astorb_database_file(\n            self,\n            astorbgz):\n        \"\"\"* parse astorb database file*\n\n        **Key Arguments:**\n            - ``astorbgz`` -- path to the downloaded astorb database file\n\n        **Return:**\n            - ``astorbDictList`` -- the astorb database parsed as a list of dictionaries\n        \"\"\"\n        self.log.info('starting the ``_parse_astorb_database_file`` method')\n\n        print \"Parsing the astorb.dat orbital elements file\"\n\n        with gzip.open(astorbgz, 'rb') as f:\n            thisData = f.read()\n\n        astorbDictList = []\n\n        lines = thisData.split(\"\\n\")\n        for l in lines:\n\n            if len(l) < 50:\n                continue\n            d = {}\n\n            # PARSE THE LINE FROM astorb.dat (UNNEEDED VALUES COMMENTED OUT)\n            d[\"mpc_number\"] = l[0:7].strip()\n            d[\"name\"] = l[7:26].strip()\n            d[\"discoverer\"] = l[26:41].strip()\n            d[\"H_abs_mag\"] = l[41:48].strip()\n            d[\"G_slope\"] = l[48:54].strip()\n            d[\"color_b_v\"] = l[54:59].strip()\n            d[\"diameter_km\"] = l[59:65].strip()\n            d[\"class\"] = l[65:71].strip()\n            # d[\"int1\"] = l[71:75].strip()\n            # d[\"int2\"] = l[75:79].strip()\n            # d[\"int3\"] = l[79:83].strip()\n            # d[\"int4\"] = l[83:87].strip()\n            # d[\"int5\"] = l[87:91].strip()\n            # d[\"int6\"] = l[91:95].strip()\n            d[\"orbital_arc_days\"] = l[95:101].strip()\n            d[\"number_obs\"] = l[101:106].strip()\n            d[\"epoch\"] = l[106:115].strip()\n            d[\"M_mean_anomaly_deg\"] = l[115:126].strip()\n            d[\"o_arg_peri_deg\"] = l[126:137].strip()\n            d[\"O_long_asc_node_deg\"] = l[137:148].strip()\n            d[\"i_inclination_deg\"] = l[148:158].strip()\n            d[\"e_eccentricity\"] = l[158:169].strip()\n            d[\"a_semimajor_axis\"] = l[169:182].strip()\n            d[\"orbit_comp_date\"] = l[182:191].strip()\n            d[\"ephem_uncertainty_arcsec\"] = l[191:199].strip()\n            d[\"ephem_uncertainty_change_arcsec_day\"] = l[199:208].strip()\n            d[\"ephem_uncertainty_date\"] = l[208:217].strip()\n            # d[\"peak_ephem_uncertainty_next_arcsec\"] = l[217:225].strip()\n            # d[\"peak_ephem_uncertainty_next_date\"] = l[225:234].strip()\n            # d[\"peak_ephem_uncertainty_10_yrs_from_ceu_arcsec\"] = l[\n            #     217:225].strip()\n            # d[\"peak_ephem_uncertainty_10_yrs_from_ceu_date\"] = l[\n            #     242:251].strip()\n            # d[\"peak_ephem_uncertainty_10_yrs_from_peu_arcsec\"] = l[\n            #     251:259].strip()\n            # d[\"peak_ephem_uncertainty_10_yrs_from_peu_date\"] = l[\n            #     259:].strip()\n\n            yyyy = int(d[\"epoch\"][:4])\n            mm = int(d[\"epoch\"][4:6])\n            dd = int(d[\"epoch\"][6:])\n            d[\"epoch_xeph\"] = \"%(mm)s/%(dd)s/%(yyyy)s\" % locals()\n\n            # CONVERT ASTORB DATABASE LINE TO XEPHEM DATABASE FORMAT\n            xephemStr = \"%(mpc_number)s %(name)s,e,%(i_inclination_deg)s,%(O_long_asc_node_deg)s,%(o_arg_peri_deg)s,%(a_semimajor_axis)s,0,%(e_eccentricity)s,%(M_mean_anomaly_deg)s,%(epoch_xeph)s,2000.0,%(H_abs_mag)s,%(G_slope)s\" % d\n            xephemStr = xephemStr.strip()\n\n            d[\"pyephem_string\"] = xephemStr\n            d[\"astorb_string\"] = l\n\n            # TIDYUP\n            if len(d[\"mpc_number\"]) == 0:\n                d[\"mpc_number\"] = None\n\n            for k, v in d.iteritems():\n                if v != None and len(v) == 0:\n                    d[k] = None\n\n            astorbDictList.append(d)\n\n        print \"Finshed parsing the astorb.dat orbital elements file\"\n\n        self.log.info('completed the ``_parse_astorb_database_file`` method')\n        return astorbDictList", "response": "Parse the astorb. dat orbital elements file and return a list of dictionaries"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _import_astorb_to_database(\n            self,\n            astorbDictList):\n        \"\"\"*import the astorb orbital elements to database*\n\n        **Key Arguments:**\n            - ``astorbDictList`` -- the astorb database parsed as a list of dictionaries\n\n        **Return:**\n            - None\n        \"\"\"\n        self.log.info('starting the ``_import_astorb_to_database`` method')\n\n        print \"Refreshing the orbital elements database table\"\n\n        dbSettings = self.settings[\"database settings\"][\"atlasMovers\"]\n\n        insert_list_of_dictionaries_into_database_tables(\n            dbConn=self.atlasMoversDBConn,\n            log=self.log,\n            dictList=astorbDictList,\n            dbTableName=\"orbital_elements\",\n            uniqueKeyList=[\"name\"],\n            dateModified=True,\n            batchSize=10000,\n            replace=True,\n            dbSettings=dbSettings\n        )\n\n        print \"Finished refreshing the orbital elements database table\"\n\n        self.log.info('completed the ``_import_astorb_to_database`` method')\n        return None", "response": "Import the astorb orbital elements to database"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef register_uri_backend(uri_scheme, create_method, module, c14n_uri_method, escape, cast, is_connected):\n    try:\n        delta_api =  __compare_api_level(module.apilevel, any_apilevel)\n        mod_paramstyle = module.paramstyle\n        mod_threadsafety = module.threadsafety\n    except NameError:\n        raise NotImplementedError(\"This module does not support registration \"\n                                  \"of non DBAPI services of at least apilevel 2.0\")\n    if delta_api < 0 or delta_api > 1:\n        raise NotImplementedError(\"This module does not support registration \"\n                                  \"of DBAPI services with a specified apilevel of %s\" % module.apilevel)\n    if mod_paramstyle not in ['pyformat', 'format', 'qmark']:\n        raise NotImplementedError(\"This module only supports registration \"\n                                  \"of DBAPI services with a 'format' or 'pyformat' 'qmark' paramstyle, not %r\" % mod_paramstyle)\n    if mod_threadsafety < any_threadsafety:\n        raise NotImplementedError(\"This module does not support registration \"\n                                  \"of DBAPI services of threadsafety %d (more generally under %d)\"\n                                  % (mod_threadsafety, any_threadsafety))\n    if not urisup.valid_scheme(uri_scheme):\n        raise urisup.InvalidSchemeError(\"Can't register an invalid URI scheme %r\" % uri_scheme)\n    __uri_create_methods[uri_scheme] = (create_method, module, c14n_uri_method, escape, cast, is_connected)", "response": "This method is used by backends only. It registers the given URI scheme with the given module."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef c14n_uri(sqluri):\n    uri_c14n_method = _get_methods_by_uri(sqluri)[METHOD_C14N_URI]\n    if not uri_c14n_method:\n        return sqluri\n    return uri_c14n_method(sqluri)", "response": "Ask the backend to c14n the uri."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprepare the SQL query for the entry - set.", "response": "def __preparequery(self, sql_query, columns):\n        \"\"\"\n        WARNING: You can't both pass a ${columns} literal to the\n        underlying .execute() method and use the columns escaping,\n        injection and symbolic access mechanism.\n        WARNING: It is not recommended to SELECT *\n        \"\"\"\n        if columns:\n            if \"${columns}\" not in sql_query:\n                raise TypeError(\"received columns but ${columns} not in query\")\n\n            escape = self.__methods[METHOD_ESCAPE]\n\n            self.__col2idx_map = {}\n            col_list = []\n\n            for idx, col in enumerate(columns):\n                self.__col2idx_map[col] = idx\n                col_list.append(escape(col))\n\n            return sql_query.replace(\"${columns}\", \",\".join(col_list))\n        else:\n            self.__col2idx_map = None\n\n            return sql_query"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexecuting a SQL query and returns the result as a string.", "response": "def query(self, sql_query, columns = None, parameters = None):\n        \"\"\"\n        If columns evaluates to true, sql_query must contain\n        \"${columns}\" (only once) and this substring will be replaced\n        by an SQL representation of the list of columns, correctly\n        escaped for the backend.\n        The resulting string is passed to the DBAPI2.0 .execute()\n        method of the underlying DBAPI2.0 cursor, alongside with\n        parameters.\n        If ''not columns'', the sql_query string will be passed\n        unchanged to the DBAPI2.0 .execute() method.\n        \"\"\"\n        tmp_query = self.__preparequery(sql_query, columns)\n        if self.__methods[METHOD_MODULE].paramstyle in ('format', 'pyformat'):\n            tmp_query = qmark_to_format(tmp_query)\n        \"\"\"\n        if self.__methods[METHOD_MODULE].paramstyle == \"qmark\":\n            if parameters is not None:\n                tmp_query = tmp_query % parameters\n                parameters = None\n        \"\"\"\n\n        try:\n            if parameters is None:\n                self.__dbapi2_cursor.execute(tmp_query)\n            else:\n                self.__dbapi2_cursor.execute(tmp_query, parameters)\n        except Exception, e:\n            # try to reconnect\n            self.__connection.reconnect(tmp_query, self.__log_reconnect)\n            self.__dbapi2_cursor = self.__connection._get_raw_cursor()\n\n            if parameters is None:\n                self.__dbapi2_cursor.execute(tmp_query)\n            else:\n                self.__dbapi2_cursor.execute(tmp_query, parameters)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef querymany(self, sql_query, columns, seq_of_parameters):\n        tmp_query = self.__preparequery(sql_query, columns)\n\n        if self.__methods[METHOD_MODULE].paramstyle == \"qmark\":\n            raise NotImplementedError, \"qmark isn't fully supported\"\n\n        try:\n            self.__dbapi2_cursor.executemany(tmp_query, seq_of_parameters)\n        except Exception, e:\n            self.__connection.reconnect(tmp_query, self.__log_reconnect)\n            self.__dbapi2_cursor = self.__connection._get_raw_cursor()\n\n            self.__dbapi2_cursor.executemany(tmp_query, seq_of_parameters)", "response": "Execute a query and return the number of rows that match the given sequence of parameters."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fetchone(self):\n        try:\n            result = self.__dbapi2_cursor.fetchone()\n        except Exception, e:\n            self.__connection.reconnect(None, self.__log_reconnect)\n            self.__dbapi2_cursor = self.__connection._get_raw_cursor()\n\n            result = self.__dbapi2_cursor.fetchone()\n\n        if not result:\n            return result\n        else:\n            return self.row(self.__col2idx_map, result)", "response": "Returns the first row of the result set."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning all rows from the cursor.", "response": "def fetchall(self):\n        \"\"\"\n        As in DBAPI2.0 (except the fact rows are not tuples but\n        lists so if you try to modify them, you will succeed instead of\n        the correct behavior that would be that an exception would have\n        been raised)\n        Additionally every row returned by this class is addressable\n        by column name besides the column position in the query.\n        \"\"\"\n        try:\n            allrows = self.__dbapi2_cursor.fetchall()\n        except Exception, e:\n            self.__connection.reconnect(None, self.__log_reconnect)\n            self.__dbapi2_cursor = self.__connection._get_raw_cursor()\n\n            allrows = self.__dbapi2_cursor.fetchall()\n\n        if not allrows:\n            return allrows\n        else:\n            return [self.row(self.__col2idx_map, dbapi2_row) for dbapi2_row in allrows]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef setoutputsize(self, size, column = None):\n        \"As in DBAPI2.0\"\n        if column is None:\n            self.__dbapi2_cursor.setoutputsize(size)\n        else:\n            self.__dbapi2_cursor.setoutputsize(size, column)", "response": "As in DBAPI2. 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconnects to the database.", "response": "def __connect(self):\n        \"\"\"\n        Connect to the database.\n        \"\"\"\n        self.__methods     = _get_methods_by_uri(self.sqluri)\n        uri_connect_method = self.__methods[METHOD_CONNECT]\n\n        self.__dbapi2_conn = uri_connect_method(self.sqluri)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reconnect(self, query = None, log_reconnect = False):\n        uri = list(urisup.uri_help_split(self.sqluri))\n        if uri[1]:\n            authority   = list(uri[1])\n            if authority[1]:\n                authority[1] = None\n            uri[1]      = authority\n\n        if log_reconnect:\n            LOG.warning('reconnecting to %r database (query: %r)', urisup.uri_help_unsplit(uri), query)\n        self.__connect()", "response": "Reconnect to the database."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncommitting any pending transaction to the database.", "response": "def commit(self):\n        \"\"\"\n        As in DBAPI2.0:\n        Commit any pending transaction to the database. Note that\n        if the database supports an auto-commit feature, this must\n        be initially off. An interface method may be provided to\n        turn it back on.\n\n        Database modules that do not support transactions should\n        implement this method with void functionality.\n        \"\"\"\n        try:\n            self.__dbapi2_conn.commit()\n        except Exception, e:\n            # try to reconnect\n            self.reconnect(None)\n            self.__dbapi2_conn.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef perform(self):\n        for request in self._cfg[Integrator._CFG_KEY_REQUESTS]:\n            request_type = self._cfg[Integrator._CFG_KEY_REQUESTS][request][Integrator._CFG_KEY_REQUEST_TYPE]\n            request_cfg_file = self._cfg[Integrator._CFG_KEY_REQUESTS][request][Integrator._CFG_KEY_REQUEST_CFG_FILE]\n            self._logger.debug('{}'.format(request_cfg_file))\n            self._process_request(request, request_type, request_cfg_file)", "response": "Performs bulk operation on the resource."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_session():\n    if hasattr(g, 'session'):\n        return g.session\n    sess = create_session(bind=current_app.config['DATABASE_ENGINE'])\n    try:\n        g.session = sess\n    except RuntimeError:\n        pass\n    return sess", "response": "Gets a session. If there s no yet creates one."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef init_db(uri, base, **kwargs):\n    engine = create_engine(uri, **kwargs)\n    base.metadata.create_all(engine)\n    return engine", "response": "Create an engine and tables\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvalidate the input fields of a PublishablePayload.", "response": "def _validate_inputs(actual_inputs, required_inputs, keypath=None):\r\n    \"\"\"\r\n    Validate inputs.  Raise exception if something is missing.\r\n\r\n    args:\r\n        actual_inputs:  the object/dictionary passed to a subclass of \r\n            PublishablePayload\r\n        required_inputs: the object/dictionary containing keys (and subkeys)\r\n            for required fields.  (See get_common_payload_template.)\r\n        keypath: used internally in recursive function calls.\r\n\r\n    return:\r\n        Nothing.  An exception will be raised if a problem is encountered.\r\n    \"\"\"\r\n    actual_keys = set(actual_inputs.keys())\r\n    required_keys = set(required_inputs.keys())\r\n    if actual_keys.intersection(required_keys) != required_keys:\r\n        prefix = '%s.' if keypath else ''\r\n        output_keys = {'%s%s' % (prefix, key) for key in required_keys}\r\n        raise Exception(\"Missing input fields.  Expected %s.\" % ', '.join(output_keys))\r\n    for key in required_keys:\r\n        # TODO: review the following usage of isinstance.\r\n        # Will this always be appropriate, given duck typing?\r\n        if isinstance(required_inputs[key], dict):\r\n            new_keypath = key if not keypath else '%s.%s' % (keypath, key)\r\n            _validate_inputs(\r\n                actual_inputs=actual_inputs[key],\r\n                required_inputs=required_inputs[key],\r\n                keypath=new_keypath\r\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a citation object to a string using standard citation formatting.", "response": "def _citation_to_string(citation):\r\n    \"\"\"\r\n    Convert citation object to a string, using standard citation formatting.  \r\n\r\n    args:\r\n        citation:   a dictionary potentially containing all fields from\r\n            pypif.obj.Reference, and possibly a few others\r\n\r\n    TODO: This is tedious and fragile.  Find a better way to get 'er done.\r\n    TODO: This function assumes that citations are either to books or journals.\r\n        urls are ignored.\r\n\r\n    references: \r\n        http://citrineinformatics.github.io/pif-documentation/schema_definition/common/Reference.html\r\n        http://www.scientificstyleandformat.org/Tools/SSF-Citation-Quick-Guide.html\r\n    \"\"\"\r\n    output = ''\r\n    sep = '. '\r\n\r\n    if 'authors' in citation:\r\n        authors = []\r\n        for author in citation['authors']:\r\n            if 'family_name' not in author:\r\n                continue\r\n            author_name = author['family_name']\r\n            if 'given_name' in author:\r\n                author_name += ' ' + author['given_name']\r\n            authors.append(author_name)\r\n        output += ', '.join(authors) + sep\r\n    if 'year' in citation:\r\n        output += str(citation['year']) + sep\r\n    if 'title' in citation:\r\n        output += citation['title'] + sep\r\n\r\n    if 'journal' in citation:\r\n        output += citation['journal'] + sep\r\n        if 'volume' in citation:\r\n            output += citation['volume']\r\n            if 'issue' in citation:\r\n                output += '(' + citation['issue'] + ')'\r\n            if 'page_location' in citation:\r\n                output += ':' + citation['page_location'] + sep\r\n    else:   # assume for now that the reference is to a book\r\n            # TODO(Handle url case.)\r\n        if 'edition' in citation:\r\n            output += citation['edition'] + sep\r\n        if 'publication_location' in citation:\r\n            output += citation['publication_location']\r\n            if 'publisher' in citation:\r\n                output += ': ' + citation['publisher'] + sep\r\n        elif 'publisher' in citation:\r\n            output += citation['publisher'] + sep\r\n        if 'extent' in citation:\r\n            output += citation['extent'] + sep\r\n        if 'notes' in citation:\r\n            output += citation['notes'] + sep\r\n\r\n    return output.strip()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_common_payload_template(services=None):\r\n    available_services = {'citrine', 'materials_commons', 'materials_data_facility'}\r\n    if services is None:\r\n        services = list(available_services)\r\n    else:\r\n        services = [service for service in services if service in available_services]\r\n        if not services:\r\n            services = list(available_services)\r\n    combined_requirements = {}\r\n    for service in services:\r\n        # TODO(Recursive check dictionaries to make sure all requirements fields are combined.)\r\n        service_requirements = eval('_%s_metadata_requirements()' % service)\r\n        if service_requirements:\r\n            for key in service_requirements:\r\n                if not key in combined_requirements:\r\n                    combined_requirements[key] = service_requirements[key]\r\n    return {\r\n        'all_fields': {\r\n            'title': 'string',\r\n            'source': {\r\n                'name': 'string',\r\n                'producer': 'string',\r\n                'url': 'url string',\r\n                'tags': ['string']\r\n            },\r\n            'data_contacts': [\r\n                {\r\n                    'given_name': 'string',\r\n                    'family_name': 'string',\r\n                    'title': 'string',\r\n                    'orcid': 'TBD',\r\n                    'email': 'string',\r\n                    'tags': ['string']\r\n                }\r\n            ],\r\n            'data_contributors': [\r\n                {\r\n                    'given_name': 'string',\r\n                    'family_name': 'string',\r\n                    'title': 'string',\r\n                    'orcid': 'TBD',\r\n                    'email': 'string',\r\n                    'tags': ['string']\r\n                }\r\n            ],\r\n            'links': {\r\n                'landing_page': 'uri (string)',\r\n                'publication': ['uri (string)'],\r\n                'data_doi': 'uri (string)',\r\n                'related_id': ['string'],\r\n                'parent_id': 'string'\r\n            },\r\n            'authors': [\r\n                {\r\n                    'given_name': 'string',\r\n                    'family_name': 'string',\r\n                    'title': 'string',\r\n                    'orcid': 'TBD',\r\n                    'email': 'string',\r\n                    'tags': ['string']\r\n                }\r\n            ],\r\n            'licenses': [\r\n                {\r\n                    'name': 'string',\r\n                    'description': 'string',\r\n                    'url': 'string',\r\n                    'tags': ['string']\r\n                }\r\n            ],\r\n            'citations': [\r\n                {\r\n                    'authors': [\r\n                        {\r\n                            'given_name': 'string',\r\n                            'family_name': 'string',\r\n                            'title': 'string',\r\n                            'orcid': 'TBD',\r\n                            'email': 'string',\r\n                            'tags': ['string']\r\n                        }\r\n                    ],\r\n                    'year': 'string',\r\n                    'title': 'string',\r\n                    'journal': 'string',\r\n                    'volume': 'string',\r\n                    'issue': 'string',\r\n                    'page_location': 'string',\r\n                    'edition': 'string',\r\n                    'publication_location': 'string',\r\n                    'publisher': 'string',\r\n                    'extent': 'string',\r\n                    'notes': 'string',\r\n                }\r\n            ],\r\n            'repository': 'not yet available',\r\n            'collection': 'not yet available',\r\n            'tags': ['string'],\r\n            'description': 'string',\r\n            'raw': 'not yet available',\r\n            'year': 'integer',\r\n            'composition': 'not yet available'\r\n        },\r\n        'required_fields': combined_requirements,\r\n        'usage': 'payload = <service class, e.g. CITPayload>(**input_dictionary).metapayload'\r\n    }", "response": "Returns a template dictionary that can be used to create a payload object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _plugin_get(self, plugin_name):\n        if not plugin_name:\n            return None, u\"Plugin name not set\"\n        for plugin in self.controller.plugins:\n            if not isinstance(plugin, SettablePlugin):\n                continue\n            if plugin.name == plugin_name:\n                return plugin, \"\"\n        return None, u\"Settable plugin '{}' not found\".format(plugin_name)", "response": "Find plugins in controller and return the corresponding SettablePlugin and error message"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef handle_msg(self, payload):\n        self.debug(u\"\\n{}\".format(pformat(payload)))\n        msg = payload['msg']\n        res = {\n            'msg': msg,\n            'error': \"\"\n        }\n        if msg == \"plugin_list\":\n            res['plugin_names'] = []\n            # Generate list of plugins available for frontend\n            for plugin in self.controller.plugins:\n                # Limit to plugins that work with this\n                if isinstance(plugin, SettablePlugin):\n                    res['plugin_names'].append(plugin.name)\n            return res\n        elif msg == \"plugin_get\":\n            res['plugin'] = {}\n            plugin_name = payload.get('plugin_name')\n            plugin, err = self._plugin_get(plugin_name)\n            if not plugin:\n                res['error'] = err\n                return res\n            res['plugin_name'] = plugin_name\n            res['plugin'] = plugin.get_info()\n            return res\n        elif msg == \"plugin_resource_list\":\n            res['resource_names'] = []\n            plugin_name = payload.get('plugin_name')\n            plugin, err = self._plugin_get(plugin_name)\n            if not plugin:\n                res['error'] = err\n                return res\n            res['plugin_name'] = plugin_name\n            try:\n                res['resource_names'] = plugin.resource_get_list()\n            except PluginException as e:\n                if str(e) == \"No resource path set\":\n                    self.debug(\n                        u\"Plugin '{}' has no resources\".format(plugin.name)\n                    )\n                else:\n                    self.exception(\n                        u\"Failed to get resource list for plugin '{}'\".format(\n                            plugin.name\n                        )\n                    )\n            return res\n        elif msg == \"plugin_resource_get\":\n            res['resource'] = {}\n            plugin_name = payload.get('plugin_name')\n            resource_name = payload.get('resource_name')\n            if not resource_name:\n                res['error'] = \"Resource name not set\"\n                return res\n            plugin, err = self._plugin_get(plugin_name)\n            if not plugin:\n                res['error'] = err\n                return res\n            res['plugin_name'] = plugin_name\n            res['resource_name'] = resource_name\n            res['resource'] = dict(plugin.resource_get(resource_name))\n            if \"path\" in res['resource']:\n                del res['resource']['path']\n            return res\n        elif msg == \"plugin_resource_load\":\n            res['resource_data'] = \"\"\n            plugin_name = payload.get('plugin_name')\n            resource_name = payload.get('resource_name')\n            if not resource_name:\n                res['error'] = \"Resource name not set\"\n                return res\n            plugin, err = self._plugin_get(plugin_name)\n            if not plugin:\n                res['error'] = err\n                return res\n            res['plugin_name'] = plugin_name\n            res['resource_name'] = resource_name\n            resource_dict = plugin.resource_get(resource_name)\n            if not resource_dict:\n                res['error'] = u\"Resource '{}' not found\".format(resource_name)\n                return res\n            self.debug(u\"Resource {}\".format(resource_dict))\n            try:\n                with open(resource_dict['path'], 'rb') as f:\n                    res['resource_data'] = base64.b64encode(f.read())\n            except:\n                self.exception(\n                    u\"Failed to load '{}'\".format(resource_dict['path'])\n                )\n                res['error'] = u\"Failed to load\"\n            return res\n        elif msg == \"plugin_data_get\":\n            plugin_name = payload.get('plugin_name')\n            plugin, err = self._plugin_get(plugin_name)\n            if not plugin:\n                res['error'] = err\n                return res\n            res['plugin_name'] = plugin_name\n            res['data'] = plugin.get_data()\n            return res\n        elif msg == \"plugin_data_set\":\n            plugin_name = payload.get('plugin_name')\n            plugin, err = self._plugin_get(plugin_name)\n            if not plugin:\n                res['error'] = err\n                return res\n            res['plugin_name'] = plugin_name\n            data = payload.get('data')\n            if not data:\n                res['error'] = u\"No data provided\"\n                return res\n            try:\n                plugin.on_config(data)\n            except NotImplementedError:\n                res['error'] = u\"Plugin does not support setting data\"\n                return res\n            except:\n                self.exception(\n                    u\"Failed to set data for {}\".format(plugin_name)\n                )\n                res['error'] = \"Failed to set data\"\n                return res\n            return {}\n        else:\n            self.error(u\"Unknown cmd '{}'\\n{}\".format(msg, payload))\n        return {}", "response": "Handle a message received from the network plugin protocol."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate and return a Builder for a component.", "response": "def _make_builder(config, current_target):\n    \"\"\"\n    Create and return a Builder for a component.\n\n    Arguments\n    component - The component the builder should be created for.\n    \"\"\"\n    tool_key = devpipeline_core.toolsupport.choose_tool_key(\n        current_target, _BUILD_TOOL_KEYS\n    )\n\n    return devpipeline_core.toolsupport.tool_builder(\n        config, tool_key, devpipeline_build.BUILDERS, current_target\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build_task(current_target):\n\n    target = current_target.config\n    try:\n        builder = _make_builder(target, current_target)\n        build_path = _get_build_path(target, builder)\n        if not os.path.exists(build_path):\n            os.makedirs(build_path)\n        builder.configure(src_dir=target.get(\"dp.src_dir\"), build_dir=build_path)\n        builder.build(build_dir=build_path)\n        no_install = devpipeline_core.toolsupport.choose_tool_key(\n            current_target, _NO_INSTALL_KEYS\n        )\n        if no_install not in target:\n            install_path = target.get(\n                devpipeline_core.toolsupport.choose_tool_key(\n                    current_target, _INSTALL_PATH_KEYS\n                ),\n                fallback=\"install\",\n            )\n            builder.install(build_dir=build_path, install_dir=install_path)\n            _find_file_paths(target, os.path.join(build_path, install_path))\n    except devpipeline_core.toolsupport.MissingToolKey as mtk:\n        current_target.executor.warning(mtk)", "response": "Build a target.\n\n    Arguments\n    target - The target to build."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(self, profile_id):\n        '''Return the profile with the received ID as a dict\n\n        If a local copy of the profile exists, it'll be returned. If not, it'll\n        be downloaded from the web. The results are cached, so any subsequent\n        calls won't hit the filesystem or the web.\n\n        This method raises DataPackageRegistryException if there were any\n        errors.\n        '''\n        if profile_id not in self._profiles:\n            try:\n                self._profiles[profile_id] = self._get_profile(profile_id)\n            except (IOError,\n                    ValueError,\n                    requests.exceptions.RequestException) as e:\n                six.raise_from(DataPackageRegistryException(e), e)\n        return self._profiles[profile_id]", "response": "Return the profile with the received ID as a dict\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the profile with the received ID as a dict", "response": "def _get_profile(self, profile_id):\n        '''Return the profile with the received ID as a dict'''\n        profile_metadata = self._registry.get(profile_id)\n        if not profile_metadata:\n            return\n\n        path = self._get_absolute_path(profile_metadata.get('schema_path'))\n        if path and os.path.isfile(path):\n            return self._load_json_file_or_url(path)\n\n        url = profile_metadata.get('schema')\n        if url:\n            return self._load_json_file_or_url(url)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_registry(self, registry_path_or_url):\n        '''Return a dict with objects mapped by their id from a CSV endpoint'''\n        if os.path.isfile(registry_path_or_url):\n            with open(registry_path_or_url, 'r') as f:\n                reader = compat.csv_dict_reader(f.readlines())\n        else:\n            res = requests.get(registry_path_or_url)\n            res.raise_for_status()\n\n            reader = compat.csv_dict_reader(StringIO(res.text))\n\n        return dict([(o['id'], o) for o in reader])", "response": "Return a dict with objects mapped by their id from a CSV endpoint"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads the JSON at the local path or URL as a dict", "response": "def _load_json_file_or_url(self, json_path_or_url):\n        '''Return the JSON at the local path or URL as a dict\n\n        This method raises DataPackageRegistryException if there were any\n        errors.\n        '''\n        try:\n            if os.path.isfile(json_path_or_url):\n                with open(json_path_or_url, 'r') as f:\n                    result = json.load(f)\n            else:\n                res = requests.get(json_path_or_url)\n                res.raise_for_status()\n                result = res.json()\n\n            return result\n\n        except (ValueError,\n                requests.exceptions.RequestException) as e:\n            six.raise_from(DataPackageRegistryException(e), e)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef kill(self, nb = 1):\n        self.count_lock.acquire()\n        if nb > self.workers:\n            nb = self.workers\n        self.count_lock.release()\n        for x in xrange(nb):\n            self.tasks.put(WorkerExit())", "response": "Kill one or many workers."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the maximum number of workers to create.", "response": "def set_max_workers(self, nb):\n        \"\"\"\n        Set the maximum workers to create.\n        \"\"\"\n        self.count_lock.acquire()\n        self.max_workers = nb\n        if self.workers > self.max_workers:\n            self.kill(self.workers - self.max_workers)\n        self.count_lock.release()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add(self, nb = 1, name = None, xid = None):\n        for x in xrange(nb):\n            self.count_lock.acquire()\n            if self.workers >= self.max_workers:\n                self.count_lock.release()\n                continue\n            self.workers += 1\n            if xid is None:\n                xid = self.workers\n            self.count_lock.release()\n            self.kill_event.clear()\n            w = WorkerThread(xid, self)\n            w.setName(self.get_name(xid, name))\n            w.start()", "response": "Create one or many workers."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run(self, target, callback = None, name = None, complete = None, *args, **kargs):\n        self.count_lock.acquire()\n        if not self.workers:\n            self.count_lock.release()\n            self.add(name = name)\n        else:\n            self.count_lock.release()\n        self.tasks.put((target, callback, name, complete, args, kargs))", "response": "Start a new task."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef killall(self, wait = None):\n        with self.tasks.mutex:\n            self.tasks.queue.clear()\n        self.count_lock.acquire()\n        self.kill(self.workers)\n        self.count_lock.release()\n        self.kill_event.wait(wait)", "response": "Kill all active workers."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of possible build ids that are valid entry points in this ISCM.", "response": "def get_possible_builds(self, purpose=PURPOSE_RUN):\n        \"\"\"\n        Returns a list of possible status ids that are valid entry points\n        into this ISCM. For each status, there is a list of phases that need\n        to be executed, i.e.:\n\n        [\n         { status_id: \"ykyk...\", run_phases: [ ] },\n         { status_id: \"znzn...\", run_phases: [ <phase3> ] },\n         { status_id: \"xyxy...\", run_phases: [ <phase2>, <phase3> ] },\n         { status_id: \"\",        run_phases: [ <phase1>, <phase2>, <phase3> ] },\n        ]\n\n        the array is sorted in such a way that entries with the least pending\n        phases are found first.\n\n        When purpose = PURPOSE_BUILD, each runnable path contains a list of the\n        buildable targets and the phases that need to be run to achieve them:\n\n        [\n         { status_id: \"ykyk...\", targets = [] },\n         { status_id: \"znzn...\", targets=[\n          { target_id: \"ykyk...\", run_phases: [ <phase3> ] },\n         ]},\n         { status_id: \"xyxy...\", targets=[\n          { target_id: \"ykyk...\", run_phases: [ <phase2>, <phase3> ] },\n          { target_id: \"znzn...\", run_phases: [ <phase2> ] },\n         ]},\n         { status_id: \"\", targets=[\n          { target_id: \"ykyk...\", run_phases: [ <phase1>, <phase2>, <phase3> ] },\n          { target_id: \"znzn...\", run_phases: [ <phase1>, <phase2> ] },\n          { target_id: \"xyxy...\", run_phases: [ <phase1> ] },\n         ]}\n        ]\n        \"\"\"\n        import hashlib\n        from copy import copy\n        \n        phases = self.phases\n        pending_list = copy(phases)\n        must_run_list = []\n        stages = [ dict(status_id=\"\", must_run=copy(must_run_list), pending=copy(pending_list)) ]\n        hashsum = hashlib.sha256()\n        status_id_after = {}    # after phase_name\n        #\n        for p in copy(pending_list):\n            hashsum.update(_dict_to_stable_str(p.get_dict_repr()))\n            status_id_after[p.phase_name] = hashsum.hexdigest()\n            pending_list = pending_list[1:]\n            if p.phase_type == RUN_EVERY_TIME:\n                must_run_list.append(p)\n                continue\n            elif p.phase_type == RUN_ON_UPDATE and purpose == PURPOSE_BUILD:\n                must_run_list.append(p)\n                continue\n            elif p.phase_type == RUN_ONCE:\n                # possible point of entry for AMIs\n                stages.insert(0, dict(status_id=hashsum.hexdigest(), must_run=copy(must_run_list), pending=copy(pending_list)))\n            elif p.phase_type == RUN_ON_DEPLOY:\n                # no more saved entry points possible\n                break\n        #\n        # If we are building images, add possible builds from each entry point\n        if purpose == PURPOSE_BUILD:\n            for rp in stages:\n                targets = []\n                must_run = rp[\"must_run\"]\n                pending = rp[\"pending\"]\n                del rp[\"must_run\"]\n                del rp[\"pending\"]\n                iterated = []\n                for p in pending:\n                    iterated.append(p)\n                    if p.phase_type == RUN_ONCE:\n                        # this makes a new target\n                        target = dict(target_id=status_id_after[p.phase_name], run_phases=must_run + iterated)\n                        targets.insert(0, target)\n                rp[\"targets\"] = targets\n        else:\n            for rp in stages:\n                rp[\"run_phases\"] = rp[\"must_run\"] + rp[\"pending\"]\n                del rp[\"must_run\"]\n                del rp[\"pending\"]\n        #\n        return stages"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_dict_repr(self):\n        return dict(\n            phase_name = self.phase_name,\n            phase_type = self.phase_type,\n            actions = self.actions\n            )", "response": "Returns a dictionary representation of this phase."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef discrete_index(self, indices):\n        elements = []\n        for i in indices:\n            elements.append(self[i])\n        return elements", "response": "get elements by discrete indices"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_rotation_scale(im0, im1, isccs=False):\n    # sanitize input\n    im0 = np.asarray(im0, dtype=np.float32)\n    im1 = np.asarray(im1, dtype=np.float32)\n    truesize = None\n\n    # if ccs, convert to shifted dft before giving to polar_fft\n    if isccs:\n        truesize = im0.shape\n        im0 = centered_mag_sq_ccs(im0)\n        im1 = centered_mag_sq_ccs(im1)\n    # Get log polar coordinates. choose the log base\n    lp1, log_base = polar_fft(im1, logpolar=True, isshiftdft=isccs,\n                              logoutput=True, truesize=truesize)\n    lp0, log_base = polar_fft(im0, logpolar=True, isshiftdft=isccs,\n                              logoutput=True, truesize=truesize,\n                              nangle=lp1.shape[0], radiimax=lp1.shape[1])\n    # Find the shift with log of the log-polar images,\n    # to compensate for dft intensity repartition\n    angle, scale = find_shift_dft(lp0, lp1)\n    # get angle in correct units\n    angle *= np.pi / lp1.shape[0]\n    # get scale in linear units\n    scale = log_base ** (scale)\n    # return angle and scale\n    return angle, scale", "response": "Compares the images and returns the best guess for the rotation angle and scale difference."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_shift_dft(im0, im1, isccs=False, subpix=True):\n    # sanitize input\n    im0 = np.asarray(im0, dtype=np.float32)\n    im1 = np.asarray(im1, dtype=np.float32)\n\n    # check input\n    if not isccs:\n        im0, im1 = dft_optsize_same(im0, im1)\n    else:\n        # Work only if the shapes are the same\n        assert(im0.shape == im1.shape)\n\n    # f0*conj(f1)\n    mulSpec = cv2.mulSpectrums(im0, im1, flags=0, conjB=True)\n    # norm(f0)*norm(f1)\n    normccs = cv2.sqrt(cv2.mulSpectrums(im0, im0, flags=0, conjB=True) *\n                       cv2.mulSpectrums(im1, im1, flags=0, conjB=True))\n    # compute the inverse DFT\n    xc = cv2.dft(ccs_normalize(mulSpec, normccs),\n                 flags=cv2.DFT_REAL_OUTPUT | cv2.DFT_INVERSE)\n    # Blur xc to remove some noise and improve the subpixel detection\n    # workaround as GaussianBlur doesn't work with BORDER_WRAP\n    blurRadii = 2\n    xc = cv2.copyMakeBorder(xc, blurRadii, blurRadii, blurRadii, blurRadii,\n                            borderType=cv2.BORDER_WRAP)\n    xc = cv2.GaussianBlur(xc, (2 * blurRadii + 1, 2 * blurRadii + 1), 1.5)\n    xc = xc[blurRadii:-blurRadii, blurRadii:-blurRadii]\n    # save shape\n    shape = np.asarray(xc.shape)\n    # find max\n    idx = np.asarray(np.unravel_index(np.argmax(xc), shape))\n\n    \"\"\"\n    from matplotlib import pyplot as plt\n    from numpy.fft import fftshift\n    plt.figure()\n    plt.imshow(np.log(np.abs(fftshift(im0))))\n    plt.figure()\n    plt.imshow(np.log(np.abs(fftshift(im1))))\n    plt.figure()\n    plt.imshow(fftshift(ccs_normalize(mulSpec,normccs)))\n    plt.figure()\n    extent= (-np.shape(xc)[1]/2, np.shape(xc)[1]/2, -np.shape(xc)[0]/2, np.shape(xc)[0]/2  )\n    plt.imshow(np.log(np.abs(fftshift(xc))),extent = extent)\n\n    #\"\"\"\n    # plt.imshow(fftshift(xc))\n    # print(idx)\n    # plt.figure()\n#    if toremove:\n#        plt.figure(1)\n#        l=len(xc[:,0])\n#        plt.plot(np.arange(l)/l,xc[:,0])\n#        print(l,xc[-1,0])\n#        plt.figure(2)\n\n    #\"\"\"\n\n    if subpix:\n        # update idx\n        idx = np.asarray([get_peak_pos(xc[:, idx[1]], wrap=True),\n                          get_peak_pos(xc[idx[0], :], wrap=True)])\n    else:\n        # restrics to reasonable values\n        idx[idx > shape // 2] -= shape[idx > shape // 2]\n    return idx", "response": "Find the shift between two images using the DFT method."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind the best shift between im0 and im1 using cross correlation.", "response": "def find_shift_cc(im0, im1, ylim=None, xlim=None, subpix=True):\n    \"\"\"Finds the best shift between im0 and im1 using cross correlation\n\n    Parameters\n    ----------\n    im0: 2d array\n        First image\n    im1: 2d array\n        Second image\n    ylim: 2 numbers, optional\n        The y limits of the search (if None full range is searched)\n    xlim: 2 numbers, optional\n        Ibidem with x\n\n    Returns\n    -------\n    [y, x]: 2 numbers\n        The offset\n\n    Notes\n    -----\n    The origin of im1 in the im0 referential is returned\n\n    ylim and xlim limit the possible output.\n\n    No subpixel precision\n    \"\"\"\n    # sanitize input\n    im0 = np.asarray(im0, dtype=np.float32)\n    im1 = np.asarray(im1, dtype=np.float32)\n    # Remove mean\n    im0 = im0 - np.nanmean(im0)\n    im1 = im1 - np.nanmean(im1)\n    # Save shapes as np array\n    shape0 = np.asarray(im0.shape)\n    shape1 = np.asarray(im1.shape)\n\n    # Compute the offset and the pad (yleft,yright,xtop,xbottom)\n    offset = 1 - shape1\n    pad = np.lib.pad(-offset, (1, 1), mode='edge')\n\n    # apply limit on padding\n    if ylim is not None:\n        pad[0] = -ylim[0]\n        pad[1] = ylim[1] + (shape1 - shape0)[0]\n    if xlim is not None:\n        pad[2] = -xlim[0]\n        pad[3] = xlim[1] + (shape1 - shape0)[1]\n\n    # pad image\n    im0, offset = pad_img(im0, pad)\n    # compute Cross correlation matrix\n    xc = cv2.matchTemplate(im0, im1, cv2.TM_CCORR)\n    # Find maximum of abs (can be anticorrelated)\n    idx = np.asarray(np.unravel_index(np.argmax(xc), xc.shape))\n    # Return origin in im0 units\n    if subpix:\n        # update idx\n        idx = np.asarray([get_peak_pos(xc[:, idx[1]], wrap=False),\n                          get_peak_pos(xc[idx[0], :], wrap=False)])\n    else:\n        # restrics to reasonable values\n        idx[idx > shape // 2] -= shape[idx > shape // 2]\n        \n    return idx + offset"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef combine_images(imgs, register=True):\n    imgs = np.asarray(imgs, dtype=\"float\")\n    if register:\n        for i in range(1, imgs.shape[0]):\n            ret = register_images(imgs[0, :, :], imgs[i, :, :])\n            imgs[i, :, :] = rotate_scale_shift(imgs[i, :, :], *ret[:3], np.nan)\n    return np.mean(imgs, 0)", "response": "Combine similar images into one"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef orientation_angle(im, approxangle=None, *, isshiftdft=False, truesize=None,\n                      rotateAngle=None):\n    \"\"\"Give the highest contribution to the orientation\n\n    Parameters\n    ----------\n    im: 2d array\n        The image\n    approxangle: number, optional\n        The approximate angle (None if unknown)\n    isshiftdft: Boolean, default False\n        True if the image has been processed (DFT, fftshift)\n    truesize: 2 numbers, optional\n        Truesize of the image if isshiftdft is True\n    rotateAngle: number, optional\n        The diagonals are more sensitives than the axis.\n        rotate the image to avoid pixel orientation (flat or diagonal)\n\n    Returns\n    -------\n    angle: number\n        The orientation of the image\n\n    Notes\n    -----\n    if approxangle is specified, search only within +- pi/4\n    \"\"\"\n    im = np.asarray(im)\n\n    # If we rotate the image first\n    if rotateAngle is not None and not isshiftdft:\n        # compute the scale corresponding to the image\n        scale = np.sqrt(.5 * (1 + (np.tan(rotateAngle) - 1)**2 /\n                              (np.tan(rotateAngle) + 1)**2))\n        # rotate the image\n        im = rotate_scale(im, rotateAngle, scale)\n\n    # compute log fft (nearest interpolation as line go between pixels)\n    lp = polar_fft(im, isshiftdft=isshiftdft,\n                   logoutput=False, interpolation='nearest',\n                   truesize=truesize)\n    # get distribution\n    adis = lp.sum(-1)\n    if approxangle is not None:\n        #-np.pi/2 as we are in fft. +- pi/4 is search window\n        amin = clamp_angle(approxangle - np.pi / 4 - np.pi / 2)\n        amax = clamp_angle(approxangle + np.pi / 4 - np.pi / 2)\n        angles = np.linspace(-np.pi / 2, np.pi / 2,\n                             lp.shape[0], endpoint=False)\n        if amin > amax:\n            adis[np.logical_and(angles > amax, angles < amin)] = adis.min()\n        else:\n            adis[np.logical_or(angles > amax, angles < amin)] = adis.min()\n\n    # get peak pos\n    ret = get_peak_pos(adis, wrap=True)\n    anglestep = np.pi / lp.shape[0]\n\n    \"\"\"\n    import matplotlib.pyplot as plt\n    plt.figure()\n    plt.plot(anglestep*np.arange(len(adis)),adis)\n    #\"\"\"\n\n    # return max (not -pi/2 as 0 is along y and we want 0 alonx x.)\n    # the transformation is basically \"For Free\"\n    ret = clamp_angle(ret * anglestep)\n\n    # Substract rotateAngle to get the original image\n    if rotateAngle is not None:\n        ret = clamp_angle(ret - rotateAngle)\n\n    return ret", "response": "Compute the angle of the image in the order that it is in the image."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef orientation_angle_2(im, nangle=None, isshiftdft=False, rotateAngle=None):\n    im = np.asarray(im, dtype=np.float32)\n\n    # If we rotate the image first\n    if rotateAngle is not None and not isshiftdft:\n        # compute the scale corresponding to the image\n        scale = np.sqrt(.5 * (1 + (np.tan(rotateAngle) - 1)**2 /\n                              (np.tan(rotateAngle) + 1)**2))\n        # rotate the image\n        im = rotate_scale(im, rotateAngle, scale)\n    else:\n        rotateAngle = 0\n\n    # get dft if not already done\n    if not isshiftdft:\n        im = centered_mag_sq_ccs(dft_optsize(im))\n\n    # the center is shifted from 0,0 to the ~ center\n    #(eg. if 4x4 image, the center is at [2,2], as if 5x5)\n    qshape = np.asarray([im.shape[0] // 2, im.shape[1]])\n    center = np.asarray([qshape[0], 0])\n    im[qshape[0], 0] = 0\n\n    # if the angle Step is not given, take the number of pixel\n    # on the perimeter as the target #=range/step\n\n    if nangle is None:\n        nangle = np.min(im.shape)  # range is pi, nbangle = 2r =~pi r\n\n    # get the theta range\n    theta = np.linspace(-np.pi / 2, np.pi / 2, nangle,\n                        endpoint=False, dtype=np.float32)\n#    X=np.arange(im.shape[1])-center[1]\n#    Y=-(np.arange(im.shape[0])-center[0])\n#    YG, XG =np.meshgrid(Y,X,indexing='ij')\n\n    YG, XG = np.ogrid[-center[0]:im.shape[0] - center[0],\n                      -center[1]:im.shape[1] - center[1]]\n    YG = -YG\n    values = np.empty(theta.shape)\n\n    # save useful value for computations\n    ylim = center[0] + 1\n\n    # The negative upper limit is the top right corner\n    upper = np.arctan((YG + .5) / (XG + .5))\n    # save lower for later\n    lower = upper.copy()\n    # The positive is top left\n    upper[:ylim, 1:] = upper[:ylim, :-1]\n    # for X=0, the top left is meaningless (atan gives only up to pi/2)\n    # should be pi/2 but not important as angle are smaller anyway\n    # Therefore avoid pi/2<pi/2 being false\n    upper[:ylim, 0] = np.pi\n\n    # idem for lower limit: lower right for positives\n    lower[:-1, :] = lower[1:, :]\n    lower[-1, :] = np.arctan((YG[-1, :] - .5) / (XG[-1, :] + .5))\n    # For negative t, the lower left\n    lower[ylim:, 1:] = lower[ylim:, :-1]\n    # correct arctan\n    lower[ylim:, 0] = -np.pi\n\n    for i, t in enumerate(theta.flat):\n        cond = np.logical_and(t > lower,\n                              t < upper)\n        values[i] = np.sum(im[cond])\n\n    \"\"\"\n    import matplotlib.pyplot as plt\n#    plt.figure()\n#    plt.imshow(np.log(im[qshape[0]-5:qshape[0]+5,:5]),interpolation='none')\n    plt.figure()\n    plt.plot(theta, values,'x')\n#    plt.plot(ir.clamp_angle(0.0555-np.pi/2-rotateAngle)*np.array([1,1]),[np.amin(values),np.amax(values)])\n    #\"\"\"\n\n    return clamp_angle(theta[np.argmax(values)] + np.pi / 2 + rotateAngle)", "response": "Gives the highest contribution to the orientation of the image in 2d array."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dft_optsize_same(im0, im1):\n    im0 = np.asarray(im0)\n    im1 = np.asarray(im1)\n    # save shape\n    shape0 = im0.shape\n    shape1 = im1.shape\n    # get optimal size\n    ys = max(cv2.getOptimalDFTSize(shape0[0]),\n             cv2.getOptimalDFTSize(shape1[0]))\n    xs = max(cv2.getOptimalDFTSize(shape0[1]),\n             cv2.getOptimalDFTSize(shape1[1]))\n    shape = [ys, xs]\n    f0 = dft_optsize(im0, shape=shape)\n    f1 = dft_optsize(im1, shape=shape)\n    return f0, f1", "response": "Resize 2 image same size for optimal DFT and computes it\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrotating and scales the image in the alphabetical order.", "response": "def rotate_scale(im, angle, scale, borderValue=0, interp=cv2.INTER_CUBIC):\n    \"\"\"Rotates and scales the image\n\n    Parameters\n    ----------\n    im: 2d array\n        The image\n    angle: number\n        The angle, in radians, to rotate\n    scale: positive number\n        The scale factor\n    borderValue: number, default 0\n        The value for the pixels outside the border (default 0)\n\n    Returns\n    -------\n    im: 2d array\n        the rotated and scaled image\n\n    Notes\n    -----\n    The output image has the same size as the input.\n    Therefore the image may be cropped in the process.\n    \"\"\"\n    im = np.asarray(im, dtype=np.float32)\n    rows, cols = im.shape\n    M = cv2.getRotationMatrix2D(\n        (cols / 2, rows / 2), -angle * 180 / np.pi, 1 / scale)\n    im = cv2.warpAffine(im, M, (cols, rows),\n                        borderMode=cv2.BORDER_CONSTANT,\n                        flags=interp,\n                        borderValue=borderValue)  # REPLICATE\n    return im"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the DFT in polar or log - polar units", "response": "def polar_fft(im, nangle=None, radiimax=None, *, isshiftdft=False,\n              truesize=None, logpolar=False, logoutput=False,\n              interpolation='bilinear'):\n    \"\"\"Return dft in polar (or log-polar) units, the angle step\n    (and the log base)\n\n    Parameters\n    ----------\n    im: 2d array\n        The image\n    nangle: number, optional\n        The number of angles in the polar representation\n    radiimax: number, optional\n        The number of radius in the polar representation\n    isshiftdft: boolean, default False\n        True if the image is pre processed (DFT + fftshift)\n    truesize: 2 numbers, required if isshiftdft is True\n        The true size of the image\n    logpolar: boolean, default False\n        True if want the log polar representation instead of polar\n    logoutput: boolean, default False\n        True if want the log of the output\n    interpolation: string, default 'bilinear'\n        ('bicubic', 'bilinear', 'nearest') The interpolation\n        technique. (For now, avoid bicubic)\n\n    Returns\n    -------\n    im: 2d array\n        The (log) polar representation of the input image\n    log_base: number, only if logpolar is True\n        the log base if this is log polar representation\n\n    Notes\n    -----\n    radiimax is the maximal radius (log of radius if logpolar is true).\n    if not provided, it is deduced from the image size\n\n    To get log-polar, set logpolar to True\n    log_base is the base of the log. It is deduced from radiimax.\n    Two images that will be compared should therefore have the same radiimax.\n    \"\"\"\n    im = np.asarray(im, dtype=np.float32)\n    # get dft if not already done\n    if not isshiftdft:\n        truesize = im.shape\n        # substract mean to avoid having large central value\n        im = im - im.mean()\n        im = centered_mag_sq_ccs(dft_optsize(im))\n    # We need truesize! otherwise border effects.\n    assert(truesize is not None)\n\n    # the center is shifted from 0,0 to the ~ center\n    #(eg. if 4x4 image, the center is at [2,2], as if 5x5)\n    qshape = np.asarray([im.shape[0] // 2, im.shape[1]])\n    center = np.asarray([qshape[0], 0])\n\n    # if the angle Step is not given, take the number of pixel\n    # on the perimeter as the target #=range/step\n\n    if nangle is None:\n        # TODO: understand why nangle need to be exactly truesize\n        nangle = np.min(truesize)  # range is pi, nbangle = 2r =~pi r\n#        nangle-=2\n\n    # get the theta range\n    theta = np.linspace(-np.pi / 2, np.pi / 2, nangle,\n                        endpoint=False, dtype=np.float32)\n\n    # For the radii, the units are comparable if the log_base and radiimax are\n    # the same. Therefore, log_base is deduced from radiimax\n    # The step is assumed to be 1\n    if radiimax is None:\n        radiimax = qshape.min()\n\n    # also as the circle is an ellipse in the image,\n    # we want the radius to be from 0 to 1\n    if logpolar:\n        # The log base solves log_radii_max=log_{log_base}(linear_radii_max)\n        # where we decided arbitrarely that linear_radii_max=log_radii_max\n        log_base = np.exp(np.log(radiimax) / radiimax)\n        radius = ((log_base ** np.arange(0, radiimax, dtype=np.float32))\n                  / radiimax)\n    else:\n        radius = np.linspace(0, 1, radiimax, endpoint=False,\n                             dtype=np.float32)\n\n    # get x y coordinates matrix (The units are 0 to 1, therefore a circle is\n    # represented as an ellipse)\n    y = cv2.gemm(np.sin(theta), radius, qshape[0], 0, 0,\n                 flags=cv2.GEMM_2_T) + center[0]\n    x = cv2.gemm(np.cos(theta), radius, qshape[1], 0, 0,\n                 flags=cv2.GEMM_2_T) + center[1]\n    interp = cv2.INTER_LINEAR\n    if interpolation == 'bicubic':\n        interp = cv2.INTER_CUBIC\n    if interpolation == 'nearest':\n        interp = cv2.INTER_NEAREST\n\n    # get output\n    output = cv2.remap(im, x, y, interp)  # LINEAR, CUBIC,LANCZOS4\n    # apply log\n    if logoutput:\n        output = cv2.log(output)\n\n    if logpolar:\n        return output, log_base\n    else:\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npadding an image with zero or negatively", "response": "def pad_img(im, pad):\n    \"\"\"Pad positively with 0 or negatively (cut)\n\n    Parameters\n    ----------\n    im: 2d array\n        The image\n    pad: 4 numbers\n        (ytop, ybottom, xleft, xright) or (imin, imax, jmin, jmax)\n\n    Returns\n    -------\n    im: 2d array\n        The padded (or cropped) image\n    offset: 2 numbers\n        The offset related to the input image\n\n    Notes\n    -----\n    This changes the size of the image\n    \"\"\"\n    im = np.asarray(im)\n    pad = np.asarray(pad)\n    # get shape\n    shape = im.shape\n    # extract offset from padding\n    offset = -pad[::2]\n    # if the padding is negatif, cut the matrix\n    cut = pad < 0\n    if cut.any():\n        # Extract value for pad\n        cut *= pad\n        # the left/top components should be positive\n        cut[::2] *= -1\n        # The right/bottom components can't be 0, replace by shape0\n        cut[1::2] += (cut[1::2] == 0) * shape\n        # cut the image\n        im = im[cut[0]:cut[1], cut[2]:cut[3]]\n    # extract positive padding\n    ppad = pad > 0\n    if ppad.any():\n        pad = pad * ppad\n        # separate pad for application on matrix\n        ypad = (pad[0], pad[1])\n        xpad = (pad[2], pad[3])\n        # prepare matrix\n        im = np.lib.pad(im, (ypad, xpad), mode='mean')\n    return im, offset"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ccs_normalize(compIM, ccsnorm):\n    compIM = np.asarray(compIM)\n    ccsnorm = np.asarray(ccsnorm)\n    ys = ccsnorm.shape[0]\n    xs = ccsnorm.shape[1]\n    # start with first column\n    ccsnorm[2::2, 0] = ccsnorm[1:ys - 1:2, 0]\n    # continue with middle columns\n    ccsnorm[:, 2::2] = ccsnorm[:, 1:xs - 1:2]\n    # finish whith last row if even\n    if xs % 2 is 0:\n        ccsnorm[2::2, xs - 1] = ccsnorm[1:ys - 1:2, xs - 1]\n    # solve problem with 0/0\n    ccsnorm[ccsnorm == 0] = np.nextafter(0., 1., dtype = ccsnorm.dtype)\n\n    res = compIM / ccsnorm\n    return res", "response": "normalize the CCS image in the CCS representation"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfits the function to a gaussian.", "response": "def gauss_fit(X, Y):\n    \"\"\"\n    Fit the function to a gaussian.\n\n    Parameters\n    ----------\n    X: 1d array\n        X values\n    Y: 1d array\n        Y values\n\n    Returns\n    -------\n    (The return from scipy.optimize.curve_fit)\n    popt : array\n        Optimal values for the parameters\n    pcov : 2d array\n        The estimated covariance of popt.\n\n    Notes\n    -----\n    /!\\ This uses a slow curve_fit function! do not use if need speed!\n    \"\"\"\n    X = np.asarray(X)\n    Y = np.asarray(Y)\n    # Can not have negative values\n    Y[Y < 0] = 0\n    # define gauss function\n\n    def gauss(x, a, x0, sigma):\n        return a * np.exp(-(x - x0)**2 / (2 * sigma**2))\n    # get first estimation for parameter\n    mean = (X * Y).sum() / Y.sum()\n    sigma = np.sqrt((Y * ((X - mean)**2)).sum() / Y.sum())\n    height = Y.max()\n    # fit with curve_fit\n    return curve_fit(gauss, X, Y, p0=[height, mean, sigma])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfit the log of the input to the log of a gaussian.", "response": "def gauss_fit_log(X, Y):\n    \"\"\"\n    Fit the log of the input to the log of a gaussian.\n\n    Parameters\n    ----------\n    X: 1d array\n        X values\n    Y: 1d array\n        Y values\n\n    Returns\n    -------\n    mean: number\n        The mean of the gaussian curve\n    var: number\n        The variance of the gaussian curve\n\n    Notes\n    -----\n    The least square method is used.\n    As this is a log, make sure the amplitude is >> noise\n\n    See the gausslog_sympy.py file for explaination\n    \"\"\"\n    X = np.asarray(X)\n    Y = np.asarray(Y)\n    # take log data\n    Data = np.log(Y)\n    # Get Di and Xi\n    D = [(Data * X**i).sum() for i in range(3)]\n    X = [(X**i).sum() for i in range(5)]\n    # compute numerator and denominator for mean and variance\n    num = (D[0] * (X[1] * X[4] - X[2] * X[3]) +\n           D[1] * (X[2]**2 - X[0] * X[4]) +\n           D[2] * (X[0] * X[3] - X[1] * X[2]))\n    den = 2 * (D[0] * (X[1] * X[3] - X[2]**2) +\n               D[1] * (X[1] * X[2] - X[0] * X[3]) +\n               D[2] * (X[0] * X[2] - X[1]**2))\n    varnum = (-X[0] * X[2] * X[4] + X[0] * X[3]**2 + X[1]**2 * X[4] -\n              2 * X[1] * X[2] * X[3] + X[2]**3)\n    # if denominator is 0, can't do anything\n    if abs(den) < 0.00001:\n        #        print('Warning: zero denominator!',den)\n        return np.nan, np.nan\n    # compute mean and variance\n    mean = num / den\n    var = varnum / den\n    # if variance is negative, the data are not a gaussian\n    if var < 0:\n        #        print('Warning: negative Variance!',var)\n        return np.nan, np.nan\n    return mean, var"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef center_of_mass(X, Y):\n    X = np.asarray(X)\n    Y = np.asarray(Y)\n    return (X * Y).sum() / Y.sum()", "response": "Get center of mass in a set of data."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_peak_pos(im, wrap=False):\n    im = np.asarray(im)\n    # remove invalid values (assuming im>0)\n    im[np.logical_not(np.isfinite(im))] = 0\n    # remove mean\n    im = im - im.mean()\n    # get maximum value\n    argmax = im.argmax()\n    dsize = im.size\n    # get cut value (30% biggest peak)\n    # TODO: choose less random value\n    cut = .3 * im[argmax]\n    # isolate peak\n    peak = im > cut\n    peak, __ = label(peak)\n    # wrap border\n    if wrap and peak[0] != 0 and peak[-1] != 0 and peak[0] != peak[-1]:\n        peak[peak == peak[-1]] = peak[0]\n    # extract peak\n    peak = peak == peak[argmax]\n\n    # get values along X and Y\n    X = np.arange(dsize)[peak]\n    Y = im[peak]\n    # wrap border\n    if wrap:\n        # wrap X values d\n        X[X > dsize // 2] -= dsize\n\n    # remove argmax as in X**4 X should be small\n    offset = X[Y == Y.max()][0]\n    X -= offset\n\n    # We want to fit in a radius of 3 around the center\n    Y = Y[abs(X) < 3]\n    X = X[abs(X) < 3]\n\n    # if>2, use fit_log\n    if peak.sum() > 2:\n        ret, __ = gauss_fit_log(X, Y)\n        # if fails, use center_of_mass\n        if ret is np.nan:\n            ret = center_of_mass(X, Y)\n    elif peak.sum() > 1:\n        # If only 2 pixel, gauss fitting is imposible, use center_of_mass\n        ret = center_of_mass(X, Y)\n    else:\n        # 1 px peak is easy\n        ret = X[0]\n\n    \"\"\"\n    import matplotlib.pyplot as plt\n    plt.figure()\n    plt.plot(X,Y,'x',label='im')\n    plt.plot([ret,ret],[1,Y.max()],label='logfit')\n    plt.plot([X.min(),X.max()],[cut,cut])\n    plt.plot([X.min(),X.max()],[im.std(),im.std()])\n    #\"\"\"\n\n    return ret + offset", "response": "Get the position of the highest peak with subpixel precision."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns centered squared magnitude of the DFT image", "response": "def centered_mag_sq_ccs(im):\n    \"\"\"return centered squared magnitude\n\n    Parameters\n    ----------\n    im: 2d array\n        A CCS DFT image\n    Returns\n    -------\n    im: 2d array\n        A centered image of the magnitude of the DFT\n\n    Notes\n    -----\n    Check doc Intel* Image Processing Library\n    https://www.comp.nus.edu.sg/~cs4243/doc/ipl.pdf\n\n    The center is at position (ys//2, 0)\n    \"\"\"\n    im = np.asarray(im)\n    # multiply image by image* to get squared magnitude\n    im = cv2.mulSpectrums(im, im, flags=0, conjB=True)\n\n    ys = im.shape[0]\n    xs = im.shape[1]\n\n    # get correct size return\n    ret = np.zeros((ys, xs // 2 + 1))\n\n    # first column:\n    # center\n    ret[ys // 2, 0] = im[0, 0]\n    # bottom\n    ret[ys // 2 + 1:, 0] = im[1:ys - 1:2, 0]\n    # top (Inverted copy bottom)\n    ret[ys // 2 - 1::-1, 0] = im[1::2, 0]\n\n    # center columns\n    ret[ys // 2:, 1:] = im[:(ys - 1) // 2 + 1, 1::2]\n    ret[:ys // 2, 1:] = im[(ys - 1) // 2 + 1:, 1::2]\n\n    # correct last line if even\n    if xs % 2 is 0:\n        ret[ys // 2 + 1:, xs // 2] = im[1:ys - 1:2, xs - 1]\n        ret[:ys // 2, xs // 2] = 0\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_overexposed(ims):\n    if len(np.shape(ims)) == 3:\n        return [is_overexposed(im) for im in ims]\n\n    ims = np.array(ims, int)\n    diffbincount = np.diff(np.bincount(np.ravel(ims)))\n    overexposed = diffbincount[-1] > np.std(diffbincount)\n    return overexposed", "response": "Simple test to check if an image is overexposed in the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns True if taps aff for this location", "response": "def is_taps_aff(self):\n        \"\"\"Returns True if taps aff for this location\"\"\"\n\n        request = requests.get('https://www.taps-aff.co.uk/api/%s' % self.location)\n        if request.status_code == 200:\n            try:\n                taps = request.json()['taps']['status']\n                if taps == 'aff':\n                    return True\n                elif taps == 'oan':\n                    return False\n                else:\n                    raise RuntimeError(\"Unexpected taps value: %s\" % taps)\n            except ValueError:\n                raise RuntimeError(\"Unexpected response from service\")\n        else:\n            raise IOError(\"Failure downloading from Api\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrotate a set of daily indices by updating a - current alias to point to a new index for today.", "response": "def rotate(prefixes, hosts, **kwargs):\n    \"\"\"\n    Rotates a set of daily indices by updating a \"-current\" alias to point to\n    a (newly-created) index for today. This should probably be called from a\n    daily cronjob just after midnight.\n    \"\"\"\n\n    rotator = Rotator(pyes.ES(hosts), **kwargs)\n\n    for prefix in prefixes:\n        rotator.rotate(prefix)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef equal(actual, expected):\n    '''\n    Compare actual and expected using ==\n\n    >>> expect = Expector([])\n    >>> expect(1).to_not(equal, 2)\n    (True, 'equal: expect 1 == 2')\n\n    >>> expect(1).to(equal, 1)\n    (True, 'equal: expect 1 == 1')\n    '''\n    is_passing = (actual == expected)\n\n    types_to_diff = (str, dict, list, tuple)\n    if not is_passing and isinstance(expected, types_to_diff) and isinstance(actual, types_to_diff):\n        readable_diff = difflib.unified_diff(pformat(expected).split('\\n'),\n                                             pformat(actual).split('\\n'), n=99)\n        description = '\\n'.join(['equal:'] + list(readable_diff))\n    else:\n        description = \"equal: expect {} == {}\".format(actual, expected)\n    outcome = (is_passing, description)\n    return outcome", "response": "Compare actual and expected using ==\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalling function subject and expect the function to raise an exception.", "response": "def raise_error(subject, error_class):\n    '''\n    Call function `subject` and expect the function to raise an exception.\n    >>> expect = Expector([])\n    >>> expect(lambda: 1 / 0).to(raise_error, ZeroDivisionError)\n    (True, 'Expect ZeroDivisionError to be raised')\n    '''\n    description = 'Expect {} to be raised'.format(error_class.__name__)\n    try:\n        subject()\n        return (False, description)\n    except error_class:\n        return (True, description)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef change(subject, evaluator, by=_NOT_SET, frm=_NOT_SET, to=_NOT_SET):\n    '''\n    Calls function `evaluator` before and after a call function `subject`. Output of `evaluator` should change.\n\n    >>> expect = Expector([])\n    >>> a = [1, 2, 3]\n    >>> expect(a.clear).to(change, lambda: len(a))\n    (True, 'expect change: actual from=3 to=0')\n\n    >>> a = [1, 2, 3]\n    >>> expect(a.clear).to(change, lambda: len(a), by=-3)\n    (True, 'expect change by=-3: actual from=3 to=0')\n\n    >>> a = [1, 2, 3]\n    >>> expect(a.clear).to(change, lambda: len(a), frm=3, to=0)\n    (True, 'expect change from=3 to=0: actual from=3 to=0')\n    '''\n    output_before = evaluator()\n    subject()\n    output_after = evaluator()\n\n    clauses = []\n    is_passing = output_before != output_after\n\n    if by != _NOT_SET:\n        clauses.append(' by={}'.format(repr(by)))\n        delta = output_after - output_before\n        if delta != by: is_passing = False\n\n    if frm != _NOT_SET:\n        clauses.append(' from={}'.format(repr(frm)))\n        if frm != output_before: is_passing = False\n\n    if to != _NOT_SET:\n        clauses.append(' to={}'.format(repr(to)))\n        if to != output_after: is_passing = False\n\n    return (is_passing, 'expect change{}: actual from={} to={}'.format(\n        ''.join(clauses),\n        repr(output_before),\n        repr(output_after)))", "response": "Returns True if evaluator should change subject."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntakes a series of single page pdfs into one multi - page pdf", "response": "def stitch_pdfs(pdf_list):\n  ''' Merges a series of single page pdfs into one multi-page doc '''\n  pdf_merger = PdfFileMerger()\n  for pdf in pdf_list:\n    pdf_merger.append(pdf)\n\n  with NamedTemporaryFile(prefix='pyglass', suffix='.pdf', delete=False) as tempfileobj:\n    dest_path = tempfileobj.name\n\n  pdf_merger.write(dest_path)\n  pdf_merger.close()\n  return dest_path"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef split_pdf(pdf_path):\n  ''' Splits a multi-page pdf into a list of single page pdfs '''\n  pdf = PdfFileReader(pdf_path)\n  pdf_list = []\n\n  for page_num in range(pdf.numPages):\n    page = pdf.getPage(page_num)\n\n    pdf_writer = PdfFileWriter()\n    pdf_writer.addPage(page)\n\n    with NamedTemporaryFile(prefix='pyglass', suffix='.pdf', delete=False) as tempfileobj:\n      pdf_writer.write(tempfileobj)\n      page_path = tempfileobj.name\n\n    pdf_list.append(page_path)\n\n  return pdf_list", "response": "Splits a multi - page pdf into a list of single page pdfs"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_png(pdf_path):\n  ''' Converts a single-page pdf to a png image via the `sips` command\n  :returns: Path to the converted png\n  '''\n  try:\n    with NamedTemporaryFile(prefix='pyglass', suffix='.png', delete=False) as tempfileobj:\n      png_path = tempfileobj.name\n\n    cmd = ['sips', '-s', 'format', 'png', pdf_path, '--out', png_path]\n    assert(check_call(cmd) == 0)\n\n    assert(exists(png_path))\n    return png_path\n  except:\n    return None", "response": "Converts a single - page pdf to a png image via the sips command."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_pngs(pdf_path):\n  ''' Converts a multi-page pdfs to a list of pngs via the `sips` command\n  :returns: A list of converted pngs\n  '''\n  pdf_list = split_pdf(pdf_path)\n  pngs = []\n  for pdf in pdf_list:\n    pngs.append(to_png(pdf))\n    os.remove(pdf)  # Clean up\n  return pngs", "response": "Converts a multi - page pdf to a list of pngs."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef evaluate(self, context):\n        headers = {\"Subject\": self._subject.format(**context)}\n\n        md = self._source.format(**context)\n        html = markdown.markdown(md)\n        parts = {\"text/html\": html, \"text/plain\": md}\n        return headers, parts", "response": "Evaluates the markdown source in the given context producing HTML\n        and ( Markdown plain text"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprocesses the file data.", "response": "def process_data(self, file_info):\n        \"\"\"expects FileInfo\"\"\"\n        if self._exceeds_max_file_size(file_info):\n            self.log.info(\"File '%s' has a size in bytes (%d) greater than the configured limit. Will be ignored.\",\n                          file_info.path, file_info.size)\n            self.fire(events.FilteredFile(file_info))\n            return None\n        else:\n            return file_info"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild response headers and in process renders templates if any.", "response": "def send_head(self):\n        \"\"\"Builds response headers and in process renders templates, if any.\n\n        This method overrides SimpleHTTPRequestHandlet.send_head()\n        \"\"\"\n        path = self.translate_path(self.path)\n        f = None\n        to_render = False\n        if os.path.isdir(path):\n            if not self.path.endswith('/'):\n                # redirect browser - doing basically what apache does\n                self.send_response(301)\n                self.send_header(\"Location\", self.path + \"/\")\n                self.end_headers()\n                return None\n        else:\n            # check if URL corresponds to a template to render\n            if path.endswith(\"/\"):\n                index = path[:-1]\n            else:\n                index = path\n            for ext in '.html', '.htm':\n                if os.path.exists(index + ext):\n                    to_render = True\n                    realpath = index + ext\n                    break\n        if os.path.isdir(path):\n            # if dir, check for existence of index.htm*\n            for index in \"index.html\", \"index.htm\":\n                index = os.path.join(path, index)\n                if os.path.exists(index):\n                    realpath = index\n                    to_render = True\n                    break\n            else:\n                return self.list_directory(path)\n        # deny if URL directly requests for *.html file, allow if dir\n        file_extension = os.path.splitext(path)[1]\n        if file_extension in ('.html', '.htm') and not os.path.isdir(path):\n            self.send_error(404, \"File not found\")\n            return None\n        if to_render:\n            path = realpath\n        ctype = self.guess_type(path)\n        try:\n            f = open(path, 'rb')\n        except IOError:\n            self.send_error(404, \"File not found\")\n            return None\n        fs = os.fstat(f.fileno())\n        if to_render:\n            stream, length = self.gen_response_stream(f)\n        else:\n            length = fs[6]\n        self.send_response(200)\n        self.send_header(\"Content-type\", ctype)\n        self.send_header(\"Content-Length\", str(length))\n        self.send_header(\"Last-Modified\", self.date_time_string(\n            fs.st_mtime))\n        self.end_headers()\n        if to_render:\n            return stream\n        return f"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the percent - decoded version of string s.", "response": "def pct_decode(s):\n    \"\"\"\n    Return the percent-decoded version of string s.\n\n    >>> pct_decode('%43%6F%75%63%6F%75%2C%20%6A%65%20%73%75%69%73%20%63%6F%6E%76%69%76%69%61%6C')\n    'Coucou, je suis convivial'\n    >>> pct_decode('')\n    ''\n    >>> pct_decode('%2525')\n    '%25'\n    \"\"\"\n    if s is None:\n        return None\n    elif not isinstance(s, unicode):\n        s = str(s)\n    else:\n        s = s.encode('utf8')\n\n    return PERCENT_CODE_SUB(lambda mo: chr(int(mo.group(0)[1:], 16)), s)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a translated version of s where each character is mapped to a string thanks to the encdct dictionary.", "response": "def pct_encode(s, encdct):\n    \"\"\"\n    Return a translated version of s where each character is mapped to a\n    string thanks to the encdct dictionary.\n\n    Use the encdct parameter to construct a string from parameter s where\n    each character k from s is replaced by the value corresponding to key k\n    in encdct.  It happens that callers use dictionaries smartly\n    constructed so that this function will perform percent-encoding quickly\n    when called whith such a dictionary.\n    \"\"\"\n    if s is None:\n        return None\n    elif not isinstance(s, unicode):\n        s = str(s)\n    else:\n        s = s.encode('utf8')\n\n    return ''.join(map(encdct.__getitem__, s))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the type of a host according to RFC 3986.", "response": "def host_type(host):\n    \"\"\"\n    Correctly classify correct RFC 3986 compliant hostnames, but do not try\n    hard to validate compliance anyway...\n    NOTE: indeed we allow a small deviation from the RFC 3986: IPv4\n    addresses are allowed to contain bytes represented in hexadecimal or\n    octal notation when begining respectively with '0x'/'0X' and '0'\n    numbers prepended with one or more zero won't be rejected.  Anyway\n    representation of multiple bytes by a single decimal/octal/hexadecimal\n    integer is not allowed.\n\n    Return 1 (HOST_IP_LITERAL), 2 (HOST_IPV4_ADDRESS) or 3 (HOST_REG_NAME)\n\n    >>> host_type('[blablabla]')\n    1\n    >>> host_type('')\n    3\n    >>> host_type('127.0.0.1')\n    2\n    >>> host_type('0x7F.0.0.00000000000001')\n    2\n    >>> host_type('666.42.131.2')\n    3\n    >>> host_type('foobar.42')\n    3\n    \"\"\"\n    if not host:\n        return HOST_REG_NAME\n    elif host[0] == '[':\n        return HOST_IP_LITERAL\n    elif __valid_IPv4address(host):\n        return HOST_IPV4_ADDRESS\n    else:\n        return HOST_REG_NAME"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsplits authority into components.", "response": "def split_authority(authority):\n    \"\"\"\n    Split authority into component parts.  This function supports\n    IP-literal as defined in RFC 3986.\n\n    >>> split_authority(\"user:passwd@host:port\")\n    ('user', 'passwd', 'host', 'port')\n    >>> split_authority(\"user:@host:port\")\n    ('user', None, 'host', 'port')\n    >>> split_authority(\"user@host:port\")\n    ('user', None, 'host', 'port')\n    >>> split_authority(\"user@[host]:port\")\n    Traceback (most recent call last):\n      File \"<stdin>\", line 1, in ?\n      File \"<stdin>\", line 26, in split_authority\n    InvalidIPLiteralError: Highly invalid IP-literal detected in URI authority 'user@[host]:port'\n    >>> split_authority(\"user@[::dead:192.168.42.131]:port\")\n    ('user', None, '[::dead:192.168.42.131]', 'port')\n    >>> split_authority(\"[::dead:192.168.42.131]:port\")\n    (None, None, '[::dead:192.168.42.131]', 'port')\n    >>> split_authority(\":port\")\n    (None, None, None, 'port')\n    >>> split_authority(\"user@:port\")\n    ('user', None, None, 'port')\n\n    Very basic validation is done if the host part of the authority starts\n    with an '[' as when this is the case, the splitting is done in a quite\n    different manner than the one used by most URI parsers.  As a result an\n    InvalidIPLiteralError exception is raised if IP-literal is patently\n    wrong, so the risk of major clashes between two deviant implementations\n    is highly reduced.\n    \"\"\"\n    if '@' in authority:\n        userinfo, hostport = authority.split('@', 1)\n        if userinfo and ':' in userinfo:\n            user, passwd = userinfo.split(':', 1)\n        else:\n            user, passwd = userinfo, None\n    else:\n        user, passwd, hostport = None, None, authority\n    if hostport:\n        if hostport[0] == '[':\n            m = re.match(r\"\\[([\\da-fA-F:\\.]+|\" + IPV_FUTURE_RE\n                                 + r\")\\](\\:.*|)$\", hostport)\n            if m:\n                host = '[' + m.group(1) + ']'\n                port = m.group(2)[1:]\n            else:\n                raise InvalidIPLiteralError, \"Highly invalid IP-literal detected in URI authority %r\" % (authority,)\n        elif ':' in hostport:\n            host, port = hostport.split(':', 1)\n        else:\n            host, port = hostport, None\n    else:\n        host, port = None, None\n    return (user or None, passwd or None, host or None, port or None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef split_query(query):\n    def split_assignment(a):\n        sa = a.split('=', 1)\n        return len(sa) == 2 and tuple(sa) or (sa[0], None)\n    assignments = query.split('&')\n    return tuple([split_assignment(a) for a in assignments if a])", "response": "Split a query into a tuple of tuples."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a query string using the tuple query returned by split_query", "response": "def unsplit_query(query):\n    \"\"\"\n    Create a query string using the tuple query with a format as the one\n    returned by split_query()\n    \"\"\"\n    def unsplit_assignment((x, y)):\n        if (x is not None) and (y is not None):\n            return x + '=' + y\n        elif x is not None:\n            return x\n        elif y is not None:\n            return '=' + y\n        else:\n            return ''\n    return '&'.join(map(unsplit_assignment, query))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef uri_split_tree(uri):\n    scheme, authority, path, query, fragment = basic_urisplit(uri)\n    if authority:\n        authority = split_authority(authority)\n    if query:\n        query = split_query(query)\n    return (scheme and scheme or None, authority and authority or None,\n            path and path or None, query and query or None,\n            fragment and fragment or None)", "response": "Split a URI into a tree of URIs."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef uri_tree_normalize(uri_tree):\n    scheme, authority, path, query, fragment = uri_tree\n    if authority and (filter(bool, authority) == ()):\n        authority = None\n    if query:\n        query = filter(lambda (x, y): bool(x) or bool(y), query)\n    return (scheme or None, authority or None, path or None,\n            query or None, fragment or None)", "response": "Normalizes a URI tree so that adjacent all - empty fields are coalesced into a single None at parent level."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef uri_tree_validate(uri_tree):\n    scheme, authority, path, query, fragment = uri_tree\n    if scheme:\n        if not valid_scheme(scheme):\n            raise InvalidSchemeError, \"Invalid scheme %r\" % (scheme,)\n    if authority:\n        user, passwd, host, port = authority\n        if user and not __all_in(user, USER_CHAR):\n            raise InvalidUserError, \"Invalid user %r\" % (user,)\n        if passwd and not __all_in(passwd, PASSWD_CHAR):\n            raise InvalidPasswdError, \"Invalid passwd %r\" % (passwd,)\n        if host:\n            type_host = host_type(host)\n            if type_host == HOST_REG_NAME:\n                if not __all_in(host, REG_NAME_CHAR):\n                    raise InvalidRegNameError, \"Invalid reg-name %r\" % (host,)\n            elif type_host == HOST_IP_LITERAL:\n                if not __valid_IPLiteral(host):\n                    raise InvalidIPLiteralError, \"Invalid IP-literal %r\" % (host,)\n        if port and not __all_in(port, DIGIT):\n            raise InvalidPortError, \"Invalid port %r\" % (port,)\n    if path:\n        if not __all_in(path, PCHAR):\n            raise InvalidPathError, \"Invalid path %r - invalid character detected\" % (path,)\n        if authority and path[0] != '/':\n            raise InvalidPathError, \"Invalid path %r - non-absolute path can't be used with an authority\" % (path,)\n        if (not authority) and (not scheme) and (':' in path.split('/', 1)[0]):\n            raise InvalidPathError, \"Invalid path %r - path-noscheme can't have a ':' if no '/' before\" % (path,)\n    if query and (not __valid_query(query)):\n        raise InvalidQueryError, \"Invalid splitted query tuple %r\" % (query,)\n    if fragment and (not __all_in(fragment, QUEFRAG_CHAR)):\n        raise InvalidFragmentError, \"Invalid fragment %r\" % (fragment,)\n    return uri_tree", "response": "Validate a URI tree."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef uri_tree_decode(uri_tree):\n    scheme, authority, path, query, fragment = uri_tree\n    if authority:\n        user, passwd, host, port = authority\n        user, passwd = pct_decode(user), pct_decode(passwd)\n        if host and host_type(host) == HOST_REG_NAME:\n            host = pct_decode(host)\n        authority = (user, passwd, host, port)\n    path, fragment = pct_decode(path), pct_decode(fragment)\n    if query:\n        query = tuple([(query_elt_decode(x), query_elt_decode(y)) for (x, y) in query])\n    return (scheme, authority, path, query, fragment)", "response": "Decode a URI tree in format returned by uri_split_tree"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef uri_tree_precode_check(uri_tree, type_host = HOST_REG_NAME):\n    scheme, authority, path, query, fragment = uri_tree # pylint: disable-msg=W0612\n    if scheme:\n        if not valid_scheme(scheme):\n            raise InvalidSchemeError, \"Invalid scheme %r\" % (scheme,)\n    if authority:\n        user, passwd, host, port = authority # pylint: disable-msg=W0612\n        if port and not __all_in(port, DIGIT):\n            raise InvalidPortError, \"Invalid port %r\" % (port,)\n        if type_host == HOST_IP_LITERAL:\n            if host and (not __valid_IPLiteral(host)):\n                raise InvalidIPLiteralError, \"Invalid IP-literal %r\" % (host,)\n        elif type_host == HOST_IPV4_ADDRESS:\n            if host and (not __valid_IPv4address(host)):\n                raise InvalidIPv4addressError, \"Invalid IPv4address %r\" % (host,)\n    if path:\n        if authority and path[0] != '/':\n            raise InvalidPathError, \"Invalid path %r - non-absolute path can't be used with an authority\" % (path,)\n    return uri_tree", "response": "Validate a raw URI tree before trying to encode it."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef uri_unsplit_tree(uri_tree):\n    scheme, authority, path, query, fragment = uri_tree\n    if authority:\n        user, passwd, host, port = authority\n        if user and passwd:\n            userinfo = user + ':' + passwd\n        elif user:\n            userinfo = user\n        elif passwd:\n            userinfo = ':' + passwd\n        else:\n            userinfo = None\n        if host and port:\n            hostport = host + ':' + port\n        elif host:\n            hostport = host\n        elif port:\n            hostport = ':' + port\n        else:\n            hostport = None\n        if userinfo and hostport:\n            authority = userinfo + '@' + hostport\n        elif userinfo:\n            authority = userinfo + '@'\n        elif hostport:\n            authority = hostport\n        else:\n            authority = None\n    if query:\n        query = unsplit_query(query)\n    uri = ''\n    if scheme:\n        uri += scheme + ':'\n    if authority:\n        uri += '//' + authority\n    if path:\n        if (not authority) and path[0:2] == '//':\n            uri += '//'\n        uri += path\n    if query:\n        uri += '?' + query\n    if fragment:\n        uri += '#' + fragment\n    return uri", "response": "Unsplit a coded URI tree."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_configuration(ctx, base_key, needed_keys):\n\n    # check for valid configuration\n    if base_key not in ctx.keys():\n        exit(\"[{}ERROR{}] missing configuration for '{}'\"\n             .format(ERROR_COLOR, RESET_COLOR, base_key))\n        # TODO: offer to create configuration file\n    if ctx.releaser is None:\n        exit(\"[{}ERROR{}] empty configuration for '{}' found\"\n             .format(ERROR_COLOR, RESET_COLOR, base_key))\n        # TODO: offer to create configuration file\n\n    # TODO: allow use of default values\n    for my_key in needed_keys:\n        if my_key not in ctx[base_key].keys():\n            exit(\"[{}ERROR{}] missing configuration key '{}.{}'\"\n                 .format(ERROR_COLOR, RESET_COLOR, base_key, my_key))", "response": "Check that the base key is in the context and that all needed_keys are in the context."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_existence(to_check, name, config_key=None, relative_to=None,\n                    allow_undefined=False, allow_not_existing=False,\n                    base_key='releaser'):\n    \"\"\"Determine whether a file or folder actually exists.\"\"\"\n    if allow_undefined and (to_check is None or to_check.lower() == 'none'):\n        print(\"{: <14} -> {}UNDEFINED{}\".format(name, WARNING_COLOR,\n                                                RESET_COLOR))\n        return\n    else:\n        if config_key is None:\n            config_key = \"{}.{}\".format(base_key, name)\n        my_check = Path(to_check).resolve()\n        if my_check.exists() and relative_to is not None:\n            printed_path = str(my_check.relative_to(relative_to))\n            if printed_path != '.':\n                printed_path = '.' + os.sep + printed_path\n        else:\n            printed_path = str(my_check)\n        if my_check.exists() or allow_not_existing:\n            print(\"{: <14} -> {}\".format(name, printed_path))\n            return\n        else:\n            raise FileNotFoundError(\"[{}ERROR{}] '{}', as given, doesn't \"\n                                    \"exist. For configuration key '{}', was \"\n                                    \"given: {}\".format(ERROR_COLOR, RESET_COLOR,\n                                                       name, config_key,\n                                                       to_check))", "response": "Check whether a file or folder actually exists."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _determine_dimensions(num_of_pixels):\n    for x in xrange(int(math.sqrt(num_of_pixels)) + 1, 1, -1):\n        if num_of_pixels % x == 0:\n            return num_of_pixels // x, x\n    return 1, num_of_pixels", "response": "Given a number of pixels determines the largest width and height that define a\n      rectangle with such an area."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting the file in file_path to a numpy array representing an RGB image", "response": "def _to_image_array(file_path):\n    \"\"\"\n    Converts the file in file_path to a numpy array (matrix) representing an RGB image\n    The dimensions of the image are calculated using __determine_dimensions.\n    Padding is added provide enough bytes to generate the image (between 1 and 3 bytes can be added).\n    \"\"\"\n    _log.debug(\"File '%s' to image\", file_path)\n    data = numpy.fromfile(file_path, numpy.uint8)\n    orig_len = len(data)\n    pad_req = (3 - (orig_len % 3))\n    pad_req += 3 if pad_req == 0 else 0\n    final_len = orig_len + pad_req\n    num_of_pixels = final_len // 3\n    w, h = _determine_dimensions(num_of_pixels)\n    reshaped = numpy.zeros((w, h, 3), dtype=numpy.uint8)\n    for i in xrange(final_len):\n        sidx = i // 3\n        y = sidx % h\n        x = sidx // h\n        s = i % 3\n        reshaped[x, y, s] = data[i] if i < orig_len else 0\n    reshaped[-1, -1, 2] = pad_req\n\n    return reshaped"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_image_to_file(img_path, file_path):\n    img = Image.open(img_path)\n    data = numpy.array(img)\n    data = numpy.reshape(data, len(img.getdata()) * 3)\n    to_remove = data[len(data) - 1]\n    data = numpy.delete(data, xrange(len(data) - to_remove, len(data)))\n    data.tofile(file_path)", "response": "Takes an image file and writes it to a file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef do_heavy_work(self, block):\n        src_file_path = block.latest_file_info.path\n        img_path = src_file_path + self.get_extension()\n        self.log.debug(\"Converting file '%s' to image '%s'\", src_file_path, img_path)\n        from_file_to_image(src_file_path, img_path)\n        block.image_converted_file_info = FileInfo(img_path)\n        block.latest_file_info = block.image_converted_file_info\n        return block", "response": "This method is used to do heavy work on the blocks."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _child(details):\n\n\t# If the details are a list\n\tif isinstance(details, list):\n\n\t\t# Create a list of options for the key\n\t\treturn OptionsNode(details)\n\n\t# Else if we got a dictionary\n\telif isinstance(details, dict):\n\n\t\t# If array is present\n\t\tif '__array__' in details:\n\t\t\treturn ArrayNode(details)\n\n\t\t# Else if we have a hash\n\t\telif '__hash__' in details:\n\t\t\treturn HashNode(details)\n\n\t\t# Else if we have a type\n\t\telif '__type__' in details:\n\n\t\t\t# If the type is a dictionary or list, this is a complex type\n\t\t\tif isinstance(details['__type__'], (dict,list)):\n\t\t\t\treturn _child(details['__type__'])\n\n\t\t\t# Else it's just a Node\n\t\t\telse:\n\t\t\t\treturn Node(details)\n\n\t\t# Else it's most likely a parent\n\t\telse:\n\t\t\treturn Parent(details)\n\n\t# Else if we got a string\n\telif isinstance(details, basestring):\n\n\t\t# Use the value as the type\n\t\treturn Node(details)\n\n\t# Else raise an error\n\telse:\n\t\traise TypeError('details')", "response": "Private function to figure out the child node type"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fromFile(cls, filename):\n\n\t\t# Load the file\n\t\toFile = open(filename)\n\n\t\t# Convert it to a dictionary\n\t\tdDetails = JSON.decodef(oFile)\n\n\t\t# Create and return the new instance\n\t\treturn cls(dDetails)", "response": "From File\n\tLoads a JSON file and creates a Node instance from it"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef optional(self, value = None):\n\n\t\t# If there's no value, this is a getter\n\t\tif value is None:\n\t\t\treturn this._optional\n\n\t\t# Else, set the flag\n\t\telse:\n\t\t\tthis._optional = value and True or False", "response": "Set the optional flag."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clean(self, value):\n\n\t\t# If the value is None and it's optional, return as is\n\t\tif value is None and self._optional:\n\t\t\treturn None\n\n\t\t# If the value is not a list\n\t\tif not isinstance(value, list):\n\t\t\traise ValueError('value')\n\n\t\t# Recurse and return it\n\t\treturn [self._node.clean(m) for m in value]", "response": "Clean the value of a list and stores it"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef minmax(self, minimum=None, maximum=None):\n\n\t\t# If neither minimum or maximum is set, this is a getter\n\t\tif(minimum is None and maximum is None):\n\t\t\treturn {\"minimum\": self._minimum, \"maximum\": self._maximum}\n\n\t\t# If the minimum is set\n\t\tif minimum is not None:\n\n\t\t\t# If the value is not a valid int or long\n\t\t\tif not isinstance(minimum, (int, long)):\n\n\t\t\t\t# If it's a valid representation of an integer\n\t\t\t\tif isinstance(minimum, basestring) \\\n\t\t\t\t\tand _typeToRegex['int'].match(minimum):\n\n\t\t\t\t\t# Convert it\n\t\t\t\t\tminimum = int(minimum, 0)\n\n\t\t\t\t# Else, raise an error\n\t\t\t\telse:\n\t\t\t\t\traise ValueError('minimum')\n\n\t\t\t# If it's below zero\n\t\t\tif minimum < 0:\n\t\t\t\traise ValueError('minimum')\n\n\t\t\t# Store the minimum\n\t\t\tself._minimum = minimum\n\n\t\t# If the maximum is set\n\t\tif maximum is not None:\n\n\t\t\t# If the value is not a valid int or long\n\t\t\tif not isinstance(maximum, (int, long)):\n\n\t\t\t\t# If it's a valid representation of an integer\n\t\t\t\tif isinstance(maximum, basestring) \\\n\t\t\t\t\tand _typeToRegex['int'].match(maximum):\n\n\t\t\t\t\t# Convert it\n\t\t\t\t\tmaximum = int(maximum, 0)\n\n\t\t\t\t# Else, raise an error\n\t\t\t\telse:\n\t\t\t\t\traise ValueError('minimum')\n\n\t\t\t# It's below zero\n\t\t\tif maximum < 0:\n\t\t\t\traise ValueError('maximum')\n\n\t\t\t# If we also have a minimum and the max is somehow below it\n\t\t\tif self._minimum \\\n\t\t\t\tand maximum < self._minimum:\n\t\t\t\traise ValueError('maximum')\n\n\t\t\t# Store the maximum\n\t\t\tself._maximum = maximum", "response": "Min and Max of Items Returns the minimum and maximum number of items for the Array."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef clean(self, value):\n\n\t\t# If the value is None and it's optional, return as is\n\t\tif value is None and self._optional:\n\t\t\treturn None\n\n\t\t# If the value is not a dict\n\t\tif not isinstance(value, dict):\n\t\t\traise ValueError('value')\n\n\t\t# Recurse and return it\n\t\treturn {str(self._key.clean(k)):self._node.clean(v) for k,v in iteritems(value)}", "response": "Clean the value of a key - value pair."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef valid(self, value, level=[]):\n\n\t\t# Reset validation failures\n\t\tself.validation_failures = []\n\n\t\t# If the value is None and it's optional, we're good\n\t\tif value is None and self._optional:\n\t\t\treturn True\n\n\t\t# If the value isn't a dictionary\n\t\tif not isinstance(value, dict):\n\t\t\tself.validation_failures.append(('.'.join(level), str(value)))\n\t\t\treturn False\n\n\t\t# Init the return, assume valid\n\t\tbRet = True\n\n\t\t# Go through each key and value\n\t\tfor k,v in iteritems(value):\n\n\t\t\t# Add the field to the level\n\t\t\tlLevel = level[:]\n\t\t\tlLevel.append(k)\n\n\t\t\t# If the key isn't valid\n\t\t\tif not self._key.valid(k):\n\t\t\t\tself.validation_failures.append(('.'.join(lLevel), 'invalid key: %s' % str(k)))\n\t\t\t\tbRet = False\n\t\t\t\tcontinue\n\n\t\t\t# Check the value\n\t\t\tif not self._node.valid(v, lLevel):\n\t\t\t\tself.validation_failures.extend(self._node.validation_failures)\n\t\t\t\tbRet = False\n\t\t\t\tcontinue\n\n\t\t# Return whatever the result was\n\t\treturn bRet", "response": "Valid\n\tChecks if a value is valid based on the instance s values and the instance s values."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompare IPs and returns a status based on which is less than or equal to second.", "response": "def __compare_ips(first, second):\n\t\t\"\"\"Compare IPs\n\n\t\tCompares two IPs and returns a status based on which is greater\n\t\tIf first is less than second: -1\n\t\tIf first is equal to second: 0\n\t\tIf first is greater than second: 1\n\n\t\tArguments:\n\t\t\tfirst {str} -- A string representing an IP address\n\t\t\tsecond {str} -- A string representing an IP address\n\n\t\tReturns:\n\t\t\tint\n\t\t\"\"\"\n\n\t\t# If the two IPs are the same, return 0\n\t\tif first == second:\n\t\t\treturn 0\n\n\t\t# Create lists from the split of each IP, store them as ints\n\t\tlFirst = [int(i) for i in first.split('.')]\n\t\tlSecond = [int(i) for i in second.split('.')]\n\n\t\t# Go through each part from left to right until we find the\n\t\t# \tdifference\n\t\tfor i in [0, 1, 2, 3]:\n\n\t\t\t# If the part of x is greater than the part of y\n\t\t\tif lFirst[i] > lSecond[i]:\n\t\t\t\treturn 1\n\n\t\t\t# Else if the part of x is less than the part of y\n\t\t\telif lFirst[i] < lSecond[i]:\n\t\t\t\treturn -1"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clean(self, value):\n\n\t\t# If the value is None and it's optional, return as is\n\t\tif value is None and self._optional:\n\t\t\treturn None\n\n\t\t# If it's an ANY, there is no reasonable expectation that we know what\n\t\t#\tthe value should be, so we return it as is\n\t\tif self._type == 'any':\n\t\t\tpass\n\n\t\t# Else if it's a basic string type\n\t\telif self._type in ['base64', 'ip', 'string', 'uuid']:\n\n\t\t\t# And not already a string\n\t\t\tif not isinstance(value, basestring):\n\t\t\t\tvalue = str(value)\n\n\t\t# Else if it's a BOOL just check if the value flags as positive\n\t\telif self._type == 'bool':\n\n\t\t\t# If it's specifically a string, it needs to match a specific\n\t\t\t#\tpattern to be true\n\t\t\tif isinstance(value, basestring):\n\t\t\t\tvalue = (value in ('true', 'True', 'TRUE', 't', 'T', 'yes', 'Yes', 'YES', 'y', 'Y', 'x', '1') and True or False);\n\n\t\t\t# Else\n\t\t\telse:\n\t\t\t\tvalue = (value and True or False)\n\n\t\t# Else if it's a date type\n\t\telif self._type == 'date':\n\n\t\t\t# If it's a python type, use strftime on it\n\t\t\tif isinstance(value, (datetime.date, datetime.datetime)):\n\t\t\t\tvalue = value.strftime('%Y-%m-%d')\n\n\t\t\t# Else if it's already a string\n\t\t\telif isinstance(value, basestring):\n\t\t\t\tpass\n\n\t\t\t# Else convert it to a string\n\t\t\telse:\n\t\t\t\tvalue = str(value)\n\n\t\t# Else if it's a datetime type\n\t\telif self._type == 'datetime':\n\n\t\t\t# If it's a python type, use strftime on it\n\t\t\tif isinstance(value, datetime.datetime):\n\t\t\t\tvalue = value.strftime('%Y-%m-%d %H:%M:%S')\n\t\t\telif isinstance(value, datetime.date):\n\t\t\t\tvalue = '%s 00:00:00' % value.strftime('%Y-%m-%d')\n\n\t\t\t# Else if it's already a string\n\t\t\telif isinstance(value, basestring):\n\t\t\t\tpass\n\n\t\t\t# Else convert it to a string\n\t\t\telse:\n\t\t\t\tvalue = str(value)\n\n\t\t# Else if it's a decimal\n\t\telif self._type == 'decimal':\n\n\t\t\t# If it's not a decimal\n\t\t\tif not isinstance(value, Decimal):\n\t\t\t\tvalue = Decimal(value)\n\n\t\t\t# Convert it to a string\n\t\t\tvalue = '{0:f}'.format(value)\n\n\t\t# Else if it's a float\n\t\telif self._type == 'float':\n\t\t\tvalue = float(value)\n\n\t\t# Else if it's an int type\n\t\telif self._type in ['int', 'timestamp', 'uint']:\n\n\t\t\t# If the value is a string\n\t\t\tif isinstance(value, basestring):\n\n\t\t\t\t# If it starts with 0\n\t\t\t\tif value[0] == '0' and len(value) > 1:\n\n\t\t\t\t\t# If it's followed by X or x, it's hex\n\t\t\t\t\tif value[1] in ['x', 'X'] and len(value) > 2:\n\t\t\t\t\t\tvalue = int(value, 16)\n\n\t\t\t\t\t# Else it's octal\n\t\t\t\t\telse:\n\t\t\t\t\t\tvalue = int(value, 8)\n\n\t\t\t\t# Else it's base 10\n\t\t\t\telse:\n\t\t\t\t\tvalue = int(value)\n\n\t\t\t# Else if it's not an int already\n\t\t\telif not isinstance(value, int):\n\t\t\t\tvalue = int(value)\n\n\t\t# Else if it's a JSON type\n\t\telif self._type == 'json':\n\n\t\t\t# If it's already a string\n\t\t\tif isinstance(value, basestring):\n\t\t\t\tpass\n\n\t\t\t# Else, encode it\n\t\t\telse:\n\t\t\t\tvalue = JSON.encode(value)\n\n\t\t# Else if it's an md5 type\n\t\telif self._type == 'md5':\n\n\t\t\t# If it's a python type, get the hexadecimal digest\n\t\t\tif isinstance(value, _MD5_TYPE):\n\t\t\t\tvalue = value.hexdigest()\n\n\t\t\t# Else if it's a string\n\t\t\telif isinstance(value, basestring):\n\t\t\t\tpass\n\n\t\t\t# Else, try to convert it to a string\n\t\t\telse:\n\t\t\t\tvalue = str(value)\n\n\t\t# Else if it's a price type\n\t\telif self._type == 'price':\n\n\t\t\t# If it's not already a Decimal\n\t\t\tif not isinstance(value, Decimal):\n\t\t\t\tvalue = Decimal(value)\n\n\t\t\t# Make sure its got 2 decimal places\n\t\t\tvalue = \"{0:f}\".format(value.quantize(Decimal('1.00')))\n\n\t\t# Else if it's a time type\n\t\telif self._type == 'time':\n\n\t\t\t# If it's a python type, use strftime on it\n\t\t\tif isinstance(value, (datetime.time, datetime.datetime)):\n\t\t\t\tvalue = value.strftime('%H:%M:%S')\n\n\t\t\t# Else if it's already a string\n\t\t\telif isinstance(value, basestring):\n\t\t\t\tpass\n\n\t\t\t# Else convert it to a string\n\t\t\telse:\n\t\t\t\tvalue = str(value)\n\n\t\t# Else we probably forgot to add a new type\n\t\telse:\n\t\t\traise Exception('%s has not been added to .clean()' % self._type)\n\n\t\t# Return the cleaned value\n\t\treturn value", "response": "Clean the value of the key based on the type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef minmax(self, minimum=None, maximum=None):\n\n\t\t# If neither min or max is set, this is a getter\n\t\tif minimum is None and maximum is None:\n\t\t\treturn {\"minimum\": self._minimum, \"maximum\": self._maximum};\n\n\t\t# If the minimum is set\n\t\tif minimum != None:\n\n\t\t\t# If the current type is a date, datetime, ip, or time\n\t\t\tif self._type in ['base64', 'date', 'datetime', 'ip', 'time']:\n\n\t\t\t\t# Make sure the value is valid for the type\n\t\t\t\tif not isinstance(minimum, basestring) \\\n\t\t\t\t\tor not _typeToRegex[self._type].match(minimum):\n\t\t\t\t\traise ValueError('__minimum__')\n\n\t\t\t# Else if the type is an int (unsigned, timestamp), or a string in\n\t\t\t# \twhich the min/max are lengths\n\t\t\telif self._type in ['int', 'string', 'timestamp', 'uint']:\n\n\t\t\t\t# If the value is not a valid int or long\n\t\t\t\tif not isinstance(minimum, (int, long)):\n\n\t\t\t\t\t# If it's a valid representation of an integer\n\t\t\t\t\tif isinstance(minimum, basestring) \\\n\t\t\t\t\t\tand _typeToRegex['int'].match(minimum):\n\n\t\t\t\t\t\t# Convert it\n\t\t\t\t\t\tminimum = int(minimum, 0)\n\n\t\t\t\t\t# Else, raise an error\n\t\t\t\t\telse:\n\t\t\t\t\t\traise ValueError('__minimum__')\n\n\t\t\t\t\t# If the type is meant to be unsigned\n\t\t\t\t\tif self._type in ['base64', 'string', 'timestamp', 'uint']:\n\n\t\t\t\t\t\t# And it's below zero\n\t\t\t\t\t\tif minimum < 0:\n\t\t\t\t\t\t\traise ValueError('__minimum__')\n\n\t\t\t# Else if the type is decimal\n\t\t\telif self._type == 'decimal':\n\n\t\t\t\t# Store it if it's valid, else throw a ValueError\n\t\t\t\ttry:\n\t\t\t\t\tminimum = Decimal(minimum)\n\t\t\t\texcept ValueError:\n\t\t\t\t\traise ValueError('__minimum__')\n\n\t\t\t# Else if the type is float\n\t\t\telif self._type == 'float':\n\n\t\t\t\t# Store it if it's valid, else throw a ValueError\n\t\t\t\ttry:\n\t\t\t\t\tminimum = float(minimum)\n\t\t\t\texcept ValueError:\n\t\t\t\t\traise ValueError('__minimum__')\n\n\t\t\t# Else if the type is price\n\t\t\telif self._type == 'price':\n\n\t\t\t\t# If it's not a valid representation of a price\n\t\t\t\tif not isinstance(minimum, basestring) or not _typeToRegex['price'].match(minimum):\n\t\t\t\t\traise ValueError('__minimum__')\n\n\t\t\t\t# Store it as a Decimal\n\t\t\t\tminimum = Decimal(minimum)\n\n\t\t\t# Else we can't have a minimum\n\t\t\telse:\n\t\t\t\traise TypeError('can not set __minimum__ for ' + self._type)\n\n\t\t\t# Store the minimum\n\t\t\tself._minimum = minimum\n\n\t\t# If the maximum is set\n\t\tif maximum != None:\n\n\t\t\t# If the current type is a date, datetime, ip, or time\n\t\t\tif self._type in ['date', 'datetime', 'ip', 'time']:\n\n\t\t\t\t# Make sure the value is valid for the type\n\t\t\t\tif not isinstance(maximum, basestring) \\\n\t\t\t\t\tor not _typeToRegex[self._type].match(maximum):\n\t\t\t\t\traise ValueError('__maximum__')\n\n\t\t\t# Else if the type is an int (unsigned, timestamp), or a string in\n\t\t\t# \twhich the min/max are lengths\n\t\t\telif self._type in ['int', 'string', 'timestamp', 'uint']:\n\n\t\t\t\t# If the value is not a valid int or long\n\t\t\t\tif not isinstance(maximum, (int, long)):\n\n\t\t\t\t\t# If it's a valid representation of an integer\n\t\t\t\t\tif isinstance(maximum, basestring) \\\n\t\t\t\t\t\tand _typeToRegex['int'].match(maximum):\n\n\t\t\t\t\t\t# Convert it\n\t\t\t\t\t\tmaximum = int(maximum, 0)\n\n\t\t\t\t\t# Else, raise an error\n\t\t\t\t\telse:\n\t\t\t\t\t\traise ValueError('__minimum__')\n\n\t\t\t\t\t# If the type is meant to be unsigned\n\t\t\t\t\tif self._type in ['string', 'timestamp', 'uint']:\n\n\t\t\t\t\t\t# And it's below zero\n\t\t\t\t\t\tif maximum < 0:\n\t\t\t\t\t\t\traise ValueError('__maximum__')\n\n\t\t\t# Else if the type is decimal\n\t\t\telif self._type == 'decimal':\n\n\t\t\t\t# Store it if it's valid, else throw a ValueError\n\t\t\t\ttry:\n\t\t\t\t\tmaximum = Decimal(maximum)\n\t\t\t\texcept ValueError:\n\t\t\t\t\traise ValueError('__maximum__')\n\n\t\t\t# Else if the type is float\n\t\t\telif self._type == 'float':\n\n\t\t\t\t# Store it if it's valid, else throw a ValueError\n\t\t\t\ttry:\n\t\t\t\t\tminimum = float(minimum)\n\t\t\t\texcept ValueError:\n\t\t\t\t\traise ValueError('__maximum__')\n\n\t\t\t# Else if the type is price\n\t\t\telif self._type == 'price':\n\n\t\t\t\t# If it's not a valid representation of a price\n\t\t\t\tif not isinstance(maximum, basestring) or not _typeToRegex['price'].match(maximum):\n\t\t\t\t\traise ValueError('__maximum__')\n\n\t\t\t\t# Store it as a Decimal\n\t\t\t\tmaximum = Decimal(maximum)\n\n\t\t\t# Else we can't have a maximum\n\t\t\telse:\n\t\t\t\traise TypeError('can not set __maximum__ for ' + self._type)\n\n\t\t\t# If we also have a minimum\n\t\t\tif self._minimum is not None:\n\n\t\t\t\t# If the type is an IP\n\t\t\t\tif self._type == 'ip':\n\n\t\t\t\t\t# If the min is above the max, we have a problem\n\t\t\t\t\tif self.__compare_ips(self._minimum, maximum) == 1:\n\t\t\t\t\t\traise ValueError('__maximum__')\n\n\t\t\t\t# Else any other data type\n\t\t\t\telse:\n\n\t\t\t\t\t# If the min is above the max, we have a problem\n\t\t\t\t\tif self._minimum > maximum:\n\t\t\t\t\t\traise ValueError('__maximum__')\n\n\t\t\t# Store the maximum\n\t\t\tself._maximum = maximum", "response": "Returns the minimum and maximum values for the Node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the list of acceptable options for this Node.", "response": "def options(self, options=None):\n\t\t\"\"\"Options\n\n\t\tSets or gets the list of acceptable values for the Node\n\n\t\tArguments:\n\t\t\toptions {list} -- A list of valid values\n\n\t\tRaises:\n\t\t\tTypeError, ValueError\n\n\t\tReturns:\n\t\t\tNone | list\n\t\t\"\"\"\n\n\t\t# If opts aren't set, this is a getter\n\t\tif options is None:\n\t\t\treturn self._options\n\n\t\t# If the options are not a list\n\t\tif not isinstance(options, (list, tuple)):\n\t\t\traise ValueError('__options__')\n\n\t\t# If the type is not one that can have options\n\t\tif self._type not in ['base64', 'date', 'datetime', 'decimal', 'float', \\\n\t\t\t\t\t\t\t\t'int', 'ip', 'md5', 'price', 'string', 'time', \\\n\t\t\t\t\t\t\t\t'timestamp', 'uint', 'uuid']:\n\t\t\traise TypeError('can not set __options__ for ' + self._type)\n\n\t\t# Init the list of options to be saved\n\t\tlOpts = []\n\n\t\t# Go through each item and make sure it's unique and valid\n\t\tfor i in range(len(options)):\n\n\t\t\t# Convert the value based on the type\n\t\t\t# If the type is a string one that we can validate\n\t\t\tif self._type in ['base64', 'date', 'datetime', 'ip', 'md5', 'time', 'uuid']:\n\n\t\t\t\t# If the value is not a string or doesn't match its regex, raise\n\t\t\t\t# \tan error\n\t\t\t\tif not isinstance(options[i], basestring) \\\n\t\t\t\t\tor not _typeToRegex[self._type].match(options[i]):\n\t\t\t\t\traise ValueError('__options__[%d]' % i)\n\n\t\t\t# Else if it's decimal\n\t\t\telif self._type == 'decimal':\n\n\t\t\t\t# If it's a Decimal\n\t\t\t\tif isinstance(options[i], Decimal):\n\t\t\t\t\tpass\n\n\t\t\t\t# Else if we can't conver it\n\t\t\t\telse:\n\t\t\t\t\ttry: options[i] = Decimal(options[i])\n\t\t\t\t\texcept ValueError:\n\t\t\t\t\t\traise ValueError('__options__[%d]' % i)\n\n\t\t\t# Else if it's a float\n\t\t\telif self._type == 'float':\n\n\t\t\t\ttry:\n\t\t\t\t\toptions[i] = float(options[i])\n\t\t\t\texcept ValueError:\n\t\t\t\t\traise ValueError('__options__[%d]' % i)\n\n\t\t\t# Else if it's an integer\n\t\t\telif self._type in ['int', 'timestamp', 'uint']:\n\n\t\t\t\t# If we don't already have an int\n\t\t\t\tif not isinstance(options[i], (int, long)):\n\n\t\t\t\t\t# And we don't have a string\n\t\t\t\t\tif not isinstance(options[i], basestring):\n\t\t\t\t\t\traise ValueError('__options__[%d]' % i)\n\n\t\t\t\t\ttry:\n\t\t\t\t\t\toptions[i] = int(options[i], 0)\n\t\t\t\t\texcept ValueError:\n\t\t\t\t\t\traise ValueError('__options__[%d]' % i)\n\n\t\t\t\t# If the type is unsigned and negative, raise an error\n\t\t\t\tif self._type in ['timestamp', 'uint'] and options[i] < 0:\n\t\t\t\t\traise ValueError('__options__[' + str(i) + ']')\n\n\t\t\t# Else if it's a price\n\t\t\telif self._type == 'price':\n\n\t\t\t\t# If it's a Decimal\n\t\t\t\tif isinstance(options[i], Decimal):\n\t\t\t\t\tpass\n\n\t\t\t\t# Else if it's not a valid price representation\n\t\t\t\telif not isinstance(options[i], basestring) or not _typeToRegex['price'].match(options[i]):\n\t\t\t\t\traise ValueError('__options__[%d]' % i)\n\n\t\t\t\t# Store it as a Decimal\n\t\t\t\toptions[i] = Decimal(options[i])\n\n\t\t\t# Else if the type is a string\n\t\t\telif self._type == 'string':\n\n\t\t\t\t# If the value is not a string\n\t\t\t\tif not isinstance(options[i], basestring):\n\n\t\t\t\t\t# If the value can't be turned into a string\n\t\t\t\t\ttry:\n\t\t\t\t\t\toptions[i] = str(options[i])\n\t\t\t\t\texcept ValueError:\n\t\t\t\t\t\traise ValueError('__options__[%d]' % i)\n\n\t\t\t# Else we have no validation for the type\n\t\t\telse:\n\t\t\t\traise TypeError('can not set __options__ for ' + self._type)\n\n\t\t\t# If it's already in the list, raise an error\n\t\t\tif options[i] in lOpts:\n\t\t\t\tsys.stderr.write('__options__[' + str(i) + '] is a duplicate')\n\n\t\t\t# Store the option\n\t\t\telse:\n\t\t\t\tlOpts.append(options[i])\n\n\t\t# Store the list of options\n\t\tself._options = lOpts"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets or gets the regular expression used to validate the Node s data", "response": "def regex(self, regex = None):\n\t\t\"\"\"Regex\n\n\t\tSets or gets the regular expression used to validate the Node\n\n\t\tArguments:\n\t\t\tregex {str} -- A standard regular expression string\n\n\t\tRaises:\n\t\t\tValueError\n\n\t\tReturns:\n\t\t\tNone | str\n\t\t\"\"\"\n\n\t\t# If regex was not set, this is a getter\n\t\tif regex is None:\n\t\t\treturn self._regex\n\n\t\t# If the type is not a string\n\t\tif self._type != 'string':\n\t\t\tsys.stderr.write('can not set __regex__ for %s' % self._type)\n\t\t\treturn\n\n\t\t# If it's not a valid string or regex\n\t\tif not isinstance(regex, (basestring, _REGEX_TYPE)):\n\t\t\traise ValueError('__regex__')\n\n\t\t# Store the regex\n\t\tself._regex = regex"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef valid(self, value, level=[]):\n\n\t\t# Reset validation failures\n\t\tself.validation_failures = []\n\n\t\t# If the value is None and it's optional, we're good\n\t\tif value is None and self._optional:\n\t\t\treturn True\n\n\t\t# If we are validating an ANY field, immediately return true\n\t\tif self._type == 'any':\n\t\t\tpass\n\n\t\t# If we are validating a DATE, DATETIME, IP or TIME data point\n\t\telif self._type in ['base64', 'date', 'datetime', 'ip', 'md5', 'time', 'uuid']:\n\n\t\t\t# If it's a date or datetime type and the value is a python type\n\t\t\tif self._type == 'date' and isinstance(value, (datetime.date, datetime.datetime)):\n\t\t\t\tvalue = value.strftime('%Y-%m-%d')\n\n\t\t\telif self._type == 'datetime' and isinstance(value, (datetime.date, datetime.datetime)):\n\t\t\t\tif isinstance(value, datetime.datetime):\n\t\t\t\t\tvalue = value.strftime('%Y-%m-%d %H:%M:%S')\n\t\t\t\telif isinstance(value, datetime.date):\n\t\t\t\t\tvalue = '%s 00:00:00' % value.strftime('%Y-%m-%d')\n\n\t\t\t# If it's a time type and the value is a python type\n\t\t\telif self._type == 'time' and isinstance(value, (datetime.time, datetime.datetime)):\n\t\t\t\tvalue = value.strftime('%H:%M:%S')\n\n\t\t\t# Else if the type is md5 and the value is a python type\n\t\t\telif self._type == 'md5' and isinstance(value, _MD5_TYPE):\n\t\t\t\tvalue = value.hexdigest()\n\n\t\t\t# If the value is not a string\n\t\t\telif not isinstance(value, basestring):\n\t\t\t\tself.validation_failures.append(('.'.join(level), 'not a string'))\n\t\t\t\treturn False\n\n\t\t\t# If there's no match\n\t\t\tif not _typeToRegex[self._type].match(value):\n\t\t\t\tself.validation_failures.append(('.'.join(level), 'failed regex (internal)'))\n\t\t\t\treturn False\n\n\t\t\t# If we are checking an IP\n\t\t\tif self._type == 'ip':\n\n\t\t\t\t# If there's a min or a max\n\t\t\t\tif self._minimum is not None or self._maximum is not None:\n\n\t\t\t\t\t# If the IP is greater than the maximum\n\t\t\t\t\tif self._maximum is not None and self.__compare_ips(value, self._maximum) == 1:\n\t\t\t\t\t\tself.validation_failures.append(('.'.join(level), 'exceeds maximum'))\n\t\t\t\t\t\treturn False\n\n\t\t\t\t\t# If the IP is less than the minimum\n\t\t\t\t\tif self._minimum is not None and self.__compare_ips(value, self._minimum) == -1:\n\t\t\t\t\t\tself.validation_failures.append(('.'.join(level), 'did not meet minimum'))\n\t\t\t\t\t\treturn False\n\n\t\t\t\t\t# Return OK\n\t\t\t\t\treturn True\n\n\t\t# Else if we are validating some sort of integer\n\t\telif self._type in ['int', 'timestamp', 'uint']:\n\n\t\t\t# If the type is a bool, fail immediately\n\t\t\tif type(value) == bool:\n\t\t\t\tself.validation_failures.append(('.'.join(level), 'is a bool'))\n\t\t\t\treturn False\n\n\t\t\t# If it's not an int\n\t\t\tif not isinstance(value, (int, long)):\n\n\t\t\t\t# And it's a valid representation of an int\n\t\t\t\tif isinstance(value, basestring) \\\n\t\t\t\t\tand _typeToRegex['int'].match(value):\n\n\t\t\t\t\t# If it starts with 0\n\t\t\t\t\tif value[0] == '0' and len(value) > 1:\n\n\t\t\t\t\t\t# If it's followed by X or x, it's hex\n\t\t\t\t\t\tif value[1] in ['x', 'X'] and len(value) > 2:\n\t\t\t\t\t\t\tvalue = int(value, 16)\n\n\t\t\t\t\t\t# Else it's octal\n\t\t\t\t\t\telse:\n\t\t\t\t\t\t\tvalue = int(value, 8)\n\n\t\t\t\t\t# Else it's base 10\n\t\t\t\t\telse:\n\t\t\t\t\t\tvalue = int(value)\n\n\t\t\t\t# Else, return false\n\t\t\t\telse:\n\t\t\t\t\tself.validation_failures.append(('.'.join(level), 'not an integer'))\n\t\t\t\t\treturn False\n\n\t\t\t# If it's not signed\n\t\t\tif self._type in ['timestamp', 'uint']:\n\n\t\t\t\t# If the value is below 0\n\t\t\t\tif value < 0:\n\t\t\t\t\tself.validation_failures.append(('.'.join(level), 'signed'))\n\t\t\t\t\treturn False\n\n\t\t# Else if we are validating a bool\n\t\telif self._type == 'bool':\n\n\t\t\t# If it's already a bool\n\t\t\tif isinstance(value, bool):\n\t\t\t\treturn True\n\n\t\t\t# If it's an int or long at 0 or 1\n\t\t\tif isinstance(value, (int, long)) and value in [0, 1]:\n\t\t\t\treturn True\n\n\t\t\t# Else if it's a string\n\t\t\telif isinstance(value, basestring):\n\n\t\t\t\t# If it's t, T, 1, f, F, or 0\n\t\t\t\tif value in ['true', 'True', 'TRUE', 't', 'T', '1', 'false', 'False', 'FALSE', 'f', 'F', '0']:\n\t\t\t\t\treturn True\n\t\t\t\telse:\n\t\t\t\t\tself.validation_failures.append(('.'.join(level), 'not a valid string representation of a bool'))\n\t\t\t\t\treturn False\n\n\t\t\t# Else it's no valid type\n\t\t\telse:\n\t\t\t\tself.validation_failures.append(('.'.join(level), 'not valid bool replacement'))\n\t\t\t\treturn False\n\n\t\t# Else if we are validating a decimal value\n\t\telif self._type == 'decimal':\n\n\t\t\t# If the type is a bool, fail immediately\n\t\t\tif type(value) == bool:\n\t\t\t\tself.validation_failures.append(('.'.join(level), 'is a bool'))\n\t\t\t\treturn False\n\n\t\t\t# If it's already a Decimal\n\t\t\tif isinstance(value, Decimal):\n\t\t\t\tpass\n\n\t\t\t# Else if we fail to convert the value\n\t\t\telse:\n\t\t\t\ttry: value = Decimal(value)\n\t\t\t\texcept (DecimalInvalid, TypeError, ValueError):\n\t\t\t\t\tself.validation_failures.append(('.'.join(level), 'can not be converted to decimal'))\n\t\t\t\t\treturn False\n\n\t\t# Else if we are validating a floating point value\n\t\telif self._type == 'float':\n\n\t\t\t# If the type is a bool, fail immediately\n\t\t\tif type(value) == bool:\n\t\t\t\tself.validation_failures.append(('.'.join(level), 'is a bool'))\n\t\t\t\treturn False\n\n\t\t\t# If it's already a float\n\t\t\tif isinstance(value, float):\n\t\t\t\tpass\n\n\t\t\t# Else if we fail to convert the value\n\t\t\telse:\n\t\t\t\ttry: value = float(value)\n\t\t\t\texcept (ValueError, TypeError):\n\t\t\t\t\tself.validation_failures.append(('.'.join(level), 'can not be converted to float'))\n\t\t\t\t\treturn False\n\n\t\t# Else if we are validating a JSON string\n\t\telif self._type == 'json':\n\n\t\t\t# If it's already a string\n\t\t\tif isinstance(value, basestring):\n\n\t\t\t\t# Try to decode it\n\t\t\t\ttry:\n\t\t\t\t\tvalue = JSON.decode(value)\n\t\t\t\t\treturn True\n\t\t\t\texcept ValueError:\n\t\t\t\t\tself.validation_failures.append(('.'.join(level), 'Can not be decoded from JSON'))\n\t\t\t\t\treturn False\n\n\t\t\t# Else\n\t\t\telse:\n\n\t\t\t\t# Try to encode it\n\t\t\t\ttry:\n\t\t\t\t\tvalue = JSON.encode(value)\n\t\t\t\t\treturn True\n\t\t\t\texcept (ValueError, TypeError):\n\t\t\t\t\tself.validation_failures.append(('.'.join(level), 'Can not be encoded to JSON'))\n\t\t\t\t\treturn False\n\n\t\t# Else if we are validating a price value\n\t\telif self._type == 'price':\n\n\t\t\t# If the type is a bool, fail immediately\n\t\t\tif type(value) == bool:\n\t\t\t\tself.validation_failures.append(('.'.join(level), 'is a bool'))\n\t\t\t\treturn False\n\n\t\t\t# If it's not a floating point value\n\t\t\tif not isinstance(value, Decimal):\n\n\t\t\t\t# But it is a valid string representing a price, or a float\n\t\t\t\tif isinstance(value, (basestring, float)) \\\n\t\t\t\t\tand _typeToRegex['price'].match(str(value)):\n\n\t\t\t\t\t# Convert it to a decimal\n\t\t\t\t\tvalue = Decimal(value).quantize(Decimal('1.00'))\n\n\t\t\t\t# Else if it's an int\n\t\t\t\telif isinstance(value, int):\n\n\t\t\t\t\t# Convert it to decimal\n\t\t\t\t\tvalue = Decimal(str(value) + '.00')\n\n\t\t\t\t# Else whatever it is is no good\n\t\t\t\telse:\n\t\t\t\t\tself.validation_failures.append(('.'.join(level), 'failed regex (internal)'))\n\t\t\t\t\treturn False\n\n\t\t\t# Else\n\t\t\telse:\n\n\t\t\t\t# If the exponent is longer than 2\n\t\t\t\tif abs(value.as_tuple().exponent) > 2:\n\t\t\t\t\tself.validation_failures.append(('.'.join(level), 'too many decimal points'))\n\t\t\t\t\treturn False\n\n\t\t# Else if we are validating a string value\n\t\telif self._type == 'string':\n\n\t\t\t# If the value is not some form of string\n\t\t\tif not isinstance(value, basestring):\n\t\t\t\tself.validation_failures.append(('.'.join(level), 'is not a string'))\n\t\t\t\treturn False\n\n\t\t\t# If we have a regex\n\t\t\tif self._regex:\n\n\t\t\t\t# If it doesn't match the regex\n\t\t\t\tif re.match(self._regex, value) == None:\n\t\t\t\t\tself.validation_failures.append(('.'.join(level), 'failed regex (custom)'))\n\t\t\t\t\treturn False\n\n\t\t\t# Else\n\t\t\telif self._minimum or self._maximum:\n\n\t\t\t\t# If there's a minimum length and we don't reach it\n\t\t\t\tif self._minimum and len(value) < self._minimum:\n\t\t\t\t\tself.validation_failures.append(('.'.join(level), 'not long enough'))\n\t\t\t\t\treturn False\n\n\t\t\t\t# If there's a maximum length and we surpass it\n\t\t\t\tif self._maximum and len(value) > self._maximum:\n\t\t\t\t\tself.validation_failures.append(('.'.join(level), 'too long'))\n\t\t\t\t\treturn False\n\n\t\t\t\t# Return OK\n\t\t\t\treturn True\n\n\t\t# If there's a list of options\n\t\tif self._options is not None:\n\n\t\t\t# Returns based on the option's existance\n\t\t\tif value not in self._options:\n\t\t\t\tself.validation_failures.append(('.'.join(level), 'not in options'))\n\t\t\t\treturn False\n\t\t\telse:\n\t\t\t\treturn True\n\n\t\t# Else check for basic min/max\n\t\telse:\n\n\t\t\t# If the value is less than the minimum\n\t\t\tif self._minimum and value < self._minimum:\n\t\t\t\tself.validation_failures.append(('.'.join(level), 'did not meet minimum'))\n\t\t\t\treturn False\n\n\t\t\t# If the value is greater than the maximum\n\t\t\tif self._maximum and value > self._maximum:\n\t\t\t\tself.validation_failures.append(('.'.join(level), 'exceeds maximum'))\n\t\t\t\treturn False\n\n\t\t# Value has no issues\n\t\treturn True", "response": "Validate a value based on the instance s values."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clean(self, value):\n\n\t\t# If the value is None and it's optional, return as is\n\t\tif value is None and self._optional:\n\t\t\treturn None\n\n\t\t# Go through each of the nodes\n\t\tfor i in range(len(self._nodes)):\n\n\t\t\t# If it's valid\n\t\t\tif self._nodes[i].valid(value):\n\n\t\t\t\t# Use it's clean\n\t\t\t\treturn self._nodes[i].clean(value)\n\n\t\t# Something went wrong\n\t\traise ValueError('value', value)", "response": "Clean the value of a node"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef valid(self, value, level=[]):\n\n\t\t# Reset validation failures\n\t\tself.validation_failures = []\n\n\t\t# If the value is None and it's optional, we're good\n\t\tif value is None and self._optional:\n\t\t\treturn True\n\n\t\t# Go through each of the nodes\n\t\tfor i in range(len(self._nodes)):\n\n\t\t\t# If it's valid\n\t\t\tif self._nodes[i].valid(value):\n\n\t\t\t\t# Return OK\n\t\t\t\treturn True\n\n\t\t# Not valid for anything\n\t\tself.validation_failures.append(('.'.join(level), 'no valid option'))\n\t\treturn False", "response": "Valid\n\tChecks if a value is valid based on the instance s values\n\n\tArguments - The value to validate\n\tArguments - The value to validate\n\tArguments - The value to validate\n\tArguments - The level of the validation failures to be used"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncleaning the value of a node in the dict and stores it", "response": "def clean(self, value):\n\t\t\"\"\"Clean\n\n\t\tGoes through each of the values in the dict, cleans it, stores it, and\n\t\treturns a new dict\n\n\t\tArguments:\n\t\t\tvalue {dict} -- The value to clean\n\n\t\tReturns:\n\t\t\tdict\n\t\t\"\"\"\n\n\t\t# If the value is None and it's optional, return as is\n\t\tif value is None and self._optional:\n\t\t\treturn None\n\n\t\t# If the value is not a dict\n\t\tif not isinstance(value, dict):\n\t\t\traise ValueError('value')\n\n\t\t# Init the return value\n\t\tdRet = {}\n\n\t\t# Go through each value and clean it using the associated node\n\t\tfor k in value.keys():\n\t\t\ttry:\n\t\t\t\tdRet[k] = self._nodes[k].clean(value[k])\n\t\t\texcept KeyError:\n\t\t\t\traise ValueError('%s is not a valid node in the parent' % k)\n\n\t\t# Return the cleaned values\n\t\treturn dRet"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a specific key from the parent node", "response": "def get(self, key, default=None):\n\t\t\"\"\"Get\n\n\t\tReturns the node of a specific key from the parent\n\n\t\tArguments:\n\t\t\tkey {str} -- The key to get\n\t\t\tdefault {mixed} Value to return if the key does not exist\n\n\t\tReturns:\n\t\t\tmixed\n\t\t\"\"\"\n\t\tif key in self._nodes: return self._nodes[key]\n\t\telse: return default"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nkey returns a list of the node names in the parent node", "response": "def keys(self):\n\t\t\"\"\"Keys\n\n\t\tReturns a list of the node names in the parent\n\n\t\tReturns:\n\t\t\tlist\n\t\t\"\"\"\n\t\tif hasattr(self._nodes, 'iterkeys'):\n\t\t\treturn self._nodes.keys()\n\t\telse:\n\t\t\treturn tuple(self._nodes.keys())"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef requires(self, require=None):\n\n\t\t# If require is None, this is a getter\n\t\tif require is None:\n\t\t\treturn self._requires\n\n\t\t# If it's not a valid dict\n\t\tif not isinstance(require, dict):\n\t\t\traise ValueError('__require__')\n\n\t\t# Go through each key and make sure it goes with a field\n\t\tfor k,v in iteritems(require):\n\n\t\t\t# If the field doesn't exist\n\t\t\tif k not in self._nodes:\n\t\t\t\traise ValueError('__require__[%s]' % str(k))\n\n\t\t\t# If the value is a string\n\t\t\tif isinstance(v, basestring):\n\t\t\t\tv = [v]\n\n\t\t\t# Else if it's not a list type\n\t\t\telif not isinstance(v, (tuple,list)):\n\t\t\t\traise ValueError('__require__[%s]' % str(k))\n\n\t\t\t# Make sure each required field also exists\n\t\t\tfor s in v:\n\t\t\t\tif s not in self._nodes:\n\t\t\t\t\traise ValueError('__require__[%s]: %s' % (str(k), str(v)))\n\n\t\t\t# If it's all good\n\t\t\tself._requires[k] = v", "response": "Sets the required rules used to validate the Parent\n\t"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef valid(self, value, include_name=True):\n\n\t\t# Call the parent valid method and return the result\n\t\treturn super(Tree, self).valid(value, include_name and [self._name] or [])", "response": "Valid\n\tChecks if a value is valid based on the instance s values and if include_name is True the Tree s name will be prepended to the Tree s name if include_name is True."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nclean and parses text from the given HTML.", "response": "def textFromHTML(html):\n    \"\"\"\n    Cleans and parses text from the given HTML.\n    \"\"\"\n    cleaner = lxml.html.clean.Cleaner(scripts=True)\n    cleaned = cleaner.clean_html(html)\n    return lxml.html.fromstring(cleaned).text_content()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef evaluate(self, context):\n        html = self._source.format(**context)\n        parts = {\"text/html\": html, \"text/plain\": textFromHTML(html)}\n        return {}, parts", "response": "Interpolates the HTML source with the context then returns that HTML\n        and the text extracted from that html."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncleans and sync all the bookkeeping tables", "response": "def clean_all(self):\n        \"\"\"\n        *clean and sync all the bookkeeping tables*\n\n        **Return:**\n            - ``bookkeeper``\n\n        **Usage:**\n\n            .. code-block:: python \n\n                from rockAtlas.bookkeeping import bookkeeper\n                bk = bookkeeper(\n                    log=log,\n                    settings=settings,\n                    fullUpdate=False\n                )\n                bk.clean_all()\n        \"\"\"\n        self.log.info('starting the ``get`` method')\n\n        if self.fullUpdate:\n            recent = False\n        else:\n            recent = True\n\n        self.import_new_atlas_pointings(recent)\n        self._run_bookkeeping_sql_scripts()\n\n        self.log.info('completed the ``get`` method')\n        return bookkeeper"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nimports any new ATLAS pointings from the atlas3 database into the atlas_exposures table of the atlas_exposures database.", "response": "def import_new_atlas_pointings(\n            self,\n            recent=False):\n        \"\"\"\n        *Import any new ATLAS pointings from the atlas3/atlas4 databases into the ``atlas_exposures`` table of the Atlas Movers database*\n\n        **Key Arguments:**\n            - ``recent`` -- only sync the most recent 2 weeks of data (speeds things up)\n\n        **Return:**\n            - None\n\n         **Usage:**\n\n            .. code-block:: python\n\n                from rockAtlas.bookkeeping import bookkeeper\n                bk = bookkeeper(\n                    log=log,\n                    settings=settings\n                )\n                bk.import_new_atlas_pointings()\n        \"\"\"\n        self.log.info('starting the ``import_new_atlas_pointings`` method')\n\n        if recent:\n            mjd = mjdnow(\n                log=self.log\n            ).get_mjd()\n            recent = mjd - 14\n            recent = \" mjd_obs > %(recent)s \" % locals()\n        else:\n            recent = \"1=1\"\n\n        # SELECT ALL OF THE POINTING INFO REQUIRED FROM THE ATLAS3 DATABASE\n        sqlQuery = u\"\"\"\n            SELECT\n                `expname`,\n                `dec` as `decDeg`,\n                `exptime` as `exp_time`,\n                `filter`,\n                `mjd_obs` as `mjd`,\n                `ra` as `raDeg`,\n                if(mjd_obs<57855.0,mag5sig-0.75,mag5sig) as `limiting_magnitude`,\n                `object` as `atlas_object_id` from atlas_metadata where %(recent)s and object like \"TA%%\" order by mjd_obs desc;\n        \"\"\" % locals()\n        rows = readquery(\n            log=self.log,\n            sqlQuery=sqlQuery,\n            dbConn=self.atlas3DbConn,\n            quiet=False\n        )\n\n        dbSettings = self.settings[\"database settings\"][\"atlasMovers\"]\n\n        # TIDY RESULTS BEFORE IMPORT\n        entries = list(rows)\n\n        if len(rows) > 0:\n            # ADD THE NEW RESULTS TO THE atlas_exposures TABLE\n            insert_list_of_dictionaries_into_database_tables(\n                dbConn=self.atlasMoversDBConn,\n                log=self.log,\n                dictList=entries,\n                dbTableName=\"atlas_exposures\",\n                uniqueKeyList=[\"expname\"],\n                dateModified=False,\n                batchSize=10000,\n                replace=True,\n                dbSettings=dbSettings\n            )\n\n        recent = recent.replace(\"mjd_obs\", \"mjd\")\n\n        # SELECT ALL OF THE POINTING INFO REQUIRED FROM THE ATLAS4 DATABASE\n        sqlQuery = u\"\"\"\n            SELECT\n                `obs` as `expname`,\n                `dec` as `decDeg`,\n                `texp` as `exp_time`,\n                `filt` as `filter`,\n                `mjd`,\n                `ra` as `raDeg`,\n                `mag5sig` as `limiting_magnitude`,\n                `obj` as `atlas_object_id` from atlas_metadataddc where %(recent)s and obj like \"TA%%\" order by mjd desc;\n        \"\"\" % locals()\n        rows = readquery(\n            log=self.log,\n            sqlQuery=sqlQuery,\n            dbConn=self.atlas4DbConn,\n            quiet=False\n        )\n\n        # TIDY RESULTS BEFORE IMPORT\n        entries = list(rows)\n\n        if len(rows) > 0:\n            # ADD THE NEW RESULTS TO THE atlas_exposures TABLE\n            insert_list_of_dictionaries_into_database_tables(\n                dbConn=self.atlasMoversDBConn,\n                log=self.log,\n                dictList=entries,\n                dbTableName=\"atlas_exposures\",\n                uniqueKeyList=[\"expname\"],\n                dateModified=False,\n                batchSize=10000,\n                replace=True,\n                dbSettings=dbSettings\n            )\n\n        # APPEND HTMIDs TO THE atlas_exposures TABLE\n        add_htm_ids_to_mysql_database_table(\n            raColName=\"raDeg\",\n            declColName=\"decDeg\",\n            tableName=\"atlas_exposures\",\n            dbConn=self.atlasMoversDBConn,\n            log=self.log,\n            primaryIdColumnName=\"primaryId\"\n        )\n\n        print \"ATLAS pointings synced between ATLAS3/ATLAS4 databases and the ATLAS Movers `atlas_exposures` database table\"\n\n        self.log.info('completed the ``import_new_atlas_pointings`` method')\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning bookkeeping sql scripts", "response": "def _run_bookkeeping_sql_scripts(\n            self):\n        \"\"\"*run bookkeeping sql scripts*\n        \"\"\"\n        self.log.info('starting the ``_run_bookkeeping_sql_scripts`` method')\n\n        moduleDirectory = os.path.dirname(__file__)\n        mysqlScripts = moduleDirectory + \"/mysql\"\n\n        directory_script_runner(\n            log=self.log,\n            pathToScriptDirectory=mysqlScripts,\n            databaseName=self.settings[\n                \"database settings\"][\"atlasMovers\"][\"db\"],\n            force=True,\n            loginPath=self.settings[\"database settings\"][\n                \"atlasMovers\"][\"loginPath\"],\n            waitForResult=True,\n            successRule=False,\n            failureRule=False\n        )\n\n        self.log.info('completed the ``_run_bookkeeping_sql_scripts`` method')\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_files(*bases):\n        for base in bases:\n            basedir, _ = base.split(\".\", 1)\n            base = os.path.join(os.path.dirname(__file__), *base.split(\".\"))\n\n            rem = len(os.path.dirname(base)) + len(basedir) + 2\n\n            for root, dirs, files in os.walk(base):\n                for name in files:\n                    yield os.path.join(basedir, root, name)[rem:]", "response": "Yields all files in a data directory."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the approximate distance between two locations.", "response": "def equirectangular_distance(self, other):\n        \"\"\"\n        Return the approximate equirectangular when the location is close to\n        the center of the cluster.\n\n        For small distances, Pythagoras\u2019 theorem can be used on an\n        equirectangular projection.\n\n        Equirectangular formula::\n\n            x = \u0394\u03bb \u22c5 cos \u03c6m\n            y = \u0394\u03c6\n            d = R \u22c5 \u221a(x\u00b2 + y)\u00b2\n\n        It will always over-estimate compared to the real Haversine distance.\n        For example it will add no more than 0.05382 % to the real distance if\n        the delta latitude or longitude between your two points does not\n        exceed 4 decimal degrees.\n\n        The standard formula (Haversine) is the exact one (that is, it works\n        for any couple of longitude/latitude on earth) but is much slower as\n        it needs 7 trigonometric and 2 square roots.  If your couple of points\n        are not too far apart, and absolute precision is not paramount, you\n        can use this approximate version (Equirectangular), which is much\n        faster as it uses only one trigonometric and one square root::\n\n            Python 2.7.6rc1 (v2.7.6rc1:4913d0e9be30+, Oct 27 2013, 20:52:11)\n            [GCC 4.2.1 (Apple Inc. build 5666) (dot 3)] on darwin\n            Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n            >>> from majormode.perseus.model.geolocation import GeoPoint\n            >>> import time\n            >>>\n            >>> source = GeoPoint(106.739036, 10.797977)\n            >>> destination = GeoPoint(106.743325, 10.800195)\n            >>>\n            >>> start_time = time.time()\n            >>> for i in xrange(1000000):\n            ...     d = source.great_circle_distance(destination)\n            ...\n            >>> print time.time() - start_time\n            5.62202811241\n            >>> print d\n            529.424701041\n            >>>\n            >>> start_time = time.time()\n            >>> for i in xrange(1000000):\n            ...     d = source.equirectangular_distance(destination)\n            ...\n            >>> print time.time() - start_time\n            2.78262710571\n            >>> print d\n            529.424701073\n            >>>\n\n        @param other: a ``GeoPoint`` instance.\n\n        @return: the great-circle distance, in meters, between this geographic\n            coordinates to the specified other point.\n        \"\"\"\n        x = math.radians(other.longitude - self.longitude) \\\n                * math.cos(math.radians(other.latitude + self.latitude) / 2);\n        y = math.radians(other.latitude - self.latitude);\n        return math.sqrt(x * x + y * y) * GeoPoint.EARTH_RADIUS_METERS;"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef great_circle_distance(self, other):\n        distance_latitude = math.radians(abs(self.latitude - other.latitude))\n        distance_longitude = math.radians(abs(self.longitude - other.longitude))\n        a = math.sin(distance_latitude / 2) * math.sin(distance_latitude / 2) \\\n            + math.cos(math.radians(self.latitude)) \\\n              * math.cos(math.radians(other.latitude)) \\\n              * math.sin(distance_longitude / 2) \\\n              * math.sin(distance_longitude / 2)\n        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n        return GeoPoint.EARTH_RADIUS_METERS * c", "response": "Return the great - circle distance between this geographic entry point and the specified other point."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbuilds a GeoPoint instance from the specified JSON object.", "response": "def from_json(payload):\n        \"\"\"\n        Build a ``GeoPoint`` instance from the specified JSON object.\n\n        @param payload: JSON representation of a geographic location::\n\n                {\n                  \"accuracy\": decimal,\n                  \"altitude\": decimal,\n                  \"bearing\": decimal,\n                  \"longitude\": decimal,\n                  \"latitude\": decimal,\n                  \"provider\": string,\n                  \"speed\": decimal\n                }\n\n            where:\n\n            * ``accuracy``: accuracy of the position in meters.\n\n            * ``altitude``: altitude in meters of the location.\n\n            * ``bearing``: bearing in degrees.  Bearing is the horizontal\n              direction of travel of the device, and is not related to the\n              device orientation.  It is guaranteed to be in the range\n              ``[0.0, 360.0]``, or ``null`` if this device does not have a\n              bearing.\n\n            * ``latitude``: latitude-angular distance, expressed in decimal\n              degrees (WGS84 datum), measured from the center of the Earth,\n              of a point north or south of the Equator.\n\n            * ``longitude``: longitude-angular distance, expressed in\n              decimal degrees (WGS84 datum), measured from the center of the\n              Earth, of a point east or west of the Prime Meridian.\n\n            * ``provider``: code name of the location provider that reported\n              the geographical location:\n\n              * ``gps``: indicate that the location has been provided by a\n                Global Positioning System (GPS).\n\n              * ``network``: indicate that the location has been provided by\n                an hybrid positioning system, which uses different\n                positioning technologies, such as Global Positioning System\n                (GPS), Wi-Fi hotspots, cell tower signals.\n\n            * ``speed``: speed in meters/second over the ground, or ``null``\n              if this location does not have a speed.\n\n        @return: a ``GeoPoint`` instance or ``None`` if the JSON payload is\n            nil.\n        \"\"\"\n        return payload and \\\n            GeoPoint(payload['longitude'],\n                     payload['latitude'],\n                     accuracy=payload.get('accuracy'),\n                     altitude=payload.get('altitude'),\n                     bearing=payload.get('bearing'),\n                     fix_time=payload.get('fix_time'),\n                     provider=payload.get('provider'),\n                     speed=payload.get('speed'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convert_dd_to_dms_string(dd):\n        degrees = int(dd)\n        minutes = (dd - degrees) * 60\n        seconds = int((minutes - int(minutes)) * 60)\n        return unicode(degrees) + u'\u00b0' + unicode(int(minutes)) + u\"'\" + unicode(int(seconds)) + u'\"'", "response": "Convert decimal degrees which expresses latitude and longitude and decimal fraction to a degrees minutes and seconds string representation such as 38\u00b0 53 23 N."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert the degree minute and second formatted GPS data to decimal degree.", "response": "def convert_dms_to_dd(\n            degree_num, degree_den,\n            minute_num, minute_den,\n            second_num, second_den):\n        \"\"\"\n        Convert the degree/minute/Second formatted GPS data to decimal\n        degrees.\n\n        @param degree_num: the numerator of the degree object.\n\n        @param degree_den: the denominator of the degree object.\n\n        @param minute_num: the numerator of the minute object.\n\n        @param minute_den: the denominator of the minute object.\n\n        @param second_num: the numerator of the second object.\n\n        @param second_den: the denominator of the second object.\n\n        @return: a decimal degree.\n        \"\"\"\n        degree = float(degree_num) / float(degree_den)\n        minute = float(minute_num) / float(minute_den)/ 60\n        second = float(second_num) / float(second_den)/ 3600\n        return degree + minute + second"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef convert_dms_string_to_dd(dms):\n        degree_mark_offset = dms.find(u'\u00b0')\n        degrees = float(dms[:degree_mark_offset].strip())\n        minute_mark_offset = dms.find(u\"'\")\n        minutes = float(dms[degree_mark_offset + 1:minute_mark_offset].strip())\n        second_mark_offset = dms.find(u'\"')\n        seconds = float(dms[minute_mark_offset + 1:second_mark_offset].strip())\n        return degrees + (minutes / 60) + (seconds / 3600)", "response": "Convert a string representation of a location on the Earth to a decimal degrees ( DD which expresses\n        latitude and longitude geographic coordinates as decimal fraction."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef public_dict(d):\n\n    if isinstance(d, dict):\n        safe_dict = dict((key, public_dict(value)) for key, value in d.items() if not key.startswith('_'))\n        if '_cls' in d:\n            safe_dict['type'] = d['_cls']\n        return safe_dict\n    if isinstance(d, list):\n        return [public_dict(l) for l in d]\n\n    return d", "response": "Convert a dict into a list of public_dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nacquiring a connection to a Relational Data Base Management System.", "response": "def acquire_connection(settings, tag=None, logger_name=None, auto_commit=False):\n        \"\"\"\n        Return a connection to a Relational DataBase Management System (RDBMS)\n        the most appropriate for the service requesting this connection.\n\n        @param settings: a dictionary of connection properties::\n                   {\n                     None: {\n                       'rdbms_hostname': \"...\",\n                       'rdbms_port': ...,\n                       'rdbms_database_name': \"...\",\n                       'rdbms_account_username': '...'\n                       'rdbms_account_password': '...'\n                     },\n                     'tag': {\n                       'rdbms_hostname': \"...\",\n                       'rdbms_port': ...,\n                       'rdbms_database_name': \"...\",\n                       'rdbms_account_username': '...'\n                       'rdbms_account_password': '...'\n                     },\n                     ...\n                   }\n               The key ``None`` is the default tag.\n\n        @param tag: a tag that specifies which particular connection\n           properties has to be used.\n\n        @param logger_name: name of the logger for debug information.\n\n        @param auto_commit: indicate whether the transaction needs to be\n           committed at the end of the session.\n\n        @return: a ``RdbmsConnection`` instance to be used supporting the\n             Python clause ``with ...:``.\n\n        @raise DefaultConnectionPropertiesSettingException: if the specified\n               tag is not defined in the dictionary of connection properties,\n               and when no default connection properties is defined either\n               (tag ``None``).\n        \"\"\"\n        try:\n            connection_properties = settings.get(tag, settings[None])\n        except KeyError:\n            raise RdbmsConnection.DefaultConnectionPropertiesSettingException()\n\n        return RdbmsConnection(\n            connection_properties['rdbms_hostname'],\n            connection_properties['rdbms_port'],\n            connection_properties['rdbms_database_name'],\n            connection_properties['rdbms_account_username'],\n            connection_properties['rdbms_account_password'],\n            logger_name=logger_name,\n            auto_commit=auto_commit)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef execute(self, sql_statement, parameters=None):\n        if parameters:\n            # Convert the simple value of parameters which the database adapter\n            # cannot adapt to SQL type, such as enum values.\n            # [http://initd.org/psycopg/docs/usage.html#query-parameters]\n            #\n            # @note: tuple is a special type used to indicate not to quote the\n            #     underlying value which is a special SQL expression, such as a\n            #     call of a stored procedure.\n            for (name, value) in parameters.iteritems():\n                if not isinstance(value, (types.NoneType, bool, int, long, float, basestring, tuple, list, set)):\n                    parameters[name] = obj.stringify(value)\n\n            # Replace the placeholders in the SQL statement for which the database\n            # adapter cannot adapt the Python value to SQL types, for instance,\n            # list and nested list.\n            sql_statement = RdbmsConnection._prepare_statement(sql_statement, parameters)\n\n        # Compact the SQL statement expression removing useless space and\n        # newline characters, and stripping all SQL comments.\n        sql_statement = ' '.join(\n                [ line for line in [ line.strip() for line in REGEX_PATTERN_SQL_COMMENT.sub('\\n', sql_statement.strip()).splitlines() ]\n                      if len(line) > 0 ])\n\n        self.logger.debug('[DEBUG] Executing SQL statement:\\n%s\\n\\twith: %s' % (sql_statement, parameters))\n\n        if self.__cursor is None:\n            self.__cursor = self.__connection.cursor()\n\n        execution_start_time = datetime.datetime.now()\n        self.__cursor.execute(sql_statement, parameters)\n        execution_end_time = datetime.datetime.now()\n        execution_duration = execution_end_time - execution_start_time\n        self.logger.debug('Time: %d ms' % ((execution_duration.seconds * 1000) + (execution_duration.microseconds / 1000)))\n\n        return RdbmsConnection.RdbmsCursor(self.__cursor)", "response": "Execute the specified Structured Query Language parameterized\n            statement."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _expand_placeholder_value(value):\n        if isinstance(value, (list, set)) or (isinstance(value, tuple) and len(value) != 1):\n            sql_value = ','.join( [ RdbmsConnection._to_sql_value(\n                        element if not isinstance(element, tuple) else element[0],\n                        noquote=isinstance(element, tuple))\n                    for element in value ])\n\n        elif isinstance(value, tuple):\n            assert len(value) == 1\n            value = value[0]\n            assert value is None or isinstance(value, basestring), 'basestring expected instead of %s' % type(value)\n            sql_value = RdbmsConnection._to_sql_value(value, True)\n\n        else:\n            sql_value = RdbmsConnection._to_sql_value(value)\n\n        return sql_value", "response": "Expands the value of a placeholder s a\n            value."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_placeholders(sql_statement, parameters):\n        # Find the list of placeholders, and their type, defined in the SQL\n        # statement.\n        placeholders = {}\n\n        try:\n            for match in REGEX_PATTERN_SQL_PLACEHOLDERS.findall(sql_statement):\n                for (i, placeholder_type) in enumerate(PlaceholderType._values):\n                    placeholder_name = match[i]\n                    if placeholder_name:\n                        placeholder_value = parameters[placeholder_name]\n\n                        if placeholder_type == PlaceholderType.nested_list \\\n                                and (isinstance(placeholder_value, tuple) and len(placeholder_value) == 1) \\\n                                and not isinstance(placeholder_value, (list, set, tuple)):\n                            raise ValueError('The value to replace the placeholder \"%s\" is not a list as expected' % placeholder_name)\n\n                        placeholders[placeholder_name] = (placeholder_type, placeholder_value)\n                        break\n\n        except KeyError:\n            raise ValueError('The placeholder %s has no corresponding parameter' % placeholder_name)\n\n        # Check whether all the specified parameters have their corresponding\n        # placeholder in the SQL statement.\n        undefined_placeholders = [ parameter for parameter in parameters.iterkeys()\n                if parameter not in placeholders ]\n\n        if undefined_placeholders:\n            raise ValueError('The placeholders %s are missing from the extended pyformat SQL statement\\n%s' \\\n                    % (', '.join([ '\"%s\"' % _ for _ in undefined_placeholders ]), sql_statement))\n\n        return placeholders", "response": "Retrieve the list of placeholders and their type defined in an SQL statement and the list of parameters used in the SQL statement."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _prepare_statement(sql_statement, parameters):\n        placehoolders = RdbmsConnection._get_placeholders(sql_statement, parameters)\n\n        for (variable_name, (variable_type, variable_value)) in placehoolders.iteritems():\n            # Only expand parameters whose value corresponds to a list.\n            if isinstance(variable_value, (list, set, tuple)):\n                sql_statement = RdbmsConnection._replace_placeholder(sql_statement,\n                        (variable_name, variable_type, variable_value))\n\n                # Remove this parameter as it has been expended in the SQL expression.\n                del parameters[variable_name]\n\n        return sql_statement", "response": "Prepares the specified SQL statement replacing the placeholders by the value of the corresponding the theCOOKIE variables."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _replace_placeholder(sql_statement, variable):\n        (variable_name, variable_type, variable_value) = variable\n\n        sql_value = RdbmsConnection._expand_placeholder_value(variable_value) if variable_type == PlaceholderType.simple_list \\\n            else ','.join([ '(%s)' % RdbmsConnection._expand_placeholder_value(v) for v in variable_value ])\n\n        return re.sub(PATTERN_SQL_PLACEHOLDER_EXPRESSIONS[variable_type] % variable_name, sql_value, sql_statement)", "response": "Return the string expression obtained by replacing the specified placeholders by their corresponding value."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a value to its SQL string representation.", "response": "def _to_sql_value(value, noquote=False):\n        \"\"\"\n        Return the SQL string representation of the specified value.\n\n\n        @param value: a value to convert into its SQL string representation.\n\n        @param noquote: indicate whether to quote or not the specified value.\n\n\n        @return: a SQL string representation of the specified value.\n        \"\"\"\n        # Convert to string the values that the database adapter can't adapt\n        # to a SQL type.\n        # [http://initd.org/psycopg/docs/usage.html#query-parameters]\n        if not isinstance(value, (types.NoneType, bool, int, long, float, basestring)):\n            value = obj.stringify(value)\n\n        if noquote:\n            return value\n\n        # @warning: do not use ``psycopg2.extensions.adapt(value).getquoted()``\n        #     because it returns ``str`` object, which is expected as adaptation\n        #     is taking a Python object and converting it into a SQL\n        #     representation: this is always a bytes string, as it has to be\n        #     sent to the socket.  However the caller might not use the quoted\n        #     value to immediately sent it to the database server, but it can\n        #     use it for rewriting an SQL statement, which will break the text\n        #     encoding.\n        return 'NULL' if value is None \\\n                else '%s' % str(value) if isinstance(value, (bool, int, long, float)) \\\n                else \"e'%s'\" % unicode(value).replace(\"'\", \"''\").replace('\\\\', '\\\\\\\\').replace('%', '%%')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives a launchable resource create a standalone EC2Instance instance.", "response": "def standalone_from_launchable(cls, launch):\n        \"\"\"\n        Given a launchable resource, create a definition of a standalone\n        instance, which doesn't depend on or contain references to other\n        elements.\n        \"\"\"\n        attrs = copy.copy(launch.el_attrs)\n        # Remove attributes we overwrite / don't need\n        del attrs[\"Type\"]\n        if attrs.has_key(\"DependsOn\"):\n            del attrs[\"DependsOn\"]\n        if attrs[\"Properties\"].has_key(\"SpotPrice\"):\n            del attrs[\"Properties\"][\"SpotPrice\"]\n        if attrs[\"Properties\"].has_key(\"InstanceMonitoring\"):\n            del attrs[\"Properties\"][\"InstanceMonitoring\"]\n        if attrs[\"Properties\"].has_key(\"SecurityGroups\"):\n            del attrs[\"Properties\"][\"SecurityGroups\"]\n        if attrs[\"Properties\"].has_key(\"InstanceId\"):\n            raise RuntimeError(\"Can't make instance from launchable containing InstanceId property\")\n        inst = EC2Instance(**attrs)\n        # TODO: shallow copy?\n        inst.iscm = launch.iscm\n        return inst"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extract_geometry(self, branch, branch_begin):\r\n        raw_geometry = []\r\n        with open(self.abspath) as fobj:\r\n            for line in fobj.readlines()[branch_begin:]:\r\n                points = []\r\n                for point in line.split(' '):\r\n                    try:\r\n                        points.append(float(point))\r\n                    except ValueError:\r\n                        pass\r\n                raw_geometry.extend(points)\r\n                if 'CATALOG' in line or 'BRANCH' in line:\r\n                    break\r\n        xy_geo = raw_geometry\r\n        self.geometries[branch] = (xy_geo[:int(len(xy_geo)/2)],\r\n                                   xy_geo[int(len(xy_geo)/2):])", "response": "This method extracts the geometry of the current branch from the file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nextracts a specific varaible varaible.", "response": "def extract(self, variable_idx):\r\n        \"\"\"\r\n        Extract a specific varaible\r\n        \"\"\"\r\n        branch = self._define_branch(variable_idx)\r\n        label = self.profiles[variable_idx].replace(\"\\n\", \"\")\r\n        self.label[variable_idx] = label\r\n        self.data[variable_idx] = [[], []]\r\n        with open(self.abspath) as fobj:\r\n            for line in fobj.readlines()[\r\n                    variable_idx+1+self._attributes['data_idx']::\r\n                    self._attributes['nvar']+1]:\r\n                points = []\r\n                for point in line.split(' '):\r\n                    try:\r\n                        points.append(float(point))\r\n                    except ValueError:\r\n                        pass\r\n                self.data[variable_idx][1].append(np.array(points))\r\n        x_st = self.geometries[branch][0]\r\n        x_no_st = [(x0+x1)/2 for x0, x1 in zip(x_st[:-1], x_st[1:])]\r\n        if len(self.data[variable_idx][1][0]) == len(x_st):\r\n            self.data[variable_idx][0] = np.array(x_st)\r\n        else:\r\n            self.data[variable_idx][0] = np.array(x_no_st)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_excel(self, *args):\r\n        path = os.getcwd()\r\n        fname = self.fname.replace(\".ppl\", \"_ppl\") + \".xlsx\"\r\n        if len(args) > 0 and args[0] != \"\":\r\n            path = args[0]\r\n            if os.path.exists(path) == False:\r\n                os.mkdir(path)\r\n        xl_file = pd.ExcelWriter(path + os.sep + fname)\r\n        for idx in self.filter_data(\"\"):\r\n            self.extract(idx)\r\n        labels = list(self.filter_data(\"\").values())\r\n        for prof in self.data:\r\n            data_df = pd.DataFrame()\r\n            data_df[\"X\"] = self.data[prof][0]\r\n            for timestep, data in zip(self.time, self.data[prof][1]):\r\n                data_df[timestep] = data\r\n            myvar = labels[prof-1].split(\" \")[0]\r\n            br_label = labels[prof-1].split(\"\\'\")[5]\r\n            unit = labels[prof-1].split(\"\\'\")[7].replace(\"/\", \"-\")\r\n            mylabel = \"{} - {} - {}\".format(myvar, br_label, unit)\r\n            data_df.to_excel(xl_file, sheet_name=mylabel)\r\n        xl_file.save()", "response": "Dump all the data to an Excel file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef quote_as2name(unquoted_name):\n\n    if re.search(r'[\\\\\" ]', unquoted_name, re.M):\n        return '\"' + email.utils.quote(unquoted_name) + '\"'\n    else:\n        return unquoted_name", "response": "Function converts an as2 name from unquoted to quoted format\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mime_to_bytes(msg, header_len):\n    fp = BytesIO()\n    g = BytesGenerator(fp, maxheaderlen=header_len)\n    g.flatten(msg)\n    return fp.getvalue()", "response": "Function to convert and email. Message to bytes"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfunctions to convert an email. Message to standard format string", "response": "def canonicalize(message):\n    \"\"\"\n    Function to convert an email Message to standard format string\n\n    :param message: email.Message to be converted to standard string\n    :return: the standard representation of the email message in bytes\n    \"\"\"\n\n    if message.is_multipart() \\\n            or message.get('Content-Transfer-Encoding') != 'binary':\n\n        return mime_to_bytes(message, 0).replace(\n            b'\\r\\n', b'\\n').replace(b'\\r', b'\\n').replace(b'\\n', b'\\r\\n')\n    else:\n        message_header = ''\n        message_body = message.get_payload(decode=True)\n        for k, v in message.items():\n            message_header += '{}: {}\\r\\n'.format(k, v)\n        message_header += '\\r\\n'\n        return message_header.encode('utf-8') + message_body"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef extract_first_part(message, boundary):\n    first_message = message.split(boundary)[1].lstrip()\n    if first_message.endswith(b'\\r\\n'):\n        first_message = first_message[:-2]\n    else:\n        first_message = first_message[:-1]\n    return first_message", "response": "Function to extract the first part of a multipart message"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pem_to_der(cert, return_multiple=True):\n\n    # initialize the certificate array\n    cert_list = []\n\n    # If certificate is in DER then un-armour it\n    if pem.detect(cert):\n        for _, _, der_bytes in pem.unarmor(cert, multiple=True):\n            cert_list.append(der_bytes)\n    else:\n        cert_list.append(cert)\n\n    # return multiple if return_multiple is set else first element\n    if return_multiple:\n        return cert_list\n    else:\n        return cert_list.pop()", "response": "Converts a given certificate or list to PEM format"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef split_pem(pem_bytes):\n    started, pem_data = False, b''\n    for line in pem_bytes.splitlines(False):\n\n        if line == b'' and not started:\n            continue\n\n        if line[0:5] in (b'-----', b'---- '):\n            if not started:\n                started = True\n            else:\n                pem_data = pem_data + line + b'\\r\\n'\n                yield pem_data\n\n                started = False\n                pem_data = b''\n\n        if started:\n            pem_data = pem_data + line + b'\\r\\n'", "response": "Splits a give PEM file with multiple certificates\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef verify_certificate_chain(cert_str, trusted_certs, ignore_self_signed=True):\n\n    # Load the certificate\n    certificate = crypto.load_certificate(crypto.FILETYPE_ASN1, cert_str)\n\n    # Create a certificate store and add your trusted certs\n    try:\n        store = crypto.X509Store()\n\n        if ignore_self_signed:\n            store.add_cert(certificate)\n\n        # Assuming the certificates are in PEM format in a trusted_certs list\n        for _cert in trusted_certs:\n            store.add_cert(\n                crypto.load_certificate(crypto.FILETYPE_ASN1, _cert))\n\n        # Create a certificate context using the store and the certificate\n        store_ctx = crypto.X509StoreContext(store, certificate)\n\n        # Verify the certificate, returns None if certificate is not valid\n        store_ctx.verify_certificate()\n\n        return True\n\n    except crypto.X509StoreContextError as e:\n        raise AS2Exception('Partner Certificate Invalid: %s' % e.args[-1][-1])", "response": "Verify a given certificate against a trust store"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef csrf(request):\n    def _get_val():\n        token = get_token(request)\n        if token is None:\n            # In order to be able to provide debugging info in the\n            # case of misconfiguration, we use a sentinel value\n            # instead of returning an empty dict.\n            return 'NOTPROVIDED'\n        else:\n            token = force_bytes(token, encoding='latin-1')\n            key = force_bytes(\n                get_random_string(len(token)),\n                encoding='latin-1'\n            )\n            value = b64_encode(xor(token, key))\n            return force_text(b'$'.join((key, value)), encoding='latin-1')\n    _get_val = lazy(_get_val, text_type)\n\n    return {'csrf_token': _get_val()}", "response": "Context processor that provides a CSRF token."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef api(root_url, service, version, path):\n    root_url = root_url.rstrip('/')\n    path = path.lstrip('/')\n    if root_url == OLD_ROOT_URL:\n        return 'https://{}.taskcluster.net/{}/{}'.format(service, version, path)\n    else:\n        return '{}/api/{}/{}/{}'.format(root_url, service, version, path)", "response": "Generate URL for path in a Taskcluster service."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef api_reference(root_url, service, version):\n    root_url = root_url.rstrip('/')\n    if root_url == OLD_ROOT_URL:\n        return 'https://references.taskcluster.net/{}/{}/api.json'.format(service, version)\n    else:\n        return '{}/references/{}/{}/api.json'.format(root_url, service, version)", "response": "Generate URL for a Taskcluster api reference."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate URL for path in the Taskcluster docs.", "response": "def docs(root_url, path):\n    \"\"\"Generate URL for path in the Taskcluster docs.\"\"\"\n    root_url = root_url.rstrip('/')\n    path = path.lstrip('/')\n    if root_url == OLD_ROOT_URL:\n        return 'https://docs.taskcluster.net/{}'.format(path)\n    else:\n        return '{}/docs/{}'.format(root_url, path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef exchange_reference(root_url, service, version):\n    root_url = root_url.rstrip('/')\n    if root_url == OLD_ROOT_URL:\n        return 'https://references.taskcluster.net/{}/{}/exchanges.json'.format(service, version)\n    else:\n        return '{}/references/{}/{}/exchanges.json'.format(root_url, service, version)", "response": "Generate URL for a Taskcluster exchange reference."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef schema(root_url, service, name):\n    root_url = root_url.rstrip('/')\n    name = name.lstrip('/')\n    if root_url == OLD_ROOT_URL:\n        return 'https://schemas.taskcluster.net/{}/{}'.format(service, name)\n    else:\n        return '{}/schemas/{}/{}'.format(root_url, service, name)", "response": "Generate URL for a schema in a Taskcluster service."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ui(root_url, path):\n    root_url = root_url.rstrip('/')\n    path = path.lstrip('/')\n    if root_url == OLD_ROOT_URL:\n        return 'https://tools.taskcluster.net/{}'.format(path)\n    else:\n        return '{}/{}'.format(root_url, path)", "response": "Generate URL for a path in the Taskcluster ui."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a sealer that just does regex - based validation.", "response": "def regex_validation_sealer(fields, defaults, RegexType=type(re.compile(\"\"))):\n    \"\"\"\n    Example sealer that just does regex-based validation.\n    \"\"\"\n    required = set(fields) - set(defaults)\n    if required:\n        raise TypeError(\n            \"regex_validation_sealer doesn't support required arguments. Fields that need fixing: %s\" % required)\n\n    klass = None\n    kwarg_validators = dict(\n        (key, val if isinstance(val, RegexType) else re.compile(val)) for key, val in defaults.items()\n    )\n    arg_validators = list(\n        kwarg_validators[key] for key in fields\n    )\n\n    def __init__(self, *args, **kwargs):\n        for pos, (value, validator) in enumerate(zip(args, arg_validators)):\n            if not validator.match(value):\n                raise ValidationError(\"Positional argument %s failed validation. %r doesn't match regex %r\" % (\n                    pos, value, validator.pattern\n                ))\n        for key, value in kwargs.items():\n            if key in kwarg_validators:\n                validator = kwarg_validators[key]\n                if not validator.match(value):\n                    raise ValidationError(\"Keyword argument %r failed validation. %r doesn't match regex %r\" % (\n                        key, value, validator.pattern\n                    ))\n        super(klass, self).__init__(*args, **kwargs)\n\n    klass = type(\"RegexValidateBase\", (__base__,), dict(\n        __init__=__init__,\n    ))\n    return klass"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef compute_samples(self):\n        eps = tf.random_normal([self.batch_size, self.eq_samples, self.iw_samples, self.num_latent])\n        z = tf.reshape(eps * self.std + self.mu, [-1, self.num_latent])\n        return z", "response": "Sample from a Normal distribution with inferred mu and std."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef neg_log_likelihood(self, x, standard=False):\n        x_reshape = tf.reshape(x, [self.batch_size, self.eq_samples, self.iw_samples, self.num_latent])\n        c = - 0.5 * math.log(2 * math.pi)\n        if standard is False:\n            density = c - tf.log(self.std) - (x_reshape - self.mu) ** 2 / (2 * self.std**2)\n        else:\n            density = c - (x_reshape - self.mu) ** 2 / 2\n        # sum over all importance weights. average over all eq_samples\n        return tf.reduce_mean(tf.reduce_sum(-density, axis=2), axis=(1, 2))", "response": "Calculate the negative log likelihood of a particular class."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsampling from a Normal distribution with inferred mu and std", "response": "def compute_samples(self):\n        \"\"\" Sample from a Normal distribution with inferred mu and std \"\"\"\n        mu, std, h, w = self.params\n        shape = tf.shape(mu)\n        eps = tf.random_normal(shape)\n        z = tf.reshape(eps * std + mu, tf.stack([-1, h, w, self.num_latent]))\n        return z"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating the log likelihood of a particular set of data.", "response": "def log_likelihood(self, x, x_dims=(128, 128), standard=False):\n        \"\"\" Calculate Log Likelihood with particular mean and std\n        x must be 2D. [batch_size * eqsamples* iwsamples, num_latent]\n        \"\"\"\n        mu, std, h, w = self.params\n        shape = tf.stack([32, x_dims[0], x_dims[1], self.num_latent, 1, 1])\n        x_reshape = tf.reshape(x, shape)\n        c = - 0.5 * math.log(2 * math.pi)\n        if standard is False:\n            density = c - tf.log(std + 1e-10) - (x_reshape - mu) ** 2 / (2 * std**2)\n        else:\n            density = c - x_reshape ** 2 / 2\n        # sum over all importance weights. average over all eq_samples\n        return tf.reduce_mean(tf.reduce_sum(density, axis=2), axis=(1, 2))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsamples from a Normal distribution with inferred mu and std.", "response": "def compute_samples(self):\n        \"\"\" Sample from a Normal distribution with inferred mu and std \"\"\"\n        shape = [self.batch_size, self.eq_samples, self.iw_samples, self.num_latent]\n        mu = tf.nn.sigmoid(self.mu)\n        z = tf.select(tf.random_uniform(shape) - mu > 0, tf.ones(shape), tf.zeros(shape))\n        return z"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the negative log likelihood of a particular mean and standard.", "response": "def neg_log_likelihood(self, x):\n        \"\"\" Calculate Log Likelihood with particular mean and std\n        x must be 2D. [batch_size * eqsamples* iwsamples, num_latent]\n        \"\"\"\n        x_reshape = tf.reshape(x, [self.batch_size, self.eq_samples, self.iw_samples, self.num_latent])\n        density = tf.nn.sigmoid_cross_entropy_with_logits(self.mu, x_reshape)\n        # sum over all importance weights. average over all eq_samples\n        return tf.reduce_mean(tf.reduce_sum(-density, axis=2), axis=(1, 2))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef compute_samples(self):\n        shape = [self.batch_size, self.eq_samples, self.iw_samples, self.num_latent]\n\n        z = tf.nn.softmax(self.pi)\n        return z", "response": "Compute the samples from a Normal distribution with inferred mu and std."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate the negative log likelihood of a particular mean and standard deviation.", "response": "def neg_log_likelihood(self, x, eps=1e-10):\n        \"\"\" Calculate Log Likelihood with particular mean and std\n        x must be 2D. [batch_size * eqsamples* iwsamples, num_latent]\n        \"\"\"\n        x_reshape = tf.reshape(x, [self.batch_size, self.eq_samples, self.iw_samples, self.num_latent])\n\n        # mean over the softmax outputs inside the log domain.\n        pi = tf.reduce_mean(self.pi, axis=(1, 2))\n\n        density = tf.reduce_mean(x * tf.log(pi + eps))\n        return tf.reduce_sum(-density, axis=2)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading function for PI server. It has to be executed by python 32 bit. It has to be executed by python 32 bit. It has to be executed by python 32 bit. It has to be executed by python 32 bit.", "response": "def PI_read(server, tag, start=None, end=None, frequency=None):\n    \"\"\"\n    Read function for PI server. It has to be executed by python 32 bit.\n    \"\"\"\n    pisdk = Dispatch('PISDK.PISDK')\n    my_server = pisdk.Servers(server)\n    # Not sure if/when the login is necessary\n    #con = Dispatch('PISDKDlg.Connections') \n    #con.Login(my_server, '', '', 1, 0)\n    time_start = Dispatch('PITimeServer.PITimeFormat')\n    time_end = Dispatch('PITimeServer.PITimeFormat')\n    sample_point = my_server.PIPoints[tag]\n    uom = sample_point.PointAttributes.Item(\"EngUnits\").Value\n    description = sample_point.PointAttributes.Item('Descriptor').Value \n    if start != None and end != None:\n        # returns a range of values (average)\n        time_start.InputString = start.strftime('%m-%d-%Y %H:%M:%S')\n        time_end.InputString = end.strftime('%m-%d-%Y %H:%M:%S')\n        sample_values = sample_point.Data.Summaries2(time_start, time_end, \n                                                     frequency, 5, 0, None)\n        values = sample_values('Average').Value\n        data = np.array([x.Value for x in values])\n    elif start != None and end == None:\n        # returns a single value at the start time\n        end = start + timedelta(seconds=1)\n        time_start.InputString = start.strftime('%m-%d-%Y %H:%M:%S')\n        time_end.InputString = end.strftime('%m-%d-%Y %H:%M:%S')\n        sample_values = sample_point.Data.Summaries2(time_start, time_end, \n                                                     frequency, 5, 0, None)\n        values = sample_values('Average').Value\n        data = [x.Value for x in values][0]\n    else:\n        # returns the actual value\n        data = sample_point.data.Snapshot.Value  \n    return description, uom, np.array(data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove some useless stuff from the head of a csv file generated by unisim and returns a pandas dataframe", "response": "def unisim_csv_formatting(path, fname):\n    \"\"\"\n    Remove some useless stuff from the head of a csv file generated by unisim\n    and returns a pandas dataframe\n    \"\"\"\n    with open(path+fname, 'r') as fobj:\n        data = fobj.readlines()\n        header = data[9].split(\",\")[:-1]\n        unit_of_measures = data[10].split(\",\")[:-1]\n    data = pd.read_csv(path+fname,\n                       skiprows=10,\n                       index_col=0,\n                       usecols=(range(0, len(header))),\n                       na_values=('Shutdown', 'Bad',\n                                  'I/O Timeout', 'Scan Timeout'))\n    data.columns = header[1:]\n    data.unit = unit_of_measures[1:]\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nextracts a specific stripchard and exposes the data in the namespace", "response": "def extract_stripchart(self, stripchart='overall', expose_data=True):\n        \"\"\"\n        Extract a specific stripchard and exposes the data in the namespace\n        \"\"\"\n        csv_fname = self.fname.split(os.sep)[-1].replace(\".usc\", \".csv\")\n        scp_fname = self.fname.split(os.sep)[-1].replace(\".usc\", \".SCP\")\n        case_details = {'case': self.fname.__repr__()[1:-1],\n                        'stripchart': stripchart,\n                        'target': self.path.__repr__()[1:-1] + csv_fname}\n        script = STRIPCHART_EXTRACTION_TEMPLATE.substitute(case_details)\n        with open(self.path + scp_fname, 'w') as fobj:\n            fobj.write(script)\n        self.case.visible = True\n        self.case.application.playscript(self.path + scp_fname)\n        self.case.visible = False\n        os.remove(self.path + scp_fname)\n        if expose_data is True:\n            self.stripcharts[stripchart] = unisim_csv_formatting(self.path,\n                                                                 csv_fname)\n        if os.path.isdir(self.path+'trends') is not True:\n            os.mkdir(self.path + 'trends')\n        shutil.copy(self.path + csv_fname,\n                    self.path + 'trends\\\\{}.csv'.format(stripchart))\n        os.remove(self.path + csv_fname)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nextracts all the profiles of a specific pipeline and exposes the data in the namespace", "response": "def extract_profiles(self, pipeline_name, expose_data=True):\n        \"\"\"\n        Extract all the profiles of a specific pipeline and exposes the data\n        in the namespace\n        \"\"\"\n        compas_pipe = self.__profile_definition(pipeline_name)\n        get_variable = compas_pipe.GEtUserVariable\n        if os.path.isdir(self.path+'profiles') is not True:\n            os.mkdir(self.path + 'profiles')\n        target_dir = self.path + 'profiles'\n        if expose_data is True:\n            self.profiles[pipeline_name] = {}\n        for key in PROFILE_KEYS:\n            pipe = self.pipes[pipeline_name]\n            pipe['data'][key] = get_variable(PROFILE_KEYS[key]).Variable()\n            temp = {key: val for (key, val) in enumerate(pipe['data'][key])}\n            try:\n                data = pd.DataFrame(temp, index=pipe['grid'])\n            except ValueError:\n                data = pd.DataFrame(temp, index=pipe['non_st_grid'])\n            data.columns = self.pipes[pipeline_name]['timesteps']\n            data.to_csv('{}/{}-{}.csv'.format(target_dir, pipeline_name, key))\n            if expose_data is True:\n                self.profiles[pipeline_name][key] = data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npreparing the profiles extraction from a specific pipeline", "response": "def __profile_definition(self, pipeline_name):\n        \"\"\"\n        Prepare the profiles extraction from a specific profile\n        \"\"\"\n        pipe = self.flsh.Operations[pipeline_name]\n        x_st = pipe.GetUserVariable(PROFILE_LENGTH_ST).Variable()\n        x_non_st = pipe.GetUserVariable(PROFILE_LENGTH_NON_ST).Variable()\n        timesteps = pipe.GetUserVariable(PROFILE_TIME).Variable()\n        self.pipes[pipeline_name] = {'grid': x_st,\n                                     'non_st_grid': x_non_st,\n                                     'timesteps': timesteps,\n                                     'data': {}\n                                    }\n        return pipe"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning a case untile the specifiend endtime", "response": "def run_until(self, endtime, timeunit='minutes', save=True):\n        \"\"\"\n        Run a case untile the specifiend endtime\n        \"\"\"\n        integrator = self.case.solver.Integrator\n        integrator.rununtil(endtime, timeunit)\n        if save is True:\n            self.case.save()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsaves the current case to a file.", "response": "def save(self, fname=''):\n        \"\"\"\n        Save the current case\n        \"\"\"\n        if fname is '':\n            self.case.save()\n        else:\n            self.case.SaveAs(self.path+os.sep+fname)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninputs data description: FLOW PATTERN (FREE=0), SUPERF. GAS VELOCITY, [m/s], SUPERF. LIQUID VEL, [m/s], WATERCUT (WC), [fraction], DENSITY GAS, [kg/m3], DENSITY OIL, [kg/m3], DENSITY WATER, [kg/m3], VISCOSITY GAS, [Ns/m2], VISCOSITY OIL, [Ns/m2], VISCOSITY WATER, [Ns/m2], SURFACE TENSION O/G, [N/m], SURFACE TENSION W/O, [N/m], PIPE DIAMETER, [m], PIPE INCLINATION, [deg], WALL ROUGHNESS,[m], ENTRAINMENT, [fraction of liquid], PHASE INVERSION, [-], LINEAR EMULSION FACTOR, [-], QUADRATIC EMULSION FACTOR, [-], SMOOTHING FACTOR, [-], POWER LAW / HERSCHEL-BULKLEY EXP (N), POWER LAW CONSISTENCY, YIELD STRESS", "response": "def run(self, phase_number=3, **kwargs):\n        \"\"\"\n        Input data description: FLOW PATTERN (FREE=0), SUPERF. GAS VELOCITY, [m/s],\n        SUPERF. LIQUID VEL, [m/s], WATERCUT (WC), [fraction], DENSITY GAS, [kg/m3],\n        DENSITY OIL, [kg/m3], DENSITY WATER, [kg/m3], VISCOSITY GAS, [Ns/m2],\n        VISCOSITY OIL, [Ns/m2], VISCOSITY WATER, [Ns/m2], SURFACE TENSION O/G, [N/m],\n        SURFACE TENSION W/O, [N/m], PIPE DIAMETER, [m], PIPE INCLINATION, [deg],\n        WALL ROUGHNESS,[m], ENTRAINMENT, [fraction of liquid], \n        PHASE INVERSION, [-], LINEAR EMULSION FACTOR, [-],\n        QUADRATIC EMULSION FACTOR, [-], SMOOTHING FACTOR, [-],\n        POWER LAW / HERSCHEL-BULKLEY EXP (N), POWER LAW CONSISTENCY, YIELD STRESS\n        \"\"\"\n        input_data = {'FP':   0,\n                      'SGV':  kwargs['SGV'],\n                      'SLV':  kwargs['SLV'],\n                      'WC':   kwargs['WC'],\n                      'RO_G': kwargs['RO_G'],\n                      'RO_O': kwargs['RO_O'],\n                      'RO_W': kwargs['RO_W'],\n                      'MU_G': kwargs['MU_G'],\n                      'MU_O': kwargs['MU_O'],\n                      'MU_W': kwargs['MU_W'],\n                      'S_OG': kwargs['S_OG'],\n                      'S_OW': kwargs['S_OW'],\n                      'ID':   kwargs['ID'],\n                      'INCL': kwargs['INCL'],\n                      'Ra':   kwargs['Ra'],\n                      'ENTRAINMENT': 0,\n                      'PHASE INVERSION': 0.67,\n                      'LINEAR EMULSION FACTOR': 1,\n                      'QUADRATIC EMULSION FACTOR': 1,\n                      'SMOOTHING FACTOR': 1,\n                      'POWER LAW / HERSCHEL-BULKLEY EXP': 0,\n                      'POWER LAW CONSISTENCY': 0,\n                      'YIELD STRESS': 0,}\n        input_arr = [v for v in input_data.values()]\n        arr = np.zeros(200)\n        if phase_number is 2:\n            indx = [4,2,1,1,6,0,0,1,2,0,2,0,0,0,0,0,0,1,0,0] # SFC 2-phase option\n        if phase_number is 3:\n            indx = [4,2,1,1,6,0,0,1,2,0,2,0,0,0,0,1,0,1,0,0] # SFC 3-phase option\n        input_arr = (ctypes.c_double * len(input_arr))(*input_arr)\n        arr = (ctypes.c_double * len(arr))(*arr)\n        indx = (ctypes.c_short * len(indx))(*indx)\n        self.dll.sfc_front(input_arr, indx, arr)\n        results = pd.DataFrame(np.hstack([input_arr[1:], arr])).T\n        results.columns = IO_COLNAMES\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef class_sealer(fields, defaults,\n                 base=__base__, make_init_func=make_init_func,\n                 initializer=True, comparable=True, printable=True, convertible=False, pass_kwargs=False):\n    \"\"\"\n    This sealer makes a normal container class. It's mutable and supports arguments with default values.\n    \"\"\"\n    baseclass_name = 'FieldsBase_for__{0}'.format('__'.join(fields))\n    if pass_kwargs:\n        options = dict(\n            header_end=', **__fields_kwargs__):\\n',\n            super_call_end=', **__fields_kwargs__)\\n',\n            super_call_pass_allargs=False,\n        )\n    else:\n        options = {}\n\n    if initializer:\n        global_namespace, local_namespace = make_init_func(fields, defaults, baseclass_name, **options)\n\n    class FieldsBase(base):\n        if initializer:\n            __init__ = local_namespace['__init__']\n\n        if comparable:\n            def __eq__(self, other):\n                if isinstance(other, self.__class__):\n                    return tuple(getattr(self, a) for a in fields) == tuple(getattr(other, a) for a in fields)\n                else:\n                    return NotImplemented\n\n            def __ne__(self, other):\n                result = self.__eq__(other)\n                if result is NotImplemented:\n                    return NotImplemented\n                else:\n                    return not result\n\n            def __lt__(self, other):\n                if isinstance(other, self.__class__):\n                    return tuple(getattr(self, a) for a in fields) < tuple(getattr(other, a) for a in fields)\n                else:\n                    return NotImplemented\n\n            def __le__(self, other):\n                if isinstance(other, self.__class__):\n                    return tuple(getattr(self, a) for a in fields) <= tuple(getattr(other, a) for a in fields)\n                else:\n                    return NotImplemented\n\n            def __gt__(self, other):\n                if isinstance(other, self.__class__):\n                    return tuple(getattr(self, a) for a in fields) > tuple(getattr(other, a) for a in fields)\n                else:\n                    return NotImplemented\n\n            def __ge__(self, other):\n                if isinstance(other, self.__class__):\n                    return tuple(getattr(self, a) for a in fields) >= tuple(getattr(other, a) for a in fields)\n                else:\n                    return NotImplemented\n\n            def __hash__(self):\n                return hash(tuple(getattr(self, a) for a in fields))\n\n        if printable:\n            def __repr__(self):\n                return \"{0}({1})\".format(\n                    self.__class__.__name__,\n                    \", \".join(\"{0}={1}\".format(attr, repr(getattr(self, attr))) for attr in fields)\n                )\n        if convertible:\n            @property\n            def as_dict(self):\n                return dict((attr, getattr(self, attr)) for attr in fields)\n\n            @property\n            def as_tuple(self):\n                return tuple(getattr(self, attr) for attr in fields)\n\n    if initializer:\n        global_namespace[baseclass_name] = FieldsBase\n    return FieldsBase", "response": "This sealer makes a normal container class. It s mutable and supports arguments with default values."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfilters available trends based on pattern", "response": "def filter_trends(self, pattern=''):\r\n        \"\"\"\r\n        Filter available trends\r\n        \"\"\"\r\n        filtered_trends = {}\r\n        with open(self.abspath) as fobj:\r\n            for idx, line in enumerate(fobj):\r\n                variable_idx = idx-self._attributes['CATALOG']-1\r\n                if 'TIME SERIES' in line:\r\n                    break\r\n                if pattern in line and variable_idx > 0:\r\n                    filtered_trends[variable_idx] = line\r\n        return filtered_trends"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef extract(self, *args):\r\n        self.time = np.loadtxt(self.abspath,\r\n                               skiprows=self._attributes['data_idx']+1,\r\n                               unpack=True, usecols=(0,))\r\n        for variable_idx in args:\r\n            data = np.loadtxt(self.abspath,\r\n                              skiprows=self._attributes['data_idx']+1,\r\n                              unpack=True,\r\n                              usecols=(variable_idx,))\r\n            with open(self.abspath) as fobj:\r\n                for idx, line in enumerate(fobj):\r\n                    if idx == 1 + variable_idx+self._attributes['CATALOG']:\r\n                        try:\r\n                            self.data[variable_idx] = data[:len(self.time)]\r\n                        except TypeError:\r\n                            self.data[variable_idx] = data.base\r\n                        self.label[variable_idx] = line.replace(\"\\'\",\r\n                                                                '').replace(\"\\n\",\r\n                                                                            \"\")\r\n                        break", "response": "Extracts a specific variable from the file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a pandas df with the available trends", "response": "def view_trends(self, pattern=''):\r\n        \"\"\"\r\n        Return a pandas df with the available trends\r\n        \"\"\"\r\n        d = OrderedDict()\r\n        d['Index'] = None\r\n        d['Variable'] = []\r\n        d['Position'] = []\r\n        d['Unit'] = []\r\n        d['Description'] = []\r\n        raw_d = self.filter_trends(pattern)\r\n        d['Index'] = [k for k in raw_d.keys()]\r\n        for st in self.filter_trends(pattern).values():\r\n            st = st.replace('\\n', '')\r\n            d['Variable'].append(st.split(' ')[0])\r\n            temp = [x[1:-1] for x in re.findall(\"\\'[\\w\\(\\) \\-\\:\\/]+\\'\", st)]\r\n            d['Description'].append(temp[-1])\r\n            d['Unit'].append(temp[-2][1:-1])\r\n            pos = \" - \".join(temp[: -2]).replace(\"BRANCH\", \"Br\").replace(\":\", \"\")\r\n            d['Position'].append(pos)\r\n        df=pd.DataFrame(d)\r\n        df.index.name = \"Filter: {}\".format(pattern)\r\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_excel(self, *args):\r\n        path = os.getcwd()\r\n        fname = self.fname.replace(\".tpl\", \"_tpl\") + \".xlsx\"\r\n        idxs = self.filter_trends(\"\")\r\n        for idx in idxs:\r\n            self.extract(idx)\r\n        data_df = pd.DataFrame(self.data)\r\n        data_df.columns = self.label.values()\r\n        data_df.insert(0, \"Time [s]\", self.time)\r\n        if len(args) > 0 and args[0] != \"\":\r\n            path = args[0]\r\n            if os.path.exists(path) == False:\r\n                os.mkdir(path)\r\n            data_df.to_excel(path + os.sep + fname)\r\n        else:\r\n            data_df.to_excel(self.path + os.sep + fname)", "response": "Dump all the data to excel fname and path can be passed as args"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _tab_type(self):\r\n        with open(self.abspath) as fobj:\r\n            contents = fobj.readlines()\r\n            for line in contents:\r\n                if 'COMPONENTS' in line:\r\n                    return 'keyword'\r\n            else:\r\n                return 'fixed'", "response": "Private method to define the tab type"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread the metadata file and add them to the self. metadata dictionary.", "response": "def _metadata_fixed(self):\r\n        \"\"\"\r\n        Define the most important tab parametersfor a fixed-type tab file\r\n        \"\"\"\r\n        # Number of fluids and index of all the phisical properties\r\n        fluids = {}\r\n        props_idx = {}\r\n        with open(self.abspath) as fobj:\r\n            contents = fobj.readlines()\r\n            for idx, line in enumerate(contents):\r\n                if re.findall(r\"\\'[\\w \\-\\,]*\\'\", line):\r\n                    if line.split('\\'')[-1] not in ('', '\\n'):\r\n                        fluid = line.split('\\'')[-1].replace(\"\\n\", \"\")\r\n                    else:\r\n                        fluid = 'unknown'\r\n                    fluids[fluid] = [idx, contents[idx+1], contents[idx+2]]\r\n                if idx not in (0, 1) and re.findall(r\"[\\w\\-\\/\\,]*[()]+\", line):\r\n                    prop, unit = line.replace(\"\\n\", \"\").split(\"(\")[0:2]\r\n                    prop = prop[1:-1]\r\n                    props_idx[idx] = (fluid, prop, unit.replace(\")\", \"\"))\r\n        self.metadata['nfluids'] = len(fluids)\r\n        # Delete the fluid idx from multiple fluids tab\r\n        for fluid in fluids:\r\n            if self.metadata['nfluids'] != 1:\r\n                fluids[fluid] = [el for idx, el in\r\n                                 enumerate(fluids[fluid]) if idx != 1]\r\n        # Define T and P arrays and all the other patrameters for a fixed tab\r\n        for fluid_idx, fluid in enumerate(fluids):\r\n            p_points, t_points = re.findall(r'[\\w+\\-\\.]+',\r\n                                            fluids[fluid][1])[0:2]\r\n            self.metadata['t_points'].append(int(t_points))\r\n            self.metadata['p_points'].append(int(p_points))\r\n            self.metadata['fluids'].append(fluid)\r\n            # t and p arrays definition\r\n            with open(self.abspath) as fobj:\r\n                contents = fobj.readlines()\r\n                if len(re.findall(r'[\\w+\\-\\.]+', contents[2])) == 2 and\\\r\n                   len(re.findall(r'[\\w+\\-\\.]+', contents[3])) == 2:\r\n                    # for tab file like 'Pearl-2-rich-sep2008.tab':\r\n                    # 'WATER-OPTION ENTROPY 'P-2-rich EOS = PR\r\n                    #    42   35    .205826E-01\r\n                    #   .487805E+06    .882353E+01\r\n                    #   .100000E+06   -.500000E+02\r\n                    p_0, t_0 = re.findall(r'[\\w+\\-\\.]+', contents[3])\r\n                    p_step, t_step = re.findall(r'[\\w+\\-\\.]+', contents[2])\r\n                    t_points = self.metadata[\"t_points\"]\r\n                    p_points = self.metadata[\"p_points\"]\r\n                    t_f = float(t_step)*t_points[fluid_idx] + float(t_0)\r\n                    p_f = float(p_step)*p_points[fluid_idx] + float(p_0)\r\n                    self.metadata['t_array'].append(np.arange(float(t_0),\r\n                                                              t_f,\r\n                                                              float(t_step)))\r\n                    self.metadata['p_array'].append(np.arange(float(p_0),\r\n                                                              p_f,\r\n                                                              float(p_step)))\r\n                else:\r\n                    # for tab file like 'Malampaya_export_gas_2011.tab':\r\n                    if self.metadata['nfluids'] != 1:\r\n                        t_p = self._partial_extraction_fixed(fluids[fluid][0],\r\n                                                             3)\r\n                    else:\r\n                        t_p = self._partial_extraction_fixed(fluids[fluid][0],\r\n                                                             2)\r\n                    len_t_array = self.metadata['t_points'][fluid_idx]\r\n                    len_p_array = self.metadata['p_points'][fluid_idx]\r\n\r\n        self.metadata['p_array'].append(t_p[:len_p_array])\r\n        self.metadata['t_array'].append(t_p[len_p_array:\r\n                                            len_t_array+len_p_array])\r\n        self.data = pd.DataFrame(props_idx,\r\n                                 index=(\"Fluid\", \"Property\",\r\n                                        \"Unit\")).transpose()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _export_all_fixed(self):\r\n        array_ts = []\r\n        array_ps = []\r\n        for array_t, array_p in it.product(self.metadata[\"t_array\"][0],\r\n                                           self.metadata[\"p_array\"][0]):\r\n            array_ts.append(array_t)\r\n            array_ps.append(array_p/1e5)\r\n\r\n        array_ts_tot = [array_ts for t in self.data.index]\r\n        array_ps_tot = [array_ps for t in self.data.index]\r\n        values = []\r\n        for idx in self.data.index:\r\n            values.append(self._partial_extraction_fixed(idx+1))\r\n        self.data[\"Temperature\"] = array_ts_tot\r\n        self.data[\"Pressure\"] = array_ps_tot\r\n        self.data[\"values\"] = values", "response": "Exports all the properties for a fixed - type tab file"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _metadata_keyword(self):\r\n        with open(self.abspath) as fobj:\r\n            for line in fobj:\r\n                if 'PVTTABLE LABEL' in line:\r\n                    label = re.findall(r\"\\=[\\w\\ \\\"]*\\,\", line)[0][1:-1]\r\n                    self.metadata[\"fluids\"].append(label)\r\n\r\n                if 'PRESSURE = (' in line:\r\n                    line = line.split('=')[1]\r\n                    vals = re.findall(r'[\\d\\-\\.eE+]+', line)\r\n                    self.metadata['p_array'] = np.array([float(val) for val in\r\n                                                         vals])\r\n                if 'TEMPERATURE = (' in line:\r\n                    line = line.split('=')[1]\r\n                    vals = re.findall(r'[\\d\\-\\.eE+]+', line)\r\n                    self.metadata['t_array'] = np.array([float(val) for val in\r\n                                                         vals])\r\n                if 'COLUMNS = (' in line:\r\n                    line = line.split('=')[1].replace(\" \", \"\").\\\r\n                           replace('(', '').replace(')\\n', '')\r\n                    self.metadata['properties'] = line.split(',')\r\n            self.metadata[\"t_points\"] = len(self.metadata[\"t_array\"])\r\n            self.metadata[\"p_points\"] = len(self.metadata[\"p_array\"])\r\n            self.metadata[\"nfluids\"] = len(self.metadata[\"fluids\"])\r\n            self.data = pd.DataFrame(self.metadata[\"properties\"])", "response": "Define the most important tab parameters for a keyword - type tab file"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _export_all_keyword(self):\r\n        data = {}\r\n        for fluid_idx, fluid in enumerate(self.metadata[\"fluids\"]):\r\n            data[fluid] = {}\r\n            with open(self.abspath) as fobj:\r\n                text = fobj.read()\r\n                try:\r\n                    text = text.split(\"!Phase properties\")[1+fluid_idx]\r\n                except IndexError:\r\n                    text = text.split(\"COLUMNS\")[1+fluid_idx]\r\n                try:\r\n                    text = text.split(\"LABEL\")[0]\r\n                except IndexError:\r\n                    pass\r\n                values = re.findall(r\"[\\.\\d\\-]+[\\.\\deE\\+\\-]+\", text)\r\n            nprops = len(self.metadata[\"properties\"])\r\n            for idx, prop in enumerate(self.metadata[\"properties\"]):\r\n                data[fluid][prop] = [float(x) for x in values[idx::nprops]]\r\n        self.data = pd.DataFrame(data)", "response": "Export all keywords in the metadata file"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef export_all(self):\r\n        if self.tab_type == 'fixed':\r\n            self._export_all_fixed()\r\n        if self.tab_type == 'keyword':\r\n            self._export_all_keyword()", "response": "This method is used to export all the properties of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads packets from the socket and parse them", "response": "def read_packets(self):\n        \"\"\"Read packets from the socket and parse them\"\"\"\n        while self.running:\n            packet_length = self.client.recv(2)\n            if len(packet_length) < 2:\n                self.stop()\n                continue\n            packet_length = struct.unpack(\"<h\", packet_length)[0] - 2\n\n            data = self.client.recv(packet_length)\n            packno = data[0]\n\n            try:\n                parser = \"Packet\" + format(packno, 'x').upper() + \"Parser\"\n                packet_class = getattr(packets, parser)\n                packet_class().parse(self.world, self.player, data, self._evman)\n            except AttributeError as e:\n                pass\n\n            if packno == 2:\n                self.stop()\n                continue"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites packets from the queue.", "response": "def write_packets(self):\n        \"\"\"Write packets from the queue\"\"\"\n        while self.running:\n            if len(self.write_queue) > 0:\n                self.write_queue[0].send(self.client)\n                self.write_queue.pop(0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef start(self):\n        if not self.writeThread.isAlive() and not self.readThread.isAlive():\n            self.client = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            self.client.connect(self.ADDR)\n            self.running = True\n            self.writeThread.start()\n            self.readThread.start()", "response": "Open sockets to the server and start threads"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes the levinson durbin of a tree from a tree of log entries", "response": "def levinson_durbin(r, order):\n    \"\"\"\n    from http://aidiary.hatenablog.com/entry/20120415/1334458954\n    \"\"\"\n    a = np.zeros(order + 1)\n    e = np.zeros(order + 1)\n\n    # k = 1\n    a[0] = 1.0\n    a[1] = - r[1] / r[0]\n    e[1] = r[0] + r[1] * a[1]\n    lam = - r[1] / r[0]\n\n    for k in xrange(1, order):\n        # update lambda\n        lam = 0.0\n        for j in xrange(k + 1):\n            lam -= a[j] * r[k + 1 - j]\n        lam /= e[k]\n\n        # update a with U and V\n        U = [1]\n        U.extend([a[i] for i in xrange(1, k + 1)])\n        U.append(0)\n        V = [0]\n        V.extend([a[i] for i in xrange(k, 0, -1)])\n        V.append(1)\n        a = np.array(U) + lam * np.array(V)\n\n        # update e\n        e[k + 1] = e[k] * (1.0 - lam * lam)\n\n    return a, e[-1]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef lpc(frame, order):\n    r = acf(frame, unbiased=False, nlags=order)\n    return levinson_durbin(r, order)[0]", "response": "get the linear predictive coefficient of a windowed signal"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates kurtosis of linear prediction residual from input signal", "response": "def lpr_kurtosis(frame, lpcorder=10):\n    \"\"\"\n    frame: windowed signal\n    return kurtosis of linear prediction residual from input signal\n    \"\"\"\n    c = lpc(frame, lpcorder)\n    coef = c[1:][::-1] * -1\n    residuals = []\n    for i in xrange(frame.size - 10):\n        residuals.append(frame[i + 10] - np.sum(frame[i:i + 10] * coef))\n    residuals = np.array(residuals)\n    return calc_kurtosis(residuals)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd or update an existing parameter.", "response": "def set_param(self, name: str, v) -> None:\n        \"\"\"Add or update an existing parameter.\"\"\"\n        self.params[zlib.crc32(name.encode())] = v"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_object(self, name: str, pobj: ParameterObject) -> None:\n        self.objects[zlib.crc32(name.encode())] = pobj", "response": "Add or update an existing object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_list(self, name: str, plist) -> None:\n        self.lists[zlib.crc32(name.encode())] = plist", "response": "Add or update an existing list."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload the dataset into memory.", "response": "def load_data(self, test_percent=0.15):\n        \"\"\"Load the dataset into memory. If data is not divided into train/test, use test_percent to divide the data\"\"\"\n        train_images = list()\n        train_labels = list()\n        test_images = list()\n        test_labels = list()\n        return train_images, train_labels, test_images, test_labels"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsplitting data into train_images train_labels valid_images and valid_labels.", "response": "def split_data(self, train_images, train_labels):\n        \"\"\"\n        :param train_images: numpy array (image_dim, image_dim, num_images)\n        :param train_labels: numpy array (labels)\n        :return: train_images, train_labels, valid_images, valid_labels\n        \"\"\"\n        valid_images = train_images[:self.num_valid_images]\n        valid_labels = train_labels[:self.num_valid_images]\n        train_images = train_images[self.num_valid_images:]\n        train_labels = train_labels[self.num_valid_images:]\n        return train_images, train_labels, valid_images, valid_labels"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the next batch of examples from train data set.", "response": "def next_train_batch(self, batch_size):\n        \"\"\"\n        Return the next batch of examples from train data set\n        :param batch_size: int, size of image batch returned\n        :return train_labels: list, of labels\n        :return images: list, of images\n        \"\"\"\n        start = self.index_in_train_epoch\n        self.index_in_train_epoch += batch_size\n        if self.index_in_train_epoch > self.num_train_images:\n            # Finished epoch\n            self.train_epochs_completed += 1\n\n            # Shuffle the data\n            perm = np.arange(self.num_train_images)\n            np.random.shuffle(perm)\n            self.train_images = self.train_images[perm]\n            self.train_labels = self.train_labels[perm]\n\n            # Start next epoch\n            start = 0\n            self.index_in_train_epoch = batch_size\n            assert batch_size <= self.num_train_images\n\n        end = self.index_in_train_epoch\n        return self.train_labels[start:end], self.img_norm(self.train_images[start:end])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef next_valid_batch(self, batch_size):\n        start = self.index_in_valid_epoch\n        if self.index_in_valid_epoch + batch_size > self.num_valid_images:\n            batch_size = 1\n        self.index_in_valid_epoch += batch_size\n        end = self.index_in_valid_epoch\n        return self.valid_labels[start:end], self.img_norm(self.valid_images[start:end]), end, batch_size", "response": "Return the next batch of examples from validiation data set."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef queue_setup(filename, mode, batch_size, num_readers, min_examples):\n        filename_queue = tf.train.string_input_producer([filename], shuffle=True, capacity=16)\n        if mode == \"train\":\n            examples_queue = tf.RandomShuffleQueue(capacity=min_examples + 3 * batch_size,\n                                                   min_after_dequeue=min_examples, dtypes=[tf.string])\n        else:\n            examples_queue = tf.FIFOQueue(capacity=min_examples + 3 * batch_size, dtypes=[tf.string])\n        enqueue_ops = list()\n        for _ in range(num_readers):\n            reader = tf.TFRecordReader()\n            _, value = reader.read(filename_queue)\n            enqueue_ops.append(examples_queue.enqueue([value]))\n        tf.train.queue_runner.add_queue_runner(tf.train.queue_runner.QueueRunner(examples_queue, enqueue_ops))\n        example_serialized = examples_queue.dequeue()\n        return example_serialized", "response": "Sets up the queue runners for data input"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef thread_setup(read_and_decode_fn, example_serialized, num_threads):\n        decoded_data = list()\n        for _ in range(num_threads):\n            decoded_data.append(read_and_decode_fn(example_serialized))\n        return decoded_data", "response": "Sets up the threads within each reader"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads config dict and yaml dict and then override both with flags dict.", "response": "def load_config_yaml(self, flags, config_dict):\n        \"\"\" Load config dict and yaml dict and then override both with flags dict. \"\"\"\n        if config_dict is None:\n            print('Config File not specified. Using only input flags.')\n            return flags\n        try:\n            config_yaml_dict = self.cfg_from_file(flags['YAML_FILE'], config_dict)\n        except KeyError:\n            print('Yaml File not specified. Using only input flags and config file.')\n            return config_dict\n        print('Using input flags, config file, and yaml file.')\n        config_yaml_flags_dict = self._merge_a_into_b_simple(flags, config_yaml_dict)\n        return config_yaml_flags_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfills in all optional keys with None. Exit in a crucial key is not defined.", "response": "def check_dict_keys(self, config_yaml_flags_dict):\n        \"\"\" Fill in all optional keys with None. Exit in a crucial key is not defined. \"\"\"\n        crucial_keys = ['MODEL_DIRECTORY', 'SAVE_DIRECTORY']\n        for key in crucial_keys:\n            if key not in config_yaml_flags_dict:\n                print('You must define %s. Now exiting...' % key)\n                exit()\n        optional_keys = ['RESTORE_SLIM_FILE', 'RESTORE_META', 'RESTORE_SLIM', 'SEED', 'GPU']\n        for key in optional_keys:\n            if key not in config_yaml_flags_dict:\n                config_yaml_flags_dict[key] = None\n                print('%s in flags, yaml or config dictionary was not found.' % key)\n        if 'RUN_NUM' not in config_yaml_flags_dict:\n            config_yaml_flags_dict['RUN_NUM'] = 0\n        if 'NUM_EPOCHS' not in config_yaml_flags_dict:\n            config_yaml_flags_dict['NUM_EPOCHS'] = 1\n        return config_yaml_flags_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates and define logging directory", "response": "def _check_file_io(self):\n        \"\"\" Create and define logging directory \"\"\"\n        folder = 'Model' + str(self.flags['RUN_NUM']) + '/'\n        folder_restore = 'Model' + str(self.flags['MODEL_RESTORE']) + '/'\n        self.flags['RESTORE_DIRECTORY'] = self.flags['SAVE_DIRECTORY'] + self.flags[\n            'MODEL_DIRECTORY'] + folder_restore\n        self.flags['LOGGING_DIRECTORY'] = self.flags['SAVE_DIRECTORY'] + self.flags[\n            'MODEL_DIRECTORY'] + folder\n        self.make_directory(self.flags['LOGGING_DIRECTORY'])\n        sys.stdout = Logger(self.flags['LOGGING_DIRECTORY'] + 'ModelInformation.log')\n        print(self.flags)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_tf_functions(self):\n        merged = tf.summary.merge_all()\n        saver = tf.train.Saver()\n        if type(self.flags['GPU']) is int:\n            os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(self.flags['GPU'])\n            print('Using GPU %d' % self.flags['GPU'])\n        gpu_options = tf.GPUOptions(allow_growth=True)\n        config = tf.ConfigProto(log_device_placement=False, gpu_options=gpu_options)\n        sess = tf.Session(config=config)\n        writer = tf.summary.FileWriter(self.flags['LOGGING_DIRECTORY'], sess.graph)\n        return merged, saver, sess, writer", "response": "Sets up summary writer saver and session"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _restore_meta(self):\n        restore_meta_file = self._get_restore_meta_file()\n        filename = self.flags['RESTORE_DIRECTORY'] + self._get_restore_meta_file()\n        new_saver = tf.train.import_meta_graph(filename)\n        new_saver.restore(self.sess, filename[:-5])\n        print(\"Model restored from %s\" % restore_meta_file)", "response": "Restore from meta file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _restore_slim(self, variables):\n        variables_to_restore = self.get_variables_in_checkpoint_file(self.flags['RESTORE_SLIM_FILE'])\n        variables_to_restore = {self.name_in_checkpoint(v): v for v in variables if (self.name_in_checkpoint(v) in variables_to_restore)}\n        if variables_to_restore is []:\n            print('Check the SLIM checkpoint filename. No model variables matched the checkpoint variables.')\n            exit()\n        saver = tf.train.Saver(variables_to_restore)\n        saver.restore(self.sess, self.flags['RESTORE_SLIM_FILE'])\n        print(\"Model restored from %s\" % self.flags['RESTORE_SLIM_FILE'])", "response": "Restore from the SLIM file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninitialize the model and restore from files.", "response": "def _initialize_model(self):\n        \"\"\" Initialize the defined network and restore from files is so specified. \"\"\"\n        # Initialize all variables first\n        self.sess.run(tf.local_variables_initializer())\n        self.sess.run(tf.global_variables_initializer())\n        if self.flags['RESTORE_META'] == 1:\n            print('Restoring from .meta file')\n            self._restore_meta()\n        elif self.flags['RESTORE_SLIM'] == 1:\n            print('Restoring TF-Slim Model.')\n            all_model_variables = tf.global_variables()\n            self._restore_slim(all_model_variables)\n        else:\n            print(\"Model training from scratch.\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninitializing all other trainable variables i. e. those which are uninitialized.", "response": "def _init_uninit_vars(self):\n        \"\"\" Initialize all other trainable variables, i.e. those which are uninitialized \"\"\"\n        uninit_vars = self.sess.run(tf.report_uninitialized_variables())\n        vars_list = list()\n        for v in uninit_vars:\n            var = v.decode(\"utf-8\")\n            vars_list.append(var)\n        uninit_vars_tf = [v for v in tf.global_variables() if v.name.split(':')[0] in vars_list]\n        self.sess.run(tf.variables_initializer(var_list=uninit_vars_tf))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _save_model(self, section):\n        checkpoint_name = self.flags['LOGGING_DIRECTORY'] + 'part_%d' % section + '.ckpt'\n        save_path = self.saver.save(self.sess, checkpoint_name)\n        print(\"Model saved in file: %s\" % save_path)", "response": "Save the current model in the logging directory"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrecord the training step.", "response": "def _record_training_step(self, summary):\n        \"\"\" Adds summary to writer and increments the step. \"\"\"\n        self.writer.add_summary(summary=summary, global_step=self.step)\n        self.step += 1"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_seed(self):\n        if self.flags['SEED'] is not None:\n            tf.set_random_seed(self.flags['SEED'])\n            np.random.seed(self.flags['SEED'])", "response": "Set random seed for numpy and tensorflow packages"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _summaries(self):\n        for var in tf.trainable_variables():\n            tf.summary.histogram(var.name, var)\n            print(var.name)", "response": "Print out summaries for every variable. Can be overriden in main function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a string for various input types", "response": "def check_str(obj):\n        \"\"\" Returns a string for various input types \"\"\"\n        if isinstance(obj, str):\n            return obj\n        if isinstance(obj, float):\n            return str(int(obj))\n        else:\n            return str(obj)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef name_in_checkpoint(var):\n        if var.op.name.startswith('model/'):\n            return var.op.name[len('model/'):]", "response": "Removes model scoping if it is present in checkpoint."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _merge_a_into_b(self, a, b):\n        from easydict import EasyDict as edict\n        if type(a) is not edict:\n            return\n\n        for k, v in a.items():\n            # a must specify keys that are in b\n            if k not in b:\n                raise KeyError('{} is not a valid config key'.format(k))\n\n            # the types must match, too\n            old_type = type(b[k])\n            if old_type is not type(v):\n                if isinstance(b[k], np.ndarray):\n                    v = np.array(v, dtype=b[k].dtype)\n                else:\n                    raise ValueError(('Type mismatch ({} vs. {}) '\n                                      'for config key: {}').format(type(b[k]),\n                                                                   type(v), k))\n\n            # recursively merge dicts\n            if type(v) is edict:\n                try:\n                    self._merge_a_into_b(a[k], b[k])\n                except:\n                    print('Error under config key: {}'.format(k))\n                    raise\n            else:\n                b[k] = v\n        return b", "response": "Merge config dictionary a into config dictionary b clobbering the\n        options in b whenever they are also specified in a."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _merge_a_into_b_simple(self, a, b):\n        for k, v in a.items():\n            b[k] = v\n        return b", "response": "Merge config dictionary a into config dictionary b."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload a config file and merge it into the default options.", "response": "def cfg_from_file(self, yaml_filename, config_dict):\n        \"\"\"Load a config file and merge it into the default options.\"\"\"\n        import yaml\n        from easydict import EasyDict as edict\n        with open(yaml_filename, 'r') as f:\n            yaml_cfg = edict(yaml.load(f))\n\n        return self._merge_a_into_b(yaml_cfg, config_dict)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef conv2d(self, filter_size, output_channels, stride=1, padding='SAME', bn=True, activation_fn=tf.nn.relu,\n               b_value=0.0, s_value=1.0, trainable=True):\n        \"\"\"\n        2D Convolutional Layer.\n        :param filter_size: int. assumes square filter\n        :param output_channels: int\n        :param stride: int\n        :param padding: 'VALID' or 'SAME'\n        :param activation_fn: tf.nn function\n        :param b_value: float\n        :param s_value: float\n        \"\"\"\n        self.count['conv'] += 1\n        scope = 'conv_' + str(self.count['conv'])\n        with tf.variable_scope(scope):\n\n            # Conv function\n            input_channels = self.input.get_shape()[3]\n            if filter_size == 0:  # outputs a 1x1 feature map; used for FCN\n                filter_size = self.input.get_shape()[2]\n                padding = 'VALID'\n            output_shape = [filter_size, filter_size, input_channels, output_channels]\n            w = self.weight_variable(name='weights', shape=output_shape, trainable=trainable)\n            self.input = tf.nn.conv2d(self.input, w, strides=[1, stride, stride, 1], padding=padding)\n\n            if bn is True:  # batch normalization\n                self.input = self.batch_norm(self.input)\n            if b_value is not None:  # bias value\n                b = self.const_variable(name='bias', shape=[output_channels], value=b_value, trainable=trainable)\n                self.input = tf.add(self.input, b)\n            if s_value is not None:  # scale value\n                s = self.const_variable(name='scale', shape=[output_channels], value=s_value, trainable=trainable)\n                self.input = tf.multiply(self.input, s)\n            if activation_fn is not None:  # activation function\n                self.input = activation_fn(self.input)\n        print(scope + ' output: ' + str(self.input.get_shape()))", "response": "2D Convolutional Layer.\n        :param filter_size: int. assumes square filter\n        :param output_channels: int\n        :param stride: int\n        :param padding: 'VALID' or 'SAME'\n        :param activation_fn: tf.nn function\n        :param b_value: float\n        :param s_value: float"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef deconv2d(self, filter_size, output_channels, stride=1, padding='SAME', activation_fn=tf.nn.relu, b_value=0.0,\n                 s_value=1.0, bn=True, trainable=True):\n        \"\"\"\n        2D Deconvolutional Layer\n        :param filter_size: int. assumes square filter\n        :param output_channels: int\n        :param stride: int\n        :param padding: 'VALID' or 'SAME'\n        :param activation_fn: tf.nn function\n        :param b_value: float\n        :param s_value: float\n        \"\"\"\n        self.count['deconv'] += 1\n        scope = 'deconv_' + str(self.count['deconv'])\n        with tf.variable_scope(scope):\n\n            # Calculate the dimensions for deconv function\n            batch_size = tf.shape(self.input)[0]\n            input_height = tf.shape(self.input)[1]\n            input_width = tf.shape(self.input)[2]\n\n            if padding == \"VALID\":\n                out_rows = (input_height - 1) * stride + filter_size\n                out_cols = (input_width - 1) * stride + filter_size\n            else:  # padding == \"SAME\":\n                out_rows = input_height * stride\n                out_cols = input_width * stride\n\n            # Deconv function\n            input_channels = self.input.get_shape()[3]\n            output_shape = [filter_size, filter_size, output_channels, input_channels]\n            w = self.weight_variable(name='weights', shape=output_shape, trainable=trainable)\n            deconv_out_shape = tf.stack([batch_size, out_rows, out_cols, output_channels])\n            self.input = tf.nn.conv2d_transpose(self.input, w, deconv_out_shape, [1, stride, stride, 1], padding)\n\n            if bn is True:  # batch normalization\n                self.input = self.batch_norm(self.input)\n            if b_value is not None:  # bias value\n                b = self.const_variable(name='bias', shape=[output_channels], value=b_value, trainable=trainable)\n                self.input = tf.add(self.input, b)\n            if s_value is not None:  # scale value\n                s = self.const_variable(name='scale', shape=[output_channels], value=s_value, trainable=trainable)\n                self.input = tf.multiply(self.input, s)\n            if activation_fn is not None:  # non-linear activation function\n                self.input = activation_fn(self.input)\n        print(scope + ' output: ' + str(self.input.get_shape()))", "response": "2D Deconvolutional Layer\n        :param filter_size: int. assumes square filter\n        :param output_channels: int\n        :param stride: int\n        :param padding: 'VALID' or 'SAME'\n        :param activation_fn: tf.nn function\n        :param b_value: float\n        :param s_value: float"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nflatten 4D Tensor into 2D Tensor.", "response": "def flatten(self, keep_prob=1):\n        \"\"\"\n        Flattens 4D Tensor (from Conv Layer) into 2D Tensor (to FC Layer)\n        :param keep_prob: int. set to 1 for no dropout\n        \"\"\"\n        self.count['flat'] += 1\n        scope = 'flat_' + str(self.count['flat'])\n        with tf.variable_scope(scope):\n            # Reshape function\n            input_nodes = tf.Dimension(\n                self.input.get_shape()[1] * self.input.get_shape()[2] * self.input.get_shape()[3])\n            output_shape = tf.stack([-1, input_nodes])\n            self.input = tf.reshape(self.input, output_shape)\n\n            # Dropout function\n            if keep_prob != 1:\n                self.input = tf.nn.dropout(self.input, keep_prob=keep_prob)\n        print(scope + ' output: ' + str(self.input.get_shape()))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fc(self, output_nodes, keep_prob=1, activation_fn=tf.nn.relu, b_value=0.0, s_value=1.0, bn=True,\n           trainable=True):\n        \"\"\"\n        Fully Connected Layer\n        :param output_nodes: int\n        :param keep_prob: int. set to 1 for no dropout\n        :param activation_fn: tf.nn function\n        :param b_value: float or None\n        :param s_value: float or None\n        :param bn: bool\n        \"\"\"\n        self.count['fc'] += 1\n        scope = 'fc_' + str(self.count['fc'])\n        with tf.variable_scope(scope):\n\n            # Flatten if necessary\n            if len(self.input.get_shape()) == 4:\n                input_nodes = tf.Dimension(\n                    self.input.get_shape()[1] * self.input.get_shape()[2] * self.input.get_shape()[3])\n                output_shape = tf.stack([-1, input_nodes])\n                self.input = tf.reshape(self.input, output_shape)\n\n            # Matrix Multiplication Function\n            input_nodes = self.input.get_shape()[1]\n            output_shape = [input_nodes, output_nodes]\n            w = self.weight_variable(name='weights', shape=output_shape, trainable=trainable)\n            self.input = tf.matmul(self.input, w)\n\n            if bn is True:  # batch normalization\n                self.input = self.batch_norm(self.input, 'fc')\n            if b_value is not None:  # bias value\n                b = self.const_variable(name='bias', shape=[output_nodes], value=b_value, trainable=trainable)\n                self.input = tf.add(self.input, b)\n            if s_value is not None:  # scale value\n                s = self.const_variable(name='scale', shape=[output_nodes], value=s_value, trainable=trainable)\n                self.input = tf.multiply(self.input, s)\n            if activation_fn is not None:  # activation function\n                self.input = activation_fn(self.input)\n            if keep_prob != 1:  # dropout function\n                self.input = tf.nn.dropout(self.input, keep_prob=keep_prob)\n        print(scope + ' output: ' + str(self.input.get_shape()))", "response": "Function to compute the full connected layer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntake max value over a k x k area in each input map or over the entire map.", "response": "def maxpool(self, k=2, s=None, globe=False):\n        \"\"\"\n        Takes max value over a k x k area in each input map, or over the entire map (global = True)\n        :param k: int\n        :param globe:  int, whether to pool over each feature map in its entirety\n        \"\"\"\n        self.count['mp'] += 1\n        scope = 'maxpool_' + str(self.count['mp'])\n        with tf.variable_scope(scope):\n            if globe is True:  # Global Pool Parameters\n                k1 = self.input.get_shape()[1]\n                k2 = self.input.get_shape()[2]\n                s1 = 1\n                s2 = 1\n                padding = 'VALID'\n            else:\n                k1 = k\n                k2 = k\n                if s is None:\n                    s1 = k\n                    s2 = k\n                else:\n                    s1 = s\n                    s2 = s\n                padding = 'SAME'\n            # Max Pool Function\n            self.input = tf.nn.max_pool(self.input, ksize=[1, k1, k2, 1], strides=[1, s1, s2, 1], padding=padding)\n        print(scope + ' output: ' + str(self.input.get_shape()))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef res_layer(self, output_channels, filter_size=3, stride=1, activation_fn=tf.nn.relu, bottle=False,\n                  trainable=True):\n        \"\"\"\n        Residual Layer: Input -> BN, Act_fn, Conv1, BN, Act_fn, Conv 2 -> Output.  Return: Input + Output\n        If stride > 1 or number of filters changes, decrease dims of Input by passing through a 1 x 1 Conv Layer\n        The bottle option changes the Residual layer blocks to the bottleneck structure\n        :param output_channels: int\n        :param filter_size: int. assumes square filter\n        :param stride: int\n        :param activation_fn: tf.nn function\n        :param bottle: boolean\n        \"\"\"\n        self.count['rn'] += 1\n        scope = 'resnet_' + str(self.count['rn'])\n        input_channels = self.input.get_shape()[3]\n        with tf.variable_scope(scope):\n\n            # Determine Additive Output if dimensions change\n            # Decrease Input dimension with 1 x 1 Conv Layer with stride > 1\n            if (stride != 1) or (input_channels != output_channels):\n                with tf.variable_scope('conv0'):\n                    output_shape = [1, 1, input_channels, output_channels]\n                    w = self.weight_variable(name='weights', shape=output_shape, trainable=trainable)\n                    additive_output = tf.nn.conv2d(self.input, w, strides=[1, stride, stride, 1], padding='SAME')\n                    b = self.const_variable(name='bias', shape=[output_channels], value=0.0)\n                    additive_output = tf.add(additive_output, b)\n            else:\n                additive_output = self.input\n\n            # First Conv Layer. Implement stride in this layer if desired.\n            with tf.variable_scope('conv1'):\n                fs = 1 if bottle else filter_size\n                oc = output_channels // 4 if bottle else output_channels\n                output_shape = [fs, fs, input_channels, oc]\n                w = self.weight_variable(name='weights', shape=output_shape, trainable=trainable)\n                self.input = self.batch_norm(self.input)\n                self.input = activation_fn(self.input)\n                self.input = tf.nn.conv2d(self.input, w, strides=[1, stride, stride, 1], padding='SAME')\n                b = self.const_variable(name='bias', shape=[oc], value=0.0)\n                self.input = tf.add(self.input, b)\n            # Second Conv Layer\n            with tf.variable_scope('conv2'):\n                input_channels = self.input.get_shape()[3]\n                oc = output_channels // 4 if bottle else output_channels\n                output_shape = [filter_size, filter_size, input_channels, oc]\n                w = self.weight_variable(name='weights', shape=output_shape, trainable=trainable)\n                self.input = self.batch_norm(self.input)\n                self.input = activation_fn(self.input)\n                self.input = tf.nn.conv2d(self.input, w, strides=[1, 1, 1, 1], padding='SAME')\n                b = self.const_variable(name='bias', shape=[oc], value=0.0)\n                self.input = tf.add(self.input, b)\n            if bottle:\n                # Third Conv Layer\n                with tf.variable_scope('conv3'):\n                    input_channels = self.input.get_shape()[3]\n                    output_shape = [1, 1, input_channels, output_channels]\n                    w = self.weight_variable(name='weights', shape=output_shape, trainable=trainable)\n                    self.input = self.batch_norm(self.input)\n                    self.input = activation_fn(self.input)\n                    self.input = tf.nn.conv2d(self.input, w, strides=[1, 1, 1, 1], padding='SAME')\n                    b = self.const_variable(name='bias', shape=[output_channels], value=0.0)\n                    self.input = tf.add(self.input, b)\n\n            # Add input and output for final return\n            self.input = self.input + additive_output\n        print(scope + ' output: ' + str(self.input.get_shape()))", "response": "Residual Layer: Input -> BN, Act_fn, Conv1, BN, Act_fn, Conv 2 -> Output.  Return: Input + Output\n        If stride > 1 or number of filters changes, decrease dims of Input by passing through a 1 x 1 Conv Layer\n        The bottle option changes the Residual layer blocks to the bottleneck structure\n        :param output_channels: int\n        :param filter_size: int. assumes square filter\n        :param stride: int\n        :param activation_fn: tf.nn function\n        :param bottle: boolean"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef noisy_and(self, num_classes, trainable=True):\n        assert self.input.get_shape()[3] == num_classes  # input tensor should have map depth equal to # of classes\n        scope = 'noisyAND'\n        with tf.variable_scope(scope):\n            a = self.const_variable(name='a', shape=[1], value=1.0, trainable=trainable)\n            b = self.const_variable(name='b', shape=[1, num_classes], value=0.0, trainable=trainable)\n            mean = tf.reduce_mean(self.input, axis=[1, 2])\n            self.input = (tf.nn.sigmoid(a * (mean - b)) - tf.nn.sigmoid(-a * b)) / (\n                tf.sigmoid(a * (1 - b)) - tf.sigmoid(-a * b))\n        print(scope + ' output: ' + str(self.input.get_shape()))", "response": "Multiple Instance Learning ( MIL ) flexible pooling function."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbatch Normalization of the feature map stack.", "response": "def batch_norm(self, x, type='conv', epsilon=1e-3):\n        \"\"\"\n        Batch Normalization: Apply mean subtraction and variance scaling\n        :param x: input feature map stack\n        :param type: string, either 'conv' or 'fc'\n        :param epsilon: float\n        :return: output feature map stack\n        \"\"\"\n        # Determine indices over which to calculate moments, based on layer type\n        if type == 'conv':\n            size = [0, 1, 2]\n        else:  # type == 'fc'\n            size = [0]\n\n        # Calculate batch mean and variance\n        batch_mean1, batch_var1 = tf.nn.moments(x, size, keep_dims=True)\n\n        # Apply the initial batch normalizing transform\n        z1_hat = (x - batch_mean1) / tf.sqrt(batch_var1 + epsilon)\n        return z1_hat"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef weight_variable(name, shape, trainable):\n        w = tf.get_variable(name=name, shape=shape, initializer=tf.contrib.layers.variance_scaling_initializer(),\n                            trainable=trainable)\n        weights_norm = tf.reduce_sum(tf.nn.l2_loss(w),\n                                     name=name + '_norm')  # Should user want to optimize weight decay\n        tf.add_to_collection('weight_losses', weights_norm)\n        return w", "response": "Returns a weight variable for the current cluster."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a constant variable.", "response": "def const_variable(name, shape, value, trainable):\n        \"\"\"\n        :param name: string\n        :param shape: 1D array\n        :param value: float\n        :return: tf variable\n        \"\"\"\n        return tf.get_variable(name, shape, initializer=tf.constant_initializer(value), trainable=trainable)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfunctioning compresses data and returns the generated ASN. 1 ASN. 1 byte string.", "response": "def compress_message(data_to_compress):\n    \"\"\"Function compresses data and returns the generated ASN.1\n    \n    :param data_to_compress: A byte string of the data to be compressed\n    \n    :return: A CMS ASN.1 byte string of the compressed data.    \n    \"\"\"\n    compressed_content = cms.ParsableOctetString(\n        zlib.compress(data_to_compress))\n    return cms.ContentInfo({\n        'content_type': cms.ContentType('compressed_data'),\n        'content': cms.CompressedData({\n            'version': cms.CMSVersion('v0'),\n            'compression_algorithm':\n                cms.CompressionAlgorithm({\n                    'algorithm': cms.CompressionAlgorithmId('zlib')\n                }),\n            'encap_content_info': cms.EncapsulatedContentInfo({\n                'content_type': cms.ContentType('data'),\n                'content': compressed_content\n            })\n        })\n    }).dump()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef decompress_message(compressed_data):\n    try:\n        cms_content = cms.ContentInfo.load(compressed_data)\n        if cms_content['content_type'].native == 'compressed_data':\n            return cms_content['content'].decompressed\n        else:\n            raise DecompressionError('Compressed data not found in ASN.1 ')\n\n    except Exception as e:\n        raise DecompressionError(\n            'Decompression failed with cause: {}'.format(e))", "response": "Function parses an ASN. 1 compressed message and extracts/decompresses \n    the original message."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef encrypt_message(data_to_encrypt, enc_alg, encryption_cert):\n\n    enc_alg_list = enc_alg.split('_')\n    cipher, key_length, mode = enc_alg_list[0], enc_alg_list[1], enc_alg_list[2]\n    enc_alg_asn1, key, encrypted_content = None, None, None\n\n    # Generate the symmetric encryption key and encrypt the message\n    if cipher == 'tripledes':\n        key = util.rand_bytes(int(key_length)//8)\n        iv, encrypted_content = symmetric.tripledes_cbc_pkcs5_encrypt(\n            key, data_to_encrypt, None)\n        enc_alg_asn1 = algos.EncryptionAlgorithm({\n            'algorithm': algos.EncryptionAlgorithmId('tripledes_3key'),\n            'parameters': cms.OctetString(iv)\n        })\n\n    # Encrypt the key and build the ASN.1 message\n    encrypted_key = asymmetric.rsa_pkcs1v15_encrypt(encryption_cert, key)\n\n    return cms.ContentInfo({\n        'content_type': cms.ContentType('enveloped_data'),\n        'content': cms.EnvelopedData({\n            'version': cms.CMSVersion('v0'),\n            'recipient_infos': [\n                cms.KeyTransRecipientInfo({\n                    'version': cms.CMSVersion('v0'),\n                    'rid': cms.RecipientIdentifier({\n                        'issuer_and_serial_number': cms.IssuerAndSerialNumber({\n                            'issuer': encryption_cert.asn1[\n                                'tbs_certificate']['issuer'],\n                            'serial_number': encryption_cert.asn1[\n                                'tbs_certificate']['serial_number']\n                        })\n                    }),\n                    'key_encryption_algorithm': cms.KeyEncryptionAlgorithm({\n                        'algorithm': cms.KeyEncryptionAlgorithmId('rsa')\n                    }),\n                    'encrypted_key': cms.OctetString(encrypted_key)\n                })\n            ],\n            'encrypted_content_info': cms.EncryptedContentInfo({\n                'content_type': cms.ContentType('data'),\n                'content_encryption_algorithm': enc_alg_asn1,\n                'encrypted_content': encrypted_content\n            })\n        })\n    }).dump()", "response": "Function encrypts data and returns the generated ASN. 1 message."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfunction parses an ASN. 1 encrypted message and extracts the decrypted message.", "response": "def decrypt_message(encrypted_data, decryption_key):\n    \"\"\"Function parses an ASN.1 encrypted message and extracts/decrypts \n        the original message.\n\n    :param encrypted_data: A CMS ASN.1 byte string containing the encrypted \n    data.\n    \n    :param decryption_key: The key to be used for decrypting the data.\n\n    :return: A byte string containing the decrypted original message.    \n    \"\"\"\n\n    cms_content = cms.ContentInfo.load(encrypted_data)\n    cipher, decrypted_content = None, None\n\n    if cms_content['content_type'].native == 'enveloped_data':\n        recipient_info = cms_content['content']['recipient_infos'][0].parse()\n        key_enc_alg = recipient_info[\n            'key_encryption_algorithm']['algorithm'].native\n        encrypted_key = recipient_info['encrypted_key'].native\n\n        if key_enc_alg == 'rsa':\n            try:\n                key = asymmetric.rsa_pkcs1v15_decrypt(\n                    decryption_key[0], encrypted_key)\n            except Exception as e:\n                raise DecryptionError('Failed to decrypt the payload: '\n                                      'Could not extract decryption key.')\n            alg = cms_content['content']['encrypted_content_info'][\n                'content_encryption_algorithm']\n\n            encapsulated_data = cms_content['content'][\n                'encrypted_content_info']['encrypted_content'].native\n\n            try:\n                if alg.encryption_cipher == 'tripledes':\n                    cipher = 'tripledes_192_cbc'\n                    decrypted_content = symmetric.tripledes_cbc_pkcs5_decrypt(\n                        key, encapsulated_data, alg.encryption_iv)\n                else:\n                    raise AS2Exception('Unsupported Encryption Algorithm')\n            except Exception as e:\n                raise DecryptionError(\n                    'Failed to decrypt the payload: {}'.format(e))\n\n    return cipher, decrypted_content"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfunctions signs the data and returns the ASN. 1 byte string of the signed data.", "response": "def sign_message(data_to_sign, digest_alg, sign_key,\n                 use_signed_attributes=True):\n    \"\"\"Function signs the data and returns the generated ASN.1\n\n    :param data_to_sign: A byte string of the data to be signed.\n\n    :param digest_alg: \n        The digest algorithm to be used for generating the signature.\n\n    :param sign_key: The key to be used for generating the signature.\n    \n    :param use_signed_attributes: Optional attribute to indicate weather the \n    CMS signature attributes should be included in the signature or not.\n\n    :return: A CMS ASN.1 byte string of the signed data.    \n    \"\"\"\n\n    if use_signed_attributes:\n        digest_func = hashlib.new(digest_alg)\n        digest_func.update(data_to_sign)\n        message_digest = digest_func.digest()\n\n        class SmimeCapability(core.Sequence):\n            _fields = [\n                ('0', core.Any, {'optional': True}),\n                ('1', core.Any, {'optional': True}),\n                ('2', core.Any, {'optional': True}),\n                ('3', core.Any, {'optional': True}),\n                ('4', core.Any, {'optional': True})\n            ]\n\n        class SmimeCapabilities(core.Sequence):\n            _fields = [\n                ('0', SmimeCapability),\n                ('1', SmimeCapability, {'optional': True}),\n                ('2', SmimeCapability, {'optional': True}),\n                ('3', SmimeCapability, {'optional': True}),\n                ('4', SmimeCapability, {'optional': True}),\n                ('5', SmimeCapability, {'optional': True}),\n            ]\n\n        smime_cap = OrderedDict([\n            ('0', OrderedDict([\n                ('0', core.ObjectIdentifier('1.2.840.113549.3.7'))])),\n            ('1', OrderedDict([\n                ('0', core.ObjectIdentifier('1.2.840.113549.3.2')),\n                ('1', core.Integer(128))])),\n            ('2', OrderedDict([\n                ('0', core.ObjectIdentifier('1.2.840.113549.3.4')),\n                ('1', core.Integer(128))])),\n        ])\n\n        signed_attributes = cms.CMSAttributes([\n            cms.CMSAttribute({\n                'type': cms.CMSAttributeType('content_type'),\n                'values': cms.SetOfContentType([\n                    cms.ContentType('data')\n                ])\n            }),\n            cms.CMSAttribute({\n                'type': cms.CMSAttributeType('signing_time'),\n                'values': cms.SetOfTime([\n                    cms.Time({\n                        'utc_time': core.UTCTime(datetime.now())\n                    })\n                ])\n            }),\n            cms.CMSAttribute({\n                'type': cms.CMSAttributeType('message_digest'),\n                'values': cms.SetOfOctetString([\n                    core.OctetString(message_digest)\n                ])\n            }),\n            cms.CMSAttribute({\n                'type': cms.CMSAttributeType('1.2.840.113549.1.9.15'),\n                'values': cms.SetOfAny([\n                    core.Any(SmimeCapabilities(smime_cap))\n                ])\n            }),\n        ])\n        signature = asymmetric.rsa_pkcs1v15_sign(\n            sign_key[0], signed_attributes.dump(), digest_alg)\n    else:\n        signed_attributes = None\n        signature = asymmetric.rsa_pkcs1v15_sign(\n            sign_key[0], data_to_sign, digest_alg)\n\n    return cms.ContentInfo({\n        'content_type': cms.ContentType('signed_data'),\n        'content': cms.SignedData({\n            'version': cms.CMSVersion('v1'),\n            'digest_algorithms': cms.DigestAlgorithms([\n                algos.DigestAlgorithm({\n                    'algorithm': algos.DigestAlgorithmId(digest_alg)\n                })\n            ]),\n            'encap_content_info': cms.ContentInfo({\n                'content_type': cms.ContentType('data')\n            }),\n            'certificates': cms.CertificateSet([\n                cms.CertificateChoices({\n                    'certificate': sign_key[1].asn1\n                })\n            ]),\n            'signer_infos': cms.SignerInfos([\n                cms.SignerInfo({\n                    'version': cms.CMSVersion('v1'),\n                    'sid': cms.SignerIdentifier({\n                        'issuer_and_serial_number': cms.IssuerAndSerialNumber({\n                            'issuer': sign_key[1].asn1[\n                                'tbs_certificate']['issuer'],\n                            'serial_number': sign_key[1].asn1[\n                                'tbs_certificate']['serial_number']\n                        })\n                    }),\n                    'digest_algorithm': algos.DigestAlgorithm({\n                        'algorithm': algos.DigestAlgorithmId(digest_alg)\n                    }),\n                    'signed_attrs': signed_attributes,\n                    'signature_algorithm': algos.SignedDigestAlgorithm({\n                        'algorithm':\n                            algos.SignedDigestAlgorithmId('rsassa_pkcs1v15')\n                    }),\n                    'signature': core.OctetString(signature)\n                })\n            ])\n        })\n    }).dump()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfunctions parses an ASN. 1 encrypted message and extracts the decrypted message.", "response": "def verify_message(data_to_verify, signature, verify_cert):\n    \"\"\"Function parses an ASN.1 encrypted message and extracts/decrypts \n            the original message.\n\n    :param data_to_verify: \n        A byte string of the data to be verified against the signature. \n\n    :param signature: A CMS ASN.1 byte string containing the signature.\n    \n    :param verify_cert: The certificate to be used for verifying the signature.\n\n    :return: The digest algorithm that was used in the signature.    \n    \"\"\"\n\n    cms_content = cms.ContentInfo.load(signature)\n    digest_alg = None\n\n    if cms_content['content_type'].native == 'signed_data':\n        for signer in cms_content['content']['signer_infos']:\n\n            signed_attributes = signer['signed_attrs'].copy()\n            digest_alg = signer['digest_algorithm']['algorithm'].native\n\n            if digest_alg not in DIGEST_ALGORITHMS:\n                raise Exception('Unsupported Digest Algorithm')\n\n            sig_alg = signer['signature_algorithm']['algorithm'].native\n            sig = signer['signature'].native\n            signed_data = data_to_verify\n\n            if signed_attributes:\n                attr_dict = {}\n                for attr in signed_attributes.native:\n                    attr_dict[attr['type']] = attr['values']\n\n                message_digest = byte_cls()\n                for d in attr_dict['message_digest']:\n                    message_digest += d\n\n                digest_func = hashlib.new(digest_alg)\n                digest_func.update(data_to_verify)\n                calc_message_digest = digest_func.digest()\n\n                if message_digest != calc_message_digest:\n                    raise IntegrityError('Failed to verify message signature: '\n                                         'Message Digest does not match.')\n\n                signed_data = signed_attributes.untag().dump()\n\n            try:\n                if sig_alg == 'rsassa_pkcs1v15':\n                    asymmetric.rsa_pkcs1v15_verify(\n                        verify_cert, sig, signed_data, digest_alg)\n                elif sig_alg == 'rsassa_pss':\n                    asymmetric.rsa_pss_verify(\n                        verify_cert, sig, signed_data, digest_alg)\n                else:\n                    raise AS2Exception('Unsupported Signature Algorithm')\n            except Exception as e:\n                raise IntegrityError(\n                    'Failed to verify message signature: {}'.format(e))\n\n    return digest_alg"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_key(key_str, key_pass):\n\n        try:\n            # First try to parse as a p12 file\n            key, cert, _ = asymmetric.load_pkcs12(key_str, key_pass)\n        except ValueError as e:\n            # If it fails due to invalid password raise error here\n            if e.args[0] == 'Password provided is invalid':\n                raise AS2Exception('Password not valid for Private Key.')\n\n            # if not try to parse as a pem file\n            key, cert = None, None\n            for kc in split_pem(key_str):\n                try:\n                    cert = asymmetric.load_certificate(kc)\n                except (ValueError, TypeError):\n                    try:\n                        key = asymmetric.load_private_key(kc, key_pass)\n                    except OSError:\n                        raise AS2Exception(\n                            'Invalid Private Key or password is not correct.')\n\n        if not key or not cert:\n            raise AS2Exception(\n                'Invalid Private key file or Public key not included.')\n\n        return key, cert", "response": "Function to load private key in p12 or pem format"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfunction returns the body of the as2 payload as a bytes object", "response": "def content(self):\n        \"\"\"Function returns the body of the as2 payload as a bytes object\"\"\"\n\n        if not self.payload:\n            return ''\n\n        if self.payload.is_multipart():\n            message_bytes = mime_to_bytes(\n                self.payload, 0).replace(b'\\n', b'\\r\\n')\n            boundary = b'--' + self.payload.get_boundary().encode('utf-8')\n            temp = message_bytes.split(boundary)\n            temp.pop(0)\n            return boundary + boundary.join(temp)\n        else:\n            content = self.payload.get_payload()\n            if isinstance(content, str_cls):\n                content = content.encode('utf-8')\n            return content"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfunctions builds the AS2 message.", "response": "def build(self, data, filename=None, subject='AS2 Message',\n              content_type='application/edi-consent', additional_headers=None):\n\n        \"\"\"Function builds the AS2 message. Compresses, signs and encrypts\n        the payload if applicable.\n\n        :param data: A byte string of the data to be transmitted.\n\n        :param filename:\n            Optional filename to be included in the Content-disposition header.\n\n        :param subject:\n            The subject for the AS2 message, used by some AS2 servers for\n            additional routing of messages. (default \"AS2 Message\")\n\n        :param content_type:\n            The content type for the AS2 message, to be used in the MIME\n            header. (default \"application/edi-consent\")\n\n        :param additional_headers:\n            Any additional headers to be included as part of the AS2 message.\n\n        \"\"\"\n\n        # Validations\n        assert type(data) is byte_cls, \\\n            'Parameter data must be of type {}'.format(byte_cls)\n\n        additional_headers = additional_headers if additional_headers else {}\n        assert type(additional_headers) is dict\n\n        if self.receiver.sign and not self.sender.sign_key:\n            raise ImproperlyConfigured(\n                'Signing of messages is enabled but sign key is not set '\n                'for the sender.')\n\n        if self.receiver.encrypt and not self.receiver.encrypt_cert:\n            raise ImproperlyConfigured(\n                'Encryption of messages is enabled but encrypt key is not set '\n                'for the receiver.')\n\n        # Generate message id using UUID 1 as it uses both hostname and time\n        self.message_id = email_utils.make_msgid().lstrip('<').rstrip('>')\n\n        # Set up the message headers\n        as2_headers = {\n            'AS2-Version': AS2_VERSION,\n            'ediint-features': EDIINT_FEATURES,\n            'Message-ID': '<{}>'.format(self.message_id),\n            'AS2-From': quote_as2name(self.sender.as2_name),\n            'AS2-To': quote_as2name(self.receiver.as2_name),\n            'Subject': subject,\n            'Date': email_utils.formatdate(localtime=True),\n            # 'recipient-address': message.partner.target_url,\n        }\n        as2_headers.update(additional_headers)\n\n        # Read the input and convert to bytes if value is unicode/str\n        # using utf-8 encoding and finally Canonicalize the payload\n        self.payload = email_message.Message()\n        self.payload.set_payload(data)\n        self.payload.set_type(content_type)\n        encoders.encode_7or8bit(self.payload)\n\n        if filename:\n            self.payload.add_header(\n                'Content-Disposition', 'attachment', filename=filename)\n        del self.payload['MIME-Version']\n\n        if self.receiver.compress:\n            self.compressed = True\n            compressed_message = email_message.Message()\n            compressed_message.set_type('application/pkcs7-mime')\n            compressed_message.set_param('name', 'smime.p7z')\n            compressed_message.set_param('smime-type', 'compressed-data')\n            compressed_message.add_header(\n                'Content-Disposition', 'attachment', filename='smime.p7z')\n            compressed_message.set_payload(\n                compress_message(canonicalize(self.payload)))\n            encoders.encode_base64(compressed_message)\n            self.payload = compressed_message\n            # logger.debug(b'Compressed message %s payload as:\\n%s' % (\n            #     self.message_id, self.payload.as_string()))\n\n        if self.receiver.sign:\n            self.signed, self.digest_alg = True, self.receiver.digest_alg\n            signed_message = MIMEMultipart(\n                'signed', protocol=\"application/pkcs7-signature\")\n            del signed_message['MIME-Version']\n            signed_message.attach(self.payload)\n\n            # Calculate the MIC Hash of the message to be verified\n            mic_content = canonicalize(self.payload)\n            digest_func = hashlib.new(self.digest_alg)\n            digest_func.update(mic_content)\n            self.mic = binascii.b2a_base64(digest_func.digest()).strip()\n\n            # Create the signature mime message\n            signature = email_message.Message()\n            signature.set_type('application/pkcs7-signature')\n            signature.set_param('name', 'smime.p7s')\n            signature.set_param('smime-type', 'signed-data')\n            signature.add_header(\n                'Content-Disposition', 'attachment', filename='smime.p7s')\n            del signature['MIME-Version']\n            signature.set_payload(sign_message(\n                mic_content, self.digest_alg, self.sender.sign_key))\n            encoders.encode_base64(signature)\n            signed_message.set_param('micalg', self.digest_alg)\n            signed_message.attach(signature)\n            self.payload = signed_message\n\n            # logger.debug(b'Signed message %s payload as:\\n%s' % (\n            #    self.message_id, self.payload.as_string()))\n\n        if self.receiver.encrypt:\n            self.encrypted, self.enc_alg = True, self.receiver.enc_alg\n            encrypted_message = email_message.Message()\n            encrypted_message.set_type('application/pkcs7-mime')\n            encrypted_message.set_param('name', 'smime.p7m')\n            encrypted_message.set_param('smime-type', 'enveloped-data')\n            encrypted_message.add_header(\n                'Content-Disposition', 'attachment', filename='smime.p7m')\n            encrypt_cert = self.receiver.load_encrypt_cert()\n            encrypted_message.set_payload(encrypt_message(\n                canonicalize(self.payload),\n                self.enc_alg,\n                encrypt_cert\n            ))\n            encoders.encode_base64(encrypted_message)\n            self.payload = encrypted_message\n            # logger.debug(b'Encrypted message %s payload as:\\n%s' % (\n            #     self.message_id, self.payload.as_string()))\n\n        if self.receiver.mdn_mode:\n            as2_headers['disposition-notification-to'] = 'no-reply@pyas2.com'\n            if self.receiver.mdn_digest_alg:\n                as2_headers['disposition-notification-options'] = \\\n                    'signed-receipt-protocol=required, pkcs7-signature; ' \\\n                    'signed-receipt-micalg=optional, {}'.format(\n                        self.receiver.mdn_digest_alg)\n            if self.receiver.mdn_mode == 'ASYNC':\n                if not self.sender.mdn_url:\n                    raise ImproperlyConfigured(\n                        'MDN URL must be set in the organization when MDN mode '\n                        'is set to ASYNC')\n                as2_headers['receipt-delivery-option'] = self.sender.mdn_url\n\n        # Update the headers of the final payload and set its boundary\n        for k, v in as2_headers.items():\n            if self.payload.get(k):\n                self.payload.replace_header(k, v)\n            else:\n                self.payload.add_header(k, v)\n\n        if self.payload.is_multipart():\n            self.payload.set_boundary(make_mime_boundary())"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse(self, raw_content, find_org_cb, find_partner_cb,\n              find_message_cb=None):\n        \"\"\"Function parses the RAW AS2 message; decrypts, verifies and\n        decompresses it and extracts the payload.\n\n        :param raw_content:\n            A byte string of the received HTTP headers followed by the body.\n\n        :param find_org_cb:\n            A callback the returns an Organization object if exists. The\n            as2-to header value is passed as an argument to it.\n\n        :param find_partner_cb:\n            A callback the returns an Partner object if exists. The\n            as2-from header value is passed as an argument to it.\n\n        :param find_message_cb:\n            An optional callback the returns an Message object if exists in\n            order to check for duplicates. The message id and partner id is\n            passed as arguments to it.\n\n        :return:\n            A three element tuple containing (status, (exception, traceback)\n            , mdn). The status is a string indicating the status of the\n            transaction. The exception is populated with any exception raised\n            during processing and the mdn is an MDN object or None in case\n            the partner did not request it.\n        \"\"\"\n\n        # Parse the raw MIME message and extract its content and headers\n        status, detailed_status, exception, mdn = \\\n            'processed', None, (None, None), None\n        self.payload = parse_mime(raw_content)\n        as2_headers = {}\n        for k, v in self.payload.items():\n            k = k.lower()\n            if k == 'message-id':\n                self.message_id = v.lstrip('<').rstrip('>')\n            as2_headers[k] = v\n\n        try:\n            # Get the organization and partner for this transmission\n            org_id = unquote_as2name(as2_headers['as2-to'])\n            self.receiver = find_org_cb(org_id)\n            if not self.receiver:\n                raise PartnerNotFound(\n                    'Unknown AS2 organization with id {}'.format(org_id))\n\n            partner_id = unquote_as2name(as2_headers['as2-from'])\n            self.sender = find_partner_cb(partner_id)\n            if not self.sender:\n                raise PartnerNotFound(\n                    'Unknown AS2 partner with id {}'.format(partner_id))\n\n            if find_message_cb and \\\n                    find_message_cb(self.message_id, partner_id):\n                raise DuplicateDocument(\n                    'Duplicate message received, message with this ID '\n                    'already processed.')\n\n            if self.sender.encrypt and \\\n                    self.payload.get_content_type() != 'application/pkcs7-mime':\n                raise InsufficientSecurityError(\n                    'Incoming messages from partner {} are must be encrypted'\n                    ' but encrypted message not found.'.format(partner_id))\n\n            if self.payload.get_content_type() == 'application/pkcs7-mime' \\\n                    and self.payload.get_param('smime-type') == 'enveloped-data':\n                encrypted_data = self.payload.get_payload(decode=True)\n                # logger.debug(\n                    # 'Decrypting the payload :\\n%s' % self.payload.as_string())\n\n                self.encrypted = True\n                self.enc_alg, decrypted_content = decrypt_message(\n                    encrypted_data,\n                    self.receiver.decrypt_key\n                )\n                raw_content = decrypted_content\n                self.payload = parse_mime(decrypted_content)\n\n                if self.payload.get_content_type() == 'text/plain':\n                    self.payload = email_message.Message()\n                    self.payload.set_payload(decrypted_content)\n                    self.payload.set_type('application/edi-consent')\n\n            # Check for compressed data here\n            self.compressed, self.payload = self.decompress_data(self.payload)\n\n            if self.sender.sign and \\\n                    self.payload.get_content_type() != 'multipart/signed':\n                raise InsufficientSecurityError(\n                    'Incoming messages from partner {} are must be signed '\n                    'but signed message not found.'.format(partner_id))\n\n            if self.payload.get_content_type() == 'multipart/signed':\n                # logger.debug(b'Verifying the signed payload:\\n{0:s}'.format(\n                #     self.payload.as_string()))\n                self.signed = True\n                signature = None\n                message_boundary = (\n                        '--' + self.payload.get_boundary()).encode('utf-8')\n                for part in self.payload.walk():\n                    if part.get_content_type() == \"application/pkcs7-signature\":\n                        signature = part.get_payload(decode=True)\n                    else:\n                        self.payload = part\n\n                # Verify the message, first using raw message and if it fails\n                # then convert to canonical form and try again\n                mic_content = canonicalize(self.payload)\n                verify_cert = self.sender.load_verify_cert()\n                try:\n                    self.digest_alg = verify_message(\n                        mic_content, signature, verify_cert)\n                except IntegrityError:\n                    mic_content = raw_content.split(message_boundary)[\n                        1].replace(b'\\n', b'\\r\\n')\n                    self.digest_alg = verify_message(\n                        mic_content, signature, verify_cert)\n\n                # Calculate the MIC Hash of the message to be verified\n                digest_func = hashlib.new(self.digest_alg)\n                digest_func.update(mic_content)\n                self.mic = binascii.b2a_base64(digest_func.digest()).strip()\n\n            # Check for compressed data here\n            if not self.compressed:\n                self.compressed, self.payload = self.decompress_data(self.payload)\n\n        except Exception as e:\n            status = getattr(e, 'disposition_type', 'processed/Error')\n            detailed_status = getattr(\n                e, 'disposition_modifier', 'unexpected-processing-error')\n            print(traceback.format_exc())\n            exception = (e, traceback.format_exc())\n        finally:\n            # Update the payload headers with the original headers\n            for k, v in as2_headers.items():\n                if self.payload.get(k) and k.lower() != 'content-disposition':\n                    del self.payload[k]\n                self.payload.add_header(k, v)\n\n            if as2_headers.get('disposition-notification-to'):\n                mdn_mode = SYNCHRONOUS_MDN\n\n                mdn_url = as2_headers.get('receipt-delivery-option')\n                if mdn_url:\n                    mdn_mode = ASYNCHRONOUS_MDN\n\n                digest_alg = as2_headers.get('disposition-notification-options')\n                if digest_alg:\n                    digest_alg = digest_alg.split(';')[-1].split(',')[\n                        -1].strip()\n                mdn = Mdn(\n                    mdn_mode=mdn_mode, mdn_url=mdn_url, digest_alg=digest_alg)\n                mdn.build(message=self,\n                          status=status,\n                          detailed_status=detailed_status)\n\n            return status, exception, mdn", "response": "Parses the AS2 message and returns the message object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfunctioning returns the body of the mdn message as a byte string", "response": "def content(self):\n        \"\"\"Function returns the body of the mdn message as a byte string\"\"\"\n\n        if self.payload:\n            message_bytes = mime_to_bytes(\n                self.payload, 0).replace(b'\\n', b'\\r\\n')\n            boundary = b'--' + self.payload.get_boundary().encode('utf-8')\n            temp = message_bytes.split(boundary)\n            temp.pop(0)\n            return boundary + boundary.join(temp)\n        else:\n            return ''"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef build(self, message, status, detailed_status=None):\n\n        # Generate message id using UUID 1 as it uses both hostname and time\n        self.message_id = email_utils.make_msgid().lstrip('<').rstrip('>')\n        self.orig_message_id = message.message_id\n\n        # Set up the message headers\n        mdn_headers = {\n            'AS2-Version': AS2_VERSION,\n            'ediint-features': EDIINT_FEATURES,\n            'Message-ID': '<{}>'.format(self.message_id),\n            'AS2-From': quote_as2name(message.headers.get('as2-to')),\n            'AS2-To': quote_as2name(message.headers.get('as2-from')),\n            'Date': email_utils.formatdate(localtime=True),\n            'user-agent': 'pyAS2 Open Source AS2 Software'\n        }\n\n        # Set the confirmation text message here\n        confirmation_text = MDN_CONFIRM_TEXT\n\n        # overwrite with organization specific message\n        if message.receiver and message.receiver.mdn_confirm_text:\n            confirmation_text = message.receiver.mdn_confirm_text\n\n        # overwrite with partner specific message\n        if message.sender and message.sender.mdn_confirm_text:\n            confirmation_text = message.sender.mdn_confirm_text\n\n        if status != 'processed':\n            confirmation_text = MDN_FAILED_TEXT\n\n        self.payload = MIMEMultipart(\n            'report', report_type='disposition-notification')\n\n        # Create and attach the MDN Text Message\n        mdn_text = email_message.Message()\n        mdn_text.set_payload('%s\\n' % confirmation_text)\n        mdn_text.set_type('text/plain')\n        del mdn_text['MIME-Version']\n        encoders.encode_7or8bit(mdn_text)\n        self.payload.attach(mdn_text)\n\n        # Create and attache the MDN Report Message\n        mdn_base = email_message.Message()\n        mdn_base.set_type('message/disposition-notification')\n        mdn_report = 'Reporting-UA: pyAS2 Open Source AS2 Software\\n'\n        mdn_report += 'Original-Recipient: rfc822; {}\\n'.format(\n            message.headers.get('as2-to'))\n        mdn_report += 'Final-Recipient: rfc822; {}\\n'.format(\n            message.headers.get('as2-to'))\n        mdn_report += 'Original-Message-ID: <{}>\\n'.format(message.message_id)\n        mdn_report += 'Disposition: automatic-action/' \\\n                      'MDN-sent-automatically; {}'.format(status)\n        if detailed_status:\n            mdn_report += ': {}'.format(detailed_status)\n        mdn_report += '\\n'\n        if message.mic:\n            mdn_report += 'Received-content-MIC: {}, {}\\n'.format(\n                message.mic.decode(), message.digest_alg)\n        mdn_base.set_payload(mdn_report)\n        del mdn_base['MIME-Version']\n        encoders.encode_7or8bit(mdn_base)\n        self.payload.attach(mdn_base)\n\n        # logger.debug('MDN for message %s created:\\n%s' % (\n        #     message.message_id, mdn_base.as_string()))\n\n        # Sign the MDN if it is requested by the sender\n        if message.headers.get('disposition-notification-options') and \\\n                message.receiver and message.receiver.sign_key:\n            self.digest_alg = \\\n                message.headers['disposition-notification-options'].split(\n                    ';')[-1].split(',')[-1].strip().replace('-', '')\n            signed_mdn = MIMEMultipart(\n                'signed', protocol=\"application/pkcs7-signature\")\n            del signed_mdn['MIME-Version']\n            signed_mdn.attach(self.payload)\n\n            # Create the signature mime message\n            signature = email_message.Message()\n            signature.set_type('application/pkcs7-signature')\n            signature.set_param('name', 'smime.p7s')\n            signature.set_param('smime-type', 'signed-data')\n            signature.add_header(\n                'Content-Disposition', 'attachment', filename='smime.p7s')\n            del signature['MIME-Version']\n            signature.set_payload(sign_message(\n                canonicalize(self.payload),\n                self.digest_alg,\n                message.receiver.sign_key\n            ))\n            encoders.encode_base64(signature)\n            # logger.debug(\n            #     'Signature for MDN created:\\n%s' % signature.as_string())\n            signed_mdn.set_param('micalg', self.digest_alg)\n            signed_mdn.attach(signature)\n\n            self.payload = signed_mdn\n\n        # Update the headers of the final payload and set message boundary\n        for k, v in mdn_headers.items():\n            if self.payload.get(k):\n                self.payload.replace_header(k, v)\n            else:\n                self.payload.add_header(k, v)\n        if self.payload.is_multipart():\n            self.payload.set_boundary(make_mime_boundary())", "response": "Function builds and signs an AS2 MDN message."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing the RAW AS2 MDN verifies it and extracts the processing status of the original AS2 message.", "response": "def parse(self, raw_content, find_message_cb):\n        \"\"\"Function parses the RAW AS2 MDN, verifies it and extracts the\n        processing status of the orginal AS2 message.\n\n        :param raw_content:\n            A byte string of the received HTTP headers followed by the body.\n\n        :param find_message_cb:\n            A callback the must returns the original Message Object. The\n            original message-id and original recipient AS2 ID are passed\n            as arguments to it.\n\n        :returns:\n            A two element tuple containing (status, detailed_status). The\n            status is a string indicating the status of the transaction. The\n            optional detailed_status gives additional information about the\n            processing status.\n        \"\"\"\n\n        status, detailed_status = None, None\n        self.payload = parse_mime(raw_content)\n        self.orig_message_id, orig_recipient = self.detect_mdn()\n\n        # Call the find message callback which should return a Message instance\n        orig_message = find_message_cb(self.orig_message_id, orig_recipient)\n\n        # Extract the headers and save it\n        mdn_headers = {}\n        for k, v in self.payload.items():\n            k = k.lower()\n            if k == 'message-id':\n                self.message_id = v.lstrip('<').rstrip('>')\n            mdn_headers[k] = v\n\n        if orig_message.receiver.mdn_digest_alg \\\n                and self.payload.get_content_type() != 'multipart/signed':\n            status = 'failed/Failure'\n            detailed_status = 'Expected signed MDN but unsigned MDN returned'\n            return status, detailed_status\n\n        if self.payload.get_content_type() == 'multipart/signed':\n            signature = None\n            message_boundary = (\n                    '--' + self.payload.get_boundary()).encode('utf-8')\n            for part in self.payload.walk():\n                if part.get_content_type() == 'application/pkcs7-signature':\n                    signature = part.get_payload(decode=True)\n                elif part.get_content_type() == 'multipart/report':\n                    self.payload = part\n\n            # Verify the message, first using raw message and if it fails\n            # then convert to canonical form and try again\n            mic_content = extract_first_part(raw_content, message_boundary)\n            verify_cert = orig_message.receiver.load_verify_cert()\n            try:\n                self.digest_alg = verify_message(\n                    mic_content, signature, verify_cert)\n            except IntegrityError:\n                mic_content = canonicalize(self.payload)\n                self.digest_alg = verify_message(\n                    mic_content, signature, verify_cert)\n\n        for part in self.payload.walk():\n            if part.get_content_type() == 'message/disposition-notification':\n                # logger.debug('Found MDN report for message %s:\\n%s' % (\n                #     orig_message.message_id, part.as_string()))\n\n                mdn = part.get_payload()[-1]\n                mdn_status = mdn['Disposition'].split(\n                    ';').pop().strip().split(':')\n                status = mdn_status[0]\n                if status == 'processed':\n                    mdn_mic = mdn.get('Received-Content-MIC', '').split(',')[0]\n\n                    # TODO: Check MIC for all cases\n                    if mdn_mic and orig_message.mic \\\n                            and mdn_mic != orig_message.mic.decode():\n                        status = 'processed/warning'\n                        detailed_status = 'Message Integrity check failed.'\n                else:\n                    detailed_status = ' '.join(mdn_status[1:]).strip()\n\n        return status, detailed_status"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef detect_mdn(self):\n        mdn_message = None\n        if self.payload.get_content_type() == 'multipart/report':\n            mdn_message = self.payload\n        elif self.payload.get_content_type() == 'multipart/signed':\n            for part in self.payload.walk():\n                if part.get_content_type() == 'multipart/report':\n                    mdn_message = self.payload\n\n        if not mdn_message:\n            raise MDNNotFound('No MDN found in the received message')\n\n        message_id, message_recipient = None, None\n        for part in mdn_message.walk():\n            if part.get_content_type() == 'message/disposition-notification':\n                mdn = part.get_payload()[0]\n                message_id = mdn.get('Original-Message-ID').strip('<>')\n                message_recipient = mdn.get(\n                    'Original-Recipient').split(';')[1].strip()\n        return message_id, message_recipient", "response": "Function checks if the received message is an AS2 MDN or not."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninitialize the logging handlers and level and formatters for the application.", "response": "def init_app(self, app):\n        \"\"\"Setup the logging handlers, level and formatters.\n\n        Level (DEBUG, INFO, CRITICAL, etc) is determined by the\n        app.config['FLASK_LOG_LEVEL'] setting, and defaults to\n        ``None``/``logging.NOTSET``.\n\n        \"\"\"\n        config_log_level = app.config.get('FLASK_LOG_LEVEL', None)\n\n        # Set up format for default logging\n        hostname = platform.node().split('.')[0]\n        formatter = (\n            '[%(asctime)s] %(levelname)s %(process)d [%(name)s] '\n            '%(filename)s:%(lineno)d - '\n            '[{hostname}] - %(message)s'\n        ).format(hostname=hostname)\n\n        config_log_int = None\n        set_level = None\n\n        if config_log_level:\n            config_log_int = getattr(logging, config_log_level.upper(), None)\n            if not isinstance(config_log_int, int):\n                raise ValueError(\n                    'Invalid log level: {0}'.format(config_log_level)\n                )\n            set_level = config_log_int\n\n        # Set to NotSet if we still aren't set yet\n        if not set_level:\n            set_level = config_log_int = logging.NOTSET\n        self.log_level = set_level\n\n        # Setup basic StreamHandler logging with format and level (do\n        # setup in case we are main, or change root logger if we aren't.\n        logging.basicConfig(format=formatter)\n        root_logger = logging.getLogger()\n        root_logger.setLevel(set_level)\n\n        # Get everything ready to setup the syslog handlers\n        address = None\n        if os.path.exists('/dev/log'):\n            address = '/dev/log'\n        elif os.path.exists('/var/run/syslog'):\n            address = '/var/run/syslog'\n        else:\n            address = ('127.0.0.1', 514)\n        # Add syslog handler before adding formatters\n        root_logger.addHandler(\n            SysLogHandler(address=address, facility=SysLogHandler.LOG_LOCAL0)\n        )\n        self.set_formatter(formatter)\n\n        return config_log_int"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_formatter(log_formatter):\n        # Add our formatter to all the handlers\n        root_logger = logging.getLogger()\n        for handler in root_logger.handlers:\n            handler.setFormatter(logging.Formatter(log_formatter))", "response": "Override the default log formatter with your own."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef api_request(path, **kwargs):\n\n    url = url_path_join(os.environ['JUPYTERHUB_API_URL'], path)\n    client = AsyncHTTPClient()\n    headers = {\n        'Authorization': 'token %s' % os.environ['JUPYTERHUB_API_TOKEN'],\n    }\n    if kwargs.get('method') == 'POST':\n        kwargs.setdefault('body', '')\n    req = HTTPRequest(url, headers=headers, **kwargs)\n    return client.fetch(req)", "response": "Make an API request to the Hub\n    to reduce boilerplate repetition."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstopping a user s server and delete the user", "response": "async def delete_user(name):\n    \"\"\"Stop a user's server and delete the user\"\"\"\n    app_log.info(\"Deleting user %s\", name)\n    await api_request('users/{}/server'.format(name), method='DELETE')\n    await api_request('users/{}'.format(name), method='DELETE')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef maybe_download(self, filename, work_directory, source_url):\n        if not os.path.exists(work_directory):\n            os.makedirs(work_directory)\n        filepath = os.path.join(work_directory, filename)\n        if not os.path.exists(filepath):\n            temp_file_name, _ = urllib.request.urlretrieve(source_url)\n            copyfile(temp_file_name, filepath)\n            print('Successfully downloaded', filename)\n        return filepath", "response": "Download the data from source url to the directory."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nextract the images into a 4D uint8 numpy array.", "response": "def extract_images(self, f):\n        \"\"\"Extract the images into a 4D uint8 numpy array [index, y, x, depth].\n        Args:\n          f: A file object that can be passed into a gzip reader.\n        Returns:\n          data: A 4D unit8 numpy array [index, y, x, depth].\n        Raises:\n          ValueError: If the bytestream does not start with 2051.\n        \"\"\"\n        print('Extracting', f.name)\n        with gzip.GzipFile(fileobj=f) as bytestream:\n            magic = self._read32(bytestream)\n            if magic != 2051:\n                raise ValueError('Invalid magic number %d in MNIST image file: %s' %\n                                 (magic, f.name))\n            num_images = self._read32(bytestream)\n            rows = self._read32(bytestream)\n            cols = self._read32(bytestream)\n            buf = bytestream.read(rows * cols * num_images)\n            data = np.frombuffer(buf, dtype=np.uint8)\n            data = data.reshape(num_images, rows, cols, 1)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nextracting the labels from a MNIST label file.", "response": "def extract_labels(self, f, one_hot=False, num_classes=10):\n        \"\"\"Extract the labels into a 1D uint8 numpy array [index].\n        Args:\n          f: A file object that can be passed into a gzip reader.\n          one_hot: Does one hot encoding for the result.\n          num_classes: Number of classes for the one hot encoding.\n        Returns:\n          labels: a 1D unit8 numpy array.\n        Raises:\n          ValueError: If the bystream doesn't start with 2049.\n        \"\"\"\n        print('Extracting', f.name)\n        with gzip.GzipFile(fileobj=f) as bytestream:\n            magic = self._read32(bytestream)\n            if magic != 2049:\n                raise ValueError('Invalid magic number %d in MNIST label file: %s' %\n                                 (magic, f.name))\n            num_items = self._read32(bytestream)\n            buf = bytestream.read(num_items)\n            labels = np.frombuffer(buf, dtype=np.uint8)\n            if one_hot:\n                return self.dense_to_one_hot(labels, num_classes)\n            return labels"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dense_to_one_hot(labels_dense, num_classes):\n        num_labels = labels_dense.shape[0]\n        index_offset = np.arange(num_labels) * num_classes\n        labels_one_hot = np.zeros((num_labels, num_classes))\n        labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n        return labels_one_hot", "response": "Convert class labels from scalars to one - hot vectors."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninput N x n_dim image of of raw data under lens function, as a dataframe output: (undirected graph, list of node contents, dictionary of patches)", "response": "def mapper_graph(df, lens_data=None, lens='pca', resolution=10, gain=0.5, equalize=True, clust='kmeans', stat='db',\n                 max_K=5):\n    \"\"\"\n    input: N x n_dim image of of raw data under lens function, as a dataframe\n    output: (undirected graph, list of node contents, dictionary of patches)\n    \"\"\"\n    if lens_data is None:\n        lens_data = apply_lens(df, lens=lens)\n\n    patch_clusterings = {}\n    counter = 0\n    patches = covering_patches(lens_data, resolution=resolution, gain=gain, equalize=equalize)\n    for key, patch in patches.items():\n        if len(patch) > 0:\n            patch_clusterings[key] = optimal_clustering(df, patch, method=clust, statistic=stat, max_K=max_K)\n            counter += 1\n    print 'total of {} patches required clustering'.format(counter)\n\n    all_clusters = []\n    for key in patch_clusterings:\n        all_clusters += patch_clusterings[key]\n    num_nodes = len(all_clusters)\n    print 'this implies {} nodes in the mapper graph'.format(num_nodes)\n\n    A = np.zeros((num_nodes, num_nodes))\n    for i in range(num_nodes):\n        for j in range(i):\n            overlap = set(all_clusters[i]).intersection(set(all_clusters[j]))\n            if len(overlap) > 0:\n                A[i, j] = 1\n                A[j, i] = 1\n\n    G = nx.from_numpy_matrix(A)\n    total = []\n    all_clusters_new = []\n    mapping = {}\n    cont = 0\n    for m in all_clusters:\n        total += m\n    for n, m in enumerate(all_clusters):\n        if len(m) == 1 and total.count(m) > 1:\n            G.remove_node(n)\n        else:\n            all_clusters_new.append(m)\n            mapping[n] = cont\n            cont += 1\n    H = nx.relabel_nodes(G, mapping)\n    return H, all_clusters_new, patches"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\napplies lens function to the data set", "response": "def apply_lens(df, lens='pca', dist='euclidean', n_dim=2, **kwargs):\n    \"\"\"\n    input: N x F dataframe of observations\n    output: N x n_dim image of input data under lens function\n    \"\"\"\n    if n_dim != 2:\n        raise 'error: image of data set must be two-dimensional'\n    if dist not in ['euclidean', 'correlation']:\n        raise 'error: only euclidean and correlation distance metrics are supported'\n    if lens == 'pca' and dist != 'euclidean':\n        raise 'error: PCA requires the use of euclidean distance metric'\n\n    if lens == 'pca':\n        df_lens = pd.DataFrame(decomposition.PCA(n_components=n_dim, **kwargs).fit_transform(df), df.index)\n    elif lens == 'mds':\n        D = metrics.pairwise.pairwise_distances(df, metric=dist)\n        df_lens = pd.DataFrame(manifold.MDS(n_components=n_dim, **kwargs).fit_transform(D), df.index)\n    elif lens == 'neighbor':\n        D = metrics.pairwise.pairwise_distances(df, metric=dist)\n        df_lens = pd.DataFrame(manifold.SpectralEmbedding(n_components=n_dim, **kwargs).fit_transform(D), df.index)\n    else:\n        raise 'error: only PCA, MDS, neighborhood lenses are supported'\n    \n    return df_lens"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrenders the HTML builder element and its children to a string.", "response": "def render(element, level=0):\n    \"\"\"Renders the HTML builder `element` and it's children to a string.\n    Example::\n\n        >>> print(\n        ...     render(\n        ...         html.form(action='/search', name='f')(\n        ...             html.input(name='q'),\n        ...             html.input(name='search_button', type='submit')\n        ...         )\n        ...     )\n        ... )\n        <form action=\"/search\" name=\"f\">\n          <input name=\"q\" />\n          <input type=\"submit\" name=\"search_button\" />\n        </form>\n\n    The :func:`render` function accepts the following arguments:\n\n    :param element: element created through the `html` builder instance, a list\n                    of such elements, or just a string.\n    :param level: indentation level of the rendered element with a step of two\n                  spaces.  If `level` is `None`, the `element` will be rendered\n                  without indentation and new line transferring, passing the\n                  same rule to the child elements.\n    \"\"\"\n\n    if hasattr(element, 'render'):\n        return element.render(level)\n    elif isinstance(element, basestring):\n        return _render_string(element, level)\n    elif hasattr(element, '__iter__'):\n        return _render_iteratable(element, level)\n    elif element is None:\n        return ''\n\n    raise TypeError('Cannot render %r' % element)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrender an iteratable sequence of HTML elements.", "response": "def _render_iteratable(iteratable, level):\n    \"\"\"Renders iteratable sequence of HTML elements.\"\"\"\n    if isinstance(iteratable, basestring):\n        return unicode(iteratable)\n    return ''.join([render(element, level) for element in iteratable])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _serialize_attributes(attributes):\n    result = ''\n    for name, value in attributes.items():\n        if not value:\n            continue\n        result += ' ' + _unmangle_attribute_name(name)\n        result += '=\"' + escape(value, True) + '\"'\n    return result", "response": "Serializes HTML element attributes in a name = value pair form."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _unmangle_attribute_name(name):\n\n    # Python keywords cannot be used as variable names, an underscore should\n    # be appended at the end of each of them when defining attribute names.\n    name = _PYTHON_KEYWORD_MAP.get(name, name)\n\n    # Attribute names are mangled with double underscore, as colon cannot\n    # be used as a variable character symbol in Python. Single underscore is\n    # used for substituting dash.\n    name = name.replace('__', ':').replace('_', '-')\n\n    return name", "response": "Unmangles attribute names so that correct Python variable names are\n    used for mapping attribute names."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef escape(string, quote=False):\n    if string is None:\n        return ''\n    elif hasattr(string, '__html__'):\n        return unicode(string)\n    string = string.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')\n    if quote:\n        string = string.replace('\"', \"&quot;\")\n    return string", "response": "Standard HTML text escaping."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef root_block(template_name=DEFAULT_TEMPLATE_NAME):\n    def decorator(block_func):\n        block = RootBlock(block_func, template_name)\n        return block_func\n    return decorator", "response": "A decorator that can be used to define that the decorated block function\n    will be at the root of the block template hierarchy."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef entropy_bits(\n        lst: Union[\n            List[Union[int, str, float, complex]],\n            Tuple[Union[int, str, float, complex]]\n        ]\n) -> float:\n    \"\"\"Calculate the number of entropy bits in a list or tuple of elements.\"\"\"\n    # Based on https://stackoverflow.com/a/45091961\n    if not isinstance(lst, (list, tuple)):\n        raise TypeError('lst must be a list or a tuple')\n\n    for num in lst:\n        if not isinstance(num, (int, str, float, complex)):\n            raise TypeError('lst can only be comprised of int, str, float, '\n                            'complex')\n\n    n_lst = len(lst)\n\n    if n_lst <= 1:\n        return 0.0\n\n    # Some NumPy replacements\n    counts = [lst.count(x) for x in lst]\n    probs = [c / n_lst for c in counts]\n\n    # Compute entropy\n    entropy = 0.0\n    for prob in probs:\n        entropy -= prob * log2(prob)\n\n    return entropy", "response": "Calculate the number of entropy bits in a list or tuple of elements."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the number of entropy bits in a range of numbers.", "response": "def entropy_bits_nrange(\n        minimum: Union[int, float], maximum: Union[int, float]\n) -> float:\n    \"\"\"Calculate the number of entropy bits in a range of numbers.\"\"\"\n    # Shannon:\n    # d = fabs(maximum - minimum)\n    # ent = -(1/d) * log(1/d, 2) * d\n    # Aprox form: log10(digits) * log2(10)\n    if not isinstance(minimum, (int, float)):\n        raise TypeError('minimum can only be int or float')\n    if not isinstance(maximum, (int, float)):\n        raise TypeError('maximum can only be int or float')\n    if minimum < 0:\n        raise ValueError('minimum should be greater than 0')\n    if maximum < 0:\n        raise ValueError('maximum should be greater than 0')\n\n    dif = fabs(maximum - minimum)\n    if dif == 0:\n        return 0.0\n\n    ent = log10(dif) * 3.321928\n    return ent"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef password_length_needed(entropybits: Union[int, float], chars: str) -> int:\n    if not isinstance(entropybits, (int, float)):\n        raise TypeError('entropybits can only be int or float')\n    if entropybits < 0:\n        raise ValueError('entropybits should be greater than 0')\n    if not isinstance(chars, str):\n        raise TypeError('chars can only be string')\n    if not chars:\n        raise ValueError(\"chars can't be null\")\n\n    # entropy_bits(list(characters)) = 6.554588\n    entropy_c = entropy_bits(list(chars))\n    return ceil(entropybits / entropy_c)", "response": "Calculate the length of a password for a given entropy and chars."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef words_amount_needed(entropybits: Union[int, float],\n                        entropy_w: Union[int, float],\n                        entropy_n: Union[int, float],\n                        amount_n: int) -> int:\n    \"\"\"Calculate words needed for a passphrase based on entropy.\"\"\"\n    # Thanks to @julianor for this tip to calculate default amount of\n    # entropy: minbitlen/log2(len(wordlist)).\n    # I set the minimum entropy bits and calculate the amount of words\n    # needed, cosidering the entropy of the wordlist.\n    # Then: entropy_w * amount_w + entropy_n * amount_n >= ENTROPY_BITS_MIN\n\n    if not isinstance(entropybits, (int, float)):\n        raise TypeError('entropybits can only be int or float')\n    if not isinstance(entropy_w, (int, float)):\n        raise TypeError('entropy_w can only be int or float')\n    if not isinstance(entropy_n, (int, float)):\n        raise TypeError('entropy_n can only be int or float')\n    if not isinstance(amount_n, int):\n        raise TypeError('amount_n can only be int')\n    if entropybits < 0:\n        raise ValueError('entropybits should be greater than 0')\n    if entropy_w <= 0:\n        raise ValueError('entropy_w should be greater than 0')\n    if entropy_n < 0:\n        raise ValueError('entropy_n should be greater than 0')\n    if amount_n < 0:\n        raise ValueError('amount_n should be greater than 0')\n\n    amount_w = (entropybits - entropy_n * amount_n) / entropy_w\n\n    if amount_w > -1.0:\n        return ceil(fabs(amount_w))\n\n    return 0", "response": "Calculate the amount of words needed for a passphrase based on entropy."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef password_entropy(length: int, chars: str) -> float:\n    if not isinstance(length, int):\n        raise TypeError('length can only be int')\n    if length < 0:\n        raise ValueError('length should be greater than 0')\n    if not isinstance(chars, str):\n        raise TypeError('chars can only be string')\n    if not chars:\n        raise ValueError(\"chars can't be null\")\n\n    if length == 0:\n        return 0.0\n\n    entropy_c = entropy_bits(list(chars))\n    return float(length * entropy_c)", "response": "Calculate the entropy of a password with given length and chars."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef passphrase_entropy(amount_w: int,\n                       entropy_w: Union[int, float],\n                       entropy_n: Union[int, float],\n                       amount_n: int) -> float:\n    \"\"\"Calculate the entropy of a passphrase with given words and numbers.\"\"\"\n    if not isinstance(amount_w, int):\n        raise TypeError('amount_w can only be int')\n    if not isinstance(entropy_w, (int, float)):\n        raise TypeError('entropy_w can only be int or float')\n    if not isinstance(entropy_n, (int, float)):\n        raise TypeError('entropy_n can only be int or float')\n    if not isinstance(amount_n, int):\n        raise TypeError('amount_n can only be int')\n    if amount_w < 0:\n        raise ValueError('amount_w should be greater than 0')\n    if entropy_w < 0:\n        raise ValueError('entropy_w should be greater than 0')\n    if entropy_n < 0:\n        raise ValueError('entropy_n should be greater than 0')\n    if amount_n < 0:\n        raise ValueError('amount_n should be greater than 0')\n\n    return float(amount_w * entropy_w + amount_n * entropy_n)", "response": "Calculate the entropy of a passphrase with given words and numbers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef entropy_bits(\n            lst: Union[\n                List[Union[int, str, float, complex]],\n                Tuple[Union[int, str, float, complex]]\n            ]\n    ) -> float:\n        \"\"\"Calculate the entropy of a wordlist or a numerical range.\n\n        Keyword arguments:\n        lst -- A wordlist as list or tuple, or a numerical range as a list:\n        (minimum, maximum)\n\n        \"\"\"\n        if not isinstance(lst, (tuple, list)):\n            raise TypeError('lst must be a list or a tuple')\n\n        size = len(lst)\n        if (\n                size == 2\n                and isinstance(lst[0], (int, float))\n                and isinstance(lst[1], (int, float))\n        ):\n            return calc_entropy_bits_nrange(lst[0], lst[1])\n\n        return calc_entropy_bits(lst)", "response": "Calculate the entropy of a list of words or a numerical range."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef import_words_from_file(self,\n                               inputfile: str,\n                               is_diceware: bool) -> None:\n        \"\"\"Import words for the wordlist from a given file.\n\n        The file can have a single column with words or be diceware-like\n        (two columns).\n\n        Keyword arguments:\n        inputfile -- A string with the path to the wordlist file to load, or\n        the value 'internal' to load the internal one.\n        is_diceware -- True if the file is diceware-like.\n\n        \"\"\"\n        if not Aux.isfile_notempty(inputfile):\n            raise FileNotFoundError('Input file does not exists, is not valid '\n                                    'or is empty: {}'.format(inputfile))\n\n        self._wordlist_entropy_bits = None\n        if is_diceware:\n            self._wordlist = self._read_words_from_diceware(inputfile)\n        else:\n            self._wordlist = self._read_words_from_wordfile(inputfile)", "response": "Imports the words for the internal one from a given file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef password_length_needed(self) -> int:\n        characters = self._get_password_characters()\n        if (\n                self.entropy_bits_req is None\n                or not characters\n        ):\n            raise ValueError(\"Can't calculate the password length needed: \"\n                             \"entropy_bits_req isn't set or the character \"\n                             \"set is empty\")\n\n        return calc_password_length_needed(\n            self.entropy_bits_req,\n            characters\n        )", "response": "Calculate the needed password length needed for the given entropy number."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the needed amount of words needed for the given wordlist.", "response": "def words_amount_needed(self) -> int:\n        \"\"\"Calculate the needed amount of words to satisfy the entropy number.\n\n        This is for the given wordlist.\n\n        \"\"\"\n        if (\n                self.entropy_bits_req is None\n                or self.amount_n is None\n                or not self.wordlist\n        ):\n            raise ValueError(\"Can't calculate the words amount needed: \"\n                             \"wordlist is empty or entropy_bits_req or \"\n                             \"amount_n isn't set\")\n\n        # Thanks to @julianor for this tip to calculate default amount of\n        # entropy: minbitlen/log2(len(wordlist)).\n        # I set the minimum entropy bits and calculate the amount of words\n        # needed, cosidering the entropy of the wordlist.\n        # Then: entropy_w * amount_w + entropy_n * amount_n >= ENTROPY_BITS_MIN\n        entropy_n = self.entropy_bits((self.randnum_min, self.randnum_max))\n\n        # The entropy for EFF Large Wordlist is ~12.9, no need to calculate\n        entropy_w = self._wordlist_entropy_bits \\\n            if self._wordlist_entropy_bits \\\n            else self.entropy_bits(self.wordlist)\n\n        return calc_words_amount_needed(\n            self.entropy_bits_req,\n            entropy_w,\n            entropy_n,\n            self.amount_n\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the entropy of a password that would be generated.", "response": "def generated_password_entropy(self) -> float:\n        \"\"\"Calculate the entropy of a password that would be generated.\"\"\"\n        characters = self._get_password_characters()\n        if (\n                self.passwordlen is None\n                or not characters\n        ):\n            raise ValueError(\"Can't calculate the password entropy: character\"\n                             \" set is empty or passwordlen isn't set\")\n\n        if self.passwordlen == 0:\n            return 0.0\n\n        return calc_password_entropy(self.passwordlen, characters)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the entropy of a passphrase that would be generated.", "response": "def generated_passphrase_entropy(self) -> float:\n        \"\"\"Calculate the entropy of a passphrase that would be generated.\"\"\"\n        if (\n                self.amount_w is None\n                or self.amount_n is None\n                or not self.wordlist\n        ):\n            raise ValueError(\"Can't calculate the passphrase entropy: \"\n                             \"wordlist is empty or amount_n or \"\n                             \"amount_w isn't set\")\n\n        if self.amount_n == 0 and self.amount_w == 0:\n            return 0.0\n\n        entropy_n = self.entropy_bits((self.randnum_min, self.randnum_max))\n\n        # The entropy for EFF Large Wordlist is ~12.9, no need to calculate\n        entropy_w = self._wordlist_entropy_bits \\\n            if self._wordlist_entropy_bits \\\n            else self.entropy_bits(self.wordlist)\n\n        return calc_passphrase_entropy(\n            self.amount_w,\n            entropy_w,\n            entropy_n,\n            self.amount_n\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate a list of words randomly chosen from a wordlist.", "response": "def generate(self, uppercase: int = None) -> list:\n        \"\"\"Generate a list of words randomly chosen from a wordlist.\n\n        Keyword arguments:\n        uppercase -- An integer number indicating how many uppercase\n        characters are wanted: bigger than zero means that many characters and\n        lower than zero means all uppercase except that many. Use 0 to make\n        them all uppercase, and None for no one.\n\n        \"\"\"\n        if (\n                self.amount_n is None\n                or self.amount_w is None\n                or not self.wordlist\n        ):\n            raise ValueError(\"Can't generate passphrase: \"\n                             \"wordlist is empty or amount_n or \"\n                             \"amount_w isn't set\")\n\n        if uppercase is not None and not isinstance(uppercase, int):\n            raise TypeError('uppercase must be an integer number')\n\n        passphrase = []\n        for _ in range(0, self.amount_w):\n            passphrase.append(randchoice(self.wordlist).lower())\n\n        # Handle uppercase\n        lowercase = Aux.lowercase_count(passphrase)\n        if passphrase and uppercase is not None:\n            if (\n                    uppercase < 0\n                    and lowercase > (uppercase * -1)\n            ):\n                uppercase = lowercase + uppercase\n\n            # If it's still negative, then means no uppercase\n            if uppercase == 0 or uppercase > lowercase:\n                # Make it all uppercase\n                passphrase = Aux.make_all_uppercase(passphrase)\n            elif uppercase > 0:\n                passphrase = Aux.make_chars_uppercase(\n                    passphrase,\n                    uppercase\n                )\n\n        # Handle numbers\n        for _ in range(0, self.amount_n):\n            passphrase.append(randbetween(MIN_NUM, MAX_NUM))\n\n        self.last_result = passphrase\n        return passphrase"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a list of random characters.", "response": "def generate_password(self) -> list:\n        \"\"\"Generate a list of random characters.\"\"\"\n        characterset = self._get_password_characters()\n        if (\n                self.passwordlen is None\n                or not characterset\n        ):\n            raise ValueError(\"Can't generate password: character set is \"\n                             \"empty or passwordlen isn't set\")\n\n        password = []\n        for _ in range(0, self.passwordlen):\n            password.append(randchoice(characterset))\n\n        self.last_result = password\n        return password"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a list of parts of a UUID version 4 string.", "response": "def generate_uuid4(self) -> list:\n        \"\"\"Generate a list of parts of a UUID version 4 string.\n\n        Usually, these parts are concatenated together using dashes.\n\n        \"\"\"\n        # uuid4: 8-4-4-4-12: xxxxxxxx-xxxx-4xxx-{8,9,a,b}xxx-xxxxxxxxxxxx\n        # instead of requesting small amounts of bytes, it's better to do it\n        # for the full amount of them.\n        hexstr = randhex(30)\n\n        uuid4 = [\n            hexstr[:8],\n            hexstr[8:12],\n            '4' + hexstr[12:15],\n            '{:x}{}'.format(randbetween(8, 11), hexstr[15:18]),\n            hexstr[18:]\n        ]\n        self.last_result = uuid4\n        return uuid4"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_ks_archs(self):\n        ''' keystone assembler '''\n        ks_archs = {\n            'x16':     (KS_ARCH_X86,     KS_MODE_16),\n            'x86':     (KS_ARCH_X86,     KS_MODE_32),\n            'x64':     (KS_ARCH_X86,     KS_MODE_64),\n            'arm':     (KS_ARCH_ARM,     KS_MODE_ARM),\n            'arm_t':   (KS_ARCH_ARM,     KS_MODE_THUMB),\n            'arm64':   (KS_ARCH_ARM64,   KS_MODE_LITTLE_ENDIAN),\n            'mips32':  (KS_ARCH_MIPS,    KS_MODE_MIPS32),\n            'mips64':  (KS_ARCH_MIPS,    KS_MODE_MIPS64),\n            'ppc32':   (KS_ARCH_PPC,     KS_MODE_PPC32),\n            'ppc64':   (KS_ARCH_PPC,     KS_MODE_PPC64),\n            'hexagon': (KS_ARCH_HEXAGON, KS_MODE_BIG_ENDIAN),\n            'sparc':   (KS_ARCH_SPARC,   KS_MODE_SPARC32),\n            'sparc64': (KS_ARCH_SPARC,   KS_MODE_SPARC64),\n            'systemz': (KS_ARCH_SYSTEMZ, KS_MODE_BIG_ENDIAN)\n            }\n        return ks_archs", "response": "Return a dictionary of architectures."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef default(self, line):\n        ''' if no other commands was invoked '''\n        try:\n            encoding, count = self._ks.asm(line)\n            machine_code = \"\"\n            for opcode in encoding:\n                machine_code += \"\\\\x\" + hexlify(pack(\"B\", opcode)).decode()\n            print(\"\\\"\" + machine_code + \"\\\"\")\n        except KsError as e:\n            print(\"Error: %s\" %e)", "response": "Default command for the naculiacute command"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _bigger_than_zero(value: str) -> int:\n    ivalue = int(value)\n    if ivalue < 0:\n        raise ArgumentTypeError(\n            '{} should be bigger than 0'.format(ivalue)\n        )\n    return ivalue", "response": "Type evaluator for argparse."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef main(argv: list) -> int:\n    passphrase = Passphrase()\n\n    # Set defaults\n    passphrase.entropy_bits_req = ENTROPY_BITS_MIN\n    passwordlen_default = passphrase.password_length_needed()\n    amount_n_default = 0\n    passphrase.amount_n = amount_n_default\n    # To avoid loading the wordlist unnecessarily, I'm hardcoding this value\n    # It's ok, it's only used to show help information\n    amount_w_default = 6\n\n    parser = ArgumentParser(\n        formatter_class=RawDescriptionHelpFormatter,\n        description='{version_string}\\n\\n'\n        'Generates a cryptographically secure passphrase, based on '\n        'a wordlist, or a\\npassword, and prints it to standard output.\\n'\n        'By default, it uses an embedded EFF Large Wordlist for passphrases.\\n'\n        'Passphrases with less than {wordsamountmin} words are considered '\n        'insecure. A safe bet is \\nbetween {wordsamountmin} and 7 words, '\n        'plus at least a number.\\n'\n        'For passwords, use at least {passwdmin} characters, but prefer '\n        '{passwdpref} or more, using the\\ncomplete characters set.\\n\\n'\n        'Instead of words and numbers, a password (random string of '\n        'printable\\ncharacters from Python String standard) can be generated '\n        'by\\n-p | --password, specifying the length. It uses uppercase, '\n        'lowercase, digits\\nand punctuation characters unless otherwise '\n        'specified.\\n'\n        'Also, a UUID v4 string can be generated by --uuid4 or a coin can be '\n        'thrown\\nwith --coin.\\n'\n        'A custom wordlist can be specified by -i | --input, the format must '\n        'be: \\nsingle column, one word per line. If -d | --diceware is used, '\n        'the input\\nfile is treated as a diceware wordlist (two columns).'\n        '\\nOptionally, -o | --output can be used to specify an output file '\n        '(existing \\nfile is overwritten).\\n'\n        'The number of words is {wordsamountmin} by default, but it '\n        'can be changed by -w | --words.\\n'\n        'The number of numbers is {numsamountmin} by default, but it can be '\n        'changed by\\n-n | --numbers. The generated numbers are between '\n        '{minnum} and {maxnum}.\\n'\n        'The default separator is a blank space, but any character or '\n        'character\\nsequence can be specified by -s | --separator.\\n'\n        '\\nExample output:\\n'\n        '\\tDefault parameters:\\tchalice sheath postcard modular cider size\\n'\n        '\\tWords=3, Numbers=2:\\tdepraved widow office 184022 320264\\n'\n        '\\tPassword, 20 chars:\\tsF#s@B+iR#ZIL-yUWKPR'.format(\n            version_string=__version_string__,\n            minnum=passphrase.randnum_min,\n            maxnum=passphrase.randnum_max,\n            wordsamountmin=amount_w_default,\n            numsamountmin=amount_n_default,\n            passwdmin=passwordlen_default,\n            passwdpref=passwordlen_default + 4\n        )\n    )\n\n    parser.add_argument(\n        '--version',\n        action='store_true',\n        help='print program version and licensing information and exit'\n    )\n    parser.add_argument(\n        '--insecure',\n        action='store_true',\n        default=False,\n        help=\"force password/passphrase generation even if the system's \"\n             \"entropy is too low\"\n    )\n    parser.add_argument(\n        '--no-newline',\n        action='store_true',\n        default=False,\n        help=\"don't print newline at the end of the passphrase/password\"\n    )\n    parser.add_argument(\n        '-m',\n        '--mute',\n        action='store_true',\n        default=False,\n        help=\"muted mode: it won't print output, only informational, warning \"\n             \"or error messages (usefull with -o | --output)\"\n    )\n    parser.add_argument(\n        '-v',\n        '--verbose',\n        action='store_true',\n        default=False,\n        help='print additional information (can coexist with -m | --mute)'\n    )\n    parser.add_argument(\n        '-e',\n        '--entropybits',\n        type=_bigger_than_zero,\n        default=ENTROPY_BITS_MIN,\n        help='specify the number of bits to use for entropy calculations '\n             '(defaults to {})'.format(ENTROPY_BITS_MIN)\n    )\n    parser.add_argument(\n        '--uuid4',\n        action='store_true',\n        default=False,\n        help='generate an UUID v4 string'\n    )\n    parser.add_argument(\n        '--coin',\n        action='store_true',\n        default=False,\n        help='generate a random coin throw: heads or tails'\n    )\n    parser.add_argument(\n        '-p',\n        '--password',\n        type=_bigger_than_zero,\n        const=-1,\n        nargs='?',\n        help='generate a password of the specified length from all printable '\n             'or selected characters'\n    )\n    parser.add_argument(\n        '--use-uppercase',\n        type=_bigger_than_zero,\n        const=0,\n        nargs='?',\n        help='use uppercase characters for password generation or give the '\n             'amount of uppercase characters in the passphrase: zero or no '\n             'input for all uppercase or any number of uppercase '\n             'characters wanted (the rest are lowercase)'\n    )\n    parser.add_argument(\n        '--use-lowercase',\n        type=_bigger_than_zero,\n        const=0,\n        nargs='?',\n        help='use lowercase characters for password generation or give the '\n             'amount of lowercase characters in the passphrase: zero or no '\n             'input for all lowercase (default) or any number of lowercase '\n             'characters wanted (the rest are uppercase)'\n    )\n    parser.add_argument(\n        '--use-digits',\n        action='store_true',\n        default=False,\n        help='use digits for password generation'\n    )\n    parser.add_argument(\n        '--use-alphanumeric',\n        action='store_true',\n        default=False,\n        help='use lowercase and uppercase characters, and digits for password '\n             'generation (equivalent to --use-lowercase --use-uppercase '\n             '--use-digits)'\n    )\n    parser.add_argument(\n        '--use-punctuation',\n        action='store_true',\n        default=False,\n        help='use punctuation characters for password generation'\n    )\n    parser.add_argument(\n        '-w',\n        '--words',\n        type=_bigger_than_zero,\n        help='specify the amount of words (0 or more)'\n    )\n    parser.add_argument(\n        '-n',\n        '--numbers',\n        type=_bigger_than_zero,\n        default=amount_n_default,\n        help='specify the amount of numbers (0 or more)'\n    )\n    parser.add_argument(\n        '-s',\n        '--separator',\n        type=str,\n        default=' ',\n        help='specify a separator character (space by default)'\n    )\n    parser.add_argument(\n        '-o',\n        '--output',\n        type=str,\n        help='specify an output file (existing file is overwritten)'\n    )\n    parser.add_argument(\n        '-i',\n        '--input',\n        type=str,\n        help='specify an input file (it must have the following format: '\n             'single column, one word per line)'\n    )\n    parser.add_argument(\n        '-d',\n        '--diceware',\n        action='store_true',\n        default=False,\n        help='specify input file as a diceware list (format: two colums)'\n    )\n\n    args = parser.parse_args(argv)\n\n    inputfile = args.input\n    outputfile = args.output\n    separator = args.separator\n    is_diceware = args.diceware\n    passwordlen = args.password\n    amount_w = args.words\n    amount_n = args.numbers\n    show_version = args.version\n    mute = args.mute\n    verbose = args.verbose\n    no_newline = args.no_newline\n    gen_uuid4 = args.uuid4\n    gen_coin = args.coin\n    p_uppercase = args.use_uppercase\n    p_lowercase = args.use_lowercase\n    p_digits = args.use_digits\n    p_punctuation = args.use_punctuation\n    p_alphanumeric = args.use_alphanumeric\n    entropy_bits = args.entropybits\n    gen_insecure = args.insecure\n\n    if show_version:\n        print(__version_string__)\n        return 0\n\n    if verbose:\n        Aux.print_stderr(__version_string__)\n\n    # Check system entropy\n    system_entropy = Aux.system_entropy()\n    if system_entropy < SYSTEM_ENTROPY_BITS_MIN:\n        Aux.print_stderr(\n            'Warning: the system has too few entropy: {} bits; randomness '\n            'quality could be poor'.format(system_entropy)\n        )\n        if not gen_insecure:\n            Aux.print_stderr(\n                'Error: system entropy too low: {system_entropy} '\n                '< {system_entropy_min}'.format(\n                    system_entropy=system_entropy,\n                    system_entropy_min=SYSTEM_ENTROPY_BITS_MIN\n                )\n            )\n            return 1\n\n    if verbose:\n        Aux.print_stderr(\n            'Using {} bits of entropy for calculations (if any). The minimum '\n            'recommended is {}'.format(entropy_bits, ENTROPY_BITS_MIN)\n        )\n\n    # Check selected entropy\n    check_chosen_entropy = False if gen_uuid4 or gen_coin else not (\n        amount_n and amount_w and passwordlen is None\n    )\n    if check_chosen_entropy and entropy_bits < ENTROPY_BITS_MIN:\n        Aux.print_stderr(\n            'Warning: insecure number of bits for entropy calculations '\n            'chosen! Should be bigger than {}'.format(ENTROPY_BITS_MIN)\n        )\n    passphrase.entropy_bits_req = entropy_bits\n\n    # Generate whatever is requested\n    if gen_uuid4:\n        # Generate uuid4\n        if verbose:\n            Aux.print_stderr('Generating UUID v4')\n        gen_what = 'UUID v4'\n        gen_ent = 120\n\n        passphrase.generate_uuid4()\n        passphrase.separator = '-'\n    elif gen_coin:\n        # Generate a coin throw\n        if verbose:\n            Aux.print_stderr('Throwing a coin')\n        gen_what = 'coin'\n        gen_ent = 1\n\n        passphrase = 'Heads' if randbool() else 'Tails'\n    elif passwordlen is not None:\n        # Generate a password\n        gen_what = 'password'\n\n        p_uppercase = True if p_uppercase is not None else False\n        p_lowercase = True if p_lowercase is not None else False\n        if (\n                p_uppercase\n                or p_lowercase\n                or p_digits\n                or p_punctuation\n                or p_alphanumeric\n        ):\n            passphrase.password_use_uppercase = (p_uppercase or p_alphanumeric)\n            passphrase.password_use_lowercase = (p_lowercase or p_alphanumeric)\n            passphrase.password_use_digits = (p_digits or p_alphanumeric)\n            passphrase.password_use_punctuation = p_punctuation\n\n        min_len = passphrase.password_length_needed()\n        if passwordlen < 1:\n            passwordlen = min_len\n        elif passwordlen < min_len:\n            Aux.print_stderr(\n                'Warning: insecure password length chosen! Should be bigger '\n                'than or equal to {}'.format(min_len)\n            )\n\n        passphrase.passwordlen = passwordlen\n        gen_ent = passphrase.generated_password_entropy()\n\n        if verbose:\n            verbose_string = (\n                'Generating password of {} characters long '\n                'using '.format(passwordlen)\n            )\n            verbose_string += (\n                'uppercase characters, ' if (\n                    passphrase.password_use_uppercase or p_alphanumeric\n                ) else ''\n            )\n            verbose_string += (\n                'lowercase characters, ' if (\n                    passphrase.password_use_lowercase or p_alphanumeric\n                ) else ''\n            )\n            verbose_string += (\n                'digits, ' if (\n                    passphrase.password_use_digits or p_alphanumeric\n                ) else ''\n            )\n            verbose_string += (\n                'punctuation characters, ' if (\n                    passphrase.password_use_punctuation\n                ) else ''\n            )\n            Aux.print_stderr(\n                verbose_string[:-2] if (\n                    verbose_string[-2:] == ', '\n                ) else verbose_string\n            )\n\n        passphrase.generate_password()\n        passphrase.separator = ''\n    else:\n        # Generate a passphrase\n        gen_what = 'passphrase'\n\n        # Read wordlist if indicated\n        if inputfile is None:\n            passphrase.load_internal_wordlist()\n        else:\n            try:\n                passphrase.import_words_from_file(inputfile, is_diceware)\n            except IOError:\n                Aux.print_stderr(\n                    \"Error: input file {} is empty or it can't be opened or \"\n                    \"read\".format(inputfile)\n                )\n                return 1\n\n        passphrase.amount_n = amount_n\n        amount_w_good = passphrase.words_amount_needed()\n        if amount_w is None:\n            amount_w = amount_w_good\n        elif amount_w < amount_w_good:\n            Aux.print_stderr(\n                'Warning: insecure amount of words chosen! Should be '\n                'bigger than or equal to {}'.format(amount_w_good)\n            )\n\n        passphrase.amount_w = amount_w\n        gen_ent = passphrase.generated_passphrase_entropy()\n\n        if verbose:\n            Aux.print_stderr(\n                'Generating a passphrase of {} words and {} '\n                'numbers using {}'.format(\n                    amount_w,\n                    amount_n,\n                    'internal wordlist' if inputfile is None else (\n                        'external wordlist: ' + inputfile + (\n                            ' (diceware-like)' if is_diceware else ''\n                        )\n                    )\n                )\n            )\n\n        case = (-1 * p_lowercase) if p_lowercase else p_uppercase\n        passphrase.generate(case)\n        passphrase.separator = separator\n\n    if verbose:\n        Aux.print_stderr(\n            'The entropy of this {what} is {ent:.2f} bits'.format(\n                what=gen_what,\n                ent=gen_ent\n            )\n        )\n\n    if not gen_coin and gen_ent < ENTROPY_BITS_MIN:\n        Aux.print_stderr('Warning: the {} is too short!'.format(gen_what))\n\n    if not mute:\n        if no_newline:\n            print(passphrase, end='')\n        else:\n            print(passphrase)\n\n    if outputfile is not None:\n        # ensure path to file exists or create\n        dir_ = os_path_dirname(outputfile)\n        if dir_:\n            try:\n                os_makedirs(dir_, exist_ok=True)\n            except PermissionError:\n                Aux.print_stderr(\n                    'Error: permission denied to create directory {}'.format(\n                        dir_,\n                    )\n                )\n                return 1\n        try:\n            with open(outputfile, mode='wt', encoding='utf-8') as outfile:\n                linefeed = '' if no_newline else '\\n'\n                outfile.write(str(passphrase) + linefeed)\n\n        except IOError:\n            Aux.print_stderr(\n                \"Error: file {} can't be opened or written\".format(\n                    outputfile,\n                )\n            )\n            return 1\n\n    return 0", "response": "This function is the main entry point for the passphrase CLI interface."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the create view that can be specified as the second argument to url in urls. py.", "response": "def create(cls):\n        \"\"\"\n        Returns the create view that can be specified as the second argument\n        to url() in urls.py.\n        \"\"\"\n\n        class NewPopupCreateView(PopupCreateView, cls.parent_class):\n            model = cls.model\n            form_class = cls.form_class\n            popup_name = cls.get_class_verbose_name()\n            template_name = cls.get_template_name_create()\n            permission_required = cls.get_permission_required('create')\n\n            def get_context_data(self, **kwargs):\n                kwargs.update(cls.context_for_all)\n                kwargs.update(cls.context_for_create)\n                return super(NewPopupCreateView, self).get_context_data(**kwargs)\n\n        return NewPopupCreateView"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the update view that can be specified as the second argument to url in urls. py.", "response": "def update(cls):\n        \"\"\"\n        Returns the update view that can be specified as the second argument\n        to url() in urls.py.\n        \"\"\"\n\n        class NewPopupUpdateView(PopupUpdateView, cls.parent_class):\n            model = cls.model\n            form_class = cls.form_class\n            popup_name = cls.get_class_verbose_name()\n            template_name = cls.get_template_name_update()\n            permission_required = cls.get_permission_required('update')\n\n            def get_context_data(self, **kwargs):\n                kwargs.update(cls.context_for_all)\n                kwargs.update(cls.context_for_update)\n                return super(NewPopupUpdateView, self).get_context_data(**kwargs)\n\n        return NewPopupUpdateView"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the delete view that can be specified as the second argument to url in urls. py.", "response": "def delete(cls):\n        \"\"\"\n        Returns the delete view that can be specified as the second argument\n        to url() in urls.py.\n        \"\"\"\n\n        class PopupDeleteViewView(PopupDeleteView, cls.parent_class):\n            model = cls.model\n            form_class = cls.form_class\n            permission_required = cls.get_permission_required('delete')\n\n        return PopupDeleteViewView"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate url and url_name for create update and delete view", "response": "def urls(cls):\n        \"\"\"\n        generate url and url_name for create\u3001update and delete view\n        default url_name is classname_name\n        \"\"\"\n        class_name = cls.get_class_name()\n        if django.VERSION >= (2, 0):\n            return path('{}/'.format(class_name), include([\n                path('popup/', cls.create().as_view(), name='{}_popup_create'.format(class_name)),\n                path('popup/<int:pk>/', cls.update().as_view(), name='{}_popup_update'.format(class_name)),\n                path('popup/delete/<int:pk>/', cls.delete().as_view(), name='{}_popup_delete'.format(class_name)),\n            ]))\n        else:\n            return url(r'^{}/'.format(class_name), include([\n                url(r'^popup/$', cls.create().as_view(), name='{}_popup_create'.format(class_name)),\n                url(r'^popup/(?P<pk>\\d+)/$', cls.update().as_view(), name='{}_popup_update'.format(class_name)),\n                url(r'^popup/delete/(?P<pk>\\d+)/$', cls.delete().as_view(), name='{}_popup_delete'.format(class_name)),\n            ]))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_fk_popup_field(cls, *args, **kwargs):\n        kwargs['popup_name'] = cls.get_class_verbose_name()\n        kwargs['permissions_required'] = cls.permissions_required\n        if cls.template_name_fk is not None:\n            kwargs['template_name'] = cls.template_name_fk\n        return ForeignKeyWidget('{}_popup_create'.format(cls.get_class_name()), *args, **kwargs)", "response": "Generate fk field related to class wait popup crud\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_m2m_popup_field(cls, *args, **kwargs):\n        kwargs['popup_name'] = cls.get_class_verbose_name()\n        kwargs['permissions_required'] = cls.permissions_required\n        if cls.template_name_m2m is not None:\n            kwargs['template_name'] = cls.template_name_m2m\n        return ManyToManyWidget('{}_popup_create'.format(cls.get_class_name()), *args, **kwargs)", "response": "Generate m2m field related to class wait popup crud\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn all ( and only ) the lowercase chars in the given string.", "response": "def lowercase_chars(string: any) -> str:\n        \"\"\"Return all (and only) the lowercase chars in the given string.\"\"\"\n        return ''.join([c if c.islower() else '' for c in str(string)])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef uppercase_chars(string: any) -> str:\n        return ''.join([c if c.isupper() else '' for c in str(string)])", "response": "Return all uppercase chars in the given string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn all the chars in the given string.", "response": "def chars(string: any) -> str:\n        \"\"\"Return all (and only) the chars in the given string.\"\"\"\n        return ''.join([c if c.isalpha() else '' for c in str(string)])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmake all characters uppercase.", "response": "def make_all_uppercase(\n            lst: Union[list, tuple, str, set]\n    ) -> Union[list, tuple, str, set]:\n        \"\"\"Make all characters uppercase.\n\n        It supports characters in a (mix of) list, tuple, set or string.\n        The return value is of the same type of the input value.\n\n        \"\"\"\n        if not isinstance(lst, (list, tuple, str, set)):\n            raise TypeError('lst must be a list, a tuple, a set or a string')\n\n        if isinstance(lst, str):\n            return lst.upper()\n\n        arr = list(lst)\n\n        # enumerate is 70% slower than range\n        # for i in range(len(lst)):\n        #     if isinstance(arr[i], (list, tuple, str, set)):\n        #         arr[i] = Aux.make_all_uppercase(arr[i])\n        arr[:] = [\n            Aux.make_all_uppercase(element) if (\n                isinstance(element, (list, tuple, str, set))\n            ) else element for element in arr\n        ]\n\n        if isinstance(lst, set):\n            return set(arr)\n        elif isinstance(lst, tuple):\n            return tuple(arr)\n\n        return arr"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmakes a single char from the string uppercase.", "response": "def _make_one_char_uppercase(string: str) -> str:\n        \"\"\"Make a single char from the string uppercase.\"\"\"\n        if not isinstance(string, str):\n            raise TypeError('string must be a string')\n\n        if Aux.lowercase_count(string) > 0:\n            while True:\n                cindex = randbelow(len(string))\n                if string[cindex].islower():\n                    aux = list(string)\n                    aux[cindex] = aux[cindex].upper()\n                    string = ''.join(aux)\n                    break\n\n        return string"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_chars_uppercase(\n            lst: Union[list, tuple, str, set],\n            uppercase: int\n    ) -> Union[list, tuple, str, set]:\n        \"\"\"Make uppercase some randomly selected characters.\n\n        The characters can be in a (mix of) string, list, tuple or set.\n\n        Keyword arguments:\n        lst -- the object to make all chars uppercase, which can be a (mix of)\n        list, tuple, string or set.\n        uppercase -- Number of characters to be set as uppercase.\n\n        \"\"\"\n        if not isinstance(lst, (list, tuple, str, set)):\n            raise TypeError('lst must be a list, a tuple, a set or a string')\n        if not isinstance(uppercase, int):\n            raise TypeError('uppercase must be an integer')\n        if uppercase < 0:\n            raise ValueError('uppercase must be bigger than zero')\n\n        lowercase = Aux.lowercase_count(lst)\n        if uppercase == 0 or lowercase == 0:\n            return lst\n        elif uppercase >= lowercase:\n            # Make it all uppercase\n            return Aux.make_all_uppercase(lst)\n\n        arr = list(lst)\n\n        # Check if at least an element is supported\n        # This is required to avoid an infinite loop below\n        supported = False\n        for element in arr:\n            if isinstance(element, (list, tuple, str, set)):\n                supported = True\n                break\n\n        if supported:\n            # Pick a word at random, then make a character uppercase\n            count = 0\n            while count < uppercase:\n                windex = randbelow(len(arr))\n                element = arr[windex]\n                # Skip unsupported types or empty ones\n                if element:\n                    aux = element\n                    if isinstance(element, str):\n                        aux = Aux._make_one_char_uppercase(element)\n                    elif isinstance(element, (list, tuple, set)):\n                        aux = Aux.make_chars_uppercase(element, 1)\n\n                    if aux != element:\n                        arr[windex] = aux\n                        count += 1\n\n        if isinstance(lst, set):\n            return set(arr)\n        elif isinstance(lst, str):\n            return ''.join(arr)\n        elif isinstance(lst, tuple):\n            return tuple(arr)\n\n        return arr", "response": "Makes all uppercase some randomly selected characters."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef isfile_notempty(inputfile: str) -> bool:\n        try:\n            return isfile(inputfile) and getsize(inputfile) > 0\n        except TypeError:\n            raise TypeError('inputfile is not a valid type')", "response": "Check if the input filename with path is a file and is not empty."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef system_entropy():\n        arg = ['cat', '/proc/sys/kernel/random/entropy_avail']\n        proc = Popen(arg, stdout=PIPE, stderr=DEVNULL)\n        response = proc.communicate()[0]\n        return int(response) if response else -1", "response": "Return the system s entropy bit count or - 1 if unknown."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a unsigned transaction for issuing an asset.", "response": "def issue(self, issuance_spec, metadata, fees):\n        \"\"\"\n        Creates a transaction for issuing an asset.\n\n        :param TransferParameters issuance_spec: The parameters of the issuance.\n        :param bytes metadata: The metadata to be embedded in the transaction.\n        :param int fees: The fees to include in the transaction.\n        :return: An unsigned transaction for issuing an asset.\n        :rtype: CTransaction\n        \"\"\"\n        inputs, total_amount = self._collect_uncolored_outputs(\n            issuance_spec.unspent_outputs, 2 * self._dust_amount + fees)\n\n        return bitcoin.core.CTransaction(\n            vin=[bitcoin.core.CTxIn(item.out_point, item.output.script) for item in inputs],\n            vout=[\n                self._get_colored_output(issuance_spec.to_script),\n                self._get_marker_output([issuance_spec.amount], metadata),\n                self._get_uncolored_output(issuance_spec.change_script, total_amount - self._dust_amount - fees)\n            ]\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef transfer(self, asset_transfer_specs, btc_transfer_spec, fees):\n        inputs = []\n        outputs = []\n        asset_quantities = []\n        for asset_id, transfer_spec in asset_transfer_specs:\n            colored_outputs, collected_amount = self._collect_colored_outputs(\n                transfer_spec.unspent_outputs, asset_id, transfer_spec.amount)\n            inputs.extend(colored_outputs)\n            outputs.append(self._get_colored_output(transfer_spec.to_script))\n            asset_quantities.append(transfer_spec.amount)\n\n            if collected_amount > transfer_spec.amount:\n                outputs.append(self._get_colored_output(transfer_spec.change_script))\n                asset_quantities.append(collected_amount - transfer_spec.amount)\n\n        btc_excess = sum([input.output.value for input in inputs]) - sum([output.nValue for output in outputs])\n\n        if btc_excess < btc_transfer_spec.amount + fees:\n            # Not enough bitcoin inputs\n            uncolored_outputs, total_amount = self._collect_uncolored_outputs(\n                btc_transfer_spec.unspent_outputs, btc_transfer_spec.amount + fees - btc_excess)\n            inputs.extend(uncolored_outputs)\n            btc_excess += total_amount\n\n        change = btc_excess - btc_transfer_spec.amount - fees\n        if change > 0:\n            # Too much bitcoin in input, send it back as change\n            outputs.append(self._get_uncolored_output(btc_transfer_spec.change_script, change))\n\n        if btc_transfer_spec.amount > 0:\n            outputs.append(self._get_uncolored_output(btc_transfer_spec.to_script, btc_transfer_spec.amount))\n\n        if asset_quantities:\n            outputs.insert(0, self._get_marker_output(asset_quantities, b''))\n\n        return bitcoin.core.CTransaction(\n            vin=[bitcoin.core.CTxIn(item.out_point, item.output.script) for item in inputs],\n            vout=outputs\n        )", "response": "Creates a transaction for sending assets and bitcoins."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef transfer_assets(self, asset_id, transfer_spec, btc_change_script, fees):\n        return self.transfer(\n            [(asset_id, transfer_spec)],\n            TransferParameters(transfer_spec.unspent_outputs, None, btc_change_script, 0),\n            fees)", "response": "Creates a transaction for sending an asset."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a transaction for swapping assets for bitcoins.", "response": "def btc_asset_swap(self, btc_transfer_spec, asset_id, asset_transfer_spec, fees):\n        \"\"\"\n        Creates a transaction for swapping assets for bitcoins.\n\n        :param TransferParameters btc_transfer_spec: The parameters of the bitcoins being transferred.\n        :param bytes asset_id: The ID of the asset being sent.\n        :param TransferParameters asset_transfer_spec: The parameters of the asset being transferred.\n        :param int fees: The fees to include in the transaction.\n        :return: The resulting unsigned transaction.\n        :rtype: CTransaction\n        \"\"\"\n        return self.transfer([(asset_id, asset_transfer_spec)], btc_transfer_spec, fees)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a transaction for swapping an asset for another asset.", "response": "def asset_asset_swap(\n            self, asset1_id, asset1_transfer_spec, asset2_id, asset2_transfer_spec, fees):\n        \"\"\"\n        Creates a transaction for swapping an asset for another asset.\n\n        :param bytes asset1_id: The ID of the first asset.\n        :param TransferParameters asset1_transfer_spec: The parameters of the first asset being transferred.\n            It is also used for paying fees and/or receiving change if any.\n        :param bytes asset2_id: The ID of the second asset.\n        :param TransferDetails asset2_transfer_spec: The parameters of the second asset being transferred.\n        :param int fees: The fees to include in the transaction.\n        :return: The resulting unsigned transaction.\n        :rtype: CTransaction\n        \"\"\"\n        btc_transfer_spec = TransferParameters(\n            asset1_transfer_spec.unspent_outputs, asset1_transfer_spec.to_script, asset1_transfer_spec.change_script, 0)\n\n        return self.transfer(\n            [(asset1_id, asset1_transfer_spec), (asset2_id, asset2_transfer_spec)], btc_transfer_spec, fees)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncollect uncolored outputs for the specified amount.", "response": "def _collect_uncolored_outputs(unspent_outputs, amount):\n        \"\"\"\n        Returns a list of uncolored outputs for the specified amount.\n\n        :param list[SpendableOutput] unspent_outputs: The list of available outputs.\n        :param int amount: The amount to collect.\n        :return: A list of outputs, and the total amount collected.\n        :rtype: (list[SpendableOutput], int)\n        \"\"\"\n        total_amount = 0\n        result = []\n        for output in unspent_outputs:\n            if output.output.asset_id is None:\n                result.append(output)\n                total_amount += output.output.value\n\n            if total_amount >= amount:\n                return result, total_amount\n\n        raise InsufficientFundsError"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _collect_colored_outputs(unspent_outputs, asset_id, asset_quantity):\n        total_amount = 0\n        result = []\n        for output in unspent_outputs:\n            if output.output.asset_id == asset_id:\n                result.append(output)\n                total_amount += output.output.asset_quantity\n\n            if total_amount >= asset_quantity:\n                return result, total_amount\n\n        raise InsufficientAssetQuantityError", "response": "Collect the unspent outputs for the specified asset_id and asset_quantity."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating an uncolored output.", "response": "def _get_uncolored_output(self, script, value):\n        \"\"\"\n        Creates an uncolored output.\n\n        :param bytes script: The output script.\n        :param int value: The satoshi value of the output.\n        :return: An object representing the uncolored output.\n        :rtype: TransactionOutput\n        \"\"\"\n        if value < self._dust_amount:\n            raise DustOutputError\n\n        return bitcoin.core.CTxOut(value, bitcoin.core.CScript(script))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_colored_output(self, script):\n        return bitcoin.core.CTxOut(self._dust_amount, bitcoin.core.CScript(script))", "response": "Creates a colored output."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_marker_output(self, asset_quantities, metadata):\n        payload = openassets.protocol.MarkerOutput(asset_quantities, metadata).serialize_payload()\n        script = openassets.protocol.MarkerOutput.build_script(payload)\n        return bitcoin.core.CTxOut(0, script)", "response": "Creates a marker output."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef authorized(self, request_token):\n        verifier = generate_token(length=self.verifier_length[1])\n        self.save_verifier(request_token, verifier)\n        response = [\n            (u'oauth_token', request_token),\n            (u'oauth_verifier', verifier)\n        ]\n        callback = self.get_callback(request_token)\n        return redirect(add_params_to_uri(callback, response))", "response": "Create a verifier for an authorized client"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a request token for a valid client request.", "response": "def request_token(self):\n        \"\"\"Create an OAuth request token for a valid client request.\n\n        Defaults to /request_token. Invoked by client applications.\n        \"\"\"\n        client_key = request.oauth.client_key\n        realm = request.oauth.realm\n        # TODO: fallback on default realm?\n        callback = request.oauth.callback_uri\n        request_token = generate_token(length=self.request_token_length[1])\n        token_secret = generate_token(length=self.secret_length)\n        self.save_request_token(client_key, request_token, callback,\n            realm=realm, secret=token_secret)\n        return urlencode([(u'oauth_token', request_token),\n                          (u'oauth_token_secret', token_secret),\n                          (u'oauth_callback_confirmed', u'true')])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate an OAuth access token for an authorized client.", "response": "def access_token(self):\n        \"\"\"Create an OAuth access token for an authorized client.\n\n        Defaults to /access_token. Invoked by client applications.\n        \"\"\"\n        access_token = generate_token(length=self.access_token_length[1])\n        token_secret = generate_token(self.secret_length)\n        client_key = request.oauth.client_key\n        self.save_access_token(client_key, access_token,\n            request.oauth.resource_owner_key, secret=token_secret)\n        return urlencode([(u'oauth_token', access_token),\n                          (u'oauth_token_secret', token_secret)])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef require_oauth(self, realm=None, require_resource_owner=True,\n            require_verifier=False, require_realm=False):\n        \"\"\"Mark the view function f as a protected resource\"\"\"\n\n        def decorator(f):\n            @wraps(f)\n            def verify_request(*args, **kwargs):\n                \"\"\"Verify OAuth params before running view function f\"\"\"\n                try:\n                    if request.form:\n                        body = request.form.to_dict()\n                    else:\n                        body = request.data.decode(\"utf-8\")\n                    verify_result = self.verify_request(request.url.decode(\"utf-8\"),\n                            http_method=request.method.decode(\"utf-8\"),\n                            body=body,\n                            headers=request.headers,\n                            require_resource_owner=require_resource_owner,\n                            require_verifier=require_verifier,\n                            require_realm=require_realm or bool(realm),\n                            required_realm=realm)\n                    valid, oauth_request = verify_result\n                    if valid:\n                        request.oauth = self.collect_request_parameters(request)\n\n                        # Request tokens are only valid when a verifier is too\n                        token = {}\n                        if require_verifier:\n                            token[u'request_token'] = request.oauth.resource_owner_key\n                        else:\n                            token[u'access_token'] = request.oauth.resource_owner_key\n\n                        # All nonce/timestamp pairs must be stored to prevent\n                        # replay attacks, they may be connected to a specific\n                        # client and token to decrease collision probability.\n                        self.save_timestamp_and_nonce(request.oauth.client_key,\n                                request.oauth.timestamp, request.oauth.nonce,\n                                **token)\n\n                        # By this point, the request is fully authorized\n                        return f(*args, **kwargs)\n                    else:\n                        # Unauthorized requests should not diclose their cause\n                        raise Unauthorized()\n\n                except ValueError as err:\n                    # Caused by missing of or badly formatted parameters\n                    raise BadRequest(err.message)\n\n            return verify_request\n        return decorator", "response": "Decorator that marks the view function f as a protected resource."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef collect_request_parameters(self, request):\n\n        class OAuthParameters(object):\n            \"\"\"Used as a parameter container since plain object()s can't\"\"\"\n            pass\n\n        # Collect parameters\n        query = urlparse(request.url.decode(\"utf-8\")).query\n        content_type = request.headers.get('Content-Type', '')\n        if request.form:\n            body = request.form.to_dict()\n        elif content_type == 'application/x-www-form-urlencoded':\n            body = request.data.decode(\"utf-8\")\n        else:\n            body = ''\n        headers = dict(encode_params_utf8(request.headers.items()))\n        params = dict(collect_parameters(uri_query=query, body=body, headers=headers))\n\n        # Extract params and store for convenient and predictable access\n        oauth_params = OAuthParameters()\n        oauth_params.client_key = params.get(u'oauth_consumer_key')\n        oauth_params.resource_owner_key = params.get(u'oauth_token', None)\n        oauth_params.nonce = params.get(u'oauth_nonce')\n        oauth_params.timestamp = params.get(u'oauth_timestamp')\n        oauth_params.verifier = params.get(u'oauth_verifier', None)\n        oauth_params.callback_uri = params.get(u'oauth_callback', None)\n        oauth_params.realm = params.get(u'realm', None)\n        return oauth_params", "response": "Collect parameters in an object for convenient access"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a resource size from the RSTB.", "response": "def get_size(self, name: str) -> int:\n        \"\"\"Get a resource size from the RSTB.\"\"\"\n        crc32 = binascii.crc32(name.encode())\n        if crc32 in self.crc32_map:\n            return self.crc32_map[crc32]\n\n        if name in self.name_map:\n            return self.name_map[name]\n\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_size(self, name: str, size: int):\n        if self._needs_to_be_in_name_map(name):\n            if len(name) >= 128:\n                raise ValueError(\"Name is too long\")\n            self.name_map[name] = size\n        else:\n            crc32 = binascii.crc32(name.encode())\n            self.crc32_map[crc32] = size", "response": "Set the size of a resource in the RSTB."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite the RSTB to the specified stream.", "response": "def write(self, stream: typing.BinaryIO, be: bool) -> None:\n        \"\"\"Write the RSTB to the specified stream.\"\"\"\n        stream.write(b'RSTB')\n        stream.write(_to_u32(len(self.crc32_map), be))\n        stream.write(_to_u32(len(self.name_map), be))\n\n        # The CRC32 hashmap *must* be sorted because the game performs a binary search.\n        for crc32, size in sorted(self.crc32_map.items()):\n            stream.write(_to_u32(crc32, be))\n            stream.write(_to_u32(size, be))\n\n        # The name map does not have to be sorted, but Nintendo seems to do it, so let's sort too.\n        for name, size in sorted(self.name_map.items()):\n            stream.write(struct.pack('128s', name.encode()))\n            stream.write(_to_u32(size, be))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef randbytes(nbytes: int) -> bytes:\n    if not isinstance(nbytes, int):\n        raise TypeError('number of bytes shoud be an integer')\n    if nbytes <= 0:\n        raise ValueError('number of bytes must be greater than zero')\n\n    return _urandom(nbytes)", "response": "r Return a random byte string containing * nbytes* bytes."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef randint(nbits: int) -> int:\n    if not isinstance(nbits, int):\n        raise TypeError('number of bits should be an integer')\n    if nbits <= 0:\n        raise ValueError('number of bits must be greater than zero')\n\n    # https://github.com/python/cpython/blob/3.6/Lib/random.py#L676\n    nbytes = (nbits + 7) // 8                       # bits / 8 and rounded up\n    num = int.from_bytes(randbytes(nbytes), 'big')\n    return num >> (nbytes * 8 - nbits)", "response": "Generate an int with nbits random bits."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a randomly chosen element from the given sequence.", "response": "def randchoice(seq: Union[str, list, tuple, dict, set]) -> any:\n    \"\"\"Return a randomly chosen element from the given sequence.\n\n    Raises TypeError if *seq* is not str, list, tuple, dict, set and an\n    IndexError if it is empty.\n\n    >>> randchoice((1, 2, 'a', 'b'))  #doctest:+SKIP\n    'a'\n\n    \"\"\"\n    if not isinstance(seq, (str, list, tuple, dict, set)):\n        raise TypeError('seq must be str, list, tuple, dict or set')\n    if len(seq) <= 0:\n        raise IndexError('seq must have at least one element')\n\n    if isinstance(seq, set):\n        values = list(seq)\n        return randchoice(values)\n    elif isinstance(seq, dict):\n        indexes = list(seq)\n        index = randchoice(indexes)\n    else:\n        index = randbelow(len(seq))\n\n    return seq[index]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef randbelow(num: int) -> int:\n    if not isinstance(num, int):\n        raise TypeError('number must be an integer')\n    if num <= 0:\n        raise ValueError('number must be greater than zero')\n    if num == 1:\n        return 0\n\n    # https://github.com/python/cpython/blob/3.6/Lib/random.py#L223\n    nbits = num.bit_length()    # don't use (n-1) here because n can be 1\n    randnum = random_randint(nbits)    # 0 <= randnum < 2**nbits\n    while randnum >= num:\n        randnum = random_randint(nbits)\n    return randnum", "response": "Return a random int in the range [ 0 num )."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef randbetween(lower: int, upper: int) -> int:\n    if not isinstance(lower, int) or not isinstance(upper, int):\n        raise TypeError('lower and upper must be integers')\n    if lower < 0 or upper <= 0:\n        raise ValueError('lower and upper must be greater than zero')\n\n    return randbelow(upper - lower + 1) + lower", "response": "Return a random int in the range [ lower upper )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef randhex(ndigits: int) -> str:\n    if not isinstance(ndigits, int):\n        raise TypeError('number of digits must be an integer')\n    if ndigits <= 0:\n        raise ValueError('number of digits must be greater than zero')\n\n    nbytes = ceil(ndigits / 2)\n    rbytes = random_randbytes(nbytes)\n    hexstr = rbytes.hex()[:ndigits]\n\n    return hexstr", "response": "Return a random text string of hexadecimal characters."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a dictionary of architectural capstone classes.", "response": "def get_cs_archs(self):\n        ''' capstone disassembler '''\n        cs_archs = {\n            'x16':     (CS_ARCH_X86,     CS_MODE_16),\n            'x86':     (CS_ARCH_X86,     CS_MODE_32),\n            'x64':     (CS_ARCH_X86,     CS_MODE_64),\n            'arm':     (CS_ARCH_ARM,     CS_MODE_ARM),\n            'arm_t':   (CS_ARCH_ARM,     CS_MODE_THUMB),\n            'arm64':   (CS_ARCH_ARM64,   CS_MODE_LITTLE_ENDIAN),\n            'mips32':  (CS_ARCH_MIPS,    CS_MODE_MIPS32),\n            'mips64':  (CS_ARCH_MIPS,    CS_MODE_MIPS64),\n            }\n        return cs_archs"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef default(self, user_input):\n        ''' if no other command was invoked '''\n        try:\n            for i in self._cs.disasm(unhexlify(self.cleanup(user_input)), self.base_address):\n                print(\"0x%08x:\\t%s\\t%s\" %(i.address, i.mnemonic, i.op_str))\n        except CsError as e:\n            print(\"Error: %s\" %e)", "response": "Default command for all the related resources."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setActiveWindow(self, win):\n        self._setProperty('_NET_ACTIVE_WINDOW', [1, X.CurrentTime, win.id],\n                          win)", "response": "Sets the given window active"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the _NET_CLOSE_WINDOW property of the given window object.", "response": "def setCloseWindow(self, win):\n        \"\"\"\n        Close the given window (property _NET_CLOSE_WINDOW)\n\n        :param win: the window object\"\"\"\n        self._setProperty('_NET_CLOSE_WINDOW',\n                          [int(time.mktime(time.localtime())), 1], win)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setMoveResizeWindow(self, win, gravity=0, x=None, y=None, w=None,\n                            h=None):\n        \"\"\"\n        Set the property _NET_MOVERESIZE_WINDOW to move or resize the given\n        window. Flags are automatically calculated if x, y, w or h are defined.\n\n        :param win: the window object\n        :param gravity: gravity (one of the Xlib.X.*Gravity constant or 0)\n        :param x: int or None\n        :param y: int or None\n        :param w: int or None\n        :param h: int or None\n        \"\"\"\n        # indicate source (application)\n        gravity_flags = gravity | 0b0000100000000000\n        if x is None:\n            x = 0\n        else:\n            gravity_flags = gravity_flags | 0b0000010000000000\n        if y is None:\n            y = 0\n        else:\n            gravity_flags = gravity_flags | 0b0000001000000000\n        if w is None:\n            w = 0\n        else:\n            gravity_flags = gravity_flags | 0b0000000100000000\n        if h is None:\n            h = 0\n        else:\n            gravity_flags = gravity_flags | 0b0000000010000000\n        self._setProperty('_NET_MOVERESIZE_WINDOW',\n                          [gravity_flags, x, y, w, h], win)", "response": "Set the _NET_MOVERESIZE_WINDOW property to move or resize the given window."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the state of the WM in the given window.", "response": "def setWmState(self, win, action, state, state2=0):\n        \"\"\"\n        Set/unset one or two state(s) for the given window (property\n        _NET_WM_STATE).\n\n        :param win: the window object\n        :param action: 0 to remove, 1 to add or 2 to toggle state(s)\n        :param state: a state\n        :type state: int or str (see :attr:`NET_WM_STATES`)\n        :param state2: a state or 0\n        :type state2: int or str (see :attr:`NET_WM_STATES`)\n        \"\"\"\n        if type(state) != int:\n            state = self.display.get_atom(state, 1)\n        if type(state2) != int:\n            state2 = self.display.get_atom(state2, 1)\n        self._setProperty('_NET_WM_STATE', [action, state, state2, 1], win)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the list of window types of the given window.", "response": "def getWmWindowType(self, win, str=False):\n        \"\"\"\n        Get the list of window types of the given window (property\n        _NET_WM_WINDOW_TYPE).\n\n        :param win: the window object\n        :param str: True to get a list of string types instead of int\n        :return: list of (int|str)\n        \"\"\"\n        types = self._getProperty('_NET_WM_WINDOW_TYPE', win) or []\n        if not str:\n            return types\n        return [self._getAtomName(t) for t in types]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the list of WM state of the given window.", "response": "def getWmState(self, win, str=False):\n        \"\"\"\n        Get the list of states of the given window (property _NET_WM_STATE).\n\n        :param win: the window object\n        :param str: True to get a list of string states instead of int\n        :return: list of (int|str)\n        \"\"\"\n        states = self._getProperty('_NET_WM_STATE', win) or []\n        if not str:\n            return states\n        return [self._getAtomName(s) for s in states]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the list of allowed actions for the given window.", "response": "def getWmAllowedActions(self, win, str=False):\n        \"\"\"\n        Get the list of allowed actions for the given window (property\n        _NET_WM_ALLOWED_ACTIONS).\n\n        :param win: the window object\n        :param str: True to get a list of string allowed actions instead of int\n        :return: list of (int|str)\n        \"\"\"\n        wAllowedActions = (\n            self._getProperty('_NET_WM_ALLOWED_ACTIONS', win) or [])\n        if not str:\n            return wAllowedActions\n        return [self._getAtomName(a) for a in wAllowedActions]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _setProperty(self, _type, data, win=None, mask=None):\n        if not win:\n            win = self.root\n        if type(data) is str:\n            dataSize = 8\n        else:\n            data = (data+[0]*(5-len(data)))[:5]\n            dataSize = 32\n\n        ev = protocol.event.ClientMessage(\n            window=win,\n            client_type=self.display.get_atom(_type), data=(dataSize, data))\n\n        if not mask:\n            mask = (X.SubstructureRedirectMask | X.SubstructureNotifyMask)\n        self.root.send_event(ev, event_mask=mask)", "response": "Send a ClientMessage event to the root window."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getProperty(self, prop, *args, **kwargs):\n        f = self.__getAttrs.get(prop)\n        if not f:\n            raise KeyError('Unknown readable property: %s' % prop)\n        return f(self, *args, **kwargs)", "response": "Get the value of a property."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef setProperty(self, prop, *args, **kwargs):\n        f = self.__setAttrs.get(prop)\n        if not f:\n            raise KeyError('Unknown writable property: %s' % prop)\n        f(self, *args, **kwargs)", "response": "Set the value of a writable property."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef scoreatpercentile(a, per, limit=(), interpolation_method='fraction',\n        axis=None):\n    \"\"\"\n    Calculate the score at a given percentile of the input sequence.\n\n    For example, the score at `per=50` is the median. If the desired quantile\n    lies between two data points, we interpolate between them, according to\n    the value of `interpolation`. If the parameter `limit` is provided, it\n    should be a tuple (lower, upper) of two values.\n\n    Parameters\n    ----------\n    a : array_like\n        A 1-D array of values from which to extract score.\n    per : array_like\n        Percentile(s) at which to extract score.  Values should be in range\n        [0,100].\n    limit : tuple, optional\n        Tuple of two scalars, the lower and upper limits within which to\n        compute the percentile. Values of `a` outside\n        this (closed) interval will be ignored.\n    interpolation : {'fraction', 'lower', 'higher'}, optional\n        This optional parameter specifies the interpolation method to use,\n        when the desired quantile lies between two data points `i` and `j`\n\n          - fraction: ``i + (j - i) * fraction`` where ``fraction`` is the\n            fractional part of the index surrounded by ``i`` and ``j``.\n          - lower: ``i``.\n          - higher: ``j``.\n\n    axis : int, optional\n        Axis along which the percentiles are computed. The default (None)\n        is to compute the median along a flattened version of the array.\n\n    Returns\n    -------\n    score : float (or sequence of floats)\n        Score at percentile.\n\n    See Also\n    --------\n    percentileofscore\n\n    Examples\n    --------\n    >>> from scipy import stats\n    >>> a = np.arange(100)\n    >>> stats.scoreatpercentile(a, 50)\n    49.5\n\n    \"\"\"\n    # adapted from NumPy's percentile function\n    a = np.asarray(a)\n\n    if limit:\n        a = a[(limit[0] <= a) & (a <= limit[1])]\n\n    if per == 0:\n        return a.min(axis=axis)\n    elif per == 100:\n        return a.max(axis=axis)\n\n    sorted = np.sort(a, axis=axis)\n    if axis is None:\n        axis = 0\n\n    return _compute_qth_percentile(sorted, per, interpolation_method, axis)", "response": "Calculates the score at a given percentile of the input sequence."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef merge_equal_neighbors(self):\n        IDX_LENGTH = 3\n\n        merged = self.segs.copy()\n        current_start = 0\n        j = 0\n        seg = self.segs.iloc[0]\n        for i in range(1, self.num_segments):\n            seg = self.segs.iloc[i]\n            last = self.segs.iloc[i - 1]\n            if seg.speaker == last.speaker:\n                merged.iat[j, IDX_LENGTH] = seg.start + seg.length - current_start\n            else:\n                j += 1\n                merged.iloc[j] = seg\n                current_start = seg.start\n        merged = merged.iloc[:(j+1)]\n        merged.sort_values('start', inplace = True)\n\n        return self.update_segs(merged)", "response": "Merge neighbors with same speaker."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexpanding ~ to path to a user s home folder.", "response": "def expand_user(path):\n    \"\"\"Expands ~/path to /home/<current_user>/path\n\n    On POSIX systems does it by getting the home directory for the\n    current effective user from the passwd database. On other systems\n    do it by using :func:`os.path.expanduser`\n\n    Args:\n        path (str): A path to expand to a user's home folder\n\n    Returns:\n        str: expanded path\n    \"\"\"\n    if not path.startswith('~'):\n        return path\n\n    if os.name == 'posix':\n        user = pwd.getpwuid(os.geteuid())\n        return path.replace('~', user.pw_dir, 1)\n    else:\n        return os.path.expanduser(path)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef format_arguments(*args):\n    positional_args = []\n    kwargs = {}\n    split_key = None\n\n    for arg in args:\n        if arg.startswith('--'):\n            arg = arg[2:]\n\n            if '=' in arg:\n                key, value = arg.split('=', 1)\n                kwargs[key.replace('-', '_')] = value\n            else:\n                split_key = arg.replace('-', '_')\n        elif split_key:\n            kwargs[split_key] = arg\n            split_key = None\n        else:\n            positional_args.append(arg)\n\n    return positional_args, kwargs", "response": "Converts a list of arguments from the command line into a list of positional arguments and a dictionary of keyword arguments."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a gocd_cli. settings. Settings instance for the specified section.", "response": "def get_settings(section='gocd', settings_paths=('~/.gocd/gocd-cli.cfg', '/etc/go/gocd-cli.cfg')):\n    \"\"\"Returns a `gocd_cli.settings.Settings` configured for settings file\n\n    The settings will be read from environment variables first, then\n    it'll be read from the first config file found (if any).\n\n    Environment variables are expected to be in UPPERCASE and to be prefixed\n    with `GOCD_`.\n\n    Args:\n      section: The prefix to use for reading environment variables and the\n        name of the section in the config file. Default: gocd\n      settings_path: Possible paths for the configuration file.\n        Default: `('~/.gocd/gocd-cli.cfg', '/etc/go/gocd-cli.cfg')`\n\n    Returns:\n        `gocd_cli.settings.Settings` instance\n    \"\"\"\n    if isinstance(settings_paths, basestring):\n        settings_paths = (settings_paths,)\n\n    config_file = next((path for path in settings_paths if is_file_readable(path)), None)\n    if config_file:\n        config_file = expand_user(config_file)\n\n    return Settings(prefix=section, section=section, filename=config_file)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a gocd. Server configured by the settings object.", "response": "def get_go_server(settings=None):\n    \"\"\"Returns a `gocd.Server` configured by the `settings`\n    object.\n\n    Args:\n      settings: a `gocd_cli.settings.Settings` object.\n        Default: if falsey calls `get_settings`.\n\n    Returns:\n      gocd.Server: a configured gocd.Server instance\n    \"\"\"\n    if not settings:\n        settings = get_settings()\n\n    return gocd.Server(\n        settings.get('server'),\n        user=settings.get('user'),\n        password=settings.get('password'),\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the standard tab completions.", "response": "def _get_standard_tc_matches(text, full_text, options):\n    '''\n    get the standard tab completions.\n    These are the options which could complete the full_text.\n    '''\n    final_matches = [o for o in options if o.startswith(full_text)]\n    return final_matches"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_fuzzy_tc_matches(text, full_text, options):\n    '''\n    Get the options that match the full text, then from each option\n    return only the individual words which have not yet been matched\n    which also match the text being tab-completed.\n    '''\n    print(\"text: {}, full: {}, options: {}\".format(text, full_text, options))\n    # get the options which match the full text\n    matching_options = _get_fuzzy_matches(full_text, options)\n    # need to only return the individual words which:\n    # - match the 'text'\n    # - are not exclusively matched by other input in full_text\n    # - when matched, still allows all other input in full_text to be matched\n    # get the input tokens\n    input_tokens = full_text.split()\n    # remove one instance of the text to be matched\n    initial_tokens = input_tokens.remove(text)\n    # track the final matches:\n    final_matches = []\n    # find matches per option\n    for option in options:\n        option_tokens = option.split()\n        # get tokens which match the text\n        matches = [t for t in option_tokens if text in t]\n        # get input tokens which match one of the matches\n        input_tokens_which_match = [t for t in input_tokens for m in matches if t in m]\n        # if any input token ONLY matches a match, remove that match\n        for token in input_tokens_which_match:\n            token_matches = [t for t in option_tokens if token in t]\n            if len(token_matches) == 1:\n                match = token_matches[0]\n                if match in matches:\n                    matches.remove(match)\n        # for the remaining matches, if the input tokens can be fuzzily matched without\n        # the match, it's ok to return it.\n        for match in matches:\n            # copy option tokens\n            option_tokens_minus_match = option_tokens[:]\n            # remove the match\n            option_tokens_minus_match.remove(match)\n            option_minus_match = ' '.join(option_tokens_minus_match)\n            if _get_fuzzy_matches(' '.join(input_tokens), [option_minus_match]):\n                if match not in final_matches:\n                    final_matches.append(match)\n    return final_matches", "response": "Get the options that match the full text and return only the individual words which are not yet been matched by other input in the full_text."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _tab_complete_init(items, post_prompt, insensitive, fuzzy, stream):\n    '''Create and use a tab-completer object'''\n    # using some sort of nested-scope construct is\n    # required because readline doesn't pass the necessary args to\n    # its callback functions\n    def _get_matches(text, state):\n        '''\n        Get a valid match, given:\n            text - the portion of text currently trying to complete\n            state - the index 0..inf which is an index into the list\n            of valid matches.\n        Put another way, given the text, this function is supposed\n        to return matches_for(text)[state], where 'matches_for' returns\n        the matches for the text from the options.\n        '''\n        # a copy of all the valid options\n        options = [o for o in items]\n        # the full user-entered text\n        full_text = _readline.get_line_buffer()\n        # insensitivity\n        if insensitive:\n            options = [o.lower() for o in options]\n            text = text.lower()\n            full_text = full_text.lower()\n        # matches\n        matches = []\n        try:\n            # get matches\n            if fuzzy:\n                # space-delimited - match words\n                _readline.set_completer_delims(' ')\n                matches = _get_fuzzy_tc_matches(text, full_text, options)\n            else:\n                # not delimited - match the whole text\n                _readline.set_completer_delims('')\n                matches = _get_standard_tc_matches(text, full_text, options)\n            # re-sensitization not necessary - this completes what's on\n            # the command prompt.  If the search is insensitive, then\n            # a lower-case entry will match as well as an original-case\n            # entry.\n        except Exception:\n            # try/catch is for debugging only.  The readline\n            # lib swallows exceptions and just doesn't print anything\n            import traceback as _traceback\n            print(_traceback.format_exc())\n            raise\n        return matches[state]\n\n    def _completion_display(substitution, matches, length):\n        '''\n        Display the matches for the substitution, which is the\n        text being completed.\n        '''\n        try:\n            response = substitution\n            stream.write(\"\\n[!] \\\"{response}\\\" matches multiple options:\\n\".format(\n                response=response\n            ))\n            if fuzzy:\n                if insensitive:\n                    ordered_matches = [o for o in items if substitution in o.lower()]\n                else:\n                    ordered_matches = [o for o in items if substitution in o]\n            else:\n                if insensitive:\n                    ordered_matches = [o for o in items if o.lower().startswith(substitution)]\n                else:\n                    ordered_matches = [o for o in items if o.startswith(substitution)]\n            for match in ordered_matches:\n                stream.write(\"[!]   {}\\n\".format(match))\n            stream.write(\"[!] Please specify your choice further.\\n\")\n            # the full user-entered text\n            full_text = _readline.get_line_buffer()\n            stream.write(post_prompt + full_text)\n            stream.flush()\n        except Exception:\n            # try/catch is for debugging only.  The readline\n            # lib swallows exceptions and just doesn't print anything\n            #import traceback as _traceback\n            #print(_traceback.format_exc())\n            raise\n\n    # activate tab completion\n    # got libedit bit from:\n    # https://stackoverflow.com/a/7116997\n    # -----------------------------------\n    if \"libedit\" in _readline.__doc__:\n        # tabcompletion init for libedit\n        _readline.parse_and_bind(\"bind ^I rl_complete\")\n    else:\n        # tabcompletion init for actual readline\n        _readline.parse_and_bind(\"tab: complete\")\n    # -----------------------------------\n    # set the function that will actually provide the valid completions\n    _readline.set_completer(_get_matches)\n    # set the function that will display the valid completions\n    _readline.set_completion_display_matches_hook(_completion_display)", "response": "Create and use a tab - completer object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _prompt(pre_prompt, items, post_prompt, default, indexed, stream):\n    '''\n    Prompt once.\n    If you want the default displayed, put a format {} into the\n    post_prompt string (like 'select one [{}]: ')\n    '''\n    # try to sub in the default if provided\n    if default is not None:\n        if '{}' in pre_prompt:\n            pre_prompt = pre_prompt.format(default)\n        if '{}' in post_prompt:\n            post_prompt = post_prompt.format(default)\n    # build the item strings\n    item_format = \"{indent}{item}\"\n    if indexed:\n        item_format = \"{indent}[{index}] {item}\"\n    item_text_list = []\n    indent = '  '\n    for index, item in enumerate(items):\n        item_text = ''\n        components = {\n            'indent': indent,\n            'item': item\n        }\n        if indexed:\n            components['index'] = index\n        item_text = item_format.format(**components)\n        item_text_list.append(item_text)\n    # build full menu\n    menu_parts = [pre_prompt] + item_text_list\n    full_menu = '\\n'.join(menu_parts) + '\\n'\n    stream.write(full_menu)\n    stream.flush()\n    # Get user response\n    # - py 2/3 compatibility\n    get_input = input\n    try:\n        get_input = raw_input\n    except NameError:\n        pass\n    # - actuall get input\n    response = get_input(post_prompt)\n    return response", "response": "Prompt one. The prompt is done once. The prompt is done once. The prompt is done once. The prompt is done once."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _fuzzily_matches(response, candidate):\n    '''return True if response fuzzily matches candidate'''\n    r_words = response.split()\n    c_words = candidate.split()\n    # match whole words first\n    for word in r_words:\n        if word in c_words:\n            r_words.remove(word)\n            c_words.remove(word)\n    # match partial words, fewest matches first\n    match_pairs = []\n    for partial in sorted(r_words, key=lambda p: len(p), reverse=True):\n        matches = [w for w in c_words if partial in w]\n        match_pairs.append((partial, matches))\n    # if all items can be uniquly matched, the match is passed\n    while len(match_pairs):\n        min_pair = min(match_pairs, key=lambda x:len(x[1]))\n        # this is the partial and matches with the shortest match list\n        # if there are ever no matches for something, the match is failed\n        if len(min_pair[1]) == 0:\n            return False\n        # choose the match with the fewest matches to remaining partials.\n        # that way we leave more options for more partials, for the best\n        # chance of a full match\n        partials_left = [p[0] for p in match_pairs]\n        min_option = min(min_pair[1], key=lambda x:len([p for p in partials_left if x in p]))\n        # remove the current pair - we've matched it now\n        match_pairs.remove(min_pair)\n        # remove the matched option from all pairs' options so it won't be matched again\n        for pair in match_pairs:\n            pair_options = pair[1]\n            if min_option in pair_options:\n                pair_options.remove(min_option)\n    # if all the items in the response were matched, this is match\n    return True", "response": "return True if response fuzzily matches candidate"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _exact_fuzzy_match(response, match, insensitive):\n    '''\n    Return True if the response matches fuzzily exactly.\n    Insensitivity is taken into account.\n    '''\n    if insensitive:\n        response = response.lower()\n        match = match.lower()\n    r_words = response.split()\n    m_words = match.split()\n    # match whole words first\n    for word in r_words:\n        if word in m_words:\n            r_words.remove(word)\n            m_words.remove(word)\n    # no partial matches allowed\n    # if all the items in the response were matched,\n    # and all the items in the match were matched,\n    # then this is an exact fuzzy match\n    return len(r_words) == 0 and len(m_words) == 0", "response": "Return True if the response matches fuzzily exactly."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning an exact match for the given response.", "response": "def _exact_match(response, matches, insensitive, fuzzy):\n    '''\n    returns an exact match, if it exists, given parameters\n    for the match\n    '''\n    for match in matches:\n        if response == match:\n            return match\n        elif insensitive and response.lower() == match.lower():\n            return match\n        elif fuzzy and _exact_fuzzy_match(response, match, insensitive):\n            return match\n    else:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck the response against the items.", "response": "def _check_response(response, items, default, indexed, stream, insensitive, fuzzy):\n    '''Check the response against the items'''\n    # Set selection\n    selection = None\n    # if indexed, check for index\n    if indexed:\n        if response.isdigit():\n            index_response = int(response)\n            if index_response < len(items):\n                selection = items[index_response]\n    # if not matched by an index, match by text\n    if selection is None:\n        # insensivitize, if necessary\n        original_items = items[:]\n        original_response = response\n        if insensitive:\n            response = response.lower()\n            items = [i.lower() for i in items]\n        # Check for text matches\n        if fuzzy:\n            matches = _get_fuzzy_matches(response, items)\n        # if insensitive, lowercase the comparison\n        else:\n            matches = [i for i in items if i.startswith(response)]\n        # re-sensivitize if necessary\n        if insensitive:\n            matches = [\n                i for i in original_items\n                if i.lower() in matches\n            ]\n            response = original_response\n        num_matches = len(matches)\n        # Empty response, no default\n        if response == '' and default is None:\n            stream.write(\"[!] an empty response is not valid.\\n\")\n        elif response == '':\n            selection = default\n        # Bad response\n        elif num_matches == 0:\n            stream.write(\"[!] \\\"{response}\\\" does not match any of the valid choices.\\n\".format(\n                response=response\n            ))\n        # One match\n        elif num_matches == 1:\n            selection = matches[0]\n        # Multiple matches\n        else:\n            # look for an exact match\n            selection = _exact_match(response, matches, insensitive, fuzzy)\n            # Multiple matches left\n            if selection is None:\n                stream.write(\"[!] \\\"{response}\\\" matches multiple choices:\\n\".format(\n                    response=response\n                ))\n                for match in matches:\n                    stream.write(\"[!]   {}\\n\".format(match))\n                stream.write(\"[!] Please specify your choice further.\\n\")\n    return selection"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck that the prompts are strings", "response": "def _check_prompts(pre_prompt, post_prompt):\n    '''Check that the prompts are strings'''\n    if not isinstance(pre_prompt, str):\n        raise TypeError(\"The pre_prompt was not a string!\")\n    if post_prompt is not _NO_ARG and not isinstance(post_prompt, str):\n        raise TypeError(\"The post_prompt was given and was not a string!\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _check_items(items):\n    '''\n    Check:\n     - that the list of items is iterable and finite.\n     - that the list is not empty\n    '''\n    num_items = 0\n    # Check that the list is iterable and finite\n    try:\n        num_items = len(items)\n    except:\n        raise TypeError(\"The item list ({}) is not a finite iterable (has no length)\".format(items))\n    # Check that the list has items\n    if num_items == 0:\n        raise ValueError(\"The item list is empty.\")", "response": "Check that the items in the item list is iterable and not empty."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks that the default is in the list and not empty.", "response": "def _check_default_index(items, default_index):\n    '''Check that the default is in the list, and not empty'''\n    num_items = len(items)\n    if default_index is not None and not isinstance(default_index, int):\n        raise TypeError(\"The default index ({}) is not an integer\".format(default_index))\n    if default_index is not None and default_index >= num_items:\n        raise ValueError(\"The default index ({}) >= length of the list ({})\".format(default_index, num_items))\n    if default_index is not None and default_index < 0:\n        raise ValueError(\"The default index ({}) < 0.\".format(default_index))\n    if default_index is not None and not items[default_index]:\n        raise ValueError(\"The default index ({}) points to an empty item.\".format(default_index))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _check_stream(stream):\n    '''Check that the stream is a file'''\n    if not isinstance(stream, type(_sys.stderr)):\n        raise TypeError(\"The stream given ({}) is not a file object.\".format(stream))", "response": "Check that the stream is a file object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _dedup(items, insensitive):\n    '''\n    Deduplicate an item list, and preserve order.\n\n    For case-insensitive lists, drop items if they case-insensitively match\n    a prior item.\n    '''\n    deduped = []\n    if insensitive:\n        i_deduped = []\n        for item in items:\n            lowered = item.lower()\n            if lowered not in i_deduped:\n                deduped.append(item)\n                i_deduped.append(lowered)\n    else:\n        for item in items:\n            if item not in deduped:\n                deduped.append(item)\n    return deduped", "response": "Deduplicate an item list and preserve order."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprompt the user to enter a menu for the items in the list.", "response": "def menu(items, pre_prompt=\"Options:\", post_prompt=_NO_ARG, default_index=None, indexed=False,\n         stream=_sys.stderr, insensitive=False, fuzzy=False, quiet=False):\n    '''\n    Prompt with a menu.\n\n    Arguments:\n        pre_prompt -  Text to print before the option list.\n        items -  The items to print as options.\n        post_prompt -  Text to print after the option list.\n        default_index -  The index of the item which should be default, if any.\n        indexed -  Boolean.  True if the options should be indexed.\n        stream -  the stream to use to prompt the user.  Defaults to stderr so that stdout\n            can be reserved for program output rather than interactive menu output.\n        insensitive -  allow insensitive matching.  Also drops items which case-insensitively match\n          prior items.\n        fuzzy -  search for the individual words in the user input anywhere in the item strings.\n\n    Specifying a default index:\n        The default index must index into the items.  In other words, `items[default_index]`\n        must exist.  It is encouraged, but not required, that you show the user that there is\n        a default, and what it is, via string interpolation in either of the prompts:\n            \"prompt [{}]\" as the prompt string will print \"prompt [default]\" if \"default\" were\n            the value of the item at the default index.\n\n    The default post-prompt:\n        The default post prompt is different depending on whether or not you provide a default_index.\n        If you don't, the prompt is just \"Enter an option to continue: \".\n        If you do, the prompt adds the default value: \"Enter an option to continue [{}]: \"\n\n    Return:\n        result -  The full text of the unambiguously selected item.\n    '''\n    # arg checking\n    _check_prompts(pre_prompt, post_prompt)\n    _check_items(items)\n    _check_default_index(items, default_index)\n    _check_stream(stream)\n    # arg mapping\n    # - Fill in post-prompt dynamically if no arg\n    actual_post_prompt = post_prompt\n    if post_prompt is _NO_ARG:\n        if default_index is None:\n            actual_post_prompt = \"Enter an option to continue: \"\n        else:\n            actual_post_prompt = \"Enter an option to continue [{}]: \"\n    # - convert items to rstripped strings\n    items = [str(i).rstrip() for i in items]\n    # - set the default argument\n    default = None\n    if default_index is not None:\n        default = items[default_index]\n    # - deduplicate items\n    items = _dedup(items, insensitive)\n    # - remove empty options\n    items = [i for i in items if i]\n    # - re-check the items\n    _check_items(items)\n    # other state init\n    acceptable_response_given = False\n    if _readline is None:\n        stream.write('[!] readline library not present - tab completion not available\\n')\n        stream.write('[!] readline library not present - arrow support not available\\n')\n    elif not stream.isatty():\n        stream.write('[!] output stream is not interactive - tab completion not available\\n')\n        stream.write('[!] output stream is not interactive - arrow support not available\\n')\n    elif _sys.version_info.major == 3 and stream is not _sys.stdout:\n        stream.write('[!] python3 input bug (issue24402) - tab completion not available\\n')\n        stream.write('[!] python3 input bug (issue24402) - arrow support not available\\n')\n        stream.write('[!] set sys.stdout as the stream to work around\\n')\n    else:\n        _tab_complete_init(items, actual_post_prompt, insensitive, fuzzy, stream)\n    # Set both stdout and stderr to the stream selected.\n    # - in py2, raw_input uses sys.stdout\n    # - in py3, input uses a lower-level stdout stream which is not redirectable.\n    #   - there is an open bug for this, scheduled to be resolved in py3.6 (https://bugs.python.org/issue24402)\n    # [raw_]input uses readline to do fancy things like tab completion, and also like reprinting the user\n    # text on the cli when you type.  If we don't redirect the output streams, [raw_]input will always use\n    # the default (stdout) even though most of the time we want stderr for interactive prompts.  we could just\n    # print the prompt ourselves (and not let [raw_]input do so), but only when we control reprinting (which\n    # we don't always for tab completion), and even then, if the user backspaces into the prompt, [raw_]input\n    # would reprint the line itself, erasing the prompt it doesn't know about.  (see issue #70)\n    try:\n        _old_stdout = _sys.stdout\n        _old_stderr = _sys.stderr\n        # only overwrite the stream if we need to, due to the python3 issue\n        if stream is _sys.stdout:\n            pass\n        else:\n            _sys.stdout = stream\n        # Prompt Loop\n        # - wait until an acceptable response has been given\n        while not acceptable_response_given:\n            selection = None\n            # Prompt and get response\n            response = _prompt(pre_prompt, items, actual_post_prompt, default, indexed, stream)\n            # validate response\n            selection = _check_response(response, items, default, indexed, stream, insensitive, fuzzy)\n            # NOTE: acceptable response logic is purposely verbose to be clear about the semantics.\n            if selection is not None:\n                acceptable_response_given = True\n    finally:\n        _sys.stdout = _old_stdout\n        _sys.stderr = _old_stderr\n    return selection"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef require_openid(f):\n    @wraps(f)\n    def decorator(*args, **kwargs):\n        if g.user is None:\n            next_url = url_for(\"login\") + \"?next=\" + request.url\n            return redirect(next_url)\n        else:\n            return f(*args, **kwargs)\n    return decorator", "response": "Decorator that allows the user to be logged in."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef login():\n    # if we are already logged in, go back to were we came from\n    if g.user is not None:\n        return redirect(oid.get_next_url())\n    if request.method == 'POST':\n        openid = request.form.get('openid')\n        if openid:\n            return oid.try_login(openid, ask_for=['email', 'fullname',\n                                                  'nickname'])\n    return render_template('login.html', next=oid.get_next_url(),\n                           error=oid.fetch_error())", "response": "Does the login via OpenID."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_or_login(resp):\n    session['openid'] = resp.identity_url\n    user = User.query.filter_by(openid=resp.identity_url).first()\n    if user is not None:\n        flash(u'Successfully signed in')\n        g.user = user\n        return redirect(oid.get_next_url())\n    return redirect(url_for('create_profile', next=oid.get_next_url(),\n                            name=resp.fullname or resp.nickname,\n                            email=resp.email))", "response": "This function is called when login with OpenID succeeded and it s not necessary to figure out if this is the users s first login or not."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_output(self, transaction_hash, output_index):\n        cached_output = yield from self._cache.get(transaction_hash, output_index)\n\n        if cached_output is not None:\n            return cached_output\n\n        transaction = yield from self._transaction_provider(transaction_hash)\n\n        if transaction is None:\n            raise ValueError('Transaction {0} could not be retrieved'.format(bitcoin.core.b2lx(transaction_hash)))\n\n        colored_outputs = yield from self.color_transaction(transaction)\n\n        for index, output in enumerate(colored_outputs):\n            yield from self._cache.put(transaction_hash, index, output)\n\n        return colored_outputs[output_index]", "response": "Gets an output and information about its asset ID and asset quantity."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef color_transaction(self, transaction):\n        # If the transaction is a coinbase transaction, the marker output is always invalid\n        if not transaction.is_coinbase():\n            for i, output in enumerate(transaction.vout):\n                # Parse the OP_RETURN script\n                marker_output_payload = MarkerOutput.parse_script(output.scriptPubKey)\n\n                if marker_output_payload is not None:\n                    # Deserialize the payload as a marker output\n                    marker_output = MarkerOutput.deserialize_payload(marker_output_payload)\n\n                    if marker_output is not None:\n                        # Fetch the colored outputs for previous transactions\n                        inputs = []\n                        for input in transaction.vin:\n                            inputs.append((yield from asyncio.async(\n                                self.get_output(input.prevout.hash, input.prevout.n), loop=self._loop)))\n\n                        asset_ids = self._compute_asset_ids(\n                            inputs,\n                            i,\n                            transaction.vout,\n                            marker_output.asset_quantities)\n\n                        if asset_ids is not None:\n                            return asset_ids\n\n        # If no valid marker output was found in the transaction, all outputs are considered uncolored\n        return [\n            TransactionOutput(output.nValue, output.scriptPubKey, None, 0, OutputType.uncolored)\n            for output in transaction.vout]", "response": "Computes the asset ID and asset quantity of every output in the transaction."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _compute_asset_ids(cls, inputs, marker_output_index, outputs, asset_quantities):\n        # If there are more items in the asset quantities list than outputs in the transaction (excluding the\n        # marker output), the marker output is deemed invalid\n        if len(asset_quantities) > len(outputs) - 1:\n            return None\n\n        # If there is no input in the transaction, the marker output is always invalid\n        if len(inputs) == 0:\n            return None\n\n        result = []\n\n        # Add the issuance outputs\n        issuance_asset_id = cls.hash_script(bytes(inputs[0].script))\n\n        for i in range(0, marker_output_index):\n            value, script = outputs[i].nValue, outputs[i].scriptPubKey\n            if i < len(asset_quantities) and asset_quantities[i] > 0:\n                output = TransactionOutput(value, script, issuance_asset_id, asset_quantities[i], OutputType.issuance)\n            else:\n                output = TransactionOutput(value, script, None, 0, OutputType.issuance)\n\n            result.append(output)\n\n        # Add the marker output\n        issuance_output = outputs[marker_output_index]\n        result.append(TransactionOutput(\n            issuance_output.nValue, issuance_output.scriptPubKey, None, 0, OutputType.marker_output))\n\n        # Add the transfer outputs\n        input_iterator = iter(inputs)\n        input_units_left = 0\n        for i in range(marker_output_index + 1, len(outputs)):\n            if i <= len(asset_quantities):\n                output_asset_quantity = asset_quantities[i - 1]\n            else:\n                output_asset_quantity = 0\n\n            output_units_left = output_asset_quantity\n            asset_id = None\n\n            while output_units_left > 0:\n\n                # Move to the next input if the current one is depleted\n                if input_units_left == 0:\n                    current_input = next(input_iterator, None)\n                    if current_input is None:\n                        # There are less asset units available in the input than in the outputs:\n                        # the marker output is considered invalid\n                        return None\n                    else:\n                        input_units_left = current_input.asset_quantity\n\n                # If the current input is colored, assign its asset ID to the current output\n                if current_input.asset_id is not None:\n                    progress = min(input_units_left, output_units_left)\n                    output_units_left -= progress\n                    input_units_left -= progress\n\n                    if asset_id is None:\n                        # This is the first input to map to this output\n                        asset_id = current_input.asset_id\n                    elif asset_id != current_input.asset_id:\n                        # Another different asset ID has already been assigned to that output:\n                        # the marker output is considered invalid\n                        return None\n\n            result.append(TransactionOutput(\n                outputs[i].nValue, outputs[i].scriptPubKey, asset_id, output_asset_quantity, OutputType.transfer))\n\n        return result", "response": "Computes the asset IDs of every output in a transaction."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhashing a script into an asset ID using SHA256 followed by RIPEMD160.", "response": "def hash_script(data):\n        \"\"\"\n        Hashes a script into an asset ID using SHA256 followed by RIPEMD160.\n\n        :param bytes data: The data to hash.\n        \"\"\"\n        sha256 = hashlib.sha256()\n        ripemd = hashlib.new('ripemd160')\n\n        sha256.update(data)\n        ripemd.update(sha256.digest())\n        return ripemd.digest()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef deserialize_payload(cls, payload):\n        with io.BytesIO(payload) as stream:\n\n            # The OAP marker and protocol version\n            oa_version = stream.read(4)\n            if oa_version != cls.OPEN_ASSETS_TAG:\n                return None\n\n            try:\n                # Deserialize the expected number of items in the asset quantity list\n                output_count = bitcoin.core.VarIntSerializer.stream_deserialize(stream)\n\n                # LEB128-encoded unsigned integers representing the asset quantity of every output in order\n                asset_quantities = []\n                for i in range(0, output_count):\n                    asset_quantity = cls.leb128_decode(stream)\n\n                    # If the LEB128-encoded asset quantity of any output exceeds 9 bytes,\n                    # the marker output is deemed invalid\n                    if asset_quantity > cls.MAX_ASSET_QUANTITY:\n                        return None\n\n                    asset_quantities.append(asset_quantity)\n\n                # The var-integer encoded length of the  metadata field.\n                metadata_length = bitcoin.core.VarIntSerializer.stream_deserialize(stream)\n\n                # The actual metadata\n                metadata = stream.read(metadata_length)\n\n                # If the metadata string wasn't long enough, the marker output is malformed\n                if len(metadata) != metadata_length:\n                    return None\n\n                # If there are bytes left to read, the marker output is malformed\n                last_byte = stream.read(1)\n                if len(last_byte) > 0:\n                    return None\n\n            except bitcoin.core.SerializationTruncationError:\n                return None\n\n            return MarkerOutput(asset_quantities, metadata)", "response": "Deserializes the marker output payload."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef serialize_payload(self):\n        with io.BytesIO() as stream:\n            stream.write(self.OPEN_ASSETS_TAG)\n\n            bitcoin.core.VarIntSerializer.stream_serialize(len(self.asset_quantities), stream)\n            for asset_quantity in self.asset_quantities:\n                stream.write(self.leb128_encode(asset_quantity))\n\n            bitcoin.core.VarIntSerializer.stream_serialize(len(self.metadata), stream)\n\n            stream.write(self.metadata)\n\n            return stream.getvalue()", "response": "Serializes the marker output data into a payload buffer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing an output script and returns the payload if the output fits the right pattern for a marker output.", "response": "def parse_script(output_script):\n        \"\"\"\n        Parses an output and returns the payload if the output matches the right pattern for a marker output,\n        or None otherwise.\n\n        :param CScript output_script: The output script to be parsed.\n        :return: The marker output payload if the output fits the pattern, None otherwise.\n        :rtype: bytes\n        \"\"\"\n        script_iterator = output_script.raw_iter()\n\n        try:\n            first_opcode, _, _ = next(script_iterator, (None, None, None))\n            _, data, _ = next(script_iterator, (None, None, None))\n            remainder = next(script_iterator, None)\n        except bitcoin.core.script.CScriptTruncatedPushDataError:\n            return None\n        except bitcoin.core.script.CScriptInvalidError:\n            return None\n\n        if first_opcode == bitcoin.core.script.OP_RETURN and data is not None and remainder is None:\n            return data\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef build_script(data):\n        return bitcoin.core.script.CScript(\n            bytes([bitcoin.core.script.OP_RETURN]) + bitcoin.core.script.CScriptOp.encode_op_pushdata(data))", "response": "Builds an output script containing an OP_RETURN and PUSHDATA."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndecode a LEB128 - encoded unsigned integer.", "response": "def leb128_decode(data):\n        \"\"\"\n        Decodes a LEB128-encoded unsigned integer.\n\n        :param BufferedIOBase data: The buffer containing the LEB128-encoded integer to decode.\n        :return: The decoded integer.\n        :rtype: int\n        \"\"\"\n        result = 0\n        shift = 0\n\n        while True:\n            character = data.read(1)\n            if len(character) == 0:\n                raise bitcoin.core.SerializationTruncationError('Invalid LEB128 integer')\n\n            b = ord(character)\n            result |= (b & 0x7f) << shift\n            if b & 0x80 == 0:\n                break\n            shift += 7\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nencode an integer using LEB128.", "response": "def leb128_encode(value):\n        \"\"\"\n        Encodes an integer using LEB128.\n\n        :param int value: The value to encode.\n        :return: The LEB128-encoded integer.\n        :rtype: bytes\n        \"\"\"\n        if value == 0:\n            return b'\\x00'\n\n        result = []\n        while value != 0:\n            byte = value & 0x7f\n            value >>= 7\n            if value != 0:\n                byte |= 0x80\n            result.append(byte)\n\n        return bytes(result)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend a packet to the Hack API.", "response": "def _send_packet(self, packet):\n        \"\"\"Sends <packet> (<dict>) to https://hack.chat.\"\"\"\n        encoded = json.dumps(packet)\n        self.ws.send(encoded)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend data to the callback functions.", "response": "def run(self):\n        \"\"\"Sends data to the callback functions.\"\"\"\n        while True:\n            result = json.loads(self.ws.recv())\n            if result[\"cmd\"] == \"chat\" and not result[\"nick\"] == self.nick:\n                for handler in list(self.on_message):\n                    handler(self, result[\"text\"], result[\"nick\"])\n            elif result[\"cmd\"] == \"onlineAdd\":\n                self.online_users.append(result[\"nick\"])\n                for handler in list(self.on_join):\n                    handler(self, result[\"nick\"])\n            elif result[\"cmd\"] == \"onlineRemove\":\n                self.online_users.remove(result[\"nick\"])\n                for handler in list(self.on_leave):\n                    handler(self, result[\"nick\"])\n            elif result[\"cmd\"] == \"onlineSet\":\n                for nick in result[\"nicks\"]:\n                    self.online_users.append(nick)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef do_setmode(self, arg):\n        ''' shift from ASM to DISASM '''\n        op_modes = config.get_op_modes()\n        if arg in op_modes:\n            op_mode = op_modes[arg]\n            op_mode.cmdloop()\n        else:\n            print(\"Error: unknown operational mode, please use 'help setmode'.\")", "response": "set mode of the resource"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a symbol with key name to scipy. Model. symbols.", "response": "def add_symbol(self, name, string=None):\n        \"\"\"\n        Add a symbol with key `name` to `scipy_data_fitting.Model.symbols`.\n        Optionally, specify an alternative `string` to pass to [`sympy.Symbol`][1],\n        otherwise `name` is used.\n\n        [1]: http://docs.sympy.org/dev/modules/core.html#id4\n        \"\"\"\n        if not string: string = name\n        self.symbols[name] = sympy.Symbol(string)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef lambdify(self, expression, symbols, **kwargs):\n        if isinstance(expression, str):\n            expression = self.expressions[expression]\n\n        if hasattr(symbols, '__iter__'):\n            variables = []\n            for s in symbols:\n                if isinstance(s, str):\n                    variables.append(self.symbol(s))\n                else:\n                    variables.append(s)\n        else:\n            if isinstance(symbols, str):\n                variables = (self.symbol(symbols), )\n            else:\n                variables = (symbols, )\n\n        return sympy.lambdify(tuple(variables), expression, **kwargs)", "response": "Converts a SymPy expression into a function using sympy. lambdify."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadvance to the next token.", "response": "def _forward(self):\n        \"\"\"Advance to the next token.\n\n        Internal methods, updates:\n        - self.current_token\n        - self.current_pos\n\n        Raises:\n            MissingTokensError: when trying to advance beyond the end of the\n                token flow.\n        \"\"\"\n        try:\n            self.current_token = next(self.tokens)\n        except StopIteration:\n            raise MissingTokensError(\"Unexpected end of token stream at %d.\" %\n                self.current_pos)\n        self.current_pos += 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef consume(self, expect_class=None):\n        if expect_class and not isinstance(self.current_token, expect_class):\n            raise InvalidTokenError(\"Unexpected token at %d: got %r, expected %s\" % (\n                self.current_pos, self.current_token, expect_class.__name__))\n\n        current_token = self.current_token\n        self._forward()\n        return current_token", "response": "Retrieve the current token then advance the parser."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef expression(self, rbp=0):\n        prev_token = self.consume()\n\n        # Retrieve the value from the previous token situated at the\n        # leftmost point in the expression\n        left = prev_token.nud(context=self)\n\n        while rbp < self.current_token.lbp:\n            # Read incoming tokens with a higher 'left binding power'.\n            # Those are tokens that prefer binding to the left of an expression\n            # than to the right of an expression.\n            prev_token = self.consume()\n            left = prev_token.led(left, context=self)\n\n        return left", "response": "Extract an expression from the flow of tokens."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse the flow of tokens and return their evaluation.", "response": "def parse(self):\n        \"\"\"Parse the flow of tokens, and return their evaluation.\"\"\"\n        expr = self.expression()\n        if not isinstance(self.current_token, EndToken):\n            raise InvalidTokenError(\"Unconsumed trailing tokens.\")\n        return expr"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_constant(value):\n    if type(value) is str:\n        if hasattr(scipy.constants, value):\n            return getattr(scipy.constants, value)\n        else:\n            return scipy.constants.physical_constants[value][0]\n    else:\n        return value", "response": "Get the corresponding constant from the specified value."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the cached value for the given arguments or the ellipsis if the key is not present.", "response": "def get_cached_value(self, *args, **kwargs):\n        \"\"\"\n        :returns: The cached value or ``Ellipsis``\n        \"\"\"\n        key = self.get_cache_key(*args, **kwargs)\n        logger.debug(key)\n        return self.cache.get(key, default=Ellipsis)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the cached value for the given key.", "response": "def set_cached_value(self, *args, **kwargs):\n        \"\"\"\n        Sets the cached value\n        \"\"\"\n        key = self.get_cache_key(*args, **kwargs)\n        logger.debug(key)\n        return namedtuple('Settable', ['to'])(lambda value: self.cache.set(key, value))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_users(arguments):\n    import coil.init\n    u = coil.utils.ask(\"Redis URL\", \"redis://localhost:6379/0\")\n    return coil.init.write_users(u)", "response": "Write users to the DB."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef devserver(arguments):\n    import coil.web\n    if coil.web.app:\n        port = int(arguments['--port'])\n        url = 'http://localhost:{0}/'.format(port)\n        coil.web.configure_url(url)\n        coil.web.app.config['DEBUG'] = True\n\n        if arguments['--browser']:\n            webbrowser.open(url)\n\n        coil.web.app.logger.info(\"Coil CMS running @ {0}\".format(url))\n        coil.web.app.run('localhost', port, debug=True)\n        return 0\n    else:\n        print(\"FATAL: no conf.py found\")\n        return 255", "response": "Run a development server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntopping level parsing function. An expression is a list of tuples where each element is a tuple of the value and the corresponding element is the value of the entry in the list.", "response": "def expr(self, token_stream, token):\n        \"\"\"Top level parsing function.\n\n        An expression is <keyword> <OR> <expr>\n        or               <keyword> <SEP> <expr>\n        or               <keyword>\n\n        \"\"\"\n        lval = self.keyword(token_stream, token, {})\n        token = next(token_stream)\n        if token[0] == 'OR':\n            op = or_\n            token = next(token_stream)\n        elif token[0] == 'TEXT' or token[0] == 'COLOR':\n            op = lambda l, r: list(flatten([l, r]))\n        elif token[0] == 'SEPARATOR':\n            op = lambda l, r: list(flatten([l, r]))\n            token = next(token_stream)\n        else:\n            return [lval]\n        rval = self.expr(token_stream, token)\n        return op(lval, rval)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef keyword(self, token_stream, token, operators):\n        if token[0] == 'TEXT' or token[0] == 'COLOR':\n            return SearchKeyword(token[1], **operators)\n        elif token[0] == 'COMPARISON':\n            operators['comparison'] = token[1]\n        elif token[0] == 'NOT':\n            operators['boolean'] = 'not'\n        else:\n            if token[1] == None:\n                problem = 'end of input.'\n            else:\n                problem = 'token {0} in input'.format(token[1])\n            raise SyntaxError('Unexpected {0}'.format(problem))\n        token = next(token_stream)\n        return self.keyword(token_stream, token, operators)", "response": "Lowest level parsing function."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse(self, text):\n        token_stream = self.lexer.tokenize(text)\n        return self.expr(token_stream, next(token_stream))", "response": "Parse the given text return a list of Keywords."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mimeType(self):\n        if self.mime_type:\n            # Supposed validated by the factory\n            return self.mime_type\n        for pattern, mime_type in self._extpattern_to_mime.items():\n            if fnmatch.fnmatch(self.filename, pattern):\n                return mime_type", "response": "Returns the MIME type of this file as a string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a dictionary of property names to values for the given content type.", "response": "def _tagValuedProperties(self, content_type):\n        \"\"\"Document properties for property files having constructs like\n        <ns:name>value</ns:name>\n\n        :param content_type: ``contenttypes.CT_CORE_PROPS`` or ``contenttypes.CT_EXT_PROPS``\n        :return: mapping like {'property name': 'property value', ...}\n        \"\"\"\n        rval = {}\n        if not content_type in self.content_types.listMetaContentTypes:\n            # We fail silently\n            return rval\n        for tree in self.content_types.getTreesFor(self, content_type):\n            for elt in tree.getroot().getchildren():\n                tag = elt.tag.split('}')[-1] # Removing namespace if any\n                rval[toUnicode(tag)] = toUnicode(elt.text)\n        return rval"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef customProperties(self):\n        rval = {}\n        if len(self.content_types.getPathsForContentType(contenttypes.CT_CUSTOM_PROPS)) == 0:\n            # We may have no custom properties at all.\n            return rval\n        XPath = lxml.etree.XPath # Class shortcut\n        properties_xpath = XPath('custom-properties:property', namespaces=ns_map)\n        propname_xpath = XPath('@name')\n        propvalue_xpath = XPath('*/text()')\n        for tree in self.content_types.getTreesFor(self, contenttypes.CT_CUSTOM_PROPS):\n            for elt in properties_xpath(tree.getroot()):\n                rval[toUnicode(propname_xpath(elt)[0])] = u\" \".join(propvalue_xpath(elt))\n        return rval", "response": "Return a mapping of custom properties to their corresponding metadata."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef allProperties(self):\n        rval = {}\n        rval.update(self.coreProperties)\n        rval.update(self.extendedProperties)\n        rval.update(self.customProperties)\n        return rval", "response": "Helper that merges core extended and custom properties with the core properties and extended properties and custom properties."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the type of cover page image", "response": "def documentCover(self):\n        \"\"\"Cover page image\n\n        :return: (file extension, file object) tuple.\n        \"\"\"\n        rels_pth = os.path.join(self._cache_dir, \"_rels\", \".rels\")\n        rels_xml = lxml.etree.parse(xmlFile(rels_pth, 'rb'))\n        thumb_ns = ns_map[\"thumbnails\"]\n        thumb_elm_xpr = \"relationships:Relationship[@Type='%s']\" % thumb_ns\n        rels_xpath = lxml.etree.XPath(thumb_elm_xpr, namespaces=ns_map)\n        try:\n            cover_path = rels_xpath(rels_xml)[0].attrib[\"Target\"]\n        except IndexError:\n            return None\n        cover_fp = open(self._cache_dir + os.sep + cover_path, \"rb\")\n        cover_type = imghdr.what(None, h=cover_fp.read(32))\n        cover_fp.seek(0)\n        # some MS docs say the type can be JPEG which is ok,\n        # or WMF, which imghdr does not recognize...\n        if not cover_type:\n            cover_type = cover_path.split('.')[-1]\n        else:\n            cover_type = cover_type.replace(\"jpeg\", \"jpg\")\n        return (cover_type, cover_fp)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef indexableText(self, include_properties=True):\n        text = set()\n        for extractor in self._text_extractors:\n            if extractor.content_type in self.content_types.overrides:\n                for tree in self.content_types.getTreesFor(self, extractor.content_type):\n                    words = extractor.indexableText(tree)\n                    text |= words\n\n        if include_properties:\n            for prop_value in self.allProperties.values():\n                if prop_value is not None:\n                    text.add(prop_value)\n        return u' '.join([word for word in text])", "response": "Returns a string containing the words found in the various texts of the document."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef canProcessFilename(cls, filename):\n        supported_patterns = cls._extpattern_to_mime.keys()\n        for pattern in supported_patterns:\n            if fnmatch.fnmatch(filename, pattern):\n                return True\n        return False", "response": "Check if we can process such file based on filename as mydoc. docx"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef register(self, token, regexp):\n        self._tokens.append((token, re.compile(regexp)))", "response": "Register a token.\n\n        Args:\n            token (Token): the token class to register\n            regexp (str): the regexp for that token"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve all token definitions matching the beginning of a text.", "response": "def matching_tokens(self, text, start=0):\n        \"\"\"Retrieve all token definitions matching the beginning of a text.\n\n        Args:\n            text (str): the text to test\n            start (int): the position where matches should be searched in the\n                string (see re.match(rx, txt, pos))\n\n        Yields:\n            (token_class, re.Match): all token class whose regexp matches the\n                text, and the related re.Match object.\n        \"\"\"\n        for token_class, regexp in self._tokens:\n            match = regexp.match(text, pos=start)\n            if match:\n                yield token_class, match"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_token(self, text, start=0):\n        best_class = best_match = None\n\n        for token_class, match in self.matching_tokens(text):\n            if best_match and best_match.end() >= match.end():\n                continue\n            best_match = match\n            best_class = token_class\n\n        return best_class, best_match", "response": "Retrieve the next token from some text."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nregistering a token class.", "response": "def register_token(self, token_class, regexp=None):\n        \"\"\"Register a token class.\n\n        Args:\n            token_class (tdparser.Token): the token class to register\n            regexp (optional str): the regexp for elements of that token.\n                Defaults to the `regexp` attribute of the token class.\n        \"\"\"\n        if regexp is None:\n            regexp = token_class.regexp\n\n        self.tokens.register(token_class, regexp)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsplitting self. text into a list of tokens.", "response": "def lex(self, text):\n        \"\"\"Split self.text into a list of tokens.\n\n        Args:\n            text (str): text to parse\n\n        Yields:\n            Token: the tokens generated from the given text.\n        \"\"\"\n        pos = 0\n        while text:\n            token_class, match = self.tokens.get_token(text)\n            if token_class is not None:\n                matched_text = text[match.start():match.end()]\n                yield token_class(matched_text)\n                text = text[match.end():]\n                pos += match.end()\n            elif text[0] in self.blank_chars:\n                text = text[1:]\n                pos += 1\n            else:\n                raise LexerError(\n                        'Invalid character %s in %s' % (text[0], text),\n                        position=pos)\n\n        yield self.end_token()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse(self, text):\n        tokens = self.lex(text)\n        parser = Parser(tokens)\n        return parser.parse()", "response": "Parse the text and return a node representing the current rule."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save_example_fit(fit):\n    json_directory = os.path.join('examples', 'json')\n    plot_directory = os.path.join('examples', 'plots')\n    if not os.path.isdir(json_directory): os.makedirs(json_directory)\n    if not os.path.isdir(plot_directory): os.makedirs(plot_directory)\n\n    fit.to_json(os.path.join(json_directory, fit.name + '.json'), meta=fit.metadata)\n\n    plot = Plot(fit)\n    plot.save(os.path.join(plot_directory, fit.name + '.svg'))\n    plot.close()", "response": "Save fit result to a json file and a plot to an svg file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving directory if it exists then create it if it doesn t exist.", "response": "def reset_directory(directory):\n    \"\"\"\n    Remove `directory` if it exists, then create it if it doesn't exist.\n    \"\"\"\n    if os.path.isdir(directory): shutil.rmtree(directory)\n    if not os.path.isdir(directory): os.makedirs(directory)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprovide all XML documents for that content type and returns a list of etree. _ElementTree objects.", "response": "def getTreesFor(self, document, content_type):\n        \"\"\"Provides all XML documents for that content type\n        @param document: a Document or subclass object\n        @param content_type: a MIME content type\n        @return: list of etree._ElementTree of that content type\n        \"\"\"\n\n        # Relative path without potential leading path separator\n        # otherwise os.path.join doesn't work\n        for rel_path in self.overrides[content_type]:\n            if rel_path[0] in ('/', '\\\\'):\n                rel_path = rel_path[1:]\n            file_path = os.path.join(document._cache_dir, rel_path)\n            yield etree.parse(utils.xmlFile(file_path, 'rb'))\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef listMetaContentTypes(self):\n\n        all_md_content_types = (\n            CT_CORE_PROPS,\n            CT_EXT_PROPS,\n            CT_CUSTOM_PROPS)\n        return [k for k in self.overrides.keys() if k in all_md_content_types]", "response": "The content types with metadata\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts the string representation of a json number into its python object equivalent, an int, long, float or whatever type suits.", "response": "def default_number_converter(number_str):\n    \"\"\"\n    Converts the string representation of a json number into its python object equivalent, an\n    int, long, float or whatever type suits.\n    \"\"\"\n    is_int = (number_str.startswith('-') and number_str[1:].isdigit()) or number_str.isdigit()\n    # FIXME: this handles a wider range of numbers than allowed by the json standard,\n    # etc.: float('nan') and float('inf'). But is this a problem?\n    return int(number_str) if is_int else float(number_str)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the matplotlib. pyplot. figure object for this instance.", "response": "def figure(self):\n        \"\"\"\n        The [`matplotlib.pyplot.figure`][1] instance.\n\n        [1]: http://matplotlib.org/api/figure_api.html#matplotlib.figure.Figure\n        \"\"\"\n        if not hasattr(self, '_figure'): self._figure = matplotlib.pyplot.figure()\n        return self._figure"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a matplotlib plot object for the current object.", "response": "def plot(self):\n        \"\"\"\n        The plot object, see [Pyplot][1].\n\n        If one does not exist, it will be created first with [`add_subplot`][2].\n\n        [1]: http://matplotlib.org/api/pyplot_api.html\n        [2]: http://matplotlib.org/api/figure_api.html#matplotlib.figure.Figure.add_subplot\n        \"\"\"\n        if not hasattr(self, '_plot'):\n            plot = self.figure.add_subplot(111)\n            pointspace = self.fit.pointspace(num=self.options['points'])\n\n            if any(v is not None for v in self.fit.data.error):\n                plot_data = plot.errorbar\n                self.options['data']['xerr'] = self.fit.data.error[0]\n                self.options['data']['yerr'] = self.fit.data.error[1]\n            else:\n                plot_data = plot.plot\n\n            plot_data(*pointspace['data'], **self.options['data'])\n            plot.plot(*pointspace['fit'], **self.options['fit'])\n\n            text = {}\n            for v in ('independent', 'dependent'):\n                meta = getattr(self.fit, v)\n                text[v] = {\n                  'name': meta['name'] if 'name' in meta else '',\n                  'units': ' (' + meta['units'] + ')' if 'units' in meta else ''\n                }\n\n            plot.set_xlabel(text['independent']['name'] + text['independent']['units'])\n            plot.set_ylabel(text['dependent']['name'] + text['dependent']['units'])\n\n            self._plot = plot\n\n        return self._plot"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsaving the current plot to the file at path.", "response": "def save(self, path, **kwargs):\n        \"\"\"\n        Save the plot to the file at `path`.\n\n        Any keyword arguments are passed to [`matplotlib.pyplot.savefig`][1].\n\n        [1]: http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.savefig\n        \"\"\"\n        self.plot if not hasattr(self, '_plot') else None\n        self.figure.savefig(path, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_utf_text_file(file_, default_encoding='UTF-8', use_utf8_strings=True):\n    if isinstance(file_, my_basestring):\n        with open(file_, 'rb') as f:\n            buf = f.read()\n    else:\n        buf = file_.read()\n    return decode_utf_text_buffer(buf, default_encoding, use_utf8_strings)", "response": "Loads the specified text file and attempts to decode it using one of the UTF - 8 encodings."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndecodes a binary file contents with optional UTF - 8 BOM prefix.", "response": "def decode_utf_text_buffer(buf, default_encoding='UTF-8', use_utf8_strings=True):\n    \"\"\"\n    :param buf: Binary file contents with optional BOM prefix.\n    :param default_encoding: The encoding to be used if the buffer\n    doesn't have a BOM prefix.\n    :param use_utf8_strings: Used only in case of python2: You can choose utf-8\n    str in-memory string representation in case of python. If use_utf8_strings is\n    False or you are using python3 then the text buffer is automatically loaded as a\n    unicode object.\n    :return: A unicode object. In case of python2 it can optionally be an str object\n    containing utf-8 encoded text.\n    \"\"\"\n    buf, encoding = detect_encoding_and_remove_bom(buf, default_encoding)\n    if python2 and use_utf8_strings:\n        if are_encoding_names_equivalent(encoding, 'UTF-8'):\n            return buf\n        return buf.decode(encoding).encode('UTF-8')\n    return buf.decode(encoding)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndetect encoding and remove BOM from buffer.", "response": "def detect_encoding_and_remove_bom(buf, default_encoding='UTF-8'):\n    \"\"\"\n    :param buf: Binary file contents with an optional BOM prefix.\n    :param default_encoding: The encoding to be used if the buffer\n    doesn't have a BOM prefix.\n    :return: (buf_without_bom_prefix, encoding)\n    \"\"\"\n    if not isinstance(buf, bytes):\n        raise TypeError('buf should be a bytes instance but it is a %s: ' % type(buf).__name__)\n    for bom, encoding in _byte_order_marks:\n        if buf.startswith(bom):\n            return buf[len(bom):], encoding\n    return buf, default_encoding"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_file(cls, filename):\n        import csv\n        with open(filename, 'r') as f:\n            reader = csv.DictReader(f)\n            row = reader.next()  # Only one row in the file\n        try:\n            cls.ACCESS_KEY_ID = row['Access Key Id']\n            cls.SECRET_ACCESS_KEY = row['Secret Access Key']\n        except KeyError:\n            raise IOError('Invalid credentials format')", "response": "Load ACCESS_KEY_ID and SECRET_ACCESS_KEY from csv file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove all orphans in the site.", "response": "def orphans(dburl, sitedir):\n    \"\"\"Remove all orphans in the site.\"\"\"\n    oldcwd = os.getcwd()\n    os.chdir(sitedir)\n    db = StrictRedis.from_url(dburl)\n    job = get_current_job(db)\n    job.meta.update({'out': '', 'return': None, 'status': None})\n    job.save()\n    returncode, out = orphans_single(default_exec=True)\n\n    job.meta.update({'out': out, 'return': returncode, 'status':\n                     returncode == 0})\n    job.save()\n    os.chdir(oldcwd)\n    return returncode"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build_single(mode):\n    if mode == 'force':\n        amode = ['-a']\n    else:\n        amode = []\n    if executable.endswith('uwsgi'):\n        # hack, might fail in some environments!\n        _executable = executable[:-5] + 'python'\n    else:\n        _executable = executable\n    p = subprocess.Popen([_executable, '-m', 'nikola', 'build'] + amode,\n                         stderr=subprocess.PIPE)\n    p.wait()\n    rl = p.stderr.readlines()\n    try:\n        out = ''.join(rl)\n    except TypeError:\n        out = ''.join(l.decode('utf-8') for l in rl)\n    return (p.returncode == 0), out", "response": "Build in the single - user mode."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove all orphans in the site in the single user - mode.", "response": "def orphans_single(default_exec=False):\n    \"\"\"Remove all orphans in the site, in the single user-mode.\"\"\"\n    if not default_exec and executable.endswith('uwsgi'):\n        # default_exec => rq => sys.executable is sane\n        _executable = executable[:-5] + 'python'\n    else:\n        _executable = executable\n    p = subprocess.Popen([_executable, '-m', 'nikola', 'orphans'],\n                         stdout=subprocess.PIPE)\n    p.wait()\n    files = [l.strip().decode('utf-8') for l in p.stdout.readlines()]\n    for f in files:\n        if f:\n            os.unlink(f)\n\n    out = '\\n'.join(files)\n    return p.returncode, out"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds the data points to the plot.", "response": "def plot_data(self):\n        \"\"\"\n        Add the data points to the plot.\n        \"\"\"\n        self.plt.plot(*self.fit.data, **self.options['data'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef plot_fit(self):\n        self.plt.plot(*self.fit.fit, **self.options['fit'])", "response": "Add the fit to the plot"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a label to the x - axis.", "response": "def add_xlabel(self, text=None):\n        \"\"\"\n        Add a label to the x-axis.\n        \"\"\"\n        x = self.fit.meta['independent']\n        if not text:\n            text = '$' + x['tex_symbol'] + r'$ $(\\si{' + x['siunitx'] +  r'})$'\n        self.plt.set_xlabel(text)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_ylabel(self, text=None):\n        y = self.fit.meta['dependent']\n        if not text:\n            text = '$' + y['tex_symbol'] + r'$ $(\\si{' + y['siunitx'] +  r'})$'\n        self.plt.set_ylabel(text)", "response": "Add a label to the y - axis."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_text_table(self, rows, r0, dr, **kwargs):\n        for m, row in enumerate(rows):\n            for n, column in enumerate(row):\n                self.plt.text(r0[0] + dr[0] * n, r0[1] + dr[1] * m, column,\n                    transform=self.plt.axes.transAxes, **kwargs)", "response": "Add text to a grid fashion."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a table of parameters.", "response": "def parameter_table(parameters):\n        \"\"\"\n        Create\n        \"\"\"\n        if not isinstance(parameters, list): parameters = [parameters]\n        rows = []\n        for param in parameters:\n            row = []\n            row.append('$' + param['tex_symbol'] + '$')\n            row.append('$=$')\n            row.append(r'$\\SI{' + param['disply_value'] + '}{' + param['siunitx'] + '}$')\n            rows.append(row)\n        return rows"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write_users(dburl):\n    data = {\n        'username': 'admin',\n        'realname': 'Website Administrator',\n        'email': 'coil@example.com',\n        'password':\n            r'$bcrypt-sha256$2a,12$NNtd2TC9mZO6.EvLwEwlLO$axojD34/iE8x'\n            r'QitQnCCOGPhofgmjNdq',\n    }\n\n    for p in PERMISSIONS:\n        data[p] = '1'\n\n    db = redis.StrictRedis.from_url(dburl)\n    db.hmset('user:1', data)\n    db.hset('users', 'admin', '1')\n    if not db.exists('last_uid'):\n        db.incr('last_uid')\n\n    print(\"Username: admin\")\n    print(\"Password: admin\")\n    return 0", "response": "Write users to the DB."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_profile_model():\n    user_profile_module = getattr(settings, 'USER_PROFILE_MODULE', None)\n    if user_profile_module:\n        app_label, model_name = user_profile_module.split('.')\n        return get_model(app_label, model_name)\n    else:\n        return None", "response": "Returns the user profile model"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_redirect_url(self, request):\n        if 'next' in request.session:\n            next_url = request.session['next']\n            del request.session['next']\n        elif 'next' in request.GET:\n            next_url = request.GET.get('next')\n        elif 'next' in request.POST:\n            next_url = request.POST.get('next')\n        else:\n            next_url = request.user.get_absolute_url()\n        if not next_url:\n            next_url = '/'\n        return next_url", "response": "Get the next url from the request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef xmlFile(path, mode='r'):\n    fh = file(path, mode)\n    while fh.read(1) != '<': # Ignoring everything before '<?xml...'\n        pass\n    fh.seek(-1, 1)\n    return fh", "response": "Open a file and return a file object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef indexableText(self, tree):\n        rval = set()\n        root = tree.getroot()\n        for txp in self.text_elts_xpaths:\n            elts = txp(root)\n            texts = []\n            # Texts in element may be empty\n            for elt in elts:\n                text = self.text_extract_xpath(elt)\n                if len(text) > 0:\n                    texts.append(text[0])\n            texts = self.separator.join(texts)\n            texts = [toUnicode(x) for x in self.wordssearch_rx.findall(texts)\n                     if len(x) > 0]\n            rval |= set(texts)\n        return rval", "response": "Provides the indexable - search engine oriented - raw text\n           "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _flatten(self, element):\n        result = [(element.text or '')]\n        if element.attrib.get('alt'):\n            result.append(Symbol(element.attrib.get('alt')).textbox)\n        for sel in element:\n            result.append(self._flatten(sel))\n            result.append(sel.tail or '')\n\n        # prevent reminder text from getting too close to mana symbols\n        return ''.join(result).replace('}(', '} (')", "response": "Recursively enter and extract text from all child\n        elements."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef split_pow_tgh(self, text):\n        return [n for n in re.split(r\"/(?=([^{}]*{[^{}]*})*[^{}]*$)\", text)\n                if n is not None][:2]", "response": "Split a power toughness string on the correct slash."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the storage instance.", "response": "def get_storage(self):\n        '''Get the storage instance.\n\n        :return Redis: Redis instance\n        '''\n\n        if self.storage:\n            return self.storage\n        self.storage = self.reconnect_redis()\n\n        return self.storage"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef on_redis_error(self, fname, exc_type, exc_value):\n        '''Callback executed when there is a redis error.\n\n        :param string fname: Function name that was being called.\n        :param type exc_type: Exception type\n        :param Exception exc_value: The current exception\n        :returns: Default value or raise the current exception\n        '''\n\n        if self.shared_client:\n            Storage.storage = None\n        else:\n            self.storage = None\n\n        if self.context.config.REDIS_STORAGE_IGNORE_ERRORS is True:\n            logger.error(\"[REDIS_STORAGE] %s\" % exc_value)\n            if fname == '_exists':\n                return False\n            return None\n        else:\n            raise exc_value", "response": "Callback executed when there is a redis error."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef node_location(config_node):\n    if isinstance(config_node, ConfigNode):\n        return _NodeLocation(config_node._line, config_node._column)\n    if isinstance(config_node, ValueNotFoundNode):\n        raise JSONConfigValueNotFoundError(config_node)\n    raise TypeError('Expected a config node but received a %s instance.' %\n                    type(config_node).__name__)", "response": "Returns the location of this node in the file as a tuple ( line column."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconfigures the Nikola site for Coil CMS.", "response": "def configure_site():\n    \"\"\"Configure the Nikola site for Coil CMS.\"\"\"\n    global _site, site, db, q\n\n    nikola.__main__._RETURN_DOITNIKOLA = True\n    _dn = nikola.__main__.main([])\n    _site = _dn.nikola\n    _site.init_plugins()\n    _dn.sub_cmds = _dn.get_cmds()\n    app.config['NIKOLA_ROOT'] = os.getcwd()\n    app.config['DEBUG'] = False\n\n    # Logging configuration\n\n    logf = (u'[{record.time:%Y-%m-%dT%H:%M:%SZ}] {record.level_name}: '\n            u'{record.channel}: {record.message}')\n    logh = (u'[{record.time:%Y-%m-%dT%H:%M:%SZ}] {record.channel} '\n            u'{record.message}')\n\n    loghandlers = [\n        ColorfulStderrHandler(level=logbook.DEBUG, format_string=logf,\n                              bubble=True),\n        logbook.FileHandler('coil.log', 'a', 'utf-8', logbook.DEBUG, logf,\n                            bubble=True)\n    ]\n\n    hloghandlers = [\n        ColorfulStderrHandler(level=logbook.DEBUG, format_string=logh,\n                              bubble=True),\n        logbook.FileHandler('coil.log', 'a', 'utf-8', logbook.DEBUG, logh,\n                            bubble=True)\n    ]\n\n    _site.loghandlers = loghandlers\n    nikola.utils.LOGGER.handlers = loghandlers\n\n    nikola.plugins.command.new_post.POSTLOGGER.handlers = loghandlers\n    nikola.plugins.command.new_post.PAGELOGGER.handlers = loghandlers\n\n    app.config['LOGGER_NAME'] = 'Coil'\n    app._logger = get_logger('Coil', loghandlers)\n    app.http_logger = get_logger('CoilHTTP', hloghandlers)\n\n    if not _site.configured:\n        app.logger(\"Not a Nikola site.\")\n        return\n\n    app.secret_key = _site.config.get('COIL_SECRET_KEY')\n    app.config['COIL_URL'] = _site.config.get('COIL_URL')\n    app.config['COIL_LOGIN_CAPTCHA'] = _site.config.get(\n        'COIL_LOGIN_CAPTCHA',\n        {'enabled': False, 'site_key': '', 'secret_key': ''})\n    app.config['COIL_USERS_PREVENT_EDITING'] = _site.config.get('COIL_USERS_PREVENT_EDITING', [])\n    app.config['COIL_LIMITED'] = _site.config.get('COIL_LIMITED', False)\n    app.config['REDIS_URL'] = _site.config.get('COIL_REDIS_URL',\n                                               'redis://localhost:6379/0')\n    if app.config['COIL_LIMITED']:\n        app.config['COIL_USERS'] = _site.config.get('COIL_USERS', {})\n        _site.coil_needs_rebuild = '0'\n    else:\n        db = redis.StrictRedis.from_url(app.config['REDIS_URL'])\n        q = rq.Queue(name='coil', connection=db)\n\n    _site.template_hooks['menu'].append(generate_menu)\n    _site.template_hooks['menu_alt'].append(generate_menu_alt)\n\n    app.config['NIKOLA_URL'] = _site.config['SITE_URL']\n    _site.config['NAVIGATION_LINKS'] = {\n        _site.default_lang: (\n            (app.config['NIKOLA_URL'],\n             '<i class=\"fa fa-globe\"></i> View Site'),\n            ('http://coil.readthedocs.io/user/',\n             '<i class=\"fa fa-question-circle\"></i> Help'),\n        )\n    }\n    _site.GLOBAL_CONTEXT['navigation_links'] = _site.config['NAVIGATION_LINKS']\n    TITLE = _site.GLOBAL_CONTEXT['blog_title']() + ' Administration'\n    _site.config['BLOG_TITLE'] = TranslatableSetting(\n        'BLOG_TITLE', TITLE, _site.config['TRANSLATIONS'])\n    _site.GLOBAL_CONTEXT['blog_title'] = _site.config['BLOG_TITLE']\n    _site.GLOBAL_CONTEXT['lang'] = _site.default_lang\n    _site.GLOBAL_CONTEXT['extra_head_data'] = TranslatableSetting(\n        'EXTRA_HEAD_DATA',\n        \"\"\"<link href=\"//maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/\"\"\"\n        \"\"\"font-awesome.min.css\" rel=\"stylesheet\">\\n\"\"\"\n        \"\"\"<link href=\"/coil_assets/css/coil.css\" rel=\"stylesheet\">\"\"\",\n        _site.config['TRANSLATIONS'])\n    # HACK: body_end appears after extra_js from templates, so we must use\n    #       social_buttons_code instead\n    _site.GLOBAL_CONTEXT['social_buttons_code'] = TranslatableSetting(\n        'SOCIAL_BUTTONS_CODE',\n        \"\"\"<script src=\"/coil_assets/js/coil.js\"></script>\"\"\",\n        _site.config['TRANSLATIONS'])\n\n    # Theme must inherit from bootstrap3, because we have hardcoded HTML.\n    themes = [os.path.basename(x) for x in _site.THEMES]\n    bs3 = (('bootstrap3' in themes) or\n           ('bootstrap3-jinja' in themes))\n    if not bs3:\n        app.logger.notice(\"THEME does not inherit from 'bootstrap3' or \"\n                          \"'bootstrap3-jinja', using 'bootstrap3' instead.\")\n        _site.config['THEME'] = 'bootstrap3'\n        # Reloading some things\n        _site._THEMES = None\n        _site._get_themes()\n        _site._template_system = None\n        _site._get_template_system()\n        if 'has_custom_css' in _site._GLOBAL_CONTEXT:\n            del _site._GLOBAL_CONTEXT['has_custom_css']\n        _site._get_global_context()\n\n    tmpl_dir = pkg_resources.resource_filename(\n        'coil', os.path.join('data', 'templates', _site.template_system.name))\n    if os.path.isdir(tmpl_dir):\n        # Inject tmpl_dir low in the theme chain\n        _site.template_system.inject_directory(tmpl_dir)\n\n    # Commands proxy (only for Nikola commands)\n    _site.commands = nikola.utils.Commands(\n        _site.doit,\n        None,\n        {'cmds': _site._commands}\n    )\n\n    # Site proxy\n    if app.config['COIL_LIMITED']:\n        site = _site\n        scan_site()\n    else:\n        site = SiteProxy(db, _site, app.logger)\n\n    configure_url(app.config['COIL_URL'])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef password_hash(password):\n    try:\n        return bcrypt_sha256.encrypt(password)\n    except TypeError:\n        return bcrypt_sha256.encrypt(password.decode('utf-8'))", "response": "Hash the password using bcrypt + sha256."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_old_password(pwdhash, password):\n    from flask.ext.bcrypt import Bcrypt\n    app.config['BCRYPT_LOG_ROUNDS'] = 12\n    bcrypt = Bcrypt(app)\n    return bcrypt.check_password_hash(pwdhash, password)", "response": "Check the old password hash from the plaintext password_hash."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate the menu with the rebuild link.", "response": "def generate_menu():\n    \"\"\"Generate ``menu`` with the rebuild link.\n\n    :return: HTML fragment\n    :rtype: str\n    \"\"\"\n    if db is not None:\n        needs_rebuild = db.get('site:needs_rebuild')\n    else:\n        needs_rebuild = site.coil_needs_rebuild\n    if needs_rebuild not in (u'0', u'-1', b'0', b'-1'):\n        return ('</li><li><a href=\"{0}\"><i class=\"fa fa-fw '\n                'fa-warning\"></i> <strong>Rebuild</strong></a></li>'.format(\n                    url_for('rebuild')))\n    else:\n        return ('</li><li><a href=\"{0}\"><i class=\"fa fa-fw '\n                'fa-cog\"></i> Rebuild</a></li>'.format(url_for('rebuild')))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_menu_alt():\n    if not current_user.is_authenticated():\n        return ('<li><a href=\"{0}\"><i class=\"fa fa-fw fa-sign-in\"></i> '\n                'Log in</a></li>'.format(url_for('login')))\n    if db is not None and current_user.is_admin:\n        edit_entry = (\n            '<li><a href=\"{0}\"><i class=\"fa fa-fw fa-users\"></i> '\n            'Manage users</a></li>'\n            '<li><a href=\"{1}\"><i class=\"fa fa-fw fa-cubes\"></i> '\n            'Permissions</a></li>'.format(\n                url_for('acp_users'), url_for('acp_users_permissions')))\n    else:\n        edit_entry = ''\n    return \"\"\"\n    <li class=\"dropdown\">\n        <a href=\"#\" class=\"dropdown-toggle\" data-toggle=\"dropdown\"\n            role=\"button\" aria-expanded=\"false\">\n            <i class=\"fa fa-fw fa-user\"></i>\n            {0} [{1}] <span class=\"caret\"></span></a>\n        <ul class=\"dropdown-menu\" role=\"menu\">\n            <li><a href=\"{3}\"><i class=\"fa fa-fw fa-sliders\"></i>\n            Account</a></li>\n            {2}\n            <li><a href=\"{4}\"><i class=\"fa fa-fw fa-sign-out\"></i>\n            Log out</a></li>\n        </ul>\n    </li>\"\"\".format(current_user.realname, current_user.username, edit_entry,\n                    url_for('acp_account'), url_for('logout'))", "response": "Generate the alt menu for the current user."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the UID of the post author.", "response": "def _author_uid_get(post):\n    \"\"\"Get the UID of the post author.\n\n    :param Post post: The post object to determine authorship of\n    :return: Author UID\n    :rtype: str\n    \"\"\"\n    u = post.meta('author.uid')\n    return u if u else str(current_user.uid)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef render(template_name, context=None, code=200, headers=None):\n    if context is None:\n        context = {}\n    if headers is None:\n        headers = {}\n\n    context['g'] = g\n    context['request'] = request\n    context['session'] = session\n    context['current_user'] = current_user\n    context['_author_get'] = _author_get\n    context['_author_uid_get'] = _author_uid_get\n    if app.config['COIL_URL'].startswith('https') and not request.url.startswith('https'):\n        # patch request URL for HTTPS proxy (eg. CloudFlare)\n        context['permalink'] = request.url.replace('http', 'https', 1)\n    else:\n        context['permalink'] = request.url\n    context['url_for'] = url_for\n    headers['Pragma'] = 'no-cache'\n    headers['Cache-Control'] = 'private, max-age=0, no-cache'\n\n    try:\n        mcp = current_user.must_change_password in (True, '1')\n    except AttributeError:\n        mcp = False\n\n    if mcp and not context.get('pwdchange_skip', False):\n        return redirect(url_for('acp_account') + '?status=pwdchange')\n\n    return _site.render_template(template_name, None, context), code, headers", "response": "Render a response using standard Nikola templates."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_user(uid):\n    if db is not None:\n        try:\n            uid = uid.decode('utf-8')\n        except AttributeError:\n            pass\n        d = db.hgetall('user:{0}'.format(uid))\n        if d:\n            nd = {}\n            # strings everywhere\n            for k in d:\n                try:\n                    nd[k.decode('utf-8')] = d[k].decode('utf-8')\n                except AttributeError:\n                    try:\n                        nd[k.decode('utf-8')] = d[k]\n                    except AttributeError:\n                        nd[k] = d[k]\n            for p in PERMISSIONS:\n                nd[p] = nd.get(p) == '1'\n            return User(uid=uid, **nd)\n        else:\n            return None\n    else:\n        d = app.config['COIL_USERS'].get(uid)\n        if d:\n            return User(uid=uid, **d)\n        else:\n            return None", "response": "Get an user by the UID."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_user_by_name(username):\n    if db is not None:\n        uid = db.hget('users', username)\n        if uid:\n            return get_user(uid)\n    else:\n        for uid, u in app.config['COIL_USERS'].items():\n            if u['username'] == username:\n                return get_user(uid)", "response": "Get an user by their username."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites a user to the database.", "response": "def write_user(user):\n    \"\"\"Write an user ot the database.\n\n    :param User user: User to write\n    \"\"\"\n\n    udata = {}\n\n    for f in USER_FIELDS:\n        udata[f] = getattr(user, f)\n\n    for p in PERMISSIONS:\n        udata[p] = '1' if getattr(user, p) else '0'\n    db.hmset('user:{0}'.format(user.uid), udata)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef login():\n    alert = None\n    alert_status = 'danger'\n    code = 200\n    captcha = app.config['COIL_LOGIN_CAPTCHA']\n    form = LoginForm()\n    if request.method == 'POST':\n        if form.validate():\n            user = find_user_by_name(request.form['username'])\n            if not user:\n                alert = 'Invalid credentials.'\n                code = 401\n            if captcha['enabled']:\n                r = requests.post('https://www.google.com/recaptcha/api/siteverify',\n                                  data={'secret': captcha['secret_key'],\n                                        'response': request.form['g-recaptcha-response'],\n                                        'remoteip': request.remote_addr})\n                if r.status_code != 200:\n                    alert = 'Cannot check CAPTCHA response.'\n                    code = 500\n                else:\n                    rj = r.json()\n                    if not rj['success']:\n                        alert = 'Invalid CAPTCHA response. Please try again.'\n                        code = 401\n            if code == 200:\n                try:\n                    pwd_ok = check_password(user.password,\n                                            request.form['password'])\n                except ValueError:\n                    if user.password.startswith('$2a$12'):\n                        # old bcrypt hash\n                        pwd_ok = check_old_password(user.password,\n                                                    request.form['password'])\n                        if pwd_ok:\n                            user.password = password_hash(\n                                request.form['password'])\n                            write_user(user)\n                    else:\n                        pwd_ok = False\n\n                if pwd_ok and user.is_active:\n                    login_user(user, remember=('remember' in request.form))\n                    return redirect(url_for('index'))\n                else:\n                    alert = \"Invalid credentials.\"\n                    code = 401\n\n        else:\n            alert = 'Invalid credentials.'\n            code = 401\n    else:\n        if request.args.get('status') == 'unauthorized':\n            alert = 'Please log in to access this page.'\n        elif request.args.get('status') == 'logout':\n            alert = 'Logged out successfully.'\n            alert_status = 'success'\n    return render('coil_login.tmpl', {'title': 'Login', 'alert': alert, 'form':\n                                      form, 'alert_status': alert_status,\n                                      'pwdchange_skip': True,\n                                      'captcha': captcha},\n                  code)", "response": "Handle user authentication.\n\n    If requested over GET, present login page.\n    If requested over POST, log user in.\n\n    :param str status: Status of previous request/login attempt"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nshow the index with all posts.", "response": "def index():\n    \"\"\"Show the index with all posts.\n\n    :param int all: Whether or not should show all posts\n    \"\"\"\n    context = {'postform': NewPostForm(),\n               'pageform': NewPageForm(),\n               'delform': DeleteForm()}\n\n    n = request.args.get('all')\n    if n is None:\n        wants_now = None\n    else:\n        wants_now = n == '1'\n\n    if wants_now is None and current_user.wants_all_posts:\n        wants = True\n    else:\n        wants = wants_now\n\n    if current_user.can_edit_all_posts and wants:\n        posts = site.all_posts\n        pages = site.pages\n    else:\n        wants = False\n        posts = []\n        pages = []\n        for p in site.timeline:\n            if (p.meta('author.uid') and\n                    p.meta('author.uid') != str(current_user.uid)):\n                continue\n            if p.is_post:\n                posts.append(p)\n            else:\n                pages.append(p)\n\n    context['posts'] = posts\n    context['pages'] = pages\n    context['title'] = 'Posts & Pages'\n    context['wants'] = wants\n    return render('coil_index.tmpl', context)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef edit(path):\n    context = {'path': path, 'site': site}\n    post = find_post(path)\n    if post is None:\n        return error(\"No such post or page.\", 404)\n\n    current_auid = int(post.meta('author.uid') or current_user.uid)\n\n    if (not current_user.can_edit_all_posts and\n            current_auid != current_user.uid):\n        return error(\"Cannot edit posts of other users.\", 401)\n\n    if request.method == 'POST':\n        meta = {}\n        for k, v in request.form.items():\n            meta[k] = v\n        meta.pop('_wysihtml5_mode', '')\n        try:\n            meta['author'] = get_user(meta['author.uid']).realname\n            current_auid = int(meta['author.uid'])\n            author_change_success = True\n        except Exception:\n            author_change_success = False\n        if (not current_user.can_transfer_post_authorship or\n                not author_change_success):\n            meta['author'] = post.meta('author') or current_user.realname\n            meta['author.uid'] = str(current_auid)\n\n        twofile = post.is_two_file\n        onefile = not twofile\n        post.compiler.create_post(post.source_path, onefile=onefile,\n                                  is_page=False, **meta)\n\n        context['post_content'] = meta['content']\n\n        if twofile:\n            meta_path = os.path.splitext(path)[0] + '.meta'\n            # We cannot save `content` as meta, otherwise things break badly\n            meta.pop('content', '')\n            with io.open(meta_path, 'w+', encoding='utf-8') as fh:\n                fh.write(write_metadata(meta))\n        scan_site()\n        if db is not None:\n            db.set('site:needs_rebuild', '1')\n        else:\n            site.coil_needs_rebuild = '1'\n        post = find_post(path)\n        context['action'] = 'save'\n    else:\n        context['action'] = 'edit'\n        with io.open(path, 'r', encoding='utf-8') as fh:\n            context['post_content'] = fh.read()\n            if not post.is_two_file:\n                context['post_content'] = context['post_content'].split(\n                    '\\n\\n', 1)[1]\n\n    context['post'] = post\n    users = []\n    if db is not None:\n        uids = db.hgetall('users').values()\n        for u in uids:\n            u = u.decode('utf-8')\n            realname, active = db.hmget('user:{0}'.format(u),\n                                        'realname', 'active')\n            if active in (u'1', b'1'):\n                users.append((u, realname.decode('utf-8')))\n    else:\n        for u, d in app.config['COIL_USERS'].items():\n            if d['active']:\n                users.append((int(u), d['realname']))\n    context['users'] = sorted(users)\n    context['current_auid'] = current_auid\n    context['title'] = 'Editing {0}'.format(post.title())\n    context['is_html'] = post.compiler.name == 'html'\n    return render('coil_post_edit.tmpl', context)", "response": "Edit a post.\n\n    If requested over GET, shows the edit UI.\n    If requested over POST, saves the post and shows the edit UI.\n\n    :param path: Path to post to edit."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef api_rebuild():\n    if db is None:\n        return '{\"error\": \"single-user mode\"}'\n    build_job = q.fetch_job('build')\n    orphans_job = q.fetch_job('orphans')\n\n    if not build_job and not orphans_job:\n        build_job = q.enqueue_call(func=coil.tasks.build,\n                                   args=(app.config['REDIS_URL'],\n                                         app.config['NIKOLA_ROOT'],\n                                         ''),\n                                   job_id='build')\n        orphans_job = q.enqueue_call(func=coil.tasks.orphans,\n                                     args=(app.config['REDIS_URL'],\n                                           app.config['NIKOLA_ROOT']),\n                                     job_id='orphans', depends_on=build_job)\n\n    d = json.dumps({'build': build_job.meta, 'orphans': orphans_job.meta})\n\n    if ('status' in build_job.meta and\n            build_job.meta['status'] is not None and\n            'status' in orphans_job.meta and\n            orphans_job.meta['status'] is not None):\n        rq.cancel_job('build', db)\n        rq.cancel_job('orphans', db)\n        db.set('site:needs_rebuild', '0')\n        site.coil_needs_rebuild = '1'\n\n    return d", "response": "Rebuild the site ( internally )."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrebuild the site with a nice UI.", "response": "def rebuild(mode=''):\n    \"\"\"Rebuild the site with a nice UI.\"\"\"\n    scan_site()  # for good measure\n    if not current_user.can_rebuild_site:\n        return error('You are not permitted to rebuild the site.</p>'\n                     '<p class=\"lead\">Contact an administartor for '\n                     'more information.', 401)\n    if db is not None:\n        db.set('site:needs_rebuild', '-1')\n        if not q.fetch_job('build') and not q.fetch_job('orphans'):\n            b = q.enqueue_call(func=coil.tasks.build,\n                               args=(app.config['REDIS_URL'],\n                                     app.config['NIKOLA_ROOT'], mode),\n                               job_id='build')\n            q.enqueue_call(func=coil.tasks.orphans,\n                           args=(app.config['REDIS_URL'],\n                                 app.config['NIKOLA_ROOT']), job_id='orphans',\n                           depends_on=b)\n        return render('coil_rebuild.tmpl', {'title': 'Rebuild'})\n    else:\n        status, outputb = coil.tasks.build_single(mode)\n        _, outputo = coil.tasks.orphans_single()\n        site.coil_needs_rebuild = '0'\n        return render('coil_rebuild_single.tmpl',\n                      {'title': 'Rebuild', 'status': '1' if status else '0',\n                       'outputb': outputb, 'outputo': outputo})"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new post or page.", "response": "def new(obj):\n    \"\"\"Create a new post or page.\n\n    :param str obj: Object to create (post or page)\n    \"\"\"\n    title = request.form['title']\n    _site.config['ADDITIONAL_METADATA']['author.uid'] = current_user.uid\n    try:\n        title = title.encode(sys.stdin.encoding)\n    except (AttributeError, TypeError):\n        title = title.encode('utf-8')\n    try:\n        if obj == 'post':\n            f = NewPostForm()\n            if f.validate():\n                _site.commands.new_post(title=title,\n                                        author=current_user.realname,\n                                        content_format='html')\n            else:\n                return error(\"Bad Request\", 400)\n        elif obj == 'page':\n            f = NewPageForm()\n            if f.validate():\n                _site.commands.new_page(title=title,\n                                        author=current_user.realname,\n                                        content_format='html')\n            else:\n                return error(\"Bad Request\", 400)\n        else:\n            return error(\"Cannot create {0} \u2014 unknown type.\".format(obj), 400)\n    except SystemExit:\n        return error(\"This {0} already exists!\".format(obj), 500)\n    finally:\n        del _site.config['ADDITIONAL_METADATA']['author.uid']\n    # reload post list and go to index\n    scan_site()\n    if db is not None:\n        db.set('site:needs_rebuild', '1')\n    else:\n        site.coil_needs_rebuild = '1'\n    return redirect(url_for('index'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nserves bower components. This is meant to be used ONLY by the internal dev server. Please configure your web server to handle requests to this URL:: /bower_components/ => coil/data/bower_components", "response": "def serve_bower_components(path):\n    \"\"\"Serve bower components.\n\n    This is meant to be used ONLY by the internal dev server.\n    Please configure your web server to handle requests to this URL::\n\n        /bower_components/ => coil/data/bower_components\n    \"\"\"\n    res = pkg_resources.resource_filename(\n        'coil', os.path.join('data', 'bower_components'))\n    return send_from_directory(res, path)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef serve_coil_assets(path):\n    res = pkg_resources.resource_filename(\n        'coil', os.path.join('data', 'coil_assets'))\n    return send_from_directory(res, path)", "response": "Serve Coil assets.\n\n    This is meant to be used ONLY by the internal dev server.\n    Please configure your web server to handle requests to this URL::\n\n        /coil_assets/ => coil/data/coil_assets"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef serve_assets(path):\n    res = os.path.join(app.config['NIKOLA_ROOT'],\n                       _site.config[\"OUTPUT_FOLDER\"], 'assets')\n    return send_from_directory(res, path)", "response": "Serve Nikola assets.\n\n    This is meant to be used ONLY by the internal dev server.\n    Please configure your web server to handle requests to this URL::\n\n        /assets/ => output/assets"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmanages the user account of currently - logged - in users.", "response": "def acp_account():\n    \"\"\"Manage the user account of currently-logged-in users.\n\n    This does NOT accept admin-specific options.\n    \"\"\"\n    if request.args.get('status') == 'pwdchange':\n        alert = 'You must change your password before proceeding.'\n        alert_status = 'danger'\n        pwdchange_skip = True\n    else:\n        alert = ''\n        alert_status = ''\n        pwdchange_skip = False\n\n    if db is None:\n        form = PwdHashForm()\n        return render('coil_account_single.tmpl',\n                      context={'title': 'My account',\n                               'form': form,\n                               'alert': alert,\n                               'alert_status': alert_status})\n\n    action = 'edit'\n    form = AccountForm()\n    if request.method == 'POST':\n        if int(current_user.uid) in app.config['COIL_USERS_PREVENT_EDITING']:\n            return error(\"Cannot edit data for this user.\", 403)\n        if not form.validate():\n            return error(\"Bad Request\", 400)\n        action = 'save'\n        data = request.form\n        if data['newpwd1']:\n            try:\n                pwd_ok = check_password(current_user.password, data['oldpwd'])\n            except ValueError:\n                if current_user.password.startswith('$2a$12'):\n                    # old bcrypt hash\n                    pwd_ok = check_old_password(current_user.password,\n                                                data['oldpwd'])\n\n            if data['newpwd1'] == data['newpwd2'] and pwd_ok:\n                current_user.password = password_hash(data['newpwd1'])\n                current_user.must_change_password = False\n                pwdchange_skip = True\n            else:\n                alert = 'Passwords don\u2019t match.'\n                alert_status = 'danger'\n                action = 'save_fail'\n        current_user.realname = data['realname']\n        current_user.email = data['email']\n        current_user.wants_all_posts = 'wants_all_posts' in data\n        write_user(current_user)\n\n    return render('coil_account.tmpl',\n                  context={'title': 'My account',\n                           'action': action,\n                           'alert': alert,\n                           'alert_status': alert_status,\n                           'form': form,\n                           'pwdchange_skip': pwdchange_skip})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef acp_users_edit():\n    global current_user\n    if not current_user.is_admin:\n        return error(\"Not authorized to edit users.\", 401)\n    if not db:\n        return error('The ACP is not available in single-user mode.', 500)\n    data = request.form\n\n    form = UserEditForm()\n    if not form.validate():\n        return error(\"Bad Request\", 400)\n    action = data['action']\n\n    if action == 'new':\n        if not data['username']:\n            return error(\"No username to create specified.\", 400)\n        uid = max(int(i) for i in db.hgetall('users').values()) + 1\n        pf = [False for p in PERMISSIONS]\n        pf[0] = True  # active\n        pf[7] = True  # must_change_password\n        user = User(uid, data['username'], '', '', '', *pf)\n        write_user(user)\n        db.hset('users', user.username, user.uid)\n        new = True\n    else:\n        user = get_user(data['uid'])\n        new = False\n\n    if not user:\n        return error(\"User does not exist.\", 404)\n\n    alert = ''\n    alert_status = ''\n\n    if action == 'save':\n        if data['newpwd1']:\n            if data['newpwd1'] == data['newpwd2']:\n                user.password = password_hash(data['newpwd1'])\n            else:\n                alert = 'Passwords don\u2019t match.'\n                alert_status = 'danger'\n                action = 'save_fail'\n        elif new:\n            alert = 'Must set a password.'\n            alert_status = 'danger'\n            action = 'save_fail'\n\n        if data['username'] != user.username:\n            db.hdel('users', user.username)\n            user.username = data['username']\n            db.hset('users', user.username, user.uid)\n        user.realname = data['realname']\n        user.email = data['email']\n        for p in PERMISSIONS:\n            setattr(user, p, p in data)\n        user.active = True\n        if user.uid == current_user.uid:\n            user.is_admin = True\n            user.must_change_password = False\n            current_user = user\n        write_user(user)\n\n    return render('coil_users_edit.tmpl',\n                  context={'title': 'Edit user',\n                           'user': user,\n                           'new': new,\n                           'action': action,\n                           'alert': alert,\n                           'alert_status': alert_status,\n                           'form': form})", "response": "Edit an user account."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nimports users from a TSV file.", "response": "def acp_users_import():\n    \"\"\"Import users from a TSV file.\"\"\"\n    if not current_user.is_admin:\n        return error(\"Not authorized to edit users.\", 401)\n    if not db:\n        return error('The ACP is not available in single-user mode.', 500)\n\n    form = UserImportForm()\n    if not form.validate():\n        return error(\"Bad Request\", 400)\n    fh = request.files['tsv'].stream\n    tsv = fh.read()\n    return tsv"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef acp_users_delete():\n    if not current_user.is_admin:\n        return error(\"Not authorized to edit users.\", 401)\n    if not db:\n        return error('The ACP is not available in single-user mode.', 500)\n\n    form = UserDeleteForm()\n    if not form.validate():\n        return error(\"Bad Request\", 400)\n    user = get_user(int(request.form['uid']))\n    direction = request.form['direction']\n    if not user:\n        return error(\"User does not exist.\", 404)\n    else:\n        for p in PERMISSIONS:\n            setattr(user, p, False)\n        user.active = direction == 'undel'\n        write_user(user)\n        return redirect(url_for('acp_users') + '?status={_del}eted'.format(\n            _del=direction))", "response": "Delete or undelete an user account."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef openXmlDocument(path=None, file_=None, data=None, url=None, mime_type=None):\n    if path is not None:\n        file_ = open(path, 'rb')\n    elif file_ is not None:\n        assert hasattr(file_, 'read')\n    elif url is not None:\n        file_ = urllib2.urlopen(url)\n        if mime_type is None:\n            mime_type = file_.headers.gettype()\n    elif data is not None:\n        file_ = cStringIO.StringIO(data)\n        assert mime_type is not None\n    else:\n        raise ValueError(\"Either path, file_, data, or url should be provided\")\n\n    # Mime type based document\n    if mime_type is not None:\n        for class_ in _document_classes:\n            if class_.canProcessMime(mime_type):\n                return class_(file_, mime_type=mime_type)\n        raise ValueError(\"%s MIME type is unknown.\" % mime_type)\n\n    else:\n        assert hasattr(file_, 'name')\n\n        for class_ in _document_classes:\n            if class_.canProcessFilename(file_.name):\n                return class_(file_, mime_type=mime_type)\n        raise ValueError(\"Can't guess mime_type. You should set the mime_type param\")\n    return", "response": "Function that opens an Open XML document and returns the appropriate document type."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns whether the C extension is installed correctly.", "response": "def is_installed():\n  # type: () -> bool\n  \"\"\"\n  Returns whether the C extension is installed correctly.\n  \"\"\"\n  try:\n    # noinspection PyUnresolvedReferences\n    from ccurl import Curl as CCurl\n  except ImportError:\n    return False\n  else:\n    # noinspection PyUnresolvedReferences\n    from iota.crypto import Curl\n    return issubclass(Curl, CCurl)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmaps a key name to a specific comparison function", "response": "def make_compare(key, value, obj):\n    \"Map a key name to a specific comparison function\"\n    if '__' not in key:\n        # If no __ exists, default to doing an \"exact\" comparison\n        key, comp = key, 'exact'\n    else:\n        key, comp = key.rsplit('__', 1)\n    # Check if comp is valid\n    if hasattr(Compare, comp):\n        return getattr(Compare, comp)(key, value, obj)\n    raise AttributeError(\"No comparison '%s'\" % comp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef array(self):\n        if not hasattr(self, '_array'): self._array = self.load_data()\n        return self._array", "response": "Return the array of the n - grams in the current directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef error(self):\n        if not hasattr(self, '_error'):\n            if any(v is not None for v in self.error_columns):\n                self._error = self.load_error()\n            else:\n                return (None, None)\n        return self._error", "response": "Return the error associated with the data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef genfromtxt_args_error(self):\n        if not hasattr(self, '_genfromtxt_args_error'):\n            self._genfromtxt_args_error = self.genfromtxt_args.copy()\n        return self._genfromtxt_args_error", "response": "Return a copy of the object with the error values set for the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_data(self):\n        array = numpy.genfromtxt(self.path, **self.genfromtxt_args)\n        for n, scale in enumerate(self.scale): array[n,:] *= self.scale[n]\n        return array", "response": "Loads data from scipy_data_fitting. Data. path using numpy. genfromtxt and returns a numpy. ndarray."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_error(self):\n        usecols = []\n        for v in self.error_columns:\n            if v is None:\n                pass\n            elif isinstance(v, int):\n                usecols.append(v)\n            elif len(v) is 2:\n                for n in v: usecols.append(n)\n        self.genfromtxt_args_error['usecols'] = tuple(usecols)\n\n        array = numpy.genfromtxt(self.path, **self.genfromtxt_args_error)\n\n        error = []\n        for n, v in enumerate(self.error_columns):\n            if v is None:\n                error.append(None)\n            elif isinstance(v, int):\n                if len(usecols) is 1:\n                    error.append(array * self.scale[n])\n                else:\n                    error.append(array[0] * self.scale[n])\n                    array = numpy.delete(array, (0), axis=(0))\n            elif len(v) is 2:\n                error.append(array[0:2] * self.scale[n])\n                array = numpy.delete(array, (0, 1), axis=(0))\n\n        return tuple(error)", "response": "Loads error values from the file and returns a two element tuple where each element is of a form described by the cases 3 and 4 in scipy_data_fitting. Data. error."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nempties method to call to slurp up args and kwargs. `args` get pushed onto the url path. `kwargs` are converted to a query string and appended to the URL.", "response": "def mock_attr(self, *args, **kwargs):\n        \"\"\"\n        Empty method to call to slurp up args and kwargs.\n\n        `args` get pushed onto the url path.\n        `kwargs` are converted to a query string and appended to the URL.\n        \"\"\"\n        self.path.extend(args)\n        self.qs.update(kwargs)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef column(self):\n        for i in my_xrange(self._column_query_pos, self.pos):\n            if self.text[i] == '\\t':\n                self._column += self.tab_size\n                self._column -= self._column % self.tab_size\n            else:\n                self._column += 1\n        self._column_query_pos = self.pos\n        return self._column", "response": "Returns the column number based on the current position of the parser."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlooks for a key from the input text without actually stepping the current position.", "response": "def peek(self, offset=0):\n        \"\"\" Looking forward in the input text without actually stepping the current position.\n        returns None if the current position is at the end of the input. \"\"\"\n        pos = self.pos + offset\n        if pos >= self.end:\n            return None\n        return self.text[pos]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef expect(self, c):\n        if self.peek() != c:\n            self.error('Expected \"%c\"' % (c,))\n        self.skip_char()", "response": "expects a specific character"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse(self, json_text, listener):\n        listener.begin_parsing(self)\n        try:\n            self.init_text_parser(json_text)\n            self.listener = listener\n\n            c = self._skip_spaces_and_peek()\n            if c == '{':\n                if self.params.root_is_array:\n                    self.error('The root of the json is expected to be an array!')\n                self._parse_object()\n            elif c == '[':\n                if not self.params.root_is_array:\n                    self.error('The root of the json is expected to be an object!')\n                self._parse_array()\n            else:\n                self.error('The json string should start with \"%s\"' % (\n                    '[' if self.params.root_is_array else '{'))\n\n            if self._skip_spaces_and_peek() is not None:\n                self.error('Garbage detected after the parsed json!')\n        finally:\n            listener.end_parsing()", "response": "Parses the specified json_text and emits parser events to the listener."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _skip_spaces_and_peek(self):\n        while 1:\n            # skipping spaces\n            self.skip_chars(self.end, lambda x: x in self.spaces)\n            c = self.peek()\n            if not self.params.allow_comments:\n                return c\n            if c != '/':\n                return c\n            d = self.peek(1)\n            if d == '/':\n                self.skip_to(self.pos + 2)\n                self._skip_singleline_comment()\n            elif d == '*':\n                self.skip_to(self.pos + 2)\n                self._skip_multiline_comment()\n            else:\n                return c", "response": "Skips all spaces and comments and returns the first character that follows the skipped spaces and comments."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses a string that doesn t have quotation marks so it doesn t have special characters so it doesn t have special characters so it doesn t have special characters so it doesn t have special characters so it doesn t have special characters so it doesn t have special characters.", "response": "def _parse_and_return_unquoted_string(self):\n        \"\"\"\n        Parses a string that has no quotation marks so it doesn't\n        contain any special characters and we don't have to interpret\n        any escape sequences.\n        :return: (string, quoted=False, end_of_string_pos)\n        \"\"\"\n        begin = self.pos\n        for end in my_xrange(self.pos, self.end):\n            if self.text[end] in self.spaces_and_special_chars:\n                break\n        else:\n            end = self.end\n        if begin == end:\n            self.error('Expected a scalar here.')\n        return self.text[begin:end], False, end"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _parse_and_return_quoted_string(self):\n        result = []\n        pos = self.pos + 1\n        segment_begin = pos\n        my_chr = my_unichr if isinstance(self.text, my_unicode) else utf8chr\n        while pos < self.end:\n            c = self.text[pos]\n            if c < ' ' and c != '\\t':\n                self.skip_to(pos)\n                self.error('Encountered a control character that isn\\'t allowed in quoted strings.')\n            elif c == '\"':\n                if segment_begin < pos:\n                    result.append(self.text[segment_begin:pos])\n                pos += 1\n                return ''.join(result), True, pos\n            elif c == '\\\\':\n                if segment_begin < pos:\n                    result.append(self.text[segment_begin:pos])\n                pos += 1\n                if pos >= self.end:\n                    break\n                c = self.text[pos]\n                if c == 'u':\n                    code_point, pos = self._handle_unicode_escape(pos)\n                    result.append(my_chr(code_point))\n                else:\n                    char, pos = self._handle_escape(pos, c)\n                    result.append(char)\n                segment_begin = pos\n            else:\n                pos += 1\n        self.error('Reached the end of stream while parsing quoted string.')", "response": "Parses a string that has quotation marks so it may contain special characters and escape sequences."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ask_yesno(query, default=None):\n    if default is None:\n        default_q = ' [y/n]'\n    elif default is True:\n        default_q = ' [Y/n]'\n    elif default is False:\n        default_q = ' [y/N]'\n    if sys.version_info[0] == 3:\n        inp = raw_input(\"{query}{default_q} \".format(\n            query=query, default_q=default_q)).strip()\n    else:\n        inp = raw_input(\"{query}{default_q} \".format(\n            query=query, default_q=default_q).encode('utf-8')).strip()\n    if inp:\n        return inp.lower().startswith('y')\n    elif default is not None:\n        return default\n    else:\n        # Loop if no answer and no default.\n        return ask_yesno(query, default)", "response": "Ask a yes or no question."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreloading the site from the database.", "response": "def reload_site(self):\n        \"\"\"Reload the site from the database.\"\"\"\n        rev = int(self.db.get('site:rev'))\n        if rev != self.revision and self.db.exists('site:rev'):\n            timeline = self.db.lrange('site:timeline', 0, -1)\n            self._timeline = []\n            for data in timeline:\n                data = json.loads(data.decode('utf-8'))\n                self._timeline.append(Post(data[0], self.config, data[1],\n                                           data[2], data[3], self.messages,\n                                           self._site.compilers[data[4]]))\n\n            self._read_indexlist('posts')\n            self._read_indexlist('all_posts')\n            self._read_indexlist('pages')\n\n            self.revision = rev\n            self.logger.info(\"Site updated to revision {0}.\".format(rev))\n        elif rev == self.revision and self.db.exists('site:rev'):\n            pass\n        else:\n            self.logger.warn(\"Site needs rescanning.\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread a list of indexes.", "response": "def _read_indexlist(self, name):\n        \"\"\"Read a list of indexes.\"\"\"\n        setattr(self, '_' + name, [self._timeline[int(i)] for i in\n                                   self.db.lrange('site:{0}'.format(name), 0,\n                                                  -1)])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite a list of indexes.", "response": "def _write_indexlist(self, name):\n        \"\"\"Write a list of indexes.\"\"\"\n        d = [self._site.timeline.index(p) for p in getattr(self._site, name)]\n        self.db.delete('site:{0}'.format(name))\n        if d:\n            self.db.rpush('site:{0}'.format(name), *d)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nscan the site for posts.", "response": "def scan_posts(self, really=True, ignore_quit=False, quiet=True):\n        \"\"\"Rescan the site.\"\"\"\n        while (self.db.exists('site:lock') and\n               int(self.db.get('site:lock')) != 0):\n            self.logger.info(\"Waiting for DB lock...\")\n            time.sleep(0.5)\n        self.db.incr('site:lock')\n        self.logger.info(\"Lock acquired.\")\n        self.logger.info(\"Scanning site...\")\n\n        self._site.scan_posts(really, ignore_quit, quiet)\n\n        timeline = []\n        for post in self._site.timeline:\n            data = [post.source_path, post.folder, post.is_post,\n                    post._template_name, post.compiler.name]\n            timeline.append(json.dumps(data))\n        self.db.delete('site:timeline')\n        if timeline:\n            self.db.rpush('site:timeline', *timeline)\n\n        self._write_indexlist('posts')\n        self._write_indexlist('all_posts')\n        self._write_indexlist('pages')\n\n        self.db.incr('site:rev')\n\n        self.db.decr('site:lock')\n        self.logger.info(\"Lock released.\")\n        self.logger.info(\"Site scanned.\")\n        self.reload_site()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the current timeline reloading the site if needed.", "response": "def timeline(self):\n        \"\"\"Get timeline, reloading the site if needed.\"\"\"\n        rev = int(self.db.get('site:rev'))\n        if rev != self.revision:\n            self.reload_site()\n\n        return self._timeline"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the posts from the database reloading the site if needed.", "response": "def posts(self):\n        \"\"\"Get posts, reloading the site if needed.\"\"\"\n        rev = int(self.db.get('site:rev'))\n        if rev != self.revision:\n            self.reload_site()\n\n        return self._posts"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef all_posts(self):\n        rev = self.db.get('site:rev')\n        if int(rev) != self.revision:\n            self.reload_site()\n\n        return self._all_posts", "response": "Get all_posts reloads the site if needed."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pages(self):\n        rev = self.db.get('site:rev')\n        if int(rev) != self.revision:\n            self.reload_site()\n\n        return self._pages", "response": "Get pages reloading the site if needed."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef loads(s,\n          parser_params=JSONParserParams(),\n          object_builder_params=PythonObjectBuilderParams()):\n    \"\"\"\n    Loads a json string as a python object hierarchy just like the standard json.loads(). Unlike\n    the standard json.loads() this function uses OrderedDict instances to represent json objects\n    but the class of the dictionary to be used is configurable.\n    :param s: The json string to load.\n    :params parser_params: Parser parameters.\n    :type parser_params: JSONParserParams\n    :param object_builder_params: Parameters to the ObjectBuilderParserListener, these parameters\n    are mostly factories to create the python object hierarchy while parsing.\n    \"\"\"\n    parser = JSONParser(parser_params)\n    listener = ObjectBuilderParserListener(object_builder_params)\n    parser.parse(s, listener)\n    return listener.result", "response": "Loads a json string as a python object hierarchy."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload a json string into a json object hierarchy.", "response": "def loads_config(s,\n                 parser_params=JSONParserParams(),\n                 string_to_scalar_converter=DefaultStringToScalarConverter()):\n    \"\"\"\n    Works similar to the loads() function but this one returns a json object hierarchy\n    that wraps all json objects, arrays and scalars to provide a nice config query syntax.\n    For example:\n    my_config = loads_config(json_string)\n    ip_address = my_config.servers.reverse_proxy.ip_address()\n    port = my_config.servers.reverse_proxy.port(80)\n\n    Note that the raw unwrapped values can be fetched with the __call__ operator.\n    This operator has the following signature: __call__(default=None, mapper=None).\n    Fetching a value without specifying a default value means that the value is required\n    and it has to be in the config. If it isn't there then a JSONConfigValueNotFoundError\n    is raised. The optional mapper parameter can be a function that receives the unwrapped\n    value and it can return something that may be based on the input parameter. You can\n    also use this mapper parameter to pass a function that performs checking on the\n    value and raises an exception (eg. ValueError) on error.\n\n    If you specify a default value and the required config value is not present then\n    default is returned. In this case mapper isn't called with the default value.\n    \"\"\"\n    parser = JSONParser(parser_params)\n    object_builder_params = ConfigObjectBuilderParams(string_to_scalar_converter=string_to_scalar_converter)\n    listener = ObjectBuilderParserListener(object_builder_params)\n    parser.parse(s, listener)\n    return listener.result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load(file_, *args, **kwargs):\n    json_str = load_utf_text_file(\n        file_,\n        default_encoding=kwargs.pop('default_encoding', 'UTF-8'),\n        use_utf8_strings=kwargs.pop('use_utf8_strings', True),\n    )\n    return loads(json_str, *args, **kwargs)", "response": "Loads a new object from a file containing a json string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_config(file_, *args, **kwargs):\n    json_str = load_utf_text_file(\n        file_,\n        default_encoding=kwargs.pop('default_encoding', 'UTF-8'),\n        use_utf8_strings=kwargs.pop('use_utf8_strings', True),\n    )\n    return loads_config(json_str, *args, **kwargs)", "response": "Loads a config file into a new object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef options(self):\n        if not hasattr(self, '_options'):\n            self._options = {\n                'fit_function': scipy.optimize.curve_fit,\n                'maxfev': 1000,\n            }\n        return self._options", "response": "Return a dictionary of options that affect the curve fitting algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a tuple of the limits for the independent variable when creating a linespace plot etc.", "response": "def limits(self):\n        \"\"\"\n        Limits to use for the independent variable whenever\n        creating a linespace, plot, etc.\n\n        Defaults to `(-x, x)` where `x` is the largest absolute value\n        of the data corresponding to the independent variable.\n        If no such values are negative, defaults to `(0, x)` instead.\n        \"\"\"\n        if not hasattr(self, '_limits'):\n            xmax = max(abs(self.data.array[0]))\n            xmin = min(self.data.array[0])\n\n            x_error = self.data.error[0]\n            if isinstance(x_error, numpy.ndarray):\n                if x_error.ndim == 0: xmax = xmax + x_error\n\n            if xmin < 0:\n                self._limits = (-xmax, xmax)\n            else:\n                self._limits = (0, xmax)\n\n        return self._limits"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef all_variables(self):\n        variables = []\n        variables.extend(self.free_variables)\n        variables.append(self.independent['symbol'])\n        variables.extend([ param['symbol'] for param in self.fitting_parameters ])\n        variables.extend([ param['symbol'] for param in self.fixed_parameters ])\n        variables.extend([ const['symbol'] for const in self.constants ])\n\n        symbols = []\n        for variable in variables:\n            if isinstance(variable, str):\n                symbols.append(self.model.symbol(variable))\n            else:\n                symbols.append(variable)\n\n        return tuple(symbols)", "response": "A flat tuple of all variables taken in order from the following ones."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef function(self):\n        if not hasattr(self,'_function'):\n            function = self.model.lambdify(self.expression, self.all_variables, **self.lambdify_options)\n            self._function = lambda *x: function(*(x + self.fixed_values))\n        return self._function", "response": "Returns the function that takes a single parameter and returns the result of the fit_function."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a function that minimizes the function for a given class.", "response": "def lmfit_fcn2min(self):\n        \"\"\"\n        The function to minimize when using [lmfit][1].\n\n        If overriding this, the replacement function must accept the following\n        non-keyword arguments in this order (even if unused):\n\n        1. A [`lmfit.Parameters`][2] object.\n           The value of each parameter must be passed appropriately to `scipy_data_fitting.Fit.function`\n           in the order determined by sorting the parameter keys alphabetically.\n           Use `scipy_data_fitting.Fit.lmfit_parameter_values` to get the ordered numerical parameter values.\n        2. Independent values: see `scipy_data_fitting.Data.array`.\n        3. Dependent values: see `scipy_data_fitting.Data.array`.\n        4. The error: see `scipy_data_fitting.Data.error`.\n\n\n        The default function computes the difference between the evaluated function and the data.\n\n        Default example:\n\n            #!python\n            lambda params, x, data, error: self.function(x, *self.lmfit_parameter_values(params)) - data\n\n        [1]: https://pypi.python.org/pypi/lmfit/\n        [2]: http://lmfit.github.io/lmfit-py/parameters.html#the-parameters-class\n        [3]: http://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html\n        \"\"\"\n        return lambda params, x, data, error: self.function(x, *self.lmfit_parameter_values(params)) - data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef curve_fit(self):\n        if not hasattr(self,'_curve_fit'):\n            options = self.options.copy()\n            fit_function = options.pop('fit_function')\n            independent_values = self.data.array[0]\n            dependent_values = self.data.array[1]\n\n            if fit_function == 'lmfit':\n                self._curve_fit = lmfit.minimize(\n                    self.lmfit_fcn2min, self.lmfit_parameters,\n                    args=(independent_values, dependent_values, self.data.error), **options)\n            else:\n                p0 = [ prefix_factor(param) * param['guess'] for param in self.fitting_parameters ]\n                self._curve_fit = fit_function(\n                    self.function, independent_values, dependent_values, p0, **options)\n\n        return self._curve_fit", "response": "Fits the function to the data and returns\n        the output from the curve fitting function."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fitted_parameters(self):\n        if hasattr(self,'_fitted_parameters'): return self._fitted_parameters\n        if not self.fitting_parameters: return tuple()\n        if self.options['fit_function'] == 'lmfit':\n            return tuple( self.curve_fit.params[key].value for key in sorted(self.curve_fit.params) )\n        else:\n            return tuple(self.curve_fit[0])", "response": "A tuple of fitted values for the fitting parameters."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef compute_quantity(self, quantity):\n        quantity = quantity.copy()\n        expression = self.model.replace(quantity.pop('expression'), self.replacements)\n        variables = self.all_variables[len(self.free_variables) + 1:]\n        function = self.model.lambdify(expression, variables, **self.lambdify_options)\n        quantity['value'] = function(*(self.fitted_parameters + self.fixed_values)) * prefix_factor(quantity)**(-1)\n        return quantity", "response": "Computes the value of a single quantity as described and used\n        in scipy_data_fitting. Fit. computed_quantities."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of dicts with the fitted parameters.", "response": "def computed_fitting_parameters(self):\n        \"\"\"\n        A list identical to what is set with `scipy_data_fitting.Fit.fitting_parameters`,\n        but in each dictionary, the key `value` is added with the fitted value of the quantity.\n        The reported value is scaled by the inverse prefix.\n        \"\"\"\n        fitted_parameters = []\n        for (i, v) in enumerate(self.fitting_parameters):\n            param = v.copy()\n            param['value'] = self.fitted_parameters[i] * prefix_factor(param)**(-1)\n            fitted_parameters.append(param)\n\n        return fitted_parameters"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a dictionary that summarizes the results of the fit.", "response": "def metadata(self):\n        \"\"\"\n        A dictionary which summarizes the results of the fit:\n\n            #!python\n            {\n                'name': self.name,\n                'description': self.description,\n                'independent': self.independent,\n                'dependent': self.dependent,\n                'quantities': self.computed_quantities,\n                'fixed_parameters': self.fixed_parameters,\n                'fitted_parameters': self.computed_fitting_parameters,\n            }\n        \"\"\"\n        return {\n          'name': self.name,\n          'description': self.description,\n          'independent': self.independent,\n          'dependent': self.dependent,\n          'quantities': self.computed_quantities,\n          'fixed_parameters': self.fixed_parameters,\n          'fitted_parameters': self.computed_fitting_parameters,\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pointspace(self, **kwargs):\n        scale_array = numpy.array([\n            [prefix_factor(self.independent)**(-1)],\n            [prefix_factor(self.dependent)**(-1)]\n        ])\n\n        linspace = numpy.linspace(self.limits[0], self.limits[1], **kwargs)\n        return {\n          'data': self.data.array * scale_array,\n          'fit': numpy.array([linspace, self.fitted_function(linspace)]) * scale_array\n        }", "response": "Returns a dictionary with the keys data and fit."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting the results of the fit to a json file at path.", "response": "def to_json(self, path, points=50, meta=None):\n        \"\"\"\n        Write the results of the fit to a json file at `path`.\n\n        `points` will define the length of the `fit` array.\n\n        If `meta` is given, a `meta` key be added with the given value.\n\n        The json object has the form\n\n            #!text\n            {\n                'data': [ [x1, y1], [x2, y2], ... ],\n                'fit': [ [x1, y1], [x2, y2], ... ],\n                'meta': meta\n            }\n        \"\"\"\n        pointspace = self.pointspace(num=points)\n        fit_points = numpy.dstack(pointspace['fit'])[0]\n        data_points = numpy.dstack(pointspace['data'])[0]\n\n        fit = [ [ point[0],  point[1] ] for point in fit_points ]\n        data = [ [ point[0],  point[1] ] for point in data_points ]\n\n        obj = {'data': data, 'fit': fit}\n        if meta: obj['meta'] = meta\n\n        f = open(path, 'w')\n        json.dump(obj, f)\n        f.close"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a tuple containing the values of the parameters in params.", "response": "def lmfit_parameter_values(self, params):\n        \"\"\"\n        `params` is a [`lmfit.Parameters`][1] object.\n\n        Returns a tuple containing the values of the parameters in `params`.\n\n        The order is determined by sorting the parameter keys alphabetically.\n\n        [1]: http://lmfit.github.io/lmfit-py/parameters.html#the-parameters-class\n\n        \"\"\"\n        return tuple( params[key].value for key in sorted(params) )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef clean_for_doc(nb):\n    new_cells = []\n    for cell in nb.worksheets[0].cells:\n        # Remove the pylab inline line.\n        if \"input\" in cell and cell[\"input\"].strip() == \"%pylab inline\":\n            continue\n        # Remove output resulting from the stream/trace method chaining.\n        if \"outputs\" in cell:\n            outputs = [_i for _i in cell[\"outputs\"] if \"text\" not in _i or\n                       not _i[\"text\"].startswith(\"<obspy.core\")]\n            cell[\"outputs\"] = outputs\n        new_cells.append(cell)\n    nb.worksheets[0].cells = new_cells\n    return nb", "response": "Cleans the notebook to be suitable for inclusion in the docs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef strip_output(nb):\n    for cell in nb.worksheets[0].cells:\n        if 'outputs' in cell:\n            cell['outputs'] = []\n        if 'prompt_number' in cell:\n            cell['prompt_number'] = None\n    return nb", "response": "strip the outputs from a notebook object"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the callback function for updating the plot.", "response": "def set_call_back(self, func):\n\n        \"\"\"sets callback function for updating the plot.\n        in the callback function implement the logic of reading of serial input\n        also the further processing of the signal if necessary has to be done\n        in this\n        callbak function.\"\"\"\n\n        self.timer.add_callback(func)\n        self.timer.start()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef plot_self(self, func):\n\n        \"\"\"define your callback function with the decorator @plotter.plot_self.\n        in the callback function set the data of lines\n        in the plot using self.lines[i][j].set_data(your data)\"\"\"\n\n        def func_wrapper():\n\n            func()\n\n            try:\n\n                self.manager.canvas.draw()\n\n            except ValueError as ve:\n                print(ve)\n                pass\n\n            except RuntimeError as RtE:\n                print(RtE)\n                pass\n\n            except Exception as e:\n                print(e)\n                pass\n\n        return func_wrapper", "response": "decorator for plotting the object with the plotter"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef all(cls):\n        if not hasattr(cls, '_cache'):\n            cls._cache = cls._all()\n        return cls._cache", "response": "Wrapper around _all to cache all results of something\n           "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(cls, **kwargs):\n        things = cls.filter(**kwargs)\n        if len(things) > 1:\n            # Raise an exception if more than one object is matched\n            raise cls.MultipleObjectsReturned\n        elif len(things) == 0:\n            # Rase an exception if no objects were matched\n            raise cls.DoesNotExist\n        return things[0]", "response": "Generic get method for one item only\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reconnect_redis(self):\n        '''Reconnect to redis.\n\n        :return: Redis client instance\n        :rettype: redis.Redis\n        '''\n\n        if self.shared_client and Storage.storage:\n            return Storage.storage\n\n        storage = Redis(\n            port=self.context.config.REDIS_RESULT_STORAGE_SERVER_PORT,\n            host=self.context.config.REDIS_RESULT_STORAGE_SERVER_HOST,\n            db=self.context.config.REDIS_RESULT_STORAGE_SERVER_DB,\n            password=self.context.config.REDIS_RESULT_STORAGE_SERVER_PASSWORD\n        )\n\n        if self.shared_client:\n            Storage.storage = storage\n        return storage", "response": "Reconnect to redis instance\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_key_from_request(self):\n        '''Return a key for the current request url.\n\n        :return: The storage key for the current url\n        :rettype: string\n        '''\n\n        path = \"result:%s\" % self.context.request.url\n\n        if self.is_auto_webp():\n            path += '/webp'\n\n        return path", "response": "Return a key for the current request url."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the TTL of the current request.", "response": "def get_max_age(self):\n        '''Return the TTL of the current request.\n\n        :returns: The TTL value for the current request.\n        :rtype: int\n        '''\n\n        default_ttl = self.context.config.RESULT_STORAGE_EXPIRATION_SECONDS\n        if self.context.request.max_age == 0:\n            return self.context.request.max_age\n\n        return default_ttl"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef put(self, bytes):\n        '''Save to redis\n\n        :param bytes: Bytes to write to the storage.\n        :return: Redis key for the current url\n        :rettype: string\n        '''\n\n        key = self.get_key_from_request()\n        result_ttl = self.get_max_age()\n\n        logger.debug(\n            \"[REDIS_RESULT_STORAGE] putting `{key}` with ttl `{ttl}`\".format(\n                key=key,\n                ttl=result_ttl\n            )\n        )\n\n        storage = self.get_storage()\n        storage.set(key, bytes)\n\n        if result_ttl > 0:\n            storage.expireat(\n                key,\n                datetime.now() + timedelta(\n                    seconds=result_ttl\n                )\n            )\n\n        return key", "response": "Save to redis\n\n        :param bytes: Bytes to write to the storage.\n        :return: Redis key for the current url\n        :rettype: string"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(self):\n        '''Get the item from redis.'''\n\n        key = self.get_key_from_request()\n        result = self.get_storage().get(key)\n\n        return result if result else None", "response": "Get the item from redis."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef last_updated(self):\n        '''Return the last_updated time of the current request item\n\n        :return: A DateTime object\n        :rettype: datetetime.datetime\n        '''\n\n        key = self.get_key_from_request()\n        max_age = self.get_max_age()\n\n        if max_age == 0:\n            return datetime.fromtimestamp(Storage.start_time)\n\n        ttl = self.get_storage().ttl(key)\n\n        if ttl >= 0:\n            return datetime.now() - timedelta(\n                seconds=(\n                    max_age - ttl\n                )\n            )\n\n        if ttl == -1:\n            # Per Redis docs: -1 is no expiry, -2 is does not exists.\n            return datetime.fromtimestamp(Storage.start_time)\n\n        # Should never reach here. It means the storage put failed or the item\n        # somehow does not exists anymore.\n        return datetime.now()", "response": "Return the last_updated time of the current request item\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_of_lists_to_dict(l):\n    d = {}\n    for key, val in l:\n        d.setdefault(key, []).append(val)\n    return d", "response": "Convert list of key value lists to dict"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget m2m value for model obj from request params like group [ ]", "response": "def get_m2m_value(session, request, obj):\n    \"\"\" Set m2m value for model obj from request params like \"group[]\"\n\n        :Parameters:\n\n            - `session`: SQLAlchemy DBSession\n            - `request`: request as dict\n            - `obj`: model instance\n    \"\"\"\n    params = {}\n    ''' m2m_request:\n\n        {u'company[]': [u'[\"id\", 1]'],\n         u'professions[]': [u'[\"id\", 2]', u'[\"id\", 3]']}\n    '''\n    m2m_request = {k: v for k, v in list(request.items()) if k.endswith('[]')}\n    for k, v in list(m2m_request.items()):\n        key = k[:-2]\n        relation = getattr(obj.__class__, key, False)\n        if not relation:\n            relation = getattr(obj, key, False)\n        if not relation:\n            continue  # pragma: no cover\n        value = get_m2m_objs(session, relation, v)\n        if value is None:\n            continue\n\n        if relation.property.uselist is False:\n            if value:\n                value = value[0]\n            else:\n                value = None\n        params[key] = value\n    return params"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndumps an integer into a base36 string.", "response": "def dumps(number):\n    \"\"\"Dumps an integer into a base36 string.\n\n    :param number: the 10-based integer.\n    :returns: the base36 string.\n    \"\"\"\n    if not isinstance(number, integer_types):\n        raise TypeError('number must be an integer')\n\n    if number < 0:\n        return '-' + dumps(-number)\n\n    value = ''\n\n    while number != 0:\n        number, index = divmod(number, len(alphabet))\n        value = alphabet[index] + value\n\n    return value or '0'"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef acl_middleware(callback):\n    async def _acl_middleware_factory(app, handler):\n\n        async def _middleware_handler(request):\n            # Save the policy in the request\n            request[GROUPS_KEY] = callback\n\n            # Call the next handler in the chain\n            return await handler(request)\n\n        return _middleware_handler\n\n    return _acl_middleware_factory", "response": "Returns a aiohttp_auth. acl middleware factory for use by the aiohttp application object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the set of groups that the user in this request has access to.", "response": "async def get_user_groups(request):\n    \"\"\"Returns the groups that the user in this request has access to.\n\n    This function gets the user id from the auth.get_auth function, and passes\n    it to the ACL callback function to get the groups.\n\n    Args:\n        request: aiohttp Request object\n\n    Returns:\n        If the ACL callback function returns None, this function returns None.\n        Otherwise this function returns the sequence of group permissions\n        provided by the callback, plus the Everyone group. If user_id is not\n        None, the AuthnticatedUser group and the user_id are added to the\n        groups returned by the function\n\n    Raises:\n        RuntimeError: If the ACL middleware is not installed\n    \"\"\"\n    acl_callback = request.get(GROUPS_KEY)\n    if acl_callback is None:\n        raise RuntimeError('acl_middleware not installed')\n\n    user_id = await get_auth(request)\n    groups = await acl_callback(user_id)\n    if groups is None:\n        return None\n\n    user_groups = (Group.AuthenticatedUser, user_id) if user_id is not None else ()\n\n    return set(itertools.chain(groups, (Group.Everyone,), user_groups))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns true if the user is allowed to access the requested permission.", "response": "async def get_permitted(request, permission, context):\n    \"\"\"Returns true if the one of the groups in the request has the requested\n    permission.\n\n    The function takes a request, a permission to check for and a context. A\n    context is a sequence of ACL tuples which consist of a Allow/Deny action,\n    a group, and a sequence of permissions for that ACL group. For example::\n\n        context = [(Permission.Allow, 'view_group', ('view',)),\n                   (Permission.Allow, 'edit_group', ('view', 'edit')),]\n\n    ACL tuple sequences are checked in order, with the first tuple that matches\n    the group the user is a member of, and includes the permission passed to\n    the function, to be the matching ACL group. If no ACL group is found, the\n    function returns False.\n\n    Groups and permissions need only be immutable objects, so can be strings,\n    numbers, enumerations, or other immutable objects.\n\n    Args:\n        request: aiohttp Request object\n        permission: The specific permission requested.\n        context: A sequence of ACL tuples\n\n    Returns:\n        The function gets the groups by calling get_user_groups() and returns\n        true if the groups are Allowed the requested permission, false\n        otherwise.\n\n    Raises:\n        RuntimeError: If the ACL middleware is not installed\n    \"\"\"\n\n    groups = await get_user_groups(request)\n    if groups is None:\n        return False\n\n    for action, group, permissions in context:\n        if group in groups:\n            if permission in permissions:\n                return action == Permission.Allow\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unique(input_list):\n    output = []\n    for item in input_list:\n        if item not in output:\n            output.append(item)\n    return output", "response": "Returns a list of unique items."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the molecular weight of a molecule.", "response": "def molecular_weight(elements):\n    \"\"\"\n    Return molecular weight of a molecule.\n\n    Parameters\n    ----------\n    elements : numpy.ndarray\n        An array of all elements (type: str) in a molecule.\n\n    Returns\n    -------\n    numpy.float64\n        A molecular weight of a molecule.\n\n    \"\"\"\n    return (np.array([atomic_mass[i.upper()] for i in elements]).sum())"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef center_of_mass(elements, coordinates):\n    mass = molecular_weight(elements)\n    mass_array = np.array([[atomic_mass[i.upper()]] * 3 for i in elements])\n    mass_coordinates = coordinates * mass_array\n    return (np.sum(mass_coordinates, axis=0) / np.array([mass, mass, mass]))", "response": "Returns the centre of mass of a molecule."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn an atom list from elements and coordinates.", "response": "def compose_atom_list(*args):\n    \"\"\"\n    Return an `atom list` from elements and/or atom ids and coordinates.\n\n    An `atom list` is a special object that some pywindowfunctions uses.\n    It is a nested list of lists with each individual list containing:\n\n        1. [[element, coordinates (x, y, z)], ...]\n\n        2. [[element, atom key, coordinates (x, y, z)], ...]\n\n    They work better for molecular re-building than two separate arrays for\n    elements and coordinates do.\n\n    Parameters\n    ----------\n    elements : :class:`numpy.ndarray`\n        An array of all elements (type: str) in a molecule.\n\n    coordinates : :class:`numpy.ndarray`\n        An array containing molecule's coordinates.\n\n    atom_ids : :class:`numpy.ndarray`, optional\n        An array of all forcfield dependent atom keys (type:str) in a molecule.\n\n\n    Returns\n    -------\n    list\n        Version 1 or version 2 atom list depending on input parameters.\n\n    Raises\n    ------\n    _FunctionError : :class:`Exception`\n        Raised when wrong number of parameters is passed to the function.\n\n    \"\"\"\n    if len(args) == 2:\n        atom_list = [[\n            i[0],\n            round(float(i[1]), 8),\n            round(float(i[2]), 8),\n            round(float(i[3]), 8),\n        ] for i in np.concatenate(\n            (args[0].reshape(-1, 1), args[1]), axis=1)]\n    elif len(args) == 3:\n        atom_list = [\n            [\n                i[0],\n                i[1],\n                round(float(i[2]), 8),\n                round(float(i[3]), 8),\n                round(float(i[4]), 8),\n            ]\n            for i in np.concatenate(\n                (np.concatenate(\n                    (args[0].reshape(-1, 1), args[1].reshape(-1, 1)\n                     ), axis=1), args[2]),\n                axis=1)\n        ]\n    else:\n        raise _FunctionError(\n            \"The compose_atom_list() function accepts only 2 or 3 arguments.\")\n    return atom_list"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns elements and/or atom ids and coordinates from an `atom list`. Depending on input type of an atom list (version 1 or 2) 1. [[element, coordinates (x, y, z)], ...] 2. [[element, atom key, coordinates (x, y, z)], ...] the function reverses what pywindow.utilities.compose_atom_list() do. Parameters ---------- atom_list : list A nested list of lists (version 1 or 2) Returns ------- touple A touple of elements and coordinates arrays, or if input contained atom ideas, also atom ids array.", "response": "def decompose_atom_list(atom_list):\n    \"\"\"\n    Return elements and/or atom ids and coordinates from an `atom list`.\n\n    Depending on input type of an atom list (version 1 or 2)\n\n        1. [[element, coordinates (x, y, z)], ...]\n        2. [[element, atom key, coordinates (x, y, z)], ...]\n\n    the function reverses what pywindow.utilities.compose_atom_list() do.\n\n    Parameters\n    ----------\n    atom_list : list\n        A nested list of lists (version 1 or 2)\n\n    Returns\n    -------\n    touple\n        A touple of elements and coordinates arrays, or if input contained\n        atom ideas, also atom ids array.\n\n    \"\"\"\n    transpose = list(zip(*atom_list))\n    if len(transpose) == 4:\n        elements = np.array(transpose[0])\n        array_a = np.array(transpose[1]).reshape(-1, 1)\n        array_b = np.array(transpose[2]).reshape(-1, 1)\n        array_c = np.array(transpose[3]).reshape(-1, 1)\n        array_ab = np.concatenate((array_a, array_b), axis=1)\n        coordinates = np.concatenate((array_ab, array_c), axis=1)\n        return elements, coordinates\n    elif len(transpose) == 5:\n        elements = np.array(transpose[0])\n        atom_ids = np.array(transpose[1])\n        array_a = np.array(transpose[2]).reshape(-1, 1)\n        array_b = np.array(transpose[3]).reshape(-1, 1)\n        array_c = np.array(transpose[4]).reshape(-1, 1)\n        array_ab = np.concatenate((array_a, array_b), axis=1)\n        coordinates = np.concatenate((array_ab, array_c), axis=1)\n        return elements, atom_ids, coordinates\n    else:\n        raise _FunctionError(\n            \"The decompose_atom_list() function accepts only list of lists \"\n            \" with only 4 or 5 items per sublist.\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dlf_notation(atom_key):\n    split = list(atom_key)\n    element = ''\n    number = False\n    count = 0\n    while number is False:\n        element = \"\".join((element, split[count]))\n        count += 1\n        if is_number(split[count]) is True:\n            number = True\n    # In case of for example Material Studio output, integers can also be\n    # in the beginning of the string. As the dlf_notation decipher function\n    # is very general in use, we have to make sure these integers are deleted.\n    # In standard DL_F notation the string will never start with integer so it\n    # will not affect the functionality towards it.\n    # EDIT2: also the '?' atoms, you can delete them manually or somewhere else\n    element = \"\".join(i for i in element if not is_number(i))\n    element = \"\".join(i for i in element if i != '?')\n    return element", "response": "Return element for atom key using DL_F notation."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef opls_notation(atom_key):\n    # warning for Ne, He, Na types overlap\n    conflicts = ['ne', 'he', 'na']\n    if atom_key in conflicts:\n        raise _AtomKeyConflict((\n            \"One of the OPLS conflicting \"\n            \"atom_keys has occured '{0}'. \"\n            \"For how to solve this issue see the manual or \"\n            \"MolecularSystem._atom_key_swap() doc string.\").format(atom_key))\n    for element in opls_atom_keys:\n        if atom_key in opls_atom_keys[element]:\n            return element\n    # In case if atom_key was not found in the OPLS keys dictionary\n    raise _AtomKeyError((\n        \"OPLS atom key {0} was not found in OPLS keys dictionary.\").format(\n            atom_key))", "response": "Return element for OPLS forcefield atom key."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef decipher_atom_key(atom_key, forcefield):\n    load_funcs = {\n        'DLF': dlf_notation,\n        'DL_F': dlf_notation,\n        'OPLS': opls_notation,\n        'OPLSAA': opls_notation,\n        'OPLS2005': opls_notation,\n        'OPLS3': opls_notation,\n    }\n    if forcefield.upper() in load_funcs.keys():\n        return load_funcs[forcefield.upper()](atom_key)\n    else:\n        raise _ForceFieldError(\n            (\"Unfortunetely, '{0}' forcefield is not supported by pyWINDOW.\"\n             \" For list of supported forcefields see User's Manual or \"\n             \"MolecularSystem._decipher_atom_keys() function doc string.\"\n             ).format(forcefield))", "response": "This function deciphers the atom key into a new element in the internal molecular system."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef shift_com(elements, coordinates, com_adjust=np.zeros(3)):\n    com = center_of_mass(elements, coordinates)\n    com = np.array([com - com_adjust] * coordinates.shape[0])\n    return coordinates - com", "response": "Returns the coordinates translated by some vector."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the maximum diameter of a molecule.", "response": "def max_dim(elements, coordinates):\n    \"\"\"\n    Return the maximum diameter of a molecule.\n\n    Parameters\n    ----------\n    elements : numpy.ndarray\n        An array of all elements (type: str) in a molecule.\n\n    coordinates : numpy.ndarray\n        An array containing molecule's coordinates.\n\n    Returns\n    -------\n\n    \"\"\"\n    atom_vdw_vertical = np.matrix(\n        [[atomic_vdw_radius[i.upper()]] for i in elements])\n    atom_vdw_horizontal = np.matrix(\n        [atomic_vdw_radius[i.upper()] for i in elements])\n    dist_matrix = euclidean_distances(coordinates, coordinates)\n    vdw_matrix = atom_vdw_vertical + atom_vdw_horizontal\n    re_dist_matrix = dist_matrix + vdw_matrix\n    final_matrix = np.triu(re_dist_matrix)\n    i1, i2 = np.unravel_index(final_matrix.argmax(), final_matrix.shape)\n    maxdim = final_matrix[i1, i2]\n    return i1, i2, maxdim"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pore_diameter(elements, coordinates, com=None):\n    if com is None:\n        com = center_of_mass(elements, coordinates)\n    atom_vdw = np.array([[atomic_vdw_radius[x.upper()]] for x in elements])\n    dist_matrix = euclidean_distances(coordinates, com.reshape(1, -1))\n    re_dist_matrix = dist_matrix - atom_vdw\n    index = np.argmin(re_dist_matrix)\n    pored = re_dist_matrix[index][0] * 2\n    return (pored, index)", "response": "Return the pore diameter of a molecule."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef correct_pore_diameter(com, *params):\n    elements, coordinates = params\n    return (-pore_diameter(elements, coordinates, com)[0])", "response": "Return negative of a pore diameter. ( optimisation function function."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns optimised pore diameter and it s COM.", "response": "def opt_pore_diameter(elements, coordinates, bounds=None, com=None, **kwargs):\n    \"\"\"Return optimised pore diameter and it's COM.\"\"\"\n    args = elements, coordinates\n    if com is not None:\n        pass\n    else:\n        com = center_of_mass(elements, coordinates)\n    if bounds is None:\n        pore_r = pore_diameter(elements, coordinates, com=com)[0] / 2\n        bounds = (\n            (com[0]-pore_r, com[0]+pore_r),\n            (com[1]-pore_r, com[1]+pore_r),\n            (com[2]-pore_r, com[2]+pore_r)\n        )\n    minimisation = minimize(\n        correct_pore_diameter, x0=com, args=args, bounds=bounds)\n    pored = pore_diameter(elements, coordinates, com=minimisation.x)\n    return (pored[0], pored[1], minimisation.x)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the gyration tensor of a molecule.", "response": "def get_gyration_tensor(elements, coordinates):\n    \"\"\"\n    Return the gyration tensor of a molecule.\n\n    The gyration tensor should be invariant to the molecule's position.\n    The known formulas for the gyration tensor have the correction for the\n    centre of mass of the molecule, therefore, the coordinates are first\n    corrected for the centre of mass and essentially shifted to the origin.\n\n    Parameters\n    ----------\n    elements : numpy.ndarray\n        The array containing the molecule's elemental data.\n\n    coordinates :  numpy.ndarray\n        The array containing the Cartesian coordinates of the molecule.\n\n    Returns\n    -------\n    numpy.ndarray\n        The gyration tensor of a molecule invariant to the molecule's position.\n\n    \"\"\"\n    # First calculate COM for correction.\n    com = centre_of_mass(elements, coordinates)\n    # Correct the coordinates for the COM.\n    coordinates = coordinates - com\n    # Calculate diagonal and then other values of the matrix.\n    diag = np.sum(coordinates**2, axis=0)\n    xy = np.sum(coordinates[:, 0] * coordinates[:, 1])\n    xz = np.sum(coordinates[:, 0] * coordinates[:, 2])\n    yz = np.sum(coordinates[:, 1] * coordinates[:, 2])\n    S = np.array([[diag[0], xy, xz], [xy, diag[1], yz],\n                  [xz, yz, diag[2]]]) / coordinates.shape[0]\n    return (S)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the tensor of inertia of a molecule.", "response": "def get_inertia_tensor(elements, coordinates):\n    \"\"\"\n    Return the tensor of inertia a molecule.\n\n    Parameters\n    ----------\n    elements : numpy.ndarray\n        The array containing the molecule's elemental data.\n\n    coordinates :  numpy.ndarray\n        The array containing the Cartesian coordinates of the molecule.\n\n    Returns\n    -------\n    numpy.ndarray\n        The tensor of inertia of a molecule.\n\n    \"\"\"\n    pow2 = coordinates**2\n    molecular_weight = np.array(\n        [[atomic_mass[e.upper()]] for e in elements])\n\n    diag_1 = np.sum(molecular_weight * (pow2[:, 1] + pow2[:, 2]))\n    diag_2 = np.sum(molecular_weight * (pow2[:, 0] + pow2[:, 2]))\n    diag_3 = np.sum(molecular_weight * (pow2[:, 0] + pow2[:, 1]))\n\n    mxy = np.sum(-molecular_weight * coordinates[:, 0] * coordinates[:, 1])\n    mxz = np.sum(-molecular_weight * coordinates[:, 0] * coordinates[:, 2])\n    myz = np.sum(-molecular_weight * coordinates[:, 1] * coordinates[:, 2])\n\n    inertia_tensor = np.array([[diag_1, mxy, mxz], [mxy, diag_2, myz],\n                               [mxz, myz, diag_3]]) / coordinates.shape[0]\n    return (inertia_tensor)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nnormalizing a vector. A new vector is returned, the original vector is not modified. Parameters ---------- vector : np.array The vector to be normalized. Returns ------- np.array The normalized vector.", "response": "def normalize_vector(vector):\n    \"\"\"\n    Normalize a vector.\n\n    A new vector is returned, the original vector is not modified.\n\n    Parameters\n    ----------\n    vector : np.array\n        The vector to be normalized.\n\n    Returns\n    -------\n    np.array\n        The normalized vector.\n\n    \"\"\"\n    v = np.divide(vector, np.linalg.norm(vector))\n    return np.round(v, decimals=4)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a rotation matrix of angle radians about axis.", "response": "def rotation_matrix_arbitrary_axis(angle, axis):\n    \"\"\"\n    Return a rotation matrix of `angle` radians about `axis`.\n\n    Parameters\n    ----------\n    angle : int or float\n        The size of the rotation in radians.\n\n    axis : numpy.array\n        A 3 element aray which represents a vector. The vector is the\n        axis about which the rotation is carried out.\n\n    Returns\n    -------\n    numpy.array\n        A 3x3 array representing a rotation matrix.\n\n    \"\"\"\n    axis = normalize_vector(axis)\n\n    a = np.cos(angle / 2)\n    b, c, d = axis * np.sin(angle / 2)\n\n    e11 = np.square(a) + np.square(b) - np.square(c) - np.square(d)\n    e12 = 2 * (b * c - a * d)\n    e13 = 2 * (b * d + a * c)\n\n    e21 = 2 * (b * c + a * d)\n    e22 = np.square(a) + np.square(c) - np.square(b) - np.square(d)\n    e23 = 2 * (c * d - a * b)\n\n    e31 = 2 * (b * d - a * c)\n    e32 = 2 * (c * d + a * b)\n    e33 = np.square(a) + np.square(d) - np.square(b) - np.square(c)\n\n    return np.array([[e11, e12, e13], [e21, e22, e23], [e31, e32, e33]])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn parallelpiped unit cell lattice matrix.", "response": "def unit_cell_to_lattice_array(cryst):\n    \"\"\"Return parallelpiped unit cell lattice matrix.\"\"\"\n    a_, b_, c_, alpha, beta, gamma = cryst\n    # Convert angles from degrees to radians.\n    r_alpha = np.deg2rad(alpha)\n    r_beta = np.deg2rad(beta)\n    r_gamma = np.deg2rad(gamma)\n    # Calculate unit cell volume that is neccessary.\n    volume = a_ * b_ * c_ * (\n        1 - np.cos(r_alpha)**2 - np.cos(r_beta)**2 - np.cos(r_gamma)**2 + 2 *\n        np.cos(r_alpha) * np.cos(r_beta) * np.cos(r_gamma))**0.5\n    # Create the orthogonalisation Matrix (M^-1) - lattice matrix\n    a_x = a_\n    a_y = b_ * np.cos(r_gamma)\n    a_z = c_ * np.cos(r_beta)\n    b_x = 0\n    b_y = b_ * np.sin(r_gamma)\n    b_z = c_ * (\n        np.cos(r_alpha) - np.cos(r_beta) * np.cos(r_gamma)) / np.sin(r_gamma)\n    c_x = 0\n    c_y = 0\n    c_z = volume / (a_ * b_ * np.sin(r_gamma))\n    lattice_array = np.array(\n        [[a_x, a_y, a_z], [b_x, b_y, b_z], [c_x, c_y, c_z]])\n    return lattice_array"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef lattice_array_to_unit_cell(lattice_array):\n    cell_lengths = np.sqrt(np.sum(lattice_array**2, axis=0))\n    gamma_r = np.arccos(lattice_array[0][1] / cell_lengths[1])\n    beta_r = np.arccos(lattice_array[0][2] / cell_lengths[2])\n    alpha_r = np.arccos(\n        lattice_array[1][2] * np.sin(gamma_r) / cell_lengths[2]\n        + np.cos(beta_r) * np.cos(gamma_r)\n        )\n    cell_angles = [\n        np.rad2deg(alpha_r), np.rad2deg(beta_r), np.rad2deg(gamma_r)\n        ]\n    return np.append(cell_lengths, cell_angles)", "response": "Return crystallographic param. from unit cell lattice matrix."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a fractional coordinate from a cartesian one.", "response": "def fractional_from_cartesian(coordinate, lattice_array):\n    \"\"\"Return a fractional coordinate from a cartesian one.\"\"\"\n    deorthogonalisation_M = np.matrix(np.linalg.inv(lattice_array))\n    fractional = deorthogonalisation_M * coordinate.reshape(-1, 1)\n    return np.array(fractional.reshape(1, -1))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn cartesian coordinate from a fractional one.", "response": "def cartisian_from_fractional(coordinate, lattice_array):\n    \"\"\"Return cartesian coordinate from a fractional one.\"\"\"\n    orthogonalisation_M = np.matrix(lattice_array)\n    orthogonal = orthogonalisation_M * coordinate.reshape(-1, 1)\n    return np.array(orthogonal.reshape(1, -1))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cart2frac_all(coordinates, lattice_array):\n    frac_coordinates = deepcopy(coordinates)\n    for coord in range(frac_coordinates.shape[0]):\n        frac_coordinates[coord] = fractional_from_cartesian(\n            frac_coordinates[coord], lattice_array)\n    return frac_coordinates", "response": "Convert all cartesian coordinates to fractional."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts all fractional coordinates to cartesian.", "response": "def frac2cart_all(frac_coordinates, lattice_array):\n    \"\"\"Convert all fractional coordinates to cartesian.\"\"\"\n    coordinates = deepcopy(frac_coordinates)\n    for coord in range(coordinates.shape[0]):\n        coordinates[coord] = cartisian_from_fractional(coordinates[coord],\n                                                       lattice_array)\n    return coordinates"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef discrete_molecules(system, rebuild=None, tol=0.4):\n    # First we check which operation mode we use.\n    #    1) Non-periodic MolecularSystem.\n    #    2) Periodic MolecularSystem without rebuilding.\n    #    3) Periodic Molecular system with rebuilding (supercell provided).\n    if rebuild is not None:\n        mode = 3\n    else:\n        if 'unit_cell' in system.keys():\n            if system['unit_cell'].shape == (6,):\n                mode = 2\n            else:\n                mode = 1\n        elif 'lattice' in system.keys():\n            if system['lattice'].shape == (3, 3):\n                mode = 2\n            else:\n                mode = 1\n        else:\n            mode = 1\n    # We create a list containing all atoms, theirs periodic elements and\n    # coordinates. As this process is quite complicated, we need a list\n    # which we will gradually be reducing.\n    try:\n        elements = system['elements']\n        coordinates = system['coordinates']\n    except KeyError:\n        raise _FunctionError(\n            \"The 'elements' key is missing in the 'system' dictionary \"\n            \"attribute of the MolecularSystem object. Which means, you need to\"\n            \" decipher the forcefield based atom keys first (see manual).\"\n        )\n    coordinates = system['coordinates']\n    args = (elements, coordinates)\n    adj = 0\n    # If there are forcefield 'atom ids' as well we will retain them.\n    if 'atom_ids' in system.keys():\n        atom_ids = system['atom_ids']\n        args = (elements, atom_ids, coordinates)\n        adj = 1\n    atom_list = compose_atom_list(*args)\n    atom_coor = decompose_atom_list(atom_list)[1 + adj]\n    # Scenario 1: We load a non-periodic MolecularSystem.\n    # We will not have 'unit_cell' nor 'lattice' keywords in the dictionary\n    # and also we do not do any re-building.\n    # Scenario 2: We load a periodic MolecularSystem. We want to only Extract\n    # complete molecules that do not have been affected by the periodic\n    # boundary.\n    # Scenario 3: We load a periodic Molecular System. We want it to be rebuild\n    # therefore, we also provide a supercell.\n    # Scenarios 2 and 3 require a lattice and also their origin is at origin.\n    # Scenario 1 should have the origin at the center of mass of the system.\n    # EDIT 09-04-18: All origins/pseudo_origin had to be skewed towards some\n    # direction (x + 0.01) so that there would be no ambiguity in periodic\n    # ang highly symmetric systems where the choice of the closest atom would\n    # be random from a set of equally far choices - bug found in the testing\n    # this way rebuild system should always look the same from the same input\n    # and on different machines.\n    if mode == 2 or mode == 3:\n        # Scenarios 2 or 3.\n        origin = np.array([0.01, 0., 0.])\n        if 'lattice' not in system.keys():\n            matrix = unit_cell_to_lattice_array(system['unit_cell'])\n        else:\n            matrix = system['lattice']\n        pseudo_origin_frac = np.array([0.26, 0.25, 0.25])\n        pseudo_origin = cartisian_from_fractional(pseudo_origin_frac, matrix)\n        # If a supercell is also provided that encloses the unit cell for the\n        # reconstruction of the molecules through the periodic boundary.\n        if rebuild is not None:\n            selements = rebuild['elements']\n            sids = rebuild['atom_ids']\n            scoordinates = rebuild['coordinates']\n            satom_list = compose_atom_list(selements, sids, scoordinates)\n            satom_coor = decompose_atom_list(satom_list)[1 + adj]\n        # There is one more step. We need to sort out for all the\n        # reconstructed molecules, which are the ones that belong to the\n        # unit cell. As we did the reconstruction to every chunk in the unit\n        # cell we have now some molecules that belong to neighbouring cells.\n        # The screening is simple. If the COM of a molecule translated to\n        # fractional coordinates (so that it works for parallelpiped) is\n        # within the unit cell boundaries <0, 1> then it's it. There is\n        # an exception, for the trajectories, very often the unit cell\n        # is centered at origin. Therefore we need to use <-0.5, 0.5>\n        # boundary. We will simply decide which is the case by calculating\n        # the centre of mass of the whole system.\n        system_com = center_of_mass(elements, coordinates)\n        if np.allclose(system_com, origin, atol=1e-00):\n            boundary = np.array([-0.5, 0.5])\n        else:\n            boundary = np.array([0., 1.])\n    else:\n        # Scenario 1.\n        pseudo_origin = center_of_mass(\n            elements, coordinates) + np.array([0.01, 0., 0.])\n    # Here the final discrete molecules will be stored.\n    molecules = []\n    # Exceptions. Usually end-point atoms that create single bonds or\n    # just a separate atoms in the system.\n    exceptions = ['H', 'CL', 'BR', 'F', 'HE', 'AR', 'NE', 'KR', 'XE', 'RN']\n    # The upper limit for distances analysed for bonds will be assigned for\n    # a given system (to save time). We take set('elements') and then find\n    # the largest R(cov) in the system and set the max_dist as a double\n    # of it plus the 150% tolerance (tol).\n    set_of_elements = set(system['elements'])\n    max_r_cov = max([\n        atomic_covalent_radius[i.upper()] for i in set_of_elements])\n    max_dist = 2 * max_r_cov + tol\n    # We continue untill all items in the list have been analysed and popped.\n    while atom_list:\n        inside_atoms_heavy = [\n            i for i in atom_list if i[0].upper() not in exceptions\n        ]\n        if inside_atoms_heavy:\n            # Now we create an array of atom coordinates. It does seem\n            # somehow counter-intuitive as this is what we started with\n            # and made it into a list. But, in my opinion it's the only\n            # way to do it. It's hard to control and delete items in two\n            # separate arrays that we started with and we don't want\n            # atoms already assigned in our array for distance matrix.\n            inside_atoms_coord_heavy = decompose_atom_list(inside_atoms_heavy)[\n                1 + adj]\n            dist_matrix = euclidean_distances(inside_atoms_coord_heavy,\n                                              pseudo_origin.reshape(1, -1))\n            atom_index_x, _ = np.unravel_index(dist_matrix.argmin(),\n                                               dist_matrix.shape)\n            # Added this so that lone atoms (even if heavy) close to the\n            # periodic boundary are not analysed, as they surely have matching\n            # symmetry equivalence that bind to a bigger atom cluster inside\n            # the unit_cell.\n            potential_starting_point = inside_atoms_heavy[atom_index_x]\n            pot_arr = np.array(potential_starting_point[1 + adj:])\n            dist_matrix = euclidean_distances(\n                atom_coor, pot_arr.reshape(1, -1)\n                )\n            idx = (dist_matrix > 0.1) * (dist_matrix < max_dist)\n            if len(idx) < 1:\n                pass\n            else:\n                working_list = [potential_starting_point]\n        else:\n            # Safety check.\n            break\n        final_molecule = []\n        while working_list:\n            working_list_temp = []\n            try:\n                atom_coor = decompose_atom_list(atom_list)[1 + adj]\n            except _FunctionError:\n                atom_coor = None\n            for i in working_list:\n                if i[0].upper() not in exceptions:\n                    # It's of GREATEST importance that the i_arr variable\n                    # is assigned here before entering the atom_coor loop.!\n                    # Otherwise it will not be re-asigned when the satom_list\n                    # still iterates, but the atom_list is already empty...\n                    i_arr = np.array(i[1 + adj:])\n                    if atom_coor is not None:\n                        dist_matrix = euclidean_distances(\n                            atom_coor, i_arr.reshape(1, -1)\n                            )\n                        idx = (dist_matrix > 0.1) * (dist_matrix < max_dist)\n                        neighbours_indexes = np.where(idx)[0]\n                        for j in neighbours_indexes:\n                            j_arr = np.array(atom_coor[j])\n                            r_i_j = distance(i_arr, j_arr)\n                            r_cov_i_j = atomic_covalent_radius[\n                                i[0].upper()] + atomic_covalent_radius[\n                                    atom_list[j][0].upper()]\n                            if r_cov_i_j - tol < r_i_j < r_cov_i_j + tol:\n                                working_list_temp.append(atom_list[j])\n                    if rebuild is not None:\n                        sdist_matrix = euclidean_distances(\n                            satom_coor, i_arr.reshape(1, -1))\n                        sidx = (sdist_matrix > 0.1) * (sdist_matrix < max_dist)\n                        sneighbours_indexes = np.where(sidx)[0]\n                        for j in sneighbours_indexes:\n                            if satom_list[j] in atom_list:\n                                pass\n                            else:\n                                j_arr = np.array(satom_coor[j])\n                                r_i_j = distance(i_arr, j_arr)\n                                r_cov_i_j = atomic_covalent_radius[\n                                    i[0].upper()\n                                    ] + atomic_covalent_radius[\n                                        satom_list[j][0].upper()]\n                                if r_cov_i_j - tol < r_i_j < r_cov_i_j + tol:\n                                    working_list_temp.append(satom_list[j])\n                    final_molecule.append(i)\n                else:\n                    final_molecule.append(i)\n            for i in working_list:\n                try:\n                    atom_list.remove(i)\n                except ValueError:\n                    pass\n            # We empty the working list as all the items were analysed\n            # and moved to the final_molecule list.\n            working_list = []\n            # We make sure there are no duplicates in the working_list_temp.\n            working_list_temp = unique(working_list_temp)\n            # Now we move the entries from the temporary working list\n            # to the working list for looping analysys.\n            for i in working_list_temp:\n                # We make sure that only new and unassigned atoms are\n                # being transfered.\n                if i not in final_molecule:\n                    working_list.append(i)\n        final_molecule_dict = {}\n        final_molecule_dict['elements'] = np.array(\n            [x[0] for x in final_molecule], dtype='str')\n        final_molecule_dict['coordinates'] = np.array(\n            [[*xyz[1 + adj:]] for xyz in final_molecule])\n        if adj == 1:\n            final_molecule_dict['atom_ids'] = np.array(\n                [x[1] for x in final_molecule], dtype='str')\n        # In general we always want the molecule so the initial bool_ is True.\n        bool_ = True\n        # But, for periodic only if the molecule is in the initial unit cell.\n        if rebuild is not None:\n            com = center_of_mass(final_molecule_dict['elements'],\n                                 final_molecule_dict['coordinates'])\n            com_frac = fractional_from_cartesian(com, matrix)[0]\n            # If we don't round the numerical errors will come up.\n            com_frac_round = np.around(com_frac, decimals=8)\n            bool_ = np.all(np.logical_and(com_frac_round >= boundary[0],\n                                          com_frac_round < boundary[1]),\n                           axis=0)\n        if bool(bool_) is True:\n            molecules.append(final_molecule_dict)\n    return molecules", "response": "Decomposes a molecular system into individual discreet molecules."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef angle_between_vectors(x, y):\n    first_step = abs(x[0] * y[0] + x[1] * y[1] + x[2] * y[2]) / (\n        np.sqrt(x[0]**2 + x[1]**2 + x[2]**2) *\n        np.sqrt(y[0]**2 + y[1]**2 + y[2]**2))\n    second_step = np.arccos(first_step)\n    return (second_step)", "response": "Calculate the angle between two vectors x and y."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef vector_analysis(vector, coordinates, elements_vdw, increment=1.0):\n    # Calculate number of chunks if vector length is divided by increment.\n    chunks = int(np.linalg.norm(vector) // increment)\n    # Create a single chunk.\n    chunk = vector / chunks\n    # Calculate set of points on vector's path every increment.\n    vector_pathway = np.array([chunk * i for i in range(chunks + 1)])\n    analysed_vector = np.array([\n        np.amin(\n            euclidean_distances(coordinates, i.reshape(1, -1)) - elements_vdw)\n        for i in vector_pathway\n    ])\n    if all(i > 0 for i in analysed_vector):\n        pos = np.argmin(analysed_vector)\n        # As first argument we need to give the distance from the origin.\n        dist = np.linalg.norm(chunk * pos)\n        return np.array(\n            [dist, analysed_vector[pos] * 2, *chunk * pos, *vector])", "response": "Analyse a sampling vector s path for window analysis purpose."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning negative pore diameter for x and y coordinates optimisation.", "response": "def optimise_xy(xy, *args):\n    \"\"\"Return negative pore diameter for x and y coordinates optimisation.\"\"\"\n    z, elements, coordinates = args\n    window_com = np.array([xy[0], xy[1], z])\n    return -pore_diameter(elements, coordinates, com=window_com)[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns pore diameter for coordinates optimisation in z direction.", "response": "def optimise_z(z, *args):\n    \"\"\"Return pore diameter for coordinates optimisation in z direction.\"\"\"\n    x, y, elements, coordinates = args\n    window_com = np.array([x, y, z])\n    return pore_diameter(elements, coordinates, com=window_com)[0]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning window diameter and window's centre. Parameters ---------- widnow: list elements: numpy.array coordinates: numpy.array elements_vdw: numpy.array step: float", "response": "def window_analysis(window,\n                    elements,\n                    coordinates,\n                    elements_vdw,\n                    increment2=0.1,\n                    z_bounds=[None, None],\n                    lb_z=True,\n                    z_second_mini=False,\n                    **kwargs):\n    \"\"\"\n    Return window diameter and window's centre.\n\n    Parameters\n    ----------\n    widnow: list\n\n    elements: numpy.array\n\n    coordinates: numpy.array\n\n    elements_vdw: numpy.array\n\n    step: float\n\n    \"\"\"\n    # Copy the coordinates as we will manipulate them.\n    coordinates = deepcopy(coordinates)\n    # Find the vector with the largest window sampling diameter from the pool.\n    vector_ = window[window.argmax(axis=0)[1]][5:8]\n    vector_analysed = vector_analysis(\n        vector_, coordinates, elements_vdw, increment=increment2)\n    # A safety check, if the refined analysis give None we end the function.\n    if vector_analysed is not None:\n        pass\n    else:\n        return None\n    vector = vector_analysed[5:8]\n    # Unit vectors.\n    vec_a = [1, 0, 0]\n    vec_b = [0, 1, 0]\n    vec_c = [0, 0, 1]\n    # Angles needed for rotation (in radians) to rotate and translate the\n    # molecule for the vector to become the Z-axis.\n    angle_1 = angle_between_vectors(np.array([vector[0], vector[1], 0]), vec_a)\n    angle_2 = angle_between_vectors(vector, vec_c)\n    # Depending in which cartesian coordinate system area the vector is\n    # We need a rotation into a different direction and by different value.\n    if vector[0] >= 0 and vector[1] >= 0 and vector[2] >= 0:\n        angle_1 = -angle_1\n        angle_2 = -angle_2\n    if vector[0] < 0 and vector[1] >= 0 and vector[2] >= 0:\n        angle_1 = np.pi * 2 + angle_1\n        angle_2 = angle_2\n    if vector[0] >= 0 and vector[1] < 0 and vector[2] >= 0:\n        angle_1 = angle_1\n        angle_2 = -angle_2\n    if vector[0] < 0 and vector[1] < 0 and vector[2] >= 0:\n        angle_1 = np.pi * 2 - angle_1\n    if vector[0] >= 0 and vector[1] >= 0 and vector[2] < 0:\n        angle_1 = -angle_1\n        angle_2 = np.pi + angle_2\n    if vector[0] < 0 and vector[1] >= 0 and vector[2] < 0:\n        angle_2 = np.pi - angle_2\n    if vector[0] >= 0 and vector[1] < 0 and vector[2] < 0:\n        angle_2 = angle_2 + np.pi\n    if vector[0] < 0 and vector[1] < 0 and vector[2] < 0:\n        angle_1 = -angle_1\n        angle_2 = np.pi - angle_2\n    # Rotation matrix for rotation around Z-axis with angle_1.\n    rotation_around_z = np.array([[np.cos(angle_1), -np.sin(angle_1), 0],\n                                  [np.sin(angle_1), np.cos(angle_1), 0],\n                                  [0, 0, 1]])\n    # Rotate the whole molecule around with rotation_around_z.\n    coordinates = np.array([np.dot(rotation_around_z, i) for i in coordinates])\n    # Rotation matrix for rotation around Y-axis with angle_2\n    rotation_around_y = np.array([[np.cos(angle_2), 0, np.sin(angle_2)],\n                                  [0, 1, 0],\n                                  [-np.sin(angle_2), 0, np.cos(angle_2)]])\n    # Rotate the whole molecule around with rotation_around_y.\n    coordinates = np.array([np.dot(rotation_around_y, i) for i in coordinates])\n    # Third step is translation. We are now at [0, 0, -z].\n    # We shift the molecule so that center of the window is at the origin.\n    # The `z` is from original vector analysis. It is the point on the vector\n    # where the largest sampling sphere was (vector_analysed[0]).\n    new_z = vector_analysed[0]\n    # Translate the whole molecule to shift window's center to origin.\n    coordinates = coordinates - np.array([[0, 0, new_z]] *\n                                         coordinates.shape[0])\n    # !!!Here the window center (xy and z) optimisation take place!!!\n    window_com = np.array([0, 0, 0], dtype=float)\n    # The lb_z parameter is 'lower bound equal to z' which means,\n    # that we set the lower bound for the z optimisation to be equal\n    # to the -new_z as in some cages it's the COM - pore that is the\n    # limiting diameter. But, no lower than new_z because we don't want to\n    # move into the other direction.\n    if lb_z:\n        z_bounds[0] = -new_z\n    window_diameter, _ = pore_diameter(elements, coordinates, com=window_com)\n    # SciPy minimisation on z coordinate.\n    z_args = (window_com[0], window_com[1], elements, coordinates)\n    z_optimisation = minimize(\n        optimise_z, x0=window_com[2], args=z_args, bounds=[z_bounds])\n    # Substitute the z coordinate for a minimised one.\n    window_com[2] = z_optimisation.x[0]\n    # SciPy brute optimisation on x and y coordinates in window plane.\n    xy_args = (window_com[2], elements, coordinates)\n    xy_bounds = ((-window_diameter / 2, window_diameter / 2),\n                 (-window_diameter / 2, window_diameter / 2))\n    xy_optimisation = brute(\n        optimise_xy, xy_bounds, args=xy_args, full_output=True, finish=fmin)\n    # Substitute the x and y coordinates for the optimised ones.\n    window_com[0] = xy_optimisation[0][0]\n    window_com[1] = xy_optimisation[0][1]\n    # Additional SciPy minimisation on z coordinate. Added on 18 May 2017.\n    # We can argue which aproach is best. Whether z opt and then xy opt\n    # or like now z opt -> xy opt -> additional z opt etc. I have also tested\n    # a loop of optimisations until some convergence and optimisation of\n    # xyz coordinates at the same time by optimising these two optimisations.\n    # In the end. I think this approach is best for cages.\n    # Update 20 October 2017: I made this optional and turned off by default\n    # In many cases that worsen the quality of the results and should be used\n    # with caution.\n    if z_second_mini is not False:\n        z_args = (window_com[0], window_com[1], elements, coordinates)\n        # The z_bounds should be passed in kwargs.\n        z_optimisation = minimize(\n            optimise_z, x0=window_com[2], args=z_args, bounds=[z_bounds])\n        # Substitute the z coordinate for a minimised one.\n        window_com[2] = z_optimisation.x[0]\n    # Calculate the new window diameter.\n    window_diameter, _ = pore_diameter(elements, coordinates, com=window_com)\n    # To get the window true centre of mass we need to revere the rotation and\n    # translation operations on the window com.\n    # Reverse the translation by substracting the new_z.\n    window_com[2] = window_com[2] + new_z\n    angle_2_1 = -angle_2\n    reverse_around_y = np.array([[np.cos(angle_2_1), 0, np.sin(angle_2_1)],\n                                 [0, 1, 0],\n                                 [-np.sin(angle_2_1), 0, np.cos(angle_2_1)]])\n    # Reversing the second rotation around Y-axis.\n    window_com = np.dot(reverse_around_y, window_com)\n    angle_1_1 = -angle_1\n    reverse_around_z = np.array([[np.cos(angle_1_1), -np.sin(angle_1_1), 0],\n                                 [np.sin(angle_1_1), np.cos(angle_1_1), 0],\n                                 [0, 0, 1]])\n    # Reversing the first rotation around Z-axis.\n    window_com = np.dot(reverse_around_z, window_com)\n    return (window_diameter, window_com)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind the windows of a molecule.", "response": "def find_windows(elements,\n                 coordinates,\n                 processes=None,\n                 mol_size=None,\n                 adjust=1,\n                 pore_opt=True,\n                 increment=1.0,\n                 **kwargs):\n    \"\"\"Return windows diameters and center of masses for a molecule.\"\"\"\n    # Copy the coordinates as will perform many opertaions on them\n    coordinates = deepcopy(coordinates)\n    # Center of our cartesian system is always at origin\n    origin = np.array([0, 0, 0])\n    # Initial center of mass to reverse translation at the end\n    initial_com = center_of_mass(elements, coordinates)\n    # Shift the cage to the origin using either the standard center of mass\n    # or if pore_opt flag is True, the optimised pore center as center of mass\n    if pore_opt is True:\n        # Normally the pore is calculated from the COM of a molecule.\n        # So, esentially the molecule's COM is the pore center.\n        # To shift the molecule so that the center of the optimised pore\n        # is at the origin of the system and not the center of the not\n        # optimised one, we need to adjust the shift. We also have to update\n        # the initial com.\n        com_adjust = initial_com - opt_pore_diameter(elements, coordinates, **\n                                                     kwargs)[2]\n        initial_com = initial_com - com_adjust\n        coordinates = shift_com(elements, coordinates, com_adjust=com_adjust)\n    else:\n        # Otherwise, we just shift the cage to the origin.\n        coordinates = shift_com(elements, coordinates)\n    # We create an array of vdw radii of elements.\n    elements_vdw = np.array([[atomic_vdw_radius[x.upper()]] for x in elements])\n    # We calculate maximum diameter of a molecule to determine the radius\n    # of a sampling sphere neccessary to enclose the whole molecule.\n    shpere_radius = max_dim(elements, coordinates)[2] / 2\n    sphere_surface_area = 4 * np.pi * shpere_radius**2\n    # Here we determine the number of sampling points necessary for a fine\n    # sampling. Smaller molecules require more finner density of sampling\n    # points on the sampling sphere's surface, whereas largen require less.\n    # This formula was created so that larger molecule do not take much longer\n    # to analyse, as number_sampling_points*length_of_sampling_vectors\n    # results in quadratic increase of sampling time. The 250 factor was\n    # specificly determined to produce close to 1 sampling point /Angstrom^2\n    # for a sphere of radius ~ 24 Angstrom. We can adjust how fine is the\n    # sampling by changing the adjust factor.\n    number_of_points = int(np.log10(sphere_surface_area) * 250 * adjust)\n    # Here I use code by Alexandre Devert for spreading points on a sphere:\n    # http://blog.marmakoide.org/?p=1\n    golden_angle = np.pi * (3 - np.sqrt(5))\n    theta = golden_angle * np.arange(number_of_points)\n    z = np.linspace(1 - 1.0 / number_of_points, 1.0 / number_of_points - 1.0,\n                    number_of_points)\n    radius = np.sqrt(1 - z * z)\n    points = np.zeros((number_of_points, 3))\n    points[:, 0] = radius * np.cos(theta) * shpere_radius\n    points[:, 1] = radius * np.sin(theta) * shpere_radius\n    points[:, 2] = z * shpere_radius\n    # Here we will compute the eps parameter for the sklearn.cluster.DBSCAN\n    # (3-dimensional spatial clustering algorithm) which is the mean distance\n    # to the closest point of all points.\n    values = []\n    tree = KDTree(points)\n    for i in points:\n        dist, ind = tree.query(i.reshape(1, -1), k=10)\n        values.extend(dist)\n    mean_distance = np.mean(values)\n    # The best eps is parametrized when adding the mean distance and it's root.\n    eps = mean_distance + mean_distance**0.5\n    # Here we either run the sampling points vectors analysis in serial\n    # or parallel. The vectors that go through molecular pores return\n    # as analysed list with the increment at vector's path with largest\n    # included sphere, coordinates for this narrow channel point. vectors\n    # that find molecule on theirs path are return as NoneType object.\n    # Parralel analysis on user's defined number of CPUs.\n    if processes:\n        pool = Pool(processes=processes)\n        parallel = [\n            pool.apply_async(\n                vector_preanalysis,\n                args=(\n                    point,\n                    coordinates,\n                    elements_vdw, ),\n                kwds={'increment': increment}) for point in points\n        ]\n        results = [p.get() for p in parallel if p.get() is not None]\n        pool.terminate()\n        # Dataset is an array of sampling points coordinates.\n        dataset = np.array([x[5:8] for x in results])\n    else:\n        results = [\n            vector_preanalysis(\n                point, coordinates, elements_vdw, increment=increment)\n            for point in points\n        ]\n        results = [x for x in results if x is not None]\n        dataset = np.array([x[5:8] for x in results])\n    # If not a single vector was returned from the analysis it mean that\n    # no molecular channels (what we call windows here) connects the\n    # molecule's interior with the surroungsings (exterior space).\n    # The number of windows in that case equals zero and zero is returned.\n    # Otherwise we continue our search for windows.\n    if len(results) == 0:\n        return None\n    else:\n        # Perfomr DBSCAN to cluster the sampling points vectors.\n        # the n_jobs will be developed later.\n        # db = DBSCAN(eps=eps, n_jobs=_ncpus).fit(dataset)\n        db = DBSCAN(eps=eps).fit(dataset)\n        core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n        core_samples_mask[db.core_sample_indices_] = True\n        labels = set(db.labels_)\n        # Assing cluster label to a sampling point.\n        clusters = [[i, j] for i, j in zip(results, db.labels_)]\n        clustered_results = {label: [] for label in labels}\n        # Create a dictionary of clusters with points listed.\n        [clustered_results[i[1]].append(i[0]) for i in clusters]\n        # No for the sampling point vector in each cluster that had\n        # the widest channel's 'neck' is assumed to pass the closest\n        # to the window's center and therefore will be passed to\n        # window analysis function.\n        # We also pass user defined settings for window analysis.\n        # Again either in serlia or in parallel.\n        # Noisy points get a cluster label -1, therefore we have to exclude it.\n        if processes:\n            pool = Pool(processes=processes)\n            parallel = [\n                pool.apply_async(\n                    window_analysis,\n                    args=(np.array(clustered_results[cluster]), elements,\n                          coordinates, elements_vdw),\n                    kwds=kwargs) for cluster in clustered_results\n                if cluster != -1\n            ]\n            window_results = [p.get() for p in parallel if p.get() is not None]\n            pool.terminate()\n        else:\n            window_results = [\n                window_analysis(\n                    np.array(clustered_results[cluster]), elements,\n                    coordinates, elements_vdw, **kwargs)\n                for cluster in clustered_results if cluster != -1\n            ]\n    # The function returns two numpy arrays, one with windows diameters\n    # in Angstrom, second with corresponding windows center's coordinates\n    windows = np.array([result[0] for result in window_results\n                        if result is not None])\n    windows_coms = np.array(\n        [np.add(result[1], initial_com) for result in window_results\n         if result is not None])\n    # Safety measures, if one of the windows is None or negative a warning\n    # should be raised.\n    for result in window_results:\n        if result is None:\n            msg_ = \" \".join(\n                ['Warning. One of the analysed windows has',\n                 'returned as None. See manual.']\n            )\n            # print(msg_)\n        elif result[0] < 0:\n            msg_ = \" \".join(\n                ['Warning. One of the analysed windows has a vdW',\n                 'corrected diameter smaller than 0. See manual.']\n            )\n            # print(msg_)\n    return (windows, windows_coms)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_average_diameter(elements, coordinates, adjust=1, increment=0.1,\n                          processes=None, **kwargs):\n    \"\"\"Return average diameter for a molecule.\"\"\"\n    # Copy the coordinates as will perform many opertaions on them\n    coordinates = deepcopy(coordinates)\n    # Center of our cartesian system is always at origin\n    origin = np.array([0, 0, 0])\n    # Initial center of mass to reverse translation at the end\n    initial_com = center_of_mass(elements, coordinates)\n    # We just shift the cage to the origin.\n    coordinates = shift_com(elements, coordinates)\n    # We create an array of vdw radii of elements.\n    elements_vdw = np.array([[atomic_vdw_radius[x.upper()]] for x in elements])\n    # We calculate maximum diameter of a molecule to determine the radius\n    # of a sampling sphere neccessary to enclose the whole molecule.\n    shpere_radius = max_dim(elements, coordinates)[2]\n    sphere_surface_area = 4 * np.pi * shpere_radius**2\n    # Here we determine the number of sampling points necessary for a fine\n    # sampling. Smaller molecules require more finner density of sampling\n    # points on the sampling sphere's surface, whereas largen require less.\n    # This formula was created so that larger molecule do not take much longer\n    # to analyse, as number_sampling_points*length_of_sampling_vectors\n    # results in quadratic increase of sampling time. The 250 factor was\n    # specificly determined to produce close to 1 sampling point /Angstrom^2\n    # for a sphere of radius ~ 24 Angstrom. We can adjust how fine is the\n    # sampling by changing the adjust factor.\n    number_of_points = int(np.log10(sphere_surface_area) * 250 * adjust)\n    # Here I use code by Alexandre Devert for spreading points on a sphere:\n    # http://blog.marmakoide.org/?p=1\n    golden_angle = np.pi * (3 - np.sqrt(5))\n    theta = golden_angle * np.arange(number_of_points)\n    z = np.linspace(1 - 1.0 / number_of_points, 1.0 / number_of_points - 1.0,\n                    number_of_points)\n    radius = np.sqrt(1 - z * z)\n    points = np.zeros((number_of_points, 3))\n    points[:, 0] = radius * np.cos(theta) * shpere_radius\n    points[:, 1] = radius * np.sin(theta) * shpere_radius\n    points[:, 2] = z * shpere_radius\n    # Here we analyse the vectors and retain the ones that create the molecule\n    # outline.\n    if processes:\n        pool = Pool(processes=processes)\n        parallel = [\n            pool.apply_async(\n                vector_analysis_reversed,\n                args=(\n                    point, coordinates, elements_vdw)\n                ) for point in points\n        ]\n        results = [p.get() for p in parallel if p.get() is not None]\n        pool.terminate()\n    else:\n        results = [\n            vector_analysis_reversed(\n                point, coordinates, elements_vdw)\n            for point in points\n        ]\n    results_cleaned = [x[0] for x in results if x is not None]\n    return np.mean(results_cleaned)*2", "response": "Return the average diameter for a molecule."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef calculate_pore_shape(elements, coordinates, adjust=1, increment=0.1,\n                         **kwargs):\n    \"\"\"Return average diameter for a molecule.\"\"\"\n    # Copy the coordinates as will perform many opertaions on them\n    coordinates = deepcopy(coordinates)\n    # Center of our cartesian system is always at origin\n    origin = np.array([0, 0, 0])\n    # Initial center of mass to reverse translation at the end\n    initial_com = center_of_mass(elements, coordinates)\n    # We just shift the cage to the origin.\n    coordinates = shift_com(elements, coordinates)\n    # We create an array of vdw radii of elements.\n    elements_vdw = np.array([[atomic_vdw_radius[x.upper()]] for x in elements])\n    # We calculate maximum diameter of a molecule to determine the radius\n    # of a sampling sphere neccessary to enclose the whole molecule.\n    shpere_radius = max_dim(elements, coordinates)[2]/2\n    sphere_surface_area = 4 * np.pi * shpere_radius**2\n    # Here we determine the number of sampling points necessary for a fine\n    # sampling. Smaller molecules require more finner density of sampling\n    # points on the sampling sphere's surface, whereas largen require less.\n    # This formula was created so that larger molecule do not take much longer\n    # to analyse, as number_sampling_points*length_of_sampling_vectors\n    # results in quadratic increase of sampling time. The 250 factor was\n    # specificly determined to produce close to 1 sampling point /Angstrom^2\n    # for a sphere of radius ~ 24 Angstrom. We can adjust how fine is the\n    # sampling by changing the adjust factor.\n    number_of_points = int(np.log10(sphere_surface_area) * 250 * adjust)\n    # Here I use code by Alexandre Devert for spreading points on a sphere:\n    # http://blog.marmakoide.org/?p=1\n    golden_angle = np.pi * (3 - np.sqrt(5))\n    theta = golden_angle * np.arange(number_of_points)\n    z = np.linspace(1 - 1.0 / number_of_points, 1.0 / number_of_points - 1.0,\n                    number_of_points)\n    radius = np.sqrt(1 - z * z)\n    points = np.zeros((number_of_points, 3))\n    points[:, 0] = radius * np.cos(theta) * shpere_radius\n    points[:, 1] = radius * np.sin(theta) * shpere_radius\n    points[:, 2] = z * shpere_radius\n    # Here we will compute the eps parameter for the sklearn.cluster.DBSCAN\n    # (3-dimensional spatial clustering algorithm) which is the mean distance\n    # to the closest point of all points.\n    values = []\n    tree = KDTree(points)\n    for i in points:\n        dist, ind = tree.query(i.reshape(1, -1), k=10)\n        values.extend(dist)\n    mean_distance = np.mean(values)\n    # The best eps is parametrized when adding the mean distance and it's root.\n    eps = mean_distance + mean_distance**0.5\n    # Here we either run the sampling points vectors analysis in serial\n    # or parallel. The vectors that go through molecular voids return\n    # as analysed list with the increment at vector's path with largest\n    # included sphere, coordinates for this narrow channel point. vectors\n    # that find molecule on theirs path are return as NoneType object.\n    results = [\n        vector_analysis_pore_shape(point, coordinates, elements_vdw)\n        for point in points\n    ]\n    results_cleaned = [x for x in results if x is not None]\n    ele = np.array(['X'] * len(results_cleaned))\n    coor = np.array(results_cleaned)\n    return coor", "response": "Calculates the average diameter of a molecule."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfunctioning to calculate the Multidimensional Gamma of a set of pages.", "response": "def lpgamma(p, a):\n    \"\"\"\n    Multidimensional gamma / partial gamma function\n\n    Parameters\n    ----------\n    p : int\n        something....\n\n    a : float\n        something....\n\n    Returns\n    -------\n    Multidimensional gamma / partial gamma function\n\n    \"\"\"\n    res = p * (p - 1.0) / 4.0 * log(pi)\n    for ii in range(1, p+1):\n        res += gammaln(a + (1.0 - ii) / 2.0)\n\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating random samples from the distribution .", "response": "def rand(self, n=1):\n        \"\"\"\n        Generate random samples from the distribution\n\n        Parameters\n        ----------\n        n : int, optional(default=1)\n            The number of samples to generate\n\n        Returns\n        -------\n        out : array_like\n            The generated samples\n\n        \"\"\"\n        if n == 1:\n            return self._rand1()\n        else:\n            out = np.empty((n, self._p, self._p))\n            for i in range(n):\n                out[i] = self._rand1()\n\n            return out"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _c0(self):\n        \"the logarithm of normalizing constant in pdf\"\n        h_df = self.df / 2\n        p, S = self._p, self.S\n\n        return h_df * (logdet(S) + p * logtwo) + lpgamma(p, h_df)", "response": "the logarithm of normalizing constant in pdf"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a single random sample", "response": "def _rand1(self):\n        \"generate a single random sample\"\n        Z = _unwhiten_cf(self._S_cf, self._genA())\n        return Z.dot(Z.T)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef insert(self, key, value, index):\n        '''Accepts a :key:, :value:, and :index: parameter and inserts\n        a new key, value member at the desired index.\n\n        Note: Inserting with a negative index will have the following behavior:\n        >>> l = [1, 2, 3, 4]\n        >>> l.insert(-1, 5)\n        >>> l\n        [1, 2, 3, 5, 4]\n        '''\n\n        if key in self._keys:\n            self._keys.remove(key)\n        self._keys.insert(index, key)\n        self._d[key] = value", "response": "Inserts a new key value member at the specified index."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreorders the keys in the current set of keys.", "response": "def reorder_keys(self, keys):\n        '''Accepts a :keys: parameter, an iterable of keys in the\n        desired new order. The :keys: parameter must contain all\n        existing keys.'''\n        if len(keys) != len(self._keys):\n            raise ValueError('The supplied number of keys does not match.')\n        if set(keys) != set(self._d.keys()):\n            raise ValueError('The supplied keys do not match the current set of keys.')\n        self._keys = keys"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_rdkit_mol(self, mol):\n        self.system = {\n            'elements': np.empty(\n                mol.GetNumAtoms(), dtype=str),\n            'coordinates': np.empty((mol.GetNumAtoms(), 3))\n        }\n        for atom in mol.GetAtoms():\n            atom_id = atom.GetIdx()\n            atom_sym = atom.GetSymbol()\n            x, y, z = mol.GetConformer().GetAtomPosition(atom_id)\n            self.system['elements'][atom_id] = atom_sym\n            self.system['coordinates'][atom_id] = x, y, z\n        return self.system", "response": "Load molecular data from RDKit."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread the Molecule file and returns a dictionary of the system data.", "response": "def _read_mol(self):\n        \"\"\"-V3000\"\"\"\n        self.system = dict()\n        if self.file_content[2] != '\\n':\n            self.system['remarks'] = self.file_content[2]\n        file_body = [i.split() for i in self.file_content]\n        elements = []\n        coordinates = []\n        atom_data = False\n        for line in file_body:\n            if len(line) > 2:\n                if line[2] == 'END' and line[3] == 'ATOM':\n                    atom_data = False\n                if atom_data is True:\n                    elements.append(line[3])\n                    coordinates.append(line[4:7])\n                if line[2] == 'BEGIN' and line[3] == 'ATOM':\n                    atom_data = True\n        self.system['elements'] = np.array(elements)\n        self.system['coordinates'] = np.array(coordinates, dtype=float)\n        return self.system"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dump2json(self, obj, filepath, override=False, **kwargs):\n        # We make sure that the object passed by the user is a dictionary.\n        if isinstance(obj, dict):\n            pass\n        else:\n            raise _NotADictionary(\n                \"This function only accepts dictionaries as input\")\n        # We check if the filepath has a json extenstion, if not we add it.\n        if str(filepath[-4:]) == 'json':\n            pass\n        else:\n            filepath = \".\".join((str(filepath), \"json\"))\n        # First we check if the file already exists. If yes and the override\n        # keyword is False (default), we will raise an exception. Otherwise\n        # the file will be overwritten.\n        if override is False:\n            if os.path.isfile(filepath):\n                raise _FileAlreadyExists(\n                    \"The file {0} already exists. Use a different filepath, \"\n                    \"or set the 'override' kwarg to True.\".format(filepath))\n        # We dump the object to the json file. Additional kwargs can be passed.\n        with open(filepath, 'w+') as json_file:\n            json.dump(obj, json_file, **kwargs)", "response": "Dump a dictionary into a JSON file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dump2file(self, obj, filepath, override=False, **kwargs):\n        # First we check if the file already exists. If yes and the override\n        # keyword is False (default), we will raise an exception. Otherwise\n        # the file will be overwritten.\n        if override is False:\n            if os.path.isfile(filepath):\n                raise _FileAlreadyExists(\n                    \"The file {0} already exists. Use a different filepath, \"\n                    \"or set the 'override' kwarg to True.\".format(filepath))\n        if str(filepath[-3:]) not in self._save_funcs.keys():\n            raise _FileTypeError(\n                \"The {0} file extension is \"\n                \"not supported for dumping a MolecularSystem or a Molecule. \"\n                \"Please use XYZ or PDB.\".format(str(filepath[-3:])))\n        self._save_funcs[str(filepath[-3:])](obj, filepath, **kwargs)", "response": "Dump a dictionary into a file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninsert a new key value member at the specified index.", "response": "def insert(self, value, index):\n        '''Accepts a :value: and :index: parameter and inserts\n        a new key, value member at the desired index.\n\n        Note: Inserting with a negative index will have the following behavior:\n        >>> l = [1, 2, 3, 4]\n        >>> l.insert(-1, 5)\n        >>> l\n        [1, 2, 3, 5, 4]\n        '''\n\n        if value in self._set:\n            self._set.discard(value)\n        self._keys.insert(index, value)\n        self._set.add(value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreorder the keys in the current set.", "response": "def reorder_keys(self, keys):\n        '''Accepts a :keys: parameter, an iterable of keys in the\n        desired new order. The :keys: parameter must contain all\n        existing keys.'''\n        if len(keys) != len(self._set):\n            raise ValueError('The supplied number of keys does not match.')\n        if set(keys) != self._set:\n            raise ValueError('The supplied keys do not match the current set of keys.')\n        self._keys = list(keys)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create(self, data, update=False, **kwargs):\n        data = unjson(data)\n\n        if update is True:\n            obj = get_obj_by_request_data(self.session, self.table, data)\n        else:\n            obj = None\n        return self._add(obj, data, **kwargs)", "response": "Create a new object in the database."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads a single entry from the DB.", "response": "def read(self, *pk):\n        \"\"\"\n        Return a list of entries in the table or single\n        entry if there is an pk.\n\n        .. code-block:: python\n\n            # All users\n            DBSession.sacrud(Users).read()\n\n            # Composite primary_key\n            DBSession.sacrud(User2Groups).read({'user_id': 4, 'group_id': 2})\n\n            # Multiple rows\n            primary_keys = [\n                {'user_id': 4, 'group_id': 2},\n                {'user_id': 4, 'group_id': 3},\n                {'user_id': 1, 'group_id': 1},\n                {'user_id': 19, 'group_id': 2}\n            ]\n            DBSession.sacrud(User2Groups).read(*primary_keys)\n\n            # JSON using\n            primary_keys = '''[\n                {\"user_id\": 4, \"group_id\": 2},\n                {\"user_id\": 4, \"group_id\": 3},\n                {\"user_id\": 1, \"group_id\": 1},\n                {\"user_id\": 19, \"group_id\": 2}\n            ]'''\n            DBSession.sacrud(User2Groups).read(primary_keys)\n\n            # Delete\n            DBSession.sacrud(User2Groups).read(*primary_keys)\\\n                .delete(synchronize_session=False)\n\n            # Same, but work with only not composite primary key\n            DBSession.sacrud(Users).read((5, 10))       # as list\n            DBSession.sacrud(Users).read('[5, 10]')     # as JSON\n            DBSession.sacrud(Users).read('{\"id\": 5}')   # as JSON explicit pk\n            DBSession.sacrud(Users).read(5, \"1\", 2)     # as *args\n            DBSession.sacrud(Users).read(42)            # single\n        \"\"\"\n        pk = [unjson(obj) for obj in pk]\n\n        if len(pk) == 1:  # like ([1,2,3,4,5], )\n            return get_obj(self.session, self.table, pk[0])\n        elif len(pk) > 1:  # like (1, 2, 3, 4, 5)\n            return get_obj(self.session, self.table, pk)\n        return self.session.query(self.table)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate the object with the given pk with the given data.", "response": "def update(self, pk, data, **kwargs):\n        \"\"\"\n        Updates the object by primary_key:\n\n        .. code-block:: python\n\n            DBSession.sacrud(Users).update(1, {'name': 'Petya'})\n            DBSession.sacrud(Users).update('1', {'name': 'Petya'})\n            DBSession.sacrud(User2Groups).update({'user_id': 4, 'group_id': 2},\n                                                 {'group_id': 1})\n\n        JSON support:\n\n        .. code-block:: python\n\n            DBSession.sacrud(Users).update(1, '{\"name\": \"Petya\"}')\n            DBSession.sacrud(User2Groups).update(\n                '{\"user_id\": 4, \"group_id\": 2}',    # primary_key\n                '{\"group_id\": 1}'                   # data\n            )\n\n        Default it run ``session.commit() or transaction.commit()``.\n        If it is not necessary use attribute ``commit=False``.\n        \"\"\"\n        pk = unjson(pk)\n        data = unjson(data)\n        obj = get_obj(self.session, self.table, pk)\n        return self._add(obj, data, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting a record by primary key.", "response": "def delete(self, pk, **kwargs):\n        \"\"\"\n        Delete the object by primary_key:\n\n        .. code-block:: python\n\n            DBSession.sacrud(Users).delete(1)\n            DBSession.sacrud(Users).delete('1')\n            DBSession.sacrud(User2Groups).delete({'user_id': 4, 'group_id': 2})\n\n        JSON support:\n\n        .. code-block:: python\n\n            DBSession.sacrud(User2Groups).delete(\n                '{\"user_id\": 4, \"group_id\": 2}'\n            )\n\n        Default it run ``session.commit() or transaction.commit()``.\n        If it is not necessary use attribute ``commit=False``.\n        \"\"\"\n        pk = unjson(pk)\n\n        obj = get_obj(self.session, self.table, pk)\n        if self._delete(obj, **kwargs):\n            return {'pk': pk, 'name': obj.__repr__()}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _add(self, obj, data, **kwargs):\n        if isinstance(obj, sqlalchemy.orm.query.Query):\n            obj = obj.one()\n        obj = self.preprocessing(obj=obj or self.table)\\\n            .add(self.session, data, self.table)\n        self.session.add(obj)\n        if kwargs.get('commit', self.commit) is True:\n            try:\n                self.session.commit()\n            except AssertionError:\n                transaction.commit()\n        return obj", "response": "Add a new object to the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes the object directly.", "response": "def _delete(self, obj, **kwargs):\n        \"\"\" Delete the object directly.\n\n        .. code-block:: python\n\n            DBSession.sacrud(Users)._delete(UserObj)\n\n        If you no needed commit session\n\n        .. code-block:: python\n\n            DBSession.sacrud(Users, commit=False)._delete(UserObj)\n        \"\"\"\n        if isinstance(obj, sqlalchemy.orm.query.Query):\n            obj = obj.one()\n        obj = self.preprocessing(obj=obj).delete()\n        self.session.delete(obj)\n        if kwargs.get('commit', self.commit) is True:\n            try:\n                self.session.commit()\n            except AssertionError:\n                transaction.commit()\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nperforming authentication using simplepam s authenticate function and returns the token and refresh token object", "response": "def authenticate(self, username, password, **token_context):\n        \"\"\"Performs authentication using simplepam\n        \n        This function calls simplepam's authenticate function and returns\n        status of authentication using PAM and token object (of type\n        self.token_type)\n\n        :param username: username in Linux\n\n        :param password: password for username\n\n        :param **token_context: additional args with keys for token generator\n        \"\"\"\n        log.info(\"Trying to authenticate user: '%s'\", username)\n        if simplepam.authenticate(username, password):\n            expire = datetime.now() + timedelta(seconds=self.token_lifetime)\n            log.info(\"Token will be valid to %s\", expire.strftime('%c'))\n\n            refresh_expire = -1\n            if self.refresh_token_lifetime != -1:\n                refresh_expire = datetime.now() + timedelta(seconds=self.refresh_token_lifetime)\n                log.info(\"Refresh token will be valid to %s\", refresh_expire.strftime('%c'))\n\n            token = self.token_type(self.app.secret_key, username, expire, **token_context)\n            token.context['salt'] = urandom(120).encode('base-64')\n\n            refresh_context = token_context.copy()\n            refresh_context['refresh_salt'] = urandom(120).encode('base-64')\n            refresh_token = self.token_type(self.app.secret_key, username, refresh_expire, **refresh_context)\n\n            self.token_storage.set(token)\n            self.refresh_token_storage.set(refresh_token)\n            return (True, token, refresh_token)\n    \n        log.warning(\"Couldn't authenticate user: %s\", username)\n        return (False, None, None)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef authenticated(self, user_token, **validation_context):\n        token = self.token_storage.get(user_token)\n        if token and token.validate(user_token, **validation_context):\n            return True\n\n        return False", "response": "Checks if user is authenticated using token passed in argument\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef group_authenticated(self, user_token, group):\n        if self.authenticated(user_token):\n            token = self.token_storage.get(user_token)\n            groups = self.get_groups(token.username)\n            if group in groups:\n                return True\n\n        return False", "response": "Checks if user represented by token is in group."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns list of groups in which user is.", "response": "def get_groups(self, username):\n        \"\"\"Returns list of groups in which user is.\n\n        :param username: name of Linux user\n        \"\"\"\n        groups = []\n        for group in grp.getgrall():\n            if username in group.gr_mem:\n                groups.append(group.gr_name)\n\n        return groups"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef auth_required(self, view):\n\n        @functools.wraps(view)\n        def decorated(*args, **kwargs):\n            log.info(\"Trying to get access to protected resource: '%s'\", view.__name__)\n            if request.method == 'POST':\n                token = request.form['token']\n                if self.development or self.authenticated(token):\n                    return view(*args, **kwargs)\n                else:\n                    log.warning(\"User has not been authorized to get access to resource: %s\", view.__name__)\n            else:\n                log.warning(\"Bad request type! Expected 'POST', actual '%s'\", request.method)\n\n            return abort(403)\n\n        return decorated", "response": "Decorator which checks if user is authenticated and if it is not authenticated"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef group_required(self, group):\n\n        def decorator(view):\n            @functools.wraps(view)\n            def decorated(*args, **kwargs):\n                log.info(\"Trying to get access to resource: %s protected by group: %s\", view.__name__, group)\n                if request.method == 'POST':\n                    token = request.form['token']\n                    if self.development or self.group_authenticated(token, group):\n                        return view(*args, **kwargs)\n                    else:\n                        log.warning(\"User has not been authorized to get access to resource: %s\", view.__name__)\n                else:\n                    log.error(\"Bad request type! Expected 'POST', actual '%s'\", request.method)\n\n                return abort(403)\n\n            return decorated\n        return decorator", "response": "Decorator for Flask s view which checks if user is in specified group"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pyc2py(filename):\n    if re.match(\".*py[co]$\", filename):\n        if PYTHON3:\n            return re.sub(r'(.*)__pycache__/(.+)\\.cpython-%s.py[co]$' % PYVER,\n                          '\\\\1\\\\2.py',\n                          filename)\n        else:\n            return filename[:-1]\n    return filename", "response": "Find corresponding. py name given a. pyc or. pyo file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nclearing the file cache. If no filename is given clear it entirely.", "response": "def clear_file_cache(filename=None):\n    \"\"\"Clear the file cache. If no filename is given clear it entirely.\n    if a filename is given, clear just that filename.\"\"\"\n    global file_cache, file2file_remap, file2file_remap_lines\n    if filename is not None:\n        if filename in file_cache:\n            del file_cache[filename]\n            pass\n    else:\n        file_cache = {}\n        file2file_remap = {}\n        file2file_remap_lines = {}\n        pass\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving syntax - formatted lines in the cache.", "response": "def clear_file_format_cache():\n    \"\"\"Remove syntax-formatted lines in the cache. Use this\n    when you change the Pygments syntax or Token formatting\n    and want to redo how files may have previously been\n    syntax marked.\"\"\"\n    for fname, cache_info in file_cache.items():\n        for format, lines in cache_info.lines.items():\n            if 'plain' == format: continue\n            file_cache[fname].lines[format] = None\n            pass\n        pass\n    pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndiscards cache entries that are out of date. Return a list of filenames that are invalidated.", "response": "def checkcache(filename=None, opts=False):\n    \"\"\"Discard cache entries that are out of date. If *filename* is *None*\n    all entries in the file cache *file_cache* are checked.  If we do not\n    have stat information about a file it will be kept. Return a list of\n    invalidated filenames.  None is returned if a filename was given but\n    not found cached.\"\"\"\n\n    if isinstance(opts, dict):\n        use_linecache_lines = opts['use_linecache_lines']\n    else:\n        use_linecache_lines = opts\n        pass\n\n    if not filename:\n        filenames = list(file_cache.keys())\n    elif filename in file_cache:\n        filenames = [filename]\n    else:\n        return None\n\n    result = []\n    for filename in filenames:\n        if filename not in file_cache: continue\n        path = file_cache[filename].path\n        if os.path.exists(path):\n            cache_info = file_cache[filename].stat\n            stat = os.stat(path)\n            if stat and \\\n                    (cache_info.st_size != stat.st_size or\n                         cache_info.st_mtime != stat.st_mtime):\n                result.append(filename)\n                update_cache(filename, use_linecache_lines)\n            else:\n                result.append(filename)\n                update_cache(filename)\n                pass\n        pass\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncache script if it is not already cached.", "response": "def cache_script(script, text, opts={}):\n    \"\"\"Cache script if it is not already cached.\"\"\"\n    global script_cache\n    if script not in script_cache:\n        update_script_cache(script, text, opts)\n        pass\n    return script"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cache_file(filename, reload_on_change=False, opts=default_opts):\n    filename = pyc2py(filename)\n    if filename in file_cache:\n        if reload_on_change: checkcache(filename)\n        pass\n    else:\n        opts['use_linecache_lines'] = True\n        update_cache(filename, opts)\n        pass\n    if filename in file_cache:\n        return file_cache[filename].path\n    else: return None\n    return", "response": "Cache a file in the cache."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_cached(file_or_script):\n    if isinstance(file_or_script, str):\n        return unmap_file(file_or_script) in file_cache\n    else:\n        return is_cached_script(file_or_script)\n    return", "response": "Return True if file_or_script is cached"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting line number from file named file_or_script. Return None if there was a problem.", "response": "def getline(file_or_script, line_number, opts=default_opts):\n    \"\"\"Get line *line_number* from file named *file_or_script*. Return None if\n    there was a problem or it is not found.\n\n    Example:\n\n    lines = pyficache.getline(\"/tmp/myfile.py\")\n    \"\"\"\n    filename = unmap_file(file_or_script)\n    filename, line_number = unmap_file_line(filename, line_number)\n    lines = getlines(filename, opts)\n    if lines and line_number >=1 and line_number <= maxline(filename):\n        line = lines[line_number-1]\n        if get_option('strip_nl', opts):\n            return line.rstrip('\\n')\n        else:\n            return line\n        pass\n    else:\n        return None\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getlines(filename, opts=default_opts):\n    if get_option('reload_on_change', opts): checkcache(filename)\n    fmt = get_option('output', opts)\n    highlight_opts = {'bg': fmt}\n    cs = opts.get('style')\n\n    # Colorstyle of Terminal255Formatter takes precidence over\n    # light/dark colorthemes of TerminalFormatter\n    if cs:\n        highlight_opts['style'] = cs\n        fmt = cs\n\n    if filename not in file_cache:\n        update_cache(filename, opts)\n        filename = pyc2py(filename)\n        if filename not in file_cache: return None\n        pass\n    lines = file_cache[filename].lines\n    if fmt not in lines.keys():\n        lines[fmt] = highlight_array(lines['plain'], **highlight_opts)\n        pass\n    return lines[fmt]", "response": "Read lines of filename and cache the results."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn full filename path for filename", "response": "def path(filename):\n    \"\"\"Return full filename path for filename\"\"\"\n    filename = unmap_file(filename)\n    if filename not in file_cache:\n        return None\n    return file_cache[filename].path"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remap_file_lines(from_path, to_path, line_map_list):\n    from_path = pyc2py(from_path)\n    cache_file(to_path)\n    remap_entry = file2file_remap_lines.get(to_path)\n    if remap_entry:\n        new_list = list(remap_entry.from_to_pairs) + list(line_map_list)\n    else:\n        new_list = line_map_list\n    # FIXME: look for duplicates ?\n    file2file_remap_lines[to_path] = RemapLineEntry(\n        from_path,\n        tuple(sorted(new_list, key=lambda t: t[0]))\n        )\n    return", "response": "Adds line_map_list to the list of association of from_file to to_file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove any mapping for filename and return that if it exists", "response": "def remove_remap_file(filename):\n    \"\"\"Remove any mapping for *filename* and return that if it exists\"\"\"\n    global file2file_remap\n    if filename in file2file_remap:\n        retval = file2file_remap[filename]\n        del file2file_remap[filename]\n        return retval\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sha1(filename):\n    filename = unmap_file(filename)\n    if filename not in file_cache:\n        cache_file(filename)\n        if filename not in file_cache:\n            return None\n        pass\n    if file_cache[filename].sha1:\n        return file_cache[filename].sha1.hexdigest()\n    sha1 = hashlib.sha1()\n    for line in file_cache[filename].lines['plain']:\n        sha1.update(line.encode('utf-8'))\n        pass\n    file_cache[filename].sha1 = sha1\n    return sha1.hexdigest()", "response": "Return SHA1 of filename."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the number of lines in filename.", "response": "def size(filename, use_cache_only=False):\n    \"\"\"Return the number of lines in filename. If `use_cache_only' is False,\n    we'll try to fetch the file if it is not cached.\"\"\"\n    filename = unmap_file(filename)\n    if filename not in file_cache:\n        if not use_cache_only: cache_file(filename)\n        if filename not in file_cache:\n            return None\n        pass\n    return len(file_cache[filename].lines['plain'])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the maximum line number filename after taking into account line remapping.", "response": "def maxline(filename, use_cache_only=False):\n    \"\"\"Return the maximum line number filename after taking into account\n    line remapping. If no remapping then this is the same as size\"\"\"\n    if filename not in file2file_remap_lines:\n        return size(filename, use_cache_only)\n    max_lineno = -1\n    remap_line_entry = file2file_remap_lines.get(filename)\n    if not remap_line_entry:\n        return size(filename, use_cache_only)\n    for t in remap_line_entry.from_to_pairs:\n        max_lineno = max(max_lineno, t[1])\n    if max_lineno == -1:\n        return size(filename, use_cache_only)\n    else:\n        return max_lineno"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef stat(filename, use_cache_only=False):\n    filename = pyc2py(filename)\n    if filename not in file_cache:\n        if not use_cache_only: cache_file(filename)\n        if filename not in file_cache:\n            return None\n        pass\n    return file_cache[filename].stat", "response": "Return stat info for filename."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef trace_line_numbers(filename, reload_on_change=False):\n    fullname = cache_file(filename, reload_on_change)\n    if not fullname: return None\n    e = file_cache[filename]\n    if not e.line_numbers:\n        if hasattr(coverage.coverage, 'analyze_morf'):\n            e.line_numbers = coverage.the_coverage.analyze_morf(fullname)[1]\n        else:\n            cov = coverage.coverage()\n            cov._warn_no_data = False\n            e.line_numbers = cov.analysis(fullname)[1]\n            pass\n        pass\n    return e.line_numbers", "response": "Return an Array of breakpoints in filename."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate a cache entry.", "response": "def update_cache(filename, opts=default_opts, module_globals=None):\n    \"\"\"Update a cache entry.  If something is wrong, return\n    *None*. Return *True* if the cache was updated and *False* if not.  If\n    *use_linecache_lines* is *True*, use an existing cache entry as source\n    for the lines of the file.\"\"\"\n\n    if not filename: return None\n\n    orig_filename = filename\n    filename = pyc2py(filename)\n    if filename in file_cache: del file_cache[filename]\n    path = os.path.abspath(filename)\n    stat = None\n    if get_option('use_linecache_lines', opts):\n        fname_list = [filename]\n        mapped_path = file2file_remap.get(path)\n        if mapped_path:\n            fname_list.append(mapped_path)\n            for filename in fname_list:\n                try:\n                    stat = os.stat(filename)\n                    plain_lines = linecache.getlines(filename)\n                    trailing_nl = has_trailing_nl(plain_lines[-1])\n                    lines = {\n                        'plain'   : plain_lines,\n                        }\n                    file_cache[filename] = LineCacheInfo(stat, None, lines,\n                                                         path, None)\n                except:\n                    pass\n                pass\n            if orig_filename != filename:\n                file2file_remap[orig_filename] = filename\n                file2file_remap[os.path.abspath(orig_filename)] = filename\n                pass\n            file2file_remap[path] = filename\n            return filename\n        pass\n    pass\n\n    if os.path.exists(path):\n        stat = os.stat(path)\n    elif module_globals and '__loader__' in module_globals:\n        name = module_globals.get('__name__')\n        loader = module_globals['__loader__']\n        get_source = getattr(loader, 'get_source', None)\n        if name and get_source:\n            try:\n                data = get_source(name)\n            except (ImportError, IOError):\n                pass\n            else:\n                if data is None:\n                    # No luck, the PEP302 loader cannot find the source\n                    # for this module.\n                    return None\n                # FIXME: DRY with code below\n                lines = {'plain' : data.splitlines()}\n                raw_string        = ''.join(lines['plain'])\n                trailing_nl       = has_trailing_nl(raw_string)\n                if 'style' in opts:\n                    key = opts['style']\n                    highlight_opts = {'style': key}\n                else:\n                    key = 'terminal'\n                    highlight_opts = {}\n\n                lines[key] = highlight_array(raw_string.split('\\n'),\n                                    trailing_nl, **highlight_opts)\n                file_cache[filename] = \\\n                  LineCacheInfo(None, None, lines, filename, None)\n                file2file_remap[path] = filename\n                return True\n            pass\n        pass\n    if not os.path.isabs(filename):\n        # Try looking through the module search path, which is only useful\n        # when handling a relative filename.\n        stat = None\n        for dirname in sys.path:\n            path = os.path.join(dirname, filename)\n            if os.path.exists(path):\n                stat = os.stat(path)\n                break\n            pass\n        if not stat: return False\n        pass\n\n    try:\n        mode = 'r' if PYTHON3 else 'rU'\n        with open(path, mode) as fp:\n                lines = {'plain' : fp.readlines()}\n                eols = fp.newlines\n    except:\n        return None\n\n    # FIXME: DRY with code above\n    raw_string        = ''.join(lines['plain'])\n    trailing_nl       = has_trailing_nl(raw_string)\n    if 'style' in opts:\n        key = opts['style'] or 'default'\n        highlight_opts = {'style': key}\n    else:\n        key = 'terminal'\n        highlight_opts = {}\n\n    lines[key] = highlight_array(raw_string.split('\\n'),\n                                 trailing_nl, **highlight_opts)\n    if orig_filename != filename:\n        file2file_remap[orig_filename] = filename\n        file2file_remap[os.path.abspath(orig_filename)] = filename\n        pass\n    pass\n\n    file_cache[filename] = LineCacheInfo(stat, None, lines, path, None, eols)\n    file2file_remap[path] = filename\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def remember_ticket(self, request, ticket):\n        session = await get_session(request)\n        session[self.cookie_name] = ticket", "response": "Stores the ticket data for a request."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def forget_ticket(self, request):\n        session = await get_session(request)\n        session.pop(self.cookie_name, '')", "response": "Called to forget the ticket data a request object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def get_ticket(self, request):\n        session = await get_session(request)\n        return session.get(self.cookie_name)", "response": "Called to get the ticket for a request."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a aiohttp_auth middleware factory for use by the aiohttp_auth application object.", "response": "def auth_middleware(policy):\n    \"\"\"Returns a aiohttp_auth middleware factory for use by the aiohttp\n    application object.\n\n    Args:\n        policy: A authentication policy with a base class of\n            AbstractAuthentication.\n    \"\"\"\n    assert isinstance(policy, AbstractAuthentication)\n\n    async def _auth_middleware_factory(app, handler):\n\n        async def _middleware_handler(request):\n            # Save the policy in the request\n            request[POLICY_KEY] = policy\n\n            # Call the next handler in the chain\n            response = await handler(request)\n\n            # Give the policy a chance to handle the response\n            await policy.process_response(request, response)\n\n            return response\n\n        return _middleware_handler\n\n    return _auth_middleware_factory"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the user_id associated with a particular request.", "response": "async def get_auth(request):\n    \"\"\"Returns the user_id associated with a particular request.\n\n    Args:\n        request: aiohttp Request object.\n\n    Returns:\n        The user_id associated with the request, or None if no user is\n        associated with the request.\n\n    Raises:\n        RuntimeError: Middleware is not installed\n    \"\"\"\n\n    auth_val = request.get(AUTH_KEY)\n    if auth_val:\n        return auth_val\n\n    auth_policy = request.get(POLICY_KEY)\n    if auth_policy is None:\n        raise RuntimeError('auth_middleware not installed')\n\n    request[AUTH_KEY] = await auth_policy.get(request)\n    return request[AUTH_KEY]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def remember(request, user_id):\n    auth_policy = request.get(POLICY_KEY)\n    if auth_policy is None:\n        raise RuntimeError('auth_middleware not installed')\n\n    return await auth_policy.remember(request, user_id)", "response": "Called to store and remember the userid for a request"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalls to forget the userid for a request", "response": "async def forget(request):\n    \"\"\"Called to forget the userid for a request\n\n    Args:\n        request: aiohttp Request object\n\n    Raises:\n        RuntimeError: Middleware is not installed\n    \"\"\"\n    auth_policy = request.get(POLICY_KEY)\n    if auth_policy is None:\n        raise RuntimeError('auth_middleware not installed')\n\n    return await auth_policy.forget(request)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def process_response(self, request, response):\n        await super().process_response(request, response)\n        if COOKIE_AUTH_KEY in request:\n            if response.started:\n                raise RuntimeError(\"Cannot save cookie into started response\")\n\n            cookie = request[COOKIE_AUTH_KEY]\n            if cookie == '':\n                response.del_cookie(self.cookie_name)\n            else:\n                response.set_cookie(self.cookie_name, cookie)", "response": "This function is called by the HTTP Server to process the response."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef login_required(f):\n    '''\n    Definition decorator for all function requiring an active session\n    Credit: http://stackoverflow.com/a/7590709\n    '''\n    def _wrapper(self, *args, **kwargs):\n        '''\n        Function to be applied on top of all decorated methods\n        '''\n        if self._token_age:\n            timediff = self._token_age - datetime.datetime.now()\n            if timediff.total_seconds() / 60 > TOKEN_TIMEOUT:\n                self.logout()  # Log out to invalidate previous token\n                self.login()  # Request new token\n        else:  # haven't logged in yet\n            self.login()\n        return f(self, *args, **kwargs)\n    return _wrapper", "response": "Decorator for all methods that require a active session."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef api_version(self, verbose=False):\n        '''\n        Get information about the API\n        http://docs.opsview.com/doku.php?id=opsview4.6:restapi#api_version_information\n        '''\n        return self.__auth_req_get(self.rest_url, verbose=verbose)", "response": "Get information about the APIVersion"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting information about the current opsview instance", "response": "def opsview_info(self, verbose=False):\n        '''\n        Get information about the current opsview instance\n        http://docs.opsview.com/doku.php?id=opsview4.6:restapi#opsview_information\n        '''\n        url = '{}/{}'.format(self.rest_url, 'info')\n        return self.__auth_req_get(url, verbose=verbose)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nauthenticating with Opsview and return the authentification token", "response": "def login(self, verbose=False):\n        '''\n        Authenticate with Opsview\n        :param verbose: Verbose output mode\n        :type verbose: bool\n        :return: The authentification token\n        :rtype: str or unicode\n        '''\n        url = '{}/{}'.format(self.rest_url, 'login')\n        logger.debug('POST: {}'.format(url))\n        r = requests.post(url, json={\n                'username': self.username,\n                'password': self.password\n            },\n            verify=self.verify_ssl\n        )\n        j = r.json()\n        logger.debug('Request response:')\n        logger.debug(pformat(vars(r)))\n        logger.debug('JSON:')\n        logger.debug(pformat(j))\n        if 'token' not in j:\n            raise OpsviewLoginException(\"Failed to retrieve token. \"\n                                        \"Please check your credentials\")\n        self.headers['X-Opsview-Token'] = j['token']\n        self._token_age = datetime.datetime.now()\n        return j['token']"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef logout(self, verbose=False):\n        '''\n        Delete the current session\n        http://docs.opsview.com/doku.php?id=opsview4.6:restapi#logout\n        '''\n        url = '{}/{}'.format(self.rest_url, 'logout')\n        response = self.__auth_req_post(url, verbose=verbose)\n        self.headers['X-Opsview-Token'] = None\n        return response", "response": "Logout the current session"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting information about the currently authenticated user", "response": "def user_info(self, verbose=False):\n        '''\n        Get information about the currently authenticated user\n        http://docs.opsview.com/doku.php?id=opsview4.6:restapi#user_information\n        '''\n        url = '{}/{}'.format(self.rest_url, 'user')\n        return self.__auth_req_get(url, verbose=verbose)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget information about the Opsview monitoring servers", "response": "def server_info(self, verbose=False):\n        '''\n        Get information about the Opsview monitoring servers\n        http://docs.opsview.com/doku.php?id=opsview4.6:restapi#server_information\n        '''\n        url = '{}/{}'.format(self.rest_url, 'serverinfo')\n        return self.__auth_req_get(url, verbose=verbose)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reload_config(self, async=True, verbose=False):\n        '''\n        Initiate a config reload. This may take a while on large installations.\n        '''\n        # If we're using an API version older than 4.5.0, don't use async\n        api_version = float(self.api_version()['api_version'])\n        if api_version < 4.5:\n            async = False\n        url = '{}/{}{}'.format(\n            self.rest_url, 'reload', '?asynchronous=1' if async else ''\n        )\n        return self.__auth_req_post(url, verbose=verbose)", "response": "Initiate a config reload. This is a blocking call."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalls to store the userid for a request. This function creates a ticket from the request and user_id, and calls the abstract function remember_ticket() to store the ticket. Args: request: aiohttp Request object. user_id: String representing the user_id to remember", "response": "async def remember(self, request, user_id):\n        \"\"\"Called to store the userid for a request.\n\n        This function creates a ticket from the request and user_id, and calls\n        the abstract function remember_ticket() to store the ticket.\n\n        Args:\n            request: aiohttp Request object.\n            user_id: String representing the user_id to remember\n        \"\"\"\n        ticket = self._new_ticket(request, user_id)\n        await self.remember_ticket(request, ticket)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def get(self, request):\n        ticket = await self.get_ticket(request)\n        if ticket is None:\n            return None\n\n        try:\n            # Returns a tuple of (user_id, token, userdata, validuntil)\n            now = time.time()\n            fields = self._ticket.validate(ticket, self._get_ip(request), now)\n\n            # Check if we need to reissue a ticket\n            if (self._reissue_time is not None and\n                now >= (fields.valid_until - self._reissue_time)):\n\n                # Reissue our ticket, and save it in our request.\n                request[_REISSUE_KEY] = self._new_ticket(request, fields.user_id)\n\n            return fields.user_id\n\n        except TicketError as e:\n            return None", "response": "Gets the user_id for the request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update(self, iterable=None, **kwds):\n\t\t'''Like dict.update() but add counts instead of replacing them.\n\n\t\tSource can be an iterable, a dictionary, or another Counter instance.\n\n\t\t>>> c = Counter('which')\n\t\t>>> c.update('witch')\t\t   # add elements from another iterable\n\t\t>>> d = Counter('watch')\n\t\t>>> c.update(d)\t\t\t\t # add elements from another counter\n\t\t>>> c['h']\t\t\t\t\t  # four 'h' in which, witch, and watch\n\t\t4\n\n\t\t'''\n\t\tif iterable is not None:\n\t\t\tif hasattr(iterable, 'iteritems'):\n\t\t\t\tif self:\n\t\t\t\t\tself_get = self.get\n\t\t\t\t\ttry:\n\t\t\t\t\t\titeritems = self.iteritems()\n\t\t\t\t\texcept AttributeError:\n\t\t\t\t\t\titeritems = iter(self)\n\t\t\t\t\tfor elem, count in iteritems:\n\t\t\t\t\t\tself[elem] = self_get(elem, 0) + count\n\t\t\t\telse:\n\t\t\t\t\tdict.update(self, iterable) # fast path when counter is empty\n\t\t\telse:\n\t\t\t\tself_get = self.get\n\t\t\t\tfor elem in iterable:\n\t\t\t\t\tself[elem] = self_get(elem, 0) + 1\n\t\tif kwds:\n\t\t\tself.update(kwds)", "response": "Like dict. update but add counts instead of replacing them."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef acl_required(permission, context):\n\n    def decorator(func):\n\n        @wraps(func)\n        async def wrapper(*args):\n            request = args[-1]\n\n            if callable(context):\n                context = context()\n\n            if await get_permitted(request, permission, context):\n                return await func(*args)\n\n            raise web.HTTPForbidden()\n\n        return wrapper\n\n    return decorator", "response": "Returns a decorator that checks if a user has the requested permission for the passed acl context."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_version_2(dataset):\n\n    if float(dataset.get('version')) >= 2.0 \\\n            if dataset.get('version') else False:\n        return True\n    else:\n        return False", "response": "Checks if json - stat version attribute exists and is equal or greater than 2. 0 for a given dataset."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef unnest_collection(collection, df_list):\n    for item in collection['link']['item']:\n        if item['class'] == 'dataset':\n            df_list.append(Dataset.read(item['href']).write('dataframe'))\n        elif item['class'] == 'collection':\n            nested_collection = request(item['href'])\n            unnest_collection(nested_collection, df_list)", "response": "Unnest a collection structure and convert all its datasets to Pandas Dataframes."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget dimensions from input data.", "response": "def get_dimensions(js_dict, naming):\n    \"\"\"Get dimensions from input data.\n\n    Args:\n      js_dict (dict): dictionary containing dataset data and metadata.\n      naming (string, optional): dimension naming. Possible values: 'label' \\\n                                 or 'id'.\n\n    Returns:\n      dimensions (list): list of pandas data frames with dimension \\\n                         category data.\n      dim_names (list): list of strings with dimension names.\n    \"\"\"\n\n    dimensions = []\n    dim_names = []\n    if check_version_2(js_dict):\n        dimension_dict = js_dict\n    else:\n        dimension_dict = js_dict['dimension']\n    for dim in dimension_dict['id']:\n        dim_name = js_dict['dimension'][dim]['label']\n        if not dim_name:\n            dim_name = dim\n        if naming == 'label':\n            dim_label = get_dim_label(js_dict, dim)\n            dimensions.append(dim_label)\n            dim_names.append(dim_name)\n        else:\n            dim_index = get_dim_index(js_dict, dim)\n            dimensions.append(dim_index)\n            dim_names.append(dim)\n    return dimensions, dim_names"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets label from a given dimension.", "response": "def get_dim_label(js_dict, dim, input=\"dataset\"):\n    \"\"\"Get label from a given dimension.\n\n    Args:\n      js_dict (dict): dictionary containing dataset data and metadata.\n      dim (string): dimension name obtained from JSON file.\n\n    Returns:\n      dim_label(pandas.DataFrame): DataFrame with label-based dimension data.\n\n    \"\"\"\n\n    if input == 'dataset':\n        input = js_dict['dimension'][dim]\n        label_col = 'label'\n    elif input == 'dimension':\n        label_col = js_dict['label']\n        input = js_dict\n    else:\n        raise ValueError\n\n    try:\n        dim_label = input['category']['label']\n\n    except KeyError:\n        dim_index = get_dim_index(js_dict, dim)\n        dim_label = pd.concat([dim_index['id'],\n                               dim_index['id']],\n                              axis=1)\n        dim_label.columns = ['id', 'label']\n    else:\n        dim_label = pd.DataFrame(list(zip(dim_label.keys(),\n                                          dim_label.values())),\n                                 index=dim_label.keys(),\n                                 columns=['id', label_col])\n    # index must be added to dim label so that it can be sorted\n    try:\n        dim_index = input['category']['index']\n    except KeyError:\n        dim_index = pd.DataFrame(list(zip([dim_label['id'][0]], [0])),\n                                 index=[0],\n                                 columns=['id', 'index'])\n    else:\n        if type(dim_index) is list:\n            dim_index = pd.DataFrame(list(zip(dim_index,\n                                              range(0, len(dim_index)))),\n                                     index=dim_index, columns=['id', 'index'])\n        else:\n            dim_index = pd.DataFrame(list(zip(dim_index.keys(),\n                                              dim_index.values())),\n                                     index=dim_index.keys(),\n                                     columns=['id', 'index'])\n    dim_label = pd.merge(dim_label, dim_index, on='id').sort_index(by='index')\n    return dim_label"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget index from a given dimension.", "response": "def get_dim_index(js_dict, dim):\n    \"\"\"Get index from a given dimension.\n\n    Args:\n      js_dict (dict): dictionary containing dataset data and metadata.\n      dim (string): dimension name obtained from JSON file.\n\n    Returns:\n      dim_index (pandas.DataFrame): DataFrame with index-based dimension data.\n\n    \"\"\"\n\n    try:\n        dim_index = js_dict['dimension'][dim]['category']['index']\n    except KeyError:\n        dim_label = get_dim_label(js_dict, dim)\n        dim_index = pd.DataFrame(list(zip([dim_label['id'][0]], [0])),\n                                 index=[0],\n                                 columns=['id', 'index'])\n    else:\n        if type(dim_index) is list:\n            dim_index = pd.DataFrame(list(zip(dim_index,\n                                              range(0, len(dim_index)))),\n                                     index=dim_index, columns=['id', 'index'])\n        else:\n            dim_index = pd.DataFrame(list(zip(dim_index.keys(),\n                                              dim_index.values())),\n                                     index=dim_index.keys(),\n                                     columns=['id', 'index'])\n    dim_index = dim_index.sort_index(by='index')\n    return dim_index"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget values from input data and metadata.", "response": "def get_values(js_dict, value='value'):\n    \"\"\"Get values from input data.\n\n    Args:\n      js_dict (dict): dictionary containing dataset data and metadata.\n      value (string, optional): name of the value column. Defaults to 'value'.\n\n    Returns:\n      values (list): list of dataset values.\n\n    \"\"\"\n\n    values = js_dict[value]\n    if type(values) is list:\n        if type(values[0]) is not dict or tuple:\n            return values\n    # being not a list of dicts or tuples leaves us with a dict...\n    values = {int(key): value for (key, value) in values.items()}\n\n    if js_dict.get('size'):\n        max_val = np.prod(np.array((js_dict['size'])))\n    else:\n        max_val = np.prod(np.array((js_dict['dimension']['size'])))\n    vals = max_val * [None]\n    for (key, value) in values.items():\n        vals[key] = value\n\n    values = vals\n    return values"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating row dimension values for a pandas dataframe.", "response": "def get_df_row(dimensions, naming='label', i=0, record=None):\n    \"\"\"Generate row dimension values for a pandas dataframe.\n\n    Args:\n      dimensions (list): list of pandas dataframes with dimension labels \\\n                         generated by get_dim_label or get_dim_index methods.\n      naming (string, optional): dimension naming. Possible values: 'label' \\\n                                 or 'id'.\n      i (int): dimension list iteration index. Default is 0, it's used in the \\\n                         recursive calls to the method.\n      record (list): list of values representing a pandas dataframe row, \\\n                     except for the value column. Default is empty, it's used \\\n                     in the recursive calls to the method.\n\n    Yields:\n      list: list with pandas dataframe column values except for value column\n\n    \"\"\"\n\n    check_input(naming)\n    if i == 0 or record is None:\n        record = []\n    for dimension in dimensions[i][naming]:\n        record.append(dimension)\n        if len(record) == len(dimensions):\n            yield record\n\n        if i + 1 < len(dimensions):\n            for row in get_df_row(dimensions, naming, i + 1, record):\n                yield row\n        if len(record) == i + 1:\n            record.pop()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list with unique values preserving original order.", "response": "def uniquify(seq):\n    \"\"\"Return unique values in a list in the original order. See:  \\\n        http://www.peterbe.com/plog/uniqifiers-benchmark\n\n    Args:\n      seq (list): original list.\n\n    Returns:\n      list: list without duplicates preserving original order.\n\n    \"\"\"\n\n    seen = set()\n    seen_add = seen.add\n    return [x for x in seq if x not in seen and not seen_add(x)]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_df(js_dict, naming, value=\"value\"):\n\n    values = []\n    dimensions, dim_names = get_dimensions(js_dict, naming)\n    values = get_values(js_dict, value=value)\n    output = pd.DataFrame([category + [values[i]]\n                           for i, category in\n                           enumerate(get_df_row(dimensions, naming))])\n    output.columns = dim_names + [value]\n    output.index = range(0, len(values))\n    return output", "response": "Decode JSON - stat dict into pandas. DataFrame."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndecodes JSON - stat formatted data into pandas. DataFrame object.", "response": "def from_json_stat(datasets, naming='label', value='value'):\n    \"\"\"Decode JSON-stat formatted data into pandas.DataFrame object.\n\n    Args:\n      datasets(OrderedDict, list): data in JSON-stat format, previously \\\n                                   deserialized to a python object by \\\n                                   json.load() or json.loads(), for example.\\\n                                   Both List and OrderedDict are accepted \\\n                                   as inputs.\n      naming(string, optional): dimension naming. Possible values: 'label'\n                                or 'id'.Defaults to 'label'.\n      value (string, optional): name of the value column. Defaults to 'value'.\n\n    Returns:\n      results(list): list of pandas.DataFrame with imported data.\n\n    \"\"\"\n\n    warnings.warn(\n        \"Shouldn't use this function anymore! Now use read() methods of\"\n        \"Dataset, Collection or Dimension.\",\n        DeprecationWarning\n    )\n\n    check_input(naming)\n    results = []\n    if type(datasets) is list:\n        for idx, element in enumerate(datasets):\n            for dataset in element:\n                js_dict = datasets[idx][dataset]\n                results.append(generate_df(js_dict, naming, value))\n    elif isinstance(datasets, OrderedDict) or type(datasets) is dict or \\\n            isinstance(datasets, Dataset):\n        if 'class' in datasets:\n            if datasets['class'] == 'dataset':\n                js_dict = datasets\n                results.append(generate_df(js_dict, naming, value))\n        else:  # 1.00 bundle type\n            for dataset in datasets:\n                js_dict = datasets[dataset]\n                results.append(generate_df(js_dict, naming, value))\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nencode pandas. DataFrame object into JSON - stat format.", "response": "def to_json_stat(input_df, value='value', output='list', version='1.3'):\n    \"\"\"Encode pandas.DataFrame object into JSON-stat format. The DataFrames\n       must have exactly one value column.\n\n    Args:\n      df(pandas.DataFrame): pandas data frame (or list of data frames) to\n      encode.\n      value (string, optional): name of the value column. Defaults to 'value'.\n      output(string): accepts two values: 'list' or 'dict'. Produce list of\\\n                      dicts or dict of dicts as output.\n      version(string): desired json-stat version. 2.0 is preferred now.\\\n                       Apart from this, only older 1.3 format is accepted,\n                       which is the default parameter in order to preserve\n                       backwards compatibility.\n\n    Returns:\n      output(string): String with JSON-stat object.\n\n    \"\"\"\n\n    warnings.warn(\n        \"Shouldn't use this function anymore! Now use write() methods of\"\n        \"Dataset, Collection or Dimension.\",\n        DeprecationWarning\n    )\n    data = []\n    if output == 'list':\n        result = []\n    elif output == 'dict':\n        result = OrderedDict({})\n    if isinstance(input_df, pd.DataFrame):\n        data.append(input_df)\n    else:\n        data = input_df\n    for row, dataframe in enumerate(data):\n        dims = data[row].filter([item for item in data[row].columns.values\n                                 if item not in value])\n        if len(dims.columns.values) != len(set(dims.columns.values)):\n            raise ValueError('Non-value columns must constitute a unique ID')\n        dim_names = list(dims)\n        categories = [{to_int(i):\n                           {\"label\": to_str(i),\n                            \"category\":\n                                {\"index\":\n                                     OrderedDict([(to_str(j), to_int(k))\n                                                  for k, j in enumerate(\n                                                      uniquify(dims[i]))]),\n                                 \"label\":\n                                     OrderedDict([(to_str(j), to_str(j))\n                                                  for k, j in enumerate(\n                                                      uniquify(dims[i]))])}}}\n                      for i in dims.columns.values]\n        if float(version) >= 2.0:\n\n            dataset = {\"dimension\": OrderedDict(),\n                       value: [None if np.isnan(x) else x\n                               for x in dataframe[value].values]}\n\n            dataset[\"version\"] = version\n            dataset[\"class\"] = \"dataset\"\n            for category in categories:\n                dataset[\"dimension\"].update(category)\n            dataset.update({\"id\": dim_names})\n            dataset.update({\"size\": [len(dims[i].unique())\n                                     for i in dims.columns.values]})\n            for category in categories:\n                dataset[\"dimension\"].update(category)\n        else:\n            dataset = {\"dataset\" +\n                       str(row + 1):\n                       {\"dimension\": OrderedDict(),\n                        value: [None if np.isnan(x) else x\n                                for x in dataframe[value].values]}}\n            for category in categories:\n                dataset[\"dataset\" + str(row + 1)][\n                    \"dimension\"].update(category)\n            dataset[\"dataset\" + str(row + 1)][\n                \"dimension\"].update({\"id\": dim_names})\n            dataset[\"dataset\" + str(row + 1)][\n                \"dimension\"].update({\"size\": [len(dims[i].unique())\n                                              for i in dims.columns.values]})\n            for category in categories:\n                dataset[\"dataset\" + str(row + 1)][\n                    \"dimension\"].update(category)\n\n        if output == 'list':\n            result.append(dataset)\n        elif output == 'dict':\n            result.update(dataset)\n        else:\n            result = None\n    return json.dumps(result, cls=NumpyEncoder)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsends a request to a given URL accepting JSON format and return a deserialized JSON Python object.", "response": "def request(path):\n    \"\"\"Send a request to a given URL accepting JSON format and return a \\\n       deserialized Python object.\n\n    Args:\n      path (str): The URI to be requested.\n\n    Returns:\n      response: Deserialized JSON Python object.\n\n    Raises:\n      HTTPError: the HTTP error returned by the requested server.\n      InvalidURL: an invalid URL has been requested.\n      Exception: generic exception.\n\n    \"\"\"\n    headers = {'Accept': 'application/json'}\n    try:\n        requested_object = requests.get(path, headers=headers)\n        requested_object.raise_for_status()\n    except requests.exceptions.HTTPError as exception:\n        LOGGER.error((inspect.stack()[0][3]) + ': HTTPError = ' +\n                     str(exception.response.status_code) + ' ' +\n                     str(exception.response.reason) + ' ' + str(path))\n        raise\n    except requests.exceptions.InvalidURL as exception:\n        LOGGER.error('URLError = ' + str(exception.reason) + ' ' + str(path))\n        raise\n    except Exception:\n        import traceback\n        LOGGER.error('Generic exception: ' + traceback.format_exc())\n        raise\n    else:\n        response = requested_object.json()\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read(cls, data):\n        if isinstance(data, pd.DataFrame):\n            return cls((json.loads(\n                to_json_stat(data, output='dict', version='2.0'),\n                object_pairs_hook=OrderedDict)))\n        elif isinstance(data, OrderedDict):\n            return cls(data)\n        elif (isinstance(data, basestring)\n              and data.startswith((\"http://\", \"https://\",\n                                   \"ftp://\", \"ftps://\"))):\n            # requests will do the rest...\n            return cls(request(data))\n        elif isinstance(data, basestring):\n            try:\n                json_dict = json.loads(data, object_pairs_hook=OrderedDict)\n                return cls(json_dict)\n            except ValueError:\n                raise\n        else:\n            try:\n                json_dict = json.load(data, object_pairs_hook=OrderedDict)\n                return cls(json_dict)\n            except ValueError:\n                raise", "response": "Reads data from a JSON string or Pandas Dataframe or a JSONstat file or a URL pointing to a JSONstat file or a string pointing to a URL pointing to a JSON file or OrderedDict."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a dimension ID string and a categody ID string into the \\ numeric index of that category in that dimension.", "response": "def get_dimension_index(self, name, value):\n        \"\"\"Converts a dimension ID string and a categody ID string into the \\\n           numeric index of that category in that dimension\n        Args:\n           name(string): ID string of the dimension.\n           value(string): ID string of the category.\n\n        Returns:\n           ndx[value](int): index of the category in the dimension.\n\n        \"\"\"\n\n        if 'index' not in self.get('dimension', {}). \\\n                get(name, {}).get('category', {}):\n            return 0\n        ndx = self['dimension'][name]['category']['index']\n\n        if isinstance(ndx, list):\n            return ndx.index(value)\n        else:\n            return ndx[value]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a dimension list of dicts into a list of \\ dimensions\u2019 indices.", "response": "def get_dimension_indices(self, query):\n        \"\"\"Converts a dimension/category list of dicts into a list of \\\n           dimensions\u2019 indices.\n        Args:\n           query(list): dimension/category list of dicts.\n\n        Returns:\n           indices(list): list of dimensions' indices.\n\n        \"\"\"\n        ids = self['id'] if self.get('id') else self['dimension']['id']\n        indices = []\n\n        for idx, id in enumerate(ids):\n            indices.append(self.get_dimension_index(id,\n                                                    [d.get(id) for d in query\n                                                     if id in d][0]))\n\n        return indices"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_value_index(self, indices):\n        size = self['size'] if self.get('size') else self['dimension']['size']\n        ndims = len(size)\n        mult = 1\n        num = 0\n        for idx, dim in enumerate(size):\n            mult *= size[ndims - idx] if (idx > 0) else 1\n            num += mult * indices[ndims - idx - 1]\n        return num", "response": "Converts a list of dimensions s indices into a numeric value index."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a dimension / category list of dicts into a numeric data value \\ in three steps.", "response": "def get_value(self, query):\n        \"\"\"Converts a dimension/category list of dicts into a data value \\\n           in three steps.\n\n       Args:\n           query(list): list of dicts with the desired query.\n\n       Returns:\n           value(float): numeric data value.\n\n       \"\"\"\n        indices = self.get_dimension_indices(query)\n        index = self.get_value_index(indices)\n        value = self.get_value_by_index(index)\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read(cls, data):\n        if isinstance(data, pd.DataFrame):\n            output = OrderedDict({})\n            output['version'] = '2.0'\n            output['class'] = 'dimension'\n            [label] = [x for x in list(data.columns.values) if\n                       x not in ['id', 'index']]\n            output['label'] = label\n            output['category'] = OrderedDict({})\n            output['category']['index'] = data.id.tolist()\n            output['category']['label'] = OrderedDict(\n                zip(data.id.values, data[label].values))\n            return cls(output)\n        elif isinstance(data, OrderedDict):\n            return cls(data)\n        elif isinstance(data, basestring) and data.startswith((\"http://\",\n                                                               \"https://\",\n                                                               \"ftp://\",\n                                                               \"ftps://\")):\n            return cls(request(data))\n        elif isinstance(data,basestring):\n            try:\n                json_dict = json.loads(data, object_pairs_hook=OrderedDict)\n                return cls(json_dict)\n            except ValueError:\n                raise\n        else:\n            try:\n                json_dict = json.load(data, object_pairs_hook=OrderedDict)\n                return cls(json_dict)\n            except ValueError:\n                raise", "response": "Reads data from URL dataframe JSON string or JSON file or OrderedDict."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write(self, output='jsonstat'):\n\n        if output == 'jsonstat':\n            return json.dumps(OrderedDict(self), cls=NumpyEncoder)\n        elif output == 'dataframe':\n            return get_dim_label(self, self['label'], 'dimension')\n        else:\n            raise ValueError(\"Allowed arguments are 'jsonstat' or 'dataframe'\")", "response": "Writes data from a Dataset object to JSONstat or Pandas Dataframe."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read(cls, data):\n        if isinstance(data, OrderedDict):\n            return cls(data)\n        elif isinstance(data, basestring)\\\n             and data.startswith((\"http://\", \"https://\", \"ftp://\", \"ftps://\")):\n            return cls(request(data))\n        elif isinstance(data, basestring):\n            try:\n                json_dict = json.loads(data, object_pairs_hook=OrderedDict)\n                return cls(json_dict)\n            except ValueError:\n                raise\n        else:\n            try:\n                json_dict = json.load(data, object_pairs_hook=OrderedDict)\n                return cls(json_dict)\n            except ValueError:\n                raise", "response": "Reads data from a JSONstat file or an OrderedDict."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting data from a Collection object to JSONstat or Pandas Dataframes.", "response": "def write(self, output='jsonstat'):\n        \"\"\"Writes data from a Collection object to JSONstat or list of \\\n           Pandas Dataframes.\n        Args:\n            output(string): can accept 'jsonstat' or 'dataframe_list'\n\n        Returns:\n            Serialized JSONstat or a list of Pandas Dataframes,depending on \\\n            the 'output' parameter.\n\n        \"\"\"\n\n        if output == 'jsonstat':\n            return json.dumps(self)\n        elif output == 'dataframe_list':\n            df_list = []\n            unnest_collection(self, df_list)\n            return df_list\n        else:\n            raise ValueError(\n                \"Allowed arguments are 'jsonstat' or 'dataframe_list'\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, element):\n\n        if self['link']['item'][element]['class'] == 'dataset':\n            return Dataset.read(self['link']['item'][element]['href'])\n        elif self['link']['item'][element]['class'] == 'collection':\n            return Collection.read(self['link']['item'][element]['href'])\n        elif self['link']['item'][element]['class'] == 'dimension':\n            return Dimension.read(self['link']['item'][element]['href'])\n        else:\n            raise ValueError(\n                \"Class not allowed. Please use dataset, collection or \"\n                \"dimension'\")", "response": "Gets ith element of a collection in an object of the corresponding \\\n           class."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef auth_required(func):\n    @wraps(func)\n    async def wrapper(*args):\n        if (await get_auth(args[-1])) is None:\n            raise web.HTTPForbidden()\n\n        return await func(*args)\n\n    return wrapper", "response": "Decorator that checks if a user has been authenticated for this request."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef render_partial(parser, token):\n\n    args = []\n    kwargs = {}\n    tokens = token.split_contents()\n    if len(tokens) < 2:\n        raise TemplateSyntaxError(\n            '%r tag requires one or more arguments' %\n            token.contents.split()[0]\n        )\n    tokens.pop(0)  # tag name\n    view_name = tokens.pop(0)\n    for token in tokens:\n        equals = token.find('=')\n        if equals == -1:\n            args.append(token)\n        else:\n            kwargs[str(token[:equals])] = token[equals+1:]\n    return ViewNode(view_name, args, kwargs)", "response": "This function renders a partial view from urls. py."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef render_wavedrom(self, node, outpath, bname, format):\n\n    # Try to convert node, raise error with code on failure\n    try:\n        svgout = WaveDrom().renderWaveForm(0, json.loads(node['code']))\n    except JSONDecodeError as e:\n        raise SphinxError(\"Cannot render the following json code: \\n{} \\n\\nError: {}\".format(node['code'], e))\n\n    if not os.path.exists(outpath):\n        os.makedirs(outpath)\n\n    # SVG can be directly written and is supported on all versions\n    if format == 'image/svg+xml':\n        fname = \"{}.{}\".format(bname, \"svg\")\n        fpath = os.path.join(outpath, fname)\n        svgout.saveas(fpath)\n        return fname\n\n    # It gets a bit ugly, if the output does not support svg. We use cairosvg, because it is the easiest\n    # to use (no dependency on installed programs). But it only works for Python 3.\n    try:\n        import cairosvg\n    except:\n        raise SphinxError(__(\"Cannot import 'cairosvg'. In Python 2 wavedrom figures other than svg are \"\n                             \"not supported, in Python 3 ensure 'cairosvg' is installed.\"))\n\n    if format == 'application/pdf':\n        fname = \"{}.{}\".format(bname, \"pdf\")\n        fpath = os.path.join(outpath, fname)\n        cairosvg.svg2pdf(svgout.tostring(), write_to=fpath)\n        return fname\n\n    if format == 'image/png':\n        fname = \"{}.{}\".format(bname, \"png\")\n        fpath = os.path.join(outpath, fname)\n        cairosvg.svg2png(svgout.tostring(), write_to=fpath)\n        return fname\n\n    raise SphinxError(\"No valid wavedrom conversion supplied\")", "response": "Render a wavedrom image"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nvisiting the wavedrom node and create a random filename and add the image node to the node.", "response": "def visit_wavedrom(self, node):\n    \"\"\"\n    Visit the wavedrom node\n    \"\"\"\n    format = determine_format(self.builder.supported_image_types)\n    if format is None:\n        raise SphinxError(__(\"Cannot determine a suitable output format\"))\n\n    # Create random filename\n    bname = \"wavedrom-{}\".format(uuid4())\n    outpath = path.join(self.builder.outdir, self.builder.imagedir)\n\n    # Render the wavedrom image\n    imgname = render_wavedrom(self, node, outpath, bname, format)\n\n    # Now we unpack the image node again. The file was created at the build destination,\n    # and we can now use the standard visitor for the image node. We add the image node\n    # as a child and then raise a SkipDepature, which will trigger the builder to visit\n    # children.\n    image_node = node['image_node']\n    image_node['uri'] = os.path.join(self.builder.imgpath, imgname)\n    node.append(image_node)\n\n    raise nodes.SkipDeparture"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninitializing the internal list of builders for this application.", "response": "def builder_inited(app):\n    \"\"\"\n    Sets wavedrom_html_jsinline to False for all non-html builders for\n    convenience (use ifconf etc.)\n\n    We instruct sphinx to include some javascript files in the output html.\n    Depending on the settings provided in the configuration, we take either\n    the online files from the wavedrom server, or the locally provided wavedrom\n    javascript files\n    \"\"\"\n    if (app.config.wavedrom_html_jsinline and\n        app.builder.name not in ('html', 'dirhtml', 'singlehtml')):\n        app.config.wavedrom_html_jsinline = False\n\n    # Skip for non-html or if javascript is not inlined\n    if not app.env.config.wavedrom_html_jsinline:\n        return\n\n    if app.config.offline_skin_js_path is not None:\n        app.add_javascript(path.basename(app.config.offline_skin_js_path))\n    else:\n        app.add_javascript(ONLINE_SKIN_JS)\n    if app.config.offline_wavedrom_js_path is not None:\n        app.add_javascript(path.basename(app.config.offline_wavedrom_js_path))\n    else:\n        app.add_javascript(ONLINE_WAVEDROM_JS)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build_finished(app, exception):\n    # Skip for non-html or if javascript is not inlined\n    if not app.env.config.wavedrom_html_jsinline:\n        return\n\n    if app.config.offline_skin_js_path is not None:\n        copy_static_entry(path.join(app.builder.srcdir, app.config.offline_skin_js_path), path.join(app.builder.outdir, '_static'), app.builder)\n    if app.config.offline_wavedrom_js_path is not None:\n        copy_static_entry(path.join(app.builder.srcdir, app.config.offline_wavedrom_js_path), path.join(app.builder.outdir, '_static'), app.builder)", "response": "This function is called when the build is finished."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_supercell(system, matrix, supercell=[1, 1, 1]):\n    user_supercell = [[1, supercell[0]], [1, supercell[1]], [1, supercell[1]]]\n    system = create_supercell(system, matrix, supercell=user_supercell)\n    return MolecularSystem.load_system(system)", "response": "Creates a supercell of a system."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nextracts frames from the trajectory file. Depending on the passed parameters a frame, a list of particular frames, a range of frames (from, to), or all frames can be extracted with this function. Parameters ---------- frames : :class:`int` or :class:`list` or :class:`touple` or :class:`str` Specified frame (:class:`int`), or frames (:class:`list`), or range (:class:`touple`), or `all`/`everything` (:class:`str`). (default=`all`) override : :class:`bool` If True, a frame already storred in :attr:`frames` can be override. (default=False) extract_data : :class:`bool`, optional If False, a frame is returned as a :class:`str` block as in the trajectory file. Ohterwise, it is extracted and returned as :class:`pywindow.molecular.MolecularSystem`. (default=True) swap_atoms : :class:`dict`, optional If this kwarg is passed with an appropriate dictionary a :func:`pywindow.molecular.MolecularSystem.swap_atom_keys()` will be applied to the extracted frame. forcefield : :class:`str`, optional If this kwarg is passed with appropriate forcefield keyword a :func:`pywindow.molecular.MolecularSystem.decipher_atom_keys()` will be applied to the extracted frame. Returns ------- :class:`pywindow.molecular.MolecularSystem` If a single frame is extracted. None : :class:`NoneType` If more than one frame is extracted, the frames are returned to :attr:`frames`", "response": "def get_frames(self, frames='all', override=False, **kwargs):\n        \"\"\"\n        Extract frames from the trajectory file.\n\n        Depending on the passed parameters a frame, a list of particular\n        frames, a range of frames (from, to), or all frames can be extracted\n        with this function.\n\n        Parameters\n        ----------\n        frames : :class:`int` or :class:`list` or :class:`touple` or :class:`str`\n            Specified frame (:class:`int`), or frames (:class:`list`), or\n            range (:class:`touple`), or `all`/`everything` (:class:`str`).\n            (default=`all`)\n\n        override : :class:`bool`\n            If True, a frame already storred in :attr:`frames` can be override.\n            (default=False)\n\n        extract_data : :class:`bool`, optional\n            If False, a frame is returned as a :class:`str` block as in the\n            trajectory file. Ohterwise, it is extracted and returned as\n            :class:`pywindow.molecular.MolecularSystem`. (default=True)\n\n        swap_atoms : :class:`dict`, optional\n            If this kwarg is passed with an appropriate dictionary a\n            :func:`pywindow.molecular.MolecularSystem.swap_atom_keys()` will\n            be applied to the extracted frame.\n\n        forcefield : :class:`str`, optional\n            If this kwarg is passed with appropriate forcefield keyword a\n            :func:`pywindow.molecular.MolecularSystem.decipher_atom_keys()`\n            will be applied to the extracted frame.\n\n        Returns\n        -------\n        :class:`pywindow.molecular.MolecularSystem`\n            If a single frame is extracted.\n\n        None : :class:`NoneType`\n            If more than one frame is extracted, the frames are returned to\n            :attr:`frames`\n\n        \"\"\"\n        if override is True:\n            self.frames = {}\n        if isinstance(frames, int):\n            frame = self._get_frame(\n                self.trajectory_map[frames], frames, **kwargs)\n            if frames not in self.frames.keys():\n                self.frames[frames] = frame\n            return frame\n        if isinstance(frames, list):\n            for frame in frames:\n                if frame not in self.frames.keys():\n                    self.frames[frame] = self._get_frame(\n                        self.trajectory_map[frame], frame, **kwargs)\n        if isinstance(frames, tuple):\n            for frame in range(frames[0], frames[1]):\n                if frame not in self.frames.keys():\n                    self.frames[frame] = self._get_frame(\n                        self.trajectory_map[frame], frame, **kwargs)\n        if isinstance(frames, str):\n            if frames in ['all', 'everything']:\n                for frame in range(0, self.no_of_frames):\n                    if frame not in self.frames.keys():\n                        self.frames[frame] = self._get_frame(\n                            self.trajectory_map[frame], frame, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef analysis(\n            self, frames='all', ncpus=1, _ncpus=1, override=False, **kwargs\n                ):\n        \"\"\"\n        Perform structural analysis on a frame/ set of frames.\n\n        Depending on the passed parameters a frame, a list of particular\n        frames, a range of frames (from, to), or all frames can be analysed\n        with this function.\n\n        The analysis is performed on each frame and each discrete molecule in\n        that frame separately. The steps are as follows:\n\n        1. A frame is extracted and returned as a :class:`MolecularSystem`.\n        2. If `swap_atoms` is set the atom ids are swapped.\n        3. If `forcefield` is set the atom ids are deciphered.\n        4. If `rebuild` is set the molecules in the system are rebuild.\n        5. Each discrete molecule is extracted as :class:`Molecule`\n        6. Each molecule is analysed with :func:`Molecule.full_analysis()`\n        7. Analysis output populates the :attr:`analysis_output` dictionary.\n\n        As the analysis of trajectories often have to be unique, many options\n        are conditional.\n\n        A side effect of this function is that the analysed frames are also\n        returned to the :attr:`frames` mimicking the behaviour of the\n        :func:`get_frames()`.\n\n        Parameters\n        ----------\n        frames : :class:`int` or :class:`list` or :class:`touple` or :class:`str`\n            Specified frame (:class:`int`), or frames (:class:`list`), or\n            range (:class:`touple`), or `all`/`everything` (:class:`str`).\n            (default='all')\n\n        override : :class:`bool`\n            If True, an output already storred in :attr:`analysis_output` can\n            be override. (default=False)\n\n        swap_atoms : :class:`dict`, optional\n            If this kwarg is passed with an appropriate dictionary a\n            :func:`pywindow.molecular.MolecularSystem.swap_atom_keys()` will\n            be applied to the extracted frame.\n\n        forcefield : :class:`str`, optional\n            If this kwarg is passed with appropriate forcefield keyword a\n            :func:`pywindow.molecular.MolecularSystem.decipher_atom_keys()`\n            will be applied to the extracted frame.\n\n        modular : :class:`bool`, optional\n            If this kwarg is passed a\n            :func:`pywindow.molecular.MolecularSystem.make_modular()`\n            will be applied to the extracted frame. (default=False)\n\n        rebuild : :class:`bool`, optional\n            If this kwarg is passed a `rebuild=True` is passed to\n            :func:`pywindow.molecular.MolecularSystem.make_modular()` that\n            will be applied to the extracted frame. (default=False)\n\n        ncpus : :class:`int`, optional\n            If ncpus > 1, then the analysis is performed in parallel for the\n            specified number of parallel jobs. Otherwise, it runs in serial.\n            (default=1)\n\n        Returns\n        -------\n        None : :class:`NoneType`\n            The function returns `None`, the analysis output is\n            returned to :attr:`analysis_output` dictionary.\n\n        \"\"\"\n        frames_for_analysis = []\n        # First populate the frames_for_analysis list.\n        if isinstance(frames, int):\n            frames_for_analysis.append(frames)\n        if isinstance(frames, list):\n            for frame in frames:\n                if isinstance(frame, int):\n                    frames_for_analysis.append(frame)\n                else:\n                    raise _FunctionError(\n                        \"The list should be populated with integers only.\"\n                    )\n        if isinstance(frames, tuple):\n            if isinstance(frames[0], int) and isinstance(frames[1], int):\n                for frame in range(frames[0], frames[1]):\n                    frames_for_analysis.append(frame)\n                else:\n                    raise _FunctionError(\n                        \"The tuple should contain only two integers \"\n                        \"for the begining and the end of the frames range.\"\n                    )\n        if isinstance(frames, str):\n            if frames in ['all', 'everything']:\n                for frame in range(0, self.no_of_frames):\n                    frames_for_analysis.append(frame)\n            else:\n                raise _FunctionError(\n                    \"Didn't recognise the keyword. (see manual)\"\n                )\n        # The override keyword by default is False. So we check if any of the\n        # frames were already analysed and if so we delete them from the list.\n        # However, if the override is set to True, then we just proceed.\n        if override is False:\n            frames_for_analysis_new = []\n            for frame in frames_for_analysis:\n                if frame not in self.analysis_output.keys():\n                    frames_for_analysis_new.append(frame)\n            frames_for_analysis = frames_for_analysis_new\n        if ncpus == 1:\n            for frame in frames_for_analysis:\n                analysed_frame = self._analysis_serial(frame, _ncpus, **kwargs)\n                self.analysis_output[frame] = analysed_frame\n        if ncpus > 1:\n            self._analysis_parallel(frames_for_analysis, ncpus, **kwargs)", "response": "This function performs structural analysis on a set of trajectories."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save_analysis(self, filepath=None, **kwargs):\n        # We pass a copy of the analysis attribute dictionary.\n        dict_obj = deepcopy(self.analysis_output)\n        # If no filepath is provided we create one.\n        if filepath is None:\n            filepath = \"_\".join(\n                (str(self.system_id), \"pywindow_analysis\")\n            )\n            filepath = '/'.join((os.getcwd(), filepath))\n        # Dump the dictionary to json file.\n        Output().dump2json(dict_obj, filepath, default=to_list, **kwargs)\n        return", "response": "Save the analysis output to a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef analysis(self, frames='all', ncpus=1, override=False, **kwargs):\n        if override is True:\n            self.analysis_output = {}\n        if isinstance(frames, int):\n            analysed_frame = self._analysis_serial(frames, ncpus, **kwargs)\n            if frames not in self.analysis_output.keys():\n                self.analysis_output[frames] = analysed_frame\n            return analysed_frame\n        else:\n            frames_for_analysis = []\n            if isinstance(frames, list):\n                for frame in frames:\n                    if frame not in self.analysis_output.keys():\n                        frames_for_analysis.append(frame)\n            if isinstance(frames, tuple):\n                for frame in range(frames[0], frames[1]):\n                    if frame not in self.analysis_output.keys():\n                        frames_for_analysis.append(frame)\n            if isinstance(frames, str):\n                if frames in ['all', 'everything']:\n                    for frame in range(0, self.no_of_frames):\n                        if frame not in self.analysis_output.keys():\n                            frames_for_analysis.append(frame)\n            self._analysis_parallel(frames_for_analysis, ncpus, **kwargs)", "response": "This function performs structural analysis on a set of frames and returns the result as a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the filepath as a class attribute", "response": "def _map_trajectory(self):\n        \"\"\" Return filepath as a class attribute\"\"\"\n        self.trajectory_map = {}\n        with open(self.filepath, 'r') as trajectory_file:\n            with closing(\n                    mmap(\n                        trajectory_file.fileno(), 0,\n                        access=ACCESS_READ)) as mapped_file:\n                progress = 0\n                line = 0\n                frame = -1\n                frame_start = 0\n                while progress <= len(mapped_file):\n                    line = line + 1\n                    # We read a binary data from a mapped file.\n                    bline = mapped_file.readline()\n                    # If the bline length equals zero we terminate.\n                    # We reached end of the file but still add the last frame!\n                    if len(bline) == 0:\n                        frame = frame + 1\n                        if progress - frame_start > 10:\n                            self.trajectory_map[frame] = [\n                                frame_start, progress\n                            ]\n                        break\n                    # We need to decode byte line into an utf-8 string.\n                    sline = bline.decode(\"utf-8\").strip('\\n').split()\n                    # We extract map's byte coordinates for each frame\n                    if len(sline) == 1 and sline[0] == 'END':\n                        frame = frame + 1\n                        self.trajectory_map[frame] = [frame_start, progress]\n                        frame_start = progress\n                    # Here we extract the map's byte coordinates for the header\n                    # And also the periodic system type needed for later.\n                    progress = progress + len(bline)\n            self.no_of_frames = frame"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_rdkit_mol(cls, mol, system_name='rdkit', mol_id=0):\n        return cls(Input().load_rdkit_mol(mol), system_name, mol_id)", "response": "Create a Molecule object from a RDKit molecule object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nperforms a full structural analysis of a molecule. This invokes other methods: 1. :attr:`molecular_weight()` 2. :attr:`calculate_centre_of_mass()` 3. :attr:`calculate_maximum_diameter()` 4. :attr:`calculate_average_diameter()` 5. :attr:`calculate_pore_diameter()` 6. :attr:`calculate_pore_volume()` 7. :attr:`calculate_pore_diameter_opt()` 8. :attr:`calculate_pore_volume_opt()` 9. :attr:`calculate_pore_diameter_opt()` 10. :attr:`calculate_windows()` Parameters ---------- ncpus : :class:`int` Number of CPUs used for the parallelised parts of :func:`pywindow.utilities.find_windows()`. (default=1=serial) Returns ------- :attr:`Molecule.properties` The updated :attr:`Molecule.properties` with returns of all used methods.", "response": "def full_analysis(self, ncpus=1, **kwargs):\n        \"\"\"\n        Perform a full structural analysis of a molecule.\n\n        This invokes other methods:\n\n            1. :attr:`molecular_weight()`\n\n            2. :attr:`calculate_centre_of_mass()`\n\n            3. :attr:`calculate_maximum_diameter()`\n\n            4. :attr:`calculate_average_diameter()`\n\n            5. :attr:`calculate_pore_diameter()`\n\n            6. :attr:`calculate_pore_volume()`\n\n            7. :attr:`calculate_pore_diameter_opt()`\n\n            8. :attr:`calculate_pore_volume_opt()`\n\n            9. :attr:`calculate_pore_diameter_opt()`\n\n            10. :attr:`calculate_windows()`\n\n        Parameters\n        ----------\n        ncpus : :class:`int`\n            Number of CPUs used for the parallelised parts of\n            :func:`pywindow.utilities.find_windows()`. (default=1=serial)\n\n        Returns\n        -------\n        :attr:`Molecule.properties`\n            The updated :attr:`Molecule.properties` with returns of all\n            used methods.\n\n        \"\"\"\n        self.molecular_weight()\n        self.calculate_centre_of_mass()\n        self.calculate_maximum_diameter()\n        self.calculate_average_diameter()\n        self.calculate_pore_diameter()\n        self.calculate_pore_volume()\n        self.calculate_pore_diameter_opt(**kwargs)\n        self.calculate_pore_volume_opt(**kwargs)\n        self.calculate_windows(ncpus=ncpus, **kwargs)\n        # self._circumcircle(**kwargs)\n        return self.properties"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef calculate_centre_of_mass(self):\n        self.centre_of_mass = center_of_mass(self.elements, self.coordinates)\n        self.properties['centre_of_mass'] = self.centre_of_mass\n        return self.centre_of_mass", "response": "Calculates the centre of mass of a molecule."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating the maximum diamension of a molecule.", "response": "def calculate_maximum_diameter(self):\n        \"\"\"\n        Return the maximum diamension of a molecule.\n\n        Returns\n        -------\n        :class:`float`\n            The maximum dimension of the molecule.\n\n        \"\"\"\n        self.maxd_atom_1, self.maxd_atom_2, self.maximum_diameter = max_dim(\n            self.elements, self.coordinates)\n        self.properties['maximum_diameter'] = {\n            'diameter': self.maximum_diameter,\n            'atom_1': int(self.maxd_atom_1),\n            'atom_2': int(self.maxd_atom_2),\n        }\n        return self.maximum_diameter"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef calculate_average_diameter(self, **kwargs):\n        self.average_diameter = find_average_diameter(\n            self.elements, self.coordinates, **kwargs)\n        return self.average_diameter", "response": "Calculates the average diamension of a molecule."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the intrinsic pore diameter.", "response": "def calculate_pore_diameter(self):\n        \"\"\"\n        Return the intrinsic pore diameter.\n\n        Returns\n        -------\n        :class:`float`\n            The intrinsic pore diameter.\n\n        \"\"\"\n        self.pore_diameter, self.pore_closest_atom = pore_diameter(\n            self.elements, self.coordinates)\n        self.properties['pore_diameter'] = {\n            'diameter': self.pore_diameter,\n            'atom': int(self.pore_closest_atom),\n        }\n        return self.pore_diameter"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncalculate the intrinsic pore volume.", "response": "def calculate_pore_volume(self):\n        \"\"\"\n        Return the intrinsic pore volume.\n\n        Returns\n        -------\n        :class:`float`\n            The intrinsic pore volume.\n\n        \"\"\"\n        self.pore_volume = sphere_volume(self.calculate_pore_diameter() / 2)\n        self.properties['pore_volume'] = self.pore_volume\n        return self.pore_volume"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef calculate_pore_diameter_opt(self, **kwargs):\n        (self.pore_diameter_opt, self.pore_opt_closest_atom,\n         self.pore_opt_COM) = opt_pore_diameter(self.elements,\n                                                self.coordinates, **kwargs)\n        self.properties['pore_diameter_opt'] = {\n            'diameter': self.pore_diameter_opt,\n            'atom_1': int(self.pore_opt_closest_atom),\n            'centre_of_mass': self.pore_opt_COM,\n        }\n        return self.pore_diameter_opt", "response": "Calculates the intrinsic pore diameter for the optimised pore centre."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating the intrinsic pore volume for optimised centre.", "response": "def calculate_pore_volume_opt(self, **kwargs):\n        \"\"\"\n        Return the intrinsic pore volume (for the optimised pore centre).\n\n        Similarly to :func:`calculate_pore_volume` this method returns the\n        the volume intrinsic pore diameter, however, for the\n        :func:`calculate_pore_diameter_opt` returned value.\n\n        Returns\n        -------\n        :class:`float`\n            The intrinsic pore volume.\n\n        \"\"\"\n        self.pore_volume_opt = sphere_volume(\n            self.calculate_pore_diameter_opt(**kwargs) / 2)\n        self.properties['pore_volume_opt'] = self.pore_volume_opt\n        return self.pore_volume_opt"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef calculate_windows(self, **kwargs):\n        windows = find_windows(self.elements, self.coordinates, **kwargs)\n        if windows:\n            self.properties.update(\n                {\n                    'windows': {\n                        'diameters': windows[0], 'centre_of_mass': windows[1],\n                    }\n                }\n            )\n            return windows[0]\n        else:\n            self.properties.update(\n                {'windows': {'diameters': None,  'centre_of_mass': None, }}\n            )\n        return None", "response": "Calculates the diameters of all windows in a molecule."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef shift_to_origin(self, **kwargs):\n        self.coordinates = shift_com(self.elements, self.coordinates, **kwargs)\n        self._update()", "response": "Shifts a molecule to Origin."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dump_properties_json(self, filepath=None, molecular=False, **kwargs):\n        # We pass a copy of the properties dictionary.\n        dict_obj = deepcopy(self.properties)\n        # If molecular data is also required we update the dictionary.\n        if molecular is True:\n            dict_obj.update(self.mol)\n        # If no filepath is provided we create one.\n        if filepath is None:\n            filepath = \"_\".join(\n                (str(self.parent_system), str(self.molecule_id))\n            )\n            filepath = '/'.join((os.getcwd(), filepath))\n        # Dump the dictionary to json file.\n        self._Output.dump2json(dict_obj, filepath, default=to_list, **kwargs)", "response": "Dump the content of the molecule. properties to a JSON dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndumps a molecule to a file.", "response": "def dump_molecule(self, filepath=None, include_coms=False, **kwargs):\n        \"\"\"\n        Dump a :class:`Molecule` to a file (PDB or XYZ).\n\n        Kwargs are passed to :func:`pywindow.io_tools.Output.dump2file()`.\n\n        For validation purposes an overlay of window centres and COMs can also\n        be dumped as:\n\n        He - for the centre of mass\n\n        Ne - for the centre of the optimised cavity\n\n        Ar - for the centres of each found window\n\n        Parameters\n        ----------\n        filepath : :class:`str`\n           The filepath for the dumped file. If :class:`None`, the file is\n           dumped localy with :attr:`molecule_id` as filename.\n           (defualt=None)\n\n        include_coms : :class:`bool`\n            If True, dump also with an overlay of window centres and COMs.\n            (default=False)\n\n        Returns\n        -------\n        None : :class:`NoneType`\n\n        \"\"\"\n        # If no filepath is provided we create one.\n        if filepath is None:\n            filepath = \"_\".join(\n                (str(self.parent_system), str(self.molecule_id)))\n            filepath = '/'.join((os.getcwd(), filepath))\n            filepath = '.'.join((filepath, 'pdb'))\n        # Check if there is an 'atom_ids' keyword in the self.mol dict.\n        # Otherwise pass to the dump2file atom_ids='elements'.\n        if 'atom_ids' not in self.mol.keys():\n            atom_ids = 'elements'\n        else:\n            atom_ids = 'atom_ids'\n        # Dump molecule into a file.\n        # If coms are to be included additional steps are required.\n        # First deepcopy the molecule\n        if include_coms is True:\n            mmol = deepcopy(self.mol)\n            # add centre of mass (centre of not optimised pore) as 'He'.\n            mmol['elements'] = np.concatenate(\n                (mmol['elements'], np.array(['He'])))\n            if 'atom_ids' not in self.mol.keys():\n                pass\n            else:\n                mmol['atom_ids'] = np.concatenate(\n                    (mmol['atom_ids'], np.array(['He'])))\n            mmol['coordinates'] = np.concatenate(\n                (mmol['coordinates'],\n                 np.array([self.properties['centre_of_mass']])))\n            # add centre of pore optimised as 'Ne'.\n            mmol['elements'] = np.concatenate(\n                (mmol['elements'], np.array(['Ne'])))\n            if 'atom_ids' not in self.mol.keys():\n                pass\n            else:\n                mmol['atom_ids'] = np.concatenate(\n                    (mmol['atom_ids'], np.array(['Ne'])))\n            mmol['coordinates'] = np.concatenate(\n                (mmol['coordinates'], np.array(\n                    [self.properties['pore_diameter_opt']['centre_of_mass']])))\n            # add centre of windows as 'Ar'.\n            if self.properties['windows']['centre_of_mass'] is not None:\n                range_ = range(\n                    len(self.properties['windows']['centre_of_mass']))\n                for com in range_:\n                    mmol['elements'] = np.concatenate(\n                        (mmol['elements'], np.array(['Ar'])))\n                    if 'atom_ids' not in self.mol.keys():\n                        pass\n                    else:\n                        mmol['atom_ids'] = np.concatenate(\n                            (mmol['atom_ids'],\n                             np.array(['Ar{0}'.format(com + 1)])))\n                    mmol['coordinates'] = np.concatenate(\n                        (mmol['coordinates'], np.array([\n                            self.properties['windows']['centre_of_mass'][com]\n                        ])))\n            self._Output.dump2file(mmol, filepath, atom_ids=atom_ids, **kwargs)\n\n        else:\n            self._Output.dump2file(\n                self.mol, filepath, atom_ids=atom_ids, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading a MolecularSystem from an input file.", "response": "def load_file(cls, filepath):\n        \"\"\"\n        Create a :class:`MolecularSystem` from an input file.\n\n        Recognized input file formats: XYZ, PDB and MOL (V3000).\n\n        Parameters\n        ----------\n        filepath : :class:`str`\n           The input's filepath.\n\n        Returns\n        -------\n        :class:`pywindow.molecular.MolecularSystem`\n            :class:`MolecularSystem`\n\n        \"\"\"\n        obj = cls()\n        obj.system = obj._Input.load_file(filepath)\n        obj.filename = os.path.basename(filepath)\n        obj.system_id = obj.filename.split(\".\")[0]\n        obj.name, ext = os.path.splitext(obj.filename)\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading a MolecularSystem from a RDKit molecule object.", "response": "def load_rdkit_mol(cls, mol):\n        \"\"\"\n        Create a :class:`MolecularSystem` from :class:`rdkit.Chem.rdchem.Mol`.\n\n        Parameters\n        ----------\n        mol : :class:`rdkit.Chem.rdchem.Mol`\n           An RDKit molecule object.\n\n        Returns\n        -------\n        :class:`pywindow.molecular.MolecularSystem`\n            :class:`MolecularSystem`\n\n        \"\"\"\n        obj = cls()\n        obj.system = obj._Input.load_rdkit_mol(mol)\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_system(cls, dict_, system_id='system'):\n        obj = cls()\n        obj.system = dict_\n        obj.system_id = system_id\n        return obj", "response": "Load a MolecularSystem from a python dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rebuild_system(self, override=False, **kwargs):\n        # First we create a 3x3x3 supercell with the initial unit cell in the\n        # centre and the 26 unit cell translations around to provide all the\n        # atom positions necessary for the molecules passing through periodic\n        # boundary reconstruction step.\n        supercell_333 = create_supercell(self.system, **kwargs)\n        # smolsys = self.load_system(supercell_333, self.system_id + '_311')\n        # smolsys.dump_system(override=True)\n        discrete = discrete_molecules(self.system, rebuild=supercell_333)\n        # This function overrides the initial data for 'coordinates',\n        # 'atom_ids', and 'elements' instances in the 'system' dictionary.\n        coordinates = np.array([], dtype=np.float64).reshape(0, 3)\n        atom_ids = np.array([])\n        elements = np.array([])\n        for i in discrete:\n            coordinates = np.concatenate(\n                [coordinates, i['coordinates']], axis=0\n                )\n            atom_ids = np.concatenate([atom_ids, i['atom_ids']], axis=0)\n            elements = np.concatenate([elements, i['elements']], axis=0)\n        rebuild_system = {\n            'coordinates': coordinates,\n            'atom_ids': atom_ids,\n            'elements': elements\n            }\n        if override is True:\n            self.system.update(rebuild_system)\n            return None\n        else:\n            return self.load_system(rebuild_system)", "response": "Rebuilds the molecular system and returns a new MolecularSystem object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef swap_atom_keys(self, swap_dict, dict_key='atom_ids'):\n        # Similar situation to the one from decipher_atom_keys function.\n        if 'atom_ids' not in self.system.keys():\n            dict_key = 'elements'\n        for atom_key in range(len(self.system[dict_key])):\n            for key in swap_dict.keys():\n                if self.system[dict_key][atom_key] == key:\n                    self.system[dict_key][atom_key] = swap_dict[key]", "response": "This function deciphers a user - defined value for atom ids for another user - defined value. This function is used to decipher all atom ids for another user - defined value for a particular atom id."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndecipher atom ids for the Molecular System.", "response": "def decipher_atom_keys(self, forcefield='DLF', dict_key='atom_ids'):\n        \"\"\"\n        Decipher force field atom ids.\n\n        This takes all values in :attr:`MolecularSystem.system['atom_ids']`\n        that match force field type criteria and creates\n        :attr:`MolecularSystem.system['elements']` with the corresponding\n        periodic table of elements equivalents.\n\n        If a forcefield is not supported by this method, the\n        :func:`MolecularSystem.swap_atom_keys()` can be used instead.\n\n        DLF stands for DL_F notation.\n\n        See: C. W. Yong, Descriptions and Implementations of DL_F Notation: A\n        Natural Chemical Expression System of Atom Types for Molecular\n        Simulations, J. Chem. Inf. Model., 2016, 56, 1405\u20131409.\n\n        Parameters\n        ----------\n        forcefield : :class:`str`\n            The forcefield used to decipher atom ids. Allowed (not case\n            sensitive): 'OPLS', 'OPLS2005', 'OPLSAA', 'OPLS3', 'DLF', 'DL_F'.\n            (default='DLF')\n\n        dict_key : :class:`str`\n            The :attr:`MolecularSystem.system` dictionary key to the array\n            containing the force field atom ids. (default='atom_ids')\n\n        Returns\n        -------\n        None : :class:`NoneType`\n\n        \"\"\"\n        # In case there is no 'atom_ids' key we try 'elements'. This is for\n        # XYZ and MOL files mostly. But, we keep the dict_key keyword for\n        # someone who would want to decipher 'elements' even if 'atom_ids' key\n        # is present in the system's dictionary.\n        if 'atom_ids' not in self.system.keys():\n            dict_key = 'elements'\n        # I do it on temporary object so that it only finishes when successful\n        temp = deepcopy(self.system[dict_key])\n        for element in range(len(temp)):\n            temp[element] = \"{0}\".format(\n                decipher_atom_key(\n                    temp[element], forcefield=forcefield))\n        self.system['elements'] = temp"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds and return all Molecules in the MolecularSystem.", "response": "def make_modular(self, rebuild=False):\n        \"\"\"\n        Find and return all :class:`Molecule` s in :class:`MolecularSystem`.\n\n        This function populates :attr:`MolecularSystem.molecules` with\n        :class:`Molecule` s.\n\n        Parameters\n        ----------\n        rebuild : :class:`bool`\n            If True, run first the :func:`rebuild_system()`. (default=False)\n\n        Returns\n        -------\n        None : :class:`NoneType`\n\n        \"\"\"\n        if rebuild is True:\n            supercell_333 = create_supercell(self.system)\n        else:\n            supercell_333 = None\n        dis = discrete_molecules(self.system, rebuild=supercell_333)\n        self.no_of_discrete_molecules = len(dis)\n        self.molecules = {}\n        for i in range(len(dis)):\n            self.molecules[i] = Molecule(dis[i], self.system_id, i)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_pores(self, sampling_points):\n        pores = []\n        for point in sampling_points:\n            pores.append(\n                Pore(\n                    self.system['elements'],\n                    self.system['coordinates'],\n                    com=point))\n        return pores", "response": "Under development. Returns a list of pores."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dump_system(self, filepath=None, modular=False, **kwargs):\n        # If no filepath is provided we create one.\n        if filepath is None:\n            filepath = '/'.join((os.getcwd(), str(self.system_id)))\n            filepath = '.'.join((filepath, 'pdb'))\n        # If modular is True substitute the molecular data for modular one.\n        system_dict = deepcopy(self.system)\n        if modular is True:\n            elements = np.array([])\n            atom_ids = np.array([])\n            coor = np.array([]).reshape(0, 3)\n            for mol_ in self.molecules:\n                mol = self.molecules[mol_]\n                elements = np.concatenate((elements, mol.mol['elements']))\n                atom_ids = np.concatenate((atom_ids, mol.mol['atom_ids']))\n                coor = np.concatenate((coor, mol.mol['coordinates']), axis=0)\n            system_dict['elements'] = elements\n            system_dict['atom_ids'] = atom_ids\n            system_dict['coordinates'] = coor\n        # Check if there is an 'atom_ids' keyword in the self.mol dict.\n        # Otherwise pass to the dump2file atom_ids='elements'.\n        # This is mostly for XYZ files and not deciphered trajectories.\n        if 'atom_ids' not in system_dict.keys():\n            atom_ids = 'elements'\n        else:\n            atom_ids = 'atom_ids'\n        # Dump system into a file.\n        self._Output.dump2file(\n            system_dict, filepath, atom_ids=atom_ids, **kwargs)", "response": "Dump a MolecularSystem to a file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndumping a MolecularSystem to a JSON file.", "response": "def dump_system_json(self, filepath=None, modular=False, **kwargs):\n        \"\"\"\n        Dump a :class:`MolecularSystem` to a JSON dictionary.\n\n        The dumped JSON dictionary, with :class:`MolecularSystem`, can then be\n        loaded through a JSON loader and then through :func:`load_system()`\n        to retrieve a :class:`MolecularSystem`.\n\n        Kwargs are passed to :func:`pywindow.io_tools.Output.dump2json()`.\n\n        Parameters\n        ----------\n        filepath : :class:`str`\n           The filepath for the dumped file. If :class:`None`, the file is\n           dumped localy with :attr:`system_id` as filename.\n           (defualt=None)\n\n        modular : :class:`bool`\n            If False, dump the :class:`MolecularSystem` as in\n            :attr:`MolecularSystem.system`, if True, dump the\n            :class:`MolecularSystem` as catenated :class:Molecule objects\n            from :attr:`MolecularSystem.molecules`\n\n        Returns\n        -------\n        None : :class:`NoneType`\n\n        \"\"\"\n        # We pass a copy of the properties dictionary.\n        dict_obj = deepcopy(self.system)\n        # In case we want a modular system.\n        if modular is True:\n            try:\n                if self.molecules:\n                    pass\n            except AttributeError:\n                raise _NotAModularSystem(\n                    \"This system is not modular. Please, run first the \"\n                    \"make_modular() function of this class.\")\n            dict_obj = {}\n            for molecule in self.molecules:\n                mol_ = self.molecules[molecule]\n                dict_obj[molecule] = mol_.mol\n        # If no filepath is provided we create one.\n        if filepath is None:\n            filepath = '/'.join((os.getcwd(), str(self.system_id)))\n        # Dump the dictionary to json file.\n        self._Output.dump2json(dict_obj, filepath, default=to_list, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_attrname_by_colname(instance, name):\n    for attr, column in list(sqlalchemy.inspect(instance.__class__).c.items()):\n        if column.name == name:\n            return attr", "response": "Get value from SQLAlchemy model instance by column name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_empty_instance(table):\n    instance_defaults_params = inspect.getargspec(table.__init__).args[1:]\n    # list like ['name', 'group', 'visible'] to dict with empty\n    # value as {'name': None, 'group': None, 'visible': None}\n    init = dict(\n        list(zip(instance_defaults_params, itertools.repeat(None)))\n    )\n    return table(**init)", "response": "Return an empty instance of model.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_pk(obj):\n    if inspect.isclass(obj):\n        pk_list = sqlalchemy.inspect(obj).primary_key\n    else:\n        pk_list = obj.__mapper__.primary_key\n    return pk_list", "response": "Return primary key name by model class or instance."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_rule(self, **args):\n        #The defaults are indicated below\n        myrule = {\n                  \"source\": \"\",\n                  \"dest\": \"\",\n                  \"messagetype\": \"request\",\n                  \"headerpattern\": \"*\",\n                  \"bodypattern\": \"*\",\n                  \"delayprobability\": 0.0,\n                  \"delaydistribution\": \"uniform\",\n                  \"mangleprobability\": 0.0,\n                  \"mangledistribution\": \"uniform\",\n                  \"abortprobability\": 0.0,\n                  \"abortdistribution\": \"uniform\",\n                  \"delaytime\": \"0s\",\n                  \"errorcode\": -1,\n                  \"searchstring\": \"\",\n                  \"replacestring\": \"\"\n        }\n        rule = args.copy()\n        #copy\n        for i in rule.keys():\n            if i not in myrule:\n                continue\n            myrule[i] = rule[i]\n        #check defaults\n        services = self.app.get_services()\n        assert myrule[\"source\"] != \"\" and myrule[\"dest\"] != \"\"\n        assert myrule[\"source\"] in services and myrule[\"dest\"] in services\n        assert myrule['headerpattern'] != \"\" or myrule[\"bodypattern\"] != \"\"\n        assert myrule['delayprobability'] >0.0 or myrule['abortprobability'] >0.0 or myrule['mangleprobability'] >0.0\n        if myrule[\"delayprobability\"] > 0.0:\n            assert myrule[\"delaytime\"] != \"\"\n        if myrule[\"abortprobability\"] > 0.0:\n            assert myrule[\"errorcode\"] >= -1\n        assert myrule[\"messagetype\"] in [\"request\", \"response\", \"publish\", \"subscribe\"]\n        self._queue.append(myrule)", "response": "Adds a new rule to the current instance of the class."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nclears fault injection rules from all known service proxies.", "response": "def clear_rules_from_all_proxies(self):\n        \"\"\"\n            Clear fault injection rules from all known service proxies.\n        \"\"\"\n        self._queue = []        \n        if self.debug:\n            print 'Clearing rules'\n        for service in self.app.get_services():\n            for instance in self.app.get_service_instances(service):\n                if self.debug:\n                    print 'Clearing rules for %s - instance %s' % (service, instance)\n                resp = requests.delete(\"http://{}/gremlin/v1/rules\".format(instance))\n                if resp.status_code != 200:\n                    print 'Failed to clear rules for %s - instance %s' % (service, instance)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_rules(self, service=None):\n        rules = {}\n        for service in self.app.get_services():\n            rules[service] = {}\n            for instance in self.app.get_service_instances(service):\n                rules[service][instance] = {}\n                resp = requests.get(\"http://{}/gremlin/v1/rules/list\".format(instance))\n                if resp.status_code != 200:\n                    print 'Failed to fetch rules from %s - instance %s' % (service, instance)\n                    continue\n                rules[service][instance] = resp.json()\n                return rules", "response": "List fault injection rules installed on instances of a given service"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npartition two connected services.", "response": "def partition_services(self, **args):\n        \"\"\"Partitions two connected services. Not two sets of services (TODO)\n        Expects usual arguments and srcprobability and dstprobability, that indicates probability of \n        terminating connections from source to dest and vice versa\n        \"\"\"\n        rule = args.copy()\n        assert 'source' in rule and 'dest' in rule\n        #assert 'srcprobability' in rule and 'dstprobability' in rule\n        assert rule['source'] != \"\" and rule['dest'] != \"\"\n        #check if the two services are connected\n        assert rule['dest'] in self.app.get_dependencies(rule['source'])\n\n        rule['errorcode'] = rule.pop('errorcode', -1) or -1\n        rule['abortprobability'] = rule.pop('srcprobability', 1) or 1\n        self.abort_requests(**rule)\n\n        rule['abortprobability'] = rule.pop('dstprobability', 1) or 1\n        temp = rule['source']\n        rule['source'] = rule['dest']\n        rule['dest'] = temp\n        self.abort_requests(**rule)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a given failure scenario", "response": "def setup_failure(self, scenario=None, **args):\n        \"\"\"Add a given failure scenario\n        @param scenario: string 'delayrequests' or 'crash'\n        \"\"\"\n        assert scenario is not None and scenario in self.functiondict\n        self.functiondict[scenario](**args)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding gremlins to environment", "response": "def setup_failures(self, gremlins):\n        \"\"\"Add gremlins to environment\"\"\"\n\n        assert isinstance(gremlins, dict) and 'gremlins' in gremlins\n        for gremlin in gremlins['gremlins']:\n            self.setup_failure(**gremlin)\n        self.push_rules()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nformats instance to dump", "response": "def format(self, vertices):\n        \"\"\"Format instance to dump\n        vertices is dict of name to Vertex\n        \"\"\"\n        index = ' '.join(str(vertices[vn].index) for vn in self.vnames)\n        com = ' '.join(self.vnames)  # for comment\n        return '({0:s})  // {1:s} ({2:s})'.format(index, self.name, com)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nformat instance to dump", "response": "def format(self, vertices):\n        \"\"\"Format instance to dump\n        vertices is dict of name to Vertex\n        \"\"\"\n        index = ' '.join(str(vertices[vn].index) for vn in self.vnames)\n        vcom = ' '.join(self.vnames)  # for comment\n        return 'hex ({0:s}) {2:s} ({1[0]:d} {1[1]:d} {1[2]:d}) '\\\n               '{4:s}  // {2:s} ({3:s})'.format(\n                    index, self.cells, self.name, vcom, self.grading.format())"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate object containing the face of the object.", "response": "def face(self, index, name=None):\n        \"\"\"Generate Face object\n        index is number or keyword to identify the face of Hex\n            0 = 'w' = 'xm' = '-100' = (0 4 7 3)\n            1 = 'e' = 'xp' = '100' = (1 2 5 6)\n            2 = 's' = 'ym' = '0-10' = (0 1 5 4)\n            3 = 'n' = 'yp' = '010' = (2 3 7 6)\n            4 = 'b' = 'zm' = '00-1' = (0 3 2 1)\n            5 = 't' = zp' = '001' = (4 5 6 7)\n        name is given to Face instance. If omitted, name is automatically\n            genaratied like ('f-' + self.name + '-w')\n        \"\"\"\n        kw_to_index = {\n            'w': 0, 'xm': 0, '-100': 0,\n            'e': 1, 'xp': 1, '100': 1,\n            's': 2, 'ym': 2, '0-10': 2,\n            'n': 3, 'yp': 3, '010': 3,\n            'b': 4, 'zm': 4, '00-1': 4,\n            't': 5, 'zp': 5, '001': 5}\n        index_to_vertex = [\n            (0, 4, 7, 3),\n            (1, 2, 6, 5),\n            (0, 1, 5, 4),\n            (2, 3, 7, 6),\n            (0, 3, 2, 1),\n            (4, 5, 6, 7)]\n        index_to_defaultsuffix = [\n            'f-{}-w',\n            'f-{}-n',\n            'f-{}-s',\n            'f-{}-n',\n            'f-{}-b',\n            'f-{}-t']\n\n        if isinstance(index, string_types):\n            index = kw_to_index[index]\n\n        vnames = tuple([self.vnames[i] for i in index_to_vertex[index]])\n        if name is None:\n            name = index_to_defaultsuffix[index].format(self.name)\n        return Face(vnames, name)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef format(self, vertices):\n        index = ' '.join(str(vertices[vn].index) for vn in self.vnames)\n        vcom = ' '.join(self.vnames)  # for comment\n        return 'arc {0:s} ({1.x:18.15g} {1.y:18.15g} {1.z:18.15g}) '\\\n                '// {2:s} ({3:s})'.format(\n                        index, self.interVertex, self.name, vcom)", "response": "Format instance to dump\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nformats instance to dump", "response": "def format(self, vertices):\n        \"\"\"Format instance to dump\n        vertices is dict of name to Vertex\n        \"\"\"\n        index = ' '.join(str(vertices[vn].index) for vn in self.vnames)\n        vcom = ' '.join(self.vnames)  # for comment\n        buf = io.StringIO()\n\n        buf.write('spline {0:s}                      '\\\n                '// {1:s} ({2:s})'.format(\n                        index,self.name, vcom))\n        buf.write('\\n     (\\n')\n        for p in self.points:\n            buf.write('         '+p.format()+'\\n')\n        buf.write('\\n     )\\n')\n        buf.write('')\n        return buf.getvalue()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nformat instance to dump", "response": "def format(self, vertices):\n        \"\"\"Format instance to dump\n        vertices is dict of name to Vertex\n        \"\"\"\n        buf = io.StringIO()\n\n        buf.write(self.name + '\\n')\n        buf.write('{\\n')\n        buf.write('    type {};\\n'.format(self.type_))\n        buf.write('    faces\\n')\n        buf.write('    (\\n')\n        for f in self.faces:\n            s = f.format(vertices)\n            buf.write('        {}\\n'.format(s))\n        buf.write('    );\\n')\n        buf.write('}')\n        return buf.getvalue()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a vertex by coordinate and uniq name", "response": "def add_vertex(self, x, y, z, name):\n        \"\"\"add vertex by coordinate and uniq name\n        x y z is coordinates of vertex\n        name is uniq name to refer the vertex\n        returns Vertex object whici is added.\n        \"\"\"\n        self.vertices[name] = Vertex(x, y, z, name)\n        return self.vertices[name]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reduce_vertex(self, name1, *names):\n        v = self.vertices[name1]\n        for n in names:\n            w = self.vertices[n]\n            v.alias.update(w.alias)\n            # replace mapping from n w by to v\n            self.vertices[n] = v", "response": "reduce the key name1 to name2 and name3 to the key name2 name3..."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef merge_vertices(self):\n\n        # groupby expects sorted data\n        sorted_vertices = sorted(list(self.vertices.items()), key=lambda v: hash(v[1]))\n        groups = []\n        for k, g in groupby(sorted_vertices, lambda v: hash(v[1])):\n            groups.append(list(g))\n        for group in groups:\n            if len(group) == 1:\n                continue\n            names = [v[0] for v in group]\n            self.reduce_vertex(*names)", "response": "call reduce_vertex on all vertices with identical values."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef assign_vertexid(self):\n\n        # gather 'uniq' names which are refferred by blocks\n        validvnames = set()\n        self.valid_vertices = []\n        for b in self.blocks.values():\n            for n in b.vnames:\n                v = self.vertices[n]\n                if v.name not in validvnames:\n                    validvnames.update([v.name])\n                    self.valid_vertices.append(v)\n\n        self.valid_vertices = sorted(self.valid_vertices)\n        for i, v in enumerate(self.valid_vertices):\n            v.index = i", "response": "assigns unique id for each vertex in the list of vertices that are not already in the list"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef format_vertices_section(self):\n        buf = io.StringIO()\n        buf.write('vertices\\n')\n        buf.write('(\\n')\n        for v in self.valid_vertices:\n            buf.write('    ' + v.format() + '\\n')\n        buf.write(');')\n        return buf.getvalue()", "response": "format the vertices section."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nformats the blocks section.", "response": "def format_blocks_section(self):\n        \"\"\"format blocks section.\n        assign_vertexid() should be called before this method, because\n        vertices reffered by blocks should have valid index.\n        \"\"\"\n        buf = io.StringIO()\n        buf.write('blocks\\n')\n        buf.write('(\\n')\n        for b in self.blocks.values():\n            buf.write('    ' + b.format(self.vertices) + '\\n')\n        buf.write(');')\n        return buf.getvalue()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nformats edges section. assign_vertexid() should be called before this method, because vertices reffered by blocks should have valid index.", "response": "def format_edges_section(self):\n        \"\"\"format edges section.\n        assign_vertexid() should be called before this method, because\n        vertices reffered by blocks should have valid index.\n        \"\"\"\n        buf = io.StringIO()\n        buf.write('edges\\n')\n        buf.write('(\\n')\n        for e in self.edges.values():\n            buf.write('  ' + e.format(self.vertices) + '\\n')\n        buf.write(');')\n        return buf.getvalue()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nformatting boundary section. assign_vertexid() should be called before this method, because vertices reffered by faces should have valid index.", "response": "def format_boundary_section(self):\n        \"\"\"format boundary section.\n        assign_vertexid() should be called before this method, because\n        vertices reffered by faces should have valid index.\n        \"\"\"\n        buf = io.StringIO()\n        buf.write('boundary\\n')\n        buf.write('(\\n')\n        for b in self.boundaries.values():\n            # format Boundary instance and add indent\n            indent = ' ' * 4\n            s = b.format(self.vertices).replace('\\n', '\\n'+indent)\n            buf.write(indent + s + '\\n')\n        buf.write(');')\n        return buf.getvalue()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nunpacks the tar or zip file at the specified path to the specified directory to_path.", "response": "def extract(path, to_path='', ext='', **kwargs):\n    \"\"\"\n    Unpack the tar or zip file at the specified path to the directory\n    specified by to_path.\n    \"\"\"\n    Archive(path, ext=ext).extract(to_path, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the proper Archive implementation class based on the file type.", "response": "def _archive_cls(file, ext=''):\n        \"\"\"\n        Return the proper Archive implementation class, based on the file type.\n        \"\"\"\n        cls = None\n        filename = None\n        if is_string(file):\n            filename = file\n        else:\n            try:\n                filename = file.name\n            except AttributeError:\n                raise UnrecognizedArchiveFormat(\n                    \"File object not a recognized archive format.\")\n        lookup_filename = filename + ext\n        base, tail_ext = os.path.splitext(lookup_filename.lower())\n        cls = extension_map.get(tail_ext)\n        if not cls:\n            base, ext = os.path.splitext(base)\n            cls = extension_map.get(ext)\n        if not cls:\n            raise UnrecognizedArchiveFormat(\n                \"Path not a recognized archive format: %s\" % filename)\n        return cls"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking that all of the files contained in the archive are within the target directory.", "response": "def check_files(self, to_path=None):\n        \"\"\"\n        Check that all of the files contained in the archive are within the\n        target directory.\n        \"\"\"\n        if to_path:\n            target_path = os.path.normpath(os.path.realpath(to_path))\n        else:\n            target_path = os.getcwd()\n        for filename in self.filenames():\n            extract_path = os.path.join(target_path, filename)\n            extract_path = os.path.normpath(os.path.realpath(extract_path))\n            if not extract_path.startswith(target_path):\n                raise UnsafeArchive(\n                    \"Archive member destination is outside the target\"\n                    \" directory.  member: %s\" % filename)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef meanstack(infn: Path, Navg: int, ut1: Optional[datetime]=None,\n              method: str='mean') -> Tuple[np.ndarray, Optional[datetime]]:\n\n    infn = Path(infn).expanduser()\n# %% parse indicies to load\n    if isinstance(Navg, slice):\n        key = Navg\n    elif isinstance(Navg, int):\n        key = slice(0, Navg)\n    elif len(Navg) == 1:\n        key = slice(0, Navg[0])\n    elif len(Navg) == 2:\n        key = slice(Navg[0], Navg[1])\n    else:\n        raise ValueError(f'not sure what you mean by Navg={Navg}')\n# %% load images\n    \"\"\"\n    some methods handled individually to improve efficiency with huge files\n    \"\"\"\n    if infn.suffix == '.h5':\n        img, ut1 = _h5mean(infn, ut1, key, method)\n    elif infn.suffix == '.fits':\n        with fits.open(infn, mode='readonly', memmap=False) as f:  # mmap doesn't work with BZERO/BSCALE/BLANK\n            img = collapsestack(f[0].data, key, method)\n    elif infn.suffix == '.mat':\n        img = loadmat(infn)\n        img = collapsestack(img['data'].T, key, method)  # matlab is fortran order\n    else:  # .tif etc.\n        img = imageio.imread(infn, as_gray=True)\n        if img.ndim in (3, 4) and img.shape[-1] == 3:  # assume RGB\n            img = collapsestack(img, key, method)\n\n    return img, ut1", "response": "This function takes a file name and returns the meanstack image and ut1."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns the specified request at the specified object_name and generates an object of the specified class.", "response": "def _run_search_request(\n            self, protocol_request, object_name, protocol_response_class):\n        \"\"\"\n        Runs the specified request at the specified object_name and\n        instantiates an object of the specified class. We yield each object in\n        listAttr.  If pages of results are present, repeat this process\n        until the pageToken is null.\n        \"\"\"\n        not_done = True\n        while not_done:\n            response_object = self._run_search_page_request(\n                protocol_request, object_name, protocol_response_class)\n            value_list = getattr(\n                response_object,\n                protocol.getValueListName(protocol_response_class))\n            for extract in value_list:\n                yield extract\n            not_done = bool(response_object.next_page_token)\n            protocol_request.page_token = response_object.next_page_token"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning an iterator over the bases of the specified reference.", "response": "def list_reference_bases(self, id_, start=0, end=None):\n        \"\"\"\n        Returns an iterator over the bases from the server in the form\n        of consecutive strings. This command does not conform to the\n        patterns of the other search and get requests, and is implemented\n        differently.\n        \"\"\"\n        request = protocol.ListReferenceBasesRequest()\n        request.start = pb.int(start)\n        request.end = pb.int(end)\n        request.reference_id = id_\n        not_done = True\n        # TODO We should probably use a StringIO here to make string buffering\n        # a bit more efficient.\n        bases_list = []\n        while not_done:\n            response = self._run_list_reference_bases_page_request(request)\n            bases_list.append(response.sequence)\n            not_done = bool(response.next_page_token)\n            request.page_token = response.next_page_token\n        return \"\".join(bases_list)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef search_variants(\n            self, variant_set_id, start=None, end=None, reference_name=None,\n            call_set_ids=None):\n        \"\"\"\n        Returns an iterator over the Variants fulfilling the specified\n        conditions from the specified VariantSet.\n\n        :param str variant_set_id: The ID of the\n            :class:`ga4gh.protocol.VariantSet` of interest.\n        :param int start: Required. The beginning of the window (0-based,\n            inclusive) for which overlapping variants should be returned.\n            Genomic positions are non-negative integers less than reference\n            length. Requests spanning the join of circular genomes are\n            represented as two requests one on each side of the join\n            (position 0).\n        :param int end: Required. The end of the window (0-based, exclusive)\n            for which overlapping variants should be returned.\n        :param str reference_name: The name of the\n            :class:`ga4gh.protocol.Reference` we wish to return variants from.\n        :param list call_set_ids: Only return variant calls which belong to\n            call sets with these IDs. If an empty array, returns variants\n            without any call objects. If null, returns all variant calls.\n\n        :return: An iterator over the :class:`ga4gh.protocol.Variant` objects\n            defined by the query parameters.\n        :rtype: iter\n        \"\"\"\n        request = protocol.SearchVariantsRequest()\n        request.reference_name = pb.string(reference_name)\n        request.start = pb.int(start)\n        request.end = pb.int(end)\n        request.variant_set_id = variant_set_id\n        request.call_set_ids.extend(pb.string(call_set_ids))\n        request.page_size = pb.int(self._page_size)\n        return self._run_search_request(\n            request, \"variants\", protocol.SearchVariantsResponse)", "response": "Returns an iterator over the variants fulfilling the specified conditions from the specified VariantSet."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning an iterator over the Variant Annotations fulfilling the specified conditions from the specified VariantSet.", "response": "def search_variant_annotations(\n            self, variant_annotation_set_id, reference_name=\"\",\n            reference_id=\"\", start=0, end=0, effects=[]):\n        \"\"\"\n        Returns an iterator over the Variant Annotations fulfilling\n        the specified conditions from the specified VariantSet.\n\n        :param str variant_annotation_set_id: The ID of the\n            :class:`ga4gh.protocol.VariantAnnotationSet` of interest.\n        :param int start: Required. The beginning of the window (0-based,\n            inclusive) for which overlapping variants should be returned.\n            Genomic positions are non-negative integers less than reference\n            length. Requests spanning the join of circular genomes are\n            represented as two requests one on each side of the join\n            (position 0).\n        :param int end: Required. The end of the window (0-based, exclusive)\n            for which overlapping variants should be returned.\n        :param str reference_name: The name of the\n            :class:`ga4gh.protocol.Reference` we wish to return variants from.\n\n        :return: An iterator over the\n            :class:`ga4gh.protocol.VariantAnnotation` objects\n            defined by the query parameters.\n        :rtype: iter\n        \"\"\"\n        request = protocol.SearchVariantAnnotationsRequest()\n        request.variant_annotation_set_id = variant_annotation_set_id\n        request.reference_name = reference_name\n        request.reference_id = reference_id\n        request.start = start\n        request.end = end\n        for effect in effects:\n            request.effects.add().CopyFrom(protocol.OntologyTerm(**effect))\n        for effect in request.effects:\n            if not effect.term_id:\n                raise exceptions.ErrantRequestException(\n                    \"Each ontology term should have an id set\")\n        request.page_size = pb.int(self._page_size)\n        return self._run_search_request(\n            request, \"variantannotations\",\n            protocol.SearchVariantAnnotationsResponse)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef search_features(\n            self, feature_set_id=None, parent_id=\"\", reference_name=\"\",\n            start=0, end=0, feature_types=[], name=\"\", gene_symbol=\"\"):\n        \"\"\"\n        Returns the result of running a search_features method\n        on a request with the passed-in parameters.\n\n        :param str feature_set_id: ID of the feature Set being searched\n        :param str parent_id: ID (optional) of the parent feature\n        :param str reference_name: name of the reference to search\n            (ex: \"chr1\")\n        :param int start: search start position on reference\n        :param int end: end position on reference\n        :param feature_types: array of terms to limit search by (ex: \"gene\")\n        :param str name: only return features with this name\n        :param str gene_symbol: only return features on this gene\n        :return: an iterator over Features as returned in the\n            SearchFeaturesResponse object.\n        \"\"\"\n        request = protocol.SearchFeaturesRequest()\n        request.feature_set_id = feature_set_id\n        request.parent_id = parent_id\n        request.reference_name = reference_name\n        request.name = name\n        request.gene_symbol = gene_symbol\n        request.start = start\n        request.end = end\n        request.feature_types.extend(feature_types)\n        request.page_size = pb.int(self._page_size)\n        return self._run_search_request(\n            request, \"features\",\n            protocol.SearchFeaturesResponse)", "response": "Returns an iterator over the features in the specified feature set."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn an iterator over the Continuous objects in the specified range.", "response": "def search_continuous(\n            self, continuous_set_id=None, reference_name=\"\", start=0, end=0):\n        \"\"\"\n        Returns the result of running a search_continuous method\n        on a request with the passed-in parameters.\n\n        :param str continuous_set_id: ID of the ContinuousSet being searched\n        :param str reference_name: name of the reference to search\n            (ex: \"chr1\")\n        :param int start: search start position on reference\n        :param int end: end position on reference\n        :return: an iterator over Continuous returned in the\n            SearchContinuousResponse object.\n        \"\"\"\n        request = protocol.SearchContinuousRequest()\n        request.continuous_set_id = continuous_set_id\n        request.reference_name = reference_name\n        request.start = start\n        request.end = end\n        request.page_size = pb.int(self._page_size)\n        return self._run_search_request(\n            request, \"continuous\",\n            protocol.SearchContinuousResponse)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning an iterator over the Datasets on the server.", "response": "def search_datasets(self):\n        \"\"\"\n        Returns an iterator over the Datasets on the server.\n\n        :return: An iterator over the :class:`ga4gh.protocol.Dataset`\n            objects on the server.\n        \"\"\"\n        request = protocol.SearchDatasetsRequest()\n        request.page_size = pb.int(self._page_size)\n        return self._run_search_request(\n            request, \"datasets\", protocol.SearchDatasetsResponse)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an iterator over the VariantSets fulfilling the specified conditions from the specified Dataset.", "response": "def search_variant_sets(self, dataset_id):\n        \"\"\"\n        Returns an iterator over the VariantSets fulfilling the specified\n        conditions from the specified Dataset.\n\n        :param str dataset_id: The ID of the :class:`ga4gh.protocol.Dataset`\n            of interest.\n        :return: An iterator over the :class:`ga4gh.protocol.VariantSet`\n            objects defined by the query parameters.\n        \"\"\"\n        request = protocol.SearchVariantSetsRequest()\n        request.dataset_id = dataset_id\n        request.page_size = pb.int(self._page_size)\n        return self._run_search_request(\n            request, \"variantsets\", protocol.SearchVariantSetsResponse)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning an iterator over the Annotation Sets fulfilling the specified conditions from the specified variant set.", "response": "def search_variant_annotation_sets(self, variant_set_id):\n        \"\"\"\n        Returns an iterator over the Annotation Sets fulfilling the specified\n        conditions from the specified variant set.\n\n        :param str variant_set_id: The ID of the\n            :class:`ga4gh.protocol.VariantSet` of interest.\n        :return: An iterator over the :class:`ga4gh.protocol.AnnotationSet`\n            objects defined by the query parameters.\n        \"\"\"\n        request = protocol.SearchVariantAnnotationSetsRequest()\n        request.variant_set_id = variant_set_id\n        request.page_size = pb.int(self._page_size)\n        return self._run_search_request(\n            request, \"variantannotationsets\",\n            protocol.SearchVariantAnnotationSetsResponse)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn an iterator over the FeatureSets fulfilling the specified conditions from the specified Dataset.", "response": "def search_feature_sets(self, dataset_id):\n        \"\"\"\n        Returns an iterator over the FeatureSets fulfilling the specified\n        conditions from the specified Dataset.\n\n        :param str dataset_id: The ID of the\n            :class:`ga4gh.protocol.Dataset` of interest.\n        :return: An iterator over the :class:`ga4gh.protocol.FeatureSet`\n            objects defined by the query parameters.\n        \"\"\"\n        request = protocol.SearchFeatureSetsRequest()\n        request.dataset_id = dataset_id\n        request.page_size = pb.int(self._page_size)\n        return self._run_search_request(\n            request, \"featuresets\", protocol.SearchFeatureSetsResponse)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn an iterator over the ContinuousSets fulfilling the specified conditions from the specified Dataset.", "response": "def search_continuous_sets(self, dataset_id):\n        \"\"\"\n        Returns an iterator over the ContinuousSets fulfilling the specified\n        conditions from the specified Dataset.\n\n        :param str dataset_id: The ID of the\n            :class:`ga4gh.protocol.Dataset` of interest.\n        :return: An iterator over the :class:`ga4gh.protocol.ContinuousSet`\n            objects defined by the query parameters.\n        \"\"\"\n        request = protocol.SearchContinuousSetsRequest()\n        request.dataset_id = dataset_id\n        request.page_size = pb.int(self._page_size)\n        return self._run_search_request(\n            request, \"continuoussets\", protocol.SearchContinuousSetsResponse)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef search_reference_sets(\n            self, accession=None, md5checksum=None, assembly_id=None):\n        \"\"\"\n        Returns an iterator over the ReferenceSets fulfilling the specified\n        conditions.\n\n        :param str accession: If not null, return the reference sets for which\n            the `accession` matches this string (case-sensitive, exact match).\n        :param str md5checksum: If not null, return the reference sets for\n            which the `md5checksum` matches this string (case-sensitive, exact\n            match). See :class:`ga4gh.protocol.ReferenceSet::md5checksum` for\n            details.\n        :param str assembly_id: If not null, return the reference sets for\n            which the `assembly_id` matches this string (case-sensitive,\n            exact match).\n        :return: An iterator over the :class:`ga4gh.protocol.ReferenceSet`\n            objects defined by the query parameters.\n        \"\"\"\n        request = protocol.SearchReferenceSetsRequest()\n        request.accession = pb.string(accession)\n        request.md5checksum = pb.string(md5checksum)\n        request.assembly_id = pb.string(assembly_id)\n        request.page_size = pb.int(self._page_size)\n        return self._run_search_request(\n            request, \"referencesets\", protocol.SearchReferenceSetsResponse)", "response": "Returns an iterator over the ReferenceSets fulfilling the specified conditions."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef search_references(\n            self, reference_set_id, accession=None, md5checksum=None):\n        \"\"\"\n        Returns an iterator over the References fulfilling the specified\n        conditions from the specified Dataset.\n\n        :param str reference_set_id: The ReferenceSet to search.\n        :param str accession: If not None, return the references for which the\n            `accession` matches this string (case-sensitive, exact match).\n        :param str md5checksum: If not None, return the references for which\n            the `md5checksum` matches this string (case-sensitive, exact\n            match).\n        :return: An iterator over the :class:`ga4gh.protocol.Reference`\n            objects defined by the query parameters.\n        \"\"\"\n        request = protocol.SearchReferencesRequest()\n        request.reference_set_id = reference_set_id\n        request.accession = pb.string(accession)\n        request.md5checksum = pb.string(md5checksum)\n        request.page_size = pb.int(self._page_size)\n        return self._run_search_request(\n            request, \"references\", protocol.SearchReferencesResponse)", "response": "Returns an iterator over the References fulfilling the specified conditions from the Dataset."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef search_call_sets(self, variant_set_id, name=None, biosample_id=None):\n        request = protocol.SearchCallSetsRequest()\n        request.variant_set_id = variant_set_id\n        request.name = pb.string(name)\n        request.biosample_id = pb.string(biosample_id)\n        request.page_size = pb.int(self._page_size)\n        return self._run_search_request(\n            request, \"callsets\", protocol.SearchCallSetsResponse)", "response": "Returns an iterator over the CallSets fulfilling the specified conditions from the specified VariantSet."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn an iterator over the Biosamples fulfilling the specified conditions.", "response": "def search_biosamples(self, dataset_id, name=None, individual_id=None):\n        \"\"\"\n        Returns an iterator over the Biosamples fulfilling the specified\n        conditions.\n\n        :param str dataset_id: The dataset to search within.\n        :param str name: Only Biosamples matching the specified name will\n            be returned.\n        :param str individual_id: Only Biosamples matching matching this\n            id will be returned.\n        :return: An iterator over the :class:`ga4gh.protocol.Biosample`\n            objects defined by the query parameters.\n        \"\"\"\n        request = protocol.SearchBiosamplesRequest()\n        request.dataset_id = dataset_id\n        request.name = pb.string(name)\n        request.individual_id = pb.string(individual_id)\n        request.page_size = pb.int(self._page_size)\n        return self._run_search_request(\n            request, \"biosamples\", protocol.SearchBiosamplesResponse)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef search_individuals(self, dataset_id, name=None):\n        request = protocol.SearchIndividualsRequest()\n        request.dataset_id = dataset_id\n        request.name = pb.string(name)\n        request.page_size = pb.int(self._page_size)\n        return self._run_search_request(\n            request, \"individuals\", protocol.SearchIndividualsResponse)", "response": "Returns an iterator over the Individuals fulfilling the specified conditions."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef search_read_group_sets(\n            self, dataset_id, name=None, biosample_id=None):\n        \"\"\"\n        Returns an iterator over the ReadGroupSets fulfilling the specified\n        conditions from the specified Dataset.\n\n        :param str name: Only ReadGroupSets matching the specified name\n            will be returned.\n        :param str biosample_id: Only ReadGroups matching the specified\n            biosample will be included in the response.\n        :return: An iterator over the :class:`ga4gh.protocol.ReadGroupSet`\n            objects defined by the query parameters.\n        :rtype: iter\n        \"\"\"\n        request = protocol.SearchReadGroupSetsRequest()\n        request.dataset_id = dataset_id\n        request.name = pb.string(name)\n        request.biosample_id = pb.string(biosample_id)\n        request.page_size = pb.int(self._page_size)\n        return self._run_search_request(\n            request, \"readgroupsets\", protocol.SearchReadGroupSetsResponse)", "response": "Returns an iterator over the ReadGroupSets fulfilling the specified name\n            and biosample_id."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn an iterator over the Reads fulfilling the specified conditions from the specified read_group_ids.", "response": "def search_reads(\n            self, read_group_ids, reference_id=None, start=None, end=None):\n        \"\"\"\n        Returns an iterator over the Reads fulfilling the specified\n        conditions from the specified read_group_ids.\n\n        :param str read_group_ids: The IDs of the\n            :class:`ga4gh.protocol.ReadGroup` of interest.\n        :param str reference_id: The name of the\n            :class:`ga4gh.protocol.Reference` we wish to return reads\n            mapped to.\n        :param int start: The start position (0-based) of this query. If a\n            reference is specified, this defaults to 0. Genomic positions are\n            non-negative integers less than reference length. Requests spanning\n            the join of circular genomes are represented as two requests one on\n            each side of the join (position 0).\n        :param int end: The end position (0-based, exclusive) of this query.\n            If a reference is specified, this defaults to the reference's\n            length.\n        :return: An iterator over the\n            :class:`ga4gh.protocol.ReadAlignment` objects defined by\n            the query parameters.\n        :rtype: iter\n        \"\"\"\n        request = protocol.SearchReadsRequest()\n        request.read_group_ids.extend(read_group_ids)\n        request.reference_id = pb.string(reference_id)\n        request.start = pb.int(start)\n        request.end = pb.int(end)\n        request.page_size = pb.int(self._page_size)\n        return self._run_search_request(\n            request, \"reads\", protocol.SearchReadsResponse)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef search_phenotype_association_sets(self, dataset_id):\n        request = protocol.SearchPhenotypeAssociationSetsRequest()\n        request.dataset_id = dataset_id\n        request.page_size = pb.int(self._page_size)\n        return self._run_search_request(\n            request, \"phenotypeassociationsets\",\n            protocol.SearchPhenotypeAssociationSetsResponse)", "response": "Returns an iterator over the PhenotypeAssociationSets on the server."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef search_genotype_phenotype(\n            self, phenotype_association_set_id=None, feature_ids=None,\n            phenotype_ids=None, evidence=None):\n        \"\"\"\n        Returns an iterator over the GeneotypePhenotype associations from\n        the server\n        \"\"\"\n        request = protocol.SearchGenotypePhenotypeRequest()\n        request.phenotype_association_set_id = phenotype_association_set_id\n        if feature_ids:\n            request.feature_ids.extend(feature_ids)\n        if phenotype_ids:\n            request.phenotype_ids.extend(phenotype_ids)\n        if evidence:\n            request.evidence.extend(evidence)\n        request.page_size = pb.int(self._page_size)\n        self._logger.debug(\"search_genotype_phenotype {}\".format(request))\n        return self._run_search_request(\n            request, \"featurephenotypeassociations\",\n            protocol.SearchGenotypePhenotypeResponse)", "response": "Returns an iterator over the GeneotypePhenotype associations from the server."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef search_phenotype(\n            self, phenotype_association_set_id=None, phenotype_id=None,\n            description=None, type_=None, age_of_onset=None):\n        \"\"\"\n        Returns an iterator over the Phenotypes from the server\n        \"\"\"\n        request = protocol.SearchPhenotypesRequest()\n        request.phenotype_association_set_id = phenotype_association_set_id\n        if phenotype_id:\n            request.id = phenotype_id\n        if description:\n            request.description = description\n        if type_:\n            request.type.mergeFrom(type_)\n        if age_of_onset:\n            request.age_of_onset = age_of_onset\n        request.page_size = pb.int(self._page_size)\n        return self._run_search_request(\n            request, \"phenotypes\",\n            protocol.SearchPhenotypesResponse)", "response": "Returns an iterator over the Phenotypes from the server."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning an iterator over the RnaQuantificationSets in the specified dataset.", "response": "def search_rna_quantification_sets(self, dataset_id):\n        \"\"\"\n        Returns an iterator over the RnaQuantificationSet objects from the\n        server\n        \"\"\"\n        request = protocol.SearchRnaQuantificationSetsRequest()\n        request.dataset_id = dataset_id\n        request.page_size = pb.int(self._page_size)\n        return self._run_search_request(\n            request, \"rnaquantificationsets\",\n            protocol.SearchRnaQuantificationSetsResponse)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef search_rna_quantifications(self, rna_quantification_set_id=\"\"):\n        request = protocol.SearchRnaQuantificationsRequest()\n        request.rna_quantification_set_id = rna_quantification_set_id\n        request.page_size = pb.int(self._page_size)\n        return self._run_search_request(\n            request, \"rnaquantifications\",\n            protocol.SearchRnaQuantificationsResponse)", "response": "Returns an iterator over the RnaQuantification objects from the server."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef search_expression_levels(\n            self, rna_quantification_id=\"\", names=[], threshold=0.0):\n        \"\"\"\n        Returns an iterator over the ExpressionLevel objects from the server\n\n        :param str feature_ids: The IDs of the\n            :class:`ga4gh.protocol.Feature` of interest.\n        :param str rna_quantification_id: The ID of the\n            :class:`ga4gh.protocol.RnaQuantification` of interest.\n        :param float threshold: Minimum expression of responses to return.\n        \"\"\"\n        request = protocol.SearchExpressionLevelsRequest()\n        request.rna_quantification_id = rna_quantification_id\n        request.names.extend(names)\n        request.threshold = threshold\n        request.page_size = pb.int(self._page_size)\n        return self._run_search_request(\n            request, \"expressionlevels\",\n            protocol.SearchExpressionLevelsResponse)", "response": "Returns an iterator over the ExpressionLevel objects from the server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting up the common HTTP session parameters used by requests.", "response": "def _setup_http_session(self):\n        \"\"\"\n        Sets up the common HTTP session parameters used by requests.\n        \"\"\"\n        headers = {\"Content-type\": \"application/json\"}\n        if (self._id_token):\n            headers.update({\"authorization\": \"Bearer {}\".format(\n                self._id_token)})\n        self._session.headers.update(headers)\n        # TODO is this unsafe????\n        self._session.verify = False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _check_response_status(self, response):\n        if response.status_code != requests.codes.ok:\n            self._logger.error(\"%s %s\", response.status_code, response.text)\n            raise exceptions.RequestNonSuccessException(\n                \"Url {0} had status_code {1}\".format(\n                    response.url, response.status_code))", "response": "Checks the status code of the response and raises an exception if it is not 200."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninitializing the captcha extension to the given Flask application object.", "response": "def init_app(self, app):\n        \"\"\"\n        Initialize the captcha extension to the given app object.\n        \"\"\"\n        self.enabled = app.config.get(\"CAPTCHA_ENABLE\", True)\n        self.digits = app.config.get(\"CAPTCHA_LENGTH\", 4)\n        self.max = 10**self.digits\n        self.image_generator = ImageCaptcha()\n        self.rand = SystemRandom()\n\n        def _generate():\n            if not self.enabled:\n                return \"\"\n            base64_captcha = self.generate()\n            return Markup(\"<img src='{}'>\".format(\"data:image/png;base64, {}\".format(base64_captcha)))\n\n        app.jinja_env.globals['captcha'] = _generate\n        \n        # Check for sessions that do not persist on the server. Issue a warning because they are most likely open to replay attacks.\n        # This addon is built upon flask-session.\n        session_type = app.config.get('SESSION_TYPE', None)\n        if session_type is None or session_type == \"null\":\n            raise RuntimeWarning(\"Flask-Sessionstore is not set to use a server persistent storage type. This likely means that captchas are vulnerable to replay attacks.\")\n        elif session_type == \"sqlalchemy\":\n            # I have to do this as of version 0.3.1 of flask-session if using sqlalchemy as the session type in order to create the initial database.\n            # Flask-sessionstore seems to have the same problem. \n            app.session_interface.db.create_all()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate(self):\n        answer = self.rand.randrange(self.max)\n        answer = str(answer).zfill(self.digits)        \n        image_data = self.image_generator.generate(answer)\n        base64_captcha = base64.b64encode(image_data.getvalue()).decode(\"ascii\")\n        logging.debug('Generated captcha with answer: ' + answer)\n        session['captcha_answer'] = answer\n        return base64_captcha", "response": "Generates and returns a numeric captcha image in base64 format."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validate(self, form_key=\"captcha\", value=None):\n        if not self.enabled:\n            return True\n\n        session_value = session.get('captcha_answer', None)\n        if not session_value:\n            return False\n        \n        if not value and form_key in request.form:\n            value = request.form[form_key].strip()\n\n        # invalidate the answer to stop new tries on the same challenge.\n        session['captcha_answer'] = None\n        return value and value == session_value", "response": "Validate a captcha answer against the answer saved in the session."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(self):\n        url = self.baseurl + '/_status?format=xml'\n        response = self.s.get(url)\n        response.raise_for_status()\n        from xml.etree.ElementTree import XML\n        root = XML(response.text)\n        for serv_el in root.iter('service'):\n            serv = Monit.Service(self, serv_el)\n            self[serv.name] = serv\n            # Pendingaction occurs when a service is stopping\n            if self[serv.name].pendingaction:\n                time.sleep(1)\n                return Monit.update(self)\n            # Monitor == 2 when service in startup\n            if self[serv.name].monitorState == 2:\n                time.sleep(1)\n                return Monit.update(self)", "response": "Update Monit deamon and services status."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef init_send(self):\n        packet = Packet()\n        self.packets.append(packet)\n        packet.add_payload(payloads.SA())\n        packet.add_payload(payloads.KE(diffie_hellman=self.diffie_hellman))\n        packet.add_payload(payloads.Nonce(nonce=self.Ni))\n        packet.iSPI = self.iSPI = packet.payloads[0].spi\n        self.state = State.INIT\n        return bytes(packet)", "response": "Generates the first IKE_INIT packet for Initiator\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef auth_send(self):\n        assert len(self.packets) == 2\n        packet = Packet(exchange_type=const.ExchangeType.IKE_AUTH, iSPI=self.iSPI, rSPI=self.rSPI)\n\n        # Add IDi (35)\n        id_payload = payloads.IDi()\n        packet.add_payload(id_payload)\n\n        # Add AUTH (39)\n        signed_octets = bytes(self.packets[0]) + self.Nr + prf(self.SK_pi, id_payload._data)\n        packet.add_payload(payloads.AUTH(signed_octets))\n\n        # Add SA (33)\n        self.esp_SPIout = int.from_bytes(os.urandom(4), 'big')\n        packet.add_payload(payloads.SA(proposals=[\n            proposal.Proposal(protocol=const.ProtocolID.ESP, spi=self.esp_SPIout, last=True, transforms=[\n                ('ENCR_CAMELLIA_CBC', 256), ('ESN',), ('AUTH_HMAC_SHA2_256_128',)\n            ])\n        ]))\n\n        # Add TSi (44)\n        packet.add_payload(payloads.TSi(addr=self.address))\n\n        # Add TSr (45)\n        packet.add_payload(payloads.TSr(addr=self.peer))\n\n        # Add N(INITIAL_CONTACT)\n        packet.add_payload(payloads.Notify(notify_type=const.MessageType.INITIAL_CONTACT))\n\n        self.packets.append(packet)\n        self.state = State.AUTH\n\n        return self.encrypt_and_hmac(packet)", "response": "Generates the second IKE_INIT packet for Initiator\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing the response packet and assigns all keys to self.", "response": "def init_recv(self):\n        \"\"\"\n        Parses the IKE_INIT response packet received from Responder.\n\n        Assigns the correct values of rSPI and Nr\n        Calculates Diffie-Hellman exchange and assigns all keys to self.\n\n        \"\"\"\n        assert len(self.packets) == 2\n        packet = self.packets[-1]\n        for p in packet.payloads:\n            if p._type == payloads.Type.Nr:\n                self.Nr = p._data\n                logger.debug(u\"Responder nonce {}\".format(binascii.hexlify(self.Nr)))\n            elif p._type == payloads.Type.KE:\n                int_from_bytes = int.from_bytes(p.kex_data, 'big')\n                self.diffie_hellman.derivate(int_from_bytes)\n            else:\n                logger.debug('Ignoring: {}'.format(p))\n\n        logger.debug('Nonce I: {}\\nNonce R: {}'.format(binascii.hexlify(self.Ni), binascii.hexlify(self.Nr)))\n        logger.debug('DH shared secret: {}'.format(binascii.hexlify(self.diffie_hellman.shared_secret)))\n\n        SKEYSEED = prf(self.Ni + self.Nr, self.diffie_hellman.shared_secret)\n\n        logger.debug(u\"SKEYSEED is: {0!r:s}\\n\".format(binascii.hexlify(SKEYSEED)))\n\n        keymat = prfplus(SKEYSEED, (self.Ni + self.Nr +\n                                    to_bytes(self.iSPI) + to_bytes(self.rSPI)),\n                         32 * 7)\n        #3 * 32 + 2 * 32 + 2 * 32)\n\n        logger.debug(\"Got %d bytes of key material\" % len(keymat))\n        # get keys from material\n        ( self.SK_d,\n          self.SK_ai,\n          self.SK_ar,\n          self.SK_ei,\n          self.SK_er,\n          self.SK_pi,\n          self.SK_pr ) = unpack(\"32s\" * 7, keymat)  # XXX: Should support other than 256-bit algorithms, really.\n\n        logger.debug(\"SK_ai: {}\".format(dump(self.SK_ai)))\n        logger.debug(\"SK_ei: {}\".format(dump(self.SK_ei)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef authenticate_peer(self, auth_data, peer_id, message):\n        logger.debug('message: {}'.format(dump(message)))\n        signed_octets = message + self.Ni + prf(self.SK_pr, peer_id._data)\n        auth_type = const.AuthenticationType(struct.unpack(const.AUTH_HEADER, auth_data[:4])[0])\n        assert auth_type == const.AuthenticationType.RSA\n        logger.debug(dump(auth_data))\n        try:\n            return pubkey.verify(signed_octets, auth_data[4:], 'tests/peer.pem')\n        except pubkey.VerifyError:\n            raise IkeError(\"Remote peer authentication failed.\")", "response": "Verifies the peer s authentication."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nhandling the IKE_AUTH response.", "response": "def auth_recv(self):\n        \"\"\"\n        Handle peer's IKE_AUTH response.\n        \"\"\"\n        id_r = auth_data = None\n        for p in self.packets[-1].payloads:\n            if p._type == payloads.Type.IDr:\n                id_r = p\n                logger.debug('Got responder ID: {}'.format(dump(bytes(p))))\n            if p._type == payloads.Type.AUTH:\n                auth_data = p._data\n            if p._type == payloads.Type.SA:\n                logger.debug('ESP_SPIin: {}'.format(p.spi))\n                self.esp_SPIin = p.spi\n                for proposal in p.proposals:\n                    logger.debug(\"Proposal: {}\".format(proposal.__dict__))\n                    logger.debug(proposal.spi)\n        if id_r is None or auth_data is None:\n            raise IkeError('IDr missing from IKE_AUTH response')\n        message2 = bytes(self.packets[1])\n        authenticated = self.authenticate_peer(auth_data, id_r, message2)\n        assert authenticated\n        keymat = prfplus(self.SK_d, self.Ni + self.Nr, 4 * 32)\n        (self.esp_ei,\n          self.esp_ai,\n          self.esp_er,\n          self.esp_ar,\n         ) = unpack(\"32s\" * 4, keymat)\n        # TODO: Figure out the names for the params, they _ARE_ in correct places, just the names migth mismatch.\n        self.install_ipsec_sas()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nencrypts and signs a Packet using self. SK_ei and self. SK_ai .", "response": "def encrypt_and_hmac(self, packet):\n        \"\"\"\n        Encrypts and signs a Packet() using self.SK_ei and self.SK_ai\n\n        :param packet: Unecrypted Packet() with one or more payloads.\n        :return: Encrypted and signed Packet() with a single payloads.SK\n        \"\"\"\n        final = Packet(exchange_type=packet.exchange_type, iSPI=packet.iSPI, rSPI=packet.rSPI, message_id=1)\n        # Set up crypto\n        iv = os.urandom(16)\n        ikecrypto = Camellia(self.SK_ei, iv)\n        ikehash = HMAC(self.SK_ai, digestmod=sha256)\n        logger.debug('IV: {}'.format(dump(iv)))\n\n        # Encrypt\n        plain = bytes(packet)[const.IKE_HEADER.size:]\n        ciphertext = ikecrypto.encrypt(plain)\n        sk = payloads.SK(next_payload=packet.payloads[0]._type, iv=iv, ciphertext=ciphertext)\n        final.add_payload(sk)\n        logger.debug(dump(bytes(final)))\n\n        # Sign\n        ikehash.update(bytes(final)[:-MACLEN])\n        mac = ikehash.digest()[:MACLEN]\n        sk.mac(mac)\n\n        logger.debug(dump(bytes(final)))\n        return bytes(final)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nverifying the HMAC signature of an encrypted ( SK 46 ) payload.", "response": "def verify_hmac(self, data):\n        \"\"\"\n        Verifies the HMAC signature of an encrypted (SK, 46) payload using self.SK_ar\n\n        :param data: bytes(payloads.SK())\n        :raise IkeError: if calculated signature does not match the one in the payload\n        \"\"\"\n        hmac = HMAC(self.SK_ar, digestmod=sha256)\n        hmac_theirs = data[-MACLEN:]\n        hmac.update(data[:-MACLEN])\n        hmac_ours = hmac.digest()[:MACLEN]\n        logger.debug('HMAC verify (ours){} (theirs){}'.format(\n            binascii.hexlify(hmac_ours), binascii.hexlify(hmac_theirs)))\n        if hmac_ours != hmac_theirs:\n            raise IkeError('HMAC verify failed')"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse a received packet in to Packet instance with corresponding payloads.", "response": "def parse_packet(self, data):\n        \"\"\"\n        Parses a received packet in to Packet() with corresponding payloads.\n        Will decrypt encrypted packets when needed.\n\n        :param data: bytes() IKE packet from wire.\n        :return: Packet() instance\n        :raise IkeError: on malformed packet\n        \"\"\"\n        packet = Packet(data=data)\n        packet.header = data[0:const.IKE_HEADER.size]\n        (packet.iSPI, packet.rSPI, next_payload, packet.version, exchange_type, packet.flags,\n         packet.message_id, packet.length) = const.IKE_HEADER.unpack(packet.header)\n        packet.exchange_type = const.ExchangeType(exchange_type)\n        if self.iSPI != packet.iSPI:\n            raise IkeError(\"Initiator SPI mismatch, packet to an unknown IKE SA\")\n        elif not self.rSPI:\n            logger.debug(\"Setting responder SPI: {0:x}\".format(packet.rSPI))\n            self.rSPI = packet.rSPI\n        elif self.rSPI != packet.rSPI:\n            raise IkeError(\"Responder SPI mismatch, packet to an unknown IKE SA\")\n        if packet.message_id - int(self.state) != 1:\n            logger.debug(\"message ID {} at state {!r}\".format(packet.message_id, self.state))\n        logger.debug(\"next payload: {!r}\".format(next_payload))\n        if next_payload == 46:\n            self.verify_hmac(data)\n            next_payload, data = self.decrypt(data[const.IKE_HEADER.size:])\n        else:\n            data = data[const.IKE_HEADER.size:]\n        while next_payload:\n            logger.debug('Next payload: {0!r}'.format(next_payload))\n            logger.debug('{0} bytes remaining'.format(len(data)))\n            try:\n                payload = payloads.get_by_type(next_payload)(data=data)\n            except KeyError as e:\n                logger.error(\"Unidentified payload {}\".format(e))\n                payload = payloads._IkePayload(data=data)\n            packet.payloads.append(payload)\n            logger.debug('Payloads: {0!r}'.format(packet.payloads))\n            next_payload = payload.next_payload\n            data = data[payload.length:]\n        logger.debug(\"Packed parsed successfully\")\n        self.packets.append(packet)\n        return packet"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_payload(self, payload):\n        if self.payloads:\n            self.payloads[-1].next_payload = payload._type\n        self.payloads.append(payload)", "response": "Adds a payload to the packet updating last payload s next_payload field"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the name of the caller s module as a string.", "response": "def get_caller_module():\n    \"\"\"\n    Returns the name of the caller's module as a string.\n\n    >>> get_caller_module()\n    '__main__'\n    \"\"\"\n    stack = inspect.stack()\n    assert len(stack) > 1\n    caller = stack[2][0]\n    return caller.f_globals['__name__']"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new sentinel instance of Sentinel class.", "response": "def create(name, mro=(object,), extra_methods={}, *args, **kwargs):\n    \"\"\"\n    create(name, mro=(object,), extra_methods={}, ...) -> Sentinel instance\n\n    Creates a new sentinel instance. This is a singleton instance kind\n    of like the builtin None, and Ellipsis.\n\n    Method resolution order (MRO) for the anonymous class can be\n    specified (i.e., it can be a subclass). Provide the mro as tuple of\n    all classes that it inherits from. If only one class, provide a\n    1-tuple: e.g., (Cls,).\n\n    Additionally extra class attributes, such as methods can be provided\n    in the extra_methods dict. The following methods are provided, but\n    can be overridden:\n\n        __repr__()\n            Returns the class name, similar to None and Ellipsis.\n        __copy__()\n        __deepcopy__()\n            Always return the same singleton instance such that\n            ``copy(Sentinel) is Sentinel`` is true.\n        __reduce__()\n            Provided for proper pickling prowess. That is,\n            ``pickle.loads(pickle.dumps(Sentinel)) is Sentinel`` is\n            true.\n\n    Finally, the remain arguments and keyword arguments are passed to\n    the super class's __init__().  This is helpful when for\n    instantiating base classes such as a tuple.\n    \"\"\"\n\n    cls_dict = {}\n\n    cls_dict.update(\n        # Provide a nice, clean, self-documenting __repr__\n        __repr__=lambda self: name,\n        # Provide a copy and deepcopy implementation which simply return the\n        # same exact instance.\n        __deepcopy__=lambda self, _memo: self,\n        __copy__=lambda self: self,\n        # Provide a hook for pickling the sentinel.\n        __reduce__=lambda self: name\n    )\n\n    # If the default MRO is given, then it's safe to prevent the singleton\n    # instance from having a instance dictionary.\n    if mro == (object,):\n        cls_dict.update(__slots__=())\n\n    cls_dict.update(extra_methods)\n\n    anon_type = type(name, mro, cls_dict)\n\n    # Stack introspection -- make the singleton always belong to the module of\n    # its caller. If we don't do this, pickling using __reduce__() will fail!\n    anon_type.__module__ = get_caller_module()\n\n    # Return the singleton instance of this new, \"anonymous\" type.\n    return anon_type(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates a pseudorandom value between 0 and 1 ( inclusive", "response": "def _random(self, key):\n        \"\"\"Generates a pseudorandom value between 0 and 1 (inclusive)\"\"\"\n\n        if hasattr(key, \"encode\"):\n            key = key.encode('ascii')\n\n        value = (zlib.crc32(key, self.seed) & MAX_VALUE)\n\n        return value * INV_MAX_VALUE"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef uniform(self, key, min_value=0., max_value=1.):\n        return min_value + self._random(key) * (max_value - min_value)", "response": "Returns a random number between min_value and max_value"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef weighted_choice(self, probabilities, key):\n\n        total = sum(x[0] for x in probabilities)\n        choice = total * self._random(key)\n\n        for probability, option in probabilities:\n            choice -= probability\n            if choice <= 0:\n                return option", "response": "Makes a weighted choice between several options. Probabilities is a list of 2 - tuples."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a PerlinNoise object with the specified key. For parameters check the PerlinNoise class.", "response": "def perlin(self, key, **kwargs):\n        \"\"\"Return perlin noise seede with the specified key.\n        For parameters, check the PerlinNoise class.\"\"\"\n\n        if hasattr(key, \"encode\"):\n            key = key.encode('ascii')\n\n        value = zlib.adler32(key, self.seed)\n        return PerlinNoise(value, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmake a weighted choice between several options. Probabilities is a list of 2 - tuples. Probabilities are a list of 2 - tuples.", "response": "def weighted_choice(self, probabilities, key):\n        \"\"\"Makes a weighted choice between several options.\n\n        Probabilities is a list of 2-tuples, (probability, option). The\n        probabilties don't need to add up to anything, they are automatically\n        scaled.\"\"\"\n\n        try:\n            choice = self.values[key].lower()\n        except KeyError:\n            # override not set.\n            result = super(OverridableParameters, self)\\\n                .weighted_choice(probabilities, key)\n            if hasattr(result, \"__call__\"):\n                self.results[key] = result.__name__\n            else:\n                self.results[key] = str(result)\n            return result\n\n        # Find the matching key (case insensitive)\n        for probability, option in probabilities:\n            if str(option).lower() == choice:\n                self.results[key] = option\n                return option\n\n        # for function or class-type choices, also check __name__\n        for probability, option in probabilities:\n            if option.__name__.lower() == choice:\n                self.results[key] = option.__name__\n                return option\n\n        assert False, \"Invalid value provided\""}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmaking a weighted choice between several options. Probabilities is a list of 2 - tuples. Probabilities are a list of 2 - tuples.", "response": "def weighted_choice(self, probabilities, key):\n        \"\"\"Makes a weighted choice between several options.\n\n        Probabilities is a list of 2-tuples, (probability, option). The\n        probabilties don't need to add up to anything, they are automatically\n        scaled.\"\"\"\n\n        try:\n            choice = self.values[key].lower()\n        except KeyError:\n            # override not set.\n            return super(RecordingParameters, self)\\\n                .weighted_choice(probabilities, key)\n\n        # Find the matching key (case insensitive)\n        for probability, option in probabilities:\n            if str(option).lower() == choice:\n                return option\n\n        # for function or class-type choices, also check __name__\n        for probability, option in probabilities:\n            if option.__name__.lower() == choice:\n                return option\n\n        assert False, \"Invalid value provided\""}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _check_value_recursively(key, val, haystack):\n    if isinstance(haystack, list):\n        return any([_check_value_recursively(key, val, l) for l in haystack])\n    elif isinstance(haystack, dict):\n        if not key in haystack:\n            return any([_check_value_recursively(key, val, d) for k, d in haystack.items()\n                        if isinstance(d, list) or isinstance(d, dict)])\n        else:\n            return haystack[key] == val\n    else:\n        return False", "response": "Check if the given key with value _val_ is in the given dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting all elements that have key = val in list l", "response": "def _get_by(key, val, l):\n    \"\"\"\n    Out of list *l* return all elements that have *key=val*\n    This comes in handy when you are working with aggregated/bucketed queries\n    \"\"\"\n    return [x for x in l if _check_value_recursively(key, val, x)]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_no_proxy_errors(self, **kwargs):\n        data = self._es.search(body={\n            \"size\": max_query_results,\n            \"query\": {\n                \"filtered\": {\n                    \"query\": {\n                        \"match_all\": {}\n                    },\n                    \"filter\": {\n                        \"term\": {\n                            \"level\": \"error\"\n                        }\n                    }\n                }\n            }\n        })\n#        if self.debug:\n#            print(data)\n        return GremlinTestResult(data[\"hits\"][\"total\"] == 0, data)", "response": "Helper method to determine if the proxies logged any major errors related to the functioning of the proxy itself."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_requests_with_errors(self):\n        data = self._es.search(body={\n            \"size\": max_query_results,\n            \"query\": {\n                \"filtered\": {\n                    \"query\": {\n                        \"match_all\": {}\n                    },\n                    \"filter\": {\n                        \"exists\": {\n                            \"field\": \"errmsg\"\n                        }\n                    }\n                }\n            }\n        })\n        return GremlinTestResult(False, data)", "response": "Helper method to determine if proxies logged any error related to the requests passing through"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking that source service sent at most num_request to dest service.", "response": "def check_at_most_requests(self, source, dest, num_requests, **kwargs):\n        \"\"\"\n        Check that source service sent at most num_request to the dest service\n        :param source the source service name\n        :param dest the destination service name\n        :param num_requests the maximum number of requests that we expect\n        :return:\n        \"\"\"\n        # TODO: Does the proxy support logging of instances so that grouping by instance is possible?\n\n        if self.debug:\n            print 'in check_at_most_requests (%s, %s, %s, %s)' % (source, dest, num_requests, self._id)\n\n        # Fetch requests for src->dst\n        data = self._es.search(body={\n            \"size\": max_query_results,\n            \"query\": {\n                \"filtered\": {\n                    \"query\": {\n                        \"match_all\": {}\n                    },\n                    \"filter\": {\n                        \"bool\": {\n                            \"must\": [\n                                {\"term\": {\"msg\": \"Request\"}},\n                                {\"term\": {\"source\": source}},\n                                {\"term\": {\"dest\": dest}},\n                                {\"term\": {\"protocol\": \"http\"}},\n                                {\"term\": {\"testid\": self._id}}\n                            ]\n                        }\n                    }\n                }\n            },\n            \"aggs\": {\n                # Need size, otherwise only top buckets are returned\n                #\"size\": max_query_results,\n                \"byid\": {\n                    \"terms\": {\n                        \"field\": \"reqID\",\n                    }\n                }\n            }\n        })\n\n        if self.debug:\n            pprint.pprint(data)\n\n        result = True\n        errormsg = \"\"\n        if not self._check_non_zero_results(data):\n            result = False\n            errormsg = \"No log entries found\"\n            return GremlinTestResult(result, errormsg)\n\n        # Check number of requests in each bucket\n        for bucket in data[\"aggregations\"][\"byid\"][\"buckets\"]:\n            if bucket[\"doc_count\"] > (num_requests + 1):\n                errormsg = \"{} -> {} - expected {} requests, but found {} \"\\\n                         \"requests for id {}\".format(\n                            source, dest, num_requests, bucket['doc_count'] - 1,\n                            bucket['key'])\n                result = False\n                if self.debug:\n                    print errormsg\n                return GremlinTestResult(result, errormsg)\n        return GremlinTestResult(result, errormsg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_bulkhead(self, source, dependencies, slow_dest, rate):\n        #Remove slow dest\n        dependencies.remove(slow_dest)\n\n\n        s =str(float(1)/float(rate))\n        max_spacing = _parse_duration(s+'s')\n\n           \n        \n        for dest in dependencies:\n            data = self._es.search(body={\n                \"size\": max_query_results,\n                \"query\": {\n                    \"filtered\": {\n                        \"query\": {\n                            \"match_all\": {}\n                        },\n                        \"filter\": {\n                            \"bool\": {\n                                \"must\": [\n                                    {\"term\": {\"msg\": \"Request\"}},\n                                    {\"term\": {\"source\": source}},\n                                    {\"term\": {\"dest\": dest}},\n                                    {\"term\": {\"testid\": self._id}}\n                                ]\n                            }\n                        }\n                    }\n                }\n            })\n\n            if self.debug:\n                pprint.pprint(data)\n\n            result = True\n            errormsg = \"\"\n            if not self._check_non_zero_results(data):\n                result = False\n                errormsg = \"No log entries found\"\n                return GremlinTestResult(result, errormsg)\n\n            req_seq = _get_by(\"source\", source, data[\"hits\"][\"hits\"])\n            req_seq.sort(key=lambda x: isodate.parse_datetime(x['_source'][\"ts\"]))\n\n            last_request = isodate.parse_datetime(req_seq[0]['_source'][\"ts\"])\n\n            for req in req_seq:\n                req_spacing = isodate.parse_datetime(req['_source'][\"ts\"]) - last_request\n                last_request = isodate.parse_datetime(req['_source'][\"ts\"])\n                if self.debug:\n                    print \"spacing\", req_spacing, max_spacing\n                if req_spacing > max_spacing:\n\n                    errormsg = \"{} -> {} - new request was issued at ({}s) but max spacing should be ({}s)\".format(source,\n                                                                                                                     dest,\n                                                                                                                     req_spacing,\n                                                                                                                     max_spacing) \n                    result = False\n                    return GremlinTestResult(result, errormsg)                \n                \n\n                \n\n        return GremlinTestResult(result, errormsg)", "response": "Checks bulkheads by ensuring that the rate of requests to other services is kept when slow_dest is not being tested for slow_src."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_assertions(self, checklist, all=False):\n\n        assert isinstance(checklist, dict) and 'checks' in checklist\n\n        retval = None\n        retlist = []\n\n        for assertion in checklist['checks']:\n            retval = self.check_assertion(**assertion)\n            retlist.append(retval)\n            if not retval.success and not all:\n                print \"Error message:\", retval[3]\n                return retlist\n\n        return retlist", "response": "Check a set of assertions with a given checklist."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create(self, component_context, overriding_args):\n        return self.component_scope.instance(lambda: self._create(component_context, overriding_args))", "response": "Creates a new instance of the component with the given context."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _find_constructor(self):\n\n        def isconstructor(object):\n            return inspect.isfunction(object) and object.__name__ == '__init__'\n\n        # find all the dependencies from the constructor\n        constructors = inspect.getmembers(self.class_type, predicate=isconstructor)\n\n        if constructors:\n            name, func = constructors[0]\n            return func\n\n        # No explicit __init__\n        return None", "response": "Finds the constructor from the class_type."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef resolve(self, component_type, **kwargs):\n        with self._resolve_lock:\n            context = _ComponentContext(self)\n            return context.resolve(component_type, **kwargs)", "response": "Resolves an instance of the component type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef register_class(self, class_type, component_scope=scope.InstancePerDependency, register_as=None):\n        registration = _ConstructorRegistration(class_type, component_scope())\n        self._register(class_type, registration, register_as)", "response": "Registers the given class type for creation via its constructor."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef register_callback(self, class_type, callback, component_scope=scope.InstancePerDependency, register_as=None):\n        registration = _CallbackRegistration(callback, component_scope())\n        self._register(class_type, registration, register_as)", "response": "Registers a callback function to create a new component for creation via the given callback."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef register_instance(self, class_type, instance, register_as=None):\n        registration = _InstanceRegistration(instance)\n        self._register(class_type, registration, register_as)", "response": "Registers the given instance with the given class type."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndownload star index files.", "response": "def download(odir: Path, source_url: str, irng: Sequence[int]):\n    \"\"\"Download star index files.\n    The default range was useful for my cameras.\n    \"\"\"\n    assert len(irng) == 2, 'specify start, stop indices'\n\n    odir = Path(odir).expanduser()\n    odir.mkdir(parents=True, exist_ok=True)\n\n    ri = int(source_url.split('/')[-2][:2])\n\n    for i in range(*irng):\n        fn = f'index-{ri:2d}{i:02d}.fits'\n        url = f'{source_url}{fn}'\n        ofn = odir / fn\n        if ofn.is_file():  # no clobber\n            print('skipping', ofn)\n            continue\n        print(f'{url} => {ofn}', end='\\r')\n\n        urlretrieve(url, ofn)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks the excluded value against the link s current value", "response": "def exclude_match(exclude, link_value):\n    \"\"\" Check excluded value against the link's current value \"\"\"\n    if hasattr(exclude, \"search\") and exclude.search(link_value):\n        return True\n\n    if exclude == link_value:\n        return True\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef seoify_hyperlink(hyperlink):\n    last_slash = hyperlink.rfind('/')\n    return re.sub(r' +|-', ' ', hyperlink[last_slash + 1:])", "response": "Modify a hyperlink to make it SEO - friendly by replacing hyphens with spaces and trimming multiple spaces."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find(self, limit=None, reverse=False, sort=None,\n             exclude=None, duplicates=True, pretty=False, **filters):\n        \"\"\" Using filters and sorts, this finds all hyperlinks\n        on a web page\n\n        :param limit: Crop results down to limit specified\n        :param reverse: Reverse the list of links, useful for before limiting\n        :param exclude: Remove links from list\n        :param duplicates: Determines if identical URLs should be displayed\n        :param pretty: Quick and pretty formatting using pprint\n        :param filters: All the links to search for \"\"\"\n        if exclude is None:\n            exclude = []\n\n        if 'href' not in filters:\n            filters['href'] = True\n        search = self._soup.findAll('a', **filters)\n\n        if reverse:\n            search.reverse()\n\n        links = []\n        for anchor in search:\n            build_link = anchor.attrs\n            try:\n                build_link[u'seo'] = seoify_hyperlink(anchor['href'])\n            except KeyError:\n                pass\n\n            try:\n                build_link[u'text'] = anchor.string or build_link['seo']\n            except KeyError:\n                pass\n\n            ignore_link = False\n            for nixd in exclude:\n                for key, value in six.iteritems(nixd):\n                    if key in build_link:\n                        if (isinstance(build_link[key], collections.Iterable)\n                                and not isinstance(build_link[key], six.string_types)):\n                           for item in build_link[key]:\n                                ignore_link = exclude_match(value, item)\n                        else:\n                            ignore_link = exclude_match(value, build_link[key])\n\n            if not duplicates:\n                for link in links:\n                    if link['href'] == anchor['href']:\n                        ignore_link = True\n\n            if not ignore_link:\n                links.append(build_link)\n\n            if limit is not None and len(links) == limit:\n                break\n\n        if sort is not None:\n            links = sorted(links, key=sort, reverse=reverse)\n\n        if pretty:\n            pp = pprint.PrettyPrinter(indent=4)\n            return pp.pprint(links)\n        else:\n            return links", "response": "This method searches the hyperlinks of the current page and returns a list of hyperlinks that are found in the web page."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning a script through the setkey command that is a user space insterface for PFKEY.", "response": "def run_setkey(input):\n    \"\"\"\n    Runs a script through the 'setkey' command that is a user space insterface for PFKEY.\n    :param input: setkey configuration file contents.\n    \"\"\"\n    SETKEY_BINARY = '/usr/sbin/setkey'\n    fd, filename = tempfile.mkstemp('w')\n    f = os.fdopen(fd, 'w')\n    f.write(input)\n    f.close()\n    output = subprocess.check_output(['sudo', SETKEY_BINARY, '-f', filename])\n    os.remove(filename)\n    return output.decode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_plot(fn: Path, cm, ax, alpha=1):\n\n    with fits.open(fn, mode='readonly', memmap=False) as f:\n        img = f[0].data\n\n        yPix, xPix = f[0].shape[-2:]\n        x, y = np.meshgrid(range(xPix), range(yPix))  # pixel indices to find RA/dec of\n        xy = np.column_stack((x.ravel(order='C'), y.ravel(order='C')))\n\n        radec = wcs.WCS(f[0].header).all_pix2world(xy, 0)\n\n    ra = radec[:, 0].reshape((yPix, xPix), order='C')\n    dec = radec[:, 1].reshape((yPix, xPix), order='C')\n\n    ax.set_title(fn.name)\n    ax.pcolormesh(ra, dec, img, alpha=alpha, cmap=cm, norm=LogNorm())\n    ax.set_ylabel('Right Ascension [deg.]')\n    ax.set_xlabel('Declination [deg.]')", "response": "Add a plot to the Astrometry. net plot."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef    fvga(a, i, g, n):\n    return a * ((((1 + i) ** n) - (((1 + g) ** n)))/(i - g))", "response": "This function is for the future value of an annuity\n    with growth rate."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef    dbal(c, s, r, l):\n    ad = 0\n    res = []\n    for x in range(l):\n        if x == (l -1):\n            dexp = (c - s -ad)\n        else: \n            dexp = (((c)/l)/(c) * r) * (c - ad)\n        res.append(dexp)\n        ad = ad + dexp\n    return res", "response": "This function computes the declining balance\n    depreciation for an asset with the given cost and price and the expected useful life span and salvage value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndumping a sequence of 4 octets into a hex string.", "response": "def dump(src):\n    \"\"\"\n    Returns data in hex format in groups of 4 octets delimited by spaces for debugging purposes.\n    \"\"\"\n    return b' '.join(binascii.hexlify(bytes(x)) for x in zip(src[::4], src[1::4], src[2::4], src[3::4]))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndisplays productpage with normal user and test user buttons", "response": "def index():\n    \"\"\" Display productpage with normal user and test user buttons\"\"\"\n    global productpage\n\n    table = json2html.convert(json = json.dumps(productpage),\n                              table_attributes=\"class=\\\"table table-condensed table-bordered table-hover\\\"\")\n\n    return render_template('index.html', serviceTable=table)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef gridrange(start, end, step):\n    for x in frange(start.real, end.real, step.real):\n        for y in frange(start.imag, end.imag, step.imag):\n            yield x + y * 1j", "response": "Generate a grid of complex numbers between start and end."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pad(data, blocksize=16):\n    padlen = blocksize - len(data) % blocksize\n    return bytes(data + bytearray(range(1, padlen)) + bytearray((padlen - 1,)))", "response": "Pads data to blocksize according to RFC 4303."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a FITS file to a RA and DEC dataset.", "response": "def fits2radec(fitsfn: Path, solve: bool=False, args: str=None) -> xarray.Dataset:\n\n    fitsfn = Path(fitsfn).expanduser()\n\n    if fitsfn.suffix == '.fits':\n        WCSfn = fitsfn.with_suffix('.wcs')  # using .wcs will also work but gives a spurious warning\n    elif fitsfn.suffix == '.wcs':\n        WCSfn = fitsfn\n    else:\n        raise ValueError(f'please convert {fitsfn} to GRAYSCALE .fits e.g. with ImageJ or ImageMagick')\n\n    if solve:\n        doSolve(fitsfn, args)\n\n    with fits.open(fitsfn, mode='readonly') as f:\n        yPix, xPix = f[0].shape[-2:]\n\n    x, y = meshgrid(range(xPix), range(yPix))  # pixel indices to find RA/dec of\n    xy = column_stack((x.ravel(order='C'), y.ravel(order='C')))\n# %% use astropy.wcs to register pixels to RA/DEC\n    \"\"\"\n    http://docs.astropy.org/en/stable/api/astropy.wcs.WCS.html#astropy.wcs.WCS\n    naxis=[0,1] is to take x,y axes in case a color photo was input e.g. to astrometry.net cloud solver\n    \"\"\"\n    try:\n        with fits.open(WCSfn, mode='readonly') as f:\n            # radec = wcs.WCS(hdul[0].header,naxis=[0,1]).all_pix2world(xy, 0)\n            radec = wcs.WCS(f[0].header).all_pix2world(xy, 0)\n    except OSError:\n        raise OSError(f'It appears the WCS solution is not present, was the FITS image solved?  looking for: {WCSfn}')\n\n    ra = radec[:, 0].reshape((yPix, xPix), order='C')\n    dec = radec[:, 1].reshape((yPix, xPix), order='C')\n# %% collect output\n    radec = xarray.Dataset({'ra': (('y', 'x'), ra),\n                            'dec': (('y', 'x'), dec), },\n                           {'x': range(xPix), 'y': range(yPix)},\n                           attrs={'filename': fitsfn})\n\n    return radec"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsolve Astrometry. net from at least version 0. 67 is OK with Python 3. is OK with Python 3. is OK with Python 3. is OK with Python 3. is OK with Python 3. is OK with Python 3. is OK with Python 3. is OK with Python 3. is OK with Python 3. is OK with Python 3. is OK with Python 3.", "response": "def doSolve(fitsfn: Path, args: str=None):\n    \"\"\"\n    Astrometry.net from at least version 0.67 is OK with Python 3.\n    \"\"\"\n    # binpath = Path(find_executable('solve-field')).parent\n    opts = args.split(' ') if args else []\n# %% build command\n    cmd = ['solve-field', '--overwrite', str(fitsfn)]\n    cmd += opts\n    print('\\n', ' '.join(cmd), '\\n')\n# %% execute\n    ret = subprocess.check_output(cmd, universal_newlines=True)\n\n    # solve-field returns 0 even if it didn't solve!\n    print(ret)\n    if 'Did not solve' in ret:\n        raise RuntimeError(f'could not solve {fitsfn}')\n\n    print('\\n\\n *** done with astrometry.net ***\\n ')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_rgb(hsv):\n    r, g, b = [int(min(255, max(0, component * 256)))\n               for component in colorsys.hsv_to_rgb(*hsv)]\n\n    return \"%02x%02x%02x\" % (r, g, b)", "response": "Converts a color from HSV to a hex RGB color value."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_scripts_to_package():\n    global setup_arguments\n\n    if os.path.isdir('scripts'):\n        setup_arguments['scripts'] = [\n            os.path.join('scripts', f) for f in os.listdir('scripts')\n        ]", "response": "Adds any scripts found in the scripts directory to the setup_arguments parameter."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the package metadata for this node.", "response": "def get_and_update_package_metadata():\n    \"\"\"\n    Update the package metadata for this package if we are building the package.\n    :return:metadata - Dictionary of metadata information\n    \"\"\"\n    global setup_arguments\n    global METADATA_FILENAME\n\n    if not os.path.exists('.git') and os.path.exists(METADATA_FILENAME):\n        with open(METADATA_FILENAME) as fh:\n            metadata = json.load(fh)\n    else:\n        git = Git(version=setup_arguments['version'])\n        metadata = {\n            'version': git.version,\n            'long_description': 'Tool to pip install missing imports and more',\n            'git_hash': git.hash,\n            'git_origin': git.origin,\n            'git_branch': git.branch\n        }\n        for readme_file in ['README.rst', 'README.md', 'README.txt']:\n            if os.path.exists(readme_file):\n                with open(readme_file) as file_handle:\n                    metadata['long_description'] = file_handle.read()\n                break\n        with open(METADATA_FILENAME, 'w') as fh:\n            json.dump(metadata, fh)\n    return metadata"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating a Unique version value from the git information", "response": "def version(self):\n        \"\"\"\n        Generate a Unique version value from the git information\n        :return:\n        \"\"\"\n        git_rev = len(os.popen('git rev-list HEAD').readlines())\n        if git_rev != 0:\n            self.version_list[-1] = '%d' % git_rev\n        version = '.'.join(self.version_list)\n        return version"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the fetch url for the git origin", "response": "def origin(self):\n        \"\"\"\n        Return the fetch url for the git origin\n        :return:\n        \"\"\"\n        for item in os.popen('git remote -v'):\n            split_item = item.strip().split()\n            if split_item[0] == 'origin' and split_item[-1] == '(push)':\n                return split_item[1]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef verbosityToLogLevel(verbosity):\n    ret = 0\n    if verbosity == 1:\n        ret = logging.INFO\n    elif verbosity >= 2:\n        ret = logging.DEBUG\n    return ret", "response": "Returns the specfied verbosity level interpreted as a logging level."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd common options to a sequence of variant searches command line arguments.", "response": "def addVariantSearchOptions(parser):\n    \"\"\"\n    Adds common options to a variant searches command line parser.\n    \"\"\"\n    addVariantSetIdArgument(parser)\n    addReferenceNameArgument(parser)\n    addCallSetIdsArgument(parser)\n    addStartArgument(parser)\n    addEndArgument(parser)\n    addPageSizeArgument(parser)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds common options to an annotation searches command line parser.", "response": "def addAnnotationsSearchOptions(parser):\n    \"\"\"\n    Adds common options to a annotation searches command line parser.\n    \"\"\"\n    addAnnotationSetIdArgument(parser)\n    addReferenceNameArgument(parser)\n    addReferenceIdArgument(parser)\n    addStartArgument(parser)\n    addEndArgument(parser)\n    addEffectsArgument(parser)\n    addPageSizeArgument(parser)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef addFeaturesSearchOptions(parser):\n    addFeatureSetIdArgument(parser)\n    addFeaturesReferenceNameArgument(parser)\n    addStartArgument(parser)\n    addEndArgument(parser)\n    addParentFeatureIdArgument(parser)\n    addFeatureTypesArgument(parser)", "response": "Adds common options to a features search command line parser."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds common options to a continuous search command line parser.", "response": "def addContinuousSearchOptions(parser):\n    \"\"\"\n    Adds common options to a continuous search command line parser.\n    \"\"\"\n    addContinuousSetIdArgument(parser)\n    addContinuousReferenceNameArgument(parser)\n    addStartArgument(parser)\n    addEndArgument(parser)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef addGenotypePhenotypeSearchOptions(parser):\n    parser.add_argument(\n        \"--phenotype_association_set_id\", \"-s\", default=None,\n        help=\"Only return associations from this phenotype_association_set.\")\n    parser.add_argument(\n        \"--feature_ids\", \"-f\", default=None,\n        help=\"Only return associations for these features.\")\n    parser.add_argument(\n        \"--phenotype_ids\", \"-p\", default=None,\n        help=\"Only return associations for these phenotypes.\")\n    parser.add_argument(\n        \"--evidence\", \"-E\", default=None,\n        help=\"Only return associations to this evidence.\")", "response": "Adds options to a g2p searches command line parser."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding options to a phenotype searches command line parser.", "response": "def addPhenotypeSearchOptions(parser):\n    \"\"\"\n    Adds options to a phenotype searches command line parser.\n    \"\"\"\n    parser.add_argument(\n        \"--phenotype_association_set_id\", \"-s\", default=None,\n        help=\"Only return phenotypes from this phenotype_association_set.\")\n    parser.add_argument(\n        \"--phenotype_id\", \"-p\", default=None,\n        help=\"Only return this phenotype.\")\n    parser.add_argument(\n        \"--description\", \"-d\", default=None,\n        help=\"Only return phenotypes matching this description.\")\n    parser.add_argument(\n        \"--age_of_onset\", \"-a\", default=None,\n        help=\"Only return phenotypes with this age_of_onset.\")\n    parser.add_argument(\n        \"--type\", \"-T\", default=None,\n        help=\"Only return phenotypes with this type.\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\noutputting a text summary of the specified protocol objects one ArcGIS object per line.", "response": "def _textOutput(self, gaObjects):\n        \"\"\"\n        Outputs a text summary of the specified protocol objects, one\n        per line.\n        \"\"\"\n        for gaObject in gaObjects:\n            if hasattr(gaObject, 'name'):\n                print(gaObject.id, gaObject.name, sep=\"\\t\")\n            else:\n                print(gaObject.id, sep=\"\\t\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning all variant sets on the server.", "response": "def getAllVariantSets(self):\n        \"\"\"\n        Returns all variant sets on the server.\n        \"\"\"\n        for dataset in self.getAllDatasets():\n            iterator = self._client.search_variant_sets(\n                dataset_id=dataset.id)\n            for variantSet in iterator:\n                yield variantSet"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getAllFeatureSets(self):\n        for dataset in self.getAllDatasets():\n            iterator = self._client.search_feature_sets(\n                dataset_id=dataset.id)\n            for featureSet in iterator:\n                yield featureSet", "response": "Returns all feature sets on the server."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getAllContinuousSets(self):\n        for dataset in self.getAllDatasets():\n            iterator = self._client.search_continuous_sets(\n                dataset_id=dataset.id)\n            for continuousSet in iterator:\n                yield continuousSet", "response": "Returns all continuous sets on the server."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn all readgroup sets on the server.", "response": "def getAllReadGroupSets(self):\n        \"\"\"\n        Returns all readgroup sets on the server.\n        \"\"\"\n        for dataset in self.getAllDatasets():\n            iterator = self._client.search_read_group_sets(\n                dataset_id=dataset.id)\n            for readGroupSet in iterator:\n                yield readGroupSet"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget all read groups in a read group set", "response": "def getAllReadGroups(self):\n        \"\"\"\n        Get all read groups in a read group set\n        \"\"\"\n        for dataset in self.getAllDatasets():\n            iterator = self._client.search_read_group_sets(\n                dataset_id=dataset.id)\n            for readGroupSet in iterator:\n                readGroupSet = self._client.get_read_group_set(\n                    readGroupSet.id)\n                for readGroup in readGroupSet.read_groups:\n                    yield readGroup.id"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprint out the specified Variant objects in a VCF - like form.", "response": "def _textOutput(self, gaObjects):\n        \"\"\"\n        Prints out the specified Variant objects in a VCF-like form.\n        \"\"\"\n        for variant in gaObjects:\n            print(\n                variant.id, variant.variant_set_id, variant.names,\n                variant.reference_name, variant.start, variant.end,\n                variant.reference_bases, variant.alternate_bases,\n                sep=\"\\t\", end=\"\\t\")\n            for key, value in variant.attributes.attr.items():\n                val = value.values[0].string_value\n                print(key, val, sep=\"=\", end=\";\")\n            print(\"\\t\", end=\"\")\n            for c in variant.calls:\n                print(\n                    c.call_set_id,\n                    c.genotype.__str__().replace('\\n', ''),\n                    c.genotype_likelihood, c.attributes,\n                    c.phaseset, sep=\":\", end=\"\\t\")\n            print()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _textOutput(self, gaObjects):\n        for variantAnnotation in gaObjects:\n            print(\n                variantAnnotation.id, variantAnnotation.variant_id,\n                variantAnnotation.variant_annotation_set_id,\n                variantAnnotation.created, sep=\"\\t\", end=\"\\t\")\n            for effect in variantAnnotation.transcript_effects:\n                print(effect.alternate_bases, sep=\"|\", end=\"|\")\n                for so in effect.effects:\n                    print(so.term, sep=\"&\", end=\"|\")\n                    print(so.term_id, sep=\"&\", end=\"|\")\n                print(effect.hgvs_annotation.transcript,\n                      effect.hgvs_annotation.protein, sep=\"|\", end=\"\\t\")\n            print()", "response": "Print out the specified Variant objects in a VCF - like form."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getAllAnnotationSets(self):\n        for variantSet in self.getAllVariantSets():\n            iterator = self._client.search_variant_annotation_sets(\n                variant_set_id=variantSet.id)\n            for variantAnnotationSet in iterator:\n                yield variantAnnotationSet", "response": "Returns an iterator over all the variant annotation sets on the server."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _run(self, referenceGroupId, referenceId=None):\n        # check if we can get reference id from rg\n        if referenceId is None:\n            referenceId = self._referenceId\n        if referenceId is None:\n            rg = self._client.get_read_group(\n                read_group_id=referenceGroupId)\n            iterator = self._client.search_references(rg.reference_set_id)\n            for reference in iterator:\n                self._run(referenceGroupId, reference.id)\n        else:\n            iterator = self._client.search_reads(\n                read_group_ids=[referenceGroupId],\n                reference_id=referenceId,\n                start=self._start, end=self._end)\n            self._output(iterator)", "response": "Run the search API."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\niterates passed read group ids and run all available read groups.", "response": "def run(self):\n        \"\"\"\n        Iterate passed read group ids, or go through all available read groups\n        \"\"\"\n        if not self._readGroupIds:\n            for referenceGroupId in self.getAllReadGroups():\n                self._run(referenceGroupId)\n        else:\n            for referenceGroupId in self._readGroupIds:\n                self._run(referenceGroupId)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextracting the text from the various sections of a numpy - formatted docstring.", "response": "def parse_napoleon_doc(doc, style):\n    \"\"\" Extract the text from the various sections of a numpy-formatted docstring.\n\n        Parameters\n        ----------\n        doc: Union[str, None]\n            The docstring to parse.\n\n        style: str\n            'google' or 'numpy'\n\n        Returns\n        -------\n        OrderedDict[str, Union[None,str]]\n            The extracted numpy-styled docstring sections.\"\"\"\n\n    napoleon_sections = [\"Short Summary\", \"Attributes\", \"Methods\", \"Warning\", \"Note\", \"Parameters\", \"Other Parameters\",\n                         \"Keyword Arguments\", \"Returns\", \"Yields\", \"Raises\", \"Warns\", \"See Also\", \"References\", \"Todo\",\n                         \"Example\", \"Examples\"]\n\n    aliases = {\"Args\": \"Parameters\", \"Arguments\": \"Parameters\", \"Keyword Args\": \"Keyword Arguments\",\n               \"Return\": \"Returns\", \"Warnings\": \"Warning\", \"Yield\": \"Yields\"}\n\n    doc_sections = OrderedDict([(key, None) for key in napoleon_sections])\n\n    if not doc:\n        return doc_sections\n\n    assert style in (\"google\", \"numpy\")\n\n    doc = cleandoc(doc)\n    lines = iter(doc.splitlines())\n\n    key = \"Short Summary\"\n    body = []\n    while True:\n        try:\n            line = next(lines).rstrip()\n            header = line if style == \"numpy\" else (line[:-1] if line.endswith(\":\") else line)\n            if header and (header in doc_sections or header in aliases):\n                doc_sections[aliases.get(key, key)] = \"\\n\".join(body).rstrip() if body else None\n                body = []\n                key = header\n                if style == \"numpy\":\n                    next(lines)  # skip section delimiter\n            else:\n                body.append(line)\n        except StopIteration:\n            doc_sections[aliases.get(key, key)] = \"\\n\".join(body)\n            break\n    return doc_sections"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmerges the doc - sections of the parent s and child s attributes into a single docstring.", "response": "def merge_all_sections(prnt_sctns, child_sctns, style):\n    \"\"\" Merge the doc-sections of the parent's and child's attribute into a single docstring.\n\n        Parameters\n        ----------\n        prnt_sctns: OrderedDict[str, Union[None,str]]\n        child_sctns: OrderedDict[str, Union[None,str]]\n\n        Returns\n        -------\n        str\n            Output docstring of the merged docstrings.\"\"\"\n    doc = []\n\n    prnt_only_raises = prnt_sctns[\"Raises\"] and not (prnt_sctns[\"Returns\"] or prnt_sctns[\"Yields\"])\n    if prnt_only_raises and (child_sctns[\"Returns\"] or child_sctns[\"Yields\"]):\n        prnt_sctns[\"Raises\"] = None\n\n    for key in prnt_sctns:\n        sect = merge_section(key, prnt_sctns[key], child_sctns[key], style)\n        if sect is not None:\n            doc.append(sect)\n    return \"\\n\\n\".join(doc) if doc else None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef merge_numpy_napoleon_docs(prnt_doc=None, child_doc=None):\n    style = \"numpy\"\n    return merge_all_sections(parse_napoleon_doc(prnt_doc, style), parse_napoleon_doc(child_doc, style), style)", "response": "Merge two numpy - style docstrings into a single docstring."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmerges two google - style docstrings into a single docstring.", "response": "def merge_google_napoleon_docs(prnt_doc=None, child_doc=None):\n    \"\"\" Merge two google-style docstrings into a single docstring, according to napoleon docstring sections.\n\n        Given the google-style docstrings from a parent and child's attributes, merge the docstring\n        sections such that the child's section is used, wherever present, otherwise the parent's\n        section is used.\n\n        Any whitespace that can be uniformly removed from a docstring's second line and onwards is\n        removed. Sections will be separated by a single blank line.\n\n        Aliased docstring sections are normalized. E.g Args, Arguments -> Parameters\n\n        Parameters\n        ----------\n        prnt_doc: Optional[str]\n            The docstring from the parent.\n        child_doc: Optional[str]\n            The docstring from the child.\n\n        Returns\n        -------\n        Union[str, None]\n            The merged docstring. \"\"\"\n    style = \"google\"\n    return merge_all_sections(parse_napoleon_doc(prnt_doc, style), parse_napoleon_doc(child_doc, style), style)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds a mapping between two common coordinates in x1 and x2.", "response": "def find_map( x1, x2, eps = 1e-8, allow_double = False, join = True ):\n    \"\"\"\n    Find a mapping between common coordinates in x1 and x2, such that\n    x1[cmap[:,0]] == x2[cmap[:,1]]\n    \"\"\"\n    off, dim = x1.shape\n    ir = nm.zeros( (off + x2.shape[0],), dtype = nm.int32 )\n    ir[off:] = off\n\n    x1 = nm.round( x1.T / eps ) * eps\n    x2 = nm.round( x2.T / eps ) * eps\n    xx = nm.c_[x1, x2]\n\n    keys = [xx[ii] for ii in range( dim )]\n    iis = nm.lexsort( keys = keys )\n\n    xs = xx.T[iis]\n##     import scipy.io as io\n##     io.write_array( 'sss1', x1.T )\n##     io.write_array( 'sss2', x2.T )\n##     io.write_array( 'sss', xs, precision = 16 )\n##     pause()\n    xd = nm.sqrt( nm.sum( nm.diff( xs, axis = 0 )**2.0, axis = 1 ) )\n\n    ii = nm.where( xd < eps )[0]\n    off1, off2 = ir[iis][ii], ir[iis][ii+1]\n    i1, i2 = iis[ii] - off1, iis[ii+1] - off2\n    dns = nm.where( off1 == off2 )[0]\n    if dns.size:\n        print 'double node(s) in:'\n        for dn in dns:\n            if off1[dn] == 0:\n                print 'x1: %d %d -> %s %s' % (i1[dn], i2[dn],\n                                              x1[:,i1[dn]], x1[:,i2[dn]])\n            else:\n                print 'x2: %d %d -> %s %s' % (i1[dn], i2[dn],\n                                              x2[:,i1[dn]], x2[:,i2[dn]])\n        if not allow_double:\n            raise ValueError\n\n    if join:\n        cmap = nm.c_[i1, i2]\n        return cmap\n    else:\n        return i1, i2"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef merge_mesh( x1, ngroups1, conns1, x2, ngroups2, conns2, cmap, eps = 1e-8 ):\n    n1 = x1.shape[0]\n    n2 = x2.shape[0]\n\n    err = nm.sum( nm.sum( nm.abs( x1[cmap[:,0],:-1] - x2[cmap[:,1],:-1] ) ) )\n    if abs( err ) > (10.0 * eps):\n        print 'nonmatching meshes!', err\n        raise ValueError\n\n    mask = nm.ones( (n2,), dtype = nm.int32 )\n    mask[cmap[:,1]] = 0\n#    print mask, nm.cumsum( mask )\n    remap = nm.cumsum( mask ) + n1 - 1\n    remap[cmap[:,1]] = cmap[:,0]\n#    print remap\n\n    i2 = nm.setdiff1d( nm.arange(  n2, dtype = nm.int32 ),\n                       cmap[:,1] )\n    xx = nm.r_[x1, x2[i2]]\n    ngroups = nm.r_[ngroups1, ngroups2[i2]]\n\n    conns = []\n    for ii in xrange( len( conns1 ) ):\n        conn = nm.vstack( (conns1[ii], remap[conns2[ii]]) )\n        conns.append( conn )\n    \n    return xx, ngroups, conns", "response": "Merge two meshes in common coordinates found in x1 x2."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndetects and attempt to fix double nodes in a mesh.", "response": "def fix_double_nodes(coor, ngroups, conns, eps):\n    \"\"\"\n    Detect and attempt fixing double nodes in a mesh.\n\n    The double nodes are nodes having the same coordinates\n    w.r.t. precision given by `eps`.\n    \"\"\"\n    n_nod, dim = coor.shape\n    cmap = find_map( coor, nm.zeros( (0,dim) ), eps = eps, allow_double = True )\n    if cmap.size:\n        output('double nodes in input mesh!')\n        output('trying to fix...')\n\n        while cmap.size:\n            print cmap.size\n\n            # Just like in Variable.equation_mapping()...\n            ii = nm.argsort( cmap[:,1] )\n            scmap = cmap[ii]\n\n            eq = nm.arange( n_nod )\n            eq[scmap[:,1]] = -1\n            eqi = eq[eq >= 0]\n            eq[eqi] = nm.arange( eqi.shape[0] )\n            remap = eq.copy()\n            remap[scmap[:,1]] = eq[scmap[:,0]]\n            print coor.shape\n            coor = coor[eqi]\n            ngroups = ngroups[eqi]\n            print coor.shape\n            ccs = []\n            for conn in conns:\n                ccs.append( remap[conn] )\n            conns = ccs\n            cmap = find_map( coor, nm.zeros( (0,dim) ), eps = eps,\n                            allow_double = True )\n        output('...done')\n    return coor, ngroups, conns"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the smallest edge length.", "response": "def get_min_edge_size(coor, conns):\n    \"\"\"\n    Get the smallest edge length.\n    \"\"\"\n    mes = 1e16\n    for conn in conns:\n        n_ep = conn.shape[1]\n        for ir in range( n_ep ):\n            x1 = coor[conn[:,ir]]\n            for ic in range( ir + 1, n_ep ):\n                x2 = coor[conn[:,ic]]\n                aux = nm.sqrt( nm.sum( (x2 - x1)**2.0, axis = 1 ).min() )\n                mes = min( mes, aux )\n\n    return mes"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the minimum vertex distance from a coor.", "response": "def get_min_vertex_distance( coor, guess ):\n    \"\"\"Can miss the minimum, but is enough for our purposes.\"\"\"\n    # Sort by x.\n    ix = nm.argsort( coor[:,0] )\n    scoor = coor[ix]\n\n    mvd = 1e16\n    \n    # Get mvd in chunks potentially smaller than guess.\n    n_coor = coor.shape[0]\n    print n_coor\n    \n    i0 = i1 = 0\n    x0 = scoor[i0,0]\n    while 1:\n        while ((scoor[i1,0] - x0) < guess) and (i1 < (n_coor - 1)):\n            i1 += 1\n\n#        print i0, i1, x0, scoor[i1,0]\n        aim, aa1, aa2, aux = get_min_vertex_distance_naive( scoor[i0:i1+1] )\n        if aux < mvd:\n            im, a1, a2 = aim, aa1 + i0, aa2 + i0\n        mvd = min( mvd, aux )\n        i0 = i1 = int( 0.5 * (i1 + i0 ) ) + 1\n#        i0 += 1\n        x0 = scoor[i0,0]\n#        print '-', i0\n\n        if i1 == n_coor - 1: break\n\n    print im, ix[a1], ix[a2], a1, a2, scoor[a1], scoor[a2]\n\n    return mvd"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_mesh( coor, ngroups, conns, mesh_in ):\n    mat_ids = []\n    for ii, conn in enumerate( conns ):\n        mat_id = nm.empty( (conn.shape[0],), dtype = nm.int32 )\n        mat_id.fill( mesh_in.mat_ids[ii][0] )\n        mat_ids.append( mat_id )\n        \n    mesh_out = Mesh.from_data( 'merged mesh', coor, ngroups, conns,\n                               mat_ids, mesh_in.descs )\n    return mesh_out", "response": "Create a mesh reusing mat_ids and descs of mesh_in."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_inverse_connectivity(conns, n_nod, ret_offsets=True):\n    from itertools import chain\n\n    iconn = [[] for ii in xrange( n_nod )]\n    n_els = [0] * n_nod\n    for ig, conn in enumerate( conns ):\n        for iel, row in enumerate( conn ):\n            for node in row:\n                iconn[node].extend([ig, iel])\n                n_els[node] += 1\n\n    n_els = nm.array(n_els, dtype=nm.int32)\n    iconn = nm.fromiter(chain(*iconn), nm.int32)\n\n    if ret_offsets:\n        offsets = nm.cumsum(nm.r_[0, n_els], dtype=nm.int32)\n        return offsets, iconn\n\n    else:\n        return n_els, iconn", "response": "Given a list of mesh nodes and a number of mesh nodes return the list of the edges and the list of the edges that are in the topology."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a mesh given a set of surface faces and a original mesh.", "response": "def from_surface( surf_faces, mesh_in ):\n        \"\"\"\n        Create a mesh given a set of surface faces and the original mesh.\n        \"\"\"\n        aux = nm.concatenate([faces.ravel() for faces in surf_faces])\n        inod = nm.unique(aux)\n\n        n_nod = len( inod )\n        n_nod_m, dim = mesh_in.coors.shape\n\n        aux = nm.arange( n_nod, dtype=nm.int32 )\n        remap = nm.zeros( (n_nod_m,), nm.int32 )\n        remap[inod] = aux\n\n        mesh = Mesh( mesh_in.name + \"_surf\" )\n\n        mesh.coors = mesh_in.coors[inod]\n        mesh.ngroups = mesh_in.ngroups[inod]\n\n        sfm = {3 : \"2_3\", 4 : \"2_4\"}\n        mesh.conns = []\n        mesh.descs = []\n        mesh.mat_ids = []\n        for ii, sf in enumerate( surf_faces ):\n            n_el, n_fp = sf.shape\n\n            conn = remap[sf]\n            mat_id = nm.empty( (conn.shape[0],), dtype = nm.int32 )\n            mat_id.fill( ii )\n\n            mesh.descs.append( sfm[n_fp] )\n            mesh.conns.append( conn )\n            mesh.mat_ids.append( mat_id )\n\n        mesh._set_shape_info()\n        \n        return mesh"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading a mesh from a file.", "response": "def from_file(filename=None, io='auto', prefix_dir=None,\n                  omit_facets=False):\n        \"\"\"\n        Read a mesh from a file.\n\n        Parameters\n        ----------\n        filename : string or function or MeshIO instance or Mesh instance\n            The name of file to read the mesh from. For convenience, a\n            mesh creation function or a MeshIO instance or directly a Mesh\n            instance can be passed in place of the file name.\n        io : *MeshIO instance\n            Passing *MeshIO instance has precedence over filename.\n        prefix_dir : str\n            If not None, the filename is relative to that directory.\n        omit_facets : bool\n            If True, do not read cells of lower dimension than the space\n            dimension (faces and/or edges). Only some MeshIO subclasses\n            support this!\n        \"\"\"\n        if isinstance(filename, Mesh):\n            return filename\n\n        if io == 'auto':\n            if filename is None:\n                output( 'filename or io must be specified!' )\n                raise ValueError\n            else:\n                io = MeshIO.any_from_filename(filename, prefix_dir=prefix_dir)\n\n        output('reading mesh (%s)...' % (io.filename))\n        tt = time.clock()\n\n        trunk = io.get_filename_trunk()\n        mesh = Mesh(trunk)\n        mesh = io.read(mesh, omit_facets=omit_facets)\n\n        output('...done in %.2f s' % (time.clock() - tt))\n\n        mesh._set_shape_info()\n\n        return mesh"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_region(region, mesh_in, save_edges=False, save_faces=False,\n                    localize=False, is_surface=False):\n        \"\"\"\n        Create a mesh corresponding to a given region.\n        \"\"\"\n        mesh = Mesh( mesh_in.name + \"_reg\" )\n        mesh.coors = mesh_in.coors.copy()\n        mesh.ngroups = mesh_in.ngroups.copy()\n\n        mesh.conns = []\n        mesh.descs = []\n        mesh.mat_ids = []\n\n        if not is_surface:\n            if region.has_cells():\n                for ig in region.igs:\n                    mesh.descs.append( mesh_in.descs[ig] )\n                    els = region.get_cells( ig )\n                    mesh.mat_ids.append( mesh_in.mat_ids[ig][els,:].copy() )\n                    mesh.conns.append( mesh_in.conns[ig][els,:].copy() )\n\n            if save_edges:\n                ed = region.domain.ed\n                for ig in region.igs:\n                    edges = region.get_edges( ig )\n                    mesh.descs.append( '1_2' )\n                    mesh.mat_ids.append( ed.data[edges,0] + 1 )\n                    mesh.conns.append( ed.data[edges,-2:].copy() )\n\n            if save_faces:\n                mesh._append_region_faces(region)\n\n            if save_edges or save_faces:\n                mesh.descs.append( {2 : '2_3', 3 : '3_4'}[mesh_in.dim] )\n                mesh.mat_ids.append( -nm.ones_like( region.all_vertices ) )\n                mesh.conns.append(make_point_cells(region.all_vertices,\n                                                   mesh_in.dim))\n\n        else:\n            mesh._append_region_faces(region, force_faces=True)\n\n        mesh._set_shape_info()\n\n        if localize:\n            mesh.localize( region.all_vertices )\n\n        return mesh", "response": "Create a new mesh corresponding to a given region."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a mesh from data.", "response": "def from_data( name, coors, ngroups, conns, mat_ids, descs, igs = None ):\n        \"\"\"\n        Create a mesh from mesh data.\n        \"\"\"\n        if igs is None:\n            igs = range( len( conns ) )\n        mesh = Mesh(name)\n        mesh._set_data(coors = coors,\n                       ngroups = ngroups,\n                       conns = [conns[ig] for ig in igs],\n                       mat_ids = [mat_ids[ig] for ig in igs],\n                       descs = [descs[ig] for ig in igs])\n        mesh._set_shape_info()\n        return mesh"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef copy(self, name=None):\n        return Struct.copy(self, deep=True, name=name)", "response": "Make a deep copy of self."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_data(self, coors, ngroups, conns, mat_ids, descs, nodal_bcs=None):\n        self.coors = nm.ascontiguousarray(coors)\n\n        if ngroups is None:\n            self.ngroups = nm.zeros((self.coors.shape[0],), dtype=nm.int32)\n\n        else:\n            self.ngroups = nm.ascontiguousarray(ngroups)\n\n        self.conns = [nm.asarray(conn, dtype=nm.int32) for conn in conns]\n        self.mat_ids = [nm.asarray(mat_id, dtype=nm.int32)\n                        for mat_id in mat_ids]\n        self.descs = descs\n        self.nodal_bcs = get_default(nodal_bcs, {})", "response": "Set the data for the current object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites the current object to a file.", "response": "def write(self, filename=None, io=None,\n              coors=None, igs=None, out=None, float_format=None, **kwargs):\n        \"\"\"\n        Write mesh + optional results in `out` to a file.\n\n        Parameters\n        ----------\n        filename : str, optional\n            The file name. If None, the mesh name is used instead.\n        io : MeshIO instance or 'auto', optional\n            Passing 'auto' respects the extension of `filename`.\n        coors : array, optional\n            The coordinates that can be used instead of the mesh coordinates.\n        igs : array_like, optional\n            Passing a list of group ids selects only those groups for writing.\n        out : dict, optional\n            The output data attached to the mesh vertices and/or cells.\n        float_format : str, optional\n            The format string used to print floats in case of a text file\n            format.\n        **kwargs : dict, optional\n            Additional arguments that can be passed to the `MeshIO` instance.\n        \"\"\"\n        if filename is None:\n            filename = self.name + '.mesh'\n\n        if io is None:\n            io = self.io\n            if io is None:\n                io = 'auto'\n\n        if io == 'auto':\n            io = MeshIO.any_from_filename( filename )\n\n        if coors is None:\n            coors = self.coors\n\n        if igs is None:\n            igs = range( len( self.conns ) )\n\n        aux_mesh = Mesh.from_data( self.name, coors, self.ngroups,\n                                   self.conns, self.mat_ids, self.descs, igs )\n        io.set_float_format( float_format )\n        io.write( filename, aux_mesh, out, **kwargs )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_element_coors(self, ig=None):\n        cc = self.coors\n        n_ep_max = self.n_e_ps.max()\n\n        coors = nm.empty((self.n_el, n_ep_max, self.dim), dtype=cc.dtype)\n        for ig, conn in enumerate(self.conns):\n            i1, i2 = self.el_offsets[ig], self.el_offsets[ig + 1]\n            coors[i1:i2, :conn.shape[1], :] = cc[conn]\n\n        return coors", "response": "Get the coordinates of vertices elements in group ig."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef localize(self, inod):\n        remap = nm.empty((self.n_nod,), dtype=nm.int32)\n        remap.fill(-1)\n        remap[inod] = nm.arange(inod.shape[0], dtype=nm.int32)\n\n        self.coors = self.coors[inod]\n        self.ngroups = self.ngroups[inod]\n        conns = []\n        mat_ids = []\n        for ig, conn in enumerate(self.conns):\n            if conn.shape[0] == 0:\n                continue\n\n            aux = remap[conn]\n            ii = nm.unique(nm.where(aux == -1)[0])\n            ii = nm.setdiff1d(nm.arange(conn.shape[0], dtype=nm.int32), ii)\n            conns.append(aux[ii])\n            mat_ids.append(self.mat_ids[ig][ii])\n        self.conns = conns\n        self.mat_ids = mat_ids\n\n        self._set_shape_info()", "response": "Localize the internal state of the inod."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef transform_coors(self, mtx_t, ref_coors=None):\n        if ref_coors is None:\n            ref_coors = self.coors\n\n        if mtx_t.shape[1] > self.coors.shape[1]:\n            self.coors[:] = nm.dot(ref_coors, mtx_t[:,:-1].T) + mtx_t[:,-1]\n        else:\n            self.coors[:] = nm.dot(ref_coors, mtx_t.T)", "response": "Transform coordinates of the mesh by the given transformation matrix."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef explode_groups(self, eps, return_emap=False):\n        assert_(0.0 <= eps <= 1.0)\n\n        remap = nm.empty((self.n_nod,), dtype=nm.int32)\n        offset = 0\n\n        if return_emap:\n            rows, cols = [], []\n\n        coors = []\n        ngroups = []\n        conns = []\n        mat_ids = []\n        descs = []\n        for ig, conn in enumerate(self.conns):\n            nodes = nm.unique(conn)\n            group_coors = self.coors[nodes]\n            n_nod = group_coors.shape[0]\n\n            centre = group_coors.sum(axis=0) / float(n_nod)\n            vectors = group_coors - centre[None, :]\n            new_coors = centre + (vectors * eps)\n\n            remap[nodes] = nm.arange(n_nod, dtype=nm.int32) + offset\n            new_conn = remap[conn]\n\n            coors.append(new_coors)\n            ngroups.append(self.ngroups[nodes])\n\n            conns.append(new_conn)\n            mat_ids.append(self.mat_ids[ig])\n            descs.append(self.descs[ig])\n\n            offset += n_nod\n\n            if return_emap:\n                cols.append(nodes)\n                rows.append(remap[nodes])\n\n        coors = nm.concatenate(coors, axis=0)\n        ngroups = nm.concatenate(ngroups, axis=0)\n\n        mesh = Mesh.from_data('exploded_' + self.name,\n                              coors, ngroups, conns, mat_ids, descs)\n\n        if return_emap:\n            rows = nm.concatenate(rows)\n            cols = nm.concatenate(cols)\n            data = nm.ones(rows.shape[0], dtype=nm.float64)\n\n            emap = sp.coo_matrix((data, (rows, cols)),\n                                 shape=(mesh.n_nod, self.n_nod))\n\n            return mesh, emap\n\n        else:\n            return mesh", "response": "Explode the group of the mesh element by eps."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads message from the server", "response": "def _read_message(self):\n        \"\"\"\n        \u5fc5\u987b\u542f\u52a8\u65b0\u7684greenlet\uff0c\u5426\u5219\u4f1a\u6709\u5185\u5b58\u6cc4\u6f0f\n        \"\"\"\n        job = gevent.spawn(super(GConnection, self)._read_message)\n        job.join()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets method that will set the timer and call the callback if repeat is True", "response": "def set(self, interval, callback, repeat=False, force=True):\n        \"\"\"\n        \u6dfb\u52a0timer\n        \"\"\"\n        if self.timer:\n            if force:\n                # \u5982\u679c\u5df2\u7ecf\u5b58\u5728\uff0c\u90a3\u4e48\u5148\u8981\u628a\u73b0\u5728\u7684\u6e05\u7a7a\n                self.clear()\n            else:\n                # \u5df2\u7ecf\u5b58\u5728\u7684\u8bdd\uff0c\u5c31\u8fd4\u56de\u4e86\n                return\n\n        def callback_wrapper():\n            # \u5fc5\u987b\u8981\u786e\u5b9a\uff0c\u8fd9\u6b21\u8c03\u7528\u5c31\u662f\u8fd9\u4e2atimer\u5f15\u8d77\u7684\n            if self.timer == timer:\n                # \u5fc5\u987b\u52a0\u8fd9\u53e5\uff0c\u5426\u5219\u5982\u679c\u5728callback\u4e2d\u6709clear\u64cd\u4f5c\uff0c\u4f1a\u51fa\u73b0GreenletExit\n                self.timer = None\n                # \u4e0d\u53ef\u4ee5\u52a0 timer = None\uff0c\u5426\u5219\u4f1a\u5bfc\u81f4\u5224\u65adself.timer == timer \u62a5\u9519\u627e\u4e0d\u5230timer\n                result = safe_call(callback)\n                if repeat and not self.timer:\n                    # \u4e4b\u6240\u4ee5\u8fd8\u8981\u5224\u65adtimer\uff0c\u662f\u56e0\u4e3acallback\u4e2d\u53ef\u80fd\u8bbe\u7f6e\u4e86\u65b0\u7684\u56de\u8c03\n                    self.set(interval, callback, repeat, True)\n                return result\n\n        self.timer = timer = gevent.spawn_later(interval, callback_wrapper)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef join_conn_groups( conns, descs, mat_ids, concat = False ):\n\n    el = dict_from_keys_init( descs, list )\n    for ig, desc in enumerate( descs ):\n        el[desc].append( ig )\n    groups = [ii for ii in el.values() if ii]\n##     print el, groups\n\n    descs_out, conns_out, mat_ids_out = [], [], []\n    for group in groups:\n        n_ep = conns[group[0]].shape[1]\n\n        conn = nm.zeros( (0, n_ep), nm.int32 )\n        mat_id = nm.zeros( (0,), nm.int32 )\n        for ig in group:\n            conn = nm.concatenate( (conn, conns[ig]) )\n            mat_id = nm.concatenate( (mat_id, mat_ids[ig]) )\n\n        if concat:\n            conn = nm.concatenate( (conn, mat_id[:,nm.newaxis]), 1 )\n        else:\n            mat_ids_out.append( mat_id )\n        conns_out.append( conn )\n        descs_out.append( descs[group[0]] )\n\n    if concat:\n        return conns_out, descs_out\n    else:\n        return conns_out, descs_out, mat_ids_out", "response": "Join groups of the same element type."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting complex values in the output dictionary out_in to pairs of real and imaginary parts.", "response": "def convert_complex_output(out_in):\n    \"\"\"\n    Convert complex values in the output dictionary `out_in` to pairs of\n    real and imaginary parts.\n    \"\"\"\n    out = {}\n    for key, val in out_in.iteritems():\n\n        if val.data.dtype in  complex_types:\n            rval = copy(val)\n            rval.data = val.data.real\n            out['real(%s)' % key] = rval\n\n            ival = copy(val)\n            ival.data = val.data.imag\n            out['imag(%s)' % key] = ival\n\n        else:\n            out[key] = val\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef guess_format( filename, ext, formats, io_table ):\n    ok = False\n    for format in formats:\n        output( 'guessing %s' % format )\n        try:\n            ok = io_table[format].guess( filename )\n        except AttributeError:\n            pass\n        if ok: break\n\n    else:\n        raise NotImplementedError('cannot guess format of a *%s file!' % ext)\n\n    return format", "response": "Guess the format of a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef any_from_filename(filename, prefix_dir=None):\n    if not isinstance(filename, basestr):\n        if isinstance(filename, MeshIO):\n            return filename\n\n        else:\n            return UserMeshIO(filename)\n\n    ext = op.splitext(filename)[1].lower()\n    try:\n        format = supported_formats[ext]\n    except KeyError:\n        raise ValueError('unsupported mesh file suffix! (%s)' % ext)\n\n    if isinstance(format, tuple):\n        format = guess_format(filename, ext, format, io_table)\n\n    if prefix_dir is not None:\n        filename = op.normpath(op.join(prefix_dir, filename))\n\n    return io_table[format](filename)", "response": "Create a MeshIO instance corresponding to the kind of filename."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef for_format(filename, format=None, writable=False, prefix_dir=None):\n    ext = op.splitext(filename)[1].lower()\n    try:\n        _format = supported_formats[ext]\n    except KeyError:\n        _format = None\n\n    format = get_default(format, _format)\n\n    if format is None:\n        io = MeshIO.any_from_filename(filename, prefix_dir=prefix_dir)\n\n    else:\n        if not isinstance(format, basestr):\n            raise ValueError('ambigous suffix! (%s -> %s)' % (ext, format))\n\n        if format not in io_table:\n            raise ValueError('unknown output mesh format! (%s)' % format)\n\n        if writable and ('w' not in supported_capabilities[format]):\n            output_writable_meshes()\n            msg = 'write support not implemented for output mesh format \"%s\",' \\\n                  ' see above!' \\\n                  % format\n            raise ValueError(msg)\n\n        if prefix_dir is not None:\n            filename = op.normpath(op.join(prefix_dir, filename))\n\n        io = io_table[format](filename)\n\n    return io", "response": "Create a new instance of a new mesh file with the given format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading true time step data from individual time steps.", "response": "def read_times(self, filename=None):\n        \"\"\"\n        Read true time step data from individual time steps.\n\n        Returns\n        -------\n        steps : array\n            The time steps.\n        times : array\n            The times of the time steps.\n        nts : array\n            The normalized times of the time steps, in [0, 1].\n\n        Notes\n        -----\n        The default implementation returns empty arrays.\n        \"\"\"\n        aux = nm.array([], dtype=nm.float64)\n        return aux.astype(nm.int32), aux, aux"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread data from the file.", "response": "def read_data( self, step, filename = None ):\n        \"\"\"Point data only!\"\"\"\n        filename = get_default( filename, self.filename )\n\n        out = {}\n\n        fd = open( self.filename, 'r' )\n        while 1:\n            line = skip_read_line(fd, no_eof=True).split()\n            if line[0] == 'POINT_DATA':\n                break\n\n        n_nod = int(line[1])\n\n        while 1:\n            line = skip_read_line(fd)\n            if not line:\n                break\n\n            line = line.split()\n\n            if line[0] == 'SCALARS':\n                name, dtype, nc = line[1:]\n                assert_(int(nc) == 1)\n                fd.readline() # skip lookup table line\n                \n                data = nm.zeros((n_nod,), dtype=nm.float64)\n                ii = 0\n                while ii < n_nod:\n                    data[ii] = float(fd.readline())\n                    ii += 1\n\n                out[name] = Struct( name = name,\n                                    mode = 'vertex',\n                                    data = data,\n                                    dofs = None )\n\n            elif line[0] == 'VECTORS':\n                name, dtype = line[1:]\n                data = []\n                ii = 0\n                while ii < n_nod:\n                    data.append([float(val) for val in fd.readline().split()])\n                    ii += 1\n\n                out[name] = Struct( name = name,\n                                    mode = 'vertex',\n                                    data = nm.array(data, dtype=nm.float64),\n                                    dofs = None )\n\n            elif line[0] == 'CELL_DATA':\n                break\n\n            line = fd.readline()\n\n        fd.close()\n\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getnodes(fnods, up=None, verbose=False):\n        f=open(fnods)\n        l=[int(x) for x in f.readline().split()]\n        npoints,dim,nattrib,nbound=l\n        if dim == 2:\n            ndapp = [0.0]\n        else:\n            ndapp = []\n        if verbose and up is not None: up.init(npoints)\n        nodes=[]\n        for line in f:\n            if line[0]==\"#\": continue\n            l=[float(x) for x in line.split()]\n            l = l[:(dim + 1)]\n            assert_( int(l[0])==len(nodes)+1 )\n            l = l[1:]\n            nodes.append(tuple(l + ndapp))\n            if verbose and up is not None: up.update(len(nodes))\n        assert_( npoints==len(nodes) )\n        return nodes", "response": "Reads t. 1. nodes returns a list of nodes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getele(fele, up=None, verbose=False):\n        f=file(fele)\n        l=[int(x) for x in f.readline().split()]\n        ntetra,nnod,nattrib=l\n        #we have either linear or quadratic tetrahedra:\n        elem = None\n        if nnod in [4,10]:\n            elem = '3_4'\n            linear = (nnod == 4)\n        if nnod in [3, 7]:\n            elem = '2_3'\n            linear = (nnod == 3)\n        if elem is None or not linear:\n            raise Exception(\"Only linear triangle and tetrahedra reader is implemented\")\n        if verbose and up is not None: up.init(ntetra)\n        # if nattrib!=1:\n        #     raise \"tetgen didn't assign an entity number to each element (option -A)\"\n        els=[]\n        regions={}\n        for line in f:\n            if line[0]==\"#\": continue\n            l=[int(x) for x in line.split()]\n            if elem == '2_3':\n                assert_((len(l) - 1 - nattrib) == 3 )\n                els.append((l[1],l[2],l[3]))\n            if elem == '3_4':\n                assert_((len(l) - 1 - nattrib) == 4 )\n                els.append((l[1],l[2],l[3],l[4]))\n            if nattrib == 1:\n                regionnum = l[-1]\n            else:\n                regionnum = 1\n\n            if regionnum==0:\n                print \"see %s, element # %d\"%(fele,l[0])\n                raise \"there are elements not belonging to any physical entity\"\n            if regions.has_key(regionnum):\n                regions[regionnum].append(l[0])\n            else:\n                regions[regionnum]=[l[0]]\n            assert_( l[0]==len(els) )\n            if verbose and up is not None: up.update(l[0])\n        return elem, els, regions", "response": "Reads t. 1. ele returns a list of elements and regions."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread true time step data from individual time steps.", "response": "def read_times(self, filename=None):\n        \"\"\"\n        Read true time step data from individual time steps.\n\n        Returns\n        -------\n        steps : array\n            The time steps.\n        times : array\n            The times of the time steps.\n        nts : array\n            The normalized times of the time steps, in [0, 1].\n        \"\"\"\n        filename = get_default(filename, self.filename)\n        fd = pt.openFile(filename, mode='r')\n\n        steps = sorted(int(name[4:]) for name in fd.root._v_groups.keys()\n                       if name.startswith('step'))\n        times = []\n        nts = []\n        for step in steps:\n            ts_group = fd.getNode(fd.root, 'step%d/ts' % step)\n\n            times.append(ts_group.t.read())\n            nts.append(ts_group.nt.read())\n        fd.close()\n\n        steps = nm.asarray(steps, dtype=nm.int32)\n        times = nm.asarray(times, dtype=nm.float64)\n        nts = nm.asarray(nts, dtype=nm.float64)\n\n        return steps, times, nts"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _read_line(self, f):\n        l = f.readline().strip()\n        while l == \"\" or l[0] == \"#\": # comment or an empty line\n            l = f.readline().strip()\n        return l", "response": "Reads one non empty line from the file f."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading one section from the mesh3d file.", "response": "def _read_section(self, f, integer=True):\n        \"\"\"\n        Reads one section from the mesh3d file.\n\n        integer ... if True, all numbers are passed to int(), otherwise to\n            float(), before returning\n\n        Some examples how a section can look like:\n\n        2\n        1 2 5 4 7 8 11 10\n        2 3 6 5 8 9 12 11\n\n        or\n\n        5\n        1 2 3 4     1\n        1 2 6 5     1\n        2 3 7 6     1\n        3 4 8 7     1\n        4 1 5 8     1\n\n        or\n\n        0\n\n        \"\"\"\n        if integer:\n            dtype=int\n        else:\n            dtype=float\n        l = self._read_line(f)\n        N = int(l)\n        rows = []\n        for i in range(N):\n            l = self._read_line(f)\n            row = nm.fromstring(l, sep=\" \", dtype=dtype)\n            rows.append(row)\n        return nm.array(rows)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new instance of the backend class.", "response": "def create(cls):\n        \"\"\"\n        Return always the same instance of the backend class\n        \"\"\"\n        if cls not in cls._instances:\n            cls._instances[cls] = cls()\n\n        return cls._instances[cls]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef peek(self):\n        try:\n            v = next(self._iter)\n            self._iter = itertools.chain((v,), self._iter)\n            return v\n        except StopIteration:\n            return PeekableIterator.Nothing", "response": "Returns the next item in the iterator."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nappends this entry to the parent TOMLFile.", "response": "def _append_to_parent(self):\n        \"\"\"\n        Causes this ephemeral table to be persisted on the TOMLFile.\n        \"\"\"\n\n        if self.__appended:\n            return\n\n        if self._parent is not None:\n            self._parent.append_fresh_table(self)\n\n        self.__appended = True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef access_token(self, value, request):\n\n        if self.validate(value, request) is not None:\n            return None\n        \n        access_token = AccessToken.objects.for_token(value)\n        \n        return access_token", "response": "Try to get the AccessToken associated with the provided token."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validate(self, value, request):\n\n        from django.http import HttpResponseBadRequest\n        from doac.http import HttpResponseUnauthorized\n        \n        if not value:\n            response = HttpResponseBadRequest()\n            response[\"WWW-Authenticate\"] = request_error_header(CredentialsNotProvided)\n            \n            return response\n        \n        try:\n            access_token = AccessToken.objects.for_token(value)\n        except AccessToken.DoesNotExist:\n            response = HttpResponseUnauthorized()\n            response[\"WWW-Authenticate\"] = request_error_header(InvalidToken)\n            \n            return response\n        \n        return None", "response": "Validate the token and return the corresponding HTTP response."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fetch_friends(self, user):\n\n        # Fetch the token key and secret\n        if USING_ALLAUTH:\n            social_app = SocialApp.objects.get_current('twitter')\n            consumer_key = social_app.key\n            consumer_secret = social_app.secret\n\n            oauth_token = SocialToken.objects.get(account=user, app=social_app).token\n            oauth_token_secret = SocialToken.objects.get(account=user, app=social_app).token_secret\n        else:\n            t = TwitterBackend()\n            tokens = t.tokens(user)\n            oauth_token_secret = tokens['oauth_token_secret']\n            oauth_token = tokens['oauth_token']\n\n            # Consumer key and secret from settings\n            consumer_key = settings.TWITTER_CONSUMER_KEY\n            consumer_secret = settings.TWITTER_CONSUMER_SECRET\n\n        # now fetch the twitter friends using `python-twitter`\n        api = twitter.Api(\n            consumer_key=consumer_key,\n            consumer_secret=consumer_secret,\n            access_token_key=oauth_token,\n            access_token_secret=oauth_token_secret\n        )\n        return api.GetFriends()", "response": "Fetches the friends from twitter using the\n            information on django - social - auth models\n        is an instance of UserSocialAuth\n           "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fetch_friend_ids(self, user):\n        friends = self.fetch_friends(user)\n        friend_ids = []\n        for friend in friends:\n            friend_ids.append(friend.id)\n        return friend_ids", "response": "Fetch the list of fethces of a user"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_numpy_doc(doc):\n\n    doc_sections = OrderedDict([(\"Short Summary\", None),\n                                (\"Deprecation Warning\", None),\n                                (\"Attributes\", None),\n                                (\"Extended Summary\", None),\n                                (\"Parameters\", None),\n                                (\"Returns\", None),\n                                (\"Yields\", None),\n                                (\"Other Parameters\", None),\n                                (\"Raises\", None),\n                                (\"See Also\", None),\n                                (\"Notes\", None),\n                                (\"References\", None),\n                                (\"Examples\", None)])\n\n    if not doc:\n        return doc_sections\n\n    doc = cleandoc(doc)\n    lines = iter(doc.splitlines())\n\n    key = \"Short Summary\"\n    body = []\n    while True:\n        try:\n            line = next(lines).rstrip()\n            if line in doc_sections:\n                doc_sections[key] = \"\\n\".join(body).rstrip() if body else None\n                body = []\n                key = line\n                next(lines)  # skip section delimiter\n            else:\n                body.append(line)\n        except StopIteration:\n            doc_sections[key] = \"\\n\".join(body)\n            break\n\n    return doc_sections", "response": "Extract the text from the various sections of a numpy - formatted docstring."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsynthesizes a output numpy docstring section.", "response": "def merge_section(key, prnt_sec, child_sec):\n    \"\"\" Synthesize a output numpy docstring section.\n\n        Parameters\n        ----------\n        key: str\n            The numpy-section being merged.\n        prnt_sec: Optional[str]\n            The docstring section from the parent's attribute.\n        child_sec: Optional[str]\n            The docstring section from the child's attribute.\n        Returns\n        -------\n        Optional[str]\n            The output docstring section.\"\"\"\n    if prnt_sec is None and child_sec is None:\n        return None\n\n    if key == \"Short Summary\":\n        header = ''\n    else:\n        header = \"\\n\".join((key, \"\".join(\"-\" for i in range(len(key))), \"\"))\n\n    if child_sec is None:\n        body = prnt_sec\n    else:\n        body = child_sec\n\n    return header + body"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding a line in the given file where all keys in pattern are present as keys in the line s JSON and whose values are equal to the corresponding Formula values in pattern.", "response": "def find_lines(filename, **pattern):\n    \"\"\"Find a line (JSON-formatted) in the given file where\n    all keys in `pattern` are present as keys in the line's\n    JSON, and where their values equal the corresponding\n    values in `pattern`. Additional keys in the line are\n    ignored. If no matching line is found, or if the\n    file does not exist, return None.\n    \"\"\"\n    if exists(filename):\n        with file(filename, 'r') as fp:\n            for line in fp:\n                try:\n                    data = json.loads(line)\n                except:\n                    continue\n                matches = True\n                for key, value in pattern.iteritems():\n                    matches = matches and key in data and data[key] == value\n                if matches:\n                    yield data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef append_line(filename, **line):\n    global lock\n\n    data = json.dumps(line, separators=(',', ':')) + '\\n'\n    with lock:\n        with file(filename, 'a') as fp:\n            fp.seek(0, SEEK_END)\n            fp.write(data)", "response": "Safely append a line to the given file"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef structure(table_toplevels):\n\n    table_toplevels = tuple(table_toplevels)\n    obj = NamedDict()\n\n    last_array_of_tables = None         # The Name of the last array-of-tables header\n\n    for toplevel in table_toplevels:\n\n        if isinstance(toplevel, toplevels.AnonymousTable):\n            obj[''] = toplevel.table_element\n\n        elif isinstance(toplevel, toplevels.Table):\n            if last_array_of_tables and toplevel.name.is_prefixed_with(last_array_of_tables):\n                seq = obj[last_array_of_tables]\n                unprefixed_name = toplevel.name.without_prefix(last_array_of_tables)\n\n                seq[-1] = CascadeDict(seq[-1], NamedDict({unprefixed_name: toplevel.table_element}))\n            else:\n                obj[toplevel.name] = toplevel.table_element\n        else:    # It's an ArrayOfTables\n\n            if last_array_of_tables and toplevel.name != last_array_of_tables and \\\n                    toplevel.name.is_prefixed_with(last_array_of_tables):\n\n                seq = obj[last_array_of_tables]\n                unprefixed_name = toplevel.name.without_prefix(last_array_of_tables)\n\n                if unprefixed_name in seq[-1]:\n                    seq[-1][unprefixed_name].append(toplevel.table_element)\n                else:\n                    cascaded_with = NamedDict({unprefixed_name: [toplevel.table_element]})\n                    seq[-1] = CascadeDict(seq[-1], cascaded_with)\n\n            else:\n                obj.append(toplevel.name, toplevel.table_element)\n                last_array_of_tables = toplevel.name\n\n    return obj", "response": "Returns a navigable structure representation of the given list of TopLevel instances."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove all unused and expired authorization codes from the database.", "response": "def prune_old_authorization_codes():\n    \"\"\"\n    Removes all unused and expired authorization codes from the database.\n    \"\"\"\n\n    from .compat import now\n    from .models import AuthorizationCode\n    \n    AuthorizationCode.objects.with_expiration_before(now()).delete()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_handler(handler_name):\n\n    from .conf import options\n    \n    handlers = options.handlers\n    \n    for handler in handlers:\n        handler_path = handler.split(\".\")\n        name = handler_path[-2]\n        \n        if handler_name == name:\n            handler_module = __import__(\".\".join(handler_path[:-1]), {}, {}, str(handler_path[-1]))\n            \n            return getattr(handler_module, handler_path[-1])()\n    \n    return None", "response": "Returns the handler module for the DOAC handler with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating an error header based on an OAuth exception.", "response": "def request_error_header(exception):\n    \"\"\"\n    Generates the error header for a request using a Bearer token based on a given OAuth exception.\n    \"\"\"\n\n    from .conf import options\n    \n    header = \"Bearer realm=\\\"%s\\\"\" % (options.realm, )\n    \n    if hasattr(exception, \"error\"):\n        header = header + \", error=\\\"%s\\\"\" % (exception.error, )\n    \n    if hasattr(exception, \"reason\"):\n        header = header + \", error_description=\\\"%s\\\"\" % (exception.reason, )\n    \n    return header"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a metaclass that inherits from the base class and its child class.", "response": "def DocInheritMeta(style=\"parent\", abstract_base_class=False):\n    \"\"\" A metaclass that merges the respective docstrings of a parent class and of its child, along with their\n        properties, methods (including classmethod, staticmethod, decorated methods).\n\n        Parameters\n        ----------\n        style: Union[Any, Callable[[str, str], str]], optional (default: \"parent\")\n            A valid inheritance-scheme style ID or function that merges two docstrings.\n\n        abstract_base_class: bool, optional(default: False)\n            If True, the returned metaclass inherits from abc.ABCMeta.\n\n            Thus a class that derives from DocInheritMeta(style=\"numpy\", abstract_base_class=True)\n            will be an abstract base class, whose derived classes will inherit docstrings\n            using the numpy-style inheritance scheme.\n\n\n        Returns\n        -------\n        custom_inherit.DocInheritorBase\"\"\"\n\n    merge_func = store[style]\n    metaclass = _DocInheritorBase\n    metaclass.class_doc_inherit = staticmethod(merge_func)\n    metaclass.attr_doc_inherit = staticmethod(merge_func)\n\n    return metaclass if not abstract_base_class else type(\"abc\" + metaclass.__name__, (_ABCMeta, metaclass), {})"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef doc_inherit(parent, style=\"parent\"):\n\n    merge_func = store[style]\n    decorator = _DocInheritDecorator\n    decorator.doc_merger = staticmethod(merge_func)\n    return decorator(parent)", "response": "Returns a function or method decorator that updates the docstring of the decorated\n        function or method based on the specified inheritance - scheme style and attribute of the parent."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pop(self, *args):\n        if len(args) < 3:\n            return self._store.pop(*args)\n        else:\n            raise TypeError(\"pop expected at most 2 arguments, got {}\".format(len(args)))", "response": "D. pop - remove specified key and return corresponding value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate the dictionary with the given keys and values.", "response": "def update(self, *args, **kwargs):\n        \"\"\" D.update([E, ]**F) -> None.  Update D from dict/iterable E and F.\n            If E is present and has a .keys() method, then does:  for k in E: D[k] = E[k]\"\"\"\n        if len(args) > 1:\n            raise TypeError(\"update expected at most 1 arguments, got %d\" % len(args))\n\n        for key, value in dict(*args, **kwargs).items():\n            self[key] = value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the default starting location of our character.", "response": "def set_default_pos(self, defaultPos):\n        \"\"\"Set the default starting location of our character.\"\"\"\n        self.coords = defaultPos\n        self.velocity = r.Vector2()\n        self.desired_position = defaultPos\n        r.Ragnarok.get_world().Camera.pan = self.coords\n        r.Ragnarok.get_world().Camera.desired_pan = self.coords"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __generate_location(self):\n        screen_width = world.get_backbuffer_size().X\n        self.movement_speed = random.randrange(10, 25)\n\n        # This line of code places the cloud to the right of the viewable screen, so it appears to\n        # gradually move in from the right instead of randomally appearing on some portion of the viewable\n        # window.\n        self.coords = R.Vector2(screen_width + self.image.get_width(), random.randrange(0, 100))", "response": "Generate the location of the cloud."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nregister blueprint to app.", "response": "def register_to_app(self, app):\n        \"\"\"\n        \u6ce8\u518c\u5230app\u4e0a\n        \"\"\"\n        self.app = app\n        # \u6ce8\u518c\u4e0a\n        self.app.blueprints.append(self)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntrue if a line consists only of a single punctuation character.", "response": "def is_delimiter(line):\n    \"\"\" True if a line consists only of a single punctuation character.\"\"\"\n    return bool(line) and line[0] in punctuation and line[0]*len(line) == line"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_rest_doc(doc):\n\n    class Section(object):\n        def __init__(self, header=None, body=None):\n            self.header = header  # str\n            self.body = body  # str\n\n    doc_sections = OrderedDict([('', Section(header=''))])\n    if not doc:\n        return doc_sections\n\n    doc = cleandoc(doc)\n    lines = iter(doc.splitlines())\n\n    header = ''\n    body = []\n    section = Section(header=header)\n    line = ''\n    while True:\n        try:\n            prev_line = line\n            line = next(lines)\n            # section header encountered\n            if is_delimiter(line) and 0 < len(prev_line) <= len(line):\n                # prev-prev-line is overline\n                if len(body) >= 2 and len(body[-2]) == len(line) \\\n                        and body[-2][0] == line[0] and is_delimiter(body[-2]):\n                    lim = -2\n                else:\n                    lim = -1\n\n                section.body = \"\\n\".join(body[:lim]).rstrip()\n                doc_sections.update([(header.strip(), section)])\n                section = Section(header=\"\\n\".join(body[lim:] + [line]))\n                header = prev_line\n                body = []\n                line = ''\n            else:\n                body.append(line)\n\n        except StopIteration:\n            section.body = \"\\n\".join(body).rstrip()\n            doc_sections.update([(header.strip(), section)])\n            break\n    return doc_sections", "response": "Parses the docstrings and returns a dictionary of the headers delimiters and text from the docstrings."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmerging the rest documentation into one.", "response": "def merge_rest_docs(prnt_doc=None, child_doc=None):\n    \"\"\" See custom_inherit.style_store.reST for details. \"\"\"\n    prnt_sections = parse_rest_doc(prnt_doc)\n    child_sections = parse_rest_doc(child_doc)\n\n    header = prnt_sections['']\n    prnt_sections.update(child_sections)\n    if not child_sections[''].body:\n        prnt_sections[''] = header\n        if not header.body:\n            prnt_sections.popitem(last=False)\n\n    return \"\\n\\n\".join((\"\\n\".join((x.header, x.body)) for x in prnt_sections.values())).lstrip()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef safe_call(func, *args, **kwargs):\n    try:\n        return func(*args, **kwargs)\n    except Exception as e:\n        logger.error('exc occur. e: %s, func: %s', e, func, exc_info=True)\n        # \u8c03\u7528\u65b9\u53ef\u4ee5\u901a\u8fc7 isinstance(e, BaseException) \u6765\u5224\u65ad\u662f\u5426\u53d1\u751f\u4e86\u5f02\u5e38\n        return e", "response": "safe_call - safe call of a function"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef safe_func(func):\n    @functools.wraps(func)\n    def func_wrapper(*args, **kwargs):\n        return safe_call(func, *args, **kwargs)\n    return func_wrapper", "response": "A wrapper for safe_call that returns a single object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_strings(content=\"\", filename=None):\n    if filename is not None:\n        content = _get_content(filename=filename)\n\n    stringset = []\n    f = content\n    if f.startswith(u'\\ufeff'):\n        f = f.lstrip(u'\\ufeff')\n    #regex for finding all comments in a file\n    cp = r'(?:/\\*(?P<comment>(?:[^*]|(?:\\*+[^*/]))*\\**)\\*/)'\n    p = re.compile(r'(?:%s[ \\t]*[\\n]|[\\r\\n]|[\\r]){0,1}(?P<line>((\"(?P<key>[^\"\\\\]*(?:\\\\.[^\"\\\\]*)*)\")|(?P<property>\\w+))\\s*=\\s*\"(?P<value>[^\"\\\\]*(?:\\\\.[^\"\\\\]*)*)\"\\s*;)'%cp, re.DOTALL|re.U)\n    #c = re.compile(r'\\s*/\\*(.|\\s)*?\\*/\\s*', re.U)\n    c = re.compile(r'//[^\\n]*\\n|/\\*(?:.|[\\r\\n])*?\\*/', re.U)\n    ws = re.compile(r'\\s+', re.U)\n    end=0\n    start = 0\n    for i in p.finditer(f):\n        start = i.start('line')\n        end_ = i.end()\n        key = i.group('key')\n        comment = i.group('comment') or ''\n        if not key:\n            key = i.group('property')\n        value = i.group('value')\n        while end < start:\n            m = c.match(f, end, start) or ws.match(f, end, start)\n            if not m or m.start() != end:\n                print(\"Invalid syntax: %s\" %\\\n                        f[end:start])\n            end = m.end()\n        end = end_\n        key = _unescape_key(key)\n        stringset.append({'key': key, 'value': _unescape(value), 'comment': comment})\n    return stringset", "response": "Parse an apple. strings file and create a stringset with all entries in the file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef interrupt(self, data=None):\n        self.interrupted = True\n        if data is not None:\n            return self.write(data)\n        else:\n            return True", "response": "\u4e2d\u65ad\u5904\u7406\n        :param data: \u8981\u54cd\u5e94\u7684\u6570\u636e\uff0c\u4e0d\u4f20\u5373\u4e0d\u54cd\u5e94\n        :return:"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef identify(file_elements):\n\n    if not file_elements:\n        return\n\n    _validate_file_elements(file_elements)\n\n    # An iterator over enumerate(the non-metadata) elements\n    iterator = PeekableIterator((element_i, element) for (element_i, element) in enumerate(file_elements)\n                                if element.type != elements.TYPE_METADATA)\n\n    try:\n        _, first_element = iterator.peek()\n        if isinstance(first_element, TableElement):\n            iterator.next()\n            yield AnonymousTable(first_element)\n    except KeyError:\n        pass\n    except StopIteration:\n        return\n\n    for element_i, element in iterator:\n\n        if not isinstance(element, TableHeaderElement):\n            continue\n\n        # If TableHeader of a regular table, return Table following it\n        if not element.is_array_of_tables:\n            table_element_i, table_element = next(iterator)\n            yield Table(names=element.names, table_element=table_element)\n\n        # If TableHeader of an array of tables, do your thing\n        else:\n            table_element_i, table_element = next(iterator)\n            yield ArrayOfTables(names=element.names, table_element=table_element)", "response": "Generates an ordered sequence of instances of TopLevel types."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates an instance of the main character and return it.", "response": "def load_character(tile_map, gamescreen):\n    \"\"\"Create an instance of the main character and return it.\"\"\"\n    tile_obj = thc.TileHeroCharacter(tile_map, gamescreen)\n    tile_obj.load_texture(\"..//Textures//character.png\")\n    tile_obj.origin = r.Vector2(0, 0)\n    tile_obj.hazard_touched_method = hazard_touched_method\n    tile_obj.special_touched_method = special_touched_method\n    return tile_obj"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_log_level(log_level):\n\n    if not LOGBOOK_INSTALLED:\n        return\n\n    # validate log level\n    logbook.get_level_name(log_level)\n\n    if log_level == logbook.NOTSET:\n        set_logger(is_enable=False)\n    else:\n        set_logger(is_enable=True)\n\n    logger.level = log_level", "response": "Sets the log level of this module."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nauthenticates user and retrieves access token", "response": "def auth(self, code=\"\", refresh_token=\"\"):\n\n        \"\"\"Authenticates user and retrieves (and refreshes) access token\n\n        :param code: code provided after redirect (authorization_code only)\n        :param refresh_token: the refresh_token to update access_token without authorization\n        \"\"\"\n\n        if refresh_token:\n            try:\n                self.oauth.request_token(grant_type=\"refresh_token\", refresh_token=refresh_token)\n                self.refresh_token = self.oauth.refresh_token\n            except HTTPError as e:\n\n                if e.code == 401:\n                    raise DeviantartError(\"Unauthorized: Please check your credentials (client_id and client_secret).\")\n                else:\n                    raise DeviantartError(e)\n        elif self.standard_grant_type == \"authorization_code\":\n            try:\n                self.oauth.request_token(grant_type=self.standard_grant_type, redirect_uri=self.redirect_uri, code=code)\n                self.refresh_token = self.oauth.refresh_token\n            except HTTPError as e:\n\n                if e.code == 401:\n                    raise DeviantartError(\"Unauthorized: Please check your credentials (client_id and client_secret).\")\n                else:\n                    raise DeviantartError(e)\n        elif self.standard_grant_type == \"client_credentials\":\n            try:\n                self.oauth.request_token(grant_type=self.standard_grant_type)\n            except HTTPError as e:\n\n                if e.code == 401:\n                    raise DeviantartError(\"Unauthorized: Please check your credentials (client_id and client_secret).\")\n                else:\n                    raise DeviantartError(e)\n        else:\n            raise DeviantartError('Unknown grant type.')\n\n        self.access_token = self.oauth.access_token"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef auth_uri(self):\n\n        \"\"\"The authorzation URL that should be provided to the user\"\"\"\n\n        return self.oauth.auth_uri(redirect_uri=self.redirect_uri, scope=self.scope)", "response": "The authorzation URL that should be provided to the user"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfetch user journals from user", "response": "def browse_userjournals(self, username, featured=False, offset=0, limit=10):\n\n        \"\"\"Fetch user journals from user\n\n        :param username: name of user to retrieve journals from\n        :param featured: fetch only featured or not\n        :param offset: the pagination offset\n        :param limit: the pagination limit\n        \"\"\"\n\n        response = self._req('/browse/user/journals', {\n            \"username\":username,\n            \"featured\":featured,\n            \"offset\":offset,\n            \"limit\":limit\n        })\n\n        deviations = []\n\n        for item in response['results']:\n            d = Deviation()\n            d.from_dict(item)\n            deviations.append(d)\n\n        return {\n            \"results\" : deviations,\n            \"has_more\" : response['has_more'],\n            \"next_offset\" : response['next_offset']\n        }"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef browse_morelikethis_preview(self, seed):\n\n        \"\"\"Fetch More Like This preview result for a seed deviation\n\n        :param seed: The deviationid to fetch more like\n        \"\"\"\n\n        response = self._req('/browse/morelikethis/preview', {\n            \"seed\":seed\n        })\n\n        returned_seed = response['seed']\n\n        author = User()\n        author.from_dict(response['author'])\n\n        more_from_artist = []\n\n        for item in response['more_from_artist']:\n            d = Deviation()\n            d.from_dict(item)\n            more_from_artist.append(d)\n\n        more_from_da = []\n\n        for item in response['more_from_da']:\n            d = Deviation()\n            d.from_dict(item)\n            more_from_da.append(d)\n\n        return {\n            \"seed\" : returned_seed,\n            \"author\" : author,\n            \"more_from_artist\" : more_from_artist,\n            \"more_from_da\" : more_from_da\n        }", "response": "Fetch More Like This preview result for a seed deviation\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfetch the list of deviations from the specified endpoint", "response": "def browse(self, endpoint=\"hot\", category_path=\"\", seed=\"\", q=\"\", timerange=\"24hr\", tag=\"\", offset=0, limit=10):\n\n        \"\"\"Fetch deviations from public endpoints\n\n        :param endpoint: The endpoint from which the deviations will be fetched (hot/morelikethis/newest/undiscovered/popular/tags)\n        :param category_path: category path to fetch from\n        :param q: Search query term\n        :param timerange: The timerange\n        :param tag: The tag to browse\n        :param offset: the pagination offset\n        :param limit: the pagination limit\n        \"\"\"\n\n        if endpoint == \"hot\":\n            response = self._req('/browse/hot', {\n                \"category_path\":category_path,\n                \"offset\":offset,\n                \"limit\":limit\n            })\n        elif endpoint == \"morelikethis\":\n            if seed:\n                response = self._req('/browse/morelikethis', {\n                    \"seed\":seed,\n                    \"category_path\":category_path,\n                    \"offset\":offset,\n                    \"limit\":limit\n                })\n            else:\n                raise DeviantartError(\"No seed defined.\")\n        elif endpoint == \"newest\":\n            response = self._req('/browse/newest', {\n                \"category_path\":category_path,\n                \"q\":q,\n                \"offset\":offset,\n                \"limit\":limit\n            })\n        elif endpoint == \"undiscovered\":\n            response = self._req('/browse/undiscovered', {\n                \"category_path\":category_path,\n                \"offset\":offset,\n                \"limit\":limit\n            })\n        elif endpoint == \"popular\":\n            response = self._req('/browse/popular', {\n                \"category_path\":category_path,\n                \"q\":q,\n                \"timerange\":timerange,\n                \"offset\":offset,\n                \"limit\":limit\n            })\n        elif endpoint == \"tags\":\n            if tag:\n                response = self._req('/browse/tags', {\n                    \"tag\":tag,\n                    \"offset\":offset,\n                    \"limit\":limit\n                })\n            else:\n                raise DeviantartError(\"No tag defined.\")\n        else:\n            raise DeviantartError(\"Unknown endpoint.\")\n\n        deviations = []\n\n        for item in response['results']:\n            d = Deviation()\n            d.from_dict(item)\n            deviations.append(d)\n\n        return {\n            \"results\" : deviations,\n            \"has_more\" : response['has_more'],\n            \"next_offset\" : response['next_offset']\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_categories(self, catpath=\"/\"):\n\n        \"\"\"Fetch the categorytree\n\n        :param catpath: The category to list children of\n        \"\"\"\n\n        response = self._req('/browse/categorytree', {\n            \"catpath\":catpath\n        })\n\n        categories = response['categories']\n\n        return categories", "response": "Fetch the category tree"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef search_tags(self, tag_name):\n\n        \"\"\"Searches for tags\n\n        :param tag_name: Partial tag name to get autocomplete suggestions for\n        \"\"\"\n\n        response = self._req('/browse/tags/search', {\n            \"tag_name\":tag_name\n        })\n\n        tags = list()\n\n        for item in response['results']:\n            tags.append(item['tag_name'])\n\n        return tags", "response": "Searches for tags in the browser"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfetching a single deviation from the server", "response": "def get_deviation(self, deviationid):\n\n        \"\"\"Fetch a single deviation\n\n        :param deviationid: The deviationid you want to fetch\n        \"\"\"\n\n        response = self._req('/deviation/{}'.format(deviationid))\n        d = Deviation()\n        d.from_dict(response)\n\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfetch a list of users who faved the deviation", "response": "def whofaved_deviation(self, deviationid, offset=0, limit=10):\n\n        \"\"\"Fetch a list of users who faved the deviation\n\n        :param deviationid: The deviationid you want to fetch\n        :param offset: the pagination offset\n        :param limit: the pagination limit\n        \"\"\"\n\n        response = self._req('/deviation/whofaved', get_data={\n            'deviationid' : deviationid,\n            'offset' : offset,\n            'limit' : limit\n        })\n\n        users = []\n\n        for item in response['results']:\n            u = {}\n            u['user'] = User()\n            u['user'].from_dict(item['user'])\n            u['time'] = item['time']\n\n            users.append(u)\n\n        return {\n            \"results\" : users,\n            \"has_more\" : response['has_more'],\n            \"next_offset\" : response['next_offset']\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfetch the metadata for a set of deviations", "response": "def get_deviation_metadata(self, deviationids, ext_submission=False, ext_camera=False, ext_stats=False, ext_collection=False):\n\n        \"\"\"Fetch deviation metadata for a set of deviations\n\n        :param deviationid: The deviationid you want to fetch\n        :param ext_submission: Return extended information - submission information\n        :param ext_camera: Return extended information - EXIF information (if available)\n        :param ext_stats: Return extended information - deviation statistics\n        :param ext_collection: Return extended information - favourited folder information\n        \"\"\"\n\n        response = self._req('/deviation/metadata', {\n            'ext_submission' : ext_submission,\n            'ext_camera' : ext_camera,\n            'ext_stats' : ext_stats,\n            'ext_collection' : ext_collection\n        },\n        post_data={\n            'deviationids[]' : deviationids\n        })\n\n        metadata = []\n\n        for item in response['metadata']:\n            m = {}\n            m['deviationid'] = item['deviationid']\n            m['printid'] = item['printid']\n\n            m['author'] = User()\n            m['author'].from_dict(item['author'])\n\n            m['is_watching'] = item['is_watching']\n            m['title'] = item['title']\n            m['description'] = item['description']\n            m['license'] = item['license']\n            m['allows_comments'] = item['allows_comments']\n            m['tags'] = item['tags']\n            m['is_favourited'] = item['is_favourited']\n            m['is_mature'] = item['is_mature']\n\n            if \"submission\" in item:\n                m['submission'] = item['submission']\n\n            if \"camera\" in item:\n                m['camera'] = item['camera']\n\n            if \"collections\" in item:\n                m['collections'] = item['collections']\n\n            metadata.append(m)\n\n        return metadata"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_deviation_embeddedcontent(self, deviationid, offset_deviationid=\"\", offset=0, limit=10):\n\n        \"\"\"Fetch content embedded in a deviation\n\n        :param deviationid: The deviationid of container deviation\n        :param offset_deviationid: UUID of embedded deviation to use as an offset\n        :param offset: the pagination offset\n        :param limit: the pagination limit\n        \"\"\"\n        \n        response = self._req('/deviation/embeddedcontent', {\n            'deviationid' : deviationid,\n            'offset_deviationid' : offset_deviationid,\n            'offset' : 0,\n            'limit' : 0\n        })\n\n        deviations = []\n\n        for item in response['results']:\n\n            d = Deviation()\n            d.from_dict(item)\n\n            deviations.append(d)\n\n        return {\n            \"results\" : deviations,\n            \"has_less\" : response['has_less'],\n            \"has_more\" : response['has_more'],\n            \"prev_offset\" : response['prev_offset'],\n            \"next_offset\" : response['next_offset']\n        }", "response": "Fetch content embedded in a deviation"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfetching full data that is not included in the main devaition object", "response": "def get_deviation_content(self, deviationid):\n\n        \"\"\"Fetch full data that is not included in the main devaition object\n\n        The endpoint works with journals and literatures. Deviation objects returned from API contain only excerpt of a journal, use this endpoint to load full content. \n        Any custom CSS rules and fonts applied to journal are also returned.\n\n        :param deviationid: UUID of the deviation to fetch full data for\n        \"\"\"\n        \n        response = self._req('/deviation/content', {\n            'deviationid':deviationid\n        })\n\n        content = {}\n\n        if \"html\" in response:\n            content['html'] = response['html']\n\n        if \"css\" in response:\n            content['css'] = response['css']\n\n        if \"css_fonts\" in response:\n            content['css_fonts'] = response['css_fonts']\n\n        return content"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef download_deviation(self, deviationid):\n\n        \"\"\"Get the original file download (if allowed)\n\n        :param deviationid: The deviationid you want download info for\n        \"\"\"\n\n        response = self._req('/deviation/download/{}'.format(deviationid))\n\n        return {\n            'src' : response['src'],\n            'width' : response['width'],\n            'height' : response['height'],\n            'filesize' : response['filesize']\n        }", "response": "Get the original file download"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_collections(self, username=\"\", calculate_size=False, ext_preload=False, offset=0, limit=10):\n\n        \"\"\"Fetch collection folders\n\n        :param username: The user to list folders for, if omitted the authenticated user is used\n        :param calculate_size: The option to include the content count per each collection folder\n        :param ext_preload: Include first 5 deviations from the folder\n        :param offset: the pagination offset\n        :param limit: the pagination limit\n        \"\"\"\n\n        if not username and self.standard_grant_type == \"authorization_code\":\n            response = self._req('/collections/folders', {\n                \"calculate_size\":calculate_size,\n                \"ext_preload\":ext_preload,\n                \"offset\":offset,\n                \"limit\":limit\n            })\n        else:\n            if not username:\n                raise DeviantartError(\"No username defined.\")\n            else:\n                response = self._req('/collections/folders', {\n                    \"username\":username,\n                    \"calculate_size\":calculate_size,\n                    \"ext_preload\":ext_preload,\n                    \"offset\":offset,\n                    \"limit\":limit\n                })\n\n        folders = []\n\n        for item in response['results']:\n            f = {}\n            f['folderid'] = item['folderid']\n            f['name'] = item['name']\n\n            if \"size\" in item:\n                f['size'] = item['size']\n\n            if \"deviations\" in item:\n                f['deviations'] = []\n\n                for deviation_item in item['deviations']:\n                    d = Deviation()\n                    d.from_dict(deviation_item)\n                    f['deviations'].append(d)\n\n            folders.append(f)\n\n        return {\n            \"results\" : folders,\n            \"has_more\" : response['has_more'],\n            \"next_offset\" : response['next_offset']\n        }", "response": "Fetch collection folders for a user"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_collection(self, folderid, username=\"\", offset=0, limit=10):\n\n        \"\"\"Fetch collection folder contents\n\n        :param folderid: UUID of the folder to list\n        :param username: The user to list folders for, if omitted the authenticated user is used\n        :param offset: the pagination offset\n        :param limit: the pagination limit\n        \"\"\"\n\n        if not username and self.standard_grant_type == \"authorization_code\":\n            response = self._req('/collections/{}'.format(folderid), {\n                \"offset\":offset,\n                \"limit\":limit\n            })\n        else:\n            if not username:\n                raise DeviantartError(\"No username defined.\")\n            else:\n                response = self._req('/collections/{}'.format(folderid), {\n                    \"username\":username,\n                    \"offset\":offset,\n                    \"limit\":limit\n                })\n\n        deviations = []\n\n        for item in response['results']:\n            d = Deviation()\n            d.from_dict(item)\n            deviations.append(d)\n\n        if \"name\" in response:\n            name = response['name']\n        else:\n            name = None\n\n        return {\n            \"results\" : deviations,\n            \"name\" : name,\n            \"has_more\" : response['has_more'],\n            \"next_offset\" : response['next_offset']\n        }", "response": "Fetch the contents of a folder in a user s collection"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a deviation to a collection", "response": "def fave(self, deviationid, folderid=\"\"):\n\n        \"\"\"Add deviation to favourites\n\n        :param deviationid: Id of the Deviation to favourite\n        :param folderid: Optional UUID of the Collection folder to add the favourite into\n        \"\"\"\n\n        if self.standard_grant_type is not \"authorization_code\":\n            raise DeviantartError(\"Authentication through Authorization Code (Grant Type) is required in order to connect to this endpoint.\")\n\n        post_data = {}\n\n        post_data['deviationid'] = deviationid\n\n        if folderid:\n            post_data['folderid'] = folderid\n\n        response = self._req('/collections/fave', post_data = post_data)\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_gallery_all(self, username='', offset=0, limit=10):\n        if not username:\n            raise DeviantartError('No username defined.')\n\n        response = self._req('/gallery/all', {'username': username,\n                                               'offset': offset,\n                                               'limit': limit})\n\n        deviations = []\n\n        for item in response['results']:\n            d = Deviation()\n            d.from_dict(item)\n            deviations.append(d)\n\n        if \"name\" in response:\n            name = response['name']\n        else:\n            name = None\n\n        return {\n            \"results\": deviations,\n            \"name\": name,\n            \"has_more\": response['has_more'],\n            \"next_offset\": response['next_offset']\n        }", "response": "Get all of a user s deviations"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_user(self, username=\"\", ext_collections=False, ext_galleries=False):\n\n        \"\"\"Get user profile information\n\n        :param username: username to lookup profile of\n        :param ext_collections: Include collection folder info\n        :param ext_galleries: Include gallery folder info\n        \"\"\"\n\n        if not username and self.standard_grant_type == \"authorization_code\":\n            response = self._req('/user/whoami')\n            u = User()\n            u.from_dict(response)\n        else:\n            if not username:\n                raise DeviantartError(\"No username defined.\")\n            else:\n                response = self._req('/user/profile/{}'.format(username), {\n                    'ext_collections' : ext_collections,\n                    'ext_galleries' : ext_galleries\n                })\n                u = User()\n                u.from_dict(response['user'])\n\n        return u", "response": "Get user profile information"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfetches user info for given usernames", "response": "def get_users(self, usernames):\n\n        \"\"\"Fetch user info for given usernames\n\n        :param username: The usernames you want metadata for (max. 50)\n        \"\"\"\n\n        if self.standard_grant_type is not \"authorization_code\":\n            raise DeviantartError(\"Authentication through Authorization Code (Grant Type) is required in order to connect to this endpoint.\")\n\n        response = self._req('/user/whois', post_data={\n            \"usernames\":usernames\n        })\n\n        users = []\n\n        for item in response['results']:\n            u = User()\n            u.from_dict(item)\n            users.append(u)\n\n        return users"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef watch(\n        self,\n        username,\n        watch={\n            \"friend\":True,\n            \"deviations\":True,\n            \"journals\":True,\n            \"forum_threads\":True,\n            \"critiques\":True,\n            \"scraps\":True,\n            \"activity\":True,\n            \"collections\":True\n        }\n    ):\n\n        \"\"\"Watch a user\n\n        :param username: The username you want to watch\n        \"\"\"\n\n        if self.standard_grant_type is not \"authorization_code\":\n            raise DeviantartError(\"Authentication through Authorization Code (Grant Type) is required in order to connect to this endpoint.\")\n\n        response = self._req('/user/friends/watch/{}'.format(username), post_data={\n            \"watch[friend]\": watch['friend'],\n            \"watch[deviations]\": watch['deviations'],\n            \"watch[journals]\": watch['journals'],\n            \"watch[forum_threads]\": watch['forum_threads'],\n            \"watch[critiques]\": watch['critiques'],\n            \"watch[scraps]\": watch['scraps'],\n            \"watch[activity]\": watch['activity'],\n            \"watch[collections]\": watch['collections'],\n        })\n\n        return response['success']", "response": "Watch a user s entry in the cache"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef unwatch(self, username):\n\n        \"\"\"Unwatch a user\n\n        :param username: The username you want to unwatch\n        \"\"\"\n\n        if self.standard_grant_type is not \"authorization_code\":\n            raise DeviantartError(\"Authentication through Authorization Code (Grant Type) is required in order to connect to this endpoint.\")\n\n        response = self._req('/user/friends/unwatch/{}'.format(username))\n\n        return response['success']", "response": "Unwatch a user s unique ID"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_watching(self, username):\n\n        \"\"\"Check if user is being watched by the given user\n\n        :param username: Check if username is watching you\n        \"\"\"\n\n        if self.standard_grant_type is not \"authorization_code\":\n            raise DeviantartError(\"Authentication through Authorization Code (Grant Type) is required in order to connect to this endpoint.\")\n\n        response = self._req('/user/friends/watching/{}'.format(username))\n\n        return response['watching']", "response": "Check if user is being watched by the given username"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the user s profile information", "response": "def update_user(self, user_is_artist=\"\", artist_level=\"\", artist_specialty=\"\", real_name=\"\", tagline=\"\", countryid=\"\", website=\"\", bio=\"\"):\n\n        \"\"\"Update the users profile information\n\n        :param user_is_artist: Is the user an artist?\n        :param artist_level: If the user is an artist, what level are they\n        :param artist_specialty: If the user is an artist, what is their specialty\n        :param real_name: The users real name\n        :param tagline: The users tagline\n        :param countryid: The users location\n        :param website: The users personal website\n        :param bio: The users bio\n        \"\"\"\n\n\n\n        if self.standard_grant_type is not \"authorization_code\":\n            raise DeviantartError(\"Authentication through Authorization Code (Grant Type) is required in order to connect to this endpoint.\")\n\n        post_data = {}\n\n        if user_is_artist:\n            post_data[\"user_is_artist\"] = user_is_artist\n\n        if artist_level:\n            post_data[\"artist_level\"] = artist_level\n\n        if artist_specialty:\n            post_data[\"artist_specialty\"] = artist_specialty\n\n        if real_name:\n            post_data[\"real_name\"] = real_name\n\n        if tagline:\n            post_data[\"tagline\"] = tagline\n\n        if countryid:\n            post_data[\"countryid\"] = countryid\n\n        if website:\n            post_data[\"website\"] = website\n\n        if bio:\n            post_data[\"bio\"] = bio\n\n        response = self._req('/user/profile/update', post_data=post_data)\n\n        return response['success']"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_watchers(self, username, offset=0, limit=10):\n\n        \"\"\"Get the user's list of watchers\n\n        :param username: The username you want to get a list of watchers of\n        :param offset: the pagination offset\n        :param limit: the pagination limit\n        \"\"\"\n\n        response = self._req('/user/watchers/{}'.format(username), {\n            'offset' : offset,\n            'limit' : limit\n        })\n\n        watchers = []\n\n        for item in response['results']:\n            w = {}\n            w['user'] = User()\n            w['user'].from_dict(item['user'])\n            w['is_watching'] = item['is_watching']\n            w['lastvisit'] = item['lastvisit']\n            w['watch'] = {\n                \"friend\" : item['watch']['friend'],\n                \"deviations\" : item['watch']['deviations'],\n                \"journals\" : item['watch']['journals'],\n                \"forum_threads\" : item['watch']['forum_threads'],\n                \"critiques\" : item['watch']['critiques'],\n                \"scraps\" : item['watch']['scraps'],\n                \"activity\" : item['watch']['activity'],\n                \"collections\" : item['watch']['collections']\n            }\n\n            watchers.append(w)\n\n        return {\n            \"results\" : watchers,\n            \"has_more\" : response['has_more'],\n            \"next_offset\" : response['next_offset']\n        }", "response": "Get the user s list of watchers of a user"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_friends(self, username, offset=0, limit=10):\n\n        \"\"\"Get the users list of friends\n\n        :param username: The username you want to get a list of friends of\n        :param offset: the pagination offset\n        :param limit: the pagination limit\n        \"\"\"\n\n        response = self._req('/user/friends/{}'.format(username), {\n            'offset' : offset,\n            'limit' : limit\n        })\n\n        friends = []\n\n        for item in response['results']:\n            f = {}\n            f['user'] = User()\n            f['user'].from_dict(item['user'])\n            f['is_watching'] = item['is_watching']\n            f['lastvisit'] = item['lastvisit']\n            f['watch'] = {\n                \"friend\" : item['watch']['friend'],\n                \"deviations\" : item['watch']['deviations'],\n                \"journals\" : item['watch']['journals'],\n                \"forum_threads\" : item['watch']['forum_threads'],\n                \"critiques\" : item['watch']['critiques'],\n                \"scraps\" : item['watch']['scraps'],\n                \"activity\" : item['watch']['activity'],\n                \"collections\" : item['watch']['collections']\n            }\n\n            friends.append(f)\n\n        return {\n            \"results\" : friends,\n            \"has_more\" : response['has_more'],\n            \"next_offset\" : response['next_offset']\n        }", "response": "Get the users list of friends of a user"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a list of statuses for a user", "response": "def get_statuses(self, username, offset=0, limit=10):\n\n        \"\"\"Fetch status updates of a user\n\n        :param username: The username you want to get a list of status updates from\n        :param offset: the pagination offset\n        :param limit: the pagination limit\n        \"\"\"\n\n        response = self._req('/user/statuses/', {\n            \"username\" : username,\n            'offset' : offset,\n            'limit' : limit\n        })\n\n        statuses = []\n\n        for item in response['results']:\n            s = Status()\n            s.from_dict(item)\n            statuses.append(s)\n\n        return {\n            \"results\" : statuses,\n            \"has_more\" : response['has_more'],\n            \"next_offset\" : response['next_offset']\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfetch the status with the given uuid", "response": "def get_status(self, statusid):\n\n        \"\"\"Fetch the status\n\n        :param statusid: Status uuid\n        \"\"\"\n\n        response = self._req('/user/statuses/{}'.format(statusid))\n\n        s = Status()\n        s.from_dict(response)\n\n        return s"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef post_status(self, body=\"\", id=\"\", parentid=\"\", stashid=\"\"):\n\n        \"\"\"Post a status\n\n        :param username: The body of the status\n        :param id: The id of the object you wish to share\n        :param parentid: The parentid of the object you wish to share\n        :param stashid: The stashid of the object you wish to add to the status\n        \"\"\"\n\n        if self.standard_grant_type is not \"authorization_code\":\n            raise DeviantartError(\"Authentication through Authorization Code (Grant Type) is required in order to connect to this endpoint.\")\n\n        response = self._req('/user/statuses/post', post_data={\n            \"body\":body,\n            \"id\":id,\n            \"parentid\":parentid,\n            \"stashid\":stashid\n        })\n\n        return response['statusid']", "response": "Post a status to the user"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn policies of DeviantArt", "response": "def get_data(self, endpoint=\"privacy\"):\n\n        \"\"\"Returns policies of DeviantArt\"\"\"\n\n        if endpoint == \"privacy\":\n            response = self._req('/data/privacy')\n        elif endpoint == \"submission\":\n            response = self._req('/data/submission')\n        elif endpoint == \"tos\":\n            response = self._req('/data/tos')\n        else:\n            raise DeviantartError(\"Unknown endpoint.\")\n\n        return response['text']"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_comments(self, endpoint=\"deviation\", deviationid=\"\", commentid=\"\", username=\"\", statusid=\"\", ext_item=False, offset=0, limit=10, maxdepth=0):\n\n        \"\"\"Fetch comments\n\n        :param endpoint: The source/endpoint you want to fetch comments from (deviation/profile/status/siblings)\n        :param deviationid: The deviationid you want to fetch\n        :param commentid: The commentid you want to fetch\n        :param username: The username you want to get a list of status updates from\n        :param statusid: The statusid you want to fetch\n        :param ext_item: the pagination limit\n        :param offset: the pagination offset\n        :param limit: the pagination limit\n        :param maxdepth: Depth to query replies until\n        \"\"\"\n\n        if endpoint == \"deviation\":\n            if deviationid:\n                response = self._req('/comments/{}/{}'.format(endpoint, deviationid), {\n                    \"commentid\" : commentid,\n                    'offset' : offset,\n                    'limit' : limit,\n                    'maxdepth' : maxdepth\n                })\n            else:\n                raise DeviantartError(\"No deviationid defined.\")\n\n        elif endpoint == \"profile\":\n            if username:\n                response = self._req('/comments/{}/{}'.format(endpoint, username), {\n                    \"commentid\" : commentid,\n                    'offset' : offset,\n                    'limit' : limit,\n                    'maxdepth' : maxdepth\n                })\n            else:\n                raise DeviantartError(\"No username defined.\")\n\n        elif endpoint == \"status\":\n            if statusid:\n                response = self._req('/comments/{}/{}'.format(endpoint, statusid), {\n                    \"commentid\" : commentid,\n                    'offset' : offset,\n                    'limit' : limit,\n                    'maxdepth' : maxdepth\n                })\n            else:\n                raise DeviantartError(\"No statusid defined.\")\n\n        elif endpoint == \"siblings\":\n            if commentid:\n                response = self._req('/comments/{}/{}'.format(commentid, endpoint), {\n                    \"ext_item\" : ext_item,\n                    'offset' : offset,\n                    'limit' : limit\n                })\n            else:\n                raise DeviantartError(\"No commentid defined.\")\n        else:\n            raise DeviantartError(\"Unknown endpoint.\")\n\n        comments = []\n\n        for item in response['thread']:\n            c = Comment()\n            c.from_dict(item)\n            comments.append(c)\n\n        return {\n            \"thread\" : comments,\n            \"has_less\" : response['has_less'],\n            \"has_more\" : response['has_more'],\n            \"prev_offset\" : response['prev_offset'],\n            \"next_offset\" : response['next_offset']\n        }", "response": "Fetch comments from a source endpoint"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npost a comment to a user", "response": "def post_comment(self, target, body, comment_type=\"profile\", commentid=\"\"):\n\n        \"\"\"Post comment\n\n        :param target: The target you want to post the comment to (username/deviation UUID/status UUID)\n        :param body: The comment text\n        :param comment_type: The type of entry you want to post your comment to\n        :param commentid: The commentid you are replying to\n        \"\"\"\n\n        if self.standard_grant_type is not \"authorization_code\":\n            raise DeviantartError(\"Authentication through Authorization Code (Grant Type) is required in order to connect to this endpoint.\")\n\n        if comment_type == \"profile\":\n            response = self._req('/comments/post/profile/{}'.format(target), post_data={\n                \"body\":body,\n                \"commentid\":commentid\n            })\n        elif comment_type == \"deviation\":\n            response = self._req('/comments/post/deviation/{}'.format(target), post_data={\n                \"body\":body,\n                \"commentid\":commentid\n            })\n        elif comment_type == \"status\":\n            response = self._req('/comments/post/status/{}'.format(target), post_data={\n                \"body\":body,\n                \"commentid\":commentid\n            })\n        else:\n            raise DeviantartError(\"Unknown comment type.\")\n\n        comment = Comment()\n        comment.from_dict(response)\n\n        return comment"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting all messages from a folder", "response": "def get_messages(self, folderid=\"\", stack=1, cursor=\"\"):\n\n        \"\"\"Feed of all messages\n\n        :param folderid: The folder to fetch messages from, defaults to inbox\n        :param stack: True to use stacked mode, false to use flat mode\n        \"\"\"\n\n        if self.standard_grant_type is not \"authorization_code\":\n            raise DeviantartError(\"Authentication through Authorization Code (Grant Type) is required in order to connect to this endpoint.\")\n\n        response = self._req('/messages/feed', {\n            'folderid' : folderid,\n            'stack' : stack,\n            'cursor' : cursor\n        })\n\n        messages = []\n\n        for item in response['results']:\n\n            m = Message()\n            m.from_dict(item)\n\n            messages.append(m)\n\n        return {\n            \"results\" : messages,\n            \"has_more\" : response['has_more'],\n            \"cursor\" : response['cursor']\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete a message or a stack", "response": "def delete_message(self, messageid=\"\", folderid=\"\", stackid=\"\"):\n\n        \"\"\"Delete a message or a message stack\n\n        :param folderid: The folder to delete the message from, defaults to inbox\n        :param messageid: The message to delete\n        :param stackid: The stack to delete\n        \"\"\"\n\n        if self.standard_grant_type is not \"authorization_code\":\n            raise DeviantartError(\"Authentication through Authorization Code (Grant Type) is required in order to connect to this endpoint.\")\n\n        response = self._req('/messages/delete', post_data={\n            'folderid' : folderid,\n            'messageid' : messageid,\n            'stackid' : stackid\n        })\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_feedback(self, feedbacktype=\"comments\", folderid=\"\", stack=1, offset=0, limit=10):\n\n        \"\"\"Fetch feedback messages\n\n        :param feedbacktype: Type of feedback messages to fetch (comments/replies/activity)\n        :param folderid: The folder to fetch messages from, defaults to inbox\n        :param stack: True to use stacked mode, false to use flat mode\n        :param offset: the pagination offset\n        :param limit: the pagination limit\n        \"\"\"\n\n        if self.standard_grant_type is not \"authorization_code\":\n            raise DeviantartError(\"Authentication through Authorization Code (Grant Type) is required in order to connect to this endpoint.\")\n\n        response = self._req('/messages/feedback', {\n            'type' : feedbacktype,\n            'folderid' : folderid,\n            'stack' : stack,\n            'offset' : offset,\n            'limit' : limit\n        })\n\n        messages = []\n\n        for item in response['results']:\n\n            m = Message()\n            m.from_dict(item)\n\n            messages.append(m)\n\n        return {\n            \"results\" : messages,\n            \"has_more\" : response['has_more'],\n            \"next_offset\" : response['next_offset']\n        }", "response": "Fetch feedback messages from the server"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfetches feedback messages in a stack", "response": "def get_feedback_in_stack(self, stackid, offset=0, limit=10):\n\n        \"\"\"Fetch feedback messages in a stack\n\n        :param stackid: Id of the stack\n        :param offset: the pagination offset\n        :param limit: the pagination limit\n        \"\"\"\n\n        if self.standard_grant_type is not \"authorization_code\":\n            raise DeviantartError(\"Authentication through Authorization Code (Grant Type) is required in order to connect to this endpoint.\")\n\n        response = self._req('/messages/feedback/{}'.format(stackid), {\n            'offset' : offset,\n            'limit' : limit\n        })\n\n        messages = []\n\n        for item in response['results']:\n\n            m = Message()\n            m.from_dict(item)\n\n            messages.append(m)\n\n        return {\n            \"results\" : messages,\n            \"has_more\" : response['has_more'],\n            \"next_offset\" : response['next_offset']\n        }"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_notes(self, folderid=\"\", offset=0, limit=10):\n\n        \"\"\"Fetch notes\n\n        :param folderid: The UUID of the folder to fetch notes from\n        :param offset: the pagination offset\n        :param limit: the pagination limit\n        \"\"\"\n\n        if self.standard_grant_type is not \"authorization_code\":\n            raise DeviantartError(\"Authentication through Authorization Code (Grant Type) is required in order to connect to this endpoint.\")\n\n        response = self._req('/notes', {\n            'folderid' : folderid,\n            'offset' : offset,\n            'limit' : limit\n        })\n\n        notes = []\n\n        for item in response['results']:\n            n = {}\n\n            n['noteid'] = item['noteid']\n            n['ts'] = item['ts']\n            n['unread'] = item['unread']\n            n['starred'] = item['starred']\n            n['sent'] = item['sent']\n            n['subject'] = item['subject']\n            n['preview'] = item['preview']\n            n['body'] = item['body']\n            n['user'] = User()\n            n['user'].from_dict(item['user'])\n            n['recipients'] = []\n\n            for recipient_item in item['recipients']:\n                u = User()\n                u.from_dict(recipient_item)\n                n['recipients'].append(u)\n\n            notes.append(n)\n\n        return {\n            \"results\" : notes,\n            \"has_more\" : response['has_more'],\n            \"next_offset\" : response['next_offset']\n        }", "response": "Fetch the notes from the folder"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfetching a single note from the server", "response": "def get_note(self, noteid):\n\n        \"\"\"Fetch a single note\n\n        :param folderid: The UUID of the note\n        \"\"\"\n\n        if self.standard_grant_type is not \"authorization_code\":\n            raise DeviantartError(\"Authentication through Authorization Code (Grant Type) is required in order to connect to this endpoint.\")\n\n        response = self._req('/notes/{}'.format(noteid))\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef send_note(self, to, subject=\"\", body=\"\", noetid=\"\"):\n\n        \"\"\"Send a note\n\n        :param to: The username(s) that this note is to\n        :param subject: The subject of the note\n        :param body: The body of the note\n        :param noetid: The UUID of the note that is being responded to\n        \"\"\"\n\n        if self.standard_grant_type is not \"authorization_code\":\n            raise DeviantartError(\"Authentication through Authorization Code (Grant Type) is required in order to connect to this endpoint.\")\n\n        response = self._req('/notes/send', post_data={\n            'to[]' : to,\n            'subject' : subject,\n            'body' : body,\n            'noetid' : noetid\n        })\n\n        sent_notes = []\n\n        for item in response['results']:\n            n = {}\n            n['success'] = item['success']\n            n['user'] = User()\n            n['user'].from_dict(item['user'])\n\n            sent_notes.append(n)\n\n        return sent_notes", "response": "Send a note to a user"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmove notes to a folder", "response": "def move_notes(self, noteids, folderid):\n\n        \"\"\"Move notes to a folder\n\n        :param noteids: The noteids to move\n        :param folderid: The folderid to move notes to\n        \"\"\"\n\n        if self.standard_grant_type is not \"authorization_code\":\n            raise DeviantartError(\"Authentication through Authorization Code (Grant Type) is required in order to connect to this endpoint.\")\n\n        response = self._req('/notes/move', post_data={\n            'noteids[]' : noteids,\n            'folderid' : folderid\n        })\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting a note or notes by their unique id", "response": "def delete_notes(self, noteids):\n\n        \"\"\"Delete a note or notes\n\n        :param noteids: The noteids to delete\n        \"\"\"\n\n        if self.standard_grant_type is not \"authorization_code\":\n            raise DeviantartError(\"Authentication through Authorization Code (Grant Type) is required in order to connect to this endpoint.\")\n\n        response = self._req('/notes/delete', post_data={\n            'noteids[]' : noteids\n        })\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mark_notes(self, noteids, mark_as):\n\n        \"\"\"Mark notes\n\n        :param noteids: The noteids to delete\n        :param mark_as: Mark notes as (read/unread/starred/notstarred/spam)\n        \"\"\"\n\n        if self.standard_grant_type is not \"authorization_code\":\n            raise DeviantartError(\"Authentication through Authorization Code (Grant Type) is required in order to connect to this endpoint.\")\n\n        response = self._req('/notes/mark', post_data={\n            'noteids[]' : noteids,\n            'mark_as' : mark_as\n        })\n\n        return response", "response": "Mark the notes in the current user s domain"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new folder in the notes folder", "response": "def create_notes_folder(self, title, parentid=\"\"):\n\n        \"\"\"Create new folder\n\n        :param title: The title of the folder to create\n        :param parentid: The UUID of the parent folder\n        \"\"\"\n\n        if self.standard_grant_type is not \"authorization_code\":\n            raise DeviantartError(\"Authentication through Authorization Code (Grant Type) is required in order to connect to this endpoint.\")\n\n        response = self._req('/notes/folders/create', post_data={\n            'title' : title,\n            'parentid' : parentid\n        })\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rename_notes_folder(self, title, folderid):\n\n        \"\"\"Rename a folder\n\n        :param title: New title of the folder\n        :param folderid: The UUID of the folder to rename\n        \"\"\"\n\n        if self.standard_grant_type is not \"authorization_code\":\n            raise DeviantartError(\"Authentication through Authorization Code (Grant Type) is required in order to connect to this endpoint.\")\n\n        response = self._req('/notes/folders/rename/{}'.format(folderid), post_data={\n            'title' : title\n        })\n\n        return response", "response": "Rename a folder\n\n        :param title: New title of the folder\n        :param folderid: The UUID of the folder to rename"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_notes_folder(self, folderid):\n\n        \"\"\"Delete note folder\n\n        :param folderid: The UUID of the folder to delete\n        \"\"\"\n\n        if self.standard_grant_type is not \"authorization_code\":\n            raise DeviantartError(\"Authentication through Authorization Code (Grant Type) is required in order to connect to this endpoint.\")\n\n        response = self._req('/notes/folders/remove/{}'.format(folderid))\n\n        return response", "response": "Delete a note folder"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _req(self, endpoint, get_data=dict(), post_data=dict()):\n\n        \"\"\"Helper method to make API calls\n\n        :param endpoint: The endpoint to make the API call to\n        :param get_data: data send through GET\n        :param post_data: data send through POST\n        \"\"\"\n\n        if get_data:\n            request_parameter = \"{}?{}\".format(endpoint, urlencode(get_data))\n        else:\n            request_parameter = endpoint\n\n        try:\n            encdata = urlencode(post_data, True).encode('utf-8')\n            response = self.oauth.request(request_parameter, data=encdata)\n            self._checkResponseForErrors(response)\n        except HTTPError as e:\n            raise DeviantartError(e)\n\n        return response", "response": "Helper method to make API calls to the NCBI API"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef revoke_tokens(self):\n\n        self.is_active = False\n        self.save()\n\n        self.refresh_token.revoke_tokens()", "response": "Revoke all tokens that were generated using it."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef revoke_tokens(self):\n\n        self.is_active = False\n        self.save()\n\n        for access_token in self.access_tokens.all():\n            access_token.revoke()", "response": "Revokes the refresh token and all access tokens that were generated using it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write(self, outfile, encoding):\n        try:\n            handler = EscapeFriendlyXMLGenerator(outfile, encoding, short_empty_elements=True)\n        except TypeError:  # Python 2\n            handler = EscapeFriendlyXMLGenerator(outfile, encoding)\n        handler.startDocument()\n        handler.startElement('rss', self.rss_attributes())\n        handler.startElement('channel', self.root_attributes())\n        self.add_root_elements(handler)\n        self.write_items(handler)\n        self.endChannelElement(handler)\n        handler.endElement('rss')", "response": "Method override to create self - closing elements."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntries to authenticate the user based on any given tokens that have been provided to the request object. This will try to detect the authentication type and assign the detected User object to the `request.user` variable, similar to the standard Django authentication.", "response": "def process_request(self, request):\n        \"\"\"\n        Try to authenticate the user based on any given tokens that have been provided\n        to the request object.  This will try to detect the authentication type and assign\n        the detected User object to the `request.user` variable, similar to the standard\n        Django authentication.\n        \"\"\"\n\n        request.auth_type = None\n        \n        http_authorization = request.META.get(\"HTTP_AUTHORIZATION\", None)\n        \n        if not http_authorization:\n            return\n        \n        auth = http_authorization.split()\n        \n        self.auth_type = auth[0].lower()\n        self.auth_value = \" \".join(auth[1:]).strip()\n        \n        request.auth_type = self.auth_type\n        \n        self.validate_auth_type()\n        \n        if not self.handler_name:\n            raise Exception(\"There is no handler defined for this authentication type.\")\n        \n        self.load_handler()\n        \n        response = self.handler.validate(self.auth_value, request)\n        \n        if response is not None:\n            return response\n        \n        request.access_token = self.handler.access_token(self.auth_value, request)\n        request.user = self.handler.authenticate(self.auth_value, request)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_handler(self):\n\n        handler_path = self.handler_name.split(\".\")\n        \n        handler_module = __import__(\".\".join(handler_path[:-1]), {}, {}, str(handler_path[-1]))\n        self.handler = getattr(handler_module, handler_path[-1])()", "response": "Load the detected handler."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nvalidates the detected authorization type against the list of handlers.", "response": "def validate_auth_type(self):\n        \"\"\"\n        Validate the detected authorization type against the list of handlers.  This will return the full\n        module path to the detected handler.\n        \"\"\"\n\n        for handler in HANDLERS:\n            handler_type = handler.split(\".\")[-2]\n            \n            if handler_type == self.auth_type:\n                self.handler_name = handler\n                \n                return\n        \n        self.handler_name = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the show feed URL with different protocol.", "response": "def show_url(context, **kwargs):\n    \"\"\"Return the show feed URL with different protocol.\"\"\"\n    if len(kwargs) != 2:\n        raise TemplateSyntaxError(_('\"show_url\" tag takes exactly two keyword arguments.'))\n    request = context['request']\n    current_site = get_current_site(request)\n    url = add_domain(current_site.domain, kwargs['url'])\n    return re.sub(r'https?:\\/\\/', '%s://' % kwargs['protocol'], url)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef loads(text):\n    from prettytoml.parser import parse_tokens\n    from prettytoml.lexer import tokenize as lexer\n    from .file import TOMLFile\n\n    tokens = tuple(lexer(text, is_top_level=True))\n    elements = parse_tokens(tokens)\n    return TOMLFile(elements)", "response": "Parses a TOML text into a dict - like object and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndump a data structure to TOML source code.", "response": "def dumps(value):\n    \"\"\"\n    Dumps a data structure to TOML source code.\n\n    The given value must be either a dict of dict values, a dict, or a TOML file constructed by this module.\n    \"\"\"\n\n    from contoml.file.file import TOMLFile\n\n    if not isinstance(value, TOMLFile):\n        raise RuntimeError(\"Can only dump a TOMLFile instance loaded by load() or loads()\")\n\n    return value.dumps()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndump a dictionary to the file specified by file_path.", "response": "def dump(obj, file_path, prettify=False):\n    \"\"\"\n    Dumps a data structure to the filesystem as TOML.\n\n    The given value must be either a dict of dict values, a dict, or a TOML file constructed by this module.\n    \"\"\"\n    with open(file_path, 'w') as fp:\n        fp.write(dumps(obj))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget current exchange rate.", "response": "def rate(base, target, error_log=None):\n    \"\"\"Get current exchange rate.\n\n    :param base: A base currency\n    :param target: Convert to the target currency\n    :param error_log: A callable function to track the exception\n\n    It parses current exchange rate from these services:\n\n        1) Yahoo finance\n        2) fixer.io\n        3) European Central Bank\n\n    It will fallback to the next service when previous not available.\n    The exchane rate is a decimal number. If `None` is returned, it means\n    the parsing goes wrong::\n\n        >>> import exchange\n        >>> exchange.rate('USD', 'CNY')\n        Decimal('6.2045')\n    \"\"\"\n    if base == target:\n        return decimal.Decimal(1.00)\n\n    services = [yahoo, fixer, ecb]\n    if error_log is None:\n        error_log = _error_log\n\n    for fn in services:\n        try:\n            return fn(base, target)\n        except Exception as e:\n            error_log(e)\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef yahoo(base, target):\n    api_url = 'http://download.finance.yahoo.com/d/quotes.csv'\n    resp = requests.get(\n        api_url,\n        params={\n            'e': '.csv',\n            'f': 'sl1d1t1',\n            's': '{0}{1}=X'.format(base, target)\n        },\n        timeout=1,\n    )\n    value = resp.text.split(',', 2)[1]\n    return decimal.Decimal(value)", "response": "Parse data from Yahoo."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses data from fixer. io.", "response": "def fixer(base, target):\n    \"\"\"Parse data from fixer.io.\"\"\"\n    api_url = 'http://api.fixer.io/latest'\n    resp = requests.get(\n        api_url,\n        params={\n            'base': base,\n            'symbols': target,\n        },\n        timeout=1,\n    )\n    data = resp.json()\n    return decimal.Decimal(data['rates'][target])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ecb(base, target):\n    api_url = 'http://www.ecb.europa.eu/stats/eurofxref/eurofxref-daily.xml'\n    resp = requests.get(api_url, timeout=1)\n    text = resp.text\n\n    def _find_rate(symbol):\n        if symbol == 'EUR':\n            return decimal.Decimal(1.00)\n        m = re.findall(r\"currency='%s' rate='([0-9\\.]+)'\" % symbol, text)\n        return decimal.Decimal(m[0])\n\n    return _find_rate(target) / _find_rate(base)", "response": "Parse data from European Central Bank."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dot(vec1, vec2):\n    if isinstance(vec1, Vector3) and isinstance(vec2, Vector3):\n        return (vec1.x * vec2.x) + (vec1.y * vec2.y) + (vec1.z * vec2.z)\n    elif isinstance(vec1, Vector4) and isinstance(vec2, Vector4):\n        return (vec1.x * vec2.x) + (vec1.y * vec2.y) + (vec1.z * vec2.z) + (vec1.w * vec2.w)\n    else:\n        raise TypeError(\"vec1 and vec2 must a Vector type\")", "response": "Returns the dot product of two Vectors"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef angle(vec1, vec2):\n    dot_vec = dot(vec1, vec2)\n    mag1 = vec1.length()\n    mag2 = vec2.length()\n    result = dot_vec / (mag1 * mag2)\n    return math.acos(result)", "response": "Returns the angle between two vectors"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef project(vec1, vec2):\n    if isinstance(vec1, Vector3) and isinstance(vec2, Vector3) \\\n            or isinstance(vec1, Vector4) and isinstance(vec2, Vector4):\n        return dot(vec1, vec2) / vec2.length() * vec2.normalize_copy()\n    else:\n        raise ValueError(\"vec1 and vec2 must be Vector3 or Vector4 objects.\")", "response": "Project vector1 onto vector2."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef component_add(vec1, vec2):\n    if isinstance(vec1, Vector3) and isinstance(vec2, Vector3):\n        addVec = Vector3()\n        addVec.x = vec1.x + vec2.x\n        addVec.y = vec1.y + vec2.y\n        addVec.z = vec1.z + vec2.z\n        return addVec\n\n    if isinstance(vec1, Vector4) and isinstance(vec2, Vector4):\n        addVec = Vector4()\n        addVec.x = vec1.x + vec2.x\n        addVec.y = vec1.y + vec2.y\n        addVec.z = vec1.z + vec2.z\n        addVec.w = vec1.w + vec2.w\n        return addVec", "response": "Add each of the components of vec1 and vec2 together and return a new vector."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef reflect(vec1, vec2):\n    if isinstance(vec1, Vector3) and isinstance(vec2, Vector3) \\\n            or isinstance(vec1, Vector4) and isinstance(vec2, Vector4):\n        return 2 * dot(vec1, vec2) * vec2 - vec2\n    else:\n        raise ValueError(\"vec1 and vec2 must both be a Vector type\")", "response": "Take vec1 and reflect it about vec2."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef copy(self):\n        new_vec = Vector2()\n        new_vec.X = self.X\n        new_vec.Y = self.Y\n        return new_vec", "response": "Create a copy of this Vector"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the length of this Vector", "response": "def length(self):\n        \"\"\"Gets the length of this Vector\"\"\"\n        return math.sqrt((self.X * self.X) + (self.Y * self.Y))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef distance(vec1, vec2):\n        if isinstance(vec1, Vector2) \\\n                and isinstance(vec2, Vector2):\n            dist_vec = vec2 - vec1\n            return dist_vec.length()\n        else:\n            raise TypeError(\"vec1 and vec2 must be Vector2's\")", "response": "Calculate the distance between two Vectors"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dot(vec1, vec2):\n        if isinstance(vec1, Vector2) \\\n                and isinstance(vec2, Vector2):\n            return ((vec1.X * vec2.X) + (vec1.Y * vec2.Y))\n        else:\n            raise TypeError(\"vec1 and vec2 must be Vector2's\")", "response": "Calculate the dot product between two Vectors"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef angle(vec1, vec2):\n        dotp = Vector2.dot(vec1, vec2)\n        mag1 = vec1.length()\n        mag2 = vec2.length()\n        result = dotp / (mag1 * mag2)\n        return math.acos(result)", "response": "Calculate the angle between two Vectors"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_polar(degrees, magnitude):\n        vec = Vector2()\n        vec.X = math.cos(math.radians(degrees)) * magnitude\n\n        # Negate because y in screen coordinates points down, oppisite from what is\n        # expected in traditional mathematics.\n        vec.Y = -math.sin(math.radians(degrees)) * magnitude\n        return vec", "response": "Convert polar coordinates to Carteasian Coordinates"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmultiplying the components of the vectors and return the result.", "response": "def component_mul(vec1, vec2):\n        \"\"\"Multiply the components of the vectors and return the result.\"\"\"\n        new_vec = Vector2()\n        new_vec.X = vec1.X * vec2.X\n        new_vec.Y = vec1.Y * vec2.Y\n        return new_vec"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndivide the components of the vectors and return the result.", "response": "def component_div(vec1, vec2):\n        \"\"\"Divide the components of the vectors and return the result.\"\"\"\n        new_vec = Vector2()\n        new_vec.X = vec1.X / vec2.X\n        new_vec.Y = vec1.Y / vec2.Y\n        return new_vec"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a copy of the Vector", "response": "def copy(self):\n        \"\"\"Create a copy of the Vector\"\"\"\n        cpy_vec = Vector3()\n        cpy_vec.x = self.x\n        cpy_vec.y = self.y\n        cpy_vec.z = self.z\n        return cpy_vec"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting this vector3 into a vector4 instance.", "response": "def to_vec4(self, isPoint):\n        \"\"\"Converts this vector3 into a vector4 instance.\"\"\"\n        vec4 = Vector4()\n        vec4.x = self.x\n        vec4.y = self.y\n        vec4.z = self.z\n        if isPoint:\n            vec4.w = 1\n        else:\n            vec4.w = 0\n\n        return vec4"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tuple_as_vec(xyz):\n        vec = Vector3()\n        vec[0] = xyz[0]\n        vec[1] = xyz[1]\n        vec[2] = xyz[2]\n        return vec", "response": "Generates a Vector3 from a tuple or list."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cross(vec1, vec2):\n        if isinstance(vec1, Vector3) and isinstance(vec2, Vector3):\n            vec3 = Vector3()\n            vec3.x = (vec1.y * vec2.z) - (vec1.z * vec2.y)\n            vec3.y = (vec1.z * vec2.x) - (vec1.x * vec2.z)\n            vec3.z = (vec1.x * vec2.y) - (vec1.y * vec2.x)\n            return vec3\n        else:\n            raise TypeError(\"vec1 and vec2 must be Vector3's\")", "response": "Returns the cross product of two Vectors"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef copy(self):\n        cpy_vec = Vector4()\n        cpy_vec.x = self.x\n        cpy_vec.y = self.y\n        cpy_vec.z = self.z\n        cpy_vec.w = self.w\n        return cpy_vec", "response": "Create a copy of the Vector"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_vec3(self):\n        vec3 = Vector3()\n        vec3.x = self.x\n        vec3.y = self.y\n        vec3.z = self.z\n\n        if self.w != 0:\n            vec3 /= self.w\n\n        return vec3", "response": "Convert this vector4 instance into a vector3 instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the length of the Vector", "response": "def length(self):\n        \"\"\"Gets the length of the Vector\"\"\"\n        return math.sqrt((self.x * self.x) + (self.y * self.y) + (self.z * self.z) + (self.w * self.w))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nclamps all the components in the vector to the specified clampVal.", "response": "def clamp(self, clampVal):\n        \"\"\"Clamps all the components in the vector to the specified clampVal.\"\"\"\n        if self.x > clampVal:\n            self.x = clampVal\n        if self.y > clampVal:\n            self.y = clampVal\n        if self.z > clampVal:\n            self.z = clampVal\n        if self.w > clampVal:\n            self.w = clampVal"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating a Vector4 from a tuple or list.", "response": "def tuple_as_vec(xyzw):\n        \"\"\"\n        Generates a Vector4 from a tuple or list.\n        \"\"\"\n        vec = Vector4()\n        vec[0] = xyzw[0]\n        vec[1] = xyzw[1]\n        vec[2] = xyzw[2]\n        vec[3] = xyzw[3]\n        return vec"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a transpose of this matrix.", "response": "def transpose(self):\n        \"\"\"Create a transpose of this matrix.\"\"\"\n        ma4 = Matrix4(self.get_col(0),\n                      self.get_col(1),\n                      self.get_col(2),\n                      self.get_col(3))\n        return ma4"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a translation matrix.", "response": "def translate(translationAmt):\n        \"\"\"Create a translation matrix.\"\"\"\n        if not isinstance(translationAmt, Vector3):\n            raise ValueError(\"translationAmt must be a Vector3\")\n\n        ma4 = Matrix4((1, 0, 0, translationAmt.x),\n                      (0, 1, 0, translationAmt.y),\n                      (0, 0, 1, translationAmt.z),\n                      (0, 0, 0, 1))\n        return ma4"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef scale(scaleAmt):\n        if not isinstance(scaleAmt, Vector3):\n            raise ValueError(\"scaleAmt must be a Vector3\")\n\n        ma4 = Matrix4((scaleAmt.x, 0, 0, 0),\n                      (0, scaleAmt.y, 0, 0),\n                      (0, 0, scaleAmt.z, 0),\n                      (0, 0, 0, 1))\n        return ma4", "response": "Create a scale matrix."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a matrix that rotates around the z axis.", "response": "def z_rotate(rotationAmt):\n        \"\"\"Create a matrix that rotates around the z axis.\"\"\"\n        ma4 = Matrix4((math.cos(rotationAmt), -math.sin(rotationAmt), 0, 0),\n                      (math.sin(rotationAmt), math.cos(rotationAmt), 0, 0),\n                      (0, 0, 1, 0),\n                      (0, 0, 0, 1))\n\n        return ma4"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a matrix that rotates around the y axis.", "response": "def y_rotate(rotationAmt):\n        \"\"\"Create a matrix that rotates around the y axis.\"\"\"\n        ma4 = Matrix4((math.cos(rotationAmt), 0, math.sin(rotationAmt), 0),\n                      (0, 1, 0, 0),\n                      (-math.sin(rotationAmt), 0, math.cos(rotationAmt), 0),\n                      (0, 0, 0, 1))\n        return ma4"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a matrix that rotates around the x axis.", "response": "def x_rotate(rotationAmt):\n        \"\"\"Create a matrix that rotates around the x axis.\"\"\"\n        ma4 = Matrix4((1, 0, 0, 0),\n                      (0, math.cos(rotationAmt), -math.sin(rotationAmt), 0),\n                      (0, math.sin(rotationAmt), math.cos(rotationAmt), 0),\n                      (0, 0, 0, 1))\n\n        return ma4"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef build_rotation(vec3):\n        if not isinstance(vec3, Vector3):\n            raise ValueError(\"rotAmt must be a Vector3\")\n        return Matrix4.x_rotate(vec3.x) * Matrix4.y_rotate(vec3.y) * Matrix4.z_rotate(vec3.z)", "response": "Build a rotation matrix."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new object for the pool.", "response": "def __init_object(self):\n        \"\"\"Create a new object for the pool.\"\"\"\n        # Check to see if the user created a specific initalization function for this object.\n        if self.init_function is not None:\n            new_obj = self.init_function()\n            self.__enqueue(new_obj)\n        else:\n            raise TypeError(\"The Pool must have a non None function to fill the pool.\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef center_origin(self):\n        self.set_origin(Vector2(self.image.get_width() / 2.0, self.image.get_height() / 2.0))", "response": "Sets the origin to the center of the image."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nscale the texture to the specfied width and height.", "response": "def scale_to(self, width_height=Vector2()):\n        \"\"\"Scale the texture to the specfied width and height.\"\"\"\n        scale_amt = Vector2()\n        scale_amt.X = float(width_height.X) / self.image.get_width()\n        scale_amt.Y = float(width_height.Y) / self.image.get_height()\n        self.set_scale(scale_amt)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_hflip(self, val):\n        if self.__horizontal_flip is not val:\n            self.__horizontal_flip = val\n            self.image = pygame.transform.flip(self.untransformed_image, val, self.__vertical_flip)", "response": "val is True or False that determines if we should horizontally flip the surface or not."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading a sprite s surface by loading the specified image from disk.", "response": "def load_texture(self, file_path):\n        \"\"\"Generate our sprite's surface by loading the specified image from disk.\n         Note that this automatically centers the origin.\"\"\"\n        self.image = pygame.image.load(file_path)\n        self.apply_texture(self.image)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nexecutes the rotating operation", "response": "def __execute_rot(self, surface):\n        \"\"\"Executes the rotating operation\"\"\"\n        self.image = pygame.transform.rotate(surface, self.__rotation)\n        self.__resize_surface_extents()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhandles scaling and rotation of the surface.", "response": "def __handle_scale_rot(self):\n        \"\"\"Handle scaling and rotation of the surface\"\"\"\n        if self.__is_rot_pending:\n            self.__execute_rot(self.untransformed_image)\n            self.__is_rot_pending = False\n\n            # Scale the image using the recently rotated surface to keep the orientation correct\n            self.__execute_scale(self.image, self.image.get_size())\n            self.__is_scale_pending = False\n\n        # The image is not rotating while scaling, thus use the untransformed image to scale.\n        if self.__is_scale_pending:\n            self.__execute_scale(self.untransformed_image, self.untransformed_image.get_size())\n            self.__is_scale_pending = False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef draw(self, milliseconds, render_surface):\n        if self.is_visible:\n            if not (self.__scale[0] == 0 or self.__scale[1] == 0):\n                if self.image is not None:\n                    # Create our rectangle to describe our sprite.\n                    tmpRect = pygame.Rect(self.coords.X - self.__origin.X,\n                                          self.coords.Y - self.__origin.Y,\n                                          self.image.get_width(),\n                                          self.image.get_height())\n                    # Apply tinting to the sprite.\n                    # tintedSurface = self.image.copy()\n                    # self.image.fill(self.tint_color, special_flags = pygame.BLEND_RGB_MULT)\n                    render_surface.blit(self.image, tmpRect, self.source, special_flags=0)", "response": "Draw the image to the specified surface."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_font(self, font_path, font_size):\n        self.__font_path = font_path\n        self.__font_size = font_size\n        if font_path != \"\":\n            self.__font = pygame.font.Font(font_path, font_size)\n            self.__set_text(self.__text)", "response": "Load the specified font from a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __render_onto_sprite(self):\n        font_surface = self.__font.render(self.__text, True, self.color)\n        self.__font_sprite.apply_texture(font_surface)\n        self.__font_sprite.center_origin()", "response": "Render the font onto a surface and store the surface into a sprite."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprepare our particle for use.", "response": "def initalize(self, physics_dta):\n        \"\"\"\n        Prepare our particle for use.\n        physics_dta describes the velocity, coordinates, and acceleration of the particle.\n        \"\"\"\n        self.rotation = random.randint(self.rotation_range[0], self.rotation_range[1])\n        self.current_time = 0.0\n        self.color = self.start_color\n        self.scale = self.start_scale\n        self.physics = physics_dta"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __release_particle(self):\n        # Calculate a potential angle for the particle.\n        angle = random.randint(int(self.direction_range[0]), int(self.direction_range[1]))\n        velocity = Vector2.from_polar(angle, self.particle_speed)\n\n        physics = PhysicsObj(self.coords, Vector2(), velocity)\n        particle = self.particle_pool.request_object()\n        particle.initalize(physics)\n        self.particles.append(particle)\n        self.current_particle_count += 1", "response": "Pull a particle from the queue and add it to the active list."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload a spritesheet texture.", "response": "def load_texture(self, file_path, cell_size=(256, 256)):\n        \"\"\"\n        Load a spritesheet texture.\n        cell_size is the uniform size of each cell in the spritesheet.\n        \"\"\"\n        super(SpriteSheet, self).load_texture(file_path)\n        self.__cell_bounds = cell_size\n        self.__generate_cells()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndraw out the specified cell", "response": "def draw(self, milliseconds, surface, cell):\n        \"\"\"Draw out the specified cell\"\"\"\n        # print self.cells[cell]\n        self.source = self.cells[cell].copy()\n        # Find the current scale of the image in relation to its original scale.\n        current_scale = Vector2()\n        current_scale.X = self.rect.width / float(self.untransformed_image.get_width())\n        current_scale.Y = self.rect.height / float(self.untransformed_image.get_height())\n        # self.source.x *= self.scale.X\n        # self.source.y *= self.scale.Y\n        self.source.width *= current_scale.X\n        self.source.height *= current_scale.Y\n        super(SpriteSheet, self).draw(milliseconds, surface)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef increment_frame(self):\n        self.current_frame += 1\n\n        if self.current_frame >= self.end_frame:\n            # Wrap back to the beginning of the animation.\n            self.current_frame = 0", "response": "Increment a frame of the animation."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_coords(self, value):\n        self.__coords = value\n        for image in self.images:\n            image.coords = value", "response": "Set all the images contained in the animation to the specified value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nflipping all the images in the animation list horizontally.", "response": "def set_hflip(self, val):\n        \"\"\"Flip all the images in the animation list horizontally.\"\"\"\n        self.__horizontal_flip = val\n        for image in self.images:\n            image.h_flip = val"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_vflip(self, val):\n        self.__vertical_flip = val\n        for image in self.images:\n            image.v_flip = val", "response": "Flip all the images in the animation list vertically."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a copy of the animation.", "response": "def copy(self):\n        \"\"\"Create a copy of the animation.\"\"\"\n        animation = AnimationList()\n        animation.set_frame_rate(self.frame_rate)\n        animation.__coords = self.__coords\n        animation.__horizontal_flip = self.__horizontal_flip\n        animation.__vertical_flip = self.__vertical_flip\n        animation.should_repeat = self.should_repeat\n        animation.draw_order = self.draw_order\n        animation.update_order = self.update_order\n        for image in self.images:\n            new_image = Sprite()\n            new_image.coords = image.coords\n            new_image.apply_texture(image.image)\n            animation.images.append(new_image)\n\n        return animation"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef increment_frame(self):\n        if self.current_frame < len(self.images):\n            self.current_frame += 1\n\n            if self.current_frame >= len(self.images):\n                # Wrap back to the beginning of the animation if should_repeat is true.\n                if self.should_repeat:\n                    self.current_frame = 0\n                else:\n                    # Clamp the current frame to the number of images we have in our list\n                    self.current_frame = len(self.images) - 1\n\n            # Set the image that is currently displaying.\n            if self.current_frame < len(self.images):\n                self.image = self.images[self.current_frame]\n                self.image.coords = self.coords", "response": "Increment a frame of the animation."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrendering the bounds of this collision ojbect onto the specified surface.", "response": "def draw(self, milliseconds, surface):\n        \"\"\"Render the bounds of this collision ojbect onto the specified surface.\"\"\"\n        super(CollidableObj, self).draw(milliseconds, surface)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_colliding(self, other):\n        if isinstance(other, AABoundingBox):\n            if self.rect.colliderect(other.rect):\n                return True\n            return False", "response": "Check to see if two AABoundingBoxes are colliding."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove the object from the Collision Manager.", "response": "def remove_object(collision_object):\n        \"\"\"Remove the collision object from the Manager\"\"\"\n        global collidable_objects\n        if isinstance(collision_object, CollidableObj):\n            # print \"Collision object of type \", type(collision_object), \" removed from the collision manager.\"\n            try:\n                collidable_objects.remove(collision_object)\n            except:\n                print\n                \"Ragnarok Says: Collision_Object with ID # \" + str(\n                    collision_object.obj_id) + \" could not be found in the Collision Manager. Skipping over...\""}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nquerying if the specified object is colliding with any of the objects currently in the Collision Manager.", "response": "def query_collision(collision_object):\n        \"\"\"\n        Check to see if the specified object is colliding with any of the objects currently in the Collision Manager\n        Returns the first object we are colliding with if there was a collision and None if no collisions was found\n        \"\"\"\n        global collidable_objects\n        # Note that we use a Brute Force approach for the time being.\n        # It performs horribly under heavy loads, but it meets\n        # our needs for the time being.\n        for obj in collidable_objects:\n            # Make sure we don't check ourself against ourself.\n            if obj.obj_id is not collision_object.obj_id:\n                if collision_object.is_colliding(obj):\n                    # A collision has been detected. Return the object that we are colliding with.\n                    return obj\n\n        # No collision was noticed. Return None.\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef draw(self, milliseconds, surface):\n        if self.is_visible:\n            global collidable_objects\n            for obj in collidable_objects:\n                if obj.is_visible:\n                    obj.draw(milliseconds, surface)\n            super(CollisionManager, self).draw(milliseconds, surface)", "response": "Render each of the collision objects onto the specified surface."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __wrap_index(self):\n        if self.current_index < 0:\n            self.current_index = len(self.gui_buttons) - 1\n        elif self.current_index >= len(self.gui_buttons):\n            self.current_index = 0", "response": "Wraps the current_index to the other side of the menu."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef move_up(self):\n        old_index = self.current_index\n        self.current_index -= 1\n        self.__wrap_index()\n        self.__handle_selections(old_index, self.current_index)", "response": "Try to select the currently selected one. If no button is selected wrap down to the bottom of the menu."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntry to select the currently selected button under the currently selected one. If no button is selected wrap down to the top of the menu.", "response": "def move_down(self):\n        \"\"\"\n        Try to select the button under the currently selected one.\n        If a button is not there, wrap down to the top of the menu and select the first button.\n        \"\"\"\n        old_index = self.current_index\n        self.current_index += 1\n        self.__wrap_index()\n        self.__handle_selections(old_index, self.current_index)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __update_keyboard(self, milliseconds):\n        if Ragnarok.get_world().Keyboard.is_clicked(self.move_up_button):\n            self.move_up()\n        elif Ragnarok.get_world().Keyboard.is_clicked(self.move_down_button):\n            self.move_down()\n        elif Ragnarok.get_world().Keyboard.is_clicked(self.select_button):\n            self.gui_buttons[self.current_index].clicked_action()\n\n        for button in self.gui_buttons:\n            button.update(milliseconds)", "response": "Use the keyboard to control selection of the buttons."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef copy(self):\n        ms = MouseState()\n        ms.left_pressed = self.left_pressed\n        ms.middle_pressed = self.middle_pressed\n        ms.right_pressed = self.right_pressed\n        ms.mouse_pos = self.mouse_pos\n        return ms", "response": "Create a copy of this MouseState and return it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef query_state(self, StateType):\n        if StateType == M_LEFT:\n            # Checking left mouse button\n            return self.left_pressed\n        elif StateType == M_MIDDLE:\n            # Checking middle mouse button\n            return self.middle_pressed\n        elif StateType == M_RIGHT:\n            # Checking right mouse button\n            return self.right_pressed", "response": "Query the state of a mouse button."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_clicked(self, MouseStateType):\n        return self.previous_mouse_state.query_state(MouseStateType) and (\n        not self.current_mouse_state.query_state(MouseStateType))", "response": "Check if the mouse button is clicked"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nis any button depressed?", "response": "def is_any_down(self):\n        \"\"\"Is any button depressed?\"\"\"\n        for key in range(len(self.current_state.key_states)):\n            if self.is_down(key):\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_any_clicked(self):\n        for key in range(len(self.current_state.key_states)):\n            if self.is_clicked(key):\n                return True\n        return False", "response": "Is any button clicked?"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a bounding box around this tile so that it can collide with objects not included in the TileManager", "response": "def generate_bbox(self, collision_function=None, tag=\"\"):\n        \"\"\"Create a bounding box around this tile so that it can collide with objects not included in the TileManager\"\"\"\n        boundingBox = AABoundingBox(None, collision_function, tag)\n        CollisionManager.add_object(boundingBox)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndraw the image to the specified surface.", "response": "def draw(self, milliseconds, surface):\n        \"\"\"Draw the image to the specified surface.\"\"\"\n        surface.blit(self.image, self.coords, self.source, special_flags=0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pixels_to_tiles(self, coords, clamp=True):\n        tile_coords = Vector2()\n        tile_coords.X = int(coords[0]) / self.spritesheet[0].width\n        tile_coords.Y = int(coords[1]) / self.spritesheet[0].height\n\n        if clamp:\n            tile_coords.X, tile_coords.Y = self.clamp_within_range(tile_coords.X, tile_coords.Y)\n\n        return tile_coords", "response": "Convert pixel coordinates into tile coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nclamping x and y so that they fall within range of the tilemap.", "response": "def clamp_within_range(self, x, y):\n        \"\"\"\n        Clamp x and y so that they fall within range of the tilemap.\n        \"\"\"\n        x = int(x)\n        y = int(y)\n\n        if x < 0:\n            x = 0\n        if y < 0:\n            y = 0\n        if x > self.size_in_tiles.X:\n            x = self.size_in_tiles.X\n        if y > self.size_in_tiles.Y:\n            y = self.size_in_tiles.Y\n\n        return x, y"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert tile coordinates into pixel coordinates", "response": "def tiles_to_pixels(self, tiles):\n        \"\"\"Convert tile coordinates into pixel coordinates\"\"\"\n        pixel_coords = Vector2()\n        pixel_coords.X = tiles[0] * self.spritesheet[0].width\n        pixel_coords.Y = tiles[1] * self.spritesheet[0].height\n        return pixel_coords"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck to see if the requested tile is part of the tile map.", "response": "def is_valid_tile(self, x, y):\n        \"\"\"Check to see if the requested tile is part of the tile map.\"\"\"\n        x = int(x)\n        y = int(y)\n\n        if x < 0:\n            return False\n        if y < 0:\n            return False\n        if x > self.size_in_tiles.X:\n            return False\n        if y > self.size_in_tiles.Y:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nunloading the current map from the world.", "response": "def unload():\n        \"\"\"Unload the current map from the world.\"\"\"\n        global __tile_maps\n        global active_map\n        if TileMapManager.active_map != None:\n            world = Ragnarok.get_world()\n\n            for obj in TileMapManager.active_map.objects:\n                world.remove_obj(obj)\n            world.remove_obj(TileMapManager.active_map)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the tile map and add it to the world.", "response": "def load(name):\n        \"\"\"Parse the tile map and add it to the world.\"\"\"\n        global __tile_maps\n        # Remove the current map.\n        TileMapManager.unload()\n\n        TileMapManager.active_map = __tile_maps[name]\n        TileMapManager.active_map.parse_tilemap()\n        TileMapManager.active_map.parse_collisions()\n        TileMapManager.active_map.parse_objects()\n\n        world = Ragnarok.get_world()\n        world.add_obj(TileMapManager.active_map)\n\n        for obj in TileMapManager.active_map.objects:\n            world.add_obj(obj)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_movement_delta(self):\n        pos = self.pan - self.previous_pos\n        self.previous_pos = Vector2(self.pan.X, self.pan.Y)\n        return pos", "response": "Get the amount the camera has moved since get_movement_delta was last called."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nresets the camera to its defaults.", "response": "def Reset(self):\n        \"\"\"Reset the camera back to its defaults.\"\"\"\n        self.pan = self.world_center\n        self.desired_pan = self.pos"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_bounds(self):\n        if not (self.camera_bounds == None):\n            if self.__pan.X < self.camera_bounds.Left:\n                self.__pan[0] = self.camera_bounds.Left\n\n            if self.__pan.X > self.camera_bounds.Right:\n                self.__pan[0] = self.camera_bounds.Right\n\n            if self.__pan.Y < self.camera_bounds.Top:\n                self.__pan[1] = self.camera_bounds.Top\n\n            if self.__pan.Y > self.camera_bounds.Bottom:\n                self.__pan[1] = self.camera_bounds.Bottom", "response": "Make sure the camera is outside if its legal range."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the bounds of the camera in x y max and yMax format.", "response": "def get_cam_bounds(self):\n        \"\"\"Return the bounds of the camera in x, y, xMax, and yMax format.\"\"\"\n        world_pos = self.get_world_pos()\n        screen_res = Ragnarok.get_world().get_backbuffer_size() * .5\n        return (self.pan.X - screen_res.X), (self.pan.Y - screen_res.Y), (self.pan.X + screen_res.X), (\n                self.pan.Y + screen_res.Y)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating the camera s view bounds.", "response": "def update_view_bounds(self):\n        \"\"\"Update the camera's view bounds.\"\"\"\n        self.view_bounds.left = self.pan.X - self.world_center.X\n        self.view_bounds.top = self.pan.Y - self.world_center.Y\n        self.view_bounds.width = self.world_center.X * 2\n        self.view_bounds.height = self.world_center.Y * 2"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating the backbuffer for the game.", "response": "def set_backbuffer(self, preferred_backbuffer_size, flags=0):\n        \"\"\"Create the backbuffer for the game.\"\"\"\n        if not (isinstance(preferred_backbuffer_size, Vector2)):\n            raise ValueError(\"preferred_backbuffer_size must be of type Vector2\")\n\n        self.__backbuffer = pygame.display.set_mode(preferred_backbuffer_size, flags)\n        self.Camera.world_center = preferred_backbuffer_size / 2.0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_display_at_native_res(self, should_be_fullscreen=True):\n        # Loop through all our display modes until we find one that works well.\n        for mode in self.display_modes:\n            color_depth = pygame.display.mode_ok(mode)\n            if color_depth is not 0:\n                if should_be_fullscreen:\n                    should_fill = pygame.FULLSCREEN\n                else:\n                    should_fill = 0\n\n                self.backbuffer = pygame.display.set_mode(mode, should_fill, color_depth)\n                break", "response": "Sets the display to the native resolution."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_backbuffer_size(self):\n        vec = Vector2()\n        vec.X = self.backbuffer.get_width()\n        vec.Y = self.backbuffer.get_height()\n        return vec", "response": "Get the width and height of the backbuffer as a Vector2."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsearch through all the objects in the world and return the first instance whose tag matches the specified string.", "response": "def find_obj_by_tag(self, tag):\n        \"\"\"Search through all the objects in the world and\n        return the first instance whose tag matches the specified string.\"\"\"\n        for obj in self.__up_objects:\n            if obj.tag == tag:\n                return obj\n\n        for obj in self.__draw_objects:\n            if obj.tag == tag:\n                return obj\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove_by_tag(self, tag):\n        obj = self.find_obj_by_tag(tag)\n        if obj != None:\n            self.remove_obj(obj)\n            return True\n\n        return False", "response": "Removes the first encountered object with the specified tag from the world. Returns True if an object was found and removed False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndefine how our drawable objects should be sorted", "response": "def __draw_cmp(self, obj1, obj2):\n        \"\"\"Defines how our drawable objects should be sorted\"\"\"\n        if obj1.draw_order > obj2.draw_order:\n            return 1\n        elif obj1.draw_order < obj2.draw_order:\n            return -1\n        else:\n            return 0"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndefining how our updatable objects should be sorted", "response": "def __up_cmp(self, obj1, obj2):\n        \"\"\"Defines how our updatable objects should be sorted\"\"\"\n        if obj1.update_order > obj2.update_order:\n            return 1\n        elif obj1.update_order < obj2.update_order:\n            return -1\n        else:\n            return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsorts the updatable objects according to ascending order", "response": "def __sort_up(self):\n\n        \"\"\"Sort the updatable objects according to ascending order\"\"\"\n        if self.__do_need_sort_up:\n            self.__up_objects.sort(key=cmp_to_key(self.__up_cmp))\n            self.__do_need_sort_up = False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsorting the drawable objects according to ascending order", "response": "def __sort_draw(self):\n        \"\"\"Sort the drawable objects according to ascending order\"\"\"\n        if self.__do_need_sort_draw:\n            self.__draw_objects.sort(key=cmp_to_key(self.__draw_cmp))\n            self.__do_need_sort_draw = False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate all of the objects in our world.", "response": "def update(self, milliseconds):\n        \"\"\"Updates all of the objects in our world.\"\"\"\n        self.__sort_up()\n        for obj in self.__up_objects:\n            obj.update(milliseconds)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ensure_path(filename):\n    dirname = os.path.dirname(filename)\n    if dirname and not os.path.exists(dirname):\n        os.makedirs(dirname)", "response": "Check if path to filename exists and create the necessary directories."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlocates all files matching pattern in and below the root directory.", "response": "def locate_files(pattern, root_dir=os.curdir):\n    \"\"\"\n    Locate all files matching fiven filename pattern in and below\n    supplied root directory.\n    \"\"\"\n    for dirpath, dirnames, filenames in os.walk(os.path.abspath(root_dir)):\n        for filename in fnmatch.filter(filenames, pattern):\n            yield os.path.join(dirpath, filename)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove all files and directories in supplied root directory.", "response": "def remove_files(root_dir):\n    \"\"\"\n    Remove all files and directories in supplied root directory.\n    \"\"\"\n    for dirpath, dirnames, filenames in os.walk(os.path.abspath(root_dir)):\n        for filename in filenames:\n            os.remove(os.path.join(root_dir, filename))\n\n        for dirname in dirnames:\n            shutil.rmtree(os.path.join(root_dir, dirname))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nedits a file name by adding a prefix inserting a suffix in front of a file name extension and replacing the extension.", "response": "def edit_filename(filename, prefix='', suffix='', new_ext=None):\n    \"\"\"\n    Edit a file name by add a prefix, inserting a suffix in front of a file\n    name extension or replacing the extension.\n\n    Parameters\n    ----------\n    filename : str\n        The file name.\n    prefix : str\n        The prefix to be added.\n    suffix : str\n        The suffix to be inserted.\n    new_ext : str, optional\n        If not None, it replaces the original file name extension.\n\n    Returns\n    -------\n    new_filename : str\n        The new file name.\n    \"\"\"\n    base, ext = os.path.splitext(filename)\n\n    if new_ext is None:\n        new_filename = base + suffix + ext\n\n    else:\n        new_filename = base + suffix + new_ext\n\n    return new_filename"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the max. number of digits in range ( n_step ) and the corresponding oment format string.", "response": "def get_print_info(n_step, fill=None):\n    \"\"\"\n    Returns the max. number of digits in range(n_step) and the corresponding\n    format string.\n\n    Examples:\n\n    >>> get_print_info(11)\n    (2, '%2d')\n    >>> get_print_info(8)\n    (1, '%1d')\n    >>> get_print_info(100)\n    (2, '%2d')\n    >>> get_print_info(101)\n    (3, '%3d')\n    >>> get_print_info(101, fill='0')\n    (3, '%03d')\n    \"\"\"\n    if n_step > 1:\n        n_digit = int(nm.log10(n_step - 1) + 1)\n        if fill is None:\n            format = '%%%dd' % n_digit\n        else:\n            format = '%%%s%dd' % (fill, n_digit)\n    else:\n        n_digit, format = 0, None\n    return n_digit, format"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef skip_read_line(fd, no_eof=False):\n    ls = ''\n    while 1:\n        try:\n            line = fd.readline()\n\n        except EOFError:\n            break\n\n        if not line:\n            if no_eof:\n                raise EOFError\n\n            else:\n                break\n\n        ls = line.strip()\n        if ls and (ls[0] != '#'):\n            break\n\n    return ls", "response": "Reads the first non - empty line from the given file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread a single token from the given file object.", "response": "def read_token(fd):\n    \"\"\"\n    Read a single token (sequence of non-whitespace characters) from the\n    given file object.\n\n    Notes\n    -----\n    Consumes the first whitespace character after the token.\n    \"\"\"\n    out = ''\n    # Skip initial whitespace.\n\n    while 1:\n        ch = fd.read(1)\n        if ch.isspace(): continue\n        elif len(ch) == 0: return out\n        else: break\n\n    while not ch.isspace():\n        out = out + ch\n        ch = fd.read(1)\n        if len(ch) == 0: break\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading a NumPy array of shape ( n_row n_col ) from the given file object and cast it to type dtype.", "response": "def read_array(fd, n_row, n_col, dtype):\n    \"\"\"\n    Read a NumPy array of shape `(n_row, n_col)` from the given file\n    object and cast it to type `dtype`.\n    If `n_col` is None, determine the number of columns automatically.\n    \"\"\"\n    if n_col is None:\n        idx = fd.tell()\n        row = fd.readline().split()\n        fd.seek(idx)\n        n_col = len(row)\n\n    count = n_row * n_col\n    val = nm.fromfile(fd, sep=' ', count=count)\n\n    if val.shape[0] < count:\n        raise ValueError('(%d, %d) array reading failed!' % (n_row, n_col))\n\n    val = nm.asarray(val, dtype=dtype)\n    val.shape = (n_row, n_col)\n\n    return val"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write_sparse_matrix_hdf5(filename, mtx, name='a sparse matrix'):\n    fd = pt.openFile(filename, mode='w', title=name)\n    try:\n        info = fd.createGroup('/', 'info')\n        fd.createArray(info, 'dtype', mtx.dtype.str)\n        fd.createArray(info, 'shape', mtx.shape)\n        fd.createArray(info, 'format', mtx.format)\n\n        data = fd.createGroup('/', 'data')\n        fd.createArray(data, 'data', mtx.data)\n        fd.createArray(data, 'indptr', mtx.indptr)\n        fd.createArray(data, 'indices', mtx.indices)\n\n    except:\n        print 'matrix must be in SciPy sparse CSR/CSC format!'\n        print mtx.__repr__()\n        raise\n\n    fd.close()", "response": "Write a sparse matrix to HDF5 file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfetch the fethces friends from Facebook using the oauth_tokencoherent_auth_backend.", "response": "def fetch_friends(self, user, paginate=False):\n        \"\"\"\n        fethces friends from facebook using the oauth_token\n        fethched by django-social-auth.\n\n        Note - user isn't a user - it's a UserSocialAuth if using social auth, or a SocialAccount if using allauth\n\n        Returns:\n            collection of friend objects fetched from facebook\n        \"\"\"\n\n        if USING_ALLAUTH:\n            social_app = SocialApp.objects.get_current('facebook')\n            oauth_token = SocialToken.objects.get(account=user, app=social_app).token\n        else:\n            social_auth_backend = FacebookBackend()\n\n            # Get the access_token\n            tokens = social_auth_backend.tokens(user)\n            oauth_token = tokens['access_token']\n\n        graph = facebook.GraphAPI(oauth_token)\n\n        friends = graph.get_connections(\"me\", \"friends\")\n\n        if paginate:\n            total_friends = friends.copy()\n            total_friends.pop('paging')\n            while 'paging' in friends and 'next' in friends['paging'] and friends['paging']['next']:\n                next_url = friends['paging']['next']\n                next_url_parsed = urlparse.urlparse(next_url)\n                query_data = urlparse.parse_qs(next_url_parsed.query)\n                query_data.pop('access_token')\n                for k, v in query_data.items():\n                    query_data[k] = v[0]\n                friends = graph.get_connections(\"me\", \"friends\", **query_data)\n                total_friends['data'] = sum([total_friends['data'], friends['data']], [])\n        else:\n            total_friends = friends\n\n        return total_friends"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nauthenticate the request and return the user and access token.", "response": "def authenticate(self, request):\n        \"\"\"\n        Send the request through the authentication middleware that\n        is provided with DOAC and grab the user and token from it.\n        \"\"\"\n\n        from doac.middleware import AuthenticationMiddleware\n\n        try:\n            response = AuthenticationMiddleware().process_request(request)\n        except:\n            raise exceptions.AuthenticationFailed(\"Invalid handler\")\n\n        if not hasattr(request, \"user\") or not request.user.is_authenticated():\n            return None\n\n        if not hasattr(request, \"access_token\"):\n            raise exceptions.AuthenticationFailed(\"Access token was not valid\")\n\n        return request.user, request.access_token"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef override(settings, yaml=None, env=None):\n    if yaml is not None:\n        if hasattr(yaml, 'read'):\n            settings.update(load_yaml(yaml.read()))\n        else:\n            if os.path.exists(yaml):\n                with open(yaml) as f:\n                    settings.update(load_yaml(f.read()))\n\n    if env is not None:\n        for k, v in os.environ.items():\n            if k.startswith(env):\n                settings[k[len(env):]] = load_yaml(v)", "response": "Override the settings dict with the values from the specified YAML file or environment variables."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef scope_required(*scopes):\n    \n    def decorator(view_func):\n    \n        @wraps(view_func, assigned=available_attrs(view_func))\n        def _wrapped_view(request, *args, **kwargs):\n            from django.http import HttpResponseBadRequest, HttpResponseForbidden\n            from .exceptions.base import InvalidRequest, InsufficientScope\n            from .models import Scope\n            from .utils import request_error_header\n            \n            try:\n                if not hasattr(request, \"access_token\"):\n                    raise CredentialsNotProvided()\n                \n                access_token = request.access_token\n                \n                for scope_name in scopes:\n                    try:\n                        scope = access_token.scope.for_short_name(scope_name)\n                    except Scope.DoesNotExist:\n                        raise ScopeNotEnough()\n            except InvalidRequest as e:\n                response = HttpResponseBadRequest()\n                response[\"WWW-Authenticate\"] = request_error_header(e)\n            \n                return response\n            except InsufficientScope as e:\n                response = HttpResponseForbidden()\n                response[\"WWW-Authenticate\"] = request_error_header(e)\n                \n                return response\n            \n            return view_func(request, *args, **kwargs)\n            \n        return _wrapped_view\n    \n    if scopes and hasattr(scopes[0], \"__call__\"):\n        func = scopes[0]\n        scopes = scopes[1:]\n        return decorator(func)\n    \n    return decorator", "response": "Decorator for views that checks for specific scopes that the access token has been authenticated for the resource and if they are not required for the resource."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprepare the social friend list", "response": "def get(self, request, provider=None):\n        \"\"\"prepare the social friend model\"\"\"\n        # Get the social auth connections\n        if USING_ALLAUTH:\n            self.social_auths = request.user.socialaccount_set.all()\n        else:\n            self.social_auths = request.user.social_auth.all()\n                \n        self.social_friend_lists = []\n\n        # if the user did not connect any social accounts, no need to continue\n        if self.social_auths.count() == 0:\n            if REDIRECT_IF_NO_ACCOUNT:\n                return HttpResponseRedirect(REDIRECT_URL)\n            return super(FriendListView, self).get(request)\n\n        # for each social network, get or create social_friend_list\n        self.social_friend_lists = SocialFriendList.objects.get_or_create_with_social_auths(self.social_auths)\n\n        return super(FriendListView, self).get(request)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_context_data(self, **kwargs):\n        context = super(FriendListView, self).get_context_data(**kwargs)\n\n        friends = []\n        for friend_list in self.social_friend_lists:\n            fs = friend_list.existing_social_friends()\n            for f in fs:\n                friends.append(f)\n\n        # Add friends to context\n        context['friends'] = friends\n\n        connected_providers = []\n        for sa in self.social_auths:\n            connected_providers.append(sa.provider)\n        context['connected_providers'] = connected_providers\n\n        return context", "response": "Returns the context data for the current user."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if any of the requirement files used by testenv are updated.", "response": "def are_requirements_changed(config):\n    \"\"\"Check if any of the requirement files used by testenv is updated.\n\n    :param tox.config.TestenvConfig config: Configuration object to observe.\n    :rtype: bool\n    \"\"\"\n    deps = (dep.name for dep in config.deps)\n\n    def build_fpath_for_previous_version(fname):\n        tox_dir = config.config.toxworkdir.strpath\n        envdirkey = _str_to_sha1hex(str(config.envdir))\n        fname = '{0}.{1}.previous'.format(fname.replace('/', '-'), envdirkey)\n        return os.path.join(tox_dir, fname)\n\n    requirement_files = map(parse_requirements_fname, deps)\n    return any([\n        is_changed(reqfile, build_fpath_for_previous_version(reqfile))\n        for reqfile in requirement_files\n        if reqfile and os.path.isfile(reqfile)])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_pip_requirements(requirement_file_path):\n    return sorted(\n        str(r.req)\n        for r in parse_requirements(requirement_file_path,\n                                    session=PipSession())\n        if r.req\n    )", "response": "Parses pip requirements file and returns a list of all the available modules."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if the requirements file is updated relatively to the previous version of the file.", "response": "def is_changed(fpath, prev_version_fpath):\n    \"\"\"Check requirements file is updated relatively to prev. version of the file.\n\n    :param str fpath: Path to the requirements file.\n    :param str prev_version_fpath: Path to the prev. version requirements file.\n    :rtype: bool\n    :raise ValueError: Requirements file doesn't exist.\n    \"\"\"\n    if not (fpath and os.path.isfile(fpath)):\n        raise ValueError(\"Requirements file {0!r} doesn't exist.\".format(fpath))\n\n    # Compile the list of new requirements.\n    new_requirements = parse_pip_requirements(fpath)\n\n    # Hash them.\n    new_requirements_hash = _str_to_sha1hex(str(new_requirements))\n\n    # Read the hash of the previous requirements if any.\n    previous_requirements_hash = 0\n    if os.path.exists(prev_version_fpath):\n        with open(prev_version_fpath) as fd:\n            previous_requirements_hash = fd.read()\n\n    # Create/Update the file with the hash of the new requirements.\n    dirname = os.path.dirname(prev_version_fpath)\n    # First time when running tox in the project .tox directory is missing.\n    if not os.path.isdir(dirname):\n        os.makedirs(dirname)\n    with open(prev_version_fpath, 'w+') as fd:\n        fd.write(new_requirements_hash)\n\n    # Compare the hash of the new requirements with the hash of the previous\n    # requirements.\n    return previous_requirements_hash != new_requirements_hash"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_player_collision(self):\n        player_tiles = r.TileMapManager.active_map.grab_collisions(self.char.coords)\n        enemy_tiles = r.TileMapManager.active_map.grab_collisions(self.coords)\n\n        #Check to see if any of the tiles are the same. If so, there is a collision.\n        for ptile in player_tiles:\n            for etile in enemy_tiles:\n                if r.TileMapManager.active_map.pixels_to_tiles(ptile.coords) == r.TileMapManager.active_map.pixels_to_tiles(etile.coords):\n                    return True\n\n        return False", "response": "Check to see if we are colliding with the player."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck a candidate number for validity according to the Luhn algorithm.", "response": "def luhn(candidate):\n    \"\"\"\n    Checks a candidate number for validity according to the Luhn\n    algorithm (used in validation of, for example, credit cards).\n    Both numeric and string candidates are accepted.\n    \"\"\"\n    if not isinstance(candidate, six.string_types):\n        candidate = str(candidate)\n    try:\n        evens = sum(int(c) for c in candidate[-1::-2])\n        odds = sum(LUHN_ODD_LOOKUP[int(c)] for c in candidate[-2::-2])\n        return ((evens + odds) % 10 == 0)\n    except ValueError:  # Raised if an int conversion fails\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef discover(timeout=1, retries=1):\n    locations = []\n\n    group = ('239.255.255.250', 1900)\n    service = 'ssdp:urn:schemas-upnp-org:device:MediaRenderer:1'  # 'ssdp:all'\n    message = '\\r\\n'.join(['M-SEARCH * HTTP/1.1',\n                           'HOST: {group[0]}:{group[1]}',\n                           'MAN: \"ssdp:discover\"',\n                           'ST: {st}',\n                           'MX: 1', '', '']).format(group=group, st=service)\n\n    socket.setdefaulttimeout(timeout)\n    for _ in range(retries):\n        sock = socket.socket(socket.AF_INET,\n                             socket.SOCK_DGRAM,\n                             socket.IPPROTO_UDP)\n        # socket options\n        sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        sock.setsockopt(socket.IPPROTO_IP, socket.IP_MULTICAST_TTL, 2)\n\n        # send group multicast\n        sock.sendto(message.encode('utf-8'), group)\n\n        while True:\n            try:\n                response = sock.recv(2048).decode('utf-8')\n                for line in response.split('\\r\\n'):\n                    if line.startswith('Location: '):\n                        location = line.split(' ')[1].strip()\n                        if not location in locations:\n                            locations.append(location)\n            except socket.timeout:\n                break\n    devices = [RaumfeldDevice(location) for location in locations]\n\n    # only return 'Virtual Media Player' and sort the list\n    return sorted([device for device in devices\n                   if device.model_description == 'Virtual Media Player'],\n                  key=lambda device: device.friendly_name)", "response": "Discover Raumfeld devices in the network."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef play(self, uri=None):\n        if uri:\n            self.av_transport.SetAVTransportURI(\n                InstanceID=1, CurrentURI=uri, CurrentURIMetaData=\"\")\n        else:\n            self.av_transport.Play(InstanceID=1, Speed=2)", "response": "Start playing a specific uri\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mute(self):\n        response = self.rendering_control.GetMute(InstanceID=1, Channel=1)\n        return response.CurrentMute == 1", "response": "get the current mute state"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget an instance of backend type with the given id.", "response": "def get(cls, backend_id):\n        \"\"\"\n        Return an instance of backend type\n        \"\"\"\n\n        for backend_class in cls._get_backends_classes():\n            if backend_class.id == backend_id:\n                return backend_class.create()\n\n        raise InvalidBackendError(\n            cls.backend_type,\n            backend_id,\n            get_installed_pools()[cls.backend_type]\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a vis3d HTML document.", "response": "def html(data, options, center=False, save=False,\n         save_name=None, save_path='saved', dated=True, notebook=True):\n    \"\"\"\n    save=True will create a standalone HTML doc under localdir/saved (creating folfer save if necessary)\n    center=True will center the plot in the output cell, otherwise left-aligned by default.\n    \"\"\"\n\n    def json_dumps(obj):\n        return pd.io.json.dumps(obj)\n\n    _options = dict(options)\n    _data = data\n\n    def clean_function_str(key, n=15):\n        \"\"\"\n        Remove new line characters in the first say 15 characters\n        of the value corresponding to key in dictionary _options.\n        This value is a string that potentially starts with\n        'function' or ' function' or '[newline]function' or '[newline]function', etc\n        This cleaning makes js string parsing easier to recognize functions.\n        \"\"\"\n        if key in _options.keys():\n            new_str = _options[key][:n].replace('\\n', '')\n            new_str = new_str.replace('\\r', '')\n            new_str = new_str + _options[key][n:]\n            _options[key] = new_str\n\n    clean_function_str('tooltip')\n    clean_function_str('xValueLabel')\n    clean_function_str('yValueLabel')\n    clean_function_str('zValueLabel')\n\n    chart_id = str(uuid.uuid4()).replace('-', '_')\n\n    js_init = \"\"\"\n    var options = %s;\n    %s\n    window.opt = jQuery.extend(true, {}, options);\n    console.log('vis3d options accessible as opt');\n    \n    var data = %s;\n    %s\n    window.dta = jQuery.extend(true, [], data);\n    console.log('vis3d data accessible as dta');\n    \"\"\" % (json_dumps(_options), JS_JSON_PARSE_OPTION,\n           json_dumps(_data), JS_JSON_PARSE_DATA)\n\n    js_call = \"\"\"\n    var container = document.getElementById('%s');\n    console.log(options);\n    console.log(data);\n    graph3d = new vis.Graph3d(container, data, options);\n    \"\"\" % (chart_id)\n\n    if center:\n        if not 'width' in _options.keys():\n            # Explicitly sets width to default value\n            _options['width'] = '750px'\n\n        html = \"\"\"\n        <div id=\"%s\" style=\"margin: auto; width: %s;\"></div>\n        \"\"\" % (chart_id, _options['width'])\n    else:\n        html = \"\"\"\n        <div id=\"%s\"></div>\n        \"\"\" % (chart_id)\n\n    css = \"\"\"\n    <link href=\"%s\" rel=\"stylesheet\" type=\"text/css\" />\n    \"\"\" % (CSS_LIBS_ONE)\n\n    js = \"\"\"<script>\n    // the Jupyter notebook loads jquery.min.js  and require.js and at the top of the page\n    // then to make jquery available inside a require module\n    // the trick is http://www.manuel-strehl.de/dev/load_jquery_before_requirejs.en.html\n    require(%s, function(lib) {\n        window.vis = jQuery.extend(true, {}, lib);\n        %s\n        %s\n    });\n    </script>\"\"\" % (JS_LIBS_ONE, js_init, js_call)\n\n    # save\n    js_load = ''.join(['<script src=\"%s\"></script>' % e for e in JS_SAVE])\n    if save == True:\n        if not os.path.exists(save_path):\n            os.makedirs(save_path)\n        tag = save_name if save_name else 'plot'\n        dated = dt.datetime.now().strftime('_%Y%m%d_%H%M%S') if dated else ''\n\n        with open(os.path.join(save_path, tag + dated + '.html'), 'w') as f:\n            f.write(js_load + html + js)\n\n    if notebook:\n        return html + js\n    else:\n        return js_load + html + js\n\n    return html + css + js"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fetch_friends(self, user):\n\n        if USING_ALLAUTH:\n            social_app = SocialApp.objects.get_current('google')\n            oauth_token = SocialToken.objects.get(account=user, app=social_app).token\n        else:\n            social_auth_backend = GoogleOAuth2Backend()\n            # Get the access_token\n            tokens = social_auth_backend.tokens(user)\n            oauth_token = tokens['access_token']\n\n        credentials = gdata.gauth.OAuth2Token(\n            client_id=settings.GOOGLE_OAUTH2_CLIENT_ID,\n            client_secret=settings.GOOGLE_OAUTH2_CLIENT_SECRET,\n            scope='https://www.google.com/m8/feeds/',\n            user_agent='gdata',\n            access_token=oauth_token\n        )\n        client = gdata.contacts.client.ContactsClient()\n        credentials.authorize(client)\n        contacts = client.get_contacts()\n        data = feedparser.parse(contacts.to_string())['entries']\n\n        return data", "response": "Fetches the friends from g + using the Google Contact API."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfetch friend email s from g + returns a list of friend email s", "response": "def fetch_friend_ids(self, user):\n        \"\"\"\n        fetches friend email's from g+\n\n        Return:\n            collection of friend emails (ids)\n        \"\"\"\n        friends = self.fetch_friends(user)\n\n        return [friend['ns1_email']['address']\n                for friend in friends\n                if 'ns1_email' in friend]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nhandles an unspecified exception and return the correct method that should be used for handling it.", "response": "def handle_exception(self, exception):\n        \"\"\"\n        Handle a unspecified exception and return the correct method that should be used\n        for handling it.\n\n        If the exception has the `can_redirect` property set to False, it is\n        rendered to the browser.  Otherwise, it will be redirected to the location\n        provided in the `RedirectUri` object that is associated with the request.\n        \"\"\"\n\n        can_redirect = getattr(exception, \"can_redirect\", True)\n        redirect_uri = getattr(self, \"redirect_uri\", None)\n\n        if can_redirect and redirect_uri:\n            return self.redirect_exception(exception)\n        else:\n            return self.render_exception(exception)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild the query string for the exception and return a redirect to the redirect uri that was associated with the request.", "response": "def redirect_exception(self, exception):\n        \"\"\"\n        Build the query string for the exception and return a redirect to the\n        redirect uri that was associated with the request.\n        \"\"\"\n\n        from django.http import QueryDict, HttpResponseRedirect\n\n        query = QueryDict(\"\").copy()\n        query[\"error\"] = exception.error\n        query[\"error_description\"] = exception.reason\n        query[\"state\"] = self.state\n\n        return HttpResponseRedirect(self.redirect_uri.url + \"?\" + query.urlencode())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef render_exception_js(self, exception):\n\n        from .http import JsonResponse\n\n        response = {}\n        response[\"error\"] = exception.error\n        response[\"error_description\"] = exception.reason\n\n        return JsonResponse(response, status=getattr(exception, 'code', 400))", "response": "Render an exception as JSON - formatted JSON."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef verify_dictionary(self, dict, *args):\n\n        for arg in args:\n            setattr(self, arg, dict.get(arg, None))\n\n            if hasattr(self, \"verify_\" + arg):\n                func = getattr(self, \"verify_\" + arg)\n                func()", "response": "This method will validate all of the contents of a dictionary that are not in the dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef verify_client_id(self):\n\n        from .models import Client\n        from .exceptions.invalid_client import ClientDoesNotExist\n        from .exceptions.invalid_request import ClientNotProvided\n\n        if self.client_id:\n            try:\n                self.client = Client.objects.for_id(self.client_id)\n            # Catching also ValueError for the case when client_id doesn't contain an integer.\n            except (Client.DoesNotExist, ValueError):\n                raise ClientDoesNotExist()\n        else:\n            raise ClientNotProvided()", "response": "Verify a client id against the database and set the self. client attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write(self, data):\n        if self.stream.closed():\n            return False\n\n        if isinstance(data, self.app.box_class):\n            # \u6253\u5305\n            data = data.pack()\n        elif isinstance(data, dict):\n            data = self.app.box_class(data).pack()\n\n        self.app.events.before_response(self, data)\n        for bp in self.app.blueprints:\n            bp.events.before_app_response(self, data)\n\n        ret = self.stream.write(data)\n\n        for bp in self.app.blueprints:\n            bp.events.after_app_response(self, data, ret)\n        self.app.events.after_response(self, data, ret)\n\n        return ret", "response": "Write data to the stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _on_read_complete(self, data):\n        request = self.app.request_class(self, data)\n        self._handle_request(request)", "response": "Handle the read request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set(self, interval, callback, repeat=False, force=True):\n        if self.timer:\n            if force:\n                # \u5982\u679c\u5df2\u7ecf\u5b58\u5728\uff0c\u90a3\u4e48\u5148\u8981\u628a\u73b0\u5728\u7684\u6e05\u7a7a\n                self.clear()\n            else:\n                # \u5df2\u7ecf\u5b58\u5728\u7684\u8bdd\uff0c\u5c31\u8fd4\u56de\u4e86\n                return\n\n        def callback_wrapper():\n\n            # \u5fc5\u987b\u8981\u786e\u5b9a\uff0c\u8fd9\u6b21\u8c03\u7528\u5c31\u662f\u8fd9\u4e2atimer\u5f15\u8d77\u7684\n            if self.timer == timer:\n                self.timer = None\n                result = safe_call(callback)\n                if repeat and not self.timer:\n                    # \u4e4b\u6240\u4ee5\u8fd8\u8981\u5224\u65adtimer\uff0c\u662f\u56e0\u4e3acallback\u4e2d\u53ef\u80fd\u8bbe\u7f6e\u4e86\u65b0\u7684\u56de\u8c03\n                    self.set(interval, callback, repeat, True)\n                return result\n\n        self.timer = timer = threading.Timer(interval, callback_wrapper)\n        # \u8ddf\u7740\u4e3b\u7ebf\u7a0b\u7ed3\u675f\u3002\u9ed8\u8ba4\u503c\u662f\u548c\u521b\u5efa\u7684\u7ebf\u7a0b\u4e00\u81f4\n        timer.daemon = True\n        timer.start()", "response": "set method that will set the timer and call the callback if repeat is True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the normalized Vector", "response": "def normalize(self):\n        \"\"\"Gets the normalized Vector\"\"\"\n        length = self.length()\n        if length > 0:\n            self.X /= length\n            self.Y /= length\n        else:\n            print \"Length 0, cannot normalize.\""}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks to see if this matrix is an identity matrix.", "response": "def is_identity():\n        \"\"\"Check to see if this matrix is an identity matrix.\"\"\"\n        for index, row in enumerate(self.dta):\n            if row[index] == 1:\n                for num, element in enumerate(row):\n                    if num != index:\n                        if element != 0:\n                            return False\n            else:\n                return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run(self):\n        global world\n        self.__is_running = True\n        while(self.__is_running):\n            #Our game loop\n\n            #Catch our events\n            self.__handle_events()\n\n\t        #Update our clock\n            self.__clock.tick(self.preferred_fps)\n            elapsed_milliseconds = self.__clock.get_time()\n    \t    if 2 in self.event_flags:\n                self.elapsed_milliseconds = 0\n\n            #Print the fps that the game is running at.\n    \t    if self.print_frames:\n                self.fpsTimer += elapsed_milliseconds\n                if self.fpsTimer > self.print_fps_frequency:\n                    print \"FPS: \", self.__clock.get_fps()\n                    self.fpsTimer = 0.0\n\n            #Update all of our objects\n    \t    if not 0 in self.event_flags:\n        \t   world.update(elapsed_milliseconds)\n\n            #Draw all of our objects\n    \t    if not 1 in self.event_flags:\n        \t   world.draw(elapsed_milliseconds)\n\n            #Make our world visible\n            pygame.display.flip()", "response": "Main loop of the game loop."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef request_object(self):\n        obj_to_return = None\n        if self.queue.count > 0:\n            obj_to_return = self.__dequeue()\n        else:\n            #The queue is empty, generate a new item.\n            self.__init_object()\n            object_to_return = self.__dequeue()\n        self.active_objects += 1\n        return obj_to_return", "response": "Grab an object from the pool."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef apply_texture(self, image):\n        self.image = image.convert_alpha()\n        self.untransformed_image = self.image.copy()\n##        self.rect.x = 0\n##        self.rect.y = 0\n##        self.rect.width = self.image.get_width()\n##        self.rect.height = self.image.get_height()\n        self.source.x = 0\n        self.source.y = 0\n        self.source.width = self.image.get_width()\n        self.source.height = self.image.get_height()\n        center = Vector2(self.source.width / 2.0,\n                         self.source.height / 2.0)\n        self.set_origin(center)", "response": "Place a preexisting texture as the sprite s texture."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhandle surface cleanup once a scale or rotation operation has been performed.", "response": "def __resize_surface_extents(self):\n        \"\"\"Handles surface cleanup once a scale or rotation operation has been performed.\"\"\"\n        #Set the new location of the origin, as the surface size may increase with rotation\n        self.__origin.X = self.image.get_width() * self.__untransformed_nor_origin.X\n        self.__origin.Y = self.image.get_height() * self.__untransformed_nor_origin.Y\n\n##        #Update the size of the rectangle\n##        self.rect = self.image.get_rect()\n##\n##        #Reset the coordinates of the rectangle to the user defined value\n##        self.set_coords(self.w_coords)\n\n        #We must now resize the source rectangle to prevent clipping\n        self.source.width = self.image.get_width()\n        self.source.height = self.image.get_height()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexecutes the scaling operation", "response": "def __execute_scale(self, surface, size_to_scale_from):\n        \"\"\"Execute the scaling operation\"\"\"\n        x = size_to_scale_from[0] * self.__scale[0]\n        y = size_to_scale_from[1] * self.__scale[1]\n        scaled_value = (int(x), int(y))\n\n##        #Find out what scaling technique we should use.\n##        if self.image.get_bitsize >= 24:\n##            #We have sufficient bit depth to run smooth scale\n##            self.image = pygame.transform.smoothscale(self.image, scaled_value)\n##        else:\n            ##Surface doesn't support smooth scale, revert to regular scale\n        self.image = pygame.transform.scale(self.image, scaled_value)\n\n        self.__resize_surface_extents()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_colliding(self, other):\n        if isinstance(other, BoundingCircle):\n            #Calculate the distance between two circles.\n            distance = Vector2.distance(self.coords, other.coords)\n\n            #Check to see if the sum of thier radi are greater than or equal to the distance.\n            radi_sum = self.radius + other.radius\n\n            if distance <= radi_sum:\n                #There has been a collision\n##                print \"Distance: \", distance, \"\\nRadi Sum: \", radi_sum\n##                print \"Self Coords: \", self.coords, \"\\nOther Coords: \", other.coords\n                return True\n\n            #No collision.\n            return False", "response": "Check to see if two circles are colliding."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks for and return the full list of objects colliding with collision_object", "response": "def query_all_collisions(collision_object):\n        \"\"\"\n        Check for and return the full list of objects colliding with collision_object\n        \"\"\"\n        global collidable_objects\n        colliding = []\n        for obj in collidable_objects:\n            #Make sure we don't check ourself against ourself.\n            if obj is not collision_object:\n                if collision_object.is_colliding(obj):\n                    #A collision has been detected. Add the object that we are colliding with.\n                    colliding.append(obj)\n\n        return colliding"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning the brute force query for the related objects.", "response": "def run_brute(self):\n        \"\"\"\n        A nightmare if looked at by a performance standpoint, but it gets the job done,\n        at least for now.\n\n        Checks everything against everything and handles all collision reactions.\n        \"\"\"\n        global collidable_objects\n        if self.collision_depth == self.SHALLOW_DEPTH:\n            for obj in collidable_objects:\n                collision = self.query_collision(obj)\n                if collision is not None:\n                    #Execute the reactions for both of the colliding objects.\n                    obj.collision_response(collision)\n                    collision.collision_response(obj)\n        elif self.collision_depth == self.DEEP_DEPTH:\n            for obj in collidable_objects:\n                collisions = self.query_all_collisions(obj)\n                for collision in collisions:\n                    #Execute the reactions for both of the colliding objects.\n                    obj.collision_response(collision)\n                    collision.collision_response(obj)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the keyboard focus for the specified menu items.", "response": "def set_keyboard_focus(self, move_up, move_down, select):\n        \"\"\"\n        Set the keyboard as the object that controls the menu.\n        move_up is from the pygame.KEYS enum that defines what button causes the menu selection to move up.\n        move_down is from the pygame.KEYS enum that defines what button causes the menu selection to move down.\n        select is from the pygame.KEYS enum that defines what button causes the button to be selected.\n        \"\"\"\n        self.input_focus = StateTypes.KEYBOARD\n        self.move_up_button = move_up\n        self.move_down_button = move_down\n        self.select_button = select"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __update_mouse(self, milliseconds):\n        for button in self.gui_buttons:\n            was_hovering = button.is_mouse_hovering\n            button.update(milliseconds)\n\n            #Provides capibilities for the mouse to select a button if the mouse is the focus of input.\n            if was_hovering == False and button.is_mouse_hovering:\n                #The user has just moved the mouse over the button. Set it as active.\n                old_index = self.current_index\n                self.current_index = self.gui_buttons.index(button)\n                self.__handle_selections(old_index, self.current_index)\n            elif Ragnarok.get_world().Mouse.is_clicked(self.mouse_select_button) and button.is_mouse_hovering:\n                #The main mouse button has just depressed, click the current button.\n                button.clicked_action()", "response": "Update the mouse with the given milliseconds."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwarp the tile map object from one warp to another.", "response": "def warp_object(self, tileMapObj):\n        \"\"\"Warp the tile map object from one warp to another.\"\"\"\n        print \"Collision\"\n        if tileMapObj.can_warp:\n            #Check to see if we need to load a different tile map\n            if self.map_association != self.exitWarp.map_association:\n                #Load the new tile map.\n                TileMapManager.load(exitWarp.map_association)\n\n            tileMapObj.parent.coords = self.exitWarp.coords"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses the collision map and sets the tile states as necessary.", "response": "def parse_collisions(self):\n        \"\"\"Parses the collision map and sets the tile states as necessary.\"\"\"\n        fs = open(self.collisionmap_path, \"r\")\n        self.collisionmap = fs.readlines()\n        fs.close()\n\n        x_index = 0\n        y_index = 0\n        for line in self.collisionmap:\n            if line[0] is \"#\":\n                continue\n            for char in line:\n                if char is \"\":\n                    continue\n                #An empty character is the same as collision type 0\n                elif char is \" \":\n                    char = \"0\"\n                elif char is \"s\":\n                    #Placing the start location\n                    self.start_location = self.tiles_to_pixels(Vector2(x_index, y_index))\n                    char = \"0\"\n                elif not (char in self.tile_bindings):\n                    continue\n\n                self.tiles[y_index][x_index].binding_type = self.tile_bindings[char]\n                x_index += 1\n\n            x_index = 0\n            y_index += 1"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngrab all the tiles that are colliding with the given coordinates.", "response": "def grab_collisions(self, coords):\n        \"\"\"\n        Return all the tiles the position is colliding with.\n        Tiles returned in this order:\n            Top Left\n            Top Right\n            Bottom Left\n            Bottom Right\n        \"\"\"\n        collisions = []\n        top_left = self.pixels_to_tiles(coords)\n        collisions.append(self.tiles[top_left.Y][top_left.X])\n\n        #Check to see if we are perfectly aligned with a tile\n        tile_width = int(self.spritesheet[0].width)\n        tile_height = int(self.spritesheet[0].width)\n        x_aligned = int((coords.X)) & (tile_width - 1)\n        y_aligned = int((coords.Y)) & (tile_height - 1)\n\n        if x_aligned > 0:\n            #Append the top right tile touching the rectangle\n            if self.is_valid_tile(top_left.X + 1, top_left.Y):\n                collisions.append(self.tiles[top_left.Y][top_left.X + 1])\n\n        if y_aligned > 0:\n            #Append the bottom left tile touching the rectangle\n            if self.is_valid_tile(top_left.X, top_left.Y + 1):\n                collisions.append(self.tiles[top_left.Y + 1][top_left.X])\n\n            if x_aligned > 0:\n                if self.is_valid_tile(top_left.X + 1, top_left.Y + 1):\n                    collisions.append(self.tiles[top_left.Y + 1][top_left.X + 1])\n\n        return collisions"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef draw(self, milliseconds, surface):\n        self.drawn_rects = []\n        cam = Ragnarok.get_world().Camera\n        cX, cY, cXMax, cYMax = cam.get_cam_bounds()\n\n        #Draw out only the tiles visible to the camera.\n        start_pos = self.pixels_to_tiles( (cX, cY) )\n        start_pos -= Vector2(1, 1)\n        end_pos = self.pixels_to_tiles( (cXMax, cYMax) )\n        end_pos += Vector2(1, 1)\n\n        start_pos.X, start_pos.Y = self.clamp_within_range(start_pos.X, start_pos.Y)\n        end_pos.X, end_pos.Y = self.clamp_within_range(end_pos.X, end_pos.Y)\n\n        cam_pos = cam.get_world_pos()\n        for x in range(start_pos.X, end_pos.X + 1):\n            for y in range(start_pos.Y, end_pos.Y + 1):\n                tile = self.tiles[y][x]\n                translate_posX = tile.coords.X - cam_pos.X\n                translate_posY = tile.coords.Y - cam_pos.Y\n                surface.blit(self.spritesheet.image, (translate_posX, translate_posY), tile.source, special_flags = 0)", "response": "Draw out the tilemap."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __sort_up(self):\n        if self.__do_need_sort_up:\n            self.__up_objects.sort(self.__up_cmp)\n            self.__do_need_sort_up = False", "response": "Sort the updatable objects according to ascending order"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __sort_draw(self):\n        if self.__do_need_sort_draw:\n            self.__draw_objects.sort(self.__draw_cmp)\n            self.__do_need_sort_draw = False", "response": "Sort the drawable objects according to ascending order"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef draw(self, milliseconds):\n        cam = Ragnarok.get_world().Camera\n        camPos = cam.get_world_pos()\n        self.__sort_draw()\n        self.clear_backbuffer()\n        for obj in self.__draw_objects:\n            #Check to see if the object is visible to the camera before doing anything to it.\n            if obj.is_static or obj.is_visible_to_camera(cam):\n                #Offset all of our objects by the camera offset.\n                old_pos = obj.coords\n                xVal = obj.coords.X - camPos.X\n                yVal = obj.coords.Y - camPos.Y\n                obj.coords = Vector2(xVal, yVal)\n                obj.draw(milliseconds, self.backbuffer)\n                obj.coords = old_pos", "response": "Draws all of the objects in our world."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mark_time(times, msg=None):\n    tt = time.clock()\n    times.append(tt)\n    if (msg is not None) and (len(times) > 1):\n        print msg, times[-1] - times[-2]", "response": "Mark the time of execution between subsequent calls."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef import_file(filename, package_name=None):\n    path = os.path.dirname(filename)\n\n    if not path in sys.path:\n        sys.path.append( path )\n        remove_path = True\n\n    else:\n        remove_path = False\n\n    name = os.path.splitext(os.path.basename(filename))[0]\n\n    if name in sys.modules:\n        force_reload = True\n    else:\n        force_reload = False\n\n\n    if package_name is not None:\n        mod = __import__('.'.join((package_name, name)), fromlist=[name])\n\n    else:\n        mod = __import__(name)\n\n    if force_reload:\n        reload(mod)\n\n    if remove_path:\n        sys.path.pop(-1)\n\n    return mod", "response": "Imports a file as a module."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef try_imports(imports, fail_msg=None):\n    msgs = []\n    for imp in imports:\n        try:\n            exec imp\n            break\n\n        except Exception, inst:\n            msgs.append(str(inst))\n\n    else:\n        if fail_msg is not None:\n            msgs.append(fail_msg)\n            raise ValueError('\\n'.join(msgs))\n\n    return locals()", "response": "Try import statements until one succeeds."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprint the line number and waits for a keypress.", "response": "def pause( msg = None ):\n    \"\"\"\n    Prints the line number and waits for a keypress.\n\n    If you press:\n    \"q\" ............. it will call sys.exit()\n    any other key ... it will continue execution of the program\n\n    This is useful for debugging.\n    \"\"\"\n    f = sys._getframe(1)\n    ff = f.f_code\n    if (msg):\n        print '%s, %d: %s(), %d: %s' % (ff.co_filename, ff.co_firstlineno,\n                                        ff.co_name, f.f_lineno, msg)\n    else:\n        print '%s, %d: %s(), %d' % (ff.co_filename, ff.co_firstlineno,\n                                    ff.co_name, f.f_lineno)\n    spause()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(self, ii, default=None, msg_if_none=None):\n        try:\n            out = self[ii]\n\n        except (IndexError, ValueError):\n            if default is not None:\n                out = default\n\n            else:\n                if msg_if_none is not None:\n                    raise ValueError(msg_if_none)\n\n                else:\n                    raise\n\n        return out", "response": "Wrapper around Container. __getitem__ to return the item with the specified index or name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, key, default=None, msg_if_none=None):\n        out = getattr(self, key, default)\n\n        if (out is None) and (msg_if_none is not None):\n            raise ValueError(msg_if_none)\n\n        return out", "response": "A dict - like get method for Struct attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmakes a deep copy of self.", "response": "def copy(self, deep=False, name=None):\n        \"\"\"Make a (deep) copy of self.\n\n        Parameters:\n\n        deep : bool\n            Make a deep copy.\n        name : str\n            Name of the copy, with default self.name + '_copy'.\n        \"\"\"\n        if deep:\n            other = deepcopy(self)\n        else:\n            other = copy(self)\n\n        if hasattr(self, 'name'):\n            other.name = get_default(name, self.name + '_copy')\n\n        return other"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fetch_social_friend_ids(self, social_auth_user):\n\n        # Type check\n        self.assert_user_is_social_auth_user(social_auth_user)\n\n        # Get friend finder backend\n        friends_provider = SocialFriendsFinderBackendFactory.get_backend(social_auth_user.provider)\n\n        # Get friend ids\n        friend_ids = friends_provider.fetch_friend_ids(social_auth_user)\n\n        return friend_ids", "response": "Fetches the user s social friends from its provider and returns a collection of ids"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef existing_social_friends(self, user_social_auth=None, friend_ids=None):\n        # Type check\n        self.assert_user_is_social_auth_user(user_social_auth)\n\n        if not friend_ids:\n            friend_ids = self.fetch_social_friend_ids(user_social_auth)\n\n        # Convert comma sepearated string to the list\n        if isinstance(friend_ids, basestring):\n            friend_ids = eval(friend_ids)\n\n        # Match them with the ones on the website\n        if USING_ALLAUTH:\n            return User.objects.filter(socialaccount__uid__in=friend_ids).all()            \n        else:\n            return User.objects.filter(social_auth__uid__in=friend_ids).all()", "response": "Returns a User collection of existing social friends."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting or create a SocialFriendList with the given social auth.", "response": "def get_or_create_with_social_auth(self, social_auth):\n        \"\"\"\n        creates and saves model instance with collection of UserSocialAuth\n\n        Raise:\n            NotImplemetedError\n        \"\"\"\n        # Type check\n        self.assert_user_is_social_auth_user(social_auth)\n\n        # Fetch the record\n        try:\n            social_friend_list = self.filter(user_social_auth=social_auth).get()\n        except:\n            # if no record found, create a new one\n            friend_ids = self.fetch_social_friend_ids(social_auth)\n\n            social_friend_list = SocialFriendList()\n            social_friend_list.friend_ids = friend_ids\n            social_friend_list.user_social_auth = social_auth\n            social_friend_list.save()\n\n        return social_friend_list"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_or_create_with_social_auths(self, social_auths):\n        social_friend_coll = []\n        for sa in social_auths:\n            try:\n                social_friend = self.get_or_create_with_social_auth(sa)\n            except NotImplementedError:\n                continue\n            social_friend_coll.append(social_friend)\n\n        return social_friend_coll", "response": "Creates a model instance with collection of UserSocialAuth objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns object with episode number attached to episode.", "response": "def get_object(self, queryset=None):\n        \"\"\"Return object with episode number attached to episode.\"\"\"\n        if settings.PODCAST_SINGULAR:\n            show = get_object_or_404(Show, id=settings.PODCAST_ID)\n        else:\n            show = get_object_or_404(Show, slug=self.kwargs['show_slug'])\n        obj = get_object_or_404(Episode, show=show, slug=self.kwargs['slug'])\n        index = Episode.objects.is_public_or_secret().filter(show=show, pub_date__lt=obj.pub_date).count()\n        obj.index = index + 1\n        obj.index_next = obj.index + 1\n        obj.index_previous = obj.index - 1\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef plot(self, df_data, center=False, save=False,\n             save_name=None, save_path='saved', dated=True, notebook=True):\n        \"df_data format is a dataframe with columns x, y, z (required), and style, filter (optional)\"\n        data = df_data.to_json(orient='records')\n        options = self.to_dict()\n        return plot(data, options, center=center, save=save,\n                    save_name=save_name, save_path=save_path, dated=dated, notebook=notebook)", "response": "df_data format is a dataframe with columns x y z and style filter ( optional )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsmoothing a mesh by a given number of iterations.", "response": "def smooth_mesh(mesh, n_iter=4, lam=0.6307, mu=-0.6347,\n                weights=None, bconstr=True,\n                volume_corr=False):\n    \"\"\"\n    FE mesh smoothing.\n\n    Based on:\n\n    [1] Steven K. Boyd, Ralph Muller, Smooth surface meshing for automated\n    finite element model generation from 3D image data, Journal of\n    Biomechanics, Volume 39, Issue 7, 2006, Pages 1287-1295,\n    ISSN 0021-9290, 10.1016/j.jbiomech.2005.03.006.\n    (http://www.sciencedirect.com/science/article/pii/S0021929005001442)\n\n    Parameters\n    ----------\n    mesh : mesh\n        FE mesh.\n    n_iter : integer, optional\n        Number of iteration steps.\n    lam : float, optional\n        Smoothing factor, see [1].\n    mu : float, optional\n        Unshrinking factor, see [1].\n    weights : array, optional\n        Edge weights, see [1].\n    bconstr: logical, optional\n        Boundary constraints, if True only surface smoothing performed.\n    volume_corr: logical, optional\n        Correct volume after smoothing process.\n\n    Returns\n    -------\n    coors : array\n        Coordinates of mesh nodes.\n    \"\"\"\n\n    def laplacian(coors, weights):\n\n        n_nod = coors.shape[0]\n        displ = (weights - sps.identity(n_nod)) * coors\n\n        return displ\n\n    def taubin(coors0, weights, lam, mu, n_iter):\n\n        coors = coors0.copy()\n\n        for ii in range(n_iter):\n            displ = laplacian(coors, weights)\n            if nm.mod(ii, 2) == 0:\n                coors += lam * displ\n            else:\n                coors += mu * displ\n\n        return coors\n\n    def dets_fast(a):\n        m = a.shape[0]\n        n = a.shape[1]\n        lapack_routine = lapack_lite.dgetrf\n        pivots = nm.zeros((m, n), intc)\n        flags = nm.arange(1, n + 1).reshape(1, -1)\n        for i in xrange(m):\n            tmp = a[i]\n            lapack_routine(n, n, tmp, n, pivots[i], 0)\n        sign = 1. - 2. * (nm.add.reduce(pivots != flags, axis=1) % 2)\n        idx = nm.arange(n)\n        d = a[:, idx, idx]\n        absd = nm.absolute(d)\n        sign *= nm.multiply.reduce(d / absd, axis=1)\n        nm.log(absd, absd)\n        logdet = nm.add.reduce(absd, axis=-1)\n\n        return sign * nm.exp(logdet)\n\n    def get_volume(el, nd):\n\n        dim = nd.shape[1]\n        nnd = el.shape[1]\n\n        etype = '%d_%d' % (dim, nnd)\n        if etype == '2_4' or etype == '3_8':\n            el = elems_q2t(el)\n\n        nel = el.shape[0]\n\n        mul = 1.0 / factorial(dim)\n        if dim == 3:\n            mul *= -1.0\n\n        mtx = nm.ones((nel, dim + 1, dim + 1), dtype=nm.double)\n        mtx[:,:,:-1] = nd[el,:]\n        vols = mul * dets_fast(mtx.copy()) # copy() ???\n        vol = vols.sum()\n        bc = nm.dot(vols, mtx.sum(1)[:,:-1] / nnd)\n\n        bc /= vol\n\n        return vol, bc\n\n\n    n_nod = mesh.n_nod\n\n    if weights is None:\n        # initiate all vertices as inner - hierarchy = 2\n        node_group = nm.ones((n_nod,), dtype=nm.int8) * 2\n        sndi, edges = get_snodes_uedges(mesh.conns[0], mesh.descs[0])\n        # boundary vertices - set hierarchy = 4\n        if bconstr:\n            node_group[sndi] = 4\n\n        # generate costs matrix\n        end1 = edges[:,0]\n        end2 = edges[:,1]\n        idxs = nm.where(node_group[end2] >= node_group[end1])\n        rows1 = end1[idxs]\n        cols1 = end2[idxs]\n        idxs = nm.where(node_group[end1] >= node_group[end2])\n        rows2 = end2[idxs]\n        cols2 = end1[idxs]\n        crows = nm.concatenate((rows1, rows2))\n        ccols = nm.concatenate((cols1, cols2))\n        costs = sps.coo_matrix((nm.ones_like(crows), (crows, ccols)),\n                               shape=(n_nod, n_nod),\n                               dtype=nm.double)\n\n        # generate weights matrix\n        idxs = range(n_nod)\n        aux = sps.coo_matrix((1.0 / nm.asarray(costs.sum(1)).squeeze(),\n                              (idxs, idxs)),\n                             shape=(n_nod, n_nod),\n                             dtype=nm.double)\n\n        #aux.setdiag(1.0 / costs.sum(1))\n        weights = (aux.tocsc() * costs.tocsc()).tocsr()\n\n    coors = taubin(mesh.coors, weights, lam, mu, n_iter)\n\n    if volume_corr:\n        volume0, bc = get_volume(mesh.conns[0], mesh.coors)\n        volume, _ = get_volume(mesh.conns[0], coors)\n\n        scale = volume0 / volume\n        coors = (coors - bc) * scale + bc\n\n    return coors"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a single FE mesh from a list of voxels.", "response": "def gen_mesh_from_voxels(voxels, dims, etype='q', mtype='v'):\n    \"\"\"\n    Generate FE mesh from voxels (volumetric data).\n\n    Parameters\n    ----------\n    voxels : array\n        Voxel matrix, 1=material.\n    dims : array\n        Size of one voxel.\n    etype : integer, optional\n        'q' - quadrilateral or hexahedral elements\n        't' - triangular or tetrahedral elements\n    mtype : integer, optional\n        'v' - volumetric mesh\n        's' - surface mesh\n\n    Returns\n    -------\n    mesh : Mesh instance\n        Finite element mesh.\n    \"\"\"\n\n    dims = dims.squeeze()\n    dim = len(dims)\n    nddims = nm.array(voxels.shape) + 2\n\n    nodemtx = nm.zeros(nddims, dtype=nm.int8)\n    vxidxs = nm.where(voxels)\n    set_nodemtx(nodemtx, vxidxs, etype)\n\n    ndidx = nm.where(nodemtx)\n    del(nodemtx)\n\n    coors = nm.array(ndidx).transpose() * dims\n    nnod = coors.shape[0]\n\n    nodeid = -nm.ones(nddims, dtype=nm.int32)\n    nodeid[ndidx] = nm.arange(nnod)\n\n    if mtype == 's':\n        felems = []\n        nn = nm.zeros(nddims, dtype=nm.int8)\n\n    # generate elements\n    if dim == 2:\n        ix, iy = vxidxs\n\n        if mtype == 'v':\n            elems = nm.array([nodeid[ix,iy],\n                              nodeid[ix + 1,iy],\n                              nodeid[ix + 1,iy + 1],\n                              nodeid[ix,iy + 1]]).transpose()\n            edim = 2\n\n        else:\n            fc = nm.zeros(nddims + (2,), dtype=nm.int32)\n            # x\n            fc[ix,iy,:] = nm.array([nodeid[ix,iy + 1],\n                                    nodeid[ix,iy]]).transpose()\n            fc[ix + 1,iy,:] = nm.array([nodeid[ix + 1,iy],\n                                        nodeid[ix + 1,iy + 1]]).transpose()\n            nn[ix,iy] = 1\n            nn[ix + 1,iy] += 1\n\n            idx = nm.where(nn == 1)\n            felems.append(fc[idx])\n            # y\n            fc.fill(0)\n            nn.fill(0)\n            fc[ix,iy,:] = nm.array([nodeid[ix,iy],\n                                    nodeid[ix + 1,iy]]).transpose()\n            fc[ix,iy + 1,:] = nm.array([nodeid[ix + 1,iy + 1],\n                                        nodeid[ix,iy + 1]]).transpose()\n            nn[ix,iy] = 1\n            nn[ix,iy + 1] += 1\n\n            idx = nm.where(nn == 1)\n            felems.append(fc[idx])\n\n            elems = nm.concatenate(felems)\n\n            edim = 1\n\n    elif dim == 3:\n        ix, iy, iz = vxidxs\n\n        if mtype == 'v':\n            elems = nm.array([nodeid[ix,iy,iz],\n                              nodeid[ix + 1,iy,iz],\n                              nodeid[ix + 1,iy + 1,iz],\n                              nodeid[ix,iy + 1,iz],\n                              nodeid[ix,iy,iz + 1],\n                              nodeid[ix + 1,iy,iz + 1],\n                              nodeid[ix + 1,iy + 1,iz + 1],\n                              nodeid[ix,iy + 1,iz + 1]]).transpose()\n            edim = 3\n\n        else:\n            fc = nm.zeros(tuple(nddims) + (4,), dtype=nm.int32)\n\n            # x\n            fc[ix,iy,iz,:] = nm.array([nodeid[ix,iy,iz],\n                                       nodeid[ix,iy,iz + 1],\n                                       nodeid[ix,iy + 1,iz + 1],\n                                       nodeid[ix,iy + 1,iz]]).transpose()\n            fc[ix + 1,iy,iz,:] = nm.array([nodeid[ix + 1,iy,iz],\n                                           nodeid[ix + 1,iy + 1,iz],\n                                           nodeid[ix + 1,iy + 1,iz + 1],\n                                           nodeid[ix + 1,iy,iz + 1]]).transpose()\n            nn[ix,iy,iz] = 1\n            nn[ix + 1,iy,iz] += 1\n\n            idx = nm.where(nn == 1)\n            felems.append(fc[idx])\n\n            # y\n            fc.fill(0)\n            nn.fill(0)\n            fc[ix,iy,iz,:] = nm.array([nodeid[ix,iy,iz],\n                                       nodeid[ix + 1,iy,iz],\n                                       nodeid[ix + 1,iy,iz + 1],\n                                       nodeid[ix,iy,iz + 1]]).transpose()\n            fc[ix,iy + 1,iz,:] = nm.array([nodeid[ix,iy + 1,iz],\n                                           nodeid[ix,iy + 1,iz + 1],\n                                           nodeid[ix + 1,iy + 1,iz + 1],\n                                           nodeid[ix + 1,iy + 1,iz]]).transpose()\n            nn[ix,iy,iz] = 1\n            nn[ix,iy + 1,iz] += 1\n\n            idx = nm.where(nn == 1)\n            felems.append(fc[idx])\n\n            # z\n            fc.fill(0)\n            nn.fill(0)\n            fc[ix,iy,iz,:] = nm.array([nodeid[ix,iy,iz],\n                                       nodeid[ix,iy + 1,iz],\n                                       nodeid[ix + 1,iy + 1,iz],\n                                       nodeid[ix + 1,iy,iz]]).transpose()\n            fc[ix,iy,iz + 1,:] = nm.array([nodeid[ix,iy,iz + 1],\n                                           nodeid[ix + 1,iy,iz + 1],\\\n                                           nodeid[ix + 1,iy + 1,iz + 1],\n                                           nodeid[ix,iy + 1,iz + 1]]).transpose()\n            nn[ix,iy,iz] = 1\n            nn[ix,iy,iz + 1] += 1\n\n            idx = nm.where(nn == 1)\n            felems.append(fc[idx])\n\n            elems = nm.concatenate(felems)\n\n            edim = 2\n\n    # reduce inner nodes\n    if mtype == 's':\n        aux = nm.zeros((nnod,), dtype=nm.int32)\n\n        for ii in elems.T:\n            aux[ii] = 1\n\n        idx = nm.where(aux)\n\n        aux.fill(0)\n        nnod = idx[0].shape[0]\n\n        aux[idx] = range(nnod)\n        coors = coors[idx]\n\n        for ii in range(elems.shape[1]):\n            elems[:,ii] = aux[elems[:,ii]]\n\n    if etype == 't':\n        elems = elems_q2t(elems)\n\n    nel = elems.shape[0]\n    nelnd = elems.shape[1]\n\n    mesh = Mesh.from_data('voxel_data',\n                          coors, nm.ones((nnod,), dtype=nm.int32),\n                          {0: nm.ascontiguousarray(elems)},\n                          {0: nm.ones((nel,), dtype=nm.int32)},\n                          {0: '%d_%d' % (edim, nelnd)})\n\n    return mesh"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the given backend instance", "response": "def get_backend(self, backend_name):\n        \"\"\"\n        returns the given backend instance\n        \"\"\"\n        if backend_name == 'twitter':\n            from social_friends_finder.backends.twitter_backend import TwitterFriendsProvider\n            friends_provider = TwitterFriendsProvider()\n        elif backend_name == 'facebook':\n            from social_friends_finder.backends.facebook_backend import FacebookFriendsProvider\n            friends_provider = FacebookFriendsProvider()\n        elif backend_name == 'vkontakte-oauth2':\n            from social_friends_finder.backends.vkontakte_backend import VKontakteFriendsProvider\n            friends_provider = VKontakteFriendsProvider()\n        else:\n            raise NotImplementedError(\"provider: %s is not implemented\")\n\n        return friends_provider"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fetch_friends(self, user):\n\n        if USING_ALLAUTH:\n            raise NotImplementedError(\"VKontakte support is not implemented for django-allauth\")\n            #social_app = SocialApp.objects.get_current('vkontakte')\n            #oauth_token = SocialToken.objects.get(account=user, app=social_app).token\n        else:\n            social_auth_backend = VKOAuth2Backend()\n\n            # Get the access_token\n            tokens = social_auth_backend.tokens(user)\n            oauth_token = tokens['access_token']\n\n        api = vkontakte.API(token=oauth_token)\n        return api.get(\"friends.get\")", "response": "Fetch friends from VKontakte using the access_token"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef addQuickElement(self, name, contents=None, attrs=None, escape=True, cdata=False):\n        if attrs is None:\n            attrs = {}\n        self.startElement(name, attrs)\n        if contents is not None:\n            self.characters(contents, escape=escape, cdata=cdata)\n        self.endElement(name)", "response": "Convenience method for adding an element with no children."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets a the value in the TOML file located by the given key sequence.", "response": "def _setitem_with_key_seq(self, key_seq, value):\n        \"\"\"\n        Sets a the value in the TOML file located by the given key sequence.\n\n        Example:\n        self._setitem(('key1', 'key2', 'key3'), 'text_value')\n        is equivalent to doing\n        self['key1']['key2']['key3'] = 'text_value'\n        \"\"\"\n        table = self\n        key_so_far = tuple()\n        for key in key_seq[:-1]:\n            key_so_far += (key,)\n            self._make_sure_table_exists(key_so_far)\n            table = table[key]\n        table[key_seq[-1]] = value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset a the value in the TOML file located by the given key sequence.", "response": "def _array_setitem_with_key_seq(self, array_name, index, key_seq, value):\n        \"\"\"\n        Sets a the array value in the TOML file located by the given key sequence.\n\n        Example:\n        self._array_setitem(array_name, index, ('key1', 'key2', 'key3'), 'text_value')\n        is equivalent to doing\n        self.array(array_name)[index]['key1']['key2']['key3'] = 'text_value'\n        \"\"\"\n        table = self.array(array_name)[index]\n        key_so_far = tuple()\n        for key in key_seq[:-1]:\n            key_so_far += (key,)\n            new_table = self._array_make_sure_table_exists(array_name, index, key_so_far)\n            if new_table is not None:\n                table = new_table\n            else:\n                table = table[key]\n        table[key_seq[-1]] = value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _make_sure_table_exists(self, name_seq):\n        t = self\n        for key in name_seq[:-1]:\n            t = t[key]\n        name = name_seq[-1]\n        if name not in t:\n            self.append_elements([element_factory.create_table_header_element(name_seq),\n                                  element_factory.create_table({})])", "response": "Make sure the table with the full name comprising of name_seq exists."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmakes sure the table with the full name comprising of name_seq exists.", "response": "def _array_make_sure_table_exists(self, array_name, index, name_seq):\n        \"\"\"\n        Makes sure the table with the full name comprising of name_seq exists.\n        \"\"\"\n        t = self[array_name][index]\n        for key in name_seq[:-1]:\n            t = t[key]\n        name = name_seq[-1]\n        if name not in t:\n            new_table = element_factory.create_table({})\n            self.append_elements([element_factory.create_table_header_element((array_name,) + name_seq), new_table])\n            return new_table"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndetect the TopLevel instances for the current state of this table.", "response": "def _detect_toplevels(self):\n        \"\"\"\n        Returns a sequence of TopLevel instances for the current state of this table.\n        \"\"\"\n        return tuple(e for e in toplevels.identify(self.elements) if isinstance(e, toplevels.Table))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _update_table_fallbacks(self, table_toplevels):\n\n        if len(self.elements) <= 1:\n            return\n\n        def parent_of(toplevel):\n            # Returns an TopLevel parent of the given entry, or None.\n            for parent_toplevel in table_toplevels:\n                if toplevel.name.sub_names[:-1] == parent_toplevel.name.sub_names:\n                    return parent_toplevel\n\n        for entry in table_toplevels:\n            if entry.name.is_qualified:\n                parent = parent_of(entry)\n                if parent:\n                    child_name = entry.name.without_prefix(parent.name)\n                    parent.table_element.set_fallback({child_name.sub_names[0]: entry.table_element})", "response": "Updates the fallbacks on all the table elements to make relative table access possible."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the array of tables with the given name.", "response": "def array(self, name):\n        \"\"\"\n        Returns the array of tables with the given name.\n        \"\"\"\n        if name in self._navigable:\n            if isinstance(self._navigable[name], (list, tuple)):\n                return self[name]\n            else:\n                raise NoArrayFoundError\n        else:\n            return ArrayOfTables(toml_file=self, name=name)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef append_elements(self, elements):\n        self._elements = self._elements + list(elements)\n        self._on_element_change()", "response": "Append elements to the internal elements."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef primitive(self):\n        raw_container = raw.to_raw(self._navigable)\n\n        # Collapsing the anonymous table onto the top-level container is present\n        if '' in raw_container:\n            raw_container.update(raw_container[''])\n            del raw_container['']\n\n        return raw_container", "response": "Returns a primitive object representation of this container."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a fresh table to the end of the list.", "response": "def append_fresh_table(self, fresh_table):\n        \"\"\"\n        Gets called by FreshTable instances when they get written to.\n        \"\"\"\n        if fresh_table.name:\n            elements = []\n            if fresh_table.is_array:\n                elements += [element_factory.create_array_of_tables_header_element(fresh_table.name)]\n            else:\n                elements += [element_factory.create_table_header_element(fresh_table.name)]\n\n            elements += [fresh_table, element_factory.create_newline_element()]\n            self.append_elements(elements)\n\n        else:\n            # It's an anonymous table\n            self.prepend_elements([fresh_table, element_factory.create_newline_element()])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef abort(self, exception=exc.ConnectError):\n        log.warn(\"Aborting connection to %s:%s\", self.host, self.port)\n\n        def abort_pending(f):\n            exc_info = sys.exc_info()\n            if any(exc_info):\n                f.set_exc_info(exc_info)\n            else:\n                f.set_exception(exception(self.host, self.port))\n\n        for pending in self.drain_all_pending():\n            abort_pending(pending)", "response": "Aborts a connection and puts all pending futures into an error state."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsafes rmdir which doesn t throw an exception", "response": "def rmdir(path):\n    \"\"\"Safe rmdir (non-recursive) which doesn't throw if the directory is not empty.\"\"\"\n    try:\n        os.rmdir(path)\n    except OSError as exc:\n        print(str(exc))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexecute the given shell command and returns its output.", "response": "def shell_exec(command):\n    \"\"\"Executes the given shell command and returns its output.\"\"\"\n    out = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT).communicate()[0]\n    return out.decode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets locale. Searches for locale in the following the order: - User has specified a concrete language in the query string. - Current session has a language set. - User has a language set in the profile. - Headers of the HTTP request. - Default language from ``BABEL_DEFAULT_LOCALE``. Will only accept languages defined in ``I18N_LANGUAGES``.", "response": "def get_locale():\n    \"\"\"Get locale.\n\n    Searches for locale in the following the order:\n\n    - User has specified a concrete language in the query string.\n    - Current session has a language set.\n    - User has a language set in the profile.\n    - Headers of the HTTP request.\n    - Default language from ``BABEL_DEFAULT_LOCALE``.\n\n    Will only accept languages defined in ``I18N_LANGUAGES``.\n    \"\"\"\n    locales = [x[0] for x in\n               current_app.extensions['invenio-i18n'].get_languages()]\n\n    # In the case of the user specifies a language for the resource.\n    if 'ln' in request.args:\n        language = request.args.get('ln')\n        if language in locales:\n            return language\n\n    # In the case of the user has set a language for the current session.\n    language_session_key = current_app.config['I18N_SESSION_KEY']\n    if language_session_key in session:\n        language = session[language_session_key]\n        if language in locales:\n            return language\n\n    # In the case of the registered user has a prefered language.\n    language_user_key = current_app.config['I18N_USER_LANG_ATTR']\n    if language_user_key is not None and \\\n            hasattr(current_app, 'login_manager') and \\\n            current_user.is_authenticated:\n        language = getattr(current_user, language_user_key, None)\n        if language is not None and language in locales:\n            return language\n\n    # Using the headers that the navigator has sent.\n    headers_best_match = request.accept_languages.best_match(locales)\n    if headers_best_match is not None:\n        return headers_best_match\n\n    # If there is no way to know the language, return BABEL_DEFAULT_LOCALE\n    return current_app.config['BABEL_DEFAULT_LOCALE']"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_data_value(searchpath, searchtree, dtype = None, empty_is_false = False):\n    if isinstance(searchpath, (str, unicode, int)):\n        searchpath = [searchpath]\n\n    if not isinstance(searchpath, (list, tuple)):\n        return False\n\n    for d in searchpath:\n        if isinstance(searchtree, dict):\n            if not d in searchtree.keys():\n                return False\n\n        elif isinstance(searchtree, (list, tuple)):\n            if (not isinstance(d, int) or (d >= 0 and d >= len(searchtree)) or (d < 0 and -d > len(searchtree))):\n                return False\n\n        else:\n            return False\n\n        searchtree = searchtree[d]\n\n    if dtype == None and not (empty_is_false and searchtree == None):\n        return True\n\n    if empty_is_false and searchtree in (None, \"\", {}, []):\n        return False\n\n    if isinstance(dtype, tuple):\n        dtype = list(dtype)\n\n    elif not isinstance(dtype, list):\n        dtype = [dtype]\n\n    if float in dtype and not int in dtype:\n        dtype.append(int)\n\n    if str in dtype or unicode in dtype or 'string' in dtype:\n        for dtp in (str, unicode, 'string'):\n            while dtp in dtype:\n                dtype.remove(dtp)\n        dtype.extend([str, unicode])\n\n    if list in dtype or tuple in dtype or 'list' in dtype:\n        for dtp in (list, tuple, 'list'):\n            while dtp in dtype:\n                dtype.remove(dtp)\n        dtype.extend([list, tuple])\n\n    dtype = tuple(dtype)\n\n    return bool(isinstance(searchtree, dtype))", "response": "Checks if a datatree is a data value in a specific type."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the value of the data attribute in the datatree at the specified searchpath.", "response": "def data_value(searchpath, searchtree, dtype = None, default = None):\n    \"\"\"\n    Follow searchpath through the datatree in searchtree\n    and return if it exists a value of type dtype\n    searchpath is a list of keys/indices\n    If dtype is None check for any value\n    If it is not found return default or if dtype is set to\n    a string, list or dict, an empty one\n    \"\"\"\n    if is_data_value(searchpath, searchtree, dtype):\n        if isinstance(searchpath, (str, unicode, int)):\n            searchpath = [searchpath]\n\n        for d in searchpath:\n            searchtree = searchtree[d]\n\n    else:\n        searchtree = None\n\n    if searchtree == None:\n        if default != None:\n            return default\n\n        elif dtype in (str, unicode, 'string'):\n            return \"\"\n\n        elif dtype == dict:\n            return {}\n\n        elif dtype in (list, tuple, 'list'):\n            return []\n\n    return searchtree"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef link_values(self, linkdata):\n        def get_variable(vdef, key):\n            varid = vdef[1][0]\n            if  varid >= len(linkdata):\n                self.warn('Requested datavalue \"%s\" does not exist in: %s'% (varid, linkdata), dtLinkWarning, 2)\n                return\n\n            # remove any leading or trailing spaces on a string/unicode value\n            value = linkdata[varid] if (not  isinstance(linkdata[varid], (unicode, str))) else unicode(linkdata[varid]).strip()\n            return process_extras(value, vdef, key)\n\n        def process_link_function(vdef, key):\n            funcid = vdef[1][0]\n            default = vdef[self.dtc.linkPos[self.dtc.linkhasDefault]]\n            # Process the datavalues given for the function\n            data = []\n            for fd in vdef[1][1]:\n                lact = fd[0] & self.dtc.linkGroup\n                if lact == self.dtc.linkVarID:\n                    data.append(get_variable(fd, key))\n\n                elif lact == self.dtc.linkFuncID:\n                    data.append(process_link_function(fd, key))\n\n                elif lact == self.dtc.linkValue:\n                    data.append(fd[1])\n\n            # And call the linkfunction\n            value = self.link_functions(funcid, data, default)\n            if value in self.empty_values:\n                return None\n\n            return process_extras(value, vdef, key)\n\n        def process_extras(value, vdef, key):\n            if not value in self.empty_values:\n                if vdef[0] & self.dtc.linkhasRegex and isinstance(value, (str, unicode)):\n                    search_regex = vdef[self.dtc.linkPos[self.dtc.linkhasRegex]]\n                    try:\n                        dd = re.search(search_regex, value, re.DOTALL)\n                        if dd.group(1) not in ('', None):\n                            value = dd.group(1)\n\n                        else:\n                            self.warn('Regex \"%s\" in: %s returned no value on \"%s\"'% \\\n                                (search_regex, vdef, value), dtLinkWarning, 4)\n                            value = None\n\n                    except:\n                        self.warn('Invalid value \"%s\" or invalid regex \"%s\" in: %s'% \\\n                            (value, search_regex, vdef), dtLinkWarning, 4)\n                        value = None\n\n                if vdef[0] & self.dtc.linkhasType:\n                    dtype = vdef[self.dtc.linkPos[self.dtc.linkhasType]]\n                    try:\n                        if dtype == self.dtc.typeString:\n                            value = unicode(value)\n\n                        elif dtype == self.dtc.typeLower:\n                            value = unicode(value).lower()\n\n                        elif dtype == self.dtc.typeUpper:\n                            value = unicode(value).upper()\n\n                        elif dtype == self.dtc.typeCapitalize:\n                            value = unicode(value).capitalize()\n\n                        elif dtype == self.dtc.typeInteger:\n                            value = int(value)\n\n                        elif dtype == self.dtc.typeFloat:\n                            value = float(value)\n\n                        elif dtype == self.dtc.typeBoolean:\n                            value = bool(value)\n\n                    except:\n                        vtype = {\n                                self.dtc.typeString: \"String\",\n                                self.dtc.typeLower: \"LowerCase\",\n                                self.dtc.typeUpper: \"UpperCase\",\n                                self.dtc.typeCapitalize: \"Capitalize\",\n                                self.dtc.typeInteger: \"Integer\",\n                                self.dtc.typeFloat: \"Float\",\n                                self.dtc.typeBoolean: \"Boolean\"}\n                        self.warn('Error on applying type \"%s\" on \"%s\"'% (vtype[dtype], value), dtLinkWarning, 4)\n                        value = None\n\n                if vdef[0] & self.dtc.linkhasCalc:\n                    for cv in vdef[self.dtc.linkPos[self.dtc.linkhasCalc]]:\n                        if cv[0] == self.dtc.calcMultiply:\n                            try:\n                                if not isinstance(value, (int, float)):\n                                    value = float(value)\n                                value = value * cv[1]\n\n                            except:\n                                self.warn('Error on applying multiplier \"%s\" on \"%s\"'% \\\n                                    (cv[1], value), dtLinkWarning, 4)\n\n                        if cv[0] == self.dtc.calcDivide:\n                            try:\n                                if not isinstance(value, (int, float)):\n                                    value = float(value)\n                                value = value / cv[1]\n\n                            except:\n                                self.warn('Error on applying divider \"%s\" on \"%s\"'% \\\n                                    (cv[1], value), dtLinkWarning, 4)\n\n                if vdef[0] & self.dtc.linkhasMax:\n                    if isinstance(value, (str, unicode, list, dict)) and len(value) > vdef[self.dtc.linkPos[self.dtc.linkhasMax]]:\n                        self.warn('Requested datavalue \"%s\" is longer then %s'% \\\n                            (key, vdef[self.dtc.linkPos[self.dtc.linkhasMax]]), dtLinkWarning, 4)\n                        value = None\n\n                    if isinstance(value, (int, float)) and value > vdef[self.dtc.linkPos[self.dtc.linkhasMax]]:\n                        self.warn('Requested datavalue \"%s\" is bigger then %s'% \\\n                            (key, vdef[self.dtc.linkPos[self.dtc.linkhasMax]]), dtLinkWarning, 4)\n                        value = None\n\n                if vdef[0] & self.dtc.linkhasMin:\n                    if isinstance(value, (str, unicode, list, dict)) and len(value) < vdef[self.dtc.linkPos[self.dtc.linkhasMin]]:\n                        self.warn('Requested datavalue \"%s\" is shorter then %s'% \\\n                            (key, vdef[self.dtc.linkPos[self.dtc.linkhasMin]]), dtLinkWarning, 4)\n                        value = None\n\n                    if isinstance(value, (int, float)) and value < vdef[self.dtc.linkPos[self.dtc.linkhasMin]]:\n                        self.warn('Requested datavalue \"%s\" is smaller then %s'% \\\n                            (key, vdef[self.dtc.linkPos[self.dtc.linkhasMin]]), dtLinkWarning, 4)\n                        value = None\n\n            if value in self.empty_values:\n                return vdef[self.dtc.linkPos[self.dtc.linkhasDefault]]\n\n            return value\n\n        values = {}\n        if isinstance(linkdata, list):\n            for k, v in self.data_def[\"values\"].items():\n                lact = v[0] & self.dtc.linkGroup\n                cval = None\n                if lact == self.dtc.linkVarID:\n                    cval = get_variable(v, k)\n\n                elif lact == self.dtc.linkFuncID:\n                    cval = process_link_function(v, k)\n\n                elif lact == self.dtc.linkValue:\n                    cval = v[1]\n\n                if not cval in self.empty_values:\n                    values[k] = cval\n\n                elif not v[self.dtc.linkPos[self.dtc.linkhasDefault]] in self.empty_values:\n                    values[k] = v[self.dtc.linkPos[self.dtc.linkhasDefault]]\n        else:\n            self.warn('No valid data \"%s\" to link with' % (linkdata, ), dtLinkWarning, 2)\n\n        return values", "response": "This function is used to process the data - list for every keyword in the values definition."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_file(cls, db_file, language=DEFAULT_LANG):\n        data = DBVuln.load_from_json(db_file, language=language)\n        return cls(**data)", "response": "This is a constructor for the DBVuln class which loads the data from a json file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_file_for_id(_id, language=DEFAULT_LANG):\n        file_start = '%s-' % _id\n\n        json_path = DBVuln.get_json_path(language=language)\n\n        for _file in os.listdir(json_path):\n            if _file.startswith(file_start):\n                return os.path.join(json_path, _file)\n\n        raise NotFoundException('No data for ID %s' % _id)", "response": "Given _id search the DB for the file which contains the data\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list with all the database IDs as integers", "response": "def get_all_db_ids(language=DEFAULT_LANG):\n        \"\"\"\n        :return: A list with all the database IDs as integers\n        \"\"\"\n        _ids = []\n        json_path = DBVuln.get_json_path(language=language)\n\n        for _file in os.listdir(json_path):\n\n            if not _file.endswith('.json'):\n                continue\n\n            _id = _file.split('-')[0]\n            _ids.append(_id)\n\n        return _ids"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef handle_ref(attr, language=DEFAULT_LANG):\n        ref = attr.get('$ref', None)\n        if ref is None:\n            raise NotFoundException('No $ref in attribute')\n\n        _, files, _type, _id = ref.split('/')\n\n        if 'files' != files:\n            raise NotFoundException('Mandatory \"files\" path was not found in $ref')\n\n        if _type not in ('fix', 'description'):\n            raise NotFoundException('Mandatory fix or description not found in $ref')\n\n        if not _id.isdigit():\n            raise NotFoundException('Mandatory integer ID not found in $ref')\n\n        file_path = os.path.join(DBVuln.get_json_path(language=language),\n                                 _type,\n                                 '%s.md' % _id)\n\n        if not os.path.exists(file_path):\n            raise NotFoundException('$ref points to a non existing file')\n\n        return file(file_path).read()", "response": "Handles a reference to a specific resource in the DBVuln."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_from_json(db_file, language=DEFAULT_LANG):\n        # There are a couple of things I don't do here, and are on purpose:\n        #   - I want to fail if the file doesn't exist\n        #   - I want to fail if the file doesn't contain valid JSON\n        raw = json.loads(file(db_file).read())\n\n        # Here I don't do any error handling either, I expect the JSON files to\n        # be valid\n        data = {\n            '_id': raw['id'],\n            'title': raw['title'],\n            'description': DBVuln.handle_ref(raw['description'], language=language),\n            'severity': raw['severity'],\n            'wasc': raw.get('wasc', []),\n            'tags': raw.get('tags', []),\n            'cwe': raw.get('cwe', []),\n            'owasp_top_10': raw.get('owasp_top_10', {}),\n            'fix_effort': raw['fix']['effort'],\n            'fix_guidance': DBVuln.handle_ref(raw['fix']['guidance'], language=language),\n            'references': DBVuln.handle_references(raw.get('references', [])),\n            'db_file': db_file,\n        }\n\n        return data", "response": "Parses the JSON data and returns the user s ID and the data in the format that is expected by the DBVuln."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a URL for the owasp top 10.", "response": "def get_owasp_top_10_url(owasp_version, risk_id):\n        \"\"\"\n        Similar to get_wasc_url() but for OWASP Top 10\n        \"\"\"\n        owasp_version = int(owasp_version)\n\n        # Just return one of them, 2013 release has priority over 2010\n        if owasp_version == 2013:\n            return OWASP_TOP10_2013_URL_FMT % risk_id\n\n        if owasp_version == 2010:\n            return OWASP_TOP10_2010_URL_FMT % risk_id"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef handle_references(json_references):\n        reference_list = []\n        for reference_dict in json_references:\n            reference_list.append(Reference(reference_dict['url'],\n                                            reference_dict['title']))\n\n        return reference_list", "response": "Create a list of Reference objects that represent this part of the JSON containing the JSON containing the information about the resource."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef perform_preflight_check(self):\n        failures = []\n        if not os.access(self.mount_path_base, os.W_OK):\n            msg = (\"Mount path `{path}` doesn't exist or is not writable\"\n                   \" by the current user.\")\n            failures.append(msg.format(\n                path = self.mount_path_base\n            ))\n        if which('sshfs') is None:\n            msg = (\"SSHFS (http://fuse.sourceforge.net/sshfs.html)\"\n                   \" does not seem to be installed.\")\n            failures.append(msg)\n\n        return len(failures) == 0, failures", "response": "Performs a preflight check on the current node s filesystem."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mount(self):\n        if self.mounted:\n            return\n\n        self._mount_point_local_create()\n\n        if len(self.system.mount_opts) == 0:\n            sshfs_opts = \"\"\n        else:\n            sshfs_opts = \" -o %s\" % \" -o \".join(self.system.mount_opts)\n\n        if self.system.auth_method == self.system.AUTH_METHOD_PUBLIC_KEY:\n            ssh_opts = '-o PreferredAuthentications=publickey -i %s' % self.system.ssh_key\n        elif self.system.auth_method:\n            ssh_opts = '-o PreferredAuthentications=%s' % self.system.auth_method\n        else:\n            ssh_opts = '-o PreferredAuthentications=password'\n\n        cmd = (\"{cmd_before_mount} &&\"\n               \" sshfs -o ssh_command=\"\n               \"'ssh -o ConnectTimeout={timeout} -p {port} {ssh_opts}'\"\n               \" {sshfs_opts} {user}@{host}:{remote_path} {local_path}\")\n        cmd = cmd.format(\n            cmd_before_mount = self.system.cmd_before_mount,\n            timeout = self.SSH_CONNECT_TIMEOUT,\n            port = self.system.port,\n            ssh_opts = ssh_opts,\n            sshfs_opts = sshfs_opts,\n            host = self.system.host,\n            user = self.system.user,\n            remote_path = self.mount_point_remote,\n            local_path = self.mount_point_local,\n        )\n\n        output = shell_exec(cmd).strip()\n\n        if not self.mounted:\n            # Clean up the directory tree\n            self._mount_point_local_delete()\n            if output == '':\n                output = 'Mounting failed for a reason unknown to sftpman.'\n            raise SftpMountException(cmd, output)", "response": "Mounts the sftp system if it s not already mounted."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unmount(self):\n        if not self.mounted:\n            return\n\n        # Try to unmount properly.\n        cmd = 'fusermount -u %s' % self.mount_point_local\n        shell_exec(cmd)\n\n        # The filesystem is probably still in use.\n        # kill sshfs and re-run this same command (which will work then).\n        if self.mounted:\n            self._kill()\n            shell_exec(cmd)\n\n        self._mount_point_local_delete()", "response": "Unmounts the sftp system if it s currently mounted."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _validate_order_book(self, book):\n        if book not in self.order_books:\n            raise InvalidOrderBookError(\n                'Invalid order book \\'{}\\'. Choose from {}.'\n                .format(book, tuple(self.order_books))\n            )", "response": "Check if the given order book is valid."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if the given order book is valid.", "response": "def _validate_currency(self, currency):\n        \"\"\"Check if the given order book is valid.\n\n        :param currency: Major currency name in lowercase.\n        :type currency: str | unicode\n        :raise InvalidCurrencyError: If an invalid major currency is given.\n        \"\"\"\n        if currency not in self.major_currencies:\n            raise InvalidCurrencyError(\n                'Invalid major currency \\'{}\\'. Choose from {}.'\n                .format(currency, tuple(self.major_currencies))\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef book(self, name):\n        self._validate_order_book(name)\n        return OrderBook(name, self._rest_client, self._logger)", "response": "Return an API wrapper for the given order book."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef lookup_order(self, order_id):\n        self._log('look up order(s) {}'.format(order_id))\n        return self._rest_client.post(\n            endpoint='/lookup_order',\n            payload={'id': order_id}\n        )", "response": "Look up one or more orders by ID."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncancel an open order by ID.", "response": "def cancel_order(self, order_id):\n        \"\"\"Cancel an open order by ID (64 hexadecmial characters).\n\n        :param order_id: Order ID.\n        :type order_id: str | unicode\n        :return: True if the order was cancelled successfully.\n        :rtype: bool\n        \"\"\"\n        self._log('cancel order {}'.format(order_id))\n        result = self._rest_client.post(\n            endpoint='/cancel_order',\n            payload={'id': order_id}\n        )\n        return result == 'true'"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the deposit address for the given major currency.", "response": "def get_deposit_address(self, currency):\n        \"\"\"Return the deposit address for the given major currency.\n\n        :param currency: Major currency name in lowercase (e.g. \"btc\", \"eth\").\n        :type currency: str | unicode\n        :return: Deposit address.\n        :rtype: str | unicode\n        \"\"\"\n        self._validate_currency(currency)\n        self._log('get deposit address for {}'.format(currency))\n        coin_name = self.major_currencies[currency]\n        return self._rest_client.post(\n            endpoint='/{}_deposit_address'.format(coin_name)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef withdraw(self, currency, amount, address):\n        self._validate_currency(currency)\n        self._log('withdraw {} {} to {}'.format(amount, currency, address))\n        coin_name = self.major_currencies[currency]\n        return self._rest_client.post(\n            endpoint='/{}_withdrawal'.format(coin_name)\n        )", "response": "Withdraw a major currency from QuadrigaCX to the given wallet."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd nodes to the cluster.", "response": "def add_nodes(self, nodes):\n        '''The format of node is similar to add_node.\n        If node contains a key 'cluster_node'\n        whose value is an instance of ClusterNode,\n        it will be used directly.\n        '''\n        new_nodes, master_map = self._add_nodes_as_master(nodes)\n\n        for n in new_nodes:\n            if n.name not in master_map:\n                continue\n            master_name = master_map[n.name]\n            target = self.get_node(master_name)\n            if not target:\n                raise NodeNotFound(master_name)\n            n.replicate(target.name)\n            n.flush_cache()\n            target.flush_cache()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_slaves(self, new_slaves, fast_mode=False):\n        '''This is almost the same with `add_nodes`. The difference is that\n        it will add slaves in two slower way.\n        This is mainly used to avoid huge overhead caused by full sync\n        when large amount of slaves are added to cluster.\n        If fast_mode is False, there is only one master node doing\n        replication at the same time.\n        If fast_mode is True, only after the current slave has finshed\n        its sync, will the next slave on the same host start replication.\n        '''\n        new_nodes, master_map = self._prepare_for_adding(new_slaves)\n\n        slaves = defaultdict(list)\n        for s in new_nodes:\n            slaves[s.host].append(s)\n\n        waiting = set()\n        while len(slaves) > 0:\n            for host in slaves.keys():\n                if self.check_action_stopped():\n                    logger.warning('Slaves adding was stopped, ' \\\n                        'waiting for the last slave to be finished')\n                slave_list = slaves[host]\n                s = slave_list[0]\n\n                if not fast_mode and len(waiting) > 0 and s not in waiting:\n                    continue\n\n                if s not in waiting:\n                    if self.check_action_stopped():\n                        raise ActionStopped(\n                            'Slaves adding was successfully stopped')\n                    master_name = master_map[s.name]\n                    target = self.get_node(master_name)\n                    if not target:\n                        raise NodeNotFound(master_name)\n                    self._add_as_master(s, self.nodes[0])\n                    s.replicate(target.name)\n                    waiting.add(s)\n                    continue\n\n                role = s.execute_command('ROLE')\n                # role[3] being changed to 'connected' means sync is finished\n                if role[0] == 'master' or role[3] != 'connected':\n                    continue\n\n                waiting.remove(s)\n                slave_list.pop(0)\n                if len(slave_list) == 0:\n                    slaves.pop(host)\n\n            if len(waiting) > 0:\n                waiting_list = ['{}:{}'.format(n.host, n.port) for n in waiting]\n                logger.info('sync waiting list: {}'.format(waiting_list))\n            time.sleep(1)", "response": "This method adds new slaves to the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwaits until new_nodes have been added to the cluster", "response": "def _wait_nodes_updated(self, cluster_member, new_nodes):\n        '''Sometimes even cluster_member has responded new_node.meet,\n        cluster_memeber.nodes() are still not updated\n        '''\n        while True:\n            known_nodes = [n['name'] for n in cluster_member.nodes()]\n            added_nodes = [n.name for n in new_nodes]\n            if len(set(known_nodes) & set(added_nodes)) == len(added_nodes):\n                break;\n            logger.info('waiting for adding new nodes in `cluster nodes`')\n            time.sleep(1)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a node to the cluster.", "response": "def add_node(self, node):\n        \"\"\"Add a node to cluster.\n\n        :param node: should be formated like this\n        `{\"addr\": \"\", \"role\": \"slave\", \"master\": \"master_node_id\"}\n        \"\"\"\n        new = ClusterNode.from_uri(node[\"addr\"])\n        cluster_member = self.nodes[0]\n        check_new_nodes([new], [cluster_member])\n\n        new.meet(cluster_member.host, cluster_member.port)\n        self.nodes.append(new)\n\n        self.wait()\n\n        if node[\"role\"] != \"slave\":\n            return\n\n        if \"master\" in node:\n            target = self.get_node(node[\"master\"])\n            if not target:\n                raise NodeNotFound(node[\"master\"])\n        else:\n            masters = sorted(self.masters, key=lambda x: len(x.slaves(x.name)))\n            target = masters[0]\n\n        new.replicate(target.name)\n        new.flush_cache()\n        target.flush_cache()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef func(self, node):\n        'func = \"(\" parameters \")\" _ \"->\" expr'\n        _, params, _, _, _, expr = node\n        params = map(self.eval, params)\n        def func(*args):\n            env = dict(self.env.items() + zip(params, args))\n            return Mini(env).eval(expr)\n        return func", "response": "return a function that evaluates the node s parameters"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef call(self, node, children):\n        'call = name \"(\" arguments \")\"'\n        name, _, arguments, _ = children\n        return name(*arguments)", "response": "get\n        = name \"(\" arguments \")\""}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninfixes = \"(\" expr operator expr \")\"", "response": "def infix(self, node, children):\n        'infix = \"(\" expr operator expr \")\"'\n        _, expr1, operator, expr2, _ = children\n        return operator(expr1, expr2)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef operator(self, node, children):\n        'operator = \"+\" / \"-\" / \"*\" / \"/\"'\n        operators = {'+': op.add, '-': op.sub, '*': op.mul, '/': op.div}\n        return operators[node.text]", "response": "get operator from node"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nassigning the current environment variable to the set of children.", "response": "def assignment(self, node, children):\n        'assignment = lvalue \"=\" expr'\n        lvalue, _, expr = children\n        self.env[lvalue] = expr\n        return expr"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the name of the current class.", "response": "def name(self, node, children):\n        'name = ~\"[a-z]+\" _'\n        return self.env.get(node.text.strip(), -1)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_locale(ln):\n    ctx = _request_ctx_stack.top\n    if ctx is None:\n        raise RuntimeError('Working outside of request context.')\n    new_locale = current_app.extensions['babel'].load_locale(ln)\n    old_locale = getattr(ctx, 'babel_locale', None)\n    setattr(ctx, 'babel_locale', new_locale)\n    yield\n    setattr(ctx, 'babel_locale', old_locale)", "response": "Set Babel localization in request context."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_entrypoint(self, entry_point_group):\n        for ep in iter_entry_points(group=entry_point_group):\n            if not resource_isdir(ep.module_name, 'translations'):\n                continue\n            dirname = resource_filename(ep.module_name, 'translations')\n            self.add_path(dirname)", "response": "Load translations from an entry point group."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload translations from an existing path.", "response": "def add_path(self, path):\n        \"\"\"Load translations from an existing path.\"\"\"\n        if not os.path.exists(path):\n            raise RuntimeError('Path does not exists: %s.' % path)\n        self.paths.append(path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_translation_for_locale(self, locale):\n        translations = None\n\n        for dirname in self.paths:\n            # Load a single catalog.\n            catalog = Translations.load(dirname, [locale], domain=self.domain)\n            if translations is None:\n                if isinstance(catalog, Translations):\n                    translations = catalog\n                continue\n\n            try:\n                # Merge catalog into global catalog\n                translations.merge(catalog)\n            except AttributeError:\n                # Translations is probably NullTranslations\n                if isinstance(catalog, NullTranslations):\n                    current_app.logger.debug(\n                        'Compiled translations seems to be missing'\n                        ' in {0}.'.format(dirname))\n                    continue\n                raise\n\n        return translations or NullTranslations()", "response": "Get a translation for a specific locale."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the correct gettext translations for a request.", "response": "def get_translations(self):\n        \"\"\"Return the correct gettext translations for a request.\n\n        This will never fail and return a dummy translation object if used\n        outside of the request or if a translation cannot be found.\n        \"\"\"\n        ctx = _request_ctx_stack.top\n        if ctx is None:\n            return NullTranslations()\n\n        locale = get_locale()\n\n        cache = self.get_translations_cache(ctx)\n\n        translations = cache.get(str(locale))\n\n        if translations is None:\n            translations = self._get_translation_for_locale(locale)\n            cache[str(locale)] = translations\n\n        return translations"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_lazystring_encoder(app):\n    from speaklater import _LazyString\n\n    class JSONEncoder(app.json_encoder):\n\n        def default(self, o):\n            if isinstance(o, _LazyString):\n                return text_type(o)\n            return super(JSONEncoder, self).default(o)\n\n    return JSONEncoder", "response": "Returns a JSONEncoder for handling lazy strings from Babel."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nflasking application initialization. The initialization will: * Set default values for the configuration variables. * Load translations from paths specified in ``I18N_TRANSLATIONS_PATHS``. * Load translations from ``app.root_path>/translations`` if it exists. * Load translations from a specified entry point. * Add ``toutc`` and ``tousertimezone`` template filters. * Install a custom JSON encoder on app.", "response": "def init_app(self, app):\n        \"\"\"Flask application initialization.\n\n        The initialization will:\n\n         * Set default values for the configuration variables.\n         * Load translations from paths specified in\n           ``I18N_TRANSLATIONS_PATHS``.\n         * Load translations from ``app.root_path>/translations`` if it exists.\n         * Load translations from a specified entry point.\n         * Add ``toutc`` and ``tousertimezone`` template filters.\n         * Install a custom JSON encoder on app.\n        \"\"\"\n        self.init_config(app)\n\n        # Initialize Flask-BabelEx\n        self.babel.init_app(app)\n        self.babel.localeselector(self.localeselector or get_locale)\n        self.babel.timezoneselector(self.timezoneselector or get_timezone)\n\n        # 1. Paths listed in I18N_TRANSLATIONS_PATHS\n        for p in app.config.get('I18N_TRANSLATIONS_PATHS', []):\n            self.domain.add_path(p)\n        # 2. <app.root_path>/translations\n        app_translations = os.path.join(app.root_path, 'translations')\n        if os.path.exists(app_translations):\n            self.domain.add_path(app_translations)\n        # 3. Entrypoints\n        if self.entry_point_group:\n            self.domain.add_entrypoint(self.entry_point_group)\n\n        # Register default routes if URL is set.\n        register_default_routes = app.config['I18N_SET_LANGUAGE_URL'] \\\n            and app.config['I18N_LANGUAGES']\n        app.register_blueprint(\n            create_blueprint(register_default_routes=register_default_routes),\n            url_prefix=app.config['I18N_SET_LANGUAGE_URL']\n        )\n\n        # Register Jinja2 template filters for date formatting (Flask-Babel\n        # already installs other filters).\n        app.add_template_filter(filter_to_utc, name='toutc')\n        app.add_template_filter(filter_to_user_timezone, name='tousertimezone')\n        app.add_template_filter(filter_language_name, name='language_name')\n        app.add_template_filter(\n            filter_language_name_local, name='language_name_local')\n        app.add_template_global(current_i18n, name='current_i18n')\n\n        # Lazy string aware JSON encoder.\n        app.json_encoder = get_lazystring_encoder(app)\n\n        app.extensions['invenio-i18n'] = self"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef iter_languages(self):\n        default_lang = self.babel.default_locale.language\n        default_title = self.babel.default_locale.get_display_name(\n            default_lang)\n\n        yield (default_lang, default_title)\n\n        for l, title in current_app.config.get('I18N_LANGUAGES', []):\n            yield l, title", "response": "Iterate over list of languages."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_languages(self):\n        if self._languages_cache is None:\n            self._languages_cache = list(self.iter_languages())\n        return self._languages_cache", "response": "Get list of languages."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a list of supported locales.", "response": "def get_locales(self):\n        \"\"\"Get a list of supported locales.\n\n        Computes the list using ``I18N_LANGUAGES`` configuration variable.\n        \"\"\"\n        if self._locales_cache is None:\n            langs = [self.babel.default_locale]\n            for l, dummy_title in current_app.config.get('I18N_LANGUAGES', []):\n                langs.append(self.babel.load_locale(l))\n            self._locales_cache = langs\n        return self._locales_cache"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_metaclass(metaclass):\n    vars_to_skip = ('__dict__', '__weakref__')\n\n    def wrapper(cls):\n        copied_dict = {\n            key: value\n            for key, value in cls.__dict__.items()\n            if key not in vars_to_skip\n        }\n        return metaclass(cls.__name__, cls.__bases__, copied_dict)\n    return wrapper", "response": "A class decorator for creating a class with a metaclass"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_nodes(cls, nodes, new_nodes, max_slaves_limit=None):\n        '''When this is used only for peeking reuslt\n           `new_nodes` can be any type with `host` and `port` attributes\n        '''\n        param = gen_distribution(nodes, new_nodes)\n        param['max_slaves_limit'] = max_slaves_limit\n        return cls(**param)", "response": "Create a new reuslt\n           object from a set of nodes and new_nodes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _gen_tasks(self):\n        for filename in self.args:\n            path = os.path.abspath(filename)\n            yield {\n                'name': path,\n                # 'file_dep': [path],\n                'actions': [(self.fun, (filename,))],\n            }", "response": "generate doit tasks for each file"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nimplements loader interface returns ( tasks config", "response": "def load_tasks(self, cmd, params, args):\n        \"\"\"implements loader interface, return (tasks, config)\"\"\"\n        return generate_tasks('taskname that shows up in log', self._gen_tasks()), self.DOIT_CONFIG"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef drain(iterable):\n    if getattr(iterable, \"popleft\", False):\n        def next_item(coll):\n            return coll.popleft()\n    elif getattr(iterable, \"popitem\", False):\n        def next_item(coll):\n            return coll.popitem()\n    else:\n        def next_item(coll):\n            return coll.pop()\n\n    while True:\n        try:\n            yield next_item(iterable)\n        except (IndexError, KeyError):\n            raise StopIteration", "response": "A generator that returns the items from the given iterable."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndivide integer n to m chunks", "response": "def divide(n, m):\n    \"\"\"Divide integer n to m chunks\n    \"\"\"\n    avg = int(n / m)\n    remain = n - m * avg\n    data = list(itertools.repeat(avg, m))\n    for i in range(len(data)):\n        if not remain:\n            break\n        data[i] += 1\n        remain -= 1\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef spread(nodes, n):\n    target = []\n\n    while len(target) < n and nodes:\n        for ip, node_group in list(nodes.items()):\n            if not node_group:\n                nodes.pop(ip)\n                continue\n            target.append(node_group.pop(0))\n            if len(target) >= n:\n                break\n    return target", "response": "Return a list of n master instances in different nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndetermines if URL is safe to redirect to.", "response": "def is_local_url(target):\n    \"\"\"Determine if URL is safe to redirect to.\"\"\"\n    ref_url = urlparse(request.host_url)\n    test_url = urlparse(urljoin(request.host_url, target))\n    return test_url.scheme in ('http', 'https') and \\\n        ref_url.netloc == test_url.netloc"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting URL to redirect to and ensure that it is local.", "response": "def get_redirect_target():\n    \"\"\"Get URL to redirect to and ensure that it is local.\"\"\"\n    for target in request.values.get('next'), request.referrer:\n        if target and is_local_url(target):\n            return target"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_lang(lang_code=None):\n    # Check if language is available.\n    lang_code = lang_code or request.values.get('lang_code')\n    languages = dict(current_app.extensions['invenio-i18n'].get_languages())\n    if lang_code is None or lang_code not in languages:\n        abort(404 if request.method == 'GET' else 400)\n\n    # Set language in session.\n    session[current_app.config['I18N_SESSION_KEY']] = lang_code.lower()\n\n    # Redirect user back.\n    target = get_redirect_target()\n    if not target:\n        endpoint = current_app.config['I18N_DEFAULT_REDIRECT_ENDPOINT']\n        target = url_for(endpoint) if endpoint else '/'\n\n    return redirect(target)", "response": "Set language in session and redirect."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating Invenio - I18N blueprint.", "response": "def create_blueprint(register_default_routes=True):\n    \"\"\"Create Invenio-I18N blueprint.\"\"\"\n    blueprint = Blueprint(\n        'invenio_i18n',\n        __name__,\n        template_folder='templates',\n        static_folder='static',\n    )\n\n    if register_default_routes:\n        blueprint.add_url_rule('/', view_func=set_lang, methods=['POST'])\n        blueprint.add_url_rule('/<lang_code>', view_func=set_lang,\n                               methods=['GET'])\n\n    return blueprint"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef compile_file_into_spirv(filepath, stage, optimization='size',\n                            warnings_as_errors=False):\n    \"\"\"Compile shader file into Spir-V binary.\n\n    This function uses shaderc to compile your glsl file code into Spir-V\n    code.\n\n    Args:\n        filepath (strs): Absolute path to your shader file\n        stage (str): Pipeline stage in ['vert', 'tesc', 'tese', 'geom',\n                     'frag', 'comp']\n        optimization (str): 'zero' (no optimization) or 'size' (reduce size)\n        warnings_as_errors (bool): Turn warnings into errors\n\n    Returns:\n        bytes: Compiled Spir-V binary.\n\n    Raises:\n        CompilationError: If compilation fails.\n    \"\"\"\n    with open(filepath, 'rb') as f:\n        content = f.read()\n\n    return compile_into_spirv(content, stage, filepath,\n                              optimization=optimization,\n                              warnings_as_errors=warnings_as_errors)", "response": "Compile a file into a Spir - V binary."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef compile_into_spirv(raw, stage, filepath, language=\"glsl\",\n                       optimization='size', suppress_warnings=False,\n                       warnings_as_errors=False):\n    \"\"\"Compile shader code into Spir-V binary.\n\n    This function uses shaderc to compile your glsl or hlsl code into Spir-V\n    code. You can refer to the shaderc documentation.\n\n    Args:\n        raw (bytes): glsl or hlsl code (bytes format, not str)\n        stage (str): Pipeline stage in ['vert', 'tesc', 'tese', 'geom',\n                     'frag', 'comp']\n        filepath (str): Absolute path of the file (needed for #include)\n        language (str): 'glsl' or 'hlsl'\n        optimization (str): 'zero' (no optimization) or 'size' (reduce size)\n        suppress_warnings (bool): True to suppress warnings\n        warnings_as_errors (bool): Turn warnings into errors\n\n    Returns:\n        bytes: Compiled Spir-V binary.\n\n    Raises:\n        CompilationError: If compilation fails.\n    \"\"\"\n    # extract parameters\n    stage = stages_mapping[stage]\n    lang = languages_mapping[language]\n    opt = opt_mapping[optimization]\n\n    # initialize options\n    options = lib.shaderc_compile_options_initialize()\n    lib.shaderc_compile_options_set_source_language(options, lang)\n    lib.shaderc_compile_options_set_optimization_level(options, opt)\n    lib.shaderc_compile_options_set_target_env(\n        options, lib.shaderc_target_env_vulkan, 0)\n    lib.shaderc_compile_options_set_auto_bind_uniforms(options, False)\n    lib.shaderc_compile_options_set_include_callbacks(\n        options, lib.resolve_callback, lib.release_callback, ffi.NULL)\n\n    if suppress_warnings:\n        lib.shaderc_compile_options_set_suppress_warnings(options)\n    if warnings_as_errors:\n        lib.shaderc_compile_options_set_warnings_as_errors(options)\n\n    # initialize compiler\n    compiler = lib.shaderc_compiler_initialize()\n\n    # compile\n    result = lib.shaderc_compile_into_spv(compiler, raw, len(raw), stage,\n                                          str.encode(filepath), b\"main\",\n                                          options)\n\n    # extract result\n    status = lib.shaderc_result_get_compilation_status(result)\n    if status != lib.shaderc_compilation_status_success:\n        msg = _get_log(result)\n        lib.shaderc_compile_options_release(options)\n        lib.shaderc_result_release(result)\n        lib.shaderc_compiler_release(compiler)\n        raise CompilationError(msg)\n\n    length = lib.shaderc_result_get_length(result)\n    output_pointer = lib.shaderc_result_get_bytes(result)\n\n    tmp = bytearray(length)\n    ffi.memmove(tmp, output_pointer, length)\n    spirv = bytes(tmp)\n\n    # release resources\n    lib.shaderc_compile_options_release(options)\n    lib.shaderc_result_release(result)\n    lib.shaderc_compiler_release(compiler)\n\n    return spirv", "response": "Compile the raw shader code into a Spir - V binary."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef expand_folder(files):\n    expfiles = []\n    for file in files:\n        if os.path.isdir(file):\n            for dirpath, dirnames, filenames in os.walk(file):\n                for filename in filenames:\n                    expfiles.append(os.path.join(dirpath, filename))\n        else:\n            expfiles.append(file)\n\n    for path in expfiles:\n        if not os.path.exists(path):\n            sys.stderr.write('%s: No such file or directory\\n' % path)\n\n    return expfiles", "response": "Return a clone of file list files where all directories are recursively replaced with their contents."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of strings corresponding to file names supplied by drag and drop or standard input.", "response": "def get_file_list():\n    \"\"\"Return a list of strings corresponding to file names supplied by drag and drop or standard input.\"\"\"\n\n    if len(sys.argv) > 1:\n        file_list = list(sys.argv[1:])  # make copy\n    else:\n        files_str = input('Select the files you want to process and drag and drop them onto this window, '\n                          'or type their names separated by spaces. Paths containing spaces should be '\n                          'surrounded by quotation marks.\\nPress ENTER when you\\'re done: ')\n\n        if \"win\" in sys.platform:\n            # the POSIX shlex.split uses backslashes for escape sequences, so Windows paths need to set posix=False\n            file_list = shlex.split(files_str, posix=False)\n\n            # the non-POSIX shlex.split does not automatically clean quotation marks from the final product\n            file_list = [f.replace('\"', '').replace(\"'\", \"\") for f in file_list]\n        else:\n            file_list = shlex.split(files_str, posix=True)\n\n    # substitute in shell variables and get absolute paths\n    for i in range(len(file_list)):\n        file_list[i] = os.path.abspath( os.path.expanduser(os.path.expandvars(file_list[i])) )\n\n    return file_list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete nodes from the cluster", "response": "def delete(args):\n    \"\"\"Delete nodes from the cluster\n    \"\"\"\n    nodes = [ClusterNode.from_uri(n) for n in args.nodes]\n    cluster = Cluster.from_node(ClusterNode.from_uri(args.cluster))\n\n    echo(\"Deleting...\")\n    for node in nodes:\n        cluster.delete_node(node)\n        cluster.wait()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reshard(args):\n    cluster = Cluster.from_node(ClusterNode.from_uri(args.cluster))\n    cluster.reshard()", "response": "Balance slots in the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmakes node to be the slave of a master.", "response": "def replicate(ctx, args):\n    \"\"\"Make node to be the slave of a master.\n    \"\"\"\n    slave = ClusterNode.from_uri(args.node)\n    master = ClusterNode.from_uri(args.master)\n    if not master.is_master():\n        ctx.abort(\"Node {!r} is not a master.\".format(args.master))\n\n    try:\n        slave.replicate(master.name)\n    except redis.ResponseError as e:\n        ctx.abort(str(e))\n\n    Cluster.from_node(master).wait()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef flushall(args):\n    cluster = Cluster.from_node(ClusterNode.from_uri(args.cluster))\n    for node in cluster.masters:\n        node.flushall()", "response": "Execute flushall in all cluster nodes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstopping the countdown for the given label.", "response": "def stop(label, at=None, remove_from_labels=False, stop_once=True):\n    \"\"\"Stops the countdown\"\"\"\n    t = at if at is not None else time.time()\n\n    if label not in labels:\n        return None\n\n    timer = Marker().loads(labels[label])\n\n    if timer.is_running() or (timer.is_stopped() and not stop_once):\n        timer.stop(t)\n\n    if remove_from_labels:\n        del labels[label]\n    else:\n        labels[label] = timer.dumps()\n\n    return timer.duration()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn duration in seconds for label", "response": "def duration(label, stop_it=True, stop_at=None):\n    \"\"\"Returns duration in seconds for label\"\"\"\n\n    if label not in labels:\n        return None\n\n    if \"duration\" in labels[label]:\n        return Duration(labels[label][\"duration\"])\n\n    if stop_it:\n        return stop(label, at=stop_at)\n    else:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _handle_response(self, resp):\n        http_code = resp.status_code\n        if http_code not in self.http_success_status_codes:\n            raise RequestError(\n                response=resp,\n                message='[HTTP {}] {}'.format(http_code, resp.reason)\n            )\n        try:\n            body = resp.json()\n        except ValueError:\n            raise RequestError(\n                response=resp,\n                message='[HTTP {}] response body: {}'.format(\n                    http_code,\n                    resp.text\n                )\n            )\n        else:\n            if 'error' in body:\n                error_code = body['error'].get('code', '?')\n                raise RequestError(\n                    response=resp,\n                    message='[HTTP {}][ERR {}] {}'.format(\n                        resp.status_code,\n                        error_code,\n                        body['error'].get('message', 'no error message')\n                    ),\n                    error_code=error_code\n                )\n            return body", "response": "Handle the response from QuadrigaCX."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(self, endpoint, params=None):\n        response = self._session.get(\n            url=self._url + endpoint,\n            params=params,\n            timeout=self._timeout\n        )\n        return self._handle_response(response)", "response": "Send an HTTP GET request to QuadrigaCX."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend an HTTP POST request to QuadrigaCX.", "response": "def post(self, endpoint, payload=None):\n        \"\"\"Send an HTTP POST request to QuadrigaCX.\n\n        :param endpoint: API endpoint.\n        :type endpoint: str | unicode\n        :param payload: Request payload.\n        :type payload: dict\n        :return: Response body from QuadrigaCX.\n        :rtype: dict\n        :raise quadriga.exceptions.RequestError: If HTTP OK was not returned.\n        \"\"\"\n        nonce = int(time.time() * 10000)\n        hmac_msg = str(nonce) + self._client_id + self._api_key\n        signature = hmac.new(\n            key=self._hmac_key,\n            msg=hmac_msg.encode('utf-8'),\n            digestmod=hashlib.sha256\n        ).hexdigest()\n\n        if payload is None:\n            payload = {}\n        payload['key'] = self._api_key\n        payload['nonce'] = nonce\n        payload['signature'] = signature\n\n        response = self._session.post(\n            url=self._url + endpoint,\n            json=payload,\n            timeout=self._timeout\n        )\n        return self._handle_response(response)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef command_help(self, *args, **kwargs):\n        print(\"Commands available:\\n\")\n        for name in dir(self):\n            if not name.startswith(\"command_\"):\n                continue\n            name_clean = name[len(\"command_\"):]\n            print(\"%s:\\n - %s\\n\" % (name_clean, getattr(self, name).__doc__.strip()))", "response": "Displays this help menu."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef command_setup(self, *args):\n        def usage():\n            print(self.command_setup.__doc__)\n            sys.exit(1)\n\n        if len(args) == 0:\n            usage()\n\n        try:\n            # All of these (except mount_opt) map directly to the model properties\n            # We allow several `mount_opt` flags and merge their values, before\n            # assigning to the `mount_opts` property (which expects a list).\n            fields = [\n                \"id\", \"host\", \"port\", \"user\",\n                \"mount_opt\", \"mount_point\",\n                \"ssh_key\", \"cmd_before_mount\",\n                \"auth_method\",\n            ]\n            opts, _ = getopt.getopt(args, \"\", [\"%s=\" % s for s in fields])\n        except getopt.GetoptError as e:\n            sys.stderr.write('Error: %s\\n\\n' % e)\n            usage()\n\n        system = SystemModel()\n        mount_opts = []\n        for name, value in opts:\n            name = name.lstrip('-')\n            if not hasattr(system, name):\n                continue\n            if name == 'mount_opt':\n                mount_opts.append(value)\n                continue\n            setattr(system, name, value)\n        system.mount_opts = mount_opts\n\n        is_valid, errors = system.validate()\n        if not is_valid:\n            sys.stderr.write('Invalid data found:\\n')\n            for field_name, msg in errors:\n                sys.stderr.write(' - %s: %s\\n' % (field_name, msg))\n            sys.stderr.write('\\n')\n            usage()\n            sys.exit(1)\n\n        system.save(self.environment)\n        print('Configuration created.')\n        print('You can try mounting now: `sftpman mount %s`' % system.id)", "response": "Defines a new sftp file system configuration or edits an old one with the same id."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef command_rm(self, system_id, *system_ids):\n        # Intentionally reading the first system_id separately,\n        # because it's required. The others are optional.\n        # This ensures that we'll generate an error if someone tries to call\n        # this without the required argument.\n        system_ids = (system_id,) + system_ids\n        has_failed = False\n        for system_id in system_ids:\n            try:\n                system = SystemModel.create_by_id(system_id, self.environment)\n                controller = SystemControllerModel(system, self.environment)\n                controller.unmount()\n                system.delete(self.environment)\n            except SftpException as e:\n                sys.stderr.write('Cannot remove %s: %s\\n' % (system_id, str(e)))\n                has_failed = True\n        if has_failed:\n            sys.exit(1)", "response": "Remove a system by id."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef command_preflight_check(self):\n        checks_pass, failures = self.environment.perform_preflight_check()\n        if checks_pass:\n            print('All checks pass.')\n        else:\n            sys.stderr.write('Problems encountered:\\n')\n            for msg in failures:\n                sys.stderr.write(' - %s\\n' % msg)\n            sys.exit(1)", "response": "Detects whether we have everything needed to mount sshfs filesystems."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlist the available sftp systems.", "response": "def command_ls(self, list_what):\n        \"\"\"Lists the available/mounted/unmounted sftp systems.\n        Usage: sftpman ls {what}\n        Where {what} is one of: available, mounted, unmounted\n        \"\"\"\n        if list_what in ('available', 'mounted', 'unmounted'):\n            callback = getattr(self.environment, 'get_%s_ids' % list_what)\n            lst = callback()\n        else:\n            lst = []\n        if len(lst) != 0:\n            print((\"\\n\".join(lst)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef command_mount(self, system_id, *system_ids):\n        system_ids = (system_id,) + system_ids\n        has_failed = False\n        for system_id in system_ids:\n            try:\n                system = SystemModel.create_by_id(system_id, self.environment)\n                controller = SystemControllerModel(system, self.environment)\n                controller.mount()\n            except SftpConfigException as e:\n                sys.stderr.write('Cannot mount %s: %s\\n\\n' % (system_id, str(e)))\n                has_failed = True\n            except SftpMountException as e:\n                sys.stderr.write('Cannot mount %s!\\n\\n' % system_id)\n                sys.stderr.write('Mount command: \\n%s\\n\\n' % e.mount_cmd)\n                sys.stderr.write('Command output: \\n%s\\n\\n' % e.mount_cmd_output)\n                has_failed = True\n        if has_failed:\n            sys.exit(1)", "response": "Mounts the specified sftp system."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlog a debug message prefixed with order book name.", "response": "def _log(self, message):\n        \"\"\"Log a debug message prefixed with order book name.\n\n        :param message: Debug message.\n        :type message: str | unicode\n        \"\"\"\n        self._logger.debug(\"{}: {}\".format(self.name, message))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_ticker(self):\n        self._log('get ticker')\n        return self._rest_client.get(\n            endpoint='/ticker',\n            params={'book': self.name}\n        )", "response": "Return the latest ticker information."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning public orders that are currently open.", "response": "def get_public_orders(self, group=False):\n        \"\"\"Return public orders that are currently open.\n\n        :param group: If set to True (default: False), orders with the same\n            price are grouped.\n        :type group: bool\n        :return: Public orders currently open.\n        :rtype: dict\n        \"\"\"\n        self._log('get public orders')\n        return self._rest_client.get(\n            endpoint='/order_book',\n            params={'book': self.name, 'group': int(group)}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets public trades that were completed recently.", "response": "def get_public_trades(self, time_frame='hour'):\n        \"\"\"Return public trades that were completed recently.\n\n        :param time_frame: Time frame. Allowed values are \"minute\" for trades\n            in the last minute, or \"hour\" for trades in the last hour (default:\n            \"hour\").\n        :type time_frame: str | unicode\n        :return: Public trades completed recently.\n        :rtype: [dict]\n        \"\"\"\n        self._log('get public trades')\n        return self._rest_client.get(\n            endpoint='/transactions',\n            params={'book': self.name, 'time': time_frame}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_user_orders(self):\n        self._log('get user orders')\n        return self._rest_client.post(\n            endpoint='/open_orders',\n            payload={'book': self.name}\n        )", "response": "Return user s orders that are currently open."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the user s trades.", "response": "def get_user_trades(self, limit=0, offset=0, sort='desc'):\n        \"\"\"Return user's trade history.\n\n        :param limit: Maximum number of trades to return. If set to 0 or lower,\n            all trades are returned (default: 0).\n        :type limit: int\n        :param offset: Number of trades to skip.\n        :type offset: int\n        :param sort: Method used to sort the results by date and time. Allowed\n            values are \"desc\" for descending order, and \"asc\" for ascending\n            order (default: \"desc\").\n        :type sort: str | unicode\n        :return: User's trade history.\n        :rtype: [dict]\n        \"\"\"\n        self._log('get user trades')\n        res = self._rest_client.post(\n            endpoint='/user_transactions',\n            payload={\n                'book': self.name,\n                'limit': limit,\n                'offset': offset,\n                'sort': sort\n            }\n        )\n        # TODO Workaround for the broken limit param in QuadrigaCX API\n        return res[:limit] if len(res) > limit > 0 else res"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nplaces a buy order at market price.", "response": "def buy_market_order(self, amount):\n        \"\"\"Place a buy order at market price.\n\n        :param amount: Amount of major currency to buy at market price.\n        :type amount: int | float | str | unicode | decimal.Decimal\n        :return: Order details.\n        :rtype: dict\n        \"\"\"\n        amount = str(amount)\n        self._log(\"buy {} {} at market price\".format(amount, self.major))\n        return self._rest_client.post(\n            endpoint='/buy',\n            payload={'book': self.name, 'amount': amount}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nplace a buy order at the given limit price.", "response": "def buy_limit_order(self, amount, price):\n        \"\"\"Place a buy order at the given limit price.\n\n        :param amount: Amount of major currency to buy at limit price.\n        :type amount: int | float | str | unicode | decimal.Decimal\n        :param price: Limit price.\n        :type price: int | float | str | unicode | decimal.Decimal\n        :return: Order details.\n        :rtype: dict\n        \"\"\"\n        amount = str(amount)\n        price = str(price)\n        self._log(\"buy {} {} at limit price of {} {}\".format(\n            amount, self.major, price, self.minor\n        ))\n        return self._rest_client.post(\n            endpoint='/buy',\n            payload={'book': self.name, 'amount': amount, 'price': price}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef request(self, data, request_type: RequestTypes):\n        #prepare the URL to send the request to\n        url = data['host'] + data['path']\n\n        #fixed header content\n        headers = self._DEFAULT_HEADER\n        if self._sessionid:\n            headers['Cookie'] = \"skySSEIONID=\" + self._sessionid\n\n        #prepare the payload and add the length to the header, payload might be empty.\n        if \"data\" in data:\n            payload = json.dumps(data['data'])\n            headers[\"Content-Length\"] = str(len(data['data']))\n        else: payload = \"\"\n        \n        #send the request and capture the response\n        resp = requests.request(request_type.value, url, data=payload, headers=headers)\n        # raise an error if it occured in the Request.\n        resp.raise_for_status()\n        # no error, so set result to success\n        ret = {'result': 'success'}\n        # check if there is something in the response body\n        if len(resp.text) > 0:\n            respjson = resp.json()\n            # if it is a list of things, then set the tag to things\n            if type(respjson) is list:\n                ret['things'] = respjson\n            # otherwise to a single thing. If ID is part of it it is a login response, otherwise a Thing\n            elif \"ID\" in respjson:\n                ret['login'] = respjson\n                # if it was a login a new cookie was send back, capture the sessionid from it\n                self._sessionid = resp.cookies['skySSEIONID']\n                ret['cookie'] = resp.cookies\n            else:            \n                ret['thing'] = respjson\n        return ret", "response": "internal request method for getting the internal data from the API"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef login(self, username, password):\n        self._user = username\n        self._pass = password\n        return self._login()", "response": "Login using username and password"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks whether or not the user is logged in.", "response": "def _is_logged_in(self):\n        \"\"\" Check whether or not the user is logged in. \"\"\"\n        # if the user has not logged in in 24 hours, relogin\n        if not self._http._has_session() or datetime.utcnow() >= self._lastlogin + timedelta(hours=24):\n            return self._login()\n        else:\n            return {}"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the things registered in your account", "response": "def getThings(self):\n        \"\"\" Get the things registered in your account \n        \n        :return: dict with things registered in the logged in account and API call status\n        \"\"\"\n        login_return = self._is_logged_in()\n            # raise NameError(\"Please login first using the login function, with username and password\")\n        data = {\n            \"path\": \"/thing\",\n            \"host\": \"https://sky.brunt.co\"\n        }\n        resp = self._http.request(data, RequestTypes.GET)\n        self._things = resp['things']\n        resp.update(login_return)\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getState(self, **kwargs):\n        login_return = self._is_logged_in()\n        if \"thingUri\" in kwargs:\n            thingUri = kwargs['thingUri']\n        elif \"thing\" in kwargs:\n            thing = kwargs['thing']\n            for t in self._getThings():\n                if 'NAME' in t:\n                    if  t['NAME'] == thing and 'thingUri' in t:\n                        thingUri = t['thingUri']\n                        break\n                    else:\n                        raise ValueError('Unknown thing: ' + thing)\n                else:\n                    raise ValueError('No things available.')\n        else:\n            return SyntaxError(\"Please provide either the 'thing' name or the 'thingUri' not both and at least one\")\n        data = {\n            \"path\": \"/thing\" + thingUri,\n            \"host\": \"https://thing.brunt.co:8080\" \n        }\n        resp = self._http.request(data, RequestTypes.GET)\n        resp.update(login_return)\n        return resp", "response": "Get the state of a thing."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nchange a variable of the thing.", "response": "def changeKey(self, **kwargs):\n        \"\"\"Change a variable of the thing.  Mostly included for future additions.\n\n        :param key: The value you want to change\n        :param value: The new value\n        :param thing: a string with the name of the thing, which is then checked using getThings.\n        :param thingUri: Uri (string) of the thing you are getting the state from, not checked against getThings.\n        :return: a dict with the state of the Thing.\n        :raises: ValueError if the requested thing does not exists or the position is not between 0 and 100. \n            NameError if not logged in. SyntaxError when not exactly one of the params is given. \n        \"\"\"\n        login_return = self._is_logged_in()\n        #check the thing being changed\n        if \"thingUri\" in kwargs:\n            thingUri = kwargs['thingUri']\n        elif \"thing\" in kwargs:\n            thing = kwargs['thing']\n            for t in self._getThings():\n                if 'NAME' in t:\n                    if  t['NAME'] == thing and 'thingUri' in t:\n                        thingUri = t['thingUri']\n                        break\n                    else:\n                        raise ValueError('Unknown thing: ' + thing)\n                else:\n                    raise ValueError('No things available.')\n        else:\n            return SyntaxError(\"Please provide either the 'thing' name or the 'thingUri' not both and at least one\")\n\n        if 'key' in kwargs:\n            key = kwargs['key']\n        else:\n            raise SyntaxError(\"Please provide a key to change\")\n\n        if 'value' in kwargs:\n            value = kwargs['value']\n        else:\n            raise SyntaxError(\"Please provide a value to change to\")\n\n        if key.lower().find('position'):\n            if int(value) < 0 or int(value) > 100:\n                return ValueError(\"Please set the position between 0 and 100.\")\n\n        #prepare data payload\n        data = {\n            \"data\": {\n                str(key): str(value)\n            },\n            \"path\": \"/thing\" + thingUri,\n            \"host\": \"https://thing.brunt.co:8080\"\n        }\n        \n        #call the request method and return the response.\n        resp = self._http.request(data, RequestTypes.PUT)\n        resp.update(login_return)\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef changeRequestPosition(self, request_position, **kwargs):\n        kwargs['key']=\"requestPosition\"\n        kwargs['value']=request_position\n        return self.changeKey(**kwargs)", "response": "Change the position of the requested thing."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ndlayout_(self, dataset, kdims, cols=3):\n        try:\n            return hv.NdLayout(dataset, kdims=kdims).cols(cols)\n        except Exception as e:\n            self.err(e, self.layout_, \"Can not create layout\")", "response": "Create a Holoview NdLayout from a dictionnary of chart objects"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef layout_(self, chart_objs, cols=3):\n        try:\n            return hv.Layout(chart_objs).cols(cols)\n        except Exception as e:\n            self.err(e, self.layout_, \"Can not build layout\")", "response": "Build a Holoview Layout from a list of chart objects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn an horizontal line from a column mean value", "response": "def _hline_bokeh_(self, col):\n        \"\"\"\n        Returns an horizontal line from a column mean value\n        \"\"\"\n        c = hv.HLine(self.df[col].mean())\n        return c"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a chart with a smooth line from a serie", "response": "def _sline_bokeh(self, window_size, y_label):\n        \"\"\"\n        Returns a chart with a smooth line from a serie\n        \"\"\"\n        try:\n            ds2 = self.clone_()\n            window = np.ones(int(window_size)) / float(window_size)\n            ds2.df[y_label] = np.convolve(self.df[self.y], window, 'same')\n            ds2.chart(self.x, y_label)\n            return ds2.line_()\n        except Exception as e:\n            self.err(e, self._sline_bokeh, \"Can not draw smooth line chart\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a Bokeh linear regression line", "response": "def _lreg_bokeh(self, **kwargs):\n        \"\"\"\n        Returns a Bokeh linear regression line\n        \"\"\"\n        try:\n            ds2 = self._duplicate_()\n            ds2.timestamps(ds2.x)\n            ds2.lreg(\"Timestamps\", ds2.y)\n            ds2.drop(ds2.y)\n            ds2.df = ds2.df.rename(columns={'Regression': ds2.y})\n            if \"date_format\" in self.chart_style:\n                ds2.date(\"Date\", format=self.chart_style[\"date_format\"])\n            c = ds2.line_()\n            return c\n        except Exception as e:\n            self.err(e, \"Can not draw linear regression chart\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndraw a chart to visualize quantiles for a specific class", "response": "def _bokeh_quants(self, inf, sup, chart_type, color):\n        \"\"\"\n        Draw a chart to visualize quantiles\n        \"\"\"\n        try:\n            ds2 = self._duplicate_()\n            qi = ds2.df[ds2.y].quantile(inf)\n            qs = ds2.df[ds2.y].quantile(sup)\n            ds2.add(\"sup\", qs)\n            ds2.add(\"inf\", qi)\n            ds2.chart(ds2.x, ds2.y)\n            if chart_type == \"point\":\n                c = ds2.point_(opts=self.chart_opts, style=self.chart_style)\n            elif chart_type == \"line_point\":\n                c = ds2.line_point_(opts=self.chart_opts, style=self.chart_style)\n            else:\n                c = ds2.line_(opts=self.chart_opts, style=self.chart_style)\n            ds2.color(color)\n            ds2.chart(ds2.x, \"sup\")\n            c2 = ds2.line_()\n            ds2.chart(ds2.x, \"inf\")\n            c3 = ds2.line_()\n            ds2.rcolor()\n            return c * c2 * c3\n        except Exception as e:\n            self.err(e, \"Can not draw quantile chart\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_bokeh_chart(self, x_field, y_field, chart_type,\n                         label, opts, style, options={}, **kwargs):\n        \"\"\"\n        Get a Bokeh chart object\n        \"\"\"\n        if isinstance(x_field, list):\n            kdims = x_field\n        else:\n            kdims = [x_field]\n        if isinstance(y_field, list):\n            vdims = y_field\n        else:\n            vdims = [y_field]\n        args = kwargs\n        args[\"data\"] = self.df\n        args[\"kdims\"] = kdims\n        args[\"vdims\"] = vdims\n        if label is not None:\n            args[\"label\"] = label\n        else:\n            if self.label is not None:\n                args[\"label\"] = self.label\n        chart = None\n        try:\n            if chart_type == \"line\":\n                chart = hv.Curve(**args)\n            if chart_type == \"hline\":\n                chart = self._hline_bokeh_(y_field)\n            elif chart_type == \"point\":\n                chart = hv.Scatter(**args)\n            elif chart_type == \"area\":\n                chart = hv.Area(**args)\n            elif chart_type == \"bar\":\n                chart = hv.Bars(**args)\n            elif chart_type == \"hist\":\n                chart = hv.Histogram(**args)\n            elif chart_type == \"errorBar\":\n                chart = hv.ErrorBars(**args)\n            elif chart_type == \"heatmap\":\n                chart = hv.HeatMap(**args)\n            elif chart_type == \"lreg\":\n                chart = self._lreg_bokeh(**args)\n            elif chart_type == \"sline\":\n                window_size, y_label = options[\"window_size\"], options[\"y_label\"]\n                chart = self._sline_bokeh(window_size, y_label)\n            if chart is None:\n                self.err(\"Chart type \" + chart_type + \n                         \" unknown\", self._get_bokeh_chart)\n                return\n            endchart = chart(plot=opts, style=style)\n            return endchart\n        except DataError as e:\n            msg = \"Column not found in \" + x_field + \" and \" + y_field\n            self.err(e, self._get_bokeh_chart, msg)\n        except Exception as e:\n            self.err(e)", "response": "Get a Bokeh chart object from the specified chart type and options."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the html for a Bokeh chart", "response": "def _get_bokeh_html(self, chart_obj):\n        \"\"\"\n        Get the html for a Bokeh chart\n        \"\"\"\n        global bokeh_renderer\n        try:\n            renderer = bokeh_renderer\n            p = renderer.get_plot(chart_obj).state\n            script, div = components(p)\n            return script + \"\\n\" + div\n\n        except Exception as e:\n            self.err(e, self._get_bokeh_html,\n                     \"Can not get html from the Bokeh rendering engine\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a Dataframe with the contents of the GCT file", "response": "def GCT(gct_obj):\n    \"\"\"\n    Create a Dataframe with the contents of the GCT file\n    \"\"\"\n    # Handle all the various initialization types and get an IO object\n    gct_io = _obtain_io(gct_obj)\n\n    # Load the GCT file into a DataFrame\n    df = pd.read_csv(gct_io, sep='\\t', header=2, index_col=[0, 1], skip_blank_lines=True)\n\n    # Apply backwards compatible methods\n    _apply_backwards_compatibility(df)\n\n    # Return the Dataframe\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a Dataframe with the contents of the ODF file.", "response": "def ODF(odf_obj):\n    \"\"\"\n    Create a Dataframe with the contents of the ODF file\n\n    For more information on the ODF format see:\n    http://software.broadinstitute.org/cancer/software/genepattern/file-formats-guide\n\n    :odf_obj: The ODF file. Accepts a file-like object, a file path, a URL to the file\n              or a string containing the raw data.\n    \"\"\"\n\n    # Handle all the various initialization types and get an IO object\n    odf_io = _obtain_io(odf_obj)\n\n    # Read the file as an array of lines\n    raw_lines = odf_io.readlines()\n\n    # Convert byte strings to unicode strings\n    raw_lines = _bytes_to_str(raw_lines)\n\n    try:\n        # Read the header count\n        header_count = _extract_header_number(raw_lines)\n\n        # Read the header dict\n        headers = _parse_header(raw_lines)\n\n        # Read the model\n        model = _extract_model(headers)\n\n        # Read the column names, if available\n        column_names = _extract_column_names(headers)\n\n        # Assemble the data\n        data_lines = _join_data_lines(raw_lines, header_count)\n\n        # Put together new IO\n        odf_string_io = io.StringIO(data_lines)\n\n        # Load the ODF file into a DataFrame\n        df = pd.read_csv(odf_string_io, sep='\\t', header=None, names=column_names, skip_blank_lines=True)\n\n        # Apply backwards compatible methods\n        _apply_backwards_compatibility(df)\n\n        # Apply ODF-specific properties\n        _apply_odf_properties(df, headers, model)\n\n        # Return the Dataframe\n        return df\n\n    # Catch any errors related to parsing the ODF file\n    except Exception:\n        raise TypeError('Error parsing ODF file')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting the provided DataFrame to a ODF file.", "response": "def write_odf(df, file_path, headers=None):\n    \"\"\"\n    Writes the provided DataFrame to a ODF file.\n\n    Assumes that the DataFrame matches the structure of those produced\n    by the ODF() function in this library\n\n    :param df: the DataFrame to write to ODF\n    :param file_path: path to which to write the ODF file\n    :param headers: A dict of ODF headers, if none are provided will attempt to read them from the ODF file\n    :return:\n    \"\"\"\n    if headers is None and hasattr(df, 'headers'):\n        headers = df.headers\n    else:\n        raise AttributeError('ODF headers not provided')\n\n    with open(file_path, 'w') as file:\n        file.write(_header_dict_to_str(headers))\n        df.to_csv(file, sep='\\t', header=False, index=False, mode='w+')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites the provided DataFrame to a GCT file.", "response": "def write_gct(df, file_path):\n    \"\"\"\n    Writes the provided DataFrame to a GCT file.\n\n    Assumes that the DataFrame matches the structure of those produced\n    by the GCT() function in this library\n\n    :param df:\n    :param file_path:\n    :return:\n    \"\"\"\n    with open(file_path, 'w') as file:\n        file.write('#1.2\\n' + str(len(df.index)) + '\\t' + str(len(df.columns)) + '\\n')\n        df.to_csv(file, sep='\\t', mode='w+')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _is_url(url):\n    regex = re.compile(\n        r'^(?:http|ftp)s?://'  # http:// or https://\n        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?)|'  # domain...\n        r'localhost|'  # localhost...\n        r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})'  # ...or ip\n        r'(?::\\d+)?'  # optional port\n        r'(?:/?|[/?]\\S+)$', re.IGNORECASE)\n    if regex.match(url) is not None:\n        return True\n    else:\n        return False", "response": "Used to determine if a given string represents a URL\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nattaching properties to the Dataframe to make it backwards compatible with older versions of this library", "response": "def _apply_backwards_compatibility(df):\n    \"\"\"\n    Attach properties to the Dataframe to make it backwards compatible with older versions of this library\n\n    :param df: The dataframe to be modified\n    \"\"\"\n    df.row_count = types.MethodType(lambda self: len(self.index), df)\n    df.col_count = types.MethodType(lambda self: len(self.columns), df)\n    df.dataframe = df"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nattaches properties to the Dataframe to carry along the ODF metadata", "response": "def _apply_odf_properties(df, headers, model):\n    \"\"\"\n    Attach properties to the Dataframe to carry along ODF metadata\n\n    :param df: The dataframe to be modified\n    :param headers: The ODF header lines\n    :param model: The ODF model type\n    \"\"\"\n    df.headers = headers\n    df.model = model"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert all lines from byte string to unicode string if necessary", "response": "def _bytes_to_str(lines):\n    \"\"\"\n    Convert all lines from byte string to unicode string, if necessary\n    \"\"\"\n    if len(lines) >= 1 and hasattr(lines[0], 'decode'):\n        return [line.decode('utf-8') for line in lines]\n    else:\n        return lines"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _extract_header_value(line):\n\n    # Skip blank lines, returning None\n    if not line:\n        return None\n\n    # Attempt to split by equals sign\n    halves = line.split('=')\n    if len(halves) > 1:\n        key = halves[0].strip()\n        value = halves[1].strip()\n        return {key: value}\n\n    # Otherwise, attempt to split by colon\n    else:\n        halves = line.split(':')\n        key = halves[0].strip()\n        value = halves[1].strip()\n        return {key: value}", "response": "Extracts a key value pair from a header line in an ODF file\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _extract_header_number(lines):\n    pair = _extract_header_value(lines[1])\n    value_list = list(pair.values())\n    return int(value_list[0])", "response": "Extracts the number of header lines from the first line of the ODF file\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse the ODF header and return a dict of all key - value pairs.", "response": "def _parse_header(lines):\n    \"\"\"\n    Parse the ODF header and return a dict of all key / value pairs\n    \"\"\"\n    header_count = _extract_header_number(lines)\n    header_dict = {}\n    for i in range(2, header_count + 2):\n        pair = _extract_header_value(lines[i])\n\n        if not pair:  # Ignore empty strings\n            continue\n\n        header_dict.update(pair)\n    return header_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncounts the number of blank lines in the header", "response": "def count_header_blanks(lines, count):\n    \"\"\"\n    Count the number of blank lines in the header\n    \"\"\"\n    blanks = 0\n    for i in range(2, count + 2):\n        pair = _extract_header_value(lines[i])\n        if not pair:\n            blanks += 1\n    return blanks"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\njoining all the data lines into a byte string", "response": "def _join_data_lines(lines, skip):\n    \"\"\"\n    Join all the data lines into a byte string\n    \"\"\"\n    lines = list(map(str.strip, lines))\n    blank_lines = count_header_blanks(lines, skip)\n    body = lines[skip + blank_lines + 2:]\n    return '\\n'.join(body)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the main dataframe instance to rows that contains a stringContainsValue in a column", "response": "def contains(self, column, value):\n        \"\"\"\n        Set the main dataframe instance to rows that contains a string\n        value in a column\n        \"\"\"\n        df = self.df[self.df[column].str.contains(value) == True]\n        if df is None:\n            self.err(\"Can not select contained data\")\n            return\n        self.df = df"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the main dataframe instance to rows that do not contain a string value in a column", "response": "def ncontains(self, column, value):\n        \"\"\"\n        Set the main dataframe instance to rows that do not\n        contains a string value in a column\n        \"\"\"\n        df = self.df[self.df[column].str.contains(value) == False]\n        if df is None:\n            self.err(\"Can not select contained data\")\n            return\n        self.df = df"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the main dataframe to rows that have the exact string value in a column.", "response": "def exact(self, column, *values):\n        \"\"\"\n        Sets the main dataframe to rows that has the exact string\n        value in a column\n        \"\"\"\n        df = self._exact(column, *values)\n        if df is None:\n            self.err(\"Can not select exact data\")\n        self.df = df"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef exact_(self, column, *values):\n        df = self._exact(column, *values)\n        if df is None:\n            self.err(\"Can not select exact data\")\n        return self._duplicate_(df)", "response": "Returns a Dataswim instance with rows that have the exact string\n        value in a column."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef debug(self, s, level=2):\n        self.write(s, level=level, color='white')", "response": "Write a debug message."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef exception(self, s):\n        self.error(s)\n        type, value, tb = sys.exc_info()\n        self.writelines(traceback.format_stack(), 1)\n        self.writelines(traceback.format_tb(tb)[1:], 1)\n        self.writelines(traceback.format_exception_only(type, value), 1)", "response": "Write error message with traceback info."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting a message with indentation context and optional timestamp.", "response": "def write(self, s, level=0, color=None):\n        \"\"\"Write message with indentation, context and optional timestamp.\"\"\"\n        if level > self.level:\n            return\n        if self.timestamps:\n            timestamp = time.strftime(u'%H:%M:%S ')\n        else:\n            timestamp = u''\n        with lock:\n            if self.context:\n                self.stream.write(u'%s%s> ' % (timestamp, self.context))\n            elif self.context is None:\n                self.stream.write(u'%s%s> ' % (timestamp, get_threadname()))\n            self.stream.write(u'%s' % s, color=color)\n            try:\n                text_type = unicode\n            except NameError:\n                text_type = str\n            self.stream.write(text_type(os.linesep))\n            self.stream.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reorder_translation_formset_by_language_code(inline_admin_form):\n    lang_to_form = dict([(form.form.initial['language_id'], form)\n                         for form in inline_admin_form])\n    return [lang_to_form[language_code] for language_code in\n        get_language_code_list()]", "response": "Reorder the formset of multilingual model by language code."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef main():\n    parser.name('tinman')\n    parser.description(__desc__)\n\n    p = parser.get()\n    p.add_argument('-p', '--path',\n                   action='store',\n                   dest='path',\n                   help='Path to prepend to the Python system path')\n\n    helper.start(Controller)", "response": "Invoked by the script installed by setuptools."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninsert a base path into the sys. path list if one is specified in the configuration.", "response": "def insert_paths(self):\n        \"\"\"Inserts a base path into the sys.path list if one is specified in\n        the configuration.\n\n        \"\"\"\n        if self.args.path:\n            sys.path.insert(0, self.args.path)\n\n        if hasattr(self.config.application, config.PATHS):\n            if hasattr(self.config.application.paths, config.BASE):\n                sys.path.insert(0, self.config.application.paths.base)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef process(self):\n        children = len(self.living_children)\n        LOGGER.debug('%i active child%s',\n                     children, '' if children == 1 else 'ren')", "response": "Check up on child processes and make sure everything is running as\n        it should be."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the list of ports to spawn", "response": "def ports_to_spawn(self):\n        \"\"\"Return the list of ports to spawn\n\n        :rtype: list\n\n        \"\"\"\n        return (self.config.get(config.HTTP_SERVER, dict()).get(config.PORTS)\n                or self.DEFAULT_PORTS)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_base_path(self, value):\n        if config.PATHS not in self.config.application:\n            self.config.application[config.PATHS] = dict()\n\n        if config.BASE not in self.config.application[config.PATHS]:\n            self.config.application[config.PATHS][config.BASE] = value", "response": "Munge in the base path into the configuration values\n\n           "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef setup(self):\n        LOGGER.info('Tinman v%s starting up with Tornado v%s',\n                    __version__, tornado_version)\n        # Setup debugging and paths\n        self.enable_debug()\n        self.set_base_path(os.getcwd())\n        self.insert_paths()\n\n        # Setup child processes\n        self.children = list()\n        self.manager = multiprocessing.Manager()\n        self.namespace = self.manager.Namespace()\n        self.namespace.args = self.args\n        self.namespace.config = dict(self.config.application)\n        self.namespace.logging = self.config.logging\n        self.namespace.debug = self.debug\n        self.namespace.routes = self.config.get(config.ROUTES)\n        self.namespace.server = self.config.get(config.HTTP_SERVER)\n        self.spawn_processes()", "response": "Setup the internal state of the thread."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef shutdown(self):\n        self.signal_children(signal.SIGABRT)\n\n        # Wait a few iterations when trying to stop children before terminating\n        waiting = 0\n        while self.living_children:\n            time.sleep(0.5)\n            waiting += 1\n            if waiting == self.MAX_SHUTDOWN_WAIT:\n                self.signal_children(signal.SIGKILL)\n                break", "response": "Send SIGABRT to child processes to instruct them to stop"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsends a signal to all children", "response": "def signal_children(self, signum):\n        \"\"\"Send a signal to all children\n\n        :param int signum: The signal to send\n\n        \"\"\"\n        LOGGER.info('Sending signal %i to children', signum)\n        for child in self.living_children:\n            if child.pid != os.getpid():\n                os.kill(child.pid, signum)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef spawn_process(self, port):\n        return process.Process(name=\"ServerProcess.%i\" % port,\n                               kwargs={'namespace': self.namespace,\n                                       'port': port})", "response": "Create a process that will listen on the given port."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef spawn_processes(self):\n        for port in self.ports_to_spawn:\n            process = self.spawn_process(port)\n            process.start()\n            self.children.append(process)", "response": "Spawn the appropriate number of application processes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef snake_to_camel(value):\n    camel = \"\".join(word.title() for word in value.split(\"_\"))\n    return value[:1].lower() + camel[1:]", "response": "Converts a snake_case_string to a camelCaseString."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting all rows values for a table", "response": "def getall(self, table):\n        \"\"\"\n        Get all rows values for a table\n        \"\"\"\n        try:\n            self._check_db()\n        except Exception as e:\n            self.err(e, \"Can not connect to database\")\n            return\n        if table not in self.db.tables:\n            self.warning(\"The table \" + table + \" does not exists\")\n            return\n        try:\n            res = self.db[table].all()\n            df = pd.DataFrame(list(res))\n            return df\n        except Exception as e:\n            self.err(e, \"Error retrieving data in table\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a diff column to the main dataframe", "response": "def diffn(self, diffcol: str, name: str=\"Diff\"):\n        \"\"\"\n        Add a diff column to the main dataframe: calculate the diff\n        from the next value\n\n        :param diffcol: column to diff from\n        :type diffcol: str\n        :param name: diff column name, defaults to \"Diff\"\n        :type name: str, optional\n\n        :example: ``ds.diffn(\"Col 1\", \"New col\")``\n        \"\"\"\n        try:\n            vals = []\n            i = 0\n            for _, row in self.df.iterrows():\n                current = row[diffcol]\n                try:\n                    nextv = self.df[diffcol].iloc[i + 1]\n                except Exception:\n                    vals.append(nan)\n                    continue\n                val = nextv - current\n                vals.append(round(val, 1))\n                i += 1\n            self.add(\"Diff\", vals)\n        except Exception as e:\n            self.err(e, self._append, \"Can not diff column\")\n            return\n        self.ok(\"Diff column \" + name + \" added to the dataframe\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a diff column to the main dataframe", "response": "def diffp(self, diffcol: str, name: str=\"Diff\"):\n        \"\"\"\n        Add a diff column to the main dataframe: calculate the diff\n        from the previous value\n\n        :param diffcol: column to diff from\n        :type diffcol: str\n        :param name: diff column name, defaults to \"Diff\"\n        :type name: str, optional\n\n        :example: ``ds.diffp(\"Col 1\", \"New col\")``\n        \"\"\"\n        try:\n            df = self.df.copy()\n            previous = 0\n            i = 0\n            vals = [df[diffcol].iloc[0]]\n            for _, row in df.iterrows():\n                val = row[diffcol] - previous\n                new = round(val, 1)\n                previous = row[diffcol]\n                if i == 0:\n                    vals = [0]\n                else:\n                    vals.append(new)\n                i = 1\n            self.df = df\n            self.add(name, vals)\n        except Exception as e:\n            self.err(e, self._append, \"Can not diff column\")\n            return\n        self.ok(\"Diff column \" + name + \" added to the dataframe\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a diff column to the main dataframe", "response": "def diffm(self, diffcol: str, name: str=\"Diff\", default=nan):\n        \"\"\"\n        Add a diff column to the main dataframe: calculate the\n        diff from the column mean\n\n        :param diffcol: column to diff from\n        :type diffcol: str\n        :param name: diff column name, defaults to \"Diff\"\n        :param name: str, optional\n        :param default: column default value, defaults to nan\n        :param default: optional\n\n        :example: ``ds.diffm(\"Col 1\", \"New col\")``\n        \"\"\"\n        try:\n            df = self.df.copy()\n            mean = self.df[diffcol].mean()\n            vals = []\n            for _, row in self.df.iterrows():\n                num = row[diffcol]\n                if num > 0:\n                    diff = int(((num - mean) * 100) / mean)\n                    vals.append(diff)\n                else:\n                    vals.append(default)\n            self.df = df\n            self.add(name, vals)\n        except Exception as e:\n            self.err(e, self._append, \"Can not diff column\")\n            return\n        self.ok(\"Diff column \" + name + \" added to the dataframe\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef diffsp(self, col: str, serie: \"iterable\", name: str=\"Diff\"):\n        try:\n            d = []\n            for i, row in self.df.iterrows():\n                v = (row[col]*100) / serie[i]\n                d.append(v)\n            self.df[name] = d\n        except Exception as e:\n            self.err(e, self._append, \"Can not diff column from serie\")", "response": "Add a diff column in percentage from a serie."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a new Ds object with the mean value of a column.", "response": "def gmean_(self, col: str, index_col: bool=True) -> \"Ds\":\n        \"\"\"\n        Group by and mean column\n\n        :param col: column to group\n        :type col: str\n        :param index_col: \n        :type index_col: bool\n        :return: a dataswim instance\n        :rtype: Ds\n\n        :example: ``ds2 = ds.gmean(\"Col 1\")``\n        \"\"\"\n        try:\n            df = self.df.copy()\n            df = df.groupby([col]).mean()\n            if index_col is True:\n                df[col] = df.index.values\n            return self._duplicate_(df)\n        except Exception as e:\n            self.err(e, self.gmean_, \"Can not meansum column\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef gsum_(self, col: str, index_col: bool=True) -> \"Ds\":\n        try:\n            df = self.df.copy()\n            df = df.groupby([col]).sum()\n            if index_col is True:\n                df[col] = df.index.values\n            return self._duplicate_(df)\n        except Exception as e:\n            self.err(e, self.gsum_, \"Can not groupsum column\")", "response": "Group by and sum column by column and return a new instance"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ratio(self, col: str, ratio_col: str=\"Ratio\"):\n        try:\n            df = self.df.copy()\n            df[ratio_col] = df[[col]].apply(\n                lambda x: 100 * x / float(x.sum()))\n            self.df = df\n        except Exception as e:\n            self.err(e, self.ratio, \"Can not calculate ratio\")", "response": "Add a column whith the percentages ratio from a column\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the values of the model based upon the content of the passed in dictionary.", "response": "def from_dict(self, value):\n        \"\"\"Set the values of the model based upon the content of the passed in\n        dictionary.\n\n        :param dict value: The dictionary of values to assign to this model\n\n        \"\"\"\n        for key in self.keys():\n            setattr(self, key, value.get(key, None))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a sha1 hash of the model items.", "response": "def sha1(self):\n        \"\"\"Return a sha1 hash of the model items.\n\n        :rtype: str\n\n        \"\"\"\n        sha1 = hashlib.sha1(''.join(['%s:%s' % (k,v) for k,v in self.items()]))\n        return str(sha1.hexdigest())"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete(self):\n        result = gen.Task(self._redis_client.delete, self._key)\n        raise gen.Return(bool(result))", "response": "Delete the item from storage\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfetch the data for the model from Redis and assign the values.", "response": "def fetch(self):\n        \"\"\"Fetch the data for the model from Redis and assign the values.\n\n        :rtype: bool\n\n        \"\"\"\n        raw = yield gen.Task(self._redis_client.get, self._key)\n        if raw:\n            self.loads(base64.b64decode(raw))\n            raise gen.Return(True)\n        raise gen.Return(False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstores the model in Redis.", "response": "def save(self):\n        \"\"\"Store the model in Redis.\n\n        :rtype: bool\n\n        \"\"\"\n        pipeline = self._redis_client.pipeline()\n        pipeline.set(self._key, base64.b64encode(self.dumps()))\n        if self._ttl:\n            pipeline.expire(self._key, self._ttl)\n        result = yield gen.Task(pipeline.execute)\n        self._dirty, self._saved = not all(result), all(result)\n        raise gen.Return(all(result))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef multilingual(request):\n    codes = sorted(get_language_code_list())\n    return {'LANGUAGE_CODES': codes,\n            'LANGUAGE_CODES_AND_NAMES': [(c, LANG_DICT.get(c, c)) for c in codes], \n            'DEFAULT_LANGUAGE_CODE': get_default_language_code(),\n            'ADMIN_MEDIA_URL': settings.ADMIN_MEDIA_PREFIX}", "response": "Returns context variables containing information about available languages."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing one search result page.", "response": "def handle_url(url, session, res):\n    \"\"\"Parse one search result page.\"\"\"\n    print(\"Parsing\", url, file=sys.stderr)\n    try:\n        data = getPageContent(url, session)\n    except IOError as msg:\n        print(\"ERROR:\", msg, file=sys.stderr)\n        return\n    for match in url_matcher.finditer(data):\n        url = match.group(1) + '/'\n        name = unescape(match.group(2))\n        name = asciify(name.replace('&', 'And').replace('@', 'At'))\n        name = capfirst(name)\n        if name in exclude_comics:\n            continue\n        if contains_case_insensitive(res, name):\n            # we cannot handle two comics that only differ in case\n            print(\"INFO: skipping possible duplicate\", repr(name), file=sys.stderr)\n            continue\n        # find out how many images this comic has\n        end = match.end()\n        mo = num_matcher.search(data[end:])\n        if not mo:\n            print(\"ERROR:\", repr(data[end:end+300]), file=sys.stderr)\n            continue\n        num = int(mo.group(1))\n        url = url_overrides.get(name, url)\n        try:\n            if \"/d/\" not in url:\n                check_robotstxt(url+\"d/\", session)\n            else:\n                check_robotstxt(url, session)\n        except IOError:\n            print(\"INFO: robots.txt denied for comicgenesis\", repr(name))\n            continue\n        else:\n            res[name] = (url, num)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if comic name already exists.", "response": "def has_comic(name):\n    \"\"\"Check if comic name already exists.\"\"\"\n    names = [\n        (\"Creators/%s\" % name).lower(),\n        (\"GoComics/%s\" % name).lower(),\n    ]\n    for scraperclass in get_scraperclasses():\n        lname = scraperclass.getName().lower()\n        if lname in names:\n            return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef perform_exit():\n    if SPLUNK_DEBUG:\n        print('{} -------------------------------'.format(\n            rnow()))\n        print('{} splunkpub: atexit.register - start'.format(\n            rnow()))\n    worked = True\n    for instance in instances:\n        try:\n            if SPLUNK_DEBUG:\n                print('{} - shutting down instance={} - start'.format(\n                    rnow(),\n                    instance))\n            instance.shutdown()\n            if SPLUNK_DEBUG:\n                print('{} - shutting down instance={} - done'.format(\n                    rnow(),\n                    instance))\n        except Exception as e:\n            worked = False\n            if SPLUNK_DEBUG:\n                print(\n                    '{} - shutting down instance={} '\n                    '- hit ex={} during shutdown'.format(\n                        rnow(),\n                        instance,\n                        e))\n        # end of try/ex\n    if not worked:\n        if SPLUNK_DEBUG:\n            print('{} Failed exiting'.format(\n                rnow()))\n    if SPLUNK_DEBUG:\n        print('{} splunkpub: atexit.register - done'.format(\n            rnow()))\n        print('{} -------------------------------'.format(\n            rnow()))", "response": "Perform the exit of the\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nforcing flush the current state of the current node.", "response": "def force_flush():\n    \"\"\"force_flush\"\"\"\n    if SPLUNK_DEBUG:\n        print('{} -------------------------------'.format(\n            rnow()))\n        print('{} splunkpub: force_flush - start'.format(\n            rnow()))\n    worked = True\n    for instance in instances:\n        try:\n            instance.force_flush()\n        except Exception as e:\n            worked = False\n            if SPLUNK_DEBUG:\n                print(\n                    '{} - force_flush instance={} '\n                    '- hit ex={}'.format(\n                        rnow(),\n                        instance,\n                        e))\n        # end of try/ex\n    if not worked:\n        if SPLUNK_DEBUG:\n            print('{} Failed flushing queues'.format(\n                rnow()))\n    if SPLUNK_DEBUG:\n        print('{} splunkpub: force_flush - done'.format(\n            rnow()))\n        print('{} -------------------------------'.format(\n            rnow()))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nemitting a log message to Splunk.", "response": "def emit(\n            self,\n            record):\n        \"\"\"emit\n\n        Emit handler for queue-ing message for\n        the helper thread to send to Splunk on the ``sleep_interval``\n\n        :param record: LogRecord to send to Splunk\n                       https://docs.python.org/3/library/logging.html\n        \"\"\"\n\n        self.debug_log('emit')\n\n        try:\n            record = self.format_record(\n                record)\n        except Exception as e:\n            self.write_log(\n                'Exception in Splunk logging handler={}'.format(e))\n            self.write_log(\n                traceback.format_exc())\n            return\n\n        if self.sleep_interval > 0:\n            try:\n                self.debug_log('put in queue')\n                # Put log message into queue; worker thread will pick up\n                self.queue.put_nowait(\n                    record)\n            except Exception as e:\n                self.write_log(\n                    'log queue full - log data will be dropped.')\n        else:\n            # Flush log immediately; is blocking call\n            self.publish_to_splunk(\n                payload=record)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstart the helper worker thread to publish queued messages to Splunk", "response": "def start_worker_thread(\n            self,\n            sleep_interval=1.0):\n        \"\"\"start_worker_thread\n\n        Start the helper worker thread to publish queued messages\n        to Splunk\n\n        :param sleep_interval: sleep in seconds before reading from\n                               the queue again\n        \"\"\"\n        # Start a worker thread responsible for sending logs\n        if self.sleep_interval > 0:\n            self.debug_log(\n                'starting worker thread')\n            self.timer = Timer(\n                sleep_interval,\n                self.perform_work)\n            self.timer.daemon = True  # Auto-kill thread if main process exits\n            self.timer.start()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef perform_work(\n            self):\n        \"\"\"perform_work\n\n        Process handler function for processing messages\n        found in the ``multiprocessing.Manager.queue``\n\n        Build the ``self.log_payload`` from the queued log messages\n        and POST it to the Splunk endpoint\n\n        \"\"\"\n\n        self.debug_log((\n            'perform_work - start'))\n\n        self.tid = threading.current_thread().ident\n\n        if self.sleep_interval > 0:\n            # Stop the timer. Happens automatically if this is called\n            # via the timer, does not if invoked by force_flush()\n            if self.timer:\n                self.timer.cancel()\n            else:\n                self.debug_log((\n                    'perform_work - done - timer was destroyed'))\n                return\n\n        self.debug_log((\n            'perform_work - ready tid={}').format(\n                self.tid))\n\n        try:\n\n            not_done = not self.is_shutting_down(\n                shutdown_event=self.shutdown_event)\n\n            while not_done:\n\n                try:\n                    self.build_payload_from_queued_messages(\n                        use_queue=self.queue,\n                        shutdown_event=self.shutdown_event)\n                except Exception as e:\n                    if self.is_shutting_down(\n                            shutdown_event=self.shutdown_event):\n                        self.debug_log(\n                            'perform_work - done - detected shutdown')\n                    else:\n                        self.debug_log((\n                            'perform_work - done - '\n                            'Exception shutting down with ex={}').format(\n                                e))\n                        self.shutdown()\n                    self.already_done.set()\n                    return\n                # end of try to return if the queue\n\n                self.publish_to_splunk()\n                timer_interval = self.sleep_interval\n\n                if not_done:\n                    if self.is_shutting_down(\n                            shutdown_event=self.shutdown_event):\n                        self.debug_log(\n                            'perform_work - done - shutdown detected')\n                        self.already_done.set()\n                        return\n                    # check if done\n                    else:\n                        if self.num_sent > 0:\n                            # run again if queue was not cleared\n                            timer_interval = 0.5\n                            self.debug_log(\n                                'queue not empty - run again')\n                        else:\n                            self.debug_log(\n                                'sleep={}s'.format(\n                                    timer_interval))\n                        time.sleep(timer_interval)\n                # end of checking if this should run again or is shutting down\n\n            # end of while not done\n\n        except Exception as e:\n            if self.is_shutting_down(\n                    shutdown_event=self.shutdown_event):\n                self.debug_log((\n                    'perform_work - shutdown sent={}').format(\n                        self.num_sent))\n            else:\n                self.debug_log((\n                    'perform_work - ex={}').format(\n                        e))\n        # end of try/ex\n\n        self.already_done.set()\n\n        self.debug_log((\n            'EXIT - perform_work - done - tid={}').format(\n                self.tid))", "response": "This function is called by the process_queue method to process the queued log messages in the queue and sends the log payload to the Splunk endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npublish the message to Splunk", "response": "def publish_to_splunk(\n            self,\n            payload=None):\n        \"\"\"publish_to_splunk\n\n        Build the ``self.log_payload`` from the queued log messages\n        and POST it to the Splunk endpoint\n\n        :param payload: string message to send to Splunk\n        \"\"\"\n        self.debug_log('publish_to_splunk - start')\n\n        use_payload = payload\n        if not use_payload:\n            use_payload = self.log_payload\n\n        self.num_sent = 0\n\n        if use_payload:\n            url = 'https://{}:{}/services/collector'.format(\n                self.host,\n                self.port)\n            self.debug_log('splunk url={}'.format(\n                url))\n\n            try:\n                if self.debug:\n                    try:\n                        msg_dict = json.loads(use_payload)\n                        event_data = json.loads(msg_dict['event'])\n                        msg_dict['event'] = event_data\n                        self.debug_log((\n                            'sending payload: {}').format(\n                                ppj(msg_dict)))\n                    except Exception:\n                        self.debug_log((\n                            'sending data payload: {}').format(\n                                use_payload))\n                if self.num_sent > 100000:\n                    self.num_sent = 1\n                else:\n                    self.num_sent += 1\n                send_to_splunk.send_to_splunk(\n                    session=self.session,\n                    url=url,\n                    data=use_payload,\n                    headers={'Authorization': 'Splunk {}'.format(\n                        self.token)},\n                    verify=self.verify,\n                    timeout=self.timeout)\n                self.debug_log('payload sent success')\n            except Exception as e:\n                try:\n                    self.write_log(\n                        'Exception in Splunk logging handler: {}'.format(\n                            e))\n                    self.write_log(traceback.format_exc())\n                except Exception:\n                    self.debug_log(\n                        'Exception encountered,'\n                        'but traceback could not be formatted')\n\n            self.log_payload = ''\n        else:\n            self.debug_log(\n                'no logs to send')\n\n        self.debug_log((\n            'publish_to_splunk - done - '\n            'self.is_shutting_down={} self.shutdown_now={}').format(\n                self.is_shutting_down(shutdown_event=self.shutdown_event),\n                self.shutdown_now))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if the parent is shutting down or False otherwise.", "response": "def is_shutting_down(\n            self,\n            shutdown_event):\n        \"\"\"is_shutting_down\n\n        Determine if the parent is shutting down or this was\n        triggered to shutdown\n\n        :param shutdown_event: shutdown event\n        \"\"\"\n\n        return bool(\n            shutdown_event.is_set()\n            or self.shutdown_now\n            or self.run_once)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef close(\n            self):\n        \"\"\"close\"\"\"\n        self.debug_log('close - start')\n        self.shutdown()\n        logging.Handler.close(self)\n        self.debug_log('close - done')", "response": "close the object and shutdown the logging handler."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef shutdown(\n            self):\n        \"\"\"shutdown\"\"\"\n        self.debug_log('shutdown - start')\n\n        # Only initiate shutdown once\n        if not self.shutdown_now:\n            self.debug_log('shutdown - still shutting down')\n            # Cancels the scheduled Timer, allows exit immediately\n            if self.timer:\n                self.timer.cancel()\n                self.timer = None\n            return\n        else:\n            self.debug_log('shutdown - start - setting instance shutdown')\n            self.shutdown_now = True\n            self.shutdown_event.set()\n        # if/else already shutting down\n\n        # Cancels the scheduled Timer, allows exit immediately\n        self.timer.cancel()\n        self.timer = None\n\n        self.debug_log(\n            'shutdown - publishing remaining logs')\n\n        if self.sleep_interval > 0:\n            try:\n                self.build_payload_from_queued_messages(\n                    use_queue=self.queue,\n                    shutdown_event=self.shutdown_event,\n                    triggered_by_shutdown=True)\n            except Exception as e:\n                self.write_log((\n                    'shutdown - failed to build a payload for remaining '\n                    'messages in queue Exception shutting down '\n                    'with ex={}').format(\n                    e))\n\n            self.debug_log(\n                'publishing remaining logs')\n\n            # Send the remaining items in the queue\n            self.publish_to_splunk()\n        # end of try to publish remaining messages in the queue\n        # during shutdown\n\n        self.debug_log('shutdown - done')", "response": "This method is called by the instance shutdown method. It is called by the instance shutdown method when the instance is shut down."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _statsd_address(self):\n        return (self.application.settings.get('statsd',\n                                              {}).get('host',\n                                                      self.STATSD_HOST),\n                self.application.settings.get('statsd',\n                                              {}).get('port',\n                                                      self.STATSD_PORT))", "response": "Return a tuple of host and port for the statsd server to send\n        stats to."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninvoke once the request has been finished. Increment a counter created in the format of package [. module. Class. METHOD. STATUS tornado. web. RequestHandler. GET. 200.", "response": "def on_finish(self):\n        \"\"\"Invoked once the request has been finished. Increment a counter\n        created in the format:\n\n            package[.module].Class.METHOD.STATUS\n            tornado.web.RequestHandler.GET.200\n\n        \"\"\"\n        super(StatsdMixin, self).on_finish()\n        key = '%s.%s.%s.%s' % (self.__module__,\n                               self.__class__.__name__,\n                               self.request.method, self._status_code)\n        LOGGER.info('Processing %s', key)\n        self.statsd_incr(key)\n        self.statsd_add_timing(key, self.request.request_time() * 1000)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _new_redis_client(self):\n        if 'tornadoredis' not in globals():\n            import tornadoredis\n        kwargs = self._redis_connection_settings()\n        LOGGER.info('Connecting to %(host)s:%(port)s DB %(selected_db)s',\n                    kwargs)\n        return tornadoredis.Client(**kwargs)", "response": "Create a new redis client and assign it the class _redis_client\n        attribute for reuse across requests."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a dictionary of redis connection settings.", "response": "def _redis_connection_settings(self):\n        \"\"\"Return a dictionary of redis connection settings.\n\n        \"\"\"\n        return {config.HOST: self.settings.get(config.HOST, self._REDIS_HOST),\n                config.PORT: self.settings.get(config.PORT, self._REDIS_PORT),\n                'selected_db': self.settings.get(config.DB, self._REDIS_DB)}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete(self, *args, **kwargs):\n        # Create the model and fetch its data\n        self.model = self.get_model(kwargs.get('id'))\n        result = yield self.model.fetch()\n\n        # If model is not found, return 404\n        if not result:\n            self.not_found()\n            return\n\n        # Stub to check for delete permissions\n        if not self.has_delete_permission():\n            self.permission_denied()\n            return\n\n        # Delete the model from its storage backend\n        self.model.delete()\n\n        # Set the status to request processed, no content returned\n        self.set_status(204)\n        self.finish()", "response": "Handle a delete of an item in the cache"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nhandling HEAD requests for the item", "response": "def head(self, *args, **kwargs):\n        \"\"\"Handle HEAD requests for the item\n\n        :param args:\n        :param kwargs:\n\n        \"\"\"\n        # Create the model and fetch its data\n        self.model = self.get_model(kwargs.get('id'))\n        result = yield self.model.fetch()\n\n        # If model is not found, return 404\n        if not result:\n            self.not_found()\n            return\n\n        # Stub to check for read permissions\n        if not self.has_read_permission():\n            self.permission_denied()\n            return\n\n        # Add the headers (etag, content-length), set the status\n        self.add_headers()\n        self.set_status(200)\n        self.finish()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(self, *args, **kwargs):\n        # Create the model and fetch its data\n        self.model = self.get_model(kwargs.get('id'))\n        result = yield self.model.fetch()\n\n        # If model is not found, return 404\n        if not result:\n            LOGGER.debug('Not found')\n            self.not_found()\n            return\n\n        # Stub to check for read permissions\n        if not self.has_read_permission():\n            LOGGER.debug('Permission denied')\n            self.permission_denied()\n            return\n\n        # Add the headers and return the content as JSON\n        self.add_headers()\n        self.finish(self.model_json())", "response": "Handle reading of the model and return the content as JSON"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhandles creation of an item.", "response": "def post(self, *args, **kwargs):\n        \"\"\"Handle creation of an item.\n\n        :param args:\n        :param kwargs:\n\n        \"\"\"\n        self.initialize_post()\n\n        # Don't allow the post if the poster does not have permission\n        if not self.has_create_permission():\n            LOGGER.debug('Does not have write_permission')\n            self.set_status(403, self.status_message('Creation Forbidden'))\n            self.finish()\n            return\n\n        result = yield self.model.save()\n        if result:\n            self.set_status(201, self.status_message('Created'))\n            self.add_headers()\n            self.finish(self.model.as_dict())\n        else:\n            self.set_status(507, self.status_message('Creation Failed'))\n            self.finish()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef put(self, *args, **kwargs):\n        self.initialize_put(kwargs.get('id'))\n\n        if not self.has_update_permission():\n            self.set_status(403, self.status_message('Creation Forbidden'))\n            self.finish()\n            return\n\n        for key, value in self.model.items():\n            if self.json_arguments.get(key) != value:\n                self.model.set(key, self.json_arguments.get(key))\n\n        if not self.model.dirty:\n            self.set_status(431, self.status_message('No changes made'))\n            self.finish(self.model.as_dict())\n            return\n\n        result = yield self.model.save()\n        if result:\n            self.set_status(200, self.status_message('Updated'))\n        else:\n            self.set_status(507, self.status_message('Update Failed'))\n        self.add_headers()\n        self.finish(self.model.as_dict())", "response": "Handle an update of an item."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninitialize the object with the current model and the json_arguments.", "response": "def initialize_post(self):\n        \"\"\"Invoked by the ModelAPIRequestHandler.post method prior to taking\n        any action.\n\n        \"\"\"\n        self.model = self.get_model()\n        for key in self.model.keys():\n            self.model.set(key, self.json_arguments.get(key))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\napplying the self. categorical_mappings_ mappings where necessary.", "response": "def _convert_nonstring_categoricals(self, param_dict):\n        \"\"\"Apply the self.categorical_mappings_ mappings where necessary.\"\"\"\n        return {name: (self.categorical_mappings_[name][val] if name in self.categorical_mappings_ else val)\n                for (name, val) in param_dict.items()}"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns fit on the estimator with parameters chosen sequentially by SigOpt.", "response": "def fit(self, X, y=None, groups=None, **fit_params):\n        \"\"\"\n        Run fit on the estimator with parameters chosen sequentially by SigOpt.\n        Parameters\n        ----------\n        X : array-like, shape = [n_samples, n_features]\n            Training vector, where n_samples in the number of samples and\n            n_features is the number of features.\n        y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n            Target relative to X for classification or regression;\n            None for unsupervised learning.\n        \"\"\"\n        return self._fit(X, y=y, groups=groups, **fit_params)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconfiguring the Vyked Registry and Pubsub endpoints for the current process.", "response": "def configure(cls, name, registry_host: str=\"0.0.0.0\", registry_port: int=4500,\n                  pubsub_host: str=\"0.0.0.0\", pubsub_port: int=6379):\n        \"\"\" A convenience method for providing registry and pubsub(redis) endpoints\n\n        :param name: Used for process name\n        :param registry_host: IP Address for vyked-registry; default = 0.0.0.0\n        :param registry_port: Port for vyked-registry; default = 4500\n        :param pubsub_host: IP Address for pubsub component, usually redis; default = 0.0.0.0\n        :param pubsub_port: Port for pubsub component; default= 6379\n        :return: None\n        \"\"\"\n        Host.name = name\n        Host.registry_host = registry_host\n        Host.registry_port = registry_port\n        Host.pubsub_host = pubsub_host\n        Host.pubsub_port = pubsub_port"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef attach_service(cls, service):\n        invalid_service = True\n        _service_classes = {'_tcp_service': TCPService, '_http_service': HTTPService}\n        for key, value in _service_classes.items():\n            if isinstance(service, value):\n                cls._services[key] = service\n                invalid_service = False\n                break\n        if invalid_service:\n            cls._logger.error('Invalid argument attached as service')\n        cls._set_bus(service)", "response": "Allows you to attach one TCP or HTTP service to the class."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nattaches a service for hosting to the class.", "response": "def attach_http_service(cls, http_service: HTTPService):\n        \"\"\" Attaches a service for hosting\n        :param http_service: A HTTPService instance\n        \"\"\"\n        if cls._services['_http_service'] is None:\n            cls._services['_http_service'] = http_service\n            cls._set_bus(http_service)\n        else:\n            warnings.warn('HTTP service is already attached')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nattach a service for hosting to the class.", "response": "def attach_tcp_service(cls, tcp_service: TCPService):\n        \"\"\" Attaches a service for hosting\n        :param tcp_service: A TCPService instance\n        \"\"\"\n        if cls._services['_tcp_service'] is None:\n            cls._services['_tcp_service'] = tcp_service\n            cls._set_bus(tcp_service)\n        else:\n            warnings.warn('TCP service is already attached')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstarting serving attached services", "response": "def run(cls):\n        \"\"\" Fires up the event loop and starts serving attached services\n        \"\"\"\n        if not all(v is None for v in cls._services.values()):\n            cls._set_host_id()\n            cls._setup_logging()\n            cls._set_process_name()\n            cls._set_signal_handlers()\n            cls._start_server()\n        else:\n            cls._logger.error('No services to host')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete(self):\n        self.clear()\n        if os.path.isfile(self._filename):\n            os.unlink(self._filename)\n        else:\n            LOGGER.debug('Session file did not exist: %s', self._filename)", "response": "Extend to the delete the session from storage\nAttributeNames"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsaving the session for later retrieval", "response": "def save(self):\n        \"\"\"Save the session for later retrieval\n\n        :raises: IOError\n\n        \"\"\"\n        try:\n            with open(self._filename, 'wb') as session_file:\n                session_file.write(self.dumps())\n        except IOError as error:\n            LOGGER.error('Session file error: %s', error)\n            raise error"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove any stale files from the session storage directory", "response": "def _cleanup(self):\n        \"\"\"Remove any stale files from the session storage directory\"\"\"\n        for filename in os.listdir(self._storage_dir):\n            file_path = path.join(self._storage_dir, filename)\n            file_stat = os.stat(file_path)\n            evaluate = max(file_stat.st_ctime, file_stat.st_mtime)\n            if evaluate + self._duration < time.time():\n                LOGGER.debug('Removing stale file: %s', file_path)\n                os.unlink(file_path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _setup_storage_dir(self):\n        dir_path = self._settings.get(config.DIRECTORY)\n        if dir_path is None:\n            dir_path = self._default_path\n            if not os.path.exists(dir_path):\n                self._make_path(dir_path)\n        else:\n            dir_path = path.abspath(dir_path)\n            if not os.path.exists(dir_path) or not os.path.isdir(dir_path):\n                raise exceptions.ConfigurationException(self.__class__.__name__,\n                                                        config.DIRECTORY)\n        return dir_path.rstrip('/')", "response": "Setup the storage directory path value and ensure the path exists."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _redis_connect(cls, settings):\n        if 'tornadoredis' not in globals():\n            import tornadoredis\n        kwargs = {'host': settings.get('host', cls.REDIS_HOST),\n                  'port': settings.get('port', cls.REDIS_PORT),\n                  'selected_db': settings.get('db', cls.REDIS_DB)}\n        LOGGER.info('Connecting to %(host)s:%(port)s DB %(selected_db)s',\n                    kwargs)\n        cls._redis_client = tornadoredis.Client(**kwargs)\n        cls._redis_client.connect()", "response": "Connect to redis and assign the client to the class\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes the item from storage", "response": "def delete(self):\n        \"\"\"Delete the item from storage\n\n        :param method callback: The callback method to invoke when done\n\n        \"\"\"\n        result = yield gen.Task(RedisSession._redis_client.delete, self._key)\n        LOGGER.debug('Deleted session %s (%r)', self.id, result)\n        self.clear()\n        raise gen.Return(result)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfetching the data for the model from Redis and assign the values.", "response": "def fetch(self):\n        \"\"\"Fetch the data for the model from Redis and assign the values.\n\n        :param method callback: The callback method to invoke when done\n\n        \"\"\"\n        LOGGER.debug('Fetching session data: %s', self.id)\n        result = yield gen.Task(RedisSession._redis_client.get, self._key)\n        if result:\n            self.loads(result)\n            raise gen.Return(True)\n        else:\n            raise gen.Return(False)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstore the session data in redis", "response": "def save(self):\n        \"\"\"Store the session data in redis\n\n        :param method callback: The callback method to invoke when done\n\n        \"\"\"\n        result = yield gen.Task(RedisSession._redis_client.set,\n                                self._key, self.dumps())\n        LOGGER.debug('Saved session %s (%r)', self.id, result)\n        raise gen.Return(result)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload a template. :param str name: The template name :param str parent_path: The optional path for a parent document :rtype: tornado.template.Template", "response": "def load(self, name, parent_path=None):\n        \"\"\"Loads a template.\n\n        :param str name: The template name\n        :param str parent_path: The optional path for a parent document\n        :rtype: tornado.template.Template\n\n        \"\"\"\n        if name not in self.templates:\n            self.templates[name] = self._create_template(name)\n        return self.templates[name]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _create_template(self, name):\n        url = '%s/%s' % (self._base_url, escape.url_escape(name))\n        LOGGER.debug('Making HTTP GET request to %s', url)\n        response = self._http_client.fetch(url)\n        data = json.loads(response.body, ensure_ascii=False)\n        return template.Template(data['template'], name=name, loader=self)", "response": "Create an instance of tornado. template. Template object for the\n        given template name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef xcompile(source_code, args=0, optimize=True):\n    code = crianza.compile(crianza.parse(source_code), optimize=optimize)\n    return crianza.native.compile(code, args=args)", "response": "Parses Crianza source code and returns a native Python function."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef xeval(source, optimize=True):\n    native = xcompile(source, optimize=optimize)\n    return native()", "response": "Compiles to native Python bytecode and runs program returning the topmost value on the stack."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _ensure_parameters(self):\n\n        if hasattr(self, \"_parameters_checked\"):\n            return\n\n        if (\n            not hasattr(self.model, \"_cte_node_table\")\n            or self.model._cte_node_table is None\n        ):\n            setattr(self.model, \"_cte_node_table\", self.DEFAULT_TABLE_NAME)\n\n        if (\n            not hasattr(self.model, \"_cte_node_depth\")\n            or self.model._cte_node_depth is None\n        ):\n            setattr(self.model, \"_cte_node_depth\", self.VIRTUAL_FIELD_DEPTH)\n\n        if (\n            not hasattr(self.model, \"_cte_node_path\")\n            or self.model._cte_node_depth is None\n        ):\n            setattr(self.model, \"_cte_node_path\", self.VIRTUAL_FIELD_PATH)\n\n        if (\n            not hasattr(self.model, \"_cte_node_ordering\")\n            or self.model._cte_node_ordering is None\n        ):\n            setattr(self.model, \"_cte_node_ordering\", self.VIRTUAL_FIELD_ORDERING)\n\n        if (\n            not hasattr(self.model, \"_cte_node_traversal\")\n            or self.model._cte_node_traversal is None\n        ):\n            setattr(self.model, \"_cte_node_traversal\", self.DEFAULT_TREE_TRAVERSAL)\n\n        if (\n            not hasattr(self.model, \"_cte_node_children\")\n            or self.model._cte_node_children is None\n        ):\n            setattr(self.model, \"_cte_node_children\", self.DEFAULT_CHILDREN_NAME)\n\n        if not hasattr(self.model, \"_cte_node_primary_key_type\"):\n            setattr(self.model, \"_cte_node_primary_key_type\", None)\n\n        # Determine the parent foreign key field name, either\n        # explicitly specified, or the first foreign key to 'self'.\n        # If we need to determine, then we set the attribute for future\n        # reference.\n        if (\n            not hasattr(self.model, \"_cte_node_parent\")\n            or self.model._cte_node_parent is None\n        ):\n            found = False\n            for f in self.model._meta.fields:\n                if isinstance(f, ForeignKey):\n                    if f.remote_field.model == self.model:\n                        setattr(self.model, \"_cte_node_parent\", f.name)\n                        found = True\n            if not found:\n                raise ImproperlyConfigured(\n                    _(\n                        \"CTENode must have a Foreign Key to self for the parent \"\n                        \"relation.\"\n                    )\n                )\n\n        try:\n            parent_field = self.model._meta.get_field(self.model._cte_node_parent)\n        except FieldDoesNotExist:\n            raise ImproperlyConfigured(\n                \"\".join(\n                    [\n                        _(\n                            \"CTENode._cte_node_parent must specify a Foreign Key\"\n                            \" to self, instead it is: \"\n                        ),\n                        self.model._cte_node_parent,\n                    ]\n                )\n            )\n\n        # Ensure parent relation is a Foreign Key to self.\n        if not parent_field.remote_field.model == self.model:\n            raise ImproperlyConfigured(\n                \"\".join(\n                    [\n                        _(\n                            \"CTENode._cte_node_parent must specify a Foreign Key\"\n                            \" to self, instead it is: \"\n                        ),\n                        self.model._cte_node_parent,\n                    ]\n                )\n            )\n\n        # Record the parent field attribute name for future reference.\n        setattr(\n            self.model,\n            \"_cte_node_parent_attname\",\n            self.model._meta.get_field(self.model._cte_node_parent).attname,\n        )\n\n        # Ensure traversal choice is valid.\n        traversal_choices = [choice[0] for choice in self.TREE_TRAVERSAL_CHOICES]\n        if self.model._cte_node_traversal not in traversal_choices:\n            raise ImproperlyConfigured(\n                \" \".join(\n                    [\n                        \"CTENode._cte_node_traversal must be one of [\",\n                        \", \".join(traversal_choices),\n                        \"]; instead it is:\",\n                        self.model._cte_node_traversal,\n                    ]\n                )\n            )\n\n        # Ensure delete choice is valid.\n        if (\n            not hasattr(self.model, \"_cte_node_delete_method\")\n            or self.model._cte_node_delete_method is None\n        ):\n            setattr(self.model, \"_cte_node_delete_method\", self.DEFAULT_DELETE_METHOD)\n        else:\n            # Ensure specified method is valid.\n            method_choices = [dm[0] for dm in self.DELETE_METHOD_CHOICES]\n            if self.model._cte_node_delete_method not in method_choices:\n                raise ImproperlyConfigured(\n                    \" \".join(\n                        [\n                            \"delete method must be one of [\",\n                            \", \".join(method_choices),\n                            \"]; instead it is:\",\n                            self.model._cte_node_delete_method,\n                        ]\n                    )\n                )\n\n        setattr(self, \"_parameters_checked\", True)", "response": "Ensures that the parameters are set in the model."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _ensure_virtual_fields(self, node):\n        # Uses several _cte_node_* parameters, so ensure they exist.\n        self._ensure_parameters()\n        for vf in [\n            self.model._cte_node_depth,\n            self.model._cte_node_path,\n            self.model._cte_node_ordering,\n        ]:\n            if not hasattr(node, vf):\n                raise FieldError(\n                    _(\n                        \"CTENode objects must be loaded from the database before \"\n                        \"they can be used.\"\n                    )\n                )", "response": "Ensures that the virtual fields of the given node exist."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a custom : class:`QuerySet` which provides the CTENode objects for the given CTECOOKIE.", "response": "def get_queryset(self):\n        \"\"\" Returns a custom :class:`QuerySet` which provides the CTE\n            functionality for all queries concerning :class:`CTENode` objects.\n            This method overrides the default :meth:`get_queryset` method of\n            the :class:`Manager` class.\n\n            :returns: a custom :class:`QuerySet` which provides the CTE\n                functionality for all queries concerning :class:`CTENode`\n                objects.\n        \"\"\"\n        # The CTEQuerySet uses _cte_node_* attributes from the Model, so ensure\n        # they exist.\n        self._ensure_parameters()\n        return CTEQuerySet(self.model, using=self._db)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef leaves(self):\n        # We need to read the _cte_node_children attribute, so ensure it exists.\n        self._ensure_parameters()\n        return self.exclude(\n            **{\"%s__id__in\" % self.model._cte_node_children: self.all()}\n        )", "response": "Returns a QuerySet of all leaf nodes with no\n            children."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef branches(self):\n        # We need to read the _cte_node_children attribute, so ensure it exists.\n        self._ensure_parameters()\n        return self.filter(\n            **{\"%s__id__in\" % self.model._cte_node_children: self.all()}\n        ).distinct()", "response": "Returns a QuerySet of all branch nodes."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef root(self, node):\n        # We need to use the path virtual field, so ensure it exists.\n        self._ensure_virtual_fields(node)\n        return self.get(pk=getattr(node, self.model._cte_node_path)[0])", "response": "Returns the root node of the tree in which the given node participates."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a QuerySet of all siblings of a given CTENode.", "response": "def siblings(self, node):\n        \"\"\" Returns a :class:`QuerySet` of all siblings of a given\n            :class:`CTENode` `node`.\n\n            :param node: a :class:`CTENode` whose siblings are required.\n\n            :returns: A :class:`QuerySet` of all siblings of the given `node`.\n        \"\"\"\n        # We need to read the _cte_node_parent* attributes, so ensure they\n        # exist.\n        self._ensure_parameters()\n        # We need to construct: filter(parent = node.parent_id)\n        return self.filter(\n            **{\n                self.model._cte_node_parent: getattr(\n                    node, self.model._cte_node_parent_attname\n                )\n            }\n        ).exclude(id=node.id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a QuerySet of all ancestors of a given CTENode.", "response": "def ancestors(self, node):\n        \"\"\" Returns a :class:`QuerySet` of all ancestors of a given\n            :class:`CTENode` `node`.\n\n            :param node: A :class:`CTENode` whose ancestors are required.\n\n            :returns: A :class:`QuerySet` of all ancestors of the given `node`.\n        \"\"\"\n        # We need to use the path virtual field, so ensure it exists.\n        self._ensure_virtual_fields(node)\n        return self.filter(pk__in=getattr(node, self.model._cte_node_path)[:-1])"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a QuerySet that returns all descendants of a given CTENode.", "response": "def descendants(self, node):\n        \"\"\" Returns a :class:`QuerySet` with all descendants for a given\n            :class:`CTENode` `node`.\n\n            :param node: the :class:`CTENode` whose descendants are required.\n\n            :returns: A :class:`QuerySet` with all descendants of the given\n                `node`.\n        \"\"\"\n        # We need to read the _cte_node_* attributes, so ensure they exist.\n        self._ensure_parameters()\n        # This is implemented in the CTE WHERE logic, so we pass a reference to\n        # the offset CTENode to the custom QuerySet, which will process it.\n        # Because the compiler will include the node in question in the offset,\n        # we must exclude it here.\n        return CTEQuerySet(self.model, using=self._db, offset=node).exclude(pk=node.pk)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if the given node is a sibling of the given subject node False otherwise.", "response": "def is_sibling_of(self, node, subject):\n        \"\"\" Returns ``True`` if the given `node` is a sibling of the given\n            `subject` node, ``False`` otherwise. This method uses the\n            :attr:`parent` field, and so does not perform any query.\n\n            :param node: the :class:`CTENode' for which to determine whether it\n                is a sibling of the `subject`.\n\n            :param subject: the :class:`CTENode` for which to determine whether\n                one of its siblings is the `node`.\n\n            :returns: ``True`` if `node` is a sibling of `subject`, ``False``\n                otherwise.\n        \"\"\"\n        # Ensure nodes are not siblings of themselves.\n        return not node.id == subject.id and node.parent_id == subject.parent_id"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if the given node is an ancestor of the given subject node.", "response": "def is_ancestor_of(self, node, subject):\n        \"\"\" Returns ``True`` if the given `node` is an ancestor of the given\n            `subject` node, ``False`` otherwise. This method uses the\n            :attr:`path` virtual field, and so does not perform any query.\n\n            :param node: the :class:`CTENode' for which to determine whether it\n                is an ancestor of the `subject`.\n\n            :param subject: the :class:`CTENode` for which to determine whether\n                one of its ancestors is the `node`.\n\n            :returns: ``True`` if `node` is an ancestor of `subject`, ``False``\n                otherwise.\n        \"\"\"\n        # We will need to use the path virtual field, so ensure it exists.\n        self._ensure_virtual_fields(node)\n\n        # Convenience check so is_ancestor_of can be combined with methods\n        # returning nodes without the caller having to worry about a None\n        # subject.\n        if subject is None:\n            return False\n\n        # Optimization: a node will never be an ancestor of a root node.\n        if getattr(subject, subject._cte_node_depth) == 1:\n            return False\n\n        # The path will either be an index of primitives, or an encoding of an\n        # array.\n        if type(getattr(node, node._cte_node_path)) == list:\n            # We can slice with -1 because we know that depth > 1 from above.\n            return node.id in getattr(subject, subject._cte_node_path)[0:-1]\n        else:\n            # Search for node id up to the penultimate entry in the path of the\n            # subject, meaning we ignore the end of the path consisting of:\n            # a) the ending closing curly brace,\n            # b) the length of the subject id, and\n            # c) the separator character,\n            # therefore we look for a match ending at the length of the\n            # subject's id string plus two (so negative index length minus two).\n            _path = getattr(subject, subject._cte_node_path)\n            return _path[: -len(str(subject.id)) - 2].index(str(node.id)) > 0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating a list of values of the attribute of the given node and the given attribute.", "response": "def attribute_path(\n        self,\n        node,\n        attribute,\n        missing=None,\n        visitor=lambda node, attribute: getattr(node, attribute, None),\n    ):\n        \"\"\" Generates a list of values of the `attribute` of all ancestors of\n            the given `node` (as well as the node itself). If a value is\n            ``None``, then the optional value of `missing` is used (by default\n            ``None``).\n\n            By default, the ``getattr(node, attribute, None) or missing``\n            mechanism is used to obtain the value of the attribute for each\n            node. This can be overridden by supplying a custom `visitor`\n            function, which expects as arguments the node and the attribute, and\n            should return an appropriate value for the required attribute.\n\n            :param node: the :class:`CTENode` for which to generate the\n                attribute path.\n\n            :param attribute: the name of the attribute.\n\n            :param missing: optional value to use when attribute value is None.\n\n            :param visitor: optional function responsible for obtaining the\n                attribute value from a node.\n\n            :return: a list of values of the required `attribute` of the\n                ancestor path of the given `node`.\n        \"\"\"\n        return [visitor(c, attribute) or missing for c in node.ancestors()] + [\n            visitor(node, attribute) or missing\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef as_tree(self, visitor=None, children=None):\n        return [\n            root.as_tree(visitor=visitor, children=children) for root in self.roots()\n        ]", "response": "This method recursively traverses each tree and generates a dictionary representation of the tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef node_as_tree(\n        self,\n        node,\n        visitor=lambda self, node: self._default_node_visitor(node),\n        children=lambda self, node, visitor, children: self._default_node_children(\n            node, visitor, children\n        ),\n    ):\n        \"\"\" Visits a :class:`CTENode` `node` and delegates to the (optional)\n            `visitor` callback, as well as the (optional) `children` callback,\n            in order to generate a dictionary representation of the node along\n            with its children nodes.\n\n            :param node: the :class:`CTENode` for which to generate the\n                representation.\n\n            :param visitor: optional function responsible for generating the\n                dictionary representation of the node.\n\n            :param children: optional function responsible for generating a\n                children key and list for the node.\n\n            :return: a dictionary representation of the structure of the node\n                and its descendant tree.\n        \"\"\"\n        tree = visitor(self, node)\n        tree.update(children(self, node, visitor, children))\n        return tree", "response": "Returns a dictionary representation of the node as a tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _default_node_visitor(self, node):\n        return {\n            \"depth\": getattr(node, node._cte_node_depth),\n            \"path\": [str(c) for c in getattr(node, node._cte_node_path)],\n            \"ordering\": getattr(node, node._cte_node_ordering),\n            \"leaf\": node.is_leaf(),\n            \"branch\": node.is_branch(),\n            \"node\": node,\n        }", "response": "Generates a dictionary representation of the given :class:`CTENode`\n        `node`, which consists of the node itself under the key ``node``, as\n        well as structural information under the keys ``depth``, ``path``,\n        ``ordering``, ``leaf``, and ``branch``.\n\n        :param node: the :class:`CTENode` for which to generate the\n            representation.\n\n        :return: a dictionary representation of the structure of the node."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _default_node_children(self, node, visitor, children):\n        return {\n            self.model._cte_node_children: [\n                self.node_as_tree(child, visitor=visitor, children=children)\n                for child in node.children.all()\n            ]\n        }", "response": "Generate a key and list of children of the given node."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef drilldown(self, attributes, path):\n\n        # empty path result in first root, if present\n        if len(path) == 0:\n            try:\n                return self.roots()[0]\n            except IndexError:\n                raise self.model.DoesNotExist\n\n        # bootstrap with the first component, then iterate through the remaining\n        # components in the path as long as each child node is found\n        component = path[0]\n        current = None\n\n        # mapping of attribute names with values, as per QuerySet filter\n        def attrs(component):\n            return dict(zip(attributes, component))\n\n        # find the root corresponding to the bootstrapped initial path component\n        try:\n            root = self.roots().filter(**attrs(component))[0]\n        except IndexError:\n            raise self.model.DoesNotExist\n\n        # proceed to drill down until path components are exhausted\n        current = root\n        for component in path[1:]:\n            try:\n                current = current.children.filter(**attrs(component))[0]\n            except IndexError:\n                raise self.model.DoesNotExist\n        return current", "response": "This method recursively descends the tree and forests of the given path and returns the tree node which corresponds to the given path."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npreparing a given node for deletion by executing the appropriate delete methods.", "response": "def prepare_delete(self, node, method, position=None, save=True):\n        \"\"\" Prepares a given :class:`CTENode` `node` for deletion, by executing\n            the required deletion semantics (Pharaoh, Grandmother, or Monarchy).\n\n            The `method` argument can be one of the valid\n            :const:`DELETE_METHODS` choices. If it is\n            :const:`DELETE_METHOD_NONE` or ``None``, then the default delete\n            method will be used (as specified from the optional\n            :attr:`_cte_node_delete_method`).\n\n            Under the :const:`DELETE_METHOD_GRANDMOTHER` and\n            :const:`DELETE_METHOD_MONARCHY` delete semantics, descendant nodes\n            may be moved; in this case the optional `position` can be a\n            ``callable`` which is invoked prior to each move operation (see\n            :meth:`move` for details).\n\n            Furthermore, by default, after each move operation, sub-tree nodes\n            which were moved will be saved through a call to :meth:`Model.save`\n            unless `save` is ``False``.\n\n            This method delegates move operations to :meth:`move`.\n\n            :param node: the :class:`CTENode` to prepare for deletion.\n\n            :param method: optionally, a delete method to use.\n\n            :param position: optionally, a ``callable`` to invoke prior to each\n                move operation.\n\n            :param save: flag indicating whether to save after each move\n                operation, ``True`` by default.\n        \"\"\"\n        # If no delete method preference is specified, use attribute.\n        if method is None:\n            method = node._cte_node_delete_method\n        # If no preference specified, use default.\n        if method == self.DELETE_METHOD_NONE:\n            method = self.DEFAULT_DELETE_METHOD\n        # Delegate to appropriate method.\n        getattr(self, \"prepare_delete_%s\" % method)(node, position, save)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprepare a given node for deletion by executing the GRANDMOTHER DELETE_METHOD.", "response": "def prepare_delete_grandmother(self, node, position=None, save=True):\n        \"\"\" Prepares a given :class:`CTENode` `node` for deletion, by executing\n            the :const:`DELETE_METHOD_GRANDMOTHER` semantics. Descendant nodes,\n            if present, will be moved; in this case the optional `position` can\n            be a ``callable`` which is invoked prior to each move operation (see\n            :meth:`move` for details).\n\n            By default, after each move operation, sub-tree nodes which were\n            moved will be saved through a call to :meth:`Model.save` unless\n            `save` is ``False``.\n\n            This method delegates move operations to :meth:`move`.\n\n            :param node: the :class:`CTENode` to prepare for deletion.\n\n            :param position: optionally, a ``callable`` to invoke prior to each\n                move operation.\n\n            :param save: flag indicating whether to save after each move\n                operation, ``True`` by default.\n        \"\"\"\n        # Move all children to the node's parent.\n        for child in node.children.all():\n            child.move(node.parent, position, save)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef prepare_delete_monarchy(self, node, position=None, save=True):\n        # We are going to iterate all children, even though the first child is\n        # treated in a special way, because the query iterator may be custom, so\n        # we will avoid using slicing children[0] and children[1:].\n        first = None\n        for child in node.children.all():\n            if first is None:\n                first = child\n                first.move(node.parent, position, save)\n            else:\n                child.move(first, position, save)", "response": "Prepares a given node for deletion by executing the delete monarchy method."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef move(self, node, destination, position=None, save=False):\n        # Allow custom positioning semantics to specify the position before\n        # setting the parent.\n        if position is not None:\n            position(node, destination)\n        node.parent = destination\n        if save:\n            node.save()\n        return node", "response": "Moves the given node and places it as a child node of the given destination."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprevent cycles in the tree.", "response": "def clean(self):\n        \"\"\" Prevents cycles in the tree. \"\"\"\n        super(CTENode, self).clean()\n        if self.parent and self.pk in getattr(self.parent, self._cte_node_path):\n            raise ValidationError(_(\"A node cannot be made a descendant of itself.\"))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate a list of values of the attribute of all ancestors of this node.", "response": "def attribute_path(self, attribute, missing=None, visitor=None):\n        \"\"\" Generates a list of values of the `attribute` of all ancestors of\n            this node (as well as the node itself). If a value is ``None``, then\n            the optional value of `missing` is used (by default ``None``).\n\n            By default, the ``getattr(node, attribute, None) or missing``\n            mechanism is used to obtain the value of the attribute for each\n            node. This can be overridden by supplying a custom `visitor`\n            function, which expects as arguments the node and the attribute, and\n            should return an appropriate value for the required attribute.\n\n            :param attribute: the name of the attribute.\n\n            :param missing: optional value to use when attribute value is None.\n\n            :param visitor: optional function responsible for obtaining the\n                attribute value from a node.\n\n            :return: a list of values of the required `attribute` of the\n                ancestor path of this node.\n        \"\"\"\n        _parameters = {\"node\": self, \"attribute\": attribute}\n        if missing is not None:\n            _parameters[\"missing\"] = missing\n        if visitor is not None:\n            _parameters[\"visitor\"] = visitor\n        return self.__class__.objects.attribute_path(**_parameters)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef as_tree(self, visitor=None, children=None):\n        _parameters = {\"node\": self}\n        if visitor is not None:\n            _parameters[\"visitor\"] = visitor\n        if children is not None:\n            _parameters[\"children\"] = children\n        return self.__class__.objects.node_as_tree(**_parameters)", "response": "Returns a dictionary representation of the node in order\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmoving this node and places it as a child of the destination node.", "response": "def move(self, destination=None, position=None, save=False):\n        \"\"\" Moves this node and places it as a child node of the `destination`\n            :class:`CTENode` (or makes it a root node if `destination` is\n            ``None``).\n\n            Optionally, `position` can be a callable which is invoked prior to\n            placement of the node with this node and the destination node as the\n            sole two arguments; this can be useful in implementing specific\n            sibling ordering semantics.\n\n            Optionally, if `save` is ``True``, after the move operation\n            completes (after the :attr:`parent` foreign key is updated and the\n            `position` callable is called if present), a call to\n            :meth:`Model.save` is made.\n\n            :param destination: the destination node of this move, ``None``\n                denoting that the node will become a root node.\n\n            :param position: optional callable invoked prior to placement for\n                purposes of custom sibling ordering semantics.\n\n            :param save: optional flag indicating whether this model's\n                :meth:`save` method should be invoked after the move.\n\n            :return: this node.\n        \"\"\"\n        return self.__class__.objects.move(self, destination, position, save)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete(self, method=None, position=None, save=True):\n        self.__class__.objects.prepare_delete(\n            self, method=method, position=position, save=save\n        )\n        return super(CTENode, self).delete()", "response": "Delete the object in the tree according to the specified deletion semantics."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn an Article object by untyped arguments.", "response": "def _get_article_by_untyped_arg(article_lookup, request, site_id):\n    \"\"\"\n    The `article_lookup` argument can be of any of the following types:\n    - Integer: interpreted as `pk` of the desired article\n    - `dict`: a dictionary containing keyword arguments to find the desired article\n    (for instance: `{'pk': 1}`)\n    - `Article`: you can also pass an Article object directly, in which case there will be no database lookup.\n    - `None`: the current article will be used\n    \"\"\"\n    if article_lookup is None:\n        return request.current_article\n    if isinstance(article_lookup, Article):\n        if hasattr(request, 'current_article') and request.current_article.pk == article_lookup.pk:\n            return request.current_article\n        return article_lookup\n    if isinstance(article_lookup, six.integer_types):\n        article_lookup = {'pk': article_lookup}\n    elif not isinstance(article_lookup, dict):\n        raise TypeError('The article_lookup argument can be either a Dictionary, Integer, or Article.')\n    article_lookup.update({'site': site_id})\n    try:\n        article = Article.objects.all().get(**article_lookup)\n        if request and use_draft(request):\n            if article.publisher_is_draft:\n                return article\n            else:\n                return article.publisher_draft\n        else:\n            if article.publisher_is_draft:\n                return article.publisher_public\n            else:\n                return article\n    except Article.DoesNotExist:\n        site = Site.objects.get_current()\n        subject = _('Article not found on %(domain)s') % {'domain': site.domain}\n        body = (\n            _(\"A template tag couldn't find the article with lookup arguments `%(article_lookup)s\\n`. \"\n              \"The URL of the request was: http://%(host)s%(path)s\") %\n            {'article_lookup': repr(article_lookup), 'host': site.domain, 'path': request.path_info}\n        )\n        if settings.DEBUG:\n            raise Article.DoesNotExist(body)\n        else:\n            mw = get_middleware()\n            if getattr(settings, 'SEND_BROKEN_LINK_EMAILS', False):\n                mail_managers(subject, body, fail_silently=True)\n            elif 'django.middleware.common.BrokenLinkEmailsMiddleware' in mw:\n                middle = BrokenLinkEmailsMiddleware()\n                domain = request.get_host()\n                path = request.get_full_path()\n                referer = force_text(request.META.get('HTTP_REFERER', ''), errors='replace')\n                if not middle.is_ignorable_request(request, path, domain, referer):\n                    mail_managers(subject, body, fail_silently=True)\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef main():\n\n    'Build the parser and parse the arguments'\n    parser = argparse.ArgumentParser(\n        description='www.duckduckgo.com zero-click api for your command-line'\n    )\n    parser.add_argument('query', nargs='*', help='the search query')\n    parser.add_argument('-b', '--bang', action='store_true',\n                        help='open the !bang redirect url in a new browser tab')\n    parser.add_argument('-d', '--define', action='store_true',\n                        help='return the definition result')\n    parser.add_argument('-j', '--json', action='store_true',\n                        help='return the zero-click info api json response')\n    parser.add_argument('-l', '--lucky', action='store_true',\n                        help='open the result url in a new browser tab')\n    parser.add_argument('-s', '--search', action='store_true',\n                        help='launch a DuckDuckGo search in a new browser tab')\n    parser.add_argument('-u', '--url', action='store_true',\n                        help='return the result url')\n    args = parser.parse_args()\n\n    'Get the queries'\n    if args.query:\n        queries = [' '.join(args.query)]\n    elif not sys.stdin.isatty():\n        queries = sys.stdin.read().splitlines()\n    else:\n        parser.print_help()\n        return\n\n    'Determine if we need to add any prefixes based on user flags'\n    prefix = '!ddg ' if args.search else '!' if args.bang else ''\n\n    'Loop through each query'\n    for query in queries:\n        'Prefix the query'\n        query = prefix + query\n\n        'Get a response from api.duckduck.com using the duckduckgo module'\n        results = duckduckgo.search(query)\n\n        'If results is null, continue to the next query'\n        if not results:\n            continue\n\n        'Print the raw json output and return'\n        if args.json:\n            print_result(results.json)\n            continue\n\n        'a list of where to look for an answer first'\n        results_priority = get_results_priority(args)\n\n        'do we want the text or url output of the answer found'\n        var = get_text_or_url(args)\n\n        'action to perform when an answer is found'\n        action = get_action(args)\n\n        'Search for an answer and perform an action'\n        failed_to_find_answer = True\n        for r in results_priority:\n            result = getattr(getattr(results, r), var)\n            if result:\n                action(result)\n                failed_to_find_answer = False\n                break\n\n        'Let the user know if no answer was found'\n        if failed_to_find_answer:\n            if results.type == 'disambiguation':\n                print 'Your query was ambiguous, please be more specific'\n            else:\n                print 'No results found'", "response": "Main function for the main function of the ddg application"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a result priority list based on user input", "response": "def get_results_priority(args):\n    \"\"\"Return a result priority list based on user input\"\"\"\n    redirect_mode = args.bang or args.search or args.lucky\n    if redirect_mode:\n        results_priority = ['redirect', 'result', 'abstract']\n    else:\n        results_priority = ['answer',  'abstract', 'result']\n\n    insert_pos = 0 if args.define else len(results_priority)\n    results_priority.insert(insert_pos, 'definition')\n    return results_priority"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_action(args):\n    redirect_mode = args.bang or args.search or args.lucky\n    if redirect_mode and not args.url:\n        return webbrowser.open_new_tab\n    else:\n        return print_result", "response": "Return a function to launch the web browser or print a result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndetermine if we need text or url output", "response": "def get_text_or_url(args):\n    \"\"\"Determine if we need text or url output\"\"\"\n    redirect_mode = args.bang or args.search or args.lucky\n    if redirect_mode or args.url:\n        return 'url'\n    else:\n        return 'text'"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprint the result to stdout ascii encode if necessary", "response": "def print_result(result):\n    \"\"\"Print the result, ascii encode if necessary\"\"\"\n    try:\n        print result\n    except UnicodeEncodeError:\n        if sys.stdout.encoding:\n            print result.encode(sys.stdout.encoding, 'replace')\n        else:\n            print result.encode('utf8')\n    except:\n        print \"Unexpected error attempting to print result\""}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tables(self):\n        if self._check_db() == False:\n            return\n        try:\n            pmodels = self._tables()\n            if pmodels is None:\n                return\n            num = len(pmodels)\n            s = \"s\"\n            if num == 1:\n                s = \"\"\n            msg = \"Found \" + colors.bold(str(num)) + \" table\" + s + \":\\n\"\n            msg += \"\\n\".join(pmodels)\n            self.info(msg)\n        except Exception as e:\n            self.err(e, \"Can not print tables\")", "response": "Print the existing tables in a database"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tables_(self) -> list:\n        if self._check_db() == False:\n            return\n        try:\n            return self._tables()\n        except Exception as e:\n            self.err(e, \"Can not print tables\")", "response": "Return a list of the existing tables in a database"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef table(self, name: str):\n        if self._check_db() == False:\n            return\n        try:\n            res = self.getall(name)\n        except Exception as e:\n            self.err(e, self.table, \"Can not get records from database\")\n            return\n        if res is None:\n            self.warning(\"Table\", name, \"does not contain any record\")\n            return\n        num = len(res)\n        self.info(num, \"rows\")\n        self.info(\"Fields:\", \", \".join(list(res)))", "response": "Display info about a table"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract the value of the expand query string parameter from a request.", "response": "def parse_requested_expands(query_key, request):\n    \"\"\"\n    Extracts the value of the expand query string parameter from a request.\n    Supports comma separated lists.\n\n    :param query_key: The name query string parameter.\n    :param request: Request instance.\n    :return: List of strings representing the values of the expand query string value.\n    \"\"\"\n\n    requested_expands = []\n\n    for key, val in request.params.items():\n        if key == query_key:\n            requested_expands += val.split(',')\n\n    return requested_expands"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a query that will return the records that are available for the current resource.", "response": "def get_query(self):\n        \"\"\"\n        If you override this method do not forget to call ``super()``.\n        \"\"\"\n\n        query = super(ExpandableViewMixin, self).get_query()\n        expandable_fields = getattr(self, 'expandable_fields', [])\n\n        if expandable_fields:\n            requested_expands = parse_requested_expands(self.schema_class.QUERY_KEY, self.request)\n\n            if requested_expands:\n                available_expands = self.expandable_fields.keys()\n\n                for name in requested_expands:\n                    if name in available_expands:\n                        field = self.expandable_fields[name]\n\n                        innerjoin = field.get('join')\n                        outerjoin = field.get('outerjoin')\n\n                        if innerjoin:\n                            query = query.join(innerjoin)\n                        elif outerjoin:\n                            query = query.outerjoin(outerjoin)\n\n                        # Apply optional options\n                        options = field.get('options')\n\n                        if options:\n                            query = query.options(*options)\n\n        return query"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef emit(\n            self,\n            record):\n        \"\"\"emit\n\n        Emit handler for queue-ing message for\n        the helper thread to send to Splunk on the ``self.sleep_interval``\n\n        :param record: LogRecord to send to Splunk\n                       https://docs.python.org/3/library/logging.html\n        \"\"\"\n        self.debug_log('emit - start')\n\n        try:\n            record = self.format_record(\n                record)\n        except Exception as e:\n            self.write_log(\n                'exception in Splunk logging handler: %s' % str(e))\n            self.write_log(\n                traceback.format_exc())\n            return\n\n        if not self.is_shutting_down(shutdown_event=self.shutdown_event) \\\n                and self.sleep_interval > 0.1:\n            try:\n                self.debug_log(\n                    'writing to queue={}'.format(\n                        self.queue))\n                # Put log message into queue; worker thread will pick up\n                self.queue.put(\n                    record)\n            except Exception as e:\n                self.write_log(\n                    'log queue full; log data will be dropped.')\n        else:\n            # Publish immediately because there is no worker\n            self.publish_to_splunk(\n                payload=record)\n\n        self.debug_log('emit - done')", "response": "Emits a log record to Splunk."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstart the worker process to package queued messages to Splunk and send them to Splunk", "response": "def start_worker(\n            self):\n        \"\"\"start_worker\n\n        Start the helper worker process to package queued messages\n        and send them to Splunk\n        \"\"\"\n        # Start a worker thread responsible for sending logs\n        if not self.is_shutting_down(shutdown_event=self.shutdown_event) \\\n                and self.sleep_interval > 0.1:\n            self.processes = []\n            self.debug_log(\n                'start_worker - start multiprocessing.Process')\n            p = multiprocessing.Process(\n                target=self.perform_work,\n                args=(\n                    self.queue,\n                    self.shutdown_event,\n                    self.shutdown_ack,\n                    self.already_done))\n            p.daemon = True\n            p.start()\n            self.processes.append({\n                'process': p,\n                'shutdown_event': self.shutdown_event,\n                'shutdown_ack_event': self.shutdown_ack,\n                'already_done_event': self.already_done\n            })\n            self.debug_log(\n                'start_worker - done')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef force_flush(\n            self):\n        \"\"\"force_flush\n\n        Flush the queue and publish everything to Splunk\n        \"\"\"\n        self.debug_log('force flush requested')\n        self.perform_work(\n            self.queue,\n            self.shutdown_event,\n            self.shutdown_ack,\n            self.already_done)", "response": "Force flush the queue and publish everything to Splunk."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef close(self):\n        self.debug_log(\n            'close - start shutdown')\n        self.shutdown()\n        logging.Handler.close(self)\n        self.debug_log(\n            'close - handler join on processes={}'.format(\n                len(self.processes)))\n        self.debug_log(\n            'close - done')", "response": "close the current instance of the class and shutdown the logging handler."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsending the shutdown message to all processes.", "response": "def shutdown(\n            self):\n        \"\"\"shutdown\n        \"\"\"\n\n        # Only initiate shutdown once\n        if self.is_shutting_down(\n                shutdown_event=self.shutdown_event):\n            self.debug_log('shutdown - still shutting down')\n            return\n        else:\n            self.debug_log('shutdown - start - setting instance shutdown')\n            self.shutdown_now = True\n            self.shutdown_event.set()\n        # if/else already shutting down\n\n        self.debug_log(\n            'shutdown - trying to publish remaining msgs')\n\n        # Send the remaining items that might be sitting in queue.\n        self.perform_work(\n            self.queue,\n            self.shutdown_event,\n            self.shutdown_ack,\n            self.already_done)\n\n        self.debug_log('shutdown - joining')\n\n        for p in self.processes:\n            p['shutdown_event'].set()\n\n        self.debug_log('shutdown - done')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes a device. \\b DOES: Delete a device. sn: device_sn wio delete <device_sn> \\b EXAMPLE: wio delete 2885b2cab8abc5fb8e229e4a77bf5e4d", "response": "def cli(wio, sn):\n    '''\n    Delete a device.\n\n    \\b\n    DOES:\n        Delete a device.\n        sn: device_sn\n        wio delete <device_sn>\n\n    \\b\n    EXAMPLE:\n        wio delete 2885b2cab8abc5fb8e229e4a77bf5e4d\n    '''\n    user_token = wio.config.get(\"token\", None)\n    api_prefix = wio.config.get(\"mserver\", None)\n    if not api_prefix or not user_token:\n        click.echo(click.style('>> ', fg='red') + \"Please login, use \" +\n            click.style(\"wio login\", fg='green'))\n        return\n\n    params = {\"access_token\":user_token, \"node_sn\":sn}\n    try:\n        r = requests.post(\"%s%s\" %(api_prefix, nodes_delete_endpoint), params=params, timeout=10, verify=verify)\n        r.raise_for_status()\n        json_response = r.json()\n    except requests.exceptions.HTTPError as e:\n        if r.status_code == 400:\n            error = r.json().get(\"error\", None)\n            click.secho(\">> %s\" %error, fg='red')\n        else:\n            click.secho(\">> %s\" %e, fg='red')\n        return\n    except Exception as e:\n        click.secho(\">> %s\" %e, fg='red')\n        return\n\n    click.secho('>> Delete device commplete!', fg='white')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreplace the methodname in a format_string with the given methodname.", "response": "def replace_methodname(format_string, methodname):\n    \"\"\"\n    Partially format a format_string, swapping out any '{methodname}' or '{methodnamehyphen}' components.\n    \"\"\"\n\n    methodnamehyphen = methodname.replace('_', '-')\n    ret = format_string\n    ret = ret.replace('{methodname}', methodname)\n    ret = ret.replace('{methodnamehyphen}', methodnamehyphen)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nregisters a new route with the pyramid.", "response": "def register(self, prefix, viewset, basename, factory=None, permission=None):\n        \"\"\"\n        Factory and permission are likely only going to exist until I have enough time\n        to write a permissions module for PRF.\n\n        :param prefix: the uri route prefix.\n        :param viewset: The ViewSet class to route.\n        :param basename: Used to name the route in pyramid.\n        :param factory: Optional, root factory to be used as the context to the route.\n        :param permission: Optional, permission to assign the route.\n        \"\"\"\n\n        lookup = self.get_lookup(viewset)\n        routes = self.get_routes(viewset)\n\n        for route in routes:\n            # Only actions which actually exist on the viewset will be bound\n            mapping = self.get_method_map(viewset, route.mapping)\n\n            if not mapping:\n                continue  # empty viewset\n\n            url = route.url.format(\n                prefix=prefix,\n                lookup=lookup,\n                trailing_slash=self.trailing_slash\n            )\n            view = viewset.as_view(mapping, **route.initkwargs)\n            name = route.name.format(basename=basename)\n\n            if factory:\n                self.configurator.add_route(name, url, factory=factory)\n            else:\n                self.configurator.add_route(name, url)\n\n            self.configurator.add_view(view, route_name=name, permission=permission)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_routes(self, viewset):\n\n        known_actions = list(flatten([route.mapping.values() for route in self.routes if isinstance(route, Route)]))\n\n        # Determine any `@detail_route` or `@list_route` decorated methods on the viewset\n        detail_routes = []\n        list_routes = []\n\n        for methodname in dir(viewset):\n            attr = getattr(viewset, methodname)\n            httpmethods = getattr(attr, 'bind_to_methods', None)\n            detail = getattr(attr, 'detail', True)\n\n            if httpmethods:\n                # check against know actions list\n                if methodname in known_actions:\n                    raise ImproperlyConfigured('Cannot use @detail_route or @list_route '\n                                               'decorators on method \"%s\" '\n                                               'as it is an existing route'.format(methodname))\n\n                httpmethods = [method.lower() for method in httpmethods]\n\n                if detail:\n                    detail_routes.append((httpmethods, methodname))\n                else:\n                    list_routes.append((httpmethods, methodname))\n\n        def _get_dynamic_routes(route, dynamic_routes):\n            ret = []\n\n            for httpmethods, methodname in dynamic_routes:\n                method_kwargs = getattr(viewset, methodname).kwargs\n                initkwargs = route.initkwargs.copy()\n                initkwargs.update(method_kwargs)\n                url_path = initkwargs.pop(\"url_path\", None) or methodname\n\n                ret.append(Route(\n                    url=replace_methodname(route.url, url_path),\n                    mapping={httpmethod: methodname for httpmethod in httpmethods},\n                    name=replace_methodname(route.name, url_path),\n                    initkwargs=initkwargs,\n                ))\n\n            return ret\n\n        ret = []\n\n        for route in self.routes:\n            if isinstance(route, DynamicDetailRoute):\n                # Dynamic detail routes (@detail_route decorator)\n                ret += _get_dynamic_routes(route, detail_routes)\n            elif isinstance(route, DynamicListRoute):\n                # Dynamic list routes (@list_route decorator)\n                ret += _get_dynamic_routes(route, list_routes)\n            else:\n                # Standard route\n                ret.append(route)\n\n        return ret", "response": "Returns a list of the Route namedtuple."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngives a viewset and a mapping of http methods to actions return a new mapping which includes any mappings that are actually implemented by the viewset.", "response": "def get_method_map(self, viewset, method_map):\n        \"\"\"\n        Given a viewset, and a mapping of http methods to actions, return a new mapping which only\n        includes any mappings that are actually implemented by the viewset.\n        \"\"\"\n\n        bound_methods = {}\n\n        for method, action in method_map.items():\n            if hasattr(viewset, action):\n                bound_methods[method] = action\n\n        return bound_methods"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nimplements the HTTP OPTIONS method", "response": "def options(self, *args, **kwargs):\n        \"\"\"Implement the HTTP OPTIONS method\n\n        :param list args: Positional arguments\n        :param dict kwargs: Keyword arguments\n\n        \"\"\"\n        self.set_header('Allow', ', '.join(self.ALLOW))\n        self.set_status(204)\n        self.finish()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef prepare(self):\n        super(RequestHandler, self).prepare()\n        if self.request.headers.get('content-type', '').startswith(self.JSON):\n            self.request.body = escape.json_decode(self.request.body)", "response": "Prepare the incoming request for processing."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write(self, chunk):\n        if self._finished:\n            raise RuntimeError(\"Cannot write() after finish().  May be caused \"\n                               \"by using async operations without the \"\n                               \"@asynchronous decorator.\")\n        if isinstance(chunk, dict):\n            options = {'ensure_ascii': False}\n            if 'curl' in self.request.headers.get('user-agent'):\n                options['indent'] = 2\n                options['sort_keys'] = True\n            chunk = json.dumps(chunk, **options).replace(\"</\", \"<\\\\/\") + '\\n'\n            self.set_header(\"Content-Type\", \"application/json; charset=UTF-8\")\n        self._write_buffer.append(web.utf8(chunk))", "response": "Writes the given chunk to the output buffer."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef on_finish(self):\n        super(SessionRequestHandler, self).on_finish()\n        LOGGER.debug('Entering SessionRequestHandler.on_finish: %s',\n                     self.session.id)\n        self.session.last_request_at = self.current_epoch()\n        self.session.last_request_uri = self.request.uri\n        if self.session.dirty:\n            result = yield self.session.save()\n            LOGGER.debug('on_finish yield save: %r', result)\n        self.session = None\n        LOGGER.debug('Exiting SessionRequestHandler.on_finish: %r',\n                     self.session)", "response": "Called by Tornado when the request is done. Update the session data\n        and remove the session object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef start_session(self):\n        self.session = self._session_start()\n        result = yield gen.Task(self.session.fetch)\n        self._set_session_cookie()\n        if not self.session.get('ip_address'):\n            self.session.ip_address = self.request.remote_ip\n        self._last_values()\n        raise gen.Return(result)", "response": "Start the session. Invoke in your prepare\n            method like :: start_session."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprepares the session for the next request.", "response": "def prepare(self):\n        \"\"\"Prepare the session, setting up the session object and loading in\n        the values, assigning the IP address to the session if it's an new one.\n\n        \"\"\"\n        super(SessionRequestHandler, self).prepare()\n        result = yield gen.Task(self.start_session)\n        LOGGER.debug('Exiting SessionRequestHandler.prepare: %r', result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _cookie_expiration(self):\n        value = (datetime.datetime.utcnow() +\n                 datetime.timedelta(seconds=self._session_duration))\n        LOGGER.debug('Cookie expires: %s', value.isoformat())\n        return value", "response": "Return the expiration timestamp for the session cookie."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the last_request_uri and last_request_at values.", "response": "def _last_values(self):\n        \"\"\"Always carry last_request_uri and last_request_at even if the last_*\n        values are null.\n\n        \"\"\"\n        if not self.session.get('last_request_uri'):\n            self.session.last_request_uri = None\n        self.session.last_request_at = self.session.get('last_request_at', 0)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _session_start(self):\n        return self._session_class(self._session_id,\n                                   self._session_duration,\n                                   self._session_settings)", "response": "Return an instance of the proper session object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_session_cookie(self):\n        LOGGER.debug('Setting session cookie for %s', self.session.id)\n        self.set_secure_cookie(name=self._session_cookie_name,\n                               value=self.session.id,\n                               expires=self._cookie_expiration)", "response": "Set the session cookie."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild a Splunk TCP message from a Splunk JSON dictionary msg body.", "response": "def build_into_splunk_tcp_message(\n            self,\n            body):\n        \"\"\"build_into_splunk_tcp_message\n\n        Format a message for a Splunk JSON sourcetype\n\n        :param body: splunk JSON dictionary msg body\n        \"\"\"\n        # is for an authenticated Splunk TCP Port\n        log_msg = None\n        if self.token:\n            if IS_PY2:\n                log_msg = ('token={}, body={}').format(\n                    self.token,\n                    body)\n            else:\n                log_msg = ('token={}, body={}').format(\n                    self.token,\n                    body).encode()\n        else:\n            if IS_PY2:\n                log_msg = ('{}').format(\n                    body)\n            else:\n                log_msg = body.encode()\n        # end of support for building different\n        # Splunk socket-ready messages\n\n        self.debug_log('build={}'.format(\n            log_msg))\n\n        return log_msg"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rename(self, source_col: str, dest_col: str):\n        try:\n            self.df = self.df.rename(columns={source_col: dest_col})\n        except Exception as e:\n            self.err(e, self.rename, \"Can not rename column\")\n            return\n        self.ok(\"Column\", source_col, \"renamed\")", "response": "Renames a column in the main dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a column with default values", "response": "def add(self, col: str, value):\n        \"\"\"\n        Add a column with default values\n\n        :param col: column name\n        :type col: str\n        :param value: column value\n        :type value: any\n\n        :example: ``ds.add(\"Col 4\", 0)``\n        \"\"\"\n        try:\n            self.df[col] = value\n        except Exception as e:\n            self.err(e, self.add, \"Can not add column\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a dataswim instance with a dataframe limited to some columns", "response": "def keep_(self, *cols) -> \"Ds\":\n        \"\"\"\n        Returns a dataswim instance with a dataframe limited\n        to some columns\n\n        :param cols: names of the columns\n        :type cols: str\n        :return: a dataswim instance\n        :rtype: Ds\n\n        :example: ``ds2 = ds.keep_(\"Col 1\", \"Col 2\")``\n        \"\"\"\n        try:\n            ds2 = self._duplicate_(self.df[list(cols)])\n        except Exception as e:\n            self.err(e, \"Can not remove colums\")\n            return\n        self.ok(\"Columns\", \" ,\".join(cols), \"kept\")\n        return ds2"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlimit the dataframe to some columns", "response": "def keep(self, *cols):\n        \"\"\"\n        Limit the dataframe to some columns\n\n        :param cols: names of the columns\n        :type cols: str\n\n        :example: ``ds.keep(\"Col 1\", \"Col 2\")``\n        \"\"\"\n        try:\n            self.df = self.df[list(cols)]\n        except Exception as e:\n            self.err(e, \"Can not remove colums\")\n            return\n        self.ok(\"Setting dataframe to columns\", \" \".join(cols))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndropping columns from the main dataframe", "response": "def drop(self, *cols):\n        \"\"\"\n        Drops columns from the main dataframe\n\n        :param cols: names of the columns\n        :type cols: str\n\n        :example: ``ds.drop(\"Col 1\", \"Col 2\")``\n        \"\"\"\n        try:\n            index = self.df.columns.values\n            for col in cols:\n                if col not in index:\n                    self.warning(\"Column\", col, \"not found. Aborting\")\n                    return\n                self.df = self.df.drop(col, axis=1)\n        except Exception as e:\n            self.err(e, self.drop, \"Can not drop column\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexclude rows based on value", "response": "def exclude(self, col: str, val):\n        \"\"\"\n        Delete rows based on value\n\n        :param col: column name\n        :type col: str\n        :param val: value to delete\n        :type val: any\n\n        :example: ``ds.exclude(\"Col 1\", \"value\")``\n        \"\"\"\n        try:\n            self.df = self.df[self.df[col] != val]\n        except Exception as e:\n            self.err(e, \"Can not exclude rows based on value \" + str(val))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncopy a column values in another column", "response": "def copycol(self, origin_col: str, dest_col: str):\n        \"\"\"\n        Copy a columns values in another column\n\n        :param origin_col: name of the column to copy\n        :type origin_col: str\n        :param dest_col: name of the new column\n        :type dest_col: str\n\n        :example: ``ds.copy(\"col 1\", \"New col\")``\n        \"\"\"\n        try:\n            self.df[dest_col] = self.df[[origin_col]]\n        except Exception as e:\n            self.err(e, self.copy_col, \"Can not copy column\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef indexcol(self, col: str):\n        try:\n            self.df[col] = self.df.index.values\n        except Exception as e:\n            self.err(e)\n            return\n        self.ok(\"Column\", col, \"added from the index\")", "response": "Add a column from the index"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_article_placeholders(self, article):\n        placeholders_search_list = getattr(settings, 'CMS_ARTICLES_PLACEHOLDERS_SEARCH_LIST', {})\n\n        included = placeholders_search_list.get('include', [])\n        excluded = placeholders_search_list.get('exclude', [])\n        diff = set(included) - set(excluded)\n        if diff:\n            return article.placeholders.filter(slot__in=diff)\n        elif excluded:\n            return article.placeholders.exclude(slot__in=excluded)\n        else:\n            return article.placeholders.all()", "response": "Returns the list of article s placeholders."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef new_(self, df=pd.DataFrame(), db=None, quiet=False,\n             nbload_libs=True):\n        \"\"\"\n        Returns a new DataSwim instance from a dataframe\n        \"\"\"\n        ds2 = Ds(df, db, nbload_libs)\n        if quiet is False:\n            self.ok(\"A new instance was created\")\n        return ds2", "response": "Returns a new DataSwim instance from a dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef insert(self, table, records, create_cols=False, dtypes=None):\n        if self._check_db() is False:\n            return\n        try:\n            table = self.db[table]\n        except Exception as e:\n            self.err(e, \"Can not find table \" + table)\n        t = type(records)\n        if t == dict:\n            func = table.insert\n        elif t == list:\n            func = table.insert_many\n        else:\n            msg = \"Rows datatype \" + \\\n                str(t) + \" not valid: use a list or a dictionary\"\n            self.err(msg)\n        if create_cols is True:\n            try:\n                func(records, ensure=True, types=dtypes)\n            except Exception as e:\n                self.err(e, \"Can not insert create columns and insert data\")\n            return\n        else:\n            try:\n                func(records, types=dtypes)\n            except Exception as e:\n                self.err(e, \"Can not insert data\")\n            return\n        self.ok(\"Rows inserted in the database\")", "response": "Insert one or many records in the database from a dictionary or a list of dictionaries"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_table(self, table, pks=['id']):\n        if self._check_db() is False:\n            return\n        try:\n            table = self.db[table]\n        except Exception as e:\n            self.err(e, \"Can not find table \" + table)\n        if self.db is None:\n            msg = \"Please connect a database before or provide a database url\"\n            self.err(msg)\n            return\n        recs = self.to_records_()\n        for rec in recs:\n            table.insert_ignore(rec, pks, ensure=True)\n        self.ok(\"Data updated in table\", table)", "response": "Update records in a database table from the main dataframe"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_db(self, table, dtypes=None):\n        if self._check_db() is False:\n            return\n        if table not in self.db.tables:\n            self.db.create_table(table)\n            self.info(\"Created table \", table)\n        self.start(\"Saving data to database table \" + table + \" ...\")\n        recs = self.to_records_()\n        self.insert(table, recs, dtypes)\n        self.end(\"Data inserted in table\", table)", "response": "Save the main dataframe to the database"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef residual_(self, label=None, style=None, opts=None):\n        color, _ = self._get_color_size(style)\n        try:\n            fig = sns.residplot(self.df[self.x], self.df[self.y],\n                                lowess=True, color=color)\n            fig = self._set_with_height(fig, opts)\n            return fig\n        except Exception as e:\n            self.err(e, self.residual_,\n                     \"Can not draw models residuals chart\")", "response": "Returns a Seaborn models residuals chart"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a Seaborn density chart", "response": "def _density_seaborn_(self, label=None, style=None, opts=None):\n        \"\"\"\n        Returns a Seaborn density chart\n        \"\"\"\n        try:\n            fig = sns.kdeplot(self.df[self.x], self.df[self.y])\n            fig = self._set_with_height(fig, opts)\n            return fig\n        except Exception as e:\n            self.err(e, self.density_,\n                     \"Can not draw density chart\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a Seaborn distribution chart", "response": "def _distrib_seaborn_(self, label=None, style=None, opts=None):\n        \"\"\"\n        Returns a Seaborn distribution chart\n        \"\"\"\n        try:\n            kde = False\n            rug = True\n            if \"kde\" in opts:\n                kde = opts[\"kde\"]\n                rug = opts[\"rug\"]\n            fig = sns.distplot(self.df[self.x], kde=kde, rug=rug)\n            fig = self._set_with_height(fig, opts)\n            return fig\n        except Exception as e:\n            self.err(e, self.distrib_,\n                     \"Can not draw distribution chart\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a Seaborn linear regression plot", "response": "def _linear_seaborn_(self, label=None, style=None, opts=None):\n        \"\"\"\n        Returns a Seaborn linear regression plot\n        \"\"\"\n        xticks, yticks = self._get_ticks(opts)\n        try:\n            fig = sns.lmplot(self.x, self.y, data=self.df)\n            fig = self._set_with_height(fig, opts)\n            return fig\n        except Exception as e:\n            self.err(e, self.linear_,\n                     \"Can not draw linear regression chart\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _dlinear_seaborn_(self, label=None, style=None, opts=None):\n        color, size = self._get_color_size(style)\n        try:\n            fig = sns.jointplot(self.x, self.y, color=color,\n                                size=size, data=self.df, kind=\"reg\")\n            fig = self._set_with_height(fig, opts)\n            return fig\n        except Exception as e:\n            self.err(e, self.dlinear_,\n                     \"Can not draw linear regression chart with distribution\")", "response": "Returns a Seaborn linear regression plot with marginal distribution\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef seaborn_bar_(self, label=None, style=None, opts=None):\n        try:\n            fig = sns.barplot(self.x, self.y, palette=\"BuGn_d\")\n            return fig\n        except Exception as e:\n            self.err(e, self.seaborn_bar_,\n                     \"Can not get Seaborn bar chart object\")", "response": "Get a Seaborn bar chart object"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_opts_seaborn(self, opts, style):\n        if opts is None:\n            if self.chart_opts is None:\n                opts = {}\n            else:\n                opts = self.chart_opts\n        if style is None:\n            if self.chart_style is None:\n                style = self.chart_style\n            else:\n                style = {}\n        return opts, style", "response": "Initialise for chart rendering Seaborn options"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_seaborn_chart(self, xfield, yfield, chart_type, label,\n                           _opts=None, _style=None, **kwargs):\n        \"\"\"\n        Get an Seaborn chart object\n        \"\"\"\n        plt.figure()\n        try:\n            opts, style = self._get_opts_seaborn(_opts, _style)\n        except Exception as e:\n            self.err(e, \"Can not get chart options\")\n            return\n        # params\n        # opts[\"xfield\"] = xfield\n        # opts[\"yfield\"] = yfield\n        # opts[\"dataobj\"] = self.df\n        opts[\"chart_type\"] = chart_type\n        self.x = xfield\n        self.y = yfield\n        # generate\n        try:\n            if chart_type == \"dlinear\":\n                chart_obj = self._dlinear_seaborn_(label, style, opts)\n            elif chart_type == \"linear\":\n                chart_obj = self._linear_seaborn_(label, style, opts)\n            elif chart_type == \"distribution\":\n                chart_obj = self._distrib_seaborn_(label, style, opts)\n            elif chart_type == \"density\":\n                chart_obj = self._density_seaborn_(label, style, opts)\n            elif chart_type == \"residual\":\n                chart_obj = self.residual_(label, style, opts)\n            elif chart_type == \"bar\":\n                chart_obj = self.seaborn_bar_(label, style, opts)\n            else:\n                self.err(self._get_seaborn_chart, \"Chart type \" + \n                         chart_type + \" not supported with Seaborn\")\n                return\n        except Exception as e:\n            self.err(e, self._get_seaborn_chart,\n                     \"Can not get Seaborn chart object\")\n            return\n        return chart_obj", "response": "Get an Seaborn chart object for the specified label and options."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_ticks(self, opts):\n        opts, _ = self._get_opts(opts, None)\n        if \"xticks\" not in opts:\n            if \"xticks\" not in self.chart_opts:\n                self.err(self.dlinear_,\n                         \"Please set the xticks option for this chart to work\")\n                return\n            else:\n                xticks = self.chart_opts[\"xticks\"]\n        else:\n            xticks = opts[\"xticks\"]\n        if \"yticks\" not in opts:\n            if \"yticks\"not in self.chart_opts:\n                self.err(self.dlinear_,\n                         \"Please set the yticks option for this chart to work\")\n                return\n            else:\n                yticks = self.chart_opts[\"yticks\"]\n        else:\n            yticks = opts[\"yticks\"]\n        return xticks, yticks", "response": "Check if xticks and yticks are set"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_color_size(self, style):\n        color = \"b\"\n        if \"color\" in style:\n            color = style[\"color\"]\n        size = 7\n        if \"size\" in style:\n            size = style[\"size\"]\n        return color, size", "response": "Get color and size from a style dict."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the width and height of a Matplotlib figure with the height of a Matplotlib figure.", "response": "def _set_with_height(self, fig, opts):\n        \"\"\"\n        Set the width and height of a Matplotlib figure\n        \"\"\"\n        h = 5\n        if \"height\" in opts:\n            h = opts[\"height\"]\n        w = 12\n        if \"width\" in opts:\n            w = opts[\"width\"]\n        try:\n            fig.figure.set_size_inches((w, h))\n            return fig\n        except Exception:\n            try:\n                fig.fig.set_size_inches((w, h))\n                return fig\n            except Exception as e:\n                self.err(e, self._set_with_height,\n                         \"Can not set figure width and height from chart object\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _save_seaborn_chart(self, report, folderpath):\n        if folderpath is None:\n            if self.imgs_path is None:\n                self.err(self._save_seaborn_chart,\n                         \"Please set a path where to save images: ds.imgs_path\"\n                         \" = '/my/path'\")\n                return\n            path = self.imgs_path\n        else:\n            path = folderpath\n        path = path + \"/\" + report[\"slug\"] + \".png\"\n        try:\n            try:\n                # print(\"*** TRY\", report[\"seaborn_chart\"].figure.show())\n                fig = report[\"seaborn_chart\"].figure\n                fig.savefig(path)\n            except Exception as e:\n                try:\n                    fig = report[\"seaborn_chart\"]\n                    fig.savefig(path)\n                except Exception:\n                    plot = report[\"seaborn_chart\"]\n                    plot = plot.get_figure()\n                    plot.savefig(path)\n        except Exception as e:\n            self.err(e, self._save_seaborn_chart, \"Can not save Seaborn chart\")\n            return\n        if self.autoprint is True:\n            self.ok(\"Seaborn chart writen to \" + path)", "response": "Saves a png image of the seaborn chart of the seaborn chart"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef bytes_required(self):\n        return np.sum([hcu.array_bytes(a) for a\n            in self.arrays(reify=True).itervalues()])", "response": "Returns the number of bytes required by the array that are registered with the key\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nregister a dimension on this hypercube.", "response": "def register_dimension(self, name, dim_data, **kwargs):\n        \"\"\"\n        Registers a dimension on this cube.\n\n        .. code-block:: python\n\n            cube.register_dimension('ntime', 10000,\n                        decription=\"Number of Timesteps\",\n                        lower_extent=100, upper_extent=200)\n\n        Parameters\n        ----------\n        dim_data : int or :class:`~hypercube.dims.Dimension`\n            if an integer, this will be used to\n            define the global_size of the dimension\n            and possibly other attributes if they are\n            not present in kwargs.\n            If a Dimension, it will be updated with\n            any appropriate keyword arguments\n        description : str\n            The description for this dimension.\n            e.g. 'Number of timesteps'.\n        lower_extent : int\n            The lower extent of this dimension\n            within the global space\n        upper_extent : int\n            The upper extent of this dimension\n            within the global space\n        name : Dimension name\n\n\n        Returns\n        -------\n        :class:`~hypercube.dims.Dimension`\n            A hypercube Dimension\n\n        \"\"\"\n\n        if name in self._dims:\n            raise AttributeError((\n                \"Attempted to register dimension '{n}'' \"\n                \"as an attribute of the cube, but \"\n                \"it already exists. Please choose \"\n                \"a different name!\").format(n=name))\n\n        # Create the dimension dictionary\n        D = self._dims[name] = create_dimension(name,\n            dim_data, **kwargs)\n\n        return D"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nregistering multiple dimensions on the Cube.", "response": "def register_dimensions(self, dims):\n        \"\"\"\n        Register multiple dimensions on the cube.\n\n        .. code-block:: python\n\n            cube.register_dimensions([\n                {'name' : 'ntime', 'global_size' : 10,\n                'lower_extent' : 2, 'upper_extent' : 7 },\n                {'name' : 'na', 'global_size' : 3,\n                'lower_extent' : 2, 'upper_extent' : 7 },\n            ])\n\n\n        Parameters\n        ----------\n        dims : list or dict\n            A list or dictionary of dimensions\n\n        \"\"\"\n\n        if isinstance(dims, collections.Mapping):\n            dims = dims.itervalues()\n\n        for dim in dims:\n            self.register_dimension(dim.name, dim)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate multiple dimension on the cube.", "response": "def update_dimensions(self, dims):\n        \"\"\"\n        Update multiple dimension on the cube.\n\n        .. code-block:: python\n\n            cube.update_dimensions([\n                {'name' : 'ntime', 'global_size' : 10,\n                'lower_extent' : 2, 'upper_extent' : 7 },\n                {'name' : 'na', 'global_size' : 3,\n                'lower_extent' : 2, 'upper_extent' : 7 },\n            ])\n\n        Parameters\n        ----------\n        dims : list or dict:\n            A list or dictionary of dimension updates\n        \"\"\"\n\n        if isinstance(dims, collections.Mapping):\n            dims = dims.itervalues()\n\n        for dim in dims:\n            # Defer to update dimension for dictionaries\n            if isinstance(dim, dict):\n                self.update_dimension(**dim)\n            # Replace if given a Dimension object\n            elif isinstance(dim, Dimension):\n                self._dims[dim.name] = dim\n            else:\n                raise TypeError(\"Unhandled type '{t}'\"\n                    \"in update_dimensions\".format(t=type(dim)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the size and extents of a dimension.", "response": "def update_dimension(self, name, **update_dict):\n        \"\"\"\n        Update the dimension size and extents.\n\n        Parameters\n        ----------\n        **update_dict : : dict: dict\n            A dictionary containing keywords passed through to\n            :meth:`~hypercube.dims.Dimension.update`\n        name : str\n            Name of the dimension to update\n        \"\"\"\n        if not name:\n            raise AttributeError(\"A dimension name is required to update \"\n                \"a dimension. Update dictionary {u}.\"\n                    .format(u=update_dict))\n\n        dim = self._dims.get(name, None)\n\n        # Sanity check dimension existence\n        if not dim:\n            raise ValueError(\"'Dimension {n}' cannot be updated as it \"\n                \"is not registered in the dimension dictionary.\"\n                    .format(n=name))\n\n        dim.update(**update_dict)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of dimension attribute attr for the dimensions specified as strings in args.", "response": "def _dim_attribute(self, attr, *args, **kwargs):\n        \"\"\"\n        Returns a list of dimension attribute attr, for the\n        dimensions specified as strings in args.\n\n        .. code-block:: python\n\n            ntime, nbl, nchan = cube._dim_attribute('global_size', 'ntime', 'nbl', 'nchan')\n\n        or\n\n        .. code-block:: python\n\n            ntime, nbl, nchan, nsrc = cube._dim_attribute('global_size', 'ntime,nbl:nchan nsrc')\n        \"\"\"\n\n        import re\n\n        # If we got a single string argument, try splitting it by separators\n        if len(args) == 1 and isinstance(args[0], str):\n            args = (s.strip() for s in re.split(',|:|;| ', args[0]))\n\n        # Now get the specific attribute for each string dimension\n        # Integers are returned as is\n        result = [d if isinstance(d, (int, np.integer))\n            else getattr(self._dims[d], attr) for d in args]\n\n        # Return single element if length one and single else entire list\n        return (result[0] if kwargs.get('single', True)\n            and len(result) == 1 else result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a mapping of dimension name to global size", "response": "def dim_global_size_dict(self):\n        \"\"\" Returns a mapping of dimension name to global size \"\"\"\n        return { d.name: d.global_size for d in self._dims.itervalues()}"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dim_lower_extent_dict(self):\n        return { d.name: d.lower_extent for d in self._dims.itervalues()}", "response": "Returns a mapping of dimension name to lower_extent"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a mapping of dimension name to upper_extent", "response": "def dim_upper_extent_dict(self):\n        \"\"\" Returns a mapping of dimension name to upper_extent \"\"\"\n        return { d.name: d.upper_extent for d in self._dims.itervalues()}"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the lower extent of the dimensions in args.", "response": "def dim_lower_extent(self, *args, **kwargs):\n        \"\"\"\n        Returns the lower extent of the dimensions in args.\n\n        .. code-block:: python\n\n            t_ex, bl_ex, ch_ex = cube.dim_lower_extent('ntime', 'nbl', 'nchan')\n\n        or\n\n        .. code-block:: python\n\n            t_ex, bl_ex, ch_ex, src_ex = cube.dim_lower_extent('ntime,nbl:nchan nsrc')\n        \"\"\"\n\n        # The lower extent of any integral dimension is 0 by default\n        args = tuple(0 if isinstance(a, (int, np.integer))\n            else a for a in args)\n        return self._dim_attribute('lower_extent', *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dim_extents(self, *args, **kwargs):\n\n\n        l = self.dim_lower_extent(*args, **kwargs)\n        u = self.dim_upper_extent(*args, **kwargs)\n\n        # Handle sequence and singles differently\n        if isinstance(l, collections.Sequence):\n            return zip(l, u)\n        else:\n            return (l, u)", "response": "Returns extent tuples of the dimensions in args."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dim_extent_size(self, *args, **kwargs):\n\n\n        extents = self.dim_extents(*args, **kwargs)\n\n        # Handle tuples and sequences differently\n        if isinstance(extents, tuple):\n            return extents[1] - extents[0]\n        else: # isinstance(extents, collections.Sequence):\n            return (u-l for l, u in extents)", "response": "Returns extent sizes of the dimensions in args."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nregister an array with this cube.", "response": "def register_array(self, name, shape, dtype, **kwargs):\n        \"\"\"\n        Register an array with this cube.\n\n        .. code-block:: python\n\n            cube.register_array(\"model_vis\", (\"ntime\", \"nbl\", \"nchan\", 4), np.complex128)\n\n        Parameters\n        ----------\n        name : str\n            Array name\n        shape : A tuple containing either Dimension names or ints\n            Array shape schema\n        dtype :\n            Array data type\n        \"\"\"\n\n        # Complain if array exists\n        if name in self._arrays:\n            raise ValueError(('Array %s is already registered '\n                'on this cube object.') % name)\n\n        # OK, create a record for this array\n        A = self._arrays[name] = AttrDict(name=name,\n            dtype=dtype, shape=shape,\n            **kwargs)\n\n        return A"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nregister arrays using a list of dictionaries defining the arrays.", "response": "def register_arrays(self, arrays):\n        \"\"\"\n        Register arrays using a list of dictionaries defining the arrays.\n\n        The list should itself contain dictionaries. i.e.\n\n        .. code-block:: python\n\n            D = [{ 'name':'uvw', 'shape':(3,'ntime','nbl'),'dtype':np.float32 },\n                { 'name':'lm', 'shape':(2,'nsrc'),'dtype':np.float32 }]\n\n        Parameters\n        ----------\n        arrays : A list or dict.\n            A list or dictionary of dictionaries describing arrays.\n        \"\"\"\n\n        if isinstance(arrays, collections.Mapping):\n            arrays = arrays.itervalues()\n\n        for ary in arrays:\n            self.register_array(**ary)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef register_property(self, name, dtype, default, **kwargs):\n        if name in self._properties:\n            raise ValueError(('Property %s is already registered '\n                'on this cube object.') % name)\n\n        P = self._properties[name] = AttrDict(name=name,\n            dtype=dtype, default=default)\n\n        #if not hasattr(HyperCube, name):\n        if not HyperCube.__dict__.has_key(name):\n                # Create the descriptor for this property on the class instance\n            setattr(HyperCube, name, PropertyDescriptor(record_key=name, default=default))\n\n        # Set the descriptor on this object instance\n        setattr(self, name, default)\n\n        # Should we create a setter for this property?\n        setter = kwargs.get('setter_method', True)\n        setter_name = hcu.setter_name(name)\n\n        # Yes, create a default setter\n        if isinstance(setter, types.BooleanType) and setter is True:\n            def set(self, value):\n                setattr(self,name,value)\n\n            setter_method = types.MethodType(set, self)\n            setattr(self, setter_name, setter_method)\n\n            # Set up the docstring, using the supplied one\n            # if it is present, otherwise generating a default\n            setter_docstring = kwargs.get('setter_docstring', None)\n            getattr(setter_method, '__func__').__doc__ = \\\n                \"\"\" Sets property %s to value. \"\"\" % (name) \\\n                if setter_docstring is None else setter_docstring\n\n        elif isinstance(setter, types.MethodType):\n            setattr(self, setter_name, setter)\n        else:\n            raise TypeError, ('setter keyword argument set',\n                ' to an invalid type %s' % (type(setter)))\n\n        return P", "response": "Registers a property with this Solver object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef register_properties(self, properties):\n        if isinstance(properties, collections.Mapping):\n            properties = properties.itervalues()\n\n        for prop in properties:\n            self.register_property(**prop)", "response": "Register properties using a list defining the properties."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a dictionary of dimensions.", "response": "def dimensions(self, copy=True):\n        \"\"\"\n        Return a dictionary of :class:`~hypercube.dims.Dimension` objects.\n\n        Parameters\n        ----------\n        copy : boolean:\n            Returns a copy of the dimension dictionary if True (Default value = True)\n\n        Returns\n        -------\n        dict\n            Dictionary of :class:`~hypercube.dims.Dimension` objects.\n\n        \"\"\"\n\n        return self._dims.copy() if copy else self._dims"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the requested dimension object.", "response": "def dimension(self, name, copy=True):\n        \"\"\"\n        Returns the requested :class:`~hypercube.dims.Dimension` object\n\n        Parameters\n        ----------\n        name : str\n            Name of the :class:`~hypercube.dims.Dimension` object\n        copy : boolean\n            Returns a copy of the :class:`~hypercube.dims.Dimension` object if True (Default value = True)\n\n        Returns\n        -------\n        :class:`~hypercube.dims.Dimension`\n            A :class:`~hypercube.dims.Dimension` object.\n        \"\"\"\n\n        try:\n            return create_dimension(name, self._dims[name]) if copy else self._dims[name]\n        except KeyError:\n            raise KeyError(\"Dimension '{n}' is not registered \"\n                \"on this cube\".format(n=name)), None, sys.exc_info()[2]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a copy of the hypercube", "response": "def copy(self):\n        \"\"\" :rtype: Return a copy of the hypercube \"\"\"\n        return HyperCube(\n            dimensions=self.dimensions(copy=False),\n            arrays=self.arrays(),\n            properties=self.properties())"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a 2D array describing each registered dimension and its headers.", "response": "def _gen_dimension_table(self):\n        \"\"\"\n        2D array describing each registered dimension\n        together with headers - for use in __str__\n        \"\"\"\n        headers = ['Dimension Name', 'Description',\n            'Global Size', 'Extents']\n\n        table = []\n        for dimval in sorted(self.dimensions(copy=False).itervalues(),\n                             key=lambda dval: dval.name.upper()):\n\n            table.append([dimval.name,\n                dimval.description,\n                dimval.global_size,\n                (dimval.lower_extent, dimval.upper_extent)])\n\n        return table, headers"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _gen_array_table(self):\n        headers = ['Array Name', 'Size', 'Type', 'Shape']\n\n        # Reify arrays to work out their actual size\n        reified_arrays = self.arrays(reify=True)\n\n        table = []\n        for array in sorted(self.arrays().itervalues(),\n                             key=lambda aval: aval.name.upper()):\n            # Get the actual size of the array\n            nbytes = hcu.array_bytes(reified_arrays[array.name])\n            # Print shape tuples without spaces and single quotes\n            sshape = '(%s)' % (','.join(map(str, array.shape)),)\n            table.append([array.name,\n                hcu.fmt_bytes(nbytes),\n                np.dtype(array.dtype).name,\n                sshape])\n\n        return table, headers", "response": "Generate a table of 2D arrays describing each registered array\n            and returns it and the headers"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _gen_property_table(self):\n        headers = ['Property Name', 'Type', 'Value', 'Default Value']\n\n        table = []\n        for propval in sorted(self._properties.itervalues(),\n                              key=lambda pval: pval.name.upper()):\n            table.append([propval.name,\n                np.dtype(propval.dtype).name,\n                getattr(self, propval.name),\n                propval.default])\n\n        return table, headers", "response": "Generate a 2D array describing each registered property and its properties together with headers - for use in __str__\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef slice_iter(self, *dim_strides, **kwargs):\n        def _create_slices(*args):\n            return tuple(slice(s,e,1) for (s, e) in args)\n\n        return (_create_slices(*s) for s in self.endpoint_iter(\n            *dim_strides, **kwargs))", "response": "This method recursively iterates over the dimension and stride of the log entry in the specified dimension and returns the chunk start offsets for each specified dimension."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dim_iter(self, *dim_strides, **kwargs):\n\n        # Extract dimension names\n        dims = [ds[0] for ds in dim_strides]\n\n        def _create_dim_dicts(*args):\n            return tuple({ 'name': d,\n                    'lower_extent': s,\n                    'upper_extent': e\n                } for (d, (s, e)) in args)\n\n        # Return a tuple-dict-creating generator\n        return (_create_dim_dicts(*zip(dims, s)) for s\n            in self.endpoint_iter(*dim_strides, **kwargs))", "response": "Recursively iterate over the dimension strides and return a generator that yields a tuple containing a dictionary describing a dimension update."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of lower and upper extents for the given array name.", "response": "def array_extents(self, array_name, **kwargs):\n        \"\"\"\n        Return a list of lower and upper extents for\n        the given array_name.\n\n        .. code-block:: python\n\n            cube.register(\"uvw\", (\"ntime\", \"na\", 3), np.float64)\n\n            (lt, ut), (la, ua), (_, _) = cube.array_extents(\"uvw\")\n\n        Parameters\n        ----------\n        array_name : string\n            Name of an array registered on this hypercube\n\n\n        Returns\n        -------\n        list\n            List of (lower_extent, upper_extent) tuples\n            associated with each array dimension\n\n\n        \"\"\"\n\n        A = self.array(array_name, reify=False)\n        return self.dim_extents(*A.shape, single=False)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef array_slice_index(self, array_name, **kwargs):\n\n        A = self.array(array_name, reify=False)\n        return self.slice_index(*A.shape, single=False)", "response": "Returns a tuple of slices each slice equal to the\n            slice of the lower_extent upper_extent 1 of the dimensions\n            of array_name."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a tuple of slices each slice equal to the slice lower_extent upper_extent and 1 of the dimensions of the objects in the log.", "response": "def slice_index(self, *slice_dims, **kwargs):\n        \"\"\"\n        Returns a tuple of slices, each slice equal to the\n        slice(lower_extent, upper_extent, 1) of the dimensions\n        supplied in slice_dims. If the dimension is integer d,\n        slice(0, d, 1) will be used instead of the lower and upper extents\n\n        .. code-block:: python\n\n            A = np.ones(ntime, na)\n            idx = cube.slice_index('ntime','na', 3)\n            A[idx].sum()\n            ntime, na, components = cube.slice_index('ntime', 'na', 3)\n            A[ntime, na, components].sum()\n\n        Parameters\n        ----------\n        *slice_dims : tuple\n            Tuple of dimensions for which slice\n            objects should be returned.\n\n\n        Returns\n        -------\n            tuple\n                Tuple of :code:`slice(lower,upper,1)` objects\n\n        \"\"\"\n        return tuple(slice(l, u, 1) for l, u in zip(\n            self.dim_lower_extent(*slice_dims, single=False),\n            self.dim_upper_extent(*slice_dims, single=False)))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef contains_case_insensitive(adict, akey):\n    for key in adict:\n        if key.lower() == akey.lower():\n            return True\n    return False", "response": "Check if key is in adict. The search is case insensitive."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsave result to file.", "response": "def save_result(res, json_file):\n    \"\"\"Save result to file.\"\"\"\n    with open(json_file, 'wb') as f:\n        json.dump(res, f, sort_keys=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nformats a comic name.", "response": "def format_name(text):\n    \"\"\"Format a comic name.\"\"\"\n    name = unescape(text)\n    name = asciify(name.replace(u'&', u'And').replace(u'@', u'At'))\n    name = capfirst(name)\n    return name"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_article_from_slug(tree, slug, preview=False, draft=False):\n    from ..models import Title\n\n    titles = Title.objects.select_related('article').filter(article__tree=tree)\n    published_only = (not draft and not preview)\n\n    if draft:\n        titles = titles.filter(publisher_is_draft=True)\n    elif preview:\n        titles = titles.filter(publisher_is_draft=False)\n    else:\n        titles = titles.filter(published=True, publisher_is_draft=False)\n    titles = titles.filter(slug=slug)\n\n    for title in titles.iterator():\n        if published_only and not _page_is_published(title.article):\n            continue\n\n        title.article.title_cache = {title.language: title}\n        return title.article\n    return", "response": "Resolves a slug to a single article object. Returns None if the slug does not exist."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a view function that can be used to dispatch the request to the appropriate method.", "response": "def as_view(cls, action_map=None, **initkwargs):\n        \"\"\"\n        Allows custom request to method routing based on given ``action_map`` kwarg.\n        \"\"\"\n\n        # Needs to re-implement the method but contains all the things the parent does.\n        if not action_map:  # actions must not be empty\n            raise TypeError(\"action_map is a required argument.\")\n\n        def view(request):\n            self = cls(**initkwargs)\n            self.request = request\n            self.lookup_url_kwargs = self.request.matchdict\n            self.action_map = action_map\n            self.action = self.action_map.get(self.request.method.lower())\n\n            for method, action in action_map.items():\n                handler = getattr(self, action)\n                setattr(self, method, handler)\n\n            return self.dispatch(self.request, **self.request.matchdict)\n\n        return view"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _deserialize_datetime(self, data):\n        for key in data:\n            if isinstance(data[key], dict):\n                if data[key].get('type') == 'datetime':\n                    data[key] = \\\n                        datetime.datetime.fromtimestamp(data[key]['value'])\n        return data", "response": "Take any values coming in as a datetime and deserialize them\n\nosity"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef deserialize(self, data):\n        if not data:\n            return dict()\n        return self._deserialize_datetime(pickle.loads(data))", "response": "Return the deserialized data.\n\n        :param str data: The data to deserialize\n        :rtype: dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the data as serialized string.", "response": "def serialize(self, data):\n        \"\"\"Return the data as serialized string.\n\n        :param dict data: The data to serialize\n        :rtype: str\n\n        \"\"\"\n        return json.dumps(self._serialize_datetime(data), ensure_ascii=False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate(self):\n        # Check all values for None\n        for attr in self.__dict__:\n            if self.__dict__[attr] is None:\n                raise ValueError(attr + \" is not set\")\n\n        # Validate name\n        invalid_chars = GPTaskSpec.invalid_chars()\n        if any(char in invalid_chars for char in self.name):\n            raise ValueError(\"module name includes invalid characters: \" + self.name)\n\n        # Validate LSID\n        self._valid_lsid()\n\n        # Validate categories\n        if not self.all_strings(self.categories):\n            raise TypeError(\"categories contains non-string value: \" + str(self.categories))\n\n        # Validate file formats\n        if not self.all_strings(self.file_format):\n            raise TypeError(\"file_format contains non-string value: \" + str(self.file_format))\n\n        # Validate support files\n        if not self.all_strings(self.support_files):\n            raise TypeError(\"support_files contains non-string value: \" + str(self.support_files))\n\n        # Validate parameter list\n        if not self._all_params(self.parameters):\n            raise TypeError(\"parameters contains non-GPParamSpec value: \" + str(self.parameters))\n\n        # Validate individual parameters\n        for param in self.parameters:\n            param.validate()\n\n        # Return that everything validates\n        return True", "response": "Perform some basic checks to help ensure that the specification is valid."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a GenePattern module zip file for upload and installation on a GenePattern server.", "response": "def create_zip(self, clean=True, increment_version=True, register=True):\n        \"\"\"\n        Creates a GenePattern module zip file for upload and installation on a GenePattern server\n        :param clean: boolean\n        :return:\n        \"\"\"\n        # First validate the attributes\n        self.validate()\n\n        # Check to see if an existing interferes with module creation\n        if os.path.exists(MANIFEST_FILE_NAME):\n            raise OSError(\"existing manifest blocks manifest file creation\")\n\n        # Write the manifest\n        self.write_manifest()\n\n        # Create the zip\n        self._zip_files()\n\n        # Increment the version of the module\n        if increment_version:\n            self.version += 1\n\n        # Register the module with the LSID authority\n        if register and self.lsid_authority:\n            self.lsid_authority.register(self)\n\n        # Clean up the manifest\n        if clean:\n            os.remove(MANIFEST_FILE_NAME)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd the manifest and all support files to the zip file", "response": "def _zip_files(self):\n        \"\"\"\n        Adds the manifest and all support files to the zip file\n        :return:\n        \"\"\"\n        # Create the zip file\n        zip = zipfile.ZipFile(self.name + '.zip', 'w', zipfile.ZIP_DEFLATED)\n\n        # Add the manifest file to the zip\n        zip.write(MANIFEST_FILE_NAME)\n\n        # Add the support files to the zip\n        for file in self.support_files:\n            zip.write(file)\n\n        # Close the zip file\n        zip.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_manifest(self, module_directory=\"\"):\n        # First validate the spec\n        self.validate()\n\n        # Open the manifest file for writing\n        manifest_file = open(os.path.join(module_directory, \"manifest\"), \"w\")\n\n        # Write the header\n        manifest_file.write(\"# \" + self.name + \"\\n\")\n        manifest_file.write(\"# \" + str(datetime.now()) + \"\\n\")\n        manifest_file.write(\"# Generated by Python Module Creator v\" + __version__ + \"\\n\")\n\n        # Write initial attributes\n        manifest_file.write(\"JVMLevel=\\n\")\n        manifest_file.write(\"LSID=\" + self.manifest_escape(self.lsid) + ':' + str(self.version) + \"\\n\")\n        manifest_file.write(\"author=\" + self._author_line() + \"\\n\")\n        manifest_file.write(\"categories=\" + ';'.join(self.categories) + \"\\n\")\n        manifest_file.write(\"commandLine=\" + self.command_line + \"\\n\")\n        manifest_file.write(\"cpuType=\" + str(self.cpu.value) + \"\\n\")\n        manifest_file.write(\"description=\" + self.description + \"\\n\")\n        manifest_file.write(\"fileFormat=\" + ';'.join(self.file_format) + \"\\n\")\n        manifest_file.write(\"language=\" + self.language + \"\\n\")\n        manifest_file.write(\"license=\" + self.license + \"\\n\")\n        manifest_file.write(\"name=\" + self.name + \"\\n\")\n        manifest_file.write(\"os=\" + str(self.os.value) + \"\\n\")\n\n        # Write parameter attributes\n        for index, param in enumerate(self.parameters):\n            manifest_file.write(param.manifest_repr(index+1))\n\n        # Write footer attributes\n        manifest_file.write(\"privacy=\" + str(self.privacy.value) + \"\\n\")\n        manifest_file.write(\"publicationDate=\" + self._publication_date() + \"\\n\")\n        manifest_file.write(\"quality=\" + str(self.quality.value) + \"\\n\")\n        manifest_file.write(\"taskDoc=\" + self.documentation + \"\\n\")\n        manifest_file.write(\"taskType=\" + self._task_type() + \"\\n\")\n        manifest_file.write(\"userid=\" + self.user + \"\\n\")\n        manifest_file.write(\"version=\" + self.version_comment + \"\\n\")\n\n        # Close the file\n        manifest_file.close()", "response": "Writes a GenePattern manifest file for the current module."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef all_strings(arr):\n        if not isinstance([], list):\n            raise TypeError(\"non-list value found where list is expected\")\n        return all(isinstance(x, str) for x in arr)", "response": "Ensures that the argument is a list that either contains only strings\n        or raises a TypeError"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _all_params(arr):\n        if not isinstance([], list):\n            raise TypeError(\"non-list value found for parameters\")\n        return all(isinstance(x, GPParamSpec) for x in arr)", "response": "Checks that the argument is a list that either contains only GPParamSpec s\n        or raises a TypeError"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nperform some basic LSID validation.", "response": "def _valid_lsid(self):\n        \"\"\"\n        Performs some basic (non-comprehensive) LSID validation\n        :return:\n        \"\"\"\n        if not isinstance(self.lsid, str):\n            raise TypeError(\"lsid is not a string, string expected: \" + str(self.lsid))\n\n        if self.lsid.count(':') != 4:\n            raise ValueError(\"lsid contains incorrect number of colons, 4 expected: \" + str(self.lsid))\n\n        if self.lsid.split(':')[0].lower() != 'urn':\n            raise ValueError(\"lsid does not begin with urn: \" + str(self.lsid))\n\n        # If an LSID authority is specified, check with the authority\n        if self.lsid_authority:\n            if not self.lsid_authority.validate(self.lsid, check_existing=False):\n                raise ValueError(\"lsid does not the authority: \" + str(self.lsid))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef manifest_repr(self, p_num):\n        # Build the parameter prefix\n        prefix = \"p\" + str(p_num) + \"_\"\n\n        # Generate the manifest string\n        manifest = prefix + \"MODE=\" + (\"IN\" if self.type == Type.FILE else \"\") + \"\\n\"\n        manifest += prefix + \"TYPE=\" + str(self.type.value) + \"\\n\"\n        if self.type == Type.FILE and len(self.choices) > 0:\n            manifest += prefix + \"choices=\" + self._choices() + \"\\n\"\n        manifest += prefix + \"default_value=\" + self.default_value + \"\\n\"\n        manifest += prefix + \"description=\" + GPTaskSpec.manifest_escape(self.description) + \"\\n\"\n        manifest += prefix + \"fileFormat=\" + ';'.join(self.file_format) + \"\\n\"\n        manifest += prefix + \"flag=\" + self.flag + \"\\n\"\n        manifest += prefix + \"name=\" + self.name + \"\\n\"\n        manifest += prefix + \"numValues=\" + self._num_values() + \"\\n\"\n        manifest += prefix + \"optional=\" + str(self.optional.value) + \"\\n\"\n        manifest += prefix + \"prefix=\" + (self.flag if self.prefix_when_specified else \"\") + \"\\n\"\n        manifest += prefix + \"prefix_when_specified=\" + (self.flag if self.prefix_when_specified else \"\") + \"\\n\"\n        manifest += prefix + \"type=\" + self._java_type() + \"\\n\"\n        manifest += prefix + \"value=\" + (self._choices() if self.type != Type.FILE and len(self.choices) > 0 else \"\") + \"\\n\"\n\n        # Return the manifest string\n        return manifest", "response": "Builds a manifest string representation of the parameters and returns it"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate a string of choices as key value pairs", "response": "def _choices(self):\n        \"\"\"\n        Generate a string of choices as key/value pairs\n        :return: string\n        \"\"\"\n        # Generate key/value strings\n        pairs = []\n        for key, value in self.choices.items():\n            pairs.append(str(value) + \"=\" + str(key))\n\n        # Assemble into overall string and escape\n        return GPTaskSpec.manifest_escape(\";\".join(pairs))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a valid num_values string based off min_values and max_values", "response": "def _num_values(self):\n        \"\"\"\n        Generate a valid num_values string based off min_values and max_values\n        :return: string\n        \"\"\"\n        # Add min_values to string\n        num_values = str(self.min_values) if self.min_values else \"0\"\n\n        # Handle infinite max_values or finite max_values\n        if self.max_values is None or self.max_values == float(\"inf\"):\n            num_values += \"+\"\n        else:\n            num_values += \"..\" + str(self.max_values)\n\n        # Return the num_values string\n        return num_values"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating an LSID namespace based off Jupyter user or system user", "response": "def _generate_namespace():\n        \"\"\"\n        Generate an LSID namespace based off Jupyter user or system user\n        :return: string\n        \"\"\"\n        raw_namespace = None\n\n        # Get the Jupyter user, if available\n        try:\n            raw_namespace = os.environ['JPY_USER']\n        except KeyError:\n            pass\n\n        # Otherwise get the current user\n        if raw_namespace is None or raw_namespace == '':\n            raw_namespace = getpass.getuser()\n\n        # Remove illegal characters and return\n        return re.sub(r'[^\\w.-]', '-', raw_namespace)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating an LSID domain based off a setting file or the hostname", "response": "def _generate_domain():\n        \"\"\"\n        Generate an LSID domain based off a setting file or the hostname\n        :return: string\n        \"\"\"\n\n        # Check for LSID domain setting file\n        try:\n            user_dir = str(pathlib.Path.home())\n            jupyter_dir = os.path.join(user_dir, '.jupyter')\n            domain_path = os.path.join(jupyter_dir, 'lsid_domain')\n            with open(domain_path, 'r') as domain_file:\n                domain = str(domain_file.read()).strip()\n            if domain is not None and domain != '':\n                return domain\n        except:\n            # Ignore exceptions, simply fall back to the domain name\n            pass\n\n        # If this fails, return the fully qualified domain name\n        return socket.getfqdn()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating and returns a base LSID", "response": "def _generate_base_lsid(self):\n        \"\"\"\n        Generates and returns a base LSID\n        :return:\n        \"\"\"\n        domain = self._generate_domain()\n        namespace = self._generate_namespace()\n\n        # Return the base LSID\n        return \"urn:lsid:\" + domain + \":\" + namespace"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _create_authority_file(self, file_path):\n        parent_dir = os.path.dirname(os.path.realpath(file_path))\n\n        # Create the parent directory if it does not exist\n        if not os.path.exists(parent_dir):\n            os.makedirs(parent_dir)\n\n        # Create blank LSID authority structure\n        blank = self._create_blank_authority()\n\n        # Write blank structure to new authority file\n        with open(file_path, 'w+') as authority_file:\n            json.dump(blank, authority_file, sort_keys=True, indent=4, separators=(',', ': '))", "response": "Create a new LSID authority file at the indicated location."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _load_lsid_authority(self):\n        authority_file = open(self.authority, 'r')\n        authority_json = json.load(authority_file)\n        authority_file.close()\n        self.base_lsid = authority_json['base_lsid']\n        self.module_count = int(authority_json['module_count'])\n        self.registered_modules = authority_json['registered_modules']", "response": "Load the LSID authority file and set class attributes"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _assemble_lsid(self, module_number):\n        if self.base_lsid is None:\n            raise Exception(\"Base LSID in LSID authority not initialized\")\n\n        return self.base_lsid + \":\" + str(module_number)", "response": "Assemble the base LSID based off the module number and the authority s base LSID."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef register(self, task_spec):\n        if self.validate(task_spec.lsid):\n            # Add the module name to the map\n            self.registered_modules[task_spec.lsid] = task_spec.name\n\n            # Increment module count\n            self.module_count += 1\n\n            # Write the updated LSID authority file and reload\n            with open(self.authority, 'w') as authority_file:\n                json.dump({\n                    'base_lsid': self.base_lsid,\n                    'module_count': self.module_count,\n                    'registered_modules': self.registered_modules,\n                }, authority_file, sort_keys=True, indent=4, separators=(',', ': '))\n            self._load_lsid_authority()\n        else:\n            raise RuntimeError(\"Module LSID id not valid: \" + str(task_spec.lsid))\n\n        return True", "response": "Registers a module specification with the LSID authority."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate(self, lsid, check_existing=True):\n        # Base LSID matches\n        if not lsid.startswith(self.base_lsid):\n            return False\n\n        # Module number isn't already taken\n        if check_existing and lsid in self.registered_modules:\n            return False\n\n        # Everything checks out, return True\n        return True", "response": "Validate an LSID with the LSID authority."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlook up the name of a module by LSID assigned by the authority.", "response": "def lookup(self, lsid):\n        \"\"\"\n        Look up the name of a module by LSID assigned by the authority.\n        Returns None if the LSID is not found.\n        :param lsid:\n        :return: string or none\n        \"\"\"\n        if self.registered_modules is None or lsid not in self.registered_modules:\n            return None\n        else:\n            return self.registered_modules[lsid]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget lock object for given URL host.", "response": "def get_host_lock(url):\n    \"\"\"Get lock object for given URL host.\"\"\"\n    hostname = get_hostname(url)\n    return host_locks.setdefault(hostname, threading.Lock())"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint warning about interrupt and empty the job queue.", "response": "def finish():\n    \"\"\"Print warning about interrupt and empty the job queue.\"\"\"\n    out.warn(\"Interrupted!\")\n    for t in threads:\n        t.stop()\n    jobs.clear()\n    out.warn(\"Waiting for download threads to finish.\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget all scraper objects for the given comics.", "response": "def getScrapers(comics, basepath=None, adult=True, multiple_allowed=False, listing=False):\n    \"\"\"Get scraper objects for the given comics.\"\"\"\n    if '@' in comics:\n        # only scrapers whose directory already exists\n        if len(comics) > 1:\n            out.warn(u\"using '@' as comic name ignores all other specified comics.\")\n        for scraperclass in scraper.get_scraperclasses():\n            dirname = getDirname(scraperclass.getName())\n            if os.path.isdir(os.path.join(basepath, dirname)):\n                if shouldRunScraper(scraperclass, adult, listing):\n                    yield scraperclass()\n    elif '@@' in comics:\n        # all scrapers\n        for scraperclass in scraper.get_scraperclasses():\n            if shouldRunScraper(scraperclass, adult, listing):\n                yield scraperclass()\n    else:\n        # get only selected comic scrapers\n        # store them in a set to eliminate duplicates\n        scrapers = set()\n        for comic in comics:\n            # Helpful when using shell completion to pick comics to get\n            comic = comic.rstrip(os.path.sep)\n            if basepath and comic.startswith(basepath):\n                # make the following command work:\n                # find Comics -type d | xargs -n1 -P10 dosage -b Comics\n                comic = comic[len(basepath):].lstrip(os.sep)\n            if ':' in comic:\n                name, index = comic.split(':', 1)\n                indexes = index.split(',')\n            else:\n                name = comic\n                indexes = None\n            scraperclasses = scraper.find_scraperclasses(name, multiple_allowed=multiple_allowed)\n            for scraperclass in scraperclasses:\n                if shouldRunScraper(scraperclass, adult, listing):\n                    scraperobj = scraperclass(indexes=indexes)\n                    if scraperobj not in scrapers:\n                        scrapers.add(scraperobj)\n                        yield scraperobj"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef warn_disabled(scraperclass, reasons):\n    out.warn(u\"Skipping comic %s: %s\" % (scraperclass.getName(), ' '.join(reasons.values())))", "response": "Print warning about disabled comic modules."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef join(self, timeout=None):\n        self.all_tasks_done.acquire()\n        try:\n            while self.unfinished_tasks:\n                self.all_tasks_done.wait(timeout)\n        finally:\n            self.all_tasks_done.release()", "response": "Blocks until all items in the Queue have been processed and all work on it has been done."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove all entries from the queue.", "response": "def clear(self):\n        \"\"\"Remove all queue entries.\"\"\"\n        self.mutex.acquire()\n        self.queue.clear()\n        self.mutex.release()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run(self):\n        try:\n            while not self.stopped:\n                scraperobj = jobs.get(False)\n                self.setName(scraperobj.getName())\n                try:\n                    self.getStrips(scraperobj)\n                finally:\n                    jobs.task_done()\n                    self.setName(self.origname)\n        except Empty:\n            pass\n        except KeyboardInterrupt:\n            thread.interrupt_main()", "response": "Process from queue until it is empty."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _getStrips(self, scraperobj):\n        if self.options.all or self.options.cont:\n            numstrips = None\n        elif self.options.numstrips:\n            numstrips = self.options.numstrips\n        else:\n            # get current strip\n            numstrips = 1\n        try:\n            if scraperobj.isComplete(self.options.basepath):\n                out.info(u\"All comics are already downloaded.\")\n                return 0\n            for strip in scraperobj.getStrips(numstrips):\n                skipped = self.saveComicStrip(strip)\n                if skipped and self.options.cont:\n                    # stop when retrieval skipped an image for one comic strip\n                    out.info(u\"Stop retrieval because image file already exists\")\n                    break\n                if self.stopped:\n                    break\n            if self.options.all and not (self.errors or self.options.dry_run or\n                                    self.options.cont or scraperobj.indexes):\n                scraperobj.setComplete(self.options.basepath)\n        except Exception as msg:\n            out.exception(msg)\n            self.errors += 1", "response": "Get all strips from a scraper."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsaves a comic strip which can consist of multiple images.", "response": "def saveComicStrip(self, strip):\n        \"\"\"Save a comic strip which can consist of multiple images.\"\"\"\n        allskipped = True\n        for image in strip.getImages():\n            try:\n                if self.options.dry_run:\n                    filename, saved = \"\", False\n                else:\n                    filename, saved = image.save(self.options.basepath)\n                if saved:\n                    allskipped = False\n                if self.stopped:\n                    break\n            except Exception as msg:\n                out.exception('Could not save image at %s to %s: %r' % (image.referrer, image.filename, msg))\n                self.errors += 1\n        return allskipped"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef merge(var1, var2):\n    out = {}\n    out['value'] = var2.get('value', var1.get('value', None))\n    out['mimetype'] = var2.get('mimetype', var1.get('mimetype', None))\n    out['types'] = var2.get('types') + [x for x in var1.get('types') if x not in var2.get('types')]\n    out['optional'] = var2.get('optional', var1.get('optional', False))\n    out['filename'] = var2.get('filename', var2.get('filename', None))\n    return Variable(var1.default_type, **out)", "response": "Merge two variables into a single variable."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef has_value_of_type(self, var_type):\n        if self.has_value() and self.has_type(var_type):\n            return True\n        return False", "response": "Returns True if the variable has a value of the given type."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a list of the names of the optional variables in this class.", "response": "def optional_names(self):\n        \"\"\"\n        Get a list of the variables that are defined, but not required\n        \"\"\"\n        for name, var in self.items():\n            if var.get('optional', False):\n                yield name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomposing a string showing the optional variables", "response": "def optional_namestring(self):\n        \"\"\"\n        Compose a string showing the optional variables (helper for the\n        API printing function)\n        \"\"\"\n        opt_names = list(self.optional_names())\n        if opt_names:\n            return '[, {}]'.format(', '.join(opt_names))\n        else:\n            return ''"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef types(self):\n        output = set()\n        for var in self.values():\n            if var.has_value():\n                output.update(var.types())\n        return list(output)", "response": "Returns a list of all the variable types that exist in the Variables object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef vals(self, var_type):\n        return {x: y for x, y in self.items() if y.has_value_of_type(var_type)}", "response": "Create a dictionary with name / value pairs listing the available variables of a particular type."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add(self, **kwargs):\n        for name, var in kwargs.items():\n            if iskeyword(name):\n                var['name'] = name\n                name = '_' + name\n            if name in self:\n                self[name] = merge(self[name], Variable(self.default_type, **var))\n            else:\n                self[name] = Variable(self.default_type, **var)\n        return self", "response": "Add additional Variables to the Variables\n        object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fill_arg(self, *args):\n        missing = self.missing_vars()\n        if len(args) == len(missing) == 1:\n            self.setval(missing[0], args[0])", "response": "Fill the value of the key with the value from the given arguments."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfill empty variable objects by name with the values from any present keyword arguments.", "response": "def fill_kwargs(self, **kwargs):\n        \"\"\"\n        Fill empty variable objects by name with the values from\n        any present keyword arguments.\n        \"\"\"\n        for var, val in kwargs.items():\n            self.setval(var, val)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntakes args and kwargs and fill up any variables that don t have a value yet.", "response": "def fill(self, *args, **kwargs):\n        \"\"\"\n        Take args and kwargs and fill up any variables that\n        don't have a value yet.\n        \"\"\"\n        self.fill_kwargs(**kwargs)\n        self.fill_arg(*args)\n        self.assert_full()\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef setval(self, varname, value):\n        if varname in self:\n            self[varname]['value'] = value\n        else:\n            self[varname] = Variable(self.default_type, value=value)", "response": "Set the value of the variable with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a chart object", "response": "def chart(self, x=None, y=None, chart_type=None, opts=None,\n\t\t\t  style=None, label=None, options={}, **kwargs):\n\t\t\"\"\"\n\t\tGet a chart\n\t\t\"\"\"\n\t\ttry:\n\t\t\tself.chart_obj = self._chart(x, y, chart_type, opts, style, label,\n\t\t\t\t\t\t\t\t\t\t options=options, **kwargs)\n\t\texcept Exception as e:\n\t\t\tself.err(e, self.chart, \"Can not create chart\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _chart(self, x, y, chart_type, opts, style, label, options, **kwargs):\n\t\tif opts is not None:\n\t\t\tself.chart_opts = opts\n\t\tif style is not None:\n\t\t\tself.chart_style = style\n\t\tif label is not None:\n\t\t\tself.label = label\n\t\tself.x = x\n\t\tself.y = y\n\t\tif chart_type is None:\n\t\t\treturn\n\t\ttry:\n\t\t\tchart_obj = self._get_chart(chart_type, x, y, style=style,\n\t\t\t\t\t\t\t\t\t\topts=opts, label=label,\n\t\t\t\t\t\t\t\t\t\toptions=options, **kwargs)\n\t\t\treturn chart_obj\n\t\texcept Exception as e:\n\t\t\tself.err(e)", "response": "Internal function to get a chart object"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting a bar chart", "response": "def bar_(self, label=None, style=None, opts=None, options={}):\n\t\t\"\"\"\n\t\tGet a bar chart\n\t\t\"\"\"\n\t\ttry:\n\t\t\treturn self._get_chart(\"bar\", style=style, opts=opts, label=label,\n\t\t\t\t\t\t\t\t   options=options)\n\t\texcept Exception as e:\n\t\t\tself.err(e, self.bar_, \"Can not draw bar chart\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sbar_(self, stack_index=None, label=None, style=None, opts=None,\n\t\t\t  options={}):\n\t\t\"\"\"\n\t\tGet a stacked bar chart\n\t\t\"\"\"\n\t\tself.opts(dict(stack_index=stack_index, color_index=stack_index))\n\t\ttry:\n\t\t\tif stack_index is None:\n\t\t\t\tself.err(self.sbar_, \"Please provide a stack index parameter\")\n\t\t\toptions[\"stack_index\"] = stack_index\n\t\t\treturn self._get_chart(\"bar\", style=style, opts=opts, label=label,\n\t\t\t\t\t\t\t\t   options=options)\n\t\texcept Exception as e:\n\t\t\tself.err(e, self.sbar_, \"Can not draw stacked bar chart\")", "response": "Get a stacked bar chart"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndrawing a chart to visualize quantiles", "response": "def quants_(self, inf, sup, chart_type=\"point\",\n\t\t\t\tcolor=\"green\"):\n\t\t\"\"\"\n\t\tDraw a chart to visualize quantiles\n\t\t\"\"\"\n\t\ttry:\n\t\t\treturn self._bokeh_quants(inf, sup, chart_type, color)\n\t\texcept Exception as e:\n\t\t\tself.err(e, self.quants_, \"Can not draw quantile chart\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sline_(self, window_size=5,\n\t\t\t   y_label=\"Moving average\", chart_label=None):\n\t\t\"\"\"\n\t\tGet a moving average curve chart to smooth between points\n\t\t\"\"\"\n\t\toptions = dict(window_size=window_size, y_label=y_label)\n\t\ttry:\n\t\t\treturn self._get_chart(\"sline\", style=self.chart_style,\n\t\t\t\t\t\t\t\t   opts=self.chart_opts, label=chart_label,\n\t\t\t\t\t\t\t\t   options=options)\n\t\texcept Exception as e:\n\t\t\tself.err(e, self.sline_, \"Can not draw smooth curve chart\")", "response": "Get a moving average curve chart to smooth between points\n\t is a chart with a moving average y_label and y_label"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sarea_(self, col, x=None, y=None, rsum=None, rmean=None):\n\t\ttry:\n\t\t\tcharts = self._multiseries(col, x, y, \"area\", rsum, rmean)\n\t\t\treturn hv.Area.stack(charts)\n\t\texcept Exception as e:\n\t\t\tself.err(e, self.sarea_, \"Can not draw stacked area chart\")", "response": "Get an stacked area chart"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a line and point chart", "response": "def line_point_(self, label=None, style=None, opts=None, options={},\n\t\t\t\t\tcolors={\"line\": \"orange\", \"point\": \"#30A2DA\"}):\n\t\t\"\"\"\n\t\tGet a line and point chart\n\t\t\"\"\"\n\t\ttry:\n\t\t\tif style is None:\n\t\t\t\tstyle = self.chart_style\n\t\t\t\tif \"size\" not in style:\n\t\t\t\t\tstyle[\"size\"] = 10\n\t\t\tstyle[\"color\"] = colors[\"line\"]\n\t\t\tc = self._get_chart(\"line\", style=style, opts=opts,\n\t\t\t\t\t\t\t\tlabel=label, options=options)\n\t\t\tstyle[\"color\"] = colors[\"point\"]\n\t\t\tc2 = self._get_chart(\"point\", style=style, opts=opts,\n\t\t\t\t\t\t\t\t label=label, options=options)\n\t\t\treturn c * c2\n\t\texcept Exception as e:\n\t\t\tself.err(e, self.line_point_, \"Can not draw line_point chart\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsplits a column into multiple series based on the column's unique values. Then visualize theses series in a chart. Parameters: column to split, x axis column, y axis column Optional: rsum=\"1D\" to resample and sum data an rmean=\"1D\" to mean the data", "response": "def mpoint_(self, col, x=None, y=None, rsum=None, rmean=None):\n\t\t\"\"\"\n\t\tSplits a column into multiple series based on the column's\n\t\tunique values. Then visualize theses series in a chart.\n\t\tParameters: column to split, x axis column, y axis column\n\t\tOptional: rsum=\"1D\" to resample and sum data an rmean=\"1D\"\n\t\tto mean the data\n\t\t\"\"\"\n\t\treturn self._multiseries(col, x, y, \"point\", rsum, rmean)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsplit a column into multiple series based on the column's unique values. Then visualize theses series in a chart. Parameters: column to split, x axis column, y axis column Optional: rsum=\"1D\" to resample and sum data an rmean=\"1D\" to mean the data", "response": "def mline_(self, col, x=None, y=None, rsum=None, rmean=None):\n\t\t\"\"\"\n\t\tSplits a column into multiple series based on the column's\n\t\tunique values. Then visualize theses series in a chart.\n\t\tParameters: column to split, x axis column, y axis column\n\t\tOptional: rsum=\"1D\" to resample and sum data an rmean=\"1D\"\n\t\tto mean the data\n\t\t\"\"\"\n\t\treturn self._multiseries(col, x, y, \"line\", rsum, rmean)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsplit a column into multiple series based on the column's unique values. Then visualize theses series in a chart. Parameters: column to split, x axis column, y axis column Optional: rsum=\"1D\" to resample and sum data an rmean=\"1D\" to mean the data", "response": "def mbar_(self, col, x=None, y=None, rsum=None, rmean=None):\n\t\t\"\"\"\n\t\tSplits a column into multiple series based on the column's\n\t\tunique values. Then visualize theses series in a chart.\n\t\tParameters: column to split, x axis column, y axis column\n\t\tOptional: rsum=\"1D\" to resample and sum data an rmean=\"1D\"\n\t\tto mean the data\n\t\t\"\"\"\n\t\treturn self._multiseries(col, x, y, \"bar\", rsum, rmean)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsplit a column into multiple series based on the column's unique values. Then visualize theses series in a chart. Parameters: column to split, x axis column, y axis column Optional: rsum=\"1D\" to resample and sum data an rmean=\"1D\" to mean the data", "response": "def mline_point_(self, col, x=None, y=None, rsum=None, rmean=None):\n\t\t\"\"\"\n\t\tSplits a column into multiple series based on the column's\n\t\tunique values. Then visualize theses series in a chart.\n\t\tParameters: column to split, x axis column, y axis column\n\t\tOptional: rsum=\"1D\" to resample and sum data an rmean=\"1D\"\n\t\tto mean the data\n\t\t\"\"\"\n\t\tline = self._multiseries(col, x, y, \"line\", rsum, rmean)\n\t\tpoint = self._multiseries(col, x, y, \"point\", rsum, rmean)\n\t\treturn line * point"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef arrow_(self, xloc, yloc, text, orientation=\"v\", arrowstyle='->'):\n\t\ttry:\n\t\t\tarrow = hv.Arrow(\n\t\t\t\txloc,\n\t\t\t\tyloc,\n\t\t\t\ttext,\n\t\t\t\torientation,\n\t\t\t\tarrowstyle=arrowstyle)\n\t\t\treturn arrow\n\t\texcept Exception as e:\n\t\t\tself.err(e, self.arrow_, \"Can not draw arrow chart\")", "response": "Function to draw an arrow chart"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _multiseries(self, col, x, y, ctype, rsum, rmean):\n\t\tself.autoprint = False\n\t\tx, y = self._check_fields(x, y)\n\t\tchart = None\n\t\tseries = self.split_(col)\n\t\tfor key in series:\n\t\t\tinstance = series[key]\n\t\t\tif rsum is not None:\n\t\t\t\tinstance.rsum(rsum, index_col=x)\n\t\t\tif rmean is not None:\n\t\t\t\tinstance.rmean(rmean, index_col=x)\n\t\t\tinstance.chart(x, y)\n\t\t\tself.scolor()\n\t\t\tc = None\n\t\t\tlabel = str(key)\n\t\t\tif ctype == \"point\":\n\t\t\t\tc = instance.point_(label)\n\t\t\tif ctype == \"line\":\n\t\t\t\tinstance.zero_nan(y)\n\t\t\t\tc = instance.line_(label)\n\t\t\tif ctype == \"bar\":\n\t\t\t\tc = instance.bar_(label)\n\t\t\tif ctype == \"area\":\n\t\t\t\tc = instance.area_(label)\n\t\t\tif c is None:\n\t\t\t\tself.warning(\"Chart type \" + ctype + \n\t\t\t\t\t\t\t \" not supported, aborting\")\n\t\t\t\treturn\n\t\t\tif chart is None:\n\t\t\t\tchart = c\n\t\t\telse:\n\t\t\t\tchart = chart * c\n\t\treturn chart", "response": "This function is used to create a chart from a column distinct values. It will create a chart from a column distinct values."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef distrib_(self, label=None, style=None, opts=None):\n\t\ttry:\n\t\t\treturn self._get_chart(\"distribution\", style=style, opts=opts, label=label)\n\t\texcept Exception as e:\n\t\t\tself.err(e, \"Can not draw distrinution chart\")", "response": "Get a Seaborn distribution chart"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef opts(self, dictobj):\n\t\tfor k in dictobj:\n\t\t\tself.chart_opts[k] = dictobj[k]", "response": "Add or update options"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd or update styles", "response": "def styles(self, dictobj):\n\t\t\"\"\"\n\t\tAdd or update styles\n\t\t\"\"\"\n\t\tfor k in dictobj:\n\t\t\tself.chart_style[k] = dictobj[k]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove one option from the chart", "response": "def ropt(self, name):\n\t\t\"\"\"\n\t\tRemove one option\n\t\t\"\"\"\n\t\ttry:\n\t\t\tdel self.chart_opts[name]\n\t\texcept KeyError:\n\t\t\tself.warning(\"Option \" + name + \" is not set\")\n\t\texcept:\n\t\t\tself.err(\"Can not remove option \" + name)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rstyle(self, name):\n\t\ttry:\n\t\t\tdel self.chart_style[name]\n\t\texcept KeyError:\n\t\t\tself.warning(\"Style \" + name + \" is not set\")\n\t\texcept:\n\t\t\tself.err(\"Can not remove style \" + name)", "response": "Remove one style from the chart"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef defaults(self):\n\t\tself.chart_style = {}\n\t\tself.chart_opts = {}\n\t\tself.style(\"color\", \"#30A2DA\")\n\t\tself.width(900)\n\t\tself.height(250)", "response": "Reset the chart options style and width to defaults"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _check_fields(self, x, y):\n\t\tif x is None:\n\t\t\tif self.x is None:\n\t\t\t\tself.err(\n\t\t\t\t\tself._check_fields,\n\t\t\t\t\t\"X field is not set: please specify a parameter\")\n\t\t\t\treturn\n\t\t\tx = self.x\n\t\tif y is None:\n\t\t\tif self.y is None:\n\t\t\t\tself.err(\n\t\t\t\t\tself._check_fields,\n\t\t\t\t\t\"Y field is not set: please specify a parameter\")\n\t\t\t\treturn\n\t\t\ty = self.y\n\t\treturn x, y", "response": "check x and y fields parameters and initialize\n\tif"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting a chart object from the chart object.", "response": "def _get_chart(self, chart_type, x=None, y=None, style=None, opts=None,\n\t\t\t\t   label=None, options={}, **kwargs):\n\t\t\"\"\"\n\t\tGet a full chart object\n\t\t\"\"\"\n\t\tsbcharts = [\"density\", \"distribution\", \"dlinear\"]\n\t\tacharts = [\"tick\", \"circle\", \"text\", \"line_num\", \"bar_num\"]\n\t\tif chart_type in sbcharts:\n\t\t\tself._set_seaborn_engine()\n\t\tif chart_type in acharts:\n\t\t\tself._set_altair_engine()\n\t\tif chart_type != \"sline\":\n\t\t\tx, y = self._check_fields(x, y)\n\t\tif opts is None:\n\t\t\topts = self.chart_opts\n\t\tif style is None:\n\t\t\tstyle = self.chart_style\n\t\tif self.engine == \"bokeh\":\n\t\t\tfunc = self._get_bokeh_chart\n\t\telif self.engine == \"altair\":\n\t\t\tfunc = self._get_altair_chart\n\t\telif self.engine == \"chartjs\":\n\t\t\tfunc = self._get_chartjs_chart\n\t\telif self.engine == \"seaborn\":\n\t\t\tfunc = self._get_seaborn_chart\n\t\telse:\n\t\t\tself.err(\"Engine \" + self.engine + \" unknown\")\n\t\t\treturn\n\t\ttry:\n\t\t\tchart = func(\n\t\t\t\tx, y, chart_type, label, opts, style,\n\t\t\t\toptions=options, **kwargs)\n\t\t\treturn chart\n\t\texcept Exception as e:\n\t\t\tself.err(e)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _check_defaults(self, x_only=True):\n\t\tif self.x is None:\n\t\t\tself.err(self._check_defaults,\n\t\t\t\t\t \"X field is not set: please specify a parameter\")\n\t\t\treturn\n\t\tif x_only is True:\n\t\t\treturn\n\t\tif self.y is None:\n\t\t\tself.err(self._check_defaults,\n\t\t\t\t\t \"Y field is not set: please specify a parameter\")\n\t\t\treturn", "response": "Checks if charts defaults are set"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getIndexStripUrl(self, index):\n        chapter, num = index.split('-')\n        return self.stripUrl % (chapter, chapter, num)", "response": "Get comic strip URL from index."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_flags(self, *flags):\n        if not isinstance(flags, (list, tuple)):\n            flags = [str(flags)]\n\n        self.extend([\"--%s\" % f for f in flags])\n        return self", "response": "Adds one or more flags to the query."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef search(self, q, language=None, current_site_only=True):\n        from cms.plugin_pool import plugin_pool\n\n        qs = self.get_queryset()\n        qs = qs.public()\n\n        if current_site_only:\n            site = Site.objects.get_current()\n            qs = qs.filter(tree__site=site)\n\n        qt = Q(title_set__title__icontains=q)\n\n        # find 'searchable' plugins and build query\n        qp = Q()\n        plugins = plugin_pool.get_all_plugins()\n        for plugin in plugins:\n            cmsplugin = plugin.model\n            if not (\n                hasattr(cmsplugin, 'search_fields') and\n                hasattr(cmsplugin, 'cmsplugin_ptr')\n            ):\n                continue\n            field = cmsplugin.cmsplugin_ptr.field\n            related_query_name = field.related_query_name()\n            if related_query_name and not related_query_name.startswith('+'):\n                for field in cmsplugin.search_fields:\n                    qp |= Q(**{\n                        'placeholders__cmsplugin__{0}__{1}__icontains'.format(\n                            related_query_name,\n                            field,\n                        ): q})\n        if language:\n            qt &= Q(title_set__language=language)\n            qp &= Q(cmsplugin__language=language)\n\n        qs = qs.filter(qt | qp)\n\n        return qs.distinct()", "response": "Simple search function that returns a queryset of all available items that match the query."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_title(self, article, language, language_fallback=False):\n        try:\n            title = self.get(language=language, article=article)\n            return title\n        except self.model.DoesNotExist:\n            if language_fallback:\n                try:\n                    titles = self.filter(article=article)\n                    fallbacks = get_fallback_languages(language)\n                    for lang in fallbacks:\n                        for title in titles:\n                            if lang == title.language:\n                                return title\n                    return None\n                except self.model.DoesNotExist:\n                    pass\n            else:\n                raise\n        return None", "response": "Gets the latest content for a particular article and language. Falls back to another language."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting or create a title for a particular article and language", "response": "def set_or_create(self, request, article, form, language):\n        \"\"\"\n        set or create a title for a particular article and language\n        \"\"\"\n        base_fields = [\n            'slug',\n            'title',\n            'description',\n            'meta_description',\n            'page_title',\n            'menu_title',\n            'image',\n        ]\n        cleaned_data = form.cleaned_data\n        try:\n            obj = self.get(article=article, language=language)\n        except self.model.DoesNotExist:\n            data = {}\n            for name in base_fields:\n                if name in cleaned_data:\n                    data[name] = cleaned_data[name]\n            data['article'] = article\n            data['language'] = language\n            return self.create(**data)\n        for name in base_fields:\n            if name in form.base_fields:\n                value = cleaned_data.get(name, None)\n                setattr(obj, name, value)\n        obj.save()\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef auth_user_ldap(uname, pwd):\n    if not uname or not pwd:\n        logging.error(\"Username or password not supplied\")\n        return False\n\n    ld = ldap.initialize(LDAP_URL)\n    if LDAP_VERSION_3:\n        ld.set_option(ldap.VERSION3, 1)\n    ld.start_tls_s()\n    udn = ld.search_s(LDAP_SEARCH_BASE, ldap.SCOPE_ONELEVEL,\n                           '(%s=%s)' % (LDAP_UNAME_ATTR,uname), [LDAP_BIND_ATTR])\n    if udn:\n        try:\n            bindres = ld.simple_bind_s(udn[0][0], pwd)\n        except ldap.INVALID_CREDENTIALS, ldap.UNWILLING_TO_PERFORM:\n            logging.error(\"Invalid or incomplete credentials for %s\", uname)\n            return False\n        except Exception as out:\n            logging.error(\"Auth attempt for %s had an unexpected error: %s\",\n                         uname, out)\n            return False\n        else:\n            return True\n    else:\n        logging.error(\"No user by that name\")\n        return False", "response": "Authenticates a user using LDAP."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a unique ID to identify a system.", "response": "def get_system_uid():\n    \"\"\"Get a (probably) unique ID to identify a system.\n    Used to differentiate votes.\n    \"\"\"\n    try:\n        if os.name == 'nt':\n            return get_nt_system_uid()\n        if sys.platform == 'darwin':\n            return get_osx_system_uid()\n    except Exception:\n        return get_mac_uid()\n    else:\n        return get_mac_uid()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the MachineGuid from the NtSystemUID registry", "response": "def get_nt_system_uid():\n    \"\"\"Get the MachineGuid from\n    HKEY_LOCAL_MACHINE\\Software\\Microsoft\\Cryptography\\MachineGuid\n    \"\"\"\n    try:\n        import _winreg as winreg\n    except ImportError:\n        import winreg\n    lm = winreg.ConnectRegistry(None, winreg.HKEY_LOCAL_MACHINE)\n    try:\n        key = winreg.OpenKey(lm, r\"Software\\Microsoft\\Cryptography\")\n        try:\n            return winreg.QueryValueEx(key, \"MachineGuid\")[0]\n        finally:\n            key.Close()\n    finally:\n        lm.Close()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the OSX system ID.", "response": "def get_osx_system_uid():\n    \"\"\"Get the OSX system ID.\n    $ system_profiler |grep \"r (system)\"\n    Serial Number (system): C24E1322XYZ\n    \"\"\"\n    res = backtick([\"system_profile\"]).splitlines()\n    for line in res:\n        if \"r (system)\" in line:\n            return line.split(':', 1)[1].strip()\n    raise ValueError(\"Could not find system number in %r\" % res)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndecoding text to Unicode if not already done.", "response": "def unicode_safe(text, encoding=UrlEncoding, errors='ignore'):\n    \"\"\"Decode text to Unicode if not already done.\"\"\"\n    try:\n        text_type = unicode\n    except NameError:\n        text_type = str\n    if isinstance(text, text_type):\n        return text\n    return text.decode(encoding, errors)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tagre(tag, attribute, value, quote='\"', before=\"\", after=\"\"):\n    if before:\n        prefix = r\"[^>]*%s[^>]*\\s+\" % before\n    else:\n        prefix = r\"(?:[^>]*\\s+)?\"\n    attrs = dict(\n        tag=case_insensitive_re(tag),\n        attribute=case_insensitive_re(attribute),\n        value=value,\n        quote=quote,\n        prefix=prefix,\n        after=after,\n    )\n    return r'<\\s*%(tag)s\\s+%(prefix)s%(attribute)s\\s*=\\s*%(quote)s%(value)s%(quote)s[^>]*%(after)s[^>]*>' % attrs", "response": "Return a regular expression matching the given HTML tag attribute and value."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting text content of given URL.", "response": "def getPageContent(url, session, max_content_bytes=MaxContentBytes):\n    \"\"\"Get text content of given URL.\"\"\"\n    check_robotstxt(url, session)\n    # read page data\n    try:\n        page = urlopen(url, session, max_content_bytes=max_content_bytes)\n    except IOError:\n        page = urlopen(url, session, max_content_bytes=max_content_bytes)\n    data = page.text\n    tries = MaxRetries\n    while not isValidPageContent(data) and tries > 0:\n        time.sleep(RetryPauseSeconds)\n        page = urlopen(url, session, max_content_bytes=max_content_bytes)\n        data = page.text\n        tries -= 1\n    if not isValidPageContent(data):\n        raise ValueError(\"Got invalid page content from %s: %r\" % (url, data))\n    out.debug(u\"Got page content %r\" % data, level=3)\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting response object for given image URL.", "response": "def getImageObject(url, referrer, session, max_content_bytes=MaxImageBytes):\n    \"\"\"Get response object for given image URL.\"\"\"\n    return urlopen(url, session, referrer=referrer, max_content_bytes=max_content_bytes, stream=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef prettyMatcherList(things):\n    norm = []\n    for x in makeSequence(things):\n        if hasattr(x, 'pattern'):\n            norm.append(x.pattern)\n        else:\n            norm.append(x)\n    return \"('%s')\" % \"', '\".join(norm)", "response": "Try to construct a nicely - formatted string for a list of matcher objects. Those may be compiled regular expressions or strings..."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef normaliseURL(url):\n    url = unicode_safe(url).strip()\n    # XXX: brutal hack\n    url = unescape(url)\n\n    pu = list(urlparse(url))\n    segments = pu[2].split('/')\n    while segments and segments[0] in ('', '..'):\n        del segments[0]\n    pu[2] = '/' + '/'.join(segments)\n    # remove leading '&' from query\n    if pu[4].startswith('&'):\n        pu[4] = pu[4][1:]\n    # remove anchor\n    pu[5] = \"\"\n    return urlunparse(pu)", "response": "Normalise a URL to be a valid URL."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if robots. txt allows our user agent for the given URL.", "response": "def check_robotstxt(url, session):\n    \"\"\"Check if robots.txt allows our user agent for the given URL.\n    @raises: IOError if URL is not allowed\n    \"\"\"\n    roboturl = get_roboturl(url)\n    rp = get_robotstxt_parser(roboturl, session=session)\n    if not rp.can_fetch(UserAgent, str(url)):\n        raise IOError(\"%s is disallowed by %s\" % (url, roboturl))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a RobotFileParser for the given robots. txt URL.", "response": "def get_robotstxt_parser(url, session=None):\n    \"\"\"Get a RobotFileParser for the given robots.txt URL.\"\"\"\n    rp = robotparser.RobotFileParser()\n    try:\n        req = urlopen(url, session, max_content_bytes=MaxContentBytes, raise_for_status=False)\n    except Exception:\n        # connect or timeout errors are treated as an absent robots.txt\n        rp.allow_all = True\n    else:\n        if req.status_code >= 400:\n            rp.allow_all = True\n        elif req.status_code == 200:\n            rp.parse(req.text.splitlines())\n    return rp"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nopens an URL and return the response object.", "response": "def urlopen(url, session, referrer=None, max_content_bytes=None,\n            timeout=ConnectionTimeoutSecs, raise_for_status=True,\n            stream=False, data=None, useragent=UserAgent):\n    \"\"\"Open an URL and return the response object.\"\"\"\n    out.debug(u'Open URL %s' % url)\n    headers = {'User-Agent': useragent}\n    if referrer:\n        headers['Referer'] = referrer\n    out.debug(u'Sending headers %s' % headers, level=3)\n    out.debug(u'Sending cookies %s' % session.cookies)\n    kwargs = {\n        \"headers\": headers,\n        \"timeout\": timeout,\n    }\n    if hasattr(requests, 'adapters'):\n        # requests >= 1.0\n        kwargs[\"stream\"] = stream\n    else:\n        # requests << 1.0\n        kwargs[\"prefetch\"] = not stream\n        kwargs[\"config\"] = {\"max_retries\": MaxRetries}\n    if data is None:\n        func = session.get\n    else:\n        kwargs['data'] = data\n        func = session.post\n        out.debug(u'Sending POST data %s' % data, level=3)\n    try:\n        req = func(url, **kwargs)\n        out.debug(u'Response cookies: %s' % req.cookies)\n        check_content_size(url, req.headers, max_content_bytes)\n        if raise_for_status:\n            req.raise_for_status()\n        return req\n    except requests.exceptions.RequestException as err:\n        msg = 'URL retrieval of %s failed: %s' % (url, err)\n        raise IOError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_content_size(url, headers, max_content_bytes):\n    if not max_content_bytes:\n        return\n    if 'content-length' in headers:\n        size = int(headers['content-length'])\n        if size > max_content_bytes:\n            msg = 'URL content of %s with %d bytes exceeds %d bytes.' % (url, size, max_content_bytes)\n            raise IOError(msg)", "response": "Check that the content length in the response headers do not exceed the max_content_bytes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsplitting a path in its components.", "response": "def splitpath(path):\n    \"\"\"Split a path in its components.\"\"\"\n    c = []\n    head, tail = os.path.split(path)\n    while tail:\n        c.insert(0, tail)\n        head, tail = os.path.split(head)\n    return c"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a path that is relative to the given base path.", "response": "def getRelativePath(basepath, path):\n    \"\"\"Get a path that is relative to the given base path.\"\"\"\n    basepath = splitpath(os.path.abspath(basepath))\n    path = splitpath(os.path.abspath(path))\n    afterCommon = False\n    for c in basepath:\n        if afterCommon or path[0] != c:\n            path.insert(0, os.path.pardir)\n            afterCommon = True\n        else:\n            del path[0]\n    return os.path.join(*path)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting URL query parameters.", "response": "def getQueryParams(url):\n    \"\"\"Get URL query parameters.\"\"\"\n    query = urlsplit(url)[3]\n    out.debug(u'Extracting query parameters from %r (%r)...' % (url, query))\n    return cgi.parse_qs(query)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef internal_error(out=sys.stderr, etype=None, evalue=None, tb=None):\n    print(os.linesep, file=out)\n    print(\"\"\"********** Oops, I did it again. *************\n\nYou have found an internal error in %(app)s. Please write a bug report\nat %(url)s and include at least the information below:\n\nNot disclosing some of the information below due to privacy reasons is ok.\nI will try to help you nonetheless, but you have to give me something\nI can work with ;) .\n\"\"\" % dict(app=AppName, url=SupportUrl), file=out)\n    if etype is None:\n        etype = sys.exc_info()[0]\n    if evalue is None:\n        evalue = sys.exc_info()[1]\n    print(etype, evalue, file=out)\n    if tb is None:\n        tb = sys.exc_info()[2]\n    traceback.print_exception(etype, evalue, tb, None, out)\n    print_app_info(out=out)\n    print_proxy_info(out=out)\n    print_locale_info(out=out)\n    print(os.linesep,\n            \"******** %s internal error, over and out ********\" % AppName, file=out)", "response": "Print internal error message."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef unquote(text):\n    while '%' in text:\n        newtext = url_unquote(text)\n        if newtext == text:\n            break\n        text = newtext\n    return text", "response": "Replace all percent - encoded entities in text."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn human representation of bytes b. A negative number of bytes raises a value error.", "response": "def strsize (b):\n    \"\"\"Return human representation of bytes b. A negative number of bytes\n    raises a value error.\"\"\"\n    if b < 0:\n        raise ValueError(\"Invalid negative byte number\")\n    if b < 1024:\n        return \"%dB\" % b\n    if b < 1024 * 10:\n        return \"%dKB\" % (b // 1024)\n    if b < 1024 * 1024:\n        return \"%.2fKB\" % (float(b) / 1024)\n    if b < 1024 * 1024 * 10:\n        return \"%.2fMB\" % (float(b) / (1024*1024))\n    if b < 1024 * 1024 * 1024:\n        return \"%.1fMB\" % (float(b) / (1024*1024))\n    if b < 1024 * 1024 * 1024 * 10:\n        return \"%.2fGB\" % (float(b) / (1024*1024*1024))\n    return \"%.1fGB\" % (float(b) / (1024*1024*1024))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a filename from given name without dangerous or incompatible characters.", "response": "def getFilename(name):\n    \"\"\"Get a filename from given name without dangerous or incompatible characters.\"\"\"\n    # first replace all illegal chars\n    name = re.sub(r\"[^0-9a-zA-Z_\\-\\.]\", \"_\", name)\n    # then remove double dots and underscores\n    while \"..\" in name:\n        name = name.replace('..', '.')\n    while \"__\" in name:\n        name = name.replace('__', '_')\n    # remove a leading dot or minus\n    if name.startswith((\".\", \"-\")):\n        name = name[1:]\n    return name"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a filename from a name until file exists.", "response": "def getExistingFile(name, max_suffix=1000):\n    \"\"\"Add filename suffix until file exists\n    @return: filename if file is found\n    @raise: ValueError if maximum suffix number is reached while searching\n    \"\"\"\n    num = 1\n    stem, ext = os.path.splitext(name)\n    filename = name\n    while not os.path.exists(filename):\n        suffix = \"-%d\" % num\n        filename = stem + suffix + ext\n        num += 1\n        if num >= max_suffix:\n            raise ValueError(\"No file %r found\" % name)\n    return filename"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getNonexistingFile(name):\n    num = 1\n    stem, ext = os.path.splitext(name)\n    filename = name\n    while os.path.exists(filename):\n        suffix = \"-%d\" % num\n        filename = stem + suffix + ext\n        num += 1\n    return filename", "response": "Add filename suffix until file not exists"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a string that is limited to length + 3 characters.", "response": "def strlimit (s, length=72):\n    \"\"\"If the length of the string exceeds the given limit, it will be cut\n    off and three dots will be appended.\n\n    @param s: the string to limit\n    @type s: string\n    @param length: maximum length\n    @type length: non-negative integer\n    @return: limited string, at most length+3 characters long\n    \"\"\"\n    assert length >= 0, \"length limit must be a non-negative integer\"\n    if not s or len(s) <= length:\n        return s\n    if length == 0:\n        return \"\"\n    return \"%s...\" % s[:length]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite content to given filename.", "response": "def writeFile(filename, content, encoding=None):\n    \"\"\"Write content to given filename. Checks for zero-sized files.\n    If encoding is given writes to a codec.open() file.\"\"\"\n    if not content:\n        raise OSError(\"empty content for file %s\" % filename)\n\n    def getfp(filename, encoding):\n        \"\"\"Get open file object.\"\"\"\n        if encoding:\n            return codecs.open(filename, 'w', encoding)\n        return open(filename, 'wb')\n\n    try:\n        with getfp(filename, encoding) as fp:\n            fp.write(content)\n            fp.flush()\n            os.fsync(fp.fileno())\n            size = os.path.getsize(filename)\n            if size == 0:\n                raise OSError(\"empty file %s\" % filename)\n    except Exception:\n        if os.path.isfile(filename):\n            os.remove(filename)\n        raise\n    else:\n        out.info(u\"Saved %s (%s).\" % (filename, strsize(size)))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing one search result page.", "response": "def handle_url(url, session, res):\n    \"\"\"Parse one search result page.\"\"\"\n    print(\"Parsing\", url, file=sys.stderr)\n    try:\n        data = getPageContent(url, session)\n    except IOError as msg:\n        print(\"ERROR:\", msg, file=sys.stderr)\n        return\n    for match in url_matcher.finditer(data):\n        url = match.group(1)\n        name = unescape(match.group(2))\n        name = asciify(name.replace('&', 'And').replace('@', 'At'))\n        name = capfirst(name)\n        if name in exclude_comics:\n            continue\n        if contains_case_insensitive(res, name):\n            # we cannot handle two comics that only differ in case\n            print(\"INFO: skipping possible duplicate\", repr(name), file=sys.stderr)\n            continue\n        res[name] = url"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse all search result pages and store results in a dictionary.", "response": "def get_results():\n    \"\"\"Parse all search result pages.\"\"\"\n    # store info in a dictionary {name -> shortname}\n    res = {}\n    session = requests.Session()\n    handle_url('http://www.creators.com/comics/cat-seeall.html', session, res)\n    save_result(res, json_file)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntesting if comic name already exists.", "response": "def has_gocomics_comic(name):\n    \"\"\"Test if comic name already exists.\"\"\"\n    cname = \"Gocomics/%s\" % name\n    for scraperclass in get_scraperclasses():\n        lname = scraperclass.getName().lower()\n        if lname == cname.lower():\n            return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef search_product(self, limit=100, offset=0, with_price=0, with_supported_software=0,\n                       with_description=0):\n        \"\"\"Search the list of available products.\"\"\"\n\n        response = self.request(E.searchProductSslCertRequest(\n            E.limit(limit),\n            E.offset(offset),\n            E.withPrice(int(with_price)),\n            E.withSupportedSoftware(int(with_supported_software)),\n            E.withDescription(int(with_description)),\n        ))\n        return response.as_models(SSLProduct)", "response": "Search the list of available products."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef retrieve_product(self, product_id):\n\n        response = self.request(E.retrieveProductSslCertRequest(\n            E.id(product_id)\n        ))\n\n        return response.as_model(SSLProduct)", "response": "Retrieve details on a single product."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef search_order(self, limit=100, offset=0, common_name_pattern=None, status=None,\n                     contact_handle=None):\n        \"\"\"Search all SSL certificate orders.\"\"\"\n\n        response = self.request(E.searchOrderSslCertRequest(\n            E.limit(limit),\n            E.offset(offset),\n            OE('commonNamePattern', common_name_pattern),\n            OE('status', status, transform=_simple_array),\n            OE('contactHandle', contact_handle),\n        ))\n\n        return response.as_models(SSLOrder)", "response": "Search all SSL certificate orders."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef retrieve_order(self, order_id):\n\n        response = self.request(E.retrieveOrderSslCertRequest(\n            E.id(order_id)\n        ))\n\n        return response.as_model(SSLOrder)", "response": "Retrieve details on a single order."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create(self, product_id, period, csr, software_id, organization_handle,\n               approver_email=None, signature_hash_algorithm=None, domain_validation_methods=None,\n               hostnames=None, technical_handle=None):\n        \"\"\"Order a new SSL certificate.\"\"\"\n\n        response = self.request(E.createSslCertRequest(\n            E.productId(product_id),\n            E.period(period),\n            E.csr(csr),\n            E.softwareId(software_id),\n            E.organizationHandle(organization_handle),\n            OE('approverEmail', approver_email),\n            OE('signatureHashAlgorithm', signature_hash_algorithm),\n            OE('domainValidationMethods', domain_validation_methods, transform=_domain_validation_methods),\n            OE('hostNames', hostnames, transform=_simple_array),\n            OE('technicalHandle', technical_handle),\n        ))\n\n        return int(response.data.id)", "response": "Order a new SSL certificate."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreissuing an SSL certificate order", "response": "def reissue(self, order_id, csr, software_id, organization_handle, approver_email=None,\n                signature_hash_algorithm=None, domain_validation_methods=None, hostnames=None,\n                technical_handle=None):\n        \"\"\"Reissue an SSL certificate order\"\"\"\n\n        response = self.request(E.reissueSslCertRequest(\n            E.id(order_id),\n            E.csr(csr),\n            E.softwareId(software_id),\n            E.organizationHandle(organization_handle),\n            OE('approverEmail', approver_email),\n            OE('signatureHashAlgorithm', signature_hash_algorithm),\n            OE('domainValidationMethods', domain_validation_methods, transform=_domain_validation_methods),\n            OE('hostNames', hostnames, transform=_simple_array),\n            OE('technicalHandle', technical_handle),\n        ))\n\n        return int(response.data.id)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmodifying an ordered SSL certificate.", "response": "def modify(self, order_id, approver_email=None, domain_validation_methods=None):\n        \"\"\"Modify an ordered SSL certificate.\"\"\"\n\n        response = self.request(E.modifySslCertRequest(\n            E.id(order_id),\n            OE('approverEmail', approver_email),\n            OE('domainValidationMethods', domain_validation_methods, transform=_domain_validation_methods),\n        ))\n\n        return response.data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cancel(self, order_id):\n\n        response = self.request(E.cancelSslCertRequest(\n            E.id(order_id)\n        ))\n\n        return int(response.data.id)", "response": "Cancel an ordered SSL certificate."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef retrieve_approver_email_list(self, domain, product_id):\n\n        response = self.request(E.retrieveApproverEmailListSslCertRequest(\n            E.domain(domain),\n            E.productId(product_id)\n        ))\n\n        return [str(i) for i in response.data.array[0].item]", "response": "Retrieve the list of allowed approver email addresses."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef resend_approver_email(self, order_id):\n\n        response = self.request(E.resendApproverEmailSslCertRequest(\n            E.id(order_id)\n        ))\n\n        return int(response.data.id)", "response": "Resend the activation email to the approver."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nchange the approver email address for an ordered SSL certificate.", "response": "def change_approver_email_address(self, order_id, approver_email):\n        \"\"\"Change the approver email address for an ordered SSL certificate.\"\"\"\n\n        response = self.request(\n            E.changeApproverEmailAddressSslCertRequest(\n                E.id(order_id),\n                E.approverEmail(approver_email)\n            )\n        )\n\n        return int(response.data.id)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef decode_csr(self, csr):\n\n        response = self.request(E.decodeCsrSslCertRequest(\n            E.csr(csr)\n        ))\n\n        return response.data", "response": "Decode a CSR and return its data."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_proxies(self, quantity, type):\n        '''\n        quantity: \u6570\u91cf\n        type: \u7c7b\u578b\n            1.\u56fd\u5185\u9ad8\u533f\u4ee3\u7406\n            2.\u56fd\u5185\u666e\u901a\u4ee3\u7406\n            3.\u56fd\u5916\u9ad8\u533f\u4ee3\u7406\n            4.\u56fd\u5916\u666e\u901a\u4ee3\u7406\n        '''\n        url_queue = Queue()\n        need_pages = int(math.ceil(quantity/15))\n        # \u5224\u65ad\u7c7b\u578b\n        if type == 1:\n            # \u56fd\u5185\u9ad8\u533f\u4ee3\u7406\n            base_url = self.domestic_gn_url\n        elif type == 2:\n            # \u56fd\u5185\u666e\u901a\u4ee3\u7406\n            base_url = self.domestic_pt_url\n        elif type == 3:\n            # \u56fd\u5916\u9ad8\u533f\u4ee3\u7406\n            base_url = self.abroad_gn_url\n        elif type == 4:\n            # \u56fd\u5916\u666e\u901a\u4ee3\u7406\n            base_url = self.abroad_pt_url\n        # \u83b7\u53d6\u6240\u9700\u8981\u7684\u9875\u9762URL\n        for index in range(need_pages):\n            url = base_url.format(index+1)\n            url_queue.put(url)\n        # \u5904\u7406\u6240\u6709URL,\u5f00\u542f2\u4e2a\u534f\u7a0b\n        gevent_list = []\n        gevent_list.append(\n            gevent.spawn(self.fetch_urls, url_queue, quantity)\n        )\n        gevent.joinall(gevent_list)", "response": "Get proxies from the domestic GN and ABROTO server."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef log_request(self, handler):\n        if config.LOG_FUNCTION in self.settings:\n            self.settings[config.LOG_FUNCTION](handler)\n            return\n        if handler.get_status() < 400:\n            log_method = LOGGER.info\n        elif handler.get_status() < 500:\n            log_method = LOGGER.warning\n        else:\n            log_method = LOGGER.exception\n        request_time = 1000.0 * handler.request.request_time()\n        log_method(\"%d %s %.2fms\", handler.get_status(),\n                   handler._request_summary(), request_time)", "response": "Writes a completed HTTP request to the logs."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _import_class(self, class_path):\n        LOGGER.debug('Importing %s', class_path)\n        try:\n            return utils.import_namespaced_class(class_path)\n        except ImportError as error:\n            LOGGER.critical('Could not import %s: %s', class_path, error)\n            return None", "response": "Try and import the specified namespaced class."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _insert_base_path(self):\n        if config.BASE in self.paths:\n            sys.path.insert(0, self.paths[config.BASE])", "response": "Insert base path into sys. path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the value of base in paths if the base path is set in the configuration.", "response": "def _prepare_paths(self):\n        \"\"\"Set the value of {{base}} in paths if the base path is set in the\n        configuration.\n\n        :raises: ValueError\n\n        \"\"\"\n        if config.BASE in self.paths:\n            for path in [path for path in self.paths if path != config.BASE]:\n                if config.BASE_VARIABLE in self.paths[path]:\n                    self.paths[path] = \\\n                        self.paths[path].replace(config.BASE_VARIABLE,\n                                                 self.paths[config.BASE])\n        LOGGER.debug('Prepared paths: %r', self.paths)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _prepare_route(self, attrs):\n        if type(attrs) not in (list, tuple):\n            LOGGER.error('Invalid route, must be a list or tuple: %r', attrs)\n            return\n\n        # By default there are not any extra kwargs\n        kwargs = None\n\n        # If there is a regex based route, set it up with a raw string\n        if attrs[0] == 're':\n            route = r'%s' % attrs[1]\n            classpath = attrs[2]\n            if len(attrs) == 4:\n                kwargs = attrs[3]\n        else:\n            route = r'%s' % attrs[0]\n            classpath = attrs[1]\n            if len(attrs) == 3:\n                kwargs = attrs[2]\n\n        LOGGER.debug('Initializing route: %s with %s', route, classpath)\n        try:\n            handler = self._import_class(classpath)\n        except ImportError as error:\n            LOGGER.error('Class import error for %s: %r', classpath, error)\n            return None\n\n        # Setup the prepared route, adding kwargs if there are any\n        prepared_route = [route, handler]\n        if kwargs:\n            prepared_route.append(kwargs)\n\n        # Return the prepared route as a tuple\n        return tuple(prepared_route)", "response": "Takes a given inbound list for a route and parse it creating the route and importing the class it belongs to."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprepare the routes by iterating through the list of tuples and calling them to prepare the route on them.", "response": "def _prepare_routes(self, routes):\n        \"\"\"Prepare the routes by iterating through the list of tuples & calling\n        prepare route on them.\n\n        :param routes: Routes to prepare\n        :type routes: list\n        :rtype: list\n        :raises: ValueError\n\n        \"\"\"\n        if not isinstance(routes, list):\n            raise ValueError('Routes parameter must be a list of tuples')\n        prepared_routes = list()\n        for parts in routes:\n            route = self._prepare_route(parts)\n            if route:\n                LOGGER.info('Appending handler: %r', route)\n                prepared_routes.append(route)\n        return prepared_routes"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _prepare_transforms(self):\n        for offset, value in enumerate(self._config.get(config.TRANSFORMS, [])):\n            self._config[config.TRANSFORMS][offset] = self._import_class(value)", "response": "Prepare the list of transforming objects"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads in translations if they are set and add the default locale as well.", "response": "def _prepare_translations(self):\n        \"\"\"Load in translations if they are set, and add the default locale as\n        well.\n\n        \"\"\"\n        if config.TRANSLATIONS in self.paths:\n            LOGGER.info('Loading translations from %s',\n                        self.paths[config.TRANSLATIONS])\n            from tornado import locale\n            locale.load_translations(self.paths[config.TRANSLATIONS])\n            if config.DEFAULT_LOCALE in self._config:\n                LOGGER.info('Setting default locale to %s',\n                            self._config[config.DEFAULT_LOCALE])\n                locale.set_default_locale(self._config[config.DEFAULT_LOCALE])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _prepare_uimodules(self):\n        for key, value in self._config.get(config.UI_MODULES, {}).iteritems():\n            self._config[config.UI_MODULES][key] = self._import_class(value)\n        self._config[config.UI_MODULES] = dict(self._config[config.UI_MODULES] or {})", "response": "Prepare the UI Modules from a list of namespaced paths."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _prepare_version(self):\n        if config.VERSION not in self._config:\n            self._config[config.VERSION] = __version__", "response": "Setup the application version"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add(self, item, value):\n        if item in self.__dict__[self.ATTRIBUTES].keys():\n            raise AttributeError('%s already exists' % item)\n        setattr(self, item, value)", "response": "Add an attribute value to our object instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves an attribute value to our object instance.", "response": "def remove(self, item):\n        \"\"\"Remove an attribute value to our object instance.\n\n        :param str item: Application attribute name\n        :raises: AttributeError\n\n        \"\"\"\n        if item not in self.__dict__[self.ATTRIBUTES].keys():\n            raise AttributeError('%s does not exist' % item)\n        delattr(self, item)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsearching Splunk with a pre - built query dictionary and wait until it finishes.", "response": "def search(\n        user=None,\n        password=None,\n        token=None,\n        address=None,\n        query_dict=None,\n        verify=False,\n        debug=False):\n    \"\"\"search\n\n    Search Splunk with a pre-built query dictionary and\n    wait until it finishes.\n\n    :param user: splunk username\n    :param password: splunk password\n    :param token: splunk token\n    :param address: splunk HEC address: localhost:8089\n    :param query_dict: query dictionary to search\n    :param verify: ssl verify\n    :param debug: debug flag\n    \"\"\"\n\n    response_dict = None\n    res = {\n        'status': NOT_RUN,\n        'err': '',\n        'record': response_dict\n    }\n    try:\n        url = 'https://{}'.format(\n            address)\n\n        if not token:\n            try:\n                token = get_session_key.get_session_key(\n                    user=user,\n                    password=password,\n                    url=url,\n                    verify=verify)\n            except Exception as f:\n                res['err'] = (\n                    'Failed to get splunk token for user={} url={} '\n                    'ex={}').format(\n                        user,\n                        url,\n                        f)\n                res['status'] = ERR\n                return res\n        # end of trying to login to get a valid token\n\n        auth_header = {\n            'Authorization': 'Splunk {}'.format(\n                token)\n        }\n        search_url = '{}/services/search/jobs'.format(\n            url)\n\n        search_job = requests.post(\n            url=search_url,\n            headers=auth_header,\n            verify=verify,\n            data=query_dict\n        )\n\n        job_id = None\n        try:\n            job_id = parseString(\n                search_job.text).getElementsByTagName(\n                    'sid')[0].childNodes[0].nodeValue\n        except Exception as e:\n            log.error((\n                'Failed searching splunk response={} for '\n                'query={} url={} '\n                'ex={}').format(\n                    search_job.text,\n                    ppj(query_dict),\n                    search_url,\n                    e))\n        # end of try/ex for search\n\n        if job_id:\n            # Step 3: Get the search status\n            search_status_url = '{}/services/search/jobs/{}/'.format(\n                url,\n                job_id)\n            isnotdone = True\n            while isnotdone:\n                searchstatus = requests.get(\n                    url=search_status_url,\n                    verify=verify,\n                    headers=auth_header)\n                isdonestatus = re.compile('isDone\">(0|1)')\n                isdonestatus = isdonestatus.search(\n                    searchstatus.text).groups()[0]\n                if (isdonestatus == '1'):\n                    isnotdone = False\n\n            # Step 4: Get the search results\n            job_url = (\n                '{}/services/search/jobs/{}/'\n                'results?output_mode=json&count=0').format(\n                    url,\n                    job_id)\n            search_results = requests.get(\n                job_url,\n                verify=verify,\n                headers=auth_header)\n            if debug:\n                log.info(\n                    'search {}\\nresults:\\n[{}]'.format(\n                        query_dict,\n                        search_results.text))\n\n            response_dict = None\n            try:\n                response_dict = json.loads(search_results.text)\n            except Exception as e:\n                log.error((\n                    'Failed to load json from search_results.text={} '\n                    'url={} '\n                    'ex={}').format(\n                        search_results.text,\n                        job_url,\n                        e))\n\n        res['status'] = SUCCESS\n        res['err'] = ''\n        res['record'] = response_dict\n    except Exception as e:\n        res['err'] = (\n            'Failed searching user={} url={} query={} '\n            'ex={}').format(\n                user,\n                query_dict,\n                e)\n        res['status'] = ERR\n        log.error(res['err'])\n    # end of try/ex\n\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncasting a string to a strictly positive integer.", "response": "def _positive_int(integer_string, strict=False, cutoff=None):\n    \"\"\"\n    Cast a string to a strictly positive integer.\n    \"\"\"\n    ret = int(integer_string)\n\n    if ret < 0 or (ret == 0 and strict):\n        raise ValueError()\n    if cutoff:\n        ret = min(ret, cutoff)\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef page(self, number):\n\n        number = self.validate_number(number)\n        bottom = (number - 1) * self.per_page\n        top = bottom + self.per_page\n\n        if top + self.orphans >= self.count:\n            top = self.count\n        return self._get_page(self.object_list[bottom:top], number, self)", "response": "Returns a Page object for the given 1 - based page number."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the total number of objects across all pages.", "response": "def count(self):\n        \"\"\"\n        Returns the total number of objects, across all pages.\n        \"\"\"\n\n        try:\n            return self.object_list.count()\n        except (AttributeError, TypeError):\n            # AttributeError if object_list has no count() method.\n            # TypeError if object_list.count() requires arguments\n            # (i.e. is of type list).\n            return len(self.object_list)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the total number of pages.", "response": "def num_pages(self):\n        \"\"\"\n        Returns the total number of pages.\n        \"\"\"\n\n        if self.count == 0 and not self.allow_empty_first_page:\n            return 0\n\n        hits = max(1, self.count - self.orphans)\n\n        return int(ceil(hits / float(self.per_page)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwarns if self. object_list is unordered.", "response": "def _check_object_list_is_ordered(self):\n        \"\"\"\n        Warn if self.object_list is unordered (typically a QuerySet).\n        \"\"\"\n\n        if hasattr(self.object_list, 'ordered') and not self.object_list.ordered:\n            warnings.warn(\n                'Pagination may yield inconsistent results with an unordered '\n                'object_list: {!r}'.format(self.object_list),\n                UnorderedObjectListWarning\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run_main():\n\n    # max_messages_to_send = 200\n    max_messages_to_send = 1000000\n    end_time = None\n    num_logs_per_batch = 0.0\n    num_logs = 0.0\n    running_time = 0.0\n\n    start_time = datetime.datetime.utcnow()\n    checkpoint = datetime.datetime.utcnow()\n    last_checkpoint = datetime.datetime.utcnow()\n\n    try:\n        while True:\n\n            log.debug('DEBUG message_id={}'.format(\n                str(uuid.uuid4())))\n            log.info('INFO message_id={}'.format(\n                str(uuid.uuid4())))\n            log.error('ERROR message_id={}'.format(\n                str(uuid.uuid4())))\n            log.critical('CRITICAL message_id={}'.format(\n                str(uuid.uuid4())))\n            log.warning('WARNING message_id={}'.format(\n                str(uuid.uuid4())))\n            num_logs += 5.0\n            num_logs_per_batch += 5.0\n\n            if num_logs >= max_messages_to_send:\n                print('done')\n                break\n\n            if num_logs % 10000 == 0:\n                checkpoint = datetime.datetime.utcnow()\n                running_time = float(\n                    (checkpoint - last_checkpoint).total_seconds())\n                total_exec_time = float(\n                    (checkpoint - start_time).total_seconds())\n                print((\n                    'sent total_logs={} logs_in_batch={} '\n                    'batch_time={}s rate={} '\n                    'msg/batch time={}s').format(\n                        num_logs,\n                        num_logs_per_batch,\n                        running_time,\n                        float(num_logs_per_batch / running_time),\n                        total_exec_time))\n                last_checkpoint = checkpoint\n                num_logs_per_batch = 0.0\n    # end of while\n    except Exception as e:\n        print('stopping')\n    # end of try/ex\n\n    end_time = datetime.datetime.utcnow()\n    running_time = float((end_time - start_time).total_seconds())\n    print('\\n')\n    print('start_time={}'.format(start_time))\n    print('end_time={}'.format(end_time))\n    print('---------------------------')\n    print('total_time: {} seconds'.format(running_time))\n    print('total_logs: {}'.format(num_logs))\n    print('log rate: {}'.format(float(num_logs / running_time)))\n    print('')\n    search_query = (\n        'search index=\\\"antinex\\\" AND logger_name=\\\"{}\\\" '\n        '| stats count').format(\n            name)\n\n    print((\n        'Find this load test in splunk using the search query: '\n        '\\n'\n        '{}'\n        '\\n\\n'\n        'Or with the Spylunking search tool:\\n'\n        'sp -q \\'{}\\' ').format(\n            search_query,\n            search_query))\n\n    print('')\n    print('sleeping before pulling load test: {} results'.format(\n        name))\n    print('pulling load test: {} results'.format(\n        name))", "response": "Main function for the main function of the main function of the base class."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef as_models(self, klass):\n        try:\n            return [klass(mod) for mod in self.tree.reply.data.results.array[0].item]\n        except AttributeError:\n            return []", "response": "Turns an array - style response into a list of models."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate and return the argument parser with all of the arguments and configuration ready to go.", "response": "def _create_argument_parser(self):\n        \"\"\"Create and return the argument parser with all of the arguments\n        and configuration ready to go.\n\n        :rtype: argparse.ArgumentParser\n\n        \"\"\"\n        parser = self._new_argument_parser()\n        self._add_base_arguments(parser)\n        self._add_required_arguments(parser)\n        return parser"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef configure(config: List[Egg], subclass: 'Container' = None) -> None:\n\n        profiles = Configuration().get_var(PROFILES, tuple)\n        assert isinstance(profiles, (list, tuple))\n        profiles = tuple(profiles) + (None,)\n\n        seen = set()\n        registered = set()\n\n        filtered_config: List[Egg] = []\n\n        for profile in profiles:\n            for egg_ in (e for e in config if e.profile == profile):\n                ident = (egg_.base_, egg_.qualifier, egg_.profile)\n                if ident in seen:\n                    raise ConfigurationError(\n                        \"Ambiguous implementation %s\" % repr(egg_.base_))\n                dep_ident = (egg_.base_, egg_.qualifier)\n                if dep_ident in registered:\n                    continue\n\n                filtered_config.append(egg_)\n\n                registered.add(dep_ident)\n                seen.add(ident)\n        config = filtered_config\n\n        with Container._lock:\n            if Container.__configured:\n                raise AlreadyConfigured\n            if subclass is None:\n                subclass = Container\n\n            Container.__subclass = subclass\n            Container.__configured = True\n\n            container = Container()\n            if not all(isinstance(o, Egg) for o in config):\n                raise ConfigurationError('All config items should be the eggs')\n            container.config = config\n\n            container.register_scope(INSTANCE_SCOPE, InstanceScope)\n            container.register_scope(SINGLETON_SCOPE, SingletonScope)", "response": "Configure haps manually an alternative to Container. autodiscover."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads all modules automatically and find bases and eggs.", "response": "def autodiscover(cls,\n                     module_paths: List[str],\n                     subclass: 'Container' = None) -> None:\n        \"\"\"\n        Load all modules automatically and find bases and eggs.\n\n        :param module_paths: List of paths that should be discovered\n        :param subclass: Optional Container subclass that should be used\n        \"\"\"\n\n        def find_base(bases: set, implementation: Type):\n            found = {b for b in bases if issubclass(implementation, b)}\n            if not found:\n                raise ConfigurationError(\n                    \"No base defined for %r\" % implementation)\n            elif len(found) > 1:\n                raise ConfigurationError(\n                    \"More than one base found for %r\" % implementation)\n            else:\n                return found.pop()\n\n        def walk(pkg: Union[str, ModuleType]) -> Dict[str, ModuleType]:\n            if isinstance(pkg, str):\n                pkg: ModuleType = importlib.import_module(pkg)\n            results = {}\n\n            try:\n                path = pkg.__path__\n            except AttributeError:\n                results[pkg.__name__] = importlib.import_module(pkg.__name__)\n            else:\n                for loader, name, is_pkg in pkgutil.walk_packages(path):\n                    full_name = pkg.__name__ + '.' + name\n                    results[full_name] = importlib.import_module(full_name)\n                    if is_pkg:\n                        results.update(walk(full_name))\n            return results\n\n        with cls._lock:\n            for module_path in module_paths:\n                walk(module_path)\n\n            config: List[Egg] = []\n            for egg_ in egg.factories:\n                base_ = find_base(base.classes, egg_.type_)\n                egg_.base_ = base_\n                config.append(egg_)\n\n            cls.configure(config, subclass=subclass)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget object directly from the container.", "response": "def get_object(self, base_: Type, qualifier: str = None) -> Any:\n        \"\"\"\n        Get instance directly from the container.\n\n        If the qualifier is not None, proper method to create/retrieve instance\n        is  used.\n\n        :param base_: `base` of this object\n        :param qualifier: optional qualifier\n        :return: object instance\n        \"\"\"\n        egg_ = self._find_egg(base_, qualifier)\n        if egg_ is None:\n            raise UnknownDependency('Unknown dependency %s' % base_)\n\n        scope_id = getattr(egg_.egg, '__haps_custom_scope', INSTANCE_SCOPE)\n\n        try:\n            _scope = self.scopes[scope_id]\n        except KeyError:\n            raise UnknownScope('Unknown scopes with id %s' % scope_id)\n        else:\n            with self._lock:\n                return _scope.get_object(egg_.egg)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nregister new scopes which should be subclass of Scope.", "response": "def register_scope(self, name: str, scope_class: Type[Scope]) -> None:\n        \"\"\"\n        Register new scopes which should be subclass of `Scope`\n\n        :param name: Name of new scopes\n        :param scope_class: Class of new scopes\n        \"\"\"\n        with self._lock:\n            if name in self.scopes:\n                raise AlreadyConfigured(f'Scope {name} already registered')\n            self.scopes[name] = scope_class()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef render_article(request, article, current_language, slug):\n    context = {}\n    context['article'] = article\n    context['lang'] = current_language\n    context['current_article'] = article\n    context['has_change_permissions'] = article.has_change_permission(request)\n\n    response = TemplateResponse(request, article.template, context)\n    response.add_post_render_callback(set_page_cache)\n\n    # Add headers for X Frame Options - this really should be changed upon moving to class based views\n    xframe_options = article.tree.get_xframe_options()\n    # xframe_options can be None if there's no xframe information on the page\n    # (eg. a top-level page which has xframe options set to \"inherit\")\n    if xframe_options == Page.X_FRAME_OPTIONS_INHERIT or xframe_options is None:\n        # This is when we defer to django's own clickjacking handling\n        return response\n\n    # We want to prevent django setting this in their middlewear\n    response.xframe_options_exempt = True\n\n    if xframe_options == Page.X_FRAME_OPTIONS_ALLOW:\n        # Do nothing, allowed is no header.\n        return response\n    elif xframe_options == Page.X_FRAME_OPTIONS_SAMEORIGIN:\n        response['X-Frame-Options'] = 'SAMEORIGIN'\n    elif xframe_options == Page.X_FRAME_OPTIONS_DENY:\n        response['X-Frame-Options'] = 'DENY'\n    return response", "response": "Renders an article in a order that it can be rendered."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef new_action(self, method='GET', **kwargs):\n        if method not in self.methods:\n            raise TypeError('{} not in valid method(s): {}.'.format(method, self.methods))\n        return Action(self, method, **kwargs)", "response": "Create a new Action linked to this endpoint with the given args."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a single Action to the APIObject.", "response": "def add_action(self, name, parent, action):\n        \"\"\"\n        Add a single Action to the APIObject.\n        \"\"\"\n        if iskeyword(name):\n            name = '_' + name\n        self._actions[name] = parent.new_action(**action)\n        setattr(self, name, self._actions[name].execute)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef printed_out(self, name):\n        out = ''\n        out += '|\\n'\n        if self._id_variable:\n            subs = '[{}]'.format(self._id_variable)\n        else:\n            subs = ''\n        out += '|---{}{}\\n'.format(name, subs)\n        if self._description:\n            out += '|   |   {}\\n'.format(self._description)\n        for name, action in self._actions.items():\n            out += action.printed_out(name)\n        return out", "response": "Return a string describing the APIObject and its children."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexecuting the request and return the response.", "response": "def execute(self, *args, **kwargs):\n        \"\"\"\n        Fill all variables from *args and **kwargs, build the request,\n        and send it. If we set the _verbose kwarg to true, then we'll\n        get a Response object back instead of loaded data.\n        \"\"\"\n        _verbose = kwargs.pop('_verbose', False)\n        return_full_object = kwargs.pop('return_full_object', False)\n        variables = self.variables().fill(*args, **kwargs)\n        return Request(self, variables).send(\n            traversal=self.traversal,\n            _verbose=_verbose,\n            return_full_object=return_full_object,\n            _timeout=self.timeout\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef printed_out(self, name):\n        opt = self.variables().optional_namestring()\n        req = self.variables().required_namestring()\n        out = ''\n        out += '|   |\\n'\n        out += '|   |---{}({}{})\\n'.format(name, req, opt)\n        if self.description:\n            out += '|   |       {}\\n'.format(self.description)\n        return out", "response": "Create a string representation of the action"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_hive_file(cls, fname, *args, **kwargs):\n        version = kwargs.pop('version', None)\n        require = kwargs.pop('require_https', True)\n        return cls(Hive.from_file(fname, version, require), *args, **kwargs)", "response": "Initialize a new object from a local JSON hive file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_remote_hive(cls, url, *args, **kwargs):\n        version = kwargs.pop('version', None)\n        require = kwargs.pop('require_https', False)\n        return cls(Hive.from_url(url, version, require), *args, **kwargs)", "response": "Download a JSON hive file from a URL and initialize it from it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a new instance of the class from a domain.", "response": "def from_domain(cls, domain, *args, **kwargs):\n        \"\"\"\n        Try to download the hive file from the domain using the defined\n        beekeeper spec of domain/api/hive.json.\n        \"\"\"\n        version = kwargs.pop('version', None)\n        require = kwargs.pop('require_https', False)\n        return cls(Hive.from_domain(domain, version, require), *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_endpoint(self, name, **kwargs):\n        self._endpoints[name] = Endpoint(self, **kwargs)", "response": "Add an endpoint with the given name to the API."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd an object to the internal dict.", "response": "def add_object(self, name, obj):\n        \"\"\"\n        Initialize an APIObject with the given name and make it available\n        using dot notation from the top-level namespace.\n        \"\"\"\n        if iskeyword(name):\n            name = '_' + name\n        setattr(self, name, APIObject(self, **obj))\n        self._objects[name] = getattr(self, name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving an entry from the altair encoding dict", "response": "def raenc(self, key):\n        \"\"\"\n        Remove an entry from the altair encoding dict\n        \"\"\"\n        if key in self.altair_encode:\n            del self.altair_encode[key]\n        else:\n            self.warning(\"Key \" + key + \" not found in Altair encoding dict\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a line + text number chart", "response": "def _altair_line_num_(self, xfield, yfield, opts, style, encode):\n        \"\"\"\n        Get a line + text number chart\n        \"\"\"\n        try:\n            c = self._altair_chart_num_(\"line\", xfield,\n                                           yfield, opts, style, encode)\n        except Exception as e:\n            self.err(e, \"Can not draw a line num chart\")\n            return\n        return c"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a chart + text number chart", "response": "def _altair_chart_num_(self, chart_type, xfield, yfield, opts, style2, encode):\n        \"\"\"\n        Get a chart + text number chart\n        \"\"\"\n        style = {**style2}\n        text_color = \"grey\"\n        if \"text_color\" in style:\n            text_color = style[\"text_color\"]\n            del style[\"text_color\"]\n            if \"text_color\" in self.chart_style:\n                del self.chart_style[\"text_color\"]\n        if chart_type == \"line\":\n            c = Chart(self.df).mark_line(**style).encode(x=xfield, \\\n                                                y=yfield, **encode).properties(**opts)\n        elif chart_type == \"bar\":\n            c = Chart(self.df).mark_bar(**style).encode(x=xfield, \\\n                                                y=yfield, **encode).properties(**opts)\n        elif chart_type == \"point\":\n            c = Chart(self.df).mark_point(**style).encode(x=xfield, \\\n                                                y=yfield, **encode).properties(**opts)\n        encoder = encode\n        if \"text\" not in encoder:\n            encoder[\"text\"] = yfield\n        if \"align\" not in style:\n            style[\"align\"] = \"center\"\n        if \"dy\" not in style:\n            style[\"dy\"] = -5\n        if \"dx\" not in style and chart_type != \"bar\":\n            style[\"dx\"] = 8\n        if \"size\" in style:\n            del style[\"size\"]\n        style[\"color\"] = text_color\n        df2 = self.df.replace({yfield.split(\":\")[0]: {0: self.nan}})\n        num = Chart(df2).mark_text(**style).encode(x=xfield, \\\n                                            y=yfield, **encoder).properties(**opts)\n        return c + num"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a mean line chart", "response": "def _altair_hline_(self, xfield, yfield, opts, style, encode):\n        \"\"\"\n        Get a mean line chart\n        \"\"\"\n        try:\n            rawy = yfield\n            if \":\" in yfield:\n                rawy = yfield.split(\":\")[0]\n            mean = self.df[rawy].mean()\n            l = []\n            i = 0\n            while i < len(self.df[rawy]):\n                l.append(mean)\n                i += 1\n            self.df[\"Mean\"] = l\n            chart = Chart(self.df).mark_line(**style).encode(x=xfield, \\\n                                            y=\"Mean\", **encode).properties(**opts)\n            self.drop(\"Mean\")\n            return chart\n        except Exception as e:\n            self.err(e, \"Can not draw mean line chart\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_altair_chart(self, xfield, yfield, chart_type,\n                          label, opts={}, style={}, **kwargs):\n        \"\"\"\n        Get an Altair chart object\n        \"\"\"\n        encode = self.altair_encode\n        chart = None\n        if chart_type == \"bar\":\n            chart = Chart(self.df).mark_bar(**style).encode(x=xfield, \\\n                                            y=yfield, **encode).properties(**opts)\n        elif chart_type == \"circle\":\n            chart = Chart(self.df).mark_circle(**style).encode(x=xfield, \\\n                                            y=yfield, **encode).properties(**opts)\n        elif chart_type == \"line\":\n            chart = Chart(self.df).mark_line(**style).encode(x=xfield, \\\n                                            y=yfield, **encode).properties(**opts)\n        elif chart_type == \"hline\":\n            chart = self._altair_hline_(xfield, yfield, opts, style, encode)\n        elif chart_type == \"line_num\":\n            chart = self._altair_line_num_(xfield, yfield, opts, style, encode)\n        elif chart_type == \"bar_num\":\n            chart = self._altair_bar_num_(xfield, yfield, opts, style, encode)\n        elif chart_type == \"point_num\":\n            chart = self._altair_point_num_(xfield, yfield, opts, style, encode)\n        elif chart_type == \"point\":\n            chart = Chart(self.df).mark_point(**style).encode(x=xfield, \\\n                                            y=yfield, **encode).properties(**opts)\n        elif chart_type == \"area\":\n            chart = Chart(self.df).mark_area(**style).encode(x=xfield, \\\n                                            y=yfield, **encode).properties(**opts)\n        elif chart_type == \"heatmap\":\n            chart = Chart(self.df).mark_rect(**style).encode(x=xfield, \\\n                                            y=yfield, **encode).properties(**opts)\n        elif chart_type == \"text\":\n            chart = Chart(self.df).mark_text(**style).encode(x=xfield, \\\n                                            y=yfield, **encode).properties(**opts)\n        elif chart_type == \"square\":\n            chart = Chart(self.df).mark_square(**style).encode(x=xfield, \\\n                                                y=yfield, **encode).properties(**opts)\n        elif chart_type == \"tick\":\n            chart = Chart(self.df).mark_tick(**style).encode(x=xfield, \\\n                                            y=yfield, **encode).properties(**opts)\n        elif chart_type == \"rule\":\n            chart = Chart(self.df).mark_rule(**style).encode(x=xfield, \\\n                                            y=yfield, **encode).properties(**opts)\n        return chart", "response": "Get an Altair chart object for the given field and type."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_altair_html_(self, chart_obj, slug):\n        try:\n            json_data = chart_obj.to_json(indent=0)\n        except Exception as e:\n            self.err(e)\n        html = '<div id=\"' + slug + '\"></div>\\n'\n        html += '<script type=\"text/javascript\">'\n        html += 'var spec = ' + json_data.replace(\"\\n\", \"\") + \";\"\n        html += \"\"\"\n        var embed_opt = {\"mode\": \"vega-lite\"};\n        function showError(altel, error){\n            altel.innerHTML = ('<div class=\"error\">'\n                            + '<p>JavaScript Error: ' + error.message + '</p>'\n                            + \"<p>This usually means there's a typo in your chart specification. \"\n                            + \"See the javascript console for the full traceback.</p>\"\n                            + '</div>');\n            throw error;\n        };\\n\"\"\"\n        html += \"const el_\" + slug + \" = document.getElementById('\" + slug + \"');\"\n        html += \"vegaEmbed('#\" + slug + \"', spec, embed_opt)\"\n        html += \".catch(error => showError(el_\" + slug + \", error));\"\n        html += '</script>'\n        return html", "response": "Get html for an Altair chart"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsplit a string into a list of start_column substring tuples.", "response": "def split(self, s):\n        \"\"\"Splits a string into a list of (start_column, substring) tuples.\"\"\"\n\n        normalized = \"\".join(map(lambda c: \" \" if c.isspace() else c, s))\n\n        string = False\n        quote = False\n        v = []\n        for col, char in enumerate(normalized.rstrip(), 1):\n            if char == '\\\\':\n                quote = True\n            if char == '\"' and not quote:\n                if string:\n                    v[-1] = (v[-1][0], v[-1][1] + '\"')\n                string = not string\n\n            if char.isspace() and not string:\n                v.append((col, \"\"))\n            else:\n                if len(v) == 0:\n                    v.append((col, char))\n                else:\n                    col, part = v[-1]\n                    v[-1] = (col, part + char)\n\n            if char != '\\\\' and quote:\n                quote = False\n\n        return [t_p for t_p in v if t_p[1] != \"\"]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing integers in bases 10 and 16 and floats.", "response": "def parse_number(self, s):\n        \"\"\"Parses integers in bases 10 and 16 and floats.\"\"\"\n        start = 1 if s[0] in [\"-\",\"+\"] else 0\n\n        all_digits = lambda x: all(map(lambda c: c.isdigit(), x))\n        ishex = lambda c: c.isdigit() or ord(c.lower()) in range(ord(\"a\"), ord(\"f\"))\n        all_hex = lambda x: all(map(ishex, x))\n\n        if all_digits(s[start:]):\n            try:\n                return (Tokenizer.INTEGER, int(s))\n            except ValueError:\n                raise ParseError(\"%d:%d: Invalid integer '%s'\" % (self.lineno,\n                    self.column, s))\n\n        if s[start:].startswith(\"0x\") and all_hex(s[start+2:]):\n            try:\n                return (Tokenizer.INTEGER, int(s, base=16))\n            except ValueError:\n                raise ParseError(\"%d:%d: Invalid hexadecimal integer '%s'\" %\n                        (self.lineno, self.column, s))\n\n        if any(map(lambda c: c==\".\", s)) or any(map(lambda c: c==\"e\", s)):\n            try:\n                return (Tokenizer.FLOAT, float(s))\n            except ValueError:\n                raise ParseError(\"%d:%d: Invalid float '%s'\" % (self.lineno,\n                    self.column, s))\n\n        raise ParseError(\"%d:%d: Invalid number '%s'\" % (self.lineno,\n            self.column, s))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse string and returns a ( Tokenizer. TYPE value ) tuple.", "response": "def tokentype(self, s):\n        \"\"\"Parses string and returns a (Tokenizer.TYPE, value) tuple.\"\"\"\n        a = s[0] if len(s)>0 else \"\"\n        b = s[1] if len(s)>1 else \"\"\n\n        if a.isdigit() or (a in [\"+\",\"-\"] and b.isdigit()):\n            return self.parse_number(s)\n        elif a == '\"': return self.parse_string(s)\n        elif a == ':': return self.parse_colon(s)\n        elif a == ';': return self.parse_semicolon(s)\n        else:\n            return self.parse_word(s)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbreak a stream up into tokens. Yields tuples of the form line_number column tokenizer. TOKEN.", "response": "def tokenize(self):\n        \"\"\"Breaks a stream up into tokens.\n\n        Yields tuples of the form (line_number, column, Tokenizer.TOKEN).\n        \"\"\"\n        def readlines(s):\n            while True:\n                line = s.readline()\n                if line != \"\":\n                    yield line.rstrip()\n                else:\n                    break\n\n        for self.lineno, line in enumerate(readlines(self.stream), 1):\n            for self.column, part in self.split(line):\n                if part[0] == \"#\": # COMMENT\n                    break\n                yield (self.lineno, self.column, self.tokentype(part))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving a dict in python - zimbra format or XML generate a new object.", "response": "def from_dict(cls, d):\n        \"\"\" Given a dict in python-zimbra format or XML, generate\n        a Python object.\n        \"\"\"\n\n        if type(d) != dict:\n            raise TypeError('Expecting a <dict>, got a {0}'.format(type(d)))\n        obj = cls()\n        obj._full_data = d\n\n        # import attributes\n        obj._import_attributes(d)\n\n        # import <a> child tags as dict items, see __getitem__()\n        obj._a_tags = obj._parse_a_tags(d)\n\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a property value from the a_tags dict.", "response": "def property(self, property_name, default=Ellipsis):\n        \"\"\" Returns a property value\n\n        :param: default will return that value if the property is not found,\n               else, will raise a KeyError.\n        \"\"\"\n        try:\n            return self._a_tags[property_name]\n        except KeyError:\n            if default != Ellipsis:\n                return default\n            else:\n                raise"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef property_as_list(self, property_name):\n        try:\n            res = self._a_tags[property_name]\n        except KeyError:\n            return []\n\n        if type(res) == list:\n            return res\n        else:\n            return [res]", "response": "property - encapsulates it in a list if it s a\n        single - element property."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses all tags and returns a dict with the tags values.", "response": "def _parse_a_tags(cls, dic):\n        \"\"\" Iterates over all <a> tags and builds a dict with those.\n        If a tag with same \"n\" attributes appears several times, the\n        dict value is a list with the tags values, else it's a string.\n\n        :param: dic the dict describing the tag\n        :returns:   a dict\n        \"\"\"\n        props = {}\n\n        if 'a' in dic:\n            childs = dic['a']\n            # If there is only one \"a\", it's not presentend as\n            # a list, that's why we put it in a list\n            if not isinstance(childs, (list, tuple)):\n                childs = [childs]\n        else:\n            childs = []\n\n        for child in childs:\n            k = child[cls.ATTRNAME_PROPERTY]\n            try:\n                v = child['_content']\n            except KeyError:\n                v = None\n\n            try:\n                v = utils.auto_type(str(v))\n            except UnicodeEncodeError:\n                # Some times, str() fails because of accents...\n                v = utils.auto_type(v)\n\n            if k in props:\n                prev_v = props[k]\n                if type(prev_v) != list:\n                    props[k] = [prev_v]\n\n                props[k].append(v)\n\n            else:\n                props[k] = v\n        return props"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _unparse_a_tags(cls, attrs_dict):\n        prop_tags = []\n\n        for k, v in attrs_dict.items():\n            node = {cls.ATTRNAME_PROPERTY: k, '_content': utils.auto_type(v)}\n            prop_tags.append(node)\n\n        return prop_tags", "response": "Returns a list of xml. etree. Element objects representing the tags of the a element."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_creator(self):\n        o = {}\n\n        for prop in ('name', 'id'):\n            if hasattr(self, prop):\n                o[prop] = getattr(self, prop)\n\n        try:\n            if len(self.a) > 0:\n                o['a'] = []\n                for node in self._unparse_a_tags(self._a_tags):\n                    o['a'].append(node)\n        except AttributeError:\n            pass\n        return o", "response": "Returns the dict suitable for CreateIdentity or ModifyIdentity\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting the current object to a selector.", "response": "def to_selector(self):\n        \"\"\" For some reason, the selector for <identity> is\n\n            <identity id=\"1234\" />\n\n        rather than\n\n            <identity by=\"id\"></identity>\n        \"\"\"\n\n        for i in self.SELECTORS:\n            if hasattr(self, i):\n                val = getattr(self, i)\n                selector = i\n                break\n\n        return {selector: val}"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_dict(cls, d):\n        o = super(DistributionList, cls).from_dict(d)\n        o.members = []\n        if 'dlm' in d:\n            o.members = [utils.get_content(member)\n                         for member in utils.as_list(d[\"dlm\"])]\n        return o", "response": "Override default to add the capture of members."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\noverriding default with the capture of content and contenttype.", "response": "def from_dict(cls, d):\n        \"\"\" Override default, adding the capture of content and contenttype.\n        \"\"\"\n        o = super(Signature, cls).from_dict(d)\n        if 'content' in d:\n            # Sometimes, several contents, (one txt, other  html), take last\n            try:\n                o._content = d['content']['_content']\n                o._contenttype = d['content']['type']\n            except TypeError:\n                o._content = d['content'][-1]['_content']\n                o._contenttype = d['content'][-1]['type']\n\n        return o"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a dict object suitable for a CreateSignature.", "response": "def to_creator(self, for_modify=False):\n        \"\"\" Returns a dict object suitable for a 'CreateSignature'.\n\n        A signature object for creation is like :\n\n            <signature name=\"unittest\">\n              <content type=\"text/plain\">My signature content</content>\n            </signature>\n\n        which is :\n\n            {\n             'name' : 'unittest',\n             'content': {\n               'type': 'text/plain',\n               '_content': 'My signature content'\n             }\n            }\n\n        Note that if the contenttype is text/plain, the content with text/html\n        will be cleared by the request (for consistency).\n        \"\"\"\n        signature = {}\n\n        if for_modify:\n            try:\n                # we should have an ID\n                signature['id'] = self.id\n            except AttributeError:\n                raise AttributeError('a modify request should specify an ID')\n            # Case where we change or set a name\n            if hasattr(self, 'name'):\n                signature['name'] = self.name\n\n        else:\n            # a new signature should have a name\n            signature['name'] = self.name\n\n        if self.has_content():\n            # Set one, flush the other (otherwise, we let relief behind...)\n            if self._contenttype == 'text/plain':\n                plain_text = self._content\n                html_text = ''\n            else:\n                html_text = self._content\n                plain_text = ''\n\n            content_plain = {'type': 'text/plain', '_content': plain_text}\n            content_html = {'type': 'text/html', '_content': html_text}\n\n            signature['content'] = [content_plain, content_html]\n\n        else:\n            # A creation request should have a content\n            if not for_modify:\n                raise AttributeError(\n                    'too little information on signature, '\n                    'run setContent before')\n\n        return signature"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a python - zimbra dict for CreateTaskRequest", "response": "def to_creator(self, subject, desc):\n        \"\"\" Return a python-zimbra dict for CreateTaskRequest\n\n        Example :\n        <CreateTaskRequest>\n            <m su=\"Task subject\">\n                <inv>\n                    <comp name=\"Task subject\">\n                        <fr>Task comment</fr>\n                        <desc>Task comment</desc>\n                    </comp>\n                </inv>\n                <mp>\n                    <content/>\n                </mp>\n            </m>\n        </CreateTaskRequest>\n        \"\"\"\n\n        task = {\n            'm': {\n                'su': subject,\n                'inv': {\n                    'comp': {\n                        'name': subject,\n                        'fr': {'_content': desc},\n                        'desc': {'_content': desc},\n                        'percentComplete': '0'\n                    }\n                },\n                'mp': {\n                    'content': {}\n                }\n            }\n        }\n\n        return task"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend a request to a server from a ServiceClient alid packet.", "response": "def _request_sender(self, packet: dict):\n        \"\"\"\n        Sends a request to a server from a ServiceClient\n        auto dispatch method called from self.send()\n        \"\"\"\n        node_id = self._get_node_id_for_packet(packet)\n        client_protocol = self._client_protocols.get(node_id)\n\n        if node_id and client_protocol:\n            if client_protocol.is_connected():\n                packet['to'] = node_id\n                client_protocol.send(packet)\n                return True\n            else:\n                self._logger.error('Client protocol is not connected for packet %s', packet)\n                raise ClientDisconnected()\n        else:\n            # No node found to send request\n            self._logger.error('Out of %s, Client Not found for packet %s', self._client_protocols.keys(), packet)\n            raise ClientNotFoundError()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading list of authors from a text file filtering comments.", "response": "def get_authors():\n    \"\"\"Read list of authors from a text file, filtering comments.\"\"\"\n    authors = []\n    authorfile = os.path.join('doc', 'authors.txt')\n    with codecs.open(authorfile, 'r', 'utf-8') as f:\n        for line in f:\n            line = line.strip()\n            if line and not line.startswith(u'#'):\n                authors.append(line)\n    return u\", \".join(authors)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef clone_(self, quiet=False):\n        ds2 = self._duplicate_(quiet=True)\n        if ds2 is None:\n            self.err(\"Can not clone instance\")\n        else:\n            if quiet is False:\n                self.ok(\"Instance cloned\")\n        return ds2", "response": "Clone the instance of this instance"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef backup(self):\n        try:\n            self.backup_df = self.df.copy()\n        except Exception as e:\n            self.err(e, \"Can not backup data\")\n            return\n        self.ok(\"Dataframe backed up\")", "response": "Backup the main dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef restore(self):\n        if self.backup_df is None:\n            self.warning(\"No dataframe is backed up: nothing restore\")\n            return\n        self.df = self.backup_df\n        self.ok(\"Dataframe is restored\")", "response": "Restore the main dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload data in the main dataframe from json file", "response": "def load_json(self, path, **kwargs):\n        \"\"\"Load data in the main dataframe from json\n\n        :param filepath: url of the csv file to load,\n                                         can be absolute if it starts with ``/``\n                                         or relative if it starts with ``./``\n        :type filepath: str\n\n        :param kwargs: keyword arguments to pass to\n                                                   Pandas ``read_json`` function\n\n        :example: ``ds.load_json(\"./myfile.json\")``\n        \"\"\"\n        try:\n            df = pd.read_json(path, **kwargs)\n            self.df = df\n        except Exception as e:\n            self.err(e, \"Can not load json\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_h5(self, filepath):\n        try:\n            self.start(\"Loading Hdf5 data...\")\n            self.df = dd.io.load(filepath)\n            self.end(\"Finished loading Hdf5 data\")\n        except Exception as e:\n            self.err(e, \"Can not load Hdf5 file\")", "response": "Load a Hdf5 file to the main dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload the main dataframe with the content of an Excel file", "response": "def load_excel(self, filepath, **kwargs):\n        \"\"\"Set the main dataframe with the content of an Excel file\n\n        :param filepath: url of the csv file to load,\n                        can be absolute if it starts with ``/``\n                        or relative if it starts with ``./``\n        :type filepath: str\n\n        :param kwargs: keyword arguments to pass to \n                            Pandas ``read_excel`` function\n\n        :example: ``ds.load_excel(\"./myfile.xlsx\")``\n        \"\"\"\n        try:\n            df = pd.read_excel(filepath, **kwargs)\n            if len(df.index) == 0:\n                self.warning(\"Empty Excel file. Can not set the dataframe.\")\n                return\n            self.df = df\n        except Exception as e:\n            self.err(e, \"Can not load Excel file\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_csv(self, url, **kwargs):\n        self.start(\"Loading csv...\")\n        try:\n            if self.datapath is not None and url.startswith(\"/\") is False:\n                url = self.datapath + \"/\" + url\n            df = pd.read_csv(url, **kwargs)\n            self.df = df\n        except FileNotFoundError:\n            msg = \"File \" + url + \" not found\"\n            self.warning(msg)\n            return\n        except Exception as e:\n            self.err(e, \"Can not load csv file\")\n            return\n        self.end(\"Finished loading csv\")", "response": "Loads csv data in the main dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a date parser for pandas", "response": "def dateparser(self, dformat='%d/%m/%Y'):\n        \"\"\"\n        Returns a date parser for pandas\n        \"\"\"\n\n        def dateparse(dates):\n            return [pd.datetime.strptime(d, dformat) for d in dates]\n\n        return dateparse"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nperforms the authentication redirect to GitHub s URL.", "response": "def authenticate_redirect(self, callback_uri=None, cancel_uri=None,\n                              extended_permissions=None, callback=None):\n        \"\"\"Perform the authentication redirect to GitHub\n\n\n        \"\"\"\n        self.require_setting(self._CLIENT_ID_SETTING, self._API_NAME)\n\n        scope = self._BASE_SCOPE\n        if extended_permissions:\n            scope += extended_permissions\n\n        args = {'client_id': self.settings[self._CLIENT_ID_SETTING],\n                'redirect_uri': self.oauth2_redirect_uri(callback_uri),\n                'scope': ','.join(scope)}\n\n        # If cookie_secret is set, use it for GitHub's state value\n        if not self.state and 'cookie_secret' in self.settings:\n            sha1 = hashlib.sha1(self.settings['cookie_secret'])\n            self.state = str(sha1.hexdigest())\n\n        # If state is set, add it to args\n        if self.state:\n            args['state'] = self.state\n\n        LOGGER.info('Redirect args: %r', args)\n\n        # Redirect the user to the proper URL\n        self.redirect(self._OAUTH_AUTHORIZE_URL +\n                      auth.urllib_parse.urlencode(args))\n        callback()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_authenticated_user(self, callback):\n        self.require_setting(self._CLIENT_ID_SETTING, self._API_NAME)\n        self.require_setting(self._CLIENT_SECRET_SETTING, self._API_NAME)\n\n        if self.state:\n            if (not self.get_argument('state', None) or\n                self.state != self.get_argument('state')):\n                LOGGER.error('State did not match: %s != %s',\n                             self.state, self.get_argument('state'))\n                raise auth.AuthError('Problematic Reply from %s' %\n                                     self._API_NAME)\n\n        args = {'client_id': self.settings[self._CLIENT_ID_SETTING],\n                'client_secret': self.settings[self._CLIENT_SECRET_SETTING],\n                'code': self.get_argument('code'),\n                'redirect_uri': self.oauth2_redirect_uri()}\n\n        http_client = self._get_auth_http_client()\n        callback = self.async_callback(self._on_access_token, callback)\n        http_client.fetch(self._OAUTH_ACCESS_TOKEN_URL,\n                          method='POST',\n                          headers={'Accept': self._ACCEPT},\n                          user_agent=self._USER_AGENT,\n                          body=auth.urllib_parse.urlencode(args),\n                          callback=callback)", "response": "Fetches the authenticated user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninvoke as a callback when GitHub has returned a response to the get_user_access_token request.", "response": "def _on_access_token(self, future, response):\n        \"\"\"Invoked as a callback when GitHub has returned a response to the\n        access token request.\n\n        :param method future: The callback method to pass along\n        :param tornado.httpclient.HTTPResponse response: The HTTP response\n\n        \"\"\"\n        content = escape.json_decode(response.body)\n        if 'error' in content:\n            LOGGER.error('Error fetching access token: %s', content['error'])\n            future.set_exception(auth.AuthError('Github auth error: %s' %\n                                                str(content['error'])))\n            return\n        callback = self.async_callback(self._on_github_user, future,\n                                       content['access_token'])\n        self.github_request('user', callback, content['access_token'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninvokes as a callback when self. github_request returns the response from the request for the user data.", "response": "def _on_github_user(self, future, access_token, response):\n        \"\"\"Invoked as a callback when self.github_request returns the response\n        to the request for user data.\n\n        :param method future: The callback method to pass along\n        :param str access_token: The access token for the user's use\n        :param dict response: The HTTP response already decoded\n\n        \"\"\"\n        response['access_token'] = access_token\n        future.set_result(response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmakes a request to the GitHub API passing in the path a callback access_token optional post arguments and keyword arguments to be added as values in the request body or URI AttributeNames", "response": "def github_request(self, path, callback, access_token=None,\n                       post_args=None, **kwargs):\n        \"\"\"Make a request to the GitHub API, passing in the path, a callback,\n        the access token, optional post arguments and keyword arguments to be\n        added as values in the request body or URI\n\n        \"\"\"\n        url = self._API_URL + path\n        all_args = {}\n        if access_token:\n            all_args[\"access_token\"] = access_token\n            all_args.update(kwargs)\n        if all_args:\n            url += \"?\" + auth.urllib_parse.urlencode(all_args)\n        callback = self.async_callback(self._on_github_request, callback)\n        http = self._get_auth_http_client()\n        if post_args is not None:\n            http.fetch(url, method=\"POST\",\n                       user_agent='Tinman/Tornado',\n                       body=auth.urllib_parse.urlencode(post_args),\n                       callback=callback)\n        else:\n            http.fetch(url, user_agent='Tinman/Tornado', callback=callback)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _on_github_request(self, future, response):\n        try:\n            content = escape.json_decode(response.body)\n        except ValueError as error:\n            future.set_exception(Exception('Github error: %s' %\n                                           response.body))\n            return\n\n        if 'error' in content:\n            future.set_exception(Exception('Github error: %s' %\n                                           str(content['error'])))\n            return\n        future.set_result(content)", "response": "Invoked as a response to the GitHub API request. Will decode the response and set the result for the future to return the callback or\n        raise an exception"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _on_access_token(self, future, response):\n        LOGGER.info(response.body)\n        content = escape.json_decode(response.body)\n        if 'error' in content:\n            LOGGER.error('Error fetching access token: %s', content['error'])\n            future.set_exception(auth.AuthError('StackExchange auth error: %s' %\n                                                str(content['error'])))\n            return\n        callback = self.async_callback(self._on_stackexchange_user, future,\n                                       content['access_token'])\n        self.stackexchange_request('me', callback, content['access_token'])", "response": "Invoked as a callback when StackExchange has returned a response to\n        the access token request."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _on_stackexchange_user(self, future, access_token, response):\n        response['access_token'] = access_token\n        future.set_result(response)", "response": "Invoked as a callback when self. stackexchange_request returns the the\n        response to the request."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmaking a request to the StackExchange API passing in the path aaterange and the callback the access token optional post arguments and keyword arguments to be added as values in the request body or URI AttributeNames", "response": "def stackexchange_request(self, path, callback, access_token=None,\n                       post_args=None, **kwargs):\n        \"\"\"Make a request to the StackExchange API, passing in the path, a\n        callback, the access token, optional post arguments and keyword\n        arguments to be added as values in the request body or URI\n\n        \"\"\"\n        url = self._API_URL + path\n        all_args = {}\n        if access_token:\n            all_args[\"access_token\"] = access_token\n            all_args.update(kwargs)\n        if all_args:\n            url += \"?\" + auth.urllib_parse.urlencode(all_args)\n        callback = self.async_callback(self._on_stackexchange_request, callback)\n        http = self._get_auth_http_client()\n        if post_args is not None:\n            http.fetch(url, method=\"POST\",\n                       body=auth.urllib_parse.urlencode(post_args),\n                       callback=callback)\n        else:\n            http.fetch(url, callback=callback)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _on_stackexchange_request(self, future, response):\n        content = escape.json_decode(response.body)\n        if 'error' in content:\n            future.set_exception(Exception('StackExchange error: %s' %\n                                           str(content['error'])))\n            return\n        future.set_result(content)", "response": "Invoked as a response to the StackExchange API request. Will decode the response and set the result for the future to return the callback or\n            raise an exception"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses the query string from the request. params dictionary.", "response": "def parse_query_string(self, params):\n        \"\"\"\n        Override this method if you need to support query string filter keys other than those in the\n        format of ``key[field_name]=val``. Maps query string values == 'null' to ``None``.\n\n        :param params: The query string parameters from ``request.params``.\n        :return: Dictionary.\n        \"\"\"\n        results = {}\n\n        for key, val in params.items():\n            lookup_len = len(self.query_string_lookup) + 1\n\n            if key[0:lookup_len] == '{}['.format(self.query_string_lookup) and key[-1] == ']':\n                results[key[lookup_len:-1]] = val if val.lower() != 'null' else None\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef multilingual_flatpage(request, url):\n    if not url.endswith('/') and settings.APPEND_SLASH:\n        return HttpResponseRedirect(\"%s/\" % request.path)\n    if not url.startswith('/'):\n        url = \"/\" + url\n    f = get_object_or_404(MultilingualFlatPage, url__exact=url, sites__id__exact=settings.SITE_ID)\n    # If registration is required for accessing this page, and the user isn't\n    # logged in, redirect to the login page.\n    if f.registration_required and not request.user.is_authenticated():\n        from django.contrib.auth.views import redirect_to_login\n        return redirect_to_login(request.path)\n    # Serve the content in the language defined by the Django translation module\n    # if possible else serve the default language.\n    f._default_language = get_language()\n    if f.template_name:\n        t = loader.select_template((f.template_name, DEFAULT_TEMPLATE))\n    else:\n        t = loader.get_template(DEFAULT_TEMPLATE)\n\n    # To avoid having to always use the \"|safe\" filter in flatpage templates,\n    # mark the title and content as already safe (since they are raw HTML\n    # content in the first place).\n    f.title = mark_safe(f.title)\n    f.content = mark_safe(f.content)\n\n    c = RequestContext(request, {\n        'flatpage': f,\n    })\n    response = HttpResponse(t.render(c))\n    populate_xheaders(request, response, MultilingualFlatPage, f.id)\n    return response", "response": "A multilingual flat page view."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef transform(self, raw_X, y=None):\n        return [self._extract_features(sequence1, sequence2) for sequence1, sequence2 in raw_X]", "response": "Transform sequence pairs to feature arrays that can be used as input to Hacrf models."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ok(self, *msg):\n        label = colors.green(\"OK\")\n        self._msg(label, *msg)", "response": "Prints a message with an ok prefix"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint a message with an info prefix", "response": "def info(self, *msg):\n        \"\"\"\n        Prints a message with an info prefix\n        \"\"\"\n        label = colors.blue(\"INFO\")\n        self._msg(label, *msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprints a status message", "response": "def status(self, *msg):\n        \"\"\"\n        Prints a status message\n        \"\"\"\n        label = colors.yellow(\"STATUS\")\n        self._msg(label, *msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprints a warning message", "response": "def warning(self, *msg):\n        \"\"\"\n        Prints a warning\n        \"\"\"\n        label = colors.yellow(\"WARNING\")\n        self._msg(label, *msg)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef debug(self, *msg):\n        label = colors.yellow(\"DEBUG\")\n        self._msg(label, *msg)", "response": "Prints a warning with a label"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint a progress message", "response": "def progress(self, *msg):\n        \"\"\"\n        Prints a progress message\n        \"\"\"\n        label = colors.purple(\"Progress\")\n        self._msg(label, *msg)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprinting a start message", "response": "def start(self, *msg):\n        \"\"\"\n        Prints an start message\n        \"\"\"\n        self.start_time = datetime.datetime.now()\n        label = colors.purple(\"START\")\n        self._msg(label, *msg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprint an end message with elapsed time", "response": "def end(self, *msg):\n        \"\"\"\n        Prints an end message with elapsed time\n        \"\"\"\n        if self.start_time is None:\n            self.err(\"No start time set: please use start() \"\n                     \"before using this function\")\n        endtime = datetime.datetime.now()\n        rd = dateutil.relativedelta.relativedelta(endtime, self.start_time)\n        endmsg = self._endmsg(rd)\n        label = colors.purple(\"END\")\n        msg += (\"in \" + endmsg,)\n        self._msg(label, *msg)\n        self.start_time = None"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprint html in notebook", "response": "def html(self, label, *msg):\n        \"\"\"\n        Prints html in notebook\n        \"\"\"\n        lbl = \"[\" + label + \"] \"\n        txt = lbl + \" \" + \" \".join(list(msg))\n        if self.notebook is True:\n            html = HTML(txt)\n            display(lbl + html)\n        else:\n            print(lbl + txt)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a message with a label", "response": "def msg_(self, label, *msg):\n        \"\"\"\n        Returns a message with a label\n        \"\"\"\n        txt = self._unpack_msg(*msg)\n        return \"[\" + label + \"] \" + txt"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _msg(self, label, *msg):\n        if self.quiet is False:\n            txt = self._unpack_msg(*msg)\n            print(\"[\" + label + \"] \" + txt)", "response": "Print a message with a label"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _unpack_msg(self, *msg):\n        l = []\n        for m in msg:\n            l.append(str(m))\n        return \" \".join(l)", "response": "Convert all message elements to string"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _endmsg(self, rd):\n        msg = \"\"\n        s = \"\"\n        if rd.hours > 0:\n            if rd.hours > 1:\n                s = \"s\"\n            msg += colors.bold(str(rd.hours)) + \" hour\" + s + \" \"\n        s = \"\"\n        if rd.minutes > 0:\n            if rd.minutes > 1:\n                s = \"s\"\n            msg += colors.bold(str(rd.minutes)) + \" minute\" + s + \" \"\n        # if rd.seconds > 0:\n        #    msg+=str(rd.seconds)\n        # else:\n        #    msg+=\"0.\"\n        milliseconds = int(rd.microseconds / 1000)\n        if milliseconds > 0:\n            msg += colors.bold(str(rd.seconds) + \".\" + str(milliseconds))\n        msg += \" seconds\"\n        return msg", "response": "Returns an end message with elapsed time"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setup_logging(\n        default_level=logging.INFO,\n        default_path=None,\n        env_key='LOG_CFG',\n        handler_name='console',\n        handlers_dict=None,\n        log_dict=None,\n        config_name=None,\n        splunk_host=None,\n        splunk_port=None,\n        splunk_index=None,\n        splunk_token=None,\n        splunk_verify=False,\n        splunk_handler_name='splunk',\n        splunk_sleep_interval=-1,\n        splunk_debug=False):\n    \"\"\"setup_logging\n\n    Setup logging configuration\n\n    :param default_level: level to log\n    :param default_path: path to config (optional)\n    :param env_key: path to config in this env var\n    :param handler_name: handler name in the config\n    :param handlers_dict: handlers dict\n    :param log_dict: full log dictionary config\n    :param config_name: filename for config\n    :param splunk_host: optional splunk host\n    :param splunk_port: optional splunk port\n    :param splunk_index: optional splunk index\n    :param splunk_token: optional splunk token\n    :param splunk_verify: optional splunk verify - default to False\n    :param splunk_handler_name: optional splunk handler name\n    :param splunk_sleep_interval: optional splunk sleep interval\n    :param splunk_debug: optional splunk debug - default to False\n\n    \"\"\"\n\n    if SPLUNK_DEBUG:\n        splunk_debug = True\n\n    if not splunk_token:\n        if SPLUNK_TOKEN:\n            splunk_token = splunk_token\n\n    config = None\n    if os.getenv(\n            'LOG_DICT',\n            False):\n        try:\n            config = json.loads(os.getenv(\n                'LOG_DICT',\n                None).strip())\n        except Exception as e:\n            print(\n                'Please confirm the env key LOG_DICT has a valid '\n                'JSON dictionary. Failed json.loads() parsing with '\n                '- using default config for '\n                'ex={}').format(\n                    e)\n        # try to parse the dict and log it that there was a failure\n\n    elif log_dict:\n        config = config\n    # end of if passed in set in an environment variable\n\n    if not config and default_path:\n        path = default_path\n        file_name = default_path.split('/')[-1]\n        if config_name:\n            file_name = config_name\n        path = '{}/{}'.format(\n                    '/'.join(default_path.split('/')[:-1]),\n                    file_name)\n        value = os.getenv(env_key, None)\n        if value:\n            path = value\n        if os.path.exists(path):\n            with open(path, 'rt') as f:\n                config = json.load(f)\n        else:\n            cwd_path = os.getcwd() + '/spylunking/log/{}'.format(\n                file_name)\n            if os.path.exists(cwd_path):\n                with open(cwd_path, 'rt') as f:\n                    config = json.load(f)\n            else:\n                rels_path = os.getcwd() + '/../log/{}'.format(\n                    file_name)\n                if os.path.exists(rels_path):\n                    with open(rels_path, 'rt') as f:\n                        config = json.load(f)\n                else:\n                    repo_config = (\n                        '/opt/spylunking/spylunking/log/'\n                        'shared-logging.json')\n                    if os.path.exists(repo_config):\n                        if splunk_debug:\n                            print(\n                                'checking repo_config={}'.format(\n                                    repo_config))\n                        with open(repo_config, 'rt') as f:\n                            config = json.load(f)\n        # end of finding a config dictionary\n    # end of trying to find a config on disk\n\n    if config:\n        if handlers_dict:\n            config['handlers'] = handlers_dict\n\n        found_splunk_handler = False\n        if handler_name:\n            for hidx, h in enumerate(config['handlers']):\n                if splunk_debug:\n                    print('handler={} name={}'.format(\n                        hidx,\n                        h))\n                if handler_name == h:\n                    config['root']['handlers'].append(h)\n                # by default splunk_handler_name == 'splunk'\n                if splunk_handler_name == h and splunk_token:\n                    found_splunk_handler = True\n\n        if found_splunk_handler:\n            if splunk_token:\n                config['handlers'][splunk_handler_name]['token'] = \\\n                    splunk_token\n                config['handlers'][splunk_handler_name]['verify'] = \\\n                    splunk_verify\n                if splunk_host:\n                    config['handlers'][splunk_handler_name]['host'] = \\\n                        splunk_host\n                if splunk_port:\n                    config['handlers'][splunk_handler_name]['port'] = \\\n                        splunk_port\n                if splunk_index:\n                    config['handlers'][splunk_handler_name]['index'] = \\\n                        splunk_index\n\n                config['handlers'][splunk_handler_name]['debug'] = \\\n                    splunk_debug\n\n                if config['handlers'][splunk_handler_name].get(\n                        'queue_size',\n                        True):\n                    key = 'queue_size'\n                    config['handlers'][splunk_handler_name][key] = \\\n                        SPLUNK_QUEUE_SIZE\n                # end of checking for queue_size changes\n\n                if SPLUNK_RETRY_COUNT:\n                    key = 'retry_count'\n                    config['handlers'][splunk_handler_name][key] = \\\n                        SPLUNK_RETRY_COUNT\n                # end of checking for retry_count changes\n\n                if SPLUNK_TIMEOUT:\n                    config['handlers'][splunk_handler_name][key] = \\\n                        SPLUNK_TIMEOUT\n                # end of checking for splunk_timeout changes\n\n                key = 'sleep_interval'\n                if splunk_sleep_interval >= 0:\n                    config['handlers'][splunk_handler_name][key] = \\\n                        splunk_sleep_interval\n                else:\n                    if SPLUNK_SLEEP_INTERVAL:\n                        key = 'sleep_interval'\n                        config['handlers'][splunk_handler_name][key] = \\\n                            SPLUNK_SLEEP_INTERVAL\n\n                # end of checking for sleep_interval changes\n\n                if found_splunk_handler:\n                    config['root']['handlers'].append(\n                        splunk_handler_name)\n            else:\n                if splunk_debug:\n                    print(\n                        'Unable to get a valid splunk token '\n                        '- splunk disabled')\n                config['handlers'].pop('splunk', None)\n                good_handlers = []\n                for k in config['root']['handlers']:\n                    if k != splunk_handler_name:\n                        good_handlers.append(k)\n                config['root']['handlers'] = good_handlers\n        else:\n            if splunk_debug:\n                print(\n                    'splunk disabled')\n            config['handlers'].pop(splunk_handler_name, None)\n            good_handlers = []\n            for k in config['root']['handlers']:\n                if k != splunk_handler_name:\n                    good_handlers.append(k)\n            config['root']['handlers'] = good_handlers\n\n        if len(config['root']['handlers']) == 0:\n            print((\n                'Failed to find logging root.handlers={} in log '\n                'config={}').format(\n                    config['root']['handlers'],\n                    ppj(config)))\n        else:\n            if splunk_debug:\n                print((\n                    'Using log config={}').format(\n                        ppj(config)))\n        logging.config.dictConfig(\n            config)\n        return\n    else:\n        if not splunk_host and not splunk_port:\n            if SPLUNK_ADDRESS:\n                try:\n                    addr_split = SPLUNK_ADDRESS.split(':')\n                    if len(addr_split) > 1:\n                        splunk_host = addr_split[0]\n                        splunk_port = int(addr_split[1])\n                except Exception as e:\n                    print((\n                        'Failed building SPLUNK_ADDRESS={} as'\n                        'host:port with ex={}').format(\n                            SPLUNK_ADDRESS,\n                            e))\n        else:\n            if not splunk_host:\n                if SPLUNK_HOST:\n                    splunk_host = SPLUNK_HOST\n            if not splunk_port:\n                if SPLUNK_PORT:\n                    splunk_port = SPLUNK_PORT\n        # end of connectivity changes from env vars\n\n        config = {\n            'version': 1,\n            'disable_existing_loggers': False,\n            'formatters': {\n                'colors': {\n                    '()': 'colorlog.ColoredFormatter',\n                    'format': (\n                        '%(log_color)s%(asctime)s - %(name)s - '\n                        '%(levelname)s - %(message)s%(reset)s')\n                },\n                'no_date_colors': {\n                    '()': 'colorlog.ColoredFormatter',\n                    'format': (\n                        '%(log_color)s%(name)s - %(levelname)s '\n                        '- %(message)s%(reset)s')\n                },\n                'simple': {\n                    '()': 'colorlog.ColoredFormatter',\n                    'format': (\n                        '%(log_color)s'\n                        '%(message)s%(reset)s')\n                },\n                splunk_handler_name: {\n                    '()': 'spylunking.log.setup_logging.SplunkFormatter',\n                    'format': (\n                        '%(asctime)s - %(name)s - %(levelname)s '\n                        '- %(message)s [%(filename)s:%(lineno)s]')\n                }\n            },\n            'handlers': {\n                'console': {\n                    'class': 'logging.StreamHandler',\n                    'level': 'INFO',\n                    'formatter': 'colors',\n                    'stream': 'ext://sys.stdout'\n                },\n                'no_date_colors': {\n                    'class': 'logging.StreamHandler',\n                    'level': 'INFO',\n                    'formatter': 'no_date_colors',\n                    'stream': 'ext://sys.stdout'\n                },\n                'simple': {\n                    'class': 'logging.StreamHandler',\n                    'level': 'INFO',\n                    'formatter': 'simple',\n                    'stream': 'ext://sys.stdout'\n                }\n            },\n            'loggers': {\n                '': {\n                    'level': 'INFO',\n                    'propagate': True\n                }\n            },\n            'root': {\n                'level': 'INFO',\n                'propagate': True,\n                'handlers': [\n                    'console'\n                ]\n            }\n        }\n        if splunk_token and splunk_host and splunk_port:\n            config['handlers'][splunk_handler_name] = {\n                'class': (\n                    'spylunking.splunk_publisher.SplunkPublisher'),\n                'host': splunk_host,\n                'port': splunk_port,\n                'index': SPLUNK_INDEX,\n                'token': splunk_token,\n                'formatter': splunk_handler_name,\n                'sourcetype': SPLUNK_SOURCETYPE,\n                'verify': SPLUNK_VERIFY,\n                'timeout': SPLUNK_TIMEOUT,\n                'retry_count': SPLUNK_RETRY_COUNT,\n                'sleep_interval': SPLUNK_SLEEP_INTERVAL,\n                'queue_size': SPLUNK_QUEUE_SIZE,\n                'debug': SPLUNK_DEBUG\n            }\n            config['root']['handlers'].append(splunk_handler_name)\n        # only add splunk if the token is set for HEC\n        logging.config.dictConfig(config)\n        return", "response": "Setup logging for the current instance of the current application."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfunction to build a colorized logger with the given name config and handlers dict.", "response": "def build_colorized_logger(\n        name='lg',\n        config='shared-logging.json',\n        log_level=logging.INFO,\n        log_config_path=None,\n        handler_name='console',\n        handlers_dict=None,\n        enable_splunk=True,\n        splunk_user=None,\n        splunk_password=None,\n        splunk_address=None,\n        splunk_api_address=None,\n        splunk_index=None,\n        splunk_token=None,\n        splunk_handler_name='splunk',\n        splunk_sleep_interval=-1,\n        splunk_verify=None,\n        splunk_debug=False):\n    \"\"\"build_colorized_logger\n\n    Build a colorized logger using function arguments and environment\n    variables.\n\n    :param name: name that shows in the logger\n    :param config: name of the config file\n    :param log_level: level to log\n    :param log_config_path: path to log config file\n    :param handler_name: handler name in the config\n    :param handlers_dict: handlers dict\n    :param enable_splunk: Turn off splunk even if the env keys are set\n                          True by default - all processes that have the\n                          ``SPLUNK_*`` env keys will publish logs to splunk\n    :param splunk_user: splunk username - defaults to environment variable:\n                        SPLUNK_USER\n    :param splunk_password: splunk password - defaults to\n                            environment variable:\n                            SPLUNK_PASSWORD\n    :param splunk_address: splunk address - defaults to environment variable:\n                           SPLUNK_ADDRESS which is localhost:8088\n    :param splunk_api_address: splunk api address - defaults to\n                               environment variable:\n                               SPLUNK_API_ADDRESS which is localhost:8089\n    :param splunk_index: splunk index - defaults to environment variable:\n                         SPLUNK_INDEX\n    :param splunk_token: splunk token - defaults to environment variable:\n                         SPLUNK_TOKEN\n    :param splunk_handler_name: splunk log config handler name - defaults to :\n                                SPLUNK_HANDLER_NAME\n    :param splunk_handler_name: splunk log config handler name - defaults to :\n                                SPLUNK_HANDLER_NAME\n    :param splunk_sleep_interval: optional splunk sleep interval\n    :param splunk_verify: splunk verify - defaults to environment variable:\n                          SPLUNK_VERIFY=<1|0>\n    :param splunk_debug: print out the connection attempt for debugging\n                         Please Avoid on production...\n    \"\"\"\n\n    use_log_config_path = '{}/{}'.format(\n        os.getenv(\n            'LOG_CFG',\n            os.path.dirname(os.path.realpath(__file__))),\n        config)\n    use_splunk_user = SPLUNK_USER\n    use_splunk_password = SPLUNK_PASSWORD\n    use_splunk_address = SPLUNK_ADDRESS\n    use_splunk_api_address = SPLUNK_API_ADDRESS\n    use_splunk_token = SPLUNK_TOKEN\n    use_splunk_index = SPLUNK_INDEX\n    use_splunk_verify = SPLUNK_VERIFY\n    use_splunk_debug = SPLUNK_DEBUG\n    use_splunk_handler_name = SPLUNK_HANDLER_NAME\n    use_handler_name = LOG_HANDLER_NAME\n    use_handlers_dict = None\n    use_splunk_host = None\n    use_splunk_port = None\n    if log_config_path:\n        use_log_config_path = log_config_path\n    if handler_name:\n        use_handler_name = handler_name\n    if handlers_dict:\n        use_handlers_dict = handlers_dict\n    if splunk_user:\n        use_splunk_user = splunk_user\n    if splunk_password:\n        use_splunk_password = splunk_password\n    if splunk_address:\n        use_splunk_address = splunk_address\n    if splunk_api_address:\n        if 'https:' in splunk_api_address:\n            use_splunk_api_address = splunk_api_address\n        else:\n            use_splunk_api_address = 'https://{}'.format(\n                splunk_api_address)\n    else:\n        use_splunk_api_address = 'https://{}'.format(\n            use_splunk_api_address)\n    if splunk_index:\n        use_splunk_index = splunk_index\n    if splunk_token:\n        use_splunk_token = splunk_token\n    if splunk_handler_name:\n        use_splunk_handler_name = splunk_handler_name\n    if splunk_verify:\n        use_splunk_verify = splunk_verify\n    if splunk_debug:\n        use_splunk_debug = splunk_debug\n\n    override_config = os.getenv(\n        'SHARED_LOG_CFG',\n        None)\n    debug_log_config = bool(os.getenv(\n        'DEBUG_SHARED_LOG_CFG',\n        '0') == '1')\n    use_config = (\n        './log/{}').format(\n            '{}'.format(\n                config))\n    if override_config:\n        if debug_log_config:\n            print((\n                'creating logger config env var: '\n                'SHARED_LOG_CFG={}'.format(\n                    override_config)))\n        use_config = override_config\n    else:\n        if debug_log_config:\n            print((\n                'Not using shared logging env var: '\n                'SHARED_LOG_CFG={}'.format(\n                    override_config)))\n    # allow a shared log config across all components\n\n    if not os.path.exists(use_config):\n        use_config = use_log_config_path\n        if not os.path.exists(use_config):\n            use_config = ('./spylunking/log/{}').format(\n                    config)\n            if not os.path.exists(use_config):\n                use_config = ('./spylunking/log/{}').format(\n                    'shared-logging.json')\n    # find the log processing\n\n    try:\n        use_splunk_host = use_splunk_address.split(':')[0]\n        use_splunk_port = int(use_splunk_address.split(':')[1])\n    except Exception as e:\n        print((\n            'Failed parsing Splunk Address={} '\n            'with ex={}').format(\n                use_splunk_address,\n                e))\n        use_splunk_host = None\n        use_splunk_port = None\n    # end of try/ex to parse splunk address\n\n    if enable_splunk and (\n            use_splunk_user\n            and use_splunk_password\n            and use_splunk_address\n            and use_splunk_api_address):\n        try:\n            if SPLUNK_TOKEN:\n                use_splunk_token = SPLUNK_TOKEN\n            else:\n                use_splunk_token = get_token.get_token(\n                    user=use_splunk_user,\n                    password=use_splunk_password,\n                    url=use_splunk_api_address,\n                    verify=use_splunk_verify)\n            if use_splunk_debug:\n                print((\n                    'connected to splunk address={} user={} '\n                    'password={} token={}').format(\n                        use_splunk_address,\n                        use_splunk_user,\n                        use_splunk_password,\n                        use_splunk_token))\n        except Exception as e:\n            print((\n                'Failed connecting to splunk address={} user={} '\n                'ex={}').format(\n                    use_splunk_api_address,\n                    splunk_user,\n                    e))\n            use_splunk_token = None\n        # end of try/ex on splunk login\n    # end of try to set the token to use\n\n    if enable_splunk:\n        if use_splunk_token and use_splunk_debug:\n            print('Using splunk address={} token={}'.format(\n                use_splunk_address,\n                use_splunk_token))\n    else:\n        # turn off external keyword arguments (kwargs):\n        use_splunk_host = None\n        use_splunk_port = None\n        use_splunk_index = None\n        use_splunk_token = None\n\n    setup_logging(\n        default_level=log_level,\n        default_path=use_config,\n        handler_name=use_handler_name,\n        handlers_dict=use_handlers_dict,\n        splunk_host=use_splunk_host,\n        splunk_port=use_splunk_port,\n        splunk_index=use_splunk_index,\n        splunk_token=use_splunk_token,\n        splunk_handler_name=use_splunk_handler_name,\n        splunk_sleep_interval=splunk_sleep_interval,\n        splunk_verify=use_splunk_verify,\n        splunk_debug=use_splunk_debug)\n\n    if enable_splunk:\n        default_fields = {\n            'name': SPLUNK_LOG_NAME,\n            'dc': SPLUNK_DEPLOY_CONFIG,\n            'env': SPLUNK_ENV_NAME\n        }\n\n        last_step = ''\n        try:\n            last_step = (\n                'checking if LOG_FIELDS_DICT '\n                'has valid JSON using json.loads({})').format(\n                    os.getenv(\n                        'LOG_FIELDS_DICT',\n                        None))\n            if use_splunk_debug:\n                print(last_step)\n            if os.getenv(\n                    'LOG_FIELDS_DICT',\n                    None):\n                default_fields = json.loads(\n                    os.getenv(\n                        'LOG_FIELDS_DICT',\n                        default_fields))\n            last_step = (\n                'looking for splunk_handler={}').format(\n                    splunk_handler_name)\n            if use_splunk_debug:\n                print(last_step)\n            for i in logging.root.handlers:\n                handler_class_name = i.__class__.__name__.lower()\n                last_step = (\n                    'checking splunk_handler_name={} '\n                    'in handler_name={} or '\n                    'hasattr({}.formatter, set_fields)').format(\n                        handler_class_name,\n                        splunk_handler_name,\n                        handler_class_name)\n                if use_splunk_debug:\n                    print(last_step)\n                if (splunk_handler_name in handler_class_name\n                        or hasattr(i.formatter, 'set_fields')):\n                    last_step = (\n                        'assigning fields={} to formatter={}').format(\n                            default_fields,\n                            i.formatter.__class__.__name__)\n                    if use_splunk_debug:\n                        print(last_step)\n                    i.formatter.set_fields(\n                        new_fields=default_fields)\n        except Exception as e:\n            print((\n                'Failed assigning splunk_handler_name={} '\n                'during last_step={} with ex={}').format(\n                    splunk_handler_name,\n                    last_step,\n                    e))\n        # end of try/ex for setting the formatter\n    return logging.getLogger(name)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef simple_logger(\n        name='',\n        config='shared-logging.json',\n        log_level=logging.INFO,\n        log_config_path=None,\n        handler_name='simple',\n        handlers_dict=None,\n        enable_splunk=False,\n        splunk_user=None,\n        splunk_password=None,\n        splunk_address=None,\n        splunk_api_address=None,\n        splunk_index=None,\n        splunk_token=None,\n        splunk_handler_name=None,\n        splunk_sleep_interval=-1,\n        splunk_verify=None,\n        splunk_debug=False):\n    \"\"\"simple_logger\n\n    Build a colorized logger for just the message - Used by\n    command line tools.\n\n    :param name: name that shows in the logger\n    :param config: name of the config file\n    :param log_level: level to log\n    :param log_config_path: path to log config file\n    :param handler_name: handler name in the config\n    :param handlers_dict: handlers dict\n    :param enable_splunk: Turn off splunk even if the env keys are set\n                          False by default - all processes that have the\n                          ``SPLUNK_*`` env keys will publish logs to splunk\n    :param splunk_user: splunk username - defaults to environment variable:\n                        SPLUNK_USER\n    :param splunk_password: splunk password - defaults to\n                            environment variable:\n                            SPLUNK_PASSWORD\n    :param splunk_address: splunk address - defaults to environment variable:\n                           SPLUNK_ADDRESS which is localhost:8088\n    :param splunk_api_address: splunk api address - defaults to\n                               environment variable:\n                               SPLUNK_API_ADDRESS which is localhost:8089\n    :param splunk_index: splunk index - defaults to environment variable:\n                         SPLUNK_INDEX\n    :param splunk_token: splunk token - defaults to environment variable:\n                         SPLUNK_TOKEN\n    :param splunk_handler_name: splunk log config handler name - defaults to :\n                           SPLUNK_HANDLER_NAME\n    :param splunk_sleep_interval: optional splunk sleep interval\n    :param splunk_verify: splunk verify - defaults to environment variable:\n                          SPLUNK_VERIFY=<1|0>\n    :param splunk_debug: print out the connection attempt for debugging\n                         Please Avoid on production...\n    \"\"\"\n\n    return build_colorized_logger(\n        name=name,\n        config=config,\n        log_level=log_level,\n        log_config_path=log_config_path,\n        handler_name=handler_name,\n        handlers_dict=handlers_dict,\n        enable_splunk=enable_splunk,\n        splunk_user=splunk_user,\n        splunk_password=splunk_password,\n        splunk_address=splunk_address,\n        splunk_api_address=splunk_api_address,\n        splunk_index=splunk_index,\n        splunk_token=splunk_token,\n        splunk_handler_name=splunk_handler_name,\n        splunk_sleep_interval=splunk_sleep_interval,\n        splunk_verify=splunk_verify,\n        splunk_debug=splunk_debug)", "response": "Simple logger for all processes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchanging the fields that will be added in on a log", "response": "def set_fields(\n            self,\n            new_fields):\n        \"\"\"set_fields\n\n        Change the fields that will be added in on\n        a log\n\n        :param new_fields: new fields to patch in\n        \"\"\"\n        self.org_fields = {}\n        self.fields_to_add = {}\n        for k in new_fields:\n            self.org_fields[k] = new_fields[k]\n            self.fields_to_add[k] = new_fields[k]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_fields(\n            self,\n            log_record,\n            record,\n            message_dict):\n        \"\"\"add_fields\n\n        :param log_record: log record\n        :param record: log message\n        :param message_dict: message dict\n        \"\"\"\n        super(\n            SplunkFormatter,\n            self).add_fields(\n                log_record,\n                record,\n                message_dict)\n        if not log_record.get('timestamp'):\n            now = datetime.datetime.utcnow().strftime(\n                '%Y-%m-%dT%H:%M:%S.%fZ')\n            log_record['timestamp'] = now", "response": "Add fields to log record and message dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef format(\n            self,\n            record,\n            datefmt='%Y:%m:%d %H:%M:%S.%f'):\n        \"\"\"format\n\n        :param record: message object to format\n        \"\"\"\n\n        now = datetime.datetime.now()\n        utc_now = datetime.datetime.utcnow()\n        asctime = None\n        if self.datefmt:\n            asctime = now.strftime(\n                self.datefmt)\n        else:\n            asctime = now.strftime(\n                datefmt)\n\n        message = {\n            'time': record.created,\n            'timestamp': utc_now.strftime(\n                '%Y-%m-%dT%H:%M:%S.%fZ'),\n            'asctime': asctime,\n            'path': record.pathname,\n            'message': record.getMessage(),\n            'exc': None,\n            'logger_name': record.name\n        }\n\n        if record.exc_info and not message.get('exc'):\n            message['exc'] = self.formatException(\n                record.exc_info)\n        if not message.get(\n                'exc') and record.exc_text:\n            message['exc'] = record.exc_text\n\n        log_record = {}\n        try:\n            log_record = OrderedDict()\n        except NameError:\n            log_record = {}\n        # end of try/ex\n\n        message.update(\n            self.fields_to_add)\n        self.add_fields(\n            log_record,\n            record,\n            message)\n        use_log_record = self.process_log_record(\n            log_record)\n        return '{}{}'.format(\n            self.prefix,\n            self.jsonify_log_record(\n                use_log_record))", "response": "Formats the log record into a string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nperforming optimizations on already parsed code.", "response": "def optimized(code, silent=True, ignore_errors=True):\n    \"\"\"Performs optimizations on already parsed code.\"\"\"\n    return constant_fold(code, silent=silent, ignore_errors=ignore_errors)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef constant_fold(code, silent=True, ignore_errors=True):\n    # Loop until we haven't done any optimizations.  E.g., \"2 3 + 5 *\" will be\n    # optimized to \"5 5 *\" and in the next iteration to 25.  Yes, this is\n    # extremely slow, big-O wise. We'll fix that some other time. (TODO)\n\n    arithmetic = list(map(instructions.lookup, [\n        instructions.add,\n        instructions.bitwise_and,\n        instructions.bitwise_or,\n        instructions.bitwise_xor,\n        instructions.div,\n        instructions.equal,\n        instructions.greater,\n        instructions.less,\n        instructions.mod,\n        instructions.mul,\n        instructions.sub,\n    ]))\n\n    divzero = map(instructions.lookup, [\n        instructions.div,\n        instructions.mod,\n    ])\n\n    lookup = instructions.lookup\n\n    def isfunction(op):\n        try:\n            instructions.lookup(op)\n            return True\n        except KeyError:\n            return False\n\n    def isconstant(op):\n        return op is None or interpreter.isconstant(op, quoted=True) or not isfunction(op)\n\n    keep_running = True\n    while keep_running:\n        keep_running = False\n        # Find two consecutive numbes and an arithmetic operator\n        for i, a in enumerate(code):\n            b = code[i+1] if i+1 < len(code) else None\n            c = code[i+2] if i+2 < len(code) else None\n\n            # Constant fold arithmetic operations (TODO: Move to check-func)\n            if interpreter.isnumber(a, b) and c in arithmetic:\n                # Although we can detect division by zero at compile time, we\n                # don't report it here, because the surrounding system doesn't\n                # handle that very well. So just leave it for now.  (NOTE: If\n                # we had an \"error\" instruction, we could actually transform\n                # the expression to an error, or exit instruction perhaps)\n                if b==0 and c in divzero:\n                    if ignore_errors:\n                        continue\n                    else:\n                        raise errors.CompileError(ZeroDivisionError(\n                            \"Division by zero\"))\n\n                # Calculate result by running on a machine (lambda vm: ... is\n                # embedded pushes, see compiler)\n                result = interpreter.Machine([lambda vm: vm.push(a), lambda vm:\n                    vm.push(b), instructions.lookup(c)]).run().top\n                del code[i:i+3]\n                code.insert(i, result)\n\n                if not silent:\n                    print(\"Optimizer: Constant-folded %s %s %s to %s\" % (a,b,c,result))\n\n                keep_running = True\n                break\n\n            # Translate <constant> dup to <constant> <constant>\n            if isconstant(a) and b == lookup(instructions.dup):\n                code[i+1] = a\n                if not silent:\n                    print(\"Optimizer: Translated %s %s to %s %s\" % (a,b,a,a))\n                keep_running = True\n                break\n\n            # Dead code removal: <constant> drop\n            if isconstant(a) and b == lookup(instructions.drop):\n                del code[i:i+2]\n                if not silent:\n                    print(\"Optimizer: Removed dead code %s %s\" % (a,b))\n                keep_running = True\n                break\n\n            if a == lookup(instructions.nop):\n                del code[i]\n                if not silent:\n                    print(\"Optimizer: Removed dead code %s\" % a)\n                keep_running = True\n                break\n\n            # Dead code removal: <integer> cast_int\n            if isinstance(a, int) and b == lookup(instructions.cast_int):\n                del code[i+1]\n                if not silent:\n                    print(\"Optimizer: Translated %s %s to %s\" % (a,b,a))\n                keep_running = True\n                break\n\n            # Dead code removal: <float> cast_float\n            if isinstance(a, float) and b == lookup(instructions.cast_float):\n                del code[i+1]\n                if not silent:\n                    print(\"Optimizer: Translated %s %s to %s\" % (a,b,a))\n                keep_running = True\n                break\n\n            # Dead code removal: <string> cast_str\n            if isinstance(a, str) and b == lookup(instructions.cast_str):\n                del code[i+1]\n                if not silent:\n                    print(\"Optimizer: Translated %s %s to %s\" % (a,b,a))\n                keep_running = True\n                break\n\n            # Dead code removal: <boolean> cast_bool\n            if isinstance(a, bool) and b == lookup(instructions.cast_bool):\n                del code[i+1]\n                if not silent:\n                    print(\"Optimizer: Translated %s %s to %s\" % (a,b,a))\n                keep_running = True\n                break\n\n            # <c1> <c2> swap -> <c2> <c1>\n            if isconstant(a) and isconstant(b) and c == lookup(instructions.swap):\n                del code[i:i+3]\n                code = code[:i] + [b, a] + code[i:]\n                if not silent:\n                    print(\"Optimizer: Translated %s %s %s to %s %s\" %\n                            (a,b,c,b,a))\n                keep_running = True\n                break\n\n            # a b over -> a b a\n            if isconstant(a) and isconstant(b) and c == lookup(instructions.over):\n                code[i+2] = a\n                if not silent:\n                    print(\"Optimizer: Translated %s %s %s to %s %s %s\" %\n                            (a,b,c,a,b,a))\n                keep_running = True\n                break\n\n            # \"123\" cast_int -> 123\n            if interpreter.isstring(a) and b == lookup(instructions.cast_int):\n                try:\n                    number = int(a)\n                    del code[i:i+2]\n                    code.insert(i, number)\n                    if not silent:\n                        print(\"Optimizer: Translated %s %s to %s\" % (a, b,\n                            number))\n                    keep_running = True\n                    break\n                except ValueError:\n                    pass\n\n            if isconstant(a) and b == lookup(instructions.cast_str):\n                del code[i:i+2]\n                code.insert(i, str(a)) # TODO: Try-except here\n                if not silent:\n                    print(\"Optimizer: Translated %s %s to %s\" % (a, b, str(a)))\n                keep_running = True\n                break\n\n            if isconstant(a) and b == lookup(instructions.cast_bool):\n                del code[i:i+2]\n                code.insert(i, bool(a)) # TODO: Try-except here\n                if not silent:\n                    print(\"Optimizer: Translated %s %s to %s\" % (a, b, bool(a)))\n                keep_running = True\n                break\n\n            if isconstant(a) and b == lookup(instructions.cast_float):\n                try:\n                    v = float(a)\n                    del code[i:i+2]\n                    code.insert(i, v)\n                    if not silent:\n                        print(\"Optimizer: Translated %s %s to %s\" % (a, b, v))\n                    keep_running = True\n                    break\n                except ValueError:\n                    pass\n    return code", "response": "A simple expression like 2 3 + 5 to 5."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pre_sql_setup(self):\n        super(MultilingualSQLCompiler, self).pre_sql_setup()\n\n        if not self.query.include_translation_data:\n            return\n\n        opts = self.query.model._meta\n        qn = self.quote_name_unless_alias\n        qn2 = self.connection.ops.quote_name\n\n        if hasattr(opts, 'translation_model'):\n            master_table_name = self.query.join((None, opts.db_table, None, None))\n            translation_opts = opts.translation_model._meta\n            trans_table_name = translation_opts.db_table\n            for language_code in get_language_code_list():\n                table_alias = get_translation_table_alias(trans_table_name,\n                                                          language_code)\n                trans_join = (\"LEFT JOIN %s AS %s ON ((%s.master_id = %s.%s) AND (%s.language_code = '%s'))\"\n                           % (qn2(translation_opts.db_table),\n                           qn2(table_alias),\n                           qn2(table_alias),\n                           qn(master_table_name),\n                           qn2(opts.pk.column),\n                           qn2(table_alias),\n                           language_code))\n                self.query.extra_join[table_alias] = trans_join", "response": "Adds the JOINS and SELECTS for fetching multilingual data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd the JOINS for related multilingual fields filtering.", "response": "def get_from_clause(self):\n        \"\"\"\n        Add the JOINS for related multilingual fields filtering.\n        \"\"\"\n        result = super(MultilingualSQLCompiler, self).get_from_clause()\n\n        if not self.query.include_translation_data:\n            return result\n\n        from_ = result[0]\n        for join in self.query.extra_join.values():\n            from_.append(join)\n        return (from_, result[1])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save_new(self, form, commit=True):\n        kwargs = {self.fk.get_attname(): self.instance.pk}\n        new_obj = self.model(**kwargs)\n        self._prepare_multilingual_object(new_obj, form)\n        return forms.save_instance(form, new_obj, exclude=[self._pk_field.name], commit=commit)", "response": "Save a new object to the database."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save_existing(self, form, instance, commit=True):\n        self._prepare_multilingual_object(instance, form)\n        return forms.save_instance(form, instance, exclude=[self._pk_field.name], commit=commit)", "response": "Save an existing object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef queryset(self, request):\n        qs = super(MultilingualInlineAdmin, self).queryset(request)\n        # Don't now what the hell I was thinking here, but this code breaks stuff:\n        #\n        # checkfield = self.get_fill_check_field()\n        # if checkfield is not None:\n        #     kwargs = {str('%s_%s__isnull' % (checkfield, GLL.language_code)): False}\n        #     from django.db.models.fields import CharField\n        #     if isinstance(self.model._meta.translation_model._meta.get_field_by_name(checkfield)[0], CharField):\n        #         kwargs[str('%s_%s__gt' % (checkfield, GLL.language_code))] = ''\n        #     return qs.filter(**kwargs)\n        return qs.filter(translations__language_code=GLL.language_code).distinct()", "response": "Filter objects which don t have a value in this language\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndisplaying a list of your devices and their APIs.", "response": "def cli(wio):\n    '''\n    Displays a list of your devices.\n\n    \\b\n    DOES:\n        Displays a list of your devices, as well as their APIs\n\n    \\b\n    USE:\n        wio list\n    '''\n    user_token = wio.config.get(\"token\", None)\n    api_prefix = wio.config.get(\"mserver\", None)\n    if not api_prefix or not user_token:\n        click.echo(click.style('>> ', fg='red') + \"Please login, use \" +\n            click.style(\"wio login\", fg='green'))\n        return\n\n    thread = termui.waiting_echo(\"Retrieving devices...\")\n    thread.daemon = True\n    thread.start()\n    params = {\"access_token\":user_token}\n    try:\n        r = requests.get(\"%s%s\" %(api_prefix, node_list_endpoint), params=params, timeout=10, verify=verify)\n        r.raise_for_status()\n        json_response = r.json()\n    except requests.exceptions.HTTPError as e:\n        thread.stop('')\n        thread.join()\n        if r.status_code == 400:\n            error = r.json().get(\"error\", None)\n            click.secho(\">> %s\" %error, fg='red')\n        else:\n            click.secho(\">> %s\" %e, fg='red')\n        return\n    except Exception as e:\n        thread.stop('')\n        thread.join()\n        click.secho(\">> %s\" %e, fg='red')\n        return\n\n    nodes = json_response.get(\"nodes\", None)\n    thread.message(\"Retrieving device APIs...\")\n    node_list = []\n    for n in nodes:\n        if n['name'] == 'node000':\n            params = {\"access_token\":user_token, \"node_sn\":n['node_sn']}\n            try:\n                r = requests.post(\"%s%s\" %(api_prefix, nodes_delete_endpoint), params=params, timeout=10, verify=verify)\n                r.raise_for_status()\n                json_response = r.json()\n            except requests.exceptions.HTTPError as e:\n                thread.stop('')\n                thread.join()\n                if r.status_code == 400:\n                    error = r.json().get(\"error\", None)\n                    click.secho(\">> %s\" %error, fg='red')\n                else:\n                    click.secho(\">> %s\" %e, fg='red')\n                return\n            except Exception as e:\n                thread.stop('')\n                thread.join()\n                click.secho(\">> %s\" %e, fg='red')\n                return\n            continue\n        if n[\"online\"]:\n            params = {\"access_token\":n[\"node_key\"]}\n            try:\n                r = requests.get(\"%s%s\" %(api_prefix, well_known_endpoint), params=params, timeout=15, verify=verify)\n                r.raise_for_status()\n                json_response = r.json()\n            except requests.exceptions.HTTPError as e:\n                # thread.stop('')\n                # thread.join()\n                if r.status_code == 400:\n                    error = r.json().get(\"error\", None)\n                    click.secho(\">> %s\" %error, fg='red')\n                else:\n                    click.secho(\">> %s\" %e, fg='red')\n                n['well_known'] = []\n                # n['onoff'] = 'offline'\n            except Exception as e:\n                # thread.stop('')\n                # thread.join()\n                click.secho(\">> %s\" %e, fg='red')\n                n['well_known'] = []\n            else:\n                well_known = json_response[\"well_known\"] #todo error risk\n                n['well_known'] = well_known\n\n            n['onoff'] = 'online'\n        else:\n            n['well_known'] = []\n            n['onoff'] = 'offline'\n\n        n['resources'] = \"%s%s?access_token=%s\" %(api_prefix, node_resources_endpoint, n['node_key'])\n        node_list.append(n)\n\n    thread.stop('')\n    thread.join()\n\n    termui.tree(node_list)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconcatenating dataswim instances from and set it to the main dataframe", "response": "def concat(self, *dss, **kwargs):\n        \"\"\"\n        Concatenate dataswim instances from and\n                set it to the main dataframe\n\n        :param dss: dataswim instances to concatenate\n        :type dss: Ds\n        :param kwargs: keyword arguments for ``pd.concat``\n\n\n        \"\"\"\n        try:\n            df = pd.DataFrame()\n            for dsx in dss:\n                df = pd.concat([df, dsx.df], **kwargs)\n            self.df = df\n        except Exception as e:\n            self.err(e, \"Can not concatenate data\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef split_(self, col: str) -> \"list(Ds)\":\n        try:\n            dss = {}\n            unique = self.df[col].unique()\n            for key in unique:\n                df2 = self.df.loc[self.df[col] == key]\n                ds2 = self._duplicate_(df2)\n                dss[key] = ds2\n            return dss\n        except Exception as e:\n            self.err(e, \"Can not split dataframe\")", "response": "Split the main dataframe according to a column s unique values and\n            returns a dict of dataswim instances with the keys as keys and the values as values"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef merge(self, df: pd.DataFrame, on: str, how: str=\"outer\", **kwargs):\n        try:\n            df = pd.merge(self.df, df, on=on, how=how, **kwargs)\n            self.df = df\n        except Exception as e:\n            self.err(e, self.merge, \"Can not merge dataframes\")", "response": "Merge the main dataframe with the passed dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nquerying the server for a list of caches parse the JSON response and and AttributeNames return the result.", "response": "def caches(self, options={}):\n        \"\"\"Query the server for a list of caches, parse the JSON response, and\n        return the result.\n\n        Keyword arguments:\n        options -- a dict of arguments to send with the request. See\n                   http://dev.iron.io/cache/reference/api/#list_caches for more\n                   information on defaults and possible values.\n        \"\"\"\n        query = urllib.urlencode(options)\n        url = \"caches\"\n        if query != \"\":\n            url = \"%s?%s\" % (url, query)\n        result = self.client.get(url)\n        return [cache[\"name\"] for cache in result[\"body\"]]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nquery the server for an item parse the JSON and return the result.", "response": "def get(self, key, cache=None):\n        \"\"\"Query the server for an item, parse the JSON, and return the result.\n\n        Keyword arguments:\n        key -- the key of the item that you'd like to retrieve. Required.\n        cache -- the name of the cache that the item resides in. Defaults to\n                 None, which uses self.name. If no name is set, raises a\n                 ValueError.\n        \"\"\"\n        if cache is None:\n            cache = self.name\n        if cache is None:\n            raise ValueError(\"Cache name must be set\")\n        cache = quote_plus(cache)\n        key = quote_plus(key)\n        url = \"caches/%s/items/%s\" % (cache, key)\n        result = self.client.get(url)\n        return Item(values=result[\"body\"])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nput an item in a cache.", "response": "def put(self, key, value, cache=None, options={}):\n        \"\"\"Query the server to set the key specified to the value specified in\n        the specified cache.\n\n        Keyword arguments:\n        key -- the name of the key to be set. Required.\n        value -- the value to set key to. Must be a string or JSON\n                 serialisable. Required.\n        cache -- the cache to store the item in. Defaults to None, which uses\n                 self.name. If no name is set, raises a ValueError.\n        options -- a dict of arguments to send with the request. See\n                   http://dev.iron.io/cache/reference/api/#put_item for more\n                   information on defaults and possible values.\n        \"\"\"\n        if cache is None:\n            cache = self.name\n        if cache is None:\n            raise ValueError(\"Cache name must be set\")\n\n\n        if not isinstance(value, str_type) and not isinstance(value, int_types):\n            value = json.dumps(value)\n\n        options[\"value\"] = value\n        body = json.dumps(options)\n\n        cache = quote_plus(cache)\n        key = quote_plus(key)\n\n        result = self.client.put(\"caches/%s/items/%s\" % (cache, key), body,\n                {\"Content-Type\": \"application/json\"})\n        return Item(cache=cache, key=key, value=value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete(self, key, cache=None):\n        if cache is None:\n            cache = self.name\n        if cache is None:\n            raise ValueError(\"Cache name must be set\")\n        cache = quote_plus(cache)\n        key = quote_plus(key)\n\n        self.client.delete(\"caches/%s/items/%s\" % (cache, key))\n\n        return True", "response": "Delete an item from a cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nquery the server to increment the value of the specified key by the specified amount.", "response": "def increment(self, key, cache=None, amount=1):\n        \"\"\"Query the server to increment the value of the key by the specified\n        amount. Negative amounts can be used to decrement.\n\n        Keyword arguments:\n        key -- the key the item is stored under. Required.\n        cache -- the cache the item belongs to. Defaults to None, which uses\n                 self.name. If no name is set, raises a ValueError.\n        amount -- the amount to increment the value by. Can be negative to\n                  decrement the value. Defaults to 1.\n        \"\"\"\n        if cache is None:\n            cache = self.name\n        if cache is None:\n            raise ValueError(\"Cache name must be set\")\n        cache = quote_plus(cache)\n        key = quote_plus(key)\n\n        body = json.dumps({\"amount\": amount})\n\n        result = self.client.post(\"caches/%s/items/%s/increment\" % (cache,\n            key), body, {\"Content-Type\": \"application/json\"})\n        result = result[\"body\"]\n        return Item(values=result, cache=cache, key=key)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndump a representation of the Model on standard output.", "response": "def dump(self, *args, **kwargs):\n        \"\"\"Dumps a representation of the Model on standard output.\"\"\"\n        lxml.etree.dump(self._obj, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a function that returns the name of the requested parameter.", "response": "def queryNamer(paramName, usePageUrl=False):\n    \"\"\"Get name from URL query part.\"\"\"\n    @classmethod\n    def _namer(cls, imageUrl, pageUrl):\n        \"\"\"Get URL query part.\"\"\"\n        url = pageUrl if usePageUrl else imageUrl\n        return getQueryParams(url)[paramName][0]\n    return _namer"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a method that returns the first regular expression group from the given regular expression.", "response": "def regexNamer(regex, usePageUrl=False):\n    \"\"\"Get name from regular expression.\"\"\"\n    @classmethod\n    def _namer(cls, imageUrl, pageUrl):\n        \"\"\"Get first regular expression group.\"\"\"\n        url = pageUrl if usePageUrl else imageUrl\n        mo = regex.search(url)\n        if mo:\n            return mo.group(1)\n    return _namer"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbounce back and forth one time.", "response": "def bounceStarter(url, nextSearch):\n    \"\"\"Get start URL by \"bouncing\" back and forth one time.\"\"\"\n    @classmethod\n    def _starter(cls):\n        \"\"\"Get bounced start URL.\"\"\"\n        data = cls.getPage(url)\n        url1 = cls.fetchUrl(url, data, cls.prevSearch)\n        data = cls.getPage(url1)\n        return cls.fetchUrl(url1, data, nextSearch)\n    return _starter"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a function that returns the start URL of the given URL by indirection.", "response": "def indirectStarter(url, latestSearch):\n    \"\"\"Get start URL by indirection.\"\"\"\n    @classmethod\n    def _starter(cls):\n        \"\"\"Get indirect start URL.\"\"\"\n        data = cls.getPage(url)\n        return cls.fetchUrl(url, data, latestSearch)\n    return _starter"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_many(self, domains):\n        return dict((item.domain, item.status) for item in self.check_domain_request(domains))", "response": "Check availability for a number of domains. Returns a dictionary mapping the domain names to their statuses as a string\n        (\"active\"/\"free\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef check_domain_request(self, domains):\n        request = E.checkDomainRequest(\n            E.domains(\n                E.array(\n                    *[E.item(\n                        E.name(domain.split(\".\")[0]),\n                        E.extension(domain.split(\".\")[1])\n                    ) for domain in domains]\n                )\n            )\n        )\n\n        response = self.request(request)\n        return [Model(item) for item in response.data.array.item]", "response": "Return the availability of one or more domain names."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef relation(self, table, origin_field, search_field,\n                 destination_field=None, id_field=\"id\"):\n        \"\"\"\n        Add a column to the main dataframe from a relation foreign key \n        \"\"\"\n        df = self._relation(table, origin_field,\n                            search_field, destination_field, id_field)\n        self.df = df", "response": "Add a column to the main dataframe from a relation foreign key \n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a DataSwim instance filled from a relation foreign key", "response": "def relation_(self, table, origin_field, search_field, destination_field=None,\n                  id_field=\"id\"):\n        \"\"\"\n        Returns a DataSwim instance with a column filled from a relation foreign key \n        \"\"\"\n        df = self._relation(table, origin_field,\n                            search_field, destination_field, id_field)\n        return self._duplicate_(df)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _relation(self, table, origin_field, search_field, destination_field, id_field):\n        self.start(\"Processing relation\",\n                   origin_field, \"->\", search_field)\n        search_ds = self._duplicate_(db=self.db, quiet=True)\n        search_ds.load(table)\n        df = self.df.copy()\n        if destination_field is None:\n            destination_field = search_field\n        df[destination_field] = None\n\n        if origin_field not in self.df.columns.values:\n            msg = \"Can not find field \" + origin_field + \" in dataset: \"\n            msg += \"found fields \" + \", \".join(list(self.df.columns.values))\n            self.warning(msg)\n            return\n        if search_field not in search_ds.df.columns.values:\n            msg = \"Can not find field \" + search_field + \" in related dataset: \"\n            msg += \"found fields \" + \\\n                \", \".join(list(search_ds.df.columns.values))\n            self.warning(msg)\n            return\n\n        def set_rel(row):\n            try:\n                origin_val = row[origin_field]\n                end_val = search_ds.df.loc[search_ds.df[id_field]\n                                           == origin_val][search_field].values[0]\n                return end_val\n            except:\n                return nan\n\n        try:\n            df = df.copy()\n            df[destination_field] = df.apply(set_rel, axis=1)\n        except Exception as e:\n            self.err(e, self._relation, \"Can not get relation data\")\n            return\n        self.end(\"Finished processing relation\")\n        return df", "response": "This function takes a table and a field name and a field name and returns a new dataframe with the values of the related key in the main dataframe."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nclean pre - existing links in output directory.", "response": "def prepare_output(d):\n    \"\"\"Clean pre-existing links in output directory.\"\"\"\n    outDir = os.path.join(d, 'inorder')\n    if not os.path.exists(outDir):\n        os.mkdir(outDir)\n    for f in os.listdir(outDir):\n        f = os.path.join(outDir, f)\n        if os.path.islink(f):\n            os.remove(f)\n    return outDir"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates new symbolic links in output directory.", "response": "def create_symlinks(d):\n    \"\"\"Create new symbolic links in output directory.\"\"\"\n    data = loadJson(d)\n    outDir = prepare_output(d)\n\n    unseen = data[\"pages\"].keys()\n    while len(unseen) > 0:\n        latest = work = unseen[0]\n        while work in unseen:\n            unseen.remove(work)\n            if \"prev\" in data[\"pages\"][work]:\n                work = data[\"pages\"][work][\"prev\"]\n    print(\"Latest page: %s\" % (latest))\n\n    order = []\n    work = latest\n    while work in data[\"pages\"]:\n        order.extend(data[\"pages\"][work][\"images\"].values())\n        if \"prev\" in data[\"pages\"][work]:\n            work = data[\"pages\"][work][\"prev\"]\n        else:\n            work = None\n    order.reverse()\n\n    for i, img in enumerate(order):\n        os.symlink(os.path.join('..', img), os.path.join(outDir, '%05i_%s' % (i, img)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses source code returns an array of instructions suitable for a Machine.", "response": "def parse(source):\n    \"\"\"Parses source code returns an array of instructions suitable for\n    optimization and execution by a Machine.\n\n    Args:\n        source: A string or stream containing source code.\n    \"\"\"\n    if isinstance(source, str):\n        return parse_stream(six.StringIO(source))\n    else:\n        return parse_stream(source)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse a Forth - like language and return code.", "response": "def parse_stream(stream):\n    \"\"\"Parse a Forth-like language and return code.\"\"\"\n    code = []\n\n    for (line, col, (token, value)) in Tokenizer(stream).tokenize():\n        if token == Tokenizer.STRING:\n            value = '\"' + value + '\"'\n        code.append(value)\n\n    return code"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a config variable.", "response": "def get_var(self, var_name: str, default: Optional[Any] = _NONE) -> Any:\n        \"\"\"\n        Get a config variable. If a variable is not set, a resolver is not\n        set, and no default is given\n        :class:`~haps.exceptions.UnknownConfigVariable` is raised.\n\n        :param var_name: Name of variable\n        :param default: Default value\n        :return: Value of config variable\n        \"\"\"\n        try:\n            return self.cache[var_name]\n        except KeyError:\n            try:\n                var = self._resolve_var(var_name)\n            except UnknownConfigVariable as e:\n                if default is not _NONE:\n                    if callable(default):\n                        return default()\n                    else:\n                        return default\n                else:\n                    raise e\n            else:\n                self.cache[var_name] = var\n                return var"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef resolver(cls, var_name: str) -> FunctionType:\n        def dec(f):\n            if var_name in cls().resolvers:\n                raise ConfigurationError(\n                    f'Resolver for {var_name} already registered')\n            cls().resolvers[var_name] = f\n            return f\n\n        return dec", "response": "Function or method decorator that registers a new resolver for the given variable name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef env_resolver(cls, var_name: str, env_name: str = None,\n                     default: Any = _NONE) -> 'Configuration':\n        \"\"\"\n        Method for configuring environment resolver.\n\n        :param var_name: Variable name\n        :param env_name: An optional environment variable name. If not set\\\n            haps looks for `HAPS_var_name`\n        :param default: Default value for variable. If it's a callable,\\\n            is called before return. If not provided\\\n            :class:`~haps.exceptions.UnknownConfigVariable` is raised\n        :return: :class:`~haps.config.Configuration` instance for easy\\\n                  chaining\n        \"\"\"\n\n        cls.resolver(var_name)(\n            partial(\n                _env_resolver, var_name=var_name, env_name=env_name,\n                default=default))\n        return cls()", "response": "Method for configuring environment resolver."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set(cls, var_name: str, value: Any) -> 'Configuration':\n        with cls._lock:\n            if var_name not in cls().cache:\n                cls().cache[var_name] = value\n            else:\n                raise ConfigurationError(\n                    f'Value for {var_name} already set')\n        return cls()", "response": "Set the value of a variable in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef perform_create(self, data):\n\n        instance = self.model(**data)\n        self.request.dbsession.add(instance)\n        self.request.dbsession.flush()\n        return instance", "response": "This method is called by the base class to perform the actual creation of a new object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef perform_update(self, data, instance):\n\n        for key, val in data.items():\n            setattr(instance, key, val)", "response": "This method is called when the data is deserialized from a resource and the instance is updated."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nhooking for controlling the update of an model instance. Override this if you need to do more with your data before updating the object than just mapping the deserialized data to the attribute of the instance.", "response": "def perform_partial_update(self, data, instance):\n        \"\"\"\n        Hook for controlling the update of an model instance. Override this if you need to do more with your\n        data before updating the object than just mapping the deserialized data to the attribute of the instance.\n        \"\"\"\n\n        for key, val in data.items():\n            setattr(instance, key, val)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a new user s logins.", "response": "def cli(wio):\n    '''\n    Login state.\n\n    \\b\n    DOES:\n        Display login email, token, server url.\n\n    \\b\n    USE:\n        wio state\n    '''\n    user_token = wio.config.get(\"token\", None)\n    mserver_url = wio.config.get(\"mserver\", None)\n    if not mserver_url or not user_token:\n        click.echo(click.style('>> ', fg='red') + \"Please login, use \" +\n            click.style(\"wio login\", fg='green'))\n        return\n\n    email = wio.config.get(\"email\",None)\n    server = wio.config.get(\"server\",None)\n    token = wio.config.get(\"token\",None)\n    click.secho('> ', fg='green', nl=False)\n    click.echo(\"server: \" + click.style(server, fg='green', bold=True) + ', ' +\n        click.style(mserver_url, fg='green', bold=True))\n    click.secho('> ', fg='green', nl=False)\n    click.echo(\"email:  \" + click.style(email, fg='green', bold=True))\n    click.secho('> ', fg='green', nl=False)\n    click.echo(\"token:  \" + click.style(token, fg='green', bold=True))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef top_level(self):\n        output = {}\n        if isinstance(self.obj, dict):\n            for name, item in self.obj.items():\n                if isinstance(item, dict):\n                    if item:\n                        output[name] = StrReprWrapper('{...}')\n                    else:\n                        output[name] = StrReprWrapper('{}')\n                elif isinstance(item, list):\n                    if item:\n                        output[name] = StrReprWrapper('[...]')\n                    else:\n                        output[name] = StrReprWrapper('[]')\n                else:\n                    output[name] = item\n            return output\n        else:\n            return self.obj", "response": "Print just the top level of an object being sure to show where\n        it goes deeper"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a closure that pushed the given value onto a Machine s stack.", "response": "def make_embedded_push(value):\n    \"\"\"Returns a closure that pushed the given value onto a Machine's stack.\n\n    We use this to embed stack pushes in the VM code, so that the interpreter\n    can assume that all instructions are callable Python functions. This makes\n    dispatching much faster than checking if an instruction is a constant\n    (number, string, etc) or a Python function.\n    \"\"\"\n    push = lambda vm: vm.push(value)\n    push.tag = EMBEDDED_PUSH_TAG\n    return push"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nextracting the embedded push value.", "response": "def get_embedded_push_value(obj):\n    \"\"\"Extracts the embedded push value.\"\"\"\n    assert(is_embedded_push(obj))\n    assert(len(obj.__closure__) == 1)\n    return obj.__closure__[0].cell_contents"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check(code):\n    def safe_lookup(op):\n        try:\n            return instructions.lookup(op)\n        except Exception:\n            return op\n\n    for i, a in enumerate(code):\n        b = code[i+1] if i+1 < len(code) else None\n\n        # Does instruction exist?\n        if not isconstant(a):\n            try:\n                instructions.lookup(a)\n            except KeyError as err:\n                # Skip embedded push closures\n                if not (len(err.args)==1 and is_embedded_push(err.args[0])):\n                    raise CompileError(\"Instruction at index %d is unknown: %s\"\n                            % (i, a))\n\n        # Invalid: <str> int\n        if isstring(a) and safe_lookup(b) == instructions.cast_int:\n            raise CompileError(\n                \"Cannot convert string to integer (index %d): %s %s\" % (i, a,\n                    b))\n\n        # Invalid: <int> <binary op>\n        boolean_ops = [instructions.boolean_not,\n                      instructions.boolean_or,\n                      instructions.boolean_and]\n\n        if not isbool(a) and safe_lookup(b) in boolean_ops:\n            raise CompileError(\n                \"Can only use binary operators on booleans (index %d): %s %s\" %\n                    (i, a, b))\n    return code", "response": "Checks code for obvious errors."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef compile(code, silent=True, ignore_errors=False, optimize=True):\n    assert(isinstance(code, list))\n\n    output = []\n    subroutine = {}\n    builtins = Machine([]).instructions\n\n    # Gather up subroutines\n    try:\n        it = code.__iter__()\n        while True:\n            word = next(it)\n            if word == \":\":\n                name = next(it)\n                if name in builtins:\n                    raise CompileError(\"Cannot shadow internal word definition '%s'.\" % name)\n                if name in [\":\", \";\"]:\n                    raise CompileError(\"Invalid word name '%s'.\" % name)\n                subroutine[name] = []\n                while True:\n                    op = next(it)\n                    if op == \";\":\n                        subroutine[name].append(instructions.lookup(instructions.return_))\n                        break\n                    else:\n                        subroutine[name].append(op)\n            else:\n                output.append(word)\n    except StopIteration:\n        pass\n\n    # Expand all subroutine words to [\"<name>\", \"call\"]\n    for name, code in subroutine.items():\n        # For subroutines\n        xcode = []\n        for op in code:\n            xcode.append(op)\n            if op in subroutine:\n                xcode.append(instructions.lookup(instructions.call))\n        subroutine[name] = xcode\n\n    # Compile main code (code outside of subroutines)\n    xcode = []\n    for op in output:\n        xcode.append(op)\n        if op in subroutine:\n            xcode.append(instructions.lookup(instructions.call))\n\n    # Because main code comes before subroutines, we need to explicitly add an\n    # exit instruction\n    output = xcode\n    if len(subroutine) > 0:\n        output += [instructions.lookup(instructions.exit)]\n\n    # Optimize main code\n    if optimize:\n        output = optimizer.optimized(output, silent=silent, ignore_errors=False)\n\n    # Add subroutines to output, track their locations\n    location = {}\n    for name, code in subroutine.items():\n        location[name] = len(output)\n        if optimize:\n            output += optimizer.optimized(code, silent=silent, ignore_errors=False)\n        else:\n            output += code\n\n    # Resolve all subroutine references\n    for i, op in enumerate(output):\n        if op in location:\n            output[i] = location[op]\n\n    output = native_types(output)\n    if not ignore_errors:\n        check(output)\n    return output", "response": "Compiles a string of code into a complete working code."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef native_types(code):\n    out = []\n    for c in code:\n        if isconstant(c, quoted=True):\n            if isstring(c, quoted=True):\n                v = c[1:-1]\n            elif isbool(c):\n                v = to_bool(c)\n            elif isnumber(c):\n                v = c\n            else:\n                raise CompileError(\"Unknown type %s: %s\" % (type(c).__name__, c))\n\n            # Instead of pushing constants in the code, we always push callable\n            # Python functions, for fast dispatching:\n            out.append(make_embedded_push(v))\n        else:\n            try:\n                out.append(instructions.lookup(c))\n            except KeyError:\n                raise CompileError(\"Unknown word '%s'\" % c)\n    return out", "response": "Convert code elements from strings to native Python types."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef copy(self):\n        return Dimension(self._name, self._global_size,\n            lower_extent=self._lower_extent,\n            upper_extent=self._upper_extent,\n            description=self._description)", "response": "Returns a copy of the dimension."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update(self, global_size=None, lower_extent=None, upper_extent=None,\n        description=None):\n        \"\"\"\n        Update the dimension properties\n\n        Parameters\n        ----------\n        global_size : int\n            Global dimension size (Default value = None)\n        lower_extent : int\n            Lower dimension extent (Default value = None)\n        upper_extent : int\n            Upper dimension extent (Default value = None)\n        description : str\n            Dimension description (Default value = None)\n        \"\"\"\n\n        if global_size is not None: self._global_size = global_size\n        if lower_extent is not None: self._lower_extent = lower_extent\n        if upper_extent is not None: self._upper_extent = upper_extent\n        if description is not None: self._description = description\n\n        # Check that we've been given valid values\n        self.validate()", "response": "Update the properties of the dimension properties."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate the contents of a dimension data dictionary.", "response": "def validate(self):\n        \"\"\" Validate the contents of a dimension data dictionary \"\"\"\n\n        extents_valid = (0 <= self.lower_extent <= self.upper_extent\n            <= self.global_size)\n\n        if not extents_valid:\n            raise ValueError(\"Dimension '{d}' fails 0 <= {el} <= {eu} <= {gs}\"\n                .format(d=self.name, gs=self.global_size,\n                    el=self.lower_extent, eu=self.upper_extent))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sum_(self, col: str) -> float:\n        try:\n            df = self.df[col]\n            num = float(df.sum())\n            return num\n        except Exception as e:\n            self.err(e, \"Can not sum data on column \" + str(col))", "response": "Returns the sum of all the values in a column"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndrop some rows from the main dataframe", "response": "def dropr(self, *rows):\n        \"\"\"\n        Drops some rows from the main dataframe\n\n        :param rows: rows names\n        :type rows: list of ints\n\n        :example: ``ds.drop_rows([0, 2])``\n        \"\"\"\n        try:\n            self.df = rows = list(rows)\n            self.df.drop(rows)\n        except Exception as e:\n            self.err(e, self.dropr, \"Can not drop rows\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nappending a row to the main dataframe", "response": "def append(self, vals: list, index=None):\n        \"\"\"\n        Append a row to the main dataframe\n\n        :param vals: list of the row values to add\n        :type vals: list\n        :param index: index key, defaults to None\n        :param index: any, optional\n\n        :example: ``ds.append([0, 2, 2, 3, 4])``\n        \"\"\"\n        try:\n            self.df = self.df.loc[len(self.df.index)] = vals\n        except Exception as e:\n            self.err(e, self.append, \"Can not append row\")\n            return\n        self.ok(\"Row added to dataframe\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsorts the main dataframe according to the given column name", "response": "def sort(self, col: str):\n        \"\"\"\n        Sorts the main dataframe according to the given column\n\n        :param col: column name\n        :type col: str\n\n        :example: ``ds.sort(\"Col 1\")``\n        \"\"\"\n        try:\n            self.df = self.df.copy().sort_values(col)\n        except Exception as e:\n            self.err(e, \"Can not sort the dataframe from column \" +\n                     str(col))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reverse(self):\n        try:\n            self.df = self.df.iloc[::-1]\n        except Exception as e:\n            self.err(e, \"Can not reverse the dataframe\")", "response": "Reverses the main dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef apply(self, function: \"function\", *cols, axis=1, **kwargs):\n        try:\n            if len(cols) == 0:\n                self.df = self.df.apply(function, axis=axis, **kwargs)\n            else:\n                cols = list(cols)\n                self.df[cols] = self.df[cols].apply(function, **kwargs)\n        except Exception as e:\n            self.err(e, \"Can not apply function\")", "response": "Apply a function to the columns values\n getSequenceTime"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npivoting a dataframe into a new dataframe", "response": "def pivot(self, index, **kwargs):\n        \"\"\"\n        Pivots a dataframe\n        \"\"\"\n        try:\n            df = self._pivot(index, **kwargs)\n            return pd.pivot_table(self.df, index=kwargs[\"index\"],  **kwargs)\n            \"\"\"if df is None:\n                self.err(\"Can not pivot table\")\n                return\n            self.df = df\"\"\"\n        except Exception as e:\n            self.err(e, \"Can not pivot dataframe\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef trimquants(self, col: str, inf: float, sup: float):\n        try:\n            self.df = self._trimquants(col, inf, sup)\n        except Exception as e:\n            self.err(e, self.trimquants, \"Can not trim quantiles\")", "response": "Removes superior and inferior quantiles from the dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef trimsquants(self, col: str, sup: float):\n        try:\n            self.df = self._trimquants(col, None, sup)\n        except Exception as e:\n            self.err(e, self.trimsquants, \"Can not trim superior quantiles\")", "response": "Removes superior quantiles from the dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef trimiquants(self, col: str, inf: float):\n        try:\n            self.df = self._trimquants(col, inf, None)\n        except Exception as e:\n            self.err(e, self.trimiquants, \"Can not trim inferior quantiles\")", "response": "Removes superior and inferior quantiles from the dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if value is a ( quoted ) string.", "response": "def isstring(args, quoted=False):\n    \"\"\"Checks if value is a (quoted) string.\"\"\"\n    isquoted = lambda c: c[0]==c[-1] and c[0] in ['\"', \"'\"]\n\n    if quoted:\n        check = lambda c: isinstance(c, str) and isquoted(c)\n    else:\n        check = lambda c: isinstance(c, str)\n\n    if isinstance(args, list):\n        return all(map(check, args))\n    else:\n        return check(args)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if value is an integer long integer or float.", "response": "def isnumber(*args):\n    \"\"\"Checks if value is an integer, long integer or float.\n\n    NOTE: Treats booleans as numbers, where True=1 and False=0.\n    \"\"\"\n    return all(map(lambda c: isinstance(c, int) or isinstance(c, float), args))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef isbool(*args):\n    true_or_false = [instructions.lookup(instructions.true_),\n                     instructions.lookup(instructions.false_)]\n    return all(map(lambda c: isinstance(c, bool) or c in true_or_false, args))", "response": "Checks if value is boolean."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if value can be part of binary or bitwise operations.", "response": "def isbinary(*args):\n    \"\"\"Checks if value can be part of binary/bitwise operations.\"\"\"\n    return all(map(lambda c: isnumber(c) or isbool(c), args))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if value is a boolean number or string.", "response": "def isconstant(args, quoted=False):\n    \"\"\"Checks if value is a boolean, number or string.\"\"\"\n    check = lambda c: isbool(c) or isnumber(c) or isstring(c, quoted)\n    if isinstance(args, list):\n        return all(map(check, args))\n    else:\n        return check(args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef execute(source, optimize=True, output=sys.stdout, input=sys.stdin, steps=-1):\n    from crianza import compiler\n    code = compiler.compile(parser.parse(source), optimize=optimize)\n    machine = Machine(code, output=output, input=input)\n    return machine.run(steps)", "response": "Compiles and runs the specified source code and returns the Machine instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef eval(source, optimize=True, output=sys.stdout, input=sys.stdin, steps=-1):\n    machine = execute(source, optimize=optimize, output=output, input=input,\n            steps=steps)\n    ds = machine.stack\n\n    if len(ds) == 0:\n        return None\n    elif len(ds) == 1:\n        return ds[-1]\n    else:\n        return ds", "response": "Compiles and runs program returning the values on the stack."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nresetting stacks and instruction pointer.", "response": "def reset(self):\n        \"\"\"Reset stacks and instruction pointer.\"\"\"\n        self.data_stack = stack.Stack()\n        self.return_stack = stack.Stack()\n        self.instruction_pointer = 0\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pop(self):\n        try:\n            return self.data_stack.pop()\n        except errors.MachineError as e:\n            raise errors.MachineError(\"%s: At index %d in code: %s\" %\n                    (e, self.instruction_pointer, self.code_string))", "response": "Pops the data stack returning the value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef step(self):\n        op = self.code[self.instruction_pointer]\n        self.instruction_pointer += 1\n        op(self)", "response": "Executes one instruction and stops."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run(self, steps=None):\n        try:\n            while self.instruction_pointer < len(self.code):\n                self.step()\n\n                if steps is not None:\n                    steps -= 1\n                    if steps == 0:\n                        break\n        except StopIteration:\n            pass\n        except EOFError:\n            pass\n        return self", "response": "Run threaded code in machine."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nassigns the values from the dictionary passed in to the object.", "response": "def from_dict(self, values):\n        \"\"\"Assign the values from the dict passed in. All items in the dict\n        are assigned as attributes of the object.\n\n        :param dict values: The dictionary of values to assign to this mapping\n\n        \"\"\"\n        for k in values.keys():\n            setattr(self, k, values[k])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of attribute names for the mapping.", "response": "def keys(self):\n        \"\"\"Return a list of attribute names for the mapping.\n\n        :rtype: list\n\n        \"\"\"\n        return sorted([k for k in dir(self) if\n                       k[0:1] != '_' and k != 'keys' and not k.isupper() and\n                       not inspect.ismethod(getattr(self, k)) and\n                       not (hasattr(self.__class__, k) and\n                            isinstance(getattr(self.__class__, k),\n                                       property)) and\n                       not isinstance(getattr(self, k), property)])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a LinearSegmentedColormap from a sequence of floats and RGB - tuples.", "response": "def make_colormap(seq):\n    \"\"\"Return a LinearSegmentedColormap\n    seq: a sequence of floats and RGB-tuples. The floats should be increasing\n    and in the interval (0,1).\n    \"\"\"\n    seq = [(None,) * 3, 0.0] + list(seq) + [1.0, (None,) * 3]\n    cdict = {'red': [], 'green': [], 'blue': []}\n    for i, item in enumerate(seq):\n        if isinstance(item, float):\n            r1, g1, b1 = seq[i - 1]\n            r2, g2, b2 = seq[i + 1]\n            cdict['red'].append([item, r1, r2])\n            cdict['green'].append([item, g1, g2])\n            cdict['blue'].append([item, b1, b2])\n    return mcolors.LinearSegmentedColormap('CustomMap', cdict)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving random junk from image names.", "response": "def namer(cls, imageUrl, pageUrl):\n        \"\"\"Remove random junk from image names.\"\"\"\n        imgname = imageUrl.split('/')[-1]\n        imgbase = imgname.rsplit('-', 1)[0]\n        imgext = imgname.rsplit('.', 1)[1]\n        return '%s.%s' % (imgbase, imgext)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef flat_(self, col, nums=True):\n        try:\n            res = \"\"\n            i = 0\n            vals = self.df[col].tolist()\n            for el in vals:\n                if nums is True:\n                    res = res + str(i) + \" \" + el\n                else:\n                    res = res + el\n                if i < (len(vals)-1):\n                    res += \" \"\n                i += 1\n            return res\n        except Exception as e:\n            self.err(e, \"Can not flat \" + col)", "response": "Returns a flat representation of a column s values"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a Dataswim instance with the most frequent words in a specific column exluding the most common stop words in the specified language", "response": "def mfw_(self, col, sw_lang=\"english\", limit=100):\n        \"\"\"\n        Returns a Dataswim instance with the most frequent words in a\n        column exluding the most common stop words\n        \"\"\"\n        df = self._mfw(col, sw_lang, limit)\n        if df is None:\n            self.err(\"Can not find most frequent words\")\n            return\n        return self._duplicate_(df)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main():\n    fn = os.path.join(basepath, 'dosagelib', 'languages.py')\n    encoding = 'utf-8'\n    with codecs.open(fn, 'w', encoding) as f:\n        f.write('# -*- coding: %s -*-%s' % (encoding, os.linesep))\n        f.write('# ISO 693-1 language codes from pycountry%s' % os.linesep)\n        f.write('# This file is automatically generated, DO NOT EDIT!%s' % os.linesep)\n        lang = get_used_languages()\n        write_languages(f, lang)", "response": "Update language information in dosagelib. languages. py"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate descriptors associated with array name and then sets the array as a member variable", "response": "def generic_stitch(cube, arrays):\n    \"\"\"\n    Creates descriptors associated with array name and\n    then sets the array as a member variable\n    \"\"\"\n    \n    for name, ary in arrays.iteritems():\n        if name not in type(cube).__dict__:\n            setattr(type(cube), name, ArrayDescriptor(name))\n\n        setattr(cube, name, ary)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfunction that creates arrays given the array definitions in the reified_arrays dictionary and array_factory keyword argument.", "response": "def create_local_arrays(reified_arrays, array_factory=None):\n    \"\"\"\n    Function that creates arrays, given the definitions in\n    the reified_arrays dictionary and the array_factory\n    keyword argument.\n\n    Arguments\n    ---------\n        reified_arrays : dictionary\n            Dictionary keyed on array name and array definitions.\n            Can be obtained via cube.arrays(reify=True)\n\n    Keyword Arguments\n    -----------------\n        array_factory : function\n            A function used to create array objects. It's signature should\n            be array_factory(shape, dtype) and should return a constructed\n            array of the supplied shape and data type. If None,\n            numpy.empty will be used.\n\n    Returns\n    -------\n    A dictionary of array objects, keyed on array names\n    \"\"\"\n\n\n    # By default, create numpy arrays\n    if array_factory is None:\n        array_factory = np.empty\n\n    # Construct the array dictionary by calling the\n    # array_factory for each array\n    return { n: array_factory(ra.shape, ra.dtype)\n        for n, ra in reified_arrays.iteritems() }"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_local_arrays_on_cube(cube, reified_arrays=None, array_stitch=None, array_factory=None):\n\n    # Create a default array stitching method\n    if array_stitch is None:\n        array_stitch = generic_stitch\n\n    # Get reified arrays from the cube if necessary\n    if reified_arrays is None:\n        reified_arrays = cube.arrays(reify=True)\n\n    arrays = create_local_arrays(reified_arrays, array_factory=array_factory)\n    array_stitch(cube, arrays)\n\n    return arrays", "response": "Function that creates arrays on the supplied hypercube and returns a dictionary of arrays keyed on array names and arrays type."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tanimoto_coefficient(a, b):\n    return sum(map(lambda (x,y): float(x)*float(y), zip(a,b))) / sum([\n          -sum(map(lambda (x,y): float(x)*float(y), zip(a,b))),\n           sum(map(lambda x: float(x)**2, a)),\n           sum(map(lambda x: float(x)**2, b))])", "response": "Measured similarity between two points in a multi - dimensional space."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef weighted_tanimoto(a, b, weights):\n    weighted = lambda s: map(lambda (x,y): float(x)*float(y), zip(s, weights))\n    return tanimoto_coefficient(weighted(a), weighted(b))", "response": "Same as the Tanimoto coefficient but wit weights for each dimension."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\naverages a sequence based on a key.", "response": "def average(sequence, key):\n    \"\"\"Averages a sequence based on a key.\"\"\"\n    return sum(map(key, sequence)) / float(len(sequence))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stochastic_choice(machines):\n    if len(machines) < 4:\n        return random.choice(machines)\n\n    r = random.random()\n    if r < 0.5:\n        return random.choice(machines[:len(machines)/4])\n    elif r < 0.75:\n        return random.choice(machines[:len(machines)/2])\n    else:\n        return random.choice(machines)", "response": "Stochastically choose one random machine distributed along their\n    scores."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreplace existing code with completely random instructions.", "response": "def randomize(vm,\n        length=(10,10),\n        ints=(0,999),\n        strs=(1,10),\n        chars=(32,126),\n        instruction_ratio=0.5,\n        number_string_ratio=0.8,\n        exclude=map(crianza.instructions.lookup, [\".\", \"exit\", \"read\", \"write\", \"str\"]),\n        restrict_to=None):\n\n    \"\"\"Replaces existing code with completely random instructions. Does not\n    optimize code after generating it.\n\n    Args:\n        length: Tuple of minimum and maximum code lengths. Code length will\n        be a random number between these two, inclusive values.\n\n        ints: Integers in the code will be selected at random from this\n        inclusive range.\n\n        strs: Inclusive range of the length of strings in the code.\n\n        chars: Inclusive range of characters in random strings.\n\n        instruction_ratio: Ratio of instructions to numbers/strings,\n        meaning that if this value is 0.5 then there will just as many\n        instructions in the code as there are numbers and strings.\n\n        number_string_ratio: Ratio of numbers to strings.\n\n        exclude: Excluded instructions. For genetic programming, one wants\n        to avoid the program to hang for user input.  The default value is\n        to exclude console i/o and debug instructions.\n\n        restrict_to: Limit instructions to the given list.\n\n    Returns:\n        The VM.\n    \"\"\"\n    vm.code = []\n    instructions = set(vm.instructions.values()) - set(exclude)\n\n    if restrict_to is not None:\n        instructions = instructions.intersection(set(restrict_to))\n\n    instructions = list(instructions)\n\n    for _ in xrange(random.randint(*length)):\n        r = random.random()\n        if r <= instruction_ratio:\n            # Generate a random instruction\n            vm.code.append(random.choice(instructions))\n        elif r <= number_string_ratio:\n            # Generate a random number\n            vm.code.append(crianza.compiler.make_embedded_push(random.randint(*ints)))\n        else:\n            # Generate a random string\n            vm.code.append(crianza.compiler.make_embedded_push('%s' %\n                \"\".join(chr(random.randint(*chars)) for n in xrange(0,\n                    random.randint(*strs)))))\n    return vm"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef crossover(m, f):\n    i = random.randint(0, len(m.code))\n    j = random.randint(0, len(f.code))\n    return m.code[:i] + f.code[j:]", "response": "Produces an offspring from two Machines whose code is a\n    combination of the two."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef iterate(MachineClass, stop_function=lambda iterations: iterations < 10000,\n        machines=1000, survival_rate=0.05, mutation_rate=0.075, silent=False):\n    \"\"\"Creates a bunch of machines, runs them for a number of steps and then\n    gives them a fitness score.  The best produce offspring that are passed on\n    to the next generation.\n\n    Args:\n        setup: Function taking a Machine argument, makes the machine ready\n        machine_class: A class that should inherit from Machine and contain the\n        following methods:\n            setUp(self) [optional]: Run before each new run, should at least\n            call self.reset() for each run.\n\n            tearDown(self) [optional]: Run after each run.\n\n            crossover(self, other): Returns a Machine offspring between itself and\n            another Machine.\n\n            score(self):  Score the machine. Lower is better. Can return a\n            tuple of values used to sort the machines from best to worst in\n            fitness.\n\n        stop_function: An optional function that takes the current generation\n        number and returns True if the processing should stop.\n\n        machines: The number of machines to create for each generation.\n\n        steps: The number of instructions each machine is allowed to execute in\n        each run.\n\n        code_length: Tuple of (minimum code length, maximum code length) for a\n        Machine.\n\n        survival_ratio: Ratio of the best Machines which are allowed to produce\n        offspring for the next generation.\n\n        mutation_rate: Rate for each machine's chance of being mutated.\n    \"\"\"\n    def make_random(n):\n        return MachineClass().randomize()\n\n    def run_once(m):\n        m.setUp()\n        m.run()\n        m.tearDown()\n        return m\n\n    def make_offspring(survivors):\n        a = stochastic_choice(survivors)\n        b = stochastic_choice(survivors)\n        return a.crossover(b)\n\n    generation = map(make_random, xrange(machines))\n    survivors = generation\n\n    if silent:\n        log = lambda s,stream=None: None\n    else:\n        log = _log\n\n    try:\n        iterations = 0\n        while not stop_function(iterations, survivors):\n            iterations += 1\n            log(\"running ... \")\n\n            # Run all machines in this generation\n            generation = map(run_once, generation)\n\n            # Sort machines from best to worst\n            generation = sorted(generation, key=lambda m: m.score())\n\n            # Select the best\n            survivors = generation[:int(survival_rate * len(generation))]\n\n            # Remove code larger than 50\n            for s in survivors:\n                if len(s.code) >= 50:\n                    s.code = s.code[:50]\n\n            # Remove dead ones\n            survivors = [s for s in survivors if len(s.code)>0]\n\n            #survivors = [s for s in survivors if len(s.code)<=50]\n            # All dead? start with a new set\n            if len(survivors) == 0:\n                log(\"\\nNo survivors, restarting\")\n                survivors = map(make_random, xrange(machines))\n                generation = survivors\n                continue\n\n            # Create a new generation based on the survivors.\n            log(\"crossover ... \")\n            cross = lambda _: make_offspring(survivors)\n            generation = map(cross, xrange(machines))\n\n            # Add mutations from time to time\n            for m in generation:\n                if random.random() > mutation_rate:\n                    m.mutate()\n\n            log(\"\\rgen %d 1-fitness %.12f avg code len %.2f avg stack len %.2f\\n\" %\n                (iterations,\n                 average(survivors, lambda m: m.score()),\n                 average(survivors, lambda m: len(m.code)),\n                 average(survivors, lambda m: len(m.stack) + len(m.return_stack))))\n    except KeyboardInterrupt:\n        pass\n\n    return survivors", "response": "This function generates a bunch of machines and then runs them for a number of steps and then gives them a fitness score."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexecutes up to steps instructions.", "response": "def run(self, steps=10):\n        \"\"\"Executes up to `steps` instructions.\"\"\"\n        try:\n            super(GeneticMachine, self).run(steps)\n            self._error = False\n        except StopIteration:\n            self._error = False\n        except Exception:\n            self._error = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the field from the model that is in the order of the field.", "response": "def get_field(cls, model, opts, label, field):\n    \"\"\"\n    Just like django.contrib.admin.validation.get_field, but knows\n    about translation models.\n    \"\"\"\n\n    trans_model = model._meta.translation_model\n    try:\n        (f, lang_id) = trans_model._meta.translated_fields[field]\n        return f\n    except KeyError:\n        # fall back to the old way -- see if model contains the field\n        # directly\n        pass\n\n    try:\n        return opts.get_field(field)\n    except models.FieldDoesNotExist:\n        raise ImproperlyConfigured(\"'%s.%s' refers to field '%s' that is \" \\\n            \"missing from model '%s'.\" \\\n            % (cls.__name__, label, field, model.__name__))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvalidate a class specified as a model admin.", "response": "def validate_admin_registration(cls, model):\n    \"\"\"\n    Validates a class specified as a model admin.\n\n    Right now this means validating prepopulated_fields, as for\n    multilingual models DM handles them by itself.\n    \"\"\"\n\n    if not is_multilingual_model(model):\n        return\n\n    from django.contrib.admin.validation import check_isdict, check_isseq\n\n    opts = model._meta\n\n    # this is heavily based on django.contrib.admin.validation.\n    if hasattr(cls, '_dm_prepopulated_fields'):\n        check_isdict(cls, '_dm_prepopulated_fields', cls.prepopulated_fields)\n        for field, val in cls._dm_prepopulated_fields.items():\n            f = get_field(cls, model, opts, 'prepopulated_fields', field)\n            if isinstance(f, (models.DateTimeField, models.ForeignKey,\n                models.ManyToManyField)):\n                raise ImproperlyConfigured(\"'%s.prepopulated_fields['%s']' \"\n                        \"is either a DateTimeField, ForeignKey or \"\n                        \"ManyToManyField. This isn't allowed.\"\n                        % (cls.__name__, field))\n            check_isseq(cls, \"prepopulated_fields['%s']\" % field, val)\n            for idx, f in enumerate(val):\n                get_field(cls, model,\n                        opts, \"prepopulated_fields['%s'][%d]\"\n                        % (f, idx), f)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse all search result pages.", "response": "def get_results():\n    \"\"\"Parse all search result pages.\"\"\"\n    # store info in a dictionary {name -> shortname}\n    res = {}\n    session = requests.Session()\n    handle_url('http://www.gocomics.com/features', session, res)\n    handle_url('http://www.gocomics.com/explore/espanol', session, res)\n    handle_url('http://www.gocomics.com/explore/editorial_list', session, res)\n    handle_url('http://www.gocomics.com/explore/sherpa_list', session, res)\n    save_result(res, json_file)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef print_results(args):\n    min_comics, filename = args\n    with codecs.open(filename, 'a', 'utf-8') as fp:\n        for name, shortname in sorted(load_result(json_file).items()):\n            if name in exclude_comics:\n                print(\"Excluded \" + name)\n                continue\n            fp.write(u\"add(%r, %r)\\n\" % (\n              str(truncate_name(name)), str(shortname))\n            )", "response": "Print all comics that have at least the given number of minimum comic strips."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef build_lattice(self, x):\n        I, J, _ = x.shape\n        start_states, transitions = self._start_states, self._transitions\n\n        lattice = []\n        transitions_d = defaultdict(list)\n        for transition_index, (s0, s1, delta) in enumerate(transitions):\n            transitions_d[s0].append((s1, delta, transition_index))\n        # Add start states\n        unvisited_nodes = deque([(0, 0, s) for s in start_states])\n        visited_nodes = set()\n        n_states = self.n_states\n\n        while unvisited_nodes:\n            node = unvisited_nodes.popleft()\n            lattice.append(node)\n            i, j, s0 = node\n            for s1, delta, transition_index in transitions_d[s0]:\n                try:\n                    di, dj = delta\n                except TypeError:\n                    di, dj = delta(i, j, x)\n\n                if i + di < I and j + dj < J:\n                    edge = (i, j, s0, i + di, j + dj, s1, transition_index + n_states)\n                    lattice.append(edge)\n                    dest_node = (i + di, j + dj, s1)\n                    if dest_node not in visited_nodes:\n                        unvisited_nodes.append(dest_node)\n                        visited_nodes.add(dest_node)\n\n        lattice.sort()\n\n        # Step backwards through lattice and add visitable nodes to the set of nodes to keep. The rest are discarded.\n        final_lattice = []\n        visited_nodes = set((I-1, J-1, s) for s in range(n_states))\n\n        for node in lattice[::-1]:\n            if node in visited_nodes:\n                final_lattice.append(node)\n            elif len(node) > 3:\n                source_node, dest_node = node[0:3], node[3:6]\n                if dest_node in visited_nodes:\n                    visited_nodes.add(source_node)\n                    final_lattice.append(node)\n\n        reversed_list = list(reversed(final_lattice))\n\n        # Squash list\n        lattice = [edge for edge in reversed_list if len(edge) > 3]\n        return np.array(lattice, dtype='int64')", "response": "Builds the lattice for the given input features."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _independent_lattice(self, shape, lattice=None):\n        I, J = shape\n\n        if lattice is not None:\n            end_I = min(I, max(lattice[..., 3])) - 1\n            end_J = min(J, max(lattice[..., 4])) - 1\n            unvisited_nodes = deque([(i, j, s)\n                                     for i in range(end_I)\n                                     for j in range(end_J)\n                                     for s in self._start_states])\n            lattice = lattice.tolist()\n        else:\n            lattice = []\n            unvisited_nodes = deque([(0, 0, s) for s in self._start_states])\n        lattice += _grow_independent_lattice(self._transitions, \n                                             self.n_states, (I, J), \n                                             unvisited_nodes)\n        lattice = np.array(sorted(lattice), dtype='int64')\n        return lattice", "response": "Helper function to construct the list of nodes and edges for the given shape."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconstruct the list of nodes and edges for input features.", "response": "def build_lattice(self, x):\n        \"\"\" Construct the list of nodes and edges for input features. \"\"\"\n        I, J, _ = x.shape\n        lattice = self._subset_independent_lattice((I, J))\n        return lattice"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getDownloader(self, url):\n        filename = self.namer(url, self.stripUrl)\n        if filename is None:\n            filename = url.rsplit('/', 1)[1]\n        dirname = getDirname(self.name)\n        return ComicImage(self.name, url, self.stripUrl, dirname, filename, self.session, text=self.text)", "response": "Get an image downloader."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconnects to host and get meta information.", "response": "def connect(self):\n        \"\"\"Connect to host and get meta information.\"\"\"\n        self.urlobj = getImageObject(self.url, self.referrer, self.session)\n        content_type = unquote(self.urlobj.headers.get('content-type', 'application/octet-stream'))\n        content_type = content_type.split(';', 1)[0]\n        if '/' in content_type:\n            maintype, subtype = content_type.split('/', 1)\n        else:\n            maintype = content_type\n            subtype = None\n        if maintype != 'image' and content_type not in ('application/octet-stream', 'application/x-shockwave-flash'):\n            raise IOError('content type %r is not an image at %s' % (content_type, self.url))\n        # Always use mime type for file extension if it is sane.\n        if maintype == 'image':\n            self.ext = '.' + subtype.replace('jpeg', 'jpg')\n        self.contentLength = int(self.urlobj.headers.get('content-length', 0))\n        out.debug(u'... filename = %r, ext = %r, contentLength = %d' % (self.filename, self.ext, self.contentLength))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save(self, basepath):\n        out.info(u\"Get image URL %s\" % self.url, level=1)\n        self.connect()\n        filename = \"%s%s\" % (self.filename, self.ext)\n        comicDir = os.path.join(basepath, self.dirname)\n        if not os.path.isdir(comicDir):\n            os.makedirs(comicDir)\n        fn = os.path.join(comicDir, filename)\n        # compare with >= since content length could be the compressed size\n        if os.path.isfile(fn) and os.path.getsize(fn) >= self.contentLength:\n            out.info(u'Skipping existing file \"%s\".' % fn)\n            return fn, False\n        content = self.urlobj.content\n        if not content:\n            out.warn(u\"Empty content from %s, try again...\" % self.url)\n            self.connect()\n            content = self.urlobj.content\n        out.debug(u'Writing comic to file %s...' % fn)\n        writeFile(fn, content)\n        if self.text:\n            fntext = os.path.join(comicDir, \"%s.txt\" % self.filename)\n            out.debug(u'Writing comic text to file %s...' % fntext)\n            writeFile(fntext, self.text, encoding='utf-8')\n        getHandler().comicDownloaded(self, fn, text=self.text)\n        return fn, True", "response": "Save the comic URL to filename on disk."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a string containing the authorization header used to authenticate the user with GenePattern.", "response": "def authorization_header(self):\n        \"\"\"\n        Returns a string containing the authorization header used to authenticate\n        with GenePattern. This string is included in the header of subsequent\n        requests sent to GenePattern.\n        \"\"\"\n        return 'Basic %s' % base64.b64encode(bytes(self.username + ':' + self.password, 'ascii')).decode('ascii')"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupload a local file to a server and returns a GPFile object that wraps the URI of the uploaded file.", "response": "def upload_file(self, file_name, file_path):\n        \"\"\"\n        Upload a file to a server\n\n        Attempts to upload a local file with path filepath, to the server, where it\n        will be named filename.\n\n        Args:\n            :param file_name: The name that the uploaded file will be called on the server.\n            :param file_path: The path of the local file to upload.\n\n        Returns:\n            :return: A GPFile object that wraps the URI of the uploaded file, or None if the upload fails.\n        \"\"\"\n\n        request = urllib.request.Request(self.url + '/rest/v1/data/upload/job_input?name=' + file_name)\n        if self.authorization_header() is not None:\n            request.add_header('Authorization', self.authorization_header())\n        request.add_header('User-Agent', 'GenePatternRest')\n        with open(file_path, 'rb') as f:\n            data = f.read()\n\n        try:\n            response = urllib.request.urlopen(request, data)\n        except IOError:\n            print(\"authentication failed\")\n            return None\n\n        if response.getcode() != 201:\n            print(\"file upload failed, status code = %i\" % response.getcode())\n            return None\n\n        return GPFile(self, response.info().get('Location'))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrun a job defined by jobspec and returns the information associated with the running job.", "response": "def run_job(self, job_spec, wait_until_done=True):\n        \"\"\"\n        Runs a job defined by jobspec, optionally non-blocking.\n\n        Takes a GPJobSpec object that defines a request to run a job, and makes the\n        request to the server.  By default blocks until the job is finished by\n        polling the server, but can also run asynchronously.\n\n        Args:\n            :param job_spec: A GPJobSpec object that contains the data defining the job to be run.\n            :param wait_until_done: Whether to wait until the job is finished before returning.\n            :return:\n\n        Returns:\n            a GPJob object that refers to the running job on the server.  If called\n            synchronously, this object will contain the info associated with the\n            completed job.  Otherwise, it will just wrap the URI of the running job.\n        \"\"\"\n\n        # names should be a list of names,\n        # values should be a list of **lists** of values\n        json_string = json.dumps({'lsid': job_spec.lsid, 'params': job_spec.params, 'tags': ['GenePattern Python Client']}, cls=GPJSONEncoder)\n        if sys.version_info.major == 3:  # Handle conversion to bytes for Python 3\n            json_string = bytes(json_string, 'utf-8')\n        request = urllib.request.Request(self.url + '/rest/v1/jobs')\n        if self.authorization_header() is not None:\n            request.add_header('Authorization', self.authorization_header())\n        request.add_header('Content-Type', 'application/json')\n        request.add_header('User-Agent', 'GenePatternRest')\n        response = urllib.request.urlopen(request, json_string)\n        if response.getcode() != 201:\n            print(\" job POST failed, status code = %i\" % response.getcode())\n            return None\n        data = json.loads(response.read().decode('utf-8'))\n        job = GPJob(self, data['jobId'])\n        job.get_info()\n        self.last_job = job  # Set the last job\n        if wait_until_done:\n            job.wait_until_done()\n        return job"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nqueries the GenePattern server and returns a list of GPTask objects each representing one of the modules installed on the server. Useful for determining which modules are available on the server.", "response": "def get_task_list(self):\n        \"\"\"\n        Queries the GenePattern server and returns a list of GPTask objects,\n        each representing one of the modules installed on the server. Useful\n        for determining which are available on the server.\n        \"\"\"\n        request = urllib.request.Request(self.url + '/rest/v1/tasks/all.json')\n        if self.authorization_header() is not None:\n            request.add_header('Authorization', self.authorization_header())\n        request.add_header('User-Agent', 'GenePatternRest')\n        response = urllib.request.urlopen(request)\n        response_string = response.read().decode('utf-8')\n        category_and_tasks = json.loads(response_string)\n        raw_list = category_and_tasks['all_modules']\n        task_list = []\n        for task_dict in raw_list:\n            task = GPTask(self, task_dict['lsid'], task_dict)\n            task_list.append(task)\n        return task_list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the user s N most recently submitted jobs on the GenePattern server.", "response": "def get_recent_jobs(self, n_jobs=10):\n        \"\"\"\n        Returns the user's N most recently submitted jobs on the GenePattern server.\n\n        Args: If not specified, n_jobs = 10.\n\n        Returns: An array of GPJob objects.\n        \"\"\"\n\n        # Query the server for the list of jobs\n        request = urllib.request.Request(self.url + '/rest/v1/jobs/?pageSize=' +\n                                         str(n_jobs) + '&userId=' + str(urllib.parse.quote(self.username)) +\n                                         '&orderBy=-dateSubmitted')\n        if self.authorization_header() is not None:\n            request.add_header('Authorization', self.authorization_header())\n        request.add_header('User-Agent', 'GenePatternRest')\n        response = urllib.request.urlopen(request)\n        response_string = response.read().decode('utf-8')\n        response_json = json.loads(response_string)\n\n        # For each job in the JSON Array, build a GPJob object and add to the job list\n        job_list = []\n        for job_json in response_json['items']:\n            job_id = job_json['jobId']\n            job = GPJob(self, job_id)\n            job.info = job_json\n            job.load_info()\n            job_list.append(job)\n\n        return job_list"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef open(self):\n        request = urllib.request.Request(self.uri)\n        if self.server_data.authorization_header() is not None:\n            request.add_header('Authorization', self.server_data.authorization_header())\n        request.add_header('User-Agent', 'GenePatternRest')\n        return urllib.request.urlopen(request)", "response": "Opens the URL associated with the GPFile and returns a file - like object that contains the file - like object that represents the GPFile."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read(self):\n        with closing(self.open()) as f:\n            data = f.read()\n        return data.decode(\"utf-8\") or None", "response": "Reads the contents of the GPFile and returns the contents as a string"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nquery the GenePattern server for metadata regarding this job and assign them to the properties on this GPJob object.", "response": "def get_info(self):\n        \"\"\"\n        Query the GenePattern server for metadata regarding this job and assign\n        that metadata to the properties on this GPJob object. Including:\n            * Task Name\n            * LSID\n            * User ID\n            * Job Number\n            * Status\n            * Date Submitted\n            * URL of Log Files\n            * URL of Output Files\n            * Number of Output Files\n        \"\"\"\n        request = urllib.request.Request(self.server_data.url + \"/rest/v1/jobs/\" + self.uri)\n        if self.server_data.authorization_header() is not None:\n            request.add_header('Authorization', self.server_data.authorization_header())\n        request.add_header('User-Agent', 'GenePatternRest')\n        response = urllib.request.urlopen(request)\n\n        self.json = response.read().decode('utf-8')\n        self.info = json.loads(self.json)\n        self.load_info()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_info(self):\n        self.task_name = self.info['taskName']\n        self.task_lsid = self.info['taskLsid']\n        self.user_id = self.info['userId']\n        self.job_number = int(self.info['jobId'])\n        self.status = self.get_status_message()\n        self.date_submitted = self.info['dateSubmitted']\n        self.log_files = self.info['logFiles']\n        self.output_files = self.info['outputFiles']\n        self.num_output_files = self.info['numOutputFiles']\n\n        # Create children, if relevant\n        self.children = self.get_child_jobs()", "response": "Loads the information from the GPJob object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_child_jobs(self):\n        # Lazily load info\n        if self.info is None:\n            self.get_info()\n\n        # Lazily load children\n        if self.children is not None:\n            return self.children\n        else:\n            if 'children' in self.info:\n                child_list = []\n                for child in self.info['children']['items']:\n                    child_job = GPJob(self.server_data, child['jobId'])\n                    child_job.info = child\n                    child_job.load_info()\n                    child_list.append(child_job)\n                return child_list\n            else:               # No children? Return empty list\n                return []", "response": "Queries the GenePattern server for child jobs of this job and returns a list of GPJob objects representing each of them."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_finished(self):\n        self.get_info()\n\n        if 'status' not in self.info:\n            return False\n        if 'isFinished' not in self.info['status']:\n            return False\n\n        return self.info['status']['isFinished']", "response": "Returns True if the job has been completed False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef has_error(self):\n        self.get_info()\n\n        if 'status' not in self.info:\n            return False\n        if 'hasError' not in self.info['status']:\n            return False\n\n        return self.info['status']['hasError']", "response": "Returns True if the job has an error."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_pending(self):\n        self.get_info()\n\n        if 'status' not in self.info:\n            return False\n        if 'isPending' not in self.info['status']:\n            return False\n\n        return self.info['status']['isPending']", "response": "Returns True if the job is pending False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the tags for the job querying the server if necessary.", "response": "def get_tags(self):\n        \"\"\"\n        Returns the tags for the job, querying the\n        server if necessary.\n        \"\"\"\n        # Lazily load info\n        if self.info is None:\n            self.get_info()\n\n        if 'tags' in self.info:\n            return [structure['tag']['tag'] for structure in self.info['tags']]\n        else:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the comments for the job querying the server if necessary.", "response": "def get_comments(self):\n        \"\"\"\n        Returns the comments for the job, querying the\n        server if necessary.\n        \"\"\"\n        # Lazily load info\n        if self.info is None:\n            self.get_info()\n\n        if 'comments' in self.info:\n            return [structure['text'] for structure in self.info['comments']['comments']]\n        else:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_output_files(self):\n        # Lazily load info\n        if self.info is None:\n            self.get_info()\n\n        if 'outputFiles' in self.info:\n            return [GPFile(self.server_data, f['link']['href']) for f in self.info['outputFiles']]\n        else:\n            return []", "response": "Returns a list of the files output by the job querying the server if necessary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_file(self, name):\n        files = self.get_output_files()\n        for f in files:\n            if f.get_name() == name:\n                return f\n        return None", "response": "Returns the output file with the specified name or None if no output file with the specified name exists."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wait_until_done(self):\n        wait = 1\n        while True:\n            time.sleep(wait)\n            self.get_info()\n            if self.info['status']['isFinished']:\n                break\n            # implements a crude exponential back off\n            wait = min(wait * 2, 60)", "response": "This method will not return until the job is complete or has an error state."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_parameter(self, name, values, group_id=None):\n        if not isinstance(values, list):\n            values = [values]\n        if group_id is None:\n            self.params.append({'name': name, 'values': values})\n        else:\n            self.params.append({'name': name, 'groupId': group_id, 'values': values})", "response": "Sets the value of a parameter for the GPJobSpec\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef param_load(self):\n        escaped_uri = urllib.parse.quote(self.uri)\n        request = urllib.request.Request(self.server_data.url + '/rest/v1/tasks/' + escaped_uri)\n        if self.server_data.authorization_header() is not None:\n            request.add_header('Authorization', self.server_data.authorization_header())\n        request.add_header('User-Agent', 'GenePatternRest')\n        response = urllib.request.urlopen(request)\n        self.json = response.read().decode('utf-8')\n        self.dto = json.loads(self.json)\n\n        self.description = self.dto['description'] if 'description' in self.dto else \"\"\n        self.name = self.dto['name']\n        self.documentation = self.dto['documentation'] if 'documentation' in self.dto else \"\"\n        self.lsid = self.dto['lsid']\n        self.version = self.dto['version'] if 'version' in self.dto else \"\"\n        self.params = []\n        for param in self.dto['params']:\n            self.params.append(GPTaskParam(self, param))\n        self._params_loaded = True", "response": "Queries the server for the parameter information and other metadata associated with this task\n        self. uri"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_job_spec(self):\n        # If the parameters haven't been loaded yet, do so\n        if not self._params_loaded and self.server_data is not None:\n            self.param_load()\n\n        return GPJobSpec(self.server_data, self.lsid)", "response": "Returns a GPJobSpec object that can be used to launch a job of this task type."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_optional(self):\n        if (('optional' in self.attributes and bool(self.attributes['optional'].strip())) and\n                ('minValue' in self.attributes and self.attributes['minValue'] == 0)):\n            return True\n        else:\n            return False", "response": "Returns whether the parameter is optional or required."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn either File or String.", "response": "def get_type(self):\n        \"\"\"\n        Returns either 'File' or 'String'.\n\n        The type attribute (e.g., java.io.File, java.lang.Integer, java.lang.Float),\n        which might give a hint as to what string should represent,\n        is not enforced and not employed consistently across all tasks, so we ignore.\n        \"\"\"\n\n        if 'TYPE' in self.attributes and 'MODE' in self.attributes:\n            dto_type = self.attributes['TYPE']\n            dto_mode = self.attributes['MODE']\n            if dto_type == 'FILE' and dto_mode == 'IN':\n                return 'File'\n        return 'String'"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the default value for the parameter.", "response": "def get_default_value(self):\n        \"\"\"\n        Return the default value for the parameter. If here is no default value, return None\n        \"\"\"\n        if ('default_value' in self.attributes and\n                bool(self.attributes['default_value'].strip())):\n            return self.attributes['default_value']\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_choice_status(self):\n        if 'choiceInfo' not in self.dto[self.name]:\n            raise GPException('not a choice parameter')\n\n        status = self.dto[self.name]['choiceInfo']['status']\n        return status['message'], status['flag']", "response": "Returns a message field which indicates whether the choices statically\n        or dynamically defined and flag indicating whether a dynamic file\n        selection loading error occurred."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_choice_href(self):\n        if 'choiceInfo' not in self.dto[self.name]:\n            raise GPException('not a choice parameter')\n\n        return self.dto[self.name]['choiceInfo']['href']", "response": "Returns the HREF of a dynamic choice parameter."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the default selection from a choice menu", "response": "def get_choice_selected_value(self):\n        \"\"\"\n        Returns the default selection from a choice menu\n        Throws an error if this is not a choice parameter.\n        \"\"\"\n        if 'choiceInfo' not in self.dto[self.name]:\n            raise GPException('not a choice parameter')\n        choice_info_dto = self.dto[self.name]['choiceInfo']\n        if 'selectedValue' in choice_info_dto:\n            return self.dto[self.name]['choiceInfo']['selectedValue']\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning boolean indicating whether the user can provide custom value for the choice parameter.", "response": "def allow_choice_custom_value(self):\n        \"\"\"\n        Returns boolean indicating whether choice parameter supports custom value.\n\n        If choice parameter supports custom value, user can provide parameter value\n        other than those provided in choice list.\n        \"\"\"\n        if 'choiceInfo' not in self.dto[self.name]:\n            raise GPException('not a choice parameter')\n        return self._is_string_true(self.dto[self.name]['choiceInfo']['choiceAllowCustom'])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of dictionary objects one dictionary object per choice.", "response": "def get_choices(self):\n        \"\"\"\n        Returns a list of dictionary objects, one dictionary object per choice.\n\n        Each object has two keys defined: 'value', 'label'.\n        The 'label' entry is what should be displayed on the UI, the 'value' entry\n        is what is written into GPJobSpec.\n        \"\"\"\n\n        if 'choiceInfo' not in self.dto[self.name]:\n            raise GPException('not a choice parameter')\n        if self.get_choice_status()[1] == \"NOT_INITIALIZED\":\n            print(self.get_choice_status())\n            print(\"choice status not initialized\")\n\n            request = urllib.request.Request(self.get_choice_href())\n            if self.task.server_data.authorization_header() is not None:\n                request.add_header('Authorization', self.task.server_data.authorization_header())\n            request.add_header('User-Agent', 'GenePatternRest')\n            response = urllib.request.urlopen(request)\n            self.dto[self.name]['choiceInfo'] = json.loads(response.read().decode('utf-8'))\n        return self.dto[self.name]['choiceInfo']['choices']"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_alt_name(self):\n        if ('altName' in self.attributes and\n                bool(self.attributes['altName'].strip())):\n            return self.attributes['altName']\n        else:\n            return None", "response": "Returns the alternate name of a parameter. Only pipeline prompt - when - run parameters can have alternate names and alternate descriptions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the alternate description of a parameter.", "response": "def get_alt_description(self):\n        \"\"\"\n        Returns the alternate description of a parameter.\n        Only pipeline prompt-when-run parameters\n        can have alternate names and alternate descriptions\n        \"\"\"\n        if 'altDescription' in self.attributes and bool(self.attributes['altDescription'].strip()):\n            return self.attributes['altDescription']\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend a UDP command to the computer network.", "response": "def cli(wio, send):\n    '''\n    Sends a UDP command to the wio device.\n\n    \\b\n    DOES:\n        Support \"VERSION\", \"SCAN\", \"Blank?\", \"DEBUG\", \"ENDEBUG: 1\", \"ENDEBUG: 0\"\n        \"APCFG: AP\\\\tPWDs\\\\tTOKENs\\\\tSNs\\\\tSERVER_Domains\\\\tXSERVER_Domain\\\\t\\\\r\\\\n\",\n        Note:\n        1. Ensure your device is Configure Mode.\n        2. Change your computer network to Wio's AP.\n\n    \\b\n    EXAMPLE:\n        wio udp --send [command], send UPD command\n    '''\n    command = send\n    click.echo(\"UDP command: {}\".format(command))\n    result = udp.common_send(command)\n    if result is None:\n        return debug_error()\n    else:\n        click.echo(result)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef print_code(vm, out=sys.stdout, ops_per_line=8, registers=True):\n    if registers:\n        out.write(\"IP: %d\\n\" % vm.instruction_pointer)\n        out.write(\"DS: %s\\n\" % str(vm.stack))\n        out.write(\"RS: %s\\n\" % str(vm.return_stack))\n\n    def to_str(op):\n        if is_embedded_push(op):\n            op = get_embedded_push_value(op)\n\n        if isstring(op):\n            return '\"%s\"' % repr(op)[1:-1]\n        elif callable(op):\n            return vm.lookup(op)\n        else:\n            return str(op)\n\n    for addr, op in enumerate(vm.code):\n        if (addr % ops_per_line) == 0 and (addr==0 or (addr+1) < len(vm.code)):\n            if addr > 0:\n                out.write(\"\\n\")\n            out.write(\"%0*d  \" % (max(4, len(str(len(vm.code)))), addr))\n        out.write(\"%s \" % to_str(op))\n    out.write(\"\\n\")", "response": "Prints code and state for VM."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef repl(optimize=True, persist=True):\n    print(\"Extra commands for the REPL:\")\n    print(\".code    - print code\")\n    print(\".raw     - print raw code\")\n    print(\".quit    - exit immediately\")\n    print(\".reset   - reset machine (IP and stacks)\")\n    print(\".restart - create a clean, new machine\")\n    print(\".clear   - same as .restart\")\n    print(\".stack   - print data stack\")\n    print(\"\")\n\n    machine = Machine([])\n\n    def match(s, *args):\n        return any(map(lambda arg: s.strip()==arg, args))\n\n    while True:\n        try:\n            source = raw_input(\"> \").strip()\n\n            if source[0] == \".\" and len(source) > 1:\n                if match(source, \".quit\"):\n                    return\n                elif match(source, \".code\"):\n                    print_code(machine)\n                elif match(source, \".raw\"):\n                    print(machine.code)\n                elif match(source, \".reset\"):\n                    machine.reset()\n                elif match(source, \".restart\", \".clear\"):\n                    machine = Machine([])\n                elif match(source, \".stack\"):\n                    print(machine.stack)\n                else:\n                    raise ParseError(\"Unknown command: %s\" % source)\n                continue\n\n            code = compile(parse(source), silent=False, optimize=optimize)\n\n            if not persist:\n                machine.reset()\n\n            machine.code += code\n            machine.run()\n        except EOFError:\n            return\n        except KeyboardInterrupt:\n            return\n        except ParseError as e:\n            print(\"Parse error: %s\" % e)\n        except MachineError as e:\n            print(\"Machine error: %s\" % e)\n        except CompileError as e:\n            print(\"Compile error: %s\" % e)", "response": "Starts a simple REPL for this machine."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconnect to the database and set it as main database", "response": "def connect(self, url: str):\n        \"\"\"Connect to the database and set it as main database\n\n        :param url: path to the database, uses the Sqlalchemy format\n        :type url: str\n\n        :example: ``ds.connect(\"sqlite:///mydb.slqite\")``\n        \"\"\"\n        try:\n            self.db = dataset.connect(url, row_type=stuf)\n        except Exception as e:\n            self.err(e, \"Can not connect to database\")\n            return\n        if self.db is None:\n            self.err(\"Database \" + url + \" not found\")\n            return\n        self.ok(\"Db\", self.db.url, \"connected\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load(self, table: str):\n        if self._check_db() is False:\n            return\n        if table not in self.db.tables:\n            self.warning(\"The table \" + table + \" does not exists\")\n            return\n        try:\n            self.start(\"Loading data from table \" + table)\n            res = self.db[table].all()\n            self.df = pd.DataFrame(list(res))\n            self.end(\"Data loaded from table \" + table)\n        except Exception as e:\n            self.err(e, \"Can not load table \" + table)", "response": "Load the main dataframe from a table s data\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_django(self, query: \"django query\"):\n        try:\n            self.df = self._load_django(query)\n        except Exception as e:\n            self.err(e, \"Can not load data from query\")", "response": "Load the main dataframe from a django orm query"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a DataSwim instance with data from a django orm query", "response": "def load_django_(self, query: \"django query\") -> \"Ds\":\n        \"\"\"Returns a DataSwim instance from a django orm query\n\n        :param query: django query from a model\n        :type query: django query\n        :return: a dataswim instance with data from a django query\n        :rtype: Ds\n\n        :example: ``ds2 = ds.load_django_(Mymodel.objects.all())``\n        \"\"\"\n        try:\n            df = self._load_django(query)\n            return self.clone_(df)\n        except Exception as e:\n            self.err(e, \"Can not load data from query\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parseFeed(filename, yesterday):\n    dom = xml.dom.minidom.parse(filename)\n\n    getText = lambda node, tag: node.getElementsByTagName(tag)[0].childNodes[0].data\n    getNode = lambda tag: dom.getElementsByTagName(tag)\n\n    content = getNode('channel')[0] # Only one channel node\n\n    feedTitle = getText(content, 'title')\n    feedLink = getText(content, 'link')\n    feedDesc = getText(content, 'description')\n\n    feed = Feed(feedTitle, feedLink, feedDesc)\n\n    for item in getNode('item'):\n        itemDate = time.strptime(getText(item, 'pubDate'), '%a, %d %b %Y %H:%M:%S GMT')\n        if (itemDate > yesterday): # If newer than yesterday\n            feed.addItem(getText(item, 'title'),\n                         getText(item, 'link'),\n                         getText(item, 'description'),\n                         getText(item, 'pubDate'))\n    return feed", "response": "Parse an RSS feed and filter only entries that are newer than yesterday."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding an RSS item.", "response": "def addElement(self, parent, tag, value):\n        \"\"\"Add an RSS item.\"\"\"\n        elem = self.rss.createElement(tag)\n        node = self.rss.createTextNode(value)\n        return parent.appendChild(elem).appendChild(node)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write(self, path):\n        with open(path, 'wb') as f:\n            f.write(self.getXML())", "response": "Write RSS content to file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndisplaying info about the dataframe", "response": "def show(self, rows: int=5,\n             dataframe: pd.DataFrame=None) -> pd.DataFrame:\n        \"\"\"\n        Display info about the dataframe\n\n        :param rows: number of rows to show, defaults to 5\n        :param rows: int, optional\n        :param dataframe: a pandas dataframe, defaults to None\n        :param dataframe: pd.DataFrame, optional\n        :return: a pandas dataframe\n        :rtype: pd.DataFrame\n\n        :example: ``ds.show()``\n        \"\"\"\n        try:\n            if dataframe is not None:\n                df = dataframe\n            else:\n                df = self.df\n            if df is None:\n                self.warning(\"Dataframe is empty: nothing to show\")\n                return\n            num = len(df.columns.values)\n        except Exception as e:\n            self.err(e, self.show, \"Can not show dataframe\")\n            return\n        f = list(df)\n        fds = []\n        for fi in f:\n            fds.append(str(fi))\n        fields = \", \".join(fds)\n        num_rows = len(df.index)\n        self.info(\"The dataframe has\", colors.bold(num_rows), \"rows and\",\n                  colors.bold(num), \"columns:\")\n        print(fields)\n        return df.head(rows)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndisplaying one row of the dataframe and the field names wiht count", "response": "def one(self):\n        \"\"\"\n        Shows one row of the dataframe and the field \n        names wiht count\n\n        :return: a pandas dataframe\n        :rtype: pd.DataFrame\n\n        :example: ``ds.one()``\n        \"\"\"\n        try:\n            return self.show(1)\n        except Exception as e:\n            self.err(e, self.one, \"Can not display dataframe\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the main dataframe s tail", "response": "def tail(self, rows: int=5):\n        \"\"\"\n        Returns the main dataframe's tail\n\n        :param rows: number of rows to print, defaults to 5\n        :param rows: int, optional\n        :return: a pandas dataframe\n        :rtype: pd.DataFrame\n\n        :example: ``ds.tail()``\n        \"\"\"\n        if self.df is None:\n            self.warning(\"Dataframe is empty: no tail available\")\n        return self.df.tail(rows)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cols_(self) -> pd.DataFrame:\n        try:\n            s = self.df.iloc[0]\n            df = pd.DataFrame(s)\n            df = df.rename(columns={0: \"value\"})\n\n            def run(row):\n                t = row[0]\n                return type(t).__name__\n\n            s = df.apply(run, axis=1)\n            df = df.rename(columns={0: \"value\"})\n            df[\"types\"] = s\n            return df\n        except Exception as e:\n            self.err(e)", "response": "Returns a pandas dataframe with columns info\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef types_(self, col: str) -> pd.DataFrame:\n        cols = self.df.columns.values\n        all_types = {}\n        for col in cols:\n            local_types = []\n            for i, val in self.df[col].iteritems():\n                #print(i, val, type(val))\n                t = type(val).__name__\n                if t not in local_types:\n                    local_types.append(t)\n            all_types[col] = (local_types, i)\n        df = pd.DataFrame(all_types, index=[\"type\", \"num\"])\n        return df", "response": "Display types of values in a column\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef article(request, slug):\n    # Get current CMS Page as article tree\n    tree = request.current_page.get_public_object()\n\n    # Check whether it really is a tree.\n    # It could also be one of its sub-pages.\n    if tree.application_urls != 'CMSArticlesApp':\n        # In such case show regular CMS Page\n        return page(request, slug)\n\n    # Get an Article object from the request\n    draft = use_draft(request) and request.user.has_perm('cms_articles.change_article')\n    preview = 'preview' in request.GET and request.user.has_perm('cms_articles.change_article')\n\n    site = tree.node.site\n    article = get_article_from_slug(tree, slug, preview, draft)\n\n    if not article:\n        # raise 404\n        _handle_no_page(request)\n\n    request.current_article = article\n\n    if hasattr(request, 'user') and request.user.is_staff:\n        user_languages = get_language_list(site_id=site.pk)\n    else:\n        user_languages = get_public_languages(site_id=site.pk)\n\n    request_language = get_language_from_request(request, check_path=True)\n\n    # get_published_languages will return all languages in draft mode\n    # and published only in live mode.\n    # These languages are then filtered out by the user allowed languages\n    available_languages = [\n        language for language in user_languages\n        if language in list(article.get_published_languages())\n    ]\n\n    own_urls = [\n        request.build_absolute_uri(request.path),\n        '/%s' % request.path,\n        request.path,\n    ]\n\n    try:\n        redirect_on_fallback = get_redirect_on_fallback(request_language, site_id=site.pk)\n    except LanguageError:\n        redirect_on_fallback = False\n\n    if request_language not in user_languages:\n        # Language is not allowed\n        # Use the default site language\n        default_language = get_default_language_for_site(site.pk)\n        fallbacks = get_fallback_languages(default_language, site_id=site.pk)\n        fallbacks = [default_language] + fallbacks\n    else:\n        fallbacks = get_fallback_languages(request_language, site_id=site.pk)\n\n    # Only fallback to languages the user is allowed to see\n    fallback_languages = [\n        language for language in fallbacks\n        if language != request_language and language in available_languages\n    ]\n    language_is_unavailable = request_language not in available_languages\n\n    if language_is_unavailable and not fallback_languages:\n        # There is no page with the requested language\n        # and there's no configured fallbacks\n        return _handle_no_page(request)\n    elif language_is_unavailable and redirect_on_fallback:\n        # There is no page with the requested language and\n        # the user has explicitly requested to redirect on fallbacks,\n        # so redirect to the first configured / available fallback language\n        fallback = fallback_languages[0]\n        redirect_url = article.get_absolute_url(fallback, fallback=False)\n    else:\n        redirect_url = False\n\n    if redirect_url:\n        if request.user.is_staff and hasattr(request, 'toolbar') and request.toolbar.edit_mode_active:\n            request.toolbar.redirect_url = redirect_url\n        elif redirect_url not in own_urls:\n            # prevent redirect to self\n            return HttpResponseRedirect(redirect_url)\n\n    # permission checks\n    if article.login_required and not request.user.is_authenticated():\n        return redirect_to_login(urlquote(request.get_full_path()), settings.LOGIN_URL)\n\n    if hasattr(request, 'toolbar'):\n        request.toolbar.obj = article\n\n    structure_requested = get_cms_setting('CMS_TOOLBAR_URL__BUILD') in request.GET\n\n    if article.has_change_permission(request) and structure_requested:\n        return render_object_structure(request, article)\n    return render_article(request, article, current_language=request_language, slug=slug)", "response": "Returns the article for the given slug."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef namer(cls, imageUrl, pageUrl):\n        num = pageUrl.split('/')[-1]\n        ext = imageUrl.rsplit('.', 1)[1]\n        return \"thethinhline-%s.%s\" % (num, ext)", "response": "Use page URL sequence which is apparently increasing."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndownloading the data at the URL and load it as JSON", "response": "def download_as_json(url):\n    \"\"\"\n    Download the data at the URL and load it as JSON\n    \"\"\"\n    try:\n        return Response('application/json', request(url=url)).read()\n    except HTTPError as err:\n        raise ResponseException('application/json', err)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef request(*args, **kwargs):\n    timeout = kwargs.pop('timeout', 5)\n    req = PythonRequest(*args, **kwargs)\n    return REQUEST_OPENER.open(req, timeout=timeout)", "response": "Make a request with the received arguments and return an HTTPResponse object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntraversing the object with the given path.", "response": "def traverse(obj, *path, **kwargs):\n    \"\"\"\n    Traverse the object we receive with the given path. Path\n    items can be either strings or lists of strings (or any\n    nested combination thereof). Behavior in given cases is\n    laid out line by line below.\n    \"\"\"\n    if path:\n        if isinstance(obj, list) or isinstance(obj, tuple):\n            #If the current state of the object received is a\n            #list, return a list of each of its children elements,\n            #traversed with the current state of the string\n            return [traverse(x, *path) for x in obj]\n        elif isinstance(obj, dict):\n            #If the current state of the object received is a\n            #dictionary, do the following...\n            if isinstance(path[0], list) or isinstance(path[0], tuple):\n                #If the current top item in the path is a list,\n                #return a dictionary with keys to each of the\n                #items in the list, each traversed recursively.\n                for branch in path[0]:\n                    if not isinstance(branch, basestring):\n                        raise TraversalError(obj, path[0])\n                return {name: traverse(obj[name], *path[1:], split=True) for name in path[0]}\n            elif not isinstance(path[0], basestring):\n                #If the key isn't a string (or a list; handled\n                #previously), raise an exception.\n                raise TraversalError(obj, path[0])\n            elif path[0] == '\\\\*':\n                #If the key is a wildcard, return a dict containing\n                #each item, traversed down recursively.\n                return {name: traverse(item, *path[1:], split=True) for name, item in obj.items()}\n            elif path[0] in obj:\n                #The individual key is in the current object;\n                #traverse it and return the result.\n                return traverse(obj[path[0]], *path[1:])\n            else:\n                #The individual key doesn't exist in the\n                #current object; raise an error\n                raise TraversalError(obj, path[0])\n        else:\n            #If the current object isn't either a list or\n            #a dict, then do one of two things:\n            if kwargs.get('split', False):\n                #If the previously-recursed operation caused\n                #a split in a dict, just return the object; it's\n                #been specifically called out, but it isn't\n                #possible to recurse further.\n                return obj\n            else:\n                #The object can't be traversed, and we didn't\n                #specifically call it out to do something\n                #else with. Raise an exception.\n                raise TraversalError(obj, path[0])\n    else:\n        #If there's no path left, then just return the\n        #object that we received.\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send(self, **kwargs):\n        return_full_object = kwargs.get('return_full_object', False)\n        _verbose = kwargs.get('_verbose', False)\n        traversal = kwargs.get('traversal', None)\n        timeout = kwargs.get('_timeout', 5)\n        self.output['url'] = self.render_url()\n        with VerboseContextManager(verbose=_verbose):\n            try:\n                resp = Response(self.action.format(), request(timeout=timeout, **self.output), traversal)\n            except HTTPError as err:\n                raise ResponseException(self.action.format(), err)\n            except socket.timeout:\n                raise RequestTimeout(functools.partial(self.send, **kwargs))\n            except URLError as err:\n                if isinstance(err.reason, socket.timeout):\n                    raise RequestTimeout(functools.partial(self.send, **kwargs))\n                else:\n                    raise\n\n        if return_full_object:\n            return resp\n        else:\n            return resp.read()", "response": "Send the request defined by the data stored in the object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef render_url(self):\n        url = self.url.format(**self.replacements)\n        if self.params:\n            return url + '?' + urlencode(self.params)\n        return url", "response": "Render the final URL based on available variables and parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mimetype(self):\n        if ';' in self.headers.get('Content-Type', ''):\n            return self.headers['Content-Type'].split(';')[0]\n        return self.headers.get('Content-Type', self.static_format)", "response": "Get the mimetype from the response."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread the content of the resource from the response.", "response": "def read(self, raw=False, perform_traversal=True):\n        \"\"\"\n        Parse the body of the response using the Content-Type\n        header we pulled from the response, or the hive-defined\n        format, if such couldn't be pulled automatically.\n        \"\"\"\n        if not raw:\n            response_body = decode(self.data, self.mimetype(), encoding=self.encoding())\n            if perform_traversal and self.traversal is not None:\n                return traverse(response_body, *self.traversal)\n            return response_body\n        else:\n            return self.data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the SQLAlchemy Query object for this view.", "response": "def get_query(self):\n        \"\"\"\n        Get the list of items for this view.\n        You may want to override this if you need to provide different query  depending on the incoming request.\n        (Eg. return a list of items that is specific to the user)\n\n        :return: ``sqlalchemy.orm.query.Query``\n        \"\"\"\n\n        assert self.model is not None, (\n            \"'{}' should include a `model` attribute, or override the `get_query()` method.\"\n                .format(self.__class__.__name__)\n        )\n\n        return self.request.dbsession.query(self.model)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_object(self):\n\n        query = self.filter_query(self.get_query())\n\n        # If query joins more than one table and you need to base the lookup on something besides\n        # an id field on the self.model, you can provide an alternative lookup as tuple of the model class\n        # and a string of the column name.\n        if isinstance(self.lookup_field, str):\n            lookup_col = getattr(self.model, self.lookup_field)\n            lookup_val = self.lookup_url_kwargs[self.lookup_field]\n        else:\n            assert isinstance(self.lookup_field, tuple), (\n                \"'{}' `lookup_field` attribute should be a string or a tuple of (<model class>, `column`) \"\n                    .format(self.__class__.__name__)\n            )\n\n            lookup_col = getattr(self.lookup_field[0], self.lookup_field[1])\n            lookup_val = self.lookup_url_kwargs[self.lookup_field[1]]\n\n        try:\n            instance = query.filter(lookup_col == lookup_val).one()\n        except NoResultFound:\n            raise HTTPNotFound()\n\n        # May raise HTTPForbidden\n        self.check_object_permissions(self.request, instance)\n\n        return instance", "response": "Returns the object that the view is displaying."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the schema instance that should be used for validating and deserializing input and serializing output.", "response": "def get_schema(self, *args, **kwargs):\n        \"\"\"\n        Return the schema instance that should be used for validating and\n        deserializing input, and for serializing output.\n        \"\"\"\n\n        klass = self.get_schema_class()\n\n        # kwargs context value take precedence.\n        kwargs['context'] = dict(\n            self.get_schema_context(),\n            **kwargs.get('context', {})\n        )\n\n        return klass(*args, strict=True, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef filter_query(self, query):\n\n        for filter_class in list(self.filter_classes):\n            query = filter_class().filter_query(self.request, query, self)\n\n        return query", "response": "Filter the given query using the filter classes specified on the view if any are specified on the view."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef paginate_query(self, query):\n\n        if self.paginator is None:\n            return None\n\n        return self.paginator.paginate_query(query, self.request)", "response": "Paginate the query and return a single page of results."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef drop_nan(self, col: str=None, method: str=\"all\", **kwargs):\n        try:\n            if col is None:\n                self.df = self.df.dropna(how=method, **kwargs)\n            else:\n                self.df = self.df[self.df[col].notnull()]\n        except Exception as e:\n            self.err(e, \"Error dropping nan values\")", "response": "Drop rows with NaN values from the main dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef nan_empty(self, col: str):\n        try:\n            self.df[col] = self.df[col].replace('', nan)\n            self.ok(\"Filled empty values with nan in column \" + col)\n        except Exception as e:\n            self.err(e, \"Can not fill empty values with nan\")", "response": "Fill empty values with NaN values in the specified column"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert zero values to nan values in selected columns", "response": "def zero_nan(self, *cols):\n        \"\"\"\n        Converts zero values to nan values in selected columns\n\n        :param \\*cols: names of the colums\n        :type \\*cols: str, at least one\n\n        :example: ``ds.zero_nan(\"mycol1\", \"mycol2\")``\n        \"\"\"\n        if len(cols) == 0:\n            self.warning(\"Can not nan zero values if a column name \"\n                         \"is not provided\")\n        df = self._zero_nan(*cols)\n        if df is None:\n            self.err(\"Can not fill zero values with nan\")\n            return\n        self.df = df"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfills NaN values with new values in the main dataframe", "response": "def fill_nan(self, val: str, *cols):\n        \"\"\"\n        Fill NaN values with new values in the main dataframe\n\n        :param val: new value\n        :type val: str\n        :param \\*cols: names of the colums\n        :type \\*cols: str, at least one\n\n        :example: ``ds.fill_nan(\"new value\", \"mycol1\", \"mycol2\")``\n        \"\"\"\n        df = self._fill_nan(val, *cols)\n        if df is not None:\n            self.df = df\n        else:\n            self.err(\"Can not fill nan values\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fill_nulls(self, col: str):\n        n = [None, \"\"]\n        try:\n            self.df[col] = self.df[col].replace(n, nan)\n        except Exception as e:\n            self.err(e)", "response": "Fill all null values with NaN values in a column."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting some column values to integers", "response": "def to_int(self, *cols, **kwargs):\n        \"\"\"\n        Convert some column values to integers\n\n        :param \\*cols: names of the colums\n        :type \\*cols: str, at least one\n        :param \\*\\*kwargs: keyword arguments for ``pd.to_numeric``\n        :type \\*\\*kwargs: optional\n\n        :example: ``ds.to_int(\"mycol1\", \"mycol2\", errors=\"coerce\")``\n        \"\"\"\n        try:\n            for col in cols:\n                self.df[col] = pd.to_numeric(self.df[col], **kwargs)\n        except Exception as e:\n            self.err(e, \"Can not convert column values to integer\")\n            return\n        self.ok(\"Converted column values to integers\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_float(self, col: str, **kwargs):\n        try:\n            self.df[col] = self.df[col].astype(np.float64, **kwargs)\n            self.ok(\"Converted column values to float\")\n        except Exception as e:\n            self.err(e, \"Error converting to float\")", "response": "Convert the values of a column to float"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_type(self, dtype: type, *cols, **kwargs):\n        try:\n            allcols = self.df.columns.values\n            for col in cols:\n                if col not in allcols:\n                    self.err(\"Column \" + col + \" not found\")\n                    return\n                self.df[col] = self.df[col].astype(dtype, **kwargs)\n        except Exception as e:\n            self.err(e, \"Can not convert to type\")", "response": "Convert the columns values in the \n        main dataframe to a given type"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fdate(self, *cols, precision: str=\"S\", format: str=None):\n\n        def formatdate(row):\n            return row.strftime(format)\n\n        def convert(row):\n            encoded = '%Y-%m-%d %H:%M:%S'\n            if precision == \"Min\":\n                encoded = '%Y-%m-%d %H:%M'\n            elif precision == \"H\":\n                encoded = '%Y-%m-%d %H'\n            elif precision == \"D\":\n                encoded = '%Y-%m-%d'\n            elif precision == \"M\":\n                encoded = '%Y-%m'\n            elif precision == \"Y\":\n                encoded = '%Y'\n            return row.strftime(encoded)\n\n        try:\n            for f in cols:\n                try:\n                    if format is None:\n                        self.df[f] = pd.to_datetime(self.df[f]).apply(convert)\n                    else:\n                        self.df[f] = pd.to_datetime(\n                            self.df[f]).apply(formatdate)\n                except ValueError as e:\n                    self.err(e, \"Can not convert date\")\n                    return\n        except KeyError:\n            self.warning(\"Can not find colums \" + \" \".join(cols))\n            return\n        except Exception as e:\n            self.err(e, \"Can not process date col\")", "response": "Convert column values to formated date string"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef timestamps(self, col: str, **kwargs):\n        try:\n            name = \"Timestamps\"\n            if \"name\" in kwargs:\n                name = kwargs[\"name\"]\n            if \"errors\" not in kwargs:\n                kwargs[\"errors\"] = \"coerce\"\n            if \"unit\" in kwargs:\n                kwargs[\"unit\"] = \"ms\"\n            try:\n                self.df[col] = pd.to_datetime(self.df[col], **kwargs)\n            except TypeError:\n                pass\n            ts = []\n            for el in self.df[col]:\n                ts.append(arrow.get(el).timestamp)\n            self.df[name] = ts\n        except Exception as e:\n            self.err(e, \"Can not convert to timestamps\")", "response": "Adds a timestamps column from a date column"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef date(self, col: str, **kwargs):\n        try:\n            self.df[col] = pd.to_datetime(self.df[col], **kwargs)\n        except Exception as e:\n            self.err(e, \"Can not convert to date\")", "response": "Convert a column to date type"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dateindex(self, col: str):\n        df = self._dateindex(col)\n        if df is None:\n            self.err(\"Can not create date index\")\n            return\n        self.df = df\n        self.ok(\"Added a datetime index from column\", col)", "response": "Set a datetime index from a column"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef index(self, col: str):\n        df = self._index(col)\n        if df is None:\n            self.err(\"Can not create index\")\n            return\n        self.df = df", "response": "Set an index to the main dataframe"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef strip(self, col: str):\n        def remove_ws(row):\n            val = str(row[col])\n            if \" \" in val.startswith(\" \"):\n                row[col] = val.strip()\n            return row\n\n        try:\n            self.df.apply(remove_ws)\n        except Exception as e:\n            self.err(e, \"Can not remove white space in column\")\n            return\n        self.ok(\"White space removed in column values\")", "response": "Remove leading and trailing white spaces in a column s values"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving leading and trailing white spaces in columns names", "response": "def strip_cols(self):\n        \"\"\"\n        Remove leading and trailing white spaces in columns names\n\n        :example: ``ds.strip_cols()``\n        \"\"\"\n        cols = {}\n        skipped = []\n        for col in self.df.columns.values:\n            try:\n                cols[col] = col.strip()\n            except Exception:\n                skipped.append(str(col))\n        self.df = self.df.rename(columns=cols)\n        self.ok(\"White spaces removed in columns names\")\n        if len(skipped) > 0:\n            self.info(\"Skipped columns\", ','.join(\n                skipped), \"while removing white spaces\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef roundvals(self, col: str, precision: int=2):\n        try:\n            self.df[col] = self.df[col].astype(\"float64\")\n            self.df[col] = self.df[col].apply(lambda x: round(x, precision))\n        except Exception as e:\n            self.err(e, \"Can not round column values\")\n            return\n        self.ok(\"Rounded values in column \" + col)", "response": "Round floats in a column. Numbers are going to be\n        converted to floats"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreplacing a value in a column in the main dataframe", "response": "def replace(self, col: str, searchval: str, replaceval: str):\n        \"\"\"\n        Replace a value in a column in the main dataframe\n\n        :param col: column name\n        :type col: str\n        :param searchval: value to replace\n        :type searchval: str\n        :param replaceval: new value\n        :type replaceval: str\n\n        :example: ``ds.replace(\"mycol\", \"value\", \"new_value\")``\n        \"\"\"\n        try:\n            self.df[col] = self.df[col].replace(searchval, replaceval)\n        except Exception as e:\n            self.err(e, \"Can not replace value in column\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_filter(self, filter_expr, connector=AND, negate=False, trim=False,\n            can_reuse=None, process_extras=True, force_having=False):\n        \"\"\"\n        Copied from add_filter to generate WHERES for translation fields.\n        \"\"\"\n        if force_having:\n            import warnings\n            warnings.warn(\"multilingual-ng doesn't support force_having (see Django ticket #11293)\")\n        arg, value = filter_expr\n        parts = arg.split(LOOKUP_SEP)\n        if not parts:\n            raise FieldError(\"Cannot parse keyword query %r\" % arg)\n\n        # Work out the lookup type and remove it from 'parts', if necessary.\n        if len(parts) == 1 or parts[-1] not in self.query_terms:\n            lookup_type = 'exact'\n        else:\n            lookup_type = parts.pop()\n\n        # Interpret '__exact=None' as the sql 'is NULL'; otherwise, reject all\n        # uses of None as a query value.\n        if value is None:\n            if lookup_type != 'exact':\n                raise ValueError(\"Cannot use None as a query value\")\n            lookup_type = 'isnull'\n            value = True\n        elif (value == '' and lookup_type == 'exact' and\n              self.get_compiler(DEFAULT_DB_ALIAS).connection.features.interprets_empty_strings_as_nulls):\n            lookup_type = 'isnull'\n            value = True\n        elif callable(value):\n            value = value()\n\n        opts = self.get_meta()\n        alias = self.get_initial_alias()\n        allow_many = trim or not negate\n\n        try:\n            field, target, opts, join_list, last, extra_filters = self.setup_joins(\n                    parts, opts, alias, True, allow_many, can_reuse=can_reuse,\n                    negate=negate, process_extras=process_extras)\n        except MultiJoin, e:\n            self.split_exclude(filter_expr, LOOKUP_SEP.join(parts[:e.level]),\n                    can_reuse)\n            return\n\n        #=======================================================================\n        # Django Mulitlingual NG Specific Code START\n        #=======================================================================\n        if hasattr(opts, 'translation_model'):\n            field_name = parts[-1]\n            if field_name == 'pk':\n                field_name = opts.pk.name\n            translation_opts = opts.translation_model._meta\n            if field_name in translation_opts.translated_fields.keys():\n                field, model, direct, m2m = opts.get_field_by_name(field_name)\n                if model == opts.translation_model:\n                    language_code = translation_opts.translated_fields[field_name][1]\n                    if language_code is None:\n                        language_code = get_default_language()\n                    master_table_name = opts.db_table\n                    trans_table_alias = get_translation_table_alias(\n                        model._meta.db_table, language_code)\n                    new_table = (master_table_name + \"__\" + trans_table_alias)\n                    self.where.add(constraint_tuple(new_table, field.column, field, lookup_type, value), connector)\n                    return\n        #=======================================================================\n        # Django Mulitlingual NG Specific Code END\n        #=======================================================================\n        final = len(join_list)\n        penultimate = last.pop()\n        if penultimate == final:\n            penultimate = last.pop()\n        if trim and len(join_list) > 1:\n            extra = join_list[penultimate:]\n            join_list = join_list[:penultimate]\n            final = penultimate\n            penultimate = last.pop()\n            col = self.alias_map[extra[0]][LHS_JOIN_COL]\n            for alias in extra:\n                self.unref_alias(alias)\n        else:\n            col = target.column\n        alias = join_list[-1]\n\n        while final > 1:\n            # An optimization: if the final join is against the same column as\n            # we are comparing against, we can go back one step in the join\n            # chain and compare against the lhs of the join instead (and then\n            # repeat the optimization). The result, potentially, involves less\n            # table joins.\n            join = self.alias_map[alias]\n            if col != join[RHS_JOIN_COL]:\n                break\n            self.unref_alias(alias)\n            alias = join[LHS_ALIAS]\n            col = join[LHS_JOIN_COL]\n            join_list = join_list[:-1]\n            final -= 1\n            if final == penultimate:\n                penultimate = last.pop()\n\n        if (lookup_type == 'isnull' and value is True and not negate and\n                final > 1):\n            # If the comparison is against NULL, we need to use a left outer\n            # join when connecting to the previous model. We make that\n            # adjustment here. We don't do this unless needed as it's less\n            # efficient at the database level.\n            self.promote_alias(join_list[penultimate])\n\n        if connector == OR:\n            # Some joins may need to be promoted when adding a new filter to a\n            # disjunction. We walk the list of new joins and where it diverges\n            # from any previous joins (ref count is 1 in the table list), we\n            # make the new additions (and any existing ones not used in the new\n            # join list) an outer join.\n            join_it = iter(join_list)\n            table_it = iter(self.tables)\n            join_it.next(), table_it.next()\n            table_promote = False\n            join_promote = False\n            for join in join_it:\n                table = table_it.next()\n                if join == table and self.alias_refcount[join] > 1:\n                    continue\n                join_promote = self.promote_alias(join)\n                if table != join:\n                    table_promote = self.promote_alias(table)\n                break\n            self.promote_alias_chain(join_it, join_promote)\n            self.promote_alias_chain(table_it, table_promote)\n\n        self.where.add(constraint_tuple(alias, col, field, lookup_type, value), connector)\n\n        if negate:\n            self.promote_alias_chain(join_list)\n            if lookup_type != 'isnull':\n                if final > 1:\n                    for alias in join_list:\n                        if self.alias_map[alias][JOIN_TYPE] == self.LOUTER:\n                            j_col = self.alias_map[alias][RHS_JOIN_COL]\n                            entry = self.where_class()\n                            entry.add(constraint_tuple(alias, j_col, None, 'isnull', True), AND)\n                            entry.negate()\n                            self.where.add(entry, AND)\n                            break\n                elif not (lookup_type == 'in' and not value) and field.null:\n                    # Leaky abstraction artifact: We have to specifically\n                    # exclude the \"foo__in=[]\" case from this handling, because\n                    # it's short-circuited in the Where class.\n                    entry = self.where_class()\n                    entry.add(constraint_tuple(alias, col, None, 'isnull', True), AND)\n                    entry.negate()\n                    self.where.add(entry, AND)\n\n        if can_reuse is not None:\n            can_reuse.update(join_list)\n        if process_extras:\n            for filter in extra_filters:\n                self.add_filter(filter, negate=negate, can_reuse=can_reuse,\n                        process_extras=False)", "response": "Add a filter to the list of related fields."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _setup_joins_with_translation(self, names, opts, alias,\n                                      dupe_multis, allow_many=True,\n                                      allow_explicit_fk=False, can_reuse=None,\n                                      negate=False, process_extras=True):\n        \"\"\"\n        This is based on a full copy of Query.setup_joins because\n        currently I see no way to handle it differently.\n\n        TO DO: there might actually be a way, by splitting a single\n        multi-name setup_joins call into separate calls.  Check it.\n\n        -- marcin@elksoft.pl\n\n        Compute the necessary table joins for the passage through the fields\n        given in 'names'. 'opts' is the Options class for the current model\n        (which gives the table we are joining to), 'alias' is the alias for the\n        table we are joining to. If dupe_multis is True, any many-to-many or\n        many-to-one joins will always create a new alias (necessary for\n        disjunctive filters).\n\n        Returns the final field involved in the join, the target database\n        column (used for any 'where' constraint), the final 'opts' value and the\n        list of tables joined.\n        \"\"\"\n        joins = [alias]\n        last = [0]\n        dupe_set = set()\n        exclusions = set()\n        extra_filters = []\n        for pos, name in enumerate(names):\n            try:\n                exclusions.add(int_alias)\n            except NameError:\n                pass\n            exclusions.add(alias)\n            last.append(len(joins))\n            if name == 'pk':\n                name = opts.pk.name\n            try:\n                field, model, direct, m2m = opts.get_field_by_name(name)\n            except FieldDoesNotExist:\n                for f in opts.fields:\n                    if allow_explicit_fk and name == f.attname:\n                        # XXX: A hack to allow foo_id to work in values() for\n                        # backwards compatibility purposes. If we dropped that\n                        # feature, this could be removed.\n                        field, model, direct, m2m = opts.get_field_by_name(f.name)\n                        break\n                else:\n                    names = opts.get_all_field_names() + self.aggregate_select.keys()\n                    raise FieldError(\"Cannot resolve keyword %r into field. \"\n                            \"Choices are: %s\" % (name, \", \".join(names)))\n\n            if not allow_many and (m2m or not direct):\n                for alias in joins:\n                    self.unref_alias(alias)\n                raise MultiJoin(pos + 1)\n            #===================================================================\n            # Django Multilingual NG Specific Code START\n            #===================================================================\n            if hasattr(opts, 'translation_model'):\n                translation_opts = opts.translation_model._meta\n                if model == opts.translation_model:\n                    language_code = translation_opts.translated_fields[name][1]\n                    if language_code is None:\n                        language_code = get_default_language()\n                    #TODO: check alias\n                    master_table_name = opts.db_table\n                    trans_table_alias = get_translation_table_alias(\n                        model._meta.db_table, language_code)\n                    new_table = (master_table_name + \"__\" + trans_table_alias)\n                    qn = self.get_compiler(DEFAULT_DB_ALIAS).quote_name_unless_alias\n                    qn2 = self.get_compiler(DEFAULT_DB_ALIAS).connection.ops.quote_name\n                    trans_join = (\"JOIN %s AS %s ON ((%s.master_id = %s.%s) AND (%s.language_code = '%s'))\"\n                                 % (qn2(model._meta.db_table),\n                                 qn2(new_table),\n                                 qn2(new_table),\n                                 qn(master_table_name),\n                                 qn2(model._meta.pk.column),\n                                 qn2(new_table),\n                                 language_code))\n                    self.extra_join[new_table] = trans_join\n                    target = field\n                    continue\n            #===================================================================\n            # Django Multilingual NG Specific Code END\n            #===================================================================\n            elif model:\n                # The field lives on a base class of the current model.\n                # Skip the chain of proxy to the concrete proxied model\n                proxied_model = get_proxied_model(opts)\n\n                for int_model in opts.get_base_chain(model):\n                    if int_model is proxied_model:\n                        opts = int_model._meta\n                    else:\n                        lhs_col = opts.parents[int_model].column\n                        dedupe = lhs_col in opts.duplicate_targets\n                        if dedupe:\n                            exclusions.update(self.dupe_avoidance.get(\n                                    (id(opts), lhs_col), ()))\n                            dupe_set.add((opts, lhs_col))\n                        opts = int_model._meta\n                        alias = self.join((alias, opts.db_table, lhs_col,\n                                opts.pk.column), exclusions=exclusions)\n                        joins.append(alias)\n                        exclusions.add(alias)\n                        for (dupe_opts, dupe_col) in dupe_set:\n                            self.update_dupe_avoidance(dupe_opts, dupe_col,\n                                    alias)\n            cached_data = opts._join_cache.get(name)\n            orig_opts = opts\n            dupe_col = direct and field.column or field.field.column\n            dedupe = dupe_col in opts.duplicate_targets\n            if dupe_set or dedupe:\n                if dedupe:\n                    dupe_set.add((opts, dupe_col))\n                exclusions.update(self.dupe_avoidance.get((id(opts), dupe_col),\n                        ()))\n\n            if process_extras and hasattr(field, 'extra_filters'):\n                extra_filters.extend(field.extra_filters(names, pos, negate))\n            if direct:\n                if m2m:\n                    # Many-to-many field defined on the current model.\n                    if cached_data:\n                        (table1, from_col1, to_col1, table2, from_col2,\n                                to_col2, opts, target) = cached_data\n                    else:\n                        table1 = field.m2m_db_table()\n                        from_col1 = opts.pk.column\n                        to_col1 = field.m2m_column_name()\n                        opts = field.rel.to._meta\n                        table2 = opts.db_table\n                        from_col2 = field.m2m_reverse_name()\n                        to_col2 = opts.pk.column\n                        target = opts.pk\n                        orig_opts._join_cache[name] = (table1, from_col1,\n                                to_col1, table2, from_col2, to_col2, opts,\n                                target)\n\n                    int_alias = self.join((alias, table1, from_col1, to_col1),\n                            dupe_multis, exclusions, nullable=True,\n                            reuse=can_reuse)\n                    if int_alias == table2 and from_col2 == to_col2:\n                        joins.append(int_alias)\n                        alias = int_alias\n                    else:\n                        alias = self.join(\n                                (int_alias, table2, from_col2, to_col2),\n                                dupe_multis, exclusions, nullable=True,\n                                reuse=can_reuse)\n                        joins.extend([int_alias, alias])\n                elif field.rel:\n                    # One-to-one or many-to-one field\n                    if cached_data:\n                        (table, from_col, to_col, opts, target) = cached_data\n                    else:\n                        opts = field.rel.to._meta\n                        target = field.rel.get_related_field()\n                        table = opts.db_table\n                        from_col = field.column\n                        to_col = target.column\n                        orig_opts._join_cache[name] = (table, from_col, to_col,\n                                opts, target)\n\n                    alias = self.join((alias, table, from_col, to_col),\n                            exclusions=exclusions, nullable=field.null)\n                    joins.append(alias)\n                else:\n                    # Non-relation fields.\n                    target = field\n                    break\n            else:\n                orig_field = field\n                field = field.field\n                if m2m:\n                    # Many-to-many field defined on the target model.\n                    if cached_data:\n                        (table1, from_col1, to_col1, table2, from_col2,\n                                to_col2, opts, target) = cached_data\n                    else:\n                        table1 = field.m2m_db_table()\n                        from_col1 = opts.pk.column\n                        to_col1 = field.m2m_reverse_name()\n                        opts = orig_field.opts\n                        table2 = opts.db_table\n                        from_col2 = field.m2m_column_name()\n                        to_col2 = opts.pk.column\n                        target = opts.pk\n                        orig_opts._join_cache[name] = (table1, from_col1,\n                                to_col1, table2, from_col2, to_col2, opts,\n                                target)\n\n                    int_alias = self.join((alias, table1, from_col1, to_col1),\n                            dupe_multis, exclusions, nullable=True,\n                            reuse=can_reuse)\n                    alias = self.join((int_alias, table2, from_col2, to_col2),\n                            dupe_multis, exclusions, nullable=True,\n                            reuse=can_reuse)\n                    joins.extend([int_alias, alias])\n                else:\n                    # One-to-many field (ForeignKey defined on the target model)\n                    if cached_data:\n                        (table, from_col, to_col, opts, target) = cached_data\n                    else:\n                        local_field = opts.get_field_by_name(\n                                field.rel.field_name)[0]\n                        opts = orig_field.opts\n                        table = opts.db_table\n                        from_col = local_field.column\n                        to_col = field.column\n                        target = opts.pk\n                        orig_opts._join_cache[name] = (table, from_col, to_col,\n                                opts, target)\n\n                    alias = self.join((alias, table, from_col, to_col),\n                            dupe_multis, exclusions, nullable=True,\n                            reuse=can_reuse)\n                    joins.append(alias)\n\n            for (dupe_opts, dupe_col) in dupe_set:\n                try:\n                    self.update_dupe_avoidance(dupe_opts, dupe_col, int_alias)\n                except NameError:\n                    self.update_dupe_avoidance(dupe_opts, dupe_col, alias)\n\n        if pos != len(names) - 1:\n            if pos == len(names) - 2:\n                raise FieldError(\"Join on field %r not permitted. Did you misspell %r for the lookup type?\" % (name, names[pos + 1]))\n            else:\n                raise FieldError(\"Join on field %r not permitted.\" % name)\n\n        return field, target, opts, joins, last, extra_filters", "response": "This method is used to create a list of tables that are needed to join the tables with a translation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a new object with the specified language set.", "response": "def for_language(self, language_code):\n        \"\"\"\n        Set the default language for all objects returned with this\n        query.\n        \"\"\"\n        clone = self._clone()\n        clone._default_language = language_code\n        return clone"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\niterate over the objects in this MultilingualModelQuerySet.", "response": "def iterator(self):\n        \"\"\"\n        Add the default language information to all returned objects.\n        \"\"\"\n        default_language = getattr(self, '_default_language', None)\n        for obj in super(MultilingualModelQuerySet, self).iterator():\n            obj._default_language = default_language\n            yield obj"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\noverride _clone to preserve additional information needed by MultilingualModelQuerySet.", "response": "def _clone(self, klass=None, **kwargs):\n        \"\"\"\n        Override _clone to preserve additional information needed by\n        MultilingualModelQuerySet.\n        \"\"\"\n        clone = super(MultilingualModelQuerySet, self)._clone(klass, **kwargs)\n        clone._default_language = getattr(self, '_default_language', None)\n        return clone"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cli(wio, get_debug, debug):\n    '''\n    Change setting of device.\n\n    \\b\n    DOES:\n        The config command lets you change setting of device through upd.\n        1. Ensure your device is Configure Mode.\n        2. Change your computer network to Wio's AP.\n\n    \\b\n    EXAMPLE:\n        wio config --debug [on|off], enable/disable wio debug\n        wio config --get-debug, get wio debug status\n    '''\n    if debug:\n        if debug == \"on\":\n            cmd = \"ENDEBUG: 1\"\n        elif debug == \"off\":\n            cmd = \"ENDEBUG: 0\"\n        if not cmd:\n            return debug_error()\n        result = udp.send(cmd)\n        if not result:\n            return debug_error()\n        click.echo(\"Setting success!! Device will reboot!!\")\n    \n    elif get_debug:\n        try:\n            result = udp.udp_debug()\n        except Exception as e:\n            return get_debug_error()\n    \n        if result == \"1\":\n            click.echo(\"debug: on\")\n        elif result == '0':\n            click.echo(\"debug: off\")\n        else:\n            return get_debug_error()\n            \n    else:\n        click.echo(\"Note:\")\n        click.echo(\"    1. Ensure your device is Configure Mode.\")\n        click.echo(\"    2. Change your computer network to Wio's AP.\")\n        click.echo()\n        click.echo(\"Use:\")\n        click.echo(\"    wio config --debug [on|off], enable/disable wio debug\")\n        click.echo(\"    wio config --get-debug, get wio debug status\")", "response": "Command line interface for setting of a single element of a tree."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nselect the first row in the table", "response": "def first_(self):\n        \"\"\"\n        Select the first row\n        \"\"\"\n        try:\n            val = self.df.iloc[0]\n            return val\n        except Exception as e:\n            self.err(e, \"Can not select first row\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlimiting selection to a range in the main dataframe", "response": "def limit(self, r=5):\n        \"\"\"\n        Limit selection to a range in the main dataframe\n        \"\"\"\n        try:\n            self.df = self.df[:r]\n        except Exception as e:\n            self.err(e, \"Can not limit data\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a DataSwim instance with limited selection", "response": "def limit_(self, r=5):\n        \"\"\"\n        Returns a DataSwim instance with limited selection\n        \"\"\"\n        try:\n            return self._duplicate_(self.df[:r])\n        except Exception as e:\n            self.err(e, \"Can not limit data\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef unique_(self, col):\n        try:\n            df = self.df.drop_duplicates(subset=[col], inplace=False)\n            return list(df[col])\n        except Exception as e:\n            self.err(e, \"Can not select unique data\")", "response": "Returns unique values in a column"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nweighting unique values: returns a dataframe with a count of unique values", "response": "def wunique_(self, col):\n        \"\"\"\n        Weight unique values: returns a dataframe with a count\n        of unique values\n        \"\"\"\n        try:\n            s = pd.value_counts(self.df[col].values)\n            df = pd.DataFrame(s, columns=[\"Number\"])\n            return df\n        except Exception as e:\n            self.err(e, \"Can not weight unique data\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef nowrange(self, col, timeframe):\n        df = self._nowrange(col, timeframe)\n        if df is None:\n            self.err(\"Can not select range data from now\")\n            return\n        self.df = df", "response": "Set the main dataframe with rows within a date range from now\n            ex : ds. nowrange ( Date"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a Dataswim instance with rows within a date range from now", "response": "def nowrange_(self, col, timeframe):\n        \"\"\"\n        Returns a Dataswim instance with rows within a date range from now\n        ex: ds.nowrange(\"Date\", \"3D\") for a 3 days range. Units are: S,\n        H, D, W, M, Y\n        \"\"\"\n        df = self._nowrange(col, timeframe)\n        if df is None:\n            self.err(\"Can not select range data from now\")\n            return\n        return self._duplicate_(df)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef daterange(self, datecol, date_start, op, **args):\n        df = self._daterange(datecol, date_start, op, **args)\n        if df is None:\n            self.err(\"Can not select date range data\")\n        self.df = df", "response": "Returns rows in a date range"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a DataSwim instance with rows in a date range", "response": "def daterange_(self, datecol, date_start, op, **args):\n        \"\"\"\n        Returns a DataSwim instance with rows in a date range\n        \"\"\"\n        df = self._daterange(datecol, date_start, op, **args)\n        if df is None:\n            self.err(\"Can not select date range data\")\n        return self._duplicate_(df)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef subset(self, *args):\n        df = self._subset(*args)\n        if df is None:\n            self.err(\"Can get subset of data\")\n            return\n        self.df = df", "response": "Set the main dataframe to a subset based in positions\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a Dataswim instance with a subset of the main dataframe based on positions", "response": "def subset_(self, *args):\n        \"\"\"\n        Returns a Dataswim instance with a subset data based in positions\n        Select a subset of the main dataframe based on position:\n        ex: ds.subset(0,10) or ds.subset(10) is equivalent: it starts\n        at the first row if only one argument is provided\n        \"\"\"\n        df = self._subset(*args)\n        if df is None:\n            self.err(\"Can not get subset of data\")\n            return\n        return self._duplicate_(df)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse one search result page.", "response": "def handle_url(url, session, url_matcher, num_matcher, res):\n    \"\"\"Parse one search result page.\"\"\"\n    try:\n        data = getPageContent(url, session)\n    except IOError as msg:\n        print(\"ERROR:\", msg, file=sys.stderr)\n        return\n    for match in url_matcher.finditer(data):\n        comicurl = unquote(unescape(match.group(1)))\n        path = comicurl[:-1].rsplit('/')[-1]\n        name = capfirst(asciify(path))\n        if contains_case_insensitive(res, name):\n            # we cannot handle two comics that only differ in case\n            print(\"INFO: skipping possible duplicate\", repr(name), file=sys.stderr)\n            continue\n        if name in exclude_comics:\n            continue\n        # find out how many images this comic has\n        end = match.end(1)\n        mo = num_matcher.search(data[end:])\n        if not mo:\n            print(\"ERROR:\", repr(data[end:end+300]), file=sys.stderr)\n            continue\n        num = int(mo.group(1))\n        res[name] = (path, num)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses all search result pages.", "response": "def get_results():\n    \"\"\"Parse all search result pages.\"\"\"\n    base = \"http://www.theduckwebcomics.com/search/?page=%d&search=&type=0&type=1&last_update=\"\n    href = re.compile(tagre(\"a\", \"href\", r'(/[^\"]+/)', before=\"size24 yanone blue\"))\n    num = re.compile(r'(\\d+) pages?</span>')\n    # store info in a dictionary {name -> number of comics}\n    res = {}\n    # a search for an empty string returned 825 result pages\n    result_pages = 825\n    print(\"Parsing\", result_pages, \"search result pages...\", file=sys.stderr)\n    session = requests.Session()\n    for i in range(1, result_pages + 1):\n        print(i, file=sys.stderr, end=\" \")\n        handle_url(base % i, session, href, num, res)\n    save_result(res, json_file)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprints all comics that have at least the given number of minimum comic strips.", "response": "def print_results(args):\n    \"\"\"Print all comics that have at least the given number of minimum comic strips.\"\"\"\n    min_comics, filename = args\n    min_comics = int(min_comics)\n    with codecs.open(filename, 'a', 'utf-8') as fp:\n        for name, entry in sorted(load_result(json_file).items()):\n            if name in exclude_comics:\n                continue\n            path, num = entry\n            if num >= min_comics:\n                fp.write(u\"add(%r, %r)\\n\" % (\n                  str(truncate_name(name)), str(path)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbuild the preauth string and hmac it", "response": "def build_preauth_str(preauth_key, account_name, timestamp, expires,\n                      admin=False):\n    \"\"\" Builds the preauth string and hmac it, following the zimbra spec.\n\n    Spec and examples are here http://wiki.zimbra.com/wiki/Preauth\n    \"\"\"\n    if admin:\n        s = '{0}|1|name|{1}|{2}'.format(account_name, expires, timestamp)\n    else:\n        s = '{0}|name|{1}|{2}'.format(account_name, expires, timestamp)\n\n    return hmac.new(preauth_key.encode('utf-8'), s.encode('utf-8'),\n                    hashlib.sha1).hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntrying to convert a string to a Python base object.", "response": "def auto_type(s):\n    \"\"\" Get a XML response and tries to convert it to Python base object\n    \"\"\"\n    if isinstance(s, bool):\n        return s\n    elif s is None:\n        return ''\n    elif s == 'TRUE':\n        return True\n    elif s == 'FALSE':\n        return False\n    else:\n        try:\n            try:\n                # telephone numbers may be wrongly interpretted as ints\n                if s.startswith('+'):\n                    return s\n                else:\n                    return int(s)\n            except ValueError:\n                return float(s)\n\n        except ValueError:\n            return s"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntransform an XML string it to a dict with python - zimbra format", "response": "def xml_str_to_dict(s):\n    \"\"\" Transforms an XML string it to python-zimbra dict format\n\n    For format, see:\n      https://github.com/Zimbra-Community/python-zimbra/blob/master/README.md\n\n    :param: a string, containing XML\n    :returns: a dict, with python-zimbra format\n    \"\"\"\n    xml = minidom.parseString(s)\n    return pythonzimbra.tools.xmlserializer.dom_to_dict(xml.firstChild)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nshow search results for a single log record.", "response": "def show_search_results(\n        log_rec,\n        code_view=True,\n        json_view=False,\n        show_message_details=False):\n    \"\"\"show_search_results\n\n    Show search results like rsyslog or as pretty-printed\n    JSON dictionaries per log for debugging drill-down fields\n\n    :param log_rec: log record from splunk\n    :param code_view: show as a normal tail -f <log file> view\n    :param json_view: pretty print each log's dictionary\n    :param show_message_details\n    \"\"\"\n\n    log_dict = None\n    try:\n        log_dict = json.loads(\n            log_rec)\n    except Exception as e:\n        log.error((\n            'Failed logging record={} with ex={}').format(\n                log_rec,\n                e))\n        return\n    # end of try/ex\n\n    if not log_dict:\n        log.error((\n            'Failed to parse log_rec={} as a dictionary').format(\n                log_rec))\n        return\n\n    if code_view:\n        comp_name = log_dict.get(\n            'name',\n            '')\n        logger_name = log_dict.get(\n            'logger_name',\n            '')\n        use_log_name = (\n            '{}').format(\n            logger_name)\n        if logger_name:\n            use_log_name = '{}'.format(\n                logger_name)\n        else:\n            if comp_name:\n                use_log_name = '{}'.format(\n                    comp_name)\n\n        prefix_log = (\n            '{} {} - {} -').format(\n                log_dict.get(\n                    'systime',\n                    log_dict.get(\n                        'asctime',\n                        '')),\n                use_log_name,\n                log_dict.get(\n                    'levelname',\n                    ''))\n\n        suffix_log = ''\n        if log_dict.get(\n                'exc',\n                ''):\n            suffix_log = (\n                '{} exc={}').format(\n                    suffix_log,\n                    log_dict.get(\n                        'exc',\n                        ''))\n\n        if show_message_details:\n            suffix_log = (\n                'dc={} env={} '\n                'source={} line={}').format(\n                    log_dict.get(\n                        'dc',\n                        ''),\n                    log_dict.get(\n                        'env',\n                        ''),\n                    log_dict.get(\n                        'path',\n                        ''),\n                    log_dict.get(\n                        'lineno',\n                        ''))\n\n        msg = (\n            '{} {} {}').format(\n                prefix_log,\n                log_dict.get(\n                    'message',\n                    ''),\n                suffix_log)\n\n        if log_dict['levelname'] == 'INFO':\n            log.info((\n                '{}').format(\n                    msg))\n        elif log_dict['levelname'] == 'DEBUG':\n            log.debug((\n                '{}').format(\n                    msg))\n        elif log_dict['levelname'] == 'ERROR':\n            log.error((\n                '{}').format(\n                    msg))\n        elif log_dict['levelname'] == 'CRITICAL':\n            log.critical((\n                '{}').format(\n                    msg))\n        elif log_dict['levelname'] == 'WARNING':\n            log.warning((\n                '{}').format(\n                    msg))\n        else:\n            log.debug((\n                '{}').format(\n                    msg))\n    elif json_view:\n        if log_dict['levelname'] == 'INFO':\n            log.info((\n                '{}').format(\n                    ppj(log_dict)))\n        elif log_dict['levelname'] == 'DEBUG':\n            log.debug((\n                '{}').format(\n                    ppj(log_dict)))\n        elif log_dict['levelname'] == 'ERROR':\n            log.error((\n                '{}').format(\n                    ppj(log_dict)))\n        elif log_dict['levelname'] == 'CRITICAL':\n            log.critical((\n                '{}').format(\n                    ppj(log_dict)))\n        elif log_dict['levelname'] == 'WARNING':\n            log.warning((\n                '{}').format(\n                    ppj(log_dict)))\n        else:\n            log.debug((\n                '{}').format(\n                    ppj(log_dict)))\n    else:\n        log.error((\n            'Please use either code_view or json_view to view the logs'))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run_main():\n\n    parser = argparse.ArgumentParser(\n        description=(\n            'Search Splunk'))\n    parser.add_argument(\n        '-u',\n        help='username',\n        required=False,\n        dest='user')\n    parser.add_argument(\n        '-p',\n        help='user password',\n        required=False,\n        dest='password')\n    parser.add_argument(\n        '-f',\n        help='splunk-ready request in a json file',\n        required=False,\n        dest='datafile')\n    parser.add_argument(\n        '-i',\n        help='index to search',\n        required=False,\n        dest='index_name')\n    parser.add_argument(\n        '-a',\n        help='host address: <fqdn:port>',\n        required=False,\n        dest='address')\n    parser.add_argument(\n        '-e',\n        help='(Optional) earliest_time minutes back',\n        required=False,\n        dest='earliest_time_minutes')\n    parser.add_argument(\n        '-l',\n        help='(Optional) latest_time minutes back',\n        required=False,\n        dest='latest_time_minutes')\n    parser.add_argument(\n        '-q',\n        '--queryargs',\n        nargs='*',\n        help=(\n            'query string for searching splunk: '\n            'search index=\"antinex\" AND levelname=\"ERROR\"'),\n        required=False,\n        dest='query_args')\n    parser.add_argument(\n        '-j',\n        help='(Optional) view as json dictionary logs',\n        required=False,\n        dest='json_view',\n        action='store_true')\n    parser.add_argument(\n        '-t',\n        help=(\n            '(Optional) pre-existing Splunk token '\n            'which can be set using export '\n            'SPLUNK_TOKEN=<token>  - if provided '\n            'the user (-u) and password (-p) '\n            'arguments are not required'),\n        required=False,\n        dest='token')\n    parser.add_argument(\n        '-m',\n        help='(Optional) verbose message when getting logs',\n        required=False,\n        dest='message_details',\n        action='store_true')\n    parser.add_argument(\n        '-v',\n        help='(Optional) verify certs - disabled by default',\n        required=False,\n        dest='verify',\n        action='store_true')\n    parser.add_argument(\n        '-b',\n        help='verbose',\n        required=False,\n        dest='verbose',\n        action='store_true')\n    args = parser.parse_args()\n\n    user = SPLUNK_USER\n    password = SPLUNK_PASSWORD\n    token = SPLUNK_TOKEN\n    address = SPLUNK_API_ADDRESS\n    index_name = SPLUNK_INDEX\n    verbose = SPLUNK_VERBOSE\n    show_message_details = bool(str(ev(\n        'MESSAGE_DETAILS',\n        '0')).lower() == '1')\n    earliest_time_minutes = None\n    latest_time_minutes = None\n    verify = False\n    code_view = True\n    json_view = False\n    datafile = None\n\n    if args.user:\n        user = args.user\n    if args.password:\n        password = args.password\n    if args.address:\n        address = args.address\n    if args.datafile:\n        datafile = args.datafile\n    if args.index_name:\n        index_name = args.index_name\n    if args.verify:\n        verify = args.verify\n    if args.earliest_time_minutes:\n        earliest_time_minutes = int(args.earliest_time_minutes)\n    if args.latest_time_minutes:\n        latest_time_minutes = int(args.latest_time_minutes)\n    if args.verbose:\n        verbose = True\n    if args.message_details:\n        show_message_details = args.message_details\n    if args.token:\n        token = args.token\n    if args.json_view:\n        json_view = True\n        code_view = False\n\n    default_search_query = 'index=\"{}\" | head 10 | reverse'.format(\n        index_name)\n    search_query = ev(\n        'SPLUNK_QUERY',\n        default_search_query)\n    if args.query_args:\n        search_query = ' '.join(\n            args.query_args)\n\n    valid = True\n    if not user or user == 'user-not-set':\n        log.critical('missing user')\n        valid = False\n    if not password or password == 'password-not-set':\n        log.critical('missing password')\n        valid = False\n    if not index_name:\n        log.critical('missing splunk index')\n        valid = False\n    if token:\n        # if the token is present,\n        # then the user and the password are not required\n        if not valid and index_name:\n            valid = True\n    if not valid:\n        log.critical(\n            'Please run with the following arguments:\\n')\n        log.error(\n            '-u <username> -p <password> '\n            '-i <index> -t <token if user and password not set> '\n            '-a <host address as: fqdn:port>')\n        log.critical(\n            '\\n'\n            'Or you can export the following '\n            'environment variables and retry the command: '\n            '\\n')\n        log.error(\n            'export SPLUNK_ADDRESS=\"splunkenterprise:8088\"\\n'\n            'export SPLUNK_API_ADDRESS=\"splunkenterprise:8089\"\\n'\n            'export SPLUNK_PASSWORD=\"123321\"\\n'\n            'export SPLUNK_USER=\"trex\"\\n'\n            'export SPLUNK_INDEX=\"antinex\"\\n'\n            'export SPLUNK_TOKEN=\"<Optional pre-existing Splunk token>\"\\n')\n        sys.exit(1)\n\n    if verbose:\n        log.info((\n            'creating client user={} address={}').format(\n                user,\n                address))\n\n    last_msg = ''\n    host = ''\n    port = -1\n    try:\n        last_msg = (\n            'Invalid address={}').format(\n                address)\n        address_split = address.split(':')\n        last_msg = (\n            'Failed finding host in address={} '\n            '- please use: -a <fqdn:port>').format(\n                address)\n        host = address_split[0]\n        last_msg = (\n            'Failed finding integer port in address={} '\n            '- please use: -a <fqdn:port>').format(\n                address)\n        port = int(address_split[1])\n    except Exception as e:\n        log.error((\n            'Failed to parse -a {} for the '\n            'splunk host address: {} which threw an '\n            'ex={}').format(\n                address,\n                last_msg,\n                e))\n        sys.exit(1)\n    # end of try ex\n\n    if verbose:\n        log.info((\n            'connecting {}@{}:{}').format(\n                user,\n                host,\n                port))\n\n    req_body = None\n    if datafile:\n        if verbose:\n            log.info((\n                'loading request in datafile={}').format(\n                    datafile))\n\n        with open(datafile, 'r') as f:\n            req_body = json.loads(f.read())\n\n    earliest_time = None\n    latest_time = None\n    now = datetime.datetime.now()\n    if earliest_time_minutes:\n        min_15_ago = now - datetime.timedelta(\n            minutes=earliest_time_minutes)\n        earliest_time = min_15_ago.strftime(\n            '%Y-%m-%dT%H:%M:%S.000-00:00')\n    if latest_time_minutes:\n        latest_time = (now - datetime.timedelta(\n            minutes=latest_time_minutes)).strftime(\n                '%Y-%m-%dT%H:%M:%S.000-00:00')\n\n    # Step 2: Create a search job\n    if not search_query.startswith('search'):\n        search_query = 'search {}'.format(\n            search_query)\n\n    search_data = req_body\n    if not search_data:\n        search_data = {\n            'search': search_query\n        }\n        if earliest_time:\n            search_data['earliest_time'] = earliest_time\n        if latest_time:\n            search_data['latest_time'] = latest_time\n\n    res = sp.search(\n        user=user,\n        password=password,\n        address=address,\n        token=token,\n        query_dict=search_data,\n        verify=verify)\n\n    if res['status'] == SUCCESS:\n        result_list = []\n        try:\n            result_list = res['record'].get(\n                'results',\n                result_list)\n            if len(result_list) == 0:\n                log.info((\n                    'No matches for search={} '\n                    'response={}').format(\n                        ppj(search_data),\n                        ppj(res['record'])))\n        except Exception as e:\n            result_list = []\n            log.error((\n                'Failed to find results for the query={} '\n                'with ex={}').format(\n                    ppj(search_data),\n                    e))\n\n        for ridx, log_record in enumerate(result_list):\n            log_raw = log_record.get(\n                '_raw',\n                None)\n            if log_raw:\n                show_search_results(\n                    log_rec=log_raw,\n                    code_view=code_view,\n                    json_view=json_view,\n                    show_message_details=show_message_details)\n            else:\n                show_non_search_results(\n                    log_rec=log_record,\n                    code_view=code_view,\n                    json_view=json_view,\n                    show_message_details=show_message_details)\n            # end of handling log record presentation as a view\n        # end for all log records\n    else:\n        log.error((\n            'Failed searching splunk with status={} and '\n            'error: {}').format(\n                res['status'],\n                res['err']))\n    # end of if job_id\n\n    if verbose:\n        log.info('done')", "response": "Main function for the main function of the main function of the main function of the main function of the main function of the main function of the main function of the main function of the main function of the main function."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef socket_send(\n        sock,\n        msg,\n        debug=False):\n    \"\"\"socket_send\n\n    Send the ``msg`` over the connected socket ``sock``.\n    This will throw for any errors.\n\n    :param sock: connected socket\n    :param msg: message as a string\n    :param debug: debug bool\n    \"\"\"\n    if IS_PY2:\n        sock.send(msg)\n    else:\n        sock.send(msg.encode())", "response": "Send a message over the connected socket."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send_to_splunk(\n        session=None,\n        url=None,\n        data=None,\n        headers=None,\n        verify=False,\n        ssl_options=None,\n        timeout=10.0):\n    \"\"\"send_to_splunk\n\n    Send formatted msgs to Splunk. This will throw exceptions\n    for any errors. It is decoupled from the publishers to\n    make testing easier with mocks.\n\n    :param session: requests.Session\n    :param url: url for splunk logs\n    :param data: data to send\n    :param headers: headers for splunk\n    :param verify: verify certs\n    :param ssl_options: certs dictionary\n    :param timeout: timeout in seconds\n    \"\"\"\n    r = session.post(\n        url=url,\n        data=data,\n        headers=headers,\n        verify=verify,\n        timeout=timeout\n    )\n    r.raise_for_status()  # Throws exception for 4xx/5xx status\n    return r", "response": "Send formatted msgs to Splunk"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse one search result page.", "response": "def handle_url(url, session, res):\n    \"\"\"Parse one search result page.\"\"\"\n    print(\"Parsing\", url, file=sys.stderr)\n    try:\n        data = getPageContent(url, session)\n    except IOError as msg:\n        print(\"ERROR:\", msg, file=sys.stderr)\n        return\n    for match in page_matcher.finditer(data):\n        page_url = match.group(1)\n        page_url = urlparse.urljoin(url, page_url)\n        name = format_name(match.group(2))\n        if name in exclude_comics:\n            continue\n        if contains_case_insensitive(res, name):\n            # we cannot handle two comics that only differ in case\n            print(\"INFO: skipping possible duplicate\", repr(name), file=sys.stderr)\n            continue\n        # find out how many images this comic has\n        end = match.end()\n        mo = num_matcher.search(data[end:])\n        if not mo:\n            print(\"ERROR matching number:\", repr(data[end:end+300]), file=sys.stderr)\n            continue\n        num = int(mo.group(1))\n        # search for url in extra page\n        print(\"Getting\", page_url)\n        try:\n            data2 = getPageContent(page_url, session)\n        except IOError as msg:\n            print(\"ERROR:\", msg, file=sys.stderr)\n            return\n        mo = url_matcher.search(data2)\n        if not mo:\n            print(\"ERROR matching comic URL:\", repr(data2[:300]), file=sys.stderr)\n            continue\n        comic_url = mo.group(1)\n        # search for adult flag\n        adult = adult_matcher.search(data2[end:])\n        bounce = name not in repeat_comics\n        res[name] = [\n          url_overrides.get(name, comic_url), num, bool(adult), bounce\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_results():\n    base = \"http://www.smackjeeves.com/search.php?submit=Search+for+Webcomics&search_mode=webcomics&comic_title=&special=all&last_update=3&style_all=on&genre_all=on&format_all=on&sort_by=2&start=%d\"\n    session = requests.Session()\n    # store info in a dictionary {name -> url, number of comics, adult flag, bounce flag}\n    res = {}\n    # a search for an empty string returned 286 result pages\n    result_pages = 286\n    print(\"Parsing\", result_pages, \"search result pages...\", file=sys.stderr)\n    for i in range(0, result_pages):\n        print(i+1, file=sys.stderr, end=\" \")\n        handle_url(base % (i*12), session, res)\n    save_result(res, json_file)", "response": "Parse all search result pages."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _execute(self):\n\n        query = [\n            'gerrit', 'query',\n            '--current-patch-set',\n            str(self._filters),\n            '--format=JSON']\n\n        results = self.client.exec_command(' '.join(query))\n        stdin, stdout, stderr = results\n\n        for line in stdout:\n            normalized = json.loads(line)\n\n            # Do not return the last item\n            # since it is the summary of\n            # of the query\n            if \"rowCount\" in normalized:\n                raise StopIteration\n\n            yield normalized", "response": "Executes the query and yields items."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef commit(self, message=None):\n\n        flags = filters.Items()\n\n        if self._status:\n            flags.add_flags(self._status)\n\n        if self._code_review is not None:\n            flags.add_flags(\"code-review %s\" % self._code_review)\n\n        if self._verified is not None:\n            flags.add_flags(\"verified %s\" % self._verified)\n\n        if message:\n            flags.add_flags(\"message '%s'\" % message)\n\n        query = ['gerrit', 'review', str(flags), str(self._review)]\n\n        results = self.client.exec_command(' '.join(query))\n        stdin, stdout, stderr = results\n\n        # NOTE(flaper87): Log error messages\n        error = []\n        for line in stderr:\n            error.append(line)\n\n        # True if success\n        return not error", "response": "Executes the command and returns the status of the current state of the current state of the current state."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_macro_params(token):\n    try:\n        bits = token.split_contents()\n        tag_name, macro_name, values = bits[0], bits[1], bits[2:]\n    except IndexError:\n        raise template.TemplateSyntaxError(\n            \"{0} tag requires at least one argument (macro name)\".format(\n                token.contents.split()[0]))\n\n    args = []\n    kwargs = {}\n\n    # leaving most validation up to the template.Variable\n    # class, but use regex here so that validation could\n    # be added in future if necessary.\n    kwarg_regex = (\n        r'^([A-Za-z_][\\w_]*)=(\".*\"|{0}.*{0}|[A-Za-z_][\\w_]*)$'.format(\n            \"'\"))\n    arg_regex = r'^([A-Za-z_][\\w_]*|\".*\"|{0}.*{0}|(\\d+))$'.format(\n        \"'\")\n    for value in values:\n        # must check against the kwarg regex first\n        # because the arg regex matches everything!\n        kwarg_match = regex_match(\n            kwarg_regex, value)\n        if kwarg_match:\n            kwargs[kwarg_match.groups()[0]] = template.Variable(\n                # convert to a template variable here\n                kwarg_match.groups()[1])\n        else:\n            arg_match = regex_match(\n                arg_regex, value)\n            if arg_match:\n                args.append(template.Variable(arg_match.groups()[0]))\n            else:\n                raise template.TemplateSyntaxError(\n                    \"Malformed arguments to the {0} tag.\".format(\n                        tag_name))\n\n    return tag_name, macro_name, args, kwargs", "response": "Common parsing logic for both use_macro and macro_block\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfunction taking parsed template tag and a MacroBlockNode.", "response": "def do_macro_block(parser, token):\n    \"\"\" Function taking parsed template tag\n    to a MacroBlockNode.\n    \"\"\"\n    tag_name, macro_name, args, kwargs = parse_macro_params(token)\n    # could add extra validation on the macro_name tag\n    # here, but probably don't need to since we're checking\n    # if there's a macro by that name anyway.\n    try:\n        # see if the macro is in the context.\n        macro = parser._macros[macro_name]\n    except (AttributeError, KeyError):\n        raise template.TemplateSyntaxError(\n            \"Macro '{0}' is not defined \".format(macro_name) +\n            \"previously to the {0} tag\".format(tag_name))\n    # get the arg and kwarg nodes from the nodelist\n    nodelist = parser.parse(('endmacro_block',))\n    parser.delete_first_token()\n\n    # Loop through nodes, sorting into args/kwargs\n    # (we could do this more semantically, but we loop\n    # only once like this as an optimization).\n    for node in nodelist:\n        if isinstance(node, MacroArgNode) and not isinstance(node, MacroKwargNode):\n            # note that MacroKwargNode is also a MacroArgNode (via inheritance),\n            # so we must check against this.\n            args.append(node)\n        elif isinstance(node, MacroKwargNode):\n            if node.keyword in macro.kwargs:\n                # check that the keyword is defined as an argument for\n                # the macro.\n                if node.keyword not in kwargs:\n                    # add the keyword argument to the dict\n                    # if it's not in there\n                    kwargs[node.keyword] = node\n                else:\n                    # raise a template syntax error if the\n                    # keyword is already in the dict (thus a keyword\n                    # argument was passed twice.\n                    raise template.TemplateSyntaxError(\n                        \"{0} template tag was supplied \"\n                        \"the same keyword argument multiple times.\".format(\n                            tag_name))\n            else:\n                raise template.TemplateSyntaxError(\n                    \"{0} template tag was supplied with a \"\n                    \"keyword argument not defined by the {1} macro.\".format(\n                        tag_name, macro_name))\n        # The following is a check that only whitespace is inside the macro_block tag,\n        # but it's currently removed for reasons of backwards compatibility/potential \n        # uses people might have to put extra stuff in te macro_block tag.\n        # elif not isinstance(node, template.TextNode) or node.s.strip() != \"\":\n        #     # whitespace is allowed, anything else is not\n        #     raise template.TemplateSyntaxError(\n        #         \"{0} template tag received an argument that \"\n        #         \"is neither a arg or a kwarg tag. Make sure there's \"\n        #         \"text or template tags directly descending \"\n        #         \"from the {0} tag.\".format(tag_name))\n\n    # check that there aren't more arg tags than args\n    # in the macro.\n    if len(args) > len(macro.args):\n        raise template.TemplateSyntaxError(\n            \"{0} template tag was supplied too many arg block tags.\".format(\n                tag_name))\n\n    macro.parser = parser\n    return MacroBlockNode(macro, nodelist, args, kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfunctions taking a parsed template tag to a MacroArgNode. MacroArgNode is used to validate the template tagMacroArgNode.", "response": "def do_macro_arg(parser, token):\n    \"\"\" Function taking a parsed template tag\n    to a MacroArgNode.\n    \"\"\"\n    # macro_arg takes no arguments, so we don't\n    # need to split the token/do validation.\n    nodelist = parser.parse(('endmacro_arg',))\n    parser.delete_first_token()\n    # simply save the contents to a MacroArgNode.\n    return MacroArgNode(nodelist)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef do_macro_kwarg(parser, token):\n    try:\n        tag_name, keyword = token.split_contents()\n    except ValueError:\n        raise template.TemplateSyntaxError(\n            \"{0} tag requires exactly one argument, a keyword\".format(\n                token.contents.split()[0]))\n\n    # add some validation of the keyword argument here.\n    nodelist = parser.parse(('endmacro_kwarg',))\n    parser.delete_first_token()\n    return MacroKwargNode(keyword, nodelist)", "response": "Function taking a parsed template tag\n    to a MacroKwargNode."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nuse to mark a method on a ViewSet that should be routed for detail requests. Usage:: class UserViewSet(ModelCRUDViewSet): model = User schema = UserSchema @detail_route(methods=['post'], url_path='lock-user') def lock_user(request, id): ... :param methods: An iterable of strings representing the HTTP (GET, POST, etc.) methods accepted by the route. :param url_path: Replaces the route automatically generated by the ViewSetRouter for the decorated method with the value provided.", "response": "def detail_route(methods=None, **kwargs):\n    \"\"\"\n    Used to mark a method on a ViewSet that should be routed for detail requests.\n\n    Usage::\n\n        class UserViewSet(ModelCRUDViewSet):\n            model = User\n            schema = UserSchema\n\n            @detail_route(methods=['post'], url_path='lock-user')\n            def lock_user(request, id):\n                ...\n\n    :param methods: An iterable of strings representing the HTTP (GET, POST, etc.) methods accepted by the route.\n    :param url_path: Replaces the route automatically generated by the ViewSetRouter for the decorated method\n                     with the value provided.\n    \"\"\"\n    methods = ['get'] if (methods is None) else methods\n\n    def decorator(func):\n        func.bind_to_methods = methods\n        func.detail = True\n        func.kwargs = kwargs\n\n        return func\n\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_route(methods=None, **kwargs):\n\n    methods = ['get'] if (methods is None) else methods\n\n    def decorator(func):\n        func.bind_to_methods = methods\n        func.detail = False\n        func.kwargs = kwargs\n\n        return func\n\n    return decorator", "response": "Decorator that creates a list route for a viewset."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef count_nulls(self, field):\n        try:\n            n = self.df[field].isnull().sum()\n        except KeyError:\n            self.warning(\"Can not find column\", field)\n            return\n        except Exception as e:\n            self.err(e, \"Can not count nulls\")\n            return\n        self.ok(\"Found\", n, \"nulls in column\", field)", "response": "Count the number of null values in a column"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef count(self):\n        try:\n            num = len(self.df.index)\n        except Exception as e:\n            self.err(e, \"Can not count data\")\n            return\n        self.ok(\"Found\", num, \"rows in the dataframe\")", "response": "Counts the number of rows in the main dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the number of rows of the main dataframe", "response": "def count_(self):\n        \"\"\"\n        Returns the number of rows of the main dataframe\n        \"\"\"\n        try:\n            num = len(self.df.index)\n        except Exception as e:\n            self.err(e, \"Can not count data\")\n            return\n        return num"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef count_empty(self, field):\n        try:\n            df2 = self.df[[field]]\n            vals = where(df2.applymap(lambda x: x == ''))\n            num = len(vals[0])\n        except Exception as e:\n            self.err(e, \"Can not count empty values\")\n            return\n        self.ok(\"Found\", num, \"empty rows in column \" + field)", "response": "Count the number of empty rows in a column"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncounts the number of unique values in a column", "response": "def count_unique_(self, field):\n        \"\"\"\n        Return the number of unique values in a column\n        \"\"\"\n        try:\n            num = self.df[field].nunique()\n        except Exception as e:\n            self.err(e, \"Can not count unique values\")\n            return\n        self.ok(\"Found\", num, \"unique values in column\", field)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsearching the list of customers.", "response": "def search_customer(self, limit=100, offset=0, email_pattern=None, last_name_pattern=None,\n            company_name_pattern=None, with_additional_data=False):\n        \"\"\"Search the list of customers.\"\"\"\n\n        response = self.request(E.searchCustomerRequest(\n            E.limit(limit),\n            E.offset(offset),\n            E.emailPattern(email_pattern or ''),\n            E.lastNamePattern(last_name_pattern or ''),\n            E.companyNamePattern(company_name_pattern or ''),\n            E.withAdditionalData(int(with_additional_data)),\n        ))\n\n        return response.as_models(Customer)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves information of an existing customer.", "response": "def retrieve_customer(self, handle, with_additional_data=False):\n        \"\"\"Retrieve information of an existing customer.\"\"\"\n\n        response = self.request(E.retrieveCustomerRequest(\n            E.handle(handle),\n            E.withAdditionalData(int(with_additional_data)),\n        ))\n\n        return response.as_model(Customer)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef import_namespaced_class(path):\n    parts = path.split('.')\n    return getattr(importlib.import_module('.'.join(parts[0:-1])), parts[-1])", "response": "Import a class from a string in the format of foo. Bar Baz Qux\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_importable_modules(folder):\n    for fname in os.listdir(folder):\n        if fname.endswith('.py') and not fname.startswith('_'):\n            yield fname[:-3]", "response": "Find all module files in the given folder that end with. py and don t start with an underscore."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds all class objects in all modules.", "response": "def get_plugins(modules, classobj):\n    \"\"\"Find all class objects in all modules.\n    @param modules: the modules to search\n    @ptype modules: iterator of modules\n    @return: found classes\n    @rytpe: iterator of class objects\n    \"\"\"\n    for module in modules:\n        for plugin in get_module_plugins(module, classobj):\n            yield plugin"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_module_plugins(module, classobj):\n    try:\n        names = module.__all__\n    except AttributeError:\n        names = [x for x in vars(module) if not x.startswith('_')]\n    for name in names:\n        try:\n            obj = getattr(module, name)\n        except AttributeError:\n            continue\n        try:\n            if issubclass(obj, classobj):\n                yield obj\n        except TypeError:\n            continue", "response": "Return all subclasses of a class in the module."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstacks a report in the database.", "response": "def stack(self, slug, chart_obj=None, title=None):\n        \"\"\"\n        Get the html for a chart and store it\n        \"\"\"\n        if chart_obj is None:\n            if self.chart_obj is None:\n                self.err(\n                    self.stack,\n                    \"No chart object set: please provide one in parameters\")\n                return\n            chart_obj = self.chart_obj\n        try:\n            seaborn_chart = None\n            if self.engine == \"chartjs\":\n                html = chart_obj\n            elif self.engine == \"seaborn\":\n                html = \"\"\n                seaborn_chart = chart_obj\n            else:\n                html = self.get_html(chart_obj, slug)\n            if html is None and seaborn_chart is None:\n                self.err(\n                    self.stack, \"Can not stack: empty html reveived for \" +\n                    str(chart_obj), \"-\", slug)\n                return\n            report = dict(slug=slug, html=html)\n            if seaborn_chart is not None:\n                report[\"seaborn_chart\"] = seaborn_chart\n            if self.engine not in self.report_engines:\n                self.report_engines.append(self.engine)\n            self.reports.append(report)\n        except Exception as e:\n            self.err(e, self.stack, \"Can not stack report\")\n            return\n        self.ok(\"Stacked report\", slug)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_file(self, slug, folderpath=None, header=None, footer=None):\n        if folderpath is None:\n            if self.report_path is None:\n                self.err(\n                    \"Please set the report_path parameter or pass a path in arguments\")\n                return\n            folderpath = self.report_path\n        else:\n            self.report_path = folderpath\n        html = self._get_header(header)\n        if html is None or html == \"\":\n            self.err(self.to_file, \"Can not get html header\")\n        for report in self.reports:\n            if \"html\" not in report:\n                self.err(\"No html for report \" + report)\n                self.reports = self.report_engines = []\n                return\n            html += report[\"html\"]\n        html += self._get_footer(footer)\n        try:\n            path = self._write_file(slug, folderpath, html)\n            path = \"file://\" + path\n        except Exception as e:\n            self.err(e, self.to_file, \"Can not save report to file\")\n            return\n        self.reports = []\n        self.report_engines = []\n        if self.notebook is True:\n            link = '<a href=\"' + path + '\" target=\"_blank\">' + path + '</a>'\n            return display(HTML(link))", "response": "Writes the html report to a file from the report stack"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_files(self, folderpath=None):\n        if len(self.reports) == 0:\n            self.warning(\n                \"No charts to save. Use stack to add charts for saving\")\n            return\n        if folderpath is None:\n            if self.report_path is None and \"seaborn\" \\\n                    not in self.report_engines:\n                self.err(\"No folder path set for reports: please provide \"\n                         \"one as argument or set ds.report_path\")\n                return\n            folderpath = self.report_path\n        else:\n            if folderpath.startswith('/') or folderpath.startswith(\".\"):\n                pass\n            else:\n                folderpath = self.report_path + \"/\" + folderpath\n        try:\n            for report in self.reports:\n                if \"html\" not in report:\n                    self.err(\"No html for report \" + report)\n                    self.reports = self.report_engines = []\n                    return\n                if \"seaborn_chart\" in report:\n                    if folderpath is None and self.static_path is None:\n                        self.err(\"Please provide a folder path or set the \"\n                                 \"static_path property\")\n                        return\n                    self._save_seaborn_chart(report, self.static_path)\n                else:\n                    html = report[\"html\"]\n                    self._write_file(report[\"slug\"], folderpath, html)\n            self.reports = []\n            self.report_engines = []\n        except Exception as e:\n            self.err(e, self.to_files, \"Can not save reports to files\")\n            return\n        self.ok(\"Data writen to files\")", "response": "Writes the html report to one file per report"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the html and script tag for a chart object", "response": "def get_html(self, chart_obj=None, slug=None):\n        \"\"\"\n        Get the html and script tag for a chart\n        \"\"\"\n        if chart_obj is None:\n            if self.chart_obj is None:\n                self.err(\n                    \"No chart object registered, please provide \"\n                    \"one in parameters\"\n                )\n                return\n            chart_obj = self.chart_obj\n        try:\n            if self.engine == \"bokeh\":\n                html = self._get_bokeh_html(chart_obj)\n                if html is None:\n                    self.err(\"No html returned for \" + str(chart_obj))\n                return html\n            elif self.engine == \"altair\":\n                html = self._get_altair_html_(chart_obj, slug)\n                if html is None:\n                    self.err(\"No html returned for \" + str(chart_obj))\n                return html\n            else:\n                self.err(\"Chart engine \" + self.engine + \" unknown\")\n                return\n        except Exception as e:\n            self.err(e, \"Can not get html from chart object\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the html header", "response": "def _get_header(self, header):\n        \"\"\"\n        Gets the html header\n        \"\"\"\n        if header is None:\n            html = self.header()\n        else:\n            html = header\n        return html"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the html footer", "response": "def _get_footer(self, footer):\n        \"\"\"\n        Gets the html footer\n        \"\"\"\n        if footer is None:\n            html = self.footer()\n        else:\n            html = footer\n        return html"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _write_file(self, slug, folderpath, html):\n        # check directories\n        if not os.path.isdir(folderpath):\n            try:\n                os.makedirs(folderpath)\n                self.info(\"Creating directory \" + folderpath)\n            except Exception as e:\n                self.err(e)\n                return\n        # construct file path\n        filepath = folderpath + \"/\" + slug + \".html\"\n        # write the file\n        try:\n            filex = open(filepath, \"w\")\n            filex.write(html)\n            filex.close()\n            if self.notebook is False:\n                self.ok(\"File written to\", filepath)\n            else:\n                html = '<a href=\"' + filepath + '\">' + filepath + '</a>'\n                self.html(\"File written to\", html)\n        except Exception as e:\n            self.err(e)\n        return filepath", "response": "Writes a chart s html to a file"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the HTML header for the current locale.", "response": "def _header(self):\n        \"\"\"\n        Default html header\n        \"\"\"\n        html = \"\"\"\n\t\t<!DOCTYPE html>\n\t\t<html lang=\"en\">\n\t\t<head>\n\t\t\t<meta charset=\"utf-8\">\n\t\t\t<title>Report</title>\n\t\t\"\"\"\n        if \"bokeh\" in self.report_engines:\n            html += self.bokeh_header_()\n        if \"altair\" in self.report_engines:\n            html += self.altair_header_()\n        if \"chartjs\" in self.report_engines:\n            html += self.chartjs_header_()\n        html += \"\"\"\n\t\t</head>\n\t\t<body>\n\t\t\"\"\"\n        return html"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef title(self, txt):\n        num = len(txt)\n        ticks = \"=\" * num\n        print(ticks)\n        print(txt)\n        print(ticks)", "response": "Prints a title for pipelines\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef subtitle(self, txt):\n        num = len(txt)\n        ticks = \"-\" * num\n        print(txt)\n        print(ticks)", "response": "Prints a subtitle for pipelines\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndownloading update info and parse it.", "response": "def get_online_version ():\n    \"\"\"Download update info and parse it.\"\"\"\n    session = requests.session()\n    page = urlopen(UPDATE_URL, session)\n    version, url = None, None\n    for line in page.text.splitlines():\n        if line.startswith(VERSION_TAG):\n            version = line.split(':', 1)[1].strip()\n        elif line.startswith(URL_TAG):\n            url = line.split(':', 1)[1].strip()\n            url = url.replace('${version}', version)\n    return version, url"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates and return a new instance of tinman. application. Application", "response": "def create_application(self):\n        \"\"\"Create and return a new instance of tinman.application.Application\"\"\"\n        return application.Application(self.settings,\n                                       self.namespace.routes,\n                                       self.port)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a dictionary of HTTPServer arguments using the default values as specified in the HTTPServer class docstrings.", "response": "def http_config(self):\n        \"\"\"Return a dictionary of HTTPServer arguments using the default values\n        as specified in the HTTPServer class docstrings if no values are\n        specified.\n\n        :param dict config: The HTTPServer specific section of the config\n        :rtype: dict\n\n        \"\"\"\n        return {config.NO_KEEP_ALIVE:\n                    self.namespace.server.get(config.NO_KEEP_ALIVE, False),\n                config.SSL_OPTIONS: self.ssl_options,\n                config.XHEADERS: self.namespace.server.get(config.XHEADERS,\n                                                           False)}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstopping the HTTP Server and IO Loop", "response": "def on_sigabrt(self, signal_unused, frame_unused):\n        \"\"\"Stop the HTTP Server and IO Loop, shutting down the process\n\n        :param int signal_unused: Unused signal number\n        :param frame frame_unused: Unused frame the signal was caught in\n\n        \"\"\"\n        LOGGER.info('Stopping HTTP Server and IOLoop')\n        self.http_server.stop()\n        self.ioloop.stop()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreloads the configuration and routes", "response": "def on_sighup(self, signal_unused, frame_unused):\n        \"\"\"Reload the configuration\n\n        :param int signal_unused: Unused signal number\n        :param frame frame_unused: Unused frame the signal was caught in\n\n        \"\"\"\n        # Update HTTP configuration\n        for setting in self.http_config:\n            if getattr(self.http_server, setting) != self.http_config[setting]:\n                LOGGER.debug('Changing HTTPServer %s setting', setting)\n                setattr(self.http_server, setting, self.http_config[setting])\n\n        # Update Application Settings\n        for setting in self.settings:\n            if self.app.settings[setting] != self.settings[setting]:\n                LOGGER.debug('Changing Application %s setting', setting)\n                self.app.settings[setting] = self.settings[setting]\n\n        # Update the routes\n        self.app.handlers = []\n        self.app.named_handlers = {}\n        routes = self.namespace.config.get(config.ROUTES)\n        self.app.add_handlers(\".*$\", self.app.prepare_routes(routes))\n\n        LOGGER.info('Configuration reloaded')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalls when the process has started", "response": "def run(self):\n        \"\"\"Called when the process has started\n\n        :param int port: The HTTP Server port\n\n        \"\"\"\n        LOGGER.debug('Initializing process')\n\n        # Setup logging\n        self.logging_config = self.setup_logging()\n\n        # Register the signal handlers\n        self.setup_signal_handlers()\n\n        # Create the application instance\n        try:\n            self.app = self.create_application()\n        except exceptions.NoRoutesException:\n            return\n\n        # Create the HTTPServer\n        self.http_server = self.create_http_server()\n\n        # Hold on to the IOLoop in case it's needed for responding to signals\n        self.ioloop = ioloop.IOLoop.instance()\n\n        # Start the IOLoop, blocking until it is stopped\n        try:\n            self.ioloop.start()\n        except KeyboardInterrupt:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setup_signal_handlers(self):\n        LOGGER.debug('Registering signal handlers')\n        signal.signal(signal.SIGABRT, self.on_sigabrt)", "response": "Called when a child process is spawned to register the signal handlers"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck the config to see if SSL configuration options have been passed and replace none option and required with the correct values in the certreqs attribute if it is specified.", "response": "def ssl_options(self):\n        \"\"\"Check the config to see if SSL configuration options have been passed\n        and replace none, option, and required with the correct values in\n        the certreqs attribute if it is specified.\n\n        :rtype: dict\n\n        \"\"\"\n        opts = self.namespace.server.get(config.SSL_OPTIONS) or dict()\n        if config.CERT_REQS in opts:\n            opts[config.CERT_REQS] = \\\n                self.CERT_REQUIREMENTS[opts[config.CERT_REQS]]\n        return opts or None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstart the HTTPServer on the given port.", "response": "def start_http_server(self, port, args):\n        \"\"\"Start the HTTPServer\n\n        :param int port: The port to run the HTTPServer on\n        :param dict args: Dictionary of arguments for HTTPServer\n        :rtype: tornado.httpserver.HTTPServer\n\n        \"\"\"\n        # Start the HTTP Server\n        LOGGER.info(\"Starting Tornado v%s HTTPServer on port %i Args: %r\",\n                    tornado_version, port, args)\n        http_server = httpserver.HTTPServer(self.app, **args)\n        http_server.bind(port, family=socket.AF_INET)\n        http_server.start(1)\n        return http_server"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef handle_url(url, session, res):\n    print(\"Parsing\", url, file=sys.stderr)\n    try:\n        data = getPageContent(url, session)\n    except IOError as msg:\n        print(\"ERROR:\", msg, file=sys.stderr)\n        return\n    for match in url_matcher.finditer(data):\n        comicurl = match.group(1)\n        name = format_name(comicurl.split('.', 1)[0][7:])\n        if name in exclude_comics:\n            continue\n        if contains_case_insensitive(res, name):\n            # we cannot handle two comics that only differ in case\n            print(\"INFO: skipping possible duplicate\", repr(name), file=sys.stderr)\n            continue\n        # find out how many images this comic has\n        end = match.end()\n        mo = num_matcher.search(data[end:])\n        if not mo:\n            print(\"ERROR matching number:\", repr(data[end:end+300]), file=sys.stderr)\n            continue\n        num = int(mo.group(1))\n        # find activity\n        mo = activity_matcher.search(data[end:])\n        if not mo:\n            print(\"ERROR matching activity:\", repr(data[end:end+300]), file=sys.stderr)\n            continue\n        active = mo.group(1).lower() == \"active\"\n        res[name] = [comicurl, num, active]\n    if not res:\n        print(\"ERROR:\", \"did not match any comics\", file=sys.stderr)", "response": "Parse one search result page."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_results():\n    # store info in a dictionary {name -> shortname}\n    res = {}\n    session = requests.Session()\n    baseUrl = 'http://comicfury.com/search.php?search=1&webcomics=Search+for+webcomics&query=&worder=5&asc=1&incvi=1&incse=1&incnu=1&incla=1&all_ge=1&all_st=1&all_la=1&page='\n    pages = 382\n    for i in range(1, pages+1):\n        url = baseUrl + str(i)\n        handle_url(url, session, res)\n    save_result(res, json_file)", "response": "Parse all search result pages."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef print_results(args):\n    min_comics, filename = args\n    min_comics = int(min_comics)\n    with codecs.open(filename, 'a', 'utf-8') as fp:\n        for name, entry in sorted(load_result(json_file).items()):\n            if name in exclude_comics:\n                continue\n            url, num, active = entry\n            if num < min_comics:\n                continue\n            if has_comic(name):\n                prefix = u'#'\n            else:\n                prefix = u''\n            fp.write(u\"%sadd(%r, %r)\\n\" % (\n              prefix, str(truncate_name(name)), str(url)\n            ))", "response": "Print all comics that have at least the given number of minimum comic strips."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvalidate given slug depending on settings.", "response": "def is_valid_article_slug(article, language, slug):\n    \"\"\"Validates given slug depending on settings.\n    \"\"\"\n    from ..models import Title\n\n    qs = Title.objects.filter(slug=slug, language=language)\n\n    if article.pk:\n        qs = qs.exclude(Q(language=language) & Q(article=article))\n        qs = qs.exclude(article__publisher_public=article)\n\n    if qs.count():\n        return False\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nestimates the memory of the supplied array in bytes", "response": "def array_bytes(array):\n    \"\"\" Estimates the memory of the supplied array in bytes \"\"\"\n    return np.product(array.shape)*np.dtype(array.dtype).itemsize"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reify_arrays(arrays, dims, copy=True):\n    arrays = ({ k : AttrDict(**a) for k, a in arrays.iteritems() }\n        if copy else arrays)\n\n    for n, a in arrays.iteritems():\n        a.shape = tuple(dims[v].extent_size if isinstance(v, str) else v\n            for v in a.shape)\n\n    return arrays", "response": "Reify arrays given the supplied dimensions."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if the request should be permitted. Raises an appropriate exception if the request is not permitted.", "response": "def check_permissions(self, request):\n        \"\"\"\n        Check if the request should be permitted.\n        Raises an appropriate exception if the request is not permitted.\n\n        :param request: Pyramid Request object.\n        \"\"\"\n\n        for permission in self.get_permissions():\n            if not permission.has_permission(request, self):\n                self.permission_denied(request, message=getattr(permission, 'message', None))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_object_permissions(self, request, obj):\n\n        for permission in self.get_permissions():\n            if not permission.has_object_permission(request, self, obj):\n                self.permission_denied(request, message=getattr(permission, 'message', None))", "response": "Checks if the request should be permitted for a given object. Raises an appropriate exception if the request is not permitted."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef options(self, request, *args, **kwargs):\n\n        response = Response()\n\n        response.headers['Allow'] = ', '.join(self.allowed_methods)\n        response.headers['Content-Length'] = '0'\n\n        return response", "response": "Handles responding to requests for the OPTIONS HTTP verb."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nskipping pages without images.", "response": "def shouldSkipUrl(self, url, data):\n        \"\"\"Skip pages without images.\"\"\"\n        return url in (\n            self.stripUrl % '130217', # video\n            self.stripUrl % '130218', # video\n            self.stripUrl % '130226', # video\n            self.stripUrl % '130424', # video\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the admin urls", "response": "def get_urls(self):\n        \"\"\"Get the admin urls\n        \"\"\"\n        info = '%s_%s' % (self.model._meta.app_label, self.model._meta.model_name)\n\n        def pat(regex, fn):\n            return url(regex, self.admin_site.admin_view(fn), name='%s_%s' % (info, fn.__name__))\n\n        url_patterns = [\n            pat(r'^([0-9]+)/delete-translation/$', self.delete_translation),\n            pat(r'^([0-9]+)/([a-z\\-]+)/publish/$', self.publish_article),\n            pat(r'^([0-9]+)/([a-z\\-]+)/unpublish/$', self.unpublish),\n            pat(r'^([0-9]+)/([a-z\\-]+)/preview/$', self.preview_article),\n        ]\n\n        url_patterns += super(ArticleAdmin, self).get_urls()\n        return url_patterns"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget ArticleForm for the Article model and modify its fields depending on the request.", "response": "def get_form(self, request, obj=None, **kwargs):\n        \"\"\"\n        Get ArticleForm for the Article model and modify its fields depending on\n        the request.\n        \"\"\"\n        language = get_language_from_request(request)\n        form = super(ArticleAdmin, self).get_form(\n            request, obj,\n            form=(obj and ArticleForm or ArticleCreateForm),\n            **kwargs\n        )\n        # get_form method operates by overriding initial fields value which\n        # may persist across invocation. Code below deepcopies fields definition\n        # to avoid leaks\n        for field in tuple(form.base_fields.keys()):\n            form.base_fields[field] = copy.deepcopy(form.base_fields[field])\n\n        if 'language' in form.base_fields:\n            form.base_fields['language'].initial = language\n\n        if obj:\n            title_obj = obj.get_title_obj(language=language, fallback=False, force_reload=True)\n\n            if hasattr(title_obj, 'id'):\n                for name in ('title', 'description', 'page_title', 'menu_title', 'meta_description', 'image'):\n                    if name in form.base_fields:\n                        form.base_fields[name].initial = getattr(title_obj, name)\n                try:\n                    slug = self.SLUG_REGEXP.search(title_obj.slug).groups()[settings.CMS_ARTICLES_SLUG_GROUP_INDEX]\n                except AttributeError:\n                    warnings.warn('Failed to parse slug from CMS_ARTICLES_SLUG_REGEXP. '\n                                  'It probably doesn\\'t correspond to CMS_ARTICLES_SLUG_FORMAT.')\n                    slug = title_obj.slug\n                form.base_fields['slug'].initial = slug\n\n        return form"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npublishes or unpublish a language of a article", "response": "def unpublish(self, request, article_id, language):\n        \"\"\"\n        Publish or unpublish a language of a article\n        \"\"\"\n        article = get_object_or_404(self.model, pk=article_id)\n        if not article.has_publish_permission(request):\n            return HttpResponseForbidden(force_text(_('You do not have permission to unpublish this article')))\n        if not article.publisher_public_id:\n            return HttpResponseForbidden(force_text(_('This article was never published')))\n        try:\n            article.unpublish(language)\n            message = _('The %(language)s article \"%(article)s\" was successfully unpublished') % {\n                'language': get_language_object(language)['name'], 'article': article}\n            messages.info(request, message)\n            LogEntry.objects.log_action(\n                user_id=request.user.id,\n                content_type_id=ContentType.objects.get_for_model(Article).pk,\n                object_id=article_id,\n                object_repr=article.get_title(),\n                action_flag=CHANGE,\n                change_message=message,\n            )\n        except RuntimeError:\n            exc = sys.exc_info()[1]\n            messages.error(request, exc.message)\n        except ValidationError:\n            exc = sys.exc_info()[1]\n            messages.error(request, exc.message)\n        path = admin_reverse('cms_articles_article_changelist')\n        if request.GET.get('redirect_language'):\n            path = '%s?language=%s&article_id=%s' % (\n                path,\n                request.GET.get('redirect_language'),\n                request.GET.get('redirect_article_id')\n            )\n        return HttpResponseRedirect(path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nredirects preview function based on draft_id", "response": "def preview_article(self, request, object_id, language):\n        \"\"\"Redirecting preview function based on draft_id\n        \"\"\"\n        article = get_object_or_404(self.model, id=object_id)\n        attrs = '?%s' % get_cms_setting('CMS_TOOLBAR_URL__EDIT_ON')\n        attrs += '&language=' + language\n        with force_language(language):\n            url = article.get_absolute_url(language) + attrs\n        return HttpResponseRedirect(url)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninitializes an Influxdb database client", "response": "def influx_init(self, url, port, user, pwd, db):\n        \"\"\"\n        Initialize an Influxdb database client\n        \"\"\"\n        try:\n            cli = DataFrameClient(url, port, user, pwd, db)\n            self.influx_cli = cli\n        except Exception as e:\n            self.err(e, self.influx_init,\n                     \"Can not initialize Influxdb database\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef influx_query_(self, q):\n        if self.influx_cli is None:\n            self.err(\n                self.influx_query_,\n                \"No database connected. Please initialize a connection\")\n            return\n        try:\n            return self.influx_cli.query(q)\n        except Exception as e:\n            self.err(e, self.influx_query_,\n                     \"Can not query database\")", "response": "Runs an Influx db query"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncounts the number of rows for a measurement", "response": "def influx_count_(self, measurement):\n        \"\"\"\n        Count the number of rows for a measurement\n        \"\"\"\n        try:\n            q = \"select count(*) from \" + measurement\n            self.start(\"Querying: count ...\")\n            datalen = self.influx_cli.query(q)\n            self.end(\"Finished querying\")\n            numrows = int(datalen[measurement][datalen[measurement].keys()[0]])\n            return numrows\n        except Exception as e:\n            self.err(e, self.influx_count_,\n                     \"Can not count rows for measurement\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef influx_to_csv(self, measurement, batch_size=5000):\n        if self.autoprint is True:\n            print(\"Processing data from InfluxDb to csv\")\n        try:\n            q = \"select count(*) from \" + measurement\n            numrows = self.influx_cli.query(q)[measurement].iloc[0, 0]\n            self.info(\"Processing\", str(numrows),\n                      \"datapoints from InfluxDb to csv\")\n            done = 0\n            offset = 1\n            while (done + 1) < numrows:\n                q = \"select * from \" + measurement + \\\n                    \" limit \" + str(batch_size)\n                if done > 0:\n                    q += \" offset \" + str(offset)\n                if self.autoprint is True:\n                    self.start(\n                        \"Querying database for the next \" +\n                        str(batch_size) + \" datapoints\")\n                res = self.influx_cli.query(q)\n                if self.autoprint is True:\n                    self.end(\"Finished to query\")\n                numres = 0\n                try:\n                    numres = len(res[measurement])\n                except KeyError:\n                    return\n                df = res[measurement]\n                ds2 = self.clone_(df)\n                ds2.to_csv(\"data/\" + measurement +\n                           \".csv\", index=False, mode='a')\n                ds2.df = None\n                if numres < batch_size:\n                    done += numres\n                else:\n                    done += batch_size\n                self.progress(\"Processed points\", offset, \"to\", done)\n                offset += batch_size\n                # if (done + 1) == numrows:\n                #    break\n        except Exception as e:\n            self.err(e, self.influx_to_csv,\n                     \"Can not transfer data from Influxdb to csv\")\n            return\n        if self.autoprint is True:\n            print(\"Finished processing data from InfluxDb to csv\")", "response": "This function takes an Influxdb measurement and attempts to transfer data from it to csv."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a list comic scraper classes. Can return more than one entry if multiple_allowed is True.", "response": "def find_scraperclasses(comic, multiple_allowed=False):\n    \"\"\"Get a list comic scraper classes. Can return more than one entries if\n    multiple_allowed is True, else it raises a ValueError if multiple\n    modules match. The match is a case insensitive substring search.\"\"\"\n    if not comic:\n        raise ValueError(\"empty comic name\")\n    candidates = []\n    cname = comic.lower()\n    for scraperclass in get_scraperclasses():\n        lname = scraperclass.getName().lower()\n        if lname == cname:\n            # perfect match\n            if not multiple_allowed:\n                return [scraperclass]\n            else:\n                candidates.append(scraperclass)\n        elif cname in lname:\n            candidates.append(scraperclass)\n    if len(candidates) > 1 and not multiple_allowed:\n        comics = \", \".join(x.getName() for x in candidates)\n        raise ValueError('multiple comics found: %s' % comics)\n    elif not candidates:\n        raise ValueError('comic %r not found' % comic)\n    return candidates"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_scraperclasses():\n    global _scraperclasses\n    if _scraperclasses is None:\n        out.debug(u\"Loading comic modules...\")\n        modules = loader.get_modules('plugins')\n        plugins = loader.get_plugins(modules, Scraper)\n        _scraperclasses = list(plugins)\n        check_scrapers()\n        out.debug(u\"... %d modules loaded.\" % len(_scraperclasses))\n    return _scraperclasses", "response": "Find all comic scraper classes in the plugins directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_scrapers():\n    d = {}\n    for scraperclass in _scraperclasses:\n        name = scraperclass.getName().lower()\n        if name in d:\n            name1 = scraperclass.getName()\n            name2 = d[name].getName()\n            raise ValueError('duplicate scrapers %s and %s found' % (name1, name2))\n        d[name] = scraperclass", "response": "Check for duplicate scraper class names."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getComicStrip(self, url, data):\n        imageUrls = self.fetchUrls(url, data, self.imageSearch)\n        # map modifier function on image URLs\n        imageUrls = [self.imageUrlModifier(x, data) for x in imageUrls]\n        # remove duplicate URLs\n        imageUrls = set(imageUrls)\n        if len(imageUrls) > 1 and not self.multipleImagesPerStrip:\n            out.warn(u\"Found %d images instead of 1 at %s with expressions %s\" % (len(imageUrls), url, prettyMatcherList(self.imageSearch)))\n            image = sorted(imageUrls)[0]\n            out.warn(u\"Choosing image %s\" % image)\n            imageUrls = (image,)\n        elif not imageUrls:\n            out.warn(u\"Found no images at %s with expressions %s\" % (url, prettyMatcherList(self.imageSearch)))\n        if self.textSearch:\n            text = self.fetchText(url, data, self.textSearch, optional=self.textOptional)\n        else:\n            text = None\n        return ComicStrip(self.getName(), url, imageUrls, self.namer, self.session, text=text)", "response": "Get comic strip downloader for given URL and data."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets comic strips for a given URL.", "response": "def getStripsFor(self, url, maxstrips):\n        \"\"\"Get comic strips for an URL. If maxstrips is a positive number, stop after\n        retrieving the given number of strips.\"\"\"\n        self.hitFirstStripUrl = False\n        seen_urls = set()\n        while url:\n            out.info(u'Get strip URL %s' % url, level=1)\n            data = self.getPage(url)\n            if self.shouldSkipUrl(url, data):\n                out.info(u'Skipping URL %s' % url)\n                self.skippedUrls.add(url)\n            else:\n                try:\n                    yield self.getComicStrip(url, data)\n                except ValueError as msg:\n                    # image not found\n                    out.exception(msg)\n            if self.firstStripUrl == url:\n                out.debug(u\"Stop at first URL %s\" % url)\n                self.hitFirstStripUrl = True\n                break\n            if maxstrips is not None:\n                maxstrips -= 1\n                if maxstrips <= 0:\n                    break\n            prevUrl = self.getPrevUrl(url, data)\n            seen_urls.add(url)\n            if prevUrl in seen_urls:\n                # avoid recursive URL loops\n                out.warn(u\"Already seen previous URL %r\" % prevUrl)\n                break\n            url = prevUrl\n            if url:\n                # wait up to 2 seconds for next URL\n                time.sleep(1.0 + random.random())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef vote(cls):\n        url = configuration.VoteUrl + 'count/'\n        uid = get_system_uid()\n        data = {\"name\": cls.getName().replace('/', '_'), \"uid\": uid}\n        page = urlopen(url, cls.session, data=data)\n        return page.text", "response": "Cast a public vote for this comic."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget filename indicating all comics are downloaded.", "response": "def getCompleteFile(self, basepath):\n        \"\"\"Get filename indicating all comics are downloaded.\"\"\"\n        dirname = getDirname(self.getName())\n        return os.path.join(basepath, dirname, \"complete.txt\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset complete flag for this comic ie. all comics are downloaded here.", "response": "def setComplete(self, basepath):\n        \"\"\"Set complete flag for this comic, ie. all comics are downloaded.\"\"\"\n        if self.endOfLife:\n            filename = self.getCompleteFile(basepath)\n            if not os.path.exists(filename):\n                with open(filename, 'w') as f:\n                    f.write('All comics should be downloaded here.')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the language of the comic as a human - readable language name instead of a 2 - character ISO639 - 1 code.", "response": "def language(cls):\n        \"\"\"\n        Return language of the comic as a human-readable language name instead\n        of a 2-character ISO639-1 code.\n        \"\"\"\n        lang = 'Unknown (%s)' % cls.lang\n        if pycountry is None:\n            if cls.lang in languages.Languages:\n                lang = languages.Languages[cls.lang]\n        else:\n            try:\n                lang = pycountry.languages.get(alpha2 = cls.lang).name\n            except KeyError:\n                try:\n                    lang = pycountry.languages.get(iso639_1_code = cls.lang).name\n                except KeyError:\n                    pass\n        return lang"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsearching all entries for given URL pattern in a HTML page.", "response": "def fetchUrls(cls, url, data, urlSearch):\n        \"\"\"Search all entries for given URL pattern(s) in a HTML page.\"\"\"\n        searchUrls = []\n        searches = makeSequence(urlSearch)\n        for search in searches:\n            for match in search.finditer(data[0]):\n                searchUrl = match.group(1)\n                if not searchUrl:\n                    raise ValueError(\"Pattern %s matched empty URL at %s.\" % (search.pattern, url))\n                out.debug(u'matched URL %r with pattern %s' % (searchUrl, search.pattern))\n                searchUrls.append(normaliseURL(urljoin(data[1], searchUrl)))\n            if searchUrls:\n                # do not search other links if one pattern matched\n                break\n        if not searchUrls:\n            patterns = [x.pattern for x in searches]\n            raise ValueError(\"Patterns %s not found at URL %s.\" % (patterns, url))\n        return searchUrls"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fetchText(cls, url, data, textSearch, optional):\n        if textSearch:\n            match = textSearch.search(data[0])\n            if match:\n                text = match.group(1)\n                out.debug(u'matched text %r with pattern %s' % (text, textSearch.pattern))\n                return unescape(text).strip()\n            if optional:\n                return None\n            else:\n                raise ValueError(\"Pattern %s not found at URL %s.\" % (textSearch.pattern, url))\n        else:\n            return None", "response": "Search text entry for given text pattern in a HTML page."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fetchUrls(cls, url, data, urlSearch):\n        searchUrls = []\n        if cls.css:\n            searchFun = data.cssselect\n        else:\n            searchFun = data.xpath\n        searches = makeSequence(urlSearch)\n        for search in searches:\n            for match in searchFun(search):\n                try:\n                    for attrib in html_link_attrs:\n                        if attrib in match.attrib:\n                            searchUrls.append(match.get(attrib))\n                except AttributeError:\n                    searchUrls.append(str(match))\n            if not cls.multipleImagesPerStrip and searchUrls:\n                # do not search other links if one pattern matched\n                break\n        if not searchUrls:\n            raise ValueError(\"XPath %s not found at URL %s.\" % (searches, url))\n        return searchUrls", "response": "Search all entries for given XPath in a HTML page."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fetchText(cls, url, data, textSearch, optional):\n        if cls.css:\n            searchFun = data.cssselect\n        else:\n            searchFun = data.xpath\n        if textSearch:\n            text = ''\n            for match in searchFun(textSearch):\n                try:\n                    text += ' ' + match.text_content()\n                except AttributeError:\n                    text += ' ' + unicode(match)\n            if text.strip() == '':\n                if optional:\n                    return None\n                else:\n                    raise ValueError(\"XPath %s did not match anything at URL %s.\" % (textSearch, url))\n            out.debug(u'Matched text %r with XPath %s' % (text, textSearch))\n            return unescape(text).strip()\n        else:\n            return None", "response": "Search text entry for given text XPath in a HTML page."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run_main():\n\n    parser = argparse.ArgumentParser(\n            description=(\n                'AntiNex - '\n                'Get Token from Splunk'))\n    parser.add_argument(\n            '-u',\n            help='username',\n            required=False,\n            dest='user')\n    parser.add_argument(\n            '-p',\n            help='user password',\n            required=False,\n            dest='password')\n    parser.add_argument(\n            '-f',\n            help='splunk-ready request in a json file',\n            required=False,\n            dest='datafile')\n    parser.add_argument(\n            '-a',\n            help='host address: <fqdn:port>',\n            required=False,\n            dest='address')\n    parser.add_argument(\n            '-s',\n            help='silent',\n            required=False,\n            dest='silent',\n            action='store_true')\n    args = parser.parse_args()\n\n    user = ev(\n        'API_USER',\n        'user-not-set')\n    password = ev(\n        'API_PASSWORD',\n        'password-not-set')\n    address = ev(\n        'API_ADDRESS',\n        'localhost:8088')\n    admin_address = ev(\n        'API_ADDRESS',\n        'localhost:8089')\n    host = ev(\n        'API_HOST',\n        'localhost')\n    port = int(ev(\n        'API_PORT',\n        '8088'))\n    verbose = bool(str(ev(\n        'API_VERBOSE',\n        'true')).lower() == 'true')\n    datafile = None\n\n    if args.user:\n        user = args.user\n    if args.password:\n        password = args.password\n    if args.address:\n        address = args.address\n    if args.datafile:\n        datafile = args.datafile\n    if args.silent:\n        verbose = False\n\n    usage = ('Please run with -u <username> '\n             '-p <password> '\n             '-a <host address as: fqdn:port> ')\n\n    valid = True\n    if not user or user == 'user-not-set':\n        log.error('missing user')\n        valid = False\n    if not password or password == 'password-not-set':\n        log.error('missing password')\n        valid = False\n    if not valid:\n        log.error(usage)\n        sys.exit(1)\n\n    if verbose:\n        log.info((\n            'creating client user={} address={}').format(\n                user,\n                address))\n\n    last_msg = ''\n    host = ''\n    port = -1\n    try:\n        last_msg = (\n            'Invalid address={}').format(\n                address)\n        address_split = address.split(':')\n        last_msg = (\n            'Failed finding host in address={} '\n            '- please use: -a <fqdn:port>').format(\n                address)\n        host = address_split[0]\n        last_msg = (\n            'Failed finding integer port in address={} '\n            '- please use: -a <fqdn:port>').format(\n                address)\n        port = int(address_split[1])\n    except Exception as e:\n        log.error((\n            'Failed to parse -a {} for the '\n            'splunk host address: {} which threw an '\n            'ex={}').format(\n                address,\n                last_msg,\n                e))\n        sys.exit(1)\n    # end of try ex\n\n    if verbose:\n        log.info((\n            'connecting {}@{}:{}').format(\n                user,\n                host,\n                port))\n\n    req_body = None\n    if datafile:\n        if verbose:\n            log.info((\n                'loading request in datafile={}').format(\n                    datafile))\n\n        with open(datafile, 'r') as f:\n            req_body = json.loads(f.read())\n\n    servercontent = requests.post(\n        'https://{}/services/auth/login'.format(\n            admin_address),\n        headers={},\n        verify=False,\n        data={\n            'username': user,\n            'password': password\n        })\n    token = parseString(\n        servercontent.text).getElementsByTagName(\n            'sessionKey')[0].childNodes[0].nodeValue\n    log.info((\n        'user={} has token={}').format(\n            user,\n            token))\n\n    if verbose:\n        if req_body:\n            log.info('starting with req_body')\n        else:\n            log.info('starting')\n\n    if verbose:\n        log.info('done')", "response": "Main function for the get_splunk_service_token command."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning scaled image size in ( width height ) format.", "response": "def getDimensionForImage(filename, maxsize):\n    \"\"\"Return scaled image size in (width, height) format.\n    The scaling preserves the aspect ratio.\n    If PIL is not found returns None.\"\"\"\n    try:\n        from PIL import Image\n    except ImportError:\n        return None\n    img = Image.open(filename)\n    width, height = img.size\n    if width > maxsize[0] or height > maxsize[1]:\n        img.thumbnail(maxsize)\n        out.info(\"Downscaled display size from %s to %s\" % ((width, height), img.size))\n    return img.size"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd an event handler with given name.", "response": "def addHandler(name, basepath=None, baseurl=None, allowDownscale=False):\n    \"\"\"Add an event handler with given name.\"\"\"\n    if basepath is None:\n        basepath = '.'\n    _handlers.append(_handler_classes[name](basepath, baseurl, allowDownscale))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getBaseUrl(self):\n        '''Return a file: URL that probably points to the basedir.\n\n        This is used as a halfway sane default when the base URL is not\n        provided; not perfect, but should work in most cases.'''\n        components = util.splitpath(os.path.abspath(self.basepath))\n        url = '/'.join([url_quote(component, '') for component in components])\n        return 'file:///' + url + '/'", "response": "Return a file URL that probably points to the basedir."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconstructing URL from filename.", "response": "def getUrlFromFilename(self, filename):\n        \"\"\"Construct URL from filename.\"\"\"\n        components = util.splitpath(util.getRelativePath(self.basepath, filename))\n        url = '/'.join([url_quote(component, '') for component in components])\n        return self.baseurl + url"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef comicDownloaded(self, comic, filename, text=None):\n        imageUrl = self.getUrlFromFilename(filename)\n        size = None\n        if self.allowdownscale:\n            size = getDimensionForImage(filename, MaxImageSize)\n        title = '%s - %s' % (comic.name, os.path.basename(filename))\n        pageUrl = comic.referrer\n        description = '<img src=\"%s\"' % imageUrl\n        if size:\n            description += ' width=\"%d\" height=\"%d\"' % size\n        description += '/>'\n        if text:\n            description += '<br/>%s' % text\n        description += '<br/><a href=\"%s\">View Comic Online</a>' % pageUrl\n        args = (\n            title,\n            imageUrl,\n            description,\n            util.rfc822date(time.time())\n        )\n\n        if self.newfile:\n            self.newfile = False\n            self.rss.addItem(*args)\n        else:\n            self.rss.addItem(*args, append=False)", "response": "Write RSS entry for downloaded comic."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fnFromDate(self, date):\n        fn = time.strftime('comics-%Y%m%d', date)\n        fn = os.path.join(self.basepath, 'html', fn + \".html\")\n        fn = os.path.abspath(fn)\n        return fn", "response": "Get filename from date."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting HTML entry for downloaded comic.", "response": "def comicDownloaded(self, comic, filename, text=None):\n        \"\"\"Write HTML entry for downloaded comic.\"\"\"\n        if self.lastComic != comic.name:\n            self.newComic(comic)\n        size = None\n        if self.allowdownscale:\n            size = getDimensionForImage(filename, MaxImageSize)\n        imageUrl = self.getUrlFromFilename(filename)\n        pageUrl = comic.referrer\n        if pageUrl != self.lastUrl:\n            self.html.write(u'<li><a href=\"%s\">%s</a>\\n' % (pageUrl, pageUrl))\n        self.html.write(u'<br/><img src=\"%s\"' % imageUrl)\n        if size:\n            self.html.write(' width=\"%d\" height=\"%d\"' % size)\n        self.html.write('/>\\n')\n        if text:\n            self.html.write(u'<br/>%s\\n' % text)\n        self.lastComic = comic.name\n        self.lastUrl = pageUrl"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef newComic(self, comic):\n        if self.lastUrl is not None:\n            self.html.write(u'</li>\\n')\n        if self.lastComic is not None:\n            self.html.write(u'</ul>\\n')\n        self.html.write(u'<li>%s</li>\\n' % comic.name)\n        self.html.write(u'<ul>\\n')", "response": "Start new comic list in HTML."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the filename for the JSON file for a comic.", "response": "def jsonFn(self, comic):\n        \"\"\"Get filename for the JSON file for a comic.\"\"\"\n        fn = os.path.join(self.basepath, comic, 'dosage.json')\n        fn = os.path.abspath(fn)\n        return fn"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getComicData(self, comic):\n        if comic not in self.data:\n            if os.path.exists(self.jsonFn(comic)):\n                with codecs.open(self.jsonFn(comic), 'r', self.encoding) as f:\n                    self.data[comic] = json.load(f)\n            else:\n                self.data[comic] = {'pages':{}}\n        return self.data[comic]", "response": "Return dictionary with comic info."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns dictionary with comic page info.", "response": "def getPageInfo(self, comic, url):\n        \"\"\"Return dictionary with comic page info.\"\"\"\n        comicData = self.getComicData(comic)\n        if url not in comicData['pages']:\n            comicData['pages'][url] = {'images':{}}\n        return comicData['pages'][url]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef comicDownloaded(self, comic, filename, text=None):\n        pageInfo = self.getPageInfo(comic.name, comic.referrer)\n        pageInfo['images'][comic.url] = os.path.basename(filename)", "response": "Add URL - to - filename mapping into JSON."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef comicPageLink(self, comic, url, prevUrl):\n        pageInfo = self.getPageInfo(comic, url)\n        pageInfo['prev'] = prevUrl", "response": "Write previous link into JSON."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef end(self):\n        for comic in self.data:\n            with codecs.open(self.jsonFn(comic), 'w', self.encoding) as f:\n                json.dump(self.data[comic], f, indent=2, separators=(',', ': '), sort_keys=True)", "response": "Write all JSON data to files."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef comicDownloaded(self, comic, filename, text=None):\n        for handler in _handlers:\n            handler.comicDownloaded(comic, filename, text=text)", "response": "Emit comic downloaded events for all handlers."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nemits an event to inform the handler about links between comic pages. Should be overridden in subclass.", "response": "def comicPageLink(self, comic, url, prevUrl):\n        \"\"\"Emit an event to inform the handler about links between comic pages. Should be overridden in subclass.\"\"\"\n        for handler in _handlers:\n            handler.comicPageLink(comic, url, prevUrl)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef encode(*args):\n    \"Pack a series of arguments into a value Redis command\"\n    result = []\n    result.append(\"*\")\n    result.append(str(len(args)))\n    result.append(DELIMITER)\n    for arg in args:\n        result.append(\"$\")\n        result.append(str(len(arg)))\n        result.append(DELIMITER)\n        result.append(arg)\n        result.append(DELIMITER)\n    return \"\".join(result)", "response": "Pack a series of arguments into a value Redis command"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndo a SOAP request and return the result.", "response": "def request(self, name, content={}, namespace=None):\n        \"\"\" Do a SOAP request and returns the result.\n\n        Simple wrapper arround pythonzimbra functions\n        :param name: ex: 'Auth' for performing an 'AuthRequest'\n        :param content: a dict formatted pythonzimbra-style for request\n        :param namespace: (optional), the namespace, if different from the\n                          client's\n\n        :returns: a dict with response\n        \"\"\"\n        if not namespace:\n            namespace = self.NAMESPACE\n\n        req_name = name+'Request'\n        resp_name = name+'Response'\n        req = pythonzimbra.request_xml.RequestXml()\n        resp = pythonzimbra.response_xml.ResponseXml()\n\n        if self._session.is_logged_in():\n            req.set_auth_token(self._session.authToken)\n\n        req.add_request(req_name, content, namespace)\n        try:\n            self.com.send_request(req, resp)\n        except HTTPError as e:\n            if resp:\n                raise ZimbraSoapServerError(e.req, e.resp)\n            else:\n                raise\n\n        try:\n            resp_content = resp.get_response()\n            return resp_content[resp_name]\n        except KeyError:\n            if 'Fault' in resp_content:\n                raise ZimbraSoapServerError(req, resp)\n            raise ZimbraSoapUnexpectedResponse(\n                req, resp, 'Cannot find {} in response \"{}\"'.format(\n                    resp_name, resp.get_response()))\n\n        return resp_content"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef request_single(self, name, content={}):\n        resp = self.request(name, content)\n\n        # We stop on the first non-attribute (attributes are unicode/str)\n        # If it's a list, we only return the first one.\n\n        for i in resp.values():\n            if type(i) == list:\n                return i[0]\n            elif type(i) == dict:\n                return i\n\n        return None", "response": "Simple wrapper arround request to extract a single response from the server"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_logged_in_by(self, login, parent_zc, duration=0):\n        domain_name = zobjects.Account(name=login).get_domain()\n        preauth_key = parent_zc.get_domain(domain_name)['zimbraPreAuthKey']\n\n        rc = self.REST_PREAUTH(\n            self._server_host, parent_zc._server_port, preauth_key=preauth_key)\n\n        authToken = rc.get_preauth_token(login)\n\n        self.login_with_authToken(authToken)", "response": "Get logged in via preauth mechanism by login."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delegated_login(self, login, admin_zc, duration=0):\n        # a duration of zero is interpretted literaly by the API...\n        selector = zobjects.Account(name=login).to_selector()\n        delegate_args = {'account': selector}\n        if duration:\n            delegate_args['duration': duration]\n        resp = admin_zc.request('DelegateAuth', delegate_args)\n\n        lifetime = resp['lifetime']\n        authToken = resp['authToken']\n\n        self.login_account = login\n        self.login_with_authToken(authToken, lifetime)", "response": "Use another client to get logged in via delegated_auth mechanism by another client to get logged in via delegated_auth mechanism by another client"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_share_info(self, grantee_type=None, grantee_id=None,\n                       grantee_name=None, owner=None, owner_type='name'):\n        \"\"\"\n        :returns: list of dict representing shares informations\n        \"\"\"\n        params = {}\n        if grantee_type:\n            if 'grantee' not in params.keys():\n                params['grantee'] = {}\n            params['grantee'].update({'type': grantee_type})\n        if grantee_id:\n            if 'grantee' not in params.keys():\n                params['grantee'] = {}\n            params['grantee'].update({'id': grantee_id})\n        if grantee_name:\n            if 'grantee' not in params.keys():\n                params['grantee'] = {}\n            params['grantee'].update({'name': grantee_name})\n        if owner:\n            params['owner'] = {'by': owner_type, '_content': owner}\n\n        try:\n            resp = self.request('GetShareInfo', params)\n        # if user never logged in, no mailbox was created\n        except ZimbraSoapServerError as e:\n            if 'mailbox not found for account' in str(e):\n                return []\n            else:\n                raise e\n        if resp and isinstance(resp['share'], list):\n            return resp['share']\n        elif resp and isinstance(resp['share'], dict):\n            return [resp['share']]\n        else:\n            return []", "response": "Returns a list of dict representing shares informations"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a signature for a specific resource.", "response": "def create_signature(self, name, content, contenttype=\"text/html\"):\n        \"\"\"\n        :param:  name        verbose name of the signature\n        :param:  content     content of the signature, in html or plain-text\n        :param:  contenttype can be \"text/html\" (default) or \"text/plain\"\n        :returns: a zobjects.Signature object\n        \"\"\"\n        s = zobjects.Signature(name=name)\n        s.set_content(content, contenttype)\n\n        resp = self.request('CreateSignature', {'signature': s.to_creator()})\n        return zobjects.Signature.from_dict(resp['signature'])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting all signatures for the current user", "response": "def get_signatures(self):\n        \"\"\" Get all signatures for the current user\n\n        :returns: a list of zobjects.Signature\n        \"\"\"\n        signatures = self.request_list('GetSignatures')\n\n        return [zobjects.Signature.from_dict(i) for i in signatures]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nretrieving one signature discriminated by name or id or name.", "response": "def get_signature(self, signature):\n        \"\"\"Retrieve one signature, discriminated by name or id.\n\n        Note that signature name is not case sensitive.\n\n        :param: a zobjects.Signature describing the signature\n               like \"Signature(name='my-sig')\"\n\n        :returns: a zobjects.Signature object, filled with the signature if no\n                 signature is matching, returns None.\n        \"\"\"\n        resp = self.request_list('GetSignatures')\n\n        # GetSignature does not allow to filter the results, so we do it by\n        # hand...\n        if resp and (len(resp) > 0):\n            for sig_dict in resp:\n                sig = zobjects.Signature.from_dict(sig_dict)\n                if hasattr(signature, 'id'):\n                    its_this_one = (sig.id == signature.id)\n                elif hasattr(signature, 'name'):\n                    its_this_one = (sig.name.upper() == signature.name.upper())\n                else:\n                    raise ValueError('should mention one of id,name')\n                if its_this_one:\n                    return sig\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmodify an existing signature", "response": "def modify_signature(self, signature):\n        \"\"\" Modify an existing signature\n\n        Can modify the content, contenttype and name. An unset attribute will\n        not delete the attribute but leave it untouched.\n        :param: signature a zobject.Signature object, with modified\n                         content/contentype/name, the id should be present and\n                          valid, the name does not allows to identify the\n                         signature for that operation.\n        \"\"\"\n        # if no content is specified, just use a selector (id/name)\n        dic = signature.to_creator(for_modify=True)\n\n        self.request('ModifySignature', {'signature': dic})"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting all the preferences of the current user", "response": "def get_preferences(self):\n        \"\"\" Gets all the preferences of the current user\n\n        :returns: a dict presenting the preferences by name, values are\n                 typed to str/bool/int/float regarding their content.\n        \"\"\"\n        pref_list = self.request('GetPrefs')['pref']\n\n        out = {}\n        for pref in pref_list:\n            out[pref['name']] = utils.auto_type(pref['_content'])\n\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_preference(self, pref_name):\n        resp = self.request_single('GetPrefs', {'pref': {'name': pref_name}})\n        return utils.auto_type(resp['_content'])", "response": "Gets a single named preference."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate an Identity object", "response": "def create_identity(self, name, attrs=[]):\n        \"\"\" Create an Identity\n\n        :param: name identity name\n        :param: attrs list of dict of attributes (zimsoap format)\n        :returns: a zobjects.Identity object\n        \"\"\"\n        params = {\n            'name': name,\n            'a': attrs\n        }\n        resp = self.request('CreateIdentity', {'identity': params})\n        return zobjects.Identity.from_dict(resp['identity'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets identities matching name and attributes of the user.", "response": "def get_identities(self, identity=None, attrs=None):\n        \"\"\" Get identities matching name and attrs\n        of the user, as a list\n\n        :param: zobjects.Identity or identity name (string)\n        :param: attrs dict of attributes to return only identities matching\n        :returns: list of zobjects.Identity\n        \"\"\"\n        resp = self.request('GetIdentities')\n\n        if 'identity' in resp:\n            identities = resp['identity']\n            if type(identities) != list:\n                identities = [identities]\n\n            if identity or attrs:\n                wanted_identities = []\n\n                for u_identity in [\n                        zobjects.Identity.from_dict(i) for i in identities]:\n                    if identity:\n                        if isinstance(identity, zobjects.Identity):\n                            if u_identity.name == identity.name:\n                                return [u_identity]\n                        else:\n                            if u_identity.name == identity:\n                                return [u_identity]\n\n                    elif attrs:\n                        for attr, value in attrs.items():\n                            if (attr in u_identity._a_tags and\n                                    u_identity._a_tags[attr] == value):\n                                wanted_identities.append(u_identity)\n                return wanted_identities\n            else:\n                return [zobjects.Identity.from_dict(i) for i in identities]\n        else:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmodifies some attributes of an identity or its name.", "response": "def modify_identity(self, identity, **kwargs):\n        \"\"\" Modify some attributes of an identity or its name.\n\n        :param: identity a zobjects.Identity with `id` set (mandatory). Also\n               set items you want to modify/set and/or the `name` attribute to\n               rename the identity.\n               Can also take the name in string and then attributes to modify\n        :returns: zobjects.Identity object\n        \"\"\"\n\n        if isinstance(identity, zobjects.Identity):\n            self.request('ModifyIdentity', {'identity': identity._full_data})\n            return self.get_identities(identity=identity.name)[0]\n        else:\n            attrs = []\n            for attr, value in kwargs.items():\n                attrs.append({\n                    'name': attr,\n                    '_content': value\n                })\n            self.request('ModifyIdentity', {\n                'identity': {\n                    'name': identity,\n                    'a': attrs\n                }\n            })\n            return self.get_identities(identity=identity)[0]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete_identity(self, identity):\n        if isinstance(identity, zobjects.Identity):\n            self.request(\n                'DeleteIdentity', {'identity': identity.to_selector()})\n        else:\n            self.request('DeleteIdentity', {'identity': {'name': identity}})", "response": "Delete an identity from its name or id or id"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_or_fetch_id(self, zobj, fetch_func):\n\n        try:\n            return zobj.id\n        except AttributeError:\n            try:\n                return fetch_func(zobj).id\n            except AttributeError:\n                raise ValueError('Unqualified Resource')", "response": "Returns the ID of a Zobject wether it s already known or not."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_calendar_resource(self, cal_resource):\n        selector = cal_resource.to_selector()\n        resp = self.request_single('GetCalendarResource',\n                                   {'calresource': selector})\n        return zobjects.CalendarResource.from_dict(resp)", "response": "Fetches an calendar resource with all its attributes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new calendar resource.", "response": "def create_calendar_resource(self, name, password=None, attrs={}):\n        \"\"\"\n        :param: attrs a dict of attributes, must specify the displayName and\n                     zimbraCalResType\n        \"\"\"\n        args = {\n            'name': name,\n            'a': [{'n': k, '_content': v} for k, v in attrs.items()]\n            }\n        if password:\n            args['password'] = password\n        resp = self.request_single('CreateCalendarResource', args)\n        return zobjects.CalendarResource.from_dict(resp)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef modify_calendar_resource(self, calres, attrs):\n        attrs = [{'n': k, '_content': v} for k, v in attrs.items()]\n        self.request('ModifyCalendarResource', {\n            'id': self._get_or_fetch_id(\n                calres, self.get_calendar_resource),\n            'a': attrs\n        })", "response": "Modify a calendar resource."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrename a calendar resource.", "response": "def rename_calendar_resource(self, r_description, new_r_name):\n        \"\"\"\n        :param r_description : a CalendarResource specifying either :\n                   - id:   the ressource ID\n                   - r_description: the name of the ressource\n        :param new_r_name: new name of the list\n        :return: a zobjects.CalendarResource\n        \"\"\"\n        resp = self.request('RenameCalendarResource', {\n            'id': self._get_or_fetch_id(r_description,\n                                        self.get_calendar_resource),\n            'newName': new_r_name\n        })\n\n        return zobjects.CalendarResource.from_dict(resp['calresource'])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget global stats about mailboxes", "response": "def get_mailbox_stats(self):\n        \"\"\" Get global stats about mailboxes\n\n        Parses <stats numMboxes=\"6\" totalSize=\"141077\"/>\n\n        :returns: dict with stats\n        \"\"\"\n        resp = self.request_single('GetMailboxStats')\n        ret = {}\n        for k, v in resp.items():\n            ret[k] = int(v)\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef count_account(self, domain):\n        selector = domain.to_selector()\n        cos_list = self.request_list('CountAccount', {'domain': selector})\n        ret = []\n\n        for i in cos_list:\n            count = int(i['_content'])\n            ret.append((zobjects.ClassOfService.from_dict(i),  count))\n\n        return list(ret)", "response": "Count the number of accounts for a given domain sorted by cos\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a Mailbox corresponding to an account.", "response": "def get_account_mailbox(self, account_id):\n        \"\"\" Returns a Mailbox corresponding to an account. Usefull to get the\n        size (attribute 's'), and the mailbox ID, returns nothing appart from\n        that.\n        \"\"\"\n        selector = zobjects.Mailbox(id=account_id).to_selector()\n        resp = self.request_single('GetMailbox', {'mbox': selector})\n\n        return zobjects.Mailbox.from_dict(resp)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_account_cos(self, account):\n        resp = self.request(\n            'GetAccountInfo', {'account': account.to_selector()})\n        return zobjects.COS.from_dict(resp['cos'])", "response": "Fetch the cos for a given account"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new domain with the given name.", "response": "def create_domain(self, name):\n        \"\"\"\n        :param name: A string, NOT a zObject\n        :return: a zobjects.Domain\n        \"\"\"\n        args = {'name': name}\n        resp = self.request_single('CreateDomain', args)\n\n        return zobjects.Domain.from_dict(resp)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmodifying the attributes of a domain.", "response": "def modify_domain(self, domain, attrs):\n        \"\"\"\n        :type domain: a zobjects.Domain\n        :param attrs: attributes to modify\n        :type attrs dict\n        \"\"\"\n        attrs = [{'n': k, '_content': v} for k, v in attrs.items()]\n        self.request('ModifyDomain', {\n            'id': self._get_or_fetch_id(domain, self.get_domain),\n            'a': attrs\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_distribution_list_alias(self, distribution_list, alias):\n        self.request('AddDistributionListAlias', {\n            'id': self._get_or_fetch_id(\n                distribution_list, self.get_distribution_list\n                ),\n            'alias': alias,\n        })", "response": "Adds an alias to a distribution list"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves an alias from a distribution list", "response": "def remove_distribution_list_alias(self, distribution_list, alias):\n        \"\"\"\n        :param distribution_list:  an distribution list object to be used as\n        a selector\n        :param alias:     email alias address\n        :returns:         None (the API itself returns nothing)\n        \"\"\"\n        self.request('RemoveDistributionListAlias', {\n            'id': self._get_or_fetch_id(\n                distribution_list, self.get_distribution_list\n            ),\n            'alias': alias,\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_distribution_list(self, dl_description):\n        selector = dl_description.to_selector()\n\n        resp = self.request_single('GetDistributionList', {'dl': selector})\n        dl = zobjects.DistributionList.from_dict(resp)\n        return dl", "response": "returns a DistributionList object"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef modify_distribution_list(self, dl_description, attrs):\n        attrs = [{'n': k, '_content': v} for k, v in attrs.items()]\n        self.request('ModifyDistributionList', {\n            'id': self._get_or_fetch_id(dl_description,\n                                        self.get_distribution_list),\n            'a': attrs\n        })", "response": "Modify the attributes of a DistributionList"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_distribution_list_member(self, distribution_list, members):\n        members = [{'_content': v} for v in members]\n        resp = self.request_single('AddDistributionListMember', {\n            'id': self._get_or_fetch_id(distribution_list,\n                                        self.get_distribution_list),\n            'dlm': members\n        })\n        return resp", "response": "Adds members to the distribution list"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfetches an account with all its attributes.", "response": "def get_account(self, account):\n        \"\"\" Fetches an account with all its attributes.\n\n        :param account: an account object, with either id or name attribute set\n        :returns: a zobjects.Account object, filled.\n        \"\"\"\n        selector = account.to_selector()\n        resp = self.request_single('GetAccount', {'account': selector})\n        return zobjects.Account.from_dict(resp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rename_account(self, account, new_name):\n        self.request('RenameAccount', {\n            'id': self._get_or_fetch_id(account, self.get_account),\n            'newName': new_name\n        })", "response": "Rename an account.\n\n        :param account: a zobjects.Account\n        :param new_name: a string of new account name"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmodify the attributes of an account", "response": "def modify_account(self, account, attrs):\n        \"\"\"\n        :param account: a zobjects.Account\n        :param attrs  : a dictionary of attributes to set ({key:value,...})\n        \"\"\"\n        attrs = [{'n': k, '_content': v} for k, v in attrs.items()]\n        self.request('ModifyAccount', {\n            'id': self._get_or_fetch_id(account, self.get_account),\n            'a': attrs\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a new account and returns the created object", "response": "def create_account(self, email, password=None, attrs={}):\n        \"\"\"\n        :param email:    Full email with domain eg: login@domain.com\n        :param password: Password for local auth\n        :param attrs:    a dictionary of attributes to set ({key:value,...})\n        :returns:        the created zobjects.Account\n        \"\"\"\n        attrs = [{'n': k, '_content': v} for k, v in attrs.items()]\n\n        params = {'name': email, 'a': attrs}\n\n        if password:\n            params['password'] = password\n\n        resp = self.request_single('CreateAccount', params)\n\n        return zobjects.Account.from_dict(resp)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting an account from the database", "response": "def delete_account(self, account):\n        \"\"\"\n        :param account: an account object to be used as a selector\n        \"\"\"\n        self.request('DeleteAccount', {\n            'id': self._get_or_fetch_id(account, self.get_account),\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd an alias to an account", "response": "def add_account_alias(self, account, alias):\n        \"\"\"\n        :param account:  an account object to be used as a selector\n        :param alias:     email alias address\n        :returns:         None (the API itself returns nothing)\n        \"\"\"\n        self.request('AddAccountAlias', {\n            'id': self._get_or_fetch_id(account, self.get_account),\n            'alias': alias,\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove an alias from an account", "response": "def remove_account_alias(self, account, alias):\n        \"\"\"\n        :param account:  an account object to be used as a selector\n        :param alias:     email alias address\n        :returns:         None (the API itself returns nothing)\n        \"\"\"\n        self.request('RemoveAccountAlias', {\n            'id': self._get_or_fetch_id(account, self.get_account),\n            'alias': alias,\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mk_auth_token(self, account, admin=False, duration=0):\n        domain = account.get_domain()\n        try:\n            preauth_key = self.get_domain(domain)['zimbraPreAuthKey']\n        except KeyError:\n            raise DomainHasNoPreAuthKey(domain)\n        timestamp = int(time.time())*1000\n        expires = duration*1000\n        return utils.build_preauth_str(preauth_key, account.name, timestamp,\n                                       expires, admin)", "response": "Builds an authentification token using preauth mechanism."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a new ZimbraAccountClient instance with the provided account logged with the provided account.", "response": "def delegate_auth(self, account):\n        \"\"\" Uses the DelegateAuthRequest to provide a ZimbraAccountClient\n        already logged with the provided account.\n\n        It's the mechanism used with the \"view email\" button in admin console.\n        \"\"\"\n        warnings.warn(\"delegate_auth() on parent client is deprecated,\"\n                      \" use delegated_login() on child client instead\",\n                      DeprecationWarning)\n        selector = account.to_selector()\n        resp = self.request('DelegateAuth', {'account': selector})\n\n        lifetime = resp['lifetime']\n        authToken = resp['authToken']\n\n        zc = ZimbraAccountClient(self._server_host)\n        zc.login_with_authToken(authToken, lifetime)\n        return zc"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_account_authToken(self, account=None, account_name=''):\n        if account is None:\n            account = self.get_account(zobjects.Account(name=account_name))\n        selector = account.to_selector()\n\n        resp = self.request('DelegateAuth', {'account': selector})\n\n        authToken = resp['authToken']\n        lifetime = int(resp['lifetime'])\n\n        return authToken, lifetime", "response": "Use the DelegateAuthRequest to provide a token and his lifetime for the account."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef search_directory(self, **kwargs):\n\n        search_response = self.request('SearchDirectory', kwargs)\n\n        result = {}\n        items = {\n            \"account\": zobjects.Account.from_dict,\n            \"domain\": zobjects.Domain.from_dict,\n            \"dl\": zobjects.DistributionList.from_dict,\n            \"cos\": zobjects.COS.from_dict,\n            \"calresource\": zobjects.CalendarResource.from_dict\n            # \"alias\": TODO,\n        }\n\n        for obj_type, func in items.items():\n            if obj_type in search_response:\n                if isinstance(search_response[obj_type], list):\n                    result[obj_type] = [\n                        func(v) for v in search_response[obj_type]]\n                else:\n                    result[obj_type] = func(search_response[obj_type])\n        return result", "response": "Search the LDAP directory for the entry in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _return_comma_list(self, l):\n        if isinstance(l, (text_type, int)):\n            return l\n\n        if not isinstance(l, list):\n            raise TypeError(l, ' should be a list of integers, \\\nnot {0}'.format(type(l)))\n\n        str_ids = ','.join(str(i) for i in l)\n\n        return str_ids", "response": "get a list and return a string with comma separated list values\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_permissions(self, rights=[]):\n        aces = []\n        if rights:\n            for right in rights:\n                ace = self.request(\n                    'GetPermission',\n                    {'ace': {\n                        'right': {'_content': right}}})\n\n                if 'ace' in ace.keys() and isinstance(ace, list):\n                    aces.extend(ace['ace'])\n                elif 'ace' in ace.keys() and isinstance(ace, dict):\n                    aces.append(ace['ace'])\n            return {'ace': aces}\n\n        else:\n            ace = self.request('GetPermission', {})\n            if 'ace' in ace.keys() and isinstance(ace['ace'], list):\n                return ace\n            elif 'ace' in ace.keys() and isinstance(ace['ace'], dict):\n                return ace\n            else:\n                return {'ace': []}", "response": "Get permissions for a specific resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_task(self, subject, desc):\n        task = zobjects.Task()\n        task_creator = task.to_creator(subject, desc)\n        resp = self.request('CreateTask', task_creator)\n        task_id = resp['calItemId']\n        return task_id", "response": "Create a task in the cluster"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_task(self, task_id):\n        task = self.request_single('GetTask', {'id': task_id})\n\n        if task:\n            return zobjects.Task.from_dict(task)\n        else:\n            return None", "response": "Retrieve one task discriminated by id."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new contact in the specified folder.", "response": "def create_contact(self, attrs, members=None, folder_id=None, tags=None):\n        \"\"\"Create a contact\n\n        Does not include VCARD nor group membership yet\n\n        XML example :\n        <cn l=\"7> ## ContactSpec\n            <a n=\"lastName\">MARTIN</a>\n            <a n=\"firstName\">Pierre</a>\n            <a n=\"email\">pmartin@example.com</a>\n        </cn>\n        Which would be in zimsoap : attrs = { 'lastname': 'MARTIN',\n                                        'firstname': 'Pierre',\n                                        'email': 'pmartin@example.com' }\n                                    folder_id = 7\n\n        :param folder_id: a string of the ID's folder where to create\n        contact. Default '7'\n        :param tags:     comma-separated list of tag names\n        :param attrs:   a dictionary of attributes to set ({key:value,...}). At\n        least one attr is required\n        :returns:       the created zobjects.Contact\n        \"\"\"\n        cn = {}\n        if folder_id:\n            cn['l'] = str(folder_id)\n        if tags:\n            tags = self._return_comma_list(tags)\n            cn['tn'] = tags\n        if members:\n            cn['m'] = members\n\n        attrs = [{'n': k, '_content': v} for k, v in attrs.items()]\n        cn['a'] = attrs\n        resp = self.request_single('CreateContact', {'cn': cn})\n\n        return zobjects.Contact.from_dict(resp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets all contacts for the current user", "response": "def get_contacts(self, ids=None, **kwargs):\n        \"\"\" Get all contacts for the current user\n\n        :param l: string of a folder id\n        :param ids: An coma separated list of contact's ID to look for\n\n        :returns: a list of zobjects.Contact\n        \"\"\"\n        params = {}\n        if ids:\n            ids = self._return_comma_list(ids)\n            params['cn'] = {'id': ids}\n\n        for key, value in kwargs.items():\n            if key in ['a', 'ma']:\n                params[key] = {'n': value}\n            else:\n                params[key] = value\n\n        contacts = self.request_list('GetContacts', params)\n\n        return [zobjects.Contact.from_dict(i) for i in contacts]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_contacts(self, ids):\n\n        str_ids = self._return_comma_list(ids)\n        self.request('ContactAction', {'action': {'op': 'delete',\n                                                  'id': str_ids}})", "response": "Delete contacts for the current user"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_group(self, attrs, members, folder_id=None, tags=None):\n        cn = {}\n        cn['m'] = members\n\n        if folder_id:\n            cn['l'] = str(folder_id)\n        if tags:\n            cn['tn'] = tags\n\n        attrs = [{'n': k, '_content': v} for k, v in attrs.items()]\n        attrs.append({'n': 'type', '_content': 'group'})\n        cn['a'] = attrs\n        resp = self.request_single('CreateContact', {'cn': cn})\n\n        return zobjects.Contact.from_dict(resp)", "response": "Create a group of contacts."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete_folders(self, paths=None, folder_ids=None, f_type='folder'):\n        if folder_ids:\n            f_ids = folder_ids\n        elif paths:\n            f_ids = []\n            for path in paths:\n                folder = self.get_folder(path=path)\n                f_ids.append(folder[f_type]['id'])\n\n        comma_ids = self._return_comma_list(f_ids)\n\n        params = {'action': {\n            'id': comma_ids,\n            'op': 'delete'\n        }}\n\n        self.request('FolderAction', params)", "response": "Delete all folders in the specified list of paths."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting all the mountpoints in the current directory.", "response": "def delete_mountpoints(self, paths=None, folder_ids=None):\n        \"\"\"\n        :param folder_ids: list of ids\n        :param path: list of folder's paths\n        \"\"\"\n        self.delete_folders(paths=paths, folder_ids=folder_ids, f_type='link')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef modify_folder_grant(\n        self,\n        folder_ids,\n        perm,\n        zid=None,\n        grantee_name=None,\n        gt='usr',\n        flags=None\n    ):\n        \"\"\"\n        :param folder_ids: list of ids\n        :param perm: permission to grant to the user on folder(s)\n        :param zid: id of user to grant rights\n        :param grantee_name: email address of user to grant rights\n        :param flags: folder's flags\n        \"\"\"\n        f_ids = self._return_comma_list(folder_ids)\n\n        params = {'action': {\n            'id': f_ids,\n            'op': 'grant',\n            'grant': {'perm': perm, 'gt': gt}\n        }}\n\n        if perm == 'none':\n            params['action']['op'] = '!grant'\n            params['action']['zid'] = zid\n            # Remove key to raise Zimsoap exception if no zid provided\n            if not zid:\n                params['action'].pop('zid', None)\n\n        if grantee_name:\n            params['action']['grant']['d'] = grantee_name\n        elif zid:\n            params['action']['grant']['zid'] = zid\n        else:\n            raise TypeError('missing zid or grantee_name')\n\n        self.request('FolderAction', params)", "response": "Modify the permissions of a set of folders and rights to the user on the folder."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef modify_folders(\n        self, folder_ids, color=None, flags=None, parent_folder=None,\n        name=None, num_days=None, rgb=None, tags=None, view=None\n    ):\n        \"\"\"\n        :param folder_ids: list of ids\n        :param color: color numeric; range 0-127; defaults to 0 if not present;\n        client can display only 0-7\n        :param flags: flags\n        :param parent_folder: id of new location folder\n        :param name: new name for the folder\n        :param tags: list of tag names\n        :param view: list of tag view\n        \"\"\"\n        f_ids = self._return_comma_list(folder_ids)\n\n        params = {'action': {\n            'id': f_ids,\n            'op': 'update',\n        }}\n\n        if color:\n            params['action']['color'] = color\n        if flags:\n            params['action']['f'] = flags\n        if parent_folder:\n            params['action']['l'] = parent_folder\n        if name:\n            params['action']['name'] = name\n        if tags:\n            tn = self._return_comma_list(tags)\n            params['action']['tn'] = tn\n        if view:\n            params['action']['view'] = view\n\n        self.request('FolderAction', params)", "response": "This method is used to modify a list of folders in a specific folder."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete_conversations(self, ids):\n\n        str_ids = self._return_comma_list(ids)\n        self.request('ConvAction', {'action': {'op': 'delete',\n                                               'id': str_ids\n                                               }})", "response": "Delete conversations with the given ids"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmoving selected conversations to another folder", "response": "def move_conversations(self, ids, folder):\n        \"\"\" Move selected conversations to an other folder\n\n        :params ids: list of ids\n        :params folder: folder id\n        \"\"\"\n\n        str_ids = self._return_comma_list(ids)\n        self.request('ConvAction', {'action': {'op': 'move',\n                                               'id': str_ids,\n                                               'l': str(folder)}})"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a message to the cache", "response": "def add_message(self, msg_content, folder, **kwargs):\n        \"\"\" Inject a message\n\n        :params string msg_content: The entire message's content.\n        :params string folder: Folder pathname (starts with '/') or folder ID\n        \"\"\"\n        content = {'m': kwargs}\n        content['m']['l'] = str(folder)\n        content['m']['content'] = {'_content': msg_content}\n\n        return self.request('AddMsg', content)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef move_messages(self, ids, folder_id):\n        str_ids = self._return_comma_list(ids)\n        params = {'action': {\n            'id': str_ids,\n            'op': 'move',\n            'l': folder_id\n        }}\n\n        self.request('MsgAction', params)", "response": "Move selected messages to another folder"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the flags of the messages in the log.", "response": "def update_messages_flag(self, ids, flag):\n        \"\"\"\n        List of flags :\n        u -> unread                 f -> flagged\n        a -> has attachment         s -> sent by me\n        r -> replied                w -> forwarded\n        d -> draft                  x -> deleted\n        n -> notification sent\n\n        by default a message priority is \"normal\" otherwise:\n        ! -> priority high          ? -> priority low\n        \"\"\"\n        str_ids = self._return_comma_list(ids)\n        params = {'action': {\n            'id': str_ids,\n            'op': 'update',\n            'f': flag\n        }}\n\n        self.request('MsgAction', params)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting selected messages for the current user", "response": "def delete_messages(self, ids):\n        \"\"\" Delete selected messages for the current user\n\n        :param ids: list of ids\n        \"\"\"\n        str_ids = self._return_comma_list(ids)\n        return self.request('MsgAction', {'action': {'op': 'delete',\n                                                     'id': str_ids}})"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsearching object in account AttributeNames", "response": "def search(self, query, **kwargs):\n        \"\"\" Search object in account\n\n        :returns: a dic where value c contains the list of results (if there\n        is any). Example : {\n            'more': '0',\n            'offset': '0',\n            'sortBy': 'dateDesc',\n            'c': [\n                {\n                    'id': '-261',\n                    'm': {'id': '261',\n                          's': '2556',\n                          'l': '2'},\n                    'u': '0', 'd': '1450714720000',\n                    'sf': '1450714720000',\n                    'e': {'t': 'f',\n                          'd': 'kokopu',\n                          'a': 'kokopu@zimbratest3.example.com'},\n                    'n': '1',\n                    'fr': {'_content': 'Hello there !'},\n                    'su': {'_content': 'The subject is cool'}\n                }\n            ]\n        \"\"\"\n\n        content = kwargs\n        content['query'] = {'_content': query}\n\n        return self.request('Search', content)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_data_source(self, data_source, dest_folder):\n        folder = self.create_folder(dest_folder)\n        for type_source, source_config in data_source.items():\n            data_source[type_source]['l'] = folder['id']\n        return self.request('CreateDataSource', data_source)", "response": "Create a data source from a dict."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete_data_source(self, data_source):\n        source_type = [k for k in data_source.keys()][0]\n        complete_source = self.get_data_sources(\n            source_id=data_source[source_type]['id'])\n        folder_id = complete_source[source_type][0]['l']\n        self.delete_folders(folder_ids=[folder_id])\n        return self.request('DeleteDataSource', data_source)", "response": "Delete a data source."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a filter rule to the list of user s filter rules.", "response": "def add_filter_rule(\n            self, name, condition, filters, actions, active=1, way='in'):\n        \"\"\"\n        :param: name filter name\n        :param: condition allof or anyof\n        :param: filters dict of filters\n        :param: actions dict of actions\n        :param: way string discribing if filter is for 'in' or 'out' messages\n        :returns: list of user's zobjects.FilterRule\n        \"\"\"\n\n        filters['condition'] = condition\n\n        new_rule = {\n            'name': name,\n            'active': active,\n            'filterTests': filters,\n            'filterActions': actions\n        }\n\n        new_rules = [zobjects.FilterRule.from_dict(new_rule)]\n\n        prev_rules = self.get_filter_rules(way=way)\n\n        # if there is already some rules\n        if prev_rules:\n            for rule in prev_rules:\n                # don't add rule if it already exist\n                if rule.name == new_rules[0].name:\n                    raise ZimSOAPException(\n                        'filter %s already exists' % rule.name)\n            new_rules = new_rules + prev_rules\n\n        content = {\n            'filterRules': {\n                'filterRule': [r._full_data for r in new_rules]\n            }\n        }\n        if way == 'in':\n            self.request('ModifyFilterRules', content)\n        elif way == 'out':\n            self.request('ModifyOutgoingFilterRules', content)\n        return new_rules"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the filter rule for the given filter", "response": "def get_filter_rule(self, _filter, way='in'):\n        \"\"\" Return the filter rule\n\n        :param: _filter a zobjects.FilterRule or the filter name\n        :param: way string discribing if filter is for 'in' or 'out' messages\n        :returns: a zobjects.FilterRule\"\"\"\n        if isinstance(_filter, zobjects.FilterRule):\n            _filter = _filter.name\n        for f in self.get_filter_rules(way=way):\n            if f.name == _filter:\n                return f\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_filter_rules(self, way='in'):\n        try:\n            if way == 'in':\n                filters = self.request(\n                    'GetFilterRules')['filterRules']['filterRule']\n            elif way == 'out':\n                filters = self.request(\n                    'GetOutgoingFilterRules')['filterRules']['filterRule']\n\n            # Zimbra return a dict if there is only one instance\n            if isinstance(filters, dict):\n                filters = [filters]\n\n            return [zobjects.FilterRule.from_dict(f) for f in filters]\n        except KeyError:\n            return []", "response": "returns a list of zobjects. FilterRule objects for the current session"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\napplies a filter rule to the list of impacted messages.", "response": "def apply_filter_rule(self, _filter, query='in:inbox', way='in'):\n        \"\"\"\n        :param: _filter _filter a zobjects.FilterRule or the filter name\n        :param: query on what will the filter be applied\n        :param: way string discribing if filter is for 'in' or 'out' messages\n        :returns: list of impacted message's ids\n        \"\"\"\n        if isinstance(_filter, zobjects.FilterRule):\n            _filter = _filter.name\n\n        content = {\n            'filterRules': {\n                'filterRule': {'name': _filter}\n                },\n            'query': {'_content': query}\n        }\n        if way == 'in':\n            ids = self.request('ApplyFilterRules', content)\n        elif way == 'out':\n            ids = self.request('ApplyOutgoingFilterRules', content)\n\n        if ids:\n            return [int(m) for m in ids['m']['ids'].split(',')]\n        else:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_filter_rule(self, _filter, way='in'):\n        updated_rules = []\n        rules = self.get_filter_rules(way=way)\n\n        if isinstance(_filter, zobjects.FilterRule):\n            _filter = _filter.name\n\n        if rules:\n            for rule in rules:\n                if not rule.name == _filter:\n                    updated_rules.append(rule)\n\n        if rules != updated_rules:\n            content = {\n                'filterRules': {\n                    'filterRule': [f._full_data for f in updated_rules]\n                }\n            }\n            if way == 'in':\n                self.request('ModifyFilterRules', content)\n            elif way == 'out':\n                self.request('ModifyOutgoingFilterRules', content)\n\n        return updated_rules", "response": "delete a filter rule"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes and store an absolute end_date session according to the lifetime of the session", "response": "def set_end_date(self, lifetime):\n        \"\"\"Computes and store an absolute end_date session according to the\n        lifetime of the session\"\"\"\n        self.end_date = (datetime.datetime.now() +\n                         datetime.timedelta(0, lifetime))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef login(self, username, password, namespace=None):\n\n        if namespace is None:\n            namespace = self.client.NAMESPACE\n\n        data = self.client.request(\n            'Auth',\n            {\n                'account': zobjects.Account(name=username).to_selector(),\n                'password': {'_content': password}\n            },\n            namespace)\n        self.authToken = data['authToken']\n        lifetime = int(data['lifetime'])\n\n        self.authToken = str(self.authToken)\n        self.set_end_date(lifetime)", "response": "Performs the login against zimbra\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef search_extension(self, limit=100, offset=0, **kw):\n\n        response = self.request(E.searchExtensionRequest(\n            E.limit(limit),\n            E.offset(offset),\n            E.withDescription(int(kw.get('with_description', 0))),\n            E.withPrice(int(kw.get('with_price', 0))),\n            E.withUsageCount(int(kw.get('with_usage_count', 0))),\n        ))\n        return response.as_models(Extension)", "response": "Search the list of available extensions."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef retrieve_extension(self, name, **kw):\n\n        response = self.request(E.retrieveExtensionRequest(\n            E.name(name),\n            E.withDescription(int(kw.get('with_description', 0))),\n            E.withPrice(int(kw.get('with_price', 0))),\n            E.withUsageCount(int(kw.get('with_usage_count', 0))),\n        ))\n\n        return response.as_model(Extension)", "response": "Retrieve details on a single extension."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrotating topmost three items once to the left.", "response": "def rot(vm):\n    \"\"\"Rotate topmost three items once to the left. ( a b c -- b c a )\"\"\"\n    c = vm.pop()\n    b = vm.pop()\n    a = vm.pop()\n    vm.push(b)\n    vm.push(c)\n    vm.push(a)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlooks up the name of a given instruction.", "response": "def lookup(instruction, instructions = None):\n    \"\"\"Looks up instruction, which can either be a function or a string.\n    If it's a string, returns the corresponding method.\n    If it's a function, returns the corresponding name.\n    \"\"\"\n    if instructions is None:\n        instructions = default_instructions\n\n    if isinstance(instruction, str):\n        return instructions[instruction]\n    elif hasattr(instruction, \"__call__\"):\n        rev = dict(((v,k) for (k,v) in instructions.items()))\n        return rev[instruction]\n    else:\n        raise errors.MachineError(KeyError(\"Unknown instruction: %s\" %\n            str(instruction)))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef retrieve(self):\n        response = self.request(E.retrieveResellerRequest())\n        return Reseller(response.data)", "response": "Retrieve contact information on ourselves."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngive a URL and a key / val pair remove an item from the query parameter list of the URL and return the new URL.", "response": "def remove_query_param(url, key):\n    \"\"\"\n    Given a URL and a key/val pair, remove an item in the query\n    parameters of the URL, and return the new URL.\n    \"\"\"\n\n    (scheme, netloc, path, query, fragment) = urlparse.urlsplit(url)\n    query_dict = urlparse.parse_qs(query)\n    query_dict.pop(key, None)\n    query = urlparse.urlencode(sorted(list(query_dict.items())), doseq=True)\n    return urlparse.urlunsplit((scheme, netloc, path, query, fragment))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if comic name already exists.", "response": "def has_comic(name):\n    \"\"\"Check if comic name already exists.\"\"\"\n    names = [\n        (\"Creators/%s\" % name).lower(),\n        (\"DrunkDuck/%s\" % name).lower(),\n        (\"GoComics/%s\" % name).lower(),\n        (\"KeenSpot/%s\" % name).lower(),\n        (\"ComicGenesis/%s\" % name).lower(),\n        (\"SmackJeeves/%s\" % name).lower(),\n    ]\n    for scraperclass in get_scraperclasses():\n        lname = scraperclass.getName().lower()\n        if lname in names or lname == name.lower():\n            return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef print_results(args):\n    min_comics, filename = args\n    with codecs.open(filename, 'a', 'utf-8') as fp:\n        for name, shortname in sorted(load_result(json_file).items()):\n            if name in exclude_comics:\n                continue\n            if has_comic(name):\n                prefix = u'#'\n            else:\n                prefix = u''\n            fp.write(u\"%sadd(%r, %r)\\n\" % (prefix, str(truncate_name(name)),\n              str(shortname)))", "response": "Print all comics that have at least the given number of minimum comic strips."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_session_key(\n        user,\n        password,\n        url='https://localhost:8089',\n        verify=False,\n        ssl_options=None):\n    \"\"\"get_session_key\n\n    This will get a user session key and throw for any errors\n\n    :param user: username\n    :param password: password\n    :param url: splunk auth url\n    :param verify: verify cert\n    :param ssl_options: ssl options dictionary\n\n    \"\"\"\n    servercontent = requests.post(\n        '{}/services/auth/login'.format(\n            url),\n        headers={},\n        verify=False,\n        data={\n            'username': user,\n            'password': password\n        })\n    get_session_key = parseString(\n        servercontent.text).getElementsByTagName(\n            'sessionKey')[0].childNodes[0].nodeValue\n    return get_session_key", "response": "This function will get a user session key and throw for any errors"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a single object from a device.", "response": "def cli(wio, method, endpoint, token,):\n    '''\n    Request api, return json.\n\n    \\b\n    DOES:\n        Call a api on your devices.\n        token: device_token\n        method: GET or POST\n        endpoint: device_path, such as: /v1/node/GroveTempHumProD0/temperature\n        wio call <device_token> <request_method> <device_path>\n\n    \\b\n    EXAMPLE:\n        wio call 98dd464bd268d4dc4cb9b37e4e779313 GET /v1/node/GroveTempHumProD0/temperature\n    '''\n    user_token = wio.config.get(\"token\", None)\n    api_prefix = wio.config.get(\"mserver\", None)\n    if not api_prefix or not user_token:\n        click.echo(click.style('>> ', fg='red') + \"Please login, use \" +\n            click.style(\"wio login\", fg='green'))\n        return\n\n    api = \"%s%s?access_token=%s\" %(api_prefix, endpoint, token)\n\n    try:\n        if method == \"GET\":\n            r = requests.get(api, timeout=15, verify=verify)\n        elif method == \"POST\":\n            r = requests.post(api, timeout=15, verify=verify)\n        else:\n            click.secho(\">> METHOD [%s] is wrong, should be GET or POST.\" %method, fg='red')\n            return\n        r.raise_for_status()\n        json_response = r.json()\n    except requests.exceptions.HTTPError as e:\n        if r.status_code == 400:\n            # error = r.json().get(\"error\", None)\n            # click.secho(\">> %s\" %error, fg='red')\n            click.echo(r.json())\n        else:\n            click.secho(\">> %s\" %e, fg='red')\n        return\n    except Exception as e:\n        click.secho(\">> %s\" %e, fg='red')\n        return\n\n    click.echo(r.json())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef whitelisted(argument=None):\n    def is_whitelisted(remote_ip, whitelist):\n        \"\"\"Check to see if an IP address is whitelisted.\n\n        :param str ip_address: The IP address to check\n        :param list whitelist: The whitelist to check against\n        :rtype: bool\n\n        \"\"\"\n        # Convert the ip into a long int version of the ip address\n        user_ip = ipaddr.IPv4Address(remote_ip)\n\n        # Loop through the ranges in the whitelist and check\n        if any([user_ip in ipaddr.IPv4Network(entry) for entry in whitelist]):\n            return True\n\n        return False\n\n    # If the argument is a function then there were no parameters\n    if type(argument) is types.FunctionType:\n\n        def wrapper(self, *args, **kwargs):\n            \"\"\"Check the whitelist against our application.settings dictionary\n            whitelist key.\n\n            :rtype: any\n            :raises: web.HTTPError\n\n            \"\"\"\n            # Validate we have a configured whitelist\n            if 'whitelist' not in self.application.settings:\n                raise ValueError('whitelist not found in Application.settings')\n\n            # If the IP address is whitelisted, call the wrapped function\n            if is_whitelisted(self.request.remote_ip,\n                              self.application.settings['whitelist']):\n\n                # Call the original function, IP is whitelisted\n                return argument(self, *args, **kwargs)\n\n            # The ip address was not in the whitelist\n            raise web.HTTPError(403)\n\n        # Return the wrapper method\n        return wrapper\n\n    # They passed in string or list?\n    else:\n\n        # Convert a single ip address to a list\n        if isinstance(argument, str):\n            argument = [argument]\n\n        # Make sure it's a list\n        elif not isinstance(argument, list):\n            raise ValueError('whitelisted requires no parameters or '\n                             'a string or list')\n\n        def argument_wrapper(method):\n            \"\"\"Wrapper for a method passing in the IP addresses that constitute\n            the whitelist.\n\n            :param method method: The method being wrapped\n            :rtype: any\n            :raises: web.HTTPError\n\n            \"\"\"\n            def validate(self, *args, **kwargs):\n                \"\"\"\n                Validate the ip address agross the list of ip addresses\n                passed in as a list\n                \"\"\"\n                if is_whitelisted(self.request.remote_ip, argument):\n\n                    # Call the original function, IP is whitelisted\n                    return method(self, *args, **kwargs)\n\n                # The ip address was not in the whitelist\n                raise web.HTTPError(403)\n\n            # Return the validate method\n            return validate\n\n        # Return the wrapper method\n        return argument_wrapper", "response": "Decorator that checks if the requesting IP address is whitelisted."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a column to the main dataframe populted with the model s linear regression for a column", "response": "def lreg(self, xcol, ycol, name=\"Regression\"):\n        \"\"\"\n        Add a column to the main dataframe populted with\n        the model's linear regression for a column\n        \"\"\"\n        try:\n            x = self.df[xcol].values.reshape(-1, 1)\n            y = self.df[ycol]\n            lm = linear_model.LinearRegression()\n            lm.fit(x, y)\n            predictions = lm.predict(x)\n            self.df[name] = predictions\n        except Exception as e:\n            self.err(e, \"Can not calculate linear regression\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cvar_(self, col):\n        try:\n            v = (np.std(self.df[col]) / np.mean(self.df[col])) * 100\n            return v\n        except Exception as e:\n            self.err(e,\n                     \"Can not calculate coefficient of variance\")", "response": "Returns the coefficient of variance of a column\n            in percentage"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef starter(cls):\n        data = cls.getPage(cls.url)\n        url1 = cls.fetchUrl(cls.url, data, cls.prevSearch)\n        data = cls.getPage(url1)\n        url2 = cls.fetchUrl(url1, data, cls.nextSearch)\n        return cls.prevUrlModifier(url2)", "response": "Get bounced start URL."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getPrevUrl(self, url, data):\n        mo = compile(r\"index(\\d+)\\.html\").search(url)\n        num = int(mo.group(1)) - 1\n        prefix = url.rsplit('/', 1)[0]\n        return \"%s/index%d.html\" % (prefix, num)", "response": "Decrease index. html number."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates article. languages Update article. _publisher_keep_state", "response": "def pre_save_title(instance, **kwargs):\n    ''' Update article.languages\n    '''\n    if instance.article.languages:\n        languages = instance.article.languages.split(',')\n    else:\n        languages = []\n    if instance.language not in languages:\n        languages.append(instance.language)\n        instance.article.languages = ','.join(languages)\n        instance.article._publisher_keep_state = True\n        instance.article.save(no_signals=True)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pre_delete_title(instance, **kwargs):\n    ''' Update article.languages\n    '''\n    if instance.article.languages:\n        languages = instance.article.languages.split(',')\n    else:\n        languages = []\n    if instance.language in languages:\n        languages.remove(instance.language)\n        instance.article.languages = ','.join(languages)\n        instance.article._publisher_keep_state = True\n        instance.article.save(no_signals=True)", "response": "Update the article. languages\n    field to include the current language."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef digest_auth(realm, auth_func):\n    def digest_auth_decorator(func):\n        def func_replacement(self, *args, **kwargs):\n            # 'self' here is the RequestHandler object, which is inheriting\n            # from DigestAuthMixin to get 'get_authenticated_user'\n            if self.get_authenticated_user(auth_func, realm):\n                return func(self, *args, **kwargs)\n        return func_replacement\n    return digest_auth_decorator", "response": "A decorator used to protect methods with HTTP Digest authentication."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rnow(\n        format='%Y-%m-%d %H:%M:%S',\n        in_utc=False):\n    \"\"\"rnow\n\n    Get right now as a string formatted datetime\n\n    :param format: string output format for datetime\n    :param in_utc: bool timezone in utc or local time\n    \"\"\"\n\n    if in_utc:\n        return datetime.datetime.utcnow().strftime(\n            format)\n    else:\n        return datetime.datetime.now().strftime(\n            format)", "response": "rnow - Get the right now as a string formatted datetime"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a color from the palette", "response": "def color_(self, i=None):\n        \"\"\"\n        Get a color from the palette\n        \"\"\"\n        global palette, color_num\n        if i is not None:\n            color_num = i\n        if color_num == len(palette) - 1:\n            color_num = 0\n        res = palette[color_num]\n        color_num += 1\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef scolor(self):\n        global palette\n        color = palette[self.color_index]\n        if len(palette) - 1 == self.color_index:\n            self.color_index = 0\n        else:\n            self.color_index += 1\n        self.color(color)", "response": "Set a unique color from a serie\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlogs-in with your Wio account and save an access token for interacting with your account on the Wio server.", "response": "def cli(wio):\n    '''\n    Login with your Wio account.\n\n    \\b\n    DOES:\n        Login and save an access token for interacting with your account on the Wio.\n\n    \\b\n    USE:\n        wio login\n    '''\n    mserver = wio.config.get(\"mserver\", None)\n    if mserver:\n        click.echo(click.style('> ', fg='green') + \"Current server is: \" +\n            click.style(mserver, fg='green'))\n        if click.confirm(click.style('Would you like login with a different server?', bold=True), default=False):\n            choise_server(wio)\n    else:\n        choise_server(wio)\n\n    if wio.config.get(\"server\") == 'Customize':\n        email = click.prompt(click.style('? ', fg='green') +\n            click.style('Please enter your email address', bold=True), type=str)\n        password = click.prompt(click.style('? ', fg='green') +\n            click.style('Please enter your password', bold=True), hide_input=True, type=str)\n        server_url = wio.config.get(\"mserver\")\n        \n        thread = termui.waiting_echo(\"Sending login details...\")\n        thread.daemon = True\n        thread.start()\n        try:\n            json_response = login_wio(server_url, email, password)\n            token = json_response['token']\n        except Exception as e:\n            thread.stop('')\n            thread.join()\n            click.secho(\">> %s\" %e, fg='red')\n            return\n    else:\n        token = click.prompt(click.style('? ', fg='green') +\n            click.style('First get wio user token from ', bold=True) +\n            click.style('https://wio.seeed.io/login', bold=True, fg='green') +\n            click.style('\\n? ', fg='green') +\n            click.style('Then enter token', bold=True), type=str)\n        email = ''\n        thread = termui.waiting_echo(\"Checking validity of token...\")\n        thread.daemon = True\n        thread.start()\n        try:\n            check_token(wio.config.get(\"mserver\"), token)\n        except Exception as e:\n            thread.stop('')\n            thread.join()\n            click.secho(\">> %s\" %e, fg='red')\n            return\n        # res = login_seeed(email, password) #TODO(ten): next time delete\n        # token = res['data']['token']\n        # user_id = res['data']['userid']\n        # ext_user(wio.config.get(\"mserver\"), email, user_id, token)\n\n    wio.set_config('email', email)\n    wio.set_config('token', token)\n\n    thread.stop('')\n    thread.join()\n    click.secho(\"\\r> \", fg='green', nl=False)\n    click.echo(\"Successfully completed login! Check state, see 'wio state'\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwaits until the log is exiting and exit.", "response": "def wait_for_exit(\n        log,\n        debug=False):\n    \"\"\"wait_for_exit\n\n    Sleep to allow the thread to pick up final messages\n    before exiting and stopping the Splunk HTTP publisher.\n\n    You can decrease this delay (in seconds) by reducing\n    the splunk_sleep_interval or by exporting the env var:\n    export SPLUNK_SLEEP_INTERVAL=0.5\n\n    If you set the timer to 0 then it will be a blocking HTTP POST sent\n    to Splunk for each log message. This creates a blocking logger in\n    your application that will wait until each log's HTTP POST\n    was received before continuing.\n\n    Note: Reducing this Splunk sleep timer could result in losing\n          messages that were stuck in the queue when the\n          parent process exits. The multiprocessing\n          Splunk Publisher was built to do this, but will\n          not work in certain frameworks like Celery\n          as it requires access to spawn daemon processes to\n          prevent this 'message loss' case during exiting.\n          Applications using this library should ensure\n          there's no critical log messages stuck in a queue\n          when stopping a long-running process.\n\n    :param log: created logger\n    :param debug: bool to debug with prints\n    \"\"\"\n\n    debug = SPLUNK_DEBUG\n    for i in log.root.handlers:\n        handler_class_name = i.__class__.__name__.lower()\n        if debug:\n            print((\n                ' - wait_for_exit handler={}').format(\n                    handler_class_name))\n        if ('splunkpublisher' == handler_class_name\n                or 'mpsplunkpublisher' == handler_class_name):\n            if hasattr(i, 'sleep_interval'):\n                total_sleep = i.sleep_interval + 2.0\n                if os.getenv(\n                        'PUBLISHER_EXIT_DELAY',\n                        False):\n                    total_sleep = float(os.getenv(\n                        'PUBLISHER_EXIT_DELAY',\n                        total_sleep))\n                if debug:\n                    print((\n                        ' - wait_for_exit '\n                        'handler={} wait={}s').format(\n                            handler_class_name,\n                            total_sleep))\n                time.sleep(total_sleep)\n                if debug:\n                    print((\n                        'done waiting for exit'))\n                return\n            else:\n                print((\n                    ' - wait_for_exit handler={} has no'\n                    'sleep_interval').format(\n                        handler_class_name))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting node sn and key", "response": "def get_new(mserver_url, token, board):\n    '''get node sn and key'''\n    thread = termui.waiting_echo(\"Getting message from Server...\")\n    thread.daemon = True\n    thread.start()\n    try:\n        params = {\"name\":\"node000\", \"board\":board, \"access_token\":token}\n        r = requests.post(\"%s%s\" %(mserver_url, nodes_create_endpoint), params=params, timeout=10, verify=verify)\n        r.raise_for_status()\n        json_response = r.json()\n    except requests.exceptions.HTTPError as e:\n        thread.stop('')\n        thread.join()\n        if r.status_code == 400:\n            error = r.json().get(\"error\", None)\n            click.secho(\">> %s\" %error, fg='red')\n        else:\n            click.secho(\">> %s\" %e, fg='red')\n        return None\n    except Exception as e:\n        thread.stop('')\n        thread.join()\n        click.secho(\">> %s\" %e, fg='red')\n        return None\n\n    thread.stop('')\n    thread.join()\n\n    return json_response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cli(wio):\n    '''\n    Add a new device with USB connect.\n\n    \\b\n    DOES:\n        Guides you through setting up a new device, and getting it on your network.\n\n    \\b\n    USE:\n        wio setup\n    '''\n    token = wio.config.get(\"token\", None)\n    mserver_url = wio.config.get(\"mserver\", None)\n    msvr_ip = wio.config.get(\"mserver_ip\", None)\n    if not mserver_url or not token:\n        click.echo(click.style('>> ', fg='red') + \"Please login, use \" +\n            click.style(\"wio login\", fg='green'))\n        return\n    msvr = urlparse(mserver_url).hostname\n    xsvr = msvr\n    xsvr_ip = msvr_ip\n    board = ''\n\n    click.secho('> ', fg='green', nl=False)\n    click.echo(\"Setup is easy! Let's get started...\\n\")\n    click.secho('! ', fg='green', nl=False)\n    click.echo(\"PROTIP: \" +\n        click.style(\"Hold the \", fg='white') +\n        click.style(\"Configure \", fg='green') +\n        click.style(\"button ~4s into Configure Mode!\", fg='white'))\n    click.secho('! ', fg='green', nl=False)\n    click.echo(\"PROTIP: \" +\n        click.style(\"Please make sure you are \", fg='white') +\n        click.style(\"connected \", fg='green') +\n        click.style(\"to the \", fg='white') +\n        click.style(\"Server\", fg='green'))\n    click.echo()\n    click.secho('? ', fg='green', nl=False)\n    if not click.confirm(click.style('Would you like continue?', bold=True), default=True):\n        click.echo('Quit setup!')\n        return\n\n    ### choice board\n    while 1:\n        for x in range(len(boards)):\n            click.echo(\"%s.) %s\" %(x, boards[x]))\n        click.secho('? ', fg='green', nl=False)\n        value = click.prompt(click.style('Please choice the board type', bold=True), type=int)\n        if value >= 0 and value < len(boards):\n            board = boards[value]\n            break\n        else:\n            click.echo(click.style('>> ', fg='red') + \"invalid input.\")\n\n    r = get_new(mserver_url, token, board)\n    if not r:\n        return\n    node_key = r[\"node_key\"]\n    node_sn = r[\"node_sn\"]\n\n    ### list wio with serial\n    if board == WIO_LINK_V1_0:\n        try:\n            ports = serial_list.serial_ports()\n        except serial.SerialException as e:\n            click.secho('>> ', fg='red', nl=False)\n            click.echo(e)\n            if e.errno == 13:\n                click.echo(\"For more information, see https://github.com/Seeed-Studio/wio-cli#serial-port-permissions\")\n            return\n        # click.echo(ports)\n        count = len(ports)\n        port = None\n        if count == 0:\n            pass #scan\n        elif count == 1:\n            port = ports[0]\n        elif count >= 2:\n            while 1:\n                for x in range(len(ports)):\n                    click.echo(\"%s.) %s\" %(x, ports[x]))\n                click.secho('? ', fg='green', nl=False)\n                value = click.prompt(click.style('Please choice a device', bold=True), type=int)\n                if value >= 0 and value < len(ports):\n                    port = ports[value]\n                    break\n                else:\n                    click.echo(click.style('>> ', fg='red') + \"invalid input.\")\n\n        if not port:\n            click.secho('> ', fg='green', nl=False)\n            click.echo(\"No devices detected via USB.\")\n            # click.echo('>> change your network to wio_?')\n            click.secho('? ', fg='green', nl=False)\n            value = click.confirm(\n                click.style('Would you like to enter Wi-Fi setup mode?', bold=True), default=True)\n\n            #### udp setup\n            r = upd_send(msvr, msvr_ip, xsvr, xsvr_ip, node_sn, node_key)\n            if not r:\n                return\n            d_name = r['name']\n            check_connect(mserver_url, token, node_sn, d_name)\n            return\n            \n        click.echo(click.style('> ', fg='green') + \"I have detected a \" +\n            click.style(\"Wio \", fg='green') + \"connected via USB.\")\n\n        r = serial_send(msvr, msvr_ip, xsvr, xsvr_ip, node_sn, node_key, port)\n        if not r:\n            return\n        d_name = r['name']\n        check_connect(mserver_url, token, node_sn, d_name)\n    elif board == WIO_NODE_V1_0:\n        r = upd_send(msvr, msvr_ip, xsvr, xsvr_ip, node_sn, node_key)\n        if not r:\n            return\n        d_name = r['name']\n        check_connect(mserver_url, token, node_sn, d_name)", "response": "A simple command line interface for the USB - specific get - new - device."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_image(filename):\n    # note: isfile() also accepts symlinks\n    return os.path.isfile(filename) and filename.lower().endswith(ImageExts)", "response": "Determine if given filename is an image."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_cbz(directory):\n    if not os.path.isdir(directory):\n        print(\"ERROR: Directory\", directory, \"not found.\")\n        return\n    base = os.path.basename(directory.rstrip(os.path.sep))\n    zipname = '%s.cbz' % base\n    zipname = os.path.join(directory, zipname)\n    d = os.path.join(directory, 'inorder')\n    if os.path.isdir(d):\n        # use directory with ordered symlinks\n        directory = d\n    if os.path.exists(zipname):\n        os.remove(zipname)\n    with zipfile.ZipFile(zipname, 'w') as myzip:\n        for filename in sorted(os.listdir(d)):\n            fullname = os.path.join(d, filename)\n            if is_image(fullname):\n                myzip.write(fullname)\n        myzip.comment = get_cbz_comment()\n    print(\"INFO: Created\", zipname)", "response": "Creates or updates a CBZ file in the given comic directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nvisit a node. Calls ``visit_CLASSNAME`` on itself passing ``node``, where ``CLASSNAME`` is the node's class. If the visitor does not implement an appropriate visitation method, will go up the `MRO <https://www.python.org/download/releases/2.3/mro/>`_ until a match is found. If the search exhausts all classes of node, raises a :class:`~exceptions.NotImplementedError`. :param node: The node to visit. :return: The return value of the called visitation function.", "response": "def visit(self, node):\n        \"\"\"Visit a node.\n\n        Calls ``visit_CLASSNAME`` on itself passing ``node``, where\n        ``CLASSNAME`` is the node's class. If the visitor does not implement an\n        appropriate visitation method, will go up the\n        `MRO <https://www.python.org/download/releases/2.3/mro/>`_ until a\n        match is found.\n\n        If the search exhausts all classes of node, raises a\n        :class:`~exceptions.NotImplementedError`.\n\n        :param node: The node to visit.\n        :return: The return value of the called visitation function.\n        \"\"\"\n        if isinstance(node, type):\n            mro = node.mro()\n        else:\n            mro = type(node).mro()\n        for cls in mro:\n            meth = getattr(self, 'visit_' + cls.__name__, None)\n            if meth is not None:\n                return meth(node)\n\n        raise NotImplementedError('No visitation method visit_{}'\n                                  .format(node.__class__.__name__))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef translation_save_translated_fields(instance, **kwargs):\n    if not hasattr(instance, '_translation_cache'):\n        return\n    for l_id, translation in instance._translation_cache.iteritems():\n        # set the translation ID just in case the translation was\n        # created while instance was not stored in the DB yet\n\n        # note: we're using _get_pk_val here even though it is\n        # private, since that's the most reliable way to get the value\n        # on older Django (pk property did not exist yet)\n        translation.master_id = instance._get_pk_val()\n        translation.save()", "response": "Save all the translations of instance in post_save signal handler."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fill_translation_cache(instance):\n\n    if hasattr(instance, '_translation_cache'):\n        # do not refill the cache\n        return\n    instance._translation_cache = {}\n\n    # unsafed instances cannot have translations\n    if not instance.pk:\n        return\n\n    for language_code in get_language_code_list():\n        # see if translation for language_code was in the query\n        field_alias = get_translated_field_alias('code', language_code)\n        if getattr(instance, field_alias, None) is not None:\n            field_names = [f.attname for f in instance._meta.translation_model._meta.fields]\n\n            # if so, create a translation object and put it in the cache\n            field_data = {}\n            for fname in field_names:\n                field_data[fname] = getattr(instance,\n                                            get_translated_field_alias(fname, language_code))\n\n            translation = instance._meta.translation_model(**field_data)\n            instance._translation_cache[language_code] = translation\n\n    # In some situations an (existing in the DB) object is loaded\n    # without using the normal QuerySet.  In such case fallback to\n    # loading the translations using a separate query.\n\n    # Unfortunately, this is indistinguishable from the situation when\n    # an object does not have any translations.  Oh well, we'll have\n    # to live with this for the time being.\n    if len(instance._translation_cache.keys()) == 0:\n        for translation in instance.translations.all():\n            instance._translation_cache[translation.language_code] = translation", "response": "Fill the translation cache with the information received in the object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getter_generator(field_name, short_description):\n    def get_translation_field(cls, language_code=None, fallback=False):\n        try:\n            return cls.get_translation(language_code,\n                                       fallback=fallback,\n                                       field=field_name)\n        except TranslationDoesNotExist:\n            return None\n    get_translation_field.short_description = short_description\n    return get_translation_field", "response": "Generate get_field name method for field field_name."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates set_field name method for field field_name.", "response": "def setter_generator(field_name):\n    \"\"\"\n    Generate set_'field name' method for field field_name.\n    \"\"\"\n    def set_translation_field(cls, value, language_code=None):\n        setattr(cls.get_translation(language_code, True),\n                field_name, value)\n    set_translation_field.short_description = \"set \" + field_name\n    return set_translation_field"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_translation(cls, language_code, create_if_necessary=False,\n                    fallback=False, field=None):\n    \"\"\"\n    Get a translation instance for the given `language_id_or_code`.\n\n    If the translation does not exist:\n\n    1. if `create_if_necessary` is True, this function will create one\n    2. otherwise, if `fallback` is True, this function will search the\n       list of languages looking for the first existing translation\n    3. if all of the above fails to find a translation, raise the\n    TranslationDoesNotExist exception\n    \"\"\"\n    # fill the cache if necessary\n    cls.fill_translation_cache()\n\n    if language_code is None:\n        language_code = getattr(cls, '_default_language', None)\n    if language_code is None:\n        language_code = get_default_language()\n\n    force = False\n    if GLL.is_active:\n        language_code = GLL.language_code\n        force = True\n\n    if language_code in cls._translation_cache:\n        transobj = cls._translation_cache.get(language_code, None)\n        if field is None:\n            return transobj    \n        value = getattr(transobj, field)\n        if value or force or (not fallback):\n            return value\n\n    if create_if_necessary:\n        new_translation = cls._meta.translation_model(master=cls,\n                                                      language_code=language_code)\n        cls._translation_cache[language_code] = new_translation\n        return new_translation\n    # only fall backif we're not in 'force' mode (GLL)\n    elif (not force) and fallback:\n        for fb_lang_code in get_fallbacks(language_code):\n            transobj = cls._translation_cache.get(fb_lang_code, None)\n            if transobj:\n                if field is None:\n                    return transobj\n                else:\n                    value = getattr(transobj, field)\n                    if value:\n                        return value\n    raise TranslationDoesNotExist(language_code)", "response": "Returns a translation instance for the given language_code."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef contribute_to_class(cls, main_cls, name):\n\n        # delay the creation of the *Translation until the master model is\n        # fully created\n        signals.class_prepared.connect(cls.finish_multilingual_class,\n                sender=main_cls, weak=False)\n\n        # connect the post_save signal on master class to a handler\n        # that saves translations\n        signals.post_save.connect(translation_save_translated_fields,\n                sender=main_cls)", "response": "Contributes the given name to the given main_cls."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating the necessary attributes for the translation fields of the main_cls.", "response": "def create_translation_attrs(cls, main_cls):\n        \"\"\"\n        Creates get_'field name'(language_code) and set_'field\n        name'(language_id) methods for all the translation fields.\n        Adds the 'field name' properties too.\n\n        Returns the translated_fields hash used in field lookups, see\n        multilingual.query.  It maps field names to (field,\n        language_id) tuples.\n        \"\"\"\n        translated_fields = {}\n\n        for fname, field in cls.__dict__.items():\n            if isinstance(field, models.fields.Field):\n                translated_fields[fname] = (field, None)\n\n                # add get_'fname' and set_'fname' methods to main_cls\n                getter = getter_generator(fname, getattr(field, 'verbose_name', fname))\n                setattr(main_cls, 'get_' + fname, getter)\n\n                setter = setter_generator(fname)\n                setattr(main_cls, 'set_' + fname, setter)\n\n                # add the 'fname' proxy property that allows reads\n                # from and writing to the appropriate translation\n                setattr(main_cls, fname,\n                        TranslatedFieldProxy(fname, fname, field, fallback=True))\n\n                # add the 'fname'_any fallback\n                setattr(main_cls, fname + FALLBACK_FIELD_SUFFIX,\n                        TranslatedFieldProxy(fname, fname, field, fallback=True))\n\n                # create the 'fname'_'language_code' proxy properties\n                for language_code in get_language_code_list():\n                    fname_lng = fname + '_' + language_code.replace('-', '_')\n                    translated_fields[fname_lng] = (field, language_code)\n                    setattr(main_cls, fname_lng,\n                            TranslatedFieldProxy(fname, fname_lng, field,\n                                                 language_code))\n                    # add the 'fname'_'language_code'_any fallback proxy\n                    setattr(main_cls, fname_lng + FALLBACK_FIELD_SUFFIX,\n                            TranslatedFieldProxy(fname, fname_lng, field,\n                                                 language_code, fallback=True))\n                fname_current = fname + '_current'\n                setattr(main_cls, fname_current,\n                        TranslatedFieldProxy(fname, fname_current, field, None))\n                setattr(main_cls, fname_current + FALLBACK_FIELD_SUFFIX,\n                        TranslatedFieldProxy(fname, fname_current, field, None, fallback=True))\n\n        return translated_fields"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_unique_fields(cls):\n        unique_fields = []\n\n        for fname, field in cls.__dict__.items():\n            if isinstance(field, models.fields.Field):\n                if getattr(field,'unique',False):\n                    try:\n                        field.unique = False\n                    except AttributeError:\n                        # newer Django defines unique as a property\n                        # that uses _unique to store data.  We're\n                        # jumping over the fence by setting _unique,\n                        # so this sucks, but this happens early enough\n                        # to be safe.\n                        field._unique = False\n                    unique_fields.append(fname)\n        return unique_fields", "response": "Return a list of fields with unique attribute set to False."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef finish_multilingual_class(cls, *args, **kwargs):\n\n        main_cls = kwargs['sender']\n        translation_model_name = main_cls.__name__ + \"Translation\"\n\n        # create the model with all the translatable fields\n        unique = [('language_code', 'master')]\n        for f in cls.get_unique_fields():\n            unique.append(('language_code',f))\n\n        class TransMeta:\n            pass\n\n        try:\n            meta = cls.Meta\n        except AttributeError:\n            meta = TransMeta\n\n        meta.ordering = ('language_code',)\n        meta.unique_together = tuple(unique)\n        meta.app_label = main_cls._meta.app_label\n        if not hasattr(meta, 'db_table'):\n            meta.db_table = main_cls._meta.db_table + '_translation'\n\n        trans_attrs = cls.__dict__.copy()\n        trans_attrs['Meta'] = meta\n        # TODO: increase the length of this field, but to what???\n        trans_attrs['language_code'] = models.CharField(max_length=15, blank=True,\n                                                        choices=get_language_choices(),\n                                                        db_index=True)\n        \n        related_name = getattr(meta, 'related_name', 'translations')\n        if hasattr(meta, 'related_name'):\n            delattr(meta, 'related_name')\n        \n        edit_inline = True\n\n        trans_attrs['master'] = TranslationForeignKey(main_cls, blank=False, null=False,\n                                                      related_name=related_name,)\n        trans_attrs['__str__'] = lambda self: (\"%s object, language_code=%s\"\n                                               % (translation_model_name,\n                                                  self.language_code))\n\n        trans_model = ModelBase(translation_model_name, (models.Model,), trans_attrs)\n        trans_model._meta.translated_fields = cls.create_translation_attrs(main_cls)\n        trans_model._meta.related_name = related_name\n\n        _old_init_name_map = main_cls._meta.__class__.init_name_map\n        def init_name_map(self):\n            cache = _old_init_name_map(self)\n            for name, field_and_lang_id in trans_model._meta.translated_fields.items():\n                #import sys; sys.stderr.write('TM %r\\n' % trans_model)\n                cache[name] = (field_and_lang_id[0], trans_model, True, False)\n            return cache\n        main_cls._meta.init_name_map = instancemethod(init_name_map,\n                                                      main_cls._meta,\n                                                      main_cls._meta.__class__)\n\n        main_cls._meta.translation_model = trans_model\n        main_cls._meta.force_language = None\n        main_cls.Translation = trans_model\n        main_cls.get_translation = get_translation\n        main_cls.fill_translation_cache = fill_translation_cache", "response": "Create a new multilingual class."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npick last one in a list of archive pages.", "response": "def starter(cls):\n        \"\"\"Pick last one in a list of archive pages.\"\"\"\n        archive = cls.url + 'archive.html'\n        data = getPageContent(archive, cls.session)\n        search = compile(tagre(\"a\", \"href\", r\"(\\d\\d\\d\\d-\\d\\d.html)\"))\n        archivepages = search.findall(data)\n        return cls.url + archivepages[-1]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef namer(cls, imageUrl, pageUrl):\n        start = ''\n        tsmatch = compile(r'/(\\d+)-').search(imageUrl)\n        if tsmatch:\n            start = datetime.utcfromtimestamp(int(tsmatch.group(1))).strftime(\"%Y-%m-%d\")\n        else:\n            # There were only chapter 1, page 4 and 5 not matching when writing\n            # this...\n            start = '2015-04-11x'\n        return start + \"-\" + pageUrl.rsplit('/', 1)[-1]", "response": "Image file name is UNIX time stamp & something for most of the comics..."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nusing strip index number for image name.", "response": "def namer(cls, imageUrl, pageUrl):\n        \"\"\"Use strip index number for image name.\"\"\"\n        index = int(compile(r'id=(\\d+)').search(pageUrl).group(1))\n        ext = imageUrl.rsplit('.', 1)[1]\n        return \"SnowFlakes-%d.%s\" % (index, ext)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nuse page URL to construct meaningful image name.", "response": "def namer(cls, imageUrl, pageUrl):\n        \"\"\"Use page URL to construct meaningful image name.\"\"\"\n        parts, year, month, stripname = pageUrl.rsplit('/', 3)\n        stripname = stripname.rsplit('.', 1)[0]\n        parts, imagename = imageUrl.rsplit('/', 1)\n        return '%s-%s-%s-%s' % (year, month, stripname, imagename)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef aggregate(self, *args, **kwargs):\n        if self.query.distinct_fields:\n            raise NotImplementedError(\"aggregate() + distinct(fields) not implemented.\")\n        for arg in args:\n            # The default_alias property may raise a TypeError, so we use\n            # a try/except construct rather than hasattr in order to remain\n            # consistent between PY2 and PY3 (hasattr would swallow\n            # the TypeError on PY2).\n            try:\n                arg.default_alias\n            except (AttributeError, TypeError):\n                raise TypeError(\"Complex aggregates require an alias\")\n            kwargs[arg.default_alias] = arg\n\n        if django.VERSION < (2, 0):\n            query = self.query.clone(CTEAggregateQuery)\n        else:\n            query = self.query.chain(CTEAggregateQuery)\n        for (alias, aggregate_expr) in kwargs.items():\n            query.add_annotation(aggregate_expr, alias, is_summary=True)\n            if not query.annotations[alias].contains_aggregate:\n                raise TypeError(\"%s is not an aggregate expression\" % alias)\n        return query.get_aggregation(self.db, kwargs.keys())", "response": "Returns a dictionary containing the calculations over the current queryset."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a custom compiler for the current language.", "response": "def get_compiler(self, using=None, connection=None):\n        \"\"\" Overrides the Query method get_compiler in order to return\n            an instance of the above custom compiler.\n        \"\"\"\n        # Copy the body of this method from Django except the final\n        # return statement. We will ignore code coverage for this.\n        if using is None and connection is None:  # pragma: no cover\n            raise ValueError(\"Need either using or connection\")\n        if using:\n            connection = connections[using]\n        # Check that the compiler will be able to execute the query\n        for alias, aggregate in self.annotation_select.items():\n            connection.ops.check_expression_support(aggregate)\n        # Instantiate the custom compiler.\n        return {\n            CTEUpdateQuery: CTEUpdateQueryCompiler,\n            CTEInsertQuery: CTEInsertQueryCompiler,\n            CTEDeleteQuery: CTEDeleteQueryCompiler,\n            CTEAggregateQuery: CTEAggregateQueryCompiler,\n        }.get(self.__class__, CTEQueryCompiler)(self, connection, using)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\noverride the SQLUpdateCompiler. as_sql method to remove any CTE - related WHERE clauses from the query.", "response": "def as_sql(self, *args, **kwargs):\n        \"\"\"\n        Overrides the :class:`SQLUpdateCompiler` method in order to remove any\n        CTE-related WHERE clauses, which are not necessary for UPDATE queries,\n        yet may have been added if this query was cloned from a CTEQuery.\n\n        :return:\n        :rtype:\n        \"\"\"\n        CTEQuery._remove_cte_where(self.query)\n        return super(self.__class__, self).as_sql(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\noverride the SQLAggregateCompiler method to add necessary CTE syntax to the query string.", "response": "def as_sql(self, *args, **kwargs):\n        \"\"\"\n        Overrides the :class:`SQLAggregateCompiler` method in order to\n        prepend the necessary CTE syntax, as well as perform pre- and post-\n        processing, including adding the extra CTE table and WHERE clauses.\n\n        :param qn:\n        :type qn:\n        :return:\n        :rtype:\n        \"\"\"\n\n        def _as_sql():\n            return super(CTEAggregateQueryCompiler, self).as_sql(*args, **kwargs)\n\n        return CTECompiler.generate_sql(self.connection, self.query, _as_sql)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _add_to_publish_stack(self, exchange, routing_key, message, properties):\n        global message_stack\n        message_stack.append((exchange, routing_key, message, properties))", "response": "Temporarily add the message to the stack to publish to RabbitMQ\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _connect_to_rabbitmq(self):\n        global pending_rabbitmq_connection, rabbitmq_connection\n        if not rabbitmq_connection:\n            LOGGER.info('Creating a new RabbitMQ connection')\n            pending_rabbitmq_connection = self._new_rabbitmq_connection()", "response": "Connect to RabbitMQ and assign a local attribute"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new BasicProperties object with the properties specified.", "response": "def _new_message_properties(self, content_type=None, content_encoding=None,\n                                headers=None, delivery_mode=None, priority=None,\n                                correlation_id=None, reply_to=None,\n                                expiration=None, message_id=None,\n                                timestamp=None, message_type=None, user_id=None,\n                                app_id=None):\n        \"\"\"Create a BasicProperties object, with the properties specified\n\n        :param str content_type: MIME content type\n        :param str content_encoding: MIME content encoding\n        :param dict headers: Message header field table\n        :param int delivery_mode: Non-persistent (1) or persistent (2)\n        :param int priority: Message priority, 0 to 9\n        :param str correlation_id: Application correlation identifier\n        :param str reply_to: Address to reply to\n        :param str expiration: Message expiration specification\n        :param str message_id: Application message identifier\n        :param int timestamp: Message timestamp\n        :param str message_type: Message type name\n        :param str user_id: Creating user id\n        :param str app_id: Creating application id\n        :rtype: pika.BasicProperties\n\n        \"\"\"\n        return pika.BasicProperties(content_type, content_encoding, headers,\n                                    delivery_mode, priority, correlation_id,\n                                    reply_to, expiration, message_id, timestamp,\n                                    message_type, user_id, app_id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npublishes the message to RabbitMQ", "response": "def _publish_message(self, exchange, routing_key, message, properties):\n        \"\"\"Publish the message to RabbitMQ\n\n        :param str exchange: The exchange to publish to\n        :param str routing_key: The routing key to publish with\n        :param str message: The message body\n        :param pika.BasicProperties: The message properties\n\n        \"\"\"\n        if self._rabbitmq_is_closed or not self._rabbitmq_channel:\n            LOGGER.warning('Temporarily buffering message to publish')\n            self._add_to_publish_stack(exchange, routing_key,\n                                       message, properties)\n            return\n        self._rabbitmq_channel.basic_publish(exchange, routing_key,\n                                             message, properties)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the RabbitMQ configuration dictionary.", "response": "def _rabbitmq_config(self):\n        \"\"\"Return the RabbitMQ configuration dictionary.\n\n        :rtype: dict\n\n        \"\"\"\n        config = self.application.settings.get('rabbitmq')\n        if not config:\n            raise exceptions.ConfigurationException('rabbitmq')\n        return config"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _rabbitmq_parameters(self):\n        kwargs = dict(self._rabbitmq_config)\n        kwargs['credentials'] =  pika.PlainCredentials(kwargs['username'],\n                                                       kwargs['password'])\n        for key in ['username', 'password']:\n            del kwargs[key]\n        return pika.ConnectionParameters(**kwargs)", "response": "Return a pika. ConnectionParameters object using the configurationdict should\n        match the parameters for the pika. ConnectionParameters and\n            include an extra username and password variable."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nassigning the channel object to the tinman global object.", "response": "def _set_rabbitmq_channel(self, channel):\n        \"\"\"Assign the channel object to the tinman global object.\n\n        :param pika.channel.Channel channel: The pika channel\n\n        \"\"\"\n        setattr(self.application.attributes, self.CHANNEL, channel)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncall when RabbitMQ has been disconnected.", "response": "def on_rabbitmq_close(self, reply_code, reply_text):\n        \"\"\"Called when RabbitMQ has been connected to.\n\n        :param int reply_code: The code for the disconnect\n        :param str reply_text: The disconnect reason\n\n        \"\"\"\n        global rabbitmq_connection\n        LOGGER.warning('RabbitMQ has disconnected (%s): %s',\n                       reply_code, reply_text)\n        rabbitmq_connection = None\n        self._set_rabbitmq_channel(None)\n        self._connect_to_rabbitmq()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef on_rabbitmq_conn_open(self, connection):\n        global pending_rabbitmq_connection, rabbitmq_connection\n        LOGGER.info('RabbitMQ has connected')\n        rabbitmq_connection = connection\n        rabbitmq_connection.add_on_close_callback(self.on_rabbitmq_close)\n        rabbitmq_connection.channel(self.on_rabbitmq_channel_open)\n        pending_rabbitmq_connection = None", "response": "Called when RabbitMQ has been opened to."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalling when the RabbitMQ channel is opened.", "response": "def on_rabbitmq_channel_open(self, channel):\n        \"\"\"Called when the RabbitMQ accepts the channel open request.\n\n        :param pika.channel.Channel channel: The channel opened with RabbitMQ\n\n        \"\"\"\n        LOGGER.info('Channel %i is opened for communication with RabbitMQ',\n                    channel.channel_number)\n        self._set_rabbitmq_channel(channel)\n        self._publish_deferred_messages()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef prepare(self):\n        super(RabbitMQRequestHandler, self).prepare()\n        if self._rabbitmq_is_closed:\n            self._connect_to_rabbitmq()", "response": "Prepare the handler ensuring RabbitMQ is connected or start a new connection attempt."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn last gallery link.", "response": "def starter(cls):\n        \"\"\"Return last gallery link.\"\"\"\n        url = 'http://www.hagardunor.net/comics.php'\n        data = cls.getPage(url)\n        pattern = compile(tagre(\"a\", \"href\", cls.prevUrl))\n        for starturl in cls.fetchUrls(url, data, pattern):\n            pass\n        return starturl"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run_once(self):\n        packet = _parse_irc_packet(next(self.lines)) #Get next line from generator\n\n        for event_handler in list(self.on_packet_received):\n            event_handler(self, packet)\n\n        if packet.command == \"PRIVMSG\":\n            if packet.arguments[0].startswith(\"#\"):\n                for event_handler in list(self.on_public_message):\n                    event_handler(self, packet.arguments[0], packet.prefix.split(\"!\")[0], packet.arguments[1])\n            else:\n                for event_handler in list(self.on_private_message):\n                    event_handler(self, packet.prefix.split(\"!\")[0], packet.arguments[1])\n        elif packet.command == \"PING\":\n            self.send_line(\"PONG :{}\".format(packet.arguments[0]))\n\n            for event_handler in list(self.on_ping):\n                event_handler(self)\n        elif packet.command == \"433\" or packet.command == \"437\":\n            #Command 433 is \"Nick in use\"\n            #Add underscore to the nick\n\n            self.set_nick(\"{}_\".format(self.nick))\n        elif packet.command == \"001\":\n            for event_handler in list(self.on_welcome):\n                event_handler(self)\n        elif packet.command == \"JOIN\":\n            for event_handler in list(self.on_join):\n                event_handler(self, packet.arguments[0], packet.prefix.split(\"!\")[0])\n        elif packet.command == \"PART\":\n            for event_handler in list(self.on_leave):\n                event_handler(self, packet.arguments[0], packet.prefix.split(\"!\")[0])", "response": "This function runs one iteration of the IRC client."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconnect to a given server.", "response": "def connect(self, server, port=6667):\n        \"\"\"Connects to a given IRC server. After the connection is established, it calls\n        the on_connect event handler.\n\n        \"\"\"\n        self.socket.connect((server, port))\n        self.lines = self._read_lines()\n        for event_handler in list(self.on_connect):\n            event_handler(self)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_nick(self, nick):\n        self.nick = nick\n        self.send_line(\"NICK {}\".format(nick))", "response": "Sets or changes the nickname of the channel."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfitting the model to the given training data.", "response": "def fit(self, X, y, verbosity=0):\n        \"\"\"Fit the model according to the given training data.\n\n        Parameters\n        ----------\n        X : List of ndarrays, one for each training example.\n            Each training example's shape is (string1_len, string2_len, n_features), where\n            string1_len and string2_len are the length of the two training strings and n_features the\n            number of features.\n\n        y : array-like, shape (n_samples,)\n            Target vector relative to X.\n\n        Returns\n        -------\n        self : object\n            Returns self.\n        \"\"\"\n        self.classes = list(set(y))\n        n_points = len(y)\n        if len(X) != n_points:\n            raise Exception('Number of training points should be the same as training labels.')\n\n        if not self._state_machine:\n            self._state_machine = DefaultStateMachine(self.classes)\n\n        # Initialize the parameters given the state machine, features, and target classes.\n        self.parameters = self._initialize_parameters(self._state_machine, X[0].shape[2])\n\n        # Create a new model object for each training example\n        models = [_Model(self._state_machine, x, ty) for x, ty in zip(X, y)]\n\n        self._evaluation_count = 0\n\n        def _objective(parameters):\n            gradient = np.zeros(self.parameters.shape)\n            ll = 0.0  # Log likelihood\n            # TODO: Embarrassingly parallel\n            for model in models:\n                dll, dgradient = model.forward_backward(parameters.reshape(self.parameters.shape))\n                ll += dll\n                gradient += dgradient\n\n            parameters_without_bias = np.array(parameters, dtype='float64')  # exclude the bias parameters from being regularized\n            parameters_without_bias[0] = 0\n            ll -= self.l2_regularization * np.dot(parameters_without_bias.T, parameters_without_bias)\n            gradient = gradient.flatten() - 2.0 * self.l2_regularization * parameters_without_bias\n\n            if verbosity > 0:\n                if self._evaluation_count == 0:\n                    print('{:10} {:10} {:10}'.format('Iteration', 'Log-likelihood', '|gradient|'))\n                if self._evaluation_count % verbosity == 0:\n                    print('{:10} {:10.4} {:10.4}'.format(self._evaluation_count, ll, (abs(gradient).sum())))\n            self._evaluation_count += 1\n\n            # TODO: Allow some of the parameters to be frozen. ie. not trained. Can later also completely remove\n            # TODO:     the computation associated with these parameters.\n            return -ll, -gradient\n\n        def _objective_copy_gradient(paramers, g):\n            nll, ngradient = _objective(paramers)\n            g[:] = ngradient\n            return nll\n\n        if self._optimizer:\n            self.optimizer_result = self._optimizer(_objective, self.parameters.flatten(), **self._optimizer_kwargs)\n            self.parameters = self.optimizer_result[0].reshape(self.parameters.shape)\n        else:\n            optimizer = lbfgs.LBFGS()\n            final_betas = optimizer.minimize(_objective_copy_gradient,\n                                             x0=self.parameters.flatten(),\n                                             progress=None)\n            self.optimizer_result = final_betas\n            self.parameters = final_betas.reshape(self.parameters.shape)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef predict_proba(self, X):\n        \n        parameters = np.ascontiguousarray(self.parameters.T)\n\n        predictions = [_Model(self._state_machine, x).predict(parameters, self.viterbi)\n                       for x in X]\n        predictions = np.array([[probability\n                                 for _, probability\n                                 in sorted(prediction.items())]\n                                for prediction in predictions])\n        return predictions", "response": "Predicts the probability of each class in the model for each training example."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npredicts the class for each sample in X.", "response": "def predict(self, X):\n        \"\"\"Predict the class for X.\n\n        The predicted class for each sample in X is returned.\n\n        Parameters\n        ----------\n        X : List of ndarrays, one for each training example.\n            Each training example's shape is (string1_len,\n            string2_len, n_features), where string1_len and\n            string2_len are the length of the two training strings and\n            n_features the number of features.\n\n        Returns\n        -------\n        y : iterable of shape = [n_samples]\n            The predicted classes.\n\n        \"\"\"\n        return [self.classes[prediction.argmax()] for prediction in self.predict_proba(X)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _initialize_parameters(state_machine, n_features):\n        return np.zeros((state_machine.n_states \n                         + state_machine.n_transitions,\n                         n_features))", "response": "Helper function to create initial parameter vector with the correct shape."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_params(self, deep=True):\n        return {'l2_regularization': self.l2_regularization,\n                'optimizer': self._optimizer,\n                'optimizer_kwargs': self._optimizer_kwargs}", "response": "Returns the parameters for this estimator."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the parameters of this estimator.", "response": "def set_params(self, l2_regularization=0.0, optimizer=None, optimizer_kwargs=None):\n        \"\"\"Set the parameters of this estimator.\n\n        Returns\n        -------\n        self\n        \"\"\"\n        self.l2_regularization = l2_regularization\n        self._optimizer = optimizer\n        self._optimizer_kwargs = optimizer_kwargs\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef forward_backward(self, parameters):\n        # If the features are sparse, we can use an optimization.\n        # I'm not using scipy.sparse here because we want to avoid a scipy dependency and also scipy.sparse doesn't seem\n        # to handle arrays of shape higher than 2.\n        if isinstance(self.sparse_x, str) and self.sparse_x == 'uninitialized':\n            if (self.x == 0).sum() * 1.0 / self.x.size > 0.6:\n                self.sparse_x = self._construct_sparse_features(self.x)\n            else:\n                self.sparse_x = 'not sparse'\n\n        I, J, K = self.x.shape\n        if not isinstance(self.sparse_x, str):\n            C = self.sparse_x[0].shape[2]\n            S, _ = parameters.shape\n            x_dot_parameters = np.zeros((I, J, S))\n            sparse_multiply(x_dot_parameters, self.sparse_x[0], self.sparse_x[1], parameters.T, I, J, K, C, S)\n        else:\n            x_dot_parameters = np.dot(self.x, parameters.T)  # Pre-compute the dot product\n        alpha = self._forward(x_dot_parameters)\n        beta = self._backward(x_dot_parameters)\n        classes_to_ints = {k: i for i, k in enumerate(set(self.states_to_classes.values()))}\n        states_to_classes = np.array([classes_to_ints[self.states_to_classes[state]]\n                                      for state in range(max(self.states_to_classes.keys()) + 1)], dtype='int64')\n        if not isinstance(self.sparse_x, str):\n            ll, deriv = gradient_sparse(alpha, beta, parameters, states_to_classes,\n                                        self.sparse_x[0], self.sparse_x[1], classes_to_ints[self.y],\n                                        I, J, self.sparse_x[0].shape[2])\n        else:\n            ll, deriv = gradient(alpha, beta, parameters, states_to_classes,\n                                 self.x, classes_to_ints[self.y], I, J, K)\n        return ll, deriv", "response": "Run the forward and backward algorithm with the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning forward algorithm to find the predicted distribution over classes.", "response": "def predict(self, parameters, viterbi):\n        \"\"\" Run forward algorithm to find the predicted distribution over classes. \"\"\"\n        x_dot_parameters = np.einsum('ijk,kl->ijl', self.x, parameters)\n\n        if not viterbi:\n            alpha = forward_predict(self._lattice, x_dot_parameters,\n                                    self.state_machine.n_states)\n        else:\n            alpha = forward_max_predict(self._lattice, x_dot_parameters,\n                                        self.state_machine.n_states)\n\n        I, J, _ = self.x.shape\n\n        class_Z = {}\n        Z = -np.inf\n\n        for state, predicted_class in self.states_to_classes.items():\n            weight = alpha[I - 1, J - 1, state]\n            class_Z[self.states_to_classes[state]] = weight\n            Z = np.logaddexp(Z, weight)\n\n        return {label: np.exp(class_z - Z) for label, class_z in class_Z.items()}"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_html_(self) -> str:\n        try:\n            renderer = pytablewriter.HtmlTableWriter\n            data = self._build_export(renderer)\n            return data\n        except Exception as e:\n            self.err(e, \"Can not convert data to html\")", "response": "Convert the main dataframe to html"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert the main dataframe to json", "response": "def to_json_(self) -> str:\n        \"\"\"Convert the main dataframe to json\n\n        :return: json data\n        :rtype: str\n\n        :example: ``ds.to_json_()``\n        \"\"\"\n        try:\n            renderer = pytablewriter.JsonTableWriter\n            data = self._build_export(renderer)\n            return data\n        except Exception as e:\n            self.err(e, \"Can not convert data to json\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_javascript_(self, table_name: str=\"data\") -> str:\n        try:\n            renderer = pytablewriter.JavaScriptTableWriter\n            data = self._build_export(renderer, table_name)\n            return data\n        except Exception as e:\n            self.err(e, \"Can not convert data to javascript code\")", "response": "Convert the main dataframe to javascript code"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts the main dataframe to markdown", "response": "def to_markdown_(self) -> str:\n        \"\"\"Convert the main dataframe to markdown\n\n        :return: markdown data\n        :rtype: str\n\n        :example: ``ds.to_markdown_()``\n        \"\"\"\n        try:\n            renderer = pytablewriter.MarkdownTableWriter\n            data = self._build_export(renderer)\n            return data\n        except Exception as e:\n            self.err(e, \"Can not convert data to markdown\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert the main dataframe to restructured text", "response": "def to_rst_(self) -> str:\n        \"\"\"Convert the main dataframe to restructured text\n\n        :return: rst data\n        :rtype: str\n\n        :example: ``ds.to_rst_()``\n        \"\"\"\n        try:\n            renderer = pytablewriter.RstGridTableWriter\n            data = self._build_export(renderer)\n            return data\n        except Exception as e:\n            self.err(e, \"Can not convert data to restructured text\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert the main dataframe to python a python list", "response": "def to_python_(self, table_name: str=\"data\") -> list:\n        \"\"\"Convert the main dataframe to python a python list\n\n        :param table_name: python variable name, defaults to \"data\"\n        :param table_name: str, optional\n        :return: a python list of lists with the data\n        :rtype: str\n\n        :example: ``ds.to_python_(\"myvar\")``\n        \"\"\"\n        try:\n            renderer = pytablewriter.PythonCodeTableWriter\n            data = self._build_export(renderer, table_name)\n            return data\n        except Exception as e:\n            self.err(e, \"Can not convert data to python list\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_numpy_(self, table_name: str=\"data\") -> numpy.array:\n        try:\n            renderer = pytablewriter.NumpyTableWriter\n            data = self._build_export(renderer, table_name)\n            return data\n        except Exception as e:\n            self.err(e, \"Can not convert data to numpy array\")", "response": "Convert the main dataframe to a numpy array"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of dictionary records from the main dataframe", "response": "def to_records_(self) -> dict:\n        \"\"\"Returns a list of dictionary records from the main dataframe\n\n        :return: a python dictionnary with the data\n        :rtype: str\n\n        :example: ``ds.to_records_()``\n        \"\"\"\n        try:\n            dic = self.df.to_dict(orient=\"records\")\n            return dic\n        except Exception as e:\n            self.err(e, \"Can not convert data to records\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_csv(self, filepath: str, index: bool=False, **kwargs):\n        try:\n            self.start(\"Saving data to \"+filepath + \" ...\")\n            if self.datapath is not None:\n                if filepath.startswith(\"/\") is False and \\\n                        filepath.startswith(\".\") is False:\n                    filepath = self.datapath + \"/\" + filepath\n            self.df.to_csv(filepath, encoding='utf-8', index=index, **kwargs)\n            self.end(\"Data exported to\", filepath)\n        except Exception as e:\n            self.err(e, \"Can not convert data to csv\")", "response": "Write the main dataframe to a csv file"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_excel(self, filepath: str, title: str):\n        try:\n            self.start(\"Saving data to Excell file: \"+filepath + \" ...\")\n            writer = pytablewriter.ExcelXlsxTableWriter()\n            writer.from_dataframe(self.df)\n            writer.open(filepath)\n            writer.make_worksheet(title)\n            writer.write_table()\n            writer.close()\n            self.end(\"File exported to\", filepath)\n        except Exception as e:\n            self.err(e, \"Can not convert data to Excel\")", "response": "Write the main dataframe to an Excell file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite the main dataframe to Hdf5 file", "response": "def to_hdf5(self, filepath: str):\n        \"\"\"Write the main dataframe to Hdf5 file\n\n        :param filepath: path where to save the file\n        :type filepath: str\n\n        :example: ``ds.to_hdf5_(\"./myfile.hdf5\")``\n        \"\"\"\n        try:\n            self.start(\"Saving data to Hdf5...\")\n            dd.io.save(filepath, self.df)\n            self.end(\"Finished saving Hdf5 data\")\n        except Exception as e:\n            self.err(e, \"Can not convert data to Hdf5\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a CMS Article and it s title for the given language.", "response": "def create_article(tree, template, title, language, slug=None, description=None,\n                   page_title=None, menu_title=None, meta_description=None,\n                   created_by=None, image=None, publication_date=None, publication_end_date=None,\n                   published=False, login_required=False, creation_date=None, categories=[]):\n    \"\"\"\n    Create a CMS Article and it's title for the given language\n    \"\"\"\n\n    # validate tree\n    tree = tree.get_public_object()\n    assert tree.application_urls == 'CMSArticlesApp'\n\n    # validate template\n    assert template in [tpl[0] for tpl in settings.CMS_ARTICLES_TEMPLATES]\n    get_template(template)\n\n    # validate language:\n    assert language in get_language_list(tree.node.site_id), settings.CMS_LANGUAGES.get(tree.node.site_id)\n\n    # validate publication date\n    if publication_date:\n        assert isinstance(publication_date, datetime.date)\n\n    # validate publication end date\n    if publication_end_date:\n        assert isinstance(publication_end_date, datetime.date)\n\n    # validate creation date\n    if not creation_date:\n        creation_date = publication_date\n    if creation_date:\n        assert isinstance(creation_date, datetime.date)\n\n    # get username\n    if created_by:\n        try:\n            username = created_by.get_username()\n        except Exception:\n            username = force_text(created_by)\n    else:\n        username = 'script'\n\n    with current_user(username):\n        # create article\n        article = Article.objects.create(\n            tree=tree,\n            template=template,\n            login_required=login_required,\n            creation_date=creation_date,\n            publication_date=publication_date,\n            publication_end_date=publication_end_date,\n            languages=language,\n        )\n        for category in categories:\n            article.categories.add(category)\n\n        # create title\n        create_title(\n            article=article,\n            language=language,\n            title=title,\n            slug=slug,\n            description=description,\n            page_title=page_title,\n            menu_title=menu_title,\n            meta_description=meta_description,\n            creation_date=creation_date,\n            image=image,\n        )\n\n        # publish article\n        if published:\n            article.publish(language)\n\n    return article.reload()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate an article title.", "response": "def create_title(article, language, title, slug=None, description=None,\n                 page_title=None, menu_title=None, meta_description=None,\n                 creation_date=None, image=None):\n    \"\"\"\n    Create an article title.\n    \"\"\"\n    # validate article\n    assert isinstance(article, Article)\n\n    # validate language:\n    assert language in get_language_list(article.tree.node.site_id)\n\n    # validate creation date\n    if creation_date:\n        assert isinstance(creation_date, datetime.date)\n\n    # set default slug:\n    if not slug:\n        slug = settings.CMS_ARTICLES_SLUG_FORMAT.format(\n            now=creation_date or now(),\n            slug=slugify(title),\n        )\n\n    # find unused slug:\n    base_slug = slug\n    qs = Title.objects.filter(language=language)\n    used_slugs = list(s for s in qs.values_list('slug', flat=True) if s.startswith(base_slug))\n    i = 1\n    while slug in used_slugs:\n        slug = '%s-%s' % (base_slug, i)\n        i += 1\n\n    # create title\n    title = Title.objects.create(\n        article=article,\n        language=language,\n        title=title,\n        slug=slug,\n        description=description,\n        page_title=page_title,\n        menu_title=menu_title,\n        meta_description=meta_description,\n        image=image,\n    )\n\n    return title"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_content(obj, language, slot, content):\n    placeholder = obj.placeholders.get(slot=slot)\n    add_plugin(placeholder, TextPlugin, language, body=content)", "response": "Adds a TextPlugin with given content to given slot"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npublish an article. This sets `article.published` to `True` and calls article.publish() which does the actual publishing.", "response": "def publish_article(article, language, changed_by=None):\n    \"\"\"\n    Publish an article. This sets `article.published` to `True`\n    and calls article.publish() which does the actual publishing.\n    \"\"\"\n    article = article.reload()\n\n    # get username\n    if changed_by:\n        username = changed_by.get_username()\n    else:\n        username = 'script'\n\n    with current_user(username):\n        article.publish(language)\n\n    return article.reload()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the module name.", "response": "def _get_module_name(module):\n    \"\"\"\n    Return the module name.\n\n    >>> from openprovider.modules import CustomerModule\n    >>> _get_module_name(CustomerModule)\n    'customer'\n\n    >>> _get_module_name(OpenProvider)\n    'openprovider'\n    \"\"\"\n    name = module.__name__[:-6] if module.__name__.endswith('Module') else module.__name__\n    return name.lower()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef request(self, tree, **kwargs):\n\n        apirequest = lxml.etree.tostring(\n            E.openXML(\n                E.credentials(\n                    E.username(self.username),\n                    OE('password', self.password),\n                    OE('hash', self.password_hash),\n                ),\n                tree\n            ),\n\n            method='c14n'\n        )\n\n        try:\n            apiresponse = self.session.post(self.url, data=apirequest)\n            apiresponse.raise_for_status()\n        except requests.RequestException as e:\n            raise ServiceUnavailable(str(e))\n\n        tree = lxml.objectify.fromstring(apiresponse.content)\n\n        if tree.reply.code == 0:\n            return Response(tree)\n        else:\n            klass = from_code(tree.reply.code)\n            desc = tree.reply.desc\n            code = tree.reply.code\n            data = getattr(tree.reply, 'data', '')\n            raise klass(u\"{0} ({1}) {2}\".format(desc, code, data), code)", "response": "Create a new request to the OpenProvider API."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_file(cls, fname, version=None, require_https=True):\n        if os.path.exists(fname):\n            with open(fname) as hive_file:\n                return cls(**json.load(hive_file)).from_version(version, require_https=require_https)\n        else:\n            raise MissingHive(fname)", "response": "Create a Hive object based on a local file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new instance of the class from a JSON located at a remote URL.", "response": "def from_url(cls, url, version=None, require_https=False):\n        \"\"\"\n        Create a Hive object based on JSON located at a remote URL.\n        \"\"\"\n        if \"https://\" in url:\n            require_https = True\n        if \"http://\" in url and require_https:\n            try:\n                hive = cls.from_url(url, version=version, require_https=False)\n            except HiveLoadedOverHTTP as err:\n                hive = err.hive\n            raise HiveLoadedOverHTTP(url, hive)\n        else:\n            try:\n                return cls(**download_as_json(url)).from_version(version, require_https)\n            except (ResponseException, URLError):\n                raise MissingHive(url)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new instance of the class from a domain.", "response": "def from_domain(cls, domain, version=None, require_https=True):\n        \"\"\"\n        Try to find a hive for the given domain; raise an error if we have to\n        failover to HTTP and haven't explicitly suppressed it in the call.\n        \"\"\"\n        url = 'https://' + domain + '/api/hive.json'\n        try:\n            return cls.from_url(url, version=version, require_https=require_https)\n        except MissingHive:\n            url = 'http://' + domain + '/api/hive.json'\n            return cls.from_url(url, version=version, require_https=require_https)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_version(self, version, require_https=False):\n        if version is None or self.version() == version:\n            return self\n        else:\n            return Hive.from_url(self.get_version_url(version), require_https=require_https)", "response": "Create a Hive object based on the version passed in."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_version_url(self, version):\n        for each_version in self.other_versions():\n            if version == each_version['version'] and 'location' in each_version:\n                return each_version.get('location')\n        raise VersionNotInHive(version)", "response": "Retrieve the URL for the designated version of the hive."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the map with a text marker", "response": "def tmarker(self, lat, long, text, color=None, icon=None, style=None):\n        \"\"\"\n        Returns the map with a text marker to the default map\n        \"\"\"\n        try:\n            self.dsmap = self._marker(\n                lat, long, text, self.dsmap, color, icon, True, style)\n            return self.dsmap\n        except Exception as e:\n            self.err(e, self.tmarker, \"Can not get text marker\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tmarker_(self, lat, long, text, pmap,\n                 color=None, icon=None, style=None):\n        \"\"\"\n        Returns the map with a text marker to the default map\n        \"\"\"\n        try:\n            xmap = self._marker(\n                lat, long, text, pmap, color, icon, True, style)\n            return xmap\n        except Exception as e:\n            self.err(e, self.tmarker_, \"Can not get text marker\")", "response": "Returns the map with a text marker"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef marker_(self, lat, long, text, pmap, color=None, icon=None):\n        try:\n            xmap = self._marker(lat, long, text, pmap, color, icon)\n            return xmap\n        except Exception as e:\n            self.err(e, self.marker_, \"Can not get marker\")", "response": "Returns the map with a marker"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef marker(self, lat, long, text, color=None, icon=None):\n        try:\n            self.dsmap = self._marker(lat, long, text, self.dsmap, color, icon)\n            return self.dsmap\n        except Exception as e:\n            self.err(e, self.marker, \"Can not get marker\")", "response": "Set the main map with a marker"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a marker to the default map", "response": "def _marker(self, lat, long, text, xmap, color=None, icon=None,\n                text_mark=False, style=None):\n        \"\"\"\n        Adds a marker to the default map\n        \"\"\"\n        kwargs = {}\n        if icon is not None:\n            kwargs[\"icon\"] = icon\n        if color is not None:\n            kwargs[\"color\"] = color\n        if style is None:\n            style = \"font-size:18pt;font-weight:bold;\" + \\\n                \"color:black;border-radius:0.5\"\n        try:\n            xicon1 = folium.Icon(**kwargs)\n            if text_mark is True:\n                xicon = DivIcon(\n                    icon_size=(150, 36),\n                    icon_anchor=(0, 0),\n                    html='<div style=\"' + style + '\">' + text + '</div>',\n                )\n                folium.Marker([lat, long], popup=text,\n                              icon=xicon).add_to(xmap)\n            folium.Marker([lat, long], popup=text,\n                          icon=xicon1).add_to(xmap)\n            return xmap\n        except Exception as e:\n            self.err(e, self._marker, \"Can not get marker\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a map object", "response": "def map_(self, lat, long, zoom=13, tiles=\"map\"):\n        \"\"\"\n        Returns a map\n        \"\"\"\n        try:\n            return self._map(lat, long, zoom, tiles)\n        except Exception as e:\n            self.err(e, self.map_, \"Can not get map\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a map object from the specified location and zoom", "response": "def _map(self, lat, long, zoom, tiles):\n        \"\"\"\n        Returns a map\n        \"\"\"\n        if tiles == \"map\":\n            tiles = \"OpenStreetMap\"\n        elif tiles == \"terrain\":\n            tiles = \"Stamen Terrain\"\n        elif tiles == \"basic\":\n            tiles = \"Stamen Toner\"\n        try:\n            xmap = folium.Map(\n                location=[lat, long],\n                tiles=tiles,\n                zoom_start=zoom\n            )\n            return xmap\n        except Exception as e:\n            self.err(e, self._map, \"Can not make map\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates an Optional Element.", "response": "def OE(element, value, transform=lambda x: x):\n    \"\"\"\n    Create an Optional Element.\n\n    Returns an Element as ElementMaker would, unless value is None. Optionally the value can be\n    transformed through a function.\n\n    >>> OE('elem', None)\n    None\n\n    >>> lxml.etree.tostring(OE('elem', 'value'))\n    <elem>value</elem>\n\n    >>> lxml.etree.tostring(OE('elem', True, int))\n    <elem>1</elem>\n    \"\"\"\n    return E(element, transform(value)) if value is not None else None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a function which calls _call_command for the given command_name.", "response": "def _make_command_method(cls, command_name):\n        \"\"\"\n        Return a function which call _call_command for the given name.\n        Used to bind redis commands to our own calls\n        \"\"\"\n        def func(self, *args, **kwargs):\n            return self._call_command(command_name, *args, **kwargs)\n        return func"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncall the specified command on the object.", "response": "def _call_command(self, name, *args, **kwargs):\n        \"\"\"\n        Check if the command to be executed is a modifier, to connect the object.\n        Then call _traverse_command.\n        \"\"\"\n        obj = getattr(self, '_instance', self)  # _instance if a field, self if an instance\n\n        # The object may not be already connected, so if we want to update a\n        # field, connect it before.\n        # If the object as no PK yet, let the object create itself\n        if name in self.available_modifiers and obj._pk and not obj.connected:\n            obj.connect()\n\n        #\u00a0Give priority to a \"_call_{commmand}\" method\n        meth = getattr(self, '_call_%s' % name, self._traverse_command)\n        return meth(name, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _traverse_command(self, name, *args, **kwargs):\n        if not name in self.available_commands:\n            raise AttributeError(\"%s is not an available command for %s\" %\n                                 (name, self.__class__.__name__))\n        attr = getattr(self.connection, \"%s\" % name)\n        key = self.key\n        log.debug(u\"Requesting %s with key %s and args %s\" % (name, key, args))\n        result = attr(key, *args, **kwargs)\n        result = self.post_command(\n            sender=self,\n            name=name,\n            result=result,\n            args=args,\n            kwargs=kwargs\n        )\n        return result", "response": "Traverse the command list and call the Redis command."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef key(self):\n        return self.make_key(\n            self._instance._name,\n            self._instance.pk.get(),\n            self.name,\n        )", "response": "A property to return the key used in redis for the current field."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalls after we got the result of a redis command.", "response": "def post_command(self, sender, name, result, args, kwargs):\n        \"\"\"\n        Call after we got the result of a redis command.\n        By default, let the instance manage the post_modify signal\n        \"\"\"\n        return self._instance.post_command(\n                   sender=self,\n                   name=name,\n                   result=result,\n                   args=args,\n                   kwargs=kwargs\n               )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef exists(self):\n        try:\n            key = self.key\n        except DoesNotExist:\n            \"\"\"\n            If the object doesn't exists anymore, its PK is deleted, so the\n            \"self.key\" call will raise a DoesNotExist exception. We catch it\n            to return False, as the field doesn't exists too.\n            \"\"\"\n            return False\n        else:\n            return self.connection.exists(key)", "response": "Check if the redis key exists for the current object"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _indexes(self):\n        if not self.indexable:\n            return []\n        if not self.index_classes:\n            self.index_classes = self.get_default_indexes()[::1]\n        if not self.index_classes:\n            raise ImplementationError('%s field is indexable but has no indexes attached' %\n                                      self.__class__.__name__)\n\n        return [index_class(field=self) for index_class in self.index_classes]", "response": "Instantiate the indexes only when asked\n            is not indexable."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntelling if the current field has an index matching the current one", "response": "def has_index(self, index):\n        \"\"\"Tells if the field have an index matching the current one\n\n        Parameters\n        -----------\n        index: type or BaseIndex\n            It could be an index instance, or an index class\n\n        Returns\n        -------\n        bool\n            Will be ``True`` if the current field has an index that is an instance\n            of the given index or of the class of the given index\n\n        \"\"\"\n        klass = index if isclass(index) else index.__class__\n        for one_index in self._indexes:\n            if isinstance(one_index, klass):\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _attach_to_instance(self, instance):\n        self._instance = instance\n        self.lockable = self.lockable and instance.lockable", "response": "Attach the current field to an instance of a model."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntells if the current field is the one attached to the model not instance", "response": "def attached_to_model(self):\n        \"\"\"Tells if the current field is the one attached to the model, not instance\"\"\"\n        try:\n            if not bool(self._model):\n                return False\n        except AttributeError:\n            return False\n        else:\n            try:\n                return not bool(self._instance)\n            except AttributeError:\n                return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncall the command with the specified name and arguments.", "response": "def _call_command(self, name, *args, **kwargs):\n        \"\"\"\n        Add lock management and call parent.\n        \"\"\"\n        meth = super(RedisField, self)._call_command\n        if self.indexable and name in self.available_modifiers:\n            with FieldLock(self):\n                try:\n                    result = meth(name, *args, **kwargs)\n                except:\n                    self._rollback_indexes()\n                    raise\n                else:\n                    return result\n                finally:\n                    self._reset_indexes_caches()\n        else:\n            return meth(name, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clear_indexes(self, chunk_size=1000, aggressive=False, index_class=None):\n        assert self.indexable, \"Field not indexable\"\n        assert self.attached_to_model, \\\n            '`rebuild_indexes` can only be called on a field attached to the model'\n\n        for index in self._indexes:\n            if index_class and not isinstance(index, index_class):\n                continue\n            index.clear(chunk_size=chunk_size, aggressive=aggressive)", "response": "Clear all indexes tied to this field."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rebuild_indexes(self, chunk_size=1000, aggressive_clear=False, index_class=None):\n        assert self.indexable, \"Field not indexable\"\n        assert self.attached_to_model, \\\n            '`rebuild_indexes` can only be called on a field attached to the model'\n\n        for index in self._indexes:\n            if index_class and not isinstance(index, index_class):\n                continue\n            index.rebuild(chunk_size=chunk_size, aggressive_clear=aggressive_clear)", "response": "Rebuild all indexes tied to this field."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _call_setnx(self, command, value):\n        result = self._traverse_command(command, value)\n        if self.indexable and value is not None and result:\n            self.index(value)\n        return result", "response": "Helper function to call the setnx command."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _rem(self, command, *args, **kwargs):\n        if self.indexable:\n            self.deindex(args)\n        return self._traverse_command(command, *args, **kwargs)", "response": "Shortcut for commands that only remove values from the field."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nindexing all values stored in the field or only given ones if any.", "response": "def index(self, values=None, only_index=None):\n        \"\"\"\n        Index all values stored in the field, or only given ones if any.\n        \"\"\"\n        assert self.indexable, \"Field not indexable\"\n        assert not only_index or self.has_index(only_index), \"Invalid index\"\n        if only_index:\n            only_index = only_index if isclass(only_index) else only_index.__class__\n\n        if values is None:\n            values = self.proxy_get()\n\n        for value in values:\n            if value is not None:\n                needs_to_check_uniqueness = bool(self.unique)\n\n                for index in self._indexes:\n                    if only_index and not isinstance(index, only_index):\n                        continue\n\n                    index.add(value, check_uniqueness=needs_to_check_uniqueness and index.handle_uniqueness)\n\n                    if needs_to_check_uniqueness and index.handle_uniqueness:\n                        # uniqueness check is done for this value\n                        needs_to_check_uniqueness = False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _call_zincrby(self, command, value, *args, **kwargs):\n        if self.indexable:\n            self.index([value])\n        return self._traverse_command(command, value, *args, **kwargs)", "response": "This is the main entry point for zincrby."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef coerce_zadd_args(*args, **kwargs):\n        values_callback = kwargs.pop('values_callback', None)\n\n        pieces = []\n        if args:\n            if len(args) % 2 != 0:\n                raise RedisError(\"ZADD requires an equal number of \"\n                                 \"values and scores\")\n            pieces.extend(args)\n\n        for pair in iteritems(kwargs):\n            pieces.append(pair[1])\n            pieces.append(pair[0])\n\n        values = pieces[1::2]\n        if values_callback:\n            values = values_callback(*values)\n\n        scores = pieces[0::2]\n\n        pieces = []\n        for z in zip(scores, values):\n            pieces.extend(z)\n\n        return pieces", "response": "Coerce arguments attended by a zadd call and return a flat list of the names that can be used."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _pushx(self, command, *args, **kwargs):\n        result = self._traverse_command(command, *args, **kwargs)\n        if self.indexable and result:\n            self.index(args)\n        return result", "response": "Helper for lpushx and rpushx that only index the new values if the list\n        existed when the command was called."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _call_lrem(self, command, count, value, *args, **kwargs):\n        if not count:\n            if self.indexable:\n                self.deindex([value])\n            return self._traverse_command(command, count, value, *args, **kwargs)\n        else:\n            return self._reset(command, count, value, *args, **kwargs)", "response": "Internal method to call the _reset method of the _traverse_command method."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef deindex(self, values=None, only_index=None):\n        assert self.indexable, \"Field not indexable\"\n        assert not only_index or self.has_index(only_index), \"Invalid index\"\n        if only_index:\n            only_index = only_index if isclass(only_index) else only_index.__class__\n\n        if values is None:\n            values = self.proxy_get()\n        for field_name, value in iteritems(values):\n            if value is not None:\n                for index in self._indexes:\n                    if only_index and not isinstance(index, only_index):\n                        continue\n                    index.remove(field_name, value)", "response": "Deal with dicts and field names."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef hexists(self, key):\n        try:\n            hashkey = self.key\n        except DoesNotExist:\n            \"\"\"\n            If the object doesn't exists anymore, its PK is deleted, so the\n            \"self.key\" call will raise a DoesNotExist exception. We catch it\n            to return False, as the field doesn't exists too.\n            \"\"\"\n            return False\n        else:\n            return self.connection.hexists(hashkey, key)", "response": "Check if the redis hash key exists for the given key"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _traverse_command(self, name, *args, **kwargs):\n        args = list(args)\n        args.insert(0, self.name)\n        return super(InstanceHashField, self)._traverse_command(name, *args, **kwargs)", "response": "Add the key AND the hash field to the args and call the Redis command."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef hexists(self):\n        try:\n            key = self.key\n        except DoesNotExist:\n            \"\"\"\n            If the object doesn't exists anymore, its PK is deleted, so the\n            \"self.key\" call will raise a DoesNotExist exception. We catch it\n            to return False, as the field doesn't exists too.\n            \"\"\"\n            return False\n        else:\n            return self.connection.hexists(key, self.name)", "response": "Check if the redis hash key exists for the current object"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _validate(self, value):\n        if value is None:\n            raise ValueError('The pk for %s is not \"auto-increment\", you must fill it' %\n                            self._model.__name__)\n        value = self.normalize(value)\n\n        # Check that this pk does not already exist\n        if self.exists(value):\n            raise UniquenessError('PKField %s already exists for model %s)' %\n                                  (value, self._instance.__class__))\n\n        return value", "response": "Validate that a given pk to set is always set and return it."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True if the given pk value exists for the given class.", "response": "def exists(self, value=None):\n        \"\"\"\n        Return True if the given pk value exists for the given class.\n        If no value is given, we use the value of the current field, which\n        is the value of the \"_pk\" attribute of its instance.\n        \"\"\"\n        try:\n            if not value:\n                value = self.get()\n        except (AttributeError, DoesNotExist):\n            # If the instance is deleted, the _pk attribute doesn't exist\n            # anymore. So we catch the AttributeError to return False (this pk\n            # field doesn't exist anymore) in this specific case\n            return False\n        else:\n            return self.connection.sismember(self.collection_key, value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set(self, value):\n        # Deny updating of an already set pk\n        if self._set:\n            raise ValueError('A primary key cannot be updated')\n\n        # Validate and return the value to be used as a pk\n        value = self._validate(value)\n\n        # Tell the model the pk is now set\n        self._instance._set_pk(value)\n        self._set = True\n\n        # We have a new pk, so add it to the collection\n        log.debug(\"Adding %s in %s collection\" % (value, self._model._name))\n        self.connection.sadd(self.collection_key, value)\n\n        # Finally return 1 as we did a real redis call to the set command\n        return 1", "response": "Set the value of the _pk attribute of the current instance."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the value of the current object.", "response": "def get(self):\n        \"\"\"\n        We do not call the default getter as we have the value cached in the\n        instance in its _pk attribute\n        \"\"\"\n        if not hasattr(self, '_instance'):\n            raise ImplementationError(\"Impossible to get the PK of an unbound field\")\n        if not hasattr(self._instance, '_pk'):\n            raise DoesNotExist(\"The current object doesn't exists anymore\")\n\n        if not self._instance._pk:\n            self.set(value=None)\n\n        return self.normalize(self._instance._pk)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nvalidates that a given pk is always set to None then return", "response": "def _validate(self, value):\n        \"\"\"\n        Validate that a given new pk to set is always set to None, then return\n        a new pk\n        \"\"\"\n        if value is not None:\n            raise ValueError('The pk for %s is \"auto-increment\", you must not fill it' %\n                            self._model.__name__)\n        key = self._instance.make_key(self._model._name, 'max_pk')\n        return self.normalize(self.connection.incr(key))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef release(self, *args, **kwargs):\n        if not self.field.lockable:\n            return\n        if self.sub_lock_mode:\n            return\n        super(FieldLock, self).release(*args, **kwargs)\n        self.already_locked_by_model = self.sub_lock_mode = False", "response": "Really release the lock only if it s not a sub - lock."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef handle_readable(client):\n\n    data = client.recv(1028)\n    if data == b'':\n        return False\n    client.sendall(b'SERVER: ' + data)\n    print(threading.active_count())\n    return True", "response": "Handle readable messages from the server."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new class with the given index classes.", "response": "def compose(cls, index_classes, key=None, transform=None, name=None):\n        \"\"\"Create a new class with the given index classes\n\n        Parameters\n        -----------\n        index_classes: list\n            The list of index classes to be used in the multi-index class to create\n        name: str\n            The name of the new multi-index class. If not set, it will be the same\n            as the current class\n        key: str\n            A key to augment the default key of each index, to avoid collision.\n        transform: callable\n            None by default, can be set to a function that will transform the value to be indexed.\n            This callable can accept one (`value`) or two (`self`, `value`) arguments\n\n        \"\"\"\n\n        attrs = {}\n        if index_classes:\n            attrs['index_classes'] = index_classes\n\n        klass = type(str(name or cls.__name__), (cls, ), attrs)\n\n        # let the ``configure`` method manage some fields\n        configure_attrs = {}\n        if key is not None:\n            configure_attrs['key'] = key\n        if transform is not None:\n            configure_attrs['transform'] = transform\n\n        if configure_attrs:\n            klass = klass.configure(**configure_attrs)\n\n        return klass"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntell if one of the managed indexes can handle the given suffix", "response": "def can_handle_suffix(self, suffix):\n        \"\"\"Tell if one of the managed indexes  can be used for the given filter prefix\n\n        For parameters, see BaseIndex.can_handle_suffix\n\n        \"\"\"\n        for index in self._indexes:\n            if index.can_handle_suffix(suffix):\n                return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprepares the list of arguments to be used by a sub - index.", "response": "def prepare_args(self, args, transform=True):\n        \"\"\"Prepare args to be used by a sub-index\n\n        Parameters\n        ----------\n        args: list\n            The while list of arguments passed to add, check_uniqueness, get_filtered_keys...\n        transform: bool\n            If ``True``, the last entry in `args`, ie the value, will be transformed.\n            Else it will be kept as is.\n\n        \"\"\"\n        updated_args = list(args)\n        if transform:\n            updated_args[-1] = self.transform_value(updated_args[-1])\n        if self.key:\n            updated_args.insert(-1, self.key)\n\n        return updated_args"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef check_uniqueness(self, *args):\n        self.get_unique_index().check_uniqueness(*self.prepare_args(args, transform=False))", "response": "Check if the given args are not used twice"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add(self, *args, **kwargs):\n\n        check_uniqueness = kwargs.pop('check_uniqueness', False)\n        args = self.prepare_args(args)\n\n        for index in self._indexes:\n            index.add(*args, check_uniqueness=check_uniqueness and index.handle_uniqueness, **kwargs)\n            if check_uniqueness and index.handle_uniqueness:\n                check_uniqueness = False", "response": "Add the instance tied to the field to all the indexes"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove(self, *args):\n\n        args = self.prepare_args(args)\n\n        for index in self._indexes:\n            index.remove(*args)", "response": "Remove the instance tied to the field from all the indexes"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_filtered_keys(self, suffix, *args, **kwargs):\n\n        args = self.prepare_args(args, transform=False)\n\n        for index in self._indexes:\n            if index.can_handle_suffix(suffix):\n                return index.get_filtered_keys(suffix, *args, **kwargs)", "response": "Returns the index keys to be used by the collection for the given suffix"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the set of all storage keys that are removed by clear in aggressive mode", "response": "def get_all_storage_keys(self):\n        \"\"\"Returns the keys to be removed by `clear` in aggressive mode\n\n        For the parameters, see BaseIndex.get_all_storage_keys\n        \"\"\"\n\n        keys = set()\n        for index in self._indexes:\n            keys.update(index.get_all_storage_keys())\n\n        return keys"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new multi - index class with the given info.", "response": "def configure(cls, **kwargs):\n        \"\"\"Create a new index class with the given info\n\n        This allow to avoid creating a new class when only few changes are\n        to be made\n\n        Parameters\n        ----------\n        kwargs: dict\n            prefix: str\n                The string part to use in the collection, before the normal suffix.\n                For example `foo` to filter on `myfiled__foo__eq=`\n                This prefix will also be used by the indexes to store the data at\n                a different place than the same index without prefix.\n            transform: callable\n                A function that will transform the value to be used as the reference\n                for the index, before the call to `normalize_value`.\n                If can be extraction of a date, or any computation.\n                The filter in the collection will then have to use a transformed value,\n                for example `birth_date__year=1976` if the transform take a date and\n                transform it to a year.\n            handle_uniqueness: bool\n                To make the index handle or not the uniqueness\n            key: str\n                To override the key used by the index. Two indexes for the same field of\n                the same type must not have the same key or data will be saved at the same place.\n                Note that the default key is None for `EqualIndex`, `text-range` for\n                `TextRangeIndex` and `number-range` for `NumberRangeIndex`\n            name: str\n                The name of the new multi-index class. If not set, it will be the same\n                as the current class\n\n        Returns\n        -------\n        type\n            A new class based on `cls`, with the new attributes set\n\n        \"\"\"\n\n        attrs = {}\n        for key in ('prefix', 'handle_uniqueness', 'key'):\n            if key in kwargs:\n                attrs[key] = kwargs.pop(key)\n\n        if 'transform' in kwargs:\n            attrs['transform'] = staticmethod(kwargs.pop('transform'))\n\n        name = kwargs.pop('name', None)\n\n        if kwargs:\n            raise TypeError('%s.configure only accepts these named arguments: %s' % (\n                cls.__name__,\n                ', '.join(('prefix', 'transform', 'handle_uniqueness', 'key', 'name')),\n            ))\n\n        return type((str if PY3 else oldstr)(name or cls.__name__), (cls, ), attrs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef can_handle_suffix(self, suffix):\n        try:\n            return self.remove_prefix(suffix) in self.handled_suffixes\n        except IndexError:\n            return False", "response": "Tells if the current index can handle the given filter suffix."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef normalize_value(self, value, transform=True):\n        if transform:\n            value = self.transform_value(value)\n        return str(self.field.from_python(value))", "response": "Normalizes the given value to be stored in the index\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef transform_value(self, value):\n        if not self.transform:\n            return value\n\n        try:\n            # we store a staticmethod but we accept a method taking `self` and `value`\n            return self.transform(self, value)\n        except TypeError as e:\n            if 'argument' in str(e):  # try to limit only to arguments error\n                return self.transform(value)", "response": "Convert the value to be stored."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves the class prefix from the suffix", "response": "def remove_prefix(cls, suffix):\n        \"\"\"\"Remove the class prefix from the suffix\n\n        The collection pass the full suffix used in the filters to the index.\n        But to know if it is valid, we have to remove the prefix to get the\n        real suffix, for example to check if the suffix is handled by the index.\n\n        Parameters\n        -----------\n        suffix: str\n            The full suffix to split\n\n        Returns\n        -------\n        str or None\n            The suffix without the prefix. None if the resting suffix is ''\n\n        Raises\n        ------\n        IndexError:\n            If the suffix doesn't contain the prefix\n\n        \"\"\"\n\n        if not cls.prefix:\n            return suffix\n        if cls.prefix == suffix:\n            return None\n        return (suffix or '').split(cls.prefix + '__')[1] or None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntells if the current index is the one attached to the model field not instance field", "response": "def attached_to_model(self):\n        \"\"\"Tells if the current index is the one attached to the model field, not instance field\"\"\"\n        try:\n            if not bool(self.model):\n                return False\n        except AttributeError:\n            return False\n        else:\n            try:\n                return not bool(self.instance)\n            except AttributeError:\n                return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _rollback(self):\n\n        # to avoid using self set that may be updated during the process\n        indexed_values = set(self._indexed_values)\n        deindexed_values = set(self._deindexed_values)\n\n        for args in indexed_values:\n            self.remove(*args)\n        for args in deindexed_values:\n            self.add(*args, check_uniqueness=False)", "response": "Restore the index in its previous state\n        This uses values that were indexed since the last call\n        to _reset_cache."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef assert_pks_uniqueness(self, pks, exclude, value):\n        pks = list(set(pks))\n        if len(pks) > 1:\n            # this may not happen !\n            raise UniquenessError(\n                \"Multiple values indexed for unique field %s.%s: %s\" % (\n                    self.model.__name__, self.field.name, pks\n                )\n            )\n        elif len(pks) == 1 and (not exclude or pks[0] != exclude):\n            self.connection.delete(self.field.key)\n            raise UniquenessError(\n                'Value \"%s\" already indexed for unique field %s.%s (for instance %s)' % (\n                    self.normalize_value(value), self.model.__name__, self.field.name, pks[0]\n                )\n            )", "response": "Check uniqueness of the pks."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nclearing all the values for the current instance of the current field.", "response": "def clear(self, chunk_size=1000, aggressive=False):\n        \"\"\"Will deindex all the value for the current field\n\n        Parameters\n        ----------\n        chunk_size: int\n            Default to 1000, it's the number of instances to load at once if not in aggressive mode.\n        aggressive: bool\n            Default to ``False``. When ``False``, the actual collection of instances will\n            be ran through to deindex all the values.\n            But when ``True``, the database keys will be scanned to find keys that matches the\n            pattern of the keys used by the index. This is a lot faster and may find forsgotten keys.\n            But may also find keys not related to the index.\n            Should be set to ``True`` if you are not sure about the already indexed values.\n\n        Raises\n        ------\n        AssertionError\n            If called from an index tied to an instance field. It must be called from the model field\n\n        Examples\n        --------\n\n        >>> MyModel.get_field('myfield')._indexes[0].clear()\n\n        \"\"\"\n        assert self.attached_to_model, \\\n            '`clear` can only be called on an index attached to the model field'\n\n        if aggressive:\n            keys = self.get_all_storage_keys()\n            with self.model.database.pipeline(transaction=False) as pipe:\n                for key in keys:\n                    pipe.delete(key)\n                pipe.execute()\n\n        else:\n            start = 0\n            while True:\n                instances = self.model.collection().sort().instances(skip_exist_test=True)[start:start + chunk_size]\n                for instance in instances:\n                    field = instance.get_instance_field(self.field.name)\n                    value = field.proxy_get()\n                    if value is not None:\n                        field.deindex(value, only_index=self)\n\n                if len(instances) < chunk_size:  # not enough data, it means we are done\n                    break\n\n                start += chunk_size"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rebuild(self, chunk_size=1000, aggressive_clear=False):\n        assert self.attached_to_model, \\\n            '`rebuild` can only be called on an index attached to the model field'\n\n        self.clear(chunk_size=chunk_size, aggressive=aggressive_clear)\n\n        start = 0\n        while True:\n            instances = self.model.collection().sort().instances(skip_exist_test=True)[start:start + chunk_size]\n            for instance in instances:\n                field = instance.get_instance_field(self.field.name)\n                value = field.proxy_get()\n                if value is not None:\n                    field.index(value, only_index=self)\n\n            if len(instances) < chunk_size:  # not enough data, it means we are done\n                break\n\n            start += chunk_size", "response": "Rebuild the whole index for this field."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the set used by the index for the given value", "response": "def get_filtered_keys(self, suffix, *args, **kwargs):\n        \"\"\"Return the set used by the index for the given \"value\" (`args`)\n\n        For the parameters, see ``BaseIndex.get_filtered_keys``\n\n        \"\"\"\n\n        accepted_key_types = kwargs.get('accepted_key_types', None)\n\n        if accepted_key_types and 'set' not in accepted_key_types:\n            raise ImplementationError(\n                '%s can only return keys of type \"set\"' % self.__class__.__name__\n            )\n\n        # special \"in\" case: we get n keys and make an unionstore with them then return this key\n        if suffix == 'in':\n\n            args = list(args)\n            values = set(args.pop())\n\n            if not values:\n                return []  # no keys\n\n            in_keys = [\n                self.get_storage_key(transform_value=False, *(args+[value]))\n                for value in values\n            ]\n\n            tmp_key = unique_key(self.connection)\n            self.connection.sunionstore(tmp_key, *in_keys)\n\n            return [(tmp_key, 'set', True)]\n\n        # do not transform because we already have the value we want to look for\n        return [(self.get_storage_key(transform_value=False, *args), 'set', False)]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_storage_key(self, *args, **kwargs):\n\n        args = list(args)\n        value = args.pop()\n\n        parts = [\n            self.model._name,\n            self.field.name,\n        ] + args\n\n        if self.prefix:\n            parts.append(self.prefix)\n\n        if self.key:\n            parts.append(self.key)\n\n        normalized_value = self.normalize_value(value, transform=kwargs.get('transform_value', True))\n\n        parts.append(normalized_value)\n\n        return self.field.make_key(*parts)", "response": "Return the redis key where to store the index for the given value."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the keys to be removed by clear in aggressive mode is the name of the field that is used in the index.", "response": "def get_all_storage_keys(self):\n        \"\"\"Returns the keys to be removed by `clear` in aggressive mode\n\n        For the parameters, see BaseIndex.get_all_storage_keys\n\n        \"\"\"\n\n        parts1 = [\n            self.model._name,\n            self.field.name,\n        ]\n\n        parts2 = parts1 + ['*']  # for indexes taking args, like for hashfields\n\n        if self.prefix:\n            parts1.append(self.prefix)\n            parts2.append(self.prefix)\n\n        if self.key:\n            parts1.append(self.key)\n            parts2.append(self.key)\n\n        parts1.append('*')\n        parts2.append('*')\n\n        return set(\n            self.model.database.scan_keys(self.field.make_key(*parts1))\n        ).union(\n            set(\n                self.model.database.scan_keys(self.field.make_key(*parts2))\n            )\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_uniqueness(self, *args, **kwargs):\n\n        if not self.field.unique:\n            return\n\n        key = kwargs.get('key', None)\n        if key is None:\n            key = self.get_storage_key(*args)\n\n        # Lets check if the index key already exist for another instance\n        pk = self.instance.pk.get()\n        pks = list(self.connection.smembers(key))\n\n        self.assert_pks_uniqueness(pks, pk, list(args)[-1])", "response": "Checks if the given value ( via args ) is unique or not."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd the instance tied to the field for the given value to the index.", "response": "def add(self, *args, **kwargs):\n        \"\"\"Add the instance tied to the field for the given \"value\" (via `args`) to the index\n\n        For the parameters, see ``BaseIndex.add``\n\n        \"\"\"\n\n        check_uniqueness = kwargs.get('check_uniqueness', True)\n\n        key = self.get_storage_key(*args)\n        if self.field.unique and check_uniqueness:\n            self.check_uniqueness(key=key, *args)\n\n        # Do index => create a key to be able to retrieve parent pk with\n        # current field value]\n        pk = self.instance.pk.get()\n        logger.debug(\"adding %s to index %s\" % (pk, key))\n        self.connection.sadd(key, pk)\n        self._indexed_values.add(tuple(args))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove(self, *args):\n\n        key = self.get_storage_key(*args)\n        pk = self.instance.pk.get()\n        logger.debug(\"removing %s from index %s\" % (pk, key))\n        self.connection.srem(key, pk)\n        self._deindexed_values.add(tuple(args))", "response": "Remove the instance tied to the field for the given value from the index."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_storage_key(self, *args):\n\n        args = list(args)\n        args.pop()  # final value, not needed for the storage key\n\n        parts = [\n            self.model._name,\n            self.field.name,\n        ] + args\n\n        if self.prefix:\n            parts.append(self.prefix)\n\n        if self.key:\n            parts.append(self.key)\n\n        return self.field.make_key(*parts)", "response": "Returns the redis key where to store the index for the given value."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_uniqueness(self, *args, **kwargs):\n\n        if not self.field.unique:\n            return\n\n        try:\n            pk = self.instance.pk.get()\n        except AttributeError:\n            pk = None\n\n        key = self.get_storage_key(*args)\n        value = list(args)[-1]\n        pks = self.get_pks_for_filter(key, 'eq', self.normalize_value(value))\n\n        self.assert_pks_uniqueness(pks, pk, value)", "response": "Check if the given value ( via args ) is unique or not."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add(self, *args, **kwargs):\n\n        check_uniqueness = kwargs.get('check_uniqueness', True)\n\n        if self.field.unique and check_uniqueness:\n            self.check_uniqueness(*args)\n\n        key = self.get_storage_key(*args)\n\n        args = list(args)\n        value = args[-1]\n\n        pk = self.instance.pk.get()\n        logger.debug(\"adding %s to index %s\" % (pk, key))\n        self.store(key, pk, self.prepare_value_for_storage(value, pk))\n        self._indexed_values.add(tuple(args))", "response": "Add the instance tied to the field for the given value to the index."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving the instance tied to the field for the given value from the index.", "response": "def remove(self, *args):\n        \"\"\"Remove the instance tied to the field for the given \"value\" (via `args`) from the index\n\n        For the parameters, see ``BaseIndex.remove``\n\n        Notes\n        -----\n        This method calls the ``unstore`` method that should be overridden in subclasses\n        to remove data from the index sorted-set key\n\n        \"\"\"\n\n        key = self.get_storage_key(*args)\n\n        args = list(args)\n        value = args[-1]\n\n        pk = self.instance.pk.get()\n        logger.debug(\"removing %s from index %s\" % (pk, key))\n        self.unstore(key, pk, self.prepare_value_for_storage(value, pk))\n        self._deindexed_values.add(tuple(args))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalling the lua script with given keys and args", "response": "def call_script(self, key, tmp_key, key_type, start, end, exclude, *args):\n        \"\"\"Call the lua scripts with given keys and args\n\n        Parameters\n        -----------\n        key: str\n            The key of the index sorted-set\n        tmp_key: str\n            The final temporary key where to store the filtered primary keys\n        key_type: str\n            The type of temporary key to use, either 'set' or 'zset'\n        start: str\n            The \"start\" argument to pass to the filtering sorted-set command\n        end: str\n            The \"end\" argument to pass to the filtering sorted-set command\n        exclude: any\n            A value to exclude from the filtered pks to save to the temporary key\n        args: list\n            Any other argument to be passed by a subclass will be passed as addition\n            args to the script.\n\n        \"\"\"\n        self.model.database.call_script(\n            # be sure to use the script dict at the class level\n            # to avoid registering it many times\n            script_dict=self.__class__.lua_filter_script,\n            keys=[key, tmp_key],\n            args=[key_type, start, end, exclude] + list(args)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_filtered_keys(self, suffix, *args, **kwargs):\n\n        accepted_key_types = kwargs.get('accepted_key_types', None)\n\n        if accepted_key_types\\\n                and 'set' not in accepted_key_types and 'zset' not in accepted_key_types:\n            raise ImplementationError(\n                '%s can only return keys of type \"set\" or \"zset\"' % self.__class__.__name__\n            )\n\n        key_type = 'set' if not accepted_key_types or 'set' in accepted_key_types else 'zset'\n        tmp_key = unique_key(self.connection)\n        args = list(args)\n\n        # special \"in\" case: we get n keys and make an unionstore with them then return this key\n        if suffix == 'in':\n\n            values = set(args.pop())\n\n            if not values:\n                return []  # no keys\n\n            in_keys = [\n                self.get_filtered_keys('eq', *(args+[value]), **kwargs)[0][0]\n                for value in values\n            ]\n\n            if key_type == 'set':\n                self.connection.sunionstore(tmp_key, *in_keys)\n            else:\n                self.connection.zunionstore(tmp_key, *in_keys)\n\n            # we can delete the temporary keys\n            for in_key in in_keys:\n                self.connection.delete(in_key)\n\n            return [(tmp_key, key_type, True)]\n\n        use_lua = self.model.database.support_scripting() and kwargs.get('use_lua', True)\n\n        key = self.get_storage_key(*args)\n        value = self.normalize_value(args[-1], transform=False)\n\n        real_suffix = self.remove_prefix(suffix)\n\n        if use_lua:\n            start, end, exclude = self.get_boundaries(real_suffix, value)\n            self.call_script(key, tmp_key, key_type, start, end, exclude)\n        else:\n            pks = self.get_pks_for_filter(key, real_suffix, value)\n            if pks:\n                if key_type == 'set':\n                    self.connection.sadd(tmp_key, *pks)\n                else:\n                    self.connection.zadd(tmp_key, **{pk: idx for idx, pk in enumerate(pks)})\n\n        return [(tmp_key, key_type, True)]", "response": "Returns the keys for the given args value."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprepares the value to be stored in the zset", "response": "def prepare_value_for_storage(self, value, pk):\n        \"\"\"Prepare the value to be stored in the zset\n\n        We'll store the value and pk concatenated.\n\n        For the parameters, see BaseRangeIndex.prepare_value_for_storage\n        \"\"\"\n        value = super(TextRangeIndex, self).prepare_value_for_storage(value, pk)\n        return self.separator.join([value, str(pk)])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _extract_value_from_storage(self, string):\n        parts = string.split(self.separator)\n        pk = parts.pop()\n        return self.separator.join(parts), pk", "response": "Taking a string that was a member of the zset extract the value and pk"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_boundaries(self, filter_type, value):\n\n        assert filter_type in self.handled_suffixes\n\n        start = '-'\n        end = '+'\n        exclude = None\n\n        if filter_type in (None, 'eq'):\n            # we include the separator to only get the members with the exact value\n            start = u'[%s%s' % (value, self.separator)\n            end = start.encode('utf-8') + b'\\xff'\n\n        elif filter_type == 'gt':\n            # starting at the value, excluded\n            start = u'(%s' % value\n            exclude = value\n\n        elif filter_type == 'gte':\n            # starting at the value, included\n            start = u'[%s' % value\n\n        elif filter_type == 'lt':\n            # ending with the value, excluded\n            end = u'(%s' % value\n            exclude = value\n\n        elif filter_type == 'lte':\n            # ending with the value, included (but not starting with, hence the separator)\n            end = u'[%s%s' % (value, self.separator)\n            end = end.encode('utf-8') + b'\\xff'\n\n        elif filter_type == 'startswith':\n            # using `\\xff` to simulate \"startswith\"\n            start = u'[%s' % value\n            end = start.encode('utf-8') + b'\\xff'\n\n        return start, end, exclude", "response": "Compute the boundaries to pass to zrangebylex depending of the filter type and the value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract the pks from the zset key for the given type and value", "response": "def get_pks_for_filter(self, key, filter_type, value):\n        \"\"\"Extract the pks from the zset key for the given type and value\n\n        For the parameters, see BaseRangeIndex.get_pks_for_filter\n        \"\"\"\n        start, end, exclude = self.get_boundaries(filter_type, value)\n        members = self.connection.zrangebylex(key, start, end)\n        if exclude is not None:\n            # special case where we don't want the exact given value, but we cannot\n            # exclude it from the sorted set directly\n            return [\n                member_pk\n                for member_value, member_pk in\n                [self._extract_value_from_storage(member) for member in members]\n                if member_value != exclude\n            ]\n        else:\n            return [self._extract_value_from_storage(member)[-1] for member in members]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalls the lua scripts with given keys and args", "response": "def call_script(self, key, tmp_key, key_type, start, end, exclude, *args):\n        \"\"\"Call the lua scripts with given keys and args\n\n        We add the separator to the arguments to be passed to the script\n\n        For the parameters, see BaseRangeIndex.call_script\n\n        \"\"\"\n\n        args = list(args)\n        args.append(self.separator)\n\n        super(TextRangeIndex, self).call_script(\n            key, tmp_key, key_type, start, end, exclude, *args\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef normalize_value(self, value, transform=True):\n        if transform:\n            value = self.transform_value(value)\n        try:\n            return float(value)\n        except (ValueError, TypeError):\n            if self.raise_if_not_float:\n                raise ValueError('Invalid value %s for field %s.%s' % (\n                    value, self.model.__name__, self.field.name\n                ))\n            return 0", "response": "Normalizes the given value to be stored in the index\n\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstores the value pk in the sorted set index", "response": "def store(self, key, pk, value):\n        \"\"\"Store the value/pk in the sorted set index\n\n        For the parameters, see BaseRangeIndex.store\n\n        We simple store the pk as a member of the sorted set with the value being the score\n        \"\"\"\n\n        self.connection.zadd(key, value, pk)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unstore(self, key, pk, value):\n\n        self.connection.zrem(key, pk)", "response": "Remove the value pk from the sorted set index\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes the boundaries to pass to the sorted - set command depending of the filter type and the value.", "response": "def get_boundaries(self, filter_type, value):\n        \"\"\"Compute the boundaries to pass to the sorted-set command depending of the filter type\n\n        The third return value, ``exclude`` is always ``None`` because we can easily restrict the\n        score to filter on in the sorted-set.\n\n        For the parameters, see BaseRangeIndex.store\n\n        Notes\n        -----\n        For zrangebyscore:\n        - `(` means \"not included\"\n        - `-inf` alone means \"from the very beginning\"\n        - `+inf` alone means \"to the very end\"\n        \"\"\"\n\n        assert filter_type in self.handled_suffixes\n\n        start = '-inf'\n        end = '+inf'\n        exclude = None\n\n        if filter_type in (None, 'eq'):\n            # only one score\n            start = end = value\n\n        elif filter_type == 'gt':\n            start = '(%s' % value\n\n        elif filter_type == 'gte':\n            start = value\n\n        elif filter_type == 'lt':\n            end = '(%s' % value\n\n        elif filter_type == 'lte':\n            end = value\n\n        return start, end, exclude"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nextracting the pks from the zset key for the given type and value", "response": "def get_pks_for_filter(self, key, filter_type, value):\n        \"\"\"Extract the pks from the zset key for the given type and value\n\n        For the parameters, see BaseRangeIndex.get_pks_for_filter\n        \"\"\"\n        start, end, __ = self.get_boundaries(filter_type, value)  # we have nothing to exclude\n        return self.connection.zrangebyscore(key, start, end)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwrapping to send posted scene command and get response", "response": "def scene_command(self, command):\n        \"\"\"Wrapper to send posted scene command and get response\"\"\"\n        self.logger.info(\"scene_command: Group %s Command %s\", self.group_id, command)\n        command_url = self.hub.hub_url + '/0?' + command + self.group_id + \"=I=0\"\n        return self.hub.post_direct_command(command_url)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nentering unlinking mode for a group", "response": "def enter_unlink_mode(self):\n        \"\"\"Enter unlinking mode for a group\"\"\"\n        self.logger.info(\"enter_unlink_mode Group %s\", self.group_id)\n        self.scene_command('0A')\n        # should send http://0.0.0.0/0?0A01=I=0\n\n        ## TODO check return status\n        status = self.hub.get_buffer_status()\n        return status"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cancel_link_unlink_mode(self):\n        self.logger.info(\"cancel_link_unlink_mode\")\n        self.scene_command('08')\n        # should send http://0.0.0.0/0?08=I=0\n\n        ## TODO check return status\n        status = self.hub.get_buffer_status()\n        return status", "response": "Cancel linking or unlinking mode"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _list_to_set(self, list_key, set_key):\n        if self.cls.database.support_scripting():\n            self.cls.database.call_script(\n                # be sure to use the script dict at the class level\n                # to avoid registering it many times\n                script_dict=self.__class__.scripts['list_to_set'],\n                keys=[list_key, set_key]\n            )\n        else:\n            conn = self.cls.get_connection()\n            conn.sadd(set_key, *conn.lrange(list_key, 0, -1))", "response": "Store all content of the given ListField in a redis set."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _collection(self):\n        old_sort_limits_and_len_mode = None if self._sort_limits is None else self._sort_limits.copy(), self._len_mode\n        old_sorts = None if self._sort is None else self._sort.copy(),\\\n                    None if self._sort_by_sortedset is None else self._sort_by_sortedset.copy()\n        try:\n            if self.stored_key and not self._stored_len:\n                if self._len_mode:\n                    self._len = 0\n                    self._len_mode = False\n                self._sort_limits = {}\n                return []\n\n            # Manage sort desc added by original `__getitem__` when we sort by score\n            if self._sort_by_sortedset and self._sort and self._sort.get('desc'):\n                self._sort = None\n                self._sort_by_sortedset['desc'] = not self._sort_by_sortedset.get('desc', False)\n\n            return super(ExtendedCollectionManager, self)._collection\n        finally:\n            self._sort_limits, self._len_mode = old_sort_limits_and_len_mode\n            self._sort, self._sort_by_sortedset = old_sorts", "response": "Return a list of all the items in the cache according to lazy_collection."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _prepare_sets(self, sets):\n\n        if self.stored_key and not self.stored_key_exists():\n            raise DoesNotExist('This collection is based on a previous one, '\n                               'stored at a key that does not exist anymore.')\n\n        conn = self.cls.get_connection()\n\n        all_sets = set()\n        tmp_keys = set()\n        lists = []\n\n        def add_key(key, key_type=None, is_tmp=False):\n            if not key_type:\n                key_type = conn.type(key)\n            if key_type == 'set':\n                all_sets.add(key)\n            elif key_type == 'zset':\n                all_sets.add(key)\n                self._has_sortedsets = True\n            elif key_type == 'list':\n                # if only one list, and no sets, at the end we'll directly use the list\n                # else lists will be converted to sets\n                lists.append(key)\n            elif key_type == 'none':\n                # considered as an empty set\n                 all_sets.add(key)\n            else:\n                raise ValueError('Cannot use redis key %s of type %s for filtering' % (\n                    key, key_type\n                ))\n            if is_tmp:\n                tmp_keys.add(key)\n\n        for set_ in sets:\n            if isinstance(set_, str):\n                add_key(set_)\n            elif isinstance(set_, ParsedFilter):\n\n                value = set_.value\n                # We have a RedisModel and we'll use its pk, or a RedisField\n                # (single value) and we'll use its value\n                if isinstance(value, RedisModel):\n                    value = value.pk.get()\n                elif isinstance(value, SingleValueField):\n                    value = value.proxy_get()\n                elif isinstance(value, RedisField):\n                    raise ValueError(u'Invalid filter value for %s: %s' % (set_.index.field.name, value))\n\n                for index_key, key_type, is_tmp in set_.index.get_filtered_keys(\n                            set_.suffix,\n                            accepted_key_types=self._accepted_key_types,\n                            *(set_.extra_field_parts + [value])\n                        ):\n                    if key_type not in self._accepted_key_types:\n                        raise ValueError('The index key returned by the index %s is not valid' % (\n                            set_.index.__class__.__name__\n                        ))\n                    add_key(index_key, key_type, is_tmp)\n\n            elif isinstance(set_, SetField):\n                # Use the set key. If we need to intersect, we'll use\n                # sunionstore, and if not, store accepts set\n                add_key(set_.key, 'set')\n            elif isinstance(set_, SortedSetField):\n                # Use the sorted set key. If we need to intersect, we'll use\n                # zinterstore, and if not, store accepts zset\n                add_key(set_.key, 'zset')\n            elif isinstance(set_, (ListField, _StoredCollection)):\n                add_key(set_.key, 'list')\n            elif isinstance(set_, tuple) and len(set_):\n                # if we got a list or set, create a redis set to hold its values\n                tmp_key = self._unique_key()\n                conn.sadd(tmp_key, *set_)\n                add_key(tmp_key, 'set', True)\n            else:\n                raise ValueError('Invalid filter type')\n\n        if lists:\n            if not len(all_sets) and len(lists) == 1:\n                # only one list, nothing else, we can return the list key\n                all_sets = {lists[0]}\n            else:\n                # we have many sets/lists, we need to convert them to sets\n                for list_key in lists:\n                    # many sets, convert the list to a simple redis set\n                    tmp_key = self._unique_key()\n                    self._list_to_set(list_key, tmp_key)\n                    add_key(tmp_key, 'set', True)\n\n        return all_sets, tmp_keys", "response": "This method is used to prepare the list of redis sets for the current instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef intersect(self, *sets):\n        sets_ = set()\n        for set_ in sets:\n            if isinstance(set_, (list, set)):\n                set_ = tuple(set_)\n            elif isinstance(set_, MultiValuesField) and not getattr(set_, '_instance', None):\n                raise ValueError('%s passed to \"intersect\" must be bound'\n                                 % set_.__class__.__name__)\n            elif not isinstance(set_, (tuple, str, MultiValuesField, _StoredCollection)):\n                raise ValueError('%s is not a valid type of argument that can '\n                                 'be used as a set. Allowed are: string (key '\n                                 'of a redis set, sorted set or list), '\n                                 'limpyd multi-values field ('\n                                 'SetField, ListField or SortedSetField), or '\n                                 'real python set, list or tuple' % set_)\n            if isinstance(set_, SortedSetField):\n                self._has_sortedsets = True\n            sets_.add(set_)\n\n        self._lazy_collection['intersects'].update(sets_)\n        return self", "response": "Returns a new object with the set of keys that are in the intersection of the sets."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _combine_sets(self, sets, final_set):\n        if self._has_sortedsets:\n            self.cls.get_connection().zinterstore(final_set, list(sets))\n        else:\n            final_set = super(ExtendedCollectionManager, self)._combine_sets(sets, final_set)\n        return final_set", "response": "Combine a list of sets into a single set."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the length of the final set without calling sort", "response": "def _collection_length(self, final_set):\n        \"\"\"\n        Return the length of the final collection, directly asking redis for the\n        count without calling sort\n        \"\"\"\n        conn = self.cls.get_connection()\n\n        # we have a sorted set without need to sort, use zcard\n        if self._has_sortedsets:\n            return conn.zcard(final_set)\n\n        # we have a stored collection, without other filter, use llen\n        elif self.stored_key and not self._lazy_collection['sets']\\\n                and len(self._lazy_collection['intersects']) == 1:\n\n            return conn.llen(final_set)\n\n        # normal call\n        return super(ExtendedCollectionManager, self)._collection_length(final_set)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsorts the extended collection by score.", "response": "def sort(self, **parameters):\n        \"\"\"\n        Enhance the default sort method to accept a new parameter \"by_score\", to\n        use instead of \"by\" if you want to sort by the score of a sorted set.\n        You must pass to \"by_sort\" the key of a redis sorted set (or a\n        sortedSetField attached to an instance)\n        \"\"\"\n        self._sort_by_sortedset = None\n        is_sortedset = False\n        if parameters.get('by_score'):\n            if parameters.get('by'):\n                raise ValueError(\"You can't use `by` and `by_score` in the same \"\n                                 \"call to `sort`.\")\n            by = parameters.get('by_score', None)\n            if isinstance(by, SortedSetField) and getattr(by, '_instance', None):\n                by = by.key\n            elif not isinstance(by, str):\n                by = None\n\n            if by is None:\n                raise ValueError('To sort by sorted set, you must pass a '\n                                 'SortedSetFied (attached to a model) or a '\n                                 'string representing the key of a redis zset '\n                                 'to the `by_score` named argument')\n            is_sortedset = True\n            parameters['by'] = by\n            del parameters['by_score']\n\n        else:\n            # allow passing a field, not only a field name\n            by = parameters.get('by')\n            if by and isinstance(by, RedisField):\n                parameters['by'] = by.name\n\n        super(ExtendedCollectionManager, self).sort(**parameters)\n\n        if is_sortedset:\n            self._sort_by_sortedset = self._sort\n            self._sort = None\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _zset_to_keys(self, key, values=None, alpha=False):\n        conn = self.cls.get_connection()\n        default = '' if alpha else '-inf'\n        if values is None:\n            # no values given, we get scores from the whole sorted set\n            result = conn.zrange(key, start=0, end=-1, withscores=True)\n            values = list(islice(chain.from_iterable(result), 0, None, 2))\n        else:\n            # we have values, we'll get only their scores\n\n            if isinstance(self.cls.database, PipelineDatabase):\n                # if available, use the pipeline of our database to get all\n                # scores in one redis call\n                with self.cls.database.pipeline(transaction=False) as pipe:\n                    for value in values:\n                        pipe.zscore(key, value)\n                    scores = pipe.execute()\n            else:\n                # no pipeline, we have to do a call for each value\n                scores = []\n                for value in values:\n                    scores.append(conn.zscore(key, value))\n\n            # combine values and scores in one list\n            result = []\n            for index, value in enumerate(values):\n                score = scores[index]\n                if score is None:\n                    score = default\n                result.append((value, score))\n\n        # create a temporary key for each (value,score) tuple\n        base_tmp_key = self._unique_key()\n        conn.set(base_tmp_key, 'working...')  # only to \"reserve\" the main tmp key\n        tmp_keys = []\n        # use a mapping dict (tmp_key_with_value=>score) to use in mset\n        mapping = {}\n        for value, score in result:\n            tmp_key = '%s:%s' % (base_tmp_key, value)\n            tmp_keys.append(tmp_key)\n            mapping[tmp_key] = score\n        # set all keys in one call\n        conn.mset(mapping)\n\n        return base_tmp_key, tmp_keys", "response": "Convert a redis sorted set to a list of keys to be used by sort."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _prepare_sort_by_score(self, values, sort_options):\n        # create the keys\n        base_tmp_key, tmp_keys = self._zset_to_keys(\n                                    key=self._sort_by_sortedset['by'],\n                                    values=values,\n                                    )\n        # ask to sort on our new keys\n        sort_options['by'] = '%s:*' % base_tmp_key\n\n        # retrieve original sort parameters\n        for key in ('desc', 'alpha', 'get', 'store'):\n            if key in self._sort_by_sortedset:\n                sort_options[key] = self._sort_by_sortedset[key]\n\n        # if we want to get the score with values/values_list\n        if sort_options.get('get'):\n            try:\n                pos = sort_options['get'].index(SORTED_SCORE)\n            except:\n                pass\n            else:\n                sort_options['get'][pos] = '%s:*' % base_tmp_key\n\n        return base_tmp_key, tmp_keys", "response": "Prepare the sort parameters for the new keys and the new keys based on the score of the original sort parameters."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _prepare_results(self, results):\n        # if we want a result sorted by a score, and if we have a full result\n        # (no slice), we can do it know, by creating keys for each values with\n        # the sorted set score, and sort on them\n        if self._sort_by_sortedset_after and (len(results) > 1 or self._values):\n            conn = self.cls.get_connection()\n\n            sort_params = {}\n            base_tmp_key, tmp_keys = self._prepare_sort_by_score(results, sort_params)\n\n            # compose the set to sort\n            final_set = '%s_final_set' % base_tmp_key\n            conn.sadd(final_set, *results)\n\n            # apply the sort\n            results = conn.sort(final_set, **sort_params)\n\n            # finally delete all temporary keys\n            conn.delete(*(tmp_keys + [final_set, base_tmp_key]))\n\n        if self._store:\n            # if store, redis doesn't return result, so don't return anything here\n            return\n\n        if self._values and self._values['mode'] != 'flat':\n            results = self._to_values(results)\n\n        return super(ExtendedCollectionManager, self)._prepare_results(results)", "response": "Sort results by score if not done before"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _to_values(self, collection):\n        result = zip(*([iter(collection)] * len(self._values['fields']['names'])))\n        if self._values['mode'] == 'dicts':\n            result = (dict(zip(self._values['fields']['names'], a_result)) for a_result in result)\n        return result", "response": "Regroup values in tuples or dicts for each instance."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if we have to sort by set and do the stuff before the sort", "response": "def _sort_by_sortedset_before(self):\n        \"\"\"\n        Return True if we have to sort by set and do the stuff *before* asking\n        redis for the sort\n        \"\"\"\n        return self._sort_by_sortedset and self._sort_limits and (not self._lazy_collection['pks']\n                                                            or self._want_score_value)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if we have to sort by set and do the stuff after the sort", "response": "def _sort_by_sortedset_after(self):\n        \"\"\"\n        Return True if we have to sort by set and do the stuff *after* asking\n        redis for the sort\n        \"\"\"\n        return self._sort_by_sortedset and not self._sort_limits and (not self._lazy_collection['pks']\n                                                                or self._want_score_value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprepares sort options for _values attributes.", "response": "def _prepare_sort_options(self, has_pk):\n        \"\"\"\n        Prepare sort options for _values attributes.\n        If we manager sort by score after getting the result, we do not want to\n        get values from the first sort call, but only from the last one, after\n        converting results in zset into keys\n        \"\"\"\n        sort_options = super(ExtendedCollectionManager, self)._prepare_sort_options(has_pk)\n\n        if self._values:\n            # if we asked for values, we have to use the redis 'sort'\n            # command, which is able to return other fields.\n            if not sort_options:\n                sort_options = {}\n            sort_options['get'] = self._values['fields']['keys']\n\n        if self._sort_by_sortedset_after:\n            for key in ('get', 'store'):\n                if key in self._sort_by_sortedset:\n                    del self._sort_by_sortedset[key]\n            if sort_options and (not has_pk or self._want_score_value):\n                for key in ('get', 'store'):\n                    if key in sort_options:\n                        self._sort_by_sortedset[key] = sort_options.pop(key)\n            if not sort_options:\n                sort_options = None\n        return sort_options"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds intersects fo sets and call parent's _get_final_set. If we have to sort by sorted score, and we have a slice, we have to convert the whole sorted set to keys now.", "response": "def _get_final_set(self, sets, pk, sort_options):\n        \"\"\"\n        Add intersects fo sets and call parent's _get_final_set.\n        If we have to sort by sorted score, and we have a slice, we have to\n        convert the whole sorted set to keys now.\n        \"\"\"\n        if self._lazy_collection['intersects']:\n            # if the intersect method was called, we had new sets to intersect\n            # to the global set of sets.\n            # And it there is no real filters, we had the set of the whole\n            # collection because we cannot be sure that entries in \"intersects\"\n            # are all real primary keys\n            sets = sets[::]\n            sets.extend(self._lazy_collection['intersects'])\n            if not self._lazy_collection['sets'] and not self.stored_key:\n                sets.append(self.cls.get_field('pk').collection_key)\n\n        final_set, keys_to_delete_later = super(ExtendedCollectionManager,\n                                    self)._get_final_set(sets, pk, sort_options)\n\n        # if we have a slice and we want to sort by the score of a sorted set,\n        # as redis sort command doesn't handle this, we have to create keys for\n        # each value of the sorted set and sort on them\n        # @antirez, y u don't allow this !!??!!\n        if final_set and self._sort_by_sortedset_before:\n            # TODO: if we have filters, maybe apply _zet_to_keys to only\n            #       intersected values\n            base_tmp_key, tmp_keys = self._prepare_sort_by_score(None, sort_options)\n            # new keys have to be deleted once the final sort is done\n            if not keys_to_delete_later:\n                keys_to_delete_later = []\n            keys_to_delete_later.append(base_tmp_key)\n            keys_to_delete_later += tmp_keys\n\n        return final_set, keys_to_delete_later"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _coerce_fields_parameters(self, fields):\n        try:\n            sorted_score_pos = fields.index(SORTED_SCORE)\n        except:\n            sorted_score_pos = None\n        else:\n            fields = list(fields)\n            fields.pop(sorted_score_pos)\n\n        final_fields = {'names': [], 'keys': []}\n        for field_name in fields:\n            if self._field_is_pk(field_name):\n                final_fields['names'].append(field_name)\n                final_fields['keys'].append('#')\n            else:\n                if not self.cls.has_field(field_name):\n                    raise ValueError(\"%s if not a valid field to get from collection\"\n                                     \" for %s\" % (field_name, self.cls.__name__))\n                field = self.cls.get_field(field_name)\n                if isinstance(field, MultiValuesField):\n                    raise ValueError(\"It's not possible to get a MultiValuesField\"\n                                     \" from a collection (asked: %s\" % field_name)\n                final_fields['names'].append(field_name)\n                final_fields['keys'].append(field.sort_wildcard)\n\n        if sorted_score_pos is not None:\n            final_fields['names'].insert(sorted_score_pos, SORTED_SCORE)\n            final_fields['keys'].insert(sorted_score_pos, SORTED_SCORE)\n\n        return final_fields", "response": "Coerce the parameters of the fields to a dict that can be used by values and values_list to retrieve the list of fields."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstore the result in Redis and returns a new version of the object.", "response": "def store(self, key=None, ttl=DEFAULT_STORE_TTL):\n        \"\"\"\n        Will call the collection and store the result in Redis, and return a new\n        collection based on this stored result. Note that only primary keys are\n        stored, ie calls to values/values_list are ignored when storing result.\n        But choices about instances/values_list are transmited to the new\n        collection.\n        If no key is given, a new one will be generated.\n        The ttl is the time redis will keep the new key. By default its\n        DEFAULT_STORE_TTL, which is 60 secondes. You can pass None if you don't\n        want expiration.\n        \"\"\"\n        old_sort_limits_and_len_mode = None if self._sort_limits is None else self._sort_limits.copy(), self._len_mode\n        try:\n            self._store = True\n\n            # save sort and values options\n            sort_options = None\n            if self._sort is not None:\n                sort_options = self._sort.copy()\n            values = None\n            if self._values is not None:\n                values = self._values\n                self._values = None\n\n            # create a key for storage\n            store_key = key or self._unique_key()\n            if self._sort is None:\n                self._sort = {}\n            self._sort['store'] = store_key\n\n            # if filter by pk, but without need to get \"values\", no redis call is done\n            # so force values to get a call to sort (to store result)\n            if self._lazy_collection['pks'] and not self._values:\n                self.values('pk')\n\n            # call the collection\n            self._len_mode = False\n            self._collection\n\n            # restore sort and values options\n            self._store = False\n            self._sort = sort_options\n            self._values = values\n\n            # create the new collection\n            stored_collection = self.__class__(self.cls)\n            stored_collection.from_stored(store_key)\n\n            # apply ttl if needed\n            if ttl is not None:\n                self.cls.get_connection().expire(store_key, ttl)\n\n            # set choices about instances/values from the current to the new collection\n            for attr in ('_instances', '_instances_skip_exist_test', '_values'):\n                setattr(stored_collection, attr, deepcopy(getattr(self, attr)))\n\n            # finally return the new collection\n            return stored_collection\n\n        finally:\n            self._sort_limits, self._len_mode = old_sort_limits_and_len_mode"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_stored(self, key):\n        # only one stored key allowed\n        if self.stored_key:\n            raise ValueError('This collection is already based on a stored one')\n\n        # prepare the collection\n        self.stored_key = key\n        self.intersect(_StoredCollection(self.cls.get_connection(), key))\n        self.sort(by='nosort')  # keep stored order\n\n        # count the number of results to manage empty result (to not behave like\n        # expired key)\n        self._stored_len = self.cls.get_connection().llen(key)\n\n        return self", "response": "Set the current collection as based on a stored one."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nask the collection to return a list of dict of given fields for each available each instance found in the collection.", "response": "def values(self, *fields):\n        \"\"\"\n        Ask the collection to return a list of dict of given fields for each\n        instance found in the collection.\n        If no fields are given, all \"simple value\" fields are used.\n        \"\"\"\n        if not fields:\n            fields = self._get_simple_fields()\n\n        fields = self._coerce_fields_parameters(fields)\n\n        self._instances = False\n        self._values = {'fields': fields, 'mode': 'dicts'}\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nasking the collection to return a list of tuples of given fields in the current object.", "response": "def values_list(self, *fields, **kwargs):\n        \"\"\"\n        Ask the collection to return a list of tuples of given fields (in the\n        given order) for each instance found in the collection.\n        If 'flat=True' is passed, the resulting list will be flat, ie without\n        tuple. It's a valid kwarg only if only one field is given.\n        If no fields are given, all \"simple value\" fields are used.\n        \"\"\"\n        flat = kwargs.pop('flat', False)\n        if kwargs:\n            raise ValueError('Unexpected keyword arguments for the values method: %s'\n                             % list(kwargs))\n\n        if not fields:\n            fields = self._get_simple_fields()\n\n        if flat and len(fields) > 1:\n            raise ValueError(\"'flat' is not valid when values is called with more than one field.\")\n\n        fields = self._coerce_fields_parameters(fields)\n\n        self._instances = False\n        self._values = {'fields': fields, 'mode': 'flat' if flat else 'tuples'}\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_metadata(filename, scan, paramfile='', **kwargs):\n\n    # create primary state dictionary\n    d = {}\n\n    # set misc params\n    d['filename'] = os.path.abspath(filename.rstrip('/'))\n    d['workdir'] = os.path.dirname(d['filename'])\n\n    # define parameters of pipeline via Params object\n    params = pp.Params(paramfile)\n    for k in params.defined:   # fill in default params\n        d[k] = params[k]\n\n    # overload with provided kwargs\n    for key in kwargs.keys():\n        logger.info('Setting %s to %s' % (key, kwargs[key]))\n        d[key] = kwargs[key]\n\n    assert d['read_fdownsample'] == 1, 'read_fdownsample not yet implemented for MS files.'\n\n    # read metadata either from pickle or ms file\n    pklname = d['filename'].rstrip('.ms') + '_init2.pkl'\n    if os.path.exists(pklname):\n        logger.debug('Initializing pickle found at %s.' % pklname)\n        pkl = open(pklname, 'r')\n        try:\n            stuff = pickle.load(pkl)\n        except EOFError:\n            logger.warn('Bad pickle file. Exiting...')\n            return 1\n\n        # load stuff into d\n        for key in stuff.keys():\n            d[key] = stuff[key]\n\n    else:\n        logger.debug('No initialization pickle found. Making anew...')\n\n        # find polarizations in MS\n        tb.open(d['filename']+'/POLARIZATION')\n        d['pols_orig'] = tb.getcol('CORR_TYPE').flatten()\n        d['npol_orig'] = len(d['pols_orig'])\n        tb.close()\n        tb.open(d['filename']+'/ANTENNA')\n        d['dishdiameter'] = tb.getcol('DISH_DIAMETER')[0]   # assume one diameter\n        tb.close()\n        \n        logger.debug('Opening %s...' % d['filename'])\n        # find spectral and scan info\n        ms.open(d['filename'])\n        md = ms.metadata()\n\n        # define ants and baselines\n        if 'VLA' in md.observatorynames()[0]:\n            d['ants'] = [int(md.antennanames(aa)[0][2:]) for aa in range(d['nants'])]\n        elif 'GMRT' in md.observatorynames()[0]:\n            d['ants'] = md.antennaids()\n\n        for ant in d['excludeants']:   # remove unwanted ants\n            d['ants'].remove(ant)\n        d['nants'] = len(d['ants'])\n\n#        d['nbl'] = md.nbaselines()\n#        d['blarr'] = n.array([[d['ants'][i],d['ants'][j]] for i in range(d['nants'])  for j in range(i+1, d['nants'])])\n        # find spw info\n        d['scans'] = md.scannumbers()\n\n        # find scan info\n        d['scansummary'] = ms.getscansummary()\n        scanlist = sorted(d['scansummary'].keys())\n\n        # find data structure\n        logger.debug('Reading a little data from each scan...')\n        nints_snip = 10\n        orig_spws_all = {}; freq_orig_all = {}\n        urange = {}; vrange = {}\n        for ss in scanlist:\n            # compile spws per scan\n            orig_spws0 = md.spwsforscan(int(ss))\n            orig_spws_all[ss] = [sorted(zip(orig_spws0, [md.chanfreqs(spw0)[0]/1e9 for spw0 in orig_spws0]), key=lambda ss:ss[1])[i][0] for i in range(len(orig_spws0))]\n            ff = n.array([])\n            for spw0 in orig_spws0:\n                ff = n.concatenate( (ff, md.chanfreqs(spw0)/1e9) ).astype('float32')   # save freq in GHzx\n            freq_orig_all[ss] = ff\n\n            # compile times per scan\n            starttime_mjd0 = d['scansummary'][ss]['0']['BeginTime']\n            inttime0 = d['scansummary'][ss]['0']['IntegrationTime']\n            starttime = qa.getvalue(qa.convert(qa.time(qa.quantity(starttime_mjd0,'d'),form=['ymd'], prec=9)[0], 's'))[0]\n            stoptime = qa.getvalue(qa.convert(qa.time(qa.quantity(starttime_mjd0+(nints_snip*inttime0)/(24.*60*60), 'd'), form=['ymd'], prec=9)[0], 's'))[0]  # nints+1 to be avoid buffer running out and stalling iteration\n            selection = {'time': [starttime, stoptime], 'uvdist': [1., 1e10]}    # exclude auto-corrs\n\n            # get uv data\n            ms.selectinit(datadescid=0)  # reset select params for later data selection\n            ms.select(items = selection)\n            ms.iterinit(['TIME'], nints_snip*inttime0)  # read 10 ints\n            ms.iterorigin()\n            da = ms.getdata(['axis_info', 'u', 'v', 'w'])\n            urange[ss] = da['u'].max() - da['u'].min()\n            vrange[ss] = da['v'].max() - da['v'].min()\n        d['urange'] = urange\n        d['vrange'] = vrange\n        d['freq_orig_all'] = freq_orig_all\n        d['orig_spws_all'] = orig_spws_all\n\n        ms.close()\n        # save initialization to pickle\n        pkl = open(pklname, 'wb')\n        pickle.dump((d), pkl)\n        pkl.close()\n\n    ### Now extract refine info for given scan, chans, etc. ###\n\n    if datacol:\n        d['datacol'] = datacol\n    elif not datacol:\n        d['datacol'] = 'data'\n\n    # refine pols info\n    pols = []\n    for pol in d['pols_orig']:\n        if len(selectpol):  # if lesser set is requested, filter here\n            if casautil.pol_names[pol] in selectpol:\n                pols.append(casautil.pol_names[pol])\n        else:\n            pols.append(casautil.pol_names[pol])\n    d['pols'] = pols\n    d['npol'] = len(pols)\n\n    # refine spw/freq info\n    d['scan'] = int(scanlist[scan])\n    d['orig_spws'] = n.array(d['orig_spws_all'][scanlist[scan]])\n    if len(d['spw']):\n        d['spwlist'] = d['orig_spws'][spw]\n    elif len(d['spw']):\n        d['spwlist'] = d['orig_spws'][d['spw']]\n    else:\n        d['spwlist'] = d['orig_spws']\n\n    d['spw'] = sorted(d['spwlist'])\n    allfreq = d['freq_orig_all'][scanlist[scan]]\n    chperspw = len(allfreq)/len(d['orig_spws'])\n    spwch = []\n    for ss in d['orig_spws']:\n        if ss in d['spwlist']:\n            spwch.extend(range(ss*chperspw, (ss+1)*chperspw))\n    d['freq_orig'] = allfreq[spwch]\n           \n    d['nspw'] = len(d['spwlist'])\n\n    if len(d['chans']):\n        d['freq'] = d['freq_orig'][chans]\n        d['chans'] = chans\n    elif len(d['chans']):\n        d['freq'] = d['freq_orig'][d['chans']]\n    else:\n        d['freq'] = d['freq_orig']\n        d['chans'] = range(len(d['freq']))\n    d['nchan'] = len(d['freq'])\n\n    # define integrations for given scan\n    d['nints'] = d['scansummary'][scanlist[scan]]['0']['nRow']/(d['nbl']*d['npol'])\n    inttime0 = d['scansummary'][scanlist[scan]]['0']['IntegrationTime'] # estimate of inttime from first scan\n\n    # define ideal res/npix\n    d['uvres_full'] = n.round(d['dishdiameter']/(3e-1/d['freq'].min())/2).astype('int')    # delay beam larger than VLA field of view at all freqs. assumes freq in GHz.\n    # **this may let vis slip out of bounds. should really define grid out to 2*max(abs(u)) and 2*max(abs(v)). in practice, very few are lost.**\n    urange = d['urange'][scanlist[scan]]*d['freq'].max() * (1e9/3e8)\n    vrange = d['vrange'][scanlist[scan]]*d['freq'].max() * (1e9/3e8)\n    powers = n.fromfunction(lambda i,j: 2**i*3**j, (14,10), dtype='int')   # power array for 2**i * 3**j\n    rangex = n.round(d['uvoversample']*urange).astype('int')\n    rangey = n.round(d['uvoversample']*vrange).astype('int')\n    largerx = n.where(powers-rangex/d['uvres_full'] > 0, powers, powers[-1,-1])\n    p2x, p3x = n.where(largerx == largerx.min())\n    largery = n.where(powers-rangey/d['uvres_full'] > 0, powers, powers[-1,-1])\n    p2y, p3y = n.where(largery == largery.min())\n    d['npixx_full'] = (2**p2x * 3**p3x)[0]\n    d['npixy_full'] = (2**p2y * 3**p3y)[0]\n\n    # define times\n    d['starttime_mjd'] = d['scansummary'][scanlist[scan]]['0']['BeginTime']\n    d['inttime'] = d['scansummary'][scanlist[scan]]['0']['IntegrationTime']\n\n    # summarize metadata\n    logger.info('')\n    logger.info('Metadata summary:')\n    logger.info('\\t Using scan %d (index %d)' % (d['scan'], scan))\n    logger.info('\\t nants, nbl: %d, %d' % (d['nants'], d['nbl']))\n    logger.info('\\t mid-freq, nspw, nchan: %.3f, %d, %d' % (d['freq'].mean(), d['nspw'], d['nchan']))\n    logger.info('\\t inttime: %.3f s' % (d['inttime']))\n    logger.info('\\t %d polarizations: %s' % (d['npol'], d['pols']))\n    logger.info('\\t Ideal uvgrid npix=(%d,%d) and res=%d' % (d['npixx_full'], d['npixy_full'], d['uvres_full']))\n\n    return d", "response": "Function to get metadata from pickle file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprepares to read data with ms. iter*", "response": "def readiterinit(d):\n    \"\"\" Prepare to read data with ms.iter*\n    \"\"\"\n\n    # set requested time range based on given parameters\n    starttime_mjd = d['starttime_mjd']\n    timeskip = d['inttime']*d['nskip']\n    starttime = qa.getvalue(qa.convert(qa.time(qa.quantity(starttime_mjd+timeskip/(24.*60*60),'d'),form=['ymd'], prec=9)[0], 's'))[0]\n    stoptime = qa.getvalue(qa.convert(qa.time(qa.quantity(starttime_mjd+(timeskip+(d['nints']+1)*d['inttime'])/(24.*60*60), 'd'), form=['ymd'], prec=9)[0], 's'))[0]  # nints+1 to be avoid buffer running out and stalling iteration\n    logger.debug('Time of first integration:', qa.time(qa.quantity(starttime_mjd,'d'),form=['ymd'],prec=9)[0])\n    logger.info('Reading times %s to %s in %d iterations' % (qa.time(qa.quantity(starttime_mjd+timeskip/(24.*60*60),'d'),form=['hms'], prec=9)[0], qa.time(qa.quantity(starttime_mjd+(timeskip+(d['nints']+1)*d['inttime'])/(24.*60*60), 'd'), form=['hms'], prec=9)[0], d['nthread']))\n\n    # read data into data structure\n    ms.open(d['filename'])\n    if len(d['spwlist']) == 1:\n        ms.selectinit(datadescid=d['spwlist'][0])\n    else:\n        ms.selectinit(datadescid=0, reset=True)    # reset includes spw in iteration over time\n    selection = {'time': [starttime, stoptime], 'uvdist': [1., 1e10], 'antenna1': d['ants'], 'antenna2': d['ants']}    # exclude auto-corrs\n    ms.select(items = selection)\n    ms.selectpolarization(d['pols'])\n    ms.iterinit(['TIME'], 0, d['iterint']*d['nbl']*d['nspw']*d['npol'], adddefaultsortcolumns=False)\n    iterstatus = ms.iterorigin()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread iteration of size iterint", "response": "def readiter(d):\n    \"\"\" Read iteration of size iterint\n    \"\"\"\n\n    da = ms.getdata([d['datacol'],'axis_info','u','v','w','flag','data_desc_id'], ifraxis=True)\n    good = n.where((da['data_desc_id']) == d['spwlist'][0])[0]   # take first spw                                                \n    time0 = da['axis_info']['time_axis']['MJDseconds'][good]\n    data0 = n.transpose(da[d['datacol']], axes=[3,2,1,0])[good]\n    flag0 = n.transpose(da['flag'], axes=[3,2,1,0])[good]\n    u0 = da['u'].transpose()[good] * d['freq_orig'][0] * (1e9/3e8)    # uvw are in m, so divide by wavelength of first chan to set in lambda\n    v0 = da['v'].transpose()[good] * d['freq_orig'][0] * (1e9/3e8)\n    w0 = da['w'].transpose()[good] * d['freq_orig'][0] * (1e9/3e8)\n\n    if len(d['spwlist']) > 1:\n        for spw in d['spwlist'][1:]:\n            good = n.where((da['data_desc_id']) == spw)[0]\n            data1 = n.transpose(da[d['datacol']], axes=[3,2,1,0])[good]\n            data0 = n.concatenate( (data0, data1), axis=2 )\n            flag0 = n.concatenate( (flag0, n.transpose(da['flag'], axes=[3,2,1,0])[good]), axis=2 )\n\n    del da\n    data0 = data0[:,:,d['chans'],:] * n.invert(flag0[:,:,d['chans'],:])   # flag==1 means bad data (for vla)                     \n    iterstatus = ms.iternext() \n\n    return data0.astype('complex64'), u0.astype('float32'), v0.astype('float32'), w0.astype('float32'), time0.astype('float32')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading a single segment into a sequence of objects.", "response": "def readsegment(d, segment):\n    \"\"\" Prepare to read segment of data\n    \"\"\"\n\n    # set requested time range based on given parameters\n    starttime = qa.getvalue(qa.convert(qa.time(qa.quantity(d['segmenttimes'][segment,0],'d'),form=['ymd'], prec=9)[0], 's'))[0]\n    stoptime = qa.getvalue(qa.convert(qa.time(qa.quantity(d['segmenttimes'][segment,1],'d'),form=['ymd'], prec=9)[0], 's'))[0]\n    logger.info('Reading segment %d/%d, times %s to %s' % (segment, len(d['segmenttimes'])-1, qa.time(qa.quantity(starttime/(24*3600),'d'),form=['hms'], prec=9)[0], qa.time(qa.quantity(stoptime/(24*3600), 'd'), form=['hms'], prec=9)[0]))\n\n    # read data into data structure\n    ms.open(d['filename'])\n    if len(d['spwlist']) == 1:\n        ms.selectinit(datadescid=d['spwlist'][0])\n    else:\n        ms.selectinit(datadescid=0, reset=True)    # reset includes spw in iteration over time\n    selection = {'time': [starttime, stoptime], 'uvdist': [1., 1e10]}\n#    selection = {'time': [starttime, stoptime], 'uvdist': [1., 1e10], 'antenna1': d['ants'], 'antenna2': d['ants']}    # **this misses ants for some reason!**\n    ms.select(items = selection)\n    ms.selectpolarization(d['pols'])\n    da = ms.getdata([d['datacol'],'axis_info','u','v','w','flag','data_desc_id'], ifraxis=True)\n    good = n.where((da['data_desc_id']) == d['spwlist'][0])[0]   # take first spw                                                \n    time0 = da['axis_info']['time_axis']['MJDseconds'][good]\n    data0 = n.transpose(da[d['datacol']], axes=[3,2,1,0])[good]\n    flag0 = n.transpose(da['flag'], axes=[3,2,1,0])[good]\n    u0 = da['u'].transpose()[good] * d['freq_orig'][0] * (1e9/3e8)    # uvw are in m, so divide by wavelength of first chan to set in lambda\n    v0 = da['v'].transpose()[good] * d['freq_orig'][0] * (1e9/3e8)\n    w0 = da['w'].transpose()[good] * d['freq_orig'][0] * (1e9/3e8)\n\n    if len(d['spwlist']) > 1:\n        for spw in d['spwlist'][1:]:\n            good = n.where((da['data_desc_id']) == spw)[0]\n            data1 = n.transpose(da[d['datacol']], axes=[3,2,1,0])[good]\n            data0 = n.concatenate( (data0, data1), axis=2 )\n            flag0 = n.concatenate( (flag0, n.transpose(da['flag'], axes=[3,2,1,0])[good]), axis=2 )\n\n    del da\n    data0 = data0[:,:,d['chans'],:] * n.invert(flag0[:,:,d['chans'],:])   # flag==1 means bad data (for vla)                     \n\n    return data0.astype('complex64'), u0.astype('float32'), v0.astype('float32'), w0.astype('float32')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef autocmds(namespace=None, args=None, command_suffix='_command',\n        add_dry_run_option=True, add_verbosity_option=True):\n    \"\"\"\n    Parse and run commands.\n    \n    Will search ``namespace`` for functions that end with ``command_suffix``.\n    \n    :param namespace: the namespace/module to search for commands\n    :param args: the arguments for the command parser. defaults to\n        :data:`sys.argv`\n    :param command_suffix: function name suffix that indicates that a\n        function is a command.\n    \"\"\"\n    if namespace is None:\n        namespace = inspect.currentframe().f_back.f_globals\n    elif type(namespace) is types.ModuleType:\n        namespace = namespace.__dict__\n    \n    if args is None:\n        args = sys.argv\n    \n    if len(args) < 2 or args[1] in ('-h', '--help'):\n        print_help(namespace, command_suffix)\n        return\n    \n    command_name = args.pop(1).replace('-', '_')\n    function = namespace[command_name + command_suffix]\n    parse_and_run_function(function, args, command_name,\n        add_dry_run_option=add_dry_run_option,\n        add_verbosity_option=add_verbosity_option)", "response": "Parse and run a command."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing a reStructuredText docstring and return a dictionary with parameter names and descriptions.", "response": "def parse_rst_params(doc):\n    \"\"\"\n    Parse a reStructuredText docstring and return a dictionary\n    with parameter names and descriptions. \n    \n    >>> doc = '''\n    ... :param foo: foo parameter\n    ...     foo parameter\n    ... \n    ...  :param bar: bar parameter\n    ...  :param baz: baz parameter\n    ...         baz parameter\n    ...     baz parameter\n    ...  Some text.\n    ... '''\n    >>> params = parse_rst_params(doc)\n    >>> params['foo']\n    'foo parameter foo parameter'\n    >>> params['bar']\n    'bar parameter'\n    >>> params['baz']\n    'baz parameter baz parameter baz parameter'\n    \"\"\"\n    param_re = re.compile(r\"\"\"^([ \\t]*):param\\ \n                              (?P<param>\\w+):\\ \n                              (?P<body>.*\\n(\\1[ \\t]+\\w.*\\n)*)\"\"\",\n                          re.MULTILINE|re.VERBOSE)\n    params = {}\n    for match in param_re.finditer(doc):\n        parts = match.groupdict()\n        body_lines = parts['body'].strip().split('\\n')\n        params[parts['param']] = ' '.join(s.strip() for s in body_lines)\n    \n    return params"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert django s LANGUAGE_CODE settings to a proper locale code.", "response": "def language_to_locale(language):\n    \"\"\"\n    Converts django's `LANGUAGE_CODE` settings to a proper locale code.\n    \"\"\"\n    tokens = language.split('-')\n    if len(tokens) == 1:\n        return tokens[0]\n    return \"%s_%s\" % (tokens[0], tokens[1].upper())"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef decorator(caller, func=None):\n    if func is None: # returns a decorator\n        fun = FunctionMaker(caller)\n        first_arg = inspect.getargspec(caller)[0][0]\n        src = 'def %s(%s): return _call_(caller, %s)' % (\n            caller.__name__, first_arg, first_arg)\n        return fun.make(src, dict(caller=caller, _call_=decorator),\n                        undecorated=caller)\n    else: # returns a decorated function\n        fun = FunctionMaker(func)\n        src = \"\"\"def %(name)s(%(signature)s):\n    return _call_(_func_, %(signature)s)\"\"\"\n        return fun.make(src, dict(_func_=func, _call_=caller), undecorated=func)", "response": "Decorator that converts a caller function into a decorator ;\nInsights decorator"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding input files and log initialization info", "response": "def initializenb():\n    \"\"\" Find input files and log initialization info \"\"\"\n\n    logger.info('Working directory: {0}'.format(os.getcwd()))\n    logger.info('Run on {0}'.format(asctime()))\n    try:\n        fileroot = os.environ['fileroot']\n        logger.info('Setting fileroot to {0} from environment variable.\\n'.format(fileroot))\n        candsfile = 'cands_{0}_merge.pkl'.format(fileroot)\n        noisefile = 'noise_{0}_merge.pkl'.format(fileroot)\n    except KeyError:\n        sdmdir = os.getcwd()\n        logger.info('Setting sdmdir to current directory {0}\\n'.format(os.path.abspath(sdmdir)))\n        candsfiles = glob.glob('cands_*_merge.pkl')\n        noisefiles = glob.glob('noise_*_merge.pkl')\n        if len(candsfiles) == 1 and len(noisefiles) == 1:\n            logger.info('Found one cands/merge file set')\n        else:\n            logger.warn('Found multiple cands/noise file sets. Taking first.')\n\n        candsfile = candsfiles[0]\n        noisefile = noisefiles[0]\n        fileroot = candsfile.rstrip('_merge.pkl').lstrip('cands_')\n    logger.info('Set: \\n\\t candsfile {} \\n\\t noisefile {} \\n\\t fileroot {} '.format(candsfile, noisefile, fileroot))\n    return (candsfile, noisefile, fileroot)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plot_interactive(mergepkl, noisepkl=None, thresh=6.0, thresh_link=7.0, ignoret=None, savehtml=True, url_path='plots'):\n\n    data = readdata(mergepkl)\n    circleinds = calcinds(data, thresh, ignoret)\n    crossinds = calcinds(data, -1*thresh, ignoret)\n    edgeinds = calcinds(data, thresh_link, ignoret)\n\n    workdir = os.path.dirname(mergepkl)\n    fileroot = os.path.basename(mergepkl).rstrip('_merge.pkl').lstrip('cands_')\n\n    logger.info('Total on target time: {} s'.format(calcontime(data, inds=circleinds+crossinds+edgeinds)))\n\n    if noisepkl:\n        noiseplot = plotnoisecum(noisepkl)\n    else:\n        noiseplot = None\n\n    combined = plotall(data, circleinds=circleinds, crossinds=crossinds, edgeinds=edgeinds,\n                       htmlname=None, noiseplot=noiseplot, url_path=url_path, fileroot=fileroot)\n\n    if savehtml:\n        output_file(mergepkl.rstrip('.pkl') + '.html')\n        save(combined)\n    else:\n        return combined", "response": "Backwards compatible function for making interactive candidate summary plot"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plotall(data, circleinds=[], crossinds=[], edgeinds=[], htmlname=None, noiseplot=None, url_path='plots', fileroot=None):\n\n    # set up data dictionary\n    if not circleinds: circleinds = calcinds(data, np.abs(data['snrs']).min())\n    if not crossinds: crossinds = calcinds(data, -1*np.abs(data['snrs']).min())\n\n    TOOLS = \"hover,tap,pan,box_select,wheel_zoom,reset\"\n\n    # set ranges\n    datalen = len(data['dm'])\n    inds = circleinds + crossinds + edgeinds\n    dm = [data['dm'][i] for i in inds]\n    dm_min = min(min(dm), max(dm)/1.2)\n    dm_max = max(max(dm), min(dm)*1.2)\n    time = [data['time'][i] for i in inds]\n    time_min = min(time)\n    time_max = max(time)\n    l1 = [data['l1'][i] for i in inds]\n    l1_min = min(l1)\n    l1_max = max(l1)\n    m1 = [data['m1'][i] for i in inds]\n    m1_min = min(m1)\n    m1_max = max(m1)\n    specstd = [data['specstd'][i] for i in inds]\n    specstd_min = min(specstd)\n    specstd_max = max(specstd)\n    imkur = [data['imkur'][i] for i in inds]\n    imkur_min = min(imkur)\n    imkur_max = max(imkur)\n\n    # create figures\n    dmt = Figure(plot_width=950, plot_height=500, toolbar_location=\"left\", x_axis_label='Time (s; relative)',\n                 y_axis_label='DM (pc/cm3)', x_range=(time_min, time_max), y_range=(dm_min, dm_max), \n                 output_backend='webgl', tools=TOOLS)\n    loc = Figure(plot_width=450, plot_height=400, toolbar_location=\"left\", x_axis_label='l1 (rad)', y_axis_label='m1 (rad)',\n                 x_range=(l1_min, l1_max), y_range=(m1_min,m1_max), tools=TOOLS, output_backend='webgl')\n    stat = Figure(plot_width=450, plot_height=400, toolbar_location=\"left\", x_axis_label='Spectral std',\n                  y_axis_label='Image kurtosis', x_range=(specstd_min, specstd_max), \n                  y_range=(imkur_min, imkur_max), tools=TOOLS, output_backend='webgl')\n    norm = Figure(plot_width=450, plot_height=400, toolbar_location=\"left\", x_axis_label='SNR observed',\n                  y_axis_label='SNR expected', tools=TOOLS, output_backend='webgl')\n\n    # create positive symbol source and add glyphs\n    source = ColumnDataSource(data = dict({(key, tuple([value[i] for i in circleinds if i not in edgeinds])) \n                                           for (key, value) in data.iteritems()}))\n    dmt.circle('time', 'dm', size='sizes', fill_color='colors', line_color=None, fill_alpha=0.2, source=source)\n    loc.circle('l1', 'm1', size='sizes', line_color=None, fill_color='colors', fill_alpha=0.2, source=source)\n    stat.circle('specstd', 'imkur', size='sizes', line_color=None, fill_color='colors', fill_alpha=0.2, source=source)\n    norm.circle('abssnr', 'zs', size='sizes', line_color=None, fill_color='colors', fill_alpha=0.2, source=source)\n\n    # create negative symbol source and add glyphs\n    if crossinds:\n        sourceneg = ColumnDataSource(data = dict({(key, tuple([value[i] for i in crossinds]))\n                                                  for (key, value) in data.iteritems()}))\n        dmt.cross('time', 'dm', size='sizes', fill_color='colors', line_alpha=0.3, source=sourceneg)\n        loc.cross('l1', 'm1', size='sizes', line_color='colors', line_alpha=0.3, source=sourceneg)\n        stat.cross('specstd', 'imkur', size='sizes', line_color='colors', line_alpha=0.3, source=sourceneg)\n        norm.cross('abssnr', 'zs', size='sizes', line_color='colors', line_alpha=0.3, source=sourceneg)\n\n    # create linked symbol source and add glyphs\n    if edgeinds:\n        sourceedge = ColumnDataSource(data = dict({(key, tuple([value[i] for i in edgeinds]))\n                                                   for (key, value) in data.iteritems()}))\n        dmt.circle('time', 'dm', size='sizes', line_color='colors', fill_color='colors', line_alpha=0.5, fill_alpha=0.2, source=sourceedge)\n        loc.circle('l1', 'm1', size='sizes', line_color='colors', fill_color='colors', source=sourceedge, line_alpha=0.5, fill_alpha=0.2)\n        stat.circle('specstd', 'imkur', size='sizes', line_color='colors', fill_color='colors', source=sourceedge, line_alpha=0.5, fill_alpha=0.2)\n        norm.circle('abssnr', 'zs', size='sizes', line_color='colors', fill_color='colors', source=sourceedge, line_alpha=0.5, fill_alpha=0.2)\n\n    hover = dmt.select(dict(type=HoverTool))\n    hover.tooltips = OrderedDict([('SNR', '@snrs'), ('key', '@key')])\n    hover = loc.select(dict(type=HoverTool))\n    hover.tooltips = OrderedDict([('SNR', '@snrs'), ('key', '@key')])\n    hover = stat.select(dict(type=HoverTool))\n    hover.tooltips = OrderedDict([('SNR', '@snrs'), ('key', '@key')])\n    hover = norm.select(dict(type=HoverTool))\n    hover.tooltips = OrderedDict([('SNR', '@snrs'), ('key', '@key')])\n\n    if url_path and fileroot:\n        url = '{}/cands_{}_@key.png'.format(url_path, fileroot)\n        taptool = dmt.select(type=TapTool)\n        taptool.callback = OpenURL(url=url)\n        taptool = loc.select(type=TapTool)\n        taptool.callback = OpenURL(url=url)\n        taptool = stat.select(type=TapTool)\n        taptool.callback = OpenURL(url=url)\n        taptool = norm.select(type=TapTool)\n        taptool.callback = OpenURL(url=url)\n\n# this approach does not preserve links between panels\n#    dmt = plotdmt(data, circleinds=circleinds, crossinds=crossinds, edgeinds=edgeinds, url_path=url_path, fileroot=fileroot, tools=TOOLS) # maybe add size?\n#    loc = plotloc(data, circleinds=circleinds, crossinds=crossinds, edgeinds=edgeinds, url_path=url_path, fileroot=fileroot, tools=TOOLS)\n#    stat = plotstat(data, circleinds=circleinds, crossinds=crossinds, edgeinds=edgeinds, url_path=url_path, fileroot=fileroot, tools=TOOLS)\n#    norm = plotnorm(data, circleinds=circleinds, crossinds=crossinds, edgeinds=edgeinds, url_path=url_path, fileroot=fileroot, tools=TOOLS)\n\n    # arrange figures\n    top = Row(dmt, width=950)\n    middle = Row(loc, stat, width=950)\n    if noiseplot:\n        bottom = Row(norm, noiseplot, width=950)\n    else:\n        bottom = Row(norm, width=950)\n    combined = Column(top, middle, bottom, width=950)\n\n    if htmlname:\n        output_file(htmlname)\n        save(combined)\n    else:\n        return combined", "response": "Create interactive plot from data dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmakes a light - weight dm - time figure", "response": "def plotdmt(data, circleinds=[], crossinds=[], edgeinds=[], url_path=None, fileroot=None,\n            tools=\"hover,tap,pan,box_select,wheel_zoom,reset\", plot_width=950, plot_height=500):\n    \"\"\" Make a light-weight dm-time figure \"\"\"\n\n    fields = ['dm', 'time', 'sizes', 'colors', 'snrs', 'key']\n\n    if not circleinds: circleinds = range(len(data['snrs']))\n\n    # set ranges\n    datalen = len(data['dm'])\n    inds = circleinds + crossinds + edgeinds\n    dm = [data['dm'][i] for i in inds]\n    dm_min = min(min(dm), max(dm)/1.2)\n    dm_max = max(max(dm), min(dm)*1.2)\n    time = [data['time'][i] for i in inds]\n    time_min = min(time)\n    time_max = max(time)\n\n    source = ColumnDataSource(data = dict({(key, tuple([value[i] for i in circleinds if i not in edgeinds])) \n                                           for (key, value) in data.iteritems() if key in fields}))\n    dmt = Figure(plot_width=plot_width, plot_height=plot_height, toolbar_location=\"left\", x_axis_label='Time (s; relative)',\n                 y_axis_label='DM (pc/cm3)', x_range=(time_min, time_max), y_range=(dm_min, dm_max), \n                 output_backend='webgl', tools=tools)\n    dmt.circle('time', 'dm', size='sizes', fill_color='colors', line_color=None, fill_alpha=0.2, source=source)\n\n    if crossinds:\n        sourceneg = ColumnDataSource(data = dict({(key, tuple([value[i] for i in crossinds]))\n                                                  for (key, value) in data.iteritems() if key in fields}))\n        dmt.cross('time', 'dm', size='sizes', fill_color='colors', line_alpha=0.3, source=sourceneg)\n\n    if edgeinds:\n        sourceedge = ColumnDataSource(data = dict({(key, tuple([value[i] for i in edgeinds]))\n                                                   for (key, value) in data.iteritems() if key in fields}))\n        dmt.circle('time', 'dm', size='sizes', line_color='colors', fill_color='colors', line_alpha=0.5, fill_alpha=0.2, source=sourceedge)\n    hover = dmt.select(dict(type=HoverTool))\n    hover.tooltips = OrderedDict([('SNR', '@snrs'), ('key', '@key')])\n\n    if url_path and fileroot:\n#        url = '{}/cands_{}_sc@scan-seg@seg-i@candint-dm@dmind-dt@dtind.png'.format(url_path, fileroot)\n        url = '{}/cands_{}_@key.png'.format(url_path, fileroot)\n        taptool = dmt.select(type=TapTool)\n        taptool.callback = OpenURL(url=url)\n\n    return dmt"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmake a light - weight loc figure.", "response": "def plotloc(data, circleinds=[], crossinds=[], edgeinds=[], url_path=None, fileroot=None,\n            tools=\"hover,tap,pan,box_select,wheel_zoom,reset\", plot_width=450, plot_height=400):\n    \"\"\" Make a light-weight loc figure \"\"\"\n\n    fields = ['l1', 'm1', 'sizes', 'colors', 'snrs', 'key']\n\n    if not circleinds: circleinds = range(len(data['snrs']))\n\n    # set ranges\n    datalen = len(data['dm'])\n    inds = circleinds + crossinds + edgeinds\n    l1 = [data['l1'][i] for i in inds]\n    l1_min = min(l1)\n    l1_max = max(l1)\n    m1 = [data['m1'][i] for i in inds]\n    m1_min = min(m1)\n    m1_max = max(m1)\n\n    source = ColumnDataSource(data = dict({(key, tuple([value[i] for i in circleinds if i not in edgeinds])) \n                                           for (key, value) in data.iteritems() if key in fields}))\n    loc = Figure(plot_width=plot_width, plot_height=plot_height, toolbar_location=\"left\", x_axis_label='l1 (rad)', y_axis_label='m1 (rad)',\n                 x_range=(l1_min, l1_max), y_range=(m1_min,m1_max), tools=tools, output_backend='webgl')\n    loc.circle('l1', 'm1', size='sizes', line_color=None, fill_color='colors', fill_alpha=0.2, source=source)\n\n    if crossinds:\n        sourceneg = ColumnDataSource(data = dict({(key, tuple([value[i] for i in crossinds]))\n                                                  for (key, value) in data.iteritems() if key in fields}))\n        loc.cross('l1', 'm1', size='sizes', line_color='colors', line_alpha=0.3, source=sourceneg)\n\n    if edgeinds:\n        sourceedge = ColumnDataSource(data = dict({(key, tuple([value[i] for i in edgeinds]))\n                                                   for (key, value) in data.iteritems() if key in fields}))\n        loc.circle('l1', 'm1', size='sizes', line_color='colors', fill_color='colors', source=sourceedge, line_alpha=0.5, fill_alpha=0.2)\n\n    hover = loc.select(dict(type=HoverTool))\n    hover.tooltips = OrderedDict([('SNR', '@snrs'), ('key', '@key')])\n\n    if url_path and fileroot:\n        url = '{}/cands_{}_@key.png'.format(url_path, fileroot)\n        taptool = loc.select(type=TapTool)\n        taptool.callback = OpenURL(url=url)\n\n    return loc"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmakes a light - weight stat figure.", "response": "def plotstat(data, circleinds=None, crossinds=None, edgeinds=None, url_path=None, fileroot=None, \n             tools=\"hover,tap,pan,box_select,wheel_zoom,reset\", plot_width=450, plot_height=400):\n    \"\"\" Make a light-weight stat figure \"\"\"\n\n    fields = ['imkur', 'specstd', 'sizes', 'colors', 'snrs', 'key']\n\n    if not circleinds: circleinds = range(len(data['snrs']))\n\n    # set ranges\n    datalen = len(data['dm'])\n    inds = circleinds + crossinds + edgeinds\n    specstd = [data['specstd'][i] for i in inds]\n    specstd_min = min(specstd)\n    specstd_max = max(specstd)\n    imkur = [data['imkur'][i] for i in inds]\n    imkur_min = min(imkur)\n    imkur_max = max(imkur)\n\n    source = ColumnDataSource(data = dict({(key, tuple([value[i] for i in circleinds if i not in edgeinds])) \n                                           for (key, value) in data.iteritems() if key in fields}))\n    stat = Figure(plot_width=plot_width, plot_height=plot_height, toolbar_location=\"left\", x_axis_label='Spectral std',\n                  y_axis_label='Image kurtosis', x_range=(specstd_min, specstd_max), \n                  y_range=(imkur_min, imkur_max), tools=tools, output_backend='webgl')\n    stat.circle('specstd', 'imkur', size='sizes', line_color=None, fill_color='colors', fill_alpha=0.2, source=source)\n\n    if crossinds:\n        sourceneg = ColumnDataSource(data = dict({(key, tuple([value[i] for i in crossinds]))\n                                                  for (key, value) in data.iteritems() if key in fields}))\n        stat.cross('specstd', 'imkur', size='sizes', line_color='colors', line_alpha=0.3, source=sourceneg)\n\n    if edgeinds:\n        sourceedge = ColumnDataSource(data = dict({(key, tuple([value[i] for i in edgeinds]))\n                                                   for (key, value) in data.iteritems() if key in fields}))\n        stat.circle('specstd', 'imkur', size='sizes', line_color='colors', fill_color='colors', source=sourceedge, line_alpha=0.5, fill_alpha=0.2)\n\n    hover = stat.select(dict(type=HoverTool))\n    hover.tooltips = OrderedDict([('SNR', '@snrs'), ('key', '@key')])\n\n    if url_path and fileroot:\n        url = '{}/cands_{}_@key.png'.format(url_path, fileroot)\n        taptool = stat.select(type=TapTool)\n        taptool.callback = OpenURL(url=url)\n\n    return stat"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef plotnorm(data, circleinds=[], crossinds=[], edgeinds=[], url_path=None, fileroot=None,\n             tools=\"hover,tap,pan,box_select,wheel_zoom,reset\", plot_width=450, plot_height=400):\n    \"\"\" Make a light-weight norm figure \"\"\"\n\n    fields = ['zs', 'sizes', 'colors', 'abssnr', 'key', 'snrs']\n\n    if not circleinds: circleinds = range(len(data['snrs']))\n\n    source = ColumnDataSource(data = dict({(key, tuple([value[i] for i in circleinds if i not in edgeinds])) \n                                           for (key, value) in data.iteritems() if key in fields}))\n    norm = Figure(plot_width=plot_width, plot_height=plot_height, toolbar_location=\"left\", x_axis_label='SNR observed',\n                  y_axis_label='SNR expected', tools=tools, output_backend='webgl')\n    norm.circle('abssnr', 'zs', size='sizes', line_color=None, fill_color='colors', fill_alpha=0.2, source=source)\n\n    if crossinds:\n        sourceneg = ColumnDataSource(data = dict({(key, tuple([value[i] for i in crossinds]))\n                                                  for (key, value) in data.iteritems() if key in fields}))\n        norm.cross('abssnr', 'zs', size='sizes', line_color='colors', line_alpha=0.3, source=sourceneg)\n\n    if edgeinds:\n        sourceedge = ColumnDataSource(data = dict({(key, tuple([value[i] for i in edgeinds]))\n                                                   for (key, value) in data.iteritems() if key in fields}))\n        norm.circle('abssnr', 'zs', size='sizes', line_color='colors', fill_color='colors', source=sourceedge, line_alpha=0.5, fill_alpha=0.2)\n\n    hover = norm.select(dict(type=HoverTool))\n    hover.tooltips = OrderedDict([('SNR', '@snrs'), ('key', '@key')])\n\n    if url_path and fileroot:\n        url = '{}/cands_{}_@key.png'.format(url_path, fileroot)\n        taptool = norm.select(type=TapTool)\n        taptool.callback = OpenURL(url=url)\n\n    return norm", "response": "Make a light - weight norm figure."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef plotnoise(noisepkl, mergepkl, plot_width=950, plot_height=400):\n\n    d = pickle.load(open(mergepkl))\n    ndist, imstd, flagfrac = plotnoisedist(noisepkl, plot_width=plot_width/2, plot_height=plot_height)\n    fluxscale = calcfluxscale(d, imstd, flagfrac)\n    logger.info('Median image noise is {0:.3} Jy.'.format(fluxscale*imstd))\n    ncum, imnoise = plotnoisecum(noisepkl, fluxscale=fluxscale, plot_width=plot_width/2, plot_height=plot_height)\n\n    hndle = show(Row(ndist, ncum, width=plot_width, height=plot_height))\n    return imnoise", "response": "Make two panel plot to summary noise analysis with estimated flux scale"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nplot the noise pkl converted to interactive cumulative histogram", "response": "def plotnoisecum(noisepkl, fluxscale=1, plot_width=450, plot_height=400):\n    \"\"\" Merged noise pkl converted to interactive cumulative histogram \n\n    noisepkl is standard noise pickle file.\n    fluxscale is scaling applied by gain calibrator. telcal solutions have fluxscale=1.\n    also returns corrected imnoise values if non-unity fluxscale provided\n    \"\"\"\n\n    # noise histogram\n    noises = read_noise(noisepkl)\n    imnoise = np.sort(fluxscale*noises[4])\n    frac = [float(count)/len(imnoise) for count in reversed(range(1, len(imnoise)+1))]\n    noiseplot = Figure(plot_width=plot_width, plot_height=plot_height, toolbar_location=\"above\",\n                       x_axis_label='Image noise (Jy; cal scaling {0:.3})'.format(fluxscale),\n                       y_axis_label='Cumulative fraction', tools='pan, wheel_zoom, reset')\n    noiseplot.line(imnoise, frac)\n\n    if fluxscale != 1:\n        return noiseplot, imnoise\n    else:\n        return noiseplot"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef calcfluxscale(d, imstd_med, flagfrac_med):\n\n    # useful functions and VLA parameters\n    sensitivity = lambda sefd, dt, bw, eta, nbl, npol: sefd/(eta*np.sqrt(nbl*2 * dt * bw * npol))\n    nbl = lambda nant: nant*(nant-1)/2\n    eta = {'L': 0.92, 'S': 0.92, 'C': 0.8, 'X': 0.8}   # correlator efficiency\n    sefd = {'L': 420, 'S': 370, 'C': 310, 'X': 250}    # fixed to match exposure calculator int time to 100 microJy.\n\n    bw = sum([d['spw_nchan_select'][i]*d['spw_chansize'][i] for i in range(len(d['spw_chansize']))])\n    dt = d['inttime']\n    npol = d['npol']\n    nant = d['nants']\n    freq = d['freq'][0]\n    if (freq >= 1 and freq < 2):\n        band = 'L'\n    elif (freq >= 2 and freq < 4):\n        band = 'S'\n    elif (freq >= 4 and freq < 8):\n        band = 'C'\n    elif (freq >= 8 and freq < 12):\n        band = 'X'\n    else:\n        logger.warn('first channel freq ({0}) not in bands L, S, C, or X. Assuming L band.'.format(freq))\n        band = 'L'\n\n    goodfrac = 1 - flagfrac_med # correct for flagged data\n    slim_theory = sensitivity(sefd[band], dt, bw, eta[band], goodfrac*nbl(nant), npol)\n    fluxscale = slim_theory/imstd_med\n\n    return fluxscale", "response": "Calculates the flux scale at the VLA \nd given a state dict and noise properties and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef readdata(mergepkl=None, d=None, cands=None, sizerange=(2,70)):\n\n    # get cands from pkl\n    if mergepkl:\n        logger.info('Reading {0}'.format(mergepkl))\n        loc, prop, d = read_candidates(mergepkl, returnstate=True)\n    elif d and cands:\n        logger.info('Using provided d/cands')\n        loc, prop = cands\n\n    # define columns to extract\n    if 'snr2' in d['features']:\n        snrcol = d['features'].index('snr2')\n    elif 'snr1' in d['features']:\n        snrcol = d['features'].index('snr1')\n    l1col = d['features'].index('l1')\n    m1col = d['features'].index('m1')\n    specstdcol = d['features'].index('specstd')\n    imkurcol = d['features'].index('imkurtosis')\n    dtindcol = d['featureind'].index('dtind')\n    dmindcol = d['featureind'].index('dmind')\n    intcol = d['featureind'].index('int')\n    segmentcol = d['featureind'].index('segment')\n    scancol = d['featureind'].index('scan')\n\n    # define data to plot\n    key = ['sc{0}-seg{1}-i{2}-dm{3}-dt{4}'.format(ll[scancol], ll[segmentcol], ll[intcol], ll[dmindcol], ll[dtindcol]) for ll in loc]\n#    key = [tuple(ll) for ll in loc]\n    scan = loc[:, scancol]\n    seg = loc[:, segmentcol]\n    candint = loc[:, 2]\n    dmind = loc[:, 3]\n    dtind = loc[:, 4]\n    beamnum = loc[:, 5]\n\n    logger.info('Setting columns...')\n    snrs = prop[:, snrcol]\n    abssnr = np.abs(prop[:, snrcol])\n    dm = np.array(d['dmarr'])[loc[:, dmindcol]]\n    l1 = prop[:, l1col]\n    m1 = prop[:, m1col]\n    time = np.array([24*3600*d['segmenttimesdict'][scan[i]][seg[i], 0] + d['inttime']*candint[i] for i in range(len(loc))])\n#    time.append(24*3600*d['segmenttimesdict'][k[scancol]][k[segmentcol],0] + d['inttime']*k[intcol])\n    specstd = prop[:, specstdcol]\n    imkur = prop[:, imkurcol]\n\n    logger.info('Calculating sizes, colors, normprob...')\n    time = time - min(time)\n    sizes = calcsize(snrs)\n    colors = colorsat(l1, m1)\n    zs = normprob(d, snrs)\n\n    # if pandas is available use dataframe to allow datashader feature\n#    data = DataFrame(data={'snrs': snrs, 'dm': dm, 'l1': l1, 'm1': m1, 'time': time, 'specstd': specstd,\n#                           'imkur': imkur, 'scan': scan, 'seg': seg, 'candint': candint, 'dmind': dmind,\n#                           'dtind': dtind, 'sizes': sizes, 'colors': colors, 'key': key, 'zs': zs, 'abssnr': abssnr})\n#    logger.info('Returning a pandas dataframe')\n    data = dict(snrs=snrs, dm=dm, l1=l1, m1=m1, time=time, specstd=specstd, scan=scan,\n                imkur=imkur, sizes=sizes, colors=colors, key=key, zs=zs, abssnr=abssnr)\n#                dtind=dtind, scan=scan, seg=seg, candint=candint, dmind=dmind,\n\n    return data", "response": "Converts candidate data to dictionary for bokeh\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef findhight(data, ignoret=None, threshold=20):\n\n    time = np.sort(data['time'])\n\n    ww = np.ones(len(time), dtype=bool)  # initialize pass filter\n    if ignoret:\n        for (t0, t1) in ignoret:\n            ww = ww & np.where( (time < t0) | (time > t1), True, False )\n\n    bins = np.round(time[ww]).astype('int')\n    counts = np.bincount(bins)\n    high = np.where(counts > np.median(counts) + threshold*counts.std())[0]\n\n    return high, counts[high]", "response": "Find bad time ranges from distribution of candidates."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds indexes for data above or below threshold.", "response": "def calcinds(data, threshold, ignoret=None):\n    \"\"\" Find indexes for data above (or below) given threshold. \"\"\"\n\n    inds = []\n    for i in range(len(data['time'])):\n        snr = data['snrs'][i]\n        time = data['time'][i]\n        if (threshold >= 0 and snr > threshold):\n            if ignoret:\n                incl = [t0 for (t0, t1) in ignoret if np.round(time).astype(int) in range(t0,t1)]\n                logger.debug('{} {} {} {}'.format(np.round(time).astype(int), t0, t1, incl))\n                if not incl:\n                    inds.append(i)\n            else:\n                inds.append(i)\n        elif threshold < 0 and snr < threshold:\n            if ignoret:\n                incl = [t0 for (t0, t1) in ignoret if np.round(time).astype(int) in range(t0,t1)]\n                logger.debug('{} {} {} {}'.format(np.round(time).astype(int), t0, t1, incl))\n                if not incl:\n                    inds.append(i)\n            else:\n                inds.append(i)\n\n    return inds"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef calcontime(data, inds=None):\n\n    if not inds:\n        inds = range(len(data['time']))\n        logger.info('No indices provided. Assuming all are valid.')\n\n    scans = set([data['scan'][i] for i in inds])\n    total = 0.\n    for scan in scans:\n        time = [data['time'][i] for i in inds if data['scan'][i] == scan]\n        total += max(time) - min(time)\n\n    return total", "response": "Given indices of good times calculate total time per scan with indices."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef normprob(d, snrs, inds=None, version=2):\n\n    if not inds: inds = range(len(snrs))\n\n    # define norm quantile functions\n    Z = lambda quan: np.sqrt(2)*erfinv( 2*quan - 1) \n    quan = lambda ntrials, i: (ntrials + 1/2. - i)/ntrials\n\n    # calc number of trials\n    npix = d['npixx']*d['npixy']\n    if d.has_key('goodintcount'):\n        nints = d['goodintcount']\n    else:\n        nints = d['nints']\n    ndms = len(d['dmarr'])\n    dtfactor = np.sum([1./i for i in d['dtarr']])    # assumes dedisperse-all algorithm\n    ntrials = npix*nints*ndms*dtfactor\n    logger.info('Calculating normal probability distribution for npix*nints*ndms*dtfactor = %d' % (ntrials))\n\n    # calc normal quantile\n    if version == 2:\n        # purely sort and numpy-based\n        sortinds = np.argsort(snrs[inds])\n        lenpos = len(np.where(snrs[inds] >= 0)[0])\n        lenneg = len(np.where(snrs[inds] < 0)[0])\n        unsortinds = np.zeros(len(sortinds), dtype=int)\n        unsortinds[sortinds] = np.arange(len(sortinds))\n        rank = np.concatenate( (np.arange(1, lenneg+1), np.arange(1, lenpos+1)[::-1]) )\n        logger.debug('{} {}'.format(rank, sortinds))\n        zval = Z(quan(ntrials, rank[unsortinds]))\n        if inds != range(len(snrs)):  # add zeros for filtered data to match length to original snr array\n            zval = np.array([zval[inds.index(i)] if i in inds else 0 for i in range(len(snrs))])\n\n    elif version == 1:\n        # numpy array based\n        snrpos = snrs[inds][np.where(snrs[inds] > 0)]\n        snrneg = snrs[inds][np.where(snrs[inds] < 0)]\n        snrsortpos = np.sort(snrpos)[::-1]\n        snrsortneg = np.sort(snrneg)\n        \n        logger.debug('Sorted pos/neg SNRs')\n\n        zval = []\n        for i,snr in enumerate(snrs):\n            if i in inds:\n                if snr in snrsortpos:\n                    zval.append(Z(quan(ntrials, np.where(snr == snrsortpos)[0][0]+1)))\n                elif snr in snrsortneg:\n                    zval.append(Z(quan(ntrials, np.where(snr == snrsortneg)[0][0]+1)))\n\n    elif version == 0:\n        # list based\n        snrsortpos = []\n        snrsortneg = []\n        for i in inds:\n            if snrs[i] > 0:\n                snrsortpos.append(snrs[i])\n            elif snrs[i] < 0:\n                snrsortneg.append(abs(snrs[i]))\n\n        snrsortpos = sorted(snrsortpos, reverse=True)\n        snrsortneg = sorted(snrsortneg, reverse=True)\n        logger.debug('Sorted pos/neg SNRs')\n\n        zval = []\n        for (i, snr) in enumerate(snrs):\n            if snr >= 0 and i in inds:\n                zval.append(Z(quan(ntrials, snrsortpos.index(snr)+1)))\n            elif snr < 0 and i in inds:\n                zval.append(Z(quan(ntrials, snrsortneg.index(abs(snr))+1)))\n            else:\n                zval.append(0)\n\n    return zval", "response": "Calculates the normal probability of a list of observed SNRs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef calcsize(values, sizerange=(2,70), inds=None, plaw=3):\n\n    if inds:\n        smax = max([abs(values[i]) for i in inds])\n        smin = min([abs(values[i]) for i in inds])\n    else:\n        smax = max([abs(val) for val in values])\n        smin = min([abs(val) for val in values])\n    return [sizerange[0] + sizerange[1] * ((abs(val) - smin)/(smax - smin))**plaw for val in values]", "response": "Calculate symbol size from a list of values."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef colorsat(l,m):\n\n    lm = np.zeros(len(l), dtype='complex')\n    lm.real = l\n    lm.imag = m\n    red = 0.5*(1+np.cos(np.angle(lm)))\n    green = 0.5*(1+np.cos(np.angle(lm) + 2*3.14/3))\n    blue = 0.5*(1+np.cos(np.angle(lm) - 2*3.14/3))\n    amp = 256*np.abs(lm)/np.abs(lm).max()\n    return [\"#%02x%02x%02x\" % (np.floor(amp[i]*red[i]), np.floor(amp[i]*green[i]), np.floor(amp[i]*blue[i])) for i in range(len(l))]", "response": "Returns a list of colors for given l and m"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef filterdata(data, plinds, d, threshold, ignorestr):\n\n    logger.info('Ignoring times from ignorestr {0}'.format(ignorestr))\n    ignoret = parseignoret(ignorestr)\n\n    thresh0 = d['sigma_image1']\n    thresh1 = d['sigma_plot']\n\n    plinds['cir'] = calcinds(data, thresh0, ignoret=ignoret) # positive cands\n    plinds['cro'] = calcinds(data, -1*thresh0, ignoret=ignoret) # negative cands\n    plinds['edg'] = calcinds(data, thresh1, ignoret=ignoret) # cands with png plots\n    sortinds = sorted(set(plinds['cir'] + plinds['cro'] + plinds['edg']))\n    logger.info('Selected {} ({} linked) points.'.format(len(sortinds), len(plinds['edg'])))\n    \n    logger.info('Estimated total on target time: {} s\\n'.format(calcontime(\n        data, inds=plinds['cir']+plinds['cro']+plinds['edg'])))\n    \n    # these must get get rescaled when cands are ignored\n    data['zs'] = normprob(d, data['snrs'], inds=sortinds)   \n\n    # print high 1s bin counts\n    logger.info('Finding high 1-second bins with threshold {0}'.format(threshold))\n    hight, highcount = findhight(data, ignoret=ignoret, threshold=threshold)\n    if len(hight):\n        logger.info('High times \\t High counts:')\n        for i in range(len(hight)):\n              logger.info('{0}\\t{1}'.format(hight[i], highcount[i]))\n    else:\n        logger.info('No high 1s bin counts.\\n')\n\n    # print high cands and their times\n    biginds = np.argsort(data['abssnr'][sortinds])[-5:]    \n    logger.info('Top 5 abs(snr) candidates and times:')\n    for ind in biginds[::-1]:\n        logger.info('{0} {1}'.format(data['snrs'][sortinds][ind], data['time'][sortinds][ind]))\n    logger.info('\\n')", "response": "Iteratively filter bad times and set indices for later plotting."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef addclassifications(agdir, prop, version=None, statfeats = [0,4,5,6,7,8]):\n\n    try:\n        ag = activegit.ActiveGit(agdir)\n        if version:\n            ag.set_version(version)\n        clf = ag.classifier\n\n        score = clf.predict_proba((np.nan_to_num(prop[:,statfeats])))[:,1]  # take real score\n        return score\n    except:\n        logger.info('Failure when parsing activegit repo or applying classification.\\n{0}'.format(sys.exc_info()[0]))\n        return []", "response": "Calculate real score probability of prop from an activegit repo."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef future_datetime(end='+30d'):\n    return lambda n, f: f.future_datetime(\n        end_date=end, tzinfo=get_timezone(),\n    )", "response": "Returns a function that returns a datetime object in the future of the specified end date."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef future_date(end='+30d'):\n    return lambda n, f: f.future_date(\n        end_date=end, tzinfo=get_timezone(),\n    )", "response": "Returns a function that returns a date object in the future of the specified end date."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a function that returns a datetime object in the past between 1 second ago and the specified start.", "response": "def past_datetime(start='-30d'):\n    \"\"\"\n    Returns a ``datetime`` object in the past between 1 second ago and the\n    specified ``start``. ``start`` can be a string, another datetime, or a\n    timedelta. If it's a string, it must start with `-`, followed by and integer\n    and a unit, Eg: ``'-30d'``. Defaults to `'-30d'`\n\n    Valid units are:\n    * ``'years'``, ``'y'``\n    * ``'weeks'``, ``'w'``\n    * ``'days'``, ``'d'``\n    * ``'hours'``, ``'h'``\n    * ``'minutes'``, ``'m'``\n    * ``'seconds'``, ``'s'``\n    \"\"\"\n    return lambda n, f: f.past_datetime(\n        start_date=start, tzinfo=get_timezone(),\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef past_date(start='-30d'):\n    return lambda n, f: f.past_date(\n        start_date=start, tzinfo=get_timezone(),\n    )", "response": "Returns a function that returns a date object in the past between 1 day ago and the\n    specified start."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cast_to_list(emoticons_list):\n    emoticons_tuple = []\n    for emoticons, image in emoticons_list:\n        if isinstance(emoticons, basestring):\n            emoticons = [emoticons]\n        else:\n            emoticons = list(emoticons)\n        emoticons_tuple.append((emoticons, image))\n    return emoticons_tuple", "response": "Casts list of emoticons with a single name\n    and cast iterables to list."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef compile_emoticons(emoticons_list):\n    emoticons_compiled = []\n    for emoticons, image in emoticons_list:\n        for emoticon in emoticons:\n            context = {\n                'name': emoticon,\n                'image': os.path.join(EMOTICONS_DIRECTORY, image),\n                'code': binascii.hexlify(emoticon.encode('utf-8'))}\n            emoticons_compiled.append(\n                (re.compile(re.escape(emoticon)),\n                 EMOTICON_TEMPLATE.render(context).strip())\n            )\n    return emoticons_compiled", "response": "Compile a list of emoticons into a single list of compiled regular expressions."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _update(self, data):\n      '''Update the step using the blob of json-parsed data directly from the\n      API.\n      '''\n      self.orderby = data['orderby']\n      self.revision = data['revisionid']\n      self.title = data['title']\n      self.lines = [Line(self.guideid, self.stepid, line['lineid'], data=line)\n                    for line in data['lines']]\n      # TODO: Support video.\n      if data['media']['type'] == 'image':\n         self.media = []\n         for image in data['media']['data']:\n            self.media.append(Image(image['id']))", "response": "Update the step using the blob of json - parsed data directly from the\n      API."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read(filename, paramfile, bdfdir, scan):\n\n    filename = os.path.abspath(filename)\n\n    scans = ps.read_scans(filename, bdfdir=bdfdir)\n    logger.info('Scans, Target names:')\n    logger.info('%s' % str([(ss, scans[ss]['source']) for ss in scans]))\n    logger.info('Example pipeline:')\n    state = rt.set_pipeline(filename, scan, paramfile=paramfile, logfile=False)", "response": "Simple parse and return metadata for first scan"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsearches one scan of filename", "response": "def searchone(filename, scan, paramfile, logfile, bdfdir):\n    \"\"\" Searches one scan of filename\n\n    filename is name of local sdm ('filename.GN' expected locally).\n    scan is scan number to search. if none provided, script prints all.\n    assumes filename is an sdm.\n    \"\"\"\n\n    filename = os.path.abspath(filename)\n    scans = ps.read_scans(filename, bdfdir=bdfdir)\n\n    if scan != 0:\n        d = rt.set_pipeline(filename, scan, paramfile=paramfile,\n                            fileroot=os.path.basename(filename), logfile=logfile)\n        rt.pipeline(d, range(d['nsegments']))\n\n        # clean up and merge files\n        pc.merge_segments(filename, scan)\n        pc.merge_scans(os.path.dirname(filename), os.path.basename(filename), scans.keys())\n    else:\n        logger.info('Scans, Target names:')\n        logger.info('%s' % str([(ss, scans[ss]['source']) for ss in scans]))\n        logger.info('Example pipeline:')\n        state = rt.set_pipeline(filename, scans.popitem()[0], paramfile=paramfile,\n                                fileroot=os.path.basename(filename), logfile=logfile)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mergeall(filename, snrmin, snrmax, bdfdir):\n\n    filename = os.path.abspath(filename)\n    bignumber = 500\n\n    if os.path.exists(filename):\n        scans = ps.read_scans(filename, bdfdir=bdfdir)\n        scanlist = sorted(scans.keys())\n    else:\n        logger.warn('Could not find file {0}. Estimating scans from available files.'.format(filename))\n        filelist = glob.glob(os.path.join(os.path.dirname(filename), '*{0}_sc*pkl'.format(os.path.basename(filename))))\n        try:\n            scanlist = sorted(set([int(fn.rstrip('.pkl').split('_sc')[1].split('seg')[0]) for fn in filelist]))\n        except IndexError:\n            logger.warn('Could not parse filenames for scans. Looking over big range.')\n            scanlist = range(bignumber)\n\n    logger.info('Merging over scans {0}'.format(scanlist))\n\n    for scan in scanlist:\n        pc.merge_segments(filename, scan)\n    pc.merge_scans(os.path.dirname(filename), os.path.basename(filename), scanlist, snrmin=snrmin, snrmax=snrmax)", "response": "Merge all cands and noise files over all scans."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef nbcompile(filename, html, basenb, agdir):\n\n    filename = os.path.abspath(filename)\n\n    pc.nbcompile(os.path.dirname(filename), os.path.basename(filename), html=html, basenb=basenb, agdir=agdir)", "response": "Compile the baseinteract. ipynb notebook into an analysis notebook for filename."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef refine_cand(candsfile, candnum, threshold):\n\n    reproduce.refine_cand(candsfile, candnum=candnum, threshold=threshold)", "response": "Re - refine a candidate number in a list of candnums."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef refresh(self):\n      '''Refetch instance data from the API.\n      '''\n      response = requests.get('%s/categories/%s' % (API_BASE_URL, self.name))\n      attributes = response.json()\n      \n      self.ancestors = [Category(name) for name in attributes['ancestors']]\n      self.contents = WikiText(attributes['contents_raw'],\n                               attributes['contents_rendered'])\n      self.description = attributes['description']\n      self.guides = []\n      for guide in attributes['guides']:\n         self.guides.append(Guide(guide['guideid']))\n      # Unlike guides, categories return flags as a dict, keyed by flagid.\n      # *Except* when it's empty, in which case we get an empty list due to\n      # PHP's json_encode() not knowing the difference between an empty array\n      # and an empty dict.\n      flags = dict(attributes['flags']).values()\n      self.flags = [Flag.from_id(flag['flagid']) for flag in flags]\n      self.image = Image(attributes['image']['id']) if attributes['image'] else None\n      self.locale = attributes['locale']\n      #self.parts = attributes['parts']\n      #self.solutions = attributes['solutions']\n      self.title = attributes['display_title']", "response": "Refresh the instance data from the API."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef status(self, return_led=0):\n        status = self.hub.get_device_status(self.device_id, return_led)\n        self.logger.info(\"Dimmer %s status: %s\", self.device_id,\n                         pprint.pformat(status))\n        return status", "response": "Get status from device"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_view(self, request, object_id, extra_context=None):\n        if not extra_context:\n            extra_context = {}\n        extra_context['is_popup'] = request.REQUEST.get('_popup', 0)\n        return super(EnhancedAdminMixin, self).delete_view(request, object_id, extra_context)", "response": "Sets is_popup context variable to hide admin header."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun coverage with coverage. py.", "response": "def coverage(c, html=True):\n    \"\"\"\n    Run coverage with coverage.py.\n    \"\"\"\n    # NOTE: this MUST use coverage itself, and not pytest-cov, because the\n    # latter is apparently unable to prevent pytest plugins from being loaded\n    # before pytest-cov itself is able to start up coverage.py! The result is\n    # that coverage _always_ skips over all module level code, i.e. constants,\n    # 'def' lines, etc. Running coverage as the \"outer\" layer avoids this\n    # problem, thus no need for pytest-cov.\n    # NOTE: this does NOT hold true for NON-PYTEST code, so\n    # pytest-relaxed-USING modules can happily use pytest-cov.\n    c.run(\"coverage run --source=pytest_relaxed -m pytest\")\n    if html:\n        c.run(\"coverage html\")\n        c.run(\"open htmlcov/index.html\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving the instance from the related fields", "response": "def remove_instance(self):\n        \"\"\"\n        Remove the instance from the related fields (delete the field if it's\n        a simple one, or remove the instance from the field if it's a set/list/\n        sorted_set)\n        \"\"\"\n        with fields.FieldLock(self.related_field):\n            related_pks = self()\n            for pk in related_pks:\n\n                # get the real related field\n                related_instance = self.related_field._model(pk)\n                related_field = getattr(related_instance, self.related_field.name)\n\n                # check if we have a dedicated remove method\n                remover = getattr(related_field, '_related_remover', None)\n\n                # then remove the instance from the related field\n                if remover is not None:\n                    # if we have a remover method, it wants the instance as argument\n                    # (the related field may be a set/list/sorted_set)\n                    getattr(related_field, remover)(self.instance._pk)\n                else:\n                    # no remover method, simple delete the field\n                    related_field.delete()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndeleting the related record.", "response": "def delete(self):\n        \"\"\"\n        When the instance is deleted, we propagate the deletion to the related\n        collections, which will remove it from the related fields.\n        \"\"\"\n        for related_collection_name in self.related_collections:\n            related_collection = getattr(self, related_collection_name)\n            related_collection.remove_instance()\n        return super(RelatedModel, self).delete()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmove the related model and its submodels to the new database.", "response": "def use_database(cls, database):\n        \"\"\"\n        Move model and its submodels to the new database, as the original\n        use_database method. And manage relations too (done here instead of\n        the database because the database class is not aware of relations)\n        \"\"\"\n        original_database = getattr(cls, 'database', None)\n        impacted_models = super(RelatedModel, cls).use_database(database)\n\n        # no relation on the current database, so nothing nore to transfer\n        if not original_database or not getattr(original_database, '_relations', {}):\n            return impacted_models\n\n        # prepare relations to remove impacted ones\n        # relations in original_database._relations have this format\n        # related_model => (original_model, original_field, related_name)\n        # Here we want all relations with an original_model in our list of\n        # models impacted by the change of database (impacted_models), to move\n        # these relation on the new database\n        reverse_relations = {}\n        for related_model_name, relations in original_database._relations.items():\n            for relation in relations:\n                reverse_relations.setdefault(relation[0], []).append((related_model_name, relation))\n\n        # create an dict to store relations in the new database\n        if not hasattr(database, '_relations'):\n            database._relations = {}\n\n        # move relation for all impacted models\n        for _model in impacted_models:\n            if _model.abstract:\n                continue\n            for related_model_name, relation in reverse_relations[_model._name]:\n                # if the related model name is already used as a relation, check\n                # if it's not already used with the related_name of the relation\n                if related_model_name in database._relations:\n                    field = _model.get_field(relation[1])\n                    field._assert_relation_does_not_exists()\n                # move the relation from the original database to the new\n                original_database._relations[related_model_name].remove(relation)\n                database._relations.setdefault(related_model_name, []).append(relation)\n\n        return impacted_models"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating the related collection for the given model.", "response": "def _attach_to_model(self, model):\n        \"\"\"\n        When we have a model, save the relation in the database, to later create\n        RelatedCollection objects in the related model\n        \"\"\"\n        super(RelatedFieldMixin, self)._attach_to_model(model)\n\n        if model.abstract:\n            # do not manage the relation if it's an abstract model\n            return\n\n        # now, check related_name and save the relation in the database\n\n        # get related parameters to identify the relation\n        self.related_name = self._get_related_name()\n        self.related_to = self._get_related_model_name()\n\n        # create entry for the model in the _relations list of the database\n        if not hasattr(self.database, '_relations'):\n            self.database._relations = {}\n        self.database._relations.setdefault(self.related_to, [])\n\n        # check unicity of related name for related model\n        self._assert_relation_does_not_exists()\n\n        # the relation didn't exists, we can save it\n        relation = (self._model._name, self.name, self.related_name)\n        self.database._relations[self.related_to].append(relation)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _assert_relation_does_not_exists(self):\n        relations = self.database._relations[self.related_to]\n        existing = [r for r in relations if r[2] == self.related_name]\n        if existing:\n            error = (\"The related name defined for the field '%s.%s', named '%s', already exists \"\n                     \"on the model '%s' (tied to the field '%s.%s')\")\n            raise ImplementationError(error % (self._model.__name__, self.name, self.related_name,\n                                      self.related_to, existing[0][1], existing[0][0]))", "response": "Check if a relation with the current related_name doesn t already exists on the related model"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the name of the related model in the database object.", "response": "def _get_related_model_name(self):\n        \"\"\"\n        Return the name of the related model, as used to store all models in the\n        database object, in the following format: \"%(namespace)s:%(class_name)\"\n        The result is computed from the \"to\" argument of the RelatedField\n        constructor, stored in the \"related_to\" attribute, based on theses rules :\n        - if a \"RelatedModel\" subclass, get its namespace:name\n        - if a string :\n          - if \"self\", get from the current model (relation on self)\n          - if a RelatedModel class name, keep it, and if no namesace, use the\n            namespace of the current model\n        \"\"\"\n        if isinstance(self.related_to, type) and issubclass(self.related_to, RelatedModel):\n            model_name = self.related_to._name\n\n        elif isinstance(self.related_to, str):\n            if self.related_to == 'self':\n                model_name = self._model._name\n            elif ':' not in self.related_to:\n                model_name = ':'.join((self._model.namespace, self.related_to))\n            else:\n                model_name = self.related_to\n\n        else:\n            raise ImplementationError(\"The `to` argument to a related field \"\n                                      \"must be a RelatedModel as a class or as \"\n                                      \"a string (with or without namespace). \"\n                                      \"Or simply 'self'.\")\n\n        return model_name.lower()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_related_name(self):\n        related_name = self.related_name or '%(model)s_set'\n        related_name = related_name % {\n            'namespace': re_identifier.sub('_', self._model.namespace),\n            'model': self._model.__name__\n        }\n        if re_identifier.sub('', related_name) != related_name:\n            raise ImplementationError('The related_name \"%s\" is not a valid '\n                                      'python identifier' % related_name)\n\n        return related_name.lower()", "response": "Return the related name to use to access this related field."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_python(self, value):\n        if isinstance(value, model.RedisModel):\n            value = value._pk\n        elif isinstance(value, SimpleValueRelatedFieldMixin):\n            value = value.proxy_get()\n        return value", "response": "Convert a value from the python representation to the equivalent object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _make_command_method(cls, command_name, many=False):\n        def func(self, *args, **kwargs):\n            if many:\n                args = self.from_python_many(*args)\n            else:\n                if 'value' in kwargs:\n                    kwargs['value'] = self.from_python(kwargs['value'])\n                else:\n                    args = list(args)\n                    args[0] = self.from_python(args[0])\n\n            # call the super method, with real pk\n            sup_method = getattr(super(cls, self), command_name)\n            return sup_method(*args, **kwargs)\n        return func", "response": "Return a function which will convert objects to their pk then call the super method with real pk."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef instance(self, skip_exist_test=False):\n        model = self.database._models[self.related_to]\n        meth = model.lazy_connect if skip_exist_test else model\n        return meth(self.proxy_get())", "response": "Returns the instance of the related object linked by the field."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef zadd(self, *args, **kwargs):\n        if 'values_callback' not in kwargs:\n            kwargs['values_callback'] = self.from_python_many\n        pieces = fields.SortedSetField.coerce_zadd_args(*args, **kwargs)\n        return super(M2MSortedSetField, self).zadd(*pieces)", "response": "Add a new entry to the set."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrefresh the instance data from the API.", "response": "def refresh(self):\n      '''Refetch instance data from the API.\n      '''\n      response = requests.get('%s/media/images/%s' % (API_BASE_URL, self.id))\n      attributes = response.json()\n      \n      #self.exif = attributes['exif']\n      self.height = attributes['height']\n      self.width = attributes['width']\n      #self.ratio = attributes['ratio']\n      #self.markup = attributes['markup']\n      #self.srcid = attributes['srcid']\n      \n      image = attributes['image']\n      # Images are allowed to have different sizes, depending on the dimensions\n      # of the original image.  To avoid doing a bunch of explicit 'in' checks,\n      # splat the variables into scope.\n      del(image['id'])\n      for size in image:\n         vars(self)[size] = image[size]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pipeline(self, transaction=True, share_in_threads=False):\n        return _Pipeline(self, transaction=transaction, share_in_threads=share_in_threads)", "response": "A simple pipeline that returns a list of all the keys that are currently in the current database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef transaction(self, func, *watches, **kwargs):\n        with self.pipeline(True, share_in_threads=kwargs.get('share_in_threads', False)) as pipe:\n            while 1:\n                try:\n                    if watches:\n                        pipe.watch(*watches)\n                    func(pipe)\n                    return pipe.execute()\n                except WatchError:\n                    continue", "response": "Convenience method for executing a callable func while watching all keys specified in watches."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the connection object for this thread.", "response": "def _connection(self):\n        \"\"\"\n        If we have a pipeline, shared in thread, or in the good thread, return it\n        else use the direct connection\n        \"\"\"\n        if self._pipelined_connection is not None:\n            if self._pipelined_connection.share_in_threads or \\\n                    threading.current_thread().ident == self._pipelined_connection.current_thread_id:\n                return self._pipelined_connection\n\n\n        return self._direct_connection"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _connection(self, value):\n        if isinstance(value, _Pipeline):\n            self._pipelined_connection = value\n        else:\n            self._direct_connection = value\n            self._pipelined_connection = None", "response": "Save the connection to use for the current user."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\noverrides the default watch method to allow user to pass RedisField objects as names", "response": "def watch(self, *names):\n        \"\"\"\n        Override the default watch method to allow the user to pass RedisField\n        objects as names, which will be translated to their real keys and passed\n        to the default watch method\n        \"\"\"\n        watches = []\n        for watch in names:\n            if isinstance(watch, RedisField):\n                watch = watch.key\n            watches.append(watch)\n        return super(_Pipeline, self).watch(*watches)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_connection_distance(relationship, obj1, obj2, limit=2):\n    return get_relationship(relationship).distance_between(obj1, obj2, limit)", "response": "Calculates the distance between two objects for the given relationship."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_candidates(candsfile, snrmin=0, snrmax=999, returnstate=False):\n\n    # read in pickle file of candidates\n    assert os.path.exists(candsfile)\n\n    try:\n        with open(candsfile, 'rb') as pkl:\n            d = pickle.load(pkl)\n            cands = pickle.load(pkl)\n    except IOError:\n        logger.error('Trouble parsing candsfile')\n        loc = np.array([])\n        prop = np.array([])\n        if returnstate:\n            return (loc, prop, d)\n        else:\n            return (loc, prop)\n\n    if 'snr2' in d['features']:\n        snrcol = d['features'].index('snr2')\n    elif 'snr1' in d['features']:\n        snrcol = d['features'].index('snr1')\n\n    # old style. here for backwards compatibility\n    if isinstance(cands, dict):\n        loc = []; prop = []\n        for kk in sorted(cands.keys()):\n            if ((np.abs(cands[kk][snrcol]) > snrmin) and (np.abs(cands[kk][snrcol]) < snrmax)):\n                loc.append( list(kk) )\n                prop.append( list(cands[kk]) )\n        loc = np.array(loc)\n        prop = np.array(prop)\n\n    # new style\n    elif isinstance(cands, tuple):\n        loc, prop = cands\n        assert isinstance(loc, np.ndarray) and isinstance(prop, np.ndarray), 'if cands object is tuple, contents must be two ndarrays'\n        if not len(loc):\n            if returnstate:\n                return (loc, prop, d)\n            else:\n                return (loc, prop)\n\n        snrsel = np.where( (np.abs(prop[:, snrcol]) > snrmin) & (np.abs(prop[:, snrcol]) < snrmax) )\n        loc = loc[snrsel]\n        prop = prop[snrsel]\n\n    else:\n        logger.error('Cands object (in cands file) must be dict or tuple(np.array, np.array).')\n\n    # if segment or scan pkl, insert scan number as first col and modify d\n    if 'scan' not in d['featureind']:\n        scanarr = d['scan'] * np.ones(len(loc), dtype=int)\n        loc = np.concatenate( (scanarr[:,None], loc), axis=1)\n        d['featureind'].insert(0, 'scan')\n\n    logger.info('Read %d candidates from %s.' % (len(loc), candsfile))\n\n    if returnstate:\n        return loc, prop, d\n    else:\n        return loc, prop", "response": "Reads candidate file and returns data as python object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_noise(noisefile):\n\n    noises = pickle.load(open(noisefile, 'r'))\n\n    scan = []; seg = []; noiseperbl = []; flagfrac = []; imnoise = []\n    if len(noises[0]) == 4:\n        for noise in noises:\n            seg.append(noise[0]); noiseperbl.append(noise[1])\n            flagfrac.append(noise[2]); imnoise.append(noise[3])\n        return (np.array(seg), np.array(noiseperbl), np.array(flagfrac), np.array(imnoise))\n    elif len(noises[0]) == 5:\n        for noise in noises:\n            scan.append(noise[0])\n            seg.append(noise[1]); noiseperbl.append(noise[2])\n            flagfrac.append(noise[3]); imnoise.append(noise[4])\n        return (np.array(scan), np.array(seg), np.array(noiseperbl), np.array(flagfrac), np.array(imnoise))\n    else:\n        logger.warn('structure of noise file not understood. first entry should be length 4 of 5.')", "response": "Function to read a noise file and parse columns."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmerge multiple cands pkls into a single cands archive.", "response": "def merge_segments(filename, scan, cleanup=True, sizelimit=0):\n    \"\"\" Merges cands/noise pkl files from multiple segments to single cands/noise file.\n\n    Expects segment cands pkls with have (1) state dict and (2) cands dict.\n    Writes tuple state dict and duple of numpy arrays\n    A single pkl written per scan using root name fileroot.\n    if cleanup, it will remove segments after merging.\n    if sizelimit, it will reduce the output file to be less than this many MB.\n    \"\"\"\n\n    workdir = os.path.dirname(filename)\n    fileroot = os.path.basename(filename)\n    candslist = glob.glob(os.path.join(workdir, 'cands_' + fileroot + '_sc' + str(scan) + 'seg*.pkl'))\n    noiselist = glob.glob(os.path.join(workdir, 'noise_' + fileroot + '_sc' + str(scan) + 'seg*.pkl'))\n    candssegs = sorted([candsfile.rstrip('.pkl').split('seg')[1] for candsfile in candslist])\n    noisesegs = sorted([noisefile.rstrip('.pkl').split('seg')[1] for noisefile in noiselist])\n\n    # test for good list with segments\n    if not candslist and not noiselist:\n        logger.warn('candslist and noiselist are empty.')\n        return\n\n    # aggregate cands over segments\n    if not os.path.exists(os.path.join(workdir, 'cands_' + fileroot + '_sc' + str(scan) + '.pkl')):\n        logger.info('Aggregating cands over segments %s for fileroot %s, scan %d' % (str(candssegs), fileroot, scan))\n        logger.debug('%s' % candslist)\n\n        cands = {}\n        for candsfile in candslist:\n            with open(candsfile, 'r') as pkl:\n                state = pickle.load(pkl)\n                result = pickle.load(pkl)\n            for kk in result.keys():\n                cands[kk] = result[kk]\n            segment = state.pop('segment')  # remove this key, as it has no meaning after merging segments\n\n        # optionally limit size\n        if sizelimit and len(cands):\n            logger.debug('Checking size of cands dictionary...')\n            if 'snr2' in state['features']:\n                snrcol = state['features'].index('snr2')\n            elif 'snr1' in state['features']:\n                snrcol = state['features'].index('snr1')\n\n            candsize = sys.getsizeof(cands[cands.keys()[0]])/1e6\n            maxlen = int(sizelimit/candsize)\n            if len(cands) > maxlen:  # need to reduce length to newlen\n                logger.info('cands dictionary of length %.1f would exceed sizelimit of %d MB. Trimming to strongest %d candidates' % (len(cands), sizelimit, maxlen))\n                snrs = [abs(cands[k][snrcol]) for k in cands.iterkeys()]  # take top snrs\n                snrsort = sorted(snrs, reverse=True)\n                snrmax = snrsort[maxlen]  # get min snr for given length limit\n                cands = {k: v for k,v in cands.items() if abs(v[snrcol]) > snrmax} # new cands dict\n\n        # write cands to single file\n        with open(os.path.join(workdir, 'cands_' + fileroot + '_sc' + str(scan) + '.pkl'), 'w') as pkl:\n            pickle.dump(state, pkl, protocol=2)\n            pickle.dump( (np.array(cands.keys()), np.array(cands.values())), pkl, protocol=2)\n            \n        if cleanup:\n            if os.path.exists(os.path.join(workdir, 'cands_' + fileroot + '_sc' + str(scan) + '.pkl')):\n                for candsfile in candslist:\n                    os.remove(candsfile)\n    else:\n        logger.warn('Merged candsfile already exists for scan %d. Not merged.' % scan)\n\n    # aggregate noise over segments\n    if not os.path.exists(os.path.join(workdir, 'noise_' + fileroot + '_sc' + str(scan) + '.pkl')):\n        logger.info('Aggregating noise over segments %s for fileroot %s, scan %d' % (str(noisesegs), fileroot, scan))\n        logger.debug('%s' % noiselist)\n\n        noise = []\n        for noisefile in noiselist:\n            with open(noisefile, 'r') as pkl:\n                result = pickle.load(pkl)   # gets all noises for segment as list\n            noise += result\n\n        # write noise to single file\n        if len(noise):\n            with open(os.path.join(workdir, 'noise_' + fileroot + '_sc' + str(scan) + '.pkl'), 'w') as pkl:\n                pickle.dump(noise, pkl, protocol=2)\n\n        if cleanup:\n            if os.path.exists(os.path.join(workdir, 'noise_' + fileroot + '_sc' + str(scan) + '.pkl')):\n                for noisefile in noiselist:\n                    os.remove(noisefile)\n\n    else:\n        logger.warn('Merged noisefile already exists for scan %d. Not merged.' % scan)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cleanup(workdir, fileroot, scans=[]):\n\n    os.chdir(workdir)\n\n    # merge cands/noise files per scan\n    for scan in scans:\n        merge_segments(fileroot, scan, cleanup=True, sizelimit=2.)", "response": "Cleanup up noise and cands files."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmerges noise files from multiple segments.", "response": "def merge_noises(pkllist, outroot=''):\n    \"\"\" Merge noise files from multiple segments.\n    Output noise file has scan number at start of each entry.\n    \"\"\"\n\n    assert isinstance(pkllist, list), \"pkllist must be list of file names\"\n    if not outroot:\n        outroot = '_'.join(pkllist[0].split('_')[1:-1])\n\n    workdir = os.path.dirname(pkllist[0])\n    mergepkl = os.path.join(workdir, 'noise_' + outroot + '_merge.pkl')\n\n    pkllist = [pkllist[i] for i in range(len(pkllist)) if ('merge' not in pkllist[i]) and ('seg' not in pkllist[i])]  # filter list down to per-scan noise pkls\n    pkllist.sort(key=lambda i: int(i.rstrip('.pkl').split('_sc')[1]))  # sort by scan assuming filename structure\n    scans = [int(ff.rstrip('.pkl').split('_sc')[1]) for ff in pkllist]\n    logger.info('Aggregating noise from scans %s' % scans)\n\n    allnoise = []\n    for pklfile in pkllist:\n        scan = int(pklfile.rstrip('.pkl').split('_sc')[1])   # parsing filename to get scan number\n        with open(pklfile, 'r') as pkl:\n            noises = pickle.load(pkl)   # gets all noises for segment as list\n        allnoise += [[scan] + list(noise) for noise in noises]  # prepend scan number\n\n    # write noise to single file\n    if os.path.exists(mergepkl):\n        logger.info('Overwriting merged noise file %s' % mergepkl)\n        os.remove(mergepkl)\n    else:\n        logger.info('Writing merged noise file %s' % mergepkl)\n\n    with open(mergepkl, 'w') as pkl:\n        pickle.dump(allnoise, pkl, protocol=2)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef merge_cands(pkllist, outroot='', remove=[], snrmin=0, snrmax=999):\n\n    assert isinstance(pkllist, list), \"pkllist must be list of file names\"\n    if not outroot:\n        outroot = '_'.join(pkllist[0].split('_')[1:-1])\n\n    workdir = os.path.dirname(pkllist[0])\n    mergepkl = os.path.join(workdir, 'cands_' + outroot + '_merge.pkl')\n\n    pkllist = [pkllist[i] for i in range(len(pkllist)) if ('merge' not in pkllist[i]) and ('seg' not in pkllist[i])]\n    pkllist.sort(key=lambda i: int(i.rstrip('.pkl').split('_sc')[1]))  # assumes filename structure\n    scans = [int(ff.rstrip('.pkl').split('_sc')[1]) for ff in pkllist]\n    logger.info('Aggregating cands from scans %s' % scans)\n\n    # get sample state dict. use 'dict' suffix to define multi-scan metadata dictionaries\n    mergeloc = []; mergeprop = []; mergetimes = []\n    segmenttimesdict = {}\n    starttime_mjddict = {}\n    for pklfile in pkllist:\n\n        # get scan number and read candidates\n        locs, props, d = read_candidates(pklfile, snrmin=snrmin, snrmax=snrmax, returnstate=True)\n        if 'snr2' in d['features']:\n            snrcol = d['features'].index('snr2')\n        elif 'snr1' in d['features']:\n            snrcol = d['features'].index('snr1')\n#        scan = int(pklfile.rstrip('.pkl').split('_sc')[1])   # parsing filename to get scan number\n        scan = d['scan']\n        segmenttimesdict[scan] = d['segmenttimes']\n        starttime_mjddict[scan] = d['starttime_mjd']\n\n        times = int2mjd(d, locs)\n\n        # build merged loc,prop lists\n        for i in range(len(locs)):\n            loc = list(locs[i])\n            prop = list(props[i])\n            mergeloc += [loc]\n            mergeprop += [prop]\n            mergetimes.append(times[i])\n\n    mergeloc = np.array(mergeloc)\n    mergeprop = np.array(mergeprop)\n    mergetimes = np.array(mergetimes)\n\n    # filter by remove, if needed\n    if remove:\n        mergetimes -= mergetimes.min()\n\n        ww = np.ones(len(mergetimes), dtype=bool)  # initialize pass filter\n        nranges = len(remove)\n        for first in range(0,nranges,2):\n            badrange0 = remove[first]\n            badrange1 = remove[first+1]\n\n            ww = ww & np.where( (mergetimes < badrange0) | (mergetimes > badrange1), True, False )\n\n        mergeloc = mergeloc[ww]\n        mergeprop = mergeprop[ww]\n\n    # update metadata\n    d['remove'] = remove\n    d['segmenttimesdict'] = segmenttimesdict\n    d['starttime_mjddict'] = starttime_mjddict\n    logger.info('Writing filtered set of %d candidates to %s' % (len(mergeloc), mergepkl))\n\n    # write up new pkl\n    pkl = open(mergepkl, 'w')\n    pickle.dump(d, pkl, protocol=2)\n    pickle.dump((mergeloc, mergeprop), pkl, protocol=2)\n    pkl.close()", "response": "Takes a list of pkls and returns a single merge pkl file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmerging cands and noise files over all scans.", "response": "def merge_scans(workdir, fileroot, scans, snrmin=0, snrmax=999):\n    \"\"\" Merge cands/noise files over all scans \"\"\"\n\n\n    pkllist = [ff for ff in\n               [os.path.join(workdir, 'cands_{0}_sc{1}.pkl'.format(fileroot, scan))\n                for scan in scans] if os.path.exists(ff)]\n    merge_cands(pkllist, outroot=fileroot, snrmin=snrmin, snrmax=snrmax)\n\n    pkllist = [ff for ff in\n               [os.path.join(workdir, 'noise_{0}_sc{1}.pkl'.format(fileroot, scan))\n                for scan in scans] if os.path.exists(ff)]\n    merge_noises(pkllist, fileroot)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef nbcompile(workdir, fileroot, html=True, basenb='', agdir=''):\n\n    from shutil import copy\n    from rtpipe import get_notebook\n    from subprocess import call\n\n    os.environ['fileroot'] = fileroot\n    if agdir:\n        os.environ['agdir'] = agdir\n\n    if not basenb:\n        basenb = get_notebook('baseinteract.ipynb')\n\n    logger.info('Moving to {0} and building notebook for {1}'.format(workdir, fileroot))\n    os.chdir(workdir)\n    copy(basenb, '{0}/{1}.ipynb'.format(workdir, fileroot))\n\n    cmd = 'jupyter nbconvert {0}.ipynb --inplace --execute --to notebook --allow-errors --ExecutePreprocessor.timeout=3600'.format(fileroot).split(' ')\n    status = call(cmd)\n\n    cmd = 'jupyter trust {0}.ipynb'.format(fileroot).split(' ')\n    status = call(cmd)\n\n    if html:\n        cmd = 'jupyter nbconvert {0}.ipynb --to html --output {0}.html'.format(fileroot).split(' ')\n        status = call(cmd)", "response": "Run analysis pipeline from jupyter base notebook and save as notebook and html."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning list of significant candidate loc in candsfile that are above threshold", "response": "def thresholdcands(candsfile, threshold, numberperscan=1):\n    \"\"\" Returns list of significant candidate loc in candsfile.\n    Can define threshold and maximum number of locs per scan.\n    Works on merge or per-scan cands pkls.\n    \"\"\"\n\n    # read metadata and define columns of interest\n    loc, prop, d = read_candidates(candsfile, returnstate=True)\n    try:\n        scancol = d['featureind'].index('scan')\n    except ValueError:\n        scancol = -1\n    if 'snr2' in d['features']:\n        snrcol = d['features'].index('snr2')\n    elif 'snr1' in d['features']:\n        snrcol = d['features'].index('snr1')\n\n    snrs = [prop[i][snrcol] for i in range(len(prop)) if prop[i][snrcol] > threshold]\n\n    # calculate unique list of locs of interest\n    siglocs = [list(loc[i]) for i in range(len(prop)) if prop[i][snrcol] > threshold]\n    siglocssort = sorted(zip([list(ll) for ll in siglocs], snrs), key=lambda stuff: stuff[1], reverse=True)\n\n    if scancol >= 0:\n        scanset = list(set([siglocs[i][scancol] for i in range(len(siglocs))]))\n        candlist= []\n        for scan in scanset:\n            logger.debug('looking in scan %d' % scan)\n            count = 0\n            for sigloc in siglocssort:\n                if sigloc[0][scancol] == scan:\n                    logger.debug('adding sigloc %s' % str(sigloc))\n                    candlist.append(sigloc)\n                    count += 1\n                if count >= numberperscan:\n                    break\n    else:\n        candlist = siglocssort[:numberperscan]\n\n    logger.debug('Returning %d cands above threshold %.1f' % (len(candlist), threshold))\n    return [loc for loc,snr in candlist]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfunction to convert segment + integration into mjd seconds.", "response": "def int2mjd(d, loc):\n    \"\"\" Function to convert segment+integration into mjd seconds.\n    \"\"\"\n\n    # needs to take merge pkl dict\n\n    if len(loc):\n        intcol = d['featureind'].index('int')\n        segmentcol = d['featureind'].index('segment')\n        if d.has_key('segmenttimesdict'):  # using merged pkl\n            scancol = d['featureind'].index('scan')\n            t0 = np.array([d['segmenttimesdict'][loc[i,scancol]][loc[i,segmentcol],0] for i in range(len(loc))])\n        else:\n            t0 = d['segmenttimes'][loc[:,segmentcol]][:,0]\n        return (t0 + (d['inttime']/(24*3600.))*loc[:,intcol]) * 24*3600\n    else:\n        return np.array([])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plot_full(candsfile, cands, mode='im'):\n\n    loc, prop, d = read_candidates(candsfile, returnstate=True)\n    npixx, npixy = prop[0][4].shape\n    nints, nchan, npol = prop[0][5].shape\n\n    bin = 10\n    plt.figure(1)\n    for i in cands:\n        if mode == 'spec':\n            rr = np.array([np.abs(prop[i][5][:,i0:i0+bin,0].mean(axis=1)) for i0 in range(0,nchan,bin)])\n            ll = np.array([np.abs(prop[i][5][:,i0:i0+bin,1].mean(axis=1)) for i0 in range(0,nchan,bin)])\n            sh = ll.shape\n            data = np.concatenate( (rr, np.zeros(shape=(sh[0], sh[1]/2)), ll), axis=1)\n        elif mode == 'im':\n            data = prop[i][4]\n        plt.subplot(np.sqrt(len(cands)), np.sqrt(len(cands)), cands.index(i))\n        plt.imshow(data, interpolation='nearest')\n    plt.show()", "response": "Plot full features such as cutout image and spectrum."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvisualize cands in set of pkl files from pulsar observations.", "response": "def make_psrrates(pkllist, nbins=60, period=0.156):\n    \"\"\" Visualize cands in set of pkl files from pulsar observations.\n    Input pkl list assumed to start with on-axis pulsar scan, followed by off-axis scans.\n    nbins for output histogram. period is pulsar period in seconds (used to find single peak for cluster of detections).\n    \"\"\"\n\n    # get metadata\n    state = pickle.load(open(pkllist[0], 'r'))  # assume single state for all scans\n    if 'image2' in state['searchtype']:\n        immaxcol = state['features'].index('immax2')\n        logger.info('Using immax2 for flux.')\n    elif 'image1' in state['searchtype']:\n        try:\n            immaxcol = state['features'].index('immax1')\n            logger.info('Using immax1 for flux.')\n        except:\n            immaxcol = state['features'].index('snr1')\n            logger.info('Warning: Using snr1 for flux.')\n\n    # read cands\n    for pklfile in pkllist:\n        loc, prop = read_candidates(pklfile)\n\n        ffm = []\n        if (loc):\n            times = int2mjd(state, loc)\n\n            for (mint,maxt) in zip(np.arange(times.min()-period/2,times.max()+period/2,period), np.arange(times.min()+period/2,times.max()+3*period/2,period)):\n                ff = np.array([prop[i][immaxcol] for i in range(len(prop))])\n                mm = ff[np.where( (times >= mint) & (times < maxt) )]\n                if mm:\n                    ffm.append(mm.max())\n            ffm.sort()\n\n        logger.info('Found %d unique pulses.' % len(ffm))\n        # calculate params\n        if pkllist.index(pklfile) == 0:\n            duration0 = times.max() - times.min()\n            ratemin = 1/duration0\n            ratemax = len(ffm)/duration0\n            rates = np.linspace(ratemin, ratemax, nbins)\n            f0m = ffm\n        elif pkllist.index(pklfile) == 1:\n            duration1 = times.max() - times.min()\n            f1m = ffm\n        elif pkllist.index(pklfile) == 2:\n            f2m = ffm\n        elif pkllist.index(pklfile) == 3:\n            f3m = ffm\n\n    # calc rates\n    f0 = []; f1 = []; f2 = []; f3 = []\n    for rr in rates:\n        num0 = (np.round(rr*duration0)).astype(int)\n        num1 = (np.round(rr*duration1)).astype(int)\n        \n        if (num0 > 0) and (num0 <= len(f0m)):\n            f0.append((rr,f0m[-num0]))\n\n        if (num1 > 0) and (num1 <= len(f1m)):\n            f1.append((rr,f1m[-num1]))\n\n        if (num1 > 0) and (num1 <= len(f2m)):\n            f2.append((rr,f2m[-num1]))\n\n        if len(pkllist) == 4:\n            if f3m:\n                if (num1 > 0) and (num1 <= len(f3m)):\n                    f3.append((rr,f3m[-num1]))\n\n    if f3:\n        return {0: np.array(f0).transpose(), 1: np.array(f1).transpose(), 2: np.array(f2).transpose(), 3: np.array(f3).transpose()}\n    else:\n        return {0: np.array(f0).transpose(), 1: np.array(f1).transpose(), 2: np.array(f2).transpose()}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plot_psrrates(pkllist, outname=''):\n\n    if not outname:\n        outname = 'tmp.png'\n\n    labels = {0: 'Flux at 0\\'', 1: 'Flux at 7\\'', 2: 'Flux at 15\\'', 3: 'Flux at 25\\''}\n    labelsr = {1: 'Flux Ratio 7\\' to 0\\'', 2: 'Flux Ratio 15\\' to 0\\'', 3: 'Flux Ratio 25\\' to 0\\''}\n    colors = {0: 'b.', 1: 'r.', 2: 'g.', 3: 'y.'}\n\n    rates = make_psrrates(pkllist)\n    plt.clf()\n    fig = plt.figure(1, figsize=(10,8), facecolor='white')\n    ax = fig.add_subplot(211, axis_bgcolor='white')\n    for kk in rates.keys():\n        flux, rate = rates[kk]\n        plt.plot(flux, rate, colors[kk], label=labels[kk])\n\n    plt.setp( ax.get_xticklabels(), visible=False)\n    plt.ylabel('Flux (Jy)', fontsize='20')\n    plt.legend(numpoints=1)\n    plt.loglog()\n\n    ax2 = fig.add_subplot(212, sharex=ax, axis_bgcolor='white')\n    flux0, rate0 = rates[0]\n    for kk in rates.keys():\n        flux, rate = rates[kk]\n        if kk == 1:\n            r10 = [rate[i]/rate0[np.where(flux0 == flux[i])[0][0]] for i in range(len(rate))]\n            plt.plot(flux, r10, colors[kk], label=labelsr[kk])\n        elif kk == 2:\n            r20 = [rate[i]/rate0[np.where(flux0 == flux[i])[0][0]] for i in range(len(rate))]\n            plt.plot(flux, r20, colors[kk], label=labelsr[kk])\n        elif kk == 3:\n            r30 = [rate[i]/rate0[np.where(flux0 == flux[i])[0][0]] for i in range(len(rate))]\n            plt.plot(flux, r30, colors[kk], label=labelsr[kk])\n\n    plt.xlabel('Rate (1/s)', fontsize='20')\n    plt.ylabel('Flux ratio', fontsize='20')\n    plt.legend(numpoints=1)\n    plt.subplots_adjust(hspace=0)\n\n    # find typical ratio. avoid pulsar period saturation and low-count regimes (high and low ends)\n    if len(rates) == 4:\n        logger.info('flux ratio, lowest common (1/0, 2/0, 3/0):', (r10[len(r30)-1], r20[len(r30)-1], r30[-1]))\n        logger.info('flux ratio, high end (1/0, 2/0, 3/0):', (r10[-1], r20[-1], r30[-1]))\n    elif len(rates) == 3:\n        logger.info('flux ratio, lowest common (1/0, 2/0):', (r10[len(r20)-1], r20[-1]))\n        logger.info('flux ratio, high end (1/0, 2/0):', (r10[-1], r20[-1]))\n\n    plt.savefig(outname)", "response": "Plot cumulative rate histograms for the pkl files in order."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mock_fluxratio(candsfile, mockcandsfile, dmbin=0):\n\n    loc, prop = read_candidates(candsfile)\n    loc2, prop2 = read_candidates(mockcandsfile)\n\n    dmselect = np.where(loc[:,2] == dmbin)[0]\n    mocki = [i for i in loc2[:,1].astype(int)]  # known transients\n    rat = []; newloc = []; newprop = []\n    for i in mocki:\n        try:\n            detind = list(loc[dmselect,1]).index(i)   # try to find detection\n            rat.append(prop[dmselect][detind][1]/prop2[mocki.index(i)][1])\n            newloc.append(list(loc2[mocki.index(i)]))\n            newprop.append(list(prop2[mocki.index(i)]))\n        except ValueError:\n            pass\n\n    return rat, np.array(newloc), newprop", "response": "Returns ratio of detected to expected flux for all associations in mockcandsfile."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef flag_calcmad(data):\n\n    absdev = np.abs(data - np.median(data))\n    return np.median(absdev)", "response": "Calculate median absolute deviation of data array"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting numeric brightness percentage into hex for insteon", "response": "def brightness_to_hex(self, level):\n        \"\"\"Convert numeric brightness percentage into hex for insteon\"\"\"\n        level_int = int(level)\n        new_int = int((level_int * 255)/100)\n        new_level = format(new_int, '02X')\n        self.logger.debug(\"brightness_to_hex: %s to %s\", level, str(new_level))\n        return str(new_level)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsending raw command via post", "response": "def post_direct_command(self, command_url):\n        \"\"\"Send raw command via post\"\"\"\n        self.logger.info(\"post_direct_command: %s\", command_url)\n        req = requests.post(command_url, timeout=self.timeout,\n                            auth=requests.auth.HTTPBasicAuth(self.username,\n                                                             self.password))\n        self.http_code = req.status_code\n        req.raise_for_status()\n        return req"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends raw command via get", "response": "def get_direct_command(self, command_url):\n        \"\"\"Send raw command via get\"\"\"\n        self.logger.info(\"get_direct_command: %s\", command_url)\n        req = requests.get(command_url, timeout=self.timeout,\n                           auth=requests.auth.HTTPBasicAuth(self.username,\n                                                            self.password))\n        self.http_code = req.status_code\n        req.raise_for_status()\n        return req"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef direct_command(self, device_id, command, command2, extended_payload=None):\n        extended_payload = extended_payload or ''\n        if not extended_payload:\n            msg_type = '0'\n            msg_type_desc = 'Standard'\n        else:\n            msg_type = '1'\n            msg_type_desc = 'Extended'\n\n            extended_payload = extended_payload.ljust(26, '0')\n\n            ### Determine checksum to add onto the payload for I2CS support\n            checksum_payload_hex = [int(\"0x\" + extended_payload[i:i+2],16) for i in range(0,len(extended_payload)-1,2)]\n            checksum_payload_hex.insert(0, int(\"0x\" + command2, 16))\n            checksum_payload_hex.insert(0, int(\"0x\" + command, 16))\n\n            # Get sum of all hex bytes\n            bytessum = 0\n            for ch in checksum_payload_hex:\n                bytessum += ch\n            bytessumStr = hex(bytessum)\n\n            # Get last byte of the bytessum\n            lastByte = bytessumStr[-2:]\n            lastByte = '0x' + lastByte.zfill(2)\n            # Determine compliment of last byte\n            lastByteHex = int(lastByte, 16)\n            lastCompliment = lastByteHex ^ 0xFF\n            # Add one to create checksum\n            checksum = hex(lastCompliment + 0x01)\n            # Remove 0x prefix\n            checksum_final = (format(int(checksum, 16), 'x'))\n            checksum_final = checksum_final.upper()\n            #print(\"final checksum\")\n            #pprint.pprint(checksum_final)\n            extended_payload = extended_payload + checksum_final\n\n        self.logger.info(\"direct_command: Device: %s Command: %s Command 2: %s Extended: %s MsgType: %s\", device_id, command, command2, extended_payload, msg_type_desc)\n        device_id = device_id.upper()\n        command_url = (self.hub_url + '/3?' + \"0262\"\n                       + device_id + msg_type + \"F\"\n                       + command + command2 + extended_payload + \"=I=3\")\n        return self.post_direct_command(command_url)", "response": "Wrapper to send a direct command and get response. Level is 0 - 100."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend direct hub command", "response": "def direct_command_hub(self, command):\n        \"\"\"Send direct hub command\"\"\"\n        self.logger.info(\"direct_command_hub: Command %s\", command)\n        command_url = (self.hub_url + '/3?' + command + \"=I=3\")\n        return self.post_direct_command(command_url)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef direct_command_short(self, command):\n        self.logger.info(\"direct_command_short: Command %s\", command)\n        command_url = (self.hub_url + '/3?' + command + \"=I=0\")\n        return self.post_direct_command(command_url)", "response": "Wrapper for direct command short - form commands"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a list of currently linked devices from the hub", "response": "def get_linked(self):\n        \"\"\"Get a list of currently linked devices from the hub\"\"\"\n        linked_devices = {}\n        self.logger.info(\"\\nget_linked\")\n\n        #todo instead of sleep, create loop to keep checking buffer\n        self.direct_command_hub('0269')\n        sleep(1)\n        self.get_buffer_status()\n        msgs = self.buffer_status.get('msgs', [])\n        for entry in msgs:\n            im_code = entry.get('im_code', '')\n            #self.logger.info(\"get_linked entry {}\".format(pprint.pformat(entry)))\n\n            if im_code == '57':\n                device_id = entry.get('id_high', '') + entry.get('id_mid', '') \\\n                            + entry.get('id_low', '')\n                group = entry.get('group', '')\n                if device_id not in linked_devices:\n                    dev_info = self.id_request(device_id)\n                    dev_cat = dev_info.get('id_high', '')\n                    dev_sub_cat = dev_info.get('id_mid', '')\n                    dev_cat_record = self.get_device_category(dev_cat)\n                    if dev_cat_record and 'name' in dev_cat_record:\n                        dev_cat_name = dev_cat_record['name']\n                        dev_cat_type = dev_cat_record['type']\n                    else:\n                        dev_cat_name = 'unknown'\n                        dev_cat_type = 'unknown'\n\n                    linked_dev_model = self.get_device_model(dev_cat, dev_sub_cat)\n                    if 'name' in linked_dev_model:\n                        dev_model_name = linked_dev_model['name']\n                    else:\n                        dev_model_name = 'unknown'\n\n                    if 'sku' in linked_dev_model:\n                        dev_sku = linked_dev_model['sku']\n                    else:\n                        dev_sku = 'unknown'\n\n                    self.logger.info(\"get_linked: Got first device: %s group %s \"\n                                     \"cat type %s cat name %s dev model name %s\",\n                                     device_id, group, dev_cat_type,\n                                     dev_cat_name, dev_model_name)\n                    linked_devices[device_id] = {\n                        'cat_name': dev_cat_name,\n                        'cat_type': dev_cat_type,\n                        'model_name' : dev_model_name,\n                        'cat': dev_cat,\n                        'sub_cat': dev_sub_cat,\n                        'sku': dev_sku,\n                        'group': []\n                    }\n\n                linked_devices[device_id]['group'].append(group)\n\n        while self.buffer_status['success']:\n            self.direct_command_hub('026A')\n            sleep(1)\n            self.get_buffer_status()\n            msgs = self.buffer_status.get('msgs', [])\n            for entry in msgs:\n                im_code = entry.get('im_code', '')\n                if im_code == '57':\n                    device_id = entry.get('id_high', '') + entry.get('id_mid', '') \\\n                                + entry.get('id_low', '')\n                    group = entry.get('group', '')\n\n                    if device_id not in linked_devices:\n                        dev_info = self.id_request(device_id)\n                        dev_cat = dev_info.get('id_high', '')\n                        dev_sub_cat = dev_info.get('id_mid', '')\n                        dev_cat_record = self.get_device_category(dev_cat)\n                        if dev_cat_record and 'name' in dev_cat_record:\n                            dev_cat_name = dev_cat_record['name']\n                            dev_cat_type = dev_cat_record['type']\n                        else:\n                            dev_cat_name = 'unknown'\n                            dev_cat_type = 'unknown'\n\n                        linked_dev_model = self.get_device_model(dev_cat, dev_sub_cat)\n                        if 'name' in linked_dev_model:\n                            dev_model_name = linked_dev_model['name']\n                        else:\n                            dev_model_name = 'unknown'\n\n                        if 'sku' in linked_dev_model:\n                            dev_sku = linked_dev_model['sku']\n                        else:\n                            dev_sku = 'unknown'\n\n                        self.logger.info(\"get_linked: Got device: %s group %s \"\n                                         + \"cat type %s cat name %s dev model name %s\",\n                                         device_id, group, dev_cat_type,\n                                         dev_cat_name, dev_model_name)\n                        linked_devices[device_id] = {\n                            'cat_name': dev_cat_name,\n                            'cat_type': dev_cat_type,\n                            'model_name' : dev_model_name,\n                            'cat': dev_cat,\n                            'sub_cat': dev_sub_cat,\n                            'sku': dev_sku,\n                            'group': []\n                        }\n\n                    linked_devices[device_id]['group'].append(group)\n\n        self.logger.info(\"get_linked: Final device list: %s\", pprint.pformat(linked_devices))\n        return linked_devices"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the device category and name given the category id", "response": "def get_device_category(self, cat):\n        \"\"\"Return the device category and name given the category id\"\"\"\n        if cat in self.device_categories:\n            return self.device_categories[cat]\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the model name given cat sub_cat or product key", "response": "def get_device_model(self, cat, sub_cat, key=''):\n        \"\"\"Return the model name given cat/subcat or product key\"\"\"\n        if cat + ':' + sub_cat in self.device_models:\n            return self.device_models[cat + ':' + sub_cat]\n        else:\n            for i_key, i_val in self.device_models.items():\n                if 'key' in i_val:\n                    if i_val['key'] == key:\n                        return i_val\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef id_request(self, device_id):\n        self.logger.info(\"\\nid_request for device %s\", device_id)\n        device_id = device_id.upper()\n\n        self.direct_command(device_id, '10', '00')\n\n        sleep(2)\n\n        status = self.get_buffer_status(device_id)\n        if not status:\n            sleep(1)\n            status = self.get_buffer_status(device_id)\n\n        return status", "response": "Get the device for the ID."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_device_status(self, device_id, return_led=0, level=None):\n        # status['responseCmd2'] is lighting level\n        # responseCmd1 contains All-Link Database delta\n        # if returnLED = 0. returns light level in responseCmd2\n        # if returnLED = 1, returns LED Bit Flags in responseCmd1\n\n        self.logger.info(\"\\nget_device_status for device %s\", device_id)\n        device_id = device_id.upper()\n        status = False\n\n        if not level:\n            if return_led == 1:\n                level = '01'\n            else:\n                level = '00'\n\n        if os.path.exists(device_id + CACHE_FILE):\n            status = self.get_command_response_from_cache(device_id, '19', level)\n\n        if not status:\n            self.logger.info(\"no cached status for device %s\", device_id)\n            self.direct_command(device_id, '19', level)\n\n            attempts = 1\n            sleep(1)\n\n            status = self.get_buffer_status(device_id)\n            while 'success' not in status and attempts < 9:\n                status = self.get_command_response_from_cache(device_id, '19', level)\n                if not status:\n                    if attempts % 3 == 0:\n                        self.direct_command(device_id, '19', level)\n                    else:\n                        sleep(1)\n                    status = self.get_buffer_status(device_id)\n                attempts += 1\n        else:\n            self.logger.info(\"got cached status for device %s\", device_id)\n\n        return status", "response": "Get the status of a device. This can tell if the device is on or off. This can tell if the device is on or off. This can tell if the device is on or off. This can tell if the device is on or off. This can tell if the device is on or off. This can tell if the device is on or off."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_command_response_from_cache(self, device_id, command, command2):\n        key = self.create_key_from_command(command, command2)\n        command_cache = self.get_cache_from_file(device_id)\n\n        if device_id not in command_cache:\n            command_cache[device_id] = {}\n            return False\n        elif key not in command_cache[device_id]:\n            return False\n\n        response = command_cache[device_id][key]\n        expired = False\n        if response['ttl'] < int(time()):\n            self.logger.info(\"cache expired for device %s\", device_id)\n            expired = True\n\n            if os.path.exists(LOCK_FILE):\n                self.logger.info(\"cache locked - will wait to rebuild %s\", device_id)\n            else:\n                self.logger.info(\"cache unlocked - will rebuild %s\", device_id)\n                newpid = os.fork()\n                if newpid == 0:\n                    self.rebuild_cache(device_id, command, command2)\n\n        if expired:\n            self.logger.info(\"returning expired cached device status %s\", device_id)\n        else:\n            self.logger.info(\"returning unexpired cached device status %s\", device_id)\n\n        return response['response']", "response": "Gets response from cache"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets response to the command cache file", "response": "def set_command_response_from_cache(self, response, device_id, command, command2):\n        \"\"\"Sets response\"\"\"\n        if not device_id:\n            return False\n\n        key = self.create_key_from_command(command, command2)\n        ttl = int(time()) + CACHE_TTL\n\n        command_cache = self.get_cache_from_file(device_id)\n\n        if device_id not in command_cache:\n            command_cache[device_id] = {}\n\n        command_cache[device_id][key] = {'ttl': ttl, 'response': response}\n\n        self.write_cache_file(command_cache, device_id)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_success(self, device_id, sent_cmd1, sent_cmd2):\n        device_id = device_id.upper()\n\n        self.logger.info('check_success: for device %s cmd1 %s cmd2 %s',\n                         device_id, sent_cmd1, sent_cmd2)\n\n        sleep(2)\n        status = self.get_buffer_status(device_id)\n        check_id = status.get('id_from', '')\n        cmd1 = status.get('cmd1', '')\n        cmd2 = status.get('cmd2', '')\n        if (check_id == device_id) and (cmd1 == sent_cmd1) and (cmd2 == sent_cmd2):\n            self.logger.info(\"check_success: Response device %s cmd %s cmd2 %s SUCCESS\",\n                             check_id, cmd1, cmd2)\n            return True\n\n        self.logger.info(\"check_success: No valid response found for device %s cmd %s cmd2 %s\",\n                         device_id, sent_cmd1, sent_cmd2)\n        return False", "response": "Check if last command was successfully sent by checking buffer"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef clear_buffer(self):\n        command_url = self.hub_url + '/1?XB=M=1'\n        response = self.post_direct_command(command_url)\n        self.logger.info(\"clear_buffer: %s\", response)\n        return response", "response": "Clear the hub buffer"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef connect(self, **settings):\n        # compute a unique key for this settings, for caching. Work on the whole\n        # dict without directly using known keys to allow the use of unix socket\n        # connection or any other (future ?) way to connect to redis\n        if not settings:\n            settings = self.connection_settings\n        connection_key = ':'.join([str(settings[k]) for k in sorted(settings)])\n        if connection_key not in self._connections:\n            self._connections[connection_key] = redis.StrictRedis(\n                                            decode_responses=True, **settings)\n        return self._connections[connection_key]", "response": "Connect to redis and cache the new connection"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _add_model(self, model):\n        name = model._name\n        existing = self._models.get(name, None)\n        if not existing:\n            self._models[name] = model\n        elif model.__name__ != existing.__name__ or model._creation_source != existing._creation_source:\n            raise ImplementationError(\n                'A model with namespace \"%s\" and name \"%s\" is already defined '\n                'on this database' % (model.namespace, model.__name__))\n        return self._models[name]", "response": "Add a model to the database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _use_for_model(self, model):\n        original_database = getattr(model, 'database', None)\n\n        def get_models(model):\n            \"\"\"\n            Return the model and all its submodels that are on the same database\n            \"\"\"\n            model_database = getattr(model, 'database', None)\n            if model_database == self:\n                return []\n            models = [model]\n            for submodel in model.__subclasses__():\n                if getattr(submodel, 'database', None) == model_database:\n                    models += get_models(submodel)\n            return models\n\n        # put the model and all its matching submodels on the new database\n        models = get_models(model)\n        for _model in models:\n            if not _model.abstract:\n                self._add_model(_model)\n                del original_database._models[_model._name]\n            _model.database = self\n\n        # return updated models\n        return models", "response": "Update the given model to use the current database."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef redis_version(self):\n        if not hasattr(self, '_redis_version'):\n            self._redis_version = tuple(\n                map(int, self.connection.info().get('redis_version').split('.')[:3])\n            )\n        return self._redis_version", "response": "Return the redis version as a tuple"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if scripting is available.", "response": "def support_scripting(self):\n        \"\"\"\n        Returns True if scripting is available. Checks are done in the client\n        library (redis-py) AND the redis server. Result is cached, so done only\n        one time.\n        \"\"\"\n        if not hasattr(self, '_support_scripting'):\n            try:\n                self._support_scripting = self.redis_version >= (2, 5) \\\n                    and hasattr(self.connection, 'register_script')\n            except:\n                self._support_scripting = False\n        return self._support_scripting"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if zrangebylex is available.", "response": "def support_zrangebylex(self):\n        \"\"\"\n        Returns True if zrangebylex is available. Checks are done in the client\n        library (redis-py) AND the redis server. Result is cached, so done only\n        one time.\n        \"\"\"\n        if not hasattr(self, '_support_zrangebylex'):\n            try:\n                self._support_zrangebylex = self.redis_version >= (2, 8, 9) \\\n                    and hasattr(self.connection, 'zrangebylex')\n            except:\n                self._support_zrangebylex = False\n        return self._support_zrangebylex"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalling a redis script with keys and args", "response": "def call_script(self, script_dict, keys=None, args=None):\n        \"\"\"Call a redis script with keys and args\n\n        The first time we call a script, we register it to speed up later calls.\n        We expect a dict with a ``lua`` key having the script, and the dict will be\n        updated with a ``script_object`` key, with the content returned by the\n        the redis-py ``register_script`` command.\n\n        Parameters\n        ----------\n        script_dict: dict\n            A dict with a ``lua`` entry containing the lua code. A new key, ``script_object``\n            will be added after that.\n        keys: list of str\n            List of the keys that will be read/updated by the lua script\n        args: list of str\n            List of all the args expected by the script.\n\n        Returns\n        -------\n        Anything that will be returned by the script\n\n        \"\"\"\n        if keys is None:\n            keys = []\n        if args is None:\n            args = []\n        if 'script_object' not in script_dict:\n            script_dict['script_object'] = self.connection.register_script(script_dict['lua'])\n        return script_dict['script_object'](keys=keys, args=args, client=self.connection)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef scan_keys(self, match=None, count=None):\n        cursor = 0\n        while True:\n            cursor, keys = self.connection.scan(cursor, match=match, count=count)\n            for key in keys:\n                yield key\n            if not cursor or cursor == '0':  # string for redis.py < 2.10\n                break", "response": "Yields all the keys that match the pattern expected by the SCAN command."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating the line using the blob of json - parsed data directly from the API.", "response": "def _update(self, data):\n      '''Update the line using the blob of json-parsed data directly from the\n      API.\n      '''\n      self.bullet = data['bullet']\n      self.level = data['level']\n      self.text = WikiText(data['text_raw'],\n                           data['text_rendered'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef calcChebyshev(coeffs, validDomain, freqs):\n\n    logger = logging.getLogger(__name__)\n\n    domain = (validDomain[1] - validDomain[0])[0]\n    bins = -1 + 2* n.array([ (freqs[i]-validDomain[0,i])/domain for i in range(len(freqs))])\n    ncoeffs = len(coeffs[0])/2\n    rr = n.array([n.polynomial.chebyshev.chebval(bins[i], coeffs[i,:ncoeffs]) for i in range(len(coeffs))])\n    ll = n.array([n.polynomial.chebyshev.chebval(bins[i], coeffs[i,ncoeffs:]) for i in range(len(coeffs))])\n\n    return rr,ll", "response": "This method evaluates a Chebyshev approximation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parsegain(self, gainfile):\n\n        tb.open(gainfile)\n        mjd = tb.getcol('TIME')/(24*3600)     # mjd days, as for telcal\n        field = tb.getcol('FIELD_ID')\n        spw = tb.getcol('SPECTRAL_WINDOW_ID')\n        gain = tb.getcol('CPARAM')    # dimensions of (npol, 1?, ntimes*nants)\n        snr = tb.getcol('SNR')\n        flagged = tb.getcol('FLAG')\n        tb.close()\n        tb.open(os.path.join(gainfile, 'ANTENNA'))\n        antname = tb.getcol('NAME')   # ant number in order written to gain file\n        antnum = n.array([int(antname[i][2:]) for i in range(len(antname))])\n        tb.close()\n        tb.open(os.path.join(gainfile, 'FIELD'))\n        caldir = tb.getcol('PHASE_DIR')   # shape = (2 dirs, 1?, n sources)\n        calra = n.mod(caldir[0,0,:], 2*n.pi)\n        caldec = caldir[1,0,:]\n        self.radec = zip(calra, caldec)\n\n        tb.close()\n\n        # # need to find parent data MS to get some metadata\n        # mslist = glob.glob(gainfile[:-3] + '*.ms')\n        # try:\n        #     msfile = mslist[0]\n        #     self.logger.info('Found parent data MS %s' % msfile)\n        # except IndexError:\n        #     self.logger.warn('Could not find parent data MS for metadata...')\n\n        # tb.open(msfile + '/ANTENNA')\n        # antname = tb.getcol('NAME')      # one name per ant\n        # tb.close()\n        # tb.open(msfile + '/SPECTRAL_WINDOW')\n        # reffreq = 1e-6*(tb.getcol('REF_FREQUENCY')+tb.getcol('TOTAL_BANDWIDTH')/2)   # similar to telcal \"skyfreq\"\n        # specname = tb.getcol('NAME')\n        # tb.close()\n        # tb.open(msfile + '/SOURCE')\n        # source = [name for name in tb.getcol('NAME') if 'J' in name][0]          # should return single cal name **hack**\n        # tb.close()\n        # nsol = len(gain[0,0])\n\n        # ifid0R = specname[0][7] + '-' + specname[0][8]       # one value\n        # ifid0L = specname[0][9] + '-' + specname[0][10]       # one value\n        # ifid1R = specname[1][7] + '-' + specname[1][8]       # one value\n        # ifid1L = specname[1][9] + '-' + specname[1][10]       # one value\n\n        # # paste R,L end to end, so first loop over time, then spw, then pol\n        # mjd = n.concatenate( (time, time), axis=0)\n        # ifid = [ifid0R]*(nsol/2) + [ifid1R]*(nsol/2) + [ifid0L]*(nsol/2) + [ifid1L]*(nsol/2)   # first quarter is spw0,pol0, then spw1,pol0, ...\n        # skyfreq = n.concatenate( (reffreq[0]*n.ones(nsol/2), reffreq[1]*n.ones(nsol/2), reffreq[0]*n.ones(nsol/2), reffreq[1]*n.ones(nsol/2)), axis=0)\n        # gain = n.concatenate( (gain[0,0],gain[1,0]), axis=0)\n        # amp = n.abs(gain)\n        # phase = n.degrees(n.angle(gain))\n        # source = [source]*nsol*2\n        # flagged = n.concatenate( (flag[0,0],flag[1,0]), axis=0)\n                   \n        nants = len(n.unique(antnum))\n        nspw = len(n.unique(spw))\n        self.spwlist = n.unique(spw)\n        npol = len(gain)\n\n        # merge times less than some threshold\n        nsol = 0\n        newmjd = [n.unique(mjd)[0]]\n        uniquefield = [field[n.where(newmjd[0] == mjd)][0]]\n\n        skip = []\n        for i in range(1, len(n.unique(mjd))):\n            if 24*3600*(n.unique(mjd)[i] - n.unique(mjd)[i-1]) < 30.:\n                skip.append(n.unique(mjd)[i])\n                continue\n            else:\n                newmjd.append(n.unique(mjd)[i])\n                uniquefield.append(field[n.where(n.unique(mjd)[i] == mjd)[0][0]])\n        \n        self.uniquemjd = n.array(newmjd)\n        self.uniquefield = n.array(uniquefield)\n        nsol = len(self.uniquemjd)\n\n        self.logger.info('Parsed gain table solutions for %d solutions (skipping %d), %d ants, %d spw, and %d pols' % (nsol, len(skip), nants, nspw, npol))\n        self.logger.info('Unique solution fields/times: %s' % str(zip(self.uniquefield, self.uniquemjd)))\n\n        self.gain = n.zeros( (nsol, nants, nspw, npol), dtype='complex' )\n        flags = n.zeros( (nsol, nants, nspw, npol), dtype='complex' )\n        for sol in range(nsol):\n            for ant in range(nants):\n                for spw in range(nspw):\n                    for pol in range(npol):\n                        self.gain[sol, ant, spw, pol] = gain[pol,0,spw*nsol*nants+sol*nants+ant]\n                        flags[sol, ant, spw, pol] = flagged[pol,0,spw*nsol*nants+sol*nants+ant]\n        self.gain = n.ma.masked_array(self.gain, flags)\n\n#        gain = n.concatenate( (n.concatenate( (gain[0,0,:nants*nsol].reshape(nsol,nants,1,1), gain[1,0,:nants*nsol].reshape(nsol,nants,1,1)), axis=3), n.concatenate( (gain[0,0,nants*nsol:].reshape(nsol,nants,1,1), gain[1,0,nants*nsol:].reshape(nsol,nants,1,1)), axis=3)), axis=2)\n#        flagged = n.concatenate( (n.concatenate( (flagged[0,0,:nants*nsol].reshape(nsol,nants,1,1), flagged[1,0,:nants*nsol].reshape(nsol,nants,1,1)), axis=3), n.concatenate( (flagged[0,0,nants*nsol:].reshape(nsol,nants,1,1), flagged[1,0,nants*nsol:].reshape(nsol,nants,1,1)), axis=3)), axis=2)\n#        self.gain = n.ma.masked_array(gain, flagged == True)        \n\n        self.mjd = n.array(mjd); self.antnum = antnum", "response": "Parses the. g1 file and stores the values in numpy arrays."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parsebp(self, bpfile, debug=False):\n\n        # bandpass. taking liberally from Corder et al's analysisutilities\n        ([polyMode, polyType, nPolyAmp, nPolyPhase, scaleFactor, nRows, nSpws, nUniqueTimesBP, uniqueTimesBP,\n          nPolarizations, frequencyLimits, increments, frequenciesGHz, polynomialPhase,\n          polynomialAmplitude, timesBP, antennasBP, cal_desc_idBP, spwBP]) = openBpolyFile(bpfile, debug)\n\n        # index iterates over antennas, then times/sources (solution sets). each index has 2x npoly, which are 2 pols\n        polynomialAmplitude = n.array(polynomialAmplitude); polynomialPhase = n.array(polynomialPhase)\n        polynomialAmplitude[:,0] = 0.; polynomialAmplitude[:,nPolyAmp] = 0.\n        polynomialPhase[:,0] = 0.; polynomialPhase[nPolyPhase] = 0.\n        ampSolR, ampSolL = calcChebyshev(polynomialAmplitude, frequencyLimits, n.array(frequenciesGHz)*1e+9)\n        phaseSolR, phaseSolL = calcChebyshev(polynomialPhase, frequencyLimits, n.array(frequenciesGHz)*1e+9)\n\n        nants = len(n.unique(antennasBP))\n        self.bptimes = n.array(timesBP)\n        ptsperspec = 1000\n        npol = 2\n        self.logger.info('Parsed bp solutions for %d solutions, %d ants, %d spw, and %d pols' % (nUniqueTimesBP, nants, nSpws, nPolarizations))\n        self.bandpass = n.zeros( (nants, nSpws*ptsperspec, npol), dtype='complex')\n        for spw in range(nSpws):\n            ampSolR[spw*nants:(spw+1)*nants] += 1 - ampSolR[spw*nants:(spw+1)*nants].mean()     # renormalize mean over ants (per spw) == 1\n            ampSolL[spw*nants:(spw+1)*nants] += 1 - ampSolL[spw*nants:(spw+1)*nants].mean()\n            for ant in range(nants):\n                self.bandpass[ant, spw*ptsperspec:(spw+1)*ptsperspec, 0] = ampSolR[ant+spw*nants] * n.exp(1j*phaseSolR[ant+spw*nants])\n                self.bandpass[ant, spw*ptsperspec:(spw+1)*ptsperspec, 1] = ampSolL[ant+spw*nants] * n.exp(1j*phaseSolL[ant+spw*nants])\n\n        self.bpfreq = n.zeros( (nSpws*ptsperspec) )\n        for spw in range(nSpws):\n            self.bpfreq[spw*ptsperspec:(spw+1)*ptsperspec] = 1e9 * frequenciesGHz[nants*spw]", "response": "Parses the CASA calibration table and stores the values in numpy arrays."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_selection(self, time, freqs, blarr, calname='', radec=(), dist=1, spwind=[], pols=['XX','YY']):\n\n        self.spwind = spwind\n        if calname:\n            self.logger.warn('calname option not used for casa_sol. Applied based on radec.')\n\n        # define pol index\n        if 'X' in ''.join(pols) or 'Y' in ''.join(pols):\n            polord = ['XX', 'YY']\n        elif 'R' in ''.join(pols) or 'L' in ''.join(pols):\n            polord = ['RR', 'LL']\n        self.polind = [polord.index(pol) for pol in pols]\n\n        self.ant1ind = [n.where(ant1 == n.unique(blarr))[0][0] for (ant1,ant2) in blarr]\n        self.ant2ind = [n.where(ant2 == n.unique(blarr))[0][0] for (ant1,ant2) in blarr]\n\n        # select by smallest time distance for source within some angular region of target\n        if radec:\n            ra, dec = radec\n            calra = n.array(self.radec)[:,0]\n            caldec = n.array(self.radec)[:,1]\n            fields = n.where( (n.abs(calra - ra) < n.radians(dist)) & (n.abs(caldec - dec) < n.radians(dist)) )[0]\n            if len(fields) == 0:\n                self.logger.warn('Warning: no close calibrator found. Removing radec restriction.')\n                fields = n.unique(self.uniquefield)\n        else:\n            fields = n.unique(self.uniquefield)\n\n        sel = []\n        for field in fields:\n            sel += list(n.where(field == self.uniquefield)[0])\n        mjddist = n.abs(time - self.uniquemjd[sel])\n        closestgain = n.where(mjddist == mjddist.min())[0][0]\n\n        self.logger.info('Using gain solution for field %d at MJD %.5f, separated by %d min ' % (self.uniquefield[n.where(self.uniquemjd == self.uniquemjd[sel][closestgain])], self.uniquemjd[closestgain], mjddist[closestgain]*24*60))\n        self.gain = self.gain.take(self.spwind, axis=2).take(self.polind, axis=3)[closestgain]\n\n        if hasattr(self, 'bandpass'):\n            bins = [n.where(n.min(n.abs(self.bpfreq-selfreq)) == n.abs(self.bpfreq-selfreq))[0][0] for selfreq in freqs]\n            self.bandpass = self.bandpass.take(bins, axis=1).take(self.polind, axis=2)\n            self.freqs = freqs\n            self.logger.debug('Using bandpass at BP bins (1000 bins per spw): %s', str(bins))", "response": "Set the select parameter that defines time spw and pol for a given set of bandpass solutions."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the antennas to flag based on bad gain and bp solutions.", "response": "def calc_flag(self, sig=3.0):\n        \"\"\" Calculates antennas to flag, based on bad gain and bp solutions.\n        \"\"\"\n \n        if len(self.gain.shape) == 4:\n            gamp = n.abs(self.gain).mean(axis=0)   # mean gain amp for each ant over time\n        elif len(self.gain.shape) == 3:\n            gamp = n.abs(self.gain)   # gain amp for selected time\n\n#        badgain = n.where(gamp < gamp.mean() - sig*gamp.std())\n        badgain = n.where( (gamp < gamp.mean() - sig*gamp.std()) | gamp.mask)\n        self.logger.info('Flagging low/bad gains for ant/spw/pol: %s %s %s' % (str(self.antnum[badgain[0]]), str(badgain[1]), str(badgain[2])))\n\n        badants = badgain\n        return badants"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\napply calibration solution to data array. Assumes structure of nint nbl nch npol.", "response": "def apply(self, data):\n        \"\"\" Applies calibration solution to data array. Assumes structure of (nint, nbl, nch, npol).\n        \"\"\"\n\n        # flag bad ants\n        if self.flagants:\n            badants = self.calc_flag()\n        else:\n            badants = n.array([[]])\n\n        # apply gain correction\n        if hasattr(self, 'bandpass'):\n            corr = n.ones_like(data)\n            flag = n.ones_like(data.real).astype('int')\n            chans_uncal = range(len(self.freqs))\n            for spwi in range(len(self.spwind)):\n                chsize = n.round(self.bpfreq[1]-self.bpfreq[0], 0)\n                ww = n.where( (self.freqs >= self.bpfreq[self.spwind[spwi]*1000]) & (self.freqs <= self.bpfreq[(self.spwind[spwi]+1)*1000-1]+chsize) )[0]\n                if len(ww) == 0:\n                    self.logger.info('Gain solution frequencies not found in data for spw %d.' % (self.spwind[spwi]))\n                firstch = ww[0]\n                lastch = ww[-1]+1\n                for ch in ww:\n                    chans_uncal.remove(ch)\n                self.logger.info('Combining gain sol from spw=%d with BW chans from %d-%d' % (self.spwind[spwi], firstch, lastch))\n                for badant in n.transpose(badants):\n                    if badant[1] == spwi:\n                        badbl = n.where((badant[0] == n.array(self.ant1ind)) | (badant[0] == n.array(self.ant2ind)))[0]\n                        flag[:, badbl, firstch:lastch, badant[2]] = 0\n\n                corr1 = self.gain[self.ant1ind, spwi, :][None, :, None, :] * self.bandpass[self.ant1ind, firstch:lastch, :][None, :, :, :]\n                corr2 = (self.gain[self.ant2ind, spwi, :][None, :, None, :] * self.bandpass[self.ant2ind, firstch:lastch, :][None, :, :, :]).conj()\n\n                corr[:, :, firstch:lastch, :] = corr1 * corr2\n            if len(chans_uncal):\n                self.logger.info('Setting data without bp solution to zero for chans %s.' % (chans_uncal))\n                flag[:, :, chans_uncal,:] = 0\n            data[:] *= flag/corr\n        else:\n            for spw in range(len(self.gain[0,0])):\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef plot(self):\n        import pylab as p\n        p.clf()\n        fig = p.figure(1)\n        nspw = len(self.gain[0])\n        ext = n.ceil(n.sqrt(nspw))  # find best squre plot (simplest)\n        for spw in range(len(self.gain[0])):\n            ax = fig.add_subplot(ext, ext, spw+1)\n            for pol in [0,1]:\n                ax.scatter(range(len(self.gain)), n.abs(self.gain.data[:,spw,pol]), color=n.array(['k','y']).take(self.gain.mask[:,spw,pol]), marker=['x','.'][pol])\n\n        fig.show()", "response": "Quick visualization of calibration solution."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nflagging solutions with amplitude less than threshold larger than median.", "response": "def flagants(self, threshold=50):\n        \"\"\" Flags solutions with amplitude more than threshold larger than median.\n        \"\"\"\n\n        # identify very low gain amps not already flagged\n        badsols = n.where( (n.median(self.amp)/self.amp > threshold) & (self.flagged == False))[0]\n        if len(badsols):\n            self.logger.info('Solutions %s flagged (times %s, ants %s, freqs %s) for low gain amplitude.' % (str(badsols), self.mjd[badsols], self.antname[badsols], self.ifid[badsols]))\n            for sol in badsols:\n                self.flagged[sol] = True"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the select parameter that defines spectral window time frequency and frequency for a given calibrator.", "response": "def set_selection(self, time, freqs, blarr, calname='', radec=(), dist=0, spwind=[], pols=['XX','YY']):\n        \"\"\" Set select parameter that defines spectral window, time, or any other selection.\n        time (in mjd) defines the time to find solutions near for given calname.\n        freqs (in Hz) is frequencies in data.\n        blarr is array of size 2xnbl that gives pairs of antennas in each baseline (a la tpipe.blarr).\n        calname defines the name of the calibrator to use. if blank, uses only the time selection.\n        pols is from d['pols'] (e.g., ['RR']). single or dual parallel allowed. not yet implemented.\n        radec, dist, spwind not used. here for uniformity with casa_sol.\n        \"\"\"\n\n        self.freqs = freqs\n        self.chansize = freqs[1]-freqs[0]\n        self.select = self.complete   # use only complete solution sets (set during parse)\n        self.blarr = blarr\n        if spwind:\n            self.logger.warn('spwind option not used for telcal_sol. Applied based on freqs.')\n        if radec:\n            self.logger.warn('radec option not used for telcal_sol. Applied based on calname.')\n        if dist:\n            self.logger.warn('dist option not used for telcal_sol. Applied based on calname.')\n\n        # define pol index\n        if 'X' in ''.join(pols) or 'Y' in ''.join(pols):\n            polord = ['XX', 'YY']\n        elif 'R' in ''.join(pols) or 'L' in ''.join(pols):\n            polord = ['RR', 'LL']\n        self.polind = [polord.index(pol) for pol in pols]\n\n        if calname:\n            nameselect = []\n            for ss in n.unique(self.source[self.select]):\n                if calname in ss:\n                    nameselect = n.where(self.source[self.select] == ss)   # define selection for name\n                    self.select = self.select[nameselect]       # update overall selection\n                    self.logger.debug('Selection down to %d solutions with %s' % (len(self.select), calname))\n            if not nameselect:\n                self.logger.warn('Calibrator name %s not found. Ignoring.' % (calname))\n\n        # select freq\n        freqselect = n.where([ff in n.around(self.freqs, -6) for ff in n.around(1e6*self.skyfreq[self.select], -6)])   # takes solution if band center is in (rounded) array of chan freqs\n        if len(freqselect[0]) == 0:\n            raise StandardError('No complete set of telcal solutions at that frequency.')\n        self.select = self.select[freqselect[0]]    # update overall selection\n        self.logger.info('Frequency selection cut down to %d solutions' % (len(self.select)))\n\n        # select pol\n#        ifids = self.ifid[self.select]\n#        if (polstr == 'RR') or (polstr == 'XX'):\n#            polselect = n.where(['A' in ifid or 'B' in ifid for ifid in ifids])\n#        elif (polstr == 'LL') or (polstr == 'YY'):\n#            polselect = n.where(['C' in ifid or 'D' in ifid for ifid in ifids])\n#        self.select = self.select[polselect]    # update overall selection\n        self.polarization = n.empty(len(self.ifid))\n        for i in range(len(self.ifid)):\n            if ('A' in self.ifid[i]) or ('B' in self.ifid[i]):\n                self.polarization[i] = 0\n            elif ('C' in self.ifid[i]) or ('D' in self.ifid[i]):\n                self.polarization[i] = 1\n\n        # select by smallest time distance for source\n        mjddist = n.abs(time - n.unique(self.mjd[self.select]))\n        closest = n.where(mjddist == mjddist.min())\n        if len(closest[0]) > 1:\n            self.logger.info('Multiple closest solutions in time (%s). Taking first.' % (str(closest[0])))\n            closest = closest[0][0]\n        timeselect = n.where(self.mjd[self.select] == n.unique(self.mjd[self.select])[closest])   # define selection for time\n        self.select = self.select[timeselect[0]]    # update overall selection\n        self.logger.info('Selection down to %d solutions separated from given time by %d minutes' % (len(self.select), mjddist[closest]*24*60))\n\n        self.logger.debug('Selected solutions: %s' % str(self.select))\n        self.logger.info('MJD: %s' % str(n.unique(self.mjd[self.select])))\n        self.logger.debug('Mid frequency (MHz): %s' % str(n.unique(self.skyfreq[self.select])))\n        self.logger.debug('IFID: %s' % str(n.unique(self.ifid[self.select])))\n        self.logger.info('Source: %s' % str(n.unique(self.source[self.select])))\n        self.logger.debug('Ants: %s' % str(n.unique(self.antname[self.select])))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parseGN(self, telcalfile, onlycomplete=True):\n\n        skip = 3   # skip first three header lines\n        MJD = 0; UTC = 1; LSTD = 2; LSTS = 3; IFID = 4; SKYFREQ = 5; ANT = 6; AMP = 7; PHASE = 8\n        RESIDUAL = 9; DELAY = 10; FLAGGED = 11; ZEROED = 12; HA = 13; AZ = 14; EL = 15\n        SOURCE = 16\n        #FLAGREASON = 17\n\n        mjd = []; utc = []; lstd = []; lsts = []; ifid = []; skyfreq = []; \n        antname = []; amp = []; phase = []; residual = []; delay = []; \n        flagged = []; zeroed = []; ha = []; az = []; el = []; source = []\n        #flagreason = []\n\n        i = 0\n        for line in open(telcalfile,'r'):\n\n            fields = line.split()\n            if i < skip:\n                i += 1\n                continue\n\n            if ('NO_ANTSOL_SOLUTIONS_FOUND' in line):\n                # keep ERROR solutions now that flagging works\n                continue\n\n            try:\n                mjd.append(float(fields[MJD])); utc.append(fields[UTC]); lstd.append(float(fields[LSTD])); lsts.append(fields[LSTS])\n                ifid.append(fields[IFID]); skyfreq.append(float(fields[SKYFREQ])); antname.append(fields[ANT])\n                amp.append(float(fields[AMP])); phase.append(float(fields[PHASE])); residual.append(float(fields[RESIDUAL]))\n                delay.append(float(fields[DELAY])); flagged.append('true' == (fields[FLAGGED]))\n                zeroed.append('true' == (fields[ZEROED])); ha.append(float(fields[HA])); az.append(float(fields[AZ]))\n                el.append(float(fields[EL])); source.append(fields[SOURCE])\n#                flagreason.append('')  # 18th field not yet implemented\n            except ValueError:\n                self.logger.warn('Trouble parsing line of telcal file. Skipping.')\n                continue\n\n        self.mjd = n.array(mjd); self.utc = n.array(utc); self.lstd = n.array(lstd); self.lsts = n.array(lsts)\n        self.ifid = n.array(ifid); self.skyfreq = n.array(skyfreq); self.antname = n.array(antname); self.amp = n.array(amp) \n        self.phase = n.array(phase); self.residual = n.array(residual); self.delay = n.array(delay)\n        self.flagged = n.array(flagged); self.zeroed = n.array(zeroed); self.ha = n.array(ha); self.az = n.array(az)\n        self.el = n.array(el); self.source = n.array(source); \n        #self.flagreason = n.array(flagreason)\n\n        # purify list to keep only complete solution sets\n        if onlycomplete:\n            completecount = len(n.unique(self.ifid)) * len(n.unique(self.antname))\n            complete = []\n            for mjd in n.unique(self.mjd):\n                mjdselect = list(n.where(mjd == self.mjd)[0])\n                if len(mjdselect) == completecount:\n                    complete = complete + mjdselect\n            self.complete = n.array(complete)\n        else:\n            self.complete = n.arange(len(self.mjd))\n\n        # make another version of ants array\n        antnum = []\n        for aa in self.antname:\n            antnum.append(int(aa[2:]))    # cuts the 'ea' from start of antenna string to get integer\n        self.antnum = n.array(antnum)", "response": "Parses the. GN file and places values in numpy arrays."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef calcgain(self, ant1, ant2, skyfreq, pol):\n\n        select = self.select[n.where( (self.skyfreq[self.select] == skyfreq) & (self.polarization[self.select] == pol) )[0]]\n\n        if len(select):  # for when telcal solutions don't exist\n            ind1 = n.where(ant1 == self.antnum[select])\n            ind2 = n.where(ant2 == self.antnum[select])\n            g1 = self.amp[select][ind1]*n.exp(1j*n.radians(self.phase[select][ind1])) * (not self.flagged.astype(int)[select][ind1][0])\n            g2 = self.amp[select][ind2]*n.exp(-1j*n.radians(self.phase[select][ind2])) * (not self.flagged.astype(int)[select][ind2][0])\n        else:\n            g1 = [0]; g2 = [0]\n\n        try:\n            assert (g1[0] != 0j) and (g2[0] != 0j)\n            invg1g2 = 1./(g1[0]*g2[0])\n        except (AssertionError, IndexError):\n            invg1g2 = 0\n        return invg1g2", "response": "Calculates the complex gain product for a pair of antennas."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the relative delay of antennas in ns.", "response": "def calcdelay(self, ant1, ant2, skyfreq, pol):\n        \"\"\" Calculates the relative delay (d1-d2) for a pair of antennas in ns.\n        \"\"\"\n\n        select = self.select[n.where( (self.skyfreq[self.select] == skyfreq) & (self.polarization[self.select] == pol) )[0]]\n\n        ind1 = n.where(ant1 == self.antnum[select])\n        ind2 = n.where(ant2 == self.antnum[select])\n        d1 = self.delay[select][ind1]\n        d2 = self.delay[select][ind2]\n        if len(d1-d2) > 0:\n            return d1-d2\n        else:\n            return n.array([0])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\napply calibration solution to data array. Assumes structure of nint nbl nch npol.", "response": "def apply(self, data):\n        \"\"\" Applies calibration solution to data array. Assumes structure of (nint, nbl, nch, npol).\n        \"\"\"\n\n        # find best skyfreq for each channel\n        skyfreqs = n.unique(self.skyfreq[self.select])    # one per spw\n        nch_tot = len(self.freqs)\n        chan_bandnum = [range(nch_tot*i/len(skyfreqs), nch_tot*(i+1)/len(skyfreqs)) for i in range(len(skyfreqs))]  # divide chans by number of spw in solution\n        self.logger.info('Solutions for %d spw: (%s)' % (len(skyfreqs), skyfreqs))\n\n        for j in range(len(skyfreqs)):\n            skyfreq = skyfreqs[j]\n            chans = chan_bandnum[j]\n            self.logger.info('Applying gain solution for chans from %d-%d' % (chans[0], chans[-1]))\n\n            # define freq structure to apply delay solution\n            nch = len(chans)\n            chanref = nch/2    # reference channel at center\n            relfreq = self.chansize*(n.arange(nch) - chanref)   # relative frequency\n\n            for i in range(len(self.blarr)):\n                ant1, ant2 = self.blarr[i]  # ant numbers (1-based)\n                for pol in self.polind:\n                    # apply gain correction\n                    invg1g2 = self.calcgain(ant1, ant2, skyfreq, pol)\n                    data[:,i,chans,pol-self.polind[0]] = data[:,i,chans,pol-self.polind[0]] * invg1g2    # hack: lousy data pol indexing\n\n                    # apply delay correction\n                    d1d2 = self.calcdelay(ant1, ant2, skyfreq, pol)\n                    delayrot = 2*n.pi*(d1d2[0] * 1e-9) * relfreq      # phase to rotate across band\n                    data[:,i,chans,pol-self.polind[0]] = data[:,i,chans,pol-self.polind[0]] * n.exp(-1j*delayrot[None, None, :])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn RingBuffer class using the given CFFI instance.", "response": "def init(ffi, lib):\n    \"\"\"Return RingBuffer class using the given CFFI instance.\"\"\"\n\n    class RingBuffer(_RingBufferBase):\n        __doc__ = _RingBufferBase.__doc__\n        _ffi = ffi\n        _lib = lib\n\n    return RingBuffer"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite data to the ring buffer.", "response": "def write(self, data, size=-1):\n        \"\"\"Write data to the ring buffer.\n\n        This advances the write index after writing;\n        calling :meth:`advance_write_index` is *not* necessary.\n\n        :param data: Data to write to the buffer.\n        :type data: CData pointer or buffer or bytes\n        :param size: The number of elements to be written.\n        :type size: int, optional\n\n        :returns: The number of elements written.\n        :rtype: int\n\n        \"\"\"\n        try:\n            data = self._ffi.from_buffer(data)\n        except TypeError:\n            pass  # input is not a buffer\n        if size < 0:\n            size, rest = divmod(self._ffi.sizeof(data), self.elementsize)\n            if rest:\n                raise ValueError('data size must be multiple of elementsize')\n        return self._lib.PaUtil_WriteRingBuffer(self._ptr, data, size)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads data from the ring buffer into a new buffer.", "response": "def read(self, size=-1):\n        \"\"\"Read data from the ring buffer into a new buffer.\n\n        This advances the read index after reading;\n        calling :meth:`advance_read_index` is *not* necessary.\n\n        :param size: The number of elements to be read.\n            If not specified, all available elements are read.\n        :type size: int, optional\n\n        :returns: A new buffer containing the read data.\n            Its size may be less than the requested *size*.\n        :rtype: buffer\n\n        \"\"\"\n        if size < 0:\n            size = self.read_available\n        data = self._ffi.new('unsigned char[]', size * self.elementsize)\n        size = self.readinto(data)\n        return self._ffi.buffer(data, size * self.elementsize)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread data from the ring buffer into a user - provided buffer.", "response": "def readinto(self, data):\n        \"\"\"Read data from the ring buffer into a user-provided buffer.\n\n        This advances the read index after reading;\n        calling :meth:`advance_read_index` is *not* necessary.\n\n        :param data: The memory where the data should be stored.\n        :type data: CData pointer or buffer\n\n        :returns: The number of elements read, which may be less than\n            the size of *data*.\n        :rtype: int\n\n        \"\"\"\n        try:\n            data = self._ffi.from_buffer(data)\n        except TypeError:\n            pass  # input is not a buffer\n        size, rest = divmod(self._ffi.sizeof(data), self.elementsize)\n        if rest:\n            raise ValueError('data size must be multiple of elementsize')\n        return self._lib.PaUtil_ReadRingBuffer(self._ptr, data, size)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the write buffers for the current locale.", "response": "def get_write_buffers(self, size):\n        \"\"\"Get buffer(s) to which we can write data.\n\n        When done writing, use :meth:`advance_write_index` to make the\n        written data available for reading.\n\n        :param size: The number of elements desired.\n        :type size: int\n\n        :returns:\n            * The room available to be written or the given *size*,\n              whichever is smaller.\n            * The first buffer.\n            * The second buffer.\n        :rtype: (int, buffer, buffer)\n\n        \"\"\"\n        ptr1 = self._ffi.new('void**')\n        ptr2 = self._ffi.new('void**')\n        size1 = self._ffi.new('ring_buffer_size_t*')\n        size2 = self._ffi.new('ring_buffer_size_t*')\n        return (self._lib.PaUtil_GetRingBufferWriteRegions(\n                    self._ptr, size, ptr1, size1, ptr2, size2),\n                self._ffi.buffer(ptr1[0], size1[0] * self.elementsize),\n                self._ffi.buffer(ptr2[0], size2[0] * self.elementsize))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_read_buffers(self, size):\n        ptr1 = self._ffi.new('void**')\n        ptr2 = self._ffi.new('void**')\n        size1 = self._ffi.new('ring_buffer_size_t*')\n        size2 = self._ffi.new('ring_buffer_size_t*')\n        return (self._lib.PaUtil_GetRingBufferReadRegions(\n                    self._ptr, size, ptr1, size1, ptr2, size2),\n                self._ffi.buffer(ptr1[0], size1[0] * self.elementsize),\n                self._ffi.buffer(ptr2[0], size2[0] * self.elementsize))", "response": "Get the read buffers from which we can read data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of connected hosts and the number of connections to each.", "response": "def open_connections(self):\n        \"\"\"return a list of connected hosts and the number of connections\n        to each.  [('foo.com:80', 2), ('bar.org', 1)]\"\"\"\n        return [(host, len(li)) for (host, li) in self._cm.get_all().items()]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef close_connection(self, host):\n        for h in self._cm.get_all(host):\n            self._cm.remove(h)\n            h.close()", "response": "close connection to a specific host"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef close_all(self):\n        for host, conns in self._cm.get_all().items():\n            for h in conns:\n                self._cm.remove(h)\n                h.close()", "response": "close all open connections"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstarting the transaction with a re-used connection return a response object (r) upon success or None on failure. This DOES not close or remove bad connections in cases where it returns. However, if an unexpected exception occurs, it will close and remove the connection before re-raising.", "response": "def _reuse_connection(self, h, req, host):\n        \"\"\"start the transaction with a re-used connection\n        return a response object (r) upon success or None on failure.\n        This DOES not close or remove bad connections in cases where\n        it returns.  However, if an unexpected exception occurs, it\n        will close and remove the connection before re-raising.\n        \"\"\"\n        try:\n            self._start_transaction(h, req)\n            r = h.getresponse()\n            # note: just because we got something back doesn't mean it\n            # worked.  We'll check the version below, too.\n        except (socket.error, httplib.HTTPException):\n            r = None\n        except:\n            # adding this block just in case we've missed\n            # something we will still raise the exception, but\n            # lets try and close the connection and remove it\n            # first.  We previously got into a nasty loop\n            # where an exception was uncaught, and so the\n            # connection stayed open.  On the next try, the\n            # same exception was raised, etc.  The tradeoff is\n            # that it's now possible this call will raise\n            # a DIFFERENT exception\n            if DEBUG: DEBUG.error(\"unexpected exception - closing \" + \\\n                                  \"connection to %s (%d)\", host, id(h))\n            self._cm.remove(h)\n            h.close()\n            raise\n                    \n        if r is None or r.version == 9:\n            # httplib falls back to assuming HTTP 0.9 if it gets a\n            # bad header back.  This is most likely to happen if\n            # the socket has been closed by the server since we\n            # last used the connection.\n            if DEBUG: DEBUG.info(\"failed to re-use connection to %s (%d)\",\n                                 host, id(h))\n            r = None\n        else:\n            if DEBUG: DEBUG.info(\"re-using connection to %s (%d)\", host, id(h))\n\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the sdm file and returns a dictionary of metadata for observation.", "response": "def get_metadata(filename, scan, paramfile='', **kwargs):\n    \"\"\" Parses sdm file to define metadata for observation, including scan info,\n    image grid parameters, pipeline memory usage, etc.\n    Mirrors parsems.get_metadata().\n    If paramfile defined, it will use it (filename or RT.Params instance ok).\n    \"\"\"\n\n    # create primary state dictionary\n    d = {}\n\n    # set workdir\n    d['filename'] = os.path.abspath(filename)\n    d['workdir'] = os.path.dirname(d['filename'])\n\n    # define parameters of pipeline via Params object\n    params = pp.Params(paramfile)\n    for k in params.defined:   # fill in default params\n        d[k] = params[k]\n\n    # overload with provided kwargs\n    for key in kwargs.keys():\n        if key in params.defined:\n            stdname = '(standard)'\n        else:\n            stdname = ''\n        logger.info('Setting %s key %s to %s' % (stdname, key, kwargs[key]))\n        d[key] = kwargs[key]\n\n    # option of not writing log file (need to improve later)\n    if d['logfile']:\n        fh = logging.FileHandler(os.path.join(d['workdir'], 'rtpipe_%d.log' % int(round(time()))))\n        fh.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))\n        logger.parent.addHandler(fh)\n        if hasattr(logging, d['loglevel']):\n            logger.parent.setLevel(getattr(logging, d['loglevel']))\n        else:\n            logger.warn('loglevel of {0} not attribute of logging'.format(d['loglevel']))\n\n    # define scan list\n#    if 'bdfdir' not in d:\n#        d['bdfdir'] = ''\n\n    scans = read_scans(d['filename'], bdfdir=d['bdfdir'])\n    sources = read_sources(d['filename'])\n\n    # define source props\n    d['source'] = scans[scan]['source']\n    d['radec'] = [(prop['ra'], prop['dec'])\n                  for (sr, prop) in sources.iteritems()\n                  if prop['source'] == d['source']][0]\n\n    # define spectral info\n    sdm = getsdm(d['filename'], bdfdir=d['bdfdir'])\n    d['spw_orig'] = [int(str(row.spectralWindowId).split('_')[1])\n                     for row in sdm['SpectralWindow']]\n    d['spw_nchan'] = [int(row.numChan) for row in sdm['SpectralWindow']]\n\n    try:\n        d['spw_reffreq'] = [float(row.chanFreqStart)\n                            for row in sdm['SpectralWindow']]   # nominal\n    except:\n        # GMRT uses array of all channel starts\n        d['spw_reffreq'] = [float(row.chanFreqArray.strip().split(' ')[2])\n                            for row in sdm['SpectralWindow']]\n    try:\n        d['spw_chansize'] = [float(row.chanFreqStep)\n                             for row in sdm['SpectralWindow']]   # nominal\n    except:\n        # GMRT uses array of all channel starts\n        d['spw_chansize'] = [float(row.chanWidthArray.strip().split(' ')[2])\n                             for row in sdm['SpectralWindow']]\n\n    # select spw. note that spw selection not fully supported yet.\n    if not len(d['spw']):\n        d['spw'] = d['spw_orig']\n\n    spwch = []\n    reffreq = d['spw_reffreq']\n    spectralwindow = d['spw_orig']\n    numchan = d['spw_nchan']\n    chansize = d['spw_chansize']\n    for freq in sorted(d['spw_reffreq']):\n        ii = reffreq.index(freq)\n        if spectralwindow[ii] in d['spw']:\n            # spacing of channel *centers*\n            spwch.extend(list(np.linspace(reffreq[ii], reffreq[ii]\n                                          + (numchan[ii]-1) * chansize[ii],\n                                          numchan[ii])))\n\n    d['freq_orig'] = np.array([np.mean(spwch[i:i+d['read_fdownsample']])\n                               for i in range(0, len(spwch),\n                                              d['read_fdownsample'])],\n                              dtype='float32') / 1e9\n\n    # select subset of channels\n    if not len(d['chans']):\n        d['chans'] = range(len(d['freq_orig']))\n\n    d['nspw'] = len(d['spw'])\n    d['freq'] = d['freq_orig'][d['chans']]\n    d['nchan'] = len(d['chans'])\n\n    # define chan ranges per spw (before selecting subset)\n    spw_chanr = []\n    i0 = 0\n    for nch in d['spw_nchan']:\n        spw_chanr.append((i0, i0+nch))\n        i0 = nch\n    d['spw_chanr'] = spw_chanr\n\n    # define nchan per spw after selecting subset\n    d['spw_nchan_select'] = [len([ch\n                                  for ch in range(d['spw_chanr'][i][0],\n                                                  d['spw_chanr'][i][1])\n                                  if ch in d['chans']])\n                             for i in range(len(d['spw_chanr']))]\n    spw_chanr_select = []\n    i0 = 0\n    for nch in d['spw_nchan_select']:\n        spw_chanr_select.append((i0, i0+nch))\n        i0 += nch\n    d['spw_chanr_select'] = spw_chanr_select\n\n    # define image params\n    d['urange'] = {}\n    d['vrange'] = {}\n    d['scan'] = scan\n    (u, v, w) = calc_uvw(d['filename'],\n                         d['scan'], bdfdir=d['bdfdir'])  # default uses time at start\n    u = u * d['freq_orig'][0] * (1e9/3e8) * (-1)\n    v = v * d['freq_orig'][0] * (1e9/3e8) * (-1)\n    d['urange'][d['scan']] = u.max() - u.min()\n    d['vrange'][d['scan']] = v.max() - v.min()\n    d['dishdiameter'] = float(str(sdm['Antenna'][0]\n                                  .dishDiameter).strip())  # should be in meters\n    # delay beam larger than VLA field of view at all freqs\n    d['uvres_full'] = np.round(d['dishdiameter']\n                               / (3e-1 / d['freq'].min()) / 2).astype('int')\n\n    if not all(('npixx_full' in d, 'npixy_full' in d)):\n        # uvw from get_uvw already in lambda at ch0\n        urange = d['urange'][d['scan']] * (d['freq'].max()\n                                           / d['freq_orig'][0])\n        vrange = d['vrange'][d['scan']] * (d['freq'].max()\n                                           / d['freq_orig'][0])\n        # power array for 2**i * 3**j\n        powers = np.fromfunction(lambda i, j: 2**i*3**j,\n                                 (14, 10), dtype='int')\n        rangex = np.round(d['uvoversample']*urange).astype('int')\n        rangey = np.round(d['uvoversample']*vrange).astype('int')\n        largerx = np.where(powers - rangex / d['uvres_full'] > 0,\n                           powers, powers[-1, -1])\n        p2x, p3x = np.where(largerx == largerx.min())\n        largery = np.where(powers - rangey / d['uvres_full'] > 0,\n                           powers, powers[-1, -1])\n        p2y, p3y = np.where(largery == largery.min())\n        d['npixx_full'] = (2**p2x * 3**p3x)[0]\n        d['npixy_full'] = (2**p2y * 3**p3y)[0]\n\n    # define ants/bls\n    # hacking here to fit observatory-specific use of antenna names\n    if 'VLA' in str(sdm['ExecBlock'][0]['telescopeName']):\n# find config first, then antids, then ant names\n        configid = [str(row.configDescriptionId) for row in sdm['Main']\n                    if d['scan'] == int(row.scanNumber)][0]\n        antids = [str(row.antennaId) for row in sdm['ConfigDescription']\n                  if configid == row.configDescriptionId][0].split(' ')[2:]\n        d['ants'] = [int(str(row.name).lstrip('ea'))\n                     for antid in antids\n                     for row in sdm['Antenna']\n                     if antid == str(row.antennaId)]\n# Not complete. Execblock defines ants per scan, which can change.\n#        d['ants'] = [int(ant.name.lstrip('ea'))\n#                     for ant in sdm['Antenna']]\n    elif 'GMRT' in str(sdm['ExecBlock'][0]['telescopeName']):\n        d['ants'] = [int(str(ant.antennaId).split('_')[1])\n                     for ant in sdm['Antenna']]\n\n    # remove unwanted ants\n    for ant in d['excludeants']:\n        d['ants'].remove(ant)\n    # required to assure that added antennas don't confuse cal antenna parsing\n    d['ants'].sort()\n\n    d['nants'] = len(d['ants'])\n#    d['blarr'] = np.array([[d['ants'][i],d['ants'][j]]\n#                           for j in range(d['nants']) for i in range(0,j)])\n    d['nbl'] = d['nants']*(d['nants']-1)/2\n\n    # define times\n    d['starttime_mjd'] = scans[d['scan']]['startmjd']\n\n    # assume inttime same for all scans\n    scan = sdm.scan(d['scan'])\n    d['inttime'] = scan.bdf.get_integration(0).interval\n    d['nints'] = int(scan.bdf.numIntegration)\n\n    # define pols\n    d['pols_orig'] = [pol\n                      for pol in (str(sdm['Polarization'][0]\n                                      .corrType).strip()\n                                      .split(' '))\n                      if pol in ['XX', 'YY', 'XY', 'YX',\n                                 'RR', 'LL', 'RL', 'LR']]\n    d['npol_orig'] = int(sdm['Polarization'][0].numCorr)\n\n    # summarize metadata\n    logger.info('\\n')\n    logger.info('Metadata summary:')\n    logger.info('\\t Working directory and data at %s, %s'\n                % (d['workdir'], os.path.basename(d['filename'])))\n    logger.info('\\t Using scan %d, source %s'\n                % (int(d['scan']), d['source']))\n    logger.info('\\t nants, nbl: %d, %d' % (d['nants'], d['nbl']))\n    logger.info('\\t Freq range (%.3f -- %.3f). %d spw with %d chans.'\n                % (d['freq'].min(), d['freq'].max(), d['nspw'], d['nchan']))\n    logger.info('\\t Scan has %d ints (%.1f s) and inttime %.3f s'\n                % (d['nints'], d['nints']*d['inttime'], d['inttime']))\n    logger.info('\\t %d polarizations: %s'\n                % (d['npol_orig'], d['pols_orig']))\n    logger.info('\\t Ideal uvgrid npix=(%d,%d) and res=%d (oversample %.1f)'\n                % (d['npixx_full'], d['npixy_full'], d['uvres_full'],\n                   d['uvoversample']))\n\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread a given range of integrations from a given scan.", "response": "def read_bdf(sdmfile, scannum, nskip=0, readints=0, bdfdir=''):\n    \"\"\" Uses sdmpy to read a given range of integrations from sdm of given scan.\n\n    readints=0 will read all of bdf (skipping nskip).\n    \"\"\"\n\n    assert os.path.exists(sdmfile), 'sdmfile %s does not exist' % sdmfile\n\n    sdm = getsdm(sdmfile, bdfdir=bdfdir)\n    scan = sdm.scan(scannum)\n    assert scan.bdf.fname, 'bdfstr not defined for scan %d' % scannum\n\n    if readints == 0:\n        readints = scan.bdf.numIntegration - nskip\n\n    logger.info('Reading %d ints starting at int %d' % (readints, nskip))\n    npols = len(sdmpy.scan.sdmarray(sdm['Polarization'][0].corrType))\n    data = np.empty( (readints, scan.bdf.numBaseline, sum(scan.numchans), npols), dtype='complex64', order='C')\n    data[:] = scan.bdf.get_data(trange=[nskip, nskip+readints]).reshape(data.shape)\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread bdf format data into numpy array for realtime pipeline.", "response": "def read_bdf_segment(d, segment=-1):\n    \"\"\" Reads bdf (sdm) format data into numpy array for realtime pipeline.\n\n    d defines pipeline state. assumes segmenttimes defined by RT.set_pipeline.\n    d should have 'writebdfpkl' key to define\n    boolean for writing to bdfpkls in ASDMBinary directory.\n    \"\"\"\n\n    # define integration range\n    if segment != -1:\n        assert 'segmenttimes' in d\n        assert segment < d['nsegments'], \\\n            'segment %d is too big for nsegments %d' % (segment,\n                                                        d['nsegments'])\n        readints = d['readints']\n        nskip = (24*3600*(d['segmenttimes'][segment, 0]\n                          - d['starttime_mjd'])\n                 / d['inttime']).astype(int)\n        logger.info('Reading scan %d, segment %d/%d, times %s to %s'\n                    % (d['scan'], segment,\n                       len(d['segmenttimes'])-1,\n                       qa.time(qa.quantity(d['segmenttimes'][segment, 0], 'd'),\n                               form=['hms'], prec=9)[0],\n                       qa.time(qa.quantity(d['segmenttimes'][segment, 1], 'd'),\n                               form=['hms'], prec=9)[0]))\n    else:\n        nskip = 0\n        readints = 0\n\n    # read (all) data\n    if 'bdfdir' not in d:\n        d['bdfdir'] = None\n\n    data = read_bdf(d['filename'], d['scan'], nskip=nskip, readints=readints, bdfdir=d['bdfdir']).astype('complex64')\n\n    # read Flag.xml and apply flags for given ant/time range\n    # currently only implemented for segmented data\n    if d['applyonlineflags'] and segment > -1:\n        sdm = getsdm(d['filename'], bdfdir=d['bdfdir'])\n\n        allantdict = dict(zip([str(ant.antennaId) for ant in sdm['Antenna']],\n                              [int(str(ant.name).lstrip('ea'))\n                               for ant in sdm['Antenna']]))\n        antflags = [(allantdict[str(flag.antennaId).split(' ')[2]],\n                     int(flag.startTime)/(1e9*24*3600),\n                     int(flag.endTime)/(1e9*24*3600))\n                    for flag in sdm['Flag']]  # assumes one flag per entry\n        logger.info('Found online flags for %d antenna/time ranges.'\n                    % (len(antflags)))\n        blarr = calc_blarr(d)  # d may define different ants than in allantdict\n        timearr = np.linspace(d['segmenttimes'][segment][0],\n                              d['segmenttimes'][segment][1], d['readints'])\n        badints_cum = []\n        for antflag in antflags:\n            antnum, time0, time1 = antflag\n            badbls = np.where((blarr == antnum).any(axis=1))[0]\n            badints = np.where((timearr >= time0) & (timearr <= time1))[0]\n            for badint in badints:\n                data[badint, badbls] = 0j\n            badints_cum = badints_cum + list(badints)\n        logger.info('Applied online flags to %d ints.'\n                    % (len(set(badints_cum))))\n    elif segment == -1:\n        logger.warn('Online flags not yet supported without segments.')\n    else:\n        logger.info('Not applying online flags.')\n\n    # test that spw are in freq sorted order\n    # only one use case supported: rolled spw\n    dfreq = np.array([d['spw_reffreq'][i+1] - d['spw_reffreq'][i]\n                      for i in range(len(d['spw_reffreq'])-1)])\n    dfreqneg = [df for df in dfreq if df < 0]\n    # if spw are permuted, then roll them.\n    # !! not a perfect test of permutability!!\n    if len(dfreqneg) <= 1:\n        if len(dfreqneg) == 1:\n            logger.info('Rolling spw frequencies to increasing order: %s'\n                        % str(d['spw_reffreq']))\n            rollch = np.sum([d['spw_nchan'][ss]\n                             for ss in range(np.where(dfreq < 0)[0][0]+1)])\n            data = np.roll(data, rollch, axis=2)\n    else:\n        raise StandardError('SPW out of order and can\\'t be permuted '\n                            'to increasing order: %s'\n                            % str(d['spw_reffreq']))\n\n    # optionally integrate (downsample)\n    if ((d['read_tdownsample'] > 1) or (d['read_fdownsample'] > 1)):\n        sh = data.shape\n        tsize = sh[0]/d['read_tdownsample']\n        fsize = sh[2]/d['read_fdownsample']\n        data2 = np.zeros((tsize, sh[1], fsize, sh[3]), dtype='complex64')\n        if d['read_tdownsample'] > 1:\n            logger.info('Downsampling in time by %d' % d['read_tdownsample'])\n            for i in range(tsize):\n                data2[i] = data[\n                    i*d['read_tdownsample']:(i+1)*d['read_tdownsample']\n                    ].mean(axis=0)\n        if d['read_fdownsample'] > 1:\n            logger.info('Downsampling in frequency by %d'\n                        % d['read_fdownsample'])\n            for i in range(fsize):\n                data2[:, :, i, :] = data[\n                    :, :, i * d['read_fdownsample']:(i+1)*d['read_fdownsample']\n                    ].mean(axis=2)\n        data = data2\n\n    takepol = [d['pols_orig'].index(pol) for pol in d['pols']]\n    logger.debug('Selecting pols %s' % d['pols'])\n\n    return data.take(d['chans'], axis=2).take(takepol, axis=3)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_uvw_segment(d, segment=-1):\n\n    # define times to read\n    if segment != -1:\n        assert 'segmenttimes' in d, 'd must have segmenttimes defined'\n\n        t0 = d['segmenttimes'][segment][0]\n        t1 = d['segmenttimes'][segment][1]\n        datetime = qa.time(qa.quantity((t1+t0)/2, 'd'),\n                           form=['ymdhms'], prec=9)[0]\n        logger.debug('Calculating uvw for segment %d' % (segment))\n    else:\n        datetime = 0\n\n    (u, v, w) = calc_uvw(d['filename'], d['scan'],\n                         datetime=datetime, bdfdir=d['bdfdir'])\n\n    # cast to units of lambda at first channel.\n    # -1 keeps consistent with ms reading convention\n    u = u * d['freq_orig'][0] * (1e9/3e8) * (-1)\n    v = v * d['freq_orig'][0] * (1e9/3e8) * (-1)\n    w = w * d['freq_orig'][0] * (1e9/3e8) * (-1)\n\n    return u.astype('float32'), v.astype('float32'), w.astype('float32')", "response": "Calculates the uvw for each baseline at mid time of a given segment."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nuse sdmpy to get all sources and ra dec per scan as dict", "response": "def read_sources(sdmname):\n    \"\"\" Use sdmpy to get all sources and ra,dec per scan as dict \"\"\"\n\n    sdm = getsdm(sdmname)\n    sourcedict = {}\n\n    for row in sdm['Field']:\n        src = str(row.fieldName)\n        sourcenum = int(row.sourceId)\n        direction = str(row.referenceDir)\n        (ra,dec) = [float(val) for val in direction.split(' ')[3:]]  # skip first two values in string\n\n        sourcedict[sourcenum] = {}\n        sourcedict[sourcenum]['source'] = src\n        sourcedict[sourcenum]['ra'] = ra\n        sourcedict[sourcenum]['dec'] = dec\n\n    return sourcedict"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_scans(sdmfile, bdfdir=''):\n\n    sdm = getsdm(sdmfile, bdfdir=bdfdir)\n    scandict = {}\n    skippedscans = []\n\n    for scan in sdm.scans():\n        scannum = int(scan.idx)\n        scandict[scannum] = {}\n\n        intentstr = ' '.join(scan.intents)\n        src = scan.source\n\n        scandict[scannum]['source'] = src\n        scandict[scannum]['intent'] = intentstr\n\n        # bdf specific properties\n        try:\n            startmjd = scan.bdf.startTime\n            nints = scan.bdf.numIntegration\n            interval = scan.bdf.get_integration(0).interval\n            endmjd = startmjd + (nints*interval)/(24*3600)\n            bdfstr = scan.bdf.fname\n        except AttributeError, IOError:\n            skippedscans.append(scannum)\n        else:\n            scandict[scannum]['startmjd'] = startmjd\n            scandict[scannum]['endmjd'] = endmjd\n            scandict[scannum]['duration'] = endmjd-startmjd\n            scandict[scannum]['nints'] = nints\n            scandict[scannum]['bdfstr'] = bdfstr\n\n            # clear reference to nonexistent BDFs (either bad or not in standard locations)\n            if (not os.path.exists(scandict[scannum]['bdfstr'])) or ('X1' in bdfstr):\n                scandict[scannum]['bdfstr'] = None\n                logger.debug('Invalid bdf for %d of %s' % (scannum, sdmfile) )\n\n    if skippedscans:\n        logger.warn('No BDF found for scans {0}'.format(skippedscans))\n\n    return scandict", "response": "Read all scans and info needed for rtpipe as dict"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sdm2ms(sdmfile, msfile, scan, inttime='0'):\n\n    # fill ms file\n    if os.path.exists(msfile):\n        logger.debug('%s already set.' % msfile)\n    else:\n        logger.info('No %s found. Creating anew.' % msfile)\n        if inttime != '0':\n            logger.info('Filtering by int time.')\n            call(['asdm2MS', '--ocm', 'co',\n                             '--icm', 'co', '--lazy', '--scans',\n                             scan, sdmfile, msfile + '.tmp'])\n            cfg = tasklib.SplitConfig()  # configure split\n            cfg.vis = msfile + '.tmp'\n            cfg.out = msfile\n            cfg.timebin = inttime\n            cfg.col = 'data'\n            cfg.antenna = '*&*'  # discard autos\n            tasklib.split(cfg)  # run task\n            # clean up\n            rmtree(msfile+'.tmp')\n        else:\n            call(['asdm2MS', '--ocm', 'co',\n                             '--icm', 'co', '--lazy', '--scans',\n                             scan, sdmfile, msfile])\n\n    return msfile", "response": "Convert a single sdm file to a single ms file."}
